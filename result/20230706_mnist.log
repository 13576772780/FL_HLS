nohup: ignoring input
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.269, Test loss: 2.258, Test accuracy: 30.05 

Round   0, Global train loss: 2.269, Global test loss: 2.294, Global test accuracy: 23.97 

Round   1, Train loss: 2.147, Test loss: 2.150, Test accuracy: 37.07 

Round   1, Global train loss: 2.147, Global test loss: 2.277, Global test accuracy: 30.58 

Round   2, Train loss: 1.954, Test loss: 2.041, Test accuracy: 42.97 

Round   2, Global train loss: 1.954, Global test loss: 2.250, Global test accuracy: 18.78 

Round   3, Train loss: 1.765, Test loss: 1.950, Test accuracy: 52.85 

Round   3, Global train loss: 1.765, Global test loss: 2.236, Global test accuracy: 18.57 

Round   4, Train loss: 1.762, Test loss: 1.864, Test accuracy: 61.25 

Round   4, Global train loss: 1.762, Global test loss: 2.228, Global test accuracy: 29.30 

Round   5, Train loss: 1.622, Test loss: 1.773, Test accuracy: 71.45 

Round   5, Global train loss: 1.622, Global test loss: 2.156, Global test accuracy: 33.30 

Round   6, Train loss: 1.568, Test loss: 1.707, Test accuracy: 77.80 

Round   6, Global train loss: 1.568, Global test loss: 2.127, Global test accuracy: 33.45 

Round   7, Train loss: 1.565, Test loss: 1.684, Test accuracy: 80.50 

Round   7, Global train loss: 1.565, Global test loss: 2.186, Global test accuracy: 23.27 

Round   8, Train loss: 1.695, Test loss: 1.603, Test accuracy: 90.17 

Round   8, Global train loss: 1.695, Global test loss: 2.174, Global test accuracy: 33.38 

Round   9, Train loss: 1.522, Test loss: 1.582, Test accuracy: 90.63 

Round   9, Global train loss: 1.522, Global test loss: 2.234, Global test accuracy: 19.32 

Round  10, Train loss: 1.502, Test loss: 1.567, Test accuracy: 92.10 

Round  10, Global train loss: 1.502, Global test loss: 2.164, Global test accuracy: 27.22 

Round  11, Train loss: 1.537, Test loss: 1.556, Test accuracy: 92.48 

Round  11, Global train loss: 1.537, Global test loss: 2.133, Global test accuracy: 33.27 

Round  12, Train loss: 1.487, Test loss: 1.551, Test accuracy: 92.73 

Round  12, Global train loss: 1.487, Global test loss: 2.139, Global test accuracy: 39.37 

Round  13, Train loss: 1.492, Test loss: 1.545, Test accuracy: 93.08 

Round  13, Global train loss: 1.492, Global test loss: 2.228, Global test accuracy: 23.60 

Round  14, Train loss: 1.535, Test loss: 1.522, Test accuracy: 95.80 

Round  14, Global train loss: 1.535, Global test loss: 2.147, Global test accuracy: 32.20 

Round  15, Train loss: 1.479, Test loss: 1.521, Test accuracy: 95.92 

Round  15, Global train loss: 1.479, Global test loss: 2.207, Global test accuracy: 23.12 

Round  16, Train loss: 1.494, Test loss: 1.513, Test accuracy: 96.33 

Round  16, Global train loss: 1.494, Global test loss: 2.140, Global test accuracy: 27.50 

Round  17, Train loss: 1.478, Test loss: 1.512, Test accuracy: 96.32 

Round  17, Global train loss: 1.478, Global test loss: 2.199, Global test accuracy: 21.70 

Round  18, Train loss: 1.482, Test loss: 1.511, Test accuracy: 96.28 

Round  18, Global train loss: 1.482, Global test loss: 2.050, Global test accuracy: 47.35 

Round  19, Train loss: 1.486, Test loss: 1.507, Test accuracy: 96.30 

Round  19, Global train loss: 1.486, Global test loss: 2.129, Global test accuracy: 34.85 

Round  20, Train loss: 1.471, Test loss: 1.506, Test accuracy: 96.30 

Round  20, Global train loss: 1.471, Global test loss: 2.159, Global test accuracy: 32.62 

Round  21, Train loss: 1.471, Test loss: 1.506, Test accuracy: 96.25 

Round  21, Global train loss: 1.471, Global test loss: 2.204, Global test accuracy: 18.07 

Round  22, Train loss: 1.470, Test loss: 1.506, Test accuracy: 96.30 

Round  22, Global train loss: 1.470, Global test loss: 2.174, Global test accuracy: 26.98 

Round  23, Train loss: 1.474, Test loss: 1.505, Test accuracy: 96.32 

Round  23, Global train loss: 1.474, Global test loss: 2.108, Global test accuracy: 38.45 

Round  24, Train loss: 1.473, Test loss: 1.505, Test accuracy: 96.33 

Round  24, Global train loss: 1.473, Global test loss: 2.191, Global test accuracy: 29.92 

Round  25, Train loss: 1.468, Test loss: 1.504, Test accuracy: 96.33 

Round  25, Global train loss: 1.468, Global test loss: 2.111, Global test accuracy: 32.90 

Round  26, Train loss: 1.477, Test loss: 1.503, Test accuracy: 96.38 

Round  26, Global train loss: 1.477, Global test loss: 2.143, Global test accuracy: 28.82 

Round  27, Train loss: 1.471, Test loss: 1.503, Test accuracy: 96.42 

Round  27, Global train loss: 1.471, Global test loss: 2.195, Global test accuracy: 24.63 

Round  28, Train loss: 1.468, Test loss: 1.503, Test accuracy: 96.47 

Round  28, Global train loss: 1.468, Global test loss: 2.073, Global test accuracy: 43.62 

Round  29, Train loss: 1.466, Test loss: 1.503, Test accuracy: 96.48 

Round  29, Global train loss: 1.466, Global test loss: 2.164, Global test accuracy: 27.55 

Round  30, Train loss: 1.472, Test loss: 1.502, Test accuracy: 96.47 

Round  30, Global train loss: 1.472, Global test loss: 2.072, Global test accuracy: 54.70 

Round  31, Train loss: 1.469, Test loss: 1.502, Test accuracy: 96.48 

Round  31, Global train loss: 1.469, Global test loss: 2.130, Global test accuracy: 35.90 

Round  32, Train loss: 1.469, Test loss: 1.502, Test accuracy: 96.50 

Round  32, Global train loss: 1.469, Global test loss: 2.099, Global test accuracy: 51.48 

Round  33, Train loss: 1.467, Test loss: 1.501, Test accuracy: 96.53 

Round  33, Global train loss: 1.467, Global test loss: 2.093, Global test accuracy: 38.12 

Round  34, Train loss: 1.468, Test loss: 1.501, Test accuracy: 96.45 

Round  34, Global train loss: 1.468, Global test loss: 2.172, Global test accuracy: 26.12 

Round  35, Train loss: 1.470, Test loss: 1.501, Test accuracy: 96.45 

Round  35, Global train loss: 1.470, Global test loss: 2.182, Global test accuracy: 30.18 

Round  36, Train loss: 1.467, Test loss: 1.501, Test accuracy: 96.42 

Round  36, Global train loss: 1.467, Global test loss: 2.111, Global test accuracy: 34.18 

Round  37, Train loss: 1.466, Test loss: 1.501, Test accuracy: 96.43 

Round  37, Global train loss: 1.466, Global test loss: 2.165, Global test accuracy: 24.55 

Round  38, Train loss: 1.468, Test loss: 1.501, Test accuracy: 96.40 

Round  38, Global train loss: 1.468, Global test loss: 2.147, Global test accuracy: 28.60 

Round  39, Train loss: 1.467, Test loss: 1.501, Test accuracy: 96.38 

Round  39, Global train loss: 1.467, Global test loss: 2.120, Global test accuracy: 33.60 

Round  40, Train loss: 1.468, Test loss: 1.501, Test accuracy: 96.38 

Round  40, Global train loss: 1.468, Global test loss: 2.065, Global test accuracy: 40.85 

Round  41, Train loss: 1.466, Test loss: 1.501, Test accuracy: 96.38 

Round  41, Global train loss: 1.466, Global test loss: 2.070, Global test accuracy: 40.70 

Round  42, Train loss: 1.466, Test loss: 1.501, Test accuracy: 96.38 

Round  42, Global train loss: 1.466, Global test loss: 2.122, Global test accuracy: 34.30 

Round  43, Train loss: 1.466, Test loss: 1.501, Test accuracy: 96.42 

Round  43, Global train loss: 1.466, Global test loss: 2.077, Global test accuracy: 35.22 

Round  44, Train loss: 1.465, Test loss: 1.500, Test accuracy: 96.38 

Round  44, Global train loss: 1.465, Global test loss: 2.244, Global test accuracy: 18.23 

Round  45, Train loss: 1.466, Test loss: 1.500, Test accuracy: 96.38 

Round  45, Global train loss: 1.466, Global test loss: 2.152, Global test accuracy: 29.73 

Round  46, Train loss: 1.469, Test loss: 1.500, Test accuracy: 96.38 

Round  46, Global train loss: 1.469, Global test loss: 2.096, Global test accuracy: 38.43 

Round  47, Train loss: 1.465, Test loss: 1.500, Test accuracy: 96.42 

Round  47, Global train loss: 1.465, Global test loss: 2.126, Global test accuracy: 33.57 

Round  48, Train loss: 1.466, Test loss: 1.500, Test accuracy: 96.43 

Round  48, Global train loss: 1.466, Global test loss: 2.107, Global test accuracy: 32.73 

Round  49, Train loss: 1.465, Test loss: 1.500, Test accuracy: 96.43 

Round  49, Global train loss: 1.465, Global test loss: 2.151, Global test accuracy: 31.35 

Final Round, Train loss: 1.467, Test loss: 1.499, Test accuracy: 96.47 

Final Round, Global train loss: 1.467, Global test loss: 2.151, Global test accuracy: 31.35 

Average accuracy final 10 rounds: 96.39999999999999 

Average global accuracy final 10 rounds: 33.51166666666666 

893.3115334510803
[3.383993148803711, 4.458006858825684, 5.529992580413818, 6.605836391448975, 7.6764819622039795, 8.746079444885254, 9.822452545166016, 10.90629506111145, 11.976627826690674, 13.050469398498535, 14.116493701934814, 15.180103778839111, 16.244740962982178, 17.31470227241516, 18.379292726516724, 19.443716287612915, 20.50457739830017, 21.5661039352417, 22.627143383026123, 23.72835683822632, 24.78862166404724, 25.849456787109375, 26.91216516494751, 27.973299503326416, 29.060192108154297, 30.12612557411194, 31.19174814224243, 32.26194500923157, 33.3240852355957, 34.390953540802, 35.45638728141785, 36.521278858184814, 37.58671712875366, 38.661171436309814, 39.72237515449524, 40.786059856414795, 41.84854030609131, 42.90968346595764, 43.97392177581787, 45.03327202796936, 46.09535360336304, 47.155484676361084, 48.225693225860596, 49.28915548324585, 50.353055238723755, 51.41749668121338, 52.483217000961304, 53.54917931556702, 54.61017942428589, 55.67070722579956, 57.793580055236816]
[30.05, 37.06666666666667, 42.96666666666667, 52.85, 61.25, 71.45, 77.8, 80.5, 90.16666666666667, 90.63333333333334, 92.1, 92.48333333333333, 92.73333333333333, 93.08333333333333, 95.8, 95.91666666666667, 96.33333333333333, 96.31666666666666, 96.28333333333333, 96.3, 96.3, 96.25, 96.3, 96.31666666666666, 96.33333333333333, 96.33333333333333, 96.38333333333334, 96.41666666666667, 96.46666666666667, 96.48333333333333, 96.46666666666667, 96.48333333333333, 96.5, 96.53333333333333, 96.45, 96.45, 96.41666666666667, 96.43333333333334, 96.4, 96.38333333333334, 96.38333333333334, 96.38333333333334, 96.38333333333334, 96.41666666666667, 96.38333333333334, 96.38333333333334, 96.38333333333334, 96.41666666666667, 96.43333333333334, 96.43333333333334, 96.46666666666667]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.257, Test loss: 2.239, Test accuracy: 20.35 

Round   0, Global train loss: 2.257, Global test loss: 2.276, Global test accuracy: 15.00 

Round   1, Train loss: 2.119, Test loss: 2.149, Test accuracy: 36.35 

Round   1, Global train loss: 2.119, Global test loss: 2.252, Global test accuracy: 27.50 

Round   2, Train loss: 1.965, Test loss: 2.036, Test accuracy: 44.75 

Round   2, Global train loss: 1.965, Global test loss: 2.177, Global test accuracy: 26.05 

Round   3, Train loss: 1.811, Test loss: 1.915, Test accuracy: 57.63 

Round   3, Global train loss: 1.811, Global test loss: 2.130, Global test accuracy: 32.57 

Round   4, Train loss: 1.758, Test loss: 1.849, Test accuracy: 64.72 

Round   4, Global train loss: 1.758, Global test loss: 2.088, Global test accuracy: 43.82 

Round   5, Train loss: 1.823, Test loss: 1.771, Test accuracy: 73.18 

Round   5, Global train loss: 1.823, Global test loss: 1.999, Global test accuracy: 56.92 

Round   6, Train loss: 1.751, Test loss: 1.748, Test accuracy: 74.32 

Round   6, Global train loss: 1.751, Global test loss: 2.059, Global test accuracy: 39.38 

Round   7, Train loss: 1.701, Test loss: 1.730, Test accuracy: 75.73 

Round   7, Global train loss: 1.701, Global test loss: 2.035, Global test accuracy: 44.05 

Round   8, Train loss: 1.732, Test loss: 1.715, Test accuracy: 77.25 

Round   8, Global train loss: 1.732, Global test loss: 1.961, Global test accuracy: 51.37 

Round   9, Train loss: 1.701, Test loss: 1.699, Test accuracy: 77.40 

Round   9, Global train loss: 1.701, Global test loss: 1.983, Global test accuracy: 48.43 

Round  10, Train loss: 1.666, Test loss: 1.688, Test accuracy: 78.80 

Round  10, Global train loss: 1.666, Global test loss: 1.939, Global test accuracy: 53.70 

Round  11, Train loss: 1.756, Test loss: 1.681, Test accuracy: 79.55 

Round  11, Global train loss: 1.756, Global test loss: 1.975, Global test accuracy: 49.17 

Round  12, Train loss: 1.680, Test loss: 1.630, Test accuracy: 84.35 

Round  12, Global train loss: 1.680, Global test loss: 1.923, Global test accuracy: 55.52 

Round  13, Train loss: 1.585, Test loss: 1.638, Test accuracy: 83.13 

Round  13, Global train loss: 1.585, Global test loss: 1.908, Global test accuracy: 58.95 

Round  14, Train loss: 1.621, Test loss: 1.632, Test accuracy: 83.38 

Round  14, Global train loss: 1.621, Global test loss: 1.851, Global test accuracy: 67.97 

Round  15, Train loss: 1.609, Test loss: 1.628, Test accuracy: 83.70 

Round  15, Global train loss: 1.609, Global test loss: 1.903, Global test accuracy: 56.27 

Round  16, Train loss: 1.565, Test loss: 1.631, Test accuracy: 83.33 

Round  16, Global train loss: 1.565, Global test loss: 1.875, Global test accuracy: 58.35 

Round  17, Train loss: 1.608, Test loss: 1.630, Test accuracy: 83.57 

Round  17, Global train loss: 1.608, Global test loss: 1.851, Global test accuracy: 62.65 

Round  18, Train loss: 1.622, Test loss: 1.610, Test accuracy: 85.62 

Round  18, Global train loss: 1.622, Global test loss: 1.810, Global test accuracy: 68.55 

Round  19, Train loss: 1.599, Test loss: 1.608, Test accuracy: 85.68 

Round  19, Global train loss: 1.599, Global test loss: 1.894, Global test accuracy: 55.32 

Round  20, Train loss: 1.691, Test loss: 1.608, Test accuracy: 85.67 

Round  20, Global train loss: 1.691, Global test loss: 1.876, Global test accuracy: 59.85 

Round  21, Train loss: 1.656, Test loss: 1.608, Test accuracy: 85.72 

Round  21, Global train loss: 1.656, Global test loss: 1.828, Global test accuracy: 65.93 

Round  22, Train loss: 1.569, Test loss: 1.605, Test accuracy: 85.93 

Round  22, Global train loss: 1.569, Global test loss: 1.855, Global test accuracy: 62.27 

Round  23, Train loss: 1.705, Test loss: 1.605, Test accuracy: 85.93 

Round  23, Global train loss: 1.705, Global test loss: 1.862, Global test accuracy: 61.05 

Round  24, Train loss: 1.647, Test loss: 1.605, Test accuracy: 85.92 

Round  24, Global train loss: 1.647, Global test loss: 1.806, Global test accuracy: 67.58 

Round  25, Train loss: 1.602, Test loss: 1.604, Test accuracy: 85.92 

Round  25, Global train loss: 1.602, Global test loss: 1.782, Global test accuracy: 69.47 

Round  26, Train loss: 1.648, Test loss: 1.604, Test accuracy: 86.00 

Round  26, Global train loss: 1.648, Global test loss: 1.756, Global test accuracy: 74.82 

Round  27, Train loss: 1.694, Test loss: 1.604, Test accuracy: 85.97 

Round  27, Global train loss: 1.694, Global test loss: 1.770, Global test accuracy: 71.78 

Round  28, Train loss: 1.587, Test loss: 1.604, Test accuracy: 85.95 

Round  28, Global train loss: 1.587, Global test loss: 1.781, Global test accuracy: 70.85 

Round  29, Train loss: 1.687, Test loss: 1.603, Test accuracy: 85.93 

Round  29, Global train loss: 1.687, Global test loss: 1.871, Global test accuracy: 59.15 

Round  30, Train loss: 1.562, Test loss: 1.603, Test accuracy: 85.98 

Round  30, Global train loss: 1.562, Global test loss: 1.763, Global test accuracy: 73.25 

Round  31, Train loss: 1.601, Test loss: 1.604, Test accuracy: 85.92 

Round  31, Global train loss: 1.601, Global test loss: 1.764, Global test accuracy: 70.13 

Round  32, Train loss: 1.593, Test loss: 1.603, Test accuracy: 85.90 

Round  32, Global train loss: 1.593, Global test loss: 1.741, Global test accuracy: 75.97 

Round  33, Train loss: 1.553, Test loss: 1.602, Test accuracy: 86.02 

Round  33, Global train loss: 1.553, Global test loss: 1.753, Global test accuracy: 73.70 

Round  34, Train loss: 1.544, Test loss: 1.602, Test accuracy: 86.02 

Round  34, Global train loss: 1.544, Global test loss: 1.730, Global test accuracy: 77.08 

Round  35, Train loss: 1.588, Test loss: 1.602, Test accuracy: 86.02 

Round  35, Global train loss: 1.588, Global test loss: 1.751, Global test accuracy: 73.68 

Round  36, Train loss: 1.645, Test loss: 1.603, Test accuracy: 85.87 

Round  36, Global train loss: 1.645, Global test loss: 1.733, Global test accuracy: 77.03 

Round  37, Train loss: 1.691, Test loss: 1.602, Test accuracy: 85.98 

Round  37, Global train loss: 1.691, Global test loss: 1.735, Global test accuracy: 76.95 

Round  38, Train loss: 1.587, Test loss: 1.601, Test accuracy: 86.07 

Round  38, Global train loss: 1.587, Global test loss: 1.777, Global test accuracy: 69.83 

Round  39, Train loss: 1.653, Test loss: 1.602, Test accuracy: 85.98 

Round  39, Global train loss: 1.653, Global test loss: 1.732, Global test accuracy: 76.68 

Round  40, Train loss: 1.540, Test loss: 1.602, Test accuracy: 86.07 

Round  40, Global train loss: 1.540, Global test loss: 1.721, Global test accuracy: 77.05 

Round  41, Train loss: 1.598, Test loss: 1.602, Test accuracy: 86.10 

Round  41, Global train loss: 1.598, Global test loss: 1.761, Global test accuracy: 70.18 

Round  42, Train loss: 1.541, Test loss: 1.601, Test accuracy: 86.17 

Round  42, Global train loss: 1.541, Global test loss: 1.716, Global test accuracy: 77.45 

Round  43, Train loss: 1.589, Test loss: 1.600, Test accuracy: 86.18 

Round  43, Global train loss: 1.589, Global test loss: 1.740, Global test accuracy: 74.50 

Round  44, Train loss: 1.696, Test loss: 1.600, Test accuracy: 86.25 

Round  44, Global train loss: 1.696, Global test loss: 1.756, Global test accuracy: 70.32 

Round  45, Train loss: 1.634, Test loss: 1.599, Test accuracy: 86.23 

Round  45, Global train loss: 1.634, Global test loss: 1.742, Global test accuracy: 71.63 

Round  46, Train loss: 1.636, Test loss: 1.600, Test accuracy: 86.13 

Round  46, Global train loss: 1.636, Global test loss: 1.724, Global test accuracy: 76.73 

Round  47, Train loss: 1.585, Test loss: 1.600, Test accuracy: 86.10 

Round  47, Global train loss: 1.585, Global test loss: 1.741, Global test accuracy: 72.37 

Round  48, Train loss: 1.685, Test loss: 1.600, Test accuracy: 86.10 

Round  48, Global train loss: 1.685, Global test loss: 1.800, Global test accuracy: 65.98 

Round  49, Train loss: 1.589, Test loss: 1.600, Test accuracy: 86.20 

Round  49, Global train loss: 1.589, Global test loss: 1.751, Global test accuracy: 72.35 

Final Round, Train loss: 1.587, Test loss: 1.599, Test accuracy: 86.20 

Final Round, Global train loss: 1.587, Global test loss: 1.751, Global test accuracy: 72.35 

Average accuracy final 10 rounds: 86.15333333333334 

Average global accuracy final 10 rounds: 72.85666666666667 

917.1646857261658
[2.8182871341705322, 3.8924379348754883, 4.961000919342041, 6.120694875717163, 7.198871374130249, 8.272608757019043, 9.34454083442688, 10.450749635696411, 11.52804970741272, 12.595650434494019, 13.99389362335205, 15.402769804000854, 16.80230689048767, 18.208297967910767, 19.62325119972229, 20.69701385498047, 21.7673556804657, 22.843023538589478, 23.95638608932495, 25.019542932510376, 26.084436178207397, 27.15435242652893, 28.220364332199097, 29.286921739578247, 30.353150606155396, 31.41774821281433, 32.48541831970215, 33.58155608177185, 34.64791464805603, 35.712202310562134, 36.77947402000427, 37.837268352508545, 38.915117263793945, 39.98513579368591, 41.05243396759033, 42.1214554309845, 43.192201137542725, 44.26372003555298, 45.33181142807007, 46.3918023109436, 47.45935916900635, 48.52623677253723, 49.59912085533142, 50.669079303741455, 51.73905968666077, 52.8082172870636, 53.875755310058594, 54.94080972671509, 56.00866150856018, 57.08364224433899, 59.21181058883667]
[20.35, 36.35, 44.75, 57.63333333333333, 64.71666666666667, 73.18333333333334, 74.31666666666666, 75.73333333333333, 77.25, 77.4, 78.8, 79.55, 84.35, 83.13333333333334, 83.38333333333334, 83.7, 83.33333333333333, 83.56666666666666, 85.61666666666666, 85.68333333333334, 85.66666666666667, 85.71666666666667, 85.93333333333334, 85.93333333333334, 85.91666666666667, 85.91666666666667, 86.0, 85.96666666666667, 85.95, 85.93333333333334, 85.98333333333333, 85.91666666666667, 85.9, 86.01666666666667, 86.01666666666667, 86.01666666666667, 85.86666666666666, 85.98333333333333, 86.06666666666666, 85.98333333333333, 86.06666666666666, 86.1, 86.16666666666667, 86.18333333333334, 86.25, 86.23333333333333, 86.13333333333334, 86.1, 86.1, 86.2, 86.2]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.294, Test loss: 2.299, Test accuracy: 24.63 

Round   1, Train loss: 2.290, Test loss: 2.290, Test accuracy: 16.43 

Round   2, Train loss: 2.254, Test loss: 2.265, Test accuracy: 21.53 

Round   3, Train loss: 2.196, Test loss: 2.217, Test accuracy: 39.80 

Round   4, Train loss: 2.080, Test loss: 2.133, Test accuracy: 43.65 

Round   5, Train loss: 1.944, Test loss: 2.039, Test accuracy: 48.20 

Round   6, Train loss: 1.862, Test loss: 1.951, Test accuracy: 55.15 

Round   7, Train loss: 1.827, Test loss: 1.872, Test accuracy: 62.88 

Round   8, Train loss: 1.790, Test loss: 1.790, Test accuracy: 72.17 

Round   9, Train loss: 1.674, Test loss: 1.752, Test accuracy: 74.20 

Round  10, Train loss: 1.696, Test loss: 1.708, Test accuracy: 78.37 

Round  11, Train loss: 1.638, Test loss: 1.664, Test accuracy: 82.70 

Round  12, Train loss: 1.581, Test loss: 1.644, Test accuracy: 84.92 

Round  13, Train loss: 1.542, Test loss: 1.636, Test accuracy: 85.03 

Round  14, Train loss: 1.536, Test loss: 1.628, Test accuracy: 85.68 

Round  15, Train loss: 1.569, Test loss: 1.609, Test accuracy: 86.97 

Round  16, Train loss: 1.581, Test loss: 1.602, Test accuracy: 87.73 

Round  17, Train loss: 1.577, Test loss: 1.595, Test accuracy: 88.17 

Round  18, Train loss: 1.556, Test loss: 1.575, Test accuracy: 90.13 

Round  19, Train loss: 1.539, Test loss: 1.558, Test accuracy: 91.97 

Round  20, Train loss: 1.524, Test loss: 1.553, Test accuracy: 92.28 

Round  21, Train loss: 1.507, Test loss: 1.552, Test accuracy: 92.18 

Round  22, Train loss: 1.522, Test loss: 1.539, Test accuracy: 93.53 

Round  23, Train loss: 1.495, Test loss: 1.537, Test accuracy: 93.55 

Round  24, Train loss: 1.509, Test loss: 1.535, Test accuracy: 93.85 

Round  25, Train loss: 1.498, Test loss: 1.535, Test accuracy: 93.75 

Round  26, Train loss: 1.548, Test loss: 1.534, Test accuracy: 93.82 

Round  27, Train loss: 1.501, Test loss: 1.531, Test accuracy: 93.97 

Round  28, Train loss: 1.516, Test loss: 1.530, Test accuracy: 93.97 

Round  29, Train loss: 1.501, Test loss: 1.529, Test accuracy: 93.92 

Round  30, Train loss: 1.494, Test loss: 1.528, Test accuracy: 93.98 

Round  31, Train loss: 1.506, Test loss: 1.528, Test accuracy: 93.98 

Round  32, Train loss: 1.505, Test loss: 1.526, Test accuracy: 94.28 

Round  33, Train loss: 1.565, Test loss: 1.526, Test accuracy: 94.18 

Round  34, Train loss: 1.501, Test loss: 1.525, Test accuracy: 94.30 

Round  35, Train loss: 1.487, Test loss: 1.526, Test accuracy: 94.05 

Round  36, Train loss: 1.493, Test loss: 1.525, Test accuracy: 94.08 

Round  37, Train loss: 1.505, Test loss: 1.523, Test accuracy: 94.23 

Round  38, Train loss: 1.525, Test loss: 1.514, Test accuracy: 95.65 

Round  39, Train loss: 1.494, Test loss: 1.514, Test accuracy: 95.85 

Round  40, Train loss: 1.489, Test loss: 1.513, Test accuracy: 95.93 

Round  41, Train loss: 1.489, Test loss: 1.513, Test accuracy: 95.80 

Round  42, Train loss: 1.488, Test loss: 1.512, Test accuracy: 95.80 

Round  43, Train loss: 1.508, Test loss: 1.506, Test accuracy: 96.17 

Round  44, Train loss: 1.493, Test loss: 1.506, Test accuracy: 96.17 

Round  45, Train loss: 1.489, Test loss: 1.506, Test accuracy: 96.20 

Round  46, Train loss: 1.490, Test loss: 1.505, Test accuracy: 96.27 

Round  47, Train loss: 1.498, Test loss: 1.504, Test accuracy: 96.28 

Round  48, Train loss: 1.491, Test loss: 1.505, Test accuracy: 96.22 

Round  49, Train loss: 1.484, Test loss: 1.504, Test accuracy: 96.23 

Final Round, Train loss: 1.489, Test loss: 1.504, Test accuracy: 96.25 

Average accuracy final 10 rounds: 96.10666666666667 

640.2437331676483
[2.7642064094543457, 3.8266124725341797, 4.895200967788696, 5.944467067718506, 7.000524997711182, 8.043118953704834, 9.09792685508728, 10.150540828704834, 11.194982528686523, 12.249537229537964, 13.290727853775024, 14.342661619186401, 15.405209064483643, 16.6785991191864, 17.723511695861816, 18.757058143615723, 20.05129623413086, 21.393085718154907, 22.732903718948364, 24.08393430709839, 25.440914154052734, 26.78224205970764, 28.128987073898315, 29.483356475830078, 30.541263580322266, 31.593045949935913, 32.65683937072754, 33.73286724090576, 34.787986278533936, 35.82384753227234, 36.89474821090698, 37.96963596343994, 39.03707504272461, 40.120508670806885, 41.19269561767578, 42.256592750549316, 43.31435775756836, 44.36189556121826, 45.40901732444763, 46.4572868347168, 47.50040674209595, 48.56275296211243, 49.63310098648071, 50.69156050682068, 51.74993658065796, 52.79902148246765, 53.85828113555908, 54.92066979408264, 55.97760200500488, 57.03507471084595, 59.1279878616333]
[24.633333333333333, 16.433333333333334, 21.533333333333335, 39.8, 43.65, 48.2, 55.15, 62.88333333333333, 72.16666666666667, 74.2, 78.36666666666666, 82.7, 84.91666666666667, 85.03333333333333, 85.68333333333334, 86.96666666666667, 87.73333333333333, 88.16666666666667, 90.13333333333334, 91.96666666666667, 92.28333333333333, 92.18333333333334, 93.53333333333333, 93.55, 93.85, 93.75, 93.81666666666666, 93.96666666666667, 93.96666666666667, 93.91666666666667, 93.98333333333333, 93.98333333333333, 94.28333333333333, 94.18333333333334, 94.3, 94.05, 94.08333333333333, 94.23333333333333, 95.65, 95.85, 95.93333333333334, 95.8, 95.8, 96.16666666666667, 96.16666666666667, 96.2, 96.26666666666667, 96.28333333333333, 96.21666666666667, 96.23333333333333, 96.25]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.308, Test loss: 2.296, Test accuracy: 15.08
Round   1, Train loss: 2.250, Test loss: 2.259, Test accuracy: 15.00
Round   2, Train loss: 2.217, Test loss: 2.241, Test accuracy: 25.33
Round   3, Train loss: 2.094, Test loss: 2.172, Test accuracy: 27.13
Round   4, Train loss: 2.068, Test loss: 2.106, Test accuracy: 39.63
Round   5, Train loss: 1.942, Test loss: 2.033, Test accuracy: 49.00
Round   6, Train loss: 1.859, Test loss: 1.969, Test accuracy: 53.55
Round   7, Train loss: 1.848, Test loss: 1.871, Test accuracy: 64.20
Round   8, Train loss: 1.754, Test loss: 1.803, Test accuracy: 71.93
Round   9, Train loss: 1.735, Test loss: 1.768, Test accuracy: 74.97
Round  10, Train loss: 1.711, Test loss: 1.745, Test accuracy: 77.70
Round  11, Train loss: 1.744, Test loss: 1.731, Test accuracy: 79.25
Round  12, Train loss: 1.645, Test loss: 1.697, Test accuracy: 82.92
Round  13, Train loss: 1.594, Test loss: 1.684, Test accuracy: 83.20
Round  14, Train loss: 1.574, Test loss: 1.653, Test accuracy: 85.82
Round  15, Train loss: 1.577, Test loss: 1.610, Test accuracy: 90.67
Round  16, Train loss: 1.537, Test loss: 1.611, Test accuracy: 89.27
Round  17, Train loss: 1.597, Test loss: 1.597, Test accuracy: 90.25
Round  18, Train loss: 1.559, Test loss: 1.587, Test accuracy: 90.65
Round  19, Train loss: 1.538, Test loss: 1.586, Test accuracy: 89.67
Round  20, Train loss: 1.564, Test loss: 1.574, Test accuracy: 91.13
Round  21, Train loss: 1.540, Test loss: 1.567, Test accuracy: 91.85
Round  22, Train loss: 1.535, Test loss: 1.546, Test accuracy: 94.80
Round  23, Train loss: 1.563, Test loss: 1.529, Test accuracy: 95.95
Round  24, Train loss: 1.530, Test loss: 1.525, Test accuracy: 96.25
Round  25, Train loss: 1.528, Test loss: 1.523, Test accuracy: 96.52
Round  26, Train loss: 1.548, Test loss: 1.518, Test accuracy: 96.62
Round  27, Train loss: 1.539, Test loss: 1.516, Test accuracy: 96.57
Round  28, Train loss: 1.507, Test loss: 1.517, Test accuracy: 96.63
Round  29, Train loss: 1.505, Test loss: 1.517, Test accuracy: 96.68
Round  30, Train loss: 1.516, Test loss: 1.514, Test accuracy: 96.85
Round  31, Train loss: 1.507, Test loss: 1.513, Test accuracy: 96.83
Round  32, Train loss: 1.534, Test loss: 1.512, Test accuracy: 96.92
Round  33, Train loss: 1.516, Test loss: 1.510, Test accuracy: 97.08
Round  34, Train loss: 1.513, Test loss: 1.510, Test accuracy: 96.95
Round  35, Train loss: 1.497, Test loss: 1.509, Test accuracy: 97.00
Round  36, Train loss: 1.492, Test loss: 1.509, Test accuracy: 97.02
Round  37, Train loss: 1.526, Test loss: 1.507, Test accuracy: 97.13
Round  38, Train loss: 1.515, Test loss: 1.507, Test accuracy: 97.05
Round  39, Train loss: 1.507, Test loss: 1.506, Test accuracy: 97.08
Round  40, Train loss: 1.510, Test loss: 1.506, Test accuracy: 97.07
Round  41, Train loss: 1.495, Test loss: 1.506, Test accuracy: 97.15
Round  42, Train loss: 1.507, Test loss: 1.504, Test accuracy: 97.28
Round  43, Train loss: 1.500, Test loss: 1.505, Test accuracy: 97.23
Round  44, Train loss: 1.497, Test loss: 1.505, Test accuracy: 97.15
Round  45, Train loss: 1.502, Test loss: 1.503, Test accuracy: 97.32
Round  46, Train loss: 1.489, Test loss: 1.503, Test accuracy: 97.33
Round  47, Train loss: 1.502, Test loss: 1.502, Test accuracy: 97.38
Round  48, Train loss: 1.497, Test loss: 1.503, Test accuracy: 97.27
Round  49, Train loss: 1.495, Test loss: 1.502, Test accuracy: 97.33
Final Round, Train loss: 1.489, Test loss: 1.499, Test accuracy: 97.37
Average accuracy final 10 rounds: 97.25166666666668
795.7354245185852
[3.4427216053009033, 5.032637119293213, 6.629580974578857, 8.215285301208496, 9.803895950317383, 11.39559817314148, 12.987422704696655, 14.5828115940094, 16.169656991958618, 17.755683183670044, 19.339126586914062, 20.940844535827637, 22.53300666809082, 24.122321605682373, 25.712732076644897, 27.39721918106079, 29.08203935623169, 30.66952657699585, 32.26227426528931, 33.85782337188721, 35.443490982055664, 37.045413970947266, 38.64007616043091, 40.22667932510376, 41.8157684803009, 43.56992244720459, 45.154672622680664, 46.753379821777344, 48.35034704208374, 49.939435958862305, 51.534902572631836, 53.13008689880371, 54.729576587677, 56.313592195510864, 57.90728950500488, 59.5007438659668, 61.10390496253967, 62.71020007133484, 64.30613541603088, 65.90118646621704, 67.48039388656616, 69.14401054382324, 70.84519076347351, 72.545401096344, 74.14033460617065, 75.74581956863403, 77.33595275878906, 79.03499221801758, 80.94928669929504, 82.87844038009644, 85.6747899055481]
[15.083333333333334, 15.0, 25.333333333333332, 27.133333333333333, 39.63333333333333, 49.0, 53.55, 64.2, 71.93333333333334, 74.96666666666667, 77.7, 79.25, 82.91666666666667, 83.2, 85.81666666666666, 90.66666666666667, 89.26666666666667, 90.25, 90.65, 89.66666666666667, 91.13333333333334, 91.85, 94.8, 95.95, 96.25, 96.51666666666667, 96.61666666666666, 96.56666666666666, 96.63333333333334, 96.68333333333334, 96.85, 96.83333333333333, 96.91666666666667, 97.08333333333333, 96.95, 97.0, 97.01666666666667, 97.13333333333334, 97.05, 97.08333333333333, 97.06666666666666, 97.15, 97.28333333333333, 97.23333333333333, 97.15, 97.31666666666666, 97.33333333333333, 97.38333333333334, 97.26666666666667, 97.33333333333333, 97.36666666666666]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
Round   0, Train loss: 2.290, Test loss: 2.294, Test accuracy: 26.15
Round   1, Train loss: 2.205, Test loss: 2.242, Test accuracy: 19.65
Round   2, Train loss: 2.017, Test loss: 2.179, Test accuracy: 25.17
Round   3, Train loss: 1.926, Test loss: 2.130, Test accuracy: 32.28
Round   4, Train loss: 1.821, Test loss: 2.102, Test accuracy: 35.25
Round   5, Train loss: 1.825, Test loss: 2.082, Test accuracy: 34.55
Round   6, Train loss: 1.651, Test loss: 2.011, Test accuracy: 45.72
Round   7, Train loss: 1.714, Test loss: 1.955, Test accuracy: 51.38
Round   8, Train loss: 1.605, Test loss: 2.020, Test accuracy: 47.78
Round   9, Train loss: 1.603, Test loss: 1.908, Test accuracy: 59.38
Round  10, Train loss: 1.618, Test loss: 1.908, Test accuracy: 58.47
Round  11, Train loss: 1.553, Test loss: 1.845, Test accuracy: 68.18
Round  12, Train loss: 1.516, Test loss: 1.881, Test accuracy: 58.60
Round  13, Train loss: 1.543, Test loss: 1.771, Test accuracy: 75.90
Round  14, Train loss: 1.504, Test loss: 1.841, Test accuracy: 61.80
Round  15, Train loss: 1.524, Test loss: 1.821, Test accuracy: 65.35
Round  16, Train loss: 1.531, Test loss: 1.881, Test accuracy: 60.98
Round  17, Train loss: 1.523, Test loss: 1.768, Test accuracy: 73.57
Round  18, Train loss: 1.518, Test loss: 1.781, Test accuracy: 72.00
Round  19, Train loss: 1.507, Test loss: 1.711, Test accuracy: 77.62
Round  20, Train loss: 1.504, Test loss: 1.719, Test accuracy: 77.20
Round  21, Train loss: 1.518, Test loss: 1.719, Test accuracy: 75.15
Round  22, Train loss: 1.492, Test loss: 1.683, Test accuracy: 80.55
Round  23, Train loss: 1.492, Test loss: 1.669, Test accuracy: 84.53
Round  24, Train loss: 1.490, Test loss: 1.721, Test accuracy: 76.60
Round  25, Train loss: 1.496, Test loss: 1.770, Test accuracy: 70.38
Round  26, Train loss: 1.494, Test loss: 1.695, Test accuracy: 77.93
Round  27, Train loss: 1.487, Test loss: 1.674, Test accuracy: 81.53
Round  28, Train loss: 1.488, Test loss: 1.684, Test accuracy: 81.62
Round  29, Train loss: 1.499, Test loss: 1.697, Test accuracy: 77.82
Round  30, Train loss: 1.489, Test loss: 1.676, Test accuracy: 82.67
Round  31, Train loss: 1.488, Test loss: 1.629, Test accuracy: 87.03
Round  32, Train loss: 1.498, Test loss: 1.665, Test accuracy: 81.38
Round  33, Train loss: 1.483, Test loss: 1.651, Test accuracy: 83.60
Round  34, Train loss: 1.489, Test loss: 1.639, Test accuracy: 85.83
Round  35, Train loss: 1.482, Test loss: 1.645, Test accuracy: 84.42
Round  36, Train loss: 1.486, Test loss: 1.667, Test accuracy: 79.77
Round  37, Train loss: 1.486, Test loss: 1.704, Test accuracy: 76.38
Round  38, Train loss: 1.474, Test loss: 1.683, Test accuracy: 79.42
Round  39, Train loss: 1.485, Test loss: 1.688, Test accuracy: 79.28
Round  40, Train loss: 1.482, Test loss: 1.659, Test accuracy: 80.97
Round  41, Train loss: 1.483, Test loss: 1.635, Test accuracy: 85.27
Round  42, Train loss: 1.491, Test loss: 1.668, Test accuracy: 81.00
Round  43, Train loss: 1.477, Test loss: 1.640, Test accuracy: 83.25
Round  44, Train loss: 1.482, Test loss: 1.722, Test accuracy: 73.75
Round  45, Train loss: 1.485, Test loss: 1.677, Test accuracy: 79.07
Round  46, Train loss: 1.479, Test loss: 1.640, Test accuracy: 84.67
Round  47, Train loss: 1.479, Test loss: 1.644, Test accuracy: 83.97
Round  48, Train loss: 1.482, Test loss: 1.674, Test accuracy: 80.98
Round  49, Train loss: 1.481, Test loss: 1.635, Test accuracy: 84.12
Final Round, Train loss: 1.480, Test loss: 1.600, Test accuracy: 88.43
Average accuracy final 10 rounds: 81.70333333333332
1261.1454458236694
[4.927298069000244, 8.037392616271973, 11.161489486694336, 14.289478778839111, 17.410518169403076, 20.539262056350708, 23.65025568008423, 26.766961097717285, 29.881160259246826, 33.18695282936096, 36.49618887901306, 39.63839292526245, 42.75698208808899, 45.86637234687805, 48.974600315093994, 52.08396577835083, 55.201998233795166, 57.97451186180115, 61.08880138397217, 64.46678280830383, 67.84722208976746, 71.24427151679993, 74.68019938468933, 77.79792356491089, 80.91664600372314, 84.03785634040833, 87.16562390327454, 90.2873945236206, 93.40102577209473, 96.51851677894592, 99.63646745681763, 102.75783729553223, 105.87200045585632, 108.98524737358093, 112.09988737106323, 115.33068084716797, 118.44016718864441, 121.5415186882019, 124.64625787734985, 127.77031588554382, 130.89229726791382, 134.01841115951538, 137.13336873054504, 140.50888919830322, 143.6279377937317, 146.76067185401917, 149.86851692199707, 152.97980499267578, 156.09038972854614, 159.20842909812927, 162.32525897026062]
[26.15, 19.65, 25.166666666666668, 32.28333333333333, 35.25, 34.55, 45.71666666666667, 51.38333333333333, 47.78333333333333, 59.38333333333333, 58.46666666666667, 68.18333333333334, 58.6, 75.9, 61.8, 65.35, 60.983333333333334, 73.56666666666666, 72.0, 77.61666666666666, 77.2, 75.15, 80.55, 84.53333333333333, 76.6, 70.38333333333334, 77.93333333333334, 81.53333333333333, 81.61666666666666, 77.81666666666666, 82.66666666666667, 87.03333333333333, 81.38333333333334, 83.6, 85.83333333333333, 84.41666666666667, 79.76666666666667, 76.38333333333334, 79.41666666666667, 79.28333333333333, 80.96666666666667, 85.26666666666667, 81.0, 83.25, 73.75, 79.06666666666666, 84.66666666666667, 83.96666666666667, 80.98333333333333, 84.11666666666666, 88.43333333333334]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
Round   0, Train loss: 1.494, Test loss: 2.222, Test accuracy: 34.47
Round   1, Train loss: 1.302, Test loss: 2.098, Test accuracy: 51.10
Round   2, Train loss: 1.303, Test loss: 1.978, Test accuracy: 66.80
Round   3, Train loss: 1.235, Test loss: 1.900, Test accuracy: 67.35
Round   4, Train loss: 1.208, Test loss: 1.848, Test accuracy: 69.93
Round   5, Train loss: 1.161, Test loss: 1.797, Test accuracy: 74.47
Round   6, Train loss: 1.246, Test loss: 1.768, Test accuracy: 73.82
Round   7, Train loss: 1.226, Test loss: 1.714, Test accuracy: 80.35
Round   8, Train loss: 1.191, Test loss: 1.712, Test accuracy: 80.00
Round   9, Train loss: 1.187, Test loss: 1.699, Test accuracy: 80.90
Round  10, Train loss: 1.216, Test loss: 1.684, Test accuracy: 81.42
Round  11, Train loss: 1.232, Test loss: 1.678, Test accuracy: 81.67
Round  12, Train loss: 1.191, Test loss: 1.675, Test accuracy: 81.72
Round  13, Train loss: 1.186, Test loss: 1.670, Test accuracy: 81.95
Round  14, Train loss: 1.279, Test loss: 1.654, Test accuracy: 83.30
Round  15, Train loss: 1.195, Test loss: 1.644, Test accuracy: 83.87
Round  16, Train loss: 1.221, Test loss: 1.642, Test accuracy: 84.70
Round  17, Train loss: 1.155, Test loss: 1.636, Test accuracy: 85.05
Round  18, Train loss: 1.194, Test loss: 1.629, Test accuracy: 85.72
Round  19, Train loss: 1.148, Test loss: 1.629, Test accuracy: 85.45
Round  20, Train loss: 1.120, Test loss: 1.623, Test accuracy: 86.48
Round  21, Train loss: 1.148, Test loss: 1.620, Test accuracy: 86.63
Round  22, Train loss: 1.168, Test loss: 1.611, Test accuracy: 87.70
Round  23, Train loss: 1.116, Test loss: 1.606, Test accuracy: 87.97
Round  24, Train loss: 1.148, Test loss: 1.592, Test accuracy: 89.90
Round  25, Train loss: 1.185, Test loss: 1.591, Test accuracy: 90.08
Round  26, Train loss: 1.147, Test loss: 1.589, Test accuracy: 89.87
Round  27, Train loss: 1.108, Test loss: 1.588, Test accuracy: 89.60
Round  28, Train loss: 1.187, Test loss: 1.587, Test accuracy: 89.68
Round  29, Train loss: 1.145, Test loss: 1.587, Test accuracy: 89.47
Round  30, Train loss: 1.223, Test loss: 1.587, Test accuracy: 89.40
Round  31, Train loss: 1.186, Test loss: 1.586, Test accuracy: 89.58
Round  32, Train loss: 1.147, Test loss: 1.584, Test accuracy: 89.57
Round  33, Train loss: 1.144, Test loss: 1.584, Test accuracy: 89.57
Round  34, Train loss: 1.145, Test loss: 1.584, Test accuracy: 89.37
Round  35, Train loss: 1.146, Test loss: 1.585, Test accuracy: 89.18
Round  36, Train loss: 1.144, Test loss: 1.585, Test accuracy: 89.15
Round  37, Train loss: 1.147, Test loss: 1.585, Test accuracy: 89.13
Round  38, Train loss: 1.107, Test loss: 1.585, Test accuracy: 89.10
Round  39, Train loss: 1.103, Test loss: 1.585, Test accuracy: 89.25
Round  40, Train loss: 1.103, Test loss: 1.585, Test accuracy: 89.15
Round  41, Train loss: 1.187, Test loss: 1.588, Test accuracy: 88.75
Round  42, Train loss: 1.142, Test loss: 1.585, Test accuracy: 88.95
Round  43, Train loss: 1.171, Test loss: 1.576, Test accuracy: 89.87
Round  44, Train loss: 1.102, Test loss: 1.578, Test accuracy: 89.85
Round  45, Train loss: 1.147, Test loss: 1.576, Test accuracy: 89.87
Round  46, Train loss: 1.145, Test loss: 1.576, Test accuracy: 89.70
Round  47, Train loss: 1.146, Test loss: 1.577, Test accuracy: 89.72
Round  48, Train loss: 1.109, Test loss: 1.560, Test accuracy: 91.63
Round  49, Train loss: 1.103, Test loss: 1.561, Test accuracy: 91.38
Final Round, Train loss: 1.128, Test loss: 1.564, Test accuracy: 91.25
Average accuracy final 10 rounds: 89.88666666666667
942.3676865100861
[]
[34.46666666666667, 51.1, 66.8, 67.35, 69.93333333333334, 74.46666666666667, 73.81666666666666, 80.35, 80.0, 80.9, 81.41666666666667, 81.66666666666667, 81.71666666666667, 81.95, 83.3, 83.86666666666666, 84.7, 85.05, 85.71666666666667, 85.45, 86.48333333333333, 86.63333333333334, 87.7, 87.96666666666667, 89.9, 90.08333333333333, 89.86666666666666, 89.6, 89.68333333333334, 89.46666666666667, 89.4, 89.58333333333333, 89.56666666666666, 89.56666666666666, 89.36666666666666, 89.18333333333334, 89.15, 89.13333333333334, 89.1, 89.25, 89.15, 88.75, 88.95, 89.86666666666666, 89.85, 89.86666666666666, 89.7, 89.71666666666667, 91.63333333333334, 91.38333333333334, 91.25]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.286, Test loss: 2.288, Test accuracy: 24.85
Round   0: Global train loss: 2.286, Global test loss: 2.302, Global test accuracy: 11.50
Round   1, Train loss: 2.263, Test loss: 2.268, Test accuracy: 29.80
Round   1: Global train loss: 2.263, Global test loss: 2.301, Global test accuracy: 12.28
Round   2, Train loss: 2.173, Test loss: 2.229, Test accuracy: 27.15
Round   2: Global train loss: 2.173, Global test loss: 2.301, Global test accuracy: 12.55
Round   3, Train loss: 2.187, Test loss: 2.226, Test accuracy: 28.10
Round   3: Global train loss: 2.187, Global test loss: 2.301, Global test accuracy: 12.55
Round   4, Train loss: 2.103, Test loss: 2.230, Test accuracy: 22.58
Round   4: Global train loss: 2.103, Global test loss: 2.301, Global test accuracy: 12.92
Round   5, Train loss: 1.973, Test loss: 2.162, Test accuracy: 26.83
Round   5: Global train loss: 1.973, Global test loss: 2.300, Global test accuracy: 13.12
Round   6, Train loss: 2.077, Test loss: 2.193, Test accuracy: 25.65
Round   6: Global train loss: 2.077, Global test loss: 2.300, Global test accuracy: 12.95
Round   7, Train loss: 1.910, Test loss: 2.126, Test accuracy: 29.03
Round   7: Global train loss: 1.910, Global test loss: 2.299, Global test accuracy: 13.30
Round   8, Train loss: 1.811, Test loss: 2.095, Test accuracy: 32.40
Round   8: Global train loss: 1.811, Global test loss: 2.299, Global test accuracy: 13.98
Round   9, Train loss: 1.272, Test loss: 2.022, Test accuracy: 42.22
Round   9: Global train loss: 1.272, Global test loss: 2.297, Global test accuracy: 13.38
Round  10, Train loss: 1.526, Test loss: 2.057, Test accuracy: 38.40
Round  10: Global train loss: 1.526, Global test loss: 2.296, Global test accuracy: 13.33
Round  11, Train loss: 1.524, Test loss: 2.011, Test accuracy: 43.92
Round  11: Global train loss: 1.524, Global test loss: 2.294, Global test accuracy: 13.52
Round  12, Train loss: 1.390, Test loss: 2.021, Test accuracy: 45.85
Round  12: Global train loss: 1.390, Global test loss: 2.295, Global test accuracy: 13.63
Round  13, Train loss: 1.626, Test loss: 2.076, Test accuracy: 40.77
Round  13: Global train loss: 1.626, Global test loss: 2.296, Global test accuracy: 13.33
Round  14, Train loss: 0.896, Test loss: 2.067, Test accuracy: 41.15
Round  14: Global train loss: 0.896, Global test loss: 2.297, Global test accuracy: 13.73
Round  15, Train loss: 0.554, Test loss: 1.962, Test accuracy: 52.42
Round  15: Global train loss: 0.554, Global test loss: 2.294, Global test accuracy: 20.12
Round  16, Train loss: 0.881, Test loss: 1.901, Test accuracy: 60.17
Round  16: Global train loss: 0.881, Global test loss: 2.293, Global test accuracy: 21.90
Round  17, Train loss: 0.985, Test loss: 1.932, Test accuracy: 59.88
Round  17: Global train loss: 0.985, Global test loss: 2.292, Global test accuracy: 25.95
Round  18, Train loss: 0.586, Test loss: 1.937, Test accuracy: 59.22
Round  18: Global train loss: 0.586, Global test loss: 2.292, Global test accuracy: 31.12
Round  19, Train loss: -0.517, Test loss: 1.798, Test accuracy: 72.07
Round  19: Global train loss: -0.517, Global test loss: 2.286, Global test accuracy: 41.68
Round  20, Train loss: 1.203, Test loss: 1.936, Test accuracy: 61.92
Round  20: Global train loss: 1.203, Global test loss: 2.290, Global test accuracy: 29.48
Round  21, Train loss: 0.268, Test loss: 1.903, Test accuracy: 61.83
Round  21: Global train loss: 0.268, Global test loss: 2.289, Global test accuracy: 24.72
Round  22, Train loss: 0.199, Test loss: 1.875, Test accuracy: 65.52
Round  22: Global train loss: 0.199, Global test loss: 2.286, Global test accuracy: 38.57
Round  23, Train loss: -1.126, Test loss: 1.769, Test accuracy: 75.90
Round  23: Global train loss: -1.126, Global test loss: 2.275, Global test accuracy: 42.08
Round  24, Train loss: -0.153, Test loss: 1.811, Test accuracy: 67.90
Round  24: Global train loss: -0.153, Global test loss: 2.271, Global test accuracy: 38.15
Round  25, Train loss: -0.389, Test loss: 1.785, Test accuracy: 72.17
Round  25: Global train loss: -0.389, Global test loss: 2.263, Global test accuracy: 41.97
Round  26, Train loss: -0.312, Test loss: 1.794, Test accuracy: 70.72
Round  26: Global train loss: -0.312, Global test loss: 2.259, Global test accuracy: 40.17
Round  27, Train loss: -0.071, Test loss: 1.841, Test accuracy: 67.07
Round  27: Global train loss: -0.071, Global test loss: 2.260, Global test accuracy: 36.97
Round  28, Train loss: 0.912, Test loss: 1.920, Test accuracy: 61.03
Round  28: Global train loss: 0.912, Global test loss: 2.270, Global test accuracy: 31.85
Round  29, Train loss: -0.446, Test loss: 1.867, Test accuracy: 65.52
Round  29: Global train loss: -0.446, Global test loss: 2.271, Global test accuracy: 23.38
Round  30, Train loss: 0.667, Test loss: 1.859, Test accuracy: 66.53
Round  30: Global train loss: 0.667, Global test loss: 2.270, Global test accuracy: 23.92
Round  31, Train loss: -1.377, Test loss: 1.749, Test accuracy: 74.83
Round  31: Global train loss: -1.377, Global test loss: 2.256, Global test accuracy: 30.05
Round  32, Train loss: -1.814, Test loss: 1.689, Test accuracy: 79.92
Round  32: Global train loss: -1.814, Global test loss: 2.242, Global test accuracy: 37.72
Round  33, Train loss: -0.580, Test loss: 1.663, Test accuracy: 83.07
Round  33: Global train loss: -0.580, Global test loss: 2.236, Global test accuracy: 32.62
Round  34, Train loss: -1.043, Test loss: 1.647, Test accuracy: 85.13
Round  34: Global train loss: -1.043, Global test loss: 2.222, Global test accuracy: 32.28
Round  35, Train loss: -1.959, Test loss: 1.598, Test accuracy: 88.67
Round  35: Global train loss: -1.959, Global test loss: 2.209, Global test accuracy: 30.97
Round  36, Train loss: -0.426, Test loss: 1.648, Test accuracy: 83.48
Round  36: Global train loss: -0.426, Global test loss: 2.205, Global test accuracy: 31.43
Round  37, Train loss: -0.284, Test loss: 1.658, Test accuracy: 82.93
Round  37: Global train loss: -0.284, Global test loss: 2.207, Global test accuracy: 28.88
Round  38, Train loss: -0.380, Test loss: 1.686, Test accuracy: 79.75
Round  38: Global train loss: -0.380, Global test loss: 2.210, Global test accuracy: 27.32
Round  39, Train loss: -1.436, Test loss: 1.685, Test accuracy: 79.42
Round  39: Global train loss: -1.436, Global test loss: 2.215, Global test accuracy: 28.38
Round  40, Train loss: -0.950, Test loss: 1.715, Test accuracy: 76.07
Round  40: Global train loss: -0.950, Global test loss: 2.219, Global test accuracy: 27.20
Round  41, Train loss: -1.638, Test loss: 1.652, Test accuracy: 82.35
Round  41: Global train loss: -1.638, Global test loss: 2.215, Global test accuracy: 28.83
Round  42, Train loss: -1.248, Test loss: 1.655, Test accuracy: 82.23
Round  42: Global train loss: -1.248, Global test loss: 2.218, Global test accuracy: 28.33
Round  43, Train loss: -1.798, Test loss: 1.640, Test accuracy: 83.65
Round  43: Global train loss: -1.798, Global test loss: 2.211, Global test accuracy: 29.40
Round  44, Train loss: -1.831, Test loss: 1.657, Test accuracy: 82.00
Round  44: Global train loss: -1.831, Global test loss: 2.214, Global test accuracy: 29.48
Round  45, Train loss: -2.252, Test loss: 1.599, Test accuracy: 88.20
Round  45: Global train loss: -2.252, Global test loss: 2.207, Global test accuracy: 31.18
Round  46, Train loss: -2.173, Test loss: 1.566, Test accuracy: 90.00
Round  46: Global train loss: -2.173, Global test loss: 2.189, Global test accuracy: 35.28
Round  47, Train loss: -2.673, Test loss: 1.537, Test accuracy: 93.18
Round  47: Global train loss: -2.673, Global test loss: 2.181, Global test accuracy: 35.48
Round  48, Train loss: -0.802, Test loss: 1.560, Test accuracy: 90.72
Round  48: Global train loss: -0.802, Global test loss: 2.177, Global test accuracy: 36.32
Round  49, Train loss: -1.114, Test loss: 1.589, Test accuracy: 88.37
Round  49: Global train loss: -1.114, Global test loss: 2.177, Global test accuracy: 36.43
Final Round: Train loss: 1.736, Test loss: 1.600, Test accuracy: 88.12
Final Round: Global train loss: 1.736, Global test loss: 2.166, Global test accuracy: 38.10
Average accuracy final 10 rounds: 85.67666666666668
Average global accuracy final 10 rounds: 31.794999999999998
998.8770000934601
[]
[24.85, 29.8, 27.15, 28.1, 22.583333333333332, 26.833333333333332, 25.65, 29.033333333333335, 32.4, 42.21666666666667, 38.4, 43.916666666666664, 45.85, 40.766666666666666, 41.15, 52.416666666666664, 60.166666666666664, 59.88333333333333, 59.21666666666667, 72.06666666666666, 61.916666666666664, 61.833333333333336, 65.51666666666667, 75.9, 67.9, 72.16666666666667, 70.71666666666667, 67.06666666666666, 61.03333333333333, 65.51666666666667, 66.53333333333333, 74.83333333333333, 79.91666666666667, 83.06666666666666, 85.13333333333334, 88.66666666666667, 83.48333333333333, 82.93333333333334, 79.75, 79.41666666666667, 76.06666666666666, 82.35, 82.23333333333333, 83.65, 82.0, 88.2, 90.0, 93.18333333333334, 90.71666666666667, 88.36666666666666, 88.11666666666666]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.306, Test loss: 2.303, Test accuracy: 7.78 

Round   0, Global train loss: 2.306, Global test loss: 2.303, Global test accuracy: 7.60 

Round   1, Train loss: 2.304, Test loss: 2.303, Test accuracy: 8.03 

Round   1, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 7.83 

Round   2, Train loss: 2.300, Test loss: 2.303, Test accuracy: 8.47 

Round   2, Global train loss: 2.300, Global test loss: 2.303, Global test accuracy: 8.02 

Round   3, Train loss: 2.306, Test loss: 2.303, Test accuracy: 8.67 

Round   3, Global train loss: 2.306, Global test loss: 2.303, Global test accuracy: 8.27 

Round   4, Train loss: 2.305, Test loss: 2.303, Test accuracy: 8.78 

Round   4, Global train loss: 2.305, Global test loss: 2.303, Global test accuracy: 8.38 

Round   5, Train loss: 2.300, Test loss: 2.303, Test accuracy: 9.12 

Round   5, Global train loss: 2.300, Global test loss: 2.303, Global test accuracy: 8.67 

Round   6, Train loss: 2.306, Test loss: 2.303, Test accuracy: 9.08 

Round   6, Global train loss: 2.306, Global test loss: 2.303, Global test accuracy: 8.70 

Round   7, Train loss: 2.303, Test loss: 2.303, Test accuracy: 9.15 

Round   7, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.52 

Round   8, Train loss: 2.306, Test loss: 2.303, Test accuracy: 9.33 

Round   8, Global train loss: 2.306, Global test loss: 2.303, Global test accuracy: 8.93 

Round   9, Train loss: 2.305, Test loss: 2.303, Test accuracy: 9.37 

Round   9, Global train loss: 2.305, Global test loss: 2.303, Global test accuracy: 8.98 

Round  10, Train loss: 2.302, Test loss: 2.303, Test accuracy: 9.43 

Round  10, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 9.17 

Round  11, Train loss: 2.300, Test loss: 2.303, Test accuracy: 9.97 

Round  11, Global train loss: 2.300, Global test loss: 2.303, Global test accuracy: 9.27 

Round  12, Train loss: 2.304, Test loss: 2.303, Test accuracy: 10.17 

Round  12, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 9.55 

Round  13, Train loss: 2.306, Test loss: 2.302, Test accuracy: 10.65 

Round  13, Global train loss: 2.306, Global test loss: 2.303, Global test accuracy: 10.20 

Round  14, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.10 

Round  14, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 10.47 

Round  15, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.45 

Round  15, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 10.98 

Round  16, Train loss: 2.300, Test loss: 2.302, Test accuracy: 11.60 

Round  16, Global train loss: 2.300, Global test loss: 2.303, Global test accuracy: 11.13 

Round  17, Train loss: 2.299, Test loss: 2.302, Test accuracy: 11.68 

Round  17, Global train loss: 2.299, Global test loss: 2.302, Global test accuracy: 11.42 

Round  18, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.27 

Round  18, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.72 

Round  19, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.30 

Round  19, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.80 

Round  20, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.53 

Round  20, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.15 

Round  21, Train loss: 2.305, Test loss: 2.302, Test accuracy: 12.42 

Round  21, Global train loss: 2.305, Global test loss: 2.302, Global test accuracy: 12.22 

Round  22, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.78 

Round  22, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.33 

Round  23, Train loss: 2.304, Test loss: 2.302, Test accuracy: 12.90 

Round  23, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 12.58 

Round  24, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.30 

Round  24, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.73 

Round  25, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.38 

Round  25, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.12 

Round  26, Train loss: 2.303, Test loss: 2.302, Test accuracy: 13.30 

Round  26, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 13.27 

Round  27, Train loss: 2.298, Test loss: 2.302, Test accuracy: 13.48 

Round  27, Global train loss: 2.298, Global test loss: 2.302, Global test accuracy: 13.48 

Round  28, Train loss: 2.300, Test loss: 2.302, Test accuracy: 14.07 

Round  28, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.65 

Round  29, Train loss: 2.303, Test loss: 2.302, Test accuracy: 14.10 

Round  29, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 13.85 

Round  30, Train loss: 2.298, Test loss: 2.302, Test accuracy: 14.18 

Round  30, Global train loss: 2.298, Global test loss: 2.302, Global test accuracy: 14.00 

Round  31, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.32 

Round  31, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.12 

Round  32, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.38 

Round  32, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.13 

Round  33, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.52 

Round  33, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.42 

Round  34, Train loss: 2.303, Test loss: 2.302, Test accuracy: 14.48 

Round  34, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 14.45 

Round  35, Train loss: 2.300, Test loss: 2.302, Test accuracy: 14.80 

Round  35, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 14.55 

Round  36, Train loss: 2.300, Test loss: 2.302, Test accuracy: 14.92 

Round  36, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 14.73 

Round  37, Train loss: 2.302, Test loss: 2.302, Test accuracy: 15.13 

Round  37, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.85 

Round  38, Train loss: 2.300, Test loss: 2.302, Test accuracy: 15.15 

Round  38, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 14.87 

Round  39, Train loss: 2.304, Test loss: 2.301, Test accuracy: 15.17 

Round  39, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 14.98 

Round  40, Train loss: 2.301, Test loss: 2.301, Test accuracy: 15.22 

Round  40, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.88 

Round  41, Train loss: 2.302, Test loss: 2.301, Test accuracy: 15.10 

Round  41, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.95 

Round  42, Train loss: 2.301, Test loss: 2.301, Test accuracy: 15.12 

Round  42, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.00 

Round  43, Train loss: 2.300, Test loss: 2.301, Test accuracy: 15.13 

Round  43, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 15.12 

Round  44, Train loss: 2.302, Test loss: 2.301, Test accuracy: 15.35 

Round  44, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.03 

Round  45, Train loss: 2.300, Test loss: 2.301, Test accuracy: 15.35 

Round  45, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 15.17 

Round  46, Train loss: 2.301, Test loss: 2.301, Test accuracy: 15.40 

Round  46, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 15.18 

Round  47, Train loss: 2.296, Test loss: 2.301, Test accuracy: 15.40 

Round  47, Global train loss: 2.296, Global test loss: 2.301, Global test accuracy: 15.23 

Round  48, Train loss: 2.299, Test loss: 2.301, Test accuracy: 15.47 

Round  48, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 15.25 

Round  49, Train loss: 2.301, Test loss: 2.301, Test accuracy: 15.47 

Round  49, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 15.27 

Final Round, Train loss: 2.300, Test loss: 2.301, Test accuracy: 16.20 

Final Round, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 15.27 

Average accuracy final 10 rounds: 15.3 

Average global accuracy final 10 rounds: 15.108333333333334 

693.116376876831
[3.045736312866211, 4.251467227935791, 5.455471515655518, 6.711708307266235, 7.937098741531372, 9.176584243774414, 10.560027360916138, 11.706241130828857, 12.703619718551636, 13.808506488800049, 14.892048835754395, 15.919580459594727, 16.923566579818726, 17.926610946655273, 18.742024660110474, 19.53281569480896, 20.5049467086792, 21.597193241119385, 22.57929539680481, 23.598116159439087, 24.51536989212036, 25.380277156829834, 26.27040934562683, 27.186078548431396, 28.218201637268066, 29.15518021583557, 30.101719856262207, 30.96278190612793, 31.913615465164185, 33.004664182662964, 33.96518611907959, 34.86377263069153, 35.95110106468201, 36.933475494384766, 38.092825412750244, 38.868393421173096, 39.79384183883667, 40.738505363464355, 41.65228533744812, 42.549999952316284, 43.73199248313904, 44.91023373603821, 46.07213354110718, 47.23235011100769, 48.38862442970276, 49.554901123046875, 50.71568512916565, 51.89753580093384, 53.03634190559387, 54.19669198989868, 56.516221046447754]
[7.783333333333333, 8.033333333333333, 8.466666666666667, 8.666666666666666, 8.783333333333333, 9.116666666666667, 9.083333333333334, 9.15, 9.333333333333334, 9.366666666666667, 9.433333333333334, 9.966666666666667, 10.166666666666666, 10.65, 11.1, 11.45, 11.6, 11.683333333333334, 12.266666666666667, 12.3, 12.533333333333333, 12.416666666666666, 12.783333333333333, 12.9, 13.3, 13.383333333333333, 13.3, 13.483333333333333, 14.066666666666666, 14.1, 14.183333333333334, 14.316666666666666, 14.383333333333333, 14.516666666666667, 14.483333333333333, 14.8, 14.916666666666666, 15.133333333333333, 15.15, 15.166666666666666, 15.216666666666667, 15.1, 15.116666666666667, 15.133333333333333, 15.35, 15.35, 15.4, 15.4, 15.466666666666667, 15.466666666666667, 16.2]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.280, Test loss: 2.278, Test accuracy: 30.88 

Round   0, Global train loss: 2.280, Global test loss: 2.292, Global test accuracy: 29.83 

Round   1, Train loss: 2.179, Test loss: 2.196, Test accuracy: 37.70 

Round   1, Global train loss: 2.179, Global test loss: 2.251, Global test accuracy: 27.73 

Round   2, Train loss: 1.993, Test loss: 2.050, Test accuracy: 50.50 

Round   2, Global train loss: 1.993, Global test loss: 2.184, Global test accuracy: 30.28 

Round   3, Train loss: 1.915, Test loss: 1.958, Test accuracy: 58.30 

Round   3, Global train loss: 1.915, Global test loss: 2.175, Global test accuracy: 27.45 

Round   4, Train loss: 1.826, Test loss: 1.881, Test accuracy: 64.72 

Round   4, Global train loss: 1.826, Global test loss: 2.145, Global test accuracy: 41.68 

Round   5, Train loss: 1.800, Test loss: 1.799, Test accuracy: 70.57 

Round   5, Global train loss: 1.800, Global test loss: 2.154, Global test accuracy: 36.75 

Round   6, Train loss: 1.685, Test loss: 1.742, Test accuracy: 74.58 

Round   6, Global train loss: 1.685, Global test loss: 2.183, Global test accuracy: 23.23 

Round   7, Train loss: 1.747, Test loss: 1.678, Test accuracy: 81.30 

Round   7, Global train loss: 1.747, Global test loss: 2.152, Global test accuracy: 34.60 

Round   8, Train loss: 1.609, Test loss: 1.659, Test accuracy: 83.05 

Round   8, Global train loss: 1.609, Global test loss: 2.087, Global test accuracy: 40.27 

Round   9, Train loss: 1.644, Test loss: 1.647, Test accuracy: 84.37 

Round   9, Global train loss: 1.644, Global test loss: 2.100, Global test accuracy: 51.42 

Round  10, Train loss: 1.520, Test loss: 1.631, Test accuracy: 84.78 

Round  10, Global train loss: 1.520, Global test loss: 2.158, Global test accuracy: 36.30 

Round  11, Train loss: 1.591, Test loss: 1.629, Test accuracy: 84.87 

Round  11, Global train loss: 1.591, Global test loss: 2.072, Global test accuracy: 42.47 

Round  12, Train loss: 1.598, Test loss: 1.625, Test accuracy: 85.05 

Round  12, Global train loss: 1.598, Global test loss: 2.134, Global test accuracy: 31.48 

Round  13, Train loss: 1.604, Test loss: 1.614, Test accuracy: 86.15 

Round  13, Global train loss: 1.604, Global test loss: 2.162, Global test accuracy: 28.92 

Round  14, Train loss: 1.585, Test loss: 1.613, Test accuracy: 86.12 

Round  14, Global train loss: 1.585, Global test loss: 2.210, Global test accuracy: 20.90 

Round  15, Train loss: 1.567, Test loss: 1.601, Test accuracy: 87.58 

Round  15, Global train loss: 1.567, Global test loss: 2.258, Global test accuracy: 10.03 

Round  16, Train loss: 1.594, Test loss: 1.593, Test accuracy: 87.67 

Round  16, Global train loss: 1.594, Global test loss: 2.143, Global test accuracy: 29.80 

Round  17, Train loss: 1.633, Test loss: 1.588, Test accuracy: 88.00 

Round  17, Global train loss: 1.633, Global test loss: 2.087, Global test accuracy: 39.83 

Round  18, Train loss: 1.503, Test loss: 1.574, Test accuracy: 89.52 

Round  18, Global train loss: 1.503, Global test loss: 2.192, Global test accuracy: 22.90 

Round  19, Train loss: 1.477, Test loss: 1.573, Test accuracy: 89.53 

Round  19, Global train loss: 1.477, Global test loss: 2.151, Global test accuracy: 33.83 

Round  20, Train loss: 1.486, Test loss: 1.563, Test accuracy: 90.82 

Round  20, Global train loss: 1.486, Global test loss: 2.136, Global test accuracy: 31.52 

Round  21, Train loss: 1.598, Test loss: 1.548, Test accuracy: 92.52 

Round  21, Global train loss: 1.598, Global test loss: 2.109, Global test accuracy: 42.33 

Round  22, Train loss: 1.530, Test loss: 1.547, Test accuracy: 92.50 

Round  22, Global train loss: 1.530, Global test loss: 2.137, Global test accuracy: 32.58 

Round  23, Train loss: 1.533, Test loss: 1.544, Test accuracy: 92.77 

Round  23, Global train loss: 1.533, Global test loss: 2.103, Global test accuracy: 34.17 

Round  24, Train loss: 1.472, Test loss: 1.542, Test accuracy: 92.83 

Round  24, Global train loss: 1.472, Global test loss: 2.092, Global test accuracy: 39.85 

Round  25, Train loss: 1.470, Test loss: 1.541, Test accuracy: 92.90 

Round  25, Global train loss: 1.470, Global test loss: 2.084, Global test accuracy: 34.12 

Round  26, Train loss: 1.473, Test loss: 1.540, Test accuracy: 92.98 

Round  26, Global train loss: 1.473, Global test loss: 2.102, Global test accuracy: 39.42 

Round  27, Train loss: 1.469, Test loss: 1.539, Test accuracy: 92.95 

Round  27, Global train loss: 1.469, Global test loss: 2.028, Global test accuracy: 53.22 

Round  28, Train loss: 1.525, Test loss: 1.534, Test accuracy: 93.83 

Round  28, Global train loss: 1.525, Global test loss: 2.183, Global test accuracy: 25.05 

Round  29, Train loss: 1.524, Test loss: 1.533, Test accuracy: 93.88 

Round  29, Global train loss: 1.524, Global test loss: 2.054, Global test accuracy: 41.98 

Round  30, Train loss: 1.472, Test loss: 1.532, Test accuracy: 93.93 

Round  30, Global train loss: 1.472, Global test loss: 2.160, Global test accuracy: 30.75 

Round  31, Train loss: 1.492, Test loss: 1.527, Test accuracy: 94.32 

Round  31, Global train loss: 1.492, Global test loss: 2.115, Global test accuracy: 37.20 

Round  32, Train loss: 1.467, Test loss: 1.527, Test accuracy: 94.33 

Round  32, Global train loss: 1.467, Global test loss: 2.010, Global test accuracy: 49.62 

Round  33, Train loss: 1.482, Test loss: 1.526, Test accuracy: 94.37 

Round  33, Global train loss: 1.482, Global test loss: 2.149, Global test accuracy: 32.48 

Round  34, Train loss: 1.467, Test loss: 1.525, Test accuracy: 94.35 

Round  34, Global train loss: 1.467, Global test loss: 2.121, Global test accuracy: 33.08 

Round  35, Train loss: 1.469, Test loss: 1.525, Test accuracy: 94.33 

Round  35, Global train loss: 1.469, Global test loss: 2.065, Global test accuracy: 44.37 

Round  36, Train loss: 1.468, Test loss: 1.525, Test accuracy: 94.33 

Round  36, Global train loss: 1.468, Global test loss: 2.019, Global test accuracy: 47.15 

Round  37, Train loss: 1.473, Test loss: 1.525, Test accuracy: 94.28 

Round  37, Global train loss: 1.473, Global test loss: 2.135, Global test accuracy: 32.70 

Round  38, Train loss: 1.522, Test loss: 1.525, Test accuracy: 94.28 

Round  38, Global train loss: 1.522, Global test loss: 2.137, Global test accuracy: 35.90 

Round  39, Train loss: 1.471, Test loss: 1.524, Test accuracy: 94.30 

Round  39, Global train loss: 1.471, Global test loss: 2.149, Global test accuracy: 32.78 

Round  40, Train loss: 1.525, Test loss: 1.524, Test accuracy: 94.32 

Round  40, Global train loss: 1.525, Global test loss: 2.180, Global test accuracy: 28.53 

Round  41, Train loss: 1.468, Test loss: 1.524, Test accuracy: 94.27 

Round  41, Global train loss: 1.468, Global test loss: 2.075, Global test accuracy: 53.77 

Round  42, Train loss: 1.525, Test loss: 1.524, Test accuracy: 94.27 

Round  42, Global train loss: 1.525, Global test loss: 2.196, Global test accuracy: 23.42 

Round  43, Train loss: 1.469, Test loss: 1.524, Test accuracy: 94.27 

Round  43, Global train loss: 1.469, Global test loss: 2.030, Global test accuracy: 44.17 

Round  44, Train loss: 1.467, Test loss: 1.523, Test accuracy: 94.30 

Round  44, Global train loss: 1.467, Global test loss: 2.164, Global test accuracy: 24.20 

Round  45, Train loss: 1.523, Test loss: 1.523, Test accuracy: 94.28 

Round  45, Global train loss: 1.523, Global test loss: 2.129, Global test accuracy: 31.10 

Round  46, Train loss: 1.470, Test loss: 1.523, Test accuracy: 94.28 

Round  46, Global train loss: 1.470, Global test loss: 2.147, Global test accuracy: 31.83 

Round  47, Train loss: 1.466, Test loss: 1.523, Test accuracy: 94.28 

Round  47, Global train loss: 1.466, Global test loss: 2.100, Global test accuracy: 41.57 

Round  48, Train loss: 1.520, Test loss: 1.523, Test accuracy: 94.28 

Round  48, Global train loss: 1.520, Global test loss: 2.026, Global test accuracy: 42.10 

Round  49, Train loss: 1.518, Test loss: 1.523, Test accuracy: 94.30 

Round  49, Global train loss: 1.518, Global test loss: 2.068, Global test accuracy: 42.17 

Final Round, Train loss: 1.480, Test loss: 1.511, Test accuracy: 95.78 

Final Round, Global train loss: 1.480, Global test loss: 2.068, Global test accuracy: 42.17 

Average accuracy final 10 rounds: 94.285 

Average global accuracy final 10 rounds: 36.285 

899.1320395469666
[2.8673574924468994, 3.9377317428588867, 4.996559381484985, 6.069786071777344, 7.139969110488892, 8.210421085357666, 9.280860662460327, 10.353599548339844, 11.428102493286133, 12.497438669204712, 13.565586566925049, 14.627792358398438, 15.70078158378601, 16.779879331588745, 17.858477354049683, 18.933263063430786, 20.002060890197754, 21.07128357887268, 22.147727966308594, 23.21908736228943, 24.338510274887085, 25.407931566238403, 26.475285053253174, 27.54060435295105, 28.60527467727661, 29.672751426696777, 30.737952709197998, 31.80146050453186, 32.873985290527344, 33.94178915023804, 35.00792217254639, 36.074140548706055, 37.14112210273743, 38.212162494659424, 39.28217792510986, 40.347087144851685, 41.41349411010742, 42.482234954833984, 43.55760884284973, 44.631691455841064, 45.7100830078125, 46.77784085273743, 47.886518478393555, 48.94913673400879, 50.013739347457886, 51.07379913330078, 52.142887353897095, 53.2170033454895, 54.28293585777283, 55.344961404800415, 57.472901821136475]
[30.883333333333333, 37.7, 50.5, 58.3, 64.71666666666667, 70.56666666666666, 74.58333333333333, 81.3, 83.05, 84.36666666666666, 84.78333333333333, 84.86666666666666, 85.05, 86.15, 86.11666666666666, 87.58333333333333, 87.66666666666667, 88.0, 89.51666666666667, 89.53333333333333, 90.81666666666666, 92.51666666666667, 92.5, 92.76666666666667, 92.83333333333333, 92.9, 92.98333333333333, 92.95, 93.83333333333333, 93.88333333333334, 93.93333333333334, 94.31666666666666, 94.33333333333333, 94.36666666666666, 94.35, 94.33333333333333, 94.33333333333333, 94.28333333333333, 94.28333333333333, 94.3, 94.31666666666666, 94.26666666666667, 94.26666666666667, 94.26666666666667, 94.3, 94.28333333333333, 94.28333333333333, 94.28333333333333, 94.28333333333333, 94.3, 95.78333333333333]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.283, Test loss: 2.279, Test accuracy: 34.48 

Round   0, Global train loss: 2.283, Global test loss: 2.296, Global test accuracy: 29.90 

Round   1, Train loss: 2.219, Test loss: 2.195, Test accuracy: 38.98 

Round   1, Global train loss: 2.219, Global test loss: 2.266, Global test accuracy: 18.33 

Round   2, Train loss: 2.000, Test loss: 2.067, Test accuracy: 51.60 

Round   2, Global train loss: 2.000, Global test loss: 2.157, Global test accuracy: 29.38 

Round   3, Train loss: 1.925, Test loss: 1.958, Test accuracy: 59.87 

Round   3, Global train loss: 1.925, Global test loss: 2.126, Global test accuracy: 35.13 

Round   4, Train loss: 1.819, Test loss: 1.864, Test accuracy: 70.80 

Round   4, Global train loss: 1.819, Global test loss: 2.065, Global test accuracy: 49.62 

Round   5, Train loss: 1.760, Test loss: 1.826, Test accuracy: 71.30 

Round   5, Global train loss: 1.760, Global test loss: 2.026, Global test accuracy: 47.13 

Round   6, Train loss: 1.780, Test loss: 1.758, Test accuracy: 75.20 

Round   6, Global train loss: 1.780, Global test loss: 1.955, Global test accuracy: 56.93 

Round   7, Train loss: 1.580, Test loss: 1.710, Test accuracy: 79.53 

Round   7, Global train loss: 1.580, Global test loss: 1.940, Global test accuracy: 52.20 

Round   8, Train loss: 1.575, Test loss: 1.693, Test accuracy: 81.13 

Round   8, Global train loss: 1.575, Global test loss: 1.922, Global test accuracy: 53.85 

Round   9, Train loss: 1.728, Test loss: 1.668, Test accuracy: 83.88 

Round   9, Global train loss: 1.728, Global test loss: 1.889, Global test accuracy: 64.83 

Round  10, Train loss: 1.704, Test loss: 1.617, Test accuracy: 86.22 

Round  10, Global train loss: 1.704, Global test loss: 1.863, Global test accuracy: 61.07 

Round  11, Train loss: 1.553, Test loss: 1.614, Test accuracy: 86.15 

Round  11, Global train loss: 1.553, Global test loss: 1.835, Global test accuracy: 63.33 

Round  12, Train loss: 1.617, Test loss: 1.610, Test accuracy: 86.25 

Round  12, Global train loss: 1.617, Global test loss: 1.860, Global test accuracy: 60.38 

Round  13, Train loss: 1.607, Test loss: 1.600, Test accuracy: 87.60 

Round  13, Global train loss: 1.607, Global test loss: 1.840, Global test accuracy: 62.55 

Round  14, Train loss: 1.554, Test loss: 1.596, Test accuracy: 87.80 

Round  14, Global train loss: 1.554, Global test loss: 1.821, Global test accuracy: 65.12 

Round  15, Train loss: 1.613, Test loss: 1.595, Test accuracy: 87.88 

Round  15, Global train loss: 1.613, Global test loss: 1.842, Global test accuracy: 61.40 

Round  16, Train loss: 1.582, Test loss: 1.580, Test accuracy: 89.37 

Round  16, Global train loss: 1.582, Global test loss: 1.786, Global test accuracy: 69.80 

Round  17, Train loss: 1.520, Test loss: 1.579, Test accuracy: 89.15 

Round  17, Global train loss: 1.520, Global test loss: 1.750, Global test accuracy: 76.52 

Round  18, Train loss: 1.505, Test loss: 1.579, Test accuracy: 89.12 

Round  18, Global train loss: 1.505, Global test loss: 1.755, Global test accuracy: 73.90 

Round  19, Train loss: 1.546, Test loss: 1.580, Test accuracy: 89.02 

Round  19, Global train loss: 1.546, Global test loss: 1.784, Global test accuracy: 69.78 

Round  20, Train loss: 1.565, Test loss: 1.575, Test accuracy: 89.18 

Round  20, Global train loss: 1.565, Global test loss: 1.776, Global test accuracy: 70.32 

Round  21, Train loss: 1.609, Test loss: 1.576, Test accuracy: 89.02 

Round  21, Global train loss: 1.609, Global test loss: 1.774, Global test accuracy: 70.90 

Round  22, Train loss: 1.605, Test loss: 1.575, Test accuracy: 89.10 

Round  22, Global train loss: 1.605, Global test loss: 1.723, Global test accuracy: 78.60 

Round  23, Train loss: 1.599, Test loss: 1.572, Test accuracy: 89.38 

Round  23, Global train loss: 1.599, Global test loss: 1.746, Global test accuracy: 75.93 

Round  24, Train loss: 1.499, Test loss: 1.571, Test accuracy: 89.45 

Round  24, Global train loss: 1.499, Global test loss: 1.685, Global test accuracy: 81.03 

Round  25, Train loss: 1.653, Test loss: 1.569, Test accuracy: 89.60 

Round  25, Global train loss: 1.653, Global test loss: 1.709, Global test accuracy: 77.37 

Round  26, Train loss: 1.531, Test loss: 1.568, Test accuracy: 89.60 

Round  26, Global train loss: 1.531, Global test loss: 1.703, Global test accuracy: 78.37 

Round  27, Train loss: 1.556, Test loss: 1.569, Test accuracy: 89.67 

Round  27, Global train loss: 1.556, Global test loss: 1.707, Global test accuracy: 77.50 

Round  28, Train loss: 1.644, Test loss: 1.568, Test accuracy: 89.82 

Round  28, Global train loss: 1.644, Global test loss: 1.736, Global test accuracy: 73.95 

Round  29, Train loss: 1.597, Test loss: 1.567, Test accuracy: 89.90 

Round  29, Global train loss: 1.597, Global test loss: 1.707, Global test accuracy: 77.13 

Round  30, Train loss: 1.542, Test loss: 1.566, Test accuracy: 89.92 

Round  30, Global train loss: 1.542, Global test loss: 1.711, Global test accuracy: 76.05 

Round  31, Train loss: 1.543, Test loss: 1.567, Test accuracy: 89.80 

Round  31, Global train loss: 1.543, Global test loss: 1.747, Global test accuracy: 71.97 

Round  32, Train loss: 1.547, Test loss: 1.567, Test accuracy: 89.83 

Round  32, Global train loss: 1.547, Global test loss: 1.705, Global test accuracy: 77.88 

Round  33, Train loss: 1.595, Test loss: 1.566, Test accuracy: 89.83 

Round  33, Global train loss: 1.595, Global test loss: 1.699, Global test accuracy: 78.62 

Round  34, Train loss: 1.491, Test loss: 1.566, Test accuracy: 89.90 

Round  34, Global train loss: 1.491, Global test loss: 1.680, Global test accuracy: 79.10 

Round  35, Train loss: 1.481, Test loss: 1.565, Test accuracy: 89.90 

Round  35, Global train loss: 1.481, Global test loss: 1.688, Global test accuracy: 78.10 

Round  36, Train loss: 1.538, Test loss: 1.565, Test accuracy: 89.93 

Round  36, Global train loss: 1.538, Global test loss: 1.685, Global test accuracy: 78.48 

Round  37, Train loss: 1.592, Test loss: 1.564, Test accuracy: 90.15 

Round  37, Global train loss: 1.592, Global test loss: 1.674, Global test accuracy: 80.83 

Round  38, Train loss: 1.537, Test loss: 1.565, Test accuracy: 90.12 

Round  38, Global train loss: 1.537, Global test loss: 1.712, Global test accuracy: 76.48 

Round  39, Train loss: 1.486, Test loss: 1.566, Test accuracy: 89.90 

Round  39, Global train loss: 1.486, Global test loss: 1.665, Global test accuracy: 80.95 

Round  40, Train loss: 1.495, Test loss: 1.564, Test accuracy: 90.17 

Round  40, Global train loss: 1.495, Global test loss: 1.663, Global test accuracy: 81.82 

Round  41, Train loss: 1.585, Test loss: 1.565, Test accuracy: 90.00 

Round  41, Global train loss: 1.585, Global test loss: 1.659, Global test accuracy: 81.63 

Round  42, Train loss: 1.532, Test loss: 1.566, Test accuracy: 90.02 

Round  42, Global train loss: 1.532, Global test loss: 1.682, Global test accuracy: 79.13 

Round  43, Train loss: 1.541, Test loss: 1.566, Test accuracy: 89.88 

Round  43, Global train loss: 1.541, Global test loss: 1.666, Global test accuracy: 81.02 

Round  44, Train loss: 1.543, Test loss: 1.564, Test accuracy: 90.15 

Round  44, Global train loss: 1.543, Global test loss: 1.647, Global test accuracy: 83.30 

Round  45, Train loss: 1.486, Test loss: 1.564, Test accuracy: 90.20 

Round  45, Global train loss: 1.486, Global test loss: 1.664, Global test accuracy: 81.30 

Round  46, Train loss: 1.534, Test loss: 1.563, Test accuracy: 90.25 

Round  46, Global train loss: 1.534, Global test loss: 1.669, Global test accuracy: 80.08 

Round  47, Train loss: 1.487, Test loss: 1.564, Test accuracy: 90.10 

Round  47, Global train loss: 1.487, Global test loss: 1.645, Global test accuracy: 83.38 

Round  48, Train loss: 1.530, Test loss: 1.563, Test accuracy: 90.13 

Round  48, Global train loss: 1.530, Global test loss: 1.664, Global test accuracy: 81.42 

Round  49, Train loss: 1.536, Test loss: 1.564, Test accuracy: 90.08 

Round  49, Global train loss: 1.536, Global test loss: 1.677, Global test accuracy: 79.15 

Final Round, Train loss: 1.539, Test loss: 1.562, Test accuracy: 90.10 

Final Round, Global train loss: 1.539, Global test loss: 1.677, Global test accuracy: 79.15 

Average accuracy final 10 rounds: 90.09833333333333 

Average global accuracy final 10 rounds: 81.22333333333333 

895.3521070480347
[2.9013001918792725, 3.9723105430603027, 5.122573614120483, 6.187418699264526, 7.291707515716553, 8.389276504516602, 9.45288634300232, 10.525602102279663, 11.595342636108398, 12.661375284194946, 13.727453708648682, 14.797011375427246, 15.867795467376709, 16.93822169303894, 18.008325576782227, 19.080246925354004, 20.145458936691284, 21.22026491165161, 22.294955253601074, 23.37912392616272, 24.441840648651123, 25.50795030593872, 26.57382822036743, 27.641502380371094, 28.702018976211548, 29.765558004379272, 30.829174995422363, 31.88987636566162, 32.958083152770996, 34.02465462684631, 35.08838891983032, 36.15253305435181, 37.22257590293884, 38.382681131362915, 39.452589988708496, 40.51814246177673, 41.58418011665344, 42.64944052696228, 43.72227215766907, 44.79807496070862, 45.88096785545349, 46.95121502876282, 48.02163743972778, 49.09281826019287, 50.15669870376587, 51.22214865684509, 52.29006099700928, 53.363417863845825, 54.42907643318176, 55.49560308456421, 57.62984490394592]
[34.483333333333334, 38.983333333333334, 51.6, 59.86666666666667, 70.8, 71.3, 75.2, 79.53333333333333, 81.13333333333334, 83.88333333333334, 86.21666666666667, 86.15, 86.25, 87.6, 87.8, 87.88333333333334, 89.36666666666666, 89.15, 89.11666666666666, 89.01666666666667, 89.18333333333334, 89.01666666666667, 89.1, 89.38333333333334, 89.45, 89.6, 89.6, 89.66666666666667, 89.81666666666666, 89.9, 89.91666666666667, 89.8, 89.83333333333333, 89.83333333333333, 89.9, 89.9, 89.93333333333334, 90.15, 90.11666666666666, 89.9, 90.16666666666667, 90.0, 90.01666666666667, 89.88333333333334, 90.15, 90.2, 90.25, 90.1, 90.13333333333334, 90.08333333333333, 90.1]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.295, Test loss: 2.299, Test accuracy: 15.55 

Round   1, Train loss: 2.290, Test loss: 2.293, Test accuracy: 29.33 

Round   2, Train loss: 2.284, Test loss: 2.284, Test accuracy: 36.82 

Round   3, Train loss: 2.222, Test loss: 2.226, Test accuracy: 29.83 

Round   4, Train loss: 2.119, Test loss: 2.147, Test accuracy: 42.77 

Round   5, Train loss: 1.994, Test loss: 2.048, Test accuracy: 46.10 

Round   6, Train loss: 1.838, Test loss: 1.978, Test accuracy: 48.83 

Round   7, Train loss: 1.863, Test loss: 1.902, Test accuracy: 61.55 

Round   8, Train loss: 1.744, Test loss: 1.832, Test accuracy: 68.32 

Round   9, Train loss: 1.782, Test loss: 1.776, Test accuracy: 73.28 

Round  10, Train loss: 1.670, Test loss: 1.744, Test accuracy: 74.75 

Round  11, Train loss: 1.686, Test loss: 1.730, Test accuracy: 75.83 

Round  12, Train loss: 1.624, Test loss: 1.714, Test accuracy: 77.55 

Round  13, Train loss: 1.749, Test loss: 1.694, Test accuracy: 79.40 

Round  14, Train loss: 1.614, Test loss: 1.679, Test accuracy: 80.75 

Round  15, Train loss: 1.617, Test loss: 1.677, Test accuracy: 80.38 

Round  16, Train loss: 1.619, Test loss: 1.658, Test accuracy: 82.08 

Round  17, Train loss: 1.573, Test loss: 1.653, Test accuracy: 82.28 

Round  18, Train loss: 1.580, Test loss: 1.642, Test accuracy: 83.48 

Round  19, Train loss: 1.648, Test loss: 1.638, Test accuracy: 83.58 

Round  20, Train loss: 1.654, Test loss: 1.628, Test accuracy: 84.47 

Round  21, Train loss: 1.628, Test loss: 1.616, Test accuracy: 85.75 

Round  22, Train loss: 1.529, Test loss: 1.615, Test accuracy: 85.67 

Round  23, Train loss: 1.665, Test loss: 1.610, Test accuracy: 86.35 

Round  24, Train loss: 1.616, Test loss: 1.607, Test accuracy: 86.63 

Round  25, Train loss: 1.523, Test loss: 1.603, Test accuracy: 86.77 

Round  26, Train loss: 1.563, Test loss: 1.601, Test accuracy: 87.02 

Round  27, Train loss: 1.606, Test loss: 1.601, Test accuracy: 86.92 

Round  28, Train loss: 1.604, Test loss: 1.601, Test accuracy: 86.85 

Round  29, Train loss: 1.560, Test loss: 1.596, Test accuracy: 87.45 

Round  30, Train loss: 1.548, Test loss: 1.595, Test accuracy: 87.48 

Round  31, Train loss: 1.561, Test loss: 1.593, Test accuracy: 87.63 

Round  32, Train loss: 1.602, Test loss: 1.592, Test accuracy: 87.83 

Round  33, Train loss: 1.545, Test loss: 1.593, Test accuracy: 87.70 

Round  34, Train loss: 1.598, Test loss: 1.592, Test accuracy: 87.58 

Round  35, Train loss: 1.598, Test loss: 1.592, Test accuracy: 87.60 

Round  36, Train loss: 1.492, Test loss: 1.592, Test accuracy: 87.32 

Round  37, Train loss: 1.545, Test loss: 1.591, Test accuracy: 87.90 

Round  38, Train loss: 1.601, Test loss: 1.588, Test accuracy: 87.97 

Round  39, Train loss: 1.597, Test loss: 1.588, Test accuracy: 87.97 

Round  40, Train loss: 1.591, Test loss: 1.588, Test accuracy: 88.00 

Round  41, Train loss: 1.591, Test loss: 1.588, Test accuracy: 88.13 

Round  42, Train loss: 1.494, Test loss: 1.589, Test accuracy: 87.87 

Round  43, Train loss: 1.583, Test loss: 1.588, Test accuracy: 87.90 

Round  44, Train loss: 1.519, Test loss: 1.579, Test accuracy: 88.67 

Round  45, Train loss: 1.568, Test loss: 1.570, Test accuracy: 89.82 

Round  46, Train loss: 1.591, Test loss: 1.570, Test accuracy: 89.72 

Round  47, Train loss: 1.567, Test loss: 1.558, Test accuracy: 91.22 

Round  48, Train loss: 1.499, Test loss: 1.557, Test accuracy: 91.18 

Round  49, Train loss: 1.539, Test loss: 1.558, Test accuracy: 91.13 

Final Round, Train loss: 1.538, Test loss: 1.556, Test accuracy: 90.87 

Average accuracy final 10 rounds: 89.36333333333334 

631.9531579017639
[2.8532354831695557, 3.9181675910949707, 4.976714372634888, 6.039551496505737, 7.091418743133545, 8.170656442642212, 9.222690105438232, 10.2911536693573, 11.35287094116211, 12.414932250976562, 13.47737979888916, 14.539711952209473, 15.59974193572998, 16.652711868286133, 17.708922863006592, 18.77280616760254, 19.83591103553772, 20.897448539733887, 21.954320669174194, 23.004778385162354, 24.058902740478516, 25.124301433563232, 26.192073822021484, 27.25273060798645, 28.313854932785034, 29.38347554206848, 30.44374704360962, 31.499162912368774, 32.55894422531128, 33.62389802932739, 34.68209719657898, 35.73991680145264, 36.80342221260071, 37.85310626029968, 38.905494689941406, 39.96904492378235, 41.02895927429199, 42.117881298065186, 43.180387020111084, 44.24334764480591, 45.30303192138672, 46.36192440986633, 47.43077731132507, 48.495834827423096, 49.55487680435181, 50.61682462692261, 51.67394804954529, 52.73367786407471, 53.786731004714966, 54.855313777923584, 56.9445059299469]
[15.55, 29.333333333333332, 36.81666666666667, 29.833333333333332, 42.766666666666666, 46.1, 48.833333333333336, 61.55, 68.31666666666666, 73.28333333333333, 74.75, 75.83333333333333, 77.55, 79.4, 80.75, 80.38333333333334, 82.08333333333333, 82.28333333333333, 83.48333333333333, 83.58333333333333, 84.46666666666667, 85.75, 85.66666666666667, 86.35, 86.63333333333334, 86.76666666666667, 87.01666666666667, 86.91666666666667, 86.85, 87.45, 87.48333333333333, 87.63333333333334, 87.83333333333333, 87.7, 87.58333333333333, 87.6, 87.31666666666666, 87.9, 87.96666666666667, 87.96666666666667, 88.0, 88.13333333333334, 87.86666666666666, 87.9, 88.66666666666667, 89.81666666666666, 89.71666666666667, 91.21666666666667, 91.18333333333334, 91.13333333333334, 90.86666666666666]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.315, Test loss: 2.299, Test accuracy: 19.67
Round   1, Train loss: 2.294, Test loss: 2.291, Test accuracy: 25.85
Round   2, Train loss: 2.263, Test loss: 2.266, Test accuracy: 30.60
Round   3, Train loss: 2.170, Test loss: 2.191, Test accuracy: 29.73
Round   4, Train loss: 2.033, Test loss: 2.103, Test accuracy: 42.07
Round   5, Train loss: 1.981, Test loss: 2.050, Test accuracy: 46.75
Round   6, Train loss: 1.815, Test loss: 1.973, Test accuracy: 56.08
Round   7, Train loss: 1.861, Test loss: 1.916, Test accuracy: 59.75
Round   8, Train loss: 1.817, Test loss: 1.847, Test accuracy: 66.43
Round   9, Train loss: 1.765, Test loss: 1.831, Test accuracy: 66.28
Round  10, Train loss: 1.729, Test loss: 1.795, Test accuracy: 69.58
Round  11, Train loss: 1.714, Test loss: 1.740, Test accuracy: 76.82
Round  12, Train loss: 1.748, Test loss: 1.710, Test accuracy: 79.20
Round  13, Train loss: 1.686, Test loss: 1.664, Test accuracy: 83.87
Round  14, Train loss: 1.642, Test loss: 1.641, Test accuracy: 86.45
Round  15, Train loss: 1.557, Test loss: 1.633, Test accuracy: 86.98
Round  16, Train loss: 1.519, Test loss: 1.632, Test accuracy: 86.85
Round  17, Train loss: 1.670, Test loss: 1.617, Test accuracy: 89.12
Round  18, Train loss: 1.626, Test loss: 1.608, Test accuracy: 89.43
Round  19, Train loss: 1.553, Test loss: 1.597, Test accuracy: 90.83
Round  20, Train loss: 1.603, Test loss: 1.589, Test accuracy: 92.03
Round  21, Train loss: 1.542, Test loss: 1.583, Test accuracy: 92.35
Round  22, Train loss: 1.590, Test loss: 1.576, Test accuracy: 92.47
Round  23, Train loss: 1.562, Test loss: 1.568, Test accuracy: 93.12
Round  24, Train loss: 1.539, Test loss: 1.562, Test accuracy: 93.42
Round  25, Train loss: 1.532, Test loss: 1.559, Test accuracy: 93.70
Round  26, Train loss: 1.547, Test loss: 1.554, Test accuracy: 93.80
Round  27, Train loss: 1.526, Test loss: 1.553, Test accuracy: 93.75
Round  28, Train loss: 1.518, Test loss: 1.551, Test accuracy: 93.92
Round  29, Train loss: 1.565, Test loss: 1.539, Test accuracy: 95.25
Round  30, Train loss: 1.528, Test loss: 1.538, Test accuracy: 95.43
Round  31, Train loss: 1.503, Test loss: 1.537, Test accuracy: 95.47
Round  32, Train loss: 1.525, Test loss: 1.535, Test accuracy: 95.62
Round  33, Train loss: 1.517, Test loss: 1.530, Test accuracy: 95.73
Round  34, Train loss: 1.527, Test loss: 1.528, Test accuracy: 95.78
Round  35, Train loss: 1.527, Test loss: 1.526, Test accuracy: 95.90
Round  36, Train loss: 1.505, Test loss: 1.527, Test accuracy: 95.78
Round  37, Train loss: 1.502, Test loss: 1.526, Test accuracy: 95.87
Round  38, Train loss: 1.520, Test loss: 1.524, Test accuracy: 96.00
Round  39, Train loss: 1.518, Test loss: 1.522, Test accuracy: 96.33
Round  40, Train loss: 1.509, Test loss: 1.521, Test accuracy: 96.40
Round  41, Train loss: 1.494, Test loss: 1.521, Test accuracy: 96.35
Round  42, Train loss: 1.490, Test loss: 1.522, Test accuracy: 96.28
Round  43, Train loss: 1.513, Test loss: 1.520, Test accuracy: 96.37
Round  44, Train loss: 1.510, Test loss: 1.519, Test accuracy: 96.20
Round  45, Train loss: 1.509, Test loss: 1.517, Test accuracy: 96.50
Round  46, Train loss: 1.505, Test loss: 1.516, Test accuracy: 96.47
Round  47, Train loss: 1.492, Test loss: 1.516, Test accuracy: 96.58
Round  48, Train loss: 1.500, Test loss: 1.515, Test accuracy: 96.52
Round  49, Train loss: 1.500, Test loss: 1.514, Test accuracy: 96.48
Final Round, Train loss: 1.494, Test loss: 1.510, Test accuracy: 96.80
Average accuracy final 10 rounds: 96.41499999999999
783.7357230186462
[3.366722822189331, 4.959686756134033, 6.562409162521362, 8.172823667526245, 9.776904344558716, 11.381662607192993, 12.984413623809814, 14.600161790847778, 16.20761013031006, 17.817951202392578, 19.433587551116943, 21.042030334472656, 22.641281127929688, 24.239850997924805, 25.85260033607483, 27.4494788646698, 29.057642698287964, 30.66689682006836, 32.2781298160553, 33.87746620178223, 35.52450513839722, 37.132463216781616, 38.71172285079956, 40.25110721588135, 41.78165626525879, 43.31336569786072, 44.916162729263306, 46.50492000579834, 48.108808755874634, 49.70793795585632, 51.28674030303955, 52.87984085083008, 54.47508382797241, 56.06464982032776, 57.660452127456665, 59.251747608184814, 60.95796728134155, 62.5556480884552, 64.1653082370758, 65.75253582000732, 67.34885382652283, 68.94473791122437, 70.53447413444519, 72.18831419944763, 73.77483224868774, 75.35941529273987, 76.94973731040955, 78.57211208343506, 80.16589856147766, 81.74311661720276, 83.93190097808838]
[19.666666666666668, 25.85, 30.6, 29.733333333333334, 42.06666666666667, 46.75, 56.083333333333336, 59.75, 66.43333333333334, 66.28333333333333, 69.58333333333333, 76.81666666666666, 79.2, 83.86666666666666, 86.45, 86.98333333333333, 86.85, 89.11666666666666, 89.43333333333334, 90.83333333333333, 92.03333333333333, 92.35, 92.46666666666667, 93.11666666666666, 93.41666666666667, 93.7, 93.8, 93.75, 93.91666666666667, 95.25, 95.43333333333334, 95.46666666666667, 95.61666666666666, 95.73333333333333, 95.78333333333333, 95.9, 95.78333333333333, 95.86666666666666, 96.0, 96.33333333333333, 96.4, 96.35, 96.28333333333333, 96.36666666666666, 96.2, 96.5, 96.46666666666667, 96.58333333333333, 96.51666666666667, 96.48333333333333, 96.8]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
Round   0, Train loss: 2.293, Test loss: 2.297, Test accuracy: 25.33
Round   1, Train loss: 2.274, Test loss: 2.281, Test accuracy: 38.37
Round   2, Train loss: 2.070, Test loss: 2.166, Test accuracy: 36.87
Round   3, Train loss: 1.937, Test loss: 2.114, Test accuracy: 36.60
Round   4, Train loss: 1.815, Test loss: 2.027, Test accuracy: 53.25
Round   5, Train loss: 1.688, Test loss: 1.950, Test accuracy: 52.22
Round   6, Train loss: 1.597, Test loss: 1.925, Test accuracy: 55.72
Round   7, Train loss: 1.668, Test loss: 1.923, Test accuracy: 61.85
Round   8, Train loss: 1.588, Test loss: 1.874, Test accuracy: 62.27
Round   9, Train loss: 1.639, Test loss: 1.836, Test accuracy: 67.98
Round  10, Train loss: 1.537, Test loss: 1.838, Test accuracy: 63.92
Round  11, Train loss: 1.512, Test loss: 1.833, Test accuracy: 63.70
Round  12, Train loss: 1.540, Test loss: 1.806, Test accuracy: 67.23
Round  13, Train loss: 1.541, Test loss: 1.756, Test accuracy: 79.17
Round  14, Train loss: 1.514, Test loss: 1.766, Test accuracy: 74.95
Round  15, Train loss: 1.505, Test loss: 1.754, Test accuracy: 73.32
Round  16, Train loss: 1.531, Test loss: 1.812, Test accuracy: 66.58
Round  17, Train loss: 1.505, Test loss: 1.726, Test accuracy: 75.75
Round  18, Train loss: 1.498, Test loss: 1.738, Test accuracy: 73.07
Round  19, Train loss: 1.498, Test loss: 1.705, Test accuracy: 78.55
Round  20, Train loss: 1.492, Test loss: 1.720, Test accuracy: 76.17
Round  21, Train loss: 1.500, Test loss: 1.682, Test accuracy: 80.67
Round  22, Train loss: 1.488, Test loss: 1.683, Test accuracy: 80.35
Round  23, Train loss: 1.507, Test loss: 1.644, Test accuracy: 85.10
Round  24, Train loss: 1.503, Test loss: 1.684, Test accuracy: 81.73
Round  25, Train loss: 1.501, Test loss: 1.667, Test accuracy: 81.73
Round  26, Train loss: 1.493, Test loss: 1.642, Test accuracy: 84.50
Round  27, Train loss: 1.489, Test loss: 1.705, Test accuracy: 76.85
Round  28, Train loss: 1.485, Test loss: 1.647, Test accuracy: 83.58
Round  29, Train loss: 1.486, Test loss: 1.679, Test accuracy: 79.82
Round  30, Train loss: 1.485, Test loss: 1.664, Test accuracy: 82.43
Round  31, Train loss: 1.492, Test loss: 1.671, Test accuracy: 81.17
Round  32, Train loss: 1.496, Test loss: 1.637, Test accuracy: 83.85
Round  33, Train loss: 1.489, Test loss: 1.686, Test accuracy: 78.92
Round  34, Train loss: 1.480, Test loss: 1.659, Test accuracy: 81.50
Round  35, Train loss: 1.490, Test loss: 1.630, Test accuracy: 84.82
Round  36, Train loss: 1.479, Test loss: 1.700, Test accuracy: 78.05
Round  37, Train loss: 1.483, Test loss: 1.659, Test accuracy: 82.10
Round  38, Train loss: 1.480, Test loss: 1.664, Test accuracy: 80.08
Round  39, Train loss: 1.485, Test loss: 1.625, Test accuracy: 85.48
Round  40, Train loss: 1.481, Test loss: 1.649, Test accuracy: 82.27
Round  41, Train loss: 1.475, Test loss: 1.617, Test accuracy: 85.92
Round  42, Train loss: 1.479, Test loss: 1.662, Test accuracy: 80.52
Round  43, Train loss: 1.482, Test loss: 1.649, Test accuracy: 81.77
Round  44, Train loss: 1.476, Test loss: 1.654, Test accuracy: 81.57
Round  45, Train loss: 1.476, Test loss: 1.624, Test accuracy: 85.30
Round  46, Train loss: 1.484, Test loss: 1.618, Test accuracy: 86.10
Round  47, Train loss: 1.474, Test loss: 1.654, Test accuracy: 81.40
Round  48, Train loss: 1.481, Test loss: 1.625, Test accuracy: 84.97
Round  49, Train loss: 1.481, Test loss: 1.612, Test accuracy: 85.93
Final Round, Train loss: 1.478, Test loss: 1.597, Test accuracy: 87.73
Average accuracy final 10 rounds: 83.57333333333334
1250.1852583885193
[4.911078214645386, 8.03350305557251, 11.149030447006226, 14.26823902130127, 17.39883279800415, 20.53644037246704, 23.64686894416809, 26.796432971954346, 29.943824529647827, 33.073920011520386, 36.189992904663086, 39.30717396736145, 42.41953945159912, 45.53570604324341, 48.65479254722595, 51.76783776283264, 54.8913094997406, 57.99988293647766, 61.11064052581787, 64.22439122200012, 67.3474006652832, 70.46761083602905, 73.57918667793274, 76.7106454372406, 79.83656811714172, 82.94653129577637, 86.07530999183655, 89.24373483657837, 92.37161183357239, 95.49735021591187, 98.64262771606445, 101.43256950378418, 104.5267505645752, 107.64927768707275, 110.76514458656311, 113.87988686561584, 116.98857927322388, 120.10947275161743, 123.2268385887146, 126.33285999298096, 129.44270205497742, 132.55838680267334, 135.67391991615295, 138.79833459854126, 141.93080806732178, 145.06703901290894, 148.1845428943634, 151.30419206619263, 154.4279956817627, 157.55038809776306, 160.66944813728333]
[25.333333333333332, 38.36666666666667, 36.86666666666667, 36.6, 53.25, 52.21666666666667, 55.71666666666667, 61.85, 62.266666666666666, 67.98333333333333, 63.916666666666664, 63.7, 67.23333333333333, 79.16666666666667, 74.95, 73.31666666666666, 66.58333333333333, 75.75, 73.06666666666666, 78.55, 76.16666666666667, 80.66666666666667, 80.35, 85.1, 81.73333333333333, 81.73333333333333, 84.5, 76.85, 83.58333333333333, 79.81666666666666, 82.43333333333334, 81.16666666666667, 83.85, 78.91666666666667, 81.5, 84.81666666666666, 78.05, 82.1, 80.08333333333333, 85.48333333333333, 82.26666666666667, 85.91666666666667, 80.51666666666667, 81.76666666666667, 81.56666666666666, 85.3, 86.1, 81.4, 84.96666666666667, 85.93333333333334, 87.73333333333333]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
Round   0, Train loss: 1.616, Test loss: 2.268, Test accuracy: 34.70
Round   1, Train loss: 1.388, Test loss: 2.159, Test accuracy: 56.45
Round   2, Train loss: 1.254, Test loss: 2.036, Test accuracy: 67.75
Round   3, Train loss: 1.251, Test loss: 1.911, Test accuracy: 79.77
Round   4, Train loss: 1.198, Test loss: 1.834, Test accuracy: 80.33
Round   5, Train loss: 1.171, Test loss: 1.791, Test accuracy: 83.70
Round   6, Train loss: 1.203, Test loss: 1.765, Test accuracy: 82.80
Round   7, Train loss: 1.155, Test loss: 1.739, Test accuracy: 84.20
Round   8, Train loss: 1.231, Test loss: 1.727, Test accuracy: 84.42
Round   9, Train loss: 1.187, Test loss: 1.715, Test accuracy: 84.15
Round  10, Train loss: 1.229, Test loss: 1.707, Test accuracy: 84.38
Round  11, Train loss: 1.189, Test loss: 1.697, Test accuracy: 84.20
Round  12, Train loss: 1.116, Test loss: 1.692, Test accuracy: 84.50
Round  13, Train loss: 1.226, Test loss: 1.686, Test accuracy: 84.32
Round  14, Train loss: 1.230, Test loss: 1.679, Test accuracy: 84.35
Round  15, Train loss: 1.146, Test loss: 1.678, Test accuracy: 84.32
Round  16, Train loss: 1.108, Test loss: 1.673, Test accuracy: 84.45
Round  17, Train loss: 1.267, Test loss: 1.674, Test accuracy: 84.08
Round  18, Train loss: 1.147, Test loss: 1.670, Test accuracy: 84.02
Round  19, Train loss: 1.184, Test loss: 1.669, Test accuracy: 83.80
Round  20, Train loss: 1.142, Test loss: 1.668, Test accuracy: 83.67
Round  21, Train loss: 1.183, Test loss: 1.670, Test accuracy: 83.63
Round  22, Train loss: 1.267, Test loss: 1.665, Test accuracy: 84.08
Round  23, Train loss: 1.181, Test loss: 1.668, Test accuracy: 83.68
Round  24, Train loss: 1.186, Test loss: 1.664, Test accuracy: 83.82
Round  25, Train loss: 1.224, Test loss: 1.662, Test accuracy: 83.73
Round  26, Train loss: 1.266, Test loss: 1.662, Test accuracy: 83.73
Round  27, Train loss: 1.144, Test loss: 1.662, Test accuracy: 83.48
Round  28, Train loss: 1.143, Test loss: 1.659, Test accuracy: 83.52
Round  29, Train loss: 1.143, Test loss: 1.659, Test accuracy: 83.38
Round  30, Train loss: 1.224, Test loss: 1.658, Test accuracy: 83.32
Round  31, Train loss: 1.185, Test loss: 1.656, Test accuracy: 83.38
Round  32, Train loss: 1.225, Test loss: 1.657, Test accuracy: 83.23
Round  33, Train loss: 1.183, Test loss: 1.660, Test accuracy: 83.13
Round  34, Train loss: 1.183, Test loss: 1.659, Test accuracy: 83.05
Round  35, Train loss: 1.225, Test loss: 1.659, Test accuracy: 83.17
Round  36, Train loss: 1.184, Test loss: 1.657, Test accuracy: 83.33
Round  37, Train loss: 1.225, Test loss: 1.657, Test accuracy: 83.33
Round  38, Train loss: 1.144, Test loss: 1.655, Test accuracy: 83.37
Round  39, Train loss: 1.141, Test loss: 1.657, Test accuracy: 83.33
Round  40, Train loss: 1.224, Test loss: 1.655, Test accuracy: 83.28
Round  41, Train loss: 1.144, Test loss: 1.654, Test accuracy: 83.30
Round  42, Train loss: 1.222, Test loss: 1.652, Test accuracy: 83.30
Round  43, Train loss: 1.103, Test loss: 1.653, Test accuracy: 83.12
Round  44, Train loss: 1.226, Test loss: 1.655, Test accuracy: 82.98
Round  45, Train loss: 1.183, Test loss: 1.655, Test accuracy: 82.88
Round  46, Train loss: 1.265, Test loss: 1.655, Test accuracy: 82.90
Round  47, Train loss: 1.267, Test loss: 1.656, Test accuracy: 82.85
Round  48, Train loss: 1.141, Test loss: 1.655, Test accuracy: 82.78
Round  49, Train loss: 1.144, Test loss: 1.656, Test accuracy: 82.82
Final Round, Train loss: 1.188, Test loss: 1.652, Test accuracy: 83.15
Average accuracy final 10 rounds: 83.02166666666666
925.4281876087189
[]
[34.7, 56.45, 67.75, 79.76666666666667, 80.33333333333333, 83.7, 82.8, 84.2, 84.41666666666667, 84.15, 84.38333333333334, 84.2, 84.5, 84.31666666666666, 84.35, 84.31666666666666, 84.45, 84.08333333333333, 84.01666666666667, 83.8, 83.66666666666667, 83.63333333333334, 84.08333333333333, 83.68333333333334, 83.81666666666666, 83.73333333333333, 83.73333333333333, 83.48333333333333, 83.51666666666667, 83.38333333333334, 83.31666666666666, 83.38333333333334, 83.23333333333333, 83.13333333333334, 83.05, 83.16666666666667, 83.33333333333333, 83.33333333333333, 83.36666666666666, 83.33333333333333, 83.28333333333333, 83.3, 83.3, 83.11666666666666, 82.98333333333333, 82.88333333333334, 82.9, 82.85, 82.78333333333333, 82.81666666666666, 83.15]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.283, Test loss: 2.281, Test accuracy: 23.35
Round   0: Global train loss: 2.283, Global test loss: 2.301, Global test accuracy: 12.58
Round   1, Train loss: 2.252, Test loss: 2.252, Test accuracy: 33.65
Round   1: Global train loss: 2.252, Global test loss: 2.300, Global test accuracy: 16.12
Round   2, Train loss: 2.200, Test loss: 2.214, Test accuracy: 34.83
Round   2: Global train loss: 2.200, Global test loss: 2.299, Global test accuracy: 20.47
Round   3, Train loss: 2.099, Test loss: 2.158, Test accuracy: 41.20
Round   3: Global train loss: 2.099, Global test loss: 2.297, Global test accuracy: 25.35
Round   4, Train loss: 2.057, Test loss: 2.146, Test accuracy: 41.23
Round   4: Global train loss: 2.057, Global test loss: 2.297, Global test accuracy: 30.75
Round   5, Train loss: 2.014, Test loss: 2.094, Test accuracy: 44.27
Round   5: Global train loss: 2.014, Global test loss: 2.295, Global test accuracy: 31.73
Round   6, Train loss: 1.556, Test loss: 1.963, Test accuracy: 57.10
Round   6: Global train loss: 1.556, Global test loss: 2.292, Global test accuracy: 31.42
Round   7, Train loss: 1.646, Test loss: 2.003, Test accuracy: 51.07
Round   7: Global train loss: 1.646, Global test loss: 2.290, Global test accuracy: 30.37
Round   8, Train loss: 1.130, Test loss: 1.955, Test accuracy: 52.23
Round   8: Global train loss: 1.130, Global test loss: 2.286, Global test accuracy: 32.57
Round   9, Train loss: 1.512, Test loss: 1.979, Test accuracy: 52.07
Round   9: Global train loss: 1.512, Global test loss: 2.284, Global test accuracy: 35.40
Round  10, Train loss: 1.393, Test loss: 2.012, Test accuracy: 48.03
Round  10: Global train loss: 1.393, Global test loss: 2.284, Global test accuracy: 37.45
Round  11, Train loss: 0.930, Test loss: 1.968, Test accuracy: 44.73
Round  11: Global train loss: 0.930, Global test loss: 2.275, Global test accuracy: 34.03
Round  12, Train loss: 1.590, Test loss: 2.029, Test accuracy: 40.23
Round  12: Global train loss: 1.590, Global test loss: 2.276, Global test accuracy: 33.87
Round  13, Train loss: 1.398, Test loss: 2.027, Test accuracy: 44.27
Round  13: Global train loss: 1.398, Global test loss: 2.277, Global test accuracy: 29.53
Round  14, Train loss: 1.358, Test loss: 2.016, Test accuracy: 49.00
Round  14: Global train loss: 1.358, Global test loss: 2.279, Global test accuracy: 25.65
Round  15, Train loss: 0.422, Test loss: 1.917, Test accuracy: 56.07
Round  15: Global train loss: 0.422, Global test loss: 2.273, Global test accuracy: 27.22
Round  16, Train loss: 1.105, Test loss: 1.942, Test accuracy: 55.98
Round  16: Global train loss: 1.105, Global test loss: 2.275, Global test accuracy: 27.88
Round  17, Train loss: 0.861, Test loss: 1.992, Test accuracy: 53.78
Round  17: Global train loss: 0.861, Global test loss: 2.280, Global test accuracy: 28.45
Round  18, Train loss: 1.386, Test loss: 2.066, Test accuracy: 48.30
Round  18: Global train loss: 1.386, Global test loss: 2.287, Global test accuracy: 26.97
Round  19, Train loss: 0.580, Test loss: 2.017, Test accuracy: 49.95
Round  19: Global train loss: 0.580, Global test loss: 2.285, Global test accuracy: 23.95
Round  20, Train loss: 0.511, Test loss: 1.972, Test accuracy: 51.93
Round  20: Global train loss: 0.511, Global test loss: 2.282, Global test accuracy: 20.08
Round  21, Train loss: 0.386, Test loss: 1.953, Test accuracy: 54.07
Round  21: Global train loss: 0.386, Global test loss: 2.281, Global test accuracy: 18.75
Round  22, Train loss: -0.696, Test loss: 1.884, Test accuracy: 61.05
Round  22: Global train loss: -0.696, Global test loss: 2.276, Global test accuracy: 18.63
Round  23, Train loss: -0.179, Test loss: 1.878, Test accuracy: 60.02
Round  23: Global train loss: -0.179, Global test loss: 2.276, Global test accuracy: 26.20
Round  24, Train loss: 0.347, Test loss: 1.949, Test accuracy: 55.05
Round  24: Global train loss: 0.347, Global test loss: 2.284, Global test accuracy: 27.97
Round  25, Train loss: -0.133, Test loss: 1.862, Test accuracy: 63.47
Round  25: Global train loss: -0.133, Global test loss: 2.276, Global test accuracy: 39.00
Round  26, Train loss: -0.073, Test loss: 1.823, Test accuracy: 66.28
Round  26: Global train loss: -0.073, Global test loss: 2.274, Global test accuracy: 39.02
Round  27, Train loss: -1.006, Test loss: 1.807, Test accuracy: 66.97
Round  27: Global train loss: -1.006, Global test loss: 2.262, Global test accuracy: 43.00
Round  28, Train loss: -0.044, Test loss: 1.842, Test accuracy: 64.85
Round  28: Global train loss: -0.044, Global test loss: 2.263, Global test accuracy: 40.88
Round  29, Train loss: -0.915, Test loss: 1.789, Test accuracy: 72.10
Round  29: Global train loss: -0.915, Global test loss: 2.258, Global test accuracy: 38.27
Round  30, Train loss: -1.073, Test loss: 1.707, Test accuracy: 77.57
Round  30: Global train loss: -1.073, Global test loss: 2.255, Global test accuracy: 48.17
Round  31, Train loss: 0.237, Test loss: 1.787, Test accuracy: 70.18
Round  31: Global train loss: 0.237, Global test loss: 2.265, Global test accuracy: 41.48
Round  32, Train loss: -1.198, Test loss: 1.748, Test accuracy: 74.57
Round  32: Global train loss: -1.198, Global test loss: 2.260, Global test accuracy: 38.13
Round  33, Train loss: -0.848, Test loss: 1.720, Test accuracy: 76.53
Round  33: Global train loss: -0.848, Global test loss: 2.259, Global test accuracy: 39.73
Round  34, Train loss: -0.303, Test loss: 1.753, Test accuracy: 72.33
Round  34: Global train loss: -0.303, Global test loss: 2.262, Global test accuracy: 41.75
Round  35, Train loss: -1.963, Test loss: 1.731, Test accuracy: 73.78
Round  35: Global train loss: -1.963, Global test loss: 2.252, Global test accuracy: 45.70
Round  36, Train loss: -1.600, Test loss: 1.736, Test accuracy: 74.02
Round  36: Global train loss: -1.600, Global test loss: 2.241, Global test accuracy: 44.10
Round  37, Train loss: -1.090, Test loss: 1.724, Test accuracy: 74.87
Round  37: Global train loss: -1.090, Global test loss: 2.240, Global test accuracy: 43.22
Round  38, Train loss: -1.213, Test loss: 1.711, Test accuracy: 76.78
Round  38: Global train loss: -1.213, Global test loss: 2.241, Global test accuracy: 42.13
Round  39, Train loss: -2.047, Test loss: 1.707, Test accuracy: 77.27
Round  39: Global train loss: -2.047, Global test loss: 2.238, Global test accuracy: 42.78
Round  40, Train loss: -2.311, Test loss: 1.677, Test accuracy: 79.92
Round  40: Global train loss: -2.311, Global test loss: 2.211, Global test accuracy: 49.82
Round  41, Train loss: -2.138, Test loss: 1.640, Test accuracy: 82.80
Round  41: Global train loss: -2.138, Global test loss: 2.205, Global test accuracy: 52.00
Round  42, Train loss: -1.231, Test loss: 1.645, Test accuracy: 83.32
Round  42: Global train loss: -1.231, Global test loss: 2.212, Global test accuracy: 43.98
Round  43, Train loss: -0.593, Test loss: 1.631, Test accuracy: 85.47
Round  43: Global train loss: -0.593, Global test loss: 2.231, Global test accuracy: 41.38
Round  44, Train loss: -1.587, Test loss: 1.618, Test accuracy: 86.90
Round  44: Global train loss: -1.587, Global test loss: 2.222, Global test accuracy: 41.73
Round  45, Train loss: -1.902, Test loss: 1.617, Test accuracy: 86.38
Round  45: Global train loss: -1.902, Global test loss: 2.208, Global test accuracy: 42.07
Round  46, Train loss: -2.099, Test loss: 1.621, Test accuracy: 85.87
Round  46: Global train loss: -2.099, Global test loss: 2.203, Global test accuracy: 42.28
Round  47, Train loss: -2.206, Test loss: 1.588, Test accuracy: 89.05
Round  47: Global train loss: -2.206, Global test loss: 2.188, Global test accuracy: 41.83
Round  48, Train loss: -2.091, Test loss: 1.602, Test accuracy: 87.58
Round  48: Global train loss: -2.091, Global test loss: 2.181, Global test accuracy: 41.70
Round  49, Train loss: -1.997, Test loss: 1.610, Test accuracy: 85.52
Round  49: Global train loss: -1.997, Global test loss: 2.176, Global test accuracy: 41.63
Final Round: Train loss: 1.652, Test loss: 1.555, Test accuracy: 92.32
Final Round: Global train loss: 1.652, Global test loss: 2.159, Global test accuracy: 42.18
Average accuracy final 10 rounds: 85.27999999999999
Average global accuracy final 10 rounds: 43.84333333333334
993.1899328231812
[]
[23.35, 33.65, 34.833333333333336, 41.2, 41.233333333333334, 44.266666666666666, 57.1, 51.06666666666667, 52.233333333333334, 52.06666666666667, 48.03333333333333, 44.733333333333334, 40.233333333333334, 44.266666666666666, 49.0, 56.06666666666667, 55.983333333333334, 53.78333333333333, 48.3, 49.95, 51.93333333333333, 54.06666666666667, 61.05, 60.016666666666666, 55.05, 63.46666666666667, 66.28333333333333, 66.96666666666667, 64.85, 72.1, 77.56666666666666, 70.18333333333334, 74.56666666666666, 76.53333333333333, 72.33333333333333, 73.78333333333333, 74.01666666666667, 74.86666666666666, 76.78333333333333, 77.26666666666667, 79.91666666666667, 82.8, 83.31666666666666, 85.46666666666667, 86.9, 86.38333333333334, 85.86666666666666, 89.05, 87.58333333333333, 85.51666666666667, 92.31666666666666]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.300, Test loss: 2.302, Test accuracy: 11.97 

Round   0, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 11.87 

Round   1, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.98 

Round   1, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.93 

Round   2, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.98 

Round   2, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.93 

Round   3, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.98 

Round   3, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.97 

Round   4, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.02 

Round   4, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.00 

Round   5, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.02 

Round   5, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.03 

Round   6, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.02 

Round   6, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.08 

Round   7, Train loss: 2.300, Test loss: 2.302, Test accuracy: 12.03 

Round   7, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 12.10 

Round   8, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.13 

Round   8, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.13 

Round   9, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.17 

Round   9, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.15 

Round  10, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.20 

Round  10, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.22 

Round  11, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.30 

Round  11, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.27 

Round  12, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.30 

Round  12, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.28 

Round  13, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.38 

Round  13, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.32 

Round  14, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.45 

Round  14, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.50 

Round  15, Train loss: 2.300, Test loss: 2.302, Test accuracy: 12.57 

Round  15, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 12.55 

Round  16, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.73 

Round  16, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.73 

Round  17, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.82 

Round  17, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.82 

Round  18, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.00 

Round  18, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.90 

Round  19, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.12 

Round  19, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.05 

Round  20, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.25 

Round  20, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.23 

Round  21, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.38 

Round  21, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.27 

Round  22, Train loss: 2.299, Test loss: 2.302, Test accuracy: 13.50 

Round  22, Global train loss: 2.299, Global test loss: 2.302, Global test accuracy: 13.38 

Round  23, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.72 

Round  23, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.78 

Round  24, Train loss: 2.304, Test loss: 2.301, Test accuracy: 13.70 

Round  24, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 13.78 

Round  25, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.78 

Round  25, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.92 

Round  26, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.92 

Round  26, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.95 

Round  27, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.93 

Round  27, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.93 

Round  28, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.07 

Round  28, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.25 

Round  29, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.37 

Round  29, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.40 

Round  30, Train loss: 2.303, Test loss: 2.301, Test accuracy: 14.58 

Round  30, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 14.67 

Round  31, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.68 

Round  31, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.63 

Round  32, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.70 

Round  32, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.73 

Round  33, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.85 

Round  33, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.85 

Round  34, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.93 

Round  34, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.88 

Round  35, Train loss: 2.302, Test loss: 2.301, Test accuracy: 15.00 

Round  35, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.97 

Round  36, Train loss: 2.299, Test loss: 2.301, Test accuracy: 15.13 

Round  36, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.95 

Round  37, Train loss: 2.301, Test loss: 2.301, Test accuracy: 15.23 

Round  37, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 15.30 

Round  38, Train loss: 2.302, Test loss: 2.301, Test accuracy: 15.27 

Round  38, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 15.40 

Round  39, Train loss: 2.301, Test loss: 2.301, Test accuracy: 15.32 

Round  39, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 15.38 

Round  40, Train loss: 2.301, Test loss: 2.301, Test accuracy: 15.43 

Round  40, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 15.62 

Round  41, Train loss: 2.300, Test loss: 2.301, Test accuracy: 15.78 

Round  41, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 16.00 

Round  42, Train loss: 2.299, Test loss: 2.301, Test accuracy: 16.05 

Round  42, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 16.05 

Round  43, Train loss: 2.300, Test loss: 2.301, Test accuracy: 16.32 

Round  43, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 16.12 

Round  44, Train loss: 2.300, Test loss: 2.301, Test accuracy: 16.48 

Round  44, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 16.28 

Round  45, Train loss: 2.300, Test loss: 2.301, Test accuracy: 16.73 

Round  45, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 16.53 

Round  46, Train loss: 2.298, Test loss: 2.301, Test accuracy: 17.05 

Round  46, Global train loss: 2.298, Global test loss: 2.301, Global test accuracy: 16.70 

Round  47, Train loss: 2.301, Test loss: 2.301, Test accuracy: 17.10 

Round  47, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 17.00 

Round  48, Train loss: 2.299, Test loss: 2.301, Test accuracy: 17.32 

Round  48, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 17.33 

Round  49, Train loss: 2.299, Test loss: 2.301, Test accuracy: 17.53 

Round  49, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 17.37 

Final Round, Train loss: 2.300, Test loss: 2.300, Test accuracy: 18.78 

Final Round, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 17.37 

Average accuracy final 10 rounds: 16.580000000000002 

Average global accuracy final 10 rounds: 16.5 

916.9392321109772
[3.0018372535705566, 4.241694927215576, 5.465635299682617, 6.70674991607666, 7.945924997329712, 9.229761362075806, 10.379050016403198, 11.51941728591919, 12.6562659740448, 13.843789100646973, 14.976224899291992, 16.091000080108643, 17.20981526374817, 18.329450845718384, 19.4495050907135, 20.596641778945923, 21.755276679992676, 22.894962787628174, 24.020421743392944, 25.170198917388916, 26.306064128875732, 27.42970585823059, 28.520581007003784, 29.651337385177612, 30.799575090408325, 31.999536275863647, 33.108025789260864, 34.177042961120605, 35.311405658721924, 36.43134951591492, 37.565383195877075, 38.7995400428772, 39.93719696998596, 41.053058385849, 42.210652589797974, 43.352558612823486, 44.46017646789551, 45.57878088951111, 46.745452642440796, 47.86235451698303, 48.985042333602905, 50.20930552482605, 51.37220096588135, 52.4862494468689, 53.61015605926514, 54.76092553138733, 55.89771318435669, 57.02862763404846, 58.16431427001953, 59.279086112976074, 61.556692361831665]
[11.966666666666667, 11.983333333333333, 11.983333333333333, 11.983333333333333, 12.016666666666667, 12.016666666666667, 12.016666666666667, 12.033333333333333, 12.133333333333333, 12.166666666666666, 12.2, 12.3, 12.3, 12.383333333333333, 12.45, 12.566666666666666, 12.733333333333333, 12.816666666666666, 13.0, 13.116666666666667, 13.25, 13.383333333333333, 13.5, 13.716666666666667, 13.7, 13.783333333333333, 13.916666666666666, 13.933333333333334, 14.066666666666666, 14.366666666666667, 14.583333333333334, 14.683333333333334, 14.7, 14.85, 14.933333333333334, 15.0, 15.133333333333333, 15.233333333333333, 15.266666666666667, 15.316666666666666, 15.433333333333334, 15.783333333333333, 16.05, 16.316666666666666, 16.483333333333334, 16.733333333333334, 17.05, 17.1, 17.316666666666666, 17.533333333333335, 18.783333333333335]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.287, Test loss: 2.289, Test accuracy: 18.60 

Round   0, Global train loss: 2.287, Global test loss: 2.300, Global test accuracy: 10.80 

Round   1, Train loss: 2.151, Test loss: 2.196, Test accuracy: 26.23 

Round   1, Global train loss: 2.151, Global test loss: 2.269, Global test accuracy: 11.92 

Round   2, Train loss: 2.032, Test loss: 2.091, Test accuracy: 34.50 

Round   2, Global train loss: 2.032, Global test loss: 2.245, Global test accuracy: 15.18 

Round   3, Train loss: 1.861, Test loss: 1.965, Test accuracy: 51.35 

Round   3, Global train loss: 1.861, Global test loss: 2.184, Global test accuracy: 28.48 

Round   4, Train loss: 1.793, Test loss: 1.855, Test accuracy: 63.00 

Round   4, Global train loss: 1.793, Global test loss: 2.162, Global test accuracy: 34.63 

Round   5, Train loss: 1.703, Test loss: 1.773, Test accuracy: 72.43 

Round   5, Global train loss: 1.703, Global test loss: 2.172, Global test accuracy: 34.08 

Round   6, Train loss: 1.665, Test loss: 1.724, Test accuracy: 77.40 

Round   6, Global train loss: 1.665, Global test loss: 2.200, Global test accuracy: 18.92 

Round   7, Train loss: 1.625, Test loss: 1.672, Test accuracy: 82.92 

Round   7, Global train loss: 1.625, Global test loss: 2.169, Global test accuracy: 33.07 

Round   8, Train loss: 1.507, Test loss: 1.656, Test accuracy: 83.17 

Round   8, Global train loss: 1.507, Global test loss: 2.170, Global test accuracy: 25.73 

Round   9, Train loss: 1.618, Test loss: 1.625, Test accuracy: 86.47 

Round   9, Global train loss: 1.618, Global test loss: 2.191, Global test accuracy: 25.47 

Round  10, Train loss: 1.506, Test loss: 1.612, Test accuracy: 87.93 

Round  10, Global train loss: 1.506, Global test loss: 2.144, Global test accuracy: 35.63 

Round  11, Train loss: 1.552, Test loss: 1.597, Test accuracy: 88.58 

Round  11, Global train loss: 1.552, Global test loss: 2.143, Global test accuracy: 42.95 

Round  12, Train loss: 1.581, Test loss: 1.582, Test accuracy: 89.60 

Round  12, Global train loss: 1.581, Global test loss: 2.162, Global test accuracy: 35.05 

Round  13, Train loss: 1.580, Test loss: 1.581, Test accuracy: 89.53 

Round  13, Global train loss: 1.580, Global test loss: 2.054, Global test accuracy: 56.95 

Round  14, Train loss: 1.535, Test loss: 1.557, Test accuracy: 92.02 

Round  14, Global train loss: 1.535, Global test loss: 2.134, Global test accuracy: 34.43 

Round  15, Train loss: 1.491, Test loss: 1.554, Test accuracy: 92.05 

Round  15, Global train loss: 1.491, Global test loss: 2.160, Global test accuracy: 31.05 

Round  16, Train loss: 1.600, Test loss: 1.550, Test accuracy: 92.38 

Round  16, Global train loss: 1.600, Global test loss: 2.114, Global test accuracy: 36.50 

Round  17, Train loss: 1.483, Test loss: 1.547, Test accuracy: 92.47 

Round  17, Global train loss: 1.483, Global test loss: 2.116, Global test accuracy: 43.22 

Round  18, Train loss: 1.589, Test loss: 1.546, Test accuracy: 92.37 

Round  18, Global train loss: 1.589, Global test loss: 2.195, Global test accuracy: 19.20 

Round  19, Train loss: 1.487, Test loss: 1.544, Test accuracy: 92.53 

Round  19, Global train loss: 1.487, Global test loss: 2.160, Global test accuracy: 29.87 

Round  20, Train loss: 1.471, Test loss: 1.543, Test accuracy: 92.53 

Round  20, Global train loss: 1.471, Global test loss: 2.169, Global test accuracy: 27.88 

Round  21, Train loss: 1.473, Test loss: 1.542, Test accuracy: 92.55 

Round  21, Global train loss: 1.473, Global test loss: 2.214, Global test accuracy: 20.78 

Round  22, Train loss: 1.475, Test loss: 1.542, Test accuracy: 92.57 

Round  22, Global train loss: 1.475, Global test loss: 2.171, Global test accuracy: 29.05 

Round  23, Train loss: 1.576, Test loss: 1.541, Test accuracy: 92.60 

Round  23, Global train loss: 1.576, Global test loss: 2.136, Global test accuracy: 31.93 

Round  24, Train loss: 1.468, Test loss: 1.541, Test accuracy: 92.60 

Round  24, Global train loss: 1.468, Global test loss: 2.199, Global test accuracy: 20.35 

Round  25, Train loss: 1.524, Test loss: 1.541, Test accuracy: 92.58 

Round  25, Global train loss: 1.524, Global test loss: 2.212, Global test accuracy: 23.68 

Round  26, Train loss: 1.468, Test loss: 1.541, Test accuracy: 92.52 

Round  26, Global train loss: 1.468, Global test loss: 2.147, Global test accuracy: 25.48 

Round  27, Train loss: 1.468, Test loss: 1.541, Test accuracy: 92.53 

Round  27, Global train loss: 1.468, Global test loss: 2.117, Global test accuracy: 35.28 

Round  28, Train loss: 1.520, Test loss: 1.532, Test accuracy: 93.95 

Round  28, Global train loss: 1.520, Global test loss: 2.141, Global test accuracy: 32.07 

Round  29, Train loss: 1.468, Test loss: 1.532, Test accuracy: 93.93 

Round  29, Global train loss: 1.468, Global test loss: 2.128, Global test accuracy: 32.95 

Round  30, Train loss: 1.484, Test loss: 1.529, Test accuracy: 93.83 

Round  30, Global train loss: 1.484, Global test loss: 2.108, Global test accuracy: 37.12 

Round  31, Train loss: 1.466, Test loss: 1.529, Test accuracy: 93.78 

Round  31, Global train loss: 1.466, Global test loss: 2.153, Global test accuracy: 30.30 

Round  32, Train loss: 1.529, Test loss: 1.528, Test accuracy: 93.83 

Round  32, Global train loss: 1.529, Global test loss: 2.105, Global test accuracy: 46.48 

Round  33, Train loss: 1.476, Test loss: 1.527, Test accuracy: 93.85 

Round  33, Global train loss: 1.476, Global test loss: 2.142, Global test accuracy: 45.22 

Round  34, Train loss: 1.522, Test loss: 1.527, Test accuracy: 93.82 

Round  34, Global train loss: 1.522, Global test loss: 2.173, Global test accuracy: 27.53 

Round  35, Train loss: 1.471, Test loss: 1.527, Test accuracy: 93.83 

Round  35, Global train loss: 1.471, Global test loss: 2.145, Global test accuracy: 30.17 

Round  36, Train loss: 1.522, Test loss: 1.527, Test accuracy: 93.83 

Round  36, Global train loss: 1.522, Global test loss: 2.217, Global test accuracy: 16.80 

Round  37, Train loss: 1.466, Test loss: 1.527, Test accuracy: 93.82 

Round  37, Global train loss: 1.466, Global test loss: 2.173, Global test accuracy: 26.13 

Round  38, Train loss: 1.519, Test loss: 1.527, Test accuracy: 93.83 

Round  38, Global train loss: 1.519, Global test loss: 2.113, Global test accuracy: 44.42 

Round  39, Train loss: 1.469, Test loss: 1.527, Test accuracy: 93.87 

Round  39, Global train loss: 1.469, Global test loss: 2.150, Global test accuracy: 37.88 

Round  40, Train loss: 1.468, Test loss: 1.526, Test accuracy: 93.87 

Round  40, Global train loss: 1.468, Global test loss: 2.143, Global test accuracy: 33.00 

Round  41, Train loss: 1.468, Test loss: 1.526, Test accuracy: 93.87 

Round  41, Global train loss: 1.468, Global test loss: 2.108, Global test accuracy: 39.40 

Round  42, Train loss: 1.467, Test loss: 1.526, Test accuracy: 93.90 

Round  42, Global train loss: 1.467, Global test loss: 2.191, Global test accuracy: 24.97 

Round  43, Train loss: 1.523, Test loss: 1.526, Test accuracy: 93.90 

Round  43, Global train loss: 1.523, Global test loss: 2.179, Global test accuracy: 26.13 

Round  44, Train loss: 1.466, Test loss: 1.526, Test accuracy: 93.90 

Round  44, Global train loss: 1.466, Global test loss: 2.193, Global test accuracy: 25.48 

Round  45, Train loss: 1.466, Test loss: 1.526, Test accuracy: 93.85 

Round  45, Global train loss: 1.466, Global test loss: 2.117, Global test accuracy: 31.40 

Round  46, Train loss: 1.466, Test loss: 1.526, Test accuracy: 93.82 

Round  46, Global train loss: 1.466, Global test loss: 2.181, Global test accuracy: 25.50 

Round  47, Train loss: 1.465, Test loss: 1.526, Test accuracy: 93.85 

Round  47, Global train loss: 1.465, Global test loss: 2.187, Global test accuracy: 29.33 

Round  48, Train loss: 1.521, Test loss: 1.526, Test accuracy: 93.85 

Round  48, Global train loss: 1.521, Global test loss: 2.132, Global test accuracy: 30.05 

Round  49, Train loss: 1.522, Test loss: 1.526, Test accuracy: 93.85 

Round  49, Global train loss: 1.522, Global test loss: 2.148, Global test accuracy: 38.02 

Final Round, Train loss: 1.482, Test loss: 1.525, Test accuracy: 93.90 

Final Round, Global train loss: 1.482, Global test loss: 2.148, Global test accuracy: 38.02 

Average accuracy final 10 rounds: 93.86500000000001 

Average global accuracy final 10 rounds: 30.328333333333333 

508.2340316772461
[3.04213809967041, 4.432173013687134, 5.507330417633057, 6.574072360992432, 7.667630672454834, 8.59485149383545, 9.394012451171875, 10.28177261352539, 11.21979570388794, 12.223408937454224, 13.20695972442627, 14.166658163070679, 15.097434520721436, 16.013609886169434, 16.92038631439209, 17.916414737701416, 18.86497735977173, 19.51977229118347, 20.493104934692383, 21.465118885040283, 22.362492084503174, 23.273496627807617, 24.153144598007202, 25.18076491355896, 26.01774263381958, 26.92410111427307, 27.757206201553345, 28.56216549873352, 29.42112421989441, 30.28459620475769, 31.172133922576904, 32.05241584777832, 32.74397373199463, 33.47857213020325, 34.232484102249146, 34.93501663208008, 35.78503680229187, 36.67931795120239, 37.53657293319702, 38.41796946525574, 39.307875871658325, 40.15909790992737, 41.04733228683472, 41.652485847473145, 42.25152826309204, 42.852405309677124, 43.46140646934509, 44.064000368118286, 44.61828804016113, 45.17326831817627, 46.37033033370972]
[18.6, 26.233333333333334, 34.5, 51.35, 63.0, 72.43333333333334, 77.4, 82.91666666666667, 83.16666666666667, 86.46666666666667, 87.93333333333334, 88.58333333333333, 89.6, 89.53333333333333, 92.01666666666667, 92.05, 92.38333333333334, 92.46666666666667, 92.36666666666666, 92.53333333333333, 92.53333333333333, 92.55, 92.56666666666666, 92.6, 92.6, 92.58333333333333, 92.51666666666667, 92.53333333333333, 93.95, 93.93333333333334, 93.83333333333333, 93.78333333333333, 93.83333333333333, 93.85, 93.81666666666666, 93.83333333333333, 93.83333333333333, 93.81666666666666, 93.83333333333333, 93.86666666666666, 93.86666666666666, 93.86666666666666, 93.9, 93.9, 93.9, 93.85, 93.81666666666666, 93.85, 93.85, 93.85, 93.9]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.285, Test loss: 2.288, Test accuracy: 26.85 

Round   0, Global train loss: 2.285, Global test loss: 2.300, Global test accuracy: 22.58 

Round   1, Train loss: 2.242, Test loss: 2.218, Test accuracy: 30.62 

Round   1, Global train loss: 2.242, Global test loss: 2.285, Global test accuracy: 16.55 

Round   2, Train loss: 2.023, Test loss: 2.079, Test accuracy: 43.47 

Round   2, Global train loss: 2.023, Global test loss: 2.219, Global test accuracy: 26.90 

Round   3, Train loss: 1.899, Test loss: 1.967, Test accuracy: 55.48 

Round   3, Global train loss: 1.899, Global test loss: 2.143, Global test accuracy: 46.82 

Round   4, Train loss: 1.827, Test loss: 1.876, Test accuracy: 63.57 

Round   4, Global train loss: 1.827, Global test loss: 2.099, Global test accuracy: 45.82 

Round   5, Train loss: 1.746, Test loss: 1.802, Test accuracy: 69.82 

Round   5, Global train loss: 1.746, Global test loss: 2.046, Global test accuracy: 39.83 

Round   6, Train loss: 1.794, Test loss: 1.798, Test accuracy: 69.73 

Round   6, Global train loss: 1.794, Global test loss: 2.015, Global test accuracy: 44.72 

Round   7, Train loss: 1.799, Test loss: 1.779, Test accuracy: 71.20 

Round   7, Global train loss: 1.799, Global test loss: 1.934, Global test accuracy: 63.23 

Round   8, Train loss: 1.770, Test loss: 1.774, Test accuracy: 71.45 

Round   8, Global train loss: 1.770, Global test loss: 1.937, Global test accuracy: 57.53 

Round   9, Train loss: 1.668, Test loss: 1.761, Test accuracy: 71.78 

Round   9, Global train loss: 1.668, Global test loss: 1.872, Global test accuracy: 65.47 

Round  10, Train loss: 1.705, Test loss: 1.759, Test accuracy: 71.78 

Round  10, Global train loss: 1.705, Global test loss: 1.894, Global test accuracy: 58.58 

Round  11, Train loss: 1.759, Test loss: 1.759, Test accuracy: 71.73 

Round  11, Global train loss: 1.759, Global test loss: 1.875, Global test accuracy: 61.68 

Round  12, Train loss: 1.766, Test loss: 1.735, Test accuracy: 72.98 

Round  12, Global train loss: 1.766, Global test loss: 1.849, Global test accuracy: 64.60 

Round  13, Train loss: 1.757, Test loss: 1.735, Test accuracy: 72.97 

Round  13, Global train loss: 1.757, Global test loss: 1.893, Global test accuracy: 58.57 

Round  14, Train loss: 1.758, Test loss: 1.735, Test accuracy: 72.95 

Round  14, Global train loss: 1.758, Global test loss: 1.865, Global test accuracy: 61.68 

Round  15, Train loss: 1.803, Test loss: 1.734, Test accuracy: 73.03 

Round  15, Global train loss: 1.803, Global test loss: 1.840, Global test accuracy: 65.30 

Round  16, Train loss: 1.809, Test loss: 1.733, Test accuracy: 73.05 

Round  16, Global train loss: 1.809, Global test loss: 1.828, Global test accuracy: 67.90 

Round  17, Train loss: 1.705, Test loss: 1.733, Test accuracy: 73.10 

Round  17, Global train loss: 1.705, Global test loss: 1.822, Global test accuracy: 68.05 

Round  18, Train loss: 1.594, Test loss: 1.732, Test accuracy: 73.13 

Round  18, Global train loss: 1.594, Global test loss: 1.822, Global test accuracy: 66.07 

Round  19, Train loss: 1.806, Test loss: 1.730, Test accuracy: 73.20 

Round  19, Global train loss: 1.806, Global test loss: 1.811, Global test accuracy: 66.87 

Round  20, Train loss: 1.646, Test loss: 1.730, Test accuracy: 73.23 

Round  20, Global train loss: 1.646, Global test loss: 1.796, Global test accuracy: 68.62 

Round  21, Train loss: 1.740, Test loss: 1.720, Test accuracy: 74.25 

Round  21, Global train loss: 1.740, Global test loss: 1.832, Global test accuracy: 63.87 

Round  22, Train loss: 1.667, Test loss: 1.692, Test accuracy: 77.33 

Round  22, Global train loss: 1.667, Global test loss: 1.825, Global test accuracy: 65.32 

Round  23, Train loss: 1.626, Test loss: 1.676, Test accuracy: 79.00 

Round  23, Global train loss: 1.626, Global test loss: 1.822, Global test accuracy: 66.20 

Round  24, Train loss: 1.666, Test loss: 1.662, Test accuracy: 80.42 

Round  24, Global train loss: 1.666, Global test loss: 1.820, Global test accuracy: 66.38 

Round  25, Train loss: 1.604, Test loss: 1.659, Test accuracy: 80.65 

Round  25, Global train loss: 1.604, Global test loss: 1.790, Global test accuracy: 68.60 

Round  26, Train loss: 1.754, Test loss: 1.659, Test accuracy: 80.63 

Round  26, Global train loss: 1.754, Global test loss: 1.778, Global test accuracy: 70.22 

Round  27, Train loss: 1.601, Test loss: 1.659, Test accuracy: 80.53 

Round  27, Global train loss: 1.601, Global test loss: 1.827, Global test accuracy: 65.28 

Round  28, Train loss: 1.661, Test loss: 1.657, Test accuracy: 80.65 

Round  28, Global train loss: 1.661, Global test loss: 1.835, Global test accuracy: 64.50 

Round  29, Train loss: 1.662, Test loss: 1.656, Test accuracy: 80.82 

Round  29, Global train loss: 1.662, Global test loss: 1.817, Global test accuracy: 65.62 

Round  30, Train loss: 1.753, Test loss: 1.656, Test accuracy: 80.75 

Round  30, Global train loss: 1.753, Global test loss: 1.764, Global test accuracy: 70.28 

Round  31, Train loss: 1.699, Test loss: 1.656, Test accuracy: 80.77 

Round  31, Global train loss: 1.699, Global test loss: 1.763, Global test accuracy: 73.27 

Round  32, Train loss: 1.539, Test loss: 1.656, Test accuracy: 80.75 

Round  32, Global train loss: 1.539, Global test loss: 1.772, Global test accuracy: 68.88 

Round  33, Train loss: 1.591, Test loss: 1.655, Test accuracy: 80.80 

Round  33, Global train loss: 1.591, Global test loss: 1.791, Global test accuracy: 66.98 

Round  34, Train loss: 1.646, Test loss: 1.655, Test accuracy: 80.82 

Round  34, Global train loss: 1.646, Global test loss: 1.761, Global test accuracy: 72.88 

Round  35, Train loss: 1.596, Test loss: 1.655, Test accuracy: 80.78 

Round  35, Global train loss: 1.596, Global test loss: 1.740, Global test accuracy: 74.98 

Round  36, Train loss: 1.641, Test loss: 1.654, Test accuracy: 80.90 

Round  36, Global train loss: 1.641, Global test loss: 1.750, Global test accuracy: 71.90 

Round  37, Train loss: 1.535, Test loss: 1.655, Test accuracy: 80.78 

Round  37, Global train loss: 1.535, Global test loss: 1.759, Global test accuracy: 70.18 

Round  38, Train loss: 1.692, Test loss: 1.655, Test accuracy: 80.75 

Round  38, Global train loss: 1.692, Global test loss: 1.754, Global test accuracy: 72.05 

Round  39, Train loss: 1.644, Test loss: 1.654, Test accuracy: 80.85 

Round  39, Global train loss: 1.644, Global test loss: 1.735, Global test accuracy: 75.22 

Round  40, Train loss: 1.693, Test loss: 1.653, Test accuracy: 80.75 

Round  40, Global train loss: 1.693, Global test loss: 1.755, Global test accuracy: 73.03 

Round  41, Train loss: 1.647, Test loss: 1.653, Test accuracy: 80.83 

Round  41, Global train loss: 1.647, Global test loss: 1.767, Global test accuracy: 69.65 

Round  42, Train loss: 1.587, Test loss: 1.652, Test accuracy: 80.93 

Round  42, Global train loss: 1.587, Global test loss: 1.770, Global test accuracy: 69.03 

Round  43, Train loss: 1.689, Test loss: 1.652, Test accuracy: 80.95 

Round  43, Global train loss: 1.689, Global test loss: 1.740, Global test accuracy: 73.53 

Round  44, Train loss: 1.589, Test loss: 1.652, Test accuracy: 80.88 

Round  44, Global train loss: 1.589, Global test loss: 1.759, Global test accuracy: 70.03 

Round  45, Train loss: 1.643, Test loss: 1.651, Test accuracy: 80.95 

Round  45, Global train loss: 1.643, Global test loss: 1.749, Global test accuracy: 73.62 

Round  46, Train loss: 1.582, Test loss: 1.651, Test accuracy: 80.98 

Round  46, Global train loss: 1.582, Global test loss: 1.729, Global test accuracy: 74.98 

Round  47, Train loss: 1.694, Test loss: 1.651, Test accuracy: 81.00 

Round  47, Global train loss: 1.694, Global test loss: 1.738, Global test accuracy: 73.50 

Round  48, Train loss: 1.637, Test loss: 1.652, Test accuracy: 80.88 

Round  48, Global train loss: 1.637, Global test loss: 1.773, Global test accuracy: 69.33 

Round  49, Train loss: 1.533, Test loss: 1.652, Test accuracy: 80.90 

Round  49, Global train loss: 1.533, Global test loss: 1.764, Global test accuracy: 69.65 

Final Round, Train loss: 1.635, Test loss: 1.650, Test accuracy: 80.97 

Final Round, Global train loss: 1.635, Global test loss: 1.764, Global test accuracy: 69.65 

Average accuracy final 10 rounds: 80.90666666666667 

Average global accuracy final 10 rounds: 71.63666666666667 

343.28339433670044
[1.5077507495880127, 2.1009771823883057, 2.7007100582122803, 3.354851484298706, 3.945326566696167, 4.538585186004639, 5.133448600769043, 5.761075735092163, 6.355224132537842, 6.972532749176025, 7.56807017326355, 8.166102886199951, 8.760483026504517, 9.35797905921936, 9.957704544067383, 10.568103313446045, 11.162542581558228, 11.781657457351685, 12.37903094291687, 12.975235939025879, 13.582849025726318, 14.19554352760315, 14.787582635879517, 15.38021731376648, 15.97436237335205, 16.568942546844482, 17.163544416427612, 17.76050066947937, 18.354164361953735, 18.950018644332886, 19.532227993011475, 20.126468420028687, 20.748239517211914, 21.339604139328003, 21.933752298355103, 22.530511617660522, 23.11934781074524, 23.707172393798828, 24.294774770736694, 24.89604640007019, 25.48470449447632, 26.0769305229187, 26.682414770126343, 27.283074617385864, 27.879817724227905, 28.475276708602905, 29.07351040840149, 29.666123151779175, 30.255125284194946, 30.84922432899475, 32.0548050403595]
[26.85, 30.616666666666667, 43.46666666666667, 55.483333333333334, 63.56666666666667, 69.81666666666666, 69.73333333333333, 71.2, 71.45, 71.78333333333333, 71.78333333333333, 71.73333333333333, 72.98333333333333, 72.96666666666667, 72.95, 73.03333333333333, 73.05, 73.1, 73.13333333333334, 73.2, 73.23333333333333, 74.25, 77.33333333333333, 79.0, 80.41666666666667, 80.65, 80.63333333333334, 80.53333333333333, 80.65, 80.81666666666666, 80.75, 80.76666666666667, 80.75, 80.8, 80.81666666666666, 80.78333333333333, 80.9, 80.78333333333333, 80.75, 80.85, 80.75, 80.83333333333333, 80.93333333333334, 80.95, 80.88333333333334, 80.95, 80.98333333333333, 81.0, 80.88333333333334, 80.9, 80.96666666666667]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.298, Test loss: 2.301, Test accuracy: 15.98 

Round   1, Train loss: 2.291, Test loss: 2.298, Test accuracy: 20.23 

Round   2, Train loss: 2.278, Test loss: 2.290, Test accuracy: 18.28 

Round   3, Train loss: 2.230, Test loss: 2.258, Test accuracy: 28.40 

Round   4, Train loss: 2.109, Test loss: 2.183, Test accuracy: 32.85 

Round   5, Train loss: 2.005, Test loss: 2.108, Test accuracy: 44.57 

Round   6, Train loss: 1.940, Test loss: 2.020, Test accuracy: 49.27 

Round   7, Train loss: 1.867, Test loss: 1.965, Test accuracy: 53.57 

Round   8, Train loss: 1.812, Test loss: 1.919, Test accuracy: 58.82 

Round   9, Train loss: 1.763, Test loss: 1.870, Test accuracy: 63.27 

Round  10, Train loss: 1.734, Test loss: 1.817, Test accuracy: 67.37 

Round  11, Train loss: 1.782, Test loss: 1.809, Test accuracy: 67.87 

Round  12, Train loss: 1.785, Test loss: 1.763, Test accuracy: 72.28 

Round  13, Train loss: 1.760, Test loss: 1.738, Test accuracy: 75.00 

Round  14, Train loss: 1.735, Test loss: 1.731, Test accuracy: 75.15 

Round  15, Train loss: 1.726, Test loss: 1.727, Test accuracy: 74.98 

Round  16, Train loss: 1.764, Test loss: 1.725, Test accuracy: 75.10 

Round  17, Train loss: 1.684, Test loss: 1.719, Test accuracy: 75.55 

Round  18, Train loss: 1.709, Test loss: 1.716, Test accuracy: 75.62 

Round  19, Train loss: 1.720, Test loss: 1.715, Test accuracy: 75.47 

Round  20, Train loss: 1.650, Test loss: 1.713, Test accuracy: 75.60 

Round  21, Train loss: 1.608, Test loss: 1.710, Test accuracy: 75.78 

Round  22, Train loss: 1.758, Test loss: 1.710, Test accuracy: 75.65 

Round  23, Train loss: 1.622, Test loss: 1.698, Test accuracy: 76.87 

Round  24, Train loss: 1.682, Test loss: 1.687, Test accuracy: 78.17 

Round  25, Train loss: 1.705, Test loss: 1.686, Test accuracy: 78.28 

Round  26, Train loss: 1.657, Test loss: 1.683, Test accuracy: 78.43 

Round  27, Train loss: 1.562, Test loss: 1.671, Test accuracy: 79.90 

Round  28, Train loss: 1.709, Test loss: 1.671, Test accuracy: 79.92 

Round  29, Train loss: 1.600, Test loss: 1.670, Test accuracy: 79.87 

Round  30, Train loss: 1.760, Test loss: 1.668, Test accuracy: 80.02 

Round  31, Train loss: 1.609, Test loss: 1.667, Test accuracy: 80.10 

Round  32, Train loss: 1.696, Test loss: 1.667, Test accuracy: 80.03 

Round  33, Train loss: 1.660, Test loss: 1.666, Test accuracy: 80.10 

Round  34, Train loss: 1.703, Test loss: 1.665, Test accuracy: 80.18 

Round  35, Train loss: 1.645, Test loss: 1.663, Test accuracy: 80.42 

Round  36, Train loss: 1.659, Test loss: 1.663, Test accuracy: 80.47 

Round  37, Train loss: 1.699, Test loss: 1.663, Test accuracy: 80.45 

Round  38, Train loss: 1.557, Test loss: 1.650, Test accuracy: 81.70 

Round  39, Train loss: 1.548, Test loss: 1.647, Test accuracy: 81.92 

Round  40, Train loss: 1.624, Test loss: 1.636, Test accuracy: 83.20 

Round  41, Train loss: 1.603, Test loss: 1.635, Test accuracy: 83.22 

Round  42, Train loss: 1.488, Test loss: 1.634, Test accuracy: 83.38 

Round  43, Train loss: 1.642, Test loss: 1.633, Test accuracy: 83.47 

Round  44, Train loss: 1.547, Test loss: 1.633, Test accuracy: 83.50 

Round  45, Train loss: 1.640, Test loss: 1.632, Test accuracy: 83.47 

Round  46, Train loss: 1.588, Test loss: 1.632, Test accuracy: 83.47 

Round  47, Train loss: 1.586, Test loss: 1.631, Test accuracy: 83.48 

Round  48, Train loss: 1.603, Test loss: 1.629, Test accuracy: 83.60 

Round  49, Train loss: 1.588, Test loss: 1.629, Test accuracy: 83.62 

Final Round, Train loss: 1.615, Test loss: 1.621, Test accuracy: 84.57 

Average accuracy final 10 rounds: 83.44 

251.47568583488464
[1.492377758026123, 2.1144516468048096, 2.7554450035095215, 3.3917722702026367, 4.0252697467803955, 4.579220771789551, 5.104699611663818, 5.629518747329712, 6.156741380691528, 6.690883636474609, 7.281045198440552, 7.803034543991089, 8.330456256866455, 8.873132467269897, 9.39985990524292, 9.922023057937622, 10.479369401931763, 11.04082989692688, 11.57274842262268, 12.141979455947876, 12.702742576599121, 13.2642982006073, 13.790294170379639, 14.339340209960938, 14.861988067626953, 15.390848159790039, 15.917339563369751, 16.46150493621826, 16.98564624786377, 17.513418436050415, 18.060245513916016, 18.583467721939087, 19.10414695739746, 19.63358497619629, 20.179429292678833, 20.70598268508911, 21.232061624526978, 21.759581565856934, 22.309924364089966, 22.875324487686157, 23.4122633934021, 23.935023069381714, 24.46111512184143, 24.99614906311035, 25.524822473526, 26.04834222793579, 26.574845790863037, 27.10249161720276, 27.63260054588318, 28.15447449684143, 29.08060908317566]
[15.983333333333333, 20.233333333333334, 18.283333333333335, 28.4, 32.85, 44.56666666666667, 49.266666666666666, 53.56666666666667, 58.81666666666667, 63.266666666666666, 67.36666666666666, 67.86666666666666, 72.28333333333333, 75.0, 75.15, 74.98333333333333, 75.1, 75.55, 75.61666666666666, 75.46666666666667, 75.6, 75.78333333333333, 75.65, 76.86666666666666, 78.16666666666667, 78.28333333333333, 78.43333333333334, 79.9, 79.91666666666667, 79.86666666666666, 80.01666666666667, 80.1, 80.03333333333333, 80.1, 80.18333333333334, 80.41666666666667, 80.46666666666667, 80.45, 81.7, 81.91666666666667, 83.2, 83.21666666666667, 83.38333333333334, 83.46666666666667, 83.5, 83.46666666666667, 83.46666666666667, 83.48333333333333, 83.6, 83.61666666666666, 84.56666666666666]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.316, Test loss: 2.301, Test accuracy: 11.05
Round   1, Train loss: 2.295, Test loss: 2.295, Test accuracy: 20.48
Round   2, Train loss: 2.283, Test loss: 2.287, Test accuracy: 19.60
Round   3, Train loss: 2.227, Test loss: 2.247, Test accuracy: 34.37
Round   4, Train loss: 2.140, Test loss: 2.188, Test accuracy: 40.20
Round   5, Train loss: 2.001, Test loss: 2.090, Test accuracy: 46.73
Round   6, Train loss: 1.968, Test loss: 2.012, Test accuracy: 55.03
Round   7, Train loss: 1.831, Test loss: 1.937, Test accuracy: 59.68
Round   8, Train loss: 1.740, Test loss: 1.892, Test accuracy: 62.95
Round   9, Train loss: 1.847, Test loss: 1.829, Test accuracy: 69.32
Round  10, Train loss: 1.820, Test loss: 1.777, Test accuracy: 74.98
Round  11, Train loss: 1.666, Test loss: 1.726, Test accuracy: 79.62
Round  12, Train loss: 1.671, Test loss: 1.680, Test accuracy: 83.38
Round  13, Train loss: 1.654, Test loss: 1.651, Test accuracy: 85.55
Round  14, Train loss: 1.659, Test loss: 1.634, Test accuracy: 87.45
Round  15, Train loss: 1.570, Test loss: 1.623, Test accuracy: 87.45
Round  16, Train loss: 1.646, Test loss: 1.620, Test accuracy: 87.98
Round  17, Train loss: 1.600, Test loss: 1.605, Test accuracy: 88.83
Round  18, Train loss: 1.560, Test loss: 1.600, Test accuracy: 89.07
Round  19, Train loss: 1.542, Test loss: 1.596, Test accuracy: 89.32
Round  20, Train loss: 1.654, Test loss: 1.588, Test accuracy: 90.67
Round  21, Train loss: 1.593, Test loss: 1.585, Test accuracy: 90.73
Round  22, Train loss: 1.537, Test loss: 1.583, Test accuracy: 90.93
Round  23, Train loss: 1.517, Test loss: 1.581, Test accuracy: 90.98
Round  24, Train loss: 1.558, Test loss: 1.559, Test accuracy: 92.97
Round  25, Train loss: 1.614, Test loss: 1.558, Test accuracy: 92.90
Round  26, Train loss: 1.527, Test loss: 1.557, Test accuracy: 92.90
Round  27, Train loss: 1.529, Test loss: 1.553, Test accuracy: 93.42
Round  28, Train loss: 1.518, Test loss: 1.551, Test accuracy: 93.42
Round  29, Train loss: 1.511, Test loss: 1.551, Test accuracy: 93.43
Round  30, Train loss: 1.621, Test loss: 1.549, Test accuracy: 93.42
Round  31, Train loss: 1.561, Test loss: 1.548, Test accuracy: 93.50
Round  32, Train loss: 1.565, Test loss: 1.548, Test accuracy: 93.45
Round  33, Train loss: 1.573, Test loss: 1.539, Test accuracy: 94.75
Round  34, Train loss: 1.537, Test loss: 1.536, Test accuracy: 94.82
Round  35, Train loss: 1.508, Test loss: 1.537, Test accuracy: 94.75
Round  36, Train loss: 1.534, Test loss: 1.534, Test accuracy: 94.93
Round  37, Train loss: 1.525, Test loss: 1.532, Test accuracy: 95.20
Round  38, Train loss: 1.519, Test loss: 1.530, Test accuracy: 95.27
Round  39, Train loss: 1.528, Test loss: 1.525, Test accuracy: 95.63
Round  40, Train loss: 1.530, Test loss: 1.523, Test accuracy: 95.88
Round  41, Train loss: 1.511, Test loss: 1.521, Test accuracy: 95.93
Round  42, Train loss: 1.500, Test loss: 1.520, Test accuracy: 95.90
Round  43, Train loss: 1.509, Test loss: 1.519, Test accuracy: 96.05
Round  44, Train loss: 1.524, Test loss: 1.518, Test accuracy: 96.27
Round  45, Train loss: 1.511, Test loss: 1.517, Test accuracy: 96.18
Round  46, Train loss: 1.505, Test loss: 1.517, Test accuracy: 96.37
Round  47, Train loss: 1.503, Test loss: 1.517, Test accuracy: 96.30
Round  48, Train loss: 1.507, Test loss: 1.516, Test accuracy: 96.37
Round  49, Train loss: 1.499, Test loss: 1.515, Test accuracy: 96.28
Final Round, Train loss: 1.493, Test loss: 1.511, Test accuracy: 96.47
Average accuracy final 10 rounds: 96.15333333333332
302.0839376449585
[1.6275649070739746, 2.343167543411255, 3.0626542568206787, 3.7795443534851074, 4.477533340454102, 5.160041570663452, 5.839773416519165, 6.516463041305542, 7.1979217529296875, 7.86873459815979, 8.548199653625488, 9.22356390953064, 9.902567386627197, 10.690894603729248, 11.481642484664917, 12.158974409103394, 12.838171243667603, 13.545374631881714, 14.235411882400513, 14.932766199111938, 15.609678268432617, 16.334115743637085, 17.034796476364136, 17.711103200912476, 18.497798204421997, 19.174431562423706, 19.849555015563965, 20.52219009399414, 21.194629907608032, 21.88462233543396, 22.606696367263794, 23.284367084503174, 23.971319675445557, 24.645184993743896, 25.325247049331665, 26.033028841018677, 26.746137380599976, 27.44830584526062, 28.12229061126709, 28.800190448760986, 29.49130082130432, 30.194194793701172, 30.86613702774048, 31.542560815811157, 32.246851444244385, 32.95148062705994, 33.69451975822449, 34.39915442466736, 35.07833981513977, 35.75282645225525, 36.93592405319214]
[11.05, 20.483333333333334, 19.6, 34.36666666666667, 40.2, 46.733333333333334, 55.03333333333333, 59.68333333333333, 62.95, 69.31666666666666, 74.98333333333333, 79.61666666666666, 83.38333333333334, 85.55, 87.45, 87.45, 87.98333333333333, 88.83333333333333, 89.06666666666666, 89.31666666666666, 90.66666666666667, 90.73333333333333, 90.93333333333334, 90.98333333333333, 92.96666666666667, 92.9, 92.9, 93.41666666666667, 93.41666666666667, 93.43333333333334, 93.41666666666667, 93.5, 93.45, 94.75, 94.81666666666666, 94.75, 94.93333333333334, 95.2, 95.26666666666667, 95.63333333333334, 95.88333333333334, 95.93333333333334, 95.9, 96.05, 96.26666666666667, 96.18333333333334, 96.36666666666666, 96.3, 96.36666666666666, 96.28333333333333, 96.46666666666667]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
Round   0, Train loss: 2.292, Test loss: 2.297, Test accuracy: 15.20
Round   1, Train loss: 2.271, Test loss: 2.278, Test accuracy: 31.27
Round   2, Train loss: 2.128, Test loss: 2.231, Test accuracy: 17.82
Round   3, Train loss: 2.041, Test loss: 2.186, Test accuracy: 32.98
Round   4, Train loss: 1.893, Test loss: 2.132, Test accuracy: 35.22
Round   5, Train loss: 1.735, Test loss: 2.074, Test accuracy: 42.53
Round   6, Train loss: 1.713, Test loss: 1.994, Test accuracy: 50.82
Round   7, Train loss: 1.601, Test loss: 1.954, Test accuracy: 53.70
Round   8, Train loss: 1.717, Test loss: 1.911, Test accuracy: 56.60
Round   9, Train loss: 1.622, Test loss: 1.926, Test accuracy: 55.68
Round  10, Train loss: 1.652, Test loss: 1.915, Test accuracy: 57.47
Round  11, Train loss: 1.537, Test loss: 1.986, Test accuracy: 45.78
Round  12, Train loss: 1.617, Test loss: 1.844, Test accuracy: 64.85
Round  13, Train loss: 1.591, Test loss: 1.805, Test accuracy: 69.97
Round  14, Train loss: 1.599, Test loss: 1.805, Test accuracy: 70.25
Round  15, Train loss: 1.627, Test loss: 1.778, Test accuracy: 72.12
Round  16, Train loss: 1.607, Test loss: 1.777, Test accuracy: 72.50
Round  17, Train loss: 1.558, Test loss: 1.784, Test accuracy: 70.82
Round  18, Train loss: 1.613, Test loss: 1.769, Test accuracy: 71.55
Round  19, Train loss: 1.516, Test loss: 1.749, Test accuracy: 73.93
Round  20, Train loss: 1.600, Test loss: 1.764, Test accuracy: 72.23
Round  21, Train loss: 1.497, Test loss: 1.755, Test accuracy: 72.78
Round  22, Train loss: 1.502, Test loss: 1.770, Test accuracy: 71.68
Round  23, Train loss: 1.604, Test loss: 1.740, Test accuracy: 75.82
Round  24, Train loss: 1.543, Test loss: 1.747, Test accuracy: 74.38
Round  25, Train loss: 1.537, Test loss: 1.746, Test accuracy: 73.83
Round  26, Train loss: 1.548, Test loss: 1.705, Test accuracy: 78.33
Round  27, Train loss: 1.567, Test loss: 1.713, Test accuracy: 77.38
Round  28, Train loss: 1.535, Test loss: 1.707, Test accuracy: 77.15
Round  29, Train loss: 1.493, Test loss: 1.731, Test accuracy: 74.38
Round  30, Train loss: 1.487, Test loss: 1.711, Test accuracy: 76.95
Round  31, Train loss: 1.492, Test loss: 1.668, Test accuracy: 82.38
Round  32, Train loss: 1.543, Test loss: 1.691, Test accuracy: 78.50
Round  33, Train loss: 1.537, Test loss: 1.699, Test accuracy: 78.35
Round  34, Train loss: 1.489, Test loss: 1.751, Test accuracy: 72.10
Round  35, Train loss: 1.591, Test loss: 1.671, Test accuracy: 80.97
Round  36, Train loss: 1.593, Test loss: 1.685, Test accuracy: 79.57
Round  37, Train loss: 1.494, Test loss: 1.693, Test accuracy: 77.20
Round  38, Train loss: 1.544, Test loss: 1.666, Test accuracy: 81.17
Round  39, Train loss: 1.533, Test loss: 1.684, Test accuracy: 79.60
Round  40, Train loss: 1.536, Test loss: 1.666, Test accuracy: 81.33
Round  41, Train loss: 1.530, Test loss: 1.651, Test accuracy: 83.25
Round  42, Train loss: 1.481, Test loss: 1.691, Test accuracy: 78.73
Round  43, Train loss: 1.540, Test loss: 1.675, Test accuracy: 80.38
Round  44, Train loss: 1.536, Test loss: 1.675, Test accuracy: 81.03
Round  45, Train loss: 1.534, Test loss: 1.685, Test accuracy: 79.20
Round  46, Train loss: 1.530, Test loss: 1.705, Test accuracy: 77.05
Round  47, Train loss: 1.542, Test loss: 1.678, Test accuracy: 80.15
Round  48, Train loss: 1.534, Test loss: 1.658, Test accuracy: 81.95
Round  49, Train loss: 1.588, Test loss: 1.690, Test accuracy: 78.77
Final Round, Train loss: 1.529, Test loss: 1.643, Test accuracy: 83.33
Average accuracy final 10 rounds: 80.185
592.8949120044708
[2.788670778274536, 4.3744730949401855, 6.251178026199341, 8.111316442489624, 9.702720403671265, 11.289065599441528, 12.866060256958008, 14.538045406341553, 16.20983338356018, 17.904106616973877, 19.499355792999268, 21.079134225845337, 22.659239053726196, 24.242035627365112, 25.822998762130737, 27.679775953292847, 29.545759916305542, 31.40630030632019, 33.06227993965149, 34.644813537597656, 36.2439649105072, 38.02063584327698, 39.597840785980225, 41.16978859901428, 42.75462746620178, 44.34611487388611, 45.927677154541016, 47.50909471511841, 49.19273614883423, 50.781981468200684, 52.35559892654419, 53.9316930770874, 55.50892639160156, 57.08262348175049, 58.66366100311279, 60.246562004089355, 62.10035586357117, 63.954405546188354, 65.81856918334961, 67.6909351348877, 69.27319145202637, 70.84459447860718, 72.41890215873718, 74.03563261032104, 75.63404440879822, 77.21421766281128, 78.80181646347046, 80.37250542640686, 81.9412477016449, 83.51382780075073, 85.19948673248291]
[15.2, 31.266666666666666, 17.816666666666666, 32.983333333333334, 35.21666666666667, 42.53333333333333, 50.81666666666667, 53.7, 56.6, 55.68333333333333, 57.46666666666667, 45.78333333333333, 64.85, 69.96666666666667, 70.25, 72.11666666666666, 72.5, 70.81666666666666, 71.55, 73.93333333333334, 72.23333333333333, 72.78333333333333, 71.68333333333334, 75.81666666666666, 74.38333333333334, 73.83333333333333, 78.33333333333333, 77.38333333333334, 77.15, 74.38333333333334, 76.95, 82.38333333333334, 78.5, 78.35, 72.1, 80.96666666666667, 79.56666666666666, 77.2, 81.16666666666667, 79.6, 81.33333333333333, 83.25, 78.73333333333333, 80.38333333333334, 81.03333333333333, 79.2, 77.05, 80.15, 81.95, 78.76666666666667, 83.33333333333333]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
Round   0, Train loss: 1.550, Test loss: 2.255, Test accuracy: 39.27
Round   1, Train loss: 1.349, Test loss: 2.142, Test accuracy: 45.17
Round   2, Train loss: 1.288, Test loss: 2.020, Test accuracy: 57.18
Round   3, Train loss: 1.362, Test loss: 1.942, Test accuracy: 67.70
Round   4, Train loss: 1.329, Test loss: 1.905, Test accuracy: 68.50
Round   5, Train loss: 1.323, Test loss: 1.823, Test accuracy: 74.45
Round   6, Train loss: 1.269, Test loss: 1.807, Test accuracy: 75.02
Round   7, Train loss: 1.180, Test loss: 1.757, Test accuracy: 77.87
Round   8, Train loss: 1.214, Test loss: 1.741, Test accuracy: 82.63
Round   9, Train loss: 1.201, Test loss: 1.717, Test accuracy: 82.70
Round  10, Train loss: 1.165, Test loss: 1.701, Test accuracy: 82.92
Round  11, Train loss: 1.123, Test loss: 1.677, Test accuracy: 84.42
Round  12, Train loss: 1.126, Test loss: 1.656, Test accuracy: 88.42
Round  13, Train loss: 1.114, Test loss: 1.644, Test accuracy: 88.65
Round  14, Train loss: 1.151, Test loss: 1.639, Test accuracy: 88.47
Round  15, Train loss: 1.149, Test loss: 1.626, Test accuracy: 88.95
Round  16, Train loss: 1.225, Test loss: 1.623, Test accuracy: 88.88
Round  17, Train loss: 1.185, Test loss: 1.622, Test accuracy: 88.73
Round  18, Train loss: 1.146, Test loss: 1.619, Test accuracy: 88.52
Round  19, Train loss: 1.105, Test loss: 1.615, Test accuracy: 88.62
Round  20, Train loss: 1.111, Test loss: 1.614, Test accuracy: 88.47
Round  21, Train loss: 1.188, Test loss: 1.613, Test accuracy: 88.43
Round  22, Train loss: 1.145, Test loss: 1.610, Test accuracy: 88.48
Round  23, Train loss: 1.103, Test loss: 1.606, Test accuracy: 88.65
Round  24, Train loss: 1.144, Test loss: 1.606, Test accuracy: 88.67
Round  25, Train loss: 1.226, Test loss: 1.606, Test accuracy: 88.38
Round  26, Train loss: 1.267, Test loss: 1.605, Test accuracy: 88.60
Round  27, Train loss: 1.142, Test loss: 1.603, Test accuracy: 88.53
Round  28, Train loss: 1.185, Test loss: 1.603, Test accuracy: 88.58
Round  29, Train loss: 1.147, Test loss: 1.601, Test accuracy: 88.78
Round  30, Train loss: 1.106, Test loss: 1.600, Test accuracy: 88.57
Round  31, Train loss: 1.146, Test loss: 1.600, Test accuracy: 88.58
Round  32, Train loss: 1.104, Test loss: 1.599, Test accuracy: 88.38
Round  33, Train loss: 1.146, Test loss: 1.599, Test accuracy: 88.45
Round  34, Train loss: 1.144, Test loss: 1.600, Test accuracy: 88.30
Round  35, Train loss: 1.145, Test loss: 1.600, Test accuracy: 88.25
Round  36, Train loss: 1.141, Test loss: 1.599, Test accuracy: 88.20
Round  37, Train loss: 1.142, Test loss: 1.599, Test accuracy: 88.37
Round  38, Train loss: 1.143, Test loss: 1.599, Test accuracy: 88.30
Round  39, Train loss: 1.143, Test loss: 1.600, Test accuracy: 88.02
Round  40, Train loss: 1.143, Test loss: 1.599, Test accuracy: 88.15
Round  41, Train loss: 1.145, Test loss: 1.599, Test accuracy: 88.15
Round  42, Train loss: 1.143, Test loss: 1.601, Test accuracy: 87.83
Round  43, Train loss: 1.145, Test loss: 1.600, Test accuracy: 88.03
Round  44, Train loss: 1.144, Test loss: 1.599, Test accuracy: 88.08
Round  45, Train loss: 1.186, Test loss: 1.599, Test accuracy: 87.95
Round  46, Train loss: 1.146, Test loss: 1.598, Test accuracy: 87.87
Round  47, Train loss: 1.101, Test loss: 1.599, Test accuracy: 87.88
Round  48, Train loss: 1.144, Test loss: 1.598, Test accuracy: 87.90
Round  49, Train loss: 1.144, Test loss: 1.599, Test accuracy: 87.77
Final Round, Train loss: 1.151, Test loss: 1.599, Test accuracy: 87.77
Average accuracy final 10 rounds: 87.96166666666669
476.23786664009094
[]
[39.266666666666666, 45.166666666666664, 57.18333333333333, 67.7, 68.5, 74.45, 75.01666666666667, 77.86666666666666, 82.63333333333334, 82.7, 82.91666666666667, 84.41666666666667, 88.41666666666667, 88.65, 88.46666666666667, 88.95, 88.88333333333334, 88.73333333333333, 88.51666666666667, 88.61666666666666, 88.46666666666667, 88.43333333333334, 88.48333333333333, 88.65, 88.66666666666667, 88.38333333333334, 88.6, 88.53333333333333, 88.58333333333333, 88.78333333333333, 88.56666666666666, 88.58333333333333, 88.38333333333334, 88.45, 88.3, 88.25, 88.2, 88.36666666666666, 88.3, 88.01666666666667, 88.15, 88.15, 87.83333333333333, 88.03333333333333, 88.08333333333333, 87.95, 87.86666666666666, 87.88333333333334, 87.9, 87.76666666666667, 87.76666666666667]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.288, Test loss: 2.290, Test accuracy: 22.67
Round   0: Global train loss: 2.288, Global test loss: 2.304, Global test accuracy: 9.25
Round   1, Train loss: 2.264, Test loss: 2.279, Test accuracy: 18.10
Round   1: Global train loss: 2.264, Global test loss: 2.304, Global test accuracy: 10.23
Round   2, Train loss: 2.268, Test loss: 2.263, Test accuracy: 28.27
Round   2: Global train loss: 2.268, Global test loss: 2.304, Global test accuracy: 12.12
Round   3, Train loss: 2.220, Test loss: 2.238, Test accuracy: 30.18
Round   3: Global train loss: 2.220, Global test loss: 2.304, Global test accuracy: 15.63
Round   4, Train loss: 2.162, Test loss: 2.227, Test accuracy: 30.28
Round   4: Global train loss: 2.162, Global test loss: 2.303, Global test accuracy: 15.62
Round   5, Train loss: 2.225, Test loss: 2.270, Test accuracy: 18.37
Round   5: Global train loss: 2.225, Global test loss: 2.304, Global test accuracy: 12.43
Round   6, Train loss: 2.159, Test loss: 2.247, Test accuracy: 19.68
Round   6: Global train loss: 2.159, Global test loss: 2.304, Global test accuracy: 11.82
Round   7, Train loss: 1.955, Test loss: 2.180, Test accuracy: 28.20
Round   7: Global train loss: 1.955, Global test loss: 2.303, Global test accuracy: 11.30
Round   8, Train loss: 1.637, Test loss: 2.102, Test accuracy: 37.35
Round   8: Global train loss: 1.637, Global test loss: 2.303, Global test accuracy: 16.12
Round   9, Train loss: 2.032, Test loss: 2.178, Test accuracy: 24.50
Round   9: Global train loss: 2.032, Global test loss: 2.303, Global test accuracy: 11.17
Round  10, Train loss: 1.302, Test loss: 2.063, Test accuracy: 35.72
Round  10: Global train loss: 1.302, Global test loss: 2.301, Global test accuracy: 15.88
Round  11, Train loss: 1.734, Test loss: 2.169, Test accuracy: 22.37
Round  11: Global train loss: 1.734, Global test loss: 2.303, Global test accuracy: 14.53
Round  12, Train loss: 1.192, Test loss: 2.043, Test accuracy: 39.03
Round  12: Global train loss: 1.192, Global test loss: 2.301, Global test accuracy: 11.47
Round  13, Train loss: 1.022, Test loss: 2.038, Test accuracy: 43.00
Round  13: Global train loss: 1.022, Global test loss: 2.301, Global test accuracy: 18.87
Round  14, Train loss: 0.862, Test loss: 1.957, Test accuracy: 53.52
Round  14: Global train loss: 0.862, Global test loss: 2.299, Global test accuracy: 18.82
Round  15, Train loss: 1.366, Test loss: 1.968, Test accuracy: 53.73
Round  15: Global train loss: 1.366, Global test loss: 2.299, Global test accuracy: 17.55
Round  16, Train loss: 0.420, Test loss: 1.947, Test accuracy: 57.13
Round  16: Global train loss: 0.420, Global test loss: 2.298, Global test accuracy: 22.78
Round  17, Train loss: 0.594, Test loss: 1.950, Test accuracy: 52.85
Round  17: Global train loss: 0.594, Global test loss: 2.297, Global test accuracy: 22.22
Round  18, Train loss: 0.014, Test loss: 1.888, Test accuracy: 57.40
Round  18: Global train loss: 0.014, Global test loss: 2.294, Global test accuracy: 35.72
Round  19, Train loss: -0.818, Test loss: 1.799, Test accuracy: 68.57
Round  19: Global train loss: -0.818, Global test loss: 2.288, Global test accuracy: 39.25
Round  20, Train loss: 0.159, Test loss: 1.860, Test accuracy: 64.88
Round  20: Global train loss: 0.159, Global test loss: 2.286, Global test accuracy: 37.67
Round  21, Train loss: 0.999, Test loss: 1.900, Test accuracy: 60.85
Round  21: Global train loss: 0.999, Global test loss: 2.284, Global test accuracy: 38.20
Round  22, Train loss: 0.229, Test loss: 1.832, Test accuracy: 70.55
Round  22: Global train loss: 0.229, Global test loss: 2.277, Global test accuracy: 37.62
Round  23, Train loss: 0.114, Test loss: 1.842, Test accuracy: 67.58
Round  23: Global train loss: 0.114, Global test loss: 2.267, Global test accuracy: 34.13
Round  24, Train loss: 0.179, Test loss: 1.847, Test accuracy: 68.92
Round  24: Global train loss: 0.179, Global test loss: 2.265, Global test accuracy: 33.08
Round  25, Train loss: -0.690, Test loss: 1.764, Test accuracy: 74.88
Round  25: Global train loss: -0.690, Global test loss: 2.255, Global test accuracy: 31.42
Round  26, Train loss: -1.194, Test loss: 1.669, Test accuracy: 82.72
Round  26: Global train loss: -1.194, Global test loss: 2.240, Global test accuracy: 30.10
Round  27, Train loss: -0.883, Test loss: 1.671, Test accuracy: 83.03
Round  27: Global train loss: -0.883, Global test loss: 2.218, Global test accuracy: 28.62
Round  28, Train loss: 0.693, Test loss: 1.774, Test accuracy: 74.37
Round  28: Global train loss: 0.693, Global test loss: 2.216, Global test accuracy: 29.88
Round  29, Train loss: 0.738, Test loss: 1.796, Test accuracy: 70.23
Round  29: Global train loss: 0.738, Global test loss: 2.212, Global test accuracy: 28.85
Round  30, Train loss: -1.461, Test loss: 1.743, Test accuracy: 74.88
Round  30: Global train loss: -1.461, Global test loss: 2.202, Global test accuracy: 26.73
Round  31, Train loss: 0.265, Test loss: 1.811, Test accuracy: 68.25
Round  31: Global train loss: 0.265, Global test loss: 2.206, Global test accuracy: 25.15
Round  32, Train loss: -0.623, Test loss: 1.722, Test accuracy: 77.18
Round  32: Global train loss: -0.623, Global test loss: 2.196, Global test accuracy: 27.98
Round  33, Train loss: -0.009, Test loss: 1.721, Test accuracy: 77.93
Round  33: Global train loss: -0.009, Global test loss: 2.194, Global test accuracy: 26.83
Round  34, Train loss: 0.274, Test loss: 1.753, Test accuracy: 75.38
Round  34: Global train loss: 0.274, Global test loss: 2.197, Global test accuracy: 25.28
Round  35, Train loss: -0.653, Test loss: 1.646, Test accuracy: 83.87
Round  35: Global train loss: -0.653, Global test loss: 2.189, Global test accuracy: 29.03
Round  36, Train loss: -0.435, Test loss: 1.614, Test accuracy: 86.77
Round  36: Global train loss: -0.435, Global test loss: 2.182, Global test accuracy: 32.65
Round  37, Train loss: -1.050, Test loss: 1.619, Test accuracy: 86.35
Round  37: Global train loss: -1.050, Global test loss: 2.182, Global test accuracy: 33.32
Round  38, Train loss: 0.025, Test loss: 1.647, Test accuracy: 84.40
Round  38: Global train loss: 0.025, Global test loss: 2.183, Global test accuracy: 31.35
Round  39, Train loss: -0.160, Test loss: 1.660, Test accuracy: 82.27
Round  39: Global train loss: -0.160, Global test loss: 2.179, Global test accuracy: 30.15
Round  40, Train loss: -1.322, Test loss: 1.622, Test accuracy: 85.08
Round  40: Global train loss: -1.322, Global test loss: 2.178, Global test accuracy: 33.63
Round  41, Train loss: -1.474, Test loss: 1.579, Test accuracy: 89.13
Round  41: Global train loss: -1.474, Global test loss: 2.169, Global test accuracy: 35.25
Round  42, Train loss: -0.856, Test loss: 1.598, Test accuracy: 87.60
Round  42: Global train loss: -0.856, Global test loss: 2.168, Global test accuracy: 37.02
Round  43, Train loss: -1.109, Test loss: 1.593, Test accuracy: 88.02
Round  43: Global train loss: -1.109, Global test loss: 2.163, Global test accuracy: 37.30
Round  44, Train loss: -2.184, Test loss: 1.574, Test accuracy: 89.63
Round  44: Global train loss: -2.184, Global test loss: 2.154, Global test accuracy: 36.70
Round  45, Train loss: -1.596, Test loss: 1.565, Test accuracy: 90.65
Round  45: Global train loss: -1.596, Global test loss: 2.152, Global test accuracy: 37.20
Round  46, Train loss: -2.088, Test loss: 1.548, Test accuracy: 92.07
Round  46: Global train loss: -2.088, Global test loss: 2.152, Global test accuracy: 37.78
Round  47, Train loss: -1.085, Test loss: 1.575, Test accuracy: 89.37
Round  47: Global train loss: -1.085, Global test loss: 2.148, Global test accuracy: 38.35
Round  48, Train loss: -2.297, Test loss: 1.594, Test accuracy: 87.35
Round  48: Global train loss: -2.297, Global test loss: 2.147, Global test accuracy: 39.15
Round  49, Train loss: -2.396, Test loss: 1.577, Test accuracy: 89.07
Round  49: Global train loss: -2.396, Global test loss: 2.144, Global test accuracy: 39.40
Final Round: Train loss: 1.661, Test loss: 1.540, Test accuracy: 93.78
Final Round: Global train loss: 1.661, Global test loss: 2.134, Global test accuracy: 39.62
Average accuracy final 10 rounds: 88.79666666666667
Average global accuracy final 10 rounds: 37.178333333333335
388.15525126457214
[]
[22.666666666666668, 18.1, 28.266666666666666, 30.183333333333334, 30.283333333333335, 18.366666666666667, 19.683333333333334, 28.2, 37.35, 24.5, 35.71666666666667, 22.366666666666667, 39.03333333333333, 43.0, 53.516666666666666, 53.733333333333334, 57.13333333333333, 52.85, 57.4, 68.56666666666666, 64.88333333333334, 60.85, 70.55, 67.58333333333333, 68.91666666666667, 74.88333333333334, 82.71666666666667, 83.03333333333333, 74.36666666666666, 70.23333333333333, 74.88333333333334, 68.25, 77.18333333333334, 77.93333333333334, 75.38333333333334, 83.86666666666666, 86.76666666666667, 86.35, 84.4, 82.26666666666667, 85.08333333333333, 89.13333333333334, 87.6, 88.01666666666667, 89.63333333333334, 90.65, 92.06666666666666, 89.36666666666666, 87.35, 89.06666666666666, 93.78333333333333]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.304, Test loss: 2.303, Test accuracy: 10.07 

Round   0, Global train loss: 2.304, Global test loss: 2.304, Global test accuracy: 9.97 

Round   1, Train loss: 2.304, Test loss: 2.303, Test accuracy: 10.15 

Round   1, Global train loss: 2.304, Global test loss: 2.304, Global test accuracy: 9.97 

Round   2, Train loss: 2.302, Test loss: 2.303, Test accuracy: 10.17 

Round   2, Global train loss: 2.302, Global test loss: 2.304, Global test accuracy: 10.00 

Round   3, Train loss: 2.301, Test loss: 2.303, Test accuracy: 10.20 

Round   3, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 10.08 

Round   4, Train loss: 2.304, Test loss: 2.303, Test accuracy: 10.23 

Round   4, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 10.08 

Round   5, Train loss: 2.303, Test loss: 2.303, Test accuracy: 10.18 

Round   5, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.07 

Round   6, Train loss: 2.301, Test loss: 2.303, Test accuracy: 10.27 

Round   6, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 10.08 

Round   7, Train loss: 2.303, Test loss: 2.303, Test accuracy: 10.30 

Round   7, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.13 

Round   8, Train loss: 2.303, Test loss: 2.303, Test accuracy: 10.32 

Round   8, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.15 

Round   9, Train loss: 2.303, Test loss: 2.303, Test accuracy: 10.35 

Round   9, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.17 

Round  10, Train loss: 2.305, Test loss: 2.303, Test accuracy: 10.40 

Round  10, Global train loss: 2.305, Global test loss: 2.303, Global test accuracy: 10.18 

Round  11, Train loss: 2.301, Test loss: 2.303, Test accuracy: 10.48 

Round  11, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 10.25 

Round  12, Train loss: 2.304, Test loss: 2.303, Test accuracy: 10.47 

Round  12, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 10.33 

Round  13, Train loss: 2.303, Test loss: 2.303, Test accuracy: 10.47 

Round  13, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.22 

Round  14, Train loss: 2.303, Test loss: 2.303, Test accuracy: 10.47 

Round  14, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.22 

Round  15, Train loss: 2.301, Test loss: 2.303, Test accuracy: 10.47 

Round  15, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 10.28 

Round  16, Train loss: 2.303, Test loss: 2.303, Test accuracy: 10.50 

Round  16, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.25 

Round  17, Train loss: 2.305, Test loss: 2.303, Test accuracy: 10.45 

Round  17, Global train loss: 2.305, Global test loss: 2.303, Global test accuracy: 10.25 

Round  18, Train loss: 2.305, Test loss: 2.303, Test accuracy: 10.47 

Round  18, Global train loss: 2.305, Global test loss: 2.303, Global test accuracy: 10.25 

Round  19, Train loss: 2.303, Test loss: 2.303, Test accuracy: 10.47 

Round  19, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.25 

Round  20, Train loss: 2.304, Test loss: 2.303, Test accuracy: 10.48 

Round  20, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 10.30 

Round  21, Train loss: 2.303, Test loss: 2.303, Test accuracy: 10.50 

Round  21, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.37 

Round  22, Train loss: 2.303, Test loss: 2.303, Test accuracy: 10.55 

Round  22, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.53 

Round  23, Train loss: 2.301, Test loss: 2.303, Test accuracy: 10.58 

Round  23, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 10.52 

Round  24, Train loss: 2.299, Test loss: 2.303, Test accuracy: 10.72 

Round  24, Global train loss: 2.299, Global test loss: 2.303, Global test accuracy: 10.58 

Round  25, Train loss: 2.301, Test loss: 2.303, Test accuracy: 10.87 

Round  25, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 10.65 

Round  26, Train loss: 2.301, Test loss: 2.303, Test accuracy: 10.83 

Round  26, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 10.68 

Round  27, Train loss: 2.304, Test loss: 2.303, Test accuracy: 10.92 

Round  27, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 10.75 

Round  28, Train loss: 2.301, Test loss: 2.303, Test accuracy: 10.95 

Round  28, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 10.78 

Round  29, Train loss: 2.302, Test loss: 2.303, Test accuracy: 11.02 

Round  29, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 10.83 

Round  30, Train loss: 2.303, Test loss: 2.303, Test accuracy: 11.15 

Round  30, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.87 

Round  31, Train loss: 2.303, Test loss: 2.303, Test accuracy: 11.13 

Round  31, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.88 

Round  32, Train loss: 2.303, Test loss: 2.303, Test accuracy: 11.15 

Round  32, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.93 

Round  33, Train loss: 2.303, Test loss: 2.303, Test accuracy: 11.18 

Round  33, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.97 

Round  34, Train loss: 2.303, Test loss: 2.303, Test accuracy: 11.25 

Round  34, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.92 

Round  35, Train loss: 2.304, Test loss: 2.303, Test accuracy: 11.20 

Round  35, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 11.03 

Round  36, Train loss: 2.304, Test loss: 2.303, Test accuracy: 11.25 

Round  36, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 11.07 

Round  37, Train loss: 2.303, Test loss: 2.303, Test accuracy: 11.25 

Round  37, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 11.05 

Round  38, Train loss: 2.301, Test loss: 2.303, Test accuracy: 11.30 

Round  38, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 11.10 

Round  39, Train loss: 2.302, Test loss: 2.303, Test accuracy: 11.35 

Round  39, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 11.15 

Round  40, Train loss: 2.300, Test loss: 2.303, Test accuracy: 11.43 

Round  40, Global train loss: 2.300, Global test loss: 2.303, Global test accuracy: 11.18 

Round  41, Train loss: 2.304, Test loss: 2.303, Test accuracy: 11.43 

Round  41, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 11.20 

Round  42, Train loss: 2.301, Test loss: 2.303, Test accuracy: 11.52 

Round  42, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 11.23 

Round  43, Train loss: 2.301, Test loss: 2.303, Test accuracy: 11.58 

Round  43, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 11.32 

Round  44, Train loss: 2.303, Test loss: 2.303, Test accuracy: 11.70 

Round  44, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 11.37 

Round  45, Train loss: 2.303, Test loss: 2.303, Test accuracy: 11.70 

Round  45, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 11.47 

Round  46, Train loss: 2.302, Test loss: 2.303, Test accuracy: 11.85 

Round  46, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 11.62 

Round  47, Train loss: 2.299, Test loss: 2.303, Test accuracy: 11.95 

Round  47, Global train loss: 2.299, Global test loss: 2.303, Global test accuracy: 11.65 

Round  48, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.02 

Round  48, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 11.78 

Round  49, Train loss: 2.304, Test loss: 2.302, Test accuracy: 12.05 

Round  49, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 11.73 

Final Round, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.57 

Final Round, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 11.73 

Average accuracy final 10 rounds: 11.723333333333333 

Average global accuracy final 10 rounds: 11.454999999999998 

367.6906883716583
[1.7201013565063477, 2.385131597518921, 3.051065444946289, 3.7146589756011963, 4.430372953414917, 5.144299745559692, 5.854520797729492, 6.563960790634155, 7.269951820373535, 7.934756755828857, 8.60486626625061, 9.271679401397705, 9.93674612045288, 10.599306583404541, 11.265175580978394, 11.931253671646118, 12.596880435943604, 13.269178628921509, 13.94227147102356, 14.652105569839478, 15.366735458374023, 16.082242488861084, 16.795859336853027, 17.505431413650513, 18.212289810180664, 18.87851119041443, 19.547577142715454, 20.215738773345947, 20.883986473083496, 21.551337480545044, 22.23991060256958, 22.908517360687256, 23.591290712356567, 24.266722917556763, 24.96915626525879, 25.636560201644897, 26.30990958213806, 26.977601289749146, 27.644473552703857, 28.312115907669067, 28.981091737747192, 29.647796630859375, 30.31546640396118, 30.98397135734558, 31.6561496257782, 32.324299335479736, 32.867457151412964, 33.41304397583008, 33.94753885269165, 34.484307289123535, 35.56562662124634]
[10.066666666666666, 10.15, 10.166666666666666, 10.2, 10.233333333333333, 10.183333333333334, 10.266666666666667, 10.3, 10.316666666666666, 10.35, 10.4, 10.483333333333333, 10.466666666666667, 10.466666666666667, 10.466666666666667, 10.466666666666667, 10.5, 10.45, 10.466666666666667, 10.466666666666667, 10.483333333333333, 10.5, 10.55, 10.583333333333334, 10.716666666666667, 10.866666666666667, 10.833333333333334, 10.916666666666666, 10.95, 11.016666666666667, 11.15, 11.133333333333333, 11.15, 11.183333333333334, 11.25, 11.2, 11.25, 11.25, 11.3, 11.35, 11.433333333333334, 11.433333333333334, 11.516666666666667, 11.583333333333334, 11.7, 11.7, 11.85, 11.95, 12.016666666666667, 12.05, 12.566666666666666]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.286, Test loss: 2.287, Test accuracy: 28.33 

Round   0, Global train loss: 2.286, Global test loss: 2.298, Global test accuracy: 22.00 

Round   1, Train loss: 2.243, Test loss: 2.218, Test accuracy: 31.52 

Round   1, Global train loss: 2.243, Global test loss: 2.275, Global test accuracy: 14.32 

Round   2, Train loss: 2.031, Test loss: 2.061, Test accuracy: 45.93 

Round   2, Global train loss: 2.031, Global test loss: 2.216, Global test accuracy: 22.80 

Round   3, Train loss: 1.805, Test loss: 1.930, Test accuracy: 61.60 

Round   3, Global train loss: 1.805, Global test loss: 2.172, Global test accuracy: 37.28 

Round   4, Train loss: 1.627, Test loss: 1.852, Test accuracy: 69.43 

Round   4, Global train loss: 1.627, Global test loss: 2.127, Global test accuracy: 37.28 

Round   5, Train loss: 1.763, Test loss: 1.775, Test accuracy: 77.10 

Round   5, Global train loss: 1.763, Global test loss: 2.059, Global test accuracy: 44.18 

Round   6, Train loss: 1.735, Test loss: 1.711, Test accuracy: 80.93 

Round   6, Global train loss: 1.735, Global test loss: 2.158, Global test accuracy: 42.50 

Round   7, Train loss: 1.503, Test loss: 1.700, Test accuracy: 81.12 

Round   7, Global train loss: 1.503, Global test loss: 2.143, Global test accuracy: 30.57 

Round   8, Train loss: 1.591, Test loss: 1.670, Test accuracy: 84.40 

Round   8, Global train loss: 1.591, Global test loss: 2.114, Global test accuracy: 39.12 

Round   9, Train loss: 1.584, Test loss: 1.642, Test accuracy: 85.00 

Round   9, Global train loss: 1.584, Global test loss: 2.205, Global test accuracy: 23.53 

Round  10, Train loss: 1.551, Test loss: 1.627, Test accuracy: 86.62 

Round  10, Global train loss: 1.551, Global test loss: 2.127, Global test accuracy: 34.75 

Round  11, Train loss: 1.563, Test loss: 1.610, Test accuracy: 88.67 

Round  11, Global train loss: 1.563, Global test loss: 2.240, Global test accuracy: 15.35 

Round  12, Train loss: 1.483, Test loss: 1.607, Test accuracy: 88.75 

Round  12, Global train loss: 1.483, Global test loss: 2.094, Global test accuracy: 39.35 

Round  13, Train loss: 1.645, Test loss: 1.556, Test accuracy: 92.53 

Round  13, Global train loss: 1.645, Global test loss: 2.110, Global test accuracy: 36.80 

Round  14, Train loss: 1.515, Test loss: 1.543, Test accuracy: 93.77 

Round  14, Global train loss: 1.515, Global test loss: 2.096, Global test accuracy: 35.22 

Round  15, Train loss: 1.523, Test loss: 1.523, Test accuracy: 95.65 

Round  15, Global train loss: 1.523, Global test loss: 2.085, Global test accuracy: 36.38 

Round  16, Train loss: 1.487, Test loss: 1.518, Test accuracy: 95.73 

Round  16, Global train loss: 1.487, Global test loss: 2.150, Global test accuracy: 28.10 

Round  17, Train loss: 1.478, Test loss: 1.514, Test accuracy: 95.90 

Round  17, Global train loss: 1.478, Global test loss: 2.143, Global test accuracy: 33.45 

Round  18, Train loss: 1.468, Test loss: 1.514, Test accuracy: 95.85 

Round  18, Global train loss: 1.468, Global test loss: 2.068, Global test accuracy: 46.02 

Round  19, Train loss: 1.468, Test loss: 1.513, Test accuracy: 95.93 

Round  19, Global train loss: 1.468, Global test loss: 2.141, Global test accuracy: 42.23 

Round  20, Train loss: 1.474, Test loss: 1.512, Test accuracy: 95.88 

Round  20, Global train loss: 1.474, Global test loss: 2.031, Global test accuracy: 46.43 

Round  21, Train loss: 1.480, Test loss: 1.511, Test accuracy: 95.83 

Round  21, Global train loss: 1.480, Global test loss: 2.070, Global test accuracy: 52.83 

Round  22, Train loss: 1.470, Test loss: 1.511, Test accuracy: 95.80 

Round  22, Global train loss: 1.470, Global test loss: 2.201, Global test accuracy: 20.75 

Round  23, Train loss: 1.473, Test loss: 1.510, Test accuracy: 95.78 

Round  23, Global train loss: 1.473, Global test loss: 2.141, Global test accuracy: 34.93 

Round  24, Train loss: 1.472, Test loss: 1.509, Test accuracy: 95.78 

Round  24, Global train loss: 1.472, Global test loss: 2.092, Global test accuracy: 45.97 

Round  25, Train loss: 1.469, Test loss: 1.509, Test accuracy: 95.82 

Round  25, Global train loss: 1.469, Global test loss: 2.186, Global test accuracy: 22.05 

Round  26, Train loss: 1.467, Test loss: 1.509, Test accuracy: 95.83 

Round  26, Global train loss: 1.467, Global test loss: 2.112, Global test accuracy: 35.88 

Round  27, Train loss: 1.465, Test loss: 1.509, Test accuracy: 95.68 

Round  27, Global train loss: 1.465, Global test loss: 2.111, Global test accuracy: 35.35 

Round  28, Train loss: 1.468, Test loss: 1.509, Test accuracy: 95.68 

Round  28, Global train loss: 1.468, Global test loss: 2.062, Global test accuracy: 41.90 

Round  29, Train loss: 1.469, Test loss: 1.509, Test accuracy: 95.63 

Round  29, Global train loss: 1.469, Global test loss: 2.097, Global test accuracy: 38.33 

Round  30, Train loss: 1.470, Test loss: 1.509, Test accuracy: 95.68 

Round  30, Global train loss: 1.470, Global test loss: 2.125, Global test accuracy: 35.83 

Round  31, Train loss: 1.466, Test loss: 1.508, Test accuracy: 95.68 

Round  31, Global train loss: 1.466, Global test loss: 2.068, Global test accuracy: 39.57 

Round  32, Train loss: 1.466, Test loss: 1.508, Test accuracy: 95.68 

Round  32, Global train loss: 1.466, Global test loss: 2.170, Global test accuracy: 24.78 

Round  33, Train loss: 1.468, Test loss: 1.508, Test accuracy: 95.68 

Round  33, Global train loss: 1.468, Global test loss: 2.040, Global test accuracy: 45.42 

Round  34, Train loss: 1.467, Test loss: 1.508, Test accuracy: 95.77 

Round  34, Global train loss: 1.467, Global test loss: 2.041, Global test accuracy: 41.57 

Round  35, Train loss: 1.465, Test loss: 1.508, Test accuracy: 95.78 

Round  35, Global train loss: 1.465, Global test loss: 2.131, Global test accuracy: 38.87 

Round  36, Train loss: 1.466, Test loss: 1.508, Test accuracy: 95.77 

Round  36, Global train loss: 1.466, Global test loss: 2.098, Global test accuracy: 48.10 

Round  37, Train loss: 1.465, Test loss: 1.507, Test accuracy: 95.68 

Round  37, Global train loss: 1.465, Global test loss: 2.102, Global test accuracy: 37.33 

Round  38, Train loss: 1.467, Test loss: 1.507, Test accuracy: 95.68 

Round  38, Global train loss: 1.467, Global test loss: 2.013, Global test accuracy: 48.55 

Round  39, Train loss: 1.465, Test loss: 1.507, Test accuracy: 95.70 

Round  39, Global train loss: 1.465, Global test loss: 2.102, Global test accuracy: 35.30 

Round  40, Train loss: 1.465, Test loss: 1.507, Test accuracy: 95.72 

Round  40, Global train loss: 1.465, Global test loss: 2.093, Global test accuracy: 37.92 

Round  41, Train loss: 1.464, Test loss: 1.507, Test accuracy: 95.65 

Round  41, Global train loss: 1.464, Global test loss: 2.019, Global test accuracy: 56.35 

Round  42, Train loss: 1.466, Test loss: 1.507, Test accuracy: 95.62 

Round  42, Global train loss: 1.466, Global test loss: 2.147, Global test accuracy: 34.90 

Round  43, Train loss: 1.468, Test loss: 1.507, Test accuracy: 95.60 

Round  43, Global train loss: 1.468, Global test loss: 2.186, Global test accuracy: 24.25 

Round  44, Train loss: 1.465, Test loss: 1.507, Test accuracy: 95.60 

Round  44, Global train loss: 1.465, Global test loss: 2.113, Global test accuracy: 38.30 

Round  45, Train loss: 1.466, Test loss: 1.507, Test accuracy: 95.58 

Round  45, Global train loss: 1.466, Global test loss: 1.992, Global test accuracy: 46.80 

Round  46, Train loss: 1.465, Test loss: 1.507, Test accuracy: 95.62 

Round  46, Global train loss: 1.465, Global test loss: 2.070, Global test accuracy: 40.20 

Round  47, Train loss: 1.466, Test loss: 1.507, Test accuracy: 95.63 

Round  47, Global train loss: 1.466, Global test loss: 2.076, Global test accuracy: 41.90 

Round  48, Train loss: 1.465, Test loss: 1.507, Test accuracy: 95.65 

Round  48, Global train loss: 1.465, Global test loss: 2.167, Global test accuracy: 24.23 

Round  49, Train loss: 1.467, Test loss: 1.506, Test accuracy: 95.70 

Round  49, Global train loss: 1.467, Global test loss: 2.031, Global test accuracy: 42.67 

Final Round, Train loss: 1.465, Test loss: 1.506, Test accuracy: 95.62 

Final Round, Global train loss: 1.465, Global test loss: 2.031, Global test accuracy: 42.67 

Average accuracy final 10 rounds: 95.63666666666668 

Average global accuracy final 10 rounds: 38.75166666666666 

367.3486132621765
[1.6577458381652832, 2.397923469543457, 3.0688865184783936, 3.7392075061798096, 4.409415006637573, 5.0776917934417725, 5.705637454986572, 6.335138320922852, 6.970829486846924, 7.600614309310913, 8.228471994400024, 8.853583574295044, 9.483431577682495, 10.118995428085327, 10.788751363754272, 11.41920781135559, 12.0465726852417, 12.675920963287354, 13.423227310180664, 14.157356262207031, 14.785100221633911, 15.406620264053345, 16.0366849899292, 16.6730740070343, 17.341718196868896, 17.969638347625732, 18.592106103897095, 19.215837955474854, 19.83979344367981, 20.46588969230652, 21.08808922767639, 21.713774919509888, 22.38227081298828, 23.068148851394653, 23.73826813697815, 24.40617799758911, 25.072415828704834, 25.738853216171265, 26.408348560333252, 27.076483964920044, 27.64307188987732, 28.288432121276855, 28.920515298843384, 29.5398006439209, 30.172166109085083, 30.799391508102417, 31.4559485912323, 32.0992157459259, 32.84197115898132, 33.49472236633301, 34.788180351257324]
[28.333333333333332, 31.516666666666666, 45.93333333333333, 61.6, 69.43333333333334, 77.1, 80.93333333333334, 81.11666666666666, 84.4, 85.0, 86.61666666666666, 88.66666666666667, 88.75, 92.53333333333333, 93.76666666666667, 95.65, 95.73333333333333, 95.9, 95.85, 95.93333333333334, 95.88333333333334, 95.83333333333333, 95.8, 95.78333333333333, 95.78333333333333, 95.81666666666666, 95.83333333333333, 95.68333333333334, 95.68333333333334, 95.63333333333334, 95.68333333333334, 95.68333333333334, 95.68333333333334, 95.68333333333334, 95.76666666666667, 95.78333333333333, 95.76666666666667, 95.68333333333334, 95.68333333333334, 95.7, 95.71666666666667, 95.65, 95.61666666666666, 95.6, 95.6, 95.58333333333333, 95.61666666666666, 95.63333333333334, 95.65, 95.7, 95.61666666666666]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.288, Test loss: 2.289, Test accuracy: 28.02 

Round   0, Global train loss: 2.288, Global test loss: 2.298, Global test accuracy: 29.20 

Round   1, Train loss: 2.263, Test loss: 2.240, Test accuracy: 38.48 

Round   1, Global train loss: 2.263, Global test loss: 2.286, Global test accuracy: 30.28 

Round   2, Train loss: 2.033, Test loss: 2.092, Test accuracy: 44.83 

Round   2, Global train loss: 2.033, Global test loss: 2.183, Global test accuracy: 31.98 

Round   3, Train loss: 1.994, Test loss: 1.976, Test accuracy: 53.95 

Round   3, Global train loss: 1.994, Global test loss: 2.156, Global test accuracy: 30.53 

Round   4, Train loss: 1.713, Test loss: 1.846, Test accuracy: 67.57 

Round   4, Global train loss: 1.713, Global test loss: 2.041, Global test accuracy: 42.28 

Round   5, Train loss: 1.687, Test loss: 1.801, Test accuracy: 71.18 

Round   5, Global train loss: 1.687, Global test loss: 2.050, Global test accuracy: 45.17 

Round   6, Train loss: 1.619, Test loss: 1.741, Test accuracy: 77.22 

Round   6, Global train loss: 1.619, Global test loss: 1.966, Global test accuracy: 50.85 

Round   7, Train loss: 1.693, Test loss: 1.722, Test accuracy: 77.48 

Round   7, Global train loss: 1.693, Global test loss: 1.992, Global test accuracy: 44.62 

Round   8, Train loss: 1.628, Test loss: 1.672, Test accuracy: 80.22 

Round   8, Global train loss: 1.628, Global test loss: 1.881, Global test accuracy: 58.18 

Round   9, Train loss: 1.703, Test loss: 1.629, Test accuracy: 85.65 

Round   9, Global train loss: 1.703, Global test loss: 1.810, Global test accuracy: 69.90 

Round  10, Train loss: 1.606, Test loss: 1.631, Test accuracy: 85.48 

Round  10, Global train loss: 1.606, Global test loss: 1.824, Global test accuracy: 65.98 

Round  11, Train loss: 1.544, Test loss: 1.608, Test accuracy: 86.83 

Round  11, Global train loss: 1.544, Global test loss: 1.790, Global test accuracy: 70.95 

Round  12, Train loss: 1.510, Test loss: 1.608, Test accuracy: 86.77 

Round  12, Global train loss: 1.510, Global test loss: 1.800, Global test accuracy: 68.23 

Round  13, Train loss: 1.602, Test loss: 1.605, Test accuracy: 86.93 

Round  13, Global train loss: 1.602, Global test loss: 1.784, Global test accuracy: 70.13 

Round  14, Train loss: 1.610, Test loss: 1.601, Test accuracy: 87.07 

Round  14, Global train loss: 1.610, Global test loss: 1.751, Global test accuracy: 76.02 

Round  15, Train loss: 1.642, Test loss: 1.600, Test accuracy: 87.08 

Round  15, Global train loss: 1.642, Global test loss: 1.778, Global test accuracy: 72.03 

Round  16, Train loss: 1.541, Test loss: 1.600, Test accuracy: 87.02 

Round  16, Global train loss: 1.541, Global test loss: 1.733, Global test accuracy: 76.23 

Round  17, Train loss: 1.555, Test loss: 1.594, Test accuracy: 87.10 

Round  17, Global train loss: 1.555, Global test loss: 1.778, Global test accuracy: 69.40 

Round  18, Train loss: 1.646, Test loss: 1.594, Test accuracy: 87.07 

Round  18, Global train loss: 1.646, Global test loss: 1.736, Global test accuracy: 74.45 

Round  19, Train loss: 1.645, Test loss: 1.594, Test accuracy: 87.12 

Round  19, Global train loss: 1.645, Global test loss: 1.786, Global test accuracy: 67.38 

Round  20, Train loss: 1.646, Test loss: 1.592, Test accuracy: 87.25 

Round  20, Global train loss: 1.646, Global test loss: 1.725, Global test accuracy: 75.17 

Round  21, Train loss: 1.540, Test loss: 1.591, Test accuracy: 87.42 

Round  21, Global train loss: 1.540, Global test loss: 1.719, Global test accuracy: 76.75 

Round  22, Train loss: 1.638, Test loss: 1.591, Test accuracy: 87.35 

Round  22, Global train loss: 1.638, Global test loss: 1.713, Global test accuracy: 77.03 

Round  23, Train loss: 1.542, Test loss: 1.592, Test accuracy: 87.22 

Round  23, Global train loss: 1.542, Global test loss: 1.764, Global test accuracy: 70.45 

Round  24, Train loss: 1.544, Test loss: 1.592, Test accuracy: 87.18 

Round  24, Global train loss: 1.544, Global test loss: 1.753, Global test accuracy: 71.52 

Round  25, Train loss: 1.638, Test loss: 1.591, Test accuracy: 87.20 

Round  25, Global train loss: 1.638, Global test loss: 1.708, Global test accuracy: 77.50 

Round  26, Train loss: 1.548, Test loss: 1.591, Test accuracy: 87.20 

Round  26, Global train loss: 1.548, Global test loss: 1.718, Global test accuracy: 76.12 

Round  27, Train loss: 1.592, Test loss: 1.590, Test accuracy: 87.17 

Round  27, Global train loss: 1.592, Global test loss: 1.701, Global test accuracy: 78.90 

Round  28, Train loss: 1.699, Test loss: 1.590, Test accuracy: 87.27 

Round  28, Global train loss: 1.699, Global test loss: 1.721, Global test accuracy: 75.50 

Round  29, Train loss: 1.541, Test loss: 1.590, Test accuracy: 87.18 

Round  29, Global train loss: 1.541, Global test loss: 1.718, Global test accuracy: 75.78 

Round  30, Train loss: 1.531, Test loss: 1.590, Test accuracy: 87.15 

Round  30, Global train loss: 1.531, Global test loss: 1.745, Global test accuracy: 72.45 

Round  31, Train loss: 1.695, Test loss: 1.590, Test accuracy: 87.25 

Round  31, Global train loss: 1.695, Global test loss: 1.708, Global test accuracy: 76.93 

Round  32, Train loss: 1.538, Test loss: 1.591, Test accuracy: 87.08 

Round  32, Global train loss: 1.538, Global test loss: 1.778, Global test accuracy: 68.02 

Round  33, Train loss: 1.540, Test loss: 1.591, Test accuracy: 87.18 

Round  33, Global train loss: 1.540, Global test loss: 1.698, Global test accuracy: 78.15 

Round  34, Train loss: 1.581, Test loss: 1.591, Test accuracy: 87.13 

Round  34, Global train loss: 1.581, Global test loss: 1.699, Global test accuracy: 77.47 

Round  35, Train loss: 1.635, Test loss: 1.590, Test accuracy: 87.17 

Round  35, Global train loss: 1.635, Global test loss: 1.698, Global test accuracy: 77.88 

Round  36, Train loss: 1.588, Test loss: 1.590, Test accuracy: 87.17 

Round  36, Global train loss: 1.588, Global test loss: 1.692, Global test accuracy: 78.53 

Round  37, Train loss: 1.589, Test loss: 1.590, Test accuracy: 87.20 

Round  37, Global train loss: 1.589, Global test loss: 1.704, Global test accuracy: 76.98 

Round  38, Train loss: 1.639, Test loss: 1.590, Test accuracy: 87.15 

Round  38, Global train loss: 1.639, Global test loss: 1.722, Global test accuracy: 74.98 

Round  39, Train loss: 1.689, Test loss: 1.590, Test accuracy: 87.13 

Round  39, Global train loss: 1.689, Global test loss: 1.683, Global test accuracy: 79.43 

Round  40, Train loss: 1.532, Test loss: 1.590, Test accuracy: 87.13 

Round  40, Global train loss: 1.532, Global test loss: 1.713, Global test accuracy: 76.50 

Round  41, Train loss: 1.531, Test loss: 1.589, Test accuracy: 87.25 

Round  41, Global train loss: 1.531, Global test loss: 1.681, Global test accuracy: 79.50 

Round  42, Train loss: 1.480, Test loss: 1.589, Test accuracy: 87.20 

Round  42, Global train loss: 1.480, Global test loss: 1.697, Global test accuracy: 78.25 

Round  43, Train loss: 1.633, Test loss: 1.589, Test accuracy: 87.20 

Round  43, Global train loss: 1.633, Global test loss: 1.680, Global test accuracy: 79.90 

Round  44, Train loss: 1.640, Test loss: 1.589, Test accuracy: 87.27 

Round  44, Global train loss: 1.640, Global test loss: 1.698, Global test accuracy: 77.53 

Round  45, Train loss: 1.581, Test loss: 1.589, Test accuracy: 87.23 

Round  45, Global train loss: 1.581, Global test loss: 1.679, Global test accuracy: 80.00 

Round  46, Train loss: 1.473, Test loss: 1.590, Test accuracy: 87.12 

Round  46, Global train loss: 1.473, Global test loss: 1.686, Global test accuracy: 78.95 

Round  47, Train loss: 1.636, Test loss: 1.590, Test accuracy: 87.15 

Round  47, Global train loss: 1.636, Global test loss: 1.691, Global test accuracy: 78.75 

Round  48, Train loss: 1.530, Test loss: 1.590, Test accuracy: 87.17 

Round  48, Global train loss: 1.530, Global test loss: 1.684, Global test accuracy: 78.93 

Round  49, Train loss: 1.636, Test loss: 1.590, Test accuracy: 87.17 

Round  49, Global train loss: 1.636, Global test loss: 1.725, Global test accuracy: 73.62 

Final Round, Train loss: 1.569, Test loss: 1.588, Test accuracy: 87.33 

Final Round, Global train loss: 1.569, Global test loss: 1.725, Global test accuracy: 73.62 

Average accuracy final 10 rounds: 87.18833333333333 

Average global accuracy final 10 rounds: 78.19333333333333 

347.4986674785614
[1.5076370239257812, 2.1606667041778564, 2.764082193374634, 3.3616628646850586, 3.959470272064209, 4.558399677276611, 5.159357070922852, 5.752396583557129, 6.351282596588135, 6.951556205749512, 7.551169157028198, 8.154378890991211, 8.737866401672363, 9.305342435836792, 9.906931161880493, 10.50894832611084, 11.107928991317749, 11.70617127418518, 12.308243751525879, 12.906826734542847, 13.50684118270874, 14.105080842971802, 14.706462621688843, 15.310960531234741, 15.912151336669922, 16.51679539680481, 17.11845302581787, 17.717355012893677, 18.316198110580444, 18.915456295013428, 19.51362633705139, 20.124586582183838, 20.721932411193848, 21.32047986984253, 21.91758894920349, 22.523062229156494, 23.12345290184021, 23.722679376602173, 24.324091911315918, 24.921606302261353, 25.519845962524414, 26.12152862548828, 26.717564582824707, 27.314208269119263, 27.91414785385132, 28.51267647743225, 29.107314348220825, 29.70209765434265, 30.298364400863647, 30.897115468978882, 32.1652467250824]
[28.016666666666666, 38.483333333333334, 44.833333333333336, 53.95, 67.56666666666666, 71.18333333333334, 77.21666666666667, 77.48333333333333, 80.21666666666667, 85.65, 85.48333333333333, 86.83333333333333, 86.76666666666667, 86.93333333333334, 87.06666666666666, 87.08333333333333, 87.01666666666667, 87.1, 87.06666666666666, 87.11666666666666, 87.25, 87.41666666666667, 87.35, 87.21666666666667, 87.18333333333334, 87.2, 87.2, 87.16666666666667, 87.26666666666667, 87.18333333333334, 87.15, 87.25, 87.08333333333333, 87.18333333333334, 87.13333333333334, 87.16666666666667, 87.16666666666667, 87.2, 87.15, 87.13333333333334, 87.13333333333334, 87.25, 87.2, 87.2, 87.26666666666667, 87.23333333333333, 87.11666666666666, 87.15, 87.16666666666667, 87.16666666666667, 87.33333333333333]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.297, Test loss: 2.299, Test accuracy: 26.93 

Round   1, Train loss: 2.292, Test loss: 2.296, Test accuracy: 31.20 

Round   2, Train loss: 2.284, Test loss: 2.289, Test accuracy: 32.88 

Round   3, Train loss: 2.262, Test loss: 2.271, Test accuracy: 42.45 

Round   4, Train loss: 2.160, Test loss: 2.184, Test accuracy: 49.02 

Round   5, Train loss: 1.970, Test loss: 2.072, Test accuracy: 52.33 

Round   6, Train loss: 1.841, Test loss: 1.974, Test accuracy: 61.63 

Round   7, Train loss: 1.761, Test loss: 1.893, Test accuracy: 65.58 

Round   8, Train loss: 1.604, Test loss: 1.834, Test accuracy: 70.28 

Round   9, Train loss: 1.678, Test loss: 1.775, Test accuracy: 74.90 

Round  10, Train loss: 1.555, Test loss: 1.737, Test accuracy: 77.20 

Round  11, Train loss: 1.650, Test loss: 1.722, Test accuracy: 78.48 

Round  12, Train loss: 1.584, Test loss: 1.700, Test accuracy: 80.30 

Round  13, Train loss: 1.616, Test loss: 1.645, Test accuracy: 84.42 

Round  14, Train loss: 1.633, Test loss: 1.637, Test accuracy: 84.70 

Round  15, Train loss: 1.582, Test loss: 1.634, Test accuracy: 85.10 

Round  16, Train loss: 1.657, Test loss: 1.617, Test accuracy: 86.33 

Round  17, Train loss: 1.591, Test loss: 1.610, Test accuracy: 86.98 

Round  18, Train loss: 1.558, Test loss: 1.593, Test accuracy: 88.43 

Round  19, Train loss: 1.615, Test loss: 1.577, Test accuracy: 90.38 

Round  20, Train loss: 1.587, Test loss: 1.572, Test accuracy: 90.35 

Round  21, Train loss: 1.529, Test loss: 1.563, Test accuracy: 91.02 

Round  22, Train loss: 1.519, Test loss: 1.557, Test accuracy: 91.68 

Round  23, Train loss: 1.551, Test loss: 1.555, Test accuracy: 91.68 

Round  24, Train loss: 1.539, Test loss: 1.555, Test accuracy: 91.78 

Round  25, Train loss: 1.495, Test loss: 1.553, Test accuracy: 91.82 

Round  26, Train loss: 1.545, Test loss: 1.552, Test accuracy: 91.73 

Round  27, Train loss: 1.598, Test loss: 1.551, Test accuracy: 92.10 

Round  28, Train loss: 1.519, Test loss: 1.538, Test accuracy: 93.35 

Round  29, Train loss: 1.560, Test loss: 1.536, Test accuracy: 93.40 

Round  30, Train loss: 1.512, Test loss: 1.534, Test accuracy: 93.65 

Round  31, Train loss: 1.544, Test loss: 1.533, Test accuracy: 93.67 

Round  32, Train loss: 1.544, Test loss: 1.532, Test accuracy: 93.68 

Round  33, Train loss: 1.503, Test loss: 1.529, Test accuracy: 93.90 

Round  34, Train loss: 1.488, Test loss: 1.529, Test accuracy: 93.93 

Round  35, Train loss: 1.506, Test loss: 1.526, Test accuracy: 94.17 

Round  36, Train loss: 1.488, Test loss: 1.526, Test accuracy: 94.25 

Round  37, Train loss: 1.494, Test loss: 1.525, Test accuracy: 94.23 

Round  38, Train loss: 1.551, Test loss: 1.525, Test accuracy: 94.25 

Round  39, Train loss: 1.490, Test loss: 1.524, Test accuracy: 94.28 

Round  40, Train loss: 1.496, Test loss: 1.524, Test accuracy: 94.30 

Round  41, Train loss: 1.544, Test loss: 1.524, Test accuracy: 94.22 

Round  42, Train loss: 1.482, Test loss: 1.524, Test accuracy: 94.25 

Round  43, Train loss: 1.490, Test loss: 1.523, Test accuracy: 94.38 

Round  44, Train loss: 1.534, Test loss: 1.522, Test accuracy: 94.35 

Round  45, Train loss: 1.546, Test loss: 1.521, Test accuracy: 94.52 

Round  46, Train loss: 1.491, Test loss: 1.521, Test accuracy: 94.57 

Round  47, Train loss: 1.477, Test loss: 1.521, Test accuracy: 94.62 

Round  48, Train loss: 1.488, Test loss: 1.521, Test accuracy: 94.57 

Round  49, Train loss: 1.546, Test loss: 1.521, Test accuracy: 94.57 

Final Round, Train loss: 1.501, Test loss: 1.520, Test accuracy: 94.43 

Average accuracy final 10 rounds: 94.43333333333334 

244.49099135398865
[1.4447104930877686, 1.971102237701416, 2.513031005859375, 3.0330650806427, 3.5840141773223877, 4.1105616092681885, 4.607551574707031, 5.134809494018555, 5.654990196228027, 6.173933982849121, 6.696354150772095, 7.215384006500244, 7.730518341064453, 8.2535982131958, 8.781752586364746, 9.306017637252808, 9.826630353927612, 10.349819421768188, 10.88712453842163, 11.40635061264038, 11.932439804077148, 12.469565868377686, 12.991376876831055, 13.544928073883057, 14.072444677352905, 14.56474494934082, 15.053919076919556, 15.551557302474976, 16.074935913085938, 16.596473455429077, 17.114559412002563, 17.640334367752075, 18.16138195991516, 18.684070110321045, 19.212563037872314, 19.7327401638031, 20.25274133682251, 20.774415969848633, 21.30287265777588, 21.8241024017334, 22.34317398071289, 22.866232872009277, 23.396140098571777, 23.916091442108154, 24.45322346687317, 24.969540119171143, 25.482956886291504, 26.0249924659729, 26.552761793136597, 27.07472562789917, 28.016586303710938]
[26.933333333333334, 31.2, 32.88333333333333, 42.45, 49.016666666666666, 52.333333333333336, 61.63333333333333, 65.58333333333333, 70.28333333333333, 74.9, 77.2, 78.48333333333333, 80.3, 84.41666666666667, 84.7, 85.1, 86.33333333333333, 86.98333333333333, 88.43333333333334, 90.38333333333334, 90.35, 91.01666666666667, 91.68333333333334, 91.68333333333334, 91.78333333333333, 91.81666666666666, 91.73333333333333, 92.1, 93.35, 93.4, 93.65, 93.66666666666667, 93.68333333333334, 93.9, 93.93333333333334, 94.16666666666667, 94.25, 94.23333333333333, 94.25, 94.28333333333333, 94.3, 94.21666666666667, 94.25, 94.38333333333334, 94.35, 94.51666666666667, 94.56666666666666, 94.61666666666666, 94.56666666666666, 94.56666666666666, 94.43333333333334]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.315, Test loss: 2.299, Test accuracy: 25.10
Round   1, Train loss: 2.287, Test loss: 2.294, Test accuracy: 30.17
Round   2, Train loss: 2.277, Test loss: 2.284, Test accuracy: 25.83
Round   3, Train loss: 2.223, Test loss: 2.240, Test accuracy: 28.85
Round   4, Train loss: 2.079, Test loss: 2.156, Test accuracy: 31.25
Round   5, Train loss: 2.105, Test loss: 2.075, Test accuracy: 47.52
Round   6, Train loss: 1.918, Test loss: 1.996, Test accuracy: 53.48
Round   7, Train loss: 1.797, Test loss: 1.881, Test accuracy: 62.32
Round   8, Train loss: 1.647, Test loss: 1.819, Test accuracy: 68.95
Round   9, Train loss: 1.798, Test loss: 1.778, Test accuracy: 72.13
Round  10, Train loss: 1.768, Test loss: 1.716, Test accuracy: 80.33
Round  11, Train loss: 1.702, Test loss: 1.691, Test accuracy: 83.63
Round  12, Train loss: 1.676, Test loss: 1.667, Test accuracy: 85.15
Round  13, Train loss: 1.600, Test loss: 1.657, Test accuracy: 85.90
Round  14, Train loss: 1.617, Test loss: 1.639, Test accuracy: 87.08
Round  15, Train loss: 1.585, Test loss: 1.620, Test accuracy: 87.25
Round  16, Train loss: 1.551, Test loss: 1.596, Test accuracy: 90.02
Round  17, Train loss: 1.538, Test loss: 1.591, Test accuracy: 90.03
Round  18, Train loss: 1.579, Test loss: 1.589, Test accuracy: 90.27
Round  19, Train loss: 1.522, Test loss: 1.585, Test accuracy: 90.23
Round  20, Train loss: 1.579, Test loss: 1.584, Test accuracy: 90.25
Round  21, Train loss: 1.587, Test loss: 1.572, Test accuracy: 91.47
Round  22, Train loss: 1.510, Test loss: 1.570, Test accuracy: 91.38
Round  23, Train loss: 1.520, Test loss: 1.567, Test accuracy: 91.52
Round  24, Train loss: 1.529, Test loss: 1.564, Test accuracy: 91.52
Round  25, Train loss: 1.572, Test loss: 1.561, Test accuracy: 91.75
Round  26, Train loss: 1.548, Test loss: 1.543, Test accuracy: 93.75
Round  27, Train loss: 1.510, Test loss: 1.542, Test accuracy: 93.77
Round  28, Train loss: 1.521, Test loss: 1.537, Test accuracy: 94.52
Round  29, Train loss: 1.558, Test loss: 1.536, Test accuracy: 94.48
Round  30, Train loss: 1.507, Test loss: 1.535, Test accuracy: 94.62
Round  31, Train loss: 1.572, Test loss: 1.533, Test accuracy: 94.55
Round  32, Train loss: 1.568, Test loss: 1.531, Test accuracy: 94.78
Round  33, Train loss: 1.512, Test loss: 1.529, Test accuracy: 94.92
Round  34, Train loss: 1.557, Test loss: 1.529, Test accuracy: 94.90
Round  35, Train loss: 1.508, Test loss: 1.528, Test accuracy: 94.85
Round  36, Train loss: 1.506, Test loss: 1.527, Test accuracy: 94.90
Round  37, Train loss: 1.548, Test loss: 1.527, Test accuracy: 94.77
Round  38, Train loss: 1.553, Test loss: 1.526, Test accuracy: 94.90
Round  39, Train loss: 1.499, Test loss: 1.526, Test accuracy: 94.83
Round  40, Train loss: 1.495, Test loss: 1.526, Test accuracy: 94.95
Round  41, Train loss: 1.494, Test loss: 1.526, Test accuracy: 94.82
Round  42, Train loss: 1.500, Test loss: 1.526, Test accuracy: 94.85
Round  43, Train loss: 1.485, Test loss: 1.525, Test accuracy: 94.88
Round  44, Train loss: 1.497, Test loss: 1.525, Test accuracy: 94.97
Round  45, Train loss: 1.492, Test loss: 1.525, Test accuracy: 94.93
Round  46, Train loss: 1.489, Test loss: 1.525, Test accuracy: 94.93
Round  47, Train loss: 1.544, Test loss: 1.524, Test accuracy: 95.00
Round  48, Train loss: 1.491, Test loss: 1.525, Test accuracy: 94.92
Round  49, Train loss: 1.490, Test loss: 1.524, Test accuracy: 94.90
Final Round, Train loss: 1.504, Test loss: 1.522, Test accuracy: 95.07
Average accuracy final 10 rounds: 94.915
289.9316236972809
[1.6151790618896484, 2.2949788570404053, 2.9731156826019287, 3.661877393722534, 4.333984375, 5.002187252044678, 5.6691577434539795, 6.342398405075073, 7.013550043106079, 7.683279037475586, 8.35213828086853, 9.021454095840454, 9.687175750732422, 10.356752157211304, 11.02768611907959, 11.701481342315674, 12.393030643463135, 13.060763597488403, 13.728112936019897, 14.401930809020996, 15.071049928665161, 15.732649564743042, 16.38794231414795, 17.059341192245483, 17.755950927734375, 18.425917863845825, 19.098512172698975, 19.761411666870117, 20.439119338989258, 21.11120843887329, 21.781768321990967, 22.449229955673218, 23.125898361206055, 23.802780628204346, 24.486207723617554, 25.17790651321411, 25.847709894180298, 26.5143039226532, 27.174036026000977, 27.859955072402954, 28.52472710609436, 29.189943075180054, 29.869271278381348, 30.537765502929688, 31.210546016693115, 31.915132522583008, 32.49376964569092, 33.065300941467285, 33.62468886375427, 34.18269491195679, 35.097585678100586]
[25.1, 30.166666666666668, 25.833333333333332, 28.85, 31.25, 47.516666666666666, 53.483333333333334, 62.31666666666667, 68.95, 72.13333333333334, 80.33333333333333, 83.63333333333334, 85.15, 85.9, 87.08333333333333, 87.25, 90.01666666666667, 90.03333333333333, 90.26666666666667, 90.23333333333333, 90.25, 91.46666666666667, 91.38333333333334, 91.51666666666667, 91.51666666666667, 91.75, 93.75, 93.76666666666667, 94.51666666666667, 94.48333333333333, 94.61666666666666, 94.55, 94.78333333333333, 94.91666666666667, 94.9, 94.85, 94.9, 94.76666666666667, 94.9, 94.83333333333333, 94.95, 94.81666666666666, 94.85, 94.88333333333334, 94.96666666666667, 94.93333333333334, 94.93333333333334, 95.0, 94.91666666666667, 94.9, 95.06666666666666]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
Round   0, Train loss: 2.295, Test loss: 2.298, Test accuracy: 12.13
Round   1, Train loss: 2.266, Test loss: 2.258, Test accuracy: 15.82
Round   2, Train loss: 2.030, Test loss: 2.143, Test accuracy: 39.87
Round   3, Train loss: 1.868, Test loss: 2.059, Test accuracy: 47.05
Round   4, Train loss: 1.784, Test loss: 2.030, Test accuracy: 45.85
Round   5, Train loss: 1.701, Test loss: 2.004, Test accuracy: 46.35
Round   6, Train loss: 1.573, Test loss: 1.918, Test accuracy: 60.38
Round   7, Train loss: 1.627, Test loss: 1.877, Test accuracy: 63.28
Round   8, Train loss: 1.584, Test loss: 1.905, Test accuracy: 53.92
Round   9, Train loss: 1.682, Test loss: 1.840, Test accuracy: 63.18
Round  10, Train loss: 1.589, Test loss: 1.889, Test accuracy: 57.75
Round  11, Train loss: 1.603, Test loss: 1.917, Test accuracy: 52.70
Round  12, Train loss: 1.501, Test loss: 1.836, Test accuracy: 63.22
Round  13, Train loss: 1.605, Test loss: 1.759, Test accuracy: 72.73
Round  14, Train loss: 1.506, Test loss: 1.772, Test accuracy: 71.35
Round  15, Train loss: 1.597, Test loss: 1.735, Test accuracy: 75.78
Round  16, Train loss: 1.583, Test loss: 1.773, Test accuracy: 69.12
Round  17, Train loss: 1.599, Test loss: 1.844, Test accuracy: 60.52
Round  18, Train loss: 1.535, Test loss: 1.773, Test accuracy: 69.72
Round  19, Train loss: 1.587, Test loss: 1.772, Test accuracy: 69.45
Round  20, Train loss: 1.600, Test loss: 1.766, Test accuracy: 69.75
Round  21, Train loss: 1.541, Test loss: 1.735, Test accuracy: 75.20
Round  22, Train loss: 1.691, Test loss: 1.753, Test accuracy: 72.00
Round  23, Train loss: 1.585, Test loss: 1.707, Test accuracy: 79.22
Round  24, Train loss: 1.530, Test loss: 1.750, Test accuracy: 72.68
Round  25, Train loss: 1.589, Test loss: 1.724, Test accuracy: 75.75
Round  26, Train loss: 1.579, Test loss: 1.708, Test accuracy: 78.22
Round  27, Train loss: 1.583, Test loss: 1.730, Test accuracy: 74.78
Round  28, Train loss: 1.484, Test loss: 1.712, Test accuracy: 76.43
Round  29, Train loss: 1.644, Test loss: 1.697, Test accuracy: 78.97
Round  30, Train loss: 1.530, Test loss: 1.721, Test accuracy: 75.62
Round  31, Train loss: 1.536, Test loss: 1.691, Test accuracy: 79.25
Round  32, Train loss: 1.592, Test loss: 1.748, Test accuracy: 72.35
Round  33, Train loss: 1.641, Test loss: 1.730, Test accuracy: 74.17
Round  34, Train loss: 1.587, Test loss: 1.720, Test accuracy: 76.27
Round  35, Train loss: 1.635, Test loss: 1.676, Test accuracy: 80.90
Round  36, Train loss: 1.582, Test loss: 1.690, Test accuracy: 78.68
Round  37, Train loss: 1.533, Test loss: 1.730, Test accuracy: 74.65
Round  38, Train loss: 1.585, Test loss: 1.704, Test accuracy: 77.07
Round  39, Train loss: 1.641, Test loss: 1.732, Test accuracy: 73.10
Round  40, Train loss: 1.583, Test loss: 1.725, Test accuracy: 75.00
Round  41, Train loss: 1.583, Test loss: 1.676, Test accuracy: 80.57
Round  42, Train loss: 1.583, Test loss: 1.690, Test accuracy: 78.73
Round  43, Train loss: 1.530, Test loss: 1.674, Test accuracy: 80.37
Round  44, Train loss: 1.635, Test loss: 1.674, Test accuracy: 80.65
Round  45, Train loss: 1.583, Test loss: 1.695, Test accuracy: 77.98
Round  46, Train loss: 1.638, Test loss: 1.708, Test accuracy: 76.65
Round  47, Train loss: 1.579, Test loss: 1.703, Test accuracy: 77.50
Round  48, Train loss: 1.582, Test loss: 1.711, Test accuracy: 76.18
Round  49, Train loss: 1.474, Test loss: 1.662, Test accuracy: 81.70
Final Round, Train loss: 1.570, Test loss: 1.660, Test accuracy: 81.75
Average accuracy final 10 rounds: 78.53333333333333
568.0401523113251
[2.4692890644073486, 4.0381903648376465, 5.609124660491943, 7.1909096240997314, 8.761757850646973, 10.339939594268799, 11.92945408821106, 13.42036247253418, 14.92064642906189, 16.420814990997314, 18.000377655029297, 19.608642101287842, 21.234729290008545, 22.846768617630005, 24.400545597076416, 25.951743841171265, 27.505493879318237, 29.074002265930176, 30.643772840499878, 32.22868037223816, 33.8170051574707, 35.41558384895325, 37.00735402107239, 38.588735580444336, 40.17783784866333, 41.75690698623657, 43.34273052215576, 44.92684054374695, 46.52447319030762, 48.11332726478577, 49.73143243789673, 51.31732535362244, 52.89702868461609, 54.48620271682739, 56.0632381439209, 57.63196349143982, 59.21552920341492, 60.866384744644165, 62.485734939575195, 64.07506537437439, 65.65161347389221, 67.25285220146179, 68.83470916748047, 70.1460018157959, 71.71427822113037, 73.28918552398682, 74.86753511428833, 76.45328283309937, 78.04075717926025, 79.63119411468506, 81.23153805732727]
[12.133333333333333, 15.816666666666666, 39.86666666666667, 47.05, 45.85, 46.35, 60.38333333333333, 63.28333333333333, 53.916666666666664, 63.18333333333333, 57.75, 52.7, 63.21666666666667, 72.73333333333333, 71.35, 75.78333333333333, 69.11666666666666, 60.516666666666666, 69.71666666666667, 69.45, 69.75, 75.2, 72.0, 79.21666666666667, 72.68333333333334, 75.75, 78.21666666666667, 74.78333333333333, 76.43333333333334, 78.96666666666667, 75.61666666666666, 79.25, 72.35, 74.16666666666667, 76.26666666666667, 80.9, 78.68333333333334, 74.65, 77.06666666666666, 73.1, 75.0, 80.56666666666666, 78.73333333333333, 80.36666666666666, 80.65, 77.98333333333333, 76.65, 77.5, 76.18333333333334, 81.7, 81.75]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
Round   0, Train loss: 1.558, Test loss: 2.252, Test accuracy: 49.77
Round   1, Train loss: 1.291, Test loss: 2.105, Test accuracy: 52.03
Round   2, Train loss: 1.292, Test loss: 1.972, Test accuracy: 68.87
Round   3, Train loss: 1.226, Test loss: 1.867, Test accuracy: 77.38
Round   4, Train loss: 1.205, Test loss: 1.791, Test accuracy: 81.20
Round   5, Train loss: 1.182, Test loss: 1.762, Test accuracy: 81.27
Round   6, Train loss: 1.239, Test loss: 1.735, Test accuracy: 83.25
Round   7, Train loss: 1.154, Test loss: 1.697, Test accuracy: 85.57
Round   8, Train loss: 1.191, Test loss: 1.683, Test accuracy: 86.02
Round   9, Train loss: 1.190, Test loss: 1.663, Test accuracy: 86.63
Round  10, Train loss: 1.109, Test loss: 1.647, Test accuracy: 87.18
Round  11, Train loss: 1.191, Test loss: 1.638, Test accuracy: 87.18
Round  12, Train loss: 1.190, Test loss: 1.636, Test accuracy: 86.97
Round  13, Train loss: 1.184, Test loss: 1.629, Test accuracy: 87.15
Round  14, Train loss: 1.188, Test loss: 1.630, Test accuracy: 87.02
Round  15, Train loss: 1.184, Test loss: 1.627, Test accuracy: 86.98
Round  16, Train loss: 1.145, Test loss: 1.624, Test accuracy: 87.20
Round  17, Train loss: 1.144, Test loss: 1.622, Test accuracy: 87.13
Round  18, Train loss: 1.104, Test loss: 1.620, Test accuracy: 87.17
Round  19, Train loss: 1.143, Test loss: 1.617, Test accuracy: 87.12
Round  20, Train loss: 1.226, Test loss: 1.618, Test accuracy: 87.13
Round  21, Train loss: 1.186, Test loss: 1.618, Test accuracy: 87.25
Round  22, Train loss: 1.141, Test loss: 1.614, Test accuracy: 87.32
Round  23, Train loss: 1.183, Test loss: 1.611, Test accuracy: 87.35
Round  24, Train loss: 1.182, Test loss: 1.612, Test accuracy: 87.40
Round  25, Train loss: 1.226, Test loss: 1.614, Test accuracy: 87.08
Round  26, Train loss: 1.101, Test loss: 1.612, Test accuracy: 87.15
Round  27, Train loss: 1.102, Test loss: 1.612, Test accuracy: 87.25
Round  28, Train loss: 1.101, Test loss: 1.613, Test accuracy: 87.07
Round  29, Train loss: 1.099, Test loss: 1.609, Test accuracy: 87.17
Round  30, Train loss: 1.141, Test loss: 1.610, Test accuracy: 87.13
Round  31, Train loss: 1.142, Test loss: 1.611, Test accuracy: 86.95
Round  32, Train loss: 1.183, Test loss: 1.613, Test accuracy: 86.83
Round  33, Train loss: 1.142, Test loss: 1.612, Test accuracy: 86.87
Round  34, Train loss: 1.141, Test loss: 1.612, Test accuracy: 86.82
Round  35, Train loss: 1.182, Test loss: 1.612, Test accuracy: 86.90
Round  36, Train loss: 1.182, Test loss: 1.612, Test accuracy: 86.73
Round  37, Train loss: 1.140, Test loss: 1.612, Test accuracy: 86.60
Round  38, Train loss: 1.182, Test loss: 1.612, Test accuracy: 86.68
Round  39, Train loss: 1.183, Test loss: 1.613, Test accuracy: 86.67
Round  40, Train loss: 1.223, Test loss: 1.613, Test accuracy: 86.60
Round  41, Train loss: 1.181, Test loss: 1.611, Test accuracy: 86.70
Round  42, Train loss: 1.181, Test loss: 1.611, Test accuracy: 86.68
Round  43, Train loss: 1.182, Test loss: 1.614, Test accuracy: 86.53
Round  44, Train loss: 1.141, Test loss: 1.613, Test accuracy: 86.47
Round  45, Train loss: 1.141, Test loss: 1.613, Test accuracy: 86.33
Round  46, Train loss: 1.140, Test loss: 1.613, Test accuracy: 86.30
Round  47, Train loss: 1.141, Test loss: 1.614, Test accuracy: 86.32
Round  48, Train loss: 1.141, Test loss: 1.615, Test accuracy: 86.18
Round  49, Train loss: 1.138, Test loss: 1.614, Test accuracy: 86.22
Final Round, Train loss: 1.161, Test loss: 1.617, Test accuracy: 86.05
Average accuracy final 10 rounds: 86.43333333333334
494.3425827026367
[]
[49.766666666666666, 52.03333333333333, 68.86666666666666, 77.38333333333334, 81.2, 81.26666666666667, 83.25, 85.56666666666666, 86.01666666666667, 86.63333333333334, 87.18333333333334, 87.18333333333334, 86.96666666666667, 87.15, 87.01666666666667, 86.98333333333333, 87.2, 87.13333333333334, 87.16666666666667, 87.11666666666666, 87.13333333333334, 87.25, 87.31666666666666, 87.35, 87.4, 87.08333333333333, 87.15, 87.25, 87.06666666666666, 87.16666666666667, 87.13333333333334, 86.95, 86.83333333333333, 86.86666666666666, 86.81666666666666, 86.9, 86.73333333333333, 86.6, 86.68333333333334, 86.66666666666667, 86.6, 86.7, 86.68333333333334, 86.53333333333333, 86.46666666666667, 86.33333333333333, 86.3, 86.31666666666666, 86.18333333333334, 86.21666666666667, 86.05]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.289, Test loss: 2.289, Test accuracy: 19.07
Round   0: Global train loss: 2.289, Global test loss: 2.301, Global test accuracy: 8.53
Round   1, Train loss: 2.268, Test loss: 2.274, Test accuracy: 25.50
Round   1: Global train loss: 2.268, Global test loss: 2.301, Global test accuracy: 12.33
Round   2, Train loss: 2.256, Test loss: 2.266, Test accuracy: 22.27
Round   2: Global train loss: 2.256, Global test loss: 2.300, Global test accuracy: 12.33
Round   3, Train loss: 2.187, Test loss: 2.251, Test accuracy: 18.95
Round   3: Global train loss: 2.187, Global test loss: 2.300, Global test accuracy: 13.77
Round   4, Train loss: 2.214, Test loss: 2.241, Test accuracy: 15.80
Round   4: Global train loss: 2.214, Global test loss: 2.300, Global test accuracy: 12.98
Round   5, Train loss: 1.958, Test loss: 2.132, Test accuracy: 32.38
Round   5: Global train loss: 1.958, Global test loss: 2.299, Global test accuracy: 17.50
Round   6, Train loss: 1.894, Test loss: 2.079, Test accuracy: 39.22
Round   6: Global train loss: 1.894, Global test loss: 2.297, Global test accuracy: 21.75
Round   7, Train loss: 1.846, Test loss: 2.082, Test accuracy: 41.08
Round   7: Global train loss: 1.846, Global test loss: 2.297, Global test accuracy: 24.58
Round   8, Train loss: 1.612, Test loss: 2.037, Test accuracy: 43.22
Round   8: Global train loss: 1.612, Global test loss: 2.295, Global test accuracy: 27.40
Round   9, Train loss: 1.734, Test loss: 2.134, Test accuracy: 32.05
Round   9: Global train loss: 1.734, Global test loss: 2.297, Global test accuracy: 29.45
Round  10, Train loss: 1.905, Test loss: 2.169, Test accuracy: 29.10
Round  10: Global train loss: 1.905, Global test loss: 2.298, Global test accuracy: 36.35
Round  11, Train loss: 0.880, Test loss: 2.024, Test accuracy: 43.17
Round  11: Global train loss: 0.880, Global test loss: 2.293, Global test accuracy: 39.67
Round  12, Train loss: 1.377, Test loss: 1.993, Test accuracy: 48.47
Round  12: Global train loss: 1.377, Global test loss: 2.292, Global test accuracy: 40.07
Round  13, Train loss: 1.133, Test loss: 2.002, Test accuracy: 47.72
Round  13: Global train loss: 1.133, Global test loss: 2.292, Global test accuracy: 36.90
Round  14, Train loss: 1.561, Test loss: 2.070, Test accuracy: 42.17
Round  14: Global train loss: 1.561, Global test loss: 2.294, Global test accuracy: 39.83
Round  15, Train loss: 0.882, Test loss: 1.969, Test accuracy: 52.95
Round  15: Global train loss: 0.882, Global test loss: 2.291, Global test accuracy: 40.57
Round  16, Train loss: 0.936, Test loss: 2.047, Test accuracy: 46.30
Round  16: Global train loss: 0.936, Global test loss: 2.292, Global test accuracy: 39.65
Round  17, Train loss: 0.809, Test loss: 2.056, Test accuracy: 44.87
Round  17: Global train loss: 0.809, Global test loss: 2.295, Global test accuracy: 39.33
Round  18, Train loss: 0.798, Test loss: 1.961, Test accuracy: 52.78
Round  18: Global train loss: 0.798, Global test loss: 2.294, Global test accuracy: 38.00
Round  19, Train loss: 0.786, Test loss: 1.956, Test accuracy: 55.57
Round  19: Global train loss: 0.786, Global test loss: 2.295, Global test accuracy: 26.48
Round  20, Train loss: -0.393, Test loss: 1.930, Test accuracy: 55.23
Round  20: Global train loss: -0.393, Global test loss: 2.291, Global test accuracy: 24.85
Round  21, Train loss: 1.047, Test loss: 1.950, Test accuracy: 54.75
Round  21: Global train loss: 1.047, Global test loss: 2.293, Global test accuracy: 24.42
Round  22, Train loss: 0.123, Test loss: 1.856, Test accuracy: 66.38
Round  22: Global train loss: 0.123, Global test loss: 2.288, Global test accuracy: 26.78
Round  23, Train loss: -0.683, Test loss: 1.835, Test accuracy: 66.38
Round  23: Global train loss: -0.683, Global test loss: 2.283, Global test accuracy: 26.67
Round  24, Train loss: -0.481, Test loss: 1.871, Test accuracy: 62.48
Round  24: Global train loss: -0.481, Global test loss: 2.282, Global test accuracy: 26.27
Round  25, Train loss: 0.172, Test loss: 1.873, Test accuracy: 64.03
Round  25: Global train loss: 0.172, Global test loss: 2.284, Global test accuracy: 27.48
Round  26, Train loss: 0.584, Test loss: 2.000, Test accuracy: 51.18
Round  26: Global train loss: 0.584, Global test loss: 2.286, Global test accuracy: 27.15
Round  27, Train loss: 0.589, Test loss: 2.039, Test accuracy: 49.47
Round  27: Global train loss: 0.589, Global test loss: 2.294, Global test accuracy: 25.72
Round  28, Train loss: -0.085, Test loss: 1.881, Test accuracy: 63.57
Round  28: Global train loss: -0.085, Global test loss: 2.288, Global test accuracy: 25.92
Round  29, Train loss: -1.219, Test loss: 1.839, Test accuracy: 67.77
Round  29: Global train loss: -1.219, Global test loss: 2.285, Global test accuracy: 34.33
Round  30, Train loss: 0.000, Test loss: 1.837, Test accuracy: 66.42
Round  30: Global train loss: 0.000, Global test loss: 2.284, Global test accuracy: 30.33
Round  31, Train loss: -1.073, Test loss: 1.823, Test accuracy: 69.48
Round  31: Global train loss: -1.073, Global test loss: 2.278, Global test accuracy: 34.50
Round  32, Train loss: -2.184, Test loss: 1.766, Test accuracy: 70.30
Round  32: Global train loss: -2.184, Global test loss: 2.261, Global test accuracy: 32.53
Round  33, Train loss: 0.196, Test loss: 1.839, Test accuracy: 61.52
Round  33: Global train loss: 0.196, Global test loss: 2.262, Global test accuracy: 29.37
Round  34, Train loss: -0.449, Test loss: 1.826, Test accuracy: 65.12
Round  34: Global train loss: -0.449, Global test loss: 2.255, Global test accuracy: 27.67
Round  35, Train loss: -0.819, Test loss: 1.853, Test accuracy: 62.60
Round  35: Global train loss: -0.819, Global test loss: 2.257, Global test accuracy: 29.80
Round  36, Train loss: -2.013, Test loss: 1.733, Test accuracy: 76.15
Round  36: Global train loss: -2.013, Global test loss: 2.228, Global test accuracy: 29.37
Round  37, Train loss: -1.734, Test loss: 1.695, Test accuracy: 78.60
Round  37: Global train loss: -1.734, Global test loss: 2.203, Global test accuracy: 40.68
Round  38, Train loss: -1.146, Test loss: 1.682, Test accuracy: 79.05
Round  38: Global train loss: -1.146, Global test loss: 2.185, Global test accuracy: 43.50
Round  39, Train loss: 0.273, Test loss: 1.699, Test accuracy: 78.33
Round  39: Global train loss: 0.273, Global test loss: 2.196, Global test accuracy: 43.08
Round  40, Train loss: -1.196, Test loss: 1.659, Test accuracy: 82.45
Round  40: Global train loss: -1.196, Global test loss: 2.196, Global test accuracy: 42.85
Round  41, Train loss: -1.790, Test loss: 1.648, Test accuracy: 83.05
Round  41: Global train loss: -1.790, Global test loss: 2.179, Global test accuracy: 42.70
Round  42, Train loss: -1.185, Test loss: 1.684, Test accuracy: 79.43
Round  42: Global train loss: -1.185, Global test loss: 2.168, Global test accuracy: 44.67
Round  43, Train loss: -1.017, Test loss: 1.682, Test accuracy: 79.02
Round  43: Global train loss: -1.017, Global test loss: 2.151, Global test accuracy: 46.45
Round  44, Train loss: -1.511, Test loss: 1.630, Test accuracy: 85.02
Round  44: Global train loss: -1.511, Global test loss: 2.150, Global test accuracy: 46.58
Round  45, Train loss: -0.362, Test loss: 1.627, Test accuracy: 85.35
Round  45: Global train loss: -0.362, Global test loss: 2.154, Global test accuracy: 44.42
Round  46, Train loss: -0.612, Test loss: 1.655, Test accuracy: 82.33
Round  46: Global train loss: -0.612, Global test loss: 2.163, Global test accuracy: 42.70
Round  47, Train loss: -0.763, Test loss: 1.604, Test accuracy: 86.50
Round  47: Global train loss: -0.763, Global test loss: 2.155, Global test accuracy: 42.52
Round  48, Train loss: -2.785, Test loss: 1.569, Test accuracy: 89.75
Round  48: Global train loss: -2.785, Global test loss: 2.131, Global test accuracy: 43.02
Round  49, Train loss: -1.413, Test loss: 1.569, Test accuracy: 91.22
Round  49: Global train loss: -1.413, Global test loss: 2.123, Global test accuracy: 44.12
Final Round: Train loss: 1.704, Test loss: 1.587, Test accuracy: 89.35
Final Round: Global train loss: 1.704, Global test loss: 2.109, Global test accuracy: 44.32
Average accuracy final 10 rounds: 84.41166666666666
Average global accuracy final 10 rounds: 44.00166666666667
405.9901602268219
[]
[19.066666666666666, 25.5, 22.266666666666666, 18.95, 15.8, 32.38333333333333, 39.21666666666667, 41.083333333333336, 43.21666666666667, 32.05, 29.1, 43.166666666666664, 48.46666666666667, 47.71666666666667, 42.166666666666664, 52.95, 46.3, 44.86666666666667, 52.78333333333333, 55.56666666666667, 55.233333333333334, 54.75, 66.38333333333334, 66.38333333333334, 62.483333333333334, 64.03333333333333, 51.18333333333333, 49.46666666666667, 63.56666666666667, 67.76666666666667, 66.41666666666667, 69.48333333333333, 70.3, 61.516666666666666, 65.11666666666666, 62.6, 76.15, 78.6, 79.05, 78.33333333333333, 82.45, 83.05, 79.43333333333334, 79.01666666666667, 85.01666666666667, 85.35, 82.33333333333333, 86.5, 89.75, 91.21666666666667, 89.35]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.303, Test loss: 2.302, Test accuracy: 14.75 

Round   0, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 14.47 

Round   1, Train loss: 2.300, Test loss: 2.302, Test accuracy: 14.98 

Round   1, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 14.40 

Round   2, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.03 

Round   2, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.47 

Round   3, Train loss: 2.300, Test loss: 2.302, Test accuracy: 15.33 

Round   3, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 14.67 

Round   4, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.52 

Round   4, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.75 

Round   5, Train loss: 2.302, Test loss: 2.302, Test accuracy: 15.60 

Round   5, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.95 

Round   6, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.62 

Round   6, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.73 

Round   7, Train loss: 2.304, Test loss: 2.302, Test accuracy: 15.73 

Round   7, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 15.07 

Round   8, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.85 

Round   8, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.18 

Round   9, Train loss: 2.302, Test loss: 2.302, Test accuracy: 16.02 

Round   9, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.18 

Round  10, Train loss: 2.300, Test loss: 2.302, Test accuracy: 16.03 

Round  10, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 15.28 

Round  11, Train loss: 2.300, Test loss: 2.302, Test accuracy: 16.18 

Round  11, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 15.23 

Round  12, Train loss: 2.300, Test loss: 2.302, Test accuracy: 16.28 

Round  12, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 15.45 

Round  13, Train loss: 2.300, Test loss: 2.302, Test accuracy: 16.35 

Round  13, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 15.22 

Round  14, Train loss: 2.303, Test loss: 2.302, Test accuracy: 16.35 

Round  14, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 15.33 

Round  15, Train loss: 2.302, Test loss: 2.302, Test accuracy: 16.38 

Round  15, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.62 

Round  16, Train loss: 2.302, Test loss: 2.302, Test accuracy: 16.47 

Round  16, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.98 

Round  17, Train loss: 2.303, Test loss: 2.302, Test accuracy: 16.57 

Round  17, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 16.18 

Round  18, Train loss: 2.299, Test loss: 2.302, Test accuracy: 16.57 

Round  18, Global train loss: 2.299, Global test loss: 2.302, Global test accuracy: 16.30 

Round  19, Train loss: 2.300, Test loss: 2.302, Test accuracy: 16.78 

Round  19, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 16.32 

Round  20, Train loss: 2.303, Test loss: 2.302, Test accuracy: 16.85 

Round  20, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 16.42 

Round  21, Train loss: 2.300, Test loss: 2.301, Test accuracy: 16.93 

Round  21, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 16.42 

Round  22, Train loss: 2.301, Test loss: 2.301, Test accuracy: 16.92 

Round  22, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 16.42 

Round  23, Train loss: 2.299, Test loss: 2.301, Test accuracy: 16.98 

Round  23, Global train loss: 2.299, Global test loss: 2.302, Global test accuracy: 16.50 

Round  24, Train loss: 2.301, Test loss: 2.301, Test accuracy: 17.10 

Round  24, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 16.58 

Round  25, Train loss: 2.302, Test loss: 2.301, Test accuracy: 17.18 

Round  25, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 16.53 

Round  26, Train loss: 2.301, Test loss: 2.301, Test accuracy: 17.20 

Round  26, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 16.67 

Round  27, Train loss: 2.303, Test loss: 2.301, Test accuracy: 17.28 

Round  27, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 16.77 

Round  28, Train loss: 2.302, Test loss: 2.301, Test accuracy: 17.42 

Round  28, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 16.92 

Round  29, Train loss: 2.301, Test loss: 2.301, Test accuracy: 17.53 

Round  29, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 17.25 

Round  30, Train loss: 2.302, Test loss: 2.301, Test accuracy: 17.48 

Round  30, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 16.98 

Round  31, Train loss: 2.298, Test loss: 2.301, Test accuracy: 17.65 

Round  31, Global train loss: 2.298, Global test loss: 2.301, Global test accuracy: 17.07 

Round  32, Train loss: 2.303, Test loss: 2.301, Test accuracy: 17.72 

Round  32, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 16.83 

Round  33, Train loss: 2.302, Test loss: 2.301, Test accuracy: 17.70 

Round  33, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 17.00 

Round  34, Train loss: 2.302, Test loss: 2.301, Test accuracy: 17.73 

Round  34, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 17.20 

Round  35, Train loss: 2.302, Test loss: 2.301, Test accuracy: 17.88 

Round  35, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 17.27 

Round  36, Train loss: 2.298, Test loss: 2.301, Test accuracy: 17.95 

Round  36, Global train loss: 2.298, Global test loss: 2.301, Global test accuracy: 17.23 

Round  37, Train loss: 2.303, Test loss: 2.301, Test accuracy: 18.07 

Round  37, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 17.40 

Round  38, Train loss: 2.302, Test loss: 2.301, Test accuracy: 18.03 

Round  38, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 17.47 

Round  39, Train loss: 2.299, Test loss: 2.301, Test accuracy: 18.17 

Round  39, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 17.37 

Round  40, Train loss: 2.304, Test loss: 2.301, Test accuracy: 18.25 

Round  40, Global train loss: 2.304, Global test loss: 2.301, Global test accuracy: 17.58 

Round  41, Train loss: 2.299, Test loss: 2.301, Test accuracy: 18.28 

Round  41, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 17.65 

Round  42, Train loss: 2.300, Test loss: 2.301, Test accuracy: 18.42 

Round  42, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 17.82 

Round  43, Train loss: 2.298, Test loss: 2.301, Test accuracy: 18.53 

Round  43, Global train loss: 2.298, Global test loss: 2.301, Global test accuracy: 17.95 

Round  44, Train loss: 2.300, Test loss: 2.301, Test accuracy: 18.62 

Round  44, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 17.98 

Round  45, Train loss: 2.299, Test loss: 2.301, Test accuracy: 18.78 

Round  45, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 18.33 

Round  46, Train loss: 2.302, Test loss: 2.301, Test accuracy: 19.07 

Round  46, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 18.48 

Round  47, Train loss: 2.301, Test loss: 2.301, Test accuracy: 19.10 

Round  47, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 18.53 

Round  48, Train loss: 2.301, Test loss: 2.301, Test accuracy: 19.12 

Round  48, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 18.55 

Round  49, Train loss: 2.299, Test loss: 2.301, Test accuracy: 19.17 

Round  49, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 18.58 

Final Round, Train loss: 2.300, Test loss: 2.301, Test accuracy: 20.33 

Final Round, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 18.58 

Average accuracy final 10 rounds: 18.733333333333334 

Average global accuracy final 10 rounds: 18.14666666666667 

365.88619565963745
[1.5941455364227295, 2.2265396118164062, 2.8878684043884277, 3.5501201152801514, 4.26164174079895, 4.923544883728027, 5.582866668701172, 6.205371379852295, 6.860135555267334, 7.518477201461792, 8.18414044380188, 8.848408460617065, 9.517005681991577, 10.174573183059692, 10.860435247421265, 11.522406816482544, 12.183013439178467, 12.851351976394653, 13.513995885848999, 14.184178352355957, 14.84853196144104, 15.543087005615234, 16.2164204120636, 16.874738454818726, 17.533753395080566, 18.19502902030945, 18.855117321014404, 19.4555344581604, 20.05350089073181, 20.7020423412323, 21.359748363494873, 22.016916036605835, 22.674639225006104, 23.33550477027893, 24.02116870880127, 24.675139665603638, 25.33923316001892, 26.002572059631348, 26.656264781951904, 27.308391571044922, 27.95618772506714, 28.606769323349, 29.264942169189453, 29.91762924194336, 30.56889247894287, 31.227509260177612, 31.879984140396118, 32.529436111450195, 33.17585563659668, 33.83065700531006, 35.135196685791016]
[14.75, 14.983333333333333, 15.033333333333333, 15.333333333333334, 15.516666666666667, 15.6, 15.616666666666667, 15.733333333333333, 15.85, 16.016666666666666, 16.033333333333335, 16.183333333333334, 16.283333333333335, 16.35, 16.35, 16.383333333333333, 16.466666666666665, 16.566666666666666, 16.566666666666666, 16.783333333333335, 16.85, 16.933333333333334, 16.916666666666668, 16.983333333333334, 17.1, 17.183333333333334, 17.2, 17.283333333333335, 17.416666666666668, 17.533333333333335, 17.483333333333334, 17.65, 17.716666666666665, 17.7, 17.733333333333334, 17.883333333333333, 17.95, 18.066666666666666, 18.033333333333335, 18.166666666666668, 18.25, 18.283333333333335, 18.416666666666668, 18.533333333333335, 18.616666666666667, 18.783333333333335, 19.066666666666666, 19.1, 19.116666666666667, 19.166666666666668, 20.333333333333332]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 1, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.290, Test loss: 2.274, Test accuracy: 36.90 

Round   0, Global train loss: 2.290, Global test loss: 2.276, Global test accuracy: 31.95 

Round   1, Train loss: 2.156, Test loss: 2.103, Test accuracy: 43.12 

Round   1, Global train loss: 2.156, Global test loss: 2.107, Global test accuracy: 33.35 

Round   2, Train loss: 1.827, Test loss: 1.958, Test accuracy: 59.22 

Round   2, Global train loss: 1.827, Global test loss: 2.037, Global test accuracy: 45.50 

Round   3, Train loss: 1.809, Test loss: 1.876, Test accuracy: 62.20 

Round   3, Global train loss: 1.809, Global test loss: 2.070, Global test accuracy: 37.43 

Round   4, Train loss: 1.735, Test loss: 1.769, Test accuracy: 72.58 

Round   4, Global train loss: 1.735, Global test loss: 2.031, Global test accuracy: 43.88 

Round   5, Train loss: 1.668, Test loss: 1.692, Test accuracy: 80.32 

Round   5, Global train loss: 1.668, Global test loss: 2.019, Global test accuracy: 45.60 

Round   6, Train loss: 1.589, Test loss: 1.640, Test accuracy: 85.18 

Round   6, Global train loss: 1.589, Global test loss: 2.020, Global test accuracy: 44.80 

Round   7, Train loss: 1.654, Test loss: 1.601, Test accuracy: 88.17 

Round   7, Global train loss: 1.654, Global test loss: 2.024, Global test accuracy: 42.23 

Round   8, Train loss: 1.553, Test loss: 1.591, Test accuracy: 89.10 

Round   8, Global train loss: 1.553, Global test loss: 1.994, Global test accuracy: 46.52 

Round   9, Train loss: 1.555, Test loss: 1.569, Test accuracy: 91.47 

Round   9, Global train loss: 1.555, Global test loss: 2.011, Global test accuracy: 44.32 

Round  10, Train loss: 1.493, Test loss: 1.561, Test accuracy: 91.90 

Round  10, Global train loss: 1.493, Global test loss: 2.035, Global test accuracy: 41.87 

Round  11, Train loss: 1.488, Test loss: 1.561, Test accuracy: 91.52 

Round  11, Global train loss: 1.488, Global test loss: 2.013, Global test accuracy: 44.92 

Round  12, Train loss: 1.481, Test loss: 1.560, Test accuracy: 91.60 

Round  12, Global train loss: 1.481, Global test loss: 1.995, Global test accuracy: 46.90 

Round  13, Train loss: 1.540, Test loss: 1.545, Test accuracy: 93.05 

Round  13, Global train loss: 1.540, Global test loss: 2.017, Global test accuracy: 44.10 

Round  14, Train loss: 1.478, Test loss: 1.542, Test accuracy: 93.15 

Round  14, Global train loss: 1.478, Global test loss: 2.038, Global test accuracy: 42.05 

Round  15, Train loss: 1.503, Test loss: 1.525, Test accuracy: 94.92 

Round  15, Global train loss: 1.503, Global test loss: 2.017, Global test accuracy: 43.03 

Round  16, Train loss: 1.471, Test loss: 1.524, Test accuracy: 94.88 

Round  16, Global train loss: 1.471, Global test loss: 2.010, Global test accuracy: 45.23 

Round  17, Train loss: 1.470, Test loss: 1.524, Test accuracy: 94.80 

Round  17, Global train loss: 1.470, Global test loss: 1.995, Global test accuracy: 46.93 

Round  18, Train loss: 1.474, Test loss: 1.523, Test accuracy: 94.77 

Round  18, Global train loss: 1.474, Global test loss: 2.038, Global test accuracy: 41.05 

Round  19, Train loss: 1.469, Test loss: 1.522, Test accuracy: 94.85 

Round  19, Global train loss: 1.469, Global test loss: 2.010, Global test accuracy: 45.57 

Round  20, Train loss: 1.474, Test loss: 1.521, Test accuracy: 94.87 

Round  20, Global train loss: 1.474, Global test loss: 2.016, Global test accuracy: 43.05 

Round  21, Train loss: 1.472, Test loss: 1.520, Test accuracy: 94.97 

Round  21, Global train loss: 1.472, Global test loss: 2.025, Global test accuracy: 44.58 

Round  22, Train loss: 1.468, Test loss: 1.520, Test accuracy: 94.97 

Round  22, Global train loss: 1.468, Global test loss: 1.986, Global test accuracy: 48.05 

Round  23, Train loss: 1.468, Test loss: 1.520, Test accuracy: 94.97 

Round  23, Global train loss: 1.468, Global test loss: 2.003, Global test accuracy: 45.72 

Round  24, Train loss: 1.474, Test loss: 1.518, Test accuracy: 95.03 

Round  24, Global train loss: 1.474, Global test loss: 2.018, Global test accuracy: 42.23 

Round  25, Train loss: 1.470, Test loss: 1.517, Test accuracy: 95.05 

Round  25, Global train loss: 1.470, Global test loss: 2.017, Global test accuracy: 43.13 

Round  26, Train loss: 1.470, Test loss: 1.517, Test accuracy: 94.97 

Round  26, Global train loss: 1.470, Global test loss: 2.038, Global test accuracy: 41.27 

Round  27, Train loss: 1.469, Test loss: 1.517, Test accuracy: 94.97 

Round  27, Global train loss: 1.469, Global test loss: 2.034, Global test accuracy: 41.10 

Round  28, Train loss: 1.471, Test loss: 1.517, Test accuracy: 95.02 

Round  28, Global train loss: 1.471, Global test loss: 2.017, Global test accuracy: 43.38 

Round  29, Train loss: 1.469, Test loss: 1.517, Test accuracy: 94.95 

Round  29, Global train loss: 1.469, Global test loss: 2.027, Global test accuracy: 42.33 

Round  30, Train loss: 1.467, Test loss: 1.516, Test accuracy: 94.95 

Round  30, Global train loss: 1.467, Global test loss: 2.033, Global test accuracy: 41.32 

Round  31, Train loss: 1.469, Test loss: 1.516, Test accuracy: 94.97 

Round  31, Global train loss: 1.469, Global test loss: 2.010, Global test accuracy: 44.78 

Round  32, Train loss: 1.466, Test loss: 1.516, Test accuracy: 94.97 

Round  32, Global train loss: 1.466, Global test loss: 2.033, Global test accuracy: 40.73 

Round  33, Train loss: 1.467, Test loss: 1.516, Test accuracy: 95.05 

Round  33, Global train loss: 1.467, Global test loss: 2.038, Global test accuracy: 41.93 

Round  34, Train loss: 1.466, Test loss: 1.516, Test accuracy: 95.10 

Round  34, Global train loss: 1.466, Global test loss: 2.021, Global test accuracy: 43.78 

Round  35, Train loss: 1.465, Test loss: 1.516, Test accuracy: 95.17 

Round  35, Global train loss: 1.465, Global test loss: 2.017, Global test accuracy: 43.62 

Round  36, Train loss: 1.464, Test loss: 1.515, Test accuracy: 95.18 

Round  36, Global train loss: 1.464, Global test loss: 2.006, Global test accuracy: 44.53 

Round  37, Train loss: 1.466, Test loss: 1.515, Test accuracy: 95.18 

Round  37, Global train loss: 1.466, Global test loss: 2.000, Global test accuracy: 45.88 

Round  38, Train loss: 1.466, Test loss: 1.515, Test accuracy: 95.15 

Round  38, Global train loss: 1.466, Global test loss: 2.007, Global test accuracy: 44.18 

Round  39, Train loss: 1.466, Test loss: 1.515, Test accuracy: 95.15 

Round  39, Global train loss: 1.466, Global test loss: 1.995, Global test accuracy: 46.48 

Round  40, Train loss: 1.466, Test loss: 1.515, Test accuracy: 95.17 

Round  40, Global train loss: 1.466, Global test loss: 2.027, Global test accuracy: 41.62 

Round  41, Train loss: 1.466, Test loss: 1.515, Test accuracy: 95.15 

Round  41, Global train loss: 1.466, Global test loss: 2.001, Global test accuracy: 45.22 

Round  42, Train loss: 1.465, Test loss: 1.515, Test accuracy: 95.12 

Round  42, Global train loss: 1.465, Global test loss: 2.001, Global test accuracy: 45.30 

Round  43, Train loss: 1.466, Test loss: 1.515, Test accuracy: 95.13 

Round  43, Global train loss: 1.466, Global test loss: 2.003, Global test accuracy: 45.08 

Round  44, Train loss: 1.465, Test loss: 1.515, Test accuracy: 95.13 

Round  44, Global train loss: 1.465, Global test loss: 1.988, Global test accuracy: 47.48 

Round  45, Train loss: 1.468, Test loss: 1.515, Test accuracy: 95.13 

Round  45, Global train loss: 1.468, Global test loss: 2.038, Global test accuracy: 42.03 

Round  46, Train loss: 1.466, Test loss: 1.515, Test accuracy: 95.15 

Round  46, Global train loss: 1.466, Global test loss: 1.972, Global test accuracy: 49.13 

Round  47, Train loss: 1.465, Test loss: 1.514, Test accuracy: 95.13 

Round  47, Global train loss: 1.465, Global test loss: 2.016, Global test accuracy: 43.75 

Round  48, Train loss: 1.466, Test loss: 1.514, Test accuracy: 95.13 

Round  48, Global train loss: 1.466, Global test loss: 2.014, Global test accuracy: 42.18 

Round  49, Train loss: 1.467, Test loss: 1.514, Test accuracy: 95.15 

Round  49, Global train loss: 1.467, Global test loss: 2.026, Global test accuracy: 42.23 

Final Round, Train loss: 1.466, Test loss: 1.514, Test accuracy: 95.17 

Final Round, Global train loss: 1.466, Global test loss: 2.026, Global test accuracy: 42.23 

Average accuracy final 10 rounds: 95.14 

Average global accuracy final 10 rounds: 44.403333333333336 

355.03163385391235
[1.502030849456787, 2.14463472366333, 2.7698135375976562, 3.3986332416534424, 4.050374746322632, 4.678110599517822, 5.316789865493774, 5.937600135803223, 6.560722589492798, 7.181124448776245, 7.8052942752838135, 8.42719841003418, 9.04890751838684, 9.675204277038574, 10.296558380126953, 10.944460153579712, 11.56625771522522, 12.190765142440796, 12.812406063079834, 13.4729163646698, 14.103885650634766, 14.731770277023315, 15.354778528213501, 15.9798002243042, 16.47190499305725, 16.96490168571472, 17.455032110214233, 17.94645667076111, 18.44723629951477, 18.950202226638794, 19.455242395401, 20.088755130767822, 20.725069284439087, 21.34681272506714, 21.97473454475403, 22.597681522369385, 23.25269913673401, 23.904202938079834, 24.537895917892456, 25.165125370025635, 25.790359497070312, 26.409459829330444, 27.0333411693573, 27.650375843048096, 28.273332834243774, 28.895958423614502, 29.523165702819824, 30.14949131011963, 30.770687580108643, 31.39242386817932, 32.677316665649414]
[36.9, 43.11666666666667, 59.21666666666667, 62.2, 72.58333333333333, 80.31666666666666, 85.18333333333334, 88.16666666666667, 89.1, 91.46666666666667, 91.9, 91.51666666666667, 91.6, 93.05, 93.15, 94.91666666666667, 94.88333333333334, 94.8, 94.76666666666667, 94.85, 94.86666666666666, 94.96666666666667, 94.96666666666667, 94.96666666666667, 95.03333333333333, 95.05, 94.96666666666667, 94.96666666666667, 95.01666666666667, 94.95, 94.95, 94.96666666666667, 94.96666666666667, 95.05, 95.1, 95.16666666666667, 95.18333333333334, 95.18333333333334, 95.15, 95.15, 95.16666666666667, 95.15, 95.11666666666666, 95.13333333333334, 95.13333333333334, 95.13333333333334, 95.15, 95.13333333333334, 95.13333333333334, 95.15, 95.16666666666667]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.290, Test loss: 2.273, Test accuracy: 39.77 

Round   0, Global train loss: 2.290, Global test loss: 2.275, Global test accuracy: 34.12 

Round   1, Train loss: 2.165, Test loss: 2.112, Test accuracy: 43.15 

Round   1, Global train loss: 2.165, Global test loss: 2.109, Global test accuracy: 33.53 

Round   2, Train loss: 1.911, Test loss: 1.983, Test accuracy: 58.58 

Round   2, Global train loss: 1.911, Global test loss: 2.031, Global test accuracy: 43.58 

Round   3, Train loss: 1.761, Test loss: 1.890, Test accuracy: 66.25 

Round   3, Global train loss: 1.761, Global test loss: 1.992, Global test accuracy: 47.08 

Round   4, Train loss: 1.686, Test loss: 1.807, Test accuracy: 74.40 

Round   4, Global train loss: 1.686, Global test loss: 1.993, Global test accuracy: 45.92 

Round   5, Train loss: 1.770, Test loss: 1.740, Test accuracy: 79.47 

Round   5, Global train loss: 1.770, Global test loss: 1.980, Global test accuracy: 49.03 

Round   6, Train loss: 1.642, Test loss: 1.700, Test accuracy: 81.05 

Round   6, Global train loss: 1.642, Global test loss: 1.978, Global test accuracy: 48.35 

Round   7, Train loss: 1.606, Test loss: 1.694, Test accuracy: 80.57 

Round   7, Global train loss: 1.606, Global test loss: 1.996, Global test accuracy: 45.73 

Round   8, Train loss: 1.734, Test loss: 1.662, Test accuracy: 81.70 

Round   8, Global train loss: 1.734, Global test loss: 1.978, Global test accuracy: 47.98 

Round   9, Train loss: 1.752, Test loss: 1.636, Test accuracy: 84.03 

Round   9, Global train loss: 1.752, Global test loss: 1.974, Global test accuracy: 48.43 

Round  10, Train loss: 1.685, Test loss: 1.636, Test accuracy: 83.95 

Round  10, Global train loss: 1.685, Global test loss: 1.969, Global test accuracy: 49.17 

Round  11, Train loss: 1.718, Test loss: 1.647, Test accuracy: 82.72 

Round  11, Global train loss: 1.718, Global test loss: 2.013, Global test accuracy: 43.88 

Round  12, Train loss: 1.658, Test loss: 1.660, Test accuracy: 81.48 

Round  12, Global train loss: 1.658, Global test loss: 1.994, Global test accuracy: 46.07 

Round  13, Train loss: 1.680, Test loss: 1.657, Test accuracy: 81.53 

Round  13, Global train loss: 1.680, Global test loss: 1.962, Global test accuracy: 49.88 

Round  14, Train loss: 1.632, Test loss: 1.668, Test accuracy: 80.15 

Round  14, Global train loss: 1.632, Global test loss: 1.967, Global test accuracy: 49.37 

Round  15, Train loss: 1.617, Test loss: 1.677, Test accuracy: 79.08 

Round  15, Global train loss: 1.617, Global test loss: 1.967, Global test accuracy: 48.93 

Round  16, Train loss: 1.596, Test loss: 1.679, Test accuracy: 78.70 

Round  16, Global train loss: 1.596, Global test loss: 1.962, Global test accuracy: 49.33 

Round  17, Train loss: 1.598, Test loss: 1.673, Test accuracy: 79.37 

Round  17, Global train loss: 1.598, Global test loss: 1.971, Global test accuracy: 48.13 

Round  18, Train loss: 1.625, Test loss: 1.671, Test accuracy: 79.45 

Round  18, Global train loss: 1.625, Global test loss: 1.957, Global test accuracy: 50.45 

Round  19, Train loss: 1.607, Test loss: 1.670, Test accuracy: 79.50 

Round  19, Global train loss: 1.607, Global test loss: 1.988, Global test accuracy: 46.70 

Round  20, Train loss: 1.611, Test loss: 1.656, Test accuracy: 80.85 

Round  20, Global train loss: 1.611, Global test loss: 1.980, Global test accuracy: 47.75 

Round  21, Train loss: 1.586, Test loss: 1.657, Test accuracy: 80.73 

Round  21, Global train loss: 1.586, Global test loss: 1.964, Global test accuracy: 49.38 

Round  22, Train loss: 1.584, Test loss: 1.646, Test accuracy: 81.90 

Round  22, Global train loss: 1.584, Global test loss: 1.989, Global test accuracy: 46.28 

Round  23, Train loss: 1.560, Test loss: 1.627, Test accuracy: 83.80 

Round  23, Global train loss: 1.560, Global test loss: 1.993, Global test accuracy: 45.78 

Round  24, Train loss: 1.522, Test loss: 1.612, Test accuracy: 85.33 

Round  24, Global train loss: 1.522, Global test loss: 1.964, Global test accuracy: 49.53 

Round  25, Train loss: 1.619, Test loss: 1.626, Test accuracy: 83.98 

Round  25, Global train loss: 1.619, Global test loss: 2.003, Global test accuracy: 44.92 

Round  26, Train loss: 1.728, Test loss: 1.617, Test accuracy: 84.70 

Round  26, Global train loss: 1.728, Global test loss: 1.973, Global test accuracy: 47.98 

Round  27, Train loss: 1.718, Test loss: 1.618, Test accuracy: 84.70 

Round  27, Global train loss: 1.718, Global test loss: 1.965, Global test accuracy: 49.23 

Round  28, Train loss: 1.592, Test loss: 1.603, Test accuracy: 86.13 

Round  28, Global train loss: 1.592, Global test loss: 1.968, Global test accuracy: 48.45 

Round  29, Train loss: 1.731, Test loss: 1.617, Test accuracy: 84.75 

Round  29, Global train loss: 1.731, Global test loss: 1.995, Global test accuracy: 45.70 

Round  30, Train loss: 1.547, Test loss: 1.603, Test accuracy: 86.15 

Round  30, Global train loss: 1.547, Global test loss: 1.983, Global test accuracy: 47.25 

Round  31, Train loss: 1.617, Test loss: 1.596, Test accuracy: 86.70 

Round  31, Global train loss: 1.617, Global test loss: 1.978, Global test accuracy: 47.10 

Round  32, Train loss: 1.508, Test loss: 1.595, Test accuracy: 86.93 

Round  32, Global train loss: 1.508, Global test loss: 1.946, Global test accuracy: 51.15 

Round  33, Train loss: 1.563, Test loss: 1.605, Test accuracy: 85.97 

Round  33, Global train loss: 1.563, Global test loss: 1.984, Global test accuracy: 46.90 

Round  34, Train loss: 1.577, Test loss: 1.603, Test accuracy: 86.12 

Round  34, Global train loss: 1.577, Global test loss: 1.965, Global test accuracy: 49.33 

Round  35, Train loss: 1.507, Test loss: 1.601, Test accuracy: 86.35 

Round  35, Global train loss: 1.507, Global test loss: 1.969, Global test accuracy: 48.65 

Round  36, Train loss: 1.546, Test loss: 1.600, Test accuracy: 86.52 

Round  36, Global train loss: 1.546, Global test loss: 1.961, Global test accuracy: 49.67 

Round  37, Train loss: 1.540, Test loss: 1.586, Test accuracy: 87.85 

Round  37, Global train loss: 1.540, Global test loss: 1.968, Global test accuracy: 48.48 

Round  38, Train loss: 1.486, Test loss: 1.586, Test accuracy: 87.85 

Round  38, Global train loss: 1.486, Global test loss: 1.974, Global test accuracy: 48.13 

Round  39, Train loss: 1.637, Test loss: 1.601, Test accuracy: 86.30 

Round  39, Global train loss: 1.637, Global test loss: 1.959, Global test accuracy: 49.92 

Round  40, Train loss: 1.561, Test loss: 1.586, Test accuracy: 87.82 

Round  40, Global train loss: 1.561, Global test loss: 1.952, Global test accuracy: 50.67 

Round  41, Train loss: 1.604, Test loss: 1.578, Test accuracy: 88.73 

Round  41, Global train loss: 1.604, Global test loss: 1.962, Global test accuracy: 49.42 

Round  42, Train loss: 1.581, Test loss: 1.571, Test accuracy: 89.37 

Round  42, Global train loss: 1.581, Global test loss: 1.977, Global test accuracy: 47.65 

Round  43, Train loss: 1.540, Test loss: 1.571, Test accuracy: 89.35 

Round  43, Global train loss: 1.540, Global test loss: 1.950, Global test accuracy: 50.53 

Round  44, Train loss: 1.486, Test loss: 1.571, Test accuracy: 89.37 

Round  44, Global train loss: 1.486, Global test loss: 1.940, Global test accuracy: 52.02 

Round  45, Train loss: 1.544, Test loss: 1.571, Test accuracy: 89.30 

Round  45, Global train loss: 1.544, Global test loss: 1.938, Global test accuracy: 51.88 

Round  46, Train loss: 1.509, Test loss: 1.573, Test accuracy: 89.08 

Round  46, Global train loss: 1.509, Global test loss: 1.938, Global test accuracy: 51.58 

Round  47, Train loss: 1.486, Test loss: 1.573, Test accuracy: 89.18 

Round  47, Global train loss: 1.486, Global test loss: 1.948, Global test accuracy: 50.53 

Round  48, Train loss: 1.580, Test loss: 1.569, Test accuracy: 89.70 

Round  48, Global train loss: 1.580, Global test loss: 1.973, Global test accuracy: 48.25 

Round  49, Train loss: 1.557, Test loss: 1.584, Test accuracy: 88.17 

Round  49, Global train loss: 1.557, Global test loss: 1.957, Global test accuracy: 49.93 

Final Round, Train loss: 1.546, Test loss: 1.567, Test accuracy: 89.73 

Final Round, Global train loss: 1.546, Global test loss: 1.957, Global test accuracy: 49.93 

Average accuracy final 10 rounds: 89.00666666666666 

Average global accuracy final 10 rounds: 50.24666666666667 

349.64866757392883
[1.509227991104126, 2.1115596294403076, 2.7174007892608643, 3.3223800659179688, 3.9285361766815186, 4.532715797424316, 5.1397294998168945, 5.749411344528198, 6.3638224601745605, 6.989173889160156, 7.595149040222168, 8.19574785232544, 8.798711776733398, 9.40786623954773, 10.012375593185425, 10.614461421966553, 11.224870920181274, 11.831530332565308, 12.449764966964722, 13.055433511734009, 13.666826725006104, 14.293875694274902, 14.903509378433228, 15.50814962387085, 16.109217643737793, 16.711453914642334, 17.311902284622192, 17.922813653945923, 18.524774312973022, 19.160969495773315, 19.76545524597168, 20.37027406692505, 20.97514820098877, 21.577003002166748, 22.179863214492798, 22.78324580192566, 23.3848934173584, 23.989720344543457, 24.59859323501587, 25.20577907562256, 25.808408737182617, 26.376275777816772, 26.941677570343018, 27.503307580947876, 28.10447072982788, 28.705060958862305, 29.306602239608765, 29.907615184783936, 30.50595498085022, 31.107325553894043, 32.31991457939148]
[39.766666666666666, 43.15, 58.583333333333336, 66.25, 74.4, 79.46666666666667, 81.05, 80.56666666666666, 81.7, 84.03333333333333, 83.95, 82.71666666666667, 81.48333333333333, 81.53333333333333, 80.15, 79.08333333333333, 78.7, 79.36666666666666, 79.45, 79.5, 80.85, 80.73333333333333, 81.9, 83.8, 85.33333333333333, 83.98333333333333, 84.7, 84.7, 86.13333333333334, 84.75, 86.15, 86.7, 86.93333333333334, 85.96666666666667, 86.11666666666666, 86.35, 86.51666666666667, 87.85, 87.85, 86.3, 87.81666666666666, 88.73333333333333, 89.36666666666666, 89.35, 89.36666666666666, 89.3, 89.08333333333333, 89.18333333333334, 89.7, 88.16666666666667, 89.73333333333333]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.299, Test loss: 2.294, Test accuracy: 34.00 

Round   1, Train loss: 2.285, Test loss: 2.275, Test accuracy: 34.38 

Round   2, Train loss: 2.250, Test loss: 2.209, Test accuracy: 31.88 

Round   3, Train loss: 2.122, Test loss: 2.127, Test accuracy: 28.75 

Round   4, Train loss: 2.072, Test loss: 2.098, Test accuracy: 37.47 

Round   5, Train loss: 2.008, Test loss: 2.045, Test accuracy: 43.80 

Round   6, Train loss: 1.935, Test loss: 1.988, Test accuracy: 52.33 

Round   7, Train loss: 1.792, Test loss: 1.940, Test accuracy: 55.78 

Round   8, Train loss: 1.922, Test loss: 1.928, Test accuracy: 55.38 

Round   9, Train loss: 1.714, Test loss: 1.889, Test accuracy: 59.37 

Round  10, Train loss: 1.823, Test loss: 1.868, Test accuracy: 61.83 

Round  11, Train loss: 1.818, Test loss: 1.850, Test accuracy: 63.80 

Round  12, Train loss: 1.814, Test loss: 1.834, Test accuracy: 65.57 

Round  13, Train loss: 1.858, Test loss: 1.828, Test accuracy: 65.78 

Round  14, Train loss: 1.670, Test loss: 1.816, Test accuracy: 66.50 

Round  15, Train loss: 1.732, Test loss: 1.810, Test accuracy: 66.88 

Round  16, Train loss: 1.835, Test loss: 1.808, Test accuracy: 66.87 

Round  17, Train loss: 1.729, Test loss: 1.795, Test accuracy: 67.47 

Round  18, Train loss: 1.796, Test loss: 1.787, Test accuracy: 68.57 

Round  19, Train loss: 1.810, Test loss: 1.787, Test accuracy: 68.57 

Round  20, Train loss: 1.721, Test loss: 1.783, Test accuracy: 68.92 

Round  21, Train loss: 1.806, Test loss: 1.784, Test accuracy: 68.42 

Round  22, Train loss: 1.667, Test loss: 1.780, Test accuracy: 68.77 

Round  23, Train loss: 1.728, Test loss: 1.769, Test accuracy: 69.75 

Round  24, Train loss: 1.757, Test loss: 1.769, Test accuracy: 70.37 

Round  25, Train loss: 1.625, Test loss: 1.749, Test accuracy: 72.28 

Round  26, Train loss: 1.764, Test loss: 1.749, Test accuracy: 72.30 

Round  27, Train loss: 1.710, Test loss: 1.745, Test accuracy: 72.37 

Round  28, Train loss: 1.672, Test loss: 1.745, Test accuracy: 72.25 

Round  29, Train loss: 1.656, Test loss: 1.748, Test accuracy: 72.10 

Round  30, Train loss: 1.766, Test loss: 1.745, Test accuracy: 72.25 

Round  31, Train loss: 1.741, Test loss: 1.743, Test accuracy: 72.33 

Round  32, Train loss: 1.756, Test loss: 1.750, Test accuracy: 71.50 

Round  33, Train loss: 1.713, Test loss: 1.748, Test accuracy: 71.70 

Round  34, Train loss: 1.766, Test loss: 1.745, Test accuracy: 72.18 

Round  35, Train loss: 1.753, Test loss: 1.751, Test accuracy: 71.40 

Round  36, Train loss: 1.761, Test loss: 1.749, Test accuracy: 71.48 

Round  37, Train loss: 1.628, Test loss: 1.746, Test accuracy: 71.85 

Round  38, Train loss: 1.674, Test loss: 1.745, Test accuracy: 71.80 

Round  39, Train loss: 1.675, Test loss: 1.739, Test accuracy: 72.47 

Round  40, Train loss: 1.624, Test loss: 1.737, Test accuracy: 72.83 

Round  41, Train loss: 1.709, Test loss: 1.736, Test accuracy: 72.90 

Round  42, Train loss: 1.605, Test loss: 1.735, Test accuracy: 73.03 

Round  43, Train loss: 1.697, Test loss: 1.736, Test accuracy: 72.73 

Round  44, Train loss: 1.701, Test loss: 1.737, Test accuracy: 72.62 

Round  45, Train loss: 1.650, Test loss: 1.737, Test accuracy: 72.55 

Round  46, Train loss: 1.693, Test loss: 1.729, Test accuracy: 73.63 

Round  47, Train loss: 1.700, Test loss: 1.716, Test accuracy: 74.98 

Round  48, Train loss: 1.633, Test loss: 1.712, Test accuracy: 75.22 

Round  49, Train loss: 1.669, Test loss: 1.712, Test accuracy: 75.22 

Final Round, Train loss: 1.672, Test loss: 1.704, Test accuracy: 76.32 

Average accuracy final 10 rounds: 73.57166666666666 

256.87538838386536
[1.4524998664855957, 2.018625497817993, 2.569427967071533, 3.1142709255218506, 3.6651368141174316, 4.21737003326416, 4.765544891357422, 5.30817437171936, 5.859403610229492, 6.406509637832642, 6.951468229293823, 7.496236324310303, 8.060473918914795, 8.604933738708496, 9.14734935760498, 9.692553997039795, 10.238404750823975, 10.78315806388855, 11.328173398971558, 11.875414609909058, 12.422868967056274, 12.969793558120728, 13.514932870864868, 14.068025827407837, 14.611091613769531, 15.155705451965332, 15.702693223953247, 16.254924774169922, 16.779869079589844, 17.326019525527954, 17.873658418655396, 18.430180072784424, 18.971000909805298, 19.54221224784851, 20.08507990837097, 20.62309741973877, 21.165241956710815, 21.71073055267334, 22.278008460998535, 22.822973012924194, 23.364744901657104, 23.91097640991211, 24.460015535354614, 25.021888256072998, 25.568007946014404, 26.11805295944214, 26.664023399353027, 27.208892107009888, 27.757172107696533, 28.3136203289032, 29.274925708770752]
[34.0, 34.38333333333333, 31.883333333333333, 28.75, 37.46666666666667, 43.8, 52.333333333333336, 55.78333333333333, 55.38333333333333, 59.36666666666667, 61.833333333333336, 63.8, 65.56666666666666, 65.78333333333333, 66.5, 66.88333333333334, 66.86666666666666, 67.46666666666667, 68.56666666666666, 68.56666666666666, 68.91666666666667, 68.41666666666667, 68.76666666666667, 69.75, 70.36666666666666, 72.28333333333333, 72.3, 72.36666666666666, 72.25, 72.1, 72.25, 72.33333333333333, 71.5, 71.7, 72.18333333333334, 71.4, 71.48333333333333, 71.85, 71.8, 72.46666666666667, 72.83333333333333, 72.9, 73.03333333333333, 72.73333333333333, 72.61666666666666, 72.55, 73.63333333333334, 74.98333333333333, 75.21666666666667, 75.21666666666667, 76.31666666666666]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
401408
401920
532992
533248
549632
549696
550336
550346
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Traceback (most recent call last):
  File "main_fedpac_k_means.py", line 291, in <module>
    w_local, loss, indd, class_center_local, class_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_grob_local, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 1492, in train
    sub_clc = self.features - torch.from_numpy(class_center_batch)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
Round   0, Train loss: 2.291, Test loss: 2.268, Test accuracy: 33.33
Round   1, Train loss: 2.203, Test loss: 2.109, Test accuracy: 33.33
Round   2, Train loss: 2.008, Test loss: 2.041, Test accuracy: 46.12
Round   3, Train loss: 1.813, Test loss: 1.994, Test accuracy: 47.22
Round   4, Train loss: 1.723, Test loss: 1.985, Test accuracy: 47.72
Round   5, Train loss: 1.796, Test loss: 1.995, Test accuracy: 46.20
Round   6, Train loss: 1.598, Test loss: 2.001, Test accuracy: 45.10
Round   7, Train loss: 1.717, Test loss: 2.003, Test accuracy: 45.42
Round   8, Train loss: 1.588, Test loss: 1.984, Test accuracy: 47.32
Round   9, Train loss: 1.582, Test loss: 1.976, Test accuracy: 48.32
Round  10, Train loss: 1.615, Test loss: 1.997, Test accuracy: 45.98
Round  11, Train loss: 1.584, Test loss: 1.997, Test accuracy: 46.00
Round  12, Train loss: 1.551, Test loss: 2.027, Test accuracy: 43.38
Round  13, Train loss: 1.571, Test loss: 1.973, Test accuracy: 48.35
Round  14, Train loss: 1.555, Test loss: 1.995, Test accuracy: 46.05
Round  15, Train loss: 1.555, Test loss: 1.970, Test accuracy: 48.78
Round  16, Train loss: 1.560, Test loss: 1.974, Test accuracy: 48.12
Round  17, Train loss: 1.492, Test loss: 1.990, Test accuracy: 46.48
Round  18, Train loss: 1.547, Test loss: 1.968, Test accuracy: 49.25
Round  19, Train loss: 1.503, Test loss: 1.966, Test accuracy: 49.15
Round  20, Train loss: 1.500, Test loss: 1.973, Test accuracy: 48.33
Round  21, Train loss: 1.541, Test loss: 1.961, Test accuracy: 49.93
Round  22, Train loss: 1.494, Test loss: 1.965, Test accuracy: 49.52
Round  23, Train loss: 1.485, Test loss: 1.976, Test accuracy: 47.90
Round  24, Train loss: 1.483, Test loss: 1.970, Test accuracy: 48.57
Round  25, Train loss: 1.486, Test loss: 1.955, Test accuracy: 50.38
Round  26, Train loss: 1.483, Test loss: 1.982, Test accuracy: 47.48
Round  27, Train loss: 1.487, Test loss: 1.986, Test accuracy: 46.77
Round  28, Train loss: 1.483, Test loss: 1.953, Test accuracy: 50.67
Round  29, Train loss: 1.483, Test loss: 1.964, Test accuracy: 49.08
Round  30, Train loss: 1.480, Test loss: 1.978, Test accuracy: 47.78
Round  31, Train loss: 1.542, Test loss: 1.969, Test accuracy: 48.85
Round  32, Train loss: 1.476, Test loss: 1.971, Test accuracy: 48.40
Round  33, Train loss: 1.535, Test loss: 1.978, Test accuracy: 48.05
Round  34, Train loss: 1.487, Test loss: 1.993, Test accuracy: 46.33
Round  35, Train loss: 1.492, Test loss: 1.963, Test accuracy: 49.37
Round  36, Train loss: 1.477, Test loss: 1.963, Test accuracy: 49.12
Round  37, Train loss: 1.540, Test loss: 1.976, Test accuracy: 48.12
Round  38, Train loss: 1.532, Test loss: 1.971, Test accuracy: 48.45
Round  39, Train loss: 1.532, Test loss: 1.990, Test accuracy: 46.43
Round  40, Train loss: 1.476, Test loss: 1.976, Test accuracy: 47.95
Round  41, Train loss: 1.481, Test loss: 1.958, Test accuracy: 50.03
Round  42, Train loss: 1.480, Test loss: 1.959, Test accuracy: 49.53
Round  43, Train loss: 1.472, Test loss: 1.965, Test accuracy: 48.95
Round  44, Train loss: 1.485, Test loss: 1.969, Test accuracy: 49.05
Round  45, Train loss: 1.473, Test loss: 1.994, Test accuracy: 45.92
Round  46, Train loss: 1.475, Test loss: 1.967, Test accuracy: 48.70
Round  47, Train loss: 1.474, Test loss: 1.976, Test accuracy: 47.67
Round  48, Train loss: 1.476, Test loss: 1.945, Test accuracy: 51.42
Round  49, Train loss: 1.476, Test loss: 1.941, Test accuracy: 51.77
Final Round, Train loss: 1.491, Test loss: 1.938, Test accuracy: 52.13
Average accuracy final 10 rounds: 49.09833333333333
567.5904386043549
[2.492072105407715, 4.070265293121338, 5.646525859832764, 7.238588094711304, 8.733085632324219, 10.219017267227173, 11.721318483352661, 13.211654663085938, 14.708687782287598, 16.191458463668823, 17.682154655456543, 19.245954513549805, 20.80888056755066, 22.374403715133667, 23.952502727508545, 25.53177809715271, 27.164385318756104, 28.74783730506897, 30.334681034088135, 31.934783935546875, 33.52086544036865, 35.12599849700928, 36.72802424430847, 38.25576567649841, 39.8483567237854, 41.45223140716553, 43.097837924957275, 44.6827974319458, 46.25963759422302, 47.83907341957092, 49.410789489746094, 50.990848779678345, 52.588074922561646, 54.16940903663635, 55.75523090362549, 57.33581304550171, 58.92667055130005, 60.50381922721863, 62.1163535118103, 63.70858979225159, 65.30994915962219, 66.89064860343933, 68.49814891815186, 70.08436703681946, 71.66270017623901, 73.32606291770935, 74.92431616783142, 76.53650546073914, 78.10217475891113, 79.61435008049011, 81.11087250709534]
[33.333333333333336, 33.333333333333336, 46.11666666666667, 47.21666666666667, 47.71666666666667, 46.2, 45.1, 45.416666666666664, 47.31666666666667, 48.31666666666667, 45.983333333333334, 46.0, 43.38333333333333, 48.35, 46.05, 48.78333333333333, 48.11666666666667, 46.483333333333334, 49.25, 49.15, 48.333333333333336, 49.93333333333333, 49.516666666666666, 47.9, 48.56666666666667, 50.38333333333333, 47.483333333333334, 46.766666666666666, 50.666666666666664, 49.083333333333336, 47.78333333333333, 48.85, 48.4, 48.05, 46.333333333333336, 49.36666666666667, 49.11666666666667, 48.11666666666667, 48.45, 46.43333333333333, 47.95, 50.03333333333333, 49.53333333333333, 48.95, 49.05, 45.916666666666664, 48.7, 47.666666666666664, 51.416666666666664, 51.766666666666666, 52.13333333333333]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
Round   0, Train loss: 1.560, Test loss: 2.202, Test accuracy: 46.27
Round   1, Train loss: 1.293, Test loss: 2.011, Test accuracy: 58.35
Round   2, Train loss: 1.354, Test loss: 1.934, Test accuracy: 65.07
Round   3, Train loss: 1.194, Test loss: 1.864, Test accuracy: 71.88
Round   4, Train loss: 1.218, Test loss: 1.815, Test accuracy: 74.98
Round   5, Train loss: 1.210, Test loss: 1.790, Test accuracy: 76.00
Round   6, Train loss: 1.187, Test loss: 1.755, Test accuracy: 79.50
Round   7, Train loss: 1.153, Test loss: 1.739, Test accuracy: 80.65
Round   8, Train loss: 1.149, Test loss: 1.722, Test accuracy: 81.35
Round   9, Train loss: 1.141, Test loss: 1.700, Test accuracy: 83.17
Round  10, Train loss: 1.194, Test loss: 1.684, Test accuracy: 84.18
Round  11, Train loss: 1.156, Test loss: 1.661, Test accuracy: 85.93
Round  12, Train loss: 1.170, Test loss: 1.646, Test accuracy: 86.85
Round  13, Train loss: 1.147, Test loss: 1.631, Test accuracy: 88.23
Round  14, Train loss: 1.151, Test loss: 1.619, Test accuracy: 88.88
Round  15, Train loss: 1.144, Test loss: 1.614, Test accuracy: 89.08
Round  16, Train loss: 1.147, Test loss: 1.607, Test accuracy: 89.37
Round  17, Train loss: 1.127, Test loss: 1.585, Test accuracy: 91.67
Round  18, Train loss: 1.108, Test loss: 1.581, Test accuracy: 91.78
Round  19, Train loss: 1.104, Test loss: 1.576, Test accuracy: 91.95
Round  20, Train loss: 1.149, Test loss: 1.572, Test accuracy: 92.07
Round  21, Train loss: 1.146, Test loss: 1.570, Test accuracy: 92.07
Round  22, Train loss: 1.108, Test loss: 1.566, Test accuracy: 92.28
Round  23, Train loss: 1.106, Test loss: 1.563, Test accuracy: 92.40
Round  24, Train loss: 1.102, Test loss: 1.561, Test accuracy: 92.52
Round  25, Train loss: 1.104, Test loss: 1.560, Test accuracy: 92.38
Round  26, Train loss: 1.105, Test loss: 1.559, Test accuracy: 92.43
Round  27, Train loss: 1.139, Test loss: 1.554, Test accuracy: 93.38
Round  28, Train loss: 1.101, Test loss: 1.551, Test accuracy: 93.33
Round  29, Train loss: 1.105, Test loss: 1.550, Test accuracy: 93.33
Round  30, Train loss: 1.101, Test loss: 1.550, Test accuracy: 93.18
Round  31, Train loss: 1.101, Test loss: 1.549, Test accuracy: 93.07
Round  32, Train loss: 1.102, Test loss: 1.548, Test accuracy: 93.28
Round  33, Train loss: 1.102, Test loss: 1.547, Test accuracy: 93.13
Round  34, Train loss: 1.107, Test loss: 1.540, Test accuracy: 93.85
Round  35, Train loss: 1.103, Test loss: 1.540, Test accuracy: 94.08
Round  36, Train loss: 1.102, Test loss: 1.539, Test accuracy: 93.97
Round  37, Train loss: 1.105, Test loss: 1.538, Test accuracy: 94.15
Round  38, Train loss: 1.105, Test loss: 1.537, Test accuracy: 94.23
Round  39, Train loss: 1.103, Test loss: 1.538, Test accuracy: 94.12
Round  40, Train loss: 1.103, Test loss: 1.538, Test accuracy: 94.03
Round  41, Train loss: 1.104, Test loss: 1.538, Test accuracy: 93.97
Round  42, Train loss: 1.105, Test loss: 1.538, Test accuracy: 93.95
Round  43, Train loss: 1.107, Test loss: 1.537, Test accuracy: 93.93
Round  44, Train loss: 1.104, Test loss: 1.536, Test accuracy: 93.95
Round  45, Train loss: 1.103, Test loss: 1.536, Test accuracy: 93.93
Round  46, Train loss: 1.102, Test loss: 1.535, Test accuracy: 93.92
Round  47, Train loss: 1.102, Test loss: 1.536, Test accuracy: 93.90
Round  48, Train loss: 1.105, Test loss: 1.535, Test accuracy: 94.02
Round  49, Train loss: 1.100, Test loss: 1.535, Test accuracy: 94.00
Final Round, Train loss: 1.102, Test loss: 1.535, Test accuracy: 94.00
Average accuracy final 10 rounds: 93.96000000000001
460.5744409561157
[]
[46.266666666666666, 58.35, 65.06666666666666, 71.88333333333334, 74.98333333333333, 76.0, 79.5, 80.65, 81.35, 83.16666666666667, 84.18333333333334, 85.93333333333334, 86.85, 88.23333333333333, 88.88333333333334, 89.08333333333333, 89.36666666666666, 91.66666666666667, 91.78333333333333, 91.95, 92.06666666666666, 92.06666666666666, 92.28333333333333, 92.4, 92.51666666666667, 92.38333333333334, 92.43333333333334, 93.38333333333334, 93.33333333333333, 93.33333333333333, 93.18333333333334, 93.06666666666666, 93.28333333333333, 93.13333333333334, 93.85, 94.08333333333333, 93.96666666666667, 94.15, 94.23333333333333, 94.11666666666666, 94.03333333333333, 93.96666666666667, 93.95, 93.93333333333334, 93.95, 93.93333333333334, 93.91666666666667, 93.9, 94.01666666666667, 94.0, 94.0]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.259, Test loss: 2.253, Test accuracy: 29.05
Round   0: Global train loss: 2.259, Global test loss: 2.298, Global test accuracy: 27.50
Round   1, Train loss: 2.109, Test loss: 2.176, Test accuracy: 36.62
Round   1: Global train loss: 2.109, Global test loss: 2.291, Global test accuracy: 32.52
Round   2, Train loss: 2.051, Test loss: 2.118, Test accuracy: 42.20
Round   2: Global train loss: 2.051, Global test loss: 2.284, Global test accuracy: 32.10
Round   3, Train loss: 1.974, Test loss: 2.103, Test accuracy: 41.55
Round   3: Global train loss: 1.974, Global test loss: 2.281, Global test accuracy: 31.82
Round   4, Train loss: 1.503, Test loss: 2.074, Test accuracy: 42.25
Round   4: Global train loss: 1.503, Global test loss: 2.274, Global test accuracy: 31.08
Round   5, Train loss: 1.720, Test loss: 1.987, Test accuracy: 51.25
Round   5: Global train loss: 1.720, Global test loss: 2.260, Global test accuracy: 31.38
Round   6, Train loss: 1.495, Test loss: 1.910, Test accuracy: 56.98
Round   6: Global train loss: 1.495, Global test loss: 2.244, Global test accuracy: 32.35
Round   7, Train loss: 0.932, Test loss: 1.877, Test accuracy: 61.83
Round   7: Global train loss: 0.932, Global test loss: 2.221, Global test accuracy: 32.87
Round   8, Train loss: 1.112, Test loss: 1.847, Test accuracy: 66.92
Round   8: Global train loss: 1.112, Global test loss: 2.199, Global test accuracy: 34.03
Round   9, Train loss: 1.524, Test loss: 1.897, Test accuracy: 61.30
Round   9: Global train loss: 1.524, Global test loss: 2.186, Global test accuracy: 31.75
Round  10, Train loss: 0.860, Test loss: 1.895, Test accuracy: 58.22
Round  10: Global train loss: 0.860, Global test loss: 2.175, Global test accuracy: 30.78
Round  11, Train loss: 0.750, Test loss: 1.800, Test accuracy: 68.67
Round  11: Global train loss: 0.750, Global test loss: 2.155, Global test accuracy: 34.43
Round  12, Train loss: 0.700, Test loss: 1.646, Test accuracy: 84.53
Round  12: Global train loss: 0.700, Global test loss: 2.134, Global test accuracy: 39.72
Round  13, Train loss: 1.192, Test loss: 1.676, Test accuracy: 81.37
Round  13: Global train loss: 1.192, Global test loss: 2.121, Global test accuracy: 39.95
Round  14, Train loss: 1.092, Test loss: 1.719, Test accuracy: 76.83
Round  14: Global train loss: 1.092, Global test loss: 2.110, Global test accuracy: 44.93
Round  15, Train loss: 0.906, Test loss: 1.685, Test accuracy: 80.15
Round  15: Global train loss: 0.906, Global test loss: 2.105, Global test accuracy: 42.38
Round  16, Train loss: 0.403, Test loss: 1.656, Test accuracy: 82.78
Round  16: Global train loss: 0.403, Global test loss: 2.098, Global test accuracy: 40.43
Round  17, Train loss: -0.271, Test loss: 1.605, Test accuracy: 87.92
Round  17: Global train loss: -0.271, Global test loss: 2.087, Global test accuracy: 42.22
Round  18, Train loss: 0.075, Test loss: 1.599, Test accuracy: 87.58
Round  18: Global train loss: 0.075, Global test loss: 2.081, Global test accuracy: 40.40
Round  19, Train loss: -0.367, Test loss: 1.576, Test accuracy: 90.08
Round  19: Global train loss: -0.367, Global test loss: 2.070, Global test accuracy: 42.67
Round  20, Train loss: -0.396, Test loss: 1.554, Test accuracy: 91.93
Round  20: Global train loss: -0.396, Global test loss: 2.065, Global test accuracy: 41.65
Round  21, Train loss: -0.332, Test loss: 1.565, Test accuracy: 90.67
Round  21: Global train loss: -0.332, Global test loss: 2.054, Global test accuracy: 43.47
Round  22, Train loss: 0.334, Test loss: 1.563, Test accuracy: 91.25
Round  22: Global train loss: 0.334, Global test loss: 2.054, Global test accuracy: 43.47
Round  23, Train loss: -0.705, Test loss: 1.564, Test accuracy: 90.87
Round  23: Global train loss: -0.705, Global test loss: 2.055, Global test accuracy: 43.23
Round  24, Train loss: -0.472, Test loss: 1.547, Test accuracy: 92.57
Round  24: Global train loss: -0.472, Global test loss: 2.056, Global test accuracy: 43.27
Round  25, Train loss: -0.807, Test loss: 1.542, Test accuracy: 93.13
Round  25: Global train loss: -0.807, Global test loss: 2.053, Global test accuracy: 43.20
Round  26, Train loss: -0.977, Test loss: 1.535, Test accuracy: 93.43
Round  26: Global train loss: -0.977, Global test loss: 2.049, Global test accuracy: 44.05
Round  27, Train loss: -0.609, Test loss: 1.530, Test accuracy: 93.60
Round  27: Global train loss: -0.609, Global test loss: 2.049, Global test accuracy: 44.12
Round  28, Train loss: -0.550, Test loss: 1.524, Test accuracy: 94.12
Round  28: Global train loss: -0.550, Global test loss: 2.052, Global test accuracy: 43.32
Round  29, Train loss: -0.504, Test loss: 1.525, Test accuracy: 94.10
Round  29: Global train loss: -0.504, Global test loss: 2.048, Global test accuracy: 44.40
Round  30, Train loss: -1.168, Test loss: 1.526, Test accuracy: 93.90
Round  30: Global train loss: -1.168, Global test loss: 2.045, Global test accuracy: 44.72
Round  31, Train loss: -1.200, Test loss: 1.525, Test accuracy: 93.83
Round  31: Global train loss: -1.200, Global test loss: 2.042, Global test accuracy: 44.88
Round  32, Train loss: -1.410, Test loss: 1.526, Test accuracy: 93.85
Round  32: Global train loss: -1.410, Global test loss: 2.042, Global test accuracy: 44.38
Round  33, Train loss: -1.263, Test loss: 1.527, Test accuracy: 93.62
Round  33: Global train loss: -1.263, Global test loss: 2.039, Global test accuracy: 44.43
Round  34, Train loss: -1.399, Test loss: 1.525, Test accuracy: 93.88
Round  34: Global train loss: -1.399, Global test loss: 2.040, Global test accuracy: 43.35
Round  35, Train loss: -1.356, Test loss: 1.524, Test accuracy: 93.90
Round  35: Global train loss: -1.356, Global test loss: 2.034, Global test accuracy: 44.68
Round  36, Train loss: -1.924, Test loss: 1.522, Test accuracy: 94.13
Round  36: Global train loss: -1.924, Global test loss: 2.031, Global test accuracy: 45.12
Round  37, Train loss: -1.211, Test loss: 1.522, Test accuracy: 94.05
Round  37: Global train loss: -1.211, Global test loss: 2.029, Global test accuracy: 45.05
Round  38, Train loss: -1.647, Test loss: 1.523, Test accuracy: 93.98
Round  38: Global train loss: -1.647, Global test loss: 2.026, Global test accuracy: 45.87
Round  39, Train loss: -1.321, Test loss: 1.522, Test accuracy: 94.08
Round  39: Global train loss: -1.321, Global test loss: 2.024, Global test accuracy: 46.08
Round  40, Train loss: -2.096, Test loss: 1.520, Test accuracy: 94.18
Round  40: Global train loss: -2.096, Global test loss: 2.021, Global test accuracy: 46.83
Round  41, Train loss: -1.324, Test loss: 1.521, Test accuracy: 94.05
Round  41: Global train loss: -1.324, Global test loss: 2.022, Global test accuracy: 46.33
Round  42, Train loss: -1.284, Test loss: 1.521, Test accuracy: 93.97
Round  42: Global train loss: -1.284, Global test loss: 2.023, Global test accuracy: 45.42
Round  43, Train loss: -1.812, Test loss: 1.521, Test accuracy: 94.02
Round  43: Global train loss: -1.812, Global test loss: 2.022, Global test accuracy: 45.85
Round  44, Train loss: -1.559, Test loss: 1.520, Test accuracy: 94.12
Round  44: Global train loss: -1.559, Global test loss: 2.017, Global test accuracy: 46.18
Round  45, Train loss: -1.433, Test loss: 1.520, Test accuracy: 94.10
Round  45: Global train loss: -1.433, Global test loss: 2.014, Global test accuracy: 46.60
Round  46, Train loss: -2.182, Test loss: 1.520, Test accuracy: 94.15
Round  46: Global train loss: -2.182, Global test loss: 2.012, Global test accuracy: 46.05
Round  47, Train loss: -2.035, Test loss: 1.521, Test accuracy: 93.90
Round  47: Global train loss: -2.035, Global test loss: 2.010, Global test accuracy: 46.32
Round  48, Train loss: -1.821, Test loss: 1.522, Test accuracy: 93.83
Round  48: Global train loss: -1.821, Global test loss: 2.010, Global test accuracy: 46.38
Round  49, Train loss: -1.740, Test loss: 1.520, Test accuracy: 94.08
Round  49: Global train loss: -1.740, Global test loss: 2.007, Global test accuracy: 47.12
Final Round: Train loss: 1.615, Test loss: 1.575, Test accuracy: 89.93
Final Round: Global train loss: 1.615, Global test loss: 2.005, Global test accuracy: 46.77
Average accuracy final 10 rounds: 94.03999999999999
Average global accuracy final 10 rounds: 46.30833333333333
428.7488589286804
[]
[29.05, 36.61666666666667, 42.2, 41.55, 42.25, 51.25, 56.983333333333334, 61.833333333333336, 66.91666666666667, 61.3, 58.21666666666667, 68.66666666666667, 84.53333333333333, 81.36666666666666, 76.83333333333333, 80.15, 82.78333333333333, 87.91666666666667, 87.58333333333333, 90.08333333333333, 91.93333333333334, 90.66666666666667, 91.25, 90.86666666666666, 92.56666666666666, 93.13333333333334, 93.43333333333334, 93.6, 94.11666666666666, 94.1, 93.9, 93.83333333333333, 93.85, 93.61666666666666, 93.88333333333334, 93.9, 94.13333333333334, 94.05, 93.98333333333333, 94.08333333333333, 94.18333333333334, 94.05, 93.96666666666667, 94.01666666666667, 94.11666666666666, 94.1, 94.15, 93.9, 93.83333333333333, 94.08333333333333, 89.93333333333334]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.305, Test loss: 2.305, Test accuracy: 0.02 

Round   0, Global train loss: 2.305, Global test loss: 2.305, Global test accuracy: 0.02 

Round   1, Train loss: 2.305, Test loss: 2.305, Test accuracy: 0.03 

Round   1, Global train loss: 2.305, Global test loss: 2.305, Global test accuracy: 0.03 

Round   2, Train loss: 2.304, Test loss: 2.305, Test accuracy: 0.05 

Round   2, Global train loss: 2.304, Global test loss: 2.305, Global test accuracy: 0.05 

Round   3, Train loss: 2.304, Test loss: 2.305, Test accuracy: 0.05 

Round   3, Global train loss: 2.304, Global test loss: 2.305, Global test accuracy: 0.05 

Round   4, Train loss: 2.304, Test loss: 2.305, Test accuracy: 0.05 

Round   4, Global train loss: 2.304, Global test loss: 2.304, Global test accuracy: 0.07 

Round   5, Train loss: 2.304, Test loss: 2.305, Test accuracy: 0.08 

Round   5, Global train loss: 2.304, Global test loss: 2.304, Global test accuracy: 0.10 

Round   6, Train loss: 2.304, Test loss: 2.304, Test accuracy: 0.10 

Round   6, Global train loss: 2.304, Global test loss: 2.304, Global test accuracy: 0.17 

Round   7, Train loss: 2.304, Test loss: 2.304, Test accuracy: 0.17 

Round   7, Global train loss: 2.304, Global test loss: 2.304, Global test accuracy: 0.20 

Round   8, Train loss: 2.303, Test loss: 2.304, Test accuracy: 0.18 

Round   8, Global train loss: 2.303, Global test loss: 2.304, Global test accuracy: 0.25 

Round   9, Train loss: 2.303, Test loss: 2.304, Test accuracy: 0.18 

Round   9, Global train loss: 2.303, Global test loss: 2.304, Global test accuracy: 0.27 

Round  10, Train loss: 2.303, Test loss: 2.304, Test accuracy: 0.23 

Round  10, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 0.28 

Round  11, Train loss: 2.303, Test loss: 2.303, Test accuracy: 0.28 

Round  11, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 0.33 

Round  12, Train loss: 2.303, Test loss: 2.303, Test accuracy: 0.33 

Round  12, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 0.52 

Round  13, Train loss: 2.303, Test loss: 2.303, Test accuracy: 0.37 

Round  13, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 0.65 

Round  14, Train loss: 2.302, Test loss: 2.303, Test accuracy: 0.60 

Round  14, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 0.87 

Round  15, Train loss: 2.302, Test loss: 2.303, Test accuracy: 0.80 

Round  15, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 1.12 

Round  16, Train loss: 2.302, Test loss: 2.303, Test accuracy: 0.95 

Round  16, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 1.25 

Round  17, Train loss: 2.302, Test loss: 2.302, Test accuracy: 1.12 

Round  17, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 1.47 

Round  18, Train loss: 2.302, Test loss: 2.302, Test accuracy: 1.37 

Round  18, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 1.82 

Round  19, Train loss: 2.301, Test loss: 2.302, Test accuracy: 1.73 

Round  19, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 2.37 

Round  20, Train loss: 2.301, Test loss: 2.302, Test accuracy: 2.07 

Round  20, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 2.87 

Round  21, Train loss: 2.301, Test loss: 2.302, Test accuracy: 2.33 

Round  21, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 3.47 

Round  22, Train loss: 2.300, Test loss: 2.302, Test accuracy: 2.78 

Round  22, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 3.98 

Round  23, Train loss: 2.300, Test loss: 2.301, Test accuracy: 3.63 

Round  23, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 4.77 

Round  24, Train loss: 2.300, Test loss: 2.301, Test accuracy: 4.08 

Round  24, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 5.65 

Round  25, Train loss: 2.300, Test loss: 2.301, Test accuracy: 4.93 

Round  25, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 6.35 

Round  26, Train loss: 2.300, Test loss: 2.301, Test accuracy: 5.72 

Round  26, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 7.27 

Round  27, Train loss: 2.300, Test loss: 2.301, Test accuracy: 6.58 

Round  27, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 8.20 

Round  28, Train loss: 2.300, Test loss: 2.300, Test accuracy: 7.38 

Round  28, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 9.37 

Round  29, Train loss: 2.299, Test loss: 2.300, Test accuracy: 8.42 

Round  29, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 10.50 

Round  30, Train loss: 2.299, Test loss: 2.300, Test accuracy: 9.18 

Round  30, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 11.60 

Round  31, Train loss: 2.299, Test loss: 2.300, Test accuracy: 10.32 

Round  31, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 12.55 

Round  32, Train loss: 2.299, Test loss: 2.300, Test accuracy: 11.68 

Round  32, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 13.85 

Round  33, Train loss: 2.298, Test loss: 2.300, Test accuracy: 13.12 

Round  33, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 15.17 

Round  34, Train loss: 2.299, Test loss: 2.299, Test accuracy: 14.17 

Round  34, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 16.27 

Round  35, Train loss: 2.298, Test loss: 2.299, Test accuracy: 15.02 

Round  35, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 17.78 

Round  36, Train loss: 2.298, Test loss: 2.299, Test accuracy: 17.28 

Round  36, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 19.13 

Round  37, Train loss: 2.298, Test loss: 2.299, Test accuracy: 18.52 

Round  37, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 20.28 

Round  38, Train loss: 2.298, Test loss: 2.298, Test accuracy: 19.22 

Round  38, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 21.57 

Round  39, Train loss: 2.297, Test loss: 2.298, Test accuracy: 21.20 

Round  39, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 22.82 

Round  40, Train loss: 2.297, Test loss: 2.298, Test accuracy: 22.35 

Round  40, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 24.03 

Round  41, Train loss: 2.297, Test loss: 2.298, Test accuracy: 22.97 

Round  41, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 25.25 

Round  42, Train loss: 2.297, Test loss: 2.298, Test accuracy: 23.87 

Round  42, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 26.33 

Round  43, Train loss: 2.297, Test loss: 2.298, Test accuracy: 25.13 

Round  43, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 27.50 

Round  44, Train loss: 2.297, Test loss: 2.297, Test accuracy: 26.07 

Round  44, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 28.28 

Round  45, Train loss: 2.296, Test loss: 2.297, Test accuracy: 26.50 

Round  45, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 29.23 

Round  46, Train loss: 2.296, Test loss: 2.297, Test accuracy: 27.07 

Round  46, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 29.92 

Round  47, Train loss: 2.296, Test loss: 2.297, Test accuracy: 28.75 

Round  47, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 30.48 

Round  48, Train loss: 2.296, Test loss: 2.297, Test accuracy: 29.20 

Round  48, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 30.72 

Round  49, Train loss: 2.295, Test loss: 2.296, Test accuracy: 29.73 

Round  49, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 31.08 

Final Round, Train loss: 2.295, Test loss: 2.295, Test accuracy: 32.37 

Final Round, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 31.08 

Average accuracy final 10 rounds: 26.16333333333333 

Average global accuracy final 10 rounds: 28.28333333333333 

364.8495833873749
[1.5270774364471436, 2.265054702758789, 2.9291651248931885, 3.645531177520752, 4.30837082862854, 4.961408615112305, 5.626715183258057, 6.289508819580078, 6.9541335105896, 7.619352579116821, 8.2785325050354, 8.901584386825562, 9.554754734039307, 10.212843179702759, 10.868061780929565, 11.522729873657227, 12.176911115646362, 12.837954044342041, 13.495586156845093, 14.158857583999634, 14.814149379730225, 15.476215362548828, 16.1417133808136, 16.79055404663086, 17.448549032211304, 18.107038021087646, 18.765320301055908, 19.42484974861145, 20.083717584609985, 20.74549627304077, 21.408358812332153, 22.00991725921631, 22.662346839904785, 23.31960678100586, 23.97942590713501, 24.63594937324524, 25.283032178878784, 25.905473470687866, 26.52670407295227, 27.180783987045288, 27.8371160030365, 28.501527786254883, 29.169224739074707, 29.813674211502075, 30.46439504623413, 31.11220645904541, 31.75932741165161, 32.42310643196106, 33.08330845832825, 33.75242757797241, 35.07144904136658]
[0.016666666666666666, 0.03333333333333333, 0.05, 0.05, 0.05, 0.08333333333333333, 0.1, 0.16666666666666666, 0.18333333333333332, 0.18333333333333332, 0.23333333333333334, 0.2833333333333333, 0.3333333333333333, 0.36666666666666664, 0.6, 0.8, 0.95, 1.1166666666666667, 1.3666666666666667, 1.7333333333333334, 2.066666666666667, 2.3333333333333335, 2.783333333333333, 3.6333333333333333, 4.083333333333333, 4.933333333333334, 5.716666666666667, 6.583333333333333, 7.383333333333334, 8.416666666666666, 9.183333333333334, 10.316666666666666, 11.683333333333334, 13.116666666666667, 14.166666666666666, 15.016666666666667, 17.283333333333335, 18.516666666666666, 19.216666666666665, 21.2, 22.35, 22.966666666666665, 23.866666666666667, 25.133333333333333, 26.066666666666666, 26.5, 27.066666666666666, 28.75, 29.2, 29.733333333333334, 32.36666666666667]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 1, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.289, Test loss: 2.278, Test accuracy: 34.00 

Round   0, Global train loss: 2.289, Global test loss: 2.280, Global test accuracy: 33.33 

Round   1, Train loss: 2.190, Test loss: 2.148, Test accuracy: 35.48 

Round   1, Global train loss: 2.190, Global test loss: 2.136, Global test accuracy: 33.33 

Round   2, Train loss: 1.889, Test loss: 2.034, Test accuracy: 46.55 

Round   2, Global train loss: 1.889, Global test loss: 2.051, Global test accuracy: 40.07 

Round   3, Train loss: 1.809, Test loss: 1.937, Test accuracy: 54.47 

Round   3, Global train loss: 1.809, Global test loss: 2.063, Global test accuracy: 36.98 

Round   4, Train loss: 1.770, Test loss: 1.861, Test accuracy: 63.02 

Round   4, Global train loss: 1.770, Global test loss: 2.037, Global test accuracy: 41.38 

Round   5, Train loss: 1.656, Test loss: 1.785, Test accuracy: 69.47 

Round   5, Global train loss: 1.656, Global test loss: 2.021, Global test accuracy: 45.82 

Round   6, Train loss: 1.704, Test loss: 1.745, Test accuracy: 71.95 

Round   6, Global train loss: 1.704, Global test loss: 2.058, Global test accuracy: 38.28 

Round   7, Train loss: 1.593, Test loss: 1.679, Test accuracy: 80.18 

Round   7, Global train loss: 1.593, Global test loss: 2.038, Global test accuracy: 42.10 

Round   8, Train loss: 1.651, Test loss: 1.633, Test accuracy: 85.73 

Round   8, Global train loss: 1.651, Global test loss: 2.049, Global test accuracy: 39.63 

Round   9, Train loss: 1.541, Test loss: 1.606, Test accuracy: 88.23 

Round   9, Global train loss: 1.541, Global test loss: 2.013, Global test accuracy: 43.87 

Round  10, Train loss: 1.482, Test loss: 1.598, Test accuracy: 88.82 

Round  10, Global train loss: 1.482, Global test loss: 2.018, Global test accuracy: 45.07 

Round  11, Train loss: 1.528, Test loss: 1.578, Test accuracy: 89.88 

Round  11, Global train loss: 1.528, Global test loss: 2.043, Global test accuracy: 39.68 

Round  12, Train loss: 1.488, Test loss: 1.566, Test accuracy: 91.47 

Round  12, Global train loss: 1.488, Global test loss: 2.019, Global test accuracy: 43.88 

Round  13, Train loss: 1.503, Test loss: 1.566, Test accuracy: 90.23 

Round  13, Global train loss: 1.503, Global test loss: 2.033, Global test accuracy: 41.92 

Round  14, Train loss: 1.510, Test loss: 1.559, Test accuracy: 90.82 

Round  14, Global train loss: 1.510, Global test loss: 2.051, Global test accuracy: 39.23 

Round  15, Train loss: 1.479, Test loss: 1.537, Test accuracy: 93.43 

Round  15, Global train loss: 1.479, Global test loss: 1.984, Global test accuracy: 49.00 

Round  16, Train loss: 1.475, Test loss: 1.542, Test accuracy: 92.97 

Round  16, Global train loss: 1.475, Global test loss: 2.041, Global test accuracy: 41.83 

Round  17, Train loss: 1.472, Test loss: 1.547, Test accuracy: 92.03 

Round  17, Global train loss: 1.472, Global test loss: 2.031, Global test accuracy: 41.73 

Round  18, Train loss: 1.475, Test loss: 1.541, Test accuracy: 92.93 

Round  18, Global train loss: 1.475, Global test loss: 2.004, Global test accuracy: 47.28 

Round  19, Train loss: 1.529, Test loss: 1.532, Test accuracy: 93.58 

Round  19, Global train loss: 1.529, Global test loss: 2.007, Global test accuracy: 44.53 

Round  20, Train loss: 1.471, Test loss: 1.531, Test accuracy: 93.55 

Round  20, Global train loss: 1.471, Global test loss: 2.004, Global test accuracy: 45.07 

Round  21, Train loss: 1.471, Test loss: 1.531, Test accuracy: 93.55 

Round  21, Global train loss: 1.471, Global test loss: 2.000, Global test accuracy: 45.90 

Round  22, Train loss: 1.524, Test loss: 1.531, Test accuracy: 93.62 

Round  22, Global train loss: 1.524, Global test loss: 2.004, Global test accuracy: 45.75 

Round  23, Train loss: 1.523, Test loss: 1.531, Test accuracy: 93.62 

Round  23, Global train loss: 1.523, Global test loss: 2.001, Global test accuracy: 45.75 

Round  24, Train loss: 1.472, Test loss: 1.530, Test accuracy: 93.72 

Round  24, Global train loss: 1.472, Global test loss: 2.062, Global test accuracy: 38.68 

Round  25, Train loss: 1.467, Test loss: 1.529, Test accuracy: 93.72 

Round  25, Global train loss: 1.467, Global test loss: 2.006, Global test accuracy: 44.43 

Round  26, Train loss: 1.520, Test loss: 1.529, Test accuracy: 93.70 

Round  26, Global train loss: 1.520, Global test loss: 1.995, Global test accuracy: 47.48 

Round  27, Train loss: 1.468, Test loss: 1.529, Test accuracy: 93.73 

Round  27, Global train loss: 1.468, Global test loss: 2.035, Global test accuracy: 41.08 

Round  28, Train loss: 1.522, Test loss: 1.528, Test accuracy: 93.73 

Round  28, Global train loss: 1.522, Global test loss: 2.029, Global test accuracy: 41.80 

Round  29, Train loss: 1.468, Test loss: 1.528, Test accuracy: 93.73 

Round  29, Global train loss: 1.468, Global test loss: 2.021, Global test accuracy: 43.97 

Round  30, Train loss: 1.466, Test loss: 1.528, Test accuracy: 93.78 

Round  30, Global train loss: 1.466, Global test loss: 2.018, Global test accuracy: 42.75 

Round  31, Train loss: 1.466, Test loss: 1.528, Test accuracy: 93.72 

Round  31, Global train loss: 1.466, Global test loss: 2.036, Global test accuracy: 39.92 

Round  32, Train loss: 1.466, Test loss: 1.528, Test accuracy: 93.72 

Round  32, Global train loss: 1.466, Global test loss: 2.036, Global test accuracy: 40.55 

Round  33, Train loss: 1.468, Test loss: 1.528, Test accuracy: 93.73 

Round  33, Global train loss: 1.468, Global test loss: 2.022, Global test accuracy: 44.70 

Round  34, Train loss: 1.522, Test loss: 1.527, Test accuracy: 93.73 

Round  34, Global train loss: 1.522, Global test loss: 2.093, Global test accuracy: 33.75 

Round  35, Train loss: 1.467, Test loss: 1.527, Test accuracy: 93.73 

Round  35, Global train loss: 1.467, Global test loss: 2.010, Global test accuracy: 45.40 

Round  36, Train loss: 1.468, Test loss: 1.527, Test accuracy: 93.75 

Round  36, Global train loss: 1.468, Global test loss: 2.021, Global test accuracy: 42.90 

Round  37, Train loss: 1.466, Test loss: 1.527, Test accuracy: 93.77 

Round  37, Global train loss: 1.466, Global test loss: 2.051, Global test accuracy: 38.77 

Round  38, Train loss: 1.469, Test loss: 1.527, Test accuracy: 93.78 

Round  38, Global train loss: 1.469, Global test loss: 2.019, Global test accuracy: 43.53 

Round  39, Train loss: 1.517, Test loss: 1.527, Test accuracy: 93.78 

Round  39, Global train loss: 1.517, Global test loss: 1.996, Global test accuracy: 46.28 

Round  40, Train loss: 1.467, Test loss: 1.527, Test accuracy: 93.80 

Round  40, Global train loss: 1.467, Global test loss: 2.091, Global test accuracy: 34.85 

Round  41, Train loss: 1.466, Test loss: 1.527, Test accuracy: 93.80 

Round  41, Global train loss: 1.466, Global test loss: 2.034, Global test accuracy: 41.47 

Round  42, Train loss: 1.467, Test loss: 1.527, Test accuracy: 93.80 

Round  42, Global train loss: 1.467, Global test loss: 2.059, Global test accuracy: 37.28 

Round  43, Train loss: 1.465, Test loss: 1.527, Test accuracy: 93.82 

Round  43, Global train loss: 1.465, Global test loss: 2.051, Global test accuracy: 38.52 

Round  44, Train loss: 1.519, Test loss: 1.527, Test accuracy: 93.82 

Round  44, Global train loss: 1.519, Global test loss: 1.997, Global test accuracy: 46.17 

Round  45, Train loss: 1.463, Test loss: 1.527, Test accuracy: 93.82 

Round  45, Global train loss: 1.463, Global test loss: 2.035, Global test accuracy: 41.82 

Round  46, Train loss: 1.465, Test loss: 1.526, Test accuracy: 93.85 

Round  46, Global train loss: 1.465, Global test loss: 2.085, Global test accuracy: 31.03 

Round  47, Train loss: 1.465, Test loss: 1.526, Test accuracy: 93.83 

Round  47, Global train loss: 1.465, Global test loss: 2.020, Global test accuracy: 42.90 

Round  48, Train loss: 1.464, Test loss: 1.526, Test accuracy: 93.88 

Round  48, Global train loss: 1.464, Global test loss: 2.039, Global test accuracy: 41.08 

Round  49, Train loss: 1.520, Test loss: 1.526, Test accuracy: 93.88 

Round  49, Global train loss: 1.520, Global test loss: 1.992, Global test accuracy: 47.28 

Final Round, Train loss: 1.481, Test loss: 1.526, Test accuracy: 93.97 

Final Round, Global train loss: 1.481, Global test loss: 1.992, Global test accuracy: 47.28 

Average accuracy final 10 rounds: 93.83000000000001 

Average global accuracy final 10 rounds: 40.239999999999995 

343.96184253692627
[1.4828073978424072, 2.082770586013794, 2.6761507987976074, 3.266871213912964, 3.879244804382324, 4.472043991088867, 5.063454627990723, 5.65775465965271, 6.2471113204956055, 6.838443756103516, 7.459508180618286, 8.051769495010376, 8.657431602478027, 9.25184941291809, 9.846285581588745, 10.43793511390686, 11.026134729385376, 11.616018295288086, 12.213891744613647, 12.805397272109985, 13.396372318267822, 13.98557710647583, 14.577953100204468, 15.170366287231445, 15.761253833770752, 16.35142731666565, 16.944264888763428, 17.535709142684937, 18.127695083618164, 18.718713998794556, 19.315309286117554, 19.90929365158081, 20.499919652938843, 21.094944953918457, 21.687347412109375, 22.281472206115723, 22.871349096298218, 23.46056628227234, 24.068668127059937, 24.660932779312134, 25.25403642654419, 25.850188732147217, 26.442575454711914, 27.037443161010742, 27.631582021713257, 28.227019786834717, 28.819255113601685, 29.410419702529907, 30.003726720809937, 30.596943616867065, 31.78640627861023]
[34.0, 35.483333333333334, 46.55, 54.46666666666667, 63.016666666666666, 69.46666666666667, 71.95, 80.18333333333334, 85.73333333333333, 88.23333333333333, 88.81666666666666, 89.88333333333334, 91.46666666666667, 90.23333333333333, 90.81666666666666, 93.43333333333334, 92.96666666666667, 92.03333333333333, 92.93333333333334, 93.58333333333333, 93.55, 93.55, 93.61666666666666, 93.61666666666666, 93.71666666666667, 93.71666666666667, 93.7, 93.73333333333333, 93.73333333333333, 93.73333333333333, 93.78333333333333, 93.71666666666667, 93.71666666666667, 93.73333333333333, 93.73333333333333, 93.73333333333333, 93.75, 93.76666666666667, 93.78333333333333, 93.78333333333333, 93.8, 93.8, 93.8, 93.81666666666666, 93.81666666666666, 93.81666666666666, 93.85, 93.83333333333333, 93.88333333333334, 93.88333333333334, 93.96666666666667]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.288, Test loss: 2.276, Test accuracy: 33.88 

Round   0, Global train loss: 2.288, Global test loss: 2.279, Global test accuracy: 33.33 

Round   1, Train loss: 2.194, Test loss: 2.152, Test accuracy: 35.23 

Round   1, Global train loss: 2.194, Global test loss: 2.135, Global test accuracy: 33.33 

Round   2, Train loss: 1.973, Test loss: 2.033, Test accuracy: 45.92 

Round   2, Global train loss: 1.973, Global test loss: 2.062, Global test accuracy: 42.53 

Round   3, Train loss: 1.819, Test loss: 1.929, Test accuracy: 54.12 

Round   3, Global train loss: 1.819, Global test loss: 2.058, Global test accuracy: 35.18 

Round   4, Train loss: 1.698, Test loss: 1.854, Test accuracy: 62.73 

Round   4, Global train loss: 1.698, Global test loss: 2.055, Global test accuracy: 35.90 

Round   5, Train loss: 1.606, Test loss: 1.751, Test accuracy: 74.53 

Round   5, Global train loss: 1.606, Global test loss: 2.030, Global test accuracy: 41.47 

Round   6, Train loss: 1.613, Test loss: 1.666, Test accuracy: 82.15 

Round   6, Global train loss: 1.613, Global test loss: 1.994, Global test accuracy: 46.42 

Round   7, Train loss: 1.608, Test loss: 1.652, Test accuracy: 83.63 

Round   7, Global train loss: 1.608, Global test loss: 1.981, Global test accuracy: 48.17 

Round   8, Train loss: 1.650, Test loss: 1.629, Test accuracy: 85.72 

Round   8, Global train loss: 1.650, Global test loss: 1.998, Global test accuracy: 46.23 

Round   9, Train loss: 1.827, Test loss: 1.668, Test accuracy: 81.13 

Round   9, Global train loss: 1.827, Global test loss: 2.029, Global test accuracy: 42.00 

Round  10, Train loss: 1.673, Test loss: 1.659, Test accuracy: 81.12 

Round  10, Global train loss: 1.673, Global test loss: 1.996, Global test accuracy: 46.63 

Round  11, Train loss: 1.707, Test loss: 1.653, Test accuracy: 81.87 

Round  11, Global train loss: 1.707, Global test loss: 2.054, Global test accuracy: 38.57 

Round  12, Train loss: 1.616, Test loss: 1.650, Test accuracy: 82.03 

Round  12, Global train loss: 1.616, Global test loss: 1.999, Global test accuracy: 45.68 

Round  13, Train loss: 1.705, Test loss: 1.636, Test accuracy: 83.32 

Round  13, Global train loss: 1.705, Global test loss: 1.994, Global test accuracy: 46.40 

Round  14, Train loss: 1.719, Test loss: 1.654, Test accuracy: 81.32 

Round  14, Global train loss: 1.719, Global test loss: 2.035, Global test accuracy: 40.75 

Round  15, Train loss: 1.767, Test loss: 1.639, Test accuracy: 82.95 

Round  15, Global train loss: 1.767, Global test loss: 2.020, Global test accuracy: 42.78 

Round  16, Train loss: 1.673, Test loss: 1.639, Test accuracy: 82.85 

Round  16, Global train loss: 1.673, Global test loss: 2.020, Global test accuracy: 43.67 

Round  17, Train loss: 1.662, Test loss: 1.641, Test accuracy: 82.67 

Round  17, Global train loss: 1.662, Global test loss: 2.003, Global test accuracy: 44.88 

Round  18, Train loss: 1.668, Test loss: 1.656, Test accuracy: 80.97 

Round  18, Global train loss: 1.668, Global test loss: 1.988, Global test accuracy: 46.67 

Round  19, Train loss: 1.555, Test loss: 1.653, Test accuracy: 81.25 

Round  19, Global train loss: 1.555, Global test loss: 1.990, Global test accuracy: 46.55 

Round  20, Train loss: 1.507, Test loss: 1.639, Test accuracy: 82.52 

Round  20, Global train loss: 1.507, Global test loss: 1.995, Global test accuracy: 46.32 

Round  21, Train loss: 1.616, Test loss: 1.654, Test accuracy: 81.12 

Round  21, Global train loss: 1.616, Global test loss: 2.043, Global test accuracy: 40.33 

Round  22, Train loss: 1.496, Test loss: 1.653, Test accuracy: 81.17 

Round  22, Global train loss: 1.496, Global test loss: 2.022, Global test accuracy: 43.35 

Round  23, Train loss: 1.671, Test loss: 1.625, Test accuracy: 84.07 

Round  23, Global train loss: 1.671, Global test loss: 2.039, Global test accuracy: 40.75 

Round  24, Train loss: 1.597, Test loss: 1.640, Test accuracy: 82.47 

Round  24, Global train loss: 1.597, Global test loss: 1.987, Global test accuracy: 46.78 

Round  25, Train loss: 1.637, Test loss: 1.609, Test accuracy: 85.55 

Round  25, Global train loss: 1.637, Global test loss: 1.969, Global test accuracy: 49.28 

Round  26, Train loss: 1.665, Test loss: 1.609, Test accuracy: 85.45 

Round  26, Global train loss: 1.665, Global test loss: 1.981, Global test accuracy: 47.50 

Round  27, Train loss: 1.644, Test loss: 1.623, Test accuracy: 84.10 

Round  27, Global train loss: 1.644, Global test loss: 1.998, Global test accuracy: 45.70 

Round  28, Train loss: 1.752, Test loss: 1.623, Test accuracy: 84.08 

Round  28, Global train loss: 1.752, Global test loss: 1.997, Global test accuracy: 46.07 

Round  29, Train loss: 1.655, Test loss: 1.623, Test accuracy: 84.08 

Round  29, Global train loss: 1.655, Global test loss: 2.013, Global test accuracy: 43.92 

Round  30, Train loss: 1.703, Test loss: 1.638, Test accuracy: 82.63 

Round  30, Global train loss: 1.703, Global test loss: 1.990, Global test accuracy: 46.32 

Round  31, Train loss: 1.698, Test loss: 1.667, Test accuracy: 79.70 

Round  31, Global train loss: 1.698, Global test loss: 1.991, Global test accuracy: 46.52 

Round  32, Train loss: 1.628, Test loss: 1.653, Test accuracy: 81.05 

Round  32, Global train loss: 1.628, Global test loss: 1.977, Global test accuracy: 47.90 

Round  33, Train loss: 1.656, Test loss: 1.653, Test accuracy: 81.10 

Round  33, Global train loss: 1.656, Global test loss: 1.990, Global test accuracy: 46.53 

Round  34, Train loss: 1.626, Test loss: 1.651, Test accuracy: 81.23 

Round  34, Global train loss: 1.626, Global test loss: 1.992, Global test accuracy: 46.35 

Round  35, Train loss: 1.689, Test loss: 1.636, Test accuracy: 82.72 

Round  35, Global train loss: 1.689, Global test loss: 2.044, Global test accuracy: 40.77 

Round  36, Train loss: 1.673, Test loss: 1.650, Test accuracy: 81.32 

Round  36, Global train loss: 1.673, Global test loss: 1.974, Global test accuracy: 48.23 

Round  37, Train loss: 1.540, Test loss: 1.651, Test accuracy: 81.17 

Round  37, Global train loss: 1.540, Global test loss: 1.959, Global test accuracy: 50.23 

Round  38, Train loss: 1.589, Test loss: 1.650, Test accuracy: 81.27 

Round  38, Global train loss: 1.589, Global test loss: 1.984, Global test accuracy: 47.33 

Round  39, Train loss: 1.770, Test loss: 1.650, Test accuracy: 81.25 

Round  39, Global train loss: 1.770, Global test loss: 2.031, Global test accuracy: 42.12 

Round  40, Train loss: 1.694, Test loss: 1.679, Test accuracy: 78.35 

Round  40, Global train loss: 1.694, Global test loss: 1.976, Global test accuracy: 48.02 

Round  41, Train loss: 1.532, Test loss: 1.679, Test accuracy: 78.27 

Round  41, Global train loss: 1.532, Global test loss: 1.939, Global test accuracy: 52.17 

Round  42, Train loss: 1.702, Test loss: 1.694, Test accuracy: 76.87 

Round  42, Global train loss: 1.702, Global test loss: 1.988, Global test accuracy: 46.70 

Round  43, Train loss: 1.699, Test loss: 1.694, Test accuracy: 76.78 

Round  43, Global train loss: 1.699, Global test loss: 2.035, Global test accuracy: 41.95 

Round  44, Train loss: 1.664, Test loss: 1.680, Test accuracy: 78.22 

Round  44, Global train loss: 1.664, Global test loss: 1.991, Global test accuracy: 46.40 

Round  45, Train loss: 1.662, Test loss: 1.665, Test accuracy: 79.77 

Round  45, Global train loss: 1.662, Global test loss: 2.008, Global test accuracy: 44.95 

Round  46, Train loss: 1.698, Test loss: 1.665, Test accuracy: 79.70 

Round  46, Global train loss: 1.698, Global test loss: 2.000, Global test accuracy: 45.40 

Round  47, Train loss: 1.661, Test loss: 1.651, Test accuracy: 81.12 

Round  47, Global train loss: 1.661, Global test loss: 1.968, Global test accuracy: 48.87 

Round  48, Train loss: 1.652, Test loss: 1.663, Test accuracy: 79.88 

Round  48, Global train loss: 1.652, Global test loss: 1.987, Global test accuracy: 46.68 

Round  49, Train loss: 1.725, Test loss: 1.664, Test accuracy: 79.77 

Round  49, Global train loss: 1.725, Global test loss: 1.970, Global test accuracy: 48.38 

Final Round, Train loss: 1.581, Test loss: 1.589, Test accuracy: 87.35 

Final Round, Global train loss: 1.581, Global test loss: 1.970, Global test accuracy: 48.38 

Average accuracy final 10 rounds: 78.87166666666667 

Average global accuracy final 10 rounds: 46.951666666666675 

343.24800086021423
[1.4829378128051758, 2.037992477416992, 2.6321024894714355, 3.2278411388397217, 3.8236923217773438, 4.418407917022705, 5.012486934661865, 5.610755443572998, 6.20892071723938, 6.803704023361206, 7.399208307266235, 7.994492292404175, 8.589166402816772, 9.18015718460083, 9.790113687515259, 10.382562398910522, 10.940255165100098, 11.533036708831787, 12.129256010055542, 12.722478866577148, 13.31668758392334, 13.908915996551514, 14.501110076904297, 15.09102463722229, 15.680978059768677, 16.273836851119995, 16.872287273406982, 17.465647220611572, 18.056405782699585, 18.647431135177612, 19.242390632629395, 19.834562063217163, 20.42618155479431, 21.01830530166626, 21.613808155059814, 22.205918073654175, 22.795692682266235, 23.389270782470703, 23.980865478515625, 24.572495937347412, 25.167237997055054, 25.75866675376892, 26.35329008102417, 26.948580265045166, 27.541029691696167, 28.133795261383057, 28.727290391921997, 29.31885814666748, 29.913336277008057, 30.506754159927368, 31.693729639053345]
[33.88333333333333, 35.233333333333334, 45.916666666666664, 54.11666666666667, 62.733333333333334, 74.53333333333333, 82.15, 83.63333333333334, 85.71666666666667, 81.13333333333334, 81.11666666666666, 81.86666666666666, 82.03333333333333, 83.31666666666666, 81.31666666666666, 82.95, 82.85, 82.66666666666667, 80.96666666666667, 81.25, 82.51666666666667, 81.11666666666666, 81.16666666666667, 84.06666666666666, 82.46666666666667, 85.55, 85.45, 84.1, 84.08333333333333, 84.08333333333333, 82.63333333333334, 79.7, 81.05, 81.1, 81.23333333333333, 82.71666666666667, 81.31666666666666, 81.16666666666667, 81.26666666666667, 81.25, 78.35, 78.26666666666667, 76.86666666666666, 76.78333333333333, 78.21666666666667, 79.76666666666667, 79.7, 81.11666666666666, 79.88333333333334, 79.76666666666667, 87.35]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.296, Test loss: 2.293, Test accuracy: 33.33 

Round   1, Train loss: 2.286, Test loss: 2.281, Test accuracy: 33.33 

Round   2, Train loss: 2.264, Test loss: 2.248, Test accuracy: 33.33 

Round   3, Train loss: 2.169, Test loss: 2.156, Test accuracy: 33.33 

Round   4, Train loss: 2.080, Test loss: 2.105, Test accuracy: 33.13 

Round   5, Train loss: 1.996, Test loss: 2.067, Test accuracy: 39.15 

Round   6, Train loss: 2.050, Test loss: 2.047, Test accuracy: 41.70 

Round   7, Train loss: 1.906, Test loss: 2.002, Test accuracy: 46.52 

Round   8, Train loss: 1.905, Test loss: 1.990, Test accuracy: 47.50 

Round   9, Train loss: 1.900, Test loss: 1.986, Test accuracy: 47.30 

Round  10, Train loss: 1.912, Test loss: 1.970, Test accuracy: 49.40 

Round  11, Train loss: 1.860, Test loss: 1.952, Test accuracy: 51.68 

Round  12, Train loss: 1.823, Test loss: 1.940, Test accuracy: 53.55 

Round  13, Train loss: 1.838, Test loss: 1.933, Test accuracy: 54.15 

Round  14, Train loss: 1.873, Test loss: 1.912, Test accuracy: 56.48 

Round  15, Train loss: 1.772, Test loss: 1.898, Test accuracy: 57.33 

Round  16, Train loss: 1.953, Test loss: 1.890, Test accuracy: 58.27 

Round  17, Train loss: 1.707, Test loss: 1.874, Test accuracy: 59.63 

Round  18, Train loss: 1.803, Test loss: 1.860, Test accuracy: 61.15 

Round  19, Train loss: 1.972, Test loss: 1.859, Test accuracy: 61.33 

Round  20, Train loss: 1.799, Test loss: 1.862, Test accuracy: 61.23 

Round  21, Train loss: 1.829, Test loss: 1.839, Test accuracy: 63.17 

Round  22, Train loss: 1.825, Test loss: 1.836, Test accuracy: 63.53 

Round  23, Train loss: 1.823, Test loss: 1.829, Test accuracy: 63.92 

Round  24, Train loss: 1.808, Test loss: 1.830, Test accuracy: 63.75 

Round  25, Train loss: 1.627, Test loss: 1.832, Test accuracy: 63.27 

Round  26, Train loss: 1.714, Test loss: 1.830, Test accuracy: 63.60 

Round  27, Train loss: 1.895, Test loss: 1.825, Test accuracy: 64.35 

Round  28, Train loss: 1.799, Test loss: 1.823, Test accuracy: 64.45 

Round  29, Train loss: 1.785, Test loss: 1.817, Test accuracy: 64.65 

Round  30, Train loss: 1.853, Test loss: 1.817, Test accuracy: 64.92 

Round  31, Train loss: 1.700, Test loss: 1.808, Test accuracy: 65.92 

Round  32, Train loss: 1.737, Test loss: 1.810, Test accuracy: 65.88 

Round  33, Train loss: 1.670, Test loss: 1.806, Test accuracy: 66.20 

Round  34, Train loss: 1.767, Test loss: 1.808, Test accuracy: 66.00 

Round  35, Train loss: 1.684, Test loss: 1.805, Test accuracy: 66.08 

Round  36, Train loss: 1.785, Test loss: 1.803, Test accuracy: 66.65 

Round  37, Train loss: 1.686, Test loss: 1.793, Test accuracy: 67.67 

Round  38, Train loss: 1.726, Test loss: 1.794, Test accuracy: 67.27 

Round  39, Train loss: 1.719, Test loss: 1.790, Test accuracy: 67.60 

Round  40, Train loss: 1.726, Test loss: 1.788, Test accuracy: 67.98 

Round  41, Train loss: 1.720, Test loss: 1.789, Test accuracy: 67.50 

Round  42, Train loss: 1.670, Test loss: 1.784, Test accuracy: 68.33 

Round  43, Train loss: 1.769, Test loss: 1.783, Test accuracy: 68.40 

Round  44, Train loss: 1.628, Test loss: 1.777, Test accuracy: 69.10 

Round  45, Train loss: 1.872, Test loss: 1.780, Test accuracy: 68.93 

Round  46, Train loss: 1.766, Test loss: 1.777, Test accuracy: 69.02 

Round  47, Train loss: 1.716, Test loss: 1.783, Test accuracy: 68.50 

Round  48, Train loss: 1.698, Test loss: 1.788, Test accuracy: 67.92 

Round  49, Train loss: 1.724, Test loss: 1.784, Test accuracy: 68.40 

Final Round, Train loss: 1.737, Test loss: 1.764, Test accuracy: 70.07 

Average accuracy final 10 rounds: 68.40833333333333 

247.10686898231506
[1.4369802474975586, 1.9614131450653076, 2.486664295196533, 3.0100135803222656, 3.532241106033325, 4.054007291793823, 4.580683469772339, 5.1070475578308105, 5.627989292144775, 6.151782989501953, 6.6721296310424805, 7.193018198013306, 7.714235305786133, 8.236607074737549, 8.759159803390503, 9.290247917175293, 9.811094760894775, 10.333296060562134, 10.855295419692993, 11.380057573318481, 11.907514333724976, 12.43108081817627, 12.95298957824707, 13.473329067230225, 13.99673056602478, 14.518142461776733, 15.040155410766602, 15.565106868743896, 16.087592601776123, 16.608253717422485, 17.12893033027649, 17.65128779411316, 18.17220902442932, 18.692068099975586, 19.214299201965332, 19.737807273864746, 20.2601261138916, 20.78253197669983, 21.304425954818726, 21.829169273376465, 22.352323293685913, 22.874847412109375, 23.398762226104736, 23.92268419265747, 24.445536851882935, 24.970673322677612, 25.49418568611145, 26.015278100967407, 26.536216020584106, 27.054413557052612, 27.96717071533203]
[33.333333333333336, 33.333333333333336, 33.333333333333336, 33.333333333333336, 33.13333333333333, 39.15, 41.7, 46.516666666666666, 47.5, 47.3, 49.4, 51.68333333333333, 53.55, 54.15, 56.483333333333334, 57.333333333333336, 58.266666666666666, 59.63333333333333, 61.15, 61.333333333333336, 61.233333333333334, 63.166666666666664, 63.53333333333333, 63.916666666666664, 63.75, 63.266666666666666, 63.6, 64.35, 64.45, 64.65, 64.91666666666667, 65.91666666666667, 65.88333333333334, 66.2, 66.0, 66.08333333333333, 66.65, 67.66666666666667, 67.26666666666667, 67.6, 67.98333333333333, 67.5, 68.33333333333333, 68.4, 69.1, 68.93333333333334, 69.01666666666667, 68.5, 67.91666666666667, 68.4, 70.06666666666666]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
401408
401920
532992
533248
549632
549696
550336
550346
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Traceback (most recent call last):
  File "main_fedpac_k_means.py", line 291, in <module>
    w_local, loss, indd, class_center_local, class_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_grob_local, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 1492, in train
    sub_clc = self.features - torch.from_numpy(class_center_batch)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
Round   0, Train loss: 2.296, Test loss: 2.273, Test accuracy: 37.43
Round   1, Train loss: 2.207, Test loss: 2.096, Test accuracy: 36.57
Round   2, Train loss: 2.005, Test loss: 2.064, Test accuracy: 35.35
Round   3, Train loss: 1.744, Test loss: 2.020, Test accuracy: 43.70
Round   4, Train loss: 1.661, Test loss: 2.008, Test accuracy: 43.85
Round   5, Train loss: 1.693, Test loss: 2.018, Test accuracy: 43.12
Round   6, Train loss: 1.539, Test loss: 1.987, Test accuracy: 47.78
Round   7, Train loss: 1.647, Test loss: 2.001, Test accuracy: 45.77
Round   8, Train loss: 1.583, Test loss: 1.996, Test accuracy: 46.43
Round   9, Train loss: 1.562, Test loss: 2.000, Test accuracy: 45.38
Round  10, Train loss: 1.564, Test loss: 2.033, Test accuracy: 41.58
Round  11, Train loss: 1.555, Test loss: 2.019, Test accuracy: 43.00
Round  12, Train loss: 1.597, Test loss: 1.983, Test accuracy: 47.33
Round  13, Train loss: 1.557, Test loss: 1.994, Test accuracy: 46.43
Round  14, Train loss: 1.559, Test loss: 2.011, Test accuracy: 43.97
Round  15, Train loss: 1.540, Test loss: 1.997, Test accuracy: 46.10
Round  16, Train loss: 1.596, Test loss: 1.990, Test accuracy: 47.07
Round  17, Train loss: 1.496, Test loss: 1.964, Test accuracy: 49.82
Round  18, Train loss: 1.491, Test loss: 1.991, Test accuracy: 45.80
Round  19, Train loss: 1.487, Test loss: 1.977, Test accuracy: 48.18
Round  20, Train loss: 1.539, Test loss: 1.985, Test accuracy: 46.70
Round  21, Train loss: 1.538, Test loss: 1.967, Test accuracy: 49.50
Round  22, Train loss: 1.535, Test loss: 1.957, Test accuracy: 50.32
Round  23, Train loss: 1.536, Test loss: 1.991, Test accuracy: 46.17
Round  24, Train loss: 1.549, Test loss: 1.976, Test accuracy: 48.20
Round  25, Train loss: 1.589, Test loss: 1.972, Test accuracy: 48.45
Round  26, Train loss: 1.533, Test loss: 1.966, Test accuracy: 49.62
Round  27, Train loss: 1.486, Test loss: 2.047, Test accuracy: 39.87
Round  28, Train loss: 1.481, Test loss: 2.025, Test accuracy: 41.98
Round  29, Train loss: 1.482, Test loss: 1.968, Test accuracy: 48.80
Round  30, Train loss: 1.545, Test loss: 1.979, Test accuracy: 47.88
Round  31, Train loss: 1.492, Test loss: 1.977, Test accuracy: 48.05
Round  32, Train loss: 1.482, Test loss: 1.988, Test accuracy: 46.47
Round  33, Train loss: 1.582, Test loss: 1.977, Test accuracy: 47.65
Round  34, Train loss: 1.533, Test loss: 2.019, Test accuracy: 43.15
Round  35, Train loss: 1.550, Test loss: 1.973, Test accuracy: 48.17
Round  36, Train loss: 1.477, Test loss: 1.974, Test accuracy: 47.88
Round  37, Train loss: 1.483, Test loss: 1.968, Test accuracy: 48.72
Round  38, Train loss: 1.487, Test loss: 1.968, Test accuracy: 49.23
Round  39, Train loss: 1.476, Test loss: 1.958, Test accuracy: 50.23
Round  40, Train loss: 1.476, Test loss: 2.016, Test accuracy: 43.28
Round  41, Train loss: 1.482, Test loss: 1.949, Test accuracy: 50.78
Round  42, Train loss: 1.534, Test loss: 1.956, Test accuracy: 50.13
Round  43, Train loss: 1.483, Test loss: 1.949, Test accuracy: 51.03
Round  44, Train loss: 1.521, Test loss: 1.983, Test accuracy: 47.27
Round  45, Train loss: 1.481, Test loss: 1.962, Test accuracy: 49.93
Round  46, Train loss: 1.477, Test loss: 2.000, Test accuracy: 45.77
Round  47, Train loss: 1.478, Test loss: 1.960, Test accuracy: 49.62
Round  48, Train loss: 1.476, Test loss: 1.947, Test accuracy: 51.13
Round  49, Train loss: 1.475, Test loss: 1.968, Test accuracy: 48.22
Final Round, Train loss: 1.475, Test loss: 1.949, Test accuracy: 51.03
Average accuracy final 10 rounds: 48.71666666666666
570.6040472984314
[2.4953839778900146, 4.098268508911133, 5.67562460899353, 7.258574485778809, 8.851356506347656, 10.42192530632019, 11.995174407958984, 13.564730882644653, 15.138065099716187, 16.7148699760437, 18.29801344871521, 19.87029719352722, 21.440072774887085, 23.039628982543945, 24.617265701293945, 26.19216227531433, 27.669488191604614, 29.13444495201111, 30.61042284965515, 32.09305286407471, 33.58289408683777, 35.04782295227051, 36.551836252212524, 38.027666330337524, 39.506221294403076, 41.06264042854309, 42.62925696372986, 44.22955775260925, 45.83026075363159, 47.41610145568848, 48.99572134017944, 50.572301626205444, 52.15901279449463, 53.74075698852539, 55.32449507713318, 56.90463638305664, 58.48389649391174, 60.06604266166687, 61.65169954299927, 63.23104786872864, 64.8113226890564, 66.39182710647583, 67.97217512130737, 69.55160355567932, 71.13564610481262, 72.7184476852417, 74.29775214195251, 75.87844634056091, 77.46220517158508, 79.04082417488098, 80.91575598716736]
[37.43333333333333, 36.56666666666667, 35.35, 43.7, 43.85, 43.11666666666667, 47.78333333333333, 45.766666666666666, 46.43333333333333, 45.38333333333333, 41.583333333333336, 43.0, 47.333333333333336, 46.43333333333333, 43.96666666666667, 46.1, 47.06666666666667, 49.81666666666667, 45.8, 48.18333333333333, 46.7, 49.5, 50.31666666666667, 46.166666666666664, 48.2, 48.45, 49.61666666666667, 39.86666666666667, 41.983333333333334, 48.8, 47.88333333333333, 48.05, 46.46666666666667, 47.65, 43.15, 48.166666666666664, 47.88333333333333, 48.71666666666667, 49.233333333333334, 50.233333333333334, 43.28333333333333, 50.78333333333333, 50.13333333333333, 51.03333333333333, 47.266666666666666, 49.93333333333333, 45.766666666666666, 49.61666666666667, 51.13333333333333, 48.21666666666667, 51.03333333333333]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
Round   0, Train loss: 1.463, Test loss: 2.126, Test accuracy: 49.85
Round   1, Train loss: 1.274, Test loss: 1.965, Test accuracy: 66.47
Round   2, Train loss: 1.220, Test loss: 1.890, Test accuracy: 71.57
Round   3, Train loss: 1.249, Test loss: 1.812, Test accuracy: 79.65
Round   4, Train loss: 1.187, Test loss: 1.766, Test accuracy: 82.57
Round   5, Train loss: 1.195, Test loss: 1.751, Test accuracy: 82.45
Round   6, Train loss: 1.199, Test loss: 1.709, Test accuracy: 85.48
Round   7, Train loss: 1.119, Test loss: 1.693, Test accuracy: 86.05
Round   8, Train loss: 1.149, Test loss: 1.687, Test accuracy: 85.65
Round   9, Train loss: 1.185, Test loss: 1.671, Test accuracy: 87.12
Round  10, Train loss: 1.172, Test loss: 1.641, Test accuracy: 89.30
Round  11, Train loss: 1.108, Test loss: 1.634, Test accuracy: 89.60
Round  12, Train loss: 1.107, Test loss: 1.629, Test accuracy: 89.72
Round  13, Train loss: 1.150, Test loss: 1.618, Test accuracy: 89.93
Round  14, Train loss: 1.180, Test loss: 1.607, Test accuracy: 90.87
Round  15, Train loss: 1.129, Test loss: 1.593, Test accuracy: 91.93
Round  16, Train loss: 1.105, Test loss: 1.587, Test accuracy: 92.10
Round  17, Train loss: 1.102, Test loss: 1.583, Test accuracy: 92.05
Round  18, Train loss: 1.100, Test loss: 1.580, Test accuracy: 91.82
Round  19, Train loss: 1.103, Test loss: 1.576, Test accuracy: 91.98
Round  20, Train loss: 1.100, Test loss: 1.575, Test accuracy: 91.87
Round  21, Train loss: 1.101, Test loss: 1.574, Test accuracy: 91.87
Round  22, Train loss: 1.141, Test loss: 1.573, Test accuracy: 91.53
Round  23, Train loss: 1.105, Test loss: 1.569, Test accuracy: 91.85
Round  24, Train loss: 1.105, Test loss: 1.559, Test accuracy: 92.88
Round  25, Train loss: 1.105, Test loss: 1.559, Test accuracy: 92.93
Round  26, Train loss: 1.100, Test loss: 1.555, Test accuracy: 93.15
Round  27, Train loss: 1.104, Test loss: 1.554, Test accuracy: 93.17
Round  28, Train loss: 1.102, Test loss: 1.552, Test accuracy: 93.15
Round  29, Train loss: 1.142, Test loss: 1.550, Test accuracy: 93.17
Round  30, Train loss: 1.116, Test loss: 1.544, Test accuracy: 93.70
Round  31, Train loss: 1.104, Test loss: 1.538, Test accuracy: 94.35
Round  32, Train loss: 1.102, Test loss: 1.533, Test accuracy: 94.67
Round  33, Train loss: 1.100, Test loss: 1.532, Test accuracy: 94.75
Round  34, Train loss: 1.103, Test loss: 1.532, Test accuracy: 94.78
Round  35, Train loss: 1.104, Test loss: 1.531, Test accuracy: 94.78
Round  36, Train loss: 1.101, Test loss: 1.531, Test accuracy: 94.82
Round  37, Train loss: 1.099, Test loss: 1.529, Test accuracy: 94.85
Round  38, Train loss: 1.101, Test loss: 1.528, Test accuracy: 94.75
Round  39, Train loss: 1.101, Test loss: 1.526, Test accuracy: 94.93
Round  40, Train loss: 1.105, Test loss: 1.527, Test accuracy: 95.02
Round  41, Train loss: 1.103, Test loss: 1.527, Test accuracy: 94.95
Round  42, Train loss: 1.099, Test loss: 1.525, Test accuracy: 94.95
Round  43, Train loss: 1.101, Test loss: 1.524, Test accuracy: 94.90
Round  44, Train loss: 1.100, Test loss: 1.525, Test accuracy: 94.82
Round  45, Train loss: 1.101, Test loss: 1.525, Test accuracy: 94.72
Round  46, Train loss: 1.101, Test loss: 1.525, Test accuracy: 94.58
Round  47, Train loss: 1.100, Test loss: 1.524, Test accuracy: 94.65
Round  48, Train loss: 1.100, Test loss: 1.525, Test accuracy: 94.47
Round  49, Train loss: 1.103, Test loss: 1.524, Test accuracy: 94.48
Final Round, Train loss: 1.100, Test loss: 1.523, Test accuracy: 94.62
Average accuracy final 10 rounds: 94.75333333333334
456.2081034183502
[]
[49.85, 66.46666666666667, 71.56666666666666, 79.65, 82.56666666666666, 82.45, 85.48333333333333, 86.05, 85.65, 87.11666666666666, 89.3, 89.6, 89.71666666666667, 89.93333333333334, 90.86666666666666, 91.93333333333334, 92.1, 92.05, 91.81666666666666, 91.98333333333333, 91.86666666666666, 91.86666666666666, 91.53333333333333, 91.85, 92.88333333333334, 92.93333333333334, 93.15, 93.16666666666667, 93.15, 93.16666666666667, 93.7, 94.35, 94.66666666666667, 94.75, 94.78333333333333, 94.78333333333333, 94.81666666666666, 94.85, 94.75, 94.93333333333334, 95.01666666666667, 94.95, 94.95, 94.9, 94.81666666666666, 94.71666666666667, 94.58333333333333, 94.65, 94.46666666666667, 94.48333333333333, 94.61666666666666]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.285, Test loss: 2.285, Test accuracy: 32.72
Round   0: Global train loss: 2.285, Global test loss: 2.300, Global test accuracy: 31.78
Round   1, Train loss: 2.230, Test loss: 2.233, Test accuracy: 33.33
Round   1: Global train loss: 2.230, Global test loss: 2.296, Global test accuracy: 33.35
Round   2, Train loss: 2.161, Test loss: 2.211, Test accuracy: 30.47
Round   2: Global train loss: 2.161, Global test loss: 2.295, Global test accuracy: 33.35
Round   3, Train loss: 2.227, Test loss: 2.245, Test accuracy: 24.57
Round   3: Global train loss: 2.227, Global test loss: 2.296, Global test accuracy: 33.35
Round   4, Train loss: 2.030, Test loss: 2.206, Test accuracy: 29.22
Round   4: Global train loss: 2.030, Global test loss: 2.293, Global test accuracy: 33.35
Round   5, Train loss: 1.825, Test loss: 2.185, Test accuracy: 31.57
Round   5: Global train loss: 1.825, Global test loss: 2.293, Global test accuracy: 33.33
Round   6, Train loss: 1.831, Test loss: 2.129, Test accuracy: 38.87
Round   6: Global train loss: 1.831, Global test loss: 2.289, Global test accuracy: 33.32
Round   7, Train loss: 2.076, Test loss: 2.150, Test accuracy: 37.05
Round   7: Global train loss: 2.076, Global test loss: 2.291, Global test accuracy: 33.33
Round   8, Train loss: 1.761, Test loss: 2.120, Test accuracy: 41.98
Round   8: Global train loss: 1.761, Global test loss: 2.290, Global test accuracy: 33.33
Round   9, Train loss: 1.535, Test loss: 2.049, Test accuracy: 48.07
Round   9: Global train loss: 1.535, Global test loss: 2.287, Global test accuracy: 33.75
Round  10, Train loss: 1.460, Test loss: 2.051, Test accuracy: 51.60
Round  10: Global train loss: 1.460, Global test loss: 2.287, Global test accuracy: 34.10
Round  11, Train loss: 1.518, Test loss: 1.969, Test accuracy: 60.62
Round  11: Global train loss: 1.518, Global test loss: 2.282, Global test accuracy: 33.27
Round  12, Train loss: 0.968, Test loss: 1.944, Test accuracy: 62.53
Round  12: Global train loss: 0.968, Global test loss: 2.278, Global test accuracy: 34.18
Round  13, Train loss: 1.269, Test loss: 1.931, Test accuracy: 66.33
Round  13: Global train loss: 1.269, Global test loss: 2.274, Global test accuracy: 34.05
Round  14, Train loss: 0.243, Test loss: 1.814, Test accuracy: 74.00
Round  14: Global train loss: 0.243, Global test loss: 2.256, Global test accuracy: 35.05
Round  15, Train loss: 1.323, Test loss: 1.896, Test accuracy: 65.90
Round  15: Global train loss: 1.323, Global test loss: 2.256, Global test accuracy: 33.82
Round  16, Train loss: 1.197, Test loss: 1.998, Test accuracy: 57.98
Round  16: Global train loss: 1.197, Global test loss: 2.264, Global test accuracy: 33.05
Round  17, Train loss: 0.462, Test loss: 1.927, Test accuracy: 64.10
Round  17: Global train loss: 0.462, Global test loss: 2.259, Global test accuracy: 35.38
Round  18, Train loss: -0.091, Test loss: 1.852, Test accuracy: 71.00
Round  18: Global train loss: -0.091, Global test loss: 2.249, Global test accuracy: 35.93
Round  19, Train loss: -0.435, Test loss: 1.747, Test accuracy: 75.77
Round  19: Global train loss: -0.435, Global test loss: 2.217, Global test accuracy: 38.10
Round  20, Train loss: 0.817, Test loss: 1.802, Test accuracy: 73.37
Round  20: Global train loss: 0.817, Global test loss: 2.217, Global test accuracy: 36.87
Round  21, Train loss: 0.299, Test loss: 1.757, Test accuracy: 74.95
Round  21: Global train loss: 0.299, Global test loss: 2.202, Global test accuracy: 36.55
Round  22, Train loss: 0.574, Test loss: 1.811, Test accuracy: 70.88
Round  22: Global train loss: 0.574, Global test loss: 2.203, Global test accuracy: 34.73
Round  23, Train loss: -0.241, Test loss: 1.814, Test accuracy: 70.27
Round  23: Global train loss: -0.241, Global test loss: 2.205, Global test accuracy: 34.52
Round  24, Train loss: 0.237, Test loss: 1.817, Test accuracy: 70.85
Round  24: Global train loss: 0.237, Global test loss: 2.207, Global test accuracy: 36.08
Round  25, Train loss: -0.975, Test loss: 1.734, Test accuracy: 77.98
Round  25: Global train loss: -0.975, Global test loss: 2.188, Global test accuracy: 34.00
Round  26, Train loss: -0.787, Test loss: 1.721, Test accuracy: 79.00
Round  26: Global train loss: -0.787, Global test loss: 2.180, Global test accuracy: 35.63
Round  27, Train loss: -0.800, Test loss: 1.654, Test accuracy: 82.85
Round  27: Global train loss: -0.800, Global test loss: 2.168, Global test accuracy: 33.20
Round  28, Train loss: -0.686, Test loss: 1.633, Test accuracy: 84.20
Round  28: Global train loss: -0.686, Global test loss: 2.157, Global test accuracy: 32.68
Round  29, Train loss: -0.693, Test loss: 1.619, Test accuracy: 85.53
Round  29: Global train loss: -0.693, Global test loss: 2.149, Global test accuracy: 32.22
Round  30, Train loss: -1.400, Test loss: 1.599, Test accuracy: 87.12
Round  30: Global train loss: -1.400, Global test loss: 2.134, Global test accuracy: 31.98
Round  31, Train loss: -0.900, Test loss: 1.598, Test accuracy: 88.20
Round  31: Global train loss: -0.900, Global test loss: 2.134, Global test accuracy: 32.07
Round  32, Train loss: -1.878, Test loss: 1.584, Test accuracy: 89.25
Round  32: Global train loss: -1.878, Global test loss: 2.128, Global test accuracy: 32.40
Round  33, Train loss: -2.547, Test loss: 1.556, Test accuracy: 91.18
Round  33: Global train loss: -2.547, Global test loss: 2.121, Global test accuracy: 30.87
Round  34, Train loss: -2.810, Test loss: 1.535, Test accuracy: 93.05
Round  34: Global train loss: -2.810, Global test loss: 2.109, Global test accuracy: 30.62
Round  35, Train loss: -0.978, Test loss: 1.539, Test accuracy: 92.88
Round  35: Global train loss: -0.978, Global test loss: 2.110, Global test accuracy: 30.42
Round  36, Train loss: -2.061, Test loss: 1.553, Test accuracy: 91.32
Round  36: Global train loss: -2.061, Global test loss: 2.108, Global test accuracy: 30.33
Round  37, Train loss: -1.363, Test loss: 1.536, Test accuracy: 92.92
Round  37: Global train loss: -1.363, Global test loss: 2.106, Global test accuracy: 31.28
Round  38, Train loss: -2.552, Test loss: 1.521, Test accuracy: 94.37
Round  38: Global train loss: -2.552, Global test loss: 2.102, Global test accuracy: 30.68
Round  39, Train loss: -2.032, Test loss: 1.524, Test accuracy: 94.22
Round  39: Global train loss: -2.032, Global test loss: 2.100, Global test accuracy: 32.10
Round  40, Train loss: -2.051, Test loss: 1.526, Test accuracy: 93.92
Round  40: Global train loss: -2.051, Global test loss: 2.099, Global test accuracy: 32.95
Round  41, Train loss: -2.903, Test loss: 1.524, Test accuracy: 94.00
Round  41: Global train loss: -2.903, Global test loss: 2.096, Global test accuracy: 31.95
Round  42, Train loss: -2.734, Test loss: 1.521, Test accuracy: 94.20
Round  42: Global train loss: -2.734, Global test loss: 2.091, Global test accuracy: 33.87
Round  43, Train loss: -3.362, Test loss: 1.520, Test accuracy: 94.33
Round  43: Global train loss: -3.362, Global test loss: 2.082, Global test accuracy: 36.77
Round  44, Train loss: -3.357, Test loss: 1.516, Test accuracy: 94.58
Round  44: Global train loss: -3.357, Global test loss: 2.072, Global test accuracy: 38.13
Round  45, Train loss: -2.751, Test loss: 1.520, Test accuracy: 94.33
Round  45: Global train loss: -2.751, Global test loss: 2.061, Global test accuracy: 41.45
Round  46, Train loss: -3.285, Test loss: 1.523, Test accuracy: 93.92
Round  46: Global train loss: -3.285, Global test loss: 2.055, Global test accuracy: 43.10
Round  47, Train loss: -2.964, Test loss: 1.521, Test accuracy: 94.08
Round  47: Global train loss: -2.964, Global test loss: 2.053, Global test accuracy: 42.08
Round  48, Train loss: -2.444, Test loss: 1.519, Test accuracy: 94.48
Round  48: Global train loss: -2.444, Global test loss: 2.054, Global test accuracy: 42.70
Round  49, Train loss: -3.370, Test loss: 1.518, Test accuracy: 94.57
Round  49: Global train loss: -3.370, Global test loss: 2.048, Global test accuracy: 43.77
Final Round: Train loss: 1.636, Test loss: 1.573, Test accuracy: 90.23
Final Round: Global train loss: 1.636, Global test loss: 2.041, Global test accuracy: 44.52
Average accuracy final 10 rounds: 94.24166666666666
Average global accuracy final 10 rounds: 38.67666666666667
421.3534734249115
[]
[32.71666666666667, 33.333333333333336, 30.466666666666665, 24.566666666666666, 29.216666666666665, 31.566666666666666, 38.86666666666667, 37.05, 41.983333333333334, 48.06666666666667, 51.6, 60.61666666666667, 62.53333333333333, 66.33333333333333, 74.0, 65.9, 57.983333333333334, 64.1, 71.0, 75.76666666666667, 73.36666666666666, 74.95, 70.88333333333334, 70.26666666666667, 70.85, 77.98333333333333, 79.0, 82.85, 84.2, 85.53333333333333, 87.11666666666666, 88.2, 89.25, 91.18333333333334, 93.05, 92.88333333333334, 91.31666666666666, 92.91666666666667, 94.36666666666666, 94.21666666666667, 93.91666666666667, 94.0, 94.2, 94.33333333333333, 94.58333333333333, 94.33333333333333, 93.91666666666667, 94.08333333333333, 94.48333333333333, 94.56666666666666, 90.23333333333333]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.301, Test loss: 2.301, Test accuracy: 27.67 

Round   0, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 27.62 

Round   1, Train loss: 2.301, Test loss: 2.301, Test accuracy: 28.18 

Round   1, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 28.22 

Round   2, Train loss: 2.301, Test loss: 2.301, Test accuracy: 28.60 

Round   2, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 28.73 

Round   3, Train loss: 2.301, Test loss: 2.301, Test accuracy: 28.95 

Round   3, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 29.17 

Round   4, Train loss: 2.300, Test loss: 2.301, Test accuracy: 29.28 

Round   4, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 29.70 

Round   5, Train loss: 2.300, Test loss: 2.301, Test accuracy: 29.63 

Round   5, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 30.15 

Round   6, Train loss: 2.300, Test loss: 2.301, Test accuracy: 30.08 

Round   6, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 30.65 

Round   7, Train loss: 2.300, Test loss: 2.300, Test accuracy: 30.37 

Round   7, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 30.95 

Round   8, Train loss: 2.300, Test loss: 2.300, Test accuracy: 30.67 

Round   8, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 31.33 

Round   9, Train loss: 2.299, Test loss: 2.300, Test accuracy: 30.92 

Round   9, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 31.62 

Round  10, Train loss: 2.299, Test loss: 2.300, Test accuracy: 31.10 

Round  10, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 31.85 

Round  11, Train loss: 2.299, Test loss: 2.300, Test accuracy: 31.60 

Round  11, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 32.00 

Round  12, Train loss: 2.299, Test loss: 2.300, Test accuracy: 31.85 

Round  12, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 32.22 

Round  13, Train loss: 2.299, Test loss: 2.300, Test accuracy: 32.13 

Round  13, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 32.40 

Round  14, Train loss: 2.299, Test loss: 2.299, Test accuracy: 32.37 

Round  14, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 32.57 

Round  15, Train loss: 2.299, Test loss: 2.299, Test accuracy: 32.52 

Round  15, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 32.72 

Round  16, Train loss: 2.299, Test loss: 2.299, Test accuracy: 32.55 

Round  16, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 32.82 

Round  17, Train loss: 2.299, Test loss: 2.299, Test accuracy: 32.62 

Round  17, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 32.88 

Round  18, Train loss: 2.298, Test loss: 2.299, Test accuracy: 32.70 

Round  18, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 32.90 

Round  19, Train loss: 2.298, Test loss: 2.299, Test accuracy: 32.83 

Round  19, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 33.03 

Round  20, Train loss: 2.298, Test loss: 2.299, Test accuracy: 32.85 

Round  20, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 33.05 

Round  21, Train loss: 2.298, Test loss: 2.299, Test accuracy: 32.85 

Round  21, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 33.10 

Round  22, Train loss: 2.298, Test loss: 2.298, Test accuracy: 32.93 

Round  22, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 33.15 

Round  23, Train loss: 2.298, Test loss: 2.298, Test accuracy: 33.07 

Round  23, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 33.17 

Round  24, Train loss: 2.297, Test loss: 2.298, Test accuracy: 33.15 

Round  24, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 33.22 

Round  25, Train loss: 2.297, Test loss: 2.298, Test accuracy: 33.18 

Round  25, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 33.23 

Round  26, Train loss: 2.297, Test loss: 2.298, Test accuracy: 33.22 

Round  26, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 33.25 

Round  27, Train loss: 2.297, Test loss: 2.298, Test accuracy: 33.23 

Round  27, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 33.25 

Round  28, Train loss: 2.297, Test loss: 2.297, Test accuracy: 33.27 

Round  28, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 33.27 

Round  29, Train loss: 2.297, Test loss: 2.297, Test accuracy: 33.27 

Round  29, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 33.28 

Round  30, Train loss: 2.297, Test loss: 2.297, Test accuracy: 33.27 

Round  30, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 33.32 

Round  31, Train loss: 2.296, Test loss: 2.297, Test accuracy: 33.28 

Round  31, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 33.32 

Round  32, Train loss: 2.296, Test loss: 2.297, Test accuracy: 33.30 

Round  32, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 33.32 

Round  33, Train loss: 2.296, Test loss: 2.297, Test accuracy: 33.30 

Round  33, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 33.32 

Round  34, Train loss: 2.296, Test loss: 2.297, Test accuracy: 33.30 

Round  34, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 33.33 

Round  35, Train loss: 2.296, Test loss: 2.296, Test accuracy: 33.30 

Round  35, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 33.33 

Round  36, Train loss: 2.295, Test loss: 2.296, Test accuracy: 33.32 

Round  36, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 33.33 

Round  37, Train loss: 2.296, Test loss: 2.296, Test accuracy: 33.32 

Round  37, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 33.33 

Round  38, Train loss: 2.295, Test loss: 2.296, Test accuracy: 33.32 

Round  38, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 33.33 

Round  39, Train loss: 2.295, Test loss: 2.296, Test accuracy: 33.32 

Round  39, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 33.33 

Round  40, Train loss: 2.295, Test loss: 2.296, Test accuracy: 33.33 

Round  40, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 33.33 

Round  41, Train loss: 2.295, Test loss: 2.296, Test accuracy: 33.33 

Round  41, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 33.33 

Round  42, Train loss: 2.295, Test loss: 2.296, Test accuracy: 33.33 

Round  42, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 33.33 

Round  43, Train loss: 2.295, Test loss: 2.295, Test accuracy: 33.33 

Round  43, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 33.33 

Round  44, Train loss: 2.294, Test loss: 2.295, Test accuracy: 33.33 

Round  44, Global train loss: 2.294, Global test loss: 2.295, Global test accuracy: 33.33 

Round  45, Train loss: 2.294, Test loss: 2.295, Test accuracy: 33.33 

Round  45, Global train loss: 2.294, Global test loss: 2.295, Global test accuracy: 33.33 

Round  46, Train loss: 2.294, Test loss: 2.295, Test accuracy: 33.33 

Round  46, Global train loss: 2.294, Global test loss: 2.295, Global test accuracy: 33.33 

Round  47, Train loss: 2.294, Test loss: 2.295, Test accuracy: 33.33 

Round  47, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 33.33 

Round  48, Train loss: 2.294, Test loss: 2.295, Test accuracy: 33.33 

Round  48, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 33.33 

Round  49, Train loss: 2.294, Test loss: 2.294, Test accuracy: 33.33 

Round  49, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 33.33 

Final Round, Train loss: 2.293, Test loss: 2.294, Test accuracy: 33.33 

Final Round, Global train loss: 2.293, Global test loss: 2.294, Global test accuracy: 33.33 

Average accuracy final 10 rounds: 33.33333333333333 

Average global accuracy final 10 rounds: 33.33333333333333 

371.0343461036682
[1.5365068912506104, 2.1897084712982178, 2.8897359371185303, 3.555690288543701, 4.2212889194488525, 4.885627031326294, 5.547510385513306, 6.2117767333984375, 6.876713752746582, 7.53911280632019, 8.203703165054321, 8.86914849281311, 9.53298020362854, 10.194472551345825, 10.858057498931885, 11.522914171218872, 12.187278985977173, 12.854050397872925, 13.515647172927856, 14.17955994606018, 14.846208333969116, 15.511622428894043, 16.218415021896362, 16.890624523162842, 17.558484077453613, 18.225326538085938, 18.892736673355103, 19.56251287460327, 20.229512929916382, 20.89768886566162, 21.567152738571167, 22.234182119369507, 22.903990030288696, 23.57039737701416, 24.240357160568237, 24.908669471740723, 25.57466220855713, 26.240925312042236, 26.905465841293335, 27.57107400894165, 28.235509872436523, 28.908766508102417, 29.57864809036255, 30.244800567626953, 30.9127676486969, 31.58173418045044, 32.24937033653259, 32.91710424423218, 33.580599784851074, 34.249075174331665, 35.58236789703369]
[27.666666666666668, 28.183333333333334, 28.6, 28.95, 29.283333333333335, 29.633333333333333, 30.083333333333332, 30.366666666666667, 30.666666666666668, 30.916666666666668, 31.1, 31.6, 31.85, 32.13333333333333, 32.36666666666667, 32.516666666666666, 32.55, 32.61666666666667, 32.7, 32.833333333333336, 32.85, 32.85, 32.93333333333333, 33.06666666666667, 33.15, 33.18333333333333, 33.21666666666667, 33.233333333333334, 33.266666666666666, 33.266666666666666, 33.266666666666666, 33.28333333333333, 33.3, 33.3, 33.3, 33.3, 33.31666666666667, 33.31666666666667, 33.31666666666667, 33.31666666666667, 33.333333333333336, 33.333333333333336, 33.333333333333336, 33.333333333333336, 33.333333333333336, 33.333333333333336, 33.333333333333336, 33.333333333333336, 33.333333333333336, 33.333333333333336, 33.333333333333336]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 1, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.234, Test loss: 2.140, Test accuracy: 37.32 

Round   0, Global train loss: 2.234, Global test loss: 2.161, Global test accuracy: 33.33 

Round   1, Train loss: 1.844, Test loss: 1.943, Test accuracy: 54.75 

Round   1, Global train loss: 1.844, Global test loss: 2.060, Global test accuracy: 43.08 

Round   2, Train loss: 1.636, Test loss: 1.841, Test accuracy: 63.60 

Round   2, Global train loss: 1.636, Global test loss: 2.001, Global test accuracy: 47.27 

Round   3, Train loss: 1.569, Test loss: 1.796, Test accuracy: 67.83 

Round   3, Global train loss: 1.569, Global test loss: 2.003, Global test accuracy: 47.00 

Round   4, Train loss: 1.629, Test loss: 1.729, Test accuracy: 74.35 

Round   4, Global train loss: 1.629, Global test loss: 1.963, Global test accuracy: 49.47 

Round   5, Train loss: 1.588, Test loss: 1.674, Test accuracy: 80.22 

Round   5, Global train loss: 1.588, Global test loss: 1.968, Global test accuracy: 49.50 

Round   6, Train loss: 1.615, Test loss: 1.611, Test accuracy: 87.35 

Round   6, Global train loss: 1.615, Global test loss: 2.033, Global test accuracy: 40.93 

Round   7, Train loss: 1.541, Test loss: 1.574, Test accuracy: 90.53 

Round   7, Global train loss: 1.541, Global test loss: 2.037, Global test accuracy: 42.32 

Round   8, Train loss: 1.563, Test loss: 1.560, Test accuracy: 91.82 

Round   8, Global train loss: 1.563, Global test loss: 1.974, Global test accuracy: 49.25 

Round   9, Train loss: 1.537, Test loss: 1.556, Test accuracy: 91.92 

Round   9, Global train loss: 1.537, Global test loss: 2.032, Global test accuracy: 42.17 

Round  10, Train loss: 1.532, Test loss: 1.554, Test accuracy: 91.93 

Round  10, Global train loss: 1.532, Global test loss: 2.004, Global test accuracy: 46.18 

Round  11, Train loss: 1.475, Test loss: 1.553, Test accuracy: 91.88 

Round  11, Global train loss: 1.475, Global test loss: 2.009, Global test accuracy: 45.30 

Round  12, Train loss: 1.477, Test loss: 1.551, Test accuracy: 91.90 

Round  12, Global train loss: 1.477, Global test loss: 1.993, Global test accuracy: 48.72 

Round  13, Train loss: 1.530, Test loss: 1.543, Test accuracy: 92.88 

Round  13, Global train loss: 1.530, Global test loss: 1.948, Global test accuracy: 51.48 

Round  14, Train loss: 1.541, Test loss: 1.534, Test accuracy: 93.58 

Round  14, Global train loss: 1.541, Global test loss: 1.979, Global test accuracy: 49.82 

Round  15, Train loss: 1.530, Test loss: 1.533, Test accuracy: 93.63 

Round  15, Global train loss: 1.530, Global test loss: 2.010, Global test accuracy: 46.03 

Round  16, Train loss: 1.472, Test loss: 1.532, Test accuracy: 93.73 

Round  16, Global train loss: 1.472, Global test loss: 2.004, Global test accuracy: 46.38 

Round  17, Train loss: 1.467, Test loss: 1.531, Test accuracy: 93.68 

Round  17, Global train loss: 1.467, Global test loss: 1.976, Global test accuracy: 50.53 

Round  18, Train loss: 1.468, Test loss: 1.531, Test accuracy: 93.70 

Round  18, Global train loss: 1.468, Global test loss: 2.020, Global test accuracy: 43.15 

Round  19, Train loss: 1.471, Test loss: 1.530, Test accuracy: 93.77 

Round  19, Global train loss: 1.471, Global test loss: 1.964, Global test accuracy: 49.00 

Round  20, Train loss: 1.467, Test loss: 1.530, Test accuracy: 93.78 

Round  20, Global train loss: 1.467, Global test loss: 1.956, Global test accuracy: 49.87 

Round  21, Train loss: 1.524, Test loss: 1.530, Test accuracy: 93.73 

Round  21, Global train loss: 1.524, Global test loss: 2.067, Global test accuracy: 37.10 

Round  22, Train loss: 1.468, Test loss: 1.529, Test accuracy: 93.75 

Round  22, Global train loss: 1.468, Global test loss: 2.041, Global test accuracy: 40.37 

Round  23, Train loss: 1.466, Test loss: 1.529, Test accuracy: 93.73 

Round  23, Global train loss: 1.466, Global test loss: 1.992, Global test accuracy: 46.42 

Round  24, Train loss: 1.522, Test loss: 1.529, Test accuracy: 93.70 

Round  24, Global train loss: 1.522, Global test loss: 1.959, Global test accuracy: 50.08 

Round  25, Train loss: 1.466, Test loss: 1.529, Test accuracy: 93.70 

Round  25, Global train loss: 1.466, Global test loss: 2.013, Global test accuracy: 43.82 

Round  26, Train loss: 1.466, Test loss: 1.529, Test accuracy: 93.72 

Round  26, Global train loss: 1.466, Global test loss: 1.991, Global test accuracy: 47.50 

Round  27, Train loss: 1.466, Test loss: 1.529, Test accuracy: 93.70 

Round  27, Global train loss: 1.466, Global test loss: 2.025, Global test accuracy: 41.32 

Round  28, Train loss: 1.468, Test loss: 1.529, Test accuracy: 93.70 

Round  28, Global train loss: 1.468, Global test loss: 1.979, Global test accuracy: 48.20 

Round  29, Train loss: 1.468, Test loss: 1.529, Test accuracy: 93.68 

Round  29, Global train loss: 1.468, Global test loss: 1.961, Global test accuracy: 49.80 

Round  30, Train loss: 1.466, Test loss: 1.529, Test accuracy: 93.67 

Round  30, Global train loss: 1.466, Global test loss: 1.961, Global test accuracy: 50.43 

Round  31, Train loss: 1.468, Test loss: 1.529, Test accuracy: 93.63 

Round  31, Global train loss: 1.468, Global test loss: 1.986, Global test accuracy: 46.63 

Round  32, Train loss: 1.467, Test loss: 1.528, Test accuracy: 93.67 

Round  32, Global train loss: 1.467, Global test loss: 1.991, Global test accuracy: 47.87 

Round  33, Train loss: 1.465, Test loss: 1.528, Test accuracy: 93.67 

Round  33, Global train loss: 1.465, Global test loss: 1.962, Global test accuracy: 50.47 

Round  34, Train loss: 1.465, Test loss: 1.528, Test accuracy: 93.67 

Round  34, Global train loss: 1.465, Global test loss: 2.010, Global test accuracy: 45.37 

Round  35, Train loss: 1.519, Test loss: 1.528, Test accuracy: 93.65 

Round  35, Global train loss: 1.519, Global test loss: 2.020, Global test accuracy: 42.20 

Round  36, Train loss: 1.465, Test loss: 1.528, Test accuracy: 93.63 

Round  36, Global train loss: 1.465, Global test loss: 2.041, Global test accuracy: 39.08 

Round  37, Train loss: 1.465, Test loss: 1.528, Test accuracy: 93.63 

Round  37, Global train loss: 1.465, Global test loss: 1.956, Global test accuracy: 50.98 

Round  38, Train loss: 1.467, Test loss: 1.528, Test accuracy: 93.63 

Round  38, Global train loss: 1.467, Global test loss: 1.989, Global test accuracy: 48.00 

Round  39, Train loss: 1.464, Test loss: 1.528, Test accuracy: 93.63 

Round  39, Global train loss: 1.464, Global test loss: 1.978, Global test accuracy: 48.33 

Round  40, Train loss: 1.519, Test loss: 1.528, Test accuracy: 93.65 

Round  40, Global train loss: 1.519, Global test loss: 1.990, Global test accuracy: 46.00 

Round  41, Train loss: 1.465, Test loss: 1.528, Test accuracy: 93.70 

Round  41, Global train loss: 1.465, Global test loss: 1.964, Global test accuracy: 50.40 

Round  42, Train loss: 1.518, Test loss: 1.528, Test accuracy: 93.72 

Round  42, Global train loss: 1.518, Global test loss: 2.027, Global test accuracy: 40.82 

Round  43, Train loss: 1.519, Test loss: 1.528, Test accuracy: 93.65 

Round  43, Global train loss: 1.519, Global test loss: 2.060, Global test accuracy: 38.57 

Round  44, Train loss: 1.465, Test loss: 1.528, Test accuracy: 93.68 

Round  44, Global train loss: 1.465, Global test loss: 2.021, Global test accuracy: 43.52 

Round  45, Train loss: 1.465, Test loss: 1.528, Test accuracy: 93.65 

Round  45, Global train loss: 1.465, Global test loss: 1.996, Global test accuracy: 46.93 

Round  46, Train loss: 1.518, Test loss: 1.527, Test accuracy: 93.65 

Round  46, Global train loss: 1.518, Global test loss: 2.031, Global test accuracy: 42.52 

Round  47, Train loss: 1.465, Test loss: 1.527, Test accuracy: 93.62 

Round  47, Global train loss: 1.465, Global test loss: 1.977, Global test accuracy: 48.08 

Round  48, Train loss: 1.464, Test loss: 1.527, Test accuracy: 93.63 

Round  48, Global train loss: 1.464, Global test loss: 1.956, Global test accuracy: 50.13 

Round  49, Train loss: 1.466, Test loss: 1.527, Test accuracy: 93.63 

Round  49, Global train loss: 1.466, Global test loss: 1.959, Global test accuracy: 49.88 

Final Round, Train loss: 1.480, Test loss: 1.527, Test accuracy: 93.75 

Final Round, Global train loss: 1.480, Global test loss: 1.959, Global test accuracy: 49.88 

Average accuracy final 10 rounds: 93.65833333333332 

Average global accuracy final 10 rounds: 45.685 

354.39463806152344
[1.4850728511810303, 2.1158809661865234, 2.725665330886841, 3.35105562210083, 3.961953639984131, 4.576237916946411, 5.1858720779418945, 5.7984678745269775, 6.4080164432525635, 7.016460180282593, 7.625131845474243, 8.23843264579773, 8.84880018234253, 9.4610755443573, 10.074139595031738, 10.686391592025757, 11.293957471847534, 11.904787540435791, 12.51422905921936, 13.12448763847351, 13.734970569610596, 14.344445943832397, 14.949950218200684, 15.562630653381348, 16.173729419708252, 16.785868883132935, 17.399214267730713, 18.007933855056763, 18.620556592941284, 19.232329607009888, 19.844762802124023, 20.45725703239441, 21.067065477371216, 21.677116632461548, 22.287271738052368, 22.897761583328247, 23.5084707736969, 24.11715316772461, 24.72945261001587, 25.338746547698975, 25.948482513427734, 26.560096979141235, 27.173795223236084, 27.7806978225708, 28.393878936767578, 29.00551176071167, 29.616618871688843, 30.227937698364258, 30.83638024330139, 31.45026683807373, 32.66727614402771]
[37.31666666666667, 54.75, 63.6, 67.83333333333333, 74.35, 80.21666666666667, 87.35, 90.53333333333333, 91.81666666666666, 91.91666666666667, 91.93333333333334, 91.88333333333334, 91.9, 92.88333333333334, 93.58333333333333, 93.63333333333334, 93.73333333333333, 93.68333333333334, 93.7, 93.76666666666667, 93.78333333333333, 93.73333333333333, 93.75, 93.73333333333333, 93.7, 93.7, 93.71666666666667, 93.7, 93.7, 93.68333333333334, 93.66666666666667, 93.63333333333334, 93.66666666666667, 93.66666666666667, 93.66666666666667, 93.65, 93.63333333333334, 93.63333333333334, 93.63333333333334, 93.63333333333334, 93.65, 93.7, 93.71666666666667, 93.65, 93.68333333333334, 93.65, 93.65, 93.61666666666666, 93.63333333333334, 93.63333333333334, 93.75]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.244, Test loss: 2.152, Test accuracy: 38.35 

Round   0, Global train loss: 2.244, Global test loss: 2.170, Global test accuracy: 33.97 

Round   1, Train loss: 1.925, Test loss: 1.956, Test accuracy: 59.37 

Round   1, Global train loss: 1.925, Global test loss: 2.023, Global test accuracy: 49.98 

Round   2, Train loss: 1.729, Test loss: 1.864, Test accuracy: 63.57 

Round   2, Global train loss: 1.729, Global test loss: 1.998, Global test accuracy: 47.53 

Round   3, Train loss: 1.753, Test loss: 1.766, Test accuracy: 71.87 

Round   3, Global train loss: 1.753, Global test loss: 1.991, Global test accuracy: 47.52 

Round   4, Train loss: 1.597, Test loss: 1.675, Test accuracy: 81.72 

Round   4, Global train loss: 1.597, Global test loss: 1.952, Global test accuracy: 50.52 

Round   5, Train loss: 1.688, Test loss: 1.661, Test accuracy: 82.20 

Round   5, Global train loss: 1.688, Global test loss: 1.962, Global test accuracy: 48.95 

Round   6, Train loss: 1.757, Test loss: 1.703, Test accuracy: 76.98 

Round   6, Global train loss: 1.757, Global test loss: 1.972, Global test accuracy: 48.20 

Round   7, Train loss: 1.783, Test loss: 1.691, Test accuracy: 78.58 

Round   7, Global train loss: 1.783, Global test loss: 1.955, Global test accuracy: 50.32 

Round   8, Train loss: 1.677, Test loss: 1.671, Test accuracy: 80.27 

Round   8, Global train loss: 1.677, Global test loss: 1.954, Global test accuracy: 50.05 

Round   9, Train loss: 1.774, Test loss: 1.703, Test accuracy: 76.82 

Round   9, Global train loss: 1.774, Global test loss: 1.945, Global test accuracy: 51.75 

Round  10, Train loss: 1.671, Test loss: 1.698, Test accuracy: 77.22 

Round  10, Global train loss: 1.671, Global test loss: 1.953, Global test accuracy: 50.25 

Round  11, Train loss: 1.701, Test loss: 1.683, Test accuracy: 78.88 

Round  11, Global train loss: 1.701, Global test loss: 1.960, Global test accuracy: 49.63 

Round  12, Train loss: 1.653, Test loss: 1.684, Test accuracy: 78.70 

Round  12, Global train loss: 1.653, Global test loss: 1.957, Global test accuracy: 49.55 

Round  13, Train loss: 1.731, Test loss: 1.660, Test accuracy: 80.73 

Round  13, Global train loss: 1.731, Global test loss: 1.970, Global test accuracy: 48.60 

Round  14, Train loss: 1.554, Test loss: 1.659, Test accuracy: 80.80 

Round  14, Global train loss: 1.554, Global test loss: 1.948, Global test accuracy: 50.40 

Round  15, Train loss: 1.607, Test loss: 1.663, Test accuracy: 80.27 

Round  15, Global train loss: 1.607, Global test loss: 1.963, Global test accuracy: 48.92 

Round  16, Train loss: 1.661, Test loss: 1.663, Test accuracy: 80.32 

Round  16, Global train loss: 1.661, Global test loss: 1.957, Global test accuracy: 49.38 

Round  17, Train loss: 1.734, Test loss: 1.668, Test accuracy: 79.70 

Round  17, Global train loss: 1.734, Global test loss: 1.937, Global test accuracy: 52.40 

Round  18, Train loss: 1.688, Test loss: 1.664, Test accuracy: 80.27 

Round  18, Global train loss: 1.688, Global test loss: 1.975, Global test accuracy: 47.65 

Round  19, Train loss: 1.557, Test loss: 1.622, Test accuracy: 84.57 

Round  19, Global train loss: 1.557, Global test loss: 1.946, Global test accuracy: 51.43 

Round  20, Train loss: 1.591, Test loss: 1.607, Test accuracy: 86.00 

Round  20, Global train loss: 1.591, Global test loss: 1.958, Global test accuracy: 50.52 

Round  21, Train loss: 1.624, Test loss: 1.609, Test accuracy: 85.73 

Round  21, Global train loss: 1.624, Global test loss: 1.955, Global test accuracy: 50.00 

Round  22, Train loss: 1.553, Test loss: 1.612, Test accuracy: 85.47 

Round  22, Global train loss: 1.553, Global test loss: 1.955, Global test accuracy: 50.57 

Round  23, Train loss: 1.634, Test loss: 1.583, Test accuracy: 88.55 

Round  23, Global train loss: 1.634, Global test loss: 1.953, Global test accuracy: 51.08 

Round  24, Train loss: 1.735, Test loss: 1.597, Test accuracy: 86.97 

Round  24, Global train loss: 1.735, Global test loss: 2.050, Global test accuracy: 39.05 

Round  25, Train loss: 1.615, Test loss: 1.610, Test accuracy: 85.53 

Round  25, Global train loss: 1.615, Global test loss: 1.980, Global test accuracy: 47.93 

Round  26, Train loss: 1.597, Test loss: 1.611, Test accuracy: 85.33 

Round  26, Global train loss: 1.597, Global test loss: 1.959, Global test accuracy: 50.83 

Round  27, Train loss: 1.549, Test loss: 1.612, Test accuracy: 85.12 

Round  27, Global train loss: 1.549, Global test loss: 1.946, Global test accuracy: 50.82 

Round  28, Train loss: 1.664, Test loss: 1.596, Test accuracy: 86.73 

Round  28, Global train loss: 1.664, Global test loss: 1.952, Global test accuracy: 50.68 

Round  29, Train loss: 1.503, Test loss: 1.596, Test accuracy: 86.87 

Round  29, Global train loss: 1.503, Global test loss: 1.933, Global test accuracy: 52.55 

Round  30, Train loss: 1.575, Test loss: 1.596, Test accuracy: 86.80 

Round  30, Global train loss: 1.575, Global test loss: 1.961, Global test accuracy: 50.33 

Round  31, Train loss: 1.540, Test loss: 1.582, Test accuracy: 88.25 

Round  31, Global train loss: 1.540, Global test loss: 1.977, Global test accuracy: 48.23 

Round  32, Train loss: 1.545, Test loss: 1.583, Test accuracy: 88.13 

Round  32, Global train loss: 1.545, Global test loss: 1.935, Global test accuracy: 52.63 

Round  33, Train loss: 1.591, Test loss: 1.610, Test accuracy: 85.43 

Round  33, Global train loss: 1.591, Global test loss: 1.939, Global test accuracy: 52.07 

Round  34, Train loss: 1.631, Test loss: 1.612, Test accuracy: 85.23 

Round  34, Global train loss: 1.631, Global test loss: 1.932, Global test accuracy: 51.88 

Round  35, Train loss: 1.624, Test loss: 1.595, Test accuracy: 86.87 

Round  35, Global train loss: 1.624, Global test loss: 1.942, Global test accuracy: 50.83 

Round  36, Train loss: 1.679, Test loss: 1.610, Test accuracy: 85.43 

Round  36, Global train loss: 1.679, Global test loss: 1.932, Global test accuracy: 52.45 

Round  37, Train loss: 1.675, Test loss: 1.610, Test accuracy: 85.47 

Round  37, Global train loss: 1.675, Global test loss: 1.931, Global test accuracy: 52.55 

Round  38, Train loss: 1.668, Test loss: 1.607, Test accuracy: 85.70 

Round  38, Global train loss: 1.668, Global test loss: 1.936, Global test accuracy: 52.70 

Round  39, Train loss: 1.500, Test loss: 1.607, Test accuracy: 85.75 

Round  39, Global train loss: 1.500, Global test loss: 1.937, Global test accuracy: 51.42 

Round  40, Train loss: 1.630, Test loss: 1.607, Test accuracy: 85.68 

Round  40, Global train loss: 1.630, Global test loss: 1.945, Global test accuracy: 50.82 

Round  41, Train loss: 1.541, Test loss: 1.607, Test accuracy: 85.60 

Round  41, Global train loss: 1.541, Global test loss: 1.931, Global test accuracy: 52.47 

Round  42, Train loss: 1.580, Test loss: 1.594, Test accuracy: 86.98 

Round  42, Global train loss: 1.580, Global test loss: 1.959, Global test accuracy: 49.63 

Round  43, Train loss: 1.581, Test loss: 1.595, Test accuracy: 86.85 

Round  43, Global train loss: 1.581, Global test loss: 1.927, Global test accuracy: 53.05 

Round  44, Train loss: 1.547, Test loss: 1.594, Test accuracy: 87.02 

Round  44, Global train loss: 1.547, Global test loss: 1.927, Global test accuracy: 52.88 

Round  45, Train loss: 1.645, Test loss: 1.583, Test accuracy: 88.18 

Round  45, Global train loss: 1.645, Global test loss: 1.973, Global test accuracy: 48.08 

Round  46, Train loss: 1.607, Test loss: 1.597, Test accuracy: 86.70 

Round  46, Global train loss: 1.607, Global test loss: 1.944, Global test accuracy: 51.42 

Round  47, Train loss: 1.510, Test loss: 1.583, Test accuracy: 87.98 

Round  47, Global train loss: 1.510, Global test loss: 1.942, Global test accuracy: 51.82 

Round  48, Train loss: 1.545, Test loss: 1.583, Test accuracy: 88.15 

Round  48, Global train loss: 1.545, Global test loss: 1.934, Global test accuracy: 52.15 

Round  49, Train loss: 1.580, Test loss: 1.584, Test accuracy: 88.05 

Round  49, Global train loss: 1.580, Global test loss: 1.919, Global test accuracy: 53.62 

Final Round, Train loss: 1.569, Test loss: 1.591, Test accuracy: 87.30 

Final Round, Global train loss: 1.569, Global test loss: 1.919, Global test accuracy: 53.62 

Average accuracy final 10 rounds: 87.12 

Average global accuracy final 10 rounds: 51.593333333333334 

344.97541904449463
[1.4760687351226807, 2.0681350231170654, 2.6596035957336426, 3.2588541507720947, 3.859849452972412, 4.412918329238892, 4.967828989028931, 5.56195068359375, 6.156949281692505, 6.758867025375366, 7.359720230102539, 7.961728572845459, 8.566647291183472, 9.166545391082764, 9.767806768417358, 10.369686603546143, 10.970516681671143, 11.569568872451782, 12.169649124145508, 12.768842935562134, 13.369096755981445, 13.967745780944824, 14.566048860549927, 15.168182849884033, 15.772357940673828, 16.373455047607422, 16.974022388458252, 17.574344158172607, 18.179173707962036, 18.77939510345459, 19.378416538238525, 19.981597900390625, 20.529824018478394, 21.082904815673828, 21.631672143936157, 22.18056869506836, 22.736302614212036, 23.2890784740448, 23.887633800506592, 24.486850023269653, 25.089410305023193, 25.691447257995605, 26.29121470451355, 26.894123792648315, 27.49588680267334, 28.096397876739502, 28.699042797088623, 29.304055213928223, 29.903602361679077, 30.507465600967407, 31.708640575408936]
[38.35, 59.36666666666667, 63.56666666666667, 71.86666666666666, 81.71666666666667, 82.2, 76.98333333333333, 78.58333333333333, 80.26666666666667, 76.81666666666666, 77.21666666666667, 78.88333333333334, 78.7, 80.73333333333333, 80.8, 80.26666666666667, 80.31666666666666, 79.7, 80.26666666666667, 84.56666666666666, 86.0, 85.73333333333333, 85.46666666666667, 88.55, 86.96666666666667, 85.53333333333333, 85.33333333333333, 85.11666666666666, 86.73333333333333, 86.86666666666666, 86.8, 88.25, 88.13333333333334, 85.43333333333334, 85.23333333333333, 86.86666666666666, 85.43333333333334, 85.46666666666667, 85.7, 85.75, 85.68333333333334, 85.6, 86.98333333333333, 86.85, 87.01666666666667, 88.18333333333334, 86.7, 87.98333333333333, 88.15, 88.05, 87.3]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.283, Test loss: 2.268, Test accuracy: 35.22 

Round   1, Train loss: 2.223, Test loss: 2.160, Test accuracy: 33.33 

Round   2, Train loss: 2.075, Test loss: 2.086, Test accuracy: 34.43 

Round   3, Train loss: 1.975, Test loss: 2.050, Test accuracy: 36.78 

Round   4, Train loss: 1.882, Test loss: 2.002, Test accuracy: 45.78 

Round   5, Train loss: 1.890, Test loss: 1.974, Test accuracy: 48.77 

Round   6, Train loss: 1.795, Test loss: 1.945, Test accuracy: 51.98 

Round   7, Train loss: 1.761, Test loss: 1.874, Test accuracy: 61.53 

Round   8, Train loss: 1.757, Test loss: 1.848, Test accuracy: 63.12 

Round   9, Train loss: 1.774, Test loss: 1.823, Test accuracy: 65.37 

Round  10, Train loss: 1.635, Test loss: 1.817, Test accuracy: 66.13 

Round  11, Train loss: 1.773, Test loss: 1.814, Test accuracy: 65.90 

Round  12, Train loss: 1.650, Test loss: 1.809, Test accuracy: 66.32 

Round  13, Train loss: 1.677, Test loss: 1.812, Test accuracy: 65.83 

Round  14, Train loss: 1.750, Test loss: 1.804, Test accuracy: 66.62 

Round  15, Train loss: 1.880, Test loss: 1.798, Test accuracy: 67.27 

Round  16, Train loss: 1.851, Test loss: 1.804, Test accuracy: 66.45 

Round  17, Train loss: 1.826, Test loss: 1.788, Test accuracy: 68.22 

Round  18, Train loss: 1.702, Test loss: 1.781, Test accuracy: 68.78 

Round  19, Train loss: 1.706, Test loss: 1.773, Test accuracy: 69.82 

Round  20, Train loss: 1.629, Test loss: 1.764, Test accuracy: 70.83 

Round  21, Train loss: 1.631, Test loss: 1.757, Test accuracy: 71.50 

Round  22, Train loss: 1.557, Test loss: 1.753, Test accuracy: 71.88 

Round  23, Train loss: 1.645, Test loss: 1.754, Test accuracy: 71.60 

Round  24, Train loss: 1.759, Test loss: 1.751, Test accuracy: 72.07 

Round  25, Train loss: 1.682, Test loss: 1.748, Test accuracy: 72.18 

Round  26, Train loss: 1.670, Test loss: 1.747, Test accuracy: 72.10 

Round  27, Train loss: 1.754, Test loss: 1.748, Test accuracy: 71.98 

Round  28, Train loss: 1.630, Test loss: 1.745, Test accuracy: 72.40 

Round  29, Train loss: 1.772, Test loss: 1.742, Test accuracy: 72.58 

Round  30, Train loss: 1.678, Test loss: 1.738, Test accuracy: 72.82 

Round  31, Train loss: 1.682, Test loss: 1.736, Test accuracy: 73.35 

Round  32, Train loss: 1.668, Test loss: 1.734, Test accuracy: 73.43 

Round  33, Train loss: 1.616, Test loss: 1.734, Test accuracy: 73.37 

Round  34, Train loss: 1.664, Test loss: 1.732, Test accuracy: 73.62 

Round  35, Train loss: 1.669, Test loss: 1.730, Test accuracy: 73.80 

Round  36, Train loss: 1.762, Test loss: 1.730, Test accuracy: 73.77 

Round  37, Train loss: 1.759, Test loss: 1.734, Test accuracy: 73.40 

Round  38, Train loss: 1.668, Test loss: 1.731, Test accuracy: 73.80 

Round  39, Train loss: 1.633, Test loss: 1.726, Test accuracy: 74.20 

Round  40, Train loss: 1.557, Test loss: 1.727, Test accuracy: 73.98 

Round  41, Train loss: 1.755, Test loss: 1.723, Test accuracy: 74.48 

Round  42, Train loss: 1.784, Test loss: 1.723, Test accuracy: 74.38 

Round  43, Train loss: 1.654, Test loss: 1.721, Test accuracy: 74.68 

Round  44, Train loss: 1.608, Test loss: 1.720, Test accuracy: 74.60 

Round  45, Train loss: 1.706, Test loss: 1.723, Test accuracy: 74.27 

Round  46, Train loss: 1.607, Test loss: 1.729, Test accuracy: 73.78 

Round  47, Train loss: 1.783, Test loss: 1.718, Test accuracy: 74.87 

Round  48, Train loss: 1.552, Test loss: 1.716, Test accuracy: 74.90 

Round  49, Train loss: 1.556, Test loss: 1.714, Test accuracy: 75.22 

Final Round, Train loss: 1.680, Test loss: 1.702, Test accuracy: 76.27 

Average accuracy final 10 rounds: 74.51666666666667 

247.76329851150513
[1.4407413005828857, 1.967092752456665, 2.4788143634796143, 2.9829111099243164, 3.491248846054077, 4.016007661819458, 4.540009021759033, 5.063149452209473, 5.587408065795898, 6.131816387176514, 6.663482427597046, 7.192345142364502, 7.721062660217285, 8.248461723327637, 8.775393009185791, 9.309138536453247, 9.837414979934692, 10.36410903930664, 10.894134521484375, 11.423470735549927, 11.950435876846313, 12.476635217666626, 12.999440908432007, 13.51952576637268, 14.048250198364258, 14.572081804275513, 15.100559711456299, 15.625648736953735, 16.15595269203186, 16.68188190460205, 17.206549406051636, 17.732935190200806, 18.259310007095337, 18.785049438476562, 19.309297800064087, 19.834877729415894, 20.361515283584595, 20.893604040145874, 21.419339656829834, 21.942568063735962, 22.46719241142273, 22.995171785354614, 23.52230954170227, 24.049465894699097, 24.574280500411987, 25.101794481277466, 25.623680114746094, 26.151814937591553, 26.679383516311646, 27.207144498825073, 28.119237899780273]
[35.21666666666667, 33.333333333333336, 34.43333333333333, 36.78333333333333, 45.78333333333333, 48.766666666666666, 51.983333333333334, 61.53333333333333, 63.11666666666667, 65.36666666666666, 66.13333333333334, 65.9, 66.31666666666666, 65.83333333333333, 66.61666666666666, 67.26666666666667, 66.45, 68.21666666666667, 68.78333333333333, 69.81666666666666, 70.83333333333333, 71.5, 71.88333333333334, 71.6, 72.06666666666666, 72.18333333333334, 72.1, 71.98333333333333, 72.4, 72.58333333333333, 72.81666666666666, 73.35, 73.43333333333334, 73.36666666666666, 73.61666666666666, 73.8, 73.76666666666667, 73.4, 73.8, 74.2, 73.98333333333333, 74.48333333333333, 74.38333333333334, 74.68333333333334, 74.6, 74.26666666666667, 73.78333333333333, 74.86666666666666, 74.9, 75.21666666666667, 76.26666666666667]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
401408
401920
532992
533248
549632
549696
550336
550346
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Traceback (most recent call last):
  File "main_fedpac_k_means.py", line 291, in <module>
    w_local, loss, indd, class_center_local, class_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_grob_local, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 1492, in train
    sub_clc = self.features - torch.from_numpy(class_center_batch)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
Round   0, Train loss: 2.290, Test loss: 2.270, Test accuracy: 34.13
Round   1, Train loss: 2.212, Test loss: 2.094, Test accuracy: 33.43
Round   2, Train loss: 1.914, Test loss: 2.006, Test accuracy: 49.18
Round   3, Train loss: 1.835, Test loss: 1.988, Test accuracy: 47.13
Round   4, Train loss: 1.624, Test loss: 2.003, Test accuracy: 46.30
Round   5, Train loss: 1.670, Test loss: 1.966, Test accuracy: 49.78
Round   6, Train loss: 1.603, Test loss: 1.986, Test accuracy: 46.73
Round   7, Train loss: 1.564, Test loss: 1.967, Test accuracy: 49.63
Round   8, Train loss: 1.544, Test loss: 1.978, Test accuracy: 48.15
Round   9, Train loss: 1.564, Test loss: 2.031, Test accuracy: 41.05
Round  10, Train loss: 1.552, Test loss: 1.979, Test accuracy: 48.12
Round  11, Train loss: 1.596, Test loss: 2.013, Test accuracy: 42.67
Round  12, Train loss: 1.498, Test loss: 2.027, Test accuracy: 42.95
Round  13, Train loss: 1.527, Test loss: 1.961, Test accuracy: 50.70
Round  14, Train loss: 1.491, Test loss: 1.973, Test accuracy: 48.27
Round  15, Train loss: 1.534, Test loss: 1.952, Test accuracy: 50.47
Round  16, Train loss: 1.494, Test loss: 1.944, Test accuracy: 52.03
Round  17, Train loss: 1.491, Test loss: 1.957, Test accuracy: 49.58
Round  18, Train loss: 1.487, Test loss: 1.944, Test accuracy: 51.22
Round  19, Train loss: 1.541, Test loss: 1.940, Test accuracy: 51.80
Round  20, Train loss: 1.539, Test loss: 1.954, Test accuracy: 50.83
Round  21, Train loss: 1.531, Test loss: 1.939, Test accuracy: 51.28
Round  22, Train loss: 1.530, Test loss: 1.948, Test accuracy: 50.60
Round  23, Train loss: 1.482, Test loss: 1.955, Test accuracy: 49.90
Round  24, Train loss: 1.475, Test loss: 1.944, Test accuracy: 50.92
Round  25, Train loss: 1.486, Test loss: 1.941, Test accuracy: 51.20
Round  26, Train loss: 1.481, Test loss: 1.940, Test accuracy: 51.62
Round  27, Train loss: 1.483, Test loss: 1.942, Test accuracy: 51.58
Round  28, Train loss: 1.481, Test loss: 1.953, Test accuracy: 50.32
Round  29, Train loss: 1.534, Test loss: 1.985, Test accuracy: 46.58
Round  30, Train loss: 1.478, Test loss: 1.947, Test accuracy: 50.75
Round  31, Train loss: 1.484, Test loss: 1.956, Test accuracy: 50.15
Round  32, Train loss: 1.479, Test loss: 1.947, Test accuracy: 52.05
Round  33, Train loss: 1.480, Test loss: 1.964, Test accuracy: 49.70
Round  34, Train loss: 1.479, Test loss: 1.952, Test accuracy: 49.88
Round  35, Train loss: 1.531, Test loss: 1.956, Test accuracy: 50.25
Round  36, Train loss: 1.474, Test loss: 1.943, Test accuracy: 51.30
Round  37, Train loss: 1.477, Test loss: 1.941, Test accuracy: 51.48
Round  38, Train loss: 1.474, Test loss: 1.933, Test accuracy: 52.93
Round  39, Train loss: 1.478, Test loss: 1.952, Test accuracy: 51.00
Round  40, Train loss: 1.479, Test loss: 1.946, Test accuracy: 51.17
Round  41, Train loss: 1.473, Test loss: 1.951, Test accuracy: 49.98
Round  42, Train loss: 1.471, Test loss: 1.956, Test accuracy: 50.07
Round  43, Train loss: 1.525, Test loss: 1.930, Test accuracy: 52.57
Round  44, Train loss: 1.526, Test loss: 1.941, Test accuracy: 51.12
Round  45, Train loss: 1.518, Test loss: 1.947, Test accuracy: 50.90
Round  46, Train loss: 1.475, Test loss: 1.943, Test accuracy: 51.25
Round  47, Train loss: 1.476, Test loss: 1.938, Test accuracy: 52.03
Round  48, Train loss: 1.473, Test loss: 1.943, Test accuracy: 51.68
Round  49, Train loss: 1.475, Test loss: 1.936, Test accuracy: 52.47
Final Round, Train loss: 1.472, Test loss: 1.923, Test accuracy: 53.62
Average accuracy final 10 rounds: 51.32333333333334
575.6395182609558
[2.5222465991973877, 4.118366003036499, 5.698019504547119, 7.288146257400513, 8.869658708572388, 10.452272176742554, 12.029398679733276, 13.607020616531372, 15.187825679779053, 16.766743659973145, 18.344029188156128, 19.922195434570312, 21.5019588470459, 23.108800649642944, 24.68468141555786, 26.306646585464478, 27.928070068359375, 29.54446768760681, 31.161434650421143, 32.776532888412476, 34.38377404212952, 36.00006914138794, 37.6103241443634, 39.22290849685669, 40.83335733413696, 42.44235324859619, 44.049253702163696, 45.66689395904541, 47.287049531936646, 48.88495755195618, 50.48587203025818, 52.087080001831055, 53.68906235694885, 55.28706479072571, 56.89766025543213, 58.60150861740112, 60.221030712127686, 61.825297355651855, 63.42272973060608, 65.04561877250671, 66.67461800575256, 68.29031109809875, 69.898446559906, 71.24178099632263, 72.58122158050537, 73.90582728385925, 75.23212432861328, 76.83845162391663, 78.4595148563385, 80.08025979995728, 81.70610976219177]
[34.13333333333333, 33.43333333333333, 49.18333333333333, 47.13333333333333, 46.3, 49.78333333333333, 46.733333333333334, 49.63333333333333, 48.15, 41.05, 48.11666666666667, 42.666666666666664, 42.95, 50.7, 48.266666666666666, 50.46666666666667, 52.03333333333333, 49.583333333333336, 51.21666666666667, 51.8, 50.833333333333336, 51.28333333333333, 50.6, 49.9, 50.916666666666664, 51.2, 51.61666666666667, 51.583333333333336, 50.31666666666667, 46.583333333333336, 50.75, 50.15, 52.05, 49.7, 49.88333333333333, 50.25, 51.3, 51.483333333333334, 52.93333333333333, 51.0, 51.166666666666664, 49.983333333333334, 50.06666666666667, 52.56666666666667, 51.11666666666667, 50.9, 51.25, 52.03333333333333, 51.68333333333333, 52.46666666666667, 53.61666666666667]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
Round   0, Train loss: 1.600, Test loss: 2.226, Test accuracy: 47.13
Round   1, Train loss: 1.257, Test loss: 2.001, Test accuracy: 65.40
Round   2, Train loss: 1.157, Test loss: 1.861, Test accuracy: 73.22
Round   3, Train loss: 1.192, Test loss: 1.804, Test accuracy: 78.30
Round   4, Train loss: 1.120, Test loss: 1.801, Test accuracy: 75.55
Round   5, Train loss: 1.176, Test loss: 1.743, Test accuracy: 80.73
Round   6, Train loss: 1.189, Test loss: 1.713, Test accuracy: 83.35
Round   7, Train loss: 1.112, Test loss: 1.700, Test accuracy: 83.65
Round   8, Train loss: 1.108, Test loss: 1.681, Test accuracy: 85.45
Round   9, Train loss: 1.110, Test loss: 1.667, Test accuracy: 86.00
Round  10, Train loss: 1.110, Test loss: 1.662, Test accuracy: 86.20
Round  11, Train loss: 1.105, Test loss: 1.657, Test accuracy: 86.27
Round  12, Train loss: 1.187, Test loss: 1.635, Test accuracy: 87.38
Round  13, Train loss: 1.118, Test loss: 1.630, Test accuracy: 88.50
Round  14, Train loss: 1.153, Test loss: 1.609, Test accuracy: 90.78
Round  15, Train loss: 1.109, Test loss: 1.606, Test accuracy: 90.75
Round  16, Train loss: 1.136, Test loss: 1.597, Test accuracy: 91.12
Round  17, Train loss: 1.109, Test loss: 1.584, Test accuracy: 92.13
Round  18, Train loss: 1.104, Test loss: 1.582, Test accuracy: 91.95
Round  19, Train loss: 1.113, Test loss: 1.575, Test accuracy: 92.47
Round  20, Train loss: 1.104, Test loss: 1.573, Test accuracy: 92.65
Round  21, Train loss: 1.144, Test loss: 1.569, Test accuracy: 92.77
Round  22, Train loss: 1.103, Test loss: 1.566, Test accuracy: 92.87
Round  23, Train loss: 1.101, Test loss: 1.566, Test accuracy: 92.77
Round  24, Train loss: 1.104, Test loss: 1.564, Test accuracy: 92.60
Round  25, Train loss: 1.102, Test loss: 1.560, Test accuracy: 92.77
Round  26, Train loss: 1.143, Test loss: 1.557, Test accuracy: 92.72
Round  27, Train loss: 1.102, Test loss: 1.557, Test accuracy: 92.70
Round  28, Train loss: 1.110, Test loss: 1.542, Test accuracy: 94.25
Round  29, Train loss: 1.101, Test loss: 1.541, Test accuracy: 94.33
Round  30, Train loss: 1.101, Test loss: 1.539, Test accuracy: 94.18
Round  31, Train loss: 1.101, Test loss: 1.539, Test accuracy: 94.18
Round  32, Train loss: 1.103, Test loss: 1.539, Test accuracy: 94.10
Round  33, Train loss: 1.101, Test loss: 1.537, Test accuracy: 94.33
Round  34, Train loss: 1.101, Test loss: 1.537, Test accuracy: 94.32
Round  35, Train loss: 1.102, Test loss: 1.537, Test accuracy: 94.25
Round  36, Train loss: 1.102, Test loss: 1.535, Test accuracy: 94.30
Round  37, Train loss: 1.099, Test loss: 1.534, Test accuracy: 94.23
Round  38, Train loss: 1.100, Test loss: 1.535, Test accuracy: 94.15
Round  39, Train loss: 1.103, Test loss: 1.536, Test accuracy: 94.00
Round  40, Train loss: 1.101, Test loss: 1.536, Test accuracy: 93.90
Round  41, Train loss: 1.100, Test loss: 1.535, Test accuracy: 93.98
Round  42, Train loss: 1.100, Test loss: 1.534, Test accuracy: 94.05
Round  43, Train loss: 1.101, Test loss: 1.530, Test accuracy: 94.25
Round  44, Train loss: 1.102, Test loss: 1.532, Test accuracy: 94.15
Round  45, Train loss: 1.101, Test loss: 1.532, Test accuracy: 94.03
Round  46, Train loss: 1.100, Test loss: 1.533, Test accuracy: 94.00
Round  47, Train loss: 1.101, Test loss: 1.533, Test accuracy: 93.85
Round  48, Train loss: 1.099, Test loss: 1.532, Test accuracy: 93.95
Round  49, Train loss: 1.100, Test loss: 1.532, Test accuracy: 93.92
Final Round, Train loss: 1.101, Test loss: 1.535, Test accuracy: 93.65
Average accuracy final 10 rounds: 94.00833333333334
487.58052468299866
[]
[47.13333333333333, 65.4, 73.21666666666667, 78.3, 75.55, 80.73333333333333, 83.35, 83.65, 85.45, 86.0, 86.2, 86.26666666666667, 87.38333333333334, 88.5, 90.78333333333333, 90.75, 91.11666666666666, 92.13333333333334, 91.95, 92.46666666666667, 92.65, 92.76666666666667, 92.86666666666666, 92.76666666666667, 92.6, 92.76666666666667, 92.71666666666667, 92.7, 94.25, 94.33333333333333, 94.18333333333334, 94.18333333333334, 94.1, 94.33333333333333, 94.31666666666666, 94.25, 94.3, 94.23333333333333, 94.15, 94.0, 93.9, 93.98333333333333, 94.05, 94.25, 94.15, 94.03333333333333, 94.0, 93.85, 93.95, 93.91666666666667, 93.65]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.286, Test loss: 2.288, Test accuracy: 33.33
Round   0: Global train loss: 2.286, Global test loss: 2.297, Global test accuracy: 33.33
Round   1, Train loss: 2.260, Test loss: 2.261, Test accuracy: 32.62
Round   1: Global train loss: 2.260, Global test loss: 2.294, Global test accuracy: 33.33
Round   2, Train loss: 2.195, Test loss: 2.225, Test accuracy: 32.58
Round   2: Global train loss: 2.195, Global test loss: 2.291, Global test accuracy: 33.33
Round   3, Train loss: 2.166, Test loss: 2.195, Test accuracy: 32.72
Round   3: Global train loss: 2.166, Global test loss: 2.288, Global test accuracy: 33.33
Round   4, Train loss: 2.058, Test loss: 2.192, Test accuracy: 36.25
Round   4: Global train loss: 2.058, Global test loss: 2.287, Global test accuracy: 33.33
Round   5, Train loss: 2.029, Test loss: 2.168, Test accuracy: 38.17
Round   5: Global train loss: 2.029, Global test loss: 2.286, Global test accuracy: 33.33
Round   6, Train loss: 1.770, Test loss: 2.064, Test accuracy: 48.97
Round   6: Global train loss: 1.770, Global test loss: 2.279, Global test accuracy: 33.40
Round   7, Train loss: 1.748, Test loss: 2.060, Test accuracy: 52.47
Round   7: Global train loss: 1.748, Global test loss: 2.277, Global test accuracy: 33.58
Round   8, Train loss: 2.131, Test loss: 2.142, Test accuracy: 46.12
Round   8: Global train loss: 2.131, Global test loss: 2.281, Global test accuracy: 33.63
Round   9, Train loss: 1.954, Test loss: 2.056, Test accuracy: 53.85
Round   9: Global train loss: 1.954, Global test loss: 2.274, Global test accuracy: 33.48
Round  10, Train loss: 2.076, Test loss: 2.139, Test accuracy: 45.53
Round  10: Global train loss: 2.076, Global test loss: 2.278, Global test accuracy: 33.33
Round  11, Train loss: 1.177, Test loss: 2.040, Test accuracy: 53.00
Round  11: Global train loss: 1.177, Global test loss: 2.273, Global test accuracy: 33.33
Round  12, Train loss: 1.123, Test loss: 2.031, Test accuracy: 53.88
Round  12: Global train loss: 1.123, Global test loss: 2.270, Global test accuracy: 33.47
Round  13, Train loss: 1.787, Test loss: 2.118, Test accuracy: 46.18
Round  13: Global train loss: 1.787, Global test loss: 2.278, Global test accuracy: 33.33
Round  14, Train loss: 1.112, Test loss: 1.980, Test accuracy: 57.73
Round  14: Global train loss: 1.112, Global test loss: 2.268, Global test accuracy: 33.33
Round  15, Train loss: 0.952, Test loss: 1.908, Test accuracy: 61.97
Round  15: Global train loss: 0.952, Global test loss: 2.262, Global test accuracy: 33.67
Round  16, Train loss: 1.177, Test loss: 2.003, Test accuracy: 52.88
Round  16: Global train loss: 1.177, Global test loss: 2.267, Global test accuracy: 33.33
Round  17, Train loss: 0.925, Test loss: 1.983, Test accuracy: 54.43
Round  17: Global train loss: 0.925, Global test loss: 2.265, Global test accuracy: 33.73
Round  18, Train loss: 1.000, Test loss: 2.022, Test accuracy: 51.05
Round  18: Global train loss: 1.000, Global test loss: 2.271, Global test accuracy: 33.35
Round  19, Train loss: 0.344, Test loss: 1.998, Test accuracy: 52.45
Round  19: Global train loss: 0.344, Global test loss: 2.270, Global test accuracy: 33.55
Round  20, Train loss: 0.478, Test loss: 1.935, Test accuracy: 57.10
Round  20: Global train loss: 0.478, Global test loss: 2.264, Global test accuracy: 33.58
Round  21, Train loss: 0.264, Test loss: 1.929, Test accuracy: 57.87
Round  21: Global train loss: 0.264, Global test loss: 2.264, Global test accuracy: 33.33
Round  22, Train loss: -0.146, Test loss: 1.893, Test accuracy: 62.08
Round  22: Global train loss: -0.146, Global test loss: 2.261, Global test accuracy: 33.60
Round  23, Train loss: 0.723, Test loss: 1.944, Test accuracy: 56.45
Round  23: Global train loss: 0.723, Global test loss: 2.265, Global test accuracy: 33.33
Round  24, Train loss: -0.593, Test loss: 1.778, Test accuracy: 70.10
Round  24: Global train loss: -0.593, Global test loss: 2.249, Global test accuracy: 34.42
Round  25, Train loss: -0.420, Test loss: 1.756, Test accuracy: 71.15
Round  25: Global train loss: -0.420, Global test loss: 2.242, Global test accuracy: 34.80
Round  26, Train loss: 0.038, Test loss: 1.791, Test accuracy: 67.48
Round  26: Global train loss: 0.038, Global test loss: 2.236, Global test accuracy: 33.78
Round  27, Train loss: -0.101, Test loss: 1.778, Test accuracy: 67.20
Round  27: Global train loss: -0.101, Global test loss: 2.228, Global test accuracy: 33.82
Round  28, Train loss: -1.062, Test loss: 1.757, Test accuracy: 68.72
Round  28: Global train loss: -1.062, Global test loss: 2.216, Global test accuracy: 34.70
Round  29, Train loss: -0.559, Test loss: 1.779, Test accuracy: 66.32
Round  29: Global train loss: -0.559, Global test loss: 2.207, Global test accuracy: 34.15
Round  30, Train loss: -1.473, Test loss: 1.783, Test accuracy: 65.97
Round  30: Global train loss: -1.473, Global test loss: 2.202, Global test accuracy: 34.98
Round  31, Train loss: -0.747, Test loss: 1.684, Test accuracy: 76.47
Round  31: Global train loss: -0.747, Global test loss: 2.176, Global test accuracy: 36.52
Round  32, Train loss: -0.855, Test loss: 1.644, Test accuracy: 82.03
Round  32: Global train loss: -0.855, Global test loss: 2.162, Global test accuracy: 36.12
Round  33, Train loss: -0.955, Test loss: 1.653, Test accuracy: 81.37
Round  33: Global train loss: -0.955, Global test loss: 2.153, Global test accuracy: 35.95
Round  34, Train loss: -0.402, Test loss: 1.669, Test accuracy: 78.65
Round  34: Global train loss: -0.402, Global test loss: 2.151, Global test accuracy: 36.17
Round  35, Train loss: -1.302, Test loss: 1.646, Test accuracy: 80.80
Round  35: Global train loss: -1.302, Global test loss: 2.138, Global test accuracy: 36.95
Round  36, Train loss: -1.022, Test loss: 1.649, Test accuracy: 81.80
Round  36: Global train loss: -1.022, Global test loss: 2.133, Global test accuracy: 38.27
Round  37, Train loss: -1.821, Test loss: 1.595, Test accuracy: 87.65
Round  37: Global train loss: -1.821, Global test loss: 2.116, Global test accuracy: 38.95
Round  38, Train loss: -0.793, Test loss: 1.595, Test accuracy: 86.75
Round  38: Global train loss: -0.793, Global test loss: 2.116, Global test accuracy: 38.38
Round  39, Train loss: -2.481, Test loss: 1.564, Test accuracy: 89.92
Round  39: Global train loss: -2.481, Global test loss: 2.108, Global test accuracy: 37.52
Round  40, Train loss: -1.413, Test loss: 1.549, Test accuracy: 91.73
Round  40: Global train loss: -1.413, Global test loss: 2.100, Global test accuracy: 39.18
Round  41, Train loss: -1.143, Test loss: 1.551, Test accuracy: 91.98
Round  41: Global train loss: -1.143, Global test loss: 2.093, Global test accuracy: 40.65
Round  42, Train loss: -1.501, Test loss: 1.561, Test accuracy: 90.73
Round  42: Global train loss: -1.501, Global test loss: 2.086, Global test accuracy: 42.17
Round  43, Train loss: -3.016, Test loss: 1.558, Test accuracy: 90.80
Round  43: Global train loss: -3.016, Global test loss: 2.077, Global test accuracy: 41.10
Round  44, Train loss: -2.035, Test loss: 1.554, Test accuracy: 91.02
Round  44: Global train loss: -2.035, Global test loss: 2.070, Global test accuracy: 41.78
Round  45, Train loss: -1.532, Test loss: 1.525, Test accuracy: 94.12
Round  45: Global train loss: -1.532, Global test loss: 2.073, Global test accuracy: 39.83
Round  46, Train loss: -2.794, Test loss: 1.525, Test accuracy: 94.07
Round  46: Global train loss: -2.794, Global test loss: 2.072, Global test accuracy: 41.85
Round  47, Train loss: -1.581, Test loss: 1.531, Test accuracy: 93.07
Round  47: Global train loss: -1.581, Global test loss: 2.072, Global test accuracy: 41.55
Round  48, Train loss: -3.350, Test loss: 1.533, Test accuracy: 92.85
Round  48: Global train loss: -3.350, Global test loss: 2.060, Global test accuracy: 42.38
Round  49, Train loss: -1.216, Test loss: 1.539, Test accuracy: 92.35
Round  49: Global train loss: -1.216, Global test loss: 2.058, Global test accuracy: 42.52
Final Round: Train loss: 1.589, Test loss: 1.540, Test accuracy: 93.63
Final Round: Global train loss: 1.589, Global test loss: 2.053, Global test accuracy: 42.75
Average accuracy final 10 rounds: 92.27166666666668
Average global accuracy final 10 rounds: 41.30166666666666
419.067547082901
[]
[33.333333333333336, 32.61666666666667, 32.583333333333336, 32.71666666666667, 36.25, 38.166666666666664, 48.96666666666667, 52.46666666666667, 46.11666666666667, 53.85, 45.53333333333333, 53.0, 53.88333333333333, 46.18333333333333, 57.733333333333334, 61.96666666666667, 52.88333333333333, 54.43333333333333, 51.05, 52.45, 57.1, 57.86666666666667, 62.083333333333336, 56.45, 70.1, 71.15, 67.48333333333333, 67.2, 68.71666666666667, 66.31666666666666, 65.96666666666667, 76.46666666666667, 82.03333333333333, 81.36666666666666, 78.65, 80.8, 81.8, 87.65, 86.75, 89.91666666666667, 91.73333333333333, 91.98333333333333, 90.73333333333333, 90.8, 91.01666666666667, 94.11666666666666, 94.06666666666666, 93.06666666666666, 92.85, 92.35, 93.63333333333334]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.295, Test loss: 2.296, Test accuracy: 4.82 

Round   0, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 4.78 

Round   1, Train loss: 2.294, Test loss: 2.295, Test accuracy: 5.65 

Round   1, Global train loss: 2.294, Global test loss: 2.295, Global test accuracy: 5.65 

Round   2, Train loss: 2.294, Test loss: 2.295, Test accuracy: 6.23 

Round   2, Global train loss: 2.294, Global test loss: 2.295, Global test accuracy: 6.67 

Round   3, Train loss: 2.294, Test loss: 2.295, Test accuracy: 6.78 

Round   3, Global train loss: 2.294, Global test loss: 2.295, Global test accuracy: 7.68 

Round   4, Train loss: 2.294, Test loss: 2.295, Test accuracy: 7.40 

Round   4, Global train loss: 2.294, Global test loss: 2.295, Global test accuracy: 8.88 

Round   5, Train loss: 2.293, Test loss: 2.295, Test accuracy: 8.55 

Round   5, Global train loss: 2.293, Global test loss: 2.294, Global test accuracy: 10.27 

Round   6, Train loss: 2.293, Test loss: 2.294, Test accuracy: 9.87 

Round   6, Global train loss: 2.293, Global test loss: 2.294, Global test accuracy: 11.98 

Round   7, Train loss: 2.293, Test loss: 2.294, Test accuracy: 10.63 

Round   7, Global train loss: 2.293, Global test loss: 2.294, Global test accuracy: 13.55 

Round   8, Train loss: 2.292, Test loss: 2.294, Test accuracy: 12.50 

Round   8, Global train loss: 2.292, Global test loss: 2.293, Global test accuracy: 14.85 

Round   9, Train loss: 2.292, Test loss: 2.294, Test accuracy: 13.60 

Round   9, Global train loss: 2.292, Global test loss: 2.293, Global test accuracy: 16.62 

Round  10, Train loss: 2.291, Test loss: 2.293, Test accuracy: 15.65 

Round  10, Global train loss: 2.291, Global test loss: 2.293, Global test accuracy: 18.43 

Round  11, Train loss: 2.292, Test loss: 2.293, Test accuracy: 17.57 

Round  11, Global train loss: 2.292, Global test loss: 2.292, Global test accuracy: 20.22 

Round  12, Train loss: 2.292, Test loss: 2.293, Test accuracy: 18.57 

Round  12, Global train loss: 2.292, Global test loss: 2.292, Global test accuracy: 21.68 

Round  13, Train loss: 2.291, Test loss: 2.293, Test accuracy: 19.23 

Round  13, Global train loss: 2.291, Global test loss: 2.292, Global test accuracy: 23.25 

Round  14, Train loss: 2.291, Test loss: 2.292, Test accuracy: 20.20 

Round  14, Global train loss: 2.291, Global test loss: 2.292, Global test accuracy: 24.52 

Round  15, Train loss: 2.290, Test loss: 2.292, Test accuracy: 22.52 

Round  15, Global train loss: 2.290, Global test loss: 2.291, Global test accuracy: 25.73 

Round  16, Train loss: 2.290, Test loss: 2.292, Test accuracy: 23.52 

Round  16, Global train loss: 2.290, Global test loss: 2.291, Global test accuracy: 27.37 

Round  17, Train loss: 2.290, Test loss: 2.291, Test accuracy: 24.53 

Round  17, Global train loss: 2.290, Global test loss: 2.291, Global test accuracy: 28.85 

Round  18, Train loss: 2.289, Test loss: 2.291, Test accuracy: 28.30 

Round  18, Global train loss: 2.289, Global test loss: 2.290, Global test accuracy: 30.22 

Round  19, Train loss: 2.289, Test loss: 2.290, Test accuracy: 29.92 

Round  19, Global train loss: 2.289, Global test loss: 2.290, Global test accuracy: 31.43 

Round  20, Train loss: 2.289, Test loss: 2.290, Test accuracy: 30.40 

Round  20, Global train loss: 2.289, Global test loss: 2.290, Global test accuracy: 32.15 

Round  21, Train loss: 2.288, Test loss: 2.290, Test accuracy: 31.30 

Round  21, Global train loss: 2.288, Global test loss: 2.289, Global test accuracy: 32.65 

Round  22, Train loss: 2.288, Test loss: 2.289, Test accuracy: 31.97 

Round  22, Global train loss: 2.288, Global test loss: 2.289, Global test accuracy: 33.08 

Round  23, Train loss: 2.287, Test loss: 2.289, Test accuracy: 32.90 

Round  23, Global train loss: 2.287, Global test loss: 2.289, Global test accuracy: 33.67 

Round  24, Train loss: 2.288, Test loss: 2.289, Test accuracy: 33.45 

Round  24, Global train loss: 2.288, Global test loss: 2.288, Global test accuracy: 34.08 

Round  25, Train loss: 2.287, Test loss: 2.289, Test accuracy: 33.65 

Round  25, Global train loss: 2.287, Global test loss: 2.288, Global test accuracy: 34.25 

Round  26, Train loss: 2.286, Test loss: 2.288, Test accuracy: 34.32 

Round  26, Global train loss: 2.286, Global test loss: 2.287, Global test accuracy: 34.30 

Round  27, Train loss: 2.286, Test loss: 2.288, Test accuracy: 34.30 

Round  27, Global train loss: 2.286, Global test loss: 2.287, Global test accuracy: 34.53 

Round  28, Train loss: 2.286, Test loss: 2.288, Test accuracy: 34.60 

Round  28, Global train loss: 2.286, Global test loss: 2.287, Global test accuracy: 34.58 

Round  29, Train loss: 2.285, Test loss: 2.287, Test accuracy: 34.62 

Round  29, Global train loss: 2.285, Global test loss: 2.286, Global test accuracy: 34.63 

Round  30, Train loss: 2.285, Test loss: 2.287, Test accuracy: 34.85 

Round  30, Global train loss: 2.285, Global test loss: 2.286, Global test accuracy: 34.65 

Round  31, Train loss: 2.284, Test loss: 2.286, Test accuracy: 34.90 

Round  31, Global train loss: 2.284, Global test loss: 2.286, Global test accuracy: 34.67 

Round  32, Train loss: 2.284, Test loss: 2.286, Test accuracy: 34.98 

Round  32, Global train loss: 2.284, Global test loss: 2.285, Global test accuracy: 34.80 

Round  33, Train loss: 2.284, Test loss: 2.286, Test accuracy: 35.17 

Round  33, Global train loss: 2.284, Global test loss: 2.285, Global test accuracy: 34.88 

Round  34, Train loss: 2.284, Test loss: 2.285, Test accuracy: 35.15 

Round  34, Global train loss: 2.284, Global test loss: 2.284, Global test accuracy: 34.97 

Round  35, Train loss: 2.283, Test loss: 2.285, Test accuracy: 35.25 

Round  35, Global train loss: 2.283, Global test loss: 2.284, Global test accuracy: 34.93 

Round  36, Train loss: 2.283, Test loss: 2.284, Test accuracy: 35.28 

Round  36, Global train loss: 2.283, Global test loss: 2.284, Global test accuracy: 34.92 

Round  37, Train loss: 2.282, Test loss: 2.284, Test accuracy: 35.27 

Round  37, Global train loss: 2.282, Global test loss: 2.283, Global test accuracy: 34.92 

Round  38, Train loss: 2.282, Test loss: 2.284, Test accuracy: 35.33 

Round  38, Global train loss: 2.282, Global test loss: 2.283, Global test accuracy: 34.95 

Round  39, Train loss: 2.280, Test loss: 2.283, Test accuracy: 35.38 

Round  39, Global train loss: 2.280, Global test loss: 2.282, Global test accuracy: 34.85 

Round  40, Train loss: 2.280, Test loss: 2.283, Test accuracy: 35.47 

Round  40, Global train loss: 2.280, Global test loss: 2.282, Global test accuracy: 34.87 

Round  41, Train loss: 2.280, Test loss: 2.282, Test accuracy: 35.55 

Round  41, Global train loss: 2.280, Global test loss: 2.281, Global test accuracy: 34.93 

Round  42, Train loss: 2.280, Test loss: 2.282, Test accuracy: 35.58 

Round  42, Global train loss: 2.280, Global test loss: 2.281, Global test accuracy: 35.05 

Round  43, Train loss: 2.279, Test loss: 2.282, Test accuracy: 35.53 

Round  43, Global train loss: 2.279, Global test loss: 2.280, Global test accuracy: 35.03 

Round  44, Train loss: 2.278, Test loss: 2.281, Test accuracy: 35.35 

Round  44, Global train loss: 2.278, Global test loss: 2.280, Global test accuracy: 35.10 

Round  45, Train loss: 2.278, Test loss: 2.280, Test accuracy: 35.40 

Round  45, Global train loss: 2.278, Global test loss: 2.279, Global test accuracy: 35.07 

Round  46, Train loss: 2.278, Test loss: 2.280, Test accuracy: 35.52 

Round  46, Global train loss: 2.278, Global test loss: 2.279, Global test accuracy: 35.08 

Round  47, Train loss: 2.277, Test loss: 2.279, Test accuracy: 35.72 

Round  47, Global train loss: 2.277, Global test loss: 2.278, Global test accuracy: 35.02 

Round  48, Train loss: 2.276, Test loss: 2.279, Test accuracy: 35.80 

Round  48, Global train loss: 2.276, Global test loss: 2.278, Global test accuracy: 35.17 

Round  49, Train loss: 2.276, Test loss: 2.279, Test accuracy: 35.97 

Round  49, Global train loss: 2.276, Global test loss: 2.277, Global test accuracy: 35.18 

Final Round, Train loss: 2.275, Test loss: 2.276, Test accuracy: 36.83 

Final Round, Global train loss: 2.275, Global test loss: 2.277, Global test accuracy: 35.18 

Average accuracy final 10 rounds: 35.58833333333333 

Average global accuracy final 10 rounds: 35.05 

364.02974224090576
[1.590313196182251, 2.242366075515747, 2.896357774734497, 3.5512337684631348, 4.201838493347168, 4.854382514953613, 5.506990671157837, 6.189992666244507, 6.847678184509277, 7.4971795082092285, 8.148910522460938, 8.801867246627808, 9.44880723953247, 10.09919810295105, 10.750782012939453, 11.401214361190796, 12.050361156463623, 12.700775146484375, 13.351314067840576, 13.996928691864014, 14.64549970626831, 15.297544002532959, 15.946068286895752, 16.59703278541565, 17.248125076293945, 17.894612312316895, 18.546273469924927, 19.195114612579346, 19.84664249420166, 20.495698928833008, 21.145456790924072, 21.797107696533203, 22.44762134552002, 23.097901582717896, 23.745668172836304, 24.394315719604492, 25.04271674156189, 25.695821285247803, 26.34407377243042, 26.992489337921143, 27.644409894943237, 28.292207717895508, 28.942062616348267, 29.589114665985107, 30.235300302505493, 30.885913610458374, 31.536564588546753, 32.184250593185425, 32.834409952163696, 33.4944212436676, 34.81698989868164]
[4.816666666666666, 5.65, 6.233333333333333, 6.783333333333333, 7.4, 8.55, 9.866666666666667, 10.633333333333333, 12.5, 13.6, 15.65, 17.566666666666666, 18.566666666666666, 19.233333333333334, 20.2, 22.516666666666666, 23.516666666666666, 24.533333333333335, 28.3, 29.916666666666668, 30.4, 31.3, 31.966666666666665, 32.9, 33.45, 33.65, 34.31666666666667, 34.3, 34.6, 34.61666666666667, 34.85, 34.9, 34.983333333333334, 35.166666666666664, 35.15, 35.25, 35.28333333333333, 35.266666666666666, 35.333333333333336, 35.38333333333333, 35.46666666666667, 35.55, 35.583333333333336, 35.53333333333333, 35.35, 35.4, 35.516666666666666, 35.71666666666667, 35.8, 35.96666666666667, 36.833333333333336]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 1, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.285, Test loss: 2.267, Test accuracy: 36.05 

Round   0, Global train loss: 2.285, Global test loss: 2.270, Global test accuracy: 33.38 

Round   1, Train loss: 2.151, Test loss: 2.100, Test accuracy: 42.25 

Round   1, Global train loss: 2.151, Global test loss: 2.103, Global test accuracy: 33.43 

Round   2, Train loss: 1.879, Test loss: 1.956, Test accuracy: 56.53 

Round   2, Global train loss: 1.879, Global test loss: 2.048, Global test accuracy: 41.27 

Round   3, Train loss: 1.748, Test loss: 1.864, Test accuracy: 66.28 

Round   3, Global train loss: 1.748, Global test loss: 2.052, Global test accuracy: 41.25 

Round   4, Train loss: 1.699, Test loss: 1.774, Test accuracy: 75.70 

Round   4, Global train loss: 1.699, Global test loss: 2.043, Global test accuracy: 41.18 

Round   5, Train loss: 1.675, Test loss: 1.729, Test accuracy: 80.03 

Round   5, Global train loss: 1.675, Global test loss: 2.062, Global test accuracy: 39.88 

Round   6, Train loss: 1.537, Test loss: 1.691, Test accuracy: 82.28 

Round   6, Global train loss: 1.537, Global test loss: 2.032, Global test accuracy: 43.32 

Round   7, Train loss: 1.538, Test loss: 1.631, Test accuracy: 87.55 

Round   7, Global train loss: 1.538, Global test loss: 2.038, Global test accuracy: 42.38 

Round   8, Train loss: 1.592, Test loss: 1.592, Test accuracy: 89.97 

Round   8, Global train loss: 1.592, Global test loss: 2.070, Global test accuracy: 35.13 

Round   9, Train loss: 1.488, Test loss: 1.583, Test accuracy: 91.45 

Round   9, Global train loss: 1.488, Global test loss: 2.052, Global test accuracy: 39.40 

Round  10, Train loss: 1.512, Test loss: 1.557, Test accuracy: 94.05 

Round  10, Global train loss: 1.512, Global test loss: 2.027, Global test accuracy: 41.72 

Round  11, Train loss: 1.477, Test loss: 1.555, Test accuracy: 94.12 

Round  11, Global train loss: 1.477, Global test loss: 2.029, Global test accuracy: 42.40 

Round  12, Train loss: 1.476, Test loss: 1.555, Test accuracy: 94.10 

Round  12, Global train loss: 1.476, Global test loss: 2.042, Global test accuracy: 41.22 

Round  13, Train loss: 1.480, Test loss: 1.551, Test accuracy: 94.22 

Round  13, Global train loss: 1.480, Global test loss: 2.039, Global test accuracy: 41.82 

Round  14, Train loss: 1.475, Test loss: 1.550, Test accuracy: 94.28 

Round  14, Global train loss: 1.475, Global test loss: 2.065, Global test accuracy: 38.20 

Round  15, Train loss: 1.485, Test loss: 1.544, Test accuracy: 94.43 

Round  15, Global train loss: 1.485, Global test loss: 2.056, Global test accuracy: 40.07 

Round  16, Train loss: 1.481, Test loss: 1.539, Test accuracy: 94.77 

Round  16, Global train loss: 1.481, Global test loss: 2.028, Global test accuracy: 43.42 

Round  17, Train loss: 1.478, Test loss: 1.538, Test accuracy: 94.80 

Round  17, Global train loss: 1.478, Global test loss: 2.042, Global test accuracy: 40.47 

Round  18, Train loss: 1.466, Test loss: 1.537, Test accuracy: 94.83 

Round  18, Global train loss: 1.466, Global test loss: 2.052, Global test accuracy: 40.35 

Round  19, Train loss: 1.475, Test loss: 1.536, Test accuracy: 94.83 

Round  19, Global train loss: 1.475, Global test loss: 2.058, Global test accuracy: 38.30 

Round  20, Train loss: 1.497, Test loss: 1.519, Test accuracy: 95.13 

Round  20, Global train loss: 1.497, Global test loss: 2.035, Global test accuracy: 41.98 

Round  21, Train loss: 1.466, Test loss: 1.518, Test accuracy: 95.22 

Round  21, Global train loss: 1.466, Global test loss: 2.054, Global test accuracy: 39.57 

Round  22, Train loss: 1.468, Test loss: 1.518, Test accuracy: 95.22 

Round  22, Global train loss: 1.468, Global test loss: 2.033, Global test accuracy: 42.95 

Round  23, Train loss: 1.470, Test loss: 1.517, Test accuracy: 95.27 

Round  23, Global train loss: 1.470, Global test loss: 2.035, Global test accuracy: 42.30 

Round  24, Train loss: 1.469, Test loss: 1.516, Test accuracy: 95.37 

Round  24, Global train loss: 1.469, Global test loss: 2.043, Global test accuracy: 40.88 

Round  25, Train loss: 1.468, Test loss: 1.516, Test accuracy: 95.37 

Round  25, Global train loss: 1.468, Global test loss: 2.053, Global test accuracy: 39.28 

Round  26, Train loss: 1.469, Test loss: 1.516, Test accuracy: 95.38 

Round  26, Global train loss: 1.469, Global test loss: 2.034, Global test accuracy: 41.28 

Round  27, Train loss: 1.468, Test loss: 1.516, Test accuracy: 95.37 

Round  27, Global train loss: 1.468, Global test loss: 2.019, Global test accuracy: 42.80 

Round  28, Train loss: 1.466, Test loss: 1.515, Test accuracy: 95.43 

Round  28, Global train loss: 1.466, Global test loss: 2.052, Global test accuracy: 39.12 

Round  29, Train loss: 1.465, Test loss: 1.515, Test accuracy: 95.43 

Round  29, Global train loss: 1.465, Global test loss: 2.048, Global test accuracy: 39.60 

Round  30, Train loss: 1.466, Test loss: 1.515, Test accuracy: 95.45 

Round  30, Global train loss: 1.466, Global test loss: 2.081, Global test accuracy: 36.95 

Round  31, Train loss: 1.467, Test loss: 1.515, Test accuracy: 95.43 

Round  31, Global train loss: 1.467, Global test loss: 2.013, Global test accuracy: 43.98 

Round  32, Train loss: 1.476, Test loss: 1.513, Test accuracy: 95.58 

Round  32, Global train loss: 1.476, Global test loss: 2.038, Global test accuracy: 40.83 

Round  33, Train loss: 1.463, Test loss: 1.513, Test accuracy: 95.55 

Round  33, Global train loss: 1.463, Global test loss: 2.072, Global test accuracy: 37.63 

Round  34, Train loss: 1.465, Test loss: 1.513, Test accuracy: 95.55 

Round  34, Global train loss: 1.465, Global test loss: 2.040, Global test accuracy: 41.52 

Round  35, Train loss: 1.470, Test loss: 1.513, Test accuracy: 95.53 

Round  35, Global train loss: 1.470, Global test loss: 2.038, Global test accuracy: 41.00 

Round  36, Train loss: 1.470, Test loss: 1.513, Test accuracy: 95.47 

Round  36, Global train loss: 1.470, Global test loss: 2.072, Global test accuracy: 36.83 

Round  37, Train loss: 1.468, Test loss: 1.512, Test accuracy: 95.53 

Round  37, Global train loss: 1.468, Global test loss: 2.055, Global test accuracy: 38.25 

Round  38, Train loss: 1.466, Test loss: 1.512, Test accuracy: 95.52 

Round  38, Global train loss: 1.466, Global test loss: 2.035, Global test accuracy: 42.27 

Round  39, Train loss: 1.465, Test loss: 1.512, Test accuracy: 95.53 

Round  39, Global train loss: 1.465, Global test loss: 2.033, Global test accuracy: 41.88 

Round  40, Train loss: 1.466, Test loss: 1.512, Test accuracy: 95.53 

Round  40, Global train loss: 1.466, Global test loss: 2.051, Global test accuracy: 39.35 

Round  41, Train loss: 1.466, Test loss: 1.511, Test accuracy: 95.52 

Round  41, Global train loss: 1.466, Global test loss: 2.043, Global test accuracy: 40.67 

Round  42, Train loss: 1.466, Test loss: 1.511, Test accuracy: 95.53 

Round  42, Global train loss: 1.466, Global test loss: 2.038, Global test accuracy: 41.68 

Round  43, Train loss: 1.465, Test loss: 1.511, Test accuracy: 95.50 

Round  43, Global train loss: 1.465, Global test loss: 2.060, Global test accuracy: 39.50 

Round  44, Train loss: 1.465, Test loss: 1.511, Test accuracy: 95.48 

Round  44, Global train loss: 1.465, Global test loss: 2.038, Global test accuracy: 41.30 

Round  45, Train loss: 1.465, Test loss: 1.511, Test accuracy: 95.47 

Round  45, Global train loss: 1.465, Global test loss: 2.058, Global test accuracy: 38.33 

Round  46, Train loss: 1.469, Test loss: 1.511, Test accuracy: 95.47 

Round  46, Global train loss: 1.469, Global test loss: 2.069, Global test accuracy: 37.62 

Round  47, Train loss: 1.463, Test loss: 1.511, Test accuracy: 95.45 

Round  47, Global train loss: 1.463, Global test loss: 2.025, Global test accuracy: 42.43 

Round  48, Train loss: 1.462, Test loss: 1.511, Test accuracy: 95.45 

Round  48, Global train loss: 1.462, Global test loss: 2.061, Global test accuracy: 37.82 

Round  49, Train loss: 1.463, Test loss: 1.511, Test accuracy: 95.45 

Round  49, Global train loss: 1.463, Global test loss: 2.057, Global test accuracy: 38.70 

Final Round, Train loss: 1.465, Test loss: 1.511, Test accuracy: 95.47 

Final Round, Global train loss: 1.465, Global test loss: 2.057, Global test accuracy: 38.70 

Average accuracy final 10 rounds: 95.485 

Average global accuracy final 10 rounds: 39.739999999999995 

354.54047775268555
[1.5140559673309326, 2.1596946716308594, 2.771857500076294, 3.3838422298431396, 3.9979498386383057, 4.613088369369507, 5.247217178344727, 5.861263275146484, 6.473480463027954, 7.087806701660156, 7.7051777839660645, 8.333724975585938, 8.949365139007568, 9.568506002426147, 10.191428661346436, 10.793774843215942, 11.410368919372559, 12.053678274154663, 12.66277551651001, 13.272089958190918, 13.881067752838135, 14.487942218780518, 15.098458051681519, 15.70466947555542, 16.318430185317993, 16.926432609558105, 17.532989740371704, 18.144041776657104, 18.754142999649048, 19.36322593688965, 19.98891305923462, 20.60452890396118, 21.21712851524353, 21.829140663146973, 22.440130710601807, 23.05414390563965, 23.66421413421631, 24.27423334121704, 24.884565830230713, 25.49660062789917, 26.112724781036377, 26.727943897247314, 27.34828472137451, 27.96218228340149, 28.581241130828857, 29.19801688194275, 29.816962957382202, 30.431102514266968, 31.044116735458374, 31.664165019989014, 32.90657067298889]
[36.05, 42.25, 56.53333333333333, 66.28333333333333, 75.7, 80.03333333333333, 82.28333333333333, 87.55, 89.96666666666667, 91.45, 94.05, 94.11666666666666, 94.1, 94.21666666666667, 94.28333333333333, 94.43333333333334, 94.76666666666667, 94.8, 94.83333333333333, 94.83333333333333, 95.13333333333334, 95.21666666666667, 95.21666666666667, 95.26666666666667, 95.36666666666666, 95.36666666666666, 95.38333333333334, 95.36666666666666, 95.43333333333334, 95.43333333333334, 95.45, 95.43333333333334, 95.58333333333333, 95.55, 95.55, 95.53333333333333, 95.46666666666667, 95.53333333333333, 95.51666666666667, 95.53333333333333, 95.53333333333333, 95.51666666666667, 95.53333333333333, 95.5, 95.48333333333333, 95.46666666666667, 95.46666666666667, 95.45, 95.45, 95.45, 95.46666666666667]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.286, Test loss: 2.268, Test accuracy: 34.83 

Round   0, Global train loss: 2.286, Global test loss: 2.270, Global test accuracy: 33.43 

Round   1, Train loss: 2.162, Test loss: 2.118, Test accuracy: 41.05 

Round   1, Global train loss: 2.162, Global test loss: 2.101, Global test accuracy: 33.83 

Round   2, Train loss: 1.903, Test loss: 2.001, Test accuracy: 50.40 

Round   2, Global train loss: 1.903, Global test loss: 2.057, Global test accuracy: 40.23 

Round   3, Train loss: 1.725, Test loss: 1.876, Test accuracy: 61.77 

Round   3, Global train loss: 1.725, Global test loss: 2.055, Global test accuracy: 38.30 

Round   4, Train loss: 1.724, Test loss: 1.826, Test accuracy: 66.40 

Round   4, Global train loss: 1.724, Global test loss: 2.040, Global test accuracy: 40.50 

Round   5, Train loss: 1.632, Test loss: 1.768, Test accuracy: 71.83 

Round   5, Global train loss: 1.632, Global test loss: 2.027, Global test accuracy: 42.30 

Round   6, Train loss: 1.741, Test loss: 1.719, Test accuracy: 75.75 

Round   6, Global train loss: 1.741, Global test loss: 2.018, Global test accuracy: 43.43 

Round   7, Train loss: 1.676, Test loss: 1.702, Test accuracy: 77.32 

Round   7, Global train loss: 1.676, Global test loss: 2.020, Global test accuracy: 43.40 

Round   8, Train loss: 1.812, Test loss: 1.693, Test accuracy: 78.62 

Round   8, Global train loss: 1.812, Global test loss: 2.026, Global test accuracy: 43.02 

Round   9, Train loss: 1.596, Test loss: 1.694, Test accuracy: 78.20 

Round   9, Global train loss: 1.596, Global test loss: 2.021, Global test accuracy: 43.03 

Round  10, Train loss: 1.721, Test loss: 1.673, Test accuracy: 80.42 

Round  10, Global train loss: 1.721, Global test loss: 2.032, Global test accuracy: 41.85 

Round  11, Train loss: 1.738, Test loss: 1.675, Test accuracy: 79.43 

Round  11, Global train loss: 1.738, Global test loss: 2.040, Global test accuracy: 41.20 

Round  12, Train loss: 1.662, Test loss: 1.651, Test accuracy: 81.92 

Round  12, Global train loss: 1.662, Global test loss: 2.036, Global test accuracy: 41.15 

Round  13, Train loss: 1.652, Test loss: 1.632, Test accuracy: 83.70 

Round  13, Global train loss: 1.652, Global test loss: 2.028, Global test accuracy: 42.52 

Round  14, Train loss: 1.725, Test loss: 1.631, Test accuracy: 83.73 

Round  14, Global train loss: 1.725, Global test loss: 2.011, Global test accuracy: 43.90 

Round  15, Train loss: 1.612, Test loss: 1.629, Test accuracy: 83.80 

Round  15, Global train loss: 1.612, Global test loss: 2.021, Global test accuracy: 43.48 

Round  16, Train loss: 1.664, Test loss: 1.628, Test accuracy: 83.95 

Round  16, Global train loss: 1.664, Global test loss: 2.011, Global test accuracy: 44.72 

Round  17, Train loss: 1.659, Test loss: 1.638, Test accuracy: 82.77 

Round  17, Global train loss: 1.659, Global test loss: 2.020, Global test accuracy: 43.22 

Round  18, Train loss: 1.647, Test loss: 1.623, Test accuracy: 84.30 

Round  18, Global train loss: 1.647, Global test loss: 2.003, Global test accuracy: 45.52 

Round  19, Train loss: 1.654, Test loss: 1.624, Test accuracy: 84.20 

Round  19, Global train loss: 1.654, Global test loss: 2.007, Global test accuracy: 44.32 

Round  20, Train loss: 1.611, Test loss: 1.624, Test accuracy: 84.17 

Round  20, Global train loss: 1.611, Global test loss: 2.013, Global test accuracy: 43.85 

Round  21, Train loss: 1.548, Test loss: 1.623, Test accuracy: 84.43 

Round  21, Global train loss: 1.548, Global test loss: 2.003, Global test accuracy: 45.22 

Round  22, Train loss: 1.573, Test loss: 1.638, Test accuracy: 82.75 

Round  22, Global train loss: 1.573, Global test loss: 1.999, Global test accuracy: 45.42 

Round  23, Train loss: 1.700, Test loss: 1.653, Test accuracy: 81.30 

Round  23, Global train loss: 1.700, Global test loss: 2.018, Global test accuracy: 43.75 

Round  24, Train loss: 1.554, Test loss: 1.624, Test accuracy: 84.23 

Round  24, Global train loss: 1.554, Global test loss: 2.024, Global test accuracy: 42.57 

Round  25, Train loss: 1.567, Test loss: 1.621, Test accuracy: 84.53 

Round  25, Global train loss: 1.567, Global test loss: 2.015, Global test accuracy: 43.60 

Round  26, Train loss: 1.608, Test loss: 1.621, Test accuracy: 84.58 

Round  26, Global train loss: 1.608, Global test loss: 2.001, Global test accuracy: 45.37 

Round  27, Train loss: 1.661, Test loss: 1.622, Test accuracy: 84.50 

Round  27, Global train loss: 1.661, Global test loss: 2.009, Global test accuracy: 44.37 

Round  28, Train loss: 1.601, Test loss: 1.621, Test accuracy: 84.60 

Round  28, Global train loss: 1.601, Global test loss: 2.017, Global test accuracy: 43.53 

Round  29, Train loss: 1.599, Test loss: 1.622, Test accuracy: 84.35 

Round  29, Global train loss: 1.599, Global test loss: 2.027, Global test accuracy: 42.65 

Round  30, Train loss: 1.575, Test loss: 1.622, Test accuracy: 84.33 

Round  30, Global train loss: 1.575, Global test loss: 1.993, Global test accuracy: 45.87 

Round  31, Train loss: 1.557, Test loss: 1.621, Test accuracy: 84.42 

Round  31, Global train loss: 1.557, Global test loss: 2.002, Global test accuracy: 45.27 

Round  32, Train loss: 1.610, Test loss: 1.620, Test accuracy: 84.52 

Round  32, Global train loss: 1.610, Global test loss: 2.004, Global test accuracy: 45.00 

Round  33, Train loss: 1.599, Test loss: 1.621, Test accuracy: 84.38 

Round  33, Global train loss: 1.599, Global test loss: 2.004, Global test accuracy: 44.48 

Round  34, Train loss: 1.655, Test loss: 1.622, Test accuracy: 84.12 

Round  34, Global train loss: 1.655, Global test loss: 2.011, Global test accuracy: 45.10 

Round  35, Train loss: 1.661, Test loss: 1.607, Test accuracy: 85.72 

Round  35, Global train loss: 1.661, Global test loss: 2.024, Global test accuracy: 42.28 

Round  36, Train loss: 1.562, Test loss: 1.607, Test accuracy: 85.67 

Round  36, Global train loss: 1.562, Global test loss: 2.026, Global test accuracy: 43.00 

Round  37, Train loss: 1.593, Test loss: 1.608, Test accuracy: 85.60 

Round  37, Global train loss: 1.593, Global test loss: 2.012, Global test accuracy: 44.40 

Round  38, Train loss: 1.622, Test loss: 1.610, Test accuracy: 85.45 

Round  38, Global train loss: 1.622, Global test loss: 1.995, Global test accuracy: 46.18 

Round  39, Train loss: 1.637, Test loss: 1.611, Test accuracy: 85.28 

Round  39, Global train loss: 1.637, Global test loss: 2.023, Global test accuracy: 43.02 

Round  40, Train loss: 1.603, Test loss: 1.610, Test accuracy: 85.20 

Round  40, Global train loss: 1.603, Global test loss: 2.007, Global test accuracy: 44.42 

Round  41, Train loss: 1.647, Test loss: 1.613, Test accuracy: 85.00 

Round  41, Global train loss: 1.647, Global test loss: 2.008, Global test accuracy: 44.23 

Round  42, Train loss: 1.598, Test loss: 1.628, Test accuracy: 83.47 

Round  42, Global train loss: 1.598, Global test loss: 2.018, Global test accuracy: 43.35 

Round  43, Train loss: 1.576, Test loss: 1.615, Test accuracy: 84.72 

Round  43, Global train loss: 1.576, Global test loss: 2.040, Global test accuracy: 40.55 

Round  44, Train loss: 1.563, Test loss: 1.601, Test accuracy: 86.32 

Round  44, Global train loss: 1.563, Global test loss: 2.056, Global test accuracy: 38.87 

Round  45, Train loss: 1.716, Test loss: 1.582, Test accuracy: 88.15 

Round  45, Global train loss: 1.716, Global test loss: 2.014, Global test accuracy: 44.32 

Round  46, Train loss: 1.545, Test loss: 1.581, Test accuracy: 88.15 

Round  46, Global train loss: 1.545, Global test loss: 2.013, Global test accuracy: 44.32 

Round  47, Train loss: 1.627, Test loss: 1.580, Test accuracy: 88.40 

Round  47, Global train loss: 1.627, Global test loss: 2.038, Global test accuracy: 41.32 

Round  48, Train loss: 1.592, Test loss: 1.593, Test accuracy: 86.92 

Round  48, Global train loss: 1.592, Global test loss: 2.004, Global test accuracy: 45.07 

Round  49, Train loss: 1.597, Test loss: 1.593, Test accuracy: 86.92 

Round  49, Global train loss: 1.597, Global test loss: 2.028, Global test accuracy: 42.50 

Final Round, Train loss: 1.555, Test loss: 1.577, Test accuracy: 88.57 

Final Round, Global train loss: 1.555, Global test loss: 2.028, Global test accuracy: 42.50 

Average accuracy final 10 rounds: 86.32333333333334 

Average global accuracy final 10 rounds: 42.89333333333333 

348.38260889053345
[1.4932641983032227, 2.089263916015625, 2.6978542804718018, 3.3008599281311035, 3.905217409133911, 4.512182712554932, 5.118874788284302, 5.7226409912109375, 6.32274866104126, 6.924668550491333, 7.521232843399048, 8.11932897567749, 8.7183358669281, 9.316513061523438, 9.917996883392334, 10.515436887741089, 11.115214347839355, 11.71323037147522, 12.312422037124634, 12.910452842712402, 13.510421514511108, 14.107929706573486, 14.70633602142334, 15.305291652679443, 15.903653144836426, 16.501726865768433, 17.09817385673523, 17.694664001464844, 18.293818950653076, 18.893088817596436, 19.477835655212402, 20.075379371643066, 20.67341899871826, 21.27419662475586, 21.868443489074707, 22.46739387512207, 23.068103075027466, 23.665481567382812, 24.26237726211548, 24.85835313796997, 25.4594087600708, 26.064030647277832, 26.671889305114746, 27.293062210083008, 27.88611912727356, 28.488482236862183, 29.090165615081787, 29.695122003555298, 30.29431986808777, 30.916242837905884, 32.1299729347229]
[34.833333333333336, 41.05, 50.4, 61.766666666666666, 66.4, 71.83333333333333, 75.75, 77.31666666666666, 78.61666666666666, 78.2, 80.41666666666667, 79.43333333333334, 81.91666666666667, 83.7, 83.73333333333333, 83.8, 83.95, 82.76666666666667, 84.3, 84.2, 84.16666666666667, 84.43333333333334, 82.75, 81.3, 84.23333333333333, 84.53333333333333, 84.58333333333333, 84.5, 84.6, 84.35, 84.33333333333333, 84.41666666666667, 84.51666666666667, 84.38333333333334, 84.11666666666666, 85.71666666666667, 85.66666666666667, 85.6, 85.45, 85.28333333333333, 85.2, 85.0, 83.46666666666667, 84.71666666666667, 86.31666666666666, 88.15, 88.15, 88.4, 86.91666666666667, 86.91666666666667, 88.56666666666666]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.296, Test loss: 2.290, Test accuracy: 33.35 

Round   1, Train loss: 2.280, Test loss: 2.269, Test accuracy: 33.40 

Round   2, Train loss: 2.236, Test loss: 2.190, Test accuracy: 33.33 

Round   3, Train loss: 2.110, Test loss: 2.113, Test accuracy: 34.40 

Round   4, Train loss: 2.064, Test loss: 2.084, Test accuracy: 37.28 

Round   5, Train loss: 2.026, Test loss: 2.067, Test accuracy: 35.43 

Round   6, Train loss: 2.011, Test loss: 2.047, Test accuracy: 37.57 

Round   7, Train loss: 1.957, Test loss: 2.024, Test accuracy: 42.38 

Round   8, Train loss: 1.884, Test loss: 2.007, Test accuracy: 44.73 

Round   9, Train loss: 1.861, Test loss: 1.975, Test accuracy: 48.80 

Round  10, Train loss: 1.857, Test loss: 1.929, Test accuracy: 55.05 

Round  11, Train loss: 1.808, Test loss: 1.903, Test accuracy: 56.53 

Round  12, Train loss: 1.807, Test loss: 1.886, Test accuracy: 58.75 

Round  13, Train loss: 1.761, Test loss: 1.860, Test accuracy: 61.67 

Round  14, Train loss: 1.802, Test loss: 1.832, Test accuracy: 65.12 

Round  15, Train loss: 1.738, Test loss: 1.818, Test accuracy: 66.53 

Round  16, Train loss: 1.759, Test loss: 1.806, Test accuracy: 67.70 

Round  17, Train loss: 1.703, Test loss: 1.788, Test accuracy: 69.42 

Round  18, Train loss: 1.666, Test loss: 1.781, Test accuracy: 70.13 

Round  19, Train loss: 1.665, Test loss: 1.782, Test accuracy: 69.42 

Round  20, Train loss: 1.703, Test loss: 1.781, Test accuracy: 69.25 

Round  21, Train loss: 1.630, Test loss: 1.770, Test accuracy: 70.43 

Round  22, Train loss: 1.742, Test loss: 1.758, Test accuracy: 71.70 

Round  23, Train loss: 1.628, Test loss: 1.763, Test accuracy: 70.87 

Round  24, Train loss: 1.749, Test loss: 1.764, Test accuracy: 70.82 

Round  25, Train loss: 1.630, Test loss: 1.746, Test accuracy: 72.75 

Round  26, Train loss: 1.752, Test loss: 1.739, Test accuracy: 73.17 

Round  27, Train loss: 1.726, Test loss: 1.738, Test accuracy: 73.03 

Round  28, Train loss: 1.644, Test loss: 1.712, Test accuracy: 76.28 

Round  29, Train loss: 1.808, Test loss: 1.711, Test accuracy: 76.55 

Round  30, Train loss: 1.678, Test loss: 1.703, Test accuracy: 77.25 

Round  31, Train loss: 1.640, Test loss: 1.701, Test accuracy: 76.97 

Round  32, Train loss: 1.580, Test loss: 1.695, Test accuracy: 77.47 

Round  33, Train loss: 1.632, Test loss: 1.691, Test accuracy: 77.98 

Round  34, Train loss: 1.725, Test loss: 1.690, Test accuracy: 78.13 

Round  35, Train loss: 1.568, Test loss: 1.687, Test accuracy: 78.13 

Round  36, Train loss: 1.613, Test loss: 1.684, Test accuracy: 78.42 

Round  37, Train loss: 1.716, Test loss: 1.686, Test accuracy: 78.23 

Round  38, Train loss: 1.560, Test loss: 1.686, Test accuracy: 78.08 

Round  39, Train loss: 1.611, Test loss: 1.684, Test accuracy: 78.37 

Round  40, Train loss: 1.651, Test loss: 1.685, Test accuracy: 78.30 

Round  41, Train loss: 1.654, Test loss: 1.687, Test accuracy: 78.05 

Round  42, Train loss: 1.698, Test loss: 1.687, Test accuracy: 78.27 

Round  43, Train loss: 1.669, Test loss: 1.680, Test accuracy: 78.77 

Round  44, Train loss: 1.616, Test loss: 1.678, Test accuracy: 78.93 

Round  45, Train loss: 1.677, Test loss: 1.676, Test accuracy: 79.07 

Round  46, Train loss: 1.664, Test loss: 1.674, Test accuracy: 79.18 

Round  47, Train loss: 1.701, Test loss: 1.674, Test accuracy: 79.13 

Round  48, Train loss: 1.560, Test loss: 1.674, Test accuracy: 79.05 

Round  49, Train loss: 1.673, Test loss: 1.674, Test accuracy: 79.10 

Final Round, Train loss: 1.643, Test loss: 1.671, Test accuracy: 79.30 

Average accuracy final 10 rounds: 78.785 

248.38160061836243
[1.4218435287475586, 1.9852068424224854, 2.521038770675659, 3.0577657222747803, 3.575164794921875, 4.071985960006714, 4.591207027435303, 5.120800733566284, 5.6490325927734375, 6.183244943618774, 6.717271327972412, 7.242579698562622, 7.765345096588135, 8.267289876937866, 8.760350942611694, 9.284255266189575, 9.81568193435669, 10.343405723571777, 10.869723558425903, 11.401294469833374, 11.9359290599823, 12.46366834640503, 12.99535059928894, 13.525913000106812, 14.050025224685669, 14.5799241065979, 15.11653470993042, 15.645520210266113, 16.167187213897705, 16.697093725204468, 17.227942943572998, 17.756794452667236, 18.2816219329834, 18.809848308563232, 19.337303638458252, 19.86485767364502, 20.39765238761902, 20.925580978393555, 21.45127558708191, 21.991906881332397, 22.521236896514893, 23.055089950561523, 23.58476948738098, 24.11584734916687, 24.63654065132141, 25.170166015625, 25.701722383499146, 26.228145360946655, 26.760597944259644, 27.2961003780365, 28.228420972824097]
[33.35, 33.4, 33.333333333333336, 34.4, 37.28333333333333, 35.43333333333333, 37.56666666666667, 42.38333333333333, 44.733333333333334, 48.8, 55.05, 56.53333333333333, 58.75, 61.666666666666664, 65.11666666666666, 66.53333333333333, 67.7, 69.41666666666667, 70.13333333333334, 69.41666666666667, 69.25, 70.43333333333334, 71.7, 70.86666666666666, 70.81666666666666, 72.75, 73.16666666666667, 73.03333333333333, 76.28333333333333, 76.55, 77.25, 76.96666666666667, 77.46666666666667, 77.98333333333333, 78.13333333333334, 78.13333333333334, 78.41666666666667, 78.23333333333333, 78.08333333333333, 78.36666666666666, 78.3, 78.05, 78.26666666666667, 78.76666666666667, 78.93333333333334, 79.06666666666666, 79.18333333333334, 79.13333333333334, 79.05, 79.1, 79.3]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
401408
401920
532992
533248
549632
549696
550336
550346
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Traceback (most recent call last):
  File "main_fedpac_k_means.py", line 291, in <module>
    w_local, loss, indd, class_center_local, class_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_grob_local, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 1492, in train
    sub_clc = self.features - torch.from_numpy(class_center_batch)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
Round   0, Train loss: 2.294, Test loss: 2.282, Test accuracy: 33.33
Round   1, Train loss: 2.271, Test loss: 2.187, Test accuracy: 33.33
Round   2, Train loss: 2.161, Test loss: 2.088, Test accuracy: 32.75
Round   3, Train loss: 1.922, Test loss: 2.048, Test accuracy: 40.82
Round   4, Train loss: 1.816, Test loss: 2.086, Test accuracy: 33.68
Round   5, Train loss: 1.722, Test loss: 2.083, Test accuracy: 34.82
Round   6, Train loss: 1.815, Test loss: 2.050, Test accuracy: 39.98
Round   7, Train loss: 1.685, Test loss: 2.045, Test accuracy: 39.75
Round   8, Train loss: 1.654, Test loss: 1.993, Test accuracy: 46.70
Round   9, Train loss: 1.604, Test loss: 1.997, Test accuracy: 46.10
Round  10, Train loss: 1.567, Test loss: 2.023, Test accuracy: 42.83
Round  11, Train loss: 1.590, Test loss: 2.011, Test accuracy: 44.33
Round  12, Train loss: 1.614, Test loss: 2.040, Test accuracy: 40.75
Round  13, Train loss: 1.653, Test loss: 2.045, Test accuracy: 40.52
Round  14, Train loss: 1.602, Test loss: 2.041, Test accuracy: 40.42
Round  15, Train loss: 1.662, Test loss: 2.049, Test accuracy: 40.78
Round  16, Train loss: 1.546, Test loss: 2.025, Test accuracy: 42.83
Round  17, Train loss: 1.510, Test loss: 2.014, Test accuracy: 44.05
Round  18, Train loss: 1.648, Test loss: 2.028, Test accuracy: 42.52
Round  19, Train loss: 1.653, Test loss: 1.995, Test accuracy: 46.22
Round  20, Train loss: 1.548, Test loss: 1.996, Test accuracy: 45.68
Round  21, Train loss: 1.641, Test loss: 2.019, Test accuracy: 43.93
Round  22, Train loss: 1.595, Test loss: 2.015, Test accuracy: 44.43
Round  23, Train loss: 1.640, Test loss: 2.042, Test accuracy: 40.67
Round  24, Train loss: 1.648, Test loss: 2.023, Test accuracy: 42.92
Round  25, Train loss: 1.542, Test loss: 2.013, Test accuracy: 44.42
Round  26, Train loss: 1.583, Test loss: 2.006, Test accuracy: 45.02
Round  27, Train loss: 1.639, Test loss: 2.003, Test accuracy: 45.42
Round  28, Train loss: 1.587, Test loss: 2.007, Test accuracy: 44.58
Round  29, Train loss: 1.587, Test loss: 2.012, Test accuracy: 44.07
Round  30, Train loss: 1.536, Test loss: 2.003, Test accuracy: 45.42
Round  31, Train loss: 1.542, Test loss: 2.007, Test accuracy: 44.65
Round  32, Train loss: 1.646, Test loss: 2.014, Test accuracy: 43.88
Round  33, Train loss: 1.643, Test loss: 2.031, Test accuracy: 42.10
Round  34, Train loss: 1.532, Test loss: 2.003, Test accuracy: 45.10
Round  35, Train loss: 1.636, Test loss: 2.017, Test accuracy: 43.87
Round  36, Train loss: 1.582, Test loss: 2.016, Test accuracy: 44.20
Round  37, Train loss: 1.637, Test loss: 2.016, Test accuracy: 43.67
Round  38, Train loss: 1.585, Test loss: 2.017, Test accuracy: 43.63
Round  39, Train loss: 1.563, Test loss: 2.010, Test accuracy: 44.55
Round  40, Train loss: 1.584, Test loss: 2.038, Test accuracy: 41.20
Round  41, Train loss: 1.527, Test loss: 2.009, Test accuracy: 44.17
Round  42, Train loss: 1.479, Test loss: 2.021, Test accuracy: 43.17
Round  43, Train loss: 1.487, Test loss: 2.024, Test accuracy: 43.10
Round  44, Train loss: 1.582, Test loss: 2.021, Test accuracy: 42.93
Round  45, Train loss: 1.633, Test loss: 2.028, Test accuracy: 41.83
Round  46, Train loss: 1.577, Test loss: 2.014, Test accuracy: 43.82
Round  47, Train loss: 1.525, Test loss: 2.044, Test accuracy: 40.87
Round  48, Train loss: 1.504, Test loss: 2.031, Test accuracy: 41.90
Round  49, Train loss: 1.576, Test loss: 2.008, Test accuracy: 44.37
Final Round, Train loss: 1.554, Test loss: 2.001, Test accuracy: 44.90
Average accuracy final 10 rounds: 42.735
568.1318006515503
[2.4775853157043457, 4.062664747238159, 5.629953145980835, 7.206159830093384, 8.774311780929565, 10.35916018486023, 11.923826932907104, 13.480425357818604, 15.044487714767456, 16.609737873077393, 18.17467761039734, 19.798791885375977, 21.389538526535034, 22.98607325553894, 24.574148178100586, 26.149833917617798, 27.72230887413025, 29.294108390808105, 30.88121747970581, 32.465482234954834, 34.04425311088562, 35.63646650314331, 37.22076201438904, 38.807666063308716, 40.356600522994995, 41.905930519104004, 43.49152874946594, 45.058250188827515, 46.53755855560303, 48.051730155944824, 49.36694884300232, 50.84520959854126, 52.38936424255371, 54.0055136680603, 55.53682518005371, 57.11207938194275, 58.68081474304199, 60.248677253723145, 61.82318830490112, 63.41260623931885, 64.98375988006592, 66.5526294708252, 68.11418795585632, 69.68330430984497, 71.25693774223328, 72.8317289352417, 74.39974975585938, 75.96636199951172, 77.52759265899658, 79.09598088264465, 80.66438388824463]
[33.333333333333336, 33.333333333333336, 32.75, 40.81666666666667, 33.68333333333333, 34.81666666666667, 39.983333333333334, 39.75, 46.7, 46.1, 42.833333333333336, 44.333333333333336, 40.75, 40.516666666666666, 40.416666666666664, 40.78333333333333, 42.833333333333336, 44.05, 42.516666666666666, 46.21666666666667, 45.68333333333333, 43.93333333333333, 44.43333333333333, 40.666666666666664, 42.916666666666664, 44.416666666666664, 45.016666666666666, 45.416666666666664, 44.583333333333336, 44.06666666666667, 45.416666666666664, 44.65, 43.88333333333333, 42.1, 45.1, 43.86666666666667, 44.2, 43.666666666666664, 43.63333333333333, 44.55, 41.2, 44.166666666666664, 43.166666666666664, 43.1, 42.93333333333333, 41.833333333333336, 43.81666666666667, 40.86666666666667, 41.9, 44.36666666666667, 44.9]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
Round   0, Train loss: 1.484, Test loss: 2.131, Test accuracy: 51.43
Round   1, Train loss: 1.231, Test loss: 1.980, Test accuracy: 61.83
Round   2, Train loss: 1.199, Test loss: 1.902, Test accuracy: 68.17
Round   3, Train loss: 1.123, Test loss: 1.853, Test accuracy: 70.70
Round   4, Train loss: 1.131, Test loss: 1.812, Test accuracy: 73.58
Round   5, Train loss: 1.153, Test loss: 1.754, Test accuracy: 79.30
Round   6, Train loss: 1.118, Test loss: 1.758, Test accuracy: 77.03
Round   7, Train loss: 1.215, Test loss: 1.693, Test accuracy: 84.03
Round   8, Train loss: 1.109, Test loss: 1.680, Test accuracy: 84.35
Round   9, Train loss: 1.111, Test loss: 1.666, Test accuracy: 84.95
Round  10, Train loss: 1.157, Test loss: 1.653, Test accuracy: 85.58
Round  11, Train loss: 1.112, Test loss: 1.610, Test accuracy: 90.32
Round  12, Train loss: 1.105, Test loss: 1.598, Test accuracy: 90.98
Round  13, Train loss: 1.104, Test loss: 1.597, Test accuracy: 90.77
Round  14, Train loss: 1.150, Test loss: 1.591, Test accuracy: 90.75
Round  15, Train loss: 1.104, Test loss: 1.592, Test accuracy: 90.37
Round  16, Train loss: 1.107, Test loss: 1.593, Test accuracy: 90.13
Round  17, Train loss: 1.102, Test loss: 1.598, Test accuracy: 89.00
Round  18, Train loss: 1.122, Test loss: 1.564, Test accuracy: 92.35
Round  19, Train loss: 1.105, Test loss: 1.562, Test accuracy: 92.43
Round  20, Train loss: 1.103, Test loss: 1.561, Test accuracy: 92.22
Round  21, Train loss: 1.102, Test loss: 1.559, Test accuracy: 92.18
Round  22, Train loss: 1.104, Test loss: 1.558, Test accuracy: 92.15
Round  23, Train loss: 1.102, Test loss: 1.555, Test accuracy: 92.47
Round  24, Train loss: 1.101, Test loss: 1.556, Test accuracy: 92.35
Round  25, Train loss: 1.144, Test loss: 1.553, Test accuracy: 92.50
Round  26, Train loss: 1.100, Test loss: 1.554, Test accuracy: 92.38
Round  27, Train loss: 1.142, Test loss: 1.553, Test accuracy: 92.47
Round  28, Train loss: 1.099, Test loss: 1.551, Test accuracy: 92.63
Round  29, Train loss: 1.102, Test loss: 1.550, Test accuracy: 92.57
Round  30, Train loss: 1.101, Test loss: 1.549, Test accuracy: 92.52
Round  31, Train loss: 1.142, Test loss: 1.550, Test accuracy: 92.35
Round  32, Train loss: 1.101, Test loss: 1.549, Test accuracy: 92.35
Round  33, Train loss: 1.102, Test loss: 1.549, Test accuracy: 92.35
Round  34, Train loss: 1.097, Test loss: 1.548, Test accuracy: 92.33
Round  35, Train loss: 1.142, Test loss: 1.548, Test accuracy: 92.42
Round  36, Train loss: 1.102, Test loss: 1.548, Test accuracy: 92.35
Round  37, Train loss: 1.099, Test loss: 1.547, Test accuracy: 92.35
Round  38, Train loss: 1.100, Test loss: 1.547, Test accuracy: 92.30
Round  39, Train loss: 1.101, Test loss: 1.543, Test accuracy: 92.80
Round  40, Train loss: 1.099, Test loss: 1.542, Test accuracy: 92.83
Round  41, Train loss: 1.103, Test loss: 1.542, Test accuracy: 92.72
Round  42, Train loss: 1.100, Test loss: 1.542, Test accuracy: 92.80
Round  43, Train loss: 1.102, Test loss: 1.541, Test accuracy: 92.78
Round  44, Train loss: 1.143, Test loss: 1.541, Test accuracy: 92.75
Round  45, Train loss: 1.099, Test loss: 1.541, Test accuracy: 92.57
Round  46, Train loss: 1.099, Test loss: 1.541, Test accuracy: 92.67
Round  47, Train loss: 1.101, Test loss: 1.541, Test accuracy: 92.77
Round  48, Train loss: 1.139, Test loss: 1.540, Test accuracy: 92.82
Round  49, Train loss: 1.101, Test loss: 1.539, Test accuracy: 92.80
Final Round, Train loss: 1.112, Test loss: 1.540, Test accuracy: 92.73
Average accuracy final 10 rounds: 92.75
464.10736322402954
[]
[51.43333333333333, 61.833333333333336, 68.16666666666667, 70.7, 73.58333333333333, 79.3, 77.03333333333333, 84.03333333333333, 84.35, 84.95, 85.58333333333333, 90.31666666666666, 90.98333333333333, 90.76666666666667, 90.75, 90.36666666666666, 90.13333333333334, 89.0, 92.35, 92.43333333333334, 92.21666666666667, 92.18333333333334, 92.15, 92.46666666666667, 92.35, 92.5, 92.38333333333334, 92.46666666666667, 92.63333333333334, 92.56666666666666, 92.51666666666667, 92.35, 92.35, 92.35, 92.33333333333333, 92.41666666666667, 92.35, 92.35, 92.3, 92.8, 92.83333333333333, 92.71666666666667, 92.8, 92.78333333333333, 92.75, 92.56666666666666, 92.66666666666667, 92.76666666666667, 92.81666666666666, 92.8, 92.73333333333333]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.283, Test loss: 2.281, Test accuracy: 18.43
Round   0: Global train loss: 2.283, Global test loss: 2.304, Global test accuracy: 6.45
Round   1, Train loss: 2.212, Test loss: 2.239, Test accuracy: 29.27
Round   1: Global train loss: 2.212, Global test loss: 2.300, Global test accuracy: 22.28
Round   2, Train loss: 2.168, Test loss: 2.215, Test accuracy: 30.02
Round   2: Global train loss: 2.168, Global test loss: 2.298, Global test accuracy: 28.55
Round   3, Train loss: 1.932, Test loss: 2.135, Test accuracy: 38.38
Round   3: Global train loss: 1.932, Global test loss: 2.291, Global test accuracy: 34.58
Round   4, Train loss: 1.964, Test loss: 2.094, Test accuracy: 41.22
Round   4: Global train loss: 1.964, Global test loss: 2.288, Global test accuracy: 35.50
Round   5, Train loss: 1.760, Test loss: 2.018, Test accuracy: 47.88
Round   5: Global train loss: 1.760, Global test loss: 2.280, Global test accuracy: 34.97
Round   6, Train loss: 1.747, Test loss: 2.046, Test accuracy: 45.65
Round   6: Global train loss: 1.747, Global test loss: 2.278, Global test accuracy: 34.82
Round   7, Train loss: 1.032, Test loss: 1.962, Test accuracy: 55.27
Round   7: Global train loss: 1.032, Global test loss: 2.265, Global test accuracy: 34.50
Round   8, Train loss: 1.411, Test loss: 2.018, Test accuracy: 53.53
Round   8: Global train loss: 1.411, Global test loss: 2.263, Global test accuracy: 34.98
Round   9, Train loss: 0.806, Test loss: 1.948, Test accuracy: 60.05
Round   9: Global train loss: 0.806, Global test loss: 2.250, Global test accuracy: 34.28
Round  10, Train loss: 0.535, Test loss: 1.843, Test accuracy: 66.77
Round  10: Global train loss: 0.535, Global test loss: 2.222, Global test accuracy: 35.73
Round  11, Train loss: 1.509, Test loss: 1.858, Test accuracy: 63.78
Round  11: Global train loss: 1.509, Global test loss: 2.207, Global test accuracy: 36.45
Round  12, Train loss: 0.639, Test loss: 1.826, Test accuracy: 65.43
Round  12: Global train loss: 0.639, Global test loss: 2.187, Global test accuracy: 38.50
Round  13, Train loss: 0.796, Test loss: 1.797, Test accuracy: 67.82
Round  13: Global train loss: 0.796, Global test loss: 2.170, Global test accuracy: 39.33
Round  14, Train loss: 0.850, Test loss: 1.750, Test accuracy: 71.85
Round  14: Global train loss: 0.850, Global test loss: 2.157, Global test accuracy: 38.83
Round  15, Train loss: 0.788, Test loss: 1.725, Test accuracy: 75.65
Round  15: Global train loss: 0.788, Global test loss: 2.145, Global test accuracy: 36.93
Round  16, Train loss: 1.062, Test loss: 1.729, Test accuracy: 76.28
Round  16: Global train loss: 1.062, Global test loss: 2.134, Global test accuracy: 36.92
Round  17, Train loss: 0.686, Test loss: 1.744, Test accuracy: 74.68
Round  17: Global train loss: 0.686, Global test loss: 2.128, Global test accuracy: 35.07
Round  18, Train loss: 0.274, Test loss: 1.662, Test accuracy: 82.78
Round  18: Global train loss: 0.274, Global test loss: 2.120, Global test accuracy: 35.57
Round  19, Train loss: -0.532, Test loss: 1.601, Test accuracy: 87.65
Round  19: Global train loss: -0.532, Global test loss: 2.112, Global test accuracy: 37.23
Round  20, Train loss: -0.289, Test loss: 1.597, Test accuracy: 87.67
Round  20: Global train loss: -0.289, Global test loss: 2.107, Global test accuracy: 39.77
Round  21, Train loss: -0.057, Test loss: 1.593, Test accuracy: 88.12
Round  21: Global train loss: -0.057, Global test loss: 2.100, Global test accuracy: 40.85
Round  22, Train loss: -0.297, Test loss: 1.589, Test accuracy: 87.90
Round  22: Global train loss: -0.297, Global test loss: 2.098, Global test accuracy: 39.45
Round  23, Train loss: -0.080, Test loss: 1.600, Test accuracy: 87.90
Round  23: Global train loss: -0.080, Global test loss: 2.094, Global test accuracy: 40.08
Round  24, Train loss: -0.636, Test loss: 1.588, Test accuracy: 89.07
Round  24: Global train loss: -0.636, Global test loss: 2.090, Global test accuracy: 40.65
Round  25, Train loss: -1.515, Test loss: 1.582, Test accuracy: 90.02
Round  25: Global train loss: -1.515, Global test loss: 2.090, Global test accuracy: 38.60
Round  26, Train loss: -1.032, Test loss: 1.573, Test accuracy: 89.78
Round  26: Global train loss: -1.032, Global test loss: 2.086, Global test accuracy: 39.93
Round  27, Train loss: -0.713, Test loss: 1.572, Test accuracy: 89.73
Round  27: Global train loss: -0.713, Global test loss: 2.083, Global test accuracy: 37.05
Round  28, Train loss: -1.296, Test loss: 1.570, Test accuracy: 90.05
Round  28: Global train loss: -1.296, Global test loss: 2.082, Global test accuracy: 38.42
Round  29, Train loss: -1.685, Test loss: 1.555, Test accuracy: 91.37
Round  29: Global train loss: -1.685, Global test loss: 2.082, Global test accuracy: 39.25
Round  30, Train loss: -1.532, Test loss: 1.554, Test accuracy: 91.37
Round  30: Global train loss: -1.532, Global test loss: 2.082, Global test accuracy: 37.48
Round  31, Train loss: -1.104, Test loss: 1.537, Test accuracy: 93.07
Round  31: Global train loss: -1.104, Global test loss: 2.081, Global test accuracy: 37.60
Round  32, Train loss: -1.181, Test loss: 1.540, Test accuracy: 92.88
Round  32: Global train loss: -1.181, Global test loss: 2.082, Global test accuracy: 36.87
Round  33, Train loss: -1.461, Test loss: 1.533, Test accuracy: 93.28
Round  33: Global train loss: -1.461, Global test loss: 2.080, Global test accuracy: 37.32
Round  34, Train loss: -1.928, Test loss: 1.527, Test accuracy: 93.65
Round  34: Global train loss: -1.928, Global test loss: 2.080, Global test accuracy: 36.08
Round  35, Train loss: -2.930, Test loss: 1.524, Test accuracy: 93.92
Round  35: Global train loss: -2.930, Global test loss: 2.079, Global test accuracy: 36.58
Round  36, Train loss: -1.692, Test loss: 1.528, Test accuracy: 93.58
Round  36: Global train loss: -1.692, Global test loss: 2.077, Global test accuracy: 36.82
Round  37, Train loss: -1.999, Test loss: 1.524, Test accuracy: 93.80
Round  37: Global train loss: -1.999, Global test loss: 2.075, Global test accuracy: 38.02
Round  38, Train loss: -2.101, Test loss: 1.522, Test accuracy: 93.92
Round  38: Global train loss: -2.101, Global test loss: 2.075, Global test accuracy: 38.02
Round  39, Train loss: -1.797, Test loss: 1.520, Test accuracy: 94.15
Round  39: Global train loss: -1.797, Global test loss: 2.074, Global test accuracy: 37.38
Round  40, Train loss: -2.693, Test loss: 1.520, Test accuracy: 94.10
Round  40: Global train loss: -2.693, Global test loss: 2.074, Global test accuracy: 37.07
Round  41, Train loss: -3.003, Test loss: 1.522, Test accuracy: 93.92
Round  41: Global train loss: -3.003, Global test loss: 2.073, Global test accuracy: 36.25
Round  42, Train loss: -3.051, Test loss: 1.521, Test accuracy: 94.10
Round  42: Global train loss: -3.051, Global test loss: 2.071, Global test accuracy: 36.85
Round  43, Train loss: -2.302, Test loss: 1.522, Test accuracy: 94.00
Round  43: Global train loss: -2.302, Global test loss: 2.068, Global test accuracy: 38.93
Round  44, Train loss: -2.614, Test loss: 1.523, Test accuracy: 94.03
Round  44: Global train loss: -2.614, Global test loss: 2.070, Global test accuracy: 37.72
Round  45, Train loss: -3.340, Test loss: 1.523, Test accuracy: 93.98
Round  45: Global train loss: -3.340, Global test loss: 2.067, Global test accuracy: 38.42
Round  46, Train loss: -2.568, Test loss: 1.523, Test accuracy: 93.88
Round  46: Global train loss: -2.568, Global test loss: 2.067, Global test accuracy: 38.37
Round  47, Train loss: -3.424, Test loss: 1.523, Test accuracy: 93.93
Round  47: Global train loss: -3.424, Global test loss: 2.068, Global test accuracy: 37.33
Round  48, Train loss: -2.456, Test loss: 1.521, Test accuracy: 94.15
Round  48: Global train loss: -2.456, Global test loss: 2.066, Global test accuracy: 38.45
Round  49, Train loss: -3.380, Test loss: 1.523, Test accuracy: 93.95
Round  49: Global train loss: -3.380, Global test loss: 2.066, Global test accuracy: 37.77
Final Round: Train loss: 1.632, Test loss: 1.570, Test accuracy: 90.78
Final Round: Global train loss: 1.632, Global test loss: 2.063, Global test accuracy: 38.83
Average accuracy final 10 rounds: 94.005
Average global accuracy final 10 rounds: 37.714999999999996
400.3384733200073
[]
[18.433333333333334, 29.266666666666666, 30.016666666666666, 38.38333333333333, 41.21666666666667, 47.88333333333333, 45.65, 55.266666666666666, 53.53333333333333, 60.05, 66.76666666666667, 63.78333333333333, 65.43333333333334, 67.81666666666666, 71.85, 75.65, 76.28333333333333, 74.68333333333334, 82.78333333333333, 87.65, 87.66666666666667, 88.11666666666666, 87.9, 87.9, 89.06666666666666, 90.01666666666667, 89.78333333333333, 89.73333333333333, 90.05, 91.36666666666666, 91.36666666666666, 93.06666666666666, 92.88333333333334, 93.28333333333333, 93.65, 93.91666666666667, 93.58333333333333, 93.8, 93.91666666666667, 94.15, 94.1, 93.91666666666667, 94.1, 94.0, 94.03333333333333, 93.98333333333333, 93.88333333333334, 93.93333333333334, 94.15, 93.95, 90.78333333333333]
/data/jij/csm/code/FL_HLS/utils/sampling.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.32 

Round   0, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.28 

Round   1, Train loss: 2.301, Test loss: 2.301, Test accuracy: 22.37 

Round   1, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 22.37 

Round   2, Train loss: 2.300, Test loss: 2.301, Test accuracy: 23.25 

Round   2, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 23.45 

Round   3, Train loss: 2.300, Test loss: 2.301, Test accuracy: 23.72 

Round   3, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 24.32 

Round   4, Train loss: 2.300, Test loss: 2.301, Test accuracy: 24.30 

Round   4, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 25.37 

Round   5, Train loss: 2.300, Test loss: 2.301, Test accuracy: 25.52 

Round   5, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 26.07 

Round   6, Train loss: 2.300, Test loss: 2.300, Test accuracy: 25.97 

Round   6, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 26.82 

Round   7, Train loss: 2.300, Test loss: 2.300, Test accuracy: 26.90 

Round   7, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 27.73 

Round   8, Train loss: 2.300, Test loss: 2.300, Test accuracy: 27.58 

Round   8, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 28.48 

Round   9, Train loss: 2.299, Test loss: 2.300, Test accuracy: 27.73 

Round   9, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 29.03 

Round  10, Train loss: 2.299, Test loss: 2.300, Test accuracy: 28.23 

Round  10, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 29.57 

Round  11, Train loss: 2.299, Test loss: 2.300, Test accuracy: 28.52 

Round  11, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 30.05 

Round  12, Train loss: 2.299, Test loss: 2.300, Test accuracy: 28.82 

Round  12, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 30.37 

Round  13, Train loss: 2.298, Test loss: 2.300, Test accuracy: 29.22 

Round  13, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 30.78 

Round  14, Train loss: 2.299, Test loss: 2.299, Test accuracy: 30.30 

Round  14, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 31.13 

Round  15, Train loss: 2.298, Test loss: 2.299, Test accuracy: 30.47 

Round  15, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 31.42 

Round  16, Train loss: 2.298, Test loss: 2.299, Test accuracy: 30.65 

Round  16, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 31.68 

Round  17, Train loss: 2.298, Test loss: 2.299, Test accuracy: 30.98 

Round  17, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 31.97 

Round  18, Train loss: 2.298, Test loss: 2.299, Test accuracy: 31.42 

Round  18, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 32.10 

Round  19, Train loss: 2.298, Test loss: 2.298, Test accuracy: 31.63 

Round  19, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 32.32 

Round  20, Train loss: 2.297, Test loss: 2.298, Test accuracy: 31.93 

Round  20, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 32.55 

Round  21, Train loss: 2.297, Test loss: 2.298, Test accuracy: 32.00 

Round  21, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 32.70 

Round  22, Train loss: 2.297, Test loss: 2.298, Test accuracy: 32.03 

Round  22, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 32.85 

Round  23, Train loss: 2.297, Test loss: 2.298, Test accuracy: 32.33 

Round  23, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 32.93 

Round  24, Train loss: 2.297, Test loss: 2.298, Test accuracy: 32.42 

Round  24, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 33.07 

Round  25, Train loss: 2.296, Test loss: 2.298, Test accuracy: 32.47 

Round  25, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 33.13 

Round  26, Train loss: 2.296, Test loss: 2.297, Test accuracy: 33.05 

Round  26, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 33.18 

Round  27, Train loss: 2.296, Test loss: 2.297, Test accuracy: 33.08 

Round  27, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 33.20 

Round  28, Train loss: 2.296, Test loss: 2.297, Test accuracy: 33.17 

Round  28, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 33.25 

Round  29, Train loss: 2.296, Test loss: 2.297, Test accuracy: 33.17 

Round  29, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 33.27 

Round  30, Train loss: 2.296, Test loss: 2.297, Test accuracy: 33.25 

Round  30, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 33.32 

Round  31, Train loss: 2.296, Test loss: 2.296, Test accuracy: 33.38 

Round  31, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 33.33 

Round  32, Train loss: 2.295, Test loss: 2.296, Test accuracy: 33.35 

Round  32, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 33.33 

Round  33, Train loss: 2.295, Test loss: 2.296, Test accuracy: 33.35 

Round  33, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 33.33 

Round  34, Train loss: 2.295, Test loss: 2.296, Test accuracy: 33.35 

Round  34, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 33.32 

Round  35, Train loss: 2.295, Test loss: 2.295, Test accuracy: 33.37 

Round  35, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 33.35 

Round  36, Train loss: 2.295, Test loss: 2.295, Test accuracy: 33.40 

Round  36, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 33.38 

Round  37, Train loss: 2.294, Test loss: 2.295, Test accuracy: 33.38 

Round  37, Global train loss: 2.294, Global test loss: 2.295, Global test accuracy: 33.38 

Round  38, Train loss: 2.295, Test loss: 2.295, Test accuracy: 33.42 

Round  38, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 33.40 

Round  39, Train loss: 2.294, Test loss: 2.295, Test accuracy: 33.43 

Round  39, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 33.42 

Round  40, Train loss: 2.294, Test loss: 2.295, Test accuracy: 33.43 

Round  40, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 33.40 

Round  41, Train loss: 2.294, Test loss: 2.294, Test accuracy: 33.43 

Round  41, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 33.40 

Round  42, Train loss: 2.293, Test loss: 2.294, Test accuracy: 33.45 

Round  42, Global train loss: 2.293, Global test loss: 2.294, Global test accuracy: 33.45 

Round  43, Train loss: 2.294, Test loss: 2.294, Test accuracy: 33.45 

Round  43, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 33.45 

Round  44, Train loss: 2.293, Test loss: 2.294, Test accuracy: 33.45 

Round  44, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 33.45 

Round  45, Train loss: 2.293, Test loss: 2.294, Test accuracy: 33.47 

Round  45, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 33.43 

Round  46, Train loss: 2.293, Test loss: 2.294, Test accuracy: 33.47 

Round  46, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 33.45 

Round  47, Train loss: 2.292, Test loss: 2.293, Test accuracy: 33.45 

Round  47, Global train loss: 2.292, Global test loss: 2.293, Global test accuracy: 33.43 

Round  48, Train loss: 2.292, Test loss: 2.293, Test accuracy: 33.45 

Round  48, Global train loss: 2.292, Global test loss: 2.293, Global test accuracy: 33.43 

Round  49, Train loss: 2.292, Test loss: 2.293, Test accuracy: 33.45 

Round  49, Global train loss: 2.292, Global test loss: 2.293, Global test accuracy: 33.43 

Final Round, Train loss: 2.292, Test loss: 2.292, Test accuracy: 33.45 

Final Round, Global train loss: 2.292, Global test loss: 2.293, Global test accuracy: 33.43 

Average accuracy final 10 rounds: 33.45 

Average global accuracy final 10 rounds: 33.43333333333333 

369.0841827392578
[1.5739390850067139, 2.2612826824188232, 2.924898147583008, 3.5863752365112305, 4.2559802532196045, 4.918618440628052, 5.577258586883545, 6.251668214797974, 6.913743734359741, 7.574721813201904, 8.233585119247437, 8.894853591918945, 9.553245544433594, 10.208105087280273, 10.867213487625122, 11.531432151794434, 12.1875, 12.850168943405151, 13.511156797409058, 14.217897653579712, 14.888875007629395, 15.505943775177002, 16.169952154159546, 16.834253787994385, 17.504817962646484, 18.16875720024109, 18.834455013275146, 19.500245094299316, 20.1762797832489, 20.83704400062561, 21.50802779197693, 22.178136825561523, 22.840330600738525, 23.520559787750244, 24.193490028381348, 24.856658458709717, 25.51560926437378, 26.182121753692627, 26.840818643569946, 27.50215721130371, 28.161120653152466, 28.824206113815308, 29.506657123565674, 30.177546977996826, 30.842263221740723, 31.508703470230103, 32.170809268951416, 32.87421202659607, 33.536208391189575, 34.195510387420654, 35.524075508117676]
[21.316666666666666, 22.366666666666667, 23.25, 23.716666666666665, 24.3, 25.516666666666666, 25.966666666666665, 26.9, 27.583333333333332, 27.733333333333334, 28.233333333333334, 28.516666666666666, 28.816666666666666, 29.216666666666665, 30.3, 30.466666666666665, 30.65, 30.983333333333334, 31.416666666666668, 31.633333333333333, 31.933333333333334, 32.0, 32.03333333333333, 32.333333333333336, 32.416666666666664, 32.46666666666667, 33.05, 33.083333333333336, 33.166666666666664, 33.166666666666664, 33.25, 33.38333333333333, 33.35, 33.35, 33.35, 33.36666666666667, 33.4, 33.38333333333333, 33.416666666666664, 33.43333333333333, 33.43333333333333, 33.43333333333333, 33.45, 33.45, 33.45, 33.46666666666667, 33.46666666666667, 33.45, 33.45, 33.45, 33.45]
