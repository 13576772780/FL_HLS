%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.176, Test loss: 2.038, Test accuracy: 22.97 

Round   0, Global train loss: 1.176, Global test loss: 2.384, Global test accuracy: 14.87 

Round   1, Train loss: 1.003, Test loss: 1.552, Test accuracy: 42.08 

Round   1, Global train loss: 1.003, Global test loss: 2.184, Global test accuracy: 24.23 

Round   2, Train loss: 0.911, Test loss: 1.338, Test accuracy: 47.15 

Round   2, Global train loss: 0.911, Global test loss: 2.268, Global test accuracy: 24.18 

Round   3, Train loss: 0.858, Test loss: 1.177, Test accuracy: 50.00 

Round   3, Global train loss: 0.858, Global test loss: 2.155, Global test accuracy: 22.03 

Round   4, Train loss: 0.907, Test loss: 1.078, Test accuracy: 56.52 

Round   4, Global train loss: 0.907, Global test loss: 2.342, Global test accuracy: 25.07 

Round   5, Train loss: 0.795, Test loss: 0.944, Test accuracy: 58.38 

Round   5, Global train loss: 0.795, Global test loss: 2.122, Global test accuracy: 24.97 

Round   6, Train loss: 0.739, Test loss: 0.932, Test accuracy: 58.63 

Round   6, Global train loss: 0.739, Global test loss: 2.182, Global test accuracy: 21.05 

Round   7, Train loss: 0.738, Test loss: 0.864, Test accuracy: 62.30 

Round   7, Global train loss: 0.738, Global test loss: 2.610, Global test accuracy: 19.12 

Round   8, Train loss: 0.770, Test loss: 0.782, Test accuracy: 64.07 

Round   8, Global train loss: 0.770, Global test loss: 2.088, Global test accuracy: 23.95 

Round   9, Train loss: 0.649, Test loss: 0.768, Test accuracy: 64.47 

Round   9, Global train loss: 0.649, Global test loss: 2.466, Global test accuracy: 23.98 

Round  10, Train loss: 0.645, Test loss: 0.766, Test accuracy: 65.25 

Round  10, Global train loss: 0.645, Global test loss: 2.070, Global test accuracy: 29.92 

Round  11, Train loss: 0.794, Test loss: 0.764, Test accuracy: 65.97 

Round  11, Global train loss: 0.794, Global test loss: 2.212, Global test accuracy: 24.65 

Round  12, Train loss: 0.733, Test loss: 0.755, Test accuracy: 66.93 

Round  12, Global train loss: 0.733, Global test loss: 2.512, Global test accuracy: 24.50 

Round  13, Train loss: 0.634, Test loss: 0.746, Test accuracy: 67.58 

Round  13, Global train loss: 0.634, Global test loss: 2.395, Global test accuracy: 20.00 

Round  14, Train loss: 0.694, Test loss: 0.729, Test accuracy: 68.72 

Round  14, Global train loss: 0.694, Global test loss: 2.332, Global test accuracy: 21.75 

Round  15, Train loss: 0.592, Test loss: 0.723, Test accuracy: 68.73 

Round  15, Global train loss: 0.592, Global test loss: 2.036, Global test accuracy: 32.35 

Round  16, Train loss: 0.650, Test loss: 0.744, Test accuracy: 68.55 

Round  16, Global train loss: 0.650, Global test loss: 2.084, Global test accuracy: 30.10 

Round  17, Train loss: 0.530, Test loss: 0.726, Test accuracy: 69.52 

Round  17, Global train loss: 0.530, Global test loss: 2.186, Global test accuracy: 21.37 

Round  18, Train loss: 0.540, Test loss: 0.724, Test accuracy: 69.63 

Round  18, Global train loss: 0.540, Global test loss: 2.173, Global test accuracy: 25.68 

Round  19, Train loss: 0.515, Test loss: 0.734, Test accuracy: 69.25 

Round  19, Global train loss: 0.515, Global test loss: 2.189, Global test accuracy: 23.27 

Round  20, Train loss: 0.580, Test loss: 0.722, Test accuracy: 69.98 

Round  20, Global train loss: 0.580, Global test loss: 2.230, Global test accuracy: 23.50 

Round  21, Train loss: 0.545, Test loss: 0.717, Test accuracy: 70.62 

Round  21, Global train loss: 0.545, Global test loss: 2.136, Global test accuracy: 26.92 

Round  22, Train loss: 0.512, Test loss: 0.716, Test accuracy: 70.95 

Round  22, Global train loss: 0.512, Global test loss: 2.322, Global test accuracy: 26.30 

Round  23, Train loss: 0.460, Test loss: 0.712, Test accuracy: 71.08 

Round  23, Global train loss: 0.460, Global test loss: 2.317, Global test accuracy: 24.30 

Round  24, Train loss: 0.503, Test loss: 0.740, Test accuracy: 70.68 

Round  24, Global train loss: 0.503, Global test loss: 2.142, Global test accuracy: 25.23 

Round  25, Train loss: 0.603, Test loss: 0.755, Test accuracy: 70.18 

Round  25, Global train loss: 0.603, Global test loss: 2.165, Global test accuracy: 30.17 

Round  26, Train loss: 0.373, Test loss: 0.758, Test accuracy: 70.83 

Round  26, Global train loss: 0.373, Global test loss: 2.180, Global test accuracy: 21.00 

Round  27, Train loss: 0.432, Test loss: 0.741, Test accuracy: 71.22 

Round  27, Global train loss: 0.432, Global test loss: 2.054, Global test accuracy: 27.55 

Round  28, Train loss: 0.554, Test loss: 0.735, Test accuracy: 71.50 

Round  28, Global train loss: 0.554, Global test loss: 2.080, Global test accuracy: 27.80 

Round  29, Train loss: 0.375, Test loss: 0.751, Test accuracy: 71.42 

Round  29, Global train loss: 0.375, Global test loss: 2.538, Global test accuracy: 25.93 

Round  30, Train loss: 0.439, Test loss: 0.753, Test accuracy: 71.32 

Round  30, Global train loss: 0.439, Global test loss: 2.092, Global test accuracy: 28.18 

Round  31, Train loss: 0.448, Test loss: 0.783, Test accuracy: 71.30 

Round  31, Global train loss: 0.448, Global test loss: 2.110, Global test accuracy: 31.12 

Round  32, Train loss: 0.439, Test loss: 0.778, Test accuracy: 71.68 

Round  32, Global train loss: 0.439, Global test loss: 2.114, Global test accuracy: 21.42 

Round  33, Train loss: 0.473, Test loss: 0.776, Test accuracy: 71.85 

Round  33, Global train loss: 0.473, Global test loss: 2.172, Global test accuracy: 25.75 

Round  34, Train loss: 0.367, Test loss: 0.771, Test accuracy: 72.18 

Round  34, Global train loss: 0.367, Global test loss: 2.163, Global test accuracy: 28.82 

Round  35, Train loss: 0.410, Test loss: 0.745, Test accuracy: 72.92 

Round  35, Global train loss: 0.410, Global test loss: 2.117, Global test accuracy: 21.95 

Round  36, Train loss: 0.295, Test loss: 0.746, Test accuracy: 73.03 

Round  36, Global train loss: 0.295, Global test loss: 2.268, Global test accuracy: 23.52 

Round  37, Train loss: 0.436, Test loss: 0.770, Test accuracy: 72.90 

Round  37, Global train loss: 0.436, Global test loss: 2.083, Global test accuracy: 28.98 

Round  38, Train loss: 0.249, Test loss: 0.759, Test accuracy: 73.17 

Round  38, Global train loss: 0.249, Global test loss: 2.268, Global test accuracy: 26.45 

Round  39, Train loss: 0.244, Test loss: 0.773, Test accuracy: 72.98 

Round  39, Global train loss: 0.244, Global test loss: 2.198, Global test accuracy: 22.52 

Round  40, Train loss: 0.308, Test loss: 0.787, Test accuracy: 73.48 

Round  40, Global train loss: 0.308, Global test loss: 2.100, Global test accuracy: 22.48 

Round  41, Train loss: 0.252, Test loss: 0.793, Test accuracy: 73.32 

Round  41, Global train loss: 0.252, Global test loss: 2.003, Global test accuracy: 30.08 

Round  42, Train loss: 0.273, Test loss: 0.801, Test accuracy: 73.48 

Round  42, Global train loss: 0.273, Global test loss: 2.141, Global test accuracy: 25.55 

Round  43, Train loss: 0.275, Test loss: 0.805, Test accuracy: 73.53 

Round  43, Global train loss: 0.275, Global test loss: 2.162, Global test accuracy: 25.73 

Round  44, Train loss: 0.258, Test loss: 0.830, Test accuracy: 73.12 

Round  44, Global train loss: 0.258, Global test loss: 2.429, Global test accuracy: 25.83 

Round  45, Train loss: 0.252, Test loss: 0.812, Test accuracy: 73.57 

Round  45, Global train loss: 0.252, Global test loss: 2.257, Global test accuracy: 24.45 

Round  46, Train loss: 0.410, Test loss: 0.823, Test accuracy: 73.42 

Round  46, Global train loss: 0.410, Global test loss: 2.357, Global test accuracy: 27.32 

Round  47, Train loss: 0.297, Test loss: 0.847, Test accuracy: 73.08 

Round  47, Global train loss: 0.297, Global test loss: 2.085, Global test accuracy: 32.97 

Round  48, Train loss: 0.262, Test loss: 0.851, Test accuracy: 73.15 

Round  48, Global train loss: 0.262, Global test loss: 2.124, Global test accuracy: 22.33 

Round  49, Train loss: 0.309, Test loss: 0.848, Test accuracy: 73.42 

Round  49, Global train loss: 0.309, Global test loss: 2.123, Global test accuracy: 23.08 

Round  50, Train loss: 0.340, Test loss: 0.869, Test accuracy: 73.43 

Round  50, Global train loss: 0.340, Global test loss: 2.282, Global test accuracy: 21.08 

Round  51, Train loss: 0.175, Test loss: 0.862, Test accuracy: 73.68 

Round  51, Global train loss: 0.175, Global test loss: 2.030, Global test accuracy: 35.10 

Round  52, Train loss: 0.293, Test loss: 0.892, Test accuracy: 73.20 

Round  52, Global train loss: 0.293, Global test loss: 2.159, Global test accuracy: 24.82 

Round  53, Train loss: 0.262, Test loss: 0.925, Test accuracy: 73.13 

Round  53, Global train loss: 0.262, Global test loss: 2.057, Global test accuracy: 25.90 

Round  54, Train loss: 0.289, Test loss: 0.911, Test accuracy: 73.68 

Round  54, Global train loss: 0.289, Global test loss: 2.105, Global test accuracy: 29.37 

Round  55, Train loss: 0.200, Test loss: 0.936, Test accuracy: 73.63 

Round  55, Global train loss: 0.200, Global test loss: 2.144, Global test accuracy: 23.30 

Round  56, Train loss: 0.232, Test loss: 0.949, Test accuracy: 73.55 

Round  56, Global train loss: 0.232, Global test loss: 2.008, Global test accuracy: 30.52 

Round  57, Train loss: 0.156, Test loss: 0.965, Test accuracy: 73.47 

Round  57, Global train loss: 0.156, Global test loss: 2.296, Global test accuracy: 20.13 

Round  58, Train loss: 0.270, Test loss: 0.973, Test accuracy: 73.77 

Round  58, Global train loss: 0.270, Global test loss: 2.115, Global test accuracy: 23.65 

Round  59, Train loss: 0.199, Test loss: 0.973, Test accuracy: 74.03 

Round  59, Global train loss: 0.199, Global test loss: 1.971, Global test accuracy: 28.67 

Round  60, Train loss: 0.161, Test loss: 0.987, Test accuracy: 73.73 

Round  60, Global train loss: 0.161, Global test loss: 2.233, Global test accuracy: 23.17 

Round  61, Train loss: 0.269, Test loss: 1.029, Test accuracy: 73.47 

Round  61, Global train loss: 0.269, Global test loss: 2.213, Global test accuracy: 16.05 

Round  62, Train loss: 0.261, Test loss: 1.008, Test accuracy: 73.67 

Round  62, Global train loss: 0.261, Global test loss: 2.215, Global test accuracy: 30.42 

Round  63, Train loss: 0.152, Test loss: 1.036, Test accuracy: 73.65 

Round  63, Global train loss: 0.152, Global test loss: 2.188, Global test accuracy: 29.17 

Round  64, Train loss: 0.160, Test loss: 1.058, Test accuracy: 73.60 

Round  64, Global train loss: 0.160, Global test loss: 2.172, Global test accuracy: 28.50 

Round  65, Train loss: 0.142, Test loss: 1.067, Test accuracy: 73.02 

Round  65, Global train loss: 0.142, Global test loss: 2.198, Global test accuracy: 24.70 

Round  66, Train loss: 0.224, Test loss: 1.146, Test accuracy: 72.25 

Round  66, Global train loss: 0.224, Global test loss: 2.311, Global test accuracy: 28.58 

Round  67, Train loss: 0.199, Test loss: 1.100, Test accuracy: 72.87 

Round  67, Global train loss: 0.199, Global test loss: 2.083, Global test accuracy: 22.15 

Round  68, Train loss: 0.145, Test loss: 1.072, Test accuracy: 73.43 

Round  68, Global train loss: 0.145, Global test loss: 2.041, Global test accuracy: 30.18 

Round  69, Train loss: 0.131, Test loss: 1.080, Test accuracy: 73.05 

Round  69, Global train loss: 0.131, Global test loss: 2.086, Global test accuracy: 27.83 

Round  70, Train loss: 0.151, Test loss: 1.059, Test accuracy: 73.23 

Round  70, Global train loss: 0.151, Global test loss: 2.123, Global test accuracy: 30.58 

Round  71, Train loss: 0.139, Test loss: 1.087, Test accuracy: 72.97 

Round  71, Global train loss: 0.139, Global test loss: 1.998, Global test accuracy: 28.78 

Round  72, Train loss: 0.113, Test loss: 1.096, Test accuracy: 72.93 

Round  72, Global train loss: 0.113, Global test loss: 2.154, Global test accuracy: 27.10 

Round  73, Train loss: 0.173, Test loss: 1.158, Test accuracy: 72.42 

Round  73, Global train loss: 0.173, Global test loss: 2.073, Global test accuracy: 28.32 

Round  74, Train loss: 0.125, Test loss: 1.141, Test accuracy: 72.75 

Round  74, Global train loss: 0.125, Global test loss: 2.011, Global test accuracy: 28.22 

Round  75, Train loss: 0.127, Test loss: 1.154, Test accuracy: 72.38 

Round  75, Global train loss: 0.127, Global test loss: 2.104, Global test accuracy: 28.92 

Round  76, Train loss: 0.160, Test loss: 1.189, Test accuracy: 72.63 

Round  76, Global train loss: 0.160, Global test loss: 2.063, Global test accuracy: 28.87 

Round  77, Train loss: 0.091, Test loss: 1.169, Test accuracy: 72.72 

Round  77, Global train loss: 0.091, Global test loss: 2.100, Global test accuracy: 29.43 

Round  78, Train loss: 0.125, Test loss: 1.148, Test accuracy: 72.73 

Round  78, Global train loss: 0.125, Global test loss: 2.013, Global test accuracy: 30.38 

Round  79, Train loss: 0.116, Test loss: 1.178, Test accuracy: 72.75 

Round  79, Global train loss: 0.116, Global test loss: 2.064, Global test accuracy: 25.92 

Round  80, Train loss: 0.105, Test loss: 1.217, Test accuracy: 72.75 

Round  80, Global train loss: 0.105, Global test loss: 1.994, Global test accuracy: 32.55 

Round  81, Train loss: 0.092, Test loss: 1.222, Test accuracy: 72.78 

Round  81, Global train loss: 0.092, Global test loss: 2.124, Global test accuracy: 25.67 

Round  82, Train loss: 0.110, Test loss: 1.203, Test accuracy: 73.15 

Round  82, Global train loss: 0.110, Global test loss: 2.109, Global test accuracy: 27.58 

Round  83, Train loss: 0.110, Test loss: 1.212, Test accuracy: 73.58 

Round  83, Global train loss: 0.110, Global test loss: 2.234, Global test accuracy: 26.22 

Round  84, Train loss: 0.114, Test loss: 1.190, Test accuracy: 73.53 

Round  84, Global train loss: 0.114, Global test loss: 2.048, Global test accuracy: 27.02 

Round  85, Train loss: 0.089, Test loss: 1.182, Test accuracy: 73.83 

Round  85, Global train loss: 0.089, Global test loss: 2.086, Global test accuracy: 29.78 

Round  86, Train loss: 0.069, Test loss: 1.222, Test accuracy: 74.02 

Round  86, Global train loss: 0.069, Global test loss: 2.087, Global test accuracy: 25.75 

Round  87, Train loss: 0.104, Test loss: 1.247, Test accuracy: 74.02 

Round  87, Global train loss: 0.104, Global test loss: 2.112, Global test accuracy: 21.95 

Round  88, Train loss: 0.078, Test loss: 1.204, Test accuracy: 74.83 

Round  88, Global train loss: 0.078, Global test loss: 2.746, Global test accuracy: 25.73 

Round  89, Train loss: 0.111, Test loss: 1.258, Test accuracy: 74.13 

Round  89, Global train loss: 0.111, Global test loss: 2.167, Global test accuracy: 21.43 

Round  90, Train loss: 0.098, Test loss: 1.282, Test accuracy: 73.95 

Round  90, Global train loss: 0.098, Global test loss: 2.057, Global test accuracy: 27.40 

Round  91, Train loss: 0.082, Test loss: 1.315, Test accuracy: 73.70 

Round  91, Global train loss: 0.082, Global test loss: 2.016, Global test accuracy: 29.78 

Round  92, Train loss: 0.078, Test loss: 1.303, Test accuracy: 73.78 

Round  92, Global train loss: 0.078, Global test loss: 2.083, Global test accuracy: 27.12 

Round  93, Train loss: 0.079, Test loss: 1.285, Test accuracy: 73.88 

Round  93, Global train loss: 0.079, Global test loss: 2.102, Global test accuracy: 25.75 

Round  94, Train loss: 0.080, Test loss: 1.280, Test accuracy: 73.85 

Round  94, Global train loss: 0.080, Global test loss: 2.151, Global test accuracy: 16.90 

Round  95, Train loss: 0.109, Test loss: 1.306, Test accuracy: 73.42 

Round  95, Global train loss: 0.109, Global test loss: 2.101, Global test accuracy: 23.60 

Round  96, Train loss: 0.067, Test loss: 1.275, Test accuracy: 73.93 

Round  96, Global train loss: 0.067, Global test loss: 2.366, Global test accuracy: 20.93 

Round  97, Train loss: 0.089, Test loss: 1.270, Test accuracy: 73.98 

Round  97, Global train loss: 0.089, Global test loss: 2.358, Global test accuracy: 25.77 

Round  98, Train loss: 0.051, Test loss: 1.260, Test accuracy: 74.47 

Round  98, Global train loss: 0.051, Global test loss: 2.065, Global test accuracy: 28.78 

Round  99, Train loss: 0.045, Test loss: 1.318, Test accuracy: 74.15 

Round  99, Global train loss: 0.045, Global test loss: 2.166, Global test accuracy: 22.22 

Final Round, Train loss: 0.067, Test loss: 1.380, Test accuracy: 74.08 

Final Round, Global train loss: 0.067, Global test loss: 2.166, Global test accuracy: 22.22 

Average accuracy final 10 rounds: 73.91166666666668 

Average global accuracy final 10 rounds: 24.825000000000003 

1071.702574968338
[3.1705753803253174, 4.245746374130249, 5.316850423812866, 6.394582033157349, 7.492797613143921, 8.626570463180542, 9.704574823379517, 10.78037405014038, 11.856940031051636, 12.934921503067017, 14.012092113494873, 15.10041069984436, 16.181586980819702, 17.26633071899414, 18.349278211593628, 19.43156671524048, 20.51831030845642, 21.590883493423462, 22.66316246986389, 23.741546869277954, 24.820412158966064, 25.895050287246704, 26.973572492599487, 28.04613423347473, 29.12498641014099, 30.20013403892517, 31.27816605567932, 32.35037565231323, 33.41690516471863, 34.49745059013367, 35.5741810798645, 36.65091371536255, 37.730149030685425, 38.804651975631714, 39.880847692489624, 40.95252585411072, 42.0332236289978, 43.11332082748413, 44.19035029411316, 45.270901679992676, 46.36200428009033, 47.441097021102905, 48.51699924468994, 49.59474301338196, 50.68000364303589, 51.76269197463989, 52.843289613723755, 53.92224335670471, 55.008758544921875, 56.08316421508789, 57.15936732292175, 58.23779225349426, 59.314295530319214, 60.394614458084106, 61.471338748931885, 62.547683238983154, 63.62851881980896, 64.70593905448914, 65.7807023525238, 66.85750794410706, 67.93248987197876, 69.01299977302551, 70.08965587615967, 71.17074465751648, 72.24717926979065, 73.32153797149658, 74.39835357666016, 75.47399735450745, 76.55149126052856, 77.62665963172913, 78.70189452171326, 79.78115510940552, 80.88228869438171, 81.96075057983398, 83.04515743255615, 84.12966704368591, 85.21295809745789, 86.29433965682983, 87.37712693214417, 88.46150302886963, 89.54348683357239, 90.6253731250763, 91.70848274230957, 92.80890274047852, 93.88275218009949, 94.95639419555664, 96.0277464389801, 97.1019275188446, 98.17605638504028, 99.24818921089172, 100.32176685333252, 101.39158201217651, 102.45958971977234, 103.53359079360962, 104.60461068153381, 105.6773624420166, 106.75132894515991, 107.82555150985718, 108.90209197998047, 109.9790403842926, 112.13250780105591]
[22.966666666666665, 42.083333333333336, 47.15, 50.0, 56.516666666666666, 58.38333333333333, 58.63333333333333, 62.3, 64.06666666666666, 64.46666666666667, 65.25, 65.96666666666667, 66.93333333333334, 67.58333333333333, 68.71666666666667, 68.73333333333333, 68.55, 69.51666666666667, 69.63333333333334, 69.25, 69.98333333333333, 70.61666666666666, 70.95, 71.08333333333333, 70.68333333333334, 70.18333333333334, 70.83333333333333, 71.21666666666667, 71.5, 71.41666666666667, 71.31666666666666, 71.3, 71.68333333333334, 71.85, 72.18333333333334, 72.91666666666667, 73.03333333333333, 72.9, 73.16666666666667, 72.98333333333333, 73.48333333333333, 73.31666666666666, 73.48333333333333, 73.53333333333333, 73.11666666666666, 73.56666666666666, 73.41666666666667, 73.08333333333333, 73.15, 73.41666666666667, 73.43333333333334, 73.68333333333334, 73.2, 73.13333333333334, 73.68333333333334, 73.63333333333334, 73.55, 73.46666666666667, 73.76666666666667, 74.03333333333333, 73.73333333333333, 73.46666666666667, 73.66666666666667, 73.65, 73.6, 73.01666666666667, 72.25, 72.86666666666666, 73.43333333333334, 73.05, 73.23333333333333, 72.96666666666667, 72.93333333333334, 72.41666666666667, 72.75, 72.38333333333334, 72.63333333333334, 72.71666666666667, 72.73333333333333, 72.75, 72.75, 72.78333333333333, 73.15, 73.58333333333333, 73.53333333333333, 73.83333333333333, 74.01666666666667, 74.01666666666667, 74.83333333333333, 74.13333333333334, 73.95, 73.7, 73.78333333333333, 73.88333333333334, 73.85, 73.41666666666667, 73.93333333333334, 73.98333333333333, 74.46666666666667, 74.15, 74.08333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.236, Test loss: 1.962, Test accuracy: 23.88 

Round   0, Global train loss: 1.236, Global test loss: 2.296, Global test accuracy: 17.33 

Round   1, Train loss: 1.040, Test loss: 1.704, Test accuracy: 32.98 

Round   1, Global train loss: 1.040, Global test loss: 2.250, Global test accuracy: 21.28 

Round   2, Train loss: 0.893, Test loss: 1.450, Test accuracy: 38.60 

Round   2, Global train loss: 0.893, Global test loss: 2.310, Global test accuracy: 14.73 

Round   3, Train loss: 0.911, Test loss: 1.284, Test accuracy: 47.12 

Round   3, Global train loss: 0.911, Global test loss: 2.051, Global test accuracy: 26.53 

Round   4, Train loss: 0.908, Test loss: 1.226, Test accuracy: 48.37 

Round   4, Global train loss: 0.908, Global test loss: 2.074, Global test accuracy: 24.75 

Round   5, Train loss: 0.879, Test loss: 1.043, Test accuracy: 57.25 

Round   5, Global train loss: 0.879, Global test loss: 2.067, Global test accuracy: 28.53 

Round   6, Train loss: 0.900, Test loss: 1.047, Test accuracy: 55.20 

Round   6, Global train loss: 0.900, Global test loss: 2.049, Global test accuracy: 22.93 

Round   7, Train loss: 0.798, Test loss: 0.971, Test accuracy: 60.63 

Round   7, Global train loss: 0.798, Global test loss: 1.914, Global test accuracy: 32.03 

Round   8, Train loss: 0.884, Test loss: 0.967, Test accuracy: 60.63 

Round   8, Global train loss: 0.884, Global test loss: 1.884, Global test accuracy: 32.52 

Round   9, Train loss: 0.721, Test loss: 1.013, Test accuracy: 58.72 

Round   9, Global train loss: 0.721, Global test loss: 2.148, Global test accuracy: 25.57 

Round  10, Train loss: 0.771, Test loss: 0.831, Test accuracy: 63.78 

Round  10, Global train loss: 0.771, Global test loss: 1.707, Global test accuracy: 38.23 

Round  11, Train loss: 0.736, Test loss: 0.823, Test accuracy: 65.03 

Round  11, Global train loss: 0.736, Global test loss: 1.939, Global test accuracy: 34.55 

Round  12, Train loss: 0.831, Test loss: 0.794, Test accuracy: 67.35 

Round  12, Global train loss: 0.831, Global test loss: 1.940, Global test accuracy: 37.18 

Round  13, Train loss: 0.724, Test loss: 0.777, Test accuracy: 68.25 

Round  13, Global train loss: 0.724, Global test loss: 1.725, Global test accuracy: 40.30 

Round  14, Train loss: 0.664, Test loss: 0.673, Test accuracy: 70.52 

Round  14, Global train loss: 0.664, Global test loss: 1.940, Global test accuracy: 32.98 

Round  15, Train loss: 0.688, Test loss: 0.676, Test accuracy: 70.72 

Round  15, Global train loss: 0.688, Global test loss: 1.725, Global test accuracy: 39.60 

Round  16, Train loss: 0.705, Test loss: 0.699, Test accuracy: 70.28 

Round  16, Global train loss: 0.705, Global test loss: 1.740, Global test accuracy: 39.92 

Round  17, Train loss: 0.701, Test loss: 0.707, Test accuracy: 70.23 

Round  17, Global train loss: 0.701, Global test loss: 1.760, Global test accuracy: 36.43 

Round  18, Train loss: 0.659, Test loss: 0.709, Test accuracy: 70.27 

Round  18, Global train loss: 0.659, Global test loss: 1.759, Global test accuracy: 43.33 

Round  19, Train loss: 0.626, Test loss: 0.677, Test accuracy: 71.28 

Round  19, Global train loss: 0.626, Global test loss: 1.913, Global test accuracy: 36.10 

Round  20, Train loss: 0.711, Test loss: 0.669, Test accuracy: 71.87 

Round  20, Global train loss: 0.711, Global test loss: 1.947, Global test accuracy: 37.35 

Round  21, Train loss: 0.640, Test loss: 0.661, Test accuracy: 72.25 

Round  21, Global train loss: 0.640, Global test loss: 1.714, Global test accuracy: 42.55 

Round  22, Train loss: 0.674, Test loss: 0.652, Test accuracy: 72.60 

Round  22, Global train loss: 0.674, Global test loss: 1.780, Global test accuracy: 43.57 

Round  23, Train loss: 0.648, Test loss: 0.646, Test accuracy: 72.73 

Round  23, Global train loss: 0.648, Global test loss: 1.522, Global test accuracy: 46.33 

Round  24, Train loss: 0.665, Test loss: 0.636, Test accuracy: 73.10 

Round  24, Global train loss: 0.665, Global test loss: 1.539, Global test accuracy: 44.70 

Round  25, Train loss: 0.579, Test loss: 0.623, Test accuracy: 73.92 

Round  25, Global train loss: 0.579, Global test loss: 1.665, Global test accuracy: 42.65 

Round  26, Train loss: 0.662, Test loss: 0.619, Test accuracy: 74.00 

Round  26, Global train loss: 0.662, Global test loss: 1.702, Global test accuracy: 42.80 

Round  27, Train loss: 0.656, Test loss: 0.621, Test accuracy: 73.50 

Round  27, Global train loss: 0.656, Global test loss: 1.670, Global test accuracy: 39.28 

Round  28, Train loss: 0.506, Test loss: 0.629, Test accuracy: 73.43 

Round  28, Global train loss: 0.506, Global test loss: 1.547, Global test accuracy: 45.42 

Round  29, Train loss: 0.514, Test loss: 0.632, Test accuracy: 73.50 

Round  29, Global train loss: 0.514, Global test loss: 1.494, Global test accuracy: 46.87 

Round  30, Train loss: 0.517, Test loss: 0.620, Test accuracy: 74.30 

Round  30, Global train loss: 0.517, Global test loss: 1.555, Global test accuracy: 45.92 

Round  31, Train loss: 0.570, Test loss: 0.638, Test accuracy: 73.55 

Round  31, Global train loss: 0.570, Global test loss: 1.485, Global test accuracy: 48.30 

Round  32, Train loss: 0.599, Test loss: 0.634, Test accuracy: 74.18 

Round  32, Global train loss: 0.599, Global test loss: 1.672, Global test accuracy: 46.00 

Round  33, Train loss: 0.636, Test loss: 0.632, Test accuracy: 74.57 

Round  33, Global train loss: 0.636, Global test loss: 1.430, Global test accuracy: 48.87 

Round  34, Train loss: 0.455, Test loss: 0.643, Test accuracy: 74.53 

Round  34, Global train loss: 0.455, Global test loss: 1.549, Global test accuracy: 46.02 

Round  35, Train loss: 0.529, Test loss: 0.628, Test accuracy: 74.72 

Round  35, Global train loss: 0.529, Global test loss: 1.651, Global test accuracy: 42.20 

Round  36, Train loss: 0.531, Test loss: 0.633, Test accuracy: 74.72 

Round  36, Global train loss: 0.531, Global test loss: 1.585, Global test accuracy: 45.67 

Round  37, Train loss: 0.471, Test loss: 0.624, Test accuracy: 74.97 

Round  37, Global train loss: 0.471, Global test loss: 1.412, Global test accuracy: 50.95 

Round  38, Train loss: 0.509, Test loss: 0.615, Test accuracy: 75.42 

Round  38, Global train loss: 0.509, Global test loss: 1.591, Global test accuracy: 44.45 

Round  39, Train loss: 0.578, Test loss: 0.624, Test accuracy: 75.08 

Round  39, Global train loss: 0.578, Global test loss: 1.509, Global test accuracy: 46.98 

Round  40, Train loss: 0.625, Test loss: 0.616, Test accuracy: 75.32 

Round  40, Global train loss: 0.625, Global test loss: 1.495, Global test accuracy: 46.95 

Round  41, Train loss: 0.452, Test loss: 0.602, Test accuracy: 75.90 

Round  41, Global train loss: 0.452, Global test loss: 1.436, Global test accuracy: 49.43 

Round  42, Train loss: 0.465, Test loss: 0.585, Test accuracy: 76.32 

Round  42, Global train loss: 0.465, Global test loss: 1.594, Global test accuracy: 45.95 

Round  43, Train loss: 0.555, Test loss: 0.588, Test accuracy: 76.45 

Round  43, Global train loss: 0.555, Global test loss: 1.528, Global test accuracy: 49.52 

Round  44, Train loss: 0.510, Test loss: 0.587, Test accuracy: 76.50 

Round  44, Global train loss: 0.510, Global test loss: 1.442, Global test accuracy: 52.48 

Round  45, Train loss: 0.485, Test loss: 0.600, Test accuracy: 76.20 

Round  45, Global train loss: 0.485, Global test loss: 1.576, Global test accuracy: 48.78 

Round  46, Train loss: 0.456, Test loss: 0.608, Test accuracy: 76.12 

Round  46, Global train loss: 0.456, Global test loss: 1.727, Global test accuracy: 45.90 

Round  47, Train loss: 0.452, Test loss: 0.604, Test accuracy: 75.93 

Round  47, Global train loss: 0.452, Global test loss: 1.606, Global test accuracy: 44.48 

Round  48, Train loss: 0.364, Test loss: 0.615, Test accuracy: 75.83 

Round  48, Global train loss: 0.364, Global test loss: 1.572, Global test accuracy: 48.82 

Round  49, Train loss: 0.509, Test loss: 0.631, Test accuracy: 75.42 

Round  49, Global train loss: 0.509, Global test loss: 1.404, Global test accuracy: 50.25 

Round  50, Train loss: 0.444, Test loss: 0.639, Test accuracy: 75.05 

Round  50, Global train loss: 0.444, Global test loss: 1.649, Global test accuracy: 45.95 

Round  51, Train loss: 0.464, Test loss: 0.636, Test accuracy: 75.32 

Round  51, Global train loss: 0.464, Global test loss: 1.463, Global test accuracy: 50.97 

Round  52, Train loss: 0.405, Test loss: 0.640, Test accuracy: 75.50 

Round  52, Global train loss: 0.405, Global test loss: 1.552, Global test accuracy: 50.90 

Round  53, Train loss: 0.421, Test loss: 0.619, Test accuracy: 76.55 

Round  53, Global train loss: 0.421, Global test loss: 1.495, Global test accuracy: 52.62 

Round  54, Train loss: 0.414, Test loss: 0.630, Test accuracy: 76.63 

Round  54, Global train loss: 0.414, Global test loss: 1.473, Global test accuracy: 53.33 

Round  55, Train loss: 0.349, Test loss: 0.621, Test accuracy: 76.90 

Round  55, Global train loss: 0.349, Global test loss: 1.630, Global test accuracy: 48.35 

Round  56, Train loss: 0.401, Test loss: 0.630, Test accuracy: 76.57 

Round  56, Global train loss: 0.401, Global test loss: 1.409, Global test accuracy: 53.87 

Round  57, Train loss: 0.414, Test loss: 0.639, Test accuracy: 76.32 

Round  57, Global train loss: 0.414, Global test loss: 1.366, Global test accuracy: 53.65 

Round  58, Train loss: 0.358, Test loss: 0.619, Test accuracy: 77.00 

Round  58, Global train loss: 0.358, Global test loss: 1.428, Global test accuracy: 52.53 

Round  59, Train loss: 0.342, Test loss: 0.641, Test accuracy: 76.97 

Round  59, Global train loss: 0.342, Global test loss: 1.416, Global test accuracy: 55.23 

Round  60, Train loss: 0.346, Test loss: 0.658, Test accuracy: 76.67 

Round  60, Global train loss: 0.346, Global test loss: 1.546, Global test accuracy: 51.45 

Round  61, Train loss: 0.416, Test loss: 0.630, Test accuracy: 77.27 

Round  61, Global train loss: 0.416, Global test loss: 1.441, Global test accuracy: 51.88 

Round  62, Train loss: 0.410, Test loss: 0.619, Test accuracy: 77.82 

Round  62, Global train loss: 0.410, Global test loss: 1.480, Global test accuracy: 52.70 

Round  63, Train loss: 0.382, Test loss: 0.648, Test accuracy: 77.42 

Round  63, Global train loss: 0.382, Global test loss: 1.442, Global test accuracy: 52.50 

Round  64, Train loss: 0.453, Test loss: 0.653, Test accuracy: 77.03 

Round  64, Global train loss: 0.453, Global test loss: 1.519, Global test accuracy: 51.60 

Round  65, Train loss: 0.357, Test loss: 0.668, Test accuracy: 76.80 

Round  65, Global train loss: 0.357, Global test loss: 1.657, Global test accuracy: 47.52 

Round  66, Train loss: 0.376, Test loss: 0.671, Test accuracy: 76.72 

Round  66, Global train loss: 0.376, Global test loss: 1.421, Global test accuracy: 53.12 

Round  67, Train loss: 0.321, Test loss: 0.683, Test accuracy: 76.43 

Round  67, Global train loss: 0.321, Global test loss: 1.510, Global test accuracy: 51.32 

Round  68, Train loss: 0.374, Test loss: 0.651, Test accuracy: 77.15 

Round  68, Global train loss: 0.374, Global test loss: 1.384, Global test accuracy: 54.87 

Round  69, Train loss: 0.366, Test loss: 0.652, Test accuracy: 77.02 

Round  69, Global train loss: 0.366, Global test loss: 1.299, Global test accuracy: 56.65 

Round  70, Train loss: 0.276, Test loss: 0.667, Test accuracy: 77.00 

Round  70, Global train loss: 0.276, Global test loss: 1.628, Global test accuracy: 49.08 

Round  71, Train loss: 0.276, Test loss: 0.670, Test accuracy: 76.85 

Round  71, Global train loss: 0.276, Global test loss: 1.723, Global test accuracy: 48.08 

Round  72, Train loss: 0.376, Test loss: 0.664, Test accuracy: 77.22 

Round  72, Global train loss: 0.376, Global test loss: 1.990, Global test accuracy: 45.55 

Round  73, Train loss: 0.356, Test loss: 0.673, Test accuracy: 76.95 

Round  73, Global train loss: 0.356, Global test loss: 1.447, Global test accuracy: 53.73 

Round  74, Train loss: 0.402, Test loss: 0.664, Test accuracy: 76.98 

Round  74, Global train loss: 0.402, Global test loss: 1.377, Global test accuracy: 55.22 

Round  75, Train loss: 0.330, Test loss: 0.664, Test accuracy: 77.05 

Round  75, Global train loss: 0.330, Global test loss: 1.463, Global test accuracy: 53.62 

Round  76, Train loss: 0.284, Test loss: 0.672, Test accuracy: 77.10 

Round  76, Global train loss: 0.284, Global test loss: 1.528, Global test accuracy: 53.25 

Round  77, Train loss: 0.321, Test loss: 0.666, Test accuracy: 77.07 

Round  77, Global train loss: 0.321, Global test loss: 1.327, Global test accuracy: 56.55 

Round  78, Train loss: 0.302, Test loss: 0.653, Test accuracy: 77.70 

Round  78, Global train loss: 0.302, Global test loss: 1.594, Global test accuracy: 52.73 

Round  79, Train loss: 0.282, Test loss: 0.653, Test accuracy: 77.58 

Round  79, Global train loss: 0.282, Global test loss: 1.410, Global test accuracy: 55.53 

Round  80, Train loss: 0.246, Test loss: 0.662, Test accuracy: 77.12 

Round  80, Global train loss: 0.246, Global test loss: 1.877, Global test accuracy: 47.28 

Round  81, Train loss: 0.284, Test loss: 0.676, Test accuracy: 77.13 

Round  81, Global train loss: 0.284, Global test loss: 1.569, Global test accuracy: 52.40 

Round  82, Train loss: 0.286, Test loss: 0.672, Test accuracy: 77.68 

Round  82, Global train loss: 0.286, Global test loss: 1.495, Global test accuracy: 54.57 

Round  83, Train loss: 0.277, Test loss: 0.658, Test accuracy: 78.30 

Round  83, Global train loss: 0.277, Global test loss: 1.758, Global test accuracy: 46.82 

Round  84, Train loss: 0.294, Test loss: 0.639, Test accuracy: 78.65 

Round  84, Global train loss: 0.294, Global test loss: 1.407, Global test accuracy: 55.28 

Round  85, Train loss: 0.321, Test loss: 0.641, Test accuracy: 78.20 

Round  85, Global train loss: 0.321, Global test loss: 1.469, Global test accuracy: 52.85 

Round  86, Train loss: 0.305, Test loss: 0.650, Test accuracy: 78.25 

Round  86, Global train loss: 0.305, Global test loss: 1.477, Global test accuracy: 54.72 

Round  87, Train loss: 0.336, Test loss: 0.630, Test accuracy: 79.17 

Round  87, Global train loss: 0.336, Global test loss: 1.467, Global test accuracy: 54.60 

Round  88, Train loss: 0.285, Test loss: 0.635, Test accuracy: 79.23 

Round  88, Global train loss: 0.285, Global test loss: 1.660, Global test accuracy: 52.22 

Round  89, Train loss: 0.239, Test loss: 0.647, Test accuracy: 79.05 

Round  89, Global train loss: 0.239, Global test loss: 1.969, Global test accuracy: 48.25 

Round  90, Train loss: 0.338, Test loss: 0.669, Test accuracy: 78.48 

Round  90, Global train loss: 0.338, Global test loss: 1.618, Global test accuracy: 51.65 

Round  91, Train loss: 0.253, Test loss: 0.657, Test accuracy: 79.18 

Round  91, Global train loss: 0.253, Global test loss: 1.479, Global test accuracy: 54.12 

Round  92, Train loss: 0.296, Test loss: 0.669, Test accuracy: 78.75 

Round  92, Global train loss: 0.296, Global test loss: 1.416, Global test accuracy: 55.57 

Round  93, Train loss: 0.294, Test loss: 0.694, Test accuracy: 77.98 

Round  93, Global train loss: 0.294, Global test loss: 1.548, Global test accuracy: 53.00 

Round  94, Train loss: 0.250, Test loss: 0.707, Test accuracy: 77.42 

Round  94, Global train loss: 0.250, Global test loss: 1.525, Global test accuracy: 55.55 

Round  95, Train loss: 0.300, Test loss: 0.715, Test accuracy: 77.28 

Round  95, Global train loss: 0.300, Global test loss: 1.469, Global test accuracy: 56.72 

Round  96, Train loss: 0.322, Test loss: 0.717, Test accuracy: 77.20 

Round  96, Global train loss: 0.322, Global test loss: 1.496, Global test accuracy: 54.83 

Round  97, Train loss: 0.297, Test loss: 0.710, Test accuracy: 77.53 

Round  97, Global train loss: 0.297, Global test loss: 1.437, Global test accuracy: 56.63 

Round  98, Train loss: 0.238, Test loss: 0.727, Test accuracy: 77.72 

Round  98, Global train loss: 0.238, Global test loss: 1.444, Global test accuracy: 57.13 

Round  99, Train loss: 0.291, Test loss: 0.726, Test accuracy: 77.65 

Round  99, Global train loss: 0.291, Global test loss: 1.567, Global test accuracy: 53.40 

Final Round, Train loss: 0.230, Test loss: 0.803, Test accuracy: 77.88 

Final Round, Global train loss: 0.230, Global test loss: 1.567, Global test accuracy: 53.40 

Average accuracy final 10 rounds: 77.91999999999999 

Average global accuracy final 10 rounds: 54.86 

1096.9532339572906
[3.3252930641174316, 4.544652462005615, 5.764466762542725, 6.983431100845337, 8.196228265762329, 9.410619020462036, 10.623618364334106, 11.84001612663269, 13.05566143989563, 14.271160125732422, 15.488212585449219, 16.565854787826538, 17.639647960662842, 18.716745615005493, 19.792589902877808, 20.88907480239868, 21.961381196975708, 23.040085554122925, 24.119070768356323, 25.195335865020752, 26.27156949043274, 27.385253429412842, 28.463107347488403, 29.543553113937378, 30.76288104057312, 31.886106491088867, 33.01486825942993, 34.09452223777771, 35.21560883522034, 36.342652797698975, 37.46811890602112, 38.555445432662964, 39.64798665046692, 40.72771143913269, 41.80536484718323, 42.887667179107666, 43.97125744819641, 45.09578776359558, 46.231773138046265, 47.31321620941162, 48.391284465789795, 49.470059394836426, 50.548726081848145, 51.62655520439148, 52.706825971603394, 53.787609815597534, 54.877936601638794, 56.11446952819824, 57.33603096008301, 58.552096128463745, 59.63360357284546, 60.728750705718994, 61.812232971191406, 62.8925096988678, 63.97298502922058, 65.05341386795044, 66.14672183990479, 67.2266366481781, 68.30089116096497, 69.37967801094055, 70.45454788208008, 71.5327160358429, 72.66882967948914, 73.74907350540161, 74.8270411491394, 75.9047794342041, 76.98016834259033, 78.06685280799866, 79.15780210494995, 80.24652123451233, 81.33323931694031, 82.41066384315491, 83.48731541633606, 84.56206917762756, 85.63566327095032, 86.71219992637634, 87.78651857376099, 88.8618323802948, 89.94237208366394, 91.0366621017456, 92.11888194084167, 93.21239352226257, 94.28411221504211, 95.3568046092987, 96.434086561203, 97.51153445243835, 98.6526563167572, 99.74052333831787, 100.82547116279602, 101.95412349700928, 103.08819317817688, 104.22350001335144, 105.35413455963135, 106.48226380348206, 107.62861180305481, 108.72781920433044, 109.79968667030334, 110.87163043022156, 111.94519639015198, 113.02181005477905, 115.17453479766846]
[23.883333333333333, 32.983333333333334, 38.6, 47.11666666666667, 48.36666666666667, 57.25, 55.2, 60.63333333333333, 60.63333333333333, 58.71666666666667, 63.78333333333333, 65.03333333333333, 67.35, 68.25, 70.51666666666667, 70.71666666666667, 70.28333333333333, 70.23333333333333, 70.26666666666667, 71.28333333333333, 71.86666666666666, 72.25, 72.6, 72.73333333333333, 73.1, 73.91666666666667, 74.0, 73.5, 73.43333333333334, 73.5, 74.3, 73.55, 74.18333333333334, 74.56666666666666, 74.53333333333333, 74.71666666666667, 74.71666666666667, 74.96666666666667, 75.41666666666667, 75.08333333333333, 75.31666666666666, 75.9, 76.31666666666666, 76.45, 76.5, 76.2, 76.11666666666666, 75.93333333333334, 75.83333333333333, 75.41666666666667, 75.05, 75.31666666666666, 75.5, 76.55, 76.63333333333334, 76.9, 76.56666666666666, 76.31666666666666, 77.0, 76.96666666666667, 76.66666666666667, 77.26666666666667, 77.81666666666666, 77.41666666666667, 77.03333333333333, 76.8, 76.71666666666667, 76.43333333333334, 77.15, 77.01666666666667, 77.0, 76.85, 77.21666666666667, 76.95, 76.98333333333333, 77.05, 77.1, 77.06666666666666, 77.7, 77.58333333333333, 77.11666666666666, 77.13333333333334, 77.68333333333334, 78.3, 78.65, 78.2, 78.25, 79.16666666666667, 79.23333333333333, 79.05, 78.48333333333333, 79.18333333333334, 78.75, 77.98333333333333, 77.41666666666667, 77.28333333333333, 77.2, 77.53333333333333, 77.71666666666667, 77.65, 77.88333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.627, Test loss: 2.562, Test accuracy: 20.37 

Round   1, Train loss: 1.088, Test loss: 2.136, Test accuracy: 27.52 

Round   2, Train loss: 1.008, Test loss: 1.548, Test accuracy: 41.88 

Round   3, Train loss: 0.904, Test loss: 1.308, Test accuracy: 48.25 

Round   4, Train loss: 0.889, Test loss: 1.194, Test accuracy: 51.18 

Round   5, Train loss: 0.830, Test loss: 1.072, Test accuracy: 52.50 

Round   6, Train loss: 0.872, Test loss: 0.967, Test accuracy: 54.03 

Round   7, Train loss: 0.821, Test loss: 0.909, Test accuracy: 56.83 

Round   8, Train loss: 0.808, Test loss: 0.940, Test accuracy: 58.08 

Round   9, Train loss: 0.811, Test loss: 0.914, Test accuracy: 58.30 

Round  10, Train loss: 0.686, Test loss: 0.845, Test accuracy: 61.27 

Round  11, Train loss: 0.757, Test loss: 0.821, Test accuracy: 62.13 

Round  12, Train loss: 0.672, Test loss: 0.810, Test accuracy: 63.40 

Round  13, Train loss: 0.731, Test loss: 0.790, Test accuracy: 64.72 

Round  14, Train loss: 0.722, Test loss: 0.732, Test accuracy: 66.28 

Round  15, Train loss: 0.707, Test loss: 0.732, Test accuracy: 66.38 

Round  16, Train loss: 0.671, Test loss: 0.713, Test accuracy: 66.87 

Round  17, Train loss: 0.640, Test loss: 0.721, Test accuracy: 66.47 

Round  18, Train loss: 0.669, Test loss: 0.722, Test accuracy: 66.60 

Round  19, Train loss: 0.706, Test loss: 0.716, Test accuracy: 67.18 

Round  20, Train loss: 0.695, Test loss: 0.728, Test accuracy: 67.07 

Round  21, Train loss: 0.776, Test loss: 0.714, Test accuracy: 68.22 

Round  22, Train loss: 0.654, Test loss: 0.729, Test accuracy: 67.03 

Round  23, Train loss: 0.577, Test loss: 0.729, Test accuracy: 68.00 

Round  24, Train loss: 0.621, Test loss: 0.692, Test accuracy: 69.38 

Round  25, Train loss: 0.582, Test loss: 0.665, Test accuracy: 70.43 

Round  26, Train loss: 0.519, Test loss: 0.685, Test accuracy: 69.30 

Round  27, Train loss: 0.607, Test loss: 0.672, Test accuracy: 70.15 

Round  28, Train loss: 0.496, Test loss: 0.677, Test accuracy: 70.27 

Round  29, Train loss: 0.640, Test loss: 0.701, Test accuracy: 69.50 

Round  30, Train loss: 0.486, Test loss: 0.667, Test accuracy: 70.63 

Round  31, Train loss: 0.567, Test loss: 0.644, Test accuracy: 71.90 

Round  32, Train loss: 0.592, Test loss: 0.640, Test accuracy: 71.83 

Round  33, Train loss: 0.548, Test loss: 0.633, Test accuracy: 72.13 

Round  34, Train loss: 0.488, Test loss: 0.634, Test accuracy: 72.08 

Round  35, Train loss: 0.535, Test loss: 0.633, Test accuracy: 72.40 

Round  36, Train loss: 0.664, Test loss: 0.632, Test accuracy: 71.88 

Round  37, Train loss: 0.552, Test loss: 0.628, Test accuracy: 72.32 

Round  38, Train loss: 0.621, Test loss: 0.615, Test accuracy: 72.98 

Round  39, Train loss: 0.434, Test loss: 0.617, Test accuracy: 73.25 

Round  40, Train loss: 0.538, Test loss: 0.614, Test accuracy: 73.07 

Round  41, Train loss: 0.596, Test loss: 0.594, Test accuracy: 73.72 

Round  42, Train loss: 0.504, Test loss: 0.607, Test accuracy: 73.72 

Round  43, Train loss: 0.511, Test loss: 0.591, Test accuracy: 74.58 

Round  44, Train loss: 0.475, Test loss: 0.585, Test accuracy: 74.87 

Round  45, Train loss: 0.521, Test loss: 0.572, Test accuracy: 75.45 

Round  46, Train loss: 0.508, Test loss: 0.579, Test accuracy: 75.40 

Round  47, Train loss: 0.440, Test loss: 0.579, Test accuracy: 75.28 

Round  48, Train loss: 0.422, Test loss: 0.580, Test accuracy: 75.10 

Round  49, Train loss: 0.431, Test loss: 0.583, Test accuracy: 74.72 

Round  50, Train loss: 0.433, Test loss: 0.575, Test accuracy: 74.72 

Round  51, Train loss: 0.461, Test loss: 0.579, Test accuracy: 74.98 

Round  52, Train loss: 0.562, Test loss: 0.578, Test accuracy: 75.32 

Round  53, Train loss: 0.566, Test loss: 0.592, Test accuracy: 75.02 

Round  54, Train loss: 0.419, Test loss: 0.582, Test accuracy: 75.38 

Round  55, Train loss: 0.457, Test loss: 0.592, Test accuracy: 74.77 

Round  56, Train loss: 0.413, Test loss: 0.578, Test accuracy: 75.25 

Round  57, Train loss: 0.337, Test loss: 0.567, Test accuracy: 75.70 

Round  58, Train loss: 0.515, Test loss: 0.560, Test accuracy: 76.68 

Round  59, Train loss: 0.578, Test loss: 0.557, Test accuracy: 76.73 

Round  60, Train loss: 0.516, Test loss: 0.562, Test accuracy: 76.80 

Round  61, Train loss: 0.395, Test loss: 0.564, Test accuracy: 76.70 

Round  62, Train loss: 0.423, Test loss: 0.566, Test accuracy: 76.97 

Round  63, Train loss: 0.475, Test loss: 0.562, Test accuracy: 77.12 

Round  64, Train loss: 0.399, Test loss: 0.556, Test accuracy: 77.92 

Round  65, Train loss: 0.378, Test loss: 0.571, Test accuracy: 77.38 

Round  66, Train loss: 0.473, Test loss: 0.563, Test accuracy: 76.93 

Round  67, Train loss: 0.306, Test loss: 0.573, Test accuracy: 76.33 

Round  68, Train loss: 0.454, Test loss: 0.567, Test accuracy: 76.53 

Round  69, Train loss: 0.396, Test loss: 0.557, Test accuracy: 76.72 

Round  70, Train loss: 0.343, Test loss: 0.550, Test accuracy: 76.95 

Round  71, Train loss: 0.387, Test loss: 0.544, Test accuracy: 77.43 

Round  72, Train loss: 0.378, Test loss: 0.559, Test accuracy: 76.87 

Round  73, Train loss: 0.394, Test loss: 0.553, Test accuracy: 77.23 

Round  74, Train loss: 0.313, Test loss: 0.547, Test accuracy: 77.55 

Round  75, Train loss: 0.358, Test loss: 0.546, Test accuracy: 77.22 

Round  76, Train loss: 0.449, Test loss: 0.541, Test accuracy: 78.02 

Round  77, Train loss: 0.326, Test loss: 0.549, Test accuracy: 77.87 

Round  78, Train loss: 0.413, Test loss: 0.540, Test accuracy: 77.82 

Round  79, Train loss: 0.409, Test loss: 0.543, Test accuracy: 77.77 

Round  80, Train loss: 0.345, Test loss: 0.555, Test accuracy: 77.72 

Round  81, Train loss: 0.300, Test loss: 0.543, Test accuracy: 77.95 

Round  82, Train loss: 0.386, Test loss: 0.552, Test accuracy: 77.73 

Round  83, Train loss: 0.303, Test loss: 0.546, Test accuracy: 78.02 

Round  84, Train loss: 0.326, Test loss: 0.561, Test accuracy: 78.27 

Round  85, Train loss: 0.423, Test loss: 0.548, Test accuracy: 78.18 

Round  86, Train loss: 0.351, Test loss: 0.541, Test accuracy: 78.70 

Round  87, Train loss: 0.522, Test loss: 0.545, Test accuracy: 78.87 

Round  88, Train loss: 0.328, Test loss: 0.540, Test accuracy: 79.32 

Round  89, Train loss: 0.364, Test loss: 0.543, Test accuracy: 78.68 

Round  90, Train loss: 0.315, Test loss: 0.548, Test accuracy: 78.12 

Round  91, Train loss: 0.331, Test loss: 0.542, Test accuracy: 78.07 

Round  92, Train loss: 0.346, Test loss: 0.540, Test accuracy: 78.67 

Round  93, Train loss: 0.369, Test loss: 0.534, Test accuracy: 78.88 

Round  94, Train loss: 0.325, Test loss: 0.549, Test accuracy: 78.52 

Round  95, Train loss: 0.412, Test loss: 0.531, Test accuracy: 79.02 

Round  96, Train loss: 0.374, Test loss: 0.549, Test accuracy: 78.87 

Round  97, Train loss: 0.240, Test loss: 0.547, Test accuracy: 78.88 

Round  98, Train loss: 0.241, Test loss: 0.547, Test accuracy: 79.15 

Round  99, Train loss: 0.456, Test loss: 0.542, Test accuracy: 78.87 

Final Round, Train loss: 0.305, Test loss: 0.542, Test accuracy: 78.93 

Average accuracy final 10 rounds: 78.70333333333333 

793.6077437400818
[3.2439568042755127, 4.319978952407837, 5.271640777587891, 6.224650144577026, 7.183601140975952, 8.131852626800537, 9.113026142120361, 10.075495481491089, 11.018994569778442, 11.96440315246582, 12.914791345596313, 13.862446784973145, 14.833958387374878, 15.700268030166626, 16.663047790527344, 17.625964403152466, 18.5890691280365, 19.554057359695435, 20.534813165664673, 21.495204210281372, 22.452306032180786, 23.41083836555481, 24.397379398345947, 25.39004921913147, 26.381596088409424, 27.378260135650635, 28.371374130249023, 29.36250352859497, 30.35259509086609, 31.342981576919556, 32.334925413131714, 33.329564809799194, 34.31735062599182, 35.30881404876709, 36.29839324951172, 37.29307842254639, 38.24755334854126, 39.20262169837952, 40.15735077857971, 41.11226296424866, 42.038448095321655, 42.96009135246277, 43.939733266830444, 44.87584710121155, 45.795769929885864, 46.706743478775024, 47.628418922424316, 48.58580732345581, 49.54125237464905, 50.50942945480347, 51.45613241195679, 52.40322184562683, 53.3445508480072, 54.29235649108887, 55.23475384712219, 56.15018320083618, 57.09619355201721, 58.015957832336426, 58.94212102890015, 59.88620853424072, 60.834484577178955, 61.78190016746521, 62.726234674453735, 63.67278718948364, 64.62213659286499, 65.57107353210449, 66.5117199420929, 67.45298290252686, 68.40208745002747, 69.35026693344116, 70.30209732055664, 71.25375771522522, 72.20073938369751, 73.15285086631775, 74.10002613067627, 75.04467225074768, 75.99375653266907, 76.93696856498718, 77.88031053543091, 78.82798385620117, 79.77014470100403, 80.71194529533386, 81.69027280807495, 82.6427960395813, 83.59680223464966, 84.55111575126648, 85.49878120422363, 86.44699048995972, 87.39840459823608, 88.34762525558472, 89.2960593700409, 90.24610686302185, 91.1961133480072, 92.14308786392212, 93.0893657207489, 94.03553175926208, 94.98332667350769, 95.92868041992188, 96.87589240074158, 97.82210516929626, 99.34949994087219]
[20.366666666666667, 27.516666666666666, 41.88333333333333, 48.25, 51.18333333333333, 52.5, 54.03333333333333, 56.833333333333336, 58.083333333333336, 58.3, 61.266666666666666, 62.13333333333333, 63.4, 64.71666666666667, 66.28333333333333, 66.38333333333334, 66.86666666666666, 66.46666666666667, 66.6, 67.18333333333334, 67.06666666666666, 68.21666666666667, 67.03333333333333, 68.0, 69.38333333333334, 70.43333333333334, 69.3, 70.15, 70.26666666666667, 69.5, 70.63333333333334, 71.9, 71.83333333333333, 72.13333333333334, 72.08333333333333, 72.4, 71.88333333333334, 72.31666666666666, 72.98333333333333, 73.25, 73.06666666666666, 73.71666666666667, 73.71666666666667, 74.58333333333333, 74.86666666666666, 75.45, 75.4, 75.28333333333333, 75.1, 74.71666666666667, 74.71666666666667, 74.98333333333333, 75.31666666666666, 75.01666666666667, 75.38333333333334, 74.76666666666667, 75.25, 75.7, 76.68333333333334, 76.73333333333333, 76.8, 76.7, 76.96666666666667, 77.11666666666666, 77.91666666666667, 77.38333333333334, 76.93333333333334, 76.33333333333333, 76.53333333333333, 76.71666666666667, 76.95, 77.43333333333334, 76.86666666666666, 77.23333333333333, 77.55, 77.21666666666667, 78.01666666666667, 77.86666666666666, 77.81666666666666, 77.76666666666667, 77.71666666666667, 77.95, 77.73333333333333, 78.01666666666667, 78.26666666666667, 78.18333333333334, 78.7, 78.86666666666666, 79.31666666666666, 78.68333333333334, 78.11666666666666, 78.06666666666666, 78.66666666666667, 78.88333333333334, 78.51666666666667, 79.01666666666667, 78.86666666666666, 78.88333333333334, 79.15, 78.86666666666666, 78.93333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.692, Test loss: 2.211, Test accuracy: 25.43
Round   1, Train loss: 1.092, Test loss: 1.813, Test accuracy: 36.13
Round   2, Train loss: 0.982, Test loss: 1.795, Test accuracy: 38.65
Round   3, Train loss: 0.893, Test loss: 1.457, Test accuracy: 42.78
Round   4, Train loss: 0.898, Test loss: 1.158, Test accuracy: 50.00
Round   5, Train loss: 0.787, Test loss: 1.090, Test accuracy: 51.98
Round   6, Train loss: 0.770, Test loss: 1.020, Test accuracy: 54.65
Round   7, Train loss: 0.870, Test loss: 0.812, Test accuracy: 59.67
Round   8, Train loss: 0.764, Test loss: 0.797, Test accuracy: 61.92
Round   9, Train loss: 0.737, Test loss: 0.785, Test accuracy: 63.23
Round  10, Train loss: 0.799, Test loss: 0.763, Test accuracy: 64.02
Round  11, Train loss: 0.659, Test loss: 0.756, Test accuracy: 65.17
Round  12, Train loss: 0.642, Test loss: 0.751, Test accuracy: 65.82
Round  13, Train loss: 0.780, Test loss: 0.736, Test accuracy: 66.80
Round  14, Train loss: 0.715, Test loss: 0.717, Test accuracy: 68.42
Round  15, Train loss: 0.662, Test loss: 0.699, Test accuracy: 69.15
Round  16, Train loss: 0.654, Test loss: 0.689, Test accuracy: 69.05
Round  17, Train loss: 0.563, Test loss: 0.689, Test accuracy: 69.28
Round  18, Train loss: 0.569, Test loss: 0.672, Test accuracy: 69.93
Round  19, Train loss: 0.734, Test loss: 0.654, Test accuracy: 70.38
Round  20, Train loss: 0.733, Test loss: 0.654, Test accuracy: 70.53
Round  21, Train loss: 0.609, Test loss: 0.647, Test accuracy: 70.73
Round  22, Train loss: 0.580, Test loss: 0.637, Test accuracy: 71.23
Round  23, Train loss: 0.633, Test loss: 0.644, Test accuracy: 71.52
Round  24, Train loss: 0.633, Test loss: 0.631, Test accuracy: 72.75
Round  25, Train loss: 0.645, Test loss: 0.617, Test accuracy: 73.13
Round  26, Train loss: 0.686, Test loss: 0.612, Test accuracy: 73.25
Round  27, Train loss: 0.632, Test loss: 0.616, Test accuracy: 73.18
Round  28, Train loss: 0.590, Test loss: 0.614, Test accuracy: 73.22
Round  29, Train loss: 0.558, Test loss: 0.605, Test accuracy: 73.72
Round  30, Train loss: 0.575, Test loss: 0.609, Test accuracy: 73.27
Round  31, Train loss: 0.698, Test loss: 0.598, Test accuracy: 74.30
Round  32, Train loss: 0.513, Test loss: 0.596, Test accuracy: 74.67
Round  33, Train loss: 0.599, Test loss: 0.590, Test accuracy: 74.37
Round  34, Train loss: 0.556, Test loss: 0.583, Test accuracy: 75.15
Round  35, Train loss: 0.593, Test loss: 0.588, Test accuracy: 74.92
Round  36, Train loss: 0.651, Test loss: 0.584, Test accuracy: 75.18
Round  37, Train loss: 0.502, Test loss: 0.572, Test accuracy: 76.08
Round  38, Train loss: 0.540, Test loss: 0.579, Test accuracy: 75.28
Round  39, Train loss: 0.509, Test loss: 0.566, Test accuracy: 75.82
Round  40, Train loss: 0.444, Test loss: 0.566, Test accuracy: 76.13
Round  41, Train loss: 0.600, Test loss: 0.557, Test accuracy: 76.23
Round  42, Train loss: 0.496, Test loss: 0.563, Test accuracy: 75.95
Round  43, Train loss: 0.520, Test loss: 0.557, Test accuracy: 76.30
Round  44, Train loss: 0.553, Test loss: 0.564, Test accuracy: 76.42
Round  45, Train loss: 0.614, Test loss: 0.564, Test accuracy: 76.35
Round  46, Train loss: 0.499, Test loss: 0.546, Test accuracy: 77.20
Round  47, Train loss: 0.417, Test loss: 0.546, Test accuracy: 76.73
Round  48, Train loss: 0.497, Test loss: 0.541, Test accuracy: 76.87
Round  49, Train loss: 0.476, Test loss: 0.545, Test accuracy: 76.15
Round  50, Train loss: 0.505, Test loss: 0.539, Test accuracy: 76.78
Round  51, Train loss: 0.430, Test loss: 0.538, Test accuracy: 77.12
Round  52, Train loss: 0.538, Test loss: 0.542, Test accuracy: 77.35
Round  53, Train loss: 0.390, Test loss: 0.535, Test accuracy: 77.37
Round  54, Train loss: 0.456, Test loss: 0.532, Test accuracy: 77.27
Round  55, Train loss: 0.608, Test loss: 0.532, Test accuracy: 77.33
Round  56, Train loss: 0.407, Test loss: 0.528, Test accuracy: 77.78
Round  57, Train loss: 0.429, Test loss: 0.528, Test accuracy: 77.78
Round  58, Train loss: 0.514, Test loss: 0.527, Test accuracy: 77.78
Round  59, Train loss: 0.412, Test loss: 0.533, Test accuracy: 77.77
Round  60, Train loss: 0.438, Test loss: 0.530, Test accuracy: 77.97
Round  61, Train loss: 0.385, Test loss: 0.533, Test accuracy: 77.85
Round  62, Train loss: 0.353, Test loss: 0.533, Test accuracy: 77.57
Round  63, Train loss: 0.408, Test loss: 0.523, Test accuracy: 78.15
Round  64, Train loss: 0.373, Test loss: 0.522, Test accuracy: 78.38
Round  65, Train loss: 0.468, Test loss: 0.520, Test accuracy: 78.43
Round  66, Train loss: 0.375, Test loss: 0.514, Test accuracy: 78.40
Round  67, Train loss: 0.469, Test loss: 0.515, Test accuracy: 78.40
Round  68, Train loss: 0.465, Test loss: 0.511, Test accuracy: 78.75
Round  69, Train loss: 0.392, Test loss: 0.512, Test accuracy: 78.35
Round  70, Train loss: 0.507, Test loss: 0.510, Test accuracy: 78.65
Round  71, Train loss: 0.373, Test loss: 0.517, Test accuracy: 78.33
Round  72, Train loss: 0.544, Test loss: 0.514, Test accuracy: 78.77
Round  73, Train loss: 0.303, Test loss: 0.500, Test accuracy: 79.48
Round  74, Train loss: 0.445, Test loss: 0.508, Test accuracy: 78.98
Round  75, Train loss: 0.407, Test loss: 0.511, Test accuracy: 78.95
Round  76, Train loss: 0.387, Test loss: 0.515, Test accuracy: 78.58
Round  77, Train loss: 0.448, Test loss: 0.508, Test accuracy: 78.52
Round  78, Train loss: 0.478, Test loss: 0.510, Test accuracy: 79.08
Round  79, Train loss: 0.471, Test loss: 0.513, Test accuracy: 79.15
Round  80, Train loss: 0.418, Test loss: 0.507, Test accuracy: 79.35
Round  81, Train loss: 0.330, Test loss: 0.510, Test accuracy: 79.07
Round  82, Train loss: 0.411, Test loss: 0.507, Test accuracy: 79.22
Round  83, Train loss: 0.448, Test loss: 0.510, Test accuracy: 79.12
Round  84, Train loss: 0.327, Test loss: 0.499, Test accuracy: 79.13
Round  85, Train loss: 0.420, Test loss: 0.501, Test accuracy: 79.03
Round  86, Train loss: 0.310, Test loss: 0.497, Test accuracy: 79.17
Round  87, Train loss: 0.339, Test loss: 0.500, Test accuracy: 79.15
Round  88, Train loss: 0.299, Test loss: 0.504, Test accuracy: 79.13
Round  89, Train loss: 0.377, Test loss: 0.498, Test accuracy: 78.93
Round  90, Train loss: 0.324, Test loss: 0.495, Test accuracy: 79.62
Round  91, Train loss: 0.358, Test loss: 0.492, Test accuracy: 79.37
Round  92, Train loss: 0.343, Test loss: 0.496, Test accuracy: 79.92
Round  93, Train loss: 0.346, Test loss: 0.504, Test accuracy: 79.53
Round  94, Train loss: 0.332, Test loss: 0.497, Test accuracy: 79.75
Round  95, Train loss: 0.331, Test loss: 0.496, Test accuracy: 79.95
Round  96, Train loss: 0.276, Test loss: 0.497, Test accuracy: 79.90
Round  97, Train loss: 0.351, Test loss: 0.497, Test accuracy: 79.57
Round  98, Train loss: 0.351, Test loss: 0.494, Test accuracy: 80.15
Round  99, Train loss: 0.316, Test loss: 0.504, Test accuracy: 79.78
Final Round, Train loss: 0.291, Test loss: 0.500, Test accuracy: 79.95
Average accuracy final 10 rounds: 79.75333333333334
930.2494621276855
[3.300593376159668, 4.357024192810059, 5.412686824798584, 6.460900545120239, 7.510906457901001, 8.550628185272217, 9.55097222328186, 10.727636337280273, 11.885975122451782, 13.043672561645508, 14.197335958480835, 15.357295274734497, 16.51729965209961, 17.80574870109558, 19.108417987823486, 20.40456533432007, 21.697856664657593, 22.998890161514282, 24.290419101715088, 25.58764338493347, 26.88440728187561, 28.176218509674072, 29.472909450531006, 30.769978284835815, 32.068700551986694, 33.36202526092529, 34.513103723526, 35.66111779212952, 36.79879808425903, 37.93693947792053, 39.07523250579834, 40.24552321434021, 41.389766693115234, 42.53890085220337, 43.6979033946991, 44.88041114807129, 46.02609872817993, 47.18904209136963, 48.34354281425476, 49.487661838531494, 50.6337513923645, 51.77836275100708, 52.94469594955444, 54.093321084976196, 55.240793228149414, 56.380863904953, 57.524505853652954, 58.68229126930237, 59.82285141944885, 60.96634912490845, 62.11661887168884, 63.26968789100647, 64.40811967849731, 65.55078530311584, 66.69207048416138, 67.83572459220886, 68.98177981376648, 70.12620663642883, 71.27885246276855, 72.42060375213623, 73.56811690330505, 74.71263718605042, 75.85580062866211, 77.00205898284912, 78.1421160697937, 79.28967332839966, 80.43677234649658, 81.57989406585693, 82.72774291038513, 83.86968111991882, 85.01552724838257, 86.16083359718323, 87.33322739601135, 88.483802318573, 89.63702583312988, 90.78832364082336, 91.93624639511108, 93.09773778915405, 94.33953261375427, 95.52262306213379, 96.67162728309631, 97.83295726776123, 98.97745299339294, 100.12967252731323, 101.27855920791626, 102.43303990364075, 103.58235621452332, 104.73528385162354, 105.88999652862549, 107.04102635383606, 108.19109845161438, 109.48525929450989, 110.71008014678955, 111.89260339736938, 113.07178449630737, 114.24901819229126, 115.4276168346405, 116.60308146476746, 117.7518265247345, 118.90106844902039, 120.62204837799072]
[25.433333333333334, 36.13333333333333, 38.65, 42.78333333333333, 50.0, 51.983333333333334, 54.65, 59.666666666666664, 61.916666666666664, 63.233333333333334, 64.01666666666667, 65.16666666666667, 65.81666666666666, 66.8, 68.41666666666667, 69.15, 69.05, 69.28333333333333, 69.93333333333334, 70.38333333333334, 70.53333333333333, 70.73333333333333, 71.23333333333333, 71.51666666666667, 72.75, 73.13333333333334, 73.25, 73.18333333333334, 73.21666666666667, 73.71666666666667, 73.26666666666667, 74.3, 74.66666666666667, 74.36666666666666, 75.15, 74.91666666666667, 75.18333333333334, 76.08333333333333, 75.28333333333333, 75.81666666666666, 76.13333333333334, 76.23333333333333, 75.95, 76.3, 76.41666666666667, 76.35, 77.2, 76.73333333333333, 76.86666666666666, 76.15, 76.78333333333333, 77.11666666666666, 77.35, 77.36666666666666, 77.26666666666667, 77.33333333333333, 77.78333333333333, 77.78333333333333, 77.78333333333333, 77.76666666666667, 77.96666666666667, 77.85, 77.56666666666666, 78.15, 78.38333333333334, 78.43333333333334, 78.4, 78.4, 78.75, 78.35, 78.65, 78.33333333333333, 78.76666666666667, 79.48333333333333, 78.98333333333333, 78.95, 78.58333333333333, 78.51666666666667, 79.08333333333333, 79.15, 79.35, 79.06666666666666, 79.21666666666667, 79.11666666666666, 79.13333333333334, 79.03333333333333, 79.16666666666667, 79.15, 79.13333333333334, 78.93333333333334, 79.61666666666666, 79.36666666666666, 79.91666666666667, 79.53333333333333, 79.75, 79.95, 79.9, 79.56666666666666, 80.15, 79.78333333333333, 79.95]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
Traceback (most recent call last):
  File "main_ditto.py", line 182, in <module>
    w_k, loss, indd = local.train(net=net_global.to(args.device), idx=idx, lr=args.lr, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 488, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 52707 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
Traceback (most recent call last):
  File "main_apfl.py", line 147, in <module>
    w_global, w_local, loss, indd = local.train(net=net_local.to(args.device),w_local=w_local, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 354, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 56350 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 2.248, Test loss: 2.262, Test accuracy: 14.08
Round   0: Global train loss: 2.248, Global test loss: 2.301, Global test accuracy: 11.77
Traceback (most recent call last):
  File "main_scaffold.py", line 150, in <module>
    w_local, loss, indd, count = local.train(net=net_local.to(args.device), idx=idx, lr=lr, c_list=c_list, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 237, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 56258 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_pfedme.py", line 236, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx],w_locals = w_locals)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 808, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 56691 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.214, Test loss: 2.302, Test accuracy: 25.35 

Round   0, Global train loss: 1.214, Global test loss: 2.584, Global test accuracy: 18.65 

Round   1, Train loss: 0.967, Test loss: 1.665, Test accuracy: 36.45 

Round   1, Global train loss: 0.967, Global test loss: 2.159, Global test accuracy: 25.43 

Round   2, Train loss: 0.946, Test loss: 1.367, Test accuracy: 45.08 

Round   2, Global train loss: 0.946, Global test loss: 2.107, Global test accuracy: 23.32 

Round   3, Train loss: 0.881, Test loss: 1.321, Test accuracy: 48.62 

Round   3, Global train loss: 0.881, Global test loss: 2.287, Global test accuracy: 23.12 

Round   4, Train loss: 0.718, Test loss: 1.214, Test accuracy: 49.70 

Round   4, Global train loss: 0.718, Global test loss: 2.108, Global test accuracy: 23.65 

Round   5, Train loss: 0.762, Test loss: 1.397, Test accuracy: 50.13 

Round   5, Global train loss: 0.762, Global test loss: 2.526, Global test accuracy: 22.80 

Round   6, Train loss: 0.744, Test loss: 0.974, Test accuracy: 59.65 

Round   6, Global train loss: 0.744, Global test loss: 1.974, Global test accuracy: 30.38 

Round   7, Train loss: 0.667, Test loss: 0.982, Test accuracy: 60.15 

Round   7, Global train loss: 0.667, Global test loss: 2.113, Global test accuracy: 28.43 

Round   8, Train loss: 0.658, Test loss: 0.943, Test accuracy: 61.82 

Round   8, Global train loss: 0.658, Global test loss: 2.120, Global test accuracy: 25.52 

Round   9, Train loss: 0.732, Test loss: 0.826, Test accuracy: 64.93 

Round   9, Global train loss: 0.732, Global test loss: 2.039, Global test accuracy: 31.83 

Round  10, Train loss: 0.598, Test loss: 0.841, Test accuracy: 65.33 

Round  10, Global train loss: 0.598, Global test loss: 2.219, Global test accuracy: 26.63 

Round  11, Train loss: 0.583, Test loss: 0.796, Test accuracy: 65.95 

Round  11, Global train loss: 0.583, Global test loss: 1.998, Global test accuracy: 25.23 

Round  12, Train loss: 0.632, Test loss: 0.747, Test accuracy: 67.45 

Round  12, Global train loss: 0.632, Global test loss: 2.189, Global test accuracy: 25.53 

Round  13, Train loss: 0.668, Test loss: 0.736, Test accuracy: 68.38 

Round  13, Global train loss: 0.668, Global test loss: 2.283, Global test accuracy: 22.80 

Round  14, Train loss: 0.556, Test loss: 0.736, Test accuracy: 68.92 

Round  14, Global train loss: 0.556, Global test loss: 2.204, Global test accuracy: 28.80 

Round  15, Train loss: 0.560, Test loss: 0.728, Test accuracy: 68.95 

Round  15, Global train loss: 0.560, Global test loss: 2.299, Global test accuracy: 26.45 

Round  16, Train loss: 0.498, Test loss: 0.731, Test accuracy: 69.30 

Round  16, Global train loss: 0.498, Global test loss: 2.391, Global test accuracy: 25.90 

Round  17, Train loss: 0.492, Test loss: 0.724, Test accuracy: 69.77 

Round  17, Global train loss: 0.492, Global test loss: 2.190, Global test accuracy: 26.40 

Round  18, Train loss: 0.589, Test loss: 0.702, Test accuracy: 70.90 

Round  18, Global train loss: 0.589, Global test loss: 1.998, Global test accuracy: 28.40 

Round  19, Train loss: 0.493, Test loss: 0.674, Test accuracy: 71.48 

Round  19, Global train loss: 0.493, Global test loss: 2.225, Global test accuracy: 26.45 

Round  20, Train loss: 0.547, Test loss: 0.681, Test accuracy: 71.75 

Round  20, Global train loss: 0.547, Global test loss: 2.602, Global test accuracy: 25.65 

Round  21, Train loss: 0.584, Test loss: 0.704, Test accuracy: 71.20 

Round  21, Global train loss: 0.584, Global test loss: 2.535, Global test accuracy: 27.32 

Round  22, Train loss: 0.493, Test loss: 0.708, Test accuracy: 71.33 

Round  22, Global train loss: 0.493, Global test loss: 2.097, Global test accuracy: 27.95 

Round  23, Train loss: 0.478, Test loss: 0.713, Test accuracy: 71.80 

Round  23, Global train loss: 0.478, Global test loss: 2.533, Global test accuracy: 26.75 

Round  24, Train loss: 0.432, Test loss: 0.691, Test accuracy: 72.85 

Round  24, Global train loss: 0.432, Global test loss: 2.212, Global test accuracy: 30.35 

Round  25, Train loss: 0.480, Test loss: 0.692, Test accuracy: 72.83 

Round  25, Global train loss: 0.480, Global test loss: 2.189, Global test accuracy: 25.95 

Round  26, Train loss: 0.441, Test loss: 0.702, Test accuracy: 73.03 

Round  26, Global train loss: 0.441, Global test loss: 1.955, Global test accuracy: 31.25 

Round  27, Train loss: 0.402, Test loss: 0.718, Test accuracy: 73.02 

Round  27, Global train loss: 0.402, Global test loss: 2.663, Global test accuracy: 26.58 

Round  28, Train loss: 0.394, Test loss: 0.724, Test accuracy: 72.83 

Round  28, Global train loss: 0.394, Global test loss: 1.923, Global test accuracy: 29.55 

Round  29, Train loss: 0.418, Test loss: 0.722, Test accuracy: 73.20 

Round  29, Global train loss: 0.418, Global test loss: 2.111, Global test accuracy: 29.47 

Round  30, Train loss: 0.392, Test loss: 0.727, Test accuracy: 73.27 

Round  30, Global train loss: 0.392, Global test loss: 2.214, Global test accuracy: 20.22 

Round  31, Train loss: 0.332, Test loss: 0.728, Test accuracy: 73.15 

Round  31, Global train loss: 0.332, Global test loss: 2.026, Global test accuracy: 30.22 

Round  32, Train loss: 0.329, Test loss: 0.737, Test accuracy: 73.33 

Round  32, Global train loss: 0.329, Global test loss: 2.491, Global test accuracy: 27.47 

Round  33, Train loss: 0.340, Test loss: 0.784, Test accuracy: 72.90 

Round  33, Global train loss: 0.340, Global test loss: 2.343, Global test accuracy: 27.35 

Round  34, Train loss: 0.388, Test loss: 0.780, Test accuracy: 72.70 

Round  34, Global train loss: 0.388, Global test loss: 2.071, Global test accuracy: 28.90 

Round  35, Train loss: 0.308, Test loss: 0.793, Test accuracy: 72.77 

Round  35, Global train loss: 0.308, Global test loss: 2.507, Global test accuracy: 26.88 

Round  36, Train loss: 0.336, Test loss: 0.795, Test accuracy: 73.35 

Round  36, Global train loss: 0.336, Global test loss: 2.006, Global test accuracy: 29.37 

Round  37, Train loss: 0.386, Test loss: 0.805, Test accuracy: 73.60 

Round  37, Global train loss: 0.386, Global test loss: 2.295, Global test accuracy: 29.33 

Round  38, Train loss: 0.311, Test loss: 0.788, Test accuracy: 74.40 

Round  38, Global train loss: 0.311, Global test loss: 2.105, Global test accuracy: 23.17 

Round  39, Train loss: 0.249, Test loss: 0.789, Test accuracy: 74.32 

Round  39, Global train loss: 0.249, Global test loss: 1.935, Global test accuracy: 30.22 

Round  40, Train loss: 0.259, Test loss: 0.826, Test accuracy: 73.57 

Round  40, Global train loss: 0.259, Global test loss: 2.064, Global test accuracy: 27.98 

Round  41, Train loss: 0.273, Test loss: 0.830, Test accuracy: 73.57 

Round  41, Global train loss: 0.273, Global test loss: 2.139, Global test accuracy: 23.28 

Round  42, Train loss: 0.314, Test loss: 0.813, Test accuracy: 74.03 

Round  42, Global train loss: 0.314, Global test loss: 2.153, Global test accuracy: 24.75 

Round  43, Train loss: 0.305, Test loss: 0.839, Test accuracy: 73.97 

Round  43, Global train loss: 0.305, Global test loss: 2.122, Global test accuracy: 27.72 

Round  44, Train loss: 0.189, Test loss: 0.868, Test accuracy: 73.62 

Round  44, Global train loss: 0.189, Global test loss: 2.145, Global test accuracy: 29.62 

Round  45, Train loss: 0.222, Test loss: 0.832, Test accuracy: 74.27 

Round  45, Global train loss: 0.222, Global test loss: 2.350, Global test accuracy: 25.23 

Round  46, Train loss: 0.256, Test loss: 0.808, Test accuracy: 74.82 

Round  46, Global train loss: 0.256, Global test loss: 2.019, Global test accuracy: 31.82 

Round  47, Train loss: 0.251, Test loss: 0.818, Test accuracy: 74.88 

Round  47, Global train loss: 0.251, Global test loss: 2.159, Global test accuracy: 25.02 

Round  48, Train loss: 0.225, Test loss: 0.839, Test accuracy: 74.83 

Round  48, Global train loss: 0.225, Global test loss: 2.145, Global test accuracy: 27.92 

Round  49, Train loss: 0.260, Test loss: 0.855, Test accuracy: 74.72 

Round  49, Global train loss: 0.260, Global test loss: 2.103, Global test accuracy: 27.22 

Round  50, Train loss: 0.178, Test loss: 0.858, Test accuracy: 75.02 

Round  50, Global train loss: 0.178, Global test loss: 1.908, Global test accuracy: 29.73 

Round  51, Train loss: 0.199, Test loss: 0.885, Test accuracy: 74.42 

Round  51, Global train loss: 0.199, Global test loss: 2.319, Global test accuracy: 25.52 

Round  52, Train loss: 0.206, Test loss: 0.922, Test accuracy: 74.17 

Round  52, Global train loss: 0.206, Global test loss: 2.316, Global test accuracy: 23.58 

Round  53, Train loss: 0.232, Test loss: 0.940, Test accuracy: 74.03 

Round  53, Global train loss: 0.232, Global test loss: 1.890, Global test accuracy: 27.98 

Round  54, Train loss: 0.156, Test loss: 0.934, Test accuracy: 74.55 

Round  54, Global train loss: 0.156, Global test loss: 1.944, Global test accuracy: 31.13 

Round  55, Train loss: 0.118, Test loss: 0.981, Test accuracy: 74.55 

Round  55, Global train loss: 0.118, Global test loss: 2.155, Global test accuracy: 29.85 

Round  56, Train loss: 0.218, Test loss: 0.941, Test accuracy: 74.48 

Round  56, Global train loss: 0.218, Global test loss: 2.040, Global test accuracy: 28.83 

Round  57, Train loss: 0.202, Test loss: 0.972, Test accuracy: 74.23 

Round  57, Global train loss: 0.202, Global test loss: 2.100, Global test accuracy: 24.10 

Round  58, Train loss: 0.187, Test loss: 0.965, Test accuracy: 74.30 

Round  58, Global train loss: 0.187, Global test loss: 2.424, Global test accuracy: 24.52 

Round  59, Train loss: 0.172, Test loss: 0.931, Test accuracy: 74.90 

Round  59, Global train loss: 0.172, Global test loss: 2.032, Global test accuracy: 27.48 

Round  60, Train loss: 0.226, Test loss: 0.936, Test accuracy: 74.98 

Round  60, Global train loss: 0.226, Global test loss: 2.235, Global test accuracy: 25.95 

Round  61, Train loss: 0.173, Test loss: 0.938, Test accuracy: 74.62 

Round  61, Global train loss: 0.173, Global test loss: 2.174, Global test accuracy: 29.12 

Round  62, Train loss: 0.180, Test loss: 0.949, Test accuracy: 74.60 

Round  62, Global train loss: 0.180, Global test loss: 2.261, Global test accuracy: 27.22 

Round  63, Train loss: 0.104, Test loss: 0.973, Test accuracy: 74.57 

Round  63, Global train loss: 0.104, Global test loss: 2.078, Global test accuracy: 29.33 

Round  64, Train loss: 0.142, Test loss: 0.978, Test accuracy: 75.15 

Round  64, Global train loss: 0.142, Global test loss: 2.118, Global test accuracy: 34.17 

Round  65, Train loss: 0.126, Test loss: 0.989, Test accuracy: 74.80 

Round  65, Global train loss: 0.126, Global test loss: 1.999, Global test accuracy: 32.77 

Round  66, Train loss: 0.114, Test loss: 1.025, Test accuracy: 74.40 

Round  66, Global train loss: 0.114, Global test loss: 1.946, Global test accuracy: 30.13 

Round  67, Train loss: 0.157, Test loss: 1.019, Test accuracy: 74.87 

Round  67, Global train loss: 0.157, Global test loss: 2.056, Global test accuracy: 28.85 

Round  68, Train loss: 0.107, Test loss: 1.028, Test accuracy: 75.10 

Round  68, Global train loss: 0.107, Global test loss: 2.078, Global test accuracy: 28.77 

Round  69, Train loss: 0.116, Test loss: 1.031, Test accuracy: 75.40 

Round  69, Global train loss: 0.116, Global test loss: 2.086, Global test accuracy: 29.70 

Round  70, Train loss: 0.107, Test loss: 1.045, Test accuracy: 75.52 

Round  70, Global train loss: 0.107, Global test loss: 2.475, Global test accuracy: 26.60 

Round  71, Train loss: 0.104, Test loss: 1.091, Test accuracy: 74.92 

Round  71, Global train loss: 0.104, Global test loss: 2.257, Global test accuracy: 20.92 

Round  72, Train loss: 0.110, Test loss: 1.074, Test accuracy: 75.15 

Round  72, Global train loss: 0.110, Global test loss: 1.992, Global test accuracy: 28.03 

Round  73, Train loss: 0.111, Test loss: 1.035, Test accuracy: 75.37 

Round  73, Global train loss: 0.111, Global test loss: 2.309, Global test accuracy: 29.40 

Round  74, Train loss: 0.087, Test loss: 1.030, Test accuracy: 75.13 

Round  74, Global train loss: 0.087, Global test loss: 2.066, Global test accuracy: 30.75 

Round  75, Train loss: 0.097, Test loss: 1.046, Test accuracy: 75.48 

Round  75, Global train loss: 0.097, Global test loss: 2.160, Global test accuracy: 29.55 

Round  76, Train loss: 0.093, Test loss: 1.083, Test accuracy: 75.05 

Round  76, Global train loss: 0.093, Global test loss: 2.506, Global test accuracy: 26.57 

Round  77, Train loss: 0.118, Test loss: 1.113, Test accuracy: 74.82 

Round  77, Global train loss: 0.118, Global test loss: 2.651, Global test accuracy: 26.65 

Round  78, Train loss: 0.135, Test loss: 1.113, Test accuracy: 74.88 

Round  78, Global train loss: 0.135, Global test loss: 2.070, Global test accuracy: 29.02 

Round  79, Train loss: 0.077, Test loss: 1.112, Test accuracy: 74.58 

Round  79, Global train loss: 0.077, Global test loss: 2.007, Global test accuracy: 31.95 

Round  80, Train loss: 0.114, Test loss: 1.173, Test accuracy: 74.48 

Round  80, Global train loss: 0.114, Global test loss: 2.326, Global test accuracy: 26.92 

Round  81, Train loss: 0.105, Test loss: 1.170, Test accuracy: 74.52 

Round  81, Global train loss: 0.105, Global test loss: 2.105, Global test accuracy: 21.60 

Round  82, Train loss: 0.071, Test loss: 1.182, Test accuracy: 74.67 

Round  82, Global train loss: 0.071, Global test loss: 2.104, Global test accuracy: 27.55 

Round  83, Train loss: 0.084, Test loss: 1.182, Test accuracy: 74.88 

Round  83, Global train loss: 0.084, Global test loss: 2.486, Global test accuracy: 27.25 

Round  84, Train loss: 0.087, Test loss: 1.164, Test accuracy: 75.10 

Round  84, Global train loss: 0.087, Global test loss: 1.968, Global test accuracy: 32.70 

Round  85, Train loss: 0.059, Test loss: 1.159, Test accuracy: 75.07 

Round  85, Global train loss: 0.059, Global test loss: 2.162, Global test accuracy: 28.50 

Round  86, Train loss: 0.092, Test loss: 1.160, Test accuracy: 75.13 

Round  86, Global train loss: 0.092, Global test loss: 2.208, Global test accuracy: 31.77 

Round  87, Train loss: 0.080, Test loss: 1.157, Test accuracy: 75.28 

Round  87, Global train loss: 0.080, Global test loss: 2.331, Global test accuracy: 27.78 

Round  88, Train loss: 0.082, Test loss: 1.163, Test accuracy: 75.47 

Round  88, Global train loss: 0.082, Global test loss: 2.082, Global test accuracy: 28.23 

Round  89, Train loss: 0.068, Test loss: 1.185, Test accuracy: 75.12 

Round  89, Global train loss: 0.068, Global test loss: 1.923, Global test accuracy: 27.72 

Round  90, Train loss: 0.062, Test loss: 1.200, Test accuracy: 74.82 

Round  90, Global train loss: 0.062, Global test loss: 1.928, Global test accuracy: 29.87 

Round  91, Train loss: 0.099, Test loss: 1.207, Test accuracy: 74.28 

Round  91, Global train loss: 0.099, Global test loss: 2.131, Global test accuracy: 31.15 

Round  92, Train loss: 0.106, Test loss: 1.229, Test accuracy: 74.98 

Round  92, Global train loss: 0.106, Global test loss: 2.052, Global test accuracy: 30.65 

Round  93, Train loss: 0.088, Test loss: 1.228, Test accuracy: 74.53 

Round  93, Global train loss: 0.088, Global test loss: 2.573, Global test accuracy: 26.63 

Round  94, Train loss: 0.055, Test loss: 1.233, Test accuracy: 74.52 

Round  94, Global train loss: 0.055, Global test loss: 2.154, Global test accuracy: 27.52 

Round  95, Train loss: 0.078, Test loss: 1.229, Test accuracy: 74.98 

Round  95, Global train loss: 0.078, Global test loss: 2.130, Global test accuracy: 26.57 

Round  96, Train loss: 0.075, Test loss: 1.220, Test accuracy: 75.58 

Round  96, Global train loss: 0.075, Global test loss: 2.116, Global test accuracy: 29.43 

Round  97, Train loss: 0.077, Test loss: 1.275, Test accuracy: 75.42 

Round  97, Global train loss: 0.077, Global test loss: 2.165, Global test accuracy: 23.30 

Round  98, Train loss: 0.043, Test loss: 1.310, Test accuracy: 75.17 

Round  98, Global train loss: 0.043, Global test loss: 1.958, Global test accuracy: 30.40 

Round  99, Train loss: 0.082, Test loss: 1.335, Test accuracy: 75.02 

Round  99, Global train loss: 0.082, Global test loss: 2.003, Global test accuracy: 28.05 

Final Round, Train loss: 0.069, Test loss: 1.265, Test accuracy: 75.43 

Final Round, Global train loss: 0.069, Global test loss: 2.003, Global test accuracy: 28.05 

Average accuracy final 10 rounds: 74.92999999999999 

Average global accuracy final 10 rounds: 28.356666666666662 

1125.015897989273
[3.2274911403656006, 4.440886497497559, 5.51326060295105, 6.591691970825195, 7.667201995849609, 8.814372777938843, 9.90360403060913, 11.082524061203003, 12.300386190414429, 13.377068281173706, 14.500081777572632, 15.575055360794067, 16.673600912094116, 17.760175943374634, 18.974287033081055, 20.19339609146118, 21.41071891784668, 22.63100290298462, 23.849398612976074, 25.065890550613403, 26.27827000617981, 27.494319677352905, 28.71139359474182, 29.928022623062134, 31.146795511245728, 32.36794900894165, 33.583942890167236, 34.79730463027954, 36.01154136657715, 37.223570823669434, 38.32917499542236, 39.600067138671875, 40.812928676605225, 42.03309488296509, 43.24442911148071, 44.45719027519226, 45.664738178253174, 46.880672216415405, 48.093132734298706, 49.31176447868347, 50.52404236793518, 51.73807716369629, 52.95033144950867, 54.16138291358948, 55.372488021850586, 56.576810359954834, 57.65166521072388, 58.72933316230774, 59.79947781562805, 60.87912440299988, 61.9596266746521, 63.03885293006897, 64.11836361885071, 65.19425892829895, 66.26926565170288, 67.34645223617554, 68.42348647117615, 69.51561689376831, 70.58821821212769, 71.72232985496521, 72.80407500267029, 73.87991118431091, 74.9574556350708, 76.03749442100525, 77.11472415924072, 78.19420337677002, 79.3211407661438, 80.44248676300049, 81.56565260887146, 82.68649435043335, 83.81577396392822, 84.93730330467224, 86.05953884124756, 87.14902925491333, 88.22633481025696, 89.30419492721558, 90.38468432426453, 91.46709513664246, 92.55239272117615, 93.63758707046509, 94.76403307914734, 95.85048913955688, 96.94738817214966, 98.03022456169128, 99.13148498535156, 100.20828819274902, 101.32016777992249, 102.39220380783081, 103.46902346611023, 104.56914019584656, 105.6523826122284, 106.72914600372314, 107.8081922531128, 108.88733839988708, 109.9716386795044, 111.04937410354614, 112.12398886680603, 113.19893527030945, 114.27566981315613, 115.35202193260193, 117.51206517219543]
[25.35, 36.45, 45.083333333333336, 48.61666666666667, 49.7, 50.13333333333333, 59.65, 60.15, 61.81666666666667, 64.93333333333334, 65.33333333333333, 65.95, 67.45, 68.38333333333334, 68.91666666666667, 68.95, 69.3, 69.76666666666667, 70.9, 71.48333333333333, 71.75, 71.2, 71.33333333333333, 71.8, 72.85, 72.83333333333333, 73.03333333333333, 73.01666666666667, 72.83333333333333, 73.2, 73.26666666666667, 73.15, 73.33333333333333, 72.9, 72.7, 72.76666666666667, 73.35, 73.6, 74.4, 74.31666666666666, 73.56666666666666, 73.56666666666666, 74.03333333333333, 73.96666666666667, 73.61666666666666, 74.26666666666667, 74.81666666666666, 74.88333333333334, 74.83333333333333, 74.71666666666667, 75.01666666666667, 74.41666666666667, 74.16666666666667, 74.03333333333333, 74.55, 74.55, 74.48333333333333, 74.23333333333333, 74.3, 74.9, 74.98333333333333, 74.61666666666666, 74.6, 74.56666666666666, 75.15, 74.8, 74.4, 74.86666666666666, 75.1, 75.4, 75.51666666666667, 74.91666666666667, 75.15, 75.36666666666666, 75.13333333333334, 75.48333333333333, 75.05, 74.81666666666666, 74.88333333333334, 74.58333333333333, 74.48333333333333, 74.51666666666667, 74.66666666666667, 74.88333333333334, 75.1, 75.06666666666666, 75.13333333333334, 75.28333333333333, 75.46666666666667, 75.11666666666666, 74.81666666666666, 74.28333333333333, 74.98333333333333, 74.53333333333333, 74.51666666666667, 74.98333333333333, 75.58333333333333, 75.41666666666667, 75.16666666666667, 75.01666666666667, 75.43333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.237, Test loss: 1.969, Test accuracy: 28.13 

Round   0, Global train loss: 1.237, Global test loss: 2.289, Global test accuracy: 20.77 

Round   1, Train loss: 1.049, Test loss: 1.759, Test accuracy: 30.80 

Round   1, Global train loss: 1.049, Global test loss: 2.305, Global test accuracy: 19.23 

Round   2, Train loss: 0.943, Test loss: 1.255, Test accuracy: 46.48 

Round   2, Global train loss: 0.943, Global test loss: 2.061, Global test accuracy: 25.67 

Round   3, Train loss: 0.873, Test loss: 1.116, Test accuracy: 51.40 

Round   3, Global train loss: 0.873, Global test loss: 2.041, Global test accuracy: 25.60 

Round   4, Train loss: 0.809, Test loss: 1.024, Test accuracy: 55.50 

Round   4, Global train loss: 0.809, Global test loss: 2.035, Global test accuracy: 30.22 

Round   5, Train loss: 0.795, Test loss: 0.965, Test accuracy: 58.63 

Round   5, Global train loss: 0.795, Global test loss: 2.549, Global test accuracy: 26.78 

Round   6, Train loss: 0.721, Test loss: 0.805, Test accuracy: 63.33 

Round   6, Global train loss: 0.721, Global test loss: 2.172, Global test accuracy: 31.12 

Round   7, Train loss: 0.829, Test loss: 0.765, Test accuracy: 65.92 

Round   7, Global train loss: 0.829, Global test loss: 1.889, Global test accuracy: 32.33 

Round   8, Train loss: 0.842, Test loss: 0.741, Test accuracy: 67.32 

Round   8, Global train loss: 0.842, Global test loss: 1.976, Global test accuracy: 27.60 

Round   9, Train loss: 0.746, Test loss: 0.742, Test accuracy: 67.93 

Round   9, Global train loss: 0.746, Global test loss: 1.808, Global test accuracy: 30.75 

Round  10, Train loss: 0.715, Test loss: 0.724, Test accuracy: 68.88 

Round  10, Global train loss: 0.715, Global test loss: 1.715, Global test accuracy: 36.22 

Round  11, Train loss: 0.615, Test loss: 0.705, Test accuracy: 69.73 

Round  11, Global train loss: 0.615, Global test loss: 1.756, Global test accuracy: 37.13 

Round  12, Train loss: 0.609, Test loss: 0.685, Test accuracy: 70.10 

Round  12, Global train loss: 0.609, Global test loss: 1.748, Global test accuracy: 40.20 

Round  13, Train loss: 0.692, Test loss: 0.692, Test accuracy: 69.77 

Round  13, Global train loss: 0.692, Global test loss: 1.676, Global test accuracy: 38.77 

Round  14, Train loss: 0.637, Test loss: 0.667, Test accuracy: 70.97 

Round  14, Global train loss: 0.637, Global test loss: 2.028, Global test accuracy: 33.93 

Round  15, Train loss: 0.659, Test loss: 0.663, Test accuracy: 71.63 

Round  15, Global train loss: 0.659, Global test loss: 1.766, Global test accuracy: 36.18 

Round  16, Train loss: 0.634, Test loss: 0.654, Test accuracy: 72.12 

Round  16, Global train loss: 0.634, Global test loss: 1.569, Global test accuracy: 42.75 

Round  17, Train loss: 0.592, Test loss: 0.650, Test accuracy: 72.57 

Round  17, Global train loss: 0.592, Global test loss: 1.682, Global test accuracy: 38.62 

Round  18, Train loss: 0.616, Test loss: 0.640, Test accuracy: 72.72 

Round  18, Global train loss: 0.616, Global test loss: 1.791, Global test accuracy: 35.68 

Round  19, Train loss: 0.705, Test loss: 0.630, Test accuracy: 73.27 

Round  19, Global train loss: 0.705, Global test loss: 1.692, Global test accuracy: 40.18 

Round  20, Train loss: 0.605, Test loss: 0.633, Test accuracy: 73.67 

Round  20, Global train loss: 0.605, Global test loss: 1.746, Global test accuracy: 37.93 

Round  21, Train loss: 0.611, Test loss: 0.631, Test accuracy: 73.48 

Round  21, Global train loss: 0.611, Global test loss: 2.064, Global test accuracy: 35.72 

Round  22, Train loss: 0.576, Test loss: 0.638, Test accuracy: 73.90 

Round  22, Global train loss: 0.576, Global test loss: 1.929, Global test accuracy: 37.38 

Round  23, Train loss: 0.625, Test loss: 0.639, Test accuracy: 73.50 

Round  23, Global train loss: 0.625, Global test loss: 1.692, Global test accuracy: 39.52 

Round  24, Train loss: 0.563, Test loss: 0.640, Test accuracy: 73.28 

Round  24, Global train loss: 0.563, Global test loss: 1.676, Global test accuracy: 39.33 

Round  25, Train loss: 0.544, Test loss: 0.660, Test accuracy: 73.03 

Round  25, Global train loss: 0.544, Global test loss: 1.617, Global test accuracy: 43.70 

Round  26, Train loss: 0.566, Test loss: 0.650, Test accuracy: 73.93 

Round  26, Global train loss: 0.566, Global test loss: 1.682, Global test accuracy: 40.80 

Round  27, Train loss: 0.533, Test loss: 0.646, Test accuracy: 74.00 

Round  27, Global train loss: 0.533, Global test loss: 1.562, Global test accuracy: 43.80 

Round  28, Train loss: 0.474, Test loss: 0.622, Test accuracy: 74.80 

Round  28, Global train loss: 0.474, Global test loss: 1.748, Global test accuracy: 41.07 

Round  29, Train loss: 0.498, Test loss: 0.618, Test accuracy: 74.52 

Round  29, Global train loss: 0.498, Global test loss: 1.583, Global test accuracy: 45.10 

Round  30, Train loss: 0.438, Test loss: 0.626, Test accuracy: 74.23 

Round  30, Global train loss: 0.438, Global test loss: 1.492, Global test accuracy: 46.03 

Round  31, Train loss: 0.605, Test loss: 0.618, Test accuracy: 74.47 

Round  31, Global train loss: 0.605, Global test loss: 1.488, Global test accuracy: 45.13 

Round  32, Train loss: 0.535, Test loss: 0.622, Test accuracy: 74.27 

Round  32, Global train loss: 0.535, Global test loss: 1.692, Global test accuracy: 37.53 

Round  33, Train loss: 0.521, Test loss: 0.605, Test accuracy: 75.10 

Round  33, Global train loss: 0.521, Global test loss: 1.475, Global test accuracy: 45.12 

Round  34, Train loss: 0.451, Test loss: 0.599, Test accuracy: 75.53 

Round  34, Global train loss: 0.451, Global test loss: 1.457, Global test accuracy: 49.23 

Round  35, Train loss: 0.502, Test loss: 0.609, Test accuracy: 75.47 

Round  35, Global train loss: 0.502, Global test loss: 1.708, Global test accuracy: 36.88 

Round  36, Train loss: 0.467, Test loss: 0.617, Test accuracy: 75.02 

Round  36, Global train loss: 0.467, Global test loss: 1.493, Global test accuracy: 46.48 

Round  37, Train loss: 0.469, Test loss: 0.612, Test accuracy: 75.50 

Round  37, Global train loss: 0.469, Global test loss: 1.359, Global test accuracy: 51.45 

Round  38, Train loss: 0.417, Test loss: 0.597, Test accuracy: 76.12 

Round  38, Global train loss: 0.417, Global test loss: 1.553, Global test accuracy: 46.72 

Round  39, Train loss: 0.484, Test loss: 0.600, Test accuracy: 76.27 

Round  39, Global train loss: 0.484, Global test loss: 1.515, Global test accuracy: 47.67 

Round  40, Train loss: 0.414, Test loss: 0.600, Test accuracy: 76.43 

Round  40, Global train loss: 0.414, Global test loss: 1.605, Global test accuracy: 45.17 

Round  41, Train loss: 0.445, Test loss: 0.584, Test accuracy: 77.37 

Round  41, Global train loss: 0.445, Global test loss: 1.380, Global test accuracy: 50.40 

Round  42, Train loss: 0.412, Test loss: 0.583, Test accuracy: 77.33 

Round  42, Global train loss: 0.412, Global test loss: 1.612, Global test accuracy: 44.77 

Round  43, Train loss: 0.405, Test loss: 0.587, Test accuracy: 77.50 

Round  43, Global train loss: 0.405, Global test loss: 1.410, Global test accuracy: 49.68 

Round  44, Train loss: 0.487, Test loss: 0.591, Test accuracy: 77.58 

Round  44, Global train loss: 0.487, Global test loss: 1.621, Global test accuracy: 43.88 

Round  45, Train loss: 0.374, Test loss: 0.576, Test accuracy: 77.80 

Round  45, Global train loss: 0.374, Global test loss: 1.665, Global test accuracy: 46.17 

Round  46, Train loss: 0.457, Test loss: 0.574, Test accuracy: 77.45 

Round  46, Global train loss: 0.457, Global test loss: 1.575, Global test accuracy: 45.37 

Round  47, Train loss: 0.420, Test loss: 0.574, Test accuracy: 77.70 

Round  47, Global train loss: 0.420, Global test loss: 1.394, Global test accuracy: 50.62 

Round  48, Train loss: 0.420, Test loss: 0.570, Test accuracy: 78.32 

Round  48, Global train loss: 0.420, Global test loss: 1.613, Global test accuracy: 45.10 

Round  49, Train loss: 0.383, Test loss: 0.579, Test accuracy: 78.12 

Round  49, Global train loss: 0.383, Global test loss: 1.479, Global test accuracy: 49.33 

Round  50, Train loss: 0.431, Test loss: 0.583, Test accuracy: 78.32 

Round  50, Global train loss: 0.431, Global test loss: 1.644, Global test accuracy: 45.37 

Round  51, Train loss: 0.361, Test loss: 0.585, Test accuracy: 78.15 

Round  51, Global train loss: 0.361, Global test loss: 1.538, Global test accuracy: 49.52 

Round  52, Train loss: 0.367, Test loss: 0.588, Test accuracy: 77.87 

Round  52, Global train loss: 0.367, Global test loss: 2.155, Global test accuracy: 40.70 

Round  53, Train loss: 0.400, Test loss: 0.607, Test accuracy: 77.48 

Round  53, Global train loss: 0.400, Global test loss: 1.467, Global test accuracy: 49.12 

Round  54, Train loss: 0.465, Test loss: 0.611, Test accuracy: 77.52 

Round  54, Global train loss: 0.465, Global test loss: 1.465, Global test accuracy: 48.68 

Round  55, Train loss: 0.396, Test loss: 0.627, Test accuracy: 77.13 

Round  55, Global train loss: 0.396, Global test loss: 1.330, Global test accuracy: 53.27 

Round  56, Train loss: 0.325, Test loss: 0.621, Test accuracy: 77.28 

Round  56, Global train loss: 0.325, Global test loss: 1.423, Global test accuracy: 51.90 

Round  57, Train loss: 0.354, Test loss: 0.603, Test accuracy: 77.73 

Round  57, Global train loss: 0.354, Global test loss: 1.521, Global test accuracy: 50.73 

Round  58, Train loss: 0.325, Test loss: 0.613, Test accuracy: 77.45 

Round  58, Global train loss: 0.325, Global test loss: 1.365, Global test accuracy: 53.78 

Round  59, Train loss: 0.342, Test loss: 0.600, Test accuracy: 77.85 

Round  59, Global train loss: 0.342, Global test loss: 1.491, Global test accuracy: 49.93 

Round  60, Train loss: 0.357, Test loss: 0.612, Test accuracy: 77.57 

Round  60, Global train loss: 0.357, Global test loss: 1.698, Global test accuracy: 44.57 

Round  61, Train loss: 0.393, Test loss: 0.600, Test accuracy: 78.42 

Round  61, Global train loss: 0.393, Global test loss: 1.284, Global test accuracy: 55.38 

Round  62, Train loss: 0.340, Test loss: 0.592, Test accuracy: 78.25 

Round  62, Global train loss: 0.340, Global test loss: 1.526, Global test accuracy: 49.00 

Round  63, Train loss: 0.344, Test loss: 0.615, Test accuracy: 78.18 

Round  63, Global train loss: 0.344, Global test loss: 1.463, Global test accuracy: 49.97 

Round  64, Train loss: 0.299, Test loss: 0.618, Test accuracy: 78.15 

Round  64, Global train loss: 0.299, Global test loss: 1.436, Global test accuracy: 53.97 

Round  65, Train loss: 0.363, Test loss: 0.608, Test accuracy: 78.63 

Round  65, Global train loss: 0.363, Global test loss: 1.484, Global test accuracy: 48.95 

Round  66, Train loss: 0.354, Test loss: 0.599, Test accuracy: 78.90 

Round  66, Global train loss: 0.354, Global test loss: 1.546, Global test accuracy: 46.93 

Round  67, Train loss: 0.305, Test loss: 0.593, Test accuracy: 79.38 

Round  67, Global train loss: 0.305, Global test loss: 1.413, Global test accuracy: 51.63 

Round  68, Train loss: 0.321, Test loss: 0.579, Test accuracy: 79.75 

Round  68, Global train loss: 0.321, Global test loss: 1.425, Global test accuracy: 52.12 

Round  69, Train loss: 0.358, Test loss: 0.588, Test accuracy: 79.57 

Round  69, Global train loss: 0.358, Global test loss: 1.531, Global test accuracy: 49.42 

Round  70, Train loss: 0.327, Test loss: 0.592, Test accuracy: 79.28 

Round  70, Global train loss: 0.327, Global test loss: 1.354, Global test accuracy: 53.10 

Round  71, Train loss: 0.281, Test loss: 0.585, Test accuracy: 79.93 

Round  71, Global train loss: 0.281, Global test loss: 1.397, Global test accuracy: 53.77 

Round  72, Train loss: 0.273, Test loss: 0.615, Test accuracy: 79.12 

Round  72, Global train loss: 0.273, Global test loss: 1.619, Global test accuracy: 49.57 

Round  73, Train loss: 0.352, Test loss: 0.618, Test accuracy: 78.72 

Round  73, Global train loss: 0.352, Global test loss: 1.378, Global test accuracy: 55.05 

Round  74, Train loss: 0.339, Test loss: 0.612, Test accuracy: 79.17 

Round  74, Global train loss: 0.339, Global test loss: 1.394, Global test accuracy: 53.10 

Round  75, Train loss: 0.294, Test loss: 0.586, Test accuracy: 79.78 

Round  75, Global train loss: 0.294, Global test loss: 1.488, Global test accuracy: 51.05 

Round  76, Train loss: 0.330, Test loss: 0.596, Test accuracy: 79.63 

Round  76, Global train loss: 0.330, Global test loss: 1.788, Global test accuracy: 45.50 

Round  77, Train loss: 0.336, Test loss: 0.595, Test accuracy: 79.63 

Round  77, Global train loss: 0.336, Global test loss: 1.380, Global test accuracy: 52.97 

Round  78, Train loss: 0.266, Test loss: 0.597, Test accuracy: 79.63 

Round  78, Global train loss: 0.266, Global test loss: 1.750, Global test accuracy: 50.03 

Round  79, Train loss: 0.316, Test loss: 0.612, Test accuracy: 78.82 

Round  79, Global train loss: 0.316, Global test loss: 1.317, Global test accuracy: 56.95 

Round  80, Train loss: 0.290, Test loss: 0.604, Test accuracy: 79.40 

Round  80, Global train loss: 0.290, Global test loss: 1.451, Global test accuracy: 52.82 

Round  81, Train loss: 0.228, Test loss: 0.593, Test accuracy: 79.92 

Round  81, Global train loss: 0.228, Global test loss: 1.490, Global test accuracy: 54.53 

Round  82, Train loss: 0.293, Test loss: 0.614, Test accuracy: 79.55 

Round  82, Global train loss: 0.293, Global test loss: 1.577, Global test accuracy: 47.72 

Round  83, Train loss: 0.268, Test loss: 0.631, Test accuracy: 79.30 

Round  83, Global train loss: 0.268, Global test loss: 1.401, Global test accuracy: 52.78 

Round  84, Train loss: 0.304, Test loss: 0.619, Test accuracy: 79.82 

Round  84, Global train loss: 0.304, Global test loss: 1.371, Global test accuracy: 55.73 

Round  85, Train loss: 0.229, Test loss: 0.613, Test accuracy: 80.00 

Round  85, Global train loss: 0.229, Global test loss: 1.512, Global test accuracy: 53.40 

Round  86, Train loss: 0.367, Test loss: 0.604, Test accuracy: 80.08 

Round  86, Global train loss: 0.367, Global test loss: 1.715, Global test accuracy: 49.00 

Round  87, Train loss: 0.293, Test loss: 0.596, Test accuracy: 80.62 

Round  87, Global train loss: 0.293, Global test loss: 1.442, Global test accuracy: 53.53 

Round  88, Train loss: 0.306, Test loss: 0.601, Test accuracy: 80.32 

Round  88, Global train loss: 0.306, Global test loss: 1.527, Global test accuracy: 53.65 

Round  89, Train loss: 0.286, Test loss: 0.617, Test accuracy: 80.12 

Round  89, Global train loss: 0.286, Global test loss: 1.309, Global test accuracy: 56.38 

Round  90, Train loss: 0.241, Test loss: 0.612, Test accuracy: 80.35 

Round  90, Global train loss: 0.241, Global test loss: 1.615, Global test accuracy: 51.18 

Round  91, Train loss: 0.279, Test loss: 0.604, Test accuracy: 80.97 

Round  91, Global train loss: 0.279, Global test loss: 1.365, Global test accuracy: 55.38 

Round  92, Train loss: 0.255, Test loss: 0.607, Test accuracy: 80.95 

Round  92, Global train loss: 0.255, Global test loss: 1.388, Global test accuracy: 54.95 

Round  93, Train loss: 0.282, Test loss: 0.613, Test accuracy: 80.18 

Round  93, Global train loss: 0.282, Global test loss: 1.593, Global test accuracy: 51.17 

Round  94, Train loss: 0.232, Test loss: 0.618, Test accuracy: 80.25 

Round  94, Global train loss: 0.232, Global test loss: 1.635, Global test accuracy: 53.07 

Round  95, Train loss: 0.249, Test loss: 0.634, Test accuracy: 79.78 

Round  95, Global train loss: 0.249, Global test loss: 1.635, Global test accuracy: 52.05 

Round  96, Train loss: 0.263, Test loss: 0.625, Test accuracy: 80.23 

Round  96, Global train loss: 0.263, Global test loss: 1.570, Global test accuracy: 52.65 

Round  97, Train loss: 0.320, Test loss: 0.639, Test accuracy: 80.15 

Round  97, Global train loss: 0.320, Global test loss: 1.564, Global test accuracy: 52.17 

Round  98, Train loss: 0.208, Test loss: 0.634, Test accuracy: 80.53 

Round  98, Global train loss: 0.208, Global test loss: 1.493, Global test accuracy: 53.92 

Round  99, Train loss: 0.249, Test loss: 0.636, Test accuracy: 80.38 

Round  99, Global train loss: 0.249, Global test loss: 1.493, Global test accuracy: 53.68 

Final Round, Train loss: 0.199, Test loss: 0.684, Test accuracy: 80.52 

Final Round, Global train loss: 0.199, Global test loss: 1.493, Global test accuracy: 53.68 

Average accuracy final 10 rounds: 80.37833333333333 

Average global accuracy final 10 rounds: 53.02166666666667 

1075.9710335731506
[3.140737533569336, 4.220508575439453, 5.315503358840942, 6.386629819869995, 7.455854892730713, 8.534568309783936, 9.600779294967651, 10.669673204421997, 11.735309839248657, 12.804857969284058, 13.875093460083008, 14.945538997650146, 16.00916576385498, 17.08959650993347, 18.16948890686035, 19.29062819480896, 20.268181800842285, 21.231346607208252, 22.19933247566223, 23.174382209777832, 24.251150369644165, 25.328020334243774, 26.406503915786743, 27.487270832061768, 28.584492683410645, 29.660454988479614, 30.74026918411255, 31.818074464797974, 32.898478984832764, 33.97693347930908, 35.049262046813965, 36.12940430641174, 37.20692539215088, 38.28131628036499, 39.35794258117676, 40.43465542793274, 41.51266026496887, 42.58833932876587, 43.664310932159424, 44.743200063705444, 45.789214849472046, 46.86628317832947, 47.94141125679016, 49.02745342254639, 50.11025309562683, 51.18998646736145, 52.27075433731079, 53.402849197387695, 54.48472881317139, 55.562408685684204, 56.639275312423706, 57.716044425964355, 58.81119441986084, 59.933725118637085, 61.19303750991821, 62.414066553115845, 63.62956142425537, 64.70430326461792, 65.78443002700806, 66.85934448242188, 67.93359875679016, 69.0130627155304, 70.10098671913147, 71.16664123535156, 72.24383687973022, 73.29957890510559, 74.42864608764648, 75.54914951324463, 76.67171502113342, 77.79328894615173, 78.91502141952515, 80.03516101837158, 81.15223932266235, 82.27515482902527, 83.39849352836609, 84.51735973358154, 85.63904905319214, 86.75864386558533, 87.88919425010681, 88.96806240081787, 90.0404109954834, 91.11438584327698, 92.18779993057251, 93.26183199882507, 94.34202432632446, 95.42173194885254, 96.50002837181091, 97.57870125770569, 98.65522289276123, 99.73227143287659, 100.80542325973511, 101.87972354888916, 103.00673246383667, 104.13547682762146, 105.25919556617737, 106.33386182785034, 107.40752816200256, 108.48455929756165, 109.5562629699707, 110.63264727592468, 112.78468060493469]
[28.133333333333333, 30.8, 46.483333333333334, 51.4, 55.5, 58.63333333333333, 63.333333333333336, 65.91666666666667, 67.31666666666666, 67.93333333333334, 68.88333333333334, 69.73333333333333, 70.1, 69.76666666666667, 70.96666666666667, 71.63333333333334, 72.11666666666666, 72.56666666666666, 72.71666666666667, 73.26666666666667, 73.66666666666667, 73.48333333333333, 73.9, 73.5, 73.28333333333333, 73.03333333333333, 73.93333333333334, 74.0, 74.8, 74.51666666666667, 74.23333333333333, 74.46666666666667, 74.26666666666667, 75.1, 75.53333333333333, 75.46666666666667, 75.01666666666667, 75.5, 76.11666666666666, 76.26666666666667, 76.43333333333334, 77.36666666666666, 77.33333333333333, 77.5, 77.58333333333333, 77.8, 77.45, 77.7, 78.31666666666666, 78.11666666666666, 78.31666666666666, 78.15, 77.86666666666666, 77.48333333333333, 77.51666666666667, 77.13333333333334, 77.28333333333333, 77.73333333333333, 77.45, 77.85, 77.56666666666666, 78.41666666666667, 78.25, 78.18333333333334, 78.15, 78.63333333333334, 78.9, 79.38333333333334, 79.75, 79.56666666666666, 79.28333333333333, 79.93333333333334, 79.11666666666666, 78.71666666666667, 79.16666666666667, 79.78333333333333, 79.63333333333334, 79.63333333333334, 79.63333333333334, 78.81666666666666, 79.4, 79.91666666666667, 79.55, 79.3, 79.81666666666666, 80.0, 80.08333333333333, 80.61666666666666, 80.31666666666666, 80.11666666666666, 80.35, 80.96666666666667, 80.95, 80.18333333333334, 80.25, 79.78333333333333, 80.23333333333333, 80.15, 80.53333333333333, 80.38333333333334, 80.51666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.641, Test loss: 2.299, Test accuracy: 18.45 

Round   1, Train loss: 1.099, Test loss: 2.042, Test accuracy: 22.15 

Round   2, Train loss: 0.966, Test loss: 1.590, Test accuracy: 37.18 

Round   3, Train loss: 0.887, Test loss: 1.602, Test accuracy: 44.23 

Round   4, Train loss: 0.829, Test loss: 1.251, Test accuracy: 49.72 

Round   5, Train loss: 0.818, Test loss: 1.185, Test accuracy: 53.15 

Round   6, Train loss: 0.778, Test loss: 1.098, Test accuracy: 54.23 

Round   7, Train loss: 0.785, Test loss: 0.878, Test accuracy: 59.63 

Round   8, Train loss: 0.757, Test loss: 0.890, Test accuracy: 60.93 

Round   9, Train loss: 0.783, Test loss: 0.808, Test accuracy: 64.22 

Round  10, Train loss: 0.722, Test loss: 0.772, Test accuracy: 64.68 

Round  11, Train loss: 0.670, Test loss: 0.717, Test accuracy: 67.00 

Round  12, Train loss: 0.628, Test loss: 0.696, Test accuracy: 68.00 

Round  13, Train loss: 0.649, Test loss: 0.691, Test accuracy: 68.33 

Round  14, Train loss: 0.719, Test loss: 0.682, Test accuracy: 69.20 

Round  15, Train loss: 0.624, Test loss: 0.672, Test accuracy: 69.43 

Round  16, Train loss: 0.684, Test loss: 0.674, Test accuracy: 69.67 

Round  17, Train loss: 0.594, Test loss: 0.671, Test accuracy: 68.97 

Round  18, Train loss: 0.579, Test loss: 0.654, Test accuracy: 69.75 

Round  19, Train loss: 0.681, Test loss: 0.663, Test accuracy: 69.88 

Round  20, Train loss: 0.608, Test loss: 0.638, Test accuracy: 71.28 

Round  21, Train loss: 0.625, Test loss: 0.616, Test accuracy: 73.25 

Round  22, Train loss: 0.585, Test loss: 0.616, Test accuracy: 72.32 

Round  23, Train loss: 0.511, Test loss: 0.622, Test accuracy: 72.45 

Round  24, Train loss: 0.528, Test loss: 0.634, Test accuracy: 72.08 

Round  25, Train loss: 0.572, Test loss: 0.641, Test accuracy: 71.92 

Round  26, Train loss: 0.562, Test loss: 0.641, Test accuracy: 71.47 

Round  27, Train loss: 0.543, Test loss: 0.634, Test accuracy: 72.22 

Round  28, Train loss: 0.559, Test loss: 0.621, Test accuracy: 72.85 

Round  29, Train loss: 0.538, Test loss: 0.617, Test accuracy: 72.30 

Round  30, Train loss: 0.501, Test loss: 0.600, Test accuracy: 73.72 

Round  31, Train loss: 0.508, Test loss: 0.584, Test accuracy: 74.47 

Round  32, Train loss: 0.500, Test loss: 0.581, Test accuracy: 74.07 

Round  33, Train loss: 0.509, Test loss: 0.611, Test accuracy: 73.38 

Round  34, Train loss: 0.568, Test loss: 0.586, Test accuracy: 74.45 

Round  35, Train loss: 0.484, Test loss: 0.585, Test accuracy: 74.43 

Round  36, Train loss: 0.474, Test loss: 0.569, Test accuracy: 75.65 

Round  37, Train loss: 0.556, Test loss: 0.563, Test accuracy: 75.92 

Round  38, Train loss: 0.550, Test loss: 0.556, Test accuracy: 75.70 

Round  39, Train loss: 0.571, Test loss: 0.544, Test accuracy: 76.87 

Round  40, Train loss: 0.570, Test loss: 0.572, Test accuracy: 75.57 

Round  41, Train loss: 0.478, Test loss: 0.558, Test accuracy: 76.13 

Round  42, Train loss: 0.476, Test loss: 0.558, Test accuracy: 76.37 

Round  43, Train loss: 0.512, Test loss: 0.558, Test accuracy: 75.92 

Round  44, Train loss: 0.474, Test loss: 0.546, Test accuracy: 76.47 

Round  45, Train loss: 0.549, Test loss: 0.530, Test accuracy: 77.55 

Round  46, Train loss: 0.396, Test loss: 0.532, Test accuracy: 77.73 

Round  47, Train loss: 0.441, Test loss: 0.535, Test accuracy: 77.87 

Round  48, Train loss: 0.456, Test loss: 0.535, Test accuracy: 77.43 

Round  49, Train loss: 0.500, Test loss: 0.531, Test accuracy: 77.55 

Round  50, Train loss: 0.455, Test loss: 0.532, Test accuracy: 77.80 

Round  51, Train loss: 0.503, Test loss: 0.529, Test accuracy: 77.60 

Round  52, Train loss: 0.456, Test loss: 0.527, Test accuracy: 78.05 

Round  53, Train loss: 0.382, Test loss: 0.527, Test accuracy: 77.90 

Round  54, Train loss: 0.438, Test loss: 0.508, Test accuracy: 78.88 

Round  55, Train loss: 0.519, Test loss: 0.517, Test accuracy: 78.68 

Round  56, Train loss: 0.420, Test loss: 0.528, Test accuracy: 78.03 

Round  57, Train loss: 0.405, Test loss: 0.511, Test accuracy: 78.63 

Round  58, Train loss: 0.457, Test loss: 0.506, Test accuracy: 78.97 

Round  59, Train loss: 0.383, Test loss: 0.511, Test accuracy: 78.68 

Round  60, Train loss: 0.474, Test loss: 0.499, Test accuracy: 79.50 

Round  61, Train loss: 0.448, Test loss: 0.503, Test accuracy: 79.50 

Round  62, Train loss: 0.375, Test loss: 0.507, Test accuracy: 79.50 

Round  63, Train loss: 0.443, Test loss: 0.511, Test accuracy: 79.15 

Round  64, Train loss: 0.390, Test loss: 0.505, Test accuracy: 78.83 

Round  65, Train loss: 0.461, Test loss: 0.504, Test accuracy: 78.97 

Round  66, Train loss: 0.402, Test loss: 0.497, Test accuracy: 79.77 

Round  67, Train loss: 0.412, Test loss: 0.501, Test accuracy: 79.45 

Round  68, Train loss: 0.374, Test loss: 0.493, Test accuracy: 79.97 

Round  69, Train loss: 0.394, Test loss: 0.488, Test accuracy: 80.32 

Round  70, Train loss: 0.425, Test loss: 0.493, Test accuracy: 79.88 

Round  71, Train loss: 0.450, Test loss: 0.497, Test accuracy: 79.83 

Round  72, Train loss: 0.431, Test loss: 0.492, Test accuracy: 80.17 

Round  73, Train loss: 0.413, Test loss: 0.492, Test accuracy: 79.95 

Round  74, Train loss: 0.389, Test loss: 0.500, Test accuracy: 79.92 

Round  75, Train loss: 0.325, Test loss: 0.504, Test accuracy: 79.95 

Round  76, Train loss: 0.387, Test loss: 0.500, Test accuracy: 79.90 

Round  77, Train loss: 0.370, Test loss: 0.500, Test accuracy: 79.70 

Round  78, Train loss: 0.419, Test loss: 0.491, Test accuracy: 80.10 

Round  79, Train loss: 0.326, Test loss: 0.506, Test accuracy: 79.78 

Round  80, Train loss: 0.369, Test loss: 0.497, Test accuracy: 80.30 

Round  81, Train loss: 0.327, Test loss: 0.488, Test accuracy: 80.37 

Round  82, Train loss: 0.388, Test loss: 0.493, Test accuracy: 80.18 

Round  83, Train loss: 0.347, Test loss: 0.480, Test accuracy: 81.00 

Round  84, Train loss: 0.359, Test loss: 0.487, Test accuracy: 80.60 

Round  85, Train loss: 0.350, Test loss: 0.478, Test accuracy: 80.92 

Round  86, Train loss: 0.337, Test loss: 0.479, Test accuracy: 80.80 

Round  87, Train loss: 0.318, Test loss: 0.473, Test accuracy: 81.38 

Round  88, Train loss: 0.341, Test loss: 0.490, Test accuracy: 80.83 

Round  89, Train loss: 0.363, Test loss: 0.481, Test accuracy: 81.03 

Round  90, Train loss: 0.315, Test loss: 0.478, Test accuracy: 80.92 

Round  91, Train loss: 0.371, Test loss: 0.497, Test accuracy: 80.78 

Round  92, Train loss: 0.354, Test loss: 0.497, Test accuracy: 80.48 

Round  93, Train loss: 0.310, Test loss: 0.492, Test accuracy: 80.83 

Round  94, Train loss: 0.341, Test loss: 0.494, Test accuracy: 80.83 

Round  95, Train loss: 0.299, Test loss: 0.501, Test accuracy: 80.05 

Round  96, Train loss: 0.372, Test loss: 0.505, Test accuracy: 80.02 

Round  97, Train loss: 0.329, Test loss: 0.483, Test accuracy: 80.87 

Round  98, Train loss: 0.305, Test loss: 0.494, Test accuracy: 80.58 

Round  99, Train loss: 0.294, Test loss: 0.495, Test accuracy: 80.67 

Final Round, Train loss: 0.268, Test loss: 0.487, Test accuracy: 81.27 

Average accuracy final 10 rounds: 80.60333333333332 

804.6124713420868
[3.2100465297698975, 4.284385919570923, 5.254925966262817, 6.216686487197876, 7.181021213531494, 8.176339864730835, 9.184334754943848, 10.139171361923218, 11.092623949050903, 12.044899702072144, 12.998277187347412, 13.947491884231567, 14.902609825134277, 15.853162288665771, 16.807518005371094, 17.756170511245728, 18.704123497009277, 19.659961223602295, 20.640480041503906, 21.605088233947754, 22.566285610198975, 23.52711582183838, 24.484349966049194, 25.449187517166138, 26.40922737121582, 27.488630533218384, 28.57354187965393, 29.5543475151062, 30.51141119003296, 31.460639238357544, 32.56057548522949, 33.64077115058899, 34.63332271575928, 35.6209282875061, 36.57446813583374, 37.551711082458496, 38.49955987930298, 39.473177433013916, 40.42672061920166, 41.381946086883545, 42.335049867630005, 43.31731700897217, 44.27354311943054, 45.23180365562439, 46.185038566589355, 47.14149236679077, 48.094826459884644, 49.05159616470337, 50.00882124900818, 50.968570709228516, 51.92535471916199, 52.93253183364868, 53.88709092140198, 54.83868384361267, 55.796369552612305, 56.75051665306091, 57.70352578163147, 58.652469873428345, 59.6072096824646, 60.57249736785889, 61.52283477783203, 62.47285294532776, 63.423420429229736, 64.37985801696777, 65.34225654602051, 66.30162000656128, 67.26174592971802, 68.24983286857605, 69.19859194755554, 70.15257740020752, 71.1065468788147, 72.06020855903625, 73.01207995414734, 73.97201657295227, 74.92579364776611, 75.88969230651855, 76.84557771682739, 77.8003408908844, 78.75555777549744, 79.70950245857239, 80.65927147865295, 81.61767435073853, 82.58469343185425, 83.53375816345215, 84.47831225395203, 85.4253294467926, 86.37202644348145, 87.33097839355469, 88.30638527870178, 89.29394698143005, 90.28159666061401, 91.26791548728943, 92.24948763847351, 93.2303307056427, 94.21085143089294, 95.19667458534241, 96.1770236492157, 97.12531161308289, 98.1158516407013, 99.06111311912537, 100.62645888328552]
[18.45, 22.15, 37.18333333333333, 44.233333333333334, 49.71666666666667, 53.15, 54.233333333333334, 59.63333333333333, 60.93333333333333, 64.21666666666667, 64.68333333333334, 67.0, 68.0, 68.33333333333333, 69.2, 69.43333333333334, 69.66666666666667, 68.96666666666667, 69.75, 69.88333333333334, 71.28333333333333, 73.25, 72.31666666666666, 72.45, 72.08333333333333, 71.91666666666667, 71.46666666666667, 72.21666666666667, 72.85, 72.3, 73.71666666666667, 74.46666666666667, 74.06666666666666, 73.38333333333334, 74.45, 74.43333333333334, 75.65, 75.91666666666667, 75.7, 76.86666666666666, 75.56666666666666, 76.13333333333334, 76.36666666666666, 75.91666666666667, 76.46666666666667, 77.55, 77.73333333333333, 77.86666666666666, 77.43333333333334, 77.55, 77.8, 77.6, 78.05, 77.9, 78.88333333333334, 78.68333333333334, 78.03333333333333, 78.63333333333334, 78.96666666666667, 78.68333333333334, 79.5, 79.5, 79.5, 79.15, 78.83333333333333, 78.96666666666667, 79.76666666666667, 79.45, 79.96666666666667, 80.31666666666666, 79.88333333333334, 79.83333333333333, 80.16666666666667, 79.95, 79.91666666666667, 79.95, 79.9, 79.7, 80.1, 79.78333333333333, 80.3, 80.36666666666666, 80.18333333333334, 81.0, 80.6, 80.91666666666667, 80.8, 81.38333333333334, 80.83333333333333, 81.03333333333333, 80.91666666666667, 80.78333333333333, 80.48333333333333, 80.83333333333333, 80.83333333333333, 80.05, 80.01666666666667, 80.86666666666666, 80.58333333333333, 80.66666666666667, 81.26666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Traceback (most recent call last):
  File "main_fedpac.py", line 229, in <module>
    w_local, loss, indd, class_center_local, class_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 1255, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 57065 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
Traceback (most recent call last):
  File "main_ditto.py", line 182, in <module>
    w_k, loss, indd = local.train(net=net_global.to(args.device), idx=idx, lr=args.lr, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 488, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 56366 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
Traceback (most recent call last):
  File "main_apfl.py", line 147, in <module>
    w_global, w_local, loss, indd = local.train(net=net_local.to(args.device),w_local=w_local, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 354, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 54001 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Traceback (most recent call last):
  File "main_scaffold.py", line 150, in <module>
    w_local, loss, indd, count = local.train(net=net_local.to(args.device), idx=idx, lr=lr, c_list=c_list, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 237, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 56439 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_pfedme.py", line 236, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx],w_locals = w_locals)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 808, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 52076 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.230, Test loss: 2.026, Test accuracy: 25.22 

Round   0, Global train loss: 1.230, Global test loss: 2.368, Global test accuracy: 17.03 

Round   1, Train loss: 1.021, Test loss: 1.473, Test accuracy: 40.95 

Round   1, Global train loss: 1.021, Global test loss: 2.108, Global test accuracy: 26.13 

Round   2, Train loss: 0.910, Test loss: 1.303, Test accuracy: 44.75 

Round   2, Global train loss: 0.910, Global test loss: 2.109, Global test accuracy: 20.10 

Round   3, Train loss: 0.912, Test loss: 1.084, Test accuracy: 53.58 

Round   3, Global train loss: 0.912, Global test loss: 2.124, Global test accuracy: 22.90 

Round   4, Train loss: 0.840, Test loss: 1.078, Test accuracy: 55.43 

Round   4, Global train loss: 0.840, Global test loss: 2.142, Global test accuracy: 25.53 

Round   5, Train loss: 0.764, Test loss: 1.049, Test accuracy: 58.28 

Round   5, Global train loss: 0.764, Global test loss: 2.447, Global test accuracy: 24.08 

Round   6, Train loss: 0.769, Test loss: 0.895, Test accuracy: 62.70 

Round   6, Global train loss: 0.769, Global test loss: 2.203, Global test accuracy: 27.23 

Round   7, Train loss: 0.683, Test loss: 0.807, Test accuracy: 64.93 

Round   7, Global train loss: 0.683, Global test loss: 2.050, Global test accuracy: 28.20 

Round   8, Train loss: 0.623, Test loss: 0.809, Test accuracy: 65.62 

Round   8, Global train loss: 0.623, Global test loss: 2.083, Global test accuracy: 31.85 

Round   9, Train loss: 0.741, Test loss: 0.782, Test accuracy: 65.92 

Round   9, Global train loss: 0.741, Global test loss: 2.175, Global test accuracy: 16.57 

Round  10, Train loss: 0.638, Test loss: 0.764, Test accuracy: 67.62 

Round  10, Global train loss: 0.638, Global test loss: 1.965, Global test accuracy: 32.63 

Round  11, Train loss: 0.702, Test loss: 0.763, Test accuracy: 69.18 

Round  11, Global train loss: 0.702, Global test loss: 2.178, Global test accuracy: 29.13 

Round  12, Train loss: 0.760, Test loss: 0.746, Test accuracy: 69.38 

Round  12, Global train loss: 0.760, Global test loss: 2.088, Global test accuracy: 21.75 

Round  13, Train loss: 0.685, Test loss: 0.750, Test accuracy: 68.90 

Round  13, Global train loss: 0.685, Global test loss: 2.114, Global test accuracy: 25.25 

Round  14, Train loss: 0.624, Test loss: 0.752, Test accuracy: 69.15 

Round  14, Global train loss: 0.624, Global test loss: 1.982, Global test accuracy: 23.52 

Round  15, Train loss: 0.631, Test loss: 0.735, Test accuracy: 69.75 

Round  15, Global train loss: 0.631, Global test loss: 2.239, Global test accuracy: 18.45 

Round  16, Train loss: 0.571, Test loss: 0.763, Test accuracy: 67.20 

Round  16, Global train loss: 0.571, Global test loss: 2.006, Global test accuracy: 22.43 

Round  17, Train loss: 0.588, Test loss: 0.753, Test accuracy: 69.77 

Round  17, Global train loss: 0.588, Global test loss: 2.433, Global test accuracy: 20.20 

Round  18, Train loss: 0.545, Test loss: 0.706, Test accuracy: 70.90 

Round  18, Global train loss: 0.545, Global test loss: 2.122, Global test accuracy: 21.35 

Round  19, Train loss: 0.529, Test loss: 0.653, Test accuracy: 72.70 

Round  19, Global train loss: 0.529, Global test loss: 2.100, Global test accuracy: 21.60 

Round  20, Train loss: 0.550, Test loss: 0.655, Test accuracy: 72.42 

Round  20, Global train loss: 0.550, Global test loss: 2.048, Global test accuracy: 30.90 

Round  21, Train loss: 0.547, Test loss: 0.648, Test accuracy: 72.88 

Round  21, Global train loss: 0.547, Global test loss: 2.120, Global test accuracy: 24.67 

Round  22, Train loss: 0.496, Test loss: 0.643, Test accuracy: 73.22 

Round  22, Global train loss: 0.496, Global test loss: 2.084, Global test accuracy: 24.27 

Round  23, Train loss: 0.447, Test loss: 0.639, Test accuracy: 73.55 

Round  23, Global train loss: 0.447, Global test loss: 1.922, Global test accuracy: 30.62 

Round  24, Train loss: 0.492, Test loss: 0.648, Test accuracy: 73.20 

Round  24, Global train loss: 0.492, Global test loss: 2.046, Global test accuracy: 31.22 

Round  25, Train loss: 0.530, Test loss: 0.648, Test accuracy: 74.02 

Round  25, Global train loss: 0.530, Global test loss: 2.130, Global test accuracy: 16.75 

Round  26, Train loss: 0.396, Test loss: 0.635, Test accuracy: 74.43 

Round  26, Global train loss: 0.396, Global test loss: 1.990, Global test accuracy: 30.20 

Round  27, Train loss: 0.439, Test loss: 0.645, Test accuracy: 74.45 

Round  27, Global train loss: 0.439, Global test loss: 2.111, Global test accuracy: 29.97 

Round  28, Train loss: 0.365, Test loss: 0.633, Test accuracy: 75.18 

Round  28, Global train loss: 0.365, Global test loss: 2.304, Global test accuracy: 20.77 

Round  29, Train loss: 0.411, Test loss: 0.648, Test accuracy: 74.75 

Round  29, Global train loss: 0.411, Global test loss: 2.202, Global test accuracy: 26.97 

Round  30, Train loss: 0.488, Test loss: 0.640, Test accuracy: 75.15 

Round  30, Global train loss: 0.488, Global test loss: 2.009, Global test accuracy: 31.72 

Round  31, Train loss: 0.347, Test loss: 0.639, Test accuracy: 74.92 

Round  31, Global train loss: 0.347, Global test loss: 2.163, Global test accuracy: 28.75 

Round  32, Train loss: 0.334, Test loss: 0.662, Test accuracy: 74.42 

Round  32, Global train loss: 0.334, Global test loss: 1.902, Global test accuracy: 33.27 

Round  33, Train loss: 0.405, Test loss: 0.648, Test accuracy: 75.23 

Round  33, Global train loss: 0.405, Global test loss: 2.086, Global test accuracy: 19.00 

Round  34, Train loss: 0.357, Test loss: 0.684, Test accuracy: 75.17 

Round  34, Global train loss: 0.357, Global test loss: 2.043, Global test accuracy: 24.82 

Round  35, Train loss: 0.314, Test loss: 0.684, Test accuracy: 75.47 

Round  35, Global train loss: 0.314, Global test loss: 2.023, Global test accuracy: 34.25 

Round  36, Train loss: 0.365, Test loss: 0.694, Test accuracy: 75.02 

Round  36, Global train loss: 0.365, Global test loss: 2.312, Global test accuracy: 24.43 

Round  37, Train loss: 0.284, Test loss: 0.701, Test accuracy: 75.03 

Round  37, Global train loss: 0.284, Global test loss: 2.005, Global test accuracy: 32.37 

Round  38, Train loss: 0.309, Test loss: 0.705, Test accuracy: 75.28 

Round  38, Global train loss: 0.309, Global test loss: 1.961, Global test accuracy: 35.77 

Round  39, Train loss: 0.364, Test loss: 0.736, Test accuracy: 74.88 

Round  39, Global train loss: 0.364, Global test loss: 2.259, Global test accuracy: 10.58 

Round  40, Train loss: 0.259, Test loss: 0.725, Test accuracy: 75.48 

Round  40, Global train loss: 0.259, Global test loss: 2.041, Global test accuracy: 31.62 

Round  41, Train loss: 0.257, Test loss: 0.718, Test accuracy: 76.10 

Round  41, Global train loss: 0.257, Global test loss: 2.170, Global test accuracy: 25.45 

Round  42, Train loss: 0.360, Test loss: 0.715, Test accuracy: 76.28 

Round  42, Global train loss: 0.360, Global test loss: 2.105, Global test accuracy: 24.75 

Round  43, Train loss: 0.293, Test loss: 0.729, Test accuracy: 76.02 

Round  43, Global train loss: 0.293, Global test loss: 1.956, Global test accuracy: 32.60 

Round  44, Train loss: 0.261, Test loss: 0.717, Test accuracy: 76.37 

Round  44, Global train loss: 0.261, Global test loss: 2.053, Global test accuracy: 31.08 

Round  45, Train loss: 0.297, Test loss: 0.713, Test accuracy: 76.28 

Round  45, Global train loss: 0.297, Global test loss: 1.950, Global test accuracy: 28.10 

Round  46, Train loss: 0.298, Test loss: 0.707, Test accuracy: 76.33 

Round  46, Global train loss: 0.298, Global test loss: 2.118, Global test accuracy: 30.22 

Round  47, Train loss: 0.269, Test loss: 0.714, Test accuracy: 76.53 

Round  47, Global train loss: 0.269, Global test loss: 2.136, Global test accuracy: 26.83 

Round  48, Train loss: 0.223, Test loss: 0.759, Test accuracy: 76.22 

Round  48, Global train loss: 0.223, Global test loss: 1.955, Global test accuracy: 30.70 

Round  49, Train loss: 0.273, Test loss: 0.757, Test accuracy: 76.55 

Round  49, Global train loss: 0.273, Global test loss: 2.179, Global test accuracy: 20.73 

Round  50, Train loss: 0.227, Test loss: 0.776, Test accuracy: 76.18 

Round  50, Global train loss: 0.227, Global test loss: 2.092, Global test accuracy: 30.02 

Round  51, Train loss: 0.222, Test loss: 0.767, Test accuracy: 75.88 

Round  51, Global train loss: 0.222, Global test loss: 2.261, Global test accuracy: 26.25 

Round  52, Train loss: 0.209, Test loss: 0.776, Test accuracy: 76.00 

Round  52, Global train loss: 0.209, Global test loss: 2.204, Global test accuracy: 29.07 

Round  53, Train loss: 0.220, Test loss: 0.774, Test accuracy: 76.08 

Round  53, Global train loss: 0.220, Global test loss: 1.989, Global test accuracy: 32.22 

Round  54, Train loss: 0.148, Test loss: 0.796, Test accuracy: 76.37 

Round  54, Global train loss: 0.148, Global test loss: 2.103, Global test accuracy: 22.65 

Round  55, Train loss: 0.168, Test loss: 0.793, Test accuracy: 76.33 

Round  55, Global train loss: 0.168, Global test loss: 2.056, Global test accuracy: 27.77 

Round  56, Train loss: 0.179, Test loss: 0.803, Test accuracy: 76.82 

Round  56, Global train loss: 0.179, Global test loss: 2.341, Global test accuracy: 26.77 

Round  57, Train loss: 0.144, Test loss: 0.798, Test accuracy: 77.07 

Round  57, Global train loss: 0.144, Global test loss: 2.191, Global test accuracy: 21.33 

Round  58, Train loss: 0.172, Test loss: 0.810, Test accuracy: 77.07 

Round  58, Global train loss: 0.172, Global test loss: 2.030, Global test accuracy: 26.05 

Round  59, Train loss: 0.146, Test loss: 0.821, Test accuracy: 77.10 

Round  59, Global train loss: 0.146, Global test loss: 2.152, Global test accuracy: 21.43 

Round  60, Train loss: 0.216, Test loss: 0.836, Test accuracy: 76.92 

Round  60, Global train loss: 0.216, Global test loss: 2.029, Global test accuracy: 24.20 

Round  61, Train loss: 0.159, Test loss: 0.828, Test accuracy: 76.70 

Round  61, Global train loss: 0.159, Global test loss: 2.085, Global test accuracy: 25.07 

Round  62, Train loss: 0.184, Test loss: 0.836, Test accuracy: 77.07 

Round  62, Global train loss: 0.184, Global test loss: 1.997, Global test accuracy: 26.90 

Round  63, Train loss: 0.185, Test loss: 0.844, Test accuracy: 77.30 

Round  63, Global train loss: 0.185, Global test loss: 1.978, Global test accuracy: 30.12 

Round  64, Train loss: 0.124, Test loss: 0.874, Test accuracy: 77.17 

Round  64, Global train loss: 0.124, Global test loss: 1.992, Global test accuracy: 29.92 

Round  65, Train loss: 0.138, Test loss: 0.864, Test accuracy: 77.03 

Round  65, Global train loss: 0.138, Global test loss: 2.085, Global test accuracy: 33.43 

Round  66, Train loss: 0.166, Test loss: 0.884, Test accuracy: 76.73 

Round  66, Global train loss: 0.166, Global test loss: 1.981, Global test accuracy: 34.73 

Round  67, Train loss: 0.140, Test loss: 0.907, Test accuracy: 76.40 

Round  67, Global train loss: 0.140, Global test loss: 1.949, Global test accuracy: 29.90 

Round  68, Train loss: 0.139, Test loss: 0.903, Test accuracy: 77.05 

Round  68, Global train loss: 0.139, Global test loss: 2.156, Global test accuracy: 20.65 

Round  69, Train loss: 0.128, Test loss: 0.916, Test accuracy: 76.55 

Round  69, Global train loss: 0.128, Global test loss: 1.922, Global test accuracy: 32.10 

Round  70, Train loss: 0.132, Test loss: 0.916, Test accuracy: 76.30 

Round  70, Global train loss: 0.132, Global test loss: 1.953, Global test accuracy: 33.92 

Round  71, Train loss: 0.123, Test loss: 0.929, Test accuracy: 76.55 

Round  71, Global train loss: 0.123, Global test loss: 2.074, Global test accuracy: 26.32 

Round  72, Train loss: 0.165, Test loss: 0.928, Test accuracy: 76.70 

Round  72, Global train loss: 0.165, Global test loss: 2.124, Global test accuracy: 27.82 

Round  73, Train loss: 0.089, Test loss: 0.924, Test accuracy: 76.87 

Round  73, Global train loss: 0.089, Global test loss: 2.030, Global test accuracy: 28.98 

Round  74, Train loss: 0.101, Test loss: 0.934, Test accuracy: 76.70 

Round  74, Global train loss: 0.101, Global test loss: 2.141, Global test accuracy: 30.75 

Round  75, Train loss: 0.137, Test loss: 0.957, Test accuracy: 76.63 

Round  75, Global train loss: 0.137, Global test loss: 1.963, Global test accuracy: 26.62 

Round  76, Train loss: 0.109, Test loss: 0.944, Test accuracy: 76.98 

Round  76, Global train loss: 0.109, Global test loss: 1.938, Global test accuracy: 31.30 

Round  77, Train loss: 0.107, Test loss: 0.944, Test accuracy: 76.95 

Round  77, Global train loss: 0.107, Global test loss: 2.141, Global test accuracy: 28.88 

Round  78, Train loss: 0.110, Test loss: 0.965, Test accuracy: 76.88 

Round  78, Global train loss: 0.110, Global test loss: 2.116, Global test accuracy: 25.48 

Round  79, Train loss: 0.095, Test loss: 0.977, Test accuracy: 77.05 

Round  79, Global train loss: 0.095, Global test loss: 2.082, Global test accuracy: 26.40 

Round  80, Train loss: 0.073, Test loss: 0.991, Test accuracy: 77.15 

Round  80, Global train loss: 0.073, Global test loss: 1.998, Global test accuracy: 25.60 

Round  81, Train loss: 0.084, Test loss: 0.964, Test accuracy: 77.10 

Round  81, Global train loss: 0.084, Global test loss: 1.942, Global test accuracy: 30.80 

Round  82, Train loss: 0.085, Test loss: 0.969, Test accuracy: 77.50 

Round  82, Global train loss: 0.085, Global test loss: 2.002, Global test accuracy: 28.43 

Round  83, Train loss: 0.085, Test loss: 0.983, Test accuracy: 77.32 

Round  83, Global train loss: 0.085, Global test loss: 1.963, Global test accuracy: 27.38 

Round  84, Train loss: 0.095, Test loss: 1.005, Test accuracy: 77.13 

Round  84, Global train loss: 0.095, Global test loss: 2.012, Global test accuracy: 33.07 

Round  85, Train loss: 0.096, Test loss: 1.007, Test accuracy: 77.17 

Round  85, Global train loss: 0.096, Global test loss: 2.059, Global test accuracy: 27.97 

Round  86, Train loss: 0.081, Test loss: 1.013, Test accuracy: 77.30 

Round  86, Global train loss: 0.081, Global test loss: 2.086, Global test accuracy: 26.43 

Round  87, Train loss: 0.076, Test loss: 1.057, Test accuracy: 77.57 

Round  87, Global train loss: 0.076, Global test loss: 2.057, Global test accuracy: 23.57 

Round  88, Train loss: 0.101, Test loss: 1.046, Test accuracy: 77.35 

Round  88, Global train loss: 0.101, Global test loss: 2.129, Global test accuracy: 24.62 

Round  89, Train loss: 0.087, Test loss: 1.026, Test accuracy: 77.48 

Round  89, Global train loss: 0.087, Global test loss: 2.092, Global test accuracy: 28.73 

Round  90, Train loss: 0.060, Test loss: 1.027, Test accuracy: 77.38 

Round  90, Global train loss: 0.060, Global test loss: 1.961, Global test accuracy: 29.95 

Round  91, Train loss: 0.072, Test loss: 1.055, Test accuracy: 77.53 

Round  91, Global train loss: 0.072, Global test loss: 2.034, Global test accuracy: 30.90 

Round  92, Train loss: 0.051, Test loss: 1.087, Test accuracy: 77.72 

Round  92, Global train loss: 0.051, Global test loss: 1.986, Global test accuracy: 36.00 

Round  93, Train loss: 0.063, Test loss: 1.086, Test accuracy: 77.65 

Round  93, Global train loss: 0.063, Global test loss: 2.216, Global test accuracy: 13.98 

Round  94, Train loss: 0.097, Test loss: 1.070, Test accuracy: 77.12 

Round  94, Global train loss: 0.097, Global test loss: 2.037, Global test accuracy: 27.77 

Round  95, Train loss: 0.099, Test loss: 1.054, Test accuracy: 77.28 

Round  95, Global train loss: 0.099, Global test loss: 2.061, Global test accuracy: 27.48 

Round  96, Train loss: 0.036, Test loss: 1.085, Test accuracy: 77.03 

Round  96, Global train loss: 0.036, Global test loss: 1.959, Global test accuracy: 32.20 

Round  97, Train loss: 0.089, Test loss: 1.091, Test accuracy: 76.82 

Round  97, Global train loss: 0.089, Global test loss: 1.956, Global test accuracy: 30.97 

Round  98, Train loss: 0.076, Test loss: 1.081, Test accuracy: 77.23 

Round  98, Global train loss: 0.076, Global test loss: 1.887, Global test accuracy: 33.20 

Round  99, Train loss: 0.066, Test loss: 1.096, Test accuracy: 77.35 

Round  99, Global train loss: 0.066, Global test loss: 2.203, Global test accuracy: 22.67 

Final Round, Train loss: 0.063, Test loss: 1.179, Test accuracy: 76.52 

Final Round, Global train loss: 0.063, Global test loss: 2.203, Global test accuracy: 22.67 

Average accuracy final 10 rounds: 77.31166666666667 

Average global accuracy final 10 rounds: 28.511666666666667 

1057.5104701519012
[3.210373640060425, 4.452184200286865, 5.533019542694092, 6.633557558059692, 7.725145101547241, 8.808837652206421, 9.894099950790405, 10.983294010162354, 12.067819595336914, 13.156414985656738, 14.242957830429077, 15.326559782028198, 16.406779289245605, 17.48735022544861, 18.571656703948975, 19.654786825180054, 20.73988938331604, 21.827996969223022, 22.91834020614624, 24.00837993621826, 25.13461446762085, 26.066885232925415, 26.99466586112976, 28.080583333969116, 29.15993332862854, 30.29870867729187, 31.149473428726196, 32.00486493110657, 32.87291979789734, 33.74472999572754, 34.594621896743774, 35.44975280761719, 36.307600259780884, 37.16009306907654, 38.01628255844116, 38.873350620269775, 39.72267961502075, 40.575000286102295, 41.428719997406006, 42.276005268096924, 43.318459033966064, 44.42604351043701, 45.50680065155029, 46.618767976760864, 47.70419096946716, 48.78525185585022, 49.86702871322632, 50.945409536361694, 52.026357650756836, 53.10711050033569, 54.187986850738525, 55.26610040664673, 56.34437894821167, 57.47018313407898, 58.55272078514099, 59.63234043121338, 60.71368718147278, 61.79451608657837, 62.872246503829956, 63.95371460914612, 65.03162837028503, 66.1129150390625, 67.19495964050293, 68.28006339073181, 69.3601176738739, 70.44676065444946, 71.53433132171631, 72.62379002571106, 73.70371127128601, 74.78633880615234, 75.86702466011047, 76.94753360748291, 78.02990221977234, 79.10914897918701, 80.20181465148926, 81.28349804878235, 82.36059141159058, 83.44390344619751, 84.52333188056946, 85.60041427612305, 86.67851138114929, 87.7545518875122, 88.84750699996948, 89.95966601371765, 91.03119039535522, 92.10604882240295, 93.18245816230774, 94.25913047790527, 95.33453011512756, 96.45695853233337, 97.57827019691467, 98.70265698432922, 99.78003883361816, 100.857102394104, 101.94705843925476, 103.04382061958313, 104.12453365325928, 105.20684885978699, 106.28470730781555, 107.36170959472656, 109.51616168022156]
[25.216666666666665, 40.95, 44.75, 53.583333333333336, 55.43333333333333, 58.28333333333333, 62.7, 64.93333333333334, 65.61666666666666, 65.91666666666667, 67.61666666666666, 69.18333333333334, 69.38333333333334, 68.9, 69.15, 69.75, 67.2, 69.76666666666667, 70.9, 72.7, 72.41666666666667, 72.88333333333334, 73.21666666666667, 73.55, 73.2, 74.01666666666667, 74.43333333333334, 74.45, 75.18333333333334, 74.75, 75.15, 74.91666666666667, 74.41666666666667, 75.23333333333333, 75.16666666666667, 75.46666666666667, 75.01666666666667, 75.03333333333333, 75.28333333333333, 74.88333333333334, 75.48333333333333, 76.1, 76.28333333333333, 76.01666666666667, 76.36666666666666, 76.28333333333333, 76.33333333333333, 76.53333333333333, 76.21666666666667, 76.55, 76.18333333333334, 75.88333333333334, 76.0, 76.08333333333333, 76.36666666666666, 76.33333333333333, 76.81666666666666, 77.06666666666666, 77.06666666666666, 77.1, 76.91666666666667, 76.7, 77.06666666666666, 77.3, 77.16666666666667, 77.03333333333333, 76.73333333333333, 76.4, 77.05, 76.55, 76.3, 76.55, 76.7, 76.86666666666666, 76.7, 76.63333333333334, 76.98333333333333, 76.95, 76.88333333333334, 77.05, 77.15, 77.1, 77.5, 77.31666666666666, 77.13333333333334, 77.16666666666667, 77.3, 77.56666666666666, 77.35, 77.48333333333333, 77.38333333333334, 77.53333333333333, 77.71666666666667, 77.65, 77.11666666666666, 77.28333333333333, 77.03333333333333, 76.81666666666666, 77.23333333333333, 77.35, 76.51666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.211, Test loss: 1.902, Test accuracy: 23.37 

Round   0, Global train loss: 1.211, Global test loss: 2.241, Global test accuracy: 13.35 

Round   1, Train loss: 1.011, Test loss: 1.610, Test accuracy: 38.53 

Round   1, Global train loss: 1.011, Global test loss: 2.324, Global test accuracy: 18.65 

Round   2, Train loss: 0.982, Test loss: 1.352, Test accuracy: 43.05 

Round   2, Global train loss: 0.982, Global test loss: 2.130, Global test accuracy: 22.43 

Round   3, Train loss: 0.893, Test loss: 1.326, Test accuracy: 49.47 

Round   3, Global train loss: 0.893, Global test loss: 2.161, Global test accuracy: 30.22 

Round   4, Train loss: 0.822, Test loss: 1.368, Test accuracy: 50.43 

Round   4, Global train loss: 0.822, Global test loss: 2.395, Global test accuracy: 28.25 

Round   5, Train loss: 0.823, Test loss: 0.946, Test accuracy: 57.65 

Round   5, Global train loss: 0.823, Global test loss: 1.899, Global test accuracy: 33.42 

Round   6, Train loss: 0.739, Test loss: 0.915, Test accuracy: 60.23 

Round   6, Global train loss: 0.739, Global test loss: 1.875, Global test accuracy: 36.68 

Round   7, Train loss: 0.822, Test loss: 0.790, Test accuracy: 65.82 

Round   7, Global train loss: 0.822, Global test loss: 1.825, Global test accuracy: 36.92 

Round   8, Train loss: 0.731, Test loss: 0.783, Test accuracy: 66.43 

Round   8, Global train loss: 0.731, Global test loss: 1.714, Global test accuracy: 37.12 

Round   9, Train loss: 0.724, Test loss: 0.684, Test accuracy: 70.58 

Round   9, Global train loss: 0.724, Global test loss: 1.734, Global test accuracy: 41.02 

Round  10, Train loss: 0.669, Test loss: 0.666, Test accuracy: 71.38 

Round  10, Global train loss: 0.669, Global test loss: 1.671, Global test accuracy: 40.57 

Round  11, Train loss: 0.663, Test loss: 0.656, Test accuracy: 71.57 

Round  11, Global train loss: 0.663, Global test loss: 1.591, Global test accuracy: 43.07 

Round  12, Train loss: 0.732, Test loss: 0.638, Test accuracy: 72.42 

Round  12, Global train loss: 0.732, Global test loss: 1.520, Global test accuracy: 45.63 

Round  13, Train loss: 0.618, Test loss: 0.636, Test accuracy: 72.10 

Round  13, Global train loss: 0.618, Global test loss: 1.767, Global test accuracy: 39.02 

Round  14, Train loss: 0.721, Test loss: 0.632, Test accuracy: 73.12 

Round  14, Global train loss: 0.721, Global test loss: 1.531, Global test accuracy: 45.60 

Round  15, Train loss: 0.659, Test loss: 0.630, Test accuracy: 73.55 

Round  15, Global train loss: 0.659, Global test loss: 1.949, Global test accuracy: 34.90 

Round  16, Train loss: 0.657, Test loss: 0.607, Test accuracy: 74.08 

Round  16, Global train loss: 0.657, Global test loss: 1.508, Global test accuracy: 46.00 

Round  17, Train loss: 0.574, Test loss: 0.600, Test accuracy: 74.65 

Round  17, Global train loss: 0.574, Global test loss: 1.636, Global test accuracy: 46.67 

Round  18, Train loss: 0.539, Test loss: 0.588, Test accuracy: 74.70 

Round  18, Global train loss: 0.539, Global test loss: 1.651, Global test accuracy: 42.78 

Round  19, Train loss: 0.557, Test loss: 0.591, Test accuracy: 74.93 

Round  19, Global train loss: 0.557, Global test loss: 1.564, Global test accuracy: 41.85 

Round  20, Train loss: 0.550, Test loss: 0.601, Test accuracy: 74.68 

Round  20, Global train loss: 0.550, Global test loss: 1.553, Global test accuracy: 43.98 

Round  21, Train loss: 0.599, Test loss: 0.598, Test accuracy: 75.08 

Round  21, Global train loss: 0.599, Global test loss: 1.468, Global test accuracy: 45.62 

Round  22, Train loss: 0.682, Test loss: 0.598, Test accuracy: 75.55 

Round  22, Global train loss: 0.682, Global test loss: 1.483, Global test accuracy: 47.57 

Round  23, Train loss: 0.690, Test loss: 0.590, Test accuracy: 75.55 

Round  23, Global train loss: 0.690, Global test loss: 1.420, Global test accuracy: 48.52 

Round  24, Train loss: 0.574, Test loss: 0.585, Test accuracy: 75.58 

Round  24, Global train loss: 0.574, Global test loss: 1.463, Global test accuracy: 48.02 

Round  25, Train loss: 0.598, Test loss: 0.579, Test accuracy: 76.45 

Round  25, Global train loss: 0.598, Global test loss: 1.710, Global test accuracy: 39.47 

Round  26, Train loss: 0.476, Test loss: 0.564, Test accuracy: 76.73 

Round  26, Global train loss: 0.476, Global test loss: 1.418, Global test accuracy: 48.70 

Round  27, Train loss: 0.541, Test loss: 0.575, Test accuracy: 76.82 

Round  27, Global train loss: 0.541, Global test loss: 1.730, Global test accuracy: 40.43 

Round  28, Train loss: 0.544, Test loss: 0.570, Test accuracy: 77.37 

Round  28, Global train loss: 0.544, Global test loss: 1.487, Global test accuracy: 45.02 

Round  29, Train loss: 0.583, Test loss: 0.572, Test accuracy: 77.35 

Round  29, Global train loss: 0.583, Global test loss: 1.372, Global test accuracy: 50.37 

Round  30, Train loss: 0.609, Test loss: 0.565, Test accuracy: 77.63 

Round  30, Global train loss: 0.609, Global test loss: 1.448, Global test accuracy: 47.82 

Round  31, Train loss: 0.617, Test loss: 0.566, Test accuracy: 77.75 

Round  31, Global train loss: 0.617, Global test loss: 1.472, Global test accuracy: 47.63 

Round  32, Train loss: 0.492, Test loss: 0.558, Test accuracy: 78.27 

Round  32, Global train loss: 0.492, Global test loss: 1.579, Global test accuracy: 46.02 

Round  33, Train loss: 0.538, Test loss: 0.554, Test accuracy: 78.17 

Round  33, Global train loss: 0.538, Global test loss: 1.358, Global test accuracy: 50.65 

Round  34, Train loss: 0.439, Test loss: 0.581, Test accuracy: 77.58 

Round  34, Global train loss: 0.439, Global test loss: 1.401, Global test accuracy: 52.00 

Round  35, Train loss: 0.481, Test loss: 0.577, Test accuracy: 77.87 

Round  35, Global train loss: 0.481, Global test loss: 1.411, Global test accuracy: 51.70 

Round  36, Train loss: 0.464, Test loss: 0.551, Test accuracy: 78.60 

Round  36, Global train loss: 0.464, Global test loss: 1.587, Global test accuracy: 44.23 

Round  37, Train loss: 0.597, Test loss: 0.541, Test accuracy: 79.43 

Round  37, Global train loss: 0.597, Global test loss: 1.428, Global test accuracy: 51.43 

Round  38, Train loss: 0.470, Test loss: 0.547, Test accuracy: 78.85 

Round  38, Global train loss: 0.470, Global test loss: 1.483, Global test accuracy: 48.38 

Round  39, Train loss: 0.450, Test loss: 0.547, Test accuracy: 78.88 

Round  39, Global train loss: 0.450, Global test loss: 1.440, Global test accuracy: 50.52 

Round  40, Train loss: 0.430, Test loss: 0.545, Test accuracy: 78.95 

Round  40, Global train loss: 0.430, Global test loss: 1.263, Global test accuracy: 56.50 

Round  41, Train loss: 0.459, Test loss: 0.554, Test accuracy: 78.37 

Round  41, Global train loss: 0.459, Global test loss: 1.462, Global test accuracy: 51.73 

Round  42, Train loss: 0.584, Test loss: 0.557, Test accuracy: 78.08 

Round  42, Global train loss: 0.584, Global test loss: 1.389, Global test accuracy: 52.10 

Round  43, Train loss: 0.478, Test loss: 0.582, Test accuracy: 77.48 

Round  43, Global train loss: 0.478, Global test loss: 1.675, Global test accuracy: 49.08 

Round  44, Train loss: 0.435, Test loss: 0.555, Test accuracy: 78.50 

Round  44, Global train loss: 0.435, Global test loss: 1.461, Global test accuracy: 51.97 

Round  45, Train loss: 0.430, Test loss: 0.549, Test accuracy: 78.93 

Round  45, Global train loss: 0.430, Global test loss: 1.395, Global test accuracy: 53.27 

Round  46, Train loss: 0.424, Test loss: 0.544, Test accuracy: 79.32 

Round  46, Global train loss: 0.424, Global test loss: 1.427, Global test accuracy: 54.68 

Round  47, Train loss: 0.470, Test loss: 0.546, Test accuracy: 79.42 

Round  47, Global train loss: 0.470, Global test loss: 1.488, Global test accuracy: 50.60 

Round  48, Train loss: 0.412, Test loss: 0.548, Test accuracy: 79.62 

Round  48, Global train loss: 0.412, Global test loss: 1.434, Global test accuracy: 53.30 

Round  49, Train loss: 0.393, Test loss: 0.551, Test accuracy: 79.42 

Round  49, Global train loss: 0.393, Global test loss: 1.394, Global test accuracy: 53.92 

Round  50, Train loss: 0.479, Test loss: 0.552, Test accuracy: 79.62 

Round  50, Global train loss: 0.479, Global test loss: 1.273, Global test accuracy: 56.13 

Round  51, Train loss: 0.445, Test loss: 0.559, Test accuracy: 79.15 

Round  51, Global train loss: 0.445, Global test loss: 1.218, Global test accuracy: 57.77 

Round  52, Train loss: 0.337, Test loss: 0.557, Test accuracy: 79.12 

Round  52, Global train loss: 0.337, Global test loss: 1.313, Global test accuracy: 57.18 

Round  53, Train loss: 0.419, Test loss: 0.534, Test accuracy: 80.32 

Round  53, Global train loss: 0.419, Global test loss: 1.339, Global test accuracy: 54.13 

Round  54, Train loss: 0.376, Test loss: 0.548, Test accuracy: 80.03 

Round  54, Global train loss: 0.376, Global test loss: 1.261, Global test accuracy: 58.03 

Round  55, Train loss: 0.368, Test loss: 0.550, Test accuracy: 79.90 

Round  55, Global train loss: 0.368, Global test loss: 1.511, Global test accuracy: 51.72 

Round  56, Train loss: 0.447, Test loss: 0.542, Test accuracy: 79.95 

Round  56, Global train loss: 0.447, Global test loss: 1.293, Global test accuracy: 53.95 

Round  57, Train loss: 0.311, Test loss: 0.540, Test accuracy: 79.90 

Round  57, Global train loss: 0.311, Global test loss: 1.514, Global test accuracy: 53.05 

Round  58, Train loss: 0.327, Test loss: 0.542, Test accuracy: 79.92 

Round  58, Global train loss: 0.327, Global test loss: 1.527, Global test accuracy: 50.33 

Round  59, Train loss: 0.432, Test loss: 0.533, Test accuracy: 80.37 

Round  59, Global train loss: 0.432, Global test loss: 1.462, Global test accuracy: 52.97 

Round  60, Train loss: 0.361, Test loss: 0.558, Test accuracy: 79.80 

Round  60, Global train loss: 0.361, Global test loss: 1.401, Global test accuracy: 54.90 

Round  61, Train loss: 0.394, Test loss: 0.530, Test accuracy: 80.48 

Round  61, Global train loss: 0.394, Global test loss: 1.513, Global test accuracy: 50.78 

Round  62, Train loss: 0.359, Test loss: 0.525, Test accuracy: 80.88 

Round  62, Global train loss: 0.359, Global test loss: 1.297, Global test accuracy: 56.82 

Round  63, Train loss: 0.291, Test loss: 0.519, Test accuracy: 81.38 

Round  63, Global train loss: 0.291, Global test loss: 1.574, Global test accuracy: 50.97 

Round  64, Train loss: 0.353, Test loss: 0.506, Test accuracy: 81.78 

Round  64, Global train loss: 0.353, Global test loss: 1.335, Global test accuracy: 57.50 

Round  65, Train loss: 0.346, Test loss: 0.513, Test accuracy: 81.87 

Round  65, Global train loss: 0.346, Global test loss: 1.283, Global test accuracy: 56.58 

Round  66, Train loss: 0.284, Test loss: 0.524, Test accuracy: 81.18 

Round  66, Global train loss: 0.284, Global test loss: 1.541, Global test accuracy: 53.85 

Round  67, Train loss: 0.383, Test loss: 0.525, Test accuracy: 81.33 

Round  67, Global train loss: 0.383, Global test loss: 1.373, Global test accuracy: 55.33 

Round  68, Train loss: 0.305, Test loss: 0.538, Test accuracy: 81.32 

Round  68, Global train loss: 0.305, Global test loss: 1.428, Global test accuracy: 54.87 

Round  69, Train loss: 0.336, Test loss: 0.532, Test accuracy: 81.50 

Round  69, Global train loss: 0.336, Global test loss: 1.295, Global test accuracy: 56.77 

Round  70, Train loss: 0.301, Test loss: 0.532, Test accuracy: 81.18 

Round  70, Global train loss: 0.301, Global test loss: 1.257, Global test accuracy: 59.30 

Round  71, Train loss: 0.306, Test loss: 0.532, Test accuracy: 81.30 

Round  71, Global train loss: 0.306, Global test loss: 1.524, Global test accuracy: 53.02 

Round  72, Train loss: 0.322, Test loss: 0.531, Test accuracy: 81.40 

Round  72, Global train loss: 0.322, Global test loss: 1.278, Global test accuracy: 58.02 

Round  73, Train loss: 0.331, Test loss: 0.553, Test accuracy: 80.62 

Round  73, Global train loss: 0.331, Global test loss: 1.247, Global test accuracy: 57.78 

Round  74, Train loss: 0.275, Test loss: 0.559, Test accuracy: 80.73 

Round  74, Global train loss: 0.275, Global test loss: 1.296, Global test accuracy: 57.90 

Round  75, Train loss: 0.341, Test loss: 0.540, Test accuracy: 81.28 

Round  75, Global train loss: 0.341, Global test loss: 1.648, Global test accuracy: 53.98 

Round  76, Train loss: 0.311, Test loss: 0.548, Test accuracy: 81.18 

Round  76, Global train loss: 0.311, Global test loss: 1.772, Global test accuracy: 50.25 

Round  77, Train loss: 0.340, Test loss: 0.556, Test accuracy: 81.42 

Round  77, Global train loss: 0.340, Global test loss: 1.248, Global test accuracy: 58.13 

Round  78, Train loss: 0.258, Test loss: 0.569, Test accuracy: 80.93 

Round  78, Global train loss: 0.258, Global test loss: 1.402, Global test accuracy: 57.78 

Round  79, Train loss: 0.331, Test loss: 0.559, Test accuracy: 81.18 

Round  79, Global train loss: 0.331, Global test loss: 1.529, Global test accuracy: 53.97 

Round  80, Train loss: 0.340, Test loss: 0.542, Test accuracy: 81.42 

Round  80, Global train loss: 0.340, Global test loss: 1.242, Global test accuracy: 59.82 

Round  81, Train loss: 0.250, Test loss: 0.553, Test accuracy: 81.25 

Round  81, Global train loss: 0.250, Global test loss: 1.516, Global test accuracy: 56.10 

Round  82, Train loss: 0.262, Test loss: 0.547, Test accuracy: 81.32 

Round  82, Global train loss: 0.262, Global test loss: 1.356, Global test accuracy: 56.82 

Round  83, Train loss: 0.362, Test loss: 0.544, Test accuracy: 81.23 

Round  83, Global train loss: 0.362, Global test loss: 1.914, Global test accuracy: 46.00 

Round  84, Train loss: 0.235, Test loss: 0.543, Test accuracy: 81.12 

Round  84, Global train loss: 0.235, Global test loss: 1.401, Global test accuracy: 56.33 

Round  85, Train loss: 0.263, Test loss: 0.550, Test accuracy: 81.38 

Round  85, Global train loss: 0.263, Global test loss: 1.250, Global test accuracy: 59.52 

Round  86, Train loss: 0.290, Test loss: 0.565, Test accuracy: 81.53 

Round  86, Global train loss: 0.290, Global test loss: 1.296, Global test accuracy: 58.83 

Round  87, Train loss: 0.287, Test loss: 0.573, Test accuracy: 81.60 

Round  87, Global train loss: 0.287, Global test loss: 1.535, Global test accuracy: 52.82 

Round  88, Train loss: 0.277, Test loss: 0.564, Test accuracy: 81.98 

Round  88, Global train loss: 0.277, Global test loss: 1.281, Global test accuracy: 58.78 

Round  89, Train loss: 0.308, Test loss: 0.560, Test accuracy: 81.72 

Round  89, Global train loss: 0.308, Global test loss: 1.241, Global test accuracy: 59.28 

Round  90, Train loss: 0.269, Test loss: 0.557, Test accuracy: 81.65 

Round  90, Global train loss: 0.269, Global test loss: 1.446, Global test accuracy: 56.55 

Round  91, Train loss: 0.267, Test loss: 0.560, Test accuracy: 81.57 

Round  91, Global train loss: 0.267, Global test loss: 1.371, Global test accuracy: 56.75 

Round  92, Train loss: 0.290, Test loss: 0.545, Test accuracy: 82.23 

Round  92, Global train loss: 0.290, Global test loss: 1.422, Global test accuracy: 54.42 

Round  93, Train loss: 0.275, Test loss: 0.543, Test accuracy: 82.83 

Round  93, Global train loss: 0.275, Global test loss: 1.625, Global test accuracy: 54.13 

Round  94, Train loss: 0.255, Test loss: 0.558, Test accuracy: 82.28 

Round  94, Global train loss: 0.255, Global test loss: 1.591, Global test accuracy: 53.08 

Round  95, Train loss: 0.242, Test loss: 0.554, Test accuracy: 81.97 

Round  95, Global train loss: 0.242, Global test loss: 1.670, Global test accuracy: 53.40 

Round  96, Train loss: 0.239, Test loss: 0.555, Test accuracy: 82.18 

Round  96, Global train loss: 0.239, Global test loss: 1.674, Global test accuracy: 55.43 

Round  97, Train loss: 0.216, Test loss: 0.557, Test accuracy: 82.33 

Round  97, Global train loss: 0.216, Global test loss: 1.648, Global test accuracy: 57.77 

Round  98, Train loss: 0.244, Test loss: 0.564, Test accuracy: 82.25 

Round  98, Global train loss: 0.244, Global test loss: 1.704, Global test accuracy: 52.78 

Round  99, Train loss: 0.197, Test loss: 0.537, Test accuracy: 82.85 

Round  99, Global train loss: 0.197, Global test loss: 1.406, Global test accuracy: 58.40 

Final Round, Train loss: 0.196, Test loss: 0.605, Test accuracy: 81.57 

Final Round, Global train loss: 0.196, Global test loss: 1.406, Global test accuracy: 58.40 

Average accuracy final 10 rounds: 82.21499999999999 

Average global accuracy final 10 rounds: 55.27166666666666 

1075.1793167591095
[3.2114694118499756, 4.2924535274505615, 5.373516321182251, 6.4741740226745605, 7.552062511444092, 8.633957862854004, 9.713176250457764, 10.793668508529663, 11.878883838653564, 12.957862615585327, 14.035245895385742, 15.115078449249268, 16.194242238998413, 17.27169108390808, 18.345867156982422, 19.423032522201538, 20.501981735229492, 21.579402208328247, 22.654887199401855, 23.73195457458496, 24.850757598876953, 25.971784353256226, 27.08864188194275, 28.197476387023926, 29.27060627937317, 30.364463329315186, 31.437624216079712, 32.512805223464966, 33.58776521682739, 34.67005205154419, 35.74557328224182, 36.8348433971405, 37.931843757629395, 39.021631717681885, 40.287243604660034, 41.5051589012146, 42.72014331817627, 43.79429626464844, 44.94413685798645, 46.089592695236206, 47.209067583084106, 48.32662057876587, 49.44969367980957, 50.5711305141449, 51.68964600563049, 52.80580401420593, 53.88189220428467, 54.95623779296875, 56.0280647277832, 57.10725402832031, 58.19167733192444, 59.267322301864624, 60.340545654296875, 61.425623416900635, 62.501197814941406, 63.57340955734253, 64.64739227294922, 65.71794986724854, 66.924556016922, 68.1372139453888, 69.35131669044495, 70.56930708885193, 71.69952130317688, 72.84133958816528, 73.97300410270691, 75.10121464729309, 76.21571326255798, 77.28454566001892, 78.35232782363892, 79.42059922218323, 80.48902463912964, 81.56480765342712, 82.63484239578247, 83.71296906471252, 84.78551983833313, 85.8524079322815, 86.92151808738708, 87.98889541625977, 89.05711960792542, 90.12828850746155, 91.19700121879578, 92.26526260375977, 93.34427809715271, 94.41612482070923, 95.48977088928223, 96.56423377990723, 97.63612627983093, 98.56351113319397, 99.47833895683289, 100.3352038860321, 101.395911693573, 102.47425699234009, 103.54455327987671, 104.61060881614685, 105.67783045768738, 106.74699306488037, 107.82579636573792, 108.8960816860199, 109.96537041664124, 111.03061389923096, 113.27292251586914]
[23.366666666666667, 38.53333333333333, 43.05, 49.46666666666667, 50.43333333333333, 57.65, 60.233333333333334, 65.81666666666666, 66.43333333333334, 70.58333333333333, 71.38333333333334, 71.56666666666666, 72.41666666666667, 72.1, 73.11666666666666, 73.55, 74.08333333333333, 74.65, 74.7, 74.93333333333334, 74.68333333333334, 75.08333333333333, 75.55, 75.55, 75.58333333333333, 76.45, 76.73333333333333, 76.81666666666666, 77.36666666666666, 77.35, 77.63333333333334, 77.75, 78.26666666666667, 78.16666666666667, 77.58333333333333, 77.86666666666666, 78.6, 79.43333333333334, 78.85, 78.88333333333334, 78.95, 78.36666666666666, 78.08333333333333, 77.48333333333333, 78.5, 78.93333333333334, 79.31666666666666, 79.41666666666667, 79.61666666666666, 79.41666666666667, 79.61666666666666, 79.15, 79.11666666666666, 80.31666666666666, 80.03333333333333, 79.9, 79.95, 79.9, 79.91666666666667, 80.36666666666666, 79.8, 80.48333333333333, 80.88333333333334, 81.38333333333334, 81.78333333333333, 81.86666666666666, 81.18333333333334, 81.33333333333333, 81.31666666666666, 81.5, 81.18333333333334, 81.3, 81.4, 80.61666666666666, 80.73333333333333, 81.28333333333333, 81.18333333333334, 81.41666666666667, 80.93333333333334, 81.18333333333334, 81.41666666666667, 81.25, 81.31666666666666, 81.23333333333333, 81.11666666666666, 81.38333333333334, 81.53333333333333, 81.6, 81.98333333333333, 81.71666666666667, 81.65, 81.56666666666666, 82.23333333333333, 82.83333333333333, 82.28333333333333, 81.96666666666667, 82.18333333333334, 82.33333333333333, 82.25, 82.85, 81.56666666666666]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.603, Test loss: 2.496, Test accuracy: 19.00 

Round   1, Train loss: 1.063, Test loss: 1.789, Test accuracy: 34.83 

Round   2, Train loss: 0.946, Test loss: 1.548, Test accuracy: 40.10 

Round   3, Train loss: 0.899, Test loss: 1.274, Test accuracy: 47.75 

Round   4, Train loss: 0.860, Test loss: 1.234, Test accuracy: 48.73 

Round   5, Train loss: 0.847, Test loss: 1.017, Test accuracy: 55.15 

Round   6, Train loss: 0.790, Test loss: 0.972, Test accuracy: 55.92 

Round   7, Train loss: 0.749, Test loss: 0.844, Test accuracy: 60.95 

Round   8, Train loss: 0.711, Test loss: 0.815, Test accuracy: 64.78 

Round   9, Train loss: 0.779, Test loss: 0.750, Test accuracy: 66.82 

Round  10, Train loss: 0.753, Test loss: 0.731, Test accuracy: 67.08 

Round  11, Train loss: 0.722, Test loss: 0.703, Test accuracy: 67.92 

Round  12, Train loss: 0.632, Test loss: 0.690, Test accuracy: 68.48 

Round  13, Train loss: 0.641, Test loss: 0.669, Test accuracy: 69.98 

Round  14, Train loss: 0.657, Test loss: 0.657, Test accuracy: 71.32 

Round  15, Train loss: 0.596, Test loss: 0.659, Test accuracy: 70.65 

Round  16, Train loss: 0.546, Test loss: 0.657, Test accuracy: 71.32 

Round  17, Train loss: 0.661, Test loss: 0.649, Test accuracy: 71.08 

Round  18, Train loss: 0.669, Test loss: 0.639, Test accuracy: 71.87 

Round  19, Train loss: 0.516, Test loss: 0.633, Test accuracy: 71.98 

Round  20, Train loss: 0.537, Test loss: 0.628, Test accuracy: 71.88 

Round  21, Train loss: 0.663, Test loss: 0.612, Test accuracy: 72.65 

Round  22, Train loss: 0.622, Test loss: 0.599, Test accuracy: 74.08 

Round  23, Train loss: 0.494, Test loss: 0.609, Test accuracy: 73.45 

Round  24, Train loss: 0.606, Test loss: 0.601, Test accuracy: 73.80 

Round  25, Train loss: 0.641, Test loss: 0.602, Test accuracy: 73.80 

Round  26, Train loss: 0.659, Test loss: 0.596, Test accuracy: 74.12 

Round  27, Train loss: 0.613, Test loss: 0.582, Test accuracy: 74.68 

Round  28, Train loss: 0.620, Test loss: 0.572, Test accuracy: 75.18 

Round  29, Train loss: 0.572, Test loss: 0.569, Test accuracy: 75.12 

Round  30, Train loss: 0.500, Test loss: 0.579, Test accuracy: 74.22 

Round  31, Train loss: 0.569, Test loss: 0.572, Test accuracy: 74.67 

Round  32, Train loss: 0.603, Test loss: 0.558, Test accuracy: 75.75 

Round  33, Train loss: 0.580, Test loss: 0.553, Test accuracy: 76.70 

Round  34, Train loss: 0.513, Test loss: 0.556, Test accuracy: 76.62 

Round  35, Train loss: 0.498, Test loss: 0.560, Test accuracy: 75.73 

Round  36, Train loss: 0.555, Test loss: 0.539, Test accuracy: 76.75 

Round  37, Train loss: 0.487, Test loss: 0.532, Test accuracy: 77.20 

Round  38, Train loss: 0.488, Test loss: 0.541, Test accuracy: 77.20 

Round  39, Train loss: 0.505, Test loss: 0.530, Test accuracy: 77.68 

Round  40, Train loss: 0.425, Test loss: 0.524, Test accuracy: 78.22 

Round  41, Train loss: 0.573, Test loss: 0.518, Test accuracy: 77.88 

Round  42, Train loss: 0.446, Test loss: 0.526, Test accuracy: 77.73 

Round  43, Train loss: 0.488, Test loss: 0.515, Test accuracy: 78.57 

Round  44, Train loss: 0.508, Test loss: 0.524, Test accuracy: 77.78 

Round  45, Train loss: 0.483, Test loss: 0.528, Test accuracy: 78.02 

Round  46, Train loss: 0.564, Test loss: 0.525, Test accuracy: 78.25 

Round  47, Train loss: 0.458, Test loss: 0.508, Test accuracy: 78.63 

Round  48, Train loss: 0.449, Test loss: 0.503, Test accuracy: 79.17 

Round  49, Train loss: 0.426, Test loss: 0.502, Test accuracy: 78.93 

Round  50, Train loss: 0.422, Test loss: 0.495, Test accuracy: 79.30 

Round  51, Train loss: 0.539, Test loss: 0.484, Test accuracy: 79.82 

Round  52, Train loss: 0.443, Test loss: 0.496, Test accuracy: 79.62 

Round  53, Train loss: 0.465, Test loss: 0.492, Test accuracy: 79.90 

Round  54, Train loss: 0.386, Test loss: 0.485, Test accuracy: 79.97 

Round  55, Train loss: 0.424, Test loss: 0.490, Test accuracy: 79.97 

Round  56, Train loss: 0.525, Test loss: 0.493, Test accuracy: 79.40 

Round  57, Train loss: 0.380, Test loss: 0.492, Test accuracy: 79.35 

Round  58, Train loss: 0.497, Test loss: 0.475, Test accuracy: 80.33 

Round  59, Train loss: 0.350, Test loss: 0.474, Test accuracy: 80.57 

Round  60, Train loss: 0.503, Test loss: 0.472, Test accuracy: 80.85 

Round  61, Train loss: 0.475, Test loss: 0.478, Test accuracy: 80.70 

Round  62, Train loss: 0.422, Test loss: 0.480, Test accuracy: 80.62 

Round  63, Train loss: 0.444, Test loss: 0.479, Test accuracy: 80.63 

Round  64, Train loss: 0.358, Test loss: 0.482, Test accuracy: 80.33 

Round  65, Train loss: 0.316, Test loss: 0.477, Test accuracy: 80.87 

Round  66, Train loss: 0.368, Test loss: 0.470, Test accuracy: 81.28 

Round  67, Train loss: 0.410, Test loss: 0.468, Test accuracy: 81.17 

Round  68, Train loss: 0.391, Test loss: 0.472, Test accuracy: 80.72 

Round  69, Train loss: 0.395, Test loss: 0.464, Test accuracy: 80.97 

Round  70, Train loss: 0.364, Test loss: 0.469, Test accuracy: 81.47 

Round  71, Train loss: 0.324, Test loss: 0.462, Test accuracy: 81.30 

Round  72, Train loss: 0.403, Test loss: 0.468, Test accuracy: 81.65 

Round  73, Train loss: 0.344, Test loss: 0.455, Test accuracy: 82.00 

Round  74, Train loss: 0.371, Test loss: 0.455, Test accuracy: 81.65 

Round  75, Train loss: 0.339, Test loss: 0.462, Test accuracy: 81.83 

Round  76, Train loss: 0.366, Test loss: 0.464, Test accuracy: 81.53 

Round  77, Train loss: 0.432, Test loss: 0.462, Test accuracy: 81.67 

Round  78, Train loss: 0.338, Test loss: 0.462, Test accuracy: 81.32 

Round  79, Train loss: 0.357, Test loss: 0.473, Test accuracy: 80.82 

Round  80, Train loss: 0.470, Test loss: 0.464, Test accuracy: 81.83 

Round  81, Train loss: 0.312, Test loss: 0.459, Test accuracy: 81.90 

Round  82, Train loss: 0.296, Test loss: 0.467, Test accuracy: 81.57 

Round  83, Train loss: 0.422, Test loss: 0.459, Test accuracy: 81.97 

Round  84, Train loss: 0.409, Test loss: 0.456, Test accuracy: 81.60 

Round  85, Train loss: 0.349, Test loss: 0.460, Test accuracy: 82.08 

Round  86, Train loss: 0.297, Test loss: 0.453, Test accuracy: 81.88 

Round  87, Train loss: 0.303, Test loss: 0.456, Test accuracy: 82.02 

Round  88, Train loss: 0.381, Test loss: 0.452, Test accuracy: 82.27 

Round  89, Train loss: 0.322, Test loss: 0.464, Test accuracy: 81.87 

Round  90, Train loss: 0.352, Test loss: 0.461, Test accuracy: 81.87 

Round  91, Train loss: 0.384, Test loss: 0.455, Test accuracy: 81.73 

Round  92, Train loss: 0.283, Test loss: 0.469, Test accuracy: 81.02 

Round  93, Train loss: 0.370, Test loss: 0.455, Test accuracy: 82.00 

Round  94, Train loss: 0.301, Test loss: 0.456, Test accuracy: 82.30 

Round  95, Train loss: 0.291, Test loss: 0.451, Test accuracy: 82.17 

Round  96, Train loss: 0.330, Test loss: 0.455, Test accuracy: 82.23 

Round  97, Train loss: 0.265, Test loss: 0.454, Test accuracy: 82.12 

Round  98, Train loss: 0.339, Test loss: 0.451, Test accuracy: 82.62 

Round  99, Train loss: 0.340, Test loss: 0.450, Test accuracy: 82.62 

Final Round, Train loss: 0.274, Test loss: 0.457, Test accuracy: 82.47 

Average accuracy final 10 rounds: 82.06666666666666 

801.2026379108429
[3.1542108058929443, 4.221270799636841, 5.293199062347412, 6.36148476600647, 7.425323963165283, 8.492478370666504, 9.527760744094849, 10.455745220184326, 11.429325580596924, 12.37138295173645, 13.352102041244507, 14.319225788116455, 15.266190528869629, 16.23149299621582, 17.201550483703613, 18.153731107711792, 19.122763872146606, 20.05929660797119, 21.003143548965454, 21.979703426361084, 22.95346236228943, 23.897319316864014, 24.84037184715271, 25.95660710334778, 27.02653431892395, 28.096544981002808, 29.16718578338623, 30.244066953659058, 31.191632747650146, 32.12947869300842, 33.080137968063354, 34.039674043655396, 34.97634267807007, 35.92008447647095, 36.85834050178528, 37.80962419509888, 38.75023627281189, 39.81727337837219, 40.88648843765259, 41.956279039382935, 43.02390813827515, 44.09394454956055, 45.16424226760864, 46.106812715530396, 47.04575228691101, 47.98428654670715, 48.92412877082825, 49.865612506866455, 50.80269742012024, 51.74350047111511, 52.69025993347168, 53.62355017662048, 54.556979179382324, 55.488022565841675, 56.42336845397949, 57.35595464706421, 58.292707204818726, 59.22952628135681, 60.16327881813049, 61.097792625427246, 62.03481197357178, 62.9689576625824, 63.90059041976929, 64.83199882507324, 65.78598213195801, 66.75561141967773, 67.72559118270874, 68.69831466674805, 69.69028782844543, 70.62527179718018, 71.5676200389862, 72.51065945625305, 73.44592213630676, 74.3644630908966, 75.22719717025757, 76.24025678634644, 77.22790503501892, 78.20093083381653, 79.16773700714111, 80.14257216453552, 81.1187891960144, 82.05054640769958, 82.98239088058472, 83.91244053840637, 84.84726023674011, 85.77930784225464, 86.71710062026978, 87.6565899848938, 88.59482431411743, 89.52748203277588, 90.46081185340881, 91.3938536643982, 92.32966661453247, 93.26833510398865, 94.20444369316101, 95.14081716537476, 96.07682538032532, 97.00954985618591, 97.94541215896606, 98.88173651695251, 100.39742612838745]
[19.0, 34.833333333333336, 40.1, 47.75, 48.733333333333334, 55.15, 55.916666666666664, 60.95, 64.78333333333333, 66.81666666666666, 67.08333333333333, 67.91666666666667, 68.48333333333333, 69.98333333333333, 71.31666666666666, 70.65, 71.31666666666666, 71.08333333333333, 71.86666666666666, 71.98333333333333, 71.88333333333334, 72.65, 74.08333333333333, 73.45, 73.8, 73.8, 74.11666666666666, 74.68333333333334, 75.18333333333334, 75.11666666666666, 74.21666666666667, 74.66666666666667, 75.75, 76.7, 76.61666666666666, 75.73333333333333, 76.75, 77.2, 77.2, 77.68333333333334, 78.21666666666667, 77.88333333333334, 77.73333333333333, 78.56666666666666, 77.78333333333333, 78.01666666666667, 78.25, 78.63333333333334, 79.16666666666667, 78.93333333333334, 79.3, 79.81666666666666, 79.61666666666666, 79.9, 79.96666666666667, 79.96666666666667, 79.4, 79.35, 80.33333333333333, 80.56666666666666, 80.85, 80.7, 80.61666666666666, 80.63333333333334, 80.33333333333333, 80.86666666666666, 81.28333333333333, 81.16666666666667, 80.71666666666667, 80.96666666666667, 81.46666666666667, 81.3, 81.65, 82.0, 81.65, 81.83333333333333, 81.53333333333333, 81.66666666666667, 81.31666666666666, 80.81666666666666, 81.83333333333333, 81.9, 81.56666666666666, 81.96666666666667, 81.6, 82.08333333333333, 81.88333333333334, 82.01666666666667, 82.26666666666667, 81.86666666666666, 81.86666666666666, 81.73333333333333, 81.01666666666667, 82.0, 82.3, 82.16666666666667, 82.23333333333333, 82.11666666666666, 82.61666666666666, 82.61666666666666, 82.46666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Traceback (most recent call last):
  File "main_fedpac.py", line 229, in <module>
    w_local, loss, indd, class_center_local, class_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 1255, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 57580 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
Traceback (most recent call last):
  File "main_ditto.py", line 182, in <module>
    w_k, loss, indd = local.train(net=net_global.to(args.device), idx=idx, lr=args.lr, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 488, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 58293 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
Traceback (most recent call last):
  File "main_apfl.py", line 147, in <module>
    w_global, w_local, loss, indd = local.train(net=net_local.to(args.device),w_local=w_local, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 354, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 54998 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Traceback (most recent call last):
  File "main_scaffold.py", line 150, in <module>
    w_local, loss, indd, count = local.train(net=net_local.to(args.device), idx=idx, lr=lr, c_list=c_list, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 237, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 53429 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_pfedme.py", line 236, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx],w_locals = w_locals)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 808, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 57612 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.189, Test loss: 2.026, Test accuracy: 22.17 

Round   0, Global train loss: 1.189, Global test loss: 2.337, Global test accuracy: 13.33 

Round   1, Train loss: 0.989, Test loss: 1.578, Test accuracy: 36.25 

Round   1, Global train loss: 0.989, Global test loss: 2.183, Global test accuracy: 18.53 

Round   2, Train loss: 0.869, Test loss: 1.487, Test accuracy: 42.63 

Round   2, Global train loss: 0.869, Global test loss: 2.199, Global test accuracy: 27.33 

Round   3, Train loss: 0.812, Test loss: 1.440, Test accuracy: 44.48 

Round   3, Global train loss: 0.812, Global test loss: 2.250, Global test accuracy: 21.72 

Round   4, Train loss: 0.817, Test loss: 1.120, Test accuracy: 54.35 

Round   4, Global train loss: 0.817, Global test loss: 2.171, Global test accuracy: 22.23 

Round   5, Train loss: 0.762, Test loss: 1.046, Test accuracy: 56.18 

Round   5, Global train loss: 0.762, Global test loss: 2.241, Global test accuracy: 25.45 

Round   6, Train loss: 0.817, Test loss: 0.919, Test accuracy: 60.20 

Round   6, Global train loss: 0.817, Global test loss: 2.051, Global test accuracy: 26.32 

Round   7, Train loss: 0.713, Test loss: 0.928, Test accuracy: 59.43 

Round   7, Global train loss: 0.713, Global test loss: 2.141, Global test accuracy: 27.27 

Round   8, Train loss: 0.833, Test loss: 0.859, Test accuracy: 61.07 

Round   8, Global train loss: 0.833, Global test loss: 2.124, Global test accuracy: 25.70 

Round   9, Train loss: 0.800, Test loss: 0.786, Test accuracy: 64.98 

Round   9, Global train loss: 0.800, Global test loss: 2.228, Global test accuracy: 15.40 

Round  10, Train loss: 0.779, Test loss: 0.787, Test accuracy: 65.18 

Round  10, Global train loss: 0.779, Global test loss: 2.210, Global test accuracy: 12.78 

Round  11, Train loss: 0.683, Test loss: 0.778, Test accuracy: 66.32 

Round  11, Global train loss: 0.683, Global test loss: 2.143, Global test accuracy: 23.90 

Round  12, Train loss: 0.633, Test loss: 0.772, Test accuracy: 66.18 

Round  12, Global train loss: 0.633, Global test loss: 2.339, Global test accuracy: 20.32 

Round  13, Train loss: 0.718, Test loss: 0.757, Test accuracy: 67.52 

Round  13, Global train loss: 0.718, Global test loss: 2.088, Global test accuracy: 25.67 

Round  14, Train loss: 0.578, Test loss: 0.734, Test accuracy: 68.60 

Round  14, Global train loss: 0.578, Global test loss: 2.370, Global test accuracy: 27.87 

Round  15, Train loss: 0.688, Test loss: 0.716, Test accuracy: 69.97 

Round  15, Global train loss: 0.688, Global test loss: 2.109, Global test accuracy: 22.25 

Round  16, Train loss: 0.620, Test loss: 0.723, Test accuracy: 69.93 

Round  16, Global train loss: 0.620, Global test loss: 2.120, Global test accuracy: 24.52 

Round  17, Train loss: 0.654, Test loss: 0.737, Test accuracy: 69.90 

Round  17, Global train loss: 0.654, Global test loss: 2.376, Global test accuracy: 19.73 

Round  18, Train loss: 0.666, Test loss: 0.735, Test accuracy: 69.83 

Round  18, Global train loss: 0.666, Global test loss: 2.146, Global test accuracy: 22.02 

Round  19, Train loss: 0.647, Test loss: 0.749, Test accuracy: 69.43 

Round  19, Global train loss: 0.647, Global test loss: 2.451, Global test accuracy: 18.05 

Round  20, Train loss: 0.588, Test loss: 0.740, Test accuracy: 70.35 

Round  20, Global train loss: 0.588, Global test loss: 2.121, Global test accuracy: 20.80 

Round  21, Train loss: 0.615, Test loss: 0.739, Test accuracy: 70.33 

Round  21, Global train loss: 0.615, Global test loss: 2.097, Global test accuracy: 19.02 

Round  22, Train loss: 0.588, Test loss: 0.749, Test accuracy: 70.50 

Round  22, Global train loss: 0.588, Global test loss: 2.095, Global test accuracy: 27.43 

Round  23, Train loss: 0.497, Test loss: 0.749, Test accuracy: 70.82 

Round  23, Global train loss: 0.497, Global test loss: 2.082, Global test accuracy: 26.28 

Round  24, Train loss: 0.588, Test loss: 0.754, Test accuracy: 70.83 

Round  24, Global train loss: 0.588, Global test loss: 2.112, Global test accuracy: 25.22 

Round  25, Train loss: 0.479, Test loss: 0.737, Test accuracy: 71.97 

Round  25, Global train loss: 0.479, Global test loss: 2.256, Global test accuracy: 23.37 

Round  26, Train loss: 0.381, Test loss: 0.733, Test accuracy: 72.07 

Round  26, Global train loss: 0.381, Global test loss: 2.048, Global test accuracy: 29.88 

Round  27, Train loss: 0.465, Test loss: 0.718, Test accuracy: 72.85 

Round  27, Global train loss: 0.465, Global test loss: 2.038, Global test accuracy: 25.38 

Round  28, Train loss: 0.478, Test loss: 0.731, Test accuracy: 72.57 

Round  28, Global train loss: 0.478, Global test loss: 2.284, Global test accuracy: 17.83 

Round  29, Train loss: 0.462, Test loss: 0.730, Test accuracy: 73.05 

Round  29, Global train loss: 0.462, Global test loss: 2.133, Global test accuracy: 25.78 

Round  30, Train loss: 0.461, Test loss: 0.712, Test accuracy: 73.40 

Round  30, Global train loss: 0.461, Global test loss: 2.203, Global test accuracy: 20.17 

Round  31, Train loss: 0.500, Test loss: 0.720, Test accuracy: 73.45 

Round  31, Global train loss: 0.500, Global test loss: 2.202, Global test accuracy: 13.75 

Round  32, Train loss: 0.371, Test loss: 0.733, Test accuracy: 72.80 

Round  32, Global train loss: 0.371, Global test loss: 2.029, Global test accuracy: 30.75 

Round  33, Train loss: 0.346, Test loss: 0.744, Test accuracy: 72.85 

Round  33, Global train loss: 0.346, Global test loss: 2.004, Global test accuracy: 27.30 

Round  34, Train loss: 0.421, Test loss: 0.750, Test accuracy: 72.87 

Round  34, Global train loss: 0.421, Global test loss: 2.201, Global test accuracy: 19.68 

Round  35, Train loss: 0.326, Test loss: 0.757, Test accuracy: 72.88 

Round  35, Global train loss: 0.326, Global test loss: 2.118, Global test accuracy: 24.80 

Round  36, Train loss: 0.390, Test loss: 0.756, Test accuracy: 73.05 

Round  36, Global train loss: 0.390, Global test loss: 2.126, Global test accuracy: 15.15 

Round  37, Train loss: 0.337, Test loss: 0.776, Test accuracy: 72.75 

Round  37, Global train loss: 0.337, Global test loss: 2.216, Global test accuracy: 27.62 

Round  38, Train loss: 0.391, Test loss: 0.779, Test accuracy: 72.95 

Round  38, Global train loss: 0.391, Global test loss: 2.629, Global test accuracy: 24.48 

Round  39, Train loss: 0.288, Test loss: 0.790, Test accuracy: 73.28 

Round  39, Global train loss: 0.288, Global test loss: 2.127, Global test accuracy: 31.48 

Round  40, Train loss: 0.340, Test loss: 0.821, Test accuracy: 72.88 

Round  40, Global train loss: 0.340, Global test loss: 2.200, Global test accuracy: 23.25 

Round  41, Train loss: 0.308, Test loss: 0.786, Test accuracy: 74.18 

Round  41, Global train loss: 0.308, Global test loss: 2.163, Global test accuracy: 21.47 

Round  42, Train loss: 0.297, Test loss: 0.780, Test accuracy: 74.83 

Round  42, Global train loss: 0.297, Global test loss: 2.338, Global test accuracy: 26.35 

Round  43, Train loss: 0.286, Test loss: 0.792, Test accuracy: 74.42 

Round  43, Global train loss: 0.286, Global test loss: 2.528, Global test accuracy: 23.32 

Round  44, Train loss: 0.287, Test loss: 0.805, Test accuracy: 74.20 

Round  44, Global train loss: 0.287, Global test loss: 2.060, Global test accuracy: 30.93 

Round  45, Train loss: 0.282, Test loss: 0.819, Test accuracy: 73.65 

Round  45, Global train loss: 0.282, Global test loss: 2.233, Global test accuracy: 27.88 

Round  46, Train loss: 0.253, Test loss: 0.815, Test accuracy: 74.17 

Round  46, Global train loss: 0.253, Global test loss: 1.956, Global test accuracy: 28.28 

Round  47, Train loss: 0.258, Test loss: 0.835, Test accuracy: 73.82 

Round  47, Global train loss: 0.258, Global test loss: 2.277, Global test accuracy: 25.35 

Round  48, Train loss: 0.244, Test loss: 0.829, Test accuracy: 74.28 

Round  48, Global train loss: 0.244, Global test loss: 2.178, Global test accuracy: 26.77 

Round  49, Train loss: 0.268, Test loss: 0.873, Test accuracy: 74.22 

Round  49, Global train loss: 0.268, Global test loss: 2.108, Global test accuracy: 22.43 

Round  50, Train loss: 0.236, Test loss: 0.900, Test accuracy: 73.88 

Round  50, Global train loss: 0.236, Global test loss: 1.981, Global test accuracy: 25.72 

Round  51, Train loss: 0.196, Test loss: 0.878, Test accuracy: 74.63 

Round  51, Global train loss: 0.196, Global test loss: 1.997, Global test accuracy: 25.45 

Round  52, Train loss: 0.205, Test loss: 0.843, Test accuracy: 74.43 

Round  52, Global train loss: 0.205, Global test loss: 2.066, Global test accuracy: 27.10 

Round  53, Train loss: 0.236, Test loss: 0.876, Test accuracy: 74.02 

Round  53, Global train loss: 0.236, Global test loss: 2.031, Global test accuracy: 32.45 

Round  54, Train loss: 0.234, Test loss: 0.878, Test accuracy: 74.38 

Round  54, Global train loss: 0.234, Global test loss: 2.186, Global test accuracy: 24.15 

Round  55, Train loss: 0.193, Test loss: 0.921, Test accuracy: 73.87 

Round  55, Global train loss: 0.193, Global test loss: 2.340, Global test accuracy: 23.43 

Round  56, Train loss: 0.162, Test loss: 0.887, Test accuracy: 74.65 

Round  56, Global train loss: 0.162, Global test loss: 1.935, Global test accuracy: 30.05 

Round  57, Train loss: 0.134, Test loss: 0.886, Test accuracy: 74.55 

Round  57, Global train loss: 0.134, Global test loss: 2.090, Global test accuracy: 18.43 

Round  58, Train loss: 0.182, Test loss: 0.916, Test accuracy: 74.40 

Round  58, Global train loss: 0.182, Global test loss: 2.108, Global test accuracy: 29.20 

Round  59, Train loss: 0.201, Test loss: 0.916, Test accuracy: 74.38 

Round  59, Global train loss: 0.201, Global test loss: 2.117, Global test accuracy: 27.58 

Round  60, Train loss: 0.174, Test loss: 0.932, Test accuracy: 74.82 

Round  60, Global train loss: 0.174, Global test loss: 2.061, Global test accuracy: 26.47 

Round  61, Train loss: 0.170, Test loss: 0.943, Test accuracy: 74.80 

Round  61, Global train loss: 0.170, Global test loss: 2.039, Global test accuracy: 31.17 

Round  62, Train loss: 0.190, Test loss: 0.948, Test accuracy: 74.80 

Round  62, Global train loss: 0.190, Global test loss: 1.970, Global test accuracy: 35.95 

Round  63, Train loss: 0.182, Test loss: 0.957, Test accuracy: 74.63 

Round  63, Global train loss: 0.182, Global test loss: 2.126, Global test accuracy: 26.62 

Round  64, Train loss: 0.137, Test loss: 0.980, Test accuracy: 74.57 

Round  64, Global train loss: 0.137, Global test loss: 2.354, Global test accuracy: 22.90 

Round  65, Train loss: 0.172, Test loss: 0.973, Test accuracy: 74.42 

Round  65, Global train loss: 0.172, Global test loss: 2.099, Global test accuracy: 25.88 

Round  66, Train loss: 0.099, Test loss: 1.024, Test accuracy: 74.12 

Round  66, Global train loss: 0.099, Global test loss: 2.164, Global test accuracy: 26.40 

Round  67, Train loss: 0.141, Test loss: 1.051, Test accuracy: 74.42 

Round  67, Global train loss: 0.141, Global test loss: 2.383, Global test accuracy: 28.63 

Round  68, Train loss: 0.174, Test loss: 1.030, Test accuracy: 74.63 

Round  68, Global train loss: 0.174, Global test loss: 2.051, Global test accuracy: 30.93 

Round  69, Train loss: 0.140, Test loss: 1.044, Test accuracy: 74.53 

Round  69, Global train loss: 0.140, Global test loss: 2.553, Global test accuracy: 25.05 

Round  70, Train loss: 0.173, Test loss: 1.054, Test accuracy: 74.12 

Round  70, Global train loss: 0.173, Global test loss: 2.147, Global test accuracy: 20.00 

Round  71, Train loss: 0.129, Test loss: 1.062, Test accuracy: 74.43 

Round  71, Global train loss: 0.129, Global test loss: 2.799, Global test accuracy: 21.20 

Round  72, Train loss: 0.150, Test loss: 1.064, Test accuracy: 74.32 

Round  72, Global train loss: 0.150, Global test loss: 2.115, Global test accuracy: 28.83 

Round  73, Train loss: 0.111, Test loss: 1.071, Test accuracy: 74.17 

Round  73, Global train loss: 0.111, Global test loss: 2.025, Global test accuracy: 27.75 

Round  74, Train loss: 0.099, Test loss: 1.067, Test accuracy: 74.37 

Round  74, Global train loss: 0.099, Global test loss: 2.082, Global test accuracy: 26.35 

Round  75, Train loss: 0.154, Test loss: 1.108, Test accuracy: 74.37 

Round  75, Global train loss: 0.154, Global test loss: 2.232, Global test accuracy: 20.80 

Round  76, Train loss: 0.081, Test loss: 1.128, Test accuracy: 74.63 

Round  76, Global train loss: 0.081, Global test loss: 2.112, Global test accuracy: 26.35 

Round  77, Train loss: 0.150, Test loss: 1.108, Test accuracy: 74.73 

Round  77, Global train loss: 0.150, Global test loss: 2.162, Global test accuracy: 17.80 

Round  78, Train loss: 0.138, Test loss: 1.133, Test accuracy: 74.93 

Round  78, Global train loss: 0.138, Global test loss: 2.424, Global test accuracy: 25.48 

Round  79, Train loss: 0.088, Test loss: 1.146, Test accuracy: 75.08 

Round  79, Global train loss: 0.088, Global test loss: 2.009, Global test accuracy: 28.78 

Round  80, Train loss: 0.096, Test loss: 1.149, Test accuracy: 75.13 

Round  80, Global train loss: 0.096, Global test loss: 2.063, Global test accuracy: 25.12 

Round  81, Train loss: 0.146, Test loss: 1.146, Test accuracy: 74.83 

Round  81, Global train loss: 0.146, Global test loss: 2.191, Global test accuracy: 28.18 

Round  82, Train loss: 0.090, Test loss: 1.128, Test accuracy: 75.08 

Round  82, Global train loss: 0.090, Global test loss: 1.973, Global test accuracy: 32.17 

Round  83, Train loss: 0.108, Test loss: 1.126, Test accuracy: 74.70 

Round  83, Global train loss: 0.108, Global test loss: 1.965, Global test accuracy: 33.75 

Round  84, Train loss: 0.096, Test loss: 1.171, Test accuracy: 74.78 

Round  84, Global train loss: 0.096, Global test loss: 2.027, Global test accuracy: 21.58 

Round  85, Train loss: 0.099, Test loss: 1.161, Test accuracy: 74.80 

Round  85, Global train loss: 0.099, Global test loss: 2.161, Global test accuracy: 29.20 

Round  86, Train loss: 0.055, Test loss: 1.171, Test accuracy: 74.30 

Round  86, Global train loss: 0.055, Global test loss: 2.114, Global test accuracy: 27.75 

Round  87, Train loss: 0.103, Test loss: 1.188, Test accuracy: 74.00 

Round  87, Global train loss: 0.103, Global test loss: 2.150, Global test accuracy: 24.35 

Round  88, Train loss: 0.092, Test loss: 1.217, Test accuracy: 73.73 

Round  88, Global train loss: 0.092, Global test loss: 2.552, Global test accuracy: 20.07 

Round  89, Train loss: 0.074, Test loss: 1.218, Test accuracy: 74.05 

Round  89, Global train loss: 0.074, Global test loss: 2.035, Global test accuracy: 29.38 

Round  90, Train loss: 0.061, Test loss: 1.237, Test accuracy: 73.75 

Round  90, Global train loss: 0.061, Global test loss: 2.018, Global test accuracy: 27.37 

Round  91, Train loss: 0.069, Test loss: 1.260, Test accuracy: 73.70 

Round  91, Global train loss: 0.069, Global test loss: 2.059, Global test accuracy: 26.82 

Round  92, Train loss: 0.099, Test loss: 1.292, Test accuracy: 74.12 

Round  92, Global train loss: 0.099, Global test loss: 2.183, Global test accuracy: 25.67 

Round  93, Train loss: 0.090, Test loss: 1.287, Test accuracy: 74.30 

Round  93, Global train loss: 0.090, Global test loss: 2.045, Global test accuracy: 24.10 

Round  94, Train loss: 0.103, Test loss: 1.281, Test accuracy: 74.95 

Round  94, Global train loss: 0.103, Global test loss: 2.248, Global test accuracy: 23.53 

Round  95, Train loss: 0.048, Test loss: 1.290, Test accuracy: 75.05 

Round  95, Global train loss: 0.048, Global test loss: 2.301, Global test accuracy: 26.58 

Round  96, Train loss: 0.059, Test loss: 1.301, Test accuracy: 75.22 

Round  96, Global train loss: 0.059, Global test loss: 2.040, Global test accuracy: 28.20 

Round  97, Train loss: 0.065, Test loss: 1.303, Test accuracy: 75.12 

Round  97, Global train loss: 0.065, Global test loss: 2.068, Global test accuracy: 27.27 

Round  98, Train loss: 0.068, Test loss: 1.275, Test accuracy: 75.27 

Round  98, Global train loss: 0.068, Global test loss: 2.400, Global test accuracy: 25.62 

Round  99, Train loss: 0.091, Test loss: 1.264, Test accuracy: 75.37 

Round  99, Global train loss: 0.091, Global test loss: 2.435, Global test accuracy: 19.40 

Final Round, Train loss: 0.070, Test loss: 1.360, Test accuracy: 74.37 

Final Round, Global train loss: 0.070, Global test loss: 2.435, Global test accuracy: 19.40 

Average accuracy final 10 rounds: 74.68333333333332 

Average global accuracy final 10 rounds: 25.455000000000002 

1082.2475397586823
[3.229236125946045, 4.370291233062744, 5.517032623291016, 6.650408506393433, 7.79584002494812, 8.892140865325928, 9.988312482833862, 11.074241399765015, 12.16093397140503, 13.252549409866333, 14.393855333328247, 15.486342906951904, 16.576165199279785, 17.672473430633545, 18.836981534957886, 19.918412923812866, 21.00203514099121, 22.086053371429443, 23.16653871536255, 24.246791124343872, 25.32804775238037, 26.40740466117859, 27.492359399795532, 28.587627172470093, 29.6876962184906, 30.77580165863037, 31.86429715156555, 32.957634925842285, 34.04522728919983, 35.135640144348145, 36.222925901412964, 37.31262493133545, 38.40096974372864, 39.490025997161865, 40.57959866523743, 41.66851282119751, 42.763845682144165, 43.85534405708313, 44.94808650016785, 46.04080247879028, 47.129862785339355, 48.220465421676636, 49.308414936065674, 50.39685368537903, 51.484920024871826, 52.50159168243408, 53.640586376190186, 54.727139472961426, 55.82542705535889, 56.91061615943909, 57.98814558982849, 59.06564426422119, 60.144609212875366, 61.22340416908264, 62.30077910423279, 63.38154578208923, 64.4610824584961, 65.54328632354736, 66.61934638023376, 67.6987783908844, 68.78156065940857, 69.88813090324402, 71.0164725780487, 72.09826135635376, 73.1798300743103, 74.2619845867157, 75.34241271018982, 76.42277789115906, 77.508296251297, 78.58877754211426, 79.69510793685913, 80.78861594200134, 81.88004994392395, 82.96234011650085, 84.04669666290283, 85.17499852180481, 86.26177525520325, 87.34685897827148, 88.43074035644531, 89.51481890678406, 90.60336422920227, 91.71000933647156, 92.80090308189392, 93.8993546962738, 94.98512101173401, 96.07175421714783, 97.16281318664551, 98.25462675094604, 99.36917042732239, 100.46435737609863, 101.55184698104858, 102.63918447494507, 103.72548699378967, 104.81500363349915, 105.89953398704529, 106.98369669914246, 108.06783723831177, 109.15232038497925, 110.23658084869385, 111.35442900657654, 113.58173990249634]
[22.166666666666668, 36.25, 42.63333333333333, 44.483333333333334, 54.35, 56.18333333333333, 60.2, 59.43333333333333, 61.06666666666667, 64.98333333333333, 65.18333333333334, 66.31666666666666, 66.18333333333334, 67.51666666666667, 68.6, 69.96666666666667, 69.93333333333334, 69.9, 69.83333333333333, 69.43333333333334, 70.35, 70.33333333333333, 70.5, 70.81666666666666, 70.83333333333333, 71.96666666666667, 72.06666666666666, 72.85, 72.56666666666666, 73.05, 73.4, 73.45, 72.8, 72.85, 72.86666666666666, 72.88333333333334, 73.05, 72.75, 72.95, 73.28333333333333, 72.88333333333334, 74.18333333333334, 74.83333333333333, 74.41666666666667, 74.2, 73.65, 74.16666666666667, 73.81666666666666, 74.28333333333333, 74.21666666666667, 73.88333333333334, 74.63333333333334, 74.43333333333334, 74.01666666666667, 74.38333333333334, 73.86666666666666, 74.65, 74.55, 74.4, 74.38333333333334, 74.81666666666666, 74.8, 74.8, 74.63333333333334, 74.56666666666666, 74.41666666666667, 74.11666666666666, 74.41666666666667, 74.63333333333334, 74.53333333333333, 74.11666666666666, 74.43333333333334, 74.31666666666666, 74.16666666666667, 74.36666666666666, 74.36666666666666, 74.63333333333334, 74.73333333333333, 74.93333333333334, 75.08333333333333, 75.13333333333334, 74.83333333333333, 75.08333333333333, 74.7, 74.78333333333333, 74.8, 74.3, 74.0, 73.73333333333333, 74.05, 73.75, 73.7, 74.11666666666666, 74.3, 74.95, 75.05, 75.21666666666667, 75.11666666666666, 75.26666666666667, 75.36666666666666, 74.36666666666666]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.148, Test loss: 1.871, Test accuracy: 28.52 

Round   0, Global train loss: 1.148, Global test loss: 2.252, Global test accuracy: 17.98 

Round   1, Train loss: 0.973, Test loss: 1.761, Test accuracy: 38.93 

Round   1, Global train loss: 0.973, Global test loss: 2.456, Global test accuracy: 22.63 

Round   2, Train loss: 0.941, Test loss: 1.466, Test accuracy: 43.18 

Round   2, Global train loss: 0.941, Global test loss: 2.108, Global test accuracy: 24.18 

Round   3, Train loss: 0.903, Test loss: 1.327, Test accuracy: 48.15 

Round   3, Global train loss: 0.903, Global test loss: 2.131, Global test accuracy: 26.40 

Round   4, Train loss: 0.847, Test loss: 1.118, Test accuracy: 52.60 

Round   4, Global train loss: 0.847, Global test loss: 1.966, Global test accuracy: 28.97 

Round   5, Train loss: 0.904, Test loss: 1.020, Test accuracy: 56.22 

Round   5, Global train loss: 0.904, Global test loss: 2.133, Global test accuracy: 29.80 

Round   6, Train loss: 0.932, Test loss: 0.970, Test accuracy: 57.77 

Round   6, Global train loss: 0.932, Global test loss: 2.041, Global test accuracy: 23.58 

Round   7, Train loss: 0.795, Test loss: 0.892, Test accuracy: 61.30 

Round   7, Global train loss: 0.795, Global test loss: 2.029, Global test accuracy: 28.63 

Round   8, Train loss: 0.752, Test loss: 0.804, Test accuracy: 64.55 

Round   8, Global train loss: 0.752, Global test loss: 1.994, Global test accuracy: 31.88 

Round   9, Train loss: 0.754, Test loss: 0.796, Test accuracy: 65.23 

Round   9, Global train loss: 0.754, Global test loss: 1.944, Global test accuracy: 34.33 

Round  10, Train loss: 0.818, Test loss: 0.783, Test accuracy: 66.23 

Round  10, Global train loss: 0.818, Global test loss: 1.917, Global test accuracy: 34.33 

Round  11, Train loss: 0.749, Test loss: 0.766, Test accuracy: 67.63 

Round  11, Global train loss: 0.749, Global test loss: 1.872, Global test accuracy: 30.77 

Round  12, Train loss: 0.767, Test loss: 0.758, Test accuracy: 68.17 

Round  12, Global train loss: 0.767, Global test loss: 1.782, Global test accuracy: 34.32 

Round  13, Train loss: 0.781, Test loss: 0.737, Test accuracy: 69.70 

Round  13, Global train loss: 0.781, Global test loss: 1.963, Global test accuracy: 27.60 

Round  14, Train loss: 0.747, Test loss: 0.726, Test accuracy: 69.52 

Round  14, Global train loss: 0.747, Global test loss: 1.629, Global test accuracy: 39.53 

Round  15, Train loss: 0.723, Test loss: 0.716, Test accuracy: 70.55 

Round  15, Global train loss: 0.723, Global test loss: 1.776, Global test accuracy: 36.13 

Round  16, Train loss: 0.721, Test loss: 0.721, Test accuracy: 70.08 

Round  16, Global train loss: 0.721, Global test loss: 1.726, Global test accuracy: 36.30 

Round  17, Train loss: 0.651, Test loss: 0.710, Test accuracy: 70.32 

Round  17, Global train loss: 0.651, Global test loss: 1.799, Global test accuracy: 38.72 

Round  18, Train loss: 0.643, Test loss: 0.684, Test accuracy: 71.80 

Round  18, Global train loss: 0.643, Global test loss: 1.725, Global test accuracy: 38.32 

Round  19, Train loss: 0.642, Test loss: 0.703, Test accuracy: 71.20 

Round  19, Global train loss: 0.642, Global test loss: 1.821, Global test accuracy: 37.08 

Round  20, Train loss: 0.683, Test loss: 0.700, Test accuracy: 71.63 

Round  20, Global train loss: 0.683, Global test loss: 1.628, Global test accuracy: 40.73 

Round  21, Train loss: 0.710, Test loss: 0.695, Test accuracy: 71.83 

Round  21, Global train loss: 0.710, Global test loss: 1.639, Global test accuracy: 41.18 

Round  22, Train loss: 0.656, Test loss: 0.684, Test accuracy: 72.33 

Round  22, Global train loss: 0.656, Global test loss: 1.472, Global test accuracy: 47.37 

Round  23, Train loss: 0.657, Test loss: 0.688, Test accuracy: 71.85 

Round  23, Global train loss: 0.657, Global test loss: 1.582, Global test accuracy: 43.57 

Round  24, Train loss: 0.628, Test loss: 0.685, Test accuracy: 72.08 

Round  24, Global train loss: 0.628, Global test loss: 1.915, Global test accuracy: 36.35 

Round  25, Train loss: 0.558, Test loss: 0.673, Test accuracy: 72.57 

Round  25, Global train loss: 0.558, Global test loss: 1.402, Global test accuracy: 51.35 

Round  26, Train loss: 0.622, Test loss: 0.667, Test accuracy: 72.82 

Round  26, Global train loss: 0.622, Global test loss: 1.408, Global test accuracy: 49.55 

Round  27, Train loss: 0.576, Test loss: 0.674, Test accuracy: 72.50 

Round  27, Global train loss: 0.576, Global test loss: 1.722, Global test accuracy: 41.53 

Round  28, Train loss: 0.534, Test loss: 0.659, Test accuracy: 72.93 

Round  28, Global train loss: 0.534, Global test loss: 1.515, Global test accuracy: 47.42 

Round  29, Train loss: 0.602, Test loss: 0.676, Test accuracy: 72.70 

Round  29, Global train loss: 0.602, Global test loss: 1.715, Global test accuracy: 40.22 

Round  30, Train loss: 0.612, Test loss: 0.675, Test accuracy: 72.93 

Round  30, Global train loss: 0.612, Global test loss: 1.663, Global test accuracy: 43.05 

Round  31, Train loss: 0.527, Test loss: 0.684, Test accuracy: 72.80 

Round  31, Global train loss: 0.527, Global test loss: 1.761, Global test accuracy: 41.33 

Round  32, Train loss: 0.557, Test loss: 0.656, Test accuracy: 74.25 

Round  32, Global train loss: 0.557, Global test loss: 1.819, Global test accuracy: 40.03 

Round  33, Train loss: 0.637, Test loss: 0.660, Test accuracy: 74.38 

Round  33, Global train loss: 0.637, Global test loss: 1.845, Global test accuracy: 40.52 

Round  34, Train loss: 0.485, Test loss: 0.656, Test accuracy: 74.70 

Round  34, Global train loss: 0.485, Global test loss: 1.431, Global test accuracy: 50.95 

Round  35, Train loss: 0.551, Test loss: 0.648, Test accuracy: 74.83 

Round  35, Global train loss: 0.551, Global test loss: 1.471, Global test accuracy: 48.67 

Round  36, Train loss: 0.584, Test loss: 0.637, Test accuracy: 75.23 

Round  36, Global train loss: 0.584, Global test loss: 1.552, Global test accuracy: 47.55 

Round  37, Train loss: 0.551, Test loss: 0.617, Test accuracy: 76.53 

Round  37, Global train loss: 0.551, Global test loss: 1.533, Global test accuracy: 46.10 

Round  38, Train loss: 0.471, Test loss: 0.634, Test accuracy: 76.08 

Round  38, Global train loss: 0.471, Global test loss: 1.615, Global test accuracy: 44.25 

Round  39, Train loss: 0.515, Test loss: 0.629, Test accuracy: 76.08 

Round  39, Global train loss: 0.515, Global test loss: 1.516, Global test accuracy: 47.87 

Round  40, Train loss: 0.521, Test loss: 0.610, Test accuracy: 76.22 

Round  40, Global train loss: 0.521, Global test loss: 1.357, Global test accuracy: 51.32 

Round  41, Train loss: 0.486, Test loss: 0.615, Test accuracy: 76.05 

Round  41, Global train loss: 0.486, Global test loss: 1.410, Global test accuracy: 51.27 

Round  42, Train loss: 0.414, Test loss: 0.633, Test accuracy: 75.77 

Round  42, Global train loss: 0.414, Global test loss: 1.487, Global test accuracy: 50.67 

Round  43, Train loss: 0.504, Test loss: 0.640, Test accuracy: 76.05 

Round  43, Global train loss: 0.504, Global test loss: 1.364, Global test accuracy: 53.28 

Round  44, Train loss: 0.477, Test loss: 0.639, Test accuracy: 76.22 

Round  44, Global train loss: 0.477, Global test loss: 1.697, Global test accuracy: 42.52 

Round  45, Train loss: 0.458, Test loss: 0.619, Test accuracy: 76.45 

Round  45, Global train loss: 0.458, Global test loss: 1.543, Global test accuracy: 48.45 

Round  46, Train loss: 0.451, Test loss: 0.599, Test accuracy: 77.13 

Round  46, Global train loss: 0.451, Global test loss: 1.555, Global test accuracy: 49.52 

Round  47, Train loss: 0.444, Test loss: 0.603, Test accuracy: 77.12 

Round  47, Global train loss: 0.444, Global test loss: 1.408, Global test accuracy: 52.23 

Round  48, Train loss: 0.470, Test loss: 0.609, Test accuracy: 77.13 

Round  48, Global train loss: 0.470, Global test loss: 1.230, Global test accuracy: 57.27 

Round  49, Train loss: 0.396, Test loss: 0.613, Test accuracy: 77.70 

Round  49, Global train loss: 0.396, Global test loss: 1.559, Global test accuracy: 49.93 

Round  50, Train loss: 0.514, Test loss: 0.628, Test accuracy: 77.73 

Round  50, Global train loss: 0.514, Global test loss: 1.314, Global test accuracy: 54.67 

Round  51, Train loss: 0.431, Test loss: 0.628, Test accuracy: 77.35 

Round  51, Global train loss: 0.431, Global test loss: 1.214, Global test accuracy: 58.05 

Round  52, Train loss: 0.454, Test loss: 0.626, Test accuracy: 77.45 

Round  52, Global train loss: 0.454, Global test loss: 1.327, Global test accuracy: 54.75 

Round  53, Train loss: 0.408, Test loss: 0.633, Test accuracy: 76.97 

Round  53, Global train loss: 0.408, Global test loss: 1.342, Global test accuracy: 54.55 

Round  54, Train loss: 0.420, Test loss: 0.633, Test accuracy: 77.17 

Round  54, Global train loss: 0.420, Global test loss: 1.277, Global test accuracy: 56.47 

Round  55, Train loss: 0.376, Test loss: 0.631, Test accuracy: 77.03 

Round  55, Global train loss: 0.376, Global test loss: 1.507, Global test accuracy: 51.50 

Round  56, Train loss: 0.345, Test loss: 0.603, Test accuracy: 78.02 

Round  56, Global train loss: 0.345, Global test loss: 1.445, Global test accuracy: 53.68 

Round  57, Train loss: 0.374, Test loss: 0.594, Test accuracy: 78.38 

Round  57, Global train loss: 0.374, Global test loss: 1.295, Global test accuracy: 55.42 

Round  58, Train loss: 0.356, Test loss: 0.598, Test accuracy: 78.25 

Round  58, Global train loss: 0.356, Global test loss: 1.493, Global test accuracy: 52.77 

Round  59, Train loss: 0.432, Test loss: 0.595, Test accuracy: 78.32 

Round  59, Global train loss: 0.432, Global test loss: 1.379, Global test accuracy: 52.88 

Round  60, Train loss: 0.423, Test loss: 0.593, Test accuracy: 78.37 

Round  60, Global train loss: 0.423, Global test loss: 1.332, Global test accuracy: 55.02 

Round  61, Train loss: 0.394, Test loss: 0.600, Test accuracy: 78.65 

Round  61, Global train loss: 0.394, Global test loss: 1.336, Global test accuracy: 55.93 

Round  62, Train loss: 0.401, Test loss: 0.616, Test accuracy: 78.42 

Round  62, Global train loss: 0.401, Global test loss: 1.335, Global test accuracy: 55.08 

Round  63, Train loss: 0.381, Test loss: 0.629, Test accuracy: 78.40 

Round  63, Global train loss: 0.381, Global test loss: 1.205, Global test accuracy: 59.43 

Round  64, Train loss: 0.429, Test loss: 0.607, Test accuracy: 78.50 

Round  64, Global train loss: 0.429, Global test loss: 1.408, Global test accuracy: 52.87 

Round  65, Train loss: 0.314, Test loss: 0.605, Test accuracy: 78.47 

Round  65, Global train loss: 0.314, Global test loss: 1.253, Global test accuracy: 58.20 

Round  66, Train loss: 0.417, Test loss: 0.619, Test accuracy: 77.98 

Round  66, Global train loss: 0.417, Global test loss: 1.445, Global test accuracy: 54.45 

Round  67, Train loss: 0.427, Test loss: 0.635, Test accuracy: 77.57 

Round  67, Global train loss: 0.427, Global test loss: 1.539, Global test accuracy: 50.45 

Round  68, Train loss: 0.362, Test loss: 0.644, Test accuracy: 77.43 

Round  68, Global train loss: 0.362, Global test loss: 1.454, Global test accuracy: 53.43 

Round  69, Train loss: 0.314, Test loss: 0.618, Test accuracy: 78.25 

Round  69, Global train loss: 0.314, Global test loss: 1.610, Global test accuracy: 51.48 

Round  70, Train loss: 0.363, Test loss: 0.595, Test accuracy: 78.93 

Round  70, Global train loss: 0.363, Global test loss: 1.722, Global test accuracy: 49.98 

Round  71, Train loss: 0.364, Test loss: 0.600, Test accuracy: 79.38 

Round  71, Global train loss: 0.364, Global test loss: 1.478, Global test accuracy: 53.50 

Round  72, Train loss: 0.315, Test loss: 0.632, Test accuracy: 79.12 

Round  72, Global train loss: 0.315, Global test loss: 1.254, Global test accuracy: 59.17 

Round  73, Train loss: 0.382, Test loss: 0.630, Test accuracy: 78.98 

Round  73, Global train loss: 0.382, Global test loss: 1.347, Global test accuracy: 56.25 

Round  74, Train loss: 0.337, Test loss: 0.614, Test accuracy: 79.30 

Round  74, Global train loss: 0.337, Global test loss: 1.317, Global test accuracy: 57.38 

Round  75, Train loss: 0.423, Test loss: 0.617, Test accuracy: 79.08 

Round  75, Global train loss: 0.423, Global test loss: 1.412, Global test accuracy: 53.85 

Round  76, Train loss: 0.269, Test loss: 0.618, Test accuracy: 79.15 

Round  76, Global train loss: 0.269, Global test loss: 1.706, Global test accuracy: 50.02 

Round  77, Train loss: 0.292, Test loss: 0.615, Test accuracy: 79.55 

Round  77, Global train loss: 0.292, Global test loss: 1.539, Global test accuracy: 53.78 

Round  78, Train loss: 0.298, Test loss: 0.662, Test accuracy: 79.02 

Round  78, Global train loss: 0.298, Global test loss: 1.737, Global test accuracy: 49.20 

Round  79, Train loss: 0.293, Test loss: 0.695, Test accuracy: 78.03 

Round  79, Global train loss: 0.293, Global test loss: 1.478, Global test accuracy: 54.75 

Round  80, Train loss: 0.295, Test loss: 0.689, Test accuracy: 78.08 

Round  80, Global train loss: 0.295, Global test loss: 1.333, Global test accuracy: 58.70 

Round  81, Train loss: 0.343, Test loss: 0.678, Test accuracy: 78.23 

Round  81, Global train loss: 0.343, Global test loss: 1.263, Global test accuracy: 57.88 

Round  82, Train loss: 0.284, Test loss: 0.623, Test accuracy: 79.73 

Round  82, Global train loss: 0.284, Global test loss: 1.334, Global test accuracy: 59.17 

Round  83, Train loss: 0.299, Test loss: 0.623, Test accuracy: 79.72 

Round  83, Global train loss: 0.299, Global test loss: 1.581, Global test accuracy: 53.58 

Round  84, Train loss: 0.340, Test loss: 0.653, Test accuracy: 78.78 

Round  84, Global train loss: 0.340, Global test loss: 1.427, Global test accuracy: 56.75 

Round  85, Train loss: 0.281, Test loss: 0.634, Test accuracy: 79.25 

Round  85, Global train loss: 0.281, Global test loss: 1.513, Global test accuracy: 54.98 

Round  86, Train loss: 0.229, Test loss: 0.664, Test accuracy: 78.52 

Round  86, Global train loss: 0.229, Global test loss: 1.687, Global test accuracy: 51.67 

Round  87, Train loss: 0.350, Test loss: 0.667, Test accuracy: 78.08 

Round  87, Global train loss: 0.350, Global test loss: 1.259, Global test accuracy: 58.48 

Round  88, Train loss: 0.283, Test loss: 0.656, Test accuracy: 78.83 

Round  88, Global train loss: 0.283, Global test loss: 1.535, Global test accuracy: 54.55 

Round  89, Train loss: 0.301, Test loss: 0.645, Test accuracy: 79.42 

Round  89, Global train loss: 0.301, Global test loss: 1.579, Global test accuracy: 52.98 

Round  90, Train loss: 0.316, Test loss: 0.658, Test accuracy: 78.95 

Round  90, Global train loss: 0.316, Global test loss: 1.287, Global test accuracy: 58.55 

Round  91, Train loss: 0.333, Test loss: 0.654, Test accuracy: 78.98 

Round  91, Global train loss: 0.333, Global test loss: 1.587, Global test accuracy: 53.17 

Round  92, Train loss: 0.308, Test loss: 0.631, Test accuracy: 79.63 

Round  92, Global train loss: 0.308, Global test loss: 1.343, Global test accuracy: 56.68 

Round  93, Train loss: 0.284, Test loss: 0.622, Test accuracy: 79.87 

Round  93, Global train loss: 0.284, Global test loss: 1.250, Global test accuracy: 60.67 

Round  94, Train loss: 0.353, Test loss: 0.633, Test accuracy: 79.87 

Round  94, Global train loss: 0.353, Global test loss: 1.330, Global test accuracy: 58.85 

Round  95, Train loss: 0.218, Test loss: 0.637, Test accuracy: 79.65 

Round  95, Global train loss: 0.218, Global test loss: 1.410, Global test accuracy: 58.27 

Round  96, Train loss: 0.256, Test loss: 0.640, Test accuracy: 79.35 

Round  96, Global train loss: 0.256, Global test loss: 1.310, Global test accuracy: 60.00 

Round  97, Train loss: 0.261, Test loss: 0.632, Test accuracy: 79.63 

Round  97, Global train loss: 0.261, Global test loss: 1.456, Global test accuracy: 57.05 

Round  98, Train loss: 0.349, Test loss: 0.626, Test accuracy: 79.97 

Round  98, Global train loss: 0.349, Global test loss: 1.300, Global test accuracy: 58.25 

Round  99, Train loss: 0.225, Test loss: 0.644, Test accuracy: 79.58 

Round  99, Global train loss: 0.225, Global test loss: 1.474, Global test accuracy: 58.15 

Final Round, Train loss: 0.218, Test loss: 0.725, Test accuracy: 79.13 

Final Round, Global train loss: 0.218, Global test loss: 1.474, Global test accuracy: 58.15 

Average accuracy final 10 rounds: 79.54833333333333 

Average global accuracy final 10 rounds: 57.96333333333333 

1077.7157878875732
[3.082794427871704, 4.149334669113159, 5.21570611000061, 6.281300067901611, 7.34717321395874, 8.412710428237915, 9.480618238449097, 10.54916262626648, 11.6096670627594, 12.676991701126099, 13.748843431472778, 14.816268920898438, 15.87948489189148, 16.939908981323242, 18.00823187828064, 19.071070671081543, 20.130870580673218, 21.20582675933838, 22.266101360321045, 23.329259634017944, 24.388159036636353, 25.45009207725525, 26.512174367904663, 27.572487831115723, 28.636095762252808, 29.716672897338867, 30.76574397087097, 31.824458837509155, 32.881454944610596, 33.94041204452515, 34.995508670806885, 36.05349540710449, 37.11334848403931, 38.168710470199585, 39.25323486328125, 40.34222102165222, 41.43353247642517, 42.51997756958008, 43.60800576210022, 44.69710993766785, 45.78686475753784, 46.87840747833252, 47.96759009361267, 49.05337834358215, 50.13719081878662, 51.22532367706299, 52.31071424484253, 53.40204405784607, 54.49197578430176, 55.57986927032471, 56.66822099685669, 57.75182771682739, 58.842888832092285, 59.93316078186035, 61.02350926399231, 62.109760999679565, 63.19533085823059, 64.29604601860046, 65.38955998420715, 66.48197603225708, 67.56362891197205, 68.64785885810852, 69.73252010345459, 70.81847953796387, 71.91064643859863, 72.99881720542908, 74.08624362945557, 75.18242239952087, 76.27964806556702, 77.3673779964447, 78.45502614974976, 79.54740691184998, 80.63812708854675, 81.72395730018616, 82.80863118171692, 83.90670871734619, 84.99509692192078, 86.08258414268494, 87.17102122306824, 88.25636148452759, 89.34641361236572, 90.43285799026489, 91.52654504776001, 92.61185932159424, 93.6950581073761, 94.78554224967957, 95.87258005142212, 96.93231773376465, 97.9873411655426, 99.0442624092102, 100.10506939888, 101.1710479259491, 102.22928285598755, 103.28785872459412, 104.34773802757263, 105.4136552810669, 106.49384903907776, 107.57519674301147, 108.65974450111389, 109.74375462532043, 111.9038896560669]
[28.516666666666666, 38.93333333333333, 43.18333333333333, 48.15, 52.6, 56.21666666666667, 57.766666666666666, 61.3, 64.55, 65.23333333333333, 66.23333333333333, 67.63333333333334, 68.16666666666667, 69.7, 69.51666666666667, 70.55, 70.08333333333333, 70.31666666666666, 71.8, 71.2, 71.63333333333334, 71.83333333333333, 72.33333333333333, 71.85, 72.08333333333333, 72.56666666666666, 72.81666666666666, 72.5, 72.93333333333334, 72.7, 72.93333333333334, 72.8, 74.25, 74.38333333333334, 74.7, 74.83333333333333, 75.23333333333333, 76.53333333333333, 76.08333333333333, 76.08333333333333, 76.21666666666667, 76.05, 75.76666666666667, 76.05, 76.21666666666667, 76.45, 77.13333333333334, 77.11666666666666, 77.13333333333334, 77.7, 77.73333333333333, 77.35, 77.45, 76.96666666666667, 77.16666666666667, 77.03333333333333, 78.01666666666667, 78.38333333333334, 78.25, 78.31666666666666, 78.36666666666666, 78.65, 78.41666666666667, 78.4, 78.5, 78.46666666666667, 77.98333333333333, 77.56666666666666, 77.43333333333334, 78.25, 78.93333333333334, 79.38333333333334, 79.11666666666666, 78.98333333333333, 79.3, 79.08333333333333, 79.15, 79.55, 79.01666666666667, 78.03333333333333, 78.08333333333333, 78.23333333333333, 79.73333333333333, 79.71666666666667, 78.78333333333333, 79.25, 78.51666666666667, 78.08333333333333, 78.83333333333333, 79.41666666666667, 78.95, 78.98333333333333, 79.63333333333334, 79.86666666666666, 79.86666666666666, 79.65, 79.35, 79.63333333333334, 79.96666666666667, 79.58333333333333, 79.13333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.601, Test loss: 2.280, Test accuracy: 15.45 

Round   1, Train loss: 1.065, Test loss: 1.667, Test accuracy: 36.42 

Round   2, Train loss: 1.050, Test loss: 1.723, Test accuracy: 34.77 

Round   3, Train loss: 0.996, Test loss: 1.519, Test accuracy: 40.03 

Round   4, Train loss: 0.964, Test loss: 1.333, Test accuracy: 43.28 

Round   5, Train loss: 0.895, Test loss: 1.246, Test accuracy: 47.72 

Round   6, Train loss: 0.882, Test loss: 1.095, Test accuracy: 52.43 

Round   7, Train loss: 0.888, Test loss: 1.133, Test accuracy: 51.62 

Round   8, Train loss: 0.825, Test loss: 1.024, Test accuracy: 56.63 

Round   9, Train loss: 0.856, Test loss: 0.864, Test accuracy: 60.25 

Round  10, Train loss: 0.768, Test loss: 0.824, Test accuracy: 62.82 

Round  11, Train loss: 0.711, Test loss: 0.802, Test accuracy: 64.38 

Round  12, Train loss: 0.677, Test loss: 0.815, Test accuracy: 63.38 

Round  13, Train loss: 0.714, Test loss: 0.835, Test accuracy: 62.30 

Round  14, Train loss: 0.850, Test loss: 0.777, Test accuracy: 65.70 

Round  15, Train loss: 0.732, Test loss: 0.757, Test accuracy: 65.77 

Round  16, Train loss: 0.681, Test loss: 0.746, Test accuracy: 66.25 

Round  17, Train loss: 0.770, Test loss: 0.748, Test accuracy: 66.55 

Round  18, Train loss: 0.753, Test loss: 0.755, Test accuracy: 66.73 

Round  19, Train loss: 0.685, Test loss: 0.772, Test accuracy: 66.87 

Round  20, Train loss: 0.665, Test loss: 0.750, Test accuracy: 66.88 

Round  21, Train loss: 0.615, Test loss: 0.706, Test accuracy: 68.60 

Round  22, Train loss: 0.738, Test loss: 0.753, Test accuracy: 66.80 

Round  23, Train loss: 0.698, Test loss: 0.710, Test accuracy: 68.63 

Round  24, Train loss: 0.644, Test loss: 0.697, Test accuracy: 69.40 

Round  25, Train loss: 0.639, Test loss: 0.726, Test accuracy: 67.73 

Round  26, Train loss: 0.563, Test loss: 0.693, Test accuracy: 68.97 

Round  27, Train loss: 0.590, Test loss: 0.687, Test accuracy: 69.93 

Round  28, Train loss: 0.680, Test loss: 0.678, Test accuracy: 70.55 

Round  29, Train loss: 0.732, Test loss: 0.683, Test accuracy: 70.93 

Round  30, Train loss: 0.626, Test loss: 0.672, Test accuracy: 71.30 

Round  31, Train loss: 0.593, Test loss: 0.669, Test accuracy: 70.78 

Round  32, Train loss: 0.522, Test loss: 0.663, Test accuracy: 71.08 

Round  33, Train loss: 0.655, Test loss: 0.658, Test accuracy: 71.53 

Round  34, Train loss: 0.596, Test loss: 0.638, Test accuracy: 73.00 

Round  35, Train loss: 0.594, Test loss: 0.625, Test accuracy: 73.60 

Round  36, Train loss: 0.646, Test loss: 0.626, Test accuracy: 73.45 

Round  37, Train loss: 0.526, Test loss: 0.641, Test accuracy: 72.45 

Round  38, Train loss: 0.562, Test loss: 0.617, Test accuracy: 73.57 

Round  39, Train loss: 0.603, Test loss: 0.615, Test accuracy: 74.33 

Round  40, Train loss: 0.496, Test loss: 0.611, Test accuracy: 73.72 

Round  41, Train loss: 0.542, Test loss: 0.602, Test accuracy: 74.32 

Round  42, Train loss: 0.585, Test loss: 0.601, Test accuracy: 74.52 

Round  43, Train loss: 0.531, Test loss: 0.590, Test accuracy: 75.00 

Round  44, Train loss: 0.640, Test loss: 0.592, Test accuracy: 74.87 

Round  45, Train loss: 0.629, Test loss: 0.598, Test accuracy: 74.43 

Round  46, Train loss: 0.538, Test loss: 0.593, Test accuracy: 74.88 

Round  47, Train loss: 0.528, Test loss: 0.582, Test accuracy: 75.23 

Round  48, Train loss: 0.560, Test loss: 0.571, Test accuracy: 75.68 

Round  49, Train loss: 0.586, Test loss: 0.582, Test accuracy: 75.30 

Round  50, Train loss: 0.549, Test loss: 0.584, Test accuracy: 75.80 

Round  51, Train loss: 0.484, Test loss: 0.572, Test accuracy: 75.95 

Round  52, Train loss: 0.520, Test loss: 0.566, Test accuracy: 76.28 

Round  53, Train loss: 0.442, Test loss: 0.568, Test accuracy: 75.98 

Round  54, Train loss: 0.571, Test loss: 0.576, Test accuracy: 75.83 

Round  55, Train loss: 0.458, Test loss: 0.567, Test accuracy: 76.50 

Round  56, Train loss: 0.479, Test loss: 0.569, Test accuracy: 76.30 

Round  57, Train loss: 0.432, Test loss: 0.558, Test accuracy: 77.00 

Round  58, Train loss: 0.476, Test loss: 0.575, Test accuracy: 76.42 

Round  59, Train loss: 0.489, Test loss: 0.555, Test accuracy: 77.12 

Round  60, Train loss: 0.515, Test loss: 0.551, Test accuracy: 77.40 

Round  61, Train loss: 0.544, Test loss: 0.551, Test accuracy: 78.05 

Round  62, Train loss: 0.406, Test loss: 0.564, Test accuracy: 76.93 

Round  63, Train loss: 0.506, Test loss: 0.557, Test accuracy: 77.65 

Round  64, Train loss: 0.444, Test loss: 0.560, Test accuracy: 77.42 

Round  65, Train loss: 0.465, Test loss: 0.560, Test accuracy: 77.55 

Round  66, Train loss: 0.438, Test loss: 0.561, Test accuracy: 77.15 

Round  67, Train loss: 0.475, Test loss: 0.557, Test accuracy: 76.98 

Round  68, Train loss: 0.411, Test loss: 0.550, Test accuracy: 77.95 

Round  69, Train loss: 0.474, Test loss: 0.543, Test accuracy: 77.92 

Round  70, Train loss: 0.454, Test loss: 0.525, Test accuracy: 78.82 

Round  71, Train loss: 0.423, Test loss: 0.535, Test accuracy: 78.68 

Round  72, Train loss: 0.443, Test loss: 0.523, Test accuracy: 78.70 

Round  73, Train loss: 0.432, Test loss: 0.540, Test accuracy: 78.13 

Round  74, Train loss: 0.460, Test loss: 0.519, Test accuracy: 78.88 

Round  75, Train loss: 0.376, Test loss: 0.536, Test accuracy: 78.67 

Round  76, Train loss: 0.405, Test loss: 0.534, Test accuracy: 78.67 

Round  77, Train loss: 0.382, Test loss: 0.525, Test accuracy: 78.88 

Round  78, Train loss: 0.368, Test loss: 0.524, Test accuracy: 79.22 

Round  79, Train loss: 0.390, Test loss: 0.524, Test accuracy: 79.45 

Round  80, Train loss: 0.346, Test loss: 0.531, Test accuracy: 79.25 

Round  81, Train loss: 0.385, Test loss: 0.527, Test accuracy: 78.78 

Round  82, Train loss: 0.496, Test loss: 0.520, Test accuracy: 79.43 

Round  83, Train loss: 0.400, Test loss: 0.519, Test accuracy: 79.52 

Round  84, Train loss: 0.413, Test loss: 0.515, Test accuracy: 79.58 

Round  85, Train loss: 0.435, Test loss: 0.517, Test accuracy: 80.02 

Round  86, Train loss: 0.373, Test loss: 0.521, Test accuracy: 79.77 

Round  87, Train loss: 0.346, Test loss: 0.532, Test accuracy: 79.33 

Round  88, Train loss: 0.415, Test loss: 0.508, Test accuracy: 80.30 

Round  89, Train loss: 0.366, Test loss: 0.512, Test accuracy: 80.15 

Round  90, Train loss: 0.372, Test loss: 0.506, Test accuracy: 79.92 

Round  91, Train loss: 0.372, Test loss: 0.515, Test accuracy: 80.12 

Round  92, Train loss: 0.302, Test loss: 0.509, Test accuracy: 80.33 

Round  93, Train loss: 0.347, Test loss: 0.508, Test accuracy: 79.63 

Round  94, Train loss: 0.275, Test loss: 0.507, Test accuracy: 80.47 

Round  95, Train loss: 0.351, Test loss: 0.521, Test accuracy: 79.90 

Round  96, Train loss: 0.305, Test loss: 0.520, Test accuracy: 80.37 

Round  97, Train loss: 0.368, Test loss: 0.522, Test accuracy: 79.77 

Round  98, Train loss: 0.310, Test loss: 0.540, Test accuracy: 79.47 

Round  99, Train loss: 0.311, Test loss: 0.530, Test accuracy: 79.20 

Final Round, Train loss: 0.293, Test loss: 0.505, Test accuracy: 80.78 

Average accuracy final 10 rounds: 79.91666666666669 

795.2974581718445
[3.1108036041259766, 4.068521976470947, 4.87836766242981, 5.682357549667358, 6.6409430503845215, 7.612066030502319, 8.567463159561157, 9.525026559829712, 10.48624300956726, 11.381364822387695, 12.371270656585693, 13.359749555587769, 14.345156908035278, 15.149887323379517, 15.947603702545166, 16.796870470046997, 17.76325750350952, 18.73326277732849, 19.72977113723755, 20.687135457992554, 21.631598711013794, 22.623600244522095, 23.601407766342163, 24.592487573623657, 25.562116622924805, 26.531556367874146, 27.50568652153015, 28.483274459838867, 29.47865319252014, 30.476587533950806, 31.4755117893219, 32.451802253723145, 33.41974472999573, 34.39206790924072, 35.4046049118042, 36.40939688682556, 37.40675234794617, 38.377607107162476, 39.342875242233276, 40.316797733306885, 41.2846040725708, 42.16650056838989, 43.058924436569214, 44.02551054954529, 44.9950954914093, 45.96035170555115, 46.779022216796875, 47.773630142211914, 48.76681160926819, 49.738590717315674, 50.73182129859924, 51.73363137245178, 52.724830627441406, 53.698217153549194, 54.6661012172699, 55.642478704452515, 56.613608837127686, 57.58792567253113, 58.55982422828674, 59.526402711868286, 60.48365259170532, 61.44421935081482, 62.40275478363037, 63.369980573654175, 64.33011198043823, 65.28789973258972, 66.24653577804565, 67.21233057975769, 68.172776222229, 69.13087177276611, 70.08941888809204, 71.0500111579895, 72.00718307495117, 72.98373675346375, 73.94246029853821, 74.89803075790405, 75.8611364364624, 76.82490706443787, 77.79051923751831, 78.75018310546875, 79.72393250465393, 80.68280482292175, 81.6401219367981, 82.59516859054565, 83.5548210144043, 84.52104997634888, 85.48022174835205, 86.43799662590027, 87.39638304710388, 88.34997844696045, 89.30373573303223, 90.27128791809082, 91.22608423233032, 92.18751096725464, 93.15428400039673, 94.11010599136353, 95.06952595710754, 96.02699398994446, 96.98279476165771, 97.936927318573, 99.49850416183472]
[15.45, 36.416666666666664, 34.766666666666666, 40.03333333333333, 43.28333333333333, 47.71666666666667, 52.43333333333333, 51.61666666666667, 56.63333333333333, 60.25, 62.81666666666667, 64.38333333333334, 63.38333333333333, 62.3, 65.7, 65.76666666666667, 66.25, 66.55, 66.73333333333333, 66.86666666666666, 66.88333333333334, 68.6, 66.8, 68.63333333333334, 69.4, 67.73333333333333, 68.96666666666667, 69.93333333333334, 70.55, 70.93333333333334, 71.3, 70.78333333333333, 71.08333333333333, 71.53333333333333, 73.0, 73.6, 73.45, 72.45, 73.56666666666666, 74.33333333333333, 73.71666666666667, 74.31666666666666, 74.51666666666667, 75.0, 74.86666666666666, 74.43333333333334, 74.88333333333334, 75.23333333333333, 75.68333333333334, 75.3, 75.8, 75.95, 76.28333333333333, 75.98333333333333, 75.83333333333333, 76.5, 76.3, 77.0, 76.41666666666667, 77.11666666666666, 77.4, 78.05, 76.93333333333334, 77.65, 77.41666666666667, 77.55, 77.15, 76.98333333333333, 77.95, 77.91666666666667, 78.81666666666666, 78.68333333333334, 78.7, 78.13333333333334, 78.88333333333334, 78.66666666666667, 78.66666666666667, 78.88333333333334, 79.21666666666667, 79.45, 79.25, 78.78333333333333, 79.43333333333334, 79.51666666666667, 79.58333333333333, 80.01666666666667, 79.76666666666667, 79.33333333333333, 80.3, 80.15, 79.91666666666667, 80.11666666666666, 80.33333333333333, 79.63333333333334, 80.46666666666667, 79.9, 80.36666666666666, 79.76666666666667, 79.46666666666667, 79.2, 80.78333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.665, Test loss: 2.248, Test accuracy: 17.77
Round   1, Train loss: 1.100, Test loss: 1.864, Test accuracy: 33.57
Round   2, Train loss: 0.983, Test loss: 1.562, Test accuracy: 45.85
Round   3, Train loss: 0.976, Test loss: 1.113, Test accuracy: 51.58
Round   4, Train loss: 0.895, Test loss: 1.130, Test accuracy: 51.88
Round   5, Train loss: 0.960, Test loss: 1.055, Test accuracy: 54.33
Round   6, Train loss: 0.870, Test loss: 1.035, Test accuracy: 56.33
Round   7, Train loss: 0.860, Test loss: 0.913, Test accuracy: 59.15
Round   8, Train loss: 0.810, Test loss: 0.810, Test accuracy: 64.58
Round   9, Train loss: 0.843, Test loss: 0.796, Test accuracy: 65.72
Round  10, Train loss: 0.849, Test loss: 0.769, Test accuracy: 66.37
Round  11, Train loss: 0.716, Test loss: 0.776, Test accuracy: 65.18
Round  12, Train loss: 0.774, Test loss: 0.774, Test accuracy: 65.43
Round  13, Train loss: 0.751, Test loss: 0.764, Test accuracy: 65.73
Round  14, Train loss: 0.724, Test loss: 0.747, Test accuracy: 67.62
Round  15, Train loss: 0.660, Test loss: 0.753, Test accuracy: 66.18
Round  16, Train loss: 0.717, Test loss: 0.732, Test accuracy: 67.13
Round  17, Train loss: 0.659, Test loss: 0.724, Test accuracy: 68.22
Round  18, Train loss: 0.732, Test loss: 0.703, Test accuracy: 69.60
Round  19, Train loss: 0.684, Test loss: 0.696, Test accuracy: 70.47
Round  20, Train loss: 0.747, Test loss: 0.692, Test accuracy: 70.23
Round  21, Train loss: 0.720, Test loss: 0.681, Test accuracy: 70.62
Round  22, Train loss: 0.711, Test loss: 0.666, Test accuracy: 71.67
Round  23, Train loss: 0.641, Test loss: 0.656, Test accuracy: 72.42
Round  24, Train loss: 0.672, Test loss: 0.660, Test accuracy: 72.85
Round  25, Train loss: 0.700, Test loss: 0.663, Test accuracy: 71.38
Round  26, Train loss: 0.732, Test loss: 0.658, Test accuracy: 71.90
Round  27, Train loss: 0.571, Test loss: 0.647, Test accuracy: 72.22
Round  28, Train loss: 0.694, Test loss: 0.653, Test accuracy: 71.87
Round  29, Train loss: 0.565, Test loss: 0.629, Test accuracy: 73.18
Round  30, Train loss: 0.605, Test loss: 0.633, Test accuracy: 72.58
Round  31, Train loss: 0.567, Test loss: 0.628, Test accuracy: 73.20
Round  32, Train loss: 0.642, Test loss: 0.613, Test accuracy: 74.62
Round  33, Train loss: 0.667, Test loss: 0.618, Test accuracy: 73.78
Round  34, Train loss: 0.627, Test loss: 0.610, Test accuracy: 73.67
Round  35, Train loss: 0.564, Test loss: 0.599, Test accuracy: 74.55
Round  36, Train loss: 0.631, Test loss: 0.590, Test accuracy: 75.58
Round  37, Train loss: 0.605, Test loss: 0.583, Test accuracy: 75.23
Round  38, Train loss: 0.470, Test loss: 0.579, Test accuracy: 75.32
Round  39, Train loss: 0.591, Test loss: 0.581, Test accuracy: 75.77
Round  40, Train loss: 0.523, Test loss: 0.570, Test accuracy: 76.18
Round  41, Train loss: 0.493, Test loss: 0.569, Test accuracy: 76.03
Round  42, Train loss: 0.538, Test loss: 0.579, Test accuracy: 75.90
Round  43, Train loss: 0.577, Test loss: 0.563, Test accuracy: 76.53
Round  44, Train loss: 0.610, Test loss: 0.572, Test accuracy: 76.02
Round  45, Train loss: 0.553, Test loss: 0.560, Test accuracy: 76.67
Round  46, Train loss: 0.566, Test loss: 0.563, Test accuracy: 76.77
Round  47, Train loss: 0.505, Test loss: 0.552, Test accuracy: 77.07
Round  48, Train loss: 0.575, Test loss: 0.547, Test accuracy: 77.37
Round  49, Train loss: 0.470, Test loss: 0.544, Test accuracy: 77.77
Round  50, Train loss: 0.474, Test loss: 0.563, Test accuracy: 76.57
Round  51, Train loss: 0.427, Test loss: 0.545, Test accuracy: 77.40
Round  52, Train loss: 0.537, Test loss: 0.543, Test accuracy: 77.83
Round  53, Train loss: 0.536, Test loss: 0.534, Test accuracy: 78.48
Round  54, Train loss: 0.507, Test loss: 0.531, Test accuracy: 78.15
Round  55, Train loss: 0.441, Test loss: 0.541, Test accuracy: 77.45
Round  56, Train loss: 0.512, Test loss: 0.529, Test accuracy: 78.28
Round  57, Train loss: 0.445, Test loss: 0.531, Test accuracy: 77.98
Round  58, Train loss: 0.471, Test loss: 0.525, Test accuracy: 78.57
Round  59, Train loss: 0.523, Test loss: 0.520, Test accuracy: 79.17
Round  60, Train loss: 0.395, Test loss: 0.516, Test accuracy: 78.98
Round  61, Train loss: 0.485, Test loss: 0.517, Test accuracy: 78.83
Round  62, Train loss: 0.400, Test loss: 0.513, Test accuracy: 79.40
Round  63, Train loss: 0.454, Test loss: 0.510, Test accuracy: 79.02
Round  64, Train loss: 0.455, Test loss: 0.506, Test accuracy: 79.62
Round  65, Train loss: 0.445, Test loss: 0.508, Test accuracy: 79.07
Round  66, Train loss: 0.436, Test loss: 0.504, Test accuracy: 79.48
Round  67, Train loss: 0.436, Test loss: 0.500, Test accuracy: 79.63
Round  68, Train loss: 0.427, Test loss: 0.492, Test accuracy: 79.55
Round  69, Train loss: 0.358, Test loss: 0.494, Test accuracy: 79.85
Round  70, Train loss: 0.327, Test loss: 0.489, Test accuracy: 79.88
Round  71, Train loss: 0.460, Test loss: 0.493, Test accuracy: 79.85
Round  72, Train loss: 0.362, Test loss: 0.496, Test accuracy: 79.42
Round  73, Train loss: 0.394, Test loss: 0.495, Test accuracy: 79.37
Round  74, Train loss: 0.339, Test loss: 0.487, Test accuracy: 80.52
Round  75, Train loss: 0.436, Test loss: 0.484, Test accuracy: 80.43
Round  76, Train loss: 0.321, Test loss: 0.485, Test accuracy: 80.23
Round  77, Train loss: 0.375, Test loss: 0.486, Test accuracy: 80.30
Round  78, Train loss: 0.345, Test loss: 0.484, Test accuracy: 80.60
Round  79, Train loss: 0.414, Test loss: 0.487, Test accuracy: 80.75
Round  80, Train loss: 0.376, Test loss: 0.483, Test accuracy: 80.85
Round  81, Train loss: 0.317, Test loss: 0.481, Test accuracy: 80.80
Round  82, Train loss: 0.318, Test loss: 0.477, Test accuracy: 81.00
Round  83, Train loss: 0.375, Test loss: 0.477, Test accuracy: 81.12
Round  84, Train loss: 0.376, Test loss: 0.480, Test accuracy: 80.93
Round  85, Train loss: 0.424, Test loss: 0.487, Test accuracy: 80.50
Round  86, Train loss: 0.391, Test loss: 0.483, Test accuracy: 80.48
Round  87, Train loss: 0.314, Test loss: 0.480, Test accuracy: 80.88
Round  88, Train loss: 0.416, Test loss: 0.479, Test accuracy: 81.15
Round  89, Train loss: 0.407, Test loss: 0.479, Test accuracy: 81.20
Round  90, Train loss: 0.354, Test loss: 0.480, Test accuracy: 81.23
Round  91, Train loss: 0.318, Test loss: 0.475, Test accuracy: 81.35
Round  92, Train loss: 0.305, Test loss: 0.479, Test accuracy: 81.08
Round  93, Train loss: 0.351, Test loss: 0.474, Test accuracy: 81.25
Round  94, Train loss: 0.247, Test loss: 0.470, Test accuracy: 81.72
Round  95, Train loss: 0.306, Test loss: 0.472, Test accuracy: 81.47
Round  96, Train loss: 0.267, Test loss: 0.478, Test accuracy: 81.38
Round  97, Train loss: 0.253, Test loss: 0.479, Test accuracy: 81.38
Round  98, Train loss: 0.362, Test loss: 0.477, Test accuracy: 81.35
Round  99, Train loss: 0.276, Test loss: 0.476, Test accuracy: 81.70
Final Round, Train loss: 0.284, Test loss: 0.476, Test accuracy: 81.88
Average accuracy final 10 rounds: 81.39166666666668
913.9855439662933
[3.3405637741088867, 4.523072242736816, 5.687261343002319, 6.817676305770874, 7.946913003921509, 9.075525283813477, 10.205074787139893, 11.334322452545166, 12.465303659439087, 13.589065313339233, 14.717389583587646, 15.847514867782593, 16.969871520996094, 18.094754934310913, 19.235164165496826, 20.365519046783447, 21.492060899734497, 22.619457244873047, 23.74178433418274, 24.86668562889099, 25.998902082443237, 27.124590635299683, 28.255903959274292, 29.387227773666382, 30.51779818534851, 31.640756130218506, 32.768110036849976, 33.89375352859497, 35.02390956878662, 36.15144729614258, 37.2881076335907, 38.418466091156006, 39.54890155792236, 40.6793475151062, 41.80702757835388, 42.941383361816406, 44.069244146347046, 45.20627236366272, 46.36617708206177, 47.52825474739075, 48.66364288330078, 49.79778027534485, 50.92884564399719, 52.06560730934143, 53.19562125205994, 54.32896614074707, 55.48791551589966, 56.62228870391846, 57.75284242630005, 58.88079905509949, 60.00997972488403, 61.140482664108276, 62.2754225730896, 63.409747838974, 64.54297828674316, 65.67201066017151, 66.80303525924683, 67.96507978439331, 69.12469291687012, 70.28713512420654, 71.44724655151367, 72.6126000881195, 73.77109742164612, 74.9281394481659, 76.09008288383484, 77.25691652297974, 78.41189861297607, 79.56929874420166, 80.69221878051758, 81.81668329238892, 82.93663024902344, 84.05615949630737, 85.17714095115662, 86.30182361602783, 87.42025566101074, 88.69053530693054, 89.96340370178223, 91.23673343658447, 92.5061104297638, 93.78261256217957, 95.05724906921387, 96.21292781829834, 97.36723947525024, 98.51586627960205, 99.66677975654602, 100.81777143478394, 101.93850922584534, 103.08217167854309, 104.22749900817871, 105.36197304725647, 106.53452849388123, 107.66715836524963, 108.80231976509094, 109.93241834640503, 111.06359028816223, 112.240549325943, 113.39041423797607, 114.55067682266235, 115.71031141281128, 116.86946368217468, 118.62160921096802]
[17.766666666666666, 33.56666666666667, 45.85, 51.583333333333336, 51.88333333333333, 54.333333333333336, 56.333333333333336, 59.15, 64.58333333333333, 65.71666666666667, 66.36666666666666, 65.18333333333334, 65.43333333333334, 65.73333333333333, 67.61666666666666, 66.18333333333334, 67.13333333333334, 68.21666666666667, 69.6, 70.46666666666667, 70.23333333333333, 70.61666666666666, 71.66666666666667, 72.41666666666667, 72.85, 71.38333333333334, 71.9, 72.21666666666667, 71.86666666666666, 73.18333333333334, 72.58333333333333, 73.2, 74.61666666666666, 73.78333333333333, 73.66666666666667, 74.55, 75.58333333333333, 75.23333333333333, 75.31666666666666, 75.76666666666667, 76.18333333333334, 76.03333333333333, 75.9, 76.53333333333333, 76.01666666666667, 76.66666666666667, 76.76666666666667, 77.06666666666666, 77.36666666666666, 77.76666666666667, 76.56666666666666, 77.4, 77.83333333333333, 78.48333333333333, 78.15, 77.45, 78.28333333333333, 77.98333333333333, 78.56666666666666, 79.16666666666667, 78.98333333333333, 78.83333333333333, 79.4, 79.01666666666667, 79.61666666666666, 79.06666666666666, 79.48333333333333, 79.63333333333334, 79.55, 79.85, 79.88333333333334, 79.85, 79.41666666666667, 79.36666666666666, 80.51666666666667, 80.43333333333334, 80.23333333333333, 80.3, 80.6, 80.75, 80.85, 80.8, 81.0, 81.11666666666666, 80.93333333333334, 80.5, 80.48333333333333, 80.88333333333334, 81.15, 81.2, 81.23333333333333, 81.35, 81.08333333333333, 81.25, 81.71666666666667, 81.46666666666667, 81.38333333333334, 81.38333333333334, 81.35, 81.7, 81.88333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
Traceback (most recent call last):
  File "main_ditto.py", line 182, in <module>
    w_k, loss, indd = local.train(net=net_global.to(args.device), idx=idx, lr=args.lr, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 488, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 55152 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
Traceback (most recent call last):
  File "main_apfl.py", line 147, in <module>
    w_global, w_local, loss, indd = local.train(net=net_local.to(args.device),w_local=w_local, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 354, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 50271 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Traceback (most recent call last):
  File "main_scaffold.py", line 150, in <module>
    w_local, loss, indd, count = local.train(net=net_local.to(args.device), idx=idx, lr=lr, c_list=c_list, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 237, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 56720 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_pfedme.py", line 236, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx],w_locals = w_locals)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 808, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 51776 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.014, Test loss: 1.059, Test accuracy: 40.12 

Round   0, Global train loss: 1.014, Global test loss: 1.102, Global test accuracy: 35.58 

Round   1, Train loss: 0.924, Test loss: 1.002, Test accuracy: 46.48 

Round   1, Global train loss: 0.924, Global test loss: 1.117, Global test accuracy: 36.45 

Round   2, Train loss: 0.854, Test loss: 0.929, Test accuracy: 53.63 

Round   2, Global train loss: 0.854, Global test loss: 1.118, Global test accuracy: 37.30 

Round   3, Train loss: 0.790, Test loss: 0.907, Test accuracy: 55.95 

Round   3, Global train loss: 0.790, Global test loss: 1.178, Global test accuracy: 36.82 

Round   4, Train loss: 0.765, Test loss: 0.852, Test accuracy: 59.30 

Round   4, Global train loss: 0.765, Global test loss: 1.145, Global test accuracy: 36.20 

Round   5, Train loss: 0.706, Test loss: 0.800, Test accuracy: 63.22 

Round   5, Global train loss: 0.706, Global test loss: 1.196, Global test accuracy: 39.43 

Round   6, Train loss: 0.739, Test loss: 0.764, Test accuracy: 64.93 

Round   6, Global train loss: 0.739, Global test loss: 1.134, Global test accuracy: 34.20 

Round   7, Train loss: 0.675, Test loss: 0.742, Test accuracy: 66.82 

Round   7, Global train loss: 0.675, Global test loss: 1.149, Global test accuracy: 39.80 

Round   8, Train loss: 0.686, Test loss: 0.740, Test accuracy: 67.37 

Round   8, Global train loss: 0.686, Global test loss: 1.153, Global test accuracy: 37.45 

Round   9, Train loss: 0.678, Test loss: 0.714, Test accuracy: 68.27 

Round   9, Global train loss: 0.678, Global test loss: 1.146, Global test accuracy: 38.67 

Round  10, Train loss: 0.596, Test loss: 0.705, Test accuracy: 69.25 

Round  10, Global train loss: 0.596, Global test loss: 1.329, Global test accuracy: 40.23 

Round  11, Train loss: 0.596, Test loss: 0.721, Test accuracy: 68.57 

Round  11, Global train loss: 0.596, Global test loss: 1.134, Global test accuracy: 38.27 

Round  12, Train loss: 0.662, Test loss: 0.716, Test accuracy: 69.18 

Round  12, Global train loss: 0.662, Global test loss: 1.121, Global test accuracy: 39.03 

Round  13, Train loss: 0.561, Test loss: 0.718, Test accuracy: 68.93 

Round  13, Global train loss: 0.561, Global test loss: 1.123, Global test accuracy: 37.70 

Round  14, Train loss: 0.614, Test loss: 0.715, Test accuracy: 69.33 

Round  14, Global train loss: 0.614, Global test loss: 1.182, Global test accuracy: 34.17 

Round  15, Train loss: 0.507, Test loss: 0.711, Test accuracy: 69.45 

Round  15, Global train loss: 0.507, Global test loss: 1.244, Global test accuracy: 36.37 

Round  16, Train loss: 0.522, Test loss: 0.686, Test accuracy: 70.13 

Round  16, Global train loss: 0.522, Global test loss: 1.224, Global test accuracy: 40.57 

Round  17, Train loss: 0.476, Test loss: 0.668, Test accuracy: 71.07 

Round  17, Global train loss: 0.476, Global test loss: 1.263, Global test accuracy: 39.48 

Round  18, Train loss: 0.543, Test loss: 0.678, Test accuracy: 71.23 

Round  18, Global train loss: 0.543, Global test loss: 1.187, Global test accuracy: 39.10 

Round  19, Train loss: 0.453, Test loss: 0.685, Test accuracy: 71.22 

Round  19, Global train loss: 0.453, Global test loss: 1.114, Global test accuracy: 38.37 

Round  20, Train loss: 0.465, Test loss: 0.681, Test accuracy: 71.22 

Round  20, Global train loss: 0.465, Global test loss: 1.155, Global test accuracy: 39.78 

Round  21, Train loss: 0.464, Test loss: 0.658, Test accuracy: 72.37 

Round  21, Global train loss: 0.464, Global test loss: 1.392, Global test accuracy: 37.50 

Round  22, Train loss: 0.533, Test loss: 0.651, Test accuracy: 72.97 

Round  22, Global train loss: 0.533, Global test loss: 1.174, Global test accuracy: 38.83 

Round  23, Train loss: 0.498, Test loss: 0.681, Test accuracy: 72.48 

Round  23, Global train loss: 0.498, Global test loss: 1.188, Global test accuracy: 37.67 

Round  24, Train loss: 0.425, Test loss: 0.687, Test accuracy: 72.88 

Round  24, Global train loss: 0.425, Global test loss: 1.165, Global test accuracy: 39.00 

Round  25, Train loss: 0.359, Test loss: 0.705, Test accuracy: 72.65 

Round  25, Global train loss: 0.359, Global test loss: 1.220, Global test accuracy: 39.10 

Round  26, Train loss: 0.436, Test loss: 0.696, Test accuracy: 73.00 

Round  26, Global train loss: 0.436, Global test loss: 1.156, Global test accuracy: 38.78 

Round  27, Train loss: 0.403, Test loss: 0.709, Test accuracy: 72.52 

Round  27, Global train loss: 0.403, Global test loss: 1.174, Global test accuracy: 34.97 

Round  28, Train loss: 0.342, Test loss: 0.704, Test accuracy: 72.85 

Round  28, Global train loss: 0.342, Global test loss: 1.269, Global test accuracy: 40.53 

Round  29, Train loss: 0.359, Test loss: 0.707, Test accuracy: 72.55 

Round  29, Global train loss: 0.359, Global test loss: 1.256, Global test accuracy: 40.45 

Round  30, Train loss: 0.326, Test loss: 0.711, Test accuracy: 72.78 

Round  30, Global train loss: 0.326, Global test loss: 1.271, Global test accuracy: 35.35 

Round  31, Train loss: 0.300, Test loss: 0.689, Test accuracy: 73.05 

Round  31, Global train loss: 0.300, Global test loss: 1.327, Global test accuracy: 39.18 

Round  32, Train loss: 0.250, Test loss: 0.713, Test accuracy: 73.02 

Round  32, Global train loss: 0.250, Global test loss: 1.385, Global test accuracy: 40.02 

Round  33, Train loss: 0.257, Test loss: 0.726, Test accuracy: 73.00 

Round  33, Global train loss: 0.257, Global test loss: 1.362, Global test accuracy: 39.95 

Round  34, Train loss: 0.310, Test loss: 0.729, Test accuracy: 73.20 

Round  34, Global train loss: 0.310, Global test loss: 1.405, Global test accuracy: 40.65 

Round  35, Train loss: 0.315, Test loss: 0.725, Test accuracy: 73.43 

Round  35, Global train loss: 0.315, Global test loss: 1.479, Global test accuracy: 36.80 

Round  36, Train loss: 0.244, Test loss: 0.740, Test accuracy: 73.42 

Round  36, Global train loss: 0.244, Global test loss: 1.621, Global test accuracy: 39.60 

Round  37, Train loss: 0.239, Test loss: 0.748, Test accuracy: 73.43 

Round  37, Global train loss: 0.239, Global test loss: 1.451, Global test accuracy: 39.83 

Round  38, Train loss: 0.215, Test loss: 0.750, Test accuracy: 73.42 

Round  38, Global train loss: 0.215, Global test loss: 1.483, Global test accuracy: 40.90 

Round  39, Train loss: 0.223, Test loss: 0.751, Test accuracy: 73.93 

Round  39, Global train loss: 0.223, Global test loss: 1.513, Global test accuracy: 39.82 

Round  40, Train loss: 0.334, Test loss: 0.751, Test accuracy: 74.37 

Round  40, Global train loss: 0.334, Global test loss: 1.325, Global test accuracy: 38.08 

Round  41, Train loss: 0.252, Test loss: 0.794, Test accuracy: 73.75 

Round  41, Global train loss: 0.252, Global test loss: 1.283, Global test accuracy: 40.53 

Round  42, Train loss: 0.258, Test loss: 0.785, Test accuracy: 74.48 

Round  42, Global train loss: 0.258, Global test loss: 1.410, Global test accuracy: 40.50 

Round  43, Train loss: 0.203, Test loss: 0.813, Test accuracy: 74.00 

Round  43, Global train loss: 0.203, Global test loss: 1.220, Global test accuracy: 38.70 

Round  44, Train loss: 0.232, Test loss: 0.802, Test accuracy: 74.32 

Round  44, Global train loss: 0.232, Global test loss: 1.305, Global test accuracy: 38.25 

Round  45, Train loss: 0.169, Test loss: 0.824, Test accuracy: 74.45 

Round  45, Global train loss: 0.169, Global test loss: 1.293, Global test accuracy: 40.53 

Round  46, Train loss: 0.307, Test loss: 0.844, Test accuracy: 74.43 

Round  46, Global train loss: 0.307, Global test loss: 1.184, Global test accuracy: 40.03 

Round  47, Train loss: 0.156, Test loss: 0.869, Test accuracy: 73.68 

Round  47, Global train loss: 0.156, Global test loss: 1.415, Global test accuracy: 39.73 

Round  48, Train loss: 0.234, Test loss: 0.873, Test accuracy: 73.52 

Round  48, Global train loss: 0.234, Global test loss: 1.529, Global test accuracy: 39.58 

Round  49, Train loss: 0.220, Test loss: 0.865, Test accuracy: 73.77 

Round  49, Global train loss: 0.220, Global test loss: 1.318, Global test accuracy: 40.07 

Round  50, Train loss: 0.174, Test loss: 0.860, Test accuracy: 74.43 

Round  50, Global train loss: 0.174, Global test loss: 1.707, Global test accuracy: 40.65 

Round  51, Train loss: 0.241, Test loss: 0.859, Test accuracy: 74.50 

Round  51, Global train loss: 0.241, Global test loss: 1.294, Global test accuracy: 38.48 

Round  52, Train loss: 0.138, Test loss: 0.864, Test accuracy: 74.38 

Round  52, Global train loss: 0.138, Global test loss: 1.741, Global test accuracy: 40.57 

Round  53, Train loss: 0.211, Test loss: 0.896, Test accuracy: 74.32 

Round  53, Global train loss: 0.211, Global test loss: 1.693, Global test accuracy: 40.67 

Round  54, Train loss: 0.134, Test loss: 0.888, Test accuracy: 74.65 

Round  54, Global train loss: 0.134, Global test loss: 1.356, Global test accuracy: 40.93 

Round  55, Train loss: 0.189, Test loss: 0.875, Test accuracy: 74.73 

Round  55, Global train loss: 0.189, Global test loss: 1.451, Global test accuracy: 40.73 

Round  56, Train loss: 0.135, Test loss: 0.920, Test accuracy: 74.05 

Round  56, Global train loss: 0.135, Global test loss: 1.377, Global test accuracy: 39.38 

Round  57, Train loss: 0.269, Test loss: 0.920, Test accuracy: 73.77 

Round  57, Global train loss: 0.269, Global test loss: 1.211, Global test accuracy: 36.92 

Round  58, Train loss: 0.153, Test loss: 0.907, Test accuracy: 74.05 

Round  58, Global train loss: 0.153, Global test loss: 1.543, Global test accuracy: 39.20 

Round  59, Train loss: 0.138, Test loss: 0.923, Test accuracy: 73.85 

Round  59, Global train loss: 0.138, Global test loss: 2.000, Global test accuracy: 38.92 

Round  60, Train loss: 0.178, Test loss: 0.910, Test accuracy: 74.87 

Round  60, Global train loss: 0.178, Global test loss: 1.291, Global test accuracy: 32.83 

Round  61, Train loss: 0.187, Test loss: 0.912, Test accuracy: 74.80 

Round  61, Global train loss: 0.187, Global test loss: 1.262, Global test accuracy: 39.08 

Round  62, Train loss: 0.170, Test loss: 0.940, Test accuracy: 74.52 

Round  62, Global train loss: 0.170, Global test loss: 1.251, Global test accuracy: 37.33 

Round  63, Train loss: 0.191, Test loss: 0.948, Test accuracy: 74.58 

Round  63, Global train loss: 0.191, Global test loss: 1.432, Global test accuracy: 40.02 

Round  64, Train loss: 0.150, Test loss: 0.983, Test accuracy: 74.35 

Round  64, Global train loss: 0.150, Global test loss: 1.614, Global test accuracy: 39.67 

Round  65, Train loss: 0.127, Test loss: 0.997, Test accuracy: 74.90 

Round  65, Global train loss: 0.127, Global test loss: 1.428, Global test accuracy: 39.58 

Round  66, Train loss: 0.144, Test loss: 1.018, Test accuracy: 74.68 

Round  66, Global train loss: 0.144, Global test loss: 1.366, Global test accuracy: 38.92 

Round  67, Train loss: 0.143, Test loss: 0.999, Test accuracy: 74.47 

Round  67, Global train loss: 0.143, Global test loss: 1.725, Global test accuracy: 39.00 

Round  68, Train loss: 0.121, Test loss: 1.032, Test accuracy: 74.57 

Round  68, Global train loss: 0.121, Global test loss: 1.403, Global test accuracy: 38.87 

Round  69, Train loss: 0.119, Test loss: 1.028, Test accuracy: 74.57 

Round  69, Global train loss: 0.119, Global test loss: 1.406, Global test accuracy: 40.15 

Round  70, Train loss: 0.126, Test loss: 1.035, Test accuracy: 74.92 

Round  70, Global train loss: 0.126, Global test loss: 1.336, Global test accuracy: 39.78 

Round  71, Train loss: 0.127, Test loss: 1.074, Test accuracy: 74.95 

Round  71, Global train loss: 0.127, Global test loss: 1.617, Global test accuracy: 38.97 

Round  72, Train loss: 0.136, Test loss: 0.984, Test accuracy: 75.50 

Round  72, Global train loss: 0.136, Global test loss: 1.502, Global test accuracy: 34.85 

Round  73, Train loss: 0.106, Test loss: 1.023, Test accuracy: 75.67 

Round  73, Global train loss: 0.106, Global test loss: 1.770, Global test accuracy: 40.33 

Round  74, Train loss: 0.119, Test loss: 1.006, Test accuracy: 76.07 

Round  74, Global train loss: 0.119, Global test loss: 1.341, Global test accuracy: 38.85 

Round  75, Train loss: 0.071, Test loss: 1.009, Test accuracy: 76.18 

Round  75, Global train loss: 0.071, Global test loss: 1.747, Global test accuracy: 39.18 

Round  76, Train loss: 0.077, Test loss: 1.054, Test accuracy: 75.68 

Round  76, Global train loss: 0.077, Global test loss: 1.470, Global test accuracy: 40.13 

Round  77, Train loss: 0.086, Test loss: 1.104, Test accuracy: 74.57 

Round  77, Global train loss: 0.086, Global test loss: 1.818, Global test accuracy: 38.25 

Round  78, Train loss: 0.084, Test loss: 1.108, Test accuracy: 74.85 

Round  78, Global train loss: 0.084, Global test loss: 1.593, Global test accuracy: 39.13 

Round  79, Train loss: 0.118, Test loss: 1.130, Test accuracy: 74.63 

Round  79, Global train loss: 0.118, Global test loss: 1.288, Global test accuracy: 39.70 

Round  80, Train loss: 0.078, Test loss: 1.127, Test accuracy: 74.82 

Round  80, Global train loss: 0.078, Global test loss: 1.706, Global test accuracy: 39.03 

Round  81, Train loss: 0.105, Test loss: 1.162, Test accuracy: 74.55 

Round  81, Global train loss: 0.105, Global test loss: 1.236, Global test accuracy: 38.67 

Round  82, Train loss: 0.076, Test loss: 1.167, Test accuracy: 74.27 

Round  82, Global train loss: 0.076, Global test loss: 1.659, Global test accuracy: 39.82 

Round  83, Train loss: 0.075, Test loss: 1.185, Test accuracy: 74.12 

Round  83, Global train loss: 0.075, Global test loss: 1.430, Global test accuracy: 40.18 

Round  84, Train loss: 0.080, Test loss: 1.176, Test accuracy: 74.58 

Round  84, Global train loss: 0.080, Global test loss: 1.282, Global test accuracy: 38.90 

Round  85, Train loss: 0.106, Test loss: 1.161, Test accuracy: 75.00 

Round  85, Global train loss: 0.106, Global test loss: 1.530, Global test accuracy: 38.67 

Round  86, Train loss: 0.058, Test loss: 1.170, Test accuracy: 75.13 

Round  86, Global train loss: 0.058, Global test loss: 1.905, Global test accuracy: 40.17 

Round  87, Train loss: 0.073, Test loss: 1.162, Test accuracy: 75.12 

Round  87, Global train loss: 0.073, Global test loss: 1.275, Global test accuracy: 38.17 

Round  88, Train loss: 0.058, Test loss: 1.168, Test accuracy: 74.85 

Round  88, Global train loss: 0.058, Global test loss: 1.426, Global test accuracy: 38.52 

Round  89, Train loss: 0.090, Test loss: 1.118, Test accuracy: 75.13 

Round  89, Global train loss: 0.090, Global test loss: 1.347, Global test accuracy: 40.07 

Round  90, Train loss: 0.061, Test loss: 1.138, Test accuracy: 74.93 

Round  90, Global train loss: 0.061, Global test loss: 1.597, Global test accuracy: 40.10 

Round  91, Train loss: 0.074, Test loss: 1.141, Test accuracy: 75.30 

Round  91, Global train loss: 0.074, Global test loss: 1.648, Global test accuracy: 38.80 

Round  92, Train loss: 0.068, Test loss: 1.116, Test accuracy: 74.93 

Round  92, Global train loss: 0.068, Global test loss: 1.504, Global test accuracy: 39.20 

Round  93, Train loss: 0.040, Test loss: 1.143, Test accuracy: 75.42 

Round  93, Global train loss: 0.040, Global test loss: 1.789, Global test accuracy: 39.68 

Round  94, Train loss: 0.047, Test loss: 1.162, Test accuracy: 75.65 

Round  94, Global train loss: 0.047, Global test loss: 1.668, Global test accuracy: 39.40 

Round  95, Train loss: 0.069, Test loss: 1.179, Test accuracy: 75.68 

Round  95, Global train loss: 0.069, Global test loss: 1.765, Global test accuracy: 36.45 

Round  96, Train loss: 0.077, Test loss: 1.173, Test accuracy: 76.23 

Round  96, Global train loss: 0.077, Global test loss: 1.404, Global test accuracy: 39.38 

Round  97, Train loss: 0.063, Test loss: 1.212, Test accuracy: 75.83 

Round  97, Global train loss: 0.063, Global test loss: 1.357, Global test accuracy: 40.50 

Round  98, Train loss: 0.074, Test loss: 1.229, Test accuracy: 75.85 

Round  98, Global train loss: 0.074, Global test loss: 1.727, Global test accuracy: 38.27 

Round  99, Train loss: 0.054, Test loss: 1.196, Test accuracy: 75.82 

Round  99, Global train loss: 0.054, Global test loss: 1.466, Global test accuracy: 38.67 

Final Round, Train loss: 0.061, Test loss: 1.240, Test accuracy: 75.77 

Final Round, Global train loss: 0.061, Global test loss: 1.466, Global test accuracy: 38.67 

Average accuracy final 10 rounds: 75.565 

Average global accuracy final 10 rounds: 39.045 

1083.821478843689
[3.1739518642425537, 4.258780241012573, 5.344536542892456, 6.426468849182129, 7.510746479034424, 8.59360408782959, 9.679131269454956, 10.693217277526855, 11.778017044067383, 12.85903263092041, 13.969640493392944, 15.051429271697998, 16.11093258857727, 17.17081332206726, 18.230326890945435, 19.289959192276, 20.424833059310913, 21.566349506378174, 22.703219413757324, 23.781447887420654, 24.85724425315857, 25.933337926864624, 27.011427879333496, 28.040199756622314, 29.114983320236206, 30.184675216674805, 31.2606360912323, 32.37994360923767, 33.45624756813049, 34.53380060195923, 35.61332392692566, 36.68763756752014, 37.76655292510986, 38.842780113220215, 39.91649603843689, 40.992361068725586, 42.070539474487305, 43.14632487297058, 44.22376203536987, 45.29856729507446, 46.23945498466492, 47.17336130142212, 48.292797327041626, 49.41510820388794, 50.517351150512695, 51.59842085838318, 52.67668151855469, 53.755409240722656, 54.83603239059448, 55.91802930831909, 56.9976589679718, 58.07335376739502, 59.15445947647095, 60.23800349235535, 61.322662115097046, 62.32373261451721, 63.46022963523865, 64.53857493400574, 65.6134090423584, 66.68703174591064, 67.76622438430786, 68.84126281738281, 69.9190559387207, 70.99895095825195, 72.07696628570557, 73.15620970726013, 74.23349785804749, 75.31397557258606, 76.38927793502808, 77.46642565727234, 78.54352617263794, 79.61943531036377, 80.69448685646057, 81.9228584766388, 83.1438570022583, 84.37118649482727, 85.63576126098633, 86.85948467254639, 88.07870602607727, 89.29848384857178, 90.51602554321289, 91.57688546180725, 92.65738987922668, 93.73844337463379, 94.81811571121216, 95.89936780929565, 97.01017689704895, 98.09062767028809, 99.16993808746338, 100.25058078765869, 101.34433436393738, 102.42335963249207, 103.49898672103882, 104.62527799606323, 105.70205450057983, 106.77807354927063, 107.85473084449768, 108.93233561515808, 110.01343560218811, 111.08965158462524, 113.51796078681946]
[40.11666666666667, 46.483333333333334, 53.63333333333333, 55.95, 59.3, 63.21666666666667, 64.93333333333334, 66.81666666666666, 67.36666666666666, 68.26666666666667, 69.25, 68.56666666666666, 69.18333333333334, 68.93333333333334, 69.33333333333333, 69.45, 70.13333333333334, 71.06666666666666, 71.23333333333333, 71.21666666666667, 71.21666666666667, 72.36666666666666, 72.96666666666667, 72.48333333333333, 72.88333333333334, 72.65, 73.0, 72.51666666666667, 72.85, 72.55, 72.78333333333333, 73.05, 73.01666666666667, 73.0, 73.2, 73.43333333333334, 73.41666666666667, 73.43333333333334, 73.41666666666667, 73.93333333333334, 74.36666666666666, 73.75, 74.48333333333333, 74.0, 74.31666666666666, 74.45, 74.43333333333334, 73.68333333333334, 73.51666666666667, 73.76666666666667, 74.43333333333334, 74.5, 74.38333333333334, 74.31666666666666, 74.65, 74.73333333333333, 74.05, 73.76666666666667, 74.05, 73.85, 74.86666666666666, 74.8, 74.51666666666667, 74.58333333333333, 74.35, 74.9, 74.68333333333334, 74.46666666666667, 74.56666666666666, 74.56666666666666, 74.91666666666667, 74.95, 75.5, 75.66666666666667, 76.06666666666666, 76.18333333333334, 75.68333333333334, 74.56666666666666, 74.85, 74.63333333333334, 74.81666666666666, 74.55, 74.26666666666667, 74.11666666666666, 74.58333333333333, 75.0, 75.13333333333334, 75.11666666666666, 74.85, 75.13333333333334, 74.93333333333334, 75.3, 74.93333333333334, 75.41666666666667, 75.65, 75.68333333333334, 76.23333333333333, 75.83333333333333, 75.85, 75.81666666666666, 75.76666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_fedrep.py", line 235, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 662, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307387 (local), 307192 (global); Percentage 99.94 (307192/307387 
)
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_fedrep.py", line 235, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 662, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
4800
4864
107264
107328
299328
299448
307128
307192
307384
307387
# Params: 307387 (local), 307192 (global); Percentage 99.94 (307192/307387)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
Traceback (most recent call last):
  File "main_fedpac_k_means.py", line 291, in <module>
    w_local, loss, indd, class_center_local, class_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_grob_local, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 1457, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 51438 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
Traceback (most recent call last):
  File "main_ditto.py", line 182, in <module>
    w_k, loss, indd = local.train(net=net_global.to(args.device), idx=idx, lr=args.lr, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 488, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 55364 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
Traceback (most recent call last):
  File "main_apfl.py", line 147, in <module>
    w_global, w_local, loss, indd = local.train(net=net_local.to(args.device),w_local=w_local, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 412, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
Traceback (most recent call last):
  File "main_scaffold.py", line 150, in <module>
    w_local, loss, indd, count = local.train(net=net_local.to(args.device), idx=idx, lr=lr, c_list=c_list, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 237, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 53308 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_pfedme.py", line 236, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx],w_locals = w_locals)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 832, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.036, Test loss: 1.050, Test accuracy: 39.72 

Round   0, Global train loss: 1.036, Global test loss: 1.105, Global test accuracy: 34.55 

Round   1, Train loss: 0.864, Test loss: 0.961, Test accuracy: 47.82 

Round   1, Global train loss: 0.864, Global test loss: 1.112, Global test accuracy: 35.07 

Round   2, Train loss: 0.750, Test loss: 0.941, Test accuracy: 51.15 

Round   2, Global train loss: 0.750, Global test loss: 1.141, Global test accuracy: 37.38 

Round   3, Train loss: 0.760, Test loss: 0.830, Test accuracy: 60.00 

Round   3, Global train loss: 0.760, Global test loss: 1.111, Global test accuracy: 37.13 

Round   4, Train loss: 0.742, Test loss: 0.764, Test accuracy: 64.00 

Round   4, Global train loss: 0.742, Global test loss: 1.097, Global test accuracy: 40.10 

Round   5, Train loss: 0.651, Test loss: 0.721, Test accuracy: 67.48 

Round   5, Global train loss: 0.651, Global test loss: 1.169, Global test accuracy: 37.32 

Round   6, Train loss: 0.620, Test loss: 0.674, Test accuracy: 69.92 

Round   6, Global train loss: 0.620, Global test loss: 1.172, Global test accuracy: 35.72 

Round   7, Train loss: 0.567, Test loss: 0.664, Test accuracy: 70.33 

Round   7, Global train loss: 0.567, Global test loss: 1.226, Global test accuracy: 38.98 

Round   8, Train loss: 0.594, Test loss: 0.632, Test accuracy: 72.55 

Round   8, Global train loss: 0.594, Global test loss: 1.148, Global test accuracy: 35.35 

Round   9, Train loss: 0.496, Test loss: 0.639, Test accuracy: 72.10 

Round   9, Global train loss: 0.496, Global test loss: 1.123, Global test accuracy: 40.13 

Round  10, Train loss: 0.552, Test loss: 0.659, Test accuracy: 71.83 

Round  10, Global train loss: 0.552, Global test loss: 1.261, Global test accuracy: 36.10 

Round  11, Train loss: 0.492, Test loss: 0.632, Test accuracy: 72.67 

Round  11, Global train loss: 0.492, Global test loss: 1.228, Global test accuracy: 34.95 

Round  12, Train loss: 0.487, Test loss: 0.600, Test accuracy: 75.17 

Round  12, Global train loss: 0.487, Global test loss: 1.173, Global test accuracy: 34.58 

Round  13, Train loss: 0.491, Test loss: 0.587, Test accuracy: 75.83 

Round  13, Global train loss: 0.491, Global test loss: 1.221, Global test accuracy: 35.68 

Round  14, Train loss: 0.391, Test loss: 0.621, Test accuracy: 74.77 

Round  14, Global train loss: 0.391, Global test loss: 1.259, Global test accuracy: 38.98 

Round  15, Train loss: 0.514, Test loss: 0.602, Test accuracy: 75.57 

Round  15, Global train loss: 0.514, Global test loss: 1.280, Global test accuracy: 38.35 

Round  16, Train loss: 0.458, Test loss: 0.594, Test accuracy: 75.83 

Round  16, Global train loss: 0.458, Global test loss: 1.118, Global test accuracy: 39.05 

Round  17, Train loss: 0.439, Test loss: 0.582, Test accuracy: 76.42 

Round  17, Global train loss: 0.439, Global test loss: 1.207, Global test accuracy: 36.43 

Round  18, Train loss: 0.361, Test loss: 0.565, Test accuracy: 77.75 

Round  18, Global train loss: 0.361, Global test loss: 1.189, Global test accuracy: 39.85 

Round  19, Train loss: 0.412, Test loss: 0.569, Test accuracy: 78.05 

Round  19, Global train loss: 0.412, Global test loss: 1.364, Global test accuracy: 34.95 

Round  20, Train loss: 0.411, Test loss: 0.566, Test accuracy: 78.43 

Round  20, Global train loss: 0.411, Global test loss: 1.112, Global test accuracy: 39.38 

Round  21, Train loss: 0.368, Test loss: 0.600, Test accuracy: 77.72 

Round  21, Global train loss: 0.368, Global test loss: 1.321, Global test accuracy: 38.97 

Round  22, Train loss: 0.380, Test loss: 0.593, Test accuracy: 77.50 

Round  22, Global train loss: 0.380, Global test loss: 1.533, Global test accuracy: 33.58 

Round  23, Train loss: 0.355, Test loss: 0.590, Test accuracy: 77.52 

Round  23, Global train loss: 0.355, Global test loss: 1.163, Global test accuracy: 36.87 

Round  24, Train loss: 0.379, Test loss: 0.595, Test accuracy: 77.58 

Round  24, Global train loss: 0.379, Global test loss: 1.141, Global test accuracy: 38.37 

Round  25, Train loss: 0.279, Test loss: 0.595, Test accuracy: 78.10 

Round  25, Global train loss: 0.279, Global test loss: 1.295, Global test accuracy: 37.57 

Round  26, Train loss: 0.341, Test loss: 0.580, Test accuracy: 78.18 

Round  26, Global train loss: 0.341, Global test loss: 1.612, Global test accuracy: 33.57 

Round  27, Train loss: 0.321, Test loss: 0.580, Test accuracy: 78.55 

Round  27, Global train loss: 0.321, Global test loss: 1.119, Global test accuracy: 40.12 

Round  28, Train loss: 0.331, Test loss: 0.586, Test accuracy: 78.58 

Round  28, Global train loss: 0.331, Global test loss: 1.175, Global test accuracy: 38.12 

Round  29, Train loss: 0.281, Test loss: 0.593, Test accuracy: 78.45 

Round  29, Global train loss: 0.281, Global test loss: 1.289, Global test accuracy: 38.78 

Round  30, Train loss: 0.349, Test loss: 0.605, Test accuracy: 78.25 

Round  30, Global train loss: 0.349, Global test loss: 1.261, Global test accuracy: 36.30 

Round  31, Train loss: 0.292, Test loss: 0.597, Test accuracy: 78.87 

Round  31, Global train loss: 0.292, Global test loss: 1.212, Global test accuracy: 38.52 

Round  32, Train loss: 0.291, Test loss: 0.617, Test accuracy: 78.73 

Round  32, Global train loss: 0.291, Global test loss: 1.218, Global test accuracy: 38.70 

Round  33, Train loss: 0.287, Test loss: 0.627, Test accuracy: 78.88 

Round  33, Global train loss: 0.287, Global test loss: 1.315, Global test accuracy: 39.83 

Round  34, Train loss: 0.238, Test loss: 0.621, Test accuracy: 79.38 

Round  34, Global train loss: 0.238, Global test loss: 1.246, Global test accuracy: 39.03 

Round  35, Train loss: 0.240, Test loss: 0.632, Test accuracy: 79.35 

Round  35, Global train loss: 0.240, Global test loss: 1.973, Global test accuracy: 38.25 

Round  36, Train loss: 0.205, Test loss: 0.630, Test accuracy: 79.77 

Round  36, Global train loss: 0.205, Global test loss: 1.464, Global test accuracy: 40.27 

Round  37, Train loss: 0.221, Test loss: 0.640, Test accuracy: 79.98 

Round  37, Global train loss: 0.221, Global test loss: 1.354, Global test accuracy: 39.08 

Round  38, Train loss: 0.195, Test loss: 0.634, Test accuracy: 79.83 

Round  38, Global train loss: 0.195, Global test loss: 1.905, Global test accuracy: 38.62 

Round  39, Train loss: 0.196, Test loss: 0.651, Test accuracy: 79.72 

Round  39, Global train loss: 0.196, Global test loss: 1.464, Global test accuracy: 36.67 

Round  40, Train loss: 0.199, Test loss: 0.681, Test accuracy: 79.43 

Round  40, Global train loss: 0.199, Global test loss: 1.865, Global test accuracy: 39.88 

Round  41, Train loss: 0.212, Test loss: 0.681, Test accuracy: 79.55 

Round  41, Global train loss: 0.212, Global test loss: 1.755, Global test accuracy: 36.80 

Round  42, Train loss: 0.214, Test loss: 0.702, Test accuracy: 79.23 

Round  42, Global train loss: 0.214, Global test loss: 1.187, Global test accuracy: 39.18 

Round  43, Train loss: 0.201, Test loss: 0.704, Test accuracy: 79.57 

Round  43, Global train loss: 0.201, Global test loss: 1.288, Global test accuracy: 37.48 

Round  44, Train loss: 0.188, Test loss: 0.703, Test accuracy: 79.87 

Round  44, Global train loss: 0.188, Global test loss: 1.244, Global test accuracy: 36.47 

Round  45, Train loss: 0.162, Test loss: 0.689, Test accuracy: 80.28 

Round  45, Global train loss: 0.162, Global test loss: 1.810, Global test accuracy: 39.32 

Round  46, Train loss: 0.189, Test loss: 0.714, Test accuracy: 79.62 

Round  46, Global train loss: 0.189, Global test loss: 1.543, Global test accuracy: 34.52 

Round  47, Train loss: 0.185, Test loss: 0.764, Test accuracy: 78.25 

Round  47, Global train loss: 0.185, Global test loss: 1.373, Global test accuracy: 37.33 

Round  48, Train loss: 0.173, Test loss: 0.748, Test accuracy: 78.93 

Round  48, Global train loss: 0.173, Global test loss: 1.181, Global test accuracy: 39.52 

Round  49, Train loss: 0.132, Test loss: 0.759, Test accuracy: 79.37 

Round  49, Global train loss: 0.132, Global test loss: 1.575, Global test accuracy: 33.20 

Round  50, Train loss: 0.114, Test loss: 0.760, Test accuracy: 79.07 

Round  50, Global train loss: 0.114, Global test loss: 1.480, Global test accuracy: 35.67 

Round  51, Train loss: 0.165, Test loss: 0.748, Test accuracy: 79.30 

Round  51, Global train loss: 0.165, Global test loss: 1.667, Global test accuracy: 37.52 

Round  52, Train loss: 0.150, Test loss: 0.739, Test accuracy: 79.80 

Round  52, Global train loss: 0.150, Global test loss: 1.173, Global test accuracy: 39.43 

Round  53, Train loss: 0.143, Test loss: 0.736, Test accuracy: 80.23 

Round  53, Global train loss: 0.143, Global test loss: 1.887, Global test accuracy: 32.87 

Round  54, Train loss: 0.109, Test loss: 0.754, Test accuracy: 80.35 

Round  54, Global train loss: 0.109, Global test loss: 1.347, Global test accuracy: 37.15 

Round  55, Train loss: 0.155, Test loss: 0.749, Test accuracy: 80.37 

Round  55, Global train loss: 0.155, Global test loss: 1.276, Global test accuracy: 39.43 

Round  56, Train loss: 0.099, Test loss: 0.794, Test accuracy: 79.62 

Round  56, Global train loss: 0.099, Global test loss: 1.329, Global test accuracy: 37.83 

Round  57, Train loss: 0.153, Test loss: 0.790, Test accuracy: 79.63 

Round  57, Global train loss: 0.153, Global test loss: 1.183, Global test accuracy: 39.85 

Round  58, Train loss: 0.142, Test loss: 0.805, Test accuracy: 79.37 

Round  58, Global train loss: 0.142, Global test loss: 1.388, Global test accuracy: 38.87 

Round  59, Train loss: 0.143, Test loss: 0.797, Test accuracy: 78.97 

Round  59, Global train loss: 0.143, Global test loss: 1.411, Global test accuracy: 39.17 

Round  60, Train loss: 0.099, Test loss: 0.811, Test accuracy: 78.65 

Round  60, Global train loss: 0.099, Global test loss: 1.443, Global test accuracy: 38.63 

Round  61, Train loss: 0.124, Test loss: 0.804, Test accuracy: 79.30 

Round  61, Global train loss: 0.124, Global test loss: 1.245, Global test accuracy: 39.02 

Round  62, Train loss: 0.098, Test loss: 0.807, Test accuracy: 79.52 

Round  62, Global train loss: 0.098, Global test loss: 1.368, Global test accuracy: 35.83 

Round  63, Train loss: 0.104, Test loss: 0.813, Test accuracy: 79.98 

Round  63, Global train loss: 0.104, Global test loss: 1.552, Global test accuracy: 35.88 

Round  64, Train loss: 0.103, Test loss: 0.810, Test accuracy: 80.00 

Round  64, Global train loss: 0.103, Global test loss: 1.241, Global test accuracy: 35.83 

Round  65, Train loss: 0.100, Test loss: 0.852, Test accuracy: 79.68 

Round  65, Global train loss: 0.100, Global test loss: 1.374, Global test accuracy: 33.05 

Round  66, Train loss: 0.096, Test loss: 0.858, Test accuracy: 79.83 

Round  66, Global train loss: 0.096, Global test loss: 1.342, Global test accuracy: 39.53 

Round  67, Train loss: 0.071, Test loss: 0.886, Test accuracy: 79.57 

Round  67, Global train loss: 0.071, Global test loss: 1.677, Global test accuracy: 38.38 

Round  68, Train loss: 0.113, Test loss: 0.861, Test accuracy: 80.00 

Round  68, Global train loss: 0.113, Global test loss: 1.302, Global test accuracy: 38.98 

Round  69, Train loss: 0.109, Test loss: 0.846, Test accuracy: 80.23 

Round  69, Global train loss: 0.109, Global test loss: 1.250, Global test accuracy: 36.45 

Round  70, Train loss: 0.111, Test loss: 0.844, Test accuracy: 80.32 

Round  70, Global train loss: 0.111, Global test loss: 1.532, Global test accuracy: 39.72 

Round  71, Train loss: 0.089, Test loss: 0.856, Test accuracy: 80.08 

Round  71, Global train loss: 0.089, Global test loss: 1.304, Global test accuracy: 39.65 

Round  72, Train loss: 0.089, Test loss: 0.856, Test accuracy: 80.02 

Round  72, Global train loss: 0.089, Global test loss: 2.234, Global test accuracy: 34.00 

Round  73, Train loss: 0.084, Test loss: 0.865, Test accuracy: 80.03 

Round  73, Global train loss: 0.084, Global test loss: 1.546, Global test accuracy: 37.73 

Round  74, Train loss: 0.083, Test loss: 0.886, Test accuracy: 80.17 

Round  74, Global train loss: 0.083, Global test loss: 1.363, Global test accuracy: 36.90 

Round  75, Train loss: 0.071, Test loss: 0.934, Test accuracy: 79.67 

Round  75, Global train loss: 0.071, Global test loss: 1.510, Global test accuracy: 39.90 

Round  76, Train loss: 0.074, Test loss: 0.923, Test accuracy: 79.55 

Round  76, Global train loss: 0.074, Global test loss: 1.485, Global test accuracy: 39.43 

Round  77, Train loss: 0.063, Test loss: 0.954, Test accuracy: 79.35 

Round  77, Global train loss: 0.063, Global test loss: 1.348, Global test accuracy: 39.12 

Round  78, Train loss: 0.046, Test loss: 0.978, Test accuracy: 79.35 

Round  78, Global train loss: 0.046, Global test loss: 1.566, Global test accuracy: 39.92 

Round  79, Train loss: 0.082, Test loss: 0.946, Test accuracy: 79.65 

Round  79, Global train loss: 0.082, Global test loss: 1.385, Global test accuracy: 38.47 

Round  80, Train loss: 0.058, Test loss: 0.953, Test accuracy: 79.67 

Round  80, Global train loss: 0.058, Global test loss: 1.724, Global test accuracy: 38.83 

Round  81, Train loss: 0.040, Test loss: 0.954, Test accuracy: 80.07 

Round  81, Global train loss: 0.040, Global test loss: 1.783, Global test accuracy: 38.93 

Round  82, Train loss: 0.089, Test loss: 0.933, Test accuracy: 80.35 

Round  82, Global train loss: 0.089, Global test loss: 1.810, Global test accuracy: 34.45 

Round  83, Train loss: 0.053, Test loss: 0.913, Test accuracy: 80.98 

Round  83, Global train loss: 0.053, Global test loss: 2.160, Global test accuracy: 40.33 

Round  84, Train loss: 0.063, Test loss: 0.923, Test accuracy: 80.60 

Round  84, Global train loss: 0.063, Global test loss: 1.482, Global test accuracy: 33.78 

Round  85, Train loss: 0.060, Test loss: 0.932, Test accuracy: 80.70 

Round  85, Global train loss: 0.060, Global test loss: 1.530, Global test accuracy: 37.33 

Round  86, Train loss: 0.054, Test loss: 0.962, Test accuracy: 81.08 

Round  86, Global train loss: 0.054, Global test loss: 1.740, Global test accuracy: 35.83 

Round  87, Train loss: 0.071, Test loss: 0.949, Test accuracy: 80.87 

Round  87, Global train loss: 0.071, Global test loss: 1.664, Global test accuracy: 34.98 

Round  88, Train loss: 0.059, Test loss: 0.948, Test accuracy: 81.07 

Round  88, Global train loss: 0.059, Global test loss: 1.440, Global test accuracy: 35.03 

Round  89, Train loss: 0.056, Test loss: 0.956, Test accuracy: 81.05 

Round  89, Global train loss: 0.056, Global test loss: 1.509, Global test accuracy: 41.07 

Round  90, Train loss: 0.048, Test loss: 0.962, Test accuracy: 80.82 

Round  90, Global train loss: 0.048, Global test loss: 1.639, Global test accuracy: 37.87 

Round  91, Train loss: 0.055, Test loss: 0.948, Test accuracy: 81.10 

Round  91, Global train loss: 0.055, Global test loss: 2.461, Global test accuracy: 39.33 

Round  92, Train loss: 0.048, Test loss: 0.950, Test accuracy: 81.35 

Round  92, Global train loss: 0.048, Global test loss: 1.948, Global test accuracy: 39.38 

Round  93, Train loss: 0.067, Test loss: 0.987, Test accuracy: 80.73 

Round  93, Global train loss: 0.067, Global test loss: 1.818, Global test accuracy: 35.90 

Round  94, Train loss: 0.056, Test loss: 0.983, Test accuracy: 80.45 

Round  94, Global train loss: 0.056, Global test loss: 1.473, Global test accuracy: 38.73 

Round  95, Train loss: 0.068, Test loss: 0.996, Test accuracy: 79.83 

Round  95, Global train loss: 0.068, Global test loss: 1.975, Global test accuracy: 38.58 

Round  96, Train loss: 0.041, Test loss: 1.020, Test accuracy: 79.80 

Round  96, Global train loss: 0.041, Global test loss: 2.061, Global test accuracy: 38.50 

Round  97, Train loss: 0.041, Test loss: 1.024, Test accuracy: 79.92 

Round  97, Global train loss: 0.041, Global test loss: 1.348, Global test accuracy: 37.32 

Round  98, Train loss: 0.048, Test loss: 1.031, Test accuracy: 80.20 

Round  98, Global train loss: 0.048, Global test loss: 1.589, Global test accuracy: 38.50 

Round  99, Train loss: 0.045, Test loss: 1.010, Test accuracy: 80.42 

Round  99, Global train loss: 0.045, Global test loss: 1.423, Global test accuracy: 38.53 

Final Round, Train loss: 0.043, Test loss: 1.047, Test accuracy: 80.50 

Final Round, Global train loss: 0.043, Global test loss: 1.423, Global test accuracy: 38.53 

Average accuracy final 10 rounds: 80.46166666666667 

Average global accuracy final 10 rounds: 38.265 

1093.1997032165527
[3.220947504043579, 4.366645336151123, 5.497793912887573, 6.627622365951538, 7.758638143539429, 8.901034593582153, 10.035558938980103, 11.166471242904663, 12.310617923736572, 13.583200454711914, 14.808499813079834, 15.944776058197021, 17.026397228240967, 18.109441995620728, 19.187296628952026, 20.267355918884277, 21.391504764556885, 22.517405033111572, 23.64363932609558, 24.770972728729248, 25.89568781852722, 27.022618293762207, 28.151270389556885, 29.277404308319092, 30.401086568832397, 31.52516222000122, 32.60551190376282, 33.68566083908081, 34.7680082321167, 35.872251749038696, 36.95347619056702, 38.03664445877075, 39.11626839637756, 40.20083689689636, 41.286832094192505, 42.398515462875366, 43.47842454910278, 44.55846905708313, 45.635215044021606, 46.71095585823059, 47.78597950935364, 48.86123824119568, 49.94146728515625, 51.02227807044983, 52.10056233406067, 53.18616080284119, 54.31467366218567, 55.436102867126465, 56.517629623413086, 57.65237998962402, 58.73510766029358, 59.81337881088257, 60.89631724357605, 61.98039150238037, 63.06571388244629, 64.15162014961243, 65.2352397441864, 66.32177758216858, 67.40874528884888, 68.49420285224915, 69.57633805274963, 70.66009998321533, 71.74157190322876, 72.82462477684021, 73.90544772148132, 74.99341082572937, 76.0785014629364, 77.29477214813232, 78.45355129241943, 79.53105592727661, 80.60644578933716, 81.67910504341125, 82.75233125686646, 83.83017349243164, 84.90395760536194, 85.98204326629639, 87.05393767356873, 88.13111090660095, 89.20855641365051, 90.28233075141907, 91.36164021492004, 92.44004893302917, 93.51818799972534, 94.59373879432678, 95.66762590408325, 96.74187183380127, 97.82556939125061, 98.93739438056946, 100.01542329788208, 101.09571933746338, 102.18242335319519, 103.2734158039093, 104.35998153686523, 105.44207406044006, 106.53156232833862, 107.61065936088562, 108.69067716598511, 109.79487586021423, 111.01529026031494, 112.23426628112793, 114.66644859313965]
[39.71666666666667, 47.81666666666667, 51.15, 60.0, 64.0, 67.48333333333333, 69.91666666666667, 70.33333333333333, 72.55, 72.1, 71.83333333333333, 72.66666666666667, 75.16666666666667, 75.83333333333333, 74.76666666666667, 75.56666666666666, 75.83333333333333, 76.41666666666667, 77.75, 78.05, 78.43333333333334, 77.71666666666667, 77.5, 77.51666666666667, 77.58333333333333, 78.1, 78.18333333333334, 78.55, 78.58333333333333, 78.45, 78.25, 78.86666666666666, 78.73333333333333, 78.88333333333334, 79.38333333333334, 79.35, 79.76666666666667, 79.98333333333333, 79.83333333333333, 79.71666666666667, 79.43333333333334, 79.55, 79.23333333333333, 79.56666666666666, 79.86666666666666, 80.28333333333333, 79.61666666666666, 78.25, 78.93333333333334, 79.36666666666666, 79.06666666666666, 79.3, 79.8, 80.23333333333333, 80.35, 80.36666666666666, 79.61666666666666, 79.63333333333334, 79.36666666666666, 78.96666666666667, 78.65, 79.3, 79.51666666666667, 79.98333333333333, 80.0, 79.68333333333334, 79.83333333333333, 79.56666666666666, 80.0, 80.23333333333333, 80.31666666666666, 80.08333333333333, 80.01666666666667, 80.03333333333333, 80.16666666666667, 79.66666666666667, 79.55, 79.35, 79.35, 79.65, 79.66666666666667, 80.06666666666666, 80.35, 80.98333333333333, 80.6, 80.7, 81.08333333333333, 80.86666666666666, 81.06666666666666, 81.05, 80.81666666666666, 81.1, 81.35, 80.73333333333333, 80.45, 79.83333333333333, 79.8, 79.91666666666667, 80.2, 80.41666666666667, 80.5]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_fedrep.py", line 235, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 639, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 55978 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307387 (local), 307192 (global); Percentage 99.94 (307192/307387 
)
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_fedrep.py", line 235, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 639, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 53895 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
4800
4864
107264
107328
299328
299448
307128
307192
307384
307387
# Params: 307387 (local), 307192 (global); Percentage 99.94 (307192/307387)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
Traceback (most recent call last):
  File "main_fedpac_k_means.py", line 291, in <module>
    w_local, loss, indd, class_center_local, class_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_grob_local, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 1457, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 56166 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
Traceback (most recent call last):
  File "main_ditto.py", line 182, in <module>
    w_k, loss, indd = local.train(net=net_global.to(args.device), idx=idx, lr=args.lr, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 488, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 56051 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
Traceback (most recent call last):
  File "main_apfl.py", line 147, in <module>
    w_global, w_local, loss, indd = local.train(net=net_local.to(args.device),w_local=w_local, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 412, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
../aten/src/ATen/native/cuda/Loss.cuTraceback (most recent call last):
  File "main_scaffold.py", line 150, in <module>
    w_local, loss, indd, count = local.train(net=net_local.to(args.device), idx=idx, lr=lr, c_list=c_list, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 295, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_pfedme.py", line 236, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx],w_locals = w_locals)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 832, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.033, Test loss: 1.056, Test accuracy: 40.05 

Round   0, Global train loss: 1.033, Global test loss: 1.103, Global test accuracy: 35.58 

Round   1, Train loss: 0.896, Test loss: 0.996, Test accuracy: 46.52 

Round   1, Global train loss: 0.896, Global test loss: 1.133, Global test accuracy: 35.18 

Round   2, Train loss: 0.858, Test loss: 0.910, Test accuracy: 52.65 

Round   2, Global train loss: 0.858, Global test loss: 1.103, Global test accuracy: 35.20 

Round   3, Train loss: 0.783, Test loss: 0.855, Test accuracy: 57.15 

Round   3, Global train loss: 0.783, Global test loss: 1.096, Global test accuracy: 37.20 

Round   4, Train loss: 0.799, Test loss: 0.807, Test accuracy: 60.55 

Round   4, Global train loss: 0.799, Global test loss: 1.111, Global test accuracy: 36.38 

Round   5, Train loss: 0.689, Test loss: 0.770, Test accuracy: 63.87 

Round   5, Global train loss: 0.689, Global test loss: 1.179, Global test accuracy: 34.22 

Round   6, Train loss: 0.767, Test loss: 0.754, Test accuracy: 64.02 

Round   6, Global train loss: 0.767, Global test loss: 1.174, Global test accuracy: 32.72 

Round   7, Train loss: 0.627, Test loss: 0.730, Test accuracy: 66.07 

Round   7, Global train loss: 0.627, Global test loss: 1.110, Global test accuracy: 35.98 

Round   8, Train loss: 0.680, Test loss: 0.711, Test accuracy: 67.92 

Round   8, Global train loss: 0.680, Global test loss: 1.169, Global test accuracy: 33.83 

Round   9, Train loss: 0.599, Test loss: 0.707, Test accuracy: 68.23 

Round   9, Global train loss: 0.599, Global test loss: 1.239, Global test accuracy: 32.88 

Round  10, Train loss: 0.550, Test loss: 0.693, Test accuracy: 69.22 

Round  10, Global train loss: 0.550, Global test loss: 1.172, Global test accuracy: 33.53 

Round  11, Train loss: 0.538, Test loss: 0.685, Test accuracy: 69.68 

Round  11, Global train loss: 0.538, Global test loss: 1.286, Global test accuracy: 34.52 

Round  12, Train loss: 0.621, Test loss: 0.674, Test accuracy: 71.07 

Round  12, Global train loss: 0.621, Global test loss: 1.319, Global test accuracy: 36.55 

Round  13, Train loss: 0.547, Test loss: 0.680, Test accuracy: 71.02 

Round  13, Global train loss: 0.547, Global test loss: 1.135, Global test accuracy: 37.38 

Round  14, Train loss: 0.515, Test loss: 0.670, Test accuracy: 71.68 

Round  14, Global train loss: 0.515, Global test loss: 1.145, Global test accuracy: 34.05 

Round  15, Train loss: 0.460, Test loss: 0.667, Test accuracy: 71.95 

Round  15, Global train loss: 0.460, Global test loss: 1.236, Global test accuracy: 33.00 

Round  16, Train loss: 0.502, Test loss: 0.662, Test accuracy: 72.58 

Round  16, Global train loss: 0.502, Global test loss: 1.173, Global test accuracy: 37.77 

Round  17, Train loss: 0.472, Test loss: 0.669, Test accuracy: 72.52 

Round  17, Global train loss: 0.472, Global test loss: 1.290, Global test accuracy: 34.65 

Round  18, Train loss: 0.596, Test loss: 0.668, Test accuracy: 72.90 

Round  18, Global train loss: 0.596, Global test loss: 1.133, Global test accuracy: 35.80 

Round  19, Train loss: 0.390, Test loss: 0.671, Test accuracy: 73.28 

Round  19, Global train loss: 0.390, Global test loss: 1.340, Global test accuracy: 38.52 

Round  20, Train loss: 0.469, Test loss: 0.671, Test accuracy: 73.55 

Round  20, Global train loss: 0.469, Global test loss: 1.247, Global test accuracy: 35.58 

Round  21, Train loss: 0.445, Test loss: 0.667, Test accuracy: 73.95 

Round  21, Global train loss: 0.445, Global test loss: 1.227, Global test accuracy: 35.22 

Round  22, Train loss: 0.395, Test loss: 0.669, Test accuracy: 73.42 

Round  22, Global train loss: 0.395, Global test loss: 1.195, Global test accuracy: 35.33 

Round  23, Train loss: 0.409, Test loss: 0.668, Test accuracy: 73.58 

Round  23, Global train loss: 0.409, Global test loss: 1.486, Global test accuracy: 37.43 

Round  24, Train loss: 0.440, Test loss: 0.665, Test accuracy: 74.07 

Round  24, Global train loss: 0.440, Global test loss: 1.223, Global test accuracy: 35.15 

Round  25, Train loss: 0.349, Test loss: 0.659, Test accuracy: 74.22 

Round  25, Global train loss: 0.349, Global test loss: 1.393, Global test accuracy: 32.75 

Round  26, Train loss: 0.404, Test loss: 0.663, Test accuracy: 74.55 

Round  26, Global train loss: 0.404, Global test loss: 1.170, Global test accuracy: 35.55 

Round  27, Train loss: 0.365, Test loss: 0.691, Test accuracy: 74.48 

Round  27, Global train loss: 0.365, Global test loss: 1.213, Global test accuracy: 36.03 

Round  28, Train loss: 0.352, Test loss: 0.671, Test accuracy: 75.27 

Round  28, Global train loss: 0.352, Global test loss: 1.270, Global test accuracy: 36.48 

Round  29, Train loss: 0.398, Test loss: 0.671, Test accuracy: 75.68 

Round  29, Global train loss: 0.398, Global test loss: 1.203, Global test accuracy: 34.70 

Round  30, Train loss: 0.280, Test loss: 0.667, Test accuracy: 75.65 

Round  30, Global train loss: 0.280, Global test loss: 1.230, Global test accuracy: 34.27 

Round  31, Train loss: 0.335, Test loss: 0.682, Test accuracy: 75.10 

Round  31, Global train loss: 0.335, Global test loss: 1.199, Global test accuracy: 36.77 

Round  32, Train loss: 0.380, Test loss: 0.679, Test accuracy: 75.28 

Round  32, Global train loss: 0.380, Global test loss: 1.313, Global test accuracy: 34.70 

Round  33, Train loss: 0.303, Test loss: 0.722, Test accuracy: 74.75 

Round  33, Global train loss: 0.303, Global test loss: 1.420, Global test accuracy: 36.47 

Round  34, Train loss: 0.377, Test loss: 0.735, Test accuracy: 74.90 

Round  34, Global train loss: 0.377, Global test loss: 1.280, Global test accuracy: 34.43 

Round  35, Train loss: 0.338, Test loss: 0.730, Test accuracy: 74.92 

Round  35, Global train loss: 0.338, Global test loss: 1.385, Global test accuracy: 34.33 

Round  36, Train loss: 0.323, Test loss: 0.733, Test accuracy: 75.38 

Round  36, Global train loss: 0.323, Global test loss: 1.260, Global test accuracy: 35.93 

Round  37, Train loss: 0.304, Test loss: 0.733, Test accuracy: 75.73 

Round  37, Global train loss: 0.304, Global test loss: 1.191, Global test accuracy: 36.60 

Round  38, Train loss: 0.321, Test loss: 0.745, Test accuracy: 76.12 

Round  38, Global train loss: 0.321, Global test loss: 1.215, Global test accuracy: 35.67 

Round  39, Train loss: 0.331, Test loss: 0.754, Test accuracy: 75.87 

Round  39, Global train loss: 0.331, Global test loss: 1.242, Global test accuracy: 36.35 

Round  40, Train loss: 0.207, Test loss: 0.763, Test accuracy: 75.35 

Round  40, Global train loss: 0.207, Global test loss: 1.509, Global test accuracy: 35.10 

Round  41, Train loss: 0.282, Test loss: 0.770, Test accuracy: 75.60 

Round  41, Global train loss: 0.282, Global test loss: 1.169, Global test accuracy: 36.88 

Round  42, Train loss: 0.297, Test loss: 0.788, Test accuracy: 75.43 

Round  42, Global train loss: 0.297, Global test loss: 1.313, Global test accuracy: 35.83 

Round  43, Train loss: 0.220, Test loss: 0.782, Test accuracy: 75.37 

Round  43, Global train loss: 0.220, Global test loss: 1.534, Global test accuracy: 34.90 

Round  44, Train loss: 0.180, Test loss: 0.817, Test accuracy: 75.48 

Round  44, Global train loss: 0.180, Global test loss: 1.259, Global test accuracy: 35.53 

Round  45, Train loss: 0.186, Test loss: 0.833, Test accuracy: 75.53 

Round  45, Global train loss: 0.186, Global test loss: 1.329, Global test accuracy: 38.42 

Round  46, Train loss: 0.206, Test loss: 0.833, Test accuracy: 75.48 

Round  46, Global train loss: 0.206, Global test loss: 1.535, Global test accuracy: 36.33 

Round  47, Train loss: 0.238, Test loss: 0.830, Test accuracy: 76.20 

Round  47, Global train loss: 0.238, Global test loss: 1.191, Global test accuracy: 34.47 

Round  48, Train loss: 0.163, Test loss: 0.825, Test accuracy: 76.52 

Round  48, Global train loss: 0.163, Global test loss: 1.284, Global test accuracy: 34.12 

Round  49, Train loss: 0.157, Test loss: 0.837, Test accuracy: 76.18 

Round  49, Global train loss: 0.157, Global test loss: 1.524, Global test accuracy: 33.73 

Round  50, Train loss: 0.196, Test loss: 0.848, Test accuracy: 76.57 

Round  50, Global train loss: 0.196, Global test loss: 1.463, Global test accuracy: 34.08 

Round  51, Train loss: 0.196, Test loss: 0.869, Test accuracy: 76.25 

Round  51, Global train loss: 0.196, Global test loss: 1.332, Global test accuracy: 37.43 

Round  52, Train loss: 0.190, Test loss: 0.895, Test accuracy: 75.93 

Round  52, Global train loss: 0.190, Global test loss: 1.565, Global test accuracy: 35.95 

Round  53, Train loss: 0.180, Test loss: 0.866, Test accuracy: 75.85 

Round  53, Global train loss: 0.180, Global test loss: 1.253, Global test accuracy: 36.38 

Round  54, Train loss: 0.207, Test loss: 0.861, Test accuracy: 75.68 

Round  54, Global train loss: 0.207, Global test loss: 1.318, Global test accuracy: 38.22 

Round  55, Train loss: 0.190, Test loss: 0.914, Test accuracy: 75.55 

Round  55, Global train loss: 0.190, Global test loss: 1.642, Global test accuracy: 36.78 

Round  56, Train loss: 0.167, Test loss: 0.895, Test accuracy: 75.97 

Round  56, Global train loss: 0.167, Global test loss: 1.344, Global test accuracy: 34.27 

Round  57, Train loss: 0.137, Test loss: 0.904, Test accuracy: 75.95 

Round  57, Global train loss: 0.137, Global test loss: 1.413, Global test accuracy: 33.42 

Round  58, Train loss: 0.165, Test loss: 0.884, Test accuracy: 76.48 

Round  58, Global train loss: 0.165, Global test loss: 1.709, Global test accuracy: 35.92 

Round  59, Train loss: 0.188, Test loss: 0.918, Test accuracy: 75.63 

Round  59, Global train loss: 0.188, Global test loss: 1.227, Global test accuracy: 38.25 

Round  60, Train loss: 0.133, Test loss: 0.945, Test accuracy: 75.82 

Round  60, Global train loss: 0.133, Global test loss: 1.287, Global test accuracy: 37.43 

Round  61, Train loss: 0.152, Test loss: 0.966, Test accuracy: 75.52 

Round  61, Global train loss: 0.152, Global test loss: 1.624, Global test accuracy: 33.52 

Round  62, Train loss: 0.150, Test loss: 0.974, Test accuracy: 75.60 

Round  62, Global train loss: 0.150, Global test loss: 1.871, Global test accuracy: 33.00 

Round  63, Train loss: 0.178, Test loss: 0.960, Test accuracy: 75.90 

Round  63, Global train loss: 0.178, Global test loss: 1.598, Global test accuracy: 38.08 

Round  64, Train loss: 0.097, Test loss: 0.988, Test accuracy: 75.80 

Round  64, Global train loss: 0.097, Global test loss: 1.371, Global test accuracy: 37.33 

Round  65, Train loss: 0.149, Test loss: 0.999, Test accuracy: 75.25 

Round  65, Global train loss: 0.149, Global test loss: 1.225, Global test accuracy: 36.03 

Round  66, Train loss: 0.129, Test loss: 0.971, Test accuracy: 75.40 

Round  66, Global train loss: 0.129, Global test loss: 1.374, Global test accuracy: 36.40 

Round  67, Train loss: 0.120, Test loss: 0.986, Test accuracy: 75.70 

Round  67, Global train loss: 0.120, Global test loss: 1.343, Global test accuracy: 35.52 

Round  68, Train loss: 0.125, Test loss: 0.988, Test accuracy: 76.03 

Round  68, Global train loss: 0.125, Global test loss: 1.328, Global test accuracy: 34.75 

Round  69, Train loss: 0.120, Test loss: 0.990, Test accuracy: 75.53 

Round  69, Global train loss: 0.120, Global test loss: 1.990, Global test accuracy: 33.58 

Round  70, Train loss: 0.075, Test loss: 0.975, Test accuracy: 76.33 

Round  70, Global train loss: 0.075, Global test loss: 1.241, Global test accuracy: 36.22 

Round  71, Train loss: 0.128, Test loss: 0.985, Test accuracy: 76.20 

Round  71, Global train loss: 0.128, Global test loss: 1.411, Global test accuracy: 34.65 

Round  72, Train loss: 0.087, Test loss: 1.030, Test accuracy: 76.22 

Round  72, Global train loss: 0.087, Global test loss: 2.056, Global test accuracy: 34.02 

Round  73, Train loss: 0.049, Test loss: 1.040, Test accuracy: 76.27 

Round  73, Global train loss: 0.049, Global test loss: 1.551, Global test accuracy: 34.48 

Round  74, Train loss: 0.104, Test loss: 1.039, Test accuracy: 76.42 

Round  74, Global train loss: 0.104, Global test loss: 1.423, Global test accuracy: 36.75 

Round  75, Train loss: 0.086, Test loss: 1.086, Test accuracy: 75.62 

Round  75, Global train loss: 0.086, Global test loss: 1.874, Global test accuracy: 34.62 

Round  76, Train loss: 0.116, Test loss: 1.062, Test accuracy: 76.55 

Round  76, Global train loss: 0.116, Global test loss: 1.515, Global test accuracy: 35.68 

Round  77, Train loss: 0.076, Test loss: 1.056, Test accuracy: 76.98 

Round  77, Global train loss: 0.076, Global test loss: 1.458, Global test accuracy: 35.17 

Round  78, Train loss: 0.123, Test loss: 1.063, Test accuracy: 76.68 

Round  78, Global train loss: 0.123, Global test loss: 1.328, Global test accuracy: 35.17 

Round  79, Train loss: 0.082, Test loss: 1.053, Test accuracy: 76.82 

Round  79, Global train loss: 0.082, Global test loss: 2.041, Global test accuracy: 34.03 

Round  80, Train loss: 0.070, Test loss: 1.068, Test accuracy: 76.77 

Round  80, Global train loss: 0.070, Global test loss: 1.433, Global test accuracy: 35.67 

Round  81, Train loss: 0.106, Test loss: 1.088, Test accuracy: 76.38 

Round  81, Global train loss: 0.106, Global test loss: 1.375, Global test accuracy: 35.47 

Round  82, Train loss: 0.095, Test loss: 1.095, Test accuracy: 76.48 

Round  82, Global train loss: 0.095, Global test loss: 1.891, Global test accuracy: 35.20 

Round  83, Train loss: 0.074, Test loss: 1.114, Test accuracy: 76.53 

Round  83, Global train loss: 0.074, Global test loss: 2.166, Global test accuracy: 33.08 

Round  84, Train loss: 0.096, Test loss: 1.143, Test accuracy: 76.65 

Round  84, Global train loss: 0.096, Global test loss: 1.386, Global test accuracy: 35.00 

Round  85, Train loss: 0.085, Test loss: 1.140, Test accuracy: 76.43 

Round  85, Global train loss: 0.085, Global test loss: 1.726, Global test accuracy: 33.97 

Round  86, Train loss: 0.059, Test loss: 1.160, Test accuracy: 76.52 

Round  86, Global train loss: 0.059, Global test loss: 1.663, Global test accuracy: 33.88 

Round  87, Train loss: 0.090, Test loss: 1.132, Test accuracy: 76.78 

Round  87, Global train loss: 0.090, Global test loss: 1.377, Global test accuracy: 36.75 

Round  88, Train loss: 0.056, Test loss: 1.168, Test accuracy: 76.25 

Round  88, Global train loss: 0.056, Global test loss: 1.456, Global test accuracy: 35.82 

Round  89, Train loss: 0.046, Test loss: 1.174, Test accuracy: 76.48 

Round  89, Global train loss: 0.046, Global test loss: 1.634, Global test accuracy: 33.48 

Round  90, Train loss: 0.061, Test loss: 1.176, Test accuracy: 76.63 

Round  90, Global train loss: 0.061, Global test loss: 1.989, Global test accuracy: 36.75 

Round  91, Train loss: 0.069, Test loss: 1.182, Test accuracy: 76.62 

Round  91, Global train loss: 0.069, Global test loss: 1.464, Global test accuracy: 33.92 

Round  92, Train loss: 0.093, Test loss: 1.157, Test accuracy: 77.05 

Round  92, Global train loss: 0.093, Global test loss: 1.491, Global test accuracy: 35.37 

Round  93, Train loss: 0.051, Test loss: 1.165, Test accuracy: 77.03 

Round  93, Global train loss: 0.051, Global test loss: 1.393, Global test accuracy: 35.07 

Round  94, Train loss: 0.065, Test loss: 1.189, Test accuracy: 77.00 

Round  94, Global train loss: 0.065, Global test loss: 1.293, Global test accuracy: 35.52 

Round  95, Train loss: 0.078, Test loss: 1.184, Test accuracy: 76.98 

Round  95, Global train loss: 0.078, Global test loss: 1.549, Global test accuracy: 34.65 

Round  96, Train loss: 0.044, Test loss: 1.181, Test accuracy: 76.97 

Round  96, Global train loss: 0.044, Global test loss: 1.347, Global test accuracy: 37.35 

Round  97, Train loss: 0.051, Test loss: 1.205, Test accuracy: 76.65 

Round  97, Global train loss: 0.051, Global test loss: 1.634, Global test accuracy: 35.25 

Round  98, Train loss: 0.066, Test loss: 1.180, Test accuracy: 77.00 

Round  98, Global train loss: 0.066, Global test loss: 1.250, Global test accuracy: 36.42 

Round  99, Train loss: 0.065, Test loss: 1.207, Test accuracy: 76.83 

Round  99, Global train loss: 0.065, Global test loss: 1.358, Global test accuracy: 37.25 

Final Round, Train loss: 0.060, Test loss: 1.223, Test accuracy: 75.95 

Final Round, Global train loss: 0.060, Global test loss: 1.358, Global test accuracy: 37.25 

Average accuracy final 10 rounds: 76.87666666666667 

Average global accuracy final 10 rounds: 35.75333333333333 

1095.3532865047455
[3.24666428565979, 4.403831958770752, 5.6945812702178955, 6.852253675460815, 8.012284994125366, 9.114332675933838, 10.254657745361328, 11.3966805934906, 12.530857563018799, 13.667089700698853, 14.805410146713257, 15.938920497894287, 17.07451105117798, 18.209559440612793, 19.347251892089844, 20.48300862312317, 21.6174738407135, 22.75526237487793, 23.891806602478027, 25.028698205947876, 26.167590379714966, 27.309149265289307, 28.446216583251953, 29.585810899734497, 30.722436666488647, 31.854002475738525, 32.992201805114746, 34.12852931022644, 35.226503133773804, 36.31728410720825, 37.41195893287659, 38.50549650192261, 39.59831953048706, 40.68337035179138, 41.77280950546265, 42.86094379425049, 43.94923138618469, 45.07789611816406, 46.171151876449585, 47.26050353050232, 48.39135479927063, 49.485735177993774, 50.585485219955444, 51.683083295822144, 52.774818420410156, 53.86512207984924, 54.95835280418396, 56.05165076255798, 57.14260411262512, 58.24004602432251, 59.32948422431946, 60.42801523208618, 61.528462648391724, 62.62360429763794, 63.72197103500366, 64.82905387878418, 65.93819093704224, 67.02927350997925, 68.15664219856262, 69.24568724632263, 70.33736181259155, 71.42045760154724, 72.5106270313263, 73.64089632034302, 74.73849368095398, 75.8351640701294, 76.93313884735107, 78.02961993217468, 79.12594246864319, 80.2155966758728, 81.305828332901, 82.39166021347046, 83.48211455345154, 84.57126927375793, 85.66232800483704, 86.75397253036499, 87.90316605567932, 89.00659155845642, 90.10620903968811, 91.20987248420715, 92.31323599815369, 93.41400456428528, 94.52887868881226, 95.6190710067749, 96.72761535644531, 97.8266441822052, 98.92324113845825, 100.0240068435669, 101.1373040676117, 102.23872089385986, 103.33181667327881, 104.42526602745056, 105.51809430122375, 106.61311388015747, 107.70796179771423, 108.80244493484497, 109.89667057991028, 110.99576425552368, 112.0992066860199, 113.19086050987244, 115.46861743927002]
[40.05, 46.516666666666666, 52.65, 57.15, 60.55, 63.86666666666667, 64.01666666666667, 66.06666666666666, 67.91666666666667, 68.23333333333333, 69.21666666666667, 69.68333333333334, 71.06666666666666, 71.01666666666667, 71.68333333333334, 71.95, 72.58333333333333, 72.51666666666667, 72.9, 73.28333333333333, 73.55, 73.95, 73.41666666666667, 73.58333333333333, 74.06666666666666, 74.21666666666667, 74.55, 74.48333333333333, 75.26666666666667, 75.68333333333334, 75.65, 75.1, 75.28333333333333, 74.75, 74.9, 74.91666666666667, 75.38333333333334, 75.73333333333333, 76.11666666666666, 75.86666666666666, 75.35, 75.6, 75.43333333333334, 75.36666666666666, 75.48333333333333, 75.53333333333333, 75.48333333333333, 76.2, 76.51666666666667, 76.18333333333334, 76.56666666666666, 76.25, 75.93333333333334, 75.85, 75.68333333333334, 75.55, 75.96666666666667, 75.95, 76.48333333333333, 75.63333333333334, 75.81666666666666, 75.51666666666667, 75.6, 75.9, 75.8, 75.25, 75.4, 75.7, 76.03333333333333, 75.53333333333333, 76.33333333333333, 76.2, 76.21666666666667, 76.26666666666667, 76.41666666666667, 75.61666666666666, 76.55, 76.98333333333333, 76.68333333333334, 76.81666666666666, 76.76666666666667, 76.38333333333334, 76.48333333333333, 76.53333333333333, 76.65, 76.43333333333334, 76.51666666666667, 76.78333333333333, 76.25, 76.48333333333333, 76.63333333333334, 76.61666666666666, 77.05, 77.03333333333333, 77.0, 76.98333333333333, 76.96666666666667, 76.65, 77.0, 76.83333333333333, 75.95]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_fedrep.py", line 235, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 639, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 54169 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307387 (local), 307192 (global); Percentage 99.94 (307192/307387 
)
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_fedrep.py", line 235, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 662, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
4800
4864
107264
107328
299328
299448
307128
307192
307384
307387
# Params: 307387 (local), 307192 (global); Percentage 99.94 (307192/307387)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
Traceback (most recent call last):
  File "main_fedpac_k_means.py", line 291, in <module>
    w_local, loss, indd, class_center_local, class_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_grob_local, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 1498, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
Traceback (most recent call last):
  File "main_ditto.py", line 182, in <module>
    w_k, loss, indd = local.train(net=net_global.to(args.device), idx=idx, lr=args.lr, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 524, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
Traceback (most recent call last):
  File "main_apfl.py", line 147, in <module>
    w_global, w_local, loss, indd = local.train(net=net_local.to(args.device),w_local=w_local, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 412, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
Traceback (most recent call last):
  File "main_scaffold.py", line 150, in <module>
    w_local, loss, indd, count = local.train(net=net_local.to(args.device), idx=idx, lr=lr, c_list=c_list, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 295, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_pfedme.py", line 236, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx],w_locals = w_locals)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 832, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.002, Test loss: 1.046, Test accuracy: 41.32 

Round   0, Global train loss: 1.002, Global test loss: 1.093, Global test accuracy: 37.57 

Round   1, Train loss: 0.895, Test loss: 0.997, Test accuracy: 46.75 

Round   1, Global train loss: 0.895, Global test loss: 1.121, Global test accuracy: 35.75 

Round   2, Train loss: 0.845, Test loss: 0.919, Test accuracy: 52.93 

Round   2, Global train loss: 0.845, Global test loss: 1.095, Global test accuracy: 39.08 

Round   3, Train loss: 0.838, Test loss: 0.891, Test accuracy: 55.60 

Round   3, Global train loss: 0.838, Global test loss: 1.126, Global test accuracy: 40.85 

Round   4, Train loss: 0.747, Test loss: 0.843, Test accuracy: 58.55 

Round   4, Global train loss: 0.747, Global test loss: 1.163, Global test accuracy: 37.02 

Round   5, Train loss: 0.714, Test loss: 0.828, Test accuracy: 61.47 

Round   5, Global train loss: 0.714, Global test loss: 1.203, Global test accuracy: 38.70 

Round   6, Train loss: 0.747, Test loss: 0.775, Test accuracy: 63.40 

Round   6, Global train loss: 0.747, Global test loss: 1.114, Global test accuracy: 39.42 

Round   7, Train loss: 0.759, Test loss: 0.739, Test accuracy: 66.17 

Round   7, Global train loss: 0.759, Global test loss: 1.115, Global test accuracy: 37.55 

Round   8, Train loss: 0.690, Test loss: 0.745, Test accuracy: 66.45 

Round   8, Global train loss: 0.690, Global test loss: 1.136, Global test accuracy: 38.15 

Round   9, Train loss: 0.613, Test loss: 0.766, Test accuracy: 66.53 

Round   9, Global train loss: 0.613, Global test loss: 1.387, Global test accuracy: 36.85 

Round  10, Train loss: 0.618, Test loss: 0.725, Test accuracy: 68.03 

Round  10, Global train loss: 0.618, Global test loss: 1.190, Global test accuracy: 37.38 

Round  11, Train loss: 0.683, Test loss: 0.674, Test accuracy: 71.15 

Round  11, Global train loss: 0.683, Global test loss: 1.123, Global test accuracy: 37.75 

Round  12, Train loss: 0.525, Test loss: 0.655, Test accuracy: 72.17 

Round  12, Global train loss: 0.525, Global test loss: 1.118, Global test accuracy: 39.13 

Round  13, Train loss: 0.568, Test loss: 0.647, Test accuracy: 72.75 

Round  13, Global train loss: 0.568, Global test loss: 1.132, Global test accuracy: 35.07 

Round  14, Train loss: 0.549, Test loss: 0.667, Test accuracy: 71.85 

Round  14, Global train loss: 0.549, Global test loss: 1.235, Global test accuracy: 37.47 

Round  15, Train loss: 0.515, Test loss: 0.648, Test accuracy: 72.58 

Round  15, Global train loss: 0.515, Global test loss: 1.199, Global test accuracy: 37.17 

Round  16, Train loss: 0.468, Test loss: 0.650, Test accuracy: 72.55 

Round  16, Global train loss: 0.468, Global test loss: 1.348, Global test accuracy: 38.30 

Round  17, Train loss: 0.462, Test loss: 0.643, Test accuracy: 72.93 

Round  17, Global train loss: 0.462, Global test loss: 1.220, Global test accuracy: 39.92 

Round  18, Train loss: 0.474, Test loss: 0.642, Test accuracy: 73.23 

Round  18, Global train loss: 0.474, Global test loss: 1.222, Global test accuracy: 39.05 

Round  19, Train loss: 0.426, Test loss: 0.654, Test accuracy: 73.37 

Round  19, Global train loss: 0.426, Global test loss: 1.226, Global test accuracy: 36.68 

Round  20, Train loss: 0.486, Test loss: 0.654, Test accuracy: 73.85 

Round  20, Global train loss: 0.486, Global test loss: 1.198, Global test accuracy: 39.77 

Round  21, Train loss: 0.450, Test loss: 0.658, Test accuracy: 73.80 

Round  21, Global train loss: 0.450, Global test loss: 1.149, Global test accuracy: 36.45 

Round  22, Train loss: 0.381, Test loss: 0.651, Test accuracy: 74.15 

Round  22, Global train loss: 0.381, Global test loss: 1.217, Global test accuracy: 38.47 

Round  23, Train loss: 0.399, Test loss: 0.666, Test accuracy: 73.70 

Round  23, Global train loss: 0.399, Global test loss: 1.316, Global test accuracy: 39.17 

Round  24, Train loss: 0.415, Test loss: 0.654, Test accuracy: 74.15 

Round  24, Global train loss: 0.415, Global test loss: 1.138, Global test accuracy: 38.50 

Round  25, Train loss: 0.343, Test loss: 0.672, Test accuracy: 74.18 

Round  25, Global train loss: 0.343, Global test loss: 1.278, Global test accuracy: 41.33 

Round  26, Train loss: 0.368, Test loss: 0.676, Test accuracy: 74.38 

Round  26, Global train loss: 0.368, Global test loss: 1.235, Global test accuracy: 36.50 

Round  27, Train loss: 0.320, Test loss: 0.670, Test accuracy: 74.43 

Round  27, Global train loss: 0.320, Global test loss: 1.160, Global test accuracy: 38.35 

Round  28, Train loss: 0.434, Test loss: 0.685, Test accuracy: 74.22 

Round  28, Global train loss: 0.434, Global test loss: 1.170, Global test accuracy: 36.90 

Round  29, Train loss: 0.397, Test loss: 0.672, Test accuracy: 74.37 

Round  29, Global train loss: 0.397, Global test loss: 1.142, Global test accuracy: 38.97 

Round  30, Train loss: 0.340, Test loss: 0.647, Test accuracy: 75.72 

Round  30, Global train loss: 0.340, Global test loss: 1.287, Global test accuracy: 39.33 

Round  31, Train loss: 0.419, Test loss: 0.653, Test accuracy: 75.48 

Round  31, Global train loss: 0.419, Global test loss: 1.458, Global test accuracy: 35.17 

Round  32, Train loss: 0.366, Test loss: 0.681, Test accuracy: 75.23 

Round  32, Global train loss: 0.366, Global test loss: 1.152, Global test accuracy: 39.57 

Round  33, Train loss: 0.321, Test loss: 0.674, Test accuracy: 75.67 

Round  33, Global train loss: 0.321, Global test loss: 1.236, Global test accuracy: 33.80 

Round  34, Train loss: 0.327, Test loss: 0.679, Test accuracy: 75.95 

Round  34, Global train loss: 0.327, Global test loss: 1.144, Global test accuracy: 35.17 

Round  35, Train loss: 0.284, Test loss: 0.690, Test accuracy: 76.03 

Round  35, Global train loss: 0.284, Global test loss: 1.327, Global test accuracy: 36.32 

Round  36, Train loss: 0.292, Test loss: 0.728, Test accuracy: 75.67 

Round  36, Global train loss: 0.292, Global test loss: 1.220, Global test accuracy: 36.77 

Round  37, Train loss: 0.291, Test loss: 0.717, Test accuracy: 75.97 

Round  37, Global train loss: 0.291, Global test loss: 1.207, Global test accuracy: 34.82 

Round  38, Train loss: 0.325, Test loss: 0.701, Test accuracy: 76.08 

Round  38, Global train loss: 0.325, Global test loss: 1.199, Global test accuracy: 35.48 

Round  39, Train loss: 0.292, Test loss: 0.705, Test accuracy: 76.02 

Round  39, Global train loss: 0.292, Global test loss: 1.307, Global test accuracy: 33.40 

Round  40, Train loss: 0.253, Test loss: 0.720, Test accuracy: 75.92 

Round  40, Global train loss: 0.253, Global test loss: 1.199, Global test accuracy: 39.48 

Round  41, Train loss: 0.237, Test loss: 0.740, Test accuracy: 75.42 

Round  41, Global train loss: 0.237, Global test loss: 1.197, Global test accuracy: 36.97 

Round  42, Train loss: 0.276, Test loss: 0.743, Test accuracy: 75.93 

Round  42, Global train loss: 0.276, Global test loss: 1.245, Global test accuracy: 37.88 

Round  43, Train loss: 0.204, Test loss: 0.772, Test accuracy: 75.77 

Round  43, Global train loss: 0.204, Global test loss: 1.243, Global test accuracy: 38.25 

Round  44, Train loss: 0.180, Test loss: 0.788, Test accuracy: 75.67 

Round  44, Global train loss: 0.180, Global test loss: 1.415, Global test accuracy: 38.22 

Round  45, Train loss: 0.184, Test loss: 0.805, Test accuracy: 75.37 

Round  45, Global train loss: 0.184, Global test loss: 1.245, Global test accuracy: 38.45 

Round  46, Train loss: 0.208, Test loss: 0.814, Test accuracy: 75.63 

Round  46, Global train loss: 0.208, Global test loss: 1.132, Global test accuracy: 36.98 

Round  47, Train loss: 0.156, Test loss: 0.814, Test accuracy: 75.15 

Round  47, Global train loss: 0.156, Global test loss: 1.339, Global test accuracy: 38.68 

Round  48, Train loss: 0.222, Test loss: 0.797, Test accuracy: 75.53 

Round  48, Global train loss: 0.222, Global test loss: 1.260, Global test accuracy: 40.02 

Round  49, Train loss: 0.218, Test loss: 0.812, Test accuracy: 75.73 

Round  49, Global train loss: 0.218, Global test loss: 1.327, Global test accuracy: 40.05 

Round  50, Train loss: 0.166, Test loss: 0.815, Test accuracy: 75.45 

Round  50, Global train loss: 0.166, Global test loss: 1.279, Global test accuracy: 38.48 

Round  51, Train loss: 0.173, Test loss: 0.828, Test accuracy: 75.47 

Round  51, Global train loss: 0.173, Global test loss: 1.282, Global test accuracy: 38.00 

Round  52, Train loss: 0.180, Test loss: 0.827, Test accuracy: 75.87 

Round  52, Global train loss: 0.180, Global test loss: 1.446, Global test accuracy: 38.10 

Round  53, Train loss: 0.160, Test loss: 0.836, Test accuracy: 75.93 

Round  53, Global train loss: 0.160, Global test loss: 1.229, Global test accuracy: 38.20 

Round  54, Train loss: 0.135, Test loss: 0.880, Test accuracy: 76.08 

Round  54, Global train loss: 0.135, Global test loss: 1.616, Global test accuracy: 39.15 

Round  55, Train loss: 0.144, Test loss: 0.909, Test accuracy: 75.92 

Round  55, Global train loss: 0.144, Global test loss: 1.297, Global test accuracy: 37.92 

Round  56, Train loss: 0.201, Test loss: 0.913, Test accuracy: 76.48 

Round  56, Global train loss: 0.201, Global test loss: 1.215, Global test accuracy: 36.70 

Round  57, Train loss: 0.165, Test loss: 0.915, Test accuracy: 76.28 

Round  57, Global train loss: 0.165, Global test loss: 1.672, Global test accuracy: 38.40 

Round  58, Train loss: 0.146, Test loss: 0.917, Test accuracy: 76.28 

Round  58, Global train loss: 0.146, Global test loss: 1.212, Global test accuracy: 37.63 

Round  59, Train loss: 0.154, Test loss: 0.927, Test accuracy: 76.00 

Round  59, Global train loss: 0.154, Global test loss: 1.737, Global test accuracy: 37.70 

Round  60, Train loss: 0.113, Test loss: 0.956, Test accuracy: 76.45 

Round  60, Global train loss: 0.113, Global test loss: 1.389, Global test accuracy: 40.27 

Round  61, Train loss: 0.124, Test loss: 0.966, Test accuracy: 76.18 

Round  61, Global train loss: 0.124, Global test loss: 1.401, Global test accuracy: 32.35 

Round  62, Train loss: 0.152, Test loss: 0.935, Test accuracy: 76.72 

Round  62, Global train loss: 0.152, Global test loss: 1.286, Global test accuracy: 37.75 

Round  63, Train loss: 0.146, Test loss: 0.962, Test accuracy: 76.93 

Round  63, Global train loss: 0.146, Global test loss: 1.258, Global test accuracy: 36.90 

Round  64, Train loss: 0.091, Test loss: 0.987, Test accuracy: 76.63 

Round  64, Global train loss: 0.091, Global test loss: 1.312, Global test accuracy: 38.90 

Round  65, Train loss: 0.144, Test loss: 1.010, Test accuracy: 76.63 

Round  65, Global train loss: 0.144, Global test loss: 1.377, Global test accuracy: 37.30 

Round  66, Train loss: 0.095, Test loss: 1.056, Test accuracy: 76.27 

Round  66, Global train loss: 0.095, Global test loss: 1.398, Global test accuracy: 38.05 

Round  67, Train loss: 0.108, Test loss: 1.050, Test accuracy: 76.15 

Round  67, Global train loss: 0.108, Global test loss: 1.179, Global test accuracy: 38.30 

Round  68, Train loss: 0.130, Test loss: 1.043, Test accuracy: 76.05 

Round  68, Global train loss: 0.130, Global test loss: 1.470, Global test accuracy: 38.17 

Round  69, Train loss: 0.106, Test loss: 1.104, Test accuracy: 75.57 

Round  69, Global train loss: 0.106, Global test loss: 1.255, Global test accuracy: 37.48 

Round  70, Train loss: 0.137, Test loss: 1.065, Test accuracy: 75.85 

Round  70, Global train loss: 0.137, Global test loss: 1.314, Global test accuracy: 35.50 

Round  71, Train loss: 0.107, Test loss: 1.032, Test accuracy: 75.97 

Round  71, Global train loss: 0.107, Global test loss: 1.626, Global test accuracy: 36.77 

Round  72, Train loss: 0.118, Test loss: 1.045, Test accuracy: 75.78 

Round  72, Global train loss: 0.118, Global test loss: 1.288, Global test accuracy: 38.65 

Round  73, Train loss: 0.064, Test loss: 1.081, Test accuracy: 75.98 

Round  73, Global train loss: 0.064, Global test loss: 1.768, Global test accuracy: 39.62 

Round  74, Train loss: 0.105, Test loss: 1.052, Test accuracy: 75.55 

Round  74, Global train loss: 0.105, Global test loss: 1.593, Global test accuracy: 36.55 

Round  75, Train loss: 0.083, Test loss: 1.043, Test accuracy: 75.50 

Round  75, Global train loss: 0.083, Global test loss: 1.374, Global test accuracy: 39.18 

Round  76, Train loss: 0.094, Test loss: 1.064, Test accuracy: 75.93 

Round  76, Global train loss: 0.094, Global test loss: 1.450, Global test accuracy: 38.85 

Round  77, Train loss: 0.079, Test loss: 1.104, Test accuracy: 75.92 

Round  77, Global train loss: 0.079, Global test loss: 2.001, Global test accuracy: 39.22 

Round  78, Train loss: 0.092, Test loss: 1.085, Test accuracy: 75.97 

Round  78, Global train loss: 0.092, Global test loss: 1.246, Global test accuracy: 39.92 

Round  79, Train loss: 0.052, Test loss: 1.084, Test accuracy: 76.43 

Round  79, Global train loss: 0.052, Global test loss: 1.448, Global test accuracy: 39.40 

Round  80, Train loss: 0.099, Test loss: 1.093, Test accuracy: 76.57 

Round  80, Global train loss: 0.099, Global test loss: 1.388, Global test accuracy: 32.33 

Round  81, Train loss: 0.118, Test loss: 1.104, Test accuracy: 76.78 

Round  81, Global train loss: 0.118, Global test loss: 1.254, Global test accuracy: 37.47 

Round  82, Train loss: 0.073, Test loss: 1.111, Test accuracy: 76.60 

Round  82, Global train loss: 0.073, Global test loss: 1.511, Global test accuracy: 34.57 

Round  83, Train loss: 0.098, Test loss: 1.109, Test accuracy: 76.35 

Round  83, Global train loss: 0.098, Global test loss: 1.273, Global test accuracy: 38.52 

Round  84, Train loss: 0.068, Test loss: 1.135, Test accuracy: 76.30 

Round  84, Global train loss: 0.068, Global test loss: 1.487, Global test accuracy: 36.83 

Round  85, Train loss: 0.065, Test loss: 1.115, Test accuracy: 76.50 

Round  85, Global train loss: 0.065, Global test loss: 1.382, Global test accuracy: 37.93 

Round  86, Train loss: 0.060, Test loss: 1.143, Test accuracy: 76.48 

Round  86, Global train loss: 0.060, Global test loss: 1.544, Global test accuracy: 38.35 

Round  87, Train loss: 0.056, Test loss: 1.163, Test accuracy: 76.58 

Round  87, Global train loss: 0.056, Global test loss: 1.791, Global test accuracy: 37.00 

Round  88, Train loss: 0.074, Test loss: 1.179, Test accuracy: 76.38 

Round  88, Global train loss: 0.074, Global test loss: 1.440, Global test accuracy: 39.13 

Round  89, Train loss: 0.071, Test loss: 1.139, Test accuracy: 76.92 

Round  89, Global train loss: 0.071, Global test loss: 1.602, Global test accuracy: 37.22 

Round  90, Train loss: 0.046, Test loss: 1.135, Test accuracy: 77.15 

Round  90, Global train loss: 0.046, Global test loss: 1.382, Global test accuracy: 38.70 

Round  91, Train loss: 0.063, Test loss: 1.138, Test accuracy: 77.37 

Round  91, Global train loss: 0.063, Global test loss: 1.448, Global test accuracy: 38.52 

Round  92, Train loss: 0.084, Test loss: 1.157, Test accuracy: 76.90 

Round  92, Global train loss: 0.084, Global test loss: 1.427, Global test accuracy: 40.83 

Round  93, Train loss: 0.081, Test loss: 1.130, Test accuracy: 77.17 

Round  93, Global train loss: 0.081, Global test loss: 1.376, Global test accuracy: 38.10 

Round  94, Train loss: 0.061, Test loss: 1.130, Test accuracy: 77.22 

Round  94, Global train loss: 0.061, Global test loss: 1.527, Global test accuracy: 38.92 

Round  95, Train loss: 0.053, Test loss: 1.144, Test accuracy: 76.95 

Round  95, Global train loss: 0.053, Global test loss: 1.428, Global test accuracy: 36.18 

Round  96, Train loss: 0.039, Test loss: 1.165, Test accuracy: 76.87 

Round  96, Global train loss: 0.039, Global test loss: 1.697, Global test accuracy: 39.10 

Round  97, Train loss: 0.044, Test loss: 1.187, Test accuracy: 76.92 

Round  97, Global train loss: 0.044, Global test loss: 1.290, Global test accuracy: 33.95 

Round  98, Train loss: 0.049, Test loss: 1.188, Test accuracy: 76.72 

Round  98, Global train loss: 0.049, Global test loss: 1.741, Global test accuracy: 40.38 

Round  99, Train loss: 0.055, Test loss: 1.182, Test accuracy: 76.57 

Round  99, Global train loss: 0.055, Global test loss: 1.266, Global test accuracy: 38.27 

Final Round, Train loss: 0.057, Test loss: 1.242, Test accuracy: 76.35 

Final Round, Global train loss: 0.057, Global test loss: 1.266, Global test accuracy: 38.27 

Average accuracy final 10 rounds: 76.98166666666667 

Average global accuracy final 10 rounds: 38.295 

1065.7845194339752
[3.360560178756714, 4.445470094680786, 5.5275492668151855, 6.605856895446777, 7.686131477355957, 8.771195411682129, 9.850053071975708, 10.93237042427063, 12.015459775924683, 13.103453874588013, 14.183156728744507, 15.28542971611023, 16.37239694595337, 17.455389261245728, 18.540605783462524, 19.6223566532135, 20.707547187805176, 21.79156231880188, 22.879836082458496, 23.96332859992981, 25.06108331680298, 26.144935369491577, 27.230249404907227, 28.322639226913452, 29.415796041488647, 30.502000331878662, 31.591646194458008, 32.679750204086304, 33.765220642089844, 34.853362798690796, 35.946754932403564, 37.03164482116699, 38.11885452270508, 39.20285415649414, 40.28955817222595, 41.37695837020874, 42.476452112197876, 43.55373954772949, 44.63536071777344, 45.71360230445862, 46.79277801513672, 47.870471715927124, 48.96949052810669, 50.04571771621704, 51.12442469596863, 52.205395221710205, 53.285656213760376, 54.36683440208435, 55.450085163116455, 56.5354483127594, 57.67989230155945, 58.805466413497925, 59.876577615737915, 60.94235920906067, 62.0063259601593, 63.065755128860474, 64.12647104263306, 65.191232919693, 66.25409817695618, 67.31407380104065, 68.37425136566162, 69.45400810241699, 70.5198245048523, 71.58524584770203, 72.65278482437134, 73.72142362594604, 74.7886745929718, 75.86030006408691, 76.93184685707092, 78.00100040435791, 79.07475399971008, 80.14543628692627, 81.21554470062256, 82.28784823417664, 83.35718107223511, 84.42226457595825, 85.48825454711914, 86.55199146270752, 87.6163113117218, 88.68957304954529, 89.75421738624573, 90.82152652740479, 91.89002108573914, 92.95258140563965, 94.01896357536316, 95.08625817298889, 96.15884208679199, 97.23138070106506, 98.30475974082947, 99.37169766426086, 100.44050645828247, 101.51377463340759, 102.5817928314209, 103.65257382392883, 104.72070097923279, 105.80472254753113, 106.8705747127533, 107.93699240684509, 109.00123763084412, 110.06396579742432, 112.19127416610718]
[41.31666666666667, 46.75, 52.93333333333333, 55.6, 58.55, 61.46666666666667, 63.4, 66.16666666666667, 66.45, 66.53333333333333, 68.03333333333333, 71.15, 72.16666666666667, 72.75, 71.85, 72.58333333333333, 72.55, 72.93333333333334, 73.23333333333333, 73.36666666666666, 73.85, 73.8, 74.15, 73.7, 74.15, 74.18333333333334, 74.38333333333334, 74.43333333333334, 74.21666666666667, 74.36666666666666, 75.71666666666667, 75.48333333333333, 75.23333333333333, 75.66666666666667, 75.95, 76.03333333333333, 75.66666666666667, 75.96666666666667, 76.08333333333333, 76.01666666666667, 75.91666666666667, 75.41666666666667, 75.93333333333334, 75.76666666666667, 75.66666666666667, 75.36666666666666, 75.63333333333334, 75.15, 75.53333333333333, 75.73333333333333, 75.45, 75.46666666666667, 75.86666666666666, 75.93333333333334, 76.08333333333333, 75.91666666666667, 76.48333333333333, 76.28333333333333, 76.28333333333333, 76.0, 76.45, 76.18333333333334, 76.71666666666667, 76.93333333333334, 76.63333333333334, 76.63333333333334, 76.26666666666667, 76.15, 76.05, 75.56666666666666, 75.85, 75.96666666666667, 75.78333333333333, 75.98333333333333, 75.55, 75.5, 75.93333333333334, 75.91666666666667, 75.96666666666667, 76.43333333333334, 76.56666666666666, 76.78333333333333, 76.6, 76.35, 76.3, 76.5, 76.48333333333333, 76.58333333333333, 76.38333333333334, 76.91666666666667, 77.15, 77.36666666666666, 76.9, 77.16666666666667, 77.21666666666667, 76.95, 76.86666666666666, 76.91666666666667, 76.71666666666667, 76.56666666666666, 76.35]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.984, Test loss: 1.048, Test accuracy: 42.42 

Round   0, Global train loss: 0.984, Global test loss: 1.106, Global test accuracy: 37.33 

Round   1, Train loss: 0.913, Test loss: 0.983, Test accuracy: 47.98 

Round   1, Global train loss: 0.913, Global test loss: 1.114, Global test accuracy: 37.22 

Round   2, Train loss: 0.844, Test loss: 0.904, Test accuracy: 54.88 

Round   2, Global train loss: 0.844, Global test loss: 1.114, Global test accuracy: 38.52 

Round   3, Train loss: 0.883, Test loss: 0.853, Test accuracy: 58.33 

Round   3, Global train loss: 0.883, Global test loss: 1.104, Global test accuracy: 38.10 

Round   4, Train loss: 0.767, Test loss: 0.795, Test accuracy: 62.85 

Round   4, Global train loss: 0.767, Global test loss: 1.210, Global test accuracy: 36.37 

Round   5, Train loss: 0.772, Test loss: 0.773, Test accuracy: 64.10 

Round   5, Global train loss: 0.772, Global test loss: 1.173, Global test accuracy: 36.83 

Round   6, Train loss: 0.735, Test loss: 0.728, Test accuracy: 67.70 

Round   6, Global train loss: 0.735, Global test loss: 1.397, Global test accuracy: 40.80 

Round   7, Train loss: 0.690, Test loss: 0.724, Test accuracy: 67.75 

Round   7, Global train loss: 0.690, Global test loss: 1.245, Global test accuracy: 41.17 

Round   8, Train loss: 0.657, Test loss: 0.714, Test accuracy: 68.75 

Round   8, Global train loss: 0.657, Global test loss: 1.288, Global test accuracy: 41.00 

Round   9, Train loss: 0.670, Test loss: 0.691, Test accuracy: 70.03 

Round   9, Global train loss: 0.670, Global test loss: 1.292, Global test accuracy: 39.12 

Round  10, Train loss: 0.662, Test loss: 0.685, Test accuracy: 70.28 

Round  10, Global train loss: 0.662, Global test loss: 1.220, Global test accuracy: 40.53 

Round  11, Train loss: 0.684, Test loss: 0.649, Test accuracy: 72.13 

Round  11, Global train loss: 0.684, Global test loss: 1.308, Global test accuracy: 39.22 

Round  12, Train loss: 0.597, Test loss: 0.662, Test accuracy: 71.97 

Round  12, Global train loss: 0.597, Global test loss: 1.390, Global test accuracy: 40.73 

Round  13, Train loss: 0.583, Test loss: 0.660, Test accuracy: 71.90 

Round  13, Global train loss: 0.583, Global test loss: 1.218, Global test accuracy: 39.98 

Round  14, Train loss: 0.662, Test loss: 0.645, Test accuracy: 72.83 

Round  14, Global train loss: 0.662, Global test loss: 1.266, Global test accuracy: 41.40 

Round  15, Train loss: 0.686, Test loss: 0.643, Test accuracy: 73.17 

Round  15, Global train loss: 0.686, Global test loss: 1.384, Global test accuracy: 35.77 

Round  16, Train loss: 0.627, Test loss: 0.657, Test accuracy: 73.15 

Round  16, Global train loss: 0.627, Global test loss: 1.165, Global test accuracy: 38.52 

Round  17, Train loss: 0.596, Test loss: 0.640, Test accuracy: 73.62 

Round  17, Global train loss: 0.596, Global test loss: 1.198, Global test accuracy: 35.53 

Round  18, Train loss: 0.605, Test loss: 0.628, Test accuracy: 74.00 

Round  18, Global train loss: 0.605, Global test loss: 1.228, Global test accuracy: 36.78 

Round  19, Train loss: 0.639, Test loss: 0.617, Test accuracy: 74.30 

Round  19, Global train loss: 0.639, Global test loss: 1.323, Global test accuracy: 37.03 

Round  20, Train loss: 0.594, Test loss: 0.640, Test accuracy: 73.47 

Round  20, Global train loss: 0.594, Global test loss: 1.294, Global test accuracy: 35.57 

Round  21, Train loss: 0.577, Test loss: 0.620, Test accuracy: 74.42 

Round  21, Global train loss: 0.577, Global test loss: 1.399, Global test accuracy: 36.85 

Round  22, Train loss: 0.622, Test loss: 0.610, Test accuracy: 74.60 

Round  22, Global train loss: 0.622, Global test loss: 1.207, Global test accuracy: 39.48 

Round  23, Train loss: 0.615, Test loss: 0.609, Test accuracy: 74.50 

Round  23, Global train loss: 0.615, Global test loss: 1.511, Global test accuracy: 38.68 

Round  24, Train loss: 0.592, Test loss: 0.613, Test accuracy: 73.85 

Round  24, Global train loss: 0.592, Global test loss: 1.221, Global test accuracy: 38.93 

Round  25, Train loss: 0.607, Test loss: 0.598, Test accuracy: 74.67 

Round  25, Global train loss: 0.607, Global test loss: 1.251, Global test accuracy: 38.23 

Round  26, Train loss: 0.546, Test loss: 0.592, Test accuracy: 74.93 

Round  26, Global train loss: 0.546, Global test loss: 1.270, Global test accuracy: 36.90 

Round  27, Train loss: 0.533, Test loss: 0.601, Test accuracy: 74.85 

Round  27, Global train loss: 0.533, Global test loss: 1.531, Global test accuracy: 42.93 

Round  28, Train loss: 0.534, Test loss: 0.590, Test accuracy: 75.47 

Round  28, Global train loss: 0.534, Global test loss: 1.348, Global test accuracy: 42.15 

Round  29, Train loss: 0.577, Test loss: 0.595, Test accuracy: 75.12 

Round  29, Global train loss: 0.577, Global test loss: 1.430, Global test accuracy: 41.08 

Round  30, Train loss: 0.478, Test loss: 0.591, Test accuracy: 75.52 

Round  30, Global train loss: 0.478, Global test loss: 1.614, Global test accuracy: 40.45 

Round  31, Train loss: 0.467, Test loss: 0.601, Test accuracy: 75.15 

Round  31, Global train loss: 0.467, Global test loss: 1.791, Global test accuracy: 37.47 

Round  32, Train loss: 0.465, Test loss: 0.593, Test accuracy: 75.60 

Round  32, Global train loss: 0.465, Global test loss: 1.536, Global test accuracy: 40.35 

Round  33, Train loss: 0.550, Test loss: 0.594, Test accuracy: 75.55 

Round  33, Global train loss: 0.550, Global test loss: 1.281, Global test accuracy: 39.15 

Round  34, Train loss: 0.546, Test loss: 0.596, Test accuracy: 75.28 

Round  34, Global train loss: 0.546, Global test loss: 1.424, Global test accuracy: 41.58 

Round  35, Train loss: 0.461, Test loss: 0.597, Test accuracy: 75.47 

Round  35, Global train loss: 0.461, Global test loss: 1.292, Global test accuracy: 38.62 

Round  36, Train loss: 0.459, Test loss: 0.606, Test accuracy: 75.27 

Round  36, Global train loss: 0.459, Global test loss: 1.358, Global test accuracy: 39.95 

Round  37, Train loss: 0.464, Test loss: 0.620, Test accuracy: 75.17 

Round  37, Global train loss: 0.464, Global test loss: 1.556, Global test accuracy: 40.52 

Round  38, Train loss: 0.428, Test loss: 0.616, Test accuracy: 75.27 

Round  38, Global train loss: 0.428, Global test loss: 1.316, Global test accuracy: 37.63 

Round  39, Train loss: 0.461, Test loss: 0.624, Test accuracy: 74.58 

Round  39, Global train loss: 0.461, Global test loss: 1.392, Global test accuracy: 39.37 

Round  40, Train loss: 0.444, Test loss: 0.616, Test accuracy: 74.58 

Round  40, Global train loss: 0.444, Global test loss: 1.347, Global test accuracy: 39.48 

Round  41, Train loss: 0.447, Test loss: 0.616, Test accuracy: 75.38 

Round  41, Global train loss: 0.447, Global test loss: 1.394, Global test accuracy: 40.35 

Round  42, Train loss: 0.397, Test loss: 0.622, Test accuracy: 75.12 

Round  42, Global train loss: 0.397, Global test loss: 1.832, Global test accuracy: 36.22 

Round  43, Train loss: 0.497, Test loss: 0.603, Test accuracy: 75.80 

Round  43, Global train loss: 0.497, Global test loss: 1.342, Global test accuracy: 39.68 

Round  44, Train loss: 0.476, Test loss: 0.616, Test accuracy: 75.33 

Round  44, Global train loss: 0.476, Global test loss: 1.265, Global test accuracy: 37.77 

Round  45, Train loss: 0.538, Test loss: 0.628, Test accuracy: 76.08 

Round  45, Global train loss: 0.538, Global test loss: 1.359, Global test accuracy: 37.62 

Round  46, Train loss: 0.439, Test loss: 0.635, Test accuracy: 75.37 

Round  46, Global train loss: 0.439, Global test loss: 1.578, Global test accuracy: 42.10 

Round  47, Train loss: 0.473, Test loss: 0.617, Test accuracy: 76.17 

Round  47, Global train loss: 0.473, Global test loss: 1.582, Global test accuracy: 40.42 

Round  48, Train loss: 0.351, Test loss: 0.618, Test accuracy: 76.25 

Round  48, Global train loss: 0.351, Global test loss: 1.687, Global test accuracy: 40.65 

Round  49, Train loss: 0.504, Test loss: 0.609, Test accuracy: 76.43 

Round  49, Global train loss: 0.504, Global test loss: 1.407, Global test accuracy: 39.38 

Round  50, Train loss: 0.472, Test loss: 0.596, Test accuracy: 76.23 

Round  50, Global train loss: 0.472, Global test loss: 1.384, Global test accuracy: 41.13 

Round  51, Train loss: 0.448, Test loss: 0.607, Test accuracy: 76.27 

Round  51, Global train loss: 0.448, Global test loss: 1.376, Global test accuracy: 36.43 

Round  52, Train loss: 0.453, Test loss: 0.605, Test accuracy: 76.30 

Round  52, Global train loss: 0.453, Global test loss: 1.726, Global test accuracy: 42.20 

Round  53, Train loss: 0.369, Test loss: 0.622, Test accuracy: 75.85 

Round  53, Global train loss: 0.369, Global test loss: 1.686, Global test accuracy: 39.85 

Round  54, Train loss: 0.442, Test loss: 0.624, Test accuracy: 75.67 

Round  54, Global train loss: 0.442, Global test loss: 1.328, Global test accuracy: 37.53 

Round  55, Train loss: 0.437, Test loss: 0.611, Test accuracy: 76.35 

Round  55, Global train loss: 0.437, Global test loss: 1.835, Global test accuracy: 41.23 

Round  56, Train loss: 0.390, Test loss: 0.622, Test accuracy: 76.45 

Round  56, Global train loss: 0.390, Global test loss: 1.470, Global test accuracy: 38.33 

Round  57, Train loss: 0.418, Test loss: 0.632, Test accuracy: 76.15 

Round  57, Global train loss: 0.418, Global test loss: 1.435, Global test accuracy: 40.75 

Round  58, Train loss: 0.440, Test loss: 0.619, Test accuracy: 76.80 

Round  58, Global train loss: 0.440, Global test loss: 1.523, Global test accuracy: 37.47 

Round  59, Train loss: 0.389, Test loss: 0.620, Test accuracy: 76.87 

Round  59, Global train loss: 0.389, Global test loss: 1.397, Global test accuracy: 38.97 

Round  60, Train loss: 0.427, Test loss: 0.624, Test accuracy: 76.57 

Round  60, Global train loss: 0.427, Global test loss: 1.701, Global test accuracy: 41.92 

Round  61, Train loss: 0.375, Test loss: 0.619, Test accuracy: 76.48 

Round  61, Global train loss: 0.375, Global test loss: 1.448, Global test accuracy: 40.05 

Round  62, Train loss: 0.448, Test loss: 0.637, Test accuracy: 76.55 

Round  62, Global train loss: 0.448, Global test loss: 1.565, Global test accuracy: 36.38 

Round  63, Train loss: 0.400, Test loss: 0.657, Test accuracy: 76.08 

Round  63, Global train loss: 0.400, Global test loss: 1.409, Global test accuracy: 37.52 

Round  64, Train loss: 0.390, Test loss: 0.633, Test accuracy: 76.50 

Round  64, Global train loss: 0.390, Global test loss: 1.419, Global test accuracy: 38.87 

Round  65, Train loss: 0.399, Test loss: 0.650, Test accuracy: 76.10 

Round  65, Global train loss: 0.399, Global test loss: 1.615, Global test accuracy: 37.30 

Round  66, Train loss: 0.411, Test loss: 0.641, Test accuracy: 76.52 

Round  66, Global train loss: 0.411, Global test loss: 1.419, Global test accuracy: 39.38 

Round  67, Train loss: 0.336, Test loss: 0.666, Test accuracy: 76.40 

Round  67, Global train loss: 0.336, Global test loss: 1.835, Global test accuracy: 42.23 

Round  68, Train loss: 0.380, Test loss: 0.658, Test accuracy: 76.80 

Round  68, Global train loss: 0.380, Global test loss: 1.420, Global test accuracy: 39.28 

Round  69, Train loss: 0.358, Test loss: 0.665, Test accuracy: 76.82 

Round  69, Global train loss: 0.358, Global test loss: 1.784, Global test accuracy: 42.13 

Round  70, Train loss: 0.313, Test loss: 0.697, Test accuracy: 76.43 

Round  70, Global train loss: 0.313, Global test loss: 1.529, Global test accuracy: 39.40 

Round  71, Train loss: 0.380, Test loss: 0.696, Test accuracy: 76.57 

Round  71, Global train loss: 0.380, Global test loss: 1.499, Global test accuracy: 39.97 

Round  72, Train loss: 0.323, Test loss: 0.700, Test accuracy: 76.20 

Round  72, Global train loss: 0.323, Global test loss: 1.667, Global test accuracy: 38.55 

Round  73, Train loss: 0.348, Test loss: 0.698, Test accuracy: 76.37 

Round  73, Global train loss: 0.348, Global test loss: 1.541, Global test accuracy: 40.93 

Round  74, Train loss: 0.320, Test loss: 0.685, Test accuracy: 76.58 

Round  74, Global train loss: 0.320, Global test loss: 1.691, Global test accuracy: 36.32 

Round  75, Train loss: 0.357, Test loss: 0.664, Test accuracy: 77.08 

Round  75, Global train loss: 0.357, Global test loss: 1.503, Global test accuracy: 40.57 

Round  76, Train loss: 0.312, Test loss: 0.675, Test accuracy: 76.78 

Round  76, Global train loss: 0.312, Global test loss: 1.567, Global test accuracy: 39.27 

Round  77, Train loss: 0.282, Test loss: 0.675, Test accuracy: 76.58 

Round  77, Global train loss: 0.282, Global test loss: 1.548, Global test accuracy: 36.67 

Round  78, Train loss: 0.328, Test loss: 0.679, Test accuracy: 76.87 

Round  78, Global train loss: 0.328, Global test loss: 1.598, Global test accuracy: 35.95 

Round  79, Train loss: 0.352, Test loss: 0.694, Test accuracy: 76.47 

Round  79, Global train loss: 0.352, Global test loss: 2.108, Global test accuracy: 41.98 

Round  80, Train loss: 0.352, Test loss: 0.709, Test accuracy: 76.58 

Round  80, Global train loss: 0.352, Global test loss: 1.530, Global test accuracy: 33.48 

Round  81, Train loss: 0.332, Test loss: 0.698, Test accuracy: 77.45 

Round  81, Global train loss: 0.332, Global test loss: 1.679, Global test accuracy: 39.70 

Round  82, Train loss: 0.310, Test loss: 0.694, Test accuracy: 77.20 

Round  82, Global train loss: 0.310, Global test loss: 1.839, Global test accuracy: 39.67 

Round  83, Train loss: 0.318, Test loss: 0.691, Test accuracy: 77.03 

Round  83, Global train loss: 0.318, Global test loss: 1.704, Global test accuracy: 40.77 

Round  84, Train loss: 0.316, Test loss: 0.681, Test accuracy: 77.13 

Round  84, Global train loss: 0.316, Global test loss: 2.086, Global test accuracy: 38.93 

Round  85, Train loss: 0.298, Test loss: 0.688, Test accuracy: 77.22 

Round  85, Global train loss: 0.298, Global test loss: 1.770, Global test accuracy: 41.47 

Round  86, Train loss: 0.317, Test loss: 0.709, Test accuracy: 76.87 

Round  86, Global train loss: 0.317, Global test loss: 1.727, Global test accuracy: 34.37 

Round  87, Train loss: 0.309, Test loss: 0.717, Test accuracy: 77.13 

Round  87, Global train loss: 0.309, Global test loss: 1.532, Global test accuracy: 37.13 

Round  88, Train loss: 0.247, Test loss: 0.715, Test accuracy: 77.08 

Round  88, Global train loss: 0.247, Global test loss: 1.999, Global test accuracy: 36.63 

Round  89, Train loss: 0.252, Test loss: 0.734, Test accuracy: 76.88 

Round  89, Global train loss: 0.252, Global test loss: 1.842, Global test accuracy: 41.95 

Round  90, Train loss: 0.296, Test loss: 0.709, Test accuracy: 76.78 

Round  90, Global train loss: 0.296, Global test loss: 1.580, Global test accuracy: 40.20 

Round  91, Train loss: 0.240, Test loss: 0.714, Test accuracy: 76.55 

Round  91, Global train loss: 0.240, Global test loss: 2.055, Global test accuracy: 43.00 

Round  92, Train loss: 0.269, Test loss: 0.702, Test accuracy: 77.00 

Round  92, Global train loss: 0.269, Global test loss: 2.238, Global test accuracy: 42.42 

Round  93, Train loss: 0.248, Test loss: 0.708, Test accuracy: 77.45 

Round  93, Global train loss: 0.248, Global test loss: 1.882, Global test accuracy: 40.45 

Round  94, Train loss: 0.332, Test loss: 0.715, Test accuracy: 77.57 

Round  94, Global train loss: 0.332, Global test loss: 2.035, Global test accuracy: 40.87 

Round  95, Train loss: 0.288, Test loss: 0.721, Test accuracy: 77.43 

Round  95, Global train loss: 0.288, Global test loss: 2.072, Global test accuracy: 38.98 

Round  96, Train loss: 0.354, Test loss: 0.717, Test accuracy: 77.35 

Round  96, Global train loss: 0.354, Global test loss: 1.641, Global test accuracy: 33.75 

Round  97, Train loss: 0.242, Test loss: 0.707, Test accuracy: 77.02 

Round  97, Global train loss: 0.242, Global test loss: 2.013, Global test accuracy: 42.83 

Round  98, Train loss: 0.252, Test loss: 0.696, Test accuracy: 77.28 

Round  98, Global train loss: 0.252, Global test loss: 1.629, Global test accuracy: 39.35 

Round  99, Train loss: 0.288, Test loss: 0.708, Test accuracy: 77.35 

Round  99, Global train loss: 0.288, Global test loss: 1.618, Global test accuracy: 35.33 

Final Round, Train loss: 0.209, Test loss: 0.760, Test accuracy: 78.10 

Final Round, Global train loss: 0.209, Global test loss: 1.618, Global test accuracy: 35.33 

Average accuracy final 10 rounds: 77.17833333333333 

Average global accuracy final 10 rounds: 39.718333333333334 

1040.2787704467773
[3.0712411403656006, 4.1516125202178955, 5.218219041824341, 6.281366348266602, 7.345426797866821, 8.410973310470581, 9.472917079925537, 10.539912700653076, 11.604050874710083, 12.684062242507935, 13.738752365112305, 14.795700073242188, 15.851520538330078, 16.909465312957764, 17.971566915512085, 19.032555103302002, 20.09229588508606, 21.1576144695282, 22.21788215637207, 23.279949188232422, 24.34087634086609, 25.398332118988037, 26.454960584640503, 27.51791739463806, 28.583162307739258, 29.641982316970825, 30.69809865951538, 31.75605583190918, 32.812363386154175, 33.868836879730225, 34.927642822265625, 35.983967542648315, 37.04065752029419, 38.110944986343384, 39.1726336479187, 40.23293447494507, 41.30708622932434, 42.36363124847412, 43.42536926269531, 44.482327461242676, 45.54174470901489, 46.595688819885254, 47.42697310447693, 48.2549409866333, 49.08321213722229, 50.14349365234375, 51.20999526977539, 52.27436113357544, 53.337483406066895, 54.39833474159241, 55.45976686477661, 56.54422950744629, 57.60661315917969, 58.67294883728027, 59.73795413970947, 60.81165099143982, 61.8775155544281, 62.94048094749451, 64.00152802467346, 65.08490252494812, 66.1572802066803, 67.22325491905212, 68.28721904754639, 69.35307431221008, 70.41918778419495, 71.48502731323242, 72.54810810089111, 73.61543560028076, 74.67501854896545, 75.74388885498047, 76.8090717792511, 77.87567377090454, 78.94455528259277, 80.01014590263367, 81.0732774734497, 82.13659834861755, 83.21922659873962, 84.28416419029236, 85.34244561195374, 86.40144324302673, 87.46066331863403, 88.52743911743164, 89.5896315574646, 90.65360474586487, 91.7184681892395, 92.7815728187561, 93.84245371818542, 94.90336680412292, 95.96198725700378, 97.02036833763123, 98.08142185211182, 99.14035964012146, 100.19922661781311, 101.28034448623657, 102.34613156318665, 103.40778374671936, 104.47215819358826, 105.53558444976807, 106.59681940078735, 107.65972471237183, 109.80513310432434]
[42.416666666666664, 47.983333333333334, 54.88333333333333, 58.333333333333336, 62.85, 64.1, 67.7, 67.75, 68.75, 70.03333333333333, 70.28333333333333, 72.13333333333334, 71.96666666666667, 71.9, 72.83333333333333, 73.16666666666667, 73.15, 73.61666666666666, 74.0, 74.3, 73.46666666666667, 74.41666666666667, 74.6, 74.5, 73.85, 74.66666666666667, 74.93333333333334, 74.85, 75.46666666666667, 75.11666666666666, 75.51666666666667, 75.15, 75.6, 75.55, 75.28333333333333, 75.46666666666667, 75.26666666666667, 75.16666666666667, 75.26666666666667, 74.58333333333333, 74.58333333333333, 75.38333333333334, 75.11666666666666, 75.8, 75.33333333333333, 76.08333333333333, 75.36666666666666, 76.16666666666667, 76.25, 76.43333333333334, 76.23333333333333, 76.26666666666667, 76.3, 75.85, 75.66666666666667, 76.35, 76.45, 76.15, 76.8, 76.86666666666666, 76.56666666666666, 76.48333333333333, 76.55, 76.08333333333333, 76.5, 76.1, 76.51666666666667, 76.4, 76.8, 76.81666666666666, 76.43333333333334, 76.56666666666666, 76.2, 76.36666666666666, 76.58333333333333, 77.08333333333333, 76.78333333333333, 76.58333333333333, 76.86666666666666, 76.46666666666667, 76.58333333333333, 77.45, 77.2, 77.03333333333333, 77.13333333333334, 77.21666666666667, 76.86666666666666, 77.13333333333334, 77.08333333333333, 76.88333333333334, 76.78333333333333, 76.55, 77.0, 77.45, 77.56666666666666, 77.43333333333334, 77.35, 77.01666666666667, 77.28333333333333, 77.35, 78.1]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307387 (local), 307192 (global); Percentage 99.94 (307192/307387 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.067, Test loss: 1.104, Test accuracy: 34.98 

Round   1, Train loss: 1.017, Test loss: 1.092, Test accuracy: 36.93 

Round   2, Train loss: 0.943, Test loss: 1.020, Test accuracy: 46.60 

Round   3, Train loss: 0.870, Test loss: 1.003, Test accuracy: 46.68 

Round   4, Train loss: 0.842, Test loss: 1.051, Test accuracy: 44.83 

Round   5, Train loss: 0.908, Test loss: 0.967, Test accuracy: 48.45 

Round   6, Train loss: 0.882, Test loss: 0.999, Test accuracy: 49.85 

Round   7, Train loss: 0.836, Test loss: 0.945, Test accuracy: 51.92 

Round   8, Train loss: 0.869, Test loss: 0.847, Test accuracy: 58.95 

Round   9, Train loss: 0.697, Test loss: 0.895, Test accuracy: 57.55 

Round  10, Train loss: 0.812, Test loss: 0.840, Test accuracy: 60.43 

Round  11, Train loss: 0.766, Test loss: 0.842, Test accuracy: 60.68 

Round  12, Train loss: 0.718, Test loss: 0.801, Test accuracy: 62.02 

Round  13, Train loss: 0.725, Test loss: 0.773, Test accuracy: 63.68 

Round  14, Train loss: 0.672, Test loss: 0.743, Test accuracy: 65.93 

Round  15, Train loss: 0.741, Test loss: 0.692, Test accuracy: 69.70 

Round  16, Train loss: 0.602, Test loss: 0.689, Test accuracy: 69.27 

Round  17, Train loss: 0.627, Test loss: 0.680, Test accuracy: 69.53 

Round  18, Train loss: 0.567, Test loss: 0.669, Test accuracy: 70.02 

Round  19, Train loss: 0.689, Test loss: 0.657, Test accuracy: 70.53 

Round  20, Train loss: 0.604, Test loss: 0.660, Test accuracy: 70.37 

Round  21, Train loss: 0.605, Test loss: 0.649, Test accuracy: 70.67 

Round  22, Train loss: 0.565, Test loss: 0.656, Test accuracy: 70.58 

Round  23, Train loss: 0.600, Test loss: 0.626, Test accuracy: 72.05 

Round  24, Train loss: 0.584, Test loss: 0.621, Test accuracy: 72.82 

Round  25, Train loss: 0.562, Test loss: 0.616, Test accuracy: 72.92 

Round  26, Train loss: 0.496, Test loss: 0.619, Test accuracy: 72.55 

Round  27, Train loss: 0.672, Test loss: 0.606, Test accuracy: 73.62 

Round  28, Train loss: 0.643, Test loss: 0.600, Test accuracy: 73.88 

Round  29, Train loss: 0.607, Test loss: 0.599, Test accuracy: 74.05 

Round  30, Train loss: 0.565, Test loss: 0.601, Test accuracy: 74.22 

Round  31, Train loss: 0.486, Test loss: 0.592, Test accuracy: 74.07 

Round  32, Train loss: 0.519, Test loss: 0.598, Test accuracy: 74.82 

Round  33, Train loss: 0.501, Test loss: 0.582, Test accuracy: 74.52 

Round  34, Train loss: 0.546, Test loss: 0.577, Test accuracy: 74.92 

Round  35, Train loss: 0.524, Test loss: 0.571, Test accuracy: 75.08 

Round  36, Train loss: 0.544, Test loss: 0.563, Test accuracy: 75.45 

Round  37, Train loss: 0.616, Test loss: 0.571, Test accuracy: 75.65 

Round  38, Train loss: 0.519, Test loss: 0.571, Test accuracy: 75.52 

Round  39, Train loss: 0.509, Test loss: 0.549, Test accuracy: 76.35 

Round  40, Train loss: 0.483, Test loss: 0.562, Test accuracy: 75.97 

Round  41, Train loss: 0.463, Test loss: 0.557, Test accuracy: 75.83 

Round  42, Train loss: 0.566, Test loss: 0.544, Test accuracy: 76.72 

Round  43, Train loss: 0.503, Test loss: 0.543, Test accuracy: 76.78 

Round  44, Train loss: 0.613, Test loss: 0.536, Test accuracy: 76.83 

Round  45, Train loss: 0.440, Test loss: 0.531, Test accuracy: 77.23 

Round  46, Train loss: 0.493, Test loss: 0.533, Test accuracy: 77.20 

Round  47, Train loss: 0.484, Test loss: 0.531, Test accuracy: 77.28 

Round  48, Train loss: 0.451, Test loss: 0.530, Test accuracy: 77.43 

Round  49, Train loss: 0.472, Test loss: 0.526, Test accuracy: 77.57 

Round  50, Train loss: 0.440, Test loss: 0.525, Test accuracy: 77.77 

Round  51, Train loss: 0.493, Test loss: 0.523, Test accuracy: 77.63 

Round  52, Train loss: 0.452, Test loss: 0.525, Test accuracy: 78.02 

Round  53, Train loss: 0.434, Test loss: 0.514, Test accuracy: 78.38 

Round  54, Train loss: 0.470, Test loss: 0.515, Test accuracy: 78.18 

Round  55, Train loss: 0.386, Test loss: 0.510, Test accuracy: 78.40 

Round  56, Train loss: 0.437, Test loss: 0.512, Test accuracy: 78.48 

Round  57, Train loss: 0.458, Test loss: 0.507, Test accuracy: 78.58 

Round  58, Train loss: 0.479, Test loss: 0.509, Test accuracy: 78.37 

Round  59, Train loss: 0.466, Test loss: 0.501, Test accuracy: 78.58 

Round  60, Train loss: 0.414, Test loss: 0.502, Test accuracy: 79.07 

Round  61, Train loss: 0.420, Test loss: 0.502, Test accuracy: 78.82 

Round  62, Train loss: 0.383, Test loss: 0.509, Test accuracy: 78.70 

Round  63, Train loss: 0.453, Test loss: 0.501, Test accuracy: 78.92 

Round  64, Train loss: 0.486, Test loss: 0.504, Test accuracy: 78.98 

Round  65, Train loss: 0.436, Test loss: 0.495, Test accuracy: 79.55 

Round  66, Train loss: 0.346, Test loss: 0.494, Test accuracy: 79.07 

Round  67, Train loss: 0.417, Test loss: 0.495, Test accuracy: 79.13 

Round  68, Train loss: 0.397, Test loss: 0.490, Test accuracy: 79.52 

Round  69, Train loss: 0.404, Test loss: 0.488, Test accuracy: 79.43 

Round  70, Train loss: 0.412, Test loss: 0.486, Test accuracy: 79.57 

Round  71, Train loss: 0.339, Test loss: 0.488, Test accuracy: 79.42 

Round  72, Train loss: 0.386, Test loss: 0.491, Test accuracy: 79.08 

Round  73, Train loss: 0.307, Test loss: 0.491, Test accuracy: 79.28 

Round  74, Train loss: 0.391, Test loss: 0.487, Test accuracy: 79.57 

Round  75, Train loss: 0.365, Test loss: 0.486, Test accuracy: 79.75 

Round  76, Train loss: 0.382, Test loss: 0.497, Test accuracy: 79.40 

Round  77, Train loss: 0.305, Test loss: 0.489, Test accuracy: 79.93 

Round  78, Train loss: 0.336, Test loss: 0.492, Test accuracy: 79.85 

Round  79, Train loss: 0.359, Test loss: 0.496, Test accuracy: 79.60 

Round  80, Train loss: 0.401, Test loss: 0.501, Test accuracy: 79.27 

Round  81, Train loss: 0.387, Test loss: 0.497, Test accuracy: 79.17 

Round  82, Train loss: 0.367, Test loss: 0.498, Test accuracy: 79.32 

Round  83, Train loss: 0.307, Test loss: 0.496, Test accuracy: 79.18 

Round  84, Train loss: 0.322, Test loss: 0.483, Test accuracy: 79.80 

Round  85, Train loss: 0.360, Test loss: 0.488, Test accuracy: 80.23 

Round  86, Train loss: 0.373, Test loss: 0.494, Test accuracy: 79.82 

Round  87, Train loss: 0.350, Test loss: 0.491, Test accuracy: 79.98 

Round  88, Train loss: 0.366, Test loss: 0.485, Test accuracy: 80.48 

Round  89, Train loss: 0.362, Test loss: 0.488, Test accuracy: 80.02 

Round  90, Train loss: 0.366, Test loss: 0.486, Test accuracy: 80.10 

Round  91, Train loss: 0.362, Test loss: 0.484, Test accuracy: 80.33 

Round  92, Train loss: 0.296, Test loss: 0.482, Test accuracy: 80.20 

Round  93, Train loss: 0.351, Test loss: 0.489, Test accuracy: 79.82 

Round  94, Train loss: 0.235, Test loss: 0.493, Test accuracy: 80.17 

Round  95, Train loss: 0.296, Test loss: 0.503, Test accuracy: 79.83 

Round  96, Train loss: 0.306, Test loss: 0.492, Test accuracy: 80.07 

Round  97, Train loss: 0.355, Test loss: 0.493, Test accuracy: 80.22 

Round  98, Train loss: 0.307, Test loss: 0.495, Test accuracy: 80.07 

Round  99, Train loss: 0.303, Test loss: 0.487, Test accuracy: 80.30 

Final Round, Train loss: 0.273, Test loss: 0.494, Test accuracy: 80.20 

Average accuracy final 10 rounds: 80.11 

791.9416031837463
[2.9360642433166504, 3.8909807205200195, 4.8442912101745605, 5.8030829429626465, 6.759584426879883, 7.711965799331665, 8.66574501991272, 9.621712923049927, 10.57410478591919, 11.525112628936768, 12.476364374160767, 13.425845384597778, 14.37522292137146, 15.32494068145752, 16.275686264038086, 17.228328943252563, 18.174756050109863, 19.12197208404541, 20.069944143295288, 21.018389463424683, 21.967095375061035, 22.918415546417236, 23.86892867088318, 24.81989288330078, 25.769283056259155, 26.719950437545776, 27.669852018356323, 28.618999004364014, 29.565732717514038, 30.51403784751892, 31.462724685668945, 32.41143488883972, 33.35890293121338, 34.31019997596741, 35.260595083236694, 36.2136595249176, 37.16599988937378, 38.11812782287598, 39.06904911994934, 40.01758337020874, 40.968234062194824, 41.915005922317505, 42.86572313308716, 43.821237564086914, 44.76890420913696, 45.71801257133484, 46.66548156738281, 47.6138551235199, 48.56163930892944, 49.511624813079834, 50.45998668670654, 51.40802836418152, 52.35857629776001, 53.30574893951416, 54.254798889160156, 55.20811367034912, 56.156694173812866, 57.10674595832825, 58.0594379901886, 59.008928298950195, 59.95931100845337, 60.90813899040222, 61.857877254486084, 62.807493686676025, 63.76130771636963, 64.71007227897644, 65.65927386283875, 66.64353275299072, 67.6242265701294, 68.5770378112793, 69.525794506073, 70.47469544410706, 71.42406916618347, 72.37347412109375, 73.32302260398865, 74.27050113677979, 75.21937203407288, 76.16826725006104, 77.11694097518921, 78.06753921508789, 79.01230216026306, 79.95831441879272, 80.90881896018982, 81.8547465801239, 82.80170249938965, 83.75261759757996, 84.7059895992279, 85.69229674339294, 86.66922378540039, 87.61945128440857, 88.57325553894043, 89.52207779884338, 90.47464728355408, 91.42439579963684, 92.37271618843079, 93.32006239891052, 94.26756072044373, 95.2156822681427, 96.16738390922546, 97.11731362342834, 98.6494779586792]
[34.983333333333334, 36.93333333333333, 46.6, 46.68333333333333, 44.833333333333336, 48.45, 49.85, 51.916666666666664, 58.95, 57.55, 60.43333333333333, 60.68333333333333, 62.016666666666666, 63.68333333333333, 65.93333333333334, 69.7, 69.26666666666667, 69.53333333333333, 70.01666666666667, 70.53333333333333, 70.36666666666666, 70.66666666666667, 70.58333333333333, 72.05, 72.81666666666666, 72.91666666666667, 72.55, 73.61666666666666, 73.88333333333334, 74.05, 74.21666666666667, 74.06666666666666, 74.81666666666666, 74.51666666666667, 74.91666666666667, 75.08333333333333, 75.45, 75.65, 75.51666666666667, 76.35, 75.96666666666667, 75.83333333333333, 76.71666666666667, 76.78333333333333, 76.83333333333333, 77.23333333333333, 77.2, 77.28333333333333, 77.43333333333334, 77.56666666666666, 77.76666666666667, 77.63333333333334, 78.01666666666667, 78.38333333333334, 78.18333333333334, 78.4, 78.48333333333333, 78.58333333333333, 78.36666666666666, 78.58333333333333, 79.06666666666666, 78.81666666666666, 78.7, 78.91666666666667, 78.98333333333333, 79.55, 79.06666666666666, 79.13333333333334, 79.51666666666667, 79.43333333333334, 79.56666666666666, 79.41666666666667, 79.08333333333333, 79.28333333333333, 79.56666666666666, 79.75, 79.4, 79.93333333333334, 79.85, 79.6, 79.26666666666667, 79.16666666666667, 79.31666666666666, 79.18333333333334, 79.8, 80.23333333333333, 79.81666666666666, 79.98333333333333, 80.48333333333333, 80.01666666666667, 80.1, 80.33333333333333, 80.2, 79.81666666666666, 80.16666666666667, 79.83333333333333, 80.06666666666666, 80.21666666666667, 80.06666666666666, 80.3, 80.2]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
4800
4864
107264
107328
299328
299448
307128
307192
307384
307387
# Params: 307387 (local), 307192 (global); Percentage 99.94 (307192/307387)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
Traceback (most recent call last):
  File "main_fedpac_k_means.py", line 291, in <module>
    w_local, loss, indd, class_center_local, class_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_grob_local, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 1492, in train
    sub_clc = self.features - torch.from_numpy(class_center_batch)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
Round   0, Train loss: 1.022, Test loss: 1.106, Test accuracy: 35.23
Round   1, Train loss: 0.907, Test loss: 1.099, Test accuracy: 35.70
Round   2, Train loss: 0.828, Test loss: 1.137, Test accuracy: 39.67
Round   3, Train loss: 0.741, Test loss: 1.147, Test accuracy: 36.43
Round   4, Train loss: 0.787, Test loss: 1.117, Test accuracy: 39.63
Round   5, Train loss: 0.814, Test loss: 1.198, Test accuracy: 37.57
Round   6, Train loss: 0.770, Test loss: 1.130, Test accuracy: 35.23
Round   7, Train loss: 0.697, Test loss: 1.296, Test accuracy: 37.08
Round   8, Train loss: 0.603, Test loss: 1.334, Test accuracy: 37.72
Round   9, Train loss: 0.615, Test loss: 1.202, Test accuracy: 37.25
Round  10, Train loss: 0.623, Test loss: 1.207, Test accuracy: 39.98
Round  11, Train loss: 0.711, Test loss: 1.265, Test accuracy: 35.73
Round  12, Train loss: 0.563, Test loss: 1.253, Test accuracy: 35.90
Round  13, Train loss: 0.578, Test loss: 1.158, Test accuracy: 39.00
Round  14, Train loss: 0.581, Test loss: 1.432, Test accuracy: 39.10
Round  15, Train loss: 0.660, Test loss: 1.266, Test accuracy: 40.32
Round  16, Train loss: 0.472, Test loss: 1.422, Test accuracy: 36.93
Round  17, Train loss: 0.497, Test loss: 1.454, Test accuracy: 41.42
Round  18, Train loss: 0.583, Test loss: 1.285, Test accuracy: 41.28
Round  19, Train loss: 0.547, Test loss: 1.441, Test accuracy: 41.90
Round  20, Train loss: 0.564, Test loss: 1.393, Test accuracy: 40.62
Round  21, Train loss: 0.543, Test loss: 1.247, Test accuracy: 39.67
Round  22, Train loss: 0.543, Test loss: 1.526, Test accuracy: 39.87
Round  23, Train loss: 0.507, Test loss: 1.236, Test accuracy: 39.98
Round  24, Train loss: 0.487, Test loss: 1.404, Test accuracy: 42.22
Round  25, Train loss: 0.511, Test loss: 1.183, Test accuracy: 39.93
Round  26, Train loss: 0.450, Test loss: 1.603, Test accuracy: 35.27
Round  27, Train loss: 0.520, Test loss: 1.286, Test accuracy: 41.00
Round  28, Train loss: 0.526, Test loss: 1.314, Test accuracy: 39.38
Round  29, Train loss: 0.517, Test loss: 1.287, Test accuracy: 36.85
Round  30, Train loss: 0.455, Test loss: 1.282, Test accuracy: 38.67
Round  31, Train loss: 0.464, Test loss: 1.307, Test accuracy: 41.02
Round  32, Train loss: 0.416, Test loss: 1.441, Test accuracy: 40.57
Round  33, Train loss: 0.422, Test loss: 1.259, Test accuracy: 40.12
Round  34, Train loss: 0.514, Test loss: 1.264, Test accuracy: 39.60
Round  35, Train loss: 0.463, Test loss: 1.564, Test accuracy: 37.23
Round  36, Train loss: 0.413, Test loss: 1.549, Test accuracy: 40.55
Round  37, Train loss: 0.396, Test loss: 1.585, Test accuracy: 41.80
Round  38, Train loss: 0.387, Test loss: 1.537, Test accuracy: 34.93
Round  39, Train loss: 0.427, Test loss: 1.300, Test accuracy: 39.82
Round  40, Train loss: 0.435, Test loss: 1.359, Test accuracy: 33.77
Round  41, Train loss: 0.378, Test loss: 1.388, Test accuracy: 40.12
Round  42, Train loss: 0.376, Test loss: 1.680, Test accuracy: 41.73
Round  43, Train loss: 0.426, Test loss: 1.543, Test accuracy: 39.87
Round  44, Train loss: 0.452, Test loss: 1.305, Test accuracy: 39.82
Round  45, Train loss: 0.414, Test loss: 1.444, Test accuracy: 39.55
Round  46, Train loss: 0.370, Test loss: 1.406, Test accuracy: 41.03
Round  47, Train loss: 0.329, Test loss: 1.488, Test accuracy: 40.00
Round  48, Train loss: 0.282, Test loss: 1.640, Test accuracy: 41.83
Round  49, Train loss: 0.301, Test loss: 1.501, Test accuracy: 40.93
Round  50, Train loss: 0.352, Test loss: 1.542, Test accuracy: 41.53
Round  51, Train loss: 0.316, Test loss: 1.499, Test accuracy: 40.63
Round  52, Train loss: 0.279, Test loss: 1.558, Test accuracy: 41.87
Round  53, Train loss: 0.375, Test loss: 1.370, Test accuracy: 37.65
Round  54, Train loss: 0.269, Test loss: 1.422, Test accuracy: 39.53
Round  55, Train loss: 0.349, Test loss: 1.871, Test accuracy: 39.72
Round  56, Train loss: 0.241, Test loss: 1.640, Test accuracy: 41.50
Round  57, Train loss: 0.342, Test loss: 1.766, Test accuracy: 38.77
Round  58, Train loss: 0.327, Test loss: 1.782, Test accuracy: 41.87
Round  59, Train loss: 0.322, Test loss: 1.369, Test accuracy: 39.42
Round  60, Train loss: 0.280, Test loss: 1.486, Test accuracy: 40.37
Round  61, Train loss: 0.370, Test loss: 1.585, Test accuracy: 41.22
Round  62, Train loss: 0.273, Test loss: 1.758, Test accuracy: 41.28
Round  63, Train loss: 0.349, Test loss: 1.563, Test accuracy: 37.13
Round  64, Train loss: 0.252, Test loss: 1.709, Test accuracy: 40.53
Round  65, Train loss: 0.304, Test loss: 1.530, Test accuracy: 39.45
Round  66, Train loss: 0.297, Test loss: 1.828, Test accuracy: 37.58
Round  67, Train loss: 0.271, Test loss: 1.511, Test accuracy: 36.93
Round  68, Train loss: 0.267, Test loss: 1.795, Test accuracy: 35.25
Round  69, Train loss: 0.314, Test loss: 1.480, Test accuracy: 36.07
Round  70, Train loss: 0.266, Test loss: 1.982, Test accuracy: 42.17
Round  71, Train loss: 0.298, Test loss: 1.510, Test accuracy: 37.55
Round  72, Train loss: 0.294, Test loss: 1.926, Test accuracy: 37.22
Round  73, Train loss: 0.293, Test loss: 1.540, Test accuracy: 36.07
Round  74, Train loss: 0.222, Test loss: 1.682, Test accuracy: 39.53
Round  75, Train loss: 0.254, Test loss: 1.827, Test accuracy: 43.25
Round  76, Train loss: 0.246, Test loss: 1.502, Test accuracy: 39.37
Round  77, Train loss: 0.221, Test loss: 1.688, Test accuracy: 34.85
Round  78, Train loss: 0.283, Test loss: 1.562, Test accuracy: 40.32
Round  79, Train loss: 0.246, Test loss: 1.932, Test accuracy: 41.13
Round  80, Train loss: 0.220, Test loss: 1.521, Test accuracy: 41.70
Round  81, Train loss: 0.274, Test loss: 1.549, Test accuracy: 38.32
Round  82, Train loss: 0.267, Test loss: 1.491, Test accuracy: 37.35
Round  83, Train loss: 0.165, Test loss: 1.810, Test accuracy: 37.98
Round  84, Train loss: 0.215, Test loss: 1.910, Test accuracy: 34.42
Round  85, Train loss: 0.170, Test loss: 1.822, Test accuracy: 40.05
Round  86, Train loss: 0.263, Test loss: 1.696, Test accuracy: 37.70
Round  87, Train loss: 0.209, Test loss: 1.956, Test accuracy: 40.88
Round  88, Train loss: 0.222, Test loss: 2.016, Test accuracy: 42.85
Round  89, Train loss: 0.190, Test loss: 1.663, Test accuracy: 38.53
Round  90, Train loss: 0.208, Test loss: 2.109, Test accuracy: 36.25
Round  91, Train loss: 0.179, Test loss: 1.858, Test accuracy: 33.70
Round  92, Train loss: 0.237, Test loss: 1.749, Test accuracy: 37.15
Round  93, Train loss: 0.149, Test loss: 2.006, Test accuracy: 37.25
Round  94, Train loss: 0.181, Test loss: 1.849, Test accuracy: 36.75
Round  95, Train loss: 0.163, Test loss: 2.056, Test accuracy: 41.70
Round  96, Train loss: 0.183, Test loss: 2.033, Test accuracy: 42.52
Round  97, Train loss: 0.198, Test loss: 1.696, Test accuracy: 40.42
Round  98, Train loss: 0.240, Test loss: 1.739, Test accuracy: 38.77
Round  99, Train loss: 0.189, Test loss: 1.922, Test accuracy: 38.20
Final Round, Train loss: 0.193, Test loss: 1.556, Test accuracy: 40.43
Average accuracy final 10 rounds: 38.269999999999996
1858.9386096000671
[4.9152514934539795, 7.465336799621582, 10.01836895942688, 12.587581634521484, 15.150564670562744, 17.710099458694458, 20.274826765060425, 22.833827257156372, 25.397371530532837, 27.960916757583618, 30.522785663604736, 33.08618116378784, 35.646098375320435, 38.209506034851074, 40.77044367790222, 43.330365896224976, 46.260393381118774, 48.819610595703125, 51.37531805038452, 54.02048921585083, 56.6840500831604, 59.32628035545349, 61.96966814994812, 64.55986976623535, 67.12711501121521, 69.69920468330383, 72.27056980133057, 74.84123492240906, 77.41167259216309, 79.97816109657288, 82.54250621795654, 85.11118936538696, 87.67917013168335, 90.25127291679382, 92.82305479049683, 95.45002293586731, 98.00635552406311, 100.56150078773499, 103.11749839782715, 105.68665528297424, 108.31930446624756, 110.86686062812805, 113.42349600791931, 115.97626042366028, 118.52497982978821, 121.07409763336182, 123.62430500984192, 126.1724910736084, 128.73320722579956, 131.3318202495575, 133.88910508155823, 136.4414200782776, 138.99550557136536, 141.55326223373413, 144.17795538902283, 146.74567699432373, 149.31229305267334, 151.88328886032104, 154.44220209121704, 157.00360298156738, 159.56565070152283, 162.12016344070435, 164.6773087978363, 167.23595094680786, 169.79476237297058, 172.35302758216858, 174.92305517196655, 177.4877314567566, 180.05714440345764, 182.62857484817505, 185.1954791545868, 187.7711901664734, 190.39149641990662, 192.9528887271881, 195.51209449768066, 198.06872367858887, 200.6424596309662, 203.30619597434998, 205.9760308265686, 208.64706707000732, 211.60024642944336, 214.2597463130951, 216.9496784210205, 219.49665021896362, 222.13014125823975, 224.68266558647156, 227.2286388874054, 229.77518916130066, 232.3235046863556, 234.8656485080719, 237.415381193161, 239.98667669296265, 242.5550639629364, 245.45554327964783, 248.69806623458862, 251.95387959480286, 256.44516468048096, 260.0119845867157, 263.61341309547424, 267.4992160797119, 271.40544629096985]
[35.233333333333334, 35.7, 39.666666666666664, 36.43333333333333, 39.63333333333333, 37.56666666666667, 35.233333333333334, 37.083333333333336, 37.71666666666667, 37.25, 39.983333333333334, 35.733333333333334, 35.9, 39.0, 39.1, 40.31666666666667, 36.93333333333333, 41.416666666666664, 41.28333333333333, 41.9, 40.61666666666667, 39.666666666666664, 39.86666666666667, 39.983333333333334, 42.21666666666667, 39.93333333333333, 35.266666666666666, 41.0, 39.38333333333333, 36.85, 38.666666666666664, 41.016666666666666, 40.56666666666667, 40.11666666666667, 39.6, 37.233333333333334, 40.55, 41.8, 34.93333333333333, 39.81666666666667, 33.766666666666666, 40.11666666666667, 41.733333333333334, 39.86666666666667, 39.81666666666667, 39.55, 41.03333333333333, 40.0, 41.833333333333336, 40.93333333333333, 41.53333333333333, 40.63333333333333, 41.86666666666667, 37.65, 39.53333333333333, 39.71666666666667, 41.5, 38.766666666666666, 41.86666666666667, 39.416666666666664, 40.36666666666667, 41.21666666666667, 41.28333333333333, 37.13333333333333, 40.53333333333333, 39.45, 37.583333333333336, 36.93333333333333, 35.25, 36.06666666666667, 42.166666666666664, 37.55, 37.21666666666667, 36.06666666666667, 39.53333333333333, 43.25, 39.36666666666667, 34.85, 40.31666666666667, 41.13333333333333, 41.7, 38.31666666666667, 37.35, 37.983333333333334, 34.416666666666664, 40.05, 37.7, 40.88333333333333, 42.85, 38.53333333333333, 36.25, 33.7, 37.15, 37.25, 36.75, 41.7, 42.516666666666666, 40.416666666666664, 38.766666666666666, 38.2, 40.43333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
Round   0, Train loss: 0.683, Test loss: 1.095, Test accuracy: 37.35
Round   1, Train loss: 0.628, Test loss: 1.097, Test accuracy: 35.80
Round   2, Train loss: 0.599, Test loss: 1.130, Test accuracy: 42.68
Round   3, Train loss: 0.576, Test loss: 1.078, Test accuracy: 47.05
Round   4, Train loss: 0.589, Test loss: 1.071, Test accuracy: 45.22
Round   5, Train loss: 0.559, Test loss: 1.041, Test accuracy: 53.87
Round   6, Train loss: 0.516, Test loss: 1.037, Test accuracy: 54.38
Round   7, Train loss: 0.454, Test loss: 1.031, Test accuracy: 55.98
Round   8, Train loss: 0.452, Test loss: 1.019, Test accuracy: 58.32
Round   9, Train loss: 0.392, Test loss: 1.016, Test accuracy: 58.58
Round  10, Train loss: 0.425, Test loss: 1.013, Test accuracy: 57.95
Round  11, Train loss: 0.415, Test loss: 1.004, Test accuracy: 57.78
Round  12, Train loss: 0.388, Test loss: 1.000, Test accuracy: 58.73
Round  13, Train loss: 0.378, Test loss: 0.991, Test accuracy: 60.35
Round  14, Train loss: 0.325, Test loss: 0.980, Test accuracy: 59.68
Round  15, Train loss: 0.365, Test loss: 0.981, Test accuracy: 59.72
Round  16, Train loss: 0.327, Test loss: 0.969, Test accuracy: 61.57
Round  17, Train loss: 0.341, Test loss: 0.961, Test accuracy: 62.03
Round  18, Train loss: 0.327, Test loss: 0.959, Test accuracy: 61.25
Round  19, Train loss: 0.287, Test loss: 0.955, Test accuracy: 62.40
Round  20, Train loss: 0.307, Test loss: 0.953, Test accuracy: 62.28
Round  21, Train loss: 0.294, Test loss: 0.948, Test accuracy: 63.67
Round  22, Train loss: 0.272, Test loss: 0.940, Test accuracy: 63.75
Round  23, Train loss: 0.308, Test loss: 0.941, Test accuracy: 62.82
Round  24, Train loss: 0.249, Test loss: 0.930, Test accuracy: 62.93
Round  25, Train loss: 0.290, Test loss: 0.922, Test accuracy: 63.75
Round  26, Train loss: 0.239, Test loss: 0.915, Test accuracy: 64.15
Round  27, Train loss: 0.244, Test loss: 0.915, Test accuracy: 64.63
Round  28, Train loss: 0.245, Test loss: 0.914, Test accuracy: 64.38
Round  29, Train loss: 0.290, Test loss: 0.902, Test accuracy: 65.12
Round  30, Train loss: 0.225, Test loss: 0.901, Test accuracy: 65.13
Round  31, Train loss: 0.211, Test loss: 0.901, Test accuracy: 65.58
Round  32, Train loss: 0.192, Test loss: 0.892, Test accuracy: 65.75
Round  33, Train loss: 0.216, Test loss: 0.886, Test accuracy: 66.38
Round  34, Train loss: 0.229, Test loss: 0.881, Test accuracy: 65.90
Round  35, Train loss: 0.265, Test loss: 0.887, Test accuracy: 64.70
Round  36, Train loss: 0.224, Test loss: 0.881, Test accuracy: 65.13
Round  37, Train loss: 0.187, Test loss: 0.874, Test accuracy: 65.50
Round  38, Train loss: 0.205, Test loss: 0.861, Test accuracy: 67.18
Round  39, Train loss: 0.216, Test loss: 0.858, Test accuracy: 67.12
Round  40, Train loss: 0.182, Test loss: 0.853, Test accuracy: 67.67
Round  41, Train loss: 0.157, Test loss: 0.850, Test accuracy: 68.02
Round  42, Train loss: 0.180, Test loss: 0.857, Test accuracy: 65.68
Round  43, Train loss: 0.169, Test loss: 0.845, Test accuracy: 66.62
Round  44, Train loss: 0.187, Test loss: 0.850, Test accuracy: 66.82
Round  45, Train loss: 0.169, Test loss: 0.839, Test accuracy: 67.32
Round  46, Train loss: 0.134, Test loss: 0.835, Test accuracy: 67.73
Round  47, Train loss: 0.164, Test loss: 0.829, Test accuracy: 67.27
Round  48, Train loss: 0.209, Test loss: 0.829, Test accuracy: 66.40
Round  49, Train loss: 0.168, Test loss: 0.825, Test accuracy: 66.13
Round  50, Train loss: 0.138, Test loss: 0.817, Test accuracy: 66.65
Round  51, Train loss: 0.147, Test loss: 0.811, Test accuracy: 67.35
Round  52, Train loss: 0.126, Test loss: 0.799, Test accuracy: 68.43
Round  53, Train loss: 0.122, Test loss: 0.792, Test accuracy: 69.22
Round  54, Train loss: 0.168, Test loss: 0.796, Test accuracy: 68.70
Round  55, Train loss: 0.157, Test loss: 0.792, Test accuracy: 68.35
Round  56, Train loss: 0.115, Test loss: 0.794, Test accuracy: 68.32
Round  57, Train loss: 0.155, Test loss: 0.798, Test accuracy: 67.83
Round  58, Train loss: 0.133, Test loss: 0.804, Test accuracy: 67.30
Round  59, Train loss: 0.122, Test loss: 0.802, Test accuracy: 66.77
Round  60, Train loss: 0.095, Test loss: 0.796, Test accuracy: 66.58
Round  61, Train loss: 0.107, Test loss: 0.786, Test accuracy: 67.98
Round  62, Train loss: 0.087, Test loss: 0.777, Test accuracy: 68.28
Round  63, Train loss: 0.101, Test loss: 0.788, Test accuracy: 67.37
Round  64, Train loss: 0.134, Test loss: 0.789, Test accuracy: 67.28
Round  65, Train loss: 0.111, Test loss: 0.788, Test accuracy: 67.37
Round  66, Train loss: 0.149, Test loss: 0.787, Test accuracy: 67.03
Round  67, Train loss: 0.091, Test loss: 0.780, Test accuracy: 67.22
Round  68, Train loss: 0.127, Test loss: 0.781, Test accuracy: 67.23
Round  69, Train loss: 0.141, Test loss: 0.781, Test accuracy: 67.22
Round  70, Train loss: 0.091, Test loss: 0.772, Test accuracy: 67.55
Round  71, Train loss: 0.107, Test loss: 0.770, Test accuracy: 67.67
Round  72, Train loss: 0.079, Test loss: 0.763, Test accuracy: 68.20
Round  73, Train loss: 0.073, Test loss: 0.762, Test accuracy: 67.58
Round  74, Train loss: 0.096, Test loss: 0.764, Test accuracy: 67.63
Round  75, Train loss: 0.082, Test loss: 0.758, Test accuracy: 67.83
Round  76, Train loss: 0.100, Test loss: 0.750, Test accuracy: 68.02
Round  77, Train loss: 0.071, Test loss: 0.759, Test accuracy: 67.50
Round  78, Train loss: 0.069, Test loss: 0.748, Test accuracy: 68.37
Round  79, Train loss: 0.082, Test loss: 0.766, Test accuracy: 67.72
Round  80, Train loss: 0.087, Test loss: 0.764, Test accuracy: 68.20
Round  81, Train loss: 0.100, Test loss: 0.768, Test accuracy: 67.40
Round  82, Train loss: 0.078, Test loss: 0.766, Test accuracy: 66.78
Round  83, Train loss: 0.066, Test loss: 0.749, Test accuracy: 67.78
Round  84, Train loss: 0.071, Test loss: 0.744, Test accuracy: 67.97
Round  85, Train loss: 0.081, Test loss: 0.756, Test accuracy: 67.17
Round  86, Train loss: 0.076, Test loss: 0.751, Test accuracy: 67.63
Round  87, Train loss: 0.099, Test loss: 0.756, Test accuracy: 67.88
Round  88, Train loss: 0.072, Test loss: 0.755, Test accuracy: 67.18
Round  89, Train loss: 0.069, Test loss: 0.751, Test accuracy: 67.15
Round  90, Train loss: 0.059, Test loss: 0.745, Test accuracy: 67.62
Round  91, Train loss: 0.088, Test loss: 0.751, Test accuracy: 66.92
Round  92, Train loss: 0.068, Test loss: 0.756, Test accuracy: 66.72
Round  93, Train loss: 0.060, Test loss: 0.750, Test accuracy: 66.48
Round  94, Train loss: 0.102, Test loss: 0.763, Test accuracy: 66.18
Round  95, Train loss: 0.077, Test loss: 0.775, Test accuracy: 65.28
Round  96, Train loss: 0.079, Test loss: 0.774, Test accuracy: 65.22
Round  97, Train loss: 0.077, Test loss: 0.772, Test accuracy: 65.08
Round  98, Train loss: 0.061, Test loss: 0.768, Test accuracy: 65.18
Round  99, Train loss: 0.077, Test loss: 0.768, Test accuracy: 65.47
Final Round, Train loss: 0.067, Test loss: 0.759, Test accuracy: 66.33
Average accuracy final 10 rounds: 66.015
1959.2201311588287
[]
[37.35, 35.8, 42.68333333333333, 47.05, 45.21666666666667, 53.86666666666667, 54.38333333333333, 55.983333333333334, 58.31666666666667, 58.583333333333336, 57.95, 57.78333333333333, 58.733333333333334, 60.35, 59.68333333333333, 59.71666666666667, 61.56666666666667, 62.03333333333333, 61.25, 62.4, 62.28333333333333, 63.666666666666664, 63.75, 62.81666666666667, 62.93333333333333, 63.75, 64.15, 64.63333333333334, 64.38333333333334, 65.11666666666666, 65.13333333333334, 65.58333333333333, 65.75, 66.38333333333334, 65.9, 64.7, 65.13333333333334, 65.5, 67.18333333333334, 67.11666666666666, 67.66666666666667, 68.01666666666667, 65.68333333333334, 66.61666666666666, 66.81666666666666, 67.31666666666666, 67.73333333333333, 67.26666666666667, 66.4, 66.13333333333334, 66.65, 67.35, 68.43333333333334, 69.21666666666667, 68.7, 68.35, 68.31666666666666, 67.83333333333333, 67.3, 66.76666666666667, 66.58333333333333, 67.98333333333333, 68.28333333333333, 67.36666666666666, 67.28333333333333, 67.36666666666666, 67.03333333333333, 67.21666666666667, 67.23333333333333, 67.21666666666667, 67.55, 67.66666666666667, 68.2, 67.58333333333333, 67.63333333333334, 67.83333333333333, 68.01666666666667, 67.5, 68.36666666666666, 67.71666666666667, 68.2, 67.4, 66.78333333333333, 67.78333333333333, 67.96666666666667, 67.16666666666667, 67.63333333333334, 67.88333333333334, 67.18333333333334, 67.15, 67.61666666666666, 66.91666666666667, 66.71666666666667, 66.48333333333333, 66.18333333333334, 65.28333333333333, 65.21666666666667, 65.08333333333333, 65.18333333333334, 65.46666666666667, 66.33333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
Round   0, Train loss: 1.014, Test loss: 1.045, Test accuracy: 40.55
Round   0: Global train loss: 1.014, Global test loss: 1.102, Global test accuracy: 33.32
Round   1, Train loss: 0.873, Test loss: 0.989, Test accuracy: 46.55
Round   1: Global train loss: 0.873, Global test loss: 1.101, Global test accuracy: 33.55
Round   2, Train loss: 0.810, Test loss: 0.954, Test accuracy: 51.13
Round   2: Global train loss: 0.810, Global test loss: 1.101, Global test accuracy: 33.62
Round   3, Train loss: 0.707, Test loss: 0.929, Test accuracy: 53.78
Round   3: Global train loss: 0.707, Global test loss: 1.100, Global test accuracy: 33.58
Round   4, Train loss: 0.596, Test loss: 0.926, Test accuracy: 54.00
Round   4: Global train loss: 0.596, Global test loss: 1.099, Global test accuracy: 33.05
Round   5, Train loss: 0.211, Test loss: 0.880, Test accuracy: 57.72
Round   5: Global train loss: 0.211, Global test loss: 1.099, Global test accuracy: 32.47
Round   6, Train loss: 0.651, Test loss: 0.869, Test accuracy: 58.87
Round   6: Global train loss: 0.651, Global test loss: 1.099, Global test accuracy: 33.05
Round   7, Train loss: 0.508, Test loss: 0.863, Test accuracy: 59.43
Round   7: Global train loss: 0.508, Global test loss: 1.098, Global test accuracy: 33.03
Round   8, Train loss: 0.065, Test loss: 0.834, Test accuracy: 60.88
Round   8: Global train loss: 0.065, Global test loss: 1.098, Global test accuracy: 33.97
Round   9, Train loss: 0.001, Test loss: 0.818, Test accuracy: 62.03
Round   9: Global train loss: 0.001, Global test loss: 1.098, Global test accuracy: 33.40
Round  10, Train loss: -0.371, Test loss: 0.788, Test accuracy: 63.43
Round  10: Global train loss: -0.371, Global test loss: 1.098, Global test accuracy: 33.68
Round  11, Train loss: 0.231, Test loss: 0.777, Test accuracy: 64.13
Round  11: Global train loss: 0.231, Global test loss: 1.097, Global test accuracy: 35.27
Round  12, Train loss: -0.081, Test loss: 0.761, Test accuracy: 65.30
Round  12: Global train loss: -0.081, Global test loss: 1.098, Global test accuracy: 34.45
Round  13, Train loss: -0.152, Test loss: 0.768, Test accuracy: 64.60
Round  13: Global train loss: -0.152, Global test loss: 1.097, Global test accuracy: 34.77
Round  14, Train loss: -0.403, Test loss: 0.762, Test accuracy: 64.90
Round  14: Global train loss: -0.403, Global test loss: 1.097, Global test accuracy: 35.03
Round  15, Train loss: -0.373, Test loss: 0.752, Test accuracy: 65.72
Round  15: Global train loss: -0.373, Global test loss: 1.097, Global test accuracy: 35.02
Round  16, Train loss: -0.498, Test loss: 0.773, Test accuracy: 65.08
Round  16: Global train loss: -0.498, Global test loss: 1.097, Global test accuracy: 35.27
Round  17, Train loss: -0.797, Test loss: 0.754, Test accuracy: 66.77
Round  17: Global train loss: -0.797, Global test loss: 1.097, Global test accuracy: 34.95
Round  18, Train loss: -1.036, Test loss: 0.759, Test accuracy: 66.67
Round  18: Global train loss: -1.036, Global test loss: 1.097, Global test accuracy: 34.48
Round  19, Train loss: -0.927, Test loss: 0.755, Test accuracy: 67.07
Round  19: Global train loss: -0.927, Global test loss: 1.097, Global test accuracy: 34.48
Round  20, Train loss: -1.129, Test loss: 0.736, Test accuracy: 68.03
Round  20: Global train loss: -1.129, Global test loss: 1.098, Global test accuracy: 33.30
Round  21, Train loss: -1.161, Test loss: 0.718, Test accuracy: 69.12
Round  21: Global train loss: -1.161, Global test loss: 1.099, Global test accuracy: 33.48
Round  22, Train loss: -1.312, Test loss: 0.729, Test accuracy: 68.72
Round  22: Global train loss: -1.312, Global test loss: 1.098, Global test accuracy: 34.20
Round  23, Train loss: -0.957, Test loss: 0.764, Test accuracy: 67.70
Round  23: Global train loss: -0.957, Global test loss: 1.097, Global test accuracy: 34.42
Round  24, Train loss: -1.473, Test loss: 0.754, Test accuracy: 67.20
Round  24: Global train loss: -1.473, Global test loss: 1.098, Global test accuracy: 34.13
Round  25, Train loss: -0.922, Test loss: 0.745, Test accuracy: 67.93
Round  25: Global train loss: -0.922, Global test loss: 1.098, Global test accuracy: 33.97
Round  26, Train loss: -1.355, Test loss: 0.723, Test accuracy: 69.33
Round  26: Global train loss: -1.355, Global test loss: 1.098, Global test accuracy: 34.40
Round  27, Train loss: -1.306, Test loss: 0.729, Test accuracy: 68.78
Round  27: Global train loss: -1.306, Global test loss: 1.098, Global test accuracy: 34.05
Round  28, Train loss: -1.455, Test loss: 0.719, Test accuracy: 69.68
Round  28: Global train loss: -1.455, Global test loss: 1.098, Global test accuracy: 34.02
Round  29, Train loss: -1.880, Test loss: 0.715, Test accuracy: 69.62
Round  29: Global train loss: -1.880, Global test loss: 1.096, Global test accuracy: 34.62
Round  30, Train loss: -2.042, Test loss: 0.697, Test accuracy: 71.32
Round  30: Global train loss: -2.042, Global test loss: 1.096, Global test accuracy: 34.92
Round  31, Train loss: -1.224, Test loss: 0.698, Test accuracy: 71.08
Round  31: Global train loss: -1.224, Global test loss: 1.096, Global test accuracy: 35.15
Round  32, Train loss: -1.418, Test loss: 0.705, Test accuracy: 70.65
Round  32: Global train loss: -1.418, Global test loss: 1.095, Global test accuracy: 35.40
Round  33, Train loss: -2.380, Test loss: 0.720, Test accuracy: 69.98
Round  33: Global train loss: -2.380, Global test loss: 1.094, Global test accuracy: 35.55
Round  34, Train loss: -2.315, Test loss: 0.708, Test accuracy: 70.70
Round  34: Global train loss: -2.315, Global test loss: 1.094, Global test accuracy: 35.00
Round  35, Train loss: -2.471, Test loss: 0.697, Test accuracy: 71.25
Round  35: Global train loss: -2.471, Global test loss: 1.094, Global test accuracy: 34.63
Round  36, Train loss: -2.171, Test loss: 0.687, Test accuracy: 71.87
Round  36: Global train loss: -2.171, Global test loss: 1.094, Global test accuracy: 34.98
Round  37, Train loss: -2.528, Test loss: 0.697, Test accuracy: 71.02
Round  37: Global train loss: -2.528, Global test loss: 1.095, Global test accuracy: 34.95
Round  38, Train loss: -2.366, Test loss: 0.692, Test accuracy: 71.13
Round  38: Global train loss: -2.366, Global test loss: 1.093, Global test accuracy: 35.05
Round  39, Train loss: -2.319, Test loss: 0.720, Test accuracy: 69.85
Round  39: Global train loss: -2.319, Global test loss: 1.092, Global test accuracy: 36.23
Round  40, Train loss: -3.059, Test loss: 0.727, Test accuracy: 70.05
Round  40: Global train loss: -3.059, Global test loss: 1.093, Global test accuracy: 35.62
Round  41, Train loss: -2.057, Test loss: 0.712, Test accuracy: 70.23
Round  41: Global train loss: -2.057, Global test loss: 1.093, Global test accuracy: 35.33
Round  42, Train loss: -2.609, Test loss: 0.707, Test accuracy: 70.25
Round  42: Global train loss: -2.609, Global test loss: 1.093, Global test accuracy: 35.73
Round  43, Train loss: -3.225, Test loss: 0.693, Test accuracy: 71.28
Round  43: Global train loss: -3.225, Global test loss: 1.093, Global test accuracy: 35.88
Round  44, Train loss: -2.582, Test loss: 0.716, Test accuracy: 70.62
Round  44: Global train loss: -2.582, Global test loss: 1.092, Global test accuracy: 36.22
Round  45, Train loss: -2.911, Test loss: 0.710, Test accuracy: 71.20
Round  45: Global train loss: -2.911, Global test loss: 1.093, Global test accuracy: 35.82
Round  46, Train loss: -3.028, Test loss: 0.711, Test accuracy: 71.45
Round  46: Global train loss: -3.028, Global test loss: 1.092, Global test accuracy: 36.15
Round  47, Train loss: -3.181, Test loss: 0.710, Test accuracy: 71.60
Round  47: Global train loss: -3.181, Global test loss: 1.092, Global test accuracy: 35.97
Round  48, Train loss: -3.410, Test loss: 0.701, Test accuracy: 72.10
Round  48: Global train loss: -3.410, Global test loss: 1.092, Global test accuracy: 35.85
Round  49, Train loss: -2.218, Test loss: 0.688, Test accuracy: 72.07
Round  49: Global train loss: -2.218, Global test loss: 1.093, Global test accuracy: 35.77
Round  50, Train loss: -3.417, Test loss: 0.727, Test accuracy: 71.15
Round  50: Global train loss: -3.417, Global test loss: 1.094, Global test accuracy: 35.75
Round  51, Train loss: -2.885, Test loss: 0.722, Test accuracy: 71.60
Round  51: Global train loss: -2.885, Global test loss: 1.093, Global test accuracy: 35.78
Round  52, Train loss: -3.483, Test loss: 0.729, Test accuracy: 71.60
Round  52: Global train loss: -3.483, Global test loss: 1.093, Global test accuracy: 35.38
Round  53, Train loss: -3.651, Test loss: 0.738, Test accuracy: 71.33
Round  53: Global train loss: -3.651, Global test loss: 1.091, Global test accuracy: 36.38
Round  54, Train loss: -3.412, Test loss: 0.736, Test accuracy: 71.08
Round  54: Global train loss: -3.412, Global test loss: 1.091, Global test accuracy: 36.97
Round  55, Train loss: -4.120, Test loss: 0.740, Test accuracy: 71.35
Round  55: Global train loss: -4.120, Global test loss: 1.091, Global test accuracy: 36.78
Round  56, Train loss: -3.824, Test loss: 0.769, Test accuracy: 70.72
Round  56: Global train loss: -3.824, Global test loss: 1.094, Global test accuracy: 36.12
Round  57, Train loss: -3.899, Test loss: 0.768, Test accuracy: 71.27
Round  57: Global train loss: -3.899, Global test loss: 1.095, Global test accuracy: 35.70
Round  58, Train loss: -3.210, Test loss: 0.759, Test accuracy: 71.27
Round  58: Global train loss: -3.210, Global test loss: 1.095, Global test accuracy: 35.52
Round  59, Train loss: -3.454, Test loss: 0.721, Test accuracy: 73.03
Round  59: Global train loss: -3.454, Global test loss: 1.095, Global test accuracy: 35.52
Round  60, Train loss: -3.713, Test loss: 0.689, Test accuracy: 73.50
Round  60: Global train loss: -3.713, Global test loss: 1.093, Global test accuracy: 35.80
Round  61, Train loss: -3.756, Test loss: 0.704, Test accuracy: 72.95
Round  61: Global train loss: -3.756, Global test loss: 1.094, Global test accuracy: 36.22
Round  62, Train loss: -4.217, Test loss: 0.725, Test accuracy: 72.85
Round  62: Global train loss: -4.217, Global test loss: 1.096, Global test accuracy: 35.20
Round  63, Train loss: -4.035, Test loss: 0.724, Test accuracy: 73.35
Round  63: Global train loss: -4.035, Global test loss: 1.098, Global test accuracy: 35.27
Round  64, Train loss: -3.968, Test loss: 0.738, Test accuracy: 73.00
Round  64: Global train loss: -3.968, Global test loss: 1.097, Global test accuracy: 35.97
Round  65, Train loss: -3.746, Test loss: 0.754, Test accuracy: 72.78
Round  65: Global train loss: -3.746, Global test loss: 1.095, Global test accuracy: 36.82
Round  66, Train loss: -3.947, Test loss: 0.759, Test accuracy: 72.32
Round  66: Global train loss: -3.947, Global test loss: 1.093, Global test accuracy: 37.13
Round  67, Train loss: -4.421, Test loss: 0.759, Test accuracy: 72.78
Round  67: Global train loss: -4.421, Global test loss: 1.094, Global test accuracy: 36.73
Round  68, Train loss: -4.255, Test loss: 0.771, Test accuracy: 72.97
Round  68: Global train loss: -4.255, Global test loss: 1.094, Global test accuracy: 36.18
Round  69, Train loss: -4.203, Test loss: 0.756, Test accuracy: 73.27
Round  69: Global train loss: -4.203, Global test loss: 1.094, Global test accuracy: 36.18
Round  70, Train loss: -3.857, Test loss: 0.735, Test accuracy: 73.63
Round  70: Global train loss: -3.857, Global test loss: 1.092, Global test accuracy: 36.40
Round  71, Train loss: -4.753, Test loss: 0.775, Test accuracy: 73.92
Round  71: Global train loss: -4.753, Global test loss: 1.093, Global test accuracy: 36.68
Round  72, Train loss: -4.622, Test loss: 0.750, Test accuracy: 73.88
Round  72: Global train loss: -4.622, Global test loss: 1.093, Global test accuracy: 36.60
Round  73, Train loss: -4.124, Test loss: 0.764, Test accuracy: 73.35
Round  73: Global train loss: -4.124, Global test loss: 1.091, Global test accuracy: 37.52
Round  74, Train loss: -4.287, Test loss: 0.738, Test accuracy: 73.77
Round  74: Global train loss: -4.287, Global test loss: 1.091, Global test accuracy: 37.68
Round  75, Train loss: -4.046, Test loss: 0.760, Test accuracy: 72.87
Round  75: Global train loss: -4.046, Global test loss: 1.091, Global test accuracy: 37.37
Round  76, Train loss: -4.372, Test loss: 0.777, Test accuracy: 72.73
Round  76: Global train loss: -4.372, Global test loss: 1.092, Global test accuracy: 37.53
Round  77, Train loss: -5.021, Test loss: 0.781, Test accuracy: 72.75
Round  77: Global train loss: -5.021, Global test loss: 1.092, Global test accuracy: 37.82
Round  78, Train loss: -4.550, Test loss: 0.774, Test accuracy: 72.47
Round  78: Global train loss: -4.550, Global test loss: 1.092, Global test accuracy: 37.73
Round  79, Train loss: -4.947, Test loss: 0.773, Test accuracy: 72.82
Round  79: Global train loss: -4.947, Global test loss: 1.093, Global test accuracy: 37.43
Round  80, Train loss: -4.438, Test loss: 0.808, Test accuracy: 72.47
Round  80: Global train loss: -4.438, Global test loss: 1.093, Global test accuracy: 37.22
Round  81, Train loss: -3.920, Test loss: 0.803, Test accuracy: 72.00
Round  81: Global train loss: -3.920, Global test loss: 1.094, Global test accuracy: 37.43
Round  82, Train loss: -4.901, Test loss: 0.779, Test accuracy: 72.35
Round  82: Global train loss: -4.901, Global test loss: 1.090, Global test accuracy: 38.20
Round  83, Train loss: -5.540, Test loss: 0.775, Test accuracy: 72.75
Round  83: Global train loss: -5.540, Global test loss: 1.093, Global test accuracy: 37.52
Round  84, Train loss: -4.673, Test loss: 0.766, Test accuracy: 72.55
Round  84: Global train loss: -4.673, Global test loss: 1.094, Global test accuracy: 37.25
Round  85, Train loss: -4.893, Test loss: 0.782, Test accuracy: 72.70
Round  85: Global train loss: -4.893, Global test loss: 1.092, Global test accuracy: 37.75
Round  86, Train loss: -4.740, Test loss: 0.789, Test accuracy: 72.17
Round  86: Global train loss: -4.740, Global test loss: 1.093, Global test accuracy: 37.83
Round  87, Train loss: -5.028, Test loss: 0.778, Test accuracy: 72.35
Round  87: Global train loss: -5.028, Global test loss: 1.093, Global test accuracy: 37.87
Round  88, Train loss: -4.687, Test loss: 0.748, Test accuracy: 73.17
Round  88: Global train loss: -4.687, Global test loss: 1.094, Global test accuracy: 37.47
Round  89, Train loss: -5.013, Test loss: 0.754, Test accuracy: 73.33
Round  89: Global train loss: -5.013, Global test loss: 1.099, Global test accuracy: 36.83
Round  90, Train loss: -4.436, Test loss: 0.732, Test accuracy: 74.07
Round  90: Global train loss: -4.436, Global test loss: 1.096, Global test accuracy: 37.78
Round  91, Train loss: -4.939, Test loss: 0.731, Test accuracy: 74.45
Round  91: Global train loss: -4.939, Global test loss: 1.099, Global test accuracy: 37.45
Round  92, Train loss: -4.567, Test loss: 0.734, Test accuracy: 74.35
Round  92: Global train loss: -4.567, Global test loss: 1.097, Global test accuracy: 37.85
Round  93, Train loss: -5.046, Test loss: 0.745, Test accuracy: 74.53
Round  93: Global train loss: -5.046, Global test loss: 1.094, Global test accuracy: 38.25
Round  94, Train loss: -5.217, Test loss: 0.739, Test accuracy: 73.67
Round  94: Global train loss: -5.217, Global test loss: 1.094, Global test accuracy: 38.23
Round  95, Train loss: -4.643, Test loss: 0.737, Test accuracy: 73.03
Round  95: Global train loss: -4.643, Global test loss: 1.096, Global test accuracy: 38.62
Round  96, Train loss: -5.655, Test loss: 0.737, Test accuracy: 74.02
Round  96: Global train loss: -5.655, Global test loss: 1.098, Global test accuracy: 38.28
Round  97, Train loss: -5.767, Test loss: 0.762, Test accuracy: 73.40
Round  97: Global train loss: -5.767, Global test loss: 1.097, Global test accuracy: 38.52
Round  98, Train loss: -5.209, Test loss: 0.738, Test accuracy: 73.10
Round  98: Global train loss: -5.209, Global test loss: 1.096, Global test accuracy: 38.18
Round  99, Train loss: -4.838, Test loss: 0.709, Test accuracy: 73.50
Round  99: Global train loss: -4.838, Global test loss: 1.096, Global test accuracy: 38.67
Final Round: Train loss: 0.621, Test loss: 0.646, Test accuracy: 72.47
Final Round: Global train loss: 0.621, Global test loss: 1.098, Global test accuracy: 39.05
Average accuracy final 10 rounds: 73.81166666666667
Average global accuracy final 10 rounds: 38.18333333333334
1972.1648046970367
[]
[40.55, 46.55, 51.13333333333333, 53.78333333333333, 54.0, 57.71666666666667, 58.86666666666667, 59.43333333333333, 60.88333333333333, 62.03333333333333, 63.43333333333333, 64.13333333333334, 65.3, 64.6, 64.9, 65.71666666666667, 65.08333333333333, 66.76666666666667, 66.66666666666667, 67.06666666666666, 68.03333333333333, 69.11666666666666, 68.71666666666667, 67.7, 67.2, 67.93333333333334, 69.33333333333333, 68.78333333333333, 69.68333333333334, 69.61666666666666, 71.31666666666666, 71.08333333333333, 70.65, 69.98333333333333, 70.7, 71.25, 71.86666666666666, 71.01666666666667, 71.13333333333334, 69.85, 70.05, 70.23333333333333, 70.25, 71.28333333333333, 70.61666666666666, 71.2, 71.45, 71.6, 72.1, 72.06666666666666, 71.15, 71.6, 71.6, 71.33333333333333, 71.08333333333333, 71.35, 70.71666666666667, 71.26666666666667, 71.26666666666667, 73.03333333333333, 73.5, 72.95, 72.85, 73.35, 73.0, 72.78333333333333, 72.31666666666666, 72.78333333333333, 72.96666666666667, 73.26666666666667, 73.63333333333334, 73.91666666666667, 73.88333333333334, 73.35, 73.76666666666667, 72.86666666666666, 72.73333333333333, 72.75, 72.46666666666667, 72.81666666666666, 72.46666666666667, 72.0, 72.35, 72.75, 72.55, 72.7, 72.16666666666667, 72.35, 73.16666666666667, 73.33333333333333, 74.06666666666666, 74.45, 74.35, 74.53333333333333, 73.66666666666667, 73.03333333333333, 74.01666666666667, 73.4, 73.1, 73.5, 72.46666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.097, Test loss: 1.100, Test accuracy: 33.33 

Round   0, Global train loss: 1.097, Global test loss: 1.100, Global test accuracy: 33.33 

Round   1, Train loss: 1.098, Test loss: 1.099, Test accuracy: 33.33 

Round   1, Global train loss: 1.098, Global test loss: 1.100, Global test accuracy: 33.33 

Round   2, Train loss: 1.096, Test loss: 1.099, Test accuracy: 33.33 

Round   2, Global train loss: 1.096, Global test loss: 1.100, Global test accuracy: 33.33 

Round   3, Train loss: 1.098, Test loss: 1.099, Test accuracy: 33.33 

Round   3, Global train loss: 1.098, Global test loss: 1.100, Global test accuracy: 33.33 

Round   4, Train loss: 1.096, Test loss: 1.099, Test accuracy: 33.33 

Round   4, Global train loss: 1.096, Global test loss: 1.100, Global test accuracy: 33.33 

Round   5, Train loss: 1.095, Test loss: 1.098, Test accuracy: 33.33 

Round   5, Global train loss: 1.095, Global test loss: 1.099, Global test accuracy: 33.33 

Round   6, Train loss: 1.094, Test loss: 1.098, Test accuracy: 33.33 

Round   6, Global train loss: 1.094, Global test loss: 1.099, Global test accuracy: 33.33 

Round   7, Train loss: 1.097, Test loss: 1.098, Test accuracy: 33.35 

Round   7, Global train loss: 1.097, Global test loss: 1.099, Global test accuracy: 33.35 

Round   8, Train loss: 1.094, Test loss: 1.098, Test accuracy: 33.40 

Round   8, Global train loss: 1.094, Global test loss: 1.099, Global test accuracy: 33.35 

Round   9, Train loss: 1.096, Test loss: 1.098, Test accuracy: 33.43 

Round   9, Global train loss: 1.096, Global test loss: 1.099, Global test accuracy: 33.37 

Round  10, Train loss: 1.095, Test loss: 1.098, Test accuracy: 33.48 

Round  10, Global train loss: 1.095, Global test loss: 1.099, Global test accuracy: 33.38 

Round  11, Train loss: 1.096, Test loss: 1.097, Test accuracy: 33.50 

Round  11, Global train loss: 1.096, Global test loss: 1.098, Global test accuracy: 33.40 

Round  12, Train loss: 1.093, Test loss: 1.097, Test accuracy: 33.62 

Round  12, Global train loss: 1.093, Global test loss: 1.098, Global test accuracy: 33.53 

Round  13, Train loss: 1.095, Test loss: 1.097, Test accuracy: 33.58 

Round  13, Global train loss: 1.095, Global test loss: 1.098, Global test accuracy: 33.53 

Round  14, Train loss: 1.095, Test loss: 1.097, Test accuracy: 33.57 

Round  14, Global train loss: 1.095, Global test loss: 1.098, Global test accuracy: 33.52 

Round  15, Train loss: 1.095, Test loss: 1.097, Test accuracy: 33.58 

Round  15, Global train loss: 1.095, Global test loss: 1.098, Global test accuracy: 33.48 

Round  16, Train loss: 1.098, Test loss: 1.097, Test accuracy: 33.60 

Round  16, Global train loss: 1.098, Global test loss: 1.098, Global test accuracy: 33.48 

Round  17, Train loss: 1.092, Test loss: 1.097, Test accuracy: 33.65 

Round  17, Global train loss: 1.092, Global test loss: 1.098, Global test accuracy: 33.58 

Round  18, Train loss: 1.092, Test loss: 1.096, Test accuracy: 33.93 

Round  18, Global train loss: 1.092, Global test loss: 1.098, Global test accuracy: 33.75 

Round  19, Train loss: 1.093, Test loss: 1.096, Test accuracy: 34.13 

Round  19, Global train loss: 1.093, Global test loss: 1.098, Global test accuracy: 33.92 

Round  20, Train loss: 1.091, Test loss: 1.096, Test accuracy: 34.83 

Round  20, Global train loss: 1.091, Global test loss: 1.098, Global test accuracy: 34.28 

Round  21, Train loss: 1.091, Test loss: 1.096, Test accuracy: 35.13 

Round  21, Global train loss: 1.091, Global test loss: 1.098, Global test accuracy: 34.33 

Round  22, Train loss: 1.096, Test loss: 1.096, Test accuracy: 35.32 

Round  22, Global train loss: 1.096, Global test loss: 1.098, Global test accuracy: 34.42 

Round  23, Train loss: 1.091, Test loss: 1.096, Test accuracy: 35.67 

Round  23, Global train loss: 1.091, Global test loss: 1.097, Global test accuracy: 34.28 

Round  24, Train loss: 1.091, Test loss: 1.096, Test accuracy: 35.87 

Round  24, Global train loss: 1.091, Global test loss: 1.097, Global test accuracy: 34.58 

Round  25, Train loss: 1.095, Test loss: 1.096, Test accuracy: 35.85 

Round  25, Global train loss: 1.095, Global test loss: 1.097, Global test accuracy: 35.00 

Round  26, Train loss: 1.095, Test loss: 1.095, Test accuracy: 36.08 

Round  26, Global train loss: 1.095, Global test loss: 1.097, Global test accuracy: 35.05 

Round  27, Train loss: 1.094, Test loss: 1.095, Test accuracy: 36.72 

Round  27, Global train loss: 1.094, Global test loss: 1.097, Global test accuracy: 35.82 

Round  28, Train loss: 1.092, Test loss: 1.095, Test accuracy: 37.45 

Round  28, Global train loss: 1.092, Global test loss: 1.097, Global test accuracy: 35.88 

Round  29, Train loss: 1.091, Test loss: 1.095, Test accuracy: 38.23 

Round  29, Global train loss: 1.091, Global test loss: 1.097, Global test accuracy: 35.97 

Round  30, Train loss: 1.090, Test loss: 1.095, Test accuracy: 38.13 

Round  30, Global train loss: 1.090, Global test loss: 1.097, Global test accuracy: 35.70 

Round  31, Train loss: 1.090, Test loss: 1.095, Test accuracy: 38.68 

Round  31, Global train loss: 1.090, Global test loss: 1.097, Global test accuracy: 35.75 

Round  32, Train loss: 1.087, Test loss: 1.095, Test accuracy: 38.88 

Round  32, Global train loss: 1.087, Global test loss: 1.097, Global test accuracy: 35.85 

Round  33, Train loss: 1.091, Test loss: 1.094, Test accuracy: 39.42 

Round  33, Global train loss: 1.091, Global test loss: 1.096, Global test accuracy: 35.98 

Round  34, Train loss: 1.087, Test loss: 1.094, Test accuracy: 39.10 

Round  34, Global train loss: 1.087, Global test loss: 1.096, Global test accuracy: 35.93 

Round  35, Train loss: 1.089, Test loss: 1.094, Test accuracy: 38.80 

Round  35, Global train loss: 1.089, Global test loss: 1.096, Global test accuracy: 35.98 

Round  36, Train loss: 1.093, Test loss: 1.094, Test accuracy: 38.53 

Round  36, Global train loss: 1.093, Global test loss: 1.096, Global test accuracy: 36.38 

Round  37, Train loss: 1.087, Test loss: 1.094, Test accuracy: 38.77 

Round  37, Global train loss: 1.087, Global test loss: 1.096, Global test accuracy: 36.23 

Round  38, Train loss: 1.088, Test loss: 1.094, Test accuracy: 38.65 

Round  38, Global train loss: 1.088, Global test loss: 1.096, Global test accuracy: 36.30 

Round  39, Train loss: 1.095, Test loss: 1.094, Test accuracy: 38.17 

Round  39, Global train loss: 1.095, Global test loss: 1.096, Global test accuracy: 35.87 

Round  40, Train loss: 1.085, Test loss: 1.094, Test accuracy: 38.57 

Round  40, Global train loss: 1.085, Global test loss: 1.096, Global test accuracy: 36.47 

Round  41, Train loss: 1.087, Test loss: 1.093, Test accuracy: 38.33 

Round  41, Global train loss: 1.087, Global test loss: 1.096, Global test accuracy: 35.63 

Round  42, Train loss: 1.088, Test loss: 1.093, Test accuracy: 38.73 

Round  42, Global train loss: 1.088, Global test loss: 1.096, Global test accuracy: 35.97 

Round  43, Train loss: 1.088, Test loss: 1.093, Test accuracy: 39.18 

Round  43, Global train loss: 1.088, Global test loss: 1.096, Global test accuracy: 36.08 

Round  44, Train loss: 1.087, Test loss: 1.093, Test accuracy: 39.08 

Round  44, Global train loss: 1.087, Global test loss: 1.096, Global test accuracy: 36.22 

Round  45, Train loss: 1.087, Test loss: 1.093, Test accuracy: 38.70 

Round  45, Global train loss: 1.087, Global test loss: 1.096, Global test accuracy: 36.08 

Round  46, Train loss: 1.085, Test loss: 1.093, Test accuracy: 38.73 

Round  46, Global train loss: 1.085, Global test loss: 1.095, Global test accuracy: 36.40 

Round  47, Train loss: 1.081, Test loss: 1.092, Test accuracy: 38.30 

Round  47, Global train loss: 1.081, Global test loss: 1.095, Global test accuracy: 35.72 

Round  48, Train loss: 1.090, Test loss: 1.093, Test accuracy: 38.32 

Round  48, Global train loss: 1.090, Global test loss: 1.095, Global test accuracy: 35.87 

Round  49, Train loss: 1.088, Test loss: 1.092, Test accuracy: 37.93 

Round  49, Global train loss: 1.088, Global test loss: 1.095, Global test accuracy: 36.23 

Round  50, Train loss: 1.094, Test loss: 1.093, Test accuracy: 37.95 

Round  50, Global train loss: 1.094, Global test loss: 1.095, Global test accuracy: 36.17 

Round  51, Train loss: 1.086, Test loss: 1.092, Test accuracy: 37.88 

Round  51, Global train loss: 1.086, Global test loss: 1.095, Global test accuracy: 36.55 

Round  52, Train loss: 1.093, Test loss: 1.092, Test accuracy: 37.67 

Round  52, Global train loss: 1.093, Global test loss: 1.095, Global test accuracy: 36.28 

Round  53, Train loss: 1.084, Test loss: 1.092, Test accuracy: 37.58 

Round  53, Global train loss: 1.084, Global test loss: 1.095, Global test accuracy: 36.18 

Round  54, Train loss: 1.088, Test loss: 1.092, Test accuracy: 38.22 

Round  54, Global train loss: 1.088, Global test loss: 1.095, Global test accuracy: 36.28 

Round  55, Train loss: 1.086, Test loss: 1.092, Test accuracy: 38.17 

Round  55, Global train loss: 1.086, Global test loss: 1.095, Global test accuracy: 36.27 

Round  56, Train loss: 1.087, Test loss: 1.092, Test accuracy: 38.22 

Round  56, Global train loss: 1.087, Global test loss: 1.095, Global test accuracy: 36.27 

Round  57, Train loss: 1.087, Test loss: 1.092, Test accuracy: 38.45 

Round  57, Global train loss: 1.087, Global test loss: 1.095, Global test accuracy: 36.37 

Round  58, Train loss: 1.092, Test loss: 1.092, Test accuracy: 38.50 

Round  58, Global train loss: 1.092, Global test loss: 1.095, Global test accuracy: 36.32 

Round  59, Train loss: 1.088, Test loss: 1.092, Test accuracy: 38.52 

Round  59, Global train loss: 1.088, Global test loss: 1.095, Global test accuracy: 36.30 

Round  60, Train loss: 1.088, Test loss: 1.092, Test accuracy: 38.50 

Round  60, Global train loss: 1.088, Global test loss: 1.095, Global test accuracy: 36.62 

Round  61, Train loss: 1.081, Test loss: 1.091, Test accuracy: 38.50 

Round  61, Global train loss: 1.081, Global test loss: 1.095, Global test accuracy: 36.82 

Round  62, Train loss: 1.092, Test loss: 1.091, Test accuracy: 38.60 

Round  62, Global train loss: 1.092, Global test loss: 1.095, Global test accuracy: 36.88 

Round  63, Train loss: 1.085, Test loss: 1.091, Test accuracy: 38.65 

Round  63, Global train loss: 1.085, Global test loss: 1.095, Global test accuracy: 37.02 

Round  64, Train loss: 1.081, Test loss: 1.091, Test accuracy: 38.77 

Round  64, Global train loss: 1.081, Global test loss: 1.095, Global test accuracy: 37.07 

Round  65, Train loss: 1.088, Test loss: 1.091, Test accuracy: 38.78 

Round  65, Global train loss: 1.088, Global test loss: 1.095, Global test accuracy: 36.78 

Round  66, Train loss: 1.083, Test loss: 1.091, Test accuracy: 38.78 

Round  66, Global train loss: 1.083, Global test loss: 1.095, Global test accuracy: 36.72 

Round  67, Train loss: 1.086, Test loss: 1.091, Test accuracy: 38.55 

Round  67, Global train loss: 1.086, Global test loss: 1.095, Global test accuracy: 37.02 

Round  68, Train loss: 1.081, Test loss: 1.091, Test accuracy: 38.83 

Round  68, Global train loss: 1.081, Global test loss: 1.095, Global test accuracy: 37.13 

Round  69, Train loss: 1.076, Test loss: 1.091, Test accuracy: 39.10 

Round  69, Global train loss: 1.076, Global test loss: 1.095, Global test accuracy: 37.03 

Round  70, Train loss: 1.079, Test loss: 1.090, Test accuracy: 39.08 

Round  70, Global train loss: 1.079, Global test loss: 1.094, Global test accuracy: 37.10 

Round  71, Train loss: 1.076, Test loss: 1.090, Test accuracy: 39.25 

Round  71, Global train loss: 1.076, Global test loss: 1.094, Global test accuracy: 36.90 

Round  72, Train loss: 1.077, Test loss: 1.090, Test accuracy: 39.20 

Round  72, Global train loss: 1.077, Global test loss: 1.094, Global test accuracy: 37.18 

Round  73, Train loss: 1.079, Test loss: 1.090, Test accuracy: 39.27 

Round  73, Global train loss: 1.079, Global test loss: 1.094, Global test accuracy: 37.18 

Round  74, Train loss: 1.073, Test loss: 1.090, Test accuracy: 39.13 

Round  74, Global train loss: 1.073, Global test loss: 1.094, Global test accuracy: 37.22 

Round  75, Train loss: 1.092, Test loss: 1.090, Test accuracy: 39.18 

Round  75, Global train loss: 1.092, Global test loss: 1.094, Global test accuracy: 37.42 

Round  76, Train loss: 1.079, Test loss: 1.090, Test accuracy: 39.27 

Round  76, Global train loss: 1.079, Global test loss: 1.094, Global test accuracy: 37.32 

Round  77, Train loss: 1.076, Test loss: 1.090, Test accuracy: 39.25 

Round  77, Global train loss: 1.076, Global test loss: 1.094, Global test accuracy: 37.33 

Round  78, Train loss: 1.088, Test loss: 1.089, Test accuracy: 39.27 

Round  78, Global train loss: 1.088, Global test loss: 1.094, Global test accuracy: 37.35 

Round  79, Train loss: 1.084, Test loss: 1.089, Test accuracy: 39.08 

Round  79, Global train loss: 1.084, Global test loss: 1.094, Global test accuracy: 37.52 

Round  80, Train loss: 1.078, Test loss: 1.089, Test accuracy: 38.85 

Round  80, Global train loss: 1.078, Global test loss: 1.094, Global test accuracy: 37.43 

Round  81, Train loss: 1.075, Test loss: 1.089, Test accuracy: 38.95 

Round  81, Global train loss: 1.075, Global test loss: 1.094, Global test accuracy: 37.17 

Round  82, Train loss: 1.088, Test loss: 1.089, Test accuracy: 38.65 

Round  82, Global train loss: 1.088, Global test loss: 1.094, Global test accuracy: 37.35 

Round  83, Train loss: 1.087, Test loss: 1.089, Test accuracy: 38.63 

Round  83, Global train loss: 1.087, Global test loss: 1.093, Global test accuracy: 37.70 

Round  84, Train loss: 1.066, Test loss: 1.089, Test accuracy: 38.73 

Round  84, Global train loss: 1.066, Global test loss: 1.093, Global test accuracy: 37.53 

Round  85, Train loss: 1.071, Test loss: 1.088, Test accuracy: 38.80 

Round  85, Global train loss: 1.071, Global test loss: 1.093, Global test accuracy: 37.43 

Round  86, Train loss: 1.074, Test loss: 1.088, Test accuracy: 39.05 

Round  86, Global train loss: 1.074, Global test loss: 1.093, Global test accuracy: 37.58 

Round  87, Train loss: 1.087, Test loss: 1.088, Test accuracy: 39.08 

Round  87, Global train loss: 1.087, Global test loss: 1.093, Global test accuracy: 37.52 

Round  88, Train loss: 1.079, Test loss: 1.088, Test accuracy: 38.98 

Round  88, Global train loss: 1.079, Global test loss: 1.093, Global test accuracy: 37.57 

Round  89, Train loss: 1.074, Test loss: 1.088, Test accuracy: 39.18 

Round  89, Global train loss: 1.074, Global test loss: 1.093, Global test accuracy: 37.50 

Round  90, Train loss: 1.078, Test loss: 1.087, Test accuracy: 39.18 

Round  90, Global train loss: 1.078, Global test loss: 1.093, Global test accuracy: 37.43 

Round  91, Train loss: 1.082, Test loss: 1.087, Test accuracy: 39.27 

Round  91, Global train loss: 1.082, Global test loss: 1.093, Global test accuracy: 37.62 

Round  92, Train loss: 1.084, Test loss: 1.087, Test accuracy: 39.27 

Round  92, Global train loss: 1.084, Global test loss: 1.093, Global test accuracy: 37.62 

Round  93, Train loss: 1.081, Test loss: 1.088, Test accuracy: 39.35 

Round  93, Global train loss: 1.081, Global test loss: 1.093, Global test accuracy: 37.73 

Round  94, Train loss: 1.065, Test loss: 1.087, Test accuracy: 39.62 

Round  94, Global train loss: 1.065, Global test loss: 1.093, Global test accuracy: 37.47 

Round  95, Train loss: 1.077, Test loss: 1.087, Test accuracy: 39.50 

Round  95, Global train loss: 1.077, Global test loss: 1.093, Global test accuracy: 37.43 

Round  96, Train loss: 1.089, Test loss: 1.088, Test accuracy: 39.07 

Round  96, Global train loss: 1.089, Global test loss: 1.093, Global test accuracy: 37.40 

Round  97, Train loss: 1.069, Test loss: 1.087, Test accuracy: 39.05 

Round  97, Global train loss: 1.069, Global test loss: 1.093, Global test accuracy: 37.15 

Round  98, Train loss: 1.069, Test loss: 1.087, Test accuracy: 38.68 

Round  98, Global train loss: 1.069, Global test loss: 1.093, Global test accuracy: 37.27 

Round  99, Train loss: 1.085, Test loss: 1.087, Test accuracy: 39.05 

Round  99, Global train loss: 1.085, Global test loss: 1.093, Global test accuracy: 37.40 

Final Round, Train loss: 1.073, Test loss: 1.080, Test accuracy: 41.30 

Final Round, Global train loss: 1.073, Global test loss: 1.093, Global test accuracy: 37.40 

Average accuracy final 10 rounds: 39.20333333333333 

Average global accuracy final 10 rounds: 37.45166666666666 

1974.364550113678
[7.291774272918701, 8.733365058898926, 10.174970388412476, 11.614807367324829, 13.056234359741211, 14.491632461547852, 15.928268671035767, 17.36496877670288, 18.803775787353516, 20.24871301651001, 21.694419145584106, 23.1325466632843, 24.5736141204834, 26.06842041015625, 27.505465030670166, 28.940929174423218, 30.37937641143799, 31.81505036354065, 33.25434112548828, 34.69865703582764, 36.148287773132324, 37.59364652633667, 39.03306531906128, 40.58987832069397, 42.0817768573761, 43.52173399925232, 44.95675706863403, 46.393221378326416, 47.8304922580719, 49.26843500137329, 50.71045541763306, 52.1506929397583, 53.58763122558594, 55.0254168510437, 56.46882915496826, 57.91413426399231, 59.35878801345825, 60.8543643951416, 62.30701780319214, 63.74901008605957, 65.18559002876282, 66.62429928779602, 68.07138109207153, 69.51043176651001, 71.03126621246338, 72.47638869285583, 73.94097661972046, 75.49605131149292, 76.9333758354187, 78.45907092094421, 80.06272578239441, 81.55551338195801, 82.98920607566833, 84.43116044998169, 85.87088441848755, 87.31374168395996, 88.76277565956116, 90.27041149139404, 91.70755696296692, 93.14917516708374, 94.58843159675598, 96.02623653411865, 97.47031998634338, 98.9078438282013, 100.43150281906128, 101.86818981170654, 103.31799268722534, 104.75825929641724, 106.20938730239868, 107.651282787323, 109.17797827720642, 110.74099206924438, 112.31784319877625, 113.75778865814209, 115.19730067253113, 116.64770913124084, 118.09232783317566, 119.69552540779114, 121.14726305007935, 122.5892481803894, 124.02737951278687, 125.47545289993286, 126.91720056533813, 128.36050152778625, 129.79617500305176, 131.24046063423157, 132.688490152359, 134.18681359291077, 135.62288737297058, 137.0715413093567, 138.51040959358215, 139.95611906051636, 141.45888328552246, 142.98909449577332, 144.42704582214355, 145.8631148338318, 147.3070147037506, 148.74070358276367, 150.1771867275238, 151.61209845542908, 154.57113695144653]
[33.333333333333336, 33.333333333333336, 33.333333333333336, 33.333333333333336, 33.333333333333336, 33.333333333333336, 33.333333333333336, 33.35, 33.4, 33.43333333333333, 33.483333333333334, 33.5, 33.61666666666667, 33.583333333333336, 33.56666666666667, 33.583333333333336, 33.6, 33.65, 33.93333333333333, 34.13333333333333, 34.833333333333336, 35.13333333333333, 35.31666666666667, 35.666666666666664, 35.86666666666667, 35.85, 36.083333333333336, 36.71666666666667, 37.45, 38.233333333333334, 38.13333333333333, 38.68333333333333, 38.88333333333333, 39.416666666666664, 39.1, 38.8, 38.53333333333333, 38.766666666666666, 38.65, 38.166666666666664, 38.56666666666667, 38.333333333333336, 38.733333333333334, 39.18333333333333, 39.083333333333336, 38.7, 38.733333333333334, 38.3, 38.31666666666667, 37.93333333333333, 37.95, 37.88333333333333, 37.666666666666664, 37.583333333333336, 38.21666666666667, 38.166666666666664, 38.21666666666667, 38.45, 38.5, 38.516666666666666, 38.5, 38.5, 38.6, 38.65, 38.766666666666666, 38.78333333333333, 38.78333333333333, 38.55, 38.833333333333336, 39.1, 39.083333333333336, 39.25, 39.2, 39.266666666666666, 39.13333333333333, 39.18333333333333, 39.266666666666666, 39.25, 39.266666666666666, 39.083333333333336, 38.85, 38.95, 38.65, 38.63333333333333, 38.733333333333334, 38.8, 39.05, 39.083333333333336, 38.983333333333334, 39.18333333333333, 39.18333333333333, 39.266666666666666, 39.266666666666666, 39.35, 39.61666666666667, 39.5, 39.06666666666667, 39.05, 38.68333333333333, 39.05, 41.3]
