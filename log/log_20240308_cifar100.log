nohup: ignoring input
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.138, Test loss: 1.866, Test accuracy: 38.76
Round   0, Global train loss: 2.138, Global test loss: 1.884, Global test accuracy: 40.10
Round   1, Train loss: 1.853, Test loss: 1.658, Test accuracy: 43.12
Round   1, Global train loss: 1.853, Global test loss: 1.625, Global test accuracy: 45.60
Round   2, Train loss: 1.682, Test loss: 1.556, Test accuracy: 46.91
Round   2, Global train loss: 1.682, Global test loss: 1.453, Global test accuracy: 52.70
Round   3, Train loss: 1.617, Test loss: 1.500, Test accuracy: 48.88
Round   3, Global train loss: 1.617, Global test loss: 1.385, Global test accuracy: 55.40
Round   4, Train loss: 1.550, Test loss: 1.469, Test accuracy: 50.15
Round   4, Global train loss: 1.550, Global test loss: 1.372, Global test accuracy: 57.30
Round   5, Train loss: 1.527, Test loss: 1.427, Test accuracy: 51.56
Round   5, Global train loss: 1.527, Global test loss: 1.374, Global test accuracy: 59.00
Round   6, Train loss: 1.431, Test loss: 1.398, Test accuracy: 52.01
Round   6, Global train loss: 1.431, Global test loss: 1.270, Global test accuracy: 60.00
Round   7, Train loss: 1.366, Test loss: 1.387, Test accuracy: 52.42
Round   7, Global train loss: 1.366, Global test loss: 1.185, Global test accuracy: 62.40
Round   8, Train loss: 1.456, Test loss: 1.358, Test accuracy: 53.59
Round   8, Global train loss: 1.456, Global test loss: 1.342, Global test accuracy: 60.10
Round   9, Train loss: 1.233, Test loss: 1.324, Test accuracy: 55.04
Round   9, Global train loss: 1.233, Global test loss: 1.224, Global test accuracy: 62.80
Round  10, Train loss: 1.210, Test loss: 1.308, Test accuracy: 55.80
Round  10, Global train loss: 1.210, Global test loss: 1.138, Global test accuracy: 63.00
Round  11, Train loss: 1.310, Test loss: 1.297, Test accuracy: 56.17
Round  11, Global train loss: 1.310, Global test loss: 1.216, Global test accuracy: 62.00
Round  12, Train loss: 1.242, Test loss: 1.271, Test accuracy: 57.45
Round  12, Global train loss: 1.242, Global test loss: 1.246, Global test accuracy: 63.60
Round  13, Train loss: 1.226, Test loss: 1.256, Test accuracy: 58.30
Round  13, Global train loss: 1.226, Global test loss: 1.205, Global test accuracy: 62.30
Round  14, Train loss: 1.214, Test loss: 1.229, Test accuracy: 59.20
Round  14, Global train loss: 1.214, Global test loss: 1.215, Global test accuracy: 62.00
Round  15, Train loss: 1.118, Test loss: 1.233, Test accuracy: 59.27
Round  15, Global train loss: 1.118, Global test loss: 1.192, Global test accuracy: 63.80
Round  16, Train loss: 1.110, Test loss: 1.236, Test accuracy: 59.42
Round  16, Global train loss: 1.110, Global test loss: 1.180, Global test accuracy: 64.90
Round  17, Train loss: 0.984, Test loss: 1.224, Test accuracy: 59.94
Round  17, Global train loss: 0.984, Global test loss: 1.101, Global test accuracy: 65.60
Round  18, Train loss: 1.054, Test loss: 1.221, Test accuracy: 60.52
Round  18, Global train loss: 1.054, Global test loss: 1.190, Global test accuracy: 64.00
Round  19, Train loss: 0.964, Test loss: 1.227, Test accuracy: 60.79
Round  19, Global train loss: 0.964, Global test loss: 1.092, Global test accuracy: 64.60
Round  20, Train loss: 0.858, Test loss: 1.223, Test accuracy: 61.08
Round  20, Global train loss: 0.858, Global test loss: 1.052, Global test accuracy: 65.00
Round  21, Train loss: 0.832, Test loss: 1.221, Test accuracy: 61.38
Round  21, Global train loss: 0.832, Global test loss: 1.125, Global test accuracy: 65.00
Round  22, Train loss: 0.909, Test loss: 1.213, Test accuracy: 61.55
Round  22, Global train loss: 0.909, Global test loss: 1.027, Global test accuracy: 66.00
Round  23, Train loss: 0.825, Test loss: 1.229, Test accuracy: 61.45
Round  23, Global train loss: 0.825, Global test loss: 1.088, Global test accuracy: 64.80
Round  24, Train loss: 0.891, Test loss: 1.224, Test accuracy: 62.19
Round  24, Global train loss: 0.891, Global test loss: 1.108, Global test accuracy: 63.90
Round  25, Train loss: 0.824, Test loss: 1.226, Test accuracy: 62.24
Round  25, Global train loss: 0.824, Global test loss: 1.043, Global test accuracy: 67.30
Round  26, Train loss: 0.715, Test loss: 1.243, Test accuracy: 62.16
Round  26, Global train loss: 0.715, Global test loss: 1.046, Global test accuracy: 65.50
Round  27, Train loss: 0.745, Test loss: 1.246, Test accuracy: 62.57
Round  27, Global train loss: 0.745, Global test loss: 1.001, Global test accuracy: 66.90
Round  28, Train loss: 0.730, Test loss: 1.286, Test accuracy: 62.19
Round  28, Global train loss: 0.730, Global test loss: 1.029, Global test accuracy: 66.10
Round  29, Train loss: 0.613, Test loss: 1.285, Test accuracy: 62.68
Round  29, Global train loss: 0.613, Global test loss: 0.960, Global test accuracy: 68.00
Round  30, Train loss: 0.766, Test loss: 1.317, Test accuracy: 62.64
Round  30, Global train loss: 0.766, Global test loss: 1.076, Global test accuracy: 66.60
Round  31, Train loss: 0.582, Test loss: 1.311, Test accuracy: 62.91
Round  31, Global train loss: 0.582, Global test loss: 1.044, Global test accuracy: 66.90
Round  32, Train loss: 0.577, Test loss: 1.331, Test accuracy: 62.87
Round  32, Global train loss: 0.577, Global test loss: 1.070, Global test accuracy: 63.60
Round  33, Train loss: 0.581, Test loss: 1.339, Test accuracy: 62.91
Round  33, Global train loss: 0.581, Global test loss: 1.034, Global test accuracy: 66.60
Round  34, Train loss: 0.598, Test loss: 1.342, Test accuracy: 62.97
Round  34, Global train loss: 0.598, Global test loss: 1.063, Global test accuracy: 64.70
Round  35, Train loss: 0.572, Test loss: 1.381, Test accuracy: 62.65
Round  35, Global train loss: 0.572, Global test loss: 1.074, Global test accuracy: 65.00
Round  36, Train loss: 0.582, Test loss: 1.393, Test accuracy: 62.88
Round  36, Global train loss: 0.582, Global test loss: 1.026, Global test accuracy: 66.50
Round  37, Train loss: 0.546, Test loss: 1.377, Test accuracy: 63.27
Round  37, Global train loss: 0.546, Global test loss: 1.029, Global test accuracy: 66.10
Round  38, Train loss: 0.475, Test loss: 1.415, Test accuracy: 63.19
Round  38, Global train loss: 0.475, Global test loss: 1.021, Global test accuracy: 67.80
Round  39, Train loss: 0.469, Test loss: 1.410, Test accuracy: 63.63
Round  39, Global train loss: 0.469, Global test loss: 1.084, Global test accuracy: 64.50
Round  40, Train loss: 0.460, Test loss: 1.391, Test accuracy: 63.70
Round  40, Global train loss: 0.460, Global test loss: 1.056, Global test accuracy: 64.20
Round  41, Train loss: 0.600, Test loss: 1.394, Test accuracy: 63.67
Round  41, Global train loss: 0.600, Global test loss: 1.117, Global test accuracy: 64.00
Round  42, Train loss: 0.427, Test loss: 1.420, Test accuracy: 63.72
Round  42, Global train loss: 0.427, Global test loss: 1.074, Global test accuracy: 64.00
Round  43, Train loss: 0.465, Test loss: 1.445, Test accuracy: 63.74
Round  43, Global train loss: 0.465, Global test loss: 1.057, Global test accuracy: 65.70
Round  44, Train loss: 0.414, Test loss: 1.478, Test accuracy: 63.73
Round  44, Global train loss: 0.414, Global test loss: 1.061, Global test accuracy: 66.90
Round  45, Train loss: 0.475, Test loss: 1.488, Test accuracy: 63.70
Round  45, Global train loss: 0.475, Global test loss: 1.073, Global test accuracy: 64.60
Round  46, Train loss: 0.438, Test loss: 1.516, Test accuracy: 63.57
Round  46, Global train loss: 0.438, Global test loss: 1.009, Global test accuracy: 65.80
Round  47, Train loss: 0.460, Test loss: 1.517, Test accuracy: 63.62
Round  47, Global train loss: 0.460, Global test loss: 1.100, Global test accuracy: 65.60
Round  48, Train loss: 0.384, Test loss: 1.495, Test accuracy: 63.95
Round  48, Global train loss: 0.384, Global test loss: 1.041, Global test accuracy: 64.90
Round  49, Train loss: 0.392, Test loss: 1.513, Test accuracy: 63.73
Round  49, Global train loss: 0.392, Global test loss: 1.031, Global test accuracy: 66.40
Round  50, Train loss: 0.358, Test loss: 1.544, Test accuracy: 63.75
Round  50, Global train loss: 0.358, Global test loss: 1.100, Global test accuracy: 63.80
Round  51, Train loss: 0.301, Test loss: 1.563, Test accuracy: 63.60
Round  51, Global train loss: 0.301, Global test loss: 1.055, Global test accuracy: 66.70
Round  52, Train loss: 0.342, Test loss: 1.578, Test accuracy: 63.49
Round  52, Global train loss: 0.342, Global test loss: 1.084, Global test accuracy: 64.70
Round  53, Train loss: 0.301, Test loss: 1.585, Test accuracy: 63.91
Round  53, Global train loss: 0.301, Global test loss: 1.066, Global test accuracy: 64.40
Round  54, Train loss: 0.412, Test loss: 1.639, Test accuracy: 63.86
Round  54, Global train loss: 0.412, Global test loss: 1.021, Global test accuracy: 66.60
Round  55, Train loss: 0.332, Test loss: 1.639, Test accuracy: 64.00
Round  55, Global train loss: 0.332, Global test loss: 1.053, Global test accuracy: 65.50
Round  56, Train loss: 0.310, Test loss: 1.658, Test accuracy: 63.98
Round  56, Global train loss: 0.310, Global test loss: 1.025, Global test accuracy: 66.70
Round  57, Train loss: 0.299, Test loss: 1.646, Test accuracy: 64.20
Round  57, Global train loss: 0.299, Global test loss: 1.082, Global test accuracy: 63.10
Round  58, Train loss: 0.288, Test loss: 1.650, Test accuracy: 64.45
Round  58, Global train loss: 0.288, Global test loss: 1.069, Global test accuracy: 68.40
Round  59, Train loss: 0.244, Test loss: 1.664, Test accuracy: 64.48
Round  59, Global train loss: 0.244, Global test loss: 1.039, Global test accuracy: 66.80
Round  60, Train loss: 0.310, Test loss: 1.669, Test accuracy: 64.17
Round  60, Global train loss: 0.310, Global test loss: 1.059, Global test accuracy: 63.70
Round  61, Train loss: 0.261, Test loss: 1.696, Test accuracy: 64.28
Round  61, Global train loss: 0.261, Global test loss: 1.100, Global test accuracy: 63.60
Round  62, Train loss: 0.306, Test loss: 1.739, Test accuracy: 64.04
Round  62, Global train loss: 0.306, Global test loss: 1.017, Global test accuracy: 67.10
Round  63, Train loss: 0.246, Test loss: 1.769, Test accuracy: 63.81
Round  63, Global train loss: 0.246, Global test loss: 1.080, Global test accuracy: 64.90
Round  64, Train loss: 0.280, Test loss: 1.731, Test accuracy: 64.14
Round  64, Global train loss: 0.280, Global test loss: 1.102, Global test accuracy: 63.70
Round  65, Train loss: 0.253, Test loss: 1.761, Test accuracy: 64.28
Round  65, Global train loss: 0.253, Global test loss: 1.068, Global test accuracy: 65.80
Round  66, Train loss: 0.241, Test loss: 1.736, Test accuracy: 64.39
Round  66, Global train loss: 0.241, Global test loss: 1.072, Global test accuracy: 66.10
Round  67, Train loss: 0.257, Test loss: 1.757, Test accuracy: 64.28
Round  67, Global train loss: 0.257, Global test loss: 0.997, Global test accuracy: 68.50
Round  68, Train loss: 0.244, Test loss: 1.770, Test accuracy: 64.39
Round  68, Global train loss: 0.244, Global test loss: 1.076, Global test accuracy: 65.30
Round  69, Train loss: 0.209, Test loss: 1.790, Test accuracy: 64.25
Round  69, Global train loss: 0.209, Global test loss: 1.089, Global test accuracy: 64.00
Round  70, Train loss: 0.219, Test loss: 1.785, Test accuracy: 64.45
Round  70, Global train loss: 0.219, Global test loss: 1.101, Global test accuracy: 63.80
Round  71, Train loss: 0.223, Test loss: 1.790, Test accuracy: 64.79
Round  71, Global train loss: 0.223, Global test loss: 1.071, Global test accuracy: 64.10
Round  72, Train loss: 0.229, Test loss: 1.840, Test accuracy: 64.62
Round  72, Global train loss: 0.229, Global test loss: 1.104, Global test accuracy: 64.90
Round  73, Train loss: 0.243, Test loss: 1.848, Test accuracy: 64.89
Round  73, Global train loss: 0.243, Global test loss: 1.177, Global test accuracy: 59.90
Round  74, Train loss: 0.200, Test loss: 1.907, Test accuracy: 64.60
Round  74, Global train loss: 0.200, Global test loss: 1.126, Global test accuracy: 65.70
Round  75, Train loss: 0.199, Test loss: 1.891, Test accuracy: 64.17
Round  75, Global train loss: 0.199, Global test loss: 1.102, Global test accuracy: 64.00
Round  76, Train loss: 0.198, Test loss: 1.911, Test accuracy: 64.53
Round  76, Global train loss: 0.198, Global test loss: 1.062, Global test accuracy: 65.70
Round  77, Train loss: 0.208, Test loss: 1.976, Test accuracy: 64.16
Round  77, Global train loss: 0.208, Global test loss: 1.114, Global test accuracy: 63.00
Round  78, Train loss: 0.227, Test loss: 1.954, Test accuracy: 64.36
Round  78, Global train loss: 0.227, Global test loss: 1.086, Global test accuracy: 64.20
Round  79, Train loss: 0.188, Test loss: 1.944, Test accuracy: 64.73
Round  79, Global train loss: 0.188, Global test loss: 1.097, Global test accuracy: 63.40
Round  80, Train loss: 0.175, Test loss: 1.919, Test accuracy: 64.62
Round  80, Global train loss: 0.175, Global test loss: 1.086, Global test accuracy: 64.00
Round  81, Train loss: 0.171, Test loss: 1.945, Test accuracy: 64.41
Round  81, Global train loss: 0.171, Global test loss: 1.084, Global test accuracy: 65.40
Round  82, Train loss: 0.178, Test loss: 1.965, Test accuracy: 64.16
Round  82, Global train loss: 0.178, Global test loss: 1.120, Global test accuracy: 64.40
Round  83, Train loss: 0.197, Test loss: 1.988, Test accuracy: 64.25
Round  83, Global train loss: 0.197, Global test loss: 1.076, Global test accuracy: 66.30
Round  84, Train loss: 0.183, Test loss: 1.988, Test accuracy: 64.42
Round  84, Global train loss: 0.183, Global test loss: 1.123, Global test accuracy: 61.90
Round  85, Train loss: 0.163, Test loss: 1.983, Test accuracy: 64.47
Round  85, Global train loss: 0.163, Global test loss: 1.147, Global test accuracy: 61.50
Round  86, Train loss: 0.136, Test loss: 1.980, Test accuracy: 64.70
Round  86, Global train loss: 0.136, Global test loss: 1.111, Global test accuracy: 65.50
Round  87, Train loss: 0.143, Test loss: 1.981, Test accuracy: 64.69
Round  87, Global train loss: 0.143, Global test loss: 1.133, Global test accuracy: 66.30
Round  88, Train loss: 0.164, Test loss: 1.999, Test accuracy: 64.57
Round  88, Global train loss: 0.164, Global test loss: 1.101, Global test accuracy: 63.90
Round  89, Train loss: 0.144, Test loss: 1.969, Test accuracy: 65.27
Round  89, Global train loss: 0.144, Global test loss: 1.079, Global test accuracy: 64.30
Round  90, Train loss: 0.151, Test loss: 2.009, Test accuracy: 65.07
Round  90, Global train loss: 0.151, Global test loss: 1.211, Global test accuracy: 59.20
Round  91, Train loss: 0.169, Test loss: 2.026, Test accuracy: 65.04
Round  91, Global train loss: 0.169, Global test loss: 1.083, Global test accuracy: 67.00
Round  92, Train loss: 0.156, Test loss: 2.044, Test accuracy: 65.19
Round  92, Global train loss: 0.156, Global test loss: 1.135, Global test accuracy: 63.00
Round  93, Train loss: 0.140, Test loss: 2.048, Test accuracy: 64.74
Round  93, Global train loss: 0.140, Global test loss: 1.129, Global test accuracy: 62.00
Round  94, Train loss: 0.133, Test loss: 2.084, Test accuracy: 64.48
Round  94, Global train loss: 0.133, Global test loss: 1.148, Global test accuracy: 63.40
Round  95, Train loss: 0.163, Test loss: 2.114, Test accuracy: 64.30
Round  95, Global train loss: 0.163, Global test loss: 1.084, Global test accuracy: 66.20
Round  96, Train loss: 0.138, Test loss: 2.130, Test accuracy: 64.34
Round  96, Global train loss: 0.138, Global test loss: 1.224, Global test accuracy: 59.70
Round  97, Train loss: 0.140, Test loss: 2.087, Test accuracy: 64.84
Round  97, Global train loss: 0.140, Global test loss: 1.116, Global test accuracy: 65.00
Round  98, Train loss: 0.157, Test loss: 2.098, Test accuracy: 64.72
Round  98, Global train loss: 0.157, Global test loss: 1.083, Global test accuracy: 65.80
Round  99, Train loss: 0.158, Test loss: 2.125, Test accuracy: 64.88
Round  99, Global train loss: 0.158, Global test loss: 1.107, Global test accuracy: 65.00
Final Round, Train loss: 0.116, Test loss: 2.218, Test accuracy: 64.43
Final Round, Global train loss: 0.116, Global test loss: 1.107, Global test accuracy: 65.00
Average accuracy final 10 rounds: 64.7605 

Average global accuracy final 10 rounds: 63.629999999999995 

3280.542881011963
[2.495131492614746, 4.990262985229492, 7.224772930145264, 9.459282875061035, 11.713610649108887, 13.967938423156738, 16.23392391204834, 18.49990940093994, 20.75741744041443, 23.014925479888916, 25.28013586997986, 27.5453462600708, 29.81670045852661, 32.08805465698242, 34.36089301109314, 36.63373136520386, 38.904324531555176, 41.174917697906494, 43.444664001464844, 45.71441030502319, 48.00595140457153, 50.29749250411987, 52.59049677848816, 54.883501052856445, 57.19995927810669, 59.516417503356934, 61.784308433532715, 64.0521993637085, 66.32026886940002, 68.58833837509155, 70.85798072814941, 73.12762308120728, 75.39217853546143, 77.65673398971558, 79.92921590805054, 82.2016978263855, 84.51544713973999, 86.82919645309448, 89.11064887046814, 91.3921012878418, 93.68764615058899, 95.98319101333618, 98.25785374641418, 100.53251647949219, 102.8071060180664, 105.08169555664062, 107.35774302482605, 109.63379049301147, 111.94049453735352, 114.24719858169556, 116.52194261550903, 118.79668664932251, 121.12288737297058, 123.44908809661865, 125.71906161308289, 127.98903512954712, 130.255597114563, 132.52215909957886, 134.8119580745697, 137.10175704956055, 139.3678801059723, 141.63400316238403, 143.89657545089722, 146.1591477394104, 148.40049505233765, 150.6418423652649, 152.8939561843872, 155.14607000350952, 157.40583276748657, 159.66559553146362, 161.9551010131836, 164.24460649490356, 166.54673552513123, 168.8488645553589, 171.13972544670105, 173.4305863380432, 175.72112560272217, 178.01166486740112, 180.28223061561584, 182.55279636383057, 184.85158562660217, 187.15037488937378, 189.4500606060028, 191.74974632263184, 194.0133571624756, 196.27696800231934, 198.5616638660431, 200.84635972976685, 203.11504364013672, 205.3837275505066, 207.6535768508911, 209.92342615127563, 212.19631266593933, 214.46919918060303, 216.73388743400574, 218.99857568740845, 221.30162000656128, 223.6046643257141, 225.94909119606018, 228.29351806640625, 230.55726051330566, 232.82100296020508, 235.08607840538025, 237.35115385055542, 239.71550750732422, 242.07986116409302, 244.36593985557556, 246.6520185470581, 248.92763018608093, 251.20324182510376, 253.48259139060974, 255.76194095611572, 258.0392396450043, 260.3165383338928, 262.58220052719116, 264.8478627204895, 267.1425848007202, 269.4373068809509, 271.7222340106964, 274.0071611404419, 276.34208726882935, 278.6770133972168, 280.9841823577881, 283.2913513183594, 285.6306037902832, 287.96985626220703, 290.26477336883545, 292.55969047546387, 294.9300060272217, 297.3003215789795, 299.5941798686981, 301.88803815841675, 304.18857741355896, 306.4891166687012, 308.79283332824707, 311.09654998779297, 313.42377185821533, 315.7509937286377, 318.0537052154541, 320.3564167022705, 322.73269605636597, 325.1089754104614, 327.4802460670471, 329.8515167236328, 332.2602529525757, 334.66898918151855, 337.15695548057556, 339.64492177963257, 342.10300874710083, 344.5610957145691, 347.05158734321594, 349.5420789718628, 351.9187903404236, 354.2955017089844, 356.6745398044586, 359.05357789993286, 361.4796919822693, 363.9058060646057, 366.25829339027405, 368.6107807159424, 371.05877137184143, 373.5067620277405, 375.9534180164337, 378.40007400512695, 380.93061804771423, 383.4611620903015, 385.8997550010681, 388.3383479118347, 390.8759515285492, 393.4135551452637, 395.8490629196167, 398.2845706939697, 400.78564453125, 403.2867183685303, 405.8366746902466, 408.3866310119629, 410.76524114608765, 413.1438512802124, 415.6829972267151, 418.2221431732178, 420.70534491539, 423.18854665756226, 425.68805861473083, 428.1875705718994, 430.7398545742035, 433.29213857650757, 435.82838582992554, 438.3646330833435, 440.86053466796875, 443.356436252594, 445.839323759079, 448.32221126556396, 450.7803294658661, 453.2384476661682, 455.6944637298584, 458.1504797935486, 460.7621431350708, 463.373806476593, 465.9443907737732, 468.51497507095337, 471.0555965900421, 473.59621810913086]
[38.76, 38.76, 43.125, 43.125, 46.915, 46.915, 48.885, 48.885, 50.145, 50.145, 51.565, 51.565, 52.01, 52.01, 52.425, 52.425, 53.595, 53.595, 55.04, 55.04, 55.805, 55.805, 56.175, 56.175, 57.455, 57.455, 58.295, 58.295, 59.195, 59.195, 59.265, 59.265, 59.425, 59.425, 59.94, 59.94, 60.52, 60.52, 60.79, 60.79, 61.075, 61.075, 61.385, 61.385, 61.545, 61.545, 61.455, 61.455, 62.185, 62.185, 62.245, 62.245, 62.16, 62.16, 62.57, 62.57, 62.19, 62.19, 62.68, 62.68, 62.64, 62.64, 62.905, 62.905, 62.865, 62.865, 62.905, 62.905, 62.965, 62.965, 62.65, 62.65, 62.88, 62.88, 63.265, 63.265, 63.19, 63.19, 63.635, 63.635, 63.695, 63.695, 63.675, 63.675, 63.715, 63.715, 63.74, 63.74, 63.73, 63.73, 63.7, 63.7, 63.57, 63.57, 63.625, 63.625, 63.945, 63.945, 63.735, 63.735, 63.75, 63.75, 63.6, 63.6, 63.495, 63.495, 63.915, 63.915, 63.86, 63.86, 64.0, 64.0, 63.985, 63.985, 64.205, 64.205, 64.455, 64.455, 64.485, 64.485, 64.165, 64.165, 64.275, 64.275, 64.04, 64.04, 63.81, 63.81, 64.135, 64.135, 64.28, 64.28, 64.39, 64.39, 64.275, 64.275, 64.395, 64.395, 64.245, 64.245, 64.455, 64.455, 64.79, 64.79, 64.62, 64.62, 64.895, 64.895, 64.6, 64.6, 64.17, 64.17, 64.53, 64.53, 64.155, 64.155, 64.365, 64.365, 64.73, 64.73, 64.62, 64.62, 64.41, 64.41, 64.155, 64.155, 64.255, 64.255, 64.42, 64.42, 64.475, 64.475, 64.7, 64.7, 64.69, 64.69, 64.57, 64.57, 65.265, 65.265, 65.07, 65.07, 65.04, 65.04, 65.19, 65.19, 64.74, 64.74, 64.485, 64.485, 64.295, 64.295, 64.345, 64.345, 64.845, 64.845, 64.715, 64.715, 64.88, 64.88, 64.43, 64.43]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.148, Test loss: 1.905, Test accuracy: 36.00
Round   0, Global train loss: 2.148, Global test loss: 1.924, Global test accuracy: 36.90
Round   1, Train loss: 1.886, Test loss: 1.670, Test accuracy: 43.98
Round   1, Global train loss: 1.886, Global test loss: 1.607, Global test accuracy: 48.70
Round   2, Train loss: 1.703, Test loss: 1.557, Test accuracy: 46.42
Round   2, Global train loss: 1.703, Global test loss: 1.423, Global test accuracy: 52.30
Round   3, Train loss: 1.560, Test loss: 1.473, Test accuracy: 49.53
Round   3, Global train loss: 1.560, Global test loss: 1.278, Global test accuracy: 58.10
Round   4, Train loss: 1.433, Test loss: 1.371, Test accuracy: 53.14
Round   4, Global train loss: 1.433, Global test loss: 1.192, Global test accuracy: 60.50
Round   5, Train loss: 1.316, Test loss: 1.280, Test accuracy: 56.59
Round   5, Global train loss: 1.316, Global test loss: 1.103, Global test accuracy: 64.00
Round   6, Train loss: 1.245, Test loss: 1.228, Test accuracy: 58.67
Round   6, Global train loss: 1.245, Global test loss: 1.030, Global test accuracy: 66.90
Round   7, Train loss: 1.154, Test loss: 1.225, Test accuracy: 58.67
Round   7, Global train loss: 1.154, Global test loss: 0.999, Global test accuracy: 67.10
Round   8, Train loss: 1.099, Test loss: 1.168, Test accuracy: 61.01
Round   8, Global train loss: 1.099, Global test loss: 0.940, Global test accuracy: 69.00
Round   9, Train loss: 1.020, Test loss: 1.138, Test accuracy: 62.11
Round   9, Global train loss: 1.020, Global test loss: 0.926, Global test accuracy: 68.40
Round  10, Train loss: 0.963, Test loss: 1.120, Test accuracy: 62.76
Round  10, Global train loss: 0.963, Global test loss: 0.882, Global test accuracy: 70.20
Round  11, Train loss: 0.938, Test loss: 1.080, Test accuracy: 64.38
Round  11, Global train loss: 0.938, Global test loss: 0.842, Global test accuracy: 72.80
Round  12, Train loss: 0.888, Test loss: 1.058, Test accuracy: 65.11
Round  12, Global train loss: 0.888, Global test loss: 0.846, Global test accuracy: 73.30
Round  13, Train loss: 0.830, Test loss: 1.032, Test accuracy: 66.48
Round  13, Global train loss: 0.830, Global test loss: 0.823, Global test accuracy: 73.70
Round  14, Train loss: 0.765, Test loss: 1.045, Test accuracy: 66.33
Round  14, Global train loss: 0.765, Global test loss: 0.805, Global test accuracy: 74.60
Round  15, Train loss: 0.750, Test loss: 1.020, Test accuracy: 67.13
Round  15, Global train loss: 0.750, Global test loss: 0.762, Global test accuracy: 75.90
Round  16, Train loss: 0.709, Test loss: 1.008, Test accuracy: 68.11
Round  16, Global train loss: 0.709, Global test loss: 0.768, Global test accuracy: 75.90
Round  17, Train loss: 0.682, Test loss: 0.975, Test accuracy: 69.09
Round  17, Global train loss: 0.682, Global test loss: 0.786, Global test accuracy: 74.40
Round  18, Train loss: 0.649, Test loss: 0.986, Test accuracy: 69.25
Round  18, Global train loss: 0.649, Global test loss: 0.769, Global test accuracy: 75.60
Round  19, Train loss: 0.601, Test loss: 0.973, Test accuracy: 69.91
Round  19, Global train loss: 0.601, Global test loss: 0.767, Global test accuracy: 74.30
Round  20, Train loss: 0.615, Test loss: 0.985, Test accuracy: 69.66
Round  20, Global train loss: 0.615, Global test loss: 0.740, Global test accuracy: 74.50
Round  21, Train loss: 0.567, Test loss: 1.002, Test accuracy: 69.52
Round  21, Global train loss: 0.567, Global test loss: 0.741, Global test accuracy: 75.80
Round  22, Train loss: 0.515, Test loss: 0.998, Test accuracy: 70.00
Round  22, Global train loss: 0.515, Global test loss: 0.777, Global test accuracy: 75.30
Round  23, Train loss: 0.505, Test loss: 0.998, Test accuracy: 70.28
Round  23, Global train loss: 0.505, Global test loss: 0.788, Global test accuracy: 74.90
Round  24, Train loss: 0.507, Test loss: 1.002, Test accuracy: 70.58
Round  24, Global train loss: 0.507, Global test loss: 0.747, Global test accuracy: 76.30
Round  25, Train loss: 0.445, Test loss: 0.995, Test accuracy: 70.98
Round  25, Global train loss: 0.445, Global test loss: 0.817, Global test accuracy: 75.30
Round  26, Train loss: 0.446, Test loss: 1.004, Test accuracy: 71.33
Round  26, Global train loss: 0.446, Global test loss: 0.787, Global test accuracy: 75.20
Round  27, Train loss: 0.467, Test loss: 1.017, Test accuracy: 71.36
Round  27, Global train loss: 0.467, Global test loss: 0.751, Global test accuracy: 75.40
Round  28, Train loss: 0.436, Test loss: 1.016, Test accuracy: 71.59
Round  28, Global train loss: 0.436, Global test loss: 0.767, Global test accuracy: 75.60
Round  29, Train loss: 0.371, Test loss: 1.005, Test accuracy: 71.95
Round  29, Global train loss: 0.371, Global test loss: 0.778, Global test accuracy: 76.00
Round  30, Train loss: 0.369, Test loss: 1.018, Test accuracy: 71.88
Round  30, Global train loss: 0.369, Global test loss: 0.764, Global test accuracy: 74.90
Round  31, Train loss: 0.376, Test loss: 1.030, Test accuracy: 71.89
Round  31, Global train loss: 0.376, Global test loss: 0.783, Global test accuracy: 76.50
Round  32, Train loss: 0.340, Test loss: 1.028, Test accuracy: 72.02
Round  32, Global train loss: 0.340, Global test loss: 0.756, Global test accuracy: 77.70
Round  33, Train loss: 0.329, Test loss: 1.017, Test accuracy: 72.60
Round  33, Global train loss: 0.329, Global test loss: 0.773, Global test accuracy: 77.30
Round  34, Train loss: 0.323, Test loss: 1.015, Test accuracy: 72.98
Round  34, Global train loss: 0.323, Global test loss: 0.748, Global test accuracy: 77.80
Round  35, Train loss: 0.303, Test loss: 1.011, Test accuracy: 73.20
Round  35, Global train loss: 0.303, Global test loss: 0.780, Global test accuracy: 77.10
Round  36, Train loss: 0.256, Test loss: 1.033, Test accuracy: 73.41
Round  36, Global train loss: 0.256, Global test loss: 0.872, Global test accuracy: 77.20
Round  37, Train loss: 0.262, Test loss: 1.041, Test accuracy: 73.31
Round  37, Global train loss: 0.262, Global test loss: 0.798, Global test accuracy: 77.30
Round  38, Train loss: 0.302, Test loss: 1.037, Test accuracy: 73.73
Round  38, Global train loss: 0.302, Global test loss: 0.790, Global test accuracy: 77.00
Round  39, Train loss: 0.225, Test loss: 1.065, Test accuracy: 73.26
Round  39, Global train loss: 0.225, Global test loss: 0.816, Global test accuracy: 77.40
Round  40, Train loss: 0.248, Test loss: 1.050, Test accuracy: 73.48
Round  40, Global train loss: 0.248, Global test loss: 0.778, Global test accuracy: 78.30
Round  41, Train loss: 0.272, Test loss: 1.092, Test accuracy: 72.69
Round  41, Global train loss: 0.272, Global test loss: 0.825, Global test accuracy: 77.40
Round  42, Train loss: 0.224, Test loss: 1.119, Test accuracy: 72.83
Round  42, Global train loss: 0.224, Global test loss: 0.819, Global test accuracy: 77.50
Round  43, Train loss: 0.244, Test loss: 1.119, Test accuracy: 73.11
Round  43, Global train loss: 0.244, Global test loss: 0.792, Global test accuracy: 78.30
Round  44, Train loss: 0.197, Test loss: 1.121, Test accuracy: 73.63
Round  44, Global train loss: 0.197, Global test loss: 0.800, Global test accuracy: 78.60
Round  45, Train loss: 0.194, Test loss: 1.115, Test accuracy: 73.77
Round  45, Global train loss: 0.194, Global test loss: 0.827, Global test accuracy: 77.90
Round  46, Train loss: 0.180, Test loss: 1.114, Test accuracy: 73.94
Round  46, Global train loss: 0.180, Global test loss: 0.854, Global test accuracy: 77.70
Round  47, Train loss: 0.216, Test loss: 1.100, Test accuracy: 74.28
Round  47, Global train loss: 0.216, Global test loss: 0.791, Global test accuracy: 79.10
Round  48, Train loss: 0.167, Test loss: 1.098, Test accuracy: 74.66
Round  48, Global train loss: 0.167, Global test loss: 0.816, Global test accuracy: 79.80
Round  49, Train loss: 0.172, Test loss: 1.097, Test accuracy: 74.87
Round  49, Global train loss: 0.172, Global test loss: 0.813, Global test accuracy: 79.10
Round  50, Train loss: 0.161, Test loss: 1.094, Test accuracy: 74.92
Round  50, Global train loss: 0.161, Global test loss: 0.802, Global test accuracy: 79.90
Round  51, Train loss: 0.158, Test loss: 1.127, Test accuracy: 74.52
Round  51, Global train loss: 0.158, Global test loss: 0.870, Global test accuracy: 79.60
Round  52, Train loss: 0.187, Test loss: 1.118, Test accuracy: 74.84
Round  52, Global train loss: 0.187, Global test loss: 0.829, Global test accuracy: 79.20
Round  53, Train loss: 0.118, Test loss: 1.106, Test accuracy: 75.12
Round  53, Global train loss: 0.118, Global test loss: 0.873, Global test accuracy: 79.50
Round  54, Train loss: 0.159, Test loss: 1.120, Test accuracy: 75.09
Round  54, Global train loss: 0.159, Global test loss: 0.841, Global test accuracy: 80.20
Round  55, Train loss: 0.145, Test loss: 1.116, Test accuracy: 75.54
Round  55, Global train loss: 0.145, Global test loss: 0.873, Global test accuracy: 79.20
Round  56, Train loss: 0.150, Test loss: 1.114, Test accuracy: 75.52
Round  56, Global train loss: 0.150, Global test loss: 0.826, Global test accuracy: 80.10
Round  57, Train loss: 0.148, Test loss: 1.095, Test accuracy: 75.83
Round  57, Global train loss: 0.148, Global test loss: 0.841, Global test accuracy: 80.40
Round  58, Train loss: 0.096, Test loss: 1.083, Test accuracy: 76.13
Round  58, Global train loss: 0.096, Global test loss: 0.881, Global test accuracy: 80.10
Round  59, Train loss: 0.155, Test loss: 1.105, Test accuracy: 76.03
Round  59, Global train loss: 0.155, Global test loss: 0.820, Global test accuracy: 80.20
Round  60, Train loss: 0.105, Test loss: 1.130, Test accuracy: 75.86
Round  60, Global train loss: 0.105, Global test loss: 0.850, Global test accuracy: 79.90
Round  61, Train loss: 0.130, Test loss: 1.128, Test accuracy: 76.00
Round  61, Global train loss: 0.130, Global test loss: 0.792, Global test accuracy: 80.80
Round  62, Train loss: 0.078, Test loss: 1.152, Test accuracy: 75.85
Round  62, Global train loss: 0.078, Global test loss: 0.892, Global test accuracy: 79.10
Round  63, Train loss: 0.086, Test loss: 1.125, Test accuracy: 75.86
Round  63, Global train loss: 0.086, Global test loss: 0.864, Global test accuracy: 80.20
Round  64, Train loss: 0.112, Test loss: 1.158, Test accuracy: 75.96
Round  64, Global train loss: 0.112, Global test loss: 0.902, Global test accuracy: 79.40
Round  65, Train loss: 0.157, Test loss: 1.173, Test accuracy: 75.86
Round  65, Global train loss: 0.157, Global test loss: 0.844, Global test accuracy: 80.20
Round  66, Train loss: 0.076, Test loss: 1.153, Test accuracy: 76.53
Round  66, Global train loss: 0.076, Global test loss: 0.896, Global test accuracy: 80.20
Round  67, Train loss: 0.106, Test loss: 1.173, Test accuracy: 76.17
Round  67, Global train loss: 0.106, Global test loss: 0.867, Global test accuracy: 80.30
Round  68, Train loss: 0.084, Test loss: 1.188, Test accuracy: 76.11
Round  68, Global train loss: 0.084, Global test loss: 0.897, Global test accuracy: 79.00
Round  69, Train loss: 0.096, Test loss: 1.195, Test accuracy: 75.92
Round  69, Global train loss: 0.096, Global test loss: 0.881, Global test accuracy: 80.00
Round  70, Train loss: 0.103, Test loss: 1.209, Test accuracy: 75.91
Round  70, Global train loss: 0.103, Global test loss: 0.914, Global test accuracy: 79.30
Round  71, Train loss: 0.080, Test loss: 1.174, Test accuracy: 76.26
Round  71, Global train loss: 0.080, Global test loss: 0.879, Global test accuracy: 80.50
Round  72, Train loss: 0.089, Test loss: 1.190, Test accuracy: 76.42
Round  72, Global train loss: 0.089, Global test loss: 0.923, Global test accuracy: 79.90
Round  73, Train loss: 0.111, Test loss: 1.173, Test accuracy: 76.67
Round  73, Global train loss: 0.111, Global test loss: 0.872, Global test accuracy: 81.20
Round  74, Train loss: 0.093, Test loss: 1.174, Test accuracy: 76.77
Round  74, Global train loss: 0.093, Global test loss: 0.907, Global test accuracy: 80.90
Round  75, Train loss: 0.084, Test loss: 1.167, Test accuracy: 76.75
Round  75, Global train loss: 0.084, Global test loss: 0.887, Global test accuracy: 80.00
Round  76, Train loss: 0.060, Test loss: 1.156, Test accuracy: 77.03
Round  76, Global train loss: 0.060, Global test loss: 0.954, Global test accuracy: 80.50
Round  77, Train loss: 0.077, Test loss: 1.158, Test accuracy: 77.21
Round  77, Global train loss: 0.077, Global test loss: 0.875, Global test accuracy: 81.00
Round  78, Train loss: 0.095, Test loss: 1.173, Test accuracy: 77.03
Round  78, Global train loss: 0.095, Global test loss: 0.908, Global test accuracy: 79.90
Round  79, Train loss: 0.096, Test loss: 1.198, Test accuracy: 76.53
Round  79, Global train loss: 0.096, Global test loss: 0.867, Global test accuracy: 79.60
Round  80, Train loss: 0.053, Test loss: 1.171, Test accuracy: 76.90
Round  80, Global train loss: 0.053, Global test loss: 0.926, Global test accuracy: 80.50
Round  81, Train loss: 0.073, Test loss: 1.162, Test accuracy: 77.00
Round  81, Global train loss: 0.073, Global test loss: 0.916, Global test accuracy: 80.90
Round  82, Train loss: 0.061, Test loss: 1.182, Test accuracy: 76.95
Round  82, Global train loss: 0.061, Global test loss: 1.005, Global test accuracy: 80.10
Round  83, Train loss: 0.085, Test loss: 1.206, Test accuracy: 76.77
Round  83, Global train loss: 0.085, Global test loss: 0.961, Global test accuracy: 79.80
Round  84, Train loss: 0.063, Test loss: 1.211, Test accuracy: 76.91
Round  84, Global train loss: 0.063, Global test loss: 0.982, Global test accuracy: 78.90
Round  85, Train loss: 0.045, Test loss: 1.211, Test accuracy: 77.04
Round  85, Global train loss: 0.045, Global test loss: 0.966, Global test accuracy: 78.40
Round  86, Train loss: 0.059, Test loss: 1.206, Test accuracy: 77.12
Round  86, Global train loss: 0.059, Global test loss: 0.921, Global test accuracy: 80.40
Round  87, Train loss: 0.066, Test loss: 1.184, Test accuracy: 77.69
Round  87, Global train loss: 0.066, Global test loss: 0.968, Global test accuracy: 80.70
Round  88, Train loss: 0.094, Test loss: 1.169, Test accuracy: 77.65
Round  88, Global train loss: 0.094, Global test loss: 0.922, Global test accuracy: 79.80
Round  89, Train loss: 0.065, Test loss: 1.160, Test accuracy: 78.09
Round  89, Global train loss: 0.065, Global test loss: 0.945, Global test accuracy: 80.40
Round  90, Train loss: 0.048, Test loss: 1.176, Test accuracy: 78.02
Round  90, Global train loss: 0.048, Global test loss: 0.962, Global test accuracy: 80.60
Round  91, Train loss: 0.063, Test loss: 1.194, Test accuracy: 77.80
Round  91, Global train loss: 0.063, Global test loss: 1.035, Global test accuracy: 78.40
Round  92, Train loss: 0.036, Test loss: 1.167, Test accuracy: 77.94
Round  92, Global train loss: 0.036, Global test loss: 0.963, Global test accuracy: 81.70
Round  93, Train loss: 0.049, Test loss: 1.185, Test accuracy: 77.92
Round  93, Global train loss: 0.049, Global test loss: 0.978, Global test accuracy: 80.30
Round  94, Train loss: 0.046, Test loss: 1.204, Test accuracy: 77.69
Round  94, Global train loss: 0.046, Global test loss: 0.983, Global test accuracy: 80.10
Round  95, Train loss: 0.060, Test loss: 1.202, Test accuracy: 77.56
Round  95, Global train loss: 0.060, Global test loss: 0.996, Global test accuracy: 79.30
Round  96, Train loss: 0.066, Test loss: 1.219, Test accuracy: 77.52
Round  96, Global train loss: 0.066, Global test loss: 0.988, Global test accuracy: 79.40
Round  97, Train loss: 0.052, Test loss: 1.231, Test accuracy: 77.64
Round  97, Global train loss: 0.052, Global test loss: 0.979, Global test accuracy: 80.90
Round  98, Train loss: 0.065, Test loss: 1.207, Test accuracy: 77.86
Round  98, Global train loss: 0.065, Global test loss: 0.987, Global test accuracy: 79.40
Round  99, Train loss: 0.033, Test loss: 1.204, Test accuracy: 77.78
Round  99, Global train loss: 0.033, Global test loss: 1.014, Global test accuracy: 79.80
Final Round, Train loss: 0.028, Test loss: 1.257, Test accuracy: 77.72
Final Round, Global train loss: 0.028, Global test loss: 1.014, Global test accuracy: 79.80
Average accuracy final 10 rounds: 77.7735 

Average global accuracy final 10 rounds: 79.99 

3574.65465760231
[2.7103683948516846, 5.420736789703369, 7.856608867645264, 10.292480945587158, 12.80499267578125, 15.317504405975342, 17.76233148574829, 20.20715856552124, 22.74005961418152, 25.272960662841797, 27.76515293121338, 30.25734519958496, 32.71999406814575, 35.18264293670654, 37.723597288131714, 40.264551639556885, 42.73906874656677, 45.21358585357666, 47.6725959777832, 50.131606101989746, 52.59216594696045, 55.05272579193115, 57.51435613632202, 59.97598648071289, 62.38854265213013, 64.80109882354736, 67.32512044906616, 69.84914207458496, 72.30533289909363, 74.7615237236023, 77.24853897094727, 79.73555421829224, 82.19423723220825, 84.65292024612427, 87.15441536903381, 89.65591049194336, 92.24102425575256, 94.82613801956177, 97.28007793426514, 99.7340178489685, 102.24034762382507, 104.74667739868164, 107.24507474899292, 109.7434720993042, 112.20437860488892, 114.66528511047363, 117.25379037857056, 119.84229564666748, 122.2781081199646, 124.71392059326172, 127.2556848526001, 129.79744911193848, 132.27219152450562, 134.74693393707275, 137.17052817344666, 139.59412240982056, 142.12387442588806, 144.65362644195557, 147.19856238365173, 149.7434983253479, 152.28145480155945, 154.819411277771, 157.3217649459839, 159.82411861419678, 162.36590790748596, 164.90769720077515, 167.45925521850586, 170.01081323623657, 172.51738357543945, 175.02395391464233, 177.70383429527283, 180.38371467590332, 182.76081013679504, 185.13790559768677, 187.66427755355835, 190.19064950942993, 192.60770797729492, 195.0247664451599, 197.43464398384094, 199.84452152252197, 202.32506275177002, 204.80560398101807, 207.2188401222229, 209.63207626342773, 212.13059163093567, 214.6291069984436, 217.0773525238037, 219.52559804916382, 221.954692363739, 224.3837866783142, 226.91120839118958, 229.43863010406494, 231.78695011138916, 234.13527011871338, 236.66262984275818, 239.18998956680298, 241.54078340530396, 243.89157724380493, 246.34521055221558, 248.79884386062622, 251.2938928604126, 253.78894186019897, 256.17109298706055, 258.5532441139221, 261.1314368247986, 263.70962953567505, 266.15785026550293, 268.6060709953308, 271.12734508514404, 273.6486191749573, 276.1626501083374, 278.67668104171753, 281.1071934700012, 283.5377058982849, 286.0656011104584, 288.59349632263184, 290.99084091186523, 293.38818550109863, 295.9801502227783, 298.572114944458, 301.0009591579437, 303.42980337142944, 306.0008296966553, 308.5718560218811, 311.100515127182, 313.6291742324829, 316.0589439868927, 318.4887137413025, 321.12464785575867, 323.76058197021484, 326.27283334732056, 328.78508472442627, 331.3236219882965, 333.86215925216675, 336.3696081638336, 338.8770570755005, 341.22011160850525, 343.56316614151, 346.0411903858185, 348.51921463012695, 350.8999252319336, 353.28063583374023, 355.72265791893005, 358.1646800041199, 360.6956374645233, 363.22659492492676, 365.6376211643219, 368.04864740371704, 370.5557062625885, 373.06276512145996, 375.4418911933899, 377.8210172653198, 380.2720477581024, 382.723078250885, 385.19308853149414, 387.66309881210327, 390.2129445075989, 392.7627902030945, 395.26216411590576, 397.76153802871704, 400.1771113872528, 402.5926847457886, 405.1088447570801, 407.6250047683716, 410.0609965324402, 412.4969882965088, 414.9208219051361, 417.3446555137634, 419.8351411819458, 422.3256268501282, 424.8369925022125, 427.3483581542969, 429.87388706207275, 432.39941596984863, 434.85745668411255, 437.31549739837646, 439.8314309120178, 442.3473644256592, 444.88906812667847, 447.43077182769775, 449.89172887802124, 452.3526859283447, 454.91016721725464, 457.46764850616455, 459.9154815673828, 462.3633146286011, 464.8556022644043, 467.3478899002075, 469.83295607566833, 472.31802225112915, 474.79724621772766, 477.2764701843262, 479.75817465782166, 482.23987913131714, 484.642080783844, 487.04428243637085, 489.5216295719147, 491.9989767074585, 494.42185711860657, 496.84473752975464, 499.34327936172485, 501.84182119369507]
[36.0, 36.0, 43.985, 43.985, 46.425, 46.425, 49.53, 49.53, 53.14, 53.14, 56.595, 56.595, 58.67, 58.67, 58.67, 58.67, 61.01, 61.01, 62.11, 62.11, 62.76, 62.76, 64.38, 64.38, 65.115, 65.115, 66.485, 66.485, 66.33, 66.33, 67.13, 67.13, 68.115, 68.115, 69.09, 69.09, 69.255, 69.255, 69.905, 69.905, 69.66, 69.66, 69.52, 69.52, 69.995, 69.995, 70.275, 70.275, 70.575, 70.575, 70.98, 70.98, 71.33, 71.33, 71.36, 71.36, 71.595, 71.595, 71.955, 71.955, 71.875, 71.875, 71.885, 71.885, 72.015, 72.015, 72.6, 72.6, 72.985, 72.985, 73.2, 73.2, 73.405, 73.405, 73.31, 73.31, 73.735, 73.735, 73.26, 73.26, 73.485, 73.485, 72.685, 72.685, 72.835, 72.835, 73.105, 73.105, 73.63, 73.63, 73.765, 73.765, 73.945, 73.945, 74.285, 74.285, 74.66, 74.66, 74.87, 74.87, 74.925, 74.925, 74.515, 74.515, 74.84, 74.84, 75.12, 75.12, 75.095, 75.095, 75.54, 75.54, 75.515, 75.515, 75.835, 75.835, 76.13, 76.13, 76.035, 76.035, 75.855, 75.855, 75.995, 75.995, 75.85, 75.85, 75.86, 75.86, 75.96, 75.96, 75.855, 75.855, 76.53, 76.53, 76.165, 76.165, 76.11, 76.11, 75.925, 75.925, 75.905, 75.905, 76.26, 76.26, 76.42, 76.42, 76.675, 76.675, 76.765, 76.765, 76.745, 76.745, 77.035, 77.035, 77.21, 77.21, 77.03, 77.03, 76.53, 76.53, 76.9, 76.9, 77.005, 77.005, 76.955, 76.955, 76.765, 76.765, 76.905, 76.905, 77.04, 77.04, 77.125, 77.125, 77.69, 77.69, 77.65, 77.65, 78.095, 78.095, 78.015, 78.015, 77.8, 77.8, 77.945, 77.945, 77.915, 77.915, 77.69, 77.69, 77.565, 77.565, 77.52, 77.52, 77.645, 77.645, 77.855, 77.855, 77.785, 77.785, 77.715, 77.715]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 1063434 (local), 1062144 (global); Percentage 99.88 (1062144/1063434 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.264, Test loss: 2.063, Test accuracy: 27.91
Round   1, Train loss: 2.015, Test loss: 1.760, Test accuracy: 41.51
Round   2, Train loss: 1.840, Test loss: 1.619, Test accuracy: 45.49
Round   3, Train loss: 1.734, Test loss: 1.484, Test accuracy: 50.17
Round   4, Train loss: 1.626, Test loss: 1.430, Test accuracy: 52.77
Round   5, Train loss: 1.545, Test loss: 1.317, Test accuracy: 57.31
Round   6, Train loss: 1.448, Test loss: 1.247, Test accuracy: 58.94
Round   7, Train loss: 1.388, Test loss: 1.192, Test accuracy: 61.13
Round   8, Train loss: 1.310, Test loss: 1.147, Test accuracy: 62.33
Round   9, Train loss: 1.255, Test loss: 1.086, Test accuracy: 63.70
Round  10, Train loss: 1.187, Test loss: 1.036, Test accuracy: 65.70
Round  11, Train loss: 1.158, Test loss: 0.999, Test accuracy: 66.44
Round  12, Train loss: 1.110, Test loss: 0.969, Test accuracy: 67.47
Round  13, Train loss: 1.060, Test loss: 0.952, Test accuracy: 68.39
Round  14, Train loss: 1.038, Test loss: 0.919, Test accuracy: 69.38
Round  15, Train loss: 1.000, Test loss: 0.909, Test accuracy: 68.62
Round  16, Train loss: 0.991, Test loss: 0.897, Test accuracy: 70.14
Round  17, Train loss: 0.911, Test loss: 0.869, Test accuracy: 70.92
Round  18, Train loss: 0.915, Test loss: 0.853, Test accuracy: 71.80
Round  19, Train loss: 0.885, Test loss: 0.850, Test accuracy: 71.46
Round  20, Train loss: 0.849, Test loss: 0.824, Test accuracy: 72.89
Round  21, Train loss: 0.799, Test loss: 0.809, Test accuracy: 73.44
Round  22, Train loss: 0.820, Test loss: 0.802, Test accuracy: 73.80
Round  23, Train loss: 0.758, Test loss: 0.794, Test accuracy: 74.42
Round  24, Train loss: 0.751, Test loss: 0.766, Test accuracy: 74.74
Round  25, Train loss: 0.742, Test loss: 0.761, Test accuracy: 74.39
Round  26, Train loss: 0.725, Test loss: 0.770, Test accuracy: 74.43
Round  27, Train loss: 0.695, Test loss: 0.769, Test accuracy: 74.48
Round  28, Train loss: 0.682, Test loss: 0.748, Test accuracy: 75.56
Round  29, Train loss: 0.641, Test loss: 0.733, Test accuracy: 75.60
Round  30, Train loss: 0.652, Test loss: 0.740, Test accuracy: 75.25
Round  31, Train loss: 0.614, Test loss: 0.727, Test accuracy: 75.79
Round  32, Train loss: 0.600, Test loss: 0.736, Test accuracy: 75.93
Round  33, Train loss: 0.562, Test loss: 0.732, Test accuracy: 75.23
Round  34, Train loss: 0.551, Test loss: 0.773, Test accuracy: 74.77
Round  35, Train loss: 0.571, Test loss: 0.761, Test accuracy: 74.97
Round  36, Train loss: 0.524, Test loss: 0.744, Test accuracy: 75.41
Round  37, Train loss: 0.504, Test loss: 0.727, Test accuracy: 75.67
Round  38, Train loss: 0.503, Test loss: 0.740, Test accuracy: 75.86
Round  39, Train loss: 0.496, Test loss: 0.778, Test accuracy: 75.02
Round  40, Train loss: 0.479, Test loss: 0.757, Test accuracy: 75.38
Round  41, Train loss: 0.456, Test loss: 0.748, Test accuracy: 76.09
Round  42, Train loss: 0.441, Test loss: 0.755, Test accuracy: 76.66
Round  43, Train loss: 0.452, Test loss: 0.744, Test accuracy: 76.52
Round  44, Train loss: 0.405, Test loss: 0.743, Test accuracy: 76.09
Round  45, Train loss: 0.411, Test loss: 0.745, Test accuracy: 76.88
Round  46, Train loss: 0.378, Test loss: 0.765, Test accuracy: 76.53
Round  47, Train loss: 0.387, Test loss: 0.748, Test accuracy: 77.54
Round  48, Train loss: 0.385, Test loss: 0.772, Test accuracy: 76.81
Round  49, Train loss: 0.386, Test loss: 0.762, Test accuracy: 76.36
Round  50, Train loss: 0.333, Test loss: 0.777, Test accuracy: 76.39
Round  51, Train loss: 0.335, Test loss: 0.794, Test accuracy: 76.63
Round  52, Train loss: 0.310, Test loss: 0.794, Test accuracy: 76.31
Round  53, Train loss: 0.280, Test loss: 0.771, Test accuracy: 77.05
Round  54, Train loss: 0.327, Test loss: 0.814, Test accuracy: 76.47
Round  55, Train loss: 0.293, Test loss: 0.766, Test accuracy: 77.46
Round  56, Train loss: 0.288, Test loss: 0.798, Test accuracy: 76.67
Round  57, Train loss: 0.264, Test loss: 0.826, Test accuracy: 75.42
Round  58, Train loss: 0.342, Test loss: 0.761, Test accuracy: 77.02
Round  59, Train loss: 0.250, Test loss: 0.794, Test accuracy: 77.69
Round  60, Train loss: 0.264, Test loss: 0.818, Test accuracy: 78.00
Round  61, Train loss: 0.254, Test loss: 0.816, Test accuracy: 77.22
Round  62, Train loss: 0.231, Test loss: 0.809, Test accuracy: 77.33
Round  63, Train loss: 0.238, Test loss: 0.840, Test accuracy: 78.10
Round  64, Train loss: 0.232, Test loss: 0.798, Test accuracy: 78.55
Round  65, Train loss: 0.249, Test loss: 0.824, Test accuracy: 77.14
Round  66, Train loss: 0.215, Test loss: 0.834, Test accuracy: 76.48
Round  67, Train loss: 0.210, Test loss: 0.808, Test accuracy: 78.41
Round  68, Train loss: 0.222, Test loss: 0.822, Test accuracy: 77.30
Round  69, Train loss: 0.180, Test loss: 0.827, Test accuracy: 77.34
Round  70, Train loss: 0.206, Test loss: 0.831, Test accuracy: 77.95
Round  71, Train loss: 0.183, Test loss: 0.831, Test accuracy: 77.66
Round  72, Train loss: 0.188, Test loss: 0.833, Test accuracy: 77.86
Round  73, Train loss: 0.195, Test loss: 0.863, Test accuracy: 77.48
Round  74, Train loss: 0.212, Test loss: 0.826, Test accuracy: 78.15
Round  75, Train loss: 0.175, Test loss: 0.834, Test accuracy: 77.03
Round  76, Train loss: 0.160, Test loss: 0.858, Test accuracy: 77.64
Round  77, Train loss: 0.165, Test loss: 0.853, Test accuracy: 78.24
Round  78, Train loss: 0.144, Test loss: 0.864, Test accuracy: 78.03
Round  79, Train loss: 0.183, Test loss: 0.841, Test accuracy: 78.75
Round  80, Train loss: 0.155, Test loss: 0.832, Test accuracy: 78.50
Round  81, Train loss: 0.145, Test loss: 0.864, Test accuracy: 78.17
Round  82, Train loss: 0.147, Test loss: 0.881, Test accuracy: 78.00
Round  83, Train loss: 0.169, Test loss: 0.890, Test accuracy: 77.78
Round  84, Train loss: 0.120, Test loss: 0.921, Test accuracy: 77.10
Round  85, Train loss: 0.160, Test loss: 0.870, Test accuracy: 78.53
Round  86, Train loss: 0.120, Test loss: 0.881, Test accuracy: 77.83
Round  87, Train loss: 0.138, Test loss: 0.872, Test accuracy: 78.12
Round  88, Train loss: 0.131, Test loss: 0.890, Test accuracy: 77.72
Round  89, Train loss: 0.156, Test loss: 0.939, Test accuracy: 78.13
Round  90, Train loss: 0.126, Test loss: 0.928, Test accuracy: 78.72
Round  91, Train loss: 0.139, Test loss: 0.914, Test accuracy: 77.75
Round  92, Train loss: 0.096, Test loss: 0.961, Test accuracy: 77.66
Round  93, Train loss: 0.108, Test loss: 0.922, Test accuracy: 77.50
Round  94, Train loss: 0.101, Test loss: 0.955, Test accuracy: 78.19
Round  95, Train loss: 0.134, Test loss: 0.951, Test accuracy: 77.81
Round  96, Train loss: 0.120, Test loss: 0.917, Test accuracy: 78.46
Round  97, Train loss: 0.099, Test loss: 0.917, Test accuracy: 78.83
Round  98, Train loss: 0.099, Test loss: 0.964, Test accuracy: 78.60
Round  99, Train loss: 0.107, Test loss: 0.958, Test accuracy: 78.47
Final Round, Train loss: 0.065, Test loss: 0.962, Test accuracy: 78.52
Average accuracy final 10 rounds: 78.19999999999999 

2882.150812625885
[2.645292282104492, 5.290584564208984, 7.604224681854248, 9.917864799499512, 12.296291828155518, 14.674718856811523, 17.024479150772095, 19.374239444732666, 21.686362981796265, 23.998486518859863, 26.344926834106445, 28.691367149353027, 31.097805976867676, 33.504244804382324, 35.72615313529968, 37.94806146621704, 40.38303589820862, 42.818010330200195, 45.138757944107056, 47.459505558013916, 49.7847113609314, 52.10991716384888, 54.42769742012024, 56.7454776763916, 59.2001416683197, 61.6548056602478, 63.94656991958618, 66.23833417892456, 68.64466452598572, 71.05099487304688, 73.42972183227539, 75.8084487915039, 78.2875247001648, 80.76660060882568, 83.11059236526489, 85.4545841217041, 87.86732912063599, 90.28007411956787, 92.65482473373413, 95.02957534790039, 97.36806750297546, 99.70655965805054, 102.09493327140808, 104.48330688476562, 106.829505443573, 109.17570400238037, 111.5728452205658, 113.96998643875122, 116.32170104980469, 118.67341566085815, 121.01584911346436, 123.35828256607056, 125.63220930099487, 127.90613603591919, 130.3301043510437, 132.7540726661682, 135.06420946121216, 137.3743462562561, 139.8250002861023, 142.2756543159485, 144.59468531608582, 146.91371631622314, 149.30766582489014, 151.70161533355713, 153.94696736335754, 156.19231939315796, 158.5451648235321, 160.89801025390625, 163.31501150131226, 165.73201274871826, 168.05280017852783, 170.3735876083374, 172.7632555961609, 175.15292358398438, 177.46241235733032, 179.77190113067627, 182.11610007286072, 184.46029901504517, 186.75956678390503, 189.0588345527649, 191.45598459243774, 193.8531346321106, 196.17732906341553, 198.50152349472046, 200.87085032463074, 203.24017715454102, 205.5557141304016, 207.8712511062622, 210.17432141304016, 212.47739171981812, 214.776451587677, 217.0755114555359, 219.4570722579956, 221.83863306045532, 224.1630198955536, 226.48740673065186, 228.86229586601257, 231.2371850013733, 233.63152146339417, 236.02585792541504, 238.36512875556946, 240.70439958572388, 243.030348777771, 245.35629796981812, 247.67644214630127, 249.99658632278442, 252.36845207214355, 254.74031782150269, 256.95348381996155, 259.1666498184204, 261.59791588783264, 264.0291819572449, 266.33096051216125, 268.63273906707764, 270.95067620277405, 273.26861333847046, 275.6695818901062, 278.07055044174194, 280.5487756729126, 283.02700090408325, 285.4419960975647, 287.85699129104614, 290.46076822280884, 293.06454515457153, 295.4827923774719, 297.9010396003723, 300.2383306026459, 302.57562160491943, 304.9931392669678, 307.4106569290161, 309.8741617202759, 312.33766651153564, 314.6714334487915, 317.00520038604736, 319.36573600769043, 321.7262716293335, 324.2124562263489, 326.69864082336426, 328.9775607585907, 331.25648069381714, 333.7841339111328, 336.3117871284485, 338.78988695144653, 341.2679867744446, 343.6449315547943, 346.02187633514404, 348.30792570114136, 350.5939750671387, 353.0269351005554, 355.45989513397217, 357.8031713962555, 360.1464476585388, 362.4950337409973, 364.8436198234558, 367.25689721107483, 369.67017459869385, 372.0358805656433, 374.4015865325928, 376.73557686805725, 379.06956720352173, 381.572381734848, 384.0751962661743, 386.6017348766327, 389.12827348709106, 391.657523393631, 394.1867733001709, 396.80735540390015, 399.4279375076294, 401.9991567134857, 404.57037591934204, 407.00297570228577, 409.4355754852295, 411.8948452472687, 414.35411500930786, 416.96105122566223, 419.5679874420166, 422.1481373310089, 424.7282872200012, 427.41726303100586, 430.1062388420105, 432.64055156707764, 435.1748642921448, 437.69509506225586, 440.21532583236694, 442.677654504776, 445.13998317718506, 447.8599753379822, 450.5799674987793, 453.42062401771545, 456.2612805366516, 458.7053909301758, 461.14950132369995, 463.80039739608765, 466.45129346847534, 469.19955110549927, 471.9478087425232, 474.59933733940125, 477.2508659362793, 479.54326343536377, 481.83566093444824, 484.12618684768677, 486.4167127609253]
[27.915, 27.915, 41.505, 41.505, 45.49, 45.49, 50.175, 50.175, 52.765, 52.765, 57.315, 57.315, 58.935, 58.935, 61.13, 61.13, 62.325, 62.325, 63.7, 63.7, 65.705, 65.705, 66.44, 66.44, 67.475, 67.475, 68.385, 68.385, 69.375, 69.375, 68.625, 68.625, 70.14, 70.14, 70.92, 70.92, 71.795, 71.795, 71.46, 71.46, 72.885, 72.885, 73.435, 73.435, 73.8, 73.8, 74.425, 74.425, 74.74, 74.74, 74.39, 74.39, 74.43, 74.43, 74.485, 74.485, 75.555, 75.555, 75.6, 75.6, 75.245, 75.245, 75.79, 75.79, 75.93, 75.93, 75.235, 75.235, 74.765, 74.765, 74.975, 74.975, 75.41, 75.41, 75.665, 75.665, 75.865, 75.865, 75.02, 75.02, 75.38, 75.38, 76.09, 76.09, 76.655, 76.655, 76.52, 76.52, 76.095, 76.095, 76.875, 76.875, 76.525, 76.525, 77.54, 77.54, 76.815, 76.815, 76.36, 76.36, 76.385, 76.385, 76.63, 76.63, 76.305, 76.305, 77.05, 77.05, 76.465, 76.465, 77.46, 77.46, 76.665, 76.665, 75.415, 75.415, 77.02, 77.02, 77.69, 77.69, 77.995, 77.995, 77.225, 77.225, 77.335, 77.335, 78.1, 78.1, 78.55, 78.55, 77.135, 77.135, 76.48, 76.48, 78.405, 78.405, 77.3, 77.3, 77.345, 77.345, 77.955, 77.955, 77.66, 77.66, 77.86, 77.86, 77.485, 77.485, 78.15, 78.15, 77.025, 77.025, 77.635, 77.635, 78.24, 78.24, 78.03, 78.03, 78.745, 78.745, 78.505, 78.505, 78.175, 78.175, 78.0, 78.0, 77.78, 77.78, 77.1, 77.1, 78.525, 78.525, 77.825, 77.825, 78.125, 78.125, 77.72, 77.72, 78.13, 78.13, 78.72, 78.72, 77.75, 77.75, 77.655, 77.655, 77.495, 77.495, 78.195, 78.195, 77.815, 77.815, 78.46, 78.46, 78.835, 78.835, 78.6, 78.6, 78.475, 78.475, 78.52, 78.52]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
fedper
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 1063434 (local), 1062144 (global); Percentage 99.88 (1062144/1063434 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.144, Test loss: 1.917, Test accuracy: 38.07
Round   1, Train loss: 1.866, Test loss: 1.594, Test accuracy: 46.66
Round   2, Train loss: 1.682, Test loss: 1.451, Test accuracy: 52.82
Round   3, Train loss: 1.530, Test loss: 1.320, Test accuracy: 56.51
Round   4, Train loss: 1.399, Test loss: 1.212, Test accuracy: 60.85
Round   5, Train loss: 1.314, Test loss: 1.131, Test accuracy: 62.85
Round   6, Train loss: 1.220, Test loss: 1.070, Test accuracy: 64.77
Round   7, Train loss: 1.148, Test loss: 1.028, Test accuracy: 67.52
Round   8, Train loss: 1.081, Test loss: 0.953, Test accuracy: 68.48
Round   9, Train loss: 1.014, Test loss: 0.948, Test accuracy: 69.45
Round  10, Train loss: 0.979, Test loss: 0.893, Test accuracy: 70.57
Round  11, Train loss: 0.915, Test loss: 0.839, Test accuracy: 72.56
Round  12, Train loss: 0.891, Test loss: 0.857, Test accuracy: 71.80
Round  13, Train loss: 0.841, Test loss: 0.815, Test accuracy: 73.17
Round  14, Train loss: 0.779, Test loss: 0.832, Test accuracy: 72.72
Round  15, Train loss: 0.757, Test loss: 0.801, Test accuracy: 74.13
Round  16, Train loss: 0.728, Test loss: 0.801, Test accuracy: 73.40
Round  17, Train loss: 0.693, Test loss: 0.780, Test accuracy: 74.69
Round  18, Train loss: 0.621, Test loss: 0.778, Test accuracy: 75.63
Round  19, Train loss: 0.642, Test loss: 0.804, Test accuracy: 75.39
Round  20, Train loss: 0.596, Test loss: 0.758, Test accuracy: 76.09
Round  21, Train loss: 0.577, Test loss: 0.807, Test accuracy: 74.97
Round  22, Train loss: 0.583, Test loss: 0.778, Test accuracy: 75.07
Round  23, Train loss: 0.505, Test loss: 0.766, Test accuracy: 76.22
Round  24, Train loss: 0.483, Test loss: 0.795, Test accuracy: 74.72
Round  25, Train loss: 0.511, Test loss: 0.778, Test accuracy: 75.29
Round  26, Train loss: 0.467, Test loss: 0.809, Test accuracy: 74.53
Round  27, Train loss: 0.428, Test loss: 0.806, Test accuracy: 75.91
Round  28, Train loss: 0.412, Test loss: 0.801, Test accuracy: 76.19
Round  29, Train loss: 0.399, Test loss: 0.798, Test accuracy: 75.80
Round  30, Train loss: 0.379, Test loss: 0.782, Test accuracy: 76.80
Round  31, Train loss: 0.356, Test loss: 0.792, Test accuracy: 76.72
Round  32, Train loss: 0.368, Test loss: 0.795, Test accuracy: 76.49
Round  33, Train loss: 0.346, Test loss: 0.810, Test accuracy: 76.49
Round  34, Train loss: 0.345, Test loss: 0.787, Test accuracy: 77.16
Round  35, Train loss: 0.312, Test loss: 0.836, Test accuracy: 75.74
Round  36, Train loss: 0.332, Test loss: 0.799, Test accuracy: 76.78
Round  37, Train loss: 0.288, Test loss: 0.811, Test accuracy: 76.70
Round  38, Train loss: 0.234, Test loss: 0.886, Test accuracy: 77.20
Round  39, Train loss: 0.279, Test loss: 0.831, Test accuracy: 78.07
Round  40, Train loss: 0.239, Test loss: 0.864, Test accuracy: 76.45
Round  41, Train loss: 0.250, Test loss: 0.876, Test accuracy: 77.11
Round  42, Train loss: 0.241, Test loss: 0.860, Test accuracy: 77.28
Round  43, Train loss: 0.228, Test loss: 0.854, Test accuracy: 77.94
Round  44, Train loss: 0.225, Test loss: 0.853, Test accuracy: 77.34
Round  45, Train loss: 0.209, Test loss: 0.851, Test accuracy: 77.05
Round  46, Train loss: 0.193, Test loss: 0.913, Test accuracy: 75.98
Round  47, Train loss: 0.185, Test loss: 0.895, Test accuracy: 76.41
Round  48, Train loss: 0.181, Test loss: 0.867, Test accuracy: 77.12
Round  49, Train loss: 0.198, Test loss: 0.938, Test accuracy: 76.67
Round  50, Train loss: 0.176, Test loss: 0.923, Test accuracy: 77.36
Round  51, Train loss: 0.145, Test loss: 0.893, Test accuracy: 77.84
Round  52, Train loss: 0.142, Test loss: 0.925, Test accuracy: 77.47
Round  53, Train loss: 0.181, Test loss: 0.890, Test accuracy: 77.05
Round  54, Train loss: 0.140, Test loss: 0.916, Test accuracy: 77.55
Round  55, Train loss: 0.178, Test loss: 0.918, Test accuracy: 77.04
Round  56, Train loss: 0.150, Test loss: 0.942, Test accuracy: 77.69
Round  57, Train loss: 0.158, Test loss: 0.923, Test accuracy: 77.13
Round  58, Train loss: 0.152, Test loss: 0.902, Test accuracy: 77.17
Round  59, Train loss: 0.118, Test loss: 0.972, Test accuracy: 77.50
Round  60, Train loss: 0.136, Test loss: 0.971, Test accuracy: 77.03
Round  61, Train loss: 0.120, Test loss: 0.949, Test accuracy: 78.07
Round  62, Train loss: 0.134, Test loss: 0.913, Test accuracy: 78.33
Round  63, Train loss: 0.112, Test loss: 0.966, Test accuracy: 77.72
Round  64, Train loss: 0.105, Test loss: 0.992, Test accuracy: 77.72
Round  65, Train loss: 0.102, Test loss: 0.972, Test accuracy: 78.62
Round  66, Train loss: 0.128, Test loss: 0.951, Test accuracy: 78.02
Round  67, Train loss: 0.094, Test loss: 0.946, Test accuracy: 78.12
Round  68, Train loss: 0.075, Test loss: 1.023, Test accuracy: 76.39
Round  69, Train loss: 0.108, Test loss: 0.956, Test accuracy: 78.92
Round  70, Train loss: 0.113, Test loss: 0.988, Test accuracy: 77.50
Round  71, Train loss: 0.089, Test loss: 0.990, Test accuracy: 78.75
Round  72, Train loss: 0.093, Test loss: 1.003, Test accuracy: 78.17
Round  73, Train loss: 0.099, Test loss: 1.010, Test accuracy: 77.31
Round  74, Train loss: 0.072, Test loss: 1.014, Test accuracy: 77.72
Round  75, Train loss: 0.100, Test loss: 0.967, Test accuracy: 77.95
Round  76, Train loss: 0.080, Test loss: 1.018, Test accuracy: 78.71
Round  77, Train loss: 0.103, Test loss: 1.012, Test accuracy: 78.56
Round  78, Train loss: 0.061, Test loss: 1.044, Test accuracy: 78.94
Round  79, Train loss: 0.092, Test loss: 0.980, Test accuracy: 78.78
Round  80, Train loss: 0.100, Test loss: 1.017, Test accuracy: 77.78
Round  81, Train loss: 0.045, Test loss: 1.008, Test accuracy: 78.06
Round  82, Train loss: 0.072, Test loss: 1.037, Test accuracy: 77.83
Round  83, Train loss: 0.068, Test loss: 1.087, Test accuracy: 78.03
Round  84, Train loss: 0.059, Test loss: 1.084, Test accuracy: 77.80
Round  85, Train loss: 0.088, Test loss: 1.049, Test accuracy: 78.83
Round  86, Train loss: 0.063, Test loss: 1.056, Test accuracy: 78.33
Round  87, Train loss: 0.077, Test loss: 1.055, Test accuracy: 78.88
Round  88, Train loss: 0.069, Test loss: 1.069, Test accuracy: 78.33
Round  89, Train loss: 0.053, Test loss: 1.122, Test accuracy: 78.34
Round  90, Train loss: 0.055, Test loss: 1.096, Test accuracy: 79.36
Round  91, Train loss: 0.052, Test loss: 1.127, Test accuracy: 79.22
Round  92, Train loss: 0.064, Test loss: 1.098, Test accuracy: 78.14
Round  93, Train loss: 0.057, Test loss: 1.102, Test accuracy: 78.60
Round  94, Train loss: 0.041, Test loss: 1.104, Test accuracy: 79.08
Round  95, Train loss: 0.044, Test loss: 1.146, Test accuracy: 78.56
Round  96, Train loss: 0.037, Test loss: 1.120, Test accuracy: 78.81
Round  97, Train loss: 0.051, Test loss: 1.078, Test accuracy: 79.22
Round  98, Train loss: 0.063, Test loss: 1.103, Test accuracy: 78.45
Round  99, Train loss: 0.039, Test loss: 1.118, Test accuracy: 78.64
Final Round, Train loss: 0.019, Test loss: 1.132, Test accuracy: 78.53
Average accuracy final 10 rounds: 78.807 

2997.0637843608856
[2.7018685340881348, 5.4037370681762695, 7.910612106323242, 10.417487144470215, 12.916324138641357, 15.4151611328125, 17.922526836395264, 20.429892539978027, 22.999678134918213, 25.5694637298584, 28.087109804153442, 30.604755878448486, 33.17423129081726, 35.743706703186035, 38.33095145225525, 40.91819620132446, 43.447208642959595, 45.97622108459473, 48.59528732299805, 51.21435356140137, 53.89073467254639, 56.567115783691406, 59.20536971092224, 61.843623638153076, 64.36698484420776, 66.89034605026245, 69.63530373573303, 72.38026142120361, 74.990971326828, 77.60168123245239, 80.31388211250305, 83.02608299255371, 85.52846336364746, 88.03084373474121, 90.589186668396, 93.14752960205078, 95.69085240364075, 98.23417520523071, 100.95312786102295, 103.67208051681519, 106.29501700401306, 108.91795349121094, 111.54351782798767, 114.1690821647644, 116.81171107292175, 119.4543399810791, 122.09513258934021, 124.73592519760132, 127.35297179222107, 129.97001838684082, 132.6684901714325, 135.36696195602417, 138.0917649269104, 140.81656789779663, 143.40174508094788, 145.98692226409912, 148.6777467727661, 151.3685712814331, 154.04394578933716, 156.7193202972412, 159.37987732887268, 162.04043436050415, 164.69296407699585, 167.34549379348755, 170.0343120098114, 172.72313022613525, 175.3013412952423, 177.87955236434937, 180.6064989566803, 183.33344554901123, 185.98213028907776, 188.6308150291443, 191.29774165153503, 193.96466827392578, 196.6816999912262, 199.3987317085266, 202.13336610794067, 204.86800050735474, 207.54695177078247, 210.2259030342102, 213.01335644721985, 215.8008098602295, 218.39308381080627, 220.98535776138306, 223.53380680084229, 226.0822558403015, 228.53921580314636, 230.9961757659912, 233.6051471233368, 236.21411848068237, 238.72678589820862, 241.23945331573486, 243.801771402359, 246.36408948898315, 248.9905927181244, 251.61709594726562, 254.11753702163696, 256.6179780960083, 259.12655901908875, 261.6351399421692, 264.21019768714905, 266.7852554321289, 269.30577063560486, 271.8262858390808, 274.42718172073364, 277.0280776023865, 279.600191116333, 282.17230463027954, 284.73489451408386, 287.2974843978882, 289.76990962028503, 292.2423348426819, 294.7121639251709, 297.1819930076599, 299.70924639701843, 302.23649978637695, 304.64823174476624, 307.0599637031555, 309.73066568374634, 312.40136766433716, 314.90417885780334, 317.40699005126953, 319.92610454559326, 322.445219039917, 324.95410108566284, 327.4629831314087, 330.07977867126465, 332.6965742111206, 335.09239649772644, 337.4882187843323, 340.09315395355225, 342.6980891227722, 345.19023418426514, 347.68237924575806, 350.17785143852234, 352.6733236312866, 355.1693215370178, 357.665319442749, 360.2256944179535, 362.78606939315796, 365.2456912994385, 367.705313205719, 370.35105657577515, 372.9967999458313, 375.5800507068634, 378.1633014678955, 380.6638901233673, 383.1644787788391, 385.8305358886719, 388.49659299850464, 391.0251817703247, 393.5537705421448, 396.02272605895996, 398.49168157577515, 400.96343755722046, 403.43519353866577, 406.01283597946167, 408.59047842025757, 410.98813915252686, 413.38579988479614, 415.9686176776886, 418.55143547058105, 421.1808931827545, 423.810350894928, 426.3299582004547, 428.84956550598145, 431.3404152393341, 433.83126497268677, 436.415518283844, 438.9997715950012, 441.4349834918976, 443.87019538879395, 446.4741816520691, 449.07816791534424, 451.57209181785583, 454.06601572036743, 456.58229327201843, 459.09857082366943, 461.59330224990845, 464.08803367614746, 466.639452457428, 469.1908712387085, 471.6613163948059, 474.1317615509033, 476.6699483394623, 479.20813512802124, 481.8000690937042, 484.3920030593872, 486.9126696586609, 489.43333625793457, 491.99422669410706, 494.55511713027954, 497.13411140441895, 499.71310567855835, 502.2246687412262, 504.73623180389404, 507.28532433509827, 509.8344168663025, 512.492312669754, 515.1502084732056, 517.4792029857635, 519.8081974983215]
[38.07, 38.07, 46.655, 46.655, 52.82, 52.82, 56.51, 56.51, 60.855, 60.855, 62.855, 62.855, 64.765, 64.765, 67.52, 67.52, 68.485, 68.485, 69.455, 69.455, 70.57, 70.57, 72.56, 72.56, 71.8, 71.8, 73.17, 73.17, 72.725, 72.725, 74.13, 74.13, 73.4, 73.4, 74.69, 74.69, 75.63, 75.63, 75.385, 75.385, 76.09, 76.09, 74.975, 74.975, 75.07, 75.07, 76.225, 76.225, 74.725, 74.725, 75.29, 75.29, 74.535, 74.535, 75.91, 75.91, 76.19, 76.19, 75.8, 75.8, 76.795, 76.795, 76.715, 76.715, 76.49, 76.49, 76.49, 76.49, 77.16, 77.16, 75.74, 75.74, 76.785, 76.785, 76.705, 76.705, 77.2, 77.2, 78.07, 78.07, 76.455, 76.455, 77.115, 77.115, 77.28, 77.28, 77.935, 77.935, 77.34, 77.34, 77.05, 77.05, 75.98, 75.98, 76.41, 76.41, 77.125, 77.125, 76.67, 76.67, 77.36, 77.36, 77.845, 77.845, 77.465, 77.465, 77.045, 77.045, 77.545, 77.545, 77.04, 77.04, 77.685, 77.685, 77.13, 77.13, 77.165, 77.165, 77.505, 77.505, 77.025, 77.025, 78.07, 78.07, 78.335, 78.335, 77.72, 77.72, 77.725, 77.725, 78.625, 78.625, 78.02, 78.02, 78.125, 78.125, 76.395, 76.395, 78.915, 78.915, 77.505, 77.505, 78.745, 78.745, 78.17, 78.17, 77.31, 77.31, 77.715, 77.715, 77.955, 77.955, 78.71, 78.71, 78.565, 78.565, 78.945, 78.945, 78.78, 78.78, 77.775, 77.775, 78.055, 78.055, 77.835, 77.835, 78.03, 78.03, 77.795, 77.795, 78.83, 78.83, 78.335, 78.335, 78.875, 78.875, 78.33, 78.33, 78.34, 78.34, 79.365, 79.365, 79.215, 79.215, 78.14, 78.14, 78.6, 78.6, 79.075, 79.075, 78.565, 78.565, 78.805, 78.805, 79.22, 79.22, 78.45, 78.45, 78.635, 78.635, 78.525, 78.525]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
lg
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 1063434 (local), 34186 (global); Percentage 3.21 (34186/1063434 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.140, Test loss: 1.859, Test accuracy: 39.93
Round   1, Train loss: 1.844, Test loss: 1.626, Test accuracy: 43.48
Round   2, Train loss: 1.684, Test loss: 1.531, Test accuracy: 46.70
Round   3, Train loss: 1.512, Test loss: 1.485, Test accuracy: 48.50
Round   4, Train loss: 1.541, Test loss: 1.452, Test accuracy: 50.20
Round   5, Train loss: 1.461, Test loss: 1.393, Test accuracy: 52.44
Round   6, Train loss: 1.467, Test loss: 1.347, Test accuracy: 54.26
Round   7, Train loss: 1.379, Test loss: 1.325, Test accuracy: 55.23
Round   8, Train loss: 1.237, Test loss: 1.318, Test accuracy: 55.85
Round   9, Train loss: 1.283, Test loss: 1.286, Test accuracy: 57.05
Round  10, Train loss: 1.181, Test loss: 1.275, Test accuracy: 57.61
Round  11, Train loss: 1.239, Test loss: 1.241, Test accuracy: 58.80
Round  12, Train loss: 1.102, Test loss: 1.256, Test accuracy: 58.88
Round  13, Train loss: 1.083, Test loss: 1.261, Test accuracy: 59.39
Round  14, Train loss: 1.052, Test loss: 1.239, Test accuracy: 60.15
Round  15, Train loss: 1.084, Test loss: 1.237, Test accuracy: 60.38
Round  16, Train loss: 1.000, Test loss: 1.243, Test accuracy: 60.70
Round  17, Train loss: 0.906, Test loss: 1.240, Test accuracy: 61.15
Round  18, Train loss: 0.962, Test loss: 1.248, Test accuracy: 61.30
Round  19, Train loss: 0.890, Test loss: 1.235, Test accuracy: 61.70
Round  20, Train loss: 0.827, Test loss: 1.253, Test accuracy: 61.35
Round  21, Train loss: 0.784, Test loss: 1.256, Test accuracy: 61.74
Round  22, Train loss: 0.798, Test loss: 1.267, Test accuracy: 62.06
Round  23, Train loss: 0.724, Test loss: 1.304, Test accuracy: 61.97
Round  24, Train loss: 0.668, Test loss: 1.285, Test accuracy: 62.54
Round  25, Train loss: 0.674, Test loss: 1.323, Test accuracy: 62.04
Round  26, Train loss: 0.717, Test loss: 1.335, Test accuracy: 62.36
Round  27, Train loss: 0.616, Test loss: 1.348, Test accuracy: 62.65
Round  28, Train loss: 0.677, Test loss: 1.326, Test accuracy: 63.12
Round  29, Train loss: 0.570, Test loss: 1.351, Test accuracy: 63.05
Round  30, Train loss: 0.672, Test loss: 1.329, Test accuracy: 63.24
Round  31, Train loss: 0.594, Test loss: 1.354, Test accuracy: 63.52
Round  32, Train loss: 0.597, Test loss: 1.387, Test accuracy: 63.24
Round  33, Train loss: 0.540, Test loss: 1.400, Test accuracy: 63.49
Round  34, Train loss: 0.504, Test loss: 1.403, Test accuracy: 63.62
Round  35, Train loss: 0.442, Test loss: 1.415, Test accuracy: 64.17
Round  36, Train loss: 0.496, Test loss: 1.417, Test accuracy: 64.29
Round  37, Train loss: 0.404, Test loss: 1.442, Test accuracy: 64.34
Round  38, Train loss: 0.449, Test loss: 1.467, Test accuracy: 64.11
Round  39, Train loss: 0.450, Test loss: 1.471, Test accuracy: 64.12
Round  40, Train loss: 0.407, Test loss: 1.482, Test accuracy: 64.41
Round  41, Train loss: 0.374, Test loss: 1.521, Test accuracy: 64.30
Round  42, Train loss: 0.356, Test loss: 1.561, Test accuracy: 64.11
Round  43, Train loss: 0.310, Test loss: 1.568, Test accuracy: 64.43
Round  44, Train loss: 0.336, Test loss: 1.581, Test accuracy: 64.38
Round  45, Train loss: 0.320, Test loss: 1.596, Test accuracy: 64.54
Round  46, Train loss: 0.288, Test loss: 1.578, Test accuracy: 64.38
Round  47, Train loss: 0.315, Test loss: 1.608, Test accuracy: 64.23
Round  48, Train loss: 0.290, Test loss: 1.641, Test accuracy: 64.07
Round  49, Train loss: 0.266, Test loss: 1.714, Test accuracy: 63.74
Round  50, Train loss: 0.280, Test loss: 1.669, Test accuracy: 64.06
Round  51, Train loss: 0.247, Test loss: 1.693, Test accuracy: 64.15
Round  52, Train loss: 0.250, Test loss: 1.738, Test accuracy: 63.70
Round  53, Train loss: 0.249, Test loss: 1.753, Test accuracy: 63.92
Round  54, Train loss: 0.253, Test loss: 1.741, Test accuracy: 64.17
Round  55, Train loss: 0.239, Test loss: 1.735, Test accuracy: 64.56
Round  56, Train loss: 0.238, Test loss: 1.714, Test accuracy: 64.67
Round  57, Train loss: 0.270, Test loss: 1.738, Test accuracy: 64.99
Round  58, Train loss: 0.227, Test loss: 1.721, Test accuracy: 65.31
Round  59, Train loss: 0.229, Test loss: 1.775, Test accuracy: 64.89
Round  60, Train loss: 0.205, Test loss: 1.844, Test accuracy: 65.17
Round  61, Train loss: 0.166, Test loss: 1.897, Test accuracy: 64.80
Round  62, Train loss: 0.184, Test loss: 1.859, Test accuracy: 65.09
Round  63, Train loss: 0.240, Test loss: 1.851, Test accuracy: 64.82
Round  64, Train loss: 0.183, Test loss: 1.862, Test accuracy: 64.97
Round  65, Train loss: 0.173, Test loss: 1.856, Test accuracy: 65.41
Round  66, Train loss: 0.181, Test loss: 1.865, Test accuracy: 65.13
Round  67, Train loss: 0.147, Test loss: 1.894, Test accuracy: 64.94
Round  68, Train loss: 0.172, Test loss: 1.894, Test accuracy: 64.94
Round  69, Train loss: 0.153, Test loss: 1.925, Test accuracy: 64.68
Round  70, Train loss: 0.142, Test loss: 1.915, Test accuracy: 65.08
Round  71, Train loss: 0.144, Test loss: 1.966, Test accuracy: 65.03
Round  72, Train loss: 0.119, Test loss: 1.983, Test accuracy: 64.92
Round  73, Train loss: 0.127, Test loss: 2.022, Test accuracy: 64.81
Round  74, Train loss: 0.122, Test loss: 1.977, Test accuracy: 65.33
Round  75, Train loss: 0.145, Test loss: 1.974, Test accuracy: 65.42
Round  76, Train loss: 0.117, Test loss: 1.997, Test accuracy: 65.22
Round  77, Train loss: 0.158, Test loss: 2.034, Test accuracy: 65.01
Round  78, Train loss: 0.141, Test loss: 2.079, Test accuracy: 65.21
Round  79, Train loss: 0.118, Test loss: 2.091, Test accuracy: 65.17
Round  80, Train loss: 0.129, Test loss: 2.088, Test accuracy: 65.25
Round  81, Train loss: 0.099, Test loss: 2.116, Test accuracy: 65.34
Round  82, Train loss: 0.128, Test loss: 2.064, Test accuracy: 65.48
Round  83, Train loss: 0.109, Test loss: 2.129, Test accuracy: 65.33
Round  84, Train loss: 0.126, Test loss: 2.108, Test accuracy: 65.57
Round  85, Train loss: 0.093, Test loss: 2.158, Test accuracy: 65.43
Round  86, Train loss: 0.094, Test loss: 2.175, Test accuracy: 65.38
Round  87, Train loss: 0.095, Test loss: 2.150, Test accuracy: 65.61
Round  88, Train loss: 0.105, Test loss: 2.132, Test accuracy: 65.67
Round  89, Train loss: 0.097, Test loss: 2.135, Test accuracy: 65.80
Round  90, Train loss: 0.075, Test loss: 2.203, Test accuracy: 65.84
Round  91, Train loss: 0.113, Test loss: 2.142, Test accuracy: 66.02
Round  92, Train loss: 0.099, Test loss: 2.166, Test accuracy: 65.45
Round  93, Train loss: 0.109, Test loss: 2.189, Test accuracy: 65.14
Round  94, Train loss: 0.101, Test loss: 2.179, Test accuracy: 65.12
Round  95, Train loss: 0.100, Test loss: 2.212, Test accuracy: 65.03
Round  96, Train loss: 0.097, Test loss: 2.228, Test accuracy: 64.97
Round  97, Train loss: 0.074, Test loss: 2.270, Test accuracy: 65.31
Round  98, Train loss: 0.091, Test loss: 2.298, Test accuracy: 64.95
Round  99, Train loss: 0.092, Test loss: 2.266, Test accuracy: 65.14
Final Round, Train loss: 0.062, Test loss: 2.249, Test accuracy: 65.83
Average accuracy final 10 rounds: 65.299 

2963.1728055477142
[2.876218795776367, 5.752437591552734, 8.279225587844849, 10.806013584136963, 13.264402866363525, 15.722792148590088, 18.243250846862793, 20.763709545135498, 23.224124431610107, 25.684539318084717, 28.248918294906616, 30.813297271728516, 33.33946442604065, 35.86563158035278, 38.388023376464844, 40.910415172576904, 43.40178084373474, 45.89314651489258, 48.480876445770264, 51.06860637664795, 53.47454333305359, 55.88048028945923, 58.409590005874634, 60.93869972229004, 63.4487886428833, 65.95887756347656, 68.41501784324646, 70.87115812301636, 73.35226464271545, 75.83337116241455, 78.3897476196289, 80.94612407684326, 83.43314361572266, 85.92016315460205, 88.38710427284241, 90.85404539108276, 93.46191883087158, 96.0697922706604, 98.52941679954529, 100.98904132843018, 103.54367089271545, 106.09830045700073, 108.6207983493805, 111.14329624176025, 113.7638373374939, 116.38437843322754, 118.84120297431946, 121.29802751541138, 123.88711094856262, 126.47619438171387, 128.89944577217102, 131.32269716262817, 133.8436062335968, 136.36451530456543, 138.86696434020996, 141.3694133758545, 143.86196160316467, 146.35450983047485, 148.71577215194702, 151.0770344734192, 153.6713080406189, 156.2655816078186, 158.74715542793274, 161.22872924804688, 163.73135495185852, 166.23398065567017, 168.81354308128357, 171.39310550689697, 173.89672923088074, 176.4003529548645, 178.95655059814453, 181.51274824142456, 183.9904661178589, 186.4681839942932, 189.0789258480072, 191.6896677017212, 194.13271117210388, 196.57575464248657, 199.1943998336792, 201.81304502487183, 204.32977437973022, 206.84650373458862, 209.4079647064209, 211.96942567825317, 214.49862122535706, 217.02781677246094, 219.64281463623047, 222.2578125, 224.66286087036133, 227.06790924072266, 229.66633558273315, 232.26476192474365, 234.81611680984497, 237.3674716949463, 239.9291388988495, 242.49080610275269, 245.07074284553528, 247.65067958831787, 250.34205865859985, 253.03343772888184, 255.5533516407013, 258.07326555252075, 260.707368850708, 263.34147214889526, 265.93328881263733, 268.5251054763794, 271.034291267395, 273.54347705841064, 276.07204818725586, 278.6006193161011, 281.0863332748413, 283.57204723358154, 286.08611583709717, 288.6001844406128, 291.1137580871582, 293.6273317337036, 296.2247133255005, 298.82209491729736, 301.26458287239075, 303.70707082748413, 306.28110575675964, 308.85514068603516, 311.34466671943665, 313.83419275283813, 316.3289589881897, 318.82372522354126, 321.3711168766022, 323.9185085296631, 326.53749227523804, 329.156476020813, 331.57388186454773, 333.99128770828247, 336.4957263469696, 339.00016498565674, 341.49476647377014, 343.98936796188354, 346.5091116428375, 349.0288553237915, 351.51356315612793, 353.99827098846436, 356.5194766521454, 359.0406823158264, 361.57386898994446, 364.1070556640625, 366.5849435329437, 369.06283140182495, 371.6258280277252, 374.1888246536255, 376.655499458313, 379.1221742630005, 381.6380259990692, 384.15387773513794, 386.6370050907135, 389.12013244628906, 391.6414716243744, 394.1628108024597, 396.5323221683502, 398.9018335342407, 401.4665093421936, 404.0311851501465, 406.47888708114624, 408.926589012146, 411.42512369155884, 413.9236583709717, 416.41094732284546, 418.89823627471924, 421.5372037887573, 424.1761713027954, 426.75068044662476, 429.3251895904541, 431.96798825263977, 434.61078691482544, 437.21897435188293, 439.82716178894043, 442.4724507331848, 445.1177396774292, 447.6740174293518, 450.2302951812744, 452.69441771507263, 455.15854024887085, 457.7338993549347, 460.30925846099854, 462.8222711086273, 465.3352837562561, 467.98716473579407, 470.63904571533203, 473.09405040740967, 475.5490550994873, 478.2134675979614, 480.87788009643555, 483.3801383972168, 485.88239669799805, 488.4829399585724, 491.08348321914673, 493.62249064445496, 496.1614980697632, 498.7997558116913, 501.4380135536194, 503.87240862846375, 506.3068037033081, 508.8870749473572, 511.46734619140625]
[39.93, 39.93, 43.475, 43.475, 46.705, 46.705, 48.5, 48.5, 50.195, 50.195, 52.435, 52.435, 54.26, 54.26, 55.225, 55.225, 55.855, 55.855, 57.05, 57.05, 57.61, 57.61, 58.795, 58.795, 58.885, 58.885, 59.39, 59.39, 60.145, 60.145, 60.38, 60.38, 60.7, 60.7, 61.145, 61.145, 61.305, 61.305, 61.7, 61.7, 61.35, 61.35, 61.745, 61.745, 62.06, 62.06, 61.965, 61.965, 62.54, 62.54, 62.04, 62.04, 62.36, 62.36, 62.645, 62.645, 63.125, 63.125, 63.05, 63.05, 63.24, 63.24, 63.52, 63.52, 63.245, 63.245, 63.495, 63.495, 63.62, 63.62, 64.175, 64.175, 64.29, 64.29, 64.34, 64.34, 64.11, 64.11, 64.12, 64.12, 64.405, 64.405, 64.295, 64.295, 64.105, 64.105, 64.43, 64.43, 64.38, 64.38, 64.54, 64.54, 64.375, 64.375, 64.235, 64.235, 64.07, 64.07, 63.745, 63.745, 64.065, 64.065, 64.15, 64.15, 63.705, 63.705, 63.92, 63.92, 64.17, 64.17, 64.565, 64.565, 64.665, 64.665, 64.99, 64.99, 65.31, 65.31, 64.885, 64.885, 65.17, 65.17, 64.8, 64.8, 65.095, 65.095, 64.82, 64.82, 64.97, 64.97, 65.41, 65.41, 65.13, 65.13, 64.935, 64.935, 64.94, 64.94, 64.68, 64.68, 65.08, 65.08, 65.025, 65.025, 64.92, 64.92, 64.805, 64.805, 65.325, 65.325, 65.42, 65.42, 65.22, 65.22, 65.01, 65.01, 65.21, 65.21, 65.17, 65.17, 65.245, 65.245, 65.345, 65.345, 65.48, 65.48, 65.33, 65.33, 65.57, 65.57, 65.43, 65.43, 65.375, 65.375, 65.605, 65.605, 65.675, 65.675, 65.8, 65.8, 65.845, 65.845, 66.015, 66.015, 65.45, 65.45, 65.145, 65.145, 65.125, 65.125, 65.035, 65.035, 64.975, 64.975, 65.31, 65.31, 64.95, 64.95, 65.14, 65.14, 65.835, 65.835]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
Round   0, Train loss: 1.552, Test loss: 2.017, Test accuracy: 32.73
Round   1, Train loss: 1.363, Test loss: 1.895, Test accuracy: 34.20
Round   2, Train loss: 1.245, Test loss: 1.922, Test accuracy: 35.53
Round   3, Train loss: 1.147, Test loss: 1.958, Test accuracy: 37.38
Round   4, Train loss: 1.065, Test loss: 1.968, Test accuracy: 37.74
Round   5, Train loss: 1.012, Test loss: 2.092, Test accuracy: 35.48
Round   6, Train loss: 0.948, Test loss: 2.138, Test accuracy: 33.76
Round   7, Train loss: 0.877, Test loss: 2.127, Test accuracy: 34.66
Round   8, Train loss: 0.810, Test loss: 2.113, Test accuracy: 35.83
Round   9, Train loss: 0.758, Test loss: 2.102, Test accuracy: 36.57
Round  10, Train loss: 0.730, Test loss: 2.088, Test accuracy: 37.80
Round  11, Train loss: 0.652, Test loss: 2.078, Test accuracy: 38.31
Round  12, Train loss: 0.687, Test loss: 2.068, Test accuracy: 39.50
Round  13, Train loss: 0.555, Test loss: 2.052, Test accuracy: 39.92
Round  14, Train loss: 0.552, Test loss: 2.043, Test accuracy: 41.13
Round  15, Train loss: 0.581, Test loss: 2.029, Test accuracy: 41.83
Round  16, Train loss: 0.511, Test loss: 2.009, Test accuracy: 42.92
Round  17, Train loss: 0.441, Test loss: 2.005, Test accuracy: 42.08
Round  18, Train loss: 0.505, Test loss: 2.004, Test accuracy: 42.04
Round  19, Train loss: 0.432, Test loss: 1.990, Test accuracy: 42.99
Round  20, Train loss: 0.438, Test loss: 1.978, Test accuracy: 43.50
Round  21, Train loss: 0.387, Test loss: 1.961, Test accuracy: 44.65
Round  22, Train loss: 0.381, Test loss: 1.951, Test accuracy: 44.56
Round  23, Train loss: 0.310, Test loss: 1.934, Test accuracy: 46.46
Round  24, Train loss: 0.304, Test loss: 1.923, Test accuracy: 46.80
Round  25, Train loss: 0.350, Test loss: 1.916, Test accuracy: 47.41
Round  26, Train loss: 0.301, Test loss: 1.907, Test accuracy: 47.10
Round  27, Train loss: 0.269, Test loss: 1.889, Test accuracy: 48.09
Round  28, Train loss: 0.210, Test loss: 1.881, Test accuracy: 48.30
Round  29, Train loss: 0.257, Test loss: 1.875, Test accuracy: 47.59
Round  30, Train loss: 0.247, Test loss: 1.867, Test accuracy: 47.77
Round  31, Train loss: 0.206, Test loss: 1.852, Test accuracy: 48.88
Round  32, Train loss: 0.212, Test loss: 1.845, Test accuracy: 48.52
Round  33, Train loss: 0.203, Test loss: 1.836, Test accuracy: 49.48
Round  34, Train loss: 0.241, Test loss: 1.818, Test accuracy: 49.72
Round  35, Train loss: 0.199, Test loss: 1.814, Test accuracy: 49.39
Round  36, Train loss: 0.170, Test loss: 1.800, Test accuracy: 50.47
Round  37, Train loss: 0.157, Test loss: 1.787, Test accuracy: 50.84
Round  38, Train loss: 0.184, Test loss: 1.780, Test accuracy: 51.49
Round  39, Train loss: 0.145, Test loss: 1.767, Test accuracy: 51.91
Round  40, Train loss: 0.138, Test loss: 1.765, Test accuracy: 51.91
Round  41, Train loss: 0.113, Test loss: 1.749, Test accuracy: 52.43
Round  42, Train loss: 0.125, Test loss: 1.748, Test accuracy: 52.54
Round  43, Train loss: 0.119, Test loss: 1.745, Test accuracy: 52.95
Round  44, Train loss: 0.112, Test loss: 1.733, Test accuracy: 53.00
Round  45, Train loss: 0.134, Test loss: 1.739, Test accuracy: 52.51
Round  46, Train loss: 0.111, Test loss: 1.725, Test accuracy: 52.71
Round  47, Train loss: 0.114, Test loss: 1.721, Test accuracy: 52.41
Round  48, Train loss: 0.104, Test loss: 1.697, Test accuracy: 53.59
Round  49, Train loss: 0.121, Test loss: 1.701, Test accuracy: 53.22
Round  50, Train loss: 0.090, Test loss: 1.689, Test accuracy: 53.70
Round  51, Train loss: 0.078, Test loss: 1.688, Test accuracy: 53.45
Round  52, Train loss: 0.074, Test loss: 1.679, Test accuracy: 53.66
Round  53, Train loss: 0.087, Test loss: 1.689, Test accuracy: 53.39
Round  54, Train loss: 0.067, Test loss: 1.666, Test accuracy: 54.36
Round  55, Train loss: 0.069, Test loss: 1.668, Test accuracy: 53.84
Round  56, Train loss: 0.072, Test loss: 1.667, Test accuracy: 53.98
Round  57, Train loss: 0.072, Test loss: 1.664, Test accuracy: 54.02
Round  58, Train loss: 0.077, Test loss: 1.650, Test accuracy: 54.47
Round  59, Train loss: 0.064, Test loss: 1.648, Test accuracy: 54.47
Round  60, Train loss: 0.072, Test loss: 1.655, Test accuracy: 53.71
Round  61, Train loss: 0.067, Test loss: 1.641, Test accuracy: 54.62
Round  62, Train loss: 0.064, Test loss: 1.629, Test accuracy: 55.48
Round  63, Train loss: 0.059, Test loss: 1.626, Test accuracy: 55.67
Round  64, Train loss: 0.060, Test loss: 1.637, Test accuracy: 54.66
Round  65, Train loss: 0.044, Test loss: 1.617, Test accuracy: 55.57
Round  66, Train loss: 0.061, Test loss: 1.616, Test accuracy: 55.83
Round  67, Train loss: 0.051, Test loss: 1.608, Test accuracy: 55.97
Round  68, Train loss: 0.050, Test loss: 1.609, Test accuracy: 55.85
Round  69, Train loss: 0.049, Test loss: 1.616, Test accuracy: 55.62
Round  70, Train loss: 0.048, Test loss: 1.616, Test accuracy: 55.12
Round  71, Train loss: 0.046, Test loss: 1.611, Test accuracy: 55.11
Round  72, Train loss: 0.047, Test loss: 1.602, Test accuracy: 56.02
Round  73, Train loss: 0.046, Test loss: 1.597, Test accuracy: 55.58
Round  74, Train loss: 0.045, Test loss: 1.599, Test accuracy: 55.15
Round  75, Train loss: 0.038, Test loss: 1.589, Test accuracy: 55.55
Round  76, Train loss: 0.056, Test loss: 1.602, Test accuracy: 55.28
Round  77, Train loss: 0.045, Test loss: 1.587, Test accuracy: 56.13
Round  78, Train loss: 0.040, Test loss: 1.587, Test accuracy: 56.33
Round  79, Train loss: 0.036, Test loss: 1.586, Test accuracy: 56.07
Round  80, Train loss: 0.042, Test loss: 1.586, Test accuracy: 55.60
Round  81, Train loss: 0.039, Test loss: 1.600, Test accuracy: 54.78
Round  82, Train loss: 0.036, Test loss: 1.576, Test accuracy: 56.01
Round  83, Train loss: 0.038, Test loss: 1.573, Test accuracy: 56.12
Round  84, Train loss: 0.055, Test loss: 1.576, Test accuracy: 56.30
Round  85, Train loss: 0.027, Test loss: 1.554, Test accuracy: 56.77
Round  86, Train loss: 0.035, Test loss: 1.560, Test accuracy: 56.80
Round  87, Train loss: 0.031, Test loss: 1.552, Test accuracy: 56.98
Round  88, Train loss: 0.029, Test loss: 1.554, Test accuracy: 57.15
Round  89, Train loss: 0.032, Test loss: 1.561, Test accuracy: 56.28
Round  90, Train loss: 0.038, Test loss: 1.560, Test accuracy: 56.39
Round  91, Train loss: 0.030, Test loss: 1.553, Test accuracy: 56.39
Round  92, Train loss: 0.035, Test loss: 1.557, Test accuracy: 56.25
Round  93, Train loss: 0.030, Test loss: 1.545, Test accuracy: 57.02
Round  94, Train loss: 0.036, Test loss: 1.546, Test accuracy: 56.91
Round  95, Train loss: 0.022, Test loss: 1.543, Test accuracy: 57.06
Round  96, Train loss: 0.023, Test loss: 1.537, Test accuracy: 57.43
Round  97, Train loss: 0.023, Test loss: 1.531, Test accuracy: 57.55
Round  98, Train loss: 0.030, Test loss: 1.542, Test accuracy: 56.67
Round  99, Train loss: 0.030, Test loss: 1.538, Test accuracy: 56.88
Final Round, Train loss: 0.025, Test loss: 1.540, Test accuracy: 56.41
Average accuracy final 10 rounds: 56.855000000000004
3718.5106303691864
[]
[32.735, 34.2, 35.53, 37.38, 37.745, 35.485, 33.755, 34.66, 35.83, 36.57, 37.8, 38.31, 39.5, 39.925, 41.13, 41.825, 42.925, 42.08, 42.04, 42.995, 43.5, 44.65, 44.565, 46.46, 46.8, 47.415, 47.105, 48.09, 48.3, 47.585, 47.775, 48.875, 48.525, 49.485, 49.72, 49.39, 50.465, 50.835, 51.49, 51.915, 51.91, 52.43, 52.54, 52.945, 53.0, 52.51, 52.71, 52.41, 53.585, 53.22, 53.7, 53.455, 53.665, 53.39, 54.36, 53.845, 53.985, 54.02, 54.465, 54.47, 53.71, 54.62, 55.485, 55.67, 54.66, 55.57, 55.83, 55.97, 55.855, 55.625, 55.125, 55.11, 56.02, 55.58, 55.145, 55.545, 55.285, 56.13, 56.325, 56.07, 55.6, 54.78, 56.01, 56.12, 56.3, 56.775, 56.805, 56.975, 57.15, 56.285, 56.39, 56.39, 56.25, 57.015, 56.91, 57.065, 57.43, 57.55, 56.67, 56.88, 56.41]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
Round   0, Train loss: 2.151, Test loss: 2.166, Test accuracy: 20.68
Round   1, Train loss: 1.877, Test loss: 2.002, Test accuracy: 30.04
Round   2, Train loss: 1.672, Test loss: 1.876, Test accuracy: 35.47
Round   3, Train loss: 1.049, Test loss: 1.764, Test accuracy: 39.48
Round   4, Train loss: 1.157, Test loss: 1.771, Test accuracy: 39.63
Round   5, Train loss: 1.015, Test loss: 1.780, Test accuracy: 39.10
Round   6, Train loss: 0.838, Test loss: 1.673, Test accuracy: 41.22
Round   7, Train loss: 0.636, Test loss: 1.659, Test accuracy: 41.81
Round   8, Train loss: 0.303, Test loss: 1.613, Test accuracy: 43.43
Round   9, Train loss: 0.259, Test loss: 1.630, Test accuracy: 43.26
Round  10, Train loss: -0.105, Test loss: 1.596, Test accuracy: 44.77
Round  11, Train loss: -0.668, Test loss: 1.566, Test accuracy: 46.30
Round  12, Train loss: 0.224, Test loss: 1.527, Test accuracy: 47.55
Round  13, Train loss: -0.040, Test loss: 1.544, Test accuracy: 46.65
Round  14, Train loss: -0.476, Test loss: 1.524, Test accuracy: 48.15
Round  15, Train loss: -0.609, Test loss: 1.499, Test accuracy: 49.62
Round  16, Train loss: -0.220, Test loss: 1.510, Test accuracy: 49.34
Round  17, Train loss: -0.681, Test loss: 1.439, Test accuracy: 51.85
Round  18, Train loss: -0.069, Test loss: 1.452, Test accuracy: 51.26
Round  19, Train loss: -0.575, Test loss: 1.400, Test accuracy: 53.63
Round  20, Train loss: -1.560, Test loss: 1.364, Test accuracy: 54.74
Round  21, Train loss: -1.480, Test loss: 1.365, Test accuracy: 54.67
Round  22, Train loss: -1.087, Test loss: 1.378, Test accuracy: 53.74
Round  23, Train loss: -1.899, Test loss: 1.354, Test accuracy: 54.79
Round  24, Train loss: -1.918, Test loss: 1.341, Test accuracy: 55.16
Round  25, Train loss: -1.103, Test loss: 1.329, Test accuracy: 55.40
Round  26, Train loss: -2.693, Test loss: 1.312, Test accuracy: 55.98
Round  27, Train loss: -2.977, Test loss: 1.282, Test accuracy: 57.30
Round  28, Train loss: -2.818, Test loss: 1.307, Test accuracy: 56.66
Round  29, Train loss: -1.807, Test loss: 1.322, Test accuracy: 55.98
Round  30, Train loss: -2.910, Test loss: 1.312, Test accuracy: 56.51
Round  31, Train loss: -2.846, Test loss: 1.304, Test accuracy: 57.30
Round  32, Train loss: -3.727, Test loss: 1.283, Test accuracy: 58.30
Round  33, Train loss: -3.060, Test loss: 1.268, Test accuracy: 58.90
Round  34, Train loss: -3.107, Test loss: 1.252, Test accuracy: 59.27
Round  35, Train loss: -3.780, Test loss: 1.263, Test accuracy: 59.12
Round  36, Train loss: -3.947, Test loss: 1.269, Test accuracy: 59.00
Round  37, Train loss: -3.407, Test loss: 1.297, Test accuracy: 58.21
Round  38, Train loss: -3.850, Test loss: 1.256, Test accuracy: 59.26
Round  39, Train loss: -3.239, Test loss: 1.244, Test accuracy: 59.45
Round  40, Train loss: -3.590, Test loss: 1.230, Test accuracy: 60.02
Round  41, Train loss: -3.230, Test loss: 1.215, Test accuracy: 60.44
Round  42, Train loss: -4.045, Test loss: 1.221, Test accuracy: 60.95
Round  43, Train loss: -3.550, Test loss: 1.221, Test accuracy: 61.32
Round  44, Train loss: -3.207, Test loss: 1.202, Test accuracy: 61.68
Round  45, Train loss: -3.765, Test loss: 1.210, Test accuracy: 61.48
Round  46, Train loss: -4.252, Test loss: 1.203, Test accuracy: 61.76
Round  47, Train loss: -4.470, Test loss: 1.202, Test accuracy: 61.90
Round  48, Train loss: -3.765, Test loss: 1.233, Test accuracy: 61.34
Round  49, Train loss: -3.838, Test loss: 1.222, Test accuracy: 61.56
Round  50, Train loss: -4.208, Test loss: 1.227, Test accuracy: 61.77
Round  51, Train loss: -3.771, Test loss: 1.217, Test accuracy: 61.91
Round  52, Train loss: -3.898, Test loss: 1.204, Test accuracy: 62.59
Round  53, Train loss: -4.254, Test loss: 1.224, Test accuracy: 62.35
Round  54, Train loss: -4.330, Test loss: 1.218, Test accuracy: 62.59
Round  55, Train loss: -3.968, Test loss: 1.213, Test accuracy: 62.62
Round  56, Train loss: -4.080, Test loss: 1.189, Test accuracy: 62.70
Round  57, Train loss: -3.269, Test loss: 1.195, Test accuracy: 62.73
Round  58, Train loss: -3.417, Test loss: 1.177, Test accuracy: 63.16
Round  59, Train loss: -4.155, Test loss: 1.185, Test accuracy: 63.10
Round  60, Train loss: -3.717, Test loss: 1.179, Test accuracy: 63.30
Round  61, Train loss: -3.680, Test loss: 1.187, Test accuracy: 63.08
Round  62, Train loss: -3.633, Test loss: 1.187, Test accuracy: 63.31
Round  63, Train loss: -3.940, Test loss: 1.179, Test accuracy: 63.51
Round  64, Train loss: -4.093, Test loss: 1.172, Test accuracy: 63.77
Round  65, Train loss: -3.636, Test loss: 1.202, Test accuracy: 62.72
Round  66, Train loss: -3.716, Test loss: 1.197, Test accuracy: 62.91
Round  67, Train loss: -3.754, Test loss: 1.189, Test accuracy: 63.37
Round  68, Train loss: -3.908, Test loss: 1.180, Test accuracy: 63.72
Round  69, Train loss: -3.564, Test loss: 1.175, Test accuracy: 63.64
Round  70, Train loss: -3.874, Test loss: 1.178, Test accuracy: 64.00
Round  71, Train loss: -3.596, Test loss: 1.165, Test accuracy: 64.19
Round  72, Train loss: -4.411, Test loss: 1.166, Test accuracy: 64.23
Round  73, Train loss: -3.429, Test loss: 1.157, Test accuracy: 64.44
Round  74, Train loss: -3.520, Test loss: 1.134, Test accuracy: 65.03
Round  75, Train loss: -3.837, Test loss: 1.159, Test accuracy: 64.63
Round  76, Train loss: -3.753, Test loss: 1.174, Test accuracy: 64.57
Round  77, Train loss: -3.493, Test loss: 1.169, Test accuracy: 64.56
Round  78, Train loss: -3.293, Test loss: 1.152, Test accuracy: 64.60
Round  79, Train loss: -3.712, Test loss: 1.160, Test accuracy: 64.50
Round  80, Train loss: -3.523, Test loss: 1.148, Test accuracy: 65.11
Round  81, Train loss: -3.056, Test loss: 1.107, Test accuracy: 65.48
Round  82, Train loss: -3.718, Test loss: 1.106, Test accuracy: 65.47
Round  83, Train loss: -3.463, Test loss: 1.113, Test accuracy: 65.59
Round  84, Train loss: -3.383, Test loss: 1.118, Test accuracy: 65.70
Round  85, Train loss: -3.486, Test loss: 1.124, Test accuracy: 65.95
Round  86, Train loss: -3.389, Test loss: 1.116, Test accuracy: 65.90
Round  87, Train loss: -3.244, Test loss: 1.129, Test accuracy: 65.61
Round  88, Train loss: -3.538, Test loss: 1.127, Test accuracy: 65.51
Round  89, Train loss: -3.201, Test loss: 1.134, Test accuracy: 65.42
Round  90, Train loss: -3.361, Test loss: 1.132, Test accuracy: 65.59
Round  91, Train loss: -3.239, Test loss: 1.138, Test accuracy: 65.58
Round  92, Train loss: -3.321, Test loss: 1.127, Test accuracy: 65.86
Round  93, Train loss: -3.208, Test loss: 1.121, Test accuracy: 65.73
Round  94, Train loss: -3.489, Test loss: 1.131, Test accuracy: 65.33
Round  95, Train loss: -3.131, Test loss: 1.132, Test accuracy: 65.00
Round  96, Train loss: -3.126, Test loss: 1.130, Test accuracy: 65.33
Round  97, Train loss: -3.306, Test loss: 1.125, Test accuracy: 65.39
Round  98, Train loss: -3.207, Test loss: 1.116, Test accuracy: 65.72
Round  99, Train loss: -3.315, Test loss: 1.100, Test accuracy: 66.09
Final Round, Train loss: 0.876, Test loss: 1.033, Test accuracy: 67.06
Average accuracy final 10 rounds: 65.563
Average global accuracy final 10 rounds: 65.563
2653.5466542243958
[]
[20.675, 30.04, 35.465, 39.475, 39.63, 39.1, 41.22, 41.81, 43.43, 43.26, 44.765, 46.305, 47.555, 46.645, 48.145, 49.625, 49.34, 51.85, 51.26, 53.635, 54.74, 54.675, 53.745, 54.79, 55.155, 55.4, 55.975, 57.295, 56.665, 55.98, 56.51, 57.3, 58.3, 58.9, 59.275, 59.12, 59.0, 58.21, 59.26, 59.445, 60.025, 60.435, 60.95, 61.32, 61.68, 61.485, 61.76, 61.895, 61.345, 61.56, 61.77, 61.91, 62.585, 62.35, 62.595, 62.615, 62.705, 62.735, 63.165, 63.105, 63.295, 63.075, 63.315, 63.51, 63.775, 62.715, 62.915, 63.37, 63.72, 63.64, 64.0, 64.185, 64.23, 64.445, 65.03, 64.63, 64.57, 64.565, 64.6, 64.5, 65.11, 65.48, 65.475, 65.59, 65.705, 65.955, 65.9, 65.605, 65.51, 65.425, 65.59, 65.575, 65.865, 65.73, 65.335, 65.005, 65.335, 65.385, 65.72, 66.09, 67.055]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
prox
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.140, Test loss: 1.925, Test accuracy: 34.80
Round   0, Global train loss: 2.140, Global test loss: 1.938, Global test accuracy: 35.30
Round   1, Train loss: 1.919, Test loss: 1.743, Test accuracy: 40.13
Round   1, Global train loss: 1.919, Global test loss: 1.689, Global test accuracy: 42.60
Round   2, Train loss: 1.791, Test loss: 1.650, Test accuracy: 42.56
Round   2, Global train loss: 1.791, Global test loss: 1.550, Global test accuracy: 46.10
Round   3, Train loss: 1.676, Test loss: 1.595, Test accuracy: 44.82
Round   3, Global train loss: 1.676, Global test loss: 1.449, Global test accuracy: 50.60
Round   4, Train loss: 1.583, Test loss: 1.529, Test accuracy: 47.24
Round   4, Global train loss: 1.583, Global test loss: 1.330, Global test accuracy: 55.00
Round   5, Train loss: 1.477, Test loss: 1.479, Test accuracy: 48.93
Round   5, Global train loss: 1.477, Global test loss: 1.222, Global test accuracy: 60.30
Round   6, Train loss: 1.385, Test loss: 1.388, Test accuracy: 52.24
Round   6, Global train loss: 1.385, Global test loss: 1.157, Global test accuracy: 61.30
Round   7, Train loss: 1.304, Test loss: 1.357, Test accuracy: 53.52
Round   7, Global train loss: 1.304, Global test loss: 1.117, Global test accuracy: 62.50
Round   8, Train loss: 1.234, Test loss: 1.323, Test accuracy: 54.83
Round   8, Global train loss: 1.234, Global test loss: 1.043, Global test accuracy: 64.00
Round   9, Train loss: 1.208, Test loss: 1.300, Test accuracy: 55.66
Round   9, Global train loss: 1.208, Global test loss: 1.001, Global test accuracy: 67.00
Round  10, Train loss: 1.137, Test loss: 1.216, Test accuracy: 58.94
Round  10, Global train loss: 1.137, Global test loss: 0.965, Global test accuracy: 67.70
Round  11, Train loss: 1.112, Test loss: 1.171, Test accuracy: 60.62
Round  11, Global train loss: 1.112, Global test loss: 0.923, Global test accuracy: 69.00
Round  12, Train loss: 1.053, Test loss: 1.149, Test accuracy: 61.32
Round  12, Global train loss: 1.053, Global test loss: 0.919, Global test accuracy: 67.80
Round  13, Train loss: 1.016, Test loss: 1.088, Test accuracy: 63.58
Round  13, Global train loss: 1.016, Global test loss: 0.883, Global test accuracy: 69.50
Round  14, Train loss: 0.964, Test loss: 1.044, Test accuracy: 64.99
Round  14, Global train loss: 0.964, Global test loss: 0.867, Global test accuracy: 71.00
Round  15, Train loss: 0.944, Test loss: 1.031, Test accuracy: 65.47
Round  15, Global train loss: 0.944, Global test loss: 0.836, Global test accuracy: 71.80
Round  16, Train loss: 0.902, Test loss: 1.037, Test accuracy: 65.41
Round  16, Global train loss: 0.902, Global test loss: 0.861, Global test accuracy: 70.60
Round  17, Train loss: 0.858, Test loss: 1.029, Test accuracy: 65.85
Round  17, Global train loss: 0.858, Global test loss: 0.836, Global test accuracy: 70.90
Round  18, Train loss: 0.848, Test loss: 1.005, Test accuracy: 66.92
Round  18, Global train loss: 0.848, Global test loss: 0.811, Global test accuracy: 73.00
Round  19, Train loss: 0.826, Test loss: 1.012, Test accuracy: 66.78
Round  19, Global train loss: 0.826, Global test loss: 0.803, Global test accuracy: 72.00
Round  20, Train loss: 0.768, Test loss: 0.987, Test accuracy: 67.73
Round  20, Global train loss: 0.768, Global test loss: 0.799, Global test accuracy: 73.20
Round  21, Train loss: 0.774, Test loss: 0.971, Test accuracy: 68.49
Round  21, Global train loss: 0.774, Global test loss: 0.774, Global test accuracy: 74.60
Round  22, Train loss: 0.744, Test loss: 0.947, Test accuracy: 69.28
Round  22, Global train loss: 0.744, Global test loss: 0.760, Global test accuracy: 74.80
Round  23, Train loss: 0.710, Test loss: 0.940, Test accuracy: 69.31
Round  23, Global train loss: 0.710, Global test loss: 0.764, Global test accuracy: 73.70
Round  24, Train loss: 0.648, Test loss: 0.934, Test accuracy: 70.06
Round  24, Global train loss: 0.648, Global test loss: 0.774, Global test accuracy: 74.50
Round  25, Train loss: 0.622, Test loss: 0.937, Test accuracy: 69.91
Round  25, Global train loss: 0.622, Global test loss: 0.761, Global test accuracy: 73.80
Round  26, Train loss: 0.610, Test loss: 0.943, Test accuracy: 70.19
Round  26, Global train loss: 0.610, Global test loss: 0.783, Global test accuracy: 75.20
Round  27, Train loss: 0.575, Test loss: 0.946, Test accuracy: 70.23
Round  27, Global train loss: 0.575, Global test loss: 0.782, Global test accuracy: 73.80
Round  28, Train loss: 0.597, Test loss: 0.946, Test accuracy: 70.54
Round  28, Global train loss: 0.597, Global test loss: 0.753, Global test accuracy: 74.70
Round  29, Train loss: 0.522, Test loss: 0.923, Test accuracy: 71.26
Round  29, Global train loss: 0.522, Global test loss: 0.747, Global test accuracy: 76.20
Round  30, Train loss: 0.558, Test loss: 0.911, Test accuracy: 71.61
Round  30, Global train loss: 0.558, Global test loss: 0.759, Global test accuracy: 75.30
Round  31, Train loss: 0.574, Test loss: 0.915, Test accuracy: 71.72
Round  31, Global train loss: 0.574, Global test loss: 0.765, Global test accuracy: 75.60
Round  32, Train loss: 0.512, Test loss: 0.954, Test accuracy: 71.53
Round  32, Global train loss: 0.512, Global test loss: 0.775, Global test accuracy: 75.80
Round  33, Train loss: 0.468, Test loss: 0.960, Test accuracy: 71.52
Round  33, Global train loss: 0.468, Global test loss: 0.759, Global test accuracy: 76.60
Round  34, Train loss: 0.469, Test loss: 0.973, Test accuracy: 71.62
Round  34, Global train loss: 0.469, Global test loss: 0.790, Global test accuracy: 76.10
Round  35, Train loss: 0.471, Test loss: 0.953, Test accuracy: 72.11
Round  35, Global train loss: 0.471, Global test loss: 0.816, Global test accuracy: 75.90
Round  36, Train loss: 0.458, Test loss: 0.943, Test accuracy: 72.59
Round  36, Global train loss: 0.458, Global test loss: 0.782, Global test accuracy: 75.90
Round  37, Train loss: 0.407, Test loss: 0.941, Test accuracy: 72.74
Round  37, Global train loss: 0.407, Global test loss: 0.784, Global test accuracy: 76.70
Round  38, Train loss: 0.403, Test loss: 0.958, Test accuracy: 72.61
Round  38, Global train loss: 0.403, Global test loss: 0.770, Global test accuracy: 76.50
Round  39, Train loss: 0.412, Test loss: 0.977, Test accuracy: 72.35
Round  39, Global train loss: 0.412, Global test loss: 0.822, Global test accuracy: 75.60
Round  40, Train loss: 0.394, Test loss: 0.985, Test accuracy: 72.61
Round  40, Global train loss: 0.394, Global test loss: 0.800, Global test accuracy: 75.90
Round  41, Train loss: 0.382, Test loss: 0.994, Test accuracy: 72.52
Round  41, Global train loss: 0.382, Global test loss: 0.809, Global test accuracy: 75.90
Round  42, Train loss: 0.370, Test loss: 0.981, Test accuracy: 72.93
Round  42, Global train loss: 0.370, Global test loss: 0.793, Global test accuracy: 77.20
Round  43, Train loss: 0.342, Test loss: 1.012, Test accuracy: 72.64
Round  43, Global train loss: 0.342, Global test loss: 0.853, Global test accuracy: 75.80
Round  44, Train loss: 0.357, Test loss: 1.037, Test accuracy: 72.48
Round  44, Global train loss: 0.357, Global test loss: 0.799, Global test accuracy: 77.30
Round  45, Train loss: 0.335, Test loss: 1.015, Test accuracy: 72.91
Round  45, Global train loss: 0.335, Global test loss: 0.781, Global test accuracy: 76.10
Round  46, Train loss: 0.324, Test loss: 1.003, Test accuracy: 73.33
Round  46, Global train loss: 0.324, Global test loss: 0.825, Global test accuracy: 76.20
Round  47, Train loss: 0.329, Test loss: 1.023, Test accuracy: 73.36
Round  47, Global train loss: 0.329, Global test loss: 0.825, Global test accuracy: 75.90
Round  48, Train loss: 0.310, Test loss: 1.014, Test accuracy: 73.47
Round  48, Global train loss: 0.310, Global test loss: 0.804, Global test accuracy: 77.10
Round  49, Train loss: 0.332, Test loss: 1.007, Test accuracy: 73.84
Round  49, Global train loss: 0.332, Global test loss: 0.786, Global test accuracy: 77.60
Round  50, Train loss: 0.293, Test loss: 0.987, Test accuracy: 73.92
Round  50, Global train loss: 0.293, Global test loss: 0.792, Global test accuracy: 77.20
Round  51, Train loss: 0.273, Test loss: 0.996, Test accuracy: 73.98
Round  51, Global train loss: 0.273, Global test loss: 0.830, Global test accuracy: 76.60
Round  52, Train loss: 0.305, Test loss: 0.997, Test accuracy: 73.92
Round  52, Global train loss: 0.305, Global test loss: 0.814, Global test accuracy: 76.60
Round  53, Train loss: 0.265, Test loss: 0.985, Test accuracy: 74.23
Round  53, Global train loss: 0.265, Global test loss: 0.804, Global test accuracy: 77.00
Round  54, Train loss: 0.245, Test loss: 1.008, Test accuracy: 74.17
Round  54, Global train loss: 0.245, Global test loss: 0.829, Global test accuracy: 77.60
Round  55, Train loss: 0.241, Test loss: 1.007, Test accuracy: 74.38
Round  55, Global train loss: 0.241, Global test loss: 0.792, Global test accuracy: 77.90
Round  56, Train loss: 0.245, Test loss: 1.014, Test accuracy: 74.44
Round  56, Global train loss: 0.245, Global test loss: 0.824, Global test accuracy: 77.20
Round  57, Train loss: 0.227, Test loss: 1.003, Test accuracy: 74.67
Round  57, Global train loss: 0.227, Global test loss: 0.816, Global test accuracy: 77.10
Round  58, Train loss: 0.201, Test loss: 1.014, Test accuracy: 74.67
Round  58, Global train loss: 0.201, Global test loss: 0.851, Global test accuracy: 75.80
Round  59, Train loss: 0.241, Test loss: 1.011, Test accuracy: 74.62
Round  59, Global train loss: 0.241, Global test loss: 0.818, Global test accuracy: 76.30
Round  60, Train loss: 0.213, Test loss: 1.044, Test accuracy: 74.38
Round  60, Global train loss: 0.213, Global test loss: 0.880, Global test accuracy: 76.40
Round  61, Train loss: 0.241, Test loss: 1.072, Test accuracy: 74.28
Round  61, Global train loss: 0.241, Global test loss: 0.845, Global test accuracy: 76.70
Round  62, Train loss: 0.168, Test loss: 1.086, Test accuracy: 74.11
Round  62, Global train loss: 0.168, Global test loss: 0.909, Global test accuracy: 77.10
Round  63, Train loss: 0.205, Test loss: 1.086, Test accuracy: 74.45
Round  63, Global train loss: 0.205, Global test loss: 0.872, Global test accuracy: 77.60
Round  64, Train loss: 0.169, Test loss: 1.077, Test accuracy: 74.54
Round  64, Global train loss: 0.169, Global test loss: 0.883, Global test accuracy: 77.30
Round  65, Train loss: 0.220, Test loss: 1.081, Test accuracy: 74.70
Round  65, Global train loss: 0.220, Global test loss: 0.871, Global test accuracy: 78.20
Round  66, Train loss: 0.166, Test loss: 1.077, Test accuracy: 74.84
Round  66, Global train loss: 0.166, Global test loss: 0.899, Global test accuracy: 77.30
Round  67, Train loss: 0.159, Test loss: 1.092, Test accuracy: 74.79
Round  67, Global train loss: 0.159, Global test loss: 0.939, Global test accuracy: 77.20
Round  68, Train loss: 0.186, Test loss: 1.088, Test accuracy: 75.11
Round  68, Global train loss: 0.186, Global test loss: 0.911, Global test accuracy: 78.00
Round  69, Train loss: 0.180, Test loss: 1.056, Test accuracy: 75.36
Round  69, Global train loss: 0.180, Global test loss: 0.867, Global test accuracy: 77.20
Round  70, Train loss: 0.167, Test loss: 1.062, Test accuracy: 75.30
Round  70, Global train loss: 0.167, Global test loss: 0.911, Global test accuracy: 77.60
Round  71, Train loss: 0.152, Test loss: 1.075, Test accuracy: 75.18
Round  71, Global train loss: 0.152, Global test loss: 0.896, Global test accuracy: 78.60
Round  72, Train loss: 0.169, Test loss: 1.080, Test accuracy: 75.16
Round  72, Global train loss: 0.169, Global test loss: 0.887, Global test accuracy: 77.20
Round  73, Train loss: 0.145, Test loss: 1.088, Test accuracy: 75.31
Round  73, Global train loss: 0.145, Global test loss: 0.899, Global test accuracy: 77.80
Round  74, Train loss: 0.137, Test loss: 1.076, Test accuracy: 75.51
Round  74, Global train loss: 0.137, Global test loss: 0.889, Global test accuracy: 78.20
Round  75, Train loss: 0.157, Test loss: 1.118, Test accuracy: 75.03
Round  75, Global train loss: 0.157, Global test loss: 0.861, Global test accuracy: 77.60
Round  76, Train loss: 0.129, Test loss: 1.115, Test accuracy: 75.00
Round  76, Global train loss: 0.129, Global test loss: 0.897, Global test accuracy: 77.70
Round  77, Train loss: 0.115, Test loss: 1.086, Test accuracy: 75.75
Round  77, Global train loss: 0.115, Global test loss: 0.914, Global test accuracy: 77.30
Round  78, Train loss: 0.141, Test loss: 1.085, Test accuracy: 75.90
Round  78, Global train loss: 0.141, Global test loss: 0.924, Global test accuracy: 77.50
Round  79, Train loss: 0.158, Test loss: 1.098, Test accuracy: 75.72
Round  79, Global train loss: 0.158, Global test loss: 0.905, Global test accuracy: 77.50
Round  80, Train loss: 0.117, Test loss: 1.097, Test accuracy: 75.89
Round  80, Global train loss: 0.117, Global test loss: 0.933, Global test accuracy: 78.90
Round  81, Train loss: 0.109, Test loss: 1.097, Test accuracy: 75.92
Round  81, Global train loss: 0.109, Global test loss: 0.925, Global test accuracy: 78.20
Round  82, Train loss: 0.132, Test loss: 1.108, Test accuracy: 75.84
Round  82, Global train loss: 0.132, Global test loss: 0.907, Global test accuracy: 78.80
Round  83, Train loss: 0.102, Test loss: 1.096, Test accuracy: 75.89
Round  83, Global train loss: 0.102, Global test loss: 0.917, Global test accuracy: 78.30
Round  84, Train loss: 0.115, Test loss: 1.101, Test accuracy: 76.19
Round  84, Global train loss: 0.115, Global test loss: 0.922, Global test accuracy: 78.20
Round  85, Train loss: 0.125, Test loss: 1.117, Test accuracy: 76.17
Round  85, Global train loss: 0.125, Global test loss: 0.877, Global test accuracy: 79.60
Round  86, Train loss: 0.099, Test loss: 1.105, Test accuracy: 76.41
Round  86, Global train loss: 0.099, Global test loss: 0.915, Global test accuracy: 78.60
Round  87, Train loss: 0.089, Test loss: 1.122, Test accuracy: 76.34
Round  87, Global train loss: 0.089, Global test loss: 0.938, Global test accuracy: 78.20
Round  88, Train loss: 0.107, Test loss: 1.129, Test accuracy: 76.38
Round  88, Global train loss: 0.107, Global test loss: 0.922, Global test accuracy: 78.40
Round  89, Train loss: 0.087, Test loss: 1.145, Test accuracy: 76.33
Round  89, Global train loss: 0.087, Global test loss: 0.951, Global test accuracy: 78.40
Round  90, Train loss: 0.096, Test loss: 1.117, Test accuracy: 76.69
Round  90, Global train loss: 0.096, Global test loss: 0.905, Global test accuracy: 78.10
Round  91, Train loss: 0.110, Test loss: 1.133, Test accuracy: 76.41
Round  91, Global train loss: 0.110, Global test loss: 0.943, Global test accuracy: 77.70
Round  92, Train loss: 0.085, Test loss: 1.129, Test accuracy: 76.31
Round  92, Global train loss: 0.085, Global test loss: 0.971, Global test accuracy: 77.30
Round  93, Train loss: 0.092, Test loss: 1.144, Test accuracy: 76.31
Round  93, Global train loss: 0.092, Global test loss: 0.956, Global test accuracy: 78.60
Round  94, Train loss: 0.089, Test loss: 1.147, Test accuracy: 76.12
Round  94, Global train loss: 0.089, Global test loss: 0.976, Global test accuracy: 77.60
Round  95, Train loss: 0.088, Test loss: 1.142, Test accuracy: 76.15
Round  95, Global train loss: 0.088, Global test loss: 1.006, Global test accuracy: 77.00/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  96, Train loss: 0.099, Test loss: 1.175, Test accuracy: 75.99
Round  96, Global train loss: 0.099, Global test loss: 0.990, Global test accuracy: 77.70
Round  97, Train loss: 0.078, Test loss: 1.174, Test accuracy: 76.07
Round  97, Global train loss: 0.078, Global test loss: 1.010, Global test accuracy: 77.10
Round  98, Train loss: 0.060, Test loss: 1.197, Test accuracy: 75.89
Round  98, Global train loss: 0.060, Global test loss: 1.028, Global test accuracy: 77.40
Round  99, Train loss: 0.091, Test loss: 1.198, Test accuracy: 76.00
Round  99, Global train loss: 0.091, Global test loss: 1.021, Global test accuracy: 77.70
Final Round, Train loss: 0.052, Test loss: 1.197, Test accuracy: 76.40
Final Round, Global train loss: 0.052, Global test loss: 1.021, Global test accuracy: 77.70
Average accuracy final 10 rounds: 76.19399999999999 

Average global accuracy final 10 rounds: 77.62 

3709.4908723831177
[3.0318727493286133, 6.063745498657227, 8.666540622711182, 11.269335746765137, 13.865286111831665, 16.461236476898193, 19.173038005828857, 21.88483953475952, 24.42617177963257, 26.967504024505615, 29.63374352455139, 32.29998302459717, 34.945327043533325, 37.59067106246948, 40.1997184753418, 42.80876588821411, 45.505532026290894, 48.202298164367676, 50.74279761314392, 53.283297061920166, 55.92890453338623, 58.574512004852295, 61.16276931762695, 63.75102663040161, 66.33262372016907, 68.91422080993652, 71.58300518989563, 74.25178956985474, 76.76921439170837, 79.28663921356201, 81.98449087142944, 84.68234252929688, 87.27134108543396, 89.86033964157104, 92.47109127044678, 95.08184289932251, 97.69198751449585, 100.30213212966919, 102.92592430114746, 105.54971647262573, 108.26832747459412, 110.9869384765625, 113.58802580833435, 116.1891131401062, 118.80019330978394, 121.41127347946167, 124.04438328742981, 126.67749309539795, 129.28837943077087, 131.8992657661438, 134.5978639125824, 137.296462059021, 139.9419686794281, 142.5874752998352, 145.19466829299927, 147.80186128616333, 150.4156243801117, 153.02938747406006, 155.62382435798645, 158.21826124191284, 160.8483510017395, 163.47844076156616, 166.15030431747437, 168.82216787338257, 171.43788051605225, 174.05359315872192, 176.6804702281952, 179.30734729766846, 181.91946268081665, 184.53157806396484, 187.166894197464, 189.80221033096313, 192.50583338737488, 195.20945644378662, 197.79921627044678, 200.38897609710693, 203.07549667358398, 205.76201725006104, 208.39295983314514, 211.02390241622925, 213.69098019599915, 216.35805797576904, 218.96795535087585, 221.57785272598267, 224.1262445449829, 226.67463636398315, 229.4637303352356, 232.25282430648804, 234.8754529953003, 237.49808168411255, 240.1051526069641, 242.71222352981567, 245.3541750907898, 247.99612665176392, 250.51796865463257, 253.03981065750122, 255.7325303554535, 258.42525005340576, 260.9990029335022, 263.57275581359863, 266.16659903526306, 268.7604422569275, 271.4687795639038, 274.1771168708801, 276.7394163608551, 279.3017158508301, 281.98603081703186, 284.67034578323364, 287.2447156906128, 289.81908559799194, 292.4176080226898, 295.0161304473877, 297.69459080696106, 300.3730511665344, 302.9204800128937, 305.46790885925293, 308.14147663116455, 310.8150444030762, 313.40870785713196, 316.00237131118774, 318.68348455429077, 321.3645977973938, 324.0647249221802, 326.76485204696655, 329.33970952033997, 331.9145669937134, 334.60592246055603, 337.2972779273987, 339.86012601852417, 342.42297410964966, 345.1076877117157, 347.79240131378174, 350.434809923172, 353.07721853256226, 355.66962814331055, 358.26203775405884, 360.9152879714966, 363.5685381889343, 366.2122972011566, 368.8560562133789, 371.5615532398224, 374.26705026626587, 376.89749026298523, 379.5279302597046, 382.13986897468567, 384.75180768966675, 387.463250875473, 390.1746940612793, 392.8761320114136, 395.57756996154785, 398.26707196235657, 400.9565739631653, 403.6267673969269, 406.2969608306885, 408.9262626171112, 411.55556440353394, 414.20665407180786, 416.8577437400818, 419.6105635166168, 422.36338329315186, 425.0658874511719, 427.7683916091919, 430.35910201072693, 432.94981241226196, 435.5576403141022, 438.1654682159424, 440.8353102207184, 443.5051522254944, 446.16867446899414, 448.8321967124939, 451.46460223197937, 454.09700775146484, 456.7394735813141, 459.38193941116333, 461.98977303504944, 464.59760665893555, 467.2100489139557, 469.82249116897583, 472.4655976295471, 475.1087040901184, 477.73890590667725, 480.3691077232361, 483.0365183353424, 485.70392894744873, 488.3019211292267, 490.89991331100464, 493.5155589580536, 496.13120460510254, 498.78888273239136, 501.4465608596802, 504.0308952331543, 506.6152296066284, 509.291610956192, 511.9679923057556, 514.6061201095581, 517.2442479133606, 519.862508058548, 522.4807682037354, 525.0915989875793, 527.7024297714233, 530.3654112815857, 533.028392791748]
[34.8, 34.8, 40.135, 40.135, 42.56, 42.56, 44.82, 44.82, 47.24, 47.24, 48.93, 48.93, 52.245, 52.245, 53.525, 53.525, 54.83, 54.83, 55.655, 55.655, 58.935, 58.935, 60.615, 60.615, 61.32, 61.32, 63.58, 63.58, 64.99, 64.99, 65.475, 65.475, 65.41, 65.41, 65.85, 65.85, 66.92, 66.92, 66.78, 66.78, 67.73, 67.73, 68.49, 68.49, 69.275, 69.275, 69.305, 69.305, 70.065, 70.065, 69.905, 69.905, 70.195, 70.195, 70.23, 70.23, 70.54, 70.54, 71.26, 71.26, 71.615, 71.615, 71.715, 71.715, 71.535, 71.535, 71.515, 71.515, 71.62, 71.62, 72.115, 72.115, 72.595, 72.595, 72.74, 72.74, 72.615, 72.615, 72.35, 72.35, 72.61, 72.61, 72.515, 72.515, 72.93, 72.93, 72.635, 72.635, 72.485, 72.485, 72.91, 72.91, 73.325, 73.325, 73.355, 73.355, 73.475, 73.475, 73.84, 73.84, 73.915, 73.915, 73.98, 73.98, 73.92, 73.92, 74.23, 74.23, 74.17, 74.17, 74.375, 74.375, 74.435, 74.435, 74.67, 74.67, 74.675, 74.675, 74.625, 74.625, 74.375, 74.375, 74.275, 74.275, 74.115, 74.115, 74.45, 74.45, 74.54, 74.54, 74.7, 74.7, 74.845, 74.845, 74.79, 74.79, 75.105, 75.105, 75.36, 75.36, 75.295, 75.295, 75.18, 75.18, 75.155, 75.155, 75.31, 75.31, 75.51, 75.51, 75.025, 75.025, 75.0, 75.0, 75.75, 75.75, 75.9, 75.9, 75.715, 75.715, 75.895, 75.895, 75.925, 75.925, 75.84, 75.84, 75.895, 75.895, 76.195, 76.195, 76.165, 76.165, 76.405, 76.405, 76.34, 76.34, 76.375, 76.375, 76.335, 76.335, 76.685, 76.685, 76.41, 76.41, 76.305, 76.305, 76.315, 76.315, 76.12, 76.12, 76.15, 76.15, 75.99, 75.99, 76.07, 76.07, 75.895, 75.895, 76.0, 76.0, 76.4, 76.4]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
Round   0, Train loss: 2.228, Test loss: 1.859, Test accuracy: 38.30
Round   1, Train loss: 1.932, Test loss: 1.590, Test accuracy: 45.40
Round   2, Train loss: 1.758, Test loss: 1.456, Test accuracy: 51.20
Round   3, Train loss: 1.615, Test loss: 1.292, Test accuracy: 56.10
Round   4, Train loss: 1.501, Test loss: 1.170, Test accuracy: 62.30
Round   5, Train loss: 1.374, Test loss: 1.097, Test accuracy: 63.90
Round   6, Train loss: 1.292, Test loss: 1.052, Test accuracy: 66.00
Round   7, Train loss: 1.194, Test loss: 0.975, Test accuracy: 68.30
Round   8, Train loss: 1.119, Test loss: 0.939, Test accuracy: 69.60
Round   9, Train loss: 1.087, Test loss: 0.920, Test accuracy: 69.50
Round  10, Train loss: 1.009, Test loss: 0.882, Test accuracy: 69.60
Round  11, Train loss: 0.941, Test loss: 0.846, Test accuracy: 72.30
Round  12, Train loss: 0.898, Test loss: 0.813, Test accuracy: 73.60
Round  13, Train loss: 0.858, Test loss: 0.799, Test accuracy: 74.40
Round  14, Train loss: 0.810, Test loss: 0.799, Test accuracy: 74.10
Round  15, Train loss: 0.750, Test loss: 0.810, Test accuracy: 73.40
Round  16, Train loss: 0.684, Test loss: 0.774, Test accuracy: 76.50
Round  17, Train loss: 0.700, Test loss: 0.744, Test accuracy: 76.60
Round  18, Train loss: 0.620, Test loss: 0.779, Test accuracy: 75.60
Round  19, Train loss: 0.578, Test loss: 0.762, Test accuracy: 75.70
Round  20, Train loss: 0.543, Test loss: 0.772, Test accuracy: 75.80
Round  21, Train loss: 0.540, Test loss: 0.768, Test accuracy: 76.30
Round  22, Train loss: 0.503, Test loss: 0.729, Test accuracy: 76.60
Round  23, Train loss: 0.488, Test loss: 0.736, Test accuracy: 77.70
Round  24, Train loss: 0.488, Test loss: 0.731, Test accuracy: 77.50
Round  25, Train loss: 0.420, Test loss: 0.765, Test accuracy: 76.90
Round  26, Train loss: 0.416, Test loss: 0.764, Test accuracy: 76.90
Round  27, Train loss: 0.378, Test loss: 0.777, Test accuracy: 77.10
Round  28, Train loss: 0.361, Test loss: 0.752, Test accuracy: 77.00
Round  29, Train loss: 0.313, Test loss: 0.789, Test accuracy: 77.20
Round  30, Train loss: 0.303, Test loss: 0.808, Test accuracy: 77.80
Round  31, Train loss: 0.329, Test loss: 0.799, Test accuracy: 78.40
Round  32, Train loss: 0.262, Test loss: 0.794, Test accuracy: 77.40
Round  33, Train loss: 0.294, Test loss: 0.782, Test accuracy: 77.30
Round  34, Train loss: 0.305, Test loss: 0.781, Test accuracy: 77.80
Round  35, Train loss: 0.238, Test loss: 0.799, Test accuracy: 76.70
Round  36, Train loss: 0.198, Test loss: 0.778, Test accuracy: 78.00
Round  37, Train loss: 0.228, Test loss: 0.765, Test accuracy: 78.80
Round  38, Train loss: 0.220, Test loss: 0.780, Test accuracy: 78.20
Round  39, Train loss: 0.212, Test loss: 0.812, Test accuracy: 77.70
Round  40, Train loss: 0.176, Test loss: 0.843, Test accuracy: 78.40
Round  41, Train loss: 0.157, Test loss: 0.819, Test accuracy: 78.60
Round  42, Train loss: 0.152, Test loss: 0.827, Test accuracy: 78.20
Round  43, Train loss: 0.142, Test loss: 0.846, Test accuracy: 78.50
Round  44, Train loss: 0.142, Test loss: 0.823, Test accuracy: 78.70
Round  45, Train loss: 0.169, Test loss: 0.825, Test accuracy: 78.20
Round  46, Train loss: 0.138, Test loss: 0.853, Test accuracy: 79.20
Round  47, Train loss: 0.141, Test loss: 0.849, Test accuracy: 77.30
Round  48, Train loss: 0.124, Test loss: 0.850, Test accuracy: 77.90
Round  49, Train loss: 0.134, Test loss: 0.856, Test accuracy: 78.20
Round  50, Train loss: 0.111, Test loss: 0.881, Test accuracy: 78.40
Round  51, Train loss: 0.143, Test loss: 0.871, Test accuracy: 77.30
Round  52, Train loss: 0.105, Test loss: 0.886, Test accuracy: 78.10
Round  53, Train loss: 0.115, Test loss: 0.867, Test accuracy: 77.90
Round  54, Train loss: 0.100, Test loss: 0.893, Test accuracy: 79.10
Round  55, Train loss: 0.085, Test loss: 0.973, Test accuracy: 77.90
Round  56, Train loss: 0.068, Test loss: 0.911, Test accuracy: 79.40
Round  57, Train loss: 0.092, Test loss: 0.930, Test accuracy: 77.80
Round  58, Train loss: 0.060, Test loss: 0.921, Test accuracy: 78.30
Round  59, Train loss: 0.086, Test loss: 0.947, Test accuracy: 76.80
Round  60, Train loss: 0.084, Test loss: 0.918, Test accuracy: 78.50
Round  61, Train loss: 0.056, Test loss: 0.921, Test accuracy: 78.20
Round  62, Train loss: 0.059, Test loss: 0.941, Test accuracy: 78.00
Round  63, Train loss: 0.081, Test loss: 0.984, Test accuracy: 76.40
Round  64, Train loss: 0.061, Test loss: 0.984, Test accuracy: 77.40
Round  65, Train loss: 0.054, Test loss: 0.960, Test accuracy: 79.10
Round  66, Train loss: 0.046, Test loss: 0.989, Test accuracy: 78.30
Round  67, Train loss: 0.038, Test loss: 1.013, Test accuracy: 78.50
Round  68, Train loss: 0.053, Test loss: 1.004, Test accuracy: 78.60
Round  69, Train loss: 0.040, Test loss: 0.965, Test accuracy: 78.30
Round  70, Train loss: 0.055, Test loss: 0.936, Test accuracy: 77.30
Round  71, Train loss: 0.048, Test loss: 1.010, Test accuracy: 78.10
Round  72, Train loss: 0.062, Test loss: 1.000, Test accuracy: 77.20
Round  73, Train loss: 0.042, Test loss: 0.993, Test accuracy: 77.80
Round  74, Train loss: 0.036, Test loss: 0.953, Test accuracy: 78.50
Round  75, Train loss: 0.051, Test loss: 0.986, Test accuracy: 78.50
Round  76, Train loss: 0.052, Test loss: 0.940, Test accuracy: 79.50
Round  77, Train loss: 0.030, Test loss: 1.034, Test accuracy: 79.10
Round  78, Train loss: 0.038, Test loss: 0.987, Test accuracy: 79.00
Round  79, Train loss: 0.049, Test loss: 0.991, Test accuracy: 78.80
Round  80, Train loss: 0.034, Test loss: 0.987, Test accuracy: 78.70
Round  81, Train loss: 0.031, Test loss: 1.058, Test accuracy: 78.10
Round  82, Train loss: 0.033, Test loss: 0.962, Test accuracy: 78.90
Round  83, Train loss: 0.037, Test loss: 1.030, Test accuracy: 79.20
Round  84, Train loss: 0.037, Test loss: 0.989, Test accuracy: 78.10
Round  85, Train loss: 0.025, Test loss: 1.064, Test accuracy: 78.90
Round  86, Train loss: 0.023, Test loss: 1.071, Test accuracy: 78.30
Round  87, Train loss: 0.027, Test loss: 1.036, Test accuracy: 78.10
Round  88, Train loss: 0.026, Test loss: 1.077, Test accuracy: 78.20
Round  89, Train loss: 0.022, Test loss: 1.058, Test accuracy: 77.80
Round  90, Train loss: 0.033, Test loss: 1.072, Test accuracy: 78.50
Round  91, Train loss: 0.028, Test loss: 1.035, Test accuracy: 78.50
Round  92, Train loss: 0.021, Test loss: 1.035, Test accuracy: 78.60
Round  93, Train loss: 0.024, Test loss: 1.122, Test accuracy: 77.20
Round  94, Train loss: 0.024, Test loss: 1.082, Test accuracy: 77.30
Round  95, Train loss: 0.025, Test loss: 1.102, Test accuracy: 77.90
Round  96, Train loss: 0.024, Test loss: 1.089, Test accuracy: 79.00
Round  97, Train loss: 0.016, Test loss: 1.091, Test accuracy: 78.60
Round  98, Train loss: 0.018, Test loss: 1.130, Test accuracy: 79.00
Round  99, Train loss: 0.017, Test loss: 1.127, Test accuracy: 77.40
Final Round, Train loss: 0.016, Test loss: 1.117, Test accuracy: 78.40
Average accuracy final 10 rounds: 78.19999999999999
4881.720036745071
[6.905559778213501, 13.704008340835571, 20.438645839691162, 27.47283697128296, 34.40281057357788, 41.122309923172, 47.75937223434448, 54.66871786117554, 61.55906438827515, 68.29251146316528, 75.04085183143616, 81.82912015914917, 88.76750946044922, 95.38141083717346, 102.12888622283936, 108.89818096160889, 115.81270837783813, 122.70211744308472, 129.6606113910675, 136.89470314979553, 143.91878247261047, 150.81184601783752, 157.64386630058289, 164.35849165916443, 171.1481375694275, 178.0690860748291, 184.80943155288696, 191.67723178863525, 198.3156807422638, 205.30296993255615, 212.29521083831787, 219.0429699420929, 225.91403794288635, 232.82258486747742, 239.6786551475525, 246.37945866584778, 253.2329707145691, 259.99297046661377, 267.0287940502167, 274.13580298423767, 281.1727225780487, 288.1566274166107, 295.7291624546051, 303.05574345588684, 310.5411636829376, 317.22724652290344, 324.21547770500183, 331.07841181755066, 337.7765302658081, 344.7080907821655, 352.31572341918945, 359.22292137145996, 365.9841492176056, 372.80760431289673, 379.70941400527954, 386.683162689209, 393.9965569972992, 401.01599860191345, 407.99975872039795, 415.46608209609985, 422.69500279426575, 429.96772837638855, 437.1979568004608, 444.6986765861511, 451.79155468940735, 458.90487241744995, 466.07074427604675, 473.4727530479431, 480.7323763370514, 487.9215612411499, 495.2249870300293, 502.68408966064453, 509.976441860199, 517.2449164390564, 524.3986566066742, 531.5306668281555, 538.8401308059692, 546.057991027832, 553.0983278751373, 560.2744019031525, 567.6738045215607, 574.7517673969269, 581.9744729995728, 589.2527439594269, 596.6161043643951, 603.6079058647156, 610.8615896701813, 617.97997879982, 625.3389608860016, 632.3653330802917, 639.7661254405975, 647.0142195224762, 654.2528433799744, 661.4606804847717, 668.8770785331726, 676.045592546463, 683.2014682292938, 690.5081324577332, 697.854466676712, 705.0377044677734, 708.8329257965088]
[38.3, 45.4, 51.2, 56.1, 62.3, 63.9, 66.0, 68.3, 69.6, 69.5, 69.6, 72.3, 73.6, 74.4, 74.1, 73.4, 76.5, 76.6, 75.6, 75.7, 75.8, 76.3, 76.6, 77.7, 77.5, 76.9, 76.9, 77.1, 77.0, 77.2, 77.8, 78.4, 77.4, 77.3, 77.8, 76.7, 78.0, 78.8, 78.2, 77.7, 78.4, 78.6, 78.2, 78.5, 78.7, 78.2, 79.2, 77.3, 77.9, 78.2, 78.4, 77.3, 78.1, 77.9, 79.1, 77.9, 79.4, 77.8, 78.3, 76.8, 78.5, 78.2, 78.0, 76.4, 77.4, 79.1, 78.3, 78.5, 78.6, 78.3, 77.3, 78.1, 77.2, 77.8, 78.5, 78.5, 79.5, 79.1, 79.0, 78.8, 78.7, 78.1, 78.9, 79.2, 78.1, 78.9, 78.3, 78.1, 78.2, 77.8, 78.5, 78.5, 78.6, 77.2, 77.3, 77.9, 79.0, 78.6, 79.0, 77.4, 78.4]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100  

Files already downloaded and verified
Files already downloaded and verified
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 1063434 (local), 1062144 (global); Percentage 99.88 (1062144/1063434)
learning rate, batch size: 0.01, 10
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
Round   0, Train loss: 2.274, Test loss: 2.044, Test accuracy: 28.79
Round   1, Train loss: 2.025, Test loss: 1.777, Test accuracy: 41.48
Round   2, Train loss: 1.871, Test loss: 1.639, Test accuracy: 45.74
Round   3, Train loss: 1.742, Test loss: 1.544, Test accuracy: 48.72
Round   4, Train loss: 1.645, Test loss: 1.448, Test accuracy: 52.27
Round   5, Train loss: 1.552, Test loss: 1.379, Test accuracy: 56.07
Round   6, Train loss: 1.482, Test loss: 1.242, Test accuracy: 60.01
Round   7, Train loss: 1.371, Test loss: 1.198, Test accuracy: 61.37
Round   8, Train loss: 1.298, Test loss: 1.177, Test accuracy: 63.19
Round   9, Train loss: 1.294, Test loss: 1.074, Test accuracy: 63.76
Round  10, Train loss: 1.203, Test loss: 1.026, Test accuracy: 66.20
Round  11, Train loss: 1.150, Test loss: 0.985, Test accuracy: 67.55
Round  12, Train loss: 1.093, Test loss: 0.995, Test accuracy: 67.46
Round  13, Train loss: 1.079, Test loss: 0.957, Test accuracy: 68.16
Round  14, Train loss: 1.009, Test loss: 0.933, Test accuracy: 69.67
Round  15, Train loss: 0.993, Test loss: 0.899, Test accuracy: 70.43
Round  16, Train loss: 0.929, Test loss: 0.869, Test accuracy: 71.41
Round  17, Train loss: 0.887, Test loss: 0.866, Test accuracy: 70.67
Round  18, Train loss: 0.902, Test loss: 0.843, Test accuracy: 72.06
Round  19, Train loss: 0.880, Test loss: 0.804, Test accuracy: 73.43
Round  20, Train loss: 0.834, Test loss: 0.803, Test accuracy: 73.58
Round  21, Train loss: 0.798, Test loss: 0.792, Test accuracy: 74.47
Round  22, Train loss: 0.774, Test loss: 0.786, Test accuracy: 73.93
Round  23, Train loss: 0.760, Test loss: 0.790, Test accuracy: 73.99
Round  24, Train loss: 0.760, Test loss: 0.772, Test accuracy: 73.84
Round  25, Train loss: 0.695, Test loss: 0.748, Test accuracy: 74.56
Round  26, Train loss: 0.655, Test loss: 0.741, Test accuracy: 75.28
Round  27, Train loss: 0.666, Test loss: 0.727, Test accuracy: 75.67
Round  28, Train loss: 0.632, Test loss: 0.746, Test accuracy: 74.64
Round  29, Train loss: 0.584, Test loss: 0.734, Test accuracy: 75.81
Round  30, Train loss: 0.613, Test loss: 0.712, Test accuracy: 76.60
Round  31, Train loss: 0.581, Test loss: 0.716, Test accuracy: 76.56
Round  32, Train loss: 0.539, Test loss: 0.719, Test accuracy: 76.11
Round  33, Train loss: 0.550, Test loss: 0.711, Test accuracy: 75.62
Round  34, Train loss: 0.492, Test loss: 0.724, Test accuracy: 76.04
Round  35, Train loss: 0.467, Test loss: 0.728, Test accuracy: 76.39
Round  36, Train loss: 0.521, Test loss: 0.734, Test accuracy: 75.77
Round  37, Train loss: 0.461, Test loss: 0.727, Test accuracy: 75.98
Round  38, Train loss: 0.463, Test loss: 0.755, Test accuracy: 75.66
Round  39, Train loss: 0.461, Test loss: 0.730, Test accuracy: 76.51
Round  40, Train loss: 0.438, Test loss: 0.723, Test accuracy: 76.92
Round  41, Train loss: 0.410, Test loss: 0.704, Test accuracy: 76.70
Round  42, Train loss: 0.402, Test loss: 0.692, Test accuracy: 77.36
Round  43, Train loss: 0.400, Test loss: 0.692, Test accuracy: 78.17
Round  44, Train loss: 0.379, Test loss: 0.714, Test accuracy: 77.06
Round  45, Train loss: 0.361, Test loss: 0.738, Test accuracy: 77.17
Round  46, Train loss: 0.342, Test loss: 0.710, Test accuracy: 77.69
Round  47, Train loss: 0.354, Test loss: 0.736, Test accuracy: 77.08
Round  48, Train loss: 0.331, Test loss: 0.730, Test accuracy: 76.97
Round  49, Train loss: 0.324, Test loss: 0.746, Test accuracy: 77.20
Round  50, Train loss: 0.328, Test loss: 0.719, Test accuracy: 78.08
Round  51, Train loss: 0.275, Test loss: 0.725, Test accuracy: 77.85
Round  52, Train loss: 0.302, Test loss: 0.719, Test accuracy: 78.02
Round  53, Train loss: 0.265, Test loss: 0.748, Test accuracy: 77.47
Round  54, Train loss: 0.283, Test loss: 0.731, Test accuracy: 78.00
Round  55, Train loss: 0.281, Test loss: 0.747, Test accuracy: 78.12
Round  56, Train loss: 0.274, Test loss: 0.738, Test accuracy: 77.77
Round  57, Train loss: 0.256, Test loss: 0.716, Test accuracy: 78.59
Round  58, Train loss: 0.252, Test loss: 0.738, Test accuracy: 78.56
Round  59, Train loss: 0.241, Test loss: 0.742, Test accuracy: 77.98
Round  60, Train loss: 0.240, Test loss: 0.739, Test accuracy: 78.28
Round  61, Train loss: 0.215, Test loss: 0.749, Test accuracy: 78.02
Round  62, Train loss: 0.220, Test loss: 0.734, Test accuracy: 77.77
Round  63, Train loss: 0.212, Test loss: 0.723, Test accuracy: 78.90
Round  64, Train loss: 0.196, Test loss: 0.734, Test accuracy: 78.77
Round  65, Train loss: 0.194, Test loss: 0.766, Test accuracy: 77.55
Round  66, Train loss: 0.187, Test loss: 0.762, Test accuracy: 78.34
Round  67, Train loss: 0.177, Test loss: 0.739, Test accuracy: 79.19
Round  68, Train loss: 0.168, Test loss: 0.772, Test accuracy: 77.93
Round  69, Train loss: 0.164, Test loss: 0.802, Test accuracy: 77.64
Round  70, Train loss: 0.207, Test loss: 0.773, Test accuracy: 78.44
Round  71, Train loss: 0.171, Test loss: 0.767, Test accuracy: 78.59
Round  72, Train loss: 0.141, Test loss: 0.794, Test accuracy: 78.97
Round  73, Train loss: 0.149, Test loss: 0.788, Test accuracy: 78.80
Round  74, Train loss: 0.162, Test loss: 0.781, Test accuracy: 79.33
Round  75, Train loss: 0.134, Test loss: 0.818, Test accuracy: 78.47
Round  76, Train loss: 0.129, Test loss: 0.805, Test accuracy: 79.05
Round  77, Train loss: 0.167, Test loss: 0.769, Test accuracy: 78.63
Round  78, Train loss: 0.119, Test loss: 0.781, Test accuracy: 78.98
Round  79, Train loss: 0.132, Test loss: 0.776, Test accuracy: 78.56
Round  80, Train loss: 0.122, Test loss: 0.797, Test accuracy: 78.57
Round  81, Train loss: 0.139, Test loss: 0.786, Test accuracy: 79.24
Round  82, Train loss: 0.097, Test loss: 0.801, Test accuracy: 79.35
Round  83, Train loss: 0.114, Test loss: 0.776, Test accuracy: 79.30
Round  84, Train loss: 0.129, Test loss: 0.764, Test accuracy: 78.81
Round  85, Train loss: 0.133, Test loss: 0.772, Test accuracy: 79.81
Round  86, Train loss: 0.113, Test loss: 0.776, Test accuracy: 80.44
Round  87, Train loss: 0.125, Test loss: 0.812, Test accuracy: 79.48
Round  88, Train loss: 0.140, Test loss: 0.781, Test accuracy: 78.34
Round  89, Train loss: 0.123, Test loss: 0.770, Test accuracy: 79.80
Round  90, Train loss: 0.112, Test loss: 0.798, Test accuracy: 78.90
Round  91, Train loss: 0.110, Test loss: 0.789, Test accuracy: 79.32
Round  92, Train loss: 0.129, Test loss: 0.833, Test accuracy: 78.38
Round  93, Train loss: 0.115, Test loss: 0.833, Test accuracy: 78.45
Round  94, Train loss: 0.088, Test loss: 0.816, Test accuracy: 78.71
Round  95, Train loss: 0.094, Test loss: 0.815, Test accuracy: 79.17
Round  96, Train loss: 0.095, Test loss: 0.824, Test accuracy: 78.50
Round  97, Train loss: 0.077, Test loss: 0.836, Test accuracy: 78.30
Round  98, Train loss: 0.108, Test loss: 0.847, Test accuracy: 78.77
Round  99, Train loss: 0.073, Test loss: 0.835, Test accuracy: 79.00
Final Round, Train loss: 0.045, Test loss: 0.842, Test accuracy: 79.06
Average accuracy final 10 rounds: 78.74900000000001
2765.432783603668
[3.867375135421753, 7.067052364349365, 10.454590320587158, 13.984705924987793, 17.198682069778442, 20.605273246765137, 23.920625925064087, 27.61367893218994, 30.889017820358276, 34.26664352416992, 37.83600163459778, 40.91953253746033, 44.32063150405884, 47.69914269447327, 51.11135411262512, 54.41585111618042, 57.65850639343262, 61.25447463989258, 64.39103174209595, 67.83239221572876, 71.24306559562683, 74.5932776927948, 77.95573377609253, 81.20320129394531, 84.81672358512878, 88.02606201171875, 91.52076649665833, 94.98429560661316, 98.33622312545776, 101.75688195228577, 105.06873512268066, 108.73101139068604, 111.99093794822693, 115.34563565254211, 118.82175397872925, 122.13210868835449, 125.56683993339539, 128.8615972995758, 132.44592547416687, 135.72681379318237, 138.99292755126953, 142.54569053649902, 145.6385042667389, 149.02569031715393, 152.32059812545776, 155.73527026176453, 159.18065071105957, 162.43319272994995, 166.02337622642517, 169.14789032936096, 172.53401112556458, 176.0197286605835, 179.34590315818787, 182.71967029571533, 185.92552185058594, 189.53734302520752, 192.63658833503723, 196.0746476650238, 199.58189916610718, 202.94467282295227, 206.30717873573303, 209.54416060447693, 213.13763618469238, 216.47732305526733, 219.9019718170166, 223.42484426498413, 226.74059200286865, 230.20151615142822, 233.4580385684967, 236.84919452667236, 240.10087513923645, 243.2972903251648, 246.85988903045654, 249.9945993423462, 253.41308188438416, 256.77897477149963, 260.19668984413147, 263.57243299484253, 266.76532769203186, 270.31461477279663, 273.4170010089874, 276.73228335380554, 280.1387870311737, 283.523690700531, 286.86044549942017, 290.1398766040802, 293.74271750450134, 296.972229719162, 300.43606424331665, 303.9924912452698, 307.3240282535553, 310.8469080924988, 313.91427731513977, 317.18558740615845, 320.27270245552063, 323.3756642341614, 326.55727791786194, 329.77498054504395, 332.88029050827026, 336.06839513778687, 338.5238597393036]
[28.79, 41.48, 45.745, 48.715, 52.275, 56.07, 60.005, 61.37, 63.19, 63.755, 66.205, 67.55, 67.46, 68.155, 69.665, 70.43, 71.405, 70.67, 72.055, 73.43, 73.58, 74.47, 73.93, 73.99, 73.84, 74.565, 75.275, 75.675, 74.635, 75.81, 76.6, 76.565, 76.11, 75.62, 76.04, 76.385, 75.77, 75.98, 75.655, 76.51, 76.92, 76.7, 77.355, 78.175, 77.065, 77.175, 77.695, 77.08, 76.97, 77.2, 78.085, 77.85, 78.02, 77.465, 78.0, 78.125, 77.77, 78.595, 78.56, 77.98, 78.285, 78.02, 77.77, 78.9, 78.765, 77.545, 78.34, 79.185, 77.93, 77.645, 78.44, 78.59, 78.965, 78.795, 79.325, 78.475, 79.05, 78.63, 78.985, 78.565, 78.57, 79.24, 79.35, 79.3, 78.805, 79.81, 80.445, 79.48, 78.345, 79.795, 78.9, 79.32, 78.38, 78.45, 78.71, 79.17, 78.5, 78.295, 78.765, 79.0, 79.065]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100  

Files already downloaded and verified
Files already downloaded and verified
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
4800
4864
209664
209792
1028992
1029248
1062016
1062144
1063424
1063434
# Params: 1063434 (local), 1062144 (global); Percentage 99.88 (1062144/1063434)
learning rate, batch size: 0.01, 10
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
Round   0, Train loss: 2.286, Test loss: 2.080, Test accuracy: 31.70
Round   1, Train loss: 2.049, Test loss: 1.756, Test accuracy: 39.87
Round   2, Train loss: 1.871, Test loss: 1.615, Test accuracy: 47.06
Round   3, Train loss: 1.743, Test loss: 1.513, Test accuracy: 50.23
Round   4, Train loss: 1.631, Test loss: 1.425, Test accuracy: 54.17
Round   5, Train loss: 1.544, Test loss: 1.318, Test accuracy: 57.28
Round   6, Train loss: 1.459, Test loss: 1.220, Test accuracy: 60.76
Round   7, Train loss: 1.348, Test loss: 1.152, Test accuracy: 62.83
Round   8, Train loss: 1.279, Test loss: 1.115, Test accuracy: 63.28
Round   9, Train loss: 1.263, Test loss: 1.066, Test accuracy: 65.19
Round  10, Train loss: 1.163, Test loss: 1.045, Test accuracy: 65.63
Round  11, Train loss: 1.137, Test loss: 1.007, Test accuracy: 67.47
Round  12, Train loss: 1.065, Test loss: 0.970, Test accuracy: 67.70
Round  13, Train loss: 1.036, Test loss: 0.932, Test accuracy: 69.17
Round  14, Train loss: 1.021, Test loss: 0.922, Test accuracy: 70.16
Round  15, Train loss: 0.964, Test loss: 0.896, Test accuracy: 70.38
Round  16, Train loss: 0.934, Test loss: 0.897, Test accuracy: 70.68
Round  17, Train loss: 0.947, Test loss: 0.843, Test accuracy: 71.95
Round  18, Train loss: 0.894, Test loss: 0.819, Test accuracy: 73.03
Round  19, Train loss: 0.847, Test loss: 0.828, Test accuracy: 72.82
Round  20, Train loss: 0.795, Test loss: 0.819, Test accuracy: 72.42
Round  21, Train loss: 0.780, Test loss: 0.825, Test accuracy: 72.67
Round  22, Train loss: 0.763, Test loss: 0.799, Test accuracy: 74.35
Round  23, Train loss: 0.727, Test loss: 0.786, Test accuracy: 74.67
Round  24, Train loss: 0.735, Test loss: 0.756, Test accuracy: 75.52
Round  25, Train loss: 0.696, Test loss: 0.777, Test accuracy: 74.84
Round  26, Train loss: 0.713, Test loss: 0.735, Test accuracy: 76.73
Round  27, Train loss: 0.675, Test loss: 0.734, Test accuracy: 76.17
Round  28, Train loss: 0.642, Test loss: 0.752, Test accuracy: 75.67
Round  29, Train loss: 0.613, Test loss: 0.739, Test accuracy: 76.22
Round  30, Train loss: 0.605, Test loss: 0.722, Test accuracy: 76.92
Round  31, Train loss: 0.584, Test loss: 0.716, Test accuracy: 76.95
Round  32, Train loss: 0.554, Test loss: 0.710, Test accuracy: 76.66
Round  33, Train loss: 0.555, Test loss: 0.709, Test accuracy: 77.03
Round  34, Train loss: 0.581, Test loss: 0.722, Test accuracy: 76.37
Round  35, Train loss: 0.514, Test loss: 0.699, Test accuracy: 77.14
Round  36, Train loss: 0.478, Test loss: 0.713, Test accuracy: 76.46
Round  37, Train loss: 0.516, Test loss: 0.712, Test accuracy: 76.64
Round  38, Train loss: 0.471, Test loss: 0.689, Test accuracy: 78.22
Round  39, Train loss: 0.459, Test loss: 0.685, Test accuracy: 78.11
Round  40, Train loss: 0.414, Test loss: 0.695, Test accuracy: 77.81
Round  41, Train loss: 0.482, Test loss: 0.680, Test accuracy: 77.47
Round  42, Train loss: 0.430, Test loss: 0.687, Test accuracy: 77.88
Round  43, Train loss: 0.407, Test loss: 0.662, Test accuracy: 78.02
Round  44, Train loss: 0.391, Test loss: 0.670, Test accuracy: 78.42
Round  45, Train loss: 0.394, Test loss: 0.681, Test accuracy: 78.11
Round  46, Train loss: 0.349, Test loss: 0.689, Test accuracy: 77.90
Round  47, Train loss: 0.335, Test loss: 0.686, Test accuracy: 77.92
Round  48, Train loss: 0.351, Test loss: 0.682, Test accuracy: 78.08
Round  49, Train loss: 0.347, Test loss: 0.690, Test accuracy: 78.20
Round  50, Train loss: 0.284, Test loss: 0.707, Test accuracy: 77.91
Round  51, Train loss: 0.328, Test loss: 0.710, Test accuracy: 77.45
Round  52, Train loss: 0.310, Test loss: 0.745, Test accuracy: 78.14
Round  53, Train loss: 0.284, Test loss: 0.713, Test accuracy: 78.39
Round  54, Train loss: 0.296, Test loss: 0.727, Test accuracy: 77.80
Round  55, Train loss: 0.302, Test loss: 0.705, Test accuracy: 77.94
Round  56, Train loss: 0.281, Test loss: 0.738, Test accuracy: 78.36
Round  57, Train loss: 0.274, Test loss: 0.703, Test accuracy: 78.62
Round  58, Train loss: 0.264, Test loss: 0.708, Test accuracy: 78.31
Round  59, Train loss: 0.261, Test loss: 0.725, Test accuracy: 78.22
Round  60, Train loss: 0.200, Test loss: 0.707, Test accuracy: 78.72
Round  61, Train loss: 0.273, Test loss: 0.711, Test accuracy: 78.50
Round  62, Train loss: 0.228, Test loss: 0.722, Test accuracy: 78.66
Round  63, Train loss: 0.202, Test loss: 0.724, Test accuracy: 78.36
Round  64, Train loss: 0.243, Test loss: 0.731, Test accuracy: 78.55
Round  65, Train loss: 0.200, Test loss: 0.737, Test accuracy: 78.98
Round  66, Train loss: 0.213, Test loss: 0.733, Test accuracy: 77.59
Round  67, Train loss: 0.194, Test loss: 0.757, Test accuracy: 77.61
Round  68, Train loss: 0.233, Test loss: 0.739, Test accuracy: 77.92
Round  69, Train loss: 0.187, Test loss: 0.778, Test accuracy: 77.05
Round  70, Train loss: 0.219, Test loss: 0.747, Test accuracy: 78.00
Round  71, Train loss: 0.172, Test loss: 0.751, Test accuracy: 78.95
Round  72, Train loss: 0.180, Test loss: 0.748, Test accuracy: 79.69
Round  73, Train loss: 0.199, Test loss: 0.742, Test accuracy: 78.19
Round  74, Train loss: 0.196, Test loss: 0.765, Test accuracy: 79.42
Round  75, Train loss: 0.168, Test loss: 0.770, Test accuracy: 78.05
Round  76, Train loss: 0.155, Test loss: 0.750, Test accuracy: 78.06
Round  77, Train loss: 0.148, Test loss: 0.762, Test accuracy: 77.69
Round  78, Train loss: 0.139, Test loss: 0.758, Test accuracy: 78.83
Round  79, Train loss: 0.160, Test loss: 0.762, Test accuracy: 78.34
Round  80, Train loss: 0.174, Test loss: 0.748, Test accuracy: 78.44
Round  81, Train loss: 0.174, Test loss: 0.749, Test accuracy: 78.94
Round  82, Train loss: 0.159, Test loss: 0.743, Test accuracy: 79.27
Round  83, Train loss: 0.159, Test loss: 0.752, Test accuracy: 78.95
Round  84, Train loss: 0.137, Test loss: 0.771, Test accuracy: 78.72
Round  85, Train loss: 0.105, Test loss: 0.741, Test accuracy: 79.47
Round  86, Train loss: 0.120, Test loss: 0.758, Test accuracy: 78.92
Round  87, Train loss: 0.159, Test loss: 0.784, Test accuracy: 78.31
Round  88, Train loss: 0.129, Test loss: 0.777, Test accuracy: 79.33
Round  89, Train loss: 0.142, Test loss: 0.749, Test accuracy: 78.66
Round  90, Train loss: 0.118, Test loss: 0.777, Test accuracy: 78.71
Round  91, Train loss: 0.133, Test loss: 0.757, Test accuracy: 79.31
Round  92, Train loss: 0.126, Test loss: 0.765, Test accuracy: 79.58
Round  93, Train loss: 0.134, Test loss: 0.757, Test accuracy: 79.42
Round  94, Train loss: 0.117, Test loss: 0.783, Test accuracy: 79.45
Round  95, Train loss: 0.132, Test loss: 0.772, Test accuracy: 78.25
Round  96, Train loss: 0.098, Test loss: 0.765, Test accuracy: 78.84
Round  97, Train loss: 0.100, Test loss: 0.754, Test accuracy: 79.26
Round  98, Train loss: 0.108, Test loss: 0.777, Test accuracy: 78.52
Round  99, Train loss: 0.112, Test loss: 0.762, Test accuracy: 78.53
Final Round, Train loss: 0.057, Test loss: 0.767, Test accuracy: 78.53
Average accuracy final 10 rounds: 78.987
3046.187999010086
[3.610010862350464, 7.220021724700928, 10.366491556167603, 13.512961387634277, 16.557583570480347, 19.602205753326416, 22.79190969467163, 25.981613636016846, 28.95607876777649, 31.930543899536133, 34.97304677963257, 38.015549659729004, 41.252925157547, 44.49030065536499, 47.505579233169556, 50.52085781097412, 53.521501302719116, 56.52214479446411, 59.54139733314514, 62.56064987182617, 65.44750046730042, 68.33435106277466, 71.33742117881775, 74.34049129486084, 77.38072943687439, 80.42096757888794, 83.30610942840576, 86.19125127792358, 89.20983743667603, 92.22842359542847, 95.1472659111023, 98.06610822677612, 101.04529309272766, 104.0244779586792, 107.02528238296509, 110.02608680725098, 112.86364197731018, 115.70119714736938, 118.70684862136841, 121.71250009536743, 124.73710060119629, 127.76170110702515, 130.65893602371216, 133.55617094039917, 136.48951029777527, 139.42284965515137, 142.36558294296265, 145.30831623077393, 148.1659801006317, 151.0236439704895, 154.00803518295288, 156.99242639541626, 159.87672305107117, 162.76101970672607, 165.6924340724945, 168.62384843826294, 171.62300848960876, 174.6221685409546, 177.5188431739807, 180.41551780700684, 183.3886797428131, 186.36184167861938, 189.3239073753357, 192.285973072052, 195.13860750198364, 197.99124193191528, 200.95874571800232, 203.92624950408936, 206.8468954563141, 209.76754140853882, 212.61966252326965, 215.4717836380005, 218.39220666885376, 221.31262969970703, 224.1604835987091, 227.00833749771118, 229.9201943874359, 232.83205127716064, 235.80098938941956, 238.76992750167847, 241.62639546394348, 244.4828634262085, 247.39997339248657, 250.31708335876465, 253.24858260154724, 256.18008184432983, 259.0107433795929, 261.84140491485596, 264.7975654602051, 267.7537260055542, 270.66690707206726, 273.5800881385803, 276.3987019062042, 279.2173156738281, 282.1688816547394, 285.12044763565063, 287.99043583869934, 290.86042404174805, 293.7892620563507, 296.71810007095337, 299.7071943283081, 302.69628858566284, 305.612664937973, 308.5290412902832, 311.511194229126, 314.49334716796875, 317.47466492652893, 320.4559826850891, 323.34141278266907, 326.226842880249, 329.17434000968933, 332.12183713912964, 335.10509634017944, 338.08835554122925, 340.96124482154846, 343.8341341018677, 346.7954626083374, 349.75679111480713, 352.65327167510986, 355.5497522354126, 358.54716181755066, 361.5445713996887, 364.5941672325134, 367.64376306533813, 370.56531500816345, 373.48686695098877, 376.4967715740204, 379.506676197052, 382.55723094940186, 385.6077857017517, 388.4960513114929, 391.38431692123413, 394.38357949256897, 397.3828420639038, 400.3894109725952, 403.3959798812866, 406.2847032546997, 409.1734266281128, 412.1864023208618, 415.19937801361084, 418.11366295814514, 421.02794790267944, 424.00012731552124, 426.97230672836304, 429.9410562515259, 432.9098057746887, 435.7635431289673, 438.61728048324585, 441.57888293266296, 444.5404853820801, 447.5682911872864, 450.5960969924927, 453.4531636238098, 456.31023025512695, 459.2249457836151, 462.13966131210327, 465.0575602054596, 467.9754590988159, 470.88080406188965, 473.7861490249634, 476.70298290252686, 479.61981678009033, 482.452828168869, 485.2858395576477, 488.2037250995636, 491.1216106414795, 494.1149277687073, 497.10824489593506, 499.9774489402771, 502.84665298461914, 505.8481698036194, 508.84968662261963, 511.8431611061096, 514.8366355895996, 517.6521918773651, 520.4677481651306, 523.3670887947083, 526.2664294242859, 529.1909377574921, 532.1154460906982, 534.9221918582916, 537.728937625885, 540.6404659748077, 543.5519943237305, 546.4536716938019, 549.3553490638733, 552.3345448970795, 555.3137407302856, 558.3452141284943, 561.3766875267029, 564.2610971927643, 567.1455068588257, 570.0971546173096, 573.0488023757935, 576.0098371505737, 578.970871925354, 581.8319931030273, 584.6931142807007, 587.6589202880859, 590.6247262954712, 592.9371066093445, 595.2494869232178]
[31.705, 31.705, 39.865, 39.865, 47.065, 47.065, 50.235, 50.235, 54.17, 54.17, 57.28, 57.28, 60.76, 60.76, 62.825, 62.825, 63.28, 63.28, 65.185, 65.185, 65.63, 65.63, 67.465, 67.465, 67.705, 67.705, 69.175, 69.175, 70.16, 70.16, 70.38, 70.38, 70.68, 70.68, 71.95, 71.95, 73.03, 73.03, 72.82, 72.82, 72.42, 72.42, 72.665, 72.665, 74.35, 74.35, 74.665, 74.665, 75.52, 75.52, 74.84, 74.84, 76.73, 76.73, 76.17, 76.17, 75.675, 75.675, 76.22, 76.22, 76.915, 76.915, 76.955, 76.955, 76.66, 76.66, 77.035, 77.035, 76.37, 76.37, 77.145, 77.145, 76.46, 76.46, 76.645, 76.645, 78.215, 78.215, 78.105, 78.105, 77.805, 77.805, 77.465, 77.465, 77.875, 77.875, 78.02, 78.02, 78.42, 78.42, 78.105, 78.105, 77.9, 77.9, 77.92, 77.92, 78.075, 78.075, 78.2, 78.2, 77.91, 77.91, 77.45, 77.45, 78.145, 78.145, 78.395, 78.395, 77.8, 77.8, 77.945, 77.945, 78.355, 78.355, 78.625, 78.625, 78.305, 78.305, 78.225, 78.225, 78.725, 78.725, 78.505, 78.505, 78.66, 78.66, 78.365, 78.365, 78.545, 78.545, 78.985, 78.985, 77.59, 77.59, 77.61, 77.61, 77.915, 77.915, 77.045, 77.045, 78.0, 78.0, 78.95, 78.95, 79.685, 79.685, 78.195, 78.195, 79.42, 79.42, 78.05, 78.05, 78.06, 78.06, 77.685, 77.685, 78.83, 78.83, 78.34, 78.34, 78.445, 78.445, 78.935, 78.935, 79.265, 79.265, 78.95, 78.95, 78.715, 78.715, 79.47, 79.47, 78.925, 78.925, 78.31, 78.31, 79.335, 79.335, 78.66, 78.66, 78.71, 78.71, 79.31, 79.31, 79.585, 79.585, 79.42, 79.42, 79.45, 79.45, 78.245, 78.245, 78.845, 78.845, 79.26, 79.26, 78.515, 78.515, 78.53, 78.53, 78.535, 78.535]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.257, Test loss: 1.911, Test accuracy: 30.93
Round   0, Global train loss: 1.257, Global test loss: 2.229, Global test accuracy: 23.12
Round   1, Train loss: 1.015, Test loss: 1.848, Test accuracy: 40.05
Round   1, Global train loss: 1.015, Global test loss: 2.533, Global test accuracy: 22.63
Round   2, Train loss: 1.028, Test loss: 1.324, Test accuracy: 48.52
Round   2, Global train loss: 1.028, Global test loss: 2.294, Global test accuracy: 23.53
Round   3, Train loss: 0.866, Test loss: 0.930, Test accuracy: 62.18
Round   3, Global train loss: 0.866, Global test loss: 1.950, Global test accuracy: 38.13
Round   4, Train loss: 0.805, Test loss: 0.759, Test accuracy: 68.38
Round   4, Global train loss: 0.805, Global test loss: 1.922, Global test accuracy: 37.78
Round   5, Train loss: 0.815, Test loss: 0.753, Test accuracy: 69.42
Round   5, Global train loss: 0.815, Global test loss: 2.300, Global test accuracy: 31.67
Round   6, Train loss: 0.794, Test loss: 0.676, Test accuracy: 70.87
Round   6, Global train loss: 0.794, Global test loss: 2.469, Global test accuracy: 19.67
Round   7, Train loss: 0.715, Test loss: 0.659, Test accuracy: 72.07
Round   7, Global train loss: 0.715, Global test loss: 2.273, Global test accuracy: 29.93
Round   8, Train loss: 0.633, Test loss: 0.651, Test accuracy: 72.67
Round   8, Global train loss: 0.633, Global test loss: 2.104, Global test accuracy: 34.60
Round   9, Train loss: 0.673, Test loss: 0.621, Test accuracy: 74.58
Round   9, Global train loss: 0.673, Global test loss: 2.055, Global test accuracy: 26.28
Round  10, Train loss: 0.673, Test loss: 0.602, Test accuracy: 75.67
Round  10, Global train loss: 0.673, Global test loss: 2.189, Global test accuracy: 28.47
Round  11, Train loss: 0.515, Test loss: 0.599, Test accuracy: 75.82
Round  11, Global train loss: 0.515, Global test loss: 1.848, Global test accuracy: 36.72
Round  12, Train loss: 0.634, Test loss: 0.591, Test accuracy: 76.20
Round  12, Global train loss: 0.634, Global test loss: 2.211, Global test accuracy: 31.17
Round  13, Train loss: 0.608, Test loss: 0.573, Test accuracy: 76.95
Round  13, Global train loss: 0.608, Global test loss: 2.416, Global test accuracy: 28.93
Round  14, Train loss: 0.561, Test loss: 0.570, Test accuracy: 77.07
Round  14, Global train loss: 0.561, Global test loss: 2.021, Global test accuracy: 36.40
Round  15, Train loss: 0.580, Test loss: 0.585, Test accuracy: 77.05
Round  15, Global train loss: 0.580, Global test loss: 1.930, Global test accuracy: 33.53
Round  16, Train loss: 0.617, Test loss: 0.557, Test accuracy: 78.02
Round  16, Global train loss: 0.617, Global test loss: 2.037, Global test accuracy: 32.98
Round  17, Train loss: 0.467, Test loss: 0.543, Test accuracy: 78.68
Round  17, Global train loss: 0.467, Global test loss: 1.921, Global test accuracy: 35.97
Round  18, Train loss: 0.518, Test loss: 0.525, Test accuracy: 79.70
Round  18, Global train loss: 0.518, Global test loss: 2.045, Global test accuracy: 34.47
Round  19, Train loss: 0.479, Test loss: 0.524, Test accuracy: 80.00
Round  19, Global train loss: 0.479, Global test loss: 2.074, Global test accuracy: 34.03
Round  20, Train loss: 0.478, Test loss: 0.521, Test accuracy: 80.47
Round  20, Global train loss: 0.478, Global test loss: 2.047, Global test accuracy: 29.60
Round  21, Train loss: 0.466, Test loss: 0.514, Test accuracy: 81.17
Round  21, Global train loss: 0.466, Global test loss: 2.133, Global test accuracy: 23.82
Round  22, Train loss: 0.419, Test loss: 0.512, Test accuracy: 80.98
Round  22, Global train loss: 0.419, Global test loss: 2.003, Global test accuracy: 28.97
Round  23, Train loss: 0.402, Test loss: 0.511, Test accuracy: 81.17
Round  23, Global train loss: 0.402, Global test loss: 2.038, Global test accuracy: 28.00
Round  24, Train loss: 0.470, Test loss: 0.520, Test accuracy: 81.03
Round  24, Global train loss: 0.470, Global test loss: 1.946, Global test accuracy: 38.75
Round  25, Train loss: 0.327, Test loss: 0.505, Test accuracy: 81.65
Round  25, Global train loss: 0.327, Global test loss: 1.885, Global test accuracy: 38.00
Round  26, Train loss: 0.361, Test loss: 0.510, Test accuracy: 81.52
Round  26, Global train loss: 0.361, Global test loss: 2.032, Global test accuracy: 33.67
Round  27, Train loss: 0.338, Test loss: 0.525, Test accuracy: 81.32
Round  27, Global train loss: 0.338, Global test loss: 2.237, Global test accuracy: 32.97
Round  28, Train loss: 0.386, Test loss: 0.527, Test accuracy: 81.57
Round  28, Global train loss: 0.386, Global test loss: 2.326, Global test accuracy: 20.90
Round  29, Train loss: 0.399, Test loss: 0.503, Test accuracy: 81.97
Round  29, Global train loss: 0.399, Global test loss: 2.250, Global test accuracy: 24.97
Round  30, Train loss: 0.351, Test loss: 0.509, Test accuracy: 81.70
Round  30, Global train loss: 0.351, Global test loss: 1.996, Global test accuracy: 31.27
Round  31, Train loss: 0.308, Test loss: 0.519, Test accuracy: 81.63
Round  31, Global train loss: 0.308, Global test loss: 2.169, Global test accuracy: 23.20
Round  32, Train loss: 0.326, Test loss: 0.502, Test accuracy: 82.57
Round  32, Global train loss: 0.326, Global test loss: 2.345, Global test accuracy: 28.13
Round  33, Train loss: 0.307, Test loss: 0.501, Test accuracy: 83.20
Round  33, Global train loss: 0.307, Global test loss: 1.813, Global test accuracy: 45.60
Round  34, Train loss: 0.292, Test loss: 0.514, Test accuracy: 83.28
Round  34, Global train loss: 0.292, Global test loss: 2.183, Global test accuracy: 31.07
Round  35, Train loss: 0.288, Test loss: 0.512, Test accuracy: 83.35
Round  35, Global train loss: 0.288, Global test loss: 1.887, Global test accuracy: 38.03
Round  36, Train loss: 0.330, Test loss: 0.515, Test accuracy: 83.60
Round  36, Global train loss: 0.330, Global test loss: 1.827, Global test accuracy: 39.52
Round  37, Train loss: 0.234, Test loss: 0.534, Test accuracy: 83.32
Round  37, Global train loss: 0.234, Global test loss: 2.112, Global test accuracy: 32.90
Round  38, Train loss: 0.232, Test loss: 0.546, Test accuracy: 83.13
Round  38, Global train loss: 0.232, Global test loss: 2.013, Global test accuracy: 30.90
Round  39, Train loss: 0.238, Test loss: 0.526, Test accuracy: 84.13
Round  39, Global train loss: 0.238, Global test loss: 1.812, Global test accuracy: 40.37
Round  40, Train loss: 0.234, Test loss: 0.533, Test accuracy: 84.22
Round  40, Global train loss: 0.234, Global test loss: 2.047, Global test accuracy: 33.10
Round  41, Train loss: 0.182, Test loss: 0.547, Test accuracy: 84.23
Round  41, Global train loss: 0.182, Global test loss: 2.006, Global test accuracy: 34.42
Round  42, Train loss: 0.244, Test loss: 0.576, Test accuracy: 84.03
Round  42, Global train loss: 0.244, Global test loss: 2.080, Global test accuracy: 37.23
Round  43, Train loss: 0.179, Test loss: 0.564, Test accuracy: 84.27
Round  43, Global train loss: 0.179, Global test loss: 1.869, Global test accuracy: 44.57
Round  44, Train loss: 0.194, Test loss: 0.578, Test accuracy: 84.02
Round  44, Global train loss: 0.194, Global test loss: 1.907, Global test accuracy: 38.17
Round  45, Train loss: 0.173, Test loss: 0.568, Test accuracy: 84.33
Round  45, Global train loss: 0.173, Global test loss: 2.080, Global test accuracy: 32.78
Round  46, Train loss: 0.155, Test loss: 0.544, Test accuracy: 84.43
Round  46, Global train loss: 0.155, Global test loss: 1.825, Global test accuracy: 39.10
Round  47, Train loss: 0.184, Test loss: 0.552, Test accuracy: 84.05
Round  47, Global train loss: 0.184, Global test loss: 1.971, Global test accuracy: 33.43
Round  48, Train loss: 0.177, Test loss: 0.570, Test accuracy: 83.78
Round  48, Global train loss: 0.177, Global test loss: 2.324, Global test accuracy: 33.30
Round  49, Train loss: 0.224, Test loss: 0.593, Test accuracy: 83.33
Round  49, Global train loss: 0.224, Global test loss: 2.036, Global test accuracy: 25.40
Round  50, Train loss: 0.199, Test loss: 0.575, Test accuracy: 84.02
Round  50, Global train loss: 0.199, Global test loss: 1.844, Global test accuracy: 39.82
Round  51, Train loss: 0.138, Test loss: 0.585, Test accuracy: 83.55
Round  51, Global train loss: 0.138, Global test loss: 2.032, Global test accuracy: 36.38
Round  52, Train loss: 0.173, Test loss: 0.590, Test accuracy: 83.45
Round  52, Global train loss: 0.173, Global test loss: 1.894, Global test accuracy: 36.02
Round  53, Train loss: 0.170, Test loss: 0.604, Test accuracy: 83.27
Round  53, Global train loss: 0.170, Global test loss: 1.943, Global test accuracy: 36.53
Round  54, Train loss: 0.209, Test loss: 0.600, Test accuracy: 83.47
Round  54, Global train loss: 0.209, Global test loss: 2.097, Global test accuracy: 36.45
Round  55, Train loss: 0.150, Test loss: 0.596, Test accuracy: 83.40
Round  55, Global train loss: 0.150, Global test loss: 2.048, Global test accuracy: 33.20
Round  56, Train loss: 0.152, Test loss: 0.585, Test accuracy: 83.85
Round  56, Global train loss: 0.152, Global test loss: 1.927, Global test accuracy: 32.35
Round  57, Train loss: 0.162, Test loss: 0.571, Test accuracy: 84.52
Round  57, Global train loss: 0.162, Global test loss: 1.912, Global test accuracy: 33.93
Round  58, Train loss: 0.132, Test loss: 0.596, Test accuracy: 83.95
Round  58, Global train loss: 0.132, Global test loss: 2.096, Global test accuracy: 30.23
Round  59, Train loss: 0.122, Test loss: 0.614, Test accuracy: 83.97
Round  59, Global train loss: 0.122, Global test loss: 1.957, Global test accuracy: 33.70
Round  60, Train loss: 0.135, Test loss: 0.642, Test accuracy: 83.93
Round  60, Global train loss: 0.135, Global test loss: 1.962, Global test accuracy: 36.37
Round  61, Train loss: 0.135, Test loss: 0.638, Test accuracy: 84.15
Round  61, Global train loss: 0.135, Global test loss: 1.794, Global test accuracy: 40.23
Round  62, Train loss: 0.122, Test loss: 0.651, Test accuracy: 83.95
Round  62, Global train loss: 0.122, Global test loss: 1.938, Global test accuracy: 35.70
Round  63, Train loss: 0.135, Test loss: 0.669, Test accuracy: 83.43
Round  63, Global train loss: 0.135, Global test loss: 1.945, Global test accuracy: 35.15
Round  64, Train loss: 0.140, Test loss: 0.642, Test accuracy: 84.23
Round  64, Global train loss: 0.140, Global test loss: 2.050, Global test accuracy: 36.40
Round  65, Train loss: 0.154, Test loss: 0.636, Test accuracy: 84.47
Round  65, Global train loss: 0.154, Global test loss: 2.112, Global test accuracy: 34.77
Round  66, Train loss: 0.135, Test loss: 0.652, Test accuracy: 84.22
Round  66, Global train loss: 0.135, Global test loss: 2.006, Global test accuracy: 36.83
Round  67, Train loss: 0.123, Test loss: 0.656, Test accuracy: 84.58
Round  67, Global train loss: 0.123, Global test loss: 2.045, Global test accuracy: 34.88
Round  68, Train loss: 0.109, Test loss: 0.664, Test accuracy: 84.67
Round  68, Global train loss: 0.109, Global test loss: 2.120, Global test accuracy: 33.55
Round  69, Train loss: 0.105, Test loss: 0.685, Test accuracy: 84.88
Round  69, Global train loss: 0.105, Global test loss: 2.382, Global test accuracy: 33.97
Round  70, Train loss: 0.077, Test loss: 0.681, Test accuracy: 84.97
Round  70, Global train loss: 0.077, Global test loss: 1.972, Global test accuracy: 35.07
Round  71, Train loss: 0.103, Test loss: 0.687, Test accuracy: 84.92
Round  71, Global train loss: 0.103, Global test loss: 1.973, Global test accuracy: 38.17
Round  72, Train loss: 0.119, Test loss: 0.675, Test accuracy: 84.72
Round  72, Global train loss: 0.119, Global test loss: 1.920, Global test accuracy: 37.58
Round  73, Train loss: 0.078, Test loss: 0.661, Test accuracy: 85.03
Round  73, Global train loss: 0.078, Global test loss: 1.893, Global test accuracy: 39.60
Round  74, Train loss: 0.084, Test loss: 0.711, Test accuracy: 84.58
Round  74, Global train loss: 0.084, Global test loss: 2.009, Global test accuracy: 35.63
Round  75, Train loss: 0.108, Test loss: 0.692, Test accuracy: 84.78
Round  75, Global train loss: 0.108, Global test loss: 1.923, Global test accuracy: 38.60
Round  76, Train loss: 0.090, Test loss: 0.647, Test accuracy: 85.17
Round  76, Global train loss: 0.090, Global test loss: 2.041, Global test accuracy: 30.35
Round  77, Train loss: 0.087, Test loss: 0.665, Test accuracy: 84.88
Round  77, Global train loss: 0.087, Global test loss: 2.065, Global test accuracy: 36.27
Round  78, Train loss: 0.075, Test loss: 0.668, Test accuracy: 85.20
Round  78, Global train loss: 0.075, Global test loss: 1.975, Global test accuracy: 36.82
Round  79, Train loss: 0.072, Test loss: 0.681, Test accuracy: 85.03
Round  79, Global train loss: 0.072, Global test loss: 1.882, Global test accuracy: 43.73
Round  80, Train loss: 0.082, Test loss: 0.680, Test accuracy: 85.43
Round  80, Global train loss: 0.082, Global test loss: 1.861, Global test accuracy: 42.50
Round  81, Train loss: 0.079, Test loss: 0.714, Test accuracy: 85.42
Round  81, Global train loss: 0.079, Global test loss: 1.939, Global test accuracy: 43.87
Round  82, Train loss: 0.086, Test loss: 0.710, Test accuracy: 85.07
Round  82, Global train loss: 0.086, Global test loss: 1.886, Global test accuracy: 43.20
Round  83, Train loss: 0.076, Test loss: 0.760, Test accuracy: 84.42
Round  83, Global train loss: 0.076, Global test loss: 2.006, Global test accuracy: 39.03
Round  84, Train loss: 0.074, Test loss: 0.735, Test accuracy: 84.85
Round  84, Global train loss: 0.074, Global test loss: 2.003, Global test accuracy: 35.93
Round  85, Train loss: 0.063, Test loss: 0.707, Test accuracy: 85.03
Round  85, Global train loss: 0.063, Global test loss: 2.441, Global test accuracy: 33.87
Round  86, Train loss: 0.076, Test loss: 0.669, Test accuracy: 85.42
Round  86, Global train loss: 0.076, Global test loss: 1.868, Global test accuracy: 37.87
Round  87, Train loss: 0.071, Test loss: 0.669, Test accuracy: 85.20
Round  87, Global train loss: 0.071, Global test loss: 1.924, Global test accuracy: 42.50
Round  88, Train loss: 0.073, Test loss: 0.697, Test accuracy: 85.02
Round  88, Global train loss: 0.073, Global test loss: 1.920, Global test accuracy: 36.27
Round  89, Train loss: 0.070, Test loss: 0.687, Test accuracy: 85.25
Round  89, Global train loss: 0.070, Global test loss: 1.966, Global test accuracy: 36.88
Round  90, Train loss: 0.055, Test loss: 0.691, Test accuracy: 85.27
Round  90, Global train loss: 0.055, Global test loss: 1.811, Global test accuracy: 39.90
Round  91, Train loss: 0.064, Test loss: 0.698, Test accuracy: 85.52
Round  91, Global train loss: 0.064, Global test loss: 2.088, Global test accuracy: 35.67
Round  92, Train loss: 0.070, Test loss: 0.694, Test accuracy: 85.57
Round  92, Global train loss: 0.070, Global test loss: 2.005, Global test accuracy: 34.63
Round  93, Train loss: 0.067, Test loss: 0.704, Test accuracy: 85.28
Round  93, Global train loss: 0.067, Global test loss: 2.064, Global test accuracy: 24.87
Round  94, Train loss: 0.075, Test loss: 0.696, Test accuracy: 85.17
Round  94, Global train loss: 0.075, Global test loss: 1.896, Global test accuracy: 38.25
Round  95, Train loss: 0.081, Test loss: 0.675, Test accuracy: 85.13
Round  95, Global train loss: 0.081, Global test loss: 1.922, Global test accuracy: 33.17
Round  96, Train loss: 0.055, Test loss: 0.689, Test accuracy: 85.03
Round  96, Global train loss: 0.055, Global test loss: 2.014, Global test accuracy: 38.02
Round  97, Train loss: 0.050, Test loss: 0.732, Test accuracy: 84.85
Round  97, Global train loss: 0.050, Global test loss: 1.951, Global test accuracy: 36.37
Round  98, Train loss: 0.066, Test loss: 0.728, Test accuracy: 85.00
Round  98, Global train loss: 0.066, Global test loss: 2.048, Global test accuracy: 25.33
Round  99, Train loss: 0.050, Test loss: 0.707, Test accuracy: 85.40
Round  99, Global train loss: 0.050, Global test loss: 2.088, Global test accuracy: 27.90
Final Round, Train loss: 0.049, Test loss: 0.754, Test accuracy: 85.20
Final Round, Global train loss: 0.049, Global test loss: 2.088, Global test accuracy: 27.90
Average accuracy final 10 rounds: 85.22166666666666 

Average global accuracy final 10 rounds: 33.41 

1039.4269075393677
[1.0824902057647705, 2.164980411529541, 2.905081033706665, 3.645181655883789, 4.3785319328308105, 5.111882209777832, 5.814563989639282, 6.517245769500732, 7.2155609130859375, 7.913876056671143, 8.60972547531128, 9.305574893951416, 10.012086868286133, 10.71859884262085, 11.45560622215271, 12.19261360168457, 12.927999496459961, 13.663385391235352, 14.414071321487427, 15.164757251739502, 15.892405986785889, 16.620054721832275, 17.327741861343384, 18.035429000854492, 18.745323657989502, 19.45521831512451, 20.141945838928223, 20.828673362731934, 21.534175395965576, 22.23967742919922, 22.99287462234497, 23.746071815490723, 24.47452664375305, 25.20298147201538, 25.95428729057312, 26.70559310913086, 27.446818113327026, 28.188043117523193, 28.895035982131958, 29.602028846740723, 30.30993628501892, 31.01784372329712, 31.71686816215515, 32.415892601013184, 33.120060443878174, 33.824228286743164, 34.56298351287842, 35.30173873901367, 36.04208254814148, 36.78242635726929, 37.528204679489136, 38.273983001708984, 39.025630950927734, 39.777278900146484, 40.48811054229736, 41.19894218444824, 41.91606307029724, 42.63318395614624, 43.355791091918945, 44.07839822769165, 44.79717206954956, 45.51594591140747, 46.25355625152588, 46.99116659164429, 47.735979080200195, 48.4807915687561, 49.22600054740906, 49.97120952606201, 50.71983337402344, 51.46845722198486, 52.19346594810486, 52.91847467422485, 53.62362265586853, 54.32877063751221, 55.03597545623779, 55.74318027496338, 56.453959226608276, 57.164738178253174, 57.87793231010437, 58.591126441955566, 59.33663582801819, 60.08214521408081, 60.813937187194824, 61.54572916030884, 62.31010866165161, 63.074488162994385, 63.80351781845093, 64.53254747390747, 65.24430632591248, 65.95606517791748, 66.67536950111389, 67.3946738243103, 68.1018705368042, 68.8090672492981, 69.52888584136963, 70.24870443344116, 71.00221657752991, 71.75572872161865, 72.49072623252869, 73.22572374343872, 73.99052691459656, 74.7553300857544, 75.4971513748169, 76.2389726638794, 76.97086930274963, 77.70276594161987, 78.41070079803467, 79.11863565444946, 79.81962275505066, 80.52060985565186, 81.23374223709106, 81.94687461853027, 82.69593477249146, 83.44499492645264, 84.19009351730347, 84.9351921081543, 85.68522691726685, 86.4352617263794, 87.19058060646057, 87.94589948654175, 88.65709328651428, 89.36828708648682, 90.07230567932129, 90.77632427215576, 91.49094653129578, 92.20556879043579, 92.92707371711731, 93.64857864379883, 94.38995432853699, 95.13133001327515, 95.86316442489624, 96.59499883651733, 97.34031367301941, 98.08562850952148, 98.83716607093811, 99.58870363235474, 100.31183576583862, 101.03496789932251, 101.7505533695221, 102.46613883972168, 103.17504143714905, 103.88394403457642, 104.59078121185303, 105.29761838912964, 106.0436339378357, 106.78964948654175, 107.52756643295288, 108.26548337936401, 109.0333456993103, 109.80120801925659, 110.54364681243896, 111.28608560562134, 112.02050375938416, 112.75492191314697, 113.4719820022583, 114.18904209136963, 114.88919639587402, 115.58935070037842, 116.29588055610657, 117.00241041183472, 117.71697115898132, 118.43153190612793, 119.1683087348938, 119.90508556365967, 120.6499993801117, 121.39491319656372, 122.13884925842285, 122.88278532028198, 123.60721182823181, 124.33163833618164, 125.07883167266846, 125.82602500915527, 126.52815365791321, 127.23028230667114, 127.9379370212555, 128.64559173583984, 129.36990809440613, 130.0942244529724, 130.84574508666992, 131.59726572036743, 132.34829378128052, 133.0993218421936, 133.86773800849915, 134.6361541748047, 135.35410904884338, 136.07206392288208, 136.78097677230835, 137.48988962173462, 138.21308946609497, 138.93628931045532, 139.6401309967041, 140.34397268295288, 141.06090378761292, 141.77783489227295, 142.53036379814148, 143.28289270401, 144.02156972885132, 144.76024675369263, 145.51507306098938, 146.26989936828613, 147.71287178993225, 149.15584421157837]
[30.933333333333334, 30.933333333333334, 40.05, 40.05, 48.516666666666666, 48.516666666666666, 62.18333333333333, 62.18333333333333, 68.38333333333334, 68.38333333333334, 69.41666666666667, 69.41666666666667, 70.86666666666666, 70.86666666666666, 72.06666666666666, 72.06666666666666, 72.66666666666667, 72.66666666666667, 74.58333333333333, 74.58333333333333, 75.66666666666667, 75.66666666666667, 75.81666666666666, 75.81666666666666, 76.2, 76.2, 76.95, 76.95, 77.06666666666666, 77.06666666666666, 77.05, 77.05, 78.01666666666667, 78.01666666666667, 78.68333333333334, 78.68333333333334, 79.7, 79.7, 80.0, 80.0, 80.46666666666667, 80.46666666666667, 81.16666666666667, 81.16666666666667, 80.98333333333333, 80.98333333333333, 81.16666666666667, 81.16666666666667, 81.03333333333333, 81.03333333333333, 81.65, 81.65, 81.51666666666667, 81.51666666666667, 81.31666666666666, 81.31666666666666, 81.56666666666666, 81.56666666666666, 81.96666666666667, 81.96666666666667, 81.7, 81.7, 81.63333333333334, 81.63333333333334, 82.56666666666666, 82.56666666666666, 83.2, 83.2, 83.28333333333333, 83.28333333333333, 83.35, 83.35, 83.6, 83.6, 83.31666666666666, 83.31666666666666, 83.13333333333334, 83.13333333333334, 84.13333333333334, 84.13333333333334, 84.21666666666667, 84.21666666666667, 84.23333333333333, 84.23333333333333, 84.03333333333333, 84.03333333333333, 84.26666666666667, 84.26666666666667, 84.01666666666667, 84.01666666666667, 84.33333333333333, 84.33333333333333, 84.43333333333334, 84.43333333333334, 84.05, 84.05, 83.78333333333333, 83.78333333333333, 83.33333333333333, 83.33333333333333, 84.01666666666667, 84.01666666666667, 83.55, 83.55, 83.45, 83.45, 83.26666666666667, 83.26666666666667, 83.46666666666667, 83.46666666666667, 83.4, 83.4, 83.85, 83.85, 84.51666666666667, 84.51666666666667, 83.95, 83.95, 83.96666666666667, 83.96666666666667, 83.93333333333334, 83.93333333333334, 84.15, 84.15, 83.95, 83.95, 83.43333333333334, 83.43333333333334, 84.23333333333333, 84.23333333333333, 84.46666666666667, 84.46666666666667, 84.21666666666667, 84.21666666666667, 84.58333333333333, 84.58333333333333, 84.66666666666667, 84.66666666666667, 84.88333333333334, 84.88333333333334, 84.96666666666667, 84.96666666666667, 84.91666666666667, 84.91666666666667, 84.71666666666667, 84.71666666666667, 85.03333333333333, 85.03333333333333, 84.58333333333333, 84.58333333333333, 84.78333333333333, 84.78333333333333, 85.16666666666667, 85.16666666666667, 84.88333333333334, 84.88333333333334, 85.2, 85.2, 85.03333333333333, 85.03333333333333, 85.43333333333334, 85.43333333333334, 85.41666666666667, 85.41666666666667, 85.06666666666666, 85.06666666666666, 84.41666666666667, 84.41666666666667, 84.85, 84.85, 85.03333333333333, 85.03333333333333, 85.41666666666667, 85.41666666666667, 85.2, 85.2, 85.01666666666667, 85.01666666666667, 85.25, 85.25, 85.26666666666667, 85.26666666666667, 85.51666666666667, 85.51666666666667, 85.56666666666666, 85.56666666666666, 85.28333333333333, 85.28333333333333, 85.16666666666667, 85.16666666666667, 85.13333333333334, 85.13333333333334, 85.03333333333333, 85.03333333333333, 84.85, 84.85, 85.0, 85.0, 85.4, 85.4, 85.2, 85.2]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.251, Test loss: 2.047, Test accuracy: 27.82
Round   0, Global train loss: 1.251, Global test loss: 2.337, Global test accuracy: 20.00
Round   1, Train loss: 1.074, Test loss: 1.570, Test accuracy: 43.42
Round   1, Global train loss: 1.074, Global test loss: 2.262, Global test accuracy: 29.00
Round   2, Train loss: 0.982, Test loss: 1.226, Test accuracy: 53.32
Round   2, Global train loss: 0.982, Global test loss: 2.026, Global test accuracy: 35.23
Round   3, Train loss: 0.990, Test loss: 0.990, Test accuracy: 62.28
Round   3, Global train loss: 0.990, Global test loss: 1.916, Global test accuracy: 37.72
Round   4, Train loss: 0.929, Test loss: 0.947, Test accuracy: 64.13
Round   4, Global train loss: 0.929, Global test loss: 2.152, Global test accuracy: 34.63
Round   5, Train loss: 0.841, Test loss: 0.757, Test accuracy: 69.82
Round   5, Global train loss: 0.841, Global test loss: 1.688, Global test accuracy: 44.37
Round   6, Train loss: 0.786, Test loss: 0.660, Test accuracy: 72.93
Round   6, Global train loss: 0.786, Global test loss: 1.835, Global test accuracy: 44.80
Round   7, Train loss: 0.719, Test loss: 0.632, Test accuracy: 74.42
Round   7, Global train loss: 0.719, Global test loss: 1.732, Global test accuracy: 44.73
Round   8, Train loss: 0.752, Test loss: 0.617, Test accuracy: 75.32
Round   8, Global train loss: 0.752, Global test loss: 1.656, Global test accuracy: 45.75
Round   9, Train loss: 0.681, Test loss: 0.603, Test accuracy: 75.78
Round   9, Global train loss: 0.681, Global test loss: 1.632, Global test accuracy: 44.75
Round  10, Train loss: 0.771, Test loss: 0.575, Test accuracy: 77.37
Round  10, Global train loss: 0.771, Global test loss: 1.586, Global test accuracy: 47.03
Round  11, Train loss: 0.634, Test loss: 0.578, Test accuracy: 77.07
Round  11, Global train loss: 0.634, Global test loss: 1.819, Global test accuracy: 45.18
Round  12, Train loss: 0.595, Test loss: 0.583, Test accuracy: 77.03
Round  12, Global train loss: 0.595, Global test loss: 1.562, Global test accuracy: 51.10
Round  13, Train loss: 0.679, Test loss: 0.564, Test accuracy: 78.07
Round  13, Global train loss: 0.679, Global test loss: 1.475, Global test accuracy: 51.80
Round  14, Train loss: 0.526, Test loss: 0.581, Test accuracy: 78.37
Round  14, Global train loss: 0.526, Global test loss: 2.111, Global test accuracy: 44.87
Round  15, Train loss: 0.622, Test loss: 0.574, Test accuracy: 78.88
Round  15, Global train loss: 0.622, Global test loss: 1.562, Global test accuracy: 47.70
Round  16, Train loss: 0.582, Test loss: 0.527, Test accuracy: 80.00
Round  16, Global train loss: 0.582, Global test loss: 1.479, Global test accuracy: 52.97
Round  17, Train loss: 0.621, Test loss: 0.507, Test accuracy: 80.80
Round  17, Global train loss: 0.621, Global test loss: 1.349, Global test accuracy: 53.75
Round  18, Train loss: 0.586, Test loss: 0.483, Test accuracy: 82.07
Round  18, Global train loss: 0.586, Global test loss: 1.303, Global test accuracy: 57.93
Round  19, Train loss: 0.497, Test loss: 0.503, Test accuracy: 82.17
Round  19, Global train loss: 0.497, Global test loss: 1.629, Global test accuracy: 49.70
Round  20, Train loss: 0.524, Test loss: 0.467, Test accuracy: 83.00
Round  20, Global train loss: 0.524, Global test loss: 1.476, Global test accuracy: 52.72
Round  21, Train loss: 0.499, Test loss: 0.461, Test accuracy: 82.87
Round  21, Global train loss: 0.499, Global test loss: 1.650, Global test accuracy: 49.45
Round  22, Train loss: 0.536, Test loss: 0.462, Test accuracy: 82.97
Round  22, Global train loss: 0.536, Global test loss: 1.415, Global test accuracy: 55.45
Round  23, Train loss: 0.504, Test loss: 0.464, Test accuracy: 83.18
Round  23, Global train loss: 0.504, Global test loss: 1.348, Global test accuracy: 54.97
Round  24, Train loss: 0.472, Test loss: 0.470, Test accuracy: 82.98
Round  24, Global train loss: 0.472, Global test loss: 1.345, Global test accuracy: 56.42
Round  25, Train loss: 0.447, Test loss: 0.458, Test accuracy: 83.72
Round  25, Global train loss: 0.447, Global test loss: 1.339, Global test accuracy: 57.87
Round  26, Train loss: 0.537, Test loss: 0.442, Test accuracy: 83.97
Round  26, Global train loss: 0.537, Global test loss: 1.097, Global test accuracy: 63.78
Round  27, Train loss: 0.477, Test loss: 0.439, Test accuracy: 84.18
Round  27, Global train loss: 0.477, Global test loss: 1.310, Global test accuracy: 58.25
Round  28, Train loss: 0.473, Test loss: 0.448, Test accuracy: 84.17
Round  28, Global train loss: 0.473, Global test loss: 1.332, Global test accuracy: 59.53
Round  29, Train loss: 0.360, Test loss: 0.452, Test accuracy: 84.15
Round  29, Global train loss: 0.360, Global test loss: 1.477, Global test accuracy: 58.10
Round  30, Train loss: 0.447, Test loss: 0.462, Test accuracy: 83.83
Round  30, Global train loss: 0.447, Global test loss: 1.376, Global test accuracy: 57.17
Round  31, Train loss: 0.368, Test loss: 0.440, Test accuracy: 84.50
Round  31, Global train loss: 0.368, Global test loss: 1.315, Global test accuracy: 60.78
Round  32, Train loss: 0.434, Test loss: 0.469, Test accuracy: 83.93
Round  32, Global train loss: 0.434, Global test loss: 1.062, Global test accuracy: 64.22
Round  33, Train loss: 0.386, Test loss: 0.461, Test accuracy: 84.30
Round  33, Global train loss: 0.386, Global test loss: 1.152, Global test accuracy: 62.00
Round  34, Train loss: 0.360, Test loss: 0.445, Test accuracy: 84.68
Round  34, Global train loss: 0.360, Global test loss: 1.116, Global test accuracy: 63.13
Round  35, Train loss: 0.408, Test loss: 0.445, Test accuracy: 85.05
Round  35, Global train loss: 0.408, Global test loss: 1.125, Global test accuracy: 63.40
Round  36, Train loss: 0.372, Test loss: 0.426, Test accuracy: 85.62
Round  36, Global train loss: 0.372, Global test loss: 1.115, Global test accuracy: 63.10
Round  37, Train loss: 0.342, Test loss: 0.419, Test accuracy: 85.75
Round  37, Global train loss: 0.342, Global test loss: 1.136, Global test accuracy: 64.18
Round  38, Train loss: 0.322, Test loss: 0.438, Test accuracy: 85.12
Round  38, Global train loss: 0.322, Global test loss: 1.005, Global test accuracy: 66.80
Round  39, Train loss: 0.305, Test loss: 0.449, Test accuracy: 85.28
Round  39, Global train loss: 0.305, Global test loss: 1.128, Global test accuracy: 62.25
Round  40, Train loss: 0.343, Test loss: 0.437, Test accuracy: 85.72
Round  40, Global train loss: 0.343, Global test loss: 0.987, Global test accuracy: 66.85
Round  41, Train loss: 0.318, Test loss: 0.461, Test accuracy: 85.25
Round  41, Global train loss: 0.318, Global test loss: 1.185, Global test accuracy: 62.20
Round  42, Train loss: 0.333, Test loss: 0.456, Test accuracy: 85.50
Round  42, Global train loss: 0.333, Global test loss: 1.097, Global test accuracy: 64.95
Round  43, Train loss: 0.297, Test loss: 0.448, Test accuracy: 85.72
Round  43, Global train loss: 0.297, Global test loss: 1.072, Global test accuracy: 65.15
Round  44, Train loss: 0.337, Test loss: 0.459, Test accuracy: 85.32
Round  44, Global train loss: 0.337, Global test loss: 1.181, Global test accuracy: 64.13
Round  45, Train loss: 0.324, Test loss: 0.472, Test accuracy: 85.07
Round  45, Global train loss: 0.324, Global test loss: 1.043, Global test accuracy: 66.28
Round  46, Train loss: 0.323, Test loss: 0.448, Test accuracy: 85.82
Round  46, Global train loss: 0.323, Global test loss: 1.079, Global test accuracy: 65.22
Round  47, Train loss: 0.249, Test loss: 0.420, Test accuracy: 86.33
Round  47, Global train loss: 0.249, Global test loss: 1.042, Global test accuracy: 66.45
Round  48, Train loss: 0.274, Test loss: 0.439, Test accuracy: 86.17
Round  48, Global train loss: 0.274, Global test loss: 1.284, Global test accuracy: 62.32
Round  49, Train loss: 0.286, Test loss: 0.458, Test accuracy: 86.13
Round  49, Global train loss: 0.286, Global test loss: 0.987, Global test accuracy: 68.08
Round  50, Train loss: 0.233, Test loss: 0.441, Test accuracy: 86.27
Round  50, Global train loss: 0.233, Global test loss: 0.981, Global test accuracy: 67.97
Round  51, Train loss: 0.243, Test loss: 0.447, Test accuracy: 86.12
Round  51, Global train loss: 0.243, Global test loss: 1.251, Global test accuracy: 63.97
Round  52, Train loss: 0.298, Test loss: 0.447, Test accuracy: 86.17
Round  52, Global train loss: 0.298, Global test loss: 0.967, Global test accuracy: 67.97
Round  53, Train loss: 0.240, Test loss: 0.448, Test accuracy: 86.33
Round  53, Global train loss: 0.240, Global test loss: 1.304, Global test accuracy: 61.50
Round  54, Train loss: 0.259, Test loss: 0.447, Test accuracy: 86.35
Round  54, Global train loss: 0.259, Global test loss: 1.105, Global test accuracy: 65.45
Round  55, Train loss: 0.289, Test loss: 0.446, Test accuracy: 86.33
Round  55, Global train loss: 0.289, Global test loss: 1.054, Global test accuracy: 66.12
Round  56, Train loss: 0.282, Test loss: 0.421, Test accuracy: 87.22
Round  56, Global train loss: 0.282, Global test loss: 1.085, Global test accuracy: 65.57
Round  57, Train loss: 0.224, Test loss: 0.423, Test accuracy: 87.15
Round  57, Global train loss: 0.224, Global test loss: 1.201, Global test accuracy: 65.02
Round  58, Train loss: 0.261, Test loss: 0.433, Test accuracy: 86.80
Round  58, Global train loss: 0.261, Global test loss: 1.042, Global test accuracy: 66.90
Round  59, Train loss: 0.290, Test loss: 0.448, Test accuracy: 86.43
Round  59, Global train loss: 0.290, Global test loss: 1.170, Global test accuracy: 65.53
Round  60, Train loss: 0.246, Test loss: 0.458, Test accuracy: 86.37
Round  60, Global train loss: 0.246, Global test loss: 1.011, Global test accuracy: 66.83
Round  61, Train loss: 0.233, Test loss: 0.461, Test accuracy: 86.42
Round  61, Global train loss: 0.233, Global test loss: 1.069, Global test accuracy: 67.17
Round  62, Train loss: 0.197, Test loss: 0.467, Test accuracy: 86.55
Round  62, Global train loss: 0.197, Global test loss: 1.330, Global test accuracy: 62.67
Round  63, Train loss: 0.219, Test loss: 0.451, Test accuracy: 86.82
Round  63, Global train loss: 0.219, Global test loss: 1.104, Global test accuracy: 66.55
Round  64, Train loss: 0.231, Test loss: 0.456, Test accuracy: 86.32
Round  64, Global train loss: 0.231, Global test loss: 1.075, Global test accuracy: 66.97
Round  65, Train loss: 0.222, Test loss: 0.454, Test accuracy: 86.70
Round  65, Global train loss: 0.222, Global test loss: 1.204, Global test accuracy: 64.88
Round  66, Train loss: 0.252, Test loss: 0.433, Test accuracy: 87.32
Round  66, Global train loss: 0.252, Global test loss: 1.100, Global test accuracy: 67.02
Round  67, Train loss: 0.148, Test loss: 0.434, Test accuracy: 87.23
Round  67, Global train loss: 0.148, Global test loss: 1.393, Global test accuracy: 62.67
Round  68, Train loss: 0.241, Test loss: 0.430, Test accuracy: 87.35
Round  68, Global train loss: 0.241, Global test loss: 1.073, Global test accuracy: 67.18
Round  69, Train loss: 0.219, Test loss: 0.445, Test accuracy: 87.18
Round  69, Global train loss: 0.219, Global test loss: 0.987, Global test accuracy: 67.45
Round  70, Train loss: 0.175, Test loss: 0.457, Test accuracy: 87.30
Round  70, Global train loss: 0.175, Global test loss: 1.088, Global test accuracy: 66.67
Round  71, Train loss: 0.210, Test loss: 0.443, Test accuracy: 87.62
Round  71, Global train loss: 0.210, Global test loss: 0.896, Global test accuracy: 71.32
Round  72, Train loss: 0.233, Test loss: 0.480, Test accuracy: 86.78
Round  72, Global train loss: 0.233, Global test loss: 1.022, Global test accuracy: 68.25
Round  73, Train loss: 0.191, Test loss: 0.498, Test accuracy: 86.78
Round  73, Global train loss: 0.191, Global test loss: 1.098, Global test accuracy: 67.00
Round  74, Train loss: 0.217, Test loss: 0.493, Test accuracy: 86.88
Round  74, Global train loss: 0.217, Global test loss: 1.091, Global test accuracy: 66.77
Round  75, Train loss: 0.180, Test loss: 0.486, Test accuracy: 86.90
Round  75, Global train loss: 0.180, Global test loss: 1.058, Global test accuracy: 68.10
Round  76, Train loss: 0.161, Test loss: 0.463, Test accuracy: 87.50
Round  76, Global train loss: 0.161, Global test loss: 1.137, Global test accuracy: 66.78
Round  77, Train loss: 0.201, Test loss: 0.456, Test accuracy: 87.78
Round  77, Global train loss: 0.201, Global test loss: 0.936, Global test accuracy: 70.78
Round  78, Train loss: 0.173, Test loss: 0.471, Test accuracy: 87.20
Round  78, Global train loss: 0.173, Global test loss: 0.997, Global test accuracy: 68.35
Round  79, Train loss: 0.189, Test loss: 0.487, Test accuracy: 87.00
Round  79, Global train loss: 0.189, Global test loss: 0.931, Global test accuracy: 70.88
Round  80, Train loss: 0.192, Test loss: 0.478, Test accuracy: 87.20
Round  80, Global train loss: 0.192, Global test loss: 0.969, Global test accuracy: 69.17
Round  81, Train loss: 0.164, Test loss: 0.458, Test accuracy: 87.52
Round  81, Global train loss: 0.164, Global test loss: 1.132, Global test accuracy: 69.53
Round  82, Train loss: 0.224, Test loss: 0.441, Test accuracy: 87.57
Round  82, Global train loss: 0.224, Global test loss: 1.074, Global test accuracy: 67.13
Round  83, Train loss: 0.169, Test loss: 0.458, Test accuracy: 87.65
Round  83, Global train loss: 0.169, Global test loss: 0.882, Global test accuracy: 72.03
Round  84, Train loss: 0.172, Test loss: 0.466, Test accuracy: 87.72
Round  84, Global train loss: 0.172, Global test loss: 1.126, Global test accuracy: 67.28
Round  85, Train loss: 0.148, Test loss: 0.475, Test accuracy: 88.10
Round  85, Global train loss: 0.148, Global test loss: 1.006, Global test accuracy: 68.87
Round  86, Train loss: 0.129, Test loss: 0.482, Test accuracy: 87.85
Round  86, Global train loss: 0.129, Global test loss: 1.163, Global test accuracy: 67.88
Round  87, Train loss: 0.152, Test loss: 0.481, Test accuracy: 87.53
Round  87, Global train loss: 0.152, Global test loss: 0.968, Global test accuracy: 69.10
Round  88, Train loss: 0.185, Test loss: 0.450, Test accuracy: 88.05
Round  88, Global train loss: 0.185, Global test loss: 1.105, Global test accuracy: 68.03
Round  89, Train loss: 0.136, Test loss: 0.463, Test accuracy: 87.75
Round  89, Global train loss: 0.136, Global test loss: 0.975, Global test accuracy: 70.62
Round  90, Train loss: 0.151, Test loss: 0.445, Test accuracy: 88.28
Round  90, Global train loss: 0.151, Global test loss: 0.956, Global test accuracy: 70.82
Round  91, Train loss: 0.115, Test loss: 0.442, Test accuracy: 88.48
Round  91, Global train loss: 0.115, Global test loss: 1.066, Global test accuracy: 68.37
Round  92, Train loss: 0.127, Test loss: 0.450, Test accuracy: 88.42
Round  92, Global train loss: 0.127, Global test loss: 1.117, Global test accuracy: 69.02
Round  93, Train loss: 0.119, Test loss: 0.471, Test accuracy: 88.02
Round  93, Global train loss: 0.119, Global test loss: 1.092, Global test accuracy: 69.47
Round  94, Train loss: 0.137, Test loss: 0.470, Test accuracy: 88.10
Round  94, Global train loss: 0.137, Global test loss: 0.907, Global test accuracy: 72.95
Round  95, Train loss: 0.122, Test loss: 0.467, Test accuracy: 88.08
Round  95, Global train loss: 0.122, Global test loss: 1.017, Global test accuracy: 71.63
Round  96, Train loss: 0.118, Test loss: 0.455, Test accuracy: 88.13
Round  96, Global train loss: 0.118, Global test loss: 1.056, Global test accuracy: 69.80
Round  97, Train loss: 0.109, Test loss: 0.470, Test accuracy: 88.00
Round  97, Global train loss: 0.109, Global test loss: 1.186, Global test accuracy: 66.82
Round  98, Train loss: 0.136, Test loss: 0.455, Test accuracy: 88.17
Round  98, Global train loss: 0.136, Global test loss: 0.974, Global test accuracy: 70.85
Round  99, Train loss: 0.120, Test loss: 0.458, Test accuracy: 88.10
Round  99, Global train loss: 0.120, Global test loss: 1.018, Global test accuracy: 69.08
Final Round, Train loss: 0.111, Test loss: 0.476, Test accuracy: 88.13
Final Round, Global train loss: 0.111, Global test loss: 1.018, Global test accuracy: 69.08
Average accuracy final 10 rounds: 88.17833333333333 

Average global accuracy final 10 rounds: 69.88 

1034.048483133316
[1.0177030563354492, 2.0354061126708984, 2.768810987472534, 3.50221586227417, 4.253560781478882, 5.004905700683594, 5.743866682052612, 6.482827663421631, 7.224705934524536, 7.966584205627441, 8.680181980133057, 9.393779754638672, 10.126133680343628, 10.858487606048584, 11.566920518875122, 12.27535343170166, 12.986018419265747, 13.696683406829834, 14.449122428894043, 15.201561450958252, 15.929275512695312, 16.656989574432373, 17.398822784423828, 18.140655994415283, 18.87790274620056, 19.61514949798584, 20.325352430343628, 21.035555362701416, 21.73810887336731, 22.440662384033203, 23.147623300552368, 23.854584217071533, 24.56438374519348, 25.27418327331543, 25.975853204727173, 26.677523136138916, 27.415581464767456, 28.153639793395996, 28.89971685409546, 29.645793914794922, 30.382623195648193, 31.119452476501465, 31.839170455932617, 32.55888843536377, 33.25991606712341, 33.96094369888306, 34.670995235443115, 35.381046772003174, 36.08369851112366, 36.78635025024414, 37.50250720977783, 38.21866416931152, 38.97279381752014, 39.72692346572876, 40.47435164451599, 41.22177982330322, 41.96911072731018, 42.71644163131714, 43.44484829902649, 44.17325496673584, 44.88153648376465, 45.58981800079346, 46.289506673812866, 46.989195346832275, 47.69581890106201, 48.40244245529175, 49.11905097961426, 49.83565950393677, 50.586294651031494, 51.33692979812622, 52.09067416191101, 52.8444185256958, 53.58493137359619, 54.32544422149658, 55.05038094520569, 55.775317668914795, 56.464604139328, 57.15389060974121, 57.850929975509644, 58.547969341278076, 59.247661113739014, 59.94735288619995, 60.65419101715088, 61.36102914810181, 62.113219022750854, 62.8654088973999, 63.59764647483826, 64.32988405227661, 65.08628010749817, 65.84267616271973, 66.58190250396729, 67.32112884521484, 68.03300714492798, 68.74488544464111, 69.446373462677, 70.14786148071289, 70.84660911560059, 71.54535675048828, 72.24748086929321, 72.94960498809814, 73.6886260509491, 74.42764711380005, 75.16237807273865, 75.89710903167725, 76.63022637367249, 77.36334371566772, 78.1168487071991, 78.87035369873047, 79.58949565887451, 80.30863761901855, 81.01087737083435, 81.71311712265015, 82.41723799705505, 83.12135887145996, 83.81936717033386, 84.51737546920776, 85.26212358474731, 86.00687170028687, 86.74633145332336, 87.48579120635986, 88.22822308540344, 88.97065496444702, 89.72121524810791, 90.4717755317688, 91.18671107292175, 91.9016466140747, 92.66839694976807, 93.43514728546143, 94.15712809562683, 94.87910890579224, 95.63958072662354, 96.40005254745483, 97.12460803985596, 97.84916353225708, 98.61693859100342, 99.38471364974976, 100.11828207969666, 100.85185050964355, 101.59942841529846, 102.34700632095337, 103.07059240341187, 103.79417848587036, 104.49614787101746, 105.19811725616455, 105.90686273574829, 106.61560821533203, 107.3232831954956, 108.03095817565918, 108.74460649490356, 109.45825481414795, 110.20048952102661, 110.94272422790527, 111.67319130897522, 112.40365839004517, 113.15341544151306, 113.90317249298096, 114.62635064125061, 115.34952878952026, 116.04459714889526, 116.73966550827026, 117.4459822177887, 118.15229892730713, 118.8553102016449, 119.55832147598267, 120.26573824882507, 120.97315502166748, 121.7186062335968, 122.46405744552612, 123.18822050094604, 123.91238355636597, 124.65533804893494, 125.3982925415039, 126.13980054855347, 126.88130855560303, 127.5904312133789, 128.29955387115479, 129.00904726982117, 129.71854066848755, 130.42137026786804, 131.12419986724854, 131.82643866539001, 132.5286774635315, 133.28588581085205, 134.0430941581726, 134.77806639671326, 135.5130386352539, 136.25757479667664, 137.00211095809937, 137.7262122631073, 138.45031356811523, 139.15125608444214, 139.85219860076904, 140.55942368507385, 141.26664876937866, 141.9804904460907, 142.69433212280273, 143.4021453857422, 144.10995864868164, 144.86334824562073, 145.61673784255981, 147.07502055168152, 148.53330326080322]
[27.816666666666666, 27.816666666666666, 43.416666666666664, 43.416666666666664, 53.31666666666667, 53.31666666666667, 62.28333333333333, 62.28333333333333, 64.13333333333334, 64.13333333333334, 69.81666666666666, 69.81666666666666, 72.93333333333334, 72.93333333333334, 74.41666666666667, 74.41666666666667, 75.31666666666666, 75.31666666666666, 75.78333333333333, 75.78333333333333, 77.36666666666666, 77.36666666666666, 77.06666666666666, 77.06666666666666, 77.03333333333333, 77.03333333333333, 78.06666666666666, 78.06666666666666, 78.36666666666666, 78.36666666666666, 78.88333333333334, 78.88333333333334, 80.0, 80.0, 80.8, 80.8, 82.06666666666666, 82.06666666666666, 82.16666666666667, 82.16666666666667, 83.0, 83.0, 82.86666666666666, 82.86666666666666, 82.96666666666667, 82.96666666666667, 83.18333333333334, 83.18333333333334, 82.98333333333333, 82.98333333333333, 83.71666666666667, 83.71666666666667, 83.96666666666667, 83.96666666666667, 84.18333333333334, 84.18333333333334, 84.16666666666667, 84.16666666666667, 84.15, 84.15, 83.83333333333333, 83.83333333333333, 84.5, 84.5, 83.93333333333334, 83.93333333333334, 84.3, 84.3, 84.68333333333334, 84.68333333333334, 85.05, 85.05, 85.61666666666666, 85.61666666666666, 85.75, 85.75, 85.11666666666666, 85.11666666666666, 85.28333333333333, 85.28333333333333, 85.71666666666667, 85.71666666666667, 85.25, 85.25, 85.5, 85.5, 85.71666666666667, 85.71666666666667, 85.31666666666666, 85.31666666666666, 85.06666666666666, 85.06666666666666, 85.81666666666666, 85.81666666666666, 86.33333333333333, 86.33333333333333, 86.16666666666667, 86.16666666666667, 86.13333333333334, 86.13333333333334, 86.26666666666667, 86.26666666666667, 86.11666666666666, 86.11666666666666, 86.16666666666667, 86.16666666666667, 86.33333333333333, 86.33333333333333, 86.35, 86.35, 86.33333333333333, 86.33333333333333, 87.21666666666667, 87.21666666666667, 87.15, 87.15, 86.8, 86.8, 86.43333333333334, 86.43333333333334, 86.36666666666666, 86.36666666666666, 86.41666666666667, 86.41666666666667, 86.55, 86.55, 86.81666666666666, 86.81666666666666, 86.31666666666666, 86.31666666666666, 86.7, 86.7, 87.31666666666666, 87.31666666666666, 87.23333333333333, 87.23333333333333, 87.35, 87.35, 87.18333333333334, 87.18333333333334, 87.3, 87.3, 87.61666666666666, 87.61666666666666, 86.78333333333333, 86.78333333333333, 86.78333333333333, 86.78333333333333, 86.88333333333334, 86.88333333333334, 86.9, 86.9, 87.5, 87.5, 87.78333333333333, 87.78333333333333, 87.2, 87.2, 87.0, 87.0, 87.2, 87.2, 87.51666666666667, 87.51666666666667, 87.56666666666666, 87.56666666666666, 87.65, 87.65, 87.71666666666667, 87.71666666666667, 88.1, 88.1, 87.85, 87.85, 87.53333333333333, 87.53333333333333, 88.05, 88.05, 87.75, 87.75, 88.28333333333333, 88.28333333333333, 88.48333333333333, 88.48333333333333, 88.41666666666667, 88.41666666666667, 88.01666666666667, 88.01666666666667, 88.1, 88.1, 88.08333333333333, 88.08333333333333, 88.13333333333334, 88.13333333333334, 88.0, 88.0, 88.16666666666667, 88.16666666666667, 88.1, 88.1, 88.13333333333334, 88.13333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 1063434 (local), 1062144 (global); Percentage 99.88 (1062144/1063434 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.690, Test loss: 2.028, Test accuracy: 32.23
Round   1, Train loss: 1.151, Test loss: 1.991, Test accuracy: 36.82
Round   2, Train loss: 0.983, Test loss: 1.783, Test accuracy: 43.22
Round   3, Train loss: 0.985, Test loss: 1.397, Test accuracy: 49.73
Round   4, Train loss: 0.921, Test loss: 1.235, Test accuracy: 53.80
Round   5, Train loss: 0.920, Test loss: 1.116, Test accuracy: 58.03
Round   6, Train loss: 0.820, Test loss: 1.119, Test accuracy: 60.38
Round   7, Train loss: 0.884, Test loss: 0.906, Test accuracy: 64.73
Round   8, Train loss: 0.848, Test loss: 0.831, Test accuracy: 68.08
Round   9, Train loss: 0.734, Test loss: 0.817, Test accuracy: 67.90
Round  10, Train loss: 0.727, Test loss: 0.646, Test accuracy: 72.80
Round  11, Train loss: 0.731, Test loss: 0.637, Test accuracy: 73.97
Round  12, Train loss: 0.764, Test loss: 0.626, Test accuracy: 74.75
Round  13, Train loss: 0.669, Test loss: 0.618, Test accuracy: 75.47
Round  14, Train loss: 0.713, Test loss: 0.614, Test accuracy: 76.08
Round  15, Train loss: 0.699, Test loss: 0.601, Test accuracy: 75.65
Round  16, Train loss: 0.620, Test loss: 0.581, Test accuracy: 76.68
Round  17, Train loss: 0.640, Test loss: 0.579, Test accuracy: 77.78
Round  18, Train loss: 0.602, Test loss: 0.573, Test accuracy: 77.28
Round  19, Train loss: 0.598, Test loss: 0.568, Test accuracy: 77.82
Round  20, Train loss: 0.654, Test loss: 0.554, Test accuracy: 77.90
Round  21, Train loss: 0.514, Test loss: 0.549, Test accuracy: 78.62
Round  22, Train loss: 0.605, Test loss: 0.549, Test accuracy: 78.35
Round  23, Train loss: 0.547, Test loss: 0.514, Test accuracy: 79.90
Round  24, Train loss: 0.573, Test loss: 0.529, Test accuracy: 79.48
Round  25, Train loss: 0.551, Test loss: 0.505, Test accuracy: 80.30
Round  26, Train loss: 0.540, Test loss: 0.501, Test accuracy: 81.23
Round  27, Train loss: 0.532, Test loss: 0.474, Test accuracy: 81.72
Round  28, Train loss: 0.524, Test loss: 0.473, Test accuracy: 81.73
Round  29, Train loss: 0.524, Test loss: 0.468, Test accuracy: 82.15
Round  30, Train loss: 0.429, Test loss: 0.479, Test accuracy: 81.62
Round  31, Train loss: 0.512, Test loss: 0.457, Test accuracy: 82.38
Round  32, Train loss: 0.399, Test loss: 0.463, Test accuracy: 82.23
Round  33, Train loss: 0.496, Test loss: 0.447, Test accuracy: 83.00
Round  34, Train loss: 0.442, Test loss: 0.445, Test accuracy: 83.03
Round  35, Train loss: 0.364, Test loss: 0.453, Test accuracy: 82.58
Round  36, Train loss: 0.457, Test loss: 0.443, Test accuracy: 82.67
Round  37, Train loss: 0.417, Test loss: 0.428, Test accuracy: 83.67
Round  38, Train loss: 0.440, Test loss: 0.439, Test accuracy: 84.00
Round  39, Train loss: 0.467, Test loss: 0.427, Test accuracy: 84.00
Round  40, Train loss: 0.396, Test loss: 0.426, Test accuracy: 84.35
Round  41, Train loss: 0.423, Test loss: 0.418, Test accuracy: 84.17
Round  42, Train loss: 0.408, Test loss: 0.424, Test accuracy: 84.12
Round  43, Train loss: 0.361, Test loss: 0.418, Test accuracy: 84.65
Round  44, Train loss: 0.348, Test loss: 0.426, Test accuracy: 84.62
Round  45, Train loss: 0.333, Test loss: 0.396, Test accuracy: 85.23
Round  46, Train loss: 0.363, Test loss: 0.409, Test accuracy: 84.57
Round  47, Train loss: 0.389, Test loss: 0.400, Test accuracy: 85.07
Round  48, Train loss: 0.369, Test loss: 0.400, Test accuracy: 85.13
Round  49, Train loss: 0.346, Test loss: 0.382, Test accuracy: 85.37
Round  50, Train loss: 0.372, Test loss: 0.395, Test accuracy: 84.58
Round  51, Train loss: 0.372, Test loss: 0.397, Test accuracy: 85.15
Round  52, Train loss: 0.382, Test loss: 0.385, Test accuracy: 85.73
Round  53, Train loss: 0.333, Test loss: 0.378, Test accuracy: 86.20
Round  54, Train loss: 0.354, Test loss: 0.367, Test accuracy: 86.60
Round  55, Train loss: 0.351, Test loss: 0.373, Test accuracy: 86.33
Round  56, Train loss: 0.379, Test loss: 0.378, Test accuracy: 85.88
Round  57, Train loss: 0.343, Test loss: 0.374, Test accuracy: 86.00
Round  58, Train loss: 0.326, Test loss: 0.375, Test accuracy: 86.30
Round  59, Train loss: 0.323, Test loss: 0.370, Test accuracy: 86.58
Round  60, Train loss: 0.296, Test loss: 0.384, Test accuracy: 85.90
Round  61, Train loss: 0.295, Test loss: 0.377, Test accuracy: 86.40
Round  62, Train loss: 0.260, Test loss: 0.365, Test accuracy: 86.63
Round  63, Train loss: 0.290, Test loss: 0.369, Test accuracy: 86.08
Round  64, Train loss: 0.266, Test loss: 0.370, Test accuracy: 86.33
Round  65, Train loss: 0.285, Test loss: 0.378, Test accuracy: 86.13
Round  66, Train loss: 0.264, Test loss: 0.367, Test accuracy: 86.42
Round  67, Train loss: 0.280, Test loss: 0.368, Test accuracy: 86.30
Round  68, Train loss: 0.258, Test loss: 0.363, Test accuracy: 86.60
Round  69, Train loss: 0.284, Test loss: 0.382, Test accuracy: 86.00
Round  70, Train loss: 0.293, Test loss: 0.374, Test accuracy: 86.62
Round  71, Train loss: 0.310, Test loss: 0.373, Test accuracy: 85.97
Round  72, Train loss: 0.280, Test loss: 0.361, Test accuracy: 86.77
Round  73, Train loss: 0.226, Test loss: 0.381, Test accuracy: 86.67
Round  74, Train loss: 0.196, Test loss: 0.376, Test accuracy: 86.73
Round  75, Train loss: 0.252, Test loss: 0.355, Test accuracy: 87.10
Round  76, Train loss: 0.233, Test loss: 0.351, Test accuracy: 86.97
Round  77, Train loss: 0.199, Test loss: 0.357, Test accuracy: 87.02
Round  78, Train loss: 0.224, Test loss: 0.377, Test accuracy: 86.85
Round  79, Train loss: 0.259, Test loss: 0.355, Test accuracy: 86.67
Round  80, Train loss: 0.160, Test loss: 0.371, Test accuracy: 87.20
Round  81, Train loss: 0.210, Test loss: 0.360, Test accuracy: 87.57
Round  82, Train loss: 0.239, Test loss: 0.368, Test accuracy: 86.88
Round  83, Train loss: 0.160, Test loss: 0.368, Test accuracy: 87.12
Round  84, Train loss: 0.285, Test loss: 0.369, Test accuracy: 87.20
Round  85, Train loss: 0.214, Test loss: 0.361, Test accuracy: 87.38
Round  86, Train loss: 0.199, Test loss: 0.391, Test accuracy: 86.70
Round  87, Train loss: 0.256, Test loss: 0.369, Test accuracy: 87.25
Round  88, Train loss: 0.222, Test loss: 0.370, Test accuracy: 87.17
Round  89, Train loss: 0.247, Test loss: 0.359, Test accuracy: 87.73
Round  90, Train loss: 0.230, Test loss: 0.351, Test accuracy: 87.60
Round  91, Train loss: 0.218, Test loss: 0.367, Test accuracy: 87.77
Round  92, Train loss: 0.240, Test loss: 0.351, Test accuracy: 87.67
Round  93, Train loss: 0.199, Test loss: 0.354, Test accuracy: 88.02
Round  94, Train loss: 0.219, Test loss: 0.349, Test accuracy: 88.00
Round  95, Train loss: 0.165, Test loss: 0.383, Test accuracy: 87.22
Round  96, Train loss: 0.214, Test loss: 0.355, Test accuracy: 88.42
Round  97, Train loss: 0.172, Test loss: 0.349, Test accuracy: 88.43
Round  98, Train loss: 0.161, Test loss: 0.354, Test accuracy: 88.12
Round  99, Train loss: 0.186, Test loss: 0.352, Test accuracy: 87.93
Final Round, Train loss: 0.162, Test loss: 0.363, Test accuracy: 88.00
Average accuracy final 10 rounds: 87.91666666666667 

819.3101217746735
[1.0211682319641113, 2.0423364639282227, 2.7848572731018066, 3.5273780822753906, 4.259632349014282, 4.991886615753174, 5.706589698791504, 6.421292781829834, 7.115515947341919, 7.809739112854004, 8.514622926712036, 9.219506740570068, 9.927793502807617, 10.636080265045166, 11.358105421066284, 12.080130577087402, 12.79486870765686, 13.509606838226318, 14.191352128982544, 14.87309741973877, 15.540164947509766, 16.20723247528076, 16.885592222213745, 17.56395196914673, 18.23940134048462, 18.91485071182251, 19.581655740737915, 20.24846076965332, 20.922861576080322, 21.597262382507324, 22.29900360107422, 23.000744819641113, 23.711754322052002, 24.42276382446289, 25.15164804458618, 25.880532264709473, 26.599886178970337, 27.3192400932312, 28.011448621749878, 28.703657150268555, 29.37631607055664, 30.048974990844727, 30.726590871810913, 31.4042067527771, 32.08767247200012, 32.771138191223145, 33.43981051445007, 34.108482837677, 34.78639554977417, 35.46430826187134, 36.18433165550232, 36.9043550491333, 37.60858917236328, 38.31282329559326, 39.010502099990845, 39.70818090438843, 40.43522047996521, 41.16226005554199, 41.85986948013306, 42.55747890472412, 43.22980713844299, 43.902135372161865, 44.57781624794006, 45.25349712371826, 45.93292570114136, 46.61235427856445, 47.28801369667053, 47.96367311477661, 48.63681769371033, 49.30996227264404, 50.00967240333557, 50.7093825340271, 51.42098116874695, 52.1325798034668, 52.834200382232666, 53.535820960998535, 54.26476573944092, 54.9937105178833, 55.689453125, 56.3851957321167, 57.06287121772766, 57.74054670333862, 58.40109062194824, 59.06163454055786, 59.73202919960022, 60.40242385864258, 61.07262682914734, 61.7428297996521, 62.41291165351868, 63.082993507385254, 63.76308798789978, 64.4431824684143, 65.13861870765686, 65.83405494689941, 66.52553963661194, 67.21702432632446, 67.90637040138245, 68.59571647644043, 69.31454563140869, 70.03337478637695, 70.71765637397766, 71.40193796157837, 72.06225395202637, 72.72256994247437, 73.39499473571777, 74.06741952896118, 74.74758839607239, 75.4277572631836, 76.10244512557983, 76.77713298797607, 77.4512825012207, 78.12543201446533, 78.83752799034119, 79.54962396621704, 80.23182797431946, 80.91403198242188, 81.60196566581726, 82.28989934921265, 82.998788356781, 83.70767736434937, 84.43206691741943, 85.1564564704895, 85.8393383026123, 86.52222013473511, 87.18900156021118, 87.85578298568726, 88.54333353042603, 89.2308840751648, 89.89170813560486, 90.55253219604492, 91.21390581130981, 91.8752794265747, 92.5503797531128, 93.22548007965088, 93.95197248458862, 94.67846488952637, 95.37628531455994, 96.0741057395935, 96.77198791503906, 97.46987009048462, 98.17180490493774, 98.87373971939087, 99.55249261856079, 100.23124551773071, 100.89954328536987, 101.56784105300903, 102.24267077445984, 102.91750049591064, 103.58566451072693, 104.25382852554321, 104.91365456581116, 105.5734806060791, 106.25679588317871, 106.94011116027832, 107.66073536872864, 108.38135957717896, 109.05906224250793, 109.73676490783691, 110.43101501464844, 111.12526512145996, 111.84589385986328, 112.5665225982666, 113.27070665359497, 113.97489070892334, 114.64365196228027, 115.3124132156372, 115.98148846626282, 116.65056371688843, 117.32736206054688, 118.00416040420532, 118.67865037918091, 119.3531403541565, 120.02315592765808, 120.69317150115967, 121.36266613006592, 122.03216075897217, 122.74031138420105, 123.44846200942993, 124.13502264022827, 124.82158327102661, 125.53990745544434, 126.25823163986206, 126.97652506828308, 127.6948184967041, 128.38513684272766, 129.07545518875122, 129.7381889820099, 130.40092277526855, 131.07094550132751, 131.74096822738647, 132.41428136825562, 133.08759450912476, 133.7486960887909, 134.40979766845703, 135.07649993896484, 135.74320220947266, 136.44227290153503, 137.1413435935974, 137.83031582832336, 138.51928806304932, 139.84025764465332, 141.16122722625732]
[32.233333333333334, 32.233333333333334, 36.81666666666667, 36.81666666666667, 43.21666666666667, 43.21666666666667, 49.733333333333334, 49.733333333333334, 53.8, 53.8, 58.03333333333333, 58.03333333333333, 60.38333333333333, 60.38333333333333, 64.73333333333333, 64.73333333333333, 68.08333333333333, 68.08333333333333, 67.9, 67.9, 72.8, 72.8, 73.96666666666667, 73.96666666666667, 74.75, 74.75, 75.46666666666667, 75.46666666666667, 76.08333333333333, 76.08333333333333, 75.65, 75.65, 76.68333333333334, 76.68333333333334, 77.78333333333333, 77.78333333333333, 77.28333333333333, 77.28333333333333, 77.81666666666666, 77.81666666666666, 77.9, 77.9, 78.61666666666666, 78.61666666666666, 78.35, 78.35, 79.9, 79.9, 79.48333333333333, 79.48333333333333, 80.3, 80.3, 81.23333333333333, 81.23333333333333, 81.71666666666667, 81.71666666666667, 81.73333333333333, 81.73333333333333, 82.15, 82.15, 81.61666666666666, 81.61666666666666, 82.38333333333334, 82.38333333333334, 82.23333333333333, 82.23333333333333, 83.0, 83.0, 83.03333333333333, 83.03333333333333, 82.58333333333333, 82.58333333333333, 82.66666666666667, 82.66666666666667, 83.66666666666667, 83.66666666666667, 84.0, 84.0, 84.0, 84.0, 84.35, 84.35, 84.16666666666667, 84.16666666666667, 84.11666666666666, 84.11666666666666, 84.65, 84.65, 84.61666666666666, 84.61666666666666, 85.23333333333333, 85.23333333333333, 84.56666666666666, 84.56666666666666, 85.06666666666666, 85.06666666666666, 85.13333333333334, 85.13333333333334, 85.36666666666666, 85.36666666666666, 84.58333333333333, 84.58333333333333, 85.15, 85.15, 85.73333333333333, 85.73333333333333, 86.2, 86.2, 86.6, 86.6, 86.33333333333333, 86.33333333333333, 85.88333333333334, 85.88333333333334, 86.0, 86.0, 86.3, 86.3, 86.58333333333333, 86.58333333333333, 85.9, 85.9, 86.4, 86.4, 86.63333333333334, 86.63333333333334, 86.08333333333333, 86.08333333333333, 86.33333333333333, 86.33333333333333, 86.13333333333334, 86.13333333333334, 86.41666666666667, 86.41666666666667, 86.3, 86.3, 86.6, 86.6, 86.0, 86.0, 86.61666666666666, 86.61666666666666, 85.96666666666667, 85.96666666666667, 86.76666666666667, 86.76666666666667, 86.66666666666667, 86.66666666666667, 86.73333333333333, 86.73333333333333, 87.1, 87.1, 86.96666666666667, 86.96666666666667, 87.01666666666667, 87.01666666666667, 86.85, 86.85, 86.66666666666667, 86.66666666666667, 87.2, 87.2, 87.56666666666666, 87.56666666666666, 86.88333333333334, 86.88333333333334, 87.11666666666666, 87.11666666666666, 87.2, 87.2, 87.38333333333334, 87.38333333333334, 86.7, 86.7, 87.25, 87.25, 87.16666666666667, 87.16666666666667, 87.73333333333333, 87.73333333333333, 87.6, 87.6, 87.76666666666667, 87.76666666666667, 87.66666666666667, 87.66666666666667, 88.01666666666667, 88.01666666666667, 88.0, 88.0, 87.21666666666667, 87.21666666666667, 88.41666666666667, 88.41666666666667, 88.43333333333334, 88.43333333333334, 88.11666666666666, 88.11666666666666, 87.93333333333334, 87.93333333333334, 88.0, 88.0]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
fedper
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 1063434 (local), 1062144 (global); Percentage 99.88 (1062144/1063434 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.267, Test loss: 2.252, Test accuracy: 25.53
Round   1, Train loss: 1.040, Test loss: 1.944, Test accuracy: 33.38
Round   2, Train loss: 0.975, Test loss: 1.539, Test accuracy: 50.17
Round   3, Train loss: 0.876, Test loss: 1.361, Test accuracy: 56.62
Round   4, Train loss: 0.788, Test loss: 1.201, Test accuracy: 58.68
Round   5, Train loss: 0.697, Test loss: 1.147, Test accuracy: 60.38
Round   6, Train loss: 0.736, Test loss: 0.967, Test accuracy: 66.32
Round   7, Train loss: 0.727, Test loss: 0.899, Test accuracy: 68.65
Round   8, Train loss: 0.704, Test loss: 0.932, Test accuracy: 68.17
Round   9, Train loss: 0.672, Test loss: 0.815, Test accuracy: 71.47
Round  10, Train loss: 0.726, Test loss: 0.757, Test accuracy: 71.48
Round  11, Train loss: 0.582, Test loss: 0.687, Test accuracy: 74.65
Round  12, Train loss: 0.583, Test loss: 0.651, Test accuracy: 75.98
Round  13, Train loss: 0.547, Test loss: 0.643, Test accuracy: 76.52
Round  14, Train loss: 0.597, Test loss: 0.625, Test accuracy: 77.38
Round  15, Train loss: 0.454, Test loss: 0.603, Test accuracy: 77.33
Round  16, Train loss: 0.486, Test loss: 0.579, Test accuracy: 78.07
Round  17, Train loss: 0.446, Test loss: 0.567, Test accuracy: 79.35
Round  18, Train loss: 0.514, Test loss: 0.525, Test accuracy: 80.78
Round  19, Train loss: 0.442, Test loss: 0.540, Test accuracy: 80.40
Round  20, Train loss: 0.497, Test loss: 0.490, Test accuracy: 81.27
Round  21, Train loss: 0.478, Test loss: 0.492, Test accuracy: 81.88
Round  22, Train loss: 0.432, Test loss: 0.492, Test accuracy: 81.53
Round  23, Train loss: 0.420, Test loss: 0.466, Test accuracy: 82.23
Round  24, Train loss: 0.429, Test loss: 0.459, Test accuracy: 82.37
Round  25, Train loss: 0.378, Test loss: 0.477, Test accuracy: 82.30
Round  26, Train loss: 0.375, Test loss: 0.441, Test accuracy: 83.35
Round  27, Train loss: 0.363, Test loss: 0.450, Test accuracy: 83.32
Round  28, Train loss: 0.338, Test loss: 0.433, Test accuracy: 84.02
Round  29, Train loss: 0.386, Test loss: 0.417, Test accuracy: 84.25
Round  30, Train loss: 0.386, Test loss: 0.438, Test accuracy: 83.13
Round  31, Train loss: 0.341, Test loss: 0.441, Test accuracy: 83.98
Round  32, Train loss: 0.346, Test loss: 0.402, Test accuracy: 85.03
Round  33, Train loss: 0.309, Test loss: 0.422, Test accuracy: 84.55
Round  34, Train loss: 0.358, Test loss: 0.408, Test accuracy: 85.05
Round  35, Train loss: 0.295, Test loss: 0.402, Test accuracy: 84.58
Round  36, Train loss: 0.267, Test loss: 0.400, Test accuracy: 84.70
Round  37, Train loss: 0.317, Test loss: 0.407, Test accuracy: 84.37
Round  38, Train loss: 0.346, Test loss: 0.388, Test accuracy: 85.10
Round  39, Train loss: 0.302, Test loss: 0.386, Test accuracy: 85.62
Round  40, Train loss: 0.275, Test loss: 0.386, Test accuracy: 85.47
Round  41, Train loss: 0.282, Test loss: 0.406, Test accuracy: 84.72
Round  42, Train loss: 0.235, Test loss: 0.392, Test accuracy: 85.40
Round  43, Train loss: 0.232, Test loss: 0.389, Test accuracy: 85.87
Round  44, Train loss: 0.281, Test loss: 0.390, Test accuracy: 86.18
Round  45, Train loss: 0.309, Test loss: 0.400, Test accuracy: 85.18
Round  46, Train loss: 0.242, Test loss: 0.377, Test accuracy: 86.32
Round  47, Train loss: 0.234, Test loss: 0.399, Test accuracy: 85.83
Round  48, Train loss: 0.221, Test loss: 0.380, Test accuracy: 85.95
Round  49, Train loss: 0.260, Test loss: 0.372, Test accuracy: 86.30
Round  50, Train loss: 0.238, Test loss: 0.348, Test accuracy: 86.90
Round  51, Train loss: 0.257, Test loss: 0.333, Test accuracy: 87.88
Round  52, Train loss: 0.222, Test loss: 0.338, Test accuracy: 87.67
Round  53, Train loss: 0.164, Test loss: 0.356, Test accuracy: 87.22
Round  54, Train loss: 0.242, Test loss: 0.339, Test accuracy: 87.85
Round  55, Train loss: 0.217, Test loss: 0.359, Test accuracy: 86.93
Round  56, Train loss: 0.238, Test loss: 0.337, Test accuracy: 87.95
Round  57, Train loss: 0.250, Test loss: 0.356, Test accuracy: 87.53
Round  58, Train loss: 0.181, Test loss: 0.356, Test accuracy: 87.60
Round  59, Train loss: 0.200, Test loss: 0.352, Test accuracy: 87.48
Round  60, Train loss: 0.146, Test loss: 0.365, Test accuracy: 87.38
Round  61, Train loss: 0.174, Test loss: 0.359, Test accuracy: 87.52
Round  62, Train loss: 0.171, Test loss: 0.336, Test accuracy: 88.25
Round  63, Train loss: 0.187, Test loss: 0.340, Test accuracy: 87.68
Round  64, Train loss: 0.144, Test loss: 0.346, Test accuracy: 88.03
Round  65, Train loss: 0.132, Test loss: 0.349, Test accuracy: 87.98
Round  66, Train loss: 0.174, Test loss: 0.328, Test accuracy: 89.12
Round  67, Train loss: 0.165, Test loss: 0.338, Test accuracy: 88.78
Round  68, Train loss: 0.140, Test loss: 0.358, Test accuracy: 87.95
Round  69, Train loss: 0.193, Test loss: 0.320, Test accuracy: 88.93
Round  70, Train loss: 0.209, Test loss: 0.317, Test accuracy: 88.70
Round  71, Train loss: 0.156, Test loss: 0.348, Test accuracy: 87.83
Round  72, Train loss: 0.124, Test loss: 0.347, Test accuracy: 88.43
Round  73, Train loss: 0.140, Test loss: 0.355, Test accuracy: 88.15
Round  74, Train loss: 0.139, Test loss: 0.350, Test accuracy: 88.08
Round  75, Train loss: 0.166, Test loss: 0.346, Test accuracy: 88.05
Round  76, Train loss: 0.108, Test loss: 0.380, Test accuracy: 87.90
Round  77, Train loss: 0.175, Test loss: 0.357, Test accuracy: 88.10
Round  78, Train loss: 0.137, Test loss: 0.358, Test accuracy: 88.20
Round  79, Train loss: 0.128, Test loss: 0.347, Test accuracy: 88.63
Round  80, Train loss: 0.129, Test loss: 0.319, Test accuracy: 89.40
Round  81, Train loss: 0.154, Test loss: 0.323, Test accuracy: 89.17
Round  82, Train loss: 0.133, Test loss: 0.351, Test accuracy: 88.93
Round  83, Train loss: 0.105, Test loss: 0.340, Test accuracy: 88.88
Round  84, Train loss: 0.136, Test loss: 0.331, Test accuracy: 88.92
Round  85, Train loss: 0.122, Test loss: 0.343, Test accuracy: 88.50
Round  86, Train loss: 0.136, Test loss: 0.331, Test accuracy: 89.33
Round  87, Train loss: 0.130, Test loss: 0.338, Test accuracy: 89.37
Round  88, Train loss: 0.134, Test loss: 0.338, Test accuracy: 89.33
Round  89, Train loss: 0.112, Test loss: 0.341, Test accuracy: 89.27
Round  90, Train loss: 0.095, Test loss: 0.352, Test accuracy: 89.22
Round  91, Train loss: 0.144, Test loss: 0.330, Test accuracy: 89.92
Round  92, Train loss: 0.111, Test loss: 0.354, Test accuracy: 89.13
Round  93, Train loss: 0.068, Test loss: 0.353, Test accuracy: 89.17
Round  94, Train loss: 0.120, Test loss: 0.347, Test accuracy: 89.33
Round  95, Train loss: 0.118, Test loss: 0.351, Test accuracy: 89.37
Round  96, Train loss: 0.073, Test loss: 0.374, Test accuracy: 88.45
Round  97, Train loss: 0.112, Test loss: 0.342, Test accuracy: 89.65
Round  98, Train loss: 0.099, Test loss: 0.342, Test accuracy: 89.35
Round  99, Train loss: 0.085, Test loss: 0.380, Test accuracy: 88.48
Final Round, Train loss: 0.100, Test loss: 0.377, Test accuracy: 89.02
Average accuracy final 10 rounds: 89.20666666666668 

827.2983283996582
[1.0194485187530518, 2.0388970375061035, 2.7482047080993652, 3.457512378692627, 4.159181594848633, 4.860850811004639, 5.564975738525391, 6.269100666046143, 7.002910137176514, 7.736719608306885, 8.458202600479126, 9.179685592651367, 9.93141484260559, 10.683144092559814, 11.42819881439209, 12.173253536224365, 12.889630556106567, 13.60600757598877, 14.309293508529663, 15.012579441070557, 15.710651874542236, 16.408724308013916, 17.115008115768433, 17.82129192352295, 18.512072324752808, 19.202852725982666, 19.905806064605713, 20.60875940322876, 21.326248168945312, 22.043736934661865, 22.75921130180359, 23.474685668945312, 24.195111751556396, 24.91553783416748, 25.672322750091553, 26.429107666015625, 27.146334409713745, 27.863561153411865, 28.57095718383789, 29.278353214263916, 29.984559059143066, 30.690764904022217, 31.3901424407959, 32.08951997756958, 32.78423261642456, 33.47894525527954, 34.168537616729736, 34.85812997817993, 35.576648473739624, 36.295166969299316, 37.03218150138855, 37.76919603347778, 38.48825740814209, 39.2073187828064, 39.929248571395874, 40.65117835998535, 41.3836464881897, 42.11611461639404, 42.82847237586975, 43.54083013534546, 44.233469009399414, 44.92610788345337, 45.62314057350159, 46.320173263549805, 47.01564407348633, 47.71111488342285, 48.40269947052002, 49.09428405761719, 49.79267334938049, 50.4910626411438, 51.21346044540405, 51.93585824966431, 52.6527681350708, 53.369678020477295, 54.097747802734375, 54.825817584991455, 55.5612518787384, 56.29668617248535, 57.00516629219055, 57.71364641189575, 58.402543783187866, 59.09144115447998, 59.781832456588745, 60.47222375869751, 61.172454833984375, 61.87268590927124, 62.5651216506958, 63.25755739212036, 63.97156548500061, 64.68557357788086, 65.43172526359558, 66.1778769493103, 66.90972971916199, 67.64158248901367, 68.37104916572571, 69.10051584243774, 69.8529920578003, 70.60546827316284, 71.31491374969482, 72.0243592262268, 72.71753931045532, 73.41071939468384, 74.10984230041504, 74.80896520614624, 75.50588512420654, 76.20280504226685, 76.88833785057068, 77.57387065887451, 78.28606271743774, 78.99825477600098, 79.73582220077515, 80.47338962554932, 81.19029784202576, 81.9072060585022, 82.62733912467957, 83.34747219085693, 84.07412052154541, 84.80076885223389, 85.52048087120056, 86.24019289016724, 86.94487857818604, 87.64956426620483, 88.34636235237122, 89.0431604385376, 89.74247097969055, 90.4417815208435, 91.13261127471924, 91.82344102859497, 92.52099967002869, 93.2185583114624, 93.93808603286743, 94.65761375427246, 95.37865018844604, 96.09968662261963, 96.81989312171936, 97.54009962081909, 98.26804447174072, 98.99598932266235, 99.71547794342041, 100.43496656417847, 101.1442003250122, 101.85343408584595, 102.54917669296265, 103.24491930007935, 103.94694876670837, 104.6489782333374, 105.34216499328613, 106.03535175323486, 106.73665022850037, 107.43794870376587, 108.16074395179749, 108.8835391998291, 109.62421798706055, 110.36489677429199, 111.10832381248474, 111.85175085067749, 112.59869074821472, 113.34563064575195, 114.07760667800903, 114.80958271026611, 115.51401376724243, 116.21844482421875, 116.9094398021698, 117.60043478012085, 118.30946898460388, 119.01850318908691, 119.72044229507446, 120.42238140106201, 121.11329340934753, 121.80420541763306, 122.52025532722473, 123.2363052368164, 123.9723162651062, 124.708327293396, 125.44127035140991, 126.17421340942383, 126.9037401676178, 127.63326692581177, 128.39303493499756, 129.15280294418335, 129.87570357322693, 130.5986042022705, 131.28837847709656, 131.9781527519226, 132.67295265197754, 133.36775255203247, 134.06387948989868, 134.7600064277649, 135.46047973632812, 136.16095304489136, 136.86958718299866, 137.57822132110596, 138.3242416381836, 139.07026195526123, 139.8055510520935, 140.54084014892578, 141.27366256713867, 142.00648498535156, 142.74368739128113, 143.4808897972107, 144.771790266037, 146.06269073486328]
[25.533333333333335, 25.533333333333335, 33.38333333333333, 33.38333333333333, 50.166666666666664, 50.166666666666664, 56.61666666666667, 56.61666666666667, 58.68333333333333, 58.68333333333333, 60.38333333333333, 60.38333333333333, 66.31666666666666, 66.31666666666666, 68.65, 68.65, 68.16666666666667, 68.16666666666667, 71.46666666666667, 71.46666666666667, 71.48333333333333, 71.48333333333333, 74.65, 74.65, 75.98333333333333, 75.98333333333333, 76.51666666666667, 76.51666666666667, 77.38333333333334, 77.38333333333334, 77.33333333333333, 77.33333333333333, 78.06666666666666, 78.06666666666666, 79.35, 79.35, 80.78333333333333, 80.78333333333333, 80.4, 80.4, 81.26666666666667, 81.26666666666667, 81.88333333333334, 81.88333333333334, 81.53333333333333, 81.53333333333333, 82.23333333333333, 82.23333333333333, 82.36666666666666, 82.36666666666666, 82.3, 82.3, 83.35, 83.35, 83.31666666666666, 83.31666666666666, 84.01666666666667, 84.01666666666667, 84.25, 84.25, 83.13333333333334, 83.13333333333334, 83.98333333333333, 83.98333333333333, 85.03333333333333, 85.03333333333333, 84.55, 84.55, 85.05, 85.05, 84.58333333333333, 84.58333333333333, 84.7, 84.7, 84.36666666666666, 84.36666666666666, 85.1, 85.1, 85.61666666666666, 85.61666666666666, 85.46666666666667, 85.46666666666667, 84.71666666666667, 84.71666666666667, 85.4, 85.4, 85.86666666666666, 85.86666666666666, 86.18333333333334, 86.18333333333334, 85.18333333333334, 85.18333333333334, 86.31666666666666, 86.31666666666666, 85.83333333333333, 85.83333333333333, 85.95, 85.95, 86.3, 86.3, 86.9, 86.9, 87.88333333333334, 87.88333333333334, 87.66666666666667, 87.66666666666667, 87.21666666666667, 87.21666666666667, 87.85, 87.85, 86.93333333333334, 86.93333333333334, 87.95, 87.95, 87.53333333333333, 87.53333333333333, 87.6, 87.6, 87.48333333333333, 87.48333333333333, 87.38333333333334, 87.38333333333334, 87.51666666666667, 87.51666666666667, 88.25, 88.25, 87.68333333333334, 87.68333333333334, 88.03333333333333, 88.03333333333333, 87.98333333333333, 87.98333333333333, 89.11666666666666, 89.11666666666666, 88.78333333333333, 88.78333333333333, 87.95, 87.95, 88.93333333333334, 88.93333333333334, 88.7, 88.7, 87.83333333333333, 87.83333333333333, 88.43333333333334, 88.43333333333334, 88.15, 88.15, 88.08333333333333, 88.08333333333333, 88.05, 88.05, 87.9, 87.9, 88.1, 88.1, 88.2, 88.2, 88.63333333333334, 88.63333333333334, 89.4, 89.4, 89.16666666666667, 89.16666666666667, 88.93333333333334, 88.93333333333334, 88.88333333333334, 88.88333333333334, 88.91666666666667, 88.91666666666667, 88.5, 88.5, 89.33333333333333, 89.33333333333333, 89.36666666666666, 89.36666666666666, 89.33333333333333, 89.33333333333333, 89.26666666666667, 89.26666666666667, 89.21666666666667, 89.21666666666667, 89.91666666666667, 89.91666666666667, 89.13333333333334, 89.13333333333334, 89.16666666666667, 89.16666666666667, 89.33333333333333, 89.33333333333333, 89.36666666666666, 89.36666666666666, 88.45, 88.45, 89.65, 89.65, 89.35, 89.35, 88.48333333333333, 88.48333333333333, 89.01666666666667, 89.01666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
lg
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 1063434 (local), 34186 (global); Percentage 3.21 (34186/1063434 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.232, Test loss: 1.990, Test accuracy: 35.83
Round   1, Train loss: 0.957, Test loss: 1.774, Test accuracy: 40.93
Round   2, Train loss: 0.942, Test loss: 1.828, Test accuracy: 42.30
Round   3, Train loss: 0.901, Test loss: 1.309, Test accuracy: 57.28
Round   4, Train loss: 0.887, Test loss: 1.213, Test accuracy: 59.73
Round   5, Train loss: 0.836, Test loss: 1.230, Test accuracy: 61.72
Round   6, Train loss: 0.779, Test loss: 1.051, Test accuracy: 65.60
Round   7, Train loss: 0.691, Test loss: 0.936, Test accuracy: 69.85
Round   8, Train loss: 0.744, Test loss: 0.946, Test accuracy: 69.82
Round   9, Train loss: 0.727, Test loss: 0.834, Test accuracy: 73.30
Round  10, Train loss: 0.557, Test loss: 0.867, Test accuracy: 72.13
Round  11, Train loss: 0.619, Test loss: 0.810, Test accuracy: 72.93
Round  12, Train loss: 0.619, Test loss: 0.741, Test accuracy: 75.17
Round  13, Train loss: 0.612, Test loss: 0.732, Test accuracy: 74.55
Round  14, Train loss: 0.498, Test loss: 0.733, Test accuracy: 75.22
Round  15, Train loss: 0.499, Test loss: 0.746, Test accuracy: 75.20
Round  16, Train loss: 0.505, Test loss: 0.721, Test accuracy: 75.35
Round  17, Train loss: 0.462, Test loss: 0.693, Test accuracy: 76.78
Round  18, Train loss: 0.520, Test loss: 0.628, Test accuracy: 79.22
Round  19, Train loss: 0.511, Test loss: 0.604, Test accuracy: 79.87
Round  20, Train loss: 0.391, Test loss: 0.576, Test accuracy: 80.75
Round  21, Train loss: 0.399, Test loss: 0.566, Test accuracy: 81.07
Round  22, Train loss: 0.454, Test loss: 0.626, Test accuracy: 79.65
Round  23, Train loss: 0.484, Test loss: 0.610, Test accuracy: 80.08
Round  24, Train loss: 0.373, Test loss: 0.595, Test accuracy: 80.10
Round  25, Train loss: 0.437, Test loss: 0.594, Test accuracy: 80.63
Round  26, Train loss: 0.419, Test loss: 0.580, Test accuracy: 81.62
Round  27, Train loss: 0.388, Test loss: 0.538, Test accuracy: 82.75
Round  28, Train loss: 0.360, Test loss: 0.560, Test accuracy: 82.40
Round  29, Train loss: 0.369, Test loss: 0.541, Test accuracy: 82.80
Round  30, Train loss: 0.354, Test loss: 0.546, Test accuracy: 82.60
Round  31, Train loss: 0.306, Test loss: 0.540, Test accuracy: 83.27
Round  32, Train loss: 0.328, Test loss: 0.557, Test accuracy: 83.20
Round  33, Train loss: 0.290, Test loss: 0.561, Test accuracy: 82.95
Round  34, Train loss: 0.277, Test loss: 0.577, Test accuracy: 82.83
Round  35, Train loss: 0.263, Test loss: 0.574, Test accuracy: 82.65
Round  36, Train loss: 0.290, Test loss: 0.599, Test accuracy: 82.22
Round  37, Train loss: 0.317, Test loss: 0.583, Test accuracy: 82.77
Round  38, Train loss: 0.258, Test loss: 0.591, Test accuracy: 82.65
Round  39, Train loss: 0.232, Test loss: 0.598, Test accuracy: 82.73
Round  40, Train loss: 0.207, Test loss: 0.584, Test accuracy: 83.32
Round  41, Train loss: 0.206, Test loss: 0.568, Test accuracy: 83.57
Round  42, Train loss: 0.261, Test loss: 0.572, Test accuracy: 83.92
Round  43, Train loss: 0.210, Test loss: 0.587, Test accuracy: 83.75
Round  44, Train loss: 0.233, Test loss: 0.593, Test accuracy: 83.88
Round  45, Train loss: 0.198, Test loss: 0.608, Test accuracy: 83.78
Round  46, Train loss: 0.162, Test loss: 0.627, Test accuracy: 83.58
Round  47, Train loss: 0.176, Test loss: 0.632, Test accuracy: 83.87
Round  48, Train loss: 0.195, Test loss: 0.640, Test accuracy: 83.53
Round  49, Train loss: 0.162, Test loss: 0.652, Test accuracy: 83.82
Round  50, Train loss: 0.161, Test loss: 0.661, Test accuracy: 83.68
Round  51, Train loss: 0.183, Test loss: 0.627, Test accuracy: 84.30
Round  52, Train loss: 0.130, Test loss: 0.629, Test accuracy: 84.63
Round  53, Train loss: 0.176, Test loss: 0.636, Test accuracy: 84.50
Round  54, Train loss: 0.185, Test loss: 0.646, Test accuracy: 84.27
Round  55, Train loss: 0.143, Test loss: 0.625, Test accuracy: 84.82
Round  56, Train loss: 0.167, Test loss: 0.645, Test accuracy: 84.57
Round  57, Train loss: 0.122, Test loss: 0.661, Test accuracy: 84.33
Round  58, Train loss: 0.131, Test loss: 0.654, Test accuracy: 84.65
Round  59, Train loss: 0.148, Test loss: 0.676, Test accuracy: 84.80
Round  60, Train loss: 0.129, Test loss: 0.681, Test accuracy: 84.78
Round  61, Train loss: 0.124, Test loss: 0.661, Test accuracy: 84.78
Round  62, Train loss: 0.167, Test loss: 0.651, Test accuracy: 84.60
Round  63, Train loss: 0.132, Test loss: 0.674, Test accuracy: 84.48
Round  64, Train loss: 0.132, Test loss: 0.673, Test accuracy: 83.95
Round  65, Train loss: 0.104, Test loss: 0.657, Test accuracy: 84.30
Round  66, Train loss: 0.101, Test loss: 0.677, Test accuracy: 84.43
Round  67, Train loss: 0.133, Test loss: 0.695, Test accuracy: 84.32
Round  68, Train loss: 0.101, Test loss: 0.683, Test accuracy: 84.70
Round  69, Train loss: 0.103, Test loss: 0.682, Test accuracy: 84.50
Round  70, Train loss: 0.095, Test loss: 0.684, Test accuracy: 84.65
Round  71, Train loss: 0.113, Test loss: 0.709, Test accuracy: 84.20
Round  72, Train loss: 0.107, Test loss: 0.693, Test accuracy: 84.68
Round  73, Train loss: 0.109, Test loss: 0.708, Test accuracy: 84.63
Round  74, Train loss: 0.076, Test loss: 0.726, Test accuracy: 84.67
Round  75, Train loss: 0.072, Test loss: 0.730, Test accuracy: 84.82
Round  76, Train loss: 0.098, Test loss: 0.810, Test accuracy: 83.70
Round  77, Train loss: 0.063, Test loss: 0.804, Test accuracy: 84.18
Round  78, Train loss: 0.083, Test loss: 0.776, Test accuracy: 84.70
Round  79, Train loss: 0.098, Test loss: 0.768, Test accuracy: 84.47
Round  80, Train loss: 0.078, Test loss: 0.746, Test accuracy: 84.63
Round  81, Train loss: 0.111, Test loss: 0.709, Test accuracy: 85.50
Round  82, Train loss: 0.094, Test loss: 0.728, Test accuracy: 85.48
Round  83, Train loss: 0.102, Test loss: 0.706, Test accuracy: 85.48
Round  84, Train loss: 0.078, Test loss: 0.697, Test accuracy: 85.43
Round  85, Train loss: 0.058, Test loss: 0.708, Test accuracy: 85.78
Round  86, Train loss: 0.073, Test loss: 0.733, Test accuracy: 85.68
Round  87, Train loss: 0.089, Test loss: 0.719, Test accuracy: 86.03
Round  88, Train loss: 0.079, Test loss: 0.719, Test accuracy: 85.85
Round  89, Train loss: 0.052, Test loss: 0.765, Test accuracy: 85.58
Round  90, Train loss: 0.049, Test loss: 0.765, Test accuracy: 85.63
Round  91, Train loss: 0.061, Test loss: 0.791, Test accuracy: 85.35
Round  92, Train loss: 0.075, Test loss: 0.798, Test accuracy: 85.43
Round  93, Train loss: 0.059, Test loss: 0.787, Test accuracy: 85.30
Round  94, Train loss: 0.049, Test loss: 0.785, Test accuracy: 85.47
Round  95, Train loss: 0.060, Test loss: 0.798, Test accuracy: 85.33
Round  96, Train loss: 0.059, Test loss: 0.777, Test accuracy: 85.43
Round  97, Train loss: 0.059, Test loss: 0.796, Test accuracy: 85.20
Round  98, Train loss: 0.065, Test loss: 0.800, Test accuracy: 85.05
Round  99, Train loss: 0.050, Test loss: 0.816, Test accuracy: 85.02
Final Round, Train loss: 0.050, Test loss: 0.789, Test accuracy: 85.45
Average accuracy final 10 rounds: 85.32166666666666 

837.7660486698151
[0.9989612102508545, 1.997922420501709, 2.738820791244507, 3.4797191619873047, 4.226689577102661, 4.973659992218018, 5.723635196685791, 6.4736104011535645, 7.2139201164245605, 7.954229831695557, 8.699545621871948, 9.44486141204834, 10.17401123046875, 10.90316104888916, 11.607916355133057, 12.312671661376953, 13.024627923965454, 13.736584186553955, 14.44602656364441, 15.155468940734863, 15.862551927566528, 16.569634914398193, 17.309423685073853, 18.04921245574951, 18.79889464378357, 19.548576831817627, 20.27395462989807, 20.999332427978516, 21.736809492111206, 22.474286556243896, 23.226449728012085, 23.978612899780273, 24.705479383468628, 25.432345867156982, 26.133864164352417, 26.83538246154785, 27.543587923049927, 28.251793384552002, 28.965898752212524, 29.680004119873047, 30.38939619064331, 31.098788261413574, 31.84980297088623, 32.60081768035889, 33.34604573249817, 34.09127378463745, 34.82339072227478, 35.55550765991211, 36.296027183532715, 37.03654670715332, 37.77177882194519, 38.50701093673706, 39.23519730567932, 39.96338367462158, 40.662805795669556, 41.36222791671753, 42.07652020454407, 42.790812492370605, 43.51199197769165, 44.233171463012695, 44.94973087310791, 45.666290283203125, 46.42599439620972, 47.18569850921631, 47.93346691131592, 48.68123531341553, 49.414535999298096, 50.147836685180664, 50.8836464881897, 51.61945629119873, 52.35703110694885, 53.094605922698975, 53.815343141555786, 54.5360803604126, 55.23549818992615, 55.9349160194397, 56.644352197647095, 57.35378837585449, 58.06206917762756, 58.770349979400635, 59.48382544517517, 60.19730091094971, 60.903613805770874, 61.60992670059204, 62.34460949897766, 63.07929229736328, 63.82267093658447, 64.56604957580566, 65.3123550415039, 66.05866050720215, 66.80306625366211, 67.54747200012207, 68.2692608833313, 68.99104976654053, 69.6944580078125, 70.39786624908447, 71.11247706413269, 71.82708787918091, 72.54305815696716, 73.25902843475342, 73.96658682823181, 74.6741452217102, 75.38215351104736, 76.09016180038452, 76.82975912094116, 77.5693564414978, 78.30107402801514, 79.03279161453247, 79.77823638916016, 80.52368116378784, 81.27319359779358, 82.02270603179932, 82.7956371307373, 83.5685682296753, 84.26882147789001, 84.96907472610474, 85.67771244049072, 86.38635015487671, 87.0979540348053, 87.80955791473389, 88.50302577018738, 89.19649362564087, 89.89089059829712, 90.58528757095337, 91.33761143684387, 92.08993530273438, 92.83306860923767, 93.57620191574097, 94.30122780799866, 95.02625370025635, 95.74985003471375, 96.47344636917114, 97.1969735622406, 97.92050075531006, 98.61774945259094, 99.31499814987183, 100.02741551399231, 100.7398328781128, 101.44491720199585, 102.1500015258789, 102.85640811920166, 103.56281471252441, 104.27482199668884, 104.98682928085327, 105.72696042060852, 106.46709156036377, 107.2038516998291, 107.94061183929443, 108.67842221260071, 109.41623258590698, 110.16265368461609, 110.9090747833252, 111.63479924201965, 112.36052370071411, 113.05578446388245, 113.75104522705078, 114.45963835716248, 115.16823148727417, 115.86610317230225, 116.56397485733032, 117.27198481559753, 117.97999477386475, 118.6824860572815, 119.38497734069824, 120.11962819099426, 120.85427904129028, 121.59033727645874, 122.3263955116272, 123.05566239356995, 123.7849292755127, 124.52965450286865, 125.27437973022461, 126.00087261199951, 126.72736549377441, 127.41717886924744, 128.10699224472046, 128.7981185913086, 129.48924493789673, 130.1942036151886, 130.89916229248047, 131.61550426483154, 132.33184623718262, 133.01793766021729, 133.70402908325195, 134.4610996246338, 135.21817016601562, 135.97240138053894, 136.72663259506226, 137.45992636680603, 138.1932201385498, 138.93403887748718, 139.67485761642456, 140.4098572731018, 141.14485692977905, 141.8542127609253, 142.56356859207153, 143.25898027420044, 143.95439195632935, 144.66650247573853, 145.3786129951477, 146.7784457206726, 148.1782784461975]
[35.833333333333336, 35.833333333333336, 40.93333333333333, 40.93333333333333, 42.3, 42.3, 57.28333333333333, 57.28333333333333, 59.733333333333334, 59.733333333333334, 61.71666666666667, 61.71666666666667, 65.6, 65.6, 69.85, 69.85, 69.81666666666666, 69.81666666666666, 73.3, 73.3, 72.13333333333334, 72.13333333333334, 72.93333333333334, 72.93333333333334, 75.16666666666667, 75.16666666666667, 74.55, 74.55, 75.21666666666667, 75.21666666666667, 75.2, 75.2, 75.35, 75.35, 76.78333333333333, 76.78333333333333, 79.21666666666667, 79.21666666666667, 79.86666666666666, 79.86666666666666, 80.75, 80.75, 81.06666666666666, 81.06666666666666, 79.65, 79.65, 80.08333333333333, 80.08333333333333, 80.1, 80.1, 80.63333333333334, 80.63333333333334, 81.61666666666666, 81.61666666666666, 82.75, 82.75, 82.4, 82.4, 82.8, 82.8, 82.6, 82.6, 83.26666666666667, 83.26666666666667, 83.2, 83.2, 82.95, 82.95, 82.83333333333333, 82.83333333333333, 82.65, 82.65, 82.21666666666667, 82.21666666666667, 82.76666666666667, 82.76666666666667, 82.65, 82.65, 82.73333333333333, 82.73333333333333, 83.31666666666666, 83.31666666666666, 83.56666666666666, 83.56666666666666, 83.91666666666667, 83.91666666666667, 83.75, 83.75, 83.88333333333334, 83.88333333333334, 83.78333333333333, 83.78333333333333, 83.58333333333333, 83.58333333333333, 83.86666666666666, 83.86666666666666, 83.53333333333333, 83.53333333333333, 83.81666666666666, 83.81666666666666, 83.68333333333334, 83.68333333333334, 84.3, 84.3, 84.63333333333334, 84.63333333333334, 84.5, 84.5, 84.26666666666667, 84.26666666666667, 84.81666666666666, 84.81666666666666, 84.56666666666666, 84.56666666666666, 84.33333333333333, 84.33333333333333, 84.65, 84.65, 84.8, 84.8, 84.78333333333333, 84.78333333333333, 84.78333333333333, 84.78333333333333, 84.6, 84.6, 84.48333333333333, 84.48333333333333, 83.95, 83.95, 84.3, 84.3, 84.43333333333334, 84.43333333333334, 84.31666666666666, 84.31666666666666, 84.7, 84.7, 84.5, 84.5, 84.65, 84.65, 84.2, 84.2, 84.68333333333334, 84.68333333333334, 84.63333333333334, 84.63333333333334, 84.66666666666667, 84.66666666666667, 84.81666666666666, 84.81666666666666, 83.7, 83.7, 84.18333333333334, 84.18333333333334, 84.7, 84.7, 84.46666666666667, 84.46666666666667, 84.63333333333334, 84.63333333333334, 85.5, 85.5, 85.48333333333333, 85.48333333333333, 85.48333333333333, 85.48333333333333, 85.43333333333334, 85.43333333333334, 85.78333333333333, 85.78333333333333, 85.68333333333334, 85.68333333333334, 86.03333333333333, 86.03333333333333, 85.85, 85.85, 85.58333333333333, 85.58333333333333, 85.63333333333334, 85.63333333333334, 85.35, 85.35, 85.43333333333334, 85.43333333333334, 85.3, 85.3, 85.46666666666667, 85.46666666666667, 85.33333333333333, 85.33333333333333, 85.43333333333334, 85.43333333333334, 85.2, 85.2, 85.05, 85.05, 85.01666666666667, 85.01666666666667, 85.45, 85.45]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
Round   0, Train loss: 0.818, Test loss: 2.272, Test accuracy: 28.97
Round   1, Train loss: 0.741, Test loss: 2.274, Test accuracy: 41.38
Round   2, Train loss: 0.679, Test loss: 2.036, Test accuracy: 51.37
Round   3, Train loss: 0.607, Test loss: 2.024, Test accuracy: 54.97
Round   4, Train loss: 0.593, Test loss: 1.973, Test accuracy: 55.57
Round   5, Train loss: 0.513, Test loss: 1.966, Test accuracy: 58.12
Round   6, Train loss: 0.502, Test loss: 1.870, Test accuracy: 60.02
Round   7, Train loss: 0.442, Test loss: 1.821, Test accuracy: 61.72
Round   8, Train loss: 0.456, Test loss: 1.844, Test accuracy: 61.50
Round   9, Train loss: 0.367, Test loss: 1.807, Test accuracy: 64.12
Round  10, Train loss: 0.405, Test loss: 1.793, Test accuracy: 64.07
Round  11, Train loss: 0.403, Test loss: 1.677, Test accuracy: 65.80
Round  12, Train loss: 0.365, Test loss: 1.718, Test accuracy: 67.10
Round  13, Train loss: 0.370, Test loss: 1.660, Test accuracy: 65.35
Round  14, Train loss: 0.349, Test loss: 1.675, Test accuracy: 66.32
Round  15, Train loss: 0.415, Test loss: 1.617, Test accuracy: 67.52
Round  16, Train loss: 0.317, Test loss: 1.590, Test accuracy: 66.00
Round  17, Train loss: 0.331, Test loss: 1.580, Test accuracy: 66.62
Round  18, Train loss: 0.333, Test loss: 1.550, Test accuracy: 67.23
Round  19, Train loss: 0.306, Test loss: 1.525, Test accuracy: 67.78
Round  20, Train loss: 0.291, Test loss: 1.496, Test accuracy: 67.37
Round  21, Train loss: 0.272, Test loss: 1.466, Test accuracy: 68.62
Round  22, Train loss: 0.228, Test loss: 1.447, Test accuracy: 67.45
Round  23, Train loss: 0.288, Test loss: 1.431, Test accuracy: 68.67
Round  24, Train loss: 0.219, Test loss: 1.389, Test accuracy: 69.70
Round  25, Train loss: 0.235, Test loss: 1.361, Test accuracy: 68.90
Round  26, Train loss: 0.222, Test loss: 1.348, Test accuracy: 71.07
Round  27, Train loss: 0.167, Test loss: 1.306, Test accuracy: 72.32
Round  28, Train loss: 0.196, Test loss: 1.279, Test accuracy: 71.97
Round  29, Train loss: 0.175, Test loss: 1.265, Test accuracy: 72.62
Round  30, Train loss: 0.217, Test loss: 1.230, Test accuracy: 73.83
Round  31, Train loss: 0.176, Test loss: 1.208, Test accuracy: 74.65
Round  32, Train loss: 0.170, Test loss: 1.200, Test accuracy: 73.83
Round  33, Train loss: 0.187, Test loss: 1.196, Test accuracy: 75.02
Round  34, Train loss: 0.200, Test loss: 1.173, Test accuracy: 75.72
Round  35, Train loss: 0.161, Test loss: 1.155, Test accuracy: 74.28
Round  36, Train loss: 0.157, Test loss: 1.142, Test accuracy: 75.07
Round  37, Train loss: 0.153, Test loss: 1.137, Test accuracy: 73.90
Round  38, Train loss: 0.157, Test loss: 1.103, Test accuracy: 75.15
Round  39, Train loss: 0.119, Test loss: 1.078, Test accuracy: 75.83
Round  40, Train loss: 0.156, Test loss: 1.068, Test accuracy: 74.68
Round  41, Train loss: 0.135, Test loss: 1.044, Test accuracy: 76.83
Round  42, Train loss: 0.124, Test loss: 1.022, Test accuracy: 77.40
Round  43, Train loss: 0.139, Test loss: 1.006, Test accuracy: 77.27
Round  44, Train loss: 0.130, Test loss: 1.000, Test accuracy: 77.63
Round  45, Train loss: 0.107, Test loss: 1.002, Test accuracy: 76.95
Round  46, Train loss: 0.110, Test loss: 1.000, Test accuracy: 76.80
Round  47, Train loss: 0.125, Test loss: 0.976, Test accuracy: 78.33
Round  48, Train loss: 0.100, Test loss: 0.955, Test accuracy: 77.35
Round  49, Train loss: 0.093, Test loss: 0.938, Test accuracy: 77.25
Round  50, Train loss: 0.113, Test loss: 0.943, Test accuracy: 77.78
Round  51, Train loss: 0.097, Test loss: 0.927, Test accuracy: 77.60
Round  52, Train loss: 0.099, Test loss: 0.916, Test accuracy: 77.35
Round  53, Train loss: 0.100, Test loss: 0.901, Test accuracy: 77.40
Round  54, Train loss: 0.089, Test loss: 0.889, Test accuracy: 77.40
Round  55, Train loss: 0.081, Test loss: 0.859, Test accuracy: 78.23
Round  56, Train loss: 0.095, Test loss: 0.862, Test accuracy: 78.10
Round  57, Train loss: 0.090, Test loss: 0.844, Test accuracy: 77.38
Round  58, Train loss: 0.087, Test loss: 0.832, Test accuracy: 77.43
Round  59, Train loss: 0.093, Test loss: 0.833, Test accuracy: 77.83
Round  60, Train loss: 0.065, Test loss: 0.805, Test accuracy: 78.32
Round  61, Train loss: 0.076, Test loss: 0.789, Test accuracy: 79.83
Round  62, Train loss: 0.071, Test loss: 0.778, Test accuracy: 79.93
Round  63, Train loss: 0.097, Test loss: 0.789, Test accuracy: 79.25
Round  64, Train loss: 0.060, Test loss: 0.775, Test accuracy: 80.02
Round  65, Train loss: 0.066, Test loss: 0.775, Test accuracy: 80.17
Round  66, Train loss: 0.078, Test loss: 0.784, Test accuracy: 79.78
Round  67, Train loss: 0.100, Test loss: 0.779, Test accuracy: 79.17
Round  68, Train loss: 0.058, Test loss: 0.779, Test accuracy: 78.23
Round  69, Train loss: 0.049, Test loss: 0.761, Test accuracy: 78.10
Round  70, Train loss: 0.047, Test loss: 0.747, Test accuracy: 78.90
Round  71, Train loss: 0.079, Test loss: 0.741, Test accuracy: 79.52
Round  72, Train loss: 0.053, Test loss: 0.739, Test accuracy: 80.20
Round  73, Train loss: 0.069, Test loss: 0.734, Test accuracy: 80.10
Round  74, Train loss: 0.048, Test loss: 0.719, Test accuracy: 80.32
Round  75, Train loss: 0.067, Test loss: 0.736, Test accuracy: 79.37
Round  76, Train loss: 0.046, Test loss: 0.724, Test accuracy: 78.87
Round  77, Train loss: 0.058, Test loss: 0.710, Test accuracy: 79.32
Round  78, Train loss: 0.055, Test loss: 0.711, Test accuracy: 79.52
Round  79, Train loss: 0.059, Test loss: 0.711, Test accuracy: 79.38
Round  80, Train loss: 0.054, Test loss: 0.698, Test accuracy: 79.83
Round  81, Train loss: 0.053, Test loss: 0.691, Test accuracy: 79.72
Round  82, Train loss: 0.068, Test loss: 0.680, Test accuracy: 79.72
Round  83, Train loss: 0.065, Test loss: 0.677, Test accuracy: 79.92
Round  84, Train loss: 0.045, Test loss: 0.674, Test accuracy: 80.55
Round  85, Train loss: 0.044, Test loss: 0.667, Test accuracy: 81.37
Round  86, Train loss: 0.055, Test loss: 0.673, Test accuracy: 80.73
Round  87, Train loss: 0.066, Test loss: 0.677, Test accuracy: 81.22
Round  88, Train loss: 0.051, Test loss: 0.679, Test accuracy: 80.60
Round  89, Train loss: 0.070, Test loss: 0.694, Test accuracy: 79.67
Round  90, Train loss: 0.043, Test loss: 0.686, Test accuracy: 79.60
Round  91, Train loss: 0.035, Test loss: 0.670, Test accuracy: 80.15
Round  92, Train loss: 0.061, Test loss: 0.673, Test accuracy: 79.50
Round  93, Train loss: 0.038, Test loss: 0.658, Test accuracy: 79.73
Round  94, Train loss: 0.036, Test loss: 0.655, Test accuracy: 78.97
Round  95, Train loss: 0.039, Test loss: 0.658, Test accuracy: 78.57
Round  96, Train loss: 0.036, Test loss: 0.652, Test accuracy: 78.63
Round  97, Train loss: 0.051, Test loss: 0.661, Test accuracy: 77.82
Round  98, Train loss: 0.058, Test loss: 0.672, Test accuracy: 78.20
Round  99, Train loss: 0.035, Test loss: 0.653, Test accuracy: 78.60
Final Round, Train loss: 0.048, Test loss: 0.655, Test accuracy: 78.72
Average accuracy final 10 rounds: 78.97666666666667
1019.383686542511
[]
[28.966666666666665, 41.38333333333333, 51.36666666666667, 54.96666666666667, 55.56666666666667, 58.11666666666667, 60.016666666666666, 61.71666666666667, 61.5, 64.11666666666666, 64.06666666666666, 65.8, 67.1, 65.35, 66.31666666666666, 67.51666666666667, 66.0, 66.61666666666666, 67.23333333333333, 67.78333333333333, 67.36666666666666, 68.61666666666666, 67.45, 68.66666666666667, 69.7, 68.9, 71.06666666666666, 72.31666666666666, 71.96666666666667, 72.61666666666666, 73.83333333333333, 74.65, 73.83333333333333, 75.01666666666667, 75.71666666666667, 74.28333333333333, 75.06666666666666, 73.9, 75.15, 75.83333333333333, 74.68333333333334, 76.83333333333333, 77.4, 77.26666666666667, 77.63333333333334, 76.95, 76.8, 78.33333333333333, 77.35, 77.25, 77.78333333333333, 77.6, 77.35, 77.4, 77.4, 78.23333333333333, 78.1, 77.38333333333334, 77.43333333333334, 77.83333333333333, 78.31666666666666, 79.83333333333333, 79.93333333333334, 79.25, 80.01666666666667, 80.16666666666667, 79.78333333333333, 79.16666666666667, 78.23333333333333, 78.1, 78.9, 79.51666666666667, 80.2, 80.1, 80.31666666666666, 79.36666666666666, 78.86666666666666, 79.31666666666666, 79.51666666666667, 79.38333333333334, 79.83333333333333, 79.71666666666667, 79.71666666666667, 79.91666666666667, 80.55, 81.36666666666666, 80.73333333333333, 81.21666666666667, 80.6, 79.66666666666667, 79.6, 80.15, 79.5, 79.73333333333333, 78.96666666666667, 78.56666666666666, 78.63333333333334, 77.81666666666666, 78.2, 78.6, 78.71666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
Round   0, Train loss: 1.242, Test loss: 1.864, Test accuracy: 23.48
Round   1, Train loss: 1.106, Test loss: 1.564, Test accuracy: 41.57
Round   2, Train loss: 1.017, Test loss: 1.334, Test accuracy: 49.27
Round   3, Train loss: 0.930, Test loss: 1.151, Test accuracy: 53.90
Round   4, Train loss: 0.865, Test loss: 1.108, Test accuracy: 53.42
Round   5, Train loss: -0.154, Test loss: 0.977, Test accuracy: 59.93
Round   6, Train loss: 0.256, Test loss: 0.993, Test accuracy: 59.12
Round   7, Train loss: -0.526, Test loss: 0.884, Test accuracy: 63.00
Round   8, Train loss: -0.281, Test loss: 0.875, Test accuracy: 64.25
Round   9, Train loss: -0.570, Test loss: 0.842, Test accuracy: 65.73
Round  10, Train loss: -0.691, Test loss: 0.747, Test accuracy: 67.58
Round  11, Train loss: -1.792, Test loss: 0.727, Test accuracy: 68.65
Round  12, Train loss: -0.938, Test loss: 0.724, Test accuracy: 69.23
Round  13, Train loss: -1.235, Test loss: 0.703, Test accuracy: 70.60
Round  14, Train loss: -1.003, Test loss: 0.720, Test accuracy: 69.50
Round  15, Train loss: -1.344, Test loss: 0.715, Test accuracy: 69.78
Round  16, Train loss: -1.930, Test loss: 0.689, Test accuracy: 71.75
Round  17, Train loss: -2.274, Test loss: 0.695, Test accuracy: 71.65
Round  18, Train loss: -2.309, Test loss: 0.710, Test accuracy: 70.77
Round  19, Train loss: -1.845, Test loss: 0.696, Test accuracy: 70.97
Round  20, Train loss: -2.056, Test loss: 0.693, Test accuracy: 70.68
Round  21, Train loss: -1.811, Test loss: 0.687, Test accuracy: 70.72
Round  22, Train loss: -2.847, Test loss: 0.664, Test accuracy: 71.98
Round  23, Train loss: -2.771, Test loss: 0.647, Test accuracy: 73.03
Round  24, Train loss: -2.702, Test loss: 0.644, Test accuracy: 73.15
Round  25, Train loss: -3.482, Test loss: 0.657, Test accuracy: 72.42
Round  26, Train loss: -2.824, Test loss: 0.666, Test accuracy: 73.28
Round  27, Train loss: -3.679, Test loss: 0.649, Test accuracy: 74.67
Round  28, Train loss: -3.939, Test loss: 0.614, Test accuracy: 76.33
Round  29, Train loss: -3.726, Test loss: 0.615, Test accuracy: 75.92
Round  30, Train loss: -4.404, Test loss: 0.619, Test accuracy: 75.90
Round  31, Train loss: -3.763, Test loss: 0.623, Test accuracy: 76.38
Round  32, Train loss: -3.303, Test loss: 0.618, Test accuracy: 76.00
Round  33, Train loss: -3.167, Test loss: 0.630, Test accuracy: 75.58
Round  34, Train loss: -4.222, Test loss: 0.620, Test accuracy: 76.33
Round  35, Train loss: -3.617, Test loss: 0.610, Test accuracy: 77.17
Round  36, Train loss: -4.196, Test loss: 0.590, Test accuracy: 77.72
Round  37, Train loss: -4.246, Test loss: 0.582, Test accuracy: 77.48
Round  38, Train loss: -3.489, Test loss: 0.596, Test accuracy: 76.87
Round  39, Train loss: -3.938, Test loss: 0.577, Test accuracy: 78.15
Round  40, Train loss: -4.415, Test loss: 0.585, Test accuracy: 78.12
Round  41, Train loss: -4.757, Test loss: 0.571, Test accuracy: 78.35
Round  42, Train loss: -3.766, Test loss: 0.551, Test accuracy: 79.23
Round  43, Train loss: -4.824, Test loss: 0.557, Test accuracy: 79.20
Round  44, Train loss: -4.442, Test loss: 0.569, Test accuracy: 78.58
Round  45, Train loss: -4.312, Test loss: 0.570, Test accuracy: 78.38
Round  46, Train loss: -4.548, Test loss: 0.588, Test accuracy: 77.73
Round  47, Train loss: -3.919, Test loss: 0.594, Test accuracy: 77.43
Round  48, Train loss: -4.612, Test loss: 0.584, Test accuracy: 77.70
Round  49, Train loss: -5.005, Test loss: 0.608, Test accuracy: 77.32
Round  50, Train loss: -4.294, Test loss: 0.608, Test accuracy: 77.10
Round  51, Train loss: -4.858, Test loss: 0.570, Test accuracy: 78.43
Round  52, Train loss: -4.335, Test loss: 0.572, Test accuracy: 78.05
Round  53, Train loss: -5.262, Test loss: 0.577, Test accuracy: 78.20
Round  54, Train loss: -5.062, Test loss: 0.583, Test accuracy: 78.07
Round  55, Train loss: -4.911, Test loss: 0.571, Test accuracy: 78.77
Round  56, Train loss: -4.586, Test loss: 0.566, Test accuracy: 78.78
Round  57, Train loss: -4.690, Test loss: 0.564, Test accuracy: 79.33
Round  58, Train loss: -4.818, Test loss: 0.548, Test accuracy: 79.93
Round  59, Train loss: -5.131, Test loss: 0.549, Test accuracy: 80.15
Round  60, Train loss: -4.694, Test loss: 0.544, Test accuracy: 80.20
Round  61, Train loss: -5.225, Test loss: 0.570, Test accuracy: 79.02
Round  62, Train loss: -4.633, Test loss: 0.562, Test accuracy: 79.57
Round  63, Train loss: -5.161, Test loss: 0.553, Test accuracy: 80.65
Round  64, Train loss: -5.037, Test loss: 0.550, Test accuracy: 81.02
Round  65, Train loss: -4.998, Test loss: 0.543, Test accuracy: 80.93
Round  66, Train loss: -4.975, Test loss: 0.542, Test accuracy: 80.88
Round  67, Train loss: -5.601, Test loss: 0.558, Test accuracy: 80.18
Round  68, Train loss: -4.873, Test loss: 0.567, Test accuracy: 80.10
Round  69, Train loss: -5.338, Test loss: 0.546, Test accuracy: 80.15
Round  70, Train loss: -5.090, Test loss: 0.554, Test accuracy: 80.33
Round  71, Train loss: -5.268, Test loss: 0.553, Test accuracy: 79.83
Round  72, Train loss: -5.798, Test loss: 0.585, Test accuracy: 79.43
Round  73, Train loss: -6.053, Test loss: 0.599, Test accuracy: 79.33
Round  74, Train loss: -4.809, Test loss: 0.575, Test accuracy: 79.37
Round  75, Train loss: -4.423, Test loss: 0.572, Test accuracy: 79.57
Round  76, Train loss: -5.185, Test loss: 0.589, Test accuracy: 79.65
Round  77, Train loss: -5.271, Test loss: 0.596, Test accuracy: 79.72
Round  78, Train loss: -4.692, Test loss: 0.574, Test accuracy: 79.88
Round  79, Train loss: -5.474, Test loss: 0.561, Test accuracy: 80.53
Round  80, Train loss: -4.929, Test loss: 0.550, Test accuracy: 80.48
Round  81, Train loss: -5.241, Test loss: 0.586, Test accuracy: 79.93
Round  82, Train loss: -4.545, Test loss: 0.578, Test accuracy: 79.90
Round  83, Train loss: -4.997, Test loss: 0.574, Test accuracy: 79.90
Round  84, Train loss: -5.101, Test loss: 0.561, Test accuracy: 80.75
Round  85, Train loss: -4.780, Test loss: 0.571, Test accuracy: 80.22
Round  86, Train loss: -5.693, Test loss: 0.577, Test accuracy: 80.60
Round  87, Train loss: -4.937, Test loss: 0.588, Test accuracy: 80.18
Round  88, Train loss: -4.993, Test loss: 0.616, Test accuracy: 80.27
Round  89, Train loss: -5.188, Test loss: 0.599, Test accuracy: 80.60
Round  90, Train loss: -5.335, Test loss: 0.580, Test accuracy: 81.08
Round  91, Train loss: -5.433, Test loss: 0.564, Test accuracy: 81.32
Round  92, Train loss: -4.942, Test loss: 0.570, Test accuracy: 81.10
Round  93, Train loss: -5.084, Test loss: 0.542, Test accuracy: 81.05
Round  94, Train loss: -5.765, Test loss: 0.573, Test accuracy: 81.02
Round  95, Train loss: -5.022, Test loss: 0.539, Test accuracy: 81.77
Round  96, Train loss: -5.061, Test loss: 0.538, Test accuracy: 81.92
Round  97, Train loss: -5.400, Test loss: 0.541, Test accuracy: 82.28
Round  98, Train loss: -4.556, Test loss: 0.549, Test accuracy: 82.08
Round  99, Train loss: -4.564, Test loss: 0.563, Test accuracy: 81.60
Final Round, Train loss: 0.609, Test loss: 0.505, Test accuracy: 80.98
Average accuracy final 10 rounds: 81.52166666666666
Average global accuracy final 10 rounds: 81.52166666666666
745.5234839916229
[]
[23.483333333333334, 41.56666666666667, 49.266666666666666, 53.9, 53.416666666666664, 59.93333333333333, 59.11666666666667, 63.0, 64.25, 65.73333333333333, 67.58333333333333, 68.65, 69.23333333333333, 70.6, 69.5, 69.78333333333333, 71.75, 71.65, 70.76666666666667, 70.96666666666667, 70.68333333333334, 70.71666666666667, 71.98333333333333, 73.03333333333333, 73.15, 72.41666666666667, 73.28333333333333, 74.66666666666667, 76.33333333333333, 75.91666666666667, 75.9, 76.38333333333334, 76.0, 75.58333333333333, 76.33333333333333, 77.16666666666667, 77.71666666666667, 77.48333333333333, 76.86666666666666, 78.15, 78.11666666666666, 78.35, 79.23333333333333, 79.2, 78.58333333333333, 78.38333333333334, 77.73333333333333, 77.43333333333334, 77.7, 77.31666666666666, 77.1, 78.43333333333334, 78.05, 78.2, 78.06666666666666, 78.76666666666667, 78.78333333333333, 79.33333333333333, 79.93333333333334, 80.15, 80.2, 79.01666666666667, 79.56666666666666, 80.65, 81.01666666666667, 80.93333333333334, 80.88333333333334, 80.18333333333334, 80.1, 80.15, 80.33333333333333, 79.83333333333333, 79.43333333333334, 79.33333333333333, 79.36666666666666, 79.56666666666666, 79.65, 79.71666666666667, 79.88333333333334, 80.53333333333333, 80.48333333333333, 79.93333333333334, 79.9, 79.9, 80.75, 80.21666666666667, 80.6, 80.18333333333334, 80.26666666666667, 80.6, 81.08333333333333, 81.31666666666666, 81.1, 81.05, 81.01666666666667, 81.76666666666667, 81.91666666666667, 82.28333333333333, 82.08333333333333, 81.6, 80.98333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
prox
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.291, Test loss: 1.875, Test accuracy: 35.12
Round   0, Global train loss: 1.291, Global test loss: 2.191, Global test accuracy: 27.40
Round   1, Train loss: 1.043, Test loss: 2.049, Test accuracy: 38.40
Round   1, Global train loss: 1.043, Global test loss: 2.551, Global test accuracy: 26.60
Round   2, Train loss: 1.059, Test loss: 1.144, Test accuracy: 54.65
Round   2, Global train loss: 1.059, Global test loss: 1.911, Global test accuracy: 35.90
Round   3, Train loss: 0.889, Test loss: 1.165, Test accuracy: 59.10
Round   3, Global train loss: 0.889, Global test loss: 2.166, Global test accuracy: 34.03
Round   4, Train loss: 0.958, Test loss: 0.806, Test accuracy: 67.62
Round   4, Global train loss: 0.958, Global test loss: 1.802, Global test accuracy: 43.17
Round   5, Train loss: 0.871, Test loss: 0.796, Test accuracy: 67.93
Round   5, Global train loss: 0.871, Global test loss: 1.740, Global test accuracy: 40.83
Round   6, Train loss: 0.861, Test loss: 0.773, Test accuracy: 68.20
Round   6, Global train loss: 0.861, Global test loss: 1.822, Global test accuracy: 35.27
Round   7, Train loss: 0.831, Test loss: 0.772, Test accuracy: 70.00
Round   7, Global train loss: 0.831, Global test loss: 1.762, Global test accuracy: 44.10
Round   8, Train loss: 0.708, Test loss: 0.747, Test accuracy: 71.60
Round   8, Global train loss: 0.708, Global test loss: 1.911, Global test accuracy: 44.03
Round   9, Train loss: 0.793, Test loss: 0.728, Test accuracy: 72.60
Round   9, Global train loss: 0.793, Global test loss: 1.785, Global test accuracy: 44.55
Round  10, Train loss: 0.745, Test loss: 0.673, Test accuracy: 73.82
Round  10, Global train loss: 0.745, Global test loss: 1.548, Global test accuracy: 46.02
Round  11, Train loss: 0.706, Test loss: 0.699, Test accuracy: 72.97
Round  11, Global train loss: 0.706, Global test loss: 1.526, Global test accuracy: 46.62
Round  12, Train loss: 0.690, Test loss: 0.685, Test accuracy: 74.38
Round  12, Global train loss: 0.690, Global test loss: 1.545, Global test accuracy: 51.40
Round  13, Train loss: 0.717, Test loss: 0.649, Test accuracy: 75.62
Round  13, Global train loss: 0.717, Global test loss: 1.384, Global test accuracy: 55.18
Round  14, Train loss: 0.558, Test loss: 0.658, Test accuracy: 76.17
Round  14, Global train loss: 0.558, Global test loss: 1.582, Global test accuracy: 51.70
Round  15, Train loss: 0.664, Test loss: 0.646, Test accuracy: 76.28
Round  15, Global train loss: 0.664, Global test loss: 1.487, Global test accuracy: 50.93
Round  16, Train loss: 0.620, Test loss: 0.632, Test accuracy: 76.52
Round  16, Global train loss: 0.620, Global test loss: 1.458, Global test accuracy: 52.53
Round  17, Train loss: 0.679, Test loss: 0.620, Test accuracy: 77.10
Round  17, Global train loss: 0.679, Global test loss: 1.489, Global test accuracy: 52.95
Round  18, Train loss: 0.535, Test loss: 0.569, Test accuracy: 78.83
Round  18, Global train loss: 0.535, Global test loss: 1.437, Global test accuracy: 54.37
Round  19, Train loss: 0.527, Test loss: 0.561, Test accuracy: 79.37
Round  19, Global train loss: 0.527, Global test loss: 1.299, Global test accuracy: 58.48
Round  20, Train loss: 0.559, Test loss: 0.561, Test accuracy: 80.30
Round  20, Global train loss: 0.559, Global test loss: 1.371, Global test accuracy: 58.55
Round  21, Train loss: 0.546, Test loss: 0.537, Test accuracy: 80.80
Round  21, Global train loss: 0.546, Global test loss: 1.267, Global test accuracy: 58.08
Round  22, Train loss: 0.466, Test loss: 0.590, Test accuracy: 79.87
Round  22, Global train loss: 0.466, Global test loss: 1.555, Global test accuracy: 53.50
Round  23, Train loss: 0.576, Test loss: 0.508, Test accuracy: 81.62
Round  23, Global train loss: 0.576, Global test loss: 1.548, Global test accuracy: 51.40
Round  24, Train loss: 0.462, Test loss: 0.494, Test accuracy: 82.07
Round  24, Global train loss: 0.462, Global test loss: 1.379, Global test accuracy: 57.35
Round  25, Train loss: 0.544, Test loss: 0.480, Test accuracy: 82.38
Round  25, Global train loss: 0.544, Global test loss: 1.397, Global test accuracy: 52.92
Round  26, Train loss: 0.452, Test loss: 0.511, Test accuracy: 81.32
Round  26, Global train loss: 0.452, Global test loss: 1.283, Global test accuracy: 57.65
Round  27, Train loss: 0.434, Test loss: 0.523, Test accuracy: 81.53
Round  27, Global train loss: 0.434, Global test loss: 1.398, Global test accuracy: 57.32
Round  28, Train loss: 0.372, Test loss: 0.529, Test accuracy: 81.72
Round  28, Global train loss: 0.372, Global test loss: 1.380, Global test accuracy: 58.47
Round  29, Train loss: 0.492, Test loss: 0.513, Test accuracy: 82.02
Round  29, Global train loss: 0.492, Global test loss: 1.139, Global test accuracy: 64.42
Round  30, Train loss: 0.495, Test loss: 0.507, Test accuracy: 82.43
Round  30, Global train loss: 0.495, Global test loss: 1.189, Global test accuracy: 60.53
Round  31, Train loss: 0.509, Test loss: 0.522, Test accuracy: 82.53
Round  31, Global train loss: 0.509, Global test loss: 1.107, Global test accuracy: 62.67
Round  32, Train loss: 0.370, Test loss: 0.506, Test accuracy: 82.55
Round  32, Global train loss: 0.370, Global test loss: 1.172, Global test accuracy: 61.92
Round  33, Train loss: 0.479, Test loss: 0.485, Test accuracy: 83.65
Round  33, Global train loss: 0.479, Global test loss: 1.142, Global test accuracy: 65.18
Round  34, Train loss: 0.394, Test loss: 0.492, Test accuracy: 83.45
Round  34, Global train loss: 0.394, Global test loss: 1.109, Global test accuracy: 63.92
Round  35, Train loss: 0.415, Test loss: 0.433, Test accuracy: 84.87
Round  35, Global train loss: 0.415, Global test loss: 1.131, Global test accuracy: 63.98
Round  36, Train loss: 0.403, Test loss: 0.420, Test accuracy: 85.42
Round  36, Global train loss: 0.403, Global test loss: 1.085, Global test accuracy: 65.15
Round  37, Train loss: 0.450, Test loss: 0.424, Test accuracy: 85.33
Round  37, Global train loss: 0.450, Global test loss: 1.092, Global test accuracy: 64.33
Round  38, Train loss: 0.369, Test loss: 0.426, Test accuracy: 85.47
Round  38, Global train loss: 0.369, Global test loss: 1.027, Global test accuracy: 66.18
Round  39, Train loss: 0.369, Test loss: 0.438, Test accuracy: 85.27
Round  39, Global train loss: 0.369, Global test loss: 1.119, Global test accuracy: 65.78
Round  40, Train loss: 0.346, Test loss: 0.414, Test accuracy: 85.97
Round  40, Global train loss: 0.346, Global test loss: 1.162, Global test accuracy: 64.78
Round  41, Train loss: 0.401, Test loss: 0.418, Test accuracy: 85.75
Round  41, Global train loss: 0.401, Global test loss: 1.044, Global test accuracy: 65.72
Round  42, Train loss: 0.340, Test loss: 0.427, Test accuracy: 86.00
Round  42, Global train loss: 0.340, Global test loss: 1.024, Global test accuracy: 67.40
Round  43, Train loss: 0.307, Test loss: 0.415, Test accuracy: 86.45
Round  43, Global train loss: 0.307, Global test loss: 1.176, Global test accuracy: 63.70
Round  44, Train loss: 0.282, Test loss: 0.420, Test accuracy: 85.90
Round  44, Global train loss: 0.282, Global test loss: 1.139, Global test accuracy: 65.32
Round  45, Train loss: 0.352, Test loss: 0.419, Test accuracy: 86.32
Round  45, Global train loss: 0.352, Global test loss: 1.055, Global test accuracy: 65.55
Round  46, Train loss: 0.432, Test loss: 0.402, Test accuracy: 86.82
Round  46, Global train loss: 0.432, Global test loss: 1.068, Global test accuracy: 63.52
Round  47, Train loss: 0.361, Test loss: 0.386, Test accuracy: 87.05
Round  47, Global train loss: 0.361, Global test loss: 1.315, Global test accuracy: 59.67
Round  48, Train loss: 0.275, Test loss: 0.400, Test accuracy: 86.48
Round  48, Global train loss: 0.275, Global test loss: 1.241, Global test accuracy: 62.88
Round  49, Train loss: 0.354, Test loss: 0.382, Test accuracy: 86.87
Round  49, Global train loss: 0.354, Global test loss: 0.999, Global test accuracy: 66.03
Round  50, Train loss: 0.257, Test loss: 0.379, Test accuracy: 87.07
Round  50, Global train loss: 0.257, Global test loss: 1.059, Global test accuracy: 68.25
Round  51, Train loss: 0.333, Test loss: 0.394, Test accuracy: 87.12
Round  51, Global train loss: 0.333, Global test loss: 1.340, Global test accuracy: 59.33
Round  52, Train loss: 0.312, Test loss: 0.401, Test accuracy: 86.67
Round  52, Global train loss: 0.312, Global test loss: 1.000, Global test accuracy: 67.65
Round  53, Train loss: 0.325, Test loss: 0.390, Test accuracy: 87.12
Round  53, Global train loss: 0.325, Global test loss: 1.048, Global test accuracy: 66.58
Round  54, Train loss: 0.283, Test loss: 0.396, Test accuracy: 87.08
Round  54, Global train loss: 0.283, Global test loss: 1.167, Global test accuracy: 64.72
Round  55, Train loss: 0.285, Test loss: 0.393, Test accuracy: 87.60
Round  55, Global train loss: 0.285, Global test loss: 1.138, Global test accuracy: 65.37
Round  56, Train loss: 0.316, Test loss: 0.404, Test accuracy: 87.02
Round  56, Global train loss: 0.316, Global test loss: 1.230, Global test accuracy: 62.02
Round  57, Train loss: 0.269, Test loss: 0.413, Test accuracy: 86.77
Round  57, Global train loss: 0.269, Global test loss: 1.064, Global test accuracy: 67.62
Round  58, Train loss: 0.280, Test loss: 0.431, Test accuracy: 86.42
Round  58, Global train loss: 0.280, Global test loss: 1.077, Global test accuracy: 65.97
Round  59, Train loss: 0.274, Test loss: 0.422, Test accuracy: 86.82
Round  59, Global train loss: 0.274, Global test loss: 1.167, Global test accuracy: 64.77
Round  60, Train loss: 0.288, Test loss: 0.403, Test accuracy: 87.33
Round  60, Global train loss: 0.288, Global test loss: 1.104, Global test accuracy: 68.02
Round  61, Train loss: 0.259, Test loss: 0.368, Test accuracy: 88.33
Round  61, Global train loss: 0.259, Global test loss: 1.042, Global test accuracy: 67.23
Round  62, Train loss: 0.223, Test loss: 0.390, Test accuracy: 87.98
Round  62, Global train loss: 0.223, Global test loss: 1.116, Global test accuracy: 65.93
Round  63, Train loss: 0.228, Test loss: 0.407, Test accuracy: 87.40
Round  63, Global train loss: 0.228, Global test loss: 1.210, Global test accuracy: 65.07
Round  64, Train loss: 0.239, Test loss: 0.398, Test accuracy: 87.72
Round  64, Global train loss: 0.239, Global test loss: 1.206, Global test accuracy: 65.37
Round  65, Train loss: 0.268, Test loss: 0.395, Test accuracy: 87.80
Round  65, Global train loss: 0.268, Global test loss: 0.987, Global test accuracy: 69.18
Round  66, Train loss: 0.241, Test loss: 0.407, Test accuracy: 87.62
Round  66, Global train loss: 0.241, Global test loss: 1.148, Global test accuracy: 65.47
Round  67, Train loss: 0.212, Test loss: 0.399, Test accuracy: 88.28
Round  67, Global train loss: 0.212, Global test loss: 1.031, Global test accuracy: 69.10
Round  68, Train loss: 0.209, Test loss: 0.403, Test accuracy: 88.00
Round  68, Global train loss: 0.209, Global test loss: 1.103, Global test accuracy: 66.47
Round  69, Train loss: 0.226, Test loss: 0.412, Test accuracy: 88.23
Round  69, Global train loss: 0.226, Global test loss: 1.139, Global test accuracy: 66.18
Round  70, Train loss: 0.194, Test loss: 0.419, Test accuracy: 87.92
Round  70, Global train loss: 0.194, Global test loss: 1.044, Global test accuracy: 68.30
Round  71, Train loss: 0.218, Test loss: 0.429, Test accuracy: 87.43
Round  71, Global train loss: 0.218, Global test loss: 1.178, Global test accuracy: 64.72
Round  72, Train loss: 0.200, Test loss: 0.438, Test accuracy: 87.10
Round  72, Global train loss: 0.200, Global test loss: 1.253, Global test accuracy: 64.10
Round  73, Train loss: 0.216, Test loss: 0.453, Test accuracy: 86.87
Round  73, Global train loss: 0.216, Global test loss: 1.107, Global test accuracy: 67.73
Round  74, Train loss: 0.224, Test loss: 0.438, Test accuracy: 87.02
Round  74, Global train loss: 0.224, Global test loss: 1.026, Global test accuracy: 68.85
Round  75, Train loss: 0.178, Test loss: 0.417, Test accuracy: 87.72
Round  75, Global train loss: 0.178, Global test loss: 1.250, Global test accuracy: 66.05
Round  76, Train loss: 0.214, Test loss: 0.409, Test accuracy: 87.95
Round  76, Global train loss: 0.214, Global test loss: 1.055, Global test accuracy: 68.40
Round  77, Train loss: 0.172, Test loss: 0.424, Test accuracy: 88.03
Round  77, Global train loss: 0.172, Global test loss: 1.017, Global test accuracy: 69.25
Round  78, Train loss: 0.169, Test loss: 0.444, Test accuracy: 87.52
Round  78, Global train loss: 0.169, Global test loss: 1.037, Global test accuracy: 69.42
Round  79, Train loss: 0.197, Test loss: 0.443, Test accuracy: 87.25
Round  79, Global train loss: 0.197, Global test loss: 1.001, Global test accuracy: 69.78
Round  80, Train loss: 0.155, Test loss: 0.414, Test accuracy: 88.27
Round  80, Global train loss: 0.155, Global test loss: 1.266, Global test accuracy: 66.12
Round  81, Train loss: 0.216, Test loss: 0.413, Test accuracy: 88.12
Round  81, Global train loss: 0.216, Global test loss: 0.930, Global test accuracy: 70.12
Round  82, Train loss: 0.223, Test loss: 0.396, Test accuracy: 88.25
Round  82, Global train loss: 0.223, Global test loss: 1.220, Global test accuracy: 66.13
Round  83, Train loss: 0.164, Test loss: 0.421, Test accuracy: 88.15
Round  83, Global train loss: 0.164, Global test loss: 1.050, Global test accuracy: 69.03
Round  84, Train loss: 0.221, Test loss: 0.417, Test accuracy: 87.98
Round  84, Global train loss: 0.221, Global test loss: 0.958, Global test accuracy: 69.68
Round  85, Train loss: 0.217, Test loss: 0.421, Test accuracy: 87.88
Round  85, Global train loss: 0.217, Global test loss: 1.060, Global test accuracy: 67.23
Round  86, Train loss: 0.173, Test loss: 0.413, Test accuracy: 87.90
Round  86, Global train loss: 0.173, Global test loss: 0.994, Global test accuracy: 68.97
Round  87, Train loss: 0.196, Test loss: 0.404, Test accuracy: 88.32
Round  87, Global train loss: 0.196, Global test loss: 1.175, Global test accuracy: 66.70
Round  88, Train loss: 0.132, Test loss: 0.408, Test accuracy: 88.17
Round  88, Global train loss: 0.132, Global test loss: 1.119, Global test accuracy: 68.22
Round  89, Train loss: 0.192, Test loss: 0.425, Test accuracy: 87.83
Round  89, Global train loss: 0.192, Global test loss: 1.209, Global test accuracy: 65.97
Round  90, Train loss: 0.222, Test loss: 0.413, Test accuracy: 88.03
Round  90, Global train loss: 0.222, Global test loss: 1.021, Global test accuracy: 69.13
Round  91, Train loss: 0.182, Test loss: 0.419, Test accuracy: 88.35
Round  91, Global train loss: 0.182, Global test loss: 1.071, Global test accuracy: 69.57
Round  92, Train loss: 0.144, Test loss: 0.421, Test accuracy: 88.20
Round  92, Global train loss: 0.144, Global test loss: 1.155, Global test accuracy: 67.98
Round  93, Train loss: 0.128, Test loss: 0.379, Test accuracy: 88.67
Round  93, Global train loss: 0.128, Global test loss: 1.200, Global test accuracy: 68.80
Round  94, Train loss: 0.162, Test loss: 0.388, Test accuracy: 88.48
Round  94, Global train loss: 0.162, Global test loss: 1.548, Global test accuracy: 63.77
Round  95, Train loss: 0.099, Test loss: 0.399, Test accuracy: 88.32
Round  95, Global train loss: 0.099, Global test loss: 1.145, Global test accuracy: 68.72/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  96, Train loss: 0.172, Test loss: 0.428, Test accuracy: 88.07
Round  96, Global train loss: 0.172, Global test loss: 1.036, Global test accuracy: 68.72
Round  97, Train loss: 0.205, Test loss: 0.428, Test accuracy: 88.12
Round  97, Global train loss: 0.205, Global test loss: 0.916, Global test accuracy: 71.75
Round  98, Train loss: 0.140, Test loss: 0.426, Test accuracy: 88.08
Round  98, Global train loss: 0.140, Global test loss: 0.990, Global test accuracy: 69.80
Round  99, Train loss: 0.141, Test loss: 0.431, Test accuracy: 88.05
Round  99, Global train loss: 0.141, Global test loss: 1.191, Global test accuracy: 66.80
Final Round, Train loss: 0.131, Test loss: 0.471, Test accuracy: 88.50
Final Round, Global train loss: 0.131, Global test loss: 1.191, Global test accuracy: 66.80
Average accuracy final 10 rounds: 88.23666666666665 

Average global accuracy final 10 rounds: 68.50333333333333 

1057.5915982723236
[1.074960470199585, 2.14992094039917, 2.911508798599243, 3.6730966567993164, 4.44917106628418, 5.225245475769043, 6.00544285774231, 6.785640239715576, 7.576963424682617, 8.368286609649658, 9.183900117874146, 9.999513626098633, 10.789130449295044, 11.578747272491455, 12.379754543304443, 13.180761814117432, 13.93592643737793, 14.691091060638428, 15.458433389663696, 16.225775718688965, 16.99530792236328, 17.764840126037598, 18.53874969482422, 19.31265926361084, 20.116896390914917, 20.921133518218994, 21.736966609954834, 22.552799701690674, 23.3374183177948, 24.122036933898926, 24.900362968444824, 25.678689002990723, 26.455852031707764, 27.233015060424805, 27.993032932281494, 28.753050804138184, 29.527490615844727, 30.30193042755127, 31.06825065612793, 31.83457088470459, 32.64183807373047, 33.44910526275635, 34.25787973403931, 35.066654205322266, 35.85418248176575, 36.64171075820923, 37.43084764480591, 38.21998453140259, 38.987523555755615, 39.75506258010864, 40.54417324066162, 41.3332839012146, 42.10189175605774, 42.87049961090088, 43.636239767074585, 44.40197992324829, 45.19298768043518, 45.98399543762207, 46.78120279312134, 47.578410148620605, 48.36513829231262, 49.15186643600464, 49.93163275718689, 50.71139907836914, 51.47516703605652, 52.2389349937439, 52.99040961265564, 53.74188423156738, 54.498112201690674, 55.254340171813965, 56.015549659729004, 56.77675914764404, 57.55192852020264, 58.32709789276123, 59.11810660362244, 59.90911531448364, 60.69766116142273, 61.486207008361816, 62.272175550460815, 63.058144092559814, 63.810118675231934, 64.56209325790405, 65.32933616638184, 66.09657907485962, 66.85928964614868, 67.62200021743774, 68.38654494285583, 69.15108966827393, 69.95080280303955, 70.75051593780518, 71.52477502822876, 72.29903411865234, 73.08884406089783, 73.87865400314331, 74.65126585960388, 75.42387771606445, 76.17918634414673, 76.934494972229, 77.69360995292664, 78.45272493362427, 79.21243405342102, 79.97214317321777, 80.73846459388733, 81.50478601455688, 82.27876019477844, 83.052734375, 83.8307147026062, 84.6086950302124, 85.40196180343628, 86.19522857666016, 86.96843481063843, 87.7416410446167, 88.48580479621887, 89.22996854782104, 89.984295129776, 90.73862171173096, 91.49921083450317, 92.25979995727539, 93.05592632293701, 93.85205268859863, 94.64976119995117, 95.44746971130371, 96.23049521446228, 97.01352071762085, 97.80224204063416, 98.59096336364746, 99.35779309272766, 100.12462282180786, 100.87618136405945, 101.62773990631104, 102.38896083831787, 103.1501817703247, 103.91027688980103, 104.67037200927734, 105.45458698272705, 106.23880195617676, 107.01001596450806, 107.78122997283936, 108.58134722709656, 109.38146448135376, 110.16970920562744, 110.95795392990112, 111.72752714157104, 112.49710035324097, 113.25162053108215, 114.00614070892334, 114.76039624214172, 115.51465177536011, 116.27597856521606, 117.03730535507202, 117.82134413719177, 118.60538291931152, 119.37244415283203, 120.13950538635254, 120.94001078605652, 121.7405161857605, 122.51897168159485, 123.2974271774292, 124.06080055236816, 124.82417392730713, 125.57564806938171, 126.3271222114563, 127.09260773658752, 127.85809326171875, 128.61272192001343, 129.3673505783081, 130.15924525260925, 130.9511399269104, 131.74043560028076, 132.52973127365112, 133.3315510749817, 134.13337087631226, 134.91425800323486, 135.69514513015747, 136.46563148498535, 137.23611783981323, 137.99122095108032, 138.7463240623474, 139.50608825683594, 140.26585245132446, 141.03364515304565, 141.80143785476685, 142.5759162902832, 143.35039472579956, 144.14348721504211, 144.93657970428467, 145.72153878211975, 146.50649785995483, 147.29047966003418, 148.07446146011353, 148.85176587104797, 149.62907028198242, 150.3787453174591, 151.1284203529358, 151.90355372428894, 152.6786870956421, 153.46983551979065, 154.2609839439392, 155.05326175689697, 155.84553956985474, 157.39789271354675, 158.95024585723877]
[35.11666666666667, 35.11666666666667, 38.4, 38.4, 54.65, 54.65, 59.1, 59.1, 67.61666666666666, 67.61666666666666, 67.93333333333334, 67.93333333333334, 68.2, 68.2, 70.0, 70.0, 71.6, 71.6, 72.6, 72.6, 73.81666666666666, 73.81666666666666, 72.96666666666667, 72.96666666666667, 74.38333333333334, 74.38333333333334, 75.61666666666666, 75.61666666666666, 76.16666666666667, 76.16666666666667, 76.28333333333333, 76.28333333333333, 76.51666666666667, 76.51666666666667, 77.1, 77.1, 78.83333333333333, 78.83333333333333, 79.36666666666666, 79.36666666666666, 80.3, 80.3, 80.8, 80.8, 79.86666666666666, 79.86666666666666, 81.61666666666666, 81.61666666666666, 82.06666666666666, 82.06666666666666, 82.38333333333334, 82.38333333333334, 81.31666666666666, 81.31666666666666, 81.53333333333333, 81.53333333333333, 81.71666666666667, 81.71666666666667, 82.01666666666667, 82.01666666666667, 82.43333333333334, 82.43333333333334, 82.53333333333333, 82.53333333333333, 82.55, 82.55, 83.65, 83.65, 83.45, 83.45, 84.86666666666666, 84.86666666666666, 85.41666666666667, 85.41666666666667, 85.33333333333333, 85.33333333333333, 85.46666666666667, 85.46666666666667, 85.26666666666667, 85.26666666666667, 85.96666666666667, 85.96666666666667, 85.75, 85.75, 86.0, 86.0, 86.45, 86.45, 85.9, 85.9, 86.31666666666666, 86.31666666666666, 86.81666666666666, 86.81666666666666, 87.05, 87.05, 86.48333333333333, 86.48333333333333, 86.86666666666666, 86.86666666666666, 87.06666666666666, 87.06666666666666, 87.11666666666666, 87.11666666666666, 86.66666666666667, 86.66666666666667, 87.11666666666666, 87.11666666666666, 87.08333333333333, 87.08333333333333, 87.6, 87.6, 87.01666666666667, 87.01666666666667, 86.76666666666667, 86.76666666666667, 86.41666666666667, 86.41666666666667, 86.81666666666666, 86.81666666666666, 87.33333333333333, 87.33333333333333, 88.33333333333333, 88.33333333333333, 87.98333333333333, 87.98333333333333, 87.4, 87.4, 87.71666666666667, 87.71666666666667, 87.8, 87.8, 87.61666666666666, 87.61666666666666, 88.28333333333333, 88.28333333333333, 88.0, 88.0, 88.23333333333333, 88.23333333333333, 87.91666666666667, 87.91666666666667, 87.43333333333334, 87.43333333333334, 87.1, 87.1, 86.86666666666666, 86.86666666666666, 87.01666666666667, 87.01666666666667, 87.71666666666667, 87.71666666666667, 87.95, 87.95, 88.03333333333333, 88.03333333333333, 87.51666666666667, 87.51666666666667, 87.25, 87.25, 88.26666666666667, 88.26666666666667, 88.11666666666666, 88.11666666666666, 88.25, 88.25, 88.15, 88.15, 87.98333333333333, 87.98333333333333, 87.88333333333334, 87.88333333333334, 87.9, 87.9, 88.31666666666666, 88.31666666666666, 88.16666666666667, 88.16666666666667, 87.83333333333333, 87.83333333333333, 88.03333333333333, 88.03333333333333, 88.35, 88.35, 88.2, 88.2, 88.66666666666667, 88.66666666666667, 88.48333333333333, 88.48333333333333, 88.31666666666666, 88.31666666666666, 88.06666666666666, 88.06666666666666, 88.11666666666666, 88.11666666666666, 88.08333333333333, 88.08333333333333, 88.05, 88.05, 88.5, 88.5]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
Round   0, Train loss: 1.297, Test loss: 2.311, Test accuracy: 29.37
Round   1, Train loss: 1.077, Test loss: 2.264, Test accuracy: 31.00
Round   2, Train loss: 1.073, Test loss: 2.099, Test accuracy: 33.90
Round   3, Train loss: 0.877, Test loss: 1.876, Test accuracy: 38.90
Round   4, Train loss: 0.929, Test loss: 1.798, Test accuracy: 38.23
Round   5, Train loss: 0.898, Test loss: 1.775, Test accuracy: 43.27
Round   6, Train loss: 0.726, Test loss: 1.891, Test accuracy: 41.67
Round   7, Train loss: 0.765, Test loss: 1.650, Test accuracy: 43.22
Round   8, Train loss: 0.751, Test loss: 1.719, Test accuracy: 46.27
Round   9, Train loss: 0.645, Test loss: 1.763, Test accuracy: 48.02
Round  10, Train loss: 0.733, Test loss: 1.792, Test accuracy: 41.73
Round  11, Train loss: 0.723, Test loss: 1.552, Test accuracy: 48.22
Round  12, Train loss: 0.607, Test loss: 1.455, Test accuracy: 51.48
Round  13, Train loss: 0.636, Test loss: 1.650, Test accuracy: 47.07
Round  14, Train loss: 0.625, Test loss: 1.516, Test accuracy: 49.83
Round  15, Train loss: 0.546, Test loss: 1.520, Test accuracy: 50.83
Round  16, Train loss: 0.578, Test loss: 1.766, Test accuracy: 45.65
Round  17, Train loss: 0.572, Test loss: 1.408, Test accuracy: 54.23
Round  18, Train loss: 0.453, Test loss: 1.555, Test accuracy: 52.43
Round  19, Train loss: 0.522, Test loss: 1.801, Test accuracy: 48.87
Round  20, Train loss: 0.548, Test loss: 1.328, Test accuracy: 56.50
Round  21, Train loss: 0.454, Test loss: 1.342, Test accuracy: 57.30
Round  22, Train loss: 0.426, Test loss: 1.556, Test accuracy: 52.82
Round  23, Train loss: 0.423, Test loss: 1.396, Test accuracy: 56.00
Round  24, Train loss: 0.401, Test loss: 1.509, Test accuracy: 55.42
Round  25, Train loss: 0.504, Test loss: 1.245, Test accuracy: 59.38
Round  26, Train loss: 0.425, Test loss: 1.673, Test accuracy: 53.12
Round  27, Train loss: 0.422, Test loss: 1.335, Test accuracy: 56.47
Round  28, Train loss: 0.417, Test loss: 1.137, Test accuracy: 64.20
Round  29, Train loss: 0.361, Test loss: 1.446, Test accuracy: 56.05
Round  30, Train loss: 0.384, Test loss: 1.308, Test accuracy: 59.60
Round  31, Train loss: 0.308, Test loss: 1.699, Test accuracy: 53.20
Round  32, Train loss: 0.328, Test loss: 1.181, Test accuracy: 61.28
Round  33, Train loss: 0.362, Test loss: 1.227, Test accuracy: 61.88
Round  34, Train loss: 0.294, Test loss: 1.304, Test accuracy: 58.68
Round  35, Train loss: 0.299, Test loss: 1.335, Test accuracy: 59.58
Round  36, Train loss: 0.326, Test loss: 1.274, Test accuracy: 62.70
Round  37, Train loss: 0.293, Test loss: 1.272, Test accuracy: 60.25
Round  38, Train loss: 0.332, Test loss: 1.281, Test accuracy: 60.03
Round  39, Train loss: 0.254, Test loss: 1.385, Test accuracy: 60.47
Round  40, Train loss: 0.328, Test loss: 1.182, Test accuracy: 62.15
Round  41, Train loss: 0.258, Test loss: 1.259, Test accuracy: 63.20
Round  42, Train loss: 0.268, Test loss: 1.161, Test accuracy: 64.70
Round  43, Train loss: 0.288, Test loss: 1.116, Test accuracy: 63.82
Round  44, Train loss: 0.212, Test loss: 1.114, Test accuracy: 65.35
Round  45, Train loss: 0.251, Test loss: 1.103, Test accuracy: 65.75
Round  46, Train loss: 0.284, Test loss: 1.149, Test accuracy: 64.05
Round  47, Train loss: 0.264, Test loss: 1.014, Test accuracy: 66.02
Round  48, Train loss: 0.259, Test loss: 1.135, Test accuracy: 63.88
Round  49, Train loss: 0.286, Test loss: 1.171, Test accuracy: 62.97
Round  50, Train loss: 0.220, Test loss: 1.189, Test accuracy: 63.63
Round  51, Train loss: 0.166, Test loss: 1.216, Test accuracy: 62.40
Round  52, Train loss: 0.229, Test loss: 1.104, Test accuracy: 65.58
Round  53, Train loss: 0.255, Test loss: 0.926, Test accuracy: 69.03
Round  54, Train loss: 0.246, Test loss: 1.121, Test accuracy: 65.03
Round  55, Train loss: 0.203, Test loss: 1.240, Test accuracy: 63.00
Round  56, Train loss: 0.201, Test loss: 1.111, Test accuracy: 66.10
Round  57, Train loss: 0.223, Test loss: 0.910, Test accuracy: 68.77
Round  58, Train loss: 0.190, Test loss: 1.094, Test accuracy: 65.75
Round  59, Train loss: 0.236, Test loss: 1.055, Test accuracy: 65.92
Round  60, Train loss: 0.184, Test loss: 1.039, Test accuracy: 67.45
Round  61, Train loss: 0.164, Test loss: 1.330, Test accuracy: 63.45
Round  62, Train loss: 0.201, Test loss: 1.064, Test accuracy: 67.13
Round  63, Train loss: 0.222, Test loss: 1.016, Test accuracy: 67.40
Round  64, Train loss: 0.186, Test loss: 1.064, Test accuracy: 67.40
Round  65, Train loss: 0.170, Test loss: 1.081, Test accuracy: 67.73
Round  66, Train loss: 0.152, Test loss: 1.062, Test accuracy: 67.15
Round  67, Train loss: 0.165, Test loss: 1.306, Test accuracy: 64.63
Round  68, Train loss: 0.182, Test loss: 1.053, Test accuracy: 68.12
Round  69, Train loss: 0.203, Test loss: 1.076, Test accuracy: 65.20
Round  70, Train loss: 0.142, Test loss: 1.418, Test accuracy: 63.20
Round  71, Train loss: 0.140, Test loss: 1.402, Test accuracy: 64.30
Round  72, Train loss: 0.178, Test loss: 1.022, Test accuracy: 68.83
Round  73, Train loss: 0.167, Test loss: 1.017, Test accuracy: 68.55
Round  74, Train loss: 0.167, Test loss: 1.029, Test accuracy: 68.38
Round  75, Train loss: 0.137, Test loss: 1.074, Test accuracy: 69.45
Round  76, Train loss: 0.165, Test loss: 1.229, Test accuracy: 65.57
Round  77, Train loss: 0.128, Test loss: 0.918, Test accuracy: 71.97
Round  78, Train loss: 0.118, Test loss: 1.135, Test accuracy: 67.62
Round  79, Train loss: 0.114, Test loss: 1.056, Test accuracy: 69.17
Round  80, Train loss: 0.105, Test loss: 1.112, Test accuracy: 69.38
Round  81, Train loss: 0.122, Test loss: 0.988, Test accuracy: 70.02
Round  82, Train loss: 0.112, Test loss: 1.007, Test accuracy: 70.72
Round  83, Train loss: 0.140, Test loss: 0.922, Test accuracy: 69.88
Round  84, Train loss: 0.087, Test loss: 1.074, Test accuracy: 69.57
Round  85, Train loss: 0.130, Test loss: 1.044, Test accuracy: 69.27
Round  86, Train loss: 0.114, Test loss: 1.258, Test accuracy: 68.08
Round  87, Train loss: 0.098, Test loss: 1.198, Test accuracy: 67.93
Round  88, Train loss: 0.092, Test loss: 1.181, Test accuracy: 69.32
Round  89, Train loss: 0.090, Test loss: 1.113, Test accuracy: 69.52
Round  90, Train loss: 0.145, Test loss: 1.232, Test accuracy: 64.82
Round  91, Train loss: 0.105, Test loss: 1.091, Test accuracy: 68.25
Round  92, Train loss: 0.091, Test loss: 1.010, Test accuracy: 68.78
Round  93, Train loss: 0.078, Test loss: 1.020, Test accuracy: 71.15
Round  94, Train loss: 0.106, Test loss: 1.131, Test accuracy: 68.30
Round  95, Train loss: 0.110, Test loss: 1.136, Test accuracy: 67.75
Round  96, Train loss: 0.134, Test loss: 1.008, Test accuracy: 70.00
Round  97, Train loss: 0.140, Test loss: 0.954, Test accuracy: 70.20
Round  98, Train loss: 0.122, Test loss: 0.922, Test accuracy: 71.20
Round  99, Train loss: 0.081, Test loss: 1.094, Test accuracy: 70.18
Final Round, Train loss: 0.099, Test loss: 0.889, Test accuracy: 73.03
Average accuracy final 10 rounds: 69.06333333333333
1352.3089516162872
[2.248018980026245, 4.1210620403289795, 6.030857563018799, 8.010566473007202, 9.925063133239746, 11.863163471221924, 13.71333646774292, 15.591717958450317, 17.48522162437439, 19.40971279144287, 21.30484175682068, 23.250117540359497, 25.11941695213318, 26.97307777404785, 28.863929510116577, 30.77004837989807, 32.70254349708557, 34.62536144256592, 36.57616877555847, 38.44325590133667, 40.33351182937622, 42.24561929702759, 44.14051604270935, 46.058494567871094, 47.98790001869202, 49.838499784469604, 51.69035196304321, 53.566330909729004, 55.4398934841156, 57.36292815208435, 59.27812337875366, 61.12941932678223, 63.004318952560425, 64.86759638786316, 66.77801179885864, 68.6773190498352, 70.61110758781433, 72.51645255088806, 74.41129159927368, 76.25275349617004, 78.16652965545654, 80.0872495174408, 82.02254009246826, 83.93803858757019, 85.82910442352295, 87.7032573223114, 89.57712054252625, 91.50237584114075, 93.37886261940002, 95.38537669181824, 97.26550912857056, 99.16265106201172, 101.10283422470093, 103.06780529022217, 105.00733923912048, 106.96464323997498, 108.88413953781128, 110.76247692108154, 112.66315698623657, 114.60263156890869, 116.49383091926575, 118.40963768959045, 120.37208199501038, 122.22071599960327, 124.10880327224731, 126.0738308429718, 127.99017357826233, 129.92180347442627, 131.85097289085388, 133.73731803894043, 135.61885380744934, 137.5248839855194, 139.45776295661926, 141.38804697990417, 143.37045216560364, 145.24000358581543, 147.11970257759094, 149.00417494773865, 150.93065071105957, 152.8825671672821, 154.8509202003479, 156.72947072982788, 158.6096272468567, 160.5070698261261, 162.39324593544006, 164.33224821090698, 166.29051733016968, 168.21964645385742, 170.07888007164001, 172.00019907951355, 173.86499118804932, 175.81892037391663, 177.77621841430664, 179.72608041763306, 181.6192889213562, 183.4894413948059, 185.38075280189514, 187.2943980693817, 189.25550174713135, 191.23298406600952, 193.1842555999756]
[29.366666666666667, 31.0, 33.9, 38.9, 38.233333333333334, 43.266666666666666, 41.666666666666664, 43.21666666666667, 46.266666666666666, 48.016666666666666, 41.733333333333334, 48.21666666666667, 51.483333333333334, 47.06666666666667, 49.833333333333336, 50.833333333333336, 45.65, 54.233333333333334, 52.43333333333333, 48.86666666666667, 56.5, 57.3, 52.81666666666667, 56.0, 55.416666666666664, 59.38333333333333, 53.11666666666667, 56.46666666666667, 64.2, 56.05, 59.6, 53.2, 61.28333333333333, 61.88333333333333, 58.68333333333333, 59.583333333333336, 62.7, 60.25, 60.03333333333333, 60.46666666666667, 62.15, 63.2, 64.7, 63.81666666666667, 65.35, 65.75, 64.05, 66.01666666666667, 63.88333333333333, 62.96666666666667, 63.63333333333333, 62.4, 65.58333333333333, 69.03333333333333, 65.03333333333333, 63.0, 66.1, 68.76666666666667, 65.75, 65.91666666666667, 67.45, 63.45, 67.13333333333334, 67.4, 67.4, 67.73333333333333, 67.15, 64.63333333333334, 68.11666666666666, 65.2, 63.2, 64.3, 68.83333333333333, 68.55, 68.38333333333334, 69.45, 65.56666666666666, 71.96666666666667, 67.61666666666666, 69.16666666666667, 69.38333333333334, 70.01666666666667, 70.71666666666667, 69.88333333333334, 69.56666666666666, 69.26666666666667, 68.08333333333333, 67.93333333333334, 69.31666666666666, 69.51666666666667, 64.81666666666666, 68.25, 68.78333333333333, 71.15, 68.3, 67.75, 70.0, 70.2, 71.2, 70.18333333333334, 73.03333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100  

Files already downloaded and verified
Files already downloaded and verified
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 1063434 (local), 1062144 (global); Percentage 99.88 (1062144/1063434)
learning rate, batch size: 0.01, 10
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
Round   0, Train loss: 1.746, Test loss: 2.282, Test accuracy: 20.92
Round   1, Train loss: 1.172, Test loss: 1.940, Test accuracy: 37.22
Round   2, Train loss: 1.073, Test loss: 1.383, Test accuracy: 50.27
Round   3, Train loss: 0.964, Test loss: 1.277, Test accuracy: 54.57
Round   4, Train loss: 0.955, Test loss: 1.158, Test accuracy: 59.15
Round   5, Train loss: 0.811, Test loss: 1.116, Test accuracy: 59.98
Round   6, Train loss: 0.720, Test loss: 1.137, Test accuracy: 63.63
Round   7, Train loss: 0.871, Test loss: 0.781, Test accuracy: 70.55
Round   8, Train loss: 0.703, Test loss: 0.768, Test accuracy: 71.33
Round   9, Train loss: 0.676, Test loss: 0.817, Test accuracy: 71.73
Round  10, Train loss: 0.780, Test loss: 0.665, Test accuracy: 74.55
Round  11, Train loss: 0.758, Test loss: 0.654, Test accuracy: 73.82
Round  12, Train loss: 0.729, Test loss: 0.647, Test accuracy: 74.75
Round  13, Train loss: 0.676, Test loss: 0.609, Test accuracy: 75.85
Round  14, Train loss: 0.619, Test loss: 0.601, Test accuracy: 76.78
Round  15, Train loss: 0.652, Test loss: 0.597, Test accuracy: 76.72
Round  16, Train loss: 0.701, Test loss: 0.567, Test accuracy: 77.82
Round  17, Train loss: 0.629, Test loss: 0.560, Test accuracy: 78.33
Round  18, Train loss: 0.607, Test loss: 0.554, Test accuracy: 78.88
Round  19, Train loss: 0.604, Test loss: 0.539, Test accuracy: 79.30
Round  20, Train loss: 0.527, Test loss: 0.534, Test accuracy: 79.78
Round  21, Train loss: 0.666, Test loss: 0.537, Test accuracy: 79.58
Round  22, Train loss: 0.590, Test loss: 0.535, Test accuracy: 79.98
Round  23, Train loss: 0.541, Test loss: 0.492, Test accuracy: 81.40
Round  24, Train loss: 0.589, Test loss: 0.512, Test accuracy: 80.75
Round  25, Train loss: 0.473, Test loss: 0.496, Test accuracy: 81.27
Round  26, Train loss: 0.421, Test loss: 0.489, Test accuracy: 80.70
Round  27, Train loss: 0.558, Test loss: 0.481, Test accuracy: 81.38
Round  28, Train loss: 0.464, Test loss: 0.474, Test accuracy: 81.82
Round  29, Train loss: 0.479, Test loss: 0.462, Test accuracy: 82.53
Round  30, Train loss: 0.486, Test loss: 0.468, Test accuracy: 82.22
Round  31, Train loss: 0.404, Test loss: 0.452, Test accuracy: 83.33
Round  32, Train loss: 0.482, Test loss: 0.441, Test accuracy: 83.27
Round  33, Train loss: 0.406, Test loss: 0.454, Test accuracy: 83.15
Round  34, Train loss: 0.373, Test loss: 0.446, Test accuracy: 82.95
Round  35, Train loss: 0.386, Test loss: 0.437, Test accuracy: 83.68
Round  36, Train loss: 0.403, Test loss: 0.440, Test accuracy: 83.47
Round  37, Train loss: 0.446, Test loss: 0.437, Test accuracy: 83.13
Round  38, Train loss: 0.425, Test loss: 0.414, Test accuracy: 84.90
Round  39, Train loss: 0.348, Test loss: 0.404, Test accuracy: 84.93
Round  40, Train loss: 0.421, Test loss: 0.408, Test accuracy: 84.82
Round  41, Train loss: 0.438, Test loss: 0.418, Test accuracy: 84.97
Round  42, Train loss: 0.373, Test loss: 0.403, Test accuracy: 84.93
Round  43, Train loss: 0.420, Test loss: 0.395, Test accuracy: 85.63
Round  44, Train loss: 0.309, Test loss: 0.399, Test accuracy: 84.88
Round  45, Train loss: 0.429, Test loss: 0.380, Test accuracy: 85.70
Round  46, Train loss: 0.370, Test loss: 0.402, Test accuracy: 85.18
Round  47, Train loss: 0.355, Test loss: 0.390, Test accuracy: 85.22
Round  48, Train loss: 0.363, Test loss: 0.382, Test accuracy: 84.92
Round  49, Train loss: 0.320, Test loss: 0.379, Test accuracy: 85.45
Round  50, Train loss: 0.323, Test loss: 0.366, Test accuracy: 86.15
Round  51, Train loss: 0.346, Test loss: 0.370, Test accuracy: 85.85
Round  52, Train loss: 0.320, Test loss: 0.365, Test accuracy: 85.97
Round  53, Train loss: 0.306, Test loss: 0.375, Test accuracy: 85.83
Round  54, Train loss: 0.330, Test loss: 0.367, Test accuracy: 86.35
Round  55, Train loss: 0.290, Test loss: 0.347, Test accuracy: 87.30
Round  56, Train loss: 0.299, Test loss: 0.355, Test accuracy: 86.57
Round  57, Train loss: 0.269, Test loss: 0.355, Test accuracy: 86.95
Round  58, Train loss: 0.239, Test loss: 0.370, Test accuracy: 86.53
Round  59, Train loss: 0.314, Test loss: 0.376, Test accuracy: 86.02
Round  60, Train loss: 0.272, Test loss: 0.368, Test accuracy: 86.82
Round  61, Train loss: 0.263, Test loss: 0.352, Test accuracy: 87.13
Round  62, Train loss: 0.300, Test loss: 0.364, Test accuracy: 87.32
Round  63, Train loss: 0.210, Test loss: 0.345, Test accuracy: 87.43
Round  64, Train loss: 0.311, Test loss: 0.338, Test accuracy: 87.62
Round  65, Train loss: 0.218, Test loss: 0.346, Test accuracy: 87.55
Round  66, Train loss: 0.240, Test loss: 0.348, Test accuracy: 87.13
Round  67, Train loss: 0.288, Test loss: 0.349, Test accuracy: 87.63
Round  68, Train loss: 0.316, Test loss: 0.377, Test accuracy: 87.08
Round  69, Train loss: 0.201, Test loss: 0.368, Test accuracy: 86.95
Round  70, Train loss: 0.298, Test loss: 0.349, Test accuracy: 87.63
Round  71, Train loss: 0.213, Test loss: 0.358, Test accuracy: 87.12
Round  72, Train loss: 0.288, Test loss: 0.346, Test accuracy: 87.95
Round  73, Train loss: 0.240, Test loss: 0.331, Test accuracy: 88.72
Round  74, Train loss: 0.234, Test loss: 0.342, Test accuracy: 87.38
Round  75, Train loss: 0.243, Test loss: 0.328, Test accuracy: 88.42
Round  76, Train loss: 0.189, Test loss: 0.350, Test accuracy: 88.08
Round  77, Train loss: 0.236, Test loss: 0.337, Test accuracy: 88.05
Round  78, Train loss: 0.200, Test loss: 0.326, Test accuracy: 88.37
Round  79, Train loss: 0.206, Test loss: 0.337, Test accuracy: 88.18
Round  80, Train loss: 0.255, Test loss: 0.338, Test accuracy: 87.90
Round  81, Train loss: 0.225, Test loss: 0.333, Test accuracy: 87.95
Round  82, Train loss: 0.209, Test loss: 0.340, Test accuracy: 87.83
Round  83, Train loss: 0.207, Test loss: 0.327, Test accuracy: 88.52
Round  84, Train loss: 0.206, Test loss: 0.331, Test accuracy: 88.18
Round  85, Train loss: 0.164, Test loss: 0.331, Test accuracy: 88.37
Round  86, Train loss: 0.187, Test loss: 0.331, Test accuracy: 88.43
Round  87, Train loss: 0.178, Test loss: 0.329, Test accuracy: 88.28
Round  88, Train loss: 0.189, Test loss: 0.345, Test accuracy: 87.97
Round  89, Train loss: 0.194, Test loss: 0.335, Test accuracy: 88.58
Round  90, Train loss: 0.191, Test loss: 0.332, Test accuracy: 88.45
Round  91, Train loss: 0.221, Test loss: 0.331, Test accuracy: 89.08
Round  92, Train loss: 0.166, Test loss: 0.321, Test accuracy: 88.88
Round  93, Train loss: 0.186, Test loss: 0.316, Test accuracy: 89.37
Round  94, Train loss: 0.196, Test loss: 0.327, Test accuracy: 88.75
Round  95, Train loss: 0.170, Test loss: 0.318, Test accuracy: 89.05
Round  96, Train loss: 0.188, Test loss: 0.313, Test accuracy: 89.12
Round  97, Train loss: 0.249, Test loss: 0.336, Test accuracy: 88.48
Round  98, Train loss: 0.198, Test loss: 0.337, Test accuracy: 88.80
Round  99, Train loss: 0.172, Test loss: 0.324, Test accuracy: 89.07
Final Round, Train loss: 0.144, Test loss: 0.328, Test accuracy: 89.13
Average accuracy final 10 rounds: 88.90499999999999
749.6805384159088
[1.2551665306091309, 2.2189440727233887, 3.1288647651672363, 4.072021722793579, 5.0166730880737305, 5.9288763999938965, 6.818453788757324, 7.7106969356536865, 8.600466251373291, 9.471455097198486, 10.351629495620728, 11.238672256469727, 12.154621362686157, 13.072975397109985, 14.007708072662354, 14.90923023223877, 15.811647176742554, 16.75037455558777, 17.65192723274231, 18.521214485168457, 19.393927335739136, 20.2700355052948, 21.129711151123047, 22.064881086349487, 23.020012855529785, 23.93167281150818, 24.878228425979614, 25.804974794387817, 26.726763486862183, 27.620291471481323, 28.509442806243896, 29.382373094558716, 30.281237602233887, 31.177496194839478, 32.07094860076904, 32.99848413467407, 33.934075355529785, 34.87112331390381, 35.8079674243927, 36.77239108085632, 37.704416275024414, 38.592026472091675, 39.46005392074585, 40.3552348613739, 41.247634172439575, 42.122132301330566, 42.99910020828247, 43.91405773162842, 44.83586859703064, 45.75286626815796, 46.704962491989136, 47.64567518234253, 48.55584144592285, 49.43265771865845, 50.31121897697449, 51.19085192680359, 52.071800231933594, 52.97474813461304, 53.889421701431274, 54.81931662559509, 55.75328516960144, 56.71093273162842, 57.6669225692749, 58.58120584487915, 59.48408222198486, 60.3477303981781, 61.244218587875366, 62.14546036720276, 63.030630350112915, 63.903164863586426, 64.81430196762085, 65.75685787200928, 66.6748857498169, 67.59367871284485, 68.5379958152771, 69.45929479598999, 70.342116355896, 71.23177409172058, 72.09206581115723, 72.97451758384705, 73.87303233146667, 74.81558585166931, 75.72987270355225, 76.69116306304932, 77.6069610118866, 78.52808427810669, 79.4651358127594, 80.34893345832825, 81.2253737449646, 82.1058611869812, 82.97629737854004, 83.86041212081909, 84.72671461105347, 85.65468835830688, 86.61341714859009, 87.51478981971741, 88.44182085990906, 89.36442732810974, 90.26783919334412, 91.14897179603577, 92.5368926525116]
[20.916666666666668, 37.21666666666667, 50.266666666666666, 54.56666666666667, 59.15, 59.983333333333334, 63.63333333333333, 70.55, 71.33333333333333, 71.73333333333333, 74.55, 73.81666666666666, 74.75, 75.85, 76.78333333333333, 76.71666666666667, 77.81666666666666, 78.33333333333333, 78.88333333333334, 79.3, 79.78333333333333, 79.58333333333333, 79.98333333333333, 81.4, 80.75, 81.26666666666667, 80.7, 81.38333333333334, 81.81666666666666, 82.53333333333333, 82.21666666666667, 83.33333333333333, 83.26666666666667, 83.15, 82.95, 83.68333333333334, 83.46666666666667, 83.13333333333334, 84.9, 84.93333333333334, 84.81666666666666, 84.96666666666667, 84.93333333333334, 85.63333333333334, 84.88333333333334, 85.7, 85.18333333333334, 85.21666666666667, 84.91666666666667, 85.45, 86.15, 85.85, 85.96666666666667, 85.83333333333333, 86.35, 87.3, 86.56666666666666, 86.95, 86.53333333333333, 86.01666666666667, 86.81666666666666, 87.13333333333334, 87.31666666666666, 87.43333333333334, 87.61666666666666, 87.55, 87.13333333333334, 87.63333333333334, 87.08333333333333, 86.95, 87.63333333333334, 87.11666666666666, 87.95, 88.71666666666667, 87.38333333333334, 88.41666666666667, 88.08333333333333, 88.05, 88.36666666666666, 88.18333333333334, 87.9, 87.95, 87.83333333333333, 88.51666666666667, 88.18333333333334, 88.36666666666666, 88.43333333333334, 88.28333333333333, 87.96666666666667, 88.58333333333333, 88.45, 89.08333333333333, 88.88333333333334, 89.36666666666666, 88.75, 89.05, 89.11666666666666, 88.48333333333333, 88.8, 89.06666666666666, 89.13333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar100  

Files already downloaded and verified
Files already downloaded and verified
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
4800
4864
209664
209792
1028992
1029248
1062016
1062144
1063424
1063434
# Params: 1063434 (local), 1062144 (global); Percentage 99.88 (1062144/1063434)
learning rate, batch size: 0.01, 10
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
Round   0, Train loss: 1.722, Test loss: 2.041, Test accuracy: 25.82
Round   1, Train loss: 1.217, Test loss: 1.827, Test accuracy: 37.55
Round   2, Train loss: 1.075, Test loss: 1.578, Test accuracy: 42.55
Round   3, Train loss: 0.980, Test loss: 1.186, Test accuracy: 53.58
Round   4, Train loss: 0.924, Test loss: 1.064, Test accuracy: 59.50
Round   5, Train loss: 0.858, Test loss: 0.970, Test accuracy: 61.38
Round   6, Train loss: 0.850, Test loss: 0.824, Test accuracy: 69.50
Round   7, Train loss: 0.780, Test loss: 0.790, Test accuracy: 69.28
Round   8, Train loss: 0.785, Test loss: 0.746, Test accuracy: 72.13
Round   9, Train loss: 0.735, Test loss: 0.668, Test accuracy: 73.83
Round  10, Train loss: 0.749, Test loss: 0.653, Test accuracy: 74.65
Round  11, Train loss: 0.719, Test loss: 0.649, Test accuracy: 75.57
Round  12, Train loss: 0.696, Test loss: 0.650, Test accuracy: 76.83
Round  13, Train loss: 0.700, Test loss: 0.628, Test accuracy: 77.83
Round  14, Train loss: 0.614, Test loss: 0.592, Test accuracy: 77.25
Round  15, Train loss: 0.675, Test loss: 0.590, Test accuracy: 78.52
Round  16, Train loss: 0.634, Test loss: 0.569, Test accuracy: 79.25
Round  17, Train loss: 0.609, Test loss: 0.548, Test accuracy: 80.58
Round  18, Train loss: 0.577, Test loss: 0.524, Test accuracy: 81.32
Round  19, Train loss: 0.558, Test loss: 0.513, Test accuracy: 81.33
Round  20, Train loss: 0.523, Test loss: 0.494, Test accuracy: 81.98
Round  21, Train loss: 0.584, Test loss: 0.473, Test accuracy: 82.00
Round  22, Train loss: 0.528, Test loss: 0.486, Test accuracy: 82.93
Round  23, Train loss: 0.538, Test loss: 0.476, Test accuracy: 83.52
Round  24, Train loss: 0.465, Test loss: 0.462, Test accuracy: 83.20
Round  25, Train loss: 0.480, Test loss: 0.461, Test accuracy: 83.47
Round  26, Train loss: 0.495, Test loss: 0.458, Test accuracy: 83.73
Round  27, Train loss: 0.468, Test loss: 0.440, Test accuracy: 83.52
Round  28, Train loss: 0.438, Test loss: 0.445, Test accuracy: 83.97
Round  29, Train loss: 0.425, Test loss: 0.461, Test accuracy: 82.60
Round  30, Train loss: 0.435, Test loss: 0.450, Test accuracy: 83.95
Round  31, Train loss: 0.396, Test loss: 0.445, Test accuracy: 84.33
Round  32, Train loss: 0.429, Test loss: 0.428, Test accuracy: 84.30
Round  33, Train loss: 0.422, Test loss: 0.427, Test accuracy: 84.48
Round  34, Train loss: 0.369, Test loss: 0.413, Test accuracy: 84.18
Round  35, Train loss: 0.479, Test loss: 0.408, Test accuracy: 84.57
Round  36, Train loss: 0.425, Test loss: 0.405, Test accuracy: 85.03
Round  37, Train loss: 0.345, Test loss: 0.405, Test accuracy: 85.53
Round  38, Train loss: 0.389, Test loss: 0.412, Test accuracy: 85.30
Round  39, Train loss: 0.347, Test loss: 0.401, Test accuracy: 85.60
Round  40, Train loss: 0.309, Test loss: 0.410, Test accuracy: 85.20
Round  41, Train loss: 0.348, Test loss: 0.419, Test accuracy: 85.50
Round  42, Train loss: 0.289, Test loss: 0.406, Test accuracy: 85.35
Round  43, Train loss: 0.414, Test loss: 0.399, Test accuracy: 86.52
Round  44, Train loss: 0.378, Test loss: 0.383, Test accuracy: 86.70
Round  45, Train loss: 0.372, Test loss: 0.385, Test accuracy: 86.63
Round  46, Train loss: 0.320, Test loss: 0.380, Test accuracy: 86.47
Round  47, Train loss: 0.423, Test loss: 0.375, Test accuracy: 86.28
Round  48, Train loss: 0.299, Test loss: 0.369, Test accuracy: 86.62
Round  49, Train loss: 0.336, Test loss: 0.354, Test accuracy: 86.82
Round  50, Train loss: 0.307, Test loss: 0.373, Test accuracy: 86.55
Round  51, Train loss: 0.333, Test loss: 0.361, Test accuracy: 86.82
Round  52, Train loss: 0.372, Test loss: 0.355, Test accuracy: 87.15
Round  53, Train loss: 0.268, Test loss: 0.352, Test accuracy: 87.13
Round  54, Train loss: 0.366, Test loss: 0.365, Test accuracy: 86.45
Round  55, Train loss: 0.251, Test loss: 0.367, Test accuracy: 87.05
Round  56, Train loss: 0.305, Test loss: 0.358, Test accuracy: 86.98
Round  57, Train loss: 0.352, Test loss: 0.360, Test accuracy: 86.62
Round  58, Train loss: 0.354, Test loss: 0.345, Test accuracy: 87.43
Round  59, Train loss: 0.324, Test loss: 0.345, Test accuracy: 87.25
Round  60, Train loss: 0.311, Test loss: 0.347, Test accuracy: 87.12
Round  61, Train loss: 0.282, Test loss: 0.351, Test accuracy: 87.50
Round  62, Train loss: 0.274, Test loss: 0.339, Test accuracy: 87.83
Round  63, Train loss: 0.259, Test loss: 0.333, Test accuracy: 87.97
Round  64, Train loss: 0.222, Test loss: 0.338, Test accuracy: 87.95
Round  65, Train loss: 0.335, Test loss: 0.341, Test accuracy: 87.72
Round  66, Train loss: 0.315, Test loss: 0.329, Test accuracy: 88.32
Round  67, Train loss: 0.265, Test loss: 0.328, Test accuracy: 88.28
Round  68, Train loss: 0.269, Test loss: 0.341, Test accuracy: 87.92
Round  69, Train loss: 0.223, Test loss: 0.341, Test accuracy: 87.73
Round  70, Train loss: 0.273, Test loss: 0.344, Test accuracy: 87.48
Round  71, Train loss: 0.280, Test loss: 0.341, Test accuracy: 87.87
Round  72, Train loss: 0.322, Test loss: 0.341, Test accuracy: 88.32
Round  73, Train loss: 0.275, Test loss: 0.320, Test accuracy: 88.07
Round  74, Train loss: 0.242, Test loss: 0.329, Test accuracy: 88.35
Round  75, Train loss: 0.229, Test loss: 0.337, Test accuracy: 88.30
Round  76, Train loss: 0.239, Test loss: 0.335, Test accuracy: 88.25
Round  77, Train loss: 0.234, Test loss: 0.341, Test accuracy: 88.10
Round  78, Train loss: 0.214, Test loss: 0.331, Test accuracy: 88.38
Round  79, Train loss: 0.257, Test loss: 0.335, Test accuracy: 87.92
Round  80, Train loss: 0.204, Test loss: 0.342, Test accuracy: 87.50
Round  81, Train loss: 0.252, Test loss: 0.340, Test accuracy: 87.48
Round  82, Train loss: 0.219, Test loss: 0.341, Test accuracy: 87.87
Round  83, Train loss: 0.264, Test loss: 0.345, Test accuracy: 87.38
Round  84, Train loss: 0.227, Test loss: 0.333, Test accuracy: 88.35
Round  85, Train loss: 0.241, Test loss: 0.325, Test accuracy: 88.18
Round  86, Train loss: 0.229, Test loss: 0.332, Test accuracy: 88.37
Round  87, Train loss: 0.228, Test loss: 0.335, Test accuracy: 88.33
Round  88, Train loss: 0.209, Test loss: 0.337, Test accuracy: 88.50
Round  89, Train loss: 0.181, Test loss: 0.328, Test accuracy: 88.93
Round  90, Train loss: 0.202, Test loss: 0.332, Test accuracy: 88.48
Round  91, Train loss: 0.230, Test loss: 0.331, Test accuracy: 88.17
Round  92, Train loss: 0.186, Test loss: 0.335, Test accuracy: 88.32
Round  93, Train loss: 0.225, Test loss: 0.332, Test accuracy: 88.12
Round  94, Train loss: 0.196, Test loss: 0.332, Test accuracy: 87.80
Round  95, Train loss: 0.159, Test loss: 0.329, Test accuracy: 88.23
Round  96, Train loss: 0.215, Test loss: 0.343, Test accuracy: 87.38
Round  97, Train loss: 0.199, Test loss: 0.318, Test accuracy: 88.62
Round  98, Train loss: 0.203, Test loss: 0.325, Test accuracy: 89.05
Round  99, Train loss: 0.181, Test loss: 0.313, Test accuracy: 88.85
Final Round, Train loss: 0.148, Test loss: 0.319, Test accuracy: 88.95
Average accuracy final 10 rounds: 88.30166666666666
903.811115026474
[1.324157953262329, 2.648315906524658, 3.591960906982422, 4.5356059074401855, 5.470037221908569, 6.404468536376953, 7.307798862457275, 8.211129188537598, 9.115455865859985, 10.019782543182373, 10.878713369369507, 11.73764419555664, 12.593455076217651, 13.449265956878662, 14.316246747970581, 15.1832275390625, 16.04794478416443, 16.912662029266357, 17.827526330947876, 18.742390632629395, 19.667907238006592, 20.59342384338379, 21.52214026451111, 22.450856685638428, 23.357114791870117, 24.263372898101807, 25.14104413986206, 26.018715381622314, 26.876480102539062, 27.73424482345581, 28.59365701675415, 29.45306921005249, 30.29965305328369, 31.146236896514893, 32.011011362075806, 32.87578582763672, 33.778095722198486, 34.680405616760254, 35.61172008514404, 36.54303455352783, 37.45056414604187, 38.35809373855591, 39.28924369812012, 40.220393657684326, 41.127567291259766, 42.034740924835205, 42.90613770484924, 43.77753448486328, 44.62703990936279, 45.476545333862305, 46.3507342338562, 47.2249231338501, 48.11801838874817, 49.01111364364624, 49.898659229278564, 50.78620481491089, 51.698630571365356, 52.611056327819824, 53.50475764274597, 54.39845895767212, 55.33224177360535, 56.266024589538574, 57.24341416358948, 58.22080373764038, 59.05518960952759, 59.889575481414795, 60.73114562034607, 61.572715759277344, 62.419891119003296, 63.26706647872925, 64.13449335098267, 65.00192022323608, 65.86867356300354, 66.735426902771, 67.57014393806458, 68.40486097335815, 69.24818825721741, 70.09151554107666, 70.95531249046326, 71.81910943984985, 72.6588442325592, 73.49857902526855, 74.34773850440979, 75.19689798355103, 76.0911111831665, 76.98532438278198, 77.81590247154236, 78.64648056030273, 79.49674677848816, 80.34701299667358, 81.17860198020935, 82.01019096374512, 82.85297679901123, 83.69576263427734, 84.55051279067993, 85.40526294708252, 86.23632192611694, 87.06738090515137, 87.92003154754639, 88.7726821899414, 89.63522243499756, 90.49776268005371, 91.3435127735138, 92.18926286697388, 93.05422186851501, 93.91918087005615, 94.74968576431274, 95.58019065856934, 96.4271309375763, 97.27407121658325, 98.12061405181885, 98.96715688705444, 99.80134534835815, 100.63553380966187, 101.49041271209717, 102.34529161453247, 103.21530342102051, 104.08531522750854, 104.92928910255432, 105.7732629776001, 106.63769721984863, 107.50213146209717, 108.35325360298157, 109.20437574386597, 110.06642603874207, 110.92847633361816, 111.77265787124634, 112.61683940887451, 113.43930959701538, 114.26177978515625, 115.12421345710754, 115.98664712905884, 116.84673357009888, 117.70682001113892, 118.54172277450562, 119.37662553787231, 120.23371458053589, 121.09080362319946, 121.9345932006836, 122.77838277816772, 123.6389307975769, 124.49947881698608, 125.35926222801208, 126.21904563903809, 127.05543756484985, 127.89182949066162, 128.74171376228333, 129.59159803390503, 130.43428754806519, 131.27697706222534, 132.12138319015503, 132.96578931808472, 133.82261657714844, 134.67944383621216, 135.52452182769775, 136.36959981918335, 137.24146914482117, 138.11333847045898, 138.97045516967773, 139.82757186889648, 140.67956614494324, 141.53156042099, 142.3836395740509, 143.23571872711182, 144.0736391544342, 144.9115595817566, 145.749258518219, 146.5869574546814, 147.44112467765808, 148.29529190063477, 149.1405894756317, 149.98588705062866, 150.84559321403503, 151.7052993774414, 152.56853985786438, 153.43178033828735, 154.27476954460144, 155.11775875091553, 155.96539640426636, 156.8130340576172, 157.65880036354065, 158.5045666694641, 159.33443093299866, 160.1642951965332, 161.01744985580444, 161.87060451507568, 162.73479342460632, 163.59898233413696, 164.4356484413147, 165.27231454849243, 166.13329339027405, 166.99427223205566, 167.83401346206665, 168.67375469207764, 169.53089570999146, 170.38803672790527, 171.24186992645264, 172.095703125, 172.91831755638123, 173.74093198776245, 175.09194612503052, 176.44296026229858]
[25.816666666666666, 25.816666666666666, 37.55, 37.55, 42.55, 42.55, 53.583333333333336, 53.583333333333336, 59.5, 59.5, 61.38333333333333, 61.38333333333333, 69.5, 69.5, 69.28333333333333, 69.28333333333333, 72.13333333333334, 72.13333333333334, 73.83333333333333, 73.83333333333333, 74.65, 74.65, 75.56666666666666, 75.56666666666666, 76.83333333333333, 76.83333333333333, 77.83333333333333, 77.83333333333333, 77.25, 77.25, 78.51666666666667, 78.51666666666667, 79.25, 79.25, 80.58333333333333, 80.58333333333333, 81.31666666666666, 81.31666666666666, 81.33333333333333, 81.33333333333333, 81.98333333333333, 81.98333333333333, 82.0, 82.0, 82.93333333333334, 82.93333333333334, 83.51666666666667, 83.51666666666667, 83.2, 83.2, 83.46666666666667, 83.46666666666667, 83.73333333333333, 83.73333333333333, 83.51666666666667, 83.51666666666667, 83.96666666666667, 83.96666666666667, 82.6, 82.6, 83.95, 83.95, 84.33333333333333, 84.33333333333333, 84.3, 84.3, 84.48333333333333, 84.48333333333333, 84.18333333333334, 84.18333333333334, 84.56666666666666, 84.56666666666666, 85.03333333333333, 85.03333333333333, 85.53333333333333, 85.53333333333333, 85.3, 85.3, 85.6, 85.6, 85.2, 85.2, 85.5, 85.5, 85.35, 85.35, 86.51666666666667, 86.51666666666667, 86.7, 86.7, 86.63333333333334, 86.63333333333334, 86.46666666666667, 86.46666666666667, 86.28333333333333, 86.28333333333333, 86.61666666666666, 86.61666666666666, 86.81666666666666, 86.81666666666666, 86.55, 86.55, 86.81666666666666, 86.81666666666666, 87.15, 87.15, 87.13333333333334, 87.13333333333334, 86.45, 86.45, 87.05, 87.05, 86.98333333333333, 86.98333333333333, 86.61666666666666, 86.61666666666666, 87.43333333333334, 87.43333333333334, 87.25, 87.25, 87.11666666666666, 87.11666666666666, 87.5, 87.5, 87.83333333333333, 87.83333333333333, 87.96666666666667, 87.96666666666667, 87.95, 87.95, 87.71666666666667, 87.71666666666667, 88.31666666666666, 88.31666666666666, 88.28333333333333, 88.28333333333333, 87.91666666666667, 87.91666666666667, 87.73333333333333, 87.73333333333333, 87.48333333333333, 87.48333333333333, 87.86666666666666, 87.86666666666666, 88.31666666666666, 88.31666666666666, 88.06666666666666, 88.06666666666666, 88.35, 88.35, 88.3, 88.3, 88.25, 88.25, 88.1, 88.1, 88.38333333333334, 88.38333333333334, 87.91666666666667, 87.91666666666667, 87.5, 87.5, 87.48333333333333, 87.48333333333333, 87.86666666666666, 87.86666666666666, 87.38333333333334, 87.38333333333334, 88.35, 88.35, 88.18333333333334, 88.18333333333334, 88.36666666666666, 88.36666666666666, 88.33333333333333, 88.33333333333333, 88.5, 88.5, 88.93333333333334, 88.93333333333334, 88.48333333333333, 88.48333333333333, 88.16666666666667, 88.16666666666667, 88.31666666666666, 88.31666666666666, 88.11666666666666, 88.11666666666666, 87.8, 87.8, 88.23333333333333, 88.23333333333333, 87.38333333333334, 87.38333333333334, 88.61666666666666, 88.61666666666666, 89.05, 89.05, 88.85, 88.85, 88.95, 88.95]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 1, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.207, Test loss: 1.911, Test accuracy: 28.63
Round   0, Global train loss: 1.207, Global test loss: 2.294, Global test accuracy: 16.28
Round   1, Train loss: 1.007, Test loss: 1.687, Test accuracy: 37.52
Round   1, Global train loss: 1.007, Global test loss: 2.551, Global test accuracy: 12.08
Round   2, Train loss: 0.873, Test loss: 1.287, Test accuracy: 50.00
Round   2, Global train loss: 0.873, Global test loss: 2.249, Global test accuracy: 15.52
Round   3, Train loss: 0.812, Test loss: 1.223, Test accuracy: 52.68
Round   3, Global train loss: 0.812, Global test loss: 2.336, Global test accuracy: 15.00
Round   4, Train loss: 0.700, Test loss: 1.125, Test accuracy: 57.38
Round   4, Global train loss: 0.700, Global test loss: 2.292, Global test accuracy: 19.45
Round   5, Train loss: 0.737, Test loss: 1.170, Test accuracy: 58.37
Round   5, Global train loss: 0.737, Global test loss: 2.790, Global test accuracy: 16.08
Round   6, Train loss: 0.647, Test loss: 0.988, Test accuracy: 60.35
Round   6, Global train loss: 0.647, Global test loss: 2.221, Global test accuracy: 20.05
Round   7, Train loss: 0.759, Test loss: 0.823, Test accuracy: 67.53
Round   7, Global train loss: 0.759, Global test loss: 2.291, Global test accuracy: 14.60
Round   8, Train loss: 0.649, Test loss: 0.785, Test accuracy: 68.07
Round   8, Global train loss: 0.649, Global test loss: 2.234, Global test accuracy: 16.68
Round   9, Train loss: 0.586, Test loss: 0.847, Test accuracy: 68.15
Round   9, Global train loss: 0.586, Global test loss: 2.696, Global test accuracy: 15.00
Round  10, Train loss: 0.733, Test loss: 0.684, Test accuracy: 72.67
Round  10, Global train loss: 0.733, Global test loss: 2.338, Global test accuracy: 13.92
Round  11, Train loss: 0.520, Test loss: 0.661, Test accuracy: 73.85
Round  11, Global train loss: 0.520, Global test loss: 2.410, Global test accuracy: 18.18
Round  12, Train loss: 0.578, Test loss: 0.601, Test accuracy: 76.17
Round  12, Global train loss: 0.578, Global test loss: 2.304, Global test accuracy: 18.47
Round  13, Train loss: 0.444, Test loss: 0.575, Test accuracy: 77.75
Round  13, Global train loss: 0.444, Global test loss: 2.347, Global test accuracy: 19.10
Round  14, Train loss: 0.488, Test loss: 0.570, Test accuracy: 77.90
Round  14, Global train loss: 0.488, Global test loss: 2.363, Global test accuracy: 16.42
Round  15, Train loss: 0.501, Test loss: 0.574, Test accuracy: 77.65
Round  15, Global train loss: 0.501, Global test loss: 2.280, Global test accuracy: 15.52
Round  16, Train loss: 0.589, Test loss: 0.542, Test accuracy: 78.88
Round  16, Global train loss: 0.589, Global test loss: 2.206, Global test accuracy: 18.17
Round  17, Train loss: 0.506, Test loss: 0.538, Test accuracy: 79.18
Round  17, Global train loss: 0.506, Global test loss: 2.472, Global test accuracy: 18.63
Round  18, Train loss: 0.533, Test loss: 0.521, Test accuracy: 79.93
Round  18, Global train loss: 0.533, Global test loss: 2.363, Global test accuracy: 16.27
Round  19, Train loss: 0.464, Test loss: 0.528, Test accuracy: 80.00
Round  19, Global train loss: 0.464, Global test loss: 2.354, Global test accuracy: 15.40
Round  20, Train loss: 0.345, Test loss: 0.541, Test accuracy: 80.12
Round  20, Global train loss: 0.345, Global test loss: 2.358, Global test accuracy: 17.92
Round  21, Train loss: 0.356, Test loss: 0.548, Test accuracy: 80.17
Round  21, Global train loss: 0.356, Global test loss: 2.311, Global test accuracy: 17.25
Round  22, Train loss: 0.337, Test loss: 0.525, Test accuracy: 80.72
Round  22, Global train loss: 0.337, Global test loss: 2.235, Global test accuracy: 17.15
Round  23, Train loss: 0.368, Test loss: 0.528, Test accuracy: 80.85
Round  23, Global train loss: 0.368, Global test loss: 2.226, Global test accuracy: 17.28
Round  24, Train loss: 0.382, Test loss: 0.532, Test accuracy: 80.83
Round  24, Global train loss: 0.382, Global test loss: 2.354, Global test accuracy: 13.83
Round  25, Train loss: 0.356, Test loss: 0.544, Test accuracy: 80.68
Round  25, Global train loss: 0.356, Global test loss: 2.278, Global test accuracy: 19.70
Round  26, Train loss: 0.400, Test loss: 0.541, Test accuracy: 81.02
Round  26, Global train loss: 0.400, Global test loss: 2.610, Global test accuracy: 13.33
Round  27, Train loss: 0.380, Test loss: 0.520, Test accuracy: 81.75
Round  27, Global train loss: 0.380, Global test loss: 2.282, Global test accuracy: 17.82
Round  28, Train loss: 0.342, Test loss: 0.501, Test accuracy: 82.50
Round  28, Global train loss: 0.342, Global test loss: 2.298, Global test accuracy: 13.07
Round  29, Train loss: 0.317, Test loss: 0.521, Test accuracy: 82.22
Round  29, Global train loss: 0.317, Global test loss: 2.396, Global test accuracy: 18.87
Round  30, Train loss: 0.255, Test loss: 0.520, Test accuracy: 82.05
Round  30, Global train loss: 0.255, Global test loss: 2.277, Global test accuracy: 12.00
Round  31, Train loss: 0.352, Test loss: 0.508, Test accuracy: 82.57
Round  31, Global train loss: 0.352, Global test loss: 2.300, Global test accuracy: 19.28
Round  32, Train loss: 0.273, Test loss: 0.512, Test accuracy: 82.45
Round  32, Global train loss: 0.273, Global test loss: 2.755, Global test accuracy: 13.43
Round  33, Train loss: 0.238, Test loss: 0.526, Test accuracy: 82.68
Round  33, Global train loss: 0.238, Global test loss: 2.271, Global test accuracy: 20.27
Round  34, Train loss: 0.276, Test loss: 0.529, Test accuracy: 82.60
Round  34, Global train loss: 0.276, Global test loss: 2.509, Global test accuracy: 15.32
Round  35, Train loss: 0.277, Test loss: 0.520, Test accuracy: 82.68
Round  35, Global train loss: 0.277, Global test loss: 2.220, Global test accuracy: 16.57
Round  36, Train loss: 0.258, Test loss: 0.512, Test accuracy: 82.82
Round  36, Global train loss: 0.258, Global test loss: 2.351, Global test accuracy: 14.55
Round  37, Train loss: 0.237, Test loss: 0.525, Test accuracy: 82.77
Round  37, Global train loss: 0.237, Global test loss: 2.676, Global test accuracy: 15.55
Round  38, Train loss: 0.184, Test loss: 0.551, Test accuracy: 82.43
Round  38, Global train loss: 0.184, Global test loss: 2.233, Global test accuracy: 15.75
Round  39, Train loss: 0.242, Test loss: 0.559, Test accuracy: 82.82
Round  39, Global train loss: 0.242, Global test loss: 2.418, Global test accuracy: 14.55
Round  40, Train loss: 0.207, Test loss: 0.571, Test accuracy: 82.98
Round  40, Global train loss: 0.207, Global test loss: 2.402, Global test accuracy: 17.75
Round  41, Train loss: 0.185, Test loss: 0.584, Test accuracy: 82.57
Round  41, Global train loss: 0.185, Global test loss: 2.308, Global test accuracy: 19.05
Round  42, Train loss: 0.237, Test loss: 0.566, Test accuracy: 83.48
Round  42, Global train loss: 0.237, Global test loss: 2.346, Global test accuracy: 16.87
Round  43, Train loss: 0.195, Test loss: 0.564, Test accuracy: 83.63
Round  43, Global train loss: 0.195, Global test loss: 2.309, Global test accuracy: 19.30
Round  44, Train loss: 0.211, Test loss: 0.554, Test accuracy: 83.67
Round  44, Global train loss: 0.211, Global test loss: 2.425, Global test accuracy: 12.62
Round  45, Train loss: 0.171, Test loss: 0.568, Test accuracy: 83.78
Round  45, Global train loss: 0.171, Global test loss: 2.248, Global test accuracy: 15.02
Round  46, Train loss: 0.206, Test loss: 0.583, Test accuracy: 83.80
Round  46, Global train loss: 0.206, Global test loss: 2.378, Global test accuracy: 13.77
Round  47, Train loss: 0.154, Test loss: 0.603, Test accuracy: 83.73
Round  47, Global train loss: 0.154, Global test loss: 2.274, Global test accuracy: 19.23
Round  48, Train loss: 0.156, Test loss: 0.598, Test accuracy: 84.03
Round  48, Global train loss: 0.156, Global test loss: 2.385, Global test accuracy: 14.80
Round  49, Train loss: 0.163, Test loss: 0.601, Test accuracy: 83.77
Round  49, Global train loss: 0.163, Global test loss: 2.365, Global test accuracy: 17.08
Round  50, Train loss: 0.173, Test loss: 0.592, Test accuracy: 83.92
Round  50, Global train loss: 0.173, Global test loss: 2.340, Global test accuracy: 17.78
Round  51, Train loss: 0.222, Test loss: 0.587, Test accuracy: 83.87
Round  51, Global train loss: 0.222, Global test loss: 2.342, Global test accuracy: 16.03
Round  52, Train loss: 0.170, Test loss: 0.608, Test accuracy: 83.38
Round  52, Global train loss: 0.170, Global test loss: 2.272, Global test accuracy: 16.92
Round  53, Train loss: 0.167, Test loss: 0.590, Test accuracy: 84.07
Round  53, Global train loss: 0.167, Global test loss: 2.238, Global test accuracy: 15.42
Round  54, Train loss: 0.185, Test loss: 0.597, Test accuracy: 83.82
Round  54, Global train loss: 0.185, Global test loss: 2.217, Global test accuracy: 20.05
Round  55, Train loss: 0.137, Test loss: 0.593, Test accuracy: 83.93
Round  55, Global train loss: 0.137, Global test loss: 2.521, Global test accuracy: 17.45
Round  56, Train loss: 0.092, Test loss: 0.599, Test accuracy: 84.15
Round  56, Global train loss: 0.092, Global test loss: 2.289, Global test accuracy: 18.13
Round  57, Train loss: 0.165, Test loss: 0.611, Test accuracy: 83.87
Round  57, Global train loss: 0.165, Global test loss: 2.279, Global test accuracy: 16.92
Round  58, Train loss: 0.118, Test loss: 0.574, Test accuracy: 84.63
Round  58, Global train loss: 0.118, Global test loss: 2.241, Global test accuracy: 17.67
Round  59, Train loss: 0.113, Test loss: 0.580, Test accuracy: 84.52
Round  59, Global train loss: 0.113, Global test loss: 2.247, Global test accuracy: 13.75
Round  60, Train loss: 0.082, Test loss: 0.633, Test accuracy: 84.10
Round  60, Global train loss: 0.082, Global test loss: 2.308, Global test accuracy: 18.42
Round  61, Train loss: 0.106, Test loss: 0.636, Test accuracy: 83.85
Round  61, Global train loss: 0.106, Global test loss: 2.434, Global test accuracy: 14.23
Round  62, Train loss: 0.113, Test loss: 0.610, Test accuracy: 84.28
Round  62, Global train loss: 0.113, Global test loss: 2.283, Global test accuracy: 14.80
Round  63, Train loss: 0.128, Test loss: 0.620, Test accuracy: 84.30
Round  63, Global train loss: 0.128, Global test loss: 2.395, Global test accuracy: 13.55
Round  64, Train loss: 0.100, Test loss: 0.620, Test accuracy: 84.15
Round  64, Global train loss: 0.100, Global test loss: 2.234, Global test accuracy: 18.63
Round  65, Train loss: 0.073, Test loss: 0.648, Test accuracy: 83.78
Round  65, Global train loss: 0.073, Global test loss: 2.270, Global test accuracy: 16.58
Round  66, Train loss: 0.131, Test loss: 0.647, Test accuracy: 83.90
Round  66, Global train loss: 0.131, Global test loss: 2.251, Global test accuracy: 17.37
Round  67, Train loss: 0.145, Test loss: 0.647, Test accuracy: 83.67
Round  67, Global train loss: 0.145, Global test loss: 2.363, Global test accuracy: 13.90
Round  68, Train loss: 0.087, Test loss: 0.655, Test accuracy: 84.15
Round  68, Global train loss: 0.087, Global test loss: 2.294, Global test accuracy: 12.43
Round  69, Train loss: 0.122, Test loss: 0.668, Test accuracy: 84.48
Round  69, Global train loss: 0.122, Global test loss: 2.315, Global test accuracy: 17.15
Round  70, Train loss: 0.090, Test loss: 0.654, Test accuracy: 85.08
Round  70, Global train loss: 0.090, Global test loss: 2.301, Global test accuracy: 16.60
Round  71, Train loss: 0.109, Test loss: 0.655, Test accuracy: 85.15
Round  71, Global train loss: 0.109, Global test loss: 2.284, Global test accuracy: 14.30
Round  72, Train loss: 0.101, Test loss: 0.680, Test accuracy: 84.48
Round  72, Global train loss: 0.101, Global test loss: 2.220, Global test accuracy: 19.98
Round  73, Train loss: 0.074, Test loss: 0.698, Test accuracy: 84.63
Round  73, Global train loss: 0.074, Global test loss: 2.268, Global test accuracy: 11.58
Round  74, Train loss: 0.107, Test loss: 0.710, Test accuracy: 84.60
Round  74, Global train loss: 0.107, Global test loss: 2.249, Global test accuracy: 15.52
Round  75, Train loss: 0.074, Test loss: 0.719, Test accuracy: 84.43
Round  75, Global train loss: 0.074, Global test loss: 2.255, Global test accuracy: 15.08
Round  76, Train loss: 0.089, Test loss: 0.692, Test accuracy: 84.42
Round  76, Global train loss: 0.089, Global test loss: 2.552, Global test accuracy: 18.23
Round  77, Train loss: 0.124, Test loss: 0.722, Test accuracy: 83.85
Round  77, Global train loss: 0.124, Global test loss: 2.271, Global test accuracy: 15.80
Round  78, Train loss: 0.085, Test loss: 0.680, Test accuracy: 84.33
Round  78, Global train loss: 0.085, Global test loss: 2.347, Global test accuracy: 18.30
Round  79, Train loss: 0.096, Test loss: 0.688, Test accuracy: 84.33
Round  79, Global train loss: 0.096, Global test loss: 2.270, Global test accuracy: 15.82
Round  80, Train loss: 0.093, Test loss: 0.685, Test accuracy: 84.52
Round  80, Global train loss: 0.093, Global test loss: 2.272, Global test accuracy: 15.58
Round  81, Train loss: 0.090, Test loss: 0.702, Test accuracy: 84.63
Round  81, Global train loss: 0.090, Global test loss: 2.285, Global test accuracy: 14.33
Round  82, Train loss: 0.099, Test loss: 0.715, Test accuracy: 84.65
Round  82, Global train loss: 0.099, Global test loss: 2.383, Global test accuracy: 11.67
Round  83, Train loss: 0.082, Test loss: 0.689, Test accuracy: 85.35
Round  83, Global train loss: 0.082, Global test loss: 2.370, Global test accuracy: 15.30
Round  84, Train loss: 0.065, Test loss: 0.695, Test accuracy: 85.38
Round  84, Global train loss: 0.065, Global test loss: 2.936, Global test accuracy: 13.52
Round  85, Train loss: 0.079, Test loss: 0.710, Test accuracy: 85.47
Round  85, Global train loss: 0.079, Global test loss: 2.256, Global test accuracy: 18.45
Round  86, Train loss: 0.069, Test loss: 0.727, Test accuracy: 85.27
Round  86, Global train loss: 0.069, Global test loss: 2.296, Global test accuracy: 19.02
Round  87, Train loss: 0.077, Test loss: 0.730, Test accuracy: 85.32
Round  87, Global train loss: 0.077, Global test loss: 2.366, Global test accuracy: 17.70
Round  88, Train loss: 0.070, Test loss: 0.712, Test accuracy: 85.25
Round  88, Global train loss: 0.070, Global test loss: 2.330, Global test accuracy: 11.73
Round  89, Train loss: 0.045, Test loss: 0.719, Test accuracy: 85.27
Round  89, Global train loss: 0.045, Global test loss: 2.243, Global test accuracy: 15.30
Round  90, Train loss: 0.070, Test loss: 0.727, Test accuracy: 85.25
Round  90, Global train loss: 0.070, Global test loss: 2.295, Global test accuracy: 18.80
Round  91, Train loss: 0.060, Test loss: 0.724, Test accuracy: 85.58
Round  91, Global train loss: 0.060, Global test loss: 2.328, Global test accuracy: 16.13
Round  92, Train loss: 0.056, Test loss: 0.723, Test accuracy: 85.65
Round  92, Global train loss: 0.056, Global test loss: 2.227, Global test accuracy: 16.93
Round  93, Train loss: 0.079, Test loss: 0.740, Test accuracy: 85.40
Round  93, Global train loss: 0.079, Global test loss: 2.210, Global test accuracy: 19.27
Round  94, Train loss: 0.042, Test loss: 0.743, Test accuracy: 85.22
Round  94, Global train loss: 0.042, Global test loss: 2.321, Global test accuracy: 16.95
Round  95, Train loss: 0.058, Test loss: 0.701, Test accuracy: 85.17
Round  95, Global train loss: 0.058, Global test loss: 2.345, Global test accuracy: 18.57
Round  96, Train loss: 0.079, Test loss: 0.706, Test accuracy: 84.97
Round  96, Global train loss: 0.079, Global test loss: 2.304, Global test accuracy: 13.72
Round  97, Train loss: 0.067, Test loss: 0.721, Test accuracy: 85.15
Round  97, Global train loss: 0.067, Global test loss: 2.415, Global test accuracy: 16.38
Round  98, Train loss: 0.065, Test loss: 0.710, Test accuracy: 85.35
Round  98, Global train loss: 0.065, Global test loss: 2.272, Global test accuracy: 16.93
Round  99, Train loss: 0.054, Test loss: 0.694, Test accuracy: 85.60
Round  99, Global train loss: 0.054, Global test loss: 2.239, Global test accuracy: 18.73
Final Round, Train loss: 0.051, Test loss: 0.783, Test accuracy: 85.03
Final Round, Global train loss: 0.051, Global test loss: 2.239, Global test accuracy: 18.73
Average accuracy final 10 rounds: 85.33333333333334 

Average global accuracy final 10 rounds: 17.241666666666667 

997.6237621307373
[1.0071940422058105, 2.014388084411621, 2.714311361312866, 3.4142346382141113, 4.117577791213989, 4.820920944213867, 5.5262510776519775, 6.231581211090088, 6.936088800430298, 7.640596389770508, 8.337042808532715, 9.033489227294922, 9.734596252441406, 10.43570327758789, 11.13173222541809, 11.827761173248291, 12.527111291885376, 13.226461410522461, 13.924545526504517, 14.622629642486572, 15.306109189987183, 15.989588737487793, 16.6966814994812, 17.40377426147461, 18.108728885650635, 18.81368350982666, 19.51765513420105, 20.22162675857544, 20.926756381988525, 21.63188600540161, 22.33480191230774, 23.037717819213867, 23.74306344985962, 24.44840908050537, 25.146917581558228, 25.845426082611084, 26.56146478652954, 27.277503490447998, 27.983553409576416, 28.689603328704834, 29.395134687423706, 30.100666046142578, 30.803341388702393, 31.506016731262207, 32.19647812843323, 32.88693952560425, 33.58278965950012, 34.278639793395996, 34.96778583526611, 35.65693187713623, 36.35948443412781, 37.062036991119385, 37.762967348098755, 38.463897705078125, 39.16497302055359, 39.86604833602905, 40.567556619644165, 41.26906490325928, 41.96337103843689, 42.6576771736145, 43.347816467285156, 44.03795576095581, 44.72625541687012, 45.414555072784424, 46.111632108688354, 46.808709144592285, 47.49498987197876, 48.181270599365234, 48.87139105796814, 49.561511516571045, 50.2679603099823, 50.974409103393555, 51.661776304244995, 52.349143505096436, 53.04601240158081, 53.742881298065186, 54.43515920639038, 55.127437114715576, 55.83220601081848, 56.53697490692139, 57.227309465408325, 57.917644023895264, 58.61054062843323, 59.30343723297119, 60.00141167640686, 60.69938611984253, 61.383755683898926, 62.06812524795532, 62.77069640159607, 63.473267555236816, 64.15786123275757, 64.84245491027832, 65.58926653862, 66.33607816696167, 67.04791688919067, 67.75975561141968, 68.45540881156921, 69.15106201171875, 69.84873461723328, 70.5464072227478, 71.25369882583618, 71.96099042892456, 72.66612029075623, 73.37125015258789, 74.07560443878174, 74.77995872497559, 75.46476221084595, 76.14956569671631, 76.84599161148071, 77.54241752624512, 78.24171352386475, 78.94100952148438, 79.63849306106567, 80.33597660064697, 81.03600668907166, 81.73603677749634, 82.42776942253113, 83.11950206756592, 83.82489514350891, 84.5302882194519, 85.25563383102417, 85.98097944259644, 86.6782603263855, 87.37554121017456, 88.07465028762817, 88.77375936508179, 89.47974038124084, 90.1857213973999, 90.88967180252075, 91.5936222076416, 92.29273676872253, 92.99185132980347, 93.695729970932, 94.39960861206055, 95.10110831260681, 95.80260801315308, 96.51284313201904, 97.22307825088501, 97.93345236778259, 98.64382648468018, 99.34371399879456, 100.04360151290894, 100.75057482719421, 101.45754814147949, 102.1545512676239, 102.85155439376831, 103.54797601699829, 104.24439764022827, 104.94240951538086, 105.64042139053345, 106.34657382965088, 107.05272626876831, 107.75560879707336, 108.45849132537842, 109.15761804580688, 109.85674476623535, 110.56259417533875, 111.26844358444214, 111.97376155853271, 112.67907953262329, 113.38291335105896, 114.08674716949463, 114.79298949241638, 115.49923181533813, 116.19808149337769, 116.89693117141724, 117.60929226875305, 118.32165336608887, 119.01927351951599, 119.71689367294312, 120.41734385490417, 121.11779403686523, 121.81815218925476, 122.51851034164429, 123.22087240219116, 123.92323446273804, 124.63001656532288, 125.33679866790771, 126.03971362113953, 126.74262857437134, 127.44766879081726, 128.15270900726318, 128.85120129585266, 129.54969358444214, 130.25664973258972, 130.9636058807373, 131.6583969593048, 132.35318803787231, 133.0546383857727, 133.7560887336731, 134.46453595161438, 135.17298316955566, 135.86696791648865, 136.56095266342163, 137.26004076004028, 137.95912885665894, 138.65681552886963, 139.35450220108032, 140.05657982826233, 140.75865745544434, 142.16133880615234, 143.56402015686035]
[28.633333333333333, 28.633333333333333, 37.516666666666666, 37.516666666666666, 50.0, 50.0, 52.68333333333333, 52.68333333333333, 57.38333333333333, 57.38333333333333, 58.36666666666667, 58.36666666666667, 60.35, 60.35, 67.53333333333333, 67.53333333333333, 68.06666666666666, 68.06666666666666, 68.15, 68.15, 72.66666666666667, 72.66666666666667, 73.85, 73.85, 76.16666666666667, 76.16666666666667, 77.75, 77.75, 77.9, 77.9, 77.65, 77.65, 78.88333333333334, 78.88333333333334, 79.18333333333334, 79.18333333333334, 79.93333333333334, 79.93333333333334, 80.0, 80.0, 80.11666666666666, 80.11666666666666, 80.16666666666667, 80.16666666666667, 80.71666666666667, 80.71666666666667, 80.85, 80.85, 80.83333333333333, 80.83333333333333, 80.68333333333334, 80.68333333333334, 81.01666666666667, 81.01666666666667, 81.75, 81.75, 82.5, 82.5, 82.21666666666667, 82.21666666666667, 82.05, 82.05, 82.56666666666666, 82.56666666666666, 82.45, 82.45, 82.68333333333334, 82.68333333333334, 82.6, 82.6, 82.68333333333334, 82.68333333333334, 82.81666666666666, 82.81666666666666, 82.76666666666667, 82.76666666666667, 82.43333333333334, 82.43333333333334, 82.81666666666666, 82.81666666666666, 82.98333333333333, 82.98333333333333, 82.56666666666666, 82.56666666666666, 83.48333333333333, 83.48333333333333, 83.63333333333334, 83.63333333333334, 83.66666666666667, 83.66666666666667, 83.78333333333333, 83.78333333333333, 83.8, 83.8, 83.73333333333333, 83.73333333333333, 84.03333333333333, 84.03333333333333, 83.76666666666667, 83.76666666666667, 83.91666666666667, 83.91666666666667, 83.86666666666666, 83.86666666666666, 83.38333333333334, 83.38333333333334, 84.06666666666666, 84.06666666666666, 83.81666666666666, 83.81666666666666, 83.93333333333334, 83.93333333333334, 84.15, 84.15, 83.86666666666666, 83.86666666666666, 84.63333333333334, 84.63333333333334, 84.51666666666667, 84.51666666666667, 84.1, 84.1, 83.85, 83.85, 84.28333333333333, 84.28333333333333, 84.3, 84.3, 84.15, 84.15, 83.78333333333333, 83.78333333333333, 83.9, 83.9, 83.66666666666667, 83.66666666666667, 84.15, 84.15, 84.48333333333333, 84.48333333333333, 85.08333333333333, 85.08333333333333, 85.15, 85.15, 84.48333333333333, 84.48333333333333, 84.63333333333334, 84.63333333333334, 84.6, 84.6, 84.43333333333334, 84.43333333333334, 84.41666666666667, 84.41666666666667, 83.85, 83.85, 84.33333333333333, 84.33333333333333, 84.33333333333333, 84.33333333333333, 84.51666666666667, 84.51666666666667, 84.63333333333334, 84.63333333333334, 84.65, 84.65, 85.35, 85.35, 85.38333333333334, 85.38333333333334, 85.46666666666667, 85.46666666666667, 85.26666666666667, 85.26666666666667, 85.31666666666666, 85.31666666666666, 85.25, 85.25, 85.26666666666667, 85.26666666666667, 85.25, 85.25, 85.58333333333333, 85.58333333333333, 85.65, 85.65, 85.4, 85.4, 85.21666666666667, 85.21666666666667, 85.16666666666667, 85.16666666666667, 84.96666666666667, 84.96666666666667, 85.15, 85.15, 85.35, 85.35, 85.6, 85.6, 85.03333333333333, 85.03333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.224, Test loss: 1.972, Test accuracy: 21.07
Round   0, Global train loss: 1.224, Global test loss: 2.306, Global test accuracy: 10.00
Round   1, Train loss: 1.057, Test loss: 1.840, Test accuracy: 32.12
Round   1, Global train loss: 1.057, Global test loss: 2.413, Global test accuracy: 11.18
Round   2, Train loss: 1.021, Test loss: 1.423, Test accuracy: 47.60
Round   2, Global train loss: 1.021, Global test loss: 2.206, Global test accuracy: 20.40
Round   3, Train loss: 0.980, Test loss: 1.188, Test accuracy: 54.08
Round   3, Global train loss: 0.980, Global test loss: 2.233, Global test accuracy: 19.18
Round   4, Train loss: 0.939, Test loss: 1.079, Test accuracy: 57.93
Round   4, Global train loss: 0.939, Global test loss: 2.333, Global test accuracy: 17.72
Round   5, Train loss: 0.901, Test loss: 1.000, Test accuracy: 60.73
Round   5, Global train loss: 0.901, Global test loss: 2.300, Global test accuracy: 20.55
Round   6, Train loss: 0.870, Test loss: 0.975, Test accuracy: 63.82
Round   6, Global train loss: 0.870, Global test loss: 2.675, Global test accuracy: 17.83
Round   7, Train loss: 0.840, Test loss: 0.948, Test accuracy: 65.40
Round   7, Global train loss: 0.840, Global test loss: 2.316, Global test accuracy: 23.15
Round   8, Train loss: 0.871, Test loss: 0.863, Test accuracy: 67.93
Round   8, Global train loss: 0.871, Global test loss: 2.140, Global test accuracy: 25.52
Round   9, Train loss: 0.767, Test loss: 0.971, Test accuracy: 66.83
Round   9, Global train loss: 0.767, Global test loss: 2.575, Global test accuracy: 24.42
Round  10, Train loss: 0.845, Test loss: 0.788, Test accuracy: 70.13
Round  10, Global train loss: 0.845, Global test loss: 2.219, Global test accuracy: 21.55
Round  11, Train loss: 0.725, Test loss: 0.781, Test accuracy: 71.78
Round  11, Global train loss: 0.725, Global test loss: 2.293, Global test accuracy: 23.88
Round  12, Train loss: 0.679, Test loss: 0.779, Test accuracy: 72.08
Round  12, Global train loss: 0.679, Global test loss: 2.388, Global test accuracy: 23.73
Round  13, Train loss: 0.691, Test loss: 0.587, Test accuracy: 77.32
Round  13, Global train loss: 0.691, Global test loss: 2.171, Global test accuracy: 26.90
Round  14, Train loss: 0.672, Test loss: 0.579, Test accuracy: 77.43
Round  14, Global train loss: 0.672, Global test loss: 2.173, Global test accuracy: 23.88
Round  15, Train loss: 0.648, Test loss: 0.554, Test accuracy: 79.00
Round  15, Global train loss: 0.648, Global test loss: 2.324, Global test accuracy: 20.60
Round  16, Train loss: 0.678, Test loss: 0.526, Test accuracy: 80.28
Round  16, Global train loss: 0.678, Global test loss: 2.591, Global test accuracy: 20.27
Round  17, Train loss: 0.673, Test loss: 0.527, Test accuracy: 81.03
Round  17, Global train loss: 0.673, Global test loss: 2.456, Global test accuracy: 23.80
Round  18, Train loss: 0.612, Test loss: 0.518, Test accuracy: 81.13
Round  18, Global train loss: 0.612, Global test loss: 2.624, Global test accuracy: 22.35
Round  19, Train loss: 0.595, Test loss: 0.505, Test accuracy: 81.63
Round  19, Global train loss: 0.595, Global test loss: 2.344, Global test accuracy: 22.43
Round  20, Train loss: 0.601, Test loss: 0.513, Test accuracy: 80.88
Round  20, Global train loss: 0.601, Global test loss: 2.462, Global test accuracy: 26.28
Round  21, Train loss: 0.672, Test loss: 0.528, Test accuracy: 80.40
Round  21, Global train loss: 0.672, Global test loss: 2.208, Global test accuracy: 26.70
Round  22, Train loss: 0.606, Test loss: 0.515, Test accuracy: 81.37
Round  22, Global train loss: 0.606, Global test loss: 2.304, Global test accuracy: 26.42
Round  23, Train loss: 0.578, Test loss: 0.498, Test accuracy: 81.73
Round  23, Global train loss: 0.578, Global test loss: 2.268, Global test accuracy: 22.60
Round  24, Train loss: 0.581, Test loss: 0.486, Test accuracy: 82.12
Round  24, Global train loss: 0.581, Global test loss: 2.333, Global test accuracy: 26.15
Round  25, Train loss: 0.524, Test loss: 0.470, Test accuracy: 82.58
Round  25, Global train loss: 0.524, Global test loss: 2.457, Global test accuracy: 18.92
Round  26, Train loss: 0.516, Test loss: 0.469, Test accuracy: 82.48
Round  26, Global train loss: 0.516, Global test loss: 2.329, Global test accuracy: 27.57
Round  27, Train loss: 0.536, Test loss: 0.452, Test accuracy: 83.72
Round  27, Global train loss: 0.536, Global test loss: 2.313, Global test accuracy: 26.70
Round  28, Train loss: 0.495, Test loss: 0.463, Test accuracy: 82.67
Round  28, Global train loss: 0.495, Global test loss: 2.400, Global test accuracy: 22.67
Round  29, Train loss: 0.499, Test loss: 0.472, Test accuracy: 82.13
Round  29, Global train loss: 0.499, Global test loss: 2.383, Global test accuracy: 20.33
Round  30, Train loss: 0.504, Test loss: 0.464, Test accuracy: 82.73
Round  30, Global train loss: 0.504, Global test loss: 2.245, Global test accuracy: 25.75
Round  31, Train loss: 0.474, Test loss: 0.476, Test accuracy: 82.62
Round  31, Global train loss: 0.474, Global test loss: 2.516, Global test accuracy: 21.80
Round  32, Train loss: 0.424, Test loss: 0.476, Test accuracy: 82.80
Round  32, Global train loss: 0.424, Global test loss: 2.573, Global test accuracy: 24.60
Round  33, Train loss: 0.463, Test loss: 0.471, Test accuracy: 83.03
Round  33, Global train loss: 0.463, Global test loss: 2.229, Global test accuracy: 23.72
Round  34, Train loss: 0.440, Test loss: 0.449, Test accuracy: 83.65
Round  34, Global train loss: 0.440, Global test loss: 2.381, Global test accuracy: 23.28
Round  35, Train loss: 0.406, Test loss: 0.424, Test accuracy: 84.67
Round  35, Global train loss: 0.406, Global test loss: 2.581, Global test accuracy: 22.13
Round  36, Train loss: 0.395, Test loss: 0.437, Test accuracy: 84.18
Round  36, Global train loss: 0.395, Global test loss: 2.484, Global test accuracy: 24.60
Round  37, Train loss: 0.466, Test loss: 0.434, Test accuracy: 84.83
Round  37, Global train loss: 0.466, Global test loss: 2.513, Global test accuracy: 28.45
Round  38, Train loss: 0.392, Test loss: 0.438, Test accuracy: 84.57
Round  38, Global train loss: 0.392, Global test loss: 2.428, Global test accuracy: 28.13
Round  39, Train loss: 0.446, Test loss: 0.444, Test accuracy: 84.48
Round  39, Global train loss: 0.446, Global test loss: 2.460, Global test accuracy: 30.33
Round  40, Train loss: 0.426, Test loss: 0.434, Test accuracy: 85.08
Round  40, Global train loss: 0.426, Global test loss: 2.417, Global test accuracy: 26.95
Round  41, Train loss: 0.395, Test loss: 0.433, Test accuracy: 85.47
Round  41, Global train loss: 0.395, Global test loss: 2.508, Global test accuracy: 25.28
Round  42, Train loss: 0.431, Test loss: 0.420, Test accuracy: 85.90
Round  42, Global train loss: 0.431, Global test loss: 2.613, Global test accuracy: 26.72
Round  43, Train loss: 0.366, Test loss: 0.415, Test accuracy: 86.12
Round  43, Global train loss: 0.366, Global test loss: 2.291, Global test accuracy: 29.32
Round  44, Train loss: 0.386, Test loss: 0.432, Test accuracy: 85.62
Round  44, Global train loss: 0.386, Global test loss: 2.427, Global test accuracy: 23.95
Round  45, Train loss: 0.354, Test loss: 0.431, Test accuracy: 85.63
Round  45, Global train loss: 0.354, Global test loss: 2.447, Global test accuracy: 28.35
Round  46, Train loss: 0.337, Test loss: 0.433, Test accuracy: 85.63
Round  46, Global train loss: 0.337, Global test loss: 2.593, Global test accuracy: 22.53
Round  47, Train loss: 0.330, Test loss: 0.432, Test accuracy: 85.98
Round  47, Global train loss: 0.330, Global test loss: 2.424, Global test accuracy: 25.83
Round  48, Train loss: 0.366, Test loss: 0.427, Test accuracy: 86.35
Round  48, Global train loss: 0.366, Global test loss: 2.821, Global test accuracy: 30.48
Round  49, Train loss: 0.364, Test loss: 0.433, Test accuracy: 86.22
Round  49, Global train loss: 0.364, Global test loss: 2.417, Global test accuracy: 28.58
Round  50, Train loss: 0.366, Test loss: 0.426, Test accuracy: 86.32
Round  50, Global train loss: 0.366, Global test loss: 2.580, Global test accuracy: 28.23
Round  51, Train loss: 0.409, Test loss: 0.434, Test accuracy: 85.93
Round  51, Global train loss: 0.409, Global test loss: 2.943, Global test accuracy: 26.02
Round  52, Train loss: 0.336, Test loss: 0.438, Test accuracy: 85.78
Round  52, Global train loss: 0.336, Global test loss: 2.394, Global test accuracy: 31.73
Round  53, Train loss: 0.323, Test loss: 0.438, Test accuracy: 85.83
Round  53, Global train loss: 0.323, Global test loss: 2.604, Global test accuracy: 20.37
Round  54, Train loss: 0.334, Test loss: 0.415, Test accuracy: 86.68
Round  54, Global train loss: 0.334, Global test loss: 2.520, Global test accuracy: 28.82
Round  55, Train loss: 0.291, Test loss: 0.408, Test accuracy: 86.95
Round  55, Global train loss: 0.291, Global test loss: 2.696, Global test accuracy: 22.87
Round  56, Train loss: 0.315, Test loss: 0.402, Test accuracy: 86.92
Round  56, Global train loss: 0.315, Global test loss: 2.570, Global test accuracy: 26.20
Round  57, Train loss: 0.333, Test loss: 0.420, Test accuracy: 86.22
Round  57, Global train loss: 0.333, Global test loss: 2.673, Global test accuracy: 24.88
Round  58, Train loss: 0.346, Test loss: 0.436, Test accuracy: 86.23
Round  58, Global train loss: 0.346, Global test loss: 2.557, Global test accuracy: 29.65
Round  59, Train loss: 0.289, Test loss: 0.443, Test accuracy: 86.28
Round  59, Global train loss: 0.289, Global test loss: 2.653, Global test accuracy: 28.82
Round  60, Train loss: 0.356, Test loss: 0.424, Test accuracy: 86.95
Round  60, Global train loss: 0.356, Global test loss: 2.786, Global test accuracy: 29.07
Round  61, Train loss: 0.312, Test loss: 0.435, Test accuracy: 86.88
Round  61, Global train loss: 0.312, Global test loss: 2.688, Global test accuracy: 21.52
Round  62, Train loss: 0.290, Test loss: 0.434, Test accuracy: 86.40
Round  62, Global train loss: 0.290, Global test loss: 2.476, Global test accuracy: 26.27
Round  63, Train loss: 0.301, Test loss: 0.445, Test accuracy: 86.00
Round  63, Global train loss: 0.301, Global test loss: 2.447, Global test accuracy: 22.90
Round  64, Train loss: 0.313, Test loss: 0.423, Test accuracy: 86.33
Round  64, Global train loss: 0.313, Global test loss: 2.446, Global test accuracy: 28.02
Round  65, Train loss: 0.309, Test loss: 0.419, Test accuracy: 86.37
Round  65, Global train loss: 0.309, Global test loss: 2.444, Global test accuracy: 26.07
Round  66, Train loss: 0.256, Test loss: 0.429, Test accuracy: 85.93
Round  66, Global train loss: 0.256, Global test loss: 2.737, Global test accuracy: 23.77
Round  67, Train loss: 0.297, Test loss: 0.420, Test accuracy: 86.12
Round  67, Global train loss: 0.297, Global test loss: 2.409, Global test accuracy: 29.47
Round  68, Train loss: 0.314, Test loss: 0.449, Test accuracy: 85.85
Round  68, Global train loss: 0.314, Global test loss: 2.499, Global test accuracy: 29.83
Round  69, Train loss: 0.252, Test loss: 0.457, Test accuracy: 85.87
Round  69, Global train loss: 0.252, Global test loss: 3.095, Global test accuracy: 26.05
Round  70, Train loss: 0.286, Test loss: 0.432, Test accuracy: 86.85
Round  70, Global train loss: 0.286, Global test loss: 2.623, Global test accuracy: 26.95
Round  71, Train loss: 0.257, Test loss: 0.398, Test accuracy: 87.47
Round  71, Global train loss: 0.257, Global test loss: 2.609, Global test accuracy: 29.55
Round  72, Train loss: 0.295, Test loss: 0.414, Test accuracy: 86.97
Round  72, Global train loss: 0.295, Global test loss: 2.466, Global test accuracy: 30.88
Round  73, Train loss: 0.242, Test loss: 0.409, Test accuracy: 87.43
Round  73, Global train loss: 0.242, Global test loss: 2.624, Global test accuracy: 27.35
Round  74, Train loss: 0.312, Test loss: 0.428, Test accuracy: 87.30
Round  74, Global train loss: 0.312, Global test loss: 2.446, Global test accuracy: 31.53
Round  75, Train loss: 0.249, Test loss: 0.414, Test accuracy: 87.42
Round  75, Global train loss: 0.249, Global test loss: 2.937, Global test accuracy: 26.57
Round  76, Train loss: 0.280, Test loss: 0.400, Test accuracy: 87.88
Round  76, Global train loss: 0.280, Global test loss: 2.438, Global test accuracy: 31.62
Round  77, Train loss: 0.280, Test loss: 0.403, Test accuracy: 87.52
Round  77, Global train loss: 0.280, Global test loss: 2.503, Global test accuracy: 30.07
Round  78, Train loss: 0.250, Test loss: 0.420, Test accuracy: 87.07
Round  78, Global train loss: 0.250, Global test loss: 2.549, Global test accuracy: 27.38
Round  79, Train loss: 0.249, Test loss: 0.408, Test accuracy: 87.50
Round  79, Global train loss: 0.249, Global test loss: 2.553, Global test accuracy: 28.75
Round  80, Train loss: 0.225, Test loss: 0.421, Test accuracy: 87.38
Round  80, Global train loss: 0.225, Global test loss: 2.675, Global test accuracy: 24.13
Round  81, Train loss: 0.244, Test loss: 0.434, Test accuracy: 87.38
Round  81, Global train loss: 0.244, Global test loss: 2.504, Global test accuracy: 32.23
Round  82, Train loss: 0.198, Test loss: 0.436, Test accuracy: 87.22
Round  82, Global train loss: 0.198, Global test loss: 2.641, Global test accuracy: 25.38
Round  83, Train loss: 0.258, Test loss: 0.432, Test accuracy: 87.25
Round  83, Global train loss: 0.258, Global test loss: 2.695, Global test accuracy: 23.68
Round  84, Train loss: 0.213, Test loss: 0.435, Test accuracy: 87.30
Round  84, Global train loss: 0.213, Global test loss: 2.910, Global test accuracy: 25.95
Round  85, Train loss: 0.233, Test loss: 0.445, Test accuracy: 86.53
Round  85, Global train loss: 0.233, Global test loss: 3.174, Global test accuracy: 27.92
Round  86, Train loss: 0.258, Test loss: 0.440, Test accuracy: 86.90
Round  86, Global train loss: 0.258, Global test loss: 2.378, Global test accuracy: 27.87
Round  87, Train loss: 0.190, Test loss: 0.450, Test accuracy: 86.97
Round  87, Global train loss: 0.190, Global test loss: 2.971, Global test accuracy: 25.58
Round  88, Train loss: 0.209, Test loss: 0.445, Test accuracy: 86.93
Round  88, Global train loss: 0.209, Global test loss: 2.984, Global test accuracy: 26.87
Round  89, Train loss: 0.220, Test loss: 0.445, Test accuracy: 87.03
Round  89, Global train loss: 0.220, Global test loss: 2.840, Global test accuracy: 28.47
Round  90, Train loss: 0.244, Test loss: 0.449, Test accuracy: 86.85
Round  90, Global train loss: 0.244, Global test loss: 2.593, Global test accuracy: 31.48
Round  91, Train loss: 0.231, Test loss: 0.445, Test accuracy: 87.05
Round  91, Global train loss: 0.231, Global test loss: 2.479, Global test accuracy: 25.27
Round  92, Train loss: 0.226, Test loss: 0.470, Test accuracy: 86.73
Round  92, Global train loss: 0.226, Global test loss: 2.546, Global test accuracy: 27.55
Round  93, Train loss: 0.187, Test loss: 0.466, Test accuracy: 86.80
Round  93, Global train loss: 0.187, Global test loss: 2.694, Global test accuracy: 27.03
Round  94, Train loss: 0.191, Test loss: 0.456, Test accuracy: 87.37
Round  94, Global train loss: 0.191, Global test loss: 2.805, Global test accuracy: 24.93
Round  95, Train loss: 0.184, Test loss: 0.451, Test accuracy: 87.62
Round  95, Global train loss: 0.184, Global test loss: 2.757, Global test accuracy: 23.95
Round  96, Train loss: 0.199, Test loss: 0.474, Test accuracy: 87.40
Round  96, Global train loss: 0.199, Global test loss: 2.675, Global test accuracy: 31.62
Round  97, Train loss: 0.208, Test loss: 0.454, Test accuracy: 87.65
Round  97, Global train loss: 0.208, Global test loss: 2.778, Global test accuracy: 32.52
Round  98, Train loss: 0.176, Test loss: 0.451, Test accuracy: 87.70
Round  98, Global train loss: 0.176, Global test loss: 2.867, Global test accuracy: 26.58
Round  99, Train loss: 0.199, Test loss: 0.450, Test accuracy: 87.87
Round  99, Global train loss: 0.199, Global test loss: 2.897, Global test accuracy: 28.70
Final Round, Train loss: 0.148, Test loss: 0.455, Test accuracy: 88.10
Final Round, Global train loss: 0.148, Global test loss: 2.897, Global test accuracy: 28.70
Average accuracy final 10 rounds: 87.30333333333333 

Average global accuracy final 10 rounds: 27.963333333333328 

982.0431826114655
[1.10329008102417, 2.20658016204834, 2.909064769744873, 3.6115493774414062, 4.332473516464233, 5.0533976554870605, 5.769752264022827, 6.486106872558594, 7.173079967498779, 7.860053062438965, 8.555115699768066, 9.250178337097168, 9.936794757843018, 10.623411178588867, 11.319732189178467, 12.016053199768066, 12.705320119857788, 13.39458703994751, 14.087781429290771, 14.780975818634033, 15.478620767593384, 16.176265716552734, 16.869076013565063, 17.561886310577393, 18.248313188552856, 18.93474006652832, 19.631994009017944, 20.32924795150757, 21.017951011657715, 21.70665407180786, 22.408835649490356, 23.11101722717285, 23.8070547580719, 24.503092288970947, 25.193285942077637, 25.883479595184326, 26.574036836624146, 27.264594078063965, 27.95715355873108, 28.649713039398193, 29.35284733772278, 30.055981636047363, 30.748719215393066, 31.44145679473877, 32.13950157165527, 32.83754634857178, 33.529217004776, 34.220887660980225, 34.91764426231384, 35.61440086364746, 36.31412482261658, 37.01384878158569, 37.712153673172, 38.4104585647583, 39.10412526130676, 39.797791957855225, 40.48993372917175, 41.18207550048828, 41.87693476676941, 42.57179403305054, 43.265178203582764, 43.95856237411499, 44.652724742889404, 45.34688711166382, 46.04391384124756, 46.7409405708313, 47.43529963493347, 48.129658699035645, 48.82684683799744, 49.52403497695923, 50.215717792510986, 50.907400608062744, 51.59971046447754, 52.292020320892334, 52.99279189109802, 53.69356346130371, 54.390549182891846, 55.08753490447998, 55.77602791786194, 56.4645209312439, 57.16077756881714, 57.85703420639038, 58.55540466308594, 59.253775119781494, 59.95483446121216, 60.65589380264282, 61.35199475288391, 62.048095703125, 62.74161386489868, 63.43513202667236, 64.13001561164856, 64.82489919662476, 65.52329158782959, 66.22168397903442, 66.9141321182251, 67.60658025741577, 68.29749274253845, 68.98840522766113, 69.68809080123901, 70.3877763748169, 71.08757448196411, 71.78737258911133, 72.48220181465149, 73.17703104019165, 73.87215662002563, 74.56728219985962, 75.26107597351074, 75.95486974716187, 76.65124320983887, 77.34761667251587, 78.04439067840576, 78.74116468429565, 79.44067096710205, 80.14017724990845, 80.82548356056213, 81.51078987121582, 82.20480179786682, 82.89881372451782, 83.58653950691223, 84.27426528930664, 84.96915292739868, 85.66404056549072, 86.34605932235718, 87.02807807922363, 87.72078657150269, 88.41349506378174, 89.11850118637085, 89.82350730895996, 90.51188707351685, 91.20026683807373, 91.89296078681946, 92.58565473556519, 93.2684714794159, 93.9512882232666, 94.63777780532837, 95.32426738739014, 96.01671624183655, 96.70916509628296, 97.40522170066833, 98.10127830505371, 98.7932767868042, 99.48527526855469, 100.17269277572632, 100.86011028289795, 101.55441927909851, 102.24872827529907, 102.93468761444092, 103.62064695358276, 104.31744742393494, 105.01424789428711, 105.70337557792664, 106.39250326156616, 107.08993768692017, 107.78737211227417, 108.47722601890564, 109.16707992553711, 109.86103320121765, 110.5549864768982, 111.24620366096497, 111.93742084503174, 112.63222861289978, 113.32703638076782, 114.01678538322449, 114.70653438568115, 115.39750075340271, 116.08846712112427, 116.78839778900146, 117.48832845687866, 118.17696619033813, 118.86560392379761, 119.55969214439392, 120.25378036499023, 120.94012570381165, 121.62647104263306, 122.32371807098389, 123.02096509933472, 123.7154769897461, 124.40998888015747, 125.09925866127014, 125.78852844238281, 126.49123930931091, 127.19395017623901, 127.89089155197144, 128.58783292770386, 129.28976106643677, 129.99168920516968, 130.68665385246277, 131.38161849975586, 132.07270097732544, 132.76378345489502, 133.4742133617401, 134.1846432685852, 134.88165426254272, 135.57866525650024, 136.26904892921448, 136.9594326019287, 137.6567952632904, 138.3541579246521, 139.05620622634888, 139.75825452804565, 141.15667271614075, 142.55509090423584]
[21.066666666666666, 21.066666666666666, 32.11666666666667, 32.11666666666667, 47.6, 47.6, 54.083333333333336, 54.083333333333336, 57.93333333333333, 57.93333333333333, 60.733333333333334, 60.733333333333334, 63.81666666666667, 63.81666666666667, 65.4, 65.4, 67.93333333333334, 67.93333333333334, 66.83333333333333, 66.83333333333333, 70.13333333333334, 70.13333333333334, 71.78333333333333, 71.78333333333333, 72.08333333333333, 72.08333333333333, 77.31666666666666, 77.31666666666666, 77.43333333333334, 77.43333333333334, 79.0, 79.0, 80.28333333333333, 80.28333333333333, 81.03333333333333, 81.03333333333333, 81.13333333333334, 81.13333333333334, 81.63333333333334, 81.63333333333334, 80.88333333333334, 80.88333333333334, 80.4, 80.4, 81.36666666666666, 81.36666666666666, 81.73333333333333, 81.73333333333333, 82.11666666666666, 82.11666666666666, 82.58333333333333, 82.58333333333333, 82.48333333333333, 82.48333333333333, 83.71666666666667, 83.71666666666667, 82.66666666666667, 82.66666666666667, 82.13333333333334, 82.13333333333334, 82.73333333333333, 82.73333333333333, 82.61666666666666, 82.61666666666666, 82.8, 82.8, 83.03333333333333, 83.03333333333333, 83.65, 83.65, 84.66666666666667, 84.66666666666667, 84.18333333333334, 84.18333333333334, 84.83333333333333, 84.83333333333333, 84.56666666666666, 84.56666666666666, 84.48333333333333, 84.48333333333333, 85.08333333333333, 85.08333333333333, 85.46666666666667, 85.46666666666667, 85.9, 85.9, 86.11666666666666, 86.11666666666666, 85.61666666666666, 85.61666666666666, 85.63333333333334, 85.63333333333334, 85.63333333333334, 85.63333333333334, 85.98333333333333, 85.98333333333333, 86.35, 86.35, 86.21666666666667, 86.21666666666667, 86.31666666666666, 86.31666666666666, 85.93333333333334, 85.93333333333334, 85.78333333333333, 85.78333333333333, 85.83333333333333, 85.83333333333333, 86.68333333333334, 86.68333333333334, 86.95, 86.95, 86.91666666666667, 86.91666666666667, 86.21666666666667, 86.21666666666667, 86.23333333333333, 86.23333333333333, 86.28333333333333, 86.28333333333333, 86.95, 86.95, 86.88333333333334, 86.88333333333334, 86.4, 86.4, 86.0, 86.0, 86.33333333333333, 86.33333333333333, 86.36666666666666, 86.36666666666666, 85.93333333333334, 85.93333333333334, 86.11666666666666, 86.11666666666666, 85.85, 85.85, 85.86666666666666, 85.86666666666666, 86.85, 86.85, 87.46666666666667, 87.46666666666667, 86.96666666666667, 86.96666666666667, 87.43333333333334, 87.43333333333334, 87.3, 87.3, 87.41666666666667, 87.41666666666667, 87.88333333333334, 87.88333333333334, 87.51666666666667, 87.51666666666667, 87.06666666666666, 87.06666666666666, 87.5, 87.5, 87.38333333333334, 87.38333333333334, 87.38333333333334, 87.38333333333334, 87.21666666666667, 87.21666666666667, 87.25, 87.25, 87.3, 87.3, 86.53333333333333, 86.53333333333333, 86.9, 86.9, 86.96666666666667, 86.96666666666667, 86.93333333333334, 86.93333333333334, 87.03333333333333, 87.03333333333333, 86.85, 86.85, 87.05, 87.05, 86.73333333333333, 86.73333333333333, 86.8, 86.8, 87.36666666666666, 87.36666666666666, 87.61666666666666, 87.61666666666666, 87.4, 87.4, 87.65, 87.65, 87.7, 87.7, 87.86666666666666, 87.86666666666666, 88.1, 88.1]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 1063434 (local), 1062144 (global); Percentage 99.88 (1062144/1063434 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.666, Test loss: 2.446, Test accuracy: 18.67
Round   1, Train loss: 1.158, Test loss: 2.169, Test accuracy: 26.10
Round   2, Train loss: 1.056, Test loss: 1.622, Test accuracy: 39.48
Round   3, Train loss: 0.926, Test loss: 1.425, Test accuracy: 47.23
Round   4, Train loss: 0.880, Test loss: 1.318, Test accuracy: 51.03
Round   5, Train loss: 0.966, Test loss: 1.120, Test accuracy: 55.40
Round   6, Train loss: 0.940, Test loss: 0.883, Test accuracy: 63.30
Round   7, Train loss: 0.764, Test loss: 0.931, Test accuracy: 63.97
Round   8, Train loss: 0.810, Test loss: 0.813, Test accuracy: 67.78
Round   9, Train loss: 0.803, Test loss: 0.706, Test accuracy: 70.33
Round  10, Train loss: 0.794, Test loss: 0.692, Test accuracy: 71.68
Round  11, Train loss: 0.680, Test loss: 0.684, Test accuracy: 72.00
Round  12, Train loss: 0.718, Test loss: 0.652, Test accuracy: 73.13
Round  13, Train loss: 0.685, Test loss: 0.670, Test accuracy: 72.52
Round  14, Train loss: 0.752, Test loss: 0.625, Test accuracy: 75.25
Round  15, Train loss: 0.735, Test loss: 0.607, Test accuracy: 75.92
Round  16, Train loss: 0.664, Test loss: 0.622, Test accuracy: 74.73
Round  17, Train loss: 0.642, Test loss: 0.601, Test accuracy: 76.42
Round  18, Train loss: 0.634, Test loss: 0.568, Test accuracy: 77.72
Round  19, Train loss: 0.598, Test loss: 0.577, Test accuracy: 77.68
Round  20, Train loss: 0.583, Test loss: 0.563, Test accuracy: 78.22
Round  21, Train loss: 0.619, Test loss: 0.561, Test accuracy: 79.00
Round  22, Train loss: 0.620, Test loss: 0.538, Test accuracy: 79.22
Round  23, Train loss: 0.578, Test loss: 0.534, Test accuracy: 79.23
Round  24, Train loss: 0.527, Test loss: 0.520, Test accuracy: 79.48
Round  25, Train loss: 0.586, Test loss: 0.513, Test accuracy: 80.23
Round  26, Train loss: 0.544, Test loss: 0.505, Test accuracy: 80.05
Round  27, Train loss: 0.619, Test loss: 0.532, Test accuracy: 79.75
Round  28, Train loss: 0.560, Test loss: 0.490, Test accuracy: 81.32
Round  29, Train loss: 0.461, Test loss: 0.483, Test accuracy: 81.77
Round  30, Train loss: 0.508, Test loss: 0.479, Test accuracy: 81.97
Round  31, Train loss: 0.439, Test loss: 0.452, Test accuracy: 82.53
Round  32, Train loss: 0.467, Test loss: 0.460, Test accuracy: 82.83
Round  33, Train loss: 0.455, Test loss: 0.439, Test accuracy: 83.03
Round  34, Train loss: 0.460, Test loss: 0.442, Test accuracy: 82.92
Round  35, Train loss: 0.442, Test loss: 0.433, Test accuracy: 83.05
Round  36, Train loss: 0.517, Test loss: 0.423, Test accuracy: 84.27
Round  37, Train loss: 0.424, Test loss: 0.432, Test accuracy: 83.47
Round  38, Train loss: 0.448, Test loss: 0.425, Test accuracy: 83.78
Round  39, Train loss: 0.488, Test loss: 0.413, Test accuracy: 84.12
Round  40, Train loss: 0.426, Test loss: 0.403, Test accuracy: 84.62
Round  41, Train loss: 0.345, Test loss: 0.396, Test accuracy: 85.15
Round  42, Train loss: 0.410, Test loss: 0.419, Test accuracy: 83.83
Round  43, Train loss: 0.405, Test loss: 0.414, Test accuracy: 83.75
Round  44, Train loss: 0.417, Test loss: 0.394, Test accuracy: 84.93
Round  45, Train loss: 0.339, Test loss: 0.417, Test accuracy: 84.03
Round  46, Train loss: 0.388, Test loss: 0.435, Test accuracy: 83.12
Round  47, Train loss: 0.335, Test loss: 0.405, Test accuracy: 84.45
Round  48, Train loss: 0.366, Test loss: 0.378, Test accuracy: 85.52
Round  49, Train loss: 0.365, Test loss: 0.388, Test accuracy: 85.00
Round  50, Train loss: 0.457, Test loss: 0.383, Test accuracy: 85.38
Round  51, Train loss: 0.335, Test loss: 0.374, Test accuracy: 85.62
Round  52, Train loss: 0.337, Test loss: 0.387, Test accuracy: 85.37
Round  53, Train loss: 0.360, Test loss: 0.378, Test accuracy: 85.95
Round  54, Train loss: 0.326, Test loss: 0.369, Test accuracy: 86.25
Round  55, Train loss: 0.311, Test loss: 0.371, Test accuracy: 86.00
Round  56, Train loss: 0.390, Test loss: 0.382, Test accuracy: 85.83
Round  57, Train loss: 0.383, Test loss: 0.368, Test accuracy: 85.87
Round  58, Train loss: 0.315, Test loss: 0.373, Test accuracy: 86.23
Round  59, Train loss: 0.319, Test loss: 0.368, Test accuracy: 86.18
Round  60, Train loss: 0.283, Test loss: 0.372, Test accuracy: 86.23
Round  61, Train loss: 0.291, Test loss: 0.385, Test accuracy: 85.28
Round  62, Train loss: 0.292, Test loss: 0.362, Test accuracy: 86.70
Round  63, Train loss: 0.301, Test loss: 0.348, Test accuracy: 86.88
Round  64, Train loss: 0.316, Test loss: 0.357, Test accuracy: 86.70
Round  65, Train loss: 0.273, Test loss: 0.361, Test accuracy: 86.65
Round  66, Train loss: 0.297, Test loss: 0.341, Test accuracy: 87.25
Round  67, Train loss: 0.327, Test loss: 0.350, Test accuracy: 86.92
Round  68, Train loss: 0.246, Test loss: 0.362, Test accuracy: 86.25
Round  69, Train loss: 0.323, Test loss: 0.369, Test accuracy: 86.03
Round  70, Train loss: 0.260, Test loss: 0.353, Test accuracy: 86.82
Round  71, Train loss: 0.272, Test loss: 0.350, Test accuracy: 87.07
Round  72, Train loss: 0.232, Test loss: 0.362, Test accuracy: 86.83
Round  73, Train loss: 0.306, Test loss: 0.339, Test accuracy: 87.50
Round  74, Train loss: 0.273, Test loss: 0.353, Test accuracy: 87.63
Round  75, Train loss: 0.265, Test loss: 0.351, Test accuracy: 86.93
Round  76, Train loss: 0.271, Test loss: 0.337, Test accuracy: 88.03
Round  77, Train loss: 0.245, Test loss: 0.338, Test accuracy: 88.07
Round  78, Train loss: 0.262, Test loss: 0.350, Test accuracy: 87.53
Round  79, Train loss: 0.252, Test loss: 0.352, Test accuracy: 87.33
Round  80, Train loss: 0.244, Test loss: 0.362, Test accuracy: 86.93
Round  81, Train loss: 0.280, Test loss: 0.353, Test accuracy: 87.30
Round  82, Train loss: 0.205, Test loss: 0.353, Test accuracy: 87.55
Round  83, Train loss: 0.248, Test loss: 0.352, Test accuracy: 87.65
Round  84, Train loss: 0.232, Test loss: 0.356, Test accuracy: 87.60
Round  85, Train loss: 0.223, Test loss: 0.350, Test accuracy: 87.47
Round  86, Train loss: 0.228, Test loss: 0.338, Test accuracy: 88.45
Round  87, Train loss: 0.224, Test loss: 0.342, Test accuracy: 87.68
Round  88, Train loss: 0.208, Test loss: 0.338, Test accuracy: 87.83
Round  89, Train loss: 0.220, Test loss: 0.344, Test accuracy: 87.88
Round  90, Train loss: 0.192, Test loss: 0.342, Test accuracy: 87.30
Round  91, Train loss: 0.204, Test loss: 0.354, Test accuracy: 87.70
Round  92, Train loss: 0.197, Test loss: 0.356, Test accuracy: 87.68
Round  93, Train loss: 0.232, Test loss: 0.341, Test accuracy: 88.13
Round  94, Train loss: 0.213, Test loss: 0.351, Test accuracy: 87.85
Round  95, Train loss: 0.189, Test loss: 0.344, Test accuracy: 88.25
Round  96, Train loss: 0.183, Test loss: 0.341, Test accuracy: 88.15
Round  97, Train loss: 0.190, Test loss: 0.358, Test accuracy: 88.30
Round  98, Train loss: 0.226, Test loss: 0.369, Test accuracy: 87.82
Round  99, Train loss: 0.214, Test loss: 0.362, Test accuracy: 87.53
Final Round, Train loss: 0.168, Test loss: 0.360, Test accuracy: 88.13
Average accuracy final 10 rounds: 87.87166666666667 

766.8279104232788
[0.9870202541351318, 1.9740405082702637, 2.6287710666656494, 3.283501625061035, 3.9328742027282715, 4.582246780395508, 5.2208216190338135, 5.859396457672119, 6.504661321640015, 7.14992618560791, 7.797334909439087, 8.444743633270264, 9.095150470733643, 9.745557308197021, 10.392785549163818, 11.040013790130615, 11.68593430519104, 12.331854820251465, 12.973573207855225, 13.615291595458984, 14.264027833938599, 14.912764072418213, 15.562362432479858, 16.211960792541504, 16.85863423347473, 17.50530767440796, 18.15218997001648, 18.799072265625, 19.452953338623047, 20.106834411621094, 20.750892400741577, 21.39495038986206, 22.039417266845703, 22.683884143829346, 23.33509635925293, 23.986308574676514, 24.62780237197876, 25.269296169281006, 25.93163299560547, 26.59396982192993, 27.241992712020874, 27.890015602111816, 28.54643678665161, 29.202857971191406, 29.855849742889404, 30.508841514587402, 31.15710759162903, 31.805373668670654, 32.452438831329346, 33.09950399398804, 33.74977493286133, 34.40004587173462, 35.05207872390747, 35.70411157608032, 36.35547685623169, 37.00684213638306, 37.659980058670044, 38.31311798095703, 38.96476125717163, 39.61640453338623, 40.2697868347168, 40.92316913604736, 41.58047866821289, 42.23778820037842, 42.892526149749756, 43.547264099121094, 44.19691777229309, 44.84657144546509, 45.49271750450134, 46.1388635635376, 46.79142165184021, 47.44397974014282, 48.0977201461792, 48.751460552215576, 49.40914797782898, 50.06683540344238, 50.721007108688354, 51.375178813934326, 52.025285720825195, 52.675392627716064, 53.327197790145874, 53.979002952575684, 54.63477277755737, 55.29054260253906, 55.948702335357666, 56.60686206817627, 57.25435829162598, 57.901854515075684, 58.55512619018555, 59.20839786529541, 59.86236119270325, 60.516324520111084, 61.17156362533569, 61.8268027305603, 62.47887587547302, 63.13094902038574, 63.78751015663147, 64.4440712928772, 65.1071424484253, 65.77021360397339, 66.42469954490662, 67.07918548583984, 67.72640132904053, 68.37361717224121, 69.03414297103882, 69.69466876983643, 70.3508415222168, 71.00701427459717, 71.65144920349121, 72.29588413238525, 72.94501900672913, 73.594153881073, 74.2455701828003, 74.89698648452759, 75.5512216091156, 76.20545673370361, 76.84597158432007, 77.48648643493652, 78.1343846321106, 78.78228282928467, 79.4356279373169, 80.08897304534912, 80.74631810188293, 81.40366315841675, 82.05134510993958, 82.6990270614624, 83.35142469406128, 84.00382232666016, 84.65790438652039, 85.31198644638062, 85.96667575836182, 86.62136507034302, 87.26826357841492, 87.91516208648682, 88.56911158561707, 89.22306108474731, 89.87056469917297, 90.51806831359863, 91.1715784072876, 91.82508850097656, 92.46706104278564, 93.10903358459473, 93.75826001167297, 94.40748643875122, 95.06386065483093, 95.72023487091064, 96.37551259994507, 97.03079032897949, 97.6770966053009, 98.32340288162231, 98.97309947013855, 99.62279605865479, 100.274094581604, 100.92539310455322, 101.57279515266418, 102.22019720077515, 102.86891007423401, 103.51762294769287, 104.17347407341003, 104.8293251991272, 105.4799702167511, 106.130615234375, 106.77803206443787, 107.42544889450073, 108.066415309906, 108.70738172531128, 109.35204482078552, 109.99670791625977, 110.64577078819275, 111.29483366012573, 111.93707799911499, 112.57932233810425, 113.22650599479675, 113.87368965148926, 114.52085494995117, 115.16802024841309, 115.81422162055969, 116.4604229927063, 117.09757661819458, 117.73473024368286, 118.3837513923645, 119.03277254104614, 119.68181586265564, 120.33085918426514, 120.97686886787415, 121.62287855148315, 122.26256012916565, 122.90224170684814, 123.55107593536377, 124.1999101638794, 124.85084962844849, 125.50178909301758, 126.1504852771759, 126.79918146133423, 127.44366097450256, 128.0881404876709, 128.74115538597107, 129.39417028427124, 130.0478057861328, 130.70144128799438, 131.90249395370483, 133.10354661941528]
[18.666666666666668, 18.666666666666668, 26.1, 26.1, 39.483333333333334, 39.483333333333334, 47.233333333333334, 47.233333333333334, 51.03333333333333, 51.03333333333333, 55.4, 55.4, 63.3, 63.3, 63.96666666666667, 63.96666666666667, 67.78333333333333, 67.78333333333333, 70.33333333333333, 70.33333333333333, 71.68333333333334, 71.68333333333334, 72.0, 72.0, 73.13333333333334, 73.13333333333334, 72.51666666666667, 72.51666666666667, 75.25, 75.25, 75.91666666666667, 75.91666666666667, 74.73333333333333, 74.73333333333333, 76.41666666666667, 76.41666666666667, 77.71666666666667, 77.71666666666667, 77.68333333333334, 77.68333333333334, 78.21666666666667, 78.21666666666667, 79.0, 79.0, 79.21666666666667, 79.21666666666667, 79.23333333333333, 79.23333333333333, 79.48333333333333, 79.48333333333333, 80.23333333333333, 80.23333333333333, 80.05, 80.05, 79.75, 79.75, 81.31666666666666, 81.31666666666666, 81.76666666666667, 81.76666666666667, 81.96666666666667, 81.96666666666667, 82.53333333333333, 82.53333333333333, 82.83333333333333, 82.83333333333333, 83.03333333333333, 83.03333333333333, 82.91666666666667, 82.91666666666667, 83.05, 83.05, 84.26666666666667, 84.26666666666667, 83.46666666666667, 83.46666666666667, 83.78333333333333, 83.78333333333333, 84.11666666666666, 84.11666666666666, 84.61666666666666, 84.61666666666666, 85.15, 85.15, 83.83333333333333, 83.83333333333333, 83.75, 83.75, 84.93333333333334, 84.93333333333334, 84.03333333333333, 84.03333333333333, 83.11666666666666, 83.11666666666666, 84.45, 84.45, 85.51666666666667, 85.51666666666667, 85.0, 85.0, 85.38333333333334, 85.38333333333334, 85.61666666666666, 85.61666666666666, 85.36666666666666, 85.36666666666666, 85.95, 85.95, 86.25, 86.25, 86.0, 86.0, 85.83333333333333, 85.83333333333333, 85.86666666666666, 85.86666666666666, 86.23333333333333, 86.23333333333333, 86.18333333333334, 86.18333333333334, 86.23333333333333, 86.23333333333333, 85.28333333333333, 85.28333333333333, 86.7, 86.7, 86.88333333333334, 86.88333333333334, 86.7, 86.7, 86.65, 86.65, 87.25, 87.25, 86.91666666666667, 86.91666666666667, 86.25, 86.25, 86.03333333333333, 86.03333333333333, 86.81666666666666, 86.81666666666666, 87.06666666666666, 87.06666666666666, 86.83333333333333, 86.83333333333333, 87.5, 87.5, 87.63333333333334, 87.63333333333334, 86.93333333333334, 86.93333333333334, 88.03333333333333, 88.03333333333333, 88.06666666666666, 88.06666666666666, 87.53333333333333, 87.53333333333333, 87.33333333333333, 87.33333333333333, 86.93333333333334, 86.93333333333334, 87.3, 87.3, 87.55, 87.55, 87.65, 87.65, 87.6, 87.6, 87.46666666666667, 87.46666666666667, 88.45, 88.45, 87.68333333333334, 87.68333333333334, 87.83333333333333, 87.83333333333333, 87.88333333333334, 87.88333333333334, 87.3, 87.3, 87.7, 87.7, 87.68333333333334, 87.68333333333334, 88.13333333333334, 88.13333333333334, 87.85, 87.85, 88.25, 88.25, 88.15, 88.15, 88.3, 88.3, 87.81666666666666, 87.81666666666666, 87.53333333333333, 87.53333333333333, 88.13333333333334, 88.13333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
fedper
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 1063434 (local), 1062144 (global); Percentage 99.88 (1062144/1063434 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.221, Test loss: 2.288, Test accuracy: 19.60
Round   1, Train loss: 1.012, Test loss: 2.081, Test accuracy: 28.65
Round   2, Train loss: 1.014, Test loss: 1.779, Test accuracy: 35.83
Round   3, Train loss: 0.934, Test loss: 1.550, Test accuracy: 43.67
Round   4, Train loss: 0.901, Test loss: 1.400, Test accuracy: 48.77
Round   5, Train loss: 0.767, Test loss: 1.368, Test accuracy: 51.55
Round   6, Train loss: 0.718, Test loss: 1.251, Test accuracy: 56.55
Round   7, Train loss: 0.714, Test loss: 1.133, Test accuracy: 59.50
Round   8, Train loss: 0.714, Test loss: 1.126, Test accuracy: 59.88
Round   9, Train loss: 0.681, Test loss: 1.017, Test accuracy: 63.27
Round  10, Train loss: 0.680, Test loss: 1.025, Test accuracy: 64.87
Round  11, Train loss: 0.690, Test loss: 0.914, Test accuracy: 67.18
Round  12, Train loss: 0.618, Test loss: 0.801, Test accuracy: 70.82
Round  13, Train loss: 0.654, Test loss: 0.783, Test accuracy: 70.05
Round  14, Train loss: 0.568, Test loss: 0.781, Test accuracy: 68.82
Round  15, Train loss: 0.597, Test loss: 0.740, Test accuracy: 71.93
Round  16, Train loss: 0.556, Test loss: 0.685, Test accuracy: 73.42
Round  17, Train loss: 0.578, Test loss: 0.647, Test accuracy: 75.70
Round  18, Train loss: 0.504, Test loss: 0.582, Test accuracy: 77.63
Round  19, Train loss: 0.547, Test loss: 0.577, Test accuracy: 78.20
Round  20, Train loss: 0.473, Test loss: 0.547, Test accuracy: 79.35
Round  21, Train loss: 0.471, Test loss: 0.521, Test accuracy: 81.15
Round  22, Train loss: 0.430, Test loss: 0.525, Test accuracy: 80.65
Round  23, Train loss: 0.402, Test loss: 0.495, Test accuracy: 80.58
Round  24, Train loss: 0.417, Test loss: 0.513, Test accuracy: 81.18
Round  25, Train loss: 0.476, Test loss: 0.475, Test accuracy: 82.35
Round  26, Train loss: 0.448, Test loss: 0.479, Test accuracy: 82.92
Round  27, Train loss: 0.379, Test loss: 0.461, Test accuracy: 83.08
Round  28, Train loss: 0.401, Test loss: 0.460, Test accuracy: 83.38
Round  29, Train loss: 0.387, Test loss: 0.443, Test accuracy: 84.20
Round  30, Train loss: 0.335, Test loss: 0.421, Test accuracy: 83.78
Round  31, Train loss: 0.392, Test loss: 0.451, Test accuracy: 82.75
Round  32, Train loss: 0.350, Test loss: 0.432, Test accuracy: 83.55
Round  33, Train loss: 0.312, Test loss: 0.432, Test accuracy: 84.10
Round  34, Train loss: 0.309, Test loss: 0.443, Test accuracy: 83.73
Round  35, Train loss: 0.335, Test loss: 0.405, Test accuracy: 84.55
Round  36, Train loss: 0.367, Test loss: 0.409, Test accuracy: 84.27
Round  37, Train loss: 0.277, Test loss: 0.399, Test accuracy: 84.92
Round  38, Train loss: 0.314, Test loss: 0.393, Test accuracy: 84.77
Round  39, Train loss: 0.288, Test loss: 0.400, Test accuracy: 84.70
Round  40, Train loss: 0.282, Test loss: 0.387, Test accuracy: 85.25
Round  41, Train loss: 0.287, Test loss: 0.390, Test accuracy: 85.65
Round  42, Train loss: 0.233, Test loss: 0.387, Test accuracy: 85.82
Round  43, Train loss: 0.253, Test loss: 0.403, Test accuracy: 85.40
Round  44, Train loss: 0.260, Test loss: 0.388, Test accuracy: 85.93
Round  45, Train loss: 0.285, Test loss: 0.396, Test accuracy: 85.28
Round  46, Train loss: 0.225, Test loss: 0.383, Test accuracy: 85.87
Round  47, Train loss: 0.263, Test loss: 0.379, Test accuracy: 86.32
Round  48, Train loss: 0.234, Test loss: 0.354, Test accuracy: 86.47
Round  49, Train loss: 0.224, Test loss: 0.362, Test accuracy: 87.05
Round  50, Train loss: 0.199, Test loss: 0.361, Test accuracy: 86.17
Round  51, Train loss: 0.194, Test loss: 0.358, Test accuracy: 87.25
Round  52, Train loss: 0.241, Test loss: 0.365, Test accuracy: 86.45
Round  53, Train loss: 0.211, Test loss: 0.394, Test accuracy: 85.90
Round  54, Train loss: 0.183, Test loss: 0.385, Test accuracy: 86.80
Round  55, Train loss: 0.182, Test loss: 0.388, Test accuracy: 86.20
Round  56, Train loss: 0.179, Test loss: 0.389, Test accuracy: 86.15
Round  57, Train loss: 0.219, Test loss: 0.348, Test accuracy: 87.12
Round  58, Train loss: 0.176, Test loss: 0.372, Test accuracy: 86.87
Round  59, Train loss: 0.138, Test loss: 0.361, Test accuracy: 87.65
Round  60, Train loss: 0.197, Test loss: 0.362, Test accuracy: 87.10
Round  61, Train loss: 0.191, Test loss: 0.365, Test accuracy: 86.80
Round  62, Train loss: 0.193, Test loss: 0.357, Test accuracy: 87.15
Round  63, Train loss: 0.206, Test loss: 0.359, Test accuracy: 87.22
Round  64, Train loss: 0.190, Test loss: 0.374, Test accuracy: 87.12
Round  65, Train loss: 0.196, Test loss: 0.352, Test accuracy: 87.52
Round  66, Train loss: 0.173, Test loss: 0.378, Test accuracy: 86.62
Round  67, Train loss: 0.172, Test loss: 0.356, Test accuracy: 87.83
Round  68, Train loss: 0.177, Test loss: 0.353, Test accuracy: 87.78
Round  69, Train loss: 0.149, Test loss: 0.357, Test accuracy: 88.08
Round  70, Train loss: 0.173, Test loss: 0.345, Test accuracy: 87.82
Round  71, Train loss: 0.152, Test loss: 0.354, Test accuracy: 88.08
Round  72, Train loss: 0.153, Test loss: 0.377, Test accuracy: 87.70
Round  73, Train loss: 0.159, Test loss: 0.366, Test accuracy: 87.67
Round  74, Train loss: 0.124, Test loss: 0.368, Test accuracy: 87.88
Round  75, Train loss: 0.155, Test loss: 0.389, Test accuracy: 87.00
Round  76, Train loss: 0.145, Test loss: 0.400, Test accuracy: 87.48
Round  77, Train loss: 0.186, Test loss: 0.355, Test accuracy: 87.73
Round  78, Train loss: 0.133, Test loss: 0.374, Test accuracy: 87.53
Round  79, Train loss: 0.145, Test loss: 0.376, Test accuracy: 87.78
Round  80, Train loss: 0.155, Test loss: 0.386, Test accuracy: 87.32
Round  81, Train loss: 0.134, Test loss: 0.388, Test accuracy: 87.20
Round  82, Train loss: 0.151, Test loss: 0.369, Test accuracy: 87.67
Round  83, Train loss: 0.163, Test loss: 0.371, Test accuracy: 87.63
Round  84, Train loss: 0.131, Test loss: 0.380, Test accuracy: 87.58
Round  85, Train loss: 0.144, Test loss: 0.384, Test accuracy: 87.33
Round  86, Train loss: 0.102, Test loss: 0.391, Test accuracy: 87.87
Round  87, Train loss: 0.098, Test loss: 0.378, Test accuracy: 88.28
Round  88, Train loss: 0.158, Test loss: 0.364, Test accuracy: 87.58
Round  89, Train loss: 0.128, Test loss: 0.358, Test accuracy: 88.18
Round  90, Train loss: 0.102, Test loss: 0.380, Test accuracy: 88.13
Round  91, Train loss: 0.100, Test loss: 0.380, Test accuracy: 87.77
Round  92, Train loss: 0.106, Test loss: 0.391, Test accuracy: 87.93
Round  93, Train loss: 0.117, Test loss: 0.386, Test accuracy: 88.02
Round  94, Train loss: 0.141, Test loss: 0.363, Test accuracy: 88.42
Round  95, Train loss: 0.084, Test loss: 0.377, Test accuracy: 88.23
Round  96, Train loss: 0.084, Test loss: 0.371, Test accuracy: 88.37
Round  97, Train loss: 0.102, Test loss: 0.372, Test accuracy: 88.73
Round  98, Train loss: 0.111, Test loss: 0.381, Test accuracy: 88.37
Round  99, Train loss: 0.095, Test loss: 0.401, Test accuracy: 88.08
Final Round, Train loss: 0.096, Test loss: 0.403, Test accuracy: 88.53
Average accuracy final 10 rounds: 88.20500000000001 

784.9367632865906
[0.9468934535980225, 1.893786907196045, 2.5790703296661377, 3.2643537521362305, 3.952204704284668, 4.6400556564331055, 5.331085920333862, 6.022116184234619, 6.698648691177368, 7.375181198120117, 8.058943748474121, 8.742706298828125, 9.431072235107422, 10.119438171386719, 10.801785230636597, 11.484132289886475, 12.165812015533447, 12.84749174118042, 13.540096044540405, 14.23270034790039, 14.919418811798096, 15.6061372756958, 16.29446053504944, 16.982783794403076, 17.6615047454834, 18.34022569656372, 19.029383420944214, 19.718541145324707, 20.409118175506592, 21.099695205688477, 21.781984567642212, 22.464273929595947, 23.157971143722534, 23.85166835784912, 24.54280710220337, 25.233945846557617, 25.92302393913269, 26.612102031707764, 27.29221534729004, 27.972328662872314, 28.66329288482666, 29.354257106781006, 30.043389081954956, 30.732521057128906, 31.4235417842865, 32.11456251144409, 32.79759407043457, 33.48062562942505, 34.170629024505615, 34.86063241958618, 35.54597043991089, 36.231308460235596, 36.91124367713928, 37.59117889404297, 38.27664756774902, 38.96211624145508, 39.65323209762573, 40.34434795379639, 41.03489804267883, 41.72544813156128, 42.39993476867676, 43.074421405792236, 43.76185441017151, 44.44928741455078, 45.139129877090454, 45.82897233963013, 46.52058744430542, 47.21220254898071, 47.89451360702515, 48.57682466506958, 49.26477241516113, 49.952720165252686, 50.64124417304993, 51.32976818084717, 52.01693654060364, 52.70410490036011, 53.38718867301941, 54.07027244567871, 54.763784408569336, 55.45729637145996, 56.14194631576538, 56.8265962600708, 57.50198745727539, 58.17737865447998, 58.860674142837524, 59.54396963119507, 60.237775564193726, 60.93158149719238, 61.619211196899414, 62.306840896606445, 62.98916459083557, 63.6714882850647, 64.35328602790833, 65.03508377075195, 65.71835970878601, 66.40163564682007, 67.08564043045044, 67.76964521408081, 68.4404730796814, 69.11130094528198, 69.79376101493835, 70.47622108459473, 71.15382051467896, 71.83141994476318, 72.51393008232117, 73.19644021987915, 73.87232804298401, 74.54821586608887, 75.23674511909485, 75.92527437210083, 76.60998320579529, 77.29469203948975, 77.96999096870422, 78.6452898979187, 79.39512157440186, 80.14495325088501, 80.8302710056305, 81.51558876037598, 82.19560885429382, 82.87562894821167, 83.55811190605164, 84.2405948638916, 84.91849327087402, 85.59639167785645, 86.28920245170593, 86.98201322555542, 87.67354321479797, 88.36507320404053, 89.04790425300598, 89.73073530197144, 90.4102394580841, 91.08974361419678, 91.78109216690063, 92.47244071960449, 93.15784335136414, 93.84324598312378, 94.52706789970398, 95.21088981628418, 95.89160394668579, 96.5723180770874, 97.2582414150238, 97.9441647529602, 98.63179755210876, 99.31943035125732, 100.00293588638306, 100.68644142150879, 101.36566424369812, 102.04488706588745, 102.72696161270142, 103.40903615951538, 104.08111596107483, 104.75319576263428, 105.43178057670593, 106.11036539077759, 106.79205226898193, 107.47373914718628, 108.15926909446716, 108.84479904174805, 109.52205228805542, 110.1993055343628, 110.89438199996948, 111.58945846557617, 112.27384877204895, 112.95823907852173, 113.65001344680786, 114.341787815094, 115.02108454704285, 115.7003812789917, 116.38830327987671, 117.07622528076172, 117.76291728019714, 118.44960927963257, 119.13423585891724, 119.8188624382019, 120.49783515930176, 121.17680788040161, 121.85937094688416, 122.5419340133667, 123.22565746307373, 123.90938091278076, 124.58828139305115, 125.26718187332153, 125.94772410392761, 126.62826633453369, 127.31471228599548, 128.00115823745728, 128.6892282962799, 129.37729835510254, 130.05989861488342, 130.7424988746643, 131.4241006374359, 132.10570240020752, 132.79360818862915, 133.48151397705078, 134.1697337627411, 134.8579535484314, 135.5397093296051, 136.2214651107788, 136.90483260154724, 137.58820009231567, 138.83050298690796, 140.07280588150024]
[19.6, 19.6, 28.65, 28.65, 35.833333333333336, 35.833333333333336, 43.666666666666664, 43.666666666666664, 48.766666666666666, 48.766666666666666, 51.55, 51.55, 56.55, 56.55, 59.5, 59.5, 59.88333333333333, 59.88333333333333, 63.266666666666666, 63.266666666666666, 64.86666666666666, 64.86666666666666, 67.18333333333334, 67.18333333333334, 70.81666666666666, 70.81666666666666, 70.05, 70.05, 68.81666666666666, 68.81666666666666, 71.93333333333334, 71.93333333333334, 73.41666666666667, 73.41666666666667, 75.7, 75.7, 77.63333333333334, 77.63333333333334, 78.2, 78.2, 79.35, 79.35, 81.15, 81.15, 80.65, 80.65, 80.58333333333333, 80.58333333333333, 81.18333333333334, 81.18333333333334, 82.35, 82.35, 82.91666666666667, 82.91666666666667, 83.08333333333333, 83.08333333333333, 83.38333333333334, 83.38333333333334, 84.2, 84.2, 83.78333333333333, 83.78333333333333, 82.75, 82.75, 83.55, 83.55, 84.1, 84.1, 83.73333333333333, 83.73333333333333, 84.55, 84.55, 84.26666666666667, 84.26666666666667, 84.91666666666667, 84.91666666666667, 84.76666666666667, 84.76666666666667, 84.7, 84.7, 85.25, 85.25, 85.65, 85.65, 85.81666666666666, 85.81666666666666, 85.4, 85.4, 85.93333333333334, 85.93333333333334, 85.28333333333333, 85.28333333333333, 85.86666666666666, 85.86666666666666, 86.31666666666666, 86.31666666666666, 86.46666666666667, 86.46666666666667, 87.05, 87.05, 86.16666666666667, 86.16666666666667, 87.25, 87.25, 86.45, 86.45, 85.9, 85.9, 86.8, 86.8, 86.2, 86.2, 86.15, 86.15, 87.11666666666666, 87.11666666666666, 86.86666666666666, 86.86666666666666, 87.65, 87.65, 87.1, 87.1, 86.8, 86.8, 87.15, 87.15, 87.21666666666667, 87.21666666666667, 87.11666666666666, 87.11666666666666, 87.51666666666667, 87.51666666666667, 86.61666666666666, 86.61666666666666, 87.83333333333333, 87.83333333333333, 87.78333333333333, 87.78333333333333, 88.08333333333333, 88.08333333333333, 87.81666666666666, 87.81666666666666, 88.08333333333333, 88.08333333333333, 87.7, 87.7, 87.66666666666667, 87.66666666666667, 87.88333333333334, 87.88333333333334, 87.0, 87.0, 87.48333333333333, 87.48333333333333, 87.73333333333333, 87.73333333333333, 87.53333333333333, 87.53333333333333, 87.78333333333333, 87.78333333333333, 87.31666666666666, 87.31666666666666, 87.2, 87.2, 87.66666666666667, 87.66666666666667, 87.63333333333334, 87.63333333333334, 87.58333333333333, 87.58333333333333, 87.33333333333333, 87.33333333333333, 87.86666666666666, 87.86666666666666, 88.28333333333333, 88.28333333333333, 87.58333333333333, 87.58333333333333, 88.18333333333334, 88.18333333333334, 88.13333333333334, 88.13333333333334, 87.76666666666667, 87.76666666666667, 87.93333333333334, 87.93333333333334, 88.01666666666667, 88.01666666666667, 88.41666666666667, 88.41666666666667, 88.23333333333333, 88.23333333333333, 88.36666666666666, 88.36666666666666, 88.73333333333333, 88.73333333333333, 88.36666666666666, 88.36666666666666, 88.08333333333333, 88.08333333333333, 88.53333333333333, 88.53333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
lg
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 1063434 (local), 34186 (global); Percentage 3.21 (34186/1063434 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.207, Test loss: 2.080, Test accuracy: 24.62
Round   1, Train loss: 0.996, Test loss: 1.899, Test accuracy: 31.37
Round   2, Train loss: 0.966, Test loss: 1.663, Test accuracy: 39.98
Round   3, Train loss: 0.854, Test loss: 1.707, Test accuracy: 38.53
Round   4, Train loss: 0.898, Test loss: 1.422, Test accuracy: 51.68
Round   5, Train loss: 0.751, Test loss: 1.331, Test accuracy: 55.98
Round   6, Train loss: 0.768, Test loss: 1.222, Test accuracy: 58.88
Round   7, Train loss: 0.833, Test loss: 1.131, Test accuracy: 62.18
Round   8, Train loss: 0.683, Test loss: 1.041, Test accuracy: 63.08
Round   9, Train loss: 0.814, Test loss: 0.887, Test accuracy: 70.52
Round  10, Train loss: 0.708, Test loss: 0.882, Test accuracy: 70.87
Round  11, Train loss: 0.577, Test loss: 0.841, Test accuracy: 71.45
Round  12, Train loss: 0.616, Test loss: 0.724, Test accuracy: 75.67
Round  13, Train loss: 0.544, Test loss: 0.688, Test accuracy: 76.88
Round  14, Train loss: 0.668, Test loss: 0.654, Test accuracy: 77.83
Round  15, Train loss: 0.596, Test loss: 0.629, Test accuracy: 78.43
Round  16, Train loss: 0.456, Test loss: 0.659, Test accuracy: 77.72
Round  17, Train loss: 0.648, Test loss: 0.622, Test accuracy: 78.93
Round  18, Train loss: 0.539, Test loss: 0.614, Test accuracy: 79.37
Round  19, Train loss: 0.543, Test loss: 0.606, Test accuracy: 79.40
Round  20, Train loss: 0.469, Test loss: 0.595, Test accuracy: 79.65
Round  21, Train loss: 0.494, Test loss: 0.562, Test accuracy: 81.32
Round  22, Train loss: 0.482, Test loss: 0.558, Test accuracy: 81.42
Round  23, Train loss: 0.434, Test loss: 0.582, Test accuracy: 80.47
Round  24, Train loss: 0.393, Test loss: 0.583, Test accuracy: 80.78
Round  25, Train loss: 0.371, Test loss: 0.578, Test accuracy: 81.10
Round  26, Train loss: 0.392, Test loss: 0.595, Test accuracy: 81.05
Round  27, Train loss: 0.390, Test loss: 0.617, Test accuracy: 81.13
Round  28, Train loss: 0.312, Test loss: 0.622, Test accuracy: 80.72
Round  29, Train loss: 0.418, Test loss: 0.611, Test accuracy: 80.73
Round  30, Train loss: 0.339, Test loss: 0.636, Test accuracy: 79.80
Round  31, Train loss: 0.337, Test loss: 0.630, Test accuracy: 80.07
Round  32, Train loss: 0.300, Test loss: 0.633, Test accuracy: 80.23
Round  33, Train loss: 0.328, Test loss: 0.632, Test accuracy: 81.30
Round  34, Train loss: 0.364, Test loss: 0.547, Test accuracy: 83.08
Round  35, Train loss: 0.273, Test loss: 0.550, Test accuracy: 82.93
Round  36, Train loss: 0.244, Test loss: 0.587, Test accuracy: 82.62
Round  37, Train loss: 0.250, Test loss: 0.578, Test accuracy: 82.72
Round  38, Train loss: 0.357, Test loss: 0.584, Test accuracy: 82.78
Round  39, Train loss: 0.221, Test loss: 0.597, Test accuracy: 82.70
Round  40, Train loss: 0.272, Test loss: 0.617, Test accuracy: 82.35
Round  41, Train loss: 0.215, Test loss: 0.592, Test accuracy: 82.93
Round  42, Train loss: 0.217, Test loss: 0.613, Test accuracy: 82.77
Round  43, Train loss: 0.296, Test loss: 0.615, Test accuracy: 83.02
Round  44, Train loss: 0.230, Test loss: 0.596, Test accuracy: 83.27
Round  45, Train loss: 0.238, Test loss: 0.575, Test accuracy: 83.80
Round  46, Train loss: 0.233, Test loss: 0.598, Test accuracy: 83.17
Round  47, Train loss: 0.175, Test loss: 0.626, Test accuracy: 82.85
Round  48, Train loss: 0.202, Test loss: 0.622, Test accuracy: 82.70
Round  49, Train loss: 0.219, Test loss: 0.624, Test accuracy: 83.13
Round  50, Train loss: 0.184, Test loss: 0.614, Test accuracy: 83.55
Round  51, Train loss: 0.199, Test loss: 0.612, Test accuracy: 83.75
Round  52, Train loss: 0.147, Test loss: 0.610, Test accuracy: 83.67
Round  53, Train loss: 0.193, Test loss: 0.636, Test accuracy: 83.48
Round  54, Train loss: 0.185, Test loss: 0.649, Test accuracy: 83.78
Round  55, Train loss: 0.189, Test loss: 0.622, Test accuracy: 84.17
Round  56, Train loss: 0.179, Test loss: 0.640, Test accuracy: 83.80
Round  57, Train loss: 0.162, Test loss: 0.633, Test accuracy: 84.28
Round  58, Train loss: 0.158, Test loss: 0.634, Test accuracy: 84.55
Round  59, Train loss: 0.147, Test loss: 0.638, Test accuracy: 84.48
Round  60, Train loss: 0.144, Test loss: 0.642, Test accuracy: 84.50
Round  61, Train loss: 0.160, Test loss: 0.661, Test accuracy: 84.40
Round  62, Train loss: 0.136, Test loss: 0.663, Test accuracy: 84.13
Round  63, Train loss: 0.127, Test loss: 0.668, Test accuracy: 84.38
Round  64, Train loss: 0.141, Test loss: 0.643, Test accuracy: 84.92
Round  65, Train loss: 0.150, Test loss: 0.634, Test accuracy: 84.93
Round  66, Train loss: 0.110, Test loss: 0.617, Test accuracy: 85.62
Round  67, Train loss: 0.082, Test loss: 0.638, Test accuracy: 85.48
Round  68, Train loss: 0.097, Test loss: 0.642, Test accuracy: 85.30
Round  69, Train loss: 0.073, Test loss: 0.676, Test accuracy: 84.83
Round  70, Train loss: 0.108, Test loss: 0.660, Test accuracy: 85.63
Round  71, Train loss: 0.096, Test loss: 0.697, Test accuracy: 85.13
Round  72, Train loss: 0.109, Test loss: 0.670, Test accuracy: 85.15
Round  73, Train loss: 0.111, Test loss: 0.679, Test accuracy: 85.30
Round  74, Train loss: 0.056, Test loss: 0.709, Test accuracy: 85.22
Round  75, Train loss: 0.104, Test loss: 0.729, Test accuracy: 84.72
Round  76, Train loss: 0.101, Test loss: 0.747, Test accuracy: 83.98
Round  77, Train loss: 0.105, Test loss: 0.749, Test accuracy: 84.05
Round  78, Train loss: 0.080, Test loss: 0.732, Test accuracy: 84.58
Round  79, Train loss: 0.078, Test loss: 0.706, Test accuracy: 84.70
Round  80, Train loss: 0.114, Test loss: 0.672, Test accuracy: 85.00
Round  81, Train loss: 0.084, Test loss: 0.688, Test accuracy: 85.25
Round  82, Train loss: 0.087, Test loss: 0.717, Test accuracy: 84.82
Round  83, Train loss: 0.055, Test loss: 0.730, Test accuracy: 84.80
Round  84, Train loss: 0.091, Test loss: 0.717, Test accuracy: 85.10
Round  85, Train loss: 0.068, Test loss: 0.753, Test accuracy: 84.60
Round  86, Train loss: 0.060, Test loss: 0.761, Test accuracy: 84.37
Round  87, Train loss: 0.068, Test loss: 0.775, Test accuracy: 84.27
Round  88, Train loss: 0.076, Test loss: 0.752, Test accuracy: 84.85
Round  89, Train loss: 0.056, Test loss: 0.749, Test accuracy: 85.22
Round  90, Train loss: 0.070, Test loss: 0.730, Test accuracy: 85.13
Round  91, Train loss: 0.060, Test loss: 0.740, Test accuracy: 85.40
Round  92, Train loss: 0.044, Test loss: 0.761, Test accuracy: 85.35
Round  93, Train loss: 0.078, Test loss: 0.763, Test accuracy: 85.23
Round  94, Train loss: 0.058, Test loss: 0.749, Test accuracy: 85.68
Round  95, Train loss: 0.052, Test loss: 0.738, Test accuracy: 85.72
Round  96, Train loss: 0.049, Test loss: 0.753, Test accuracy: 85.60
Round  97, Train loss: 0.064, Test loss: 0.772, Test accuracy: 85.32
Round  98, Train loss: 0.047, Test loss: 0.787, Test accuracy: 85.35
Round  99, Train loss: 0.052, Test loss: 0.773, Test accuracy: 85.38
Final Round, Train loss: 0.053, Test loss: 0.775, Test accuracy: 85.33
Average accuracy final 10 rounds: 85.41666666666666 

784.010311126709
[0.9820723533630371, 1.9641447067260742, 2.645007848739624, 3.325870990753174, 4.014307737350464, 4.702744483947754, 5.394453763961792, 6.08616304397583, 6.772053241729736, 7.457943439483643, 8.137701749801636, 8.817460060119629, 9.50878620147705, 10.200112342834473, 10.895001411437988, 11.589890480041504, 12.283438682556152, 12.9769868850708, 13.661148309707642, 14.345309734344482, 15.029856443405151, 15.71440315246582, 16.409119606018066, 17.103836059570312, 17.80375599861145, 18.503675937652588, 19.179890394210815, 19.856104850769043, 20.550847053527832, 21.24558925628662, 21.937066555023193, 22.628543853759766, 23.31763482093811, 24.006725788116455, 24.693893909454346, 25.381062030792236, 26.08008074760437, 26.779099464416504, 27.466094493865967, 28.15308952331543, 28.831549882888794, 29.510010242462158, 30.201449632644653, 30.89288902282715, 31.58572793006897, 32.27856683731079, 32.96666240692139, 33.65475797653198, 34.336384534835815, 35.01801109313965, 35.708616971969604, 36.39922285079956, 37.08536767959595, 37.771512508392334, 38.4537250995636, 39.13593769073486, 39.81001853942871, 40.48409938812256, 41.1685004234314, 41.852901458740234, 42.534226417541504, 43.21555137634277, 43.88206720352173, 44.548583030700684, 45.23122978210449, 45.9138765335083, 46.597115993499756, 47.28035545349121, 47.96831560134888, 48.65627574920654, 49.33676719665527, 50.017258644104004, 50.70797944068909, 51.39870023727417, 52.09573841094971, 52.792776584625244, 53.486690044403076, 54.18060350418091, 54.86260747909546, 55.54461145401001, 56.23898506164551, 56.933358669281006, 57.62315058708191, 58.31294250488281, 58.99281597137451, 59.67268943786621, 60.3405647277832, 61.008440017700195, 61.695730447769165, 62.383020877838135, 63.059707164764404, 63.736393451690674, 64.40183711051941, 65.06728076934814, 65.74446868896484, 66.42165660858154, 67.10180568695068, 67.78195476531982, 68.46861243247986, 69.15527009963989, 69.82303047180176, 70.49079084396362, 71.1723563671112, 71.85392189025879, 72.543705701828, 73.23348951339722, 73.92658114433289, 74.61967277526855, 75.3041307926178, 75.98858880996704, 76.68075108528137, 77.3729133605957, 78.07003498077393, 78.76715660095215, 79.45128917694092, 80.13542175292969, 80.81893157958984, 81.50244140625, 82.1952702999115, 82.888099193573, 83.57837152481079, 84.26864385604858, 84.94627928733826, 85.62391471862793, 86.31318020820618, 87.00244569778442, 87.69936847686768, 88.39629125595093, 89.08306694030762, 89.7698426246643, 90.45080327987671, 91.13176393508911, 91.81963157653809, 92.50749921798706, 93.20431709289551, 93.90113496780396, 94.58363151550293, 95.2661280632019, 95.94663429260254, 96.62714052200317, 97.32509684562683, 98.02305316925049, 98.71570754051208, 99.40836191177368, 100.09920406341553, 100.79004621505737, 101.47530436515808, 102.16056251525879, 102.85247564315796, 103.54438877105713, 104.23713541030884, 104.92988204956055, 105.60985541343689, 106.28982877731323, 106.97057628631592, 107.6513237953186, 108.33607697486877, 109.02083015441895, 109.70572972297668, 110.39062929153442, 111.05904245376587, 111.72745561599731, 112.40871524810791, 113.0899748802185, 113.77077412605286, 114.4515733718872, 115.1309745311737, 115.8103756904602, 116.4748764038086, 117.13937711715698, 117.82337355613708, 118.50736999511719, 119.1957471370697, 119.88412427902222, 120.56288862228394, 121.24165296554565, 121.91350603103638, 122.5853590965271, 123.26930952072144, 123.95325994491577, 124.64315271377563, 125.3330454826355, 126.01188683509827, 126.69072818756104, 127.3765299320221, 128.06233167648315, 128.75036597251892, 129.4384002685547, 130.13052916526794, 130.8226580619812, 131.51047039031982, 132.19828271865845, 132.88096475601196, 133.56364679336548, 134.24703550338745, 134.93042421340942, 135.68092966079712, 136.43143510818481, 137.1033010482788, 137.7751669883728, 139.11475682258606, 140.45434665679932]
[24.616666666666667, 24.616666666666667, 31.366666666666667, 31.366666666666667, 39.983333333333334, 39.983333333333334, 38.53333333333333, 38.53333333333333, 51.68333333333333, 51.68333333333333, 55.983333333333334, 55.983333333333334, 58.88333333333333, 58.88333333333333, 62.18333333333333, 62.18333333333333, 63.083333333333336, 63.083333333333336, 70.51666666666667, 70.51666666666667, 70.86666666666666, 70.86666666666666, 71.45, 71.45, 75.66666666666667, 75.66666666666667, 76.88333333333334, 76.88333333333334, 77.83333333333333, 77.83333333333333, 78.43333333333334, 78.43333333333334, 77.71666666666667, 77.71666666666667, 78.93333333333334, 78.93333333333334, 79.36666666666666, 79.36666666666666, 79.4, 79.4, 79.65, 79.65, 81.31666666666666, 81.31666666666666, 81.41666666666667, 81.41666666666667, 80.46666666666667, 80.46666666666667, 80.78333333333333, 80.78333333333333, 81.1, 81.1, 81.05, 81.05, 81.13333333333334, 81.13333333333334, 80.71666666666667, 80.71666666666667, 80.73333333333333, 80.73333333333333, 79.8, 79.8, 80.06666666666666, 80.06666666666666, 80.23333333333333, 80.23333333333333, 81.3, 81.3, 83.08333333333333, 83.08333333333333, 82.93333333333334, 82.93333333333334, 82.61666666666666, 82.61666666666666, 82.71666666666667, 82.71666666666667, 82.78333333333333, 82.78333333333333, 82.7, 82.7, 82.35, 82.35, 82.93333333333334, 82.93333333333334, 82.76666666666667, 82.76666666666667, 83.01666666666667, 83.01666666666667, 83.26666666666667, 83.26666666666667, 83.8, 83.8, 83.16666666666667, 83.16666666666667, 82.85, 82.85, 82.7, 82.7, 83.13333333333334, 83.13333333333334, 83.55, 83.55, 83.75, 83.75, 83.66666666666667, 83.66666666666667, 83.48333333333333, 83.48333333333333, 83.78333333333333, 83.78333333333333, 84.16666666666667, 84.16666666666667, 83.8, 83.8, 84.28333333333333, 84.28333333333333, 84.55, 84.55, 84.48333333333333, 84.48333333333333, 84.5, 84.5, 84.4, 84.4, 84.13333333333334, 84.13333333333334, 84.38333333333334, 84.38333333333334, 84.91666666666667, 84.91666666666667, 84.93333333333334, 84.93333333333334, 85.61666666666666, 85.61666666666666, 85.48333333333333, 85.48333333333333, 85.3, 85.3, 84.83333333333333, 84.83333333333333, 85.63333333333334, 85.63333333333334, 85.13333333333334, 85.13333333333334, 85.15, 85.15, 85.3, 85.3, 85.21666666666667, 85.21666666666667, 84.71666666666667, 84.71666666666667, 83.98333333333333, 83.98333333333333, 84.05, 84.05, 84.58333333333333, 84.58333333333333, 84.7, 84.7, 85.0, 85.0, 85.25, 85.25, 84.81666666666666, 84.81666666666666, 84.8, 84.8, 85.1, 85.1, 84.6, 84.6, 84.36666666666666, 84.36666666666666, 84.26666666666667, 84.26666666666667, 84.85, 84.85, 85.21666666666667, 85.21666666666667, 85.13333333333334, 85.13333333333334, 85.4, 85.4, 85.35, 85.35, 85.23333333333333, 85.23333333333333, 85.68333333333334, 85.68333333333334, 85.71666666666667, 85.71666666666667, 85.6, 85.6, 85.31666666666666, 85.31666666666666, 85.35, 85.35, 85.38333333333334, 85.38333333333334, 85.33333333333333, 85.33333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
Round   0, Train loss: 0.845, Test loss: 2.396, Test accuracy: 25.13
Round   1, Train loss: 0.776, Test loss: 2.458, Test accuracy: 33.62
Round   2, Train loss: 0.724, Test loss: 2.274, Test accuracy: 40.93
Round   3, Train loss: 0.628, Test loss: 2.178, Test accuracy: 49.48
Round   4, Train loss: 0.604, Test loss: 2.162, Test accuracy: 48.77
Round   5, Train loss: 0.619, Test loss: 2.092, Test accuracy: 51.98
Round   6, Train loss: 0.484, Test loss: 2.106, Test accuracy: 53.70
Round   7, Train loss: 0.517, Test loss: 2.053, Test accuracy: 53.77
Round   8, Train loss: 0.558, Test loss: 1.948, Test accuracy: 61.92
Round   9, Train loss: 0.450, Test loss: 1.913, Test accuracy: 64.68
Round  10, Train loss: 0.387, Test loss: 1.901, Test accuracy: 65.55
Round  11, Train loss: 0.470, Test loss: 1.795, Test accuracy: 68.40
Round  12, Train loss: 0.416, Test loss: 1.748, Test accuracy: 68.78
Round  13, Train loss: 0.415, Test loss: 1.717, Test accuracy: 68.83
Round  14, Train loss: 0.358, Test loss: 1.676, Test accuracy: 69.28
Round  15, Train loss: 0.363, Test loss: 1.653, Test accuracy: 71.07
Round  16, Train loss: 0.365, Test loss: 1.604, Test accuracy: 72.62
Round  17, Train loss: 0.276, Test loss: 1.577, Test accuracy: 70.95
Round  18, Train loss: 0.338, Test loss: 1.554, Test accuracy: 72.18
Round  19, Train loss: 0.296, Test loss: 1.523, Test accuracy: 72.83
Round  20, Train loss: 0.309, Test loss: 1.517, Test accuracy: 71.77
Round  21, Train loss: 0.267, Test loss: 1.489, Test accuracy: 72.80
Round  22, Train loss: 0.273, Test loss: 1.463, Test accuracy: 73.50
Round  23, Train loss: 0.262, Test loss: 1.459, Test accuracy: 74.08
Round  24, Train loss: 0.268, Test loss: 1.440, Test accuracy: 73.80
Round  25, Train loss: 0.252, Test loss: 1.397, Test accuracy: 74.57
Round  26, Train loss: 0.252, Test loss: 1.389, Test accuracy: 75.22
Round  27, Train loss: 0.245, Test loss: 1.367, Test accuracy: 73.57
Round  28, Train loss: 0.281, Test loss: 1.336, Test accuracy: 75.00
Round  29, Train loss: 0.223, Test loss: 1.308, Test accuracy: 74.33
Round  30, Train loss: 0.233, Test loss: 1.299, Test accuracy: 74.90
Round  31, Train loss: 0.194, Test loss: 1.279, Test accuracy: 74.70
Round  32, Train loss: 0.225, Test loss: 1.273, Test accuracy: 76.12
Round  33, Train loss: 0.208, Test loss: 1.261, Test accuracy: 76.02
Round  34, Train loss: 0.208, Test loss: 1.242, Test accuracy: 75.87
Round  35, Train loss: 0.187, Test loss: 1.194, Test accuracy: 75.00
Round  36, Train loss: 0.145, Test loss: 1.179, Test accuracy: 74.37
Round  37, Train loss: 0.158, Test loss: 1.165, Test accuracy: 76.07
Round  38, Train loss: 0.161, Test loss: 1.158, Test accuracy: 74.95
Round  39, Train loss: 0.164, Test loss: 1.116, Test accuracy: 74.55
Round  40, Train loss: 0.160, Test loss: 1.102, Test accuracy: 74.45
Round  41, Train loss: 0.152, Test loss: 1.091, Test accuracy: 74.63
Round  42, Train loss: 0.166, Test loss: 1.105, Test accuracy: 74.75
Round  43, Train loss: 0.137, Test loss: 1.093, Test accuracy: 75.03
Round  44, Train loss: 0.136, Test loss: 1.064, Test accuracy: 75.55
Round  45, Train loss: 0.126, Test loss: 1.044, Test accuracy: 75.72
Round  46, Train loss: 0.134, Test loss: 1.019, Test accuracy: 75.83
Round  47, Train loss: 0.138, Test loss: 1.012, Test accuracy: 76.07
Round  48, Train loss: 0.126, Test loss: 0.999, Test accuracy: 76.07
Round  49, Train loss: 0.139, Test loss: 0.982, Test accuracy: 77.45
Round  50, Train loss: 0.141, Test loss: 0.966, Test accuracy: 77.40
Round  51, Train loss: 0.127, Test loss: 0.958, Test accuracy: 76.98
Round  52, Train loss: 0.107, Test loss: 0.950, Test accuracy: 77.88
Round  53, Train loss: 0.114, Test loss: 0.929, Test accuracy: 78.28
Round  54, Train loss: 0.110, Test loss: 0.942, Test accuracy: 77.68
Round  55, Train loss: 0.150, Test loss: 0.925, Test accuracy: 77.58
Round  56, Train loss: 0.119, Test loss: 0.933, Test accuracy: 76.40
Round  57, Train loss: 0.082, Test loss: 0.914, Test accuracy: 77.43
Round  58, Train loss: 0.111, Test loss: 0.926, Test accuracy: 76.73
Round  59, Train loss: 0.113, Test loss: 0.898, Test accuracy: 77.17
Round  60, Train loss: 0.078, Test loss: 0.885, Test accuracy: 76.62
Round  61, Train loss: 0.098, Test loss: 0.874, Test accuracy: 76.93
Round  62, Train loss: 0.126, Test loss: 0.873, Test accuracy: 76.42
Round  63, Train loss: 0.118, Test loss: 0.894, Test accuracy: 74.45
Round  64, Train loss: 0.092, Test loss: 0.864, Test accuracy: 75.62
Round  65, Train loss: 0.107, Test loss: 0.850, Test accuracy: 76.18
Round  66, Train loss: 0.102, Test loss: 0.879, Test accuracy: 75.53
Round  67, Train loss: 0.103, Test loss: 0.855, Test accuracy: 76.57
Round  68, Train loss: 0.082, Test loss: 0.845, Test accuracy: 76.35
Round  69, Train loss: 0.069, Test loss: 0.837, Test accuracy: 76.48
Round  70, Train loss: 0.082, Test loss: 0.830, Test accuracy: 76.52
Round  71, Train loss: 0.100, Test loss: 0.817, Test accuracy: 76.67
Round  72, Train loss: 0.110, Test loss: 0.807, Test accuracy: 77.03
Round  73, Train loss: 0.076, Test loss: 0.823, Test accuracy: 76.20
Round  74, Train loss: 0.085, Test loss: 0.816, Test accuracy: 75.28
Round  75, Train loss: 0.067, Test loss: 0.810, Test accuracy: 75.72
Round  76, Train loss: 0.072, Test loss: 0.795, Test accuracy: 76.32
Round  77, Train loss: 0.065, Test loss: 0.799, Test accuracy: 75.77
Round  78, Train loss: 0.073, Test loss: 0.785, Test accuracy: 75.58
Round  79, Train loss: 0.131, Test loss: 0.798, Test accuracy: 75.17
Round  80, Train loss: 0.063, Test loss: 0.756, Test accuracy: 75.58
Round  81, Train loss: 0.069, Test loss: 0.743, Test accuracy: 76.95
Round  82, Train loss: 0.087, Test loss: 0.764, Test accuracy: 76.32
Round  83, Train loss: 0.088, Test loss: 0.766, Test accuracy: 76.70
Round  84, Train loss: 0.078, Test loss: 0.773, Test accuracy: 75.95
Round  85, Train loss: 0.073, Test loss: 0.764, Test accuracy: 76.15
Round  86, Train loss: 0.071, Test loss: 0.746, Test accuracy: 76.72
Round  87, Train loss: 0.061, Test loss: 0.745, Test accuracy: 76.67
Round  88, Train loss: 0.067, Test loss: 0.743, Test accuracy: 77.40
Round  89, Train loss: 0.058, Test loss: 0.728, Test accuracy: 77.68
Round  90, Train loss: 0.083, Test loss: 0.751, Test accuracy: 76.80
Round  91, Train loss: 0.056, Test loss: 0.734, Test accuracy: 77.13
Round  92, Train loss: 0.098, Test loss: 0.743, Test accuracy: 76.28
Round  93, Train loss: 0.063, Test loss: 0.726, Test accuracy: 76.78
Round  94, Train loss: 0.087, Test loss: 0.727, Test accuracy: 77.40
Round  95, Train loss: 0.059, Test loss: 0.725, Test accuracy: 75.72
Round  96, Train loss: 0.077, Test loss: 0.738, Test accuracy: 75.27
Round  97, Train loss: 0.080, Test loss: 0.743, Test accuracy: 75.33
Round  98, Train loss: 0.058, Test loss: 0.732, Test accuracy: 75.17
Round  99, Train loss: 0.069, Test loss: 0.718, Test accuracy: 76.95
Final Round, Train loss: 0.068, Test loss: 0.727, Test accuracy: 75.12
Average accuracy final 10 rounds: 76.28333333333333
1009.3232748508453
[]
[25.133333333333333, 33.61666666666667, 40.93333333333333, 49.483333333333334, 48.766666666666666, 51.983333333333334, 53.7, 53.766666666666666, 61.916666666666664, 64.68333333333334, 65.55, 68.4, 68.78333333333333, 68.83333333333333, 69.28333333333333, 71.06666666666666, 72.61666666666666, 70.95, 72.18333333333334, 72.83333333333333, 71.76666666666667, 72.8, 73.5, 74.08333333333333, 73.8, 74.56666666666666, 75.21666666666667, 73.56666666666666, 75.0, 74.33333333333333, 74.9, 74.7, 76.11666666666666, 76.01666666666667, 75.86666666666666, 75.0, 74.36666666666666, 76.06666666666666, 74.95, 74.55, 74.45, 74.63333333333334, 74.75, 75.03333333333333, 75.55, 75.71666666666667, 75.83333333333333, 76.06666666666666, 76.06666666666666, 77.45, 77.4, 76.98333333333333, 77.88333333333334, 78.28333333333333, 77.68333333333334, 77.58333333333333, 76.4, 77.43333333333334, 76.73333333333333, 77.16666666666667, 76.61666666666666, 76.93333333333334, 76.41666666666667, 74.45, 75.61666666666666, 76.18333333333334, 75.53333333333333, 76.56666666666666, 76.35, 76.48333333333333, 76.51666666666667, 76.66666666666667, 77.03333333333333, 76.2, 75.28333333333333, 75.71666666666667, 76.31666666666666, 75.76666666666667, 75.58333333333333, 75.16666666666667, 75.58333333333333, 76.95, 76.31666666666666, 76.7, 75.95, 76.15, 76.71666666666667, 76.66666666666667, 77.4, 77.68333333333334, 76.8, 77.13333333333334, 76.28333333333333, 76.78333333333333, 77.4, 75.71666666666667, 75.26666666666667, 75.33333333333333, 75.16666666666667, 76.95, 75.11666666666666]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
Round   0, Train loss: 1.283, Test loss: 1.901, Test accuracy: 26.50
Round   1, Train loss: 1.235, Test loss: 1.698, Test accuracy: 33.30
Round   2, Train loss: 1.053, Test loss: 1.428, Test accuracy: 41.70
Round   3, Train loss: 0.482, Test loss: 1.419, Test accuracy: 43.17
Round   4, Train loss: 0.579, Test loss: 1.171, Test accuracy: 52.92
Round   5, Train loss: 0.022, Test loss: 1.068, Test accuracy: 55.58
Round   6, Train loss: -0.456, Test loss: 0.886, Test accuracy: 60.88
Round   7, Train loss: -0.466, Test loss: 0.871, Test accuracy: 62.50
Round   8, Train loss: -0.306, Test loss: 0.911, Test accuracy: 59.95
Round   9, Train loss: -0.040, Test loss: 0.806, Test accuracy: 64.30
Round  10, Train loss: -0.908, Test loss: 0.809, Test accuracy: 64.73
Round  11, Train loss: -1.450, Test loss: 0.780, Test accuracy: 66.22
Round  12, Train loss: -0.199, Test loss: 0.791, Test accuracy: 65.32
Round  13, Train loss: -0.744, Test loss: 0.735, Test accuracy: 67.83
Round  14, Train loss: -1.712, Test loss: 0.743, Test accuracy: 66.58
Round  15, Train loss: -2.136, Test loss: 0.719, Test accuracy: 68.07
Round  16, Train loss: -2.268, Test loss: 0.709, Test accuracy: 68.92
Round  17, Train loss: -2.502, Test loss: 0.716, Test accuracy: 69.45
Round  18, Train loss: -2.150, Test loss: 0.709, Test accuracy: 69.85
Round  19, Train loss: -2.867, Test loss: 0.687, Test accuracy: 70.62
Round  20, Train loss: -2.652, Test loss: 0.673, Test accuracy: 71.38
Round  21, Train loss: -2.410, Test loss: 0.646, Test accuracy: 73.62
Round  22, Train loss: -3.105, Test loss: 0.656, Test accuracy: 72.62
Round  23, Train loss: -3.599, Test loss: 0.649, Test accuracy: 72.80
Round  24, Train loss: -2.789, Test loss: 0.667, Test accuracy: 72.20
Round  25, Train loss: -3.740, Test loss: 0.659, Test accuracy: 73.27
Round  26, Train loss: -3.034, Test loss: 0.663, Test accuracy: 72.97
Round  27, Train loss: -3.094, Test loss: 0.638, Test accuracy: 74.68
Round  28, Train loss: -3.384, Test loss: 0.639, Test accuracy: 74.13
Round  29, Train loss: -4.027, Test loss: 0.631, Test accuracy: 74.22
Round  30, Train loss: -4.569, Test loss: 0.651, Test accuracy: 74.33
Round  31, Train loss: -4.476, Test loss: 0.642, Test accuracy: 73.40
Round  32, Train loss: -3.077, Test loss: 0.638, Test accuracy: 73.88
Round  33, Train loss: -4.929, Test loss: 0.648, Test accuracy: 74.07
Round  34, Train loss: -4.216, Test loss: 0.646, Test accuracy: 74.40
Round  35, Train loss: -4.293, Test loss: 0.633, Test accuracy: 75.12
Round  36, Train loss: -5.162, Test loss: 0.620, Test accuracy: 75.85
Round  37, Train loss: -4.642, Test loss: 0.638, Test accuracy: 74.90
Round  38, Train loss: -4.550, Test loss: 0.614, Test accuracy: 75.93
Round  39, Train loss: -4.559, Test loss: 0.595, Test accuracy: 77.25
Round  40, Train loss: -4.542, Test loss: 0.577, Test accuracy: 78.07
Round  41, Train loss: -4.631, Test loss: 0.566, Test accuracy: 78.25
Round  42, Train loss: -5.073, Test loss: 0.577, Test accuracy: 78.58
Round  43, Train loss: -4.378, Test loss: 0.587, Test accuracy: 77.73
Round  44, Train loss: -5.444, Test loss: 0.604, Test accuracy: 77.13
Round  45, Train loss: -5.421, Test loss: 0.589, Test accuracy: 78.13
Round  46, Train loss: -5.351, Test loss: 0.589, Test accuracy: 78.47
Round  47, Train loss: -5.154, Test loss: 0.609, Test accuracy: 77.57
Round  48, Train loss: -4.343, Test loss: 0.627, Test accuracy: 76.48
Round  49, Train loss: -5.314, Test loss: 0.609, Test accuracy: 77.42
Round  50, Train loss: -5.981, Test loss: 0.607, Test accuracy: 77.53
Round  51, Train loss: -6.295, Test loss: 0.654, Test accuracy: 77.07
Round  52, Train loss: -5.905, Test loss: 0.633, Test accuracy: 77.97
Round  53, Train loss: -6.337, Test loss: 0.618, Test accuracy: 77.57
Round  54, Train loss: -5.371, Test loss: 0.601, Test accuracy: 78.15
Round  55, Train loss: -6.676, Test loss: 0.582, Test accuracy: 79.33
Round  56, Train loss: -5.280, Test loss: 0.590, Test accuracy: 78.72
Round  57, Train loss: -6.495, Test loss: 0.575, Test accuracy: 79.62
Round  58, Train loss: -5.914, Test loss: 0.582, Test accuracy: 78.57
Round  59, Train loss: -6.428, Test loss: 0.613, Test accuracy: 78.33
Round  60, Train loss: -5.969, Test loss: 0.610, Test accuracy: 78.55
Round  61, Train loss: -6.260, Test loss: 0.604, Test accuracy: 78.47
Round  62, Train loss: -5.522, Test loss: 0.601, Test accuracy: 78.18
Round  63, Train loss: -5.364, Test loss: 0.621, Test accuracy: 77.57
Round  64, Train loss: -6.049, Test loss: 0.613, Test accuracy: 78.38
Round  65, Train loss: -5.242, Test loss: 0.619, Test accuracy: 77.43
Round  66, Train loss: -6.620, Test loss: 0.620, Test accuracy: 78.60
Round  67, Train loss: -6.547, Test loss: 0.612, Test accuracy: 78.13
Round  68, Train loss: -6.698, Test loss: 0.617, Test accuracy: 79.07
Round  69, Train loss: -5.960, Test loss: 0.604, Test accuracy: 78.87
Round  70, Train loss: -6.365, Test loss: 0.610, Test accuracy: 79.03
Round  71, Train loss: -6.373, Test loss: 0.610, Test accuracy: 79.07
Round  72, Train loss: -6.188, Test loss: 0.619, Test accuracy: 78.38
Round  73, Train loss: -6.350, Test loss: 0.624, Test accuracy: 78.80
Round  74, Train loss: -5.578, Test loss: 0.616, Test accuracy: 78.78
Round  75, Train loss: -5.205, Test loss: 0.599, Test accuracy: 78.88
Round  76, Train loss: -6.504, Test loss: 0.602, Test accuracy: 79.22
Round  77, Train loss: -5.771, Test loss: 0.610, Test accuracy: 78.88
Round  78, Train loss: -5.691, Test loss: 0.625, Test accuracy: 79.17
Round  79, Train loss: -4.697, Test loss: 0.586, Test accuracy: 79.78
Round  80, Train loss: -6.646, Test loss: 0.590, Test accuracy: 80.18
Round  81, Train loss: -5.423, Test loss: 0.586, Test accuracy: 79.85
Round  82, Train loss: -6.701, Test loss: 0.598, Test accuracy: 79.52
Round  83, Train loss: -6.053, Test loss: 0.584, Test accuracy: 80.32
Round  84, Train loss: -6.914, Test loss: 0.595, Test accuracy: 79.58
Round  85, Train loss: -6.150, Test loss: 0.616, Test accuracy: 79.92
Round  86, Train loss: -5.868, Test loss: 0.608, Test accuracy: 79.88
Round  87, Train loss: -5.479, Test loss: 0.615, Test accuracy: 79.97
Round  88, Train loss: -6.097, Test loss: 0.599, Test accuracy: 80.73
Round  89, Train loss: -5.359, Test loss: 0.603, Test accuracy: 80.90
Round  90, Train loss: -6.845, Test loss: 0.588, Test accuracy: 80.98
Round  91, Train loss: -6.182, Test loss: 0.591, Test accuracy: 80.90
Round  92, Train loss: -6.724, Test loss: 0.598, Test accuracy: 80.65
Round  93, Train loss: -6.495, Test loss: 0.590, Test accuracy: 80.80
Round  94, Train loss: -5.558, Test loss: 0.586, Test accuracy: 81.47
Round  95, Train loss: -5.906, Test loss: 0.579, Test accuracy: 81.78
Round  96, Train loss: -5.846, Test loss: 0.582, Test accuracy: 81.27
Round  97, Train loss: -5.554, Test loss: 0.589, Test accuracy: 81.45
Round  98, Train loss: -5.760, Test loss: 0.569, Test accuracy: 81.48
Round  99, Train loss: -5.353, Test loss: 0.587, Test accuracy: 81.05
Final Round, Train loss: 0.676, Test loss: 0.534, Test accuracy: 80.05
Average accuracy final 10 rounds: 81.18333333333335
Average global accuracy final 10 rounds: 81.18333333333335
705.0760407447815
[]
[26.5, 33.3, 41.7, 43.166666666666664, 52.916666666666664, 55.583333333333336, 60.88333333333333, 62.5, 59.95, 64.3, 64.73333333333333, 66.21666666666667, 65.31666666666666, 67.83333333333333, 66.58333333333333, 68.06666666666666, 68.91666666666667, 69.45, 69.85, 70.61666666666666, 71.38333333333334, 73.61666666666666, 72.61666666666666, 72.8, 72.2, 73.26666666666667, 72.96666666666667, 74.68333333333334, 74.13333333333334, 74.21666666666667, 74.33333333333333, 73.4, 73.88333333333334, 74.06666666666666, 74.4, 75.11666666666666, 75.85, 74.9, 75.93333333333334, 77.25, 78.06666666666666, 78.25, 78.58333333333333, 77.73333333333333, 77.13333333333334, 78.13333333333334, 78.46666666666667, 77.56666666666666, 76.48333333333333, 77.41666666666667, 77.53333333333333, 77.06666666666666, 77.96666666666667, 77.56666666666666, 78.15, 79.33333333333333, 78.71666666666667, 79.61666666666666, 78.56666666666666, 78.33333333333333, 78.55, 78.46666666666667, 78.18333333333334, 77.56666666666666, 78.38333333333334, 77.43333333333334, 78.6, 78.13333333333334, 79.06666666666666, 78.86666666666666, 79.03333333333333, 79.06666666666666, 78.38333333333334, 78.8, 78.78333333333333, 78.88333333333334, 79.21666666666667, 78.88333333333334, 79.16666666666667, 79.78333333333333, 80.18333333333334, 79.85, 79.51666666666667, 80.31666666666666, 79.58333333333333, 79.91666666666667, 79.88333333333334, 79.96666666666667, 80.73333333333333, 80.9, 80.98333333333333, 80.9, 80.65, 80.8, 81.46666666666667, 81.78333333333333, 81.26666666666667, 81.45, 81.48333333333333, 81.05, 80.05]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar100, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
prox
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.241, Test loss: 2.104, Test accuracy: 21.62
Round   0, Global train loss: 1.241, Global test loss: 2.462, Global test accuracy: 9.75
Round   1, Train loss: 1.045, Test loss: 2.140, Test accuracy: 34.93
Round   1, Global train loss: 1.045, Global test loss: 2.799, Global test accuracy: 16.02
Round   2, Train loss: 0.969, Test loss: 1.469, Test accuracy: 44.45
Round   2, Global train loss: 0.969, Global test loss: 2.316, Global test accuracy: 15.65
Round   3, Train loss: 0.992, Test loss: 1.178, Test accuracy: 54.95
Round   3, Global train loss: 0.992, Global test loss: 2.372, Global test accuracy: 15.25
Round   4, Train loss: 0.966, Test loss: 0.959, Test accuracy: 62.48
Round   4, Global train loss: 0.966, Global test loss: 2.375, Global test accuracy: 14.43
Round   5, Train loss: 0.864, Test loss: 0.799, Test accuracy: 67.03
Round   5, Global train loss: 0.864, Global test loss: 2.381, Global test accuracy: 14.55
Round   6, Train loss: 0.937, Test loss: 0.687, Test accuracy: 71.28
Round   6, Global train loss: 0.937, Global test loss: 2.551, Global test accuracy: 15.82
Round   7, Train loss: 0.932, Test loss: 0.665, Test accuracy: 72.87
Round   7, Global train loss: 0.932, Global test loss: 2.366, Global test accuracy: 15.97
Round   8, Train loss: 0.933, Test loss: 0.650, Test accuracy: 73.87
Round   8, Global train loss: 0.933, Global test loss: 2.539, Global test accuracy: 16.10
Round   9, Train loss: 0.750, Test loss: 0.648, Test accuracy: 74.12
Round   9, Global train loss: 0.750, Global test loss: 2.415, Global test accuracy: 14.93
Round  10, Train loss: 0.728, Test loss: 0.650, Test accuracy: 74.02
Round  10, Global train loss: 0.728, Global test loss: 2.324, Global test accuracy: 16.30
Round  11, Train loss: 0.660, Test loss: 0.631, Test accuracy: 74.93
Round  11, Global train loss: 0.660, Global test loss: 2.643, Global test accuracy: 15.45
Round  12, Train loss: 0.803, Test loss: 0.598, Test accuracy: 76.58
Round  12, Global train loss: 0.803, Global test loss: 2.520, Global test accuracy: 20.00
Round  13, Train loss: 0.713, Test loss: 0.587, Test accuracy: 76.87
Round  13, Global train loss: 0.713, Global test loss: 2.414, Global test accuracy: 18.30
Round  14, Train loss: 0.808, Test loss: 0.581, Test accuracy: 77.10
Round  14, Global train loss: 0.808, Global test loss: 2.452, Global test accuracy: 18.98
Round  15, Train loss: 0.699, Test loss: 0.592, Test accuracy: 76.78
Round  15, Global train loss: 0.699, Global test loss: 2.420, Global test accuracy: 18.03
Round  16, Train loss: 0.720, Test loss: 0.573, Test accuracy: 77.37
Round  16, Global train loss: 0.720, Global test loss: 2.266, Global test accuracy: 18.45
Round  17, Train loss: 0.754, Test loss: 0.568, Test accuracy: 77.68
Round  17, Global train loss: 0.754, Global test loss: 2.659, Global test accuracy: 10.70
Round  18, Train loss: 0.721, Test loss: 0.571, Test accuracy: 77.45
Round  18, Global train loss: 0.721, Global test loss: 2.714, Global test accuracy: 17.78
Round  19, Train loss: 0.750, Test loss: 0.576, Test accuracy: 77.68
Round  19, Global train loss: 0.750, Global test loss: 2.324, Global test accuracy: 18.67
Round  20, Train loss: 0.651, Test loss: 0.566, Test accuracy: 78.32
Round  20, Global train loss: 0.651, Global test loss: 2.669, Global test accuracy: 19.12
Round  21, Train loss: 0.680, Test loss: 0.545, Test accuracy: 79.27
Round  21, Global train loss: 0.680, Global test loss: 2.511, Global test accuracy: 19.98
Round  22, Train loss: 0.669, Test loss: 0.538, Test accuracy: 80.05
Round  22, Global train loss: 0.669, Global test loss: 2.305, Global test accuracy: 20.77
Round  23, Train loss: 0.685, Test loss: 0.520, Test accuracy: 80.47
Round  23, Global train loss: 0.685, Global test loss: 2.349, Global test accuracy: 20.10
Round  24, Train loss: 0.623, Test loss: 0.511, Test accuracy: 81.08
Round  24, Global train loss: 0.623, Global test loss: 2.526, Global test accuracy: 21.22
Round  25, Train loss: 0.545, Test loss: 0.509, Test accuracy: 81.00
Round  25, Global train loss: 0.545, Global test loss: 2.573, Global test accuracy: 19.87
Round  26, Train loss: 0.570, Test loss: 0.511, Test accuracy: 80.75
Round  26, Global train loss: 0.570, Global test loss: 2.426, Global test accuracy: 22.70
Round  27, Train loss: 0.651, Test loss: 0.501, Test accuracy: 81.70
Round  27, Global train loss: 0.651, Global test loss: 2.520, Global test accuracy: 17.15
Round  28, Train loss: 0.615, Test loss: 0.487, Test accuracy: 81.63
Round  28, Global train loss: 0.615, Global test loss: 2.515, Global test accuracy: 21.40
Round  29, Train loss: 0.552, Test loss: 0.488, Test accuracy: 81.75
Round  29, Global train loss: 0.552, Global test loss: 2.480, Global test accuracy: 18.10
Round  30, Train loss: 0.576, Test loss: 0.483, Test accuracy: 81.82
Round  30, Global train loss: 0.576, Global test loss: 2.476, Global test accuracy: 21.32
Round  31, Train loss: 0.540, Test loss: 0.462, Test accuracy: 82.75
Round  31, Global train loss: 0.540, Global test loss: 3.378, Global test accuracy: 19.00
Round  32, Train loss: 0.540, Test loss: 0.458, Test accuracy: 82.95
Round  32, Global train loss: 0.540, Global test loss: 2.590, Global test accuracy: 22.47
Round  33, Train loss: 0.497, Test loss: 0.473, Test accuracy: 82.23
Round  33, Global train loss: 0.497, Global test loss: 2.512, Global test accuracy: 19.83
Round  34, Train loss: 0.511, Test loss: 0.473, Test accuracy: 82.83
Round  34, Global train loss: 0.511, Global test loss: 2.439, Global test accuracy: 20.02
Round  35, Train loss: 0.502, Test loss: 0.464, Test accuracy: 83.50
Round  35, Global train loss: 0.502, Global test loss: 2.715, Global test accuracy: 21.05
Round  36, Train loss: 0.434, Test loss: 0.449, Test accuracy: 84.15
Round  36, Global train loss: 0.434, Global test loss: 3.069, Global test accuracy: 17.22
Round  37, Train loss: 0.454, Test loss: 0.459, Test accuracy: 84.07
Round  37, Global train loss: 0.454, Global test loss: 2.442, Global test accuracy: 21.13
Round  38, Train loss: 0.497, Test loss: 0.467, Test accuracy: 83.65
Round  38, Global train loss: 0.497, Global test loss: 2.536, Global test accuracy: 19.33
Round  39, Train loss: 0.478, Test loss: 0.459, Test accuracy: 83.65
Round  39, Global train loss: 0.478, Global test loss: 2.424, Global test accuracy: 21.05
Round  40, Train loss: 0.459, Test loss: 0.464, Test accuracy: 83.35
Round  40, Global train loss: 0.459, Global test loss: 2.540, Global test accuracy: 20.97
Round  41, Train loss: 0.462, Test loss: 0.457, Test accuracy: 83.62
Round  41, Global train loss: 0.462, Global test loss: 2.675, Global test accuracy: 21.18
Round  42, Train loss: 0.469, Test loss: 0.440, Test accuracy: 84.15
Round  42, Global train loss: 0.469, Global test loss: 2.662, Global test accuracy: 18.12
Round  43, Train loss: 0.487, Test loss: 0.434, Test accuracy: 84.72
Round  43, Global train loss: 0.487, Global test loss: 2.476, Global test accuracy: 20.67
Round  44, Train loss: 0.440, Test loss: 0.440, Test accuracy: 84.75
Round  44, Global train loss: 0.440, Global test loss: 2.691, Global test accuracy: 18.20
Round  45, Train loss: 0.476, Test loss: 0.445, Test accuracy: 84.37
Round  45, Global train loss: 0.476, Global test loss: 3.073, Global test accuracy: 19.52
Round  46, Train loss: 0.437, Test loss: 0.428, Test accuracy: 84.93
Round  46, Global train loss: 0.437, Global test loss: 2.745, Global test accuracy: 19.22
Round  47, Train loss: 0.375, Test loss: 0.428, Test accuracy: 85.02
Round  47, Global train loss: 0.375, Global test loss: 2.402, Global test accuracy: 22.62
Round  48, Train loss: 0.422, Test loss: 0.433, Test accuracy: 84.93
Round  48, Global train loss: 0.422, Global test loss: 2.619, Global test accuracy: 17.05
Round  49, Train loss: 0.395, Test loss: 0.455, Test accuracy: 84.55
Round  49, Global train loss: 0.395, Global test loss: 2.683, Global test accuracy: 23.00
Round  50, Train loss: 0.437, Test loss: 0.455, Test accuracy: 84.75
Round  50, Global train loss: 0.437, Global test loss: 3.187, Global test accuracy: 21.93
Round  51, Train loss: 0.427, Test loss: 0.447, Test accuracy: 84.63
Round  51, Global train loss: 0.427, Global test loss: 2.595, Global test accuracy: 22.00
Round  52, Train loss: 0.367, Test loss: 0.439, Test accuracy: 85.08
Round  52, Global train loss: 0.367, Global test loss: 3.123, Global test accuracy: 21.58
Round  53, Train loss: 0.369, Test loss: 0.436, Test accuracy: 85.45
Round  53, Global train loss: 0.369, Global test loss: 2.948, Global test accuracy: 21.63
Round  54, Train loss: 0.357, Test loss: 0.435, Test accuracy: 85.83
Round  54, Global train loss: 0.357, Global test loss: 2.680, Global test accuracy: 23.20
Round  55, Train loss: 0.386, Test loss: 0.432, Test accuracy: 85.65
Round  55, Global train loss: 0.386, Global test loss: 2.585, Global test accuracy: 22.25
Round  56, Train loss: 0.313, Test loss: 0.425, Test accuracy: 85.68
Round  56, Global train loss: 0.313, Global test loss: 2.888, Global test accuracy: 19.48
Round  57, Train loss: 0.441, Test loss: 0.451, Test accuracy: 84.83
Round  57, Global train loss: 0.441, Global test loss: 2.851, Global test accuracy: 18.63
Round  58, Train loss: 0.351, Test loss: 0.447, Test accuracy: 85.08
Round  58, Global train loss: 0.351, Global test loss: 3.144, Global test accuracy: 20.60
Round  59, Train loss: 0.359, Test loss: 0.454, Test accuracy: 85.13
Round  59, Global train loss: 0.359, Global test loss: 2.875, Global test accuracy: 24.35
Round  60, Train loss: 0.366, Test loss: 0.454, Test accuracy: 85.88
Round  60, Global train loss: 0.366, Global test loss: 3.001, Global test accuracy: 19.27
Round  61, Train loss: 0.360, Test loss: 0.469, Test accuracy: 85.30
Round  61, Global train loss: 0.360, Global test loss: 2.704, Global test accuracy: 23.85
Round  62, Train loss: 0.362, Test loss: 0.446, Test accuracy: 85.97
Round  62, Global train loss: 0.362, Global test loss: 2.772, Global test accuracy: 24.33
Round  63, Train loss: 0.331, Test loss: 0.429, Test accuracy: 85.95
Round  63, Global train loss: 0.331, Global test loss: 3.273, Global test accuracy: 20.62
Round  64, Train loss: 0.367, Test loss: 0.408, Test accuracy: 86.30
Round  64, Global train loss: 0.367, Global test loss: 2.613, Global test accuracy: 21.48
Round  65, Train loss: 0.347, Test loss: 0.407, Test accuracy: 86.72
Round  65, Global train loss: 0.347, Global test loss: 2.624, Global test accuracy: 23.07
Round  66, Train loss: 0.312, Test loss: 0.410, Test accuracy: 87.18
Round  66, Global train loss: 0.312, Global test loss: 2.694, Global test accuracy: 23.43
Round  67, Train loss: 0.271, Test loss: 0.418, Test accuracy: 86.62
Round  67, Global train loss: 0.271, Global test loss: 2.596, Global test accuracy: 23.63
Round  68, Train loss: 0.282, Test loss: 0.429, Test accuracy: 86.12
Round  68, Global train loss: 0.282, Global test loss: 3.186, Global test accuracy: 21.35
Round  69, Train loss: 0.336, Test loss: 0.430, Test accuracy: 85.98
Round  69, Global train loss: 0.336, Global test loss: 3.122, Global test accuracy: 20.52
Round  70, Train loss: 0.297, Test loss: 0.421, Test accuracy: 86.18
Round  70, Global train loss: 0.297, Global test loss: 2.679, Global test accuracy: 23.58
Round  71, Train loss: 0.276, Test loss: 0.411, Test accuracy: 86.47
Round  71, Global train loss: 0.276, Global test loss: 3.007, Global test accuracy: 22.13
Round  72, Train loss: 0.300, Test loss: 0.446, Test accuracy: 85.50
Round  72, Global train loss: 0.300, Global test loss: 2.635, Global test accuracy: 21.52
Round  73, Train loss: 0.362, Test loss: 0.451, Test accuracy: 85.68
Round  73, Global train loss: 0.362, Global test loss: 2.516, Global test accuracy: 24.48
Round  74, Train loss: 0.298, Test loss: 0.447, Test accuracy: 85.93
Round  74, Global train loss: 0.298, Global test loss: 2.892, Global test accuracy: 23.32
Round  75, Train loss: 0.316, Test loss: 0.460, Test accuracy: 85.95
Round  75, Global train loss: 0.316, Global test loss: 2.788, Global test accuracy: 23.18
Round  76, Train loss: 0.358, Test loss: 0.493, Test accuracy: 84.82
Round  76, Global train loss: 0.358, Global test loss: 2.726, Global test accuracy: 19.10
Round  77, Train loss: 0.311, Test loss: 0.443, Test accuracy: 86.02
Round  77, Global train loss: 0.311, Global test loss: 2.746, Global test accuracy: 19.92
Round  78, Train loss: 0.277, Test loss: 0.448, Test accuracy: 86.05
Round  78, Global train loss: 0.277, Global test loss: 2.666, Global test accuracy: 19.17
Round  79, Train loss: 0.306, Test loss: 0.449, Test accuracy: 86.12
Round  79, Global train loss: 0.306, Global test loss: 2.740, Global test accuracy: 21.88
Round  80, Train loss: 0.256, Test loss: 0.443, Test accuracy: 86.62
Round  80, Global train loss: 0.256, Global test loss: 2.985, Global test accuracy: 21.42
Round  81, Train loss: 0.287, Test loss: 0.446, Test accuracy: 86.80
Round  81, Global train loss: 0.287, Global test loss: 3.090, Global test accuracy: 20.22
Round  82, Train loss: 0.295, Test loss: 0.445, Test accuracy: 86.78
Round  82, Global train loss: 0.295, Global test loss: 2.864, Global test accuracy: 21.33
Round  83, Train loss: 0.293, Test loss: 0.443, Test accuracy: 86.82
Round  83, Global train loss: 0.293, Global test loss: 2.923, Global test accuracy: 22.15
Round  84, Train loss: 0.246, Test loss: 0.431, Test accuracy: 86.68
Round  84, Global train loss: 0.246, Global test loss: 2.931, Global test accuracy: 24.02
Round  85, Train loss: 0.285, Test loss: 0.435, Test accuracy: 86.78
Round  85, Global train loss: 0.285, Global test loss: 2.856, Global test accuracy: 22.53
Round  86, Train loss: 0.237, Test loss: 0.440, Test accuracy: 86.50
Round  86, Global train loss: 0.237, Global test loss: 2.799, Global test accuracy: 20.73
Round  87, Train loss: 0.234, Test loss: 0.438, Test accuracy: 86.38
Round  87, Global train loss: 0.234, Global test loss: 3.332, Global test accuracy: 21.63
Round  88, Train loss: 0.315, Test loss: 0.435, Test accuracy: 86.47
Round  88, Global train loss: 0.315, Global test loss: 2.691, Global test accuracy: 22.42
Round  89, Train loss: 0.282, Test loss: 0.449, Test accuracy: 86.17
Round  89, Global train loss: 0.282, Global test loss: 2.767, Global test accuracy: 22.40
Round  90, Train loss: 0.286, Test loss: 0.448, Test accuracy: 86.02
Round  90, Global train loss: 0.286, Global test loss: 2.924, Global test accuracy: 20.68
Round  91, Train loss: 0.261, Test loss: 0.435, Test accuracy: 86.67
Round  91, Global train loss: 0.261, Global test loss: 2.799, Global test accuracy: 22.35
Round  92, Train loss: 0.278, Test loss: 0.440, Test accuracy: 85.88
Round  92, Global train loss: 0.278, Global test loss: 2.887, Global test accuracy: 23.27
Round  93, Train loss: 0.258, Test loss: 0.445, Test accuracy: 86.00
Round  93, Global train loss: 0.258, Global test loss: 2.848, Global test accuracy: 22.40
Round  94, Train loss: 0.267, Test loss: 0.469, Test accuracy: 85.72
Round  94, Global train loss: 0.267, Global test loss: 3.045, Global test accuracy: 20.72
Round  95, Train loss: 0.238, Test loss: 0.467, Test accuracy: 86.38
Round  95, Global train loss: 0.238, Global test loss: 3.295, Global test accuracy: 19.93/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  96, Train loss: 0.254, Test loss: 0.453, Test accuracy: 86.35
Round  96, Global train loss: 0.254, Global test loss: 2.872, Global test accuracy: 22.72
Round  97, Train loss: 0.259, Test loss: 0.443, Test accuracy: 86.70
Round  97, Global train loss: 0.259, Global test loss: 2.843, Global test accuracy: 19.83
Round  98, Train loss: 0.266, Test loss: 0.449, Test accuracy: 86.62
Round  98, Global train loss: 0.266, Global test loss: 2.802, Global test accuracy: 21.72
Round  99, Train loss: 0.276, Test loss: 0.436, Test accuracy: 86.97
Round  99, Global train loss: 0.276, Global test loss: 3.169, Global test accuracy: 21.08
Final Round, Train loss: 0.181, Test loss: 0.454, Test accuracy: 87.25
Final Round, Global train loss: 0.181, Global test loss: 3.169, Global test accuracy: 21.08
Average accuracy final 10 rounds: 86.33 

Average global accuracy final 10 rounds: 21.470000000000002 

1028.8293147087097
[1.1300597190856934, 2.2601194381713867, 3.064207077026367, 3.8682947158813477, 4.636301040649414, 5.4043073654174805, 6.172024488449097, 6.939741611480713, 7.688923597335815, 8.438105583190918, 9.191040754318237, 9.943975925445557, 10.697204351425171, 11.450432777404785, 12.195646047592163, 12.940859317779541, 13.688119888305664, 14.435380458831787, 15.188214540481567, 15.941048622131348, 16.69086480140686, 17.440680980682373, 18.1923987865448, 18.944116592407227, 19.6912522315979, 20.438387870788574, 21.186273097991943, 21.934158325195312, 22.68272566795349, 23.43129301071167, 24.182983875274658, 24.934674739837646, 25.67656660079956, 26.418458461761475, 27.175373792648315, 27.932289123535156, 28.69573473930359, 29.45918035507202, 30.21324133872986, 30.967302322387695, 31.726776599884033, 32.48625087738037, 33.254613399505615, 34.02297592163086, 34.788455963134766, 35.55393600463867, 36.31863236427307, 37.08332872390747, 37.84724521636963, 38.61116170883179, 39.38115215301514, 40.151142597198486, 40.90995502471924, 41.66876745223999, 42.43293046951294, 43.19709348678589, 43.95291447639465, 44.70873546600342, 45.46373248100281, 46.2187294960022, 46.980144739151, 47.741559982299805, 48.49941897392273, 49.257277965545654, 50.0076322555542, 50.757986545562744, 51.52335500717163, 52.28872346878052, 53.05136823654175, 53.81401300430298, 54.575894355773926, 55.33777570724487, 56.09976935386658, 56.86176300048828, 57.623165130615234, 58.38456726074219, 59.14344334602356, 59.90231943130493, 60.66751527786255, 61.432711124420166, 62.20012807846069, 62.96754503250122, 63.724284410476685, 64.48102378845215, 65.24741435050964, 66.01380491256714, 66.77355670928955, 67.53330850601196, 68.29006552696228, 69.0468225479126, 69.81233334541321, 70.57784414291382, 71.34163117408752, 72.10541820526123, 72.86478471755981, 73.6241512298584, 74.3839042186737, 75.14365720748901, 75.89763402938843, 76.65161085128784, 77.40959072113037, 78.1675705909729, 78.92591452598572, 79.68425846099854, 80.44108867645264, 81.19791889190674, 81.95854330062866, 82.71916770935059, 83.4754786491394, 84.23178958892822, 84.99378991127014, 85.75579023361206, 86.51407647132874, 87.27236270904541, 88.0282518863678, 88.78414106369019, 89.54127764701843, 90.29841423034668, 91.06353378295898, 91.82865333557129, 92.58681988716125, 93.34498643875122, 94.10382437705994, 94.86266231536865, 95.62420916557312, 96.38575601577759, 97.14098000526428, 97.89620399475098, 98.65406918525696, 99.41193437576294, 100.17155432701111, 100.93117427825928, 101.68996047973633, 102.44874668121338, 103.20974779129028, 103.97074890136719, 104.72427558898926, 105.47780227661133, 106.23705506324768, 106.99630784988403, 107.75060510635376, 108.50490236282349, 109.26007056236267, 110.01523876190186, 110.76785278320312, 111.5204668045044, 112.27678370475769, 113.03310060501099, 113.79327940940857, 114.55345821380615, 115.30350637435913, 116.05355453491211, 116.80905175209045, 117.5645489692688, 118.32036447525024, 119.07617998123169, 119.83031749725342, 120.58445501327515, 121.34069967269897, 122.0969443321228, 122.8578429222107, 123.61874151229858, 124.37900114059448, 125.13926076889038, 125.89093852043152, 126.64261627197266, 127.41023564338684, 128.17785501480103, 128.9447259902954, 129.7115969657898, 130.47324132919312, 131.23488569259644, 132.00008583068848, 132.76528596878052, 133.51982069015503, 134.27435541152954, 135.03838729858398, 135.80241918563843, 136.56258964538574, 137.32276010513306, 138.1026463508606, 138.88253259658813, 139.63959312438965, 140.39665365219116, 141.14515089988708, 141.893648147583, 142.65313935279846, 143.41263055801392, 144.16335082054138, 144.91407108306885, 145.6704261302948, 146.42678117752075, 147.1949598789215, 147.96313858032227, 148.71512246131897, 149.46710634231567, 150.22089266777039, 150.9746789932251, 151.7347593307495, 152.49483966827393, 154.00906920433044, 155.52329874038696]
[21.616666666666667, 21.616666666666667, 34.93333333333333, 34.93333333333333, 44.45, 44.45, 54.95, 54.95, 62.483333333333334, 62.483333333333334, 67.03333333333333, 67.03333333333333, 71.28333333333333, 71.28333333333333, 72.86666666666666, 72.86666666666666, 73.86666666666666, 73.86666666666666, 74.11666666666666, 74.11666666666666, 74.01666666666667, 74.01666666666667, 74.93333333333334, 74.93333333333334, 76.58333333333333, 76.58333333333333, 76.86666666666666, 76.86666666666666, 77.1, 77.1, 76.78333333333333, 76.78333333333333, 77.36666666666666, 77.36666666666666, 77.68333333333334, 77.68333333333334, 77.45, 77.45, 77.68333333333334, 77.68333333333334, 78.31666666666666, 78.31666666666666, 79.26666666666667, 79.26666666666667, 80.05, 80.05, 80.46666666666667, 80.46666666666667, 81.08333333333333, 81.08333333333333, 81.0, 81.0, 80.75, 80.75, 81.7, 81.7, 81.63333333333334, 81.63333333333334, 81.75, 81.75, 81.81666666666666, 81.81666666666666, 82.75, 82.75, 82.95, 82.95, 82.23333333333333, 82.23333333333333, 82.83333333333333, 82.83333333333333, 83.5, 83.5, 84.15, 84.15, 84.06666666666666, 84.06666666666666, 83.65, 83.65, 83.65, 83.65, 83.35, 83.35, 83.61666666666666, 83.61666666666666, 84.15, 84.15, 84.71666666666667, 84.71666666666667, 84.75, 84.75, 84.36666666666666, 84.36666666666666, 84.93333333333334, 84.93333333333334, 85.01666666666667, 85.01666666666667, 84.93333333333334, 84.93333333333334, 84.55, 84.55, 84.75, 84.75, 84.63333333333334, 84.63333333333334, 85.08333333333333, 85.08333333333333, 85.45, 85.45, 85.83333333333333, 85.83333333333333, 85.65, 85.65, 85.68333333333334, 85.68333333333334, 84.83333333333333, 84.83333333333333, 85.08333333333333, 85.08333333333333, 85.13333333333334, 85.13333333333334, 85.88333333333334, 85.88333333333334, 85.3, 85.3, 85.96666666666667, 85.96666666666667, 85.95, 85.95, 86.3, 86.3, 86.71666666666667, 86.71666666666667, 87.18333333333334, 87.18333333333334, 86.61666666666666, 86.61666666666666, 86.11666666666666, 86.11666666666666, 85.98333333333333, 85.98333333333333, 86.18333333333334, 86.18333333333334, 86.46666666666667, 86.46666666666667, 85.5, 85.5, 85.68333333333334, 85.68333333333334, 85.93333333333334, 85.93333333333334, 85.95, 85.95, 84.81666666666666, 84.81666666666666, 86.01666666666667, 86.01666666666667, 86.05, 86.05, 86.11666666666666, 86.11666666666666, 86.61666666666666, 86.61666666666666, 86.8, 86.8, 86.78333333333333, 86.78333333333333, 86.81666666666666, 86.81666666666666, 86.68333333333334, 86.68333333333334, 86.78333333333333, 86.78333333333333, 86.5, 86.5, 86.38333333333334, 86.38333333333334, 86.46666666666667, 86.46666666666667, 86.16666666666667, 86.16666666666667, 86.01666666666667, 86.01666666666667, 86.66666666666667, 86.66666666666667, 85.88333333333334, 85.88333333333334, 86.0, 86.0, 85.71666666666667, 85.71666666666667, 86.38333333333334, 86.38333333333334, 86.35, 86.35, 86.7, 86.7, 86.61666666666666, 86.61666666666666, 86.96666666666667, 86.96666666666667, 87.25, 87.25]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
Round   0, Train loss: 1.295, Test loss: 2.325, Test accuracy: 11.67
Round   1, Train loss: 1.103, Test loss: 2.418, Test accuracy: 15.13
Round   2, Train loss: 0.964, Test loss: 2.403, Test accuracy: 18.35
Round   3, Train loss: 0.950, Test loss: 2.450, Test accuracy: 18.10
Round   4, Train loss: 0.893, Test loss: 2.515, Test accuracy: 19.43
Round   5, Train loss: 0.834, Test loss: 2.268, Test accuracy: 16.48
Round   6, Train loss: 0.907, Test loss: 2.316, Test accuracy: 14.95
Round   7, Train loss: 0.803, Test loss: 2.398, Test accuracy: 17.47
Round   8, Train loss: 0.831, Test loss: 2.296, Test accuracy: 18.58
Round   9, Train loss: 0.709, Test loss: 2.729, Test accuracy: 18.48
Round  10, Train loss: 0.834, Test loss: 2.350, Test accuracy: 17.30
Round  11, Train loss: 0.796, Test loss: 2.297, Test accuracy: 19.12
Round  12, Train loss: 0.715, Test loss: 2.374, Test accuracy: 16.92
Round  13, Train loss: 0.709, Test loss: 2.470, Test accuracy: 16.98
Round  14, Train loss: 0.725, Test loss: 2.400, Test accuracy: 16.67
Round  15, Train loss: 0.603, Test loss: 2.450, Test accuracy: 18.45
Round  16, Train loss: 0.620, Test loss: 2.334, Test accuracy: 21.93
Round  17, Train loss: 0.620, Test loss: 2.344, Test accuracy: 15.22
Round  18, Train loss: 0.590, Test loss: 2.404, Test accuracy: 19.07
Round  19, Train loss: 0.611, Test loss: 2.510, Test accuracy: 20.42
Round  20, Train loss: 0.605, Test loss: 2.659, Test accuracy: 19.42
Round  21, Train loss: 0.613, Test loss: 2.342, Test accuracy: 18.57
Round  22, Train loss: 0.575, Test loss: 2.542, Test accuracy: 20.62
Round  23, Train loss: 0.614, Test loss: 2.482, Test accuracy: 20.40
Round  24, Train loss: 0.531, Test loss: 2.400, Test accuracy: 19.43
Round  25, Train loss: 0.514, Test loss: 2.386, Test accuracy: 20.50
Round  26, Train loss: 0.518, Test loss: 2.433, Test accuracy: 21.17
Round  27, Train loss: 0.458, Test loss: 2.442, Test accuracy: 18.93
Round  28, Train loss: 0.545, Test loss: 2.345, Test accuracy: 23.22
Round  29, Train loss: 0.469, Test loss: 2.426, Test accuracy: 20.62
Round  30, Train loss: 0.477, Test loss: 2.430, Test accuracy: 19.62
Round  31, Train loss: 0.473, Test loss: 2.544, Test accuracy: 18.88
Round  32, Train loss: 0.469, Test loss: 2.419, Test accuracy: 21.20
Round  33, Train loss: 0.451, Test loss: 2.372, Test accuracy: 18.98
Round  34, Train loss: 0.402, Test loss: 2.752, Test accuracy: 20.82
Round  35, Train loss: 0.382, Test loss: 2.563, Test accuracy: 19.88
Round  36, Train loss: 0.342, Test loss: 2.730, Test accuracy: 21.75
Round  37, Train loss: 0.414, Test loss: 2.489, Test accuracy: 20.47
Round  38, Train loss: 0.362, Test loss: 2.579, Test accuracy: 20.60
Round  39, Train loss: 0.357, Test loss: 2.642, Test accuracy: 18.35
Round  40, Train loss: 0.332, Test loss: 3.057, Test accuracy: 18.53
Round  41, Train loss: 0.354, Test loss: 2.719, Test accuracy: 18.83
Round  42, Train loss: 0.338, Test loss: 2.643, Test accuracy: 18.30
Round  43, Train loss: 0.312, Test loss: 3.082, Test accuracy: 18.72
Round  44, Train loss: 0.309, Test loss: 2.504, Test accuracy: 18.05
Round  45, Train loss: 0.389, Test loss: 2.708, Test accuracy: 18.82
Round  46, Train loss: 0.364, Test loss: 2.806, Test accuracy: 19.38
Round  47, Train loss: 0.297, Test loss: 2.704, Test accuracy: 22.65
Round  48, Train loss: 0.364, Test loss: 3.009, Test accuracy: 17.97
Round  49, Train loss: 0.249, Test loss: 2.912, Test accuracy: 21.15
Round  50, Train loss: 0.334, Test loss: 2.509, Test accuracy: 22.17
Round  51, Train loss: 0.314, Test loss: 2.520, Test accuracy: 20.67
Round  52, Train loss: 0.330, Test loss: 2.834, Test accuracy: 22.93
Round  53, Train loss: 0.330, Test loss: 2.592, Test accuracy: 22.43
Round  54, Train loss: 0.340, Test loss: 2.672, Test accuracy: 21.63
Round  55, Train loss: 0.275, Test loss: 3.378, Test accuracy: 19.00
Round  56, Train loss: 0.284, Test loss: 2.554, Test accuracy: 21.52
Round  57, Train loss: 0.305, Test loss: 2.675, Test accuracy: 18.22
Round  58, Train loss: 0.243, Test loss: 3.010, Test accuracy: 22.52
Round  59, Train loss: 0.245, Test loss: 2.572, Test accuracy: 18.87
Round  60, Train loss: 0.285, Test loss: 2.697, Test accuracy: 22.85
Round  61, Train loss: 0.292, Test loss: 2.434, Test accuracy: 20.60
Round  62, Train loss: 0.271, Test loss: 2.760, Test accuracy: 21.15
Round  63, Train loss: 0.214, Test loss: 2.995, Test accuracy: 20.18
Round  64, Train loss: 0.286, Test loss: 2.862, Test accuracy: 23.07
Round  65, Train loss: 0.231, Test loss: 2.988, Test accuracy: 17.37
Round  66, Train loss: 0.201, Test loss: 2.620, Test accuracy: 21.78
Round  67, Train loss: 0.222, Test loss: 3.163, Test accuracy: 23.53
Round  68, Train loss: 0.263, Test loss: 2.558, Test accuracy: 19.15
Round  69, Train loss: 0.250, Test loss: 2.677, Test accuracy: 19.55
Round  70, Train loss: 0.216, Test loss: 2.823, Test accuracy: 20.62
Round  71, Train loss: 0.253, Test loss: 2.571, Test accuracy: 21.25
Round  72, Train loss: 0.223, Test loss: 2.972, Test accuracy: 21.15
Round  73, Train loss: 0.233, Test loss: 3.014, Test accuracy: 23.18
Round  74, Train loss: 0.208, Test loss: 2.964, Test accuracy: 18.75
Round  75, Train loss: 0.200, Test loss: 2.683, Test accuracy: 21.00
Round  76, Train loss: 0.188, Test loss: 2.694, Test accuracy: 22.13
Round  77, Train loss: 0.187, Test loss: 3.260, Test accuracy: 23.20
Round  78, Train loss: 0.169, Test loss: 3.181, Test accuracy: 22.48
Round  79, Train loss: 0.220, Test loss: 3.167, Test accuracy: 19.85
Round  80, Train loss: 0.180, Test loss: 2.981, Test accuracy: 23.37
Round  81, Train loss: 0.200, Test loss: 3.107, Test accuracy: 23.75
Round  82, Train loss: 0.158, Test loss: 2.873, Test accuracy: 22.57
Round  83, Train loss: 0.179, Test loss: 2.837, Test accuracy: 18.32
Round  84, Train loss: 0.208, Test loss: 2.771, Test accuracy: 19.45
Round  85, Train loss: 0.181, Test loss: 2.803, Test accuracy: 22.15
Round  86, Train loss: 0.166, Test loss: 3.245, Test accuracy: 19.55
Round  87, Train loss: 0.150, Test loss: 2.906, Test accuracy: 22.30
Round  88, Train loss: 0.162, Test loss: 3.197, Test accuracy: 19.45
Round  89, Train loss: 0.159, Test loss: 3.253, Test accuracy: 23.23
Round  90, Train loss: 0.179, Test loss: 3.013, Test accuracy: 21.18
Round  91, Train loss: 0.160, Test loss: 2.929, Test accuracy: 20.08
Round  92, Train loss: 0.149, Test loss: 3.069, Test accuracy: 22.37
Round  93, Train loss: 0.138, Test loss: 3.113, Test accuracy: 22.52
Round  94, Train loss: 0.153, Test loss: 2.936, Test accuracy: 20.65
Round  95, Train loss: 0.151, Test loss: 2.797, Test accuracy: 21.18
Round  96, Train loss: 0.155, Test loss: 2.993, Test accuracy: 19.87
Round  97, Train loss: 0.126, Test loss: 3.338, Test accuracy: 17.50
Round  98, Train loss: 0.132, Test loss: 3.311, Test accuracy: 20.78
Round  99, Train loss: 0.141, Test loss: 3.341, Test accuracy: 20.13
Final Round, Train loss: 0.130, Test loss: 2.498, Test accuracy: 22.80
Average accuracy final 10 rounds: 20.62666666666666
1318.473304271698
[2.179656982421875, 4.036988735198975, 5.8810741901397705, 7.794515132904053, 9.625974416732788, 11.490462064743042, 13.34670376777649, 15.191665887832642, 17.03866934776306, 18.892749547958374, 20.748060703277588, 22.614152193069458, 24.45966863632202, 26.30130124092102, 28.13416600227356, 29.985451221466064, 31.83307933807373, 33.67228102684021, 35.50659728050232, 37.379486083984375, 39.238107681274414, 41.06045150756836, 42.892831802368164, 44.75463914871216, 46.59285283088684, 48.49036192893982, 50.32880711555481, 52.1997652053833, 54.24094367027283, 56.138012647628784, 58.04084277153015, 59.929853439331055, 61.825424671173096, 63.72557711601257, 65.60091066360474, 67.46394324302673, 69.32948017120361, 71.18752574920654, 73.05647683143616, 74.9482364654541, 76.82809209823608, 78.70092225074768, 80.56678032875061, 82.415536403656, 84.26403379440308, 86.11400294303894, 87.98049235343933, 89.81825137138367, 91.65655565261841, 93.50325512886047, 95.35967826843262, 97.21399545669556, 99.0508680343628, 100.90180659294128, 102.75039172172546, 104.5959939956665, 106.44410419464111, 108.29234981536865, 110.14114451408386, 112.00069308280945, 113.83544278144836, 115.67009925842285, 117.51703143119812, 119.3665463924408, 121.20392036437988, 123.05675792694092, 124.90821623802185, 126.74829983711243, 128.59040927886963, 130.42936086654663, 132.29058599472046, 134.13411021232605, 135.98661494255066, 137.83051872253418, 139.68096113204956, 141.55051946640015, 143.3898947238922, 145.25529551506042, 147.10199999809265, 148.9727783203125, 150.86996459960938, 152.7202718257904, 154.58437538146973, 156.42892932891846, 158.28315138816833, 160.12153482437134, 161.98046207427979, 163.84314465522766, 165.68250584602356, 167.53225898742676, 169.37383580207825, 171.25269603729248, 173.10596179962158, 174.9592092037201, 176.8231716156006, 178.6822452545166, 180.5440046787262, 182.39639329910278, 184.2945261001587, 186.1585886478424, 188.06050825119019]
[11.666666666666666, 15.133333333333333, 18.35, 18.1, 19.433333333333334, 16.483333333333334, 14.95, 17.466666666666665, 18.583333333333332, 18.483333333333334, 17.3, 19.116666666666667, 16.916666666666668, 16.983333333333334, 16.666666666666668, 18.45, 21.933333333333334, 15.216666666666667, 19.066666666666666, 20.416666666666668, 19.416666666666668, 18.566666666666666, 20.616666666666667, 20.4, 19.433333333333334, 20.5, 21.166666666666668, 18.933333333333334, 23.216666666666665, 20.616666666666667, 19.616666666666667, 18.883333333333333, 21.2, 18.983333333333334, 20.816666666666666, 19.883333333333333, 21.75, 20.466666666666665, 20.6, 18.35, 18.533333333333335, 18.833333333333332, 18.3, 18.716666666666665, 18.05, 18.816666666666666, 19.383333333333333, 22.65, 17.966666666666665, 21.15, 22.166666666666668, 20.666666666666668, 22.933333333333334, 22.433333333333334, 21.633333333333333, 19.0, 21.516666666666666, 18.216666666666665, 22.516666666666666, 18.866666666666667, 22.85, 20.6, 21.15, 20.183333333333334, 23.066666666666666, 17.366666666666667, 21.783333333333335, 23.533333333333335, 19.15, 19.55, 20.616666666666667, 21.25, 21.15, 23.183333333333334, 18.75, 21.0, 22.133333333333333, 23.2, 22.483333333333334, 19.85, 23.366666666666667, 23.75, 22.566666666666666, 18.316666666666666, 19.45, 22.15, 19.55, 22.3, 19.45, 23.233333333333334, 21.183333333333334, 20.083333333333332, 22.366666666666667, 22.516666666666666, 20.65, 21.183333333333334, 19.866666666666667, 17.5, 20.783333333333335, 20.133333333333333, 22.8]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar100  

Files already downloaded and verified
Files already downloaded and verified
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 1063434 (local), 1062144 (global); Percentage 99.88 (1062144/1063434)
learning rate, batch size: 0.01, 10
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
Round   0, Train loss: 1.712, Test loss: 2.184, Test accuracy: 20.43
Round   1, Train loss: 1.166, Test loss: 1.985, Test accuracy: 32.28
Round   2, Train loss: 1.146, Test loss: 1.659, Test accuracy: 41.30
Round   3, Train loss: 1.006, Test loss: 1.407, Test accuracy: 48.58
Round   4, Train loss: 0.941, Test loss: 1.388, Test accuracy: 50.97
Round   5, Train loss: 0.988, Test loss: 0.909, Test accuracy: 63.43
Round   6, Train loss: 0.872, Test loss: 0.801, Test accuracy: 67.42
Round   7, Train loss: 0.816, Test loss: 0.787, Test accuracy: 68.52
Round   8, Train loss: 0.778, Test loss: 0.749, Test accuracy: 70.23
Round   9, Train loss: 0.762, Test loss: 0.755, Test accuracy: 70.47
Round  10, Train loss: 0.848, Test loss: 0.690, Test accuracy: 72.93
Round  11, Train loss: 0.748, Test loss: 0.642, Test accuracy: 74.67
Round  12, Train loss: 0.754, Test loss: 0.664, Test accuracy: 72.95
Round  13, Train loss: 0.691, Test loss: 0.655, Test accuracy: 74.97
Round  14, Train loss: 0.687, Test loss: 0.635, Test accuracy: 75.17
Round  15, Train loss: 0.707, Test loss: 0.604, Test accuracy: 76.87
Round  16, Train loss: 0.629, Test loss: 0.613, Test accuracy: 77.42
Round  17, Train loss: 0.613, Test loss: 0.604, Test accuracy: 77.78
Round  18, Train loss: 0.549, Test loss: 0.582, Test accuracy: 78.15
Round  19, Train loss: 0.598, Test loss: 0.553, Test accuracy: 78.63
Round  20, Train loss: 0.559, Test loss: 0.562, Test accuracy: 78.65
Round  21, Train loss: 0.607, Test loss: 0.540, Test accuracy: 79.50
Round  22, Train loss: 0.620, Test loss: 0.530, Test accuracy: 80.53
Round  23, Train loss: 0.630, Test loss: 0.536, Test accuracy: 79.73
Round  24, Train loss: 0.577, Test loss: 0.525, Test accuracy: 81.00
Round  25, Train loss: 0.502, Test loss: 0.522, Test accuracy: 81.20
Round  26, Train loss: 0.495, Test loss: 0.505, Test accuracy: 81.30
Round  27, Train loss: 0.507, Test loss: 0.525, Test accuracy: 80.48
Round  28, Train loss: 0.527, Test loss: 0.481, Test accuracy: 82.32
Round  29, Train loss: 0.468, Test loss: 0.486, Test accuracy: 82.37
Round  30, Train loss: 0.471, Test loss: 0.488, Test accuracy: 81.95
Round  31, Train loss: 0.469, Test loss: 0.466, Test accuracy: 82.88
Round  32, Train loss: 0.448, Test loss: 0.466, Test accuracy: 83.10
Round  33, Train loss: 0.506, Test loss: 0.468, Test accuracy: 83.22
Round  34, Train loss: 0.434, Test loss: 0.441, Test accuracy: 83.95
Round  35, Train loss: 0.465, Test loss: 0.437, Test accuracy: 84.12
Round  36, Train loss: 0.375, Test loss: 0.435, Test accuracy: 83.93
Round  37, Train loss: 0.362, Test loss: 0.445, Test accuracy: 83.98
Round  38, Train loss: 0.437, Test loss: 0.481, Test accuracy: 81.15
Round  39, Train loss: 0.427, Test loss: 0.431, Test accuracy: 84.72
Round  40, Train loss: 0.344, Test loss: 0.419, Test accuracy: 84.43
Round  41, Train loss: 0.358, Test loss: 0.425, Test accuracy: 84.25
Round  42, Train loss: 0.362, Test loss: 0.404, Test accuracy: 85.03
Round  43, Train loss: 0.349, Test loss: 0.397, Test accuracy: 85.38
Round  44, Train loss: 0.349, Test loss: 0.413, Test accuracy: 85.10
Round  45, Train loss: 0.439, Test loss: 0.396, Test accuracy: 85.65
Round  46, Train loss: 0.414, Test loss: 0.398, Test accuracy: 85.57
Round  47, Train loss: 0.390, Test loss: 0.379, Test accuracy: 86.48
Round  48, Train loss: 0.368, Test loss: 0.378, Test accuracy: 86.07
Round  49, Train loss: 0.375, Test loss: 0.378, Test accuracy: 85.95
Round  50, Train loss: 0.369, Test loss: 0.378, Test accuracy: 86.17
Round  51, Train loss: 0.346, Test loss: 0.365, Test accuracy: 86.57
Round  52, Train loss: 0.308, Test loss: 0.366, Test accuracy: 86.62
Round  53, Train loss: 0.334, Test loss: 0.360, Test accuracy: 86.58
Round  54, Train loss: 0.321, Test loss: 0.368, Test accuracy: 86.72
Round  55, Train loss: 0.354, Test loss: 0.355, Test accuracy: 86.77
Round  56, Train loss: 0.283, Test loss: 0.356, Test accuracy: 87.20
Round  57, Train loss: 0.327, Test loss: 0.355, Test accuracy: 87.02
Round  58, Train loss: 0.246, Test loss: 0.362, Test accuracy: 86.73
Round  59, Train loss: 0.370, Test loss: 0.352, Test accuracy: 86.95
Round  60, Train loss: 0.337, Test loss: 0.350, Test accuracy: 86.98
Round  61, Train loss: 0.292, Test loss: 0.343, Test accuracy: 87.35
Round  62, Train loss: 0.362, Test loss: 0.342, Test accuracy: 87.58
Round  63, Train loss: 0.288, Test loss: 0.346, Test accuracy: 87.27
Round  64, Train loss: 0.294, Test loss: 0.345, Test accuracy: 87.95
Round  65, Train loss: 0.257, Test loss: 0.340, Test accuracy: 87.85
Round  66, Train loss: 0.205, Test loss: 0.342, Test accuracy: 87.90
Round  67, Train loss: 0.250, Test loss: 0.337, Test accuracy: 87.90
Round  68, Train loss: 0.228, Test loss: 0.338, Test accuracy: 87.98
Round  69, Train loss: 0.252, Test loss: 0.337, Test accuracy: 88.03
Round  70, Train loss: 0.293, Test loss: 0.353, Test accuracy: 87.73
Round  71, Train loss: 0.225, Test loss: 0.361, Test accuracy: 87.27
Round  72, Train loss: 0.291, Test loss: 0.349, Test accuracy: 87.38
Round  73, Train loss: 0.221, Test loss: 0.343, Test accuracy: 87.38
Round  74, Train loss: 0.325, Test loss: 0.329, Test accuracy: 88.35
Round  75, Train loss: 0.269, Test loss: 0.335, Test accuracy: 88.75
Round  76, Train loss: 0.218, Test loss: 0.336, Test accuracy: 88.43
Round  77, Train loss: 0.244, Test loss: 0.335, Test accuracy: 88.07
Round  78, Train loss: 0.266, Test loss: 0.342, Test accuracy: 87.83
Round  79, Train loss: 0.229, Test loss: 0.333, Test accuracy: 88.37
Round  80, Train loss: 0.225, Test loss: 0.321, Test accuracy: 88.82
Round  81, Train loss: 0.226, Test loss: 0.315, Test accuracy: 88.82
Round  82, Train loss: 0.217, Test loss: 0.322, Test accuracy: 88.37
Round  83, Train loss: 0.215, Test loss: 0.320, Test accuracy: 88.35
Round  84, Train loss: 0.218, Test loss: 0.317, Test accuracy: 88.60
Round  85, Train loss: 0.235, Test loss: 0.334, Test accuracy: 88.18
Round  86, Train loss: 0.159, Test loss: 0.342, Test accuracy: 87.65
Round  87, Train loss: 0.228, Test loss: 0.349, Test accuracy: 87.28
Round  88, Train loss: 0.162, Test loss: 0.329, Test accuracy: 88.47
Round  89, Train loss: 0.197, Test loss: 0.335, Test accuracy: 88.12
Round  90, Train loss: 0.191, Test loss: 0.331, Test accuracy: 88.25
Round  91, Train loss: 0.234, Test loss: 0.328, Test accuracy: 88.43
Round  92, Train loss: 0.204, Test loss: 0.335, Test accuracy: 88.15
Round  93, Train loss: 0.256, Test loss: 0.329, Test accuracy: 88.43
Round  94, Train loss: 0.214, Test loss: 0.326, Test accuracy: 88.50
Round  95, Train loss: 0.177, Test loss: 0.317, Test accuracy: 88.97
Round  96, Train loss: 0.162, Test loss: 0.321, Test accuracy: 88.85
Round  97, Train loss: 0.210, Test loss: 0.357, Test accuracy: 88.02
Round  98, Train loss: 0.262, Test loss: 0.326, Test accuracy: 88.20
Round  99, Train loss: 0.192, Test loss: 0.320, Test accuracy: 88.72
Final Round, Train loss: 0.156, Test loss: 0.324, Test accuracy: 88.67
Average accuracy final 10 rounds: 88.45166666666668
705.0171597003937
[1.1989083290100098, 2.050652027130127, 2.9030568599700928, 3.7548820972442627, 4.606001138687134, 5.4691002368927, 6.321301221847534, 7.156507730484009, 8.007946491241455, 8.861049890518188, 9.703874826431274, 10.553946018218994, 11.403128147125244, 12.255316019058228, 13.089642524719238, 13.931133508682251, 14.787537336349487, 15.632168531417847, 16.483084201812744, 17.334463834762573, 18.186373949050903, 19.036857843399048, 19.877386331558228, 20.728675603866577, 21.58541464805603, 22.428502321243286, 23.281246185302734, 24.133548974990845, 24.972206830978394, 25.81724524497986, 26.668846130371094, 27.519218921661377, 28.36494469642639, 29.219850778579712, 30.07191801071167, 30.92207431793213, 31.750324487686157, 32.60201120376587, 33.45452833175659, 34.295222759246826, 35.139644145965576, 35.982004165649414, 36.821367263793945, 37.65760946273804, 38.49938464164734, 39.342849254608154, 40.189823389053345, 41.03808903694153, 41.88140153884888, 42.73305106163025, 43.57803988456726, 44.4265410900116, 45.274471282958984, 46.121910095214844, 46.96143317222595, 47.811652421951294, 48.6728618144989, 49.51504421234131, 50.36314415931702, 51.19981145858765, 52.05200123786926, 52.901323080062866, 53.74448204040527, 54.6054368019104, 55.457282066345215, 56.31330919265747, 57.157265186309814, 58.0172598361969, 58.86828136444092, 59.72015881538391, 60.56688904762268, 61.40658497810364, 62.24355459213257, 63.093037843704224, 63.9449737071991, 64.7910943031311, 65.64184737205505, 66.50271034240723, 67.35172080993652, 68.20632815361023, 69.0452938079834, 69.88636946678162, 70.7333824634552, 71.58300590515137, 72.43214631080627, 73.2757658958435, 74.11901593208313, 74.9659674167633, 75.79973840713501, 76.64361119270325, 77.4873673915863, 78.33402395248413, 79.18866205215454, 80.03832292556763, 80.8736789226532, 81.7083249092102, 82.54126143455505, 83.36909914016724, 84.20411777496338, 85.06231999397278, 86.42720317840576]
[20.433333333333334, 32.28333333333333, 41.3, 48.583333333333336, 50.96666666666667, 63.43333333333333, 67.41666666666667, 68.51666666666667, 70.23333333333333, 70.46666666666667, 72.93333333333334, 74.66666666666667, 72.95, 74.96666666666667, 75.16666666666667, 76.86666666666666, 77.41666666666667, 77.78333333333333, 78.15, 78.63333333333334, 78.65, 79.5, 80.53333333333333, 79.73333333333333, 81.0, 81.2, 81.3, 80.48333333333333, 82.31666666666666, 82.36666666666666, 81.95, 82.88333333333334, 83.1, 83.21666666666667, 83.95, 84.11666666666666, 83.93333333333334, 83.98333333333333, 81.15, 84.71666666666667, 84.43333333333334, 84.25, 85.03333333333333, 85.38333333333334, 85.1, 85.65, 85.56666666666666, 86.48333333333333, 86.06666666666666, 85.95, 86.16666666666667, 86.56666666666666, 86.61666666666666, 86.58333333333333, 86.71666666666667, 86.76666666666667, 87.2, 87.01666666666667, 86.73333333333333, 86.95, 86.98333333333333, 87.35, 87.58333333333333, 87.26666666666667, 87.95, 87.85, 87.9, 87.9, 87.98333333333333, 88.03333333333333, 87.73333333333333, 87.26666666666667, 87.38333333333334, 87.38333333333334, 88.35, 88.75, 88.43333333333334, 88.06666666666666, 87.83333333333333, 88.36666666666666, 88.81666666666666, 88.81666666666666, 88.36666666666666, 88.35, 88.6, 88.18333333333334, 87.65, 87.28333333333333, 88.46666666666667, 88.11666666666666, 88.25, 88.43333333333334, 88.15, 88.43333333333334, 88.5, 88.96666666666667, 88.85, 88.01666666666667, 88.2, 88.71666666666667, 88.66666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar100  

Files already downloaded and verified
Files already downloaded and verified
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
4800
4864
209664
209792
1028992
1029248
1062016
1062144
1063424
1063434
# Params: 1063434 (local), 1062144 (global); Percentage 99.88 (1062144/1063434)
learning rate, batch size: 0.01, 10
CNNCifar100(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (drop): Dropout(p=0.6, inplace=False)
  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=3200, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=128, bias=True)
  (fc3): Linear(in_features=128, out_features=10, bias=True)
)
Round   0, Train loss: 1.694, Test loss: 2.199, Test accuracy: 14.93
Round   1, Train loss: 1.210, Test loss: 1.897, Test accuracy: 28.40
Round   2, Train loss: 1.062, Test loss: 1.691, Test accuracy: 35.95
Round   3, Train loss: 1.040, Test loss: 1.488, Test accuracy: 46.28
Round   4, Train loss: 0.964, Test loss: 1.122, Test accuracy: 58.05
Round   5, Train loss: 0.880, Test loss: 0.990, Test accuracy: 61.45
Round   6, Train loss: 0.829, Test loss: 1.030, Test accuracy: 63.57
Round   7, Train loss: 0.787, Test loss: 0.963, Test accuracy: 64.33
Round   8, Train loss: 0.824, Test loss: 0.966, Test accuracy: 64.62
Round   9, Train loss: 0.850, Test loss: 0.850, Test accuracy: 68.48
Round  10, Train loss: 0.723, Test loss: 0.806, Test accuracy: 70.18
Round  11, Train loss: 0.726, Test loss: 0.797, Test accuracy: 71.08
Round  12, Train loss: 0.698, Test loss: 0.784, Test accuracy: 71.37
Round  13, Train loss: 0.686, Test loss: 0.801, Test accuracy: 71.93
Round  14, Train loss: 0.700, Test loss: 0.780, Test accuracy: 71.62
Round  15, Train loss: 0.661, Test loss: 0.757, Test accuracy: 72.63
Round  16, Train loss: 0.600, Test loss: 0.745, Test accuracy: 73.00
Round  17, Train loss: 0.708, Test loss: 0.747, Test accuracy: 74.07
Round  18, Train loss: 0.647, Test loss: 0.752, Test accuracy: 74.13
Round  19, Train loss: 0.694, Test loss: 0.551, Test accuracy: 79.22
Round  20, Train loss: 0.604, Test loss: 0.582, Test accuracy: 78.23
Round  21, Train loss: 0.625, Test loss: 0.562, Test accuracy: 79.12
Round  22, Train loss: 0.552, Test loss: 0.541, Test accuracy: 80.18
Round  23, Train loss: 0.623, Test loss: 0.498, Test accuracy: 81.18
Round  24, Train loss: 0.495, Test loss: 0.513, Test accuracy: 81.07
Round  25, Train loss: 0.527, Test loss: 0.515, Test accuracy: 81.12
Round  26, Train loss: 0.537, Test loss: 0.501, Test accuracy: 81.70
Round  27, Train loss: 0.479, Test loss: 0.487, Test accuracy: 81.58
Round  28, Train loss: 0.500, Test loss: 0.474, Test accuracy: 82.92
Round  29, Train loss: 0.463, Test loss: 0.464, Test accuracy: 82.88
Round  30, Train loss: 0.443, Test loss: 0.481, Test accuracy: 81.95
Round  31, Train loss: 0.492, Test loss: 0.467, Test accuracy: 82.45
Round  32, Train loss: 0.473, Test loss: 0.448, Test accuracy: 83.85
Round  33, Train loss: 0.405, Test loss: 0.434, Test accuracy: 84.63
Round  34, Train loss: 0.404, Test loss: 0.422, Test accuracy: 84.60
Round  35, Train loss: 0.456, Test loss: 0.435, Test accuracy: 84.17
Round  36, Train loss: 0.426, Test loss: 0.427, Test accuracy: 84.48
Round  37, Train loss: 0.423, Test loss: 0.417, Test accuracy: 84.80
Round  38, Train loss: 0.411, Test loss: 0.394, Test accuracy: 84.90
Round  39, Train loss: 0.331, Test loss: 0.404, Test accuracy: 85.42
Round  40, Train loss: 0.436, Test loss: 0.407, Test accuracy: 84.57
Round  41, Train loss: 0.373, Test loss: 0.411, Test accuracy: 85.30
Round  42, Train loss: 0.376, Test loss: 0.401, Test accuracy: 85.35
Round  43, Train loss: 0.410, Test loss: 0.406, Test accuracy: 85.20
Round  44, Train loss: 0.367, Test loss: 0.408, Test accuracy: 85.05
Round  45, Train loss: 0.346, Test loss: 0.407, Test accuracy: 84.87
Round  46, Train loss: 0.299, Test loss: 0.397, Test accuracy: 85.23
Round  47, Train loss: 0.406, Test loss: 0.394, Test accuracy: 85.82
Round  48, Train loss: 0.363, Test loss: 0.388, Test accuracy: 85.80
Round  49, Train loss: 0.300, Test loss: 0.395, Test accuracy: 84.80
Round  50, Train loss: 0.328, Test loss: 0.397, Test accuracy: 84.98
Round  51, Train loss: 0.350, Test loss: 0.378, Test accuracy: 85.72
Round  52, Train loss: 0.392, Test loss: 0.374, Test accuracy: 86.43
Round  53, Train loss: 0.331, Test loss: 0.375, Test accuracy: 86.77
Round  54, Train loss: 0.342, Test loss: 0.371, Test accuracy: 86.85
Round  55, Train loss: 0.307, Test loss: 0.381, Test accuracy: 86.63
Round  56, Train loss: 0.313, Test loss: 0.364, Test accuracy: 86.95
Round  57, Train loss: 0.337, Test loss: 0.349, Test accuracy: 86.98
Round  58, Train loss: 0.323, Test loss: 0.372, Test accuracy: 86.70
Round  59, Train loss: 0.307, Test loss: 0.367, Test accuracy: 86.40
Round  60, Train loss: 0.294, Test loss: 0.354, Test accuracy: 86.65
Round  61, Train loss: 0.300, Test loss: 0.365, Test accuracy: 86.88
Round  62, Train loss: 0.262, Test loss: 0.369, Test accuracy: 86.85
Round  63, Train loss: 0.284, Test loss: 0.362, Test accuracy: 87.02
Round  64, Train loss: 0.328, Test loss: 0.351, Test accuracy: 87.63
Round  65, Train loss: 0.310, Test loss: 0.339, Test accuracy: 87.87
Round  66, Train loss: 0.226, Test loss: 0.353, Test accuracy: 87.87
Round  67, Train loss: 0.227, Test loss: 0.376, Test accuracy: 86.90
Round  68, Train loss: 0.240, Test loss: 0.349, Test accuracy: 87.92
Round  69, Train loss: 0.278, Test loss: 0.355, Test accuracy: 87.27
Round  70, Train loss: 0.258, Test loss: 0.367, Test accuracy: 87.35
Round  71, Train loss: 0.295, Test loss: 0.360, Test accuracy: 87.33
Round  72, Train loss: 0.282, Test loss: 0.343, Test accuracy: 88.15
Round  73, Train loss: 0.237, Test loss: 0.353, Test accuracy: 87.85
Round  74, Train loss: 0.253, Test loss: 0.338, Test accuracy: 88.05
Round  75, Train loss: 0.248, Test loss: 0.340, Test accuracy: 88.10
Round  76, Train loss: 0.212, Test loss: 0.336, Test accuracy: 88.43
Round  77, Train loss: 0.234, Test loss: 0.346, Test accuracy: 87.77
Round  78, Train loss: 0.275, Test loss: 0.349, Test accuracy: 88.12
Round  79, Train loss: 0.211, Test loss: 0.355, Test accuracy: 87.53
Round  80, Train loss: 0.219, Test loss: 0.338, Test accuracy: 88.12
Round  81, Train loss: 0.215, Test loss: 0.356, Test accuracy: 87.87
Round  82, Train loss: 0.306, Test loss: 0.338, Test accuracy: 88.23
Round  83, Train loss: 0.167, Test loss: 0.338, Test accuracy: 88.35
Round  84, Train loss: 0.264, Test loss: 0.331, Test accuracy: 88.43
Round  85, Train loss: 0.238, Test loss: 0.336, Test accuracy: 88.55
Round  86, Train loss: 0.254, Test loss: 0.341, Test accuracy: 88.38
Round  87, Train loss: 0.225, Test loss: 0.337, Test accuracy: 88.68
Round  88, Train loss: 0.226, Test loss: 0.327, Test accuracy: 88.73
Round  89, Train loss: 0.228, Test loss: 0.343, Test accuracy: 88.22
Round  90, Train loss: 0.202, Test loss: 0.338, Test accuracy: 88.75
Round  91, Train loss: 0.215, Test loss: 0.338, Test accuracy: 88.60
Round  92, Train loss: 0.181, Test loss: 0.345, Test accuracy: 88.43
Round  93, Train loss: 0.229, Test loss: 0.340, Test accuracy: 88.40
Round  94, Train loss: 0.174, Test loss: 0.333, Test accuracy: 88.50
Round  95, Train loss: 0.202, Test loss: 0.340, Test accuracy: 88.25
Round  96, Train loss: 0.193, Test loss: 0.338, Test accuracy: 88.52
Round  97, Train loss: 0.180, Test loss: 0.347, Test accuracy: 88.58
Round  98, Train loss: 0.211, Test loss: 0.349, Test accuracy: 88.73
Round  99, Train loss: 0.119, Test loss: 0.339, Test accuracy: 88.62
Final Round, Train loss: 0.148, Test loss: 0.343, Test accuracy: 89.13
Average accuracy final 10 rounds: 88.53833333333333
869.9527010917664
[1.3165690898895264, 2.6331381797790527, 3.5306859016418457, 4.428233623504639, 5.261285781860352, 6.0943379402160645, 6.931925296783447, 7.76951265335083, 8.589973211288452, 9.410433769226074, 10.236549854278564, 11.062665939331055, 11.899426460266113, 12.736186981201172, 13.570229053497314, 14.404271125793457, 15.234368801116943, 16.06446647644043, 16.8986337184906, 17.73280096054077, 18.54318141937256, 19.353561878204346, 20.180012464523315, 21.006463050842285, 21.833255529403687, 22.660048007965088, 23.471687078475952, 24.283326148986816, 25.105086088180542, 25.926846027374268, 26.759387493133545, 27.591928958892822, 28.393023252487183, 29.194117546081543, 30.018855333328247, 30.84359312057495, 31.670684814453125, 32.4977765083313, 33.32948064804077, 34.161184787750244, 34.992159366607666, 35.82313394546509, 36.648887395858765, 37.47464084625244, 38.29201817512512, 39.1093955039978, 39.9461944103241, 40.78299331665039, 41.61715078353882, 42.451308250427246, 43.26510715484619, 44.07890605926514, 44.90044951438904, 45.72199296951294, 46.551405906677246, 47.38081884384155, 48.198163986206055, 49.01550912857056, 49.83665871620178, 50.65780830383301, 51.47752547264099, 52.297242641448975, 53.11698627471924, 53.9367299079895, 54.753517150878906, 55.57030439376831, 56.397501707077026, 57.22469902038574, 58.04462552070618, 58.86455202102661, 59.69198274612427, 60.519413471221924, 61.347076416015625, 62.174739360809326, 62.989426374435425, 63.80411338806152, 64.6246771812439, 65.44524097442627, 66.2585883140564, 67.07193565368652, 67.8966338634491, 68.72133207321167, 69.55198812484741, 70.38264417648315, 71.22042155265808, 72.05819892883301, 72.89440608024597, 73.73061323165894, 74.57113552093506, 75.41165781021118, 76.2376754283905, 77.06369304656982, 77.90208721160889, 78.74048137664795, 79.56960105895996, 80.39872074127197, 81.2257993221283, 82.05287790298462, 82.88884735107422, 83.72481679916382, 84.5555944442749, 85.38637208938599, 86.19583868980408, 87.00530529022217, 87.84206485748291, 88.67882442474365, 89.56784057617188, 90.4568567276001, 91.29795861244202, 92.13906049728394, 92.96598935127258, 93.79291820526123, 94.61329221725464, 95.43366622924805, 96.23397469520569, 97.03428316116333, 97.84731245040894, 98.66034173965454, 99.47051739692688, 100.28069305419922, 101.08965969085693, 101.89862632751465, 102.70996952056885, 103.52131271362305, 104.32458472251892, 105.1278567314148, 105.95474982261658, 106.78164291381836, 107.60623121261597, 108.43081951141357, 109.25648522377014, 110.08215093612671, 110.92404913902283, 111.76594734191895, 112.60743021965027, 113.44891309738159, 114.2792420387268, 115.10957098007202, 115.9301061630249, 116.75064134597778, 117.59115171432495, 118.43166208267212, 119.26405048370361, 120.09643888473511, 120.92847466468811, 121.76051044464111, 122.58933591842651, 123.41816139221191, 124.22990369796753, 125.04164600372314, 125.88518905639648, 126.72873210906982, 127.5514965057373, 128.37426090240479, 129.20514225959778, 130.03602361679077, 130.87194848060608, 131.7078733444214, 132.5329568386078, 133.3580403327942, 134.18301486968994, 135.0079894065857, 135.83380246162415, 136.6596155166626, 137.49073958396912, 138.32186365127563, 139.160174369812, 139.9984850883484, 140.82468581199646, 141.65088653564453, 142.4870331287384, 143.32317972183228, 144.16459608078003, 145.00601243972778, 145.8282573223114, 146.65050220489502, 147.47769618034363, 148.30489015579224, 149.124981880188, 149.94507360458374, 150.7583315372467, 151.57158946990967, 152.40350365638733, 153.235417842865, 154.06994485855103, 154.90447187423706, 155.86468195915222, 156.82489204406738, 157.6916799545288, 158.55846786499023, 159.41337156295776, 160.2682752609253, 161.11919808387756, 161.97012090682983, 162.81574940681458, 163.66137790679932, 164.53780007362366, 165.414222240448, 166.28141808509827, 167.14861392974854, 168.4924030303955, 169.83619213104248]
[14.933333333333334, 14.933333333333334, 28.4, 28.4, 35.95, 35.95, 46.28333333333333, 46.28333333333333, 58.05, 58.05, 61.45, 61.45, 63.56666666666667, 63.56666666666667, 64.33333333333333, 64.33333333333333, 64.61666666666666, 64.61666666666666, 68.48333333333333, 68.48333333333333, 70.18333333333334, 70.18333333333334, 71.08333333333333, 71.08333333333333, 71.36666666666666, 71.36666666666666, 71.93333333333334, 71.93333333333334, 71.61666666666666, 71.61666666666666, 72.63333333333334, 72.63333333333334, 73.0, 73.0, 74.06666666666666, 74.06666666666666, 74.13333333333334, 74.13333333333334, 79.21666666666667, 79.21666666666667, 78.23333333333333, 78.23333333333333, 79.11666666666666, 79.11666666666666, 80.18333333333334, 80.18333333333334, 81.18333333333334, 81.18333333333334, 81.06666666666666, 81.06666666666666, 81.11666666666666, 81.11666666666666, 81.7, 81.7, 81.58333333333333, 81.58333333333333, 82.91666666666667, 82.91666666666667, 82.88333333333334, 82.88333333333334, 81.95, 81.95, 82.45, 82.45, 83.85, 83.85, 84.63333333333334, 84.63333333333334, 84.6, 84.6, 84.16666666666667, 84.16666666666667, 84.48333333333333, 84.48333333333333, 84.8, 84.8, 84.9, 84.9, 85.41666666666667, 85.41666666666667, 84.56666666666666, 84.56666666666666, 85.3, 85.3, 85.35, 85.35, 85.2, 85.2, 85.05, 85.05, 84.86666666666666, 84.86666666666666, 85.23333333333333, 85.23333333333333, 85.81666666666666, 85.81666666666666, 85.8, 85.8, 84.8, 84.8, 84.98333333333333, 84.98333333333333, 85.71666666666667, 85.71666666666667, 86.43333333333334, 86.43333333333334, 86.76666666666667, 86.76666666666667, 86.85, 86.85, 86.63333333333334, 86.63333333333334, 86.95, 86.95, 86.98333333333333, 86.98333333333333, 86.7, 86.7, 86.4, 86.4, 86.65, 86.65, 86.88333333333334, 86.88333333333334, 86.85, 86.85, 87.01666666666667, 87.01666666666667, 87.63333333333334, 87.63333333333334, 87.86666666666666, 87.86666666666666, 87.86666666666666, 87.86666666666666, 86.9, 86.9, 87.91666666666667, 87.91666666666667, 87.26666666666667, 87.26666666666667, 87.35, 87.35, 87.33333333333333, 87.33333333333333, 88.15, 88.15, 87.85, 87.85, 88.05, 88.05, 88.1, 88.1, 88.43333333333334, 88.43333333333334, 87.76666666666667, 87.76666666666667, 88.11666666666666, 88.11666666666666, 87.53333333333333, 87.53333333333333, 88.11666666666666, 88.11666666666666, 87.86666666666666, 87.86666666666666, 88.23333333333333, 88.23333333333333, 88.35, 88.35, 88.43333333333334, 88.43333333333334, 88.55, 88.55, 88.38333333333334, 88.38333333333334, 88.68333333333334, 88.68333333333334, 88.73333333333333, 88.73333333333333, 88.21666666666667, 88.21666666666667, 88.75, 88.75, 88.6, 88.6, 88.43333333333334, 88.43333333333334, 88.4, 88.4, 88.5, 88.5, 88.25, 88.25, 88.51666666666667, 88.51666666666667, 88.58333333333333, 88.58333333333333, 88.73333333333333, 88.73333333333333, 88.61666666666666, 88.61666666666666, 89.13333333333334, 89.13333333333334]
