nohup: 忽略输入
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.468, Test loss: 1.485, Test accuracy: 45.76 

Round   0, Global train loss: 1.468, Global test loss: 2.256, Global test accuracy: 16.40 

Round   1, Train loss: 1.136, Test loss: 1.286, Test accuracy: 53.80 

Round   1, Global train loss: 1.136, Global test loss: 2.293, Global test accuracy: 16.08 

Round   2, Train loss: 0.969, Test loss: 1.326, Test accuracy: 53.68 

Round   2, Global train loss: 0.969, Global test loss: 2.384, Global test accuracy: 16.00 

Round   3, Train loss: 0.838, Test loss: 1.337, Test accuracy: 56.48 

Round   3, Global train loss: 0.838, Global test loss: 2.454, Global test accuracy: 16.00 

Round   4, Train loss: 0.725, Test loss: 1.350, Test accuracy: 58.20 

Round   4, Global train loss: 0.725, Global test loss: 2.478, Global test accuracy: 16.00 

Round   5, Train loss: 0.618, Test loss: 1.376, Test accuracy: 59.12 

Round   5, Global train loss: 0.618, Global test loss: 2.509, Global test accuracy: 16.04 

Round   6, Train loss: 0.521, Test loss: 1.369, Test accuracy: 60.32 

Round   6, Global train loss: 0.521, Global test loss: 2.518, Global test accuracy: 16.04 

Round   7, Train loss: 0.452, Test loss: 1.711, Test accuracy: 57.56 

Round   7, Global train loss: 0.452, Global test loss: 2.570, Global test accuracy: 16.12 

Round   8, Train loss: 0.370, Test loss: 1.513, Test accuracy: 61.56 

Round   8, Global train loss: 0.370, Global test loss: 2.535, Global test accuracy: 16.12 

Round   9, Train loss: 0.319, Test loss: 1.572, Test accuracy: 61.72 

Round   9, Global train loss: 0.319, Global test loss: 2.430, Global test accuracy: 16.12 

Round  10, Train loss: 0.268, Test loss: 1.722, Test accuracy: 60.40 

Round  10, Global train loss: 0.268, Global test loss: 2.523, Global test accuracy: 16.12 

Round  11, Train loss: 0.251, Test loss: 1.706, Test accuracy: 61.56 

Round  11, Global train loss: 0.251, Global test loss: 2.645, Global test accuracy: 16.04 

Round  12, Train loss: 0.206, Test loss: 1.607, Test accuracy: 63.76 

Round  12, Global train loss: 0.206, Global test loss: 2.533, Global test accuracy: 16.20 

Round  13, Train loss: 0.169, Test loss: 1.863, Test accuracy: 62.48 

Round  13, Global train loss: 0.169, Global test loss: 2.521, Global test accuracy: 16.12 

Round  14, Train loss: 0.153, Test loss: 1.661, Test accuracy: 63.52 

Round  14, Global train loss: 0.153, Global test loss: 2.538, Global test accuracy: 16.08 

Round  15, Train loss: 0.136, Test loss: 1.836, Test accuracy: 63.20 

Round  15, Global train loss: 0.136, Global test loss: 2.575, Global test accuracy: 16.08 

Round  16, Train loss: 0.114, Test loss: 1.689, Test accuracy: 65.84 

Round  16, Global train loss: 0.114, Global test loss: 2.454, Global test accuracy: 16.56 

Round  17, Train loss: 0.087, Test loss: 1.724, Test accuracy: 65.88 

Round  17, Global train loss: 0.087, Global test loss: 2.496, Global test accuracy: 16.12 

Round  18, Train loss: 0.089, Test loss: 1.720, Test accuracy: 65.16 

Round  18, Global train loss: 0.089, Global test loss: 2.569, Global test accuracy: 16.28 

Round  19, Train loss: 0.063, Test loss: 1.920, Test accuracy: 65.00 

Round  19, Global train loss: 0.063, Global test loss: 2.520, Global test accuracy: 16.16 

Round  20, Train loss: 0.089, Test loss: 1.745, Test accuracy: 65.04 

Round  20, Global train loss: 0.089, Global test loss: 2.481, Global test accuracy: 16.16 

Round  21, Train loss: 0.062, Test loss: 1.783, Test accuracy: 65.68 

Round  21, Global train loss: 0.062, Global test loss: 2.506, Global test accuracy: 16.12 

Round  22, Train loss: 0.057, Test loss: 1.857, Test accuracy: 65.08 

Round  22, Global train loss: 0.057, Global test loss: 2.562, Global test accuracy: 16.04 

Round  23, Train loss: 0.044, Test loss: 1.903, Test accuracy: 66.12 

Round  23, Global train loss: 0.044, Global test loss: 2.461, Global test accuracy: 16.12 

Round  24, Train loss: 0.052, Test loss: 1.908, Test accuracy: 65.40 

Round  24, Global train loss: 0.052, Global test loss: 2.450, Global test accuracy: 16.16 

Round  25, Train loss: 0.046, Test loss: 1.886, Test accuracy: 64.68 

Round  25, Global train loss: 0.046, Global test loss: 2.454, Global test accuracy: 16.76 

Round  26, Train loss: 0.039, Test loss: 1.861, Test accuracy: 66.36 

Round  26, Global train loss: 0.039, Global test loss: 2.507, Global test accuracy: 16.20 

Round  27, Train loss: 0.038, Test loss: 1.821, Test accuracy: 67.12 

Round  27, Global train loss: 0.038, Global test loss: 2.567, Global test accuracy: 16.12 

Round  28, Train loss: 0.030, Test loss: 1.891, Test accuracy: 67.32 

Round  28, Global train loss: 0.030, Global test loss: 2.507, Global test accuracy: 16.20 

Round  29, Train loss: 0.038, Test loss: 1.949, Test accuracy: 64.16 

Round  29, Global train loss: 0.038, Global test loss: 2.454, Global test accuracy: 16.20 

Round  30, Train loss: 0.042, Test loss: 2.095, Test accuracy: 64.00 

Round  30, Global train loss: 0.042, Global test loss: 2.460, Global test accuracy: 16.44 

Round  31, Train loss: 0.050, Test loss: 1.960, Test accuracy: 65.72 

Round  31, Global train loss: 0.050, Global test loss: 2.475, Global test accuracy: 16.12 

Round  32, Train loss: 0.036, Test loss: 1.971, Test accuracy: 65.00 

Round  32, Global train loss: 0.036, Global test loss: 2.478, Global test accuracy: 16.08 

Round  33, Train loss: 0.027, Test loss: 1.909, Test accuracy: 66.24 

Round  33, Global train loss: 0.027, Global test loss: 2.511, Global test accuracy: 16.04 

Round  34, Train loss: 0.025, Test loss: 2.026, Test accuracy: 64.80 

Round  34, Global train loss: 0.025, Global test loss: 2.461, Global test accuracy: 16.04 

Final Round, Train loss: 0.021, Test loss: 2.053, Test accuracy: 65.64 

Final Round, Global train loss: 0.021, Global test loss: 2.461, Global test accuracy: 16.04 

Average accuracy final 10 rounds: 65.54 

Average global accuracy final 10 rounds: 16.22 

1255.309883594513
[8.577480792999268, 15.03404974937439, 20.7474262714386, 26.57913064956665, 32.44725227355957, 38.87474966049194, 44.871464252471924, 50.95530986785889, 57.05161142349243, 63.16056036949158, 69.38764595985413, 75.61315846443176, 81.74271059036255, 87.77952361106873, 93.86428594589233, 99.73670244216919, 105.63838386535645, 111.63213682174683, 117.55699372291565, 123.54405426979065, 129.3004891872406, 135.94433093070984, 142.1546766757965, 148.0612437725067, 154.14602661132812, 160.44436407089233, 166.4529619216919, 172.7028830051422, 178.95854115486145, 185.09109616279602, 191.2293701171875, 197.30820679664612, 203.4512095451355, 209.27179169654846, 215.13010120391846, 228.13716077804565]
[45.76, 53.8, 53.68, 56.48, 58.2, 59.12, 60.32, 57.56, 61.56, 61.72, 60.4, 61.56, 63.76, 62.48, 63.52, 63.2, 65.84, 65.88, 65.16, 65.0, 65.04, 65.68, 65.08, 66.12, 65.4, 64.68, 66.36, 67.12, 67.32, 64.16, 64.0, 65.72, 65.0, 66.24, 64.8, 65.64]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.464, Test loss: 1.431, Test accuracy: 47.60 

Round   0, Global train loss: 1.464, Global test loss: 2.254, Global test accuracy: 16.08 

Round   1, Train loss: 1.325, Test loss: 1.316, Test accuracy: 50.04 

Round   1, Global train loss: 1.325, Global test loss: 1.887, Global test accuracy: 32.32 

Round   2, Train loss: 1.191, Test loss: 1.171, Test accuracy: 55.92 

Round   2, Global train loss: 1.191, Global test loss: 1.695, Global test accuracy: 41.92 

Round   3, Train loss: 1.084, Test loss: 1.208, Test accuracy: 56.40 

Round   3, Global train loss: 1.084, Global test loss: 1.629, Global test accuracy: 44.00 

Round   4, Train loss: 1.003, Test loss: 1.243, Test accuracy: 55.76 

Round   4, Global train loss: 1.003, Global test loss: 1.545, Global test accuracy: 49.52 

Round   5, Train loss: 0.914, Test loss: 1.092, Test accuracy: 59.52 

Round   5, Global train loss: 0.914, Global test loss: 1.481, Global test accuracy: 52.00 

Round   6, Train loss: 0.849, Test loss: 1.258, Test accuracy: 58.44 

Round   6, Global train loss: 0.849, Global test loss: 1.512, Global test accuracy: 52.84 

Round   7, Train loss: 0.783, Test loss: 1.073, Test accuracy: 63.00 

Round   7, Global train loss: 0.783, Global test loss: 1.442, Global test accuracy: 55.16 

Round   8, Train loss: 0.732, Test loss: 1.120, Test accuracy: 63.04 

Round   8, Global train loss: 0.732, Global test loss: 1.437, Global test accuracy: 54.00 

Round   9, Train loss: 0.679, Test loss: 1.092, Test accuracy: 64.08 

Round   9, Global train loss: 0.679, Global test loss: 1.385, Global test accuracy: 55.16 

Round  10, Train loss: 0.629, Test loss: 1.117, Test accuracy: 67.52 

Round  10, Global train loss: 0.629, Global test loss: 1.357, Global test accuracy: 57.80 

Round  11, Train loss: 0.594, Test loss: 1.158, Test accuracy: 66.08 

Round  11, Global train loss: 0.594, Global test loss: 1.241, Global test accuracy: 60.56 

Round  12, Train loss: 0.546, Test loss: 1.071, Test accuracy: 66.32 

Round  12, Global train loss: 0.546, Global test loss: 1.195, Global test accuracy: 62.56 

Round  13, Train loss: 0.508, Test loss: 1.063, Test accuracy: 67.80 

Round  13, Global train loss: 0.508, Global test loss: 1.227, Global test accuracy: 61.68 

Round  14, Train loss: 0.476, Test loss: 1.034, Test accuracy: 68.32 

Round  14, Global train loss: 0.476, Global test loss: 1.190, Global test accuracy: 61.80 

Round  15, Train loss: 0.423, Test loss: 1.089, Test accuracy: 69.88 

Round  15, Global train loss: 0.423, Global test loss: 1.194, Global test accuracy: 64.00 

Round  16, Train loss: 0.418, Test loss: 1.033, Test accuracy: 69.40 

Round  16, Global train loss: 0.418, Global test loss: 1.153, Global test accuracy: 64.16 

Round  17, Train loss: 0.373, Test loss: 1.248, Test accuracy: 66.80 

Round  17, Global train loss: 0.373, Global test loss: 1.170, Global test accuracy: 64.56 

Round  18, Train loss: 0.354, Test loss: 1.166, Test accuracy: 68.76 

Round  18, Global train loss: 0.354, Global test loss: 1.204, Global test accuracy: 64.44 

Round  19, Train loss: 0.339, Test loss: 1.181, Test accuracy: 70.92 

Round  19, Global train loss: 0.339, Global test loss: 1.132, Global test accuracy: 66.16 

Round  20, Train loss: 0.318, Test loss: 0.957, Test accuracy: 73.48 

Round  20, Global train loss: 0.318, Global test loss: 1.170, Global test accuracy: 65.28 

Round  21, Train loss: 0.285, Test loss: 1.109, Test accuracy: 71.20 

Round  21, Global train loss: 0.285, Global test loss: 1.141, Global test accuracy: 65.52 

Round  22, Train loss: 0.270, Test loss: 1.386, Test accuracy: 65.24 

Round  22, Global train loss: 0.270, Global test loss: 1.135, Global test accuracy: 66.64 

Round  23, Train loss: 0.255, Test loss: 1.068, Test accuracy: 72.52 

Round  23, Global train loss: 0.255, Global test loss: 1.120, Global test accuracy: 66.84 

Round  24, Train loss: 0.237, Test loss: 1.056, Test accuracy: 73.44 

Round  24, Global train loss: 0.237, Global test loss: 1.108, Global test accuracy: 67.16 

Round  25, Train loss: 0.221, Test loss: 1.059, Test accuracy: 71.40 

Round  25, Global train loss: 0.221, Global test loss: 1.088, Global test accuracy: 67.84 

Round  26, Train loss: 0.212, Test loss: 1.284, Test accuracy: 70.04 

Round  26, Global train loss: 0.212, Global test loss: 1.117, Global test accuracy: 68.00 

Round  27, Train loss: 0.193, Test loss: 1.054, Test accuracy: 74.24 

Round  27, Global train loss: 0.193, Global test loss: 1.128, Global test accuracy: 67.64 

Round  28, Train loss: 0.167, Test loss: 1.408, Test accuracy: 69.60 

Round  28, Global train loss: 0.167, Global test loss: 1.231, Global test accuracy: 66.56 

Round  29, Train loss: 0.175, Test loss: 1.275, Test accuracy: 71.24 

Round  29, Global train loss: 0.175, Global test loss: 1.058, Global test accuracy: 69.00 

Round  30, Train loss: 0.150, Test loss: 1.161, Test accuracy: 73.44 

Round  30, Global train loss: 0.150, Global test loss: 1.044, Global test accuracy: 69.96 

Round  31, Train loss: 0.165, Test loss: 1.103, Test accuracy: 74.48 

Round  31, Global train loss: 0.165, Global test loss: 1.135, Global test accuracy: 68.00 

Round  32, Train loss: 0.128, Test loss: 1.095, Test accuracy: 73.92 

Round  32, Global train loss: 0.128, Global test loss: 1.114, Global test accuracy: 69.12 

Round  33, Train loss: 0.108, Test loss: 1.142, Test accuracy: 73.76 

Round  33, Global train loss: 0.108, Global test loss: 1.134, Global test accuracy: 68.80 

Round  34, Train loss: 0.123, Test loss: 1.244, Test accuracy: 71.16 

Round  34, Global train loss: 0.123, Global test loss: 1.168, Global test accuracy: 69.16 

Round  35, Train loss: 0.116, Test loss: 1.085, Test accuracy: 75.28 

Round  35, Global train loss: 0.116, Global test loss: 1.113, Global test accuracy: 70.16 

Round  36, Train loss: 0.124, Test loss: 1.064, Test accuracy: 74.60 

Round  36, Global train loss: 0.124, Global test loss: 1.089, Global test accuracy: 69.72 

Round  37, Train loss: 0.081, Test loss: 1.204, Test accuracy: 73.96 

Round  37, Global train loss: 0.081, Global test loss: 1.180, Global test accuracy: 69.40 

Round  38, Train loss: 0.105, Test loss: 1.141, Test accuracy: 75.68 

Round  38, Global train loss: 0.105, Global test loss: 1.110, Global test accuracy: 69.36 

Round  39, Train loss: 0.104, Test loss: 1.320, Test accuracy: 72.20 

Round  39, Global train loss: 0.104, Global test loss: 1.147, Global test accuracy: 69.80 

Round  40, Train loss: 0.086, Test loss: 1.313, Test accuracy: 73.96 

Round  40, Global train loss: 0.086, Global test loss: 1.143, Global test accuracy: 70.16 

Round  41, Train loss: 0.068, Test loss: 1.116, Test accuracy: 75.92 

Round  41, Global train loss: 0.068, Global test loss: 1.169, Global test accuracy: 69.92 

Round  42, Train loss: 0.072, Test loss: 1.075, Test accuracy: 76.60 

Round  42, Global train loss: 0.072, Global test loss: 1.121, Global test accuracy: 70.28 

Round  43, Train loss: 0.086, Test loss: 0.976, Test accuracy: 77.52 

Round  43, Global train loss: 0.086, Global test loss: 1.124, Global test accuracy: 69.68 

Round  44, Train loss: 0.085, Test loss: 1.356, Test accuracy: 72.68 

Round  44, Global train loss: 0.085, Global test loss: 1.196, Global test accuracy: 68.96 

Round  45, Train loss: 0.072, Test loss: 1.123, Test accuracy: 75.44 

Round  45, Global train loss: 0.072, Global test loss: 1.161, Global test accuracy: 68.88 

Round  46, Train loss: 0.050, Test loss: 1.053, Test accuracy: 76.64 

Round  46, Global train loss: 0.050, Global test loss: 1.118, Global test accuracy: 70.52 

Round  47, Train loss: 0.064, Test loss: 1.039, Test accuracy: 77.56 

Round  47, Global train loss: 0.064, Global test loss: 1.097, Global test accuracy: 71.28 

Round  48, Train loss: 0.052, Test loss: 1.128, Test accuracy: 75.92 

Round  48, Global train loss: 0.052, Global test loss: 1.095, Global test accuracy: 70.92 

Round  49, Train loss: 0.058, Test loss: 1.099, Test accuracy: 76.00 

Round  49, Global train loss: 0.058, Global test loss: 1.095, Global test accuracy: 70.88 

Final Round, Train loss: 0.061, Test loss: 1.082, Test accuracy: 76.00 

Final Round, Global train loss: 0.061, Global test loss: 1.095, Global test accuracy: 70.88 

Average accuracy final 10 rounds: 75.824 

Average global accuracy final 10 rounds: 70.148 

1785.8137164115906
[8.498203039169312, 14.449324607849121, 20.142523288726807, 26.859060764312744, 33.32922172546387, 39.245086669921875, 45.734524965286255, 52.642884731292725, 59.46606969833374, 66.18889474868774, 72.10962057113647, 78.14499402046204, 84.75133991241455, 90.78724527359009, 97.57479858398438, 104.21560168266296, 110.07374835014343, 116.74170136451721, 123.11721920967102, 128.97892379760742, 134.74556803703308, 140.6823947429657, 147.01254177093506, 153.52484798431396, 159.49909615516663, 165.5076973438263, 171.78565788269043, 178.09141993522644, 184.78105235099792, 191.6060655117035, 198.09935426712036, 203.89416193962097, 209.93540501594543, 216.8072760105133, 222.59429287910461, 228.41803669929504, 234.14219903945923, 240.5657901763916, 247.2182857990265, 253.8828353881836, 259.84985160827637, 265.8379271030426, 272.21646213531494, 278.9276306629181, 285.17605900764465, 291.48911237716675, 297.5386543273926, 303.78312611579895, 310.19233870506287, 316.2092561721802, 328.440310716629]
[47.6, 50.04, 55.92, 56.4, 55.76, 59.52, 58.44, 63.0, 63.04, 64.08, 67.52, 66.08, 66.32, 67.8, 68.32, 69.88, 69.4, 66.8, 68.76, 70.92, 73.48, 71.2, 65.24, 72.52, 73.44, 71.4, 70.04, 74.24, 69.6, 71.24, 73.44, 74.48, 73.92, 73.76, 71.16, 75.28, 74.6, 73.96, 75.68, 72.2, 73.96, 75.92, 76.6, 77.52, 72.68, 75.44, 76.64, 77.56, 75.92, 76.0, 76.0]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.542, Test loss: 1.770, Test accuracy: 25.72 

Round   1, Train loss: 1.354, Test loss: 1.481, Test accuracy: 38.12 

Round   2, Train loss: 1.230, Test loss: 1.348, Test accuracy: 42.52 

Round   3, Train loss: 1.123, Test loss: 1.167, Test accuracy: 52.04 

Round   4, Train loss: 1.052, Test loss: 1.133, Test accuracy: 55.40 

Round   5, Train loss: 0.973, Test loss: 1.005, Test accuracy: 57.92 

Round   6, Train loss: 0.928, Test loss: 1.067, Test accuracy: 57.00 

Round   7, Train loss: 0.886, Test loss: 0.895, Test accuracy: 65.68 

Round   8, Train loss: 0.832, Test loss: 1.011, Test accuracy: 62.48 

Round   9, Train loss: 0.791, Test loss: 0.880, Test accuracy: 65.20 

Round  10, Train loss: 0.756, Test loss: 0.984, Test accuracy: 62.52 

Round  11, Train loss: 0.714, Test loss: 0.847, Test accuracy: 68.56 

Round  12, Train loss: 0.675, Test loss: 0.808, Test accuracy: 68.32 

Round  13, Train loss: 0.656, Test loss: 0.918, Test accuracy: 66.44 

Round  14, Train loss: 0.616, Test loss: 0.782, Test accuracy: 70.20 

Round  15, Train loss: 0.576, Test loss: 0.757, Test accuracy: 71.32 

Round  16, Train loss: 0.551, Test loss: 0.785, Test accuracy: 72.52 

Round  17, Train loss: 0.508, Test loss: 0.776, Test accuracy: 72.16 

Round  18, Train loss: 0.480, Test loss: 0.730, Test accuracy: 72.12 

Round  19, Train loss: 0.458, Test loss: 0.728, Test accuracy: 72.96 

Round  20, Train loss: 0.422, Test loss: 0.722, Test accuracy: 73.52 

Round  21, Train loss: 0.407, Test loss: 0.703, Test accuracy: 74.64 

Round  22, Train loss: 0.394, Test loss: 0.797, Test accuracy: 72.00 

Round  23, Train loss: 0.358, Test loss: 0.742, Test accuracy: 75.16 

Round  24, Train loss: 0.345, Test loss: 0.709, Test accuracy: 75.60 

Round  25, Train loss: 0.326, Test loss: 0.746, Test accuracy: 74.76 

Round  26, Train loss: 0.296, Test loss: 0.764, Test accuracy: 73.24 

Round  27, Train loss: 0.294, Test loss: 0.747, Test accuracy: 75.04 

Round  28, Train loss: 0.273, Test loss: 0.762, Test accuracy: 74.52 

Round  29, Train loss: 0.255, Test loss: 0.745, Test accuracy: 75.44 

Round  30, Train loss: 0.244, Test loss: 0.758, Test accuracy: 75.92 

Round  31, Train loss: 0.226, Test loss: 0.733, Test accuracy: 76.28 

Round  32, Train loss: 0.223, Test loss: 0.760, Test accuracy: 75.56 

Round  33, Train loss: 0.201, Test loss: 0.758, Test accuracy: 76.36 

Round  34, Train loss: 0.203, Test loss: 0.740, Test accuracy: 76.20 

Round  35, Train loss: 0.169, Test loss: 0.765, Test accuracy: 76.52 

Round  36, Train loss: 0.161, Test loss: 0.746, Test accuracy: 76.84 

Round  37, Train loss: 0.148, Test loss: 0.733, Test accuracy: 77.72 

Round  38, Train loss: 0.143, Test loss: 0.744, Test accuracy: 77.12 

Round  39, Train loss: 0.137, Test loss: 0.764, Test accuracy: 76.68 

Round  40, Train loss: 0.122, Test loss: 0.773, Test accuracy: 77.96 

Round  41, Train loss: 0.125, Test loss: 0.791, Test accuracy: 77.16 

Round  42, Train loss: 0.124, Test loss: 0.793, Test accuracy: 77.20 

Round  43, Train loss: 0.110, Test loss: 0.804, Test accuracy: 76.84 

Round  44, Train loss: 0.107, Test loss: 0.768, Test accuracy: 77.76 

Round  45, Train loss: 0.094, Test loss: 0.805, Test accuracy: 77.08 

Round  46, Train loss: 0.094, Test loss: 0.764, Test accuracy: 78.12 

Round  47, Train loss: 0.076, Test loss: 0.758, Test accuracy: 78.44 

Round  48, Train loss: 0.087, Test loss: 0.799, Test accuracy: 78.04 

Round  49, Train loss: 0.086, Test loss: 0.793, Test accuracy: 77.64 

Final Round, Train loss: 0.044, Test loss: 0.811, Test accuracy: 77.12 

Average accuracy final 10 rounds: 77.624 

1340.8733649253845
[8.984848737716675, 14.484405040740967, 19.052581310272217, 23.902995586395264, 28.619823932647705, 34.037060022354126, 38.787554025650024, 43.40383744239807, 48.70466160774231, 54.23080325126648, 58.93038058280945, 63.82697248458862, 68.64372038841248, 73.54223155975342, 78.99329853057861, 83.93371200561523, 89.43508696556091, 94.32586240768433, 100.04571986198425, 105.00923109054565, 109.96933650970459, 114.80174088478088, 119.53962898254395, 124.3763906955719, 129.7403199672699, 134.84860348701477, 139.29897832870483, 143.84490323066711, 149.13480257987976, 154.25388836860657, 158.8378393650055, 163.27967071533203, 167.8512794971466, 172.92801022529602, 177.28385758399963, 181.79782724380493, 186.33958768844604, 191.9360990524292, 197.68717288970947, 203.38624477386475, 208.21932554244995, 213.69202256202698, 218.45296621322632, 223.13672184944153, 228.7147262096405, 234.23511719703674, 239.08913564682007, 243.89888334274292, 249.15286993980408, 253.97450971603394, 260.7874631881714]
[25.72, 38.12, 42.52, 52.04, 55.4, 57.92, 57.0, 65.68, 62.48, 65.2, 62.52, 68.56, 68.32, 66.44, 70.2, 71.32, 72.52, 72.16, 72.12, 72.96, 73.52, 74.64, 72.0, 75.16, 75.6, 74.76, 73.24, 75.04, 74.52, 75.44, 75.92, 76.28, 75.56, 76.36, 76.2, 76.52, 76.84, 77.72, 77.12, 76.68, 77.96, 77.16, 77.2, 76.84, 77.76, 77.08, 78.12, 78.44, 78.04, 77.64, 77.12]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
Round   0, Train loss: 1.548, Test loss: 1.720, Test accuracy: 27.68
Round   1, Train loss: 1.374, Test loss: 1.448, Test accuracy: 38.88
Round   2, Train loss: 1.222, Test loss: 1.339, Test accuracy: 49.36
Round   3, Train loss: 1.110, Test loss: 1.092, Test accuracy: 55.04
Round   4, Train loss: 1.031, Test loss: 1.034, Test accuracy: 58.48
Round   5, Train loss: 0.975, Test loss: 1.074, Test accuracy: 57.80
Round   6, Train loss: 0.936, Test loss: 1.138, Test accuracy: 57.60
Round   7, Train loss: 0.898, Test loss: 1.000, Test accuracy: 62.08
Round   8, Train loss: 0.839, Test loss: 0.938, Test accuracy: 63.72
Round   9, Train loss: 0.787, Test loss: 1.044, Test accuracy: 60.40
Round  10, Train loss: 0.756, Test loss: 0.912, Test accuracy: 65.52
Round  11, Train loss: 0.714, Test loss: 0.876, Test accuracy: 66.60
Round  12, Train loss: 0.669, Test loss: 0.911, Test accuracy: 65.32
Round  13, Train loss: 0.631, Test loss: 0.789, Test accuracy: 70.48
Round  14, Train loss: 0.596, Test loss: 0.799, Test accuracy: 70.60
Round  15, Train loss: 0.566, Test loss: 0.771, Test accuracy: 71.40
Round  16, Train loss: 0.537, Test loss: 0.793, Test accuracy: 70.56
Round  17, Train loss: 0.522, Test loss: 0.792, Test accuracy: 71.72
Round  18, Train loss: 0.477, Test loss: 0.792, Test accuracy: 71.00
Round  19, Train loss: 0.456, Test loss: 0.840, Test accuracy: 70.64
Round  20, Train loss: 0.431, Test loss: 0.743, Test accuracy: 73.00
Round  21, Train loss: 0.405, Test loss: 0.719, Test accuracy: 74.20
Round  22, Train loss: 0.380, Test loss: 0.763, Test accuracy: 73.52
Round  23, Train loss: 0.366, Test loss: 0.727, Test accuracy: 73.56
Round  24, Train loss: 0.332, Test loss: 0.716, Test accuracy: 75.20
Round  25, Train loss: 0.319, Test loss: 0.743, Test accuracy: 75.40
Round  26, Train loss: 0.317, Test loss: 0.702, Test accuracy: 75.84
Round  27, Train loss: 0.278, Test loss: 0.745, Test accuracy: 75.24
Round  28, Train loss: 0.261, Test loss: 0.731, Test accuracy: 75.64
Round  29, Train loss: 0.265, Test loss: 0.751, Test accuracy: 75.84
Round  30, Train loss: 0.240, Test loss: 0.767, Test accuracy: 75.48
Round  31, Train loss: 0.236, Test loss: 0.724, Test accuracy: 75.16
Round  32, Train loss: 0.196, Test loss: 0.704, Test accuracy: 76.80
Round  33, Train loss: 0.190, Test loss: 0.723, Test accuracy: 76.92
Round  34, Train loss: 0.187, Test loss: 0.717, Test accuracy: 76.88
Round  35, Train loss: 0.182, Test loss: 0.709, Test accuracy: 76.68
Round  36, Train loss: 0.156, Test loss: 0.752, Test accuracy: 76.80
Round  37, Train loss: 0.160, Test loss: 0.711, Test accuracy: 76.72
Round  38, Train loss: 0.142, Test loss: 0.757, Test accuracy: 76.56
Round  39, Train loss: 0.143, Test loss: 0.721, Test accuracy: 77.20
Round  40, Train loss: 0.134, Test loss: 0.764, Test accuracy: 77.00
Round  41, Train loss: 0.125, Test loss: 0.743, Test accuracy: 77.52
Round  42, Train loss: 0.111, Test loss: 0.783, Test accuracy: 77.48
Round  43, Train loss: 0.109, Test loss: 0.768, Test accuracy: 77.36
Round  44, Train loss: 0.104, Test loss: 0.745, Test accuracy: 77.68
Round  45, Train loss: 0.089, Test loss: 0.745, Test accuracy: 77.96
Round  46, Train loss: 0.085, Test loss: 0.756, Test accuracy: 77.92
Round  47, Train loss: 0.105, Test loss: 0.774, Test accuracy: 77.40
Round  48, Train loss: 0.069, Test loss: 0.753, Test accuracy: 78.12
Round  49, Train loss: 0.073, Test loss: 0.774, Test accuracy: 78.40
Final Round, Train loss: 0.042, Test loss: 0.792, Test accuracy: 77.92
Average accuracy final 10 rounds: 77.68400000000001
1527.109272480011
[8.442850112915039, 14.716120958328247, 19.91736102104187, 25.220898628234863, 30.35368514060974, 35.55845284461975, 40.774982929229736, 46.35861134529114, 52.17902421951294, 58.117875814437866, 64.54570627212524, 70.20488739013672, 76.603830575943, 82.6962378025055, 88.95634651184082, 94.7956154346466, 100.44744658470154, 106.90641736984253, 113.78559160232544, 119.38069820404053, 125.3572506904602, 130.58589124679565, 136.19843554496765, 142.22107863426208, 148.36547684669495, 153.4722170829773, 158.6167333126068, 163.86070275306702, 169.29784393310547, 175.78333711624146, 181.90394401550293, 188.37470984458923, 194.2658429145813, 199.98386454582214, 206.22792053222656, 212.07665991783142, 217.912663936615, 224.2300045490265, 230.0309295654297, 236.41420078277588, 242.5209972858429, 247.7708761692047, 253.7785449028015, 259.4686698913574, 265.5601603984833, 270.8015487194061, 276.1373887062073, 281.5707540512085, 286.94441986083984, 292.1817464828491, 299.35081601142883]
[27.68, 38.88, 49.36, 55.04, 58.48, 57.8, 57.6, 62.08, 63.72, 60.4, 65.52, 66.6, 65.32, 70.48, 70.6, 71.4, 70.56, 71.72, 71.0, 70.64, 73.0, 74.2, 73.52, 73.56, 75.2, 75.4, 75.84, 75.24, 75.64, 75.84, 75.48, 75.16, 76.8, 76.92, 76.88, 76.68, 76.8, 76.72, 76.56, 77.2, 77.0, 77.52, 77.48, 77.36, 77.68, 77.96, 77.92, 77.4, 78.12, 78.4, 77.92]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

        init --> train local model(freeze embeding):client   0,  Train loss: 0.670, Train accuracy: 77.000, Test loss: 1.269, Test accuracy: 56.00 

        train local model (freeze embeding):client   0,  Train loss: 0.600, Train accuracy: 77.600, Test loss: 1.237, Test accuracy: 54.40 

        train local model (unfreeze embeding):client   0,  Train loss: 1.218, Train accuracy: 48.400, Test loss: 1.322, Test accuracy: 46.20 

Round   0, Train loss: 1.162, Test loss: 1.322, Test accuracy: 46.20 

        train local model (freeze embeding):client   0,  Train loss: 1.003, Train accuracy: 58.200, Test loss: 1.241, Test accuracy: 52.80 

        train local model (unfreeze embeding):client   0,  Train loss: 1.112, Train accuracy: 52.000, Test loss: 1.269, Test accuracy: 47.80 

Round   1, Train loss: 1.241, Test loss: 1.269, Test accuracy: 47.80 

        train local model (freeze embeding):client   0,  Train loss: 0.832, Train accuracy: 66.400, Test loss: 1.281, Test accuracy: 52.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.824, Train accuracy: 71.200, Test loss: 1.233, Test accuracy: 51.80 

Round   2, Train loss: 1.045, Test loss: 1.233, Test accuracy: 51.80 

        train local model (freeze embeding):client   0,  Train loss: 0.834, Train accuracy: 68.400, Test loss: 1.458, Test accuracy: 50.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.700, Train accuracy: 73.600, Test loss: 1.276, Test accuracy: 49.60 

Round   3, Train loss: 0.910, Test loss: 1.276, Test accuracy: 49.60 

        train local model (freeze embeding):client   0,  Train loss: 0.696, Train accuracy: 72.000, Test loss: 1.512, Test accuracy: 50.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.591, Train accuracy: 78.200, Test loss: 1.298, Test accuracy: 54.00 

Round   4, Train loss: 0.818, Test loss: 1.298, Test accuracy: 54.00 

        train local model (freeze embeding):client   0,  Train loss: 0.539, Train accuracy: 79.400, Test loss: 1.449, Test accuracy: 55.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.633, Train accuracy: 76.600, Test loss: 1.605, Test accuracy: 52.00 

Round   5, Train loss: 0.750, Test loss: 1.605, Test accuracy: 52.00 

        train local model (freeze embeding):client   0,  Train loss: 0.510, Train accuracy: 80.000, Test loss: 1.529, Test accuracy: 53.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.592, Train accuracy: 76.000, Test loss: 1.672, Test accuracy: 49.80 

Round   6, Train loss: 0.689, Test loss: 1.672, Test accuracy: 49.80 

        train local model (freeze embeding):client   0,  Train loss: 0.501, Train accuracy: 81.800, Test loss: 1.662, Test accuracy: 52.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.436, Train accuracy: 84.000, Test loss: 1.504, Test accuracy: 55.60 

Round   7, Train loss: 0.620, Test loss: 1.504, Test accuracy: 55.60 

        train local model (freeze embeding):client   0,  Train loss: 0.452, Train accuracy: 81.800, Test loss: 1.740, Test accuracy: 51.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.397, Train accuracy: 82.200, Test loss: 1.575, Test accuracy: 52.20 

Round   8, Train loss: 0.598, Test loss: 1.575, Test accuracy: 52.20 

        train local model (freeze embeding):client   0,  Train loss: 0.315, Train accuracy: 87.600, Test loss: 1.633, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.476, Train accuracy: 83.400, Test loss: 1.631, Test accuracy: 52.00 

Round   9, Train loss: 0.544, Test loss: 1.631, Test accuracy: 52.00 

        train local model (freeze embeding):client   0,  Train loss: 0.388, Train accuracy: 85.600, Test loss: 1.676, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.356, Train accuracy: 85.600, Test loss: 1.865, Test accuracy: 50.60 

Round  10, Train loss: 0.538, Test loss: 1.865, Test accuracy: 50.60 

        train local model (freeze embeding):client   0,  Train loss: 0.290, Train accuracy: 88.600, Test loss: 1.756, Test accuracy: 53.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.276, Train accuracy: 90.600, Test loss: 1.769, Test accuracy: 53.20 

Round  11, Train loss: 0.547, Test loss: 1.769, Test accuracy: 53.20 

        train local model (freeze embeding):client   0,  Train loss: 0.270, Train accuracy: 89.600, Test loss: 1.743, Test accuracy: 54.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.259, Train accuracy: 89.800, Test loss: 1.863, Test accuracy: 54.00 

Round  12, Train loss: 0.489, Test loss: 1.863, Test accuracy: 54.00 

        train local model (freeze embeding):client   0,  Train loss: 0.244, Train accuracy: 91.000, Test loss: 1.868, Test accuracy: 54.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.316, Train accuracy: 87.200, Test loss: 1.957, Test accuracy: 49.20 

Round  13, Train loss: 0.427, Test loss: 1.957, Test accuracy: 49.20 

        train local model (freeze embeding):client   0,  Train loss: 0.351, Train accuracy: 87.200, Test loss: 2.021, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.231, Train accuracy: 93.200, Test loss: 2.237, Test accuracy: 52.60 

Round  14, Train loss: 0.418, Test loss: 2.237, Test accuracy: 52.60 

        train local model (freeze embeding):client   0,  Train loss: 0.224, Train accuracy: 91.600, Test loss: 1.958, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.130, Train accuracy: 95.800, Test loss: 2.275, Test accuracy: 54.00 

Round  15, Train loss: 0.408, Test loss: 2.275, Test accuracy: 54.00 

        train local model (freeze embeding):client   0,  Train loss: 0.245, Train accuracy: 90.800, Test loss: 2.039, Test accuracy: 53.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.243, Train accuracy: 89.800, Test loss: 2.461, Test accuracy: 52.60 

Round  16, Train loss: 0.358, Test loss: 2.461, Test accuracy: 52.60 

        train local model (freeze embeding):client   0,  Train loss: 0.201, Train accuracy: 94.200, Test loss: 2.059, Test accuracy: 54.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.118, Train accuracy: 96.600, Test loss: 2.264, Test accuracy: 54.60 

Round  17, Train loss: 0.406, Test loss: 2.264, Test accuracy: 54.60 

        train local model (freeze embeding):client   0,  Train loss: 0.215, Train accuracy: 93.800, Test loss: 2.099, Test accuracy: 54.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.077, Train accuracy: 97.600, Test loss: 2.605, Test accuracy: 51.00 

Round  18, Train loss: 0.370, Test loss: 2.605, Test accuracy: 51.00 

        train local model (freeze embeding):client   0,  Train loss: 0.186, Train accuracy: 94.200, Test loss: 2.079, Test accuracy: 54.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.097, Train accuracy: 97.800, Test loss: 2.538, Test accuracy: 51.80 

Round  19, Train loss: 0.356, Test loss: 2.538, Test accuracy: 51.80 

        train local model (freeze embeding):client   0,  Train loss: 0.217, Train accuracy: 92.200, Test loss: 2.074, Test accuracy: 53.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.069, Train accuracy: 98.200, Test loss: 2.641, Test accuracy: 50.40 

Final Round, Train loss: 0.351, Test loss: 2.621, Test accuracy: 51.00 

---------------------------------------------train_client: [0, 1] 

        init --> train local model(freeze embeding):client   1,  Train loss: 1.012, Train accuracy: 58.800, Test loss: 1.176, Test accuracy: 54.80 

        train local model (freeze embeding):client   0,  Train loss: 0.258, Train accuracy: 90.400, Test loss: 2.176, Test accuracy: 51.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.056, Train accuracy: 98.600, Test loss: 2.671, Test accuracy: 54.20 

        train local model (freeze embeding):client   1,  Train loss: 1.162, Train accuracy: 56.800, Test loss: 1.272, Test accuracy: 54.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.774, Train accuracy: 70.400, Test loss: 1.030, Test accuracy: 60.80 

Round   0, Train loss: 0.725, Test loss: 1.593, Test accuracy: 57.10 

        train local model (freeze embeding):client   0,  Train loss: 0.229, Train accuracy: 91.000, Test loss: 2.066, Test accuracy: 54.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.093, Train accuracy: 97.200, Test loss: 2.732, Test accuracy: 55.00 

        train local model (freeze embeding):client   1,  Train loss: 0.853, Train accuracy: 64.600, Test loss: 1.086, Test accuracy: 60.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.668, Train accuracy: 73.400, Test loss: 1.067, Test accuracy: 60.20 

Round   1, Train loss: 0.706, Test loss: 1.654, Test accuracy: 57.00 

        train local model (freeze embeding):client   0,  Train loss: 0.335, Train accuracy: 88.400, Test loss: 1.934, Test accuracy: 54.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.093, Train accuracy: 97.200, Test loss: 2.448, Test accuracy: 54.20 

        train local model (freeze embeding):client   1,  Train loss: 0.839, Train accuracy: 65.200, Test loss: 1.059, Test accuracy: 61.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.621, Train accuracy: 76.800, Test loss: 1.040, Test accuracy: 58.40 

Round   2, Train loss: 0.678, Test loss: 1.537, Test accuracy: 57.40 

        train local model (freeze embeding):client   0,  Train loss: 0.296, Train accuracy: 90.000, Test loss: 1.784, Test accuracy: 55.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.118, Train accuracy: 96.000, Test loss: 2.802, Test accuracy: 50.00 

        train local model (freeze embeding):client   1,  Train loss: 0.779, Train accuracy: 68.600, Test loss: 1.094, Test accuracy: 59.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.619, Train accuracy: 75.000, Test loss: 1.143, Test accuracy: 61.40 

Round   3, Train loss: 0.676, Test loss: 1.627, Test accuracy: 58.20 

        train local model (freeze embeding):client   0,  Train loss: 0.322, Train accuracy: 89.400, Test loss: 1.799, Test accuracy: 54.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.129, Train accuracy: 95.400, Test loss: 2.644, Test accuracy: 52.40 

        train local model (freeze embeding):client   1,  Train loss: 1.020, Train accuracy: 61.000, Test loss: 1.278, Test accuracy: 54.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.654, Train accuracy: 73.000, Test loss: 1.373, Test accuracy: 52.40 

Round   4, Train loss: 0.663, Test loss: 1.698, Test accuracy: 56.60 

        train local model (freeze embeding):client   0,  Train loss: 0.360, Train accuracy: 88.000, Test loss: 1.673, Test accuracy: 55.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.093, Train accuracy: 97.600, Test loss: 2.414, Test accuracy: 53.20 

        train local model (freeze embeding):client   1,  Train loss: 0.753, Train accuracy: 68.200, Test loss: 1.131, Test accuracy: 58.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.584, Train accuracy: 76.800, Test loss: 1.276, Test accuracy: 58.60 

Round   5, Train loss: 0.682, Test loss: 1.593, Test accuracy: 57.30 

        train local model (freeze embeding):client   0,  Train loss: 0.448, Train accuracy: 81.200, Test loss: 1.637, Test accuracy: 54.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.134, Train accuracy: 96.000, Test loss: 2.208, Test accuracy: 53.20 

        train local model (freeze embeding):client   1,  Train loss: 0.771, Train accuracy: 67.000, Test loss: 1.205, Test accuracy: 56.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.480, Train accuracy: 82.800, Test loss: 1.164, Test accuracy: 58.60 

Round   6, Train loss: 0.641, Test loss: 1.597, Test accuracy: 55.70 

        train local model (freeze embeding):client   0,  Train loss: 0.479, Train accuracy: 83.800, Test loss: 1.685, Test accuracy: 55.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.159, Train accuracy: 93.400, Test loss: 2.521, Test accuracy: 50.40 

        train local model (freeze embeding):client   1,  Train loss: 0.854, Train accuracy: 68.000, Test loss: 1.223, Test accuracy: 56.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.475, Train accuracy: 82.200, Test loss: 1.265, Test accuracy: 53.20 

Round   7, Train loss: 0.655, Test loss: 1.686, Test accuracy: 52.90 

        train local model (freeze embeding):client   0,  Train loss: 0.703, Train accuracy: 71.000, Test loss: 1.776, Test accuracy: 52.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.098, Train accuracy: 97.200, Test loss: 2.382, Test accuracy: 52.00 

        train local model (freeze embeding):client   1,  Train loss: 0.896, Train accuracy: 66.400, Test loss: 1.252, Test accuracy: 57.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.405, Train accuracy: 85.600, Test loss: 1.229, Test accuracy: 59.80 

Round   8, Train loss: 0.650, Test loss: 1.614, Test accuracy: 55.90 

        train local model (freeze embeding):client   0,  Train loss: 0.673, Train accuracy: 74.000, Test loss: 1.794, Test accuracy: 50.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.123, Train accuracy: 96.800, Test loss: 2.165, Test accuracy: 54.20 

        train local model (freeze embeding):client   1,  Train loss: 0.786, Train accuracy: 69.800, Test loss: 1.265, Test accuracy: 55.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.383, Train accuracy: 84.800, Test loss: 1.346, Test accuracy: 58.80 

Round   9, Train loss: 0.664, Test loss: 1.609, Test accuracy: 58.00 

        train local model (freeze embeding):client   0,  Train loss: 0.497, Train accuracy: 81.600, Test loss: 1.532, Test accuracy: 54.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.229, Train accuracy: 90.400, Test loss: 2.707, Test accuracy: 51.20 

        train local model (freeze embeding):client   1,  Train loss: 0.778, Train accuracy: 65.600, Test loss: 1.268, Test accuracy: 52.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.508, Train accuracy: 81.200, Test loss: 1.446, Test accuracy: 53.80 

Round  10, Train loss: 0.657, Test loss: 1.772, Test accuracy: 54.90 

        train local model (freeze embeding):client   0,  Train loss: 0.577, Train accuracy: 78.200, Test loss: 1.563, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.071, Train accuracy: 98.800, Test loss: 2.346, Test accuracy: 52.20 

        train local model (freeze embeding):client   1,  Train loss: 0.614, Train accuracy: 76.600, Test loss: 1.125, Test accuracy: 56.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.308, Train accuracy: 89.600, Test loss: 1.323, Test accuracy: 60.60 

Round  11, Train loss: 0.650, Test loss: 1.663, Test accuracy: 56.60 

        train local model (freeze embeding):client   0,  Train loss: 0.537, Train accuracy: 78.600, Test loss: 1.545, Test accuracy: 53.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.157, Train accuracy: 93.800, Test loss: 2.307, Test accuracy: 48.60 

        train local model (freeze embeding):client   1,  Train loss: 0.823, Train accuracy: 71.200, Test loss: 1.326, Test accuracy: 53.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.403, Train accuracy: 85.200, Test loss: 1.345, Test accuracy: 56.60 

Round  12, Train loss: 0.676, Test loss: 1.597, Test accuracy: 56.90 

        train local model (freeze embeding):client   0,  Train loss: 1.006, Train accuracy: 62.800, Test loss: 1.894, Test accuracy: 49.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.123, Train accuracy: 96.200, Test loss: 2.356, Test accuracy: 49.20 

        train local model (freeze embeding):client   1,  Train loss: 0.646, Train accuracy: 74.200, Test loss: 1.138, Test accuracy: 58.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.346, Train accuracy: 87.000, Test loss: 1.497, Test accuracy: 54.20 

Round  13, Train loss: 0.657, Test loss: 1.718, Test accuracy: 54.80 

        train local model (freeze embeding):client   0,  Train loss: 0.672, Train accuracy: 73.600, Test loss: 1.538, Test accuracy: 51.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.311, Train accuracy: 88.600, Test loss: 2.514, Test accuracy: 51.60 

        train local model (freeze embeding):client   1,  Train loss: 0.700, Train accuracy: 71.600, Test loss: 1.248, Test accuracy: 56.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.407, Train accuracy: 85.800, Test loss: 1.575, Test accuracy: 52.80 

Round  14, Train loss: 0.686, Test loss: 1.668, Test accuracy: 55.80 

        train local model (freeze embeding):client   0,  Train loss: 0.621, Train accuracy: 76.000, Test loss: 1.464, Test accuracy: 52.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.200, Train accuracy: 92.000, Test loss: 2.369, Test accuracy: 52.20 

        train local model (freeze embeding):client   1,  Train loss: 0.670, Train accuracy: 69.800, Test loss: 1.213, Test accuracy: 54.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.279, Train accuracy: 91.000, Test loss: 1.489, Test accuracy: 55.20 

Round  15, Train loss: 0.688, Test loss: 1.719, Test accuracy: 55.50 

        train local model (freeze embeding):client   0,  Train loss: 0.741, Train accuracy: 68.000, Test loss: 1.622, Test accuracy: 50.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.185, Train accuracy: 94.000, Test loss: 2.257, Test accuracy: 50.40 

        train local model (freeze embeding):client   1,  Train loss: 0.832, Train accuracy: 65.000, Test loss: 1.381, Test accuracy: 52.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.281, Train accuracy: 90.000, Test loss: 1.407, Test accuracy: 58.60 

Round  16, Train loss: 0.674, Test loss: 1.666, Test accuracy: 56.10 

        train local model (freeze embeding):client   0,  Train loss: 0.789, Train accuracy: 67.000, Test loss: 1.521, Test accuracy: 49.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.158, Train accuracy: 95.400, Test loss: 2.130, Test accuracy: 51.40 

        train local model (freeze embeding):client   1,  Train loss: 0.670, Train accuracy: 72.000, Test loss: 1.241, Test accuracy: 54.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.421, Train accuracy: 82.800, Test loss: 1.497, Test accuracy: 52.80 

Round  17, Train loss: 0.699, Test loss: 1.575, Test accuracy: 54.90 

        train local model (freeze embeding):client   0,  Train loss: 0.679, Train accuracy: 73.600, Test loss: 1.480, Test accuracy: 50.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.163, Train accuracy: 93.800, Test loss: 2.180, Test accuracy: 53.40 

        train local model (freeze embeding):client   1,  Train loss: 0.655, Train accuracy: 71.800, Test loss: 1.231, Test accuracy: 54.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.337, Train accuracy: 87.200, Test loss: 1.542, Test accuracy: 57.60 

Round  18, Train loss: 0.685, Test loss: 1.645, Test accuracy: 55.30 

        train local model (freeze embeding):client   0,  Train loss: 0.665, Train accuracy: 76.600, Test loss: 1.497, Test accuracy: 50.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.177, Train accuracy: 93.800, Test loss: 2.396, Test accuracy: 50.00 

        train local model (freeze embeding):client   1,  Train loss: 0.686, Train accuracy: 70.400, Test loss: 1.274, Test accuracy: 52.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.309, Train accuracy: 88.200, Test loss: 1.507, Test accuracy: 58.20 

Round  19, Train loss: 0.674, Test loss: 1.719, Test accuracy: 54.30 

        train local model (freeze embeding):client   0,  Train loss: 0.783, Train accuracy: 69.200, Test loss: 1.636, Test accuracy: 47.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.230, Train accuracy: 91.600, Test loss: 2.231, Test accuracy: 51.40 

        train local model (freeze embeding):client   1,  Train loss: 0.912, Train accuracy: 63.400, Test loss: 1.493, Test accuracy: 54.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.270, Train accuracy: 90.800, Test loss: 1.433, Test accuracy: 57.00 

Final Round, Train loss: 0.700, Test loss: 1.675, Test accuracy: 54.50 

---------------------------------------------train_client: [0, 1, 2] 

        init --> train local model(freeze embeding):client   2,  Train loss: 1.709, Train accuracy: 42.400, Test loss: 2.025, Test accuracy: 40.60 

        train local model (freeze embeding):client   0,  Train loss: 0.811, Train accuracy: 66.800, Test loss: 1.550, Test accuracy: 47.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.286, Train accuracy: 88.000, Test loss: 2.581, Test accuracy: 51.60 

        train local model (freeze embeding):client   1,  Train loss: 0.750, Train accuracy: 71.200, Test loss: 1.374, Test accuracy: 56.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.337, Train accuracy: 87.200, Test loss: 1.807, Test accuracy: 55.40 

        train local model (freeze embeding):client   2,  Train loss: 0.983, Train accuracy: 60.200, Test loss: 1.186, Test accuracy: 52.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.771, Train accuracy: 67.600, Test loss: 1.149, Test accuracy: 58.00 

Round   0, Train loss: 0.820, Test loss: 1.429, Test accuracy: 56.33 

        train local model (freeze embeding):client   0,  Train loss: 0.893, Train accuracy: 61.200, Test loss: 1.631, Test accuracy: 46.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.420, Train accuracy: 82.600, Test loss: 2.517, Test accuracy: 49.80 

        train local model (freeze embeding):client   1,  Train loss: 0.747, Train accuracy: 67.000, Test loss: 1.266, Test accuracy: 51.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.305, Train accuracy: 89.200, Test loss: 1.635, Test accuracy: 52.60 

        train local model (freeze embeding):client   2,  Train loss: 0.932, Train accuracy: 62.000, Test loss: 1.157, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.658, Train accuracy: 73.400, Test loss: 1.148, Test accuracy: 58.20 

Round   1, Train loss: 0.813, Test loss: 1.472, Test accuracy: 54.53 

        train local model (freeze embeding):client   0,  Train loss: 0.896, Train accuracy: 65.600, Test loss: 1.547, Test accuracy: 47.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.224, Train accuracy: 91.400, Test loss: 2.220, Test accuracy: 48.80 

        train local model (freeze embeding):client   1,  Train loss: 0.704, Train accuracy: 73.000, Test loss: 1.280, Test accuracy: 54.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.265, Train accuracy: 92.200, Test loss: 1.486, Test accuracy: 55.60 

        train local model (freeze embeding):client   2,  Train loss: 1.009, Train accuracy: 58.200, Test loss: 1.297, Test accuracy: 53.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.692, Train accuracy: 69.800, Test loss: 1.221, Test accuracy: 56.60 

Round   2, Train loss: 0.804, Test loss: 1.414, Test accuracy: 55.80 

        train local model (freeze embeding):client   0,  Train loss: 0.790, Train accuracy: 67.800, Test loss: 1.439, Test accuracy: 49.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.236, Train accuracy: 90.400, Test loss: 2.090, Test accuracy: 51.80 

        train local model (freeze embeding):client   1,  Train loss: 0.790, Train accuracy: 68.800, Test loss: 1.301, Test accuracy: 54.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.290, Train accuracy: 89.400, Test loss: 1.548, Test accuracy: 54.40 

        train local model (freeze embeding):client   2,  Train loss: 0.935, Train accuracy: 61.600, Test loss: 1.222, Test accuracy: 52.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.560, Train accuracy: 79.800, Test loss: 1.161, Test accuracy: 58.40 

Round   3, Train loss: 0.814, Test loss: 1.408, Test accuracy: 54.93 

        train local model (freeze embeding):client   0,  Train loss: 1.074, Train accuracy: 58.400, Test loss: 1.588, Test accuracy: 45.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.180, Train accuracy: 95.200, Test loss: 2.076, Test accuracy: 48.80 

        train local model (freeze embeding):client   1,  Train loss: 0.678, Train accuracy: 74.800, Test loss: 1.258, Test accuracy: 52.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.346, Train accuracy: 86.600, Test loss: 1.550, Test accuracy: 53.00 

        train local model (freeze embeding):client   2,  Train loss: 0.826, Train accuracy: 66.800, Test loss: 1.174, Test accuracy: 54.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.537, Train accuracy: 81.000, Test loss: 1.213, Test accuracy: 56.00 

Round   4, Train loss: 0.799, Test loss: 1.403, Test accuracy: 54.20 

        train local model (freeze embeding):client   0,  Train loss: 0.749, Train accuracy: 68.600, Test loss: 1.459, Test accuracy: 48.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.149, Train accuracy: 96.400, Test loss: 2.044, Test accuracy: 50.40 

        train local model (freeze embeding):client   1,  Train loss: 0.886, Train accuracy: 60.400, Test loss: 1.393, Test accuracy: 46.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.238, Train accuracy: 92.000, Test loss: 1.412, Test accuracy: 60.20 

        train local model (freeze embeding):client   2,  Train loss: 0.868, Train accuracy: 63.200, Test loss: 1.261, Test accuracy: 51.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.542, Train accuracy: 76.800, Test loss: 1.233, Test accuracy: 56.20 

Round   5, Train loss: 0.812, Test loss: 1.381, Test accuracy: 56.33 

        train local model (freeze embeding):client   0,  Train loss: 0.917, Train accuracy: 63.200, Test loss: 1.612, Test accuracy: 46.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.157, Train accuracy: 96.200, Test loss: 1.994, Test accuracy: 51.80 

        train local model (freeze embeding):client   1,  Train loss: 0.928, Train accuracy: 59.400, Test loss: 1.523, Test accuracy: 45.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.341, Train accuracy: 88.000, Test loss: 1.491, Test accuracy: 53.20 

        train local model (freeze embeding):client   2,  Train loss: 0.966, Train accuracy: 57.800, Test loss: 1.349, Test accuracy: 49.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.517, Train accuracy: 82.000, Test loss: 1.271, Test accuracy: 55.60 

Round   6, Train loss: 0.789, Test loss: 1.377, Test accuracy: 56.53 

        train local model (freeze embeding):client   0,  Train loss: 0.939, Train accuracy: 61.800, Test loss: 1.552, Test accuracy: 48.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.141, Train accuracy: 97.200, Test loss: 1.982, Test accuracy: 52.00 

        train local model (freeze embeding):client   1,  Train loss: 0.770, Train accuracy: 67.000, Test loss: 1.313, Test accuracy: 54.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.226, Train accuracy: 93.400, Test loss: 1.478, Test accuracy: 58.00 

        train local model (freeze embeding):client   2,  Train loss: 1.045, Train accuracy: 57.800, Test loss: 1.402, Test accuracy: 47.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.503, Train accuracy: 81.400, Test loss: 1.272, Test accuracy: 56.60 

Round   7, Train loss: 0.779, Test loss: 1.388, Test accuracy: 55.73 

        train local model (freeze embeding):client   0,  Train loss: 0.780, Train accuracy: 64.400, Test loss: 1.533, Test accuracy: 48.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.200, Train accuracy: 93.600, Test loss: 1.952, Test accuracy: 49.40 

        train local model (freeze embeding):client   1,  Train loss: 0.799, Train accuracy: 64.000, Test loss: 1.318, Test accuracy: 46.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.219, Train accuracy: 94.200, Test loss: 1.434, Test accuracy: 60.00 

        train local model (freeze embeding):client   2,  Train loss: 0.858, Train accuracy: 64.600, Test loss: 1.242, Test accuracy: 51.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.503, Train accuracy: 80.200, Test loss: 1.246, Test accuracy: 58.00 

Round   8, Train loss: 0.789, Test loss: 1.373, Test accuracy: 56.07 

        train local model (freeze embeding):client   0,  Train loss: 0.805, Train accuracy: 67.200, Test loss: 1.423, Test accuracy: 47.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.187, Train accuracy: 94.600, Test loss: 1.918, Test accuracy: 51.40 

        train local model (freeze embeding):client   1,  Train loss: 0.799, Train accuracy: 65.600, Test loss: 1.346, Test accuracy: 48.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.284, Train accuracy: 88.200, Test loss: 1.538, Test accuracy: 57.40 

        train local model (freeze embeding):client   2,  Train loss: 0.798, Train accuracy: 66.400, Test loss: 1.205, Test accuracy: 52.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.518, Train accuracy: 80.200, Test loss: 1.177, Test accuracy: 57.80 

Round   9, Train loss: 0.794, Test loss: 1.384, Test accuracy: 55.07 

        train local model (freeze embeding):client   0,  Train loss: 1.056, Train accuracy: 56.400, Test loss: 1.626, Test accuracy: 44.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.240, Train accuracy: 91.800, Test loss: 2.000, Test accuracy: 52.60 

        train local model (freeze embeding):client   1,  Train loss: 0.829, Train accuracy: 69.000, Test loss: 1.428, Test accuracy: 54.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.212, Train accuracy: 91.400, Test loss: 1.419, Test accuracy: 59.60 

        train local model (freeze embeding):client   2,  Train loss: 0.965, Train accuracy: 60.200, Test loss: 1.427, Test accuracy: 48.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.497, Train accuracy: 80.600, Test loss: 1.295, Test accuracy: 56.00 

Round  10, Train loss: 0.785, Test loss: 1.410, Test accuracy: 55.07 

        train local model (freeze embeding):client   0,  Train loss: 0.879, Train accuracy: 65.000, Test loss: 1.556, Test accuracy: 47.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.212, Train accuracy: 94.000, Test loss: 1.990, Test accuracy: 51.40 

        train local model (freeze embeding):client   1,  Train loss: 0.834, Train accuracy: 66.200, Test loss: 1.384, Test accuracy: 50.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.274, Train accuracy: 91.200, Test loss: 1.577, Test accuracy: 55.40 

        train local model (freeze embeding):client   2,  Train loss: 0.865, Train accuracy: 61.200, Test loss: 1.318, Test accuracy: 48.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.427, Train accuracy: 85.200, Test loss: 1.359, Test accuracy: 56.00 

Round  11, Train loss: 0.766, Test loss: 1.473, Test accuracy: 53.73 

        train local model (freeze embeding):client   0,  Train loss: 0.912, Train accuracy: 64.400, Test loss: 1.655, Test accuracy: 46.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.227, Train accuracy: 92.600, Test loss: 2.095, Test accuracy: 50.40 

        train local model (freeze embeding):client   1,  Train loss: 0.842, Train accuracy: 64.800, Test loss: 1.375, Test accuracy: 51.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.226, Train accuracy: 91.000, Test loss: 1.503, Test accuracy: 56.60 

        train local model (freeze embeding):client   2,  Train loss: 0.887, Train accuracy: 62.200, Test loss: 1.326, Test accuracy: 50.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.676, Train accuracy: 72.400, Test loss: 1.648, Test accuracy: 50.40 

Round  12, Train loss: 0.768, Test loss: 1.461, Test accuracy: 55.33 

        train local model (freeze embeding):client   0,  Train loss: 0.934, Train accuracy: 64.400, Test loss: 1.619, Test accuracy: 45.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.281, Train accuracy: 90.200, Test loss: 2.179, Test accuracy: 50.00 

        train local model (freeze embeding):client   1,  Train loss: 0.929, Train accuracy: 63.600, Test loss: 1.542, Test accuracy: 46.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.205, Train accuracy: 92.800, Test loss: 1.464, Test accuracy: 58.40 

        train local model (freeze embeding):client   2,  Train loss: 0.826, Train accuracy: 66.200, Test loss: 1.334, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.484, Train accuracy: 81.200, Test loss: 1.421, Test accuracy: 53.60 

Round  13, Train loss: 0.765, Test loss: 1.493, Test accuracy: 54.13 

        train local model (freeze embeding):client   0,  Train loss: 0.773, Train accuracy: 66.800, Test loss: 1.427, Test accuracy: 49.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.201, Train accuracy: 93.800, Test loss: 1.930, Test accuracy: 49.20 

        train local model (freeze embeding):client   1,  Train loss: 0.715, Train accuracy: 70.200, Test loss: 1.323, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.323, Train accuracy: 87.000, Test loss: 1.663, Test accuracy: 54.60 

        train local model (freeze embeding):client   2,  Train loss: 0.964, Train accuracy: 60.600, Test loss: 1.459, Test accuracy: 48.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.395, Train accuracy: 86.200, Test loss: 1.243, Test accuracy: 57.80 

Round  14, Train loss: 0.779, Test loss: 1.390, Test accuracy: 55.00 

        train local model (freeze embeding):client   0,  Train loss: 0.880, Train accuracy: 64.800, Test loss: 1.566, Test accuracy: 45.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.245, Train accuracy: 91.400, Test loss: 1.992, Test accuracy: 48.40 

        train local model (freeze embeding):client   1,  Train loss: 0.677, Train accuracy: 72.000, Test loss: 1.318, Test accuracy: 53.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.334, Train accuracy: 88.400, Test loss: 1.535, Test accuracy: 57.20 

        train local model (freeze embeding):client   2,  Train loss: 0.780, Train accuracy: 68.200, Test loss: 1.287, Test accuracy: 51.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.324, Train accuracy: 89.000, Test loss: 1.278, Test accuracy: 58.60 

Round  15, Train loss: 0.765, Test loss: 1.418, Test accuracy: 55.47 

        train local model (freeze embeding):client   0,  Train loss: 0.875, Train accuracy: 64.400, Test loss: 1.563, Test accuracy: 46.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.199, Train accuracy: 93.800, Test loss: 1.906, Test accuracy: 51.80 

        train local model (freeze embeding):client   1,  Train loss: 0.936, Train accuracy: 60.000, Test loss: 1.522, Test accuracy: 45.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.428, Train accuracy: 83.200, Test loss: 1.615, Test accuracy: 56.00 

        train local model (freeze embeding):client   2,  Train loss: 0.796, Train accuracy: 67.400, Test loss: 1.314, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.449, Train accuracy: 83.400, Test loss: 1.460, Test accuracy: 55.40 

Round  16, Train loss: 0.767, Test loss: 1.414, Test accuracy: 55.87 

        train local model (freeze embeding):client   0,  Train loss: 0.894, Train accuracy: 62.800, Test loss: 1.551, Test accuracy: 45.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.291, Train accuracy: 88.600, Test loss: 2.156, Test accuracy: 50.60 

        train local model (freeze embeding):client   1,  Train loss: 0.789, Train accuracy: 68.800, Test loss: 1.347, Test accuracy: 51.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.263, Train accuracy: 90.000, Test loss: 1.519, Test accuracy: 56.60 

        train local model (freeze embeding):client   2,  Train loss: 0.856, Train accuracy: 65.800, Test loss: 1.375, Test accuracy: 48.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.319, Train accuracy: 87.600, Test loss: 1.296, Test accuracy: 59.60 

Round  17, Train loss: 0.757, Test loss: 1.450, Test accuracy: 56.47 

        train local model (freeze embeding):client   0,  Train loss: 0.860, Train accuracy: 63.800, Test loss: 1.473, Test accuracy: 45.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.198, Train accuracy: 93.400, Test loss: 2.008, Test accuracy: 50.20 

        train local model (freeze embeding):client   1,  Train loss: 0.814, Train accuracy: 69.200, Test loss: 1.389, Test accuracy: 51.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.211, Train accuracy: 92.200, Test loss: 1.568, Test accuracy: 60.00 

        train local model (freeze embeding):client   2,  Train loss: 0.752, Train accuracy: 69.200, Test loss: 1.368, Test accuracy: 48.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.337, Train accuracy: 87.400, Test loss: 1.333, Test accuracy: 57.80 

Round  18, Train loss: 0.745, Test loss: 1.468, Test accuracy: 56.20 

        train local model (freeze embeding):client   0,  Train loss: 0.862, Train accuracy: 63.400, Test loss: 1.575, Test accuracy: 45.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.217, Train accuracy: 91.800, Test loss: 1.969, Test accuracy: 50.00 

        train local model (freeze embeding):client   1,  Train loss: 0.933, Train accuracy: 64.600, Test loss: 1.503, Test accuracy: 49.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.167, Train accuracy: 95.600, Test loss: 1.482, Test accuracy: 58.20 

        train local model (freeze embeding):client   2,  Train loss: 0.816, Train accuracy: 66.600, Test loss: 1.297, Test accuracy: 49.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.376, Train accuracy: 85.000, Test loss: 1.452, Test accuracy: 55.00 

Round  19, Train loss: 0.754, Test loss: 1.478, Test accuracy: 54.80 

        train local model (freeze embeding):client   0,  Train loss: 0.864, Train accuracy: 65.400, Test loss: 1.453, Test accuracy: 46.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.301, Train accuracy: 88.000, Test loss: 2.089, Test accuracy: 52.80 

        train local model (freeze embeding):client   1,  Train loss: 0.751, Train accuracy: 68.000, Test loss: 1.400, Test accuracy: 51.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.204, Train accuracy: 94.200, Test loss: 1.463, Test accuracy: 56.40 

        train local model (freeze embeding):client   2,  Train loss: 0.733, Train accuracy: 69.200, Test loss: 1.286, Test accuracy: 50.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.436, Train accuracy: 83.400, Test loss: 1.423, Test accuracy: 55.60 

Final Round, Train loss: 0.744, Test loss: 1.490, Test accuracy: 54.60 

---------------------------------------------train_client: [0, 1, 2, 3] 

        init --> train local model(freeze embeding):client   3,  Train loss: 1.128, Train accuracy: 54.400, Test loss: 1.193, Test accuracy: 51.80 

        train local model (freeze embeding):client   0,  Train loss: 0.883, Train accuracy: 62.600, Test loss: 1.545, Test accuracy: 45.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.182, Train accuracy: 95.800, Test loss: 1.887, Test accuracy: 51.60 

        train local model (freeze embeding):client   1,  Train loss: 0.821, Train accuracy: 70.600, Test loss: 1.399, Test accuracy: 48.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.256, Train accuracy: 91.200, Test loss: 1.537, Test accuracy: 55.60 

        train local model (freeze embeding):client   2,  Train loss: 0.725, Train accuracy: 69.600, Test loss: 1.245, Test accuracy: 53.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.448, Train accuracy: 82.000, Test loss: 1.510, Test accuracy: 55.00 

        train local model (freeze embeding):client   3,  Train loss: 1.237, Train accuracy: 50.400, Test loss: 1.309, Test accuracy: 46.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.793, Train accuracy: 67.800, Test loss: 0.987, Test accuracy: 62.80 

Round   0, Train loss: 0.834, Test loss: 1.285, Test accuracy: 58.15 

        train local model (freeze embeding):client   0,  Train loss: 0.839, Train accuracy: 65.000, Test loss: 1.429, Test accuracy: 48.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.365, Train accuracy: 84.800, Test loss: 2.206, Test accuracy: 50.80 

        train local model (freeze embeding):client   1,  Train loss: 1.004, Train accuracy: 62.800, Test loss: 1.578, Test accuracy: 49.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.310, Train accuracy: 87.000, Test loss: 1.642, Test accuracy: 58.20 

        train local model (freeze embeding):client   2,  Train loss: 0.786, Train accuracy: 67.400, Test loss: 1.397, Test accuracy: 47.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.279, Train accuracy: 90.000, Test loss: 1.431, Test accuracy: 58.00 

        train local model (freeze embeding):client   3,  Train loss: 1.091, Train accuracy: 54.200, Test loss: 1.190, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.757, Train accuracy: 70.000, Test loss: 1.065, Test accuracy: 59.80 

Round   1, Train loss: 0.819, Test loss: 1.333, Test accuracy: 56.40 

        train local model (freeze embeding):client   0,  Train loss: 0.923, Train accuracy: 62.600, Test loss: 1.606, Test accuracy: 45.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.408, Train accuracy: 82.000, Test loss: 2.103, Test accuracy: 49.60 

        train local model (freeze embeding):client   1,  Train loss: 0.866, Train accuracy: 63.000, Test loss: 1.419, Test accuracy: 46.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.223, Train accuracy: 92.000, Test loss: 1.571, Test accuracy: 56.40 

        train local model (freeze embeding):client   2,  Train loss: 0.708, Train accuracy: 71.600, Test loss: 1.298, Test accuracy: 50.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.314, Train accuracy: 89.800, Test loss: 1.451, Test accuracy: 57.80 

        train local model (freeze embeding):client   3,  Train loss: 1.003, Train accuracy: 58.200, Test loss: 1.108, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.730, Train accuracy: 71.000, Test loss: 1.051, Test accuracy: 61.00 

Round   2, Train loss: 0.822, Test loss: 1.363, Test accuracy: 56.20 

        train local model (freeze embeding):client   0,  Train loss: 0.829, Train accuracy: 64.800, Test loss: 1.451, Test accuracy: 45.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.363, Train accuracy: 85.400, Test loss: 2.225, Test accuracy: 48.80 

        train local model (freeze embeding):client   1,  Train loss: 0.705, Train accuracy: 72.000, Test loss: 1.339, Test accuracy: 53.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.194, Train accuracy: 93.600, Test loss: 1.462, Test accuracy: 58.60 

        train local model (freeze embeding):client   2,  Train loss: 0.872, Train accuracy: 61.400, Test loss: 1.436, Test accuracy: 46.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.347, Train accuracy: 86.600, Test loss: 1.339, Test accuracy: 56.80 

        train local model (freeze embeding):client   3,  Train loss: 0.946, Train accuracy: 62.600, Test loss: 1.105, Test accuracy: 54.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.711, Train accuracy: 72.600, Test loss: 1.036, Test accuracy: 59.80 

Round   3, Train loss: 0.814, Test loss: 1.309, Test accuracy: 56.35 

        train local model (freeze embeding):client   0,  Train loss: 0.781, Train accuracy: 66.000, Test loss: 1.440, Test accuracy: 48.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.192, Train accuracy: 93.800, Test loss: 1.930, Test accuracy: 53.80 

        train local model (freeze embeding):client   1,  Train loss: 0.929, Train accuracy: 64.000, Test loss: 1.525, Test accuracy: 51.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.213, Train accuracy: 93.200, Test loss: 1.422, Test accuracy: 57.60 

        train local model (freeze embeding):client   2,  Train loss: 0.750, Train accuracy: 70.200, Test loss: 1.281, Test accuracy: 53.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.263, Train accuracy: 91.600, Test loss: 1.338, Test accuracy: 58.00 

        train local model (freeze embeding):client   3,  Train loss: 1.039, Train accuracy: 55.200, Test loss: 1.232, Test accuracy: 48.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.692, Train accuracy: 74.400, Test loss: 1.118, Test accuracy: 58.40 

Round   4, Train loss: 0.811, Test loss: 1.305, Test accuracy: 57.30 

        train local model (freeze embeding):client   0,  Train loss: 0.752, Train accuracy: 73.200, Test loss: 1.449, Test accuracy: 47.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.295, Train accuracy: 89.400, Test loss: 2.031, Test accuracy: 50.00 

        train local model (freeze embeding):client   1,  Train loss: 0.842, Train accuracy: 65.800, Test loss: 1.370, Test accuracy: 52.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.191, Train accuracy: 94.000, Test loss: 1.510, Test accuracy: 59.60 

        train local model (freeze embeding):client   2,  Train loss: 0.876, Train accuracy: 65.800, Test loss: 1.428, Test accuracy: 48.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.331, Train accuracy: 87.800, Test loss: 1.481, Test accuracy: 57.20 

        train local model (freeze embeding):client   3,  Train loss: 0.998, Train accuracy: 58.800, Test loss: 1.144, Test accuracy: 54.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.568, Train accuracy: 78.600, Test loss: 0.984, Test accuracy: 61.00 

Round   5, Train loss: 0.814, Test loss: 1.312, Test accuracy: 56.10 

        train local model (freeze embeding):client   0,  Train loss: 0.954, Train accuracy: 60.600, Test loss: 1.680, Test accuracy: 44.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.236, Train accuracy: 91.400, Test loss: 1.917, Test accuracy: 49.60 

        train local model (freeze embeding):client   1,  Train loss: 0.745, Train accuracy: 69.800, Test loss: 1.322, Test accuracy: 53.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.241, Train accuracy: 91.600, Test loss: 1.530, Test accuracy: 58.40 

        train local model (freeze embeding):client   2,  Train loss: 0.691, Train accuracy: 72.400, Test loss: 1.328, Test accuracy: 50.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.353, Train accuracy: 86.800, Test loss: 1.420, Test accuracy: 58.00 

        train local model (freeze embeding):client   3,  Train loss: 1.023, Train accuracy: 57.200, Test loss: 1.160, Test accuracy: 54.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.801, Train accuracy: 70.200, Test loss: 1.282, Test accuracy: 56.40 

Round   6, Train loss: 0.802, Test loss: 1.327, Test accuracy: 55.70 

        train local model (freeze embeding):client   0,  Train loss: 1.094, Train accuracy: 54.600, Test loss: 1.695, Test accuracy: 42.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.252, Train accuracy: 91.200, Test loss: 1.930, Test accuracy: 52.00 

        train local model (freeze embeding):client   1,  Train loss: 0.751, Train accuracy: 71.600, Test loss: 1.341, Test accuracy: 52.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.186, Train accuracy: 94.000, Test loss: 1.467, Test accuracy: 58.40 

        train local model (freeze embeding):client   2,  Train loss: 0.828, Train accuracy: 65.600, Test loss: 1.439, Test accuracy: 49.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.326, Train accuracy: 87.000, Test loss: 1.452, Test accuracy: 57.40 

        train local model (freeze embeding):client   3,  Train loss: 0.854, Train accuracy: 67.400, Test loss: 1.064, Test accuracy: 57.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.625, Train accuracy: 75.800, Test loss: 1.062, Test accuracy: 59.20 

Round   7, Train loss: 0.805, Test loss: 1.350, Test accuracy: 56.35 

        train local model (freeze embeding):client   0,  Train loss: 0.848, Train accuracy: 63.200, Test loss: 1.414, Test accuracy: 47.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.262, Train accuracy: 91.200, Test loss: 1.960, Test accuracy: 48.40 

        train local model (freeze embeding):client   1,  Train loss: 0.927, Train accuracy: 58.000, Test loss: 1.442, Test accuracy: 43.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.311, Train accuracy: 88.200, Test loss: 1.664, Test accuracy: 54.00 

        train local model (freeze embeding):client   2,  Train loss: 0.786, Train accuracy: 69.200, Test loss: 1.396, Test accuracy: 47.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.299, Train accuracy: 88.400, Test loss: 1.446, Test accuracy: 54.20 

        train local model (freeze embeding):client   3,  Train loss: 0.969, Train accuracy: 60.600, Test loss: 1.118, Test accuracy: 50.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.705, Train accuracy: 71.400, Test loss: 1.211, Test accuracy: 55.60 

Round   8, Train loss: 0.783, Test loss: 1.344, Test accuracy: 55.85 

        train local model (freeze embeding):client   0,  Train loss: 0.900, Train accuracy: 62.600, Test loss: 1.547, Test accuracy: 43.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.241, Train accuracy: 91.400, Test loss: 1.982, Test accuracy: 50.20 

        train local model (freeze embeding):client   1,  Train loss: 0.756, Train accuracy: 68.400, Test loss: 1.335, Test accuracy: 49.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.281, Train accuracy: 89.200, Test loss: 1.468, Test accuracy: 58.80 

        train local model (freeze embeding):client   2,  Train loss: 0.872, Train accuracy: 64.800, Test loss: 1.483, Test accuracy: 45.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.411, Train accuracy: 84.200, Test loss: 1.441, Test accuracy: 57.00 

        train local model (freeze embeding):client   3,  Train loss: 0.958, Train accuracy: 58.000, Test loss: 1.164, Test accuracy: 48.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.591, Train accuracy: 78.200, Test loss: 1.033, Test accuracy: 60.20 

Round   9, Train loss: 0.794, Test loss: 1.327, Test accuracy: 55.55 

        train local model (freeze embeding):client   0,  Train loss: 0.846, Train accuracy: 65.800, Test loss: 1.455, Test accuracy: 44.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.282, Train accuracy: 90.400, Test loss: 1.920, Test accuracy: 48.40 

        train local model (freeze embeding):client   1,  Train loss: 0.805, Train accuracy: 69.200, Test loss: 1.344, Test accuracy: 51.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.375, Train accuracy: 86.000, Test loss: 1.696, Test accuracy: 52.20 

        train local model (freeze embeding):client   2,  Train loss: 0.815, Train accuracy: 65.400, Test loss: 1.355, Test accuracy: 49.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.285, Train accuracy: 90.200, Test loss: 1.451, Test accuracy: 55.20 

        train local model (freeze embeding):client   3,  Train loss: 0.863, Train accuracy: 65.400, Test loss: 1.075, Test accuracy: 55.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.606, Train accuracy: 75.400, Test loss: 1.132, Test accuracy: 57.40 

Round  10, Train loss: 0.790, Test loss: 1.330, Test accuracy: 55.65 

        train local model (freeze embeding):client   0,  Train loss: 0.796, Train accuracy: 67.800, Test loss: 1.448, Test accuracy: 46.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.344, Train accuracy: 86.600, Test loss: 2.177, Test accuracy: 49.60 

        train local model (freeze embeding):client   1,  Train loss: 0.896, Train accuracy: 65.800, Test loss: 1.355, Test accuracy: 49.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.272, Train accuracy: 89.600, Test loss: 1.578, Test accuracy: 58.20 

        train local model (freeze embeding):client   2,  Train loss: 0.765, Train accuracy: 69.400, Test loss: 1.339, Test accuracy: 48.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.271, Train accuracy: 90.400, Test loss: 1.322, Test accuracy: 58.60 

        train local model (freeze embeding):client   3,  Train loss: 0.923, Train accuracy: 63.200, Test loss: 1.137, Test accuracy: 55.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.574, Train accuracy: 79.000, Test loss: 1.069, Test accuracy: 59.40 

Round  11, Train loss: 0.778, Test loss: 1.323, Test accuracy: 56.50 

        train local model (freeze embeding):client   0,  Train loss: 0.965, Train accuracy: 62.800, Test loss: 1.550, Test accuracy: 45.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.486, Train accuracy: 80.800, Test loss: 2.230, Test accuracy: 46.00 

        train local model (freeze embeding):client   1,  Train loss: 0.791, Train accuracy: 64.400, Test loss: 1.364, Test accuracy: 50.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.258, Train accuracy: 91.000, Test loss: 1.564, Test accuracy: 55.20 

        train local model (freeze embeding):client   2,  Train loss: 0.764, Train accuracy: 69.800, Test loss: 1.388, Test accuracy: 48.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.298, Train accuracy: 89.000, Test loss: 1.442, Test accuracy: 58.60 

        train local model (freeze embeding):client   3,  Train loss: 0.892, Train accuracy: 62.000, Test loss: 1.116, Test accuracy: 52.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.471, Train accuracy: 84.200, Test loss: 1.007, Test accuracy: 61.40 

Round  12, Train loss: 0.791, Test loss: 1.373, Test accuracy: 57.10 

        train local model (freeze embeding):client   0,  Train loss: 0.826, Train accuracy: 65.000, Test loss: 1.451, Test accuracy: 47.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.274, Train accuracy: 91.400, Test loss: 1.913, Test accuracy: 51.60 

        train local model (freeze embeding):client   1,  Train loss: 0.891, Train accuracy: 64.400, Test loss: 1.436, Test accuracy: 50.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.265, Train accuracy: 89.600, Test loss: 1.584, Test accuracy: 56.40 

        train local model (freeze embeding):client   2,  Train loss: 0.920, Train accuracy: 63.000, Test loss: 1.454, Test accuracy: 48.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.444, Train accuracy: 82.200, Test loss: 1.554, Test accuracy: 55.40 

        train local model (freeze embeding):client   3,  Train loss: 0.964, Train accuracy: 60.400, Test loss: 1.236, Test accuracy: 50.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.547, Train accuracy: 77.400, Test loss: 1.136, Test accuracy: 57.40 

Round  13, Train loss: 0.794, Test loss: 1.340, Test accuracy: 56.35 

        train local model (freeze embeding):client   0,  Train loss: 0.964, Train accuracy: 59.000, Test loss: 1.541, Test accuracy: 44.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.420, Train accuracy: 82.400, Test loss: 2.205, Test accuracy: 46.20 

        train local model (freeze embeding):client   1,  Train loss: 0.858, Train accuracy: 66.800, Test loss: 1.404, Test accuracy: 51.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.238, Train accuracy: 91.400, Test loss: 1.586, Test accuracy: 58.80 

        train local model (freeze embeding):client   2,  Train loss: 0.695, Train accuracy: 72.000, Test loss: 1.362, Test accuracy: 47.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.511, Train accuracy: 80.400, Test loss: 1.628, Test accuracy: 56.00 

        train local model (freeze embeding):client   3,  Train loss: 0.874, Train accuracy: 63.600, Test loss: 1.139, Test accuracy: 49.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.590, Train accuracy: 77.000, Test loss: 1.227, Test accuracy: 55.40 

Round  14, Train loss: 0.778, Test loss: 1.370, Test accuracy: 55.95 

        train local model (freeze embeding):client   0,  Train loss: 0.771, Train accuracy: 70.800, Test loss: 1.426, Test accuracy: 47.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.248, Train accuracy: 91.600, Test loss: 1.897, Test accuracy: 50.80 

        train local model (freeze embeding):client   1,  Train loss: 0.806, Train accuracy: 69.400, Test loss: 1.369, Test accuracy: 49.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.361, Train accuracy: 85.800, Test loss: 1.690, Test accuracy: 56.20 

        train local model (freeze embeding):client   2,  Train loss: 0.840, Train accuracy: 64.400, Test loss: 1.501, Test accuracy: 48.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.310, Train accuracy: 88.600, Test loss: 1.371, Test accuracy: 57.20 

        train local model (freeze embeding):client   3,  Train loss: 0.899, Train accuracy: 64.000, Test loss: 1.145, Test accuracy: 55.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.532, Train accuracy: 78.200, Test loss: 1.148, Test accuracy: 59.20 

Round  15, Train loss: 0.778, Test loss: 1.360, Test accuracy: 55.80 

        train local model (freeze embeding):client   0,  Train loss: 0.926, Train accuracy: 64.400, Test loss: 1.606, Test accuracy: 43.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.275, Train accuracy: 89.600, Test loss: 1.932, Test accuracy: 50.00 

        train local model (freeze embeding):client   1,  Train loss: 0.759, Train accuracy: 70.000, Test loss: 1.422, Test accuracy: 51.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.247, Train accuracy: 91.400, Test loss: 1.637, Test accuracy: 59.00 

        train local model (freeze embeding):client   2,  Train loss: 0.710, Train accuracy: 71.200, Test loss: 1.384, Test accuracy: 49.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.306, Train accuracy: 87.400, Test loss: 1.491, Test accuracy: 58.00 

        train local model (freeze embeding):client   3,  Train loss: 0.902, Train accuracy: 63.800, Test loss: 1.195, Test accuracy: 52.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.469, Train accuracy: 82.800, Test loss: 1.027, Test accuracy: 63.00 

Round  16, Train loss: 0.778, Test loss: 1.370, Test accuracy: 56.30 

        train local model (freeze embeding):client   0,  Train loss: 0.842, Train accuracy: 66.400, Test loss: 1.526, Test accuracy: 48.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.218, Train accuracy: 92.000, Test loss: 2.098, Test accuracy: 49.60 

        train local model (freeze embeding):client   1,  Train loss: 0.898, Train accuracy: 65.000, Test loss: 1.460, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.252, Train accuracy: 90.800, Test loss: 1.480, Test accuracy: 56.40 

        train local model (freeze embeding):client   2,  Train loss: 0.788, Train accuracy: 69.200, Test loss: 1.381, Test accuracy: 50.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.297, Train accuracy: 89.600, Test loss: 1.449, Test accuracy: 60.00 

        train local model (freeze embeding):client   3,  Train loss: 1.184, Train accuracy: 54.600, Test loss: 1.438, Test accuracy: 47.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.427, Train accuracy: 84.800, Test loss: 1.055, Test accuracy: 60.60 

Round  17, Train loss: 0.769, Test loss: 1.399, Test accuracy: 54.75 

        train local model (freeze embeding):client   0,  Train loss: 1.100, Train accuracy: 59.600, Test loss: 1.849, Test accuracy: 43.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.213, Train accuracy: 93.400, Test loss: 1.964, Test accuracy: 49.20 

        train local model (freeze embeding):client   1,  Train loss: 0.794, Train accuracy: 66.800, Test loss: 1.360, Test accuracy: 51.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.204, Train accuracy: 92.800, Test loss: 1.591, Test accuracy: 54.60 

        train local model (freeze embeding):client   2,  Train loss: 1.029, Train accuracy: 59.200, Test loss: 1.652, Test accuracy: 41.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.379, Train accuracy: 84.600, Test loss: 1.638, Test accuracy: 53.40 

        train local model (freeze embeding):client   3,  Train loss: 0.871, Train accuracy: 63.200, Test loss: 1.160, Test accuracy: 54.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.506, Train accuracy: 81.000, Test loss: 1.158, Test accuracy: 59.40 

Round  18, Train loss: 0.766, Test loss: 1.382, Test accuracy: 54.90 

        train local model (freeze embeding):client   0,  Train loss: 0.827, Train accuracy: 64.600, Test loss: 1.531, Test accuracy: 46.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.208, Train accuracy: 92.600, Test loss: 1.896, Test accuracy: 51.40 

        train local model (freeze embeding):client   1,  Train loss: 0.824, Train accuracy: 65.800, Test loss: 1.453, Test accuracy: 51.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.307, Train accuracy: 88.400, Test loss: 1.726, Test accuracy: 53.20 

        train local model (freeze embeding):client   2,  Train loss: 0.701, Train accuracy: 74.600, Test loss: 1.378, Test accuracy: 47.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.244, Train accuracy: 92.200, Test loss: 1.383, Test accuracy: 58.40 

        train local model (freeze embeding):client   3,  Train loss: 0.981, Train accuracy: 58.800, Test loss: 1.252, Test accuracy: 51.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.463, Train accuracy: 83.400, Test loss: 1.072, Test accuracy: 60.60 

Round  19, Train loss: 0.763, Test loss: 1.365, Test accuracy: 55.90 

        train local model (freeze embeding):client   0,  Train loss: 0.881, Train accuracy: 63.800, Test loss: 1.531, Test accuracy: 45.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.304, Train accuracy: 89.800, Test loss: 2.113, Test accuracy: 48.20 

        train local model (freeze embeding):client   1,  Train loss: 0.794, Train accuracy: 67.600, Test loss: 1.457, Test accuracy: 45.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.461, Train accuracy: 80.200, Test loss: 1.980, Test accuracy: 52.80 

        train local model (freeze embeding):client   2,  Train loss: 0.842, Train accuracy: 63.600, Test loss: 1.432, Test accuracy: 45.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.481, Train accuracy: 81.000, Test loss: 1.640, Test accuracy: 57.00 

        train local model (freeze embeding):client   3,  Train loss: 0.877, Train accuracy: 64.000, Test loss: 1.093, Test accuracy: 55.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.454, Train accuracy: 83.000, Test loss: 1.040, Test accuracy: 62.00 

Final Round, Train loss: 0.757, Test loss: 1.368, Test accuracy: 54.95 

---------------------------------------------train_client: [0, 1, 2, 3, 4] 

        init --> train local model(freeze embeding):client   4,  Train loss: 1.012, Train accuracy: 57.200, Test loss: 1.189, Test accuracy: 53.20 

        train local model (freeze embeding):client   0,  Train loss: 0.856, Train accuracy: 65.800, Test loss: 1.502, Test accuracy: 46.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.266, Train accuracy: 90.400, Test loss: 2.020, Test accuracy: 50.00 

        train local model (freeze embeding):client   1,  Train loss: 0.900, Train accuracy: 60.000, Test loss: 1.454, Test accuracy: 47.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.229, Train accuracy: 91.600, Test loss: 1.529, Test accuracy: 57.00 

        train local model (freeze embeding):client   2,  Train loss: 0.869, Train accuracy: 64.000, Test loss: 1.520, Test accuracy: 43.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.530, Train accuracy: 78.000, Test loss: 1.739, Test accuracy: 51.80 

        train local model (freeze embeding):client   3,  Train loss: 0.876, Train accuracy: 64.200, Test loss: 1.160, Test accuracy: 48.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.589, Train accuracy: 79.600, Test loss: 1.349, Test accuracy: 55.00 

        train local model (freeze embeding):client   4,  Train loss: 1.104, Train accuracy: 53.400, Test loss: 1.317, Test accuracy: 49.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.638, Train accuracy: 73.800, Test loss: 1.047, Test accuracy: 61.00 

Round   0, Train loss: 0.814, Test loss: 1.324, Test accuracy: 57.24 

        train local model (freeze embeding):client   0,  Train loss: 0.840, Train accuracy: 65.200, Test loss: 1.483, Test accuracy: 45.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.255, Train accuracy: 91.200, Test loss: 2.029, Test accuracy: 49.20 

        train local model (freeze embeding):client   1,  Train loss: 1.018, Train accuracy: 58.200, Test loss: 1.560, Test accuracy: 47.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.288, Train accuracy: 88.400, Test loss: 1.695, Test accuracy: 58.20 

        train local model (freeze embeding):client   2,  Train loss: 0.856, Train accuracy: 65.000, Test loss: 1.448, Test accuracy: 47.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.386, Train accuracy: 85.400, Test loss: 1.598, Test accuracy: 54.40 

        train local model (freeze embeding):client   3,  Train loss: 0.920, Train accuracy: 63.600, Test loss: 1.194, Test accuracy: 54.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.462, Train accuracy: 81.600, Test loss: 1.145, Test accuracy: 59.80 

        train local model (freeze embeding):client   4,  Train loss: 0.947, Train accuracy: 59.000, Test loss: 1.196, Test accuracy: 54.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.615, Train accuracy: 74.800, Test loss: 1.027, Test accuracy: 62.40 

Round   1, Train loss: 0.802, Test loss: 1.306, Test accuracy: 57.00 

        train local model (freeze embeding):client   0,  Train loss: 0.928, Train accuracy: 61.600, Test loss: 1.446, Test accuracy: 46.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.278, Train accuracy: 91.200, Test loss: 1.833, Test accuracy: 50.00 

        train local model (freeze embeding):client   1,  Train loss: 0.901, Train accuracy: 64.600, Test loss: 1.551, Test accuracy: 45.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.317, Train accuracy: 87.000, Test loss: 1.746, Test accuracy: 53.20 

        train local model (freeze embeding):client   2,  Train loss: 0.812, Train accuracy: 66.400, Test loss: 1.378, Test accuracy: 49.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.392, Train accuracy: 86.000, Test loss: 1.664, Test accuracy: 50.60 

        train local model (freeze embeding):client   3,  Train loss: 0.915, Train accuracy: 63.000, Test loss: 1.190, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.413, Train accuracy: 86.400, Test loss: 1.054, Test accuracy: 63.60 

        train local model (freeze embeding):client   4,  Train loss: 0.926, Train accuracy: 63.000, Test loss: 1.199, Test accuracy: 52.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.718, Train accuracy: 74.000, Test loss: 1.187, Test accuracy: 57.40 

Round   2, Train loss: 0.815, Test loss: 1.293, Test accuracy: 58.12 

        train local model (freeze embeding):client   0,  Train loss: 0.835, Train accuracy: 66.800, Test loss: 1.476, Test accuracy: 44.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.316, Train accuracy: 88.200, Test loss: 1.913, Test accuracy: 50.00 

        train local model (freeze embeding):client   1,  Train loss: 0.776, Train accuracy: 69.400, Test loss: 1.342, Test accuracy: 50.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.246, Train accuracy: 91.000, Test loss: 1.600, Test accuracy: 58.20 

        train local model (freeze embeding):client   2,  Train loss: 0.986, Train accuracy: 59.600, Test loss: 1.614, Test accuracy: 43.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.270, Train accuracy: 89.800, Test loss: 1.424, Test accuracy: 56.20 

        train local model (freeze embeding):client   3,  Train loss: 0.921, Train accuracy: 62.600, Test loss: 1.187, Test accuracy: 52.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.445, Train accuracy: 83.000, Test loss: 1.115, Test accuracy: 61.80 

        train local model (freeze embeding):client   4,  Train loss: 1.154, Train accuracy: 55.200, Test loss: 1.404, Test accuracy: 52.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.573, Train accuracy: 77.000, Test loss: 1.099, Test accuracy: 59.80 

Round   3, Train loss: 0.807, Test loss: 1.318, Test accuracy: 56.84 

        train local model (freeze embeding):client   0,  Train loss: 0.876, Train accuracy: 63.000, Test loss: 1.437, Test accuracy: 44.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.248, Train accuracy: 92.000, Test loss: 2.025, Test accuracy: 49.60 

        train local model (freeze embeding):client   1,  Train loss: 0.760, Train accuracy: 68.200, Test loss: 1.316, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.278, Train accuracy: 89.400, Test loss: 1.675, Test accuracy: 54.00 

        train local model (freeze embeding):client   2,  Train loss: 0.798, Train accuracy: 67.400, Test loss: 1.406, Test accuracy: 48.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.250, Train accuracy: 90.800, Test loss: 1.457, Test accuracy: 56.20 

        train local model (freeze embeding):client   3,  Train loss: 0.924, Train accuracy: 62.800, Test loss: 1.192, Test accuracy: 52.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.404, Train accuracy: 86.800, Test loss: 1.134, Test accuracy: 58.00 

        train local model (freeze embeding):client   4,  Train loss: 1.143, Train accuracy: 53.800, Test loss: 1.417, Test accuracy: 47.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.630, Train accuracy: 74.600, Test loss: 1.195, Test accuracy: 59.00 

Round   4, Train loss: 0.788, Test loss: 1.301, Test accuracy: 57.52 

        train local model (freeze embeding):client   0,  Train loss: 0.891, Train accuracy: 65.200, Test loss: 1.550, Test accuracy: 45.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.231, Train accuracy: 91.800, Test loss: 1.955, Test accuracy: 49.80 

        train local model (freeze embeding):client   1,  Train loss: 0.804, Train accuracy: 68.200, Test loss: 1.379, Test accuracy: 52.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.187, Train accuracy: 94.800, Test loss: 1.622, Test accuracy: 57.40 

        train local model (freeze embeding):client   2,  Train loss: 0.764, Train accuracy: 69.600, Test loss: 1.395, Test accuracy: 47.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.310, Train accuracy: 87.000, Test loss: 1.579, Test accuracy: 56.60 

        train local model (freeze embeding):client   3,  Train loss: 0.962, Train accuracy: 57.200, Test loss: 1.226, Test accuracy: 50.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.487, Train accuracy: 80.200, Test loss: 1.198, Test accuracy: 59.80 

        train local model (freeze embeding):client   4,  Train loss: 1.429, Train accuracy: 42.600, Test loss: 1.710, Test accuracy: 38.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.613, Train accuracy: 74.400, Test loss: 1.204, Test accuracy: 61.80 

Round   5, Train loss: 0.809, Test loss: 1.322, Test accuracy: 57.80 

        train local model (freeze embeding):client   0,  Train loss: 0.918, Train accuracy: 61.400, Test loss: 1.506, Test accuracy: 44.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.239, Train accuracy: 94.000, Test loss: 2.051, Test accuracy: 48.80 

        train local model (freeze embeding):client   1,  Train loss: 0.860, Train accuracy: 65.000, Test loss: 1.401, Test accuracy: 49.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.206, Train accuracy: 93.200, Test loss: 1.527, Test accuracy: 58.00 

        train local model (freeze embeding):client   2,  Train loss: 0.831, Train accuracy: 65.400, Test loss: 1.436, Test accuracy: 48.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.376, Train accuracy: 86.600, Test loss: 1.687, Test accuracy: 50.80 

        train local model (freeze embeding):client   3,  Train loss: 0.889, Train accuracy: 61.800, Test loss: 1.138, Test accuracy: 52.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.387, Train accuracy: 86.200, Test loss: 1.134, Test accuracy: 61.00 

        train local model (freeze embeding):client   4,  Train loss: 0.935, Train accuracy: 61.600, Test loss: 1.225, Test accuracy: 53.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.594, Train accuracy: 80.200, Test loss: 1.103, Test accuracy: 61.20 

Round   6, Train loss: 0.818, Test loss: 1.342, Test accuracy: 56.96 

        train local model (freeze embeding):client   0,  Train loss: 0.889, Train accuracy: 60.800, Test loss: 1.547, Test accuracy: 43.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.298, Train accuracy: 89.800, Test loss: 2.199, Test accuracy: 49.40 

        train local model (freeze embeding):client   1,  Train loss: 0.796, Train accuracy: 69.000, Test loss: 1.381, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.249, Train accuracy: 90.200, Test loss: 1.609, Test accuracy: 57.40 

        train local model (freeze embeding):client   2,  Train loss: 0.774, Train accuracy: 69.200, Test loss: 1.376, Test accuracy: 51.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.254, Train accuracy: 91.200, Test loss: 1.456, Test accuracy: 56.20 

        train local model (freeze embeding):client   3,  Train loss: 0.941, Train accuracy: 60.800, Test loss: 1.232, Test accuracy: 54.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.512, Train accuracy: 79.000, Test loss: 1.245, Test accuracy: 60.60 

        train local model (freeze embeding):client   4,  Train loss: 0.886, Train accuracy: 64.800, Test loss: 1.209, Test accuracy: 54.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.497, Train accuracy: 81.400, Test loss: 1.089, Test accuracy: 60.80 

Round   7, Train loss: 0.818, Test loss: 1.349, Test accuracy: 57.20 

        train local model (freeze embeding):client   0,  Train loss: 0.987, Train accuracy: 60.200, Test loss: 1.651, Test accuracy: 44.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.237, Train accuracy: 93.200, Test loss: 1.991, Test accuracy: 51.40 

        train local model (freeze embeding):client   1,  Train loss: 0.891, Train accuracy: 64.200, Test loss: 1.439, Test accuracy: 49.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.224, Train accuracy: 92.600, Test loss: 1.472, Test accuracy: 59.20 

        train local model (freeze embeding):client   2,  Train loss: 1.205, Train accuracy: 55.800, Test loss: 1.767, Test accuracy: 43.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.532, Train accuracy: 78.200, Test loss: 1.770, Test accuracy: 54.00 

        train local model (freeze embeding):client   3,  Train loss: 0.890, Train accuracy: 63.800, Test loss: 1.180, Test accuracy: 55.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.571, Train accuracy: 76.600, Test loss: 1.354, Test accuracy: 54.80 

        train local model (freeze embeding):client   4,  Train loss: 0.961, Train accuracy: 61.000, Test loss: 1.254, Test accuracy: 50.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.525, Train accuracy: 80.600, Test loss: 1.169, Test accuracy: 60.40 

Round   8, Train loss: 0.818, Test loss: 1.348, Test accuracy: 57.16 

        train local model (freeze embeding):client   0,  Train loss: 1.045, Train accuracy: 56.400, Test loss: 1.602, Test accuracy: 41.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.262, Train accuracy: 90.800, Test loss: 2.015, Test accuracy: 52.80 

        train local model (freeze embeding):client   1,  Train loss: 0.910, Train accuracy: 64.600, Test loss: 1.422, Test accuracy: 49.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.222, Train accuracy: 93.600, Test loss: 1.608, Test accuracy: 56.00 

        train local model (freeze embeding):client   2,  Train loss: 0.793, Train accuracy: 68.200, Test loss: 1.374, Test accuracy: 50.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.295, Train accuracy: 87.800, Test loss: 1.589, Test accuracy: 54.00 

        train local model (freeze embeding):client   3,  Train loss: 0.885, Train accuracy: 61.800, Test loss: 1.176, Test accuracy: 51.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.415, Train accuracy: 85.000, Test loss: 1.151, Test accuracy: 60.60 

        train local model (freeze embeding):client   4,  Train loss: 0.983, Train accuracy: 57.600, Test loss: 1.273, Test accuracy: 50.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.467, Train accuracy: 81.800, Test loss: 1.064, Test accuracy: 62.40 

Round   9, Train loss: 0.811, Test loss: 1.355, Test accuracy: 56.16 

        train local model (freeze embeding):client   0,  Train loss: 0.909, Train accuracy: 61.400, Test loss: 1.499, Test accuracy: 45.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.291, Train accuracy: 90.400, Test loss: 1.909, Test accuracy: 49.00 

        train local model (freeze embeding):client   1,  Train loss: 1.007, Train accuracy: 58.800, Test loss: 1.569, Test accuracy: 48.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.168, Train accuracy: 95.400, Test loss: 1.395, Test accuracy: 60.20 

        train local model (freeze embeding):client   2,  Train loss: 0.840, Train accuracy: 66.000, Test loss: 1.450, Test accuracy: 46.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.246, Train accuracy: 92.800, Test loss: 1.392, Test accuracy: 59.00 

        train local model (freeze embeding):client   3,  Train loss: 1.010, Train accuracy: 60.600, Test loss: 1.314, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.359, Train accuracy: 87.000, Test loss: 1.101, Test accuracy: 63.00 

        train local model (freeze embeding):client   4,  Train loss: 0.887, Train accuracy: 63.200, Test loss: 1.247, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.498, Train accuracy: 81.200, Test loss: 1.167, Test accuracy: 60.00 

Round  10, Train loss: 0.817, Test loss: 1.312, Test accuracy: 57.20 

        train local model (freeze embeding):client   0,  Train loss: 1.050, Train accuracy: 55.600, Test loss: 1.699, Test accuracy: 40.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.357, Train accuracy: 85.800, Test loss: 1.974, Test accuracy: 51.20 

        train local model (freeze embeding):client   1,  Train loss: 0.925, Train accuracy: 64.000, Test loss: 1.466, Test accuracy: 49.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.254, Train accuracy: 93.000, Test loss: 1.560, Test accuracy: 55.00 

        train local model (freeze embeding):client   2,  Train loss: 0.756, Train accuracy: 69.600, Test loss: 1.388, Test accuracy: 50.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.276, Train accuracy: 89.600, Test loss: 1.646, Test accuracy: 55.40 

        train local model (freeze embeding):client   3,  Train loss: 1.016, Train accuracy: 59.800, Test loss: 1.352, Test accuracy: 50.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.350, Train accuracy: 88.600, Test loss: 1.090, Test accuracy: 61.40 

        train local model (freeze embeding):client   4,  Train loss: 0.999, Train accuracy: 58.000, Test loss: 1.381, Test accuracy: 48.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.408, Train accuracy: 86.000, Test loss: 1.103, Test accuracy: 63.20 

Round  11, Train loss: 0.810, Test loss: 1.343, Test accuracy: 56.52 

        train local model (freeze embeding):client   0,  Train loss: 1.143, Train accuracy: 53.000, Test loss: 1.704, Test accuracy: 43.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.288, Train accuracy: 89.200, Test loss: 1.941, Test accuracy: 47.60 

        train local model (freeze embeding):client   1,  Train loss: 0.826, Train accuracy: 67.400, Test loss: 1.397, Test accuracy: 48.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.296, Train accuracy: 88.800, Test loss: 1.649, Test accuracy: 56.20 

        train local model (freeze embeding):client   2,  Train loss: 0.904, Train accuracy: 61.200, Test loss: 1.524, Test accuracy: 45.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.193, Train accuracy: 94.400, Test loss: 1.413, Test accuracy: 59.60 

        train local model (freeze embeding):client   3,  Train loss: 0.878, Train accuracy: 64.400, Test loss: 1.126, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.353, Train accuracy: 86.600, Test loss: 1.154, Test accuracy: 59.80 

        train local model (freeze embeding):client   4,  Train loss: 0.903, Train accuracy: 62.800, Test loss: 1.254, Test accuracy: 53.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.421, Train accuracy: 85.200, Test loss: 1.170, Test accuracy: 59.60 

Round  12, Train loss: 0.805, Test loss: 1.331, Test accuracy: 57.72 

        train local model (freeze embeding):client   0,  Train loss: 0.836, Train accuracy: 63.800, Test loss: 1.473, Test accuracy: 43.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.386, Train accuracy: 87.200, Test loss: 1.919, Test accuracy: 48.40 

        train local model (freeze embeding):client   1,  Train loss: 0.805, Train accuracy: 68.600, Test loss: 1.345, Test accuracy: 50.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.206, Train accuracy: 93.200, Test loss: 1.537, Test accuracy: 58.80 

        train local model (freeze embeding):client   2,  Train loss: 0.811, Train accuracy: 64.000, Test loss: 1.442, Test accuracy: 46.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.308, Train accuracy: 86.000, Test loss: 1.507, Test accuracy: 57.80 

        train local model (freeze embeding):client   3,  Train loss: 0.972, Train accuracy: 59.800, Test loss: 1.268, Test accuracy: 50.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.357, Train accuracy: 88.800, Test loss: 1.092, Test accuracy: 63.40 

        train local model (freeze embeding):client   4,  Train loss: 0.967, Train accuracy: 61.000, Test loss: 1.336, Test accuracy: 49.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.392, Train accuracy: 85.400, Test loss: 1.173, Test accuracy: 61.00 

Round  13, Train loss: 0.804, Test loss: 1.353, Test accuracy: 56.76 

        train local model (freeze embeding):client   0,  Train loss: 0.906, Train accuracy: 63.400, Test loss: 1.572, Test accuracy: 46.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.219, Train accuracy: 92.600, Test loss: 1.822, Test accuracy: 51.80 

        train local model (freeze embeding):client   1,  Train loss: 0.911, Train accuracy: 65.200, Test loss: 1.441, Test accuracy: 50.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.283, Train accuracy: 90.400, Test loss: 1.459, Test accuracy: 58.60 

        train local model (freeze embeding):client   2,  Train loss: 0.827, Train accuracy: 65.800, Test loss: 1.457, Test accuracy: 45.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.310, Train accuracy: 89.600, Test loss: 1.517, Test accuracy: 56.40 

        train local model (freeze embeding):client   3,  Train loss: 0.861, Train accuracy: 63.200, Test loss: 1.204, Test accuracy: 52.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.459, Train accuracy: 82.200, Test loss: 1.326, Test accuracy: 57.40 

        train local model (freeze embeding):client   4,  Train loss: 0.868, Train accuracy: 65.800, Test loss: 1.261, Test accuracy: 54.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.652, Train accuracy: 72.800, Test loss: 1.408, Test accuracy: 59.00 

Round  14, Train loss: 0.796, Test loss: 1.414, Test accuracy: 56.12 

        train local model (freeze embeding):client   0,  Train loss: 0.788, Train accuracy: 68.600, Test loss: 1.491, Test accuracy: 45.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.366, Train accuracy: 86.600, Test loss: 2.050, Test accuracy: 49.00 

        train local model (freeze embeding):client   1,  Train loss: 0.855, Train accuracy: 63.800, Test loss: 1.382, Test accuracy: 51.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.234, Train accuracy: 91.600, Test loss: 1.611, Test accuracy: 55.80 

        train local model (freeze embeding):client   2,  Train loss: 0.887, Train accuracy: 63.800, Test loss: 1.568, Test accuracy: 44.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.259, Train accuracy: 90.800, Test loss: 1.420, Test accuracy: 57.80 

        train local model (freeze embeding):client   3,  Train loss: 0.875, Train accuracy: 64.800, Test loss: 1.146, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.478, Train accuracy: 81.600, Test loss: 1.244, Test accuracy: 58.40 

        train local model (freeze embeding):client   4,  Train loss: 1.003, Train accuracy: 56.200, Test loss: 1.389, Test accuracy: 46.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.394, Train accuracy: 85.600, Test loss: 1.153, Test accuracy: 61.60 

Round  15, Train loss: 0.798, Test loss: 1.373, Test accuracy: 56.92 

        train local model (freeze embeding):client   0,  Train loss: 0.861, Train accuracy: 62.600, Test loss: 1.538, Test accuracy: 44.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.246, Train accuracy: 92.600, Test loss: 1.929, Test accuracy: 50.00 

        train local model (freeze embeding):client   1,  Train loss: 0.887, Train accuracy: 61.400, Test loss: 1.413, Test accuracy: 46.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.353, Train accuracy: 85.600, Test loss: 1.659, Test accuracy: 57.20 

        train local model (freeze embeding):client   2,  Train loss: 1.026, Train accuracy: 60.000, Test loss: 1.627, Test accuracy: 45.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.299, Train accuracy: 88.800, Test loss: 1.469, Test accuracy: 56.20 

        train local model (freeze embeding):client   3,  Train loss: 0.884, Train accuracy: 64.800, Test loss: 1.219, Test accuracy: 54.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.382, Train accuracy: 84.200, Test loss: 1.140, Test accuracy: 58.80 

        train local model (freeze embeding):client   4,  Train loss: 0.870, Train accuracy: 64.400, Test loss: 1.295, Test accuracy: 51.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.423, Train accuracy: 83.000, Test loss: 1.205, Test accuracy: 60.40 

Round  16, Train loss: 0.795, Test loss: 1.349, Test accuracy: 57.48 

        train local model (freeze embeding):client   0,  Train loss: 0.786, Train accuracy: 66.800, Test loss: 1.430, Test accuracy: 44.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.371, Train accuracy: 83.600, Test loss: 2.023, Test accuracy: 48.20 

        train local model (freeze embeding):client   1,  Train loss: 0.821, Train accuracy: 67.400, Test loss: 1.422, Test accuracy: 50.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.217, Train accuracy: 92.800, Test loss: 1.541, Test accuracy: 57.80 

        train local model (freeze embeding):client   2,  Train loss: 0.802, Train accuracy: 65.000, Test loss: 1.448, Test accuracy: 47.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.403, Train accuracy: 85.000, Test loss: 1.661, Test accuracy: 55.40 

        train local model (freeze embeding):client   3,  Train loss: 0.875, Train accuracy: 65.600, Test loss: 1.186, Test accuracy: 53.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.382, Train accuracy: 86.600, Test loss: 1.126, Test accuracy: 58.20 

        train local model (freeze embeding):client   4,  Train loss: 0.972, Train accuracy: 56.600, Test loss: 1.337, Test accuracy: 46.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.423, Train accuracy: 85.200, Test loss: 1.170, Test accuracy: 64.40 

Round  17, Train loss: 0.789, Test loss: 1.374, Test accuracy: 56.24 

        train local model (freeze embeding):client   0,  Train loss: 1.033, Train accuracy: 57.000, Test loss: 1.662, Test accuracy: 40.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.327, Train accuracy: 87.800, Test loss: 1.972, Test accuracy: 47.20 

        train local model (freeze embeding):client   1,  Train loss: 0.759, Train accuracy: 69.200, Test loss: 1.342, Test accuracy: 49.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.209, Train accuracy: 94.600, Test loss: 1.517, Test accuracy: 58.80 

        train local model (freeze embeding):client   2,  Train loss: 0.845, Train accuracy: 65.600, Test loss: 1.569, Test accuracy: 44.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.212, Train accuracy: 91.600, Test loss: 1.475, Test accuracy: 58.20 

        train local model (freeze embeding):client   3,  Train loss: 0.832, Train accuracy: 65.600, Test loss: 1.137, Test accuracy: 55.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.442, Train accuracy: 83.200, Test loss: 1.179, Test accuracy: 60.60 

        train local model (freeze embeding):client   4,  Train loss: 0.867, Train accuracy: 64.800, Test loss: 1.248, Test accuracy: 53.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.433, Train accuracy: 83.400, Test loss: 1.218, Test accuracy: 60.80 

Round  18, Train loss: 0.777, Test loss: 1.334, Test accuracy: 57.52 

        train local model (freeze embeding):client   0,  Train loss: 0.765, Train accuracy: 70.400, Test loss: 1.471, Test accuracy: 47.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.306, Train accuracy: 89.200, Test loss: 1.869, Test accuracy: 51.20 

        train local model (freeze embeding):client   1,  Train loss: 0.818, Train accuracy: 66.200, Test loss: 1.385, Test accuracy: 50.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.345, Train accuracy: 85.000, Test loss: 1.921, Test accuracy: 54.40 

        train local model (freeze embeding):client   2,  Train loss: 0.727, Train accuracy: 72.200, Test loss: 1.391, Test accuracy: 48.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.249, Train accuracy: 90.600, Test loss: 1.501, Test accuracy: 58.20 

        train local model (freeze embeding):client   3,  Train loss: 0.832, Train accuracy: 65.000, Test loss: 1.144, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.699, Train accuracy: 70.800, Test loss: 1.437, Test accuracy: 54.40 

        train local model (freeze embeding):client   4,  Train loss: 0.921, Train accuracy: 59.400, Test loss: 1.281, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.506, Train accuracy: 79.200, Test loss: 1.312, Test accuracy: 56.40 

Round  19, Train loss: 0.769, Test loss: 1.357, Test accuracy: 57.12 

        train local model (freeze embeding):client   0,  Train loss: 1.017, Train accuracy: 60.800, Test loss: 1.553, Test accuracy: 43.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.312, Train accuracy: 88.000, Test loss: 1.853, Test accuracy: 51.40 

        train local model (freeze embeding):client   1,  Train loss: 0.778, Train accuracy: 70.200, Test loss: 1.422, Test accuracy: 47.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.324, Train accuracy: 87.400, Test loss: 1.536, Test accuracy: 56.00 

        train local model (freeze embeding):client   2,  Train loss: 0.863, Train accuracy: 65.600, Test loss: 1.526, Test accuracy: 45.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.398, Train accuracy: 82.800, Test loss: 1.614, Test accuracy: 54.80 

        train local model (freeze embeding):client   3,  Train loss: 0.816, Train accuracy: 67.200, Test loss: 1.127, Test accuracy: 53.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.539, Train accuracy: 79.400, Test loss: 1.334, Test accuracy: 54.80 

        train local model (freeze embeding):client   4,  Train loss: 0.860, Train accuracy: 64.600, Test loss: 1.279, Test accuracy: 52.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.361, Train accuracy: 86.400, Test loss: 1.187, Test accuracy: 59.80 

Final Round, Train loss: 0.771, Test loss: 1.361, Test accuracy: 56.92 

Average accuracy final 10 rounds: 275.9566666666667 

3648.9449310302734
[11.287522077560425, 23.644033432006836, 35.882189989089966, 47.47274446487427, 58.007895946502686, 68.77616381645203, 79.48939371109009, 90.007817029953, 100.80755043029785, 112.06848788261414, 124.28957891464233, 135.75257778167725, 147.5143883228302, 158.97376370429993, 169.9065134525299, 181.99406123161316, 194.84227180480957, 206.5924837589264, 218.1252145767212, 229.4049367904663, 240.4470624923706, 250.6143274307251, 260.62577295303345, 270.76935052871704, 280.84923243522644, 290.78501200675964, 301.22703218460083, 313.2232186794281, 324.15801668167114, 334.4649519920349, 344.7596244812012, 354.9938917160034, 365.0442898273468, 375.2503204345703, 386.43886256217957, 398.4097340106964, 409.95773434638977, 421.02476024627686, 432.0401108264923, 442.886935710907, 454.72717809677124, 467.1347756385803, 479.93994665145874, 491.32986855506897, 504.13146901130676, 516.8620126247406, 528.9352011680603, 539.1302185058594, 549.8925268650055, 561.7544543743134, 572.3499810695648, 582.8387596607208, 593.7537388801575, 604.6032421588898, 616.6702332496643, 628.7899303436279, 640.1621098518372, 652.312224149704, 664.7163002490997, 676.3008165359497, 688.8780834674835, 700.4816038608551, 712.7569875717163, 725.1185922622681, 735.4348847866058, 745.8527569770813, 756.4303247928619, 766.7321193218231, 776.9932069778442, 787.2960751056671, 798.5279307365417, 811.6047925949097, 822.4517471790314, 834.3955883979797, 846.3822436332703, 858.2587289810181, 869.7473888397217, 880.7037289142609, 890.8107883930206, 901.4332187175751, 912.20818567276, 922.6365785598755, 934.415717124939, 945.4354434013367, 957.1872165203094, 969.2916443347931, 981.0329248905182, 992.4601397514343, 1004.131044626236, 1015.9213380813599, 1026.9818089008331, 1037.0953125953674, 1047.5414974689484, 1057.668517112732, 1068.30411028862, 1078.8164281845093, 1090.8067374229431, 1102.1083374023438, 1113.6646494865417, 1125.793713569641, 1137.3396515846252, 1148.6404864788055, 1158.7852523326874, 1169.6150319576263, 1179.75918841362]
[46.2, 47.8, 51.8, 49.6, 54.0, 52.0, 49.8, 55.6, 52.2, 52.0, 50.6, 53.2, 54.0, 49.2, 52.6, 54.0, 52.6, 54.6, 51.0, 51.8, 51.0, 57.1, 57.0, 57.4, 58.2, 56.6, 57.3, 55.7, 52.9, 55.9, 58.0, 54.9, 56.6, 56.9, 54.8, 55.8, 55.5, 56.1, 54.9, 55.3, 54.3, 54.5, 56.333333333333336, 54.53333333333333, 55.8, 54.93333333333333, 54.2, 56.333333333333336, 56.53333333333333, 55.733333333333334, 56.06666666666667, 55.06666666666667, 55.06666666666667, 53.733333333333334, 55.333333333333336, 54.13333333333333, 55.0, 55.46666666666667, 55.86666666666667, 56.46666666666667, 56.2, 54.8, 54.6, 58.15, 56.4, 56.2, 56.35, 57.3, 56.1, 55.7, 56.35, 55.85, 55.55, 55.65, 56.5, 57.1, 56.35, 55.95, 55.8, 56.3, 54.75, 54.9, 55.9, 54.95, 57.24, 57.0, 58.12, 56.84, 57.52, 57.8, 56.96, 57.2, 57.16, 56.16, 57.2, 56.52, 57.72, 56.76, 56.12, 56.92, 57.48, 56.24, 57.52, 57.12, 56.92]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.439, Test loss: 1.413, Test accuracy: 46.28 

Round   0, Global train loss: 1.439, Global test loss: 2.591, Global test accuracy: 20.00 

Round   1, Train loss: 1.128, Test loss: 1.190, Test accuracy: 55.48 

Round   1, Global train loss: 1.128, Global test loss: 2.455, Global test accuracy: 20.00 

Round   2, Train loss: 0.983, Test loss: 1.176, Test accuracy: 56.28 

Round   2, Global train loss: 0.983, Global test loss: 2.452, Global test accuracy: 20.00 

Round   3, Train loss: 0.873, Test loss: 1.394, Test accuracy: 55.96 

Round   3, Global train loss: 0.873, Global test loss: 2.576, Global test accuracy: 20.00 

Round   4, Train loss: 0.750, Test loss: 1.273, Test accuracy: 59.32 

Round   4, Global train loss: 0.750, Global test loss: 2.439, Global test accuracy: 20.00 

Round   5, Train loss: 0.654, Test loss: 1.389, Test accuracy: 57.32 

Round   5, Global train loss: 0.654, Global test loss: 2.451, Global test accuracy: 20.00 

Round   6, Train loss: 0.558, Test loss: 1.504, Test accuracy: 59.08 

Round   6, Global train loss: 0.558, Global test loss: 2.466, Global test accuracy: 20.00 

Round   7, Train loss: 0.479, Test loss: 1.476, Test accuracy: 60.00 

Round   7, Global train loss: 0.479, Global test loss: 2.413, Global test accuracy: 20.20 

Round   8, Train loss: 0.417, Test loss: 1.674, Test accuracy: 57.12 

Round   8, Global train loss: 0.417, Global test loss: 2.430, Global test accuracy: 22.92 

Round   9, Train loss: 0.332, Test loss: 1.614, Test accuracy: 58.68 

Round   9, Global train loss: 0.332, Global test loss: 2.399, Global test accuracy: 20.56 

Round  10, Train loss: 0.295, Test loss: 1.623, Test accuracy: 60.40 

Round  10, Global train loss: 0.295, Global test loss: 2.449, Global test accuracy: 22.12 

Round  11, Train loss: 0.256, Test loss: 1.649, Test accuracy: 61.84 

Round  11, Global train loss: 0.256, Global test loss: 2.439, Global test accuracy: 19.00 

Round  12, Train loss: 0.214, Test loss: 1.638, Test accuracy: 62.48 

Round  12, Global train loss: 0.214, Global test loss: 2.434, Global test accuracy: 20.00 

Round  13, Train loss: 0.188, Test loss: 1.939, Test accuracy: 62.80 

Round  13, Global train loss: 0.188, Global test loss: 2.401, Global test accuracy: 22.76 

Round  14, Train loss: 0.155, Test loss: 1.835, Test accuracy: 63.04 

Round  14, Global train loss: 0.155, Global test loss: 2.374, Global test accuracy: 22.24 

Round  15, Train loss: 0.122, Test loss: 1.902, Test accuracy: 63.08 

Round  15, Global train loss: 0.122, Global test loss: 2.475, Global test accuracy: 13.88 

Round  16, Train loss: 0.138, Test loss: 1.989, Test accuracy: 62.24 

Round  16, Global train loss: 0.138, Global test loss: 2.405, Global test accuracy: 22.76 

Round  17, Train loss: 0.093, Test loss: 1.764, Test accuracy: 64.80 

Round  17, Global train loss: 0.093, Global test loss: 2.441, Global test accuracy: 20.52 

Round  18, Train loss: 0.098, Test loss: 1.882, Test accuracy: 62.80 

Round  18, Global train loss: 0.098, Global test loss: 2.401, Global test accuracy: 22.64 

Round  19, Train loss: 0.088, Test loss: 1.990, Test accuracy: 63.68 

Round  19, Global train loss: 0.088, Global test loss: 2.471, Global test accuracy: 13.88 

Round  20, Train loss: 0.063, Test loss: 1.886, Test accuracy: 64.72 

Round  20, Global train loss: 0.063, Global test loss: 2.388, Global test accuracy: 17.20 

Round  21, Train loss: 0.079, Test loss: 1.904, Test accuracy: 63.24 

Round  21, Global train loss: 0.079, Global test loss: 2.418, Global test accuracy: 20.88 

Round  22, Train loss: 0.067, Test loss: 1.862, Test accuracy: 65.40 

Round  22, Global train loss: 0.067, Global test loss: 2.437, Global test accuracy: 14.80 

Round  23, Train loss: 0.059, Test loss: 1.846, Test accuracy: 65.60 

Round  23, Global train loss: 0.059, Global test loss: 2.428, Global test accuracy: 22.92 

Round  24, Train loss: 0.047, Test loss: 1.896, Test accuracy: 65.16 

Round  24, Global train loss: 0.047, Global test loss: 2.427, Global test accuracy: 20.68 

Round  25, Train loss: 0.059, Test loss: 2.058, Test accuracy: 65.12 

Round  25, Global train loss: 0.059, Global test loss: 2.404, Global test accuracy: 16.04 

Round  26, Train loss: 0.047, Test loss: 1.811, Test accuracy: 66.76 

Round  26, Global train loss: 0.047, Global test loss: 2.405, Global test accuracy: 13.88 

Round  27, Train loss: 0.041, Test loss: 2.033, Test accuracy: 63.80 

Round  27, Global train loss: 0.041, Global test loss: 2.413, Global test accuracy: 13.48 

Round  28, Train loss: 0.043, Test loss: 2.100, Test accuracy: 65.08 

Round  28, Global train loss: 0.043, Global test loss: 2.438, Global test accuracy: 15.04 

Round  29, Train loss: 0.052, Test loss: 1.933, Test accuracy: 65.56 

Round  29, Global train loss: 0.052, Global test loss: 2.401, Global test accuracy: 22.16 

Round  30, Train loss: 0.026, Test loss: 1.819, Test accuracy: 67.72 

Round  30, Global train loss: 0.026, Global test loss: 2.391, Global test accuracy: 23.00 

Round  31, Train loss: 0.025, Test loss: 1.881, Test accuracy: 66.40 

Round  31, Global train loss: 0.025, Global test loss: 2.451, Global test accuracy: 17.68 

Round  32, Train loss: 0.025, Test loss: 1.841, Test accuracy: 66.88 

Round  32, Global train loss: 0.025, Global test loss: 2.381, Global test accuracy: 22.00 

Round  33, Train loss: 0.030, Test loss: 1.841, Test accuracy: 66.20 

Round  33, Global train loss: 0.030, Global test loss: 2.434, Global test accuracy: 22.12 

Round  34, Train loss: 0.027, Test loss: 1.938, Test accuracy: 67.08 

Round  34, Global train loss: 0.027, Global test loss: 2.393, Global test accuracy: 20.68 

Final Round, Train loss: 0.020, Test loss: 1.934, Test accuracy: 66.96 

Final Round, Global train loss: 0.020, Global test loss: 2.393, Global test accuracy: 20.68 

Average accuracy final 10 rounds: 66.06 

Average global accuracy final 10 rounds: 18.608 

1295.0134069919586
[8.93691611289978, 15.445783853530884, 21.987980604171753, 28.381500244140625, 34.746177196502686, 41.21711301803589, 47.59768009185791, 53.90103840827942, 60.08597373962402, 66.29779100418091, 72.46686434745789, 78.52604031562805, 85.54018211364746, 92.3899917602539, 98.39829421043396, 104.62934899330139, 111.17126488685608, 117.4113359451294, 123.86529636383057, 130.2852325439453, 136.7126820087433, 143.24242901802063, 149.72503519058228, 156.02792048454285, 162.26607823371887, 168.38152527809143, 174.50765109062195, 180.69968152046204, 186.8643455505371, 193.11981916427612, 199.54878878593445, 205.64325404167175, 212.1418755054474, 218.35800170898438, 225.12124490737915, 237.9415512084961]
[46.28, 55.48, 56.28, 55.96, 59.32, 57.32, 59.08, 60.0, 57.12, 58.68, 60.4, 61.84, 62.48, 62.8, 63.04, 63.08, 62.24, 64.8, 62.8, 63.68, 64.72, 63.24, 65.4, 65.6, 65.16, 65.12, 66.76, 63.8, 65.08, 65.56, 67.72, 66.4, 66.88, 66.2, 67.08, 66.96]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.459, Test loss: 1.427, Test accuracy: 48.16 

Round   0, Global train loss: 1.459, Global test loss: 2.559, Global test accuracy: 20.00 

Round   1, Train loss: 1.320, Test loss: 1.377, Test accuracy: 52.36 

Round   1, Global train loss: 1.320, Global test loss: 2.112, Global test accuracy: 29.84 

Round   2, Train loss: 1.187, Test loss: 1.157, Test accuracy: 55.20 

Round   2, Global train loss: 1.187, Global test loss: 1.878, Global test accuracy: 39.44 

Round   3, Train loss: 1.076, Test loss: 1.171, Test accuracy: 55.32 

Round   3, Global train loss: 1.076, Global test loss: 2.005, Global test accuracy: 38.48 

Round   4, Train loss: 0.985, Test loss: 1.180, Test accuracy: 59.28 

Round   4, Global train loss: 0.985, Global test loss: 1.832, Global test accuracy: 42.20 

Round   5, Train loss: 0.923, Test loss: 1.115, Test accuracy: 61.28 

Round   5, Global train loss: 0.923, Global test loss: 1.731, Global test accuracy: 44.36 

Round   6, Train loss: 0.865, Test loss: 1.092, Test accuracy: 62.20 

Round   6, Global train loss: 0.865, Global test loss: 1.765, Global test accuracy: 45.84 

Round   7, Train loss: 0.799, Test loss: 1.223, Test accuracy: 59.64 

Round   7, Global train loss: 0.799, Global test loss: 1.627, Global test accuracy: 48.36 

Round   8, Train loss: 0.740, Test loss: 1.298, Test accuracy: 63.28 

Round   8, Global train loss: 0.740, Global test loss: 1.704, Global test accuracy: 48.88 

Round   9, Train loss: 0.694, Test loss: 1.113, Test accuracy: 65.04 

Round   9, Global train loss: 0.694, Global test loss: 1.464, Global test accuracy: 53.72 

Round  10, Train loss: 0.630, Test loss: 1.098, Test accuracy: 66.84 

Round  10, Global train loss: 0.630, Global test loss: 1.354, Global test accuracy: 58.20 

Round  11, Train loss: 0.590, Test loss: 1.424, Test accuracy: 61.76 

Round  11, Global train loss: 0.590, Global test loss: 1.696, Global test accuracy: 50.28 

Round  12, Train loss: 0.535, Test loss: 1.077, Test accuracy: 68.08 

Round  12, Global train loss: 0.535, Global test loss: 1.548, Global test accuracy: 55.48 

Round  13, Train loss: 0.504, Test loss: 1.214, Test accuracy: 63.40 

Round  13, Global train loss: 0.504, Global test loss: 1.387, Global test accuracy: 57.84 

Round  14, Train loss: 0.463, Test loss: 1.197, Test accuracy: 67.36 

Round  14, Global train loss: 0.463, Global test loss: 1.406, Global test accuracy: 59.56 

Round  15, Train loss: 0.442, Test loss: 1.450, Test accuracy: 63.60 

Round  15, Global train loss: 0.442, Global test loss: 1.476, Global test accuracy: 58.24 

Round  16, Train loss: 0.396, Test loss: 1.260, Test accuracy: 67.52 

Round  16, Global train loss: 0.396, Global test loss: 1.520, Global test accuracy: 57.76 

Round  17, Train loss: 0.368, Test loss: 1.443, Test accuracy: 67.40 

Round  17, Global train loss: 0.368, Global test loss: 1.639, Global test accuracy: 57.08 

Round  18, Train loss: 0.351, Test loss: 0.990, Test accuracy: 72.08 

Round  18, Global train loss: 0.351, Global test loss: 1.343, Global test accuracy: 62.16 

Round  19, Train loss: 0.327, Test loss: 1.205, Test accuracy: 69.20 

Round  19, Global train loss: 0.327, Global test loss: 1.367, Global test accuracy: 61.96 

Round  20, Train loss: 0.297, Test loss: 1.187, Test accuracy: 70.88 

Round  20, Global train loss: 0.297, Global test loss: 1.349, Global test accuracy: 62.80 

Round  21, Train loss: 0.282, Test loss: 1.148, Test accuracy: 70.52 

Round  21, Global train loss: 0.282, Global test loss: 1.412, Global test accuracy: 61.84 

Round  22, Train loss: 0.269, Test loss: 1.119, Test accuracy: 72.28 

Round  22, Global train loss: 0.269, Global test loss: 1.178, Global test accuracy: 67.48 

Round  23, Train loss: 0.245, Test loss: 1.403, Test accuracy: 69.88 

Round  23, Global train loss: 0.245, Global test loss: 1.420, Global test accuracy: 62.52 

Round  24, Train loss: 0.242, Test loss: 1.029, Test accuracy: 74.92 

Round  24, Global train loss: 0.242, Global test loss: 1.243, Global test accuracy: 65.88 

Round  25, Train loss: 0.199, Test loss: 1.286, Test accuracy: 70.04 

Round  25, Global train loss: 0.199, Global test loss: 1.295, Global test accuracy: 65.36 

Round  26, Train loss: 0.222, Test loss: 1.179, Test accuracy: 72.96 

Round  26, Global train loss: 0.222, Global test loss: 1.328, Global test accuracy: 64.44 

Round  27, Train loss: 0.182, Test loss: 1.138, Test accuracy: 73.20 

Round  27, Global train loss: 0.182, Global test loss: 1.189, Global test accuracy: 67.16 

Round  28, Train loss: 0.177, Test loss: 1.257, Test accuracy: 71.56 

Round  28, Global train loss: 0.177, Global test loss: 1.329, Global test accuracy: 65.88 

Round  29, Train loss: 0.156, Test loss: 1.151, Test accuracy: 72.84 

Round  29, Global train loss: 0.156, Global test loss: 1.226, Global test accuracy: 67.32 

Round  30, Train loss: 0.164, Test loss: 1.239, Test accuracy: 72.08 

Round  30, Global train loss: 0.164, Global test loss: 1.307, Global test accuracy: 66.44 

Round  31, Train loss: 0.153, Test loss: 1.582, Test accuracy: 68.80 

Round  31, Global train loss: 0.153, Global test loss: 1.418, Global test accuracy: 64.56 

Round  32, Train loss: 0.145, Test loss: 1.221, Test accuracy: 73.32 

Round  32, Global train loss: 0.145, Global test loss: 1.356, Global test accuracy: 66.48 

Round  33, Train loss: 0.133, Test loss: 1.114, Test accuracy: 74.76 

Round  33, Global train loss: 0.133, Global test loss: 1.282, Global test accuracy: 67.16 

Round  34, Train loss: 0.126, Test loss: 1.161, Test accuracy: 74.04 

Round  34, Global train loss: 0.126, Global test loss: 1.275, Global test accuracy: 68.28 

Round  35, Train loss: 0.124, Test loss: 1.240, Test accuracy: 73.12 

Round  35, Global train loss: 0.124, Global test loss: 1.390, Global test accuracy: 66.12 

Round  36, Train loss: 0.104, Test loss: 1.326, Test accuracy: 73.04 

Round  36, Global train loss: 0.104, Global test loss: 1.293, Global test accuracy: 68.04 

Round  37, Train loss: 0.105, Test loss: 1.416, Test accuracy: 71.60 

Round  37, Global train loss: 0.105, Global test loss: 1.193, Global test accuracy: 69.00 

Round  38, Train loss: 0.118, Test loss: 1.160, Test accuracy: 75.28 

Round  38, Global train loss: 0.118, Global test loss: 1.206, Global test accuracy: 69.28 

Round  39, Train loss: 0.076, Test loss: 1.276, Test accuracy: 74.96 

Round  39, Global train loss: 0.076, Global test loss: 1.159, Global test accuracy: 69.60 

Round  40, Train loss: 0.089, Test loss: 1.235, Test accuracy: 73.88 

Round  40, Global train loss: 0.089, Global test loss: 1.168, Global test accuracy: 69.76 

Round  41, Train loss: 0.078, Test loss: 1.090, Test accuracy: 76.88 

Round  41, Global train loss: 0.078, Global test loss: 1.217, Global test accuracy: 70.44 

Round  42, Train loss: 0.091, Test loss: 1.225, Test accuracy: 76.04 

Round  42, Global train loss: 0.091, Global test loss: 1.332, Global test accuracy: 68.60 

Round  43, Train loss: 0.069, Test loss: 1.242, Test accuracy: 76.04 

Round  43, Global train loss: 0.069, Global test loss: 1.402, Global test accuracy: 67.52 

Round  44, Train loss: 0.072, Test loss: 1.273, Test accuracy: 74.80 

Round  44, Global train loss: 0.072, Global test loss: 1.337, Global test accuracy: 67.96 

Round  45, Train loss: 0.064, Test loss: 1.081, Test accuracy: 77.84 

Round  45, Global train loss: 0.064, Global test loss: 1.232, Global test accuracy: 70.48 

Round  46, Train loss: 0.069, Test loss: 1.353, Test accuracy: 74.36 

Round  46, Global train loss: 0.069, Global test loss: 1.290, Global test accuracy: 68.48 

Round  47, Train loss: 0.057, Test loss: 1.118, Test accuracy: 76.96 

Round  47, Global train loss: 0.057, Global test loss: 1.335, Global test accuracy: 68.96 

Round  48, Train loss: 0.046, Test loss: 1.198, Test accuracy: 76.88 

Round  48, Global train loss: 0.046, Global test loss: 1.228, Global test accuracy: 70.64 

Round  49, Train loss: 0.048, Test loss: 1.140, Test accuracy: 77.00 

Round  49, Global train loss: 0.048, Global test loss: 1.243, Global test accuracy: 69.80 

Final Round, Train loss: 0.053, Test loss: 1.372, Test accuracy: 74.12 

Final Round, Global train loss: 0.053, Global test loss: 1.243, Global test accuracy: 69.80 

Average accuracy final 10 rounds: 76.068 

Average global accuracy final 10 rounds: 69.264 

1795.1255631446838
[9.711799383163452, 16.162784576416016, 22.56698751449585, 28.94780421257019, 35.13099026679993, 41.38060164451599, 47.57188606262207, 54.20561337471008, 60.57550525665283, 67.34519076347351, 74.2135078907013, 80.19627475738525, 86.43868827819824, 93.11943292617798, 99.4522647857666, 106.0145320892334, 112.55477261543274, 118.73273849487305, 124.94665956497192, 131.25534057617188, 137.63430070877075, 143.79025650024414, 150.3156476020813, 156.49006271362305, 162.77031207084656, 169.22263956069946, 175.62191200256348, 181.86103105545044, 187.7338206768036, 193.70092916488647, 199.35905122756958, 205.18039631843567, 211.43380546569824, 217.63500833511353, 223.88456654548645, 230.14981532096863, 236.2312912940979, 242.1653962135315, 248.2377107143402, 254.1654188632965, 260.10395526885986, 266.01083040237427, 271.7428767681122, 277.5697042942047, 283.23753118515015, 289.47569394111633, 295.0576002597809, 300.79738426208496, 306.4657835960388, 311.93311381340027, 324.1205463409424]
[48.16, 52.36, 55.2, 55.32, 59.28, 61.28, 62.2, 59.64, 63.28, 65.04, 66.84, 61.76, 68.08, 63.4, 67.36, 63.6, 67.52, 67.4, 72.08, 69.2, 70.88, 70.52, 72.28, 69.88, 74.92, 70.04, 72.96, 73.2, 71.56, 72.84, 72.08, 68.8, 73.32, 74.76, 74.04, 73.12, 73.04, 71.6, 75.28, 74.96, 73.88, 76.88, 76.04, 76.04, 74.8, 77.84, 74.36, 76.96, 76.88, 77.0, 74.12]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.571, Test loss: 1.999, Test accuracy: 20.24 

Round   1, Train loss: 1.353, Test loss: 1.581, Test accuracy: 37.08 

Round   2, Train loss: 1.244, Test loss: 1.330, Test accuracy: 44.80 

Round   3, Train loss: 1.143, Test loss: 1.187, Test accuracy: 50.64 

Round   4, Train loss: 1.088, Test loss: 1.208, Test accuracy: 49.52 

Round   5, Train loss: 1.030, Test loss: 1.132, Test accuracy: 53.40 

Round   6, Train loss: 0.963, Test loss: 0.977, Test accuracy: 59.40 

Round   7, Train loss: 0.900, Test loss: 0.942, Test accuracy: 62.48 

Round   8, Train loss: 0.860, Test loss: 0.974, Test accuracy: 61.92 

Round   9, Train loss: 0.828, Test loss: 0.952, Test accuracy: 62.44 

Round  10, Train loss: 0.778, Test loss: 0.927, Test accuracy: 63.88 

Round  11, Train loss: 0.741, Test loss: 0.894, Test accuracy: 65.44 

Round  12, Train loss: 0.703, Test loss: 0.831, Test accuracy: 67.80 

Round  13, Train loss: 0.664, Test loss: 0.961, Test accuracy: 65.92 

Round  14, Train loss: 0.635, Test loss: 0.880, Test accuracy: 67.96 

Round  15, Train loss: 0.592, Test loss: 0.791, Test accuracy: 71.24 

Round  16, Train loss: 0.564, Test loss: 0.773, Test accuracy: 71.12 

Round  17, Train loss: 0.517, Test loss: 0.765, Test accuracy: 72.16 

Round  18, Train loss: 0.490, Test loss: 0.769, Test accuracy: 72.28 

Round  19, Train loss: 0.457, Test loss: 0.740, Test accuracy: 72.84 

Round  20, Train loss: 0.425, Test loss: 0.775, Test accuracy: 72.32 

Round  21, Train loss: 0.400, Test loss: 0.752, Test accuracy: 74.20 

Round  22, Train loss: 0.376, Test loss: 0.738, Test accuracy: 75.16 

Round  23, Train loss: 0.359, Test loss: 0.703, Test accuracy: 75.72 

Round  24, Train loss: 0.335, Test loss: 0.716, Test accuracy: 75.40 

Round  25, Train loss: 0.324, Test loss: 0.678, Test accuracy: 76.84 

Round  26, Train loss: 0.295, Test loss: 0.768, Test accuracy: 75.28 

Round  27, Train loss: 0.279, Test loss: 0.730, Test accuracy: 75.80 

Round  28, Train loss: 0.259, Test loss: 0.705, Test accuracy: 76.88 

Round  29, Train loss: 0.243, Test loss: 0.723, Test accuracy: 76.84 

Round  30, Train loss: 0.235, Test loss: 0.723, Test accuracy: 76.96 

Round  31, Train loss: 0.207, Test loss: 0.726, Test accuracy: 76.84 

Round  32, Train loss: 0.203, Test loss: 0.732, Test accuracy: 76.72 

Round  33, Train loss: 0.189, Test loss: 0.736, Test accuracy: 77.28 

Round  34, Train loss: 0.180, Test loss: 0.730, Test accuracy: 77.00 

Round  35, Train loss: 0.180, Test loss: 0.766, Test accuracy: 76.52 

Round  36, Train loss: 0.161, Test loss: 0.731, Test accuracy: 78.04 

Round  37, Train loss: 0.146, Test loss: 0.743, Test accuracy: 77.52 

Round  38, Train loss: 0.138, Test loss: 0.754, Test accuracy: 77.84 

Round  39, Train loss: 0.138, Test loss: 0.773, Test accuracy: 77.12 

Round  40, Train loss: 0.122, Test loss: 0.743, Test accuracy: 78.48 

Round  41, Train loss: 0.111, Test loss: 0.768, Test accuracy: 77.92 

Round  42, Train loss: 0.107, Test loss: 0.797, Test accuracy: 77.44 

Round  43, Train loss: 0.095, Test loss: 0.813, Test accuracy: 77.24 

Round  44, Train loss: 0.085, Test loss: 0.798, Test accuracy: 78.00 

Round  45, Train loss: 0.100, Test loss: 0.810, Test accuracy: 77.92 

Round  46, Train loss: 0.091, Test loss: 0.788, Test accuracy: 78.32 

Round  47, Train loss: 0.088, Test loss: 0.804, Test accuracy: 78.40 

Round  48, Train loss: 0.087, Test loss: 0.810, Test accuracy: 79.12 

Round  49, Train loss: 0.072, Test loss: 0.825, Test accuracy: 78.40 

Final Round, Train loss: 0.039, Test loss: 0.833, Test accuracy: 78.92 

Average accuracy final 10 rounds: 78.12400000000001 

1362.0265173912048
[8.728556632995605, 13.87147068977356, 19.057552099227905, 24.455368041992188, 29.592361211776733, 34.67265439033508, 39.551714181900024, 44.54693365097046, 49.74467706680298, 54.7371711730957, 59.71921706199646, 64.51223587989807, 69.47586226463318, 74.77110171318054, 79.55439877510071, 84.60965514183044, 89.39229321479797, 94.1299340724945, 99.04475474357605, 104.22445011138916, 109.44198966026306, 114.72062563896179, 120.00159072875977, 125.19548630714417, 130.38540410995483, 135.47249102592468, 140.6877977848053, 145.84281969070435, 150.99950623512268, 156.0712969303131, 161.2360978126526, 166.11394810676575, 171.34893655776978, 176.53473782539368, 181.3224892616272, 186.3455593585968, 191.40919733047485, 196.34542894363403, 201.13942193984985, 205.97562980651855, 211.00560760498047, 216.25817036628723, 221.47836327552795, 226.76021528244019, 232.25686144828796, 237.44235134124756, 242.32583379745483, 247.3361496925354, 252.6692864894867, 257.9133052825928, 263.75350880622864]
[20.24, 37.08, 44.8, 50.64, 49.52, 53.4, 59.4, 62.48, 61.92, 62.44, 63.88, 65.44, 67.8, 65.92, 67.96, 71.24, 71.12, 72.16, 72.28, 72.84, 72.32, 74.2, 75.16, 75.72, 75.4, 76.84, 75.28, 75.8, 76.88, 76.84, 76.96, 76.84, 76.72, 77.28, 77.0, 76.52, 78.04, 77.52, 77.84, 77.12, 78.48, 77.92, 77.44, 77.24, 78.0, 77.92, 78.32, 78.4, 79.12, 78.4, 78.92]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
Round   0, Train loss: 1.585, Test loss: 1.785, Test accuracy: 24.92
Round   1, Train loss: 1.369, Test loss: 1.499, Test accuracy: 37.84
Round   2, Train loss: 1.237, Test loss: 1.266, Test accuracy: 46.64
Round   3, Train loss: 1.141, Test loss: 1.106, Test accuracy: 53.56
Round   4, Train loss: 1.066, Test loss: 1.012, Test accuracy: 58.32
Round   5, Train loss: 1.007, Test loss: 1.079, Test accuracy: 56.52
Round   6, Train loss: 0.937, Test loss: 0.881, Test accuracy: 64.56
Round   7, Train loss: 0.893, Test loss: 0.993, Test accuracy: 61.20
Round   8, Train loss: 0.843, Test loss: 0.914, Test accuracy: 64.56
Round   9, Train loss: 0.802, Test loss: 0.812, Test accuracy: 67.88
Round  10, Train loss: 0.759, Test loss: 0.837, Test accuracy: 67.52
Round  11, Train loss: 0.722, Test loss: 0.865, Test accuracy: 65.80
Round  12, Train loss: 0.693, Test loss: 0.833, Test accuracy: 68.84
Round  13, Train loss: 0.647, Test loss: 0.794, Test accuracy: 69.80
Round  14, Train loss: 0.614, Test loss: 0.850, Test accuracy: 68.68
Round  15, Train loss: 0.582, Test loss: 0.778, Test accuracy: 71.56
Round  16, Train loss: 0.539, Test loss: 0.787, Test accuracy: 71.48
Round  17, Train loss: 0.519, Test loss: 0.802, Test accuracy: 71.00
Round  18, Train loss: 0.488, Test loss: 0.733, Test accuracy: 73.20
Round  19, Train loss: 0.455, Test loss: 0.703, Test accuracy: 74.84
Round  20, Train loss: 0.434, Test loss: 0.718, Test accuracy: 74.20
Round  21, Train loss: 0.409, Test loss: 0.708, Test accuracy: 74.92
Round  22, Train loss: 0.372, Test loss: 0.724, Test accuracy: 75.04
Round  23, Train loss: 0.358, Test loss: 0.719, Test accuracy: 75.60
Round  24, Train loss: 0.332, Test loss: 0.723, Test accuracy: 75.52
Round  25, Train loss: 0.311, Test loss: 0.731, Test accuracy: 75.44
Round  26, Train loss: 0.299, Test loss: 0.685, Test accuracy: 76.16
Round  27, Train loss: 0.278, Test loss: 0.702, Test accuracy: 76.52
Round  28, Train loss: 0.271, Test loss: 0.708, Test accuracy: 77.32
Round  29, Train loss: 0.248, Test loss: 0.695, Test accuracy: 77.40
Round  30, Train loss: 0.221, Test loss: 0.692, Test accuracy: 77.48
Round  31, Train loss: 0.212, Test loss: 0.715, Test accuracy: 77.80
Round  32, Train loss: 0.195, Test loss: 0.675, Test accuracy: 76.96
Round  33, Train loss: 0.193, Test loss: 0.716, Test accuracy: 77.84
Round  34, Train loss: 0.169, Test loss: 0.695, Test accuracy: 77.72
Round  35, Train loss: 0.160, Test loss: 0.721, Test accuracy: 77.52
Round  36, Train loss: 0.169, Test loss: 0.704, Test accuracy: 78.16
Round  37, Train loss: 0.158, Test loss: 0.698, Test accuracy: 79.12
Round  38, Train loss: 0.124, Test loss: 0.692, Test accuracy: 78.48
Round  39, Train loss: 0.137, Test loss: 0.696, Test accuracy: 79.32
Round  40, Train loss: 0.120, Test loss: 0.735, Test accuracy: 77.88
Round  41, Train loss: 0.115, Test loss: 0.718, Test accuracy: 78.88
Round  42, Train loss: 0.112, Test loss: 0.717, Test accuracy: 78.32
Round  43, Train loss: 0.104, Test loss: 0.732, Test accuracy: 78.80
Round  44, Train loss: 0.091, Test loss: 0.729, Test accuracy: 78.44
Round  45, Train loss: 0.086, Test loss: 0.728, Test accuracy: 78.88
Round  46, Train loss: 0.089, Test loss: 0.742, Test accuracy: 78.80
Round  47, Train loss: 0.068, Test loss: 0.737, Test accuracy: 79.52
Round  48, Train loss: 0.076, Test loss: 0.753, Test accuracy: 79.00
Round  49, Train loss: 0.061, Test loss: 0.768, Test accuracy: 79.36
Final Round, Train loss: 0.038, Test loss: 0.780, Test accuracy: 79.76
Average accuracy final 10 rounds: 78.78799999999998
1514.3618776798248
[8.819118022918701, 14.561624765396118, 20.113824605941772, 25.491888761520386, 30.818842887878418, 36.57940101623535, 42.06576132774353, 47.402284145355225, 52.77225589752197, 58.45579743385315, 64.46658706665039, 70.64651036262512, 77.02661848068237, 82.6399576663971, 88.49343824386597, 94.35575008392334, 100.52853727340698, 106.7656946182251, 112.49319362640381, 118.5317656993866, 124.79406929016113, 130.09037733078003, 135.765625, 141.05530381202698, 146.63214015960693, 152.16253471374512, 157.79514932632446, 163.3157923221588, 168.92156457901, 174.535005569458, 180.70079612731934, 186.94035291671753, 193.0214376449585, 198.6570074558258, 204.83166670799255, 211.00276947021484, 217.0618119239807, 222.82789826393127, 228.87290740013123, 234.90130615234375, 240.357848405838, 245.64061784744263, 251.32685923576355, 257.0615074634552, 262.55714535713196, 268.08776807785034, 273.586302280426, 278.8686294555664, 284.5744709968567, 290.358838558197, 296.57755184173584]
[24.92, 37.84, 46.64, 53.56, 58.32, 56.52, 64.56, 61.2, 64.56, 67.88, 67.52, 65.8, 68.84, 69.8, 68.68, 71.56, 71.48, 71.0, 73.2, 74.84, 74.2, 74.92, 75.04, 75.6, 75.52, 75.44, 76.16, 76.52, 77.32, 77.4, 77.48, 77.8, 76.96, 77.84, 77.72, 77.52, 78.16, 79.12, 78.48, 79.32, 77.88, 78.88, 78.32, 78.8, 78.44, 78.88, 78.8, 79.52, 79.0, 79.36, 79.76]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

        init --> train local model(freeze embeding):client   0,  Train loss: 0.620, Train accuracy: 75.600, Test loss: 1.217, Test accuracy: 58.20 

        train local model (freeze embeding):client   0,  Train loss: 0.494, Train accuracy: 80.800, Test loss: 1.129, Test accuracy: 62.40 

        train local model (unfreeze embeding):client   0,  Train loss: 1.069, Train accuracy: 54.600, Test loss: 1.248, Test accuracy: 51.80 

Round   0, Train loss: 1.009, Test loss: 1.248, Test accuracy: 51.80 

        train local model (freeze embeding):client   0,  Train loss: 0.843, Train accuracy: 63.800, Test loss: 1.132, Test accuracy: 57.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.979, Train accuracy: 57.800, Test loss: 1.360, Test accuracy: 45.20 

Round   1, Train loss: 1.083, Test loss: 1.360, Test accuracy: 45.20 

        train local model (freeze embeding):client   0,  Train loss: 0.696, Train accuracy: 73.600, Test loss: 1.103, Test accuracy: 60.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.673, Train accuracy: 76.600, Test loss: 1.142, Test accuracy: 57.60 

Round   2, Train loss: 0.893, Test loss: 1.142, Test accuracy: 57.60 

        train local model (freeze embeding):client   0,  Train loss: 0.610, Train accuracy: 75.200, Test loss: 1.150, Test accuracy: 63.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.621, Train accuracy: 78.200, Test loss: 1.124, Test accuracy: 61.80 

Round   3, Train loss: 0.814, Test loss: 1.124, Test accuracy: 61.80 

        train local model (freeze embeding):client   0,  Train loss: 0.539, Train accuracy: 78.000, Test loss: 1.139, Test accuracy: 61.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.741, Train accuracy: 68.800, Test loss: 1.391, Test accuracy: 54.60 

Round   4, Train loss: 0.734, Test loss: 1.391, Test accuracy: 54.60 

        train local model (freeze embeding):client   0,  Train loss: 0.492, Train accuracy: 83.200, Test loss: 1.249, Test accuracy: 57.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.591, Train accuracy: 78.000, Test loss: 1.502, Test accuracy: 54.60 

Round   5, Train loss: 0.696, Test loss: 1.502, Test accuracy: 54.60 

        train local model (freeze embeding):client   0,  Train loss: 0.450, Train accuracy: 81.800, Test loss: 1.199, Test accuracy: 61.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.666, Train accuracy: 75.000, Test loss: 1.534, Test accuracy: 52.00 

Round   6, Train loss: 0.608, Test loss: 1.534, Test accuracy: 52.00 

        train local model (freeze embeding):client   0,  Train loss: 0.472, Train accuracy: 83.000, Test loss: 1.460, Test accuracy: 58.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.317, Train accuracy: 89.000, Test loss: 1.386, Test accuracy: 58.40 

Round   7, Train loss: 0.584, Test loss: 1.386, Test accuracy: 58.40 

        train local model (freeze embeding):client   0,  Train loss: 0.342, Train accuracy: 86.000, Test loss: 1.375, Test accuracy: 60.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.390, Train accuracy: 85.000, Test loss: 1.506, Test accuracy: 60.40 

Round   8, Train loss: 0.520, Test loss: 1.506, Test accuracy: 60.40 

        train local model (freeze embeding):client   0,  Train loss: 0.329, Train accuracy: 87.800, Test loss: 1.218, Test accuracy: 64.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.365, Train accuracy: 85.200, Test loss: 1.618, Test accuracy: 56.20 

Round   9, Train loss: 0.497, Test loss: 1.618, Test accuracy: 56.20 

        train local model (freeze embeding):client   0,  Train loss: 0.250, Train accuracy: 91.200, Test loss: 1.253, Test accuracy: 64.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.185, Train accuracy: 93.400, Test loss: 1.616, Test accuracy: 60.80 

Round  10, Train loss: 0.449, Test loss: 1.616, Test accuracy: 60.80 

        train local model (freeze embeding):client   0,  Train loss: 0.318, Train accuracy: 87.200, Test loss: 1.445, Test accuracy: 63.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.129, Train accuracy: 95.000, Test loss: 1.575, Test accuracy: 61.00 

Round  11, Train loss: 0.428, Test loss: 1.575, Test accuracy: 61.00 

        train local model (freeze embeding):client   0,  Train loss: 0.432, Train accuracy: 81.200, Test loss: 1.657, Test accuracy: 59.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.106, Train accuracy: 96.600, Test loss: 1.614, Test accuracy: 61.00 

Round  12, Train loss: 0.425, Test loss: 1.614, Test accuracy: 61.00 

        train local model (freeze embeding):client   0,  Train loss: 0.236, Train accuracy: 92.400, Test loss: 1.399, Test accuracy: 61.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.263, Train accuracy: 90.400, Test loss: 1.783, Test accuracy: 57.80 

Round  13, Train loss: 0.400, Test loss: 1.783, Test accuracy: 57.80 

        train local model (freeze embeding):client   0,  Train loss: 0.207, Train accuracy: 92.600, Test loss: 1.383, Test accuracy: 63.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.169, Train accuracy: 93.400, Test loss: 1.644, Test accuracy: 58.60 

Round  14, Train loss: 0.396, Test loss: 1.644, Test accuracy: 58.60 

        train local model (freeze embeding):client   0,  Train loss: 0.189, Train accuracy: 94.200, Test loss: 1.353, Test accuracy: 62.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.091, Train accuracy: 97.800, Test loss: 1.836, Test accuracy: 61.20 

Round  15, Train loss: 0.422, Test loss: 1.836, Test accuracy: 61.20 

        train local model (freeze embeding):client   0,  Train loss: 0.263, Train accuracy: 89.600, Test loss: 1.591, Test accuracy: 59.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.098, Train accuracy: 96.600, Test loss: 1.929, Test accuracy: 60.60 

Round  16, Train loss: 0.350, Test loss: 1.929, Test accuracy: 60.60 

        train local model (freeze embeding):client   0,  Train loss: 0.226, Train accuracy: 93.400, Test loss: 1.445, Test accuracy: 63.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.133, Train accuracy: 95.000, Test loss: 2.045, Test accuracy: 60.80 

Round  17, Train loss: 0.379, Test loss: 2.045, Test accuracy: 60.80 

        train local model (freeze embeding):client   0,  Train loss: 0.199, Train accuracy: 93.200, Test loss: 1.448, Test accuracy: 62.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.202, Train accuracy: 92.800, Test loss: 2.167, Test accuracy: 58.80 

Round  18, Train loss: 0.370, Test loss: 2.167, Test accuracy: 58.80 

        train local model (freeze embeding):client   0,  Train loss: 0.216, Train accuracy: 93.800, Test loss: 1.505, Test accuracy: 63.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.087, Train accuracy: 97.400, Test loss: 2.116, Test accuracy: 60.20 

Round  19, Train loss: 0.348, Test loss: 2.116, Test accuracy: 60.20 

        train local model (freeze embeding):client   0,  Train loss: 0.210, Train accuracy: 93.600, Test loss: 1.348, Test accuracy: 63.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.277, Train accuracy: 90.200, Test loss: 1.970, Test accuracy: 61.80 

Final Round, Train loss: 0.368, Test loss: 1.924, Test accuracy: 61.00 

---------------------------------------------train_client: [0, 1] 

        init --> train local model(freeze embeding):client   1,  Train loss: 1.309, Train accuracy: 44.800, Test loss: 1.471, Test accuracy: 41.00 

        train local model (freeze embeding):client   0,  Train loss: 0.221, Train accuracy: 92.000, Test loss: 1.420, Test accuracy: 63.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.077, Train accuracy: 97.400, Test loss: 1.757, Test accuracy: 63.00 

        train local model (freeze embeding):client   1,  Train loss: 1.266, Train accuracy: 48.400, Test loss: 1.448, Test accuracy: 46.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.947, Train accuracy: 59.400, Test loss: 1.536, Test accuracy: 46.60 

Round   0, Train loss: 0.789, Test loss: 1.489, Test accuracy: 56.20 

        train local model (freeze embeding):client   0,  Train loss: 0.253, Train accuracy: 91.200, Test loss: 1.464, Test accuracy: 61.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.115, Train accuracy: 96.200, Test loss: 2.181, Test accuracy: 61.40 

        train local model (freeze embeding):client   1,  Train loss: 1.148, Train accuracy: 54.600, Test loss: 1.487, Test accuracy: 47.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.829, Train accuracy: 70.200, Test loss: 1.385, Test accuracy: 49.40 

Round   1, Train loss: 0.742, Test loss: 1.602, Test accuracy: 55.20 

        train local model (freeze embeding):client   0,  Train loss: 0.436, Train accuracy: 81.600, Test loss: 1.554, Test accuracy: 57.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.095, Train accuracy: 97.200, Test loss: 1.907, Test accuracy: 62.80 

        train local model (freeze embeding):client   1,  Train loss: 1.074, Train accuracy: 58.400, Test loss: 1.490, Test accuracy: 46.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.715, Train accuracy: 74.200, Test loss: 1.434, Test accuracy: 47.80 

Round   2, Train loss: 0.731, Test loss: 1.499, Test accuracy: 56.00 

        train local model (freeze embeding):client   0,  Train loss: 0.311, Train accuracy: 88.800, Test loss: 1.373, Test accuracy: 60.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.118, Train accuracy: 95.400, Test loss: 2.112, Test accuracy: 59.40 

        train local model (freeze embeding):client   1,  Train loss: 0.904, Train accuracy: 64.800, Test loss: 1.453, Test accuracy: 46.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.743, Train accuracy: 69.200, Test loss: 1.610, Test accuracy: 46.80 

Round   3, Train loss: 0.691, Test loss: 1.633, Test accuracy: 53.90 

        train local model (freeze embeding):client   0,  Train loss: 0.387, Train accuracy: 86.000, Test loss: 1.357, Test accuracy: 63.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.049, Train accuracy: 98.800, Test loss: 1.857, Test accuracy: 63.00 

        train local model (freeze embeding):client   1,  Train loss: 0.925, Train accuracy: 63.600, Test loss: 1.531, Test accuracy: 48.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.609, Train accuracy: 74.200, Test loss: 1.626, Test accuracy: 49.80 

Round   4, Train loss: 0.682, Test loss: 1.593, Test accuracy: 56.10 

        train local model (freeze embeding):client   0,  Train loss: 0.459, Train accuracy: 81.600, Test loss: 1.313, Test accuracy: 59.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.138, Train accuracy: 95.400, Test loss: 1.639, Test accuracy: 63.00 

        train local model (freeze embeding):client   1,  Train loss: 0.920, Train accuracy: 65.000, Test loss: 1.515, Test accuracy: 48.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.585, Train accuracy: 77.800, Test loss: 1.656, Test accuracy: 47.00 

Round   5, Train loss: 0.702, Test loss: 1.665, Test accuracy: 53.30 

        train local model (freeze embeding):client   0,  Train loss: 0.512, Train accuracy: 78.200, Test loss: 1.356, Test accuracy: 61.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.075, Train accuracy: 98.400, Test loss: 1.960, Test accuracy: 60.20 

        train local model (freeze embeding):client   1,  Train loss: 1.001, Train accuracy: 59.800, Test loss: 1.671, Test accuracy: 42.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.554, Train accuracy: 77.600, Test loss: 1.856, Test accuracy: 44.80 

Round   6, Train loss: 0.660, Test loss: 1.763, Test accuracy: 52.50 

        train local model (freeze embeding):client   0,  Train loss: 0.465, Train accuracy: 82.800, Test loss: 1.351, Test accuracy: 59.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.089, Train accuracy: 98.000, Test loss: 1.821, Test accuracy: 58.80 

        train local model (freeze embeding):client   1,  Train loss: 0.790, Train accuracy: 65.000, Test loss: 1.474, Test accuracy: 47.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.653, Train accuracy: 75.800, Test loss: 1.987, Test accuracy: 44.00 

Round   7, Train loss: 0.693, Test loss: 1.685, Test accuracy: 54.10 

        train local model (freeze embeding):client   0,  Train loss: 0.469, Train accuracy: 82.200, Test loss: 1.251, Test accuracy: 61.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.094, Train accuracy: 97.400, Test loss: 1.946, Test accuracy: 62.20 

        train local model (freeze embeding):client   1,  Train loss: 0.947, Train accuracy: 60.400, Test loss: 1.639, Test accuracy: 42.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.467, Train accuracy: 80.800, Test loss: 1.922, Test accuracy: 47.40 

Round   8, Train loss: 0.680, Test loss: 1.783, Test accuracy: 53.80 

        train local model (freeze embeding):client   0,  Train loss: 0.760, Train accuracy: 69.200, Test loss: 1.542, Test accuracy: 50.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.141, Train accuracy: 95.400, Test loss: 1.929, Test accuracy: 57.60 

        train local model (freeze embeding):client   1,  Train loss: 0.890, Train accuracy: 62.000, Test loss: 1.587, Test accuracy: 43.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.385, Train accuracy: 86.200, Test loss: 1.701, Test accuracy: 47.80 

Round   9, Train loss: 0.682, Test loss: 1.694, Test accuracy: 54.00 

        train local model (freeze embeding):client   0,  Train loss: 0.579, Train accuracy: 76.000, Test loss: 1.412, Test accuracy: 56.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.103, Train accuracy: 95.600, Test loss: 2.028, Test accuracy: 57.60 

        train local model (freeze embeding):client   1,  Train loss: 0.982, Train accuracy: 57.800, Test loss: 1.692, Test accuracy: 42.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.417, Train accuracy: 85.200, Test loss: 1.789, Test accuracy: 46.80 

Round  10, Train loss: 0.681, Test loss: 1.858, Test accuracy: 52.70 

        train local model (freeze embeding):client   0,  Train loss: 0.647, Train accuracy: 73.000, Test loss: 1.423, Test accuracy: 56.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.121, Train accuracy: 96.600, Test loss: 2.056, Test accuracy: 60.00 

        train local model (freeze embeding):client   1,  Train loss: 0.815, Train accuracy: 64.400, Test loss: 1.556, Test accuracy: 43.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.368, Train accuracy: 86.600, Test loss: 1.930, Test accuracy: 46.00 

Round  11, Train loss: 0.673, Test loss: 1.829, Test accuracy: 51.50 

        train local model (freeze embeding):client   0,  Train loss: 0.565, Train accuracy: 78.000, Test loss: 1.307, Test accuracy: 60.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.061, Train accuracy: 98.600, Test loss: 1.912, Test accuracy: 59.80 

        train local model (freeze embeding):client   1,  Train loss: 0.851, Train accuracy: 65.600, Test loss: 1.631, Test accuracy: 44.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.457, Train accuracy: 83.000, Test loss: 2.050, Test accuracy: 47.60 

Round  12, Train loss: 0.688, Test loss: 1.920, Test accuracy: 52.30 

        train local model (freeze embeding):client   0,  Train loss: 0.600, Train accuracy: 76.800, Test loss: 1.312, Test accuracy: 56.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.071, Train accuracy: 98.400, Test loss: 1.803, Test accuracy: 59.80 

        train local model (freeze embeding):client   1,  Train loss: 0.839, Train accuracy: 66.600, Test loss: 1.655, Test accuracy: 44.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.281, Train accuracy: 90.800, Test loss: 1.987, Test accuracy: 49.00 

Round  13, Train loss: 0.683, Test loss: 1.831, Test accuracy: 54.00 

        train local model (freeze embeding):client   0,  Train loss: 0.697, Train accuracy: 71.200, Test loss: 1.340, Test accuracy: 57.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.151, Train accuracy: 94.600, Test loss: 1.607, Test accuracy: 60.80 

        train local model (freeze embeding):client   1,  Train loss: 0.929, Train accuracy: 57.200, Test loss: 1.667, Test accuracy: 43.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.420, Train accuracy: 84.000, Test loss: 2.213, Test accuracy: 48.20 

Round  14, Train loss: 0.711, Test loss: 1.742, Test accuracy: 53.60 

        train local model (freeze embeding):client   0,  Train loss: 0.894, Train accuracy: 65.200, Test loss: 1.553, Test accuracy: 49.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.184, Train accuracy: 92.600, Test loss: 2.152, Test accuracy: 57.60 

        train local model (freeze embeding):client   1,  Train loss: 0.771, Train accuracy: 69.800, Test loss: 1.546, Test accuracy: 43.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.483, Train accuracy: 81.000, Test loss: 1.959, Test accuracy: 43.80 

Round  15, Train loss: 0.701, Test loss: 1.825, Test accuracy: 51.90 

        train local model (freeze embeding):client   0,  Train loss: 0.674, Train accuracy: 73.600, Test loss: 1.310, Test accuracy: 56.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.152, Train accuracy: 94.400, Test loss: 1.756, Test accuracy: 60.60 

        train local model (freeze embeding):client   1,  Train loss: 0.725, Train accuracy: 69.000, Test loss: 1.622, Test accuracy: 44.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.249, Train accuracy: 92.200, Test loss: 2.039, Test accuracy: 45.60 

Round  16, Train loss: 0.679, Test loss: 1.817, Test accuracy: 53.40 

        train local model (freeze embeding):client   0,  Train loss: 0.761, Train accuracy: 69.600, Test loss: 1.468, Test accuracy: 49.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.402, Train accuracy: 85.000, Test loss: 2.423, Test accuracy: 54.00 

        train local model (freeze embeding):client   1,  Train loss: 0.930, Train accuracy: 63.600, Test loss: 1.734, Test accuracy: 42.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.354, Train accuracy: 87.200, Test loss: 2.413, Test accuracy: 45.80 

Round  17, Train loss: 0.668, Test loss: 2.075, Test accuracy: 51.30 

        train local model (freeze embeding):client   0,  Train loss: 0.884, Train accuracy: 68.800, Test loss: 1.561, Test accuracy: 49.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.110, Train accuracy: 95.800, Test loss: 1.851, Test accuracy: 60.40 

        train local model (freeze embeding):client   1,  Train loss: 0.689, Train accuracy: 71.600, Test loss: 1.679, Test accuracy: 42.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.367, Train accuracy: 84.800, Test loss: 2.326, Test accuracy: 45.60 

Round  18, Train loss: 0.675, Test loss: 1.981, Test accuracy: 52.20 

        train local model (freeze embeding):client   0,  Train loss: 0.686, Train accuracy: 71.800, Test loss: 1.392, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.096, Train accuracy: 97.000, Test loss: 1.775, Test accuracy: 60.20 

        train local model (freeze embeding):client   1,  Train loss: 0.923, Train accuracy: 61.400, Test loss: 1.736, Test accuracy: 43.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.219, Train accuracy: 94.000, Test loss: 2.103, Test accuracy: 48.80 

Round  19, Train loss: 0.686, Test loss: 1.925, Test accuracy: 53.80 

        train local model (freeze embeding):client   0,  Train loss: 0.629, Train accuracy: 75.400, Test loss: 1.317, Test accuracy: 57.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.081, Train accuracy: 98.200, Test loss: 1.666, Test accuracy: 61.40 

        train local model (freeze embeding):client   1,  Train loss: 0.801, Train accuracy: 66.400, Test loss: 1.635, Test accuracy: 44.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.310, Train accuracy: 87.200, Test loss: 2.450, Test accuracy: 44.40 

Final Round, Train loss: 0.685, Test loss: 1.950, Test accuracy: 53.80 

---------------------------------------------train_client: [0, 1, 2] 

        init --> train local model(freeze embeding):client   2,  Train loss: 1.243, Train accuracy: 53.000, Test loss: 1.395, Test accuracy: 49.20 

        train local model (freeze embeding):client   0,  Train loss: 0.572, Train accuracy: 77.200, Test loss: 1.270, Test accuracy: 55.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.299, Train accuracy: 90.200, Test loss: 2.206, Test accuracy: 55.40 

        train local model (freeze embeding):client   1,  Train loss: 0.942, Train accuracy: 62.600, Test loss: 1.856, Test accuracy: 40.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.256, Train accuracy: 90.600, Test loss: 2.333, Test accuracy: 46.80 

        train local model (freeze embeding):client   2,  Train loss: 1.097, Train accuracy: 52.600, Test loss: 1.222, Test accuracy: 51.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.725, Train accuracy: 70.400, Test loss: 1.112, Test accuracy: 54.60 

Round   0, Train loss: 0.826, Test loss: 1.643, Test accuracy: 53.47 

        train local model (freeze embeding):client   0,  Train loss: 0.697, Train accuracy: 72.200, Test loss: 1.365, Test accuracy: 56.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.092, Train accuracy: 97.600, Test loss: 1.705, Test accuracy: 60.80 

        train local model (freeze embeding):client   1,  Train loss: 0.745, Train accuracy: 70.400, Test loss: 1.639, Test accuracy: 42.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.228, Train accuracy: 92.600, Test loss: 2.380, Test accuracy: 47.80 

        train local model (freeze embeding):client   2,  Train loss: 0.953, Train accuracy: 58.400, Test loss: 1.146, Test accuracy: 54.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.761, Train accuracy: 69.000, Test loss: 1.193, Test accuracy: 55.00 

Round   1, Train loss: 0.792, Test loss: 1.605, Test accuracy: 53.60 

        train local model (freeze embeding):client   0,  Train loss: 0.614, Train accuracy: 76.400, Test loss: 1.289, Test accuracy: 54.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.116, Train accuracy: 96.400, Test loss: 1.816, Test accuracy: 60.00 

        train local model (freeze embeding):client   1,  Train loss: 0.763, Train accuracy: 67.000, Test loss: 1.660, Test accuracy: 44.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.294, Train accuracy: 88.400, Test loss: 2.242, Test accuracy: 48.00 

        train local model (freeze embeding):client   2,  Train loss: 0.955, Train accuracy: 61.000, Test loss: 1.151, Test accuracy: 54.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.719, Train accuracy: 71.800, Test loss: 1.270, Test accuracy: 53.40 

Round   2, Train loss: 0.795, Test loss: 1.634, Test accuracy: 53.60 

        train local model (freeze embeding):client   0,  Train loss: 0.717, Train accuracy: 69.800, Test loss: 1.279, Test accuracy: 54.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.171, Train accuracy: 94.600, Test loss: 1.876, Test accuracy: 54.40 

        train local model (freeze embeding):client   1,  Train loss: 0.910, Train accuracy: 60.800, Test loss: 1.683, Test accuracy: 42.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.237, Train accuracy: 94.000, Test loss: 2.240, Test accuracy: 45.60 

        train local model (freeze embeding):client   2,  Train loss: 0.949, Train accuracy: 61.600, Test loss: 1.163, Test accuracy: 52.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.616, Train accuracy: 75.200, Test loss: 1.174, Test accuracy: 55.60 

Round   3, Train loss: 0.796, Test loss: 1.551, Test accuracy: 53.20 

        train local model (freeze embeding):client   0,  Train loss: 0.831, Train accuracy: 67.200, Test loss: 1.405, Test accuracy: 51.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.088, Train accuracy: 97.600, Test loss: 1.700, Test accuracy: 57.40 

        train local model (freeze embeding):client   1,  Train loss: 0.856, Train accuracy: 64.400, Test loss: 1.653, Test accuracy: 44.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.290, Train accuracy: 90.200, Test loss: 2.370, Test accuracy: 47.00 

        train local model (freeze embeding):client   2,  Train loss: 0.932, Train accuracy: 60.800, Test loss: 1.145, Test accuracy: 54.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.734, Train accuracy: 68.800, Test loss: 1.331, Test accuracy: 53.60 

Round   4, Train loss: 0.797, Test loss: 1.578, Test accuracy: 53.40 

        train local model (freeze embeding):client   0,  Train loss: 0.761, Train accuracy: 68.000, Test loss: 1.340, Test accuracy: 51.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.172, Train accuracy: 95.000, Test loss: 1.733, Test accuracy: 58.00 

        train local model (freeze embeding):client   1,  Train loss: 1.134, Train accuracy: 54.600, Test loss: 1.997, Test accuracy: 41.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.205, Train accuracy: 93.200, Test loss: 2.219, Test accuracy: 46.80 

        train local model (freeze embeding):client   2,  Train loss: 1.045, Train accuracy: 57.200, Test loss: 1.286, Test accuracy: 52.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.577, Train accuracy: 77.800, Test loss: 1.286, Test accuracy: 52.40 

Round   5, Train loss: 0.779, Test loss: 1.605, Test accuracy: 54.40 

        train local model (freeze embeding):client   0,  Train loss: 0.799, Train accuracy: 64.600, Test loss: 1.349, Test accuracy: 53.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.170, Train accuracy: 94.200, Test loss: 1.797, Test accuracy: 57.20 

        train local model (freeze embeding):client   1,  Train loss: 0.945, Train accuracy: 58.000, Test loss: 1.766, Test accuracy: 40.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.405, Train accuracy: 83.800, Test loss: 2.516, Test accuracy: 47.00 

        train local model (freeze embeding):client   2,  Train loss: 0.937, Train accuracy: 58.600, Test loss: 1.203, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.552, Train accuracy: 80.200, Test loss: 1.268, Test accuracy: 54.40 

Round   6, Train loss: 0.796, Test loss: 1.665, Test accuracy: 53.40 

        train local model (freeze embeding):client   0,  Train loss: 0.761, Train accuracy: 66.000, Test loss: 1.406, Test accuracy: 50.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.136, Train accuracy: 95.600, Test loss: 1.608, Test accuracy: 60.60 

        train local model (freeze embeding):client   1,  Train loss: 0.756, Train accuracy: 69.200, Test loss: 1.566, Test accuracy: 44.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.292, Train accuracy: 87.800, Test loss: 2.226, Test accuracy: 45.00 

        train local model (freeze embeding):client   2,  Train loss: 1.005, Train accuracy: 58.800, Test loss: 1.281, Test accuracy: 51.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.481, Train accuracy: 80.600, Test loss: 1.336, Test accuracy: 53.00 

Round   7, Train loss: 0.777, Test loss: 1.621, Test accuracy: 52.60 

        train local model (freeze embeding):client   0,  Train loss: 0.720, Train accuracy: 69.600, Test loss: 1.331, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.138, Train accuracy: 95.600, Test loss: 1.852, Test accuracy: 61.20 

        train local model (freeze embeding):client   1,  Train loss: 0.812, Train accuracy: 68.400, Test loss: 1.585, Test accuracy: 46.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.237, Train accuracy: 91.600, Test loss: 2.099, Test accuracy: 46.20 

        train local model (freeze embeding):client   2,  Train loss: 0.852, Train accuracy: 64.200, Test loss: 1.124, Test accuracy: 56.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.464, Train accuracy: 81.000, Test loss: 1.259, Test accuracy: 54.40 

Round   8, Train loss: 0.754, Test loss: 1.591, Test accuracy: 52.67 

        train local model (freeze embeding):client   0,  Train loss: 0.816, Train accuracy: 64.600, Test loss: 1.440, Test accuracy: 49.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.120, Train accuracy: 95.600, Test loss: 1.778, Test accuracy: 58.40 

        train local model (freeze embeding):client   1,  Train loss: 0.833, Train accuracy: 64.800, Test loss: 1.709, Test accuracy: 41.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.191, Train accuracy: 94.000, Test loss: 2.164, Test accuracy: 48.20 

        train local model (freeze embeding):client   2,  Train loss: 0.815, Train accuracy: 66.800, Test loss: 1.135, Test accuracy: 56.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.494, Train accuracy: 80.600, Test loss: 1.330, Test accuracy: 54.60 

Round   9, Train loss: 0.772, Test loss: 1.636, Test accuracy: 52.93 

        train local model (freeze embeding):client   0,  Train loss: 0.772, Train accuracy: 65.400, Test loss: 1.438, Test accuracy: 49.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.228, Train accuracy: 91.600, Test loss: 1.787, Test accuracy: 57.20 

        train local model (freeze embeding):client   1,  Train loss: 1.032, Train accuracy: 58.600, Test loss: 1.917, Test accuracy: 42.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.215, Train accuracy: 92.600, Test loss: 2.212, Test accuracy: 49.00 

        train local model (freeze embeding):client   2,  Train loss: 0.801, Train accuracy: 66.800, Test loss: 1.095, Test accuracy: 57.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.449, Train accuracy: 82.800, Test loss: 1.356, Test accuracy: 54.80 

Round  10, Train loss: 0.763, Test loss: 1.692, Test accuracy: 53.13 

        train local model (freeze embeding):client   0,  Train loss: 0.742, Train accuracy: 68.800, Test loss: 1.323, Test accuracy: 50.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.138, Train accuracy: 95.600, Test loss: 1.790, Test accuracy: 57.40 

        train local model (freeze embeding):client   1,  Train loss: 0.821, Train accuracy: 68.200, Test loss: 1.626, Test accuracy: 44.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.215, Train accuracy: 93.000, Test loss: 2.248, Test accuracy: 46.80 

        train local model (freeze embeding):client   2,  Train loss: 0.886, Train accuracy: 63.000, Test loss: 1.152, Test accuracy: 54.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.382, Train accuracy: 86.000, Test loss: 1.228, Test accuracy: 56.60 

Round  11, Train loss: 0.764, Test loss: 1.664, Test accuracy: 51.73 

        train local model (freeze embeding):client   0,  Train loss: 0.714, Train accuracy: 72.000, Test loss: 1.316, Test accuracy: 53.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.157, Train accuracy: 94.600, Test loss: 1.638, Test accuracy: 57.80 

        train local model (freeze embeding):client   1,  Train loss: 0.788, Train accuracy: 71.200, Test loss: 1.727, Test accuracy: 45.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.174, Train accuracy: 95.600, Test loss: 2.216, Test accuracy: 48.20 

        train local model (freeze embeding):client   2,  Train loss: 0.916, Train accuracy: 62.200, Test loss: 1.270, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.469, Train accuracy: 80.800, Test loss: 1.375, Test accuracy: 55.00 

Round  12, Train loss: 0.761, Test loss: 1.668, Test accuracy: 53.20 

        train local model (freeze embeding):client   0,  Train loss: 0.787, Train accuracy: 66.000, Test loss: 1.366, Test accuracy: 50.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.151, Train accuracy: 94.800, Test loss: 1.678, Test accuracy: 60.80 

        train local model (freeze embeding):client   1,  Train loss: 0.966, Train accuracy: 60.000, Test loss: 1.848, Test accuracy: 40.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.202, Train accuracy: 93.800, Test loss: 2.144, Test accuracy: 46.20 

        train local model (freeze embeding):client   2,  Train loss: 0.801, Train accuracy: 68.400, Test loss: 1.178, Test accuracy: 54.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.500, Train accuracy: 81.400, Test loss: 1.408, Test accuracy: 53.00 

Round  13, Train loss: 0.761, Test loss: 1.616, Test accuracy: 53.20 

        train local model (freeze embeding):client   0,  Train loss: 0.855, Train accuracy: 64.600, Test loss: 1.423, Test accuracy: 51.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.206, Train accuracy: 91.800, Test loss: 1.971, Test accuracy: 58.20 

        train local model (freeze embeding):client   1,  Train loss: 0.767, Train accuracy: 69.600, Test loss: 1.629, Test accuracy: 44.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.321, Train accuracy: 89.800, Test loss: 2.130, Test accuracy: 47.60 

        train local model (freeze embeding):client   2,  Train loss: 0.763, Train accuracy: 71.800, Test loss: 1.129, Test accuracy: 57.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.433, Train accuracy: 82.200, Test loss: 1.331, Test accuracy: 52.60 

Round  14, Train loss: 0.756, Test loss: 1.690, Test accuracy: 53.47 

        train local model (freeze embeding):client   0,  Train loss: 0.845, Train accuracy: 65.200, Test loss: 1.350, Test accuracy: 52.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.147, Train accuracy: 95.000, Test loss: 1.598, Test accuracy: 61.20 

        train local model (freeze embeding):client   1,  Train loss: 0.908, Train accuracy: 63.000, Test loss: 1.757, Test accuracy: 41.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.229, Train accuracy: 91.600, Test loss: 2.361, Test accuracy: 45.60 

        train local model (freeze embeding):client   2,  Train loss: 0.789, Train accuracy: 68.000, Test loss: 1.190, Test accuracy: 54.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.389, Train accuracy: 85.200, Test loss: 1.330, Test accuracy: 56.60 

Round  15, Train loss: 0.753, Test loss: 1.621, Test accuracy: 53.67 

        train local model (freeze embeding):client   0,  Train loss: 0.742, Train accuracy: 69.600, Test loss: 1.294, Test accuracy: 54.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.113, Train accuracy: 97.600, Test loss: 1.594, Test accuracy: 60.80 

        train local model (freeze embeding):client   1,  Train loss: 0.844, Train accuracy: 65.000, Test loss: 1.685, Test accuracy: 41.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.343, Train accuracy: 86.000, Test loss: 2.372, Test accuracy: 47.00 

        train local model (freeze embeding):client   2,  Train loss: 0.820, Train accuracy: 68.000, Test loss: 1.196, Test accuracy: 53.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.451, Train accuracy: 82.000, Test loss: 1.390, Test accuracy: 56.80 

Round  16, Train loss: 0.768, Test loss: 1.626, Test accuracy: 54.13 

        train local model (freeze embeding):client   0,  Train loss: 0.804, Train accuracy: 65.200, Test loss: 1.351, Test accuracy: 48.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.236, Train accuracy: 91.600, Test loss: 1.903, Test accuracy: 54.80 

        train local model (freeze embeding):client   1,  Train loss: 1.032, Train accuracy: 56.800, Test loss: 1.816, Test accuracy: 40.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.236, Train accuracy: 92.400, Test loss: 2.200, Test accuracy: 46.20 

        train local model (freeze embeding):client   2,  Train loss: 0.878, Train accuracy: 62.000, Test loss: 1.238, Test accuracy: 53.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.365, Train accuracy: 86.800, Test loss: 1.335, Test accuracy: 55.80 

Round  17, Train loss: 0.761, Test loss: 1.678, Test accuracy: 52.47 

        train local model (freeze embeding):client   0,  Train loss: 0.932, Train accuracy: 60.000, Test loss: 1.439, Test accuracy: 52.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.161, Train accuracy: 95.200, Test loss: 1.641, Test accuracy: 58.40 

        train local model (freeze embeding):client   1,  Train loss: 0.839, Train accuracy: 65.000, Test loss: 1.652, Test accuracy: 42.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.305, Train accuracy: 87.600, Test loss: 2.424, Test accuracy: 45.40 

        train local model (freeze embeding):client   2,  Train loss: 0.758, Train accuracy: 68.800, Test loss: 1.158, Test accuracy: 56.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.332, Train accuracy: 88.200, Test loss: 1.284, Test accuracy: 55.20 

Round  18, Train loss: 0.763, Test loss: 1.661, Test accuracy: 53.80 

        train local model (freeze embeding):client   0,  Train loss: 0.854, Train accuracy: 59.400, Test loss: 1.427, Test accuracy: 46.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.262, Train accuracy: 90.200, Test loss: 1.866, Test accuracy: 54.60 

        train local model (freeze embeding):client   1,  Train loss: 0.885, Train accuracy: 64.600, Test loss: 1.782, Test accuracy: 42.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.350, Train accuracy: 86.600, Test loss: 2.076, Test accuracy: 48.40 

        train local model (freeze embeding):client   2,  Train loss: 0.793, Train accuracy: 67.200, Test loss: 1.156, Test accuracy: 58.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.395, Train accuracy: 83.400, Test loss: 1.481, Test accuracy: 52.80 

Round  19, Train loss: 0.742, Test loss: 1.664, Test accuracy: 52.40 

        train local model (freeze embeding):client   0,  Train loss: 0.789, Train accuracy: 64.200, Test loss: 1.300, Test accuracy: 51.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.200, Train accuracy: 94.000, Test loss: 1.649, Test accuracy: 59.40 

        train local model (freeze embeding):client   1,  Train loss: 0.778, Train accuracy: 67.800, Test loss: 1.642, Test accuracy: 43.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.359, Train accuracy: 86.600, Test loss: 2.434, Test accuracy: 44.80 

        train local model (freeze embeding):client   2,  Train loss: 0.878, Train accuracy: 59.200, Test loss: 1.300, Test accuracy: 50.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.306, Train accuracy: 89.600, Test loss: 1.444, Test accuracy: 57.80 

Final Round, Train loss: 0.736, Test loss: 1.649, Test accuracy: 52.47 

---------------------------------------------train_client: [0, 1, 2, 3] 

        init --> train local model(freeze embeding):client   3,  Train loss: 1.038, Train accuracy: 57.000, Test loss: 1.053, Test accuracy: 60.80 

        train local model (freeze embeding):client   0,  Train loss: 1.149, Train accuracy: 60.200, Test loss: 1.653, Test accuracy: 51.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.161, Train accuracy: 94.000, Test loss: 1.605, Test accuracy: 59.40 

        train local model (freeze embeding):client   1,  Train loss: 0.842, Train accuracy: 64.600, Test loss: 1.657, Test accuracy: 43.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.343, Train accuracy: 86.200, Test loss: 2.393, Test accuracy: 45.60 

        train local model (freeze embeding):client   2,  Train loss: 0.875, Train accuracy: 63.000, Test loss: 1.254, Test accuracy: 54.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.297, Train accuracy: 90.400, Test loss: 1.349, Test accuracy: 55.80 

        train local model (freeze embeding):client   3,  Train loss: 0.970, Train accuracy: 64.400, Test loss: 1.033, Test accuracy: 59.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.921, Train accuracy: 62.600, Test loss: 1.228, Test accuracy: 55.20 

Round   0, Train loss: 0.851, Test loss: 1.457, Test accuracy: 56.45 

        train local model (freeze embeding):client   0,  Train loss: 0.734, Train accuracy: 69.400, Test loss: 1.277, Test accuracy: 52.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.128, Train accuracy: 97.000, Test loss: 1.603, Test accuracy: 62.00 

        train local model (freeze embeding):client   1,  Train loss: 0.983, Train accuracy: 60.000, Test loss: 1.695, Test accuracy: 43.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.239, Train accuracy: 92.200, Test loss: 2.373, Test accuracy: 46.00 

        train local model (freeze embeding):client   2,  Train loss: 0.768, Train accuracy: 70.800, Test loss: 1.136, Test accuracy: 58.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.377, Train accuracy: 83.600, Test loss: 1.485, Test accuracy: 53.80 

        train local model (freeze embeding):client   3,  Train loss: 1.111, Train accuracy: 55.800, Test loss: 1.142, Test accuracy: 58.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.764, Train accuracy: 69.200, Test loss: 1.176, Test accuracy: 60.00 

Round   1, Train loss: 0.833, Test loss: 1.497, Test accuracy: 55.55 

        train local model (freeze embeding):client   0,  Train loss: 0.825, Train accuracy: 67.400, Test loss: 1.363, Test accuracy: 52.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.183, Train accuracy: 93.600, Test loss: 1.711, Test accuracy: 60.60 

        train local model (freeze embeding):client   1,  Train loss: 0.931, Train accuracy: 62.400, Test loss: 1.734, Test accuracy: 45.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.198, Train accuracy: 94.200, Test loss: 2.159, Test accuracy: 47.40 

        train local model (freeze embeding):client   2,  Train loss: 0.807, Train accuracy: 68.000, Test loss: 1.176, Test accuracy: 55.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.366, Train accuracy: 86.600, Test loss: 1.445, Test accuracy: 52.80 

        train local model (freeze embeding):client   3,  Train loss: 1.022, Train accuracy: 59.000, Test loss: 1.099, Test accuracy: 59.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.672, Train accuracy: 73.000, Test loss: 1.151, Test accuracy: 59.40 

Round   2, Train loss: 0.833, Test loss: 1.504, Test accuracy: 55.30 

        train local model (freeze embeding):client   0,  Train loss: 0.910, Train accuracy: 61.400, Test loss: 1.356, Test accuracy: 53.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.153, Train accuracy: 95.200, Test loss: 1.548, Test accuracy: 60.40 

        train local model (freeze embeding):client   1,  Train loss: 0.905, Train accuracy: 61.200, Test loss: 1.715, Test accuracy: 44.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.220, Train accuracy: 91.800, Test loss: 2.206, Test accuracy: 47.00 

        train local model (freeze embeding):client   2,  Train loss: 0.953, Train accuracy: 61.800, Test loss: 1.275, Test accuracy: 55.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.356, Train accuracy: 86.800, Test loss: 1.475, Test accuracy: 53.60 

        train local model (freeze embeding):client   3,  Train loss: 0.944, Train accuracy: 59.800, Test loss: 1.077, Test accuracy: 58.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.679, Train accuracy: 72.000, Test loss: 1.224, Test accuracy: 59.40 

Round   3, Train loss: 0.839, Test loss: 1.474, Test accuracy: 56.10 

        train local model (freeze embeding):client   0,  Train loss: 0.802, Train accuracy: 67.200, Test loss: 1.293, Test accuracy: 55.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.129, Train accuracy: 97.200, Test loss: 1.700, Test accuracy: 57.20 

        train local model (freeze embeding):client   1,  Train loss: 0.831, Train accuracy: 66.200, Test loss: 1.650, Test accuracy: 41.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.201, Train accuracy: 93.600, Test loss: 2.288, Test accuracy: 46.00 

        train local model (freeze embeding):client   2,  Train loss: 0.746, Train accuracy: 69.800, Test loss: 1.161, Test accuracy: 56.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.438, Train accuracy: 82.800, Test loss: 1.542, Test accuracy: 52.80 

        train local model (freeze embeding):client   3,  Train loss: 1.043, Train accuracy: 58.800, Test loss: 1.166, Test accuracy: 54.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.590, Train accuracy: 78.200, Test loss: 1.103, Test accuracy: 61.00 

Round   4, Train loss: 0.806, Test loss: 1.504, Test accuracy: 55.35 

        train local model (freeze embeding):client   0,  Train loss: 0.918, Train accuracy: 59.400, Test loss: 1.412, Test accuracy: 47.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.284, Train accuracy: 90.200, Test loss: 1.836, Test accuracy: 53.80 

        train local model (freeze embeding):client   1,  Train loss: 0.887, Train accuracy: 62.400, Test loss: 1.612, Test accuracy: 43.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.231, Train accuracy: 93.600, Test loss: 2.183, Test accuracy: 48.40 

        train local model (freeze embeding):client   2,  Train loss: 0.777, Train accuracy: 68.600, Test loss: 1.222, Test accuracy: 53.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.348, Train accuracy: 87.000, Test loss: 1.406, Test accuracy: 52.40 

        train local model (freeze embeding):client   3,  Train loss: 0.917, Train accuracy: 61.200, Test loss: 1.140, Test accuracy: 55.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.606, Train accuracy: 76.000, Test loss: 1.172, Test accuracy: 61.40 

Round   5, Train loss: 0.829, Test loss: 1.469, Test accuracy: 56.35 

        train local model (freeze embeding):client   0,  Train loss: 0.809, Train accuracy: 66.000, Test loss: 1.271, Test accuracy: 53.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.193, Train accuracy: 93.200, Test loss: 1.651, Test accuracy: 59.80 

        train local model (freeze embeding):client   1,  Train loss: 0.973, Train accuracy: 58.600, Test loss: 1.777, Test accuracy: 39.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.196, Train accuracy: 93.200, Test loss: 2.172, Test accuracy: 47.60 

        train local model (freeze embeding):client   2,  Train loss: 0.936, Train accuracy: 62.400, Test loss: 1.312, Test accuracy: 53.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.356, Train accuracy: 86.000, Test loss: 1.442, Test accuracy: 54.00 

        train local model (freeze embeding):client   3,  Train loss: 1.197, Train accuracy: 51.800, Test loss: 1.342, Test accuracy: 49.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.572, Train accuracy: 78.400, Test loss: 1.067, Test accuracy: 61.40 

Round   6, Train loss: 0.822, Test loss: 1.450, Test accuracy: 56.60 

        train local model (freeze embeding):client   0,  Train loss: 0.857, Train accuracy: 66.000, Test loss: 1.333, Test accuracy: 53.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.204, Train accuracy: 92.200, Test loss: 1.637, Test accuracy: 59.20 

        train local model (freeze embeding):client   1,  Train loss: 0.871, Train accuracy: 65.400, Test loss: 1.664, Test accuracy: 45.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.276, Train accuracy: 90.400, Test loss: 2.185, Test accuracy: 47.60 

        train local model (freeze embeding):client   2,  Train loss: 1.014, Train accuracy: 55.400, Test loss: 1.336, Test accuracy: 47.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.354, Train accuracy: 85.800, Test loss: 1.385, Test accuracy: 55.00 

        train local model (freeze embeding):client   3,  Train loss: 0.897, Train accuracy: 60.000, Test loss: 1.092, Test accuracy: 57.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.523, Train accuracy: 80.200, Test loss: 1.140, Test accuracy: 59.60 

Round   7, Train loss: 0.818, Test loss: 1.492, Test accuracy: 56.10 

        train local model (freeze embeding):client   0,  Train loss: 0.890, Train accuracy: 61.000, Test loss: 1.297, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.194, Train accuracy: 93.200, Test loss: 1.708, Test accuracy: 56.00 

        train local model (freeze embeding):client   1,  Train loss: 0.855, Train accuracy: 65.200, Test loss: 1.618, Test accuracy: 43.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.208, Train accuracy: 93.400, Test loss: 2.101, Test accuracy: 48.60 

        train local model (freeze embeding):client   2,  Train loss: 0.822, Train accuracy: 65.400, Test loss: 1.199, Test accuracy: 56.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.339, Train accuracy: 86.000, Test loss: 1.398, Test accuracy: 56.00 

        train local model (freeze embeding):client   3,  Train loss: 0.863, Train accuracy: 65.600, Test loss: 1.086, Test accuracy: 59.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.576, Train accuracy: 76.600, Test loss: 1.334, Test accuracy: 59.60 

Round   8, Train loss: 0.812, Test loss: 1.493, Test accuracy: 56.55 

        train local model (freeze embeding):client   0,  Train loss: 0.995, Train accuracy: 55.200, Test loss: 1.491, Test accuracy: 45.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.210, Train accuracy: 93.000, Test loss: 1.677, Test accuracy: 55.60 

        train local model (freeze embeding):client   1,  Train loss: 0.964, Train accuracy: 62.400, Test loss: 1.683, Test accuracy: 42.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.315, Train accuracy: 87.200, Test loss: 2.336, Test accuracy: 45.60 

        train local model (freeze embeding):client   2,  Train loss: 0.900, Train accuracy: 58.400, Test loss: 1.322, Test accuracy: 51.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.391, Train accuracy: 85.000, Test loss: 1.484, Test accuracy: 53.20 

        train local model (freeze embeding):client   3,  Train loss: 0.836, Train accuracy: 65.400, Test loss: 1.055, Test accuracy: 61.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.534, Train accuracy: 79.000, Test loss: 1.231, Test accuracy: 59.00 

Round   9, Train loss: 0.805, Test loss: 1.513, Test accuracy: 55.40 

        train local model (freeze embeding):client   0,  Train loss: 0.810, Train accuracy: 64.400, Test loss: 1.295, Test accuracy: 54.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.277, Train accuracy: 89.800, Test loss: 1.861, Test accuracy: 55.20 

        train local model (freeze embeding):client   1,  Train loss: 0.859, Train accuracy: 65.200, Test loss: 1.567, Test accuracy: 44.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.485, Train accuracy: 80.000, Test loss: 2.591, Test accuracy: 47.20 

        train local model (freeze embeding):client   2,  Train loss: 0.907, Train accuracy: 64.600, Test loss: 1.269, Test accuracy: 57.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.733, Train accuracy: 72.600, Test loss: 1.830, Test accuracy: 48.80 

        train local model (freeze embeding):client   3,  Train loss: 0.952, Train accuracy: 59.200, Test loss: 1.104, Test accuracy: 58.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.576, Train accuracy: 77.200, Test loss: 1.222, Test accuracy: 59.40 

Round  10, Train loss: 0.818, Test loss: 1.461, Test accuracy: 56.50 

        train local model (freeze embeding):client   0,  Train loss: 0.998, Train accuracy: 57.000, Test loss: 1.386, Test accuracy: 53.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.249, Train accuracy: 89.600, Test loss: 1.709, Test accuracy: 57.20 

        train local model (freeze embeding):client   1,  Train loss: 0.991, Train accuracy: 58.800, Test loss: 1.720, Test accuracy: 42.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.291, Train accuracy: 89.000, Test loss: 2.150, Test accuracy: 46.00 

        train local model (freeze embeding):client   2,  Train loss: 0.861, Train accuracy: 64.000, Test loss: 1.249, Test accuracy: 55.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.384, Train accuracy: 83.200, Test loss: 1.458, Test accuracy: 56.00 

        train local model (freeze embeding):client   3,  Train loss: 0.912, Train accuracy: 60.800, Test loss: 1.157, Test accuracy: 56.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.483, Train accuracy: 81.600, Test loss: 1.281, Test accuracy: 57.60 

Round  11, Train loss: 0.808, Test loss: 1.536, Test accuracy: 55.80 

        train local model (freeze embeding):client   0,  Train loss: 0.906, Train accuracy: 62.800, Test loss: 1.290, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.196, Train accuracy: 94.200, Test loss: 1.679, Test accuracy: 56.60 

        train local model (freeze embeding):client   1,  Train loss: 0.840, Train accuracy: 68.200, Test loss: 1.645, Test accuracy: 45.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.279, Train accuracy: 89.400, Test loss: 2.233, Test accuracy: 45.80 

        train local model (freeze embeding):client   2,  Train loss: 0.917, Train accuracy: 60.600, Test loss: 1.280, Test accuracy: 51.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.297, Train accuracy: 89.600, Test loss: 1.388, Test accuracy: 58.60 

        train local model (freeze embeding):client   3,  Train loss: 0.833, Train accuracy: 65.600, Test loss: 1.113, Test accuracy: 57.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.680, Train accuracy: 71.200, Test loss: 1.379, Test accuracy: 57.40 

Round  12, Train loss: 0.815, Test loss: 1.493, Test accuracy: 56.75 

        train local model (freeze embeding):client   0,  Train loss: 0.830, Train accuracy: 63.400, Test loss: 1.242, Test accuracy: 52.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.175, Train accuracy: 94.800, Test loss: 1.572, Test accuracy: 60.80 

        train local model (freeze embeding):client   1,  Train loss: 0.818, Train accuracy: 68.000, Test loss: 1.626, Test accuracy: 43.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.250, Train accuracy: 91.400, Test loss: 2.155, Test accuracy: 46.40 

        train local model (freeze embeding):client   2,  Train loss: 0.953, Train accuracy: 61.800, Test loss: 1.293, Test accuracy: 52.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.324, Train accuracy: 87.200, Test loss: 1.472, Test accuracy: 56.80 

        train local model (freeze embeding):client   3,  Train loss: 0.889, Train accuracy: 64.400, Test loss: 1.118, Test accuracy: 58.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.422, Train accuracy: 84.400, Test loss: 1.190, Test accuracy: 60.80 

Round  13, Train loss: 0.809, Test loss: 1.503, Test accuracy: 55.80 

        train local model (freeze embeding):client   0,  Train loss: 0.947, Train accuracy: 59.000, Test loss: 1.356, Test accuracy: 51.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.216, Train accuracy: 93.200, Test loss: 1.761, Test accuracy: 55.80 

        train local model (freeze embeding):client   1,  Train loss: 0.876, Train accuracy: 63.400, Test loss: 1.623, Test accuracy: 40.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.260, Train accuracy: 92.200, Test loss: 2.164, Test accuracy: 45.60 

        train local model (freeze embeding):client   2,  Train loss: 0.827, Train accuracy: 67.800, Test loss: 1.245, Test accuracy: 54.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.320, Train accuracy: 88.200, Test loss: 1.460, Test accuracy: 58.40 

        train local model (freeze embeding):client   3,  Train loss: 0.904, Train accuracy: 64.800, Test loss: 1.184, Test accuracy: 57.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.457, Train accuracy: 81.600, Test loss: 1.356, Test accuracy: 56.60 

Round  14, Train loss: 0.804, Test loss: 1.509, Test accuracy: 55.30 

        train local model (freeze embeding):client   0,  Train loss: 0.881, Train accuracy: 60.600, Test loss: 1.345, Test accuracy: 50.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.264, Train accuracy: 88.800, Test loss: 1.839, Test accuracy: 52.40 

        train local model (freeze embeding):client   1,  Train loss: 1.259, Train accuracy: 51.000, Test loss: 2.041, Test accuracy: 36.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.273, Train accuracy: 90.000, Test loss: 2.082, Test accuracy: 46.80 

        train local model (freeze embeding):client   2,  Train loss: 0.933, Train accuracy: 60.000, Test loss: 1.285, Test accuracy: 49.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.369, Train accuracy: 86.200, Test loss: 1.406, Test accuracy: 53.80 

        train local model (freeze embeding):client   3,  Train loss: 0.842, Train accuracy: 66.600, Test loss: 1.166, Test accuracy: 55.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.448, Train accuracy: 84.000, Test loss: 1.350, Test accuracy: 57.20 

Round  15, Train loss: 0.816, Test loss: 1.507, Test accuracy: 55.00 

        train local model (freeze embeding):client   0,  Train loss: 0.863, Train accuracy: 63.600, Test loss: 1.279, Test accuracy: 51.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.181, Train accuracy: 94.600, Test loss: 1.699, Test accuracy: 57.00 

        train local model (freeze embeding):client   1,  Train loss: 0.851, Train accuracy: 66.400, Test loss: 1.552, Test accuracy: 43.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.320, Train accuracy: 87.200, Test loss: 2.223, Test accuracy: 48.20 

        train local model (freeze embeding):client   2,  Train loss: 0.927, Train accuracy: 60.000, Test loss: 1.308, Test accuracy: 48.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.367, Train accuracy: 87.400, Test loss: 1.532, Test accuracy: 53.20 

        train local model (freeze embeding):client   3,  Train loss: 0.883, Train accuracy: 62.000, Test loss: 1.153, Test accuracy: 54.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.416, Train accuracy: 85.800, Test loss: 1.305, Test accuracy: 56.40 

Round  16, Train loss: 0.803, Test loss: 1.570, Test accuracy: 54.50 

        train local model (freeze embeding):client   0,  Train loss: 0.820, Train accuracy: 66.400, Test loss: 1.235, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.203, Train accuracy: 92.600, Test loss: 1.580, Test accuracy: 57.80 

        train local model (freeze embeding):client   1,  Train loss: 0.877, Train accuracy: 66.000, Test loss: 1.552, Test accuracy: 42.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.260, Train accuracy: 91.400, Test loss: 2.164, Test accuracy: 47.60 

        train local model (freeze embeding):client   2,  Train loss: 1.059, Train accuracy: 57.800, Test loss: 1.440, Test accuracy: 48.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.274, Train accuracy: 89.600, Test loss: 1.397, Test accuracy: 54.80 

        train local model (freeze embeding):client   3,  Train loss: 0.831, Train accuracy: 66.800, Test loss: 1.155, Test accuracy: 58.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.395, Train accuracy: 85.800, Test loss: 1.279, Test accuracy: 57.20 

Round  17, Train loss: 0.802, Test loss: 1.496, Test accuracy: 55.35 

        train local model (freeze embeding):client   0,  Train loss: 0.859, Train accuracy: 64.800, Test loss: 1.256, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.372, Train accuracy: 85.600, Test loss: 1.770, Test accuracy: 57.40 

        train local model (freeze embeding):client   1,  Train loss: 0.917, Train accuracy: 63.000, Test loss: 1.556, Test accuracy: 45.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.221, Train accuracy: 93.600, Test loss: 2.106, Test accuracy: 46.80 

        train local model (freeze embeding):client   2,  Train loss: 0.825, Train accuracy: 66.600, Test loss: 1.219, Test accuracy: 55.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.315, Train accuracy: 88.600, Test loss: 1.415, Test accuracy: 53.80 

        train local model (freeze embeding):client   3,  Train loss: 1.034, Train accuracy: 60.600, Test loss: 1.314, Test accuracy: 54.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.526, Train accuracy: 78.400, Test loss: 1.590, Test accuracy: 51.20 

Round  18, Train loss: 0.812, Test loss: 1.513, Test accuracy: 55.35 

        train local model (freeze embeding):client   0,  Train loss: 0.952, Train accuracy: 60.400, Test loss: 1.333, Test accuracy: 51.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.168, Train accuracy: 94.000, Test loss: 1.627, Test accuracy: 60.40 

        train local model (freeze embeding):client   1,  Train loss: 0.878, Train accuracy: 62.800, Test loss: 1.632, Test accuracy: 43.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.337, Train accuracy: 85.400, Test loss: 2.304, Test accuracy: 45.00 

        train local model (freeze embeding):client   2,  Train loss: 0.853, Train accuracy: 66.200, Test loss: 1.208, Test accuracy: 55.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.390, Train accuracy: 85.200, Test loss: 1.451, Test accuracy: 55.80 

        train local model (freeze embeding):client   3,  Train loss: 0.830, Train accuracy: 65.800, Test loss: 1.124, Test accuracy: 58.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.547, Train accuracy: 81.200, Test loss: 1.378, Test accuracy: 57.20 

Round  19, Train loss: 0.799, Test loss: 1.523, Test accuracy: 54.75 

        train local model (freeze embeding):client   0,  Train loss: 0.888, Train accuracy: 61.000, Test loss: 1.286, Test accuracy: 51.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.218, Train accuracy: 92.800, Test loss: 1.518, Test accuracy: 59.60 

        train local model (freeze embeding):client   1,  Train loss: 0.990, Train accuracy: 55.000, Test loss: 1.695, Test accuracy: 40.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.233, Train accuracy: 92.200, Test loss: 2.116, Test accuracy: 47.00 

        train local model (freeze embeding):client   2,  Train loss: 0.880, Train accuracy: 66.200, Test loss: 1.251, Test accuracy: 56.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.289, Train accuracy: 90.200, Test loss: 1.350, Test accuracy: 56.20 

        train local model (freeze embeding):client   3,  Train loss: 0.838, Train accuracy: 66.400, Test loss: 1.152, Test accuracy: 58.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.466, Train accuracy: 82.000, Test loss: 1.456, Test accuracy: 53.00 

Final Round, Train loss: 0.802, Test loss: 1.519, Test accuracy: 54.90 

---------------------------------------------train_client: [0, 1, 2, 3, 4] 

        init --> train local model(freeze embeding):client   4,  Train loss: 1.317, Train accuracy: 51.400, Test loss: 1.420, Test accuracy: 49.00 

        train local model (freeze embeding):client   0,  Train loss: 1.000, Train accuracy: 57.200, Test loss: 1.334, Test accuracy: 51.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.189, Train accuracy: 94.200, Test loss: 1.607, Test accuracy: 57.20 

        train local model (freeze embeding):client   1,  Train loss: 0.918, Train accuracy: 60.600, Test loss: 1.673, Test accuracy: 41.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.245, Train accuracy: 92.000, Test loss: 2.141, Test accuracy: 47.60 

        train local model (freeze embeding):client   2,  Train loss: 0.917, Train accuracy: 62.200, Test loss: 1.297, Test accuracy: 50.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.335, Train accuracy: 87.400, Test loss: 1.446, Test accuracy: 53.60 

        train local model (freeze embeding):client   3,  Train loss: 0.869, Train accuracy: 63.000, Test loss: 1.157, Test accuracy: 56.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.459, Train accuracy: 82.400, Test loss: 1.336, Test accuracy: 60.00 

        train local model (freeze embeding):client   4,  Train loss: 1.074, Train accuracy: 57.000, Test loss: 1.214, Test accuracy: 48.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.829, Train accuracy: 67.600, Test loss: 1.086, Test accuracy: 59.20 

Round   0, Train loss: 0.870, Test loss: 1.343, Test accuracy: 57.56 

        train local model (freeze embeding):client   0,  Train loss: 0.995, Train accuracy: 57.800, Test loss: 1.360, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.326, Train accuracy: 86.800, Test loss: 1.818, Test accuracy: 53.40 

        train local model (freeze embeding):client   1,  Train loss: 1.124, Train accuracy: 50.600, Test loss: 1.835, Test accuracy: 37.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.215, Train accuracy: 94.400, Test loss: 2.027, Test accuracy: 45.40 

        train local model (freeze embeding):client   2,  Train loss: 0.852, Train accuracy: 62.200, Test loss: 1.199, Test accuracy: 52.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.257, Train accuracy: 91.000, Test loss: 1.372, Test accuracy: 58.40 

        train local model (freeze embeding):client   3,  Train loss: 1.065, Train accuracy: 58.400, Test loss: 1.298, Test accuracy: 54.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.680, Train accuracy: 75.200, Test loss: 1.562, Test accuracy: 56.80 

        train local model (freeze embeding):client   4,  Train loss: 1.035, Train accuracy: 58.200, Test loss: 1.200, Test accuracy: 51.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.729, Train accuracy: 72.600, Test loss: 1.033, Test accuracy: 61.80 

Round   1, Train loss: 0.856, Test loss: 1.373, Test accuracy: 57.76 

        train local model (freeze embeding):client   0,  Train loss: 0.878, Train accuracy: 65.400, Test loss: 1.279, Test accuracy: 50.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.292, Train accuracy: 88.600, Test loss: 1.852, Test accuracy: 52.80 

        train local model (freeze embeding):client   1,  Train loss: 0.967, Train accuracy: 57.400, Test loss: 1.646, Test accuracy: 40.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.518, Train accuracy: 79.600, Test loss: 2.454, Test accuracy: 42.20 

        train local model (freeze embeding):client   2,  Train loss: 0.803, Train accuracy: 66.800, Test loss: 1.188, Test accuracy: 53.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.255, Train accuracy: 92.000, Test loss: 1.312, Test accuracy: 58.20 

        train local model (freeze embeding):client   3,  Train loss: 1.105, Train accuracy: 56.600, Test loss: 1.343, Test accuracy: 52.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.533, Train accuracy: 79.000, Test loss: 1.533, Test accuracy: 54.00 

        train local model (freeze embeding):client   4,  Train loss: 0.978, Train accuracy: 61.400, Test loss: 1.161, Test accuracy: 55.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.744, Train accuracy: 70.800, Test loss: 1.037, Test accuracy: 61.60 

Round   2, Train loss: 0.865, Test loss: 1.377, Test accuracy: 57.28 

        train local model (freeze embeding):client   0,  Train loss: 0.883, Train accuracy: 61.800, Test loss: 1.295, Test accuracy: 52.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.210, Train accuracy: 91.800, Test loss: 1.497, Test accuracy: 61.20 

        train local model (freeze embeding):client   1,  Train loss: 0.942, Train accuracy: 61.600, Test loss: 1.655, Test accuracy: 43.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.501, Train accuracy: 82.000, Test loss: 2.342, Test accuracy: 46.80 

        train local model (freeze embeding):client   2,  Train loss: 0.988, Train accuracy: 60.000, Test loss: 1.292, Test accuracy: 51.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.321, Train accuracy: 87.800, Test loss: 1.461, Test accuracy: 54.60 

        train local model (freeze embeding):client   3,  Train loss: 0.893, Train accuracy: 63.600, Test loss: 1.203, Test accuracy: 53.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.383, Train accuracy: 87.800, Test loss: 1.252, Test accuracy: 58.80 

        train local model (freeze embeding):client   4,  Train loss: 1.328, Train accuracy: 48.200, Test loss: 1.472, Test accuracy: 44.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.795, Train accuracy: 67.200, Test loss: 1.096, Test accuracy: 58.40 

Round   3, Train loss: 0.879, Test loss: 1.393, Test accuracy: 57.16 

        train local model (freeze embeding):client   0,  Train loss: 0.848, Train accuracy: 66.400, Test loss: 1.258, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.182, Train accuracy: 94.400, Test loss: 1.611, Test accuracy: 60.20 

        train local model (freeze embeding):client   1,  Train loss: 0.942, Train accuracy: 62.000, Test loss: 1.614, Test accuracy: 40.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.429, Train accuracy: 83.400, Test loss: 2.423, Test accuracy: 45.60 

        train local model (freeze embeding):client   2,  Train loss: 0.989, Train accuracy: 60.400, Test loss: 1.375, Test accuracy: 50.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.296, Train accuracy: 89.600, Test loss: 1.387, Test accuracy: 53.80 

        train local model (freeze embeding):client   3,  Train loss: 0.858, Train accuracy: 63.200, Test loss: 1.165, Test accuracy: 56.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.405, Train accuracy: 84.200, Test loss: 1.343, Test accuracy: 58.40 

        train local model (freeze embeding):client   4,  Train loss: 1.056, Train accuracy: 58.400, Test loss: 1.233, Test accuracy: 51.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.834, Train accuracy: 65.600, Test loss: 1.234, Test accuracy: 54.20 

Round   4, Train loss: 0.868, Test loss: 1.389, Test accuracy: 56.84 

        train local model (freeze embeding):client   0,  Train loss: 0.905, Train accuracy: 59.600, Test loss: 1.265, Test accuracy: 53.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.353, Train accuracy: 86.400, Test loss: 1.765, Test accuracy: 50.80 

        train local model (freeze embeding):client   1,  Train loss: 0.947, Train accuracy: 62.200, Test loss: 1.656, Test accuracy: 41.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.264, Train accuracy: 92.200, Test loss: 2.063, Test accuracy: 49.40 

        train local model (freeze embeding):client   2,  Train loss: 0.838, Train accuracy: 64.600, Test loss: 1.212, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.379, Train accuracy: 84.200, Test loss: 1.373, Test accuracy: 54.00 

        train local model (freeze embeding):client   3,  Train loss: 0.829, Train accuracy: 66.200, Test loss: 1.171, Test accuracy: 58.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.475, Train accuracy: 81.400, Test loss: 1.636, Test accuracy: 54.40 

        train local model (freeze embeding):client   4,  Train loss: 1.003, Train accuracy: 60.400, Test loss: 1.199, Test accuracy: 50.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.778, Train accuracy: 70.000, Test loss: 1.220, Test accuracy: 55.80 

Round   5, Train loss: 0.860, Test loss: 1.388, Test accuracy: 56.24 

        train local model (freeze embeding):client   0,  Train loss: 0.900, Train accuracy: 61.400, Test loss: 1.264, Test accuracy: 51.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.355, Train accuracy: 85.400, Test loss: 1.575, Test accuracy: 59.40 

        train local model (freeze embeding):client   1,  Train loss: 0.956, Train accuracy: 60.000, Test loss: 1.644, Test accuracy: 41.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.304, Train accuracy: 88.400, Test loss: 2.164, Test accuracy: 45.80 

        train local model (freeze embeding):client   2,  Train loss: 0.925, Train accuracy: 58.800, Test loss: 1.314, Test accuracy: 50.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.300, Train accuracy: 90.000, Test loss: 1.414, Test accuracy: 54.60 

        train local model (freeze embeding):client   3,  Train loss: 0.881, Train accuracy: 64.000, Test loss: 1.180, Test accuracy: 54.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.489, Train accuracy: 81.000, Test loss: 1.562, Test accuracy: 55.00 

        train local model (freeze embeding):client   4,  Train loss: 1.045, Train accuracy: 55.400, Test loss: 1.299, Test accuracy: 47.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.659, Train accuracy: 74.600, Test loss: 1.118, Test accuracy: 60.80 

Round   6, Train loss: 0.856, Test loss: 1.375, Test accuracy: 57.48 

        train local model (freeze embeding):client   0,  Train loss: 1.008, Train accuracy: 59.000, Test loss: 1.423, Test accuracy: 48.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.458, Train accuracy: 80.200, Test loss: 1.827, Test accuracy: 55.20 

        train local model (freeze embeding):client   1,  Train loss: 0.948, Train accuracy: 57.000, Test loss: 1.618, Test accuracy: 40.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.349, Train accuracy: 86.600, Test loss: 2.206, Test accuracy: 46.80 

        train local model (freeze embeding):client   2,  Train loss: 0.909, Train accuracy: 63.200, Test loss: 1.233, Test accuracy: 52.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.328, Train accuracy: 88.400, Test loss: 1.454, Test accuracy: 52.00 

        train local model (freeze embeding):client   3,  Train loss: 0.881, Train accuracy: 64.600, Test loss: 1.166, Test accuracy: 57.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.382, Train accuracy: 85.800, Test loss: 1.377, Test accuracy: 59.40 

        train local model (freeze embeding):client   4,  Train loss: 0.932, Train accuracy: 61.600, Test loss: 1.188, Test accuracy: 52.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.684, Train accuracy: 73.600, Test loss: 1.085, Test accuracy: 60.00 

Round   7, Train loss: 0.871, Test loss: 1.393, Test accuracy: 56.92 

        train local model (freeze embeding):client   0,  Train loss: 0.900, Train accuracy: 62.000, Test loss: 1.326, Test accuracy: 50.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.225, Train accuracy: 92.000, Test loss: 1.594, Test accuracy: 59.20 

        train local model (freeze embeding):client   1,  Train loss: 0.932, Train accuracy: 60.600, Test loss: 1.571, Test accuracy: 42.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.316, Train accuracy: 88.200, Test loss: 2.164, Test accuracy: 43.20 

        train local model (freeze embeding):client   2,  Train loss: 0.833, Train accuracy: 67.400, Test loss: 1.232, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.463, Train accuracy: 79.200, Test loss: 1.693, Test accuracy: 51.20 

        train local model (freeze embeding):client   3,  Train loss: 0.846, Train accuracy: 64.800, Test loss: 1.175, Test accuracy: 55.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.587, Train accuracy: 79.200, Test loss: 1.652, Test accuracy: 54.80 

        train local model (freeze embeding):client   4,  Train loss: 1.104, Train accuracy: 54.200, Test loss: 1.356, Test accuracy: 47.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.685, Train accuracy: 75.000, Test loss: 1.169, Test accuracy: 59.00 

Round   8, Train loss: 0.862, Test loss: 1.371, Test accuracy: 57.76 

        train local model (freeze embeding):client   0,  Train loss: 0.918, Train accuracy: 57.400, Test loss: 1.274, Test accuracy: 50.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.273, Train accuracy: 91.000, Test loss: 1.676, Test accuracy: 55.00 

        train local model (freeze embeding):client   1,  Train loss: 1.013, Train accuracy: 57.200, Test loss: 1.633, Test accuracy: 43.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.347, Train accuracy: 86.000, Test loss: 2.142, Test accuracy: 46.00 

        train local model (freeze embeding):client   2,  Train loss: 0.815, Train accuracy: 64.600, Test loss: 1.198, Test accuracy: 53.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.289, Train accuracy: 89.200, Test loss: 1.472, Test accuracy: 52.20 

        train local model (freeze embeding):client   3,  Train loss: 0.883, Train accuracy: 61.600, Test loss: 1.192, Test accuracy: 51.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.511, Train accuracy: 81.200, Test loss: 1.601, Test accuracy: 54.00 

        train local model (freeze embeding):client   4,  Train loss: 0.974, Train accuracy: 59.600, Test loss: 1.249, Test accuracy: 51.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.918, Train accuracy: 63.400, Test loss: 1.349, Test accuracy: 55.20 

Round   9, Train loss: 0.848, Test loss: 1.376, Test accuracy: 57.68 

        train local model (freeze embeding):client   0,  Train loss: 0.894, Train accuracy: 61.400, Test loss: 1.322, Test accuracy: 49.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.233, Train accuracy: 90.400, Test loss: 1.771, Test accuracy: 57.60 

        train local model (freeze embeding):client   1,  Train loss: 0.892, Train accuracy: 64.400, Test loss: 1.607, Test accuracy: 44.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.362, Train accuracy: 84.200, Test loss: 2.232, Test accuracy: 47.60 

        train local model (freeze embeding):client   2,  Train loss: 0.903, Train accuracy: 65.000, Test loss: 1.274, Test accuracy: 54.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.260, Train accuracy: 90.200, Test loss: 1.353, Test accuracy: 56.60 

        train local model (freeze embeding):client   3,  Train loss: 0.946, Train accuracy: 60.200, Test loss: 1.221, Test accuracy: 56.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.367, Train accuracy: 86.000, Test loss: 1.356, Test accuracy: 58.40 

        train local model (freeze embeding):client   4,  Train loss: 0.999, Train accuracy: 57.000, Test loss: 1.253, Test accuracy: 44.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.639, Train accuracy: 74.600, Test loss: 1.131, Test accuracy: 59.60 

Round  10, Train loss: 0.855, Test loss: 1.392, Test accuracy: 56.84 

        train local model (freeze embeding):client   0,  Train loss: 0.921, Train accuracy: 60.800, Test loss: 1.276, Test accuracy: 51.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.254, Train accuracy: 90.600, Test loss: 1.594, Test accuracy: 59.60 

        train local model (freeze embeding):client   1,  Train loss: 0.954, Train accuracy: 61.400, Test loss: 1.586, Test accuracy: 45.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.381, Train accuracy: 85.400, Test loss: 2.278, Test accuracy: 47.60 

        train local model (freeze embeding):client   2,  Train loss: 0.903, Train accuracy: 60.000, Test loss: 1.242, Test accuracy: 51.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.332, Train accuracy: 89.000, Test loss: 1.567, Test accuracy: 53.20 

        train local model (freeze embeding):client   3,  Train loss: 0.951, Train accuracy: 61.400, Test loss: 1.346, Test accuracy: 55.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.427, Train accuracy: 81.200, Test loss: 1.461, Test accuracy: 56.80 

        train local model (freeze embeding):client   4,  Train loss: 0.959, Train accuracy: 62.400, Test loss: 1.230, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.673, Train accuracy: 72.000, Test loss: 1.224, Test accuracy: 55.80 

Round  11, Train loss: 0.853, Test loss: 1.445, Test accuracy: 55.84 

        train local model (freeze embeding):client   0,  Train loss: 0.845, Train accuracy: 61.600, Test loss: 1.250, Test accuracy: 52.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.217, Train accuracy: 93.000, Test loss: 1.639, Test accuracy: 58.00 

        train local model (freeze embeding):client   1,  Train loss: 0.899, Train accuracy: 60.200, Test loss: 1.591, Test accuracy: 44.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.222, Train accuracy: 92.800, Test loss: 2.128, Test accuracy: 46.00 

        train local model (freeze embeding):client   2,  Train loss: 0.955, Train accuracy: 61.800, Test loss: 1.309, Test accuracy: 53.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.406, Train accuracy: 83.000, Test loss: 1.367, Test accuracy: 56.40 

        train local model (freeze embeding):client   3,  Train loss: 0.806, Train accuracy: 66.400, Test loss: 1.156, Test accuracy: 58.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.472, Train accuracy: 80.600, Test loss: 1.557, Test accuracy: 55.20 

        train local model (freeze embeding):client   4,  Train loss: 1.045, Train accuracy: 56.000, Test loss: 1.334, Test accuracy: 47.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.602, Train accuracy: 76.600, Test loss: 1.102, Test accuracy: 60.00 

Round  12, Train loss: 0.853, Test loss: 1.400, Test accuracy: 57.12 

        train local model (freeze embeding):client   0,  Train loss: 0.946, Train accuracy: 57.200, Test loss: 1.272, Test accuracy: 50.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.369, Train accuracy: 84.000, Test loss: 1.720, Test accuracy: 55.20 

        train local model (freeze embeding):client   1,  Train loss: 0.898, Train accuracy: 61.400, Test loss: 1.588, Test accuracy: 44.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.460, Train accuracy: 80.000, Test loss: 2.410, Test accuracy: 45.00 

        train local model (freeze embeding):client   2,  Train loss: 0.923, Train accuracy: 60.600, Test loss: 1.266, Test accuracy: 52.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.276, Train accuracy: 89.800, Test loss: 1.342, Test accuracy: 56.60 

        train local model (freeze embeding):client   3,  Train loss: 0.834, Train accuracy: 67.800, Test loss: 1.171, Test accuracy: 56.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.583, Train accuracy: 77.600, Test loss: 1.520, Test accuracy: 54.00 

        train local model (freeze embeding):client   4,  Train loss: 0.927, Train accuracy: 62.800, Test loss: 1.249, Test accuracy: 52.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.482, Train accuracy: 82.600, Test loss: 1.115, Test accuracy: 61.00 

Round  13, Train loss: 0.848, Test loss: 1.408, Test accuracy: 56.96 

        train local model (freeze embeding):client   0,  Train loss: 0.861, Train accuracy: 64.200, Test loss: 1.324, Test accuracy: 51.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.321, Train accuracy: 86.000, Test loss: 1.756, Test accuracy: 53.00 

        train local model (freeze embeding):client   1,  Train loss: 0.853, Train accuracy: 66.800, Test loss: 1.559, Test accuracy: 46.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.236, Train accuracy: 93.600, Test loss: 2.083, Test accuracy: 45.80 

        train local model (freeze embeding):client   2,  Train loss: 0.984, Train accuracy: 55.400, Test loss: 1.315, Test accuracy: 46.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.428, Train accuracy: 83.800, Test loss: 1.558, Test accuracy: 50.40 

        train local model (freeze embeding):client   3,  Train loss: 0.877, Train accuracy: 63.200, Test loss: 1.168, Test accuracy: 56.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.399, Train accuracy: 84.400, Test loss: 1.423, Test accuracy: 53.80 

        train local model (freeze embeding):client   4,  Train loss: 0.948, Train accuracy: 62.600, Test loss: 1.241, Test accuracy: 51.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.614, Train accuracy: 77.000, Test loss: 1.172, Test accuracy: 59.60 

Round  14, Train loss: 0.866, Test loss: 1.412, Test accuracy: 56.60 

        train local model (freeze embeding):client   0,  Train loss: 0.850, Train accuracy: 63.400, Test loss: 1.295, Test accuracy: 50.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.497, Train accuracy: 81.200, Test loss: 1.893, Test accuracy: 55.80 

        train local model (freeze embeding):client   1,  Train loss: 0.871, Train accuracy: 62.800, Test loss: 1.567, Test accuracy: 45.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.412, Train accuracy: 83.600, Test loss: 2.016, Test accuracy: 49.00 

        train local model (freeze embeding):client   2,  Train loss: 0.856, Train accuracy: 67.600, Test loss: 1.258, Test accuracy: 54.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.358, Train accuracy: 86.800, Test loss: 1.528, Test accuracy: 53.40 

        train local model (freeze embeding):client   3,  Train loss: 0.959, Train accuracy: 56.000, Test loss: 1.269, Test accuracy: 47.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.504, Train accuracy: 78.600, Test loss: 1.639, Test accuracy: 56.20 

        train local model (freeze embeding):client   4,  Train loss: 0.926, Train accuracy: 61.200, Test loss: 1.254, Test accuracy: 51.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.580, Train accuracy: 79.200, Test loss: 1.225, Test accuracy: 60.00 

Round  15, Train loss: 0.834, Test loss: 1.438, Test accuracy: 56.08 

        train local model (freeze embeding):client   0,  Train loss: 0.855, Train accuracy: 66.000, Test loss: 1.275, Test accuracy: 51.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.413, Train accuracy: 83.400, Test loss: 1.891, Test accuracy: 51.80 

        train local model (freeze embeding):client   1,  Train loss: 1.080, Train accuracy: 53.800, Test loss: 1.624, Test accuracy: 39.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.325, Train accuracy: 88.600, Test loss: 2.051, Test accuracy: 46.20 

        train local model (freeze embeding):client   2,  Train loss: 0.933, Train accuracy: 61.200, Test loss: 1.239, Test accuracy: 50.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.299, Train accuracy: 90.600, Test loss: 1.365, Test accuracy: 53.60 

        train local model (freeze embeding):client   3,  Train loss: 0.844, Train accuracy: 63.400, Test loss: 1.212, Test accuracy: 51.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.410, Train accuracy: 85.400, Test loss: 1.339, Test accuracy: 62.00 

        train local model (freeze embeding):client   4,  Train loss: 1.046, Train accuracy: 60.200, Test loss: 1.365, Test accuracy: 51.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.534, Train accuracy: 79.200, Test loss: 1.136, Test accuracy: 60.60 

Round  16, Train loss: 0.835, Test loss: 1.393, Test accuracy: 56.96 

        train local model (freeze embeding):client   0,  Train loss: 0.871, Train accuracy: 62.600, Test loss: 1.245, Test accuracy: 52.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.308, Train accuracy: 86.800, Test loss: 1.586, Test accuracy: 56.40 

        train local model (freeze embeding):client   1,  Train loss: 1.010, Train accuracy: 57.600, Test loss: 1.680, Test accuracy: 45.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.416, Train accuracy: 84.200, Test loss: 1.962, Test accuracy: 47.00 

        train local model (freeze embeding):client   2,  Train loss: 0.917, Train accuracy: 61.800, Test loss: 1.275, Test accuracy: 53.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.245, Train accuracy: 91.800, Test loss: 1.359, Test accuracy: 56.60 

        train local model (freeze embeding):client   3,  Train loss: 0.867, Train accuracy: 65.000, Test loss: 1.221, Test accuracy: 55.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.556, Train accuracy: 78.400, Test loss: 1.785, Test accuracy: 52.20 

        train local model (freeze embeding):client   4,  Train loss: 0.961, Train accuracy: 63.000, Test loss: 1.255, Test accuracy: 51.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.479, Train accuracy: 81.200, Test loss: 1.114, Test accuracy: 60.80 

Round  17, Train loss: 0.849, Test loss: 1.408, Test accuracy: 57.40 

        train local model (freeze embeding):client   0,  Train loss: 0.908, Train accuracy: 59.800, Test loss: 1.247, Test accuracy: 49.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.340, Train accuracy: 88.000, Test loss: 1.586, Test accuracy: 58.40 

        train local model (freeze embeding):client   1,  Train loss: 0.862, Train accuracy: 64.000, Test loss: 1.531, Test accuracy: 44.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.260, Train accuracy: 91.400, Test loss: 2.206, Test accuracy: 44.60 

        train local model (freeze embeding):client   2,  Train loss: 0.879, Train accuracy: 64.000, Test loss: 1.279, Test accuracy: 52.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.241, Train accuracy: 92.000, Test loss: 1.352, Test accuracy: 58.00 

        train local model (freeze embeding):client   3,  Train loss: 1.203, Train accuracy: 52.200, Test loss: 1.494, Test accuracy: 42.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.317, Train accuracy: 88.400, Test loss: 1.272, Test accuracy: 57.40 

        train local model (freeze embeding):client   4,  Train loss: 0.894, Train accuracy: 67.000, Test loss: 1.221, Test accuracy: 54.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.484, Train accuracy: 84.000, Test loss: 1.177, Test accuracy: 63.60 

Round  18, Train loss: 0.838, Test loss: 1.404, Test accuracy: 57.44 

        train local model (freeze embeding):client   0,  Train loss: 0.823, Train accuracy: 65.000, Test loss: 1.250, Test accuracy: 52.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.308, Train accuracy: 87.400, Test loss: 1.829, Test accuracy: 53.20 

        train local model (freeze embeding):client   1,  Train loss: 0.937, Train accuracy: 61.800, Test loss: 1.543, Test accuracy: 46.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.362, Train accuracy: 86.800, Test loss: 2.129, Test accuracy: 46.20 

        train local model (freeze embeding):client   2,  Train loss: 1.047, Train accuracy: 57.000, Test loss: 1.342, Test accuracy: 48.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.707, Train accuracy: 75.600, Test loss: 1.969, Test accuracy: 51.00 

        train local model (freeze embeding):client   3,  Train loss: 0.828, Train accuracy: 66.000, Test loss: 1.175, Test accuracy: 54.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.500, Train accuracy: 80.200, Test loss: 1.599, Test accuracy: 58.40 

        train local model (freeze embeding):client   4,  Train loss: 0.985, Train accuracy: 59.000, Test loss: 1.281, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.547, Train accuracy: 81.000, Test loss: 1.155, Test accuracy: 61.40 

Round  19, Train loss: 0.828, Test loss: 1.464, Test accuracy: 56.92 

        train local model (freeze embeding):client   0,  Train loss: 0.828, Train accuracy: 67.000, Test loss: 1.245, Test accuracy: 51.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.269, Train accuracy: 90.400, Test loss: 1.587, Test accuracy: 55.60 

        train local model (freeze embeding):client   1,  Train loss: 0.952, Train accuracy: 61.800, Test loss: 1.560, Test accuracy: 43.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.358, Train accuracy: 87.600, Test loss: 2.075, Test accuracy: 45.00 

        train local model (freeze embeding):client   2,  Train loss: 0.894, Train accuracy: 62.400, Test loss: 1.299, Test accuracy: 52.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.383, Train accuracy: 83.600, Test loss: 1.578, Test accuracy: 52.60 

        train local model (freeze embeding):client   3,  Train loss: 0.767, Train accuracy: 67.800, Test loss: 1.160, Test accuracy: 56.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.542, Train accuracy: 79.000, Test loss: 1.571, Test accuracy: 56.00 

        train local model (freeze embeding):client   4,  Train loss: 1.022, Train accuracy: 54.800, Test loss: 1.385, Test accuracy: 46.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.546, Train accuracy: 79.400, Test loss: 1.153, Test accuracy: 58.80 

Final Round, Train loss: 0.833, Test loss: 1.442, Test accuracy: 56.84 

Average accuracy final 10 rounds: 278.196 

3522.912590742111
[9.53529953956604, 21.11491560935974, 31.184106826782227, 41.80390453338623, 52.53172278404236, 63.03168559074402, 73.98955512046814, 84.66427087783813, 95.70523738861084, 107.30188989639282, 118.4124219417572, 129.38168573379517, 140.9747245311737, 151.43639469146729, 162.65251445770264, 173.94970631599426, 185.31180047988892, 196.33650946617126, 207.3466649055481, 216.87567043304443, 226.71559715270996, 236.8359296321869, 246.61242032051086, 256.4183657169342, 267.1454544067383, 277.3257610797882, 287.2607367038727, 297.1792187690735, 306.9747393131256, 317.3884930610657, 327.25237345695496, 337.2410190105438, 347.4711639881134, 357.8439109325409, 369.47367906570435, 380.9659593105316, 391.2389585971832, 401.7494463920593, 412.733065366745, 423.43286752700806, 434.1748876571655, 445.83478474617004, 457.4292023181915, 468.7029938697815, 479.64501214027405, 489.74143528938293, 499.693722486496, 510.67144560813904, 520.6476135253906, 530.75541639328, 540.3072595596313, 550.6900737285614, 561.2904341220856, 572.5839805603027, 583.7491035461426, 594.2473199367523, 605.2798676490784, 616.4501974582672, 628.5146591663361, 639.7878768444061, 651.1901295185089, 662.8274438381195, 673.2105956077576, 683.4412109851837, 693.7875385284424, 703.7795598506927, 713.6596643924713, 724.6203007698059, 735.82639336586, 746.6373071670532, 757.8700098991394, 769.030912399292, 780.7951822280884, 792.4295651912689, 804.159051656723, 814.9155056476593, 825.4774956703186, 836.10711145401, 846.7596628665924, 857.4146208763123, 867.7903027534485, 878.545693397522, 889.7660567760468, 901.4166529178619, 912.6643102169037, 923.7972645759583, 934.8249866962433, 945.6338582038879, 956.5993521213531, 966.7655417919159, 977.074939250946, 987.4044678211212, 997.7904617786407, 1008.2699382305145, 1018.9750888347626, 1030.586510181427, 1041.818383216858, 1053.0144970417023, 1064.2130765914917, 1075.1819863319397, 1086.2051403522491, 1096.5912735462189, 1106.9267959594727, 1117.4842557907104, 1127.7418539524078]
[51.8, 45.2, 57.6, 61.8, 54.6, 54.6, 52.0, 58.4, 60.4, 56.2, 60.8, 61.0, 61.0, 57.8, 58.6, 61.2, 60.6, 60.8, 58.8, 60.2, 61.0, 56.2, 55.2, 56.0, 53.9, 56.1, 53.3, 52.5, 54.1, 53.8, 54.0, 52.7, 51.5, 52.3, 54.0, 53.6, 51.9, 53.4, 51.3, 52.2, 53.8, 53.8, 53.46666666666667, 53.6, 53.6, 53.2, 53.4, 54.4, 53.4, 52.6, 52.666666666666664, 52.93333333333333, 53.13333333333333, 51.733333333333334, 53.2, 53.2, 53.46666666666667, 53.666666666666664, 54.13333333333333, 52.46666666666667, 53.8, 52.4, 52.46666666666667, 56.45, 55.55, 55.3, 56.1, 55.35, 56.35, 56.6, 56.1, 56.55, 55.4, 56.5, 55.8, 56.75, 55.8, 55.3, 55.0, 54.5, 55.35, 55.35, 54.75, 54.9, 57.56, 57.76, 57.28, 57.16, 56.84, 56.24, 57.48, 56.92, 57.76, 57.68, 56.84, 55.84, 57.12, 56.96, 56.6, 56.08, 56.96, 57.4, 57.44, 56.92, 56.84]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.568, Test loss: 0.389, Test accuracy: 83.80 

Round   0, Global train loss: 0.568, Global test loss: 0.689, Global test accuracy: 52.90 

Round   1, Train loss: 0.398, Test loss: 0.470, Test accuracy: 82.00 

Round   1, Global train loss: 0.398, Global test loss: 0.688, Global test accuracy: 55.20 

Round   2, Train loss: 0.335, Test loss: 0.516, Test accuracy: 82.00 

Round   2, Global train loss: 0.335, Global test loss: 0.693, Global test accuracy: 50.00 

Round   3, Train loss: 0.274, Test loss: 0.628, Test accuracy: 79.20 

Round   3, Global train loss: 0.274, Global test loss: 0.690, Global test accuracy: 52.20 

Round   4, Train loss: 0.255, Test loss: 0.445, Test accuracy: 83.60 

Round   4, Global train loss: 0.255, Global test loss: 0.693, Global test accuracy: 51.30 

Round   5, Train loss: 0.200, Test loss: 0.377, Test accuracy: 86.70 

Round   5, Global train loss: 0.200, Global test loss: 0.686, Global test accuracy: 54.30 

Round   6, Train loss: 0.181, Test loss: 0.384, Test accuracy: 86.80 

Round   6, Global train loss: 0.181, Global test loss: 0.683, Global test accuracy: 56.20 

Round   7, Train loss: 0.173, Test loss: 0.438, Test accuracy: 86.60 

Round   7, Global train loss: 0.173, Global test loss: 0.696, Global test accuracy: 50.20 

Round   8, Train loss: 0.149, Test loss: 0.423, Test accuracy: 87.50 

Round   8, Global train loss: 0.149, Global test loss: 0.689, Global test accuracy: 50.20 

Round   9, Train loss: 0.123, Test loss: 0.469, Test accuracy: 84.80 

Round   9, Global train loss: 0.123, Global test loss: 0.689, Global test accuracy: 51.40 

Round  10, Train loss: 0.093, Test loss: 0.535, Test accuracy: 85.90 

Round  10, Global train loss: 0.093, Global test loss: 0.682, Global test accuracy: 58.00 

Round  11, Train loss: 0.112, Test loss: 0.509, Test accuracy: 88.10 

Round  11, Global train loss: 0.112, Global test loss: 0.684, Global test accuracy: 55.80 

Round  12, Train loss: 0.071, Test loss: 0.492, Test accuracy: 87.20 

Round  12, Global train loss: 0.071, Global test loss: 0.689, Global test accuracy: 50.70 

Round  13, Train loss: 0.078, Test loss: 0.516, Test accuracy: 85.50 

Round  13, Global train loss: 0.078, Global test loss: 0.688, Global test accuracy: 53.40 

Round  14, Train loss: 0.065, Test loss: 0.561, Test accuracy: 84.10 

Round  14, Global train loss: 0.065, Global test loss: 0.693, Global test accuracy: 52.30 

Round  15, Train loss: 0.077, Test loss: 0.496, Test accuracy: 85.40 

Round  15, Global train loss: 0.077, Global test loss: 0.688, Global test accuracy: 54.00 

Round  16, Train loss: 0.053, Test loss: 0.717, Test accuracy: 84.10 

Round  16, Global train loss: 0.053, Global test loss: 0.687, Global test accuracy: 54.10 

Round  17, Train loss: 0.052, Test loss: 0.501, Test accuracy: 86.10 

Round  17, Global train loss: 0.052, Global test loss: 0.685, Global test accuracy: 54.30 

Round  18, Train loss: 0.057, Test loss: 0.495, Test accuracy: 86.00 

Round  18, Global train loss: 0.057, Global test loss: 0.681, Global test accuracy: 57.20 

Round  19, Train loss: 0.039, Test loss: 0.515, Test accuracy: 88.00 

Round  19, Global train loss: 0.039, Global test loss: 0.683, Global test accuracy: 55.40 

Round  20, Train loss: 0.033, Test loss: 0.500, Test accuracy: 88.20 

Round  20, Global train loss: 0.033, Global test loss: 0.683, Global test accuracy: 55.40 

Round  21, Train loss: 0.044, Test loss: 0.517, Test accuracy: 89.00 

Round  21, Global train loss: 0.044, Global test loss: 0.681, Global test accuracy: 56.90 

Round  22, Train loss: 0.034, Test loss: 0.479, Test accuracy: 88.00 

Round  22, Global train loss: 0.034, Global test loss: 0.682, Global test accuracy: 55.30 

Round  23, Train loss: 0.028, Test loss: 0.471, Test accuracy: 88.40 

Round  23, Global train loss: 0.028, Global test loss: 0.679, Global test accuracy: 56.90 

Round  24, Train loss: 0.024, Test loss: 0.525, Test accuracy: 87.10 

Round  24, Global train loss: 0.024, Global test loss: 0.683, Global test accuracy: 55.60 

Round  25, Train loss: 0.037, Test loss: 0.593, Test accuracy: 85.40 

Round  25, Global train loss: 0.037, Global test loss: 0.686, Global test accuracy: 53.90 

Round  26, Train loss: 0.020, Test loss: 0.556, Test accuracy: 86.60 

Round  26, Global train loss: 0.020, Global test loss: 0.692, Global test accuracy: 51.50 

Round  27, Train loss: 0.021, Test loss: 0.495, Test accuracy: 88.60 

Round  27, Global train loss: 0.021, Global test loss: 0.688, Global test accuracy: 53.60 

Round  28, Train loss: 0.015, Test loss: 0.488, Test accuracy: 89.10 

Round  28, Global train loss: 0.015, Global test loss: 0.681, Global test accuracy: 55.60 

Round  29, Train loss: 0.015, Test loss: 0.471, Test accuracy: 88.90 

Round  29, Global train loss: 0.015, Global test loss: 0.682, Global test accuracy: 55.30 

Round  30, Train loss: 0.017, Test loss: 0.490, Test accuracy: 87.60 

Round  30, Global train loss: 0.017, Global test loss: 0.690, Global test accuracy: 51.30 

Round  31, Train loss: 0.022, Test loss: 0.454, Test accuracy: 88.40 

Round  31, Global train loss: 0.022, Global test loss: 0.682, Global test accuracy: 54.60 

Round  32, Train loss: 0.011, Test loss: 0.512, Test accuracy: 88.50 

Round  32, Global train loss: 0.011, Global test loss: 0.690, Global test accuracy: 52.30 

Round  33, Train loss: 0.018, Test loss: 0.449, Test accuracy: 88.80 

Round  33, Global train loss: 0.018, Global test loss: 0.686, Global test accuracy: 53.40 

Round  34, Train loss: 0.010, Test loss: 0.468, Test accuracy: 88.90 

Round  34, Global train loss: 0.010, Global test loss: 0.687, Global test accuracy: 53.20 

Final Round, Train loss: 0.009, Test loss: 0.508, Test accuracy: 88.90 

Final Round, Global train loss: 0.009, Global test loss: 0.687, Global test accuracy: 53.20 

Average accuracy final 10 rounds: 88.07999999999998 

Average global accuracy final 10 rounds: 53.470000000000006 

533.7646083831787
[4.621625900268555, 7.558205604553223, 10.192898750305176, 12.866456747055054, 15.560200929641724, 18.199463605880737, 20.747330904006958, 23.195146799087524, 25.72560954093933, 28.406658172607422, 30.982815504074097, 33.563907623291016, 36.17240762710571, 38.82459878921509, 41.501755475997925, 44.13171863555908, 46.71256184577942, 49.37455415725708, 51.91165041923523, 54.390220165252686, 56.91062641143799, 59.537909746170044, 62.01071643829346, 64.62600898742676, 67.25006890296936, 69.71154689788818, 72.24019980430603, 75.08868193626404, 77.69946026802063, 80.26769661903381, 82.75984644889832, 85.64167737960815, 88.38315176963806, 90.94799208641052, 93.47746586799622, 98.5534200668335]
[83.8, 82.0, 82.0, 79.2, 83.6, 86.7, 86.8, 86.6, 87.5, 84.8, 85.9, 88.1, 87.2, 85.5, 84.1, 85.4, 84.1, 86.1, 86.0, 88.0, 88.2, 89.0, 88.0, 88.4, 87.1, 85.4, 86.6, 88.6, 89.1, 88.9, 87.6, 88.4, 88.5, 88.8, 88.9, 88.9]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.571, Test loss: 0.426, Test accuracy: 82.20 

Round   0, Global train loss: 0.571, Global test loss: 0.786, Global test accuracy: 50.00 

Round   1, Train loss: 0.496, Test loss: 0.408, Test accuracy: 84.30 

Round   1, Global train loss: 0.496, Global test loss: 0.721, Global test accuracy: 50.30 

Round   2, Train loss: 0.453, Test loss: 0.587, Test accuracy: 81.50 

Round   2, Global train loss: 0.453, Global test loss: 0.683, Global test accuracy: 57.40 

Round   3, Train loss: 0.392, Test loss: 0.516, Test accuracy: 80.30 

Round   3, Global train loss: 0.392, Global test loss: 0.690, Global test accuracy: 60.50 

Round   4, Train loss: 0.379, Test loss: 0.436, Test accuracy: 82.90 

Round   4, Global train loss: 0.379, Global test loss: 0.817, Global test accuracy: 54.70 

Round   5, Train loss: 0.362, Test loss: 0.359, Test accuracy: 86.70 

Round   5, Global train loss: 0.362, Global test loss: 0.716, Global test accuracy: 60.10 

Round   6, Train loss: 0.330, Test loss: 0.394, Test accuracy: 86.00 

Round   6, Global train loss: 0.330, Global test loss: 0.794, Global test accuracy: 58.90 

Round   7, Train loss: 0.307, Test loss: 0.460, Test accuracy: 84.40 

Round   7, Global train loss: 0.307, Global test loss: 0.752, Global test accuracy: 58.90 

Round   8, Train loss: 0.299, Test loss: 0.432, Test accuracy: 86.20 

Round   8, Global train loss: 0.299, Global test loss: 0.724, Global test accuracy: 62.10 

Round   9, Train loss: 0.277, Test loss: 0.490, Test accuracy: 84.90 

Round   9, Global train loss: 0.277, Global test loss: 0.745, Global test accuracy: 60.50 

Round  10, Train loss: 0.260, Test loss: 0.318, Test accuracy: 87.80 

Round  10, Global train loss: 0.260, Global test loss: 0.756, Global test accuracy: 61.50 

Round  11, Train loss: 0.260, Test loss: 0.533, Test accuracy: 85.30 

Round  11, Global train loss: 0.260, Global test loss: 0.724, Global test accuracy: 62.10 

Round  12, Train loss: 0.264, Test loss: 0.499, Test accuracy: 85.60 

Round  12, Global train loss: 0.264, Global test loss: 0.895, Global test accuracy: 59.30 

Round  13, Train loss: 0.237, Test loss: 0.391, Test accuracy: 87.30 

Round  13, Global train loss: 0.237, Global test loss: 0.870, Global test accuracy: 61.10 

Round  14, Train loss: 0.217, Test loss: 0.422, Test accuracy: 88.20 

Round  14, Global train loss: 0.217, Global test loss: 0.896, Global test accuracy: 63.30 

Round  15, Train loss: 0.198, Test loss: 0.411, Test accuracy: 87.10 

Round  15, Global train loss: 0.198, Global test loss: 0.779, Global test accuracy: 64.40 

Round  16, Train loss: 0.206, Test loss: 0.377, Test accuracy: 87.30 

Round  16, Global train loss: 0.206, Global test loss: 0.836, Global test accuracy: 62.30 

Round  17, Train loss: 0.185, Test loss: 0.437, Test accuracy: 86.20 

Round  17, Global train loss: 0.185, Global test loss: 0.850, Global test accuracy: 62.30 

Round  18, Train loss: 0.163, Test loss: 0.605, Test accuracy: 83.90 

Round  18, Global train loss: 0.163, Global test loss: 0.814, Global test accuracy: 63.90 

Round  19, Train loss: 0.162, Test loss: 0.382, Test accuracy: 88.00 

Round  19, Global train loss: 0.162, Global test loss: 0.822, Global test accuracy: 62.90 

Round  20, Train loss: 0.153, Test loss: 0.453, Test accuracy: 87.10 

Round  20, Global train loss: 0.153, Global test loss: 0.830, Global test accuracy: 63.30 

Round  21, Train loss: 0.140, Test loss: 0.565, Test accuracy: 85.00 

Round  21, Global train loss: 0.140, Global test loss: 0.829, Global test accuracy: 63.80 

Round  22, Train loss: 0.131, Test loss: 0.471, Test accuracy: 87.20 

Round  22, Global train loss: 0.131, Global test loss: 0.919, Global test accuracy: 63.90 

Round  23, Train loss: 0.129, Test loss: 0.816, Test accuracy: 82.40 

Round  23, Global train loss: 0.129, Global test loss: 0.856, Global test accuracy: 63.90 

Round  24, Train loss: 0.146, Test loss: 0.447, Test accuracy: 88.10 

Round  24, Global train loss: 0.146, Global test loss: 0.967, Global test accuracy: 63.50 

Round  25, Train loss: 0.108, Test loss: 0.689, Test accuracy: 85.70 

Round  25, Global train loss: 0.108, Global test loss: 0.947, Global test accuracy: 65.00 

Round  26, Train loss: 0.114, Test loss: 0.610, Test accuracy: 86.30 

Round  26, Global train loss: 0.114, Global test loss: 0.863, Global test accuracy: 64.60 

Round  27, Train loss: 0.110, Test loss: 0.476, Test accuracy: 87.10 

Round  27, Global train loss: 0.110, Global test loss: 1.025, Global test accuracy: 63.90 

Round  28, Train loss: 0.092, Test loss: 0.426, Test accuracy: 88.50 

Round  28, Global train loss: 0.092, Global test loss: 0.992, Global test accuracy: 65.10 

Round  29, Train loss: 0.113, Test loss: 0.372, Test accuracy: 88.90 

Round  29, Global train loss: 0.113, Global test loss: 0.844, Global test accuracy: 66.00 

Round  30, Train loss: 0.091, Test loss: 0.497, Test accuracy: 89.00 

Round  30, Global train loss: 0.091, Global test loss: 0.856, Global test accuracy: 66.40 

Round  31, Train loss: 0.107, Test loss: 0.454, Test accuracy: 88.00 

Round  31, Global train loss: 0.107, Global test loss: 0.827, Global test accuracy: 66.00 

Round  32, Train loss: 0.091, Test loss: 0.438, Test accuracy: 87.50 

Round  32, Global train loss: 0.091, Global test loss: 0.864, Global test accuracy: 65.30 

Round  33, Train loss: 0.091, Test loss: 0.417, Test accuracy: 86.80 

Round  33, Global train loss: 0.091, Global test loss: 0.901, Global test accuracy: 64.60 

Round  34, Train loss: 0.060, Test loss: 0.446, Test accuracy: 88.50 

Round  34, Global train loss: 0.060, Global test loss: 0.963, Global test accuracy: 65.10 

Final Round, Train loss: 0.059, Test loss: 0.496, Test accuracy: 87.20 

Final Round, Global train loss: 0.059, Global test loss: 0.963, Global test accuracy: 65.10 

Average accuracy final 10 rounds: 87.63 

Average global accuracy final 10 rounds: 65.2 

533.9528949260712
[4.607975959777832, 7.097179174423218, 9.675135135650635, 12.460150241851807, 15.086111783981323, 17.710776567459106, 20.250847339630127, 22.969125032424927, 25.629120588302612, 28.3918936252594, 30.96535301208496, 33.642407178878784, 36.12864351272583, 38.67923545837402, 41.25323534011841, 43.94631481170654, 46.57501816749573, 49.221792459487915, 51.94846868515015, 54.63385725021362, 57.269524335861206, 59.94345664978027, 62.48451590538025, 64.9841251373291, 67.49019575119019, 70.08779382705688, 72.69807624816895, 75.30291771888733, 77.78827619552612, 80.42791032791138, 82.904305934906, 85.48418402671814, 87.91681671142578, 90.66798758506775, 93.56930327415466, 98.9999406337738]
[82.2, 84.3, 81.5, 80.3, 82.9, 86.7, 86.0, 84.4, 86.2, 84.9, 87.8, 85.3, 85.6, 87.3, 88.2, 87.1, 87.3, 86.2, 83.9, 88.0, 87.1, 85.0, 87.2, 82.4, 88.1, 85.7, 86.3, 87.1, 88.5, 88.9, 89.0, 88.0, 87.5, 86.8, 88.5, 87.2]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.607, Test loss: 0.830, Test accuracy: 58.10 

Round   1, Train loss: 0.521, Test loss: 1.101, Test accuracy: 60.60 

Round   2, Train loss: 0.519, Test loss: 0.738, Test accuracy: 71.30 

Round   3, Train loss: 0.466, Test loss: 0.603, Test accuracy: 71.70 

Round   4, Train loss: 0.435, Test loss: 0.456, Test accuracy: 79.10 

Round   5, Train loss: 0.392, Test loss: 0.367, Test accuracy: 83.50 

Round   6, Train loss: 0.389, Test loss: 0.342, Test accuracy: 84.40 

Round   7, Train loss: 0.394, Test loss: 0.321, Test accuracy: 86.10 

Round   8, Train loss: 0.337, Test loss: 0.391, Test accuracy: 83.20 

Round   9, Train loss: 0.333, Test loss: 0.514, Test accuracy: 78.00 

Round  10, Train loss: 0.303, Test loss: 0.301, Test accuracy: 87.90 

Round  11, Train loss: 0.290, Test loss: 0.317, Test accuracy: 86.60 

Round  12, Train loss: 0.286, Test loss: 0.307, Test accuracy: 86.80 

Round  13, Train loss: 0.253, Test loss: 0.371, Test accuracy: 85.30 

Round  14, Train loss: 0.241, Test loss: 0.339, Test accuracy: 85.60 

Round  15, Train loss: 0.215, Test loss: 0.371, Test accuracy: 85.20 

Round  16, Train loss: 0.236, Test loss: 0.411, Test accuracy: 83.90 

Round  17, Train loss: 0.202, Test loss: 0.324, Test accuracy: 87.60 

Round  18, Train loss: 0.207, Test loss: 0.362, Test accuracy: 85.80 

Round  19, Train loss: 0.170, Test loss: 0.316, Test accuracy: 88.10 

Round  20, Train loss: 0.168, Test loss: 0.299, Test accuracy: 87.60 

Round  21, Train loss: 0.160, Test loss: 0.279, Test accuracy: 88.60 

Round  22, Train loss: 0.137, Test loss: 0.321, Test accuracy: 87.30 

Round  23, Train loss: 0.143, Test loss: 0.345, Test accuracy: 86.40 

Round  24, Train loss: 0.138, Test loss: 0.309, Test accuracy: 88.40 

Round  25, Train loss: 0.125, Test loss: 0.302, Test accuracy: 89.00 

Round  26, Train loss: 0.122, Test loss: 0.349, Test accuracy: 87.50 

Round  27, Train loss: 0.123, Test loss: 0.334, Test accuracy: 87.80 

Round  28, Train loss: 0.118, Test loss: 0.404, Test accuracy: 86.70 

Round  29, Train loss: 0.101, Test loss: 0.291, Test accuracy: 89.20 

Round  30, Train loss: 0.103, Test loss: 0.327, Test accuracy: 88.50 

Round  31, Train loss: 0.108, Test loss: 0.401, Test accuracy: 87.50 

Round  32, Train loss: 0.084, Test loss: 0.318, Test accuracy: 89.30 

Round  33, Train loss: 0.078, Test loss: 0.314, Test accuracy: 89.50 

Round  34, Train loss: 0.082, Test loss: 0.315, Test accuracy: 89.50 

Round  35, Train loss: 0.088, Test loss: 0.377, Test accuracy: 87.80 

Round  36, Train loss: 0.079, Test loss: 0.296, Test accuracy: 90.10 

Round  37, Train loss: 0.075, Test loss: 0.342, Test accuracy: 89.00 

Round  38, Train loss: 0.065, Test loss: 0.393, Test accuracy: 88.40 

Round  39, Train loss: 0.055, Test loss: 0.342, Test accuracy: 89.10 

Round  40, Train loss: 0.060, Test loss: 0.320, Test accuracy: 90.70 

Round  41, Train loss: 0.037, Test loss: 0.328, Test accuracy: 89.70 

Round  42, Train loss: 0.036, Test loss: 0.339, Test accuracy: 89.30 

Round  43, Train loss: 0.056, Test loss: 0.324, Test accuracy: 89.40 

Round  44, Train loss: 0.045, Test loss: 0.328, Test accuracy: 89.40 

Round  45, Train loss: 0.041, Test loss: 0.332, Test accuracy: 89.50 

Round  46, Train loss: 0.043, Test loss: 0.344, Test accuracy: 88.30 

Round  47, Train loss: 0.042, Test loss: 0.360, Test accuracy: 87.80 

Round  48, Train loss: 0.048, Test loss: 0.340, Test accuracy: 88.90 

Round  49, Train loss: 0.032, Test loss: 0.338, Test accuracy: 89.60 

Final Round, Train loss: 0.022, Test loss: 0.361, Test accuracy: 89.30 

Average accuracy final 10 rounds: 89.25999999999999 

541.5856232643127
[3.9975943565368652, 5.916346788406372, 7.944298028945923, 10.038777828216553, 11.791865587234497, 13.88115930557251, 15.91420292854309, 18.046417474746704, 19.88400363922119, 22.075912475585938, 24.244377374649048, 26.073254823684692, 28.10080051422119, 30.139809608459473, 32.2480628490448, 34.28479361534119, 36.42023944854736, 38.448426723480225, 40.5551393032074, 42.6903600692749, 44.82149863243103, 46.751052141189575, 48.6476263999939, 50.80185294151306, 52.91686034202576, 55.16607356071472, 57.31582188606262, 59.21054768562317, 61.42934966087341, 63.54967474937439, 65.58710598945618, 67.7177619934082, 69.74072694778442, 71.90356206893921, 74.0045166015625, 76.1357581615448, 78.07801651954651, 80.16588497161865, 82.23136377334595, 84.25702977180481, 86.15950584411621, 88.28381562232971, 90.16468119621277, 92.12759709358215, 94.09285187721252, 95.91519236564636, 97.88278031349182, 99.85630893707275, 101.76715111732483, 103.96617674827576, 105.72380304336548]
[58.1, 60.6, 71.3, 71.7, 79.1, 83.5, 84.4, 86.1, 83.2, 78.0, 87.9, 86.6, 86.8, 85.3, 85.6, 85.2, 83.9, 87.6, 85.8, 88.1, 87.6, 88.6, 87.3, 86.4, 88.4, 89.0, 87.5, 87.8, 86.7, 89.2, 88.5, 87.5, 89.3, 89.5, 89.5, 87.8, 90.1, 89.0, 88.4, 89.1, 90.7, 89.7, 89.3, 89.4, 89.4, 89.5, 88.3, 87.8, 88.9, 89.6, 89.3]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
Round   0, Train loss: 0.683, Test loss: 1.470, Test accuracy: 53.00
Round   1, Train loss: 0.545, Test loss: 1.176, Test accuracy: 64.40
Round   2, Train loss: 0.489, Test loss: 0.592, Test accuracy: 72.90
Round   3, Train loss: 0.440, Test loss: 0.542, Test accuracy: 76.20
Round   4, Train loss: 0.426, Test loss: 0.444, Test accuracy: 80.00
Round   5, Train loss: 0.405, Test loss: 0.574, Test accuracy: 78.60
Round   6, Train loss: 0.397, Test loss: 0.534, Test accuracy: 77.60
Round   7, Train loss: 0.352, Test loss: 0.510, Test accuracy: 80.50
Round   8, Train loss: 0.340, Test loss: 0.412, Test accuracy: 82.10
Round   9, Train loss: 0.322, Test loss: 0.627, Test accuracy: 79.70
Round  10, Train loss: 0.301, Test loss: 0.360, Test accuracy: 84.50
Round  11, Train loss: 0.265, Test loss: 0.356, Test accuracy: 86.00
Round  12, Train loss: 0.278, Test loss: 0.555, Test accuracy: 80.50
Round  13, Train loss: 0.269, Test loss: 0.343, Test accuracy: 84.30
Round  14, Train loss: 0.248, Test loss: 0.307, Test accuracy: 87.60
Round  15, Train loss: 0.230, Test loss: 0.361, Test accuracy: 86.10
Round  16, Train loss: 0.204, Test loss: 0.340, Test accuracy: 86.10
Round  17, Train loss: 0.214, Test loss: 0.310, Test accuracy: 87.70
Round  18, Train loss: 0.194, Test loss: 0.344, Test accuracy: 87.40
Round  19, Train loss: 0.193, Test loss: 0.324, Test accuracy: 87.40
Round  20, Train loss: 0.190, Test loss: 0.287, Test accuracy: 88.30
Round  21, Train loss: 0.184, Test loss: 0.335, Test accuracy: 87.10
Round  22, Train loss: 0.175, Test loss: 0.305, Test accuracy: 88.60
Round  23, Train loss: 0.173, Test loss: 0.361, Test accuracy: 86.10
Round  24, Train loss: 0.149, Test loss: 0.330, Test accuracy: 87.80
Round  25, Train loss: 0.125, Test loss: 0.298, Test accuracy: 88.00
Round  26, Train loss: 0.142, Test loss: 0.316, Test accuracy: 88.30
Round  27, Train loss: 0.142, Test loss: 0.317, Test accuracy: 88.60
Round  28, Train loss: 0.131, Test loss: 0.309, Test accuracy: 89.30
Round  29, Train loss: 0.117, Test loss: 0.331, Test accuracy: 88.00
Round  30, Train loss: 0.123, Test loss: 0.347, Test accuracy: 88.20
Round  31, Train loss: 0.103, Test loss: 0.317, Test accuracy: 88.90
Round  32, Train loss: 0.108, Test loss: 0.338, Test accuracy: 87.70
Round  33, Train loss: 0.093, Test loss: 0.308, Test accuracy: 88.40
Round  34, Train loss: 0.083, Test loss: 0.306, Test accuracy: 88.50
Round  35, Train loss: 0.080, Test loss: 0.380, Test accuracy: 87.70
Round  36, Train loss: 0.086, Test loss: 0.344, Test accuracy: 87.50
Round  37, Train loss: 0.083, Test loss: 0.345, Test accuracy: 88.50
Round  38, Train loss: 0.084, Test loss: 0.349, Test accuracy: 88.00
Round  39, Train loss: 0.085, Test loss: 0.345, Test accuracy: 88.40
Round  40, Train loss: 0.075, Test loss: 0.321, Test accuracy: 89.50
Round  41, Train loss: 0.064, Test loss: 0.307, Test accuracy: 89.20
Round  42, Train loss: 0.052, Test loss: 0.303, Test accuracy: 90.10
Round  43, Train loss: 0.070, Test loss: 0.309, Test accuracy: 89.80
Round  44, Train loss: 0.053, Test loss: 0.315, Test accuracy: 89.80
Round  45, Train loss: 0.054, Test loss: 0.331, Test accuracy: 89.40
Round  46, Train loss: 0.047, Test loss: 0.338, Test accuracy: 88.80
Round  47, Train loss: 0.049, Test loss: 0.350, Test accuracy: 88.70
Round  48, Train loss: 0.043, Test loss: 0.322, Test accuracy: 89.40
Round  49, Train loss: 0.042, Test loss: 0.343, Test accuracy: 89.20
Final Round, Train loss: 0.029, Test loss: 0.347, Test accuracy: 89.50
Average accuracy final 10 rounds: 89.39
633.7151620388031
[4.206692934036255, 6.667037487030029, 8.97243356704712, 11.32840609550476, 13.478665590286255, 15.751287460327148, 17.978694200515747, 20.421352863311768, 22.635961055755615, 24.89686632156372, 27.132675886154175, 29.361554384231567, 31.77218532562256, 34.13980007171631, 36.429789781570435, 38.661731243133545, 41.18602919578552, 43.607569456100464, 46.03614807128906, 48.62801218032837, 51.20349073410034, 53.6457724571228, 56.192081689834595, 58.64601492881775, 60.95327663421631, 63.50431489944458, 66.19264578819275, 68.74667382240295, 71.2559974193573, 73.63176083564758, 76.16602826118469, 78.67969465255737, 81.18934512138367, 83.77177143096924, 86.28026509284973, 88.57102513313293, 91.15468740463257, 93.68765187263489, 95.99834275245667, 98.45110487937927, 100.809734582901, 103.0456895828247, 105.50683164596558, 107.96581816673279, 110.33530163764954, 112.62549924850464, 114.8549313545227, 117.24449276924133, 119.43989419937134, 121.75489687919617, 124.08620381355286]
[53.0, 64.4, 72.9, 76.2, 80.0, 78.6, 77.6, 80.5, 82.1, 79.7, 84.5, 86.0, 80.5, 84.3, 87.6, 86.1, 86.1, 87.7, 87.4, 87.4, 88.3, 87.1, 88.6, 86.1, 87.8, 88.0, 88.3, 88.6, 89.3, 88.0, 88.2, 88.9, 87.7, 88.4, 88.5, 87.7, 87.5, 88.5, 88.0, 88.4, 89.5, 89.2, 90.1, 89.8, 89.8, 89.4, 88.8, 88.7, 89.4, 89.2, 89.5]
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

Traceback (most recent call last):
  File "main_fedrep_increment2.py", line 219, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[c], first=True,isNew=True, local_eps=20)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 787, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.683, Test loss: 0.762, Test accuracy: 70.50 

Round   0, Global train loss: 0.683, Global test loss: 0.816, Global test accuracy: 50.00 

Round   1, Train loss: 0.426, Test loss: 0.590, Test accuracy: 81.80 

Round   1, Global train loss: 0.426, Global test loss: 0.732, Global test accuracy: 50.10 

Round   2, Train loss: 0.355, Test loss: 0.478, Test accuracy: 82.90 

Round   2, Global train loss: 0.355, Global test loss: 0.763, Global test accuracy: 50.00 

Round   3, Train loss: 0.319, Test loss: 0.458, Test accuracy: 84.50 

Round   3, Global train loss: 0.319, Global test loss: 0.733, Global test accuracy: 50.00 

Round   4, Train loss: 0.259, Test loss: 0.541, Test accuracy: 82.30 

Round   4, Global train loss: 0.259, Global test loss: 0.761, Global test accuracy: 50.00 

Round   5, Train loss: 0.235, Test loss: 0.458, Test accuracy: 84.70 

Round   5, Global train loss: 0.235, Global test loss: 0.745, Global test accuracy: 50.00 

Round   6, Train loss: 0.187, Test loss: 0.679, Test accuracy: 82.50 

Round   6, Global train loss: 0.187, Global test loss: 0.763, Global test accuracy: 50.00 

Round   7, Train loss: 0.170, Test loss: 0.517, Test accuracy: 83.50 

Round   7, Global train loss: 0.170, Global test loss: 0.775, Global test accuracy: 50.00 

Round   8, Train loss: 0.146, Test loss: 0.511, Test accuracy: 85.60 

Round   8, Global train loss: 0.146, Global test loss: 0.768, Global test accuracy: 50.00 

Round   9, Train loss: 0.157, Test loss: 0.564, Test accuracy: 84.60 

Round   9, Global train loss: 0.157, Global test loss: 0.778, Global test accuracy: 50.00 

Round  10, Train loss: 0.103, Test loss: 0.628, Test accuracy: 85.10 

Round  10, Global train loss: 0.103, Global test loss: 0.816, Global test accuracy: 50.00 

Round  11, Train loss: 0.137, Test loss: 0.497, Test accuracy: 85.60 

Round  11, Global train loss: 0.137, Global test loss: 0.743, Global test accuracy: 50.00 

Round  12, Train loss: 0.097, Test loss: 0.517, Test accuracy: 84.70 

Round  12, Global train loss: 0.097, Global test loss: 0.761, Global test accuracy: 50.00 

Round  13, Train loss: 0.070, Test loss: 0.473, Test accuracy: 87.90 

Round  13, Global train loss: 0.070, Global test loss: 0.734, Global test accuracy: 50.00 

Round  14, Train loss: 0.080, Test loss: 0.501, Test accuracy: 86.00 

Round  14, Global train loss: 0.080, Global test loss: 0.734, Global test accuracy: 50.00 

Round  15, Train loss: 0.057, Test loss: 0.485, Test accuracy: 88.10 

Round  15, Global train loss: 0.057, Global test loss: 0.784, Global test accuracy: 50.00 

Round  16, Train loss: 0.059, Test loss: 0.583, Test accuracy: 84.90 

Round  16, Global train loss: 0.059, Global test loss: 0.811, Global test accuracy: 50.00 

Round  17, Train loss: 0.081, Test loss: 0.457, Test accuracy: 85.80 

Round  17, Global train loss: 0.081, Global test loss: 0.729, Global test accuracy: 50.00 

Round  18, Train loss: 0.055, Test loss: 0.551, Test accuracy: 85.40 

Round  18, Global train loss: 0.055, Global test loss: 0.749, Global test accuracy: 50.00 

Round  19, Train loss: 0.065, Test loss: 0.488, Test accuracy: 86.00 

Round  19, Global train loss: 0.065, Global test loss: 0.759, Global test accuracy: 50.00 

Round  20, Train loss: 0.029, Test loss: 0.496, Test accuracy: 87.20 

Round  20, Global train loss: 0.029, Global test loss: 0.781, Global test accuracy: 50.00 

Round  21, Train loss: 0.030, Test loss: 0.610, Test accuracy: 85.00 

Round  21, Global train loss: 0.030, Global test loss: 0.762, Global test accuracy: 50.00 

Round  22, Train loss: 0.027, Test loss: 0.556, Test accuracy: 86.90 

Round  22, Global train loss: 0.027, Global test loss: 0.809, Global test accuracy: 50.00 

Round  23, Train loss: 0.024, Test loss: 0.525, Test accuracy: 88.40 

Round  23, Global train loss: 0.024, Global test loss: 0.772, Global test accuracy: 50.00 

Round  24, Train loss: 0.016, Test loss: 0.509, Test accuracy: 88.30 

Round  24, Global train loss: 0.016, Global test loss: 0.818, Global test accuracy: 50.00 

Round  25, Train loss: 0.025, Test loss: 0.520, Test accuracy: 86.80 

Round  25, Global train loss: 0.025, Global test loss: 0.808, Global test accuracy: 50.00 

Round  26, Train loss: 0.028, Test loss: 0.460, Test accuracy: 88.70 

Round  26, Global train loss: 0.028, Global test loss: 0.829, Global test accuracy: 50.00 

Round  27, Train loss: 0.021, Test loss: 0.528, Test accuracy: 85.80 

Round  27, Global train loss: 0.021, Global test loss: 0.852, Global test accuracy: 50.00 

Round  28, Train loss: 0.024, Test loss: 0.475, Test accuracy: 88.90 

Round  28, Global train loss: 0.024, Global test loss: 0.784, Global test accuracy: 50.00 

Round  29, Train loss: 0.020, Test loss: 0.480, Test accuracy: 88.20 

Round  29, Global train loss: 0.020, Global test loss: 0.756, Global test accuracy: 50.00 

Round  30, Train loss: 0.026, Test loss: 0.517, Test accuracy: 87.20 

Round  30, Global train loss: 0.026, Global test loss: 0.807, Global test accuracy: 50.00 

Round  31, Train loss: 0.019, Test loss: 0.564, Test accuracy: 87.30 

Round  31, Global train loss: 0.019, Global test loss: 0.793, Global test accuracy: 50.00 

Round  32, Train loss: 0.012, Test loss: 0.487, Test accuracy: 87.10 

Round  32, Global train loss: 0.012, Global test loss: 0.803, Global test accuracy: 50.00 

Round  33, Train loss: 0.009, Test loss: 0.463, Test accuracy: 87.30 

Round  33, Global train loss: 0.009, Global test loss: 0.785, Global test accuracy: 50.00 

Round  34, Train loss: 0.005, Test loss: 0.500, Test accuracy: 87.50 

Round  34, Global train loss: 0.005, Global test loss: 0.833, Global test accuracy: 50.00 

Final Round, Train loss: 0.019, Test loss: 0.462, Test accuracy: 87.90 

Final Round, Global train loss: 0.019, Global test loss: 0.833, Global test accuracy: 50.00 

Average accuracy final 10 rounds: 87.48 

Average global accuracy final 10 rounds: 50.0 

527.7602434158325
[4.9727723598480225, 7.515771865844727, 10.12652587890625, 12.896003484725952, 15.406514883041382, 17.924424648284912, 20.402942419052124, 23.03647232055664, 25.568768978118896, 28.13443684577942, 30.632271766662598, 33.2540009021759, 35.87843871116638, 38.591196060180664, 41.25065875053406, 43.72512078285217, 46.276161670684814, 48.79474353790283, 51.37592601776123, 53.89893889427185, 56.46057868003845, 58.98272371292114, 61.64453601837158, 64.26015567779541, 66.8193712234497, 69.45486116409302, 72.04411053657532, 74.48272848129272, 77.04184317588806, 79.57948756217957, 82.08147358894348, 84.63797044754028, 87.22509574890137, 89.79172039031982, 92.53410005569458, 97.48913025856018]
[70.5, 81.8, 82.9, 84.5, 82.3, 84.7, 82.5, 83.5, 85.6, 84.6, 85.1, 85.6, 84.7, 87.9, 86.0, 88.1, 84.9, 85.8, 85.4, 86.0, 87.2, 85.0, 86.9, 88.4, 88.3, 86.8, 88.7, 85.8, 88.9, 88.2, 87.2, 87.3, 87.1, 87.3, 87.5, 87.9]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.624, Test loss: 0.792, Test accuracy: 74.30 

Round   0, Global train loss: 0.624, Global test loss: 0.693, Global test accuracy: 51.00 

Round   1, Train loss: 0.595, Test loss: 0.581, Test accuracy: 78.90 

Round   1, Global train loss: 0.595, Global test loss: 0.891, Global test accuracy: 50.00 

Round   2, Train loss: 0.497, Test loss: 0.423, Test accuracy: 83.60 

Round   2, Global train loss: 0.497, Global test loss: 0.761, Global test accuracy: 53.20 

Round   3, Train loss: 0.468, Test loss: 0.497, Test accuracy: 82.30 

Round   3, Global train loss: 0.468, Global test loss: 0.712, Global test accuracy: 60.40 

Round   4, Train loss: 0.437, Test loss: 0.460, Test accuracy: 80.10 

Round   4, Global train loss: 0.437, Global test loss: 0.656, Global test accuracy: 60.90 

Round   5, Train loss: 0.401, Test loss: 0.538, Test accuracy: 81.50 

Round   5, Global train loss: 0.401, Global test loss: 0.678, Global test accuracy: 65.00 

Round   6, Train loss: 0.385, Test loss: 0.436, Test accuracy: 84.40 

Round   6, Global train loss: 0.385, Global test loss: 0.859, Global test accuracy: 59.70 

Round   7, Train loss: 0.360, Test loss: 0.448, Test accuracy: 83.40 

Round   7, Global train loss: 0.360, Global test loss: 0.813, Global test accuracy: 60.70 

Round   8, Train loss: 0.321, Test loss: 0.362, Test accuracy: 84.90 

Round   8, Global train loss: 0.321, Global test loss: 0.770, Global test accuracy: 64.30 

Round   9, Train loss: 0.288, Test loss: 0.451, Test accuracy: 84.90 

Round   9, Global train loss: 0.288, Global test loss: 0.660, Global test accuracy: 66.40 

Round  10, Train loss: 0.287, Test loss: 0.389, Test accuracy: 83.50 

Round  10, Global train loss: 0.287, Global test loss: 0.798, Global test accuracy: 65.30 

Round  11, Train loss: 0.276, Test loss: 0.525, Test accuracy: 83.40 

Round  11, Global train loss: 0.276, Global test loss: 0.751, Global test accuracy: 65.00 

Round  12, Train loss: 0.273, Test loss: 0.441, Test accuracy: 85.40 

Round  12, Global train loss: 0.273, Global test loss: 0.674, Global test accuracy: 67.00 

Round  13, Train loss: 0.244, Test loss: 0.554, Test accuracy: 84.90 

Round  13, Global train loss: 0.244, Global test loss: 0.671, Global test accuracy: 68.80 

Round  14, Train loss: 0.214, Test loss: 0.462, Test accuracy: 86.40 

Round  14, Global train loss: 0.214, Global test loss: 0.745, Global test accuracy: 65.20 

Round  15, Train loss: 0.224, Test loss: 0.440, Test accuracy: 85.60 

Round  15, Global train loss: 0.224, Global test loss: 0.842, Global test accuracy: 65.00 

Round  16, Train loss: 0.205, Test loss: 0.501, Test accuracy: 84.70 

Round  16, Global train loss: 0.205, Global test loss: 0.862, Global test accuracy: 65.80 

Round  17, Train loss: 0.191, Test loss: 0.537, Test accuracy: 83.00 

Round  17, Global train loss: 0.191, Global test loss: 0.889, Global test accuracy: 66.50 

Round  18, Train loss: 0.182, Test loss: 0.475, Test accuracy: 86.20 

Round  18, Global train loss: 0.182, Global test loss: 0.874, Global test accuracy: 66.90 

Round  19, Train loss: 0.191, Test loss: 0.501, Test accuracy: 84.00 

Round  19, Global train loss: 0.191, Global test loss: 0.729, Global test accuracy: 67.00 

Round  20, Train loss: 0.168, Test loss: 0.347, Test accuracy: 88.80 

Round  20, Global train loss: 0.168, Global test loss: 0.826, Global test accuracy: 67.00 

Round  21, Train loss: 0.158, Test loss: 0.432, Test accuracy: 85.30 

Round  21, Global train loss: 0.158, Global test loss: 0.783, Global test accuracy: 68.10 

Round  22, Train loss: 0.150, Test loss: 0.424, Test accuracy: 88.20 

Round  22, Global train loss: 0.150, Global test loss: 0.932, Global test accuracy: 66.50 

Round  23, Train loss: 0.150, Test loss: 0.419, Test accuracy: 87.00 

Round  23, Global train loss: 0.150, Global test loss: 0.939, Global test accuracy: 65.50 

Round  24, Train loss: 0.144, Test loss: 0.602, Test accuracy: 84.10 

Round  24, Global train loss: 0.144, Global test loss: 0.916, Global test accuracy: 66.90 

Round  25, Train loss: 0.136, Test loss: 0.377, Test accuracy: 87.40 

Round  25, Global train loss: 0.136, Global test loss: 0.951, Global test accuracy: 66.10 

Round  26, Train loss: 0.138, Test loss: 0.524, Test accuracy: 83.60 

Round  26, Global train loss: 0.138, Global test loss: 1.004, Global test accuracy: 66.60 

Round  27, Train loss: 0.138, Test loss: 0.356, Test accuracy: 89.20 

Round  27, Global train loss: 0.138, Global test loss: 0.794, Global test accuracy: 67.50 

Round  28, Train loss: 0.123, Test loss: 0.700, Test accuracy: 81.20 

Round  28, Global train loss: 0.123, Global test loss: 0.994, Global test accuracy: 66.00 

Round  29, Train loss: 0.088, Test loss: 0.599, Test accuracy: 84.20 

Round  29, Global train loss: 0.088, Global test loss: 1.018, Global test accuracy: 66.60 

Round  30, Train loss: 0.133, Test loss: 0.357, Test accuracy: 87.80 

Round  30, Global train loss: 0.133, Global test loss: 0.843, Global test accuracy: 68.70 

Round  31, Train loss: 0.102, Test loss: 0.496, Test accuracy: 86.80 

Round  31, Global train loss: 0.102, Global test loss: 0.889, Global test accuracy: 69.10 

Round  32, Train loss: 0.082, Test loss: 0.372, Test accuracy: 88.70 

Round  32, Global train loss: 0.082, Global test loss: 0.957, Global test accuracy: 68.90 

Round  33, Train loss: 0.078, Test loss: 0.422, Test accuracy: 88.20 

Round  33, Global train loss: 0.078, Global test loss: 0.841, Global test accuracy: 69.80 

Round  34, Train loss: 0.098, Test loss: 0.499, Test accuracy: 87.10 

Round  34, Global train loss: 0.098, Global test loss: 0.829, Global test accuracy: 70.40 

Final Round, Train loss: 0.069, Test loss: 0.510, Test accuracy: 85.70 

Final Round, Global train loss: 0.069, Global test loss: 0.829, Global test accuracy: 70.40 

Average accuracy final 10 rounds: 86.42 

Average global accuracy final 10 rounds: 67.96999999999998 

528.4296901226044
[5.153732776641846, 7.91274881362915, 10.475103855133057, 13.043596267700195, 15.57274842262268, 18.136534214019775, 20.57066774368286, 23.171956300735474, 25.723668813705444, 28.284799337387085, 30.79143452644348, 33.51722979545593, 36.102776527404785, 38.72393298149109, 41.37197732925415, 43.967955112457275, 46.62967586517334, 49.17793893814087, 51.67306137084961, 54.23565101623535, 56.7643666267395, 59.403321743011475, 62.06294012069702, 64.84168124198914, 67.43219184875488, 70.03681325912476, 72.56360840797424, 75.1864058971405, 77.89313578605652, 80.45321750640869, 82.9186692237854, 85.30345392227173, 87.69664311408997, 90.23885655403137, 92.78334951400757, 97.42964267730713]
[74.3, 78.9, 83.6, 82.3, 80.1, 81.5, 84.4, 83.4, 84.9, 84.9, 83.5, 83.4, 85.4, 84.9, 86.4, 85.6, 84.7, 83.0, 86.2, 84.0, 88.8, 85.3, 88.2, 87.0, 84.1, 87.4, 83.6, 89.2, 81.2, 84.2, 87.8, 86.8, 88.7, 88.2, 87.1, 85.7]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.718, Test loss: 0.878, Test accuracy: 54.90 

Round   1, Train loss: 0.697, Test loss: 1.319, Test accuracy: 50.70 

Round   2, Train loss: 0.589, Test loss: 0.703, Test accuracy: 66.70 

Round   3, Train loss: 0.546, Test loss: 0.621, Test accuracy: 67.80 

Round   4, Train loss: 0.506, Test loss: 0.665, Test accuracy: 70.30 

Round   5, Train loss: 0.518, Test loss: 0.800, Test accuracy: 61.30 

Round   6, Train loss: 0.465, Test loss: 0.494, Test accuracy: 77.70 

Round   7, Train loss: 0.428, Test loss: 0.510, Test accuracy: 75.90 

Round   8, Train loss: 0.398, Test loss: 0.616, Test accuracy: 71.00 

Round   9, Train loss: 0.403, Test loss: 0.618, Test accuracy: 77.80 

Round  10, Train loss: 0.358, Test loss: 0.533, Test accuracy: 80.20 

Round  11, Train loss: 0.332, Test loss: 0.406, Test accuracy: 83.70 

Round  12, Train loss: 0.305, Test loss: 0.381, Test accuracy: 84.90 

Round  13, Train loss: 0.297, Test loss: 0.400, Test accuracy: 83.60 

Round  14, Train loss: 0.287, Test loss: 0.424, Test accuracy: 83.90 

Round  15, Train loss: 0.255, Test loss: 0.393, Test accuracy: 84.90 

Round  16, Train loss: 0.266, Test loss: 0.400, Test accuracy: 84.50 

Round  17, Train loss: 0.249, Test loss: 0.435, Test accuracy: 84.60 

Round  18, Train loss: 0.216, Test loss: 0.409, Test accuracy: 85.40 

Round  19, Train loss: 0.227, Test loss: 0.444, Test accuracy: 84.30 

Round  20, Train loss: 0.179, Test loss: 0.360, Test accuracy: 87.10 

Round  21, Train loss: 0.194, Test loss: 0.441, Test accuracy: 84.50 

Round  22, Train loss: 0.164, Test loss: 0.415, Test accuracy: 85.40 

Round  23, Train loss: 0.167, Test loss: 0.367, Test accuracy: 86.80 

Round  24, Train loss: 0.158, Test loss: 0.421, Test accuracy: 85.80 

Round  25, Train loss: 0.139, Test loss: 0.370, Test accuracy: 87.80 

Round  26, Train loss: 0.160, Test loss: 0.426, Test accuracy: 86.60 

Round  27, Train loss: 0.140, Test loss: 0.429, Test accuracy: 86.50 

Round  28, Train loss: 0.119, Test loss: 0.388, Test accuracy: 87.40 

Round  29, Train loss: 0.122, Test loss: 0.380, Test accuracy: 87.50 

Round  30, Train loss: 0.120, Test loss: 0.405, Test accuracy: 87.60 

Round  31, Train loss: 0.113, Test loss: 0.399, Test accuracy: 86.00 

Round  32, Train loss: 0.085, Test loss: 0.378, Test accuracy: 87.80 

Round  33, Train loss: 0.110, Test loss: 0.405, Test accuracy: 87.10 

Round  34, Train loss: 0.102, Test loss: 0.457, Test accuracy: 86.80 

Round  35, Train loss: 0.076, Test loss: 0.374, Test accuracy: 88.40 

Round  36, Train loss: 0.085, Test loss: 0.408, Test accuracy: 87.10 

Round  37, Train loss: 0.075, Test loss: 0.390, Test accuracy: 87.20 

Round  38, Train loss: 0.063, Test loss: 0.388, Test accuracy: 88.00 

Round  39, Train loss: 0.071, Test loss: 0.458, Test accuracy: 87.30 

Round  40, Train loss: 0.079, Test loss: 0.399, Test accuracy: 88.00 

Round  41, Train loss: 0.065, Test loss: 0.409, Test accuracy: 88.60 

Round  42, Train loss: 0.065, Test loss: 0.406, Test accuracy: 87.50 

Round  43, Train loss: 0.051, Test loss: 0.383, Test accuracy: 87.70 

Round  44, Train loss: 0.038, Test loss: 0.419, Test accuracy: 88.10 

Round  45, Train loss: 0.042, Test loss: 0.400, Test accuracy: 89.10 

Round  46, Train loss: 0.062, Test loss: 0.428, Test accuracy: 87.70 

Round  47, Train loss: 0.055, Test loss: 0.414, Test accuracy: 88.40 

Round  48, Train loss: 0.041, Test loss: 0.452, Test accuracy: 87.60 

Round  49, Train loss: 0.039, Test loss: 0.437, Test accuracy: 87.80 

Final Round, Train loss: 0.022, Test loss: 0.430, Test accuracy: 88.00 

Average accuracy final 10 rounds: 88.05 

544.5987732410431
[3.8383686542510986, 5.869520425796509, 7.858022212982178, 9.852879285812378, 11.808438777923584, 13.96486234664917, 15.962801933288574, 18.10450029373169, 20.090553283691406, 21.934160232543945, 23.91973853111267, 25.88750648498535, 27.907264709472656, 29.757884979248047, 31.67043948173523, 33.515995264053345, 35.60159420967102, 37.4856321811676, 39.490864992141724, 41.442304611206055, 43.45823383331299, 45.76539754867554, 47.93992018699646, 49.858896017074585, 52.01154804229736, 54.06866192817688, 56.15033793449402, 58.30435800552368, 60.43050193786621, 62.45697069168091, 64.48523998260498, 66.59761166572571, 68.60621500015259, 70.7303729057312, 72.73269152641296, 74.71416640281677, 76.73075222969055, 78.74990153312683, 80.77383971214294, 82.90707898139954, 84.98307943344116, 86.94388747215271, 88.84187197685242, 90.90477204322815, 92.84755444526672, 94.87076878547668, 96.83773803710938, 98.96271014213562, 100.99249625205994, 102.93021655082703, 104.72416281700134]
[54.9, 50.7, 66.7, 67.8, 70.3, 61.3, 77.7, 75.9, 71.0, 77.8, 80.2, 83.7, 84.9, 83.6, 83.9, 84.9, 84.5, 84.6, 85.4, 84.3, 87.1, 84.5, 85.4, 86.8, 85.8, 87.8, 86.6, 86.5, 87.4, 87.5, 87.6, 86.0, 87.8, 87.1, 86.8, 88.4, 87.1, 87.2, 88.0, 87.3, 88.0, 88.6, 87.5, 87.7, 88.1, 89.1, 87.7, 88.4, 87.6, 87.8, 88.0]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
Round   0, Train loss: 0.735, Test loss: 0.835, Test accuracy: 56.60
Round   1, Train loss: 0.669, Test loss: 1.399, Test accuracy: 51.20
Round   2, Train loss: 0.596, Test loss: 1.069, Test accuracy: 56.50
Round   3, Train loss: 0.542, Test loss: 0.822, Test accuracy: 61.20
Round   4, Train loss: 0.538, Test loss: 0.936, Test accuracy: 60.50
Round   5, Train loss: 0.485, Test loss: 0.614, Test accuracy: 72.60
Round   6, Train loss: 0.464, Test loss: 0.973, Test accuracy: 68.00
Round   7, Train loss: 0.419, Test loss: 0.506, Test accuracy: 75.00
Round   8, Train loss: 0.367, Test loss: 0.601, Test accuracy: 76.80
Round   9, Train loss: 0.333, Test loss: 0.403, Test accuracy: 83.60
Round  10, Train loss: 0.306, Test loss: 0.412, Test accuracy: 83.40
Round  11, Train loss: 0.342, Test loss: 0.646, Test accuracy: 74.30
Round  12, Train loss: 0.317, Test loss: 0.378, Test accuracy: 84.90
Round  13, Train loss: 0.282, Test loss: 0.385, Test accuracy: 83.70
Round  14, Train loss: 0.249, Test loss: 0.418, Test accuracy: 83.70
Round  15, Train loss: 0.250, Test loss: 0.352, Test accuracy: 84.80
Round  16, Train loss: 0.245, Test loss: 0.387, Test accuracy: 84.10
Round  17, Train loss: 0.216, Test loss: 0.416, Test accuracy: 84.50
Round  18, Train loss: 0.209, Test loss: 0.356, Test accuracy: 86.70
Round  19, Train loss: 0.197, Test loss: 0.374, Test accuracy: 85.00
Round  20, Train loss: 0.206, Test loss: 0.381, Test accuracy: 84.80
Round  21, Train loss: 0.186, Test loss: 0.349, Test accuracy: 88.20
Round  22, Train loss: 0.171, Test loss: 0.344, Test accuracy: 87.70
Round  23, Train loss: 0.171, Test loss: 0.381, Test accuracy: 86.20
Round  24, Train loss: 0.154, Test loss: 0.444, Test accuracy: 83.80
Round  25, Train loss: 0.158, Test loss: 0.588, Test accuracy: 81.10
Round  26, Train loss: 0.145, Test loss: 0.434, Test accuracy: 85.50
Round  27, Train loss: 0.122, Test loss: 0.386, Test accuracy: 87.40
Round  28, Train loss: 0.126, Test loss: 0.356, Test accuracy: 87.90
Round  29, Train loss: 0.117, Test loss: 0.384, Test accuracy: 87.40
Round  30, Train loss: 0.120, Test loss: 0.393, Test accuracy: 87.30
Round  31, Train loss: 0.124, Test loss: 0.360, Test accuracy: 87.70
Round  32, Train loss: 0.107, Test loss: 0.373, Test accuracy: 88.00
Round  33, Train loss: 0.091, Test loss: 0.383, Test accuracy: 87.00
Round  34, Train loss: 0.087, Test loss: 0.367, Test accuracy: 88.20
Round  35, Train loss: 0.088, Test loss: 0.370, Test accuracy: 87.90
Round  36, Train loss: 0.100, Test loss: 0.354, Test accuracy: 87.80
Round  37, Train loss: 0.075, Test loss: 0.367, Test accuracy: 87.90
Round  38, Train loss: 0.064, Test loss: 0.385, Test accuracy: 87.60
Round  39, Train loss: 0.057, Test loss: 0.370, Test accuracy: 89.30
Round  40, Train loss: 0.062, Test loss: 0.405, Test accuracy: 88.20
Round  41, Train loss: 0.071, Test loss: 0.425, Test accuracy: 87.40
Round  42, Train loss: 0.072, Test loss: 0.412, Test accuracy: 87.90
Round  43, Train loss: 0.053, Test loss: 0.376, Test accuracy: 88.90
Round  44, Train loss: 0.043, Test loss: 0.435, Test accuracy: 87.50
Round  45, Train loss: 0.055, Test loss: 0.399, Test accuracy: 87.90
Round  46, Train loss: 0.052, Test loss: 0.382, Test accuracy: 88.60
Round  47, Train loss: 0.065, Test loss: 0.378, Test accuracy: 88.40
Round  48, Train loss: 0.051, Test loss: 0.404, Test accuracy: 87.90
Round  49, Train loss: 0.047, Test loss: 0.405, Test accuracy: 88.40
Final Round, Train loss: 0.030, Test loss: 0.426, Test accuracy: 87.50
Average accuracy final 10 rounds: 88.11000000000001
625.2354900836945
[4.196444272994995, 6.389977216720581, 8.478737831115723, 10.941797494888306, 13.128038167953491, 15.288814783096313, 17.583379983901978, 19.690845012664795, 21.972060918807983, 24.202979564666748, 26.526779413223267, 28.81951665878296, 30.957135915756226, 33.2673876285553, 35.41874384880066, 37.608771324157715, 39.73331046104431, 42.087536573410034, 44.38684868812561, 46.80696892738342, 49.43328332901001, 51.904459714889526, 54.51796865463257, 57.116204261779785, 59.761266469955444, 62.20117712020874, 64.6420464515686, 66.97872972488403, 69.52112126350403, 71.98977160453796, 74.5849061012268, 76.9103651046753, 79.29322671890259, 81.86647367477417, 84.36411905288696, 86.8744466304779, 89.28445816040039, 91.77169036865234, 94.30809712409973, 96.78954029083252, 99.20248007774353, 101.61867022514343, 104.04456949234009, 106.41318655014038, 108.91835141181946, 111.27766680717468, 113.43542385101318, 115.67854022979736, 117.88355374336243, 120.28254103660583, 122.9272677898407]
[56.6, 51.2, 56.5, 61.2, 60.5, 72.6, 68.0, 75.0, 76.8, 83.6, 83.4, 74.3, 84.9, 83.7, 83.7, 84.8, 84.1, 84.5, 86.7, 85.0, 84.8, 88.2, 87.7, 86.2, 83.8, 81.1, 85.5, 87.4, 87.9, 87.4, 87.3, 87.7, 88.0, 87.0, 88.2, 87.9, 87.8, 87.9, 87.6, 89.3, 88.2, 87.4, 87.9, 88.9, 87.5, 87.9, 88.6, 88.4, 87.9, 88.4, 87.5]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

Traceback (most recent call last):
  File "main_fedrep_increment2.py", line 219, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[c], first=True,isNew=True, local_eps=20)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 787, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.422, Test loss: 1.297, Test accuracy: 46.90 

Round   0, Global train loss: 1.422, Global test loss: 1.612, Global test accuracy: 27.00 

Round   1, Train loss: 1.106, Test loss: 1.222, Test accuracy: 57.20 

Round   1, Global train loss: 1.106, Global test loss: 1.635, Global test accuracy: 26.90 

Round   2, Train loss: 0.923, Test loss: 1.014, Test accuracy: 62.80 

Round   2, Global train loss: 0.923, Global test loss: 1.642, Global test accuracy: 29.40 

Round   3, Train loss: 0.801, Test loss: 1.261, Test accuracy: 60.60 

Round   3, Global train loss: 0.801, Global test loss: 1.729, Global test accuracy: 20.50 

Round   4, Train loss: 0.694, Test loss: 1.032, Test accuracy: 64.20 

Round   4, Global train loss: 0.694, Global test loss: 1.691, Global test accuracy: 29.80 

Round   5, Train loss: 0.579, Test loss: 1.207, Test accuracy: 63.80 

Round   5, Global train loss: 0.579, Global test loss: 1.807, Global test accuracy: 23.40 

Round   6, Train loss: 0.479, Test loss: 1.307, Test accuracy: 64.80 

Round   6, Global train loss: 0.479, Global test loss: 1.813, Global test accuracy: 27.30 

Round   7, Train loss: 0.415, Test loss: 1.765, Test accuracy: 59.90 

Round   7, Global train loss: 0.415, Global test loss: 2.246, Global test accuracy: 20.20 

Round   8, Train loss: 0.329, Test loss: 1.362, Test accuracy: 66.60 

Round   8, Global train loss: 0.329, Global test loss: 2.286, Global test accuracy: 20.00 

Round   9, Train loss: 0.287, Test loss: 1.288, Test accuracy: 65.30 

Round   9, Global train loss: 0.287, Global test loss: 2.272, Global test accuracy: 20.00 

Round  10, Train loss: 0.300, Test loss: 1.397, Test accuracy: 64.20 

Round  10, Global train loss: 0.300, Global test loss: 2.028, Global test accuracy: 20.50 

Round  11, Train loss: 0.206, Test loss: 1.678, Test accuracy: 64.60 

Round  11, Global train loss: 0.206, Global test loss: 2.907, Global test accuracy: 20.00 

Round  12, Train loss: 0.177, Test loss: 1.656, Test accuracy: 64.00 

Round  12, Global train loss: 0.177, Global test loss: 2.102, Global test accuracy: 21.20 

Round  13, Train loss: 0.148, Test loss: 1.488, Test accuracy: 67.80 

Round  13, Global train loss: 0.148, Global test loss: 2.399, Global test accuracy: 20.20 

Round  14, Train loss: 0.138, Test loss: 1.363, Test accuracy: 70.30 

Round  14, Global train loss: 0.138, Global test loss: 1.838, Global test accuracy: 23.30 

Round  15, Train loss: 0.095, Test loss: 1.367, Test accuracy: 71.60 

Round  15, Global train loss: 0.095, Global test loss: 2.053, Global test accuracy: 21.20 

Round  16, Train loss: 0.133, Test loss: 1.546, Test accuracy: 68.20 

Round  16, Global train loss: 0.133, Global test loss: 2.712, Global test accuracy: 20.20 

Round  17, Train loss: 0.101, Test loss: 1.640, Test accuracy: 69.40 

Round  17, Global train loss: 0.101, Global test loss: 2.184, Global test accuracy: 21.60 

Round  18, Train loss: 0.072, Test loss: 1.655, Test accuracy: 68.80 

Round  18, Global train loss: 0.072, Global test loss: 2.178, Global test accuracy: 20.30 

Round  19, Train loss: 0.072, Test loss: 1.759, Test accuracy: 67.10 

Round  19, Global train loss: 0.072, Global test loss: 2.123, Global test accuracy: 20.60 

Round  20, Train loss: 0.059, Test loss: 1.511, Test accuracy: 69.60 

Round  20, Global train loss: 0.059, Global test loss: 2.249, Global test accuracy: 20.60 

Round  21, Train loss: 0.037, Test loss: 1.519, Test accuracy: 71.00 

Round  21, Global train loss: 0.037, Global test loss: 1.971, Global test accuracy: 22.40 

Round  22, Train loss: 0.037, Test loss: 1.687, Test accuracy: 70.20 

Round  22, Global train loss: 0.037, Global test loss: 2.385, Global test accuracy: 20.20 

Round  23, Train loss: 0.058, Test loss: 2.136, Test accuracy: 64.80 

Round  23, Global train loss: 0.058, Global test loss: 2.493, Global test accuracy: 23.10 

Round  24, Train loss: 0.078, Test loss: 1.611, Test accuracy: 71.00 

Round  24, Global train loss: 0.078, Global test loss: 1.823, Global test accuracy: 25.00 

Round  25, Train loss: 0.064, Test loss: 1.518, Test accuracy: 72.60 

Round  25, Global train loss: 0.064, Global test loss: 2.156, Global test accuracy: 21.50 

Round  26, Train loss: 0.052, Test loss: 1.596, Test accuracy: 72.20 

Round  26, Global train loss: 0.052, Global test loss: 2.094, Global test accuracy: 23.00 

Round  27, Train loss: 0.034, Test loss: 1.707, Test accuracy: 71.10 

Round  27, Global train loss: 0.034, Global test loss: 2.393, Global test accuracy: 20.60 

Round  28, Train loss: 0.017, Test loss: 1.773, Test accuracy: 70.60 

Round  28, Global train loss: 0.017, Global test loss: 2.553, Global test accuracy: 20.60 

Round  29, Train loss: 0.030, Test loss: 1.682, Test accuracy: 70.00 

Round  29, Global train loss: 0.030, Global test loss: 2.634, Global test accuracy: 20.40 

Round  30, Train loss: 0.032, Test loss: 1.590, Test accuracy: 70.80 

Round  30, Global train loss: 0.032, Global test loss: 2.459, Global test accuracy: 20.60 

Round  31, Train loss: 0.020, Test loss: 1.635, Test accuracy: 72.30 

Round  31, Global train loss: 0.020, Global test loss: 2.462, Global test accuracy: 20.40 

Round  32, Train loss: 0.041, Test loss: 1.718, Test accuracy: 68.80 

Round  32, Global train loss: 0.041, Global test loss: 2.217, Global test accuracy: 20.90 

Round  33, Train loss: 0.023, Test loss: 1.780, Test accuracy: 70.70 

Round  33, Global train loss: 0.023, Global test loss: 2.149, Global test accuracy: 23.40 

Round  34, Train loss: 0.014, Test loss: 1.650, Test accuracy: 70.70 

Round  34, Global train loss: 0.014, Global test loss: 2.125, Global test accuracy: 23.80 

Final Round, Train loss: 0.027, Test loss: 1.723, Test accuracy: 70.60 

Final Round, Global train loss: 0.027, Global test loss: 2.125, Global test accuracy: 23.80 

Average accuracy final 10 rounds: 70.97999999999999 

Average global accuracy final 10 rounds: 21.52 

521.1882953643799
[8.103593349456787, 14.461541414260864, 20.81277108192444, 26.80826425552368, 33.27473855018616, 39.64448523521423, 45.691040992736816, 51.94102740287781, 58.10785889625549, 64.2707347869873, 69.93856287002563, 76.30356955528259, 82.33274030685425, 88.49596095085144, 94.69591689109802, 100.71358108520508, 107.11873030662537, 113.6000165939331, 119.83949995040894, 126.21745324134827, 132.59671568870544, 138.7454309463501, 145.41314029693604, 151.79494380950928, 158.31127047538757, 164.52117466926575, 170.946280002594, 177.32174062728882, 183.69581270217896, 189.8689615726471, 196.20127606391907, 202.27316689491272, 208.53450345993042, 214.71002840995789, 220.72194266319275, 233.1126470565796]
[46.9, 57.2, 62.8, 60.6, 64.2, 63.8, 64.8, 59.9, 66.6, 65.3, 64.2, 64.6, 64.0, 67.8, 70.3, 71.6, 68.2, 69.4, 68.8, 67.1, 69.6, 71.0, 70.2, 64.8, 71.0, 72.6, 72.2, 71.1, 70.6, 70.0, 70.8, 72.3, 68.8, 70.7, 70.7, 70.6]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.423, Test loss: 1.154, Test accuracy: 54.70 

Round   0, Global train loss: 1.423, Global test loss: 1.552, Global test accuracy: 27.50 

Round   1, Train loss: 1.206, Test loss: 0.991, Test accuracy: 60.50 

Round   1, Global train loss: 1.206, Global test loss: 1.507, Global test accuracy: 35.40 

Round   2, Train loss: 1.036, Test loss: 1.398, Test accuracy: 57.00 

Round   2, Global train loss: 1.036, Global test loss: 1.603, Global test accuracy: 35.70 

Round   3, Train loss: 0.945, Test loss: 1.016, Test accuracy: 65.00 

Round   3, Global train loss: 0.945, Global test loss: 1.554, Global test accuracy: 39.50 

Round   4, Train loss: 0.874, Test loss: 1.048, Test accuracy: 63.80 

Round   4, Global train loss: 0.874, Global test loss: 1.680, Global test accuracy: 34.60 

Round   5, Train loss: 0.795, Test loss: 1.066, Test accuracy: 61.50 

Round   5, Global train loss: 0.795, Global test loss: 1.536, Global test accuracy: 40.20 

Round   6, Train loss: 0.703, Test loss: 1.137, Test accuracy: 64.50 

Round   6, Global train loss: 0.703, Global test loss: 1.569, Global test accuracy: 41.60 

Round   7, Train loss: 0.625, Test loss: 1.095, Test accuracy: 63.60 

Round   7, Global train loss: 0.625, Global test loss: 1.543, Global test accuracy: 41.30 

Round   8, Train loss: 0.552, Test loss: 1.107, Test accuracy: 64.20 

Round   8, Global train loss: 0.552, Global test loss: 1.604, Global test accuracy: 42.00 

Round   9, Train loss: 0.509, Test loss: 1.537, Test accuracy: 60.50 

Round   9, Global train loss: 0.509, Global test loss: 1.996, Global test accuracy: 42.00 

Round  10, Train loss: 0.461, Test loss: 1.354, Test accuracy: 65.20 

Round  10, Global train loss: 0.461, Global test loss: 1.838, Global test accuracy: 43.40 

Round  11, Train loss: 0.402, Test loss: 1.267, Test accuracy: 65.10 

Round  11, Global train loss: 0.402, Global test loss: 2.038, Global test accuracy: 41.40 

Round  12, Train loss: 0.396, Test loss: 1.206, Test accuracy: 69.50 

Round  12, Global train loss: 0.396, Global test loss: 1.940, Global test accuracy: 42.70 

Round  13, Train loss: 0.314, Test loss: 1.270, Test accuracy: 69.40 

Round  13, Global train loss: 0.314, Global test loss: 2.066, Global test accuracy: 43.90 

Round  14, Train loss: 0.286, Test loss: 1.360, Test accuracy: 67.80 

Round  14, Global train loss: 0.286, Global test loss: 1.933, Global test accuracy: 44.40 

Round  15, Train loss: 0.266, Test loss: 1.244, Test accuracy: 68.60 

Round  15, Global train loss: 0.266, Global test loss: 2.032, Global test accuracy: 41.70 

Round  16, Train loss: 0.214, Test loss: 1.166, Test accuracy: 69.70 

Round  16, Global train loss: 0.214, Global test loss: 2.073, Global test accuracy: 42.30 

Round  17, Train loss: 0.198, Test loss: 1.402, Test accuracy: 68.80 

Round  17, Global train loss: 0.198, Global test loss: 2.413, Global test accuracy: 42.50 

Round  18, Train loss: 0.198, Test loss: 1.439, Test accuracy: 66.00 

Round  18, Global train loss: 0.198, Global test loss: 2.152, Global test accuracy: 44.40 

Round  19, Train loss: 0.155, Test loss: 1.218, Test accuracy: 71.70 

Round  19, Global train loss: 0.155, Global test loss: 2.105, Global test accuracy: 44.50 

Round  20, Train loss: 0.165, Test loss: 1.626, Test accuracy: 68.70 

Round  20, Global train loss: 0.165, Global test loss: 2.460, Global test accuracy: 43.70 

Round  21, Train loss: 0.129, Test loss: 1.480, Test accuracy: 68.40 

Round  21, Global train loss: 0.129, Global test loss: 2.154, Global test accuracy: 45.20 

Round  22, Train loss: 0.131, Test loss: 1.412, Test accuracy: 69.90 

Round  22, Global train loss: 0.131, Global test loss: 2.367, Global test accuracy: 44.10 

Round  23, Train loss: 0.127, Test loss: 1.550, Test accuracy: 68.20 

Round  23, Global train loss: 0.127, Global test loss: 2.413, Global test accuracy: 45.30 

Round  24, Train loss: 0.130, Test loss: 1.509, Test accuracy: 70.30 

Round  24, Global train loss: 0.130, Global test loss: 2.496, Global test accuracy: 44.50 

Round  25, Train loss: 0.086, Test loss: 1.439, Test accuracy: 71.90 

Round  25, Global train loss: 0.086, Global test loss: 2.173, Global test accuracy: 44.90 

Round  26, Train loss: 0.064, Test loss: 1.503, Test accuracy: 70.50 

Round  26, Global train loss: 0.064, Global test loss: 2.421, Global test accuracy: 44.40 

Round  27, Train loss: 0.070, Test loss: 1.442, Test accuracy: 71.90 

Round  27, Global train loss: 0.070, Global test loss: 2.444, Global test accuracy: 44.80 

Round  28, Train loss: 0.092, Test loss: 2.302, Test accuracy: 64.20 

Round  28, Global train loss: 0.092, Global test loss: 2.727, Global test accuracy: 42.50 

Round  29, Train loss: 0.085, Test loss: 1.526, Test accuracy: 68.20 

Round  29, Global train loss: 0.085, Global test loss: 2.400, Global test accuracy: 46.60 

Round  30, Train loss: 0.101, Test loss: 1.743, Test accuracy: 67.30 

Round  30, Global train loss: 0.101, Global test loss: 2.239, Global test accuracy: 45.80 

Round  31, Train loss: 0.061, Test loss: 1.286, Test accuracy: 72.70 

Round  31, Global train loss: 0.061, Global test loss: 2.343, Global test accuracy: 46.60 

Round  32, Train loss: 0.047, Test loss: 1.293, Test accuracy: 73.10 

Round  32, Global train loss: 0.047, Global test loss: 2.322, Global test accuracy: 47.60 

Round  33, Train loss: 0.072, Test loss: 1.336, Test accuracy: 73.10 

Round  33, Global train loss: 0.072, Global test loss: 2.323, Global test accuracy: 46.90 

Round  34, Train loss: 0.054, Test loss: 1.570, Test accuracy: 72.20 

Round  34, Global train loss: 0.054, Global test loss: 2.527, Global test accuracy: 49.90 

Final Round, Train loss: 0.071, Test loss: 1.498, Test accuracy: 69.70 

Final Round, Global train loss: 0.071, Global test loss: 2.527, Global test accuracy: 49.90 

Average accuracy final 10 rounds: 70.51 

Average global accuracy final 10 rounds: 46.0 

516.8153622150421
[8.277174234390259, 14.179965257644653, 20.45596957206726, 26.33906602859497, 32.37631845474243, 38.82760739326477, 44.78936290740967, 50.87422752380371, 56.913612365722656, 62.81408429145813, 68.4791910648346, 74.3866856098175, 80.21331429481506, 86.09325790405273, 92.39156579971313, 98.23436236381531, 104.4634358882904, 110.64913153648376, 116.92426633834839, 123.25622987747192, 129.88805270195007, 136.35662746429443, 142.97420740127563, 149.29228568077087, 155.78884768486023, 161.879061460495, 168.28119730949402, 174.54721879959106, 180.99091267585754, 187.44832587242126, 193.7980682849884, 200.14303851127625, 206.4354121685028, 212.83438420295715, 219.1441388130188, 231.55635118484497]
[54.7, 60.5, 57.0, 65.0, 63.8, 61.5, 64.5, 63.6, 64.2, 60.5, 65.2, 65.1, 69.5, 69.4, 67.8, 68.6, 69.7, 68.8, 66.0, 71.7, 68.7, 68.4, 69.9, 68.2, 70.3, 71.9, 70.5, 71.9, 64.2, 68.2, 67.3, 72.7, 73.1, 73.1, 72.2, 69.7]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 40, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.517, Test loss: 1.739, Test accuracy: 22.40 

Round   1, Train loss: 1.314, Test loss: 1.177, Test accuracy: 50.90 

Round   2, Train loss: 1.178, Test loss: 1.067, Test accuracy: 54.30 

Round   3, Train loss: 1.059, Test loss: 1.183, Test accuracy: 53.70 

Round   4, Train loss: 0.971, Test loss: 1.002, Test accuracy: 61.20 

Round   5, Train loss: 0.901, Test loss: 1.020, Test accuracy: 59.80 

Round   6, Train loss: 0.843, Test loss: 1.041, Test accuracy: 59.40 

Round   7, Train loss: 0.769, Test loss: 0.917, Test accuracy: 66.60 

Round   8, Train loss: 0.717, Test loss: 0.893, Test accuracy: 67.20 

Round   9, Train loss: 0.671, Test loss: 0.866, Test accuracy: 68.80 

Round  10, Train loss: 0.624, Test loss: 0.903, Test accuracy: 68.60 

Round  11, Train loss: 0.553, Test loss: 0.917, Test accuracy: 69.90 

Round  12, Train loss: 0.525, Test loss: 0.884, Test accuracy: 71.00 

Round  13, Train loss: 0.480, Test loss: 0.879, Test accuracy: 70.70 

Round  14, Train loss: 0.434, Test loss: 0.908, Test accuracy: 72.30 

Round  15, Train loss: 0.392, Test loss: 0.834, Test accuracy: 73.50 

Round  16, Train loss: 0.343, Test loss: 1.118, Test accuracy: 67.70 

Round  17, Train loss: 0.310, Test loss: 0.896, Test accuracy: 73.10 

Round  18, Train loss: 0.277, Test loss: 0.895, Test accuracy: 72.50 

Round  19, Train loss: 0.260, Test loss: 0.973, Test accuracy: 71.70 

Round  20, Train loss: 0.237, Test loss: 1.008, Test accuracy: 73.40 

Round  21, Train loss: 0.194, Test loss: 0.953, Test accuracy: 72.40 

Round  22, Train loss: 0.206, Test loss: 1.050, Test accuracy: 71.40 

Round  23, Train loss: 0.180, Test loss: 0.951, Test accuracy: 73.90 

Round  24, Train loss: 0.168, Test loss: 1.088, Test accuracy: 72.00 

Round  25, Train loss: 0.154, Test loss: 0.987, Test accuracy: 71.80 

Round  26, Train loss: 0.142, Test loss: 1.009, Test accuracy: 73.90 

Round  27, Train loss: 0.134, Test loss: 1.027, Test accuracy: 75.10 

Round  28, Train loss: 0.111, Test loss: 1.007, Test accuracy: 74.40 

Round  29, Train loss: 0.114, Test loss: 1.025, Test accuracy: 73.40 

Round  30, Train loss: 0.079, Test loss: 1.121, Test accuracy: 73.20 

Round  31, Train loss: 0.084, Test loss: 1.079, Test accuracy: 72.80 

Round  32, Train loss: 0.095, Test loss: 1.681, Test accuracy: 66.90 

Round  33, Train loss: 0.103, Test loss: 1.105, Test accuracy: 74.00 

Round  34, Train loss: 0.087, Test loss: 1.073, Test accuracy: 75.10 

Round  35, Train loss: 0.075, Test loss: 1.056, Test accuracy: 74.90 

Round  36, Train loss: 0.059, Test loss: 1.106, Test accuracy: 74.20 

Round  37, Train loss: 0.054, Test loss: 1.111, Test accuracy: 74.40 

Round  38, Train loss: 0.054, Test loss: 1.125, Test accuracy: 74.40 

Round  39, Train loss: 0.065, Test loss: 1.150, Test accuracy: 73.80 

Final Round, Train loss: 0.037, Test loss: 1.155, Test accuracy: 73.50 

Average accuracy final 10 rounds: 73.36999999999999 

428.5593264102936
[8.117012023925781, 13.025329113006592, 17.598134517669678, 22.126250505447388, 26.822538137435913, 31.474576234817505, 36.252946615219116, 41.2542839050293, 45.91315293312073, 50.67200064659119, 55.3511700630188, 60.2131290435791, 65.08285331726074, 69.75715780258179, 74.38160419464111, 79.06129932403564, 83.56317281723022, 88.35475587844849, 93.30732774734497, 98.29789233207703, 102.77394890785217, 107.22511458396912, 112.26939940452576, 116.91666889190674, 121.81502556800842, 126.76786136627197, 131.46269273757935, 136.34979677200317, 141.60715579986572, 146.52264070510864, 151.47367525100708, 156.8095703125, 161.83479523658752, 167.08567810058594, 171.95352864265442, 176.84179306030273, 182.11602115631104, 186.76463508605957, 191.86798095703125, 196.37581706047058, 202.4555413722992]
[22.4, 50.9, 54.3, 53.7, 61.2, 59.8, 59.4, 66.6, 67.2, 68.8, 68.6, 69.9, 71.0, 70.7, 72.3, 73.5, 67.7, 73.1, 72.5, 71.7, 73.4, 72.4, 71.4, 73.9, 72.0, 71.8, 73.9, 75.1, 74.4, 73.4, 73.2, 72.8, 66.9, 74.0, 75.1, 74.9, 74.2, 74.4, 74.4, 73.8, 73.5]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 40, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
Round   0, Train loss: 1.525, Test loss: 1.574, Test accuracy: 29.70
Round   1, Train loss: 1.284, Test loss: 1.103, Test accuracy: 54.10
Round   2, Train loss: 1.122, Test loss: 0.982, Test accuracy: 59.80
Round   3, Train loss: 1.021, Test loss: 0.923, Test accuracy: 63.10
Round   4, Train loss: 0.919, Test loss: 0.871, Test accuracy: 65.50
Round   5, Train loss: 0.865, Test loss: 0.939, Test accuracy: 64.10
Round   6, Train loss: 0.787, Test loss: 0.846, Test accuracy: 67.70
Round   7, Train loss: 0.735, Test loss: 0.815, Test accuracy: 70.10
Round   8, Train loss: 0.664, Test loss: 0.816, Test accuracy: 68.60
Round   9, Train loss: 0.598, Test loss: 0.839, Test accuracy: 68.60
Round  10, Train loss: 0.561, Test loss: 0.832, Test accuracy: 70.10
Round  11, Train loss: 0.499, Test loss: 0.905, Test accuracy: 67.80
Round  12, Train loss: 0.476, Test loss: 0.868, Test accuracy: 70.40
Round  13, Train loss: 0.421, Test loss: 0.824, Test accuracy: 72.80
Round  14, Train loss: 0.386, Test loss: 0.871, Test accuracy: 70.10
Round  15, Train loss: 0.354, Test loss: 0.844, Test accuracy: 72.10
Round  16, Train loss: 0.298, Test loss: 0.890, Test accuracy: 71.30
Round  17, Train loss: 0.290, Test loss: 0.878, Test accuracy: 73.40
Round  18, Train loss: 0.239, Test loss: 0.903, Test accuracy: 71.90
Round  19, Train loss: 0.234, Test loss: 0.958, Test accuracy: 72.80
Round  20, Train loss: 0.210, Test loss: 0.930, Test accuracy: 72.70
Round  21, Train loss: 0.189, Test loss: 0.995, Test accuracy: 72.70
Round  22, Train loss: 0.169, Test loss: 0.967, Test accuracy: 72.40
Round  23, Train loss: 0.141, Test loss: 0.956, Test accuracy: 74.20
Round  24, Train loss: 0.160, Test loss: 1.030, Test accuracy: 72.40
Round  25, Train loss: 0.139, Test loss: 0.978, Test accuracy: 75.00
Round  26, Train loss: 0.124, Test loss: 1.088, Test accuracy: 73.40
Round  27, Train loss: 0.124, Test loss: 1.045, Test accuracy: 74.70
Round  28, Train loss: 0.129, Test loss: 1.024, Test accuracy: 73.80
Round  29, Train loss: 0.095, Test loss: 1.009, Test accuracy: 73.90
Round  30, Train loss: 0.085, Test loss: 1.030, Test accuracy: 75.10
Round  31, Train loss: 0.092, Test loss: 1.003, Test accuracy: 75.10
Round  32, Train loss: 0.090, Test loss: 1.027, Test accuracy: 73.50
Round  33, Train loss: 0.058, Test loss: 1.021, Test accuracy: 74.80
Round  34, Train loss: 0.057, Test loss: 1.026, Test accuracy: 74.80
Round  35, Train loss: 0.059, Test loss: 1.033, Test accuracy: 75.40
Round  36, Train loss: 0.046, Test loss: 0.968, Test accuracy: 77.10
Round  37, Train loss: 0.063, Test loss: 1.025, Test accuracy: 76.00
Round  38, Train loss: 0.044, Test loss: 1.047, Test accuracy: 75.00
Round  39, Train loss: 0.038, Test loss: 1.008, Test accuracy: 74.20
Final Round, Train loss: 0.025, Test loss: 1.034, Test accuracy: 75.10
Average accuracy final 10 rounds: 75.10000000000001
488.8253598213196
[7.7193686962127686, 13.878596305847168, 20.027589797973633, 26.40417504310608, 32.41840076446533, 38.484079122543335, 44.44501733779907, 50.317553758621216, 56.05807423591614, 61.905784130096436, 67.84432435035706, 73.93850374221802, 79.57736253738403, 85.31955575942993, 90.5249285697937, 95.95105791091919, 101.30692052841187, 106.65907073020935, 111.82237553596497, 117.06366300582886, 122.10050702095032, 127.56108593940735, 133.0867063999176, 138.5080966949463, 144.25271320343018, 149.52860617637634, 154.46938514709473, 159.56602001190186, 164.6465630531311, 170.14086937904358, 175.15270924568176, 180.59892463684082, 185.8093159198761, 190.87912559509277, 196.38271355628967, 201.95498633384705, 207.63560318946838, 213.27898335456848, 218.86589789390564, 224.46127438545227, 231.6018934249878]
[29.7, 54.1, 59.8, 63.1, 65.5, 64.1, 67.7, 70.1, 68.6, 68.6, 70.1, 67.8, 70.4, 72.8, 70.1, 72.1, 71.3, 73.4, 71.9, 72.8, 72.7, 72.7, 72.4, 74.2, 72.4, 75.0, 73.4, 74.7, 73.8, 73.9, 75.1, 75.1, 73.5, 74.8, 74.8, 75.4, 77.1, 76.0, 75.0, 74.2, 75.1]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

Traceback (most recent call last):
  File "main_fedrep_increment2.py", line 219, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[c], first=True,isNew=True, local_eps=20)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 787, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.460, Test loss: 1.415, Test accuracy: 45.70 

Round   0, Global train loss: 1.460, Global test loss: 2.117, Global test accuracy: 20.00 

Round   1, Train loss: 1.098, Test loss: 1.446, Test accuracy: 54.10 

Round   1, Global train loss: 1.098, Global test loss: 2.075, Global test accuracy: 20.00 

Round   2, Train loss: 0.911, Test loss: 1.492, Test accuracy: 57.80 

Round   2, Global train loss: 0.911, Global test loss: 1.545, Global test accuracy: 25.90 

Round   3, Train loss: 0.813, Test loss: 1.525, Test accuracy: 54.80 

Round   3, Global train loss: 0.813, Global test loss: 2.013, Global test accuracy: 20.00 

Round   4, Train loss: 0.671, Test loss: 1.331, Test accuracy: 61.30 

Round   4, Global train loss: 0.671, Global test loss: 1.919, Global test accuracy: 20.00 

Round   5, Train loss: 0.599, Test loss: 1.343, Test accuracy: 59.30 

Round   5, Global train loss: 0.599, Global test loss: 2.149, Global test accuracy: 20.10 

Round   6, Train loss: 0.498, Test loss: 1.616, Test accuracy: 57.90 

Round   6, Global train loss: 0.498, Global test loss: 2.583, Global test accuracy: 20.00 

Round   7, Train loss: 0.433, Test loss: 1.497, Test accuracy: 60.90 

Round   7, Global train loss: 0.433, Global test loss: 1.958, Global test accuracy: 26.20 

Round   8, Train loss: 0.374, Test loss: 1.801, Test accuracy: 59.60 

Round   8, Global train loss: 0.374, Global test loss: 2.070, Global test accuracy: 20.80 

Round   9, Train loss: 0.284, Test loss: 1.600, Test accuracy: 61.70 

Round   9, Global train loss: 0.284, Global test loss: 2.121, Global test accuracy: 20.00 

Round  10, Train loss: 0.262, Test loss: 1.664, Test accuracy: 59.60 

Round  10, Global train loss: 0.262, Global test loss: 2.101, Global test accuracy: 20.60 

Round  11, Train loss: 0.245, Test loss: 2.097, Test accuracy: 56.90 

Round  11, Global train loss: 0.245, Global test loss: 2.449, Global test accuracy: 20.10 

Round  12, Train loss: 0.179, Test loss: 1.723, Test accuracy: 62.80 

Round  12, Global train loss: 0.179, Global test loss: 2.565, Global test accuracy: 20.00 

Round  13, Train loss: 0.180, Test loss: 1.776, Test accuracy: 61.60 

Round  13, Global train loss: 0.180, Global test loss: 2.544, Global test accuracy: 20.10 

Round  14, Train loss: 0.177, Test loss: 1.899, Test accuracy: 60.70 

Round  14, Global train loss: 0.177, Global test loss: 2.883, Global test accuracy: 20.00 

Round  15, Train loss: 0.115, Test loss: 2.167, Test accuracy: 62.10 

Round  15, Global train loss: 0.115, Global test loss: 2.776, Global test accuracy: 20.00 

Round  16, Train loss: 0.097, Test loss: 1.805, Test accuracy: 63.70 

Round  16, Global train loss: 0.097, Global test loss: 2.822, Global test accuracy: 20.10 

Round  17, Train loss: 0.089, Test loss: 1.763, Test accuracy: 63.50 

Round  17, Global train loss: 0.089, Global test loss: 2.378, Global test accuracy: 20.40 

Round  18, Train loss: 0.083, Test loss: 2.307, Test accuracy: 61.80 

Round  18, Global train loss: 0.083, Global test loss: 2.460, Global test accuracy: 20.70 

Round  19, Train loss: 0.114, Test loss: 1.913, Test accuracy: 62.60 

Round  19, Global train loss: 0.114, Global test loss: 3.186, Global test accuracy: 20.10 

Round  20, Train loss: 0.074, Test loss: 1.858, Test accuracy: 64.30 

Round  20, Global train loss: 0.074, Global test loss: 3.014, Global test accuracy: 20.10 

Round  21, Train loss: 0.067, Test loss: 1.902, Test accuracy: 63.30 

Round  21, Global train loss: 0.067, Global test loss: 2.494, Global test accuracy: 21.00 

Round  22, Train loss: 0.065, Test loss: 1.870, Test accuracy: 65.30 

Round  22, Global train loss: 0.065, Global test loss: 2.309, Global test accuracy: 20.60 

Round  23, Train loss: 0.030, Test loss: 2.123, Test accuracy: 60.80 

Round  23, Global train loss: 0.030, Global test loss: 2.760, Global test accuracy: 20.60 

Round  24, Train loss: 0.040, Test loss: 2.245, Test accuracy: 62.10 

Round  24, Global train loss: 0.040, Global test loss: 3.069, Global test accuracy: 20.20 

Round  25, Train loss: 0.066, Test loss: 1.819, Test accuracy: 64.50 

Round  25, Global train loss: 0.066, Global test loss: 3.475, Global test accuracy: 20.50 

Round  26, Train loss: 0.044, Test loss: 1.944, Test accuracy: 64.70 

Round  26, Global train loss: 0.044, Global test loss: 2.567, Global test accuracy: 23.20 

Round  27, Train loss: 0.042, Test loss: 2.184, Test accuracy: 63.20 

Round  27, Global train loss: 0.042, Global test loss: 2.681, Global test accuracy: 20.50 

Round  28, Train loss: 0.038, Test loss: 1.958, Test accuracy: 63.50 

Round  28, Global train loss: 0.038, Global test loss: 2.963, Global test accuracy: 20.20 

Round  29, Train loss: 0.046, Test loss: 2.029, Test accuracy: 63.30 

Round  29, Global train loss: 0.046, Global test loss: 3.054, Global test accuracy: 20.20 

Round  30, Train loss: 0.036, Test loss: 1.937, Test accuracy: 65.10 

Round  30, Global train loss: 0.036, Global test loss: 2.768, Global test accuracy: 20.00 

Round  31, Train loss: 0.030, Test loss: 1.861, Test accuracy: 65.30 

Round  31, Global train loss: 0.030, Global test loss: 3.111, Global test accuracy: 20.10 

Round  32, Train loss: 0.023, Test loss: 1.911, Test accuracy: 66.30 

Round  32, Global train loss: 0.023, Global test loss: 3.103, Global test accuracy: 20.20 

Round  33, Train loss: 0.050, Test loss: 2.044, Test accuracy: 64.40 

Round  33, Global train loss: 0.050, Global test loss: 2.924, Global test accuracy: 20.30 

Round  34, Train loss: 0.018, Test loss: 1.995, Test accuracy: 63.30 

Round  34, Global train loss: 0.018, Global test loss: 3.360, Global test accuracy: 20.10 

Final Round, Train loss: 0.019, Test loss: 1.864, Test accuracy: 67.80 

Final Round, Global train loss: 0.019, Global test loss: 3.360, Global test accuracy: 20.10 

Average accuracy final 10 rounds: 64.36 

Average global accuracy final 10 rounds: 20.53 

523.9117910861969
[9.550628185272217, 16.833577871322632, 23.239685535430908, 29.493281602859497, 35.91299653053284, 42.19522166252136, 48.682950258255005, 55.19934415817261, 61.782307863235474, 68.09265184402466, 74.43374752998352, 80.64574074745178, 86.82170009613037, 92.9144356250763, 99.33528161048889, 105.65365934371948, 112.04472279548645, 118.30483031272888, 124.2520444393158, 130.24719548225403, 136.07395815849304, 142.33515739440918, 148.22634935379028, 154.001323223114, 160.27550745010376, 166.6332609653473, 172.95465564727783, 179.2541606426239, 185.45384907722473, 191.51565527915955, 197.43714046478271, 203.87272715568542, 210.1830756664276, 217.05845975875854, 223.0621771812439, 235.22687530517578]
[45.7, 54.1, 57.8, 54.8, 61.3, 59.3, 57.9, 60.9, 59.6, 61.7, 59.6, 56.9, 62.8, 61.6, 60.7, 62.1, 63.7, 63.5, 61.8, 62.6, 64.3, 63.3, 65.3, 60.8, 62.1, 64.5, 64.7, 63.2, 63.5, 63.3, 65.1, 65.3, 66.3, 64.4, 63.3, 67.8]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.434, Test loss: 1.285, Test accuracy: 48.10 

Round   0, Global train loss: 1.434, Global test loss: 1.787, Global test accuracy: 29.10 

Round   1, Train loss: 1.243, Test loss: 1.370, Test accuracy: 52.40 

Round   1, Global train loss: 1.243, Global test loss: 1.553, Global test accuracy: 33.80 

Round   2, Train loss: 1.086, Test loss: 1.478, Test accuracy: 53.30 

Round   2, Global train loss: 1.086, Global test loss: 1.446, Global test accuracy: 45.50 

Round   3, Train loss: 0.993, Test loss: 1.308, Test accuracy: 53.90 

Round   3, Global train loss: 0.993, Global test loss: 1.181, Global test accuracy: 53.70 

Round   4, Train loss: 0.863, Test loss: 1.234, Test accuracy: 58.80 

Round   4, Global train loss: 0.863, Global test loss: 1.264, Global test accuracy: 52.20 

Round   5, Train loss: 0.762, Test loss: 1.203, Test accuracy: 59.20 

Round   5, Global train loss: 0.762, Global test loss: 1.173, Global test accuracy: 55.30 

Round   6, Train loss: 0.696, Test loss: 1.385, Test accuracy: 59.60 

Round   6, Global train loss: 0.696, Global test loss: 1.297, Global test accuracy: 54.20 

Round   7, Train loss: 0.616, Test loss: 1.643, Test accuracy: 54.80 

Round   7, Global train loss: 0.616, Global test loss: 1.310, Global test accuracy: 55.90 

Round   8, Train loss: 0.552, Test loss: 1.550, Test accuracy: 58.20 

Round   8, Global train loss: 0.552, Global test loss: 1.340, Global test accuracy: 53.60 

Round   9, Train loss: 0.490, Test loss: 1.306, Test accuracy: 63.10 

Round   9, Global train loss: 0.490, Global test loss: 1.419, Global test accuracy: 55.00 

Round  10, Train loss: 0.446, Test loss: 1.277, Test accuracy: 62.50 

Round  10, Global train loss: 0.446, Global test loss: 1.311, Global test accuracy: 57.10 

Round  11, Train loss: 0.388, Test loss: 1.517, Test accuracy: 61.00 

Round  11, Global train loss: 0.388, Global test loss: 1.399, Global test accuracy: 56.80 

Round  12, Train loss: 0.356, Test loss: 1.651, Test accuracy: 62.70 

Round  12, Global train loss: 0.356, Global test loss: 1.610, Global test accuracy: 57.60 

Round  13, Train loss: 0.304, Test loss: 1.924, Test accuracy: 57.60 

Round  13, Global train loss: 0.304, Global test loss: 1.825, Global test accuracy: 52.20 

Round  14, Train loss: 0.291, Test loss: 1.622, Test accuracy: 62.00 

Round  14, Global train loss: 0.291, Global test loss: 1.741, Global test accuracy: 55.20 

Round  15, Train loss: 0.275, Test loss: 1.480, Test accuracy: 63.40 

Round  15, Global train loss: 0.275, Global test loss: 1.367, Global test accuracy: 59.90 

Round  16, Train loss: 0.236, Test loss: 1.600, Test accuracy: 62.90 

Round  16, Global train loss: 0.236, Global test loss: 1.600, Global test accuracy: 59.00 

Round  17, Train loss: 0.209, Test loss: 2.029, Test accuracy: 58.60 

Round  17, Global train loss: 0.209, Global test loss: 1.715, Global test accuracy: 56.90 

Round  18, Train loss: 0.176, Test loss: 1.566, Test accuracy: 66.20 

Round  18, Global train loss: 0.176, Global test loss: 1.618, Global test accuracy: 59.90 

Round  19, Train loss: 0.178, Test loss: 1.674, Test accuracy: 64.30 

Round  19, Global train loss: 0.178, Global test loss: 1.737, Global test accuracy: 59.00 

Round  20, Train loss: 0.135, Test loss: 1.925, Test accuracy: 61.50 

Round  20, Global train loss: 0.135, Global test loss: 1.762, Global test accuracy: 57.30 

Round  21, Train loss: 0.146, Test loss: 1.783, Test accuracy: 63.50 

Round  21, Global train loss: 0.146, Global test loss: 1.677, Global test accuracy: 59.40 

Round  22, Train loss: 0.112, Test loss: 1.794, Test accuracy: 64.00 

Round  22, Global train loss: 0.112, Global test loss: 1.799, Global test accuracy: 58.90 

Round  23, Train loss: 0.092, Test loss: 2.044, Test accuracy: 65.30 

Round  23, Global train loss: 0.092, Global test loss: 1.735, Global test accuracy: 59.20 

Round  24, Train loss: 0.108, Test loss: 1.955, Test accuracy: 61.70 

Round  24, Global train loss: 0.108, Global test loss: 1.870, Global test accuracy: 59.80 

Round  25, Train loss: 0.086, Test loss: 2.005, Test accuracy: 62.70 

Round  25, Global train loss: 0.086, Global test loss: 1.888, Global test accuracy: 59.30 

Round  26, Train loss: 0.099, Test loss: 1.659, Test accuracy: 65.30 

Round  26, Global train loss: 0.099, Global test loss: 1.779, Global test accuracy: 60.60 

Round  27, Train loss: 0.048, Test loss: 1.907, Test accuracy: 65.80 

Round  27, Global train loss: 0.048, Global test loss: 1.896, Global test accuracy: 60.40 

Round  28, Train loss: 0.104, Test loss: 1.924, Test accuracy: 65.40 

Round  28, Global train loss: 0.104, Global test loss: 1.866, Global test accuracy: 60.00 

Round  29, Train loss: 0.041, Test loss: 1.829, Test accuracy: 65.80 

Round  29, Global train loss: 0.041, Global test loss: 1.998, Global test accuracy: 61.20 

Round  30, Train loss: 0.065, Test loss: 1.672, Test accuracy: 68.00 

Round  30, Global train loss: 0.065, Global test loss: 1.897, Global test accuracy: 61.40 

Round  31, Train loss: 0.053, Test loss: 1.905, Test accuracy: 66.20 

Round  31, Global train loss: 0.053, Global test loss: 2.053, Global test accuracy: 61.00 

Round  32, Train loss: 0.061, Test loss: 1.863, Test accuracy: 66.10 

Round  32, Global train loss: 0.061, Global test loss: 1.913, Global test accuracy: 60.30 

Round  33, Train loss: 0.066, Test loss: 1.869, Test accuracy: 65.10 

Round  33, Global train loss: 0.066, Global test loss: 2.098, Global test accuracy: 60.50 

Round  34, Train loss: 0.020, Test loss: 1.828, Test accuracy: 68.00 

Round  34, Global train loss: 0.020, Global test loss: 2.087, Global test accuracy: 60.30 

Final Round, Train loss: 0.026, Test loss: 1.829, Test accuracy: 68.90 

Final Round, Global train loss: 0.026, Global test loss: 2.087, Global test accuracy: 60.30 

Average accuracy final 10 rounds: 65.83999999999999 

Average global accuracy final 10 rounds: 60.5 

516.1514925956726
[8.428098678588867, 14.749649286270142, 20.98287296295166, 27.25716781616211, 33.46127533912659, 39.24990940093994, 45.224416971206665, 51.25076198577881, 57.3303108215332, 63.41588521003723, 69.41624641418457, 75.35154509544373, 81.45521450042725, 88.02238368988037, 94.7633113861084, 101.26661348342896, 107.67566752433777, 114.07263541221619, 120.37722134590149, 126.81703639030457, 133.12800550460815, 139.30341577529907, 145.51430368423462, 151.5876166820526, 157.5391263961792, 163.21842885017395, 168.73871517181396, 174.35265803337097, 180.21439480781555, 186.0427930355072, 191.6701843738556, 197.4607515335083, 203.16823935508728, 208.81423020362854, 214.8552749156952, 226.59976482391357]
[48.1, 52.4, 53.3, 53.9, 58.8, 59.2, 59.6, 54.8, 58.2, 63.1, 62.5, 61.0, 62.7, 57.6, 62.0, 63.4, 62.9, 58.6, 66.2, 64.3, 61.5, 63.5, 64.0, 65.3, 61.7, 62.7, 65.3, 65.8, 65.4, 65.8, 68.0, 66.2, 66.1, 65.1, 68.0, 68.9]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 40, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.539, Test loss: 1.707, Test accuracy: 27.50 

Round   1, Train loss: 1.323, Test loss: 1.265, Test accuracy: 47.20 

Round   2, Train loss: 1.191, Test loss: 1.338, Test accuracy: 46.50 

Round   3, Train loss: 1.122, Test loss: 1.142, Test accuracy: 53.40 

Round   4, Train loss: 1.035, Test loss: 1.129, Test accuracy: 52.60 

Round   5, Train loss: 0.982, Test loss: 1.347, Test accuracy: 48.10 

Round   6, Train loss: 0.907, Test loss: 1.108, Test accuracy: 56.70 

Round   7, Train loss: 0.846, Test loss: 1.063, Test accuracy: 59.00 

Round   8, Train loss: 0.803, Test loss: 1.069, Test accuracy: 60.10 

Round   9, Train loss: 0.763, Test loss: 1.038, Test accuracy: 62.00 

Round  10, Train loss: 0.667, Test loss: 1.027, Test accuracy: 62.10 

Round  11, Train loss: 0.636, Test loss: 1.019, Test accuracy: 63.70 

Round  12, Train loss: 0.574, Test loss: 1.026, Test accuracy: 62.00 

Round  13, Train loss: 0.508, Test loss: 1.073, Test accuracy: 63.10 

Round  14, Train loss: 0.493, Test loss: 1.097, Test accuracy: 63.30 

Round  15, Train loss: 0.438, Test loss: 1.111, Test accuracy: 63.60 

Round  16, Train loss: 0.441, Test loss: 1.076, Test accuracy: 64.10 

Round  17, Train loss: 0.385, Test loss: 1.141, Test accuracy: 64.70 

Round  18, Train loss: 0.359, Test loss: 1.094, Test accuracy: 66.20 

Round  19, Train loss: 0.331, Test loss: 1.218, Test accuracy: 63.30 

Round  20, Train loss: 0.296, Test loss: 1.126, Test accuracy: 66.20 

Round  21, Train loss: 0.264, Test loss: 1.215, Test accuracy: 63.80 

Round  22, Train loss: 0.248, Test loss: 1.141, Test accuracy: 65.20 

Round  23, Train loss: 0.239, Test loss: 1.168, Test accuracy: 65.20 

Round  24, Train loss: 0.226, Test loss: 1.191, Test accuracy: 64.00 

Round  25, Train loss: 0.199, Test loss: 1.126, Test accuracy: 65.50 

Round  26, Train loss: 0.179, Test loss: 1.198, Test accuracy: 66.70 

Round  27, Train loss: 0.144, Test loss: 1.337, Test accuracy: 64.50 

Round  28, Train loss: 0.156, Test loss: 1.199, Test accuracy: 66.70 

Round  29, Train loss: 0.147, Test loss: 1.301, Test accuracy: 66.60 

Round  30, Train loss: 0.150, Test loss: 1.315, Test accuracy: 65.60 

Round  31, Train loss: 0.129, Test loss: 1.277, Test accuracy: 64.30 

Round  32, Train loss: 0.113, Test loss: 1.277, Test accuracy: 65.90 

Round  33, Train loss: 0.111, Test loss: 1.336, Test accuracy: 66.00 

Round  34, Train loss: 0.095, Test loss: 1.361, Test accuracy: 64.90 

Round  35, Train loss: 0.088, Test loss: 1.372, Test accuracy: 66.50 

Round  36, Train loss: 0.073, Test loss: 1.420, Test accuracy: 64.90 

Round  37, Train loss: 0.073, Test loss: 1.429, Test accuracy: 66.60 

Round  38, Train loss: 0.077, Test loss: 1.504, Test accuracy: 67.40 

Round  39, Train loss: 0.077, Test loss: 1.483, Test accuracy: 67.70 

Final Round, Train loss: 0.042, Test loss: 1.482, Test accuracy: 66.60 

Average accuracy final 10 rounds: 65.98 

448.98697328567505
[7.504046440124512, 12.675126314163208, 17.49118161201477, 22.447352409362793, 27.391990423202515, 32.68202304840088, 37.58146095275879, 42.58435845375061, 47.44663977622986, 52.56838631629944, 57.626036167144775, 62.92342162132263, 68.20877432823181, 73.34788227081299, 78.40671300888062, 83.38226509094238, 88.08365535736084, 92.91923427581787, 98.31171822547913, 103.31435799598694, 108.57597708702087, 113.42245531082153, 118.05817532539368, 123.21060991287231, 128.47223925590515, 133.77783393859863, 138.9395444393158, 144.1390519142151, 149.5194206237793, 154.84031176567078, 160.1257619857788, 165.32827854156494, 170.57770490646362, 175.55325651168823, 180.5126428604126, 185.55686211585999, 190.59242725372314, 195.60286045074463, 200.33013463020325, 205.08462524414062, 210.17537546157837]
[27.5, 47.2, 46.5, 53.4, 52.6, 48.1, 56.7, 59.0, 60.1, 62.0, 62.1, 63.7, 62.0, 63.1, 63.3, 63.6, 64.1, 64.7, 66.2, 63.3, 66.2, 63.8, 65.2, 65.2, 64.0, 65.5, 66.7, 64.5, 66.7, 66.6, 65.6, 64.3, 65.9, 66.0, 64.9, 66.5, 64.9, 66.6, 67.4, 67.7, 66.6]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 40, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
Round   0, Train loss: 1.535, Test loss: 1.731, Test accuracy: 29.80
Round   1, Train loss: 1.309, Test loss: 1.377, Test accuracy: 41.70
Round   2, Train loss: 1.199, Test loss: 1.337, Test accuracy: 48.10
Round   3, Train loss: 1.061, Test loss: 1.083, Test accuracy: 56.90
Round   4, Train loss: 0.967, Test loss: 1.137, Test accuracy: 57.40
Round   5, Train loss: 0.904, Test loss: 1.120, Test accuracy: 57.40
Round   6, Train loss: 0.846, Test loss: 0.983, Test accuracy: 61.30
Round   7, Train loss: 0.772, Test loss: 1.019, Test accuracy: 61.40
Round   8, Train loss: 0.707, Test loss: 1.107, Test accuracy: 59.60
Round   9, Train loss: 0.682, Test loss: 0.950, Test accuracy: 64.20
Round  10, Train loss: 0.628, Test loss: 1.030, Test accuracy: 63.20
Round  11, Train loss: 0.555, Test loss: 1.003, Test accuracy: 63.90
Round  12, Train loss: 0.510, Test loss: 0.975, Test accuracy: 64.70
Round  13, Train loss: 0.494, Test loss: 1.024, Test accuracy: 63.80
Round  14, Train loss: 0.426, Test loss: 0.977, Test accuracy: 66.60
Round  15, Train loss: 0.393, Test loss: 1.043, Test accuracy: 65.80
Round  16, Train loss: 0.378, Test loss: 1.083, Test accuracy: 64.50
Round  17, Train loss: 0.351, Test loss: 1.071, Test accuracy: 65.90
Round  18, Train loss: 0.320, Test loss: 1.022, Test accuracy: 68.00
Round  19, Train loss: 0.283, Test loss: 1.042, Test accuracy: 69.60
Round  20, Train loss: 0.269, Test loss: 1.076, Test accuracy: 66.40
Round  21, Train loss: 0.241, Test loss: 1.148, Test accuracy: 66.40
Round  22, Train loss: 0.227, Test loss: 1.136, Test accuracy: 66.80
Round  23, Train loss: 0.195, Test loss: 1.196, Test accuracy: 66.70
Round  24, Train loss: 0.179, Test loss: 1.223, Test accuracy: 67.80
Round  25, Train loss: 0.180, Test loss: 1.162, Test accuracy: 67.50
Round  26, Train loss: 0.164, Test loss: 1.247, Test accuracy: 67.80
Round  27, Train loss: 0.144, Test loss: 1.222, Test accuracy: 66.90
Round  28, Train loss: 0.123, Test loss: 1.300, Test accuracy: 67.20
Round  29, Train loss: 0.091, Test loss: 1.327, Test accuracy: 66.40
Round  30, Train loss: 0.122, Test loss: 1.235, Test accuracy: 68.70
Round  31, Train loss: 0.100, Test loss: 1.249, Test accuracy: 69.00
Round  32, Train loss: 0.086, Test loss: 1.346, Test accuracy: 67.80
Round  33, Train loss: 0.115, Test loss: 1.222, Test accuracy: 68.60
Round  34, Train loss: 0.091, Test loss: 1.189, Test accuracy: 71.40
Round  35, Train loss: 0.067, Test loss: 1.236, Test accuracy: 70.90
Round  36, Train loss: 0.069, Test loss: 1.265, Test accuracy: 70.30
Round  37, Train loss: 0.076, Test loss: 1.270, Test accuracy: 70.50
Round  38, Train loss: 0.070, Test loss: 1.251, Test accuracy: 70.10
Round  39, Train loss: 0.049, Test loss: 1.380, Test accuracy: 70.50
Final Round, Train loss: 0.033, Test loss: 1.363, Test accuracy: 69.80
Average accuracy final 10 rounds: 69.78
495.960741519928
[7.163618087768555, 12.668492317199707, 17.968404293060303, 23.14937663078308, 28.463944911956787, 33.94589352607727, 39.38159155845642, 45.33873176574707, 51.12436294555664, 56.359206438064575, 61.542548179626465, 66.86113858222961, 72.10634136199951, 77.40065598487854, 82.42327952384949, 87.68127059936523, 93.32431292533875, 98.73272490501404, 104.38306641578674, 110.17992568016052, 115.54512333869934, 121.3163275718689, 127.49229431152344, 133.6145520210266, 139.5430920124054, 145.4838261604309, 150.56296348571777, 156.311026096344, 162.16653656959534, 167.9997148513794, 173.8954212665558, 179.65443301200867, 185.5942826271057, 191.95634198188782, 198.22281312942505, 204.4411859512329, 210.6155970096588, 216.6850528717041, 222.60437154769897, 228.4778027534485, 235.4544324874878]
[29.8, 41.7, 48.1, 56.9, 57.4, 57.4, 61.3, 61.4, 59.6, 64.2, 63.2, 63.9, 64.7, 63.8, 66.6, 65.8, 64.5, 65.9, 68.0, 69.6, 66.4, 66.4, 66.8, 66.7, 67.8, 67.5, 67.8, 66.9, 67.2, 66.4, 68.7, 69.0, 67.8, 68.6, 71.4, 70.9, 70.3, 70.5, 70.1, 70.5, 69.8]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

Traceback (most recent call last):
  File "main_fedrep_increment2.py", line 219, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[c], first=True,isNew=True, local_eps=20)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 787, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
