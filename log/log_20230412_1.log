nohup: 忽略输入
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.499, Test loss: 1.489, Test accuracy: 42.76 

Round   0, Global train loss: 1.499, Global test loss: 2.716, Global test accuracy: 16.00 

Round   1, Train loss: 1.192, Test loss: 1.277, Test accuracy: 52.64 

Round   1, Global train loss: 1.192, Global test loss: 2.603, Global test accuracy: 16.00 

Round   2, Train loss: 1.021, Test loss: 1.280, Test accuracy: 54.72 

Round   2, Global train loss: 1.021, Global test loss: 2.715, Global test accuracy: 16.00 

Round   3, Train loss: 0.882, Test loss: 1.323, Test accuracy: 55.20 

Round   3, Global train loss: 0.882, Global test loss: 2.904, Global test accuracy: 16.00 

Round   4, Train loss: 0.768, Test loss: 1.388, Test accuracy: 58.48 

Round   4, Global train loss: 0.768, Global test loss: 2.826, Global test accuracy: 16.00 

Round   5, Train loss: 0.686, Test loss: 1.335, Test accuracy: 58.92 

Round   5, Global train loss: 0.686, Global test loss: 2.778, Global test accuracy: 16.00 

Round   6, Train loss: 0.552, Test loss: 1.455, Test accuracy: 61.12 

Round   6, Global train loss: 0.552, Global test loss: 3.002, Global test accuracy: 16.00 

Round   7, Train loss: 0.491, Test loss: 1.533, Test accuracy: 59.56 

Round   7, Global train loss: 0.491, Global test loss: 2.865, Global test accuracy: 16.00 

Round   8, Train loss: 0.415, Test loss: 1.684, Test accuracy: 60.20 

Round   8, Global train loss: 0.415, Global test loss: 2.823, Global test accuracy: 16.00 

Round   9, Train loss: 0.360, Test loss: 1.657, Test accuracy: 59.96 

Round   9, Global train loss: 0.360, Global test loss: 2.843, Global test accuracy: 16.00 

Round  10, Train loss: 0.308, Test loss: 1.786, Test accuracy: 59.68 

Round  10, Global train loss: 0.308, Global test loss: 2.771, Global test accuracy: 16.00 

Round  11, Train loss: 0.254, Test loss: 1.768, Test accuracy: 61.92 

Round  11, Global train loss: 0.254, Global test loss: 2.877, Global test accuracy: 16.00 

Round  12, Train loss: 0.220, Test loss: 1.775, Test accuracy: 62.48 

Round  12, Global train loss: 0.220, Global test loss: 2.886, Global test accuracy: 16.00 

Round  13, Train loss: 0.190, Test loss: 1.792, Test accuracy: 62.88 

Round  13, Global train loss: 0.190, Global test loss: 2.897, Global test accuracy: 16.00 

Round  14, Train loss: 0.178, Test loss: 1.832, Test accuracy: 64.12 

Round  14, Global train loss: 0.178, Global test loss: 2.855, Global test accuracy: 16.00 

Round  15, Train loss: 0.144, Test loss: 1.743, Test accuracy: 65.72 

Round  15, Global train loss: 0.144, Global test loss: 2.861, Global test accuracy: 16.00 

Round  16, Train loss: 0.121, Test loss: 1.846, Test accuracy: 63.60 

Round  16, Global train loss: 0.121, Global test loss: 2.883, Global test accuracy: 16.00 

Round  17, Train loss: 0.113, Test loss: 1.771, Test accuracy: 64.12 

Round  17, Global train loss: 0.113, Global test loss: 2.893, Global test accuracy: 16.00 

Round  18, Train loss: 0.098, Test loss: 1.885, Test accuracy: 63.96 

Round  18, Global train loss: 0.098, Global test loss: 2.856, Global test accuracy: 16.00 

Round  19, Train loss: 0.095, Test loss: 2.117, Test accuracy: 63.20 

Round  19, Global train loss: 0.095, Global test loss: 2.938, Global test accuracy: 16.00 

Round  20, Train loss: 0.089, Test loss: 2.090, Test accuracy: 62.92 

Round  20, Global train loss: 0.089, Global test loss: 2.888, Global test accuracy: 16.00 

Round  21, Train loss: 0.075, Test loss: 1.947, Test accuracy: 64.56 

Round  21, Global train loss: 0.075, Global test loss: 2.919, Global test accuracy: 16.00 

Round  22, Train loss: 0.079, Test loss: 1.839, Test accuracy: 66.04 

Round  22, Global train loss: 0.079, Global test loss: 2.808, Global test accuracy: 16.00 

Round  23, Train loss: 0.063, Test loss: 1.891, Test accuracy: 65.28 

Round  23, Global train loss: 0.063, Global test loss: 2.800, Global test accuracy: 16.00 

Round  24, Train loss: 0.048, Test loss: 1.923, Test accuracy: 65.08 

Round  24, Global train loss: 0.048, Global test loss: 2.763, Global test accuracy: 16.00 

Round  25, Train loss: 0.043, Test loss: 2.068, Test accuracy: 64.08 

Round  25, Global train loss: 0.043, Global test loss: 2.842, Global test accuracy: 16.00 

Round  26, Train loss: 0.030, Test loss: 1.960, Test accuracy: 65.60 

Round  26, Global train loss: 0.030, Global test loss: 2.731, Global test accuracy: 16.00 

Round  27, Train loss: 0.047, Test loss: 2.191, Test accuracy: 65.16 

Round  27, Global train loss: 0.047, Global test loss: 2.679, Global test accuracy: 16.00 

Round  28, Train loss: 0.037, Test loss: 1.895, Test accuracy: 67.48 

Round  28, Global train loss: 0.037, Global test loss: 2.685, Global test accuracy: 16.00 

Round  29, Train loss: 0.031, Test loss: 2.118, Test accuracy: 64.68 

Round  29, Global train loss: 0.031, Global test loss: 2.796, Global test accuracy: 16.00 

Round  30, Train loss: 0.042, Test loss: 2.204, Test accuracy: 64.32 

Round  30, Global train loss: 0.042, Global test loss: 2.771, Global test accuracy: 16.00 

Round  31, Train loss: 0.031, Test loss: 1.922, Test accuracy: 65.64 

Round  31, Global train loss: 0.031, Global test loss: 2.779, Global test accuracy: 16.00 

Round  32, Train loss: 0.033, Test loss: 2.108, Test accuracy: 65.40 

Round  32, Global train loss: 0.033, Global test loss: 2.855, Global test accuracy: 16.00 

Round  33, Train loss: 0.031, Test loss: 2.060, Test accuracy: 65.16 

Round  33, Global train loss: 0.031, Global test loss: 2.908, Global test accuracy: 16.00 

Round  34, Train loss: 0.026, Test loss: 1.926, Test accuracy: 66.20 

Round  34, Global train loss: 0.026, Global test loss: 2.856, Global test accuracy: 16.00 

Final Round, Train loss: 0.021, Test loss: 1.956, Test accuracy: 67.08 

Final Round, Global train loss: 0.021, Global test loss: 2.856, Global test accuracy: 16.00 

Average accuracy final 10 rounds: 65.372 

Average global accuracy final 10 rounds: 15.999999999999998 

1296.1738748550415
[8.459341764450073, 14.872000932693481, 21.16992473602295, 27.475990772247314, 33.62823748588562, 40.165828466415405, 46.71491527557373, 52.99522042274475, 59.38193416595459, 65.28848338127136, 71.38967418670654, 77.60394406318665, 84.81950187683105, 91.63601636886597, 98.17310810089111, 104.6088011264801, 110.8739025592804, 117.07489585876465, 123.31598424911499, 129.8062424659729, 136.0782823562622, 142.41088795661926, 148.68635845184326, 155.08147716522217, 161.52439713478088, 167.519389629364, 173.99917340278625, 180.47634291648865, 187.61736178398132, 193.9658603668213, 200.63454508781433, 206.9851152896881, 213.35977792739868, 219.95163679122925, 226.04806780815125, 238.81927251815796]
[42.76, 52.64, 54.72, 55.2, 58.48, 58.92, 61.12, 59.56, 60.2, 59.96, 59.68, 61.92, 62.48, 62.88, 64.12, 65.72, 63.6, 64.12, 63.96, 63.2, 62.92, 64.56, 66.04, 65.28, 65.08, 64.08, 65.6, 65.16, 67.48, 64.68, 64.32, 65.64, 65.4, 65.16, 66.2, 67.08]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.497, Test loss: 1.387, Test accuracy: 46.24 

Round   0, Global train loss: 1.497, Global test loss: 2.659, Global test accuracy: 16.00 

Round   1, Train loss: 1.388, Test loss: 1.279, Test accuracy: 51.88 

Round   1, Global train loss: 1.388, Global test loss: 2.258, Global test accuracy: 19.84 

Round   2, Train loss: 1.254, Test loss: 1.196, Test accuracy: 54.32 

Round   2, Global train loss: 1.254, Global test loss: 1.934, Global test accuracy: 29.60 

Round   3, Train loss: 1.139, Test loss: 1.333, Test accuracy: 53.88 

Round   3, Global train loss: 1.139, Global test loss: 1.747, Global test accuracy: 36.84 

Round   4, Train loss: 1.056, Test loss: 1.296, Test accuracy: 54.32 

Round   4, Global train loss: 1.056, Global test loss: 1.741, Global test accuracy: 36.60 

Round   5, Train loss: 0.981, Test loss: 1.051, Test accuracy: 60.84 

Round   5, Global train loss: 0.981, Global test loss: 1.530, Global test accuracy: 44.56 

Round   6, Train loss: 0.903, Test loss: 1.239, Test accuracy: 58.96 

Round   6, Global train loss: 0.903, Global test loss: 1.633, Global test accuracy: 43.40 

Round   7, Train loss: 0.853, Test loss: 1.221, Test accuracy: 60.20 

Round   7, Global train loss: 0.853, Global test loss: 1.515, Global test accuracy: 45.76 

Round   8, Train loss: 0.795, Test loss: 1.156, Test accuracy: 61.64 

Round   8, Global train loss: 0.795, Global test loss: 1.515, Global test accuracy: 46.08 

Round   9, Train loss: 0.738, Test loss: 1.294, Test accuracy: 59.60 

Round   9, Global train loss: 0.738, Global test loss: 1.448, Global test accuracy: 48.28 

Round  10, Train loss: 0.688, Test loss: 1.210, Test accuracy: 63.04 

Round  10, Global train loss: 0.688, Global test loss: 1.416, Global test accuracy: 49.76 

Round  11, Train loss: 0.644, Test loss: 1.438, Test accuracy: 58.80 

Round  11, Global train loss: 0.644, Global test loss: 1.405, Global test accuracy: 50.92 

Round  12, Train loss: 0.608, Test loss: 1.222, Test accuracy: 65.64 

Round  12, Global train loss: 0.608, Global test loss: 1.389, Global test accuracy: 52.56 

Round  13, Train loss: 0.561, Test loss: 1.553, Test accuracy: 60.60 

Round  13, Global train loss: 0.561, Global test loss: 1.469, Global test accuracy: 52.76 

Round  14, Train loss: 0.524, Test loss: 1.344, Test accuracy: 63.52 

Round  14, Global train loss: 0.524, Global test loss: 1.346, Global test accuracy: 55.88 

Round  15, Train loss: 0.486, Test loss: 1.222, Test accuracy: 65.92 

Round  15, Global train loss: 0.486, Global test loss: 1.327, Global test accuracy: 56.16 

Round  16, Train loss: 0.468, Test loss: 1.491, Test accuracy: 62.16 

Round  16, Global train loss: 0.468, Global test loss: 1.369, Global test accuracy: 55.32 

Round  17, Train loss: 0.439, Test loss: 1.335, Test accuracy: 65.08 

Round  17, Global train loss: 0.439, Global test loss: 1.297, Global test accuracy: 56.92 

Round  18, Train loss: 0.397, Test loss: 1.274, Test accuracy: 66.48 

Round  18, Global train loss: 0.397, Global test loss: 1.416, Global test accuracy: 54.56 

Round  19, Train loss: 0.388, Test loss: 1.276, Test accuracy: 66.52 

Round  19, Global train loss: 0.388, Global test loss: 1.325, Global test accuracy: 57.52 

Round  20, Train loss: 0.331, Test loss: 1.374, Test accuracy: 66.20 

Round  20, Global train loss: 0.331, Global test loss: 1.369, Global test accuracy: 58.24 

Round  21, Train loss: 0.336, Test loss: 1.660, Test accuracy: 61.84 

Round  21, Global train loss: 0.336, Global test loss: 1.349, Global test accuracy: 58.16 

Round  22, Train loss: 0.310, Test loss: 1.394, Test accuracy: 66.12 

Round  22, Global train loss: 0.310, Global test loss: 1.322, Global test accuracy: 59.80 

Round  23, Train loss: 0.287, Test loss: 1.398, Test accuracy: 65.48 

Round  23, Global train loss: 0.287, Global test loss: 1.320, Global test accuracy: 59.24 

Round  24, Train loss: 0.276, Test loss: 1.214, Test accuracy: 69.28 

Round  24, Global train loss: 0.276, Global test loss: 1.378, Global test accuracy: 57.72 

Round  25, Train loss: 0.253, Test loss: 1.323, Test accuracy: 68.24 

Round  25, Global train loss: 0.253, Global test loss: 1.441, Global test accuracy: 57.32 

Round  26, Train loss: 0.246, Test loss: 1.349, Test accuracy: 69.72 

Round  26, Global train loss: 0.246, Global test loss: 1.303, Global test accuracy: 60.28 

Round  27, Train loss: 0.222, Test loss: 1.408, Test accuracy: 67.40 

Round  27, Global train loss: 0.222, Global test loss: 1.283, Global test accuracy: 61.28 

Round  28, Train loss: 0.214, Test loss: 1.350, Test accuracy: 69.84 

Round  28, Global train loss: 0.214, Global test loss: 1.372, Global test accuracy: 58.84 

Round  29, Train loss: 0.195, Test loss: 1.343, Test accuracy: 69.88 

Round  29, Global train loss: 0.195, Global test loss: 1.405, Global test accuracy: 59.96 

Round  30, Train loss: 0.185, Test loss: 1.329, Test accuracy: 69.84 

Round  30, Global train loss: 0.185, Global test loss: 1.358, Global test accuracy: 60.84 

Round  31, Train loss: 0.163, Test loss: 1.424, Test accuracy: 69.24 

Round  31, Global train loss: 0.163, Global test loss: 1.312, Global test accuracy: 61.04 

Round  32, Train loss: 0.177, Test loss: 1.507, Test accuracy: 67.88 

Round  32, Global train loss: 0.177, Global test loss: 1.397, Global test accuracy: 60.20 

Round  33, Train loss: 0.166, Test loss: 1.225, Test accuracy: 71.12 

Round  33, Global train loss: 0.166, Global test loss: 1.388, Global test accuracy: 60.56 

Round  34, Train loss: 0.135, Test loss: 1.618, Test accuracy: 68.24 

Round  34, Global train loss: 0.135, Global test loss: 1.428, Global test accuracy: 60.80 

Round  35, Train loss: 0.138, Test loss: 1.560, Test accuracy: 69.20 

Round  35, Global train loss: 0.138, Global test loss: 1.344, Global test accuracy: 62.08 

Round  36, Train loss: 0.141, Test loss: 1.359, Test accuracy: 71.48 

Round  36, Global train loss: 0.141, Global test loss: 1.330, Global test accuracy: 61.84 

Round  37, Train loss: 0.123, Test loss: 1.529, Test accuracy: 69.20 

Round  37, Global train loss: 0.123, Global test loss: 1.362, Global test accuracy: 62.16 

Round  38, Train loss: 0.123, Test loss: 1.509, Test accuracy: 69.92 

Round  38, Global train loss: 0.123, Global test loss: 1.367, Global test accuracy: 62.76 

Round  39, Train loss: 0.129, Test loss: 1.300, Test accuracy: 71.16 

Round  39, Global train loss: 0.129, Global test loss: 1.329, Global test accuracy: 62.44 

Round  40, Train loss: 0.093, Test loss: 1.520, Test accuracy: 70.84 

Round  40, Global train loss: 0.093, Global test loss: 1.394, Global test accuracy: 62.80 

Round  41, Train loss: 0.095, Test loss: 1.378, Test accuracy: 72.24 

Round  41, Global train loss: 0.095, Global test loss: 1.359, Global test accuracy: 63.56 

Round  42, Train loss: 0.085, Test loss: 1.391, Test accuracy: 71.60 

Round  42, Global train loss: 0.085, Global test loss: 1.399, Global test accuracy: 62.96 

Round  43, Train loss: 0.088, Test loss: 1.540, Test accuracy: 70.76 

Round  43, Global train loss: 0.088, Global test loss: 1.426, Global test accuracy: 62.88 

Round  44, Train loss: 0.078, Test loss: 1.360, Test accuracy: 72.16 

Round  44, Global train loss: 0.078, Global test loss: 1.401, Global test accuracy: 63.44 

Round  45, Train loss: 0.075, Test loss: 1.433, Test accuracy: 72.00 

Round  45, Global train loss: 0.075, Global test loss: 1.421, Global test accuracy: 63.20 

Round  46, Train loss: 0.097, Test loss: 1.470, Test accuracy: 72.36 

Round  46, Global train loss: 0.097, Global test loss: 1.385, Global test accuracy: 63.28 

Round  47, Train loss: 0.063, Test loss: 1.356, Test accuracy: 72.48 

Round  47, Global train loss: 0.063, Global test loss: 1.451, Global test accuracy: 62.28 

Round  48, Train loss: 0.093, Test loss: 1.469, Test accuracy: 70.24 

Round  48, Global train loss: 0.093, Global test loss: 1.414, Global test accuracy: 62.96 

Round  49, Train loss: 0.063, Test loss: 1.554, Test accuracy: 71.32 

Round  49, Global train loss: 0.063, Global test loss: 1.510, Global test accuracy: 61.84 

Final Round, Train loss: 0.098, Test loss: 1.445, Test accuracy: 71.56 

Final Round, Global train loss: 0.098, Global test loss: 1.510, Global test accuracy: 61.84 

Average accuracy final 10 rounds: 71.6 

Average global accuracy final 10 rounds: 62.92 

1801.0732605457306
[8.737544775009155, 15.204532384872437, 21.785003662109375, 28.220674514770508, 34.45392322540283, 40.69933199882507, 47.10659885406494, 53.951435804367065, 60.7163245677948, 67.18558311462402, 73.42982363700867, 79.66185259819031, 85.95040559768677, 92.32162189483643, 98.73954272270203, 105.12874698638916, 111.3839898109436, 117.70498538017273, 124.21672773361206, 130.7317509651184, 136.81279730796814, 142.99830412864685, 149.37191319465637, 156.5487723350525, 162.71311378479004, 169.11403250694275, 175.51511335372925, 182.79395961761475, 188.9425504207611, 195.2579231262207, 201.60590624809265, 208.15000176429749, 214.87413692474365, 221.02200436592102, 226.97712635993958, 233.01556253433228, 238.89673781394958, 244.8830108642578, 250.87314105033875, 256.8089826107025, 262.6733207702637, 268.40708088874817, 274.02238845825195, 279.6873137950897, 285.3671774864197, 291.03989481925964, 296.66363406181335, 302.45790457725525, 308.30440759658813, 314.4498224258423, 326.71576976776123]
[46.24, 51.88, 54.32, 53.88, 54.32, 60.84, 58.96, 60.2, 61.64, 59.6, 63.04, 58.8, 65.64, 60.6, 63.52, 65.92, 62.16, 65.08, 66.48, 66.52, 66.2, 61.84, 66.12, 65.48, 69.28, 68.24, 69.72, 67.4, 69.84, 69.88, 69.84, 69.24, 67.88, 71.12, 68.24, 69.2, 71.48, 69.2, 69.92, 71.16, 70.84, 72.24, 71.6, 70.76, 72.16, 72.0, 72.36, 72.48, 70.24, 71.32, 71.56]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.576, Test loss: 1.941, Test accuracy: 21.72 

Round   1, Train loss: 1.412, Test loss: 1.814, Test accuracy: 26.80 

Round   2, Train loss: 1.295, Test loss: 1.415, Test accuracy: 40.00 

Round   3, Train loss: 1.175, Test loss: 1.102, Test accuracy: 52.84 

Round   4, Train loss: 1.119, Test loss: 1.186, Test accuracy: 51.32 

Round   5, Train loss: 1.042, Test loss: 0.985, Test accuracy: 58.88 

Round   6, Train loss: 0.982, Test loss: 1.029, Test accuracy: 58.88 

Round   7, Train loss: 0.945, Test loss: 1.018, Test accuracy: 58.56 

Round   8, Train loss: 0.891, Test loss: 0.947, Test accuracy: 61.72 

Round   9, Train loss: 0.851, Test loss: 1.125, Test accuracy: 56.76 

Round  10, Train loss: 0.813, Test loss: 1.088, Test accuracy: 59.60 

Round  11, Train loss: 0.777, Test loss: 0.994, Test accuracy: 61.36 

Round  12, Train loss: 0.727, Test loss: 0.901, Test accuracy: 64.40 

Round  13, Train loss: 0.678, Test loss: 0.905, Test accuracy: 66.68 

Round  14, Train loss: 0.652, Test loss: 0.907, Test accuracy: 66.44 

Round  15, Train loss: 0.626, Test loss: 0.861, Test accuracy: 68.40 

Round  16, Train loss: 0.589, Test loss: 0.928, Test accuracy: 66.60 

Round  17, Train loss: 0.558, Test loss: 0.865, Test accuracy: 68.96 

Round  18, Train loss: 0.520, Test loss: 0.850, Test accuracy: 69.64 

Round  19, Train loss: 0.495, Test loss: 0.891, Test accuracy: 69.84 

Round  20, Train loss: 0.479, Test loss: 0.919, Test accuracy: 68.64 

Round  21, Train loss: 0.449, Test loss: 0.891, Test accuracy: 70.20 

Round  22, Train loss: 0.406, Test loss: 0.865, Test accuracy: 70.32 

Round  23, Train loss: 0.428, Test loss: 0.950, Test accuracy: 69.12 

Round  24, Train loss: 0.372, Test loss: 0.855, Test accuracy: 70.88 

Round  25, Train loss: 0.355, Test loss: 0.860, Test accuracy: 71.88 

Round  26, Train loss: 0.320, Test loss: 0.903, Test accuracy: 70.56 

Round  27, Train loss: 0.311, Test loss: 0.948, Test accuracy: 70.68 

Round  28, Train loss: 0.301, Test loss: 0.877, Test accuracy: 71.60 

Round  29, Train loss: 0.279, Test loss: 0.926, Test accuracy: 71.08 

Round  30, Train loss: 0.266, Test loss: 0.946, Test accuracy: 71.20 

Round  31, Train loss: 0.249, Test loss: 0.933, Test accuracy: 71.44 

Round  32, Train loss: 0.227, Test loss: 0.886, Test accuracy: 72.04 

Round  33, Train loss: 0.210, Test loss: 0.952, Test accuracy: 71.68 

Round  34, Train loss: 0.214, Test loss: 0.940, Test accuracy: 71.60 

Round  35, Train loss: 0.191, Test loss: 0.896, Test accuracy: 73.28 

Round  36, Train loss: 0.185, Test loss: 0.911, Test accuracy: 72.44 

Round  37, Train loss: 0.166, Test loss: 0.869, Test accuracy: 74.44 

Round  38, Train loss: 0.170, Test loss: 0.896, Test accuracy: 73.96 

Round  39, Train loss: 0.145, Test loss: 0.921, Test accuracy: 74.76 

Round  40, Train loss: 0.157, Test loss: 0.940, Test accuracy: 72.16 

Round  41, Train loss: 0.131, Test loss: 0.939, Test accuracy: 73.52 

Round  42, Train loss: 0.134, Test loss: 0.923, Test accuracy: 73.92 

Round  43, Train loss: 0.127, Test loss: 0.923, Test accuracy: 74.40 

Round  44, Train loss: 0.115, Test loss: 0.959, Test accuracy: 73.68 

Round  45, Train loss: 0.109, Test loss: 0.974, Test accuracy: 72.88 

Round  46, Train loss: 0.095, Test loss: 0.988, Test accuracy: 73.76 

Round  47, Train loss: 0.085, Test loss: 1.043, Test accuracy: 73.76 

Round  48, Train loss: 0.080, Test loss: 0.992, Test accuracy: 73.84 

Round  49, Train loss: 0.096, Test loss: 1.053, Test accuracy: 74.04 

Final Round, Train loss: 0.046, Test loss: 1.042, Test accuracy: 73.28 

Average accuracy final 10 rounds: 73.59599999999999 

1322.1630859375
[7.85056471824646, 12.94767451286316, 17.983213186264038, 22.869065284729004, 27.820438623428345, 32.62775897979736, 37.44676375389099, 42.45772695541382, 47.276606798172, 51.95804810523987, 56.59274363517761, 61.12927532196045, 65.71373534202576, 70.34662699699402, 74.82744646072388, 79.31875538825989, 83.81757164001465, 88.36153316497803, 92.94871640205383, 97.49317932128906, 102.36462640762329, 107.44922041893005, 112.56128668785095, 117.53643846511841, 122.42510604858398, 127.36764097213745, 132.2485909461975, 137.08894109725952, 141.94981336593628, 146.9085144996643, 151.77260184288025, 156.6742503643036, 161.56178665161133, 166.3620913028717, 171.00843453407288, 175.63350987434387, 180.34332013130188, 184.9934515953064, 189.530752658844, 194.05161952972412, 198.5462031364441, 203.09126353263855, 207.7201361656189, 212.44850707054138, 217.20934748649597, 222.0918505191803, 227.2272071838379, 232.18925070762634, 237.01835417747498, 241.8079378604889, 248.26709389686584]
[21.72, 26.8, 40.0, 52.84, 51.32, 58.88, 58.88, 58.56, 61.72, 56.76, 59.6, 61.36, 64.4, 66.68, 66.44, 68.4, 66.6, 68.96, 69.64, 69.84, 68.64, 70.2, 70.32, 69.12, 70.88, 71.88, 70.56, 70.68, 71.6, 71.08, 71.2, 71.44, 72.04, 71.68, 71.6, 73.28, 72.44, 74.44, 73.96, 74.76, 72.16, 73.52, 73.92, 74.4, 73.68, 72.88, 73.76, 73.76, 73.84, 74.04, 73.28]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
Round   0, Train loss: 1.574, Test loss: 1.827, Test accuracy: 22.48
Round   1, Train loss: 1.411, Test loss: 1.696, Test accuracy: 29.60
Round   2, Train loss: 1.260, Test loss: 1.257, Test accuracy: 44.36
Round   3, Train loss: 1.165, Test loss: 1.108, Test accuracy: 52.88
Round   4, Train loss: 1.106, Test loss: 1.198, Test accuracy: 50.96
Round   5, Train loss: 1.033, Test loss: 1.061, Test accuracy: 55.76
Round   6, Train loss: 0.986, Test loss: 1.014, Test accuracy: 59.44
Round   7, Train loss: 0.918, Test loss: 1.031, Test accuracy: 57.84
Round   8, Train loss: 0.889, Test loss: 1.033, Test accuracy: 59.92
Round   9, Train loss: 0.848, Test loss: 0.909, Test accuracy: 64.24
Round  10, Train loss: 0.804, Test loss: 0.923, Test accuracy: 63.16
Round  11, Train loss: 0.766, Test loss: 0.994, Test accuracy: 62.16
Round  12, Train loss: 0.730, Test loss: 0.944, Test accuracy: 63.80
Round  13, Train loss: 0.693, Test loss: 0.910, Test accuracy: 65.40
Round  14, Train loss: 0.649, Test loss: 0.905, Test accuracy: 64.76
Round  15, Train loss: 0.619, Test loss: 0.888, Test accuracy: 66.72
Round  16, Train loss: 0.592, Test loss: 0.871, Test accuracy: 68.76
Round  17, Train loss: 0.568, Test loss: 0.815, Test accuracy: 69.80
Round  18, Train loss: 0.527, Test loss: 0.863, Test accuracy: 69.40
Round  19, Train loss: 0.494, Test loss: 0.960, Test accuracy: 66.64
Round  20, Train loss: 0.477, Test loss: 0.838, Test accuracy: 70.92
Round  21, Train loss: 0.451, Test loss: 0.820, Test accuracy: 71.52
Round  22, Train loss: 0.419, Test loss: 0.872, Test accuracy: 70.32
Round  23, Train loss: 0.397, Test loss: 0.866, Test accuracy: 70.88
Round  24, Train loss: 0.372, Test loss: 0.839, Test accuracy: 71.76
Round  25, Train loss: 0.344, Test loss: 0.849, Test accuracy: 71.48
Round  26, Train loss: 0.335, Test loss: 0.815, Test accuracy: 72.08
Round  27, Train loss: 0.314, Test loss: 0.856, Test accuracy: 71.80
Round  28, Train loss: 0.290, Test loss: 0.859, Test accuracy: 72.84
Round  29, Train loss: 0.278, Test loss: 0.887, Test accuracy: 72.16
Round  30, Train loss: 0.266, Test loss: 0.857, Test accuracy: 72.04
Round  31, Train loss: 0.258, Test loss: 0.833, Test accuracy: 73.36
Round  32, Train loss: 0.224, Test loss: 0.840, Test accuracy: 74.00
Round  33, Train loss: 0.213, Test loss: 0.874, Test accuracy: 72.96
Round  34, Train loss: 0.201, Test loss: 0.842, Test accuracy: 74.20
Round  35, Train loss: 0.186, Test loss: 0.859, Test accuracy: 73.92
Round  36, Train loss: 0.181, Test loss: 0.906, Test accuracy: 73.28
Round  37, Train loss: 0.177, Test loss: 0.871, Test accuracy: 73.76
Round  38, Train loss: 0.157, Test loss: 0.882, Test accuracy: 73.88
Round  39, Train loss: 0.147, Test loss: 0.898, Test accuracy: 73.72
Round  40, Train loss: 0.143, Test loss: 0.883, Test accuracy: 74.36
Round  41, Train loss: 0.133, Test loss: 0.911, Test accuracy: 74.12
Round  42, Train loss: 0.125, Test loss: 0.904, Test accuracy: 74.80
Round  43, Train loss: 0.116, Test loss: 0.922, Test accuracy: 75.04
Round  44, Train loss: 0.126, Test loss: 0.885, Test accuracy: 74.68
Round  45, Train loss: 0.101, Test loss: 0.943, Test accuracy: 74.64
Round  46, Train loss: 0.114, Test loss: 0.889, Test accuracy: 74.52
Round  47, Train loss: 0.101, Test loss: 0.900, Test accuracy: 74.36
Round  48, Train loss: 0.085, Test loss: 0.898, Test accuracy: 74.96
Round  49, Train loss: 0.082, Test loss: 0.890, Test accuracy: 75.64
Final Round, Train loss: 0.044, Test loss: 0.889, Test accuracy: 75.68
Average accuracy final 10 rounds: 74.71199999999999
1500.6857442855835
[9.23681378364563, 14.996619939804077, 20.797844886779785, 26.47206711769104, 32.48109841346741, 38.08566689491272, 43.315669536590576, 48.61183428764343, 53.82379102706909, 58.8573477268219, 64.08304333686829, 69.17956233024597, 74.41123986244202, 79.74702882766724, 84.92502307891846, 90.55347418785095, 96.16619801521301, 102.27302360534668, 107.95097589492798, 113.45664978027344, 119.11088418960571, 124.81932044029236, 130.79361081123352, 136.77507948875427, 142.62715983390808, 148.3222155570984, 153.9993758201599, 159.63805150985718, 164.81386256217957, 170.0067880153656, 175.07180333137512, 180.08820939064026, 185.22233200073242, 190.22197103500366, 195.66347241401672, 200.94284772872925, 206.19512009620667, 211.5553982257843, 217.12574744224548, 223.25325894355774, 228.8336956501007, 234.3597447872162, 239.96980738639832, 245.64246821403503, 251.44791507720947, 257.195791721344, 262.9348874092102, 268.8366742134094, 274.4001338481903, 280.0180480480194, 286.24939799308777]
[22.48, 29.6, 44.36, 52.88, 50.96, 55.76, 59.44, 57.84, 59.92, 64.24, 63.16, 62.16, 63.8, 65.4, 64.76, 66.72, 68.76, 69.8, 69.4, 66.64, 70.92, 71.52, 70.32, 70.88, 71.76, 71.48, 72.08, 71.8, 72.84, 72.16, 72.04, 73.36, 74.0, 72.96, 74.2, 73.92, 73.28, 73.76, 73.88, 73.72, 74.36, 74.12, 74.8, 75.04, 74.68, 74.64, 74.52, 74.36, 74.96, 75.64, 75.68]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

        init --> train local model(freeze embeding):client   0,  Train loss: 1.049, Train accuracy: 59.600, Test loss: 1.257, Test accuracy: 49.40 

        train local model (freeze embeding):client   0,  Train loss: 0.956, Train accuracy: 60.200, Test loss: 1.147, Test accuracy: 54.00 

        train local model (unfreeze embeding):client   0,  Train loss: 1.417, Train accuracy: 38.800, Test loss: 1.503, Test accuracy: 36.60 

Round   0, Train loss: 1.236, Test loss: 1.503, Test accuracy: 36.60 

        train local model (freeze embeding):client   0,  Train loss: 1.053, Train accuracy: 57.800, Test loss: 1.231, Test accuracy: 55.60 

        train local model (unfreeze embeding):client   0,  Train loss: 1.086, Train accuracy: 56.800, Test loss: 1.311, Test accuracy: 47.80 

Round   1, Train loss: 1.233, Test loss: 1.311, Test accuracy: 47.80 

        train local model (freeze embeding):client   0,  Train loss: 1.098, Train accuracy: 60.600, Test loss: 1.583, Test accuracy: 49.20 

        train local model (unfreeze embeding):client   0,  Train loss: 1.265, Train accuracy: 45.200, Test loss: 1.383, Test accuracy: 43.60 

Round   2, Train loss: 1.321, Test loss: 1.383, Test accuracy: 43.60 

        train local model (freeze embeding):client   0,  Train loss: 1.157, Train accuracy: 59.200, Test loss: 1.629, Test accuracy: 49.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.969, Train accuracy: 60.800, Test loss: 1.240, Test accuracy: 54.20 

Round   3, Train loss: 1.271, Test loss: 1.240, Test accuracy: 54.20 

        train local model (freeze embeding):client   0,  Train loss: 1.024, Train accuracy: 60.000, Test loss: 1.480, Test accuracy: 50.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.909, Train accuracy: 60.400, Test loss: 1.140, Test accuracy: 52.00 

Round   4, Train loss: 1.313, Test loss: 1.140, Test accuracy: 52.00 

        train local model (freeze embeding):client   0,  Train loss: 1.039, Train accuracy: 64.400, Test loss: 1.583, Test accuracy: 53.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.954, Train accuracy: 60.800, Test loss: 1.133, Test accuracy: 52.60 

Round   5, Train loss: 1.227, Test loss: 1.133, Test accuracy: 52.60 

        train local model (freeze embeding):client   0,  Train loss: 0.841, Train accuracy: 69.600, Test loss: 1.295, Test accuracy: 54.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.841, Train accuracy: 66.200, Test loss: 1.271, Test accuracy: 57.20 

Round   6, Train loss: 1.227, Test loss: 1.271, Test accuracy: 57.20 

        train local model (freeze embeding):client   0,  Train loss: 1.466, Train accuracy: 57.600, Test loss: 1.996, Test accuracy: 52.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.768, Train accuracy: 69.600, Test loss: 1.226, Test accuracy: 51.00 

Round   7, Train loss: 1.215, Test loss: 1.226, Test accuracy: 51.00 

        train local model (freeze embeding):client   0,  Train loss: 1.096, Train accuracy: 63.400, Test loss: 1.756, Test accuracy: 53.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.753, Train accuracy: 71.000, Test loss: 1.203, Test accuracy: 53.80 

Round   8, Train loss: 1.114, Test loss: 1.203, Test accuracy: 53.80 

        train local model (freeze embeding):client   0,  Train loss: 1.100, Train accuracy: 64.400, Test loss: 1.776, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.842, Train accuracy: 64.400, Test loss: 1.416, Test accuracy: 51.80 

Round   9, Train loss: 1.186, Test loss: 1.416, Test accuracy: 51.80 

        train local model (freeze embeding):client   0,  Train loss: 0.798, Train accuracy: 69.600, Test loss: 1.522, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.834, Train accuracy: 69.800, Test loss: 1.406, Test accuracy: 52.80 

Round  10, Train loss: 1.117, Test loss: 1.406, Test accuracy: 52.80 

        train local model (freeze embeding):client   0,  Train loss: 1.023, Train accuracy: 68.600, Test loss: 1.714, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.754, Train accuracy: 70.200, Test loss: 1.586, Test accuracy: 53.20 

Round  11, Train loss: 1.061, Test loss: 1.586, Test accuracy: 53.20 

        train local model (freeze embeding):client   0,  Train loss: 0.778, Train accuracy: 70.400, Test loss: 1.640, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.731, Train accuracy: 68.400, Test loss: 1.471, Test accuracy: 51.00 

Round  12, Train loss: 1.080, Test loss: 1.471, Test accuracy: 51.00 

        train local model (freeze embeding):client   0,  Train loss: 0.662, Train accuracy: 74.200, Test loss: 1.425, Test accuracy: 54.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.746, Train accuracy: 70.400, Test loss: 1.300, Test accuracy: 53.20 

Round  13, Train loss: 1.052, Test loss: 1.300, Test accuracy: 53.20 

        train local model (freeze embeding):client   0,  Train loss: 0.812, Train accuracy: 69.600, Test loss: 1.635, Test accuracy: 53.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.611, Train accuracy: 76.400, Test loss: 1.410, Test accuracy: 54.60 

Round  14, Train loss: 0.921, Test loss: 1.410, Test accuracy: 54.60 

        train local model (freeze embeding):client   0,  Train loss: 0.944, Train accuracy: 66.000, Test loss: 1.761, Test accuracy: 51.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.508, Train accuracy: 80.200, Test loss: 1.326, Test accuracy: 57.40 

Round  15, Train loss: 0.951, Test loss: 1.326, Test accuracy: 57.40 

        train local model (freeze embeding):client   0,  Train loss: 0.858, Train accuracy: 67.200, Test loss: 1.628, Test accuracy: 50.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.502, Train accuracy: 81.600, Test loss: 1.622, Test accuracy: 53.20 

Round  16, Train loss: 0.924, Test loss: 1.622, Test accuracy: 53.20 

        train local model (freeze embeding):client   0,  Train loss: 1.101, Train accuracy: 64.000, Test loss: 2.142, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.665, Train accuracy: 72.800, Test loss: 1.620, Test accuracy: 51.20 

Round  17, Train loss: 0.923, Test loss: 1.620, Test accuracy: 51.20 

        train local model (freeze embeding):client   0,  Train loss: 0.656, Train accuracy: 72.000, Test loss: 1.509, Test accuracy: 54.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.491, Train accuracy: 81.400, Test loss: 1.595, Test accuracy: 55.20 

Round  18, Train loss: 0.959, Test loss: 1.595, Test accuracy: 55.20 

        train local model (freeze embeding):client   0,  Train loss: 0.833, Train accuracy: 68.200, Test loss: 1.685, Test accuracy: 53.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.510, Train accuracy: 80.400, Test loss: 1.667, Test accuracy: 53.20 

Round  19, Train loss: 0.903, Test loss: 1.667, Test accuracy: 53.20 

        train local model (freeze embeding):client   0,  Train loss: 0.711, Train accuracy: 71.000, Test loss: 1.483, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.498, Train accuracy: 79.600, Test loss: 1.552, Test accuracy: 52.80 

Final Round, Train loss: 0.919, Test loss: 1.698, Test accuracy: 51.60 

---------------------------------------------train_client: [0, 1] 

        init --> train local model(freeze embeding):client   1,  Train loss: 2.272, Train accuracy: 50.800, Test loss: 2.456, Test accuracy: 47.80 

        train local model (freeze embeding):client   0,  Train loss: 0.845, Train accuracy: 66.000, Test loss: 1.578, Test accuracy: 53.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.634, Train accuracy: 75.400, Test loss: 1.460, Test accuracy: 52.00 

        train local model (freeze embeding):client   1,  Train loss: 1.087, Train accuracy: 56.200, Test loss: 1.230, Test accuracy: 55.80 

        train local model (unfreeze embeding):client   1,  Train loss: 1.007, Train accuracy: 54.800, Test loss: 1.104, Test accuracy: 52.20 

Round   0, Train loss: 1.058, Test loss: 1.279, Test accuracy: 53.20 

        train local model (freeze embeding):client   0,  Train loss: 1.089, Train accuracy: 62.400, Test loss: 1.820, Test accuracy: 49.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.533, Train accuracy: 78.800, Test loss: 1.510, Test accuracy: 54.40 

        train local model (freeze embeding):client   1,  Train loss: 0.916, Train accuracy: 62.800, Test loss: 1.183, Test accuracy: 57.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.800, Train accuracy: 70.000, Test loss: 1.006, Test accuracy: 62.20 

Round   1, Train loss: 1.024, Test loss: 1.160, Test accuracy: 60.10 

        train local model (freeze embeding):client   0,  Train loss: 0.830, Train accuracy: 66.800, Test loss: 1.353, Test accuracy: 53.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.617, Train accuracy: 75.000, Test loss: 1.778, Test accuracy: 52.40 

        train local model (freeze embeding):client   1,  Train loss: 1.314, Train accuracy: 59.800, Test loss: 1.465, Test accuracy: 51.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.698, Train accuracy: 72.600, Test loss: 1.016, Test accuracy: 58.20 

Round   2, Train loss: 1.021, Test loss: 1.190, Test accuracy: 58.00 

        train local model (freeze embeding):client   0,  Train loss: 0.824, Train accuracy: 65.000, Test loss: 1.509, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.433, Train accuracy: 84.200, Test loss: 1.434, Test accuracy: 53.60 

        train local model (freeze embeding):client   1,  Train loss: 0.890, Train accuracy: 63.400, Test loss: 1.132, Test accuracy: 56.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.720, Train accuracy: 71.600, Test loss: 0.989, Test accuracy: 62.60 

Round   3, Train loss: 0.995, Test loss: 1.083, Test accuracy: 60.70 

        train local model (freeze embeding):client   0,  Train loss: 1.049, Train accuracy: 59.200, Test loss: 1.572, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.436, Train accuracy: 83.000, Test loss: 1.469, Test accuracy: 56.40 

        train local model (freeze embeding):client   1,  Train loss: 0.907, Train accuracy: 61.600, Test loss: 1.157, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.693, Train accuracy: 70.000, Test loss: 0.994, Test accuracy: 61.00 

Round   4, Train loss: 0.961, Test loss: 1.150, Test accuracy: 59.10 

        train local model (freeze embeding):client   0,  Train loss: 0.926, Train accuracy: 64.800, Test loss: 1.469, Test accuracy: 51.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.443, Train accuracy: 83.000, Test loss: 1.563, Test accuracy: 54.00 

        train local model (freeze embeding):client   1,  Train loss: 0.953, Train accuracy: 63.800, Test loss: 1.148, Test accuracy: 56.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.651, Train accuracy: 74.800, Test loss: 0.979, Test accuracy: 63.80 

Round   5, Train loss: 0.964, Test loss: 1.204, Test accuracy: 58.70 

        train local model (freeze embeding):client   0,  Train loss: 1.007, Train accuracy: 61.800, Test loss: 1.489, Test accuracy: 49.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.465, Train accuracy: 83.600, Test loss: 1.579, Test accuracy: 53.80 

        train local model (freeze embeding):client   1,  Train loss: 0.869, Train accuracy: 64.000, Test loss: 1.216, Test accuracy: 55.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.625, Train accuracy: 76.200, Test loss: 0.982, Test accuracy: 60.20 

Round   6, Train loss: 0.962, Test loss: 1.173, Test accuracy: 60.10 

        train local model (freeze embeding):client   0,  Train loss: 0.873, Train accuracy: 64.600, Test loss: 1.405, Test accuracy: 51.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.610, Train accuracy: 76.600, Test loss: 1.537, Test accuracy: 56.00 

        train local model (freeze embeding):client   1,  Train loss: 0.795, Train accuracy: 66.800, Test loss: 1.034, Test accuracy: 61.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.724, Train accuracy: 70.800, Test loss: 1.049, Test accuracy: 58.40 

Round   7, Train loss: 0.957, Test loss: 1.117, Test accuracy: 61.70 

        train local model (freeze embeding):client   0,  Train loss: 0.979, Train accuracy: 61.800, Test loss: 1.469, Test accuracy: 51.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.459, Train accuracy: 83.400, Test loss: 1.469, Test accuracy: 57.80 

        train local model (freeze embeding):client   1,  Train loss: 1.048, Train accuracy: 60.600, Test loss: 1.220, Test accuracy: 54.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.627, Train accuracy: 74.400, Test loss: 1.015, Test accuracy: 58.80 

Round   8, Train loss: 0.987, Test loss: 1.137, Test accuracy: 59.90 

        train local model (freeze embeding):client   0,  Train loss: 1.123, Train accuracy: 61.000, Test loss: 1.684, Test accuracy: 50.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.443, Train accuracy: 83.800, Test loss: 1.528, Test accuracy: 56.80 

        train local model (freeze embeding):client   1,  Train loss: 0.847, Train accuracy: 63.800, Test loss: 1.092, Test accuracy: 56.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.681, Train accuracy: 73.600, Test loss: 1.097, Test accuracy: 57.60 

Round   9, Train loss: 0.986, Test loss: 1.130, Test accuracy: 60.20 

        train local model (freeze embeding):client   0,  Train loss: 0.796, Train accuracy: 68.200, Test loss: 1.374, Test accuracy: 55.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.400, Train accuracy: 85.800, Test loss: 1.567, Test accuracy: 55.40 

        train local model (freeze embeding):client   1,  Train loss: 1.028, Train accuracy: 55.400, Test loss: 1.308, Test accuracy: 51.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.606, Train accuracy: 74.200, Test loss: 1.123, Test accuracy: 58.20 

Round  10, Train loss: 0.912, Test loss: 1.218, Test accuracy: 59.70 

        train local model (freeze embeding):client   0,  Train loss: 1.002, Train accuracy: 63.000, Test loss: 1.485, Test accuracy: 51.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.452, Train accuracy: 84.800, Test loss: 1.369, Test accuracy: 56.40 

        train local model (freeze embeding):client   1,  Train loss: 0.880, Train accuracy: 63.200, Test loss: 1.108, Test accuracy: 59.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.686, Train accuracy: 70.200, Test loss: 1.191, Test accuracy: 54.60 

Round  11, Train loss: 0.937, Test loss: 1.102, Test accuracy: 61.00 

        train local model (freeze embeding):client   0,  Train loss: 1.315, Train accuracy: 55.400, Test loss: 1.839, Test accuracy: 46.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.472, Train accuracy: 82.000, Test loss: 1.458, Test accuracy: 54.20 

        train local model (freeze embeding):client   1,  Train loss: 0.983, Train accuracy: 60.400, Test loss: 1.183, Test accuracy: 56.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.565, Train accuracy: 78.000, Test loss: 1.011, Test accuracy: 61.20 

Round  12, Train loss: 0.946, Test loss: 1.132, Test accuracy: 60.80 

        train local model (freeze embeding):client   0,  Train loss: 1.050, Train accuracy: 59.600, Test loss: 1.481, Test accuracy: 48.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.470, Train accuracy: 82.000, Test loss: 1.431, Test accuracy: 59.80 

        train local model (freeze embeding):client   1,  Train loss: 0.974, Train accuracy: 61.400, Test loss: 1.321, Test accuracy: 54.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.560, Train accuracy: 78.400, Test loss: 1.073, Test accuracy: 58.60 

Round  13, Train loss: 0.902, Test loss: 1.089, Test accuracy: 61.20 

        train local model (freeze embeding):client   0,  Train loss: 0.885, Train accuracy: 64.000, Test loss: 1.416, Test accuracy: 48.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.518, Train accuracy: 82.000, Test loss: 1.465, Test accuracy: 55.00 

        train local model (freeze embeding):client   1,  Train loss: 1.056, Train accuracy: 63.000, Test loss: 1.341, Test accuracy: 53.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.624, Train accuracy: 75.200, Test loss: 1.130, Test accuracy: 56.60 

Round  14, Train loss: 0.935, Test loss: 1.155, Test accuracy: 59.00 

        train local model (freeze embeding):client   0,  Train loss: 0.992, Train accuracy: 61.800, Test loss: 1.421, Test accuracy: 48.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.449, Train accuracy: 83.200, Test loss: 1.397, Test accuracy: 58.00 

        train local model (freeze embeding):client   1,  Train loss: 0.858, Train accuracy: 65.600, Test loss: 1.173, Test accuracy: 55.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.617, Train accuracy: 75.000, Test loss: 1.122, Test accuracy: 57.60 

Round  15, Train loss: 0.945, Test loss: 1.183, Test accuracy: 57.90 

        train local model (freeze embeding):client   0,  Train loss: 1.031, Train accuracy: 58.200, Test loss: 1.495, Test accuracy: 47.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.545, Train accuracy: 78.400, Test loss: 1.696, Test accuracy: 56.40 

        train local model (freeze embeding):client   1,  Train loss: 0.860, Train accuracy: 64.000, Test loss: 1.127, Test accuracy: 56.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.576, Train accuracy: 77.000, Test loss: 1.127, Test accuracy: 59.20 

Round  16, Train loss: 0.891, Test loss: 1.215, Test accuracy: 60.20 

        train local model (freeze embeding):client   0,  Train loss: 0.923, Train accuracy: 63.400, Test loss: 1.281, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.449, Train accuracy: 81.200, Test loss: 1.396, Test accuracy: 58.20 

        train local model (freeze embeding):client   1,  Train loss: 0.913, Train accuracy: 62.000, Test loss: 1.155, Test accuracy: 56.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.490, Train accuracy: 81.600, Test loss: 1.005, Test accuracy: 61.80 

Round  17, Train loss: 0.943, Test loss: 1.113, Test accuracy: 60.10 

        train local model (freeze embeding):client   0,  Train loss: 1.024, Train accuracy: 58.200, Test loss: 1.489, Test accuracy: 48.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.459, Train accuracy: 82.400, Test loss: 1.509, Test accuracy: 53.60 

        train local model (freeze embeding):client   1,  Train loss: 0.840, Train accuracy: 63.200, Test loss: 1.162, Test accuracy: 54.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.734, Train accuracy: 70.200, Test loss: 1.241, Test accuracy: 55.80 

Round  18, Train loss: 0.901, Test loss: 1.128, Test accuracy: 60.50 

        train local model (freeze embeding):client   0,  Train loss: 1.244, Train accuracy: 52.800, Test loss: 1.670, Test accuracy: 43.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.514, Train accuracy: 78.600, Test loss: 1.547, Test accuracy: 58.00 

        train local model (freeze embeding):client   1,  Train loss: 1.207, Train accuracy: 58.000, Test loss: 1.414, Test accuracy: 52.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.518, Train accuracy: 79.800, Test loss: 1.018, Test accuracy: 60.40 

Round  19, Train loss: 0.929, Test loss: 1.175, Test accuracy: 61.70 

        train local model (freeze embeding):client   0,  Train loss: 1.195, Train accuracy: 52.600, Test loss: 1.592, Test accuracy: 45.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.447, Train accuracy: 82.600, Test loss: 1.292, Test accuracy: 58.40 

        train local model (freeze embeding):client   1,  Train loss: 0.998, Train accuracy: 58.000, Test loss: 1.239, Test accuracy: 52.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.503, Train accuracy: 82.000, Test loss: 1.063, Test accuracy: 61.00 

Final Round, Train loss: 0.919, Test loss: 1.146, Test accuracy: 61.60 

---------------------------------------------train_client: [0, 1, 2] 

        init --> train local model(freeze embeding):client   2,  Train loss: 1.302, Train accuracy: 44.000, Test loss: 1.366, Test accuracy: 41.40 

        train local model (freeze embeding):client   0,  Train loss: 0.953, Train accuracy: 59.400, Test loss: 1.287, Test accuracy: 52.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.449, Train accuracy: 82.600, Test loss: 1.365, Test accuracy: 56.60 

        train local model (freeze embeding):client   1,  Train loss: 0.882, Train accuracy: 63.400, Test loss: 1.184, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.510, Train accuracy: 80.000, Test loss: 1.112, Test accuracy: 57.80 

        train local model (freeze embeding):client   2,  Train loss: 1.150, Train accuracy: 51.800, Test loss: 1.237, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   2,  Train loss: 1.017, Train accuracy: 57.400, Test loss: 1.146, Test accuracy: 50.20 

Round   0, Train loss: 1.020, Test loss: 1.085, Test accuracy: 59.13 

        train local model (freeze embeding):client   0,  Train loss: 1.111, Train accuracy: 55.000, Test loss: 1.509, Test accuracy: 44.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.465, Train accuracy: 83.800, Test loss: 1.355, Test accuracy: 57.20 

        train local model (freeze embeding):client   1,  Train loss: 0.957, Train accuracy: 62.000, Test loss: 1.220, Test accuracy: 55.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.563, Train accuracy: 78.400, Test loss: 1.134, Test accuracy: 59.20 

        train local model (freeze embeding):client   2,  Train loss: 1.183, Train accuracy: 51.800, Test loss: 1.284, Test accuracy: 47.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.861, Train accuracy: 64.200, Test loss: 1.001, Test accuracy: 58.00 

Round   1, Train loss: 0.997, Test loss: 1.055, Test accuracy: 60.73 

        train local model (freeze embeding):client   0,  Train loss: 0.963, Train accuracy: 60.000, Test loss: 1.373, Test accuracy: 46.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.559, Train accuracy: 78.200, Test loss: 1.344, Test accuracy: 58.20 

        train local model (freeze embeding):client   1,  Train loss: 0.840, Train accuracy: 66.200, Test loss: 1.141, Test accuracy: 54.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.486, Train accuracy: 81.800, Test loss: 1.026, Test accuracy: 63.00 

        train local model (freeze embeding):client   2,  Train loss: 1.107, Train accuracy: 54.000, Test loss: 1.227, Test accuracy: 49.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.850, Train accuracy: 65.400, Test loss: 1.058, Test accuracy: 56.40 

Round   2, Train loss: 0.993, Test loss: 1.073, Test accuracy: 60.07 

        train local model (freeze embeding):client   0,  Train loss: 0.996, Train accuracy: 58.800, Test loss: 1.340, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.503, Train accuracy: 80.400, Test loss: 1.324, Test accuracy: 57.80 

        train local model (freeze embeding):client   1,  Train loss: 0.808, Train accuracy: 67.200, Test loss: 1.090, Test accuracy: 56.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.461, Train accuracy: 84.800, Test loss: 1.025, Test accuracy: 62.20 

        train local model (freeze embeding):client   2,  Train loss: 1.072, Train accuracy: 55.600, Test loss: 1.266, Test accuracy: 47.40 

        train local model (unfreeze embeding):client   2,  Train loss: 1.016, Train accuracy: 62.600, Test loss: 1.283, Test accuracy: 53.60 

Round   3, Train loss: 0.979, Test loss: 1.122, Test accuracy: 59.33 

        train local model (freeze embeding):client   0,  Train loss: 0.985, Train accuracy: 60.600, Test loss: 1.314, Test accuracy: 48.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.465, Train accuracy: 82.800, Test loss: 1.388, Test accuracy: 56.20 

        train local model (freeze embeding):client   1,  Train loss: 0.899, Train accuracy: 63.400, Test loss: 1.147, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.511, Train accuracy: 78.800, Test loss: 1.051, Test accuracy: 59.20 

        train local model (freeze embeding):client   2,  Train loss: 1.363, Train accuracy: 47.400, Test loss: 1.549, Test accuracy: 47.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.854, Train accuracy: 66.200, Test loss: 1.140, Test accuracy: 52.60 

Round   4, Train loss: 0.987, Test loss: 1.077, Test accuracy: 59.27 

        train local model (freeze embeding):client   0,  Train loss: 0.996, Train accuracy: 61.800, Test loss: 1.429, Test accuracy: 49.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.616, Train accuracy: 76.200, Test loss: 1.396, Test accuracy: 53.20 

        train local model (freeze embeding):client   1,  Train loss: 1.043, Train accuracy: 56.800, Test loss: 1.267, Test accuracy: 50.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.479, Train accuracy: 83.200, Test loss: 1.101, Test accuracy: 58.60 

        train local model (freeze embeding):client   2,  Train loss: 1.201, Train accuracy: 47.400, Test loss: 1.413, Test accuracy: 41.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.762, Train accuracy: 70.400, Test loss: 1.070, Test accuracy: 57.80 

Round   5, Train loss: 0.981, Test loss: 1.095, Test accuracy: 59.13 

        train local model (freeze embeding):client   0,  Train loss: 0.980, Train accuracy: 58.400, Test loss: 1.307, Test accuracy: 48.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.547, Train accuracy: 77.200, Test loss: 1.273, Test accuracy: 55.60 

        train local model (freeze embeding):client   1,  Train loss: 0.897, Train accuracy: 64.600, Test loss: 1.155, Test accuracy: 55.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.494, Train accuracy: 79.800, Test loss: 1.097, Test accuracy: 63.60 

        train local model (freeze embeding):client   2,  Train loss: 1.140, Train accuracy: 56.000, Test loss: 1.352, Test accuracy: 48.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.801, Train accuracy: 68.200, Test loss: 1.104, Test accuracy: 54.60 

Round   6, Train loss: 0.968, Test loss: 1.071, Test accuracy: 60.13 

        train local model (freeze embeding):client   0,  Train loss: 0.967, Train accuracy: 59.400, Test loss: 1.260, Test accuracy: 49.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.456, Train accuracy: 84.600, Test loss: 1.326, Test accuracy: 58.40 

        train local model (freeze embeding):client   1,  Train loss: 0.873, Train accuracy: 64.200, Test loss: 1.213, Test accuracy: 54.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.553, Train accuracy: 76.400, Test loss: 1.168, Test accuracy: 56.60 

        train local model (freeze embeding):client   2,  Train loss: 1.154, Train accuracy: 52.400, Test loss: 1.356, Test accuracy: 49.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.823, Train accuracy: 69.400, Test loss: 1.059, Test accuracy: 58.60 

Round   7, Train loss: 0.958, Test loss: 1.096, Test accuracy: 59.60 

        train local model (freeze embeding):client   0,  Train loss: 1.067, Train accuracy: 56.200, Test loss: 1.353, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.582, Train accuracy: 76.800, Test loss: 1.461, Test accuracy: 51.60 

        train local model (freeze embeding):client   1,  Train loss: 1.001, Train accuracy: 56.000, Test loss: 1.262, Test accuracy: 52.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.621, Train accuracy: 75.600, Test loss: 1.311, Test accuracy: 55.60 

        train local model (freeze embeding):client   2,  Train loss: 1.046, Train accuracy: 57.600, Test loss: 1.259, Test accuracy: 46.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.843, Train accuracy: 66.800, Test loss: 1.227, Test accuracy: 53.60 

Round   8, Train loss: 0.943, Test loss: 1.069, Test accuracy: 59.47 

        train local model (freeze embeding):client   0,  Train loss: 0.884, Train accuracy: 62.200, Test loss: 1.204, Test accuracy: 53.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.545, Train accuracy: 78.400, Test loss: 1.346, Test accuracy: 55.80 

        train local model (freeze embeding):client   1,  Train loss: 0.764, Train accuracy: 67.600, Test loss: 1.047, Test accuracy: 58.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.604, Train accuracy: 74.800, Test loss: 1.097, Test accuracy: 61.00 

        train local model (freeze embeding):client   2,  Train loss: 1.008, Train accuracy: 54.600, Test loss: 1.253, Test accuracy: 48.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.892, Train accuracy: 64.800, Test loss: 1.193, Test accuracy: 56.40 

Round   9, Train loss: 0.959, Test loss: 1.052, Test accuracy: 60.40 

        train local model (freeze embeding):client   0,  Train loss: 1.271, Train accuracy: 53.200, Test loss: 1.525, Test accuracy: 49.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.617, Train accuracy: 76.200, Test loss: 1.421, Test accuracy: 54.40 

        train local model (freeze embeding):client   1,  Train loss: 0.850, Train accuracy: 63.800, Test loss: 1.137, Test accuracy: 53.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.531, Train accuracy: 79.400, Test loss: 1.185, Test accuracy: 57.80 

        train local model (freeze embeding):client   2,  Train loss: 1.203, Train accuracy: 52.000, Test loss: 1.379, Test accuracy: 46.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.768, Train accuracy: 69.600, Test loss: 1.125, Test accuracy: 56.20 

Round  10, Train loss: 0.946, Test loss: 1.118, Test accuracy: 58.27 

        train local model (freeze embeding):client   0,  Train loss: 0.979, Train accuracy: 58.400, Test loss: 1.301, Test accuracy: 48.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.525, Train accuracy: 81.600, Test loss: 1.381, Test accuracy: 57.20 

        train local model (freeze embeding):client   1,  Train loss: 0.900, Train accuracy: 62.200, Test loss: 1.188, Test accuracy: 53.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.796, Train accuracy: 66.800, Test loss: 1.392, Test accuracy: 53.00 

        train local model (freeze embeding):client   2,  Train loss: 1.024, Train accuracy: 57.800, Test loss: 1.245, Test accuracy: 49.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.772, Train accuracy: 71.000, Test loss: 1.197, Test accuracy: 54.20 

Round  11, Train loss: 0.926, Test loss: 1.088, Test accuracy: 59.67 

        train local model (freeze embeding):client   0,  Train loss: 0.942, Train accuracy: 59.000, Test loss: 1.315, Test accuracy: 48.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.532, Train accuracy: 79.600, Test loss: 1.244, Test accuracy: 59.00 

        train local model (freeze embeding):client   1,  Train loss: 0.898, Train accuracy: 63.000, Test loss: 1.218, Test accuracy: 51.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.588, Train accuracy: 78.000, Test loss: 1.163, Test accuracy: 57.80 

        train local model (freeze embeding):client   2,  Train loss: 1.121, Train accuracy: 53.400, Test loss: 1.315, Test accuracy: 46.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.780, Train accuracy: 68.400, Test loss: 1.239, Test accuracy: 54.80 

Round  12, Train loss: 0.939, Test loss: 1.169, Test accuracy: 57.40 

        train local model (freeze embeding):client   0,  Train loss: 1.072, Train accuracy: 59.000, Test loss: 1.508, Test accuracy: 46.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.605, Train accuracy: 75.600, Test loss: 1.413, Test accuracy: 56.40 

        train local model (freeze embeding):client   1,  Train loss: 0.834, Train accuracy: 64.800, Test loss: 1.109, Test accuracy: 53.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.448, Train accuracy: 83.200, Test loss: 1.108, Test accuracy: 61.60 

        train local model (freeze embeding):client   2,  Train loss: 1.040, Train accuracy: 58.800, Test loss: 1.288, Test accuracy: 47.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.872, Train accuracy: 65.800, Test loss: 1.263, Test accuracy: 50.60 

Round  13, Train loss: 0.928, Test loss: 1.154, Test accuracy: 58.27 

        train local model (freeze embeding):client   0,  Train loss: 0.864, Train accuracy: 65.200, Test loss: 1.259, Test accuracy: 50.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.700, Train accuracy: 73.000, Test loss: 1.648, Test accuracy: 50.00 

        train local model (freeze embeding):client   1,  Train loss: 0.853, Train accuracy: 65.800, Test loss: 1.132, Test accuracy: 57.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.489, Train accuracy: 80.600, Test loss: 1.097, Test accuracy: 59.40 

        train local model (freeze embeding):client   2,  Train loss: 1.062, Train accuracy: 55.200, Test loss: 1.243, Test accuracy: 46.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.722, Train accuracy: 72.600, Test loss: 1.119, Test accuracy: 55.60 

Round  14, Train loss: 0.898, Test loss: 1.073, Test accuracy: 59.07 

        train local model (freeze embeding):client   0,  Train loss: 0.932, Train accuracy: 61.600, Test loss: 1.232, Test accuracy: 52.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.448, Train accuracy: 84.800, Test loss: 1.248, Test accuracy: 61.20 

        train local model (freeze embeding):client   1,  Train loss: 0.870, Train accuracy: 65.800, Test loss: 1.153, Test accuracy: 54.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.584, Train accuracy: 78.000, Test loss: 1.231, Test accuracy: 59.80 

        train local model (freeze embeding):client   2,  Train loss: 0.956, Train accuracy: 62.200, Test loss: 1.223, Test accuracy: 51.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.707, Train accuracy: 72.000, Test loss: 1.146, Test accuracy: 54.60 

Round  15, Train loss: 0.908, Test loss: 1.097, Test accuracy: 59.07 

        train local model (freeze embeding):client   0,  Train loss: 0.890, Train accuracy: 63.600, Test loss: 1.218, Test accuracy: 51.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.551, Train accuracy: 79.400, Test loss: 1.339, Test accuracy: 54.60 

        train local model (freeze embeding):client   1,  Train loss: 0.886, Train accuracy: 62.400, Test loss: 1.158, Test accuracy: 57.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.422, Train accuracy: 84.400, Test loss: 1.105, Test accuracy: 58.00 

        train local model (freeze embeding):client   2,  Train loss: 1.085, Train accuracy: 53.800, Test loss: 1.358, Test accuracy: 44.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.725, Train accuracy: 71.800, Test loss: 1.117, Test accuracy: 54.20 

Round  16, Train loss: 0.921, Test loss: 1.108, Test accuracy: 58.93 

        train local model (freeze embeding):client   0,  Train loss: 0.915, Train accuracy: 61.800, Test loss: 1.258, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.532, Train accuracy: 79.600, Test loss: 1.233, Test accuracy: 59.00 

        train local model (freeze embeding):client   1,  Train loss: 0.880, Train accuracy: 65.800, Test loss: 1.152, Test accuracy: 56.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.509, Train accuracy: 79.800, Test loss: 1.109, Test accuracy: 60.60 

        train local model (freeze embeding):client   2,  Train loss: 0.986, Train accuracy: 60.400, Test loss: 1.206, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.710, Train accuracy: 73.200, Test loss: 1.262, Test accuracy: 56.00 

Round  17, Train loss: 0.904, Test loss: 1.110, Test accuracy: 59.20 

        train local model (freeze embeding):client   0,  Train loss: 1.018, Train accuracy: 56.400, Test loss: 1.353, Test accuracy: 45.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.573, Train accuracy: 75.400, Test loss: 1.341, Test accuracy: 57.60 

        train local model (freeze embeding):client   1,  Train loss: 0.853, Train accuracy: 66.400, Test loss: 1.132, Test accuracy: 51.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.540, Train accuracy: 79.600, Test loss: 1.095, Test accuracy: 59.00 

        train local model (freeze embeding):client   2,  Train loss: 0.942, Train accuracy: 59.400, Test loss: 1.184, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.610, Train accuracy: 75.600, Test loss: 1.204, Test accuracy: 51.20 

Round  18, Train loss: 0.925, Test loss: 1.117, Test accuracy: 58.53 

        train local model (freeze embeding):client   0,  Train loss: 0.909, Train accuracy: 64.600, Test loss: 1.262, Test accuracy: 50.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.559, Train accuracy: 80.400, Test loss: 1.326, Test accuracy: 56.60 

        train local model (freeze embeding):client   1,  Train loss: 0.812, Train accuracy: 63.600, Test loss: 1.088, Test accuracy: 57.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.541, Train accuracy: 77.400, Test loss: 1.189, Test accuracy: 52.80 

        train local model (freeze embeding):client   2,  Train loss: 0.920, Train accuracy: 62.400, Test loss: 1.221, Test accuracy: 48.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.660, Train accuracy: 74.200, Test loss: 1.163, Test accuracy: 54.40 

Round  19, Train loss: 0.898, Test loss: 1.117, Test accuracy: 58.67 

        train local model (freeze embeding):client   0,  Train loss: 0.891, Train accuracy: 64.400, Test loss: 1.222, Test accuracy: 50.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.535, Train accuracy: 77.600, Test loss: 1.307, Test accuracy: 57.00 

        train local model (freeze embeding):client   1,  Train loss: 0.860, Train accuracy: 64.200, Test loss: 1.155, Test accuracy: 52.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.445, Train accuracy: 84.000, Test loss: 1.050, Test accuracy: 61.40 

        train local model (freeze embeding):client   2,  Train loss: 1.100, Train accuracy: 58.200, Test loss: 1.393, Test accuracy: 46.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.657, Train accuracy: 75.200, Test loss: 1.165, Test accuracy: 55.40 

Final Round, Train loss: 0.888, Test loss: 1.124, Test accuracy: 58.47 

---------------------------------------------train_client: [0, 1, 2, 3] 

        init --> train local model(freeze embeding):client   3,  Train loss: 1.274, Train accuracy: 43.600, Test loss: 1.249, Test accuracy: 48.80 

        train local model (freeze embeding):client   0,  Train loss: 0.890, Train accuracy: 63.400, Test loss: 1.199, Test accuracy: 53.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.517, Train accuracy: 80.200, Test loss: 1.307, Test accuracy: 58.60 

        train local model (freeze embeding):client   1,  Train loss: 0.799, Train accuracy: 68.600, Test loss: 1.103, Test accuracy: 56.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.499, Train accuracy: 82.000, Test loss: 1.167, Test accuracy: 59.20 

        train local model (freeze embeding):client   2,  Train loss: 1.032, Train accuracy: 58.400, Test loss: 1.335, Test accuracy: 51.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.670, Train accuracy: 74.800, Test loss: 1.244, Test accuracy: 54.00 

        train local model (freeze embeding):client   3,  Train loss: 1.127, Train accuracy: 49.600, Test loss: 1.140, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.956, Train accuracy: 61.800, Test loss: 0.998, Test accuracy: 57.80 

Round   0, Train loss: 0.954, Test loss: 1.133, Test accuracy: 57.30 

        train local model (freeze embeding):client   0,  Train loss: 0.909, Train accuracy: 64.600, Test loss: 1.231, Test accuracy: 53.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.478, Train accuracy: 81.000, Test loss: 1.317, Test accuracy: 58.00 

        train local model (freeze embeding):client   1,  Train loss: 0.949, Train accuracy: 61.800, Test loss: 1.271, Test accuracy: 49.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.896, Train accuracy: 66.600, Test loss: 1.396, Test accuracy: 56.20 

        train local model (freeze embeding):client   2,  Train loss: 1.037, Train accuracy: 57.400, Test loss: 1.336, Test accuracy: 47.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.740, Train accuracy: 71.800, Test loss: 1.373, Test accuracy: 51.60 

        train local model (freeze embeding):client   3,  Train loss: 1.441, Train accuracy: 46.000, Test loss: 1.452, Test accuracy: 47.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.930, Train accuracy: 59.400, Test loss: 1.023, Test accuracy: 56.40 

Round   1, Train loss: 0.962, Test loss: 1.120, Test accuracy: 57.10 

        train local model (freeze embeding):client   0,  Train loss: 1.054, Train accuracy: 57.000, Test loss: 1.493, Test accuracy: 44.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.517, Train accuracy: 79.200, Test loss: 1.398, Test accuracy: 57.20 

        train local model (freeze embeding):client   1,  Train loss: 0.828, Train accuracy: 66.400, Test loss: 1.107, Test accuracy: 54.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.508, Train accuracy: 81.800, Test loss: 1.128, Test accuracy: 60.00 

        train local model (freeze embeding):client   2,  Train loss: 0.983, Train accuracy: 61.000, Test loss: 1.252, Test accuracy: 49.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.581, Train accuracy: 79.800, Test loss: 1.126, Test accuracy: 53.60 

        train local model (freeze embeding):client   3,  Train loss: 1.127, Train accuracy: 50.200, Test loss: 1.188, Test accuracy: 49.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.944, Train accuracy: 62.400, Test loss: 1.021, Test accuracy: 55.40 

Round   2, Train loss: 0.950, Test loss: 1.074, Test accuracy: 59.05 

        train local model (freeze embeding):client   0,  Train loss: 0.882, Train accuracy: 66.400, Test loss: 1.207, Test accuracy: 52.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.561, Train accuracy: 78.200, Test loss: 1.331, Test accuracy: 58.20 

        train local model (freeze embeding):client   1,  Train loss: 0.852, Train accuracy: 63.400, Test loss: 1.142, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.496, Train accuracy: 81.000, Test loss: 1.105, Test accuracy: 60.00 

        train local model (freeze embeding):client   2,  Train loss: 0.979, Train accuracy: 57.800, Test loss: 1.305, Test accuracy: 44.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.611, Train accuracy: 76.000, Test loss: 1.109, Test accuracy: 55.40 

        train local model (freeze embeding):client   3,  Train loss: 1.270, Train accuracy: 47.800, Test loss: 1.370, Test accuracy: 45.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.964, Train accuracy: 55.400, Test loss: 1.151, Test accuracy: 53.80 

Round   3, Train loss: 0.956, Test loss: 1.096, Test accuracy: 58.30 

        train local model (freeze embeding):client   0,  Train loss: 0.894, Train accuracy: 60.800, Test loss: 1.197, Test accuracy: 49.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.566, Train accuracy: 77.600, Test loss: 1.291, Test accuracy: 59.60 

        train local model (freeze embeding):client   1,  Train loss: 0.836, Train accuracy: 64.800, Test loss: 1.116, Test accuracy: 53.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.431, Train accuracy: 85.600, Test loss: 1.041, Test accuracy: 60.20 

        train local model (freeze embeding):client   2,  Train loss: 0.973, Train accuracy: 61.400, Test loss: 1.297, Test accuracy: 47.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.607, Train accuracy: 75.400, Test loss: 1.198, Test accuracy: 57.60 

        train local model (freeze embeding):client   3,  Train loss: 1.130, Train accuracy: 52.800, Test loss: 1.170, Test accuracy: 51.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.910, Train accuracy: 61.800, Test loss: 1.069, Test accuracy: 57.00 

Round   4, Train loss: 0.951, Test loss: 1.116, Test accuracy: 57.65 

        train local model (freeze embeding):client   0,  Train loss: 1.008, Train accuracy: 59.600, Test loss: 1.328, Test accuracy: 48.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.516, Train accuracy: 80.600, Test loss: 1.298, Test accuracy: 56.00 

        train local model (freeze embeding):client   1,  Train loss: 0.804, Train accuracy: 69.400, Test loss: 1.090, Test accuracy: 56.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.520, Train accuracy: 80.200, Test loss: 1.142, Test accuracy: 60.40 

        train local model (freeze embeding):client   2,  Train loss: 0.859, Train accuracy: 63.600, Test loss: 1.158, Test accuracy: 50.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.711, Train accuracy: 71.600, Test loss: 1.246, Test accuracy: 54.40 

        train local model (freeze embeding):client   3,  Train loss: 1.223, Train accuracy: 48.200, Test loss: 1.280, Test accuracy: 50.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.940, Train accuracy: 58.800, Test loss: 1.108, Test accuracy: 51.80 

Round   5, Train loss: 0.935, Test loss: 1.082, Test accuracy: 58.30 

        train local model (freeze embeding):client   0,  Train loss: 0.883, Train accuracy: 63.000, Test loss: 1.195, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.463, Train accuracy: 83.400, Test loss: 1.214, Test accuracy: 59.60 

        train local model (freeze embeding):client   1,  Train loss: 0.825, Train accuracy: 64.600, Test loss: 1.110, Test accuracy: 54.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.436, Train accuracy: 85.400, Test loss: 1.053, Test accuracy: 58.00 

        train local model (freeze embeding):client   2,  Train loss: 0.918, Train accuracy: 62.600, Test loss: 1.254, Test accuracy: 48.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.641, Train accuracy: 75.800, Test loss: 1.215, Test accuracy: 57.00 

        train local model (freeze embeding):client   3,  Train loss: 1.061, Train accuracy: 52.600, Test loss: 1.130, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.853, Train accuracy: 66.400, Test loss: 1.084, Test accuracy: 54.60 

Round   6, Train loss: 0.925, Test loss: 1.075, Test accuracy: 58.60 

        train local model (freeze embeding):client   0,  Train loss: 0.888, Train accuracy: 63.400, Test loss: 1.217, Test accuracy: 49.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.540, Train accuracy: 81.000, Test loss: 1.268, Test accuracy: 58.20 

        train local model (freeze embeding):client   1,  Train loss: 0.815, Train accuracy: 66.600, Test loss: 1.109, Test accuracy: 54.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.525, Train accuracy: 81.000, Test loss: 1.207, Test accuracy: 58.00 

        train local model (freeze embeding):client   2,  Train loss: 1.104, Train accuracy: 56.000, Test loss: 1.382, Test accuracy: 49.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.603, Train accuracy: 75.400, Test loss: 1.150, Test accuracy: 55.00 

        train local model (freeze embeding):client   3,  Train loss: 1.005, Train accuracy: 57.600, Test loss: 1.086, Test accuracy: 54.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.864, Train accuracy: 66.600, Test loss: 1.085, Test accuracy: 54.80 

Round   7, Train loss: 0.910, Test loss: 1.083, Test accuracy: 59.00 

        train local model (freeze embeding):client   0,  Train loss: 0.851, Train accuracy: 66.000, Test loss: 1.234, Test accuracy: 52.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.513, Train accuracy: 82.000, Test loss: 1.282, Test accuracy: 59.20 

        train local model (freeze embeding):client   1,  Train loss: 0.831, Train accuracy: 63.000, Test loss: 1.120, Test accuracy: 54.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.514, Train accuracy: 80.000, Test loss: 1.110, Test accuracy: 58.60 

        train local model (freeze embeding):client   2,  Train loss: 0.936, Train accuracy: 54.800, Test loss: 1.240, Test accuracy: 48.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.569, Train accuracy: 77.600, Test loss: 1.179, Test accuracy: 55.80 

        train local model (freeze embeding):client   3,  Train loss: 1.184, Train accuracy: 54.400, Test loss: 1.255, Test accuracy: 51.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.781, Train accuracy: 69.400, Test loss: 1.040, Test accuracy: 55.40 

Round   8, Train loss: 0.929, Test loss: 1.077, Test accuracy: 58.75 

        train local model (freeze embeding):client   0,  Train loss: 0.882, Train accuracy: 64.400, Test loss: 1.247, Test accuracy: 49.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.657, Train accuracy: 76.000, Test loss: 1.520, Test accuracy: 54.20 

        train local model (freeze embeding):client   1,  Train loss: 0.834, Train accuracy: 65.600, Test loss: 1.151, Test accuracy: 53.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.452, Train accuracy: 84.800, Test loss: 1.102, Test accuracy: 57.20 

        train local model (freeze embeding):client   2,  Train loss: 0.875, Train accuracy: 61.800, Test loss: 1.177, Test accuracy: 51.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.523, Train accuracy: 81.600, Test loss: 1.186, Test accuracy: 55.00 

        train local model (freeze embeding):client   3,  Train loss: 1.137, Train accuracy: 52.200, Test loss: 1.198, Test accuracy: 51.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.848, Train accuracy: 64.600, Test loss: 1.046, Test accuracy: 56.20 

Round   9, Train loss: 0.911, Test loss: 1.107, Test accuracy: 58.35 

        train local model (freeze embeding):client   0,  Train loss: 0.902, Train accuracy: 61.800, Test loss: 1.263, Test accuracy: 50.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.564, Train accuracy: 77.800, Test loss: 1.305, Test accuracy: 59.00 

        train local model (freeze embeding):client   1,  Train loss: 0.808, Train accuracy: 68.400, Test loss: 1.111, Test accuracy: 55.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.563, Train accuracy: 78.400, Test loss: 1.185, Test accuracy: 61.00 

        train local model (freeze embeding):client   2,  Train loss: 0.868, Train accuracy: 63.400, Test loss: 1.191, Test accuracy: 48.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.650, Train accuracy: 72.800, Test loss: 1.183, Test accuracy: 54.40 

        train local model (freeze embeding):client   3,  Train loss: 1.062, Train accuracy: 55.200, Test loss: 1.134, Test accuracy: 52.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.816, Train accuracy: 64.800, Test loss: 1.054, Test accuracy: 56.20 

Round  10, Train loss: 0.909, Test loss: 1.097, Test accuracy: 59.45 

        train local model (freeze embeding):client   0,  Train loss: 0.828, Train accuracy: 66.200, Test loss: 1.199, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.553, Train accuracy: 76.000, Test loss: 1.438, Test accuracy: 55.80 

        train local model (freeze embeding):client   1,  Train loss: 0.811, Train accuracy: 68.800, Test loss: 1.098, Test accuracy: 57.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.403, Train accuracy: 86.600, Test loss: 1.050, Test accuracy: 59.00 

        train local model (freeze embeding):client   2,  Train loss: 1.353, Train accuracy: 53.400, Test loss: 1.754, Test accuracy: 39.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.519, Train accuracy: 81.200, Test loss: 1.182, Test accuracy: 55.60 

        train local model (freeze embeding):client   3,  Train loss: 1.023, Train accuracy: 57.600, Test loss: 1.118, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.843, Train accuracy: 65.200, Test loss: 1.128, Test accuracy: 54.00 

Round  11, Train loss: 0.911, Test loss: 1.090, Test accuracy: 58.45 

        train local model (freeze embeding):client   0,  Train loss: 0.927, Train accuracy: 63.400, Test loss: 1.225, Test accuracy: 52.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.501, Train accuracy: 80.200, Test loss: 1.253, Test accuracy: 57.80 

        train local model (freeze embeding):client   1,  Train loss: 0.806, Train accuracy: 66.200, Test loss: 1.113, Test accuracy: 54.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.436, Train accuracy: 84.400, Test loss: 1.108, Test accuracy: 58.40 

        train local model (freeze embeding):client   2,  Train loss: 0.865, Train accuracy: 63.600, Test loss: 1.200, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.550, Train accuracy: 79.800, Test loss: 1.179, Test accuracy: 54.80 

        train local model (freeze embeding):client   3,  Train loss: 1.022, Train accuracy: 58.400, Test loss: 1.124, Test accuracy: 53.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.794, Train accuracy: 67.200, Test loss: 1.070, Test accuracy: 57.80 

Round  12, Train loss: 0.898, Test loss: 1.127, Test accuracy: 57.85 

        train local model (freeze embeding):client   0,  Train loss: 0.868, Train accuracy: 64.000, Test loss: 1.219, Test accuracy: 51.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.550, Train accuracy: 77.800, Test loss: 1.342, Test accuracy: 56.20 

        train local model (freeze embeding):client   1,  Train loss: 0.844, Train accuracy: 65.800, Test loss: 1.183, Test accuracy: 56.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.527, Train accuracy: 80.200, Test loss: 1.122, Test accuracy: 58.60 

        train local model (freeze embeding):client   2,  Train loss: 0.831, Train accuracy: 67.400, Test loss: 1.185, Test accuracy: 52.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.588, Train accuracy: 76.000, Test loss: 1.287, Test accuracy: 57.00 

        train local model (freeze embeding):client   3,  Train loss: 1.115, Train accuracy: 51.400, Test loss: 1.232, Test accuracy: 48.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.742, Train accuracy: 72.600, Test loss: 1.104, Test accuracy: 55.80 

Round  13, Train loss: 0.876, Test loss: 1.145, Test accuracy: 58.95 

        train local model (freeze embeding):client   0,  Train loss: 0.890, Train accuracy: 66.200, Test loss: 1.247, Test accuracy: 49.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.550, Train accuracy: 78.200, Test loss: 1.303, Test accuracy: 57.20 

        train local model (freeze embeding):client   1,  Train loss: 0.811, Train accuracy: 65.600, Test loss: 1.138, Test accuracy: 54.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.523, Train accuracy: 78.800, Test loss: 1.176, Test accuracy: 58.20 

        train local model (freeze embeding):client   2,  Train loss: 0.910, Train accuracy: 63.400, Test loss: 1.238, Test accuracy: 51.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.590, Train accuracy: 77.000, Test loss: 1.171, Test accuracy: 54.80 

        train local model (freeze embeding):client   3,  Train loss: 1.018, Train accuracy: 54.400, Test loss: 1.126, Test accuracy: 53.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.860, Train accuracy: 66.000, Test loss: 1.088, Test accuracy: 56.40 

Round  14, Train loss: 0.891, Test loss: 1.084, Test accuracy: 58.90 

        train local model (freeze embeding):client   0,  Train loss: 0.834, Train accuracy: 67.000, Test loss: 1.162, Test accuracy: 52.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.617, Train accuracy: 76.800, Test loss: 1.337, Test accuracy: 55.60 

        train local model (freeze embeding):client   1,  Train loss: 0.833, Train accuracy: 66.600, Test loss: 1.154, Test accuracy: 54.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.452, Train accuracy: 82.400, Test loss: 1.060, Test accuracy: 61.00 

        train local model (freeze embeding):client   2,  Train loss: 0.941, Train accuracy: 61.000, Test loss: 1.283, Test accuracy: 47.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.556, Train accuracy: 78.800, Test loss: 1.211, Test accuracy: 56.00 

        train local model (freeze embeding):client   3,  Train loss: 0.978, Train accuracy: 57.000, Test loss: 1.121, Test accuracy: 51.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.779, Train accuracy: 67.800, Test loss: 1.057, Test accuracy: 56.00 

Round  15, Train loss: 0.887, Test loss: 1.093, Test accuracy: 59.30 

        train local model (freeze embeding):client   0,  Train loss: 0.888, Train accuracy: 63.800, Test loss: 1.216, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.491, Train accuracy: 81.600, Test loss: 1.237, Test accuracy: 57.20 

        train local model (freeze embeding):client   1,  Train loss: 0.783, Train accuracy: 68.200, Test loss: 1.109, Test accuracy: 57.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.453, Train accuracy: 83.400, Test loss: 1.090, Test accuracy: 59.80 

        train local model (freeze embeding):client   2,  Train loss: 0.912, Train accuracy: 61.400, Test loss: 1.229, Test accuracy: 49.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.570, Train accuracy: 76.600, Test loss: 1.227, Test accuracy: 53.60 

        train local model (freeze embeding):client   3,  Train loss: 1.077, Train accuracy: 56.200, Test loss: 1.184, Test accuracy: 50.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.854, Train accuracy: 66.600, Test loss: 1.190, Test accuracy: 52.80 

Round  16, Train loss: 0.879, Test loss: 1.107, Test accuracy: 58.85 

        train local model (freeze embeding):client   0,  Train loss: 0.859, Train accuracy: 65.200, Test loss: 1.190, Test accuracy: 53.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.487, Train accuracy: 83.800, Test loss: 1.280, Test accuracy: 59.00 

        train local model (freeze embeding):client   1,  Train loss: 0.757, Train accuracy: 70.400, Test loss: 1.077, Test accuracy: 56.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.424, Train accuracy: 85.600, Test loss: 1.053, Test accuracy: 58.80 

        train local model (freeze embeding):client   2,  Train loss: 0.897, Train accuracy: 62.400, Test loss: 1.258, Test accuracy: 48.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.589, Train accuracy: 75.200, Test loss: 1.191, Test accuracy: 57.40 

        train local model (freeze embeding):client   3,  Train loss: 0.949, Train accuracy: 60.400, Test loss: 1.080, Test accuracy: 53.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.837, Train accuracy: 68.800, Test loss: 1.088, Test accuracy: 54.60 

Round  17, Train loss: 0.889, Test loss: 1.082, Test accuracy: 59.65 

        train local model (freeze embeding):client   0,  Train loss: 0.878, Train accuracy: 63.000, Test loss: 1.205, Test accuracy: 51.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.477, Train accuracy: 83.200, Test loss: 1.253, Test accuracy: 57.60 

        train local model (freeze embeding):client   1,  Train loss: 0.797, Train accuracy: 64.800, Test loss: 1.109, Test accuracy: 55.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.453, Train accuracy: 82.400, Test loss: 1.164, Test accuracy: 57.40 

        train local model (freeze embeding):client   2,  Train loss: 0.855, Train accuracy: 66.600, Test loss: 1.195, Test accuracy: 51.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.599, Train accuracy: 78.600, Test loss: 1.226, Test accuracy: 56.40 

        train local model (freeze embeding):client   3,  Train loss: 0.985, Train accuracy: 60.200, Test loss: 1.120, Test accuracy: 53.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.722, Train accuracy: 71.600, Test loss: 1.072, Test accuracy: 55.00 

Round  18, Train loss: 0.871, Test loss: 1.090, Test accuracy: 59.75 

        train local model (freeze embeding):client   0,  Train loss: 0.854, Train accuracy: 66.800, Test loss: 1.247, Test accuracy: 56.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.519, Train accuracy: 81.400, Test loss: 1.369, Test accuracy: 55.80 

        train local model (freeze embeding):client   1,  Train loss: 0.769, Train accuracy: 69.400, Test loss: 1.109, Test accuracy: 53.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.528, Train accuracy: 78.200, Test loss: 1.214, Test accuracy: 59.80 

        train local model (freeze embeding):client   2,  Train loss: 0.919, Train accuracy: 61.600, Test loss: 1.225, Test accuracy: 53.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.573, Train accuracy: 77.000, Test loss: 1.240, Test accuracy: 56.20 

        train local model (freeze embeding):client   3,  Train loss: 0.982, Train accuracy: 57.800, Test loss: 1.103, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.712, Train accuracy: 72.400, Test loss: 1.087, Test accuracy: 57.20 

Round  19, Train loss: 0.873, Test loss: 1.107, Test accuracy: 58.65 

        train local model (freeze embeding):client   0,  Train loss: 0.864, Train accuracy: 67.000, Test loss: 1.230, Test accuracy: 53.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.661, Train accuracy: 74.800, Test loss: 1.457, Test accuracy: 51.60 

        train local model (freeze embeding):client   1,  Train loss: 0.796, Train accuracy: 66.000, Test loss: 1.144, Test accuracy: 53.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.489, Train accuracy: 81.400, Test loss: 1.206, Test accuracy: 58.40 

        train local model (freeze embeding):client   2,  Train loss: 0.964, Train accuracy: 58.600, Test loss: 1.306, Test accuracy: 47.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.458, Train accuracy: 84.600, Test loss: 1.150, Test accuracy: 59.60 

        train local model (freeze embeding):client   3,  Train loss: 1.027, Train accuracy: 57.400, Test loss: 1.158, Test accuracy: 51.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.717, Train accuracy: 71.800, Test loss: 1.083, Test accuracy: 56.80 

Final Round, Train loss: 0.880, Test loss: 1.131, Test accuracy: 57.65 

---------------------------------------------train_client: [0, 1, 2, 3, 4] 

        init --> train local model(freeze embeding):client   4,  Train loss: 0.987, Train accuracy: 61.600, Test loss: 1.047, Test accuracy: 55.40 

        train local model (freeze embeding):client   0,  Train loss: 0.883, Train accuracy: 63.200, Test loss: 1.222, Test accuracy: 49.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.502, Train accuracy: 81.400, Test loss: 1.255, Test accuracy: 59.60 

        train local model (freeze embeding):client   1,  Train loss: 0.913, Train accuracy: 62.200, Test loss: 1.204, Test accuracy: 52.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.533, Train accuracy: 77.600, Test loss: 1.170, Test accuracy: 57.40 

        train local model (freeze embeding):client   2,  Train loss: 0.947, Train accuracy: 61.600, Test loss: 1.260, Test accuracy: 49.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.521, Train accuracy: 81.200, Test loss: 1.191, Test accuracy: 57.20 

        train local model (freeze embeding):client   3,  Train loss: 0.962, Train accuracy: 59.600, Test loss: 1.114, Test accuracy: 57.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.782, Train accuracy: 70.800, Test loss: 1.141, Test accuracy: 55.80 

        train local model (freeze embeding):client   4,  Train loss: 1.063, Train accuracy: 57.400, Test loss: 1.166, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.869, Train accuracy: 65.200, Test loss: 1.020, Test accuracy: 60.40 

Round   0, Train loss: 0.906, Test loss: 1.036, Test accuracy: 60.00 

        train local model (freeze embeding):client   0,  Train loss: 0.798, Train accuracy: 69.000, Test loss: 1.192, Test accuracy: 51.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.569, Train accuracy: 76.000, Test loss: 1.413, Test accuracy: 54.60 

        train local model (freeze embeding):client   1,  Train loss: 0.727, Train accuracy: 70.200, Test loss: 1.085, Test accuracy: 55.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.463, Train accuracy: 82.000, Test loss: 1.129, Test accuracy: 57.60 

        train local model (freeze embeding):client   2,  Train loss: 0.882, Train accuracy: 63.400, Test loss: 1.219, Test accuracy: 53.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.480, Train accuracy: 84.400, Test loss: 1.159, Test accuracy: 56.80 

        train local model (freeze embeding):client   3,  Train loss: 0.959, Train accuracy: 59.000, Test loss: 1.115, Test accuracy: 53.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.739, Train accuracy: 71.400, Test loss: 1.148, Test accuracy: 54.20 

        train local model (freeze embeding):client   4,  Train loss: 0.991, Train accuracy: 64.600, Test loss: 1.040, Test accuracy: 58.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.779, Train accuracy: 69.000, Test loss: 0.944, Test accuracy: 61.60 

Round   1, Train loss: 0.903, Test loss: 1.069, Test accuracy: 58.28 

        train local model (freeze embeding):client   0,  Train loss: 0.818, Train accuracy: 67.600, Test loss: 1.200, Test accuracy: 51.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.569, Train accuracy: 78.400, Test loss: 1.269, Test accuracy: 58.40 

        train local model (freeze embeding):client   1,  Train loss: 0.771, Train accuracy: 66.800, Test loss: 1.082, Test accuracy: 56.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.451, Train accuracy: 85.800, Test loss: 1.060, Test accuracy: 61.40 

        train local model (freeze embeding):client   2,  Train loss: 0.864, Train accuracy: 65.400, Test loss: 1.237, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.443, Train accuracy: 85.800, Test loss: 1.177, Test accuracy: 59.00 

        train local model (freeze embeding):client   3,  Train loss: 1.078, Train accuracy: 55.600, Test loss: 1.212, Test accuracy: 49.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.713, Train accuracy: 75.000, Test loss: 1.168, Test accuracy: 55.80 

        train local model (freeze embeding):client   4,  Train loss: 0.943, Train accuracy: 63.600, Test loss: 1.080, Test accuracy: 55.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.769, Train accuracy: 69.600, Test loss: 1.046, Test accuracy: 58.20 

Round   2, Train loss: 0.886, Test loss: 1.091, Test accuracy: 58.68 

        train local model (freeze embeding):client   0,  Train loss: 0.964, Train accuracy: 63.200, Test loss: 1.379, Test accuracy: 50.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.493, Train accuracy: 82.400, Test loss: 1.283, Test accuracy: 56.20 

        train local model (freeze embeding):client   1,  Train loss: 0.765, Train accuracy: 70.000, Test loss: 1.077, Test accuracy: 54.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.496, Train accuracy: 81.200, Test loss: 1.124, Test accuracy: 58.60 

        train local model (freeze embeding):client   2,  Train loss: 0.843, Train accuracy: 64.000, Test loss: 1.195, Test accuracy: 51.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.513, Train accuracy: 82.000, Test loss: 1.213, Test accuracy: 59.40 

        train local model (freeze embeding):client   3,  Train loss: 0.919, Train accuracy: 62.000, Test loss: 1.082, Test accuracy: 54.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.700, Train accuracy: 73.600, Test loss: 1.085, Test accuracy: 55.60 

        train local model (freeze embeding):client   4,  Train loss: 1.237, Train accuracy: 53.400, Test loss: 1.290, Test accuracy: 48.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.735, Train accuracy: 70.400, Test loss: 1.000, Test accuracy: 61.60 

Round   3, Train loss: 0.886, Test loss: 1.080, Test accuracy: 58.60 

        train local model (freeze embeding):client   0,  Train loss: 0.837, Train accuracy: 69.200, Test loss: 1.195, Test accuracy: 53.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.546, Train accuracy: 78.000, Test loss: 1.391, Test accuracy: 54.80 

        train local model (freeze embeding):client   1,  Train loss: 0.729, Train accuracy: 71.400, Test loss: 1.078, Test accuracy: 56.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.531, Train accuracy: 78.400, Test loss: 1.155, Test accuracy: 57.00 

        train local model (freeze embeding):client   2,  Train loss: 0.983, Train accuracy: 59.800, Test loss: 1.377, Test accuracy: 44.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.528, Train accuracy: 79.800, Test loss: 1.230, Test accuracy: 54.80 

        train local model (freeze embeding):client   3,  Train loss: 1.074, Train accuracy: 54.600, Test loss: 1.271, Test accuracy: 48.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.790, Train accuracy: 67.400, Test loss: 1.285, Test accuracy: 52.80 

        train local model (freeze embeding):client   4,  Train loss: 0.904, Train accuracy: 63.600, Test loss: 1.104, Test accuracy: 56.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.755, Train accuracy: 68.600, Test loss: 0.998, Test accuracy: 57.00 

Round   4, Train loss: 0.879, Test loss: 1.060, Test accuracy: 59.44 

        train local model (freeze embeding):client   0,  Train loss: 0.844, Train accuracy: 63.600, Test loss: 1.209, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.826, Train accuracy: 68.000, Test loss: 1.595, Test accuracy: 46.00 

        train local model (freeze embeding):client   1,  Train loss: 0.877, Train accuracy: 61.400, Test loss: 1.217, Test accuracy: 54.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.470, Train accuracy: 82.800, Test loss: 1.033, Test accuracy: 60.00 

        train local model (freeze embeding):client   2,  Train loss: 0.836, Train accuracy: 66.800, Test loss: 1.201, Test accuracy: 48.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.554, Train accuracy: 81.000, Test loss: 1.172, Test accuracy: 57.00 

        train local model (freeze embeding):client   3,  Train loss: 0.980, Train accuracy: 55.200, Test loss: 1.148, Test accuracy: 52.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.822, Train accuracy: 65.000, Test loss: 1.179, Test accuracy: 55.00 

        train local model (freeze embeding):client   4,  Train loss: 0.953, Train accuracy: 61.200, Test loss: 1.104, Test accuracy: 55.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.758, Train accuracy: 69.600, Test loss: 1.093, Test accuracy: 58.60 

Round   5, Train loss: 0.878, Test loss: 1.072, Test accuracy: 58.88 

        train local model (freeze embeding):client   0,  Train loss: 0.857, Train accuracy: 64.800, Test loss: 1.174, Test accuracy: 54.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.614, Train accuracy: 74.800, Test loss: 1.381, Test accuracy: 54.60 

        train local model (freeze embeding):client   1,  Train loss: 0.758, Train accuracy: 69.200, Test loss: 1.078, Test accuracy: 55.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.558, Train accuracy: 80.600, Test loss: 1.192, Test accuracy: 57.60 

        train local model (freeze embeding):client   2,  Train loss: 0.841, Train accuracy: 67.600, Test loss: 1.210, Test accuracy: 48.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.505, Train accuracy: 79.600, Test loss: 1.247, Test accuracy: 58.00 

        train local model (freeze embeding):client   3,  Train loss: 1.001, Train accuracy: 59.400, Test loss: 1.139, Test accuracy: 53.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.685, Train accuracy: 72.000, Test loss: 1.043, Test accuracy: 56.60 

        train local model (freeze embeding):client   4,  Train loss: 0.929, Train accuracy: 64.200, Test loss: 1.112, Test accuracy: 55.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.727, Train accuracy: 69.000, Test loss: 1.040, Test accuracy: 57.60 

Round   6, Train loss: 0.872, Test loss: 1.088, Test accuracy: 58.32 

        train local model (freeze embeding):client   0,  Train loss: 0.845, Train accuracy: 67.000, Test loss: 1.212, Test accuracy: 50.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.557, Train accuracy: 79.000, Test loss: 1.314, Test accuracy: 56.60 

        train local model (freeze embeding):client   1,  Train loss: 0.764, Train accuracy: 68.600, Test loss: 1.098, Test accuracy: 57.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.465, Train accuracy: 85.000, Test loss: 1.075, Test accuracy: 60.80 

        train local model (freeze embeding):client   2,  Train loss: 0.902, Train accuracy: 64.400, Test loss: 1.238, Test accuracy: 49.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.618, Train accuracy: 77.000, Test loss: 1.246, Test accuracy: 57.40 

        train local model (freeze embeding):client   3,  Train loss: 1.078, Train accuracy: 57.400, Test loss: 1.175, Test accuracy: 52.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.695, Train accuracy: 73.800, Test loss: 1.109, Test accuracy: 55.20 

        train local model (freeze embeding):client   4,  Train loss: 0.866, Train accuracy: 67.200, Test loss: 1.046, Test accuracy: 57.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.854, Train accuracy: 65.800, Test loss: 1.199, Test accuracy: 58.40 

Round   7, Train loss: 0.874, Test loss: 1.117, Test accuracy: 58.40 

        train local model (freeze embeding):client   0,  Train loss: 1.021, Train accuracy: 56.800, Test loss: 1.374, Test accuracy: 45.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.718, Train accuracy: 71.800, Test loss: 1.403, Test accuracy: 55.80 

        train local model (freeze embeding):client   1,  Train loss: 0.723, Train accuracy: 70.400, Test loss: 1.065, Test accuracy: 57.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.468, Train accuracy: 84.000, Test loss: 1.137, Test accuracy: 59.00 

        train local model (freeze embeding):client   2,  Train loss: 0.786, Train accuracy: 70.400, Test loss: 1.196, Test accuracy: 51.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.510, Train accuracy: 82.600, Test loss: 1.235, Test accuracy: 55.60 

        train local model (freeze embeding):client   3,  Train loss: 0.982, Train accuracy: 58.600, Test loss: 1.144, Test accuracy: 51.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.813, Train accuracy: 67.600, Test loss: 1.194, Test accuracy: 56.60 

        train local model (freeze embeding):client   4,  Train loss: 0.869, Train accuracy: 66.600, Test loss: 1.030, Test accuracy: 58.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.665, Train accuracy: 75.400, Test loss: 1.014, Test accuracy: 62.60 

Round   8, Train loss: 0.871, Test loss: 1.475, Test accuracy: 51.00 

        train local model (freeze embeding):client   0,  Train loss: 0.837, Train accuracy: 64.200, Test loss: 1.203, Test accuracy: 53.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.586, Train accuracy: 76.800, Test loss: 1.269, Test accuracy: 57.40 

        train local model (freeze embeding):client   1,  Train loss: 0.775, Train accuracy: 67.800, Test loss: 1.114, Test accuracy: 55.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.644, Train accuracy: 70.800, Test loss: 1.341, Test accuracy: 53.40 

        train local model (freeze embeding):client   2,  Train loss: 0.826, Train accuracy: 68.600, Test loss: 1.181, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.538, Train accuracy: 81.000, Test loss: 1.199, Test accuracy: 57.20 

        train local model (freeze embeding):client   3,  Train loss: 0.944, Train accuracy: 61.600, Test loss: 1.098, Test accuracy: 51.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.854, Train accuracy: 65.600, Test loss: 1.258, Test accuracy: 53.20 

        train local model (freeze embeding):client   4,  Train loss: 0.953, Train accuracy: 62.800, Test loss: 1.082, Test accuracy: 56.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.621, Train accuracy: 75.200, Test loss: 1.032, Test accuracy: 62.00 

Round   9, Train loss: 0.874, Test loss: 1.064, Test accuracy: 60.68 

        train local model (freeze embeding):client   0,  Train loss: 0.890, Train accuracy: 60.600, Test loss: 1.288, Test accuracy: 47.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.552, Train accuracy: 78.400, Test loss: 1.297, Test accuracy: 58.60 

        train local model (freeze embeding):client   1,  Train loss: 0.769, Train accuracy: 65.800, Test loss: 1.111, Test accuracy: 54.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.458, Train accuracy: 81.800, Test loss: 1.095, Test accuracy: 58.80 

        train local model (freeze embeding):client   2,  Train loss: 0.808, Train accuracy: 67.200, Test loss: 1.173, Test accuracy: 52.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.573, Train accuracy: 77.800, Test loss: 1.249, Test accuracy: 52.80 

        train local model (freeze embeding):client   3,  Train loss: 1.072, Train accuracy: 52.200, Test loss: 1.206, Test accuracy: 49.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.675, Train accuracy: 74.000, Test loss: 1.170, Test accuracy: 54.60 

        train local model (freeze embeding):client   4,  Train loss: 0.903, Train accuracy: 62.600, Test loss: 1.087, Test accuracy: 54.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.702, Train accuracy: 73.800, Test loss: 1.017, Test accuracy: 59.60 

Round  10, Train loss: 0.866, Test loss: 1.068, Test accuracy: 59.84 

        train local model (freeze embeding):client   0,  Train loss: 0.799, Train accuracy: 66.800, Test loss: 1.170, Test accuracy: 51.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.510, Train accuracy: 79.200, Test loss: 1.397, Test accuracy: 55.40 

        train local model (freeze embeding):client   1,  Train loss: 1.067, Train accuracy: 62.600, Test loss: 1.379, Test accuracy: 48.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.510, Train accuracy: 82.200, Test loss: 1.220, Test accuracy: 57.20 

        train local model (freeze embeding):client   2,  Train loss: 0.850, Train accuracy: 65.800, Test loss: 1.215, Test accuracy: 50.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.441, Train accuracy: 84.000, Test loss: 1.182, Test accuracy: 59.00 

        train local model (freeze embeding):client   3,  Train loss: 0.995, Train accuracy: 58.200, Test loss: 1.178, Test accuracy: 50.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.761, Train accuracy: 68.800, Test loss: 1.197, Test accuracy: 53.00 

        train local model (freeze embeding):client   4,  Train loss: 1.033, Train accuracy: 58.400, Test loss: 1.234, Test accuracy: 51.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.684, Train accuracy: 71.200, Test loss: 1.094, Test accuracy: 58.40 

Round  11, Train loss: 0.848, Test loss: 1.097, Test accuracy: 58.72 

        train local model (freeze embeding):client   0,  Train loss: 0.781, Train accuracy: 71.800, Test loss: 1.184, Test accuracy: 51.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.510, Train accuracy: 81.400, Test loss: 1.220, Test accuracy: 59.80 

        train local model (freeze embeding):client   1,  Train loss: 0.750, Train accuracy: 70.200, Test loss: 1.081, Test accuracy: 57.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.461, Train accuracy: 82.600, Test loss: 1.086, Test accuracy: 58.00 

        train local model (freeze embeding):client   2,  Train loss: 0.779, Train accuracy: 70.200, Test loss: 1.176, Test accuracy: 52.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.508, Train accuracy: 81.800, Test loss: 1.180, Test accuracy: 57.80 

        train local model (freeze embeding):client   3,  Train loss: 0.993, Train accuracy: 58.000, Test loss: 1.157, Test accuracy: 53.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.741, Train accuracy: 67.800, Test loss: 1.169, Test accuracy: 56.00 

        train local model (freeze embeding):client   4,  Train loss: 0.896, Train accuracy: 64.000, Test loss: 1.059, Test accuracy: 56.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.719, Train accuracy: 72.400, Test loss: 1.025, Test accuracy: 61.20 

Round  12, Train loss: 0.865, Test loss: 1.062, Test accuracy: 59.64 

        train local model (freeze embeding):client   0,  Train loss: 0.920, Train accuracy: 63.600, Test loss: 1.326, Test accuracy: 48.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.558, Train accuracy: 79.200, Test loss: 1.338, Test accuracy: 55.20 

        train local model (freeze embeding):client   1,  Train loss: 0.742, Train accuracy: 70.000, Test loss: 1.072, Test accuracy: 55.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.497, Train accuracy: 80.800, Test loss: 1.154, Test accuracy: 57.20 

        train local model (freeze embeding):client   2,  Train loss: 0.793, Train accuracy: 69.000, Test loss: 1.174, Test accuracy: 50.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.507, Train accuracy: 81.800, Test loss: 1.197, Test accuracy: 57.60 

        train local model (freeze embeding):client   3,  Train loss: 1.003, Train accuracy: 58.400, Test loss: 1.176, Test accuracy: 51.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.792, Train accuracy: 67.000, Test loss: 1.189, Test accuracy: 54.40 

        train local model (freeze embeding):client   4,  Train loss: 0.829, Train accuracy: 70.000, Test loss: 1.025, Test accuracy: 60.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.718, Train accuracy: 72.600, Test loss: 1.178, Test accuracy: 59.80 

Round  13, Train loss: 0.850, Test loss: 1.139, Test accuracy: 58.28 

        train local model (freeze embeding):client   0,  Train loss: 0.873, Train accuracy: 65.200, Test loss: 1.207, Test accuracy: 53.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.509, Train accuracy: 81.600, Test loss: 1.169, Test accuracy: 58.20 

        train local model (freeze embeding):client   1,  Train loss: 0.741, Train accuracy: 72.200, Test loss: 1.088, Test accuracy: 56.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.474, Train accuracy: 81.400, Test loss: 1.125, Test accuracy: 59.00 

        train local model (freeze embeding):client   2,  Train loss: 0.792, Train accuracy: 69.600, Test loss: 1.168, Test accuracy: 52.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.873, Train accuracy: 64.800, Test loss: 1.683, Test accuracy: 49.60 

        train local model (freeze embeding):client   3,  Train loss: 0.968, Train accuracy: 59.400, Test loss: 1.169, Test accuracy: 53.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.631, Train accuracy: 74.200, Test loss: 1.102, Test accuracy: 57.40 

        train local model (freeze embeding):client   4,  Train loss: 0.891, Train accuracy: 65.600, Test loss: 1.126, Test accuracy: 56.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.652, Train accuracy: 75.000, Test loss: 1.120, Test accuracy: 60.00 

Round  14, Train loss: 0.855, Test loss: 1.238, Test accuracy: 55.04 

        train local model (freeze embeding):client   0,  Train loss: 0.885, Train accuracy: 62.200, Test loss: 1.258, Test accuracy: 49.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.571, Train accuracy: 77.000, Test loss: 1.358, Test accuracy: 55.60 

        train local model (freeze embeding):client   1,  Train loss: 0.743, Train accuracy: 68.600, Test loss: 1.075, Test accuracy: 57.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.543, Train accuracy: 80.600, Test loss: 1.127, Test accuracy: 58.00 

        train local model (freeze embeding):client   2,  Train loss: 0.827, Train accuracy: 67.200, Test loss: 1.201, Test accuracy: 49.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.499, Train accuracy: 79.800, Test loss: 1.237, Test accuracy: 57.20 

        train local model (freeze embeding):client   3,  Train loss: 0.991, Train accuracy: 59.400, Test loss: 1.164, Test accuracy: 53.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.646, Train accuracy: 77.600, Test loss: 1.090, Test accuracy: 56.60 

        train local model (freeze embeding):client   4,  Train loss: 0.815, Train accuracy: 70.200, Test loss: 1.020, Test accuracy: 60.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.651, Train accuracy: 74.600, Test loss: 1.081, Test accuracy: 59.20 

Round  15, Train loss: 0.836, Test loss: 1.113, Test accuracy: 58.52 

        train local model (freeze embeding):client   0,  Train loss: 0.816, Train accuracy: 67.400, Test loss: 1.171, Test accuracy: 55.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.535, Train accuracy: 80.600, Test loss: 1.210, Test accuracy: 57.60 

        train local model (freeze embeding):client   1,  Train loss: 0.748, Train accuracy: 69.000, Test loss: 1.079, Test accuracy: 56.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.533, Train accuracy: 80.000, Test loss: 1.173, Test accuracy: 57.00 

        train local model (freeze embeding):client   2,  Train loss: 0.759, Train accuracy: 70.600, Test loss: 1.174, Test accuracy: 51.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.578, Train accuracy: 77.200, Test loss: 1.307, Test accuracy: 56.60 

        train local model (freeze embeding):client   3,  Train loss: 0.934, Train accuracy: 59.600, Test loss: 1.133, Test accuracy: 50.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.631, Train accuracy: 75.600, Test loss: 1.117, Test accuracy: 56.60 

        train local model (freeze embeding):client   4,  Train loss: 0.822, Train accuracy: 69.400, Test loss: 1.041, Test accuracy: 59.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.638, Train accuracy: 75.800, Test loss: 0.992, Test accuracy: 65.00 

Round  16, Train loss: 0.843, Test loss: 1.080, Test accuracy: 58.68 

        train local model (freeze embeding):client   0,  Train loss: 0.787, Train accuracy: 67.000, Test loss: 1.173, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.576, Train accuracy: 78.400, Test loss: 1.276, Test accuracy: 56.40 

        train local model (freeze embeding):client   1,  Train loss: 0.755, Train accuracy: 68.000, Test loss: 1.067, Test accuracy: 55.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.397, Train accuracy: 85.800, Test loss: 1.045, Test accuracy: 60.40 

        train local model (freeze embeding):client   2,  Train loss: 0.782, Train accuracy: 68.800, Test loss: 1.192, Test accuracy: 51.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.440, Train accuracy: 84.000, Test loss: 1.234, Test accuracy: 57.80 

        train local model (freeze embeding):client   3,  Train loss: 0.904, Train accuracy: 62.200, Test loss: 1.096, Test accuracy: 53.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.726, Train accuracy: 69.800, Test loss: 1.225, Test accuracy: 54.40 

        train local model (freeze embeding):client   4,  Train loss: 0.806, Train accuracy: 69.000, Test loss: 1.048, Test accuracy: 57.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.636, Train accuracy: 78.200, Test loss: 1.033, Test accuracy: 62.00 

Round  17, Train loss: 0.827, Test loss: 1.093, Test accuracy: 58.96 

        train local model (freeze embeding):client   0,  Train loss: 0.863, Train accuracy: 64.800, Test loss: 1.293, Test accuracy: 49.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.531, Train accuracy: 82.400, Test loss: 1.300, Test accuracy: 55.40 

        train local model (freeze embeding):client   1,  Train loss: 0.795, Train accuracy: 67.800, Test loss: 1.111, Test accuracy: 55.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.586, Train accuracy: 78.200, Test loss: 1.163, Test accuracy: 59.40 

        train local model (freeze embeding):client   2,  Train loss: 0.752, Train accuracy: 69.200, Test loss: 1.149, Test accuracy: 51.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.511, Train accuracy: 81.400, Test loss: 1.226, Test accuracy: 56.20 

        train local model (freeze embeding):client   3,  Train loss: 0.873, Train accuracy: 65.800, Test loss: 1.106, Test accuracy: 53.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.710, Train accuracy: 72.200, Test loss: 1.177, Test accuracy: 55.80 

        train local model (freeze embeding):client   4,  Train loss: 0.851, Train accuracy: 68.400, Test loss: 1.091, Test accuracy: 55.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.656, Train accuracy: 75.600, Test loss: 1.121, Test accuracy: 60.80 

Round  18, Train loss: 0.834, Test loss: 1.076, Test accuracy: 59.60 

        train local model (freeze embeding):client   0,  Train loss: 0.870, Train accuracy: 63.800, Test loss: 1.223, Test accuracy: 50.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.597, Train accuracy: 76.400, Test loss: 1.292, Test accuracy: 59.20 

        train local model (freeze embeding):client   1,  Train loss: 0.739, Train accuracy: 70.600, Test loss: 1.092, Test accuracy: 54.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.440, Train accuracy: 83.400, Test loss: 1.087, Test accuracy: 61.60 

        train local model (freeze embeding):client   2,  Train loss: 0.834, Train accuracy: 63.600, Test loss: 1.185, Test accuracy: 51.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.460, Train accuracy: 83.800, Test loss: 1.262, Test accuracy: 56.80 

        train local model (freeze embeding):client   3,  Train loss: 0.946, Train accuracy: 63.200, Test loss: 1.179, Test accuracy: 51.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.693, Train accuracy: 73.600, Test loss: 1.199, Test accuracy: 52.40 

        train local model (freeze embeding):client   4,  Train loss: 0.802, Train accuracy: 68.600, Test loss: 1.037, Test accuracy: 57.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.601, Train accuracy: 75.600, Test loss: 1.058, Test accuracy: 63.20 

Round  19, Train loss: 0.826, Test loss: 1.119, Test accuracy: 58.32 

        train local model (freeze embeding):client   0,  Train loss: 0.786, Train accuracy: 70.000, Test loss: 1.180, Test accuracy: 52.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.514, Train accuracy: 80.800, Test loss: 1.408, Test accuracy: 55.00 

        train local model (freeze embeding):client   1,  Train loss: 0.718, Train accuracy: 72.000, Test loss: 1.088, Test accuracy: 57.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.403, Train accuracy: 87.400, Test loss: 1.070, Test accuracy: 59.60 

        train local model (freeze embeding):client   2,  Train loss: 0.938, Train accuracy: 63.800, Test loss: 1.370, Test accuracy: 51.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.851, Train accuracy: 68.800, Test loss: 1.587, Test accuracy: 48.80 

        train local model (freeze embeding):client   3,  Train loss: 0.989, Train accuracy: 61.600, Test loss: 1.164, Test accuracy: 50.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.621, Train accuracy: 77.000, Test loss: 1.140, Test accuracy: 55.40 

        train local model (freeze embeding):client   4,  Train loss: 0.820, Train accuracy: 68.200, Test loss: 1.060, Test accuracy: 58.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.721, Train accuracy: 71.600, Test loss: 1.145, Test accuracy: 59.80 

Final Round, Train loss: 0.823, Test loss: 1.114, Test accuracy: 58.36 

Average accuracy final 10 rounds: 289.9566666666666 

3604.582358598709
[10.59282398223877, 21.0986168384552, 31.56263303756714, 41.97374105453491, 52.01655101776123, 62.44898438453674, 72.35295557975769, 82.39664196968079, 92.4567482471466, 102.78043127059937, 112.99224853515625, 123.082026720047, 133.46442890167236, 143.69056057929993, 154.05106568336487, 164.5043306350708, 174.84422898292542, 185.35514378547668, 195.72236847877502, 206.78182864189148, 217.70059418678284, 229.35574054718018, 240.439932346344, 251.35447192192078, 262.217898607254, 273.3749213218689, 284.40735626220703, 295.49313521385193, 306.5518434047699, 317.71770119667053, 329.34455966949463, 339.99812936782837, 350.8160812854767, 361.8373944759369, 372.85776829719543, 383.18801641464233, 393.228506565094, 403.41951608657837, 413.482301235199, 423.80299043655396, 434.127507686615, 444.49354815483093, 455.1631751060486, 465.5981299877167, 476.13890075683594, 486.77790117263794, 497.91895055770874, 509.3705406188965, 520.2447907924652, 531.3274636268616, 542.4134256839752, 553.5335536003113, 564.9154164791107, 576.0263941287994, 587.0448672771454, 598.6197819709778, 609.7202084064484, 619.7321424484253, 630.2366709709167, 640.5782687664032, 650.9618923664093, 661.1341202259064, 671.987498998642, 683.3255529403687, 694.5610916614532, 706.6168038845062, 718.3356211185455, 730.2471261024475, 742.3648784160614, 754.428493976593, 766.2865047454834, 777.4947335720062, 787.3894066810608, 797.9763135910034, 808.5966334342957, 818.8084795475006, 829.2711727619171, 840.059417963028, 851.3985731601715, 862.5184659957886, 874.1103501319885, 885.9446723461151, 898.0002927780151, 909.3581919670105, 920.7320799827576, 931.9386229515076, 943.6085436344147, 953.7276468276978, 964.8624312877655, 976.7782428264618, 988.2780730724335, 1000.2572362422943, 1012.545480966568, 1024.1192636489868, 1035.5292649269104, 1045.4957554340363, 1056.117695093155, 1066.244720697403, 1077.4847362041473, 1089.1455719470978, 1100.6636686325073, 1112.4872150421143, 1124.4560017585754, 1136.1965935230255, 1147.3775386810303]
[36.6, 47.8, 43.6, 54.2, 52.0, 52.6, 57.2, 51.0, 53.8, 51.8, 52.8, 53.2, 51.0, 53.2, 54.6, 57.4, 53.2, 51.2, 55.2, 53.2, 51.6, 53.2, 60.1, 58.0, 60.7, 59.1, 58.7, 60.1, 61.7, 59.9, 60.2, 59.7, 61.0, 60.8, 61.2, 59.0, 57.9, 60.2, 60.1, 60.5, 61.7, 61.6, 59.13333333333333, 60.733333333333334, 60.06666666666667, 59.333333333333336, 59.266666666666666, 59.13333333333333, 60.13333333333333, 59.6, 59.46666666666667, 60.4, 58.266666666666666, 59.666666666666664, 57.4, 58.266666666666666, 59.06666666666667, 59.06666666666667, 58.93333333333333, 59.2, 58.53333333333333, 58.666666666666664, 58.46666666666667, 57.3, 57.1, 59.05, 58.3, 57.65, 58.3, 58.6, 59.0, 58.75, 58.35, 59.45, 58.45, 57.85, 58.95, 58.9, 59.3, 58.85, 59.65, 59.75, 58.65, 57.65, 60.0, 58.28, 58.68, 58.6, 59.44, 58.88, 58.32, 58.4, 51.0, 60.68, 59.84, 58.72, 59.64, 58.28, 55.04, 58.52, 58.68, 58.96, 59.6, 58.32, 58.36]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.455, Test loss: 1.262, Test accuracy: 51.60 

Round   0, Global train loss: 1.455, Global test loss: 2.486, Global test accuracy: 16.00 

Round   1, Train loss: 1.133, Test loss: 1.197, Test accuracy: 56.40 

Round   1, Global train loss: 1.133, Global test loss: 2.541, Global test accuracy: 16.00 

Round   2, Train loss: 0.971, Test loss: 1.170, Test accuracy: 59.88 

Round   2, Global train loss: 0.971, Global test loss: 2.735, Global test accuracy: 16.00 

Round   3, Train loss: 0.835, Test loss: 1.201, Test accuracy: 60.36 

Round   3, Global train loss: 0.835, Global test loss: 2.619, Global test accuracy: 16.00 

Round   4, Train loss: 0.715, Test loss: 1.320, Test accuracy: 58.52 

Round   4, Global train loss: 0.715, Global test loss: 2.743, Global test accuracy: 16.00 

Round   5, Train loss: 0.605, Test loss: 1.247, Test accuracy: 63.00 

Round   5, Global train loss: 0.605, Global test loss: 2.704, Global test accuracy: 16.00 

Round   6, Train loss: 0.516, Test loss: 1.396, Test accuracy: 60.68 

Round   6, Global train loss: 0.516, Global test loss: 2.878, Global test accuracy: 16.00 

Round   7, Train loss: 0.422, Test loss: 1.612, Test accuracy: 61.12 

Round   7, Global train loss: 0.422, Global test loss: 2.716, Global test accuracy: 16.00 

Round   8, Train loss: 0.372, Test loss: 1.629, Test accuracy: 61.52 

Round   8, Global train loss: 0.372, Global test loss: 2.976, Global test accuracy: 16.00 

Round   9, Train loss: 0.297, Test loss: 1.698, Test accuracy: 63.56 

Round   9, Global train loss: 0.297, Global test loss: 2.807, Global test accuracy: 16.00 

Round  10, Train loss: 0.242, Test loss: 1.452, Test accuracy: 66.40 

Round  10, Global train loss: 0.242, Global test loss: 2.793, Global test accuracy: 16.00 

Round  11, Train loss: 0.221, Test loss: 1.592, Test accuracy: 62.92 

Round  11, Global train loss: 0.221, Global test loss: 2.850, Global test accuracy: 16.00 

Round  12, Train loss: 0.190, Test loss: 1.386, Test accuracy: 67.84 

Round  12, Global train loss: 0.190, Global test loss: 2.883, Global test accuracy: 16.00 

Round  13, Train loss: 0.144, Test loss: 1.600, Test accuracy: 65.08 

Round  13, Global train loss: 0.144, Global test loss: 2.835, Global test accuracy: 16.00 

Round  14, Train loss: 0.143, Test loss: 1.482, Test accuracy: 67.64 

Round  14, Global train loss: 0.143, Global test loss: 2.830, Global test accuracy: 16.00 

Round  15, Train loss: 0.117, Test loss: 1.885, Test accuracy: 63.84 

Round  15, Global train loss: 0.117, Global test loss: 2.812, Global test accuracy: 16.00 

Round  16, Train loss: 0.103, Test loss: 1.464, Test accuracy: 68.72 

Round  16, Global train loss: 0.103, Global test loss: 2.906, Global test accuracy: 16.00 

Round  17, Train loss: 0.083, Test loss: 1.716, Test accuracy: 65.84 

Round  17, Global train loss: 0.083, Global test loss: 2.928, Global test accuracy: 16.00 

Round  18, Train loss: 0.108, Test loss: 1.710, Test accuracy: 66.08 

Round  18, Global train loss: 0.108, Global test loss: 2.918, Global test accuracy: 16.00 

Round  19, Train loss: 0.087, Test loss: 1.573, Test accuracy: 68.48 

Round  19, Global train loss: 0.087, Global test loss: 2.849, Global test accuracy: 16.00 

Round  20, Train loss: 0.070, Test loss: 1.601, Test accuracy: 69.28 

Round  20, Global train loss: 0.070, Global test loss: 2.809, Global test accuracy: 16.00 

Round  21, Train loss: 0.050, Test loss: 1.738, Test accuracy: 68.00 

Round  21, Global train loss: 0.050, Global test loss: 2.954, Global test accuracy: 16.00 

Round  22, Train loss: 0.046, Test loss: 1.552, Test accuracy: 70.04 

Round  22, Global train loss: 0.046, Global test loss: 2.916, Global test accuracy: 16.00 

Round  23, Train loss: 0.052, Test loss: 1.608, Test accuracy: 69.40 

Round  23, Global train loss: 0.052, Global test loss: 2.873, Global test accuracy: 16.00 

Round  24, Train loss: 0.041, Test loss: 1.599, Test accuracy: 68.64 

Round  24, Global train loss: 0.041, Global test loss: 2.909, Global test accuracy: 16.00 

Round  25, Train loss: 0.044, Test loss: 1.699, Test accuracy: 68.48 

Round  25, Global train loss: 0.044, Global test loss: 2.877, Global test accuracy: 16.00 

Round  26, Train loss: 0.046, Test loss: 1.594, Test accuracy: 69.76 

Round  26, Global train loss: 0.046, Global test loss: 2.798, Global test accuracy: 16.00 

Round  27, Train loss: 0.037, Test loss: 1.626, Test accuracy: 69.72 

Round  27, Global train loss: 0.037, Global test loss: 2.758, Global test accuracy: 16.00 

Round  28, Train loss: 0.032, Test loss: 1.629, Test accuracy: 69.40 

Round  28, Global train loss: 0.032, Global test loss: 2.867, Global test accuracy: 16.00 

Round  29, Train loss: 0.022, Test loss: 1.708, Test accuracy: 68.08 

Round  29, Global train loss: 0.022, Global test loss: 2.892, Global test accuracy: 16.00 

Round  30, Train loss: 0.029, Test loss: 1.672, Test accuracy: 70.32 

Round  30, Global train loss: 0.029, Global test loss: 2.752, Global test accuracy: 16.00 

Round  31, Train loss: 0.024, Test loss: 1.646, Test accuracy: 70.28 

Round  31, Global train loss: 0.024, Global test loss: 2.838, Global test accuracy: 16.00 

Round  32, Train loss: 0.016, Test loss: 1.723, Test accuracy: 69.76 

Round  32, Global train loss: 0.016, Global test loss: 2.851, Global test accuracy: 16.00 

Round  33, Train loss: 0.024, Test loss: 1.965, Test accuracy: 68.72 

Round  33, Global train loss: 0.024, Global test loss: 2.762, Global test accuracy: 16.00 

Round  34, Train loss: 0.031, Test loss: 1.590, Test accuracy: 71.16 

Round  34, Global train loss: 0.031, Global test loss: 2.817, Global test accuracy: 16.00 

Final Round, Train loss: 0.027, Test loss: 1.603, Test accuracy: 70.92 

Final Round, Global train loss: 0.027, Global test loss: 2.817, Global test accuracy: 16.00 

Average accuracy final 10 rounds: 69.56799999999998 

Average global accuracy final 10 rounds: 15.999999999999998 

1288.6324861049652
[8.789045333862305, 15.249126672744751, 21.602156162261963, 28.730464696884155, 35.19095253944397, 41.58123302459717, 48.17157435417175, 54.674726724624634, 60.98319673538208, 67.45644307136536, 73.83021235466003, 80.2738528251648, 86.5077383518219, 92.88931560516357, 99.13733506202698, 104.96598625183105, 110.70117950439453, 116.53981518745422, 122.41225457191467, 128.37337613105774, 134.3240442276001, 140.23605036735535, 146.05440211296082, 152.39913201332092, 158.5607008934021, 164.75578451156616, 171.20807433128357, 177.66902899742126, 184.03326511383057, 190.39541578292847, 196.64306473731995, 202.78687405586243, 208.84447836875916, 215.48890900611877, 221.93158054351807, 235.33177661895752]
[51.6, 56.4, 59.88, 60.36, 58.52, 63.0, 60.68, 61.12, 61.52, 63.56, 66.4, 62.92, 67.84, 65.08, 67.64, 63.84, 68.72, 65.84, 66.08, 68.48, 69.28, 68.0, 70.04, 69.4, 68.64, 68.48, 69.76, 69.72, 69.4, 68.08, 70.32, 70.28, 69.76, 68.72, 71.16, 70.92]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.456, Test loss: 1.174, Test accuracy: 54.96 

Round   0, Global train loss: 1.456, Global test loss: 2.323, Global test accuracy: 16.64 

Round   1, Train loss: 1.326, Test loss: 1.198, Test accuracy: 55.44 

Round   1, Global train loss: 1.326, Global test loss: 2.025, Global test accuracy: 24.44 

Round   2, Train loss: 1.176, Test loss: 1.144, Test accuracy: 57.16 

Round   2, Global train loss: 1.176, Global test loss: 1.590, Global test accuracy: 40.96 

Round   3, Train loss: 1.046, Test loss: 1.279, Test accuracy: 60.24 

Round   3, Global train loss: 1.046, Global test loss: 1.352, Global test accuracy: 51.68 

Round   4, Train loss: 0.951, Test loss: 1.172, Test accuracy: 61.72 

Round   4, Global train loss: 0.951, Global test loss: 1.303, Global test accuracy: 53.00 

Round   5, Train loss: 0.858, Test loss: 1.040, Test accuracy: 64.04 

Round   5, Global train loss: 0.858, Global test loss: 1.242, Global test accuracy: 57.68 

Round   6, Train loss: 0.781, Test loss: 1.140, Test accuracy: 63.76 

Round   6, Global train loss: 0.781, Global test loss: 1.144, Global test accuracy: 61.88 

Round   7, Train loss: 0.720, Test loss: 1.064, Test accuracy: 65.40 

Round   7, Global train loss: 0.720, Global test loss: 1.214, Global test accuracy: 58.20 

Round   8, Train loss: 0.683, Test loss: 1.262, Test accuracy: 63.92 

Round   8, Global train loss: 0.683, Global test loss: 1.124, Global test accuracy: 62.64 

Round   9, Train loss: 0.598, Test loss: 0.969, Test accuracy: 68.84 

Round   9, Global train loss: 0.598, Global test loss: 1.132, Global test accuracy: 62.84 

Round  10, Train loss: 0.557, Test loss: 1.139, Test accuracy: 67.96 

Round  10, Global train loss: 0.557, Global test loss: 1.056, Global test accuracy: 65.20 

Round  11, Train loss: 0.524, Test loss: 1.061, Test accuracy: 69.84 

Round  11, Global train loss: 0.524, Global test loss: 1.122, Global test accuracy: 63.68 

Round  12, Train loss: 0.484, Test loss: 0.984, Test accuracy: 71.44 

Round  12, Global train loss: 0.484, Global test loss: 1.075, Global test accuracy: 65.08 

Round  13, Train loss: 0.436, Test loss: 1.047, Test accuracy: 70.16 

Round  13, Global train loss: 0.436, Global test loss: 1.073, Global test accuracy: 65.52 

Round  14, Train loss: 0.419, Test loss: 0.955, Test accuracy: 73.08 

Round  14, Global train loss: 0.419, Global test loss: 1.027, Global test accuracy: 67.12 

Round  15, Train loss: 0.365, Test loss: 1.035, Test accuracy: 72.28 

Round  15, Global train loss: 0.365, Global test loss: 1.009, Global test accuracy: 67.36 

Round  16, Train loss: 0.335, Test loss: 0.966, Test accuracy: 74.28 

Round  16, Global train loss: 0.335, Global test loss: 0.986, Global test accuracy: 69.76 

Round  17, Train loss: 0.326, Test loss: 0.987, Test accuracy: 73.76 

Round  17, Global train loss: 0.326, Global test loss: 0.999, Global test accuracy: 68.76 

Round  18, Train loss: 0.301, Test loss: 0.982, Test accuracy: 74.36 

Round  18, Global train loss: 0.301, Global test loss: 0.991, Global test accuracy: 68.60 

Round  19, Train loss: 0.256, Test loss: 0.991, Test accuracy: 74.72 

Round  19, Global train loss: 0.256, Global test loss: 1.056, Global test accuracy: 68.92 

Round  20, Train loss: 0.258, Test loss: 1.042, Test accuracy: 75.40 

Round  20, Global train loss: 0.258, Global test loss: 1.021, Global test accuracy: 69.96 

Round  21, Train loss: 0.232, Test loss: 1.066, Test accuracy: 74.04 

Round  21, Global train loss: 0.232, Global test loss: 1.032, Global test accuracy: 69.72 

Round  22, Train loss: 0.230, Test loss: 0.839, Test accuracy: 78.04 

Round  22, Global train loss: 0.230, Global test loss: 0.928, Global test accuracy: 70.84 

Round  23, Train loss: 0.207, Test loss: 1.110, Test accuracy: 74.60 

Round  23, Global train loss: 0.207, Global test loss: 1.009, Global test accuracy: 69.92 

Round  24, Train loss: 0.192, Test loss: 1.089, Test accuracy: 73.56 

Round  24, Global train loss: 0.192, Global test loss: 1.020, Global test accuracy: 70.12 

Round  25, Train loss: 0.184, Test loss: 0.923, Test accuracy: 76.88 

Round  25, Global train loss: 0.184, Global test loss: 0.980, Global test accuracy: 71.56 

Round  26, Train loss: 0.155, Test loss: 0.884, Test accuracy: 77.76 

Round  26, Global train loss: 0.155, Global test loss: 0.959, Global test accuracy: 71.64 

Round  27, Train loss: 0.148, Test loss: 1.092, Test accuracy: 74.92 

Round  27, Global train loss: 0.148, Global test loss: 0.984, Global test accuracy: 71.64 

Round  28, Train loss: 0.151, Test loss: 1.038, Test accuracy: 75.84 

Round  28, Global train loss: 0.151, Global test loss: 0.965, Global test accuracy: 72.64 

Round  29, Train loss: 0.128, Test loss: 0.940, Test accuracy: 77.20 

Round  29, Global train loss: 0.128, Global test loss: 0.993, Global test accuracy: 72.00 

Round  30, Train loss: 0.126, Test loss: 1.107, Test accuracy: 76.60 

Round  30, Global train loss: 0.126, Global test loss: 0.984, Global test accuracy: 72.32 

Round  31, Train loss: 0.124, Test loss: 1.060, Test accuracy: 77.60 

Round  31, Global train loss: 0.124, Global test loss: 1.001, Global test accuracy: 72.40 

Round  32, Train loss: 0.100, Test loss: 1.027, Test accuracy: 77.60 

Round  32, Global train loss: 0.100, Global test loss: 0.997, Global test accuracy: 72.04 

Round  33, Train loss: 0.099, Test loss: 1.076, Test accuracy: 76.92 

Round  33, Global train loss: 0.099, Global test loss: 1.026, Global test accuracy: 72.52 

Round  34, Train loss: 0.130, Test loss: 1.149, Test accuracy: 75.48 

Round  34, Global train loss: 0.130, Global test loss: 1.038, Global test accuracy: 71.28 

Round  35, Train loss: 0.089, Test loss: 0.901, Test accuracy: 79.12 

Round  35, Global train loss: 0.089, Global test loss: 0.978, Global test accuracy: 72.36 

Round  36, Train loss: 0.092, Test loss: 1.041, Test accuracy: 77.72 

Round  36, Global train loss: 0.092, Global test loss: 1.008, Global test accuracy: 72.60 

Round  37, Train loss: 0.086, Test loss: 0.963, Test accuracy: 78.84 

Round  37, Global train loss: 0.086, Global test loss: 0.963, Global test accuracy: 72.48 

Round  38, Train loss: 0.072, Test loss: 0.988, Test accuracy: 78.80 

Round  38, Global train loss: 0.072, Global test loss: 0.973, Global test accuracy: 73.04 

Round  39, Train loss: 0.092, Test loss: 1.014, Test accuracy: 77.20 

Round  39, Global train loss: 0.092, Global test loss: 0.912, Global test accuracy: 73.48 

Round  40, Train loss: 0.055, Test loss: 1.005, Test accuracy: 78.20 

Round  40, Global train loss: 0.055, Global test loss: 1.010, Global test accuracy: 72.92 

Round  41, Train loss: 0.055, Test loss: 1.015, Test accuracy: 79.28 

Round  41, Global train loss: 0.055, Global test loss: 0.965, Global test accuracy: 74.16 

Round  42, Train loss: 0.052, Test loss: 1.077, Test accuracy: 78.44 

Round  42, Global train loss: 0.052, Global test loss: 0.972, Global test accuracy: 73.12 

Round  43, Train loss: 0.063, Test loss: 0.985, Test accuracy: 79.20 

Round  43, Global train loss: 0.063, Global test loss: 0.979, Global test accuracy: 74.28 

Round  44, Train loss: 0.061, Test loss: 0.816, Test accuracy: 81.48 

Round  44, Global train loss: 0.061, Global test loss: 0.947, Global test accuracy: 74.00 

Round  45, Train loss: 0.056, Test loss: 0.996, Test accuracy: 78.88 

Round  45, Global train loss: 0.056, Global test loss: 0.988, Global test accuracy: 74.00 

Round  46, Train loss: 0.046, Test loss: 1.126, Test accuracy: 77.88 

Round  46, Global train loss: 0.046, Global test loss: 0.991, Global test accuracy: 73.56 

Round  47, Train loss: 0.079, Test loss: 0.944, Test accuracy: 79.60 

Round  47, Global train loss: 0.079, Global test loss: 0.927, Global test accuracy: 74.40 

Round  48, Train loss: 0.041, Test loss: 0.944, Test accuracy: 79.60 

Round  48, Global train loss: 0.041, Global test loss: 0.974, Global test accuracy: 73.48 

Round  49, Train loss: 0.041, Test loss: 0.960, Test accuracy: 79.52 

Round  49, Global train loss: 0.041, Global test loss: 1.028, Global test accuracy: 73.36 

Final Round, Train loss: 0.038, Test loss: 1.148, Test accuracy: 77.92 

Final Round, Global train loss: 0.038, Global test loss: 1.028, Global test accuracy: 73.36 

Average accuracy final 10 rounds: 79.20799999999998 

Average global accuracy final 10 rounds: 73.728 

1784.2801778316498
[8.300588846206665, 14.852059602737427, 21.279515743255615, 27.37709331512451, 33.56786632537842, 39.89122986793518, 46.14801740646362, 52.880422830581665, 58.95495557785034, 65.03882384300232, 71.13805770874023, 77.26224422454834, 83.40439772605896, 89.39300179481506, 95.61740326881409, 101.65960335731506, 108.18198490142822, 114.21723008155823, 120.68053436279297, 127.33400130271912, 133.70620369911194, 140.0110478401184, 146.25267958641052, 152.38337922096252, 158.4945363998413, 164.87132930755615, 171.31408023834229, 177.39569091796875, 183.53035831451416, 189.8316295146942, 196.09971046447754, 202.0560405254364, 208.06167221069336, 214.8720269203186, 221.6417281627655, 228.1986424922943, 234.50678420066833, 241.13186621665955, 247.6030695438385, 254.38932299613953, 260.62054800987244, 266.9474925994873, 273.101313829422, 279.31919503211975, 285.68757033348083, 291.8612563610077, 298.17207384109497, 304.0766975879669, 310.2032287120819, 316.14336800575256, 328.64296078681946]
[54.96, 55.44, 57.16, 60.24, 61.72, 64.04, 63.76, 65.4, 63.92, 68.84, 67.96, 69.84, 71.44, 70.16, 73.08, 72.28, 74.28, 73.76, 74.36, 74.72, 75.4, 74.04, 78.04, 74.6, 73.56, 76.88, 77.76, 74.92, 75.84, 77.2, 76.6, 77.6, 77.6, 76.92, 75.48, 79.12, 77.72, 78.84, 78.8, 77.2, 78.2, 79.28, 78.44, 79.2, 81.48, 78.88, 77.88, 79.6, 79.6, 79.52, 77.92]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.526, Test loss: 1.794, Test accuracy: 25.36 

Round   1, Train loss: 1.354, Test loss: 1.725, Test accuracy: 32.96 

Round   2, Train loss: 1.217, Test loss: 1.247, Test accuracy: 50.36 

Round   3, Train loss: 1.127, Test loss: 1.194, Test accuracy: 52.16 

Round   4, Train loss: 1.031, Test loss: 1.175, Test accuracy: 52.52 

Round   5, Train loss: 0.946, Test loss: 0.974, Test accuracy: 61.40 

Round   6, Train loss: 0.889, Test loss: 0.993, Test accuracy: 61.52 

Round   7, Train loss: 0.826, Test loss: 0.937, Test accuracy: 63.92 

Round   8, Train loss: 0.776, Test loss: 0.864, Test accuracy: 66.20 

Round   9, Train loss: 0.733, Test loss: 0.838, Test accuracy: 68.08 

Round  10, Train loss: 0.692, Test loss: 0.832, Test accuracy: 68.92 

Round  11, Train loss: 0.637, Test loss: 0.790, Test accuracy: 70.72 

Round  12, Train loss: 0.613, Test loss: 0.792, Test accuracy: 71.48 

Round  13, Train loss: 0.571, Test loss: 0.765, Test accuracy: 72.44 

Round  14, Train loss: 0.537, Test loss: 0.714, Test accuracy: 74.56 

Round  15, Train loss: 0.506, Test loss: 0.735, Test accuracy: 74.56 

Round  16, Train loss: 0.471, Test loss: 0.700, Test accuracy: 75.44 

Round  17, Train loss: 0.447, Test loss: 0.760, Test accuracy: 73.92 

Round  18, Train loss: 0.420, Test loss: 0.713, Test accuracy: 74.80 

Round  19, Train loss: 0.411, Test loss: 0.706, Test accuracy: 75.44 

Round  20, Train loss: 0.362, Test loss: 0.675, Test accuracy: 76.20 

Round  21, Train loss: 0.341, Test loss: 0.681, Test accuracy: 76.24 

Round  22, Train loss: 0.320, Test loss: 0.686, Test accuracy: 77.84 

Round  23, Train loss: 0.292, Test loss: 0.675, Test accuracy: 77.64 

Round  24, Train loss: 0.288, Test loss: 0.696, Test accuracy: 78.00 

Round  25, Train loss: 0.264, Test loss: 0.731, Test accuracy: 77.32 

Round  26, Train loss: 0.263, Test loss: 0.672, Test accuracy: 79.00 

Round  27, Train loss: 0.232, Test loss: 0.662, Test accuracy: 79.24 

Round  28, Train loss: 0.215, Test loss: 0.711, Test accuracy: 78.64 

Round  29, Train loss: 0.202, Test loss: 0.659, Test accuracy: 79.00 

Round  30, Train loss: 0.196, Test loss: 0.658, Test accuracy: 79.52 

Round  31, Train loss: 0.173, Test loss: 0.655, Test accuracy: 80.20 

Round  32, Train loss: 0.168, Test loss: 0.653, Test accuracy: 80.52 

Round  33, Train loss: 0.151, Test loss: 0.663, Test accuracy: 80.00 

Round  34, Train loss: 0.132, Test loss: 0.661, Test accuracy: 80.40 

Round  35, Train loss: 0.144, Test loss: 0.664, Test accuracy: 80.44 

Round  36, Train loss: 0.131, Test loss: 0.686, Test accuracy: 79.52 

Round  37, Train loss: 0.127, Test loss: 0.641, Test accuracy: 81.08 

Round  38, Train loss: 0.116, Test loss: 0.651, Test accuracy: 80.64 

Round  39, Train loss: 0.110, Test loss: 0.680, Test accuracy: 81.68 

Round  40, Train loss: 0.102, Test loss: 0.682, Test accuracy: 80.88 

Round  41, Train loss: 0.092, Test loss: 0.663, Test accuracy: 82.00 

Round  42, Train loss: 0.098, Test loss: 0.690, Test accuracy: 81.16 

Round  43, Train loss: 0.082, Test loss: 0.710, Test accuracy: 80.48 

Round  44, Train loss: 0.081, Test loss: 0.684, Test accuracy: 81.12 

Round  45, Train loss: 0.078, Test loss: 0.722, Test accuracy: 80.64 

Round  46, Train loss: 0.073, Test loss: 0.683, Test accuracy: 80.60 

Round  47, Train loss: 0.064, Test loss: 0.713, Test accuracy: 80.88 

Round  48, Train loss: 0.057, Test loss: 0.757, Test accuracy: 80.92 

Round  49, Train loss: 0.077, Test loss: 0.685, Test accuracy: 81.32 

Final Round, Train loss: 0.034, Test loss: 0.695, Test accuracy: 81.60 

Average accuracy final 10 rounds: 81.0 

1308.8994626998901
[6.705749988555908, 11.59876823425293, 16.511505365371704, 21.23460102081299, 25.880523443222046, 30.990055322647095, 35.856632232666016, 40.75716686248779, 45.91100025177002, 50.75675845146179, 55.656922340393066, 60.613943099975586, 65.8625876903534, 70.97060132026672, 75.90083265304565, 80.79694819450378, 85.64996004104614, 90.44247579574585, 95.19115567207336, 99.96938967704773, 105.1957859992981, 109.91434574127197, 115.16262412071228, 120.00942039489746, 124.940988779068, 129.67938590049744, 134.8325536251068, 139.80745267868042, 144.67430973052979, 149.70924878120422, 154.51343417167664, 159.6442220211029, 164.43719220161438, 169.6363079547882, 174.55667567253113, 179.75025057792664, 184.59691667556763, 189.4296350479126, 194.3446843624115, 199.10387754440308, 204.39434361457825, 209.29127073287964, 213.98476767539978, 218.96228218078613, 223.70690059661865, 228.80893802642822, 233.39682936668396, 238.13456392288208, 243.1613597869873, 247.9676661491394, 253.09273314476013]
[25.36, 32.96, 50.36, 52.16, 52.52, 61.4, 61.52, 63.92, 66.2, 68.08, 68.92, 70.72, 71.48, 72.44, 74.56, 74.56, 75.44, 73.92, 74.8, 75.44, 76.2, 76.24, 77.84, 77.64, 78.0, 77.32, 79.0, 79.24, 78.64, 79.0, 79.52, 80.2, 80.52, 80.0, 80.4, 80.44, 79.52, 81.08, 80.64, 81.68, 80.88, 82.0, 81.16, 80.48, 81.12, 80.64, 80.6, 80.88, 80.92, 81.32, 81.6]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
Round   0, Train loss: 1.550, Test loss: 2.079, Test accuracy: 22.84
Round   1, Train loss: 1.384, Test loss: 1.890, Test accuracy: 32.72
Round   2, Train loss: 1.228, Test loss: 1.252, Test accuracy: 47.48
Round   3, Train loss: 1.110, Test loss: 1.214, Test accuracy: 49.28
Round   4, Train loss: 1.014, Test loss: 1.065, Test accuracy: 57.56
Round   5, Train loss: 0.956, Test loss: 0.959, Test accuracy: 61.76
Round   6, Train loss: 0.897, Test loss: 0.876, Test accuracy: 64.64
Round   7, Train loss: 0.838, Test loss: 0.890, Test accuracy: 64.84
Round   8, Train loss: 0.783, Test loss: 0.863, Test accuracy: 66.48
Round   9, Train loss: 0.745, Test loss: 0.767, Test accuracy: 70.00
Round  10, Train loss: 0.693, Test loss: 0.771, Test accuracy: 70.48
Round  11, Train loss: 0.656, Test loss: 0.781, Test accuracy: 71.24
Round  12, Train loss: 0.624, Test loss: 0.733, Test accuracy: 71.92
Round  13, Train loss: 0.579, Test loss: 0.683, Test accuracy: 74.56
Round  14, Train loss: 0.539, Test loss: 0.689, Test accuracy: 74.52
Round  15, Train loss: 0.503, Test loss: 0.747, Test accuracy: 72.28
Round  16, Train loss: 0.482, Test loss: 0.793, Test accuracy: 72.48
Round  17, Train loss: 0.449, Test loss: 0.683, Test accuracy: 75.44
Round  18, Train loss: 0.424, Test loss: 0.687, Test accuracy: 75.88
Round  19, Train loss: 0.407, Test loss: 0.735, Test accuracy: 74.36
Round  20, Train loss: 0.372, Test loss: 0.669, Test accuracy: 76.16
Round  21, Train loss: 0.361, Test loss: 0.689, Test accuracy: 76.00
Round  22, Train loss: 0.335, Test loss: 0.687, Test accuracy: 76.84
Round  23, Train loss: 0.314, Test loss: 0.634, Test accuracy: 78.96
Round  24, Train loss: 0.291, Test loss: 0.634, Test accuracy: 78.32
Round  25, Train loss: 0.270, Test loss: 0.669, Test accuracy: 78.20
Round  26, Train loss: 0.254, Test loss: 0.706, Test accuracy: 77.16
Round  27, Train loss: 0.242, Test loss: 0.744, Test accuracy: 76.96
Round  28, Train loss: 0.235, Test loss: 0.656, Test accuracy: 79.00
Round  29, Train loss: 0.213, Test loss: 0.655, Test accuracy: 79.00
Round  30, Train loss: 0.208, Test loss: 0.625, Test accuracy: 80.32
Round  31, Train loss: 0.170, Test loss: 0.661, Test accuracy: 79.80
Round  32, Train loss: 0.170, Test loss: 0.646, Test accuracy: 79.92
Round  33, Train loss: 0.155, Test loss: 0.650, Test accuracy: 80.16
Round  34, Train loss: 0.165, Test loss: 0.649, Test accuracy: 80.56
Round  35, Train loss: 0.142, Test loss: 0.660, Test accuracy: 80.72
Round  36, Train loss: 0.129, Test loss: 0.706, Test accuracy: 79.64
Round  37, Train loss: 0.130, Test loss: 0.665, Test accuracy: 81.56
Round  38, Train loss: 0.114, Test loss: 0.682, Test accuracy: 80.04
Round  39, Train loss: 0.120, Test loss: 0.670, Test accuracy: 80.68
Round  40, Train loss: 0.107, Test loss: 0.643, Test accuracy: 80.88
Round  41, Train loss: 0.100, Test loss: 0.661, Test accuracy: 80.76
Round  42, Train loss: 0.100, Test loss: 0.692, Test accuracy: 81.00
Round  43, Train loss: 0.092, Test loss: 0.659, Test accuracy: 80.96
Round  44, Train loss: 0.076, Test loss: 0.662, Test accuracy: 81.20
Round  45, Train loss: 0.073, Test loss: 0.689, Test accuracy: 81.08
Round  46, Train loss: 0.083, Test loss: 0.680, Test accuracy: 80.56
Round  47, Train loss: 0.075, Test loss: 0.674, Test accuracy: 80.84
Round  48, Train loss: 0.072, Test loss: 0.701, Test accuracy: 80.52
Round  49, Train loss: 0.060, Test loss: 0.670, Test accuracy: 81.40
Final Round, Train loss: 0.033, Test loss: 0.683, Test accuracy: 81.40
Average accuracy final 10 rounds: 80.92
1356.933987379074
[7.083610773086548, 11.916813135147095, 17.493605136871338, 22.617733001708984, 27.98451852798462, 33.095728158950806, 37.95520257949829, 43.09244084358215, 48.18946051597595, 53.172847270965576, 58.08034133911133, 63.22492170333862, 68.13440608978271, 73.14642286300659, 78.10638403892517, 83.15390014648438, 87.99966549873352, 93.10099506378174, 98.23737120628357, 103.16685223579407, 108.3599443435669, 113.5207290649414, 119.49855852127075, 124.94641447067261, 129.92382907867432, 135.02699255943298, 140.14603567123413, 145.20508527755737, 150.38187503814697, 155.48838925361633, 161.3584587574005, 166.51184511184692, 171.65973210334778, 177.09266924858093, 182.18117094039917, 187.34395051002502, 192.4323935508728, 197.50194215774536, 202.5358691215515, 207.7435553073883, 212.7198932170868, 217.7777659893036, 223.03493666648865, 228.2195372581482, 233.29738903045654, 238.24276614189148, 243.30670285224915, 248.38860273361206, 253.61491584777832, 258.80353331565857, 264.7640061378479]
[22.84, 32.72, 47.48, 49.28, 57.56, 61.76, 64.64, 64.84, 66.48, 70.0, 70.48, 71.24, 71.92, 74.56, 74.52, 72.28, 72.48, 75.44, 75.88, 74.36, 76.16, 76.0, 76.84, 78.96, 78.32, 78.2, 77.16, 76.96, 79.0, 79.0, 80.32, 79.8, 79.92, 80.16, 80.56, 80.72, 79.64, 81.56, 80.04, 80.68, 80.88, 80.76, 81.0, 80.96, 81.2, 81.08, 80.56, 80.84, 80.52, 81.4, 81.4]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

        init --> train local model(freeze embeding):client   0,  Train loss: 0.899, Train accuracy: 65.800, Test loss: 1.069, Test accuracy: 60.40 

        train local model (freeze embeding):client   0,  Train loss: 0.880, Train accuracy: 66.200, Test loss: 1.155, Test accuracy: 60.40 

        train local model (unfreeze embeding):client   0,  Train loss: 1.052, Train accuracy: 55.000, Test loss: 1.324, Test accuracy: 49.60 

Round   0, Train loss: 1.013, Test loss: 1.324, Test accuracy: 49.60 

        train local model (freeze embeding):client   0,  Train loss: 1.322, Train accuracy: 59.000, Test loss: 1.701, Test accuracy: 51.20 

        train local model (unfreeze embeding):client   0,  Train loss: 1.100, Train accuracy: 53.600, Test loss: 1.207, Test accuracy: 46.20 

Round   1, Train loss: 1.594, Test loss: 1.207, Test accuracy: 46.20 

        train local model (freeze embeding):client   0,  Train loss: 1.332, Train accuracy: 60.000, Test loss: 1.494, Test accuracy: 56.60 

        train local model (unfreeze embeding):client   0,  Train loss: 1.048, Train accuracy: 56.200, Test loss: 1.195, Test accuracy: 53.20 

Round   2, Train loss: 1.385, Test loss: 1.195, Test accuracy: 53.20 

        train local model (freeze embeding):client   0,  Train loss: 1.479, Train accuracy: 51.800, Test loss: 1.636, Test accuracy: 46.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.976, Train accuracy: 60.600, Test loss: 1.096, Test accuracy: 54.60 

Round   3, Train loss: 1.358, Test loss: 1.096, Test accuracy: 54.60 

        train local model (freeze embeding):client   0,  Train loss: 1.251, Train accuracy: 58.600, Test loss: 1.559, Test accuracy: 51.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.799, Train accuracy: 66.600, Test loss: 1.103, Test accuracy: 58.00 

Round   4, Train loss: 1.299, Test loss: 1.103, Test accuracy: 58.00 

        train local model (freeze embeding):client   0,  Train loss: 0.909, Train accuracy: 65.400, Test loss: 1.034, Test accuracy: 63.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.748, Train accuracy: 69.800, Test loss: 0.984, Test accuracy: 61.40 

Round   5, Train loss: 1.140, Test loss: 0.984, Test accuracy: 61.40 

        train local model (freeze embeding):client   0,  Train loss: 0.876, Train accuracy: 66.600, Test loss: 1.340, Test accuracy: 58.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.890, Train accuracy: 61.600, Test loss: 1.149, Test accuracy: 53.80 

Round   6, Train loss: 1.154, Test loss: 1.149, Test accuracy: 53.80 

        train local model (freeze embeding):client   0,  Train loss: 0.807, Train accuracy: 71.000, Test loss: 1.345, Test accuracy: 58.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.652, Train accuracy: 73.400, Test loss: 0.959, Test accuracy: 64.40 

Round   7, Train loss: 1.090, Test loss: 0.959, Test accuracy: 64.40 

        train local model (freeze embeding):client   0,  Train loss: 1.265, Train accuracy: 58.600, Test loss: 1.562, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.699, Train accuracy: 72.000, Test loss: 1.085, Test accuracy: 60.80 

Round   8, Train loss: 1.031, Test loss: 1.085, Test accuracy: 60.80 

        train local model (freeze embeding):client   0,  Train loss: 0.958, Train accuracy: 64.800, Test loss: 1.171, Test accuracy: 58.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.719, Train accuracy: 71.200, Test loss: 1.098, Test accuracy: 59.00 

Round   9, Train loss: 0.934, Test loss: 1.098, Test accuracy: 59.00 

        train local model (freeze embeding):client   0,  Train loss: 1.138, Train accuracy: 66.400, Test loss: 1.791, Test accuracy: 57.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.624, Train accuracy: 72.800, Test loss: 1.065, Test accuracy: 59.20 

Round  10, Train loss: 0.914, Test loss: 1.065, Test accuracy: 59.20 

        train local model (freeze embeding):client   0,  Train loss: 0.665, Train accuracy: 72.200, Test loss: 1.182, Test accuracy: 61.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.540, Train accuracy: 80.200, Test loss: 0.993, Test accuracy: 63.00 

Round  11, Train loss: 0.950, Test loss: 0.993, Test accuracy: 63.00 

        train local model (freeze embeding):client   0,  Train loss: 0.684, Train accuracy: 74.600, Test loss: 1.174, Test accuracy: 62.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.529, Train accuracy: 78.800, Test loss: 0.998, Test accuracy: 62.00 

Round  12, Train loss: 0.840, Test loss: 0.998, Test accuracy: 62.00 

        train local model (freeze embeding):client   0,  Train loss: 1.088, Train accuracy: 69.200, Test loss: 1.567, Test accuracy: 60.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.451, Train accuracy: 82.200, Test loss: 0.962, Test accuracy: 64.00 

Round  13, Train loss: 0.833, Test loss: 0.962, Test accuracy: 64.00 

        train local model (freeze embeding):client   0,  Train loss: 0.746, Train accuracy: 71.600, Test loss: 1.488, Test accuracy: 56.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.438, Train accuracy: 82.800, Test loss: 0.992, Test accuracy: 65.80 

Round  14, Train loss: 0.831, Test loss: 0.992, Test accuracy: 65.80 

        train local model (freeze embeding):client   0,  Train loss: 0.758, Train accuracy: 74.600, Test loss: 1.563, Test accuracy: 58.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.618, Train accuracy: 75.600, Test loss: 1.375, Test accuracy: 60.80 

Round  15, Train loss: 0.833, Test loss: 1.375, Test accuracy: 60.80 

        train local model (freeze embeding):client   0,  Train loss: 0.480, Train accuracy: 80.800, Test loss: 1.124, Test accuracy: 62.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.382, Train accuracy: 84.600, Test loss: 1.320, Test accuracy: 64.00 

Round  16, Train loss: 0.731, Test loss: 1.320, Test accuracy: 64.00 

        train local model (freeze embeding):client   0,  Train loss: 0.438, Train accuracy: 81.600, Test loss: 1.251, Test accuracy: 61.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.390, Train accuracy: 86.200, Test loss: 1.070, Test accuracy: 65.20 

Round  17, Train loss: 0.725, Test loss: 1.070, Test accuracy: 65.20 

        train local model (freeze embeding):client   0,  Train loss: 0.508, Train accuracy: 80.800, Test loss: 1.255, Test accuracy: 62.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.363, Train accuracy: 87.000, Test loss: 1.050, Test accuracy: 66.80 

Round  18, Train loss: 0.712, Test loss: 1.050, Test accuracy: 66.80 

        train local model (freeze embeding):client   0,  Train loss: 0.616, Train accuracy: 78.600, Test loss: 1.451, Test accuracy: 64.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.338, Train accuracy: 87.600, Test loss: 1.251, Test accuracy: 63.40 

Round  19, Train loss: 0.698, Test loss: 1.251, Test accuracy: 63.40 

        train local model (freeze embeding):client   0,  Train loss: 0.663, Train accuracy: 77.600, Test loss: 1.386, Test accuracy: 61.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.377, Train accuracy: 87.000, Test loss: 1.102, Test accuracy: 66.20 

Final Round, Train loss: 0.731, Test loss: 1.373, Test accuracy: 61.00 

---------------------------------------------train_client: [0, 1] 

        init --> train local model(freeze embeding):client   1,  Train loss: 1.415, Train accuracy: 47.400, Test loss: 1.545, Test accuracy: 43.20 

        train local model (freeze embeding):client   0,  Train loss: 0.568, Train accuracy: 80.400, Test loss: 1.454, Test accuracy: 61.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.411, Train accuracy: 84.800, Test loss: 1.175, Test accuracy: 63.40 

        train local model (freeze embeding):client   1,  Train loss: 1.249, Train accuracy: 48.600, Test loss: 1.388, Test accuracy: 43.60 

        train local model (unfreeze embeding):client   1,  Train loss: 1.152, Train accuracy: 47.400, Test loss: 1.217, Test accuracy: 47.00 

Round   0, Train loss: 1.051, Test loss: 1.222, Test accuracy: 55.70 

        train local model (freeze embeding):client   0,  Train loss: 0.787, Train accuracy: 72.800, Test loss: 1.783, Test accuracy: 59.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.363, Train accuracy: 86.000, Test loss: 1.251, Test accuracy: 63.80 

        train local model (freeze embeding):client   1,  Train loss: 1.975, Train accuracy: 42.600, Test loss: 1.903, Test accuracy: 42.40 

        train local model (unfreeze embeding):client   1,  Train loss: 1.100, Train accuracy: 54.000, Test loss: 1.183, Test accuracy: 48.60 

Round   1, Train loss: 1.098, Test loss: 1.245, Test accuracy: 55.10 

        train local model (freeze embeding):client   0,  Train loss: 0.620, Train accuracy: 79.200, Test loss: 1.354, Test accuracy: 61.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.334, Train accuracy: 87.400, Test loss: 1.242, Test accuracy: 65.00 

        train local model (freeze embeding):client   1,  Train loss: 1.538, Train accuracy: 51.200, Test loss: 1.765, Test accuracy: 47.60 

        train local model (unfreeze embeding):client   1,  Train loss: 1.058, Train accuracy: 56.400, Test loss: 1.228, Test accuracy: 48.80 

Round   2, Train loss: 1.042, Test loss: 1.185, Test accuracy: 58.60 

        train local model (freeze embeding):client   0,  Train loss: 0.648, Train accuracy: 77.600, Test loss: 1.249, Test accuracy: 63.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.389, Train accuracy: 83.800, Test loss: 1.351, Test accuracy: 62.60 

        train local model (freeze embeding):client   1,  Train loss: 1.294, Train accuracy: 53.800, Test loss: 1.403, Test accuracy: 50.40 

        train local model (unfreeze embeding):client   1,  Train loss: 1.016, Train accuracy: 59.400, Test loss: 1.210, Test accuracy: 48.20 

Round   3, Train loss: 1.019, Test loss: 1.186, Test accuracy: 57.90 

        train local model (freeze embeding):client   0,  Train loss: 0.547, Train accuracy: 79.200, Test loss: 1.134, Test accuracy: 61.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.294, Train accuracy: 89.000, Test loss: 1.039, Test accuracy: 66.40 

        train local model (freeze embeding):client   1,  Train loss: 1.222, Train accuracy: 48.200, Test loss: 1.356, Test accuracy: 46.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.989, Train accuracy: 58.400, Test loss: 1.165, Test accuracy: 53.40 

Round   4, Train loss: 1.010, Test loss: 1.145, Test accuracy: 57.40 

        train local model (freeze embeding):client   0,  Train loss: 0.572, Train accuracy: 75.400, Test loss: 1.055, Test accuracy: 64.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.598, Train accuracy: 77.800, Test loss: 1.521, Test accuracy: 61.60 

        train local model (freeze embeding):client   1,  Train loss: 1.142, Train accuracy: 48.600, Test loss: 1.300, Test accuracy: 45.60 

        train local model (unfreeze embeding):client   1,  Train loss: 1.049, Train accuracy: 54.800, Test loss: 1.277, Test accuracy: 47.00 

Round   5, Train loss: 0.962, Test loss: 1.293, Test accuracy: 56.10 

        train local model (freeze embeding):client   0,  Train loss: 0.575, Train accuracy: 78.000, Test loss: 1.162, Test accuracy: 63.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.370, Train accuracy: 85.000, Test loss: 1.133, Test accuracy: 65.00 

        train local model (freeze embeding):client   1,  Train loss: 1.235, Train accuracy: 51.600, Test loss: 1.423, Test accuracy: 42.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.936, Train accuracy: 61.000, Test loss: 1.174, Test accuracy: 51.20 

Round   6, Train loss: 1.015, Test loss: 1.168, Test accuracy: 56.90 

        train local model (freeze embeding):client   0,  Train loss: 0.559, Train accuracy: 77.600, Test loss: 1.140, Test accuracy: 61.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.371, Train accuracy: 85.800, Test loss: 1.131, Test accuracy: 65.60 

        train local model (freeze embeding):client   1,  Train loss: 1.312, Train accuracy: 48.400, Test loss: 1.566, Test accuracy: 43.60 

        train local model (unfreeze embeding):client   1,  Train loss: 1.002, Train accuracy: 57.600, Test loss: 1.381, Test accuracy: 46.80 

Round   7, Train loss: 0.981, Test loss: 1.201, Test accuracy: 56.60 

        train local model (freeze embeding):client   0,  Train loss: 0.591, Train accuracy: 76.000, Test loss: 1.074, Test accuracy: 61.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.381, Train accuracy: 87.400, Test loss: 0.983, Test accuracy: 66.60 

        train local model (freeze embeding):client   1,  Train loss: 1.261, Train accuracy: 51.800, Test loss: 1.416, Test accuracy: 48.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.945, Train accuracy: 61.200, Test loss: 1.329, Test accuracy: 48.20 

Round   8, Train loss: 0.977, Test loss: 1.185, Test accuracy: 56.00 

        train local model (freeze embeding):client   0,  Train loss: 0.760, Train accuracy: 73.000, Test loss: 1.335, Test accuracy: 59.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.266, Train accuracy: 90.600, Test loss: 1.033, Test accuracy: 69.20 

        train local model (freeze embeding):client   1,  Train loss: 0.980, Train accuracy: 57.600, Test loss: 1.193, Test accuracy: 49.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.991, Train accuracy: 57.800, Test loss: 1.198, Test accuracy: 48.80 

Round   9, Train loss: 0.995, Test loss: 1.100, Test accuracy: 56.20 

        train local model (freeze embeding):client   0,  Train loss: 0.649, Train accuracy: 72.200, Test loss: 1.175, Test accuracy: 58.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.372, Train accuracy: 84.600, Test loss: 1.218, Test accuracy: 66.60 

        train local model (freeze embeding):client   1,  Train loss: 1.158, Train accuracy: 53.000, Test loss: 1.486, Test accuracy: 45.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.964, Train accuracy: 62.000, Test loss: 1.249, Test accuracy: 50.40 

Round  10, Train loss: 0.988, Test loss: 1.159, Test accuracy: 57.50 

        train local model (freeze embeding):client   0,  Train loss: 0.594, Train accuracy: 76.200, Test loss: 1.106, Test accuracy: 61.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.377, Train accuracy: 85.200, Test loss: 1.239, Test accuracy: 64.20 

        train local model (freeze embeding):client   1,  Train loss: 1.511, Train accuracy: 51.600, Test loss: 1.566, Test accuracy: 46.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.983, Train accuracy: 59.600, Test loss: 1.294, Test accuracy: 49.20 

Round  11, Train loss: 0.974, Test loss: 1.188, Test accuracy: 57.40 

        train local model (freeze embeding):client   0,  Train loss: 1.118, Train accuracy: 66.400, Test loss: 1.678, Test accuracy: 54.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.467, Train accuracy: 81.600, Test loss: 1.272, Test accuracy: 62.00 

        train local model (freeze embeding):client   1,  Train loss: 1.117, Train accuracy: 51.600, Test loss: 1.282, Test accuracy: 45.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.968, Train accuracy: 58.600, Test loss: 1.254, Test accuracy: 48.80 

Round  12, Train loss: 0.988, Test loss: 1.156, Test accuracy: 55.20 

        train local model (freeze embeding):client   0,  Train loss: 0.665, Train accuracy: 73.400, Test loss: 1.229, Test accuracy: 56.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.362, Train accuracy: 87.400, Test loss: 1.123, Test accuracy: 65.80 

        train local model (freeze embeding):client   1,  Train loss: 1.403, Train accuracy: 45.200, Test loss: 1.598, Test accuracy: 40.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.914, Train accuracy: 63.800, Test loss: 1.234, Test accuracy: 51.80 

Round  13, Train loss: 1.008, Test loss: 1.172, Test accuracy: 57.00 

        train local model (freeze embeding):client   0,  Train loss: 0.779, Train accuracy: 71.600, Test loss: 1.232, Test accuracy: 58.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.380, Train accuracy: 85.800, Test loss: 1.294, Test accuracy: 61.20 

        train local model (freeze embeding):client   1,  Train loss: 1.299, Train accuracy: 51.600, Test loss: 1.661, Test accuracy: 41.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.836, Train accuracy: 67.600, Test loss: 1.229, Test accuracy: 51.80 

Round  14, Train loss: 0.956, Test loss: 1.190, Test accuracy: 56.70 

        train local model (freeze embeding):client   0,  Train loss: 1.049, Train accuracy: 60.200, Test loss: 1.376, Test accuracy: 52.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.392, Train accuracy: 84.600, Test loss: 1.124, Test accuracy: 65.40 

        train local model (freeze embeding):client   1,  Train loss: 1.234, Train accuracy: 49.800, Test loss: 1.427, Test accuracy: 40.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.968, Train accuracy: 57.800, Test loss: 1.345, Test accuracy: 50.00 

Round  15, Train loss: 0.990, Test loss: 1.201, Test accuracy: 56.60 

        train local model (freeze embeding):client   0,  Train loss: 0.839, Train accuracy: 67.200, Test loss: 1.162, Test accuracy: 58.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.353, Train accuracy: 87.000, Test loss: 1.024, Test accuracy: 64.80 

        train local model (freeze embeding):client   1,  Train loss: 1.173, Train accuracy: 52.600, Test loss: 1.388, Test accuracy: 47.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.793, Train accuracy: 68.800, Test loss: 1.189, Test accuracy: 53.00 

Round  16, Train loss: 1.005, Test loss: 1.119, Test accuracy: 56.90 

        train local model (freeze embeding):client   0,  Train loss: 0.879, Train accuracy: 68.800, Test loss: 1.215, Test accuracy: 57.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.486, Train accuracy: 81.600, Test loss: 1.325, Test accuracy: 62.40 

        train local model (freeze embeding):client   1,  Train loss: 1.883, Train accuracy: 43.600, Test loss: 2.185, Test accuracy: 39.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.788, Train accuracy: 68.200, Test loss: 1.232, Test accuracy: 52.20 

Round  17, Train loss: 0.987, Test loss: 1.195, Test accuracy: 56.80 

        train local model (freeze embeding):client   0,  Train loss: 0.962, Train accuracy: 64.000, Test loss: 1.196, Test accuracy: 56.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.329, Train accuracy: 88.400, Test loss: 1.039, Test accuracy: 65.80 

        train local model (freeze embeding):client   1,  Train loss: 1.490, Train accuracy: 47.600, Test loss: 1.790, Test accuracy: 42.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.851, Train accuracy: 65.200, Test loss: 1.280, Test accuracy: 51.80 

Round  18, Train loss: 1.011, Test loss: 1.160, Test accuracy: 56.10 

        train local model (freeze embeding):client   0,  Train loss: 0.939, Train accuracy: 62.200, Test loss: 1.255, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.498, Train accuracy: 78.200, Test loss: 1.211, Test accuracy: 62.00 

        train local model (freeze embeding):client   1,  Train loss: 1.419, Train accuracy: 47.000, Test loss: 1.601, Test accuracy: 41.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.823, Train accuracy: 64.600, Test loss: 1.325, Test accuracy: 52.40 

Round  19, Train loss: 1.028, Test loss: 1.265, Test accuracy: 54.20 

        train local model (freeze embeding):client   0,  Train loss: 1.392, Train accuracy: 54.000, Test loss: 1.696, Test accuracy: 45.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.368, Train accuracy: 86.600, Test loss: 1.046, Test accuracy: 65.00 

        train local model (freeze embeding):client   1,  Train loss: 1.437, Train accuracy: 48.400, Test loss: 1.748, Test accuracy: 42.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.795, Train accuracy: 67.800, Test loss: 1.246, Test accuracy: 51.40 

Final Round, Train loss: 1.006, Test loss: 1.310, Test accuracy: 54.30 

---------------------------------------------train_client: [0, 1, 2] 

        init --> train local model(freeze embeding):client   2,  Train loss: 1.131, Train accuracy: 53.000, Test loss: 1.194, Test accuracy: 52.80 

        train local model (freeze embeding):client   0,  Train loss: 0.879, Train accuracy: 63.600, Test loss: 1.202, Test accuracy: 53.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.457, Train accuracy: 82.400, Test loss: 1.055, Test accuracy: 66.00 

        train local model (freeze embeding):client   1,  Train loss: 1.266, Train accuracy: 53.400, Test loss: 1.444, Test accuracy: 43.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.823, Train accuracy: 67.800, Test loss: 1.279, Test accuracy: 53.00 

        train local model (freeze embeding):client   2,  Train loss: 1.217, Train accuracy: 49.400, Test loss: 1.280, Test accuracy: 48.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.834, Train accuracy: 66.000, Test loss: 0.962, Test accuracy: 60.80 

Round   0, Train loss: 1.048, Test loss: 1.113, Test accuracy: 58.20 

        train local model (freeze embeding):client   0,  Train loss: 0.763, Train accuracy: 68.600, Test loss: 1.010, Test accuracy: 61.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.368, Train accuracy: 87.200, Test loss: 0.999, Test accuracy: 66.60 

        train local model (freeze embeding):client   1,  Train loss: 1.332, Train accuracy: 51.600, Test loss: 1.522, Test accuracy: 45.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.872, Train accuracy: 64.800, Test loss: 1.290, Test accuracy: 47.60 

        train local model (freeze embeding):client   2,  Train loss: 1.140, Train accuracy: 53.600, Test loss: 1.241, Test accuracy: 51.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.923, Train accuracy: 66.200, Test loss: 1.021, Test accuracy: 61.80 

Round   1, Train loss: 1.032, Test loss: 1.078, Test accuracy: 59.93 

        train local model (freeze embeding):client   0,  Train loss: 1.027, Train accuracy: 58.800, Test loss: 1.367, Test accuracy: 49.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.578, Train accuracy: 74.400, Test loss: 1.175, Test accuracy: 60.80 

        train local model (freeze embeding):client   1,  Train loss: 1.303, Train accuracy: 45.800, Test loss: 1.539, Test accuracy: 38.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.902, Train accuracy: 63.800, Test loss: 1.299, Test accuracy: 47.40 

        train local model (freeze embeding):client   2,  Train loss: 0.995, Train accuracy: 61.000, Test loss: 1.071, Test accuracy: 60.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.819, Train accuracy: 65.800, Test loss: 0.920, Test accuracy: 66.00 

Round   2, Train loss: 1.055, Test loss: 1.081, Test accuracy: 58.07 

        train local model (freeze embeding):client   0,  Train loss: 0.902, Train accuracy: 67.600, Test loss: 1.206, Test accuracy: 56.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.330, Train accuracy: 89.600, Test loss: 0.943, Test accuracy: 68.20 

        train local model (freeze embeding):client   1,  Train loss: 1.324, Train accuracy: 48.200, Test loss: 1.524, Test accuracy: 42.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.803, Train accuracy: 67.600, Test loss: 1.215, Test accuracy: 54.80 

        train local model (freeze embeding):client   2,  Train loss: 1.023, Train accuracy: 55.000, Test loss: 1.103, Test accuracy: 52.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.780, Train accuracy: 69.600, Test loss: 0.892, Test accuracy: 65.60 

Round   3, Train loss: 1.041, Test loss: 1.038, Test accuracy: 61.07 

        train local model (freeze embeding):client   0,  Train loss: 0.839, Train accuracy: 68.600, Test loss: 1.129, Test accuracy: 58.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.458, Train accuracy: 83.800, Test loss: 0.991, Test accuracy: 62.80 

        train local model (freeze embeding):client   1,  Train loss: 1.123, Train accuracy: 51.400, Test loss: 1.367, Test accuracy: 41.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.949, Train accuracy: 62.400, Test loss: 1.290, Test accuracy: 49.60 

        train local model (freeze embeding):client   2,  Train loss: 1.106, Train accuracy: 55.000, Test loss: 1.179, Test accuracy: 55.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.750, Train accuracy: 65.600, Test loss: 0.949, Test accuracy: 64.40 

Round   4, Train loss: 1.063, Test loss: 1.025, Test accuracy: 60.73 

        train local model (freeze embeding):client   0,  Train loss: 0.877, Train accuracy: 66.600, Test loss: 1.092, Test accuracy: 57.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.379, Train accuracy: 85.000, Test loss: 0.919, Test accuracy: 68.00 

        train local model (freeze embeding):client   1,  Train loss: 1.243, Train accuracy: 50.800, Test loss: 1.457, Test accuracy: 44.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.790, Train accuracy: 67.800, Test loss: 1.161, Test accuracy: 57.00 

        train local model (freeze embeding):client   2,  Train loss: 1.043, Train accuracy: 55.000, Test loss: 1.148, Test accuracy: 52.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.758, Train accuracy: 69.200, Test loss: 0.961, Test accuracy: 64.00 

Round   5, Train loss: 1.036, Test loss: 1.030, Test accuracy: 60.40 

        train local model (freeze embeding):client   0,  Train loss: 0.930, Train accuracy: 62.200, Test loss: 1.157, Test accuracy: 56.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.452, Train accuracy: 81.800, Test loss: 0.969, Test accuracy: 67.00 

        train local model (freeze embeding):client   1,  Train loss: 1.115, Train accuracy: 51.200, Test loss: 1.331, Test accuracy: 42.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.767, Train accuracy: 65.400, Test loss: 1.200, Test accuracy: 51.40 

        train local model (freeze embeding):client   2,  Train loss: 1.218, Train accuracy: 51.000, Test loss: 1.316, Test accuracy: 52.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.752, Train accuracy: 67.800, Test loss: 1.003, Test accuracy: 58.40 

Round   6, Train loss: 1.025, Test loss: 1.051, Test accuracy: 58.27 

        train local model (freeze embeding):client   0,  Train loss: 0.978, Train accuracy: 60.600, Test loss: 1.286, Test accuracy: 49.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.428, Train accuracy: 84.200, Test loss: 1.052, Test accuracy: 64.80 

        train local model (freeze embeding):client   1,  Train loss: 1.156, Train accuracy: 51.600, Test loss: 1.320, Test accuracy: 47.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.801, Train accuracy: 69.400, Test loss: 1.258, Test accuracy: 53.80 

        train local model (freeze embeding):client   2,  Train loss: 1.069, Train accuracy: 58.400, Test loss: 1.157, Test accuracy: 51.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.709, Train accuracy: 68.000, Test loss: 1.014, Test accuracy: 61.00 

Round   7, Train loss: 1.022, Test loss: 1.045, Test accuracy: 61.73 

        train local model (freeze embeding):client   0,  Train loss: 1.354, Train accuracy: 53.000, Test loss: 1.659, Test accuracy: 43.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.525, Train accuracy: 79.600, Test loss: 1.087, Test accuracy: 62.80 

        train local model (freeze embeding):client   1,  Train loss: 1.382, Train accuracy: 42.800, Test loss: 1.651, Test accuracy: 34.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.844, Train accuracy: 63.000, Test loss: 1.237, Test accuracy: 52.40 

        train local model (freeze embeding):client   2,  Train loss: 1.179, Train accuracy: 54.800, Test loss: 1.254, Test accuracy: 56.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.674, Train accuracy: 72.600, Test loss: 0.908, Test accuracy: 67.80 

Round   8, Train loss: 1.001, Test loss: 1.025, Test accuracy: 61.60 

        train local model (freeze embeding):client   0,  Train loss: 1.015, Train accuracy: 60.400, Test loss: 1.292, Test accuracy: 53.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.417, Train accuracy: 84.600, Test loss: 0.897, Test accuracy: 69.20 

        train local model (freeze embeding):client   1,  Train loss: 1.242, Train accuracy: 49.600, Test loss: 1.440, Test accuracy: 42.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.774, Train accuracy: 69.200, Test loss: 1.190, Test accuracy: 55.40 

        train local model (freeze embeding):client   2,  Train loss: 1.016, Train accuracy: 56.200, Test loss: 1.075, Test accuracy: 57.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.805, Train accuracy: 68.200, Test loss: 0.971, Test accuracy: 63.60 

Round   9, Train loss: 0.998, Test loss: 1.052, Test accuracy: 60.33 

        train local model (freeze embeding):client   0,  Train loss: 1.288, Train accuracy: 57.800, Test loss: 1.418, Test accuracy: 53.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.498, Train accuracy: 82.400, Test loss: 1.066, Test accuracy: 66.60 

        train local model (freeze embeding):client   1,  Train loss: 1.125, Train accuracy: 53.200, Test loss: 1.317, Test accuracy: 47.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.815, Train accuracy: 67.400, Test loss: 1.223, Test accuracy: 53.40 

        train local model (freeze embeding):client   2,  Train loss: 1.139, Train accuracy: 55.000, Test loss: 1.215, Test accuracy: 52.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.663, Train accuracy: 72.000, Test loss: 0.935, Test accuracy: 67.80 

Round  10, Train loss: 0.989, Test loss: 1.007, Test accuracy: 62.67 

        train local model (freeze embeding):client   0,  Train loss: 0.989, Train accuracy: 63.200, Test loss: 1.265, Test accuracy: 54.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.396, Train accuracy: 86.200, Test loss: 0.871, Test accuracy: 70.20 

        train local model (freeze embeding):client   1,  Train loss: 1.237, Train accuracy: 50.400, Test loss: 1.503, Test accuracy: 42.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.767, Train accuracy: 68.800, Test loss: 1.186, Test accuracy: 53.20 

        train local model (freeze embeding):client   2,  Train loss: 1.306, Train accuracy: 51.000, Test loss: 1.366, Test accuracy: 48.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.743, Train accuracy: 70.000, Test loss: 0.972, Test accuracy: 65.80 

Round  11, Train loss: 0.977, Test loss: 1.010, Test accuracy: 62.27 

        train local model (freeze embeding):client   0,  Train loss: 0.973, Train accuracy: 64.400, Test loss: 1.248, Test accuracy: 54.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.472, Train accuracy: 82.400, Test loss: 0.920, Test accuracy: 68.20 

        train local model (freeze embeding):client   1,  Train loss: 1.193, Train accuracy: 48.400, Test loss: 1.431, Test accuracy: 40.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.752, Train accuracy: 71.200, Test loss: 1.174, Test accuracy: 55.60 

        train local model (freeze embeding):client   2,  Train loss: 1.005, Train accuracy: 59.600, Test loss: 1.062, Test accuracy: 57.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.659, Train accuracy: 72.800, Test loss: 1.005, Test accuracy: 63.80 

Round  12, Train loss: 0.980, Test loss: 0.985, Test accuracy: 62.67 

        train local model (freeze embeding):client   0,  Train loss: 1.010, Train accuracy: 62.600, Test loss: 1.284, Test accuracy: 51.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.471, Train accuracy: 82.800, Test loss: 0.938, Test accuracy: 67.20 

        train local model (freeze embeding):client   1,  Train loss: 1.246, Train accuracy: 50.200, Test loss: 1.480, Test accuracy: 40.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.769, Train accuracy: 69.800, Test loss: 1.250, Test accuracy: 54.20 

        train local model (freeze embeding):client   2,  Train loss: 1.052, Train accuracy: 57.800, Test loss: 1.180, Test accuracy: 53.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.691, Train accuracy: 73.400, Test loss: 0.936, Test accuracy: 67.00 

Round  13, Train loss: 0.986, Test loss: 1.008, Test accuracy: 63.07 

        train local model (freeze embeding):client   0,  Train loss: 0.988, Train accuracy: 63.200, Test loss: 1.224, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.512, Train accuracy: 80.600, Test loss: 0.994, Test accuracy: 67.20 

        train local model (freeze embeding):client   1,  Train loss: 1.180, Train accuracy: 54.400, Test loss: 1.395, Test accuracy: 46.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.781, Train accuracy: 69.600, Test loss: 1.216, Test accuracy: 54.20 

        train local model (freeze embeding):client   2,  Train loss: 0.959, Train accuracy: 60.800, Test loss: 1.016, Test accuracy: 59.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.647, Train accuracy: 73.200, Test loss: 0.930, Test accuracy: 66.40 

Round  14, Train loss: 0.978, Test loss: 1.010, Test accuracy: 61.73 

        train local model (freeze embeding):client   0,  Train loss: 0.870, Train accuracy: 65.400, Test loss: 1.117, Test accuracy: 54.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.564, Train accuracy: 76.800, Test loss: 1.010, Test accuracy: 65.40 

        train local model (freeze embeding):client   1,  Train loss: 1.172, Train accuracy: 52.200, Test loss: 1.352, Test accuracy: 46.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.753, Train accuracy: 71.800, Test loss: 1.210, Test accuracy: 53.80 

        train local model (freeze embeding):client   2,  Train loss: 0.999, Train accuracy: 57.000, Test loss: 1.091, Test accuracy: 55.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.686, Train accuracy: 74.400, Test loss: 0.990, Test accuracy: 64.80 

Round  15, Train loss: 0.953, Test loss: 1.024, Test accuracy: 61.73 

        train local model (freeze embeding):client   0,  Train loss: 0.972, Train accuracy: 62.200, Test loss: 1.193, Test accuracy: 50.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.534, Train accuracy: 78.200, Test loss: 1.026, Test accuracy: 63.60 

        train local model (freeze embeding):client   1,  Train loss: 1.127, Train accuracy: 49.400, Test loss: 1.322, Test accuracy: 44.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.753, Train accuracy: 71.600, Test loss: 1.190, Test accuracy: 54.40 

        train local model (freeze embeding):client   2,  Train loss: 0.970, Train accuracy: 59.000, Test loss: 1.046, Test accuracy: 58.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.675, Train accuracy: 73.000, Test loss: 0.971, Test accuracy: 66.40 

Round  16, Train loss: 0.956, Test loss: 1.026, Test accuracy: 61.40 

        train local model (freeze embeding):client   0,  Train loss: 0.960, Train accuracy: 59.000, Test loss: 1.220, Test accuracy: 50.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.533, Train accuracy: 81.200, Test loss: 1.008, Test accuracy: 64.20 

        train local model (freeze embeding):client   1,  Train loss: 1.090, Train accuracy: 52.400, Test loss: 1.316, Test accuracy: 45.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.845, Train accuracy: 65.200, Test loss: 1.322, Test accuracy: 52.40 

        train local model (freeze embeding):client   2,  Train loss: 1.049, Train accuracy: 56.200, Test loss: 1.160, Test accuracy: 50.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.663, Train accuracy: 74.200, Test loss: 0.956, Test accuracy: 64.80 

Round  17, Train loss: 0.986, Test loss: 1.018, Test accuracy: 62.27 

        train local model (freeze embeding):client   0,  Train loss: 0.849, Train accuracy: 68.400, Test loss: 1.074, Test accuracy: 60.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.487, Train accuracy: 81.000, Test loss: 1.017, Test accuracy: 62.40 

        train local model (freeze embeding):client   1,  Train loss: 1.299, Train accuracy: 48.400, Test loss: 1.586, Test accuracy: 38.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.752, Train accuracy: 72.000, Test loss: 1.240, Test accuracy: 53.00 

        train local model (freeze embeding):client   2,  Train loss: 0.932, Train accuracy: 61.800, Test loss: 1.072, Test accuracy: 55.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.624, Train accuracy: 75.600, Test loss: 0.984, Test accuracy: 65.80 

Round  18, Train loss: 0.963, Test loss: 1.032, Test accuracy: 62.20 

        train local model (freeze embeding):client   0,  Train loss: 0.843, Train accuracy: 66.200, Test loss: 1.057, Test accuracy: 60.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.392, Train accuracy: 84.400, Test loss: 0.909, Test accuracy: 67.60 

        train local model (freeze embeding):client   1,  Train loss: 1.086, Train accuracy: 53.600, Test loss: 1.299, Test accuracy: 44.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.701, Train accuracy: 72.600, Test loss: 1.237, Test accuracy: 53.80 

        train local model (freeze embeding):client   2,  Train loss: 0.961, Train accuracy: 60.200, Test loss: 1.066, Test accuracy: 59.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.715, Train accuracy: 68.800, Test loss: 1.063, Test accuracy: 59.20 

Round  19, Train loss: 0.926, Test loss: 1.049, Test accuracy: 60.67 

        train local model (freeze embeding):client   0,  Train loss: 0.790, Train accuracy: 70.600, Test loss: 1.009, Test accuracy: 60.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.554, Train accuracy: 77.200, Test loss: 1.084, Test accuracy: 62.80 

        train local model (freeze embeding):client   1,  Train loss: 1.206, Train accuracy: 52.400, Test loss: 1.410, Test accuracy: 43.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.705, Train accuracy: 72.200, Test loss: 1.227, Test accuracy: 54.20 

        train local model (freeze embeding):client   2,  Train loss: 1.062, Train accuracy: 58.400, Test loss: 1.163, Test accuracy: 56.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.651, Train accuracy: 72.600, Test loss: 0.968, Test accuracy: 65.40 

Final Round, Train loss: 0.933, Test loss: 1.063, Test accuracy: 61.13 

---------------------------------------------train_client: [0, 1, 2, 3] 

        init --> train local model(freeze embeding):client   3,  Train loss: 1.380, Train accuracy: 47.800, Test loss: 1.483, Test accuracy: 44.80 

        train local model (freeze embeding):client   0,  Train loss: 0.844, Train accuracy: 67.200, Test loss: 1.034, Test accuracy: 60.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.393, Train accuracy: 85.800, Test loss: 0.903, Test accuracy: 66.80 

        train local model (freeze embeding):client   1,  Train loss: 1.101, Train accuracy: 54.800, Test loss: 1.336, Test accuracy: 43.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.824, Train accuracy: 67.200, Test loss: 1.231, Test accuracy: 51.20 

        train local model (freeze embeding):client   2,  Train loss: 0.937, Train accuracy: 59.800, Test loss: 1.092, Test accuracy: 54.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.615, Train accuracy: 74.000, Test loss: 0.920, Test accuracy: 67.60 

        train local model (freeze embeding):client   3,  Train loss: 1.280, Train accuracy: 49.000, Test loss: 1.375, Test accuracy: 46.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.974, Train accuracy: 62.000, Test loss: 1.176, Test accuracy: 55.20 

Round   0, Train loss: 1.006, Test loss: 1.018, Test accuracy: 60.80 

        train local model (freeze embeding):client   0,  Train loss: 0.971, Train accuracy: 60.600, Test loss: 1.205, Test accuracy: 54.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.588, Train accuracy: 77.800, Test loss: 1.095, Test accuracy: 60.80 

        train local model (freeze embeding):client   1,  Train loss: 1.180, Train accuracy: 51.800, Test loss: 1.447, Test accuracy: 43.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.783, Train accuracy: 67.600, Test loss: 1.345, Test accuracy: 49.80 

        train local model (freeze embeding):client   2,  Train loss: 0.970, Train accuracy: 61.400, Test loss: 1.099, Test accuracy: 54.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.661, Train accuracy: 72.200, Test loss: 1.063, Test accuracy: 61.20 

        train local model (freeze embeding):client   3,  Train loss: 1.191, Train accuracy: 51.000, Test loss: 1.299, Test accuracy: 47.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.935, Train accuracy: 61.600, Test loss: 1.124, Test accuracy: 55.20 

Round   1, Train loss: 0.994, Test loss: 1.048, Test accuracy: 60.15 

        train local model (freeze embeding):client   0,  Train loss: 0.859, Train accuracy: 64.400, Test loss: 1.094, Test accuracy: 54.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.522, Train accuracy: 81.000, Test loss: 0.998, Test accuracy: 63.80 

        train local model (freeze embeding):client   1,  Train loss: 1.037, Train accuracy: 57.600, Test loss: 1.287, Test accuracy: 48.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.742, Train accuracy: 71.000, Test loss: 1.191, Test accuracy: 56.00 

        train local model (freeze embeding):client   2,  Train loss: 0.968, Train accuracy: 57.800, Test loss: 1.042, Test accuracy: 60.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.586, Train accuracy: 76.600, Test loss: 0.907, Test accuracy: 69.60 

        train local model (freeze embeding):client   3,  Train loss: 1.287, Train accuracy: 48.000, Test loss: 1.406, Test accuracy: 46.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.950, Train accuracy: 58.800, Test loss: 1.214, Test accuracy: 52.80 

Round   2, Train loss: 0.995, Test loss: 1.020, Test accuracy: 61.55 

        train local model (freeze embeding):client   0,  Train loss: 0.849, Train accuracy: 68.400, Test loss: 1.071, Test accuracy: 57.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.512, Train accuracy: 80.600, Test loss: 0.988, Test accuracy: 65.00 

        train local model (freeze embeding):client   1,  Train loss: 1.110, Train accuracy: 55.600, Test loss: 1.369, Test accuracy: 47.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.725, Train accuracy: 71.800, Test loss: 1.210, Test accuracy: 56.20 

        train local model (freeze embeding):client   2,  Train loss: 1.018, Train accuracy: 55.600, Test loss: 1.116, Test accuracy: 52.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.683, Train accuracy: 73.000, Test loss: 0.986, Test accuracy: 65.60 

        train local model (freeze embeding):client   3,  Train loss: 1.212, Train accuracy: 50.400, Test loss: 1.310, Test accuracy: 45.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.893, Train accuracy: 64.000, Test loss: 1.138, Test accuracy: 53.20 

Round   3, Train loss: 0.983, Test loss: 1.031, Test accuracy: 60.80 

        train local model (freeze embeding):client   0,  Train loss: 0.806, Train accuracy: 67.800, Test loss: 1.047, Test accuracy: 58.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.488, Train accuracy: 84.200, Test loss: 0.968, Test accuracy: 67.20 

        train local model (freeze embeding):client   1,  Train loss: 1.227, Train accuracy: 50.000, Test loss: 1.511, Test accuracy: 41.00 

        train local model (unfreeze embeding):client   1,  Train loss: 1.007, Train accuracy: 57.600, Test loss: 1.329, Test accuracy: 48.60 

        train local model (freeze embeding):client   2,  Train loss: 1.026, Train accuracy: 59.800, Test loss: 1.119, Test accuracy: 56.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.629, Train accuracy: 73.800, Test loss: 0.969, Test accuracy: 65.40 

        train local model (freeze embeding):client   3,  Train loss: 1.173, Train accuracy: 46.200, Test loss: 1.284, Test accuracy: 44.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.894, Train accuracy: 63.800, Test loss: 1.145, Test accuracy: 53.20 

Round   4, Train loss: 0.979, Test loss: 1.021, Test accuracy: 60.45 

        train local model (freeze embeding):client   0,  Train loss: 1.222, Train accuracy: 52.200, Test loss: 1.491, Test accuracy: 42.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.598, Train accuracy: 76.400, Test loss: 1.046, Test accuracy: 62.80 

        train local model (freeze embeding):client   1,  Train loss: 1.146, Train accuracy: 51.800, Test loss: 1.428, Test accuracy: 40.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.737, Train accuracy: 72.400, Test loss: 1.201, Test accuracy: 54.40 

        train local model (freeze embeding):client   2,  Train loss: 1.040, Train accuracy: 55.200, Test loss: 1.117, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.641, Train accuracy: 76.400, Test loss: 0.971, Test accuracy: 63.80 

        train local model (freeze embeding):client   3,  Train loss: 1.231, Train accuracy: 50.400, Test loss: 1.357, Test accuracy: 47.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.908, Train accuracy: 61.600, Test loss: 1.188, Test accuracy: 53.60 

Round   5, Train loss: 0.978, Test loss: 1.014, Test accuracy: 61.65 

        train local model (freeze embeding):client   0,  Train loss: 0.821, Train accuracy: 70.000, Test loss: 1.020, Test accuracy: 59.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.519, Train accuracy: 81.400, Test loss: 1.047, Test accuracy: 62.60 

        train local model (freeze embeding):client   1,  Train loss: 1.143, Train accuracy: 55.200, Test loss: 1.373, Test accuracy: 46.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.694, Train accuracy: 74.400, Test loss: 1.161, Test accuracy: 53.20 

        train local model (freeze embeding):client   2,  Train loss: 1.158, Train accuracy: 52.000, Test loss: 1.224, Test accuracy: 51.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.612, Train accuracy: 74.000, Test loss: 0.948, Test accuracy: 68.00 

        train local model (freeze embeding):client   3,  Train loss: 1.149, Train accuracy: 48.600, Test loss: 1.298, Test accuracy: 42.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.836, Train accuracy: 66.600, Test loss: 1.128, Test accuracy: 54.80 

Round   6, Train loss: 0.974, Test loss: 1.043, Test accuracy: 60.70 

        train local model (freeze embeding):client   0,  Train loss: 0.800, Train accuracy: 67.800, Test loss: 1.027, Test accuracy: 58.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.386, Train accuracy: 86.000, Test loss: 0.969, Test accuracy: 69.20 

        train local model (freeze embeding):client   1,  Train loss: 1.192, Train accuracy: 56.200, Test loss: 1.456, Test accuracy: 44.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.947, Train accuracy: 61.600, Test loss: 1.396, Test accuracy: 50.40 

        train local model (freeze embeding):client   2,  Train loss: 0.890, Train accuracy: 61.200, Test loss: 1.004, Test accuracy: 60.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.568, Train accuracy: 77.400, Test loss: 0.913, Test accuracy: 67.60 

        train local model (freeze embeding):client   3,  Train loss: 1.078, Train accuracy: 53.200, Test loss: 1.252, Test accuracy: 49.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.833, Train accuracy: 67.200, Test loss: 1.163, Test accuracy: 56.20 

Round   7, Train loss: 0.959, Test loss: 1.042, Test accuracy: 60.85 

        train local model (freeze embeding):client   0,  Train loss: 0.855, Train accuracy: 66.200, Test loss: 1.055, Test accuracy: 60.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.457, Train accuracy: 81.600, Test loss: 0.948, Test accuracy: 66.60 

        train local model (freeze embeding):client   1,  Train loss: 1.005, Train accuracy: 59.800, Test loss: 1.230, Test accuracy: 47.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.754, Train accuracy: 69.800, Test loss: 1.177, Test accuracy: 53.80 

        train local model (freeze embeding):client   2,  Train loss: 0.956, Train accuracy: 62.000, Test loss: 1.072, Test accuracy: 57.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.685, Train accuracy: 72.400, Test loss: 1.020, Test accuracy: 64.20 

        train local model (freeze embeding):client   3,  Train loss: 1.031, Train accuracy: 53.600, Test loss: 1.223, Test accuracy: 46.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.891, Train accuracy: 64.400, Test loss: 1.283, Test accuracy: 53.80 

Round   8, Train loss: 0.957, Test loss: 1.055, Test accuracy: 60.60 

        train local model (freeze embeding):client   0,  Train loss: 0.848, Train accuracy: 65.200, Test loss: 1.074, Test accuracy: 60.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.399, Train accuracy: 86.200, Test loss: 0.929, Test accuracy: 65.00 

        train local model (freeze embeding):client   1,  Train loss: 1.129, Train accuracy: 51.200, Test loss: 1.377, Test accuracy: 45.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.664, Train accuracy: 74.400, Test loss: 1.177, Test accuracy: 53.80 

        train local model (freeze embeding):client   2,  Train loss: 0.962, Train accuracy: 60.400, Test loss: 1.056, Test accuracy: 58.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.593, Train accuracy: 75.600, Test loss: 0.925, Test accuracy: 67.40 

        train local model (freeze embeding):client   3,  Train loss: 1.004, Train accuracy: 57.600, Test loss: 1.198, Test accuracy: 51.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.895, Train accuracy: 65.400, Test loss: 1.192, Test accuracy: 53.60 

Round   9, Train loss: 0.952, Test loss: 1.029, Test accuracy: 60.20 

        train local model (freeze embeding):client   0,  Train loss: 0.950, Train accuracy: 63.200, Test loss: 1.174, Test accuracy: 56.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.530, Train accuracy: 79.400, Test loss: 1.043, Test accuracy: 63.40 

        train local model (freeze embeding):client   1,  Train loss: 1.068, Train accuracy: 53.800, Test loss: 1.299, Test accuracy: 46.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.767, Train accuracy: 65.800, Test loss: 1.314, Test accuracy: 54.00 

        train local model (freeze embeding):client   2,  Train loss: 0.948, Train accuracy: 60.800, Test loss: 1.040, Test accuracy: 58.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.645, Train accuracy: 72.800, Test loss: 0.961, Test accuracy: 67.80 

        train local model (freeze embeding):client   3,  Train loss: 1.048, Train accuracy: 56.000, Test loss: 1.238, Test accuracy: 48.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.827, Train accuracy: 66.800, Test loss: 1.192, Test accuracy: 53.20 

Round  10, Train loss: 0.946, Test loss: 1.082, Test accuracy: 59.20 

        train local model (freeze embeding):client   0,  Train loss: 1.008, Train accuracy: 60.000, Test loss: 1.259, Test accuracy: 49.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.446, Train accuracy: 83.600, Test loss: 0.932, Test accuracy: 66.40 

        train local model (freeze embeding):client   1,  Train loss: 1.065, Train accuracy: 53.400, Test loss: 1.311, Test accuracy: 47.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.748, Train accuracy: 70.400, Test loss: 1.282, Test accuracy: 53.80 

        train local model (freeze embeding):client   2,  Train loss: 1.011, Train accuracy: 56.400, Test loss: 1.099, Test accuracy: 55.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.644, Train accuracy: 74.600, Test loss: 1.005, Test accuracy: 61.80 

        train local model (freeze embeding):client   3,  Train loss: 1.122, Train accuracy: 50.600, Test loss: 1.292, Test accuracy: 45.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.824, Train accuracy: 67.000, Test loss: 1.239, Test accuracy: 53.40 

Round  11, Train loss: 0.954, Test loss: 1.068, Test accuracy: 59.50 

        train local model (freeze embeding):client   0,  Train loss: 0.828, Train accuracy: 66.200, Test loss: 1.115, Test accuracy: 51.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.451, Train accuracy: 84.400, Test loss: 0.984, Test accuracy: 66.00 

        train local model (freeze embeding):client   1,  Train loss: 1.101, Train accuracy: 54.600, Test loss: 1.379, Test accuracy: 46.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.847, Train accuracy: 64.400, Test loss: 1.321, Test accuracy: 53.40 

        train local model (freeze embeding):client   2,  Train loss: 1.088, Train accuracy: 52.000, Test loss: 1.204, Test accuracy: 50.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.605, Train accuracy: 78.400, Test loss: 0.961, Test accuracy: 62.00 

        train local model (freeze embeding):client   3,  Train loss: 1.167, Train accuracy: 52.400, Test loss: 1.346, Test accuracy: 44.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.769, Train accuracy: 68.800, Test loss: 1.149, Test accuracy: 54.00 

Round  12, Train loss: 0.945, Test loss: 1.072, Test accuracy: 60.15 

        train local model (freeze embeding):client   0,  Train loss: 1.025, Train accuracy: 61.800, Test loss: 1.243, Test accuracy: 55.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.483, Train accuracy: 81.800, Test loss: 0.971, Test accuracy: 64.20 

        train local model (freeze embeding):client   1,  Train loss: 1.045, Train accuracy: 56.400, Test loss: 1.277, Test accuracy: 46.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.741, Train accuracy: 70.000, Test loss: 1.285, Test accuracy: 52.40 

        train local model (freeze embeding):client   2,  Train loss: 1.003, Train accuracy: 58.600, Test loss: 1.117, Test accuracy: 55.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.641, Train accuracy: 73.200, Test loss: 0.958, Test accuracy: 62.80 

        train local model (freeze embeding):client   3,  Train loss: 1.085, Train accuracy: 53.400, Test loss: 1.305, Test accuracy: 47.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.791, Train accuracy: 68.600, Test loss: 1.189, Test accuracy: 53.40 

Round  13, Train loss: 0.944, Test loss: 1.052, Test accuracy: 59.95 

        train local model (freeze embeding):client   0,  Train loss: 0.857, Train accuracy: 65.600, Test loss: 1.067, Test accuracy: 58.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.467, Train accuracy: 83.400, Test loss: 0.931, Test accuracy: 66.00 

        train local model (freeze embeding):client   1,  Train loss: 1.178, Train accuracy: 54.400, Test loss: 1.421, Test accuracy: 45.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.765, Train accuracy: 69.600, Test loss: 1.247, Test accuracy: 53.00 

        train local model (freeze embeding):client   2,  Train loss: 0.900, Train accuracy: 61.200, Test loss: 1.020, Test accuracy: 58.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.666, Train accuracy: 72.600, Test loss: 0.987, Test accuracy: 61.60 

        train local model (freeze embeding):client   3,  Train loss: 1.132, Train accuracy: 51.400, Test loss: 1.345, Test accuracy: 43.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.761, Train accuracy: 71.000, Test loss: 1.173, Test accuracy: 55.60 

Round  14, Train loss: 0.939, Test loss: 1.048, Test accuracy: 60.65 

        train local model (freeze embeding):client   0,  Train loss: 0.960, Train accuracy: 59.600, Test loss: 1.220, Test accuracy: 51.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.437, Train accuracy: 82.600, Test loss: 0.985, Test accuracy: 66.00 

        train local model (freeze embeding):client   1,  Train loss: 1.084, Train accuracy: 53.000, Test loss: 1.271, Test accuracy: 48.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.785, Train accuracy: 68.400, Test loss: 1.237, Test accuracy: 53.80 

        train local model (freeze embeding):client   2,  Train loss: 1.116, Train accuracy: 56.200, Test loss: 1.192, Test accuracy: 57.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.622, Train accuracy: 74.600, Test loss: 0.948, Test accuracy: 69.20 

        train local model (freeze embeding):client   3,  Train loss: 1.099, Train accuracy: 54.800, Test loss: 1.332, Test accuracy: 45.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.867, Train accuracy: 64.200, Test loss: 1.262, Test accuracy: 50.20 

Round  15, Train loss: 0.942, Test loss: 1.013, Test accuracy: 61.80 

        train local model (freeze embeding):client   0,  Train loss: 0.829, Train accuracy: 67.800, Test loss: 1.057, Test accuracy: 59.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.443, Train accuracy: 82.600, Test loss: 0.948, Test accuracy: 67.00 

        train local model (freeze embeding):client   1,  Train loss: 1.045, Train accuracy: 56.600, Test loss: 1.280, Test accuracy: 47.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.691, Train accuracy: 73.000, Test loss: 1.156, Test accuracy: 56.20 

        train local model (freeze embeding):client   2,  Train loss: 0.991, Train accuracy: 59.000, Test loss: 1.085, Test accuracy: 59.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.658, Train accuracy: 73.200, Test loss: 1.014, Test accuracy: 66.00 

        train local model (freeze embeding):client   3,  Train loss: 1.015, Train accuracy: 55.000, Test loss: 1.247, Test accuracy: 47.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.802, Train accuracy: 67.400, Test loss: 1.233, Test accuracy: 52.20 

Round  16, Train loss: 0.931, Test loss: 1.028, Test accuracy: 60.85 

        train local model (freeze embeding):client   0,  Train loss: 0.936, Train accuracy: 61.400, Test loss: 1.178, Test accuracy: 50.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.410, Train accuracy: 84.800, Test loss: 0.940, Test accuracy: 66.20 

        train local model (freeze embeding):client   1,  Train loss: 1.205, Train accuracy: 50.600, Test loss: 1.476, Test accuracy: 43.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.972, Train accuracy: 60.200, Test loss: 1.380, Test accuracy: 44.40 

        train local model (freeze embeding):client   2,  Train loss: 0.887, Train accuracy: 63.400, Test loss: 1.018, Test accuracy: 60.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.575, Train accuracy: 76.000, Test loss: 0.959, Test accuracy: 66.00 

        train local model (freeze embeding):client   3,  Train loss: 1.072, Train accuracy: 51.800, Test loss: 1.296, Test accuracy: 44.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.706, Train accuracy: 75.000, Test loss: 1.170, Test accuracy: 54.60 

Round  17, Train loss: 0.941, Test loss: 1.105, Test accuracy: 57.85 

        train local model (freeze embeding):client   0,  Train loss: 1.266, Train accuracy: 53.600, Test loss: 1.471, Test accuracy: 45.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.481, Train accuracy: 82.200, Test loss: 0.983, Test accuracy: 66.00 

        train local model (freeze embeding):client   1,  Train loss: 1.146, Train accuracy: 49.400, Test loss: 1.358, Test accuracy: 43.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.821, Train accuracy: 66.400, Test loss: 1.368, Test accuracy: 53.00 

        train local model (freeze embeding):client   2,  Train loss: 0.935, Train accuracy: 62.800, Test loss: 1.060, Test accuracy: 59.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.570, Train accuracy: 77.400, Test loss: 0.910, Test accuracy: 68.40 

        train local model (freeze embeding):client   3,  Train loss: 1.054, Train accuracy: 56.200, Test loss: 1.275, Test accuracy: 46.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.752, Train accuracy: 69.800, Test loss: 1.187, Test accuracy: 52.40 

Round  18, Train loss: 0.923, Test loss: 1.076, Test accuracy: 60.05 

        train local model (freeze embeding):client   0,  Train loss: 0.867, Train accuracy: 64.200, Test loss: 1.059, Test accuracy: 59.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.533, Train accuracy: 79.600, Test loss: 0.985, Test accuracy: 64.00 

        train local model (freeze embeding):client   1,  Train loss: 1.154, Train accuracy: 51.400, Test loss: 1.405, Test accuracy: 41.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.785, Train accuracy: 69.200, Test loss: 1.227, Test accuracy: 53.80 

        train local model (freeze embeding):client   2,  Train loss: 0.935, Train accuracy: 61.600, Test loss: 1.055, Test accuracy: 57.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.609, Train accuracy: 74.600, Test loss: 0.958, Test accuracy: 66.80 

        train local model (freeze embeding):client   3,  Train loss: 0.982, Train accuracy: 58.600, Test loss: 1.194, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.837, Train accuracy: 67.200, Test loss: 1.237, Test accuracy: 52.00 

Round  19, Train loss: 0.932, Test loss: 1.055, Test accuracy: 59.80 

        train local model (freeze embeding):client   0,  Train loss: 0.954, Train accuracy: 62.200, Test loss: 1.194, Test accuracy: 50.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.448, Train accuracy: 83.000, Test loss: 0.959, Test accuracy: 64.40 

        train local model (freeze embeding):client   1,  Train loss: 1.153, Train accuracy: 50.800, Test loss: 1.409, Test accuracy: 44.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.785, Train accuracy: 71.200, Test loss: 1.242, Test accuracy: 51.20 

        train local model (freeze embeding):client   2,  Train loss: 0.984, Train accuracy: 60.600, Test loss: 1.102, Test accuracy: 57.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.582, Train accuracy: 79.200, Test loss: 0.982, Test accuracy: 65.80 

        train local model (freeze embeding):client   3,  Train loss: 0.973, Train accuracy: 59.200, Test loss: 1.200, Test accuracy: 51.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.754, Train accuracy: 69.800, Test loss: 1.199, Test accuracy: 56.60 

Final Round, Train loss: 0.923, Test loss: 1.036, Test accuracy: 60.30 

---------------------------------------------train_client: [0, 1, 2, 3, 4] 

        init --> train local model(freeze embeding):client   4,  Train loss: 1.126, Train accuracy: 54.400, Test loss: 1.196, Test accuracy: 49.40 

        train local model (freeze embeding):client   0,  Train loss: 0.907, Train accuracy: 64.000, Test loss: 1.122, Test accuracy: 51.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.574, Train accuracy: 76.200, Test loss: 1.134, Test accuracy: 62.20 

        train local model (freeze embeding):client   1,  Train loss: 0.993, Train accuracy: 56.800, Test loss: 1.212, Test accuracy: 48.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.752, Train accuracy: 71.200, Test loss: 1.295, Test accuracy: 50.40 

        train local model (freeze embeding):client   2,  Train loss: 0.914, Train accuracy: 62.600, Test loss: 1.008, Test accuracy: 61.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.683, Train accuracy: 72.200, Test loss: 1.061, Test accuracy: 62.00 

        train local model (freeze embeding):client   3,  Train loss: 1.020, Train accuracy: 58.800, Test loss: 1.265, Test accuracy: 46.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.769, Train accuracy: 69.600, Test loss: 1.232, Test accuracy: 55.60 

        train local model (freeze embeding):client   4,  Train loss: 1.064, Train accuracy: 55.000, Test loss: 1.131, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.860, Train accuracy: 66.800, Test loss: 0.996, Test accuracy: 60.80 

Round   0, Train loss: 0.947, Test loss: 1.021, Test accuracy: 60.68 

        train local model (freeze embeding):client   0,  Train loss: 0.818, Train accuracy: 66.800, Test loss: 1.033, Test accuracy: 60.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.465, Train accuracy: 83.200, Test loss: 0.973, Test accuracy: 67.60 

        train local model (freeze embeding):client   1,  Train loss: 1.012, Train accuracy: 54.400, Test loss: 1.264, Test accuracy: 45.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.768, Train accuracy: 70.200, Test loss: 1.225, Test accuracy: 54.40 

        train local model (freeze embeding):client   2,  Train loss: 0.923, Train accuracy: 62.800, Test loss: 1.026, Test accuracy: 60.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.640, Train accuracy: 73.000, Test loss: 0.987, Test accuracy: 65.00 

        train local model (freeze embeding):client   3,  Train loss: 1.042, Train accuracy: 56.400, Test loss: 1.290, Test accuracy: 45.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.835, Train accuracy: 68.800, Test loss: 1.298, Test accuracy: 50.60 

        train local model (freeze embeding):client   4,  Train loss: 1.011, Train accuracy: 59.000, Test loss: 1.091, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.767, Train accuracy: 70.200, Test loss: 0.951, Test accuracy: 60.40 

Round   1, Train loss: 0.943, Test loss: 1.048, Test accuracy: 59.88 

        train local model (freeze embeding):client   0,  Train loss: 0.805, Train accuracy: 67.000, Test loss: 1.040, Test accuracy: 60.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.569, Train accuracy: 78.400, Test loss: 1.096, Test accuracy: 61.40 

        train local model (freeze embeding):client   1,  Train loss: 0.936, Train accuracy: 62.600, Test loss: 1.213, Test accuracy: 48.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.762, Train accuracy: 69.600, Test loss: 1.257, Test accuracy: 52.40 

        train local model (freeze embeding):client   2,  Train loss: 0.901, Train accuracy: 63.200, Test loss: 1.034, Test accuracy: 58.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.611, Train accuracy: 74.000, Test loss: 1.025, Test accuracy: 63.20 

        train local model (freeze embeding):client   3,  Train loss: 0.936, Train accuracy: 60.200, Test loss: 1.180, Test accuracy: 51.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.903, Train accuracy: 62.400, Test loss: 1.321, Test accuracy: 50.40 

        train local model (freeze embeding):client   4,  Train loss: 0.992, Train accuracy: 58.000, Test loss: 1.115, Test accuracy: 51.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.794, Train accuracy: 68.800, Test loss: 0.945, Test accuracy: 61.80 

Round   2, Train loss: 0.924, Test loss: 1.019, Test accuracy: 60.04 

        train local model (freeze embeding):client   0,  Train loss: 0.822, Train accuracy: 67.600, Test loss: 1.052, Test accuracy: 59.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.466, Train accuracy: 82.200, Test loss: 1.009, Test accuracy: 65.20 

        train local model (freeze embeding):client   1,  Train loss: 1.019, Train accuracy: 56.800, Test loss: 1.235, Test accuracy: 48.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.859, Train accuracy: 64.600, Test loss: 1.308, Test accuracy: 52.20 

        train local model (freeze embeding):client   2,  Train loss: 0.899, Train accuracy: 62.600, Test loss: 1.032, Test accuracy: 60.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.640, Train accuracy: 76.000, Test loss: 1.008, Test accuracy: 64.60 

        train local model (freeze embeding):client   3,  Train loss: 0.965, Train accuracy: 60.000, Test loss: 1.228, Test accuracy: 46.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.730, Train accuracy: 72.600, Test loss: 1.288, Test accuracy: 51.00 

        train local model (freeze embeding):client   4,  Train loss: 1.135, Train accuracy: 55.400, Test loss: 1.271, Test accuracy: 51.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.711, Train accuracy: 74.200, Test loss: 0.918, Test accuracy: 63.80 

Round   3, Train loss: 0.927, Test loss: 1.051, Test accuracy: 60.16 

        train local model (freeze embeding):client   0,  Train loss: 0.848, Train accuracy: 66.000, Test loss: 1.030, Test accuracy: 60.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.447, Train accuracy: 83.200, Test loss: 0.949, Test accuracy: 64.80 

        train local model (freeze embeding):client   1,  Train loss: 1.004, Train accuracy: 59.800, Test loss: 1.250, Test accuracy: 49.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.657, Train accuracy: 76.000, Test loss: 1.191, Test accuracy: 54.80 

        train local model (freeze embeding):client   2,  Train loss: 0.979, Train accuracy: 60.400, Test loss: 1.058, Test accuracy: 58.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.638, Train accuracy: 73.000, Test loss: 1.001, Test accuracy: 64.20 

        train local model (freeze embeding):client   3,  Train loss: 1.047, Train accuracy: 54.600, Test loss: 1.278, Test accuracy: 46.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.806, Train accuracy: 68.600, Test loss: 1.219, Test accuracy: 51.20 

        train local model (freeze embeding):client   4,  Train loss: 0.954, Train accuracy: 61.800, Test loss: 1.063, Test accuracy: 56.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.862, Train accuracy: 66.400, Test loss: 1.035, Test accuracy: 58.40 

Round   4, Train loss: 0.920, Test loss: 1.002, Test accuracy: 61.48 

        train local model (freeze embeding):client   0,  Train loss: 0.720, Train accuracy: 72.000, Test loss: 0.965, Test accuracy: 63.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.383, Train accuracy: 87.400, Test loss: 0.958, Test accuracy: 63.80 

        train local model (freeze embeding):client   1,  Train loss: 1.003, Train accuracy: 55.800, Test loss: 1.243, Test accuracy: 47.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.712, Train accuracy: 72.400, Test loss: 1.171, Test accuracy: 54.60 

        train local model (freeze embeding):client   2,  Train loss: 0.910, Train accuracy: 62.800, Test loss: 1.016, Test accuracy: 57.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.611, Train accuracy: 74.600, Test loss: 0.981, Test accuracy: 65.40 

        train local model (freeze embeding):client   3,  Train loss: 0.986, Train accuracy: 58.400, Test loss: 1.229, Test accuracy: 51.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.780, Train accuracy: 68.200, Test loss: 1.265, Test accuracy: 54.40 

        train local model (freeze embeding):client   4,  Train loss: 0.978, Train accuracy: 60.600, Test loss: 1.101, Test accuracy: 54.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.776, Train accuracy: 68.400, Test loss: 0.948, Test accuracy: 63.80 

Round   5, Train loss: 0.911, Test loss: 1.026, Test accuracy: 61.24 

        train local model (freeze embeding):client   0,  Train loss: 0.886, Train accuracy: 65.800, Test loss: 1.174, Test accuracy: 56.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.479, Train accuracy: 81.400, Test loss: 0.973, Test accuracy: 66.40 

        train local model (freeze embeding):client   1,  Train loss: 1.094, Train accuracy: 56.000, Test loss: 1.319, Test accuracy: 44.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.739, Train accuracy: 70.200, Test loss: 1.252, Test accuracy: 56.20 

        train local model (freeze embeding):client   2,  Train loss: 0.873, Train accuracy: 64.600, Test loss: 0.991, Test accuracy: 61.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.558, Train accuracy: 78.400, Test loss: 0.935, Test accuracy: 67.20 

        train local model (freeze embeding):client   3,  Train loss: 1.041, Train accuracy: 55.400, Test loss: 1.259, Test accuracy: 49.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.883, Train accuracy: 66.600, Test loss: 1.318, Test accuracy: 50.20 

        train local model (freeze embeding):client   4,  Train loss: 1.041, Train accuracy: 59.600, Test loss: 1.176, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.749, Train accuracy: 72.200, Test loss: 0.964, Test accuracy: 62.40 

Round   6, Train loss: 0.909, Test loss: 1.061, Test accuracy: 60.28 

        train local model (freeze embeding):client   0,  Train loss: 0.797, Train accuracy: 68.200, Test loss: 1.007, Test accuracy: 62.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.831, Train accuracy: 66.400, Test loss: 1.276, Test accuracy: 59.60 

        train local model (freeze embeding):client   1,  Train loss: 1.119, Train accuracy: 56.000, Test loss: 1.345, Test accuracy: 46.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.706, Train accuracy: 71.800, Test loss: 1.194, Test accuracy: 55.00 

        train local model (freeze embeding):client   2,  Train loss: 0.924, Train accuracy: 62.000, Test loss: 1.032, Test accuracy: 59.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.636, Train accuracy: 73.600, Test loss: 0.964, Test accuracy: 68.20 

        train local model (freeze embeding):client   3,  Train loss: 0.960, Train accuracy: 60.200, Test loss: 1.197, Test accuracy: 48.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.698, Train accuracy: 70.600, Test loss: 1.218, Test accuracy: 53.20 

        train local model (freeze embeding):client   4,  Train loss: 1.207, Train accuracy: 51.600, Test loss: 1.389, Test accuracy: 43.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.908, Train accuracy: 64.800, Test loss: 1.137, Test accuracy: 56.00 

Round   7, Train loss: 0.915, Test loss: 1.040, Test accuracy: 59.64 

        train local model (freeze embeding):client   0,  Train loss: 0.787, Train accuracy: 68.400, Test loss: 1.038, Test accuracy: 60.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.428, Train accuracy: 84.200, Test loss: 0.991, Test accuracy: 65.40 

        train local model (freeze embeding):client   1,  Train loss: 1.037, Train accuracy: 56.600, Test loss: 1.248, Test accuracy: 46.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.634, Train accuracy: 78.400, Test loss: 1.163, Test accuracy: 53.60 

        train local model (freeze embeding):client   2,  Train loss: 0.943, Train accuracy: 63.000, Test loss: 1.039, Test accuracy: 63.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.630, Train accuracy: 75.400, Test loss: 0.972, Test accuracy: 67.00 

        train local model (freeze embeding):client   3,  Train loss: 0.970, Train accuracy: 57.600, Test loss: 1.237, Test accuracy: 46.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.694, Train accuracy: 73.200, Test loss: 1.224, Test accuracy: 53.60 

        train local model (freeze embeding):client   4,  Train loss: 0.952, Train accuracy: 59.400, Test loss: 1.080, Test accuracy: 55.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.739, Train accuracy: 69.600, Test loss: 0.999, Test accuracy: 60.80 

Round   8, Train loss: 0.914, Test loss: 1.050, Test accuracy: 59.68 

        train local model (freeze embeding):client   0,  Train loss: 0.821, Train accuracy: 67.000, Test loss: 1.063, Test accuracy: 57.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.602, Train accuracy: 76.400, Test loss: 1.026, Test accuracy: 62.60 

        train local model (freeze embeding):client   1,  Train loss: 1.059, Train accuracy: 53.000, Test loss: 1.294, Test accuracy: 43.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.615, Train accuracy: 76.400, Test loss: 1.116, Test accuracy: 56.40 

        train local model (freeze embeding):client   2,  Train loss: 0.952, Train accuracy: 59.800, Test loss: 1.077, Test accuracy: 54.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.719, Train accuracy: 72.200, Test loss: 1.067, Test accuracy: 61.00 

        train local model (freeze embeding):client   3,  Train loss: 0.945, Train accuracy: 62.200, Test loss: 1.216, Test accuracy: 49.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.663, Train accuracy: 73.200, Test loss: 1.176, Test accuracy: 53.60 

        train local model (freeze embeding):client   4,  Train loss: 0.929, Train accuracy: 62.800, Test loss: 1.116, Test accuracy: 52.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.991, Train accuracy: 62.600, Test loss: 1.285, Test accuracy: 53.40 

Round   9, Train loss: 0.899, Test loss: 1.048, Test accuracy: 60.28 

        train local model (freeze embeding):client   0,  Train loss: 0.818, Train accuracy: 68.400, Test loss: 1.057, Test accuracy: 60.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.511, Train accuracy: 81.200, Test loss: 1.045, Test accuracy: 63.20 

        train local model (freeze embeding):client   1,  Train loss: 1.035, Train accuracy: 55.400, Test loss: 1.292, Test accuracy: 45.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.725, Train accuracy: 71.800, Test loss: 1.297, Test accuracy: 52.40 

        train local model (freeze embeding):client   2,  Train loss: 0.985, Train accuracy: 58.600, Test loss: 1.131, Test accuracy: 55.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.606, Train accuracy: 76.000, Test loss: 0.964, Test accuracy: 66.60 

        train local model (freeze embeding):client   3,  Train loss: 1.000, Train accuracy: 57.800, Test loss: 1.259, Test accuracy: 48.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.644, Train accuracy: 75.600, Test loss: 1.232, Test accuracy: 55.20 

        train local model (freeze embeding):client   4,  Train loss: 0.934, Train accuracy: 60.600, Test loss: 1.111, Test accuracy: 54.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.696, Train accuracy: 75.000, Test loss: 0.993, Test accuracy: 61.80 

Round  10, Train loss: 0.903, Test loss: 1.064, Test accuracy: 59.88 

        train local model (freeze embeding):client   0,  Train loss: 0.814, Train accuracy: 67.400, Test loss: 1.038, Test accuracy: 59.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.428, Train accuracy: 84.800, Test loss: 1.021, Test accuracy: 64.40 

        train local model (freeze embeding):client   1,  Train loss: 1.035, Train accuracy: 53.600, Test loss: 1.243, Test accuracy: 47.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.860, Train accuracy: 63.200, Test loss: 1.435, Test accuracy: 46.60 

        train local model (freeze embeding):client   2,  Train loss: 1.021, Train accuracy: 56.000, Test loss: 1.145, Test accuracy: 53.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.647, Train accuracy: 73.400, Test loss: 0.975, Test accuracy: 64.80 

        train local model (freeze embeding):client   3,  Train loss: 0.969, Train accuracy: 57.400, Test loss: 1.207, Test accuracy: 49.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.743, Train accuracy: 68.800, Test loss: 1.248, Test accuracy: 56.40 

        train local model (freeze embeding):client   4,  Train loss: 0.985, Train accuracy: 57.800, Test loss: 1.182, Test accuracy: 47.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.705, Train accuracy: 73.800, Test loss: 1.016, Test accuracy: 60.00 

Round  11, Train loss: 0.893, Test loss: 1.077, Test accuracy: 59.32 

        train local model (freeze embeding):client   0,  Train loss: 0.784, Train accuracy: 69.600, Test loss: 1.013, Test accuracy: 62.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.567, Train accuracy: 79.200, Test loss: 1.093, Test accuracy: 61.40 

        train local model (freeze embeding):client   1,  Train loss: 0.977, Train accuracy: 60.200, Test loss: 1.251, Test accuracy: 47.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.698, Train accuracy: 73.000, Test loss: 1.183, Test accuracy: 55.80 

        train local model (freeze embeding):client   2,  Train loss: 0.958, Train accuracy: 58.200, Test loss: 1.092, Test accuracy: 54.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.673, Train accuracy: 72.400, Test loss: 1.064, Test accuracy: 58.00 

        train local model (freeze embeding):client   3,  Train loss: 0.949, Train accuracy: 61.200, Test loss: 1.196, Test accuracy: 50.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.678, Train accuracy: 72.000, Test loss: 1.267, Test accuracy: 55.40 

        train local model (freeze embeding):client   4,  Train loss: 1.024, Train accuracy: 58.000, Test loss: 1.196, Test accuracy: 52.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.644, Train accuracy: 75.400, Test loss: 0.927, Test accuracy: 64.80 

Round  12, Train loss: 0.890, Test loss: 1.079, Test accuracy: 60.32 

        train local model (freeze embeding):client   0,  Train loss: 0.822, Train accuracy: 68.200, Test loss: 1.041, Test accuracy: 61.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.692, Train accuracy: 71.600, Test loss: 1.213, Test accuracy: 59.40 

        train local model (freeze embeding):client   1,  Train loss: 0.977, Train accuracy: 59.800, Test loss: 1.244, Test accuracy: 49.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.753, Train accuracy: 70.200, Test loss: 1.248, Test accuracy: 52.40 

        train local model (freeze embeding):client   2,  Train loss: 0.956, Train accuracy: 57.800, Test loss: 1.023, Test accuracy: 58.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.587, Train accuracy: 76.600, Test loss: 0.930, Test accuracy: 68.80 

        train local model (freeze embeding):client   3,  Train loss: 0.951, Train accuracy: 62.200, Test loss: 1.184, Test accuracy: 48.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.764, Train accuracy: 70.600, Test loss: 1.288, Test accuracy: 52.60 

        train local model (freeze embeding):client   4,  Train loss: 0.904, Train accuracy: 64.200, Test loss: 1.056, Test accuracy: 57.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.685, Train accuracy: 73.000, Test loss: 0.925, Test accuracy: 64.20 

Round  13, Train loss: 0.889, Test loss: 1.029, Test accuracy: 61.76 

        train local model (freeze embeding):client   0,  Train loss: 0.790, Train accuracy: 68.400, Test loss: 1.027, Test accuracy: 58.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.456, Train accuracy: 83.200, Test loss: 0.999, Test accuracy: 64.60 

        train local model (freeze embeding):client   1,  Train loss: 1.049, Train accuracy: 55.000, Test loss: 1.278, Test accuracy: 46.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.866, Train accuracy: 62.800, Test loss: 1.394, Test accuracy: 48.00 

        train local model (freeze embeding):client   2,  Train loss: 0.880, Train accuracy: 63.800, Test loss: 1.013, Test accuracy: 60.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.582, Train accuracy: 78.000, Test loss: 0.931, Test accuracy: 66.40 

        train local model (freeze embeding):client   3,  Train loss: 0.935, Train accuracy: 61.600, Test loss: 1.191, Test accuracy: 48.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.722, Train accuracy: 70.600, Test loss: 1.204, Test accuracy: 54.60 

        train local model (freeze embeding):client   4,  Train loss: 0.882, Train accuracy: 64.600, Test loss: 1.035, Test accuracy: 58.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.761, Train accuracy: 67.800, Test loss: 1.019, Test accuracy: 60.00 

Round  14, Train loss: 0.885, Test loss: 1.008, Test accuracy: 61.40 

        train local model (freeze embeding):client   0,  Train loss: 0.804, Train accuracy: 68.000, Test loss: 1.046, Test accuracy: 57.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.465, Train accuracy: 82.400, Test loss: 1.036, Test accuracy: 63.40 

        train local model (freeze embeding):client   1,  Train loss: 1.010, Train accuracy: 56.400, Test loss: 1.281, Test accuracy: 46.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.777, Train accuracy: 69.000, Test loss: 1.281, Test accuracy: 51.40 

        train local model (freeze embeding):client   2,  Train loss: 0.874, Train accuracy: 63.400, Test loss: 0.987, Test accuracy: 60.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.560, Train accuracy: 77.600, Test loss: 0.937, Test accuracy: 65.40 

        train local model (freeze embeding):client   3,  Train loss: 0.999, Train accuracy: 57.000, Test loss: 1.264, Test accuracy: 46.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.614, Train accuracy: 78.400, Test loss: 1.199, Test accuracy: 54.20 

        train local model (freeze embeding):client   4,  Train loss: 0.884, Train accuracy: 66.400, Test loss: 1.044, Test accuracy: 55.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.745, Train accuracy: 72.600, Test loss: 1.067, Test accuracy: 61.60 

Round  15, Train loss: 0.893, Test loss: 1.073, Test accuracy: 59.12 

        train local model (freeze embeding):client   0,  Train loss: 0.780, Train accuracy: 69.600, Test loss: 1.037, Test accuracy: 57.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.615, Train accuracy: 75.600, Test loss: 1.172, Test accuracy: 62.60 

        train local model (freeze embeding):client   1,  Train loss: 1.006, Train accuracy: 59.000, Test loss: 1.317, Test accuracy: 46.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.781, Train accuracy: 69.200, Test loss: 1.274, Test accuracy: 53.60 

        train local model (freeze embeding):client   2,  Train loss: 0.834, Train accuracy: 66.200, Test loss: 0.978, Test accuracy: 62.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.669, Train accuracy: 72.200, Test loss: 0.983, Test accuracy: 63.00 

        train local model (freeze embeding):client   3,  Train loss: 1.018, Train accuracy: 57.800, Test loss: 1.305, Test accuracy: 47.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.762, Train accuracy: 66.800, Test loss: 1.272, Test accuracy: 53.40 

        train local model (freeze embeding):client   4,  Train loss: 0.906, Train accuracy: 63.200, Test loss: 1.037, Test accuracy: 57.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.660, Train accuracy: 73.200, Test loss: 0.970, Test accuracy: 62.40 

Round  16, Train loss: 0.873, Test loss: 1.055, Test accuracy: 60.00 

        train local model (freeze embeding):client   0,  Train loss: 0.731, Train accuracy: 70.400, Test loss: 1.007, Test accuracy: 61.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.594, Train accuracy: 75.400, Test loss: 1.086, Test accuracy: 62.40 

        train local model (freeze embeding):client   1,  Train loss: 1.025, Train accuracy: 58.200, Test loss: 1.306, Test accuracy: 49.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.650, Train accuracy: 75.200, Test loss: 1.197, Test accuracy: 56.60 

        train local model (freeze embeding):client   2,  Train loss: 0.836, Train accuracy: 66.800, Test loss: 0.958, Test accuracy: 62.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.560, Train accuracy: 78.400, Test loss: 0.949, Test accuracy: 66.60 

        train local model (freeze embeding):client   3,  Train loss: 0.904, Train accuracy: 63.800, Test loss: 1.197, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.678, Train accuracy: 73.600, Test loss: 1.336, Test accuracy: 53.80 

        train local model (freeze embeding):client   4,  Train loss: 0.946, Train accuracy: 60.600, Test loss: 1.143, Test accuracy: 53.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.636, Train accuracy: 77.400, Test loss: 0.919, Test accuracy: 64.60 

Round  17, Train loss: 0.881, Test loss: 1.047, Test accuracy: 61.56 

        train local model (freeze embeding):client   0,  Train loss: 0.711, Train accuracy: 71.400, Test loss: 0.972, Test accuracy: 62.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.423, Train accuracy: 86.000, Test loss: 0.990, Test accuracy: 65.60 

        train local model (freeze embeding):client   1,  Train loss: 0.976, Train accuracy: 58.000, Test loss: 1.237, Test accuracy: 49.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.737, Train accuracy: 68.400, Test loss: 1.288, Test accuracy: 52.20 

        train local model (freeze embeding):client   2,  Train loss: 0.838, Train accuracy: 66.600, Test loss: 0.973, Test accuracy: 61.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.661, Train accuracy: 71.400, Test loss: 1.027, Test accuracy: 64.00 

        train local model (freeze embeding):client   3,  Train loss: 0.947, Train accuracy: 61.000, Test loss: 1.231, Test accuracy: 50.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.633, Train accuracy: 78.400, Test loss: 1.255, Test accuracy: 53.80 

        train local model (freeze embeding):client   4,  Train loss: 0.823, Train accuracy: 67.000, Test loss: 1.041, Test accuracy: 59.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.663, Train accuracy: 72.400, Test loss: 1.015, Test accuracy: 62.00 

Round  18, Train loss: 0.868, Test loss: 1.030, Test accuracy: 61.20 

        train local model (freeze embeding):client   0,  Train loss: 0.776, Train accuracy: 69.600, Test loss: 1.048, Test accuracy: 59.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.425, Train accuracy: 84.000, Test loss: 0.969, Test accuracy: 66.00 

        train local model (freeze embeding):client   1,  Train loss: 0.965, Train accuracy: 60.400, Test loss: 1.232, Test accuracy: 49.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.651, Train accuracy: 74.800, Test loss: 1.179, Test accuracy: 55.20 

        train local model (freeze embeding):client   2,  Train loss: 0.802, Train accuracy: 67.200, Test loss: 0.938, Test accuracy: 65.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.620, Train accuracy: 76.400, Test loss: 0.947, Test accuracy: 65.40 

        train local model (freeze embeding):client   3,  Train loss: 0.906, Train accuracy: 61.000, Test loss: 1.215, Test accuracy: 51.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.671, Train accuracy: 73.000, Test loss: 1.210, Test accuracy: 54.80 

        train local model (freeze embeding):client   4,  Train loss: 0.927, Train accuracy: 63.200, Test loss: 1.091, Test accuracy: 56.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.594, Train accuracy: 76.600, Test loss: 0.957, Test accuracy: 60.40 

Round  19, Train loss: 0.879, Test loss: 1.056, Test accuracy: 60.44 

        train local model (freeze embeding):client   0,  Train loss: 0.798, Train accuracy: 67.400, Test loss: 1.035, Test accuracy: 58.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.476, Train accuracy: 82.600, Test loss: 0.988, Test accuracy: 64.60 

        train local model (freeze embeding):client   1,  Train loss: 0.931, Train accuracy: 62.800, Test loss: 1.216, Test accuracy: 51.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.808, Train accuracy: 70.200, Test loss: 1.352, Test accuracy: 51.80 

        train local model (freeze embeding):client   2,  Train loss: 0.908, Train accuracy: 62.600, Test loss: 1.043, Test accuracy: 57.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.675, Train accuracy: 72.400, Test loss: 1.068, Test accuracy: 61.80 

        train local model (freeze embeding):client   3,  Train loss: 0.920, Train accuracy: 61.800, Test loss: 1.200, Test accuracy: 52.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.728, Train accuracy: 72.200, Test loss: 1.307, Test accuracy: 52.60 

        train local model (freeze embeding):client   4,  Train loss: 0.870, Train accuracy: 65.400, Test loss: 1.034, Test accuracy: 57.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.689, Train accuracy: 71.400, Test loss: 1.056, Test accuracy: 59.00 

Final Round, Train loss: 0.878, Test loss: 1.063, Test accuracy: 60.68 

Average accuracy final 10 rounds: 302.4066666666666 

3098.5454845428467
[9.511517524719238, 18.88182306289673, 28.09780240058899, 37.02584958076477, 46.05108284950256, 55.680463552474976, 65.3422474861145, 74.54403185844421, 83.45987296104431, 92.89532160758972, 102.19507074356079, 112.0109338760376, 121.28224182128906, 130.99650406837463, 139.95004558563232, 149.09189105033875, 157.75177478790283, 166.77846360206604, 175.53885173797607, 184.60735535621643, 193.9828109741211, 204.06478452682495, 213.45326566696167, 222.69628071784973, 231.8888454437256, 241.24271059036255, 250.76419687271118, 260.2049653530121, 269.77561044692993, 278.9592936038971, 289.40399837493896, 299.1962652206421, 308.5523657798767, 318.0173156261444, 327.3621664047241, 336.66417169570923, 346.39638328552246, 355.31513237953186, 364.3915283679962, 373.5764648914337, 383.2837634086609, 392.86822152137756, 402.61599230766296, 411.9786283969879, 421.49405169487, 431.24537467956543, 440.48388409614563, 450.40111207962036, 460.0003037452698, 469.63026213645935, 479.48902654647827, 489.5941379070282, 498.9800090789795, 508.4051306247711, 517.7127342224121, 526.9224815368652, 536.4323153495789, 545.9906222820282, 555.393340587616, 565.3805160522461, 574.8787639141083, 584.1060252189636, 593.5000483989716, 602.9005208015442, 612.6653883457184, 622.249986410141, 631.8400387763977, 641.3670752048492, 650.8535385131836, 660.1396174430847, 669.7816905975342, 679.5408155918121, 689.7321026325226, 698.98974609375, 708.2098829746246, 718.1235144138336, 727.7546792030334, 737.5323147773743, 747.1172027587891, 756.4527053833008, 765.6887624263763, 775.2715258598328, 784.7103247642517, 793.8579347133636, 803.3954050540924, 813.2142052650452, 822.8346331119537, 832.2369260787964, 841.7889666557312, 851.6781597137451, 861.2542994022369, 870.9754288196564, 880.6554093360901, 890.1282062530518, 900.1554844379425, 910.110570192337, 919.5846655368805, 929.192215681076, 939.0013473033905, 948.5702624320984, 958.1407067775726, 967.9538569450378, 977.3966097831726, 986.8164610862732, 996.4384329319]
[49.6, 46.2, 53.2, 54.6, 58.0, 61.4, 53.8, 64.4, 60.8, 59.0, 59.2, 63.0, 62.0, 64.0, 65.8, 60.8, 64.0, 65.2, 66.8, 63.4, 61.0, 55.7, 55.1, 58.6, 57.9, 57.4, 56.1, 56.9, 56.6, 56.0, 56.2, 57.5, 57.4, 55.2, 57.0, 56.7, 56.6, 56.9, 56.8, 56.1, 54.2, 54.3, 58.2, 59.93333333333333, 58.06666666666667, 61.06666666666667, 60.733333333333334, 60.4, 58.266666666666666, 61.733333333333334, 61.6, 60.333333333333336, 62.666666666666664, 62.266666666666666, 62.666666666666664, 63.06666666666667, 61.733333333333334, 61.733333333333334, 61.4, 62.266666666666666, 62.2, 60.666666666666664, 61.13333333333333, 60.8, 60.15, 61.55, 60.8, 60.45, 61.65, 60.7, 60.85, 60.6, 60.2, 59.2, 59.5, 60.15, 59.95, 60.65, 61.8, 60.85, 57.85, 60.05, 59.8, 60.3, 60.68, 59.88, 60.04, 60.16, 61.48, 61.24, 60.28, 59.64, 59.68, 60.28, 59.88, 59.32, 60.32, 61.76, 61.4, 59.12, 60.0, 61.56, 61.2, 60.44, 60.68]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.693, Test loss: 0.707, Test accuracy: 69.20 

Round   0, Global train loss: 0.693, Global test loss: 0.674, Global test accuracy: 53.00 

Round   1, Train loss: 0.500, Test loss: 0.664, Test accuracy: 76.30 

Round   1, Global train loss: 0.500, Global test loss: 0.675, Global test accuracy: 57.10 

Round   2, Train loss: 0.420, Test loss: 0.705, Test accuracy: 73.00 

Round   2, Global train loss: 0.420, Global test loss: 0.672, Global test accuracy: 59.50 

Round   3, Train loss: 0.369, Test loss: 0.763, Test accuracy: 76.10 

Round   3, Global train loss: 0.369, Global test loss: 0.698, Global test accuracy: 52.00 

Round   4, Train loss: 0.366, Test loss: 0.604, Test accuracy: 75.90 

Round   4, Global train loss: 0.366, Global test loss: 0.691, Global test accuracy: 52.40 

Round   5, Train loss: 0.289, Test loss: 0.608, Test accuracy: 77.20 

Round   5, Global train loss: 0.289, Global test loss: 0.704, Global test accuracy: 51.30 

Round   6, Train loss: 0.263, Test loss: 0.805, Test accuracy: 76.30 

Round   6, Global train loss: 0.263, Global test loss: 0.693, Global test accuracy: 52.90 

Round   7, Train loss: 0.230, Test loss: 0.764, Test accuracy: 76.80 

Round   7, Global train loss: 0.230, Global test loss: 0.680, Global test accuracy: 54.50 

Round   8, Train loss: 0.188, Test loss: 0.957, Test accuracy: 76.60 

Round   8, Global train loss: 0.188, Global test loss: 0.669, Global test accuracy: 58.50 

Round   9, Train loss: 0.194, Test loss: 0.611, Test accuracy: 79.80 

Round   9, Global train loss: 0.194, Global test loss: 0.684, Global test accuracy: 54.60 

Round  10, Train loss: 0.130, Test loss: 0.789, Test accuracy: 78.90 

Round  10, Global train loss: 0.130, Global test loss: 0.688, Global test accuracy: 54.60 

Round  11, Train loss: 0.134, Test loss: 0.712, Test accuracy: 79.60 

Round  11, Global train loss: 0.134, Global test loss: 0.686, Global test accuracy: 55.90 

Round  12, Train loss: 0.140, Test loss: 0.882, Test accuracy: 78.80 

Round  12, Global train loss: 0.140, Global test loss: 0.667, Global test accuracy: 60.40 

Round  13, Train loss: 0.098, Test loss: 1.074, Test accuracy: 76.40 

Round  13, Global train loss: 0.098, Global test loss: 0.691, Global test accuracy: 54.30 

Round  14, Train loss: 0.091, Test loss: 0.967, Test accuracy: 79.50 

Round  14, Global train loss: 0.091, Global test loss: 0.669, Global test accuracy: 57.90 

Round  15, Train loss: 0.064, Test loss: 0.770, Test accuracy: 81.60 

Round  15, Global train loss: 0.064, Global test loss: 0.677, Global test accuracy: 56.30 

Round  16, Train loss: 0.088, Test loss: 0.786, Test accuracy: 81.10 

Round  16, Global train loss: 0.088, Global test loss: 0.689, Global test accuracy: 53.30 

Round  17, Train loss: 0.063, Test loss: 0.881, Test accuracy: 79.70 

Round  17, Global train loss: 0.063, Global test loss: 0.682, Global test accuracy: 54.90 

Round  18, Train loss: 0.041, Test loss: 0.913, Test accuracy: 79.90 

Round  18, Global train loss: 0.041, Global test loss: 0.685, Global test accuracy: 54.10 

Round  19, Train loss: 0.068, Test loss: 0.759, Test accuracy: 80.80 

Round  19, Global train loss: 0.068, Global test loss: 0.668, Global test accuracy: 57.90 

Round  20, Train loss: 0.041, Test loss: 0.802, Test accuracy: 81.60 

Round  20, Global train loss: 0.041, Global test loss: 0.685, Global test accuracy: 54.80 

Round  21, Train loss: 0.055, Test loss: 0.838, Test accuracy: 80.10 

Round  21, Global train loss: 0.055, Global test loss: 0.695, Global test accuracy: 52.60 

Round  22, Train loss: 0.027, Test loss: 0.864, Test accuracy: 82.60 

Round  22, Global train loss: 0.027, Global test loss: 0.714, Global test accuracy: 52.10 

Round  23, Train loss: 0.043, Test loss: 0.752, Test accuracy: 82.00 

Round  23, Global train loss: 0.043, Global test loss: 0.680, Global test accuracy: 54.30 

Round  24, Train loss: 0.029, Test loss: 0.804, Test accuracy: 82.40 

Round  24, Global train loss: 0.029, Global test loss: 0.669, Global test accuracy: 57.40 

Round  25, Train loss: 0.055, Test loss: 1.058, Test accuracy: 80.10 

Round  25, Global train loss: 0.055, Global test loss: 0.682, Global test accuracy: 54.50 

Round  26, Train loss: 0.037, Test loss: 0.703, Test accuracy: 82.80 

Round  26, Global train loss: 0.037, Global test loss: 0.699, Global test accuracy: 52.70 

Round  27, Train loss: 0.029, Test loss: 0.759, Test accuracy: 81.90 

Round  27, Global train loss: 0.029, Global test loss: 0.706, Global test accuracy: 52.60 

Round  28, Train loss: 0.019, Test loss: 0.827, Test accuracy: 82.20 

Round  28, Global train loss: 0.019, Global test loss: 0.687, Global test accuracy: 54.50 

Round  29, Train loss: 0.016, Test loss: 0.905, Test accuracy: 82.20 

Round  29, Global train loss: 0.016, Global test loss: 0.680, Global test accuracy: 55.20 

Round  30, Train loss: 0.008, Test loss: 0.867, Test accuracy: 83.90 

Round  30, Global train loss: 0.008, Global test loss: 0.676, Global test accuracy: 56.30 

Round  31, Train loss: 0.015, Test loss: 0.886, Test accuracy: 81.20 

Round  31, Global train loss: 0.015, Global test loss: 0.671, Global test accuracy: 57.30 

Round  32, Train loss: 0.028, Test loss: 0.843, Test accuracy: 83.00 

Round  32, Global train loss: 0.028, Global test loss: 0.675, Global test accuracy: 56.30 

Round  33, Train loss: 0.019, Test loss: 0.840, Test accuracy: 81.30 

Round  33, Global train loss: 0.019, Global test loss: 0.686, Global test accuracy: 54.60 

Round  34, Train loss: 0.012, Test loss: 0.819, Test accuracy: 83.60 

Round  34, Global train loss: 0.012, Global test loss: 0.682, Global test accuracy: 55.20 

Final Round, Train loss: 0.014, Test loss: 0.902, Test accuracy: 81.20 

Final Round, Global train loss: 0.014, Global test loss: 0.682, Global test accuracy: 55.20 

Average accuracy final 10 rounds: 82.22 

Average global accuracy final 10 rounds: 54.92 

480.3941707611084
[4.972285509109497, 7.457990884780884, 9.753920078277588, 12.11808466911316, 14.446966648101807, 16.861698627471924, 19.28537082672119, 21.640419721603394, 24.15158224105835, 26.480247974395752, 28.91561484336853, 31.411757707595825, 33.938997745513916, 36.31698656082153, 38.873883962631226, 41.162848472595215, 43.440471172332764, 45.912702322006226, 48.25914001464844, 50.753540992736816, 53.07007098197937, 55.5641074180603, 57.88438391685486, 60.30830693244934, 62.583404302597046, 64.8593213558197, 67.26038956642151, 69.74453401565552, 72.03164458274841, 74.41893029212952, 76.65211534500122, 79.10483121871948, 81.39401721954346, 83.65846180915833, 85.9380350112915, 90.83460474014282]
[69.2, 76.3, 73.0, 76.1, 75.9, 77.2, 76.3, 76.8, 76.6, 79.8, 78.9, 79.6, 78.8, 76.4, 79.5, 81.6, 81.1, 79.7, 79.9, 80.8, 81.6, 80.1, 82.6, 82.0, 82.4, 80.1, 82.8, 81.9, 82.2, 82.2, 83.9, 81.2, 83.0, 81.3, 83.6, 81.2]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.670, Test loss: 0.644, Test accuracy: 72.10 

Round   0, Global train loss: 0.670, Global test loss: 0.695, Global test accuracy: 52.30 

Round   1, Train loss: 0.601, Test loss: 0.598, Test accuracy: 73.20 

Round   1, Global train loss: 0.601, Global test loss: 0.690, Global test accuracy: 62.90 

Round   2, Train loss: 0.562, Test loss: 0.597, Test accuracy: 72.50 

Round   2, Global train loss: 0.562, Global test loss: 0.634, Global test accuracy: 67.00 

Round   3, Train loss: 0.546, Test loss: 0.584, Test accuracy: 72.80 

Round   3, Global train loss: 0.546, Global test loss: 0.643, Global test accuracy: 67.50 

Round   4, Train loss: 0.489, Test loss: 0.879, Test accuracy: 72.70 

Round   4, Global train loss: 0.489, Global test loss: 0.668, Global test accuracy: 65.40 

Round   5, Train loss: 0.470, Test loss: 0.853, Test accuracy: 68.30 

Round   5, Global train loss: 0.470, Global test loss: 0.665, Global test accuracy: 66.00 

Round   6, Train loss: 0.469, Test loss: 0.702, Test accuracy: 74.20 

Round   6, Global train loss: 0.469, Global test loss: 0.699, Global test accuracy: 69.50 

Round   7, Train loss: 0.444, Test loss: 0.809, Test accuracy: 72.70 

Round   7, Global train loss: 0.444, Global test loss: 0.724, Global test accuracy: 64.70 

Round   8, Train loss: 0.410, Test loss: 0.704, Test accuracy: 73.30 

Round   8, Global train loss: 0.410, Global test loss: 0.636, Global test accuracy: 66.40 

Round   9, Train loss: 0.385, Test loss: 0.870, Test accuracy: 75.70 

Round   9, Global train loss: 0.385, Global test loss: 0.688, Global test accuracy: 69.20 

Round  10, Train loss: 0.351, Test loss: 0.619, Test accuracy: 79.80 

Round  10, Global train loss: 0.351, Global test loss: 0.753, Global test accuracy: 69.90 

Round  11, Train loss: 0.323, Test loss: 0.568, Test accuracy: 78.30 

Round  11, Global train loss: 0.323, Global test loss: 0.717, Global test accuracy: 67.40 

Round  12, Train loss: 0.331, Test loss: 0.507, Test accuracy: 79.30 

Round  12, Global train loss: 0.331, Global test loss: 0.724, Global test accuracy: 69.20 

Round  13, Train loss: 0.293, Test loss: 0.691, Test accuracy: 79.60 

Round  13, Global train loss: 0.293, Global test loss: 0.699, Global test accuracy: 70.30 

Round  14, Train loss: 0.284, Test loss: 0.867, Test accuracy: 76.50 

Round  14, Global train loss: 0.284, Global test loss: 0.765, Global test accuracy: 68.40 

Round  15, Train loss: 0.266, Test loss: 0.527, Test accuracy: 81.20 

Round  15, Global train loss: 0.266, Global test loss: 0.739, Global test accuracy: 67.70 

Round  16, Train loss: 0.248, Test loss: 0.566, Test accuracy: 81.60 

Round  16, Global train loss: 0.248, Global test loss: 0.779, Global test accuracy: 68.00 

Round  17, Train loss: 0.261, Test loss: 0.697, Test accuracy: 79.50 

Round  17, Global train loss: 0.261, Global test loss: 0.718, Global test accuracy: 68.20 

Round  18, Train loss: 0.222, Test loss: 0.636, Test accuracy: 80.70 

Round  18, Global train loss: 0.222, Global test loss: 0.957, Global test accuracy: 65.70 

Round  19, Train loss: 0.215, Test loss: 0.539, Test accuracy: 80.70 

Round  19, Global train loss: 0.215, Global test loss: 0.795, Global test accuracy: 66.70 

Round  20, Train loss: 0.217, Test loss: 0.642, Test accuracy: 80.70 

Round  20, Global train loss: 0.217, Global test loss: 0.908, Global test accuracy: 68.60 

Round  21, Train loss: 0.175, Test loss: 0.651, Test accuracy: 80.30 

Round  21, Global train loss: 0.175, Global test loss: 0.822, Global test accuracy: 68.70 

Round  22, Train loss: 0.167, Test loss: 0.808, Test accuracy: 79.40 

Round  22, Global train loss: 0.167, Global test loss: 0.929, Global test accuracy: 67.80 

Round  23, Train loss: 0.177, Test loss: 0.814, Test accuracy: 78.80 

Round  23, Global train loss: 0.177, Global test loss: 0.897, Global test accuracy: 66.00 

Round  24, Train loss: 0.162, Test loss: 0.875, Test accuracy: 78.70 

Round  24, Global train loss: 0.162, Global test loss: 0.866, Global test accuracy: 66.70 

Round  25, Train loss: 0.146, Test loss: 1.081, Test accuracy: 75.50 

Round  25, Global train loss: 0.146, Global test loss: 0.826, Global test accuracy: 69.20 

Round  26, Train loss: 0.154, Test loss: 0.553, Test accuracy: 82.30 

Round  26, Global train loss: 0.154, Global test loss: 0.865, Global test accuracy: 67.30 

Round  27, Train loss: 0.128, Test loss: 0.658, Test accuracy: 81.80 

Round  27, Global train loss: 0.128, Global test loss: 0.949, Global test accuracy: 66.50 

Round  28, Train loss: 0.133, Test loss: 0.688, Test accuracy: 81.80 

Round  28, Global train loss: 0.133, Global test loss: 0.931, Global test accuracy: 66.40 

Round  29, Train loss: 0.130, Test loss: 0.756, Test accuracy: 81.40 

Round  29, Global train loss: 0.130, Global test loss: 0.965, Global test accuracy: 66.70 

Round  30, Train loss: 0.100, Test loss: 0.609, Test accuracy: 82.30 

Round  30, Global train loss: 0.100, Global test loss: 0.943, Global test accuracy: 67.20 

Round  31, Train loss: 0.143, Test loss: 0.704, Test accuracy: 81.20 

Round  31, Global train loss: 0.143, Global test loss: 0.913, Global test accuracy: 65.20 

Round  32, Train loss: 0.102, Test loss: 0.866, Test accuracy: 80.40 

Round  32, Global train loss: 0.102, Global test loss: 0.995, Global test accuracy: 67.30 

Round  33, Train loss: 0.080, Test loss: 0.711, Test accuracy: 83.10 

Round  33, Global train loss: 0.080, Global test loss: 1.006, Global test accuracy: 67.10 

Round  34, Train loss: 0.107, Test loss: 0.627, Test accuracy: 83.00 

Round  34, Global train loss: 0.107, Global test loss: 0.947, Global test accuracy: 65.80 

Final Round, Train loss: 0.086, Test loss: 0.791, Test accuracy: 78.80 

Final Round, Global train loss: 0.086, Global test loss: 0.947, Global test accuracy: 65.80 

Average accuracy final 10 rounds: 81.28000000000002 

Average global accuracy final 10 rounds: 66.87 

474.52922010421753
[5.234546899795532, 7.577477693557739, 9.897343873977661, 12.266913175582886, 14.617575407028198, 17.162387132644653, 19.56143355369568, 21.871122360229492, 24.190762996673584, 26.545368432998657, 28.78495502471924, 31.106366872787476, 33.498979568481445, 35.92158603668213, 38.19569945335388, 40.42239713668823, 42.71185350418091, 45.178303718566895, 47.49221205711365, 49.91561937332153, 52.18682336807251, 54.57966494560242, 56.88316750526428, 59.15532374382019, 61.4485137462616, 63.76310133934021, 66.2116630077362, 68.4504406452179, 70.64734077453613, 72.9600727558136, 75.29099631309509, 77.54370975494385, 79.82670998573303, 82.14188361167908, 84.43565273284912, 88.9424421787262]
[72.1, 73.2, 72.5, 72.8, 72.7, 68.3, 74.2, 72.7, 73.3, 75.7, 79.8, 78.3, 79.3, 79.6, 76.5, 81.2, 81.6, 79.5, 80.7, 80.7, 80.7, 80.3, 79.4, 78.8, 78.7, 75.5, 82.3, 81.8, 81.8, 81.4, 82.3, 81.2, 80.4, 83.1, 83.0, 78.8]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.767, Test loss: 0.893, Test accuracy: 55.30 

Round   1, Train loss: 0.634, Test loss: 0.617, Test accuracy: 63.10 

Round   2, Train loss: 0.581, Test loss: 0.553, Test accuracy: 69.30 

Round   3, Train loss: 0.587, Test loss: 0.787, Test accuracy: 63.70 

Round   4, Train loss: 0.571, Test loss: 0.628, Test accuracy: 67.00 

Round   5, Train loss: 0.537, Test loss: 0.575, Test accuracy: 69.80 

Round   6, Train loss: 0.504, Test loss: 0.536, Test accuracy: 70.90 

Round   7, Train loss: 0.479, Test loss: 0.575, Test accuracy: 71.50 

Round   8, Train loss: 0.459, Test loss: 0.486, Test accuracy: 74.80 

Round   9, Train loss: 0.433, Test loss: 0.498, Test accuracy: 73.10 

Round  10, Train loss: 0.452, Test loss: 0.449, Test accuracy: 77.10 

Round  11, Train loss: 0.417, Test loss: 0.440, Test accuracy: 78.10 

Round  12, Train loss: 0.411, Test loss: 0.512, Test accuracy: 74.10 

Round  13, Train loss: 0.384, Test loss: 0.476, Test accuracy: 77.50 

Round  14, Train loss: 0.378, Test loss: 0.567, Test accuracy: 73.70 

Round  15, Train loss: 0.373, Test loss: 0.627, Test accuracy: 73.60 

Round  16, Train loss: 0.355, Test loss: 0.414, Test accuracy: 79.90 

Round  17, Train loss: 0.330, Test loss: 0.431, Test accuracy: 80.30 

Round  18, Train loss: 0.331, Test loss: 0.474, Test accuracy: 77.50 

Round  19, Train loss: 0.308, Test loss: 0.444, Test accuracy: 79.40 

Round  20, Train loss: 0.304, Test loss: 0.464, Test accuracy: 79.90 

Round  21, Train loss: 0.298, Test loss: 0.451, Test accuracy: 79.70 

Round  22, Train loss: 0.287, Test loss: 0.502, Test accuracy: 79.30 

Round  23, Train loss: 0.269, Test loss: 0.530, Test accuracy: 78.30 

Round  24, Train loss: 0.271, Test loss: 0.478, Test accuracy: 78.70 

Round  25, Train loss: 0.247, Test loss: 0.524, Test accuracy: 78.30 

Round  26, Train loss: 0.239, Test loss: 0.531, Test accuracy: 78.70 

Round  27, Train loss: 0.243, Test loss: 0.499, Test accuracy: 79.60 

Round  28, Train loss: 0.228, Test loss: 0.523, Test accuracy: 78.10 

Round  29, Train loss: 0.223, Test loss: 0.494, Test accuracy: 80.20 

Round  30, Train loss: 0.214, Test loss: 0.467, Test accuracy: 80.50 

Round  31, Train loss: 0.205, Test loss: 0.537, Test accuracy: 79.70 

Round  32, Train loss: 0.195, Test loss: 0.468, Test accuracy: 81.80 

Round  33, Train loss: 0.170, Test loss: 0.528, Test accuracy: 79.70 

Round  34, Train loss: 0.168, Test loss: 0.565, Test accuracy: 80.10 

Round  35, Train loss: 0.165, Test loss: 0.556, Test accuracy: 79.10 

Round  36, Train loss: 0.143, Test loss: 0.490, Test accuracy: 80.10 

Round  37, Train loss: 0.149, Test loss: 0.591, Test accuracy: 77.80 

Round  38, Train loss: 0.129, Test loss: 0.590, Test accuracy: 78.20 

Round  39, Train loss: 0.142, Test loss: 0.661, Test accuracy: 79.30 

Round  40, Train loss: 0.122, Test loss: 0.532, Test accuracy: 81.10 

Round  41, Train loss: 0.125, Test loss: 0.576, Test accuracy: 80.10 

Round  42, Train loss: 0.118, Test loss: 0.572, Test accuracy: 81.40 

Round  43, Train loss: 0.111, Test loss: 0.533, Test accuracy: 82.20 

Round  44, Train loss: 0.105, Test loss: 0.553, Test accuracy: 80.20 

Round  45, Train loss: 0.097, Test loss: 0.643, Test accuracy: 78.80 

Round  46, Train loss: 0.091, Test loss: 0.668, Test accuracy: 78.70 

Round  47, Train loss: 0.100, Test loss: 0.620, Test accuracy: 81.00 

Round  48, Train loss: 0.117, Test loss: 0.592, Test accuracy: 81.70 

Round  49, Train loss: 0.082, Test loss: 0.563, Test accuracy: 81.40 

Final Round, Train loss: 0.050, Test loss: 0.555, Test accuracy: 82.00 

Average accuracy final 10 rounds: 80.66 

496.2906742095947
[3.785226583480835, 5.694782018661499, 7.7193334102630615, 9.621132135391235, 11.549394607543945, 13.422617435455322, 15.308547258377075, 17.221620082855225, 19.07273006439209, 20.936373949050903, 22.89891290664673, 24.7590274810791, 26.59812307357788, 28.375974893569946, 30.23723793029785, 32.145182847976685, 34.04711079597473, 35.864333629608154, 37.674158334732056, 39.4499728679657, 41.26725363731384, 43.0836181640625, 44.86330437660217, 46.67172646522522, 48.40791368484497, 50.25414776802063, 52.102938413619995, 54.09147882461548, 56.00119400024414, 57.81917953491211, 59.75308084487915, 61.58121633529663, 63.50880718231201, 65.32672071456909, 67.18067002296448, 69.04109954833984, 70.84378600120544, 72.73787188529968, 74.52475643157959, 76.46259474754333, 78.41622304916382, 80.34112977981567, 82.14212131500244, 84.07230353355408, 85.99702668190002, 87.80302834510803, 89.64575862884521, 91.54627656936646, 93.37694430351257, 95.23854875564575, 97.1218318939209]
[55.3, 63.1, 69.3, 63.7, 67.0, 69.8, 70.9, 71.5, 74.8, 73.1, 77.1, 78.1, 74.1, 77.5, 73.7, 73.6, 79.9, 80.3, 77.5, 79.4, 79.9, 79.7, 79.3, 78.3, 78.7, 78.3, 78.7, 79.6, 78.1, 80.2, 80.5, 79.7, 81.8, 79.7, 80.1, 79.1, 80.1, 77.8, 78.2, 79.3, 81.1, 80.1, 81.4, 82.2, 80.2, 78.8, 78.7, 81.0, 81.7, 81.4, 82.0]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
Round   0, Train loss: 0.744, Test loss: 0.801, Test accuracy: 51.10
Round   1, Train loss: 0.651, Test loss: 0.736, Test accuracy: 62.50
Round   2, Train loss: 0.592, Test loss: 0.660, Test accuracy: 65.30
Round   3, Train loss: 0.571, Test loss: 0.765, Test accuracy: 66.20
Round   4, Train loss: 0.574, Test loss: 0.826, Test accuracy: 67.30
Round   5, Train loss: 0.498, Test loss: 0.576, Test accuracy: 70.40
Round   6, Train loss: 0.487, Test loss: 0.542, Test accuracy: 71.60
Round   7, Train loss: 0.504, Test loss: 0.676, Test accuracy: 71.20
Round   8, Train loss: 0.469, Test loss: 0.598, Test accuracy: 73.00
Round   9, Train loss: 0.456, Test loss: 0.531, Test accuracy: 75.60
Round  10, Train loss: 0.428, Test loss: 0.445, Test accuracy: 76.00
Round  11, Train loss: 0.409, Test loss: 0.516, Test accuracy: 75.50
Round  12, Train loss: 0.398, Test loss: 0.555, Test accuracy: 74.90
Round  13, Train loss: 0.371, Test loss: 0.535, Test accuracy: 75.70
Round  14, Train loss: 0.341, Test loss: 0.432, Test accuracy: 78.70
Round  15, Train loss: 0.353, Test loss: 0.519, Test accuracy: 75.70
Round  16, Train loss: 0.339, Test loss: 0.672, Test accuracy: 73.40
Round  17, Train loss: 0.341, Test loss: 0.487, Test accuracy: 77.30
Round  18, Train loss: 0.309, Test loss: 0.598, Test accuracy: 74.70
Round  19, Train loss: 0.312, Test loss: 0.411, Test accuracy: 80.60
Round  20, Train loss: 0.292, Test loss: 0.469, Test accuracy: 78.60
Round  21, Train loss: 0.280, Test loss: 0.444, Test accuracy: 80.10
Round  22, Train loss: 0.252, Test loss: 0.460, Test accuracy: 80.80
Round  23, Train loss: 0.247, Test loss: 0.573, Test accuracy: 77.90
Round  24, Train loss: 0.231, Test loss: 0.465, Test accuracy: 80.40
Round  25, Train loss: 0.230, Test loss: 0.538, Test accuracy: 78.70
Round  26, Train loss: 0.224, Test loss: 0.472, Test accuracy: 79.40
Round  27, Train loss: 0.211, Test loss: 0.471, Test accuracy: 79.70
Round  28, Train loss: 0.207, Test loss: 0.458, Test accuracy: 82.00
Round  29, Train loss: 0.190, Test loss: 0.505, Test accuracy: 78.70
Round  30, Train loss: 0.191, Test loss: 0.448, Test accuracy: 80.90
Round  31, Train loss: 0.165, Test loss: 0.520, Test accuracy: 80.10
Round  32, Train loss: 0.161, Test loss: 0.491, Test accuracy: 80.60
Round  33, Train loss: 0.160, Test loss: 0.504, Test accuracy: 80.60
Round  34, Train loss: 0.158, Test loss: 0.511, Test accuracy: 80.10
Round  35, Train loss: 0.132, Test loss: 0.472, Test accuracy: 81.20
Round  36, Train loss: 0.138, Test loss: 0.474, Test accuracy: 81.20
Round  37, Train loss: 0.141, Test loss: 0.480, Test accuracy: 80.80
Round  38, Train loss: 0.117, Test loss: 0.481, Test accuracy: 82.30
Round  39, Train loss: 0.119, Test loss: 0.498, Test accuracy: 82.10
Round  40, Train loss: 0.121, Test loss: 0.470, Test accuracy: 82.40
Round  41, Train loss: 0.097, Test loss: 0.531, Test accuracy: 81.60
Round  42, Train loss: 0.101, Test loss: 0.499, Test accuracy: 81.50
Round  43, Train loss: 0.106, Test loss: 0.537, Test accuracy: 81.70
Round  44, Train loss: 0.083, Test loss: 0.591, Test accuracy: 80.20
Round  45, Train loss: 0.062, Test loss: 0.522, Test accuracy: 82.90
Round  46, Train loss: 0.083, Test loss: 0.524, Test accuracy: 82.30
Round  47, Train loss: 0.064, Test loss: 0.526, Test accuracy: 82.90
Round  48, Train loss: 0.097, Test loss: 0.514, Test accuracy: 82.20
Round  49, Train loss: 0.084, Test loss: 0.518, Test accuracy: 82.20
Final Round, Train loss: 0.052, Test loss: 0.544, Test accuracy: 82.20
Average accuracy final 10 rounds: 81.99
560.5653884410858
[4.150183439254761, 6.263966083526611, 8.509626865386963, 10.55400562286377, 12.618085384368896, 14.721476078033447, 16.789491653442383, 18.857587099075317, 20.909868240356445, 23.0491886138916, 25.145716190338135, 27.271167993545532, 29.407878637313843, 31.505553722381592, 33.463385820388794, 35.58760356903076, 37.656819343566895, 39.73832297325134, 41.88817095756531, 43.965153217315674, 45.96127200126648, 48.05724096298218, 50.144662618637085, 52.25477480888367, 54.535558223724365, 56.87761068344116, 59.12894415855408, 61.33114051818848, 63.50101447105408, 65.5735354423523, 67.84306073188782, 69.92592096328735, 71.95408987998962, 73.94723010063171, 76.12740755081177, 78.10938048362732, 80.37277841567993, 82.68631720542908, 84.92671823501587, 87.25733304023743, 89.52445673942566, 91.61254501342773, 93.74793267250061, 95.97067952156067, 98.13768005371094, 100.2178328037262, 102.3714108467102, 104.41230392456055, 106.54412364959717, 108.68756318092346, 111.10417127609253]
[51.1, 62.5, 65.3, 66.2, 67.3, 70.4, 71.6, 71.2, 73.0, 75.6, 76.0, 75.5, 74.9, 75.7, 78.7, 75.7, 73.4, 77.3, 74.7, 80.6, 78.6, 80.1, 80.8, 77.9, 80.4, 78.7, 79.4, 79.7, 82.0, 78.7, 80.9, 80.1, 80.6, 80.6, 80.1, 81.2, 81.2, 80.8, 82.3, 82.1, 82.4, 81.6, 81.5, 81.7, 80.2, 82.9, 82.3, 82.9, 82.2, 82.2, 82.2]
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

Traceback (most recent call last):
  File "main_fedrep_increment2.py", line 219, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[c], first=True,isNew=True, local_eps=20)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 788, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.696, Test loss: 0.664, Test accuracy: 71.90 

Round   0, Global train loss: 0.696, Global test loss: 0.699, Global test accuracy: 51.20 

Round   1, Train loss: 0.526, Test loss: 0.563, Test accuracy: 76.60 

Round   1, Global train loss: 0.526, Global test loss: 0.703, Global test accuracy: 50.50 

Round   2, Train loss: 0.454, Test loss: 0.809, Test accuracy: 74.20 

Round   2, Global train loss: 0.454, Global test loss: 0.700, Global test accuracy: 50.50 

Round   3, Train loss: 0.405, Test loss: 0.674, Test accuracy: 77.30 

Round   3, Global train loss: 0.405, Global test loss: 0.695, Global test accuracy: 51.00 

Round   4, Train loss: 0.346, Test loss: 0.569, Test accuracy: 80.70 

Round   4, Global train loss: 0.346, Global test loss: 0.694, Global test accuracy: 50.00 

Round   5, Train loss: 0.293, Test loss: 0.816, Test accuracy: 76.90 

Round   5, Global train loss: 0.293, Global test loss: 0.701, Global test accuracy: 49.90 

Round   6, Train loss: 0.287, Test loss: 0.862, Test accuracy: 77.60 

Round   6, Global train loss: 0.287, Global test loss: 0.706, Global test accuracy: 50.30 

Round   7, Train loss: 0.237, Test loss: 0.738, Test accuracy: 80.30 

Round   7, Global train loss: 0.237, Global test loss: 0.694, Global test accuracy: 49.40 

Round   8, Train loss: 0.196, Test loss: 0.638, Test accuracy: 81.10 

Round   8, Global train loss: 0.196, Global test loss: 0.695, Global test accuracy: 50.40 

Round   9, Train loss: 0.209, Test loss: 0.783, Test accuracy: 78.40 

Round   9, Global train loss: 0.209, Global test loss: 0.710, Global test accuracy: 50.30 

Round  10, Train loss: 0.178, Test loss: 0.758, Test accuracy: 79.20 

Round  10, Global train loss: 0.178, Global test loss: 0.695, Global test accuracy: 49.40 

Round  11, Train loss: 0.123, Test loss: 0.835, Test accuracy: 79.60 

Round  11, Global train loss: 0.123, Global test loss: 0.706, Global test accuracy: 49.80 

Round  12, Train loss: 0.144, Test loss: 0.760, Test accuracy: 80.40 

Round  12, Global train loss: 0.144, Global test loss: 0.699, Global test accuracy: 50.20 

Round  13, Train loss: 0.125, Test loss: 0.733, Test accuracy: 80.30 

Round  13, Global train loss: 0.125, Global test loss: 0.695, Global test accuracy: 50.50 

Round  14, Train loss: 0.127, Test loss: 0.858, Test accuracy: 78.30 

Round  14, Global train loss: 0.127, Global test loss: 0.700, Global test accuracy: 49.40 

Round  15, Train loss: 0.111, Test loss: 0.805, Test accuracy: 81.00 

Round  15, Global train loss: 0.111, Global test loss: 0.709, Global test accuracy: 50.40 

Round  16, Train loss: 0.076, Test loss: 0.650, Test accuracy: 81.20 

Round  16, Global train loss: 0.076, Global test loss: 0.721, Global test accuracy: 50.20 

Round  17, Train loss: 0.091, Test loss: 0.785, Test accuracy: 81.70 

Round  17, Global train loss: 0.091, Global test loss: 0.718, Global test accuracy: 50.20 

Round  18, Train loss: 0.074, Test loss: 0.825, Test accuracy: 80.30 

Round  18, Global train loss: 0.074, Global test loss: 0.718, Global test accuracy: 50.20 

Round  19, Train loss: 0.076, Test loss: 1.125, Test accuracy: 79.70 

Round  19, Global train loss: 0.076, Global test loss: 0.696, Global test accuracy: 50.50 

Round  20, Train loss: 0.058, Test loss: 1.000, Test accuracy: 79.00 

Round  20, Global train loss: 0.058, Global test loss: 0.706, Global test accuracy: 49.70 

Round  21, Train loss: 0.052, Test loss: 0.714, Test accuracy: 82.10 

Round  21, Global train loss: 0.052, Global test loss: 0.701, Global test accuracy: 49.20 

Round  22, Train loss: 0.047, Test loss: 0.855, Test accuracy: 79.20 

Round  22, Global train loss: 0.047, Global test loss: 0.705, Global test accuracy: 50.10 

Round  23, Train loss: 0.049, Test loss: 0.801, Test accuracy: 82.70 

Round  23, Global train loss: 0.049, Global test loss: 0.704, Global test accuracy: 49.20 

Round  24, Train loss: 0.044, Test loss: 0.826, Test accuracy: 79.90 

Round  24, Global train loss: 0.044, Global test loss: 0.695, Global test accuracy: 50.90 

Round  25, Train loss: 0.040, Test loss: 0.790, Test accuracy: 81.60 

Round  25, Global train loss: 0.040, Global test loss: 0.700, Global test accuracy: 49.00 

Round  26, Train loss: 0.036, Test loss: 0.827, Test accuracy: 79.90 

Round  26, Global train loss: 0.036, Global test loss: 0.696, Global test accuracy: 50.90 

Round  27, Train loss: 0.034, Test loss: 0.796, Test accuracy: 82.20 

Round  27, Global train loss: 0.034, Global test loss: 0.697, Global test accuracy: 49.40 

Round  28, Train loss: 0.033, Test loss: 0.799, Test accuracy: 81.60 

Round  28, Global train loss: 0.033, Global test loss: 0.697, Global test accuracy: 49.50 

Round  29, Train loss: 0.027, Test loss: 0.813, Test accuracy: 82.30 

Round  29, Global train loss: 0.027, Global test loss: 0.705, Global test accuracy: 49.90 

Round  30, Train loss: 0.031, Test loss: 1.017, Test accuracy: 80.80 

Round  30, Global train loss: 0.031, Global test loss: 0.700, Global test accuracy: 48.70 

Round  31, Train loss: 0.019, Test loss: 0.859, Test accuracy: 83.50 

Round  31, Global train loss: 0.019, Global test loss: 0.699, Global test accuracy: 49.40 

Round  32, Train loss: 0.014, Test loss: 0.880, Test accuracy: 82.50 

Round  32, Global train loss: 0.014, Global test loss: 0.700, Global test accuracy: 48.80 

Round  33, Train loss: 0.016, Test loss: 0.905, Test accuracy: 83.00 

Round  33, Global train loss: 0.016, Global test loss: 0.702, Global test accuracy: 48.50 

Round  34, Train loss: 0.040, Test loss: 0.812, Test accuracy: 82.00 

Round  34, Global train loss: 0.040, Global test loss: 0.699, Global test accuracy: 49.10 

Final Round, Train loss: 0.020, Test loss: 0.828, Test accuracy: 82.20 

Final Round, Global train loss: 0.020, Global test loss: 0.699, Global test accuracy: 49.10 

Average accuracy final 10 rounds: 81.94 

Average global accuracy final 10 rounds: 49.32000000000001 

472.90048599243164
[4.320879220962524, 6.806532859802246, 9.091326713562012, 11.36661982536316, 13.911725759506226, 16.23076558113098, 18.433688163757324, 20.646119594573975, 22.942806482315063, 25.166197538375854, 27.929960250854492, 30.345078468322754, 32.70456266403198, 35.164297342300415, 37.44305610656738, 39.73844528198242, 42.198935985565186, 44.47876834869385, 46.807082414627075, 49.11155462265015, 51.49468398094177, 53.87663292884827, 56.18081188201904, 58.420878887176514, 60.69526767730713, 62.95254468917847, 65.21085000038147, 67.45770716667175, 69.6832685470581, 71.92878007888794, 74.20266842842102, 76.6065022945404, 79.1139087677002, 81.4045422077179, 83.77905464172363, 88.39470744132996]
[71.9, 76.6, 74.2, 77.3, 80.7, 76.9, 77.6, 80.3, 81.1, 78.4, 79.2, 79.6, 80.4, 80.3, 78.3, 81.0, 81.2, 81.7, 80.3, 79.7, 79.0, 82.1, 79.2, 82.7, 79.9, 81.6, 79.9, 82.2, 81.6, 82.3, 80.8, 83.5, 82.5, 83.0, 82.0, 82.2]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.704, Test loss: 0.602, Test accuracy: 72.10 

Round   0, Global train loss: 0.704, Global test loss: 0.700, Global test accuracy: 48.80 

Round   1, Train loss: 0.630, Test loss: 0.549, Test accuracy: 73.80 

Round   1, Global train loss: 0.630, Global test loss: 0.713, Global test accuracy: 51.10 

Round   2, Train loss: 0.571, Test loss: 0.538, Test accuracy: 75.40 

Round   2, Global train loss: 0.571, Global test loss: 0.713, Global test accuracy: 52.50 

Round   3, Train loss: 0.541, Test loss: 0.841, Test accuracy: 70.00 

Round   3, Global train loss: 0.541, Global test loss: 0.717, Global test accuracy: 55.10 

Round   4, Train loss: 0.490, Test loss: 0.604, Test accuracy: 74.70 

Round   4, Global train loss: 0.490, Global test loss: 0.673, Global test accuracy: 58.20 

Round   5, Train loss: 0.473, Test loss: 0.543, Test accuracy: 77.40 

Round   5, Global train loss: 0.473, Global test loss: 0.674, Global test accuracy: 59.70 

Round   6, Train loss: 0.453, Test loss: 0.652, Test accuracy: 75.50 

Round   6, Global train loss: 0.453, Global test loss: 0.685, Global test accuracy: 60.20 

Round   7, Train loss: 0.427, Test loss: 0.596, Test accuracy: 76.30 

Round   7, Global train loss: 0.427, Global test loss: 0.688, Global test accuracy: 62.20 

Round   8, Train loss: 0.399, Test loss: 0.683, Test accuracy: 78.10 

Round   8, Global train loss: 0.399, Global test loss: 0.720, Global test accuracy: 61.10 

Round   9, Train loss: 0.382, Test loss: 0.556, Test accuracy: 80.00 

Round   9, Global train loss: 0.382, Global test loss: 0.700, Global test accuracy: 61.80 

Round  10, Train loss: 0.359, Test loss: 0.853, Test accuracy: 79.00 

Round  10, Global train loss: 0.359, Global test loss: 0.772, Global test accuracy: 58.40 

Round  11, Train loss: 0.362, Test loss: 0.636, Test accuracy: 79.10 

Round  11, Global train loss: 0.362, Global test loss: 0.725, Global test accuracy: 61.80 

Round  12, Train loss: 0.348, Test loss: 0.680, Test accuracy: 78.00 

Round  12, Global train loss: 0.348, Global test loss: 0.761, Global test accuracy: 60.50 

Round  13, Train loss: 0.297, Test loss: 0.664, Test accuracy: 79.30 

Round  13, Global train loss: 0.297, Global test loss: 0.755, Global test accuracy: 61.40 

Round  14, Train loss: 0.304, Test loss: 0.613, Test accuracy: 78.70 

Round  14, Global train loss: 0.304, Global test loss: 0.752, Global test accuracy: 61.90 

Round  15, Train loss: 0.284, Test loss: 0.655, Test accuracy: 77.30 

Round  15, Global train loss: 0.284, Global test loss: 0.758, Global test accuracy: 60.20 

Round  16, Train loss: 0.281, Test loss: 0.721, Test accuracy: 78.60 

Round  16, Global train loss: 0.281, Global test loss: 0.829, Global test accuracy: 61.10 

Round  17, Train loss: 0.249, Test loss: 0.769, Test accuracy: 78.40 

Round  17, Global train loss: 0.249, Global test loss: 0.811, Global test accuracy: 62.10 

Round  18, Train loss: 0.248, Test loss: 0.650, Test accuracy: 82.10 

Round  18, Global train loss: 0.248, Global test loss: 0.827, Global test accuracy: 61.30 

Round  19, Train loss: 0.249, Test loss: 0.716, Test accuracy: 81.10 

Round  19, Global train loss: 0.249, Global test loss: 0.877, Global test accuracy: 60.80 

Round  20, Train loss: 0.244, Test loss: 0.687, Test accuracy: 80.70 

Round  20, Global train loss: 0.244, Global test loss: 0.835, Global test accuracy: 61.60 

Round  21, Train loss: 0.230, Test loss: 0.567, Test accuracy: 80.80 

Round  21, Global train loss: 0.230, Global test loss: 0.848, Global test accuracy: 60.80 

Round  22, Train loss: 0.200, Test loss: 0.844, Test accuracy: 77.40 

Round  22, Global train loss: 0.200, Global test loss: 0.855, Global test accuracy: 63.50 

Round  23, Train loss: 0.224, Test loss: 0.655, Test accuracy: 80.80 

Round  23, Global train loss: 0.224, Global test loss: 0.907, Global test accuracy: 61.80 

Round  24, Train loss: 0.178, Test loss: 0.983, Test accuracy: 77.40 

Round  24, Global train loss: 0.178, Global test loss: 0.898, Global test accuracy: 60.80 

Round  25, Train loss: 0.181, Test loss: 0.735, Test accuracy: 79.20 

Round  25, Global train loss: 0.181, Global test loss: 0.913, Global test accuracy: 64.10 

Round  26, Train loss: 0.186, Test loss: 0.675, Test accuracy: 80.80 

Round  26, Global train loss: 0.186, Global test loss: 0.883, Global test accuracy: 62.90 

Round  27, Train loss: 0.169, Test loss: 0.828, Test accuracy: 80.90 

Round  27, Global train loss: 0.169, Global test loss: 0.889, Global test accuracy: 62.20 

Round  28, Train loss: 0.177, Test loss: 0.736, Test accuracy: 78.70 

Round  28, Global train loss: 0.177, Global test loss: 0.932, Global test accuracy: 61.20 

Round  29, Train loss: 0.160, Test loss: 0.787, Test accuracy: 78.70 

Round  29, Global train loss: 0.160, Global test loss: 0.940, Global test accuracy: 61.20 

Round  30, Train loss: 0.144, Test loss: 0.713, Test accuracy: 80.50 

Round  30, Global train loss: 0.144, Global test loss: 0.955, Global test accuracy: 59.70 

Round  31, Train loss: 0.131, Test loss: 0.926, Test accuracy: 81.20 

Round  31, Global train loss: 0.131, Global test loss: 0.994, Global test accuracy: 62.60 

Round  32, Train loss: 0.138, Test loss: 0.767, Test accuracy: 79.70 

Round  32, Global train loss: 0.138, Global test loss: 0.967, Global test accuracy: 62.50 

Round  33, Train loss: 0.132, Test loss: 0.789, Test accuracy: 79.80 

Round  33, Global train loss: 0.132, Global test loss: 1.006, Global test accuracy: 60.90 

Round  34, Train loss: 0.120, Test loss: 1.351, Test accuracy: 79.50 

Round  34, Global train loss: 0.120, Global test loss: 1.068, Global test accuracy: 63.30 

Final Round, Train loss: 0.102, Test loss: 0.760, Test accuracy: 80.70 

Final Round, Global train loss: 0.102, Global test loss: 1.068, Global test accuracy: 63.30 

Average accuracy final 10 rounds: 79.9 

Average global accuracy final 10 rounds: 62.06 

482.3208498954773
[4.536710739135742, 6.845899343490601, 9.366708040237427, 11.74316668510437, 14.058454036712646, 16.368579626083374, 18.68011784553528, 20.98563838005066, 23.317596912384033, 25.679615259170532, 28.01391077041626, 30.42081093788147, 32.77577805519104, 35.20107388496399, 37.603416204452515, 39.968878507614136, 42.25990605354309, 44.61013436317444, 46.949296712875366, 49.406699895858765, 51.72580313682556, 54.18844699859619, 56.50298857688904, 58.94714641571045, 61.33100605010986, 63.60860276222229, 65.95497679710388, 68.40026879310608, 70.71182608604431, 73.13453435897827, 75.57867074012756, 77.85062742233276, 80.10698366165161, 82.73422598838806, 85.14771747589111, 89.87620234489441]
[72.1, 73.8, 75.4, 70.0, 74.7, 77.4, 75.5, 76.3, 78.1, 80.0, 79.0, 79.1, 78.0, 79.3, 78.7, 77.3, 78.6, 78.4, 82.1, 81.1, 80.7, 80.8, 77.4, 80.8, 77.4, 79.2, 80.8, 80.9, 78.7, 78.7, 80.5, 81.2, 79.7, 79.8, 79.5, 80.7]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.714, Test loss: 0.960, Test accuracy: 54.90 

Round   1, Train loss: 0.684, Test loss: 0.825, Test accuracy: 53.30 

Round   2, Train loss: 0.643, Test loss: 1.026, Test accuracy: 54.10 

Round   3, Train loss: 0.588, Test loss: 1.084, Test accuracy: 59.50 

Round   4, Train loss: 0.562, Test loss: 0.906, Test accuracy: 60.60 

Round   5, Train loss: 0.544, Test loss: 0.617, Test accuracy: 69.50 

Round   6, Train loss: 0.523, Test loss: 0.777, Test accuracy: 63.00 

Round   7, Train loss: 0.477, Test loss: 0.568, Test accuracy: 71.60 

Round   8, Train loss: 0.487, Test loss: 0.762, Test accuracy: 67.90 

Round   9, Train loss: 0.468, Test loss: 0.659, Test accuracy: 72.20 

Round  10, Train loss: 0.443, Test loss: 0.462, Test accuracy: 76.80 

Round  11, Train loss: 0.406, Test loss: 0.529, Test accuracy: 75.80 

Round  12, Train loss: 0.416, Test loss: 0.590, Test accuracy: 74.30 

Round  13, Train loss: 0.389, Test loss: 0.432, Test accuracy: 78.90 

Round  14, Train loss: 0.389, Test loss: 0.766, Test accuracy: 72.60 

Round  15, Train loss: 0.363, Test loss: 0.436, Test accuracy: 78.90 

Round  16, Train loss: 0.364, Test loss: 0.635, Test accuracy: 72.80 

Round  17, Train loss: 0.342, Test loss: 0.534, Test accuracy: 76.40 

Round  18, Train loss: 0.326, Test loss: 0.710, Test accuracy: 75.00 

Round  19, Train loss: 0.306, Test loss: 0.456, Test accuracy: 79.60 

Round  20, Train loss: 0.283, Test loss: 0.486, Test accuracy: 78.40 

Round  21, Train loss: 0.292, Test loss: 0.610, Test accuracy: 77.00 

Round  22, Train loss: 0.263, Test loss: 0.498, Test accuracy: 78.80 

Round  23, Train loss: 0.257, Test loss: 0.469, Test accuracy: 79.90 

Round  24, Train loss: 0.237, Test loss: 0.518, Test accuracy: 78.10 

Round  25, Train loss: 0.222, Test loss: 0.500, Test accuracy: 79.90 

Round  26, Train loss: 0.209, Test loss: 0.526, Test accuracy: 77.70 

Round  27, Train loss: 0.198, Test loss: 0.459, Test accuracy: 79.90 

Round  28, Train loss: 0.193, Test loss: 0.609, Test accuracy: 77.40 

Round  29, Train loss: 0.191, Test loss: 0.468, Test accuracy: 80.20 

Round  30, Train loss: 0.167, Test loss: 0.511, Test accuracy: 80.20 

Round  31, Train loss: 0.178, Test loss: 0.534, Test accuracy: 78.40 

Round  32, Train loss: 0.150, Test loss: 0.619, Test accuracy: 76.70 

Round  33, Train loss: 0.142, Test loss: 0.492, Test accuracy: 81.10 

Round  34, Train loss: 0.145, Test loss: 0.500, Test accuracy: 80.90 

Round  35, Train loss: 0.126, Test loss: 0.540, Test accuracy: 79.30 

Round  36, Train loss: 0.112, Test loss: 0.523, Test accuracy: 79.80 

Round  37, Train loss: 0.110, Test loss: 0.545, Test accuracy: 79.90 

Round  38, Train loss: 0.130, Test loss: 0.609, Test accuracy: 80.10 

Round  39, Train loss: 0.115, Test loss: 0.552, Test accuracy: 79.30 

Round  40, Train loss: 0.100, Test loss: 0.547, Test accuracy: 79.30 

Round  41, Train loss: 0.097, Test loss: 0.536, Test accuracy: 79.90 

Round  42, Train loss: 0.099, Test loss: 0.535, Test accuracy: 81.80 

Round  43, Train loss: 0.077, Test loss: 0.561, Test accuracy: 80.40 

Round  44, Train loss: 0.075, Test loss: 0.591, Test accuracy: 80.20 

Round  45, Train loss: 0.062, Test loss: 0.622, Test accuracy: 80.20 

Round  46, Train loss: 0.101, Test loss: 0.554, Test accuracy: 79.70 

Round  47, Train loss: 0.080, Test loss: 0.555, Test accuracy: 79.80 

Round  48, Train loss: 0.065, Test loss: 0.553, Test accuracy: 80.90 

Round  49, Train loss: 0.058, Test loss: 0.580, Test accuracy: 81.70 

Final Round, Train loss: 0.043, Test loss: 0.629, Test accuracy: 80.90 

Average accuracy final 10 rounds: 80.39 

501.2465145587921
[3.8493971824645996, 5.774319171905518, 7.586463689804077, 9.367387533187866, 11.254919052124023, 13.126204490661621, 14.982219934463501, 17.03492832183838, 18.91295289993286, 20.746666193008423, 22.59390115737915, 24.42703604698181, 26.271491765975952, 28.163883447647095, 30.070115566253662, 31.950876235961914, 33.78335666656494, 35.67091417312622, 37.52837300300598, 39.466909646987915, 41.27877736091614, 43.24673008918762, 45.09043216705322, 46.951420068740845, 48.88543152809143, 50.72698163986206, 52.53573513031006, 54.43391442298889, 56.32963991165161, 58.17952275276184, 60.00586485862732, 61.83559513092041, 63.684017181396484, 65.57846760749817, 67.43101143836975, 69.2253065109253, 71.1049132347107, 73.06513738632202, 74.89281010627747, 76.7664406299591, 78.61727929115295, 80.3413724899292, 82.2503023147583, 84.12585616111755, 85.96691870689392, 87.81466817855835, 89.8391478061676, 91.7542371749878, 93.70210194587708, 95.71493124961853, 97.85415291786194]
[54.9, 53.3, 54.1, 59.5, 60.6, 69.5, 63.0, 71.6, 67.9, 72.2, 76.8, 75.8, 74.3, 78.9, 72.6, 78.9, 72.8, 76.4, 75.0, 79.6, 78.4, 77.0, 78.8, 79.9, 78.1, 79.9, 77.7, 79.9, 77.4, 80.2, 80.2, 78.4, 76.7, 81.1, 80.9, 79.3, 79.8, 79.9, 80.1, 79.3, 79.3, 79.9, 81.8, 80.4, 80.2, 80.2, 79.7, 79.8, 80.9, 81.7, 80.9]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
Round   0, Train loss: 0.749, Test loss: 1.081, Test accuracy: 50.00
Round   1, Train loss: 0.669, Test loss: 0.811, Test accuracy: 55.10
Round   2, Train loss: 0.641, Test loss: 1.288, Test accuracy: 56.80
Round   3, Train loss: 0.591, Test loss: 1.223, Test accuracy: 61.60
Round   4, Train loss: 0.571, Test loss: 1.443, Test accuracy: 51.70
Round   5, Train loss: 0.567, Test loss: 0.792, Test accuracy: 62.10
Round   6, Train loss: 0.528, Test loss: 0.583, Test accuracy: 69.40
Round   7, Train loss: 0.508, Test loss: 0.840, Test accuracy: 70.50
Round   8, Train loss: 0.487, Test loss: 0.723, Test accuracy: 68.60
Round   9, Train loss: 0.452, Test loss: 0.521, Test accuracy: 73.70
Round  10, Train loss: 0.428, Test loss: 0.573, Test accuracy: 74.10
Round  11, Train loss: 0.425, Test loss: 0.516, Test accuracy: 76.40
Round  12, Train loss: 0.424, Test loss: 0.804, Test accuracy: 72.10
Round  13, Train loss: 0.407, Test loss: 0.494, Test accuracy: 77.20
Round  14, Train loss: 0.373, Test loss: 0.559, Test accuracy: 74.60
Round  15, Train loss: 0.350, Test loss: 0.588, Test accuracy: 74.40
Round  16, Train loss: 0.340, Test loss: 0.714, Test accuracy: 71.20
Round  17, Train loss: 0.343, Test loss: 0.416, Test accuracy: 80.80
Round  18, Train loss: 0.323, Test loss: 0.793, Test accuracy: 69.50
Round  19, Train loss: 0.315, Test loss: 0.467, Test accuracy: 78.60
Round  20, Train loss: 0.309, Test loss: 0.474, Test accuracy: 79.50
Round  21, Train loss: 0.279, Test loss: 0.641, Test accuracy: 74.70
Round  22, Train loss: 0.266, Test loss: 0.436, Test accuracy: 80.60
Round  23, Train loss: 0.254, Test loss: 0.639, Test accuracy: 75.10
Round  24, Train loss: 0.260, Test loss: 0.499, Test accuracy: 79.00
Round  25, Train loss: 0.228, Test loss: 0.507, Test accuracy: 78.00
Round  26, Train loss: 0.212, Test loss: 0.525, Test accuracy: 78.00
Round  27, Train loss: 0.217, Test loss: 0.478, Test accuracy: 80.50
Round  28, Train loss: 0.190, Test loss: 0.568, Test accuracy: 77.30
Round  29, Train loss: 0.193, Test loss: 0.535, Test accuracy: 77.90
Round  30, Train loss: 0.195, Test loss: 0.530, Test accuracy: 77.70
Round  31, Train loss: 0.182, Test loss: 0.563, Test accuracy: 77.40
Round  32, Train loss: 0.182, Test loss: 0.490, Test accuracy: 80.00
Round  33, Train loss: 0.163, Test loss: 0.641, Test accuracy: 76.70
Round  34, Train loss: 0.174, Test loss: 0.584, Test accuracy: 78.70
Round  35, Train loss: 0.145, Test loss: 0.593, Test accuracy: 78.70
Round  36, Train loss: 0.132, Test loss: 0.570, Test accuracy: 77.80
Round  37, Train loss: 0.133, Test loss: 0.577, Test accuracy: 78.00
Round  38, Train loss: 0.137, Test loss: 0.613, Test accuracy: 77.00
Round  39, Train loss: 0.127, Test loss: 0.494, Test accuracy: 81.20
Round  40, Train loss: 0.115, Test loss: 0.514, Test accuracy: 80.30
Round  41, Train loss: 0.103, Test loss: 0.507, Test accuracy: 80.50
Round  42, Train loss: 0.084, Test loss: 0.603, Test accuracy: 79.10
Round  43, Train loss: 0.117, Test loss: 0.635, Test accuracy: 76.60
Round  44, Train loss: 0.086, Test loss: 0.665, Test accuracy: 79.00
Round  45, Train loss: 0.089, Test loss: 0.537, Test accuracy: 79.80
Round  46, Train loss: 0.080, Test loss: 0.624, Test accuracy: 78.70
Round  47, Train loss: 0.071, Test loss: 0.551, Test accuracy: 81.40
Round  48, Train loss: 0.071, Test loss: 0.548, Test accuracy: 80.70
Round  49, Train loss: 0.062, Test loss: 0.562, Test accuracy: 80.80
Final Round, Train loss: 0.047, Test loss: 0.567, Test accuracy: 81.10
Average accuracy final 10 rounds: 79.68999999999998
552.8889307975769
[4.155089616775513, 6.175260066986084, 8.263575315475464, 10.279952764511108, 12.34700632095337, 14.338761329650879, 16.40968155860901, 18.567092418670654, 20.681941509246826, 22.823870420455933, 24.94650435447693, 26.932026863098145, 29.047539710998535, 31.34960412979126, 33.443615198135376, 35.48176455497742, 37.45991063117981, 39.55390167236328, 41.73234724998474, 43.97382950782776, 46.090604305267334, 48.1355881690979, 50.182116746902466, 52.243916511535645, 54.34546637535095, 56.320953607559204, 58.39645743370056, 60.581823110580444, 62.708887338638306, 64.78706097602844, 66.96539115905762, 69.08867859840393, 71.18231534957886, 73.15273857116699, 75.32159996032715, 77.33105683326721, 79.58804106712341, 81.73482489585876, 83.84010171890259, 85.92153120040894, 88.0606439113617, 90.15524816513062, 92.130784034729, 94.35345649719238, 96.44930982589722, 98.52912616729736, 100.76298880577087, 102.8253915309906, 104.87968587875366, 106.94593214988708, 108.91468334197998]
[50.0, 55.1, 56.8, 61.6, 51.7, 62.1, 69.4, 70.5, 68.6, 73.7, 74.1, 76.4, 72.1, 77.2, 74.6, 74.4, 71.2, 80.8, 69.5, 78.6, 79.5, 74.7, 80.6, 75.1, 79.0, 78.0, 78.0, 80.5, 77.3, 77.9, 77.7, 77.4, 80.0, 76.7, 78.7, 78.7, 77.8, 78.0, 77.0, 81.2, 80.3, 80.5, 79.1, 76.6, 79.0, 79.8, 78.7, 81.4, 80.7, 80.8, 81.1]
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

Traceback (most recent call last):
  File "main_fedrep_increment2.py", line 219, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[c], first=True,isNew=True, local_eps=20)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 788, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.549, Test loss: 1.477, Test accuracy: 41.50 

Round   0, Global train loss: 1.549, Global test loss: 1.480, Global test accuracy: 34.90 

Round   1, Train loss: 1.249, Test loss: 1.392, Test accuracy: 48.70 

Round   1, Global train loss: 1.249, Global test loss: 1.477, Global test accuracy: 35.10 

Round   2, Train loss: 1.080, Test loss: 1.284, Test accuracy: 51.90 

Round   2, Global train loss: 1.080, Global test loss: 1.707, Global test accuracy: 25.20 

Round   3, Train loss: 0.954, Test loss: 1.697, Test accuracy: 46.90 

Round   3, Global train loss: 0.954, Global test loss: 1.763, Global test accuracy: 24.40 

Round   4, Train loss: 0.835, Test loss: 1.398, Test accuracy: 54.70 

Round   4, Global train loss: 0.835, Global test loss: 1.838, Global test accuracy: 21.90 

Round   5, Train loss: 0.726, Test loss: 1.516, Test accuracy: 52.90 

Round   5, Global train loss: 0.726, Global test loss: 1.803, Global test accuracy: 24.00 

Round   6, Train loss: 0.617, Test loss: 1.613, Test accuracy: 54.90 

Round   6, Global train loss: 0.617, Global test loss: 1.836, Global test accuracy: 29.10 

Round   7, Train loss: 0.541, Test loss: 1.612, Test accuracy: 54.50 

Round   7, Global train loss: 0.541, Global test loss: 1.708, Global test accuracy: 30.40 

Round   8, Train loss: 0.459, Test loss: 1.726, Test accuracy: 53.60 

Round   8, Global train loss: 0.459, Global test loss: 1.755, Global test accuracy: 35.90 

Round   9, Train loss: 0.361, Test loss: 1.778, Test accuracy: 53.50 

Round   9, Global train loss: 0.361, Global test loss: 2.158, Global test accuracy: 29.60 

Round  10, Train loss: 0.325, Test loss: 1.782, Test accuracy: 55.40 

Round  10, Global train loss: 0.325, Global test loss: 2.036, Global test accuracy: 25.40 

Round  11, Train loss: 0.305, Test loss: 1.872, Test accuracy: 57.50 

Round  11, Global train loss: 0.305, Global test loss: 2.157, Global test accuracy: 23.50 

Round  12, Train loss: 0.238, Test loss: 1.658, Test accuracy: 59.50 

Round  12, Global train loss: 0.238, Global test loss: 1.942, Global test accuracy: 32.90 

Round  13, Train loss: 0.198, Test loss: 2.029, Test accuracy: 56.30 

Round  13, Global train loss: 0.198, Global test loss: 1.900, Global test accuracy: 31.00 

Round  14, Train loss: 0.184, Test loss: 1.932, Test accuracy: 59.10 

Round  14, Global train loss: 0.184, Global test loss: 2.109, Global test accuracy: 31.40 

Round  15, Train loss: 0.143, Test loss: 1.994, Test accuracy: 58.40 

Round  15, Global train loss: 0.143, Global test loss: 1.931, Global test accuracy: 33.80 

Round  16, Train loss: 0.143, Test loss: 1.935, Test accuracy: 58.90 

Round  16, Global train loss: 0.143, Global test loss: 2.043, Global test accuracy: 33.70 

Round  17, Train loss: 0.108, Test loss: 2.032, Test accuracy: 60.60 

Round  17, Global train loss: 0.108, Global test loss: 2.170, Global test accuracy: 30.10 

Round  18, Train loss: 0.102, Test loss: 2.071, Test accuracy: 59.70 

Round  18, Global train loss: 0.102, Global test loss: 2.133, Global test accuracy: 34.30 

Round  19, Train loss: 0.117, Test loss: 2.016, Test accuracy: 58.90 

Round  19, Global train loss: 0.117, Global test loss: 2.169, Global test accuracy: 34.20 

Round  20, Train loss: 0.096, Test loss: 2.102, Test accuracy: 59.40 

Round  20, Global train loss: 0.096, Global test loss: 2.114, Global test accuracy: 31.10 

Round  21, Train loss: 0.065, Test loss: 2.353, Test accuracy: 57.90 

Round  21, Global train loss: 0.065, Global test loss: 2.339, Global test accuracy: 29.00 

Round  22, Train loss: 0.055, Test loss: 2.231, Test accuracy: 60.10 

Round  22, Global train loss: 0.055, Global test loss: 2.237, Global test accuracy: 27.50 

Round  23, Train loss: 0.053, Test loss: 2.797, Test accuracy: 56.20 

Round  23, Global train loss: 0.053, Global test loss: 2.188, Global test accuracy: 29.20 

Round  24, Train loss: 0.099, Test loss: 2.155, Test accuracy: 59.00 

Round  24, Global train loss: 0.099, Global test loss: 2.254, Global test accuracy: 33.00 

Round  25, Train loss: 0.049, Test loss: 2.316, Test accuracy: 59.80 

Round  25, Global train loss: 0.049, Global test loss: 2.343, Global test accuracy: 27.90 

Round  26, Train loss: 0.051, Test loss: 2.536, Test accuracy: 59.00 

Round  26, Global train loss: 0.051, Global test loss: 2.401, Global test accuracy: 30.90 

Round  27, Train loss: 0.067, Test loss: 2.258, Test accuracy: 61.90 

Round  27, Global train loss: 0.067, Global test loss: 2.096, Global test accuracy: 33.00 

Round  28, Train loss: 0.041, Test loss: 2.246, Test accuracy: 59.50 

Round  28, Global train loss: 0.041, Global test loss: 2.239, Global test accuracy: 29.50 

Round  29, Train loss: 0.067, Test loss: 2.051, Test accuracy: 61.60 

Round  29, Global train loss: 0.067, Global test loss: 2.304, Global test accuracy: 32.60 

Round  30, Train loss: 0.044, Test loss: 2.151, Test accuracy: 59.40 

Round  30, Global train loss: 0.044, Global test loss: 2.461, Global test accuracy: 29.60 

Round  31, Train loss: 0.036, Test loss: 2.183, Test accuracy: 60.60 

Round  31, Global train loss: 0.036, Global test loss: 2.652, Global test accuracy: 25.50 

Round  32, Train loss: 0.020, Test loss: 2.241, Test accuracy: 61.00 

Round  32, Global train loss: 0.020, Global test loss: 2.685, Global test accuracy: 28.50 

Round  33, Train loss: 0.022, Test loss: 2.162, Test accuracy: 62.60 

Round  33, Global train loss: 0.022, Global test loss: 2.476, Global test accuracy: 30.50 

Round  34, Train loss: 0.022, Test loss: 2.220, Test accuracy: 61.60 

Round  34, Global train loss: 0.022, Global test loss: 2.324, Global test accuracy: 33.70 

Final Round, Train loss: 0.026, Test loss: 2.258, Test accuracy: 61.90 

Final Round, Global train loss: 0.026, Global test loss: 2.324, Global test accuracy: 33.70 

Average accuracy final 10 rounds: 60.7 

Average global accuracy final 10 rounds: 30.17 

469.26985812187195
[7.518069267272949, 13.066611766815186, 18.63146138191223, 24.266847372055054, 29.81808114051819, 35.56518197059631, 41.340463638305664, 47.00048470497131, 53.01798152923584, 58.588438987731934, 64.15031361579895, 69.77204918861389, 75.4169340133667, 81.11384320259094, 86.70748710632324, 92.34816884994507, 97.99007749557495, 103.91679382324219, 109.31905555725098, 114.78531312942505, 120.32024097442627, 125.84255075454712, 131.3533980846405, 136.9557547569275, 142.80109977722168, 148.55706000328064, 154.26129722595215, 159.85888600349426, 165.5599925518036, 171.18451499938965, 176.75694251060486, 182.4828999042511, 187.99107027053833, 193.7983479499817, 199.50331807136536, 210.9377999305725]
[41.5, 48.7, 51.9, 46.9, 54.7, 52.9, 54.9, 54.5, 53.6, 53.5, 55.4, 57.5, 59.5, 56.3, 59.1, 58.4, 58.9, 60.6, 59.7, 58.9, 59.4, 57.9, 60.1, 56.2, 59.0, 59.8, 59.0, 61.9, 59.5, 61.6, 59.4, 60.6, 61.0, 62.6, 61.6, 61.9]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.549, Test loss: 1.566, Test accuracy: 40.60 

Round   0, Global train loss: 1.549, Global test loss: 1.694, Global test accuracy: 25.20 

Round   1, Train loss: 1.372, Test loss: 1.494, Test accuracy: 45.50 

Round   1, Global train loss: 1.372, Global test loss: 1.827, Global test accuracy: 24.00 

Round   2, Train loss: 1.249, Test loss: 1.448, Test accuracy: 46.40 

Round   2, Global train loss: 1.249, Global test loss: 1.921, Global test accuracy: 26.40 

Round   3, Train loss: 1.125, Test loss: 1.304, Test accuracy: 54.90 

Round   3, Global train loss: 1.125, Global test loss: 1.394, Global test accuracy: 45.10 

Round   4, Train loss: 1.047, Test loss: 1.262, Test accuracy: 51.40 

Round   4, Global train loss: 1.047, Global test loss: 1.598, Global test accuracy: 37.40 

Round   5, Train loss: 0.961, Test loss: 1.408, Test accuracy: 53.00 

Round   5, Global train loss: 0.961, Global test loss: 1.471, Global test accuracy: 42.10 

Round   6, Train loss: 0.861, Test loss: 1.400, Test accuracy: 55.80 

Round   6, Global train loss: 0.861, Global test loss: 1.462, Global test accuracy: 46.00 

Round   7, Train loss: 0.810, Test loss: 1.596, Test accuracy: 51.80 

Round   7, Global train loss: 0.810, Global test loss: 1.720, Global test accuracy: 42.00 

Round   8, Train loss: 0.704, Test loss: 1.523, Test accuracy: 54.40 

Round   8, Global train loss: 0.704, Global test loss: 1.535, Global test accuracy: 48.70 

Round   9, Train loss: 0.643, Test loss: 1.592, Test accuracy: 54.00 

Round   9, Global train loss: 0.643, Global test loss: 1.734, Global test accuracy: 45.10 

Round  10, Train loss: 0.566, Test loss: 2.000, Test accuracy: 47.80 

Round  10, Global train loss: 0.566, Global test loss: 2.014, Global test accuracy: 41.30 

Round  11, Train loss: 0.539, Test loss: 2.021, Test accuracy: 55.80 

Round  11, Global train loss: 0.539, Global test loss: 2.123, Global test accuracy: 44.90 

Round  12, Train loss: 0.475, Test loss: 1.460, Test accuracy: 56.10 

Round  12, Global train loss: 0.475, Global test loss: 1.937, Global test accuracy: 45.10 

Round  13, Train loss: 0.400, Test loss: 1.502, Test accuracy: 59.90 

Round  13, Global train loss: 0.400, Global test loss: 1.799, Global test accuracy: 50.40 

Round  14, Train loss: 0.373, Test loss: 2.018, Test accuracy: 55.70 

Round  14, Global train loss: 0.373, Global test loss: 1.809, Global test accuracy: 50.30 

Round  15, Train loss: 0.340, Test loss: 2.301, Test accuracy: 52.70 

Round  15, Global train loss: 0.340, Global test loss: 2.092, Global test accuracy: 48.20 

Round  16, Train loss: 0.273, Test loss: 1.524, Test accuracy: 61.80 

Round  16, Global train loss: 0.273, Global test loss: 1.997, Global test accuracy: 48.50 

Round  17, Train loss: 0.296, Test loss: 1.607, Test accuracy: 62.80 

Round  17, Global train loss: 0.296, Global test loss: 1.937, Global test accuracy: 50.90 

Round  18, Train loss: 0.228, Test loss: 1.838, Test accuracy: 58.20 

Round  18, Global train loss: 0.228, Global test loss: 2.217, Global test accuracy: 49.20 

Round  19, Train loss: 0.186, Test loss: 2.028, Test accuracy: 60.30 

Round  19, Global train loss: 0.186, Global test loss: 2.392, Global test accuracy: 49.10 

Round  20, Train loss: 0.190, Test loss: 1.809, Test accuracy: 58.80 

Round  20, Global train loss: 0.190, Global test loss: 2.460, Global test accuracy: 48.00 

Round  21, Train loss: 0.202, Test loss: 1.877, Test accuracy: 61.10 

Round  21, Global train loss: 0.202, Global test loss: 2.038, Global test accuracy: 53.20 

Round  22, Train loss: 0.169, Test loss: 1.954, Test accuracy: 60.20 

Round  22, Global train loss: 0.169, Global test loss: 2.069, Global test accuracy: 51.80 

Round  23, Train loss: 0.150, Test loss: 1.925, Test accuracy: 59.90 

Round  23, Global train loss: 0.150, Global test loss: 2.395, Global test accuracy: 50.50 

Round  24, Train loss: 0.089, Test loss: 1.854, Test accuracy: 63.40 

Round  24, Global train loss: 0.089, Global test loss: 2.088, Global test accuracy: 56.00 

Round  25, Train loss: 0.158, Test loss: 2.046, Test accuracy: 59.30 

Round  25, Global train loss: 0.158, Global test loss: 2.505, Global test accuracy: 50.70 

Round  26, Train loss: 0.087, Test loss: 2.224, Test accuracy: 59.80 

Round  26, Global train loss: 0.087, Global test loss: 2.601, Global test accuracy: 50.30 

Round  27, Train loss: 0.109, Test loss: 2.214, Test accuracy: 60.30 

Round  27, Global train loss: 0.109, Global test loss: 2.676, Global test accuracy: 51.80 

Round  28, Train loss: 0.060, Test loss: 2.186, Test accuracy: 60.80 

Round  28, Global train loss: 0.060, Global test loss: 2.312, Global test accuracy: 54.00 

Round  29, Train loss: 0.093, Test loss: 2.084, Test accuracy: 61.20 

Round  29, Global train loss: 0.093, Global test loss: 2.335, Global test accuracy: 54.40 

Round  30, Train loss: 0.103, Test loss: 2.110, Test accuracy: 59.70 

Round  30, Global train loss: 0.103, Global test loss: 2.421, Global test accuracy: 51.90 

Round  31, Train loss: 0.063, Test loss: 1.887, Test accuracy: 62.90 

Round  31, Global train loss: 0.063, Global test loss: 2.208, Global test accuracy: 55.80 

Round  32, Train loss: 0.102, Test loss: 2.292, Test accuracy: 61.70 

Round  32, Global train loss: 0.102, Global test loss: 2.630, Global test accuracy: 51.20 

Round  33, Train loss: 0.041, Test loss: 2.069, Test accuracy: 63.00 

Round  33, Global train loss: 0.041, Global test loss: 2.409, Global test accuracy: 54.20 

Round  34, Train loss: 0.088, Test loss: 1.866, Test accuracy: 62.60 

Round  34, Global train loss: 0.088, Global test loss: 2.250, Global test accuracy: 55.20 

Final Round, Train loss: 0.052, Test loss: 2.053, Test accuracy: 63.30 

Final Round, Global train loss: 0.052, Global test loss: 2.250, Global test accuracy: 55.20 

Average accuracy final 10 rounds: 61.129999999999995 

Average global accuracy final 10 rounds: 52.949999999999996 

474.05718660354614
[7.662021160125732, 13.620599031448364, 19.359442472457886, 24.97349214553833, 30.72973895072937, 36.75484085083008, 42.3665075302124, 47.983007192611694, 53.67865324020386, 59.440210580825806, 65.16515445709229, 70.8621597290039, 76.61624431610107, 82.22728061676025, 87.89159560203552, 93.539071559906, 99.46063446998596, 105.25031280517578, 110.72000098228455, 116.37465000152588, 121.84332180023193, 127.49334192276001, 133.3235583305359, 138.96783328056335, 144.52238702774048, 150.22584581375122, 156.14002513885498, 161.69432020187378, 167.40871143341064, 173.12319254875183, 178.64635181427002, 184.53433227539062, 190.47963762283325, 196.09806895256042, 201.80258345603943, 213.17110323905945]
[40.6, 45.5, 46.4, 54.9, 51.4, 53.0, 55.8, 51.8, 54.4, 54.0, 47.8, 55.8, 56.1, 59.9, 55.7, 52.7, 61.8, 62.8, 58.2, 60.3, 58.8, 61.1, 60.2, 59.9, 63.4, 59.3, 59.8, 60.3, 60.8, 61.2, 59.7, 62.9, 61.7, 63.0, 62.6, 63.3]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 40, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.606, Test loss: 1.687, Test accuracy: 30.00 

Round   1, Train loss: 1.442, Test loss: 1.475, Test accuracy: 35.40 

Round   2, Train loss: 1.308, Test loss: 1.317, Test accuracy: 45.50 

Round   3, Train loss: 1.231, Test loss: 1.263, Test accuracy: 47.90 

Round   4, Train loss: 1.137, Test loss: 1.311, Test accuracy: 45.70 

Round   5, Train loss: 1.087, Test loss: 1.294, Test accuracy: 51.10 

Round   6, Train loss: 1.027, Test loss: 1.300, Test accuracy: 50.30 

Round   7, Train loss: 0.954, Test loss: 1.189, Test accuracy: 56.30 

Round   8, Train loss: 0.924, Test loss: 1.158, Test accuracy: 54.30 

Round   9, Train loss: 0.813, Test loss: 1.218, Test accuracy: 54.90 

Round  10, Train loss: 0.771, Test loss: 1.105, Test accuracy: 59.90 

Round  11, Train loss: 0.735, Test loss: 1.231, Test accuracy: 56.30 

Round  12, Train loss: 0.663, Test loss: 1.082, Test accuracy: 60.90 

Round  13, Train loss: 0.623, Test loss: 1.108, Test accuracy: 60.30 

Round  14, Train loss: 0.559, Test loss: 1.260, Test accuracy: 58.80 

Round  15, Train loss: 0.509, Test loss: 1.171, Test accuracy: 58.20 

Round  16, Train loss: 0.488, Test loss: 1.234, Test accuracy: 58.70 

Round  17, Train loss: 0.433, Test loss: 1.155, Test accuracy: 62.40 

Round  18, Train loss: 0.381, Test loss: 1.328, Test accuracy: 57.10 

Round  19, Train loss: 0.345, Test loss: 1.341, Test accuracy: 58.20 

Round  20, Train loss: 0.343, Test loss: 1.307, Test accuracy: 58.70 

Round  21, Train loss: 0.325, Test loss: 1.450, Test accuracy: 57.60 

Round  22, Train loss: 0.298, Test loss: 1.400, Test accuracy: 57.20 

Round  23, Train loss: 0.236, Test loss: 1.307, Test accuracy: 61.50 

Round  24, Train loss: 0.246, Test loss: 1.368, Test accuracy: 60.30 

Round  25, Train loss: 0.221, Test loss: 1.352, Test accuracy: 62.00 

Round  26, Train loss: 0.182, Test loss: 1.455, Test accuracy: 59.90 

Round  27, Train loss: 0.184, Test loss: 1.475, Test accuracy: 59.70 

Round  28, Train loss: 0.145, Test loss: 1.526, Test accuracy: 58.60 

Round  29, Train loss: 0.151, Test loss: 1.406, Test accuracy: 62.30 

Round  30, Train loss: 0.154, Test loss: 1.611, Test accuracy: 58.40 

Round  31, Train loss: 0.135, Test loss: 1.474, Test accuracy: 61.90 

Round  32, Train loss: 0.106, Test loss: 1.592, Test accuracy: 62.80 

Round  33, Train loss: 0.113, Test loss: 1.555, Test accuracy: 62.20 

Round  34, Train loss: 0.140, Test loss: 1.716, Test accuracy: 58.10 

Round  35, Train loss: 0.099, Test loss: 1.459, Test accuracy: 63.50 

Round  36, Train loss: 0.050, Test loss: 1.522, Test accuracy: 62.90 

Round  37, Train loss: 0.068, Test loss: 1.544, Test accuracy: 61.60 

Round  38, Train loss: 0.057, Test loss: 1.596, Test accuracy: 62.60 

Round  39, Train loss: 0.076, Test loss: 1.641, Test accuracy: 62.00 

Final Round, Train loss: 0.039, Test loss: 1.670, Test accuracy: 62.70 

Average accuracy final 10 rounds: 61.6 

387.0329043865204
[6.292743921279907, 10.626538515090942, 14.951075792312622, 19.400569677352905, 23.829662561416626, 28.333629369735718, 32.84627676010132, 37.4657826423645, 41.747416734695435, 46.167850732803345, 50.630372762680054, 55.16972255706787, 59.501848459243774, 63.917964935302734, 68.10984468460083, 72.41357564926147, 76.63768029212952, 80.95306086540222, 85.05926609039307, 89.85061383247375, 94.36863970756531, 98.98490810394287, 103.20450520515442, 107.70507764816284, 112.01320695877075, 116.49576473236084, 120.86021709442139, 125.1508150100708, 129.38637471199036, 133.9390766620636, 138.30717849731445, 142.7569625377655, 147.19334411621094, 151.4615399837494, 155.8417205810547, 160.06524443626404, 164.61195135116577, 169.09651350975037, 173.52739477157593, 177.775639295578, 182.64718866348267]
[30.0, 35.4, 45.5, 47.9, 45.7, 51.1, 50.3, 56.3, 54.3, 54.9, 59.9, 56.3, 60.9, 60.3, 58.8, 58.2, 58.7, 62.4, 57.1, 58.2, 58.7, 57.6, 57.2, 61.5, 60.3, 62.0, 59.9, 59.7, 58.6, 62.3, 58.4, 61.9, 62.8, 62.2, 58.1, 63.5, 62.9, 61.6, 62.6, 62.0, 62.7]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 40, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
Round   0, Train loss: 1.653, Test loss: 1.795, Test accuracy: 28.40
Round   1, Train loss: 1.441, Test loss: 1.493, Test accuracy: 36.30
Round   2, Train loss: 1.319, Test loss: 1.356, Test accuracy: 44.20
Round   3, Train loss: 1.231, Test loss: 1.277, Test accuracy: 50.70
Round   4, Train loss: 1.145, Test loss: 1.289, Test accuracy: 50.10
Round   5, Train loss: 1.100, Test loss: 1.289, Test accuracy: 50.70
Round   6, Train loss: 1.028, Test loss: 1.176, Test accuracy: 53.80
Round   7, Train loss: 0.988, Test loss: 1.227, Test accuracy: 52.10
Round   8, Train loss: 0.914, Test loss: 1.196, Test accuracy: 53.70
Round   9, Train loss: 0.871, Test loss: 1.188, Test accuracy: 53.40
Round  10, Train loss: 0.809, Test loss: 1.124, Test accuracy: 56.00
Round  11, Train loss: 0.745, Test loss: 1.147, Test accuracy: 57.50
Round  12, Train loss: 0.691, Test loss: 1.192, Test accuracy: 56.00
Round  13, Train loss: 0.629, Test loss: 1.180, Test accuracy: 57.20
Round  14, Train loss: 0.607, Test loss: 1.295, Test accuracy: 56.40
Round  15, Train loss: 0.563, Test loss: 1.215, Test accuracy: 57.20
Round  16, Train loss: 0.508, Test loss: 1.240, Test accuracy: 58.00
Round  17, Train loss: 0.476, Test loss: 1.201, Test accuracy: 59.50
Round  18, Train loss: 0.418, Test loss: 1.149, Test accuracy: 61.40
Round  19, Train loss: 0.370, Test loss: 1.325, Test accuracy: 58.80
Round  20, Train loss: 0.367, Test loss: 1.201, Test accuracy: 61.30
Round  21, Train loss: 0.305, Test loss: 1.289, Test accuracy: 60.50
Round  22, Train loss: 0.299, Test loss: 1.238, Test accuracy: 61.70
Round  23, Train loss: 0.277, Test loss: 1.240, Test accuracy: 62.10
Round  24, Train loss: 0.218, Test loss: 1.369, Test accuracy: 58.60
Round  25, Train loss: 0.240, Test loss: 1.450, Test accuracy: 59.30
Round  26, Train loss: 0.196, Test loss: 1.361, Test accuracy: 61.20
Round  27, Train loss: 0.175, Test loss: 1.366, Test accuracy: 61.00
Round  28, Train loss: 0.167, Test loss: 1.385, Test accuracy: 59.40
Round  29, Train loss: 0.174, Test loss: 1.367, Test accuracy: 61.50
Round  30, Train loss: 0.138, Test loss: 1.331, Test accuracy: 62.20
Round  31, Train loss: 0.133, Test loss: 1.439, Test accuracy: 61.30
Round  32, Train loss: 0.119, Test loss: 1.502, Test accuracy: 61.30
Round  33, Train loss: 0.123, Test loss: 1.538, Test accuracy: 59.50
Round  34, Train loss: 0.102, Test loss: 1.356, Test accuracy: 63.40
Round  35, Train loss: 0.105, Test loss: 1.434, Test accuracy: 61.50
Round  36, Train loss: 0.098, Test loss: 1.351, Test accuracy: 62.50
Round  37, Train loss: 0.069, Test loss: 1.473, Test accuracy: 62.80
Round  38, Train loss: 0.083, Test loss: 1.447, Test accuracy: 62.20
Round  39, Train loss: 0.072, Test loss: 1.483, Test accuracy: 62.60
Final Round, Train loss: 0.044, Test loss: 1.538, Test accuracy: 61.90
Average accuracy final 10 rounds: 61.93
434.7326936721802
[6.92021107673645, 11.843924522399902, 17.01631999015808, 22.019864797592163, 26.876951932907104, 31.93452763557434, 36.82590413093567, 41.896775245666504, 47.01094174385071, 52.303218126297, 57.49778747558594, 62.48077392578125, 67.64362812042236, 72.78945183753967, 78.08074808120728, 83.13178277015686, 88.043466091156, 93.0878496170044, 97.79227352142334, 102.96772885322571, 107.80447316169739, 112.7709436416626, 117.84050941467285, 122.85080480575562, 127.8342342376709, 132.7040388584137, 137.51191806793213, 142.47478675842285, 147.32745933532715, 152.32203006744385, 157.24027562141418, 162.23354578018188, 167.41841173171997, 172.48565673828125, 177.46048617362976, 182.1898114681244, 187.39872312545776, 192.3768424987793, 197.3818600177765, 202.25653743743896, 207.04541850090027]
[28.4, 36.3, 44.2, 50.7, 50.1, 50.7, 53.8, 52.1, 53.7, 53.4, 56.0, 57.5, 56.0, 57.2, 56.4, 57.2, 58.0, 59.5, 61.4, 58.8, 61.3, 60.5, 61.7, 62.1, 58.6, 59.3, 61.2, 61.0, 59.4, 61.5, 62.2, 61.3, 61.3, 59.5, 63.4, 61.5, 62.5, 62.8, 62.2, 62.6, 61.9]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

Traceback (most recent call last):
  File "main_fedrep_increment2.py", line 219, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[c], first=True,isNew=True, local_eps=20)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 788, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.362, Test loss: 1.425, Test accuracy: 46.00 

Round   0, Global train loss: 1.362, Global test loss: 1.913, Global test accuracy: 22.10 

Round   1, Train loss: 1.071, Test loss: 1.279, Test accuracy: 54.30 

Round   1, Global train loss: 1.071, Global test loss: 2.035, Global test accuracy: 26.50 

Round   2, Train loss: 0.907, Test loss: 1.294, Test accuracy: 55.30 

Round   2, Global train loss: 0.907, Global test loss: 2.062, Global test accuracy: 24.90 

Round   3, Train loss: 0.782, Test loss: 1.220, Test accuracy: 62.50 

Round   3, Global train loss: 0.782, Global test loss: 2.227, Global test accuracy: 25.50 

Round   4, Train loss: 0.693, Test loss: 1.305, Test accuracy: 63.00 

Round   4, Global train loss: 0.693, Global test loss: 2.136, Global test accuracy: 27.50 

Round   5, Train loss: 0.614, Test loss: 1.097, Test accuracy: 63.60 

Round   5, Global train loss: 0.614, Global test loss: 2.358, Global test accuracy: 25.10 

Round   6, Train loss: 0.509, Test loss: 1.177, Test accuracy: 65.60 

Round   6, Global train loss: 0.509, Global test loss: 2.985, Global test accuracy: 21.60 

Round   7, Train loss: 0.448, Test loss: 1.415, Test accuracy: 62.90 

Round   7, Global train loss: 0.448, Global test loss: 2.944, Global test accuracy: 21.60 

Round   8, Train loss: 0.382, Test loss: 1.323, Test accuracy: 64.40 

Round   8, Global train loss: 0.382, Global test loss: 3.028, Global test accuracy: 23.10 

Round   9, Train loss: 0.320, Test loss: 1.423, Test accuracy: 64.40 

Round   9, Global train loss: 0.320, Global test loss: 3.335, Global test accuracy: 22.40 

Round  10, Train loss: 0.279, Test loss: 1.409, Test accuracy: 67.20 

Round  10, Global train loss: 0.279, Global test loss: 3.523, Global test accuracy: 22.10 

Round  11, Train loss: 0.243, Test loss: 1.370, Test accuracy: 68.10 

Round  11, Global train loss: 0.243, Global test loss: 2.859, Global test accuracy: 25.50 

Round  12, Train loss: 0.205, Test loss: 1.418, Test accuracy: 67.00 

Round  12, Global train loss: 0.205, Global test loss: 3.434, Global test accuracy: 23.00 

Round  13, Train loss: 0.160, Test loss: 1.431, Test accuracy: 69.90 

Round  13, Global train loss: 0.160, Global test loss: 3.751, Global test accuracy: 22.90 

Round  14, Train loss: 0.158, Test loss: 1.539, Test accuracy: 65.70 

Round  14, Global train loss: 0.158, Global test loss: 3.819, Global test accuracy: 21.50 

Round  15, Train loss: 0.133, Test loss: 1.678, Test accuracy: 66.60 

Round  15, Global train loss: 0.133, Global test loss: 4.104, Global test accuracy: 21.70 

Round  16, Train loss: 0.132, Test loss: 1.508, Test accuracy: 68.80 

Round  16, Global train loss: 0.132, Global test loss: 4.552, Global test accuracy: 21.50 

Round  17, Train loss: 0.105, Test loss: 1.652, Test accuracy: 67.20 

Round  17, Global train loss: 0.105, Global test loss: 4.221, Global test accuracy: 21.50 

Round  18, Train loss: 0.115, Test loss: 1.419, Test accuracy: 69.90 

Round  18, Global train loss: 0.115, Global test loss: 4.771, Global test accuracy: 21.70 

Round  19, Train loss: 0.087, Test loss: 1.585, Test accuracy: 68.30 

Round  19, Global train loss: 0.087, Global test loss: 4.172, Global test accuracy: 21.90 

Round  20, Train loss: 0.077, Test loss: 1.756, Test accuracy: 67.20 

Round  20, Global train loss: 0.077, Global test loss: 5.084, Global test accuracy: 21.20 

Round  21, Train loss: 0.073, Test loss: 1.689, Test accuracy: 69.30 

Round  21, Global train loss: 0.073, Global test loss: 4.577, Global test accuracy: 21.90 

Round  22, Train loss: 0.079, Test loss: 1.597, Test accuracy: 71.10 

Round  22, Global train loss: 0.079, Global test loss: 3.690, Global test accuracy: 22.20 

Round  23, Train loss: 0.060, Test loss: 1.598, Test accuracy: 70.70 

Round  23, Global train loss: 0.060, Global test loss: 4.418, Global test accuracy: 22.00 

Round  24, Train loss: 0.049, Test loss: 1.551, Test accuracy: 70.50 

Round  24, Global train loss: 0.049, Global test loss: 5.456, Global test accuracy: 20.70 

Round  25, Train loss: 0.055, Test loss: 1.748, Test accuracy: 69.00 

Round  25, Global train loss: 0.055, Global test loss: 5.858, Global test accuracy: 20.90 

Round  26, Train loss: 0.056, Test loss: 1.739, Test accuracy: 67.90 

Round  26, Global train loss: 0.056, Global test loss: 5.835, Global test accuracy: 20.90 

Round  27, Train loss: 0.038, Test loss: 1.590, Test accuracy: 70.60 

Round  27, Global train loss: 0.038, Global test loss: 4.786, Global test accuracy: 21.10 

Round  28, Train loss: 0.041, Test loss: 1.682, Test accuracy: 70.80 

Round  28, Global train loss: 0.041, Global test loss: 4.705, Global test accuracy: 21.70 

Round  29, Train loss: 0.023, Test loss: 1.680, Test accuracy: 70.50 

Round  29, Global train loss: 0.023, Global test loss: 5.001, Global test accuracy: 21.00 

Round  30, Train loss: 0.030, Test loss: 1.801, Test accuracy: 68.50 

Round  30, Global train loss: 0.030, Global test loss: 4.840, Global test accuracy: 21.20 

Round  31, Train loss: 0.045, Test loss: 1.777, Test accuracy: 68.20 

Round  31, Global train loss: 0.045, Global test loss: 5.830, Global test accuracy: 20.50 

Round  32, Train loss: 0.022, Test loss: 1.714, Test accuracy: 71.40 

Round  32, Global train loss: 0.022, Global test loss: 5.690, Global test accuracy: 20.90 

Round  33, Train loss: 0.017, Test loss: 1.835, Test accuracy: 68.80 

Round  33, Global train loss: 0.017, Global test loss: 4.637, Global test accuracy: 21.90 

Round  34, Train loss: 0.023, Test loss: 1.697, Test accuracy: 71.80 

Round  34, Global train loss: 0.023, Global test loss: 4.757, Global test accuracy: 21.40 

Final Round, Train loss: 0.024, Test loss: 1.794, Test accuracy: 70.60 

Final Round, Global train loss: 0.024, Global test loss: 4.757, Global test accuracy: 21.40 

Average accuracy final 10 rounds: 69.75 

Average global accuracy final 10 rounds: 21.150000000000002 

465.6876208782196
[7.744419097900391, 12.977588891983032, 18.599852561950684, 24.332154035568237, 29.797770500183105, 35.233060121536255, 40.81128668785095, 46.47928309440613, 52.05743980407715, 57.806416511535645, 63.5063910484314, 69.15895938873291, 74.77603244781494, 80.48379230499268, 86.17751574516296, 91.6222996711731, 97.02778816223145, 102.5435266494751, 108.08189630508423, 113.86628937721252, 119.49474573135376, 125.47933793067932, 131.41565942764282, 136.8702528476715, 142.46068215370178, 148.3274703025818, 154.0726683139801, 159.7732970714569, 165.32410144805908, 171.1740746498108, 176.70809173583984, 182.71063423156738, 188.60482454299927, 194.4725215435028, 200.03965854644775, 210.85574889183044]
[46.0, 54.3, 55.3, 62.5, 63.0, 63.6, 65.6, 62.9, 64.4, 64.4, 67.2, 68.1, 67.0, 69.9, 65.7, 66.6, 68.8, 67.2, 69.9, 68.3, 67.2, 69.3, 71.1, 70.7, 70.5, 69.0, 67.9, 70.6, 70.8, 70.5, 68.5, 68.2, 71.4, 68.8, 71.8, 70.6]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.362, Test loss: 1.529, Test accuracy: 51.20 

Round   0, Global train loss: 1.362, Global test loss: 1.653, Global test accuracy: 29.70 

Round   1, Train loss: 1.163, Test loss: 1.274, Test accuracy: 58.30 

Round   1, Global train loss: 1.163, Global test loss: 1.479, Global test accuracy: 39.20 

Round   2, Train loss: 1.046, Test loss: 1.325, Test accuracy: 57.70 

Round   2, Global train loss: 1.046, Global test loss: 1.495, Global test accuracy: 39.70 

Round   3, Train loss: 0.934, Test loss: 1.195, Test accuracy: 59.70 

Round   3, Global train loss: 0.934, Global test loss: 1.443, Global test accuracy: 44.80 

Round   4, Train loss: 0.856, Test loss: 0.980, Test accuracy: 65.10 

Round   4, Global train loss: 0.856, Global test loss: 1.435, Global test accuracy: 46.90 

Round   5, Train loss: 0.762, Test loss: 1.081, Test accuracy: 66.00 

Round   5, Global train loss: 0.762, Global test loss: 1.364, Global test accuracy: 47.70 

Round   6, Train loss: 0.685, Test loss: 1.273, Test accuracy: 61.90 

Round   6, Global train loss: 0.685, Global test loss: 1.373, Global test accuracy: 48.40 

Round   7, Train loss: 0.613, Test loss: 1.276, Test accuracy: 62.90 

Round   7, Global train loss: 0.613, Global test loss: 1.415, Global test accuracy: 48.90 

Round   8, Train loss: 0.556, Test loss: 1.269, Test accuracy: 64.00 

Round   8, Global train loss: 0.556, Global test loss: 1.576, Global test accuracy: 48.80 

Round   9, Train loss: 0.494, Test loss: 1.478, Test accuracy: 62.50 

Round   9, Global train loss: 0.494, Global test loss: 1.627, Global test accuracy: 51.10 

Round  10, Train loss: 0.456, Test loss: 1.438, Test accuracy: 62.00 

Round  10, Global train loss: 0.456, Global test loss: 2.015, Global test accuracy: 46.00 

Round  11, Train loss: 0.389, Test loss: 1.378, Test accuracy: 65.50 

Round  11, Global train loss: 0.389, Global test loss: 1.676, Global test accuracy: 49.30 

Round  12, Train loss: 0.358, Test loss: 1.365, Test accuracy: 65.20 

Round  12, Global train loss: 0.358, Global test loss: 1.677, Global test accuracy: 53.10 

Round  13, Train loss: 0.321, Test loss: 1.405, Test accuracy: 64.20 

Round  13, Global train loss: 0.321, Global test loss: 1.731, Global test accuracy: 50.70 

Round  14, Train loss: 0.303, Test loss: 1.378, Test accuracy: 66.70 

Round  14, Global train loss: 0.303, Global test loss: 1.759, Global test accuracy: 53.00 

Round  15, Train loss: 0.252, Test loss: 1.283, Test accuracy: 68.70 

Round  15, Global train loss: 0.252, Global test loss: 1.695, Global test accuracy: 52.70 

Round  16, Train loss: 0.239, Test loss: 1.360, Test accuracy: 68.50 

Round  16, Global train loss: 0.239, Global test loss: 1.803, Global test accuracy: 51.00 

Round  17, Train loss: 0.209, Test loss: 1.525, Test accuracy: 65.70 

Round  17, Global train loss: 0.209, Global test loss: 1.825, Global test accuracy: 54.50 

Round  18, Train loss: 0.171, Test loss: 1.507, Test accuracy: 66.90 

Round  18, Global train loss: 0.171, Global test loss: 1.891, Global test accuracy: 52.40 

Round  19, Train loss: 0.183, Test loss: 1.415, Test accuracy: 68.20 

Round  19, Global train loss: 0.183, Global test loss: 2.024, Global test accuracy: 51.20 

Round  20, Train loss: 0.134, Test loss: 1.701, Test accuracy: 67.20 

Round  20, Global train loss: 0.134, Global test loss: 1.937, Global test accuracy: 53.90 

Round  21, Train loss: 0.149, Test loss: 1.621, Test accuracy: 67.10 

Round  21, Global train loss: 0.149, Global test loss: 2.266, Global test accuracy: 50.80 

Round  22, Train loss: 0.128, Test loss: 1.820, Test accuracy: 66.20 

Round  22, Global train loss: 0.128, Global test loss: 2.006, Global test accuracy: 53.90 

Round  23, Train loss: 0.113, Test loss: 1.589, Test accuracy: 69.60 

Round  23, Global train loss: 0.113, Global test loss: 2.082, Global test accuracy: 54.20 

Round  24, Train loss: 0.127, Test loss: 1.864, Test accuracy: 64.80 

Round  24, Global train loss: 0.127, Global test loss: 2.316, Global test accuracy: 51.00 

Round  25, Train loss: 0.101, Test loss: 1.729, Test accuracy: 64.40 

Round  25, Global train loss: 0.101, Global test loss: 2.176, Global test accuracy: 52.40 

Round  26, Train loss: 0.101, Test loss: 1.327, Test accuracy: 71.40 

Round  26, Global train loss: 0.101, Global test loss: 2.077, Global test accuracy: 53.20 

Round  27, Train loss: 0.072, Test loss: 1.749, Test accuracy: 67.20 

Round  27, Global train loss: 0.072, Global test loss: 2.230, Global test accuracy: 53.20 

Round  28, Train loss: 0.081, Test loss: 1.466, Test accuracy: 68.80 

Round  28, Global train loss: 0.081, Global test loss: 2.033, Global test accuracy: 55.60 

Round  29, Train loss: 0.063, Test loss: 1.567, Test accuracy: 69.40 

Round  29, Global train loss: 0.063, Global test loss: 2.157, Global test accuracy: 55.70 

Round  30, Train loss: 0.071, Test loss: 1.587, Test accuracy: 69.40 

Round  30, Global train loss: 0.071, Global test loss: 2.227, Global test accuracy: 52.70 

Round  31, Train loss: 0.081, Test loss: 1.656, Test accuracy: 68.60 

Round  31, Global train loss: 0.081, Global test loss: 2.201, Global test accuracy: 55.90 

Round  32, Train loss: 0.093, Test loss: 1.845, Test accuracy: 67.10 

Round  32, Global train loss: 0.093, Global test loss: 2.252, Global test accuracy: 53.70 

Round  33, Train loss: 0.040, Test loss: 1.533, Test accuracy: 69.80 

Round  33, Global train loss: 0.040, Global test loss: 2.201, Global test accuracy: 53.60 

Round  34, Train loss: 0.042, Test loss: 1.624, Test accuracy: 70.80 

Round  34, Global train loss: 0.042, Global test loss: 2.276, Global test accuracy: 56.60 

Final Round, Train loss: 0.054, Test loss: 1.665, Test accuracy: 70.10 

Final Round, Global train loss: 0.054, Global test loss: 2.276, Global test accuracy: 56.60 

Average accuracy final 10 rounds: 68.69 

Average global accuracy final 10 rounds: 54.260000000000005 

469.0412449836731
[7.865054130554199, 13.517364740371704, 19.116798162460327, 24.737783908843994, 30.168880701065063, 35.767974615097046, 41.25637340545654, 46.82732033729553, 52.385435819625854, 57.99288558959961, 63.7766695022583, 69.36694979667664, 75.0781877040863, 80.86338305473328, 86.51762056350708, 92.36312198638916, 98.2229905128479, 104.10898017883301, 109.68389368057251, 115.54889392852783, 121.11507034301758, 127.06448459625244, 132.63403463363647, 138.15569758415222, 143.8114676475525, 149.75991034507751, 155.5533263683319, 161.13808631896973, 166.84313464164734, 172.5714328289032, 178.14724779129028, 183.66057777404785, 189.33758544921875, 194.98645496368408, 200.37198853492737, 211.65028548240662]
[51.2, 58.3, 57.7, 59.7, 65.1, 66.0, 61.9, 62.9, 64.0, 62.5, 62.0, 65.5, 65.2, 64.2, 66.7, 68.7, 68.5, 65.7, 66.9, 68.2, 67.2, 67.1, 66.2, 69.6, 64.8, 64.4, 71.4, 67.2, 68.8, 69.4, 69.4, 68.6, 67.1, 69.8, 70.8, 70.1]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 40, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.479, Test loss: 1.476, Test accuracy: 33.60 

Round   1, Train loss: 1.232, Test loss: 1.533, Test accuracy: 38.60 

Round   2, Train loss: 1.097, Test loss: 1.198, Test accuracy: 54.10 

Round   3, Train loss: 1.001, Test loss: 0.992, Test accuracy: 62.40 

Round   4, Train loss: 0.931, Test loss: 1.121, Test accuracy: 59.40 

Round   5, Train loss: 0.855, Test loss: 0.964, Test accuracy: 64.70 

Round   6, Train loss: 0.804, Test loss: 0.954, Test accuracy: 65.60 

Round   7, Train loss: 0.747, Test loss: 0.953, Test accuracy: 65.00 

Round   8, Train loss: 0.680, Test loss: 0.943, Test accuracy: 65.10 

Round   9, Train loss: 0.640, Test loss: 0.978, Test accuracy: 65.70 

Round  10, Train loss: 0.604, Test loss: 0.989, Test accuracy: 65.80 

Round  11, Train loss: 0.565, Test loss: 1.012, Test accuracy: 66.00 

Round  12, Train loss: 0.503, Test loss: 1.003, Test accuracy: 65.10 

Round  13, Train loss: 0.471, Test loss: 1.060, Test accuracy: 67.80 

Round  14, Train loss: 0.443, Test loss: 0.995, Test accuracy: 67.30 

Round  15, Train loss: 0.377, Test loss: 1.034, Test accuracy: 68.70 

Round  16, Train loss: 0.376, Test loss: 1.004, Test accuracy: 68.70 

Round  17, Train loss: 0.337, Test loss: 0.985, Test accuracy: 69.10 

Round  18, Train loss: 0.289, Test loss: 1.052, Test accuracy: 68.50 

Round  19, Train loss: 0.268, Test loss: 1.087, Test accuracy: 69.80 

Round  20, Train loss: 0.252, Test loss: 1.098, Test accuracy: 67.30 

Round  21, Train loss: 0.219, Test loss: 1.172, Test accuracy: 68.70 

Round  22, Train loss: 0.222, Test loss: 1.050, Test accuracy: 70.20 

Round  23, Train loss: 0.201, Test loss: 1.008, Test accuracy: 70.70 

Round  24, Train loss: 0.172, Test loss: 1.100, Test accuracy: 69.60 

Round  25, Train loss: 0.179, Test loss: 1.159, Test accuracy: 68.70 

Round  26, Train loss: 0.133, Test loss: 1.209, Test accuracy: 69.70 

Round  27, Train loss: 0.105, Test loss: 1.254, Test accuracy: 69.30 

Round  28, Train loss: 0.136, Test loss: 1.240, Test accuracy: 68.90 

Round  29, Train loss: 0.119, Test loss: 1.207, Test accuracy: 70.80 

Round  30, Train loss: 0.112, Test loss: 1.166, Test accuracy: 70.60 

Round  31, Train loss: 0.101, Test loss: 1.235, Test accuracy: 70.60 

Round  32, Train loss: 0.072, Test loss: 1.321, Test accuracy: 69.20 

Round  33, Train loss: 0.081, Test loss: 1.213, Test accuracy: 70.70 

Round  34, Train loss: 0.084, Test loss: 1.284, Test accuracy: 71.40 

Round  35, Train loss: 0.082, Test loss: 1.344, Test accuracy: 71.10 

Round  36, Train loss: 0.089, Test loss: 1.254, Test accuracy: 71.40 

Round  37, Train loss: 0.057, Test loss: 1.241, Test accuracy: 71.70 

Round  38, Train loss: 0.061, Test loss: 1.288, Test accuracy: 71.10 

Round  39, Train loss: 0.052, Test loss: 1.308, Test accuracy: 71.60 

Final Round, Train loss: 0.026, Test loss: 1.301, Test accuracy: 71.30 

Average accuracy final 10 rounds: 70.94 

386.604688167572
[6.465874910354614, 10.801028490066528, 15.158463716506958, 19.363940000534058, 24.019285917282104, 28.351540565490723, 32.6339795589447, 36.88794207572937, 41.13321542739868, 45.62896513938904, 49.90199685096741, 54.17126131057739, 58.37981939315796, 62.64974331855774, 66.97575879096985, 71.48577451705933, 75.84491467475891, 80.2652747631073, 84.51909184455872, 89.12477040290833, 93.71885681152344, 98.50901889801025, 102.91054797172546, 107.39318513870239, 111.63247394561768, 115.98680281639099, 120.55893778800964, 124.87835121154785, 129.20713686943054, 133.65763115882874, 138.16194128990173, 142.5093469619751, 146.67890524864197, 151.12468600273132, 155.5758900642395, 159.90898776054382, 164.4976246356964, 168.9175570011139, 173.20667386054993, 177.40359616279602, 181.74086618423462]
[33.6, 38.6, 54.1, 62.4, 59.4, 64.7, 65.6, 65.0, 65.1, 65.7, 65.8, 66.0, 65.1, 67.8, 67.3, 68.7, 68.7, 69.1, 68.5, 69.8, 67.3, 68.7, 70.2, 70.7, 69.6, 68.7, 69.7, 69.3, 68.9, 70.8, 70.6, 70.6, 69.2, 70.7, 71.4, 71.1, 71.4, 71.7, 71.1, 71.6, 71.3]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 40, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
Round   0, Train loss: 1.525, Test loss: 1.982, Test accuracy: 27.90
Round   1, Train loss: 1.257, Test loss: 1.324, Test accuracy: 44.00
Round   2, Train loss: 1.107, Test loss: 1.217, Test accuracy: 51.40
Round   3, Train loss: 1.021, Test loss: 1.099, Test accuracy: 58.10
Round   4, Train loss: 0.937, Test loss: 0.982, Test accuracy: 62.50
Round   5, Train loss: 0.862, Test loss: 0.983, Test accuracy: 61.90
Round   6, Train loss: 0.804, Test loss: 0.910, Test accuracy: 64.60
Round   7, Train loss: 0.745, Test loss: 0.942, Test accuracy: 65.00
Round   8, Train loss: 0.683, Test loss: 0.992, Test accuracy: 65.50
Round   9, Train loss: 0.654, Test loss: 1.058, Test accuracy: 63.60
Round  10, Train loss: 0.595, Test loss: 1.031, Test accuracy: 64.90
Round  11, Train loss: 0.524, Test loss: 0.959, Test accuracy: 66.60
Round  12, Train loss: 0.499, Test loss: 0.979, Test accuracy: 66.80
Round  13, Train loss: 0.458, Test loss: 0.960, Test accuracy: 69.30
Round  14, Train loss: 0.439, Test loss: 1.025, Test accuracy: 65.80
Round  15, Train loss: 0.421, Test loss: 0.978, Test accuracy: 67.60
Round  16, Train loss: 0.353, Test loss: 1.004, Test accuracy: 68.20
Round  17, Train loss: 0.316, Test loss: 1.015, Test accuracy: 69.90
Round  18, Train loss: 0.296, Test loss: 1.017, Test accuracy: 69.20
Round  19, Train loss: 0.268, Test loss: 1.003, Test accuracy: 69.60
Round  20, Train loss: 0.245, Test loss: 1.087, Test accuracy: 68.60
Round  21, Train loss: 0.233, Test loss: 1.014, Test accuracy: 69.40
Round  22, Train loss: 0.214, Test loss: 1.070, Test accuracy: 70.20
Round  23, Train loss: 0.191, Test loss: 1.106, Test accuracy: 69.40
Round  24, Train loss: 0.197, Test loss: 1.097, Test accuracy: 68.50
Round  25, Train loss: 0.147, Test loss: 1.138, Test accuracy: 69.50
Round  26, Train loss: 0.136, Test loss: 1.121, Test accuracy: 69.50
Round  27, Train loss: 0.162, Test loss: 1.129, Test accuracy: 70.30
Round  28, Train loss: 0.117, Test loss: 1.154, Test accuracy: 69.70
Round  29, Train loss: 0.135, Test loss: 1.106, Test accuracy: 70.60
Round  30, Train loss: 0.115, Test loss: 1.205, Test accuracy: 70.50
Round  31, Train loss: 0.102, Test loss: 1.152, Test accuracy: 69.00
Round  32, Train loss: 0.098, Test loss: 1.143, Test accuracy: 70.40
Round  33, Train loss: 0.090, Test loss: 1.213, Test accuracy: 70.20
Round  34, Train loss: 0.077, Test loss: 1.205, Test accuracy: 69.40
Round  35, Train loss: 0.062, Test loss: 1.236, Test accuracy: 69.70
Round  36, Train loss: 0.080, Test loss: 1.280, Test accuracy: 68.50
Round  37, Train loss: 0.062, Test loss: 1.291, Test accuracy: 69.70
Round  38, Train loss: 0.068, Test loss: 1.256, Test accuracy: 70.30
Round  39, Train loss: 0.068, Test loss: 1.243, Test accuracy: 70.20
Final Round, Train loss: 0.042, Test loss: 1.219, Test accuracy: 70.90
Average accuracy final 10 rounds: 69.79
430.316246509552
[6.824570178985596, 11.6669180393219, 16.614768028259277, 21.448594093322754, 26.31126570701599, 31.438176155090332, 36.51214814186096, 41.93930125236511, 46.95019841194153, 51.88428211212158, 56.974854707717896, 62.195456743240356, 67.06538414955139, 71.77271890640259, 76.702707529068, 81.60114312171936, 86.484454870224, 91.45848035812378, 96.42006134986877, 101.2820451259613, 106.10770082473755, 111.16000771522522, 116.09221768379211, 120.89184951782227, 125.81950044631958, 130.70730638504028, 135.52213716506958, 140.59859800338745, 145.64422345161438, 150.66561150550842, 155.52713656425476, 160.59803581237793, 165.6004354953766, 170.45855712890625, 175.41448140144348, 180.26842665672302, 185.13819980621338, 189.90336966514587, 194.71671724319458, 199.534836769104, 204.23255610466003]
[27.9, 44.0, 51.4, 58.1, 62.5, 61.9, 64.6, 65.0, 65.5, 63.6, 64.9, 66.6, 66.8, 69.3, 65.8, 67.6, 68.2, 69.9, 69.2, 69.6, 68.6, 69.4, 70.2, 69.4, 68.5, 69.5, 69.5, 70.3, 69.7, 70.6, 70.5, 69.0, 70.4, 70.2, 69.4, 69.7, 68.5, 69.7, 70.3, 70.2, 70.9]
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

Traceback (most recent call last):
  File "main_fedrep_increment2.py", line 219, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[c], first=True,isNew=True, local_eps=20)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 788, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
