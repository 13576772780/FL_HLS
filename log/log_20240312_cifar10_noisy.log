nohup: ignoring input
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.634, Test loss: 1.925, Test accuracy: 25.35
Round   0, Global train loss: 1.634, Global test loss: 2.139, Global test accuracy: 19.27
Round   1, Train loss: 1.387, Test loss: 1.785, Test accuracy: 30.50
Round   1, Global train loss: 1.387, Global test loss: 2.211, Global test accuracy: 18.74
Round   2, Train loss: 1.275, Test loss: 1.476, Test accuracy: 42.83
Round   2, Global train loss: 1.275, Global test loss: 2.066, Global test accuracy: 29.66
Round   3, Train loss: 1.217, Test loss: 1.276, Test accuracy: 48.30
Round   3, Global train loss: 1.217, Global test loss: 1.739, Global test accuracy: 38.52
Round   4, Train loss: 1.163, Test loss: 1.242, Test accuracy: 49.59
Round   4, Global train loss: 1.163, Global test loss: 2.020, Global test accuracy: 33.60
Round   5, Train loss: 1.070, Test loss: 1.170, Test accuracy: 52.09
Round   5, Global train loss: 1.070, Global test loss: 1.858, Global test accuracy: 37.37
Round   6, Train loss: 1.005, Test loss: 1.162, Test accuracy: 52.89
Round   6, Global train loss: 1.005, Global test loss: 1.986, Global test accuracy: 34.02
Round   7, Train loss: 1.104, Test loss: 1.172, Test accuracy: 52.90
Round   7, Global train loss: 1.104, Global test loss: 2.031, Global test accuracy: 30.22
Round   8, Train loss: 0.963, Test loss: 1.102, Test accuracy: 55.06
Round   8, Global train loss: 0.963, Global test loss: 1.716, Global test accuracy: 39.60
Round   9, Train loss: 0.961, Test loss: 1.145, Test accuracy: 54.22
Round   9, Global train loss: 0.961, Global test loss: 2.262, Global test accuracy: 25.39
Round  10, Train loss: 0.859, Test loss: 1.115, Test accuracy: 55.41
Round  10, Global train loss: 0.859, Global test loss: 2.003, Global test accuracy: 35.02
Round  11, Train loss: 0.932, Test loss: 1.105, Test accuracy: 56.02
Round  11, Global train loss: 0.932, Global test loss: 1.758, Global test accuracy: 38.09
Round  12, Train loss: 0.944, Test loss: 1.082, Test accuracy: 56.34
Round  12, Global train loss: 0.944, Global test loss: 1.740, Global test accuracy: 36.67
Round  13, Train loss: 0.895, Test loss: 1.068, Test accuracy: 57.21
Round  13, Global train loss: 0.895, Global test loss: 1.950, Global test accuracy: 26.95
Round  14, Train loss: 0.876, Test loss: 1.040, Test accuracy: 58.74
Round  14, Global train loss: 0.876, Global test loss: 1.882, Global test accuracy: 31.35
Round  15, Train loss: 0.863, Test loss: 1.031, Test accuracy: 59.23
Round  15, Global train loss: 0.863, Global test loss: 1.829, Global test accuracy: 36.41
Round  16, Train loss: 0.780, Test loss: 1.043, Test accuracy: 59.10
Round  16, Global train loss: 0.780, Global test loss: 1.895, Global test accuracy: 38.39
Round  17, Train loss: 0.834, Test loss: 1.036, Test accuracy: 59.49
Round  17, Global train loss: 0.834, Global test loss: 2.042, Global test accuracy: 29.63
Round  18, Train loss: 0.679, Test loss: 1.051, Test accuracy: 59.77
Round  18, Global train loss: 0.679, Global test loss: 1.782, Global test accuracy: 34.89
Round  19, Train loss: 0.770, Test loss: 1.034, Test accuracy: 60.44
Round  19, Global train loss: 0.770, Global test loss: 1.717, Global test accuracy: 39.69
Round  20, Train loss: 0.777, Test loss: 1.022, Test accuracy: 60.99
Round  20, Global train loss: 0.777, Global test loss: 1.824, Global test accuracy: 33.62
Round  21, Train loss: 0.657, Test loss: 1.021, Test accuracy: 61.57
Round  21, Global train loss: 0.657, Global test loss: 1.874, Global test accuracy: 39.80
Round  22, Train loss: 0.699, Test loss: 1.035, Test accuracy: 61.56
Round  22, Global train loss: 0.699, Global test loss: 1.695, Global test accuracy: 46.66
Round  23, Train loss: 0.751, Test loss: 1.041, Test accuracy: 61.61
Round  23, Global train loss: 0.751, Global test loss: 1.815, Global test accuracy: 31.79
Round  24, Train loss: 0.663, Test loss: 1.037, Test accuracy: 62.17
Round  24, Global train loss: 0.663, Global test loss: 1.863, Global test accuracy: 34.06
Round  25, Train loss: 0.642, Test loss: 1.070, Test accuracy: 61.65
Round  25, Global train loss: 0.642, Global test loss: 1.928, Global test accuracy: 31.85
Round  26, Train loss: 0.676, Test loss: 1.074, Test accuracy: 61.68
Round  26, Global train loss: 0.676, Global test loss: 1.915, Global test accuracy: 35.38
Round  27, Train loss: 0.549, Test loss: 1.075, Test accuracy: 61.91
Round  27, Global train loss: 0.549, Global test loss: 1.836, Global test accuracy: 39.81
Round  28, Train loss: 0.526, Test loss: 1.080, Test accuracy: 62.14
Round  28, Global train loss: 0.526, Global test loss: 1.847, Global test accuracy: 36.43
Round  29, Train loss: 0.667, Test loss: 1.089, Test accuracy: 62.49
Round  29, Global train loss: 0.667, Global test loss: 1.834, Global test accuracy: 36.63
Round  30, Train loss: 0.494, Test loss: 1.099, Test accuracy: 62.92
Round  30, Global train loss: 0.494, Global test loss: 1.728, Global test accuracy: 35.93
Round  31, Train loss: 0.488, Test loss: 1.111, Test accuracy: 62.86
Round  31, Global train loss: 0.488, Global test loss: 1.828, Global test accuracy: 37.01
Round  32, Train loss: 0.533, Test loss: 1.134, Test accuracy: 62.75
Round  32, Global train loss: 0.533, Global test loss: 1.769, Global test accuracy: 38.55
Round  33, Train loss: 0.471, Test loss: 1.151, Test accuracy: 62.44
Round  33, Global train loss: 0.471, Global test loss: 1.922, Global test accuracy: 35.98
Round  34, Train loss: 0.422, Test loss: 1.185, Test accuracy: 62.41
Round  34, Global train loss: 0.422, Global test loss: 1.931, Global test accuracy: 36.51
Round  35, Train loss: 0.477, Test loss: 1.201, Test accuracy: 62.64
Round  35, Global train loss: 0.477, Global test loss: 1.829, Global test accuracy: 35.61
Round  36, Train loss: 0.600, Test loss: 1.229, Test accuracy: 62.85
Round  36, Global train loss: 0.600, Global test loss: 1.836, Global test accuracy: 39.60
Round  37, Train loss: 0.372, Test loss: 1.224, Test accuracy: 62.66
Round  37, Global train loss: 0.372, Global test loss: 1.745, Global test accuracy: 39.81
Round  38, Train loss: 0.539, Test loss: 1.214, Test accuracy: 63.31
Round  38, Global train loss: 0.539, Global test loss: 1.874, Global test accuracy: 33.46
Round  39, Train loss: 0.400, Test loss: 1.199, Test accuracy: 63.21
Round  39, Global train loss: 0.400, Global test loss: 1.940, Global test accuracy: 39.21
Round  40, Train loss: 0.338, Test loss: 1.203, Test accuracy: 63.27
Round  40, Global train loss: 0.338, Global test loss: 1.788, Global test accuracy: 40.21
Round  41, Train loss: 0.412, Test loss: 1.221, Test accuracy: 63.27
Round  41, Global train loss: 0.412, Global test loss: 1.939, Global test accuracy: 36.07
Round  42, Train loss: 0.441, Test loss: 1.239, Test accuracy: 63.56
Round  42, Global train loss: 0.441, Global test loss: 1.754, Global test accuracy: 36.15
Round  43, Train loss: 0.416, Test loss: 1.274, Test accuracy: 63.67
Round  43, Global train loss: 0.416, Global test loss: 2.205, Global test accuracy: 33.07
Round  44, Train loss: 0.430, Test loss: 1.282, Test accuracy: 64.05
Round  44, Global train loss: 0.430, Global test loss: 1.968, Global test accuracy: 33.75
Round  45, Train loss: 0.390, Test loss: 1.300, Test accuracy: 64.01
Round  45, Global train loss: 0.390, Global test loss: 1.723, Global test accuracy: 40.34
Round  46, Train loss: 0.285, Test loss: 1.326, Test accuracy: 64.02
Round  46, Global train loss: 0.285, Global test loss: 1.770, Global test accuracy: 38.79
Round  47, Train loss: 0.332, Test loss: 1.327, Test accuracy: 63.99
Round  47, Global train loss: 0.332, Global test loss: 1.706, Global test accuracy: 41.84
Round  48, Train loss: 0.278, Test loss: 1.333, Test accuracy: 64.42
Round  48, Global train loss: 0.278, Global test loss: 1.745, Global test accuracy: 38.89
Round  49, Train loss: 0.235, Test loss: 1.364, Test accuracy: 64.11
Round  49, Global train loss: 0.235, Global test loss: 1.736, Global test accuracy: 42.08
Round  50, Train loss: 0.337, Test loss: 1.379, Test accuracy: 63.95
Round  50, Global train loss: 0.337, Global test loss: 2.034, Global test accuracy: 36.44
Round  51, Train loss: 0.309, Test loss: 1.407, Test accuracy: 63.71
Round  51, Global train loss: 0.309, Global test loss: 1.782, Global test accuracy: 36.84
Round  52, Train loss: 0.285, Test loss: 1.391, Test accuracy: 63.53
Round  52, Global train loss: 0.285, Global test loss: 1.904, Global test accuracy: 35.25
Round  53, Train loss: 0.378, Test loss: 1.385, Test accuracy: 63.97
Round  53, Global train loss: 0.378, Global test loss: 1.796, Global test accuracy: 34.17
Round  54, Train loss: 0.298, Test loss: 1.420, Test accuracy: 63.46
Round  54, Global train loss: 0.298, Global test loss: 1.602, Global test accuracy: 48.46
Round  55, Train loss: 0.259, Test loss: 1.414, Test accuracy: 63.42
Round  55, Global train loss: 0.259, Global test loss: 1.798, Global test accuracy: 38.30
Round  56, Train loss: 0.252, Test loss: 1.457, Test accuracy: 63.37
Round  56, Global train loss: 0.252, Global test loss: 1.696, Global test accuracy: 37.71
Round  57, Train loss: 0.245, Test loss: 1.481, Test accuracy: 63.61
Round  57, Global train loss: 0.245, Global test loss: 2.083, Global test accuracy: 29.84
Round  58, Train loss: 0.285, Test loss: 1.484, Test accuracy: 63.74
Round  58, Global train loss: 0.285, Global test loss: 1.996, Global test accuracy: 39.46
Round  59, Train loss: 0.204, Test loss: 1.488, Test accuracy: 63.53
Round  59, Global train loss: 0.204, Global test loss: 2.060, Global test accuracy: 40.54
Round  60, Train loss: 0.246, Test loss: 1.499, Test accuracy: 63.82
Round  60, Global train loss: 0.246, Global test loss: 1.764, Global test accuracy: 37.92
Round  61, Train loss: 0.255, Test loss: 1.530, Test accuracy: 63.67
Round  61, Global train loss: 0.255, Global test loss: 1.680, Global test accuracy: 41.40
Round  62, Train loss: 0.246, Test loss: 1.548, Test accuracy: 63.93
Round  62, Global train loss: 0.246, Global test loss: 1.953, Global test accuracy: 30.07
Round  63, Train loss: 0.223, Test loss: 1.552, Test accuracy: 64.05
Round  63, Global train loss: 0.223, Global test loss: 2.041, Global test accuracy: 33.14
Round  64, Train loss: 0.163, Test loss: 1.542, Test accuracy: 64.24
Round  64, Global train loss: 0.163, Global test loss: 1.815, Global test accuracy: 36.02
Round  65, Train loss: 0.174, Test loss: 1.568, Test accuracy: 64.09
Round  65, Global train loss: 0.174, Global test loss: 1.850, Global test accuracy: 30.87
Round  66, Train loss: 0.188, Test loss: 1.575, Test accuracy: 64.66
Round  66, Global train loss: 0.188, Global test loss: 1.687, Global test accuracy: 39.84
Round  67, Train loss: 0.167, Test loss: 1.617, Test accuracy: 64.63
Round  67, Global train loss: 0.167, Global test loss: 2.396, Global test accuracy: 33.77
Round  68, Train loss: 0.173, Test loss: 1.650, Test accuracy: 64.03
Round  68, Global train loss: 0.173, Global test loss: 1.832, Global test accuracy: 34.31
Round  69, Train loss: 0.149, Test loss: 1.671, Test accuracy: 63.67
Round  69, Global train loss: 0.149, Global test loss: 1.902, Global test accuracy: 32.04
Round  70, Train loss: 0.164, Test loss: 1.709, Test accuracy: 63.74
Round  70, Global train loss: 0.164, Global test loss: 1.787, Global test accuracy: 38.08
Round  71, Train loss: 0.160, Test loss: 1.696, Test accuracy: 64.13
Round  71, Global train loss: 0.160, Global test loss: 2.108, Global test accuracy: 30.29
Round  72, Train loss: 0.179, Test loss: 1.764, Test accuracy: 63.42
Round  72, Global train loss: 0.179, Global test loss: 1.714, Global test accuracy: 40.31
Round  73, Train loss: 0.147, Test loss: 1.761, Test accuracy: 63.42
Round  73, Global train loss: 0.147, Global test loss: 1.742, Global test accuracy: 37.95
Round  74, Train loss: 0.187, Test loss: 1.740, Test accuracy: 63.43
Round  74, Global train loss: 0.187, Global test loss: 1.752, Global test accuracy: 34.50
Round  75, Train loss: 0.161, Test loss: 1.775, Test accuracy: 63.63
Round  75, Global train loss: 0.161, Global test loss: 1.714, Global test accuracy: 41.77
Round  76, Train loss: 0.123, Test loss: 1.759, Test accuracy: 63.59
Round  76, Global train loss: 0.123, Global test loss: 1.900, Global test accuracy: 36.75
Round  77, Train loss: 0.176, Test loss: 1.750, Test accuracy: 63.64
Round  77, Global train loss: 0.176, Global test loss: 1.794, Global test accuracy: 37.46
Round  78, Train loss: 0.149, Test loss: 1.759, Test accuracy: 63.68
Round  78, Global train loss: 0.149, Global test loss: 1.857, Global test accuracy: 33.36
Round  79, Train loss: 0.137, Test loss: 1.734, Test accuracy: 64.04
Round  79, Global train loss: 0.137, Global test loss: 1.830, Global test accuracy: 35.98
Round  80, Train loss: 0.119, Test loss: 1.766, Test accuracy: 64.19
Round  80, Global train loss: 0.119, Global test loss: 2.080, Global test accuracy: 33.02
Round  81, Train loss: 0.123, Test loss: 1.786, Test accuracy: 64.00
Round  81, Global train loss: 0.123, Global test loss: 1.678, Global test accuracy: 40.08
Round  82, Train loss: 0.101, Test loss: 1.813, Test accuracy: 64.19
Round  82, Global train loss: 0.101, Global test loss: 1.576, Global test accuracy: 44.94
Round  83, Train loss: 0.121, Test loss: 1.804, Test accuracy: 63.98
Round  83, Global train loss: 0.121, Global test loss: 2.094, Global test accuracy: 33.12
Round  84, Train loss: 0.134, Test loss: 1.842, Test accuracy: 64.11
Round  84, Global train loss: 0.134, Global test loss: 2.304, Global test accuracy: 31.59
Round  85, Train loss: 0.091, Test loss: 1.770, Test accuracy: 64.32
Round  85, Global train loss: 0.091, Global test loss: 1.720, Global test accuracy: 41.54
Round  86, Train loss: 0.115, Test loss: 1.804, Test accuracy: 64.29
Round  86, Global train loss: 0.115, Global test loss: 1.581, Global test accuracy: 45.10
Round  87, Train loss: 0.127, Test loss: 1.835, Test accuracy: 64.54
Round  87, Global train loss: 0.127, Global test loss: 1.691, Global test accuracy: 41.95
Round  88, Train loss: 0.119, Test loss: 1.826, Test accuracy: 64.35
Round  88, Global train loss: 0.119, Global test loss: 2.445, Global test accuracy: 30.60
Round  89, Train loss: 0.124, Test loss: 1.851, Test accuracy: 64.78
Round  89, Global train loss: 0.124, Global test loss: 1.704, Global test accuracy: 40.38
Round  90, Train loss: 0.146, Test loss: 1.890, Test accuracy: 64.82
Round  90, Global train loss: 0.146, Global test loss: 1.714, Global test accuracy: 39.56
Round  91, Train loss: 0.087, Test loss: 1.885, Test accuracy: 64.41
Round  91, Global train loss: 0.087, Global test loss: 1.993, Global test accuracy: 28.97
Round  92, Train loss: 0.131, Test loss: 1.909, Test accuracy: 64.01
Round  92, Global train loss: 0.131, Global test loss: 1.993, Global test accuracy: 36.42
Round  93, Train loss: 0.118, Test loss: 1.936, Test accuracy: 64.01
Round  93, Global train loss: 0.118, Global test loss: 1.804, Global test accuracy: 38.54
Round  94, Train loss: 0.098, Test loss: 1.937, Test accuracy: 64.14
Round  94, Global train loss: 0.098, Global test loss: 1.913, Global test accuracy: 32.50
Round  95, Train loss: 0.128, Test loss: 1.944, Test accuracy: 64.19
Round  95, Global train loss: 0.128, Global test loss: 1.882, Global test accuracy: 37.73
Round  96, Train loss: 0.104, Test loss: 1.944, Test accuracy: 64.24
Round  96, Global train loss: 0.104, Global test loss: 1.731, Global test accuracy: 41.32
Round  97, Train loss: 0.080, Test loss: 1.931, Test accuracy: 64.18
Round  97, Global train loss: 0.080, Global test loss: 1.718, Global test accuracy: 38.51
Round  98, Train loss: 0.091, Test loss: 1.964, Test accuracy: 64.58
Round  98, Global train loss: 0.091, Global test loss: 1.719, Global test accuracy: 41.23
Round  99, Train loss: 0.090, Test loss: 1.969, Test accuracy: 64.30
Round  99, Global train loss: 0.090, Global test loss: 1.846, Global test accuracy: 37.18
Final Round, Train loss: 0.091, Test loss: 2.061, Test accuracy: 64.73
Final Round, Global train loss: 0.091, Global test loss: 1.846, Global test accuracy: 37.18
Average accuracy final 10 rounds: 64.28799999999998 

Average global accuracy final 10 rounds: 37.196 

1690.3206906318665
[1.3708648681640625, 2.741729736328125, 4.036766529083252, 5.331803321838379, 6.670225381851196, 8.008647441864014, 9.27048397064209, 10.532320499420166, 11.868979454040527, 13.205638408660889, 14.57804536819458, 15.950452327728271, 17.246679306030273, 18.542906284332275, 19.76327896118164, 20.983651638031006, 22.295538902282715, 23.607426166534424, 24.98031258583069, 26.353199005126953, 27.64201784133911, 28.93083667755127, 30.292255401611328, 31.653674125671387, 32.979307889938354, 34.30494165420532, 35.61310958862305, 36.92127752304077, 38.27392387390137, 39.62657022476196, 40.827714681625366, 42.02885913848877, 43.26146149635315, 44.49406385421753, 45.7970244884491, 47.099985122680664, 48.43337035179138, 49.7667555809021, 51.079283237457275, 52.39181089401245, 53.709880113601685, 55.02794933319092, 56.3034086227417, 57.57886791229248, 58.9132182598114, 60.24756860733032, 61.56023836135864, 62.87290811538696, 64.19343185424805, 65.51395559310913, 66.78551387786865, 68.05707216262817, 69.48027610778809, 70.903480052948, 72.17188215255737, 73.44028425216675, 74.79994058609009, 76.15959692001343, 77.44126081466675, 78.72292470932007, 80.08032035827637, 81.43771600723267, 82.73834180831909, 84.03896760940552, 85.37310004234314, 86.70723247528076, 87.90997791290283, 89.1127233505249, 90.45676493644714, 91.80080652236938, 93.1457166671753, 94.4906268119812, 95.70217943191528, 96.91373205184937, 98.18139958381653, 99.44906711578369, 100.7675552368164, 102.08604335784912, 103.42132115364075, 104.75659894943237, 106.09846019744873, 107.44032144546509, 108.75967121124268, 110.07902097702026, 111.42035031318665, 112.76167964935303, 114.15465378761292, 115.5476279258728, 116.93413043022156, 118.32063293457031, 119.65783715248108, 120.99504137039185, 122.30158185958862, 123.6081223487854, 124.91758680343628, 126.22705125808716, 127.56855273246765, 128.91005420684814, 130.1042034626007, 131.29835271835327, 132.56644797325134, 133.8345432281494, 135.19236588478088, 136.55018854141235, 137.87081837654114, 139.19144821166992, 140.4930853843689, 141.79472255706787, 143.07029342651367, 144.34586429595947, 145.64894032478333, 146.95201635360718, 148.29847884178162, 149.64494132995605, 150.95883703231812, 152.27273273468018, 153.6606388092041, 155.04854488372803, 156.36298608779907, 157.67742729187012, 159.0294828414917, 160.38153839111328, 161.70511984825134, 163.0287013053894, 164.37540936470032, 165.72211742401123, 167.0903594493866, 168.45860147476196, 169.78019642829895, 171.10179138183594, 172.45113945007324, 173.80048751831055, 175.16731142997742, 176.5341353416443, 177.87316608428955, 179.21219682693481, 180.408358335495, 181.60451984405518, 182.86115503311157, 184.11779022216797, 185.43900442123413, 186.7602186203003, 188.08519983291626, 189.41018104553223, 190.65969562530518, 191.90921020507812, 193.2029082775116, 194.49660634994507, 195.8017966747284, 197.10698699951172, 198.3964741230011, 199.68596124649048, 200.9826533794403, 202.27934551239014, 203.56790804862976, 204.85647058486938, 206.1344690322876, 207.4124674797058, 208.72418665885925, 210.0359058380127, 211.30708527565002, 212.57826471328735, 213.9060184955597, 215.23377227783203, 216.43795084953308, 217.64212942123413, 218.836106300354, 220.03008317947388, 221.25434041023254, 222.4785976409912, 223.80379152297974, 225.12898540496826, 226.46495127677917, 227.8009171485901, 229.0942542552948, 230.3875913619995, 231.74060201644897, 233.09361267089844, 234.41882705688477, 235.7440414428711, 237.03464531898499, 238.32524919509888, 239.67447590827942, 241.02370262145996, 242.33280229568481, 243.64190196990967, 245.0042552947998, 246.36660861968994, 247.64151096343994, 248.91641330718994, 250.19903826713562, 251.4816632270813, 252.59587979316711, 253.71009635925293, 254.81380009651184, 255.91750383377075, 257.03185510635376, 258.14620637893677, 259.24595379829407, 260.34570121765137, 262.6210820674896, 264.8964629173279]
[25.35, 25.35, 30.5, 30.5, 42.83, 42.83, 48.3, 48.3, 49.59, 49.59, 52.09, 52.09, 52.89, 52.89, 52.9, 52.9, 55.06, 55.06, 54.22, 54.22, 55.41, 55.41, 56.02, 56.02, 56.34, 56.34, 57.21, 57.21, 58.74, 58.74, 59.23, 59.23, 59.1, 59.1, 59.49, 59.49, 59.77, 59.77, 60.44, 60.44, 60.99, 60.99, 61.57, 61.57, 61.56, 61.56, 61.61, 61.61, 62.17, 62.17, 61.65, 61.65, 61.68, 61.68, 61.91, 61.91, 62.14, 62.14, 62.49, 62.49, 62.92, 62.92, 62.86, 62.86, 62.75, 62.75, 62.44, 62.44, 62.41, 62.41, 62.64, 62.64, 62.85, 62.85, 62.66, 62.66, 63.31, 63.31, 63.21, 63.21, 63.27, 63.27, 63.27, 63.27, 63.56, 63.56, 63.67, 63.67, 64.05, 64.05, 64.01, 64.01, 64.02, 64.02, 63.99, 63.99, 64.42, 64.42, 64.11, 64.11, 63.95, 63.95, 63.71, 63.71, 63.53, 63.53, 63.97, 63.97, 63.46, 63.46, 63.42, 63.42, 63.37, 63.37, 63.61, 63.61, 63.74, 63.74, 63.53, 63.53, 63.82, 63.82, 63.67, 63.67, 63.93, 63.93, 64.05, 64.05, 64.24, 64.24, 64.09, 64.09, 64.66, 64.66, 64.63, 64.63, 64.03, 64.03, 63.67, 63.67, 63.74, 63.74, 64.13, 64.13, 63.42, 63.42, 63.42, 63.42, 63.43, 63.43, 63.63, 63.63, 63.59, 63.59, 63.64, 63.64, 63.68, 63.68, 64.04, 64.04, 64.19, 64.19, 64.0, 64.0, 64.19, 64.19, 63.98, 63.98, 64.11, 64.11, 64.32, 64.32, 64.29, 64.29, 64.54, 64.54, 64.35, 64.35, 64.78, 64.78, 64.82, 64.82, 64.41, 64.41, 64.01, 64.01, 64.01, 64.01, 64.14, 64.14, 64.19, 64.19, 64.24, 64.24, 64.18, 64.18, 64.58, 64.58, 64.3, 64.3, 64.73, 64.73]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.572, Test loss: 1.909, Test accuracy: 26.28
Round   0, Global train loss: 1.572, Global test loss: 2.096, Global test accuracy: 22.79
Round   1, Train loss: 1.385, Test loss: 1.642, Test accuracy: 36.27
Round   1, Global train loss: 1.385, Global test loss: 1.909, Global test accuracy: 32.47
Round   2, Train loss: 1.244, Test loss: 1.608, Test accuracy: 39.50
Round   2, Global train loss: 1.244, Global test loss: 2.023, Global test accuracy: 30.28
Round   3, Train loss: 1.200, Test loss: 1.360, Test accuracy: 45.84
Round   3, Global train loss: 1.200, Global test loss: 1.697, Global test accuracy: 37.80
Round   4, Train loss: 1.124, Test loss: 1.317, Test accuracy: 48.89
Round   4, Global train loss: 1.124, Global test loss: 1.831, Global test accuracy: 36.50
Round   5, Train loss: 1.064, Test loss: 1.187, Test accuracy: 52.69
Round   5, Global train loss: 1.064, Global test loss: 1.621, Global test accuracy: 41.90
Round   6, Train loss: 1.087, Test loss: 1.105, Test accuracy: 56.31
Round   6, Global train loss: 1.087, Global test loss: 1.515, Global test accuracy: 47.81
Round   7, Train loss: 1.036, Test loss: 1.099, Test accuracy: 56.97
Round   7, Global train loss: 1.036, Global test loss: 1.915, Global test accuracy: 40.19
Round   8, Train loss: 0.995, Test loss: 1.062, Test accuracy: 58.34
Round   8, Global train loss: 0.995, Global test loss: 1.527, Global test accuracy: 47.02
Round   9, Train loss: 1.000, Test loss: 1.054, Test accuracy: 58.78
Round   9, Global train loss: 1.000, Global test loss: 1.492, Global test accuracy: 46.28
Round  10, Train loss: 0.963, Test loss: 0.996, Test accuracy: 61.38
Round  10, Global train loss: 0.963, Global test loss: 1.395, Global test accuracy: 51.39
Round  11, Train loss: 0.876, Test loss: 1.030, Test accuracy: 61.16
Round  11, Global train loss: 0.876, Global test loss: 1.581, Global test accuracy: 47.31
Round  12, Train loss: 0.897, Test loss: 1.017, Test accuracy: 61.57
Round  12, Global train loss: 0.897, Global test loss: 1.392, Global test accuracy: 52.06
Round  13, Train loss: 0.863, Test loss: 1.020, Test accuracy: 61.34
Round  13, Global train loss: 0.863, Global test loss: 1.356, Global test accuracy: 52.37
Round  14, Train loss: 0.841, Test loss: 0.999, Test accuracy: 62.03
Round  14, Global train loss: 0.841, Global test loss: 1.473, Global test accuracy: 49.03
Round  15, Train loss: 0.879, Test loss: 0.951, Test accuracy: 63.54
Round  15, Global train loss: 0.879, Global test loss: 1.418, Global test accuracy: 51.87
Round  16, Train loss: 0.768, Test loss: 0.939, Test accuracy: 64.53
Round  16, Global train loss: 0.768, Global test loss: 1.593, Global test accuracy: 50.36
Round  17, Train loss: 0.866, Test loss: 0.886, Test accuracy: 65.81
Round  17, Global train loss: 0.866, Global test loss: 1.400, Global test accuracy: 52.21
Round  18, Train loss: 0.795, Test loss: 0.888, Test accuracy: 65.94
Round  18, Global train loss: 0.795, Global test loss: 1.234, Global test accuracy: 56.32
Round  19, Train loss: 0.814, Test loss: 0.893, Test accuracy: 65.80
Round  19, Global train loss: 0.814, Global test loss: 1.317, Global test accuracy: 56.30
Round  20, Train loss: 0.767, Test loss: 0.882, Test accuracy: 66.19
Round  20, Global train loss: 0.767, Global test loss: 1.439, Global test accuracy: 52.10
Round  21, Train loss: 0.768, Test loss: 0.874, Test accuracy: 67.04
Round  21, Global train loss: 0.768, Global test loss: 1.351, Global test accuracy: 55.40
Round  22, Train loss: 0.770, Test loss: 0.863, Test accuracy: 67.71
Round  22, Global train loss: 0.770, Global test loss: 1.326, Global test accuracy: 54.55
Round  23, Train loss: 0.742, Test loss: 0.860, Test accuracy: 67.79
Round  23, Global train loss: 0.742, Global test loss: 1.280, Global test accuracy: 56.73
Round  24, Train loss: 0.712, Test loss: 0.851, Test accuracy: 67.91
Round  24, Global train loss: 0.712, Global test loss: 1.190, Global test accuracy: 59.26
Round  25, Train loss: 0.715, Test loss: 0.849, Test accuracy: 68.14
Round  25, Global train loss: 0.715, Global test loss: 1.188, Global test accuracy: 59.70
Round  26, Train loss: 0.713, Test loss: 0.832, Test accuracy: 68.78
Round  26, Global train loss: 0.713, Global test loss: 1.226, Global test accuracy: 59.63
Round  27, Train loss: 0.723, Test loss: 0.833, Test accuracy: 68.85
Round  27, Global train loss: 0.723, Global test loss: 1.315, Global test accuracy: 57.90
Round  28, Train loss: 0.629, Test loss: 0.824, Test accuracy: 69.39
Round  28, Global train loss: 0.629, Global test loss: 1.288, Global test accuracy: 57.17
Round  29, Train loss: 0.668, Test loss: 0.813, Test accuracy: 69.84
Round  29, Global train loss: 0.668, Global test loss: 1.221, Global test accuracy: 59.85
Round  30, Train loss: 0.662, Test loss: 0.819, Test accuracy: 69.95
Round  30, Global train loss: 0.662, Global test loss: 1.172, Global test accuracy: 61.06
Round  31, Train loss: 0.593, Test loss: 0.827, Test accuracy: 69.61
Round  31, Global train loss: 0.593, Global test loss: 1.248, Global test accuracy: 59.70
Round  32, Train loss: 0.649, Test loss: 0.816, Test accuracy: 69.92
Round  32, Global train loss: 0.649, Global test loss: 1.363, Global test accuracy: 55.58
Round  33, Train loss: 0.608, Test loss: 0.820, Test accuracy: 70.16
Round  33, Global train loss: 0.608, Global test loss: 1.153, Global test accuracy: 62.02
Round  34, Train loss: 0.625, Test loss: 0.802, Test accuracy: 70.87
Round  34, Global train loss: 0.625, Global test loss: 1.169, Global test accuracy: 60.57
Round  35, Train loss: 0.601, Test loss: 0.812, Test accuracy: 70.72
Round  35, Global train loss: 0.601, Global test loss: 1.191, Global test accuracy: 60.09
Round  36, Train loss: 0.558, Test loss: 0.800, Test accuracy: 71.07
Round  36, Global train loss: 0.558, Global test loss: 1.272, Global test accuracy: 59.47
Round  37, Train loss: 0.594, Test loss: 0.796, Test accuracy: 71.16
Round  37, Global train loss: 0.594, Global test loss: 1.319, Global test accuracy: 57.54
Round  38, Train loss: 0.607, Test loss: 0.803, Test accuracy: 71.27
Round  38, Global train loss: 0.607, Global test loss: 1.159, Global test accuracy: 61.48
Round  39, Train loss: 0.581, Test loss: 0.815, Test accuracy: 71.26
Round  39, Global train loss: 0.581, Global test loss: 1.211, Global test accuracy: 59.05
Round  40, Train loss: 0.576, Test loss: 0.813, Test accuracy: 71.10
Round  40, Global train loss: 0.576, Global test loss: 1.261, Global test accuracy: 57.77
Round  41, Train loss: 0.547, Test loss: 0.816, Test accuracy: 71.20
Round  41, Global train loss: 0.547, Global test loss: 1.087, Global test accuracy: 63.67
Round  42, Train loss: 0.545, Test loss: 0.814, Test accuracy: 71.23
Round  42, Global train loss: 0.545, Global test loss: 1.104, Global test accuracy: 62.13
Round  43, Train loss: 0.501, Test loss: 0.805, Test accuracy: 71.49
Round  43, Global train loss: 0.501, Global test loss: 1.216, Global test accuracy: 60.77
Round  44, Train loss: 0.512, Test loss: 0.809, Test accuracy: 71.48
Round  44, Global train loss: 0.512, Global test loss: 1.115, Global test accuracy: 64.42
Round  45, Train loss: 0.489, Test loss: 0.820, Test accuracy: 71.49
Round  45, Global train loss: 0.489, Global test loss: 1.356, Global test accuracy: 57.52
Round  46, Train loss: 0.471, Test loss: 0.837, Test accuracy: 71.43
Round  46, Global train loss: 0.471, Global test loss: 1.182, Global test accuracy: 62.16
Round  47, Train loss: 0.454, Test loss: 0.827, Test accuracy: 71.97
Round  47, Global train loss: 0.454, Global test loss: 1.352, Global test accuracy: 60.28
Round  48, Train loss: 0.451, Test loss: 0.822, Test accuracy: 72.00
Round  48, Global train loss: 0.451, Global test loss: 1.326, Global test accuracy: 60.11
Round  49, Train loss: 0.512, Test loss: 0.813, Test accuracy: 72.14
Round  49, Global train loss: 0.512, Global test loss: 1.173, Global test accuracy: 62.19
Round  50, Train loss: 0.408, Test loss: 0.821, Test accuracy: 71.82
Round  50, Global train loss: 0.408, Global test loss: 1.226, Global test accuracy: 62.07
Round  51, Train loss: 0.484, Test loss: 0.821, Test accuracy: 71.88
Round  51, Global train loss: 0.484, Global test loss: 1.141, Global test accuracy: 63.57
Round  52, Train loss: 0.487, Test loss: 0.806, Test accuracy: 72.20
Round  52, Global train loss: 0.487, Global test loss: 1.091, Global test accuracy: 64.35
Round  53, Train loss: 0.416, Test loss: 0.821, Test accuracy: 71.73
Round  53, Global train loss: 0.416, Global test loss: 1.106, Global test accuracy: 63.53
Round  54, Train loss: 0.499, Test loss: 0.829, Test accuracy: 71.68
Round  54, Global train loss: 0.499, Global test loss: 1.116, Global test accuracy: 63.64
Round  55, Train loss: 0.445, Test loss: 0.814, Test accuracy: 72.16
Round  55, Global train loss: 0.445, Global test loss: 1.053, Global test accuracy: 65.81
Round  56, Train loss: 0.436, Test loss: 0.809, Test accuracy: 72.69
Round  56, Global train loss: 0.436, Global test loss: 1.195, Global test accuracy: 62.90
Round  57, Train loss: 0.487, Test loss: 0.812, Test accuracy: 73.20
Round  57, Global train loss: 0.487, Global test loss: 1.047, Global test accuracy: 65.77
Round  58, Train loss: 0.380, Test loss: 0.816, Test accuracy: 72.71
Round  58, Global train loss: 0.380, Global test loss: 1.244, Global test accuracy: 61.59
Round  59, Train loss: 0.422, Test loss: 0.817, Test accuracy: 73.01
Round  59, Global train loss: 0.422, Global test loss: 1.189, Global test accuracy: 63.02
Round  60, Train loss: 0.384, Test loss: 0.816, Test accuracy: 73.10
Round  60, Global train loss: 0.384, Global test loss: 1.160, Global test accuracy: 64.73
Round  61, Train loss: 0.433, Test loss: 0.845, Test accuracy: 72.75
Round  61, Global train loss: 0.433, Global test loss: 1.182, Global test accuracy: 64.82
Round  62, Train loss: 0.397, Test loss: 0.841, Test accuracy: 72.76
Round  62, Global train loss: 0.397, Global test loss: 1.127, Global test accuracy: 64.73
Round  63, Train loss: 0.414, Test loss: 0.834, Test accuracy: 73.04
Round  63, Global train loss: 0.414, Global test loss: 1.090, Global test accuracy: 65.99
Round  64, Train loss: 0.413, Test loss: 0.826, Test accuracy: 73.55
Round  64, Global train loss: 0.413, Global test loss: 1.209, Global test accuracy: 63.41
Round  65, Train loss: 0.461, Test loss: 0.814, Test accuracy: 73.91
Round  65, Global train loss: 0.461, Global test loss: 1.155, Global test accuracy: 63.96
Round  66, Train loss: 0.446, Test loss: 0.821, Test accuracy: 74.05
Round  66, Global train loss: 0.446, Global test loss: 1.387, Global test accuracy: 59.47
Round  67, Train loss: 0.405, Test loss: 0.833, Test accuracy: 73.90
Round  67, Global train loss: 0.405, Global test loss: 1.131, Global test accuracy: 64.13
Round  68, Train loss: 0.342, Test loss: 0.834, Test accuracy: 74.06
Round  68, Global train loss: 0.342, Global test loss: 1.277, Global test accuracy: 62.94
Round  69, Train loss: 0.375, Test loss: 0.837, Test accuracy: 73.98
Round  69, Global train loss: 0.375, Global test loss: 1.167, Global test accuracy: 64.07
Round  70, Train loss: 0.378, Test loss: 0.833, Test accuracy: 74.09
Round  70, Global train loss: 0.378, Global test loss: 1.097, Global test accuracy: 65.67
Round  71, Train loss: 0.380, Test loss: 0.846, Test accuracy: 74.04
Round  71, Global train loss: 0.380, Global test loss: 1.157, Global test accuracy: 63.81
Round  72, Train loss: 0.372, Test loss: 0.866, Test accuracy: 73.67
Round  72, Global train loss: 0.372, Global test loss: 1.284, Global test accuracy: 61.42
Round  73, Train loss: 0.366, Test loss: 0.873, Test accuracy: 73.62
Round  73, Global train loss: 0.366, Global test loss: 1.107, Global test accuracy: 66.17
Round  74, Train loss: 0.368, Test loss: 0.889, Test accuracy: 73.18
Round  74, Global train loss: 0.368, Global test loss: 1.143, Global test accuracy: 65.17
Round  75, Train loss: 0.328, Test loss: 0.869, Test accuracy: 73.57
Round  75, Global train loss: 0.328, Global test loss: 1.137, Global test accuracy: 65.68
Round  76, Train loss: 0.299, Test loss: 0.859, Test accuracy: 74.02
Round  76, Global train loss: 0.299, Global test loss: 1.416, Global test accuracy: 62.02
Round  77, Train loss: 0.317, Test loss: 0.881, Test accuracy: 73.69
Round  77, Global train loss: 0.317, Global test loss: 1.346, Global test accuracy: 63.05
Round  78, Train loss: 0.418, Test loss: 0.869, Test accuracy: 74.00
Round  78, Global train loss: 0.418, Global test loss: 1.213, Global test accuracy: 64.90
Round  79, Train loss: 0.379, Test loss: 0.859, Test accuracy: 74.30
Round  79, Global train loss: 0.379, Global test loss: 1.231, Global test accuracy: 62.95
Round  80, Train loss: 0.330, Test loss: 0.870, Test accuracy: 74.08
Round  80, Global train loss: 0.330, Global test loss: 1.273, Global test accuracy: 63.61
Round  81, Train loss: 0.353, Test loss: 0.890, Test accuracy: 73.77
Round  81, Global train loss: 0.353, Global test loss: 1.162, Global test accuracy: 65.09
Round  82, Train loss: 0.349, Test loss: 0.896, Test accuracy: 73.66
Round  82, Global train loss: 0.349, Global test loss: 1.196, Global test accuracy: 65.23
Round  83, Train loss: 0.328, Test loss: 0.903, Test accuracy: 73.43
Round  83, Global train loss: 0.328, Global test loss: 1.157, Global test accuracy: 66.73
Round  84, Train loss: 0.359, Test loss: 0.906, Test accuracy: 73.18
Round  84, Global train loss: 0.359, Global test loss: 1.305, Global test accuracy: 63.65
Round  85, Train loss: 0.331, Test loss: 0.894, Test accuracy: 73.73
Round  85, Global train loss: 0.331, Global test loss: 1.158, Global test accuracy: 65.08
Round  86, Train loss: 0.366, Test loss: 0.898, Test accuracy: 73.88
Round  86, Global train loss: 0.366, Global test loss: 1.085, Global test accuracy: 67.13
Round  87, Train loss: 0.348, Test loss: 0.902, Test accuracy: 73.80
Round  87, Global train loss: 0.348, Global test loss: 1.251, Global test accuracy: 64.50
Round  88, Train loss: 0.381, Test loss: 0.881, Test accuracy: 74.55
Round  88, Global train loss: 0.381, Global test loss: 1.240, Global test accuracy: 65.36
Round  89, Train loss: 0.312, Test loss: 0.872, Test accuracy: 74.92
Round  89, Global train loss: 0.312, Global test loss: 1.325, Global test accuracy: 63.54
Round  90, Train loss: 0.345, Test loss: 0.866, Test accuracy: 74.96
Round  90, Global train loss: 0.345, Global test loss: 1.127, Global test accuracy: 66.85
Round  91, Train loss: 0.325, Test loss: 0.894, Test accuracy: 74.56
Round  91, Global train loss: 0.325, Global test loss: 1.166, Global test accuracy: 67.13
Round  92, Train loss: 0.315, Test loss: 0.901, Test accuracy: 74.34
Round  92, Global train loss: 0.315, Global test loss: 1.601, Global test accuracy: 58.56
Round  93, Train loss: 0.324, Test loss: 0.906, Test accuracy: 74.05
Round  93, Global train loss: 0.324, Global test loss: 1.173, Global test accuracy: 65.58
Round  94, Train loss: 0.313, Test loss: 0.924, Test accuracy: 73.81
Round  94, Global train loss: 0.313, Global test loss: 1.251, Global test accuracy: 64.48
Round  95, Train loss: 0.320, Test loss: 0.932, Test accuracy: 73.58
Round  95, Global train loss: 0.320, Global test loss: 1.165, Global test accuracy: 65.71
Round  96, Train loss: 0.277, Test loss: 0.941, Test accuracy: 73.45
Round  96, Global train loss: 0.277, Global test loss: 1.191, Global test accuracy: 65.91
Round  97, Train loss: 0.290, Test loss: 0.921, Test accuracy: 73.87
Round  97, Global train loss: 0.290, Global test loss: 1.343, Global test accuracy: 63.07
Round  98, Train loss: 0.264, Test loss: 0.934, Test accuracy: 73.84
Round  98, Global train loss: 0.264, Global test loss: 1.267, Global test accuracy: 64.80
Round  99, Train loss: 0.307, Test loss: 0.916, Test accuracy: 74.56
Round  99, Global train loss: 0.307, Global test loss: 1.285, Global test accuracy: 64.70
Final Round, Train loss: 0.236, Test loss: 0.983, Test accuracy: 74.81
Final Round, Global train loss: 0.236, Global test loss: 1.285, Global test accuracy: 64.70
Average accuracy final 10 rounds: 74.10199999999999 

Average global accuracy final 10 rounds: 64.679 

1585.7837450504303
[1.5314371585845947, 3.0628743171691895, 4.21015477180481, 5.35743522644043, 6.4601616859436035, 7.562888145446777, 8.723495721817017, 9.884103298187256, 11.006049156188965, 12.127995014190674, 13.280460119247437, 14.4329252243042, 15.536242485046387, 16.639559745788574, 17.78896474838257, 18.938369750976562, 20.13664436340332, 21.334918975830078, 22.47370409965515, 23.612489223480225, 24.760581493377686, 25.908673763275146, 27.044100284576416, 28.179526805877686, 29.30748677253723, 30.435446739196777, 31.54672360420227, 32.658000469207764, 33.752010345458984, 34.846020221710205, 35.9787163734436, 37.111412525177, 38.21845197677612, 39.325491428375244, 40.4576690196991, 41.58984661102295, 42.687814712524414, 43.78578281402588, 44.91856551170349, 46.0513482093811, 47.1432569026947, 48.2351655960083, 49.37145781517029, 50.507750034332275, 51.5601110458374, 52.61247205734253, 53.75136947631836, 54.89026689529419, 55.9856972694397, 57.081127643585205, 58.209906339645386, 59.338685035705566, 60.582093954086304, 61.82550287246704, 63.10697364807129, 64.38844442367554, 65.66600918769836, 66.94357395172119, 68.0652642250061, 69.18695449829102, 70.30701017379761, 71.4270658493042, 72.54826402664185, 73.66946220397949, 74.78980851173401, 75.91015481948853, 77.00765466690063, 78.10515451431274, 79.22162914276123, 80.33810377120972, 81.43988299369812, 82.54166221618652, 83.66633033752441, 84.7909984588623, 85.88923144340515, 86.987464427948, 88.11958694458008, 89.25170946121216, 90.36978197097778, 91.48785448074341, 92.60917019844055, 93.7304859161377, 94.81702542304993, 95.90356492996216, 97.02506613731384, 98.14656734466553, 99.26067447662354, 100.37478160858154, 101.49814510345459, 102.62150859832764, 103.73787212371826, 104.85423564910889, 105.97950530052185, 107.10477495193481, 108.22879576683044, 109.35281658172607, 110.45700979232788, 111.56120300292969, 112.66050791740417, 113.75981283187866, 114.88433694839478, 116.00886106491089, 117.25828313827515, 118.5077052116394, 119.71514582633972, 120.92258644104004, 122.06500697135925, 123.20742750167847, 124.3321373462677, 125.45684719085693, 126.57679677009583, 127.69674634933472, 128.81979894638062, 129.9428515434265, 131.046368598938, 132.14988565444946, 133.26003742218018, 134.3701891899109, 135.5088334083557, 136.64747762680054, 137.7349784374237, 138.82247924804688, 139.94738173484802, 141.07228422164917, 142.15487122535706, 143.23745822906494, 144.4899618625641, 145.74246549606323, 146.83471488952637, 147.9269642829895, 149.07225060462952, 150.21753692626953, 151.29635858535767, 152.3751802444458, 153.52323603630066, 154.67129182815552, 155.72780084609985, 156.7843098640442, 158.07074403762817, 159.35717821121216, 160.57604551315308, 161.794912815094, 162.86879515647888, 163.94267749786377, 165.0057406425476, 166.06880378723145, 167.1433868408203, 168.21796989440918, 169.28708457946777, 170.35619926452637, 171.4514982700348, 172.5467972755432, 173.61372351646423, 174.68064975738525, 175.76400089263916, 176.84735202789307, 177.92232203483582, 178.99729204177856, 180.07462906837463, 181.1519660949707, 182.2211480140686, 183.2903299331665, 184.37087559700012, 185.45142126083374, 186.5201394557953, 187.58885765075684, 188.66216802597046, 189.73547840118408, 190.78507947921753, 191.83468055725098, 192.92033529281616, 194.00599002838135, 195.06672048568726, 196.12745094299316, 197.26940774917603, 198.4113645553589, 199.47072505950928, 200.53008556365967, 201.64800238609314, 202.7659192085266, 203.84611988067627, 204.92632055282593, 206.03457498550415, 207.14282941818237, 208.2181375026703, 209.2934455871582, 210.37293362617493, 211.45242166519165, 212.5547480583191, 213.65707445144653, 214.73296666145325, 215.80885887145996, 216.90377640724182, 217.99869394302368, 219.0566852092743, 220.1146764755249, 221.18728256225586, 222.25988864898682, 223.33626413345337, 224.41263961791992, 226.5611183643341, 228.7095971107483]
[26.28, 26.28, 36.27, 36.27, 39.5, 39.5, 45.84, 45.84, 48.89, 48.89, 52.69, 52.69, 56.31, 56.31, 56.97, 56.97, 58.34, 58.34, 58.78, 58.78, 61.38, 61.38, 61.16, 61.16, 61.57, 61.57, 61.34, 61.34, 62.03, 62.03, 63.54, 63.54, 64.53, 64.53, 65.81, 65.81, 65.94, 65.94, 65.8, 65.8, 66.19, 66.19, 67.04, 67.04, 67.71, 67.71, 67.79, 67.79, 67.91, 67.91, 68.14, 68.14, 68.78, 68.78, 68.85, 68.85, 69.39, 69.39, 69.84, 69.84, 69.95, 69.95, 69.61, 69.61, 69.92, 69.92, 70.16, 70.16, 70.87, 70.87, 70.72, 70.72, 71.07, 71.07, 71.16, 71.16, 71.27, 71.27, 71.26, 71.26, 71.1, 71.1, 71.2, 71.2, 71.23, 71.23, 71.49, 71.49, 71.48, 71.48, 71.49, 71.49, 71.43, 71.43, 71.97, 71.97, 72.0, 72.0, 72.14, 72.14, 71.82, 71.82, 71.88, 71.88, 72.2, 72.2, 71.73, 71.73, 71.68, 71.68, 72.16, 72.16, 72.69, 72.69, 73.2, 73.2, 72.71, 72.71, 73.01, 73.01, 73.1, 73.1, 72.75, 72.75, 72.76, 72.76, 73.04, 73.04, 73.55, 73.55, 73.91, 73.91, 74.05, 74.05, 73.9, 73.9, 74.06, 74.06, 73.98, 73.98, 74.09, 74.09, 74.04, 74.04, 73.67, 73.67, 73.62, 73.62, 73.18, 73.18, 73.57, 73.57, 74.02, 74.02, 73.69, 73.69, 74.0, 74.0, 74.3, 74.3, 74.08, 74.08, 73.77, 73.77, 73.66, 73.66, 73.43, 73.43, 73.18, 73.18, 73.73, 73.73, 73.88, 73.88, 73.8, 73.8, 74.55, 74.55, 74.92, 74.92, 74.96, 74.96, 74.56, 74.56, 74.34, 74.34, 74.05, 74.05, 73.81, 73.81, 73.58, 73.58, 73.45, 73.45, 73.87, 73.87, 73.84, 73.84, 74.56, 74.56, 74.81, 74.81]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.616, Test loss: 1.975, Test accuracy: 25.88
Round   0, Global train loss: 1.616, Global test loss: 2.176, Global test accuracy: 21.56
Round   1, Train loss: 1.402, Test loss: 1.627, Test accuracy: 35.98
Round   1, Global train loss: 1.402, Global test loss: 1.921, Global test accuracy: 28.93
Round   2, Train loss: 1.274, Test loss: 1.516, Test accuracy: 41.45
Round   2, Global train loss: 1.274, Global test loss: 1.874, Global test accuracy: 31.54
Round   3, Train loss: 1.219, Test loss: 1.455, Test accuracy: 46.02
Round   3, Global train loss: 1.219, Global test loss: 2.007, Global test accuracy: 36.50
Round   4, Train loss: 1.170, Test loss: 1.364, Test accuracy: 47.55
Round   4, Global train loss: 1.170, Global test loss: 1.799, Global test accuracy: 36.97
Round   5, Train loss: 1.134, Test loss: 1.218, Test accuracy: 51.17
Round   5, Global train loss: 1.134, Global test loss: 1.733, Global test accuracy: 37.93
Round   6, Train loss: 1.120, Test loss: 1.229, Test accuracy: 50.29
Round   6, Global train loss: 1.120, Global test loss: 1.708, Global test accuracy: 36.91
Round   7, Train loss: 1.077, Test loss: 1.137, Test accuracy: 53.55
Round   7, Global train loss: 1.077, Global test loss: 1.629, Global test accuracy: 43.80
Round   8, Train loss: 1.071, Test loss: 1.054, Test accuracy: 57.12
Round   8, Global train loss: 1.071, Global test loss: 1.551, Global test accuracy: 46.04
Round   9, Train loss: 1.063, Test loss: 1.050, Test accuracy: 57.46
Round   9, Global train loss: 1.063, Global test loss: 1.499, Global test accuracy: 47.43
Round  10, Train loss: 1.036, Test loss: 1.044, Test accuracy: 58.02
Round  10, Global train loss: 1.036, Global test loss: 1.451, Global test accuracy: 47.83
Round  11, Train loss: 0.981, Test loss: 1.046, Test accuracy: 57.40
Round  11, Global train loss: 0.981, Global test loss: 1.687, Global test accuracy: 41.84
Round  12, Train loss: 0.983, Test loss: 1.014, Test accuracy: 58.89
Round  12, Global train loss: 0.983, Global test loss: 1.447, Global test accuracy: 49.87
Round  13, Train loss: 0.933, Test loss: 0.988, Test accuracy: 59.91
Round  13, Global train loss: 0.933, Global test loss: 1.661, Global test accuracy: 44.90
Round  14, Train loss: 0.932, Test loss: 0.959, Test accuracy: 61.79
Round  14, Global train loss: 0.932, Global test loss: 1.583, Global test accuracy: 46.69
Round  15, Train loss: 0.953, Test loss: 0.951, Test accuracy: 62.23
Round  15, Global train loss: 0.953, Global test loss: 1.414, Global test accuracy: 52.86
Round  16, Train loss: 0.907, Test loss: 0.949, Test accuracy: 62.31
Round  16, Global train loss: 0.907, Global test loss: 1.491, Global test accuracy: 49.36
Round  17, Train loss: 0.917, Test loss: 0.921, Test accuracy: 63.40
Round  17, Global train loss: 0.917, Global test loss: 1.491, Global test accuracy: 48.80
Round  18, Train loss: 0.851, Test loss: 0.928, Test accuracy: 63.32
Round  18, Global train loss: 0.851, Global test loss: 1.339, Global test accuracy: 55.16
Round  19, Train loss: 0.875, Test loss: 0.905, Test accuracy: 64.35
Round  19, Global train loss: 0.875, Global test loss: 1.337, Global test accuracy: 52.98
Round  20, Train loss: 0.835, Test loss: 0.905, Test accuracy: 64.66
Round  20, Global train loss: 0.835, Global test loss: 1.315, Global test accuracy: 55.77
Round  21, Train loss: 0.822, Test loss: 0.895, Test accuracy: 65.49
Round  21, Global train loss: 0.822, Global test loss: 1.270, Global test accuracy: 55.90
Round  22, Train loss: 0.836, Test loss: 0.891, Test accuracy: 65.89
Round  22, Global train loss: 0.836, Global test loss: 1.422, Global test accuracy: 51.41
Round  23, Train loss: 0.830, Test loss: 0.886, Test accuracy: 65.93
Round  23, Global train loss: 0.830, Global test loss: 1.327, Global test accuracy: 53.48
Round  24, Train loss: 0.789, Test loss: 0.885, Test accuracy: 66.19
Round  24, Global train loss: 0.789, Global test loss: 1.486, Global test accuracy: 52.08
Round  25, Train loss: 0.783, Test loss: 0.883, Test accuracy: 66.66
Round  25, Global train loss: 0.783, Global test loss: 1.195, Global test accuracy: 58.29
Round  26, Train loss: 0.738, Test loss: 0.880, Test accuracy: 66.64
Round  26, Global train loss: 0.738, Global test loss: 1.316, Global test accuracy: 55.39
Round  27, Train loss: 0.782, Test loss: 0.868, Test accuracy: 66.87
Round  27, Global train loss: 0.782, Global test loss: 1.332, Global test accuracy: 53.20
Round  28, Train loss: 0.722, Test loss: 0.870, Test accuracy: 66.83
Round  28, Global train loss: 0.722, Global test loss: 1.312, Global test accuracy: 57.53
Round  29, Train loss: 0.737, Test loss: 0.866, Test accuracy: 67.34
Round  29, Global train loss: 0.737, Global test loss: 1.281, Global test accuracy: 56.52
Round  30, Train loss: 0.740, Test loss: 0.864, Test accuracy: 67.54
Round  30, Global train loss: 0.740, Global test loss: 1.225, Global test accuracy: 57.78
Round  31, Train loss: 0.776, Test loss: 0.851, Test accuracy: 68.01
Round  31, Global train loss: 0.776, Global test loss: 1.241, Global test accuracy: 58.58
Round  32, Train loss: 0.716, Test loss: 0.847, Test accuracy: 68.15
Round  32, Global train loss: 0.716, Global test loss: 1.218, Global test accuracy: 58.80
Round  33, Train loss: 0.667, Test loss: 0.839, Test accuracy: 68.48
Round  33, Global train loss: 0.667, Global test loss: 1.362, Global test accuracy: 55.17
Round  34, Train loss: 0.658, Test loss: 0.821, Test accuracy: 69.40
Round  34, Global train loss: 0.658, Global test loss: 1.247, Global test accuracy: 58.16
Round  35, Train loss: 0.649, Test loss: 0.821, Test accuracy: 69.43
Round  35, Global train loss: 0.649, Global test loss: 1.295, Global test accuracy: 56.62
Round  36, Train loss: 0.617, Test loss: 0.836, Test accuracy: 69.06
Round  36, Global train loss: 0.617, Global test loss: 1.227, Global test accuracy: 59.82
Round  37, Train loss: 0.632, Test loss: 0.821, Test accuracy: 69.81
Round  37, Global train loss: 0.632, Global test loss: 1.172, Global test accuracy: 60.95
Round  38, Train loss: 0.683, Test loss: 0.809, Test accuracy: 70.34
Round  38, Global train loss: 0.683, Global test loss: 1.104, Global test accuracy: 62.98
Round  39, Train loss: 0.677, Test loss: 0.808, Test accuracy: 70.56
Round  39, Global train loss: 0.677, Global test loss: 1.279, Global test accuracy: 57.38
Round  40, Train loss: 0.588, Test loss: 0.811, Test accuracy: 70.28
Round  40, Global train loss: 0.588, Global test loss: 1.206, Global test accuracy: 60.85
Round  41, Train loss: 0.637, Test loss: 0.794, Test accuracy: 70.77
Round  41, Global train loss: 0.637, Global test loss: 1.187, Global test accuracy: 61.12
Round  42, Train loss: 0.605, Test loss: 0.797, Test accuracy: 70.96
Round  42, Global train loss: 0.605, Global test loss: 1.243, Global test accuracy: 58.73
Round  43, Train loss: 0.638, Test loss: 0.798, Test accuracy: 71.17
Round  43, Global train loss: 0.638, Global test loss: 1.136, Global test accuracy: 62.95
Round  44, Train loss: 0.598, Test loss: 0.800, Test accuracy: 71.07
Round  44, Global train loss: 0.598, Global test loss: 1.250, Global test accuracy: 60.44
Round  45, Train loss: 0.577, Test loss: 0.812, Test accuracy: 70.87
Round  45, Global train loss: 0.577, Global test loss: 1.193, Global test accuracy: 62.24
Round  46, Train loss: 0.571, Test loss: 0.847, Test accuracy: 70.05
Round  46, Global train loss: 0.571, Global test loss: 1.105, Global test accuracy: 63.21
Round  47, Train loss: 0.585, Test loss: 0.809, Test accuracy: 70.91
Round  47, Global train loss: 0.585, Global test loss: 1.148, Global test accuracy: 61.90
Round  48, Train loss: 0.539, Test loss: 0.816, Test accuracy: 70.66
Round  48, Global train loss: 0.539, Global test loss: 1.248, Global test accuracy: 60.47
Round  49, Train loss: 0.615, Test loss: 0.825, Test accuracy: 70.37
Round  49, Global train loss: 0.615, Global test loss: 1.142, Global test accuracy: 62.57
Round  50, Train loss: 0.567, Test loss: 0.826, Test accuracy: 70.59
Round  50, Global train loss: 0.567, Global test loss: 1.187, Global test accuracy: 61.70
Round  51, Train loss: 0.532, Test loss: 0.812, Test accuracy: 71.19
Round  51, Global train loss: 0.532, Global test loss: 1.126, Global test accuracy: 63.06
Round  52, Train loss: 0.489, Test loss: 0.805, Test accuracy: 71.47
Round  52, Global train loss: 0.489, Global test loss: 1.131, Global test accuracy: 63.59
Round  53, Train loss: 0.503, Test loss: 0.803, Test accuracy: 71.92
Round  53, Global train loss: 0.503, Global test loss: 1.176, Global test accuracy: 62.89
Round  54, Train loss: 0.547, Test loss: 0.811, Test accuracy: 71.65
Round  54, Global train loss: 0.547, Global test loss: 1.096, Global test accuracy: 63.22
Round  55, Train loss: 0.521, Test loss: 0.818, Test accuracy: 71.59
Round  55, Global train loss: 0.521, Global test loss: 1.118, Global test accuracy: 63.58
Round  56, Train loss: 0.504, Test loss: 0.824, Test accuracy: 71.58
Round  56, Global train loss: 0.504, Global test loss: 1.167, Global test accuracy: 61.91
Round  57, Train loss: 0.533, Test loss: 0.818, Test accuracy: 71.55
Round  57, Global train loss: 0.533, Global test loss: 1.161, Global test accuracy: 62.85
Round  58, Train loss: 0.453, Test loss: 0.811, Test accuracy: 71.59
Round  58, Global train loss: 0.453, Global test loss: 1.148, Global test accuracy: 62.79
Round  59, Train loss: 0.434, Test loss: 0.824, Test accuracy: 71.62
Round  59, Global train loss: 0.434, Global test loss: 1.278, Global test accuracy: 60.62
Round  60, Train loss: 0.501, Test loss: 0.819, Test accuracy: 71.81
Round  60, Global train loss: 0.501, Global test loss: 1.182, Global test accuracy: 62.02
Round  61, Train loss: 0.481, Test loss: 0.814, Test accuracy: 72.04
Round  61, Global train loss: 0.481, Global test loss: 1.137, Global test accuracy: 63.78
Round  62, Train loss: 0.478, Test loss: 0.805, Test accuracy: 72.15
Round  62, Global train loss: 0.478, Global test loss: 1.120, Global test accuracy: 63.72
Round  63, Train loss: 0.497, Test loss: 0.847, Test accuracy: 71.57
Round  63, Global train loss: 0.497, Global test loss: 1.300, Global test accuracy: 58.83
Round  64, Train loss: 0.455, Test loss: 0.848, Test accuracy: 71.99
Round  64, Global train loss: 0.455, Global test loss: 1.153, Global test accuracy: 64.24
Round  65, Train loss: 0.450, Test loss: 0.839, Test accuracy: 72.30
Round  65, Global train loss: 0.450, Global test loss: 1.190, Global test accuracy: 62.69
Round  66, Train loss: 0.500, Test loss: 0.842, Test accuracy: 72.10
Round  66, Global train loss: 0.500, Global test loss: 1.191, Global test accuracy: 62.87
Round  67, Train loss: 0.412, Test loss: 0.820, Test accuracy: 72.52
Round  67, Global train loss: 0.412, Global test loss: 1.102, Global test accuracy: 64.97
Round  68, Train loss: 0.429, Test loss: 0.819, Test accuracy: 72.61
Round  68, Global train loss: 0.429, Global test loss: 1.204, Global test accuracy: 63.14
Round  69, Train loss: 0.420, Test loss: 0.849, Test accuracy: 72.12
Round  69, Global train loss: 0.420, Global test loss: 1.273, Global test accuracy: 62.22
Round  70, Train loss: 0.477, Test loss: 0.868, Test accuracy: 71.92
Round  70, Global train loss: 0.477, Global test loss: 1.241, Global test accuracy: 63.09
Round  71, Train loss: 0.441, Test loss: 0.873, Test accuracy: 71.90
Round  71, Global train loss: 0.441, Global test loss: 1.193, Global test accuracy: 62.98
Round  72, Train loss: 0.445, Test loss: 0.843, Test accuracy: 72.61
Round  72, Global train loss: 0.445, Global test loss: 1.162, Global test accuracy: 64.97
Round  73, Train loss: 0.424, Test loss: 0.831, Test accuracy: 72.97
Round  73, Global train loss: 0.424, Global test loss: 1.111, Global test accuracy: 65.53
Round  74, Train loss: 0.385, Test loss: 0.833, Test accuracy: 73.09
Round  74, Global train loss: 0.385, Global test loss: 1.100, Global test accuracy: 65.95
Round  75, Train loss: 0.463, Test loss: 0.850, Test accuracy: 72.51
Round  75, Global train loss: 0.463, Global test loss: 1.210, Global test accuracy: 62.60
Round  76, Train loss: 0.430, Test loss: 0.846, Test accuracy: 72.36
Round  76, Global train loss: 0.430, Global test loss: 1.181, Global test accuracy: 63.34
Round  77, Train loss: 0.384, Test loss: 0.843, Test accuracy: 72.45
Round  77, Global train loss: 0.384, Global test loss: 1.220, Global test accuracy: 63.75
Round  78, Train loss: 0.406, Test loss: 0.854, Test accuracy: 71.84
Round  78, Global train loss: 0.406, Global test loss: 1.242, Global test accuracy: 63.56
Round  79, Train loss: 0.404, Test loss: 0.818, Test accuracy: 73.03
Round  79, Global train loss: 0.404, Global test loss: 1.194, Global test accuracy: 63.79
Round  80, Train loss: 0.394, Test loss: 0.816, Test accuracy: 73.29
Round  80, Global train loss: 0.394, Global test loss: 1.266, Global test accuracy: 62.51
Round  81, Train loss: 0.402, Test loss: 0.825, Test accuracy: 73.52
Round  81, Global train loss: 0.402, Global test loss: 1.284, Global test accuracy: 62.41
Round  82, Train loss: 0.404, Test loss: 0.830, Test accuracy: 73.86
Round  82, Global train loss: 0.404, Global test loss: 1.140, Global test accuracy: 65.15
Round  83, Train loss: 0.335, Test loss: 0.851, Test accuracy: 73.43
Round  83, Global train loss: 0.335, Global test loss: 1.299, Global test accuracy: 62.11
Round  84, Train loss: 0.467, Test loss: 0.857, Test accuracy: 73.26
Round  84, Global train loss: 0.467, Global test loss: 1.170, Global test accuracy: 63.93
Round  85, Train loss: 0.367, Test loss: 0.860, Test accuracy: 73.30
Round  85, Global train loss: 0.367, Global test loss: 1.081, Global test accuracy: 66.47
Round  86, Train loss: 0.380, Test loss: 0.859, Test accuracy: 73.43
Round  86, Global train loss: 0.380, Global test loss: 1.204, Global test accuracy: 64.73
Round  87, Train loss: 0.396, Test loss: 0.850, Test accuracy: 73.72
Round  87, Global train loss: 0.396, Global test loss: 1.267, Global test accuracy: 63.78
Round  88, Train loss: 0.365, Test loss: 0.848, Test accuracy: 73.83
Round  88, Global train loss: 0.365, Global test loss: 1.227, Global test accuracy: 63.96
Round  89, Train loss: 0.389, Test loss: 0.847, Test accuracy: 74.10
Round  89, Global train loss: 0.389, Global test loss: 1.105, Global test accuracy: 66.55
Round  90, Train loss: 0.382, Test loss: 0.847, Test accuracy: 74.04
Round  90, Global train loss: 0.382, Global test loss: 1.156, Global test accuracy: 65.70
Round  91, Train loss: 0.349, Test loss: 0.830, Test accuracy: 74.36
Round  91, Global train loss: 0.349, Global test loss: 1.153, Global test accuracy: 65.43
Round  92, Train loss: 0.363, Test loss: 0.839, Test accuracy: 74.09
Round  92, Global train loss: 0.363, Global test loss: 1.157, Global test accuracy: 65.60
Round  93, Train loss: 0.339, Test loss: 0.862, Test accuracy: 73.47
Round  93, Global train loss: 0.339, Global test loss: 1.310, Global test accuracy: 62.87
Round  94, Train loss: 0.341, Test loss: 0.879, Test accuracy: 73.35
Round  94, Global train loss: 0.341, Global test loss: 1.211, Global test accuracy: 65.35
Round  95, Train loss: 0.324, Test loss: 0.871, Test accuracy: 73.63
Round  95, Global train loss: 0.324, Global test loss: 1.178, Global test accuracy: 65.69/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  96, Train loss: 0.333, Test loss: 0.886, Test accuracy: 73.31
Round  96, Global train loss: 0.333, Global test loss: 1.204, Global test accuracy: 65.56
Round  97, Train loss: 0.380, Test loss: 0.883, Test accuracy: 72.91
Round  97, Global train loss: 0.380, Global test loss: 1.253, Global test accuracy: 64.76
Round  98, Train loss: 0.353, Test loss: 0.890, Test accuracy: 72.91
Round  98, Global train loss: 0.353, Global test loss: 1.200, Global test accuracy: 65.33
Round  99, Train loss: 0.371, Test loss: 0.897, Test accuracy: 72.74
Round  99, Global train loss: 0.371, Global test loss: 1.120, Global test accuracy: 67.17
Final Round, Train loss: 0.291, Test loss: 0.938, Test accuracy: 73.32
Final Round, Global train loss: 0.291, Global test loss: 1.120, Global test accuracy: 67.17
Average accuracy final 10 rounds: 73.48100000000001 

Average global accuracy final 10 rounds: 65.346 

1655.0716004371643
[1.5932152271270752, 3.1864304542541504, 4.496800422668457, 5.807170391082764, 7.1417295932769775, 8.476288795471191, 9.802721977233887, 11.129155158996582, 12.31727933883667, 13.505403518676758, 14.688068151473999, 15.87073278427124, 17.064507961273193, 18.258283138275146, 19.42101812362671, 20.58375310897827, 21.752930402755737, 22.922107696533203, 24.085076093673706, 25.24804449081421, 26.40918207168579, 27.570319652557373, 28.745988130569458, 29.921656608581543, 31.090751886367798, 32.25984716415405, 33.43932604789734, 34.618804931640625, 35.78608989715576, 36.9533748626709, 38.18832468986511, 39.423274517059326, 40.60496425628662, 41.786653995513916, 42.965205669403076, 44.143757343292236, 45.298856019973755, 46.45395469665527, 47.641857385635376, 48.82976007461548, 49.97985816001892, 51.12995624542236, 52.32182312011719, 53.51368999481201, 54.67685413360596, 55.8400182723999, 57.052539110183716, 58.26505994796753, 59.44011044502258, 60.61516094207764, 61.796717166900635, 62.97827339172363, 64.15026521682739, 65.32225704193115, 66.51212072372437, 67.70198440551758, 68.8586015701294, 70.01521873474121, 71.21082639694214, 72.40643405914307, 73.60637831687927, 74.80632257461548, 76.02942061424255, 77.25251865386963, 78.4370367527008, 79.62155485153198, 80.86374497413635, 82.10593509674072, 83.28482174873352, 84.46370840072632, 85.64983797073364, 86.83596754074097, 88.07428097724915, 89.31259441375732, 90.49972772598267, 91.68686103820801, 92.92005753517151, 94.15325403213501, 95.34117770195007, 96.52910137176514, 97.74657940864563, 98.96405744552612, 100.13616800308228, 101.30827856063843, 102.51428699493408, 103.72029542922974, 104.92672109603882, 106.1331467628479, 107.33431339263916, 108.53548002243042, 109.74253153800964, 110.94958305358887, 112.19296383857727, 113.43634462356567, 114.62515091896057, 115.81395721435547, 116.99241375923157, 118.17087030410767, 119.35841584205627, 120.54596138000488, 121.74510049819946, 122.94423961639404, 124.125657081604, 125.30707454681396, 126.48658990859985, 127.66610527038574, 128.85226011276245, 130.03841495513916, 131.19871187210083, 132.3590087890625, 133.52778005599976, 134.696551322937, 135.88221049308777, 137.06786966323853, 138.24120926856995, 139.41454887390137, 140.60888075828552, 141.80321264266968, 142.98796033859253, 144.17270803451538, 145.35209107398987, 146.53147411346436, 147.6955144405365, 148.85955476760864, 150.0235345363617, 151.18751430511475, 152.3551151752472, 153.52271604537964, 154.68277096748352, 155.8428258895874, 157.01577925682068, 158.18873262405396, 159.49714016914368, 160.8055477142334, 162.07069540023804, 163.33584308624268, 164.53591585159302, 165.73598861694336, 166.9655680656433, 168.19514751434326, 169.39508986473083, 170.5950322151184, 171.80443334579468, 173.01383447647095, 174.20684838294983, 175.3998622894287, 176.60242104530334, 177.80497980117798, 178.9821810722351, 180.15938234329224, 181.344078540802, 182.52877473831177, 183.72314453125, 184.91751432418823, 186.1247045993805, 187.33189487457275, 188.56354641914368, 189.7951979637146, 190.99451684951782, 192.19383573532104, 193.4451174736023, 194.69639921188354, 195.86820268630981, 197.04000616073608, 198.24191164970398, 199.44381713867188, 200.61005640029907, 201.77629566192627, 202.96465253829956, 204.15300941467285, 205.33545994758606, 206.51791048049927, 207.71735644340515, 208.91680240631104, 210.08995079994202, 211.263099193573, 212.44777536392212, 213.63245153427124, 214.82028579711914, 216.00812005996704, 217.19241285324097, 218.3767056465149, 219.54662561416626, 220.71654558181763, 221.89213585853577, 223.0677261352539, 224.24500679969788, 225.42228746414185, 226.60091638565063, 227.77954530715942, 228.95064330101013, 230.12174129486084, 231.29623436927795, 232.47072744369507, 233.63641452789307, 234.80210161209106, 235.98335194587708, 237.1646022796631, 238.34181213378906, 239.51902198791504, 241.9276819229126, 244.33634185791016]
[25.88, 25.88, 35.98, 35.98, 41.45, 41.45, 46.02, 46.02, 47.55, 47.55, 51.17, 51.17, 50.29, 50.29, 53.55, 53.55, 57.12, 57.12, 57.46, 57.46, 58.02, 58.02, 57.4, 57.4, 58.89, 58.89, 59.91, 59.91, 61.79, 61.79, 62.23, 62.23, 62.31, 62.31, 63.4, 63.4, 63.32, 63.32, 64.35, 64.35, 64.66, 64.66, 65.49, 65.49, 65.89, 65.89, 65.93, 65.93, 66.19, 66.19, 66.66, 66.66, 66.64, 66.64, 66.87, 66.87, 66.83, 66.83, 67.34, 67.34, 67.54, 67.54, 68.01, 68.01, 68.15, 68.15, 68.48, 68.48, 69.4, 69.4, 69.43, 69.43, 69.06, 69.06, 69.81, 69.81, 70.34, 70.34, 70.56, 70.56, 70.28, 70.28, 70.77, 70.77, 70.96, 70.96, 71.17, 71.17, 71.07, 71.07, 70.87, 70.87, 70.05, 70.05, 70.91, 70.91, 70.66, 70.66, 70.37, 70.37, 70.59, 70.59, 71.19, 71.19, 71.47, 71.47, 71.92, 71.92, 71.65, 71.65, 71.59, 71.59, 71.58, 71.58, 71.55, 71.55, 71.59, 71.59, 71.62, 71.62, 71.81, 71.81, 72.04, 72.04, 72.15, 72.15, 71.57, 71.57, 71.99, 71.99, 72.3, 72.3, 72.1, 72.1, 72.52, 72.52, 72.61, 72.61, 72.12, 72.12, 71.92, 71.92, 71.9, 71.9, 72.61, 72.61, 72.97, 72.97, 73.09, 73.09, 72.51, 72.51, 72.36, 72.36, 72.45, 72.45, 71.84, 71.84, 73.03, 73.03, 73.29, 73.29, 73.52, 73.52, 73.86, 73.86, 73.43, 73.43, 73.26, 73.26, 73.3, 73.3, 73.43, 73.43, 73.72, 73.72, 73.83, 73.83, 74.1, 74.1, 74.04, 74.04, 74.36, 74.36, 74.09, 74.09, 73.47, 73.47, 73.35, 73.35, 73.63, 73.63, 73.31, 73.31, 72.91, 72.91, 72.91, 72.91, 72.74, 72.74, 73.32, 73.32]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.954, Test loss: 2.082, Test accuracy: 23.13
Round   1, Train loss: 1.485, Test loss: 1.810, Test accuracy: 32.64
Round   2, Train loss: 1.395, Test loss: 1.566, Test accuracy: 41.72
Round   3, Train loss: 1.328, Test loss: 1.396, Test accuracy: 44.85
Round   4, Train loss: 1.219, Test loss: 1.332, Test accuracy: 46.04
Round   5, Train loss: 1.228, Test loss: 1.241, Test accuracy: 50.44
Round   6, Train loss: 1.148, Test loss: 1.179, Test accuracy: 53.87
Round   7, Train loss: 1.079, Test loss: 1.142, Test accuracy: 55.81
Round   8, Train loss: 1.066, Test loss: 1.099, Test accuracy: 57.51
Round   9, Train loss: 1.035, Test loss: 1.049, Test accuracy: 57.14
Round  10, Train loss: 1.010, Test loss: 1.014, Test accuracy: 59.51
Round  11, Train loss: 0.997, Test loss: 1.011, Test accuracy: 59.28
Round  12, Train loss: 0.963, Test loss: 1.008, Test accuracy: 59.75
Round  13, Train loss: 1.002, Test loss: 0.999, Test accuracy: 60.60
Round  14, Train loss: 0.990, Test loss: 0.989, Test accuracy: 60.08
Round  15, Train loss: 0.970, Test loss: 0.972, Test accuracy: 61.71
Round  16, Train loss: 0.967, Test loss: 0.959, Test accuracy: 62.00
Round  17, Train loss: 0.887, Test loss: 0.935, Test accuracy: 62.70
Round  18, Train loss: 0.872, Test loss: 0.917, Test accuracy: 63.44
Round  19, Train loss: 0.907, Test loss: 0.908, Test accuracy: 64.73
Round  20, Train loss: 0.904, Test loss: 0.891, Test accuracy: 65.86
Round  21, Train loss: 0.881, Test loss: 0.860, Test accuracy: 67.05
Round  22, Train loss: 0.866, Test loss: 0.853, Test accuracy: 66.76
Round  23, Train loss: 0.853, Test loss: 0.832, Test accuracy: 67.78
Round  24, Train loss: 0.846, Test loss: 0.833, Test accuracy: 68.35
Round  25, Train loss: 0.847, Test loss: 0.826, Test accuracy: 68.91
Round  26, Train loss: 0.788, Test loss: 0.813, Test accuracy: 69.04
Round  27, Train loss: 0.805, Test loss: 0.804, Test accuracy: 69.67
Round  28, Train loss: 0.778, Test loss: 0.795, Test accuracy: 69.29
Round  29, Train loss: 0.782, Test loss: 0.780, Test accuracy: 69.86
Round  30, Train loss: 0.775, Test loss: 0.782, Test accuracy: 69.89
Round  31, Train loss: 0.726, Test loss: 0.798, Test accuracy: 69.42
Round  32, Train loss: 0.754, Test loss: 0.773, Test accuracy: 70.08
Round  33, Train loss: 0.746, Test loss: 0.764, Test accuracy: 70.79
Round  34, Train loss: 0.773, Test loss: 0.761, Test accuracy: 71.52
Round  35, Train loss: 0.722, Test loss: 0.745, Test accuracy: 71.44
Round  36, Train loss: 0.698, Test loss: 0.749, Test accuracy: 71.22
Round  37, Train loss: 0.744, Test loss: 0.746, Test accuracy: 71.27
Round  38, Train loss: 0.740, Test loss: 0.746, Test accuracy: 71.53
Round  39, Train loss: 0.753, Test loss: 0.741, Test accuracy: 71.63
Round  40, Train loss: 0.714, Test loss: 0.733, Test accuracy: 72.09
Round  41, Train loss: 0.689, Test loss: 0.728, Test accuracy: 71.84
Round  42, Train loss: 0.692, Test loss: 0.728, Test accuracy: 72.37
Round  43, Train loss: 0.675, Test loss: 0.727, Test accuracy: 72.54
Round  44, Train loss: 0.673, Test loss: 0.722, Test accuracy: 72.35
Round  45, Train loss: 0.661, Test loss: 0.717, Test accuracy: 72.63
Round  46, Train loss: 0.688, Test loss: 0.716, Test accuracy: 72.18
Round  47, Train loss: 0.708, Test loss: 0.693, Test accuracy: 73.18
Round  48, Train loss: 0.632, Test loss: 0.699, Test accuracy: 73.24
Round  49, Train loss: 0.638, Test loss: 0.708, Test accuracy: 73.11
Round  50, Train loss: 0.662, Test loss: 0.695, Test accuracy: 73.41
Round  51, Train loss: 0.646, Test loss: 0.694, Test accuracy: 73.39
Round  52, Train loss: 0.647, Test loss: 0.696, Test accuracy: 73.59
Round  53, Train loss: 0.660, Test loss: 0.695, Test accuracy: 73.48
Round  54, Train loss: 0.565, Test loss: 0.688, Test accuracy: 73.76
Round  55, Train loss: 0.579, Test loss: 0.695, Test accuracy: 73.43
Round  56, Train loss: 0.625, Test loss: 0.687, Test accuracy: 73.63
Round  57, Train loss: 0.634, Test loss: 0.687, Test accuracy: 73.73
Round  58, Train loss: 0.629, Test loss: 0.681, Test accuracy: 74.03
Round  59, Train loss: 0.599, Test loss: 0.668, Test accuracy: 74.53
Round  60, Train loss: 0.571, Test loss: 0.674, Test accuracy: 73.98
Round  61, Train loss: 0.564, Test loss: 0.668, Test accuracy: 74.14
Round  62, Train loss: 0.605, Test loss: 0.660, Test accuracy: 74.45
Round  63, Train loss: 0.579, Test loss: 0.659, Test accuracy: 74.85
Round  64, Train loss: 0.578, Test loss: 0.659, Test accuracy: 74.52
Round  65, Train loss: 0.561, Test loss: 0.663, Test accuracy: 74.48
Round  66, Train loss: 0.579, Test loss: 0.655, Test accuracy: 74.85
Round  67, Train loss: 0.572, Test loss: 0.656, Test accuracy: 75.04
Round  68, Train loss: 0.546, Test loss: 0.648, Test accuracy: 75.63
Round  69, Train loss: 0.568, Test loss: 0.649, Test accuracy: 75.23
Round  70, Train loss: 0.578, Test loss: 0.648, Test accuracy: 75.48
Round  71, Train loss: 0.501, Test loss: 0.647, Test accuracy: 75.59
Round  72, Train loss: 0.528, Test loss: 0.649, Test accuracy: 75.45
Round  73, Train loss: 0.535, Test loss: 0.649, Test accuracy: 75.49
Round  74, Train loss: 0.494, Test loss: 0.647, Test accuracy: 75.52
Round  75, Train loss: 0.528, Test loss: 0.652, Test accuracy: 75.19
Round  76, Train loss: 0.500, Test loss: 0.651, Test accuracy: 75.00
Round  77, Train loss: 0.504, Test loss: 0.650, Test accuracy: 75.53
Round  78, Train loss: 0.499, Test loss: 0.649, Test accuracy: 75.26
Round  79, Train loss: 0.526, Test loss: 0.636, Test accuracy: 75.86
Round  80, Train loss: 0.500, Test loss: 0.639, Test accuracy: 75.62
Round  81, Train loss: 0.478, Test loss: 0.635, Test accuracy: 75.61
Round  82, Train loss: 0.452, Test loss: 0.631, Test accuracy: 75.90
Round  83, Train loss: 0.474, Test loss: 0.633, Test accuracy: 76.01
Round  84, Train loss: 0.468, Test loss: 0.637, Test accuracy: 75.98
Round  85, Train loss: 0.551, Test loss: 0.634, Test accuracy: 76.25
Round  86, Train loss: 0.486, Test loss: 0.629, Test accuracy: 75.99
Round  87, Train loss: 0.512, Test loss: 0.631, Test accuracy: 76.23
Round  88, Train loss: 0.454, Test loss: 0.631, Test accuracy: 76.16
Round  89, Train loss: 0.465, Test loss: 0.630, Test accuracy: 76.32
Round  90, Train loss: 0.438, Test loss: 0.632, Test accuracy: 76.16
Round  91, Train loss: 0.408, Test loss: 0.632, Test accuracy: 76.23
Round  92, Train loss: 0.430, Test loss: 0.628, Test accuracy: 76.47
Round  93, Train loss: 0.474, Test loss: 0.627, Test accuracy: 76.25
Round  94, Train loss: 0.455, Test loss: 0.628, Test accuracy: 76.42
Round  95, Train loss: 0.469, Test loss: 0.620, Test accuracy: 76.50
Round  96, Train loss: 0.420, Test loss: 0.622, Test accuracy: 76.75
Round  97, Train loss: 0.425, Test loss: 0.624, Test accuracy: 76.82
Round  98, Train loss: 0.438, Test loss: 0.627, Test accuracy: 76.83
Round  99, Train loss: 0.448, Test loss: 0.635, Test accuracy: 76.23
Final Round, Train loss: 0.380, Test loss: 0.638, Test accuracy: 76.56
Average accuracy final 10 rounds: 76.46600000000001
2351.0571477413177
[3.7754008769989014, 7.291133642196655, 10.878620386123657, 14.36937403678894, 17.854896068572998, 21.40616774559021, 24.94717502593994, 28.455953121185303, 31.9071524143219, 35.221041679382324, 38.7608380317688, 42.27692103385925, 45.838037729263306, 49.373045682907104, 52.907084703445435, 56.44575500488281, 59.87406945228577, 63.35129690170288, 66.89468789100647, 70.37575364112854, 73.81840085983276, 77.32627487182617, 80.72146129608154, 83.9223279953003, 87.21916031837463, 90.56345129013062, 94.08366417884827, 97.48212766647339, 101.0146632194519, 104.53932929039001, 108.04116821289062, 111.5362560749054, 115.0307674407959, 118.51681876182556, 121.96818590164185, 125.47163724899292, 128.9564504623413, 132.37020111083984, 135.86784195899963, 139.4096839427948, 142.70175743103027, 145.92510652542114, 149.23075532913208, 152.47445273399353, 155.6878731250763, 158.93502926826477, 162.16154170036316, 165.36086773872375, 168.57013130187988, 171.7855224609375, 175.03317379951477, 178.29079127311707, 181.43727588653564, 184.66367387771606, 187.93379092216492, 191.14151692390442, 194.35375380516052, 197.6137216091156, 200.8658549785614, 204.1773099899292, 207.50000286102295, 210.74601936340332, 213.93504905700684, 217.21041584014893, 220.5106201171875, 223.69618725776672, 226.85165858268738, 230.10895085334778, 233.336510181427, 236.6151933670044, 239.80135226249695, 243.06110858917236, 246.29933857917786, 249.5450894832611, 252.76934432983398, 256.0057384967804, 259.3118257522583, 262.5814542770386, 265.83852648735046, 269.0953276157379, 272.31646966934204, 275.56219244003296, 278.77145195007324, 281.9840190410614, 285.1867821216583, 288.42258739471436, 291.61792516708374, 294.82135486602783, 298.08491683006287, 301.31152987480164, 304.58490681648254, 307.89043521881104, 311.14085960388184, 314.37101674079895, 317.5799038410187, 320.91334891319275, 324.18280267715454, 327.47176456451416, 330.6941373348236, 333.96374702453613, 338.6960492134094]
[23.13, 32.64, 41.72, 44.85, 46.04, 50.44, 53.87, 55.81, 57.51, 57.14, 59.51, 59.28, 59.75, 60.6, 60.08, 61.71, 62.0, 62.7, 63.44, 64.73, 65.86, 67.05, 66.76, 67.78, 68.35, 68.91, 69.04, 69.67, 69.29, 69.86, 69.89, 69.42, 70.08, 70.79, 71.52, 71.44, 71.22, 71.27, 71.53, 71.63, 72.09, 71.84, 72.37, 72.54, 72.35, 72.63, 72.18, 73.18, 73.24, 73.11, 73.41, 73.39, 73.59, 73.48, 73.76, 73.43, 73.63, 73.73, 74.03, 74.53, 73.98, 74.14, 74.45, 74.85, 74.52, 74.48, 74.85, 75.04, 75.63, 75.23, 75.48, 75.59, 75.45, 75.49, 75.52, 75.19, 75.0, 75.53, 75.26, 75.86, 75.62, 75.61, 75.9, 76.01, 75.98, 76.25, 75.99, 76.23, 76.16, 76.32, 76.16, 76.23, 76.47, 76.25, 76.42, 76.5, 76.75, 76.82, 76.83, 76.23, 76.56]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  17.4500
Round 1 global test acc  21.3500
Round 2 global test acc  21.6400
Round 3 global test acc  25.1300
Round 4 global test acc  26.5300
Round 5 global test acc  26.4100
Round 6 global test acc  27.5500
Round 7 global test acc  26.9400
Round 8 global test acc  28.7300
Round 9 global test acc  27.9900
Round 10 global test acc  27.8700
Round 11 global test acc  34.6600
Round 12 global test acc  33.1100
Round 13 global test acc  35.1500
Round 14 global test acc  33.3200
Round 15 global test acc  34.8300
Round 16 global test acc  37.3200
Round 17 global test acc  34.6500
Round 18 global test acc  33.8800
Round 19 global test acc  33.0100
Round 20 global test acc  36.7700
Round 21 global test acc  38.5500
Round 22 global test acc  33.2100
Round 23 global test acc  30.6600
Round 24 global test acc  44.2900
Round 25 global test acc  35.3600
Round 26 global test acc  39.2900
Round 27 global test acc  34.0300
Round 28 global test acc  34.4000
Round 29 global test acc  43.1400
Round 30 global test acc  38.4900
Round 31 global test acc  33.8100
Round 32 global test acc  38.1300
Round 33 global test acc  40.0000
Round 34 global test acc  37.4300
Round 35 global test acc  36.7000
Round 36 global test acc  38.5700
Round 37 global test acc  38.0500
Round 38 global test acc  45.8500
Round 39 global test acc  36.9000
Round 40 global test acc  35.6600
Round 41 global test acc  36.9200
Round 42 global test acc  45.8400
Round 43 global test acc  42.0800
Round 44 global test acc  40.9500
Round 45 global test acc  34.2500
Round 46 global test acc  35.7800
Round 47 global test acc  40.8500
Round 48 global test acc  45.5900
Round 49 global test acc  38.3600
Round 50 global test acc  40.3800
Round 51 global test acc  42.4800
Round 52 global test acc  40.8600
Round 53 global test acc  37.5700
Round 54 global test acc  49.1300
Round 55 global test acc  37.9300
Round 56 global test acc  42.5500
Round 57 global test acc  42.2600
Round 58 global test acc  40.2900
Round 59 global test acc  43.4700
Round 60 global test acc  47.4900
Round 61 global test acc  40.0900
Round 62 global test acc  45.5900
Round 63 global test acc  42.6400
Round 64 global test acc  40.8500
Round 65 global test acc  37.1700
Round 66 global test acc  49.0400
Round 67 global test acc  45.0000
Round 68 global test acc  37.8800
Round 69 global test acc  43.1300
Round 70 global test acc  41.3800
Round 71 global test acc  41.1900
Round 72 global test acc  40.6900
Round 73 global test acc  44.9400
Round 74 global test acc  39.7900
Round 75 global test acc  38.7000
Round 76 global test acc  41.1100
Round 77 global test acc  40.8600
Round 78 global test acc  44.5600
Round 79 global test acc  40.1900
Round 80 global test acc  41.0700
Round 81 global test acc  40.2100
Round 82 global test acc  41.0300
Round 83 global test acc  40.9700
Round 84 global test acc  37.5500
Round 85 global test acc  34.9200
Round 86 global test acc  33.2000
Round 87 global test acc  31.8000
Round 88 global test acc  31.9700
Round 89 global test acc  31.5900
Round 90 global test acc  29.7300
Round 91 global test acc  29.2700
Round 92 global test acc  28.0800
Round 93 global test acc  26.6800
Round 94 global test acc  27.3900
Round 95 global test acc  27.7400
Round 96 global test acc  26.9600
Round 97 global test acc  27.7300
Round 98 global test acc  27.4000
Round 99 global test acc  27.4100
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.911, Test loss: 2.154, Test accuracy: 21.72
Round   1, Train loss: 1.426, Test loss: 2.094, Test accuracy: 30.25
Round   2, Train loss: 1.399, Test loss: 1.693, Test accuracy: 37.34
Round   3, Train loss: 1.238, Test loss: 1.432, Test accuracy: 42.56
Round   4, Train loss: 1.196, Test loss: 1.350, Test accuracy: 48.09
Round   5, Train loss: 1.104, Test loss: 1.280, Test accuracy: 50.40
Round   6, Train loss: 1.105, Test loss: 1.142, Test accuracy: 54.82
Round   7, Train loss: 1.091, Test loss: 1.021, Test accuracy: 57.71
Round   8, Train loss: 1.056, Test loss: 1.005, Test accuracy: 59.03
Round   9, Train loss: 1.027, Test loss: 0.988, Test accuracy: 60.97
Round  10, Train loss: 0.982, Test loss: 0.968, Test accuracy: 61.91
Round  11, Train loss: 0.966, Test loss: 0.952, Test accuracy: 62.50
Round  12, Train loss: 0.967, Test loss: 0.947, Test accuracy: 63.16
Round  13, Train loss: 0.952, Test loss: 0.923, Test accuracy: 64.14
Round  14, Train loss: 0.898, Test loss: 0.893, Test accuracy: 65.56
Round  15, Train loss: 0.945, Test loss: 0.874, Test accuracy: 66.56
Round  16, Train loss: 0.917, Test loss: 0.852, Test accuracy: 66.73
Round  17, Train loss: 0.901, Test loss: 0.851, Test accuracy: 66.97
Round  18, Train loss: 0.873, Test loss: 0.849, Test accuracy: 67.28
Round  19, Train loss: 0.835, Test loss: 0.832, Test accuracy: 67.93
Round  20, Train loss: 0.859, Test loss: 0.822, Test accuracy: 68.12
Round  21, Train loss: 0.792, Test loss: 0.809, Test accuracy: 68.39
Round  22, Train loss: 0.878, Test loss: 0.788, Test accuracy: 69.24
Round  23, Train loss: 0.753, Test loss: 0.782, Test accuracy: 69.61
Round  24, Train loss: 0.768, Test loss: 0.787, Test accuracy: 69.83
Round  25, Train loss: 0.825, Test loss: 0.782, Test accuracy: 69.90
Round  26, Train loss: 0.776, Test loss: 0.767, Test accuracy: 70.77
Round  27, Train loss: 0.798, Test loss: 0.759, Test accuracy: 70.39
Round  28, Train loss: 0.758, Test loss: 0.762, Test accuracy: 70.97
Round  29, Train loss: 0.721, Test loss: 0.750, Test accuracy: 70.99
Round  30, Train loss: 0.730, Test loss: 0.757, Test accuracy: 70.80
Round  31, Train loss: 0.729, Test loss: 0.741, Test accuracy: 71.06
Round  32, Train loss: 0.709, Test loss: 0.728, Test accuracy: 71.40
Round  33, Train loss: 0.731, Test loss: 0.722, Test accuracy: 71.70
Round  34, Train loss: 0.746, Test loss: 0.720, Test accuracy: 72.06
Round  35, Train loss: 0.713, Test loss: 0.717, Test accuracy: 71.93
Round  36, Train loss: 0.741, Test loss: 0.706, Test accuracy: 72.07
Round  37, Train loss: 0.712, Test loss: 0.703, Test accuracy: 72.56
Round  38, Train loss: 0.666, Test loss: 0.698, Test accuracy: 72.76
Round  39, Train loss: 0.631, Test loss: 0.698, Test accuracy: 72.74
Round  40, Train loss: 0.666, Test loss: 0.693, Test accuracy: 73.17
Round  41, Train loss: 0.672, Test loss: 0.678, Test accuracy: 73.43
Round  42, Train loss: 0.692, Test loss: 0.676, Test accuracy: 73.52
Round  43, Train loss: 0.688, Test loss: 0.681, Test accuracy: 73.20
Round  44, Train loss: 0.631, Test loss: 0.679, Test accuracy: 73.24
Round  45, Train loss: 0.629, Test loss: 0.682, Test accuracy: 73.71
Round  46, Train loss: 0.644, Test loss: 0.670, Test accuracy: 73.85
Round  47, Train loss: 0.605, Test loss: 0.671, Test accuracy: 74.15
Round  48, Train loss: 0.628, Test loss: 0.660, Test accuracy: 74.28
Round  49, Train loss: 0.578, Test loss: 0.662, Test accuracy: 74.54
Round  50, Train loss: 0.591, Test loss: 0.660, Test accuracy: 74.62
Round  51, Train loss: 0.578, Test loss: 0.655, Test accuracy: 74.78
Round  52, Train loss: 0.558, Test loss: 0.658, Test accuracy: 74.52
Round  53, Train loss: 0.619, Test loss: 0.654, Test accuracy: 74.82
Round  54, Train loss: 0.566, Test loss: 0.660, Test accuracy: 75.30
Round  55, Train loss: 0.560, Test loss: 0.658, Test accuracy: 74.65
Round  56, Train loss: 0.551, Test loss: 0.663, Test accuracy: 74.39
Round  57, Train loss: 0.527, Test loss: 0.649, Test accuracy: 74.77
Round  58, Train loss: 0.558, Test loss: 0.650, Test accuracy: 75.11
Round  59, Train loss: 0.591, Test loss: 0.642, Test accuracy: 75.31
Round  60, Train loss: 0.531, Test loss: 0.634, Test accuracy: 75.87
Round  61, Train loss: 0.556, Test loss: 0.631, Test accuracy: 75.64
Round  62, Train loss: 0.511, Test loss: 0.638, Test accuracy: 75.34
Round  63, Train loss: 0.523, Test loss: 0.631, Test accuracy: 76.01
Round  64, Train loss: 0.503, Test loss: 0.627, Test accuracy: 76.06
Round  65, Train loss: 0.497, Test loss: 0.627, Test accuracy: 75.98
Round  66, Train loss: 0.535, Test loss: 0.625, Test accuracy: 76.78
Round  67, Train loss: 0.504, Test loss: 0.632, Test accuracy: 76.42
Round  68, Train loss: 0.554, Test loss: 0.620, Test accuracy: 76.86
Round  69, Train loss: 0.516, Test loss: 0.628, Test accuracy: 76.33
Round  70, Train loss: 0.459, Test loss: 0.622, Test accuracy: 76.57
Round  71, Train loss: 0.480, Test loss: 0.623, Test accuracy: 76.63
Round  72, Train loss: 0.479, Test loss: 0.619, Test accuracy: 76.56
Round  73, Train loss: 0.433, Test loss: 0.622, Test accuracy: 76.34
Round  74, Train loss: 0.486, Test loss: 0.623, Test accuracy: 75.78
Round  75, Train loss: 0.475, Test loss: 0.616, Test accuracy: 76.43
Round  76, Train loss: 0.485, Test loss: 0.626, Test accuracy: 76.58
Round  77, Train loss: 0.458, Test loss: 0.614, Test accuracy: 76.95
Round  78, Train loss: 0.421, Test loss: 0.616, Test accuracy: 77.09
Round  79, Train loss: 0.455, Test loss: 0.619, Test accuracy: 76.87
Round  80, Train loss: 0.494, Test loss: 0.620, Test accuracy: 76.18
Round  81, Train loss: 0.416, Test loss: 0.623, Test accuracy: 76.23
Round  82, Train loss: 0.477, Test loss: 0.616, Test accuracy: 76.84
Round  83, Train loss: 0.401, Test loss: 0.610, Test accuracy: 76.78
Round  84, Train loss: 0.428, Test loss: 0.611, Test accuracy: 77.05
Round  85, Train loss: 0.462, Test loss: 0.614, Test accuracy: 76.63
Round  86, Train loss: 0.433, Test loss: 0.623, Test accuracy: 76.98
Round  87, Train loss: 0.419, Test loss: 0.616, Test accuracy: 76.70
Round  88, Train loss: 0.418, Test loss: 0.616, Test accuracy: 77.07
Round  89, Train loss: 0.431, Test loss: 0.606, Test accuracy: 77.50
Round  90, Train loss: 0.362, Test loss: 0.612, Test accuracy: 77.50
Round  91, Train loss: 0.380, Test loss: 0.614, Test accuracy: 77.19
Round  92, Train loss: 0.453, Test loss: 0.617, Test accuracy: 76.98
Round  93, Train loss: 0.372, Test loss: 0.609, Test accuracy: 77.63
Round  94, Train loss: 0.421, Test loss: 0.607, Test accuracy: 77.27
Round  95, Train loss: 0.468, Test loss: 0.606, Test accuracy: 77.47
Round  96, Train loss: 0.376, Test loss: 0.602, Test accuracy: 77.38
Round  97, Train loss: 0.398, Test loss: 0.607, Test accuracy: 77.69
Round  98, Train loss: 0.398, Test loss: 0.607, Test accuracy: 77.56
Round  99, Train loss: 0.406, Test loss: 0.613, Test accuracy: 77.28
Final Round, Train loss: 0.335, Test loss: 0.617, Test accuracy: 77.58
Average accuracy final 10 rounds: 77.395
1210.951967716217
[1.6926336288452148, 3.190842628479004, 4.693173885345459, 6.17510986328125, 7.689408540725708, 9.140713691711426, 10.705367088317871, 12.267613410949707, 13.816950559616089, 15.328917741775513, 16.887908697128296, 18.40541386604309, 19.884485006332397, 21.41258692741394, 22.91407012939453, 24.477137804031372, 25.961025714874268, 27.53799033164978, 29.017298698425293, 30.491027116775513, 32.035465478897095, 33.527976512908936, 35.026673316955566, 36.52393293380737, 38.02677869796753, 39.61083436012268, 41.13940477371216, 42.688010692596436, 44.228042125701904, 45.80185151100159, 47.299073696136475, 48.85378408432007, 50.41542720794678, 51.972678661346436, 53.55143880844116, 55.080291748046875, 56.61304044723511, 58.19277262687683, 59.74452352523804, 61.23223328590393, 62.74448919296265, 64.23647928237915, 65.78711676597595, 67.29655885696411, 68.81910991668701, 70.37450170516968, 71.90106511116028, 73.51787757873535, 75.03966045379639, 76.60058283805847, 78.10059571266174, 79.68339037895203, 81.18057680130005, 82.6393506526947, 84.00228118896484, 85.36527276039124, 86.76019763946533, 88.13947486877441, 89.51202607154846, 90.83209300041199, 92.27768206596375, 93.61355996131897, 94.98099112510681, 96.33644032478333, 97.69747853279114, 99.05959105491638, 100.42943930625916, 101.82463121414185, 103.18287467956543, 104.57164144515991, 106.01304340362549, 107.42973136901855, 108.82040476799011, 110.17608880996704, 111.54473567008972, 112.91020202636719, 114.28600025177002, 115.64289617538452, 117.01445031166077, 118.39257597923279, 119.76164436340332, 121.1155948638916, 122.46392250061035, 123.81940841674805, 125.1553316116333, 126.52559471130371, 127.87239527702332, 129.22887253761292, 130.76455211639404, 132.29673743247986, 133.85251426696777, 135.3913917541504, 136.95934581756592, 138.45969605445862, 140.07876467704773, 141.59821605682373, 143.16408586502075, 144.70634746551514, 146.24125695228577, 147.77267503738403, 150.0458505153656]
[21.72, 30.25, 37.34, 42.56, 48.09, 50.4, 54.82, 57.71, 59.03, 60.97, 61.91, 62.5, 63.16, 64.14, 65.56, 66.56, 66.73, 66.97, 67.28, 67.93, 68.12, 68.39, 69.24, 69.61, 69.83, 69.9, 70.77, 70.39, 70.97, 70.99, 70.8, 71.06, 71.4, 71.7, 72.06, 71.93, 72.07, 72.56, 72.76, 72.74, 73.17, 73.43, 73.52, 73.2, 73.24, 73.71, 73.85, 74.15, 74.28, 74.54, 74.62, 74.78, 74.52, 74.82, 75.3, 74.65, 74.39, 74.77, 75.11, 75.31, 75.87, 75.64, 75.34, 76.01, 76.06, 75.98, 76.78, 76.42, 76.86, 76.33, 76.57, 76.63, 76.56, 76.34, 75.78, 76.43, 76.58, 76.95, 77.09, 76.87, 76.18, 76.23, 76.84, 76.78, 77.05, 76.63, 76.98, 76.7, 77.07, 77.5, 77.5, 77.19, 76.98, 77.63, 77.27, 77.47, 77.38, 77.69, 77.56, 77.28, 77.58]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.0 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.938, Test loss: 2.066, Test accuracy: 27.78
Round   1, Train loss: 1.505, Test loss: 1.752, Test accuracy: 32.23
Round   2, Train loss: 1.364, Test loss: 1.584, Test accuracy: 41.33
Round   3, Train loss: 1.288, Test loss: 1.491, Test accuracy: 43.84
Round   4, Train loss: 1.192, Test loss: 1.362, Test accuracy: 49.51
Round   5, Train loss: 1.174, Test loss: 1.255, Test accuracy: 51.91
Round   6, Train loss: 1.087, Test loss: 1.223, Test accuracy: 55.03
Round   7, Train loss: 1.030, Test loss: 1.310, Test accuracy: 54.03
Round   8, Train loss: 1.030, Test loss: 1.159, Test accuracy: 56.45
Round   9, Train loss: 0.977, Test loss: 1.187, Test accuracy: 56.67
Round  10, Train loss: 1.035, Test loss: 1.025, Test accuracy: 61.19
Round  11, Train loss: 0.986, Test loss: 1.022, Test accuracy: 61.60
Round  12, Train loss: 0.950, Test loss: 0.967, Test accuracy: 62.56
Round  13, Train loss: 0.894, Test loss: 0.957, Test accuracy: 62.80
Round  14, Train loss: 0.973, Test loss: 0.915, Test accuracy: 64.26
Round  15, Train loss: 0.898, Test loss: 0.933, Test accuracy: 63.38
Round  16, Train loss: 0.926, Test loss: 0.955, Test accuracy: 63.79
Round  17, Train loss: 0.895, Test loss: 0.920, Test accuracy: 64.31
Round  18, Train loss: 0.890, Test loss: 0.873, Test accuracy: 65.43
Round  19, Train loss: 0.876, Test loss: 0.882, Test accuracy: 65.33
Round  20, Train loss: 0.837, Test loss: 0.812, Test accuracy: 68.60
Round  21, Train loss: 0.850, Test loss: 0.812, Test accuracy: 68.31
Round  22, Train loss: 0.811, Test loss: 0.781, Test accuracy: 69.71
Round  23, Train loss: 0.816, Test loss: 0.774, Test accuracy: 70.18
Round  24, Train loss: 0.826, Test loss: 0.767, Test accuracy: 70.70
Round  25, Train loss: 0.852, Test loss: 0.767, Test accuracy: 70.19
Round  26, Train loss: 0.750, Test loss: 0.755, Test accuracy: 70.85
Round  27, Train loss: 0.756, Test loss: 0.743, Test accuracy: 71.37
Round  28, Train loss: 0.777, Test loss: 0.734, Test accuracy: 71.60
Round  29, Train loss: 0.760, Test loss: 0.731, Test accuracy: 72.00
Round  30, Train loss: 0.768, Test loss: 0.727, Test accuracy: 72.34
Round  31, Train loss: 0.730, Test loss: 0.730, Test accuracy: 71.59
Round  32, Train loss: 0.707, Test loss: 0.716, Test accuracy: 72.56
Round  33, Train loss: 0.754, Test loss: 0.708, Test accuracy: 72.95
Round  34, Train loss: 0.702, Test loss: 0.699, Test accuracy: 73.19
Round  35, Train loss: 0.698, Test loss: 0.714, Test accuracy: 72.65
Round  36, Train loss: 0.682, Test loss: 0.702, Test accuracy: 73.26
Round  37, Train loss: 0.688, Test loss: 0.699, Test accuracy: 72.83
Round  38, Train loss: 0.663, Test loss: 0.686, Test accuracy: 73.14
Round  39, Train loss: 0.691, Test loss: 0.694, Test accuracy: 73.33
Round  40, Train loss: 0.649, Test loss: 0.686, Test accuracy: 73.36
Round  41, Train loss: 0.620, Test loss: 0.680, Test accuracy: 73.28
Round  42, Train loss: 0.678, Test loss: 0.678, Test accuracy: 74.23
Round  43, Train loss: 0.630, Test loss: 0.670, Test accuracy: 74.64
Round  44, Train loss: 0.617, Test loss: 0.669, Test accuracy: 74.52
Round  45, Train loss: 0.615, Test loss: 0.662, Test accuracy: 74.59
Round  46, Train loss: 0.574, Test loss: 0.669, Test accuracy: 74.38
Round  47, Train loss: 0.618, Test loss: 0.663, Test accuracy: 74.18
Round  48, Train loss: 0.598, Test loss: 0.661, Test accuracy: 74.67
Round  49, Train loss: 0.629, Test loss: 0.653, Test accuracy: 74.90
Round  50, Train loss: 0.651, Test loss: 0.648, Test accuracy: 75.35
Round  51, Train loss: 0.578, Test loss: 0.640, Test accuracy: 75.66
Round  52, Train loss: 0.563, Test loss: 0.645, Test accuracy: 75.47
Round  53, Train loss: 0.579, Test loss: 0.649, Test accuracy: 75.31
Round  54, Train loss: 0.590, Test loss: 0.651, Test accuracy: 75.27
Round  55, Train loss: 0.583, Test loss: 0.641, Test accuracy: 75.96
Round  56, Train loss: 0.535, Test loss: 0.648, Test accuracy: 75.48
Round  57, Train loss: 0.541, Test loss: 0.645, Test accuracy: 75.35
Round  58, Train loss: 0.548, Test loss: 0.636, Test accuracy: 75.86
Round  59, Train loss: 0.533, Test loss: 0.644, Test accuracy: 75.49
Round  60, Train loss: 0.500, Test loss: 0.643, Test accuracy: 75.71
Round  61, Train loss: 0.550, Test loss: 0.639, Test accuracy: 75.54
Round  62, Train loss: 0.528, Test loss: 0.640, Test accuracy: 75.45
Round  63, Train loss: 0.493, Test loss: 0.636, Test accuracy: 75.94
Round  64, Train loss: 0.487, Test loss: 0.629, Test accuracy: 76.51
Round  65, Train loss: 0.462, Test loss: 0.623, Test accuracy: 76.61
Round  66, Train loss: 0.504, Test loss: 0.631, Test accuracy: 76.30
Round  67, Train loss: 0.484, Test loss: 0.635, Test accuracy: 76.09
Round  68, Train loss: 0.541, Test loss: 0.643, Test accuracy: 75.51
Round  69, Train loss: 0.511, Test loss: 0.633, Test accuracy: 75.83
Round  70, Train loss: 0.500, Test loss: 0.617, Test accuracy: 76.76
Round  71, Train loss: 0.477, Test loss: 0.629, Test accuracy: 76.41
Round  72, Train loss: 0.530, Test loss: 0.622, Test accuracy: 76.56
Round  73, Train loss: 0.467, Test loss: 0.624, Test accuracy: 76.33
Round  74, Train loss: 0.407, Test loss: 0.623, Test accuracy: 76.98
Round  75, Train loss: 0.508, Test loss: 0.623, Test accuracy: 76.62
Round  76, Train loss: 0.440, Test loss: 0.615, Test accuracy: 76.73
Round  77, Train loss: 0.498, Test loss: 0.636, Test accuracy: 76.47
Round  78, Train loss: 0.436, Test loss: 0.633, Test accuracy: 76.17
Round  79, Train loss: 0.454, Test loss: 0.635, Test accuracy: 76.19
Round  80, Train loss: 0.419, Test loss: 0.625, Test accuracy: 76.36
Round  81, Train loss: 0.499, Test loss: 0.617, Test accuracy: 76.76
Round  82, Train loss: 0.464, Test loss: 0.617, Test accuracy: 76.71
Round  83, Train loss: 0.412, Test loss: 0.615, Test accuracy: 76.72
Round  84, Train loss: 0.463, Test loss: 0.625, Test accuracy: 76.54
Round  85, Train loss: 0.478, Test loss: 0.614, Test accuracy: 77.25
Round  86, Train loss: 0.435, Test loss: 0.610, Test accuracy: 77.26
Round  87, Train loss: 0.433, Test loss: 0.613, Test accuracy: 77.20
Round  88, Train loss: 0.444, Test loss: 0.605, Test accuracy: 77.45
Round  89, Train loss: 0.424, Test loss: 0.612, Test accuracy: 76.95
Round  90, Train loss: 0.411, Test loss: 0.605, Test accuracy: 77.80
Round  91, Train loss: 0.410, Test loss: 0.608, Test accuracy: 77.39
Round  92, Train loss: 0.385, Test loss: 0.608, Test accuracy: 77.62
Round  93, Train loss: 0.442, Test loss: 0.599, Test accuracy: 78.06
Round  94, Train loss: 0.425, Test loss: 0.608, Test accuracy: 77.64
Round  95, Train loss: 0.388, Test loss: 0.612, Test accuracy: 77.42
Round  96, Train loss: 0.381, Test loss: 0.607, Test accuracy: 77.83
Round  97, Train loss: 0.378, Test loss: 0.613, Test accuracy: 77.40
Round  98, Train loss: 0.414, Test loss: 0.614, Test accuracy: 77.61
Round  99, Train loss: 0.367, Test loss: 0.607, Test accuracy: 78.08
Final Round, Train loss: 0.270, Test loss: 0.612, Test accuracy: 77.90
Average accuracy final 10 rounds: 77.685
2137.108752965927
[1.8314383029937744, 3.3608148097991943, 4.875320196151733, 6.4589903354644775, 7.970244884490967, 9.49238109588623, 10.993110418319702, 12.482733011245728, 13.97607707977295, 15.482263803482056, 16.974781274795532, 18.474202394485474, 19.971821546554565, 21.465508699417114, 22.957160711288452, 24.319641828536987, 25.701977014541626, 27.063312292099, 28.46008276939392, 29.817140579223633, 31.20246386528015, 34.82098889350891, 38.498942375183105, 42.144193172454834, 45.88906478881836, 49.512184143066406, 53.207484006881714, 56.84466886520386, 60.46073031425476, 64.25346207618713, 68.16897296905518, 71.81962656974792, 75.51902413368225, 79.12335395812988, 82.87274289131165, 86.6518235206604, 90.29213738441467, 94.00069212913513, 97.79260683059692, 101.4307472705841, 105.02048969268799, 108.72016048431396, 112.42991495132446, 115.9023802280426, 119.88225221633911, 123.76001286506653, 127.51767826080322, 131.17281436920166, 134.82185816764832, 138.44262599945068, 142.18327689170837, 145.83103704452515, 149.79187726974487, 153.66231417655945, 157.500385761261, 161.025958776474, 164.49716520309448, 168.1751832962036, 171.76986241340637, 175.59727358818054, 179.11506390571594, 182.53167057037354, 185.944509267807, 189.54292821884155, 193.04883241653442, 196.64611268043518, 200.26229166984558, 203.90891218185425, 207.55527782440186, 211.20999431610107, 214.83826065063477, 218.58960461616516, 222.10837531089783, 225.63425374031067, 229.27596044540405, 232.83129835128784, 236.30074524879456, 239.92391347885132, 243.4854462146759, 247.07861876487732, 250.56777215003967, 254.0544056892395, 257.6135036945343, 261.11247158050537, 264.5914170742035, 268.2194061279297, 271.74742221832275, 275.244841337204, 278.80486583709717, 282.3303804397583, 285.88405203819275, 289.4639627933502, 292.968994140625, 296.57768988609314, 300.30067586898804, 303.8651747703552, 307.48806500434875, 311.14698100090027, 314.8073048591614, 318.5857620239258, 320.74743604660034]
[27.78, 32.23, 41.33, 43.84, 49.51, 51.91, 55.03, 54.03, 56.45, 56.67, 61.19, 61.6, 62.56, 62.8, 64.26, 63.38, 63.79, 64.31, 65.43, 65.33, 68.6, 68.31, 69.71, 70.18, 70.7, 70.19, 70.85, 71.37, 71.6, 72.0, 72.34, 71.59, 72.56, 72.95, 73.19, 72.65, 73.26, 72.83, 73.14, 73.33, 73.36, 73.28, 74.23, 74.64, 74.52, 74.59, 74.38, 74.18, 74.67, 74.9, 75.35, 75.66, 75.47, 75.31, 75.27, 75.96, 75.48, 75.35, 75.86, 75.49, 75.71, 75.54, 75.45, 75.94, 76.51, 76.61, 76.3, 76.09, 75.51, 75.83, 76.76, 76.41, 76.56, 76.33, 76.98, 76.62, 76.73, 76.47, 76.17, 76.19, 76.36, 76.76, 76.71, 76.72, 76.54, 77.25, 77.26, 77.2, 77.45, 76.95, 77.8, 77.39, 77.62, 78.06, 77.64, 77.42, 77.83, 77.4, 77.61, 78.08, 77.9]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: none, level_n_system: 0.0 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.957, Test loss: 1.858, Test accuracy: 27.05
Round   1, Train loss: 1.513, Test loss: 1.369, Test accuracy: 42.36
Round   2, Train loss: 1.336, Test loss: 1.240, Test accuracy: 48.74
Round   3, Train loss: 1.246, Test loss: 1.152, Test accuracy: 53.10
Round   4, Train loss: 1.173, Test loss: 1.082, Test accuracy: 55.51
Round   5, Train loss: 1.116, Test loss: 1.027, Test accuracy: 58.42
Round   6, Train loss: 1.075, Test loss: 0.988, Test accuracy: 60.30
Round   7, Train loss: 1.042, Test loss: 0.964, Test accuracy: 61.48
Round   8, Train loss: 1.015, Test loss: 0.941, Test accuracy: 62.44
Round   9, Train loss: 0.993, Test loss: 0.913, Test accuracy: 63.89
Round  10, Train loss: 0.972, Test loss: 0.890, Test accuracy: 65.14
Round  11, Train loss: 0.949, Test loss: 0.874, Test accuracy: 65.73
Round  12, Train loss: 0.928, Test loss: 0.851, Test accuracy: 66.50
Round  13, Train loss: 0.912, Test loss: 0.842, Test accuracy: 66.83
Round  14, Train loss: 0.892, Test loss: 0.824, Test accuracy: 67.67
Round  15, Train loss: 0.874, Test loss: 0.811, Test accuracy: 68.94
Round  16, Train loss: 0.864, Test loss: 0.795, Test accuracy: 68.78
Round  17, Train loss: 0.848, Test loss: 0.791, Test accuracy: 69.49
Round  18, Train loss: 0.835, Test loss: 0.784, Test accuracy: 69.57
Round  19, Train loss: 0.823, Test loss: 0.769, Test accuracy: 70.13
Round  20, Train loss: 0.841, Test loss: 0.766, Test accuracy: 70.48
Round  21, Train loss: 0.808, Test loss: 0.758, Test accuracy: 70.62
Round  22, Train loss: 0.776, Test loss: 0.759, Test accuracy: 70.75
Round  23, Train loss: 0.783, Test loss: 0.755, Test accuracy: 70.98
Round  24, Train loss: 0.745, Test loss: 0.746, Test accuracy: 71.04
Round  25, Train loss: 0.750, Test loss: 0.735, Test accuracy: 71.70
Round  26, Train loss: 0.771, Test loss: 0.731, Test accuracy: 71.60
Round  27, Train loss: 0.790, Test loss: 0.726, Test accuracy: 72.09
Round  28, Train loss: 0.699, Test loss: 0.722, Test accuracy: 72.23
Round  29, Train loss: 0.767, Test loss: 0.714, Test accuracy: 72.45
Round  30, Train loss: 0.695, Test loss: 0.717, Test accuracy: 72.77
Round  31, Train loss: 0.680, Test loss: 0.701, Test accuracy: 72.95
Round  32, Train loss: 0.708, Test loss: 0.696, Test accuracy: 73.20
Round  33, Train loss: 0.716, Test loss: 0.709, Test accuracy: 72.89
Round  34, Train loss: 0.669, Test loss: 0.694, Test accuracy: 73.02
Round  35, Train loss: 0.688, Test loss: 0.687, Test accuracy: 73.83
Round  36, Train loss: 0.660, Test loss: 0.692, Test accuracy: 73.93
Round  37, Train loss: 0.685, Test loss: 0.682, Test accuracy: 73.91
Round  38, Train loss: 0.633, Test loss: 0.670, Test accuracy: 74.27
Round  39, Train loss: 0.611, Test loss: 0.667, Test accuracy: 74.69
Round  40, Train loss: 0.602, Test loss: 0.675, Test accuracy: 74.16
Round  41, Train loss: 0.619, Test loss: 0.674, Test accuracy: 74.46
Round  42, Train loss: 0.633, Test loss: 0.655, Test accuracy: 75.05
Round  43, Train loss: 0.628, Test loss: 0.661, Test accuracy: 74.71
Round  44, Train loss: 0.649, Test loss: 0.670, Test accuracy: 73.96
Round  45, Train loss: 0.590, Test loss: 0.660, Test accuracy: 74.42
Round  46, Train loss: 0.584, Test loss: 0.654, Test accuracy: 74.87
Round  47, Train loss: 0.585, Test loss: 0.652, Test accuracy: 75.04
Round  48, Train loss: 0.547, Test loss: 0.652, Test accuracy: 75.19
Round  49, Train loss: 0.582, Test loss: 0.646, Test accuracy: 75.84
Round  50, Train loss: 0.521, Test loss: 0.646, Test accuracy: 75.45
Round  51, Train loss: 0.559, Test loss: 0.646, Test accuracy: 75.63
Round  52, Train loss: 0.517, Test loss: 0.640, Test accuracy: 75.55
Round  53, Train loss: 0.526, Test loss: 0.634, Test accuracy: 76.18
Round  54, Train loss: 0.519, Test loss: 0.629, Test accuracy: 76.26
Round  55, Train loss: 0.568, Test loss: 0.622, Test accuracy: 76.25
Round  56, Train loss: 0.535, Test loss: 0.631, Test accuracy: 75.82
Round  57, Train loss: 0.558, Test loss: 0.628, Test accuracy: 75.42
Round  58, Train loss: 0.553, Test loss: 0.630, Test accuracy: 75.82
Round  59, Train loss: 0.504, Test loss: 0.627, Test accuracy: 75.77
Round  60, Train loss: 0.512, Test loss: 0.628, Test accuracy: 75.98
Round  61, Train loss: 0.524, Test loss: 0.624, Test accuracy: 76.07
Round  62, Train loss: 0.546, Test loss: 0.614, Test accuracy: 76.54
Round  63, Train loss: 0.533, Test loss: 0.623, Test accuracy: 75.95
Round  64, Train loss: 0.546, Test loss: 0.615, Test accuracy: 76.58
Round  65, Train loss: 0.534, Test loss: 0.614, Test accuracy: 77.00
Round  66, Train loss: 0.450, Test loss: 0.614, Test accuracy: 76.57
Round  67, Train loss: 0.493, Test loss: 0.621, Test accuracy: 76.23
Round  68, Train loss: 0.478, Test loss: 0.610, Test accuracy: 76.66
Round  69, Train loss: 0.479, Test loss: 0.606, Test accuracy: 76.84
Round  70, Train loss: 0.434, Test loss: 0.619, Test accuracy: 76.35
Round  71, Train loss: 0.417, Test loss: 0.616, Test accuracy: 76.53
Round  72, Train loss: 0.522, Test loss: 0.613, Test accuracy: 77.28
Round  73, Train loss: 0.462, Test loss: 0.617, Test accuracy: 76.91
Round  74, Train loss: 0.495, Test loss: 0.611, Test accuracy: 76.93
Round  75, Train loss: 0.485, Test loss: 0.610, Test accuracy: 76.97
Round  76, Train loss: 0.448, Test loss: 0.602, Test accuracy: 77.45
Round  77, Train loss: 0.405, Test loss: 0.599, Test accuracy: 77.22
Round  78, Train loss: 0.416, Test loss: 0.608, Test accuracy: 77.18
Round  79, Train loss: 0.475, Test loss: 0.601, Test accuracy: 77.57
Round  80, Train loss: 0.375, Test loss: 0.599, Test accuracy: 77.51
Round  81, Train loss: 0.359, Test loss: 0.608, Test accuracy: 77.22
Round  82, Train loss: 0.341, Test loss: 0.608, Test accuracy: 77.55
Round  83, Train loss: 0.333, Test loss: 0.608, Test accuracy: 77.39
Round  84, Train loss: 0.329, Test loss: 0.605, Test accuracy: 77.67
Round  85, Train loss: 0.319, Test loss: 0.613, Test accuracy: 77.08
Round  86, Train loss: 0.307, Test loss: 0.612, Test accuracy: 77.42
Round  87, Train loss: 0.301, Test loss: 0.615, Test accuracy: 77.04
Round  88, Train loss: 0.302, Test loss: 0.617, Test accuracy: 77.26
Round  89, Train loss: 0.290, Test loss: 0.618, Test accuracy: 77.34
Round  90, Train loss: 0.281, Test loss: 0.621, Test accuracy: 77.14
Round  91, Train loss: 0.281, Test loss: 0.621, Test accuracy: 77.24
Round  92, Train loss: 0.276, Test loss: 0.623, Test accuracy: 76.74
Round  93, Train loss: 0.268, Test loss: 0.630, Test accuracy: 76.74
Round  94, Train loss: 0.268, Test loss: 0.623, Test accuracy: 76.92
Round  95, Train loss: 0.261, Test loss: 0.626, Test accuracy: 76.64
Round  96, Train loss: 0.243, Test loss: 0.631, Test accuracy: 76.79
Round  97, Train loss: 0.253, Test loss: 0.631, Test accuracy: 76.99
Round  98, Train loss: 0.247, Test loss: 0.639, Test accuracy: 76.71
Round  99, Train loss: 0.235, Test loss: 0.635, Test accuracy: 76.78
Final Round, Train loss: 0.181, Test loss: 0.639, Test accuracy: 76.86
Average accuracy final 10 rounds: 76.869
1750.2934086322784
[1.8643097877502441, 3.4423880577087402, 5.011370420455933, 6.576944589614868, 8.189580917358398, 9.793939352035522, 11.366347551345825, 12.94789171218872, 14.51061487197876, 16.08690619468689, 17.661171674728394, 19.229512453079224, 20.800543785095215, 22.39348530769348, 23.967096090316772, 25.511882781982422, 27.083993911743164, 28.678211212158203, 30.267346382141113, 31.833835124969482, 33.414324045181274, 34.96552848815918, 36.5136559009552, 38.065420150756836, 39.65370035171509, 41.20014405250549, 42.75205588340759, 44.30552363395691, 45.85320568084717, 47.40686893463135, 48.97370195388794, 50.52386975288391, 52.10358691215515, 53.660688400268555, 55.21781349182129, 56.76237154006958, 58.338637351989746, 59.88806366920471, 61.43601655960083, 62.983741760253906, 64.52810525894165, 66.09831857681274, 67.67090272903442, 69.21316432952881, 70.79961085319519, 72.35808563232422, 73.93804216384888, 75.51877188682556, 77.05823159217834, 78.6057333946228, 80.13595986366272, 81.67709851264954, 83.27727007865906, 84.85215306282043, 86.38630557060242, 87.90856885910034, 89.44540810585022, 91.01958322525024, 92.5445544719696, 94.08238363265991, 95.637380361557, 97.17047023773193, 98.72230195999146, 100.2604570388794, 101.80876326560974, 103.32709741592407, 104.86093020439148, 106.3642258644104, 107.86701726913452, 109.34793090820312, 110.87237358093262, 112.34207034111023, 113.90298008918762, 115.41141128540039, 116.91642713546753, 118.44164276123047, 119.9584391117096, 121.46738624572754, 122.93228149414062, 124.29102182388306, 125.69292879104614, 127.0380425453186, 128.40680575370789, 129.76049065589905, 131.17182540893555, 132.53071880340576, 133.88785219192505, 135.22725772857666, 136.57356095314026, 137.94974493980408, 139.39190912246704, 140.8028211593628, 142.39305901527405, 143.85503435134888, 145.3064923286438, 146.68769192695618, 148.0752785205841, 149.474027633667, 150.83369874954224, 152.24919605255127, 154.43184399604797]
[27.05, 42.36, 48.74, 53.1, 55.51, 58.42, 60.3, 61.48, 62.44, 63.89, 65.14, 65.73, 66.5, 66.83, 67.67, 68.94, 68.78, 69.49, 69.57, 70.13, 70.48, 70.62, 70.75, 70.98, 71.04, 71.7, 71.6, 72.09, 72.23, 72.45, 72.77, 72.95, 73.2, 72.89, 73.02, 73.83, 73.93, 73.91, 74.27, 74.69, 74.16, 74.46, 75.05, 74.71, 73.96, 74.42, 74.87, 75.04, 75.19, 75.84, 75.45, 75.63, 75.55, 76.18, 76.26, 76.25, 75.82, 75.42, 75.82, 75.77, 75.98, 76.07, 76.54, 75.95, 76.58, 77.0, 76.57, 76.23, 76.66, 76.84, 76.35, 76.53, 77.28, 76.91, 76.93, 76.97, 77.45, 77.22, 77.18, 77.57, 77.51, 77.22, 77.55, 77.39, 77.67, 77.08, 77.42, 77.04, 77.26, 77.34, 77.14, 77.24, 76.74, 76.74, 76.92, 76.64, 76.79, 76.99, 76.71, 76.78, 76.86]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.0 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.956, Test loss: 1.811, Test accuracy: 33.78
Round   1, Train loss: 1.480, Test loss: 1.341, Test accuracy: 41.59
Round   2, Train loss: 1.316, Test loss: 1.216, Test accuracy: 49.43
Round   3, Train loss: 1.223, Test loss: 1.127, Test accuracy: 54.71
Round   4, Train loss: 1.158, Test loss: 1.067, Test accuracy: 56.72
Round   5, Train loss: 1.108, Test loss: 1.020, Test accuracy: 59.23
Round   6, Train loss: 1.068, Test loss: 0.993, Test accuracy: 60.07
Round   7, Train loss: 1.037, Test loss: 0.964, Test accuracy: 61.79
Round   8, Train loss: 1.014, Test loss: 0.941, Test accuracy: 62.57
Round   9, Train loss: 0.991, Test loss: 0.922, Test accuracy: 62.98
Round  10, Train loss: 0.972, Test loss: 0.899, Test accuracy: 64.43
Round  11, Train loss: 0.955, Test loss: 0.884, Test accuracy: 64.90
Round  12, Train loss: 0.938, Test loss: 0.871, Test accuracy: 65.73
Round  13, Train loss: 0.919, Test loss: 0.854, Test accuracy: 66.65
Round  14, Train loss: 0.904, Test loss: 0.840, Test accuracy: 67.47
Round  15, Train loss: 0.887, Test loss: 0.832, Test accuracy: 67.32
Round  16, Train loss: 0.874, Test loss: 0.819, Test accuracy: 68.44
Round  17, Train loss: 0.858, Test loss: 0.806, Test accuracy: 68.73
Round  18, Train loss: 0.845, Test loss: 0.805, Test accuracy: 68.43
Round  19, Train loss: 0.831, Test loss: 0.794, Test accuracy: 69.13
Round  20, Train loss: 0.838, Test loss: 0.796, Test accuracy: 68.89
Round  21, Train loss: 0.831, Test loss: 0.801, Test accuracy: 68.81
Round  22, Train loss: 0.783, Test loss: 0.808, Test accuracy: 68.64
Round  23, Train loss: 0.806, Test loss: 0.807, Test accuracy: 68.76
Round  24, Train loss: 0.800, Test loss: 0.783, Test accuracy: 69.46
Round  25, Train loss: 0.742, Test loss: 0.771, Test accuracy: 70.52
Round  26, Train loss: 0.756, Test loss: 0.766, Test accuracy: 70.66
Round  27, Train loss: 0.767, Test loss: 0.767, Test accuracy: 70.59
Round  28, Train loss: 0.699, Test loss: 0.770, Test accuracy: 69.78
Round  29, Train loss: 0.739, Test loss: 0.760, Test accuracy: 70.01
Round  30, Train loss: 0.762, Test loss: 0.740, Test accuracy: 71.30
Round  31, Train loss: 0.727, Test loss: 0.736, Test accuracy: 71.19
Round  32, Train loss: 0.717, Test loss: 0.766, Test accuracy: 69.94
Round  33, Train loss: 0.641, Test loss: 0.748, Test accuracy: 70.51
Round  34, Train loss: 0.682, Test loss: 0.750, Test accuracy: 71.00
Round  35, Train loss: 0.678, Test loss: 0.746, Test accuracy: 71.02
Round  36, Train loss: 0.663, Test loss: 0.730, Test accuracy: 71.28
Round  37, Train loss: 0.634, Test loss: 0.715, Test accuracy: 72.11
Round  38, Train loss: 0.705, Test loss: 0.712, Test accuracy: 72.10
Round  39, Train loss: 0.704, Test loss: 0.702, Test accuracy: 72.70
Round  40, Train loss: 0.666, Test loss: 0.705, Test accuracy: 72.89
Round  41, Train loss: 0.677, Test loss: 0.694, Test accuracy: 73.30
Round  42, Train loss: 0.618, Test loss: 0.701, Test accuracy: 72.81
Round  43, Train loss: 0.646, Test loss: 0.703, Test accuracy: 72.60
Round  44, Train loss: 0.607, Test loss: 0.693, Test accuracy: 72.90
Round  45, Train loss: 0.582, Test loss: 0.689, Test accuracy: 73.38
Round  46, Train loss: 0.574, Test loss: 0.686, Test accuracy: 73.32
Round  47, Train loss: 0.624, Test loss: 0.695, Test accuracy: 73.90
Round  48, Train loss: 0.593, Test loss: 0.691, Test accuracy: 73.14
Round  49, Train loss: 0.582, Test loss: 0.685, Test accuracy: 73.66
Round  50, Train loss: 0.589, Test loss: 0.682, Test accuracy: 73.83
Round  51, Train loss: 0.563, Test loss: 0.677, Test accuracy: 73.83
Round  52, Train loss: 0.575, Test loss: 0.667, Test accuracy: 74.08
Round  53, Train loss: 0.579, Test loss: 0.664, Test accuracy: 74.37
Round  54, Train loss: 0.525, Test loss: 0.661, Test accuracy: 74.93
Round  55, Train loss: 0.580, Test loss: 0.668, Test accuracy: 74.86
Round  56, Train loss: 0.578, Test loss: 0.664, Test accuracy: 75.05
Round  57, Train loss: 0.533, Test loss: 0.666, Test accuracy: 74.63
Round  58, Train loss: 0.534, Test loss: 0.665, Test accuracy: 74.76
Round  59, Train loss: 0.517, Test loss: 0.659, Test accuracy: 75.13
Round  60, Train loss: 0.510, Test loss: 0.659, Test accuracy: 75.09
Round  61, Train loss: 0.521, Test loss: 0.650, Test accuracy: 75.20
Round  62, Train loss: 0.531, Test loss: 0.652, Test accuracy: 75.12
Round  63, Train loss: 0.481, Test loss: 0.660, Test accuracy: 74.65
Round  64, Train loss: 0.530, Test loss: 0.654, Test accuracy: 74.92
Round  65, Train loss: 0.510, Test loss: 0.654, Test accuracy: 74.99
Round  66, Train loss: 0.554, Test loss: 0.649, Test accuracy: 75.37
Round  67, Train loss: 0.526, Test loss: 0.654, Test accuracy: 75.31
Round  68, Train loss: 0.479, Test loss: 0.646, Test accuracy: 75.74
Round  69, Train loss: 0.436, Test loss: 0.653, Test accuracy: 75.54
Round  70, Train loss: 0.502, Test loss: 0.650, Test accuracy: 75.57
Round  71, Train loss: 0.472, Test loss: 0.646, Test accuracy: 75.47
Round  72, Train loss: 0.456, Test loss: 0.640, Test accuracy: 75.76
Round  73, Train loss: 0.435, Test loss: 0.653, Test accuracy: 75.03
Round  74, Train loss: 0.438, Test loss: 0.657, Test accuracy: 75.30
Round  75, Train loss: 0.476, Test loss: 0.645, Test accuracy: 75.41
Round  76, Train loss: 0.409, Test loss: 0.639, Test accuracy: 75.45
Round  77, Train loss: 0.493, Test loss: 0.636, Test accuracy: 75.89
Round  78, Train loss: 0.487, Test loss: 0.646, Test accuracy: 75.64
Round  79, Train loss: 0.462, Test loss: 0.635, Test accuracy: 76.39
Round  80, Train loss: 0.381, Test loss: 0.630, Test accuracy: 76.12
Round  81, Train loss: 0.362, Test loss: 0.632, Test accuracy: 76.24
Round  82, Train loss: 0.349, Test loss: 0.633, Test accuracy: 76.40
Round  83, Train loss: 0.339, Test loss: 0.639, Test accuracy: 75.84
Round  84, Train loss: 0.326, Test loss: 0.641, Test accuracy: 75.89
Round  85, Train loss: 0.319, Test loss: 0.645, Test accuracy: 75.90
Round  86, Train loss: 0.324, Test loss: 0.650, Test accuracy: 75.29
Round  87, Train loss: 0.306, Test loss: 0.645, Test accuracy: 76.05
Round  88, Train loss: 0.294, Test loss: 0.649, Test accuracy: 75.69
Round  89, Train loss: 0.296, Test loss: 0.646, Test accuracy: 75.85
Round  90, Train loss: 0.290, Test loss: 0.654, Test accuracy: 75.66
Round  91, Train loss: 0.279, Test loss: 0.655, Test accuracy: 75.58
Round  92, Train loss: 0.282, Test loss: 0.659, Test accuracy: 75.70
Round  93, Train loss: 0.274, Test loss: 0.662, Test accuracy: 75.51
Round  94, Train loss: 0.271, Test loss: 0.659, Test accuracy: 75.33
Round  95, Train loss: 0.262, Test loss: 0.657, Test accuracy: 75.49
Round  96, Train loss: 0.259, Test loss: 0.660, Test accuracy: 75.41
Round  97, Train loss: 0.252, Test loss: 0.668, Test accuracy: 75.11
Round  98, Train loss: 0.248, Test loss: 0.672, Test accuracy: 75.16
Round  99, Train loss: 0.241, Test loss: 0.675, Test accuracy: 74.91
Final Round, Train loss: 0.182, Test loss: 0.681, Test accuracy: 74.98
Average accuracy final 10 rounds: 75.386
3127.0664904117584
[1.8820769786834717, 3.4981260299682617, 5.126502275466919, 6.747767686843872, 8.355848789215088, 9.975468635559082, 11.576145648956299, 13.183925151824951, 14.821014165878296, 16.42405676841736, 18.06184196472168, 19.678682804107666, 21.280979871749878, 22.871714115142822, 24.492707014083862, 26.08585262298584, 27.68401002883911, 29.292588233947754, 30.857868671417236, 32.30088448524475, 33.759546518325806, 37.766507148742676, 41.78603196144104, 45.97958731651306, 50.07273578643799, 54.14416742324829, 58.24779748916626, 62.277897357940674, 66.34063959121704, 70.46796083450317, 74.57274556159973, 78.64000391960144, 82.7577691078186, 86.84303045272827, 91.04309964179993, 95.18331837654114, 99.32304167747498, 103.52563858032227, 107.69974493980408, 111.64337658882141, 115.72959470748901, 119.93037247657776, 124.12383389472961, 128.19227504730225, 132.15167045593262, 135.988431930542, 140.01327061653137, 143.95842957496643, 148.0008716583252, 152.16611409187317, 156.29414558410645, 160.26664876937866, 164.27833080291748, 168.33588004112244, 172.41635823249817, 176.3480851650238, 180.23864436149597, 184.26984977722168, 188.42298436164856, 192.53723335266113, 196.74404788017273, 200.89413619041443, 205.04075145721436, 209.0386700630188, 213.22360134124756, 217.35319209098816, 221.49178194999695, 225.62970781326294, 229.63286113739014, 233.71098017692566, 237.83850026130676, 241.991544008255, 246.15108561515808, 250.37445497512817, 254.42206263542175, 258.44157886505127, 262.6808819770813, 266.85435247421265, 270.989218711853, 275.3127648830414, 279.5484480857849, 283.8824963569641, 288.18962836265564, 292.42556715011597, 296.6153964996338, 300.87314677238464, 305.11043667793274, 309.3780152797699, 313.7052094936371, 317.9964408874512, 322.16673827171326, 326.4369692802429, 330.63682866096497, 334.7860071659088, 338.94615840911865, 342.9601860046387, 346.8866238594055, 350.8752501010895, 354.8945486545563, 358.718554019928, 360.9035496711731]
[33.78, 41.59, 49.43, 54.71, 56.72, 59.23, 60.07, 61.79, 62.57, 62.98, 64.43, 64.9, 65.73, 66.65, 67.47, 67.32, 68.44, 68.73, 68.43, 69.13, 68.89, 68.81, 68.64, 68.76, 69.46, 70.52, 70.66, 70.59, 69.78, 70.01, 71.3, 71.19, 69.94, 70.51, 71.0, 71.02, 71.28, 72.11, 72.1, 72.7, 72.89, 73.3, 72.81, 72.6, 72.9, 73.38, 73.32, 73.9, 73.14, 73.66, 73.83, 73.83, 74.08, 74.37, 74.93, 74.86, 75.05, 74.63, 74.76, 75.13, 75.09, 75.2, 75.12, 74.65, 74.92, 74.99, 75.37, 75.31, 75.74, 75.54, 75.57, 75.47, 75.76, 75.03, 75.3, 75.41, 75.45, 75.89, 75.64, 76.39, 76.12, 76.24, 76.4, 75.84, 75.89, 75.9, 75.29, 76.05, 75.69, 75.85, 75.66, 75.58, 75.7, 75.51, 75.33, 75.49, 75.41, 75.11, 75.16, 74.91, 74.98]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.2 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 11, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 18, noise    level: 0.4000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.637, Test loss: 1.976, Test accuracy: 26.76
Round   0, Global train loss: 1.637, Global test loss: 2.213, Global test accuracy: 20.66
Round   1, Train loss: 1.426, Test loss: 1.858, Test accuracy: 30.44
Round   1, Global train loss: 1.426, Global test loss: 2.242, Global test accuracy: 20.62
Round   2, Train loss: 1.384, Test loss: 1.597, Test accuracy: 40.59
Round   2, Global train loss: 1.384, Global test loss: 2.050, Global test accuracy: 33.85
Round   3, Train loss: 1.205, Test loss: 1.433, Test accuracy: 43.97
Round   3, Global train loss: 1.205, Global test loss: 1.916, Global test accuracy: 29.82
Round   4, Train loss: 1.280, Test loss: 1.381, Test accuracy: 45.89
Round   4, Global train loss: 1.280, Global test loss: 1.984, Global test accuracy: 28.78
Round   5, Train loss: 1.191, Test loss: 1.332, Test accuracy: 46.87
Round   5, Global train loss: 1.191, Global test loss: 2.088, Global test accuracy: 25.13
Round   6, Train loss: 1.101, Test loss: 1.262, Test accuracy: 50.37
Round   6, Global train loss: 1.101, Global test loss: 1.956, Global test accuracy: 24.94
Round   7, Train loss: 1.285, Test loss: 1.204, Test accuracy: 51.64
Round   7, Global train loss: 1.285, Global test loss: 2.054, Global test accuracy: 26.88
Round   8, Train loss: 1.129, Test loss: 1.121, Test accuracy: 54.40
Round   8, Global train loss: 1.129, Global test loss: 1.915, Global test accuracy: 33.63
Round   9, Train loss: 0.983, Test loss: 1.121, Test accuracy: 54.90
Round   9, Global train loss: 0.983, Global test loss: 1.940, Global test accuracy: 31.98
Round  10, Train loss: 1.051, Test loss: 1.096, Test accuracy: 56.17
Round  10, Global train loss: 1.051, Global test loss: 1.941, Global test accuracy: 27.06
Round  11, Train loss: 1.063, Test loss: 1.100, Test accuracy: 56.54
Round  11, Global train loss: 1.063, Global test loss: 1.981, Global test accuracy: 30.48
Round  12, Train loss: 1.144, Test loss: 1.093, Test accuracy: 56.76
Round  12, Global train loss: 1.144, Global test loss: 2.146, Global test accuracy: 21.10
Round  13, Train loss: 0.906, Test loss: 1.072, Test accuracy: 57.68
Round  13, Global train loss: 0.906, Global test loss: 1.916, Global test accuracy: 28.55
Round  14, Train loss: 1.020, Test loss: 1.070, Test accuracy: 58.23
Round  14, Global train loss: 1.020, Global test loss: 1.993, Global test accuracy: 31.67
Round  15, Train loss: 0.881, Test loss: 1.076, Test accuracy: 58.52
Round  15, Global train loss: 0.881, Global test loss: 1.809, Global test accuracy: 33.80
Round  16, Train loss: 0.781, Test loss: 1.083, Test accuracy: 58.65
Round  16, Global train loss: 0.781, Global test loss: 1.908, Global test accuracy: 32.69
Round  17, Train loss: 0.920, Test loss: 1.079, Test accuracy: 59.07
Round  17, Global train loss: 0.920, Global test loss: 2.086, Global test accuracy: 23.52
Round  18, Train loss: 0.869, Test loss: 1.067, Test accuracy: 59.28
Round  18, Global train loss: 0.869, Global test loss: 1.897, Global test accuracy: 34.96
Round  19, Train loss: 0.855, Test loss: 1.067, Test accuracy: 59.71
Round  19, Global train loss: 0.855, Global test loss: 1.844, Global test accuracy: 35.61
Round  20, Train loss: 0.994, Test loss: 1.079, Test accuracy: 59.62
Round  20, Global train loss: 0.994, Global test loss: 2.076, Global test accuracy: 31.49
Round  21, Train loss: 0.885, Test loss: 1.061, Test accuracy: 60.55
Round  21, Global train loss: 0.885, Global test loss: 1.962, Global test accuracy: 24.55
Round  22, Train loss: 0.949, Test loss: 1.064, Test accuracy: 60.66
Round  22, Global train loss: 0.949, Global test loss: 1.991, Global test accuracy: 25.00
Round  23, Train loss: 0.815, Test loss: 1.080, Test accuracy: 60.74
Round  23, Global train loss: 0.815, Global test loss: 1.944, Global test accuracy: 32.62
Round  24, Train loss: 0.761, Test loss: 1.080, Test accuracy: 61.21
Round  24, Global train loss: 0.761, Global test loss: 1.964, Global test accuracy: 26.64
Round  25, Train loss: 0.744, Test loss: 1.088, Test accuracy: 61.16
Round  25, Global train loss: 0.744, Global test loss: 1.946, Global test accuracy: 36.37
Round  26, Train loss: 0.832, Test loss: 1.088, Test accuracy: 60.83
Round  26, Global train loss: 0.832, Global test loss: 1.933, Global test accuracy: 33.03
Round  27, Train loss: 0.848, Test loss: 1.094, Test accuracy: 60.85
Round  27, Global train loss: 0.848, Global test loss: 1.836, Global test accuracy: 33.43
Round  28, Train loss: 0.735, Test loss: 1.101, Test accuracy: 60.93
Round  28, Global train loss: 0.735, Global test loss: 1.988, Global test accuracy: 25.35
Round  29, Train loss: 0.822, Test loss: 1.094, Test accuracy: 61.40
Round  29, Global train loss: 0.822, Global test loss: 1.928, Global test accuracy: 32.52
Round  30, Train loss: 0.738, Test loss: 1.098, Test accuracy: 61.33
Round  30, Global train loss: 0.738, Global test loss: 2.098, Global test accuracy: 30.08
Round  31, Train loss: 0.826, Test loss: 1.127, Test accuracy: 60.99
Round  31, Global train loss: 0.826, Global test loss: 1.835, Global test accuracy: 34.27
Round  32, Train loss: 0.793, Test loss: 1.140, Test accuracy: 61.06
Round  32, Global train loss: 0.793, Global test loss: 1.940, Global test accuracy: 31.87
Round  33, Train loss: 0.655, Test loss: 1.147, Test accuracy: 61.11
Round  33, Global train loss: 0.655, Global test loss: 1.884, Global test accuracy: 27.02
Round  34, Train loss: 0.616, Test loss: 1.178, Test accuracy: 60.71
Round  34, Global train loss: 0.616, Global test loss: 1.882, Global test accuracy: 29.89
Round  35, Train loss: 0.525, Test loss: 1.184, Test accuracy: 61.15
Round  35, Global train loss: 0.525, Global test loss: 1.832, Global test accuracy: 38.26
Round  36, Train loss: 0.559, Test loss: 1.196, Test accuracy: 60.84
Round  36, Global train loss: 0.559, Global test loss: 1.913, Global test accuracy: 36.64
Round  37, Train loss: 0.497, Test loss: 1.197, Test accuracy: 60.52
Round  37, Global train loss: 0.497, Global test loss: 2.093, Global test accuracy: 25.81
Round  38, Train loss: 0.636, Test loss: 1.196, Test accuracy: 60.93
Round  38, Global train loss: 0.636, Global test loss: 2.007, Global test accuracy: 26.75
Round  39, Train loss: 0.577, Test loss: 1.226, Test accuracy: 60.95
Round  39, Global train loss: 0.577, Global test loss: 1.954, Global test accuracy: 33.39
Round  40, Train loss: 0.482, Test loss: 1.225, Test accuracy: 61.23
Round  40, Global train loss: 0.482, Global test loss: 2.001, Global test accuracy: 21.06
Round  41, Train loss: 0.461, Test loss: 1.253, Test accuracy: 60.73
Round  41, Global train loss: 0.461, Global test loss: 2.100, Global test accuracy: 26.79
Round  42, Train loss: 0.438, Test loss: 1.276, Test accuracy: 61.05
Round  42, Global train loss: 0.438, Global test loss: 2.021, Global test accuracy: 33.44
Round  43, Train loss: 0.423, Test loss: 1.306, Test accuracy: 60.68
Round  43, Global train loss: 0.423, Global test loss: 1.902, Global test accuracy: 34.03
Round  44, Train loss: 0.411, Test loss: 1.323, Test accuracy: 60.64
Round  44, Global train loss: 0.411, Global test loss: 1.782, Global test accuracy: 39.17
Round  45, Train loss: 0.350, Test loss: 1.334, Test accuracy: 61.23
Round  45, Global train loss: 0.350, Global test loss: 1.895, Global test accuracy: 36.84
Round  46, Train loss: 0.449, Test loss: 1.350, Test accuracy: 60.94
Round  46, Global train loss: 0.449, Global test loss: 1.967, Global test accuracy: 31.90
Round  47, Train loss: 0.344, Test loss: 1.384, Test accuracy: 60.94
Round  47, Global train loss: 0.344, Global test loss: 1.878, Global test accuracy: 31.14
Round  48, Train loss: 0.442, Test loss: 1.413, Test accuracy: 60.77
Round  48, Global train loss: 0.442, Global test loss: 2.036, Global test accuracy: 25.62
Round  49, Train loss: 0.326, Test loss: 1.443, Test accuracy: 60.77
Round  49, Global train loss: 0.326, Global test loss: 2.002, Global test accuracy: 34.74
Round  50, Train loss: 0.436, Test loss: 1.475, Test accuracy: 61.01
Round  50, Global train loss: 0.436, Global test loss: 1.911, Global test accuracy: 33.15
Round  51, Train loss: 0.370, Test loss: 1.490, Test accuracy: 60.53
Round  51, Global train loss: 0.370, Global test loss: 1.774, Global test accuracy: 37.02
Round  52, Train loss: 0.369, Test loss: 1.456, Test accuracy: 61.26
Round  52, Global train loss: 0.369, Global test loss: 2.020, Global test accuracy: 30.58
Round  53, Train loss: 0.294, Test loss: 1.466, Test accuracy: 61.24
Round  53, Global train loss: 0.294, Global test loss: 1.891, Global test accuracy: 33.60
Round  54, Train loss: 0.339, Test loss: 1.478, Test accuracy: 61.36
Round  54, Global train loss: 0.339, Global test loss: 2.034, Global test accuracy: 26.15
Round  55, Train loss: 0.215, Test loss: 1.486, Test accuracy: 60.94
Round  55, Global train loss: 0.215, Global test loss: 1.724, Global test accuracy: 38.29
Round  56, Train loss: 0.335, Test loss: 1.508, Test accuracy: 61.25
Round  56, Global train loss: 0.335, Global test loss: 1.841, Global test accuracy: 30.41
Round  57, Train loss: 0.340, Test loss: 1.540, Test accuracy: 61.34
Round  57, Global train loss: 0.340, Global test loss: 2.009, Global test accuracy: 24.67
Round  58, Train loss: 0.330, Test loss: 1.563, Test accuracy: 60.55
Round  58, Global train loss: 0.330, Global test loss: 2.088, Global test accuracy: 29.25
Round  59, Train loss: 0.236, Test loss: 1.587, Test accuracy: 60.70
Round  59, Global train loss: 0.236, Global test loss: 1.863, Global test accuracy: 36.58
Round  60, Train loss: 0.338, Test loss: 1.631, Test accuracy: 60.56
Round  60, Global train loss: 0.338, Global test loss: 1.869, Global test accuracy: 30.09
Round  61, Train loss: 0.306, Test loss: 1.615, Test accuracy: 60.97
Round  61, Global train loss: 0.306, Global test loss: 1.886, Global test accuracy: 33.36
Round  62, Train loss: 0.245, Test loss: 1.605, Test accuracy: 61.26
Round  62, Global train loss: 0.245, Global test loss: 2.023, Global test accuracy: 26.57
Round  63, Train loss: 0.246, Test loss: 1.656, Test accuracy: 61.15
Round  63, Global train loss: 0.246, Global test loss: 1.842, Global test accuracy: 34.59
Round  64, Train loss: 0.251, Test loss: 1.675, Test accuracy: 61.58
Round  64, Global train loss: 0.251, Global test loss: 1.938, Global test accuracy: 27.89
Round  65, Train loss: 0.268, Test loss: 1.688, Test accuracy: 61.17
Round  65, Global train loss: 0.268, Global test loss: 1.892, Global test accuracy: 37.32
Round  66, Train loss: 0.195, Test loss: 1.742, Test accuracy: 60.93
Round  66, Global train loss: 0.195, Global test loss: 1.859, Global test accuracy: 34.71
Round  67, Train loss: 0.237, Test loss: 1.758, Test accuracy: 60.56
Round  67, Global train loss: 0.237, Global test loss: 1.890, Global test accuracy: 32.68
Round  68, Train loss: 0.204, Test loss: 1.793, Test accuracy: 60.28
Round  68, Global train loss: 0.204, Global test loss: 1.771, Global test accuracy: 36.89
Round  69, Train loss: 0.329, Test loss: 1.850, Test accuracy: 60.07
Round  69, Global train loss: 0.329, Global test loss: 1.948, Global test accuracy: 32.01
Round  70, Train loss: 0.194, Test loss: 1.824, Test accuracy: 60.12
Round  70, Global train loss: 0.194, Global test loss: 2.006, Global test accuracy: 33.83
Round  71, Train loss: 0.251, Test loss: 1.868, Test accuracy: 60.36
Round  71, Global train loss: 0.251, Global test loss: 1.960, Global test accuracy: 33.09
Round  72, Train loss: 0.234, Test loss: 1.846, Test accuracy: 60.96
Round  72, Global train loss: 0.234, Global test loss: 1.886, Global test accuracy: 33.58
Round  73, Train loss: 0.168, Test loss: 1.876, Test accuracy: 60.58
Round  73, Global train loss: 0.168, Global test loss: 1.861, Global test accuracy: 33.17
Round  74, Train loss: 0.243, Test loss: 1.867, Test accuracy: 60.42
Round  74, Global train loss: 0.243, Global test loss: 2.078, Global test accuracy: 27.52
Round  75, Train loss: 0.233, Test loss: 1.931, Test accuracy: 60.23
Round  75, Global train loss: 0.233, Global test loss: 1.924, Global test accuracy: 35.76
Round  76, Train loss: 0.166, Test loss: 1.898, Test accuracy: 60.85
Round  76, Global train loss: 0.166, Global test loss: 1.948, Global test accuracy: 33.04
Round  77, Train loss: 0.158, Test loss: 1.900, Test accuracy: 60.87
Round  77, Global train loss: 0.158, Global test loss: 1.912, Global test accuracy: 35.79
Round  78, Train loss: 0.176, Test loss: 1.918, Test accuracy: 60.76
Round  78, Global train loss: 0.176, Global test loss: 1.966, Global test accuracy: 27.80
Round  79, Train loss: 0.159, Test loss: 1.948, Test accuracy: 60.47
Round  79, Global train loss: 0.159, Global test loss: 1.970, Global test accuracy: 29.44
Round  80, Train loss: 0.191, Test loss: 1.952, Test accuracy: 60.68
Round  80, Global train loss: 0.191, Global test loss: 1.944, Global test accuracy: 31.70
Round  81, Train loss: 0.152, Test loss: 1.972, Test accuracy: 60.54
Round  81, Global train loss: 0.152, Global test loss: 1.986, Global test accuracy: 36.76
Round  82, Train loss: 0.184, Test loss: 1.979, Test accuracy: 60.69
Round  82, Global train loss: 0.184, Global test loss: 1.934, Global test accuracy: 32.50
Round  83, Train loss: 0.146, Test loss: 1.974, Test accuracy: 60.77
Round  83, Global train loss: 0.146, Global test loss: 2.022, Global test accuracy: 27.13
Round  84, Train loss: 0.131, Test loss: 1.950, Test accuracy: 60.73
Round  84, Global train loss: 0.131, Global test loss: 2.053, Global test accuracy: 26.65
Round  85, Train loss: 0.176, Test loss: 1.962, Test accuracy: 60.73
Round  85, Global train loss: 0.176, Global test loss: 1.827, Global test accuracy: 34.27
Round  86, Train loss: 0.152, Test loss: 1.941, Test accuracy: 61.40
Round  86, Global train loss: 0.152, Global test loss: 1.937, Global test accuracy: 29.74
Round  87, Train loss: 0.134, Test loss: 1.993, Test accuracy: 61.22
Round  87, Global train loss: 0.134, Global test loss: 1.900, Global test accuracy: 31.76
Round  88, Train loss: 0.160, Test loss: 2.069, Test accuracy: 61.21
Round  88, Global train loss: 0.160, Global test loss: 2.124, Global test accuracy: 28.29
Round  89, Train loss: 0.131, Test loss: 2.087, Test accuracy: 61.09
Round  89, Global train loss: 0.131, Global test loss: 1.827, Global test accuracy: 36.76
Round  90, Train loss: 0.144, Test loss: 2.097, Test accuracy: 61.11
Round  90, Global train loss: 0.144, Global test loss: 2.006, Global test accuracy: 25.93
Round  91, Train loss: 0.132, Test loss: 2.105, Test accuracy: 61.12
Round  91, Global train loss: 0.132, Global test loss: 1.990, Global test accuracy: 35.64
Round  92, Train loss: 0.159, Test loss: 2.103, Test accuracy: 61.27
Round  92, Global train loss: 0.159, Global test loss: 1.950, Global test accuracy: 29.16
Round  93, Train loss: 0.109, Test loss: 2.118, Test accuracy: 61.31
Round  93, Global train loss: 0.109, Global test loss: 1.822, Global test accuracy: 37.38
Round  94, Train loss: 0.122, Test loss: 2.150, Test accuracy: 61.24
Round  94, Global train loss: 0.122, Global test loss: 1.922, Global test accuracy: 35.05
Round  95, Train loss: 0.121, Test loss: 2.171, Test accuracy: 61.03
Round  95, Global train loss: 0.121, Global test loss: 2.070, Global test accuracy: 27.15
Round  96, Train loss: 0.098, Test loss: 2.155, Test accuracy: 61.14
Round  96, Global train loss: 0.098, Global test loss: 1.890, Global test accuracy: 31.51
Round  97, Train loss: 0.143, Test loss: 2.177, Test accuracy: 61.04
Round  97, Global train loss: 0.143, Global test loss: 1.954, Global test accuracy: 30.49
Round  98, Train loss: 0.117, Test loss: 2.238, Test accuracy: 60.74
Round  98, Global train loss: 0.117, Global test loss: 1.880, Global test accuracy: 33.87
Round  99, Train loss: 0.122, Test loss: 2.262, Test accuracy: 60.57
Round  99, Global train loss: 0.122, Global test loss: 1.863, Global test accuracy: 38.03
Final Round, Train loss: 0.111, Test loss: 2.323, Test accuracy: 61.15
Final Round, Global train loss: 0.111, Global test loss: 1.863, Global test accuracy: 38.03
Average accuracy final 10 rounds: 61.057 

Average global accuracy final 10 rounds: 32.421 

1658.0432653427124
[1.5428729057312012, 3.0857458114624023, 4.35955023765564, 5.633354663848877, 6.902359247207642, 8.171363830566406, 9.414533615112305, 10.657703399658203, 11.973181247711182, 13.28865909576416, 14.569116830825806, 15.849574565887451, 17.14517831802368, 18.440782070159912, 19.715669870376587, 20.99055767059326, 22.24055051803589, 23.490543365478516, 24.59826397895813, 25.705984592437744, 26.84961771965027, 27.993250846862793, 29.1023371219635, 30.21142339706421, 31.47970461845398, 32.74798583984375, 33.993974447250366, 35.23996305465698, 36.50414752960205, 37.76833200454712, 39.1255829334259, 40.48283386230469, 41.73034048080444, 42.9778470993042, 44.31608986854553, 45.654332637786865, 46.77069902420044, 47.887065410614014, 49.046306848526, 50.20554828643799, 51.33513426780701, 52.464720249176025, 53.589890480041504, 54.71506071090698, 55.828641414642334, 56.942222118377686, 58.05662202835083, 59.171021938323975, 60.30472254753113, 61.43842315673828, 62.55636143684387, 63.67429971694946, 64.77220034599304, 65.87010097503662, 66.99240255355835, 68.11470413208008, 69.23639369010925, 70.35808324813843, 71.48619079589844, 72.61429834365845, 73.73719835281372, 74.860098361969, 75.97935080528259, 77.09860324859619, 78.20267248153687, 79.30674171447754, 80.41903948783875, 81.53133726119995, 82.65577030181885, 83.78020334243774, 84.89407777786255, 86.00795221328735, 87.11623859405518, 88.224524974823, 89.35068011283875, 90.47683525085449, 91.58025002479553, 92.68366479873657, 93.79839706420898, 94.9131293296814, 96.04732418060303, 97.18151903152466, 98.3039903640747, 99.42646169662476, 100.52845096588135, 101.63044023513794, 102.78819990158081, 103.94595956802368, 105.0725519657135, 106.19914436340332, 107.3229455947876, 108.44674682617188, 109.54595232009888, 110.64515781402588, 111.77119779586792, 112.89723777770996, 114.01760935783386, 115.13798093795776, 116.26160001754761, 117.38521909713745, 118.50233340263367, 119.61944770812988, 120.74957919120789, 121.87971067428589, 122.97595643997192, 124.07220220565796, 125.22418451309204, 126.37616682052612, 127.51169228553772, 128.64721775054932, 129.73198580741882, 130.81675386428833, 131.9256248474121, 133.0344958305359, 134.1501762866974, 135.2658567428589, 136.41165709495544, 137.557457447052, 138.71124601364136, 139.8650345802307, 140.99113297462463, 142.11723136901855, 143.23355650901794, 144.34988164901733, 145.44549369812012, 146.5411057472229, 147.67836260795593, 148.81561946868896, 149.93641781806946, 151.05721616744995, 152.27545976638794, 153.49370336532593, 154.7339005470276, 155.97409772872925, 157.22031021118164, 158.46652269363403, 159.72692847251892, 160.9873342514038, 162.21594882011414, 163.44456338882446, 164.69358921051025, 165.94261503219604, 167.19165420532227, 168.4406933784485, 169.70076441764832, 170.96083545684814, 172.20779585838318, 173.4547562599182, 174.72555708885193, 175.99635791778564, 177.20023846626282, 178.40411901474, 179.53965950012207, 180.67519998550415, 181.85595393180847, 183.0367078781128, 184.19170308113098, 185.34669828414917, 186.51175928115845, 187.67682027816772, 188.7996096611023, 189.92239904403687, 191.04434752464294, 192.16629600524902, 193.31063723564148, 194.45497846603394, 195.61179280281067, 196.7686071395874, 197.89792609214783, 199.02724504470825, 200.19275760650635, 201.35827016830444, 202.48982954025269, 203.62138891220093, 204.79349970817566, 205.9656105041504, 207.11278367042542, 208.25995683670044, 209.47035264968872, 210.680748462677, 211.9754889011383, 213.2702293395996, 214.47594451904297, 215.68165969848633, 216.83110880851746, 217.98055791854858, 219.16059589385986, 220.34063386917114, 221.4723026752472, 222.60397148132324, 223.7586212158203, 224.91327095031738, 226.0766019821167, 227.23993301391602, 228.40410327911377, 229.56827354431152, 230.71897959709167, 231.86968564987183, 233.0210883617401, 234.1724910736084, 236.48156762123108, 238.79064416885376]
[26.76, 26.76, 30.44, 30.44, 40.59, 40.59, 43.97, 43.97, 45.89, 45.89, 46.87, 46.87, 50.37, 50.37, 51.64, 51.64, 54.4, 54.4, 54.9, 54.9, 56.17, 56.17, 56.54, 56.54, 56.76, 56.76, 57.68, 57.68, 58.23, 58.23, 58.52, 58.52, 58.65, 58.65, 59.07, 59.07, 59.28, 59.28, 59.71, 59.71, 59.62, 59.62, 60.55, 60.55, 60.66, 60.66, 60.74, 60.74, 61.21, 61.21, 61.16, 61.16, 60.83, 60.83, 60.85, 60.85, 60.93, 60.93, 61.4, 61.4, 61.33, 61.33, 60.99, 60.99, 61.06, 61.06, 61.11, 61.11, 60.71, 60.71, 61.15, 61.15, 60.84, 60.84, 60.52, 60.52, 60.93, 60.93, 60.95, 60.95, 61.23, 61.23, 60.73, 60.73, 61.05, 61.05, 60.68, 60.68, 60.64, 60.64, 61.23, 61.23, 60.94, 60.94, 60.94, 60.94, 60.77, 60.77, 60.77, 60.77, 61.01, 61.01, 60.53, 60.53, 61.26, 61.26, 61.24, 61.24, 61.36, 61.36, 60.94, 60.94, 61.25, 61.25, 61.34, 61.34, 60.55, 60.55, 60.7, 60.7, 60.56, 60.56, 60.97, 60.97, 61.26, 61.26, 61.15, 61.15, 61.58, 61.58, 61.17, 61.17, 60.93, 60.93, 60.56, 60.56, 60.28, 60.28, 60.07, 60.07, 60.12, 60.12, 60.36, 60.36, 60.96, 60.96, 60.58, 60.58, 60.42, 60.42, 60.23, 60.23, 60.85, 60.85, 60.87, 60.87, 60.76, 60.76, 60.47, 60.47, 60.68, 60.68, 60.54, 60.54, 60.69, 60.69, 60.77, 60.77, 60.73, 60.73, 60.73, 60.73, 61.4, 61.4, 61.22, 61.22, 61.21, 61.21, 61.09, 61.09, 61.11, 61.11, 61.12, 61.12, 61.27, 61.27, 61.31, 61.31, 61.24, 61.24, 61.03, 61.03, 61.14, 61.14, 61.04, 61.04, 60.74, 60.74, 60.57, 60.57, 61.15, 61.15]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.2 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 2, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 15, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.626, Test loss: 1.958, Test accuracy: 23.66
Round   0, Global train loss: 1.626, Global test loss: 2.196, Global test accuracy: 16.39
Round   1, Train loss: 1.407, Test loss: 1.805, Test accuracy: 33.55
Round   1, Global train loss: 1.407, Global test loss: 2.180, Global test accuracy: 23.66
Round   2, Train loss: 1.325, Test loss: 1.549, Test accuracy: 42.53
Round   2, Global train loss: 1.325, Global test loss: 2.009, Global test accuracy: 34.16
Round   3, Train loss: 1.203, Test loss: 1.350, Test accuracy: 46.94
Round   3, Global train loss: 1.203, Global test loss: 1.820, Global test accuracy: 32.15
Round   4, Train loss: 1.151, Test loss: 1.241, Test accuracy: 51.07
Round   4, Global train loss: 1.151, Global test loss: 1.674, Global test accuracy: 37.80
Round   5, Train loss: 1.077, Test loss: 1.210, Test accuracy: 52.53
Round   5, Global train loss: 1.077, Global test loss: 1.991, Global test accuracy: 32.46
Round   6, Train loss: 1.088, Test loss: 1.111, Test accuracy: 56.24
Round   6, Global train loss: 1.088, Global test loss: 1.620, Global test accuracy: 40.05
Round   7, Train loss: 1.126, Test loss: 1.050, Test accuracy: 58.47
Round   7, Global train loss: 1.126, Global test loss: 1.888, Global test accuracy: 32.73
Round   8, Train loss: 1.004, Test loss: 0.985, Test accuracy: 60.86
Round   8, Global train loss: 1.004, Global test loss: 1.620, Global test accuracy: 43.31
Round   9, Train loss: 0.984, Test loss: 0.976, Test accuracy: 61.36
Round   9, Global train loss: 0.984, Global test loss: 1.554, Global test accuracy: 45.04
Round  10, Train loss: 0.966, Test loss: 0.972, Test accuracy: 61.44
Round  10, Global train loss: 0.966, Global test loss: 1.578, Global test accuracy: 43.86
Round  11, Train loss: 0.925, Test loss: 0.961, Test accuracy: 61.90
Round  11, Global train loss: 0.925, Global test loss: 1.585, Global test accuracy: 45.53
Round  12, Train loss: 0.982, Test loss: 0.953, Test accuracy: 62.67
Round  12, Global train loss: 0.982, Global test loss: 1.586, Global test accuracy: 39.50
Round  13, Train loss: 0.906, Test loss: 0.925, Test accuracy: 63.56
Round  13, Global train loss: 0.906, Global test loss: 1.571, Global test accuracy: 42.80
Round  14, Train loss: 0.874, Test loss: 0.928, Test accuracy: 63.93
Round  14, Global train loss: 0.874, Global test loss: 1.633, Global test accuracy: 43.90
Round  15, Train loss: 0.881, Test loss: 0.919, Test accuracy: 64.45
Round  15, Global train loss: 0.881, Global test loss: 1.308, Global test accuracy: 52.33
Round  16, Train loss: 0.784, Test loss: 0.923, Test accuracy: 64.24
Round  16, Global train loss: 0.784, Global test loss: 1.463, Global test accuracy: 46.42
Round  17, Train loss: 0.869, Test loss: 0.924, Test accuracy: 64.30
Round  17, Global train loss: 0.869, Global test loss: 1.427, Global test accuracy: 45.99
Round  18, Train loss: 0.805, Test loss: 0.893, Test accuracy: 66.01
Round  18, Global train loss: 0.805, Global test loss: 1.380, Global test accuracy: 50.86
Round  19, Train loss: 0.729, Test loss: 0.883, Test accuracy: 66.56
Round  19, Global train loss: 0.729, Global test loss: 1.318, Global test accuracy: 52.99
Round  20, Train loss: 0.749, Test loss: 0.862, Test accuracy: 67.31
Round  20, Global train loss: 0.749, Global test loss: 1.387, Global test accuracy: 51.22
Round  21, Train loss: 0.767, Test loss: 0.850, Test accuracy: 68.16
Round  21, Global train loss: 0.767, Global test loss: 1.365, Global test accuracy: 50.71
Round  22, Train loss: 0.795, Test loss: 0.845, Test accuracy: 68.33
Round  22, Global train loss: 0.795, Global test loss: 1.316, Global test accuracy: 52.70
Round  23, Train loss: 0.740, Test loss: 0.830, Test accuracy: 68.96
Round  23, Global train loss: 0.740, Global test loss: 1.284, Global test accuracy: 55.44
Round  24, Train loss: 0.792, Test loss: 0.830, Test accuracy: 69.74
Round  24, Global train loss: 0.792, Global test loss: 1.300, Global test accuracy: 53.27
Round  25, Train loss: 0.701, Test loss: 0.834, Test accuracy: 69.42
Round  25, Global train loss: 0.701, Global test loss: 1.246, Global test accuracy: 54.74
Round  26, Train loss: 0.723, Test loss: 0.837, Test accuracy: 69.27
Round  26, Global train loss: 0.723, Global test loss: 1.258, Global test accuracy: 54.05
Round  27, Train loss: 0.689, Test loss: 0.835, Test accuracy: 69.33
Round  27, Global train loss: 0.689, Global test loss: 1.289, Global test accuracy: 54.69
Round  28, Train loss: 0.718, Test loss: 0.843, Test accuracy: 68.94
Round  28, Global train loss: 0.718, Global test loss: 1.280, Global test accuracy: 54.73
Round  29, Train loss: 0.690, Test loss: 0.831, Test accuracy: 69.70
Round  29, Global train loss: 0.690, Global test loss: 1.269, Global test accuracy: 54.79
Round  30, Train loss: 0.701, Test loss: 0.832, Test accuracy: 69.77
Round  30, Global train loss: 0.701, Global test loss: 1.465, Global test accuracy: 48.52
Round  31, Train loss: 0.658, Test loss: 0.833, Test accuracy: 69.87
Round  31, Global train loss: 0.658, Global test loss: 1.150, Global test accuracy: 60.37
Round  32, Train loss: 0.607, Test loss: 0.832, Test accuracy: 70.30
Round  32, Global train loss: 0.607, Global test loss: 1.206, Global test accuracy: 57.70
Round  33, Train loss: 0.599, Test loss: 0.826, Test accuracy: 70.55
Round  33, Global train loss: 0.599, Global test loss: 1.193, Global test accuracy: 59.48
Round  34, Train loss: 0.602, Test loss: 0.828, Test accuracy: 70.80
Round  34, Global train loss: 0.602, Global test loss: 1.245, Global test accuracy: 56.63
Round  35, Train loss: 0.591, Test loss: 0.810, Test accuracy: 71.52
Round  35, Global train loss: 0.591, Global test loss: 1.296, Global test accuracy: 56.46
Round  36, Train loss: 0.595, Test loss: 0.810, Test accuracy: 71.53
Round  36, Global train loss: 0.595, Global test loss: 1.319, Global test accuracy: 54.84
Round  37, Train loss: 0.566, Test loss: 0.806, Test accuracy: 71.87
Round  37, Global train loss: 0.566, Global test loss: 1.296, Global test accuracy: 55.06
Round  38, Train loss: 0.596, Test loss: 0.794, Test accuracy: 72.26
Round  38, Global train loss: 0.596, Global test loss: 1.352, Global test accuracy: 54.28
Round  39, Train loss: 0.614, Test loss: 0.802, Test accuracy: 71.89
Round  39, Global train loss: 0.614, Global test loss: 1.191, Global test accuracy: 57.54
Round  40, Train loss: 0.542, Test loss: 0.785, Test accuracy: 72.41
Round  40, Global train loss: 0.542, Global test loss: 1.122, Global test accuracy: 60.26
Round  41, Train loss: 0.563, Test loss: 0.784, Test accuracy: 72.50
Round  41, Global train loss: 0.563, Global test loss: 1.469, Global test accuracy: 53.18
Round  42, Train loss: 0.520, Test loss: 0.803, Test accuracy: 72.16
Round  42, Global train loss: 0.520, Global test loss: 1.484, Global test accuracy: 53.01
Round  43, Train loss: 0.503, Test loss: 0.802, Test accuracy: 72.34
Round  43, Global train loss: 0.503, Global test loss: 1.308, Global test accuracy: 58.51
Round  44, Train loss: 0.464, Test loss: 0.807, Test accuracy: 72.30
Round  44, Global train loss: 0.464, Global test loss: 1.332, Global test accuracy: 57.87
Round  45, Train loss: 0.449, Test loss: 0.801, Test accuracy: 72.39
Round  45, Global train loss: 0.449, Global test loss: 1.406, Global test accuracy: 56.31
Round  46, Train loss: 0.520, Test loss: 0.794, Test accuracy: 72.50
Round  46, Global train loss: 0.520, Global test loss: 1.411, Global test accuracy: 55.13
Round  47, Train loss: 0.483, Test loss: 0.821, Test accuracy: 72.04
Round  47, Global train loss: 0.483, Global test loss: 1.191, Global test accuracy: 59.92
Round  48, Train loss: 0.547, Test loss: 0.821, Test accuracy: 72.77
Round  48, Global train loss: 0.547, Global test loss: 1.260, Global test accuracy: 58.27
Round  49, Train loss: 0.447, Test loss: 0.796, Test accuracy: 73.56
Round  49, Global train loss: 0.447, Global test loss: 1.449, Global test accuracy: 54.56
Round  50, Train loss: 0.512, Test loss: 0.809, Test accuracy: 73.37
Round  50, Global train loss: 0.512, Global test loss: 1.187, Global test accuracy: 60.06
Round  51, Train loss: 0.482, Test loss: 0.809, Test accuracy: 73.24
Round  51, Global train loss: 0.482, Global test loss: 1.104, Global test accuracy: 62.81
Round  52, Train loss: 0.480, Test loss: 0.804, Test accuracy: 73.11
Round  52, Global train loss: 0.480, Global test loss: 1.273, Global test accuracy: 57.39
Round  53, Train loss: 0.458, Test loss: 0.807, Test accuracy: 73.03
Round  53, Global train loss: 0.458, Global test loss: 1.197, Global test accuracy: 59.23
Round  54, Train loss: 0.464, Test loss: 0.822, Test accuracy: 73.02
Round  54, Global train loss: 0.464, Global test loss: 1.263, Global test accuracy: 58.40
Round  55, Train loss: 0.417, Test loss: 0.834, Test accuracy: 72.84
Round  55, Global train loss: 0.417, Global test loss: 1.126, Global test accuracy: 62.76
Round  56, Train loss: 0.431, Test loss: 0.823, Test accuracy: 72.87
Round  56, Global train loss: 0.431, Global test loss: 1.127, Global test accuracy: 62.41
Round  57, Train loss: 0.481, Test loss: 0.847, Test accuracy: 72.46
Round  57, Global train loss: 0.481, Global test loss: 1.157, Global test accuracy: 61.38
Round  58, Train loss: 0.451, Test loss: 0.831, Test accuracy: 73.26
Round  58, Global train loss: 0.451, Global test loss: 1.388, Global test accuracy: 54.68
Round  59, Train loss: 0.458, Test loss: 0.837, Test accuracy: 73.23
Round  59, Global train loss: 0.458, Global test loss: 1.182, Global test accuracy: 61.70
Round  60, Train loss: 0.452, Test loss: 0.830, Test accuracy: 73.61
Round  60, Global train loss: 0.452, Global test loss: 1.176, Global test accuracy: 60.33
Round  61, Train loss: 0.455, Test loss: 0.826, Test accuracy: 73.59
Round  61, Global train loss: 0.455, Global test loss: 1.147, Global test accuracy: 61.30
Round  62, Train loss: 0.433, Test loss: 0.815, Test accuracy: 74.00
Round  62, Global train loss: 0.433, Global test loss: 1.210, Global test accuracy: 60.01
Round  63, Train loss: 0.428, Test loss: 0.826, Test accuracy: 73.94
Round  63, Global train loss: 0.428, Global test loss: 1.236, Global test accuracy: 61.02
Round  64, Train loss: 0.405, Test loss: 0.832, Test accuracy: 74.00
Round  64, Global train loss: 0.405, Global test loss: 1.206, Global test accuracy: 61.26
Round  65, Train loss: 0.422, Test loss: 0.831, Test accuracy: 73.76
Round  65, Global train loss: 0.422, Global test loss: 1.263, Global test accuracy: 59.60
Round  66, Train loss: 0.366, Test loss: 0.825, Test accuracy: 74.12
Round  66, Global train loss: 0.366, Global test loss: 1.285, Global test accuracy: 60.06
Round  67, Train loss: 0.342, Test loss: 0.821, Test accuracy: 73.97
Round  67, Global train loss: 0.342, Global test loss: 1.262, Global test accuracy: 60.49
Round  68, Train loss: 0.415, Test loss: 0.833, Test accuracy: 73.79
Round  68, Global train loss: 0.415, Global test loss: 1.189, Global test accuracy: 60.85
Round  69, Train loss: 0.433, Test loss: 0.844, Test accuracy: 73.44
Round  69, Global train loss: 0.433, Global test loss: 1.155, Global test accuracy: 61.10
Round  70, Train loss: 0.359, Test loss: 0.861, Test accuracy: 73.51
Round  70, Global train loss: 0.359, Global test loss: 1.479, Global test accuracy: 56.82
Round  71, Train loss: 0.424, Test loss: 0.859, Test accuracy: 73.54
Round  71, Global train loss: 0.424, Global test loss: 1.313, Global test accuracy: 58.64
Round  72, Train loss: 0.391, Test loss: 0.869, Test accuracy: 73.35
Round  72, Global train loss: 0.391, Global test loss: 1.220, Global test accuracy: 60.81
Round  73, Train loss: 0.382, Test loss: 0.871, Test accuracy: 73.50
Round  73, Global train loss: 0.382, Global test loss: 1.167, Global test accuracy: 62.74
Round  74, Train loss: 0.390, Test loss: 0.866, Test accuracy: 74.20
Round  74, Global train loss: 0.390, Global test loss: 1.352, Global test accuracy: 59.56
Round  75, Train loss: 0.361, Test loss: 0.887, Test accuracy: 73.76
Round  75, Global train loss: 0.361, Global test loss: 1.190, Global test accuracy: 61.98
Round  76, Train loss: 0.294, Test loss: 0.884, Test accuracy: 73.81
Round  76, Global train loss: 0.294, Global test loss: 1.342, Global test accuracy: 60.20
Round  77, Train loss: 0.380, Test loss: 0.866, Test accuracy: 74.02
Round  77, Global train loss: 0.380, Global test loss: 1.259, Global test accuracy: 60.45
Round  78, Train loss: 0.386, Test loss: 0.874, Test accuracy: 73.81
Round  78, Global train loss: 0.386, Global test loss: 1.307, Global test accuracy: 59.55
Round  79, Train loss: 0.313, Test loss: 0.883, Test accuracy: 73.83
Round  79, Global train loss: 0.313, Global test loss: 1.324, Global test accuracy: 60.36
Round  80, Train loss: 0.407, Test loss: 0.893, Test accuracy: 74.22
Round  80, Global train loss: 0.407, Global test loss: 1.208, Global test accuracy: 61.85
Round  81, Train loss: 0.384, Test loss: 0.881, Test accuracy: 74.68
Round  81, Global train loss: 0.384, Global test loss: 1.433, Global test accuracy: 58.58
Round  82, Train loss: 0.352, Test loss: 0.876, Test accuracy: 74.31
Round  82, Global train loss: 0.352, Global test loss: 1.151, Global test accuracy: 62.57
Round  83, Train loss: 0.349, Test loss: 0.872, Test accuracy: 74.32
Round  83, Global train loss: 0.349, Global test loss: 1.248, Global test accuracy: 60.84
Round  84, Train loss: 0.313, Test loss: 0.886, Test accuracy: 74.26
Round  84, Global train loss: 0.313, Global test loss: 1.407, Global test accuracy: 60.11
Round  85, Train loss: 0.342, Test loss: 0.878, Test accuracy: 74.48
Round  85, Global train loss: 0.342, Global test loss: 1.199, Global test accuracy: 63.08
Round  86, Train loss: 0.344, Test loss: 0.914, Test accuracy: 74.40
Round  86, Global train loss: 0.344, Global test loss: 1.226, Global test accuracy: 61.64
Round  87, Train loss: 0.322, Test loss: 0.910, Test accuracy: 74.14
Round  87, Global train loss: 0.322, Global test loss: 1.229, Global test accuracy: 62.37
Round  88, Train loss: 0.346, Test loss: 0.916, Test accuracy: 73.78
Round  88, Global train loss: 0.346, Global test loss: 1.537, Global test accuracy: 56.70
Round  89, Train loss: 0.335, Test loss: 0.941, Test accuracy: 73.20
Round  89, Global train loss: 0.335, Global test loss: 1.276, Global test accuracy: 60.86
Round  90, Train loss: 0.350, Test loss: 0.904, Test accuracy: 74.25
Round  90, Global train loss: 0.350, Global test loss: 1.245, Global test accuracy: 63.27
Round  91, Train loss: 0.296, Test loss: 0.917, Test accuracy: 74.14
Round  91, Global train loss: 0.296, Global test loss: 1.513, Global test accuracy: 60.13
Round  92, Train loss: 0.367, Test loss: 0.892, Test accuracy: 74.36
Round  92, Global train loss: 0.367, Global test loss: 1.212, Global test accuracy: 62.87
Round  93, Train loss: 0.285, Test loss: 0.891, Test accuracy: 74.34
Round  93, Global train loss: 0.285, Global test loss: 1.334, Global test accuracy: 61.25
Round  94, Train loss: 0.307, Test loss: 0.886, Test accuracy: 74.25
Round  94, Global train loss: 0.307, Global test loss: 1.258, Global test accuracy: 61.59
Round  95, Train loss: 0.293, Test loss: 0.906, Test accuracy: 74.18
Round  95, Global train loss: 0.293, Global test loss: 1.408, Global test accuracy: 61.83
Round  96, Train loss: 0.343, Test loss: 0.912, Test accuracy: 74.13
Round  96, Global train loss: 0.343, Global test loss: 1.263, Global test accuracy: 61.87
Round  97, Train loss: 0.325, Test loss: 0.958, Test accuracy: 73.64
Round  97, Global train loss: 0.325, Global test loss: 1.193, Global test accuracy: 63.17
Round  98, Train loss: 0.315, Test loss: 0.933, Test accuracy: 74.23
Round  98, Global train loss: 0.315, Global test loss: 1.228, Global test accuracy: 62.90
Round  99, Train loss: 0.273, Test loss: 0.906, Test accuracy: 74.78
Round  99, Global train loss: 0.273, Global test loss: 1.385, Global test accuracy: 61.06
Final Round, Train loss: 0.245, Test loss: 1.020, Test accuracy: 74.32
Final Round, Global train loss: 0.245, Global test loss: 1.385, Global test accuracy: 61.06
Average accuracy final 10 rounds: 74.22999999999999 

Average global accuracy final 10 rounds: 61.994 

1693.5035619735718
[1.4731144905090332, 2.9462289810180664, 4.268880605697632, 5.591532230377197, 6.915116310119629, 8.23870038986206, 9.556803703308105, 10.87490701675415, 12.191805839538574, 13.508704662322998, 14.821858882904053, 16.135013103485107, 17.454357385635376, 18.773701667785645, 20.104171991348267, 21.43464231491089, 22.753397703170776, 24.072153091430664, 25.42949366569519, 26.786834239959717, 28.083096027374268, 29.37935781478882, 30.694333791732788, 32.00930976867676, 33.336355447769165, 34.66340112686157, 35.98526883125305, 37.30713653564453, 38.617767095565796, 39.92839765548706, 41.17430877685547, 42.42021989822388, 43.75302004814148, 45.08582019805908, 46.40369510650635, 47.72157001495361, 49.04487419128418, 50.368178367614746, 51.69063973426819, 53.01310110092163, 54.322787046432495, 55.63247299194336, 56.9290885925293, 58.225704193115234, 59.5378999710083, 60.85009574890137, 62.17581582069397, 63.50153589248657, 64.80666780471802, 66.11179971694946, 67.40808987617493, 68.70438003540039, 70.00451874732971, 71.30465745925903, 72.62520432472229, 73.94575119018555, 75.27329325675964, 76.60083532333374, 77.8882110118866, 79.17558670043945, 80.51324963569641, 81.85091257095337, 83.1533875465393, 84.45586252212524, 85.76611280441284, 87.07636308670044, 88.37898182868958, 89.68160057067871, 91.01299405097961, 92.34438753128052, 93.66956114768982, 94.99473476409912, 96.29378628730774, 97.59283781051636, 98.90093398094177, 100.20903015136719, 101.51372742652893, 102.81842470169067, 104.11292362213135, 105.40742254257202, 106.6821563243866, 107.95689010620117, 109.0997326374054, 110.24257516860962, 111.37474703788757, 112.50691890716553, 113.59922194480896, 114.69152498245239, 115.8012330532074, 116.9109411239624, 118.0086121559143, 119.10628318786621, 120.21995162963867, 121.33362007141113, 122.45819473266602, 123.5827693939209, 124.71834588050842, 125.85392236709595, 126.96413660049438, 128.07435083389282, 129.18017411231995, 130.28599739074707, 131.42015981674194, 132.55432224273682, 133.68285989761353, 134.81139755249023, 135.93133068084717, 137.0512638092041, 138.17923307418823, 139.30720233917236, 140.43612360954285, 141.56504487991333, 142.71208333969116, 143.859121799469, 144.9779405593872, 146.09675931930542, 147.22607803344727, 148.3553967475891, 149.47377800941467, 150.59215927124023, 151.71520519256592, 152.8382511138916, 153.9532539844513, 155.068256855011, 156.1921262741089, 157.3159956932068, 158.46011781692505, 159.6042399406433, 160.7048864364624, 161.8055329322815, 162.94642210006714, 164.08731126785278, 165.21912002563477, 166.35092878341675, 167.49073314666748, 168.6305375099182, 169.7466585636139, 170.86277961730957, 171.9860656261444, 173.10935163497925, 174.23340034484863, 175.35744905471802, 176.49165844917297, 177.62586784362793, 178.74205207824707, 179.8582363128662, 180.9715006351471, 182.08476495742798, 183.2091407775879, 184.3335165977478, 185.47163558006287, 186.60975456237793, 187.7500228881836, 188.89029121398926, 190.03092217445374, 191.1715531349182, 192.2927210330963, 193.4138889312744, 194.5736665725708, 195.7334442138672, 196.87512111663818, 198.01679801940918, 199.1648552417755, 200.31291246414185, 201.43068170547485, 202.54845094680786, 203.67261385917664, 204.7967767715454, 205.9420120716095, 207.08724737167358, 208.20037484169006, 209.31350231170654, 210.44764161109924, 211.58178091049194, 212.7224051952362, 213.86302947998047, 215.01446843147278, 216.1659073829651, 217.30007553100586, 218.43424367904663, 219.56246876716614, 220.69069385528564, 221.8218457698822, 222.95299768447876, 224.09780502319336, 225.24261236190796, 226.36533737182617, 227.48806238174438, 228.6520550251007, 229.81604766845703, 230.9417221546173, 232.0673966407776, 233.1885895729065, 234.3097825050354, 235.4490373134613, 236.5882921218872, 237.71320509910583, 238.83811807632446, 239.95776271820068, 241.0774073600769, 243.38657927513123, 245.69575119018555]
[23.66, 23.66, 33.55, 33.55, 42.53, 42.53, 46.94, 46.94, 51.07, 51.07, 52.53, 52.53, 56.24, 56.24, 58.47, 58.47, 60.86, 60.86, 61.36, 61.36, 61.44, 61.44, 61.9, 61.9, 62.67, 62.67, 63.56, 63.56, 63.93, 63.93, 64.45, 64.45, 64.24, 64.24, 64.3, 64.3, 66.01, 66.01, 66.56, 66.56, 67.31, 67.31, 68.16, 68.16, 68.33, 68.33, 68.96, 68.96, 69.74, 69.74, 69.42, 69.42, 69.27, 69.27, 69.33, 69.33, 68.94, 68.94, 69.7, 69.7, 69.77, 69.77, 69.87, 69.87, 70.3, 70.3, 70.55, 70.55, 70.8, 70.8, 71.52, 71.52, 71.53, 71.53, 71.87, 71.87, 72.26, 72.26, 71.89, 71.89, 72.41, 72.41, 72.5, 72.5, 72.16, 72.16, 72.34, 72.34, 72.3, 72.3, 72.39, 72.39, 72.5, 72.5, 72.04, 72.04, 72.77, 72.77, 73.56, 73.56, 73.37, 73.37, 73.24, 73.24, 73.11, 73.11, 73.03, 73.03, 73.02, 73.02, 72.84, 72.84, 72.87, 72.87, 72.46, 72.46, 73.26, 73.26, 73.23, 73.23, 73.61, 73.61, 73.59, 73.59, 74.0, 74.0, 73.94, 73.94, 74.0, 74.0, 73.76, 73.76, 74.12, 74.12, 73.97, 73.97, 73.79, 73.79, 73.44, 73.44, 73.51, 73.51, 73.54, 73.54, 73.35, 73.35, 73.5, 73.5, 74.2, 74.2, 73.76, 73.76, 73.81, 73.81, 74.02, 74.02, 73.81, 73.81, 73.83, 73.83, 74.22, 74.22, 74.68, 74.68, 74.31, 74.31, 74.32, 74.32, 74.26, 74.26, 74.48, 74.48, 74.4, 74.4, 74.14, 74.14, 73.78, 73.78, 73.2, 73.2, 74.25, 74.25, 74.14, 74.14, 74.36, 74.36, 74.34, 74.34, 74.25, 74.25, 74.18, 74.18, 74.13, 74.13, 73.64, 73.64, 74.23, 74.23, 74.78, 74.78, 74.32, 74.32]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.2 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 16, noise    level: 0.4000 
   Client 15, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.652, Test loss: 1.993, Test accuracy: 22.62
Round   0, Global train loss: 1.652, Global test loss: 2.216, Global test accuracy: 16.51
Round   1, Train loss: 1.479, Test loss: 1.881, Test accuracy: 29.99
Round   1, Global train loss: 1.479, Global test loss: 2.231, Global test accuracy: 21.18
Round   2, Train loss: 1.392, Test loss: 1.649, Test accuracy: 40.30
Round   2, Global train loss: 1.392, Global test loss: 2.134, Global test accuracy: 32.17
Round   3, Train loss: 1.298, Test loss: 1.411, Test accuracy: 44.76
Round   3, Global train loss: 1.298, Global test loss: 1.877, Global test accuracy: 30.45
Round   4, Train loss: 1.221, Test loss: 1.331, Test accuracy: 47.00
Round   4, Global train loss: 1.221, Global test loss: 1.775, Global test accuracy: 35.84
Round   5, Train loss: 1.158, Test loss: 1.267, Test accuracy: 49.53
Round   5, Global train loss: 1.158, Global test loss: 1.864, Global test accuracy: 33.18
Round   6, Train loss: 1.154, Test loss: 1.196, Test accuracy: 53.14
Round   6, Global train loss: 1.154, Global test loss: 1.694, Global test accuracy: 38.64
Round   7, Train loss: 1.216, Test loss: 1.139, Test accuracy: 55.05
Round   7, Global train loss: 1.216, Global test loss: 1.923, Global test accuracy: 31.36
Round   8, Train loss: 1.037, Test loss: 1.071, Test accuracy: 57.47
Round   8, Global train loss: 1.037, Global test loss: 1.659, Global test accuracy: 42.49
Round   9, Train loss: 1.049, Test loss: 1.058, Test accuracy: 58.49
Round   9, Global train loss: 1.049, Global test loss: 1.613, Global test accuracy: 43.67
Round  10, Train loss: 1.020, Test loss: 1.043, Test accuracy: 59.55
Round  10, Global train loss: 1.020, Global test loss: 1.580, Global test accuracy: 42.52
Round  11, Train loss: 0.994, Test loss: 1.016, Test accuracy: 60.59
Round  11, Global train loss: 0.994, Global test loss: 1.674, Global test accuracy: 42.79
Round  12, Train loss: 1.081, Test loss: 1.001, Test accuracy: 61.04
Round  12, Global train loss: 1.081, Global test loss: 1.595, Global test accuracy: 39.17
Round  13, Train loss: 0.956, Test loss: 0.983, Test accuracy: 61.76
Round  13, Global train loss: 0.956, Global test loss: 1.545, Global test accuracy: 42.42
Round  14, Train loss: 0.957, Test loss: 0.984, Test accuracy: 61.70
Round  14, Global train loss: 0.957, Global test loss: 1.597, Global test accuracy: 44.17
Round  15, Train loss: 0.952, Test loss: 0.971, Test accuracy: 62.60
Round  15, Global train loss: 0.952, Global test loss: 1.395, Global test accuracy: 49.10
Round  16, Train loss: 0.859, Test loss: 0.970, Test accuracy: 62.62
Round  16, Global train loss: 0.859, Global test loss: 1.573, Global test accuracy: 42.72
Round  17, Train loss: 0.931, Test loss: 0.965, Test accuracy: 62.69
Round  17, Global train loss: 0.931, Global test loss: 1.488, Global test accuracy: 45.47
Round  18, Train loss: 0.892, Test loss: 0.965, Test accuracy: 62.82
Round  18, Global train loss: 0.892, Global test loss: 1.411, Global test accuracy: 48.87
Round  19, Train loss: 0.813, Test loss: 0.961, Test accuracy: 63.22
Round  19, Global train loss: 0.813, Global test loss: 1.395, Global test accuracy: 49.86
Round  20, Train loss: 0.826, Test loss: 0.913, Test accuracy: 64.53
Round  20, Global train loss: 0.826, Global test loss: 1.441, Global test accuracy: 49.03
Round  21, Train loss: 0.890, Test loss: 0.908, Test accuracy: 64.97
Round  21, Global train loss: 0.890, Global test loss: 1.407, Global test accuracy: 49.61
Round  22, Train loss: 0.912, Test loss: 0.910, Test accuracy: 65.08
Round  22, Global train loss: 0.912, Global test loss: 1.402, Global test accuracy: 50.19
Round  23, Train loss: 0.851, Test loss: 0.866, Test accuracy: 66.67
Round  23, Global train loss: 0.851, Global test loss: 1.367, Global test accuracy: 51.24
Round  24, Train loss: 0.881, Test loss: 0.860, Test accuracy: 67.15
Round  24, Global train loss: 0.881, Global test loss: 1.292, Global test accuracy: 53.63
Round  25, Train loss: 0.798, Test loss: 0.854, Test accuracy: 67.42
Round  25, Global train loss: 0.798, Global test loss: 1.220, Global test accuracy: 56.78
Round  26, Train loss: 0.792, Test loss: 0.859, Test accuracy: 67.71
Round  26, Global train loss: 0.792, Global test loss: 1.300, Global test accuracy: 52.64
Round  27, Train loss: 0.794, Test loss: 0.850, Test accuracy: 68.06
Round  27, Global train loss: 0.794, Global test loss: 1.277, Global test accuracy: 54.69
Round  28, Train loss: 0.790, Test loss: 0.846, Test accuracy: 68.00
Round  28, Global train loss: 0.790, Global test loss: 1.308, Global test accuracy: 54.00
Round  29, Train loss: 0.814, Test loss: 0.837, Test accuracy: 68.50
Round  29, Global train loss: 0.814, Global test loss: 1.327, Global test accuracy: 52.78
Round  30, Train loss: 0.749, Test loss: 0.842, Test accuracy: 68.78
Round  30, Global train loss: 0.749, Global test loss: 1.496, Global test accuracy: 47.72
Round  31, Train loss: 0.733, Test loss: 0.840, Test accuracy: 68.85
Round  31, Global train loss: 0.733, Global test loss: 1.200, Global test accuracy: 57.09
Round  32, Train loss: 0.712, Test loss: 0.842, Test accuracy: 68.82
Round  32, Global train loss: 0.712, Global test loss: 1.260, Global test accuracy: 55.50
Round  33, Train loss: 0.676, Test loss: 0.839, Test accuracy: 69.09
Round  33, Global train loss: 0.676, Global test loss: 1.186, Global test accuracy: 57.72
Round  34, Train loss: 0.658, Test loss: 0.834, Test accuracy: 69.09
Round  34, Global train loss: 0.658, Global test loss: 1.242, Global test accuracy: 56.63
Round  35, Train loss: 0.666, Test loss: 0.825, Test accuracy: 69.56
Round  35, Global train loss: 0.666, Global test loss: 1.321, Global test accuracy: 54.73
Round  36, Train loss: 0.715, Test loss: 0.808, Test accuracy: 70.32
Round  36, Global train loss: 0.715, Global test loss: 1.303, Global test accuracy: 54.70
Round  37, Train loss: 0.645, Test loss: 0.811, Test accuracy: 70.60
Round  37, Global train loss: 0.645, Global test loss: 1.305, Global test accuracy: 54.70
Round  38, Train loss: 0.692, Test loss: 0.797, Test accuracy: 70.98
Round  38, Global train loss: 0.692, Global test loss: 1.379, Global test accuracy: 53.61
Round  39, Train loss: 0.691, Test loss: 0.788, Test accuracy: 71.56
Round  39, Global train loss: 0.691, Global test loss: 1.205, Global test accuracy: 56.98
Round  40, Train loss: 0.614, Test loss: 0.807, Test accuracy: 70.99
Round  40, Global train loss: 0.614, Global test loss: 1.145, Global test accuracy: 59.50
Round  41, Train loss: 0.636, Test loss: 0.797, Test accuracy: 71.38
Round  41, Global train loss: 0.636, Global test loss: 1.425, Global test accuracy: 53.20
Round  42, Train loss: 0.610, Test loss: 0.805, Test accuracy: 71.43
Round  42, Global train loss: 0.610, Global test loss: 1.354, Global test accuracy: 54.85
Round  43, Train loss: 0.610, Test loss: 0.795, Test accuracy: 71.65
Round  43, Global train loss: 0.610, Global test loss: 1.278, Global test accuracy: 56.99
Round  44, Train loss: 0.539, Test loss: 0.795, Test accuracy: 71.60
Round  44, Global train loss: 0.539, Global test loss: 1.322, Global test accuracy: 57.12
Round  45, Train loss: 0.511, Test loss: 0.790, Test accuracy: 71.72
Round  45, Global train loss: 0.511, Global test loss: 1.433, Global test accuracy: 55.59
Round  46, Train loss: 0.651, Test loss: 0.793, Test accuracy: 71.22
Round  46, Global train loss: 0.651, Global test loss: 1.372, Global test accuracy: 55.61
Round  47, Train loss: 0.557, Test loss: 0.793, Test accuracy: 71.09
Round  47, Global train loss: 0.557, Global test loss: 1.109, Global test accuracy: 60.97
Round  48, Train loss: 0.621, Test loss: 0.795, Test accuracy: 71.70
Round  48, Global train loss: 0.621, Global test loss: 1.242, Global test accuracy: 57.97
Round  49, Train loss: 0.515, Test loss: 0.801, Test accuracy: 71.90
Round  49, Global train loss: 0.515, Global test loss: 1.471, Global test accuracy: 53.60
Round  50, Train loss: 0.558, Test loss: 0.830, Test accuracy: 71.57
Round  50, Global train loss: 0.558, Global test loss: 1.182, Global test accuracy: 59.43
Round  51, Train loss: 0.572, Test loss: 0.827, Test accuracy: 71.79
Round  51, Global train loss: 0.572, Global test loss: 1.120, Global test accuracy: 61.15
Round  52, Train loss: 0.584, Test loss: 0.811, Test accuracy: 72.30
Round  52, Global train loss: 0.584, Global test loss: 1.266, Global test accuracy: 57.24
Round  53, Train loss: 0.531, Test loss: 0.811, Test accuracy: 72.47
Round  53, Global train loss: 0.531, Global test loss: 1.214, Global test accuracy: 58.64
Round  54, Train loss: 0.571, Test loss: 0.826, Test accuracy: 72.12
Round  54, Global train loss: 0.571, Global test loss: 1.198, Global test accuracy: 58.33
Round  55, Train loss: 0.500, Test loss: 0.832, Test accuracy: 72.20
Round  55, Global train loss: 0.500, Global test loss: 1.137, Global test accuracy: 62.35
Round  56, Train loss: 0.507, Test loss: 0.814, Test accuracy: 72.69
Round  56, Global train loss: 0.507, Global test loss: 1.084, Global test accuracy: 63.01
Round  57, Train loss: 0.560, Test loss: 0.823, Test accuracy: 72.10
Round  57, Global train loss: 0.560, Global test loss: 1.103, Global test accuracy: 61.26
Round  58, Train loss: 0.509, Test loss: 0.811, Test accuracy: 72.45
Round  58, Global train loss: 0.509, Global test loss: 1.314, Global test accuracy: 56.39
Round  59, Train loss: 0.521, Test loss: 0.827, Test accuracy: 71.93
Round  59, Global train loss: 0.521, Global test loss: 1.229, Global test accuracy: 59.92
Round  60, Train loss: 0.551, Test loss: 0.837, Test accuracy: 72.45
Round  60, Global train loss: 0.551, Global test loss: 1.176, Global test accuracy: 60.20
Round  61, Train loss: 0.553, Test loss: 0.826, Test accuracy: 73.04
Round  61, Global train loss: 0.553, Global test loss: 1.129, Global test accuracy: 61.45
Round  62, Train loss: 0.544, Test loss: 0.823, Test accuracy: 73.06
Round  62, Global train loss: 0.544, Global test loss: 1.280, Global test accuracy: 56.39
Round  63, Train loss: 0.510, Test loss: 0.824, Test accuracy: 72.64
Round  63, Global train loss: 0.510, Global test loss: 1.197, Global test accuracy: 60.48
Round  64, Train loss: 0.469, Test loss: 0.827, Test accuracy: 72.31
Round  64, Global train loss: 0.469, Global test loss: 1.125, Global test accuracy: 62.99
Round  65, Train loss: 0.474, Test loss: 0.811, Test accuracy: 72.98
Round  65, Global train loss: 0.474, Global test loss: 1.235, Global test accuracy: 59.86
Round  66, Train loss: 0.430, Test loss: 0.816, Test accuracy: 73.20
Round  66, Global train loss: 0.430, Global test loss: 1.216, Global test accuracy: 59.62
Round  67, Train loss: 0.406, Test loss: 0.855, Test accuracy: 72.61
Round  67, Global train loss: 0.406, Global test loss: 1.207, Global test accuracy: 61.27
Round  68, Train loss: 0.450, Test loss: 0.847, Test accuracy: 72.61
Round  68, Global train loss: 0.450, Global test loss: 1.185, Global test accuracy: 61.11
Round  69, Train loss: 0.555, Test loss: 0.849, Test accuracy: 72.99
Round  69, Global train loss: 0.555, Global test loss: 1.143, Global test accuracy: 61.75
Round  70, Train loss: 0.406, Test loss: 0.837, Test accuracy: 73.19
Round  70, Global train loss: 0.406, Global test loss: 1.400, Global test accuracy: 57.24
Round  71, Train loss: 0.474, Test loss: 0.848, Test accuracy: 72.89
Round  71, Global train loss: 0.474, Global test loss: 1.300, Global test accuracy: 59.04
Round  72, Train loss: 0.450, Test loss: 0.829, Test accuracy: 73.44
Round  72, Global train loss: 0.450, Global test loss: 1.155, Global test accuracy: 62.09
Round  73, Train loss: 0.435, Test loss: 0.823, Test accuracy: 73.63
Round  73, Global train loss: 0.435, Global test loss: 1.100, Global test accuracy: 63.01
Round  74, Train loss: 0.473, Test loss: 0.864, Test accuracy: 73.15
Round  74, Global train loss: 0.473, Global test loss: 1.381, Global test accuracy: 57.83
Round  75, Train loss: 0.462, Test loss: 0.872, Test accuracy: 72.62
Round  75, Global train loss: 0.462, Global test loss: 1.224, Global test accuracy: 60.83
Round  76, Train loss: 0.380, Test loss: 0.870, Test accuracy: 73.02
Round  76, Global train loss: 0.380, Global test loss: 1.285, Global test accuracy: 60.86
Round  77, Train loss: 0.426, Test loss: 0.833, Test accuracy: 73.71
Round  77, Global train loss: 0.426, Global test loss: 1.248, Global test accuracy: 60.85
Round  78, Train loss: 0.453, Test loss: 0.822, Test accuracy: 73.95
Round  78, Global train loss: 0.453, Global test loss: 1.252, Global test accuracy: 60.76
Round  79, Train loss: 0.403, Test loss: 0.839, Test accuracy: 73.81
Round  79, Global train loss: 0.403, Global test loss: 1.177, Global test accuracy: 62.26
Round  80, Train loss: 0.476, Test loss: 0.838, Test accuracy: 73.72
Round  80, Global train loss: 0.476, Global test loss: 1.149, Global test accuracy: 61.64
Round  81, Train loss: 0.422, Test loss: 0.839, Test accuracy: 73.78
Round  81, Global train loss: 0.422, Global test loss: 1.380, Global test accuracy: 58.56
Round  82, Train loss: 0.439, Test loss: 0.831, Test accuracy: 74.45
Round  82, Global train loss: 0.439, Global test loss: 1.130, Global test accuracy: 63.07
Round  83, Train loss: 0.384, Test loss: 0.818, Test accuracy: 74.46
Round  83, Global train loss: 0.384, Global test loss: 1.195, Global test accuracy: 62.01
Round  84, Train loss: 0.352, Test loss: 0.839, Test accuracy: 74.10
Round  84, Global train loss: 0.352, Global test loss: 1.381, Global test accuracy: 60.47
Round  85, Train loss: 0.434, Test loss: 0.857, Test accuracy: 73.61
Round  85, Global train loss: 0.434, Global test loss: 1.271, Global test accuracy: 60.58
Round  86, Train loss: 0.392, Test loss: 0.835, Test accuracy: 73.93
Round  86, Global train loss: 0.392, Global test loss: 1.190, Global test accuracy: 62.07
Round  87, Train loss: 0.411, Test loss: 0.836, Test accuracy: 74.03
Round  87, Global train loss: 0.411, Global test loss: 1.192, Global test accuracy: 62.02
Round  88, Train loss: 0.439, Test loss: 0.856, Test accuracy: 73.65
Round  88, Global train loss: 0.439, Global test loss: 1.432, Global test accuracy: 56.84
Round  89, Train loss: 0.355, Test loss: 0.854, Test accuracy: 74.06
Round  89, Global train loss: 0.355, Global test loss: 1.168, Global test accuracy: 63.25
Round  90, Train loss: 0.391, Test loss: 0.851, Test accuracy: 74.08
Round  90, Global train loss: 0.391, Global test loss: 1.230, Global test accuracy: 62.54
Round  91, Train loss: 0.352, Test loss: 0.845, Test accuracy: 74.43
Round  91, Global train loss: 0.352, Global test loss: 1.398, Global test accuracy: 60.27
Round  92, Train loss: 0.459, Test loss: 0.850, Test accuracy: 74.24
Round  92, Global train loss: 0.459, Global test loss: 1.188, Global test accuracy: 62.80
Round  93, Train loss: 0.352, Test loss: 0.848, Test accuracy: 74.46
Round  93, Global train loss: 0.352, Global test loss: 1.313, Global test accuracy: 61.01
Round  94, Train loss: 0.340, Test loss: 0.880, Test accuracy: 73.61
Round  94, Global train loss: 0.340, Global test loss: 1.218, Global test accuracy: 61.65/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  95, Train loss: 0.357, Test loss: 0.880, Test accuracy: 73.42
Round  95, Global train loss: 0.357, Global test loss: 1.277, Global test accuracy: 61.59
Round  96, Train loss: 0.410, Test loss: 0.876, Test accuracy: 73.47
Round  96, Global train loss: 0.410, Global test loss: 1.168, Global test accuracy: 62.94
Round  97, Train loss: 0.355, Test loss: 0.875, Test accuracy: 73.44
Round  97, Global train loss: 0.355, Global test loss: 1.173, Global test accuracy: 63.24
Round  98, Train loss: 0.395, Test loss: 0.866, Test accuracy: 73.73
Round  98, Global train loss: 0.395, Global test loss: 1.174, Global test accuracy: 62.93
Round  99, Train loss: 0.333, Test loss: 0.877, Test accuracy: 73.29
Round  99, Global train loss: 0.333, Global test loss: 1.347, Global test accuracy: 60.21
Final Round, Train loss: 0.297, Test loss: 0.902, Test accuracy: 74.75
Final Round, Global train loss: 0.297, Global test loss: 1.347, Global test accuracy: 60.21
Average accuracy final 10 rounds: 73.81700000000001 

Average global accuracy final 10 rounds: 61.91799999999999 

1812.1236045360565
[1.6829593181610107, 3.3659186363220215, 4.762665510177612, 6.159412384033203, 7.57508397102356, 8.990755558013916, 10.404644250869751, 11.818532943725586, 13.250062942504883, 14.68159294128418, 16.10179305076599, 17.521993160247803, 18.94321298599243, 20.36443281173706, 21.781270742416382, 23.198108673095703, 24.61068558692932, 26.02326250076294, 27.44259524345398, 28.86192798614502, 30.275954008102417, 31.689980030059814, 33.10483479499817, 34.51968955993652, 35.927964210510254, 37.336238861083984, 38.760738372802734, 40.185237884521484, 41.58931636810303, 42.99339485168457, 44.42255997657776, 45.85172510147095, 47.27497458457947, 48.69822406768799, 50.1210777759552, 51.54393148422241, 52.95687007904053, 54.36980867385864, 55.772947788238525, 57.17608690261841, 58.590802907943726, 60.00551891326904, 61.42584156990051, 62.84616422653198, 64.26826333999634, 65.6903624534607, 67.08823776245117, 68.48611307144165, 69.8933732509613, 71.30063343048096, 72.69937920570374, 74.09812498092651, 75.49152946472168, 76.88493394851685, 78.28232955932617, 79.6797251701355, 81.10011219978333, 82.52049922943115, 83.90808057785034, 85.29566192626953, 86.70694732666016, 88.11823272705078, 89.52568078041077, 90.93312883377075, 92.33318638801575, 93.73324394226074, 95.12404084205627, 96.5148377418518, 97.7946400642395, 99.0744423866272, 100.41849112510681, 101.76253986358643, 103.14989471435547, 104.53724956512451, 105.93923735618591, 107.34122514724731, 108.73056888580322, 110.11991262435913, 111.53261947631836, 112.94532632827759, 114.34631061553955, 115.74729490280151, 117.1475031375885, 118.54771137237549, 119.93905186653137, 121.33039236068726, 122.7285225391388, 124.12665271759033, 125.50631332397461, 126.88597393035889, 128.29542899131775, 129.7048840522766, 131.112553358078, 132.5202226638794, 133.9232759475708, 135.3263292312622, 136.7363772392273, 138.14642524719238, 139.54126477241516, 140.93610429763794, 142.33388137817383, 143.73165845870972, 145.13829946517944, 146.54494047164917, 147.97766208648682, 149.41038370132446, 150.815185546875, 152.21998739242554, 153.62437748908997, 155.0287675857544, 156.423011302948, 157.8172550201416, 159.23995995521545, 160.6626648902893, 162.07313179969788, 163.48359870910645, 164.90470147132874, 166.32580423355103, 167.7233555316925, 169.12090682983398, 170.52599263191223, 171.93107843399048, 173.32866835594177, 174.72625827789307, 176.13971400260925, 177.55316972732544, 178.94341826438904, 180.33366680145264, 181.7419240474701, 183.15018129348755, 184.62891793251038, 186.1076545715332, 187.40744638442993, 188.70723819732666, 190.0180914402008, 191.32894468307495, 192.7366542816162, 194.14436388015747, 195.55647373199463, 196.9685835838318, 198.3833930492401, 199.79820251464844, 201.2322380542755, 202.6662735939026, 204.07576942443848, 205.48526525497437, 206.90545916557312, 208.32565307617188, 209.72464299201965, 211.12363290786743, 212.53053045272827, 213.9374279975891, 215.316064119339, 216.69470024108887, 218.11903929710388, 219.5433783531189, 220.93760585784912, 222.33183336257935, 223.73777198791504, 225.14371061325073, 226.54590392112732, 227.9480972290039, 229.34689712524414, 230.74569702148438, 232.14276576042175, 233.53983449935913, 234.94479250907898, 236.34975051879883, 237.74411940574646, 239.1384882926941, 240.53971934318542, 241.94095039367676, 243.3587429523468, 244.77653551101685, 246.18480706214905, 247.59307861328125, 249.00736093521118, 250.4216432571411, 251.8347771167755, 253.2479109764099, 254.63215112686157, 256.01639127731323, 257.3499240875244, 258.6834568977356, 260.08288383483887, 261.48231077194214, 262.8688614368439, 264.2554121017456, 265.64632844924927, 267.03724479675293, 268.4494786262512, 269.8617124557495, 271.281920671463, 272.7021288871765, 274.12851071357727, 275.554892539978, 276.9505388736725, 278.34618520736694, 279.7456488609314, 281.14511251449585, 283.97845339775085, 286.81179428100586]
[22.62, 22.62, 29.99, 29.99, 40.3, 40.3, 44.76, 44.76, 47.0, 47.0, 49.53, 49.53, 53.14, 53.14, 55.05, 55.05, 57.47, 57.47, 58.49, 58.49, 59.55, 59.55, 60.59, 60.59, 61.04, 61.04, 61.76, 61.76, 61.7, 61.7, 62.6, 62.6, 62.62, 62.62, 62.69, 62.69, 62.82, 62.82, 63.22, 63.22, 64.53, 64.53, 64.97, 64.97, 65.08, 65.08, 66.67, 66.67, 67.15, 67.15, 67.42, 67.42, 67.71, 67.71, 68.06, 68.06, 68.0, 68.0, 68.5, 68.5, 68.78, 68.78, 68.85, 68.85, 68.82, 68.82, 69.09, 69.09, 69.09, 69.09, 69.56, 69.56, 70.32, 70.32, 70.6, 70.6, 70.98, 70.98, 71.56, 71.56, 70.99, 70.99, 71.38, 71.38, 71.43, 71.43, 71.65, 71.65, 71.6, 71.6, 71.72, 71.72, 71.22, 71.22, 71.09, 71.09, 71.7, 71.7, 71.9, 71.9, 71.57, 71.57, 71.79, 71.79, 72.3, 72.3, 72.47, 72.47, 72.12, 72.12, 72.2, 72.2, 72.69, 72.69, 72.1, 72.1, 72.45, 72.45, 71.93, 71.93, 72.45, 72.45, 73.04, 73.04, 73.06, 73.06, 72.64, 72.64, 72.31, 72.31, 72.98, 72.98, 73.2, 73.2, 72.61, 72.61, 72.61, 72.61, 72.99, 72.99, 73.19, 73.19, 72.89, 72.89, 73.44, 73.44, 73.63, 73.63, 73.15, 73.15, 72.62, 72.62, 73.02, 73.02, 73.71, 73.71, 73.95, 73.95, 73.81, 73.81, 73.72, 73.72, 73.78, 73.78, 74.45, 74.45, 74.46, 74.46, 74.1, 74.1, 73.61, 73.61, 73.93, 73.93, 74.03, 74.03, 73.65, 73.65, 74.06, 74.06, 74.08, 74.08, 74.43, 74.43, 74.24, 74.24, 74.46, 74.46, 73.61, 73.61, 73.42, 73.42, 73.47, 73.47, 73.44, 73.44, 73.73, 73.73, 73.29, 73.29, 74.75, 74.75]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.2 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 19, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 16, noise    level: 0.4000 
   Client 12, noise    level: 0.4000 
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.953, Test loss: 2.141, Test accuracy: 14.99
Round   1, Train loss: 1.579, Test loss: 1.982, Test accuracy: 26.62
Round   2, Train loss: 1.446, Test loss: 1.790, Test accuracy: 35.58
Round   3, Train loss: 1.373, Test loss: 1.564, Test accuracy: 42.20
Round   4, Train loss: 1.304, Test loss: 1.424, Test accuracy: 46.21
Round   5, Train loss: 1.255, Test loss: 1.356, Test accuracy: 48.68
Round   6, Train loss: 1.176, Test loss: 1.243, Test accuracy: 53.91
Round   7, Train loss: 1.255, Test loss: 1.174, Test accuracy: 55.44
Round   8, Train loss: 1.086, Test loss: 1.071, Test accuracy: 57.98
Round   9, Train loss: 1.091, Test loss: 1.040, Test accuracy: 59.35
Round  10, Train loss: 1.022, Test loss: 1.026, Test accuracy: 60.62
Round  11, Train loss: 0.989, Test loss: 1.005, Test accuracy: 60.91
Round  12, Train loss: 1.122, Test loss: 1.012, Test accuracy: 61.03
Round  13, Train loss: 1.090, Test loss: 1.005, Test accuracy: 61.56
Round  14, Train loss: 1.019, Test loss: 0.980, Test accuracy: 62.49
Round  15, Train loss: 1.031, Test loss: 0.959, Test accuracy: 63.45
Round  16, Train loss: 0.972, Test loss: 0.925, Test accuracy: 64.51
Round  17, Train loss: 1.084, Test loss: 0.931, Test accuracy: 64.34
Round  18, Train loss: 1.007, Test loss: 0.919, Test accuracy: 65.17
Round  19, Train loss: 0.927, Test loss: 0.901, Test accuracy: 65.35
Round  20, Train loss: 0.925, Test loss: 0.873, Test accuracy: 66.16
Round  21, Train loss: 0.939, Test loss: 0.877, Test accuracy: 66.50
Round  22, Train loss: 0.963, Test loss: 0.872, Test accuracy: 67.04
Round  23, Train loss: 0.882, Test loss: 0.863, Test accuracy: 67.37
Round  24, Train loss: 0.904, Test loss: 0.851, Test accuracy: 68.19
Round  25, Train loss: 0.860, Test loss: 0.840, Test accuracy: 68.18
Round  26, Train loss: 0.849, Test loss: 0.824, Test accuracy: 68.85
Round  27, Train loss: 0.837, Test loss: 0.813, Test accuracy: 69.66
Round  28, Train loss: 0.868, Test loss: 0.812, Test accuracy: 69.93
Round  29, Train loss: 0.886, Test loss: 0.808, Test accuracy: 70.07
Round  30, Train loss: 0.885, Test loss: 0.801, Test accuracy: 70.18
Round  31, Train loss: 0.868, Test loss: 0.788, Test accuracy: 70.87
Round  32, Train loss: 0.857, Test loss: 0.783, Test accuracy: 70.74
Round  33, Train loss: 0.781, Test loss: 0.788, Test accuracy: 70.53
Round  34, Train loss: 0.727, Test loss: 0.772, Test accuracy: 70.64
Round  35, Train loss: 0.864, Test loss: 0.764, Test accuracy: 71.40
Round  36, Train loss: 0.755, Test loss: 0.758, Test accuracy: 71.26
Round  37, Train loss: 0.799, Test loss: 0.764, Test accuracy: 71.73
Round  38, Train loss: 0.734, Test loss: 0.757, Test accuracy: 72.52
Round  39, Train loss: 0.825, Test loss: 0.741, Test accuracy: 73.20
Round  40, Train loss: 0.737, Test loss: 0.742, Test accuracy: 72.72
Round  41, Train loss: 0.819, Test loss: 0.752, Test accuracy: 72.39
Round  42, Train loss: 0.668, Test loss: 0.736, Test accuracy: 72.86
Round  43, Train loss: 0.659, Test loss: 0.721, Test accuracy: 73.17
Round  44, Train loss: 0.636, Test loss: 0.723, Test accuracy: 73.66
Round  45, Train loss: 0.649, Test loss: 0.725, Test accuracy: 73.21
Round  46, Train loss: 0.732, Test loss: 0.715, Test accuracy: 73.63
Round  47, Train loss: 0.722, Test loss: 0.716, Test accuracy: 73.50
Round  48, Train loss: 0.705, Test loss: 0.711, Test accuracy: 73.84
Round  49, Train loss: 0.615, Test loss: 0.704, Test accuracy: 74.10
Round  50, Train loss: 0.721, Test loss: 0.704, Test accuracy: 73.90
Round  51, Train loss: 0.691, Test loss: 0.719, Test accuracy: 73.45
Round  52, Train loss: 0.733, Test loss: 0.710, Test accuracy: 73.65
Round  53, Train loss: 0.607, Test loss: 0.707, Test accuracy: 74.08
Round  54, Train loss: 0.646, Test loss: 0.703, Test accuracy: 73.91
Round  55, Train loss: 0.643, Test loss: 0.702, Test accuracy: 73.57
Round  56, Train loss: 0.627, Test loss: 0.690, Test accuracy: 74.59
Round  57, Train loss: 0.612, Test loss: 0.689, Test accuracy: 74.78
Round  58, Train loss: 0.687, Test loss: 0.700, Test accuracy: 73.89
Round  59, Train loss: 0.616, Test loss: 0.690, Test accuracy: 74.62
Round  60, Train loss: 0.656, Test loss: 0.687, Test accuracy: 74.88
Round  61, Train loss: 0.629, Test loss: 0.678, Test accuracy: 75.02
Round  62, Train loss: 0.682, Test loss: 0.684, Test accuracy: 75.03
Round  63, Train loss: 0.596, Test loss: 0.685, Test accuracy: 75.02
Round  64, Train loss: 0.679, Test loss: 0.667, Test accuracy: 75.55
Round  65, Train loss: 0.592, Test loss: 0.669, Test accuracy: 75.37
Round  66, Train loss: 0.600, Test loss: 0.675, Test accuracy: 75.51
Round  67, Train loss: 0.492, Test loss: 0.674, Test accuracy: 75.10
Round  68, Train loss: 0.648, Test loss: 0.673, Test accuracy: 75.19
Round  69, Train loss: 0.578, Test loss: 0.678, Test accuracy: 75.50
Round  70, Train loss: 0.491, Test loss: 0.666, Test accuracy: 75.91
Round  71, Train loss: 0.618, Test loss: 0.667, Test accuracy: 75.57
Round  72, Train loss: 0.575, Test loss: 0.658, Test accuracy: 75.71
Round  73, Train loss: 0.571, Test loss: 0.652, Test accuracy: 76.32
Round  74, Train loss: 0.531, Test loss: 0.652, Test accuracy: 76.53
Round  75, Train loss: 0.508, Test loss: 0.662, Test accuracy: 75.91
Round  76, Train loss: 0.559, Test loss: 0.670, Test accuracy: 75.71
Round  77, Train loss: 0.460, Test loss: 0.665, Test accuracy: 76.36
Round  78, Train loss: 0.614, Test loss: 0.675, Test accuracy: 75.67
Round  79, Train loss: 0.570, Test loss: 0.670, Test accuracy: 76.01
Round  80, Train loss: 0.594, Test loss: 0.658, Test accuracy: 76.71
Round  81, Train loss: 0.511, Test loss: 0.666, Test accuracy: 76.11
Round  82, Train loss: 0.525, Test loss: 0.662, Test accuracy: 76.26
Round  83, Train loss: 0.490, Test loss: 0.668, Test accuracy: 75.76
Round  84, Train loss: 0.453, Test loss: 0.663, Test accuracy: 76.64
Round  85, Train loss: 0.539, Test loss: 0.674, Test accuracy: 75.66
Round  86, Train loss: 0.449, Test loss: 0.663, Test accuracy: 76.46
Round  87, Train loss: 0.470, Test loss: 0.660, Test accuracy: 75.97
Round  88, Train loss: 0.611, Test loss: 0.643, Test accuracy: 76.70
Round  89, Train loss: 0.504, Test loss: 0.653, Test accuracy: 76.40
Round  90, Train loss: 0.493, Test loss: 0.649, Test accuracy: 76.68
Round  91, Train loss: 0.464, Test loss: 0.647, Test accuracy: 76.83
Round  92, Train loss: 0.497, Test loss: 0.651, Test accuracy: 76.64
Round  93, Train loss: 0.502, Test loss: 0.656, Test accuracy: 76.47
Round  94, Train loss: 0.479, Test loss: 0.656, Test accuracy: 76.53
Round  95, Train loss: 0.445, Test loss: 0.654, Test accuracy: 76.55
Round  96, Train loss: 0.533, Test loss: 0.662, Test accuracy: 76.56
Round  97, Train loss: 0.432, Test loss: 0.657, Test accuracy: 76.97
Round  98, Train loss: 0.567, Test loss: 0.666, Test accuracy: 76.71
Round  99, Train loss: 0.410, Test loss: 0.656, Test accuracy: 77.00
Final Round, Train loss: 0.403, Test loss: 0.660, Test accuracy: 77.23
Average accuracy final 10 rounds: 76.694
2384.190099954605
[3.801776170730591, 7.418419599533081, 10.876725196838379, 14.400201082229614, 17.9342143535614, 21.369867086410522, 24.93476939201355, 28.507678031921387, 32.04892587661743, 35.53811073303223, 39.16769051551819, 42.718759536743164, 46.22812461853027, 49.48254942893982, 52.86416935920715, 56.363784074783325, 59.58379292488098, 63.0706467628479, 66.3965220451355, 69.69350481033325, 73.0219566822052, 76.31749653816223, 79.60102534294128, 83.06820678710938, 86.42176485061646, 89.64790534973145, 93.00354814529419, 96.32956624031067, 99.61748051643372, 102.95655655860901, 106.22942018508911, 109.50537037849426, 112.80195713043213, 116.06853151321411, 119.30402493476868, 122.54446935653687, 125.77503538131714, 129.04078364372253, 132.2647774219513, 135.61248993873596, 138.91044211387634, 142.21661353111267, 145.55328512191772, 148.87091159820557, 152.2077934741974, 155.49232411384583, 158.9014630317688, 162.34821224212646, 165.62710404396057, 168.99831557273865, 172.4014310836792, 175.68681383132935, 178.98058009147644, 182.29397749900818, 185.64439153671265, 188.84021019935608, 192.1393449306488, 195.43613004684448, 198.73999619483948, 202.0366711616516, 205.3591525554657, 208.69070029258728, 212.01522183418274, 215.35172867774963, 218.68655252456665, 222.2365846633911, 225.78849291801453, 229.3615071773529, 232.85690760612488, 236.3128626346588, 239.88908195495605, 243.22924375534058, 246.58480286598206, 250.16425323486328, 253.66845750808716, 257.20346784591675, 260.8103063106537, 264.4755713939667, 268.01454162597656, 271.4493296146393, 275.0375831127167, 278.557133436203, 282.0100910663605, 285.57439827919006, 289.0960018634796, 292.56182622909546, 296.0715777873993, 299.53839349746704, 303.19025778770447, 306.73922061920166, 310.26148891448975, 313.9187579154968, 317.47957706451416, 321.012859582901, 324.5988337993622, 328.13538932800293, 331.6662845611572, 335.11914134025574, 338.6757264137268, 342.26283740997314, 347.15969920158386]
[14.99, 26.62, 35.58, 42.2, 46.21, 48.68, 53.91, 55.44, 57.98, 59.35, 60.62, 60.91, 61.03, 61.56, 62.49, 63.45, 64.51, 64.34, 65.17, 65.35, 66.16, 66.5, 67.04, 67.37, 68.19, 68.18, 68.85, 69.66, 69.93, 70.07, 70.18, 70.87, 70.74, 70.53, 70.64, 71.4, 71.26, 71.73, 72.52, 73.2, 72.72, 72.39, 72.86, 73.17, 73.66, 73.21, 73.63, 73.5, 73.84, 74.1, 73.9, 73.45, 73.65, 74.08, 73.91, 73.57, 74.59, 74.78, 73.89, 74.62, 74.88, 75.02, 75.03, 75.02, 75.55, 75.37, 75.51, 75.1, 75.19, 75.5, 75.91, 75.57, 75.71, 76.32, 76.53, 75.91, 75.71, 76.36, 75.67, 76.01, 76.71, 76.11, 76.26, 75.76, 76.64, 75.66, 76.46, 75.97, 76.7, 76.4, 76.68, 76.83, 76.64, 76.47, 76.53, 76.55, 76.56, 76.97, 76.71, 77.0, 77.23]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 3, noise    level: 0.4000 
   Client 13, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 12, noise    level: 0.4000 
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  20.0000
Round 1 global test acc  16.4600
Round 2 global test acc  24.6000
Round 3 global test acc  29.5300
Round 4 global test acc  24.3600
Round 5 global test acc  26.9900
Round 6 global test acc  28.7500
Round 7 global test acc  26.1300
Round 8 global test acc  28.2500
Round 9 global test acc  27.7500
Round 10 global test acc  36.8800
Round 11 global test acc  32.5600
Round 12 global test acc  32.0100
Round 13 global test acc  36.7200
Round 14 global test acc  27.6800
Round 15 global test acc  36.2700
Round 16 global test acc  29.0400
Round 17 global test acc  30.6900
Round 18 global test acc  32.2700
Round 19 global test acc  33.7500
Round 20 global test acc  39.9800
Round 21 global test acc  34.0400
Round 22 global test acc  39.1900
Round 23 global test acc  34.8200
Round 24 global test acc  37.0700
Round 25 global test acc  37.5200
Round 26 global test acc  38.0400
Round 27 global test acc  39.5700
Round 28 global test acc  38.2400
Round 29 global test acc  39.1200
Round 30 global test acc  38.7500
Round 31 global test acc  42.9400
Round 32 global test acc  37.0100
Round 33 global test acc  37.0800
Round 34 global test acc  41.7100
Round 35 global test acc  36.9700
Round 36 global test acc  33.5800
Round 37 global test acc  40.0000
Round 38 global test acc  39.4100
Round 39 global test acc  38.9500
Round 40 global test acc  36.9100
Round 41 global test acc  44.2500
Round 42 global test acc  45.6800
Round 43 global test acc  39.3000
Round 44 global test acc  31.8500
Round 45 global test acc  37.1100
Round 46 global test acc  40.4800
Round 47 global test acc  40.7600
Round 48 global test acc  41.6100
Round 49 global test acc  41.6100
Round 50 global test acc  44.6500
Round 51 global test acc  39.4700
Round 52 global test acc  42.5300
Round 53 global test acc  35.2300
Round 54 global test acc  41.5800
Round 55 global test acc  40.9300
Round 56 global test acc  38.7700
Round 57 global test acc  41.0400
Round 58 global test acc  40.4400
Round 59 global test acc  38.1800
Round 60 global test acc  49.0800
Round 61 global test acc  48.2700
Round 62 global test acc  50.9300
Round 63 global test acc  49.2000
Round 64 global test acc  36.5300
Round 65 global test acc  41.1900
Round 66 global test acc  43.5600
Round 67 global test acc  40.7000
Round 68 global test acc  38.9400
Round 69 global test acc  43.6800
Round 70 global test acc  45.3100
Round 71 global test acc  47.2400
Round 72 global test acc  38.5900
Round 73 global test acc  38.8800
Round 74 global test acc  45.7200
Round 75 global test acc  40.6000
Round 76 global test acc  38.6900
Round 77 global test acc  44.4800
Round 78 global test acc  47.1300
Round 79 global test acc  39.9900
Round 80 global test acc  37.7600
Round 81 global test acc  35.5800
Round 82 global test acc  35.2700
Round 83 global test acc  34.6100
Round 84 global test acc  33.2800
Round 85 global test acc  31.2700
Round 86 global test acc  29.0800
Round 87 global test acc  27.6500
Round 88 global test acc  27.4700
Round 89 global test acc  29.4200
Round 90 global test acc  29.6400
Round 91 global test acc  28.1300
Round 92 global test acc  28.3200
Round 93 global test acc  27.9000
Round 94 global test acc  27.0200
Round 95 global test acc  26.0200
Round 96 global test acc  26.0200
Round 97 global test acc  25.5100
Round 98 global test acc  25.5000
Round 99 global test acc  23.8900
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 0, noise    level: 0.4000 
   Client 14, noise    level: 0.4000 
   Client 13, noise    level: 0.4000 
   Client 15, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.975, Test loss: 2.143, Test accuracy: 18.99
Round   1, Train loss: 1.583, Test loss: 2.062, Test accuracy: 28.72
Round   2, Train loss: 1.466, Test loss: 1.778, Test accuracy: 35.38
Round   3, Train loss: 1.319, Test loss: 1.491, Test accuracy: 44.01
Round   4, Train loss: 1.223, Test loss: 1.372, Test accuracy: 47.30
Round   5, Train loss: 1.147, Test loss: 1.295, Test accuracy: 49.95
Round   6, Train loss: 1.185, Test loss: 1.204, Test accuracy: 54.31
Round   7, Train loss: 1.191, Test loss: 1.117, Test accuracy: 56.99
Round   8, Train loss: 1.041, Test loss: 1.013, Test accuracy: 59.73
Round   9, Train loss: 1.053, Test loss: 0.978, Test accuracy: 61.73
Round  10, Train loss: 0.995, Test loss: 0.964, Test accuracy: 62.29
Round  11, Train loss: 0.990, Test loss: 0.955, Test accuracy: 62.05
Round  12, Train loss: 1.085, Test loss: 0.936, Test accuracy: 63.20
Round  13, Train loss: 0.999, Test loss: 0.933, Test accuracy: 63.10
Round  14, Train loss: 0.931, Test loss: 0.915, Test accuracy: 64.01
Round  15, Train loss: 0.993, Test loss: 0.889, Test accuracy: 65.13
Round  16, Train loss: 0.938, Test loss: 0.885, Test accuracy: 65.44
Round  17, Train loss: 0.973, Test loss: 0.897, Test accuracy: 65.05
Round  18, Train loss: 0.922, Test loss: 0.855, Test accuracy: 67.35
Round  19, Train loss: 0.870, Test loss: 0.841, Test accuracy: 67.72
Round  20, Train loss: 0.875, Test loss: 0.830, Test accuracy: 67.79
Round  21, Train loss: 0.881, Test loss: 0.822, Test accuracy: 67.88
Round  22, Train loss: 0.942, Test loss: 0.819, Test accuracy: 67.85
Round  23, Train loss: 0.811, Test loss: 0.801, Test accuracy: 68.77
Round  24, Train loss: 0.925, Test loss: 0.797, Test accuracy: 69.24
Round  25, Train loss: 0.794, Test loss: 0.794, Test accuracy: 69.19
Round  26, Train loss: 0.808, Test loss: 0.785, Test accuracy: 69.51
Round  27, Train loss: 0.805, Test loss: 0.767, Test accuracy: 70.66
Round  28, Train loss: 0.835, Test loss: 0.767, Test accuracy: 70.67
Round  29, Train loss: 0.803, Test loss: 0.756, Test accuracy: 70.97
Round  30, Train loss: 0.800, Test loss: 0.748, Test accuracy: 70.97
Round  31, Train loss: 0.778, Test loss: 0.759, Test accuracy: 71.05
Round  32, Train loss: 0.763, Test loss: 0.744, Test accuracy: 71.32
Round  33, Train loss: 0.724, Test loss: 0.736, Test accuracy: 71.62
Round  34, Train loss: 0.742, Test loss: 0.733, Test accuracy: 71.60
Round  35, Train loss: 0.741, Test loss: 0.726, Test accuracy: 72.33
Round  36, Train loss: 0.685, Test loss: 0.711, Test accuracy: 72.75
Round  37, Train loss: 0.768, Test loss: 0.707, Test accuracy: 73.02
Round  38, Train loss: 0.704, Test loss: 0.709, Test accuracy: 72.71
Round  39, Train loss: 0.780, Test loss: 0.702, Test accuracy: 73.22
Round  40, Train loss: 0.711, Test loss: 0.703, Test accuracy: 73.30
Round  41, Train loss: 0.722, Test loss: 0.705, Test accuracy: 73.31
Round  42, Train loss: 0.619, Test loss: 0.683, Test accuracy: 73.91
Round  43, Train loss: 0.628, Test loss: 0.689, Test accuracy: 73.44
Round  44, Train loss: 0.595, Test loss: 0.685, Test accuracy: 73.91
Round  45, Train loss: 0.604, Test loss: 0.686, Test accuracy: 73.94
Round  46, Train loss: 0.670, Test loss: 0.678, Test accuracy: 74.27
Round  47, Train loss: 0.635, Test loss: 0.676, Test accuracy: 74.82
Round  48, Train loss: 0.676, Test loss: 0.684, Test accuracy: 74.11
Round  49, Train loss: 0.555, Test loss: 0.673, Test accuracy: 74.33
Round  50, Train loss: 0.649, Test loss: 0.674, Test accuracy: 74.21
Round  51, Train loss: 0.594, Test loss: 0.655, Test accuracy: 75.58
Round  52, Train loss: 0.604, Test loss: 0.650, Test accuracy: 75.76
Round  53, Train loss: 0.550, Test loss: 0.652, Test accuracy: 75.62
Round  54, Train loss: 0.626, Test loss: 0.654, Test accuracy: 75.69
Round  55, Train loss: 0.584, Test loss: 0.645, Test accuracy: 75.78
Round  56, Train loss: 0.600, Test loss: 0.650, Test accuracy: 75.73
Round  57, Train loss: 0.621, Test loss: 0.647, Test accuracy: 75.96
Round  58, Train loss: 0.591, Test loss: 0.653, Test accuracy: 75.54
Round  59, Train loss: 0.607, Test loss: 0.650, Test accuracy: 75.71
Round  60, Train loss: 0.583, Test loss: 0.646, Test accuracy: 76.08
Round  61, Train loss: 0.543, Test loss: 0.635, Test accuracy: 76.31
Round  62, Train loss: 0.580, Test loss: 0.633, Test accuracy: 76.55
Round  63, Train loss: 0.539, Test loss: 0.634, Test accuracy: 76.27
Round  64, Train loss: 0.597, Test loss: 0.627, Test accuracy: 76.49
Round  65, Train loss: 0.532, Test loss: 0.634, Test accuracy: 76.08
Round  66, Train loss: 0.534, Test loss: 0.627, Test accuracy: 76.52
Round  67, Train loss: 0.461, Test loss: 0.627, Test accuracy: 76.40
Round  68, Train loss: 0.543, Test loss: 0.634, Test accuracy: 76.47
Round  69, Train loss: 0.542, Test loss: 0.624, Test accuracy: 76.95
Round  70, Train loss: 0.464, Test loss: 0.626, Test accuracy: 76.88
Round  71, Train loss: 0.575, Test loss: 0.622, Test accuracy: 77.09
Round  72, Train loss: 0.579, Test loss: 0.625, Test accuracy: 76.96
Round  73, Train loss: 0.482, Test loss: 0.608, Test accuracy: 77.69
Round  74, Train loss: 0.494, Test loss: 0.605, Test accuracy: 77.79
Round  75, Train loss: 0.480, Test loss: 0.616, Test accuracy: 77.45
Round  76, Train loss: 0.443, Test loss: 0.612, Test accuracy: 77.72
Round  77, Train loss: 0.446, Test loss: 0.613, Test accuracy: 77.69
Round  78, Train loss: 0.553, Test loss: 0.605, Test accuracy: 77.96
Round  79, Train loss: 0.475, Test loss: 0.612, Test accuracy: 77.88
Round  80, Train loss: 0.539, Test loss: 0.605, Test accuracy: 77.95
Round  81, Train loss: 0.470, Test loss: 0.607, Test accuracy: 77.88
Round  82, Train loss: 0.480, Test loss: 0.608, Test accuracy: 77.91
Round  83, Train loss: 0.491, Test loss: 0.613, Test accuracy: 78.04
Round  84, Train loss: 0.450, Test loss: 0.603, Test accuracy: 77.90
Round  85, Train loss: 0.457, Test loss: 0.617, Test accuracy: 77.57
Round  86, Train loss: 0.477, Test loss: 0.607, Test accuracy: 78.11
Round  87, Train loss: 0.435, Test loss: 0.607, Test accuracy: 78.03
Round  88, Train loss: 0.513, Test loss: 0.594, Test accuracy: 78.38
Round  89, Train loss: 0.452, Test loss: 0.597, Test accuracy: 78.16
Round  90, Train loss: 0.481, Test loss: 0.602, Test accuracy: 77.98
Round  91, Train loss: 0.400, Test loss: 0.592, Test accuracy: 78.49
Round  92, Train loss: 0.458, Test loss: 0.601, Test accuracy: 78.22
Round  93, Train loss: 0.439, Test loss: 0.602, Test accuracy: 78.33
Round  94, Train loss: 0.454, Test loss: 0.608, Test accuracy: 78.04
Round  95, Train loss: 0.401, Test loss: 0.602, Test accuracy: 78.39
Round  96, Train loss: 0.454, Test loss: 0.593, Test accuracy: 78.53
Round  97, Train loss: 0.452, Test loss: 0.600, Test accuracy: 78.11
Round  98, Train loss: 0.447, Test loss: 0.592, Test accuracy: 78.86
Round  99, Train loss: 0.387, Test loss: 0.597, Test accuracy: 78.28
Final Round, Train loss: 0.367, Test loss: 0.599, Test accuracy: 78.57
Average accuracy final 10 rounds: 78.32300000000001
1244.0511708259583
[1.9006850719451904, 3.470417022705078, 5.02531099319458, 6.580613851547241, 8.141491651535034, 9.715311288833618, 11.146035194396973, 12.563778400421143, 14.015929937362671, 15.40808892250061, 16.806098699569702, 18.295976161956787, 19.81323480606079, 21.365825176239014, 22.863397121429443, 24.418960571289062, 25.955869436264038, 27.53000235557556, 29.06334686279297, 30.60628056526184, 32.14018392562866, 33.6768593788147, 35.20209741592407, 36.74157166481018, 38.30949091911316, 39.89031267166138, 41.431316614151, 43.00532555580139, 44.538206577301025, 46.071276903152466, 47.59757709503174, 49.11906695365906, 50.63826322555542, 52.15909433364868, 53.7016236782074, 55.256133794784546, 56.81987762451172, 58.34624147415161, 59.90936017036438, 61.47129511833191, 63.01075792312622, 64.58873152732849, 66.14110016822815, 67.6704306602478, 69.22553634643555, 70.75495409965515, 72.29512929916382, 73.84104061126709, 75.37493181228638, 76.9540524482727, 78.47707080841064, 80.00006890296936, 81.4189293384552, 82.8600537776947, 84.3812940120697, 85.95441508293152, 87.35023617744446, 88.78607273101807, 90.2012848854065, 91.63576531410217, 93.08536338806152, 94.60905694961548, 96.16339111328125, 97.70000696182251, 99.23476529121399, 100.77036333084106, 102.32535290718079, 103.85089564323425, 105.36176419258118, 106.89594912528992, 108.44505834579468, 109.9705879688263, 111.50933694839478, 113.03161239624023, 114.58115601539612, 116.14076566696167, 117.7097818851471, 119.24066305160522, 120.78468489646912, 122.30953192710876, 123.86198258399963, 125.41377568244934, 126.94279479980469, 128.50830674171448, 130.0290915966034, 131.57761335372925, 133.11572194099426, 134.6884138584137, 136.2109558582306, 137.71882557868958, 139.2551715373993, 140.65028357505798, 142.1071367263794, 143.51775360107422, 144.89019870758057, 146.41182398796082, 147.96040678024292, 149.50970578193665, 151.02886128425598, 152.54576659202576, 154.82536673545837]
[18.99, 28.72, 35.38, 44.01, 47.3, 49.95, 54.31, 56.99, 59.73, 61.73, 62.29, 62.05, 63.2, 63.1, 64.01, 65.13, 65.44, 65.05, 67.35, 67.72, 67.79, 67.88, 67.85, 68.77, 69.24, 69.19, 69.51, 70.66, 70.67, 70.97, 70.97, 71.05, 71.32, 71.62, 71.6, 72.33, 72.75, 73.02, 72.71, 73.22, 73.3, 73.31, 73.91, 73.44, 73.91, 73.94, 74.27, 74.82, 74.11, 74.33, 74.21, 75.58, 75.76, 75.62, 75.69, 75.78, 75.73, 75.96, 75.54, 75.71, 76.08, 76.31, 76.55, 76.27, 76.49, 76.08, 76.52, 76.4, 76.47, 76.95, 76.88, 77.09, 76.96, 77.69, 77.79, 77.45, 77.72, 77.69, 77.96, 77.88, 77.95, 77.88, 77.91, 78.04, 77.9, 77.57, 78.11, 78.03, 78.38, 78.16, 77.98, 78.49, 78.22, 78.33, 78.04, 78.39, 78.53, 78.11, 78.86, 78.28, 78.57]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.2 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 11, noise    level: 0.4000 
   Client 15, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 10, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.932, Test loss: 2.108, Test accuracy: 19.78
Round   1, Train loss: 1.526, Test loss: 2.053, Test accuracy: 29.71
Round   2, Train loss: 1.425, Test loss: 1.746, Test accuracy: 38.30
Round   3, Train loss: 1.278, Test loss: 1.502, Test accuracy: 44.16
Round   4, Train loss: 1.251, Test loss: 1.353, Test accuracy: 49.38
Round   5, Train loss: 1.150, Test loss: 1.266, Test accuracy: 51.74
Round   6, Train loss: 1.150, Test loss: 1.179, Test accuracy: 55.51
Round   7, Train loss: 1.187, Test loss: 1.107, Test accuracy: 57.58
Round   8, Train loss: 1.058, Test loss: 1.016, Test accuracy: 59.03
Round   9, Train loss: 1.021, Test loss: 0.999, Test accuracy: 60.70
Round  10, Train loss: 0.987, Test loss: 0.973, Test accuracy: 60.98
Round  11, Train loss: 0.987, Test loss: 0.932, Test accuracy: 62.54
Round  12, Train loss: 1.041, Test loss: 0.917, Test accuracy: 63.96
Round  13, Train loss: 0.978, Test loss: 0.911, Test accuracy: 63.94
Round  14, Train loss: 0.949, Test loss: 0.904, Test accuracy: 64.53
Round  15, Train loss: 0.978, Test loss: 0.910, Test accuracy: 64.54
Round  16, Train loss: 0.896, Test loss: 0.899, Test accuracy: 64.62
Round  17, Train loss: 0.946, Test loss: 0.883, Test accuracy: 65.47
Round  18, Train loss: 0.878, Test loss: 0.881, Test accuracy: 65.84
Round  19, Train loss: 0.847, Test loss: 0.870, Test accuracy: 66.10
Round  20, Train loss: 0.847, Test loss: 0.851, Test accuracy: 66.70
Round  21, Train loss: 0.878, Test loss: 0.840, Test accuracy: 67.21
Round  22, Train loss: 0.911, Test loss: 0.818, Test accuracy: 68.06
Round  23, Train loss: 0.836, Test loss: 0.805, Test accuracy: 68.56
Round  24, Train loss: 0.884, Test loss: 0.784, Test accuracy: 69.41
Round  25, Train loss: 0.792, Test loss: 0.784, Test accuracy: 69.45
Round  26, Train loss: 0.826, Test loss: 0.786, Test accuracy: 69.55
Round  27, Train loss: 0.807, Test loss: 0.773, Test accuracy: 69.92
Round  28, Train loss: 0.830, Test loss: 0.779, Test accuracy: 69.72
Round  29, Train loss: 0.806, Test loss: 0.775, Test accuracy: 69.83
Round  30, Train loss: 0.803, Test loss: 0.768, Test accuracy: 70.23
Round  31, Train loss: 0.788, Test loss: 0.746, Test accuracy: 71.26
Round  32, Train loss: 0.726, Test loss: 0.738, Test accuracy: 71.37
Round  33, Train loss: 0.723, Test loss: 0.747, Test accuracy: 71.04
Round  34, Train loss: 0.702, Test loss: 0.734, Test accuracy: 71.59
Round  35, Train loss: 0.739, Test loss: 0.733, Test accuracy: 71.69
Round  36, Train loss: 0.690, Test loss: 0.717, Test accuracy: 72.24
Round  37, Train loss: 0.696, Test loss: 0.711, Test accuracy: 72.86
Round  38, Train loss: 0.710, Test loss: 0.703, Test accuracy: 73.37
Round  39, Train loss: 0.748, Test loss: 0.704, Test accuracy: 73.31
Round  40, Train loss: 0.679, Test loss: 0.710, Test accuracy: 72.90
Round  41, Train loss: 0.696, Test loss: 0.704, Test accuracy: 72.82
Round  42, Train loss: 0.651, Test loss: 0.696, Test accuracy: 73.13
Round  43, Train loss: 0.661, Test loss: 0.685, Test accuracy: 73.71
Round  44, Train loss: 0.605, Test loss: 0.687, Test accuracy: 73.72
Round  45, Train loss: 0.595, Test loss: 0.685, Test accuracy: 73.66
Round  46, Train loss: 0.637, Test loss: 0.678, Test accuracy: 73.89
Round  47, Train loss: 0.602, Test loss: 0.680, Test accuracy: 74.04
Round  48, Train loss: 0.676, Test loss: 0.677, Test accuracy: 74.05
Round  49, Train loss: 0.567, Test loss: 0.666, Test accuracy: 74.49
Round  50, Train loss: 0.621, Test loss: 0.666, Test accuracy: 74.45
Round  51, Train loss: 0.591, Test loss: 0.660, Test accuracy: 75.02
Round  52, Train loss: 0.620, Test loss: 0.655, Test accuracy: 74.97
Round  53, Train loss: 0.552, Test loss: 0.671, Test accuracy: 74.19
Round  54, Train loss: 0.626, Test loss: 0.657, Test accuracy: 74.90
Round  55, Train loss: 0.585, Test loss: 0.662, Test accuracy: 74.94
Round  56, Train loss: 0.575, Test loss: 0.648, Test accuracy: 75.40
Round  57, Train loss: 0.590, Test loss: 0.640, Test accuracy: 75.85
Round  58, Train loss: 0.557, Test loss: 0.638, Test accuracy: 75.96
Round  59, Train loss: 0.575, Test loss: 0.635, Test accuracy: 76.19
Round  60, Train loss: 0.589, Test loss: 0.633, Test accuracy: 76.30
Round  61, Train loss: 0.537, Test loss: 0.626, Test accuracy: 76.45
Round  62, Train loss: 0.541, Test loss: 0.634, Test accuracy: 76.03
Round  63, Train loss: 0.564, Test loss: 0.642, Test accuracy: 75.72
Round  64, Train loss: 0.531, Test loss: 0.632, Test accuracy: 76.18
Round  65, Train loss: 0.558, Test loss: 0.639, Test accuracy: 76.01
Round  66, Train loss: 0.518, Test loss: 0.646, Test accuracy: 75.45
Round  67, Train loss: 0.491, Test loss: 0.636, Test accuracy: 76.17
Round  68, Train loss: 0.529, Test loss: 0.638, Test accuracy: 76.47
Round  69, Train loss: 0.551, Test loss: 0.638, Test accuracy: 75.94
Round  70, Train loss: 0.461, Test loss: 0.635, Test accuracy: 76.02
Round  71, Train loss: 0.546, Test loss: 0.630, Test accuracy: 76.21
Round  72, Train loss: 0.518, Test loss: 0.628, Test accuracy: 76.77
Round  73, Train loss: 0.519, Test loss: 0.622, Test accuracy: 76.63
Round  74, Train loss: 0.514, Test loss: 0.624, Test accuracy: 76.79
Round  75, Train loss: 0.483, Test loss: 0.615, Test accuracy: 76.99
Round  76, Train loss: 0.422, Test loss: 0.615, Test accuracy: 77.32
Round  77, Train loss: 0.448, Test loss: 0.619, Test accuracy: 76.96
Round  78, Train loss: 0.486, Test loss: 0.614, Test accuracy: 77.21
Round  79, Train loss: 0.430, Test loss: 0.607, Test accuracy: 77.52
Round  80, Train loss: 0.533, Test loss: 0.613, Test accuracy: 77.07
Round  81, Train loss: 0.483, Test loss: 0.609, Test accuracy: 77.17
Round  82, Train loss: 0.478, Test loss: 0.610, Test accuracy: 77.50
Round  83, Train loss: 0.424, Test loss: 0.618, Test accuracy: 77.26
Round  84, Train loss: 0.416, Test loss: 0.624, Test accuracy: 77.15
Round  85, Train loss: 0.481, Test loss: 0.624, Test accuracy: 76.95
Round  86, Train loss: 0.438, Test loss: 0.608, Test accuracy: 77.37
Round  87, Train loss: 0.431, Test loss: 0.605, Test accuracy: 77.67
Round  88, Train loss: 0.482, Test loss: 0.613, Test accuracy: 77.07
Round  89, Train loss: 0.452, Test loss: 0.611, Test accuracy: 76.98
Round  90, Train loss: 0.445, Test loss: 0.605, Test accuracy: 77.33
Round  91, Train loss: 0.405, Test loss: 0.614, Test accuracy: 77.25
Round  92, Train loss: 0.461, Test loss: 0.611, Test accuracy: 77.31
Round  93, Train loss: 0.433, Test loss: 0.603, Test accuracy: 77.65
Round  94, Train loss: 0.407, Test loss: 0.603, Test accuracy: 77.65
Round  95, Train loss: 0.409, Test loss: 0.603, Test accuracy: 77.56
Round  96, Train loss: 0.418, Test loss: 0.617, Test accuracy: 77.36
Round  97, Train loss: 0.424, Test loss: 0.600, Test accuracy: 77.87
Round  98, Train loss: 0.421, Test loss: 0.615, Test accuracy: 77.35
Round  99, Train loss: 0.388, Test loss: 0.604, Test accuracy: 77.85
Final Round, Train loss: 0.286, Test loss: 0.603, Test accuracy: 77.83
Average accuracy final 10 rounds: 77.518
2198.686461687088
[1.8564167022705078, 3.3391551971435547, 4.882163047790527, 6.441158771514893, 7.970693349838257, 9.525835037231445, 11.107226610183716, 12.695115566253662, 14.310408115386963, 15.797297954559326, 17.34017515182495, 18.86580991744995, 20.440985202789307, 21.96224021911621, 23.38236355781555, 24.77909564971924, 26.138481616973877, 27.538769483566284, 28.9174747467041, 30.331294298171997, 31.723790884017944, 35.37719702720642, 38.944504737854004, 42.49833607673645, 46.116432666778564, 49.74388408660889, 53.37355613708496, 56.94757795333862, 60.511685371398926, 64.14552402496338, 67.83443856239319, 71.63869595527649, 75.34273147583008, 78.91042017936707, 82.43926477432251, 86.02388644218445, 89.57385540008545, 93.16887497901917, 96.63906288146973, 100.37689709663391, 104.32022404670715, 108.30425930023193, 112.12084984779358, 115.88670206069946, 119.76149439811707, 123.60137724876404, 127.2361650466919, 130.87455940246582, 134.56962776184082, 138.28977870941162, 142.07824754714966, 145.83161449432373, 149.5642693042755, 153.37626671791077, 157.20693564414978, 161.12232565879822, 164.98135995864868, 168.79501605033875, 172.52339792251587, 176.30035042762756, 180.01545572280884, 183.93308973312378, 187.81096076965332, 191.62698411941528, 195.353933095932, 199.1474609375, 202.83831214904785, 206.598286151886, 210.3819227218628, 214.15404796600342, 217.93197178840637, 221.64916515350342, 225.41056108474731, 229.1450662612915, 232.95372319221497, 236.74526500701904, 240.44323062896729, 244.30538296699524, 248.21819615364075, 252.17969417572021, 256.09300541877747, 259.8789031505585, 263.50546431541443, 267.22125577926636, 270.9964089393616, 274.76416659355164, 278.5283727645874, 282.39302492141724, 286.26187467575073, 289.99590396881104, 293.6959230899811, 297.45676732063293, 301.28539204597473, 305.12074279785156, 308.90117049217224, 312.71989917755127, 316.5329568386078, 320.2482953071594, 323.9800021648407, 327.6257085800171, 329.8101451396942]
[19.78, 29.71, 38.3, 44.16, 49.38, 51.74, 55.51, 57.58, 59.03, 60.7, 60.98, 62.54, 63.96, 63.94, 64.53, 64.54, 64.62, 65.47, 65.84, 66.1, 66.7, 67.21, 68.06, 68.56, 69.41, 69.45, 69.55, 69.92, 69.72, 69.83, 70.23, 71.26, 71.37, 71.04, 71.59, 71.69, 72.24, 72.86, 73.37, 73.31, 72.9, 72.82, 73.13, 73.71, 73.72, 73.66, 73.89, 74.04, 74.05, 74.49, 74.45, 75.02, 74.97, 74.19, 74.9, 74.94, 75.4, 75.85, 75.96, 76.19, 76.3, 76.45, 76.03, 75.72, 76.18, 76.01, 75.45, 76.17, 76.47, 75.94, 76.02, 76.21, 76.77, 76.63, 76.79, 76.99, 77.32, 76.96, 77.21, 77.52, 77.07, 77.17, 77.5, 77.26, 77.15, 76.95, 77.37, 77.67, 77.07, 76.98, 77.33, 77.25, 77.31, 77.65, 77.65, 77.56, 77.36, 77.87, 77.35, 77.85, 77.83]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: none, level_n_system: 0.2 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 14, noise    level: 0.4000 
   Client 12, noise    level: 0.4000 
   Client 13, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.946, Test loss: 1.839, Test accuracy: 30.11
Round   1, Train loss: 1.510, Test loss: 1.351, Test accuracy: 43.92
Round   2, Train loss: 1.342, Test loss: 1.231, Test accuracy: 48.58
Round   3, Train loss: 1.246, Test loss: 1.139, Test accuracy: 54.85
Round   4, Train loss: 1.180, Test loss: 1.075, Test accuracy: 57.26
Round   5, Train loss: 1.125, Test loss: 1.031, Test accuracy: 59.09
Round   6, Train loss: 1.087, Test loss: 0.992, Test accuracy: 60.33
Round   7, Train loss: 1.056, Test loss: 0.966, Test accuracy: 61.04
Round   8, Train loss: 1.030, Test loss: 0.951, Test accuracy: 62.37
Round   9, Train loss: 1.008, Test loss: 0.932, Test accuracy: 63.29
Round  10, Train loss: 0.988, Test loss: 0.911, Test accuracy: 63.89
Round  11, Train loss: 0.969, Test loss: 0.899, Test accuracy: 64.55
Round  12, Train loss: 0.952, Test loss: 0.885, Test accuracy: 65.02
Round  13, Train loss: 0.936, Test loss: 0.874, Test accuracy: 65.38
Round  14, Train loss: 0.920, Test loss: 0.858, Test accuracy: 65.87
Round  15, Train loss: 0.904, Test loss: 0.847, Test accuracy: 66.49
Round  16, Train loss: 0.888, Test loss: 0.842, Test accuracy: 66.88
Round  17, Train loss: 0.876, Test loss: 0.824, Test accuracy: 68.05
Round  18, Train loss: 0.864, Test loss: 0.812, Test accuracy: 68.38
Round  19, Train loss: 0.845, Test loss: 0.803, Test accuracy: 68.91
Round  20, Train loss: 0.794, Test loss: 0.804, Test accuracy: 68.70
Round  21, Train loss: 0.856, Test loss: 0.804, Test accuracy: 68.50
Round  22, Train loss: 0.896, Test loss: 0.800, Test accuracy: 68.73
Round  23, Train loss: 0.799, Test loss: 0.784, Test accuracy: 69.13
Round  24, Train loss: 0.856, Test loss: 0.783, Test accuracy: 69.91
Round  25, Train loss: 0.765, Test loss: 0.787, Test accuracy: 69.17
Round  26, Train loss: 0.771, Test loss: 0.771, Test accuracy: 70.03
Round  27, Train loss: 0.791, Test loss: 0.753, Test accuracy: 70.94
Round  28, Train loss: 0.782, Test loss: 0.750, Test accuracy: 71.10
Round  29, Train loss: 0.801, Test loss: 0.746, Test accuracy: 71.28
Round  30, Train loss: 0.776, Test loss: 0.733, Test accuracy: 71.18
Round  31, Train loss: 0.751, Test loss: 0.738, Test accuracy: 71.85
Round  32, Train loss: 0.726, Test loss: 0.732, Test accuracy: 72.20
Round  33, Train loss: 0.685, Test loss: 0.721, Test accuracy: 72.14
Round  34, Train loss: 0.676, Test loss: 0.727, Test accuracy: 71.72
Round  35, Train loss: 0.692, Test loss: 0.718, Test accuracy: 72.54
Round  36, Train loss: 0.679, Test loss: 0.709, Test accuracy: 72.49
Round  37, Train loss: 0.681, Test loss: 0.708, Test accuracy: 72.65
Round  38, Train loss: 0.703, Test loss: 0.710, Test accuracy: 73.23
Round  39, Train loss: 0.740, Test loss: 0.708, Test accuracy: 72.87
Round  40, Train loss: 0.640, Test loss: 0.686, Test accuracy: 74.18
Round  41, Train loss: 0.665, Test loss: 0.698, Test accuracy: 73.70
Round  42, Train loss: 0.590, Test loss: 0.675, Test accuracy: 74.55
Round  43, Train loss: 0.599, Test loss: 0.675, Test accuracy: 74.47
Round  44, Train loss: 0.555, Test loss: 0.669, Test accuracy: 74.76
Round  45, Train loss: 0.548, Test loss: 0.670, Test accuracy: 74.47
Round  46, Train loss: 0.637, Test loss: 0.660, Test accuracy: 75.47
Round  47, Train loss: 0.582, Test loss: 0.658, Test accuracy: 75.13
Round  48, Train loss: 0.650, Test loss: 0.660, Test accuracy: 75.69
Round  49, Train loss: 0.540, Test loss: 0.663, Test accuracy: 75.45
Round  50, Train loss: 0.592, Test loss: 0.655, Test accuracy: 75.54
Round  51, Train loss: 0.561, Test loss: 0.654, Test accuracy: 75.61
Round  52, Train loss: 0.611, Test loss: 0.652, Test accuracy: 75.28
Round  53, Train loss: 0.524, Test loss: 0.650, Test accuracy: 75.55
Round  54, Train loss: 0.592, Test loss: 0.642, Test accuracy: 76.08
Round  55, Train loss: 0.527, Test loss: 0.647, Test accuracy: 76.21
Round  56, Train loss: 0.544, Test loss: 0.643, Test accuracy: 75.57
Round  57, Train loss: 0.568, Test loss: 0.633, Test accuracy: 76.51
Round  58, Train loss: 0.532, Test loss: 0.630, Test accuracy: 76.82
Round  59, Train loss: 0.548, Test loss: 0.623, Test accuracy: 76.69
Round  60, Train loss: 0.589, Test loss: 0.625, Test accuracy: 77.21
Round  61, Train loss: 0.543, Test loss: 0.623, Test accuracy: 77.01
Round  62, Train loss: 0.542, Test loss: 0.624, Test accuracy: 76.90
Round  63, Train loss: 0.536, Test loss: 0.629, Test accuracy: 76.75
Round  64, Train loss: 0.509, Test loss: 0.629, Test accuracy: 76.47
Round  65, Train loss: 0.517, Test loss: 0.618, Test accuracy: 76.88
Round  66, Train loss: 0.468, Test loss: 0.632, Test accuracy: 76.31
Round  67, Train loss: 0.438, Test loss: 0.631, Test accuracy: 76.49
Round  68, Train loss: 0.482, Test loss: 0.621, Test accuracy: 76.89
Round  69, Train loss: 0.552, Test loss: 0.623, Test accuracy: 76.73
Round  70, Train loss: 0.436, Test loss: 0.617, Test accuracy: 77.09
Round  71, Train loss: 0.514, Test loss: 0.629, Test accuracy: 77.00
Round  72, Train loss: 0.489, Test loss: 0.628, Test accuracy: 77.10
Round  73, Train loss: 0.465, Test loss: 0.613, Test accuracy: 77.33
Round  74, Train loss: 0.499, Test loss: 0.612, Test accuracy: 77.46
Round  75, Train loss: 0.488, Test loss: 0.622, Test accuracy: 76.72
Round  76, Train loss: 0.406, Test loss: 0.622, Test accuracy: 77.16
Round  77, Train loss: 0.427, Test loss: 0.613, Test accuracy: 77.15
Round  78, Train loss: 0.500, Test loss: 0.608, Test accuracy: 77.46
Round  79, Train loss: 0.443, Test loss: 0.620, Test accuracy: 77.01
Round  80, Train loss: 0.362, Test loss: 0.606, Test accuracy: 77.22
Round  81, Train loss: 0.349, Test loss: 0.608, Test accuracy: 77.53
Round  82, Train loss: 0.334, Test loss: 0.606, Test accuracy: 77.60
Round  83, Train loss: 0.324, Test loss: 0.611, Test accuracy: 77.66
Round  84, Train loss: 0.322, Test loss: 0.616, Test accuracy: 77.65
Round  85, Train loss: 0.310, Test loss: 0.622, Test accuracy: 77.34
Round  86, Train loss: 0.309, Test loss: 0.620, Test accuracy: 77.41
Round  87, Train loss: 0.300, Test loss: 0.618, Test accuracy: 77.48
Round  88, Train loss: 0.293, Test loss: 0.624, Test accuracy: 77.76
Round  89, Train loss: 0.285, Test loss: 0.620, Test accuracy: 77.40
Round  90, Train loss: 0.277, Test loss: 0.631, Test accuracy: 77.31
Round  91, Train loss: 0.279, Test loss: 0.634, Test accuracy: 77.23
Round  92, Train loss: 0.271, Test loss: 0.633, Test accuracy: 77.51
Round  93, Train loss: 0.265, Test loss: 0.637, Test accuracy: 77.22
Round  94, Train loss: 0.259, Test loss: 0.647, Test accuracy: 76.96
Round  95, Train loss: 0.258, Test loss: 0.642, Test accuracy: 77.19
Round  96, Train loss: 0.253, Test loss: 0.651, Test accuracy: 77.03
Round  97, Train loss: 0.249, Test loss: 0.653, Test accuracy: 76.92
Round  98, Train loss: 0.245, Test loss: 0.644, Test accuracy: 77.17
Round  99, Train loss: 0.237, Test loss: 0.652, Test accuracy: 76.76
Final Round, Train loss: 0.174, Test loss: 0.655, Test accuracy: 77.09
Average accuracy final 10 rounds: 77.13000000000001
1688.585642337799
[1.821986436843872, 3.320565938949585, 4.777725458145142, 6.266067981719971, 7.782858371734619, 9.290632724761963, 10.765684604644775, 12.179011583328247, 13.595309972763062, 14.996551752090454, 16.514293670654297, 18.02502679824829, 19.615427017211914, 21.205582857131958, 22.80569338798523, 24.401124000549316, 25.97315263748169, 27.542840003967285, 29.05794382095337, 30.517894744873047, 31.970991611480713, 33.38380837440491, 34.788387060165405, 36.22212243080139, 37.640434980392456, 39.047757625579834, 40.47388243675232, 41.871535539627075, 43.29301357269287, 44.69954323768616, 46.11265778541565, 47.50486087799072, 48.91003704071045, 50.3073296546936, 51.75128412246704, 53.15048813819885, 54.60220718383789, 56.000370025634766, 57.40319466590881, 58.799768686294556, 60.21768808364868, 61.64488124847412, 63.115960359573364, 64.61115431785583, 66.04928994178772, 67.44209909439087, 68.88854932785034, 70.25725769996643, 71.6938955783844, 73.10853242874146, 74.5524251461029, 75.97432231903076, 77.36913299560547, 78.81061816215515, 80.22283482551575, 81.63667869567871, 83.06973576545715, 84.51016139984131, 85.94560933113098, 87.35308861732483, 88.77614831924438, 90.18949341773987, 91.60511088371277, 93.02770209312439, 94.46407985687256, 95.88357305526733, 97.31220316886902, 98.69980072975159, 100.11104607582092, 101.55321335792542, 102.96139597892761, 104.41252875328064, 105.7888536453247, 107.23693609237671, 108.68429064750671, 110.10006070137024, 111.56281399726868, 112.95050597190857, 114.39612603187561, 115.83355569839478, 117.29140257835388, 118.7182834148407, 120.17556810379028, 121.64766454696655, 123.09231448173523, 124.55036854743958, 125.98346781730652, 127.42151188850403, 128.88322949409485, 130.31398701667786, 131.76165056228638, 133.18959641456604, 134.64889574050903, 136.0722315311432, 137.53809094429016, 138.96955800056458, 140.4107003211975, 141.8491654396057, 143.27617692947388, 144.72844672203064, 146.98080253601074]
[30.11, 43.92, 48.58, 54.85, 57.26, 59.09, 60.33, 61.04, 62.37, 63.29, 63.89, 64.55, 65.02, 65.38, 65.87, 66.49, 66.88, 68.05, 68.38, 68.91, 68.7, 68.5, 68.73, 69.13, 69.91, 69.17, 70.03, 70.94, 71.1, 71.28, 71.18, 71.85, 72.2, 72.14, 71.72, 72.54, 72.49, 72.65, 73.23, 72.87, 74.18, 73.7, 74.55, 74.47, 74.76, 74.47, 75.47, 75.13, 75.69, 75.45, 75.54, 75.61, 75.28, 75.55, 76.08, 76.21, 75.57, 76.51, 76.82, 76.69, 77.21, 77.01, 76.9, 76.75, 76.47, 76.88, 76.31, 76.49, 76.89, 76.73, 77.09, 77.0, 77.1, 77.33, 77.46, 76.72, 77.16, 77.15, 77.46, 77.01, 77.22, 77.53, 77.6, 77.66, 77.65, 77.34, 77.41, 77.48, 77.76, 77.4, 77.31, 77.23, 77.51, 77.22, 76.96, 77.19, 77.03, 76.92, 77.17, 76.76, 77.09]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.2 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 3, noise    level: 0.4000 
   Client 16, noise    level: 0.4000 
   Client 12, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.973, Test loss: 1.906, Test accuracy: 32.21
Round   1, Train loss: 1.538, Test loss: 1.383, Test accuracy: 41.89
Round   2, Train loss: 1.362, Test loss: 1.255, Test accuracy: 48.50
Round   3, Train loss: 1.270, Test loss: 1.160, Test accuracy: 53.07
Round   4, Train loss: 1.198, Test loss: 1.093, Test accuracy: 56.95
Round   5, Train loss: 1.145, Test loss: 1.042, Test accuracy: 59.07
Round   6, Train loss: 1.104, Test loss: 1.011, Test accuracy: 59.75
Round   7, Train loss: 1.074, Test loss: 0.973, Test accuracy: 61.27
Round   8, Train loss: 1.042, Test loss: 0.946, Test accuracy: 62.68
Round   9, Train loss: 1.021, Test loss: 0.935, Test accuracy: 63.54
Round  10, Train loss: 1.004, Test loss: 0.910, Test accuracy: 64.55
Round  11, Train loss: 0.977, Test loss: 0.891, Test accuracy: 65.19
Round  12, Train loss: 0.959, Test loss: 0.877, Test accuracy: 65.97
Round  13, Train loss: 0.940, Test loss: 0.861, Test accuracy: 66.71
Round  14, Train loss: 0.922, Test loss: 0.844, Test accuracy: 67.15
Round  15, Train loss: 0.906, Test loss: 0.836, Test accuracy: 67.44
Round  16, Train loss: 0.892, Test loss: 0.823, Test accuracy: 68.21
Round  17, Train loss: 0.877, Test loss: 0.811, Test accuracy: 68.70
Round  18, Train loss: 0.857, Test loss: 0.800, Test accuracy: 69.37
Round  19, Train loss: 0.847, Test loss: 0.795, Test accuracy: 69.39
Round  20, Train loss: 0.803, Test loss: 0.807, Test accuracy: 69.42
Round  21, Train loss: 0.862, Test loss: 0.797, Test accuracy: 69.45
Round  22, Train loss: 0.859, Test loss: 0.789, Test accuracy: 69.57
Round  23, Train loss: 0.783, Test loss: 0.790, Test accuracy: 69.45
Round  24, Train loss: 0.844, Test loss: 0.769, Test accuracy: 70.56
Round  25, Train loss: 0.756, Test loss: 0.756, Test accuracy: 70.90
Round  26, Train loss: 0.783, Test loss: 0.755, Test accuracy: 71.27
Round  27, Train loss: 0.745, Test loss: 0.740, Test accuracy: 71.49
Round  28, Train loss: 0.837, Test loss: 0.741, Test accuracy: 71.58
Round  29, Train loss: 0.759, Test loss: 0.736, Test accuracy: 72.02
Round  30, Train loss: 0.801, Test loss: 0.741, Test accuracy: 71.35
Round  31, Train loss: 0.777, Test loss: 0.728, Test accuracy: 71.98
Round  32, Train loss: 0.724, Test loss: 0.739, Test accuracy: 71.55
Round  33, Train loss: 0.702, Test loss: 0.724, Test accuracy: 71.97
Round  34, Train loss: 0.690, Test loss: 0.717, Test accuracy: 72.67
Round  35, Train loss: 0.674, Test loss: 0.706, Test accuracy: 73.17
Round  36, Train loss: 0.684, Test loss: 0.701, Test accuracy: 73.45
Round  37, Train loss: 0.730, Test loss: 0.692, Test accuracy: 73.70
Round  38, Train loss: 0.671, Test loss: 0.687, Test accuracy: 74.01
Round  39, Train loss: 0.707, Test loss: 0.688, Test accuracy: 73.90
Round  40, Train loss: 0.634, Test loss: 0.686, Test accuracy: 74.07
Round  41, Train loss: 0.662, Test loss: 0.683, Test accuracy: 74.44
Round  42, Train loss: 0.587, Test loss: 0.668, Test accuracy: 74.71
Round  43, Train loss: 0.603, Test loss: 0.665, Test accuracy: 74.81
Round  44, Train loss: 0.615, Test loss: 0.661, Test accuracy: 74.61
Round  45, Train loss: 0.575, Test loss: 0.654, Test accuracy: 75.11
Round  46, Train loss: 0.618, Test loss: 0.663, Test accuracy: 74.86
Round  47, Train loss: 0.567, Test loss: 0.655, Test accuracy: 75.31
Round  48, Train loss: 0.660, Test loss: 0.653, Test accuracy: 75.44
Round  49, Train loss: 0.524, Test loss: 0.644, Test accuracy: 75.45
Round  50, Train loss: 0.597, Test loss: 0.646, Test accuracy: 75.82
Round  51, Train loss: 0.541, Test loss: 0.647, Test accuracy: 75.96
Round  52, Train loss: 0.615, Test loss: 0.648, Test accuracy: 76.04
Round  53, Train loss: 0.516, Test loss: 0.637, Test accuracy: 76.04
Round  54, Train loss: 0.573, Test loss: 0.636, Test accuracy: 76.48
Round  55, Train loss: 0.517, Test loss: 0.640, Test accuracy: 76.37
Round  56, Train loss: 0.536, Test loss: 0.631, Test accuracy: 76.47
Round  57, Train loss: 0.548, Test loss: 0.628, Test accuracy: 76.68
Round  58, Train loss: 0.524, Test loss: 0.634, Test accuracy: 76.44
Round  59, Train loss: 0.576, Test loss: 0.630, Test accuracy: 76.50
Round  60, Train loss: 0.589, Test loss: 0.631, Test accuracy: 76.52
Round  61, Train loss: 0.505, Test loss: 0.624, Test accuracy: 76.94
Round  62, Train loss: 0.526, Test loss: 0.630, Test accuracy: 76.53
Round  63, Train loss: 0.499, Test loss: 0.621, Test accuracy: 76.73
Round  64, Train loss: 0.556, Test loss: 0.623, Test accuracy: 77.12
Round  65, Train loss: 0.503, Test loss: 0.623, Test accuracy: 76.89
Round  66, Train loss: 0.467, Test loss: 0.631, Test accuracy: 76.57
Round  67, Train loss: 0.447, Test loss: 0.622, Test accuracy: 77.08
Round  68, Train loss: 0.473, Test loss: 0.614, Test accuracy: 77.27
Round  69, Train loss: 0.509, Test loss: 0.609, Test accuracy: 77.24
Round  70, Train loss: 0.478, Test loss: 0.607, Test accuracy: 77.41
Round  71, Train loss: 0.504, Test loss: 0.610, Test accuracy: 77.43
Round  72, Train loss: 0.482, Test loss: 0.615, Test accuracy: 77.33
Round  73, Train loss: 0.480, Test loss: 0.608, Test accuracy: 77.69
Round  74, Train loss: 0.488, Test loss: 0.602, Test accuracy: 77.42
Round  75, Train loss: 0.451, Test loss: 0.602, Test accuracy: 77.29
Round  76, Train loss: 0.371, Test loss: 0.600, Test accuracy: 77.83
Round  77, Train loss: 0.435, Test loss: 0.619, Test accuracy: 77.01
Round  78, Train loss: 0.451, Test loss: 0.622, Test accuracy: 77.12
Round  79, Train loss: 0.424, Test loss: 0.615, Test accuracy: 77.41
Round  80, Train loss: 0.361, Test loss: 0.597, Test accuracy: 78.20
Round  81, Train loss: 0.346, Test loss: 0.601, Test accuracy: 78.04
Round  82, Train loss: 0.335, Test loss: 0.608, Test accuracy: 77.87
Round  83, Train loss: 0.317, Test loss: 0.606, Test accuracy: 77.97
Round  84, Train loss: 0.313, Test loss: 0.608, Test accuracy: 78.17
Round  85, Train loss: 0.305, Test loss: 0.618, Test accuracy: 77.58
Round  86, Train loss: 0.301, Test loss: 0.618, Test accuracy: 77.57
Round  87, Train loss: 0.292, Test loss: 0.609, Test accuracy: 77.96
Round  88, Train loss: 0.291, Test loss: 0.615, Test accuracy: 77.86
Round  89, Train loss: 0.280, Test loss: 0.620, Test accuracy: 77.87
Round  90, Train loss: 0.273, Test loss: 0.625, Test accuracy: 78.04
Round  91, Train loss: 0.271, Test loss: 0.624, Test accuracy: 78.00
Round  92, Train loss: 0.268, Test loss: 0.627, Test accuracy: 77.43
Round  93, Train loss: 0.257, Test loss: 0.631, Test accuracy: 77.59
Round  94, Train loss: 0.250, Test loss: 0.628, Test accuracy: 77.45
Round  95, Train loss: 0.251, Test loss: 0.635, Test accuracy: 77.42
Round  96, Train loss: 0.252, Test loss: 0.638, Test accuracy: 77.48
Round  97, Train loss: 0.238, Test loss: 0.638, Test accuracy: 77.43
Round  98, Train loss: 0.245, Test loss: 0.643, Test accuracy: 77.20
Round  99, Train loss: 0.229, Test loss: 0.641, Test accuracy: 77.38
Final Round, Train loss: 0.172, Test loss: 0.645, Test accuracy: 77.40
Average accuracy final 10 rounds: 77.542
2885.3165652751923
[1.8181498050689697, 3.3177459239959717, 4.827845811843872, 6.3625593185424805, 7.858988046646118, 9.353892087936401, 10.89151668548584, 12.388965845108032, 13.89008092880249, 15.376487016677856, 16.919962406158447, 18.270662546157837, 19.753374338150024, 21.251283168792725, 22.74071502685547, 24.226691246032715, 25.705490112304688, 27.183297634124756, 28.660399436950684, 30.133965492248535, 31.607057332992554, 35.41831398010254, 39.2825562953949, 43.04331016540527, 46.559895753860474, 50.004767179489136, 53.523908853530884, 57.30906558036804, 61.141255617141724, 65.0246467590332, 68.87983989715576, 72.70372748374939, 76.39551639556885, 79.85871648788452, 83.59096622467041, 87.21177768707275, 91.08354187011719, 94.73859596252441, 98.4030065536499, 102.02859950065613, 105.51117825508118, 109.32570290565491, 113.16433453559875, 116.99911093711853, 120.67378401756287, 124.25344109535217, 127.91510939598083, 131.51856589317322, 135.21891736984253, 138.8924596309662, 142.3438994884491, 146.03164219856262, 149.58856463432312, 153.176992893219, 156.92434120178223, 160.79529190063477, 164.42575812339783, 168.08219575881958, 171.7997326850891, 175.4479010105133, 179.2984528541565, 183.16984391212463, 186.97676825523376, 190.79764127731323, 194.573490858078, 198.526597738266, 202.39880299568176, 206.12723112106323, 210.03484344482422, 213.84529638290405, 217.59251379966736, 221.4229712486267, 225.36300206184387, 229.07367610931396, 232.78392839431763, 236.57102870941162, 240.46290946006775, 244.43062257766724, 248.42287182807922, 252.155601978302, 256.1016426086426, 260.1415433883667, 264.1555452346802, 267.84695768356323, 271.5309009552002, 275.2642488479614, 278.8570122718811, 282.49828004837036, 286.17398953437805, 289.7173843383789, 293.3183858394623, 296.9418566226959, 300.57257652282715, 304.382803440094, 307.9811589717865, 311.63368010520935, 315.30960988998413, 318.8453230857849, 322.52622056007385, 326.1894507408142, 328.58533358573914]
[32.21, 41.89, 48.5, 53.07, 56.95, 59.07, 59.75, 61.27, 62.68, 63.54, 64.55, 65.19, 65.97, 66.71, 67.15, 67.44, 68.21, 68.7, 69.37, 69.39, 69.42, 69.45, 69.57, 69.45, 70.56, 70.9, 71.27, 71.49, 71.58, 72.02, 71.35, 71.98, 71.55, 71.97, 72.67, 73.17, 73.45, 73.7, 74.01, 73.9, 74.07, 74.44, 74.71, 74.81, 74.61, 75.11, 74.86, 75.31, 75.44, 75.45, 75.82, 75.96, 76.04, 76.04, 76.48, 76.37, 76.47, 76.68, 76.44, 76.5, 76.52, 76.94, 76.53, 76.73, 77.12, 76.89, 76.57, 77.08, 77.27, 77.24, 77.41, 77.43, 77.33, 77.69, 77.42, 77.29, 77.83, 77.01, 77.12, 77.41, 78.2, 78.04, 77.87, 77.97, 78.17, 77.58, 77.57, 77.96, 77.86, 77.87, 78.04, 78.0, 77.43, 77.59, 77.45, 77.42, 77.48, 77.43, 77.2, 77.38, 77.4]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.2 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 8, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 19, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.570, Test loss: 1.931, Test accuracy: 25.35
Round   0, Global train loss: 1.570, Global test loss: 2.169, Global test accuracy: 19.55
Round   1, Train loss: 1.502, Test loss: 1.792, Test accuracy: 32.26
Round   1, Global train loss: 1.502, Global test loss: 2.202, Global test accuracy: 25.26
Round   2, Train loss: 1.493, Test loss: 1.634, Test accuracy: 37.45
Round   2, Global train loss: 1.493, Global test loss: 2.202, Global test accuracy: 26.53
Round   3, Train loss: 1.440, Test loss: 1.519, Test accuracy: 39.93
Round   3, Global train loss: 1.440, Global test loss: 2.229, Global test accuracy: 25.71
Round   4, Train loss: 1.247, Test loss: 1.383, Test accuracy: 43.62
Round   4, Global train loss: 1.247, Global test loss: 2.002, Global test accuracy: 29.27
Round   5, Train loss: 1.215, Test loss: 1.343, Test accuracy: 44.72
Round   5, Global train loss: 1.215, Global test loss: 1.973, Global test accuracy: 25.73
Round   6, Train loss: 1.194, Test loss: 1.326, Test accuracy: 45.85
Round   6, Global train loss: 1.194, Global test loss: 2.029, Global test accuracy: 27.56
Round   7, Train loss: 1.113, Test loss: 1.307, Test accuracy: 47.00
Round   7, Global train loss: 1.113, Global test loss: 1.948, Global test accuracy: 24.83
Round   8, Train loss: 1.234, Test loss: 1.309, Test accuracy: 46.79
Round   8, Global train loss: 1.234, Global test loss: 2.054, Global test accuracy: 23.88
Round   9, Train loss: 1.364, Test loss: 1.289, Test accuracy: 47.52
Round   9, Global train loss: 1.364, Global test loss: 2.299, Global test accuracy: 28.46
Round  10, Train loss: 1.254, Test loss: 1.262, Test accuracy: 47.71
Round  10, Global train loss: 1.254, Global test loss: 2.228, Global test accuracy: 27.25
Round  11, Train loss: 1.346, Test loss: 1.246, Test accuracy: 47.88
Round  11, Global train loss: 1.346, Global test loss: 2.101, Global test accuracy: 23.91
Round  12, Train loss: 1.212, Test loss: 1.188, Test accuracy: 51.02
Round  12, Global train loss: 1.212, Global test loss: 2.276, Global test accuracy: 17.98
Round  13, Train loss: 1.072, Test loss: 1.183, Test accuracy: 51.20
Round  13, Global train loss: 1.072, Global test loss: 2.002, Global test accuracy: 26.81
Round  14, Train loss: 0.975, Test loss: 1.169, Test accuracy: 51.73
Round  14, Global train loss: 0.975, Global test loss: 2.118, Global test accuracy: 28.70
Round  15, Train loss: 0.952, Test loss: 1.168, Test accuracy: 51.69
Round  15, Global train loss: 0.952, Global test loss: 2.132, Global test accuracy: 24.15
Round  16, Train loss: 0.945, Test loss: 1.154, Test accuracy: 52.48
Round  16, Global train loss: 0.945, Global test loss: 1.926, Global test accuracy: 28.37
Round  17, Train loss: 0.990, Test loss: 1.144, Test accuracy: 53.03
Round  17, Global train loss: 0.990, Global test loss: 2.126, Global test accuracy: 25.24
Round  18, Train loss: 1.021, Test loss: 1.149, Test accuracy: 52.81
Round  18, Global train loss: 1.021, Global test loss: 1.965, Global test accuracy: 26.18
Round  19, Train loss: 1.163, Test loss: 1.156, Test accuracy: 53.01
Round  19, Global train loss: 1.163, Global test loss: 2.146, Global test accuracy: 28.80
Round  20, Train loss: 0.900, Test loss: 1.165, Test accuracy: 53.14
Round  20, Global train loss: 0.900, Global test loss: 2.011, Global test accuracy: 27.83
Round  21, Train loss: 0.825, Test loss: 1.162, Test accuracy: 53.61
Round  21, Global train loss: 0.825, Global test loss: 1.909, Global test accuracy: 29.17
Round  22, Train loss: 0.933, Test loss: 1.166, Test accuracy: 53.82
Round  22, Global train loss: 0.933, Global test loss: 2.003, Global test accuracy: 30.78
Round  23, Train loss: 0.879, Test loss: 1.146, Test accuracy: 54.51
Round  23, Global train loss: 0.879, Global test loss: 2.058, Global test accuracy: 30.06
Round  24, Train loss: 0.877, Test loss: 1.153, Test accuracy: 54.86
Round  24, Global train loss: 0.877, Global test loss: 1.912, Global test accuracy: 27.76
Round  25, Train loss: 1.027, Test loss: 1.169, Test accuracy: 54.63
Round  25, Global train loss: 1.027, Global test loss: 2.249, Global test accuracy: 24.40
Round  26, Train loss: 0.828, Test loss: 1.225, Test accuracy: 54.16
Round  26, Global train loss: 0.828, Global test loss: 2.099, Global test accuracy: 25.08
Round  27, Train loss: 0.692, Test loss: 1.213, Test accuracy: 54.78
Round  27, Global train loss: 0.692, Global test loss: 1.933, Global test accuracy: 32.29
Round  28, Train loss: 0.871, Test loss: 1.204, Test accuracy: 54.68
Round  28, Global train loss: 0.871, Global test loss: 2.053, Global test accuracy: 32.58
Round  29, Train loss: 0.791, Test loss: 1.192, Test accuracy: 54.91
Round  29, Global train loss: 0.791, Global test loss: 2.002, Global test accuracy: 26.51
Round  30, Train loss: 0.755, Test loss: 1.226, Test accuracy: 54.25
Round  30, Global train loss: 0.755, Global test loss: 1.933, Global test accuracy: 27.71
Round  31, Train loss: 0.705, Test loss: 1.226, Test accuracy: 54.78
Round  31, Global train loss: 0.705, Global test loss: 1.935, Global test accuracy: 31.09
Round  32, Train loss: 0.748, Test loss: 1.242, Test accuracy: 54.47
Round  32, Global train loss: 0.748, Global test loss: 2.042, Global test accuracy: 27.96
Round  33, Train loss: 0.631, Test loss: 1.263, Test accuracy: 54.22
Round  33, Global train loss: 0.631, Global test loss: 1.932, Global test accuracy: 33.87
Round  34, Train loss: 0.783, Test loss: 1.259, Test accuracy: 54.72
Round  34, Global train loss: 0.783, Global test loss: 1.948, Global test accuracy: 30.57
Round  35, Train loss: 0.664, Test loss: 1.259, Test accuracy: 54.99
Round  35, Global train loss: 0.664, Global test loss: 2.020, Global test accuracy: 32.60
Round  36, Train loss: 0.784, Test loss: 1.273, Test accuracy: 55.24
Round  36, Global train loss: 0.784, Global test loss: 1.923, Global test accuracy: 35.54
Round  37, Train loss: 0.789, Test loss: 1.300, Test accuracy: 54.72
Round  37, Global train loss: 0.789, Global test loss: 1.982, Global test accuracy: 33.21
Round  38, Train loss: 0.528, Test loss: 1.316, Test accuracy: 54.43
Round  38, Global train loss: 0.528, Global test loss: 1.902, Global test accuracy: 33.75
Round  39, Train loss: 0.822, Test loss: 1.312, Test accuracy: 55.07
Round  39, Global train loss: 0.822, Global test loss: 2.096, Global test accuracy: 30.77
Round  40, Train loss: 0.699, Test loss: 1.353, Test accuracy: 54.88
Round  40, Global train loss: 0.699, Global test loss: 1.980, Global test accuracy: 29.80
Round  41, Train loss: 0.507, Test loss: 1.365, Test accuracy: 55.31
Round  41, Global train loss: 0.507, Global test loss: 1.972, Global test accuracy: 31.81
Round  42, Train loss: 0.466, Test loss: 1.393, Test accuracy: 55.21
Round  42, Global train loss: 0.466, Global test loss: 1.794, Global test accuracy: 37.62
Round  43, Train loss: 0.571, Test loss: 1.417, Test accuracy: 54.86
Round  43, Global train loss: 0.571, Global test loss: 1.953, Global test accuracy: 30.32
Round  44, Train loss: 0.591, Test loss: 1.434, Test accuracy: 54.49
Round  44, Global train loss: 0.591, Global test loss: 1.983, Global test accuracy: 27.65
Round  45, Train loss: 0.492, Test loss: 1.441, Test accuracy: 54.98
Round  45, Global train loss: 0.492, Global test loss: 2.001, Global test accuracy: 36.37
Round  46, Train loss: 0.610, Test loss: 1.473, Test accuracy: 55.11
Round  46, Global train loss: 0.610, Global test loss: 1.924, Global test accuracy: 30.68
Round  47, Train loss: 0.642, Test loss: 1.497, Test accuracy: 55.00
Round  47, Global train loss: 0.642, Global test loss: 1.906, Global test accuracy: 34.01
Round  48, Train loss: 0.470, Test loss: 1.504, Test accuracy: 55.03
Round  48, Global train loss: 0.470, Global test loss: 2.184, Global test accuracy: 27.55
Round  49, Train loss: 0.493, Test loss: 1.513, Test accuracy: 55.54
Round  49, Global train loss: 0.493, Global test loss: 2.030, Global test accuracy: 27.58
Round  50, Train loss: 0.387, Test loss: 1.537, Test accuracy: 55.47
Round  50, Global train loss: 0.387, Global test loss: 1.784, Global test accuracy: 37.28
Round  51, Train loss: 0.308, Test loss: 1.604, Test accuracy: 55.21
Round  51, Global train loss: 0.308, Global test loss: 1.929, Global test accuracy: 31.45
Round  52, Train loss: 0.415, Test loss: 1.619, Test accuracy: 55.11
Round  52, Global train loss: 0.415, Global test loss: 2.060, Global test accuracy: 27.33
Round  53, Train loss: 0.619, Test loss: 1.602, Test accuracy: 55.58
Round  53, Global train loss: 0.619, Global test loss: 2.133, Global test accuracy: 27.75
Round  54, Train loss: 0.508, Test loss: 1.589, Test accuracy: 55.31
Round  54, Global train loss: 0.508, Global test loss: 2.013, Global test accuracy: 22.84
Round  55, Train loss: 0.404, Test loss: 1.605, Test accuracy: 55.23
Round  55, Global train loss: 0.404, Global test loss: 1.964, Global test accuracy: 30.56
Round  56, Train loss: 0.446, Test loss: 1.627, Test accuracy: 54.95
Round  56, Global train loss: 0.446, Global test loss: 1.875, Global test accuracy: 34.39
Round  57, Train loss: 0.582, Test loss: 1.688, Test accuracy: 55.16
Round  57, Global train loss: 0.582, Global test loss: 2.094, Global test accuracy: 29.09
Round  58, Train loss: 0.402, Test loss: 1.717, Test accuracy: 55.58
Round  58, Global train loss: 0.402, Global test loss: 1.918, Global test accuracy: 32.81
Round  59, Train loss: 0.313, Test loss: 1.777, Test accuracy: 54.77
Round  59, Global train loss: 0.313, Global test loss: 1.995, Global test accuracy: 27.95
Round  60, Train loss: 0.268, Test loss: 1.757, Test accuracy: 55.04
Round  60, Global train loss: 0.268, Global test loss: 1.864, Global test accuracy: 39.65
Round  61, Train loss: 0.229, Test loss: 1.747, Test accuracy: 55.59
Round  61, Global train loss: 0.229, Global test loss: 1.960, Global test accuracy: 35.75
Round  62, Train loss: 0.258, Test loss: 1.797, Test accuracy: 55.26
Round  62, Global train loss: 0.258, Global test loss: 1.881, Global test accuracy: 31.78
Round  63, Train loss: 0.314, Test loss: 1.808, Test accuracy: 55.52
Round  63, Global train loss: 0.314, Global test loss: 1.946, Global test accuracy: 29.93
Round  64, Train loss: 0.334, Test loss: 1.850, Test accuracy: 55.61
Round  64, Global train loss: 0.334, Global test loss: 1.970, Global test accuracy: 29.61
Round  65, Train loss: 0.428, Test loss: 1.886, Test accuracy: 55.16
Round  65, Global train loss: 0.428, Global test loss: 1.963, Global test accuracy: 27.94
Round  66, Train loss: 0.188, Test loss: 1.913, Test accuracy: 55.04
Round  66, Global train loss: 0.188, Global test loss: 2.009, Global test accuracy: 31.75
Round  67, Train loss: 0.241, Test loss: 1.883, Test accuracy: 55.22
Round  67, Global train loss: 0.241, Global test loss: 1.871, Global test accuracy: 32.64
Round  68, Train loss: 0.331, Test loss: 1.958, Test accuracy: 55.16
Round  68, Global train loss: 0.331, Global test loss: 1.989, Global test accuracy: 30.92
Round  69, Train loss: 0.358, Test loss: 1.971, Test accuracy: 54.83
Round  69, Global train loss: 0.358, Global test loss: 2.115, Global test accuracy: 27.54
Round  70, Train loss: 0.292, Test loss: 2.008, Test accuracy: 54.60
Round  70, Global train loss: 0.292, Global test loss: 2.019, Global test accuracy: 26.31
Round  71, Train loss: 0.211, Test loss: 1.997, Test accuracy: 54.59
Round  71, Global train loss: 0.211, Global test loss: 1.919, Global test accuracy: 31.68
Round  72, Train loss: 0.255, Test loss: 2.031, Test accuracy: 54.67
Round  72, Global train loss: 0.255, Global test loss: 1.931, Global test accuracy: 31.56
Round  73, Train loss: 0.157, Test loss: 2.053, Test accuracy: 54.89
Round  73, Global train loss: 0.157, Global test loss: 1.893, Global test accuracy: 33.00
Round  74, Train loss: 0.239, Test loss: 2.099, Test accuracy: 54.80
Round  74, Global train loss: 0.239, Global test loss: 1.868, Global test accuracy: 33.80
Round  75, Train loss: 0.265, Test loss: 2.123, Test accuracy: 55.07
Round  75, Global train loss: 0.265, Global test loss: 2.042, Global test accuracy: 24.05
Round  76, Train loss: 0.250, Test loss: 2.146, Test accuracy: 54.78
Round  76, Global train loss: 0.250, Global test loss: 1.983, Global test accuracy: 29.84
Round  77, Train loss: 0.288, Test loss: 2.128, Test accuracy: 55.09
Round  77, Global train loss: 0.288, Global test loss: 2.041, Global test accuracy: 24.64
Round  78, Train loss: 0.246, Test loss: 2.159, Test accuracy: 54.98
Round  78, Global train loss: 0.246, Global test loss: 1.901, Global test accuracy: 32.97
Round  79, Train loss: 0.286, Test loss: 2.198, Test accuracy: 55.09
Round  79, Global train loss: 0.286, Global test loss: 2.150, Global test accuracy: 33.70
Round  80, Train loss: 0.256, Test loss: 2.154, Test accuracy: 55.35
Round  80, Global train loss: 0.256, Global test loss: 1.996, Global test accuracy: 25.33
Round  81, Train loss: 0.224, Test loss: 2.223, Test accuracy: 55.25
Round  81, Global train loss: 0.224, Global test loss: 1.952, Global test accuracy: 30.76
Round  82, Train loss: 0.201, Test loss: 2.223, Test accuracy: 55.56
Round  82, Global train loss: 0.201, Global test loss: 1.980, Global test accuracy: 33.36
Round  83, Train loss: 0.257, Test loss: 2.272, Test accuracy: 55.16
Round  83, Global train loss: 0.257, Global test loss: 2.062, Global test accuracy: 26.74
Round  84, Train loss: 0.218, Test loss: 2.329, Test accuracy: 55.11
Round  84, Global train loss: 0.218, Global test loss: 2.016, Global test accuracy: 23.14
Round  85, Train loss: 0.129, Test loss: 2.314, Test accuracy: 54.95
Round  85, Global train loss: 0.129, Global test loss: 1.882, Global test accuracy: 34.40
Round  86, Train loss: 0.132, Test loss: 2.292, Test accuracy: 55.14
Round  86, Global train loss: 0.132, Global test loss: 1.957, Global test accuracy: 32.24
Round  87, Train loss: 0.134, Test loss: 2.288, Test accuracy: 55.73
Round  87, Global train loss: 0.134, Global test loss: 2.219, Global test accuracy: 30.10
Round  88, Train loss: 0.215, Test loss: 2.262, Test accuracy: 55.99
Round  88, Global train loss: 0.215, Global test loss: 2.072, Global test accuracy: 30.53
Round  89, Train loss: 0.212, Test loss: 2.349, Test accuracy: 55.75
Round  89, Global train loss: 0.212, Global test loss: 2.114, Global test accuracy: 29.41
Round  90, Train loss: 0.124, Test loss: 2.332, Test accuracy: 55.94
Round  90, Global train loss: 0.124, Global test loss: 2.010, Global test accuracy: 30.37
Round  91, Train loss: 0.172, Test loss: 2.366, Test accuracy: 56.27
Round  91, Global train loss: 0.172, Global test loss: 1.863, Global test accuracy: 31.46
Round  92, Train loss: 0.184, Test loss: 2.399, Test accuracy: 56.29
Round  92, Global train loss: 0.184, Global test loss: 2.019, Global test accuracy: 29.87
Round  93, Train loss: 0.109, Test loss: 2.401, Test accuracy: 55.99
Round  93, Global train loss: 0.109, Global test loss: 2.113, Global test accuracy: 31.82
Round  94, Train loss: 0.139, Test loss: 2.401, Test accuracy: 56.30
Round  94, Global train loss: 0.139, Global test loss: 1.773, Global test accuracy: 36.34
Round  95, Train loss: 0.166, Test loss: 2.422, Test accuracy: 55.96
Round  95, Global train loss: 0.166, Global test loss: 2.006, Global test accuracy: 29.13
Round  96, Train loss: 0.184, Test loss: 2.391, Test accuracy: 56.16
Round  96, Global train loss: 0.184, Global test loss: 2.065, Global test accuracy: 28.23
Round  97, Train loss: 0.169, Test loss: 2.410, Test accuracy: 55.90
Round  97, Global train loss: 0.169, Global test loss: 2.011, Global test accuracy: 27.54
Round  98, Train loss: 0.188, Test loss: 2.442, Test accuracy: 55.76
Round  98, Global train loss: 0.188, Global test loss: 2.064, Global test accuracy: 31.78
Round  99, Train loss: 0.133, Test loss: 2.502, Test accuracy: 56.10
Round  99, Global train loss: 0.133, Global test loss: 2.231, Global test accuracy: 26.45
Final Round, Train loss: 0.146, Test loss: 2.625, Test accuracy: 55.66
Final Round, Global train loss: 0.146, Global test loss: 2.231, Global test accuracy: 26.45
Average accuracy final 10 rounds: 56.067 

Average global accuracy final 10 rounds: 30.299000000000003 

1716.1286599636078
[1.5957832336425781, 3.1915664672851562, 4.483556509017944, 5.775546550750732, 6.962335586547852, 8.14912462234497, 9.358082056045532, 10.567039489746094, 11.88367509841919, 13.200310707092285, 14.326141357421875, 15.451972007751465, 16.675246477127075, 17.898520946502686, 19.131288290023804, 20.364055633544922, 21.6535861492157, 22.943116664886475, 24.140408039093018, 25.33769941329956, 26.620072603225708, 27.902445793151855, 29.210902452468872, 30.51935911178589, 31.833972215652466, 33.14858531951904, 34.45399832725525, 35.759411334991455, 37.04541540145874, 38.331419467926025, 39.59588146209717, 40.86034345626831, 42.10528349876404, 43.350223541259766, 44.55449390411377, 45.75876426696777, 47.0259153842926, 48.29306650161743, 49.49351382255554, 50.69396114349365, 51.82278037071228, 52.95159959793091, 54.24170160293579, 55.531803607940674, 56.72592830657959, 57.920053005218506, 59.17656660079956, 60.433080196380615, 61.623286485672, 62.81349277496338, 64.06103944778442, 65.30858612060547, 66.51441407203674, 67.72024202346802, 68.96936631202698, 70.21849060058594, 71.41348671913147, 72.608482837677, 73.85508060455322, 75.10167837142944, 76.32596015930176, 77.55024194717407, 78.8225748538971, 80.09490776062012, 81.41684007644653, 82.73877239227295, 83.97886991500854, 85.21896743774414, 86.4939067363739, 87.76884603500366, 89.00320506095886, 90.23756408691406, 91.5057258605957, 92.77388763427734, 93.99038219451904, 95.20687675476074, 96.43652653694153, 97.66617631912231, 98.89055728912354, 100.11493825912476, 101.26624274253845, 102.41754722595215, 103.58799576759338, 104.75844430923462, 105.97213411331177, 107.18582391738892, 108.45384669303894, 109.72186946868896, 110.96611166000366, 112.21035385131836, 113.38773941993713, 114.56512498855591, 115.77618551254272, 116.98724603652954, 118.20528101921082, 119.42331600189209, 120.70691013336182, 121.99050426483154, 123.32131052017212, 124.6521167755127, 126.0422306060791, 127.43234443664551, 128.7309901714325, 130.02963590621948, 131.1941249370575, 132.3586139678955, 133.54400730133057, 134.72940063476562, 135.94729471206665, 137.16518878936768, 138.42865824699402, 139.69212770462036, 140.93319535255432, 142.17426300048828, 143.34701490402222, 144.51976680755615, 145.6605143547058, 146.80126190185547, 148.0588858127594, 149.31650972366333, 150.60496950149536, 151.8934292793274, 153.25705456733704, 154.62067985534668, 155.83833074569702, 157.05598163604736, 158.31947898864746, 159.58297634124756, 160.86517214775085, 162.14736795425415, 163.49137663841248, 164.8353853225708, 166.15811419487, 167.4808430671692, 168.763329744339, 170.0458164215088, 171.52357244491577, 173.00132846832275, 174.30403399467468, 175.6067395210266, 176.8857204914093, 178.164701461792, 179.45478630065918, 180.74487113952637, 182.01272177696228, 183.2805724143982, 184.55686831474304, 185.8331642150879, 187.15927171707153, 188.48537921905518, 189.77323293685913, 191.0610866546631, 192.33260440826416, 193.60412216186523, 194.9011914730072, 196.19826078414917, 197.50739550590515, 198.81653022766113, 200.0352165699005, 201.2539029121399, 202.5745198726654, 203.89513683319092, 205.2008454799652, 206.5065541267395, 207.74210000038147, 208.97764587402344, 210.2703115940094, 211.56297731399536, 212.74087285995483, 213.9187684059143, 215.2287802696228, 216.5387921333313, 217.8572964668274, 219.1758008003235, 220.46873021125793, 221.76165962219238, 222.97033953666687, 224.17901945114136, 225.3550410270691, 226.53106260299683, 227.82341957092285, 229.11577653884888, 230.41662549972534, 231.7174744606018, 233.00196313858032, 234.28645181655884, 235.4476616382599, 236.60887145996094, 237.78822255134583, 238.9675736427307, 240.1105785369873, 241.2535834312439, 242.41383957862854, 243.57409572601318, 244.74091625213623, 245.90773677825928, 247.07703161239624, 248.2463264465332, 249.38708996772766, 250.52785348892212, 252.92256259918213, 255.31727170944214]
[25.35, 25.35, 32.26, 32.26, 37.45, 37.45, 39.93, 39.93, 43.62, 43.62, 44.72, 44.72, 45.85, 45.85, 47.0, 47.0, 46.79, 46.79, 47.52, 47.52, 47.71, 47.71, 47.88, 47.88, 51.02, 51.02, 51.2, 51.2, 51.73, 51.73, 51.69, 51.69, 52.48, 52.48, 53.03, 53.03, 52.81, 52.81, 53.01, 53.01, 53.14, 53.14, 53.61, 53.61, 53.82, 53.82, 54.51, 54.51, 54.86, 54.86, 54.63, 54.63, 54.16, 54.16, 54.78, 54.78, 54.68, 54.68, 54.91, 54.91, 54.25, 54.25, 54.78, 54.78, 54.47, 54.47, 54.22, 54.22, 54.72, 54.72, 54.99, 54.99, 55.24, 55.24, 54.72, 54.72, 54.43, 54.43, 55.07, 55.07, 54.88, 54.88, 55.31, 55.31, 55.21, 55.21, 54.86, 54.86, 54.49, 54.49, 54.98, 54.98, 55.11, 55.11, 55.0, 55.0, 55.03, 55.03, 55.54, 55.54, 55.47, 55.47, 55.21, 55.21, 55.11, 55.11, 55.58, 55.58, 55.31, 55.31, 55.23, 55.23, 54.95, 54.95, 55.16, 55.16, 55.58, 55.58, 54.77, 54.77, 55.04, 55.04, 55.59, 55.59, 55.26, 55.26, 55.52, 55.52, 55.61, 55.61, 55.16, 55.16, 55.04, 55.04, 55.22, 55.22, 55.16, 55.16, 54.83, 54.83, 54.6, 54.6, 54.59, 54.59, 54.67, 54.67, 54.89, 54.89, 54.8, 54.8, 55.07, 55.07, 54.78, 54.78, 55.09, 55.09, 54.98, 54.98, 55.09, 55.09, 55.35, 55.35, 55.25, 55.25, 55.56, 55.56, 55.16, 55.16, 55.11, 55.11, 54.95, 54.95, 55.14, 55.14, 55.73, 55.73, 55.99, 55.99, 55.75, 55.75, 55.94, 55.94, 56.27, 56.27, 56.29, 56.29, 55.99, 55.99, 56.3, 56.3, 55.96, 55.96, 56.16, 56.16, 55.9, 55.9, 55.76, 55.76, 56.1, 56.1, 55.66, 55.66]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.2 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 1, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.571, Test loss: 1.896, Test accuracy: 28.68
Round   0, Global train loss: 1.571, Global test loss: 2.129, Global test accuracy: 23.33
Round   1, Train loss: 1.433, Test loss: 1.727, Test accuracy: 34.10
Round   1, Global train loss: 1.433, Global test loss: 2.107, Global test accuracy: 25.62
Round   2, Train loss: 1.299, Test loss: 1.558, Test accuracy: 40.56
Round   2, Global train loss: 1.299, Global test loss: 2.152, Global test accuracy: 26.38
Round   3, Train loss: 1.171, Test loss: 1.421, Test accuracy: 43.95
Round   3, Global train loss: 1.171, Global test loss: 2.183, Global test accuracy: 29.72
Round   4, Train loss: 1.113, Test loss: 1.267, Test accuracy: 48.42
Round   4, Global train loss: 1.113, Global test loss: 1.863, Global test accuracy: 32.02
Round   5, Train loss: 1.097, Test loss: 1.203, Test accuracy: 51.87
Round   5, Global train loss: 1.097, Global test loss: 1.661, Global test accuracy: 39.89
Round   6, Train loss: 1.061, Test loss: 1.174, Test accuracy: 53.01
Round   6, Global train loss: 1.061, Global test loss: 1.683, Global test accuracy: 38.78
Round   7, Train loss: 1.089, Test loss: 1.128, Test accuracy: 55.32
Round   7, Global train loss: 1.089, Global test loss: 1.605, Global test accuracy: 39.24
Round   8, Train loss: 1.017, Test loss: 1.129, Test accuracy: 55.75
Round   8, Global train loss: 1.017, Global test loss: 1.689, Global test accuracy: 38.46
Round   9, Train loss: 0.973, Test loss: 1.118, Test accuracy: 56.03
Round   9, Global train loss: 0.973, Global test loss: 1.991, Global test accuracy: 35.59
Round  10, Train loss: 0.965, Test loss: 1.071, Test accuracy: 57.61
Round  10, Global train loss: 0.965, Global test loss: 1.978, Global test accuracy: 37.18
Round  11, Train loss: 0.952, Test loss: 1.023, Test accuracy: 58.83
Round  11, Global train loss: 0.952, Global test loss: 1.547, Global test accuracy: 42.68
Round  12, Train loss: 0.968, Test loss: 0.971, Test accuracy: 60.77
Round  12, Global train loss: 0.968, Global test loss: 1.824, Global test accuracy: 35.42
Round  13, Train loss: 0.870, Test loss: 0.951, Test accuracy: 61.70
Round  13, Global train loss: 0.870, Global test loss: 1.439, Global test accuracy: 51.35
Round  14, Train loss: 0.877, Test loss: 0.942, Test accuracy: 62.80
Round  14, Global train loss: 0.877, Global test loss: 1.689, Global test accuracy: 41.05
Round  15, Train loss: 0.835, Test loss: 0.934, Test accuracy: 63.45
Round  15, Global train loss: 0.835, Global test loss: 1.694, Global test accuracy: 40.84
Round  16, Train loss: 0.871, Test loss: 0.931, Test accuracy: 63.38
Round  16, Global train loss: 0.871, Global test loss: 1.398, Global test accuracy: 50.30
Round  17, Train loss: 0.776, Test loss: 0.909, Test accuracy: 64.50
Round  17, Global train loss: 0.776, Global test loss: 1.502, Global test accuracy: 45.63
Round  18, Train loss: 0.903, Test loss: 0.908, Test accuracy: 64.43
Round  18, Global train loss: 0.903, Global test loss: 1.475, Global test accuracy: 46.97
Round  19, Train loss: 0.785, Test loss: 0.893, Test accuracy: 65.17
Round  19, Global train loss: 0.785, Global test loss: 1.608, Global test accuracy: 44.78
Round  20, Train loss: 0.810, Test loss: 0.901, Test accuracy: 65.13
Round  20, Global train loss: 0.810, Global test loss: 1.538, Global test accuracy: 47.70
Round  21, Train loss: 0.805, Test loss: 0.873, Test accuracy: 66.46
Round  21, Global train loss: 0.805, Global test loss: 1.228, Global test accuracy: 55.52
Round  22, Train loss: 0.773, Test loss: 0.846, Test accuracy: 67.86
Round  22, Global train loss: 0.773, Global test loss: 1.490, Global test accuracy: 50.03
Round  23, Train loss: 0.779, Test loss: 0.845, Test accuracy: 67.95
Round  23, Global train loss: 0.779, Global test loss: 1.341, Global test accuracy: 51.83
Round  24, Train loss: 0.736, Test loss: 0.852, Test accuracy: 67.58
Round  24, Global train loss: 0.736, Global test loss: 1.168, Global test accuracy: 58.39
Round  25, Train loss: 0.701, Test loss: 0.837, Test accuracy: 68.18
Round  25, Global train loss: 0.701, Global test loss: 1.546, Global test accuracy: 46.70
Round  26, Train loss: 0.768, Test loss: 0.834, Test accuracy: 68.62
Round  26, Global train loss: 0.768, Global test loss: 1.292, Global test accuracy: 53.72
Round  27, Train loss: 0.692, Test loss: 0.839, Test accuracy: 68.26
Round  27, Global train loss: 0.692, Global test loss: 1.404, Global test accuracy: 51.52
Round  28, Train loss: 0.667, Test loss: 0.835, Test accuracy: 68.38
Round  28, Global train loss: 0.667, Global test loss: 1.622, Global test accuracy: 48.83
Round  29, Train loss: 0.656, Test loss: 0.852, Test accuracy: 68.03
Round  29, Global train loss: 0.656, Global test loss: 1.492, Global test accuracy: 51.62
Round  30, Train loss: 0.689, Test loss: 0.840, Test accuracy: 68.87
Round  30, Global train loss: 0.689, Global test loss: 1.354, Global test accuracy: 52.00
Round  31, Train loss: 0.639, Test loss: 0.851, Test accuracy: 68.81
Round  31, Global train loss: 0.639, Global test loss: 1.236, Global test accuracy: 56.76
Round  32, Train loss: 0.629, Test loss: 0.861, Test accuracy: 68.62
Round  32, Global train loss: 0.629, Global test loss: 1.507, Global test accuracy: 50.77
Round  33, Train loss: 0.646, Test loss: 0.866, Test accuracy: 68.64
Round  33, Global train loss: 0.646, Global test loss: 1.279, Global test accuracy: 55.75
Round  34, Train loss: 0.608, Test loss: 0.863, Test accuracy: 68.29
Round  34, Global train loss: 0.608, Global test loss: 1.166, Global test accuracy: 59.09
Round  35, Train loss: 0.602, Test loss: 0.839, Test accuracy: 69.10
Round  35, Global train loss: 0.602, Global test loss: 1.325, Global test accuracy: 55.67
Round  36, Train loss: 0.566, Test loss: 0.861, Test accuracy: 68.61
Round  36, Global train loss: 0.566, Global test loss: 1.207, Global test accuracy: 58.78
Round  37, Train loss: 0.575, Test loss: 0.861, Test accuracy: 68.52
Round  37, Global train loss: 0.575, Global test loss: 1.156, Global test accuracy: 59.58
Round  38, Train loss: 0.556, Test loss: 0.848, Test accuracy: 69.15
Round  38, Global train loss: 0.556, Global test loss: 1.425, Global test accuracy: 54.00
Round  39, Train loss: 0.649, Test loss: 0.848, Test accuracy: 69.73
Round  39, Global train loss: 0.649, Global test loss: 1.353, Global test accuracy: 53.32
Round  40, Train loss: 0.618, Test loss: 0.864, Test accuracy: 69.52
Round  40, Global train loss: 0.618, Global test loss: 1.312, Global test accuracy: 56.16
Round  41, Train loss: 0.574, Test loss: 0.865, Test accuracy: 69.72
Round  41, Global train loss: 0.574, Global test loss: 1.269, Global test accuracy: 57.50
Round  42, Train loss: 0.582, Test loss: 0.866, Test accuracy: 69.53
Round  42, Global train loss: 0.582, Global test loss: 1.146, Global test accuracy: 60.35
Round  43, Train loss: 0.547, Test loss: 0.855, Test accuracy: 70.04
Round  43, Global train loss: 0.547, Global test loss: 1.236, Global test accuracy: 58.20
Round  44, Train loss: 0.547, Test loss: 0.858, Test accuracy: 70.25
Round  44, Global train loss: 0.547, Global test loss: 1.230, Global test accuracy: 57.34
Round  45, Train loss: 0.493, Test loss: 0.862, Test accuracy: 70.45
Round  45, Global train loss: 0.493, Global test loss: 1.547, Global test accuracy: 52.34
Round  46, Train loss: 0.580, Test loss: 0.865, Test accuracy: 70.36
Round  46, Global train loss: 0.580, Global test loss: 1.263, Global test accuracy: 56.82
Round  47, Train loss: 0.571, Test loss: 0.858, Test accuracy: 70.42
Round  47, Global train loss: 0.571, Global test loss: 1.144, Global test accuracy: 60.19
Round  48, Train loss: 0.473, Test loss: 0.860, Test accuracy: 70.17
Round  48, Global train loss: 0.473, Global test loss: 1.557, Global test accuracy: 52.31
Round  49, Train loss: 0.558, Test loss: 0.865, Test accuracy: 70.06
Round  49, Global train loss: 0.558, Global test loss: 1.323, Global test accuracy: 54.91
Round  50, Train loss: 0.470, Test loss: 0.856, Test accuracy: 70.24
Round  50, Global train loss: 0.470, Global test loss: 1.140, Global test accuracy: 61.41
Round  51, Train loss: 0.443, Test loss: 0.867, Test accuracy: 70.45
Round  51, Global train loss: 0.443, Global test loss: 1.273, Global test accuracy: 57.90
Round  52, Train loss: 0.473, Test loss: 0.888, Test accuracy: 70.24
Round  52, Global train loss: 0.473, Global test loss: 1.291, Global test accuracy: 57.73
Round  53, Train loss: 0.532, Test loss: 0.885, Test accuracy: 70.77
Round  53, Global train loss: 0.532, Global test loss: 1.591, Global test accuracy: 51.63
Round  54, Train loss: 0.528, Test loss: 0.874, Test accuracy: 71.29
Round  54, Global train loss: 0.528, Global test loss: 1.193, Global test accuracy: 60.03
Round  55, Train loss: 0.508, Test loss: 0.873, Test accuracy: 71.31
Round  55, Global train loss: 0.508, Global test loss: 1.155, Global test accuracy: 61.12
Round  56, Train loss: 0.436, Test loss: 0.865, Test accuracy: 71.67
Round  56, Global train loss: 0.436, Global test loss: 1.157, Global test accuracy: 60.98
Round  57, Train loss: 0.473, Test loss: 0.877, Test accuracy: 71.45
Round  57, Global train loss: 0.473, Global test loss: 1.446, Global test accuracy: 54.26
Round  58, Train loss: 0.512, Test loss: 0.885, Test accuracy: 71.37
Round  58, Global train loss: 0.512, Global test loss: 1.346, Global test accuracy: 56.01
Round  59, Train loss: 0.486, Test loss: 0.877, Test accuracy: 71.23
Round  59, Global train loss: 0.486, Global test loss: 1.250, Global test accuracy: 59.49
Round  60, Train loss: 0.394, Test loss: 0.875, Test accuracy: 71.38
Round  60, Global train loss: 0.394, Global test loss: 1.419, Global test accuracy: 57.61
Round  61, Train loss: 0.388, Test loss: 0.889, Test accuracy: 71.34
Round  61, Global train loss: 0.388, Global test loss: 1.557, Global test accuracy: 56.68
Round  62, Train loss: 0.451, Test loss: 0.943, Test accuracy: 70.79
Round  62, Global train loss: 0.451, Global test loss: 1.297, Global test accuracy: 59.50
Round  63, Train loss: 0.435, Test loss: 0.925, Test accuracy: 70.94
Round  63, Global train loss: 0.435, Global test loss: 1.314, Global test accuracy: 58.83
Round  64, Train loss: 0.389, Test loss: 0.912, Test accuracy: 71.30
Round  64, Global train loss: 0.389, Global test loss: 1.235, Global test accuracy: 60.38
Round  65, Train loss: 0.451, Test loss: 0.919, Test accuracy: 71.34
Round  65, Global train loss: 0.451, Global test loss: 1.227, Global test accuracy: 60.24
Round  66, Train loss: 0.391, Test loss: 0.911, Test accuracy: 71.56
Round  66, Global train loss: 0.391, Global test loss: 1.530, Global test accuracy: 55.69
Round  67, Train loss: 0.388, Test loss: 0.919, Test accuracy: 71.53
Round  67, Global train loss: 0.388, Global test loss: 1.317, Global test accuracy: 59.40
Round  68, Train loss: 0.356, Test loss: 0.921, Test accuracy: 71.66
Round  68, Global train loss: 0.356, Global test loss: 1.652, Global test accuracy: 54.25
Round  69, Train loss: 0.517, Test loss: 0.925, Test accuracy: 71.67
Round  69, Global train loss: 0.517, Global test loss: 1.497, Global test accuracy: 54.44
Round  70, Train loss: 0.407, Test loss: 0.920, Test accuracy: 71.72
Round  70, Global train loss: 0.407, Global test loss: 1.222, Global test accuracy: 61.75
Round  71, Train loss: 0.408, Test loss: 0.898, Test accuracy: 72.14
Round  71, Global train loss: 0.408, Global test loss: 1.114, Global test accuracy: 63.35
Round  72, Train loss: 0.393, Test loss: 0.932, Test accuracy: 71.31
Round  72, Global train loss: 0.393, Global test loss: 1.342, Global test accuracy: 58.61
Round  73, Train loss: 0.407, Test loss: 0.966, Test accuracy: 70.78
Round  73, Global train loss: 0.407, Global test loss: 1.290, Global test accuracy: 59.87
Round  74, Train loss: 0.410, Test loss: 0.945, Test accuracy: 71.68
Round  74, Global train loss: 0.410, Global test loss: 1.324, Global test accuracy: 60.10
Round  75, Train loss: 0.427, Test loss: 0.946, Test accuracy: 71.62
Round  75, Global train loss: 0.427, Global test loss: 1.153, Global test accuracy: 62.24
Round  76, Train loss: 0.387, Test loss: 0.937, Test accuracy: 72.02
Round  76, Global train loss: 0.387, Global test loss: 1.270, Global test accuracy: 61.50
Round  77, Train loss: 0.387, Test loss: 0.934, Test accuracy: 72.28
Round  77, Global train loss: 0.387, Global test loss: 1.317, Global test accuracy: 59.45
Round  78, Train loss: 0.406, Test loss: 0.912, Test accuracy: 72.76
Round  78, Global train loss: 0.406, Global test loss: 1.242, Global test accuracy: 61.59
Round  79, Train loss: 0.401, Test loss: 0.913, Test accuracy: 72.38
Round  79, Global train loss: 0.401, Global test loss: 1.564, Global test accuracy: 56.41
Round  80, Train loss: 0.372, Test loss: 0.909, Test accuracy: 72.93
Round  80, Global train loss: 0.372, Global test loss: 1.247, Global test accuracy: 61.10
Round  81, Train loss: 0.366, Test loss: 0.919, Test accuracy: 72.47
Round  81, Global train loss: 0.366, Global test loss: 1.299, Global test accuracy: 60.40
Round  82, Train loss: 0.399, Test loss: 0.926, Test accuracy: 72.78
Round  82, Global train loss: 0.399, Global test loss: 1.290, Global test accuracy: 60.23
Round  83, Train loss: 0.348, Test loss: 0.928, Test accuracy: 72.46
Round  83, Global train loss: 0.348, Global test loss: 1.606, Global test accuracy: 54.94
Round  84, Train loss: 0.362, Test loss: 0.942, Test accuracy: 72.28
Round  84, Global train loss: 0.362, Global test loss: 1.486, Global test accuracy: 56.92
Round  85, Train loss: 0.317, Test loss: 0.937, Test accuracy: 72.61
Round  85, Global train loss: 0.317, Global test loss: 1.202, Global test accuracy: 63.75
Round  86, Train loss: 0.297, Test loss: 0.948, Test accuracy: 72.28
Round  86, Global train loss: 0.297, Global test loss: 1.449, Global test accuracy: 58.40
Round  87, Train loss: 0.337, Test loss: 0.951, Test accuracy: 72.43
Round  87, Global train loss: 0.337, Global test loss: 1.461, Global test accuracy: 58.92
Round  88, Train loss: 0.320, Test loss: 0.963, Test accuracy: 72.49
Round  88, Global train loss: 0.320, Global test loss: 1.634, Global test accuracy: 55.92
Round  89, Train loss: 0.381, Test loss: 0.942, Test accuracy: 72.69
Round  89, Global train loss: 0.381, Global test loss: 1.374, Global test accuracy: 59.53
Round  90, Train loss: 0.337, Test loss: 0.940, Test accuracy: 72.37
Round  90, Global train loss: 0.337, Global test loss: 1.296, Global test accuracy: 62.00
Round  91, Train loss: 0.310, Test loss: 0.951, Test accuracy: 71.96
Round  91, Global train loss: 0.310, Global test loss: 1.318, Global test accuracy: 61.11
Round  92, Train loss: 0.367, Test loss: 0.947, Test accuracy: 72.44
Round  92, Global train loss: 0.367, Global test loss: 1.225, Global test accuracy: 61.77
Round  93, Train loss: 0.305, Test loss: 0.958, Test accuracy: 72.64
Round  93, Global train loss: 0.305, Global test loss: 1.515, Global test accuracy: 58.55
Round  94, Train loss: 0.322, Test loss: 0.958, Test accuracy: 72.76
Round  94, Global train loss: 0.322, Global test loss: 1.205, Global test accuracy: 63.09
Round  95, Train loss: 0.277, Test loss: 0.963, Test accuracy: 72.82
Round  95, Global train loss: 0.277, Global test loss: 1.313, Global test accuracy: 61.76
Round  96, Train loss: 0.286, Test loss: 0.991, Test accuracy: 72.72
Round  96, Global train loss: 0.286, Global test loss: 1.566, Global test accuracy: 58.98
Round  97, Train loss: 0.375, Test loss: 0.984, Test accuracy: 72.46
Round  97, Global train loss: 0.375, Global test loss: 1.278, Global test accuracy: 60.80
Round  98, Train loss: 0.285, Test loss: 0.963, Test accuracy: 72.41
Round  98, Global train loss: 0.285, Global test loss: 1.335, Global test accuracy: 60.77
Round  99, Train loss: 0.277, Test loss: 0.956, Test accuracy: 72.56
Round  99, Global train loss: 0.277, Global test loss: 1.547, Global test accuracy: 57.10
Final Round, Train loss: 0.249, Test loss: 1.064, Test accuracy: 72.41
Final Round, Global train loss: 0.249, Global test loss: 1.547, Global test accuracy: 57.10
Average accuracy final 10 rounds: 72.514 

Average global accuracy final 10 rounds: 60.592999999999996 

1734.7530472278595
[1.6144413948059082, 3.2288827896118164, 4.548155069351196, 5.867427349090576, 7.147961378097534, 8.428495407104492, 9.75263261795044, 11.076769828796387, 12.409749269485474, 13.74272871017456, 15.052745342254639, 16.362761974334717, 17.703592538833618, 19.04442310333252, 20.38134217262268, 21.718261241912842, 23.070479154586792, 24.422697067260742, 25.65820837020874, 26.89371967315674, 28.113768577575684, 29.33381748199463, 30.573452472686768, 31.813087463378906, 33.286367416381836, 34.759647369384766, 36.03288793563843, 37.30612850189209, 38.68203854560852, 40.05794858932495, 41.35085725784302, 42.643765926361084, 43.95903253555298, 45.27429914474487, 46.6286826133728, 47.98306608200073, 49.204347372055054, 50.425628662109375, 51.5818772315979, 52.738125801086426, 54.02084183692932, 55.30355787277222, 56.478413581848145, 57.65326929092407, 58.85141944885254, 60.049569606781006, 61.352665424346924, 62.65576124191284, 64.00738620758057, 65.35901117324829, 66.69896483421326, 68.03891849517822, 69.38496375083923, 70.73100900650024, 71.97799944877625, 73.22498989105225, 74.45790123939514, 75.69081258773804, 77.17868304252625, 78.66655349731445, 80.00286912918091, 81.33918476104736, 82.65071868896484, 83.96225261688232, 85.3058021068573, 86.64935159683228, 87.95802283287048, 89.26669406890869, 90.5792088508606, 91.8917236328125, 93.15215539932251, 94.41258716583252, 95.61685943603516, 96.8211317062378, 98.00552535057068, 99.18991899490356, 100.43723487854004, 101.68455076217651, 102.97521543502808, 104.26588010787964, 105.69978523254395, 107.13369035720825, 108.4818913936615, 109.83009243011475, 111.14491772651672, 112.4597430229187, 113.73000288009644, 115.00026273727417, 116.34320187568665, 117.68614101409912, 119.03985810279846, 120.3935751914978, 121.6889100074768, 122.98424482345581, 124.1481442451477, 125.3120436668396, 126.56249523162842, 127.81294679641724, 129.12642645835876, 130.4399061203003, 131.70888352394104, 132.9778609275818, 134.2349829673767, 135.49210500717163, 136.80889296531677, 138.1256809234619, 139.5095157623291, 140.8933506011963, 142.21982669830322, 143.54630279541016, 144.84781122207642, 146.14931964874268, 147.44240760803223, 148.73549556732178, 150.08309960365295, 151.43070363998413, 152.74761033058167, 154.0645170211792, 155.26240062713623, 156.46028423309326, 157.71654534339905, 158.97280645370483, 160.2637152671814, 161.55462408065796, 162.69850945472717, 163.8423948287964, 164.97526741027832, 166.10813999176025, 167.22993206977844, 168.35172414779663, 169.46949648857117, 170.5872688293457, 171.83669233322144, 173.08611583709717, 174.3721125125885, 175.65810918807983, 176.89486837387085, 178.13162755966187, 179.4037835597992, 180.67593955993652, 181.95370173454285, 183.23146390914917, 184.52450227737427, 185.81754064559937, 186.9325840473175, 188.04762744903564, 189.19154381752014, 190.33546018600464, 191.58278512954712, 192.8301100730896, 193.96428728103638, 195.09846448898315, 196.40139961242676, 197.70433473587036, 198.98265266418457, 200.26097059249878, 201.5421917438507, 202.82341289520264, 204.10041904449463, 205.37742519378662, 206.72500896453857, 208.07259273529053, 209.4405062198639, 210.80841970443726, 212.23834490776062, 213.66827011108398, 214.93523526191711, 216.20220041275024, 217.45718812942505, 218.71217584609985, 220.0175232887268, 221.32287073135376, 222.58892726898193, 223.8549838066101, 225.10344195365906, 226.351900100708, 227.47811436653137, 228.60432863235474, 229.7272264957428, 230.85012435913086, 232.11776542663574, 233.38540649414062, 234.65998697280884, 235.93456745147705, 237.21467804908752, 238.494788646698, 239.7329125404358, 240.97103643417358, 242.33189988136292, 243.69276332855225, 245.07633996009827, 246.4599165916443, 248.00638580322266, 249.55285501480103, 250.7968463897705, 252.04083776474, 253.49374961853027, 254.94666147232056, 256.1673593521118, 257.3880572319031, 260.0512795448303, 262.71450185775757]
[28.68, 28.68, 34.1, 34.1, 40.56, 40.56, 43.95, 43.95, 48.42, 48.42, 51.87, 51.87, 53.01, 53.01, 55.32, 55.32, 55.75, 55.75, 56.03, 56.03, 57.61, 57.61, 58.83, 58.83, 60.77, 60.77, 61.7, 61.7, 62.8, 62.8, 63.45, 63.45, 63.38, 63.38, 64.5, 64.5, 64.43, 64.43, 65.17, 65.17, 65.13, 65.13, 66.46, 66.46, 67.86, 67.86, 67.95, 67.95, 67.58, 67.58, 68.18, 68.18, 68.62, 68.62, 68.26, 68.26, 68.38, 68.38, 68.03, 68.03, 68.87, 68.87, 68.81, 68.81, 68.62, 68.62, 68.64, 68.64, 68.29, 68.29, 69.1, 69.1, 68.61, 68.61, 68.52, 68.52, 69.15, 69.15, 69.73, 69.73, 69.52, 69.52, 69.72, 69.72, 69.53, 69.53, 70.04, 70.04, 70.25, 70.25, 70.45, 70.45, 70.36, 70.36, 70.42, 70.42, 70.17, 70.17, 70.06, 70.06, 70.24, 70.24, 70.45, 70.45, 70.24, 70.24, 70.77, 70.77, 71.29, 71.29, 71.31, 71.31, 71.67, 71.67, 71.45, 71.45, 71.37, 71.37, 71.23, 71.23, 71.38, 71.38, 71.34, 71.34, 70.79, 70.79, 70.94, 70.94, 71.3, 71.3, 71.34, 71.34, 71.56, 71.56, 71.53, 71.53, 71.66, 71.66, 71.67, 71.67, 71.72, 71.72, 72.14, 72.14, 71.31, 71.31, 70.78, 70.78, 71.68, 71.68, 71.62, 71.62, 72.02, 72.02, 72.28, 72.28, 72.76, 72.76, 72.38, 72.38, 72.93, 72.93, 72.47, 72.47, 72.78, 72.78, 72.46, 72.46, 72.28, 72.28, 72.61, 72.61, 72.28, 72.28, 72.43, 72.43, 72.49, 72.49, 72.69, 72.69, 72.37, 72.37, 71.96, 71.96, 72.44, 72.44, 72.64, 72.64, 72.76, 72.76, 72.82, 72.82, 72.72, 72.72, 72.46, 72.46, 72.41, 72.41, 72.56, 72.56, 72.41, 72.41]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.2 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 13, noise    level: 0.8000 
   Client 16, noise    level: 0.8000 
   Client 15, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.588, Test loss: 1.967, Test accuracy: 21.72
Round   0, Global train loss: 1.588, Global test loss: 2.189, Global test accuracy: 15.49
Round   1, Train loss: 1.491, Test loss: 1.722, Test accuracy: 34.08
Round   1, Global train loss: 1.491, Global test loss: 2.050, Global test accuracy: 26.57
Round   2, Train loss: 1.305, Test loss: 1.552, Test accuracy: 40.43
Round   2, Global train loss: 1.305, Global test loss: 2.034, Global test accuracy: 28.48
Round   3, Train loss: 1.198, Test loss: 1.452, Test accuracy: 42.96
Round   3, Global train loss: 1.198, Global test loss: 2.081, Global test accuracy: 27.59
Round   4, Train loss: 1.137, Test loss: 1.314, Test accuracy: 47.35
Round   4, Global train loss: 1.137, Global test loss: 1.789, Global test accuracy: 32.45
Round   5, Train loss: 1.221, Test loss: 1.232, Test accuracy: 51.57
Round   5, Global train loss: 1.221, Global test loss: 1.715, Global test accuracy: 35.59
Round   6, Train loss: 1.202, Test loss: 1.177, Test accuracy: 53.58
Round   6, Global train loss: 1.202, Global test loss: 1.672, Global test accuracy: 37.06
Round   7, Train loss: 1.116, Test loss: 1.157, Test accuracy: 54.55
Round   7, Global train loss: 1.116, Global test loss: 1.653, Global test accuracy: 36.61
Round   8, Train loss: 1.097, Test loss: 1.167, Test accuracy: 54.71
Round   8, Global train loss: 1.097, Global test loss: 1.708, Global test accuracy: 37.83
Round   9, Train loss: 1.065, Test loss: 1.113, Test accuracy: 56.81
Round   9, Global train loss: 1.065, Global test loss: 1.840, Global test accuracy: 36.67
Round  10, Train loss: 1.037, Test loss: 1.089, Test accuracy: 57.60
Round  10, Global train loss: 1.037, Global test loss: 1.950, Global test accuracy: 38.06
Round  11, Train loss: 1.057, Test loss: 1.072, Test accuracy: 58.20
Round  11, Global train loss: 1.057, Global test loss: 1.634, Global test accuracy: 40.99
Round  12, Train loss: 1.053, Test loss: 0.993, Test accuracy: 60.86
Round  12, Global train loss: 1.053, Global test loss: 1.785, Global test accuracy: 37.32
Round  13, Train loss: 0.943, Test loss: 1.005, Test accuracy: 60.48
Round  13, Global train loss: 0.943, Global test loss: 1.472, Global test accuracy: 50.40
Round  14, Train loss: 1.007, Test loss: 1.003, Test accuracy: 60.33
Round  14, Global train loss: 1.007, Global test loss: 1.599, Global test accuracy: 43.08
Round  15, Train loss: 0.969, Test loss: 1.010, Test accuracy: 59.93
Round  15, Global train loss: 0.969, Global test loss: 1.714, Global test accuracy: 40.53
Round  16, Train loss: 0.940, Test loss: 0.996, Test accuracy: 60.78
Round  16, Global train loss: 0.940, Global test loss: 1.478, Global test accuracy: 46.65
Round  17, Train loss: 0.937, Test loss: 0.965, Test accuracy: 62.60
Round  17, Global train loss: 0.937, Global test loss: 1.519, Global test accuracy: 46.40
Round  18, Train loss: 0.938, Test loss: 0.944, Test accuracy: 63.71
Round  18, Global train loss: 0.938, Global test loss: 1.438, Global test accuracy: 45.77
Round  19, Train loss: 0.854, Test loss: 0.950, Test accuracy: 63.18
Round  19, Global train loss: 0.854, Global test loss: 1.689, Global test accuracy: 41.41
Round  20, Train loss: 0.894, Test loss: 0.935, Test accuracy: 63.64
Round  20, Global train loss: 0.894, Global test loss: 1.559, Global test accuracy: 47.54
Round  21, Train loss: 0.923, Test loss: 0.949, Test accuracy: 63.22
Round  21, Global train loss: 0.923, Global test loss: 1.297, Global test accuracy: 52.51
Round  22, Train loss: 0.837, Test loss: 0.927, Test accuracy: 64.42
Round  22, Global train loss: 0.837, Global test loss: 1.487, Global test accuracy: 47.82
Round  23, Train loss: 0.872, Test loss: 0.906, Test accuracy: 65.08
Round  23, Global train loss: 0.872, Global test loss: 1.386, Global test accuracy: 47.77
Round  24, Train loss: 0.809, Test loss: 0.902, Test accuracy: 65.56
Round  24, Global train loss: 0.809, Global test loss: 1.230, Global test accuracy: 55.61
Round  25, Train loss: 0.852, Test loss: 0.899, Test accuracy: 65.80
Round  25, Global train loss: 0.852, Global test loss: 1.504, Global test accuracy: 46.46
Round  26, Train loss: 0.916, Test loss: 0.877, Test accuracy: 66.67
Round  26, Global train loss: 0.916, Global test loss: 1.347, Global test accuracy: 50.83
Round  27, Train loss: 0.806, Test loss: 0.886, Test accuracy: 65.91
Round  27, Global train loss: 0.806, Global test loss: 1.365, Global test accuracy: 50.20
Round  28, Train loss: 0.783, Test loss: 0.897, Test accuracy: 65.86
Round  28, Global train loss: 0.783, Global test loss: 1.534, Global test accuracy: 48.06
Round  29, Train loss: 0.856, Test loss: 0.885, Test accuracy: 65.87
Round  29, Global train loss: 0.856, Global test loss: 1.439, Global test accuracy: 51.08
Round  30, Train loss: 0.759, Test loss: 0.883, Test accuracy: 66.35
Round  30, Global train loss: 0.759, Global test loss: 1.389, Global test accuracy: 50.07
Round  31, Train loss: 0.826, Test loss: 0.883, Test accuracy: 66.32
Round  31, Global train loss: 0.826, Global test loss: 1.312, Global test accuracy: 54.20
Round  32, Train loss: 0.781, Test loss: 0.885, Test accuracy: 66.42
Round  32, Global train loss: 0.781, Global test loss: 1.461, Global test accuracy: 50.19
Round  33, Train loss: 0.845, Test loss: 0.887, Test accuracy: 66.22
Round  33, Global train loss: 0.845, Global test loss: 1.337, Global test accuracy: 52.67
Round  34, Train loss: 0.684, Test loss: 0.874, Test accuracy: 66.72
Round  34, Global train loss: 0.684, Global test loss: 1.148, Global test accuracy: 59.64
Round  35, Train loss: 0.720, Test loss: 0.879, Test accuracy: 66.96
Round  35, Global train loss: 0.720, Global test loss: 1.403, Global test accuracy: 51.53
Round  36, Train loss: 0.671, Test loss: 0.882, Test accuracy: 67.22
Round  36, Global train loss: 0.671, Global test loss: 1.230, Global test accuracy: 56.74
Round  37, Train loss: 0.680, Test loss: 0.885, Test accuracy: 67.14
Round  37, Global train loss: 0.680, Global test loss: 1.170, Global test accuracy: 59.31
Round  38, Train loss: 0.624, Test loss: 0.891, Test accuracy: 66.93
Round  38, Global train loss: 0.624, Global test loss: 1.337, Global test accuracy: 54.77
Round  39, Train loss: 0.719, Test loss: 0.885, Test accuracy: 67.32
Round  39, Global train loss: 0.719, Global test loss: 1.389, Global test accuracy: 50.35
Round  40, Train loss: 0.714, Test loss: 0.874, Test accuracy: 67.87
Round  40, Global train loss: 0.714, Global test loss: 1.285, Global test accuracy: 54.47
Round  41, Train loss: 0.697, Test loss: 0.862, Test accuracy: 68.49
Round  41, Global train loss: 0.697, Global test loss: 1.262, Global test accuracy: 56.17
Round  42, Train loss: 0.629, Test loss: 0.877, Test accuracy: 68.14
Round  42, Global train loss: 0.629, Global test loss: 1.165, Global test accuracy: 58.78
Round  43, Train loss: 0.619, Test loss: 0.878, Test accuracy: 68.31
Round  43, Global train loss: 0.619, Global test loss: 1.187, Global test accuracy: 57.76
Round  44, Train loss: 0.742, Test loss: 0.867, Test accuracy: 69.08
Round  44, Global train loss: 0.742, Global test loss: 1.201, Global test accuracy: 56.93
Round  45, Train loss: 0.583, Test loss: 0.863, Test accuracy: 69.01
Round  45, Global train loss: 0.583, Global test loss: 1.527, Global test accuracy: 51.62
Round  46, Train loss: 0.707, Test loss: 0.882, Test accuracy: 68.82
Round  46, Global train loss: 0.707, Global test loss: 1.231, Global test accuracy: 56.93
Round  47, Train loss: 0.657, Test loss: 0.872, Test accuracy: 68.86
Round  47, Global train loss: 0.657, Global test loss: 1.173, Global test accuracy: 59.37
Round  48, Train loss: 0.576, Test loss: 0.876, Test accuracy: 68.69
Round  48, Global train loss: 0.576, Global test loss: 1.345, Global test accuracy: 55.06
Round  49, Train loss: 0.716, Test loss: 0.862, Test accuracy: 68.86
Round  49, Global train loss: 0.716, Global test loss: 1.274, Global test accuracy: 56.45
Round  50, Train loss: 0.583, Test loss: 0.850, Test accuracy: 68.91
Round  50, Global train loss: 0.583, Global test loss: 1.160, Global test accuracy: 59.51
Round  51, Train loss: 0.590, Test loss: 0.859, Test accuracy: 68.94
Round  51, Global train loss: 0.590, Global test loss: 1.247, Global test accuracy: 58.00
Round  52, Train loss: 0.597, Test loss: 0.877, Test accuracy: 69.00
Round  52, Global train loss: 0.597, Global test loss: 1.200, Global test accuracy: 58.33
Round  53, Train loss: 0.595, Test loss: 0.881, Test accuracy: 68.78
Round  53, Global train loss: 0.595, Global test loss: 1.386, Global test accuracy: 53.70
Round  54, Train loss: 0.612, Test loss: 0.878, Test accuracy: 69.23
Round  54, Global train loss: 0.612, Global test loss: 1.189, Global test accuracy: 58.69
Round  55, Train loss: 0.560, Test loss: 0.872, Test accuracy: 69.51
Round  55, Global train loss: 0.560, Global test loss: 1.163, Global test accuracy: 59.20
Round  56, Train loss: 0.551, Test loss: 0.869, Test accuracy: 69.35
Round  56, Global train loss: 0.551, Global test loss: 1.133, Global test accuracy: 60.97
Round  57, Train loss: 0.606, Test loss: 0.864, Test accuracy: 69.58
Round  57, Global train loss: 0.606, Global test loss: 1.272, Global test accuracy: 57.40
Round  58, Train loss: 0.571, Test loss: 0.862, Test accuracy: 69.57
Round  58, Global train loss: 0.571, Global test loss: 1.343, Global test accuracy: 55.86
Round  59, Train loss: 0.607, Test loss: 0.870, Test accuracy: 69.52
Round  59, Global train loss: 0.607, Global test loss: 1.249, Global test accuracy: 58.09
Round  60, Train loss: 0.495, Test loss: 0.873, Test accuracy: 69.47
Round  60, Global train loss: 0.495, Global test loss: 1.413, Global test accuracy: 56.09
Round  61, Train loss: 0.513, Test loss: 0.885, Test accuracy: 69.41
Round  61, Global train loss: 0.513, Global test loss: 1.529, Global test accuracy: 54.65
Round  62, Train loss: 0.676, Test loss: 0.879, Test accuracy: 69.79
Round  62, Global train loss: 0.676, Global test loss: 1.338, Global test accuracy: 54.81
Round  63, Train loss: 0.588, Test loss: 0.881, Test accuracy: 69.78
Round  63, Global train loss: 0.588, Global test loss: 1.283, Global test accuracy: 57.09
Round  64, Train loss: 0.561, Test loss: 0.887, Test accuracy: 70.41
Round  64, Global train loss: 0.561, Global test loss: 1.290, Global test accuracy: 56.95
Round  65, Train loss: 0.572, Test loss: 0.910, Test accuracy: 70.17
Round  65, Global train loss: 0.572, Global test loss: 1.218, Global test accuracy: 59.85
Round  66, Train loss: 0.549, Test loss: 0.905, Test accuracy: 70.22
Round  66, Global train loss: 0.549, Global test loss: 1.451, Global test accuracy: 55.37
Round  67, Train loss: 0.556, Test loss: 0.915, Test accuracy: 70.16
Round  67, Global train loss: 0.556, Global test loss: 1.249, Global test accuracy: 59.14
Round  68, Train loss: 0.468, Test loss: 0.933, Test accuracy: 69.84
Round  68, Global train loss: 0.468, Global test loss: 1.459, Global test accuracy: 55.75
Round  69, Train loss: 0.557, Test loss: 0.936, Test accuracy: 69.53
Round  69, Global train loss: 0.557, Global test loss: 1.331, Global test accuracy: 56.14
Round  70, Train loss: 0.571, Test loss: 0.944, Test accuracy: 69.19
Round  70, Global train loss: 0.571, Global test loss: 1.203, Global test accuracy: 59.71
Round  71, Train loss: 0.520, Test loss: 0.946, Test accuracy: 69.18
Round  71, Global train loss: 0.520, Global test loss: 1.215, Global test accuracy: 59.98
Round  72, Train loss: 0.449, Test loss: 0.947, Test accuracy: 69.41
Round  72, Global train loss: 0.449, Global test loss: 1.304, Global test accuracy: 58.92
Round  73, Train loss: 0.533, Test loss: 0.917, Test accuracy: 70.15
Round  73, Global train loss: 0.533, Global test loss: 1.265, Global test accuracy: 58.58
Round  74, Train loss: 0.521, Test loss: 0.932, Test accuracy: 69.91
Round  74, Global train loss: 0.521, Global test loss: 1.258, Global test accuracy: 59.12
Round  75, Train loss: 0.503, Test loss: 0.911, Test accuracy: 70.18
Round  75, Global train loss: 0.503, Global test loss: 1.235, Global test accuracy: 59.58
Round  76, Train loss: 0.509, Test loss: 0.914, Test accuracy: 69.96
Round  76, Global train loss: 0.509, Global test loss: 1.199, Global test accuracy: 59.96
Round  77, Train loss: 0.553, Test loss: 0.916, Test accuracy: 70.13
Round  77, Global train loss: 0.553, Global test loss: 1.235, Global test accuracy: 59.65
Round  78, Train loss: 0.450, Test loss: 0.912, Test accuracy: 70.28
Round  78, Global train loss: 0.450, Global test loss: 1.212, Global test accuracy: 60.67
Round  79, Train loss: 0.565, Test loss: 0.922, Test accuracy: 70.34
Round  79, Global train loss: 0.565, Global test loss: 1.500, Global test accuracy: 53.81
Round  80, Train loss: 0.471, Test loss: 0.930, Test accuracy: 70.14
Round  80, Global train loss: 0.471, Global test loss: 1.263, Global test accuracy: 58.95
Round  81, Train loss: 0.474, Test loss: 0.934, Test accuracy: 70.19
Round  81, Global train loss: 0.474, Global test loss: 1.334, Global test accuracy: 57.05
Round  82, Train loss: 0.448, Test loss: 0.944, Test accuracy: 69.95
Round  82, Global train loss: 0.448, Global test loss: 1.344, Global test accuracy: 58.39
Round  83, Train loss: 0.425, Test loss: 0.956, Test accuracy: 69.92
Round  83, Global train loss: 0.425, Global test loss: 1.402, Global test accuracy: 58.04
Round  84, Train loss: 0.440, Test loss: 0.940, Test accuracy: 70.37
Round  84, Global train loss: 0.440, Global test loss: 1.359, Global test accuracy: 58.19
Round  85, Train loss: 0.428, Test loss: 0.947, Test accuracy: 70.57
Round  85, Global train loss: 0.428, Global test loss: 1.170, Global test accuracy: 62.11
Round  86, Train loss: 0.356, Test loss: 0.946, Test accuracy: 70.64
Round  86, Global train loss: 0.356, Global test loss: 1.407, Global test accuracy: 58.24
Round  87, Train loss: 0.482, Test loss: 0.937, Test accuracy: 70.74
Round  87, Global train loss: 0.482, Global test loss: 1.363, Global test accuracy: 57.98
Round  88, Train loss: 0.425, Test loss: 0.953, Test accuracy: 70.41
Round  88, Global train loss: 0.425, Global test loss: 1.365, Global test accuracy: 57.78
Round  89, Train loss: 0.481, Test loss: 0.963, Test accuracy: 70.19
Round  89, Global train loss: 0.481, Global test loss: 1.364, Global test accuracy: 58.29
Round  90, Train loss: 0.387, Test loss: 0.963, Test accuracy: 70.22
Round  90, Global train loss: 0.387, Global test loss: 1.353, Global test accuracy: 58.73
Round  91, Train loss: 0.398, Test loss: 0.956, Test accuracy: 70.84
Round  91, Global train loss: 0.398, Global test loss: 1.221, Global test accuracy: 61.08
Round  92, Train loss: 0.391, Test loss: 0.976, Test accuracy: 70.32
Round  92, Global train loss: 0.391, Global test loss: 1.243, Global test accuracy: 60.52
Round  93, Train loss: 0.420, Test loss: 0.954, Test accuracy: 70.81
Round  93, Global train loss: 0.420, Global test loss: 1.425, Global test accuracy: 57.19
Round  94, Train loss: 0.382, Test loss: 0.971, Test accuracy: 70.23
Round  94, Global train loss: 0.382, Global test loss: 1.202, Global test accuracy: 61.59/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  95, Train loss: 0.353, Test loss: 0.964, Test accuracy: 70.45
Round  95, Global train loss: 0.353, Global test loss: 1.286, Global test accuracy: 60.49
Round  96, Train loss: 0.341, Test loss: 0.975, Test accuracy: 70.34
Round  96, Global train loss: 0.341, Global test loss: 1.455, Global test accuracy: 58.11
Round  97, Train loss: 0.495, Test loss: 0.939, Test accuracy: 71.18
Round  97, Global train loss: 0.495, Global test loss: 1.251, Global test accuracy: 59.95
Round  98, Train loss: 0.330, Test loss: 0.937, Test accuracy: 71.27
Round  98, Global train loss: 0.330, Global test loss: 1.314, Global test accuracy: 60.17
Round  99, Train loss: 0.397, Test loss: 0.930, Test accuracy: 71.41
Round  99, Global train loss: 0.397, Global test loss: 1.337, Global test accuracy: 59.40
Final Round, Train loss: 0.338, Test loss: 1.057, Test accuracy: 70.36
Final Round, Global train loss: 0.338, Global test loss: 1.337, Global test accuracy: 59.40
Average accuracy final 10 rounds: 70.70700000000001 

Average global accuracy final 10 rounds: 59.72299999999999 

1725.067146539688
[1.5896832942962646, 3.1793665885925293, 4.812779903411865, 6.446193218231201, 7.863914489746094, 9.281635761260986, 10.557723045349121, 11.833810329437256, 13.08514404296875, 14.336477756500244, 15.72528886795044, 17.114099979400635, 18.57370376586914, 20.033307552337646, 21.410175800323486, 22.787044048309326, 24.040570974349976, 25.294097900390625, 26.850529670715332, 28.40696144104004, 29.799688577651978, 31.192415714263916, 32.58565950393677, 33.97890329360962, 35.27385902404785, 36.568814754486084, 37.98394274711609, 39.399070739746094, 40.71608114242554, 42.03309154510498, 43.3867609500885, 44.74043035507202, 46.079914569854736, 47.41939878463745, 48.79746055603027, 50.175522327423096, 51.55779480934143, 52.940067291259766, 54.208805322647095, 55.477543354034424, 56.8851215839386, 58.29269981384277, 59.680686950683594, 61.068674087524414, 62.39992070198059, 63.73116731643677, 64.96522092819214, 66.19927453994751, 67.43049788475037, 68.66172122955322, 69.88596081733704, 71.11020040512085, 72.32880473136902, 73.54740905761719, 74.76993441581726, 75.99245977401733, 77.21547889709473, 78.43849802017212, 79.6732406616211, 80.90798330307007, 82.35262131690979, 83.79725933074951, 84.97519636154175, 86.15313339233398, 87.34931445121765, 88.54549551010132, 89.7625560760498, 90.97961664199829, 92.21146821975708, 93.44331979751587, 94.65874290466309, 95.8741660118103, 97.08408284187317, 98.29399967193604, 99.5240113735199, 100.75402307510376, 101.96999859809875, 103.18597412109375, 104.43062949180603, 105.67528486251831, 106.98507714271545, 108.2948694229126, 109.54468703269958, 110.79450464248657, 112.05022978782654, 113.3059549331665, 114.56654238700867, 115.82712984085083, 117.08200526237488, 118.33688068389893, 119.5859363079071, 120.83499193191528, 122.07720065116882, 123.31940937042236, 124.59297776222229, 125.86654615402222, 127.13109350204468, 128.39564085006714, 129.7809453010559, 131.16624975204468, 132.52022123336792, 133.87419271469116, 135.0959026813507, 136.31761264801025, 137.57140111923218, 138.8251895904541, 140.09573364257812, 141.36627769470215, 142.6713993549347, 143.97652101516724, 145.21499586105347, 146.4534707069397, 147.70031762123108, 148.94716453552246, 150.19203424453735, 151.43690395355225, 152.676575422287, 153.91624689102173, 155.16180562973022, 156.40736436843872, 157.6484158039093, 158.88946723937988, 160.13271236419678, 161.37595748901367, 162.61481976509094, 163.8536820411682, 165.10445499420166, 166.3552279472351, 167.6072313785553, 168.8592348098755, 170.1150860786438, 171.3709373474121, 172.61853504180908, 173.86613273620605, 175.11057782173157, 176.35502290725708, 177.60698699951172, 178.85895109176636, 180.11111903190613, 181.3632869720459, 182.60593581199646, 183.84858465194702, 185.0951886177063, 186.34179258346558, 187.5901038646698, 188.83841514587402, 190.09408617019653, 191.34975719451904, 192.58809089660645, 193.82642459869385, 195.07096767425537, 196.3155107498169, 197.55938172340393, 198.80325269699097, 200.13413524627686, 201.46501779556274, 202.7209610939026, 203.97690439224243, 205.21517300605774, 206.45344161987305, 207.70888876914978, 208.9643359184265, 210.20051217079163, 211.43668842315674, 212.6909282207489, 213.94516801834106, 215.1993808746338, 216.4535937309265, 217.71170163154602, 218.96980953216553, 220.20696473121643, 221.44411993026733, 222.7079577445984, 223.97179555892944, 225.22290778160095, 226.47402000427246, 227.71810102462769, 228.9621820449829, 230.20813250541687, 231.45408296585083, 232.6987497806549, 233.94341659545898, 235.1956226825714, 236.44782876968384, 237.70243763923645, 238.95704650878906, 240.21300315856934, 241.4689598083496, 242.73916840553284, 244.00937700271606, 245.27774953842163, 246.5461220741272, 247.81330752372742, 249.08049297332764, 250.32522892951965, 251.56996488571167, 252.8153314590454, 254.06069803237915, 255.31247973442078, 256.5642614364624, 259.07680439949036, 261.5893473625183]
[21.72, 21.72, 34.08, 34.08, 40.43, 40.43, 42.96, 42.96, 47.35, 47.35, 51.57, 51.57, 53.58, 53.58, 54.55, 54.55, 54.71, 54.71, 56.81, 56.81, 57.6, 57.6, 58.2, 58.2, 60.86, 60.86, 60.48, 60.48, 60.33, 60.33, 59.93, 59.93, 60.78, 60.78, 62.6, 62.6, 63.71, 63.71, 63.18, 63.18, 63.64, 63.64, 63.22, 63.22, 64.42, 64.42, 65.08, 65.08, 65.56, 65.56, 65.8, 65.8, 66.67, 66.67, 65.91, 65.91, 65.86, 65.86, 65.87, 65.87, 66.35, 66.35, 66.32, 66.32, 66.42, 66.42, 66.22, 66.22, 66.72, 66.72, 66.96, 66.96, 67.22, 67.22, 67.14, 67.14, 66.93, 66.93, 67.32, 67.32, 67.87, 67.87, 68.49, 68.49, 68.14, 68.14, 68.31, 68.31, 69.08, 69.08, 69.01, 69.01, 68.82, 68.82, 68.86, 68.86, 68.69, 68.69, 68.86, 68.86, 68.91, 68.91, 68.94, 68.94, 69.0, 69.0, 68.78, 68.78, 69.23, 69.23, 69.51, 69.51, 69.35, 69.35, 69.58, 69.58, 69.57, 69.57, 69.52, 69.52, 69.47, 69.47, 69.41, 69.41, 69.79, 69.79, 69.78, 69.78, 70.41, 70.41, 70.17, 70.17, 70.22, 70.22, 70.16, 70.16, 69.84, 69.84, 69.53, 69.53, 69.19, 69.19, 69.18, 69.18, 69.41, 69.41, 70.15, 70.15, 69.91, 69.91, 70.18, 70.18, 69.96, 69.96, 70.13, 70.13, 70.28, 70.28, 70.34, 70.34, 70.14, 70.14, 70.19, 70.19, 69.95, 69.95, 69.92, 69.92, 70.37, 70.37, 70.57, 70.57, 70.64, 70.64, 70.74, 70.74, 70.41, 70.41, 70.19, 70.19, 70.22, 70.22, 70.84, 70.84, 70.32, 70.32, 70.81, 70.81, 70.23, 70.23, 70.45, 70.45, 70.34, 70.34, 71.18, 71.18, 71.27, 71.27, 71.41, 71.41, 70.36, 70.36]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.2 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 9, noise    level: 0.8000 
   Client 19, noise    level: 0.8000 
   Client 10, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.933, Test loss: 2.100, Test accuracy: 20.09
Round   1, Train loss: 1.514, Test loss: 1.881, Test accuracy: 30.04
Round   2, Train loss: 1.390, Test loss: 1.649, Test accuracy: 38.44
Round   3, Train loss: 1.280, Test loss: 1.506, Test accuracy: 43.84
Round   4, Train loss: 1.192, Test loss: 1.317, Test accuracy: 48.86
Round   5, Train loss: 1.156, Test loss: 1.246, Test accuracy: 51.60
Round   6, Train loss: 1.117, Test loss: 1.196, Test accuracy: 52.03
Round   7, Train loss: 1.110, Test loss: 1.147, Test accuracy: 54.41
Round   8, Train loss: 1.068, Test loss: 1.166, Test accuracy: 55.06
Round   9, Train loss: 1.035, Test loss: 1.111, Test accuracy: 56.21
Round  10, Train loss: 1.022, Test loss: 1.085, Test accuracy: 57.08
Round  11, Train loss: 0.997, Test loss: 1.042, Test accuracy: 58.28
Round  12, Train loss: 1.060, Test loss: 0.982, Test accuracy: 60.20
Round  13, Train loss: 0.936, Test loss: 0.970, Test accuracy: 61.35
Round  14, Train loss: 0.951, Test loss: 0.952, Test accuracy: 62.29
Round  15, Train loss: 0.906, Test loss: 0.952, Test accuracy: 61.71
Round  16, Train loss: 0.941, Test loss: 0.930, Test accuracy: 63.07
Round  17, Train loss: 0.854, Test loss: 0.918, Test accuracy: 63.34
Round  18, Train loss: 0.964, Test loss: 0.909, Test accuracy: 64.37
Round  19, Train loss: 0.870, Test loss: 0.903, Test accuracy: 64.60
Round  20, Train loss: 0.873, Test loss: 0.900, Test accuracy: 64.27
Round  21, Train loss: 0.873, Test loss: 0.897, Test accuracy: 64.93
Round  22, Train loss: 0.867, Test loss: 0.872, Test accuracy: 66.02
Round  23, Train loss: 0.869, Test loss: 0.865, Test accuracy: 66.23
Round  24, Train loss: 0.855, Test loss: 0.856, Test accuracy: 67.14
Round  25, Train loss: 0.798, Test loss: 0.848, Test accuracy: 66.79
Round  26, Train loss: 0.867, Test loss: 0.853, Test accuracy: 67.37
Round  27, Train loss: 0.795, Test loss: 0.824, Test accuracy: 67.91
Round  28, Train loss: 0.772, Test loss: 0.844, Test accuracy: 67.59
Round  29, Train loss: 0.789, Test loss: 0.830, Test accuracy: 67.65
Round  30, Train loss: 0.824, Test loss: 0.819, Test accuracy: 68.50
Round  31, Train loss: 0.750, Test loss: 0.817, Test accuracy: 68.80
Round  32, Train loss: 0.752, Test loss: 0.817, Test accuracy: 68.64
Round  33, Train loss: 0.797, Test loss: 0.822, Test accuracy: 68.77
Round  34, Train loss: 0.726, Test loss: 0.784, Test accuracy: 69.56
Round  35, Train loss: 0.736, Test loss: 0.788, Test accuracy: 69.66
Round  36, Train loss: 0.689, Test loss: 0.781, Test accuracy: 69.72
Round  37, Train loss: 0.697, Test loss: 0.765, Test accuracy: 70.17
Round  38, Train loss: 0.676, Test loss: 0.763, Test accuracy: 70.50
Round  39, Train loss: 0.740, Test loss: 0.759, Test accuracy: 70.75
Round  40, Train loss: 0.725, Test loss: 0.762, Test accuracy: 70.77
Round  41, Train loss: 0.687, Test loss: 0.747, Test accuracy: 71.28
Round  42, Train loss: 0.674, Test loss: 0.750, Test accuracy: 71.16
Round  43, Train loss: 0.661, Test loss: 0.734, Test accuracy: 71.34
Round  44, Train loss: 0.712, Test loss: 0.726, Test accuracy: 71.87
Round  45, Train loss: 0.627, Test loss: 0.724, Test accuracy: 72.13
Round  46, Train loss: 0.744, Test loss: 0.723, Test accuracy: 72.69
Round  47, Train loss: 0.672, Test loss: 0.722, Test accuracy: 72.54
Round  48, Train loss: 0.609, Test loss: 0.708, Test accuracy: 72.62
Round  49, Train loss: 0.733, Test loss: 0.713, Test accuracy: 72.69
Round  50, Train loss: 0.616, Test loss: 0.702, Test accuracy: 72.95
Round  51, Train loss: 0.577, Test loss: 0.705, Test accuracy: 72.58
Round  52, Train loss: 0.649, Test loss: 0.715, Test accuracy: 72.92
Round  53, Train loss: 0.640, Test loss: 0.700, Test accuracy: 73.40
Round  54, Train loss: 0.704, Test loss: 0.698, Test accuracy: 73.58
Round  55, Train loss: 0.651, Test loss: 0.700, Test accuracy: 73.18
Round  56, Train loss: 0.579, Test loss: 0.701, Test accuracy: 73.09
Round  57, Train loss: 0.623, Test loss: 0.690, Test accuracy: 73.48
Round  58, Train loss: 0.616, Test loss: 0.695, Test accuracy: 73.33
Round  59, Train loss: 0.600, Test loss: 0.691, Test accuracy: 73.30
Round  60, Train loss: 0.548, Test loss: 0.690, Test accuracy: 73.63
Round  61, Train loss: 0.545, Test loss: 0.682, Test accuracy: 73.65
Round  62, Train loss: 0.595, Test loss: 0.689, Test accuracy: 73.51
Round  63, Train loss: 0.583, Test loss: 0.686, Test accuracy: 73.99
Round  64, Train loss: 0.521, Test loss: 0.681, Test accuracy: 73.91
Round  65, Train loss: 0.630, Test loss: 0.679, Test accuracy: 73.73
Round  66, Train loss: 0.553, Test loss: 0.678, Test accuracy: 73.86
Round  67, Train loss: 0.526, Test loss: 0.677, Test accuracy: 73.96
Round  68, Train loss: 0.508, Test loss: 0.673, Test accuracy: 73.93
Round  69, Train loss: 0.622, Test loss: 0.663, Test accuracy: 74.78
Round  70, Train loss: 0.609, Test loss: 0.674, Test accuracy: 74.45
Round  71, Train loss: 0.515, Test loss: 0.667, Test accuracy: 74.17
Round  72, Train loss: 0.500, Test loss: 0.664, Test accuracy: 74.49
Round  73, Train loss: 0.591, Test loss: 0.663, Test accuracy: 74.20
Round  74, Train loss: 0.580, Test loss: 0.666, Test accuracy: 74.38
Round  75, Train loss: 0.545, Test loss: 0.655, Test accuracy: 74.95
Round  76, Train loss: 0.520, Test loss: 0.652, Test accuracy: 75.52
Round  77, Train loss: 0.567, Test loss: 0.664, Test accuracy: 74.87
Round  78, Train loss: 0.508, Test loss: 0.650, Test accuracy: 75.11
Round  79, Train loss: 0.598, Test loss: 0.653, Test accuracy: 74.99
Round  80, Train loss: 0.545, Test loss: 0.651, Test accuracy: 74.85
Round  81, Train loss: 0.496, Test loss: 0.663, Test accuracy: 74.53
Round  82, Train loss: 0.504, Test loss: 0.649, Test accuracy: 75.46
Round  83, Train loss: 0.487, Test loss: 0.651, Test accuracy: 74.90
Round  84, Train loss: 0.524, Test loss: 0.647, Test accuracy: 75.06
Round  85, Train loss: 0.476, Test loss: 0.654, Test accuracy: 75.17
Round  86, Train loss: 0.412, Test loss: 0.652, Test accuracy: 74.89
Round  87, Train loss: 0.480, Test loss: 0.645, Test accuracy: 75.18
Round  88, Train loss: 0.456, Test loss: 0.644, Test accuracy: 75.44
Round  89, Train loss: 0.480, Test loss: 0.648, Test accuracy: 75.23
Round  90, Train loss: 0.451, Test loss: 0.646, Test accuracy: 75.65
Round  91, Train loss: 0.499, Test loss: 0.658, Test accuracy: 74.95
Round  92, Train loss: 0.454, Test loss: 0.650, Test accuracy: 75.29
Round  93, Train loss: 0.428, Test loss: 0.654, Test accuracy: 75.36
Round  94, Train loss: 0.476, Test loss: 0.655, Test accuracy: 75.29
Round  95, Train loss: 0.429, Test loss: 0.655, Test accuracy: 75.17
Round  96, Train loss: 0.410, Test loss: 0.662, Test accuracy: 74.70
Round  97, Train loss: 0.459, Test loss: 0.641, Test accuracy: 75.75
Round  98, Train loss: 0.399, Test loss: 0.648, Test accuracy: 75.51
Round  99, Train loss: 0.398, Test loss: 0.655, Test accuracy: 75.27
Final Round, Train loss: 0.383, Test loss: 0.655, Test accuracy: 75.28
Average accuracy final 10 rounds: 75.29400000000001
2288.9705998897552
[3.669325351715088, 6.878167390823364, 10.193553447723389, 13.551153182983398, 17.00011658668518, 20.440210103988647, 23.897149801254272, 27.31016969680786, 30.712624073028564, 33.89649319648743, 37.07373332977295, 40.2305326461792, 43.43830990791321, 46.59907841682434, 49.710915327072144, 52.84599733352661, 55.9982008934021, 59.1960813999176, 62.37486529350281, 65.51508069038391, 68.73152017593384, 71.88553619384766, 75.03626894950867, 78.21342134475708, 81.3627450466156, 84.54446935653687, 87.72104907035828, 90.87187767028809, 94.05287170410156, 97.2104377746582, 100.45543575286865, 103.67129492759705, 106.87783670425415, 110.0892608165741, 113.36533212661743, 116.78700304031372, 119.95763325691223, 123.14310812950134, 126.29746317863464, 129.43465375900269, 132.65562438964844, 135.7767562866211, 138.94699788093567, 142.11933279037476, 145.31647443771362, 148.59931182861328, 151.67058181762695, 155.12320828437805, 158.32306504249573, 161.49651050567627, 164.93628001213074, 168.32650303840637, 171.70500898361206, 174.99362897872925, 178.21375942230225, 181.49496269226074, 184.71563506126404, 187.89753127098083, 191.09210109710693, 194.30081009864807, 197.4952540397644, 200.90674591064453, 204.31268000602722, 207.57500505447388, 210.86154460906982, 214.31125569343567, 217.58542704582214, 220.80508375167847, 224.07153868675232, 227.2757637500763, 230.49238920211792, 233.79139947891235, 236.9728865623474, 240.2597141265869, 243.43102598190308, 246.68894052505493, 249.90233778953552, 253.15604710578918, 256.3773171901703, 259.64150524139404, 263.02508640289307, 266.32011699676514, 269.5617415904999, 272.74417519569397, 275.98589420318604, 279.1856870651245, 282.6562280654907, 286.1383624076843, 289.35967803001404, 292.5842673778534, 295.78237891197205, 299.01308965682983, 302.22140669822693, 305.45551323890686, 308.71990966796875, 311.9514310359955, 315.16770911216736, 318.4868655204773, 321.68987131118774, 324.970974445343, 329.7865846157074]
[20.09, 30.04, 38.44, 43.84, 48.86, 51.6, 52.03, 54.41, 55.06, 56.21, 57.08, 58.28, 60.2, 61.35, 62.29, 61.71, 63.07, 63.34, 64.37, 64.6, 64.27, 64.93, 66.02, 66.23, 67.14, 66.79, 67.37, 67.91, 67.59, 67.65, 68.5, 68.8, 68.64, 68.77, 69.56, 69.66, 69.72, 70.17, 70.5, 70.75, 70.77, 71.28, 71.16, 71.34, 71.87, 72.13, 72.69, 72.54, 72.62, 72.69, 72.95, 72.58, 72.92, 73.4, 73.58, 73.18, 73.09, 73.48, 73.33, 73.3, 73.63, 73.65, 73.51, 73.99, 73.91, 73.73, 73.86, 73.96, 73.93, 74.78, 74.45, 74.17, 74.49, 74.2, 74.38, 74.95, 75.52, 74.87, 75.11, 74.99, 74.85, 74.53, 75.46, 74.9, 75.06, 75.17, 74.89, 75.18, 75.44, 75.23, 75.65, 74.95, 75.29, 75.36, 75.29, 75.17, 74.7, 75.75, 75.51, 75.27, 75.28]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 15, noise    level: 0.8000 
   Client 14, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  19.4700
Round 1 global test acc  19.9100
Round 2 global test acc  19.6100
Round 3 global test acc  26.9200
Round 4 global test acc  18.5400
Round 5 global test acc  19.0500
Round 6 global test acc  26.1700
Round 7 global test acc  32.9600
Round 8 global test acc  31.7700
Round 9 global test acc  24.4600
Round 10 global test acc  26.3800
Round 11 global test acc  26.5800
Round 12 global test acc  30.0200
Round 13 global test acc  25.3400
Round 14 global test acc  28.2600
Round 15 global test acc  31.5200
Round 16 global test acc  30.1500
Round 17 global test acc  30.5400
Round 18 global test acc  29.3700
Round 19 global test acc  35.4100
Round 20 global test acc  30.2300
Round 21 global test acc  34.8200
Round 22 global test acc  29.7900
Round 23 global test acc  33.8200
Round 24 global test acc  35.6500
Round 25 global test acc  32.2000
Round 26 global test acc  38.8100
Round 27 global test acc  40.2200
Round 28 global test acc  35.1000
Round 29 global test acc  32.7300
Round 30 global test acc  42.5900
Round 31 global test acc  36.8500
Round 32 global test acc  30.7700
Round 33 global test acc  45.4700
Round 34 global test acc  37.8200
Round 35 global test acc  33.3000
Round 36 global test acc  34.2700
Round 37 global test acc  42.9200
Round 38 global test acc  32.3100
Round 39 global test acc  36.7100
Round 40 global test acc  43.0500
Round 41 global test acc  38.3800
Round 42 global test acc  41.1700
Round 43 global test acc  37.5600
Round 44 global test acc  35.8300
Round 45 global test acc  39.2200
Round 46 global test acc  40.9400
Round 47 global test acc  38.0200
Round 48 global test acc  32.7900
Round 49 global test acc  34.6200
Round 50 global test acc  42.6900
Round 51 global test acc  33.0900
Round 52 global test acc  39.8000
Round 53 global test acc  44.7300
Round 54 global test acc  43.0200
Round 55 global test acc  39.4100
Round 56 global test acc  39.3200
Round 57 global test acc  38.6200
Round 58 global test acc  40.6200
Round 59 global test acc  46.4200
Round 60 global test acc  43.8900
Round 61 global test acc  39.6200
Round 62 global test acc  40.7000
Round 63 global test acc  42.2100
Round 64 global test acc  36.0000
Round 65 global test acc  47.4700
Round 66 global test acc  36.5200
Round 67 global test acc  37.4300
Round 68 global test acc  42.9900
Round 69 global test acc  43.6100
Round 70 global test acc  41.2900
Round 71 global test acc  36.1300
Round 72 global test acc  36.3800
Round 73 global test acc  37.2300
Round 74 global test acc  45.5500
Round 75 global test acc  44.6000
Round 76 global test acc  37.8100
Round 77 global test acc  43.4400
Round 78 global test acc  38.0900
Round 79 global test acc  35.9100
Round 80 global test acc  32.9000
Round 81 global test acc  31.8600
Round 82 global test acc  30.6400
Round 83 global test acc  28.4400
Round 84 global test acc  27.3300
Round 85 global test acc  27.0700
Round 86 global test acc  27.4900
Round 87 global test acc  27.7300
Round 88 global test acc  26.7300
Round 89 global test acc  25.6700
Round 90 global test acc  25.9900
Round 91 global test acc  25.6700
Round 92 global test acc  25.7600
Round 93 global test acc  25.4100
Round 94 global test acc  24.0000
Round 95 global test acc  24.1100
Round 96 global test acc  24.7800
Round 97 global test acc  24.0500
Round 98 global test acc  24.0800
Round 99 global test acc  23.9100
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 18, noise    level: 0.8000 
   Client 13, noise    level: 0.8000 
   Client 15, noise    level: 0.8000 
   Client 11, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.929, Test loss: 2.042, Test accuracy: 24.10
Round   1, Train loss: 1.553, Test loss: 1.893, Test accuracy: 28.00
Round   2, Train loss: 1.391, Test loss: 1.691, Test accuracy: 37.46
Round   3, Train loss: 1.293, Test loss: 1.484, Test accuracy: 43.55
Round   4, Train loss: 1.218, Test loss: 1.298, Test accuracy: 48.87
Round   5, Train loss: 1.149, Test loss: 1.209, Test accuracy: 52.67
Round   6, Train loss: 1.106, Test loss: 1.167, Test accuracy: 53.08
Round   7, Train loss: 1.152, Test loss: 1.139, Test accuracy: 54.86
Round   8, Train loss: 1.124, Test loss: 1.152, Test accuracy: 55.65
Round   9, Train loss: 1.075, Test loss: 1.110, Test accuracy: 56.82
Round  10, Train loss: 1.068, Test loss: 1.093, Test accuracy: 57.62
Round  11, Train loss: 1.048, Test loss: 1.055, Test accuracy: 58.70
Round  12, Train loss: 1.093, Test loss: 0.973, Test accuracy: 61.29
Round  13, Train loss: 0.944, Test loss: 0.954, Test accuracy: 62.42
Round  14, Train loss: 0.947, Test loss: 0.946, Test accuracy: 63.43
Round  15, Train loss: 0.952, Test loss: 0.921, Test accuracy: 63.75
Round  16, Train loss: 0.946, Test loss: 0.901, Test accuracy: 64.89
Round  17, Train loss: 0.948, Test loss: 0.887, Test accuracy: 65.33
Round  18, Train loss: 0.940, Test loss: 0.872, Test accuracy: 65.75
Round  19, Train loss: 0.913, Test loss: 0.890, Test accuracy: 65.46
Round  20, Train loss: 0.853, Test loss: 0.854, Test accuracy: 66.55
Round  21, Train loss: 0.911, Test loss: 0.841, Test accuracy: 67.10
Round  22, Train loss: 0.854, Test loss: 0.826, Test accuracy: 67.87
Round  23, Train loss: 0.832, Test loss: 0.838, Test accuracy: 67.85
Round  24, Train loss: 0.874, Test loss: 0.825, Test accuracy: 67.94
Round  25, Train loss: 0.892, Test loss: 0.817, Test accuracy: 68.51
Round  26, Train loss: 0.848, Test loss: 0.806, Test accuracy: 69.14
Round  27, Train loss: 0.785, Test loss: 0.794, Test accuracy: 69.50
Round  28, Train loss: 0.758, Test loss: 0.791, Test accuracy: 69.45
Round  29, Train loss: 0.806, Test loss: 0.792, Test accuracy: 69.46
Round  30, Train loss: 0.779, Test loss: 0.784, Test accuracy: 69.53
Round  31, Train loss: 0.849, Test loss: 0.780, Test accuracy: 69.93
Round  32, Train loss: 0.770, Test loss: 0.778, Test accuracy: 70.36
Round  33, Train loss: 0.811, Test loss: 0.762, Test accuracy: 70.64
Round  34, Train loss: 0.697, Test loss: 0.752, Test accuracy: 70.97
Round  35, Train loss: 0.767, Test loss: 0.757, Test accuracy: 70.61
Round  36, Train loss: 0.768, Test loss: 0.756, Test accuracy: 70.48
Round  37, Train loss: 0.714, Test loss: 0.751, Test accuracy: 71.08
Round  38, Train loss: 0.658, Test loss: 0.749, Test accuracy: 70.71
Round  39, Train loss: 0.756, Test loss: 0.743, Test accuracy: 71.36
Round  40, Train loss: 0.699, Test loss: 0.740, Test accuracy: 71.99
Round  41, Train loss: 0.707, Test loss: 0.736, Test accuracy: 71.79
Round  42, Train loss: 0.691, Test loss: 0.727, Test accuracy: 72.10
Round  43, Train loss: 0.672, Test loss: 0.721, Test accuracy: 72.17
Round  44, Train loss: 0.667, Test loss: 0.716, Test accuracy: 72.38
Round  45, Train loss: 0.618, Test loss: 0.717, Test accuracy: 72.70
Round  46, Train loss: 0.738, Test loss: 0.709, Test accuracy: 72.64
Round  47, Train loss: 0.745, Test loss: 0.705, Test accuracy: 72.82
Round  48, Train loss: 0.575, Test loss: 0.699, Test accuracy: 72.89
Round  49, Train loss: 0.720, Test loss: 0.697, Test accuracy: 73.13
Round  50, Train loss: 0.648, Test loss: 0.689, Test accuracy: 73.89
Round  51, Train loss: 0.600, Test loss: 0.689, Test accuracy: 73.37
Round  52, Train loss: 0.584, Test loss: 0.691, Test accuracy: 73.50
Round  53, Train loss: 0.656, Test loss: 0.697, Test accuracy: 73.34
Round  54, Train loss: 0.683, Test loss: 0.705, Test accuracy: 72.61
Round  55, Train loss: 0.597, Test loss: 0.711, Test accuracy: 72.51
Round  56, Train loss: 0.606, Test loss: 0.704, Test accuracy: 72.82
Round  57, Train loss: 0.592, Test loss: 0.691, Test accuracy: 73.15
Round  58, Train loss: 0.634, Test loss: 0.695, Test accuracy: 72.85
Round  59, Train loss: 0.613, Test loss: 0.686, Test accuracy: 73.36
Round  60, Train loss: 0.577, Test loss: 0.681, Test accuracy: 73.73
Round  61, Train loss: 0.525, Test loss: 0.686, Test accuracy: 73.44
Round  62, Train loss: 0.629, Test loss: 0.688, Test accuracy: 73.33
Round  63, Train loss: 0.613, Test loss: 0.683, Test accuracy: 73.47
Round  64, Train loss: 0.592, Test loss: 0.676, Test accuracy: 73.74
Round  65, Train loss: 0.586, Test loss: 0.674, Test accuracy: 73.76
Round  66, Train loss: 0.523, Test loss: 0.684, Test accuracy: 73.48
Round  67, Train loss: 0.507, Test loss: 0.678, Test accuracy: 73.70
Round  68, Train loss: 0.481, Test loss: 0.685, Test accuracy: 73.21
Round  69, Train loss: 0.577, Test loss: 0.675, Test accuracy: 74.02
Round  70, Train loss: 0.593, Test loss: 0.684, Test accuracy: 73.79
Round  71, Train loss: 0.491, Test loss: 0.683, Test accuracy: 74.09
Round  72, Train loss: 0.485, Test loss: 0.678, Test accuracy: 74.15
Round  73, Train loss: 0.526, Test loss: 0.665, Test accuracy: 74.62
Round  74, Train loss: 0.520, Test loss: 0.656, Test accuracy: 75.15
Round  75, Train loss: 0.552, Test loss: 0.658, Test accuracy: 74.68
Round  76, Train loss: 0.547, Test loss: 0.661, Test accuracy: 74.90
Round  77, Train loss: 0.589, Test loss: 0.661, Test accuracy: 74.92
Round  78, Train loss: 0.526, Test loss: 0.658, Test accuracy: 74.55
Round  79, Train loss: 0.573, Test loss: 0.656, Test accuracy: 75.24
Round  80, Train loss: 0.569, Test loss: 0.649, Test accuracy: 75.01
Round  81, Train loss: 0.522, Test loss: 0.655, Test accuracy: 75.41
Round  82, Train loss: 0.477, Test loss: 0.651, Test accuracy: 75.15
Round  83, Train loss: 0.496, Test loss: 0.654, Test accuracy: 75.01
Round  84, Train loss: 0.507, Test loss: 0.645, Test accuracy: 75.56
Round  85, Train loss: 0.478, Test loss: 0.649, Test accuracy: 75.05
Round  86, Train loss: 0.425, Test loss: 0.658, Test accuracy: 74.28
Round  87, Train loss: 0.448, Test loss: 0.651, Test accuracy: 74.60
Round  88, Train loss: 0.428, Test loss: 0.665, Test accuracy: 74.44
Round  89, Train loss: 0.446, Test loss: 0.652, Test accuracy: 75.05
Round  90, Train loss: 0.420, Test loss: 0.661, Test accuracy: 74.88
Round  91, Train loss: 0.435, Test loss: 0.671, Test accuracy: 74.46
Round  92, Train loss: 0.429, Test loss: 0.658, Test accuracy: 74.82
Round  93, Train loss: 0.403, Test loss: 0.667, Test accuracy: 74.43
Round  94, Train loss: 0.480, Test loss: 0.665, Test accuracy: 74.67
Round  95, Train loss: 0.430, Test loss: 0.670, Test accuracy: 75.04
Round  96, Train loss: 0.419, Test loss: 0.674, Test accuracy: 75.03
Round  97, Train loss: 0.426, Test loss: 0.658, Test accuracy: 75.17
Round  98, Train loss: 0.412, Test loss: 0.670, Test accuracy: 74.93
Round  99, Train loss: 0.469, Test loss: 0.662, Test accuracy: 75.02
Final Round, Train loss: 0.375, Test loss: 0.665, Test accuracy: 74.99
Average accuracy final 10 rounds: 74.845
1172.359878540039
[1.7733993530273438, 3.2841107845306396, 4.782413482666016, 6.222977876663208, 7.6444878578186035, 9.028000354766846, 10.419888734817505, 11.820351600646973, 13.246450424194336, 14.630752086639404, 16.147592544555664, 17.56472420692444, 18.95587921142578, 20.356002807617188, 21.760899543762207, 23.13229274749756, 24.52032732963562, 25.898162126541138, 27.259777545928955, 28.64745259284973, 30.01233434677124, 31.389620065689087, 32.74122500419617, 34.1398446559906, 35.536755323410034, 37.031399965286255, 38.50645160675049, 39.86734986305237, 41.272582054138184, 42.64854145050049, 43.98284888267517, 45.34976887702942, 46.75076246261597, 48.119399070739746, 49.535019636154175, 50.92578887939453, 52.33184599876404, 53.71875262260437, 55.154154777526855, 56.562408208847046, 57.99143314361572, 59.387892961502075, 60.82572913169861, 62.346975326538086, 63.7659547328949, 65.15286445617676, 66.56928944587708, 68.0045657157898, 69.39919233322144, 70.82704663276672, 72.25839424133301, 73.68052315711975, 75.08530688285828, 76.51363039016724, 77.91013765335083, 79.32917904853821, 80.7404215335846, 82.18242073059082, 83.59836769104004, 85.01133298873901, 86.51960611343384, 88.04555678367615, 89.44014096260071, 90.83262825012207, 92.25739288330078, 93.66236281394958, 95.06024312973022, 96.43776226043701, 97.84439945220947, 99.38462948799133, 100.90195870399475, 102.44573259353638, 103.98933959007263, 105.44964408874512, 106.85770964622498, 108.27585649490356, 109.66742992401123, 111.06913089752197, 112.45762300491333, 113.89558339118958, 115.47855019569397, 116.9095311164856, 118.32901549339294, 119.73937749862671, 121.15029644966125, 122.60748434066772, 124.02714800834656, 125.46186399459839, 126.88281178474426, 128.32300472259521, 129.74863505363464, 131.17124772071838, 132.59699988365173, 133.97958993911743, 135.36948418617249, 136.81454467773438, 138.29742741584778, 139.7176342010498, 141.1492326259613, 142.5812430381775, 144.86304092407227]
[24.1, 28.0, 37.46, 43.55, 48.87, 52.67, 53.08, 54.86, 55.65, 56.82, 57.62, 58.7, 61.29, 62.42, 63.43, 63.75, 64.89, 65.33, 65.75, 65.46, 66.55, 67.1, 67.87, 67.85, 67.94, 68.51, 69.14, 69.5, 69.45, 69.46, 69.53, 69.93, 70.36, 70.64, 70.97, 70.61, 70.48, 71.08, 70.71, 71.36, 71.99, 71.79, 72.1, 72.17, 72.38, 72.7, 72.64, 72.82, 72.89, 73.13, 73.89, 73.37, 73.5, 73.34, 72.61, 72.51, 72.82, 73.15, 72.85, 73.36, 73.73, 73.44, 73.33, 73.47, 73.74, 73.76, 73.48, 73.7, 73.21, 74.02, 73.79, 74.09, 74.15, 74.62, 75.15, 74.68, 74.9, 74.92, 74.55, 75.24, 75.01, 75.41, 75.15, 75.01, 75.56, 75.05, 74.28, 74.6, 74.44, 75.05, 74.88, 74.46, 74.82, 74.43, 74.67, 75.04, 75.03, 75.17, 74.93, 75.02, 74.99]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.2 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 11, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 14, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.994, Test loss: 2.118, Test accuracy: 25.52
Round   1, Train loss: 1.716, Test loss: 1.903, Test accuracy: 28.87
Round   2, Train loss: 1.507, Test loss: 1.721, Test accuracy: 36.88
Round   3, Train loss: 1.440, Test loss: 1.580, Test accuracy: 41.92
Round   4, Train loss: 1.313, Test loss: 1.416, Test accuracy: 46.35
Round   5, Train loss: 1.334, Test loss: 1.314, Test accuracy: 49.35
Round   6, Train loss: 1.263, Test loss: 1.287, Test accuracy: 49.43
Round   7, Train loss: 1.161, Test loss: 1.250, Test accuracy: 51.49
Round   8, Train loss: 1.233, Test loss: 1.252, Test accuracy: 52.53
Round   9, Train loss: 1.166, Test loss: 1.179, Test accuracy: 55.11
Round  10, Train loss: 1.116, Test loss: 1.158, Test accuracy: 56.32
Round  11, Train loss: 1.162, Test loss: 1.132, Test accuracy: 56.29
Round  12, Train loss: 1.192, Test loss: 1.045, Test accuracy: 59.30
Round  13, Train loss: 1.093, Test loss: 1.052, Test accuracy: 59.96
Round  14, Train loss: 1.105, Test loss: 1.033, Test accuracy: 60.50
Round  15, Train loss: 0.962, Test loss: 1.028, Test accuracy: 60.95
Round  16, Train loss: 1.211, Test loss: 1.018, Test accuracy: 62.26
Round  17, Train loss: 0.946, Test loss: 0.994, Test accuracy: 62.74
Round  18, Train loss: 1.170, Test loss: 0.988, Test accuracy: 63.27
Round  19, Train loss: 1.092, Test loss: 0.988, Test accuracy: 62.72
Round  20, Train loss: 0.999, Test loss: 0.977, Test accuracy: 62.97
Round  21, Train loss: 1.104, Test loss: 0.968, Test accuracy: 63.87
Round  22, Train loss: 0.909, Test loss: 0.944, Test accuracy: 64.38
Round  23, Train loss: 1.054, Test loss: 0.944, Test accuracy: 65.55
Round  24, Train loss: 1.027, Test loss: 0.925, Test accuracy: 65.60
Round  25, Train loss: 0.985, Test loss: 0.914, Test accuracy: 66.02
Round  26, Train loss: 1.010, Test loss: 0.896, Test accuracy: 66.89
Round  27, Train loss: 0.974, Test loss: 0.893, Test accuracy: 67.03
Round  28, Train loss: 0.958, Test loss: 0.881, Test accuracy: 67.10
Round  29, Train loss: 0.855, Test loss: 0.899, Test accuracy: 66.85
Round  30, Train loss: 1.043, Test loss: 0.870, Test accuracy: 67.64
Round  31, Train loss: 0.963, Test loss: 0.885, Test accuracy: 67.60
Round  32, Train loss: 0.786, Test loss: 0.881, Test accuracy: 67.11
Round  33, Train loss: 0.794, Test loss: 0.873, Test accuracy: 67.93
Round  34, Train loss: 1.057, Test loss: 0.853, Test accuracy: 68.63
Round  35, Train loss: 0.743, Test loss: 0.859, Test accuracy: 68.79
Round  36, Train loss: 0.926, Test loss: 0.853, Test accuracy: 68.90
Round  37, Train loss: 0.963, Test loss: 0.850, Test accuracy: 69.18
Round  38, Train loss: 0.807, Test loss: 0.851, Test accuracy: 68.64
Round  39, Train loss: 0.983, Test loss: 0.832, Test accuracy: 69.37
Round  40, Train loss: 0.889, Test loss: 0.838, Test accuracy: 69.22
Round  41, Train loss: 0.762, Test loss: 0.831, Test accuracy: 69.42
Round  42, Train loss: 0.939, Test loss: 0.819, Test accuracy: 69.53
Round  43, Train loss: 0.821, Test loss: 0.817, Test accuracy: 70.28
Round  44, Train loss: 0.811, Test loss: 0.793, Test accuracy: 70.73
Round  45, Train loss: 0.765, Test loss: 0.799, Test accuracy: 70.57
Round  46, Train loss: 0.882, Test loss: 0.800, Test accuracy: 70.61
Round  47, Train loss: 0.745, Test loss: 0.794, Test accuracy: 70.75
Round  48, Train loss: 0.731, Test loss: 0.784, Test accuracy: 71.07
Round  49, Train loss: 0.725, Test loss: 0.794, Test accuracy: 70.63
Round  50, Train loss: 0.771, Test loss: 0.773, Test accuracy: 72.25
Round  51, Train loss: 0.690, Test loss: 0.778, Test accuracy: 71.79
Round  52, Train loss: 0.689, Test loss: 0.771, Test accuracy: 71.93
Round  53, Train loss: 0.843, Test loss: 0.782, Test accuracy: 71.60
Round  54, Train loss: 0.894, Test loss: 0.782, Test accuracy: 71.06
Round  55, Train loss: 0.661, Test loss: 0.778, Test accuracy: 71.26
Round  56, Train loss: 0.786, Test loss: 0.771, Test accuracy: 71.71
Round  57, Train loss: 0.794, Test loss: 0.769, Test accuracy: 71.80
Round  58, Train loss: 0.777, Test loss: 0.766, Test accuracy: 71.84
Round  59, Train loss: 0.660, Test loss: 0.771, Test accuracy: 71.84
Round  60, Train loss: 0.659, Test loss: 0.771, Test accuracy: 71.66
Round  61, Train loss: 0.673, Test loss: 0.769, Test accuracy: 72.07
Round  62, Train loss: 0.680, Test loss: 0.762, Test accuracy: 72.36
Round  63, Train loss: 0.748, Test loss: 0.757, Test accuracy: 72.72
Round  64, Train loss: 0.647, Test loss: 0.763, Test accuracy: 72.61
Round  65, Train loss: 0.807, Test loss: 0.765, Test accuracy: 72.30
Round  66, Train loss: 0.568, Test loss: 0.762, Test accuracy: 72.02
Round  67, Train loss: 0.805, Test loss: 0.765, Test accuracy: 71.90
Round  68, Train loss: 0.705, Test loss: 0.764, Test accuracy: 71.76
Round  69, Train loss: 0.750, Test loss: 0.746, Test accuracy: 72.47
Round  70, Train loss: 0.685, Test loss: 0.751, Test accuracy: 72.76
Round  71, Train loss: 0.586, Test loss: 0.753, Test accuracy: 72.42
Round  72, Train loss: 0.617, Test loss: 0.750, Test accuracy: 72.80
Round  73, Train loss: 0.696, Test loss: 0.744, Test accuracy: 73.01
Round  74, Train loss: 0.701, Test loss: 0.743, Test accuracy: 72.66
Round  75, Train loss: 0.732, Test loss: 0.743, Test accuracy: 72.71
Round  76, Train loss: 0.640, Test loss: 0.736, Test accuracy: 73.36
Round  77, Train loss: 0.720, Test loss: 0.747, Test accuracy: 72.51
Round  78, Train loss: 0.577, Test loss: 0.731, Test accuracy: 73.27
Round  79, Train loss: 0.644, Test loss: 0.734, Test accuracy: 73.55
Round  80, Train loss: 0.670, Test loss: 0.730, Test accuracy: 73.37
Round  81, Train loss: 0.626, Test loss: 0.728, Test accuracy: 73.26
Round  82, Train loss: 0.740, Test loss: 0.739, Test accuracy: 72.77
Round  83, Train loss: 0.580, Test loss: 0.725, Test accuracy: 73.31
Round  84, Train loss: 0.594, Test loss: 0.728, Test accuracy: 73.26
Round  85, Train loss: 0.580, Test loss: 0.718, Test accuracy: 73.87
Round  86, Train loss: 0.578, Test loss: 0.730, Test accuracy: 73.10
Round  87, Train loss: 0.536, Test loss: 0.728, Test accuracy: 73.94
Round  88, Train loss: 0.641, Test loss: 0.722, Test accuracy: 73.86
Round  89, Train loss: 0.740, Test loss: 0.736, Test accuracy: 73.04
Round  90, Train loss: 0.628, Test loss: 0.736, Test accuracy: 73.04
Round  91, Train loss: 0.534, Test loss: 0.733, Test accuracy: 72.65
Round  92, Train loss: 0.530, Test loss: 0.739, Test accuracy: 72.77
Round  93, Train loss: 0.571, Test loss: 0.733, Test accuracy: 72.93
Round  94, Train loss: 0.518, Test loss: 0.733, Test accuracy: 73.11
Round  95, Train loss: 0.575, Test loss: 0.741, Test accuracy: 73.27
Round  96, Train loss: 0.412, Test loss: 0.729, Test accuracy: 73.77
Round  97, Train loss: 0.574, Test loss: 0.737, Test accuracy: 73.24
Round  98, Train loss: 0.523, Test loss: 0.742, Test accuracy: 73.26
Round  99, Train loss: 0.544, Test loss: 0.733, Test accuracy: 73.45
Final Round, Train loss: 0.345, Test loss: 0.734, Test accuracy: 73.57
Average accuracy final 10 rounds: 73.149
1958.8347384929657
[1.8510043621063232, 3.3844499588012695, 4.929435729980469, 6.316683769226074, 7.706422805786133, 9.077897071838379, 10.506271600723267, 11.867981195449829, 13.270798921585083, 14.664234638214111, 16.071075439453125, 17.44303035736084, 18.846011877059937, 20.236283779144287, 21.62764048576355, 23.031616687774658, 24.434645175933838, 25.83618187904358, 27.227078914642334, 28.63538146018982, 30.038305044174194, 33.513017892837524, 36.844265937805176, 40.205668449401855, 43.545154094696045, 46.80811285972595, 50.15801525115967, 53.460004568099976, 56.70217180252075, 59.90677523612976, 63.07629108428955, 66.3632881641388, 69.63463354110718, 72.75251865386963, 76.04523134231567, 79.24674105644226, 82.4312629699707, 85.78472661972046, 89.12000060081482, 92.42169547080994, 95.70827174186707, 98.93402218818665, 102.25669431686401, 105.5701117515564, 108.83643746376038, 112.24537777900696, 115.52340126037598, 118.76863288879395, 122.12517189979553, 125.44252228736877, 128.75715112686157, 132.0325973033905, 135.30870604515076, 138.57356023788452, 141.86152482032776, 145.10592532157898, 148.3987593650818, 151.65081143379211, 154.95547127723694, 158.1961386203766, 161.44529724121094, 164.86303615570068, 168.0468156337738, 171.29663038253784, 174.61861991882324, 177.79397106170654, 181.09781193733215, 184.3765847682953, 187.55644345283508, 191.02006220817566, 194.2304608821869, 197.4747223854065, 200.74398946762085, 203.99176502227783, 207.17786478996277, 210.43706274032593, 213.7265875339508, 217.09638857841492, 220.39774799346924, 223.61821246147156, 226.84011363983154, 230.03665375709534, 233.24396061897278, 236.34543776512146, 239.55568718910217, 242.68455624580383, 245.88580083847046, 249.06209564208984, 252.384263753891, 255.67026567459106, 258.93665885925293, 262.12780356407166, 265.28345131874084, 268.4350063800812, 271.6786925792694, 274.8080289363861, 277.9089159965515, 281.0648787021637, 284.18933272361755, 287.31915259361267, 289.533748626709]
[25.52, 28.87, 36.88, 41.92, 46.35, 49.35, 49.43, 51.49, 52.53, 55.11, 56.32, 56.29, 59.3, 59.96, 60.5, 60.95, 62.26, 62.74, 63.27, 62.72, 62.97, 63.87, 64.38, 65.55, 65.6, 66.02, 66.89, 67.03, 67.1, 66.85, 67.64, 67.6, 67.11, 67.93, 68.63, 68.79, 68.9, 69.18, 68.64, 69.37, 69.22, 69.42, 69.53, 70.28, 70.73, 70.57, 70.61, 70.75, 71.07, 70.63, 72.25, 71.79, 71.93, 71.6, 71.06, 71.26, 71.71, 71.8, 71.84, 71.84, 71.66, 72.07, 72.36, 72.72, 72.61, 72.3, 72.02, 71.9, 71.76, 72.47, 72.76, 72.42, 72.8, 73.01, 72.66, 72.71, 73.36, 72.51, 73.27, 73.55, 73.37, 73.26, 72.77, 73.31, 73.26, 73.87, 73.1, 73.94, 73.86, 73.04, 73.04, 72.65, 72.77, 72.93, 73.11, 73.27, 73.77, 73.24, 73.26, 73.45, 73.57]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: none, level_n_system: 0.2 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 10, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 17, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.950, Test loss: 1.808, Test accuracy: 34.40
Round   1, Train loss: 1.535, Test loss: 1.386, Test accuracy: 40.71
Round   2, Train loss: 1.390, Test loss: 1.297, Test accuracy: 45.26
Round   3, Train loss: 1.308, Test loss: 1.207, Test accuracy: 50.55
Round   4, Train loss: 1.234, Test loss: 1.135, Test accuracy: 53.66
Round   5, Train loss: 1.180, Test loss: 1.099, Test accuracy: 55.64
Round   6, Train loss: 1.138, Test loss: 1.044, Test accuracy: 57.47
Round   7, Train loss: 1.106, Test loss: 1.034, Test accuracy: 59.18
Round   8, Train loss: 1.080, Test loss: 1.003, Test accuracy: 59.46
Round   9, Train loss: 1.059, Test loss: 0.988, Test accuracy: 60.57
Round  10, Train loss: 1.040, Test loss: 0.972, Test accuracy: 61.74
Round  11, Train loss: 1.022, Test loss: 0.957, Test accuracy: 61.73
Round  12, Train loss: 1.005, Test loss: 0.938, Test accuracy: 63.00
Round  13, Train loss: 0.988, Test loss: 0.926, Test accuracy: 63.66
Round  14, Train loss: 0.973, Test loss: 0.914, Test accuracy: 64.08
Round  15, Train loss: 0.955, Test loss: 0.912, Test accuracy: 64.51
Round  16, Train loss: 0.942, Test loss: 0.899, Test accuracy: 65.02
Round  17, Train loss: 0.934, Test loss: 0.888, Test accuracy: 65.41
Round  18, Train loss: 0.921, Test loss: 0.882, Test accuracy: 66.05
Round  19, Train loss: 0.912, Test loss: 0.867, Test accuracy: 66.56
Round  20, Train loss: 0.946, Test loss: 0.870, Test accuracy: 66.50
Round  21, Train loss: 0.852, Test loss: 0.874, Test accuracy: 66.27
Round  22, Train loss: 0.882, Test loss: 0.861, Test accuracy: 66.58
Round  23, Train loss: 0.849, Test loss: 0.861, Test accuracy: 67.36
Round  24, Train loss: 0.870, Test loss: 0.838, Test accuracy: 67.49
Round  25, Train loss: 0.908, Test loss: 0.850, Test accuracy: 67.15
Round  26, Train loss: 0.885, Test loss: 0.846, Test accuracy: 67.51
Round  27, Train loss: 0.843, Test loss: 0.825, Test accuracy: 68.55
Round  28, Train loss: 0.842, Test loss: 0.826, Test accuracy: 68.23
Round  29, Train loss: 0.794, Test loss: 0.817, Test accuracy: 68.63
Round  30, Train loss: 0.866, Test loss: 0.810, Test accuracy: 69.08
Round  31, Train loss: 0.750, Test loss: 0.799, Test accuracy: 69.49
Round  32, Train loss: 0.761, Test loss: 0.797, Test accuracy: 69.28
Round  33, Train loss: 0.763, Test loss: 0.789, Test accuracy: 69.68
Round  34, Train loss: 0.794, Test loss: 0.783, Test accuracy: 70.38
Round  35, Train loss: 0.716, Test loss: 0.786, Test accuracy: 70.52
Round  36, Train loss: 0.756, Test loss: 0.779, Test accuracy: 70.52
Round  37, Train loss: 0.757, Test loss: 0.763, Test accuracy: 70.48
Round  38, Train loss: 0.702, Test loss: 0.775, Test accuracy: 70.45
Round  39, Train loss: 0.702, Test loss: 0.783, Test accuracy: 70.00
Round  40, Train loss: 0.725, Test loss: 0.768, Test accuracy: 70.95
Round  41, Train loss: 0.697, Test loss: 0.763, Test accuracy: 71.00
Round  42, Train loss: 0.699, Test loss: 0.754, Test accuracy: 71.26
Round  43, Train loss: 0.711, Test loss: 0.735, Test accuracy: 72.10
Round  44, Train loss: 0.779, Test loss: 0.735, Test accuracy: 71.70
Round  45, Train loss: 0.701, Test loss: 0.726, Test accuracy: 72.21
Round  46, Train loss: 0.722, Test loss: 0.734, Test accuracy: 71.93
Round  47, Train loss: 0.646, Test loss: 0.721, Test accuracy: 72.52
Round  48, Train loss: 0.740, Test loss: 0.722, Test accuracy: 72.59
Round  49, Train loss: 0.710, Test loss: 0.724, Test accuracy: 72.38
Round  50, Train loss: 0.678, Test loss: 0.722, Test accuracy: 73.01
Round  51, Train loss: 0.598, Test loss: 0.716, Test accuracy: 72.90
Round  52, Train loss: 0.669, Test loss: 0.716, Test accuracy: 72.63
Round  53, Train loss: 0.647, Test loss: 0.704, Test accuracy: 73.24
Round  54, Train loss: 0.667, Test loss: 0.713, Test accuracy: 72.81
Round  55, Train loss: 0.588, Test loss: 0.705, Test accuracy: 73.08
Round  56, Train loss: 0.685, Test loss: 0.698, Test accuracy: 73.12
Round  57, Train loss: 0.679, Test loss: 0.694, Test accuracy: 73.56
Round  58, Train loss: 0.626, Test loss: 0.705, Test accuracy: 73.56
Round  59, Train loss: 0.603, Test loss: 0.695, Test accuracy: 73.44
Round  60, Train loss: 0.573, Test loss: 0.703, Test accuracy: 73.45
Round  61, Train loss: 0.643, Test loss: 0.697, Test accuracy: 73.11
Round  62, Train loss: 0.601, Test loss: 0.707, Test accuracy: 73.12
Round  63, Train loss: 0.646, Test loss: 0.696, Test accuracy: 73.42
Round  64, Train loss: 0.504, Test loss: 0.692, Test accuracy: 73.94
Round  65, Train loss: 0.696, Test loss: 0.692, Test accuracy: 73.89
Round  66, Train loss: 0.609, Test loss: 0.702, Test accuracy: 73.45
Round  67, Train loss: 0.585, Test loss: 0.700, Test accuracy: 73.48
Round  68, Train loss: 0.629, Test loss: 0.694, Test accuracy: 73.90
Round  69, Train loss: 0.569, Test loss: 0.682, Test accuracy: 74.02
Round  70, Train loss: 0.547, Test loss: 0.686, Test accuracy: 74.10
Round  71, Train loss: 0.530, Test loss: 0.687, Test accuracy: 74.33
Round  72, Train loss: 0.530, Test loss: 0.695, Test accuracy: 74.14
Round  73, Train loss: 0.605, Test loss: 0.679, Test accuracy: 74.31
Round  74, Train loss: 0.587, Test loss: 0.685, Test accuracy: 74.13
Round  75, Train loss: 0.559, Test loss: 0.684, Test accuracy: 74.10
Round  76, Train loss: 0.542, Test loss: 0.690, Test accuracy: 74.01
Round  77, Train loss: 0.547, Test loss: 0.684, Test accuracy: 74.13
Round  78, Train loss: 0.483, Test loss: 0.683, Test accuracy: 74.30
Round  79, Train loss: 0.573, Test loss: 0.676, Test accuracy: 74.54
Round  80, Train loss: 0.432, Test loss: 0.677, Test accuracy: 74.31
Round  81, Train loss: 0.416, Test loss: 0.678, Test accuracy: 74.73
Round  82, Train loss: 0.401, Test loss: 0.680, Test accuracy: 74.66
Round  83, Train loss: 0.390, Test loss: 0.697, Test accuracy: 74.00
Round  84, Train loss: 0.389, Test loss: 0.691, Test accuracy: 74.26
Round  85, Train loss: 0.372, Test loss: 0.696, Test accuracy: 74.24
Round  86, Train loss: 0.368, Test loss: 0.697, Test accuracy: 74.52
Round  87, Train loss: 0.359, Test loss: 0.701, Test accuracy: 74.04
Round  88, Train loss: 0.350, Test loss: 0.700, Test accuracy: 74.26
Round  89, Train loss: 0.349, Test loss: 0.708, Test accuracy: 74.02
Round  90, Train loss: 0.337, Test loss: 0.718, Test accuracy: 73.79
Round  91, Train loss: 0.329, Test loss: 0.707, Test accuracy: 74.08
Round  92, Train loss: 0.322, Test loss: 0.713, Test accuracy: 74.13
Round  93, Train loss: 0.319, Test loss: 0.710, Test accuracy: 74.21
Round  94, Train loss: 0.311, Test loss: 0.711, Test accuracy: 74.14
Round  95, Train loss: 0.313, Test loss: 0.718, Test accuracy: 73.97
Round  96, Train loss: 0.313, Test loss: 0.720, Test accuracy: 73.81
Round  97, Train loss: 0.300, Test loss: 0.714, Test accuracy: 74.36
Round  98, Train loss: 0.288, Test loss: 0.723, Test accuracy: 74.04
Round  99, Train loss: 0.283, Test loss: 0.724, Test accuracy: 73.87
Final Round, Train loss: 0.217, Test loss: 0.731, Test accuracy: 73.93
Average accuracy final 10 rounds: 74.03999999999999
1621.9226558208466
[1.841257095336914, 3.3579440116882324, 4.889042139053345, 6.417714595794678, 7.945472240447998, 9.364316463470459, 10.772491216659546, 12.168790340423584, 13.572723150253296, 14.981834173202515, 16.400799036026, 17.83405900001526, 19.345157861709595, 20.892590522766113, 22.297253131866455, 23.688333988189697, 25.18328022956848, 26.567835807800293, 27.943490266799927, 29.47957491874695, 30.878777503967285, 32.35780334472656, 33.73495030403137, 35.27422499656677, 36.759095668792725, 38.288666009902954, 39.80438208580017, 41.29183077812195, 42.82755422592163, 44.36693572998047, 45.89527606964111, 47.421725034713745, 48.81306743621826, 50.21554231643677, 51.60131597518921, 52.94794273376465, 54.32848501205444, 55.72772550582886, 57.12409234046936, 58.563520193099976, 59.93848776817322, 61.32318139076233, 62.72933912277222, 64.06716394424438, 65.43353343009949, 66.84917140007019, 68.24979972839355, 69.61391043663025, 70.93650698661804, 72.26950097084045, 73.64493203163147, 75.03759431838989, 76.55112028121948, 77.96964716911316, 79.30519604682922, 80.63986539840698, 82.02886033058167, 83.41258430480957, 84.79834127426147, 86.16221189498901, 87.49745154380798, 88.88787460327148, 90.26178979873657, 91.63927340507507, 93.01850008964539, 94.36220598220825, 95.68876218795776, 97.07518792152405, 98.44785928726196, 99.7940423488617, 101.19132232666016, 102.5811550617218, 104.02176284790039, 105.42400074005127, 106.85376024246216, 108.25832009315491, 109.66568279266357, 111.0652346611023, 112.485684633255, 113.87197732925415, 115.27339267730713, 116.6401264667511, 118.0496175289154, 119.38478183746338, 120.79386782646179, 122.17155408859253, 123.5733208656311, 124.9160053730011, 126.31088948249817, 127.69330501556396, 129.06468892097473, 130.38582515716553, 131.7682168483734, 133.10481524467468, 134.43028807640076, 135.76883459091187, 137.1299684047699, 138.45921897888184, 139.78437995910645, 141.1629490852356, 143.38419103622437]
[34.4, 40.71, 45.26, 50.55, 53.66, 55.64, 57.47, 59.18, 59.46, 60.57, 61.74, 61.73, 63.0, 63.66, 64.08, 64.51, 65.02, 65.41, 66.05, 66.56, 66.5, 66.27, 66.58, 67.36, 67.49, 67.15, 67.51, 68.55, 68.23, 68.63, 69.08, 69.49, 69.28, 69.68, 70.38, 70.52, 70.52, 70.48, 70.45, 70.0, 70.95, 71.0, 71.26, 72.1, 71.7, 72.21, 71.93, 72.52, 72.59, 72.38, 73.01, 72.9, 72.63, 73.24, 72.81, 73.08, 73.12, 73.56, 73.56, 73.44, 73.45, 73.11, 73.12, 73.42, 73.94, 73.89, 73.45, 73.48, 73.9, 74.02, 74.1, 74.33, 74.14, 74.31, 74.13, 74.1, 74.01, 74.13, 74.3, 74.54, 74.31, 74.73, 74.66, 74.0, 74.26, 74.24, 74.52, 74.04, 74.26, 74.02, 73.79, 74.08, 74.13, 74.21, 74.14, 73.97, 73.81, 74.36, 74.04, 73.87, 73.93]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.2 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 17, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.955, Test loss: 1.861, Test accuracy: 34.96
Round   1, Train loss: 1.519, Test loss: 1.366, Test accuracy: 42.08
Round   2, Train loss: 1.356, Test loss: 1.247, Test accuracy: 46.82
Round   3, Train loss: 1.261, Test loss: 1.162, Test accuracy: 50.28
Round   4, Train loss: 1.196, Test loss: 1.115, Test accuracy: 52.68
Round   5, Train loss: 1.149, Test loss: 1.062, Test accuracy: 55.94
Round   6, Train loss: 1.109, Test loss: 1.028, Test accuracy: 58.64
Round   7, Train loss: 1.072, Test loss: 0.999, Test accuracy: 59.45
Round   8, Train loss: 1.047, Test loss: 0.967, Test accuracy: 61.10
Round   9, Train loss: 1.023, Test loss: 0.950, Test accuracy: 61.27
Round  10, Train loss: 1.004, Test loss: 0.927, Test accuracy: 62.88
Round  11, Train loss: 0.985, Test loss: 0.912, Test accuracy: 63.82
Round  12, Train loss: 0.967, Test loss: 0.900, Test accuracy: 64.33
Round  13, Train loss: 0.947, Test loss: 0.883, Test accuracy: 64.65
Round  14, Train loss: 0.931, Test loss: 0.875, Test accuracy: 65.02
Round  15, Train loss: 0.920, Test loss: 0.864, Test accuracy: 65.65
Round  16, Train loss: 0.904, Test loss: 0.847, Test accuracy: 66.72
Round  17, Train loss: 0.888, Test loss: 0.845, Test accuracy: 66.77
Round  18, Train loss: 0.879, Test loss: 0.826, Test accuracy: 67.71
Round  19, Train loss: 0.868, Test loss: 0.818, Test accuracy: 68.04
Round  20, Train loss: 0.823, Test loss: 0.828, Test accuracy: 67.31
Round  21, Train loss: 0.843, Test loss: 0.820, Test accuracy: 67.77
Round  22, Train loss: 0.880, Test loss: 0.807, Test accuracy: 68.06
Round  23, Train loss: 0.807, Test loss: 0.800, Test accuracy: 68.60
Round  24, Train loss: 0.859, Test loss: 0.793, Test accuracy: 68.60
Round  25, Train loss: 0.822, Test loss: 0.787, Test accuracy: 69.39
Round  26, Train loss: 0.833, Test loss: 0.779, Test accuracy: 69.49
Round  27, Train loss: 0.805, Test loss: 0.779, Test accuracy: 69.24
Round  28, Train loss: 0.789, Test loss: 0.772, Test accuracy: 69.26
Round  29, Train loss: 0.746, Test loss: 0.764, Test accuracy: 69.68
Round  30, Train loss: 0.764, Test loss: 0.768, Test accuracy: 69.73
Round  31, Train loss: 0.745, Test loss: 0.754, Test accuracy: 70.34
Round  32, Train loss: 0.718, Test loss: 0.756, Test accuracy: 70.30
Round  33, Train loss: 0.802, Test loss: 0.757, Test accuracy: 70.18
Round  34, Train loss: 0.700, Test loss: 0.736, Test accuracy: 71.52
Round  35, Train loss: 0.748, Test loss: 0.754, Test accuracy: 70.50
Round  36, Train loss: 0.669, Test loss: 0.735, Test accuracy: 71.45
Round  37, Train loss: 0.666, Test loss: 0.730, Test accuracy: 71.47
Round  38, Train loss: 0.704, Test loss: 0.727, Test accuracy: 71.27
Round  39, Train loss: 0.687, Test loss: 0.717, Test accuracy: 71.74
Round  40, Train loss: 0.678, Test loss: 0.717, Test accuracy: 71.75
Round  41, Train loss: 0.689, Test loss: 0.709, Test accuracy: 71.71
Round  42, Train loss: 0.642, Test loss: 0.712, Test accuracy: 72.08
Round  43, Train loss: 0.617, Test loss: 0.701, Test accuracy: 72.94
Round  44, Train loss: 0.660, Test loss: 0.696, Test accuracy: 72.90
Round  45, Train loss: 0.651, Test loss: 0.710, Test accuracy: 71.83
Round  46, Train loss: 0.727, Test loss: 0.708, Test accuracy: 72.07
Round  47, Train loss: 0.640, Test loss: 0.704, Test accuracy: 72.46
Round  48, Train loss: 0.621, Test loss: 0.704, Test accuracy: 72.42
Round  49, Train loss: 0.667, Test loss: 0.695, Test accuracy: 72.84
Round  50, Train loss: 0.637, Test loss: 0.691, Test accuracy: 73.13
Round  51, Train loss: 0.553, Test loss: 0.699, Test accuracy: 72.69
Round  52, Train loss: 0.633, Test loss: 0.706, Test accuracy: 72.77
Round  53, Train loss: 0.600, Test loss: 0.695, Test accuracy: 73.23
Round  54, Train loss: 0.620, Test loss: 0.690, Test accuracy: 73.67
Round  55, Train loss: 0.594, Test loss: 0.681, Test accuracy: 74.08
Round  56, Train loss: 0.549, Test loss: 0.677, Test accuracy: 74.00
Round  57, Train loss: 0.633, Test loss: 0.680, Test accuracy: 73.62
Round  58, Train loss: 0.581, Test loss: 0.674, Test accuracy: 74.07
Round  59, Train loss: 0.570, Test loss: 0.681, Test accuracy: 74.08
Round  60, Train loss: 0.569, Test loss: 0.684, Test accuracy: 73.70
Round  61, Train loss: 0.522, Test loss: 0.680, Test accuracy: 73.68
Round  62, Train loss: 0.574, Test loss: 0.676, Test accuracy: 74.16
Round  63, Train loss: 0.556, Test loss: 0.677, Test accuracy: 73.81
Round  64, Train loss: 0.510, Test loss: 0.685, Test accuracy: 73.83
Round  65, Train loss: 0.570, Test loss: 0.667, Test accuracy: 74.15
Round  66, Train loss: 0.516, Test loss: 0.674, Test accuracy: 73.32
Round  67, Train loss: 0.505, Test loss: 0.674, Test accuracy: 73.79
Round  68, Train loss: 0.480, Test loss: 0.678, Test accuracy: 73.74
Round  69, Train loss: 0.574, Test loss: 0.658, Test accuracy: 74.79
Round  70, Train loss: 0.539, Test loss: 0.663, Test accuracy: 74.53
Round  71, Train loss: 0.484, Test loss: 0.671, Test accuracy: 74.56
Round  72, Train loss: 0.486, Test loss: 0.671, Test accuracy: 74.17
Round  73, Train loss: 0.519, Test loss: 0.660, Test accuracy: 74.53
Round  74, Train loss: 0.559, Test loss: 0.671, Test accuracy: 74.74
Round  75, Train loss: 0.519, Test loss: 0.657, Test accuracy: 74.80
Round  76, Train loss: 0.551, Test loss: 0.657, Test accuracy: 74.89
Round  77, Train loss: 0.500, Test loss: 0.659, Test accuracy: 74.74
Round  78, Train loss: 0.529, Test loss: 0.661, Test accuracy: 75.05
Round  79, Train loss: 0.528, Test loss: 0.651, Test accuracy: 75.34
Round  80, Train loss: 0.429, Test loss: 0.650, Test accuracy: 75.29
Round  81, Train loss: 0.401, Test loss: 0.654, Test accuracy: 75.25
Round  82, Train loss: 0.389, Test loss: 0.655, Test accuracy: 75.45
Round  83, Train loss: 0.393, Test loss: 0.655, Test accuracy: 75.50
Round  84, Train loss: 0.368, Test loss: 0.668, Test accuracy: 75.08
Round  85, Train loss: 0.359, Test loss: 0.664, Test accuracy: 75.16
Round  86, Train loss: 0.355, Test loss: 0.661, Test accuracy: 75.37
Round  87, Train loss: 0.349, Test loss: 0.670, Test accuracy: 75.21
Round  88, Train loss: 0.345, Test loss: 0.675, Test accuracy: 75.03
Round  89, Train loss: 0.340, Test loss: 0.678, Test accuracy: 74.88
Round  90, Train loss: 0.333, Test loss: 0.677, Test accuracy: 74.90
Round  91, Train loss: 0.333, Test loss: 0.674, Test accuracy: 74.82
Round  92, Train loss: 0.313, Test loss: 0.679, Test accuracy: 74.81
Round  93, Train loss: 0.322, Test loss: 0.687, Test accuracy: 74.42
Round  94, Train loss: 0.309, Test loss: 0.677, Test accuracy: 74.61
Round  95, Train loss: 0.305, Test loss: 0.683, Test accuracy: 74.22
Round  96, Train loss: 0.302, Test loss: 0.692, Test accuracy: 74.36
Round  97, Train loss: 0.299, Test loss: 0.686, Test accuracy: 74.56
Round  98, Train loss: 0.289, Test loss: 0.687, Test accuracy: 74.49
Round  99, Train loss: 0.283, Test loss: 0.692, Test accuracy: 74.55
Final Round, Train loss: 0.221, Test loss: 0.698, Test accuracy: 74.53
Average accuracy final 10 rounds: 74.574
2617.241306781769
[1.8350577354431152, 3.3487279415130615, 4.865631580352783, 6.3579630851745605, 7.877010107040405, 9.410205602645874, 10.921847581863403, 12.411874532699585, 13.939964532852173, 15.448920011520386, 16.971012830734253, 18.531658411026, 20.064902544021606, 21.562960386276245, 23.041032075881958, 24.502232313156128, 25.94971203804016, 27.4070987701416, 28.882941007614136, 30.344684600830078, 31.804195404052734, 35.052056074142456, 38.353633880615234, 41.73233222961426, 45.02835249900818, 48.32571244239807, 51.64103674888611, 54.98839974403381, 58.1019811630249, 61.16357088088989, 64.27917885780334, 67.57651281356812, 70.73996210098267, 73.85847759246826, 77.21481561660767, 80.337473154068, 83.54895281791687, 86.82625555992126, 90.17303204536438, 93.6868941783905, 97.10767555236816, 100.38877058029175, 103.81961178779602, 107.26173806190491, 110.61105608940125, 113.93590664863586, 117.329585313797, 120.80361795425415, 124.06669473648071, 127.3769474029541, 130.83831787109375, 134.17374920845032, 137.44626188278198, 140.73059344291687, 143.9655258655548, 147.2111496925354, 150.32482957839966, 153.68103981018066, 156.85254049301147, 160.08154773712158, 163.2925841808319, 166.53000330924988, 169.70143961906433, 173.05394887924194, 176.1711196899414, 179.38611030578613, 182.51622819900513, 185.75031399726868, 188.8580231666565, 191.86841106414795, 195.0200366973877, 198.13910722732544, 201.28046083450317, 204.48266553878784, 207.76452326774597, 210.94969248771667, 214.02648210525513, 217.28707218170166, 220.38667964935303, 223.621985912323, 226.70994234085083, 229.94783568382263, 233.11636185646057, 236.23141813278198, 239.51955437660217, 242.73318791389465, 245.82698702812195, 249.08962440490723, 252.22952699661255, 255.45388174057007, 258.6633970737457, 261.7455577850342, 265.1753726005554, 268.57874393463135, 271.80081939697266, 275.64468145370483, 279.0265040397644, 282.291494846344, 285.5124320983887, 288.723352432251, 291.0532307624817]
[34.96, 42.08, 46.82, 50.28, 52.68, 55.94, 58.64, 59.45, 61.1, 61.27, 62.88, 63.82, 64.33, 64.65, 65.02, 65.65, 66.72, 66.77, 67.71, 68.04, 67.31, 67.77, 68.06, 68.6, 68.6, 69.39, 69.49, 69.24, 69.26, 69.68, 69.73, 70.34, 70.3, 70.18, 71.52, 70.5, 71.45, 71.47, 71.27, 71.74, 71.75, 71.71, 72.08, 72.94, 72.9, 71.83, 72.07, 72.46, 72.42, 72.84, 73.13, 72.69, 72.77, 73.23, 73.67, 74.08, 74.0, 73.62, 74.07, 74.08, 73.7, 73.68, 74.16, 73.81, 73.83, 74.15, 73.32, 73.79, 73.74, 74.79, 74.53, 74.56, 74.17, 74.53, 74.74, 74.8, 74.89, 74.74, 75.05, 75.34, 75.29, 75.25, 75.45, 75.5, 75.08, 75.16, 75.37, 75.21, 75.03, 74.88, 74.9, 74.82, 74.81, 74.42, 74.61, 74.22, 74.36, 74.56, 74.49, 74.55, 74.53]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 8, noise    level: 0.4000 
   Client 18, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 19, noise    level: 0.4000 
   Client 16, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 15, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.637, Test loss: 2.178, Test accuracy: 24.45
Round   0, Global train loss: 1.637, Global test loss: 2.367, Global test accuracy: 23.62
Round   1, Train loss: 1.539, Test loss: 1.721, Test accuracy: 35.47
Round   1, Global train loss: 1.539, Global test loss: 2.046, Global test accuracy: 28.43
Round   2, Train loss: 1.425, Test loss: 1.635, Test accuracy: 35.27
Round   2, Global train loss: 1.425, Global test loss: 2.157, Global test accuracy: 19.19
Round   3, Train loss: 1.419, Test loss: 1.488, Test accuracy: 39.79
Round   3, Global train loss: 1.419, Global test loss: 2.022, Global test accuracy: 27.47
Round   4, Train loss: 1.320, Test loss: 1.373, Test accuracy: 45.42
Round   4, Global train loss: 1.320, Global test loss: 1.996, Global test accuracy: 33.42
Round   5, Train loss: 1.337, Test loss: 1.356, Test accuracy: 44.69
Round   5, Global train loss: 1.337, Global test loss: 2.107, Global test accuracy: 24.86
Round   6, Train loss: 1.255, Test loss: 1.333, Test accuracy: 46.48
Round   6, Global train loss: 1.255, Global test loss: 2.053, Global test accuracy: 28.95
Round   7, Train loss: 1.215, Test loss: 1.294, Test accuracy: 48.05
Round   7, Global train loss: 1.215, Global test loss: 1.991, Global test accuracy: 26.73
Round   8, Train loss: 1.099, Test loss: 1.313, Test accuracy: 46.96
Round   8, Global train loss: 1.099, Global test loss: 1.908, Global test accuracy: 29.18
Round   9, Train loss: 1.128, Test loss: 1.239, Test accuracy: 50.66
Round   9, Global train loss: 1.128, Global test loss: 1.858, Global test accuracy: 39.78
Round  10, Train loss: 0.997, Test loss: 1.243, Test accuracy: 50.41
Round  10, Global train loss: 0.997, Global test loss: 1.863, Global test accuracy: 35.09
Round  11, Train loss: 1.305, Test loss: 1.241, Test accuracy: 50.48
Round  11, Global train loss: 1.305, Global test loss: 1.985, Global test accuracy: 28.00
Round  12, Train loss: 1.267, Test loss: 1.180, Test accuracy: 52.53
Round  12, Global train loss: 1.267, Global test loss: 1.982, Global test accuracy: 32.95
Round  13, Train loss: 1.279, Test loss: 1.168, Test accuracy: 53.55
Round  13, Global train loss: 1.279, Global test loss: 2.034, Global test accuracy: 27.43
Round  14, Train loss: 1.029, Test loss: 1.159, Test accuracy: 54.13
Round  14, Global train loss: 1.029, Global test loss: 1.892, Global test accuracy: 37.43
Round  15, Train loss: 1.037, Test loss: 1.138, Test accuracy: 54.97
Round  15, Global train loss: 1.037, Global test loss: 1.936, Global test accuracy: 31.86
Round  16, Train loss: 1.002, Test loss: 1.138, Test accuracy: 55.52
Round  16, Global train loss: 1.002, Global test loss: 2.049, Global test accuracy: 19.83
Round  17, Train loss: 1.202, Test loss: 1.123, Test accuracy: 55.87
Round  17, Global train loss: 1.202, Global test loss: 1.967, Global test accuracy: 28.22
Round  18, Train loss: 1.130, Test loss: 1.124, Test accuracy: 56.01
Round  18, Global train loss: 1.130, Global test loss: 1.873, Global test accuracy: 30.62
Round  19, Train loss: 1.025, Test loss: 1.134, Test accuracy: 55.87
Round  19, Global train loss: 1.025, Global test loss: 1.912, Global test accuracy: 32.24
Round  20, Train loss: 0.923, Test loss: 1.125, Test accuracy: 56.28
Round  20, Global train loss: 0.923, Global test loss: 1.782, Global test accuracy: 40.75
Round  21, Train loss: 1.067, Test loss: 1.124, Test accuracy: 55.96
Round  21, Global train loss: 1.067, Global test loss: 1.972, Global test accuracy: 28.62
Round  22, Train loss: 0.883, Test loss: 1.121, Test accuracy: 56.23
Round  22, Global train loss: 0.883, Global test loss: 1.826, Global test accuracy: 36.25
Round  23, Train loss: 1.051, Test loss: 1.120, Test accuracy: 56.75
Round  23, Global train loss: 1.051, Global test loss: 2.009, Global test accuracy: 29.04
Round  24, Train loss: 1.020, Test loss: 1.128, Test accuracy: 56.50
Round  24, Global train loss: 1.020, Global test loss: 1.887, Global test accuracy: 33.70
Round  25, Train loss: 0.897, Test loss: 1.130, Test accuracy: 56.31
Round  25, Global train loss: 0.897, Global test loss: 1.879, Global test accuracy: 34.14
Round  26, Train loss: 0.886, Test loss: 1.134, Test accuracy: 56.60
Round  26, Global train loss: 0.886, Global test loss: 1.932, Global test accuracy: 30.36
Round  27, Train loss: 0.814, Test loss: 1.118, Test accuracy: 57.64
Round  27, Global train loss: 0.814, Global test loss: 2.027, Global test accuracy: 32.57
Round  28, Train loss: 0.716, Test loss: 1.150, Test accuracy: 57.29
Round  28, Global train loss: 0.716, Global test loss: 1.834, Global test accuracy: 34.46
Round  29, Train loss: 0.655, Test loss: 1.163, Test accuracy: 57.18
Round  29, Global train loss: 0.655, Global test loss: 2.001, Global test accuracy: 37.60
Round  30, Train loss: 0.858, Test loss: 1.167, Test accuracy: 57.43
Round  30, Global train loss: 0.858, Global test loss: 1.915, Global test accuracy: 31.72
Round  31, Train loss: 0.810, Test loss: 1.180, Test accuracy: 57.11
Round  31, Global train loss: 0.810, Global test loss: 1.981, Global test accuracy: 28.98
Round  32, Train loss: 0.621, Test loss: 1.192, Test accuracy: 56.92
Round  32, Global train loss: 0.621, Global test loss: 2.138, Global test accuracy: 29.25
Round  33, Train loss: 0.702, Test loss: 1.208, Test accuracy: 56.58
Round  33, Global train loss: 0.702, Global test loss: 1.875, Global test accuracy: 34.76
Round  34, Train loss: 0.889, Test loss: 1.235, Test accuracy: 56.07
Round  34, Global train loss: 0.889, Global test loss: 2.241, Global test accuracy: 25.02
Round  35, Train loss: 0.506, Test loss: 1.263, Test accuracy: 56.14
Round  35, Global train loss: 0.506, Global test loss: 2.146, Global test accuracy: 34.02
Round  36, Train loss: 0.752, Test loss: 1.267, Test accuracy: 56.99
Round  36, Global train loss: 0.752, Global test loss: 2.034, Global test accuracy: 32.35
Round  37, Train loss: 0.802, Test loss: 1.276, Test accuracy: 57.24
Round  37, Global train loss: 0.802, Global test loss: 2.045, Global test accuracy: 30.05
Round  38, Train loss: 0.648, Test loss: 1.303, Test accuracy: 57.02
Round  38, Global train loss: 0.648, Global test loss: 1.887, Global test accuracy: 29.65
Round  39, Train loss: 0.861, Test loss: 1.295, Test accuracy: 57.79
Round  39, Global train loss: 0.861, Global test loss: 2.039, Global test accuracy: 30.36
Round  40, Train loss: 0.602, Test loss: 1.292, Test accuracy: 58.41
Round  40, Global train loss: 0.602, Global test loss: 1.931, Global test accuracy: 31.44
Round  41, Train loss: 0.636, Test loss: 1.327, Test accuracy: 57.71
Round  41, Global train loss: 0.636, Global test loss: 1.977, Global test accuracy: 30.96
Round  42, Train loss: 0.648, Test loss: 1.337, Test accuracy: 57.98
Round  42, Global train loss: 0.648, Global test loss: 1.989, Global test accuracy: 29.84
Round  43, Train loss: 0.750, Test loss: 1.361, Test accuracy: 57.45
Round  43, Global train loss: 0.750, Global test loss: 2.019, Global test accuracy: 29.45
Round  44, Train loss: 0.682, Test loss: 1.365, Test accuracy: 58.07
Round  44, Global train loss: 0.682, Global test loss: 2.085, Global test accuracy: 26.70
Round  45, Train loss: 0.391, Test loss: 1.382, Test accuracy: 58.01
Round  45, Global train loss: 0.391, Global test loss: 1.731, Global test accuracy: 39.24
Round  46, Train loss: 0.452, Test loss: 1.405, Test accuracy: 57.84
Round  46, Global train loss: 0.452, Global test loss: 1.883, Global test accuracy: 36.99
Round  47, Train loss: 0.653, Test loss: 1.430, Test accuracy: 57.74
Round  47, Global train loss: 0.653, Global test loss: 2.148, Global test accuracy: 31.89
Round  48, Train loss: 0.473, Test loss: 1.458, Test accuracy: 57.43
Round  48, Global train loss: 0.473, Global test loss: 1.906, Global test accuracy: 31.75
Round  49, Train loss: 0.500, Test loss: 1.459, Test accuracy: 57.69
Round  49, Global train loss: 0.500, Global test loss: 1.844, Global test accuracy: 37.96
Round  50, Train loss: 0.538, Test loss: 1.473, Test accuracy: 57.94
Round  50, Global train loss: 0.538, Global test loss: 2.087, Global test accuracy: 29.49
Round  51, Train loss: 0.495, Test loss: 1.483, Test accuracy: 57.87
Round  51, Global train loss: 0.495, Global test loss: 1.894, Global test accuracy: 28.53
Round  52, Train loss: 0.430, Test loss: 1.537, Test accuracy: 57.33
Round  52, Global train loss: 0.430, Global test loss: 1.891, Global test accuracy: 37.21
Round  53, Train loss: 0.635, Test loss: 1.533, Test accuracy: 57.19
Round  53, Global train loss: 0.635, Global test loss: 2.048, Global test accuracy: 33.50
Round  54, Train loss: 0.450, Test loss: 1.575, Test accuracy: 56.94
Round  54, Global train loss: 0.450, Global test loss: 1.876, Global test accuracy: 35.68
Round  55, Train loss: 0.532, Test loss: 1.584, Test accuracy: 56.19
Round  55, Global train loss: 0.532, Global test loss: 2.035, Global test accuracy: 20.06
Round  56, Train loss: 0.474, Test loss: 1.610, Test accuracy: 56.62
Round  56, Global train loss: 0.474, Global test loss: 2.077, Global test accuracy: 36.62
Round  57, Train loss: 0.311, Test loss: 1.596, Test accuracy: 56.68
Round  57, Global train loss: 0.311, Global test loss: 1.850, Global test accuracy: 31.61
Round  58, Train loss: 0.407, Test loss: 1.631, Test accuracy: 56.79
Round  58, Global train loss: 0.407, Global test loss: 1.901, Global test accuracy: 31.01
Round  59, Train loss: 0.404, Test loss: 1.640, Test accuracy: 56.83
Round  59, Global train loss: 0.404, Global test loss: 1.847, Global test accuracy: 37.94
Round  60, Train loss: 0.257, Test loss: 1.677, Test accuracy: 56.84
Round  60, Global train loss: 0.257, Global test loss: 1.759, Global test accuracy: 40.16
Round  61, Train loss: 0.210, Test loss: 1.685, Test accuracy: 57.20
Round  61, Global train loss: 0.210, Global test loss: 1.868, Global test accuracy: 32.50
Round  62, Train loss: 0.296, Test loss: 1.718, Test accuracy: 56.45
Round  62, Global train loss: 0.296, Global test loss: 1.887, Global test accuracy: 32.44
Round  63, Train loss: 0.286, Test loss: 1.781, Test accuracy: 56.51
Round  63, Global train loss: 0.286, Global test loss: 1.861, Global test accuracy: 34.84
Round  64, Train loss: 0.431, Test loss: 1.729, Test accuracy: 57.14
Round  64, Global train loss: 0.431, Global test loss: 1.993, Global test accuracy: 31.14
Round  65, Train loss: 0.282, Test loss: 1.777, Test accuracy: 57.05
Round  65, Global train loss: 0.282, Global test loss: 2.041, Global test accuracy: 25.67
Round  66, Train loss: 0.246, Test loss: 1.760, Test accuracy: 57.16
Round  66, Global train loss: 0.246, Global test loss: 1.857, Global test accuracy: 33.38
Round  67, Train loss: 0.281, Test loss: 1.783, Test accuracy: 57.22
Round  67, Global train loss: 0.281, Global test loss: 1.952, Global test accuracy: 29.07
Round  68, Train loss: 0.194, Test loss: 1.837, Test accuracy: 57.09
Round  68, Global train loss: 0.194, Global test loss: 2.103, Global test accuracy: 31.51
Round  69, Train loss: 0.581, Test loss: 1.867, Test accuracy: 56.88
Round  69, Global train loss: 0.581, Global test loss: 2.084, Global test accuracy: 21.99
Round  70, Train loss: 0.282, Test loss: 1.899, Test accuracy: 57.09
Round  70, Global train loss: 0.282, Global test loss: 1.923, Global test accuracy: 30.74
Round  71, Train loss: 0.514, Test loss: 1.947, Test accuracy: 56.90
Round  71, Global train loss: 0.514, Global test loss: 2.097, Global test accuracy: 29.26
Round  72, Train loss: 0.262, Test loss: 1.905, Test accuracy: 57.31
Round  72, Global train loss: 0.262, Global test loss: 1.912, Global test accuracy: 36.00
Round  73, Train loss: 0.236, Test loss: 1.929, Test accuracy: 56.86
Round  73, Global train loss: 0.236, Global test loss: 1.890, Global test accuracy: 35.37
Round  74, Train loss: 0.193, Test loss: 1.979, Test accuracy: 56.68
Round  74, Global train loss: 0.193, Global test loss: 1.954, Global test accuracy: 34.80
Round  75, Train loss: 0.281, Test loss: 2.010, Test accuracy: 56.91
Round  75, Global train loss: 0.281, Global test loss: 1.941, Global test accuracy: 35.90
Round  76, Train loss: 0.288, Test loss: 2.041, Test accuracy: 56.38
Round  76, Global train loss: 0.288, Global test loss: 1.799, Global test accuracy: 39.49
Round  77, Train loss: 0.251, Test loss: 2.120, Test accuracy: 56.01
Round  77, Global train loss: 0.251, Global test loss: 1.915, Global test accuracy: 33.47
Round  78, Train loss: 0.218, Test loss: 2.141, Test accuracy: 56.21
Round  78, Global train loss: 0.218, Global test loss: 2.017, Global test accuracy: 36.26
Round  79, Train loss: 0.329, Test loss: 2.133, Test accuracy: 56.23
Round  79, Global train loss: 0.329, Global test loss: 1.891, Global test accuracy: 32.49
Round  80, Train loss: 0.191, Test loss: 2.179, Test accuracy: 56.01
Round  80, Global train loss: 0.191, Global test loss: 1.913, Global test accuracy: 34.34
Round  81, Train loss: 0.257, Test loss: 2.195, Test accuracy: 56.23
Round  81, Global train loss: 0.257, Global test loss: 2.035, Global test accuracy: 29.09
Round  82, Train loss: 0.319, Test loss: 2.111, Test accuracy: 56.18
Round  82, Global train loss: 0.319, Global test loss: 1.946, Global test accuracy: 34.28
Round  83, Train loss: 0.140, Test loss: 2.156, Test accuracy: 56.11
Round  83, Global train loss: 0.140, Global test loss: 1.888, Global test accuracy: 33.01
Round  84, Train loss: 0.334, Test loss: 2.171, Test accuracy: 56.11
Round  84, Global train loss: 0.334, Global test loss: 1.929, Global test accuracy: 33.18
Round  85, Train loss: 0.163, Test loss: 2.178, Test accuracy: 56.00
Round  85, Global train loss: 0.163, Global test loss: 2.017, Global test accuracy: 31.91
Round  86, Train loss: 0.232, Test loss: 2.156, Test accuracy: 56.61
Round  86, Global train loss: 0.232, Global test loss: 1.967, Global test accuracy: 29.93
Round  87, Train loss: 0.197, Test loss: 2.171, Test accuracy: 56.75
Round  87, Global train loss: 0.197, Global test loss: 1.830, Global test accuracy: 35.61
Round  88, Train loss: 0.135, Test loss: 2.173, Test accuracy: 56.60
Round  88, Global train loss: 0.135, Global test loss: 1.741, Global test accuracy: 36.33
Round  89, Train loss: 0.300, Test loss: 2.193, Test accuracy: 56.15
Round  89, Global train loss: 0.300, Global test loss: 2.075, Global test accuracy: 25.86
Round  90, Train loss: 0.183, Test loss: 2.196, Test accuracy: 56.35
Round  90, Global train loss: 0.183, Global test loss: 1.995, Global test accuracy: 32.63
Round  91, Train loss: 0.112, Test loss: 2.263, Test accuracy: 56.21
Round  91, Global train loss: 0.112, Global test loss: 1.777, Global test accuracy: 36.10
Round  92, Train loss: 0.273, Test loss: 2.280, Test accuracy: 56.21
Round  92, Global train loss: 0.273, Global test loss: 1.983, Global test accuracy: 28.27
Round  93, Train loss: 0.134, Test loss: 2.322, Test accuracy: 56.02
Round  93, Global train loss: 0.134, Global test loss: 1.851, Global test accuracy: 34.74
Round  94, Train loss: 0.124, Test loss: 2.265, Test accuracy: 56.08
Round  94, Global train loss: 0.124, Global test loss: 1.908, Global test accuracy: 41.74
Round  95, Train loss: 0.131, Test loss: 2.334, Test accuracy: 56.28
Round  95, Global train loss: 0.131, Global test loss: 1.931, Global test accuracy: 35.72
Round  96, Train loss: 0.162, Test loss: 2.356, Test accuracy: 56.44
Round  96, Global train loss: 0.162, Global test loss: 1.919, Global test accuracy: 30.82
Round  97, Train loss: 0.210, Test loss: 2.346, Test accuracy: 56.58
Round  97, Global train loss: 0.210, Global test loss: 2.136, Global test accuracy: 24.54
Round  98, Train loss: 0.170, Test loss: 2.354, Test accuracy: 56.42
Round  98, Global train loss: 0.170, Global test loss: 2.000, Global test accuracy: 32.97
Round  99, Train loss: 0.112, Test loss: 2.372, Test accuracy: 56.70
Round  99, Global train loss: 0.112, Global test loss: 1.877, Global test accuracy: 36.88
Final Round, Train loss: 0.146, Test loss: 2.542, Test accuracy: 56.07
Final Round, Global train loss: 0.146, Global test loss: 1.877, Global test accuracy: 36.88
Average accuracy final 10 rounds: 56.32900000000001 

Average global accuracy final 10 rounds: 33.441 

1669.291647195816
[1.5722432136535645, 3.144486427307129, 4.42500638961792, 5.705526351928711, 6.97745418548584, 8.249382019042969, 9.529109477996826, 10.808836936950684, 12.086369276046753, 13.363901615142822, 14.654011726379395, 15.944121837615967, 17.234362363815308, 18.52460289001465, 19.8056001663208, 21.086597442626953, 22.384407997131348, 23.682218551635742, 24.99366021156311, 26.30510187149048, 27.61117672920227, 28.917251586914062, 30.20868229866028, 31.500113010406494, 32.805654525756836, 34.11119604110718, 35.391271114349365, 36.67134618759155, 37.96749472618103, 39.26364326477051, 40.56625699996948, 41.86887073516846, 43.16511940956116, 44.46136808395386, 45.75209164619446, 47.04281520843506, 48.33620238304138, 49.629589557647705, 50.916205167770386, 52.202820777893066, 53.489851236343384, 54.7768816947937, 56.06877160072327, 57.36066150665283, 58.6666738986969, 59.97268629074097, 61.25447964668274, 62.53627300262451, 63.81244230270386, 65.0886116027832, 66.35816597938538, 67.62772035598755, 68.91394424438477, 70.20016813278198, 71.47098875045776, 72.74180936813354, 74.02773261070251, 75.31365585327148, 76.56070327758789, 77.8077507019043, 79.10188150405884, 80.39601230621338, 81.67551898956299, 82.9550256729126, 84.2466173171997, 85.53820896148682, 86.84069013595581, 88.1431713104248, 89.43623399734497, 90.72929668426514, 91.96406078338623, 93.19882488250732, 94.4704999923706, 95.74217510223389, 97.02489638328552, 98.30761766433716, 99.60024166107178, 100.8928656578064, 102.180006980896, 103.4671483039856, 104.77223825454712, 106.07732820510864, 107.370521068573, 108.66371393203735, 109.9661705493927, 111.26862716674805, 112.57927203178406, 113.88991689682007, 115.18689703941345, 116.48387718200684, 117.7613172531128, 119.03875732421875, 120.34039759635925, 121.64203786849976, 122.98717713356018, 124.3323163986206, 125.6228199005127, 126.91332340240479, 128.2058882713318, 129.4984531402588, 130.85643482208252, 132.21441650390625, 133.5090367794037, 134.80365705490112, 136.18026971817017, 137.5568823814392, 138.8528037071228, 140.1487250328064, 141.35827684402466, 142.56782865524292, 143.82167148590088, 145.07551431655884, 146.3040792942047, 147.5326442718506, 148.7650556564331, 149.99746704101562, 151.2178726196289, 152.4382781982422, 153.74030590057373, 155.04233360290527, 156.32278084754944, 157.6032280921936, 158.90358781814575, 160.2039475440979, 161.51637935638428, 162.82881116867065, 164.14067769050598, 165.4525442123413, 166.74245929718018, 168.03237438201904, 169.32760787010193, 170.62284135818481, 171.90775179862976, 173.1926622390747, 174.4650411605835, 175.73742008209229, 177.02275681495667, 178.30809354782104, 179.61032700538635, 180.91256046295166, 182.21252179145813, 183.5124831199646, 184.81660795211792, 186.12073278427124, 187.41585659980774, 188.71098041534424, 190.0015573501587, 191.29213428497314, 192.61199617385864, 193.93185806274414, 195.23012566566467, 196.5283932685852, 197.8086051940918, 199.0888171195984, 200.39054679870605, 201.69227647781372, 202.9810700416565, 204.26986360549927, 205.56033372879028, 206.8508038520813, 208.13092756271362, 209.41105127334595, 210.7089385986328, 212.00682592391968, 213.28938746452332, 214.57194900512695, 215.874924659729, 217.17790031433105, 218.47305393218994, 219.76820755004883, 221.0594711303711, 222.35073471069336, 223.65672540664673, 224.9627161026001, 226.26595878601074, 227.5692014694214, 228.87516117095947, 230.18112087249756, 231.49933052062988, 232.8175401687622, 234.1176793575287, 235.41781854629517, 236.72147464752197, 238.02513074874878, 239.33158946037292, 240.63804817199707, 241.9329309463501, 243.22781372070312, 244.50287461280823, 245.77793550491333, 247.04305982589722, 248.3081841468811, 249.42602467536926, 250.54386520385742, 251.67228412628174, 252.80070304870605, 253.89242601394653, 254.984148979187, 256.0574793815613, 257.13080978393555, 259.40106678009033, 261.6713237762451]
[24.45, 24.45, 35.47, 35.47, 35.27, 35.27, 39.79, 39.79, 45.42, 45.42, 44.69, 44.69, 46.48, 46.48, 48.05, 48.05, 46.96, 46.96, 50.66, 50.66, 50.41, 50.41, 50.48, 50.48, 52.53, 52.53, 53.55, 53.55, 54.13, 54.13, 54.97, 54.97, 55.52, 55.52, 55.87, 55.87, 56.01, 56.01, 55.87, 55.87, 56.28, 56.28, 55.96, 55.96, 56.23, 56.23, 56.75, 56.75, 56.5, 56.5, 56.31, 56.31, 56.6, 56.6, 57.64, 57.64, 57.29, 57.29, 57.18, 57.18, 57.43, 57.43, 57.11, 57.11, 56.92, 56.92, 56.58, 56.58, 56.07, 56.07, 56.14, 56.14, 56.99, 56.99, 57.24, 57.24, 57.02, 57.02, 57.79, 57.79, 58.41, 58.41, 57.71, 57.71, 57.98, 57.98, 57.45, 57.45, 58.07, 58.07, 58.01, 58.01, 57.84, 57.84, 57.74, 57.74, 57.43, 57.43, 57.69, 57.69, 57.94, 57.94, 57.87, 57.87, 57.33, 57.33, 57.19, 57.19, 56.94, 56.94, 56.19, 56.19, 56.62, 56.62, 56.68, 56.68, 56.79, 56.79, 56.83, 56.83, 56.84, 56.84, 57.2, 57.2, 56.45, 56.45, 56.51, 56.51, 57.14, 57.14, 57.05, 57.05, 57.16, 57.16, 57.22, 57.22, 57.09, 57.09, 56.88, 56.88, 57.09, 57.09, 56.9, 56.9, 57.31, 57.31, 56.86, 56.86, 56.68, 56.68, 56.91, 56.91, 56.38, 56.38, 56.01, 56.01, 56.21, 56.21, 56.23, 56.23, 56.01, 56.01, 56.23, 56.23, 56.18, 56.18, 56.11, 56.11, 56.11, 56.11, 56.0, 56.0, 56.61, 56.61, 56.75, 56.75, 56.6, 56.6, 56.15, 56.15, 56.35, 56.35, 56.21, 56.21, 56.21, 56.21, 56.02, 56.02, 56.08, 56.08, 56.28, 56.28, 56.44, 56.44, 56.58, 56.58, 56.42, 56.42, 56.7, 56.7, 56.07, 56.07]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 0, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 12, noise    level: 0.4000 
   Client 17, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.637, Test loss: 2.025, Test accuracy: 24.57
Round   0, Global train loss: 1.637, Global test loss: 2.210, Global test accuracy: 23.58
Round   1, Train loss: 1.448, Test loss: 1.686, Test accuracy: 35.58
Round   1, Global train loss: 1.448, Global test loss: 1.988, Global test accuracy: 30.15
Round   2, Train loss: 1.329, Test loss: 1.586, Test accuracy: 36.58
Round   2, Global train loss: 1.329, Global test loss: 2.071, Global test accuracy: 25.74
Round   3, Train loss: 1.337, Test loss: 1.419, Test accuracy: 41.47
Round   3, Global train loss: 1.337, Global test loss: 1.893, Global test accuracy: 31.85
Round   4, Train loss: 1.194, Test loss: 1.277, Test accuracy: 49.89
Round   4, Global train loss: 1.194, Global test loss: 1.817, Global test accuracy: 38.73
Round   5, Train loss: 1.189, Test loss: 1.232, Test accuracy: 51.23
Round   5, Global train loss: 1.189, Global test loss: 1.857, Global test accuracy: 36.58
Round   6, Train loss: 1.055, Test loss: 1.198, Test accuracy: 53.26
Round   6, Global train loss: 1.055, Global test loss: 1.761, Global test accuracy: 40.82
Round   7, Train loss: 1.156, Test loss: 1.132, Test accuracy: 55.98
Round   7, Global train loss: 1.156, Global test loss: 1.656, Global test accuracy: 41.59
Round   8, Train loss: 1.031, Test loss: 1.145, Test accuracy: 55.26
Round   8, Global train loss: 1.031, Global test loss: 1.585, Global test accuracy: 44.04
Round   9, Train loss: 0.996, Test loss: 1.070, Test accuracy: 58.41
Round   9, Global train loss: 0.996, Global test loss: 1.548, Global test accuracy: 46.41
Round  10, Train loss: 0.981, Test loss: 1.056, Test accuracy: 58.59
Round  10, Global train loss: 0.981, Global test loss: 1.519, Global test accuracy: 46.75
Round  11, Train loss: 1.018, Test loss: 1.040, Test accuracy: 59.48
Round  11, Global train loss: 1.018, Global test loss: 1.624, Global test accuracy: 44.48
Round  12, Train loss: 1.046, Test loss: 0.986, Test accuracy: 61.37
Round  12, Global train loss: 1.046, Global test loss: 1.437, Global test accuracy: 50.45
Round  13, Train loss: 1.038, Test loss: 0.982, Test accuracy: 61.88
Round  13, Global train loss: 1.038, Global test loss: 1.370, Global test accuracy: 54.23
Round  14, Train loss: 0.863, Test loss: 0.972, Test accuracy: 61.98
Round  14, Global train loss: 0.863, Global test loss: 1.424, Global test accuracy: 53.28
Round  15, Train loss: 0.876, Test loss: 0.973, Test accuracy: 62.52
Round  15, Global train loss: 0.876, Global test loss: 1.419, Global test accuracy: 52.01
Round  16, Train loss: 0.876, Test loss: 0.963, Test accuracy: 62.93
Round  16, Global train loss: 0.876, Global test loss: 1.454, Global test accuracy: 50.11
Round  17, Train loss: 0.965, Test loss: 0.941, Test accuracy: 64.01
Round  17, Global train loss: 0.965, Global test loss: 1.343, Global test accuracy: 54.53
Round  18, Train loss: 0.978, Test loss: 0.914, Test accuracy: 65.06
Round  18, Global train loss: 0.978, Global test loss: 1.326, Global test accuracy: 54.63
Round  19, Train loss: 0.881, Test loss: 0.917, Test accuracy: 65.07
Round  19, Global train loss: 0.881, Global test loss: 1.333, Global test accuracy: 54.34
Round  20, Train loss: 0.867, Test loss: 0.894, Test accuracy: 66.50
Round  20, Global train loss: 0.867, Global test loss: 1.221, Global test accuracy: 58.76
Round  21, Train loss: 0.797, Test loss: 0.884, Test accuracy: 67.03
Round  21, Global train loss: 0.797, Global test loss: 1.398, Global test accuracy: 52.94
Round  22, Train loss: 0.842, Test loss: 0.858, Test accuracy: 67.86
Round  22, Global train loss: 0.842, Global test loss: 1.203, Global test accuracy: 57.70
Round  23, Train loss: 0.833, Test loss: 0.852, Test accuracy: 68.10
Round  23, Global train loss: 0.833, Global test loss: 1.291, Global test accuracy: 56.20
Round  24, Train loss: 0.784, Test loss: 0.849, Test accuracy: 68.45
Round  24, Global train loss: 0.784, Global test loss: 1.252, Global test accuracy: 56.92
Round  25, Train loss: 0.783, Test loss: 0.845, Test accuracy: 68.67
Round  25, Global train loss: 0.783, Global test loss: 1.263, Global test accuracy: 58.78
Round  26, Train loss: 0.779, Test loss: 0.857, Test accuracy: 68.50
Round  26, Global train loss: 0.779, Global test loss: 1.229, Global test accuracy: 59.36
Round  27, Train loss: 0.713, Test loss: 0.832, Test accuracy: 69.47
Round  27, Global train loss: 0.713, Global test loss: 1.335, Global test accuracy: 55.73
Round  28, Train loss: 0.733, Test loss: 0.834, Test accuracy: 69.35
Round  28, Global train loss: 0.733, Global test loss: 1.213, Global test accuracy: 59.02
Round  29, Train loss: 0.623, Test loss: 0.834, Test accuracy: 69.39
Round  29, Global train loss: 0.623, Global test loss: 1.380, Global test accuracy: 54.95
Round  30, Train loss: 0.779, Test loss: 0.829, Test accuracy: 69.45
Round  30, Global train loss: 0.779, Global test loss: 1.130, Global test accuracy: 62.11
Round  31, Train loss: 0.666, Test loss: 0.809, Test accuracy: 70.64
Round  31, Global train loss: 0.666, Global test loss: 1.230, Global test accuracy: 58.49
Round  32, Train loss: 0.606, Test loss: 0.802, Test accuracy: 71.03
Round  32, Global train loss: 0.606, Global test loss: 1.376, Global test accuracy: 54.00
Round  33, Train loss: 0.624, Test loss: 0.821, Test accuracy: 70.35
Round  33, Global train loss: 0.624, Global test loss: 1.156, Global test accuracy: 61.60
Round  34, Train loss: 0.787, Test loss: 0.823, Test accuracy: 70.31
Round  34, Global train loss: 0.787, Global test loss: 1.437, Global test accuracy: 52.81
Round  35, Train loss: 0.614, Test loss: 0.820, Test accuracy: 70.45
Round  35, Global train loss: 0.614, Global test loss: 1.332, Global test accuracy: 55.89
Round  36, Train loss: 0.673, Test loss: 0.814, Test accuracy: 70.81
Round  36, Global train loss: 0.673, Global test loss: 1.333, Global test accuracy: 56.54
Round  37, Train loss: 0.722, Test loss: 0.813, Test accuracy: 70.60
Round  37, Global train loss: 0.722, Global test loss: 1.193, Global test accuracy: 59.55
Round  38, Train loss: 0.713, Test loss: 0.820, Test accuracy: 70.36
Round  38, Global train loss: 0.713, Global test loss: 1.144, Global test accuracy: 61.48
Round  39, Train loss: 0.677, Test loss: 0.824, Test accuracy: 70.59
Round  39, Global train loss: 0.677, Global test loss: 1.234, Global test accuracy: 58.50
Round  40, Train loss: 0.602, Test loss: 0.834, Test accuracy: 70.60
Round  40, Global train loss: 0.602, Global test loss: 1.150, Global test accuracy: 62.23
Round  41, Train loss: 0.618, Test loss: 0.837, Test accuracy: 70.54
Round  41, Global train loss: 0.618, Global test loss: 1.330, Global test accuracy: 57.35
Round  42, Train loss: 0.640, Test loss: 0.819, Test accuracy: 71.14
Round  42, Global train loss: 0.640, Global test loss: 1.240, Global test accuracy: 59.50
Round  43, Train loss: 0.706, Test loss: 0.829, Test accuracy: 71.58
Round  43, Global train loss: 0.706, Global test loss: 1.223, Global test accuracy: 58.33
Round  44, Train loss: 0.660, Test loss: 0.823, Test accuracy: 71.60
Round  44, Global train loss: 0.660, Global test loss: 1.252, Global test accuracy: 58.14
Round  45, Train loss: 0.590, Test loss: 0.823, Test accuracy: 71.61
Round  45, Global train loss: 0.590, Global test loss: 1.064, Global test accuracy: 64.19
Round  46, Train loss: 0.582, Test loss: 0.837, Test accuracy: 71.21
Round  46, Global train loss: 0.582, Global test loss: 1.098, Global test accuracy: 63.38
Round  47, Train loss: 0.585, Test loss: 0.849, Test accuracy: 71.11
Round  47, Global train loss: 0.585, Global test loss: 1.586, Global test accuracy: 53.68
Round  48, Train loss: 0.612, Test loss: 0.846, Test accuracy: 71.13
Round  48, Global train loss: 0.612, Global test loss: 1.154, Global test accuracy: 62.99
Round  49, Train loss: 0.542, Test loss: 0.845, Test accuracy: 71.39
Round  49, Global train loss: 0.542, Global test loss: 1.137, Global test accuracy: 63.69
Round  50, Train loss: 0.558, Test loss: 0.830, Test accuracy: 72.11
Round  50, Global train loss: 0.558, Global test loss: 1.280, Global test accuracy: 59.35
Round  51, Train loss: 0.571, Test loss: 0.836, Test accuracy: 71.76
Round  51, Global train loss: 0.571, Global test loss: 1.119, Global test accuracy: 63.42
Round  52, Train loss: 0.544, Test loss: 0.838, Test accuracy: 72.08
Round  52, Global train loss: 0.544, Global test loss: 1.143, Global test accuracy: 63.87
Round  53, Train loss: 0.565, Test loss: 0.831, Test accuracy: 71.88
Round  53, Global train loss: 0.565, Global test loss: 1.227, Global test accuracy: 61.94
Round  54, Train loss: 0.527, Test loss: 0.831, Test accuracy: 71.91
Round  54, Global train loss: 0.527, Global test loss: 1.111, Global test accuracy: 64.30
Round  55, Train loss: 0.552, Test loss: 0.832, Test accuracy: 71.82
Round  55, Global train loss: 0.552, Global test loss: 1.245, Global test accuracy: 61.13
Round  56, Train loss: 0.549, Test loss: 0.837, Test accuracy: 72.17
Round  56, Global train loss: 0.549, Global test loss: 1.236, Global test accuracy: 61.77
Round  57, Train loss: 0.466, Test loss: 0.848, Test accuracy: 72.23
Round  57, Global train loss: 0.466, Global test loss: 1.110, Global test accuracy: 65.21
Round  58, Train loss: 0.520, Test loss: 0.830, Test accuracy: 72.69
Round  58, Global train loss: 0.520, Global test loss: 1.091, Global test accuracy: 65.10
Round  59, Train loss: 0.487, Test loss: 0.849, Test accuracy: 72.39
Round  59, Global train loss: 0.487, Global test loss: 1.152, Global test accuracy: 64.60
Round  60, Train loss: 0.488, Test loss: 0.868, Test accuracy: 72.09
Round  60, Global train loss: 0.488, Global test loss: 1.087, Global test accuracy: 65.98
Round  61, Train loss: 0.454, Test loss: 0.843, Test accuracy: 72.56
Round  61, Global train loss: 0.454, Global test loss: 1.087, Global test accuracy: 65.25
Round  62, Train loss: 0.417, Test loss: 0.834, Test accuracy: 72.95
Round  62, Global train loss: 0.417, Global test loss: 1.293, Global test accuracy: 64.21
Round  63, Train loss: 0.463, Test loss: 0.849, Test accuracy: 72.58
Round  63, Global train loss: 0.463, Global test loss: 1.073, Global test accuracy: 66.03
Round  64, Train loss: 0.498, Test loss: 0.848, Test accuracy: 72.50
Round  64, Global train loss: 0.498, Global test loss: 1.079, Global test accuracy: 65.60
Round  65, Train loss: 0.480, Test loss: 0.830, Test accuracy: 73.17
Round  65, Global train loss: 0.480, Global test loss: 1.142, Global test accuracy: 63.39
Round  66, Train loss: 0.409, Test loss: 0.841, Test accuracy: 72.84
Round  66, Global train loss: 0.409, Global test loss: 1.079, Global test accuracy: 66.09
Round  67, Train loss: 0.433, Test loss: 0.849, Test accuracy: 72.49
Round  67, Global train loss: 0.433, Global test loss: 1.213, Global test accuracy: 62.84
Round  68, Train loss: 0.444, Test loss: 0.841, Test accuracy: 73.12
Round  68, Global train loss: 0.444, Global test loss: 1.181, Global test accuracy: 64.28
Round  69, Train loss: 0.570, Test loss: 0.852, Test accuracy: 72.79
Round  69, Global train loss: 0.570, Global test loss: 1.153, Global test accuracy: 63.46
Round  70, Train loss: 0.415, Test loss: 0.865, Test accuracy: 72.46
Round  70, Global train loss: 0.415, Global test loss: 1.095, Global test accuracy: 66.06
Round  71, Train loss: 0.507, Test loss: 0.881, Test accuracy: 72.41
Round  71, Global train loss: 0.507, Global test loss: 1.192, Global test accuracy: 63.52
Round  72, Train loss: 0.419, Test loss: 0.864, Test accuracy: 73.41
Round  72, Global train loss: 0.419, Global test loss: 1.242, Global test accuracy: 63.20
Round  73, Train loss: 0.411, Test loss: 0.863, Test accuracy: 73.84
Round  73, Global train loss: 0.411, Global test loss: 1.211, Global test accuracy: 64.38
Round  74, Train loss: 0.371, Test loss: 0.879, Test accuracy: 73.69
Round  74, Global train loss: 0.371, Global test loss: 1.381, Global test accuracy: 62.74
Round  75, Train loss: 0.431, Test loss: 0.869, Test accuracy: 73.80
Round  75, Global train loss: 0.431, Global test loss: 1.094, Global test accuracy: 66.48
Round  76, Train loss: 0.385, Test loss: 0.888, Test accuracy: 73.29
Round  76, Global train loss: 0.385, Global test loss: 1.128, Global test accuracy: 66.80
Round  77, Train loss: 0.408, Test loss: 0.879, Test accuracy: 73.15
Round  77, Global train loss: 0.408, Global test loss: 1.243, Global test accuracy: 64.82
Round  78, Train loss: 0.414, Test loss: 0.888, Test accuracy: 73.17
Round  78, Global train loss: 0.414, Global test loss: 1.400, Global test accuracy: 60.06
Round  79, Train loss: 0.433, Test loss: 0.899, Test accuracy: 73.33
Round  79, Global train loss: 0.433, Global test loss: 1.225, Global test accuracy: 64.62
Round  80, Train loss: 0.415, Test loss: 0.886, Test accuracy: 73.20
Round  80, Global train loss: 0.415, Global test loss: 1.141, Global test accuracy: 65.24
Round  81, Train loss: 0.395, Test loss: 0.907, Test accuracy: 72.82
Round  81, Global train loss: 0.395, Global test loss: 1.436, Global test accuracy: 61.59
Round  82, Train loss: 0.419, Test loss: 0.910, Test accuracy: 72.84
Round  82, Global train loss: 0.419, Global test loss: 1.170, Global test accuracy: 65.48
Round  83, Train loss: 0.367, Test loss: 0.897, Test accuracy: 73.03
Round  83, Global train loss: 0.367, Global test loss: 1.185, Global test accuracy: 65.05
Round  84, Train loss: 0.470, Test loss: 0.893, Test accuracy: 73.18
Round  84, Global train loss: 0.470, Global test loss: 1.140, Global test accuracy: 65.11
Round  85, Train loss: 0.323, Test loss: 0.888, Test accuracy: 73.53
Round  85, Global train loss: 0.323, Global test loss: 1.193, Global test accuracy: 65.72
Round  86, Train loss: 0.414, Test loss: 0.886, Test accuracy: 73.79
Round  86, Global train loss: 0.414, Global test loss: 1.209, Global test accuracy: 64.08
Round  87, Train loss: 0.393, Test loss: 0.882, Test accuracy: 74.02
Round  87, Global train loss: 0.393, Global test loss: 1.139, Global test accuracy: 66.74
Round  88, Train loss: 0.373, Test loss: 0.870, Test accuracy: 74.25
Round  88, Global train loss: 0.373, Global test loss: 1.102, Global test accuracy: 67.35
Round  89, Train loss: 0.412, Test loss: 0.869, Test accuracy: 74.78
Round  89, Global train loss: 0.412, Global test loss: 1.189, Global test accuracy: 65.22
Round  90, Train loss: 0.347, Test loss: 0.861, Test accuracy: 75.11
Round  90, Global train loss: 0.347, Global test loss: 1.199, Global test accuracy: 65.88
Round  91, Train loss: 0.362, Test loss: 0.846, Test accuracy: 75.15
Round  91, Global train loss: 0.362, Global test loss: 1.129, Global test accuracy: 66.80
Round  92, Train loss: 0.477, Test loss: 0.856, Test accuracy: 74.99
Round  92, Global train loss: 0.477, Global test loss: 1.139, Global test accuracy: 65.79
Round  93, Train loss: 0.315, Test loss: 0.860, Test accuracy: 74.85
Round  93, Global train loss: 0.315, Global test loss: 1.191, Global test accuracy: 67.26
Round  94, Train loss: 0.331, Test loss: 0.860, Test accuracy: 75.20
Round  94, Global train loss: 0.331, Global test loss: 1.222, Global test accuracy: 64.78
Round  95, Train loss: 0.293, Test loss: 0.872, Test accuracy: 74.81
Round  95, Global train loss: 0.293, Global test loss: 1.148, Global test accuracy: 67.40
Round  96, Train loss: 0.352, Test loss: 0.882, Test accuracy: 75.15
Round  96, Global train loss: 0.352, Global test loss: 1.168, Global test accuracy: 66.50
Round  97, Train loss: 0.422, Test loss: 0.893, Test accuracy: 75.27
Round  97, Global train loss: 0.422, Global test loss: 1.313, Global test accuracy: 63.90
Round  98, Train loss: 0.315, Test loss: 0.893, Test accuracy: 75.23
Round  98, Global train loss: 0.315, Global test loss: 1.281, Global test accuracy: 65.90
Round  99, Train loss: 0.340, Test loss: 0.922, Test accuracy: 74.41
Round  99, Global train loss: 0.340, Global test loss: 1.209, Global test accuracy: 66.34
Final Round, Train loss: 0.288, Test loss: 0.960, Test accuracy: 74.28
Final Round, Global train loss: 0.288, Global test loss: 1.209, Global test accuracy: 66.34
Average accuracy final 10 rounds: 75.01700000000001 

Average global accuracy final 10 rounds: 66.055 

1657.3572783470154
[1.5539648532867432, 3.1079297065734863, 4.361944675445557, 5.615959644317627, 6.892035484313965, 8.168111324310303, 9.435189723968506, 10.702268123626709, 11.957399129867554, 13.212530136108398, 14.351511478424072, 15.490492820739746, 16.570144653320312, 17.64979648590088, 18.78235101699829, 19.914905548095703, 21.163304567337036, 22.41170358657837, 23.76569890975952, 25.119694232940674, 26.32682728767395, 27.533960342407227, 28.76156759262085, 29.989174842834473, 31.232259035110474, 32.475343227386475, 33.72787952423096, 34.98041582107544, 36.225611209869385, 37.47080659866333, 38.738590478897095, 40.00637435913086, 41.28890943527222, 42.571444511413574, 43.80908131599426, 45.04671812057495, 46.287233114242554, 47.527748107910156, 48.77249813079834, 50.01724815368652, 51.276673793792725, 52.536099433898926, 53.77462148666382, 55.01314353942871, 56.259862661361694, 57.50658178329468, 58.7774863243103, 60.04839086532593, 61.28489637374878, 62.52140188217163, 63.78636980056763, 65.05133771896362, 66.30044198036194, 67.54954624176025, 68.82723355293274, 70.10492086410522, 71.45806455612183, 72.81120824813843, 73.97228264808655, 75.13335704803467, 76.28103709220886, 77.42871713638306, 78.64865922927856, 79.86860132217407, 81.10531044006348, 82.34201955795288, 83.72587060928345, 85.10972166061401, 86.18844771385193, 87.26717376708984, 88.52204060554504, 89.77690744400024, 90.98364877700806, 92.19039011001587, 93.35856437683105, 94.52673864364624, 95.71133375167847, 96.8959288597107, 98.15270066261292, 99.40947246551514, 100.63934350013733, 101.86921453475952, 103.16345715522766, 104.4576997756958, 105.62671709060669, 106.79573440551758, 107.94657397270203, 109.09741353988647, 110.25940752029419, 111.4214015007019, 112.57778549194336, 113.73416948318481, 114.82099175453186, 115.9078140258789, 116.99318027496338, 118.07854652404785, 119.3410234451294, 120.60350036621094, 121.82347011566162, 123.0434398651123, 124.23353004455566, 125.42362022399902, 126.58302617073059, 127.74243211746216, 128.8978488445282, 130.05326557159424, 131.32153248786926, 132.5897994041443, 133.83245515823364, 135.075110912323, 136.2664179801941, 137.45772504806519, 138.59854388237, 139.7393627166748, 140.9386796951294, 142.13799667358398, 143.57651257514954, 145.0150284767151, 146.3217556476593, 147.62848281860352, 148.84898447990417, 150.06948614120483, 151.30211210250854, 152.53473806381226, 153.7364320755005, 154.93812608718872, 156.2034683227539, 157.4688105583191, 158.6541726589203, 159.83953475952148, 160.9976291656494, 162.15572357177734, 163.32219648361206, 164.48866939544678, 165.7185091972351, 166.94834899902344, 168.17386722564697, 169.3993854522705, 170.64023542404175, 171.881085395813, 173.08916521072388, 174.29724502563477, 175.4627754688263, 176.62830591201782, 177.803777217865, 178.97924852371216, 180.07408165931702, 181.16891479492188, 182.2734386920929, 183.37796258926392, 184.46535181999207, 185.55274105072021, 186.70519161224365, 187.8576421737671, 189.1325421333313, 190.4074420928955, 191.65449905395508, 192.90155601501465, 194.1209056377411, 195.34025526046753, 196.55228233337402, 197.76430940628052, 198.94225478172302, 200.12020015716553, 201.272052526474, 202.42390489578247, 203.65732312202454, 204.8907413482666, 206.0276644229889, 207.16458749771118, 208.34601736068726, 209.52744722366333, 210.67134618759155, 211.81524515151978, 212.97318530082703, 214.13112545013428, 215.23941612243652, 216.34770679473877, 217.51141667366028, 218.6751265525818, 219.85932564735413, 221.04352474212646, 222.31455945968628, 223.5855941772461, 224.82696914672852, 226.06834411621094, 227.27703666687012, 228.4857292175293, 229.75289225578308, 231.02005529403687, 232.19644379615784, 233.3728322982788, 234.55863213539124, 235.74443197250366, 236.88517498970032, 238.02591800689697, 239.33445024490356, 240.64298248291016, 241.90935015678406, 243.17571783065796, 245.70539951324463, 248.2350811958313]
[24.57, 24.57, 35.58, 35.58, 36.58, 36.58, 41.47, 41.47, 49.89, 49.89, 51.23, 51.23, 53.26, 53.26, 55.98, 55.98, 55.26, 55.26, 58.41, 58.41, 58.59, 58.59, 59.48, 59.48, 61.37, 61.37, 61.88, 61.88, 61.98, 61.98, 62.52, 62.52, 62.93, 62.93, 64.01, 64.01, 65.06, 65.06, 65.07, 65.07, 66.5, 66.5, 67.03, 67.03, 67.86, 67.86, 68.1, 68.1, 68.45, 68.45, 68.67, 68.67, 68.5, 68.5, 69.47, 69.47, 69.35, 69.35, 69.39, 69.39, 69.45, 69.45, 70.64, 70.64, 71.03, 71.03, 70.35, 70.35, 70.31, 70.31, 70.45, 70.45, 70.81, 70.81, 70.6, 70.6, 70.36, 70.36, 70.59, 70.59, 70.6, 70.6, 70.54, 70.54, 71.14, 71.14, 71.58, 71.58, 71.6, 71.6, 71.61, 71.61, 71.21, 71.21, 71.11, 71.11, 71.13, 71.13, 71.39, 71.39, 72.11, 72.11, 71.76, 71.76, 72.08, 72.08, 71.88, 71.88, 71.91, 71.91, 71.82, 71.82, 72.17, 72.17, 72.23, 72.23, 72.69, 72.69, 72.39, 72.39, 72.09, 72.09, 72.56, 72.56, 72.95, 72.95, 72.58, 72.58, 72.5, 72.5, 73.17, 73.17, 72.84, 72.84, 72.49, 72.49, 73.12, 73.12, 72.79, 72.79, 72.46, 72.46, 72.41, 72.41, 73.41, 73.41, 73.84, 73.84, 73.69, 73.69, 73.8, 73.8, 73.29, 73.29, 73.15, 73.15, 73.17, 73.17, 73.33, 73.33, 73.2, 73.2, 72.82, 72.82, 72.84, 72.84, 73.03, 73.03, 73.18, 73.18, 73.53, 73.53, 73.79, 73.79, 74.02, 74.02, 74.25, 74.25, 74.78, 74.78, 75.11, 75.11, 75.15, 75.15, 74.99, 74.99, 74.85, 74.85, 75.2, 75.2, 74.81, 74.81, 75.15, 75.15, 75.27, 75.27, 75.23, 75.23, 74.41, 74.41, 74.28, 74.28]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 10, noise    level: 0.4000 
   Client 17, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 16, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.601, Test loss: 2.092, Test accuracy: 25.60
Round   0, Global train loss: 1.601, Global test loss: 2.273, Global test accuracy: 24.42
Round   1, Train loss: 1.461, Test loss: 1.676, Test accuracy: 36.07
Round   1, Global train loss: 1.461, Global test loss: 1.974, Global test accuracy: 32.03
Round   2, Train loss: 1.388, Test loss: 1.546, Test accuracy: 37.77
Round   2, Global train loss: 1.388, Global test loss: 1.987, Global test accuracy: 26.98
Round   3, Train loss: 1.287, Test loss: 1.423, Test accuracy: 42.55
Round   3, Global train loss: 1.287, Global test loss: 1.888, Global test accuracy: 31.80
Round   4, Train loss: 1.259, Test loss: 1.282, Test accuracy: 49.63
Round   4, Global train loss: 1.259, Global test loss: 1.774, Global test accuracy: 39.47
Round   5, Train loss: 1.281, Test loss: 1.236, Test accuracy: 51.47
Round   5, Global train loss: 1.281, Global test loss: 1.799, Global test accuracy: 38.71
Round   6, Train loss: 1.107, Test loss: 1.216, Test accuracy: 52.49
Round   6, Global train loss: 1.107, Global test loss: 1.715, Global test accuracy: 42.45
Round   7, Train loss: 1.243, Test loss: 1.142, Test accuracy: 55.12
Round   7, Global train loss: 1.243, Global test loss: 1.677, Global test accuracy: 39.44
Round   8, Train loss: 1.144, Test loss: 1.172, Test accuracy: 54.23
Round   8, Global train loss: 1.144, Global test loss: 1.550, Global test accuracy: 46.53
Round   9, Train loss: 1.006, Test loss: 1.114, Test accuracy: 56.16
Round   9, Global train loss: 1.006, Global test loss: 1.571, Global test accuracy: 46.94
Round  10, Train loss: 1.082, Test loss: 1.097, Test accuracy: 56.83
Round  10, Global train loss: 1.082, Global test loss: 1.509, Global test accuracy: 48.30
Round  11, Train loss: 1.026, Test loss: 1.065, Test accuracy: 58.60
Round  11, Global train loss: 1.026, Global test loss: 1.515, Global test accuracy: 48.27
Round  12, Train loss: 1.094, Test loss: 1.022, Test accuracy: 59.97
Round  12, Global train loss: 1.094, Global test loss: 1.477, Global test accuracy: 49.17
Round  13, Train loss: 1.024, Test loss: 1.009, Test accuracy: 60.68
Round  13, Global train loss: 1.024, Global test loss: 1.413, Global test accuracy: 51.23
Round  14, Train loss: 1.048, Test loss: 1.011, Test accuracy: 60.99
Round  14, Global train loss: 1.048, Global test loss: 1.436, Global test accuracy: 52.67
Round  15, Train loss: 0.978, Test loss: 1.014, Test accuracy: 61.19
Round  15, Global train loss: 0.978, Global test loss: 1.427, Global test accuracy: 51.47
Round  16, Train loss: 1.021, Test loss: 0.996, Test accuracy: 62.06
Round  16, Global train loss: 1.021, Global test loss: 1.420, Global test accuracy: 53.47
Round  17, Train loss: 0.984, Test loss: 0.977, Test accuracy: 62.96
Round  17, Global train loss: 0.984, Global test loss: 1.394, Global test accuracy: 51.47
Round  18, Train loss: 1.125, Test loss: 0.968, Test accuracy: 63.52
Round  18, Global train loss: 1.125, Global test loss: 1.340, Global test accuracy: 54.31
Round  19, Train loss: 0.913, Test loss: 0.936, Test accuracy: 64.44
Round  19, Global train loss: 0.913, Global test loss: 1.279, Global test accuracy: 55.31
Round  20, Train loss: 0.946, Test loss: 0.904, Test accuracy: 65.98
Round  20, Global train loss: 0.946, Global test loss: 1.285, Global test accuracy: 55.58
Round  21, Train loss: 0.994, Test loss: 0.909, Test accuracy: 65.95
Round  21, Global train loss: 0.994, Global test loss: 1.438, Global test accuracy: 51.15
Round  22, Train loss: 0.944, Test loss: 0.889, Test accuracy: 66.58
Round  22, Global train loss: 0.944, Global test loss: 1.268, Global test accuracy: 56.02
Round  23, Train loss: 0.909, Test loss: 0.885, Test accuracy: 67.01
Round  23, Global train loss: 0.909, Global test loss: 1.296, Global test accuracy: 56.27
Round  24, Train loss: 0.872, Test loss: 0.886, Test accuracy: 66.90
Round  24, Global train loss: 0.872, Global test loss: 1.283, Global test accuracy: 55.31
Round  25, Train loss: 0.819, Test loss: 0.899, Test accuracy: 66.77
Round  25, Global train loss: 0.819, Global test loss: 1.296, Global test accuracy: 56.45
Round  26, Train loss: 0.883, Test loss: 0.889, Test accuracy: 67.15
Round  26, Global train loss: 0.883, Global test loss: 1.190, Global test accuracy: 59.94
Round  27, Train loss: 0.765, Test loss: 0.877, Test accuracy: 67.54
Round  27, Global train loss: 0.765, Global test loss: 1.318, Global test accuracy: 56.77
Round  28, Train loss: 0.769, Test loss: 0.878, Test accuracy: 67.68
Round  28, Global train loss: 0.769, Global test loss: 1.259, Global test accuracy: 58.11
Round  29, Train loss: 0.773, Test loss: 0.848, Test accuracy: 68.78
Round  29, Global train loss: 0.773, Global test loss: 1.375, Global test accuracy: 52.96
Round  30, Train loss: 0.807, Test loss: 0.847, Test accuracy: 69.03
Round  30, Global train loss: 0.807, Global test loss: 1.177, Global test accuracy: 59.23
Round  31, Train loss: 0.854, Test loss: 0.840, Test accuracy: 69.36
Round  31, Global train loss: 0.854, Global test loss: 1.264, Global test accuracy: 56.63
Round  32, Train loss: 0.719, Test loss: 0.831, Test accuracy: 69.55
Round  32, Global train loss: 0.719, Global test loss: 1.255, Global test accuracy: 57.54
Round  33, Train loss: 0.735, Test loss: 0.828, Test accuracy: 69.69
Round  33, Global train loss: 0.735, Global test loss: 1.240, Global test accuracy: 58.78
Round  34, Train loss: 0.839, Test loss: 0.823, Test accuracy: 70.16
Round  34, Global train loss: 0.839, Global test loss: 1.291, Global test accuracy: 55.94
Round  35, Train loss: 0.734, Test loss: 0.826, Test accuracy: 70.03
Round  35, Global train loss: 0.734, Global test loss: 1.266, Global test accuracy: 57.31
Round  36, Train loss: 0.721, Test loss: 0.818, Test accuracy: 70.35
Round  36, Global train loss: 0.721, Global test loss: 1.346, Global test accuracy: 56.13
Round  37, Train loss: 0.710, Test loss: 0.812, Test accuracy: 70.74
Round  37, Global train loss: 0.710, Global test loss: 1.228, Global test accuracy: 59.62
Round  38, Train loss: 0.743, Test loss: 0.817, Test accuracy: 70.64
Round  38, Global train loss: 0.743, Global test loss: 1.133, Global test accuracy: 62.59
Round  39, Train loss: 0.703, Test loss: 0.797, Test accuracy: 71.22
Round  39, Global train loss: 0.703, Global test loss: 1.196, Global test accuracy: 59.43
Round  40, Train loss: 0.692, Test loss: 0.820, Test accuracy: 70.46
Round  40, Global train loss: 0.692, Global test loss: 1.131, Global test accuracy: 63.69
Round  41, Train loss: 0.751, Test loss: 0.816, Test accuracy: 70.92
Round  41, Global train loss: 0.751, Global test loss: 1.237, Global test accuracy: 58.32
Round  42, Train loss: 0.818, Test loss: 0.808, Test accuracy: 71.13
Round  42, Global train loss: 0.818, Global test loss: 1.287, Global test accuracy: 56.72
Round  43, Train loss: 0.832, Test loss: 0.820, Test accuracy: 70.93
Round  43, Global train loss: 0.832, Global test loss: 1.217, Global test accuracy: 58.85
Round  44, Train loss: 0.730, Test loss: 0.840, Test accuracy: 70.58
Round  44, Global train loss: 0.730, Global test loss: 1.483, Global test accuracy: 52.50
Round  45, Train loss: 0.744, Test loss: 0.829, Test accuracy: 70.93
Round  45, Global train loss: 0.744, Global test loss: 1.090, Global test accuracy: 62.41
Round  46, Train loss: 0.654, Test loss: 0.803, Test accuracy: 71.45
Round  46, Global train loss: 0.654, Global test loss: 1.179, Global test accuracy: 61.27
Round  47, Train loss: 0.672, Test loss: 0.808, Test accuracy: 71.42
Round  47, Global train loss: 0.672, Global test loss: 1.535, Global test accuracy: 53.30
Round  48, Train loss: 0.624, Test loss: 0.821, Test accuracy: 71.31
Round  48, Global train loss: 0.624, Global test loss: 1.098, Global test accuracy: 63.26
Round  49, Train loss: 0.648, Test loss: 0.813, Test accuracy: 71.20
Round  49, Global train loss: 0.648, Global test loss: 1.089, Global test accuracy: 64.47
Round  50, Train loss: 0.590, Test loss: 0.817, Test accuracy: 71.44
Round  50, Global train loss: 0.590, Global test loss: 1.180, Global test accuracy: 61.64
Round  51, Train loss: 0.711, Test loss: 0.834, Test accuracy: 71.05
Round  51, Global train loss: 0.711, Global test loss: 1.152, Global test accuracy: 60.90
Round  52, Train loss: 0.603, Test loss: 0.812, Test accuracy: 71.74
Round  52, Global train loss: 0.603, Global test loss: 1.103, Global test accuracy: 62.86
Round  53, Train loss: 0.636, Test loss: 0.813, Test accuracy: 71.66
Round  53, Global train loss: 0.636, Global test loss: 1.179, Global test accuracy: 62.27
Round  54, Train loss: 0.588, Test loss: 0.819, Test accuracy: 71.67
Round  54, Global train loss: 0.588, Global test loss: 1.060, Global test accuracy: 64.96
Round  55, Train loss: 0.677, Test loss: 0.805, Test accuracy: 71.95
Round  55, Global train loss: 0.677, Global test loss: 1.155, Global test accuracy: 61.72
Round  56, Train loss: 0.559, Test loss: 0.804, Test accuracy: 72.12
Round  56, Global train loss: 0.559, Global test loss: 1.158, Global test accuracy: 63.01
Round  57, Train loss: 0.495, Test loss: 0.809, Test accuracy: 72.10
Round  57, Global train loss: 0.495, Global test loss: 1.100, Global test accuracy: 65.43
Round  58, Train loss: 0.593, Test loss: 0.798, Test accuracy: 72.44
Round  58, Global train loss: 0.593, Global test loss: 1.075, Global test accuracy: 64.93
Round  59, Train loss: 0.623, Test loss: 0.819, Test accuracy: 72.17
Round  59, Global train loss: 0.623, Global test loss: 1.146, Global test accuracy: 64.20
Round  60, Train loss: 0.636, Test loss: 0.831, Test accuracy: 71.87
Round  60, Global train loss: 0.636, Global test loss: 1.060, Global test accuracy: 64.46
Round  61, Train loss: 0.598, Test loss: 0.812, Test accuracy: 72.21
Round  61, Global train loss: 0.598, Global test loss: 1.143, Global test accuracy: 62.16
Round  62, Train loss: 0.600, Test loss: 0.807, Test accuracy: 72.40
Round  62, Global train loss: 0.600, Global test loss: 1.232, Global test accuracy: 61.55
Round  63, Train loss: 0.512, Test loss: 0.822, Test accuracy: 72.24
Round  63, Global train loss: 0.512, Global test loss: 1.068, Global test accuracy: 64.80
Round  64, Train loss: 0.516, Test loss: 0.803, Test accuracy: 72.67
Round  64, Global train loss: 0.516, Global test loss: 1.119, Global test accuracy: 63.97
Round  65, Train loss: 0.539, Test loss: 0.824, Test accuracy: 71.88
Round  65, Global train loss: 0.539, Global test loss: 1.090, Global test accuracy: 63.72
Round  66, Train loss: 0.506, Test loss: 0.808, Test accuracy: 72.50
Round  66, Global train loss: 0.506, Global test loss: 1.060, Global test accuracy: 65.53
Round  67, Train loss: 0.514, Test loss: 0.813, Test accuracy: 72.88
Round  67, Global train loss: 0.514, Global test loss: 1.150, Global test accuracy: 63.68
Round  68, Train loss: 0.464, Test loss: 0.817, Test accuracy: 72.55
Round  68, Global train loss: 0.464, Global test loss: 1.190, Global test accuracy: 62.13
Round  69, Train loss: 0.618, Test loss: 0.822, Test accuracy: 72.79
Round  69, Global train loss: 0.618, Global test loss: 1.144, Global test accuracy: 62.89
Round  70, Train loss: 0.496, Test loss: 0.818, Test accuracy: 73.02
Round  70, Global train loss: 0.496, Global test loss: 1.064, Global test accuracy: 66.12
Round  71, Train loss: 0.540, Test loss: 0.825, Test accuracy: 72.97
Round  71, Global train loss: 0.540, Global test loss: 1.180, Global test accuracy: 62.62
Round  72, Train loss: 0.565, Test loss: 0.814, Test accuracy: 73.59
Round  72, Global train loss: 0.565, Global test loss: 1.112, Global test accuracy: 63.27
Round  73, Train loss: 0.545, Test loss: 0.792, Test accuracy: 74.12
Round  73, Global train loss: 0.545, Global test loss: 1.130, Global test accuracy: 63.60
Round  74, Train loss: 0.455, Test loss: 0.801, Test accuracy: 74.21
Round  74, Global train loss: 0.455, Global test loss: 1.290, Global test accuracy: 61.40
Round  75, Train loss: 0.544, Test loss: 0.825, Test accuracy: 73.64
Round  75, Global train loss: 0.544, Global test loss: 1.117, Global test accuracy: 64.91
Round  76, Train loss: 0.472, Test loss: 0.833, Test accuracy: 73.30
Round  76, Global train loss: 0.472, Global test loss: 1.118, Global test accuracy: 65.56
Round  77, Train loss: 0.511, Test loss: 0.822, Test accuracy: 73.22
Round  77, Global train loss: 0.511, Global test loss: 1.219, Global test accuracy: 63.36
Round  78, Train loss: 0.558, Test loss: 0.828, Test accuracy: 73.20
Round  78, Global train loss: 0.558, Global test loss: 1.358, Global test accuracy: 59.14
Round  79, Train loss: 0.588, Test loss: 0.842, Test accuracy: 73.05
Round  79, Global train loss: 0.588, Global test loss: 1.187, Global test accuracy: 63.45
Round  80, Train loss: 0.519, Test loss: 0.854, Test accuracy: 72.53
Round  80, Global train loss: 0.519, Global test loss: 1.155, Global test accuracy: 63.08
Round  81, Train loss: 0.487, Test loss: 0.856, Test accuracy: 72.56
Round  81, Global train loss: 0.487, Global test loss: 1.280, Global test accuracy: 60.92
Round  82, Train loss: 0.488, Test loss: 0.844, Test accuracy: 72.97
Round  82, Global train loss: 0.488, Global test loss: 1.156, Global test accuracy: 65.29
Round  83, Train loss: 0.445, Test loss: 0.847, Test accuracy: 72.92
Round  83, Global train loss: 0.445, Global test loss: 1.082, Global test accuracy: 66.92
Round  84, Train loss: 0.453, Test loss: 0.823, Test accuracy: 73.31
Round  84, Global train loss: 0.453, Global test loss: 1.086, Global test accuracy: 66.58
Round  85, Train loss: 0.398, Test loss: 0.821, Test accuracy: 73.45
Round  85, Global train loss: 0.398, Global test loss: 1.160, Global test accuracy: 66.24
Round  86, Train loss: 0.435, Test loss: 0.848, Test accuracy: 72.93
Round  86, Global train loss: 0.435, Global test loss: 1.124, Global test accuracy: 65.42
Round  87, Train loss: 0.488, Test loss: 0.851, Test accuracy: 73.03
Round  87, Global train loss: 0.488, Global test loss: 1.174, Global test accuracy: 64.82
Round  88, Train loss: 0.417, Test loss: 0.852, Test accuracy: 73.11
Round  88, Global train loss: 0.417, Global test loss: 1.069, Global test accuracy: 66.50
Round  89, Train loss: 0.469, Test loss: 0.836, Test accuracy: 73.60
Round  89, Global train loss: 0.469, Global test loss: 1.182, Global test accuracy: 64.40
Round  90, Train loss: 0.478, Test loss: 0.826, Test accuracy: 73.42
Round  90, Global train loss: 0.478, Global test loss: 1.135, Global test accuracy: 65.34
Round  91, Train loss: 0.444, Test loss: 0.842, Test accuracy: 72.83
Round  91, Global train loss: 0.444, Global test loss: 1.100, Global test accuracy: 66.02
Round  92, Train loss: 0.526, Test loss: 0.842, Test accuracy: 72.95
Round  92, Global train loss: 0.526, Global test loss: 1.118, Global test accuracy: 65.34
Round  93, Train loss: 0.479, Test loss: 0.846, Test accuracy: 72.86
Round  93, Global train loss: 0.479, Global test loss: 1.099, Global test accuracy: 66.89/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  94, Train loss: 0.504, Test loss: 0.862, Test accuracy: 73.01
Round  94, Global train loss: 0.504, Global test loss: 1.224, Global test accuracy: 63.14
Round  95, Train loss: 0.360, Test loss: 0.855, Test accuracy: 73.40
Round  95, Global train loss: 0.360, Global test loss: 1.140, Global test accuracy: 65.37
Round  96, Train loss: 0.410, Test loss: 0.867, Test accuracy: 73.50
Round  96, Global train loss: 0.410, Global test loss: 1.087, Global test accuracy: 67.52
Round  97, Train loss: 0.485, Test loss: 0.886, Test accuracy: 73.84
Round  97, Global train loss: 0.485, Global test loss: 1.236, Global test accuracy: 63.78
Round  98, Train loss: 0.372, Test loss: 0.889, Test accuracy: 73.38
Round  98, Global train loss: 0.372, Global test loss: 1.226, Global test accuracy: 64.81
Round  99, Train loss: 0.390, Test loss: 0.903, Test accuracy: 72.79
Round  99, Global train loss: 0.390, Global test loss: 1.197, Global test accuracy: 64.89
Final Round, Train loss: 0.358, Test loss: 0.917, Test accuracy: 73.52
Final Round, Global train loss: 0.358, Global test loss: 1.197, Global test accuracy: 64.89
Average accuracy final 10 rounds: 73.19800000000001 

Average global accuracy final 10 rounds: 65.31 

1698.550812959671
[1.647658109664917, 3.295316219329834, 4.688428640365601, 6.081541061401367, 7.449493885040283, 8.8174467086792, 10.201181173324585, 11.58491563796997, 12.961048364639282, 14.337181091308594, 15.708642959594727, 17.08010482788086, 18.452563524246216, 19.825022220611572, 21.176926851272583, 22.528831481933594, 23.88665509223938, 25.244478702545166, 26.606351375579834, 27.968224048614502, 29.35699725151062, 30.74577045440674, 32.10578966140747, 33.4658088684082, 34.831313610076904, 36.196818351745605, 37.62833762168884, 39.05985689163208, 40.41238355636597, 41.76491022109985, 43.1467866897583, 44.52866315841675, 45.90592551231384, 47.28318786621094, 48.63868546485901, 49.99418306350708, 51.40460276603699, 52.815022468566895, 54.185434103012085, 55.555845737457275, 56.940508127212524, 58.32517051696777, 59.65756702423096, 60.98996353149414, 62.35468602180481, 63.71940851211548, 65.12006616592407, 66.52072381973267, 67.88486218452454, 69.2490005493164, 70.45350790023804, 71.65801525115967, 72.88233947753906, 74.10666370391846, 75.3031394481659, 76.49961519241333, 77.69629549980164, 78.89297580718994, 80.07633185386658, 81.25968790054321, 82.59927320480347, 83.93885850906372, 85.1557776927948, 86.37269687652588, 87.60750102996826, 88.84230518341064, 90.03621792793274, 91.23013067245483, 92.41818618774414, 93.60624170303345, 94.82985830307007, 96.05347490310669, 97.32754492759705, 98.6016149520874, 99.83920288085938, 101.07679080963135, 102.29771280288696, 103.51863479614258, 104.701908826828, 105.88518285751343, 107.06154489517212, 108.23790693283081, 109.419025182724, 110.60014343261719, 111.96966767311096, 113.33919191360474, 114.69366478919983, 116.04813766479492, 117.43740034103394, 118.82666301727295, 120.22945952415466, 121.63225603103638, 122.88687944412231, 124.14150285720825, 125.33570313453674, 126.52990341186523, 127.73504757881165, 128.94019174575806, 130.1637237071991, 131.38725566864014, 132.55264616012573, 133.71803665161133, 134.89818811416626, 136.0783395767212, 137.2711205482483, 138.4639015197754, 139.67832350730896, 140.89274549484253, 142.07528376579285, 143.25782203674316, 144.45029878616333, 145.6427755355835, 146.81031250953674, 147.97784948349, 149.3108127117157, 150.6437759399414, 152.02581524848938, 153.40785455703735, 154.7170650959015, 156.02627563476562, 157.45676183700562, 158.8872480392456, 160.29455542564392, 161.70186281204224, 163.10205745697021, 164.5022521018982, 165.84374117851257, 167.18523025512695, 168.5451054573059, 169.90498065948486, 171.32186102867126, 172.73874139785767, 174.08698415756226, 175.43522691726685, 176.79015064239502, 178.1450743675232, 179.48861622810364, 180.83215808868408, 182.1243121623993, 183.4164662361145, 184.73975658416748, 186.06304693222046, 187.43859887123108, 188.8141508102417, 190.10616159439087, 191.39817237854004, 192.7341170310974, 194.07006168365479, 195.5084421634674, 196.94682264328003, 198.36270761489868, 199.77859258651733, 201.19379568099976, 202.60899877548218, 203.88694047927856, 205.16488218307495, 206.51353907585144, 207.86219596862793, 209.20066022872925, 210.53912448883057, 211.8651990890503, 213.19127368927002, 214.54444336891174, 215.89761304855347, 217.25452303886414, 218.6114330291748, 219.96209239959717, 221.31275177001953, 222.5089259147644, 223.70510005950928, 224.89274072647095, 226.08038139343262, 227.26969456672668, 228.45900774002075, 229.6548776626587, 230.85074758529663, 232.04339814186096, 233.2360486984253, 234.42318511009216, 235.61032152175903, 236.79812574386597, 237.9859299659729, 239.32543110847473, 240.66493225097656, 241.96743631362915, 243.26994037628174, 244.54890322685242, 245.8278660774231, 247.20175313949585, 248.5756402015686, 249.91346216201782, 251.25128412246704, 252.5750436782837, 253.89880323410034, 255.2941083908081, 256.68941354751587, 258.0480942726135, 259.4067749977112, 260.6795823574066, 261.95238971710205, 264.6181962490082, 267.2840027809143]
[25.6, 25.6, 36.07, 36.07, 37.77, 37.77, 42.55, 42.55, 49.63, 49.63, 51.47, 51.47, 52.49, 52.49, 55.12, 55.12, 54.23, 54.23, 56.16, 56.16, 56.83, 56.83, 58.6, 58.6, 59.97, 59.97, 60.68, 60.68, 60.99, 60.99, 61.19, 61.19, 62.06, 62.06, 62.96, 62.96, 63.52, 63.52, 64.44, 64.44, 65.98, 65.98, 65.95, 65.95, 66.58, 66.58, 67.01, 67.01, 66.9, 66.9, 66.77, 66.77, 67.15, 67.15, 67.54, 67.54, 67.68, 67.68, 68.78, 68.78, 69.03, 69.03, 69.36, 69.36, 69.55, 69.55, 69.69, 69.69, 70.16, 70.16, 70.03, 70.03, 70.35, 70.35, 70.74, 70.74, 70.64, 70.64, 71.22, 71.22, 70.46, 70.46, 70.92, 70.92, 71.13, 71.13, 70.93, 70.93, 70.58, 70.58, 70.93, 70.93, 71.45, 71.45, 71.42, 71.42, 71.31, 71.31, 71.2, 71.2, 71.44, 71.44, 71.05, 71.05, 71.74, 71.74, 71.66, 71.66, 71.67, 71.67, 71.95, 71.95, 72.12, 72.12, 72.1, 72.1, 72.44, 72.44, 72.17, 72.17, 71.87, 71.87, 72.21, 72.21, 72.4, 72.4, 72.24, 72.24, 72.67, 72.67, 71.88, 71.88, 72.5, 72.5, 72.88, 72.88, 72.55, 72.55, 72.79, 72.79, 73.02, 73.02, 72.97, 72.97, 73.59, 73.59, 74.12, 74.12, 74.21, 74.21, 73.64, 73.64, 73.3, 73.3, 73.22, 73.22, 73.2, 73.2, 73.05, 73.05, 72.53, 72.53, 72.56, 72.56, 72.97, 72.97, 72.92, 72.92, 73.31, 73.31, 73.45, 73.45, 72.93, 72.93, 73.03, 73.03, 73.11, 73.11, 73.6, 73.6, 73.42, 73.42, 72.83, 72.83, 72.95, 72.95, 72.86, 72.86, 73.01, 73.01, 73.4, 73.4, 73.5, 73.5, 73.84, 73.84, 73.38, 73.38, 72.79, 72.79, 73.52, 73.52]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 8, noise    level: 0.4000 
   Client 13, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 19, noise    level: 0.4000 
   Client 11, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 14, noise    level: 0.4000 
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.998, Test loss: 2.235, Test accuracy: 16.94
Round   1, Train loss: 1.586, Test loss: 1.828, Test accuracy: 34.64
Round   2, Train loss: 1.437, Test loss: 1.786, Test accuracy: 33.76
Round   3, Train loss: 1.402, Test loss: 1.534, Test accuracy: 41.79
Round   4, Train loss: 1.308, Test loss: 1.383, Test accuracy: 48.40
Round   5, Train loss: 1.283, Test loss: 1.284, Test accuracy: 51.09
Round   6, Train loss: 1.198, Test loss: 1.215, Test accuracy: 53.72
Round   7, Train loss: 1.231, Test loss: 1.168, Test accuracy: 56.19
Round   8, Train loss: 1.152, Test loss: 1.183, Test accuracy: 55.04
Round   9, Train loss: 1.085, Test loss: 1.118, Test accuracy: 57.48
Round  10, Train loss: 1.099, Test loss: 1.091, Test accuracy: 58.45
Round  11, Train loss: 1.061, Test loss: 1.049, Test accuracy: 60.14
Round  12, Train loss: 1.087, Test loss: 1.007, Test accuracy: 61.91
Round  13, Train loss: 1.054, Test loss: 0.967, Test accuracy: 62.98
Round  14, Train loss: 1.038, Test loss: 0.965, Test accuracy: 63.49
Round  15, Train loss: 1.033, Test loss: 0.957, Test accuracy: 63.60
Round  16, Train loss: 1.017, Test loss: 0.926, Test accuracy: 64.95
Round  17, Train loss: 1.028, Test loss: 0.903, Test accuracy: 65.89
Round  18, Train loss: 1.042, Test loss: 0.921, Test accuracy: 66.32
Round  19, Train loss: 0.961, Test loss: 0.903, Test accuracy: 66.28
Round  20, Train loss: 0.988, Test loss: 0.878, Test accuracy: 66.95
Round  21, Train loss: 0.983, Test loss: 0.886, Test accuracy: 67.35
Round  22, Train loss: 0.917, Test loss: 0.849, Test accuracy: 67.99
Round  23, Train loss: 0.991, Test loss: 0.842, Test accuracy: 68.16
Round  24, Train loss: 0.918, Test loss: 0.827, Test accuracy: 68.96
Round  25, Train loss: 0.871, Test loss: 0.822, Test accuracy: 69.15
Round  26, Train loss: 0.876, Test loss: 0.795, Test accuracy: 70.18
Round  27, Train loss: 0.818, Test loss: 0.804, Test accuracy: 69.84
Round  28, Train loss: 0.804, Test loss: 0.791, Test accuracy: 70.24
Round  29, Train loss: 0.820, Test loss: 0.805, Test accuracy: 70.52
Round  30, Train loss: 0.853, Test loss: 0.780, Test accuracy: 71.09
Round  31, Train loss: 0.854, Test loss: 0.784, Test accuracy: 71.23
Round  32, Train loss: 0.814, Test loss: 0.778, Test accuracy: 71.15
Round  33, Train loss: 0.810, Test loss: 0.758, Test accuracy: 71.56
Round  34, Train loss: 0.893, Test loss: 0.744, Test accuracy: 72.24
Round  35, Train loss: 0.750, Test loss: 0.744, Test accuracy: 72.13
Round  36, Train loss: 0.792, Test loss: 0.738, Test accuracy: 72.83
Round  37, Train loss: 0.837, Test loss: 0.735, Test accuracy: 72.55
Round  38, Train loss: 0.756, Test loss: 0.740, Test accuracy: 72.34
Round  39, Train loss: 0.781, Test loss: 0.728, Test accuracy: 73.27
Round  40, Train loss: 0.789, Test loss: 0.729, Test accuracy: 73.08
Round  41, Train loss: 0.760, Test loss: 0.728, Test accuracy: 73.03
Round  42, Train loss: 0.788, Test loss: 0.731, Test accuracy: 72.92
Round  43, Train loss: 0.856, Test loss: 0.717, Test accuracy: 73.47
Round  44, Train loss: 0.819, Test loss: 0.703, Test accuracy: 74.04
Round  45, Train loss: 0.731, Test loss: 0.698, Test accuracy: 73.92
Round  46, Train loss: 0.684, Test loss: 0.685, Test accuracy: 74.40
Round  47, Train loss: 0.704, Test loss: 0.696, Test accuracy: 74.02
Round  48, Train loss: 0.729, Test loss: 0.690, Test accuracy: 74.43
Round  49, Train loss: 0.743, Test loss: 0.696, Test accuracy: 74.51
Round  50, Train loss: 0.656, Test loss: 0.684, Test accuracy: 75.15
Round  51, Train loss: 0.724, Test loss: 0.685, Test accuracy: 74.87
Round  52, Train loss: 0.692, Test loss: 0.670, Test accuracy: 74.84
Round  53, Train loss: 0.719, Test loss: 0.677, Test accuracy: 74.81
Round  54, Train loss: 0.710, Test loss: 0.662, Test accuracy: 75.52
Round  55, Train loss: 0.748, Test loss: 0.663, Test accuracy: 75.65
Round  56, Train loss: 0.656, Test loss: 0.660, Test accuracy: 75.56
Round  57, Train loss: 0.664, Test loss: 0.660, Test accuracy: 75.26
Round  58, Train loss: 0.660, Test loss: 0.672, Test accuracy: 75.26
Round  59, Train loss: 0.653, Test loss: 0.671, Test accuracy: 75.04
Round  60, Train loss: 0.619, Test loss: 0.655, Test accuracy: 75.82
Round  61, Train loss: 0.621, Test loss: 0.657, Test accuracy: 75.89
Round  62, Train loss: 0.649, Test loss: 0.660, Test accuracy: 75.86
Round  63, Train loss: 0.614, Test loss: 0.660, Test accuracy: 75.56
Round  64, Train loss: 0.636, Test loss: 0.653, Test accuracy: 75.97
Round  65, Train loss: 0.653, Test loss: 0.649, Test accuracy: 76.06
Round  66, Train loss: 0.584, Test loss: 0.642, Test accuracy: 76.30
Round  67, Train loss: 0.593, Test loss: 0.655, Test accuracy: 76.08
Round  68, Train loss: 0.568, Test loss: 0.667, Test accuracy: 75.54
Round  69, Train loss: 0.709, Test loss: 0.656, Test accuracy: 76.14
Round  70, Train loss: 0.591, Test loss: 0.649, Test accuracy: 76.10
Round  71, Train loss: 0.631, Test loss: 0.656, Test accuracy: 75.91
Round  72, Train loss: 0.629, Test loss: 0.647, Test accuracy: 76.55
Round  73, Train loss: 0.581, Test loss: 0.642, Test accuracy: 76.85
Round  74, Train loss: 0.571, Test loss: 0.637, Test accuracy: 76.78
Round  75, Train loss: 0.650, Test loss: 0.645, Test accuracy: 76.82
Round  76, Train loss: 0.555, Test loss: 0.637, Test accuracy: 76.98
Round  77, Train loss: 0.607, Test loss: 0.643, Test accuracy: 76.53
Round  78, Train loss: 0.569, Test loss: 0.635, Test accuracy: 76.86
Round  79, Train loss: 0.615, Test loss: 0.633, Test accuracy: 76.87
Round  80, Train loss: 0.567, Test loss: 0.625, Test accuracy: 77.04
Round  81, Train loss: 0.519, Test loss: 0.618, Test accuracy: 77.59
Round  82, Train loss: 0.515, Test loss: 0.629, Test accuracy: 76.98
Round  83, Train loss: 0.553, Test loss: 0.628, Test accuracy: 77.24
Round  84, Train loss: 0.547, Test loss: 0.623, Test accuracy: 77.17
Round  85, Train loss: 0.508, Test loss: 0.635, Test accuracy: 76.43
Round  86, Train loss: 0.501, Test loss: 0.621, Test accuracy: 77.19
Round  87, Train loss: 0.505, Test loss: 0.620, Test accuracy: 77.48
Round  88, Train loss: 0.491, Test loss: 0.621, Test accuracy: 77.17
Round  89, Train loss: 0.555, Test loss: 0.624, Test accuracy: 77.56
Round  90, Train loss: 0.547, Test loss: 0.621, Test accuracy: 77.31
Round  91, Train loss: 0.500, Test loss: 0.617, Test accuracy: 77.60
Round  92, Train loss: 0.586, Test loss: 0.616, Test accuracy: 77.81
Round  93, Train loss: 0.509, Test loss: 0.626, Test accuracy: 77.31
Round  94, Train loss: 0.486, Test loss: 0.623, Test accuracy: 77.46
Round  95, Train loss: 0.490, Test loss: 0.626, Test accuracy: 77.30
Round  96, Train loss: 0.537, Test loss: 0.617, Test accuracy: 77.96
Round  97, Train loss: 0.582, Test loss: 0.618, Test accuracy: 77.58
Round  98, Train loss: 0.449, Test loss: 0.622, Test accuracy: 77.48
Round  99, Train loss: 0.473, Test loss: 0.624, Test accuracy: 77.63
Final Round, Train loss: 0.445, Test loss: 0.624, Test accuracy: 77.68
Average accuracy final 10 rounds: 77.54400000000001
2293.767344713211
[3.736804962158203, 6.952559232711792, 10.196157217025757, 13.414843559265137, 16.5909104347229, 19.781586170196533, 23.091630220413208, 26.400133848190308, 29.656513929367065, 32.96463489532471, 36.34441685676575, 39.59998917579651, 42.9842963218689, 46.18550252914429, 49.459677934646606, 52.6689453125, 55.875720739364624, 59.04758429527283, 62.235023021698, 65.42118883132935, 68.6994092464447, 71.88332986831665, 75.10455965995789, 78.49700355529785, 81.76224374771118, 84.99342441558838, 88.29721450805664, 91.63290309906006, 95.00029635429382, 98.42688012123108, 101.80421733856201, 105.03927278518677, 108.37051057815552, 111.59823608398438, 115.00768852233887, 118.25561165809631, 121.56253671646118, 124.84208583831787, 128.1004183292389, 131.38215446472168, 134.71645736694336, 137.96492910385132, 141.30720019340515, 144.68549251556396, 148.04788875579834, 151.2225227355957, 154.47529339790344, 157.8048815727234, 161.0946159362793, 164.24962997436523, 167.4707682132721, 170.62626123428345, 173.79525780677795, 177.18593192100525, 180.73056507110596, 184.2068064212799, 187.52282309532166, 190.69300317764282, 193.91900324821472, 197.14637923240662, 200.358882188797, 203.52589893341064, 206.66030502319336, 209.85363459587097, 212.96879291534424, 216.1264774799347, 219.27502393722534, 222.3702688217163, 225.6263313293457, 228.88402605056763, 232.20864939689636, 235.5835919380188, 238.9598307609558, 242.32601475715637, 245.6098506450653, 248.78464460372925, 252.09241819381714, 255.376131772995, 258.7216260433197, 262.0941023826599, 265.30137729644775, 268.5443208217621, 271.80411195755005, 275.1372175216675, 278.4391305446625, 281.8257989883423, 285.2040011882782, 288.6817321777344, 292.0942544937134, 295.2884142398834, 298.5061628818512, 301.70390582084656, 304.85427165031433, 308.0661382675171, 311.29652976989746, 314.52061581611633, 317.6852653026581, 320.9965419769287, 324.20068359375, 327.3691999912262, 331.97773599624634]
[16.94, 34.64, 33.76, 41.79, 48.4, 51.09, 53.72, 56.19, 55.04, 57.48, 58.45, 60.14, 61.91, 62.98, 63.49, 63.6, 64.95, 65.89, 66.32, 66.28, 66.95, 67.35, 67.99, 68.16, 68.96, 69.15, 70.18, 69.84, 70.24, 70.52, 71.09, 71.23, 71.15, 71.56, 72.24, 72.13, 72.83, 72.55, 72.34, 73.27, 73.08, 73.03, 72.92, 73.47, 74.04, 73.92, 74.4, 74.02, 74.43, 74.51, 75.15, 74.87, 74.84, 74.81, 75.52, 75.65, 75.56, 75.26, 75.26, 75.04, 75.82, 75.89, 75.86, 75.56, 75.97, 76.06, 76.3, 76.08, 75.54, 76.14, 76.1, 75.91, 76.55, 76.85, 76.78, 76.82, 76.98, 76.53, 76.86, 76.87, 77.04, 77.59, 76.98, 77.24, 77.17, 76.43, 77.19, 77.48, 77.17, 77.56, 77.31, 77.6, 77.81, 77.31, 77.46, 77.3, 77.96, 77.58, 77.48, 77.63, 77.68]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 8, noise    level: 0.4000 
   Client 14, noise    level: 0.4000 
   Client 19, noise    level: 0.4000 
   Client 12, noise    level: 0.4000 
   Client 16, noise    level: 0.4000 
   Client 13, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 15, noise    level: 0.4000 
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  11.9600
Round 1 global test acc  17.2500
Round 2 global test acc  20.9200
Round 3 global test acc  25.4200
Round 4 global test acc  27.5200
Round 5 global test acc  31.5200
Round 6 global test acc  33.8300
Round 7 global test acc  26.4200
Round 8 global test acc  29.6100
Round 9 global test acc  35.0200
Round 10 global test acc  29.4300
Round 11 global test acc  32.2100
Round 12 global test acc  36.1300
Round 13 global test acc  35.7900
Round 14 global test acc  34.8800
Round 15 global test acc  40.0500
Round 16 global test acc  31.3300
Round 17 global test acc  32.6300
Round 18 global test acc  35.9300
Round 19 global test acc  33.5900
Round 20 global test acc  32.1600
Round 21 global test acc  42.2400
Round 22 global test acc  39.8300
Round 23 global test acc  32.0000
Round 24 global test acc  41.0800
Round 25 global test acc  40.4900
Round 26 global test acc  38.2600
Round 27 global test acc  32.4100
Round 28 global test acc  38.0400
Round 29 global test acc  39.6900
Round 30 global test acc  40.6600
Round 31 global test acc  36.4400
Round 32 global test acc  34.6200
Round 33 global test acc  35.8400
Round 34 global test acc  40.9200
Round 35 global test acc  41.9100
Round 36 global test acc  35.2800
Round 37 global test acc  41.2700
Round 38 global test acc  42.4100
Round 39 global test acc  45.5200
Round 40 global test acc  40.4100
Round 41 global test acc  47.5200
Round 42 global test acc  39.9600
Round 43 global test acc  44.0500
Round 44 global test acc  46.9900
Round 45 global test acc  42.7800
Round 46 global test acc  36.7600
Round 47 global test acc  38.5100
Round 48 global test acc  43.7600
Round 49 global test acc  48.4600
Round 50 global test acc  36.2400
Round 51 global test acc  38.7900
Round 52 global test acc  43.9200
Round 53 global test acc  48.8600
Round 54 global test acc  43.0900
Round 55 global test acc  42.3000
Round 56 global test acc  37.7100
Round 57 global test acc  44.8200
Round 58 global test acc  39.5000
Round 59 global test acc  36.0300
Round 60 global test acc  38.4000
Round 61 global test acc  41.8800
Round 62 global test acc  45.4300
Round 63 global test acc  44.7000
Round 64 global test acc  46.8300
Round 65 global test acc  40.3900
Round 66 global test acc  45.3200
Round 67 global test acc  44.6200
Round 68 global test acc  47.9100
Round 69 global test acc  40.2000
Round 70 global test acc  45.1600
Round 71 global test acc  49.1300
Round 72 global test acc  36.6100
Round 73 global test acc  44.9100
Round 74 global test acc  37.8400
Round 75 global test acc  37.0500
Round 76 global test acc  39.3200
Round 77 global test acc  47.7100
Round 78 global test acc  47.0100
Round 79 global test acc  39.3700
Round 80 global test acc  39.0300
Round 81 global test acc  37.6500
Round 82 global test acc  36.0400
Round 83 global test acc  34.5800
Round 84 global test acc  33.9400
Round 85 global test acc  34.2400
Round 86 global test acc  32.9800
Round 87 global test acc  33.5200
Round 88 global test acc  32.6300
Round 89 global test acc  32.3200
Round 90 global test acc  30.9200
Round 91 global test acc  29.4000
Round 92 global test acc  27.0300
Round 93 global test acc  26.2300
Round 94 global test acc  25.3800
Round 95 global test acc  29.3700
Round 96 global test acc  32.4300
Round 97 global test acc  32.7000
Round 98 global test acc  32.0500
Round 99 global test acc  30.1500
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 1, noise    level: 0.4000 
   Client 11, noise    level: 0.4000 
   Client 12, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 13, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.947, Test loss: 2.258, Test accuracy: 22.93
Round   1, Train loss: 1.511, Test loss: 1.800, Test accuracy: 34.38
Round   2, Train loss: 1.412, Test loss: 1.756, Test accuracy: 34.17
Round   3, Train loss: 1.369, Test loss: 1.503, Test accuracy: 41.47
Round   4, Train loss: 1.292, Test loss: 1.342, Test accuracy: 47.93
Round   5, Train loss: 1.242, Test loss: 1.276, Test accuracy: 49.65
Round   6, Train loss: 1.110, Test loss: 1.215, Test accuracy: 52.82
Round   7, Train loss: 1.225, Test loss: 1.159, Test accuracy: 54.66
Round   8, Train loss: 1.122, Test loss: 1.158, Test accuracy: 54.34
Round   9, Train loss: 1.085, Test loss: 1.077, Test accuracy: 58.26
Round  10, Train loss: 1.116, Test loss: 1.076, Test accuracy: 57.15
Round  11, Train loss: 1.023, Test loss: 1.054, Test accuracy: 59.38
Round  12, Train loss: 1.111, Test loss: 0.988, Test accuracy: 62.16
Round  13, Train loss: 1.065, Test loss: 0.956, Test accuracy: 63.02
Round  14, Train loss: 0.992, Test loss: 0.941, Test accuracy: 63.87
Round  15, Train loss: 0.987, Test loss: 0.922, Test accuracy: 64.29
Round  16, Train loss: 0.984, Test loss: 0.915, Test accuracy: 64.96
Round  17, Train loss: 0.996, Test loss: 0.912, Test accuracy: 65.22
Round  18, Train loss: 1.101, Test loss: 0.901, Test accuracy: 64.73
Round  19, Train loss: 0.955, Test loss: 0.891, Test accuracy: 65.99
Round  20, Train loss: 0.953, Test loss: 0.877, Test accuracy: 66.52
Round  21, Train loss: 0.915, Test loss: 0.863, Test accuracy: 67.59
Round  22, Train loss: 1.054, Test loss: 0.845, Test accuracy: 68.75
Round  23, Train loss: 0.951, Test loss: 0.830, Test accuracy: 68.09
Round  24, Train loss: 0.977, Test loss: 0.804, Test accuracy: 68.82
Round  25, Train loss: 0.931, Test loss: 0.798, Test accuracy: 69.60
Round  26, Train loss: 0.814, Test loss: 0.789, Test accuracy: 70.26
Round  27, Train loss: 0.843, Test loss: 0.790, Test accuracy: 69.32
Round  28, Train loss: 0.853, Test loss: 0.791, Test accuracy: 69.92
Round  29, Train loss: 0.751, Test loss: 0.784, Test accuracy: 70.46
Round  30, Train loss: 0.899, Test loss: 0.762, Test accuracy: 71.08
Round  31, Train loss: 0.818, Test loss: 0.752, Test accuracy: 71.30
Round  32, Train loss: 0.741, Test loss: 0.760, Test accuracy: 72.00
Round  33, Train loss: 0.758, Test loss: 0.748, Test accuracy: 71.40
Round  34, Train loss: 0.865, Test loss: 0.744, Test accuracy: 71.46
Round  35, Train loss: 0.777, Test loss: 0.731, Test accuracy: 72.00
Round  36, Train loss: 0.809, Test loss: 0.739, Test accuracy: 71.35
Round  37, Train loss: 0.781, Test loss: 0.726, Test accuracy: 71.82
Round  38, Train loss: 0.821, Test loss: 0.733, Test accuracy: 72.42
Round  39, Train loss: 0.715, Test loss: 0.718, Test accuracy: 72.71
Round  40, Train loss: 0.709, Test loss: 0.704, Test accuracy: 73.05
Round  41, Train loss: 0.778, Test loss: 0.700, Test accuracy: 73.14
Round  42, Train loss: 0.777, Test loss: 0.701, Test accuracy: 73.68
Round  43, Train loss: 0.849, Test loss: 0.709, Test accuracy: 73.29
Round  44, Train loss: 0.822, Test loss: 0.709, Test accuracy: 73.06
Round  45, Train loss: 0.821, Test loss: 0.696, Test accuracy: 73.47
Round  46, Train loss: 0.734, Test loss: 0.679, Test accuracy: 74.23
Round  47, Train loss: 0.657, Test loss: 0.692, Test accuracy: 74.15
Round  48, Train loss: 0.753, Test loss: 0.683, Test accuracy: 74.05
Round  49, Train loss: 0.705, Test loss: 0.670, Test accuracy: 74.30
Round  50, Train loss: 0.681, Test loss: 0.678, Test accuracy: 73.95
Round  51, Train loss: 0.704, Test loss: 0.667, Test accuracy: 75.25
Round  52, Train loss: 0.734, Test loss: 0.662, Test accuracy: 75.20
Round  53, Train loss: 0.669, Test loss: 0.662, Test accuracy: 75.48
Round  54, Train loss: 0.675, Test loss: 0.666, Test accuracy: 74.99
Round  55, Train loss: 0.739, Test loss: 0.655, Test accuracy: 75.24
Round  56, Train loss: 0.664, Test loss: 0.661, Test accuracy: 75.35
Round  57, Train loss: 0.601, Test loss: 0.654, Test accuracy: 75.73
Round  58, Train loss: 0.606, Test loss: 0.659, Test accuracy: 75.26
Round  59, Train loss: 0.599, Test loss: 0.650, Test accuracy: 75.49
Round  60, Train loss: 0.697, Test loss: 0.646, Test accuracy: 75.80
Round  61, Train loss: 0.635, Test loss: 0.652, Test accuracy: 75.40
Round  62, Train loss: 0.558, Test loss: 0.642, Test accuracy: 75.98
Round  63, Train loss: 0.555, Test loss: 0.639, Test accuracy: 76.37
Round  64, Train loss: 0.556, Test loss: 0.646, Test accuracy: 75.98
Round  65, Train loss: 0.683, Test loss: 0.637, Test accuracy: 76.17
Round  66, Train loss: 0.529, Test loss: 0.639, Test accuracy: 76.36
Round  67, Train loss: 0.552, Test loss: 0.639, Test accuracy: 76.22
Round  68, Train loss: 0.571, Test loss: 0.635, Test accuracy: 76.11
Round  69, Train loss: 0.676, Test loss: 0.628, Test accuracy: 76.41
Round  70, Train loss: 0.551, Test loss: 0.626, Test accuracy: 76.54
Round  71, Train loss: 0.571, Test loss: 0.635, Test accuracy: 76.58
Round  72, Train loss: 0.566, Test loss: 0.628, Test accuracy: 76.65
Round  73, Train loss: 0.596, Test loss: 0.629, Test accuracy: 76.35
Round  74, Train loss: 0.575, Test loss: 0.639, Test accuracy: 76.24
Round  75, Train loss: 0.581, Test loss: 0.626, Test accuracy: 77.11
Round  76, Train loss: 0.515, Test loss: 0.619, Test accuracy: 77.00
Round  77, Train loss: 0.611, Test loss: 0.628, Test accuracy: 76.43
Round  78, Train loss: 0.595, Test loss: 0.620, Test accuracy: 77.22
Round  79, Train loss: 0.627, Test loss: 0.616, Test accuracy: 76.94
Round  80, Train loss: 0.576, Test loss: 0.615, Test accuracy: 76.84
Round  81, Train loss: 0.488, Test loss: 0.618, Test accuracy: 76.96
Round  82, Train loss: 0.514, Test loss: 0.614, Test accuracy: 77.00
Round  83, Train loss: 0.503, Test loss: 0.606, Test accuracy: 77.48
Round  84, Train loss: 0.555, Test loss: 0.605, Test accuracy: 77.66
Round  85, Train loss: 0.461, Test loss: 0.605, Test accuracy: 77.94
Round  86, Train loss: 0.513, Test loss: 0.606, Test accuracy: 77.62
Round  87, Train loss: 0.518, Test loss: 0.611, Test accuracy: 77.52
Round  88, Train loss: 0.524, Test loss: 0.618, Test accuracy: 77.18
Round  89, Train loss: 0.505, Test loss: 0.607, Test accuracy: 77.75
Round  90, Train loss: 0.501, Test loss: 0.611, Test accuracy: 77.64
Round  91, Train loss: 0.582, Test loss: 0.605, Test accuracy: 77.42
Round  92, Train loss: 0.587, Test loss: 0.616, Test accuracy: 77.20
Round  93, Train loss: 0.499, Test loss: 0.614, Test accuracy: 77.78
Round  94, Train loss: 0.577, Test loss: 0.613, Test accuracy: 78.06
Round  95, Train loss: 0.418, Test loss: 0.615, Test accuracy: 77.51
Round  96, Train loss: 0.449, Test loss: 0.612, Test accuracy: 77.73
Round  97, Train loss: 0.516, Test loss: 0.615, Test accuracy: 77.14
Round  98, Train loss: 0.411, Test loss: 0.618, Test accuracy: 77.53
Round  99, Train loss: 0.518, Test loss: 0.609, Test accuracy: 77.64
Final Round, Train loss: 0.428, Test loss: 0.609, Test accuracy: 77.72
Average accuracy final 10 rounds: 77.56499999999998
1140.7217636108398
[1.8313305377960205, 3.2814207077026367, 4.720196723937988, 6.139735221862793, 7.5544984340667725, 8.97326374053955, 10.365557670593262, 11.774649620056152, 13.17829942703247, 14.678539991378784, 16.092060565948486, 17.57813310623169, 19.013880968093872, 20.4685001373291, 21.954078435897827, 23.381704330444336, 24.77595829963684, 26.17015314102173, 27.59365224838257, 28.99509072303772, 30.341333866119385, 31.705328464508057, 33.146708488464355, 34.57658123970032, 35.93535304069519, 37.27691864967346, 38.705795764923096, 40.10687708854675, 41.4709632396698, 42.90976309776306, 44.33474612236023, 45.69043040275574, 47.113669872283936, 48.49273610115051, 49.85179114341736, 51.23015546798706, 52.63552117347717, 54.00655150413513, 55.36055278778076, 56.79554533958435, 58.175623655319214, 59.577322483062744, 60.95524764060974, 62.304264545440674, 63.676522731781006, 65.0412368774414, 66.3980827331543, 67.80524754524231, 69.15755414962769, 70.47526049613953, 71.83237171173096, 73.19155144691467, 74.57166123390198, 75.93912196159363, 77.32628107070923, 78.70358800888062, 80.09431672096252, 81.47772288322449, 82.8440625667572, 84.19412636756897, 85.51207208633423, 86.89554810523987, 88.25983095169067, 89.58098101615906, 90.92653226852417, 92.30157566070557, 93.64700865745544, 94.99797630310059, 96.34793949127197, 97.69598007202148, 99.04500269889832, 100.36057591438293, 101.67031288146973, 103.01697254180908, 104.31428289413452, 105.65049982070923, 106.98196387290955, 108.35322499275208, 109.65385699272156, 110.99648857116699, 112.31878781318665, 113.65953516960144, 115.01532530784607, 116.3540587425232, 117.67361807823181, 119.0024733543396, 120.3156623840332, 121.66345167160034, 122.9960663318634, 124.31152319908142, 125.64087247848511, 126.99951910972595, 128.34214210510254, 129.71336936950684, 131.06966352462769, 132.3957359790802, 133.8416349887848, 135.2629702091217, 136.57651042938232, 137.91670894622803, 140.24226760864258]
[22.93, 34.38, 34.17, 41.47, 47.93, 49.65, 52.82, 54.66, 54.34, 58.26, 57.15, 59.38, 62.16, 63.02, 63.87, 64.29, 64.96, 65.22, 64.73, 65.99, 66.52, 67.59, 68.75, 68.09, 68.82, 69.6, 70.26, 69.32, 69.92, 70.46, 71.08, 71.3, 72.0, 71.4, 71.46, 72.0, 71.35, 71.82, 72.42, 72.71, 73.05, 73.14, 73.68, 73.29, 73.06, 73.47, 74.23, 74.15, 74.05, 74.3, 73.95, 75.25, 75.2, 75.48, 74.99, 75.24, 75.35, 75.73, 75.26, 75.49, 75.8, 75.4, 75.98, 76.37, 75.98, 76.17, 76.36, 76.22, 76.11, 76.41, 76.54, 76.58, 76.65, 76.35, 76.24, 77.11, 77.0, 76.43, 77.22, 76.94, 76.84, 76.96, 77.0, 77.48, 77.66, 77.94, 77.62, 77.52, 77.18, 77.75, 77.64, 77.42, 77.2, 77.78, 78.06, 77.51, 77.73, 77.14, 77.53, 77.64, 77.72]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.4 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 18, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 16, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 19, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 12, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.942, Test loss: 2.179, Test accuracy: 23.93
Round   1, Train loss: 1.504, Test loss: 1.783, Test accuracy: 35.21
Round   2, Train loss: 1.401, Test loss: 1.744, Test accuracy: 35.52
Round   3, Train loss: 1.326, Test loss: 1.490, Test accuracy: 41.60
Round   4, Train loss: 1.302, Test loss: 1.321, Test accuracy: 50.32
Round   5, Train loss: 1.217, Test loss: 1.262, Test accuracy: 50.70
Round   6, Train loss: 1.130, Test loss: 1.179, Test accuracy: 54.27
Round   7, Train loss: 1.194, Test loss: 1.134, Test accuracy: 55.60
Round   8, Train loss: 1.084, Test loss: 1.139, Test accuracy: 55.36
Round   9, Train loss: 1.034, Test loss: 1.051, Test accuracy: 59.31
Round  10, Train loss: 1.081, Test loss: 1.051, Test accuracy: 59.49
Round  11, Train loss: 0.966, Test loss: 1.019, Test accuracy: 61.25
Round  12, Train loss: 1.019, Test loss: 0.931, Test accuracy: 63.51
Round  13, Train loss: 1.011, Test loss: 0.918, Test accuracy: 64.59
Round  14, Train loss: 1.004, Test loss: 0.905, Test accuracy: 64.44
Round  15, Train loss: 0.993, Test loss: 0.893, Test accuracy: 65.30
Round  16, Train loss: 0.946, Test loss: 0.891, Test accuracy: 65.80
Round  17, Train loss: 0.920, Test loss: 0.875, Test accuracy: 67.21
Round  18, Train loss: 0.980, Test loss: 0.864, Test accuracy: 66.99
Round  19, Train loss: 0.899, Test loss: 0.871, Test accuracy: 66.95
Round  20, Train loss: 0.877, Test loss: 0.835, Test accuracy: 68.51
Round  21, Train loss: 0.866, Test loss: 0.848, Test accuracy: 67.74
Round  22, Train loss: 0.963, Test loss: 0.831, Test accuracy: 68.38
Round  23, Train loss: 0.880, Test loss: 0.807, Test accuracy: 69.27
Round  24, Train loss: 0.836, Test loss: 0.794, Test accuracy: 70.21
Round  25, Train loss: 0.849, Test loss: 0.787, Test accuracy: 70.46
Round  26, Train loss: 0.748, Test loss: 0.773, Test accuracy: 71.30
Round  27, Train loss: 0.769, Test loss: 0.762, Test accuracy: 71.69
Round  28, Train loss: 0.770, Test loss: 0.748, Test accuracy: 71.85
Round  29, Train loss: 0.741, Test loss: 0.756, Test accuracy: 71.27
Round  30, Train loss: 0.818, Test loss: 0.746, Test accuracy: 71.60
Round  31, Train loss: 0.782, Test loss: 0.725, Test accuracy: 72.02
Round  32, Train loss: 0.693, Test loss: 0.720, Test accuracy: 72.66
Round  33, Train loss: 0.767, Test loss: 0.725, Test accuracy: 72.47
Round  34, Train loss: 0.788, Test loss: 0.713, Test accuracy: 72.79
Round  35, Train loss: 0.799, Test loss: 0.709, Test accuracy: 73.42
Round  36, Train loss: 0.819, Test loss: 0.706, Test accuracy: 73.23
Round  37, Train loss: 0.745, Test loss: 0.701, Test accuracy: 73.63
Round  38, Train loss: 0.747, Test loss: 0.697, Test accuracy: 74.01
Round  39, Train loss: 0.699, Test loss: 0.690, Test accuracy: 73.89
Round  40, Train loss: 0.715, Test loss: 0.682, Test accuracy: 74.51
Round  41, Train loss: 0.710, Test loss: 0.672, Test accuracy: 74.77
Round  42, Train loss: 0.705, Test loss: 0.668, Test accuracy: 74.73
Round  43, Train loss: 0.790, Test loss: 0.670, Test accuracy: 74.46
Round  44, Train loss: 0.713, Test loss: 0.665, Test accuracy: 74.68
Round  45, Train loss: 0.775, Test loss: 0.660, Test accuracy: 74.94
Round  46, Train loss: 0.636, Test loss: 0.662, Test accuracy: 74.75
Round  47, Train loss: 0.648, Test loss: 0.654, Test accuracy: 75.41
Round  48, Train loss: 0.642, Test loss: 0.651, Test accuracy: 75.31
Round  49, Train loss: 0.658, Test loss: 0.642, Test accuracy: 75.24
Round  50, Train loss: 0.574, Test loss: 0.643, Test accuracy: 75.79
Round  51, Train loss: 0.637, Test loss: 0.634, Test accuracy: 76.10
Round  52, Train loss: 0.585, Test loss: 0.638, Test accuracy: 75.77
Round  53, Train loss: 0.666, Test loss: 0.634, Test accuracy: 76.17
Round  54, Train loss: 0.577, Test loss: 0.631, Test accuracy: 76.04
Round  55, Train loss: 0.664, Test loss: 0.632, Test accuracy: 76.13
Round  56, Train loss: 0.597, Test loss: 0.620, Test accuracy: 76.80
Round  57, Train loss: 0.558, Test loss: 0.618, Test accuracy: 76.75
Round  58, Train loss: 0.566, Test loss: 0.622, Test accuracy: 76.92
Round  59, Train loss: 0.629, Test loss: 0.621, Test accuracy: 77.09
Round  60, Train loss: 0.652, Test loss: 0.620, Test accuracy: 76.71
Round  61, Train loss: 0.607, Test loss: 0.617, Test accuracy: 76.77
Round  62, Train loss: 0.582, Test loss: 0.619, Test accuracy: 76.61
Round  63, Train loss: 0.518, Test loss: 0.618, Test accuracy: 76.74
Round  64, Train loss: 0.603, Test loss: 0.621, Test accuracy: 76.69
Round  65, Train loss: 0.576, Test loss: 0.612, Test accuracy: 77.19
Round  66, Train loss: 0.522, Test loss: 0.618, Test accuracy: 76.57
Round  67, Train loss: 0.514, Test loss: 0.618, Test accuracy: 76.85
Round  68, Train loss: 0.561, Test loss: 0.616, Test accuracy: 77.02
Round  69, Train loss: 0.595, Test loss: 0.609, Test accuracy: 77.41
Round  70, Train loss: 0.544, Test loss: 0.604, Test accuracy: 77.47
Round  71, Train loss: 0.520, Test loss: 0.609, Test accuracy: 77.29
Round  72, Train loss: 0.553, Test loss: 0.606, Test accuracy: 77.45
Round  73, Train loss: 0.480, Test loss: 0.597, Test accuracy: 77.88
Round  74, Train loss: 0.447, Test loss: 0.595, Test accuracy: 77.65
Round  75, Train loss: 0.573, Test loss: 0.597, Test accuracy: 78.08
Round  76, Train loss: 0.428, Test loss: 0.598, Test accuracy: 78.06
Round  77, Train loss: 0.552, Test loss: 0.600, Test accuracy: 78.22
Round  78, Train loss: 0.549, Test loss: 0.603, Test accuracy: 77.56
Round  79, Train loss: 0.527, Test loss: 0.610, Test accuracy: 77.49
Round  80, Train loss: 0.555, Test loss: 0.596, Test accuracy: 78.18
Round  81, Train loss: 0.509, Test loss: 0.612, Test accuracy: 77.26
Round  82, Train loss: 0.478, Test loss: 0.597, Test accuracy: 77.79
Round  83, Train loss: 0.491, Test loss: 0.597, Test accuracy: 77.58
Round  84, Train loss: 0.456, Test loss: 0.595, Test accuracy: 77.85
Round  85, Train loss: 0.479, Test loss: 0.598, Test accuracy: 77.85
Round  86, Train loss: 0.444, Test loss: 0.595, Test accuracy: 77.82
Round  87, Train loss: 0.395, Test loss: 0.589, Test accuracy: 78.15
Round  88, Train loss: 0.456, Test loss: 0.589, Test accuracy: 78.17
Round  89, Train loss: 0.490, Test loss: 0.592, Test accuracy: 77.91
Round  90, Train loss: 0.487, Test loss: 0.594, Test accuracy: 78.18
Round  91, Train loss: 0.462, Test loss: 0.596, Test accuracy: 78.05
Round  92, Train loss: 0.556, Test loss: 0.593, Test accuracy: 78.21
Round  93, Train loss: 0.490, Test loss: 0.589, Test accuracy: 77.88
Round  94, Train loss: 0.464, Test loss: 0.590, Test accuracy: 78.24
Round  95, Train loss: 0.482, Test loss: 0.601, Test accuracy: 77.89
Round  96, Train loss: 0.496, Test loss: 0.611, Test accuracy: 77.90
Round  97, Train loss: 0.483, Test loss: 0.594, Test accuracy: 78.14
Round  98, Train loss: 0.459, Test loss: 0.598, Test accuracy: 78.47
Round  99, Train loss: 0.436, Test loss: 0.598, Test accuracy: 78.13
Final Round, Train loss: 0.273, Test loss: 0.593, Test accuracy: 78.36
Average accuracy final 10 rounds: 78.10900000000001
1986.750476360321
[1.694878101348877, 3.1718266010284424, 4.657161235809326, 6.158019304275513, 7.640771150588989, 9.1369149684906, 10.653920412063599, 12.122026205062866, 13.577197790145874, 15.048088788986206, 16.537151336669922, 18.00574254989624, 19.485713243484497, 20.961462020874023, 22.42803645133972, 23.76406168937683, 25.079533100128174, 26.405226469039917, 27.744104385375977, 29.095301389694214, 30.39015507698059, 33.501428842544556, 36.741389989852905, 39.947773456573486, 43.17877197265625, 46.43372082710266, 49.74954628944397, 53.03341865539551, 56.22636604309082, 59.45997166633606, 62.79148554801941, 66.04156470298767, 69.19631719589233, 72.60741806030273, 75.77493858337402, 79.02972412109375, 82.10594892501831, 85.36292266845703, 88.67718267440796, 91.84607410430908, 95.19792199134827, 98.3471131324768, 101.56349301338196, 104.73216819763184, 108.11177158355713, 111.28776955604553, 114.54978227615356, 117.73046970367432, 121.03035688400269, 124.23575687408447, 127.50588536262512, 130.71181178092957, 133.99618458747864, 137.29250526428223, 140.39098405838013, 143.630455493927, 146.80791926383972, 150.08776092529297, 153.27687883377075, 156.66807222366333, 160.00190258026123, 163.2424921989441, 166.68690395355225, 169.97118830680847, 173.37752985954285, 176.7583944797516, 180.22070908546448, 183.67445755004883, 187.05274486541748, 190.4300684928894, 193.6935646533966, 197.09679174423218, 200.343487739563, 203.87332201004028, 207.32067775726318, 210.7884213924408, 214.22667717933655, 217.4419720172882, 220.86338448524475, 224.20918917655945, 227.71658444404602, 231.08703923225403, 234.58520531654358, 238.02412366867065, 241.3755226135254, 244.8271300792694, 248.22613859176636, 251.63584280014038, 255.00415349006653, 258.4473524093628, 261.83448553085327, 265.11646270751953, 268.5566077232361, 272.07487511634827, 275.43709921836853, 278.79320764541626, 282.1833896636963, 285.66383051872253, 289.05326557159424, 292.4884934425354, 294.7459006309509]
[23.93, 35.21, 35.52, 41.6, 50.32, 50.7, 54.27, 55.6, 55.36, 59.31, 59.49, 61.25, 63.51, 64.59, 64.44, 65.3, 65.8, 67.21, 66.99, 66.95, 68.51, 67.74, 68.38, 69.27, 70.21, 70.46, 71.3, 71.69, 71.85, 71.27, 71.6, 72.02, 72.66, 72.47, 72.79, 73.42, 73.23, 73.63, 74.01, 73.89, 74.51, 74.77, 74.73, 74.46, 74.68, 74.94, 74.75, 75.41, 75.31, 75.24, 75.79, 76.1, 75.77, 76.17, 76.04, 76.13, 76.8, 76.75, 76.92, 77.09, 76.71, 76.77, 76.61, 76.74, 76.69, 77.19, 76.57, 76.85, 77.02, 77.41, 77.47, 77.29, 77.45, 77.88, 77.65, 78.08, 78.06, 78.22, 77.56, 77.49, 78.18, 77.26, 77.79, 77.58, 77.85, 77.85, 77.82, 78.15, 78.17, 77.91, 78.18, 78.05, 78.21, 77.88, 78.24, 77.89, 77.9, 78.14, 78.47, 78.13, 78.36]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: none, level_n_system: 0.4 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 8, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 16, noise    level: 0.4000 
   Client 11, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 10, noise    level: 0.4000 
   Client 13, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.944, Test loss: 1.766, Test accuracy: 37.30
Round   1, Train loss: 1.514, Test loss: 1.373, Test accuracy: 42.66
Round   2, Train loss: 1.384, Test loss: 1.261, Test accuracy: 47.89
Round   3, Train loss: 1.315, Test loss: 1.193, Test accuracy: 52.12
Round   4, Train loss: 1.263, Test loss: 1.136, Test accuracy: 53.58
Round   5, Train loss: 1.218, Test loss: 1.092, Test accuracy: 55.96
Round   6, Train loss: 1.178, Test loss: 1.058, Test accuracy: 57.04
Round   7, Train loss: 1.146, Test loss: 1.015, Test accuracy: 59.18
Round   8, Train loss: 1.119, Test loss: 1.001, Test accuracy: 60.32
Round   9, Train loss: 1.097, Test loss: 0.969, Test accuracy: 62.11
Round  10, Train loss: 1.073, Test loss: 0.952, Test accuracy: 62.91
Round  11, Train loss: 1.053, Test loss: 0.939, Test accuracy: 63.49
Round  12, Train loss: 1.034, Test loss: 0.919, Test accuracy: 64.55
Round  13, Train loss: 1.018, Test loss: 0.897, Test accuracy: 65.64
Round  14, Train loss: 0.999, Test loss: 0.874, Test accuracy: 66.87
Round  15, Train loss: 0.984, Test loss: 0.867, Test accuracy: 67.03
Round  16, Train loss: 0.965, Test loss: 0.856, Test accuracy: 67.48
Round  17, Train loss: 0.954, Test loss: 0.836, Test accuracy: 68.33
Round  18, Train loss: 0.935, Test loss: 0.822, Test accuracy: 68.59
Round  19, Train loss: 0.920, Test loss: 0.812, Test accuracy: 69.17
Round  20, Train loss: 0.899, Test loss: 0.809, Test accuracy: 69.43
Round  21, Train loss: 0.875, Test loss: 0.804, Test accuracy: 70.05
Round  22, Train loss: 0.896, Test loss: 0.791, Test accuracy: 69.85
Round  23, Train loss: 0.836, Test loss: 0.795, Test accuracy: 69.62
Round  24, Train loss: 0.937, Test loss: 0.774, Test accuracy: 70.73
Round  25, Train loss: 0.912, Test loss: 0.769, Test accuracy: 71.24
Round  26, Train loss: 0.813, Test loss: 0.755, Test accuracy: 71.72
Round  27, Train loss: 0.826, Test loss: 0.752, Test accuracy: 72.17
Round  28, Train loss: 0.811, Test loss: 0.747, Test accuracy: 72.13
Round  29, Train loss: 0.713, Test loss: 0.747, Test accuracy: 71.98
Round  30, Train loss: 0.825, Test loss: 0.726, Test accuracy: 72.69
Round  31, Train loss: 0.754, Test loss: 0.729, Test accuracy: 72.81
Round  32, Train loss: 0.767, Test loss: 0.727, Test accuracy: 72.21
Round  33, Train loss: 0.785, Test loss: 0.724, Test accuracy: 72.26
Round  34, Train loss: 0.801, Test loss: 0.718, Test accuracy: 73.04
Round  35, Train loss: 0.741, Test loss: 0.707, Test accuracy: 73.57
Round  36, Train loss: 0.763, Test loss: 0.699, Test accuracy: 73.40
Round  37, Train loss: 0.802, Test loss: 0.694, Test accuracy: 74.05
Round  38, Train loss: 0.779, Test loss: 0.690, Test accuracy: 74.30
Round  39, Train loss: 0.701, Test loss: 0.692, Test accuracy: 74.44
Round  40, Train loss: 0.715, Test loss: 0.682, Test accuracy: 74.70
Round  41, Train loss: 0.818, Test loss: 0.681, Test accuracy: 74.94
Round  42, Train loss: 0.704, Test loss: 0.682, Test accuracy: 74.88
Round  43, Train loss: 0.758, Test loss: 0.676, Test accuracy: 74.82
Round  44, Train loss: 0.697, Test loss: 0.677, Test accuracy: 74.72
Round  45, Train loss: 0.734, Test loss: 0.670, Test accuracy: 74.97
Round  46, Train loss: 0.737, Test loss: 0.666, Test accuracy: 75.11
Round  47, Train loss: 0.659, Test loss: 0.673, Test accuracy: 74.75
Round  48, Train loss: 0.758, Test loss: 0.664, Test accuracy: 75.37
Round  49, Train loss: 0.709, Test loss: 0.657, Test accuracy: 75.99
Round  50, Train loss: 0.673, Test loss: 0.660, Test accuracy: 75.81
Round  51, Train loss: 0.611, Test loss: 0.667, Test accuracy: 75.57
Round  52, Train loss: 0.630, Test loss: 0.661, Test accuracy: 75.51
Round  53, Train loss: 0.644, Test loss: 0.658, Test accuracy: 75.42
Round  54, Train loss: 0.705, Test loss: 0.646, Test accuracy: 76.17
Round  55, Train loss: 0.656, Test loss: 0.633, Test accuracy: 76.99
Round  56, Train loss: 0.634, Test loss: 0.642, Test accuracy: 76.44
Round  57, Train loss: 0.672, Test loss: 0.641, Test accuracy: 76.65
Round  58, Train loss: 0.705, Test loss: 0.637, Test accuracy: 76.51
Round  59, Train loss: 0.641, Test loss: 0.633, Test accuracy: 76.75
Round  60, Train loss: 0.642, Test loss: 0.629, Test accuracy: 77.34
Round  61, Train loss: 0.549, Test loss: 0.617, Test accuracy: 77.35
Round  62, Train loss: 0.502, Test loss: 0.621, Test accuracy: 77.37
Round  63, Train loss: 0.551, Test loss: 0.624, Test accuracy: 77.44
Round  64, Train loss: 0.575, Test loss: 0.624, Test accuracy: 77.45
Round  65, Train loss: 0.615, Test loss: 0.617, Test accuracy: 77.59
Round  66, Train loss: 0.546, Test loss: 0.628, Test accuracy: 77.13
Round  67, Train loss: 0.490, Test loss: 0.640, Test accuracy: 76.83
Round  68, Train loss: 0.570, Test loss: 0.629, Test accuracy: 77.25
Round  69, Train loss: 0.589, Test loss: 0.634, Test accuracy: 77.12
Round  70, Train loss: 0.565, Test loss: 0.617, Test accuracy: 77.42
Round  71, Train loss: 0.536, Test loss: 0.622, Test accuracy: 77.41
Round  72, Train loss: 0.513, Test loss: 0.615, Test accuracy: 77.71
Round  73, Train loss: 0.513, Test loss: 0.613, Test accuracy: 77.58
Round  74, Train loss: 0.561, Test loss: 0.618, Test accuracy: 77.46
Round  75, Train loss: 0.592, Test loss: 0.612, Test accuracy: 77.75
Round  76, Train loss: 0.544, Test loss: 0.608, Test accuracy: 77.95
Round  77, Train loss: 0.551, Test loss: 0.613, Test accuracy: 77.35
Round  78, Train loss: 0.596, Test loss: 0.612, Test accuracy: 77.97
Round  79, Train loss: 0.509, Test loss: 0.614, Test accuracy: 77.83
Round  80, Train loss: 0.411, Test loss: 0.607, Test accuracy: 78.17
Round  81, Train loss: 0.392, Test loss: 0.611, Test accuracy: 77.81
Round  82, Train loss: 0.381, Test loss: 0.604, Test accuracy: 78.08
Round  83, Train loss: 0.375, Test loss: 0.606, Test accuracy: 78.24
Round  84, Train loss: 0.361, Test loss: 0.606, Test accuracy: 77.84
Round  85, Train loss: 0.355, Test loss: 0.616, Test accuracy: 77.53
Round  86, Train loss: 0.347, Test loss: 0.609, Test accuracy: 77.80
Round  87, Train loss: 0.340, Test loss: 0.614, Test accuracy: 78.00
Round  88, Train loss: 0.332, Test loss: 0.616, Test accuracy: 77.85
Round  89, Train loss: 0.329, Test loss: 0.631, Test accuracy: 77.04
Round  90, Train loss: 0.322, Test loss: 0.633, Test accuracy: 77.39
Round  91, Train loss: 0.310, Test loss: 0.637, Test accuracy: 77.02
Round  92, Train loss: 0.305, Test loss: 0.641, Test accuracy: 76.73
Round  93, Train loss: 0.303, Test loss: 0.642, Test accuracy: 76.55
Round  94, Train loss: 0.298, Test loss: 0.637, Test accuracy: 76.89
Round  95, Train loss: 0.286, Test loss: 0.648, Test accuracy: 76.67
Round  96, Train loss: 0.284, Test loss: 0.641, Test accuracy: 76.67
Round  97, Train loss: 0.288, Test loss: 0.650, Test accuracy: 76.42
Round  98, Train loss: 0.278, Test loss: 0.642, Test accuracy: 77.01
Round  99, Train loss: 0.277, Test loss: 0.643, Test accuracy: 76.95
Final Round, Train loss: 0.208, Test loss: 0.645, Test accuracy: 76.85
Average accuracy final 10 rounds: 76.83000000000001
1641.8355040550232
[1.8295495510101318, 3.3635671138763428, 4.910058498382568, 6.458181381225586, 8.022189617156982, 9.59489369392395, 11.144593238830566, 12.690967798233032, 14.259979963302612, 15.840791463851929, 17.37779211997986, 18.91692566871643, 20.430647134780884, 21.79738450050354, 23.218242406845093, 24.60372805595398, 25.988895416259766, 27.374337196350098, 28.76248335838318, 30.135614156723022, 31.448291063308716, 32.7682363986969, 34.08606266975403, 35.39932680130005, 36.74185562133789, 38.04796743392944, 39.38083457946777, 40.68799090385437, 41.97944450378418, 43.30613589286804, 44.61972665786743, 45.95274782180786, 47.26621127128601, 48.580333948135376, 49.901246070861816, 51.21747279167175, 52.53430151939392, 53.84925198554993, 55.158812284469604, 56.46198844909668, 57.790523290634155, 59.12625694274902, 60.41915464401245, 61.79186034202576, 63.14499282836914, 64.44670057296753, 65.79360318183899, 67.1472098827362, 68.48484253883362, 69.8303530216217, 71.16924500465393, 72.47809839248657, 73.84722971916199, 75.17958164215088, 76.52599668502808, 77.88540482521057, 79.23044490814209, 80.6083071231842, 81.95618176460266, 83.34364938735962, 84.80688452720642, 86.26423215866089, 87.69463729858398, 89.08918309211731, 90.59005761146545, 91.99787759780884, 93.44602298736572, 94.98962926864624, 96.41019678115845, 97.87223696708679, 99.32609343528748, 100.8676369190216, 102.80087685585022, 104.5153865814209, 106.31961727142334, 107.98548030853271, 109.39806461334229, 110.83870053291321, 112.23796701431274, 113.66716051101685, 115.23722720146179, 116.8755362033844, 118.85282731056213, 120.31850171089172, 121.8325822353363, 123.26886129379272, 124.80193734169006, 126.26227617263794, 127.77188730239868, 129.10981917381287, 130.48672199249268, 131.8497669696808, 133.21285009384155, 134.5076289176941, 135.9040789604187, 137.2593274116516, 138.75924444198608, 140.24633193016052, 141.74184036254883, 143.47130918502808, 146.10194087028503]
[37.3, 42.66, 47.89, 52.12, 53.58, 55.96, 57.04, 59.18, 60.32, 62.11, 62.91, 63.49, 64.55, 65.64, 66.87, 67.03, 67.48, 68.33, 68.59, 69.17, 69.43, 70.05, 69.85, 69.62, 70.73, 71.24, 71.72, 72.17, 72.13, 71.98, 72.69, 72.81, 72.21, 72.26, 73.04, 73.57, 73.4, 74.05, 74.3, 74.44, 74.7, 74.94, 74.88, 74.82, 74.72, 74.97, 75.11, 74.75, 75.37, 75.99, 75.81, 75.57, 75.51, 75.42, 76.17, 76.99, 76.44, 76.65, 76.51, 76.75, 77.34, 77.35, 77.37, 77.44, 77.45, 77.59, 77.13, 76.83, 77.25, 77.12, 77.42, 77.41, 77.71, 77.58, 77.46, 77.75, 77.95, 77.35, 77.97, 77.83, 78.17, 77.81, 78.08, 78.24, 77.84, 77.53, 77.8, 78.0, 77.85, 77.04, 77.39, 77.02, 76.73, 76.55, 76.89, 76.67, 76.67, 76.42, 77.01, 76.95, 76.85]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.4 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 3, noise    level: 0.4000 
   Client 14, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 16, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.975, Test loss: 1.879, Test accuracy: 35.27
Round   1, Train loss: 1.532, Test loss: 1.370, Test accuracy: 42.15
Round   2, Train loss: 1.387, Test loss: 1.275, Test accuracy: 47.61
Round   3, Train loss: 1.317, Test loss: 1.198, Test accuracy: 50.41
Round   4, Train loss: 1.256, Test loss: 1.137, Test accuracy: 54.00
Round   5, Train loss: 1.212, Test loss: 1.088, Test accuracy: 56.66
Round   6, Train loss: 1.173, Test loss: 1.060, Test accuracy: 57.13
Round   7, Train loss: 1.139, Test loss: 1.015, Test accuracy: 59.92
Round   8, Train loss: 1.115, Test loss: 0.986, Test accuracy: 61.32
Round   9, Train loss: 1.085, Test loss: 0.979, Test accuracy: 61.65
Round  10, Train loss: 1.067, Test loss: 0.946, Test accuracy: 63.57
Round  11, Train loss: 1.047, Test loss: 0.929, Test accuracy: 64.04
Round  12, Train loss: 1.023, Test loss: 0.915, Test accuracy: 64.65
Round  13, Train loss: 1.010, Test loss: 0.894, Test accuracy: 65.76
Round  14, Train loss: 0.994, Test loss: 0.887, Test accuracy: 66.25
Round  15, Train loss: 0.980, Test loss: 0.872, Test accuracy: 67.29
Round  16, Train loss: 0.966, Test loss: 0.858, Test accuracy: 67.62
Round  17, Train loss: 0.946, Test loss: 0.852, Test accuracy: 68.13
Round  18, Train loss: 0.930, Test loss: 0.830, Test accuracy: 68.84
Round  19, Train loss: 0.919, Test loss: 0.818, Test accuracy: 69.19
Round  20, Train loss: 0.885, Test loss: 0.823, Test accuracy: 69.42
Round  21, Train loss: 0.938, Test loss: 0.813, Test accuracy: 69.50
Round  22, Train loss: 0.939, Test loss: 0.811, Test accuracy: 69.99
Round  23, Train loss: 0.919, Test loss: 0.794, Test accuracy: 70.26
Round  24, Train loss: 0.887, Test loss: 0.789, Test accuracy: 70.37
Round  25, Train loss: 0.844, Test loss: 0.781, Test accuracy: 70.60
Round  26, Train loss: 0.791, Test loss: 0.774, Test accuracy: 70.87
Round  27, Train loss: 0.829, Test loss: 0.782, Test accuracy: 70.94
Round  28, Train loss: 0.831, Test loss: 0.781, Test accuracy: 71.53
Round  29, Train loss: 0.822, Test loss: 0.770, Test accuracy: 71.33
Round  30, Train loss: 0.808, Test loss: 0.748, Test accuracy: 72.17
Round  31, Train loss: 0.894, Test loss: 0.746, Test accuracy: 72.41
Round  32, Train loss: 0.745, Test loss: 0.743, Test accuracy: 72.96
Round  33, Train loss: 0.722, Test loss: 0.733, Test accuracy: 72.81
Round  34, Train loss: 0.838, Test loss: 0.717, Test accuracy: 73.36
Round  35, Train loss: 0.750, Test loss: 0.714, Test accuracy: 73.78
Round  36, Train loss: 0.777, Test loss: 0.705, Test accuracy: 73.88
Round  37, Train loss: 0.729, Test loss: 0.703, Test accuracy: 73.89
Round  38, Train loss: 0.784, Test loss: 0.715, Test accuracy: 73.92
Round  39, Train loss: 0.726, Test loss: 0.702, Test accuracy: 74.07
Round  40, Train loss: 0.754, Test loss: 0.703, Test accuracy: 73.81
Round  41, Train loss: 0.752, Test loss: 0.703, Test accuracy: 74.34
Round  42, Train loss: 0.781, Test loss: 0.703, Test accuracy: 74.18
Round  43, Train loss: 0.788, Test loss: 0.697, Test accuracy: 73.96
Round  44, Train loss: 0.765, Test loss: 0.695, Test accuracy: 74.22
Round  45, Train loss: 0.753, Test loss: 0.678, Test accuracy: 75.01
Round  46, Train loss: 0.673, Test loss: 0.681, Test accuracy: 74.55
Round  47, Train loss: 0.646, Test loss: 0.680, Test accuracy: 74.52
Round  48, Train loss: 0.645, Test loss: 0.662, Test accuracy: 75.47
Round  49, Train loss: 0.631, Test loss: 0.656, Test accuracy: 76.34
Round  50, Train loss: 0.606, Test loss: 0.663, Test accuracy: 75.99
Round  51, Train loss: 0.736, Test loss: 0.672, Test accuracy: 75.49
Round  52, Train loss: 0.643, Test loss: 0.656, Test accuracy: 76.26
Round  53, Train loss: 0.660, Test loss: 0.654, Test accuracy: 76.41
Round  54, Train loss: 0.620, Test loss: 0.643, Test accuracy: 76.41
Round  55, Train loss: 0.706, Test loss: 0.655, Test accuracy: 76.41
Round  56, Train loss: 0.603, Test loss: 0.641, Test accuracy: 76.64
Round  57, Train loss: 0.548, Test loss: 0.641, Test accuracy: 76.71
Round  58, Train loss: 0.546, Test loss: 0.648, Test accuracy: 76.09
Round  59, Train loss: 0.573, Test loss: 0.633, Test accuracy: 76.99
Round  60, Train loss: 0.662, Test loss: 0.639, Test accuracy: 76.51
Round  61, Train loss: 0.626, Test loss: 0.633, Test accuracy: 77.02
Round  62, Train loss: 0.597, Test loss: 0.639, Test accuracy: 76.20
Round  63, Train loss: 0.546, Test loss: 0.629, Test accuracy: 76.79
Round  64, Train loss: 0.561, Test loss: 0.631, Test accuracy: 76.72
Round  65, Train loss: 0.601, Test loss: 0.624, Test accuracy: 76.68
Round  66, Train loss: 0.483, Test loss: 0.624, Test accuracy: 77.01
Round  67, Train loss: 0.632, Test loss: 0.643, Test accuracy: 76.17
Round  68, Train loss: 0.503, Test loss: 0.628, Test accuracy: 76.54
Round  69, Train loss: 0.646, Test loss: 0.615, Test accuracy: 77.35
Round  70, Train loss: 0.526, Test loss: 0.616, Test accuracy: 77.31
Round  71, Train loss: 0.535, Test loss: 0.615, Test accuracy: 77.60
Round  72, Train loss: 0.540, Test loss: 0.614, Test accuracy: 77.81
Round  73, Train loss: 0.552, Test loss: 0.624, Test accuracy: 77.29
Round  74, Train loss: 0.525, Test loss: 0.618, Test accuracy: 77.59
Round  75, Train loss: 0.566, Test loss: 0.610, Test accuracy: 77.84
Round  76, Train loss: 0.486, Test loss: 0.608, Test accuracy: 78.01
Round  77, Train loss: 0.579, Test loss: 0.615, Test accuracy: 77.67
Round  78, Train loss: 0.565, Test loss: 0.611, Test accuracy: 77.97
Round  79, Train loss: 0.565, Test loss: 0.608, Test accuracy: 78.20
Round  80, Train loss: 0.416, Test loss: 0.601, Test accuracy: 77.94
Round  81, Train loss: 0.399, Test loss: 0.604, Test accuracy: 77.96
Round  82, Train loss: 0.393, Test loss: 0.602, Test accuracy: 78.02
Round  83, Train loss: 0.375, Test loss: 0.602, Test accuracy: 77.89
Round  84, Train loss: 0.364, Test loss: 0.605, Test accuracy: 77.96
Round  85, Train loss: 0.349, Test loss: 0.605, Test accuracy: 78.03
Round  86, Train loss: 0.352, Test loss: 0.601, Test accuracy: 77.99
Round  87, Train loss: 0.346, Test loss: 0.605, Test accuracy: 78.28
Round  88, Train loss: 0.336, Test loss: 0.608, Test accuracy: 77.73
Round  89, Train loss: 0.330, Test loss: 0.612, Test accuracy: 77.62
Round  90, Train loss: 0.323, Test loss: 0.604, Test accuracy: 77.98
Round  91, Train loss: 0.327, Test loss: 0.608, Test accuracy: 78.14
Round  92, Train loss: 0.315, Test loss: 0.617, Test accuracy: 77.74
Round  93, Train loss: 0.306, Test loss: 0.623, Test accuracy: 77.40
Round  94, Train loss: 0.301, Test loss: 0.624, Test accuracy: 77.53
Round  95, Train loss: 0.300, Test loss: 0.623, Test accuracy: 77.66
Round  96, Train loss: 0.298, Test loss: 0.627, Test accuracy: 77.62
Round  97, Train loss: 0.286, Test loss: 0.618, Test accuracy: 77.74
Round  98, Train loss: 0.290, Test loss: 0.627, Test accuracy: 77.51
Round  99, Train loss: 0.276, Test loss: 0.622, Test accuracy: 77.45
Final Round, Train loss: 0.215, Test loss: 0.626, Test accuracy: 77.51
Average accuracy final 10 rounds: 77.677
2660.0968289375305
[1.7674238681793213, 3.3100271224975586, 4.7391369342803955, 6.381424188613892, 8.255579233169556, 9.6919424533844, 11.152111291885376, 12.647394180297852, 14.363633632659912, 15.997053146362305, 17.868903398513794, 19.52070116996765, 21.204176902770996, 22.816259384155273, 24.694933891296387, 26.59456706047058, 28.551451206207275, 29.96220588684082, 31.302201747894287, 32.66560459136963, 33.991676330566406, 37.29506993293762, 40.49788475036621, 43.765005111694336, 46.89929246902466, 50.184913635253906, 53.28633689880371, 56.47350740432739, 59.78098392486572, 63.531065225601196, 66.82741022109985, 70.11355209350586, 73.67538857460022, 77.6457347869873, 81.75936317443848, 85.3028507232666, 88.60893225669861, 91.8347635269165, 95.17806577682495, 98.53089833259583, 101.72216582298279, 104.91074085235596, 108.55650424957275, 112.23002123832703, 115.52297878265381, 118.85704731941223, 122.21768403053284, 125.62190985679626, 129.00356936454773, 132.3954634666443, 135.90546536445618, 139.2672734260559, 142.5549955368042, 146.04422879219055, 149.3968961238861, 152.8297188282013, 156.23017835617065, 159.42720365524292, 162.70663976669312, 165.86069655418396, 169.2438199520111, 172.35260605812073, 175.6477563381195, 178.9991147518158, 182.30091381072998, 185.7125701904297, 188.96722030639648, 192.26119375228882, 195.6008529663086, 199.06351590156555, 202.31207847595215, 205.6673469543457, 208.90880680084229, 212.40296816825867, 215.7926127910614, 219.16222763061523, 222.39153480529785, 225.86229491233826, 229.1073968410492, 232.42229056358337, 235.77835941314697, 239.15427112579346, 242.53846502304077, 245.85693788528442, 249.21520042419434, 252.63034653663635, 255.9143078327179, 259.34438467025757, 262.7836682796478, 266.1525115966797, 269.48374223709106, 272.8776078224182, 276.2902772426605, 279.714656829834, 283.18332076072693, 286.6477210521698, 290.01457929611206, 293.3788230419159, 296.75742745399475, 300.08777499198914, 302.19338822364807]
[35.27, 42.15, 47.61, 50.41, 54.0, 56.66, 57.13, 59.92, 61.32, 61.65, 63.57, 64.04, 64.65, 65.76, 66.25, 67.29, 67.62, 68.13, 68.84, 69.19, 69.42, 69.5, 69.99, 70.26, 70.37, 70.6, 70.87, 70.94, 71.53, 71.33, 72.17, 72.41, 72.96, 72.81, 73.36, 73.78, 73.88, 73.89, 73.92, 74.07, 73.81, 74.34, 74.18, 73.96, 74.22, 75.01, 74.55, 74.52, 75.47, 76.34, 75.99, 75.49, 76.26, 76.41, 76.41, 76.41, 76.64, 76.71, 76.09, 76.99, 76.51, 77.02, 76.2, 76.79, 76.72, 76.68, 77.01, 76.17, 76.54, 77.35, 77.31, 77.6, 77.81, 77.29, 77.59, 77.84, 78.01, 77.67, 77.97, 78.2, 77.94, 77.96, 78.02, 77.89, 77.96, 78.03, 77.99, 78.28, 77.73, 77.62, 77.98, 78.14, 77.74, 77.4, 77.53, 77.66, 77.62, 77.74, 77.51, 77.45, 77.51]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 19, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
   Client 18, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 17, noise    level: 0.8000 
   Client 11, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.742, Test loss: 2.061, Test accuracy: 21.50
Round   0, Global train loss: 1.742, Global test loss: 2.252, Global test accuracy: 17.25
Round   1, Train loss: 1.500, Test loss: 1.995, Test accuracy: 24.61
Round   1, Global train loss: 1.500, Global test loss: 2.375, Global test accuracy: 18.30
Round   2, Train loss: 1.460, Test loss: 1.624, Test accuracy: 34.74
Round   2, Global train loss: 1.460, Global test loss: 2.043, Global test accuracy: 28.22
Round   3, Train loss: 1.457, Test loss: 1.555, Test accuracy: 37.64
Round   3, Global train loss: 1.457, Global test loss: 2.072, Global test accuracy: 24.56
Round   4, Train loss: 1.366, Test loss: 1.488, Test accuracy: 39.21
Round   4, Global train loss: 1.366, Global test loss: 2.053, Global test accuracy: 27.07
Round   5, Train loss: 1.399, Test loss: 1.474, Test accuracy: 39.46
Round   5, Global train loss: 1.399, Global test loss: 2.122, Global test accuracy: 23.65
Round   6, Train loss: 1.368, Test loss: 1.403, Test accuracy: 40.63
Round   6, Global train loss: 1.368, Global test loss: 2.145, Global test accuracy: 17.00
Round   7, Train loss: 1.371, Test loss: 1.390, Test accuracy: 41.18
Round   7, Global train loss: 1.371, Global test loss: 2.050, Global test accuracy: 23.01
Round   8, Train loss: 1.222, Test loss: 1.395, Test accuracy: 42.56
Round   8, Global train loss: 1.222, Global test loss: 2.057, Global test accuracy: 26.26
Round   9, Train loss: 1.341, Test loss: 1.398, Test accuracy: 42.77
Round   9, Global train loss: 1.341, Global test loss: 2.235, Global test accuracy: 16.25
Round  10, Train loss: 1.244, Test loss: 1.342, Test accuracy: 45.25
Round  10, Global train loss: 1.244, Global test loss: 2.055, Global test accuracy: 23.99
Round  11, Train loss: 1.130, Test loss: 1.352, Test accuracy: 45.35
Round  11, Global train loss: 1.130, Global test loss: 1.969, Global test accuracy: 33.33
Round  12, Train loss: 1.084, Test loss: 1.355, Test accuracy: 45.86
Round  12, Global train loss: 1.084, Global test loss: 2.140, Global test accuracy: 28.44
Round  13, Train loss: 1.336, Test loss: 1.300, Test accuracy: 47.39
Round  13, Global train loss: 1.336, Global test loss: 2.073, Global test accuracy: 29.47
Round  14, Train loss: 1.166, Test loss: 1.293, Test accuracy: 48.23
Round  14, Global train loss: 1.166, Global test loss: 2.063, Global test accuracy: 30.33
Round  15, Train loss: 1.403, Test loss: 1.286, Test accuracy: 47.77
Round  15, Global train loss: 1.403, Global test loss: 2.234, Global test accuracy: 21.96
Round  16, Train loss: 1.008, Test loss: 1.279, Test accuracy: 47.95
Round  16, Global train loss: 1.008, Global test loss: 2.029, Global test accuracy: 25.58
Round  17, Train loss: 1.275, Test loss: 1.280, Test accuracy: 48.03
Round  17, Global train loss: 1.275, Global test loss: 2.160, Global test accuracy: 25.20
Round  18, Train loss: 1.359, Test loss: 1.293, Test accuracy: 47.27
Round  18, Global train loss: 1.359, Global test loss: 2.138, Global test accuracy: 22.87
Round  19, Train loss: 1.121, Test loss: 1.290, Test accuracy: 47.57
Round  19, Global train loss: 1.121, Global test loss: 1.885, Global test accuracy: 32.65
Round  20, Train loss: 1.092, Test loss: 1.273, Test accuracy: 47.98
Round  20, Global train loss: 1.092, Global test loss: 1.967, Global test accuracy: 27.85
Round  21, Train loss: 1.271, Test loss: 1.280, Test accuracy: 48.02
Round  21, Global train loss: 1.271, Global test loss: 2.093, Global test accuracy: 28.73
Round  22, Train loss: 1.217, Test loss: 1.291, Test accuracy: 47.90
Round  22, Global train loss: 1.217, Global test loss: 2.084, Global test accuracy: 24.48
Round  23, Train loss: 0.945, Test loss: 1.292, Test accuracy: 47.77
Round  23, Global train loss: 0.945, Global test loss: 1.857, Global test accuracy: 37.07
Round  24, Train loss: 0.973, Test loss: 1.314, Test accuracy: 47.54
Round  24, Global train loss: 0.973, Global test loss: 1.961, Global test accuracy: 26.62
Round  25, Train loss: 0.955, Test loss: 1.328, Test accuracy: 47.80
Round  25, Global train loss: 0.955, Global test loss: 2.048, Global test accuracy: 20.36
Round  26, Train loss: 1.206, Test loss: 1.330, Test accuracy: 47.98
Round  26, Global train loss: 1.206, Global test loss: 2.079, Global test accuracy: 24.46
Round  27, Train loss: 1.176, Test loss: 1.318, Test accuracy: 48.93
Round  27, Global train loss: 1.176, Global test loss: 2.026, Global test accuracy: 24.86
Round  28, Train loss: 0.875, Test loss: 1.320, Test accuracy: 49.02
Round  28, Global train loss: 0.875, Global test loss: 1.972, Global test accuracy: 35.35
Round  29, Train loss: 0.840, Test loss: 1.333, Test accuracy: 48.60
Round  29, Global train loss: 0.840, Global test loss: 1.961, Global test accuracy: 30.92
Round  30, Train loss: 0.913, Test loss: 1.338, Test accuracy: 48.83
Round  30, Global train loss: 0.913, Global test loss: 1.850, Global test accuracy: 34.54
Round  31, Train loss: 0.690, Test loss: 1.346, Test accuracy: 49.14
Round  31, Global train loss: 0.690, Global test loss: 1.965, Global test accuracy: 32.21
Round  32, Train loss: 1.066, Test loss: 1.349, Test accuracy: 48.70
Round  32, Global train loss: 1.066, Global test loss: 1.931, Global test accuracy: 30.79
Round  33, Train loss: 0.841, Test loss: 1.370, Test accuracy: 48.60
Round  33, Global train loss: 0.841, Global test loss: 2.087, Global test accuracy: 19.43
Round  34, Train loss: 0.802, Test loss: 1.366, Test accuracy: 48.87
Round  34, Global train loss: 0.802, Global test loss: 1.959, Global test accuracy: 30.27
Round  35, Train loss: 0.986, Test loss: 1.361, Test accuracy: 49.37
Round  35, Global train loss: 0.986, Global test loss: 1.932, Global test accuracy: 35.15
Round  36, Train loss: 0.892, Test loss: 1.380, Test accuracy: 49.34
Round  36, Global train loss: 0.892, Global test loss: 2.030, Global test accuracy: 26.18
Round  37, Train loss: 0.837, Test loss: 1.388, Test accuracy: 49.15
Round  37, Global train loss: 0.837, Global test loss: 1.964, Global test accuracy: 28.33
Round  38, Train loss: 0.950, Test loss: 1.395, Test accuracy: 49.18
Round  38, Global train loss: 0.950, Global test loss: 2.097, Global test accuracy: 22.35
Round  39, Train loss: 0.687, Test loss: 1.432, Test accuracy: 48.62
Round  39, Global train loss: 0.687, Global test loss: 1.901, Global test accuracy: 32.77
Round  40, Train loss: 0.906, Test loss: 1.459, Test accuracy: 47.75
Round  40, Global train loss: 0.906, Global test loss: 1.939, Global test accuracy: 34.22
Round  41, Train loss: 1.025, Test loss: 1.464, Test accuracy: 48.02
Round  41, Global train loss: 1.025, Global test loss: 2.072, Global test accuracy: 31.91
Round  42, Train loss: 0.841, Test loss: 1.486, Test accuracy: 48.33
Round  42, Global train loss: 0.841, Global test loss: 2.072, Global test accuracy: 29.34
Round  43, Train loss: 0.704, Test loss: 1.483, Test accuracy: 48.83
Round  43, Global train loss: 0.704, Global test loss: 1.998, Global test accuracy: 29.94
Round  44, Train loss: 0.715, Test loss: 1.516, Test accuracy: 48.46
Round  44, Global train loss: 0.715, Global test loss: 1.940, Global test accuracy: 36.17
Round  45, Train loss: 0.684, Test loss: 1.542, Test accuracy: 48.16
Round  45, Global train loss: 0.684, Global test loss: 2.126, Global test accuracy: 25.45
Round  46, Train loss: 0.687, Test loss: 1.568, Test accuracy: 47.62
Round  46, Global train loss: 0.687, Global test loss: 2.106, Global test accuracy: 20.79
Round  47, Train loss: 0.796, Test loss: 1.572, Test accuracy: 47.98
Round  47, Global train loss: 0.796, Global test loss: 2.040, Global test accuracy: 29.10
Round  48, Train loss: 0.710, Test loss: 1.577, Test accuracy: 47.98
Round  48, Global train loss: 0.710, Global test loss: 2.051, Global test accuracy: 33.41
Round  49, Train loss: 0.431, Test loss: 1.609, Test accuracy: 47.88
Round  49, Global train loss: 0.431, Global test loss: 2.290, Global test accuracy: 23.71
Round  50, Train loss: 0.789, Test loss: 1.656, Test accuracy: 47.84
Round  50, Global train loss: 0.789, Global test loss: 2.038, Global test accuracy: 29.10
Round  51, Train loss: 0.587, Test loss: 1.709, Test accuracy: 47.56
Round  51, Global train loss: 0.587, Global test loss: 1.968, Global test accuracy: 32.15
Round  52, Train loss: 0.770, Test loss: 1.728, Test accuracy: 46.96
Round  52, Global train loss: 0.770, Global test loss: 1.970, Global test accuracy: 30.27
Round  53, Train loss: 0.623, Test loss: 1.728, Test accuracy: 47.22
Round  53, Global train loss: 0.623, Global test loss: 2.108, Global test accuracy: 23.73
Round  54, Train loss: 0.440, Test loss: 1.735, Test accuracy: 47.56
Round  54, Global train loss: 0.440, Global test loss: 2.005, Global test accuracy: 28.52
Round  55, Train loss: 0.767, Test loss: 1.790, Test accuracy: 47.32
Round  55, Global train loss: 0.767, Global test loss: 2.039, Global test accuracy: 27.75
Round  56, Train loss: 0.560, Test loss: 1.783, Test accuracy: 47.95
Round  56, Global train loss: 0.560, Global test loss: 1.909, Global test accuracy: 38.12
Round  57, Train loss: 0.459, Test loss: 1.834, Test accuracy: 47.51
Round  57, Global train loss: 0.459, Global test loss: 2.112, Global test accuracy: 24.75
Round  58, Train loss: 0.475, Test loss: 1.874, Test accuracy: 47.55
Round  58, Global train loss: 0.475, Global test loss: 1.935, Global test accuracy: 29.03
Round  59, Train loss: 0.328, Test loss: 1.857, Test accuracy: 47.83
Round  59, Global train loss: 0.328, Global test loss: 2.166, Global test accuracy: 23.47
Round  60, Train loss: 0.758, Test loss: 1.884, Test accuracy: 47.78
Round  60, Global train loss: 0.758, Global test loss: 2.177, Global test accuracy: 15.36
Round  61, Train loss: 0.403, Test loss: 1.884, Test accuracy: 47.86
Round  61, Global train loss: 0.403, Global test loss: 2.111, Global test accuracy: 20.05
Round  62, Train loss: 0.646, Test loss: 1.900, Test accuracy: 48.40
Round  62, Global train loss: 0.646, Global test loss: 2.115, Global test accuracy: 19.23
Round  63, Train loss: 0.552, Test loss: 1.921, Test accuracy: 48.02
Round  63, Global train loss: 0.552, Global test loss: 1.991, Global test accuracy: 28.51
Round  64, Train loss: 0.644, Test loss: 1.947, Test accuracy: 47.86
Round  64, Global train loss: 0.644, Global test loss: 2.169, Global test accuracy: 24.90
Round  65, Train loss: 0.614, Test loss: 1.966, Test accuracy: 47.93
Round  65, Global train loss: 0.614, Global test loss: 1.967, Global test accuracy: 33.04
Round  66, Train loss: 0.410, Test loss: 2.034, Test accuracy: 47.65
Round  66, Global train loss: 0.410, Global test loss: 2.065, Global test accuracy: 29.79
Round  67, Train loss: 0.528, Test loss: 2.036, Test accuracy: 47.51
Round  67, Global train loss: 0.528, Global test loss: 2.049, Global test accuracy: 28.26
Round  68, Train loss: 0.418, Test loss: 2.127, Test accuracy: 47.18
Round  68, Global train loss: 0.418, Global test loss: 1.905, Global test accuracy: 33.96
Round  69, Train loss: 0.503, Test loss: 2.118, Test accuracy: 47.21
Round  69, Global train loss: 0.503, Global test loss: 2.081, Global test accuracy: 26.32
Round  70, Train loss: 0.398, Test loss: 2.160, Test accuracy: 47.73
Round  70, Global train loss: 0.398, Global test loss: 1.972, Global test accuracy: 32.29
Round  71, Train loss: 0.379, Test loss: 2.152, Test accuracy: 48.06
Round  71, Global train loss: 0.379, Global test loss: 2.016, Global test accuracy: 28.10
Round  72, Train loss: 0.392, Test loss: 2.184, Test accuracy: 48.29
Round  72, Global train loss: 0.392, Global test loss: 2.060, Global test accuracy: 27.31
Round  73, Train loss: 0.445, Test loss: 2.190, Test accuracy: 48.23
Round  73, Global train loss: 0.445, Global test loss: 1.946, Global test accuracy: 30.61
Round  74, Train loss: 0.274, Test loss: 2.253, Test accuracy: 47.86
Round  74, Global train loss: 0.274, Global test loss: 1.955, Global test accuracy: 33.55
Round  75, Train loss: 0.208, Test loss: 2.267, Test accuracy: 47.92
Round  75, Global train loss: 0.208, Global test loss: 1.993, Global test accuracy: 24.77
Round  76, Train loss: 0.290, Test loss: 2.262, Test accuracy: 48.26
Round  76, Global train loss: 0.290, Global test loss: 1.920, Global test accuracy: 34.37
Round  77, Train loss: 0.278, Test loss: 2.285, Test accuracy: 48.55
Round  77, Global train loss: 0.278, Global test loss: 2.080, Global test accuracy: 26.29
Round  78, Train loss: 0.368, Test loss: 2.287, Test accuracy: 48.00
Round  78, Global train loss: 0.368, Global test loss: 2.073, Global test accuracy: 27.31
Round  79, Train loss: 0.241, Test loss: 2.312, Test accuracy: 47.29
Round  79, Global train loss: 0.241, Global test loss: 1.977, Global test accuracy: 32.17
Round  80, Train loss: 0.410, Test loss: 2.366, Test accuracy: 47.53
Round  80, Global train loss: 0.410, Global test loss: 1.992, Global test accuracy: 30.99
Round  81, Train loss: 0.339, Test loss: 2.376, Test accuracy: 47.59
Round  81, Global train loss: 0.339, Global test loss: 2.110, Global test accuracy: 23.66
Round  82, Train loss: 0.458, Test loss: 2.407, Test accuracy: 47.91
Round  82, Global train loss: 0.458, Global test loss: 2.076, Global test accuracy: 22.16
Round  83, Train loss: 0.285, Test loss: 2.416, Test accuracy: 48.36
Round  83, Global train loss: 0.285, Global test loss: 2.092, Global test accuracy: 26.60
Round  84, Train loss: 0.284, Test loss: 2.473, Test accuracy: 48.04
Round  84, Global train loss: 0.284, Global test loss: 2.136, Global test accuracy: 23.78
Round  85, Train loss: 0.282, Test loss: 2.529, Test accuracy: 47.70
Round  85, Global train loss: 0.282, Global test loss: 1.989, Global test accuracy: 30.16
Round  86, Train loss: 0.259, Test loss: 2.543, Test accuracy: 47.77
Round  86, Global train loss: 0.259, Global test loss: 1.970, Global test accuracy: 31.40
Round  87, Train loss: 0.268, Test loss: 2.640, Test accuracy: 47.54
Round  87, Global train loss: 0.268, Global test loss: 2.037, Global test accuracy: 23.72
Round  88, Train loss: 0.424, Test loss: 2.692, Test accuracy: 47.25
Round  88, Global train loss: 0.424, Global test loss: 2.193, Global test accuracy: 18.83
Round  89, Train loss: 0.265, Test loss: 2.692, Test accuracy: 47.56
Round  89, Global train loss: 0.265, Global test loss: 2.084, Global test accuracy: 26.14
Round  90, Train loss: 0.179, Test loss: 2.696, Test accuracy: 47.55
Round  90, Global train loss: 0.179, Global test loss: 2.042, Global test accuracy: 27.93
Round  91, Train loss: 0.184, Test loss: 2.721, Test accuracy: 47.45
Round  91, Global train loss: 0.184, Global test loss: 1.976, Global test accuracy: 29.45
Round  92, Train loss: 0.209, Test loss: 2.692, Test accuracy: 47.38
Round  92, Global train loss: 0.209, Global test loss: 2.133, Global test accuracy: 30.09
Round  93, Train loss: 0.273, Test loss: 2.681, Test accuracy: 48.23
Round  93, Global train loss: 0.273, Global test loss: 1.981, Global test accuracy: 32.77
Round  94, Train loss: 0.295, Test loss: 2.668, Test accuracy: 48.35
Round  94, Global train loss: 0.295, Global test loss: 2.159, Global test accuracy: 20.87
Round  95, Train loss: 0.290, Test loss: 2.717, Test accuracy: 48.50
Round  95, Global train loss: 0.290, Global test loss: 2.022, Global test accuracy: 26.03
Round  96, Train loss: 0.213, Test loss: 2.737, Test accuracy: 48.41
Round  96, Global train loss: 0.213, Global test loss: 2.107, Global test accuracy: 24.10
Round  97, Train loss: 0.321, Test loss: 2.785, Test accuracy: 47.91
Round  97, Global train loss: 0.321, Global test loss: 2.069, Global test accuracy: 24.48
Round  98, Train loss: 0.330, Test loss: 2.844, Test accuracy: 47.97
Round  98, Global train loss: 0.330, Global test loss: 2.023, Global test accuracy: 26.52
Round  99, Train loss: 0.290, Test loss: 2.883, Test accuracy: 47.88
Round  99, Global train loss: 0.290, Global test loss: 2.145, Global test accuracy: 20.79
Final Round, Train loss: 0.216, Test loss: 2.988, Test accuracy: 47.67
Final Round, Global train loss: 0.216, Global test loss: 2.145, Global test accuracy: 20.79
Average accuracy final 10 rounds: 47.962999999999994 

Average global accuracy final 10 rounds: 26.303000000000004 

1555.2250180244446
[1.4976344108581543, 2.9952688217163086, 4.203030109405518, 5.410791397094727, 6.6420488357543945, 7.8733062744140625, 9.149210691452026, 10.42511510848999, 11.633578062057495, 12.842041015625, 14.08034062385559, 15.318640232086182, 16.573605060577393, 17.828569889068604, 19.055784702301025, 20.282999515533447, 21.36035704612732, 22.43771457672119, 23.50826382637024, 24.578813076019287, 25.66725206375122, 26.755691051483154, 27.83224868774414, 28.908806324005127, 29.979262113571167, 31.049717903137207, 32.125598192214966, 33.201478481292725, 34.28746199607849, 35.37344551086426, 36.44867467880249, 37.52390384674072, 38.61361312866211, 39.703322410583496, 40.79473924636841, 41.88615608215332, 42.94840860366821, 44.010661125183105, 45.09942603111267, 46.188190937042236, 47.28894233703613, 48.38969373703003, 49.48894810676575, 50.588202476501465, 51.66842460632324, 52.74864673614502, 53.82914447784424, 54.90964221954346, 55.99757504463196, 57.08550786972046, 58.15348505973816, 59.22146224975586, 60.2969970703125, 61.37253189086914, 62.458585262298584, 63.54463863372803, 64.62196946144104, 65.69930028915405, 66.80840682983398, 67.91751337051392, 69.05365991592407, 70.18980646133423, 71.23399519920349, 72.27818393707275, 73.35408449172974, 74.42998504638672, 75.55091905593872, 76.67185306549072, 77.78512716293335, 78.89840126037598, 80.00433015823364, 81.11025905609131, 82.18144369125366, 83.25262832641602, 84.32973170280457, 85.40683507919312, 86.48908519744873, 87.57133531570435, 88.66954588890076, 89.76775646209717, 90.85280275344849, 91.9378490447998, 93.06110954284668, 94.18437004089355, 95.28100538253784, 96.37764072418213, 97.47863960266113, 98.57963848114014, 99.65765166282654, 100.73566484451294, 101.88525557518005, 103.03484630584717, 104.14027881622314, 105.24571132659912, 106.31531167030334, 107.38491201400757, 108.4518404006958, 109.51876878738403, 110.58334946632385, 111.64793014526367, 112.72306561470032, 113.79820108413696, 114.86460065841675, 115.93100023269653, 117.02405667304993, 118.11711311340332, 119.18868398666382, 120.26025485992432, 121.34454798698425, 122.42884111404419, 123.51455307006836, 124.60026502609253, 125.69941592216492, 126.7985668182373, 127.88578605651855, 128.9730052947998, 130.05208897590637, 131.13117265701294, 132.22556114196777, 133.3199496269226, 134.40130591392517, 135.48266220092773, 136.54422211647034, 137.60578203201294, 138.70685410499573, 139.80792617797852, 140.9336061477661, 142.0592861175537, 143.10792016983032, 144.15655422210693, 145.2181851863861, 146.27981615066528, 147.3626925945282, 148.4455690383911, 149.51282382011414, 150.58007860183716, 151.65221214294434, 152.7243456840515, 153.7799608707428, 154.83557605743408, 155.90401887893677, 156.97246170043945, 158.0314383506775, 159.09041500091553, 160.16307425498962, 161.23573350906372, 162.34004497528076, 163.4443564414978, 164.53122067451477, 165.61808490753174, 166.71150398254395, 167.80492305755615, 168.9020700454712, 169.99921703338623, 171.0570251941681, 172.11483335494995, 173.18409276008606, 174.25335216522217, 175.32896327972412, 176.40457439422607, 177.47116875648499, 178.5377631187439, 179.5990993976593, 180.6604356765747, 181.71659111976624, 182.77274656295776, 183.85204243659973, 184.9313383102417, 185.98554611206055, 187.0397539138794, 188.14305305480957, 189.24635219573975, 190.3412594795227, 191.43616676330566, 192.5069854259491, 193.57780408859253, 194.67494869232178, 195.77209329605103, 196.8464515209198, 197.92080974578857, 198.9821741580963, 200.04353857040405, 201.09439373016357, 202.1452488899231, 203.22526383399963, 204.30527877807617, 205.36692190170288, 206.4285650253296, 207.49830722808838, 208.56804943084717, 209.62479186058044, 210.68153429031372, 211.76995635032654, 212.85837841033936, 213.91424179077148, 214.9701051712036, 216.03409576416016, 217.0980863571167, 218.16850352287292, 219.23892068862915, 221.43516874313354, 223.63141679763794]
[21.5, 21.5, 24.61, 24.61, 34.74, 34.74, 37.64, 37.64, 39.21, 39.21, 39.46, 39.46, 40.63, 40.63, 41.18, 41.18, 42.56, 42.56, 42.77, 42.77, 45.25, 45.25, 45.35, 45.35, 45.86, 45.86, 47.39, 47.39, 48.23, 48.23, 47.77, 47.77, 47.95, 47.95, 48.03, 48.03, 47.27, 47.27, 47.57, 47.57, 47.98, 47.98, 48.02, 48.02, 47.9, 47.9, 47.77, 47.77, 47.54, 47.54, 47.8, 47.8, 47.98, 47.98, 48.93, 48.93, 49.02, 49.02, 48.6, 48.6, 48.83, 48.83, 49.14, 49.14, 48.7, 48.7, 48.6, 48.6, 48.87, 48.87, 49.37, 49.37, 49.34, 49.34, 49.15, 49.15, 49.18, 49.18, 48.62, 48.62, 47.75, 47.75, 48.02, 48.02, 48.33, 48.33, 48.83, 48.83, 48.46, 48.46, 48.16, 48.16, 47.62, 47.62, 47.98, 47.98, 47.98, 47.98, 47.88, 47.88, 47.84, 47.84, 47.56, 47.56, 46.96, 46.96, 47.22, 47.22, 47.56, 47.56, 47.32, 47.32, 47.95, 47.95, 47.51, 47.51, 47.55, 47.55, 47.83, 47.83, 47.78, 47.78, 47.86, 47.86, 48.4, 48.4, 48.02, 48.02, 47.86, 47.86, 47.93, 47.93, 47.65, 47.65, 47.51, 47.51, 47.18, 47.18, 47.21, 47.21, 47.73, 47.73, 48.06, 48.06, 48.29, 48.29, 48.23, 48.23, 47.86, 47.86, 47.92, 47.92, 48.26, 48.26, 48.55, 48.55, 48.0, 48.0, 47.29, 47.29, 47.53, 47.53, 47.59, 47.59, 47.91, 47.91, 48.36, 48.36, 48.04, 48.04, 47.7, 47.7, 47.77, 47.77, 47.54, 47.54, 47.25, 47.25, 47.56, 47.56, 47.55, 47.55, 47.45, 47.45, 47.38, 47.38, 48.23, 48.23, 48.35, 48.35, 48.5, 48.5, 48.41, 48.41, 47.91, 47.91, 47.97, 47.97, 47.88, 47.88, 47.67, 47.67]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 17, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 12, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 13, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.632, Test loss: 2.002, Test accuracy: 24.34
Round   0, Global train loss: 1.632, Global test loss: 2.214, Global test accuracy: 19.62
Round   1, Train loss: 1.451, Test loss: 1.984, Test accuracy: 29.12
Round   1, Global train loss: 1.451, Global test loss: 2.414, Global test accuracy: 21.08
Round   2, Train loss: 1.467, Test loss: 1.553, Test accuracy: 39.32
Round   2, Global train loss: 1.467, Global test loss: 2.002, Global test accuracy: 26.80
Round   3, Train loss: 1.291, Test loss: 1.385, Test accuracy: 45.50
Round   3, Global train loss: 1.291, Global test loss: 1.791, Global test accuracy: 33.68
Round   4, Train loss: 1.158, Test loss: 1.296, Test accuracy: 49.33
Round   4, Global train loss: 1.158, Global test loss: 1.774, Global test accuracy: 35.66
Round   5, Train loss: 1.182, Test loss: 1.240, Test accuracy: 52.17
Round   5, Global train loss: 1.182, Global test loss: 1.749, Global test accuracy: 38.16
Round   6, Train loss: 1.171, Test loss: 1.186, Test accuracy: 53.62
Round   6, Global train loss: 1.171, Global test loss: 1.792, Global test accuracy: 33.27
Round   7, Train loss: 1.114, Test loss: 1.151, Test accuracy: 54.89
Round   7, Global train loss: 1.114, Global test loss: 1.612, Global test accuracy: 39.79
Round   8, Train loss: 1.065, Test loss: 1.163, Test accuracy: 54.38
Round   8, Global train loss: 1.065, Global test loss: 1.717, Global test accuracy: 39.30
Round   9, Train loss: 1.069, Test loss: 1.145, Test accuracy: 56.56
Round   9, Global train loss: 1.069, Global test loss: 1.706, Global test accuracy: 41.77
Round  10, Train loss: 1.101, Test loss: 1.097, Test accuracy: 57.76
Round  10, Global train loss: 1.101, Global test loss: 1.571, Global test accuracy: 45.85
Round  11, Train loss: 0.994, Test loss: 1.084, Test accuracy: 58.74
Round  11, Global train loss: 0.994, Global test loss: 1.484, Global test accuracy: 49.61
Round  12, Train loss: 1.010, Test loss: 1.070, Test accuracy: 59.85
Round  12, Global train loss: 1.010, Global test loss: 1.734, Global test accuracy: 40.22
Round  13, Train loss: 0.960, Test loss: 1.017, Test accuracy: 61.76
Round  13, Global train loss: 0.960, Global test loss: 1.445, Global test accuracy: 48.39
Round  14, Train loss: 0.918, Test loss: 1.001, Test accuracy: 61.88
Round  14, Global train loss: 0.918, Global test loss: 1.482, Global test accuracy: 48.45
Round  15, Train loss: 0.981, Test loss: 1.008, Test accuracy: 62.09
Round  15, Global train loss: 0.981, Global test loss: 1.503, Global test accuracy: 47.65
Round  16, Train loss: 0.849, Test loss: 1.023, Test accuracy: 61.61
Round  16, Global train loss: 0.849, Global test loss: 1.347, Global test accuracy: 51.91
Round  17, Train loss: 0.925, Test loss: 1.002, Test accuracy: 62.44
Round  17, Global train loss: 0.925, Global test loss: 1.414, Global test accuracy: 51.43
Round  18, Train loss: 0.895, Test loss: 0.991, Test accuracy: 62.67
Round  18, Global train loss: 0.895, Global test loss: 1.482, Global test accuracy: 53.03
Round  19, Train loss: 0.875, Test loss: 0.963, Test accuracy: 64.45
Round  19, Global train loss: 0.875, Global test loss: 1.301, Global test accuracy: 55.40
Round  20, Train loss: 0.920, Test loss: 0.950, Test accuracy: 64.91
Round  20, Global train loss: 0.920, Global test loss: 1.304, Global test accuracy: 56.36
Round  21, Train loss: 0.890, Test loss: 0.931, Test accuracy: 65.58
Round  21, Global train loss: 0.890, Global test loss: 1.395, Global test accuracy: 51.59
Round  22, Train loss: 0.846, Test loss: 0.930, Test accuracy: 65.73
Round  22, Global train loss: 0.846, Global test loss: 1.372, Global test accuracy: 52.46
Round  23, Train loss: 0.884, Test loss: 0.941, Test accuracy: 65.58
Round  23, Global train loss: 0.884, Global test loss: 1.360, Global test accuracy: 55.45
Round  24, Train loss: 0.823, Test loss: 0.921, Test accuracy: 66.13
Round  24, Global train loss: 0.823, Global test loss: 1.353, Global test accuracy: 50.63
Round  25, Train loss: 0.776, Test loss: 0.927, Test accuracy: 66.23
Round  25, Global train loss: 0.776, Global test loss: 1.293, Global test accuracy: 55.43
Round  26, Train loss: 0.800, Test loss: 0.919, Test accuracy: 66.97
Round  26, Global train loss: 0.800, Global test loss: 1.203, Global test accuracy: 58.53
Round  27, Train loss: 0.799, Test loss: 0.920, Test accuracy: 67.13
Round  27, Global train loss: 0.799, Global test loss: 1.273, Global test accuracy: 56.21
Round  28, Train loss: 0.756, Test loss: 0.913, Test accuracy: 67.25
Round  28, Global train loss: 0.756, Global test loss: 1.296, Global test accuracy: 55.93
Round  29, Train loss: 0.745, Test loss: 0.905, Test accuracy: 67.48
Round  29, Global train loss: 0.745, Global test loss: 1.224, Global test accuracy: 57.43
Round  30, Train loss: 0.677, Test loss: 0.921, Test accuracy: 67.08
Round  30, Global train loss: 0.677, Global test loss: 1.237, Global test accuracy: 58.15
Round  31, Train loss: 0.681, Test loss: 0.921, Test accuracy: 66.96
Round  31, Global train loss: 0.681, Global test loss: 1.277, Global test accuracy: 57.50
Round  32, Train loss: 0.779, Test loss: 0.934, Test accuracy: 66.49
Round  32, Global train loss: 0.779, Global test loss: 1.247, Global test accuracy: 58.14
Round  33, Train loss: 0.687, Test loss: 0.931, Test accuracy: 67.15
Round  33, Global train loss: 0.687, Global test loss: 1.197, Global test accuracy: 60.28
Round  34, Train loss: 0.680, Test loss: 0.926, Test accuracy: 67.52
Round  34, Global train loss: 0.680, Global test loss: 1.206, Global test accuracy: 59.62
Round  35, Train loss: 0.721, Test loss: 0.925, Test accuracy: 67.58
Round  35, Global train loss: 0.721, Global test loss: 1.162, Global test accuracy: 60.04
Round  36, Train loss: 0.657, Test loss: 0.923, Test accuracy: 67.69
Round  36, Global train loss: 0.657, Global test loss: 1.175, Global test accuracy: 59.79
Round  37, Train loss: 0.622, Test loss: 0.932, Test accuracy: 67.52
Round  37, Global train loss: 0.622, Global test loss: 1.240, Global test accuracy: 59.60
Round  38, Train loss: 0.641, Test loss: 0.930, Test accuracy: 68.16
Round  38, Global train loss: 0.641, Global test loss: 1.250, Global test accuracy: 56.02
Round  39, Train loss: 0.599, Test loss: 0.929, Test accuracy: 68.31
Round  39, Global train loss: 0.599, Global test loss: 1.143, Global test accuracy: 62.03
Round  40, Train loss: 0.649, Test loss: 0.957, Test accuracy: 67.53
Round  40, Global train loss: 0.649, Global test loss: 1.306, Global test accuracy: 58.23
Round  41, Train loss: 0.637, Test loss: 0.954, Test accuracy: 67.66
Round  41, Global train loss: 0.637, Global test loss: 1.350, Global test accuracy: 57.33
Round  42, Train loss: 0.607, Test loss: 0.937, Test accuracy: 68.39
Round  42, Global train loss: 0.607, Global test loss: 1.293, Global test accuracy: 60.53
Round  43, Train loss: 0.595, Test loss: 0.918, Test accuracy: 69.34
Round  43, Global train loss: 0.595, Global test loss: 1.139, Global test accuracy: 61.45
Round  44, Train loss: 0.577, Test loss: 0.920, Test accuracy: 69.49
Round  44, Global train loss: 0.577, Global test loss: 1.266, Global test accuracy: 59.58
Round  45, Train loss: 0.645, Test loss: 0.923, Test accuracy: 69.71
Round  45, Global train loss: 0.645, Global test loss: 1.478, Global test accuracy: 53.84
Round  46, Train loss: 0.669, Test loss: 0.921, Test accuracy: 69.59
Round  46, Global train loss: 0.669, Global test loss: 1.185, Global test accuracy: 60.01
Round  47, Train loss: 0.591, Test loss: 0.922, Test accuracy: 69.64
Round  47, Global train loss: 0.591, Global test loss: 1.137, Global test accuracy: 61.30
Round  48, Train loss: 0.586, Test loss: 0.923, Test accuracy: 69.64
Round  48, Global train loss: 0.586, Global test loss: 1.199, Global test accuracy: 60.11
Round  49, Train loss: 0.578, Test loss: 0.918, Test accuracy: 69.84
Round  49, Global train loss: 0.578, Global test loss: 1.272, Global test accuracy: 58.37
Round  50, Train loss: 0.617, Test loss: 0.910, Test accuracy: 70.38
Round  50, Global train loss: 0.617, Global test loss: 1.230, Global test accuracy: 59.87
Round  51, Train loss: 0.530, Test loss: 0.928, Test accuracy: 69.97
Round  51, Global train loss: 0.530, Global test loss: 1.205, Global test accuracy: 62.65
Round  52, Train loss: 0.536, Test loss: 0.929, Test accuracy: 69.81
Round  52, Global train loss: 0.536, Global test loss: 1.196, Global test accuracy: 61.56
Round  53, Train loss: 0.551, Test loss: 0.929, Test accuracy: 70.02
Round  53, Global train loss: 0.551, Global test loss: 1.147, Global test accuracy: 61.01
Round  54, Train loss: 0.574, Test loss: 0.941, Test accuracy: 69.77
Round  54, Global train loss: 0.574, Global test loss: 1.196, Global test accuracy: 61.70
Round  55, Train loss: 0.502, Test loss: 0.938, Test accuracy: 69.88
Round  55, Global train loss: 0.502, Global test loss: 1.178, Global test accuracy: 61.74
Round  56, Train loss: 0.524, Test loss: 0.938, Test accuracy: 70.40
Round  56, Global train loss: 0.524, Global test loss: 1.167, Global test accuracy: 62.55
Round  57, Train loss: 0.555, Test loss: 0.923, Test accuracy: 70.59
Round  57, Global train loss: 0.555, Global test loss: 1.167, Global test accuracy: 61.87
Round  58, Train loss: 0.489, Test loss: 0.915, Test accuracy: 70.78
Round  58, Global train loss: 0.489, Global test loss: 1.157, Global test accuracy: 62.70
Round  59, Train loss: 0.491, Test loss: 0.945, Test accuracy: 70.27
Round  59, Global train loss: 0.491, Global test loss: 1.199, Global test accuracy: 61.72
Round  60, Train loss: 0.540, Test loss: 0.954, Test accuracy: 70.26
Round  60, Global train loss: 0.540, Global test loss: 1.195, Global test accuracy: 61.28
Round  61, Train loss: 0.536, Test loss: 0.960, Test accuracy: 69.96
Round  61, Global train loss: 0.536, Global test loss: 1.191, Global test accuracy: 61.27
Round  62, Train loss: 0.530, Test loss: 0.945, Test accuracy: 70.51
Round  62, Global train loss: 0.530, Global test loss: 1.148, Global test accuracy: 62.27
Round  63, Train loss: 0.496, Test loss: 0.929, Test accuracy: 71.04
Round  63, Global train loss: 0.496, Global test loss: 1.143, Global test accuracy: 62.03
Round  64, Train loss: 0.543, Test loss: 0.903, Test accuracy: 71.69
Round  64, Global train loss: 0.543, Global test loss: 1.357, Global test accuracy: 58.44
Round  65, Train loss: 0.499, Test loss: 0.905, Test accuracy: 71.57
Round  65, Global train loss: 0.499, Global test loss: 1.189, Global test accuracy: 61.55
Round  66, Train loss: 0.476, Test loss: 0.905, Test accuracy: 71.52
Round  66, Global train loss: 0.476, Global test loss: 1.260, Global test accuracy: 60.37
Round  67, Train loss: 0.510, Test loss: 0.906, Test accuracy: 71.83
Round  67, Global train loss: 0.510, Global test loss: 1.252, Global test accuracy: 61.40
Round  68, Train loss: 0.516, Test loss: 0.925, Test accuracy: 71.43
Round  68, Global train loss: 0.516, Global test loss: 1.168, Global test accuracy: 63.04
Round  69, Train loss: 0.497, Test loss: 0.933, Test accuracy: 71.31
Round  69, Global train loss: 0.497, Global test loss: 1.266, Global test accuracy: 61.99
Round  70, Train loss: 0.419, Test loss: 0.948, Test accuracy: 71.06
Round  70, Global train loss: 0.419, Global test loss: 1.187, Global test accuracy: 63.27
Round  71, Train loss: 0.463, Test loss: 0.966, Test accuracy: 70.65
Round  71, Global train loss: 0.463, Global test loss: 1.181, Global test accuracy: 61.75
Round  72, Train loss: 0.418, Test loss: 0.980, Test accuracy: 70.67
Round  72, Global train loss: 0.418, Global test loss: 1.257, Global test accuracy: 61.24
Round  73, Train loss: 0.418, Test loss: 0.964, Test accuracy: 71.21
Round  73, Global train loss: 0.418, Global test loss: 1.106, Global test accuracy: 64.20
Round  74, Train loss: 0.391, Test loss: 0.960, Test accuracy: 71.18
Round  74, Global train loss: 0.391, Global test loss: 1.395, Global test accuracy: 59.60
Round  75, Train loss: 0.426, Test loss: 0.956, Test accuracy: 70.97
Round  75, Global train loss: 0.426, Global test loss: 1.232, Global test accuracy: 62.75
Round  76, Train loss: 0.400, Test loss: 0.959, Test accuracy: 71.37
Round  76, Global train loss: 0.400, Global test loss: 1.287, Global test accuracy: 62.11
Round  77, Train loss: 0.425, Test loss: 0.950, Test accuracy: 71.81
Round  77, Global train loss: 0.425, Global test loss: 1.268, Global test accuracy: 60.20
Round  78, Train loss: 0.411, Test loss: 0.950, Test accuracy: 71.70
Round  78, Global train loss: 0.411, Global test loss: 1.283, Global test accuracy: 61.43
Round  79, Train loss: 0.471, Test loss: 0.964, Test accuracy: 71.59
Round  79, Global train loss: 0.471, Global test loss: 1.331, Global test accuracy: 59.59
Round  80, Train loss: 0.424, Test loss: 0.992, Test accuracy: 70.86
Round  80, Global train loss: 0.424, Global test loss: 1.216, Global test accuracy: 63.02
Round  81, Train loss: 0.401, Test loss: 0.972, Test accuracy: 70.82
Round  81, Global train loss: 0.401, Global test loss: 1.272, Global test accuracy: 60.97
Round  82, Train loss: 0.466, Test loss: 0.983, Test accuracy: 70.76
Round  82, Global train loss: 0.466, Global test loss: 1.126, Global test accuracy: 63.18
Round  83, Train loss: 0.414, Test loss: 0.972, Test accuracy: 71.11
Round  83, Global train loss: 0.414, Global test loss: 1.308, Global test accuracy: 59.43
Round  84, Train loss: 0.392, Test loss: 0.977, Test accuracy: 71.21
Round  84, Global train loss: 0.392, Global test loss: 1.223, Global test accuracy: 63.01
Round  85, Train loss: 0.398, Test loss: 0.979, Test accuracy: 71.47
Round  85, Global train loss: 0.398, Global test loss: 1.273, Global test accuracy: 62.71
Round  86, Train loss: 0.423, Test loss: 0.956, Test accuracy: 71.56
Round  86, Global train loss: 0.423, Global test loss: 1.160, Global test accuracy: 64.22
Round  87, Train loss: 0.414, Test loss: 0.973, Test accuracy: 71.66
Round  87, Global train loss: 0.414, Global test loss: 1.146, Global test accuracy: 63.96
Round  88, Train loss: 0.464, Test loss: 0.981, Test accuracy: 71.84
Round  88, Global train loss: 0.464, Global test loss: 1.382, Global test accuracy: 60.39
Round  89, Train loss: 0.379, Test loss: 0.984, Test accuracy: 71.91
Round  89, Global train loss: 0.379, Global test loss: 1.339, Global test accuracy: 61.71
Round  90, Train loss: 0.354, Test loss: 1.027, Test accuracy: 70.99
Round  90, Global train loss: 0.354, Global test loss: 1.293, Global test accuracy: 61.11
Round  91, Train loss: 0.363, Test loss: 1.013, Test accuracy: 71.27
Round  91, Global train loss: 0.363, Global test loss: 1.204, Global test accuracy: 63.22
Round  92, Train loss: 0.381, Test loss: 1.010, Test accuracy: 71.65
Round  92, Global train loss: 0.381, Global test loss: 1.369, Global test accuracy: 60.42
Round  93, Train loss: 0.396, Test loss: 1.011, Test accuracy: 71.67
Round  93, Global train loss: 0.396, Global test loss: 1.254, Global test accuracy: 62.85
Round  94, Train loss: 0.399, Test loss: 0.988, Test accuracy: 72.01
Round  94, Global train loss: 0.399, Global test loss: 1.177, Global test accuracy: 64.43
Round  95, Train loss: 0.386, Test loss: 0.978, Test accuracy: 72.27
Round  95, Global train loss: 0.386, Global test loss: 1.226, Global test accuracy: 64.29
Round  96, Train loss: 0.341, Test loss: 0.977, Test accuracy: 72.16
Round  96, Global train loss: 0.341, Global test loss: 1.232, Global test accuracy: 63.41
Round  97, Train loss: 0.360, Test loss: 1.006, Test accuracy: 71.58
Round  97, Global train loss: 0.360, Global test loss: 1.272, Global test accuracy: 63.68
Round  98, Train loss: 0.388, Test loss: 1.004, Test accuracy: 72.04
Round  98, Global train loss: 0.388, Global test loss: 1.146, Global test accuracy: 65.38
Round  99, Train loss: 0.350, Test loss: 1.005, Test accuracy: 71.93
Round  99, Global train loss: 0.350, Global test loss: 1.217, Global test accuracy: 63.15
Final Round, Train loss: 0.288, Test loss: 1.091, Test accuracy: 72.20
Final Round, Global train loss: 0.288, Global test loss: 1.217, Global test accuracy: 63.15
Average accuracy final 10 rounds: 71.75699999999999 

Average global accuracy final 10 rounds: 63.194 

1481.347375869751
[1.4770236015319824, 2.954047203063965, 4.193549156188965, 5.433051109313965, 6.6955952644348145, 7.958139419555664, 9.205246448516846, 10.452353477478027, 11.688987016677856, 12.925620555877686, 14.176642656326294, 15.427664756774902, 16.64103102684021, 17.854397296905518, 18.923292636871338, 19.992187976837158, 21.035407543182373, 22.078627109527588, 23.13672971725464, 24.19483232498169, 25.256147146224976, 26.31746196746826, 27.387430906295776, 28.45739984512329, 29.51548719406128, 30.573574542999268, 31.61032724380493, 32.647079944610596, 33.702680826187134, 34.75828170776367, 35.819865703582764, 36.881449699401855, 37.95169425010681, 39.02193880081177, 40.07980275154114, 41.13766670227051, 42.175034284591675, 43.21240186691284, 44.27406167984009, 45.335721492767334, 46.37910223007202, 47.42248296737671, 48.48244094848633, 49.54239892959595, 50.59006953239441, 51.63774013519287, 52.6903920173645, 53.74304389953613, 54.78498411178589, 55.826924324035645, 56.875521421432495, 57.924118518829346, 58.98240923881531, 60.04069995880127, 61.08860421180725, 62.13650846481323, 63.19852066040039, 64.26053285598755, 65.30843734741211, 66.35634183883667, 67.3997654914856, 68.44318914413452, 69.50091171264648, 70.55863428115845, 71.6331033706665, 72.70757246017456, 73.77245736122131, 74.83734226226807, 75.88114523887634, 76.92494821548462, 77.96292662620544, 79.00090503692627, 80.06071591377258, 81.1205267906189, 82.21439599990845, 83.308265209198, 84.35285425186157, 85.39744329452515, 86.44177436828613, 87.48610544204712, 88.53558206558228, 89.58505868911743, 90.61297011375427, 91.64088153839111, 92.66984510421753, 93.69880867004395, 94.73062372207642, 95.76243877410889, 96.80153179168701, 97.84062480926514, 98.89158964157104, 99.94255447387695, 100.9841856956482, 102.02581691741943, 103.06595373153687, 104.1060905456543, 105.13160419464111, 106.15711784362793, 107.18502998352051, 108.21294212341309, 109.24914216995239, 110.2853422164917, 111.3215103149414, 112.35767841339111, 113.39438056945801, 114.4310827255249, 115.47792363166809, 116.52476453781128, 117.56638073921204, 118.6079969406128, 119.63855600357056, 120.66911506652832, 121.6977150440216, 122.72631502151489, 123.75879287719727, 124.79127073287964, 125.82115507125854, 126.85103940963745, 127.8760552406311, 128.90107107162476, 129.93548727035522, 130.9699034690857, 132.00666284561157, 133.04342222213745, 134.0779914855957, 135.11256074905396, 136.13972783088684, 137.16689491271973, 138.19305324554443, 139.21921157836914, 140.2559940814972, 141.29277658462524, 142.31999945640564, 143.34722232818604, 144.3786633014679, 145.41010427474976, 146.43748450279236, 147.46486473083496, 148.4979166984558, 149.53096866607666, 150.5642158985138, 151.59746313095093, 152.63100814819336, 153.6645531654358, 154.6900119781494, 155.71547079086304, 156.74783325195312, 157.7801957130432, 158.82012486457825, 159.86005401611328, 160.89257740974426, 161.92510080337524, 162.95119285583496, 163.97728490829468, 165.00640654563904, 166.0355281829834, 167.07110047340393, 168.10667276382446, 169.1446235179901, 170.18257427215576, 171.20854091644287, 172.23450756072998, 173.26411271095276, 174.29371786117554, 175.32535886764526, 176.356999874115, 177.39604353904724, 178.4350872039795, 179.4669783115387, 180.4988694190979, 181.53084516525269, 182.56282091140747, 183.60233211517334, 184.6418433189392, 185.67618703842163, 186.71053075790405, 187.74290680885315, 188.77528285980225, 189.8025255203247, 190.82976818084717, 191.86120128631592, 192.89263439178467, 193.93059587478638, 194.9685573577881, 196.00151801109314, 197.0344786643982, 198.06327366828918, 199.09206867218018, 200.12780475616455, 201.16354084014893, 202.19907808303833, 203.23461532592773, 204.26777601242065, 205.30093669891357, 206.33325815200806, 207.36557960510254, 208.3994116783142, 209.43324375152588, 210.47742199897766, 211.52160024642944, 213.6022493839264, 215.68289852142334]
[24.34, 24.34, 29.12, 29.12, 39.32, 39.32, 45.5, 45.5, 49.33, 49.33, 52.17, 52.17, 53.62, 53.62, 54.89, 54.89, 54.38, 54.38, 56.56, 56.56, 57.76, 57.76, 58.74, 58.74, 59.85, 59.85, 61.76, 61.76, 61.88, 61.88, 62.09, 62.09, 61.61, 61.61, 62.44, 62.44, 62.67, 62.67, 64.45, 64.45, 64.91, 64.91, 65.58, 65.58, 65.73, 65.73, 65.58, 65.58, 66.13, 66.13, 66.23, 66.23, 66.97, 66.97, 67.13, 67.13, 67.25, 67.25, 67.48, 67.48, 67.08, 67.08, 66.96, 66.96, 66.49, 66.49, 67.15, 67.15, 67.52, 67.52, 67.58, 67.58, 67.69, 67.69, 67.52, 67.52, 68.16, 68.16, 68.31, 68.31, 67.53, 67.53, 67.66, 67.66, 68.39, 68.39, 69.34, 69.34, 69.49, 69.49, 69.71, 69.71, 69.59, 69.59, 69.64, 69.64, 69.64, 69.64, 69.84, 69.84, 70.38, 70.38, 69.97, 69.97, 69.81, 69.81, 70.02, 70.02, 69.77, 69.77, 69.88, 69.88, 70.4, 70.4, 70.59, 70.59, 70.78, 70.78, 70.27, 70.27, 70.26, 70.26, 69.96, 69.96, 70.51, 70.51, 71.04, 71.04, 71.69, 71.69, 71.57, 71.57, 71.52, 71.52, 71.83, 71.83, 71.43, 71.43, 71.31, 71.31, 71.06, 71.06, 70.65, 70.65, 70.67, 70.67, 71.21, 71.21, 71.18, 71.18, 70.97, 70.97, 71.37, 71.37, 71.81, 71.81, 71.7, 71.7, 71.59, 71.59, 70.86, 70.86, 70.82, 70.82, 70.76, 70.76, 71.11, 71.11, 71.21, 71.21, 71.47, 71.47, 71.56, 71.56, 71.66, 71.66, 71.84, 71.84, 71.91, 71.91, 70.99, 70.99, 71.27, 71.27, 71.65, 71.65, 71.67, 71.67, 72.01, 72.01, 72.27, 72.27, 72.16, 72.16, 71.58, 71.58, 72.04, 72.04, 71.93, 71.93, 72.2, 72.2]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 13, noise    level: 0.8000 
   Client 16, noise    level: 0.8000 
   Client 17, noise    level: 0.8000 
   Client 11, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 19, noise    level: 0.8000 
   Client 10, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.705, Test loss: 2.032, Test accuracy: 22.03
Round   0, Global train loss: 1.705, Global test loss: 2.237, Global test accuracy: 17.47
Round   1, Train loss: 1.511, Test loss: 1.961, Test accuracy: 26.58
Round   1, Global train loss: 1.511, Global test loss: 2.330, Global test accuracy: 18.69
Round   2, Train loss: 1.452, Test loss: 1.599, Test accuracy: 38.20
Round   2, Global train loss: 1.452, Global test loss: 1.984, Global test accuracy: 29.81
Round   3, Train loss: 1.391, Test loss: 1.461, Test accuracy: 43.25
Round   3, Global train loss: 1.391, Global test loss: 1.823, Global test accuracy: 36.27
Round   4, Train loss: 1.316, Test loss: 1.404, Test accuracy: 43.85
Round   4, Global train loss: 1.316, Global test loss: 1.829, Global test accuracy: 35.20
Round   5, Train loss: 1.206, Test loss: 1.355, Test accuracy: 47.07
Round   5, Global train loss: 1.206, Global test loss: 1.844, Global test accuracy: 35.93
Round   6, Train loss: 1.286, Test loss: 1.292, Test accuracy: 48.71
Round   6, Global train loss: 1.286, Global test loss: 1.884, Global test accuracy: 30.96
Round   7, Train loss: 1.168, Test loss: 1.239, Test accuracy: 50.27
Round   7, Global train loss: 1.168, Global test loss: 1.593, Global test accuracy: 41.79
Round   8, Train loss: 1.142, Test loss: 1.242, Test accuracy: 50.86
Round   8, Global train loss: 1.142, Global test loss: 1.712, Global test accuracy: 38.17
Round   9, Train loss: 1.175, Test loss: 1.211, Test accuracy: 53.30
Round   9, Global train loss: 1.175, Global test loss: 1.759, Global test accuracy: 36.25
Round  10, Train loss: 1.185, Test loss: 1.155, Test accuracy: 55.34
Round  10, Global train loss: 1.185, Global test loss: 1.607, Global test accuracy: 42.41
Round  11, Train loss: 1.052, Test loss: 1.131, Test accuracy: 56.63
Round  11, Global train loss: 1.052, Global test loss: 1.521, Global test accuracy: 47.85
Round  12, Train loss: 1.063, Test loss: 1.133, Test accuracy: 56.73
Round  12, Global train loss: 1.063, Global test loss: 1.747, Global test accuracy: 40.57
Round  13, Train loss: 1.059, Test loss: 1.075, Test accuracy: 58.65
Round  13, Global train loss: 1.059, Global test loss: 1.484, Global test accuracy: 46.35
Round  14, Train loss: 1.110, Test loss: 1.076, Test accuracy: 58.37
Round  14, Global train loss: 1.110, Global test loss: 1.634, Global test accuracy: 43.83
Round  15, Train loss: 1.182, Test loss: 1.061, Test accuracy: 58.98
Round  15, Global train loss: 1.182, Global test loss: 1.525, Global test accuracy: 46.08
Round  16, Train loss: 1.002, Test loss: 1.059, Test accuracy: 59.59
Round  16, Global train loss: 1.002, Global test loss: 1.456, Global test accuracy: 47.53
Round  17, Train loss: 1.022, Test loss: 1.034, Test accuracy: 60.13
Round  17, Global train loss: 1.022, Global test loss: 1.454, Global test accuracy: 49.54
Round  18, Train loss: 0.950, Test loss: 1.040, Test accuracy: 60.41
Round  18, Global train loss: 0.950, Global test loss: 1.504, Global test accuracy: 50.73
Round  19, Train loss: 0.966, Test loss: 1.026, Test accuracy: 60.93
Round  19, Global train loss: 0.966, Global test loss: 1.367, Global test accuracy: 52.70
Round  20, Train loss: 0.869, Test loss: 1.010, Test accuracy: 61.63
Round  20, Global train loss: 0.869, Global test loss: 1.337, Global test accuracy: 54.74
Round  21, Train loss: 0.988, Test loss: 0.989, Test accuracy: 62.59
Round  21, Global train loss: 0.988, Global test loss: 1.383, Global test accuracy: 51.39
Round  22, Train loss: 0.946, Test loss: 0.962, Test accuracy: 63.77
Round  22, Global train loss: 0.946, Global test loss: 1.379, Global test accuracy: 50.98
Round  23, Train loss: 0.840, Test loss: 0.961, Test accuracy: 63.73
Round  23, Global train loss: 0.840, Global test loss: 1.299, Global test accuracy: 55.96
Round  24, Train loss: 0.883, Test loss: 0.938, Test accuracy: 65.08
Round  24, Global train loss: 0.883, Global test loss: 1.282, Global test accuracy: 54.01
Round  25, Train loss: 0.987, Test loss: 0.949, Test accuracy: 64.94
Round  25, Global train loss: 0.987, Global test loss: 1.306, Global test accuracy: 54.14
Round  26, Train loss: 0.914, Test loss: 0.933, Test accuracy: 65.69
Round  26, Global train loss: 0.914, Global test loss: 1.234, Global test accuracy: 56.64
Round  27, Train loss: 0.961, Test loss: 0.931, Test accuracy: 65.65
Round  27, Global train loss: 0.961, Global test loss: 1.319, Global test accuracy: 53.86
Round  28, Train loss: 0.958, Test loss: 0.914, Test accuracy: 66.55
Round  28, Global train loss: 0.958, Global test loss: 1.303, Global test accuracy: 55.57
Round  29, Train loss: 0.832, Test loss: 0.913, Test accuracy: 66.65
Round  29, Global train loss: 0.832, Global test loss: 1.248, Global test accuracy: 55.73
Round  30, Train loss: 0.748, Test loss: 0.907, Test accuracy: 66.78
Round  30, Global train loss: 0.748, Global test loss: 1.236, Global test accuracy: 57.27
Round  31, Train loss: 0.746, Test loss: 0.923, Test accuracy: 66.10
Round  31, Global train loss: 0.746, Global test loss: 1.239, Global test accuracy: 56.23
Round  32, Train loss: 0.731, Test loss: 0.929, Test accuracy: 66.08
Round  32, Global train loss: 0.731, Global test loss: 1.146, Global test accuracy: 60.50
Round  33, Train loss: 0.726, Test loss: 0.921, Test accuracy: 66.79
Round  33, Global train loss: 0.726, Global test loss: 1.261, Global test accuracy: 56.57
Round  34, Train loss: 0.726, Test loss: 0.917, Test accuracy: 67.06
Round  34, Global train loss: 0.726, Global test loss: 1.198, Global test accuracy: 59.42
Round  35, Train loss: 0.810, Test loss: 0.926, Test accuracy: 67.39
Round  35, Global train loss: 0.810, Global test loss: 1.268, Global test accuracy: 55.54
Round  36, Train loss: 0.779, Test loss: 0.890, Test accuracy: 68.10
Round  36, Global train loss: 0.779, Global test loss: 1.226, Global test accuracy: 57.10
Round  37, Train loss: 0.835, Test loss: 0.886, Test accuracy: 68.48
Round  37, Global train loss: 0.835, Global test loss: 1.203, Global test accuracy: 58.58
Round  38, Train loss: 0.800, Test loss: 0.894, Test accuracy: 68.55
Round  38, Global train loss: 0.800, Global test loss: 1.196, Global test accuracy: 59.08
Round  39, Train loss: 0.690, Test loss: 0.900, Test accuracy: 68.27
Round  39, Global train loss: 0.690, Global test loss: 1.099, Global test accuracy: 61.77
Round  40, Train loss: 0.734, Test loss: 0.889, Test accuracy: 68.54
Round  40, Global train loss: 0.734, Global test loss: 1.149, Global test accuracy: 60.94
Round  41, Train loss: 0.674, Test loss: 0.884, Test accuracy: 68.86
Round  41, Global train loss: 0.674, Global test loss: 1.344, Global test accuracy: 56.63
Round  42, Train loss: 0.685, Test loss: 0.879, Test accuracy: 68.96
Round  42, Global train loss: 0.685, Global test loss: 1.247, Global test accuracy: 60.46
Round  43, Train loss: 0.856, Test loss: 0.873, Test accuracy: 69.09
Round  43, Global train loss: 0.856, Global test loss: 1.169, Global test accuracy: 60.50
Round  44, Train loss: 0.731, Test loss: 0.870, Test accuracy: 69.51
Round  44, Global train loss: 0.731, Global test loss: 1.192, Global test accuracy: 59.80
Round  45, Train loss: 0.762, Test loss: 0.859, Test accuracy: 69.47
Round  45, Global train loss: 0.762, Global test loss: 1.306, Global test accuracy: 55.26
Round  46, Train loss: 0.768, Test loss: 0.857, Test accuracy: 69.78
Round  46, Global train loss: 0.768, Global test loss: 1.166, Global test accuracy: 59.63
Round  47, Train loss: 0.671, Test loss: 0.851, Test accuracy: 69.91
Round  47, Global train loss: 0.671, Global test loss: 1.160, Global test accuracy: 60.77
Round  48, Train loss: 0.651, Test loss: 0.850, Test accuracy: 69.87
Round  48, Global train loss: 0.651, Global test loss: 1.184, Global test accuracy: 60.04
Round  49, Train loss: 0.587, Test loss: 0.855, Test accuracy: 69.82
Round  49, Global train loss: 0.587, Global test loss: 1.240, Global test accuracy: 58.76
Round  50, Train loss: 0.652, Test loss: 0.864, Test accuracy: 69.89
Round  50, Global train loss: 0.652, Global test loss: 1.204, Global test accuracy: 60.00
Round  51, Train loss: 0.557, Test loss: 0.872, Test accuracy: 70.04
Round  51, Global train loss: 0.557, Global test loss: 1.168, Global test accuracy: 62.41
Round  52, Train loss: 0.589, Test loss: 0.885, Test accuracy: 69.85
Round  52, Global train loss: 0.589, Global test loss: 1.176, Global test accuracy: 61.04
Round  53, Train loss: 0.638, Test loss: 0.885, Test accuracy: 70.11
Round  53, Global train loss: 0.638, Global test loss: 1.159, Global test accuracy: 60.81
Round  54, Train loss: 0.637, Test loss: 0.898, Test accuracy: 69.69
Round  54, Global train loss: 0.637, Global test loss: 1.212, Global test accuracy: 61.31
Round  55, Train loss: 0.673, Test loss: 0.880, Test accuracy: 70.14
Round  55, Global train loss: 0.673, Global test loss: 1.102, Global test accuracy: 62.46
Round  56, Train loss: 0.634, Test loss: 0.874, Test accuracy: 70.39
Round  56, Global train loss: 0.634, Global test loss: 1.121, Global test accuracy: 62.55
Round  57, Train loss: 0.705, Test loss: 0.885, Test accuracy: 70.14
Round  57, Global train loss: 0.705, Global test loss: 1.220, Global test accuracy: 59.96
Round  58, Train loss: 0.582, Test loss: 0.872, Test accuracy: 71.31
Round  58, Global train loss: 0.582, Global test loss: 1.152, Global test accuracy: 62.58
Round  59, Train loss: 0.525, Test loss: 0.868, Test accuracy: 71.32
Round  59, Global train loss: 0.525, Global test loss: 1.223, Global test accuracy: 61.08
Round  60, Train loss: 0.763, Test loss: 0.850, Test accuracy: 71.39
Round  60, Global train loss: 0.763, Global test loss: 1.205, Global test accuracy: 60.31
Round  61, Train loss: 0.624, Test loss: 0.857, Test accuracy: 71.73
Round  61, Global train loss: 0.624, Global test loss: 1.098, Global test accuracy: 63.53
Round  62, Train loss: 0.653, Test loss: 0.890, Test accuracy: 70.59
Round  62, Global train loss: 0.653, Global test loss: 1.124, Global test accuracy: 62.20
Round  63, Train loss: 0.540, Test loss: 0.873, Test accuracy: 71.22
Round  63, Global train loss: 0.540, Global test loss: 1.096, Global test accuracy: 63.95
Round  64, Train loss: 0.712, Test loss: 0.891, Test accuracy: 70.55
Round  64, Global train loss: 0.712, Global test loss: 1.238, Global test accuracy: 59.96
Round  65, Train loss: 0.562, Test loss: 0.875, Test accuracy: 71.13
Round  65, Global train loss: 0.562, Global test loss: 1.132, Global test accuracy: 62.57
Round  66, Train loss: 0.581, Test loss: 0.881, Test accuracy: 71.12
Round  66, Global train loss: 0.581, Global test loss: 1.178, Global test accuracy: 61.97
Round  67, Train loss: 0.570, Test loss: 0.878, Test accuracy: 70.94
Round  67, Global train loss: 0.570, Global test loss: 1.217, Global test accuracy: 61.26
Round  68, Train loss: 0.585, Test loss: 0.889, Test accuracy: 70.97
Round  68, Global train loss: 0.585, Global test loss: 1.089, Global test accuracy: 64.18
Round  69, Train loss: 0.613, Test loss: 0.872, Test accuracy: 71.50
Round  69, Global train loss: 0.613, Global test loss: 1.179, Global test accuracy: 62.91
Round  70, Train loss: 0.624, Test loss: 0.867, Test accuracy: 71.78
Round  70, Global train loss: 0.624, Global test loss: 1.144, Global test accuracy: 64.20
Round  71, Train loss: 0.524, Test loss: 0.876, Test accuracy: 71.65
Round  71, Global train loss: 0.524, Global test loss: 1.137, Global test accuracy: 62.68
Round  72, Train loss: 0.571, Test loss: 0.872, Test accuracy: 71.70
Round  72, Global train loss: 0.571, Global test loss: 1.121, Global test accuracy: 63.74
Round  73, Train loss: 0.513, Test loss: 0.910, Test accuracy: 70.73
Round  73, Global train loss: 0.513, Global test loss: 1.086, Global test accuracy: 64.05
Round  74, Train loss: 0.486, Test loss: 0.920, Test accuracy: 70.59
Round  74, Global train loss: 0.486, Global test loss: 1.219, Global test accuracy: 62.98
Round  75, Train loss: 0.547, Test loss: 0.928, Test accuracy: 70.92
Round  75, Global train loss: 0.547, Global test loss: 1.194, Global test accuracy: 62.30
Round  76, Train loss: 0.433, Test loss: 0.930, Test accuracy: 70.73
Round  76, Global train loss: 0.433, Global test loss: 1.159, Global test accuracy: 65.49
Round  77, Train loss: 0.478, Test loss: 0.895, Test accuracy: 71.17
Round  77, Global train loss: 0.478, Global test loss: 1.128, Global test accuracy: 63.66
Round  78, Train loss: 0.418, Test loss: 0.872, Test accuracy: 71.98
Round  78, Global train loss: 0.418, Global test loss: 1.159, Global test accuracy: 64.37
Round  79, Train loss: 0.500, Test loss: 0.896, Test accuracy: 71.63
Round  79, Global train loss: 0.500, Global test loss: 1.223, Global test accuracy: 62.46
Round  80, Train loss: 0.456, Test loss: 0.892, Test accuracy: 71.64
Round  80, Global train loss: 0.456, Global test loss: 1.121, Global test accuracy: 65.18
Round  81, Train loss: 0.527, Test loss: 0.899, Test accuracy: 71.64
Round  81, Global train loss: 0.527, Global test loss: 1.181, Global test accuracy: 64.29
Round  82, Train loss: 0.567, Test loss: 0.890, Test accuracy: 71.92
Round  82, Global train loss: 0.567, Global test loss: 1.062, Global test accuracy: 64.88
Round  83, Train loss: 0.465, Test loss: 0.882, Test accuracy: 72.35
Round  83, Global train loss: 0.465, Global test loss: 1.222, Global test accuracy: 61.22
Round  84, Train loss: 0.421, Test loss: 0.890, Test accuracy: 71.97
Round  84, Global train loss: 0.421, Global test loss: 1.161, Global test accuracy: 64.92
Round  85, Train loss: 0.430, Test loss: 0.909, Test accuracy: 71.13
Round  85, Global train loss: 0.430, Global test loss: 1.176, Global test accuracy: 64.16
Round  86, Train loss: 0.452, Test loss: 0.912, Test accuracy: 71.27
Round  86, Global train loss: 0.452, Global test loss: 1.077, Global test accuracy: 66.10
Round  87, Train loss: 0.435, Test loss: 0.926, Test accuracy: 71.27
Round  87, Global train loss: 0.435, Global test loss: 1.079, Global test accuracy: 65.94
Round  88, Train loss: 0.672, Test loss: 0.949, Test accuracy: 71.19
Round  88, Global train loss: 0.672, Global test loss: 1.224, Global test accuracy: 60.57
Round  89, Train loss: 0.471, Test loss: 0.938, Test accuracy: 71.53
Round  89, Global train loss: 0.471, Global test loss: 1.269, Global test accuracy: 61.29
Round  90, Train loss: 0.438, Test loss: 0.942, Test accuracy: 71.52
Round  90, Global train loss: 0.438, Global test loss: 1.282, Global test accuracy: 61.13
Round  91, Train loss: 0.457, Test loss: 0.937, Test accuracy: 71.71
Round  91, Global train loss: 0.457, Global test loss: 1.098, Global test accuracy: 65.00
Round  92, Train loss: 0.446, Test loss: 0.944, Test accuracy: 71.81
Round  92, Global train loss: 0.446, Global test loss: 1.319, Global test accuracy: 61.03
Round  93, Train loss: 0.535, Test loss: 0.961, Test accuracy: 71.85
Round  93, Global train loss: 0.535, Global test loss: 1.241, Global test accuracy: 62.77/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  94, Train loss: 0.541, Test loss: 0.957, Test accuracy: 71.98
Round  94, Global train loss: 0.541, Global test loss: 1.213, Global test accuracy: 63.73
Round  95, Train loss: 0.400, Test loss: 0.947, Test accuracy: 71.72
Round  95, Global train loss: 0.400, Global test loss: 1.182, Global test accuracy: 64.32
Round  96, Train loss: 0.432, Test loss: 0.930, Test accuracy: 72.46
Round  96, Global train loss: 0.432, Global test loss: 1.159, Global test accuracy: 63.77
Round  97, Train loss: 0.450, Test loss: 0.953, Test accuracy: 71.63
Round  97, Global train loss: 0.450, Global test loss: 1.253, Global test accuracy: 64.99
Round  98, Train loss: 0.551, Test loss: 0.968, Test accuracy: 71.27
Round  98, Global train loss: 0.551, Global test loss: 1.136, Global test accuracy: 65.18
Round  99, Train loss: 0.486, Test loss: 0.951, Test accuracy: 72.02
Round  99, Global train loss: 0.486, Global test loss: 1.197, Global test accuracy: 63.46
Final Round, Train loss: 0.368, Test loss: 1.018, Test accuracy: 71.82
Final Round, Global train loss: 0.368, Global test loss: 1.197, Global test accuracy: 63.46
Average accuracy final 10 rounds: 71.797 

Average global accuracy final 10 rounds: 63.53800000000001 

1508.78214097023
[1.5465190410614014, 3.0930380821228027, 4.20906138420105, 5.325084686279297, 6.439805269241333, 7.554525852203369, 8.674302816390991, 9.794079780578613, 10.920702695846558, 12.047325611114502, 13.158109426498413, 14.268893241882324, 15.37699556350708, 16.485097885131836, 17.63483214378357, 18.784566402435303, 19.899707794189453, 21.014849185943604, 22.124627351760864, 23.234405517578125, 24.339599132537842, 25.44479274749756, 26.556885480880737, 27.668978214263916, 28.78751254081726, 29.906046867370605, 31.033311367034912, 32.16057586669922, 33.276548862457275, 34.39252185821533, 35.50390553474426, 36.61528921127319, 37.72412633895874, 38.83296346664429, 39.95024299621582, 41.06752252578735, 42.177226066589355, 43.28692960739136, 44.40045213699341, 45.51397466659546, 46.620869636535645, 47.72776460647583, 48.870774030685425, 50.01378345489502, 51.138028383255005, 52.26227331161499, 53.36831855773926, 54.474363803863525, 55.57391333580017, 56.673462867736816, 57.775466203689575, 58.877469539642334, 59.992371559143066, 61.1072735786438, 62.23801612854004, 63.36875867843628, 64.48692107200623, 65.60508346557617, 66.71159410476685, 67.81810474395752, 68.94017601013184, 70.06224727630615, 71.1845395565033, 72.30683183670044, 73.42718577384949, 74.54753971099854, 75.66832208633423, 76.78910446166992, 77.90689516067505, 79.02468585968018, 80.13743805885315, 81.25019025802612, 82.3720850944519, 83.49397993087769, 84.61694097518921, 85.73990201950073, 86.87469744682312, 88.00949287414551, 89.13238644599915, 90.25528001785278, 91.3601541519165, 92.46502828598022, 93.58471012115479, 94.70439195632935, 95.82989740371704, 96.95540285110474, 98.0718641281128, 99.18832540512085, 100.29973840713501, 101.41115140914917, 102.52636814117432, 103.64158487319946, 104.77131748199463, 105.9010500907898, 107.01456832885742, 108.12808656692505, 109.24637293815613, 110.3646593093872, 111.48457741737366, 112.60449552536011, 113.72545433044434, 114.84641313552856, 115.96508383750916, 117.08375453948975, 118.20240330696106, 119.32105207443237, 120.44085216522217, 121.56065225601196, 122.6751115322113, 123.78957080841064, 124.89366030693054, 125.99774980545044, 127.1121187210083, 128.22648763656616, 129.355961561203, 130.48543548583984, 131.60772919654846, 132.73002290725708, 133.84752655029297, 134.96503019332886, 136.07541823387146, 137.18580627441406, 138.31228804588318, 139.4387698173523, 140.55647706985474, 141.67418432235718, 142.78789734840393, 143.90161037445068, 145.02019333839417, 146.13877630233765, 147.25932502746582, 148.379873752594, 149.50000262260437, 150.62013149261475, 151.73796677589417, 152.85580205917358, 153.97008514404297, 155.08436822891235, 156.20528888702393, 157.3262095451355, 158.4438979625702, 159.56158638000488, 160.67788672447205, 161.7941870689392, 162.91296434402466, 164.0317416191101, 165.14550685882568, 166.25927209854126, 167.3688452243805, 168.47841835021973, 169.5985996723175, 170.71878099441528, 171.84539103507996, 172.97200107574463, 174.10564398765564, 175.23928689956665, 176.36715149879456, 177.49501609802246, 178.60832238197327, 179.72162866592407, 180.84770035743713, 181.9737720489502, 183.1116464138031, 184.249520778656, 185.373060464859, 186.496600151062, 187.61013078689575, 188.7236614227295, 189.84037375450134, 190.9570860862732, 192.0752444267273, 193.1934027671814, 194.31266260147095, 195.4319224357605, 196.54205131530762, 197.65218019485474, 198.79038453102112, 199.9285888671875, 201.0561819076538, 202.18377494812012, 203.30025720596313, 204.41673946380615, 205.53788042068481, 206.65902137756348, 207.77544617652893, 208.89187097549438, 210.0112612247467, 211.13065147399902, 212.24316382408142, 213.35567617416382, 214.4689953327179, 215.58231449127197, 216.6939980983734, 217.80568170547485, 218.93813252449036, 220.07058334350586, 221.1788032054901, 222.28702306747437, 223.4035496711731, 224.52007627487183, 226.7774519920349, 229.034827709198]
[22.03, 22.03, 26.58, 26.58, 38.2, 38.2, 43.25, 43.25, 43.85, 43.85, 47.07, 47.07, 48.71, 48.71, 50.27, 50.27, 50.86, 50.86, 53.3, 53.3, 55.34, 55.34, 56.63, 56.63, 56.73, 56.73, 58.65, 58.65, 58.37, 58.37, 58.98, 58.98, 59.59, 59.59, 60.13, 60.13, 60.41, 60.41, 60.93, 60.93, 61.63, 61.63, 62.59, 62.59, 63.77, 63.77, 63.73, 63.73, 65.08, 65.08, 64.94, 64.94, 65.69, 65.69, 65.65, 65.65, 66.55, 66.55, 66.65, 66.65, 66.78, 66.78, 66.1, 66.1, 66.08, 66.08, 66.79, 66.79, 67.06, 67.06, 67.39, 67.39, 68.1, 68.1, 68.48, 68.48, 68.55, 68.55, 68.27, 68.27, 68.54, 68.54, 68.86, 68.86, 68.96, 68.96, 69.09, 69.09, 69.51, 69.51, 69.47, 69.47, 69.78, 69.78, 69.91, 69.91, 69.87, 69.87, 69.82, 69.82, 69.89, 69.89, 70.04, 70.04, 69.85, 69.85, 70.11, 70.11, 69.69, 69.69, 70.14, 70.14, 70.39, 70.39, 70.14, 70.14, 71.31, 71.31, 71.32, 71.32, 71.39, 71.39, 71.73, 71.73, 70.59, 70.59, 71.22, 71.22, 70.55, 70.55, 71.13, 71.13, 71.12, 71.12, 70.94, 70.94, 70.97, 70.97, 71.5, 71.5, 71.78, 71.78, 71.65, 71.65, 71.7, 71.7, 70.73, 70.73, 70.59, 70.59, 70.92, 70.92, 70.73, 70.73, 71.17, 71.17, 71.98, 71.98, 71.63, 71.63, 71.64, 71.64, 71.64, 71.64, 71.92, 71.92, 72.35, 72.35, 71.97, 71.97, 71.13, 71.13, 71.27, 71.27, 71.27, 71.27, 71.19, 71.19, 71.53, 71.53, 71.52, 71.52, 71.71, 71.71, 71.81, 71.81, 71.85, 71.85, 71.98, 71.98, 71.72, 71.72, 72.46, 72.46, 71.63, 71.63, 71.27, 71.27, 72.02, 72.02, 71.82, 71.82]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 7, noise    level: 0.8000 
   Client 14, noise    level: 0.8000 
   Client 15, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 12, noise    level: 0.8000 
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.968, Test loss: 2.194, Test accuracy: 17.13
Round   1, Train loss: 1.555, Test loss: 2.102, Test accuracy: 25.57
Round   2, Train loss: 1.583, Test loss: 1.678, Test accuracy: 36.33
Round   3, Train loss: 1.407, Test loss: 1.529, Test accuracy: 40.07
Round   4, Train loss: 1.284, Test loss: 1.402, Test accuracy: 45.42
Round   5, Train loss: 1.248, Test loss: 1.358, Test accuracy: 46.37
Round   6, Train loss: 1.319, Test loss: 1.299, Test accuracy: 48.02
Round   7, Train loss: 1.191, Test loss: 1.218, Test accuracy: 52.14
Round   8, Train loss: 1.191, Test loss: 1.235, Test accuracy: 51.78
Round   9, Train loss: 1.155, Test loss: 1.210, Test accuracy: 54.03
Round  10, Train loss: 1.140, Test loss: 1.175, Test accuracy: 55.67
Round  11, Train loss: 1.072, Test loss: 1.142, Test accuracy: 56.15
Round  12, Train loss: 1.118, Test loss: 1.116, Test accuracy: 57.64
Round  13, Train loss: 1.123, Test loss: 1.067, Test accuracy: 58.91
Round  14, Train loss: 1.139, Test loss: 1.079, Test accuracy: 58.98
Round  15, Train loss: 1.121, Test loss: 1.052, Test accuracy: 59.61
Round  16, Train loss: 1.007, Test loss: 1.042, Test accuracy: 59.70
Round  17, Train loss: 1.030, Test loss: 1.043, Test accuracy: 60.21
Round  18, Train loss: 0.966, Test loss: 1.013, Test accuracy: 61.12
Round  19, Train loss: 1.014, Test loss: 0.990, Test accuracy: 62.16
Round  20, Train loss: 0.968, Test loss: 1.002, Test accuracy: 62.55
Round  21, Train loss: 0.970, Test loss: 0.992, Test accuracy: 63.16
Round  22, Train loss: 1.069, Test loss: 0.984, Test accuracy: 63.76
Round  23, Train loss: 0.926, Test loss: 0.951, Test accuracy: 65.02
Round  24, Train loss: 0.951, Test loss: 0.946, Test accuracy: 64.51
Round  25, Train loss: 0.959, Test loss: 0.943, Test accuracy: 65.78
Round  26, Train loss: 0.892, Test loss: 0.932, Test accuracy: 66.06
Round  27, Train loss: 0.954, Test loss: 0.918, Test accuracy: 66.42
Round  28, Train loss: 0.957, Test loss: 0.908, Test accuracy: 66.89
Round  29, Train loss: 0.874, Test loss: 0.901, Test accuracy: 67.21
Round  30, Train loss: 0.863, Test loss: 0.878, Test accuracy: 67.27
Round  31, Train loss: 0.819, Test loss: 0.878, Test accuracy: 67.40
Round  32, Train loss: 0.872, Test loss: 0.869, Test accuracy: 67.51
Round  33, Train loss: 0.816, Test loss: 0.869, Test accuracy: 67.41
Round  34, Train loss: 0.787, Test loss: 0.859, Test accuracy: 68.45
Round  35, Train loss: 0.884, Test loss: 0.845, Test accuracy: 68.96
Round  36, Train loss: 0.830, Test loss: 0.839, Test accuracy: 69.05
Round  37, Train loss: 0.828, Test loss: 0.836, Test accuracy: 69.21
Round  38, Train loss: 0.926, Test loss: 0.839, Test accuracy: 69.43
Round  39, Train loss: 0.771, Test loss: 0.830, Test accuracy: 69.57
Round  40, Train loss: 0.813, Test loss: 0.838, Test accuracy: 69.33
Round  41, Train loss: 0.822, Test loss: 0.815, Test accuracy: 69.96
Round  42, Train loss: 0.706, Test loss: 0.814, Test accuracy: 70.12
Round  43, Train loss: 0.844, Test loss: 0.804, Test accuracy: 70.36
Round  44, Train loss: 0.790, Test loss: 0.798, Test accuracy: 71.01
Round  45, Train loss: 0.856, Test loss: 0.801, Test accuracy: 71.04
Round  46, Train loss: 0.809, Test loss: 0.802, Test accuracy: 70.62
Round  47, Train loss: 0.746, Test loss: 0.798, Test accuracy: 70.51
Round  48, Train loss: 0.717, Test loss: 0.789, Test accuracy: 70.83
Round  49, Train loss: 0.643, Test loss: 0.773, Test accuracy: 71.68
Round  50, Train loss: 0.769, Test loss: 0.779, Test accuracy: 71.25
Round  51, Train loss: 0.642, Test loss: 0.771, Test accuracy: 71.75
Round  52, Train loss: 0.711, Test loss: 0.774, Test accuracy: 71.65
Round  53, Train loss: 0.752, Test loss: 0.780, Test accuracy: 71.76
Round  54, Train loss: 0.726, Test loss: 0.786, Test accuracy: 71.33
Round  55, Train loss: 0.653, Test loss: 0.761, Test accuracy: 72.45
Round  56, Train loss: 0.705, Test loss: 0.749, Test accuracy: 73.03
Round  57, Train loss: 0.777, Test loss: 0.756, Test accuracy: 72.35
Round  58, Train loss: 0.745, Test loss: 0.756, Test accuracy: 72.73
Round  59, Train loss: 0.622, Test loss: 0.750, Test accuracy: 72.68
Round  60, Train loss: 0.815, Test loss: 0.742, Test accuracy: 72.77
Round  61, Train loss: 0.697, Test loss: 0.743, Test accuracy: 72.54
Round  62, Train loss: 0.775, Test loss: 0.754, Test accuracy: 72.11
Round  63, Train loss: 0.725, Test loss: 0.746, Test accuracy: 72.53
Round  64, Train loss: 0.729, Test loss: 0.738, Test accuracy: 72.73
Round  65, Train loss: 0.726, Test loss: 0.736, Test accuracy: 73.04
Round  66, Train loss: 0.709, Test loss: 0.738, Test accuracy: 72.97
Round  67, Train loss: 0.697, Test loss: 0.756, Test accuracy: 72.19
Round  68, Train loss: 0.699, Test loss: 0.736, Test accuracy: 73.16
Round  69, Train loss: 0.676, Test loss: 0.731, Test accuracy: 73.15
Round  70, Train loss: 0.608, Test loss: 0.736, Test accuracy: 72.90
Round  71, Train loss: 0.610, Test loss: 0.733, Test accuracy: 72.82
Round  72, Train loss: 0.682, Test loss: 0.721, Test accuracy: 73.74
Round  73, Train loss: 0.593, Test loss: 0.718, Test accuracy: 73.50
Round  74, Train loss: 0.573, Test loss: 0.720, Test accuracy: 73.90
Round  75, Train loss: 0.621, Test loss: 0.728, Test accuracy: 73.48
Round  76, Train loss: 0.524, Test loss: 0.723, Test accuracy: 73.49
Round  77, Train loss: 0.548, Test loss: 0.724, Test accuracy: 73.36
Round  78, Train loss: 0.551, Test loss: 0.725, Test accuracy: 73.61
Round  79, Train loss: 0.580, Test loss: 0.727, Test accuracy: 73.46
Round  80, Train loss: 0.565, Test loss: 0.714, Test accuracy: 74.15
Round  81, Train loss: 0.569, Test loss: 0.720, Test accuracy: 73.98
Round  82, Train loss: 0.667, Test loss: 0.725, Test accuracy: 73.14
Round  83, Train loss: 0.553, Test loss: 0.730, Test accuracy: 73.04
Round  84, Train loss: 0.546, Test loss: 0.723, Test accuracy: 73.24
Round  85, Train loss: 0.544, Test loss: 0.718, Test accuracy: 73.65
Round  86, Train loss: 0.545, Test loss: 0.709, Test accuracy: 74.05
Round  87, Train loss: 0.555, Test loss: 0.716, Test accuracy: 73.70
Round  88, Train loss: 0.717, Test loss: 0.720, Test accuracy: 73.35
Round  89, Train loss: 0.591, Test loss: 0.707, Test accuracy: 73.71
Round  90, Train loss: 0.513, Test loss: 0.707, Test accuracy: 74.02
Round  91, Train loss: 0.531, Test loss: 0.712, Test accuracy: 74.29
Round  92, Train loss: 0.550, Test loss: 0.715, Test accuracy: 74.19
Round  93, Train loss: 0.526, Test loss: 0.703, Test accuracy: 74.48
Round  94, Train loss: 0.598, Test loss: 0.710, Test accuracy: 74.31
Round  95, Train loss: 0.503, Test loss: 0.716, Test accuracy: 73.76
Round  96, Train loss: 0.489, Test loss: 0.719, Test accuracy: 73.65
Round  97, Train loss: 0.523, Test loss: 0.700, Test accuracy: 74.49
Round  98, Train loss: 0.539, Test loss: 0.708, Test accuracy: 74.08
Round  99, Train loss: 0.495, Test loss: 0.712, Test accuracy: 74.38
Final Round, Train loss: 0.457, Test loss: 0.712, Test accuracy: 74.14
Average accuracy final 10 rounds: 74.16499999999999
1975.0727906227112
[3.246731996536255, 6.241597890853882, 9.306945323944092, 12.31460428237915, 15.328137636184692, 18.33132028579712, 21.31016969680786, 24.271491050720215, 27.323705434799194, 30.29619288444519, 33.11870861053467, 35.9584686756134, 38.76095366477966, 41.63061261177063, 44.480568408966064, 47.302736043930054, 50.14972519874573, 52.972838401794434, 55.800583362579346, 58.63281583786011, 61.464067697525024, 64.26558303833008, 67.12156009674072, 69.90968918800354, 72.73187923431396, 75.58411574363708, 78.41433358192444, 81.25915789604187, 84.1234700679779, 86.95770287513733, 89.79856944084167, 92.62482070922852, 95.44155502319336, 98.27445960044861, 101.09178805351257, 103.7252299785614, 106.33105826377869, 108.93426537513733, 111.54548192024231, 114.15730237960815, 116.74765920639038, 119.34436297416687, 121.95894598960876, 124.56256604194641, 127.15853643417358, 129.80446863174438, 132.42204570770264, 135.03169918060303, 137.65585470199585, 140.24921226501465, 142.8577902317047, 145.48664093017578, 148.08262157440186, 150.6848521232605, 153.32306551933289, 155.91123485565186, 158.4985806941986, 161.13498401641846, 163.74265480041504, 166.3527226448059, 168.98449850082397, 171.5987057685852, 174.18908405303955, 176.80827569961548, 179.41940426826477, 181.9996817111969, 184.63423824310303, 187.2479908466339, 189.8464159965515, 192.46792316436768, 195.06436586380005, 197.67154121398926, 200.30118417739868, 202.90627551078796, 205.4516053199768, 208.0479552745819, 210.63301181793213, 213.29486203193665, 215.96639347076416, 218.84539484977722, 221.70563578605652, 224.6391956806183, 227.561368227005, 230.46104884147644, 233.3879840373993, 236.2730748653412, 239.13035583496094, 242.0121500492096, 244.88524103164673, 247.76151418685913, 250.6906807422638, 253.54556608200073, 256.40307688713074, 259.1455235481262, 261.97032260894775, 264.8712604045868, 267.76796436309814, 270.63030076026917, 273.54131627082825, 276.44562911987305, 280.6607210636139]
[17.13, 25.57, 36.33, 40.07, 45.42, 46.37, 48.02, 52.14, 51.78, 54.03, 55.67, 56.15, 57.64, 58.91, 58.98, 59.61, 59.7, 60.21, 61.12, 62.16, 62.55, 63.16, 63.76, 65.02, 64.51, 65.78, 66.06, 66.42, 66.89, 67.21, 67.27, 67.4, 67.51, 67.41, 68.45, 68.96, 69.05, 69.21, 69.43, 69.57, 69.33, 69.96, 70.12, 70.36, 71.01, 71.04, 70.62, 70.51, 70.83, 71.68, 71.25, 71.75, 71.65, 71.76, 71.33, 72.45, 73.03, 72.35, 72.73, 72.68, 72.77, 72.54, 72.11, 72.53, 72.73, 73.04, 72.97, 72.19, 73.16, 73.15, 72.9, 72.82, 73.74, 73.5, 73.9, 73.48, 73.49, 73.36, 73.61, 73.46, 74.15, 73.98, 73.14, 73.04, 73.24, 73.65, 74.05, 73.7, 73.35, 73.71, 74.02, 74.29, 74.19, 74.48, 74.31, 73.76, 73.65, 74.49, 74.08, 74.38, 74.14]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 18, noise    level: 0.8000 
   Client 16, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 13, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 14, noise    level: 0.8000 
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  10.0000
Round 1 global test acc  14.1000
Round 2 global test acc  17.9200
Round 3 global test acc  18.6100
Round 4 global test acc  24.0900
Round 5 global test acc  26.6900
Round 6 global test acc  28.5500
Round 7 global test acc  32.0000
Round 8 global test acc  27.5800
Round 9 global test acc  30.8900
Round 10 global test acc  30.9800
Round 11 global test acc  29.2100
Round 12 global test acc  34.2600
Round 13 global test acc  30.4200
Round 14 global test acc  40.4000
Round 15 global test acc  34.9800
Round 16 global test acc  31.7700
Round 17 global test acc  38.2400
Round 18 global test acc  35.0000
Round 19 global test acc  37.6500
Round 20 global test acc  32.0500
Round 21 global test acc  30.7600
Round 22 global test acc  35.1700
Round 23 global test acc  31.6000
Round 24 global test acc  38.5300
Round 25 global test acc  35.5300
Round 26 global test acc  34.1700
Round 27 global test acc  42.5300
Round 28 global test acc  39.7700
Round 29 global test acc  34.8100
Round 30 global test acc  42.5300
Round 31 global test acc  41.6300
Round 32 global test acc  30.9400
Round 33 global test acc  39.7600
Round 34 global test acc  38.1200
Round 35 global test acc  37.0400
Round 36 global test acc  40.2600
Round 37 global test acc  42.2700
Round 38 global test acc  37.5400
Round 39 global test acc  50.8100
Round 40 global test acc  46.9500
Round 41 global test acc  38.6800
Round 42 global test acc  38.6500
Round 43 global test acc  43.9000
Round 44 global test acc  43.7700
Round 45 global test acc  42.4700
Round 46 global test acc  45.4900
Round 47 global test acc  45.9000
Round 48 global test acc  39.9000
Round 49 global test acc  39.6300
Round 50 global test acc  42.0300
Round 51 global test acc  37.8700
Round 52 global test acc  39.8100
Round 53 global test acc  43.4700
Round 54 global test acc  44.8600
Round 55 global test acc  39.7100
Round 56 global test acc  44.5100
Round 57 global test acc  39.3000
Round 58 global test acc  48.0500
Round 59 global test acc  43.6800
Round 60 global test acc  41.8700
Round 61 global test acc  36.8700
Round 62 global test acc  40.6700
Round 63 global test acc  40.9000
Round 64 global test acc  39.9500
Round 65 global test acc  45.1400
Round 66 global test acc  39.5900
Round 67 global test acc  49.0800
Round 68 global test acc  44.4800
Round 69 global test acc  43.9400
Round 70 global test acc  38.4800
Round 71 global test acc  42.0500
Round 72 global test acc  42.6500
Round 73 global test acc  44.4600
Round 74 global test acc  37.3800
Round 75 global test acc  46.5300
Round 76 global test acc  46.7200
Round 77 global test acc  40.7000
Round 78 global test acc  42.3400
Round 79 global test acc  41.9800
Round 80 global test acc  38.8300
Round 81 global test acc  33.6000
Round 82 global test acc  29.1100
Round 83 global test acc  27.1500
Round 84 global test acc  24.9400
Round 85 global test acc  24.6800
Round 86 global test acc  23.8400
Round 87 global test acc  23.5400
Round 88 global test acc  23.5400
Round 89 global test acc  23.1500
Round 90 global test acc  22.7200
Round 91 global test acc  22.2900
Round 92 global test acc  21.3000
Round 93 global test acc  20.5300
Round 94 global test acc  20.1200
Round 95 global test acc  19.8600
Round 96 global test acc  19.4000
Round 97 global test acc  19.1600
Round 98 global test acc  18.8100
Round 99 global test acc  18.4000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 7, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 19, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 17, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 15, noise    level: 0.8000 
   Client 13, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.998, Test loss: 2.171, Test accuracy: 17.94
Round   1, Train loss: 1.549, Test loss: 2.223, Test accuracy: 23.69
Round   2, Train loss: 1.560, Test loss: 1.719, Test accuracy: 33.67
Round   3, Train loss: 1.413, Test loss: 1.507, Test accuracy: 40.33
Round   4, Train loss: 1.237, Test loss: 1.400, Test accuracy: 45.62
Round   5, Train loss: 1.315, Test loss: 1.331, Test accuracy: 49.36
Round   6, Train loss: 1.368, Test loss: 1.253, Test accuracy: 51.59
Round   7, Train loss: 1.258, Test loss: 1.211, Test accuracy: 53.77
Round   8, Train loss: 1.118, Test loss: 1.227, Test accuracy: 54.45
Round   9, Train loss: 1.137, Test loss: 1.176, Test accuracy: 56.72
Round  10, Train loss: 1.168, Test loss: 1.127, Test accuracy: 57.20
Round  11, Train loss: 1.031, Test loss: 1.117, Test accuracy: 57.35
Round  12, Train loss: 1.064, Test loss: 1.096, Test accuracy: 58.63
Round  13, Train loss: 1.096, Test loss: 1.008, Test accuracy: 61.76
Round  14, Train loss: 1.033, Test loss: 1.000, Test accuracy: 62.40
Round  15, Train loss: 1.012, Test loss: 0.996, Test accuracy: 63.01
Round  16, Train loss: 1.002, Test loss: 0.980, Test accuracy: 63.70
Round  17, Train loss: 1.070, Test loss: 0.974, Test accuracy: 63.44
Round  18, Train loss: 0.954, Test loss: 0.976, Test accuracy: 63.42
Round  19, Train loss: 0.992, Test loss: 0.955, Test accuracy: 63.77
Round  20, Train loss: 1.016, Test loss: 0.932, Test accuracy: 64.56
Round  21, Train loss: 0.998, Test loss: 0.914, Test accuracy: 65.99
Round  22, Train loss: 0.989, Test loss: 0.916, Test accuracy: 66.03
Round  23, Train loss: 0.926, Test loss: 0.891, Test accuracy: 66.56
Round  24, Train loss: 0.918, Test loss: 0.887, Test accuracy: 67.00
Round  25, Train loss: 0.945, Test loss: 0.874, Test accuracy: 68.07
Round  26, Train loss: 0.880, Test loss: 0.869, Test accuracy: 68.03
Round  27, Train loss: 1.001, Test loss: 0.849, Test accuracy: 69.06
Round  28, Train loss: 0.875, Test loss: 0.846, Test accuracy: 68.88
Round  29, Train loss: 0.858, Test loss: 0.842, Test accuracy: 69.54
Round  30, Train loss: 0.839, Test loss: 0.825, Test accuracy: 69.50
Round  31, Train loss: 0.757, Test loss: 0.821, Test accuracy: 70.03
Round  32, Train loss: 0.805, Test loss: 0.814, Test accuracy: 69.97
Round  33, Train loss: 0.813, Test loss: 0.814, Test accuracy: 70.47
Round  34, Train loss: 0.826, Test loss: 0.809, Test accuracy: 70.56
Round  35, Train loss: 0.911, Test loss: 0.812, Test accuracy: 70.74
Round  36, Train loss: 0.882, Test loss: 0.807, Test accuracy: 70.42
Round  37, Train loss: 0.758, Test loss: 0.801, Test accuracy: 70.76
Round  38, Train loss: 0.848, Test loss: 0.795, Test accuracy: 70.69
Round  39, Train loss: 0.790, Test loss: 0.794, Test accuracy: 71.14
Round  40, Train loss: 0.755, Test loss: 0.795, Test accuracy: 71.00
Round  41, Train loss: 0.852, Test loss: 0.784, Test accuracy: 71.51
Round  42, Train loss: 0.702, Test loss: 0.779, Test accuracy: 71.53
Round  43, Train loss: 0.673, Test loss: 0.771, Test accuracy: 72.07
Round  44, Train loss: 0.757, Test loss: 0.769, Test accuracy: 71.79
Round  45, Train loss: 0.882, Test loss: 0.768, Test accuracy: 71.83
Round  46, Train loss: 0.815, Test loss: 0.762, Test accuracy: 72.44
Round  47, Train loss: 0.757, Test loss: 0.758, Test accuracy: 72.50
Round  48, Train loss: 0.732, Test loss: 0.743, Test accuracy: 72.76
Round  49, Train loss: 0.675, Test loss: 0.745, Test accuracy: 73.08
Round  50, Train loss: 0.811, Test loss: 0.746, Test accuracy: 73.38
Round  51, Train loss: 0.708, Test loss: 0.735, Test accuracy: 73.65
Round  52, Train loss: 0.732, Test loss: 0.730, Test accuracy: 73.33
Round  53, Train loss: 0.684, Test loss: 0.733, Test accuracy: 73.72
Round  54, Train loss: 0.664, Test loss: 0.745, Test accuracy: 72.90
Round  55, Train loss: 0.699, Test loss: 0.731, Test accuracy: 73.55
Round  56, Train loss: 0.688, Test loss: 0.731, Test accuracy: 73.60
Round  57, Train loss: 0.743, Test loss: 0.728, Test accuracy: 73.45
Round  58, Train loss: 0.654, Test loss: 0.723, Test accuracy: 73.91
Round  59, Train loss: 0.595, Test loss: 0.715, Test accuracy: 74.21
Round  60, Train loss: 0.662, Test loss: 0.713, Test accuracy: 74.01
Round  61, Train loss: 0.707, Test loss: 0.714, Test accuracy: 74.32
Round  62, Train loss: 0.691, Test loss: 0.712, Test accuracy: 74.62
Round  63, Train loss: 0.573, Test loss: 0.705, Test accuracy: 74.65
Round  64, Train loss: 0.711, Test loss: 0.712, Test accuracy: 74.75
Round  65, Train loss: 0.623, Test loss: 0.708, Test accuracy: 74.17
Round  66, Train loss: 0.557, Test loss: 0.700, Test accuracy: 74.76
Round  67, Train loss: 0.677, Test loss: 0.694, Test accuracy: 74.90
Round  68, Train loss: 0.610, Test loss: 0.705, Test accuracy: 74.39
Round  69, Train loss: 0.787, Test loss: 0.714, Test accuracy: 73.88
Round  70, Train loss: 0.480, Test loss: 0.700, Test accuracy: 74.19
Round  71, Train loss: 0.594, Test loss: 0.700, Test accuracy: 74.60
Round  72, Train loss: 0.499, Test loss: 0.697, Test accuracy: 74.60
Round  73, Train loss: 0.584, Test loss: 0.704, Test accuracy: 74.79
Round  74, Train loss: 0.558, Test loss: 0.709, Test accuracy: 74.15
Round  75, Train loss: 0.581, Test loss: 0.699, Test accuracy: 74.83
Round  76, Train loss: 0.524, Test loss: 0.693, Test accuracy: 75.43
Round  77, Train loss: 0.532, Test loss: 0.696, Test accuracy: 75.75
Round  78, Train loss: 0.471, Test loss: 0.697, Test accuracy: 75.18
Round  79, Train loss: 0.607, Test loss: 0.696, Test accuracy: 75.19
Round  80, Train loss: 0.549, Test loss: 0.685, Test accuracy: 75.99
Round  81, Train loss: 0.521, Test loss: 0.682, Test accuracy: 76.26
Round  82, Train loss: 0.731, Test loss: 0.691, Test accuracy: 76.01
Round  83, Train loss: 0.530, Test loss: 0.685, Test accuracy: 75.83
Round  84, Train loss: 0.526, Test loss: 0.700, Test accuracy: 75.39
Round  85, Train loss: 0.544, Test loss: 0.703, Test accuracy: 75.34
Round  86, Train loss: 0.634, Test loss: 0.705, Test accuracy: 75.52
Round  87, Train loss: 0.583, Test loss: 0.692, Test accuracy: 75.91
Round  88, Train loss: 0.655, Test loss: 0.690, Test accuracy: 76.00
Round  89, Train loss: 0.560, Test loss: 0.689, Test accuracy: 75.78
Round  90, Train loss: 0.406, Test loss: 0.680, Test accuracy: 75.76
Round  91, Train loss: 0.569, Test loss: 0.682, Test accuracy: 75.88
Round  92, Train loss: 0.506, Test loss: 0.691, Test accuracy: 75.56
Round  93, Train loss: 0.395, Test loss: 0.685, Test accuracy: 75.94
Round  94, Train loss: 0.512, Test loss: 0.691, Test accuracy: 75.91
Round  95, Train loss: 0.610, Test loss: 0.695, Test accuracy: 75.42
Round  96, Train loss: 0.588, Test loss: 0.708, Test accuracy: 75.05
Round  97, Train loss: 0.473, Test loss: 0.694, Test accuracy: 75.69
Round  98, Train loss: 0.507, Test loss: 0.707, Test accuracy: 75.27
Round  99, Train loss: 0.441, Test loss: 0.698, Test accuracy: 75.65
Final Round, Train loss: 0.432, Test loss: 0.696, Test accuracy: 75.76
Average accuracy final 10 rounds: 75.613
1059.647974729538
[1.6960811614990234, 3.0635154247283936, 4.432043075561523, 5.7963807582855225, 7.158807277679443, 8.510706663131714, 9.876304626464844, 11.324225664138794, 12.68344497680664, 14.035374879837036, 15.384093046188354, 16.752806663513184, 18.11691164970398, 19.48091697692871, 20.845313787460327, 22.083608627319336, 23.32476019859314, 24.563207626342773, 25.795241117477417, 27.00862431526184, 28.244774341583252, 29.47464609146118, 30.692786693572998, 31.932472467422485, 33.17860794067383, 34.39711284637451, 35.66484069824219, 36.891698598861694, 38.112990379333496, 39.34271740913391, 40.579280614852905, 41.8107545375824, 43.0477454662323, 44.28956651687622, 45.51909422874451, 46.75520730018616, 47.990450859069824, 49.22165393829346, 50.448673725128174, 51.69255495071411, 52.93330645561218, 54.1564154624939, 55.38563108444214, 56.61070418357849, 57.845364570617676, 59.07724952697754, 60.30234408378601, 61.52723693847656, 62.74672317504883, 63.98185920715332, 65.20896530151367, 66.42907786369324, 67.65254759788513, 68.88073778152466, 70.10397362709045, 71.32628226280212, 72.5630271434784, 73.80456495285034, 75.03580212593079, 76.27174186706543, 77.5071063041687, 78.73040223121643, 79.95873689651489, 81.19421982765198, 82.41672325134277, 83.64161443710327, 84.88376569747925, 86.12245488166809, 87.36798787117004, 88.6067271232605, 89.84797859191895, 91.08515429496765, 92.33194422721863, 93.57731461524963, 94.8049840927124, 96.03693628311157, 97.2747814655304, 98.50451850891113, 99.72934699058533, 100.96752905845642, 102.21260809898376, 103.45125937461853, 104.84878349304199, 106.21825790405273, 107.59296822547913, 108.96292734146118, 110.33690476417542, 111.70435810089111, 113.08642721176147, 114.4478759765625, 115.81174874305725, 117.17470502853394, 118.53259611129761, 119.89051055908203, 121.25530290603638, 122.61971759796143, 123.98687887191772, 125.35332179069519, 126.71982932090759, 128.08446741104126, 130.15152072906494]
[17.94, 23.69, 33.67, 40.33, 45.62, 49.36, 51.59, 53.77, 54.45, 56.72, 57.2, 57.35, 58.63, 61.76, 62.4, 63.01, 63.7, 63.44, 63.42, 63.77, 64.56, 65.99, 66.03, 66.56, 67.0, 68.07, 68.03, 69.06, 68.88, 69.54, 69.5, 70.03, 69.97, 70.47, 70.56, 70.74, 70.42, 70.76, 70.69, 71.14, 71.0, 71.51, 71.53, 72.07, 71.79, 71.83, 72.44, 72.5, 72.76, 73.08, 73.38, 73.65, 73.33, 73.72, 72.9, 73.55, 73.6, 73.45, 73.91, 74.21, 74.01, 74.32, 74.62, 74.65, 74.75, 74.17, 74.76, 74.9, 74.39, 73.88, 74.19, 74.6, 74.6, 74.79, 74.15, 74.83, 75.43, 75.75, 75.18, 75.19, 75.99, 76.26, 76.01, 75.83, 75.39, 75.34, 75.52, 75.91, 76.0, 75.78, 75.76, 75.88, 75.56, 75.94, 75.91, 75.42, 75.05, 75.69, 75.27, 75.65, 75.76]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.4 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 1, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 13, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 14, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.973, Test loss: 2.120, Test accuracy: 23.35
Round   1, Train loss: 1.510, Test loss: 2.166, Test accuracy: 25.59
Round   2, Train loss: 1.431, Test loss: 1.635, Test accuracy: 35.70
Round   3, Train loss: 1.440, Test loss: 1.432, Test accuracy: 44.71
Round   4, Train loss: 1.185, Test loss: 1.322, Test accuracy: 48.15
Round   5, Train loss: 1.184, Test loss: 1.263, Test accuracy: 49.91
Round   6, Train loss: 1.420, Test loss: 1.212, Test accuracy: 53.30
Round   7, Train loss: 1.115, Test loss: 1.155, Test accuracy: 55.08
Round   8, Train loss: 1.141, Test loss: 1.201, Test accuracy: 54.77
Round   9, Train loss: 1.049, Test loss: 1.171, Test accuracy: 56.68
Round  10, Train loss: 1.199, Test loss: 1.102, Test accuracy: 58.10
Round  11, Train loss: 0.980, Test loss: 1.094, Test accuracy: 58.24
Round  12, Train loss: 1.102, Test loss: 1.083, Test accuracy: 59.15
Round  13, Train loss: 0.986, Test loss: 1.002, Test accuracy: 61.45
Round  14, Train loss: 1.028, Test loss: 0.993, Test accuracy: 62.39
Round  15, Train loss: 1.069, Test loss: 0.987, Test accuracy: 62.55
Round  16, Train loss: 1.004, Test loss: 0.961, Test accuracy: 63.48
Round  17, Train loss: 0.925, Test loss: 0.943, Test accuracy: 63.88
Round  18, Train loss: 0.850, Test loss: 0.927, Test accuracy: 64.89
Round  19, Train loss: 1.047, Test loss: 0.920, Test accuracy: 65.25
Round  20, Train loss: 0.879, Test loss: 0.906, Test accuracy: 66.19
Round  21, Train loss: 0.904, Test loss: 0.892, Test accuracy: 67.13
Round  22, Train loss: 1.041, Test loss: 0.883, Test accuracy: 67.10
Round  23, Train loss: 0.818, Test loss: 0.867, Test accuracy: 67.56
Round  24, Train loss: 0.827, Test loss: 0.865, Test accuracy: 67.94
Round  25, Train loss: 0.840, Test loss: 0.859, Test accuracy: 68.56
Round  26, Train loss: 0.828, Test loss: 0.848, Test accuracy: 68.15
Round  27, Train loss: 0.918, Test loss: 0.843, Test accuracy: 68.71
Round  28, Train loss: 0.844, Test loss: 0.844, Test accuracy: 68.92
Round  29, Train loss: 0.846, Test loss: 0.826, Test accuracy: 69.64
Round  30, Train loss: 0.827, Test loss: 0.813, Test accuracy: 69.93
Round  31, Train loss: 0.711, Test loss: 0.811, Test accuracy: 70.16
Round  32, Train loss: 0.836, Test loss: 0.799, Test accuracy: 70.97
Round  33, Train loss: 0.726, Test loss: 0.798, Test accuracy: 69.99
Round  34, Train loss: 0.727, Test loss: 0.797, Test accuracy: 70.59
Round  35, Train loss: 0.841, Test loss: 0.789, Test accuracy: 71.33
Round  36, Train loss: 0.817, Test loss: 0.788, Test accuracy: 71.21
Round  37, Train loss: 0.698, Test loss: 0.779, Test accuracy: 71.48
Round  38, Train loss: 0.901, Test loss: 0.771, Test accuracy: 71.64
Round  39, Train loss: 0.683, Test loss: 0.773, Test accuracy: 71.30
Round  40, Train loss: 0.690, Test loss: 0.768, Test accuracy: 71.71
Round  41, Train loss: 0.787, Test loss: 0.766, Test accuracy: 71.77
Round  42, Train loss: 0.612, Test loss: 0.766, Test accuracy: 71.59
Round  43, Train loss: 0.744, Test loss: 0.747, Test accuracy: 72.30
Round  44, Train loss: 0.743, Test loss: 0.760, Test accuracy: 72.00
Round  45, Train loss: 0.901, Test loss: 0.744, Test accuracy: 72.76
Round  46, Train loss: 0.874, Test loss: 0.747, Test accuracy: 72.72
Round  47, Train loss: 0.745, Test loss: 0.751, Test accuracy: 72.85
Round  48, Train loss: 0.805, Test loss: 0.742, Test accuracy: 73.32
Round  49, Train loss: 0.629, Test loss: 0.738, Test accuracy: 73.38
Round  50, Train loss: 0.734, Test loss: 0.727, Test accuracy: 73.84
Round  51, Train loss: 0.592, Test loss: 0.741, Test accuracy: 72.82
Round  52, Train loss: 0.584, Test loss: 0.730, Test accuracy: 73.33
Round  53, Train loss: 0.680, Test loss: 0.730, Test accuracy: 73.66
Round  54, Train loss: 0.693, Test loss: 0.721, Test accuracy: 73.98
Round  55, Train loss: 0.604, Test loss: 0.727, Test accuracy: 73.56
Round  56, Train loss: 0.686, Test loss: 0.713, Test accuracy: 74.48
Round  57, Train loss: 0.794, Test loss: 0.716, Test accuracy: 74.28
Round  58, Train loss: 0.640, Test loss: 0.710, Test accuracy: 74.46
Round  59, Train loss: 0.557, Test loss: 0.724, Test accuracy: 73.63
Round  60, Train loss: 0.790, Test loss: 0.706, Test accuracy: 74.51
Round  61, Train loss: 0.767, Test loss: 0.718, Test accuracy: 74.08
Round  62, Train loss: 0.758, Test loss: 0.713, Test accuracy: 74.31
Round  63, Train loss: 0.627, Test loss: 0.717, Test accuracy: 74.34
Round  64, Train loss: 0.782, Test loss: 0.708, Test accuracy: 74.25
Round  65, Train loss: 0.691, Test loss: 0.707, Test accuracy: 74.55
Round  66, Train loss: 0.641, Test loss: 0.692, Test accuracy: 75.25
Round  67, Train loss: 0.744, Test loss: 0.699, Test accuracy: 74.92
Round  68, Train loss: 0.598, Test loss: 0.701, Test accuracy: 75.00
Round  69, Train loss: 0.742, Test loss: 0.702, Test accuracy: 74.67
Round  70, Train loss: 0.493, Test loss: 0.689, Test accuracy: 74.92
Round  71, Train loss: 0.548, Test loss: 0.689, Test accuracy: 75.07
Round  72, Train loss: 0.574, Test loss: 0.703, Test accuracy: 74.67
Round  73, Train loss: 0.576, Test loss: 0.685, Test accuracy: 75.56
Round  74, Train loss: 0.474, Test loss: 0.697, Test accuracy: 74.58
Round  75, Train loss: 0.656, Test loss: 0.691, Test accuracy: 75.21
Round  76, Train loss: 0.450, Test loss: 0.692, Test accuracy: 75.33
Round  77, Train loss: 0.489, Test loss: 0.695, Test accuracy: 75.19
Round  78, Train loss: 0.434, Test loss: 0.689, Test accuracy: 75.42
Round  79, Train loss: 0.505, Test loss: 0.684, Test accuracy: 75.71
Round  80, Train loss: 0.630, Test loss: 0.684, Test accuracy: 75.58
Round  81, Train loss: 0.448, Test loss: 0.693, Test accuracy: 75.13
Round  82, Train loss: 0.696, Test loss: 0.685, Test accuracy: 75.46
Round  83, Train loss: 0.562, Test loss: 0.688, Test accuracy: 75.10
Round  84, Train loss: 0.519, Test loss: 0.690, Test accuracy: 75.17
Round  85, Train loss: 0.457, Test loss: 0.701, Test accuracy: 75.35
Round  86, Train loss: 0.539, Test loss: 0.695, Test accuracy: 75.13
Round  87, Train loss: 0.539, Test loss: 0.677, Test accuracy: 75.77
Round  88, Train loss: 0.797, Test loss: 0.683, Test accuracy: 75.75
Round  89, Train loss: 0.550, Test loss: 0.677, Test accuracy: 75.95
Round  90, Train loss: 0.423, Test loss: 0.679, Test accuracy: 75.77
Round  91, Train loss: 0.438, Test loss: 0.677, Test accuracy: 76.02
Round  92, Train loss: 0.548, Test loss: 0.685, Test accuracy: 75.81
Round  93, Train loss: 0.411, Test loss: 0.667, Test accuracy: 76.63
Round  94, Train loss: 0.520, Test loss: 0.680, Test accuracy: 75.55
Round  95, Train loss: 0.435, Test loss: 0.685, Test accuracy: 75.93
Round  96, Train loss: 0.453, Test loss: 0.684, Test accuracy: 75.87
Round  97, Train loss: 0.476, Test loss: 0.701, Test accuracy: 75.63
Round  98, Train loss: 0.574, Test loss: 0.692, Test accuracy: 75.77
Round  99, Train loss: 0.404, Test loss: 0.679, Test accuracy: 76.28
Final Round, Train loss: 0.297, Test loss: 0.678, Test accuracy: 76.44
Average accuracy final 10 rounds: 75.926
1703.2801005840302
[1.703709363937378, 3.171013593673706, 4.642340421676636, 6.1276280879974365, 7.5786566734313965, 9.034318447113037, 10.490002632141113, 11.956993341445923, 13.393393278121948, 14.796604633331299, 16.211673498153687, 17.649724006652832, 19.088510751724243, 20.517602920532227, 21.944910526275635, 23.372369050979614, 24.796340227127075, 26.130523920059204, 27.550822734832764, 28.971936464309692, 30.41460609436035, 33.100977420806885, 35.819323778152466, 38.509093284606934, 41.198699712753296, 43.87855529785156, 46.53853392601013, 49.22508120536804, 51.92411828041077, 54.84432768821716, 57.58333730697632, 60.33504319190979, 63.0065016746521, 65.72480869293213, 68.46071171760559, 71.1836199760437, 73.92128419876099, 76.62798595428467, 79.30171346664429, 82.05575370788574, 84.81132507324219, 87.50183010101318, 90.14309477806091, 92.81722831726074, 95.48267269134521, 98.1551661491394, 100.78919219970703, 103.43834662437439, 106.22464799880981, 108.92520475387573, 111.52120351791382, 114.09848594665527, 116.66642212867737, 119.24955654144287, 121.83274745941162, 124.45481467247009, 127.08075594902039, 129.61840724945068, 132.21411275863647, 134.81365489959717, 137.45858716964722, 140.09416031837463, 142.70624947547913, 145.3160400390625, 147.9375581741333, 150.5874798297882, 153.2076861858368, 155.82671737670898, 158.4054250717163, 161.0544137954712, 163.68237566947937, 166.2909483909607, 168.91090083122253, 171.49515652656555, 174.11831402778625, 176.74714732170105, 179.3621289730072, 181.9750943183899, 184.5951704978943, 187.29708909988403, 190.00262188911438, 192.76083850860596, 195.38810873031616, 198.08979558944702, 200.80722880363464, 203.50562167167664, 206.16439604759216, 208.85274744033813, 211.55116367340088, 214.23330163955688, 216.92095685005188, 219.62879300117493, 222.33008980751038, 224.94517254829407, 227.649085521698, 230.33650875091553, 233.0553936958313, 235.8196587562561, 239.10673904418945, 242.1209044456482, 244.56103038787842]
[23.35, 25.59, 35.7, 44.71, 48.15, 49.91, 53.3, 55.08, 54.77, 56.68, 58.1, 58.24, 59.15, 61.45, 62.39, 62.55, 63.48, 63.88, 64.89, 65.25, 66.19, 67.13, 67.1, 67.56, 67.94, 68.56, 68.15, 68.71, 68.92, 69.64, 69.93, 70.16, 70.97, 69.99, 70.59, 71.33, 71.21, 71.48, 71.64, 71.3, 71.71, 71.77, 71.59, 72.3, 72.0, 72.76, 72.72, 72.85, 73.32, 73.38, 73.84, 72.82, 73.33, 73.66, 73.98, 73.56, 74.48, 74.28, 74.46, 73.63, 74.51, 74.08, 74.31, 74.34, 74.25, 74.55, 75.25, 74.92, 75.0, 74.67, 74.92, 75.07, 74.67, 75.56, 74.58, 75.21, 75.33, 75.19, 75.42, 75.71, 75.58, 75.13, 75.46, 75.1, 75.17, 75.35, 75.13, 75.77, 75.75, 75.95, 75.77, 76.02, 75.81, 76.63, 75.55, 75.93, 75.87, 75.63, 75.77, 76.28, 76.44]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: none, level_n_system: 0.4 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 16, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 19, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 10, noise    level: 0.8000 
   Client 15, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.984, Test loss: 1.912, Test accuracy: 32.82
Round   1, Train loss: 1.628, Test loss: 1.500, Test accuracy: 40.11
Round   2, Train loss: 1.482, Test loss: 1.386, Test accuracy: 44.10
Round   3, Train loss: 1.401, Test loss: 1.286, Test accuracy: 47.96
Round   4, Train loss: 1.336, Test loss: 1.218, Test accuracy: 52.00
Round   5, Train loss: 1.283, Test loss: 1.169, Test accuracy: 53.68
Round   6, Train loss: 1.239, Test loss: 1.127, Test accuracy: 56.16
Round   7, Train loss: 1.208, Test loss: 1.096, Test accuracy: 57.61
Round   8, Train loss: 1.175, Test loss: 1.073, Test accuracy: 58.92
Round   9, Train loss: 1.150, Test loss: 1.039, Test accuracy: 60.62
Round  10, Train loss: 1.125, Test loss: 1.029, Test accuracy: 61.36
Round  11, Train loss: 1.110, Test loss: 1.005, Test accuracy: 62.20
Round  12, Train loss: 1.091, Test loss: 0.988, Test accuracy: 62.90
Round  13, Train loss: 1.072, Test loss: 0.970, Test accuracy: 63.86
Round  14, Train loss: 1.051, Test loss: 0.957, Test accuracy: 64.56
Round  15, Train loss: 1.038, Test loss: 0.938, Test accuracy: 65.42
Round  16, Train loss: 1.022, Test loss: 0.928, Test accuracy: 65.59
Round  17, Train loss: 1.006, Test loss: 0.924, Test accuracy: 66.47
Round  18, Train loss: 0.994, Test loss: 0.904, Test accuracy: 66.46
Round  19, Train loss: 0.977, Test loss: 0.891, Test accuracy: 67.16
Round  20, Train loss: 0.984, Test loss: 0.890, Test accuracy: 67.59
Round  21, Train loss: 0.966, Test loss: 0.883, Test accuracy: 67.45
Round  22, Train loss: 1.005, Test loss: 0.873, Test accuracy: 67.23
Round  23, Train loss: 0.937, Test loss: 0.864, Test accuracy: 68.55
Round  24, Train loss: 0.936, Test loss: 0.857, Test accuracy: 68.14
Round  25, Train loss: 0.954, Test loss: 0.861, Test accuracy: 68.27
Round  26, Train loss: 0.844, Test loss: 0.836, Test accuracy: 68.81
Round  27, Train loss: 0.947, Test loss: 0.834, Test accuracy: 69.52
Round  28, Train loss: 0.930, Test loss: 0.840, Test accuracy: 69.67
Round  29, Train loss: 0.833, Test loss: 0.833, Test accuracy: 69.60
Round  30, Train loss: 0.801, Test loss: 0.828, Test accuracy: 69.90
Round  31, Train loss: 0.812, Test loss: 0.812, Test accuracy: 70.23
Round  32, Train loss: 0.835, Test loss: 0.805, Test accuracy: 71.00
Round  33, Train loss: 0.792, Test loss: 0.797, Test accuracy: 71.33
Round  34, Train loss: 0.708, Test loss: 0.799, Test accuracy: 71.33
Round  35, Train loss: 0.875, Test loss: 0.793, Test accuracy: 71.58
Round  36, Train loss: 0.752, Test loss: 0.789, Test accuracy: 71.41
Round  37, Train loss: 0.767, Test loss: 0.782, Test accuracy: 71.86
Round  38, Train loss: 0.867, Test loss: 0.776, Test accuracy: 71.72
Round  39, Train loss: 0.664, Test loss: 0.779, Test accuracy: 71.87
Round  40, Train loss: 0.717, Test loss: 0.782, Test accuracy: 71.48
Round  41, Train loss: 0.770, Test loss: 0.772, Test accuracy: 71.82
Round  42, Train loss: 0.775, Test loss: 0.766, Test accuracy: 72.86
Round  43, Train loss: 0.785, Test loss: 0.766, Test accuracy: 72.06
Round  44, Train loss: 0.734, Test loss: 0.758, Test accuracy: 72.45
Round  45, Train loss: 0.796, Test loss: 0.767, Test accuracy: 72.50
Round  46, Train loss: 0.843, Test loss: 0.759, Test accuracy: 72.62
Round  47, Train loss: 0.690, Test loss: 0.753, Test accuracy: 72.53
Round  48, Train loss: 0.706, Test loss: 0.749, Test accuracy: 72.99
Round  49, Train loss: 0.750, Test loss: 0.763, Test accuracy: 72.00
Round  50, Train loss: 0.766, Test loss: 0.752, Test accuracy: 73.19
Round  51, Train loss: 0.661, Test loss: 0.747, Test accuracy: 73.24
Round  52, Train loss: 0.749, Test loss: 0.753, Test accuracy: 73.10
Round  53, Train loss: 0.762, Test loss: 0.743, Test accuracy: 73.14
Round  54, Train loss: 0.731, Test loss: 0.743, Test accuracy: 73.36
Round  55, Train loss: 0.678, Test loss: 0.740, Test accuracy: 73.81
Round  56, Train loss: 0.628, Test loss: 0.739, Test accuracy: 73.73
Round  57, Train loss: 0.811, Test loss: 0.737, Test accuracy: 73.62
Round  58, Train loss: 0.673, Test loss: 0.738, Test accuracy: 73.31
Round  59, Train loss: 0.664, Test loss: 0.730, Test accuracy: 73.95
Round  60, Train loss: 0.746, Test loss: 0.723, Test accuracy: 73.66
Round  61, Train loss: 0.686, Test loss: 0.737, Test accuracy: 73.12
Round  62, Train loss: 0.722, Test loss: 0.738, Test accuracy: 73.31
Round  63, Train loss: 0.644, Test loss: 0.733, Test accuracy: 73.19
Round  64, Train loss: 0.698, Test loss: 0.726, Test accuracy: 73.50
Round  65, Train loss: 0.605, Test loss: 0.737, Test accuracy: 73.17
Round  66, Train loss: 0.635, Test loss: 0.721, Test accuracy: 74.39
Round  67, Train loss: 0.600, Test loss: 0.712, Test accuracy: 74.50
Round  68, Train loss: 0.680, Test loss: 0.727, Test accuracy: 73.95
Round  69, Train loss: 0.661, Test loss: 0.732, Test accuracy: 73.30
Round  70, Train loss: 0.606, Test loss: 0.728, Test accuracy: 73.51
Round  71, Train loss: 0.658, Test loss: 0.723, Test accuracy: 73.92
Round  72, Train loss: 0.599, Test loss: 0.736, Test accuracy: 72.94
Round  73, Train loss: 0.528, Test loss: 0.725, Test accuracy: 73.36
Round  74, Train loss: 0.580, Test loss: 0.718, Test accuracy: 74.11
Round  75, Train loss: 0.602, Test loss: 0.726, Test accuracy: 73.73
Round  76, Train loss: 0.508, Test loss: 0.733, Test accuracy: 73.66
Round  77, Train loss: 0.570, Test loss: 0.710, Test accuracy: 74.00
Round  78, Train loss: 0.510, Test loss: 0.710, Test accuracy: 73.87
Round  79, Train loss: 0.551, Test loss: 0.715, Test accuracy: 74.48
Round  80, Train loss: 0.421, Test loss: 0.697, Test accuracy: 74.76
Round  81, Train loss: 0.403, Test loss: 0.699, Test accuracy: 74.50
Round  82, Train loss: 0.389, Test loss: 0.705, Test accuracy: 74.32
Round  83, Train loss: 0.376, Test loss: 0.702, Test accuracy: 74.73
Round  84, Train loss: 0.367, Test loss: 0.698, Test accuracy: 74.87
Round  85, Train loss: 0.366, Test loss: 0.700, Test accuracy: 74.70
Round  86, Train loss: 0.359, Test loss: 0.701, Test accuracy: 74.79
Round  87, Train loss: 0.346, Test loss: 0.706, Test accuracy: 74.69
Round  88, Train loss: 0.346, Test loss: 0.701, Test accuracy: 75.03
Round  89, Train loss: 0.334, Test loss: 0.705, Test accuracy: 74.90
Round  90, Train loss: 0.327, Test loss: 0.702, Test accuracy: 75.41
Round  91, Train loss: 0.324, Test loss: 0.705, Test accuracy: 75.11
Round  92, Train loss: 0.317, Test loss: 0.706, Test accuracy: 75.02
Round  93, Train loss: 0.314, Test loss: 0.718, Test accuracy: 74.33
Round  94, Train loss: 0.308, Test loss: 0.714, Test accuracy: 74.60
Round  95, Train loss: 0.303, Test loss: 0.709, Test accuracy: 75.07
Round  96, Train loss: 0.293, Test loss: 0.706, Test accuracy: 74.85
Round  97, Train loss: 0.288, Test loss: 0.712, Test accuracy: 74.83
Round  98, Train loss: 0.290, Test loss: 0.732, Test accuracy: 74.09
Round  99, Train loss: 0.281, Test loss: 0.712, Test accuracy: 74.72
Final Round, Train loss: 0.211, Test loss: 0.715, Test accuracy: 74.70
Average accuracy final 10 rounds: 74.80299999999998
1683.5622005462646
[1.774796485900879, 3.2039783000946045, 4.6287102699279785, 6.098374128341675, 7.537091255187988, 8.966326236724854, 10.408183336257935, 11.839951515197754, 13.289143323898315, 14.71508240699768, 16.15105152130127, 17.613226890563965, 19.060481548309326, 20.534003973007202, 21.97305941581726, 23.4116153717041, 24.847553968429565, 26.290600776672363, 27.73635172843933, 29.309911012649536, 30.80884575843811, 32.314682960510254, 33.82914161682129, 35.35082674026489, 36.83958911895752, 38.3669273853302, 39.91734600067139, 41.47044253349304, 43.07635188102722, 44.61863923072815, 46.16126108169556, 47.711233139038086, 49.252219438552856, 50.77427649497986, 52.334205627441406, 53.85913705825806, 55.42932081222534, 56.96862840652466, 58.516754150390625, 60.131338119506836, 61.705931425094604, 63.239320278167725, 64.86281371116638, 66.481440782547, 68.23132801055908, 69.80467414855957, 71.33195066452026, 72.89132809638977, 74.47287130355835, 76.06234383583069, 77.68813705444336, 79.26328778266907, 80.71814322471619, 82.17030072212219, 83.59503984451294, 84.92892932891846, 86.37865495681763, 87.83411049842834, 89.29135465621948, 90.73657846450806, 92.17759037017822, 93.63541269302368, 95.079514503479, 96.5125343799591, 97.96231698989868, 99.4110460281372, 100.85609102249146, 102.30413818359375, 103.7450578212738, 105.19822001457214, 106.64489722251892, 108.09264039993286, 109.55382037162781, 111.01380658149719, 112.46529483795166, 113.91251945495605, 115.36386466026306, 116.81119060516357, 118.24588584899902, 119.68861269950867, 121.13364958763123, 122.59670853614807, 124.0671637058258, 125.54366278648376, 127.01416206359863, 128.47276210784912, 129.94302940368652, 131.4041748046875, 132.86802005767822, 134.3380675315857, 135.8072226047516, 137.27303743362427, 138.7399935722351, 140.20213270187378, 141.66232442855835, 143.12467575073242, 144.59231328964233, 146.0554883480072, 147.5210497379303, 148.98718309402466, 151.17855525016785]
[32.82, 40.11, 44.1, 47.96, 52.0, 53.68, 56.16, 57.61, 58.92, 60.62, 61.36, 62.2, 62.9, 63.86, 64.56, 65.42, 65.59, 66.47, 66.46, 67.16, 67.59, 67.45, 67.23, 68.55, 68.14, 68.27, 68.81, 69.52, 69.67, 69.6, 69.9, 70.23, 71.0, 71.33, 71.33, 71.58, 71.41, 71.86, 71.72, 71.87, 71.48, 71.82, 72.86, 72.06, 72.45, 72.5, 72.62, 72.53, 72.99, 72.0, 73.19, 73.24, 73.1, 73.14, 73.36, 73.81, 73.73, 73.62, 73.31, 73.95, 73.66, 73.12, 73.31, 73.19, 73.5, 73.17, 74.39, 74.5, 73.95, 73.3, 73.51, 73.92, 72.94, 73.36, 74.11, 73.73, 73.66, 74.0, 73.87, 74.48, 74.76, 74.5, 74.32, 74.73, 74.87, 74.7, 74.79, 74.69, 75.03, 74.9, 75.41, 75.11, 75.02, 74.33, 74.6, 75.07, 74.85, 74.83, 74.09, 74.72, 74.7]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.4 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 17, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
   Client 13, noise    level: 0.8000 
   Client 18, noise    level: 0.8000 
   Client 14, noise    level: 0.8000 
   Client 11, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.959, Test loss: 1.850, Test accuracy: 30.60
Round   1, Train loss: 1.576, Test loss: 1.471, Test accuracy: 41.63
Round   2, Train loss: 1.431, Test loss: 1.356, Test accuracy: 43.90
Round   3, Train loss: 1.353, Test loss: 1.265, Test accuracy: 48.53
Round   4, Train loss: 1.290, Test loss: 1.197, Test accuracy: 52.39
Round   5, Train loss: 1.238, Test loss: 1.158, Test accuracy: 54.16
Round   6, Train loss: 1.197, Test loss: 1.114, Test accuracy: 56.66
Round   7, Train loss: 1.161, Test loss: 1.079, Test accuracy: 58.49
Round   8, Train loss: 1.135, Test loss: 1.058, Test accuracy: 59.23
Round   9, Train loss: 1.114, Test loss: 1.032, Test accuracy: 60.20
Round  10, Train loss: 1.094, Test loss: 1.007, Test accuracy: 61.14
Round  11, Train loss: 1.074, Test loss: 0.991, Test accuracy: 61.93
Round  12, Train loss: 1.055, Test loss: 0.980, Test accuracy: 62.74
Round  13, Train loss: 1.038, Test loss: 0.963, Test accuracy: 63.41
Round  14, Train loss: 1.021, Test loss: 0.945, Test accuracy: 64.05
Round  15, Train loss: 1.003, Test loss: 0.928, Test accuracy: 64.52
Round  16, Train loss: 0.990, Test loss: 0.929, Test accuracy: 65.18
Round  17, Train loss: 0.975, Test loss: 0.910, Test accuracy: 65.64
Round  18, Train loss: 0.961, Test loss: 0.906, Test accuracy: 65.91
Round  19, Train loss: 0.950, Test loss: 0.893, Test accuracy: 66.77
Round  20, Train loss: 0.943, Test loss: 0.902, Test accuracy: 66.29
Round  21, Train loss: 0.959, Test loss: 0.901, Test accuracy: 66.34
Round  22, Train loss: 0.940, Test loss: 0.893, Test accuracy: 66.41
Round  23, Train loss: 0.872, Test loss: 0.882, Test accuracy: 66.84
Round  24, Train loss: 0.880, Test loss: 0.877, Test accuracy: 67.16
Round  25, Train loss: 0.863, Test loss: 0.883, Test accuracy: 66.80
Round  26, Train loss: 0.885, Test loss: 0.853, Test accuracy: 67.54
Round  27, Train loss: 0.952, Test loss: 0.846, Test accuracy: 68.49
Round  28, Train loss: 0.829, Test loss: 0.843, Test accuracy: 68.80
Round  29, Train loss: 0.895, Test loss: 0.825, Test accuracy: 69.40
Round  30, Train loss: 0.792, Test loss: 0.835, Test accuracy: 68.92
Round  31, Train loss: 0.761, Test loss: 0.817, Test accuracy: 69.23
Round  32, Train loss: 0.845, Test loss: 0.819, Test accuracy: 69.79
Round  33, Train loss: 0.862, Test loss: 0.810, Test accuracy: 69.79
Round  34, Train loss: 0.790, Test loss: 0.805, Test accuracy: 69.67
Round  35, Train loss: 0.899, Test loss: 0.804, Test accuracy: 70.19
Round  36, Train loss: 0.850, Test loss: 0.811, Test accuracy: 69.79
Round  37, Train loss: 0.750, Test loss: 0.800, Test accuracy: 70.56
Round  38, Train loss: 0.740, Test loss: 0.783, Test accuracy: 70.87
Round  39, Train loss: 0.741, Test loss: 0.796, Test accuracy: 70.50
Round  40, Train loss: 0.791, Test loss: 0.783, Test accuracy: 71.47
Round  41, Train loss: 0.799, Test loss: 0.784, Test accuracy: 71.33
Round  42, Train loss: 0.738, Test loss: 0.784, Test accuracy: 71.40
Round  43, Train loss: 0.643, Test loss: 0.787, Test accuracy: 71.23
Round  44, Train loss: 0.776, Test loss: 0.771, Test accuracy: 71.35
Round  45, Train loss: 0.759, Test loss: 0.766, Test accuracy: 72.10
Round  46, Train loss: 0.829, Test loss: 0.758, Test accuracy: 72.44
Round  47, Train loss: 0.711, Test loss: 0.754, Test accuracy: 72.27
Round  48, Train loss: 0.708, Test loss: 0.759, Test accuracy: 72.14
Round  49, Train loss: 0.714, Test loss: 0.759, Test accuracy: 72.06
Round  50, Train loss: 0.751, Test loss: 0.762, Test accuracy: 72.25
Round  51, Train loss: 0.696, Test loss: 0.753, Test accuracy: 72.56
Round  52, Train loss: 0.720, Test loss: 0.756, Test accuracy: 72.48
Round  53, Train loss: 0.653, Test loss: 0.754, Test accuracy: 72.53
Round  54, Train loss: 0.673, Test loss: 0.766, Test accuracy: 71.88
Round  55, Train loss: 0.649, Test loss: 0.757, Test accuracy: 72.08
Round  56, Train loss: 0.751, Test loss: 0.745, Test accuracy: 72.79
Round  57, Train loss: 0.714, Test loss: 0.744, Test accuracy: 72.84
Round  58, Train loss: 0.614, Test loss: 0.739, Test accuracy: 73.19
Round  59, Train loss: 0.642, Test loss: 0.751, Test accuracy: 72.42
Round  60, Train loss: 0.681, Test loss: 0.733, Test accuracy: 73.08
Round  61, Train loss: 0.719, Test loss: 0.742, Test accuracy: 73.15
Round  62, Train loss: 0.747, Test loss: 0.747, Test accuracy: 72.71
Round  63, Train loss: 0.664, Test loss: 0.732, Test accuracy: 73.26
Round  64, Train loss: 0.699, Test loss: 0.735, Test accuracy: 73.45
Round  65, Train loss: 0.592, Test loss: 0.747, Test accuracy: 72.82
Round  66, Train loss: 0.620, Test loss: 0.735, Test accuracy: 73.27
Round  67, Train loss: 0.603, Test loss: 0.731, Test accuracy: 73.36
Round  68, Train loss: 0.692, Test loss: 0.724, Test accuracy: 73.53
Round  69, Train loss: 0.627, Test loss: 0.726, Test accuracy: 73.74
Round  70, Train loss: 0.587, Test loss: 0.721, Test accuracy: 73.99
Round  71, Train loss: 0.599, Test loss: 0.721, Test accuracy: 73.72
Round  72, Train loss: 0.595, Test loss: 0.725, Test accuracy: 73.57
Round  73, Train loss: 0.674, Test loss: 0.724, Test accuracy: 73.59
Round  74, Train loss: 0.575, Test loss: 0.719, Test accuracy: 73.97
Round  75, Train loss: 0.569, Test loss: 0.720, Test accuracy: 73.99
Round  76, Train loss: 0.536, Test loss: 0.731, Test accuracy: 73.85
Round  77, Train loss: 0.587, Test loss: 0.727, Test accuracy: 73.89
Round  78, Train loss: 0.640, Test loss: 0.733, Test accuracy: 73.58
Round  79, Train loss: 0.542, Test loss: 0.725, Test accuracy: 73.53
Round  80, Train loss: 0.459, Test loss: 0.721, Test accuracy: 73.72
Round  81, Train loss: 0.439, Test loss: 0.715, Test accuracy: 73.99
Round  82, Train loss: 0.421, Test loss: 0.710, Test accuracy: 74.19
Round  83, Train loss: 0.406, Test loss: 0.716, Test accuracy: 73.94
Round  84, Train loss: 0.397, Test loss: 0.717, Test accuracy: 74.09
Round  85, Train loss: 0.390, Test loss: 0.718, Test accuracy: 73.83
Round  86, Train loss: 0.370, Test loss: 0.721, Test accuracy: 74.13
Round  87, Train loss: 0.369, Test loss: 0.727, Test accuracy: 73.86
Round  88, Train loss: 0.361, Test loss: 0.728, Test accuracy: 74.06
Round  89, Train loss: 0.350, Test loss: 0.730, Test accuracy: 73.97
Round  90, Train loss: 0.354, Test loss: 0.726, Test accuracy: 74.25
Round  91, Train loss: 0.344, Test loss: 0.730, Test accuracy: 73.75
Round  92, Train loss: 0.326, Test loss: 0.729, Test accuracy: 74.02
Round  93, Train loss: 0.316, Test loss: 0.737, Test accuracy: 73.92
Round  94, Train loss: 0.321, Test loss: 0.740, Test accuracy: 73.97
Round  95, Train loss: 0.311, Test loss: 0.734, Test accuracy: 74.18
Round  96, Train loss: 0.309, Test loss: 0.741, Test accuracy: 74.08
Round  97, Train loss: 0.298, Test loss: 0.739, Test accuracy: 74.18
Round  98, Train loss: 0.298, Test loss: 0.742, Test accuracy: 74.02
Round  99, Train loss: 0.296, Test loss: 0.745, Test accuracy: 73.81
Final Round, Train loss: 0.222, Test loss: 0.749, Test accuracy: 73.72
Average accuracy final 10 rounds: 74.018
2256.7612459659576
[1.7036314010620117, 3.0982401371002197, 4.497894287109375, 5.9002299308776855, 7.300092697143555, 8.685604333877563, 10.081262111663818, 11.47226071357727, 12.725643873214722, 13.988614320755005, 15.259570121765137, 16.51592493057251, 17.766870498657227, 19.022451400756836, 20.27907943725586, 21.53362226486206, 22.792760372161865, 24.03803563117981, 25.29247283935547, 26.534197092056274, 27.78839087486267, 30.504355907440186, 33.18290638923645, 35.85113215446472, 38.52506756782532, 41.2270290851593, 43.973636865615845, 46.66331458091736, 49.405157804489136, 52.04698729515076, 54.68806791305542, 57.388195753097534, 59.991084814071655, 62.68781924247742, 65.33922028541565, 68.16990351676941, 70.93685960769653, 73.70786213874817, 76.5577404499054, 79.26336598396301, 82.081538438797, 84.91716957092285, 87.67257761955261, 90.4629054069519, 93.24338269233704, 96.05841398239136, 98.80466818809509, 101.66533327102661, 104.4702513217926, 107.30894327163696, 110.16865158081055, 112.92202734947205, 115.74370694160461, 118.49247002601624, 121.26468396186829, 124.02878260612488, 126.79036927223206, 129.53804326057434, 132.30916786193848, 135.08563017845154, 137.8600299358368, 140.71341228485107, 143.54095768928528, 146.3093090057373, 149.16449332237244, 151.86406564712524, 154.62976503372192, 157.43318152427673, 160.24916982650757, 163.11769461631775, 165.87016820907593, 168.71402668952942, 171.43007397651672, 174.21011185646057, 177.03995490074158, 179.8110692501068, 182.49991464614868, 185.16300702095032, 187.80497241020203, 190.5216839313507, 193.34596276283264, 196.17045617103577, 198.88251066207886, 201.60283255577087, 204.33119368553162, 206.9839472770691, 209.71059656143188, 212.39125752449036, 215.0793685913086, 217.76072669029236, 220.43639302253723, 223.0930416584015, 225.77532124519348, 228.47480940818787, 231.16064620018005, 233.91611742973328, 236.62514185905457, 239.38409113883972, 242.11844968795776, 244.8225417137146, 246.82248520851135]
[30.6, 41.63, 43.9, 48.53, 52.39, 54.16, 56.66, 58.49, 59.23, 60.2, 61.14, 61.93, 62.74, 63.41, 64.05, 64.52, 65.18, 65.64, 65.91, 66.77, 66.29, 66.34, 66.41, 66.84, 67.16, 66.8, 67.54, 68.49, 68.8, 69.4, 68.92, 69.23, 69.79, 69.79, 69.67, 70.19, 69.79, 70.56, 70.87, 70.5, 71.47, 71.33, 71.4, 71.23, 71.35, 72.1, 72.44, 72.27, 72.14, 72.06, 72.25, 72.56, 72.48, 72.53, 71.88, 72.08, 72.79, 72.84, 73.19, 72.42, 73.08, 73.15, 72.71, 73.26, 73.45, 72.82, 73.27, 73.36, 73.53, 73.74, 73.99, 73.72, 73.57, 73.59, 73.97, 73.99, 73.85, 73.89, 73.58, 73.53, 73.72, 73.99, 74.19, 73.94, 74.09, 73.83, 74.13, 73.86, 74.06, 73.97, 74.25, 73.75, 74.02, 73.92, 73.97, 74.18, 74.08, 74.18, 74.02, 73.81, 73.72]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.6 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 17, noise    level: 0.4000 
   Client 13, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 10, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 19, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 12, noise    level: 0.4000 
   Client 18, noise    level: 0.4000 
   Client 16, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.714, Test loss: 2.029, Test accuracy: 21.09
Round   0, Global train loss: 1.714, Global test loss: 2.233, Global test accuracy: 16.64
Round   1, Train loss: 1.573, Test loss: 1.806, Test accuracy: 29.67
Round   1, Global train loss: 1.573, Global test loss: 2.195, Global test accuracy: 21.37
Round   2, Train loss: 1.522, Test loss: 1.554, Test accuracy: 36.14
Round   2, Global train loss: 1.522, Global test loss: 1.980, Global test accuracy: 24.74
Round   3, Train loss: 1.326, Test loss: 1.528, Test accuracy: 37.52
Round   3, Global train loss: 1.326, Global test loss: 2.123, Global test accuracy: 19.71
Round   4, Train loss: 1.458, Test loss: 1.409, Test accuracy: 42.89
Round   4, Global train loss: 1.458, Global test loss: 2.183, Global test accuracy: 19.92
Round   5, Train loss: 1.402, Test loss: 1.410, Test accuracy: 42.52
Round   5, Global train loss: 1.402, Global test loss: 2.137, Global test accuracy: 20.88
Round   6, Train loss: 1.418, Test loss: 1.391, Test accuracy: 43.78
Round   6, Global train loss: 1.418, Global test loss: 2.112, Global test accuracy: 21.03
Round   7, Train loss: 1.285, Test loss: 1.341, Test accuracy: 46.40
Round   7, Global train loss: 1.285, Global test loss: 1.998, Global test accuracy: 24.45
Round   8, Train loss: 1.459, Test loss: 1.300, Test accuracy: 47.72
Round   8, Global train loss: 1.459, Global test loss: 2.074, Global test accuracy: 25.13
Round   9, Train loss: 1.138, Test loss: 1.295, Test accuracy: 48.18
Round   9, Global train loss: 1.138, Global test loss: 2.007, Global test accuracy: 24.41
Round  10, Train loss: 1.400, Test loss: 1.292, Test accuracy: 48.16
Round  10, Global train loss: 1.400, Global test loss: 2.251, Global test accuracy: 21.33
Round  11, Train loss: 1.293, Test loss: 1.271, Test accuracy: 49.34
Round  11, Global train loss: 1.293, Global test loss: 2.086, Global test accuracy: 23.78
Round  12, Train loss: 1.280, Test loss: 1.258, Test accuracy: 49.75
Round  12, Global train loss: 1.280, Global test loss: 2.086, Global test accuracy: 22.38
Round  13, Train loss: 1.226, Test loss: 1.254, Test accuracy: 50.01
Round  13, Global train loss: 1.226, Global test loss: 1.959, Global test accuracy: 25.51
Round  14, Train loss: 1.201, Test loss: 1.252, Test accuracy: 50.17
Round  14, Global train loss: 1.201, Global test loss: 1.912, Global test accuracy: 30.49
Round  15, Train loss: 1.426, Test loss: 1.241, Test accuracy: 50.57
Round  15, Global train loss: 1.426, Global test loss: 2.072, Global test accuracy: 25.04
Round  16, Train loss: 1.255, Test loss: 1.231, Test accuracy: 51.32
Round  16, Global train loss: 1.255, Global test loss: 2.039, Global test accuracy: 23.83
Round  17, Train loss: 1.265, Test loss: 1.230, Test accuracy: 51.52
Round  17, Global train loss: 1.265, Global test loss: 2.033, Global test accuracy: 30.03
Round  18, Train loss: 1.247, Test loss: 1.239, Test accuracy: 51.39
Round  18, Global train loss: 1.247, Global test loss: 2.122, Global test accuracy: 24.64
Round  19, Train loss: 1.045, Test loss: 1.258, Test accuracy: 51.03
Round  19, Global train loss: 1.045, Global test loss: 1.921, Global test accuracy: 32.04
Round  20, Train loss: 1.098, Test loss: 1.259, Test accuracy: 51.44
Round  20, Global train loss: 1.098, Global test loss: 1.933, Global test accuracy: 28.54
Round  21, Train loss: 1.012, Test loss: 1.256, Test accuracy: 52.03
Round  21, Global train loss: 1.012, Global test loss: 2.002, Global test accuracy: 26.50
Round  22, Train loss: 1.190, Test loss: 1.237, Test accuracy: 52.39
Round  22, Global train loss: 1.190, Global test loss: 2.036, Global test accuracy: 23.87
Round  23, Train loss: 1.159, Test loss: 1.252, Test accuracy: 51.99
Round  23, Global train loss: 1.159, Global test loss: 1.940, Global test accuracy: 32.08
Round  24, Train loss: 1.029, Test loss: 1.265, Test accuracy: 52.00
Round  24, Global train loss: 1.029, Global test loss: 1.994, Global test accuracy: 31.41
Round  25, Train loss: 1.102, Test loss: 1.268, Test accuracy: 52.30
Round  25, Global train loss: 1.102, Global test loss: 1.954, Global test accuracy: 32.32
Round  26, Train loss: 0.873, Test loss: 1.295, Test accuracy: 52.21
Round  26, Global train loss: 0.873, Global test loss: 2.048, Global test accuracy: 24.55
Round  27, Train loss: 0.984, Test loss: 1.311, Test accuracy: 51.43
Round  27, Global train loss: 0.984, Global test loss: 1.989, Global test accuracy: 27.17
Round  28, Train loss: 1.099, Test loss: 1.309, Test accuracy: 51.52
Round  28, Global train loss: 1.099, Global test loss: 1.980, Global test accuracy: 29.20
Round  29, Train loss: 0.990, Test loss: 1.306, Test accuracy: 51.31
Round  29, Global train loss: 0.990, Global test loss: 2.005, Global test accuracy: 28.64
Round  30, Train loss: 1.037, Test loss: 1.309, Test accuracy: 51.32
Round  30, Global train loss: 1.037, Global test loss: 1.973, Global test accuracy: 24.12
Round  31, Train loss: 1.037, Test loss: 1.320, Test accuracy: 51.54
Round  31, Global train loss: 1.037, Global test loss: 2.022, Global test accuracy: 31.78
Round  32, Train loss: 1.149, Test loss: 1.341, Test accuracy: 51.40
Round  32, Global train loss: 1.149, Global test loss: 2.181, Global test accuracy: 19.03
Round  33, Train loss: 1.033, Test loss: 1.345, Test accuracy: 51.15
Round  33, Global train loss: 1.033, Global test loss: 1.983, Global test accuracy: 30.80
Round  34, Train loss: 0.994, Test loss: 1.361, Test accuracy: 50.94
Round  34, Global train loss: 0.994, Global test loss: 1.923, Global test accuracy: 36.22
Round  35, Train loss: 0.813, Test loss: 1.373, Test accuracy: 51.24
Round  35, Global train loss: 0.813, Global test loss: 1.937, Global test accuracy: 30.02
Round  36, Train loss: 0.797, Test loss: 1.373, Test accuracy: 50.81
Round  36, Global train loss: 0.797, Global test loss: 2.089, Global test accuracy: 23.79
Round  37, Train loss: 0.714, Test loss: 1.399, Test accuracy: 50.37
Round  37, Global train loss: 0.714, Global test loss: 1.918, Global test accuracy: 31.59
Round  38, Train loss: 0.761, Test loss: 1.427, Test accuracy: 50.07
Round  38, Global train loss: 0.761, Global test loss: 1.955, Global test accuracy: 28.89
Round  39, Train loss: 0.534, Test loss: 1.462, Test accuracy: 49.93
Round  39, Global train loss: 0.534, Global test loss: 1.852, Global test accuracy: 33.25
Round  40, Train loss: 0.645, Test loss: 1.473, Test accuracy: 50.43
Round  40, Global train loss: 0.645, Global test loss: 1.946, Global test accuracy: 29.20
Round  41, Train loss: 0.721, Test loss: 1.519, Test accuracy: 49.98
Round  41, Global train loss: 0.721, Global test loss: 2.012, Global test accuracy: 25.45
Round  42, Train loss: 0.792, Test loss: 1.530, Test accuracy: 49.86
Round  42, Global train loss: 0.792, Global test loss: 1.983, Global test accuracy: 26.49
Round  43, Train loss: 0.696, Test loss: 1.540, Test accuracy: 49.38
Round  43, Global train loss: 0.696, Global test loss: 1.864, Global test accuracy: 33.29
Round  44, Train loss: 0.612, Test loss: 1.522, Test accuracy: 49.52
Round  44, Global train loss: 0.612, Global test loss: 2.154, Global test accuracy: 21.89
Round  45, Train loss: 0.791, Test loss: 1.553, Test accuracy: 49.09
Round  45, Global train loss: 0.791, Global test loss: 2.001, Global test accuracy: 29.45
Round  46, Train loss: 0.709, Test loss: 1.604, Test accuracy: 48.79
Round  46, Global train loss: 0.709, Global test loss: 1.826, Global test accuracy: 32.64
Round  47, Train loss: 0.636, Test loss: 1.637, Test accuracy: 49.28
Round  47, Global train loss: 0.636, Global test loss: 1.893, Global test accuracy: 30.11
Round  48, Train loss: 0.484, Test loss: 1.675, Test accuracy: 49.32
Round  48, Global train loss: 0.484, Global test loss: 1.965, Global test accuracy: 29.48
Round  49, Train loss: 0.698, Test loss: 1.665, Test accuracy: 49.66
Round  49, Global train loss: 0.698, Global test loss: 1.999, Global test accuracy: 29.91
Round  50, Train loss: 0.769, Test loss: 1.685, Test accuracy: 49.69
Round  50, Global train loss: 0.769, Global test loss: 2.060, Global test accuracy: 27.64
Round  51, Train loss: 0.568, Test loss: 1.701, Test accuracy: 49.68
Round  51, Global train loss: 0.568, Global test loss: 1.948, Global test accuracy: 32.55
Round  52, Train loss: 0.594, Test loss: 1.702, Test accuracy: 49.81
Round  52, Global train loss: 0.594, Global test loss: 2.031, Global test accuracy: 23.76
Round  53, Train loss: 0.540, Test loss: 1.722, Test accuracy: 49.65
Round  53, Global train loss: 0.540, Global test loss: 1.902, Global test accuracy: 28.91
Round  54, Train loss: 0.593, Test loss: 1.754, Test accuracy: 49.68
Round  54, Global train loss: 0.593, Global test loss: 2.043, Global test accuracy: 24.74
Round  55, Train loss: 0.567, Test loss: 1.787, Test accuracy: 50.02
Round  55, Global train loss: 0.567, Global test loss: 1.937, Global test accuracy: 34.15
Round  56, Train loss: 0.398, Test loss: 1.851, Test accuracy: 50.09
Round  56, Global train loss: 0.398, Global test loss: 1.915, Global test accuracy: 29.77
Round  57, Train loss: 0.528, Test loss: 1.896, Test accuracy: 49.37
Round  57, Global train loss: 0.528, Global test loss: 2.044, Global test accuracy: 25.36
Round  58, Train loss: 0.626, Test loss: 1.923, Test accuracy: 49.42
Round  58, Global train loss: 0.626, Global test loss: 2.025, Global test accuracy: 29.68
Round  59, Train loss: 0.526, Test loss: 1.971, Test accuracy: 49.48
Round  59, Global train loss: 0.526, Global test loss: 1.883, Global test accuracy: 32.65
Round  60, Train loss: 0.403, Test loss: 1.983, Test accuracy: 49.18
Round  60, Global train loss: 0.403, Global test loss: 2.017, Global test accuracy: 28.67
Round  61, Train loss: 0.362, Test loss: 1.988, Test accuracy: 49.42
Round  61, Global train loss: 0.362, Global test loss: 1.899, Global test accuracy: 28.32
Round  62, Train loss: 0.383, Test loss: 2.046, Test accuracy: 48.50
Round  62, Global train loss: 0.383, Global test loss: 2.063, Global test accuracy: 25.82
Round  63, Train loss: 0.528, Test loss: 2.056, Test accuracy: 48.49
Round  63, Global train loss: 0.528, Global test loss: 2.079, Global test accuracy: 25.10
Round  64, Train loss: 0.292, Test loss: 2.081, Test accuracy: 48.54
Round  64, Global train loss: 0.292, Global test loss: 1.918, Global test accuracy: 35.36
Round  65, Train loss: 0.335, Test loss: 2.115, Test accuracy: 48.66
Round  65, Global train loss: 0.335, Global test loss: 1.919, Global test accuracy: 31.38
Round  66, Train loss: 0.409, Test loss: 2.177, Test accuracy: 48.93
Round  66, Global train loss: 0.409, Global test loss: 2.100, Global test accuracy: 24.64
Round  67, Train loss: 0.309, Test loss: 2.197, Test accuracy: 48.61
Round  67, Global train loss: 0.309, Global test loss: 2.066, Global test accuracy: 24.58
Round  68, Train loss: 0.482, Test loss: 2.194, Test accuracy: 48.41
Round  68, Global train loss: 0.482, Global test loss: 2.178, Global test accuracy: 23.57
Round  69, Train loss: 0.409, Test loss: 2.260, Test accuracy: 48.06
Round  69, Global train loss: 0.409, Global test loss: 2.264, Global test accuracy: 22.00
Round  70, Train loss: 0.426, Test loss: 2.295, Test accuracy: 48.19
Round  70, Global train loss: 0.426, Global test loss: 2.071, Global test accuracy: 24.20
Round  71, Train loss: 0.296, Test loss: 2.297, Test accuracy: 48.57
Round  71, Global train loss: 0.296, Global test loss: 2.018, Global test accuracy: 23.43
Round  72, Train loss: 0.338, Test loss: 2.321, Test accuracy: 48.46
Round  72, Global train loss: 0.338, Global test loss: 1.883, Global test accuracy: 32.99
Round  73, Train loss: 0.344, Test loss: 2.317, Test accuracy: 48.81
Round  73, Global train loss: 0.344, Global test loss: 2.126, Global test accuracy: 18.75
Round  74, Train loss: 0.331, Test loss: 2.341, Test accuracy: 48.53
Round  74, Global train loss: 0.331, Global test loss: 1.962, Global test accuracy: 28.72
Round  75, Train loss: 0.263, Test loss: 2.394, Test accuracy: 48.30
Round  75, Global train loss: 0.263, Global test loss: 1.987, Global test accuracy: 26.56
Round  76, Train loss: 0.289, Test loss: 2.376, Test accuracy: 48.45
Round  76, Global train loss: 0.289, Global test loss: 2.025, Global test accuracy: 27.59
Round  77, Train loss: 0.296, Test loss: 2.423, Test accuracy: 48.07
Round  77, Global train loss: 0.296, Global test loss: 1.979, Global test accuracy: 27.59
Round  78, Train loss: 0.292, Test loss: 2.466, Test accuracy: 48.25
Round  78, Global train loss: 0.292, Global test loss: 1.943, Global test accuracy: 32.44
Round  79, Train loss: 0.261, Test loss: 2.468, Test accuracy: 48.56
Round  79, Global train loss: 0.261, Global test loss: 1.935, Global test accuracy: 31.25
Round  80, Train loss: 0.459, Test loss: 2.527, Test accuracy: 48.79
Round  80, Global train loss: 0.459, Global test loss: 2.072, Global test accuracy: 26.09
Round  81, Train loss: 0.297, Test loss: 2.495, Test accuracy: 48.84
Round  81, Global train loss: 0.297, Global test loss: 2.168, Global test accuracy: 21.25
Round  82, Train loss: 0.312, Test loss: 2.551, Test accuracy: 48.52
Round  82, Global train loss: 0.312, Global test loss: 1.876, Global test accuracy: 34.31
Round  83, Train loss: 0.329, Test loss: 2.534, Test accuracy: 48.50
Round  83, Global train loss: 0.329, Global test loss: 1.939, Global test accuracy: 30.47
Round  84, Train loss: 0.329, Test loss: 2.574, Test accuracy: 48.44
Round  84, Global train loss: 0.329, Global test loss: 2.041, Global test accuracy: 25.14
Round  85, Train loss: 0.244, Test loss: 2.621, Test accuracy: 48.24
Round  85, Global train loss: 0.244, Global test loss: 1.994, Global test accuracy: 27.26
Round  86, Train loss: 0.202, Test loss: 2.688, Test accuracy: 47.72
Round  86, Global train loss: 0.202, Global test loss: 2.035, Global test accuracy: 28.90
Round  87, Train loss: 0.172, Test loss: 2.694, Test accuracy: 48.25
Round  87, Global train loss: 0.172, Global test loss: 1.987, Global test accuracy: 31.83
Round  88, Train loss: 0.295, Test loss: 2.729, Test accuracy: 48.05
Round  88, Global train loss: 0.295, Global test loss: 2.130, Global test accuracy: 26.35
Round  89, Train loss: 0.185, Test loss: 2.757, Test accuracy: 47.89
Round  89, Global train loss: 0.185, Global test loss: 2.081, Global test accuracy: 28.66
Round  90, Train loss: 0.190, Test loss: 2.756, Test accuracy: 48.05
Round  90, Global train loss: 0.190, Global test loss: 1.923, Global test accuracy: 29.77
Round  91, Train loss: 0.255, Test loss: 2.780, Test accuracy: 48.32
Round  91, Global train loss: 0.255, Global test loss: 1.978, Global test accuracy: 29.62
Round  92, Train loss: 0.157, Test loss: 2.837, Test accuracy: 48.02
Round  92, Global train loss: 0.157, Global test loss: 1.932, Global test accuracy: 30.74
Round  93, Train loss: 0.140, Test loss: 2.890, Test accuracy: 48.22
Round  93, Global train loss: 0.140, Global test loss: 1.898, Global test accuracy: 34.98
Round  94, Train loss: 0.247, Test loss: 2.828, Test accuracy: 48.38
Round  94, Global train loss: 0.247, Global test loss: 1.985, Global test accuracy: 30.77
Round  95, Train loss: 0.233, Test loss: 2.848, Test accuracy: 48.45
Round  95, Global train loss: 0.233, Global test loss: 2.042, Global test accuracy: 25.03
Round  96, Train loss: 0.195, Test loss: 2.888, Test accuracy: 48.67
Round  96, Global train loss: 0.195, Global test loss: 2.088, Global test accuracy: 24.37
Round  97, Train loss: 0.175, Test loss: 2.903, Test accuracy: 48.35
Round  97, Global train loss: 0.175, Global test loss: 1.975, Global test accuracy: 30.65
Round  98, Train loss: 0.191, Test loss: 2.918, Test accuracy: 48.22
Round  98, Global train loss: 0.191, Global test loss: 1.969, Global test accuracy: 30.70
Round  99, Train loss: 0.231, Test loss: 2.998, Test accuracy: 48.39
Round  99, Global train loss: 0.231, Global test loss: 2.053, Global test accuracy: 27.70
Final Round, Train loss: 0.183, Test loss: 2.998, Test accuracy: 49.15
Final Round, Global train loss: 0.183, Global test loss: 2.053, Global test accuracy: 27.70
Average accuracy final 10 rounds: 48.307 

Average global accuracy final 10 rounds: 29.433000000000003 

1450.0340263843536
[1.454601764678955, 2.90920352935791, 4.0722010135650635, 5.235198497772217, 6.4087135791778564, 7.582228660583496, 8.771173000335693, 9.96011734008789, 11.148290157318115, 12.33646297454834, 13.519116163253784, 14.701769351959229, 15.884530305862427, 17.067291259765625, 18.24273443222046, 19.418177604675293, 20.597646236419678, 21.777114868164062, 22.957637310028076, 24.13815975189209, 25.295609951019287, 26.453060150146484, 27.607266664505005, 28.761473178863525, 29.893020629882812, 31.0245680809021, 32.153462648391724, 33.28235721588135, 34.52861213684082, 35.77486705780029, 36.93326210975647, 38.09165716171265, 39.257176637649536, 40.422696113586426, 41.58762788772583, 42.752559661865234, 43.911808490753174, 45.07105731964111, 46.22738313674927, 47.38370895385742, 48.54710292816162, 49.71049690246582, 50.865158557891846, 52.01982021331787, 53.17842769622803, 54.337035179138184, 55.50207257270813, 56.667109966278076, 57.82622194290161, 58.98533391952515, 60.13683080673218, 61.28832769393921, 62.45660972595215, 63.62489175796509, 64.78287291526794, 65.9408540725708, 67.09770250320435, 68.25455093383789, 69.40666007995605, 70.55876922607422, 71.70925736427307, 72.85974550247192, 74.0208785533905, 75.18201160430908, 76.34496521949768, 77.50791883468628, 78.66817879676819, 79.8284387588501, 80.98295092582703, 82.13746309280396, 83.2928032875061, 84.44814348220825, 85.6020679473877, 86.75599241256714, 87.89723253250122, 89.0384726524353, 90.19462466239929, 91.35077667236328, 92.50218844413757, 93.65360021591187, 94.81308436393738, 95.97256851196289, 97.12573146820068, 98.27889442443848, 99.29911351203918, 100.31933259963989, 101.33537006378174, 102.35140752792358, 103.36946296691895, 104.3875184059143, 105.40114307403564, 106.41476774215698, 107.42202043533325, 108.42927312850952, 109.43736624717712, 110.44545936584473, 111.45611524581909, 112.46677112579346, 113.47992157936096, 114.49307203292847, 115.50514626502991, 116.51722049713135, 117.53270292282104, 118.54818534851074, 119.56510329246521, 120.58202123641968, 121.59972763061523, 122.61743402481079, 123.62344312667847, 124.62945222854614, 125.63344120979309, 126.63743019104004, 127.65263628959656, 128.66784238815308, 129.6886270046234, 130.70941162109375, 131.72218799591064, 132.73496437072754, 133.7433626651764, 134.75176095962524, 135.75900602340698, 136.76625108718872, 137.7705397605896, 138.77482843399048, 139.7799997329712, 140.7851710319519, 141.7967987060547, 142.80842638015747, 143.81841897964478, 144.82841157913208, 145.8410201072693, 146.8536286354065, 147.8622806072235, 148.87093257904053, 149.88492012023926, 150.898907661438, 151.90259528160095, 152.90628290176392, 153.9163625240326, 154.92644214630127, 155.93954586982727, 156.95264959335327, 157.96884942054749, 158.9850492477417, 159.99674940109253, 161.00844955444336, 162.02241253852844, 163.03637552261353, 164.05366849899292, 165.07096147537231, 166.07862973213196, 167.0862979888916, 168.09860348701477, 169.11090898513794, 170.1158185005188, 171.12072801589966, 172.13265466690063, 173.1445813179016, 174.16085720062256, 175.1771330833435, 176.19552850723267, 177.21392393112183, 178.2259020805359, 179.23788022994995, 180.24198865890503, 181.2460970878601, 182.2537453174591, 183.2613935470581, 184.27130460739136, 185.2812156677246, 186.29327845573425, 187.3053412437439, 188.31879711151123, 189.33225297927856, 190.340651512146, 191.34905004501343, 192.36014771461487, 193.3712453842163, 194.3755350112915, 195.3798246383667, 196.38663625717163, 197.39344787597656, 198.39770817756653, 199.4019684791565, 200.4038121700287, 201.40565586090088, 202.4056692123413, 203.40568256378174, 204.41054105758667, 205.4153995513916, 206.41996884346008, 207.42453813552856, 208.42996835708618, 209.4353985786438, 210.4405324459076, 211.4456663131714, 212.44943571090698, 213.45320510864258, 214.4580523967743, 215.462899684906, 217.4734287261963, 219.48395776748657]
[21.09, 21.09, 29.67, 29.67, 36.14, 36.14, 37.52, 37.52, 42.89, 42.89, 42.52, 42.52, 43.78, 43.78, 46.4, 46.4, 47.72, 47.72, 48.18, 48.18, 48.16, 48.16, 49.34, 49.34, 49.75, 49.75, 50.01, 50.01, 50.17, 50.17, 50.57, 50.57, 51.32, 51.32, 51.52, 51.52, 51.39, 51.39, 51.03, 51.03, 51.44, 51.44, 52.03, 52.03, 52.39, 52.39, 51.99, 51.99, 52.0, 52.0, 52.3, 52.3, 52.21, 52.21, 51.43, 51.43, 51.52, 51.52, 51.31, 51.31, 51.32, 51.32, 51.54, 51.54, 51.4, 51.4, 51.15, 51.15, 50.94, 50.94, 51.24, 51.24, 50.81, 50.81, 50.37, 50.37, 50.07, 50.07, 49.93, 49.93, 50.43, 50.43, 49.98, 49.98, 49.86, 49.86, 49.38, 49.38, 49.52, 49.52, 49.09, 49.09, 48.79, 48.79, 49.28, 49.28, 49.32, 49.32, 49.66, 49.66, 49.69, 49.69, 49.68, 49.68, 49.81, 49.81, 49.65, 49.65, 49.68, 49.68, 50.02, 50.02, 50.09, 50.09, 49.37, 49.37, 49.42, 49.42, 49.48, 49.48, 49.18, 49.18, 49.42, 49.42, 48.5, 48.5, 48.49, 48.49, 48.54, 48.54, 48.66, 48.66, 48.93, 48.93, 48.61, 48.61, 48.41, 48.41, 48.06, 48.06, 48.19, 48.19, 48.57, 48.57, 48.46, 48.46, 48.81, 48.81, 48.53, 48.53, 48.3, 48.3, 48.45, 48.45, 48.07, 48.07, 48.25, 48.25, 48.56, 48.56, 48.79, 48.79, 48.84, 48.84, 48.52, 48.52, 48.5, 48.5, 48.44, 48.44, 48.24, 48.24, 47.72, 47.72, 48.25, 48.25, 48.05, 48.05, 47.89, 47.89, 48.05, 48.05, 48.32, 48.32, 48.02, 48.02, 48.22, 48.22, 48.38, 48.38, 48.45, 48.45, 48.67, 48.67, 48.35, 48.35, 48.22, 48.22, 48.39, 48.39, 49.15, 49.15]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.6 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 4, noise    level: 0.4000 
   Client 15, noise    level: 0.4000 
   Client 11, noise    level: 0.4000 
   Client 12, noise    level: 0.4000 
   Client 17, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 18, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.673, Test loss: 2.008, Test accuracy: 22.97
Round   0, Global train loss: 1.673, Global test loss: 2.223, Global test accuracy: 18.24
Round   1, Train loss: 1.506, Test loss: 1.830, Test accuracy: 30.48
Round   1, Global train loss: 1.506, Global test loss: 2.293, Global test accuracy: 20.77
Round   2, Train loss: 1.434, Test loss: 1.483, Test accuracy: 39.40
Round   2, Global train loss: 1.434, Global test loss: 1.858, Global test accuracy: 31.92
Round   3, Train loss: 1.319, Test loss: 1.442, Test accuracy: 41.65
Round   3, Global train loss: 1.319, Global test loss: 1.933, Global test accuracy: 26.57
Round   4, Train loss: 1.358, Test loss: 1.312, Test accuracy: 46.98
Round   4, Global train loss: 1.358, Global test loss: 1.923, Global test accuracy: 30.14
Round   5, Train loss: 1.222, Test loss: 1.285, Test accuracy: 47.72
Round   5, Global train loss: 1.222, Global test loss: 1.906, Global test accuracy: 28.53
Round   6, Train loss: 1.227, Test loss: 1.228, Test accuracy: 50.69
Round   6, Global train loss: 1.227, Global test loss: 1.634, Global test accuracy: 40.47
Round   7, Train loss: 1.150, Test loss: 1.151, Test accuracy: 52.84
Round   7, Global train loss: 1.150, Global test loss: 1.767, Global test accuracy: 33.41
Round   8, Train loss: 1.117, Test loss: 1.136, Test accuracy: 54.19
Round   8, Global train loss: 1.117, Global test loss: 1.590, Global test accuracy: 41.54
Round   9, Train loss: 1.157, Test loss: 1.133, Test accuracy: 54.28
Round   9, Global train loss: 1.157, Global test loss: 1.617, Global test accuracy: 39.56
Round  10, Train loss: 1.076, Test loss: 1.127, Test accuracy: 55.07
Round  10, Global train loss: 1.076, Global test loss: 1.782, Global test accuracy: 40.09
Round  11, Train loss: 1.017, Test loss: 1.098, Test accuracy: 56.84
Round  11, Global train loss: 1.017, Global test loss: 1.664, Global test accuracy: 40.10
Round  12, Train loss: 1.066, Test loss: 1.075, Test accuracy: 58.18
Round  12, Global train loss: 1.066, Global test loss: 1.588, Global test accuracy: 41.89
Round  13, Train loss: 1.040, Test loss: 1.073, Test accuracy: 58.16
Round  13, Global train loss: 1.040, Global test loss: 1.478, Global test accuracy: 46.48
Round  14, Train loss: 1.036, Test loss: 1.066, Test accuracy: 58.84
Round  14, Global train loss: 1.036, Global test loss: 1.481, Global test accuracy: 45.97
Round  15, Train loss: 1.162, Test loss: 1.061, Test accuracy: 58.90
Round  15, Global train loss: 1.162, Global test loss: 1.489, Global test accuracy: 46.41
Round  16, Train loss: 1.009, Test loss: 1.073, Test accuracy: 58.36
Round  16, Global train loss: 1.009, Global test loss: 1.557, Global test accuracy: 44.74
Round  17, Train loss: 0.974, Test loss: 1.053, Test accuracy: 58.89
Round  17, Global train loss: 0.974, Global test loss: 1.456, Global test accuracy: 50.06
Round  18, Train loss: 0.995, Test loss: 1.031, Test accuracy: 60.49
Round  18, Global train loss: 0.995, Global test loss: 1.453, Global test accuracy: 49.02
Round  19, Train loss: 0.942, Test loss: 1.035, Test accuracy: 60.25
Round  19, Global train loss: 0.942, Global test loss: 1.537, Global test accuracy: 48.04
Round  20, Train loss: 0.982, Test loss: 1.059, Test accuracy: 60.01
Round  20, Global train loss: 0.982, Global test loss: 1.453, Global test accuracy: 49.75
Round  21, Train loss: 0.837, Test loss: 1.028, Test accuracy: 60.79
Round  21, Global train loss: 0.837, Global test loss: 1.597, Global test accuracy: 45.57
Round  22, Train loss: 0.924, Test loss: 1.015, Test accuracy: 61.68
Round  22, Global train loss: 0.924, Global test loss: 1.304, Global test accuracy: 53.27
Round  23, Train loss: 0.872, Test loss: 1.014, Test accuracy: 61.71
Round  23, Global train loss: 0.872, Global test loss: 1.355, Global test accuracy: 50.90
Round  24, Train loss: 0.896, Test loss: 1.015, Test accuracy: 61.98
Round  24, Global train loss: 0.896, Global test loss: 1.428, Global test accuracy: 51.45
Round  25, Train loss: 0.801, Test loss: 0.992, Test accuracy: 62.84
Round  25, Global train loss: 0.801, Global test loss: 1.299, Global test accuracy: 53.31
Round  26, Train loss: 0.924, Test loss: 0.986, Test accuracy: 63.42
Round  26, Global train loss: 0.924, Global test loss: 1.502, Global test accuracy: 45.82
Round  27, Train loss: 0.836, Test loss: 0.987, Test accuracy: 63.51
Round  27, Global train loss: 0.836, Global test loss: 1.476, Global test accuracy: 48.06
Round  28, Train loss: 0.887, Test loss: 0.995, Test accuracy: 63.14
Round  28, Global train loss: 0.887, Global test loss: 1.303, Global test accuracy: 54.92
Round  29, Train loss: 0.870, Test loss: 0.999, Test accuracy: 63.38
Round  29, Global train loss: 0.870, Global test loss: 1.365, Global test accuracy: 52.26
Round  30, Train loss: 0.922, Test loss: 0.976, Test accuracy: 64.24
Round  30, Global train loss: 0.922, Global test loss: 1.271, Global test accuracy: 55.95
Round  31, Train loss: 0.764, Test loss: 0.958, Test accuracy: 64.97
Round  31, Global train loss: 0.764, Global test loss: 1.294, Global test accuracy: 53.97
Round  32, Train loss: 0.954, Test loss: 0.965, Test accuracy: 64.73
Round  32, Global train loss: 0.954, Global test loss: 1.439, Global test accuracy: 49.55
Round  33, Train loss: 0.762, Test loss: 0.961, Test accuracy: 65.67
Round  33, Global train loss: 0.762, Global test loss: 1.267, Global test accuracy: 56.32
Round  34, Train loss: 0.757, Test loss: 0.987, Test accuracy: 64.78
Round  34, Global train loss: 0.757, Global test loss: 1.278, Global test accuracy: 55.85
Round  35, Train loss: 0.701, Test loss: 0.994, Test accuracy: 64.68
Round  35, Global train loss: 0.701, Global test loss: 1.415, Global test accuracy: 52.91
Round  36, Train loss: 0.770, Test loss: 0.986, Test accuracy: 64.85
Round  36, Global train loss: 0.770, Global test loss: 1.438, Global test accuracy: 49.53
Round  37, Train loss: 0.698, Test loss: 1.013, Test accuracy: 63.84
Round  37, Global train loss: 0.698, Global test loss: 1.255, Global test accuracy: 56.45
Round  38, Train loss: 0.682, Test loss: 1.007, Test accuracy: 64.44
Round  38, Global train loss: 0.682, Global test loss: 1.456, Global test accuracy: 51.81
Round  39, Train loss: 0.664, Test loss: 0.993, Test accuracy: 65.07
Round  39, Global train loss: 0.664, Global test loss: 1.262, Global test accuracy: 55.69
Round  40, Train loss: 0.758, Test loss: 0.986, Test accuracy: 65.39
Round  40, Global train loss: 0.758, Global test loss: 1.292, Global test accuracy: 54.99
Round  41, Train loss: 0.698, Test loss: 0.979, Test accuracy: 65.74
Round  41, Global train loss: 0.698, Global test loss: 1.369, Global test accuracy: 53.18
Round  42, Train loss: 0.728, Test loss: 0.987, Test accuracy: 65.78
Round  42, Global train loss: 0.728, Global test loss: 1.295, Global test accuracy: 54.55
Round  43, Train loss: 0.621, Test loss: 0.980, Test accuracy: 65.99
Round  43, Global train loss: 0.621, Global test loss: 1.195, Global test accuracy: 58.71
Round  44, Train loss: 0.661, Test loss: 0.991, Test accuracy: 65.73
Round  44, Global train loss: 0.661, Global test loss: 1.430, Global test accuracy: 53.34
Round  45, Train loss: 0.691, Test loss: 0.985, Test accuracy: 66.03
Round  45, Global train loss: 0.691, Global test loss: 1.441, Global test accuracy: 52.70
Round  46, Train loss: 0.681, Test loss: 1.011, Test accuracy: 65.98
Round  46, Global train loss: 0.681, Global test loss: 1.191, Global test accuracy: 59.18
Round  47, Train loss: 0.661, Test loss: 1.030, Test accuracy: 65.80
Round  47, Global train loss: 0.661, Global test loss: 1.302, Global test accuracy: 56.07
Round  48, Train loss: 0.599, Test loss: 1.012, Test accuracy: 66.21
Round  48, Global train loss: 0.599, Global test loss: 1.294, Global test accuracy: 56.06
Round  49, Train loss: 0.598, Test loss: 1.018, Test accuracy: 66.08
Round  49, Global train loss: 0.598, Global test loss: 1.312, Global test accuracy: 56.12
Round  50, Train loss: 0.716, Test loss: 1.018, Test accuracy: 66.45
Round  50, Global train loss: 0.716, Global test loss: 1.463, Global test accuracy: 51.65
Round  51, Train loss: 0.573, Test loss: 0.998, Test accuracy: 66.90
Round  51, Global train loss: 0.573, Global test loss: 1.221, Global test accuracy: 59.37
Round  52, Train loss: 0.636, Test loss: 0.981, Test accuracy: 67.40
Round  52, Global train loss: 0.636, Global test loss: 1.237, Global test accuracy: 58.22
Round  53, Train loss: 0.645, Test loss: 0.974, Test accuracy: 67.57
Round  53, Global train loss: 0.645, Global test loss: 1.259, Global test accuracy: 57.51
Round  54, Train loss: 0.656, Test loss: 0.986, Test accuracy: 66.83
Round  54, Global train loss: 0.656, Global test loss: 1.459, Global test accuracy: 52.27
Round  55, Train loss: 0.604, Test loss: 0.985, Test accuracy: 67.18
Round  55, Global train loss: 0.604, Global test loss: 1.284, Global test accuracy: 57.65
Round  56, Train loss: 0.556, Test loss: 1.007, Test accuracy: 66.94
Round  56, Global train loss: 0.556, Global test loss: 1.262, Global test accuracy: 57.21
Round  57, Train loss: 0.604, Test loss: 1.005, Test accuracy: 67.37
Round  57, Global train loss: 0.604, Global test loss: 1.337, Global test accuracy: 55.81
Round  58, Train loss: 0.544, Test loss: 1.027, Test accuracy: 67.15
Round  58, Global train loss: 0.544, Global test loss: 1.215, Global test accuracy: 58.40
Round  59, Train loss: 0.569, Test loss: 1.000, Test accuracy: 67.70
Round  59, Global train loss: 0.569, Global test loss: 1.252, Global test accuracy: 58.80
Round  60, Train loss: 0.544, Test loss: 0.995, Test accuracy: 67.94
Round  60, Global train loss: 0.544, Global test loss: 1.353, Global test accuracy: 55.79
Round  61, Train loss: 0.516, Test loss: 1.024, Test accuracy: 67.24
Round  61, Global train loss: 0.516, Global test loss: 1.264, Global test accuracy: 59.18
Round  62, Train loss: 0.560, Test loss: 1.032, Test accuracy: 67.42
Round  62, Global train loss: 0.560, Global test loss: 1.434, Global test accuracy: 54.52
Round  63, Train loss: 0.553, Test loss: 1.033, Test accuracy: 67.50
Round  63, Global train loss: 0.553, Global test loss: 1.302, Global test accuracy: 58.98
Round  64, Train loss: 0.428, Test loss: 1.037, Test accuracy: 67.61
Round  64, Global train loss: 0.428, Global test loss: 1.325, Global test accuracy: 58.33
Round  65, Train loss: 0.515, Test loss: 1.040, Test accuracy: 67.88
Round  65, Global train loss: 0.515, Global test loss: 1.419, Global test accuracy: 55.55
Round  66, Train loss: 0.577, Test loss: 1.049, Test accuracy: 67.37
Round  66, Global train loss: 0.577, Global test loss: 1.416, Global test accuracy: 55.12
Round  67, Train loss: 0.552, Test loss: 1.044, Test accuracy: 67.75
Round  67, Global train loss: 0.552, Global test loss: 1.452, Global test accuracy: 55.10
Round  68, Train loss: 0.607, Test loss: 1.030, Test accuracy: 68.05
Round  68, Global train loss: 0.607, Global test loss: 1.442, Global test accuracy: 54.11
Round  69, Train loss: 0.478, Test loss: 1.024, Test accuracy: 68.27
Round  69, Global train loss: 0.478, Global test loss: 1.497, Global test accuracy: 53.85
Round  70, Train loss: 0.545, Test loss: 1.046, Test accuracy: 68.20
Round  70, Global train loss: 0.545, Global test loss: 1.423, Global test accuracy: 55.72
Round  71, Train loss: 0.489, Test loss: 1.073, Test accuracy: 67.66
Round  71, Global train loss: 0.489, Global test loss: 1.365, Global test accuracy: 57.61
Round  72, Train loss: 0.518, Test loss: 1.063, Test accuracy: 67.68
Round  72, Global train loss: 0.518, Global test loss: 1.302, Global test accuracy: 58.40
Round  73, Train loss: 0.515, Test loss: 1.032, Test accuracy: 68.20
Round  73, Global train loss: 0.515, Global test loss: 1.335, Global test accuracy: 58.17
Round  74, Train loss: 0.455, Test loss: 1.062, Test accuracy: 67.64
Round  74, Global train loss: 0.455, Global test loss: 1.302, Global test accuracy: 59.64
Round  75, Train loss: 0.483, Test loss: 1.063, Test accuracy: 67.77
Round  75, Global train loss: 0.483, Global test loss: 1.262, Global test accuracy: 60.54
Round  76, Train loss: 0.466, Test loss: 1.054, Test accuracy: 68.33
Round  76, Global train loss: 0.466, Global test loss: 1.394, Global test accuracy: 57.59
Round  77, Train loss: 0.513, Test loss: 1.059, Test accuracy: 67.97
Round  77, Global train loss: 0.513, Global test loss: 1.335, Global test accuracy: 59.91
Round  78, Train loss: 0.413, Test loss: 1.067, Test accuracy: 68.08
Round  78, Global train loss: 0.413, Global test loss: 1.392, Global test accuracy: 58.99
Round  79, Train loss: 0.429, Test loss: 1.064, Test accuracy: 68.40
Round  79, Global train loss: 0.429, Global test loss: 1.373, Global test accuracy: 57.56
Round  80, Train loss: 0.538, Test loss: 1.052, Test accuracy: 68.54
Round  80, Global train loss: 0.538, Global test loss: 1.296, Global test accuracy: 58.90
Round  81, Train loss: 0.491, Test loss: 1.058, Test accuracy: 68.33
Round  81, Global train loss: 0.491, Global test loss: 1.380, Global test accuracy: 59.44
Round  82, Train loss: 0.449, Test loss: 1.078, Test accuracy: 68.19
Round  82, Global train loss: 0.449, Global test loss: 1.330, Global test accuracy: 59.53
Round  83, Train loss: 0.426, Test loss: 1.098, Test accuracy: 68.19
Round  83, Global train loss: 0.426, Global test loss: 1.211, Global test accuracy: 62.13
Round  84, Train loss: 0.423, Test loss: 1.083, Test accuracy: 68.53
Round  84, Global train loss: 0.423, Global test loss: 1.317, Global test accuracy: 59.73
Round  85, Train loss: 0.511, Test loss: 1.099, Test accuracy: 68.18
Round  85, Global train loss: 0.511, Global test loss: 1.291, Global test accuracy: 59.12
Round  86, Train loss: 0.391, Test loss: 1.087, Test accuracy: 68.57
Round  86, Global train loss: 0.391, Global test loss: 1.457, Global test accuracy: 58.20
Round  87, Train loss: 0.356, Test loss: 1.096, Test accuracy: 68.41
Round  87, Global train loss: 0.356, Global test loss: 1.497, Global test accuracy: 56.71
Round  88, Train loss: 0.455, Test loss: 1.106, Test accuracy: 68.51
Round  88, Global train loss: 0.455, Global test loss: 1.420, Global test accuracy: 57.57
Round  89, Train loss: 0.363, Test loss: 1.101, Test accuracy: 68.40
Round  89, Global train loss: 0.363, Global test loss: 1.563, Global test accuracy: 55.13
Round  90, Train loss: 0.400, Test loss: 1.106, Test accuracy: 68.28
Round  90, Global train loss: 0.400, Global test loss: 1.388, Global test accuracy: 58.92
Round  91, Train loss: 0.496, Test loss: 1.120, Test accuracy: 68.09
Round  91, Global train loss: 0.496, Global test loss: 1.241, Global test accuracy: 60.98
Round  92, Train loss: 0.352, Test loss: 1.118, Test accuracy: 68.53
Round  92, Global train loss: 0.352, Global test loss: 1.386, Global test accuracy: 58.99
Round  93, Train loss: 0.372, Test loss: 1.105, Test accuracy: 68.73
Round  93, Global train loss: 0.372, Global test loss: 1.312, Global test accuracy: 60.34
Round  94, Train loss: 0.420, Test loss: 1.134, Test accuracy: 68.38
Round  94, Global train loss: 0.420, Global test loss: 1.496, Global test accuracy: 56.54
Round  95, Train loss: 0.414, Test loss: 1.104, Test accuracy: 68.94
Round  95, Global train loss: 0.414, Global test loss: 1.273, Global test accuracy: 61.49
Round  96, Train loss: 0.445, Test loss: 1.089, Test accuracy: 69.23
Round  96, Global train loss: 0.445, Global test loss: 1.312, Global test accuracy: 60.53
Round  97, Train loss: 0.375, Test loss: 1.111, Test accuracy: 68.61
Round  97, Global train loss: 0.375, Global test loss: 1.348, Global test accuracy: 60.35
Round  98, Train loss: 0.380, Test loss: 1.129, Test accuracy: 68.60
Round  98, Global train loss: 0.380, Global test loss: 1.379, Global test accuracy: 59.41
Round  99, Train loss: 0.378, Test loss: 1.122, Test accuracy: 68.62
Round  99, Global train loss: 0.378, Global test loss: 1.483, Global test accuracy: 59.54
Final Round, Train loss: 0.328, Test loss: 1.252, Test accuracy: 68.56
Final Round, Global train loss: 0.328, Global test loss: 1.483, Global test accuracy: 59.54
Average accuracy final 10 rounds: 68.601 

Average global accuracy final 10 rounds: 59.708999999999996 

1589.4744980335236
[1.5421531200408936, 3.084306240081787, 4.352086305618286, 5.619866371154785, 6.886003255844116, 8.152140140533447, 9.413132190704346, 10.674124240875244, 11.938349962234497, 13.20257568359375, 14.462974786758423, 15.723373889923096, 16.984164476394653, 18.24495506286621, 19.506181478500366, 20.76740789413452, 22.029452085494995, 23.29149627685547, 24.558537006378174, 25.82557773590088, 27.082337379455566, 28.339097023010254, 29.59696102142334, 30.854825019836426, 32.116799116134644, 33.37877321243286, 34.637370586395264, 35.895967960357666, 37.15847849845886, 38.42098903656006, 39.68685507774353, 40.952721118927, 42.21887993812561, 43.48503875732422, 44.745347023010254, 46.00565528869629, 47.264859437942505, 48.52406358718872, 49.77849507331848, 51.03292655944824, 52.29061222076416, 53.54829788208008, 54.807106733322144, 56.06591558456421, 57.32130742073059, 58.57669925689697, 59.8310444355011, 61.085389614105225, 62.342594146728516, 63.59979867935181, 64.87219429016113, 66.14458990097046, 67.40255045890808, 68.6605110168457, 69.91765093803406, 71.17479085922241, 72.43488001823425, 73.6949691772461, 74.95114541053772, 76.20732164382935, 77.46881580352783, 78.73030996322632, 79.99447083473206, 81.2586317062378, 82.51836371421814, 83.77809572219849, 85.04014992713928, 86.30220413208008, 87.55941605567932, 88.81662797927856, 90.07034039497375, 91.32405281066895, 92.57789468765259, 93.83173656463623, 95.09477353096008, 96.35781049728394, 97.61911797523499, 98.88042545318604, 100.14251661300659, 101.40460777282715, 102.6631166934967, 103.92162561416626, 105.17558026313782, 106.42953491210938, 107.68150353431702, 108.93347215652466, 110.18474340438843, 111.4360146522522, 112.70076036453247, 113.96550607681274, 115.23432183265686, 116.50313758850098, 117.77015662193298, 119.03717565536499, 120.30694508552551, 121.57671451568604, 122.83165264129639, 124.08659076690674, 125.34346318244934, 126.60033559799194, 127.86726665496826, 129.13419771194458, 130.39625811576843, 131.65831851959229, 132.91866898536682, 134.17901945114136, 135.43623971939087, 136.69345998764038, 137.95653414726257, 139.21960830688477, 140.47184705734253, 141.7240858078003, 142.97575998306274, 144.2274341583252, 145.49139618873596, 146.75535821914673, 148.01458859443665, 149.27381896972656, 150.53116035461426, 151.78850173950195, 153.04535007476807, 154.30219841003418, 155.57290053367615, 156.84360265731812, 158.10237383842468, 159.36114501953125, 160.6119146347046, 161.86268424987793, 163.11810541152954, 164.37352657318115, 165.62458205223083, 166.87563753128052, 168.12872219085693, 169.38180685043335, 170.63438367843628, 171.8869605064392, 173.1383728981018, 174.3897852897644, 175.64218091964722, 176.89457654953003, 178.1513066291809, 179.4080367088318, 180.66772627830505, 181.92741584777832, 183.18956971168518, 184.45172357559204, 185.71508288383484, 186.97844219207764, 188.23657822608948, 189.49471426010132, 190.77068495750427, 192.04665565490723, 193.32037496566772, 194.59409427642822, 195.86426067352295, 197.13442707061768, 198.39555764198303, 199.6566882133484, 200.92684149742126, 202.19699478149414, 203.4631052017212, 204.72921562194824, 205.98967051506042, 207.2501254081726, 208.5059928894043, 209.761860370636, 211.02588772773743, 212.28991508483887, 213.56132221221924, 214.8327293395996, 216.1036388874054, 217.37454843521118, 218.6420018672943, 219.90945529937744, 221.1693639755249, 222.42927265167236, 223.68661189079285, 224.94395112991333, 226.2108290195465, 227.4777069091797, 228.74736738204956, 230.01702785491943, 231.286150932312, 232.5552740097046, 233.81366848945618, 235.07206296920776, 236.32849645614624, 237.58492994308472, 238.85543990135193, 240.12594985961914, 241.3872091770172, 242.64846849441528, 243.9063754081726, 245.16428232192993, 246.42352867126465, 247.68277502059937, 248.92715215682983, 250.1715292930603, 251.423091173172, 252.6746530532837, 255.18545508384705, 257.6962571144104]
[22.97, 22.97, 30.48, 30.48, 39.4, 39.4, 41.65, 41.65, 46.98, 46.98, 47.72, 47.72, 50.69, 50.69, 52.84, 52.84, 54.19, 54.19, 54.28, 54.28, 55.07, 55.07, 56.84, 56.84, 58.18, 58.18, 58.16, 58.16, 58.84, 58.84, 58.9, 58.9, 58.36, 58.36, 58.89, 58.89, 60.49, 60.49, 60.25, 60.25, 60.01, 60.01, 60.79, 60.79, 61.68, 61.68, 61.71, 61.71, 61.98, 61.98, 62.84, 62.84, 63.42, 63.42, 63.51, 63.51, 63.14, 63.14, 63.38, 63.38, 64.24, 64.24, 64.97, 64.97, 64.73, 64.73, 65.67, 65.67, 64.78, 64.78, 64.68, 64.68, 64.85, 64.85, 63.84, 63.84, 64.44, 64.44, 65.07, 65.07, 65.39, 65.39, 65.74, 65.74, 65.78, 65.78, 65.99, 65.99, 65.73, 65.73, 66.03, 66.03, 65.98, 65.98, 65.8, 65.8, 66.21, 66.21, 66.08, 66.08, 66.45, 66.45, 66.9, 66.9, 67.4, 67.4, 67.57, 67.57, 66.83, 66.83, 67.18, 67.18, 66.94, 66.94, 67.37, 67.37, 67.15, 67.15, 67.7, 67.7, 67.94, 67.94, 67.24, 67.24, 67.42, 67.42, 67.5, 67.5, 67.61, 67.61, 67.88, 67.88, 67.37, 67.37, 67.75, 67.75, 68.05, 68.05, 68.27, 68.27, 68.2, 68.2, 67.66, 67.66, 67.68, 67.68, 68.2, 68.2, 67.64, 67.64, 67.77, 67.77, 68.33, 68.33, 67.97, 67.97, 68.08, 68.08, 68.4, 68.4, 68.54, 68.54, 68.33, 68.33, 68.19, 68.19, 68.19, 68.19, 68.53, 68.53, 68.18, 68.18, 68.57, 68.57, 68.41, 68.41, 68.51, 68.51, 68.4, 68.4, 68.28, 68.28, 68.09, 68.09, 68.53, 68.53, 68.73, 68.73, 68.38, 68.38, 68.94, 68.94, 69.23, 69.23, 68.61, 68.61, 68.6, 68.6, 68.62, 68.62, 68.56, 68.56]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.6 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 14, noise    level: 0.4000 
   Client 15, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 12, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 11, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 17, noise    level: 0.4000 
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.689, Test loss: 2.049, Test accuracy: 18.75
Round   0, Global train loss: 1.689, Global test loss: 2.254, Global test accuracy: 13.78
Round   1, Train loss: 1.607, Test loss: 1.795, Test accuracy: 29.03
Round   1, Global train loss: 1.607, Global test loss: 2.174, Global test accuracy: 20.16
Round   2, Train loss: 1.528, Test loss: 1.530, Test accuracy: 37.25
Round   2, Global train loss: 1.528, Global test loss: 1.936, Global test accuracy: 28.31
Round   3, Train loss: 1.429, Test loss: 1.518, Test accuracy: 38.56
Round   3, Global train loss: 1.429, Global test loss: 1.988, Global test accuracy: 26.31
Round   4, Train loss: 1.376, Test loss: 1.375, Test accuracy: 43.61
Round   4, Global train loss: 1.376, Global test loss: 1.986, Global test accuracy: 26.95
Round   5, Train loss: 1.330, Test loss: 1.328, Test accuracy: 45.15
Round   5, Global train loss: 1.330, Global test loss: 1.802, Global test accuracy: 28.86
Round   6, Train loss: 1.284, Test loss: 1.283, Test accuracy: 48.53
Round   6, Global train loss: 1.284, Global test loss: 1.700, Global test accuracy: 35.95
Round   7, Train loss: 1.274, Test loss: 1.206, Test accuracy: 51.78
Round   7, Global train loss: 1.274, Global test loss: 1.707, Global test accuracy: 34.32
Round   8, Train loss: 1.261, Test loss: 1.191, Test accuracy: 52.59
Round   8, Global train loss: 1.261, Global test loss: 1.637, Global test accuracy: 40.24
Round   9, Train loss: 1.224, Test loss: 1.179, Test accuracy: 52.96
Round   9, Global train loss: 1.224, Global test loss: 1.636, Global test accuracy: 38.10
Round  10, Train loss: 1.191, Test loss: 1.157, Test accuracy: 54.34
Round  10, Global train loss: 1.191, Global test loss: 1.760, Global test accuracy: 38.27
Round  11, Train loss: 1.154, Test loss: 1.136, Test accuracy: 55.38
Round  11, Global train loss: 1.154, Global test loss: 1.699, Global test accuracy: 37.91
Round  12, Train loss: 1.165, Test loss: 1.116, Test accuracy: 56.59
Round  12, Global train loss: 1.165, Global test loss: 1.693, Global test accuracy: 38.00
Round  13, Train loss: 1.136, Test loss: 1.105, Test accuracy: 57.22
Round  13, Global train loss: 1.136, Global test loss: 1.503, Global test accuracy: 45.04
Round  14, Train loss: 1.094, Test loss: 1.076, Test accuracy: 58.41
Round  14, Global train loss: 1.094, Global test loss: 1.509, Global test accuracy: 45.25
Round  15, Train loss: 1.129, Test loss: 1.069, Test accuracy: 58.40
Round  15, Global train loss: 1.129, Global test loss: 1.534, Global test accuracy: 44.77
Round  16, Train loss: 1.045, Test loss: 1.072, Test accuracy: 58.60
Round  16, Global train loss: 1.045, Global test loss: 1.508, Global test accuracy: 46.18
Round  17, Train loss: 0.986, Test loss: 1.072, Test accuracy: 58.58
Round  17, Global train loss: 0.986, Global test loss: 1.572, Global test accuracy: 45.55
Round  18, Train loss: 1.089, Test loss: 1.059, Test accuracy: 59.51
Round  18, Global train loss: 1.089, Global test loss: 1.526, Global test accuracy: 46.94
Round  19, Train loss: 1.048, Test loss: 1.043, Test accuracy: 60.10
Round  19, Global train loss: 1.048, Global test loss: 1.524, Global test accuracy: 46.40
Round  20, Train loss: 0.998, Test loss: 1.045, Test accuracy: 60.11
Round  20, Global train loss: 0.998, Global test loss: 1.411, Global test accuracy: 50.71
Round  21, Train loss: 0.925, Test loss: 1.063, Test accuracy: 59.69
Round  21, Global train loss: 0.925, Global test loss: 1.563, Global test accuracy: 45.98
Round  22, Train loss: 1.030, Test loss: 1.035, Test accuracy: 60.79
Round  22, Global train loss: 1.030, Global test loss: 1.363, Global test accuracy: 50.64
Round  23, Train loss: 0.975, Test loss: 1.019, Test accuracy: 61.14
Round  23, Global train loss: 0.975, Global test loss: 1.356, Global test accuracy: 51.65
Round  24, Train loss: 0.966, Test loss: 1.030, Test accuracy: 61.01
Round  24, Global train loss: 0.966, Global test loss: 1.401, Global test accuracy: 50.77
Round  25, Train loss: 0.898, Test loss: 1.036, Test accuracy: 61.28
Round  25, Global train loss: 0.898, Global test loss: 1.308, Global test accuracy: 53.15
Round  26, Train loss: 1.023, Test loss: 1.033, Test accuracy: 61.90
Round  26, Global train loss: 1.023, Global test loss: 1.447, Global test accuracy: 46.25
Round  27, Train loss: 0.999, Test loss: 1.019, Test accuracy: 62.37
Round  27, Global train loss: 0.999, Global test loss: 1.441, Global test accuracy: 47.53
Round  28, Train loss: 0.994, Test loss: 1.020, Test accuracy: 62.69
Round  28, Global train loss: 0.994, Global test loss: 1.358, Global test accuracy: 52.21
Round  29, Train loss: 0.973, Test loss: 0.983, Test accuracy: 64.32
Round  29, Global train loss: 0.973, Global test loss: 1.351, Global test accuracy: 52.84
Round  30, Train loss: 0.981, Test loss: 0.978, Test accuracy: 64.27
Round  30, Global train loss: 0.981, Global test loss: 1.324, Global test accuracy: 53.69
Round  31, Train loss: 0.950, Test loss: 0.976, Test accuracy: 64.35
Round  31, Global train loss: 0.950, Global test loss: 1.314, Global test accuracy: 55.27
Round  32, Train loss: 0.978, Test loss: 0.977, Test accuracy: 64.41
Round  32, Global train loss: 0.978, Global test loss: 1.353, Global test accuracy: 51.01
Round  33, Train loss: 0.813, Test loss: 0.966, Test accuracy: 65.09
Round  33, Global train loss: 0.813, Global test loss: 1.338, Global test accuracy: 53.57
Round  34, Train loss: 0.773, Test loss: 0.971, Test accuracy: 64.92
Round  34, Global train loss: 0.773, Global test loss: 1.289, Global test accuracy: 56.21
Round  35, Train loss: 0.866, Test loss: 0.967, Test accuracy: 64.75
Round  35, Global train loss: 0.866, Global test loss: 1.414, Global test accuracy: 51.82
Round  36, Train loss: 0.882, Test loss: 0.965, Test accuracy: 64.61
Round  36, Global train loss: 0.882, Global test loss: 1.374, Global test accuracy: 51.36
Round  37, Train loss: 0.817, Test loss: 0.969, Test accuracy: 64.88
Round  37, Global train loss: 0.817, Global test loss: 1.268, Global test accuracy: 55.79
Round  38, Train loss: 0.835, Test loss: 0.969, Test accuracy: 65.22
Round  38, Global train loss: 0.835, Global test loss: 1.410, Global test accuracy: 51.65
Round  39, Train loss: 0.822, Test loss: 0.980, Test accuracy: 64.43
Round  39, Global train loss: 0.822, Global test loss: 1.292, Global test accuracy: 55.37
Round  40, Train loss: 0.870, Test loss: 0.979, Test accuracy: 64.70
Round  40, Global train loss: 0.870, Global test loss: 1.292, Global test accuracy: 55.04
Round  41, Train loss: 0.829, Test loss: 0.984, Test accuracy: 64.60
Round  41, Global train loss: 0.829, Global test loss: 1.404, Global test accuracy: 51.83
Round  42, Train loss: 0.790, Test loss: 0.967, Test accuracy: 65.30
Round  42, Global train loss: 0.790, Global test loss: 1.269, Global test accuracy: 56.48
Round  43, Train loss: 0.798, Test loss: 0.984, Test accuracy: 64.94
Round  43, Global train loss: 0.798, Global test loss: 1.259, Global test accuracy: 57.26
Round  44, Train loss: 0.883, Test loss: 0.979, Test accuracy: 65.37
Round  44, Global train loss: 0.883, Global test loss: 1.400, Global test accuracy: 52.75
Round  45, Train loss: 0.813, Test loss: 0.966, Test accuracy: 65.89
Round  45, Global train loss: 0.813, Global test loss: 1.359, Global test accuracy: 53.68
Round  46, Train loss: 0.791, Test loss: 0.967, Test accuracy: 66.05
Round  46, Global train loss: 0.791, Global test loss: 1.224, Global test accuracy: 57.54
Round  47, Train loss: 0.831, Test loss: 0.949, Test accuracy: 66.78
Round  47, Global train loss: 0.831, Global test loss: 1.292, Global test accuracy: 55.48
Round  48, Train loss: 0.719, Test loss: 0.973, Test accuracy: 66.24
Round  48, Global train loss: 0.719, Global test loss: 1.327, Global test accuracy: 54.46
Round  49, Train loss: 0.697, Test loss: 0.963, Test accuracy: 66.15
Round  49, Global train loss: 0.697, Global test loss: 1.284, Global test accuracy: 56.83
Round  50, Train loss: 0.807, Test loss: 0.969, Test accuracy: 66.35
Round  50, Global train loss: 0.807, Global test loss: 1.407, Global test accuracy: 52.98
Round  51, Train loss: 0.651, Test loss: 0.979, Test accuracy: 66.27
Round  51, Global train loss: 0.651, Global test loss: 1.222, Global test accuracy: 59.06
Round  52, Train loss: 0.741, Test loss: 0.972, Test accuracy: 66.53
Round  52, Global train loss: 0.741, Global test loss: 1.249, Global test accuracy: 57.99
Round  53, Train loss: 0.794, Test loss: 0.969, Test accuracy: 66.76
Round  53, Global train loss: 0.794, Global test loss: 1.268, Global test accuracy: 55.66
Round  54, Train loss: 0.702, Test loss: 0.985, Test accuracy: 66.34
Round  54, Global train loss: 0.702, Global test loss: 1.407, Global test accuracy: 54.62
Round  55, Train loss: 0.656, Test loss: 0.984, Test accuracy: 66.21
Round  55, Global train loss: 0.656, Global test loss: 1.277, Global test accuracy: 58.21
Round  56, Train loss: 0.729, Test loss: 0.990, Test accuracy: 66.24
Round  56, Global train loss: 0.729, Global test loss: 1.289, Global test accuracy: 56.66
Round  57, Train loss: 0.664, Test loss: 0.985, Test accuracy: 66.22
Round  57, Global train loss: 0.664, Global test loss: 1.358, Global test accuracy: 54.99
Round  58, Train loss: 0.648, Test loss: 0.985, Test accuracy: 66.45
Round  58, Global train loss: 0.648, Global test loss: 1.227, Global test accuracy: 58.48
Round  59, Train loss: 0.735, Test loss: 0.988, Test accuracy: 66.39
Round  59, Global train loss: 0.735, Global test loss: 1.278, Global test accuracy: 56.61
Round  60, Train loss: 0.656, Test loss: 0.993, Test accuracy: 66.65
Round  60, Global train loss: 0.656, Global test loss: 1.388, Global test accuracy: 53.67
Round  61, Train loss: 0.623, Test loss: 1.000, Test accuracy: 66.63
Round  61, Global train loss: 0.623, Global test loss: 1.279, Global test accuracy: 57.04
Round  62, Train loss: 0.684, Test loss: 1.000, Test accuracy: 66.86
Round  62, Global train loss: 0.684, Global test loss: 1.339, Global test accuracy: 55.70
Round  63, Train loss: 0.649, Test loss: 1.003, Test accuracy: 67.14
Round  63, Global train loss: 0.649, Global test loss: 1.288, Global test accuracy: 58.01
Round  64, Train loss: 0.591, Test loss: 1.022, Test accuracy: 66.59
Round  64, Global train loss: 0.591, Global test loss: 1.288, Global test accuracy: 58.25
Round  65, Train loss: 0.608, Test loss: 1.014, Test accuracy: 67.26
Round  65, Global train loss: 0.608, Global test loss: 1.450, Global test accuracy: 54.28
Round  66, Train loss: 0.718, Test loss: 1.020, Test accuracy: 67.25
Round  66, Global train loss: 0.718, Global test loss: 1.355, Global test accuracy: 55.81
Round  67, Train loss: 0.630, Test loss: 1.014, Test accuracy: 67.57
Round  67, Global train loss: 0.630, Global test loss: 1.446, Global test accuracy: 54.01
Round  68, Train loss: 0.699, Test loss: 1.013, Test accuracy: 67.79
Round  68, Global train loss: 0.699, Global test loss: 1.388, Global test accuracy: 53.46
Round  69, Train loss: 0.658, Test loss: 0.993, Test accuracy: 67.90
Round  69, Global train loss: 0.658, Global test loss: 1.507, Global test accuracy: 51.12
Round  70, Train loss: 0.623, Test loss: 1.020, Test accuracy: 67.29
Round  70, Global train loss: 0.623, Global test loss: 1.414, Global test accuracy: 54.09
Round  71, Train loss: 0.607, Test loss: 1.018, Test accuracy: 67.02
Round  71, Global train loss: 0.607, Global test loss: 1.379, Global test accuracy: 55.58
Round  72, Train loss: 0.619, Test loss: 1.030, Test accuracy: 66.69
Round  72, Global train loss: 0.619, Global test loss: 1.314, Global test accuracy: 57.38
Round  73, Train loss: 0.569, Test loss: 1.047, Test accuracy: 66.14
Round  73, Global train loss: 0.569, Global test loss: 1.388, Global test accuracy: 56.94
Round  74, Train loss: 0.541, Test loss: 1.049, Test accuracy: 66.41
Round  74, Global train loss: 0.541, Global test loss: 1.320, Global test accuracy: 58.69
Round  75, Train loss: 0.622, Test loss: 1.076, Test accuracy: 65.97
Round  75, Global train loss: 0.622, Global test loss: 1.312, Global test accuracy: 58.68
Round  76, Train loss: 0.525, Test loss: 1.076, Test accuracy: 66.09
Round  76, Global train loss: 0.525, Global test loss: 1.358, Global test accuracy: 58.26
Round  77, Train loss: 0.540, Test loss: 1.072, Test accuracy: 66.37
Round  77, Global train loss: 0.540, Global test loss: 1.303, Global test accuracy: 59.43
Round  78, Train loss: 0.484, Test loss: 1.059, Test accuracy: 66.92
Round  78, Global train loss: 0.484, Global test loss: 1.343, Global test accuracy: 58.91
Round  79, Train loss: 0.526, Test loss: 1.054, Test accuracy: 67.05
Round  79, Global train loss: 0.526, Global test loss: 1.396, Global test accuracy: 56.64
Round  80, Train loss: 0.561, Test loss: 1.075, Test accuracy: 67.23
Round  80, Global train loss: 0.561, Global test loss: 1.321, Global test accuracy: 58.17
Round  81, Train loss: 0.520, Test loss: 1.084, Test accuracy: 67.09
Round  81, Global train loss: 0.520, Global test loss: 1.489, Global test accuracy: 56.02
Round  82, Train loss: 0.506, Test loss: 1.081, Test accuracy: 66.94
Round  82, Global train loss: 0.506, Global test loss: 1.312, Global test accuracy: 58.91
Round  83, Train loss: 0.544, Test loss: 1.088, Test accuracy: 67.13
Round  83, Global train loss: 0.544, Global test loss: 1.247, Global test accuracy: 59.81
Round  84, Train loss: 0.463, Test loss: 1.099, Test accuracy: 66.92
Round  84, Global train loss: 0.463, Global test loss: 1.395, Global test accuracy: 58.12
Round  85, Train loss: 0.571, Test loss: 1.098, Test accuracy: 67.36
Round  85, Global train loss: 0.571, Global test loss: 1.278, Global test accuracy: 59.77
Round  86, Train loss: 0.466, Test loss: 1.112, Test accuracy: 66.70
Round  86, Global train loss: 0.466, Global test loss: 1.445, Global test accuracy: 57.23
Round  87, Train loss: 0.448, Test loss: 1.115, Test accuracy: 66.69
Round  87, Global train loss: 0.448, Global test loss: 1.486, Global test accuracy: 56.00
Round  88, Train loss: 0.571, Test loss: 1.125, Test accuracy: 66.75
Round  88, Global train loss: 0.571, Global test loss: 1.457, Global test accuracy: 56.11
Round  89, Train loss: 0.494, Test loss: 1.138, Test accuracy: 66.47
Round  89, Global train loss: 0.494, Global test loss: 1.510, Global test accuracy: 53.92
Round  90, Train loss: 0.442, Test loss: 1.148, Test accuracy: 66.39
Round  90, Global train loss: 0.442, Global test loss: 1.394, Global test accuracy: 58.55
Round  91, Train loss: 0.630, Test loss: 1.134, Test accuracy: 66.78
Round  91, Global train loss: 0.630, Global test loss: 1.291, Global test accuracy: 58.54
Round  92, Train loss: 0.441, Test loss: 1.163, Test accuracy: 66.54
Round  92, Global train loss: 0.441, Global test loss: 1.436, Global test accuracy: 56.77/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  93, Train loss: 0.461, Test loss: 1.144, Test accuracy: 66.77
Round  93, Global train loss: 0.461, Global test loss: 1.407, Global test accuracy: 58.36
Round  94, Train loss: 0.562, Test loss: 1.132, Test accuracy: 66.88
Round  94, Global train loss: 0.562, Global test loss: 1.527, Global test accuracy: 54.29
Round  95, Train loss: 0.453, Test loss: 1.116, Test accuracy: 67.38
Round  95, Global train loss: 0.453, Global test loss: 1.268, Global test accuracy: 60.73
Round  96, Train loss: 0.545, Test loss: 1.101, Test accuracy: 67.71
Round  96, Global train loss: 0.545, Global test loss: 1.371, Global test accuracy: 58.18
Round  97, Train loss: 0.479, Test loss: 1.118, Test accuracy: 67.51
Round  97, Global train loss: 0.479, Global test loss: 1.373, Global test accuracy: 58.99
Round  98, Train loss: 0.463, Test loss: 1.146, Test accuracy: 67.33
Round  98, Global train loss: 0.463, Global test loss: 1.399, Global test accuracy: 58.26
Round  99, Train loss: 0.511, Test loss: 1.146, Test accuracy: 67.22
Round  99, Global train loss: 0.511, Global test loss: 1.469, Global test accuracy: 58.51
Final Round, Train loss: 0.398, Test loss: 1.186, Test accuracy: 67.15
Final Round, Global train loss: 0.398, Global test loss: 1.469, Global test accuracy: 58.51
Average accuracy final 10 rounds: 67.05099999999999 

Average global accuracy final 10 rounds: 58.118 

1610.6683971881866
[1.6077096462249756, 3.215419292449951, 4.560095548629761, 5.90477180480957, 7.248462438583374, 8.592153072357178, 9.944007635116577, 11.295862197875977, 12.633195400238037, 13.970528602600098, 15.308980464935303, 16.647432327270508, 17.980515241622925, 19.313598155975342, 20.650119066238403, 21.986639976501465, 23.322296857833862, 24.65795373916626, 25.99665403366089, 27.335354328155518, 28.67386031150818, 30.01236629486084, 31.347411394119263, 32.682456493377686, 34.01458382606506, 35.34671115875244, 36.681782722473145, 38.01685428619385, 39.35572361946106, 40.69459295272827, 42.030781984329224, 43.366971015930176, 44.70412874221802, 46.04128646850586, 47.38124132156372, 48.72119617462158, 50.06362342834473, 51.40605068206787, 52.740790128707886, 54.0755295753479, 55.4182288646698, 56.7609281539917, 58.10754108428955, 59.4541540145874, 60.79232716560364, 62.13050031661987, 63.46846628189087, 64.80643224716187, 66.14537286758423, 67.48431348800659, 68.82925844192505, 70.1742033958435, 71.51876616477966, 72.86332893371582, 74.20359492301941, 75.543860912323, 76.88386464118958, 78.22386837005615, 79.56104445457458, 80.89822053909302, 82.2395966053009, 83.58097267150879, 84.91257095336914, 86.24416923522949, 87.58071994781494, 88.91727066040039, 90.26025319099426, 91.60323572158813, 92.94210410118103, 94.28097248077393, 95.6216230392456, 96.96227359771729, 98.29792928695679, 99.63358497619629, 100.97881937026978, 102.32405376434326, 103.66384243965149, 105.00363111495972, 106.34214878082275, 107.68066644668579, 109.02085185050964, 110.3610372543335, 111.69859480857849, 113.03615236282349, 114.37019157409668, 115.70423078536987, 117.03945517539978, 118.37467956542969, 119.7196934223175, 121.06470727920532, 122.40486168861389, 123.74501609802246, 125.07989835739136, 126.41478061676025, 127.74724292755127, 129.07970523834229, 130.41060829162598, 131.74151134490967, 133.07666993141174, 134.41182851791382, 135.74844026565552, 137.08505201339722, 138.42327690124512, 139.76150178909302, 141.08363819122314, 142.40577459335327, 143.7212619781494, 145.03674936294556, 146.3717381954193, 147.70672702789307, 149.046728849411, 150.38673067092896, 151.7220332622528, 153.05733585357666, 154.39488244056702, 155.73242902755737, 157.07117414474487, 158.40991926193237, 159.7470200061798, 161.08412075042725, 162.42520928382874, 163.76629781723022, 165.10022401809692, 166.43415021896362, 167.78276371955872, 169.1313772201538, 170.47243070602417, 171.81348419189453, 173.1452853679657, 174.47708654403687, 175.80928254127502, 177.14147853851318, 178.4762372970581, 179.81099605560303, 181.1242959499359, 182.4375958442688, 183.82437586784363, 185.21115589141846, 186.52705812454224, 187.84296035766602, 189.10804653167725, 190.37313270568848, 191.68502736091614, 192.9969220161438, 194.24663186073303, 195.49634170532227, 196.74393773078918, 197.9915337562561, 199.29545831680298, 200.59938287734985, 201.81271886825562, 203.02605485916138, 204.32777309417725, 205.62949132919312, 206.88026642799377, 208.13104152679443, 209.42616629600525, 210.72129106521606, 211.98255610466003, 213.243821144104, 214.50524473190308, 215.76666831970215, 217.02139711380005, 218.27612590789795, 219.58740615844727, 220.89868640899658, 222.1522569656372, 223.40582752227783, 224.7275927066803, 226.04935789108276, 227.31742787361145, 228.58549785614014, 229.85593819618225, 231.12637853622437, 232.43329668045044, 233.7402148246765, 235.06199431419373, 236.38377380371094, 237.70684337615967, 239.0299129486084, 240.36286544799805, 241.6958179473877, 243.02507519721985, 244.354332447052, 245.67001104354858, 246.98568964004517, 248.30874276161194, 249.6317958831787, 250.96665692329407, 252.30151796340942, 253.63311576843262, 254.9647135734558, 256.2863817214966, 257.60804986953735, 258.9424841403961, 260.2769184112549, 261.60153102874756, 262.92614364624023, 264.2593038082123, 265.5924639701843, 268.25603890419006, 270.9196138381958]
[18.75, 18.75, 29.03, 29.03, 37.25, 37.25, 38.56, 38.56, 43.61, 43.61, 45.15, 45.15, 48.53, 48.53, 51.78, 51.78, 52.59, 52.59, 52.96, 52.96, 54.34, 54.34, 55.38, 55.38, 56.59, 56.59, 57.22, 57.22, 58.41, 58.41, 58.4, 58.4, 58.6, 58.6, 58.58, 58.58, 59.51, 59.51, 60.1, 60.1, 60.11, 60.11, 59.69, 59.69, 60.79, 60.79, 61.14, 61.14, 61.01, 61.01, 61.28, 61.28, 61.9, 61.9, 62.37, 62.37, 62.69, 62.69, 64.32, 64.32, 64.27, 64.27, 64.35, 64.35, 64.41, 64.41, 65.09, 65.09, 64.92, 64.92, 64.75, 64.75, 64.61, 64.61, 64.88, 64.88, 65.22, 65.22, 64.43, 64.43, 64.7, 64.7, 64.6, 64.6, 65.3, 65.3, 64.94, 64.94, 65.37, 65.37, 65.89, 65.89, 66.05, 66.05, 66.78, 66.78, 66.24, 66.24, 66.15, 66.15, 66.35, 66.35, 66.27, 66.27, 66.53, 66.53, 66.76, 66.76, 66.34, 66.34, 66.21, 66.21, 66.24, 66.24, 66.22, 66.22, 66.45, 66.45, 66.39, 66.39, 66.65, 66.65, 66.63, 66.63, 66.86, 66.86, 67.14, 67.14, 66.59, 66.59, 67.26, 67.26, 67.25, 67.25, 67.57, 67.57, 67.79, 67.79, 67.9, 67.9, 67.29, 67.29, 67.02, 67.02, 66.69, 66.69, 66.14, 66.14, 66.41, 66.41, 65.97, 65.97, 66.09, 66.09, 66.37, 66.37, 66.92, 66.92, 67.05, 67.05, 67.23, 67.23, 67.09, 67.09, 66.94, 66.94, 67.13, 67.13, 66.92, 66.92, 67.36, 67.36, 66.7, 66.7, 66.69, 66.69, 66.75, 66.75, 66.47, 66.47, 66.39, 66.39, 66.78, 66.78, 66.54, 66.54, 66.77, 66.77, 66.88, 66.88, 67.38, 67.38, 67.71, 67.71, 67.51, 67.51, 67.33, 67.33, 67.22, 67.22, 67.15, 67.15]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.6 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 7, noise    level: 0.4000 
   Client 18, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 15, noise    level: 0.4000 
   Client 11, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
   Client 13, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 10, noise    level: 0.4000 
   Client 14, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.950, Test loss: 2.187, Test accuracy: 19.42
Round   1, Train loss: 1.633, Test loss: 2.036, Test accuracy: 25.95
Round   2, Train loss: 1.570, Test loss: 1.683, Test accuracy: 33.97
Round   3, Train loss: 1.428, Test loss: 1.659, Test accuracy: 36.20
Round   4, Train loss: 1.423, Test loss: 1.465, Test accuracy: 43.42
Round   5, Train loss: 1.299, Test loss: 1.395, Test accuracy: 45.06
Round   6, Train loss: 1.266, Test loss: 1.298, Test accuracy: 47.88
Round   7, Train loss: 1.204, Test loss: 1.212, Test accuracy: 51.93
Round   8, Train loss: 1.166, Test loss: 1.191, Test accuracy: 52.44
Round   9, Train loss: 1.204, Test loss: 1.189, Test accuracy: 53.31
Round  10, Train loss: 1.124, Test loss: 1.183, Test accuracy: 52.88
Round  11, Train loss: 1.063, Test loss: 1.121, Test accuracy: 56.33
Round  12, Train loss: 1.130, Test loss: 1.118, Test accuracy: 56.46
Round  13, Train loss: 1.116, Test loss: 1.074, Test accuracy: 58.18
Round  14, Train loss: 1.162, Test loss: 1.069, Test accuracy: 57.70
Round  15, Train loss: 1.182, Test loss: 1.046, Test accuracy: 58.72
Round  16, Train loss: 1.057, Test loss: 1.045, Test accuracy: 59.32
Round  17, Train loss: 1.062, Test loss: 1.034, Test accuracy: 60.10
Round  18, Train loss: 1.099, Test loss: 1.018, Test accuracy: 60.35
Round  19, Train loss: 1.083, Test loss: 1.030, Test accuracy: 60.24
Round  20, Train loss: 1.106, Test loss: 1.030, Test accuracy: 60.46
Round  21, Train loss: 1.071, Test loss: 1.032, Test accuracy: 60.90
Round  22, Train loss: 0.995, Test loss: 0.980, Test accuracy: 61.61
Round  23, Train loss: 0.996, Test loss: 0.981, Test accuracy: 62.02
Round  24, Train loss: 1.015, Test loss: 0.980, Test accuracy: 62.50
Round  25, Train loss: 0.978, Test loss: 0.957, Test accuracy: 63.08
Round  26, Train loss: 0.997, Test loss: 0.967, Test accuracy: 62.76
Round  27, Train loss: 0.962, Test loss: 0.941, Test accuracy: 63.75
Round  28, Train loss: 0.920, Test loss: 0.942, Test accuracy: 63.65
Round  29, Train loss: 0.934, Test loss: 0.928, Test accuracy: 64.51
Round  30, Train loss: 0.943, Test loss: 0.923, Test accuracy: 64.65
Round  31, Train loss: 0.826, Test loss: 0.910, Test accuracy: 65.05
Round  32, Train loss: 0.950, Test loss: 0.917, Test accuracy: 65.28
Round  33, Train loss: 0.864, Test loss: 0.918, Test accuracy: 65.11
Round  34, Train loss: 0.874, Test loss: 0.904, Test accuracy: 65.69
Round  35, Train loss: 0.814, Test loss: 0.885, Test accuracy: 66.19
Round  36, Train loss: 0.848, Test loss: 0.890, Test accuracy: 66.39
Round  37, Train loss: 0.795, Test loss: 0.895, Test accuracy: 66.26
Round  38, Train loss: 0.843, Test loss: 0.877, Test accuracy: 66.64
Round  39, Train loss: 0.790, Test loss: 0.858, Test accuracy: 67.66
Round  40, Train loss: 0.887, Test loss: 0.854, Test accuracy: 67.74
Round  41, Train loss: 0.853, Test loss: 0.866, Test accuracy: 66.98
Round  42, Train loss: 0.842, Test loss: 0.858, Test accuracy: 67.45
Round  43, Train loss: 0.810, Test loss: 0.865, Test accuracy: 66.89
Round  44, Train loss: 0.789, Test loss: 0.868, Test accuracy: 66.78
Round  45, Train loss: 0.812, Test loss: 0.863, Test accuracy: 66.90
Round  46, Train loss: 0.864, Test loss: 0.836, Test accuracy: 68.38
Round  47, Train loss: 0.707, Test loss: 0.841, Test accuracy: 68.04
Round  48, Train loss: 0.769, Test loss: 0.844, Test accuracy: 67.94
Round  49, Train loss: 0.771, Test loss: 0.833, Test accuracy: 68.20
Round  50, Train loss: 0.900, Test loss: 0.823, Test accuracy: 68.97
Round  51, Train loss: 0.747, Test loss: 0.817, Test accuracy: 69.64
Round  52, Train loss: 0.782, Test loss: 0.818, Test accuracy: 69.08
Round  53, Train loss: 0.759, Test loss: 0.803, Test accuracy: 69.82
Round  54, Train loss: 0.860, Test loss: 0.824, Test accuracy: 69.41
Round  55, Train loss: 0.820, Test loss: 0.818, Test accuracy: 69.38
Round  56, Train loss: 0.655, Test loss: 0.796, Test accuracy: 70.04
Round  57, Train loss: 0.780, Test loss: 0.794, Test accuracy: 70.29
Round  58, Train loss: 0.666, Test loss: 0.809, Test accuracy: 69.65
Round  59, Train loss: 0.691, Test loss: 0.804, Test accuracy: 69.70
Round  60, Train loss: 0.656, Test loss: 0.807, Test accuracy: 70.07
Round  61, Train loss: 0.764, Test loss: 0.795, Test accuracy: 70.20
Round  62, Train loss: 0.780, Test loss: 0.807, Test accuracy: 69.68
Round  63, Train loss: 0.647, Test loss: 0.791, Test accuracy: 70.04
Round  64, Train loss: 0.681, Test loss: 0.795, Test accuracy: 70.14
Round  65, Train loss: 0.701, Test loss: 0.800, Test accuracy: 69.85
Round  66, Train loss: 0.701, Test loss: 0.786, Test accuracy: 70.68
Round  67, Train loss: 0.759, Test loss: 0.801, Test accuracy: 69.91
Round  68, Train loss: 0.701, Test loss: 0.799, Test accuracy: 70.37
Round  69, Train loss: 0.612, Test loss: 0.778, Test accuracy: 71.11
Round  70, Train loss: 0.679, Test loss: 0.800, Test accuracy: 70.16
Round  71, Train loss: 0.672, Test loss: 0.789, Test accuracy: 70.43
Round  72, Train loss: 0.725, Test loss: 0.786, Test accuracy: 70.34
Round  73, Train loss: 0.606, Test loss: 0.781, Test accuracy: 71.16
Round  74, Train loss: 0.585, Test loss: 0.771, Test accuracy: 71.58
Round  75, Train loss: 0.561, Test loss: 0.777, Test accuracy: 71.25
Round  76, Train loss: 0.689, Test loss: 0.775, Test accuracy: 71.32
Round  77, Train loss: 0.634, Test loss: 0.776, Test accuracy: 71.39
Round  78, Train loss: 0.681, Test loss: 0.775, Test accuracy: 71.26
Round  79, Train loss: 0.675, Test loss: 0.769, Test accuracy: 71.40
Round  80, Train loss: 0.722, Test loss: 0.769, Test accuracy: 71.99
Round  81, Train loss: 0.692, Test loss: 0.766, Test accuracy: 71.55
Round  82, Train loss: 0.616, Test loss: 0.775, Test accuracy: 71.45
Round  83, Train loss: 0.630, Test loss: 0.769, Test accuracy: 71.46
Round  84, Train loss: 0.613, Test loss: 0.752, Test accuracy: 72.39
Round  85, Train loss: 0.629, Test loss: 0.759, Test accuracy: 72.27
Round  86, Train loss: 0.544, Test loss: 0.757, Test accuracy: 72.23
Round  87, Train loss: 0.555, Test loss: 0.764, Test accuracy: 71.65
Round  88, Train loss: 0.603, Test loss: 0.762, Test accuracy: 72.17
Round  89, Train loss: 0.468, Test loss: 0.757, Test accuracy: 72.44
Round  90, Train loss: 0.574, Test loss: 0.759, Test accuracy: 72.14
Round  91, Train loss: 0.607, Test loss: 0.759, Test accuracy: 71.54
Round  92, Train loss: 0.504, Test loss: 0.763, Test accuracy: 71.73
Round  93, Train loss: 0.580, Test loss: 0.768, Test accuracy: 71.59
Round  94, Train loss: 0.563, Test loss: 0.772, Test accuracy: 71.60
Round  95, Train loss: 0.607, Test loss: 0.786, Test accuracy: 70.88
Round  96, Train loss: 0.628, Test loss: 0.751, Test accuracy: 72.63
Round  97, Train loss: 0.519, Test loss: 0.753, Test accuracy: 72.16
Round  98, Train loss: 0.534, Test loss: 0.766, Test accuracy: 72.14
Round  99, Train loss: 0.507, Test loss: 0.753, Test accuracy: 72.34
Final Round, Train loss: 0.508, Test loss: 0.762, Test accuracy: 72.31
Average accuracy final 10 rounds: 71.875
2054.6203560829163
[3.326915740966797, 6.326907396316528, 9.40352201461792, 12.47932243347168, 15.478405237197876, 18.481542825698853, 21.53816294670105, 24.562440156936646, 27.558269739151, 30.53509831428528, 33.54131484031677, 36.54525089263916, 39.54548168182373, 42.55585479736328, 45.543556451797485, 48.541321992874146, 51.556286334991455, 54.55010628700256, 57.54340314865112, 60.55325436592102, 63.55635857582092, 66.5870840549469, 69.5830647945404, 72.61200618743896, 75.62453413009644, 78.6440851688385, 81.64224123954773, 84.67223930358887, 87.6708550453186, 90.66849446296692, 93.68249154090881, 96.68563055992126, 99.71471858024597, 102.71461033821106, 105.7576231956482, 108.76024031639099, 111.76040387153625, 114.73523306846619, 117.70873355865479, 120.68455815315247, 123.56221652030945, 126.46226119995117, 129.3521649837494, 132.266122341156, 135.16683053970337, 138.06736040115356, 140.96507811546326, 143.84210085868835, 146.73434710502625, 149.628573179245, 152.5239520072937, 155.41674327850342, 158.30355167388916, 161.18606090545654, 164.09749674797058, 166.97225046157837, 169.8425714969635, 172.74925875663757, 175.62461686134338, 178.515784740448, 181.4030909538269, 184.31642603874207, 187.18748903274536, 190.07456493377686, 192.99969291687012, 195.92060375213623, 198.63455939292908, 201.49792671203613, 204.379563331604, 207.22357368469238, 210.09392929077148, 212.95209455490112, 215.79359602928162, 218.66188216209412, 221.52186918258667, 224.38282561302185, 227.23097205162048, 230.1216766834259, 232.98193049430847, 235.81965017318726, 238.70926427841187, 241.4537341594696, 244.29345178604126, 247.1072599887848, 249.8508665561676, 252.59240198135376, 255.34600734710693, 258.1571669578552, 260.9014050960541, 263.6389675140381, 266.51198744773865, 269.3892226219177, 272.0903272628784, 274.91626381874084, 277.6566343307495, 280.40699887275696, 283.19853830337524, 286.08055233955383, 288.94840908050537, 291.81807136535645, 295.9327838420868]
[19.42, 25.95, 33.97, 36.2, 43.42, 45.06, 47.88, 51.93, 52.44, 53.31, 52.88, 56.33, 56.46, 58.18, 57.7, 58.72, 59.32, 60.1, 60.35, 60.24, 60.46, 60.9, 61.61, 62.02, 62.5, 63.08, 62.76, 63.75, 63.65, 64.51, 64.65, 65.05, 65.28, 65.11, 65.69, 66.19, 66.39, 66.26, 66.64, 67.66, 67.74, 66.98, 67.45, 66.89, 66.78, 66.9, 68.38, 68.04, 67.94, 68.2, 68.97, 69.64, 69.08, 69.82, 69.41, 69.38, 70.04, 70.29, 69.65, 69.7, 70.07, 70.2, 69.68, 70.04, 70.14, 69.85, 70.68, 69.91, 70.37, 71.11, 70.16, 70.43, 70.34, 71.16, 71.58, 71.25, 71.32, 71.39, 71.26, 71.4, 71.99, 71.55, 71.45, 71.46, 72.39, 72.27, 72.23, 71.65, 72.17, 72.44, 72.14, 71.54, 71.73, 71.59, 71.6, 70.88, 72.63, 72.16, 72.14, 72.34, 72.31]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 19, noise    level: 0.4000 
   Client 14, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 17, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 12, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 18, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 15, noise    level: 0.4000 
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  16.7100
Round 1 global test acc  17.9200
Round 2 global test acc  20.1500
Round 3 global test acc  24.4900
Round 4 global test acc  24.0900
Round 5 global test acc  26.2700
Round 6 global test acc  28.7000
Round 7 global test acc  22.9400
Round 8 global test acc  27.1800
Round 9 global test acc  27.8900
Round 10 global test acc  29.6100
Round 11 global test acc  39.4500
Round 12 global test acc  33.3600
Round 13 global test acc  33.0900
Round 14 global test acc  31.4600
Round 15 global test acc  32.9000
Round 16 global test acc  37.1700
Round 17 global test acc  35.5900
Round 18 global test acc  35.4200
Round 19 global test acc  33.2900
Round 20 global test acc  32.2000
Round 21 global test acc  34.2000
Round 22 global test acc  30.9900
Round 23 global test acc  32.5000
Round 24 global test acc  39.0200
Round 25 global test acc  36.7300
Round 26 global test acc  35.9000
Round 27 global test acc  32.2700
Round 28 global test acc  35.7200
Round 29 global test acc  30.8800
Round 30 global test acc  32.1100
Round 31 global test acc  39.9700
Round 32 global test acc  32.3900
Round 33 global test acc  37.3200
Round 34 global test acc  37.4900
Round 35 global test acc  32.6000
Round 36 global test acc  33.0400
Round 37 global test acc  37.0900
Round 38 global test acc  42.4800
Round 39 global test acc  38.9400
Round 40 global test acc  42.8200
Round 41 global test acc  36.9400
Round 42 global test acc  38.6900
Round 43 global test acc  35.6100
Round 44 global test acc  37.9700
Round 45 global test acc  38.5100
Round 46 global test acc  45.3700
Round 47 global test acc  39.2700
Round 48 global test acc  39.8200
Round 49 global test acc  42.0100
Round 50 global test acc  39.0600
Round 51 global test acc  40.2100
Round 52 global test acc  45.8900
Round 53 global test acc  41.8100
Round 54 global test acc  38.3000
Round 55 global test acc  33.0000
Round 56 global test acc  40.7300
Round 57 global test acc  39.1100
Round 58 global test acc  39.5800
Round 59 global test acc  43.6200
Round 60 global test acc  36.7300
Round 61 global test acc  40.0400
Round 62 global test acc  40.5800
Round 63 global test acc  42.1300
Round 64 global test acc  44.1000
Round 65 global test acc  48.2700
Round 66 global test acc  34.9200
Round 67 global test acc  39.2900
Round 68 global test acc  42.7800
Round 69 global test acc  39.1500
Round 70 global test acc  37.5100
Round 71 global test acc  40.9200
Round 72 global test acc  38.6400
Round 73 global test acc  45.4300
Round 74 global test acc  47.5000
Round 75 global test acc  39.7400
Round 76 global test acc  40.1600
Round 77 global test acc  39.9100
Round 78 global test acc  46.7500
Round 79 global test acc  36.0300
Round 80 global test acc  32.8700
Round 81 global test acc  30.0800
Round 82 global test acc  32.3200
Round 83 global test acc  32.0600
Round 84 global test acc  30.1600
Round 85 global test acc  28.0800
Round 86 global test acc  26.8100
Round 87 global test acc  26.6500
Round 88 global test acc  26.3000
Round 89 global test acc  25.5600
Round 90 global test acc  24.9500
Round 91 global test acc  24.6600
Round 92 global test acc  24.9000
Round 93 global test acc  25.1000
Round 94 global test acc  24.7200
Round 95 global test acc  23.8500
Round 96 global test acc  23.3200
Round 97 global test acc  23.0600
Round 98 global test acc  22.7200
Round 99 global test acc  21.8200
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 4, noise    level: 0.4000 
   Client 14, noise    level: 0.4000 
   Client 19, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 16, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 17, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
   Client 18, noise    level: 0.4000 
   Client 13, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.961, Test loss: 2.146, Test accuracy: 19.30
Round   1, Train loss: 1.638, Test loss: 1.968, Test accuracy: 27.82
Round   2, Train loss: 1.504, Test loss: 1.576, Test accuracy: 37.72
Round   3, Train loss: 1.421, Test loss: 1.552, Test accuracy: 40.23
Round   4, Train loss: 1.358, Test loss: 1.358, Test accuracy: 47.46
Round   5, Train loss: 1.245, Test loss: 1.312, Test accuracy: 47.82
Round   6, Train loss: 1.265, Test loss: 1.231, Test accuracy: 49.71
Round   7, Train loss: 1.198, Test loss: 1.158, Test accuracy: 53.75
Round   8, Train loss: 1.176, Test loss: 1.144, Test accuracy: 54.29
Round   9, Train loss: 1.217, Test loss: 1.116, Test accuracy: 55.40
Round  10, Train loss: 1.136, Test loss: 1.095, Test accuracy: 56.36
Round  11, Train loss: 1.136, Test loss: 1.085, Test accuracy: 57.43
Round  12, Train loss: 1.109, Test loss: 1.042, Test accuracy: 59.44
Round  13, Train loss: 1.028, Test loss: 1.009, Test accuracy: 61.24
Round  14, Train loss: 1.059, Test loss: 1.015, Test accuracy: 60.75
Round  15, Train loss: 1.101, Test loss: 0.988, Test accuracy: 61.26
Round  16, Train loss: 1.110, Test loss: 1.001, Test accuracy: 61.16
Round  17, Train loss: 1.043, Test loss: 0.985, Test accuracy: 61.78
Round  18, Train loss: 1.076, Test loss: 0.969, Test accuracy: 62.22
Round  19, Train loss: 1.029, Test loss: 0.958, Test accuracy: 62.90
Round  20, Train loss: 1.021, Test loss: 0.960, Test accuracy: 62.60
Round  21, Train loss: 0.972, Test loss: 0.952, Test accuracy: 62.66
Round  22, Train loss: 0.975, Test loss: 0.924, Test accuracy: 64.15
Round  23, Train loss: 0.942, Test loss: 0.923, Test accuracy: 64.99
Round  24, Train loss: 1.037, Test loss: 0.939, Test accuracy: 64.34
Round  25, Train loss: 0.944, Test loss: 0.922, Test accuracy: 65.21
Round  26, Train loss: 0.946, Test loss: 0.911, Test accuracy: 64.81
Round  27, Train loss: 0.877, Test loss: 0.877, Test accuracy: 66.50
Round  28, Train loss: 0.975, Test loss: 0.887, Test accuracy: 66.81
Round  29, Train loss: 0.890, Test loss: 0.877, Test accuracy: 66.87
Round  30, Train loss: 0.921, Test loss: 0.870, Test accuracy: 67.36
Round  31, Train loss: 0.828, Test loss: 0.849, Test accuracy: 67.75
Round  32, Train loss: 0.955, Test loss: 0.866, Test accuracy: 67.38
Round  33, Train loss: 0.815, Test loss: 0.854, Test accuracy: 67.29
Round  34, Train loss: 0.833, Test loss: 0.858, Test accuracy: 67.30
Round  35, Train loss: 0.811, Test loss: 0.832, Test accuracy: 68.11
Round  36, Train loss: 0.838, Test loss: 0.850, Test accuracy: 67.58
Round  37, Train loss: 0.798, Test loss: 0.831, Test accuracy: 68.01
Round  38, Train loss: 0.784, Test loss: 0.820, Test accuracy: 68.90
Round  39, Train loss: 0.726, Test loss: 0.826, Test accuracy: 68.92
Round  40, Train loss: 0.854, Test loss: 0.818, Test accuracy: 69.34
Round  41, Train loss: 0.798, Test loss: 0.821, Test accuracy: 68.94
Round  42, Train loss: 0.841, Test loss: 0.807, Test accuracy: 69.48
Round  43, Train loss: 0.738, Test loss: 0.806, Test accuracy: 69.83
Round  44, Train loss: 0.770, Test loss: 0.804, Test accuracy: 69.49
Round  45, Train loss: 0.828, Test loss: 0.797, Test accuracy: 70.15
Round  46, Train loss: 0.714, Test loss: 0.788, Test accuracy: 70.19
Round  47, Train loss: 0.663, Test loss: 0.787, Test accuracy: 70.39
Round  48, Train loss: 0.658, Test loss: 0.792, Test accuracy: 70.46
Round  49, Train loss: 0.673, Test loss: 0.777, Test accuracy: 71.15
Round  50, Train loss: 0.855, Test loss: 0.781, Test accuracy: 70.55
Round  51, Train loss: 0.617, Test loss: 0.772, Test accuracy: 70.96
Round  52, Train loss: 0.737, Test loss: 0.781, Test accuracy: 70.59
Round  53, Train loss: 0.654, Test loss: 0.772, Test accuracy: 71.01
Round  54, Train loss: 0.703, Test loss: 0.770, Test accuracy: 71.06
Round  55, Train loss: 0.788, Test loss: 0.766, Test accuracy: 71.23
Round  56, Train loss: 0.614, Test loss: 0.763, Test accuracy: 71.39
Round  57, Train loss: 0.704, Test loss: 0.755, Test accuracy: 71.61
Round  58, Train loss: 0.692, Test loss: 0.757, Test accuracy: 71.93
Round  59, Train loss: 0.690, Test loss: 0.761, Test accuracy: 71.34
Round  60, Train loss: 0.659, Test loss: 0.757, Test accuracy: 71.43
Round  61, Train loss: 0.689, Test loss: 0.751, Test accuracy: 72.21
Round  62, Train loss: 0.651, Test loss: 0.751, Test accuracy: 71.96
Round  63, Train loss: 0.680, Test loss: 0.744, Test accuracy: 72.50
Round  64, Train loss: 0.604, Test loss: 0.747, Test accuracy: 72.10
Round  65, Train loss: 0.674, Test loss: 0.753, Test accuracy: 72.31
Round  66, Train loss: 0.727, Test loss: 0.747, Test accuracy: 72.25
Round  67, Train loss: 0.712, Test loss: 0.749, Test accuracy: 72.31
Round  68, Train loss: 0.659, Test loss: 0.753, Test accuracy: 71.59
Round  69, Train loss: 0.600, Test loss: 0.753, Test accuracy: 71.82
Round  70, Train loss: 0.679, Test loss: 0.750, Test accuracy: 72.23
Round  71, Train loss: 0.583, Test loss: 0.752, Test accuracy: 72.10
Round  72, Train loss: 0.633, Test loss: 0.740, Test accuracy: 72.76
Round  73, Train loss: 0.642, Test loss: 0.748, Test accuracy: 72.60
Round  74, Train loss: 0.562, Test loss: 0.743, Test accuracy: 72.51
Round  75, Train loss: 0.578, Test loss: 0.746, Test accuracy: 72.49
Round  76, Train loss: 0.638, Test loss: 0.742, Test accuracy: 72.77
Round  77, Train loss: 0.614, Test loss: 0.737, Test accuracy: 72.72
Round  78, Train loss: 0.617, Test loss: 0.737, Test accuracy: 72.86
Round  79, Train loss: 0.518, Test loss: 0.744, Test accuracy: 72.33
Round  80, Train loss: 0.648, Test loss: 0.738, Test accuracy: 73.01
Round  81, Train loss: 0.660, Test loss: 0.739, Test accuracy: 73.15
Round  82, Train loss: 0.497, Test loss: 0.735, Test accuracy: 72.93
Round  83, Train loss: 0.603, Test loss: 0.743, Test accuracy: 72.55
Round  84, Train loss: 0.585, Test loss: 0.733, Test accuracy: 73.14
Round  85, Train loss: 0.639, Test loss: 0.741, Test accuracy: 73.05
Round  86, Train loss: 0.482, Test loss: 0.735, Test accuracy: 73.41
Round  87, Train loss: 0.476, Test loss: 0.730, Test accuracy: 73.36
Round  88, Train loss: 0.591, Test loss: 0.737, Test accuracy: 73.03
Round  89, Train loss: 0.466, Test loss: 0.737, Test accuracy: 73.07
Round  90, Train loss: 0.532, Test loss: 0.739, Test accuracy: 73.05
Round  91, Train loss: 0.631, Test loss: 0.733, Test accuracy: 73.35
Round  92, Train loss: 0.488, Test loss: 0.736, Test accuracy: 73.41
Round  93, Train loss: 0.473, Test loss: 0.732, Test accuracy: 73.54
Round  94, Train loss: 0.551, Test loss: 0.733, Test accuracy: 73.20
Round  95, Train loss: 0.505, Test loss: 0.733, Test accuracy: 73.43
Round  96, Train loss: 0.543, Test loss: 0.739, Test accuracy: 73.36
Round  97, Train loss: 0.492, Test loss: 0.731, Test accuracy: 73.44
Round  98, Train loss: 0.576, Test loss: 0.747, Test accuracy: 73.23
Round  99, Train loss: 0.489, Test loss: 0.736, Test accuracy: 73.52
Final Round, Train loss: 0.466, Test loss: 0.730, Test accuracy: 73.57
Average accuracy final 10 rounds: 73.35300000000001
1039.700003862381
[1.6546239852905273, 2.988884449005127, 4.330941915512085, 5.667859315872192, 7.0011467933654785, 8.338423728942871, 9.638545274734497, 10.925944805145264, 12.202122211456299, 13.481459856033325, 14.767186641693115, 16.05582618713379, 17.337347745895386, 18.61985158920288, 19.90338659286499, 21.1765456199646, 22.464242458343506, 23.76975440979004, 25.07504415512085, 26.378353118896484, 27.68096661567688, 28.972545623779297, 30.258384466171265, 31.557422399520874, 32.85407781600952, 34.15617489814758, 35.454561710357666, 36.753281354904175, 38.05266785621643, 39.34455466270447, 40.64734435081482, 41.947941303253174, 43.244812965393066, 44.541444063186646, 45.844813108444214, 47.14296364784241, 48.44216823577881, 49.74010443687439, 51.04299783706665, 52.3424232006073, 53.6358323097229, 54.93447971343994, 56.23194408416748, 57.533329248428345, 58.815818786621094, 60.115129470825195, 61.41532063484192, 62.71847653388977, 64.01529502868652, 65.31142520904541, 66.60553503036499, 67.88578867912292, 69.18848323822021, 70.48136568069458, 71.78252005577087, 73.08706569671631, 74.38860726356506, 75.68515968322754, 76.97400236129761, 78.27891969680786, 79.57819414138794, 80.87610602378845, 82.18061709403992, 83.47985577583313, 84.78094267845154, 86.07448554039001, 87.37564754486084, 88.6827917098999, 89.99538826942444, 91.30057501792908, 92.60546708106995, 93.90675282478333, 95.21591901779175, 96.5067126750946, 97.83318400382996, 99.14464926719666, 100.45892524719238, 101.77094388008118, 103.07538080215454, 104.37392330169678, 105.6536054611206, 106.94988536834717, 108.24683451652527, 109.41901779174805, 110.59058547019958, 111.7606418132782, 112.93137216567993, 114.10201954841614, 115.2696123123169, 116.4404845237732, 117.610276222229, 118.78529739379883, 119.9603590965271, 121.13931560516357, 122.3201105594635, 123.49169373512268, 124.6647720336914, 125.84000253677368, 127.01711082458496, 128.19299817085266, 130.1163854598999]
[19.3, 27.82, 37.72, 40.23, 47.46, 47.82, 49.71, 53.75, 54.29, 55.4, 56.36, 57.43, 59.44, 61.24, 60.75, 61.26, 61.16, 61.78, 62.22, 62.9, 62.6, 62.66, 64.15, 64.99, 64.34, 65.21, 64.81, 66.5, 66.81, 66.87, 67.36, 67.75, 67.38, 67.29, 67.3, 68.11, 67.58, 68.01, 68.9, 68.92, 69.34, 68.94, 69.48, 69.83, 69.49, 70.15, 70.19, 70.39, 70.46, 71.15, 70.55, 70.96, 70.59, 71.01, 71.06, 71.23, 71.39, 71.61, 71.93, 71.34, 71.43, 72.21, 71.96, 72.5, 72.1, 72.31, 72.25, 72.31, 71.59, 71.82, 72.23, 72.1, 72.76, 72.6, 72.51, 72.49, 72.77, 72.72, 72.86, 72.33, 73.01, 73.15, 72.93, 72.55, 73.14, 73.05, 73.41, 73.36, 73.03, 73.07, 73.05, 73.35, 73.41, 73.54, 73.2, 73.43, 73.36, 73.44, 73.23, 73.52, 73.57]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.6 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 2, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 15, noise    level: 0.4000 
   Client 18, noise    level: 0.4000 
   Client 17, noise    level: 0.4000 
   Client 16, noise    level: 0.4000 
   Client 11, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 12, noise    level: 0.4000 
   Client 10, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.939, Test loss: 2.126, Test accuracy: 20.08
Round   1, Train loss: 1.666, Test loss: 1.963, Test accuracy: 28.85
Round   2, Train loss: 1.522, Test loss: 1.623, Test accuracy: 37.88
Round   3, Train loss: 1.457, Test loss: 1.566, Test accuracy: 40.13
Round   4, Train loss: 1.442, Test loss: 1.390, Test accuracy: 46.67
Round   5, Train loss: 1.358, Test loss: 1.359, Test accuracy: 47.70
Round   6, Train loss: 1.277, Test loss: 1.274, Test accuracy: 49.17
Round   7, Train loss: 1.217, Test loss: 1.176, Test accuracy: 52.35
Round   8, Train loss: 1.181, Test loss: 1.157, Test accuracy: 54.37
Round   9, Train loss: 1.256, Test loss: 1.166, Test accuracy: 53.98
Round  10, Train loss: 1.158, Test loss: 1.135, Test accuracy: 54.95
Round  11, Train loss: 1.079, Test loss: 1.085, Test accuracy: 56.12
Round  12, Train loss: 1.088, Test loss: 1.063, Test accuracy: 57.61
Round  13, Train loss: 1.104, Test loss: 1.034, Test accuracy: 59.89
Round  14, Train loss: 1.179, Test loss: 1.025, Test accuracy: 59.92
Round  15, Train loss: 1.136, Test loss: 1.010, Test accuracy: 61.01
Round  16, Train loss: 1.124, Test loss: 1.003, Test accuracy: 60.03
Round  17, Train loss: 0.990, Test loss: 0.990, Test accuracy: 60.63
Round  18, Train loss: 1.102, Test loss: 0.981, Test accuracy: 61.53
Round  19, Train loss: 1.105, Test loss: 0.969, Test accuracy: 62.38
Round  20, Train loss: 1.086, Test loss: 0.979, Test accuracy: 62.19
Round  21, Train loss: 1.034, Test loss: 0.970, Test accuracy: 62.66
Round  22, Train loss: 0.972, Test loss: 0.944, Test accuracy: 63.43
Round  23, Train loss: 0.914, Test loss: 0.954, Test accuracy: 63.17
Round  24, Train loss: 1.020, Test loss: 0.941, Test accuracy: 64.17
Round  25, Train loss: 1.017, Test loss: 0.924, Test accuracy: 64.27
Round  26, Train loss: 1.052, Test loss: 0.936, Test accuracy: 64.36
Round  27, Train loss: 0.995, Test loss: 0.902, Test accuracy: 65.46
Round  28, Train loss: 0.953, Test loss: 0.892, Test accuracy: 65.80
Round  29, Train loss: 0.903, Test loss: 0.879, Test accuracy: 66.10
Round  30, Train loss: 0.945, Test loss: 0.877, Test accuracy: 66.26
Round  31, Train loss: 0.825, Test loss: 0.864, Test accuracy: 66.65
Round  32, Train loss: 0.939, Test loss: 0.864, Test accuracy: 67.20
Round  33, Train loss: 0.796, Test loss: 0.875, Test accuracy: 65.92
Round  34, Train loss: 0.784, Test loss: 0.864, Test accuracy: 66.87
Round  35, Train loss: 0.729, Test loss: 0.856, Test accuracy: 66.88
Round  36, Train loss: 0.926, Test loss: 0.853, Test accuracy: 66.69
Round  37, Train loss: 0.759, Test loss: 0.861, Test accuracy: 66.68
Round  38, Train loss: 0.797, Test loss: 0.852, Test accuracy: 67.48
Round  39, Train loss: 0.805, Test loss: 0.837, Test accuracy: 67.63
Round  40, Train loss: 0.930, Test loss: 0.846, Test accuracy: 67.56
Round  41, Train loss: 0.847, Test loss: 0.836, Test accuracy: 67.83
Round  42, Train loss: 0.776, Test loss: 0.826, Test accuracy: 68.19
Round  43, Train loss: 0.761, Test loss: 0.818, Test accuracy: 68.50
Round  44, Train loss: 0.827, Test loss: 0.825, Test accuracy: 68.41
Round  45, Train loss: 0.795, Test loss: 0.824, Test accuracy: 68.21
Round  46, Train loss: 0.795, Test loss: 0.823, Test accuracy: 68.52
Round  47, Train loss: 0.700, Test loss: 0.811, Test accuracy: 68.56
Round  48, Train loss: 0.709, Test loss: 0.809, Test accuracy: 69.07
Round  49, Train loss: 0.728, Test loss: 0.800, Test accuracy: 69.47
Round  50, Train loss: 0.869, Test loss: 0.806, Test accuracy: 69.67
Round  51, Train loss: 0.659, Test loss: 0.795, Test accuracy: 69.87
Round  52, Train loss: 0.804, Test loss: 0.793, Test accuracy: 70.41
Round  53, Train loss: 0.732, Test loss: 0.790, Test accuracy: 70.33
Round  54, Train loss: 0.743, Test loss: 0.788, Test accuracy: 70.49
Round  55, Train loss: 0.805, Test loss: 0.770, Test accuracy: 71.09
Round  56, Train loss: 0.671, Test loss: 0.772, Test accuracy: 70.87
Round  57, Train loss: 0.845, Test loss: 0.786, Test accuracy: 70.55
Round  58, Train loss: 0.661, Test loss: 0.783, Test accuracy: 70.74
Round  59, Train loss: 0.681, Test loss: 0.776, Test accuracy: 70.78
Round  60, Train loss: 0.662, Test loss: 0.778, Test accuracy: 70.86
Round  61, Train loss: 0.795, Test loss: 0.779, Test accuracy: 71.06
Round  62, Train loss: 0.686, Test loss: 0.768, Test accuracy: 71.47
Round  63, Train loss: 0.679, Test loss: 0.765, Test accuracy: 71.51
Round  64, Train loss: 0.653, Test loss: 0.775, Test accuracy: 71.05
Round  65, Train loss: 0.777, Test loss: 0.769, Test accuracy: 71.21
Round  66, Train loss: 0.664, Test loss: 0.767, Test accuracy: 71.57
Round  67, Train loss: 0.808, Test loss: 0.762, Test accuracy: 72.10
Round  68, Train loss: 0.651, Test loss: 0.761, Test accuracy: 72.16
Round  69, Train loss: 0.649, Test loss: 0.770, Test accuracy: 71.53
Round  70, Train loss: 0.641, Test loss: 0.765, Test accuracy: 71.73
Round  71, Train loss: 0.603, Test loss: 0.761, Test accuracy: 71.19
Round  72, Train loss: 0.745, Test loss: 0.783, Test accuracy: 71.13
Round  73, Train loss: 0.594, Test loss: 0.767, Test accuracy: 71.64
Round  74, Train loss: 0.546, Test loss: 0.752, Test accuracy: 72.16
Round  75, Train loss: 0.540, Test loss: 0.762, Test accuracy: 71.83
Round  76, Train loss: 0.662, Test loss: 0.753, Test accuracy: 72.60
Round  77, Train loss: 0.582, Test loss: 0.758, Test accuracy: 72.11
Round  78, Train loss: 0.605, Test loss: 0.757, Test accuracy: 72.38
Round  79, Train loss: 0.545, Test loss: 0.752, Test accuracy: 72.21
Round  80, Train loss: 0.678, Test loss: 0.753, Test accuracy: 71.95
Round  81, Train loss: 0.713, Test loss: 0.754, Test accuracy: 72.32
Round  82, Train loss: 0.551, Test loss: 0.752, Test accuracy: 72.48
Round  83, Train loss: 0.694, Test loss: 0.742, Test accuracy: 72.72
Round  84, Train loss: 0.676, Test loss: 0.753, Test accuracy: 72.68
Round  85, Train loss: 0.666, Test loss: 0.760, Test accuracy: 72.05
Round  86, Train loss: 0.417, Test loss: 0.757, Test accuracy: 72.06
Round  87, Train loss: 0.496, Test loss: 0.745, Test accuracy: 73.07
Round  88, Train loss: 0.593, Test loss: 0.754, Test accuracy: 72.64
Round  89, Train loss: 0.437, Test loss: 0.756, Test accuracy: 72.30
Round  90, Train loss: 0.575, Test loss: 0.752, Test accuracy: 72.76
Round  91, Train loss: 0.646, Test loss: 0.754, Test accuracy: 72.59
Round  92, Train loss: 0.508, Test loss: 0.757, Test accuracy: 72.40
Round  93, Train loss: 0.500, Test loss: 0.758, Test accuracy: 72.81
Round  94, Train loss: 0.580, Test loss: 0.763, Test accuracy: 72.25
Round  95, Train loss: 0.520, Test loss: 0.753, Test accuracy: 72.55
Round  96, Train loss: 0.641, Test loss: 0.750, Test accuracy: 73.00
Round  97, Train loss: 0.498, Test loss: 0.743, Test accuracy: 73.29
Round  98, Train loss: 0.546, Test loss: 0.753, Test accuracy: 72.65
Round  99, Train loss: 0.436, Test loss: 0.755, Test accuracy: 72.86
Final Round, Train loss: 0.321, Test loss: 0.758, Test accuracy: 72.99
Average accuracy final 10 rounds: 72.71600000000001
1546.8656113147736
[1.7244987487792969, 3.127232551574707, 4.541194915771484, 5.949150562286377, 7.355524778366089, 8.764246225357056, 10.16298770904541, 11.568550825119019, 12.980332374572754, 14.388147592544556, 15.799459457397461, 17.207438945770264, 18.615639686584473, 20.022109270095825, 21.421772480010986, 22.816012859344482, 24.2138454914093, 25.611233472824097, 27.006345510482788, 28.387973070144653, 29.78192639350891, 32.21882081031799, 34.657652854919434, 37.07988166809082, 39.48055934906006, 41.89704251289368, 44.32460641860962, 46.746387004852295, 49.16959834098816, 51.59962248802185, 54.03893685340881, 56.4479033946991, 58.87689733505249, 61.28547787666321, 63.70924401283264, 66.12653589248657, 68.56126737594604, 70.99019622802734, 73.42103147506714, 75.86778283119202, 78.30479264259338, 80.74153256416321, 83.15517020225525, 85.59114170074463, 88.02261209487915, 90.43158841133118, 92.8125102519989, 95.24569535255432, 97.70781230926514, 100.1411874294281, 102.57534742355347, 105.01914429664612, 107.43996405601501, 109.87835693359375, 112.32155275344849, 114.70840048789978, 117.08969163894653, 119.47874450683594, 121.86938214302063, 124.18686318397522, 126.63199257850647, 129.06081318855286, 131.52267861366272, 133.9671928882599, 136.42720913887024, 138.79651522636414, 141.17462468147278, 143.64579963684082, 146.10823512077332, 148.56118845939636, 150.99087572097778, 153.43882536888123, 155.8937361240387, 158.33649468421936, 160.6826741695404, 162.9607219696045, 165.2394106388092, 167.5127682685852, 169.78930401802063, 172.075092792511, 174.28896141052246, 176.5693221092224, 178.85380244255066, 181.13225865364075, 183.40814185142517, 185.67437028884888, 187.9511754512787, 190.22788095474243, 192.50679421424866, 194.7719647884369, 197.03833627700806, 199.48095870018005, 201.74642634391785, 204.02347588539124, 206.29868078231812, 208.5611321926117, 210.84991669654846, 213.1242434978485, 215.40063977241516, 217.67527222633362, 219.6723074913025]
[20.08, 28.85, 37.88, 40.13, 46.67, 47.7, 49.17, 52.35, 54.37, 53.98, 54.95, 56.12, 57.61, 59.89, 59.92, 61.01, 60.03, 60.63, 61.53, 62.38, 62.19, 62.66, 63.43, 63.17, 64.17, 64.27, 64.36, 65.46, 65.8, 66.1, 66.26, 66.65, 67.2, 65.92, 66.87, 66.88, 66.69, 66.68, 67.48, 67.63, 67.56, 67.83, 68.19, 68.5, 68.41, 68.21, 68.52, 68.56, 69.07, 69.47, 69.67, 69.87, 70.41, 70.33, 70.49, 71.09, 70.87, 70.55, 70.74, 70.78, 70.86, 71.06, 71.47, 71.51, 71.05, 71.21, 71.57, 72.1, 72.16, 71.53, 71.73, 71.19, 71.13, 71.64, 72.16, 71.83, 72.6, 72.11, 72.38, 72.21, 71.95, 72.32, 72.48, 72.72, 72.68, 72.05, 72.06, 73.07, 72.64, 72.3, 72.76, 72.59, 72.4, 72.81, 72.25, 72.55, 73.0, 73.29, 72.65, 72.86, 72.99]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: none, level_n_system: 0.6 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 17, noise    level: 0.4000 
   Client 15, noise    level: 0.4000 
   Client 18, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 16, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 11, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.987, Test loss: 1.886, Test accuracy: 29.33
Round   1, Train loss: 1.595, Test loss: 1.456, Test accuracy: 38.94
Round   2, Train loss: 1.461, Test loss: 1.365, Test accuracy: 43.13
Round   3, Train loss: 1.386, Test loss: 1.271, Test accuracy: 48.03
Round   4, Train loss: 1.316, Test loss: 1.202, Test accuracy: 50.71
Round   5, Train loss: 1.266, Test loss: 1.157, Test accuracy: 52.79
Round   6, Train loss: 1.227, Test loss: 1.130, Test accuracy: 54.75
Round   7, Train loss: 1.199, Test loss: 1.105, Test accuracy: 55.62
Round   8, Train loss: 1.173, Test loss: 1.073, Test accuracy: 57.32
Round   9, Train loss: 1.154, Test loss: 1.055, Test accuracy: 58.00
Round  10, Train loss: 1.133, Test loss: 1.040, Test accuracy: 58.50
Round  11, Train loss: 1.114, Test loss: 1.025, Test accuracy: 59.96
Round  12, Train loss: 1.100, Test loss: 1.015, Test accuracy: 59.58
Round  13, Train loss: 1.088, Test loss: 0.997, Test accuracy: 60.96
Round  14, Train loss: 1.071, Test loss: 0.991, Test accuracy: 61.02
Round  15, Train loss: 1.059, Test loss: 0.979, Test accuracy: 61.77
Round  16, Train loss: 1.045, Test loss: 0.970, Test accuracy: 62.23
Round  17, Train loss: 1.029, Test loss: 0.951, Test accuracy: 62.38
Round  18, Train loss: 1.020, Test loss: 0.951, Test accuracy: 63.11
Round  19, Train loss: 1.005, Test loss: 0.939, Test accuracy: 63.65
Round  20, Train loss: 1.009, Test loss: 0.933, Test accuracy: 63.95
Round  21, Train loss: 0.953, Test loss: 0.925, Test accuracy: 64.03
Round  22, Train loss: 0.977, Test loss: 0.925, Test accuracy: 64.24
Round  23, Train loss: 1.067, Test loss: 0.914, Test accuracy: 64.34
Round  24, Train loss: 1.002, Test loss: 0.909, Test accuracy: 64.73
Round  25, Train loss: 0.943, Test loss: 0.903, Test accuracy: 65.26
Round  26, Train loss: 0.985, Test loss: 0.901, Test accuracy: 65.39
Round  27, Train loss: 0.919, Test loss: 0.896, Test accuracy: 65.68
Round  28, Train loss: 0.948, Test loss: 0.890, Test accuracy: 65.81
Round  29, Train loss: 0.916, Test loss: 0.896, Test accuracy: 65.58
Round  30, Train loss: 1.002, Test loss: 0.863, Test accuracy: 66.98
Round  31, Train loss: 0.796, Test loss: 0.861, Test accuracy: 67.64
Round  32, Train loss: 1.053, Test loss: 0.851, Test accuracy: 67.85
Round  33, Train loss: 0.877, Test loss: 0.854, Test accuracy: 67.78
Round  34, Train loss: 0.790, Test loss: 0.852, Test accuracy: 67.81
Round  35, Train loss: 0.740, Test loss: 0.852, Test accuracy: 67.14
Round  36, Train loss: 0.851, Test loss: 0.843, Test accuracy: 67.83
Round  37, Train loss: 0.825, Test loss: 0.836, Test accuracy: 68.21
Round  38, Train loss: 0.759, Test loss: 0.828, Test accuracy: 68.40
Round  39, Train loss: 0.700, Test loss: 0.832, Test accuracy: 68.79
Round  40, Train loss: 0.825, Test loss: 0.824, Test accuracy: 68.84
Round  41, Train loss: 0.798, Test loss: 0.823, Test accuracy: 68.65
Round  42, Train loss: 0.835, Test loss: 0.814, Test accuracy: 69.10
Round  43, Train loss: 0.782, Test loss: 0.815, Test accuracy: 68.95
Round  44, Train loss: 0.861, Test loss: 0.816, Test accuracy: 69.00
Round  45, Train loss: 0.778, Test loss: 0.812, Test accuracy: 69.18
Round  46, Train loss: 0.784, Test loss: 0.818, Test accuracy: 69.21
Round  47, Train loss: 0.776, Test loss: 0.801, Test accuracy: 69.83
Round  48, Train loss: 0.707, Test loss: 0.813, Test accuracy: 68.80
Round  49, Train loss: 0.724, Test loss: 0.820, Test accuracy: 69.18
Round  50, Train loss: 0.895, Test loss: 0.792, Test accuracy: 70.14
Round  51, Train loss: 0.584, Test loss: 0.785, Test accuracy: 70.08
Round  52, Train loss: 0.697, Test loss: 0.778, Test accuracy: 70.52
Round  53, Train loss: 0.776, Test loss: 0.779, Test accuracy: 70.51
Round  54, Train loss: 0.799, Test loss: 0.787, Test accuracy: 70.44
Round  55, Train loss: 0.780, Test loss: 0.789, Test accuracy: 70.01
Round  56, Train loss: 0.660, Test loss: 0.789, Test accuracy: 69.86
Round  57, Train loss: 0.756, Test loss: 0.786, Test accuracy: 70.03
Round  58, Train loss: 0.714, Test loss: 0.773, Test accuracy: 70.86
Round  59, Train loss: 0.735, Test loss: 0.779, Test accuracy: 70.52
Round  60, Train loss: 0.745, Test loss: 0.783, Test accuracy: 70.54
Round  61, Train loss: 0.697, Test loss: 0.786, Test accuracy: 70.44
Round  62, Train loss: 0.722, Test loss: 0.784, Test accuracy: 70.33
Round  63, Train loss: 0.671, Test loss: 0.778, Test accuracy: 70.78
Round  64, Train loss: 0.583, Test loss: 0.780, Test accuracy: 70.51
Round  65, Train loss: 0.588, Test loss: 0.784, Test accuracy: 70.52
Round  66, Train loss: 0.761, Test loss: 0.777, Test accuracy: 71.12
Round  67, Train loss: 0.727, Test loss: 0.782, Test accuracy: 70.95
Round  68, Train loss: 0.702, Test loss: 0.789, Test accuracy: 70.48
Round  69, Train loss: 0.649, Test loss: 0.787, Test accuracy: 70.74
Round  70, Train loss: 0.663, Test loss: 0.784, Test accuracy: 71.10
Round  71, Train loss: 0.621, Test loss: 0.778, Test accuracy: 71.43
Round  72, Train loss: 0.631, Test loss: 0.773, Test accuracy: 71.85
Round  73, Train loss: 0.634, Test loss: 0.782, Test accuracy: 71.26
Round  74, Train loss: 0.537, Test loss: 0.771, Test accuracy: 71.23
Round  75, Train loss: 0.578, Test loss: 0.785, Test accuracy: 70.83
Round  76, Train loss: 0.590, Test loss: 0.766, Test accuracy: 71.50
Round  77, Train loss: 0.593, Test loss: 0.764, Test accuracy: 71.58
Round  78, Train loss: 0.602, Test loss: 0.760, Test accuracy: 71.84
Round  79, Train loss: 0.556, Test loss: 0.765, Test accuracy: 71.58
Round  80, Train loss: 0.443, Test loss: 0.760, Test accuracy: 71.91
Round  81, Train loss: 0.427, Test loss: 0.757, Test accuracy: 72.26
Round  82, Train loss: 0.417, Test loss: 0.761, Test accuracy: 71.96
Round  83, Train loss: 0.407, Test loss: 0.760, Test accuracy: 72.17
Round  84, Train loss: 0.398, Test loss: 0.763, Test accuracy: 71.71
Round  85, Train loss: 0.390, Test loss: 0.767, Test accuracy: 71.99
Round  86, Train loss: 0.378, Test loss: 0.762, Test accuracy: 72.02
Round  87, Train loss: 0.371, Test loss: 0.765, Test accuracy: 71.80
Round  88, Train loss: 0.361, Test loss: 0.767, Test accuracy: 72.15
Round  89, Train loss: 0.356, Test loss: 0.781, Test accuracy: 71.60
Round  90, Train loss: 0.349, Test loss: 0.770, Test accuracy: 72.01
Round  91, Train loss: 0.354, Test loss: 0.776, Test accuracy: 71.87
Round  92, Train loss: 0.342, Test loss: 0.781, Test accuracy: 71.79
Round  93, Train loss: 0.337, Test loss: 0.781, Test accuracy: 71.38
Round  94, Train loss: 0.329, Test loss: 0.779, Test accuracy: 71.94
Round  95, Train loss: 0.327, Test loss: 0.785, Test accuracy: 71.63
Round  96, Train loss: 0.314, Test loss: 0.781, Test accuracy: 72.20
Round  97, Train loss: 0.308, Test loss: 0.783, Test accuracy: 71.73
Round  98, Train loss: 0.312, Test loss: 0.785, Test accuracy: 71.76
Round  99, Train loss: 0.298, Test loss: 0.784, Test accuracy: 72.08
Final Round, Train loss: 0.238, Test loss: 0.788, Test accuracy: 72.23
Average accuracy final 10 rounds: 71.839
1501.032015800476
[1.6511707305908203, 2.992231845855713, 4.317600250244141, 5.6444432735443115, 6.973021507263184, 8.294045686721802, 9.622497797012329, 10.950288772583008, 12.276520729064941, 13.59501576423645, 14.902841329574585, 16.22406029701233, 17.54988408088684, 18.87377619743347, 20.1982262134552, 21.498245239257812, 22.805391311645508, 24.120131015777588, 25.435473918914795, 26.75078821182251, 28.066327571868896, 29.379148483276367, 30.687881469726562, 32.001155614852905, 33.31314754486084, 34.627537965774536, 35.93873572349548, 37.25182127952576, 38.569416522979736, 39.890373945236206, 41.216318130493164, 42.52365183830261, 43.85210657119751, 45.17935919761658, 46.508246660232544, 47.841620683670044, 49.17432236671448, 50.51400446891785, 51.83942532539368, 53.16554069519043, 54.48026633262634, 55.80687236785889, 57.13089871406555, 58.44474673271179, 59.733710050582886, 61.04547643661499, 62.35987186431885, 63.66852903366089, 64.95455551147461, 66.26816534996033, 67.58644342422485, 68.8978943824768, 70.19936966896057, 71.51666975021362, 72.8339171409607, 74.14839148521423, 75.45293474197388, 76.77529764175415, 78.08809614181519, 79.4078369140625, 80.70253920555115, 82.01892757415771, 83.33556461334229, 84.65553712844849, 85.95480537414551, 87.27372145652771, 88.5865888595581, 89.90085935592651, 91.18852090835571, 92.50072574615479, 93.81380581855774, 95.1326789855957, 96.43135666847229, 97.75076937675476, 99.06536769866943, 100.38112497329712, 101.69273209571838, 103.00956463813782, 104.32588028907776, 105.64229130744934, 106.95794558525085, 108.27356195449829, 109.59040880203247, 110.90717959403992, 112.22466850280762, 113.53607130050659, 114.8484697341919, 116.16473364830017, 117.48199534416199, 118.80177021026611, 120.10843539237976, 121.41702198982239, 122.72732663154602, 123.92250680923462, 125.09341096878052, 126.26610040664673, 127.43600845336914, 128.61529517173767, 129.79844045639038, 130.96675968170166, 132.8814070224762]
[29.33, 38.94, 43.13, 48.03, 50.71, 52.79, 54.75, 55.62, 57.32, 58.0, 58.5, 59.96, 59.58, 60.96, 61.02, 61.77, 62.23, 62.38, 63.11, 63.65, 63.95, 64.03, 64.24, 64.34, 64.73, 65.26, 65.39, 65.68, 65.81, 65.58, 66.98, 67.64, 67.85, 67.78, 67.81, 67.14, 67.83, 68.21, 68.4, 68.79, 68.84, 68.65, 69.1, 68.95, 69.0, 69.18, 69.21, 69.83, 68.8, 69.18, 70.14, 70.08, 70.52, 70.51, 70.44, 70.01, 69.86, 70.03, 70.86, 70.52, 70.54, 70.44, 70.33, 70.78, 70.51, 70.52, 71.12, 70.95, 70.48, 70.74, 71.1, 71.43, 71.85, 71.26, 71.23, 70.83, 71.5, 71.58, 71.84, 71.58, 71.91, 72.26, 71.96, 72.17, 71.71, 71.99, 72.02, 71.8, 72.15, 71.6, 72.01, 71.87, 71.79, 71.38, 71.94, 71.63, 72.2, 71.73, 71.76, 72.08, 72.23]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.6 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 16, noise    level: 0.4000 
   Client 19, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
   Client 11, noise    level: 0.4000 
   Client 14, noise    level: 0.4000 
   Client 13, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 12, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.989, Test loss: 1.925, Test accuracy: 21.59
Round   1, Train loss: 1.637, Test loss: 1.490, Test accuracy: 39.43
Round   2, Train loss: 1.481, Test loss: 1.363, Test accuracy: 42.82
Round   3, Train loss: 1.397, Test loss: 1.262, Test accuracy: 49.38
Round   4, Train loss: 1.320, Test loss: 1.181, Test accuracy: 53.16
Round   5, Train loss: 1.264, Test loss: 1.135, Test accuracy: 54.90
Round   6, Train loss: 1.223, Test loss: 1.112, Test accuracy: 56.12
Round   7, Train loss: 1.195, Test loss: 1.079, Test accuracy: 57.29
Round   8, Train loss: 1.168, Test loss: 1.058, Test accuracy: 58.50
Round   9, Train loss: 1.147, Test loss: 1.043, Test accuracy: 59.42
Round  10, Train loss: 1.128, Test loss: 1.025, Test accuracy: 60.16
Round  11, Train loss: 1.112, Test loss: 1.006, Test accuracy: 60.92
Round  12, Train loss: 1.093, Test loss: 0.992, Test accuracy: 61.30
Round  13, Train loss: 1.078, Test loss: 0.977, Test accuracy: 62.00
Round  14, Train loss: 1.065, Test loss: 0.977, Test accuracy: 62.01
Round  15, Train loss: 1.051, Test loss: 0.962, Test accuracy: 62.91
Round  16, Train loss: 1.038, Test loss: 0.951, Test accuracy: 63.30
Round  17, Train loss: 1.023, Test loss: 0.933, Test accuracy: 63.88
Round  18, Train loss: 1.007, Test loss: 0.931, Test accuracy: 64.31
Round  19, Train loss: 0.993, Test loss: 0.913, Test accuracy: 64.96
Round  20, Train loss: 1.031, Test loss: 0.913, Test accuracy: 65.22
Round  21, Train loss: 0.963, Test loss: 0.917, Test accuracy: 64.54
Round  22, Train loss: 0.961, Test loss: 0.904, Test accuracy: 65.01
Round  23, Train loss: 0.928, Test loss: 0.893, Test accuracy: 65.84
Round  24, Train loss: 1.007, Test loss: 0.885, Test accuracy: 66.72
Round  25, Train loss: 0.982, Test loss: 0.881, Test accuracy: 65.96
Round  26, Train loss: 0.938, Test loss: 0.873, Test accuracy: 66.45
Round  27, Train loss: 0.902, Test loss: 0.877, Test accuracy: 66.31
Round  28, Train loss: 0.935, Test loss: 0.862, Test accuracy: 67.04
Round  29, Train loss: 0.904, Test loss: 0.855, Test accuracy: 67.61
Round  30, Train loss: 0.914, Test loss: 0.841, Test accuracy: 67.54
Round  31, Train loss: 0.786, Test loss: 0.838, Test accuracy: 68.02
Round  32, Train loss: 0.951, Test loss: 0.830, Test accuracy: 68.83
Round  33, Train loss: 0.791, Test loss: 0.832, Test accuracy: 68.38
Round  34, Train loss: 0.809, Test loss: 0.827, Test accuracy: 68.89
Round  35, Train loss: 0.726, Test loss: 0.827, Test accuracy: 68.39
Round  36, Train loss: 0.857, Test loss: 0.823, Test accuracy: 69.10
Round  37, Train loss: 0.724, Test loss: 0.824, Test accuracy: 68.82
Round  38, Train loss: 0.821, Test loss: 0.812, Test accuracy: 69.39
Round  39, Train loss: 0.757, Test loss: 0.806, Test accuracy: 70.02
Round  40, Train loss: 0.845, Test loss: 0.810, Test accuracy: 68.97
Round  41, Train loss: 0.774, Test loss: 0.809, Test accuracy: 69.26
Round  42, Train loss: 0.783, Test loss: 0.795, Test accuracy: 69.84
Round  43, Train loss: 0.774, Test loss: 0.798, Test accuracy: 70.09
Round  44, Train loss: 0.749, Test loss: 0.805, Test accuracy: 69.92
Round  45, Train loss: 0.742, Test loss: 0.805, Test accuracy: 69.62
Round  46, Train loss: 0.792, Test loss: 0.794, Test accuracy: 70.07
Round  47, Train loss: 0.652, Test loss: 0.793, Test accuracy: 70.32
Round  48, Train loss: 0.713, Test loss: 0.782, Test accuracy: 71.07
Round  49, Train loss: 0.754, Test loss: 0.784, Test accuracy: 70.87
Round  50, Train loss: 0.816, Test loss: 0.782, Test accuracy: 71.03
Round  51, Train loss: 0.701, Test loss: 0.777, Test accuracy: 70.75
Round  52, Train loss: 0.728, Test loss: 0.774, Test accuracy: 70.75
Round  53, Train loss: 0.708, Test loss: 0.765, Test accuracy: 71.28
Round  54, Train loss: 0.782, Test loss: 0.769, Test accuracy: 71.15
Round  55, Train loss: 0.788, Test loss: 0.759, Test accuracy: 71.89
Round  56, Train loss: 0.588, Test loss: 0.755, Test accuracy: 71.67
Round  57, Train loss: 0.779, Test loss: 0.760, Test accuracy: 71.91
Round  58, Train loss: 0.643, Test loss: 0.759, Test accuracy: 71.70
Round  59, Train loss: 0.617, Test loss: 0.755, Test accuracy: 72.02
Round  60, Train loss: 0.631, Test loss: 0.759, Test accuracy: 71.63
Round  61, Train loss: 0.725, Test loss: 0.771, Test accuracy: 71.49
Round  62, Train loss: 0.706, Test loss: 0.763, Test accuracy: 71.79
Round  63, Train loss: 0.601, Test loss: 0.754, Test accuracy: 71.78
Round  64, Train loss: 0.619, Test loss: 0.754, Test accuracy: 71.95
Round  65, Train loss: 0.663, Test loss: 0.757, Test accuracy: 72.27
Round  66, Train loss: 0.682, Test loss: 0.756, Test accuracy: 72.11
Round  67, Train loss: 0.717, Test loss: 0.753, Test accuracy: 72.27
Round  68, Train loss: 0.642, Test loss: 0.743, Test accuracy: 72.54
Round  69, Train loss: 0.617, Test loss: 0.740, Test accuracy: 72.69
Round  70, Train loss: 0.627, Test loss: 0.755, Test accuracy: 72.31
Round  71, Train loss: 0.591, Test loss: 0.755, Test accuracy: 72.71
Round  72, Train loss: 0.627, Test loss: 0.749, Test accuracy: 72.77
Round  73, Train loss: 0.594, Test loss: 0.753, Test accuracy: 72.61
Round  74, Train loss: 0.525, Test loss: 0.755, Test accuracy: 72.55
Round  75, Train loss: 0.486, Test loss: 0.746, Test accuracy: 72.69
Round  76, Train loss: 0.641, Test loss: 0.748, Test accuracy: 72.84
Round  77, Train loss: 0.632, Test loss: 0.748, Test accuracy: 73.07
Round  78, Train loss: 0.581, Test loss: 0.743, Test accuracy: 73.11
Round  79, Train loss: 0.545, Test loss: 0.743, Test accuracy: 72.96
Round  80, Train loss: 0.456, Test loss: 0.732, Test accuracy: 73.02
Round  81, Train loss: 0.430, Test loss: 0.729, Test accuracy: 73.72
Round  82, Train loss: 0.418, Test loss: 0.732, Test accuracy: 73.16
Round  83, Train loss: 0.410, Test loss: 0.733, Test accuracy: 73.30
Round  84, Train loss: 0.392, Test loss: 0.735, Test accuracy: 73.40
Round  85, Train loss: 0.383, Test loss: 0.739, Test accuracy: 73.31
Round  86, Train loss: 0.378, Test loss: 0.743, Test accuracy: 73.44
Round  87, Train loss: 0.366, Test loss: 0.747, Test accuracy: 73.36
Round  88, Train loss: 0.368, Test loss: 0.760, Test accuracy: 73.10
Round  89, Train loss: 0.353, Test loss: 0.762, Test accuracy: 73.34
Round  90, Train loss: 0.352, Test loss: 0.753, Test accuracy: 73.47
Round  91, Train loss: 0.352, Test loss: 0.752, Test accuracy: 73.49
Round  92, Train loss: 0.333, Test loss: 0.766, Test accuracy: 73.22
Round  93, Train loss: 0.329, Test loss: 0.762, Test accuracy: 73.41
Round  94, Train loss: 0.317, Test loss: 0.769, Test accuracy: 72.95
Round  95, Train loss: 0.319, Test loss: 0.773, Test accuracy: 73.22
Round  96, Train loss: 0.310, Test loss: 0.778, Test accuracy: 73.05
Round  97, Train loss: 0.308, Test loss: 0.782, Test accuracy: 73.05
Round  98, Train loss: 0.304, Test loss: 0.788, Test accuracy: 72.70
Round  99, Train loss: 0.293, Test loss: 0.792, Test accuracy: 72.66
Final Round, Train loss: 0.224, Test loss: 0.798, Test accuracy: 72.59
Average accuracy final 10 rounds: 73.122
2135.4656212329865
[1.674365758895874, 3.0696656703948975, 4.467111587524414, 5.867462873458862, 7.267071008682251, 8.662477016448975, 10.064403533935547, 11.459816932678223, 12.862192630767822, 14.256812334060669, 15.655596017837524, 17.04973316192627, 18.458030223846436, 19.857364416122437, 21.27633786201477, 22.684102773666382, 24.0868718624115, 25.49521565437317, 26.889129638671875, 28.286962509155273, 29.677651166915894, 32.08077049255371, 34.467745542526245, 36.847877502441406, 39.22652506828308, 41.59412407875061, 43.99698448181152, 46.39159870147705, 48.78934693336487, 51.18712306022644, 53.58457612991333, 55.98255205154419, 58.37386608123779, 60.775951623916626, 63.17128896713257, 65.56104516983032, 67.95456337928772, 70.34581303596497, 72.72922992706299, 75.11240553855896, 77.49571418762207, 79.8826813697815, 82.26638078689575, 84.66311168670654, 87.06209301948547, 89.44065546989441, 91.82231593132019, 94.18995809555054, 96.56238651275635, 98.94400882720947, 101.32571458816528, 103.7434470653534, 106.1608304977417, 108.58113074302673, 110.9968159198761, 113.41886115074158, 115.8288950920105, 118.24551749229431, 120.6676721572876, 123.07715272903442, 125.475900888443, 127.87551355361938, 130.2777614593506, 132.6791455745697, 135.08051705360413, 137.49655079841614, 139.91237497329712, 142.3247721195221, 144.73840641975403, 147.13874197006226, 149.54713678359985, 151.95728731155396, 154.3710105419159, 156.77521872520447, 159.2024745941162, 161.60082244873047, 164.01579356193542, 166.42351031303406, 168.83510732650757, 171.24566793441772, 173.6465654373169, 176.04685640335083, 178.45113563537598, 180.84901976585388, 183.23069667816162, 185.64045310020447, 188.09299778938293, 190.48749351501465, 192.8627188205719, 195.2410855293274, 197.6202847957611, 200.0179204940796, 202.42025685310364, 204.8171467781067, 207.2041473388672, 209.59307503700256, 211.986323595047, 214.38926649093628, 216.79055905342102, 219.19082951545715, 221.26484990119934]
[21.59, 39.43, 42.82, 49.38, 53.16, 54.9, 56.12, 57.29, 58.5, 59.42, 60.16, 60.92, 61.3, 62.0, 62.01, 62.91, 63.3, 63.88, 64.31, 64.96, 65.22, 64.54, 65.01, 65.84, 66.72, 65.96, 66.45, 66.31, 67.04, 67.61, 67.54, 68.02, 68.83, 68.38, 68.89, 68.39, 69.1, 68.82, 69.39, 70.02, 68.97, 69.26, 69.84, 70.09, 69.92, 69.62, 70.07, 70.32, 71.07, 70.87, 71.03, 70.75, 70.75, 71.28, 71.15, 71.89, 71.67, 71.91, 71.7, 72.02, 71.63, 71.49, 71.79, 71.78, 71.95, 72.27, 72.11, 72.27, 72.54, 72.69, 72.31, 72.71, 72.77, 72.61, 72.55, 72.69, 72.84, 73.07, 73.11, 72.96, 73.02, 73.72, 73.16, 73.3, 73.4, 73.31, 73.44, 73.36, 73.1, 73.34, 73.47, 73.49, 73.22, 73.41, 72.95, 73.22, 73.05, 73.05, 72.7, 72.66, 72.59]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.6 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 18, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
   Client 17, noise    level: 0.8000 
   Client 16, noise    level: 0.8000 
   Client 14, noise    level: 0.8000 
   Client 11, noise    level: 0.8000 
   Client 13, noise    level: 0.8000 
   Client 12, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.715, Test loss: 2.113, Test accuracy: 10.57
Round   0, Global train loss: 1.715, Global test loss: 2.302, Global test accuracy: 8.00
Round   1, Train loss: 1.643, Test loss: 1.991, Test accuracy: 24.39
Round   1, Global train loss: 1.643, Global test loss: 2.334, Global test accuracy: 18.60
Round   2, Train loss: 1.588, Test loss: 1.717, Test accuracy: 31.29
Round   2, Global train loss: 1.588, Global test loss: 2.196, Global test accuracy: 21.66
Round   3, Train loss: 1.576, Test loss: 1.542, Test accuracy: 36.81
Round   3, Global train loss: 1.576, Global test loss: 2.118, Global test accuracy: 24.49
Round   4, Train loss: 1.569, Test loss: 1.526, Test accuracy: 36.05
Round   4, Global train loss: 1.569, Global test loss: 2.230, Global test accuracy: 20.79
Round   5, Train loss: 1.434, Test loss: 1.477, Test accuracy: 36.76
Round   5, Global train loss: 1.434, Global test loss: 2.064, Global test accuracy: 23.78
Round   6, Train loss: 1.465, Test loss: 1.441, Test accuracy: 38.45
Round   6, Global train loss: 1.465, Global test loss: 2.159, Global test accuracy: 21.78
Round   7, Train loss: 1.495, Test loss: 1.433, Test accuracy: 39.41
Round   7, Global train loss: 1.495, Global test loss: 2.270, Global test accuracy: 15.69
Round   8, Train loss: 1.425, Test loss: 1.422, Test accuracy: 40.42
Round   8, Global train loss: 1.425, Global test loss: 2.074, Global test accuracy: 25.54
Round   9, Train loss: 1.443, Test loss: 1.405, Test accuracy: 40.81
Round   9, Global train loss: 1.443, Global test loss: 2.211, Global test accuracy: 19.12
Round  10, Train loss: 1.402, Test loss: 1.396, Test accuracy: 41.89
Round  10, Global train loss: 1.402, Global test loss: 2.125, Global test accuracy: 21.73
Round  11, Train loss: 1.273, Test loss: 1.391, Test accuracy: 41.88
Round  11, Global train loss: 1.273, Global test loss: 2.096, Global test accuracy: 24.78
Round  12, Train loss: 1.461, Test loss: 1.395, Test accuracy: 41.49
Round  12, Global train loss: 1.461, Global test loss: 2.241, Global test accuracy: 21.55
Round  13, Train loss: 1.590, Test loss: 1.392, Test accuracy: 41.57
Round  13, Global train loss: 1.590, Global test loss: 2.370, Global test accuracy: 24.60
Round  14, Train loss: 1.219, Test loss: 1.386, Test accuracy: 42.48
Round  14, Global train loss: 1.219, Global test loss: 2.213, Global test accuracy: 26.74
Round  15, Train loss: 1.336, Test loss: 1.393, Test accuracy: 42.62
Round  15, Global train loss: 1.336, Global test loss: 2.082, Global test accuracy: 28.89
Round  16, Train loss: 1.564, Test loss: 1.379, Test accuracy: 42.73
Round  16, Global train loss: 1.564, Global test loss: 2.228, Global test accuracy: 23.57
Round  17, Train loss: 1.093, Test loss: 1.368, Test accuracy: 43.39
Round  17, Global train loss: 1.093, Global test loss: 2.026, Global test accuracy: 25.84
Round  18, Train loss: 1.472, Test loss: 1.367, Test accuracy: 44.36
Round  18, Global train loss: 1.472, Global test loss: 2.199, Global test accuracy: 19.39
Round  19, Train loss: 1.220, Test loss: 1.354, Test accuracy: 45.00
Round  19, Global train loss: 1.220, Global test loss: 2.042, Global test accuracy: 27.63
Round  20, Train loss: 1.300, Test loss: 1.368, Test accuracy: 44.76
Round  20, Global train loss: 1.300, Global test loss: 2.163, Global test accuracy: 29.55
Round  21, Train loss: 1.011, Test loss: 1.360, Test accuracy: 44.96
Round  21, Global train loss: 1.011, Global test loss: 1.993, Global test accuracy: 24.15
Round  22, Train loss: 1.267, Test loss: 1.357, Test accuracy: 44.77
Round  22, Global train loss: 1.267, Global test loss: 2.095, Global test accuracy: 27.18
Round  23, Train loss: 1.082, Test loss: 1.363, Test accuracy: 44.50
Round  23, Global train loss: 1.082, Global test loss: 2.027, Global test accuracy: 25.75
Round  24, Train loss: 1.413, Test loss: 1.363, Test accuracy: 44.46
Round  24, Global train loss: 1.413, Global test loss: 2.183, Global test accuracy: 20.45
Round  25, Train loss: 1.045, Test loss: 1.390, Test accuracy: 44.37
Round  25, Global train loss: 1.045, Global test loss: 2.029, Global test accuracy: 35.16
Round  26, Train loss: 1.223, Test loss: 1.388, Test accuracy: 44.53
Round  26, Global train loss: 1.223, Global test loss: 2.262, Global test accuracy: 14.47
Round  27, Train loss: 1.214, Test loss: 1.399, Test accuracy: 44.20
Round  27, Global train loss: 1.214, Global test loss: 2.157, Global test accuracy: 16.35
Round  28, Train loss: 1.125, Test loss: 1.394, Test accuracy: 44.11
Round  28, Global train loss: 1.125, Global test loss: 2.067, Global test accuracy: 28.46
Round  29, Train loss: 1.416, Test loss: 1.393, Test accuracy: 44.05
Round  29, Global train loss: 1.416, Global test loss: 2.144, Global test accuracy: 21.33
Round  30, Train loss: 1.079, Test loss: 1.429, Test accuracy: 44.20
Round  30, Global train loss: 1.079, Global test loss: 1.933, Global test accuracy: 32.26
Round  31, Train loss: 1.002, Test loss: 1.430, Test accuracy: 43.78
Round  31, Global train loss: 1.002, Global test loss: 2.033, Global test accuracy: 29.40
Round  32, Train loss: 1.316, Test loss: 1.437, Test accuracy: 43.22
Round  32, Global train loss: 1.316, Global test loss: 2.239, Global test accuracy: 10.10
Round  33, Train loss: 1.315, Test loss: 1.443, Test accuracy: 42.82
Round  33, Global train loss: 1.315, Global test loss: 2.148, Global test accuracy: 19.31
Round  34, Train loss: 0.932, Test loss: 1.443, Test accuracy: 43.14
Round  34, Global train loss: 0.932, Global test loss: 1.971, Global test accuracy: 32.65
Round  35, Train loss: 1.229, Test loss: 1.453, Test accuracy: 43.39
Round  35, Global train loss: 1.229, Global test loss: 2.193, Global test accuracy: 17.05
Round  36, Train loss: 1.305, Test loss: 1.465, Test accuracy: 42.98
Round  36, Global train loss: 1.305, Global test loss: 2.225, Global test accuracy: 20.79
Round  37, Train loss: 0.862, Test loss: 1.473, Test accuracy: 43.15
Round  37, Global train loss: 0.862, Global test loss: 1.971, Global test accuracy: 29.04
Round  38, Train loss: 1.197, Test loss: 1.468, Test accuracy: 43.23
Round  38, Global train loss: 1.197, Global test loss: 2.099, Global test accuracy: 27.70
Round  39, Train loss: 0.879, Test loss: 1.491, Test accuracy: 42.74
Round  39, Global train loss: 0.879, Global test loss: 2.043, Global test accuracy: 28.69
Round  40, Train loss: 0.543, Test loss: 1.506, Test accuracy: 43.23
Round  40, Global train loss: 0.543, Global test loss: 1.812, Global test accuracy: 36.40
Round  41, Train loss: 1.028, Test loss: 1.527, Test accuracy: 42.85
Round  41, Global train loss: 1.028, Global test loss: 2.126, Global test accuracy: 23.12
Round  42, Train loss: 0.919, Test loss: 1.560, Test accuracy: 41.90
Round  42, Global train loss: 0.919, Global test loss: 2.053, Global test accuracy: 23.64
Round  43, Train loss: 0.805, Test loss: 1.567, Test accuracy: 42.20
Round  43, Global train loss: 0.805, Global test loss: 2.003, Global test accuracy: 31.72
Round  44, Train loss: 1.026, Test loss: 1.582, Test accuracy: 42.10
Round  44, Global train loss: 1.026, Global test loss: 2.078, Global test accuracy: 28.87
Round  45, Train loss: 0.939, Test loss: 1.607, Test accuracy: 41.95
Round  45, Global train loss: 0.939, Global test loss: 2.082, Global test accuracy: 28.93
Round  46, Train loss: 1.163, Test loss: 1.633, Test accuracy: 41.72
Round  46, Global train loss: 1.163, Global test loss: 2.266, Global test accuracy: 19.81
Round  47, Train loss: 0.861, Test loss: 1.645, Test accuracy: 41.80
Round  47, Global train loss: 0.861, Global test loss: 1.993, Global test accuracy: 31.78
Round  48, Train loss: 0.782, Test loss: 1.657, Test accuracy: 41.57
Round  48, Global train loss: 0.782, Global test loss: 2.084, Global test accuracy: 30.01
Round  49, Train loss: 1.034, Test loss: 1.675, Test accuracy: 41.02
Round  49, Global train loss: 1.034, Global test loss: 2.165, Global test accuracy: 26.24
Round  50, Train loss: 1.044, Test loss: 1.708, Test accuracy: 41.71
Round  50, Global train loss: 1.044, Global test loss: 2.211, Global test accuracy: 21.10
Round  51, Train loss: 1.220, Test loss: 1.712, Test accuracy: 42.16
Round  51, Global train loss: 1.220, Global test loss: 2.255, Global test accuracy: 18.51
Round  52, Train loss: 0.858, Test loss: 1.738, Test accuracy: 42.17
Round  52, Global train loss: 0.858, Global test loss: 2.052, Global test accuracy: 25.35
Round  53, Train loss: 0.792, Test loss: 1.755, Test accuracy: 41.78
Round  53, Global train loss: 0.792, Global test loss: 1.975, Global test accuracy: 29.67
Round  54, Train loss: 0.957, Test loss: 1.768, Test accuracy: 41.88
Round  54, Global train loss: 0.957, Global test loss: 2.117, Global test accuracy: 20.37
Round  55, Train loss: 0.841, Test loss: 1.807, Test accuracy: 41.46
Round  55, Global train loss: 0.841, Global test loss: 2.087, Global test accuracy: 31.55
Round  56, Train loss: 0.835, Test loss: 1.852, Test accuracy: 40.90
Round  56, Global train loss: 0.835, Global test loss: 2.036, Global test accuracy: 26.94
Round  57, Train loss: 0.790, Test loss: 1.867, Test accuracy: 41.03
Round  57, Global train loss: 0.790, Global test loss: 2.108, Global test accuracy: 28.79
Round  58, Train loss: 0.779, Test loss: 1.890, Test accuracy: 40.70
Round  58, Global train loss: 0.779, Global test loss: 2.052, Global test accuracy: 27.08
Round  59, Train loss: 0.444, Test loss: 1.924, Test accuracy: 40.53
Round  59, Global train loss: 0.444, Global test loss: 1.862, Global test accuracy: 32.72
Round  60, Train loss: 0.646, Test loss: 1.970, Test accuracy: 40.45
Round  60, Global train loss: 0.646, Global test loss: 2.061, Global test accuracy: 27.00
Round  61, Train loss: 0.729, Test loss: 2.012, Test accuracy: 40.33
Round  61, Global train loss: 0.729, Global test loss: 2.123, Global test accuracy: 19.18
Round  62, Train loss: 0.769, Test loss: 2.052, Test accuracy: 40.46
Round  62, Global train loss: 0.769, Global test loss: 2.176, Global test accuracy: 20.50
Round  63, Train loss: 0.520, Test loss: 2.088, Test accuracy: 40.04
Round  63, Global train loss: 0.520, Global test loss: 1.999, Global test accuracy: 28.22
Round  64, Train loss: 0.883, Test loss: 2.135, Test accuracy: 40.17
Round  64, Global train loss: 0.883, Global test loss: 2.150, Global test accuracy: 21.59
Round  65, Train loss: 0.686, Test loss: 2.143, Test accuracy: 39.91
Round  65, Global train loss: 0.686, Global test loss: 2.031, Global test accuracy: 31.31
Round  66, Train loss: 0.591, Test loss: 2.142, Test accuracy: 40.13
Round  66, Global train loss: 0.591, Global test loss: 2.115, Global test accuracy: 25.27
Round  67, Train loss: 0.752, Test loss: 2.179, Test accuracy: 40.22
Round  67, Global train loss: 0.752, Global test loss: 2.121, Global test accuracy: 24.30
Round  68, Train loss: 0.795, Test loss: 2.229, Test accuracy: 40.70
Round  68, Global train loss: 0.795, Global test loss: 2.220, Global test accuracy: 20.09
Round  69, Train loss: 0.597, Test loss: 2.242, Test accuracy: 40.82
Round  69, Global train loss: 0.597, Global test loss: 1.998, Global test accuracy: 31.72
Round  70, Train loss: 0.604, Test loss: 2.278, Test accuracy: 40.84
Round  70, Global train loss: 0.604, Global test loss: 2.064, Global test accuracy: 24.17
Round  71, Train loss: 0.369, Test loss: 2.350, Test accuracy: 40.61
Round  71, Global train loss: 0.369, Global test loss: 1.883, Global test accuracy: 36.26
Round  72, Train loss: 0.593, Test loss: 2.436, Test accuracy: 40.73
Round  72, Global train loss: 0.593, Global test loss: 2.196, Global test accuracy: 24.19
Round  73, Train loss: 0.557, Test loss: 2.439, Test accuracy: 40.43
Round  73, Global train loss: 0.557, Global test loss: 2.178, Global test accuracy: 22.95
Round  74, Train loss: 0.634, Test loss: 2.465, Test accuracy: 39.99
Round  74, Global train loss: 0.634, Global test loss: 2.183, Global test accuracy: 23.42
Round  75, Train loss: 0.448, Test loss: 2.466, Test accuracy: 39.52
Round  75, Global train loss: 0.448, Global test loss: 2.033, Global test accuracy: 26.62
Round  76, Train loss: 0.476, Test loss: 2.511, Test accuracy: 39.20
Round  76, Global train loss: 0.476, Global test loss: 2.069, Global test accuracy: 30.46
Round  77, Train loss: 0.470, Test loss: 2.529, Test accuracy: 39.07
Round  77, Global train loss: 0.470, Global test loss: 2.044, Global test accuracy: 28.11
Round  78, Train loss: 0.419, Test loss: 2.587, Test accuracy: 39.53
Round  78, Global train loss: 0.419, Global test loss: 1.983, Global test accuracy: 26.89
Round  79, Train loss: 0.492, Test loss: 2.552, Test accuracy: 40.07
Round  79, Global train loss: 0.492, Global test loss: 2.228, Global test accuracy: 20.16
Round  80, Train loss: 0.358, Test loss: 2.545, Test accuracy: 41.02
Round  80, Global train loss: 0.358, Global test loss: 2.018, Global test accuracy: 29.66
Round  81, Train loss: 0.286, Test loss: 2.624, Test accuracy: 40.29
Round  81, Global train loss: 0.286, Global test loss: 1.919, Global test accuracy: 32.53
Round  82, Train loss: 0.415, Test loss: 2.623, Test accuracy: 41.08
Round  82, Global train loss: 0.415, Global test loss: 2.021, Global test accuracy: 27.42
Round  83, Train loss: 0.304, Test loss: 2.624, Test accuracy: 40.65
Round  83, Global train loss: 0.304, Global test loss: 2.121, Global test accuracy: 19.59
Round  84, Train loss: 0.388, Test loss: 2.686, Test accuracy: 40.36
Round  84, Global train loss: 0.388, Global test loss: 1.955, Global test accuracy: 34.51
Round  85, Train loss: 0.481, Test loss: 2.750, Test accuracy: 40.30
Round  85, Global train loss: 0.481, Global test loss: 2.183, Global test accuracy: 20.57
Round  86, Train loss: 0.365, Test loss: 2.763, Test accuracy: 40.27
Round  86, Global train loss: 0.365, Global test loss: 2.062, Global test accuracy: 29.56
Round  87, Train loss: 0.344, Test loss: 2.846, Test accuracy: 39.90
Round  87, Global train loss: 0.344, Global test loss: 2.018, Global test accuracy: 28.30
Round  88, Train loss: 0.436, Test loss: 2.843, Test accuracy: 40.41
Round  88, Global train loss: 0.436, Global test loss: 2.178, Global test accuracy: 24.34
Round  89, Train loss: 0.313, Test loss: 2.933, Test accuracy: 40.03
Round  89, Global train loss: 0.313, Global test loss: 2.102, Global test accuracy: 26.76
Round  90, Train loss: 0.267, Test loss: 3.016, Test accuracy: 39.83
Round  90, Global train loss: 0.267, Global test loss: 2.074, Global test accuracy: 23.87
Round  91, Train loss: 0.343, Test loss: 3.009, Test accuracy: 40.31
Round  91, Global train loss: 0.343, Global test loss: 2.048, Global test accuracy: 25.98
Round  92, Train loss: 0.314, Test loss: 3.006, Test accuracy: 40.55
Round  92, Global train loss: 0.314, Global test loss: 2.083, Global test accuracy: 25.52
Round  93, Train loss: 0.215, Test loss: 3.110, Test accuracy: 40.80
Round  93, Global train loss: 0.215, Global test loss: 1.957, Global test accuracy: 31.85
Round  94, Train loss: 0.252, Test loss: 3.147, Test accuracy: 40.80
Round  94, Global train loss: 0.252, Global test loss: 2.022, Global test accuracy: 30.94
Round  95, Train loss: 0.327, Test loss: 3.190, Test accuracy: 39.99
Round  95, Global train loss: 0.327, Global test loss: 2.097, Global test accuracy: 24.93
Round  96, Train loss: 0.265, Test loss: 3.195, Test accuracy: 39.98
Round  96, Global train loss: 0.265, Global test loss: 2.110, Global test accuracy: 26.14
Round  97, Train loss: 0.249, Test loss: 3.181, Test accuracy: 40.14
Round  97, Global train loss: 0.249, Global test loss: 2.067, Global test accuracy: 26.01
Round  98, Train loss: 0.291, Test loss: 3.161, Test accuracy: 40.67
Round  98, Global train loss: 0.291, Global test loss: 2.103, Global test accuracy: 26.94
Round  99, Train loss: 0.401, Test loss: 3.200, Test accuracy: 40.68
Round  99, Global train loss: 0.401, Global test loss: 2.198, Global test accuracy: 24.11
Final Round, Train loss: 0.275, Test loss: 3.378, Test accuracy: 39.94
Final Round, Global train loss: 0.275, Global test loss: 2.198, Global test accuracy: 24.11
Average accuracy final 10 rounds: 40.375 

Average global accuracy final 10 rounds: 26.628999999999998 

1484.1085920333862
[1.5302159786224365, 3.060431957244873, 4.3179919719696045, 5.575551986694336, 6.832950830459595, 8.090349674224854, 9.345896005630493, 10.601442337036133, 11.862253427505493, 13.123064517974854, 14.382217645645142, 15.64137077331543, 16.89557909965515, 18.149787425994873, 19.407119035720825, 20.664450645446777, 21.92021346092224, 23.175976276397705, 24.43114972114563, 25.686323165893555, 26.940632343292236, 28.194941520690918, 29.465919256210327, 30.736896991729736, 31.996482372283936, 33.256067752838135, 34.52385663986206, 35.791645526885986, 37.04886746406555, 38.30608940124512, 39.55002570152283, 40.79396200180054, 42.041404724121094, 43.28884744644165, 44.533846616744995, 45.77884578704834, 47.022125005722046, 48.26540422439575, 49.508532762527466, 50.75166130065918, 51.995930194854736, 53.24019908905029, 54.47977948188782, 55.71935987472534, 56.96218395233154, 58.205008029937744, 59.44572615623474, 60.68644428253174, 61.926722288131714, 63.16700029373169, 64.40959072113037, 65.65218114852905, 66.89387512207031, 68.13556909561157, 69.37914991378784, 70.62273073196411, 71.87012076377869, 73.11751079559326, 74.36430335044861, 75.61109590530396, 76.86049795150757, 78.10989999771118, 79.35744380950928, 80.60498762130737, 81.8543438911438, 83.10370016098022, 84.35087466239929, 85.59804916381836, 86.84640336036682, 88.09475755691528, 89.34464478492737, 90.59453201293945, 91.84367084503174, 93.09280967712402, 94.34023094177246, 95.5876522064209, 96.83435463905334, 98.08105707168579, 99.3301990032196, 100.57934093475342, 101.82501649856567, 103.07069206237793, 104.31470489501953, 105.55871772766113, 106.80713272094727, 108.0555477142334, 109.30115985870361, 110.54677200317383, 111.79011869430542, 113.03346538543701, 114.28131079673767, 115.52915620803833, 116.77801084518433, 118.02686548233032, 119.26872420310974, 120.51058292388916, 121.75745916366577, 123.00433540344238, 124.25079703330994, 125.49725866317749, 126.7413170337677, 127.98537540435791, 129.23356866836548, 130.48176193237305, 131.72673630714417, 132.97171068191528, 134.2188491821289, 135.46598768234253, 136.7222456932068, 137.97850370407104, 139.2283320426941, 140.47816038131714, 141.7272183895111, 142.97627639770508, 144.22521471977234, 145.4741530418396, 146.72617053985596, 147.97818803787231, 149.22917103767395, 150.4801540374756, 151.73049139976501, 152.98082876205444, 154.23247504234314, 155.48412132263184, 156.73443865776062, 157.9847559928894, 159.23412108421326, 160.4834861755371, 161.7306625843048, 162.9778389930725, 164.2255449295044, 165.47325086593628, 166.7238574028015, 167.97446393966675, 169.21746969223022, 170.4604754447937, 171.70971155166626, 172.95894765853882, 174.20574808120728, 175.45254850387573, 176.6932315826416, 177.93391466140747, 179.1829490661621, 180.43198347091675, 181.68537068367004, 182.93875789642334, 184.17815899848938, 185.41756010055542, 186.6596896648407, 187.90181922912598, 189.1487877368927, 190.39575624465942, 191.64619135856628, 192.89662647247314, 194.13686990737915, 195.37711334228516, 196.63103127479553, 197.8849492073059, 199.13756108283997, 200.39017295837402, 201.63562774658203, 202.88108253479004, 204.12377309799194, 205.36646366119385, 206.61401200294495, 207.86156034469604, 209.10565948486328, 210.34975862503052, 211.60092163085938, 212.85208463668823, 214.10316276550293, 215.35424089431763, 216.60026502609253, 217.84628915786743, 219.0896511077881, 220.33301305770874, 221.58599734306335, 222.83898162841797, 224.0856637954712, 225.3323459625244, 226.58229160308838, 227.83223724365234, 229.08452796936035, 230.33681869506836, 231.58223366737366, 232.82764863967896, 234.07995533943176, 235.33226203918457, 236.59276390075684, 237.8532657623291, 239.10437512397766, 240.35548448562622, 241.60874462127686, 242.8620047569275, 244.1214382648468, 245.3808717727661, 246.64024591445923, 247.89962005615234, 249.1500165462494, 250.40041303634644, 252.89951491355896, 255.39861679077148]
[10.57, 10.57, 24.39, 24.39, 31.29, 31.29, 36.81, 36.81, 36.05, 36.05, 36.76, 36.76, 38.45, 38.45, 39.41, 39.41, 40.42, 40.42, 40.81, 40.81, 41.89, 41.89, 41.88, 41.88, 41.49, 41.49, 41.57, 41.57, 42.48, 42.48, 42.62, 42.62, 42.73, 42.73, 43.39, 43.39, 44.36, 44.36, 45.0, 45.0, 44.76, 44.76, 44.96, 44.96, 44.77, 44.77, 44.5, 44.5, 44.46, 44.46, 44.37, 44.37, 44.53, 44.53, 44.2, 44.2, 44.11, 44.11, 44.05, 44.05, 44.2, 44.2, 43.78, 43.78, 43.22, 43.22, 42.82, 42.82, 43.14, 43.14, 43.39, 43.39, 42.98, 42.98, 43.15, 43.15, 43.23, 43.23, 42.74, 42.74, 43.23, 43.23, 42.85, 42.85, 41.9, 41.9, 42.2, 42.2, 42.1, 42.1, 41.95, 41.95, 41.72, 41.72, 41.8, 41.8, 41.57, 41.57, 41.02, 41.02, 41.71, 41.71, 42.16, 42.16, 42.17, 42.17, 41.78, 41.78, 41.88, 41.88, 41.46, 41.46, 40.9, 40.9, 41.03, 41.03, 40.7, 40.7, 40.53, 40.53, 40.45, 40.45, 40.33, 40.33, 40.46, 40.46, 40.04, 40.04, 40.17, 40.17, 39.91, 39.91, 40.13, 40.13, 40.22, 40.22, 40.7, 40.7, 40.82, 40.82, 40.84, 40.84, 40.61, 40.61, 40.73, 40.73, 40.43, 40.43, 39.99, 39.99, 39.52, 39.52, 39.2, 39.2, 39.07, 39.07, 39.53, 39.53, 40.07, 40.07, 41.02, 41.02, 40.29, 40.29, 41.08, 41.08, 40.65, 40.65, 40.36, 40.36, 40.3, 40.3, 40.27, 40.27, 39.9, 39.9, 40.41, 40.41, 40.03, 40.03, 39.83, 39.83, 40.31, 40.31, 40.55, 40.55, 40.8, 40.8, 40.8, 40.8, 39.99, 39.99, 39.98, 39.98, 40.14, 40.14, 40.67, 40.67, 40.68, 40.68, 39.94, 39.94]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.6 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 6, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 14, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
   Client 15, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 13, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.705, Test loss: 2.053, Test accuracy: 24.42
Round   0, Global train loss: 1.705, Global test loss: 2.223, Global test accuracy: 21.03
Round   1, Train loss: 1.565, Test loss: 1.807, Test accuracy: 35.71
Round   1, Global train loss: 1.565, Global test loss: 2.104, Global test accuracy: 27.49
Round   2, Train loss: 1.489, Test loss: 1.604, Test accuracy: 39.54
Round   2, Global train loss: 1.489, Global test loss: 2.066, Global test accuracy: 25.40
Round   3, Train loss: 1.459, Test loss: 1.467, Test accuracy: 45.06
Round   3, Global train loss: 1.459, Global test loss: 1.962, Global test accuracy: 32.09
Round   4, Train loss: 1.359, Test loss: 1.384, Test accuracy: 47.27
Round   4, Global train loss: 1.359, Global test loss: 1.846, Global test accuracy: 34.64
Round   5, Train loss: 1.196, Test loss: 1.311, Test accuracy: 50.16
Round   5, Global train loss: 1.196, Global test loss: 1.680, Global test accuracy: 40.45
Round   6, Train loss: 1.252, Test loss: 1.247, Test accuracy: 52.55
Round   6, Global train loss: 1.252, Global test loss: 1.760, Global test accuracy: 34.63
Round   7, Train loss: 1.253, Test loss: 1.213, Test accuracy: 54.13
Round   7, Global train loss: 1.253, Global test loss: 1.804, Global test accuracy: 35.26
Round   8, Train loss: 1.234, Test loss: 1.178, Test accuracy: 55.49
Round   8, Global train loss: 1.234, Global test loss: 1.726, Global test accuracy: 38.13
Round   9, Train loss: 1.168, Test loss: 1.161, Test accuracy: 56.78
Round   9, Global train loss: 1.168, Global test loss: 1.643, Global test accuracy: 40.37
Round  10, Train loss: 1.060, Test loss: 1.126, Test accuracy: 57.88
Round  10, Global train loss: 1.060, Global test loss: 1.561, Global test accuracy: 46.38
Round  11, Train loss: 1.156, Test loss: 1.120, Test accuracy: 58.00
Round  11, Global train loss: 1.156, Global test loss: 1.557, Global test accuracy: 45.40
Round  12, Train loss: 1.130, Test loss: 1.114, Test accuracy: 58.49
Round  12, Global train loss: 1.130, Global test loss: 1.698, Global test accuracy: 40.17
Round  13, Train loss: 1.172, Test loss: 1.105, Test accuracy: 58.58
Round  13, Global train loss: 1.172, Global test loss: 1.891, Global test accuracy: 39.12
Round  14, Train loss: 1.069, Test loss: 1.105, Test accuracy: 58.56
Round  14, Global train loss: 1.069, Global test loss: 1.759, Global test accuracy: 40.83
Round  15, Train loss: 1.002, Test loss: 1.093, Test accuracy: 59.25
Round  15, Global train loss: 1.002, Global test loss: 1.449, Global test accuracy: 49.88
Round  16, Train loss: 1.076, Test loss: 1.083, Test accuracy: 58.99
Round  16, Global train loss: 1.076, Global test loss: 1.588, Global test accuracy: 44.46
Round  17, Train loss: 0.923, Test loss: 1.056, Test accuracy: 60.46
Round  17, Global train loss: 0.923, Global test loss: 1.436, Global test accuracy: 48.50
Round  18, Train loss: 0.997, Test loss: 1.034, Test accuracy: 61.34
Round  18, Global train loss: 0.997, Global test loss: 1.560, Global test accuracy: 46.78
Round  19, Train loss: 0.947, Test loss: 1.018, Test accuracy: 62.08
Round  19, Global train loss: 0.947, Global test loss: 1.530, Global test accuracy: 48.70
Round  20, Train loss: 0.930, Test loss: 1.004, Test accuracy: 63.17
Round  20, Global train loss: 0.930, Global test loss: 1.621, Global test accuracy: 46.15
Round  21, Train loss: 0.961, Test loss: 1.003, Test accuracy: 63.27
Round  21, Global train loss: 0.961, Global test loss: 1.387, Global test accuracy: 51.78
Round  22, Train loss: 0.949, Test loss: 1.004, Test accuracy: 63.58
Round  22, Global train loss: 0.949, Global test loss: 1.479, Global test accuracy: 49.74
Round  23, Train loss: 0.867, Test loss: 0.986, Test accuracy: 64.49
Round  23, Global train loss: 0.867, Global test loss: 1.544, Global test accuracy: 49.84
Round  24, Train loss: 1.005, Test loss: 0.995, Test accuracy: 63.95
Round  24, Global train loss: 1.005, Global test loss: 1.583, Global test accuracy: 47.82
Round  25, Train loss: 0.891, Test loss: 0.989, Test accuracy: 64.39
Round  25, Global train loss: 0.891, Global test loss: 1.399, Global test accuracy: 55.35
Round  26, Train loss: 0.911, Test loss: 0.992, Test accuracy: 64.39
Round  26, Global train loss: 0.911, Global test loss: 1.463, Global test accuracy: 51.25
Round  27, Train loss: 0.972, Test loss: 0.989, Test accuracy: 64.60
Round  27, Global train loss: 0.972, Global test loss: 1.457, Global test accuracy: 52.65
Round  28, Train loss: 0.787, Test loss: 0.984, Test accuracy: 65.30
Round  28, Global train loss: 0.787, Global test loss: 1.400, Global test accuracy: 52.73
Round  29, Train loss: 0.953, Test loss: 0.983, Test accuracy: 65.20
Round  29, Global train loss: 0.953, Global test loss: 1.273, Global test accuracy: 57.59
Round  30, Train loss: 0.789, Test loss: 0.995, Test accuracy: 65.14
Round  30, Global train loss: 0.789, Global test loss: 1.257, Global test accuracy: 57.69
Round  31, Train loss: 0.805, Test loss: 1.006, Test accuracy: 64.82
Round  31, Global train loss: 0.805, Global test loss: 1.474, Global test accuracy: 53.13
Round  32, Train loss: 0.914, Test loss: 1.007, Test accuracy: 65.11
Round  32, Global train loss: 0.914, Global test loss: 1.306, Global test accuracy: 55.09
Round  33, Train loss: 0.805, Test loss: 0.993, Test accuracy: 65.60
Round  33, Global train loss: 0.805, Global test loss: 1.308, Global test accuracy: 55.52
Round  34, Train loss: 0.773, Test loss: 0.989, Test accuracy: 66.05
Round  34, Global train loss: 0.773, Global test loss: 1.287, Global test accuracy: 56.62
Round  35, Train loss: 0.812, Test loss: 1.020, Test accuracy: 65.34
Round  35, Global train loss: 0.812, Global test loss: 1.380, Global test accuracy: 52.55
Round  36, Train loss: 0.817, Test loss: 1.043, Test accuracy: 64.80
Round  36, Global train loss: 0.817, Global test loss: 1.614, Global test accuracy: 50.39
Round  37, Train loss: 0.784, Test loss: 1.023, Test accuracy: 65.16
Round  37, Global train loss: 0.784, Global test loss: 1.308, Global test accuracy: 56.04
Round  38, Train loss: 0.767, Test loss: 1.035, Test accuracy: 64.98
Round  38, Global train loss: 0.767, Global test loss: 1.244, Global test accuracy: 57.13
Round  39, Train loss: 0.695, Test loss: 1.029, Test accuracy: 65.24
Round  39, Global train loss: 0.695, Global test loss: 1.207, Global test accuracy: 59.11
Round  40, Train loss: 0.626, Test loss: 1.017, Test accuracy: 65.29
Round  40, Global train loss: 0.626, Global test loss: 1.226, Global test accuracy: 59.92
Round  41, Train loss: 0.790, Test loss: 0.991, Test accuracy: 66.49
Round  41, Global train loss: 0.790, Global test loss: 1.185, Global test accuracy: 58.29
Round  42, Train loss: 0.698, Test loss: 1.000, Test accuracy: 66.32
Round  42, Global train loss: 0.698, Global test loss: 1.257, Global test accuracy: 57.68
Round  43, Train loss: 0.785, Test loss: 1.003, Test accuracy: 66.06
Round  43, Global train loss: 0.785, Global test loss: 1.301, Global test accuracy: 57.18
Round  44, Train loss: 0.704, Test loss: 1.009, Test accuracy: 66.32
Round  44, Global train loss: 0.704, Global test loss: 1.267, Global test accuracy: 58.87
Round  45, Train loss: 0.723, Test loss: 1.028, Test accuracy: 65.68
Round  45, Global train loss: 0.723, Global test loss: 1.379, Global test accuracy: 55.06
Round  46, Train loss: 0.717, Test loss: 1.025, Test accuracy: 65.97
Round  46, Global train loss: 0.717, Global test loss: 1.400, Global test accuracy: 54.54
Round  47, Train loss: 0.669, Test loss: 1.019, Test accuracy: 66.14
Round  47, Global train loss: 0.669, Global test loss: 1.144, Global test accuracy: 62.07
Round  48, Train loss: 0.716, Test loss: 1.019, Test accuracy: 66.30
Round  48, Global train loss: 0.716, Global test loss: 1.364, Global test accuracy: 55.26
Round  49, Train loss: 0.715, Test loss: 1.022, Test accuracy: 66.03
Round  49, Global train loss: 0.715, Global test loss: 1.370, Global test accuracy: 54.91
Round  50, Train loss: 0.708, Test loss: 1.023, Test accuracy: 66.49
Round  50, Global train loss: 0.708, Global test loss: 1.495, Global test accuracy: 53.41
Round  51, Train loss: 0.707, Test loss: 1.021, Test accuracy: 66.23
Round  51, Global train loss: 0.707, Global test loss: 1.394, Global test accuracy: 55.95
Round  52, Train loss: 0.672, Test loss: 1.051, Test accuracy: 65.87
Round  52, Global train loss: 0.672, Global test loss: 1.308, Global test accuracy: 58.27
Round  53, Train loss: 0.534, Test loss: 1.043, Test accuracy: 66.32
Round  53, Global train loss: 0.534, Global test loss: 1.338, Global test accuracy: 58.16
Round  54, Train loss: 0.583, Test loss: 1.048, Test accuracy: 66.58
Round  54, Global train loss: 0.583, Global test loss: 1.285, Global test accuracy: 58.74
Round  55, Train loss: 0.679, Test loss: 1.086, Test accuracy: 65.68
Round  55, Global train loss: 0.679, Global test loss: 1.625, Global test accuracy: 52.62
Round  56, Train loss: 0.618, Test loss: 1.092, Test accuracy: 65.84
Round  56, Global train loss: 0.618, Global test loss: 1.186, Global test accuracy: 60.94
Round  57, Train loss: 0.595, Test loss: 1.095, Test accuracy: 66.04
Round  57, Global train loss: 0.595, Global test loss: 1.301, Global test accuracy: 58.41
Round  58, Train loss: 0.630, Test loss: 1.099, Test accuracy: 66.18
Round  58, Global train loss: 0.630, Global test loss: 1.241, Global test accuracy: 59.95
Round  59, Train loss: 0.485, Test loss: 1.084, Test accuracy: 66.75
Round  59, Global train loss: 0.485, Global test loss: 1.223, Global test accuracy: 61.31
Round  60, Train loss: 0.559, Test loss: 1.064, Test accuracy: 67.54
Round  60, Global train loss: 0.559, Global test loss: 1.284, Global test accuracy: 58.96
Round  61, Train loss: 0.626, Test loss: 1.070, Test accuracy: 67.44
Round  61, Global train loss: 0.626, Global test loss: 1.265, Global test accuracy: 59.25
Round  62, Train loss: 0.559, Test loss: 1.077, Test accuracy: 67.28
Round  62, Global train loss: 0.559, Global test loss: 1.220, Global test accuracy: 60.11
Round  63, Train loss: 0.579, Test loss: 1.057, Test accuracy: 67.98
Round  63, Global train loss: 0.579, Global test loss: 1.221, Global test accuracy: 60.33
Round  64, Train loss: 0.647, Test loss: 1.062, Test accuracy: 67.96
Round  64, Global train loss: 0.647, Global test loss: 1.203, Global test accuracy: 60.77
Round  65, Train loss: 0.527, Test loss: 1.073, Test accuracy: 67.82
Round  65, Global train loss: 0.527, Global test loss: 1.316, Global test accuracy: 59.53
Round  66, Train loss: 0.619, Test loss: 1.058, Test accuracy: 68.59
Round  66, Global train loss: 0.619, Global test loss: 1.293, Global test accuracy: 58.85
Round  67, Train loss: 0.565, Test loss: 1.043, Test accuracy: 68.85
Round  67, Global train loss: 0.565, Global test loss: 1.277, Global test accuracy: 59.82
Round  68, Train loss: 0.573, Test loss: 1.101, Test accuracy: 67.64
Round  68, Global train loss: 0.573, Global test loss: 1.261, Global test accuracy: 60.26
Round  69, Train loss: 0.569, Test loss: 1.122, Test accuracy: 67.00
Round  69, Global train loss: 0.569, Global test loss: 1.283, Global test accuracy: 59.88
Round  70, Train loss: 0.481, Test loss: 1.098, Test accuracy: 67.61
Round  70, Global train loss: 0.481, Global test loss: 1.208, Global test accuracy: 61.29
Round  71, Train loss: 0.427, Test loss: 1.158, Test accuracy: 66.77
Round  71, Global train loss: 0.427, Global test loss: 1.230, Global test accuracy: 61.82
Round  72, Train loss: 0.557, Test loss: 1.182, Test accuracy: 65.91
Round  72, Global train loss: 0.557, Global test loss: 1.519, Global test accuracy: 55.27
Round  73, Train loss: 0.504, Test loss: 1.161, Test accuracy: 66.63
Round  73, Global train loss: 0.504, Global test loss: 1.417, Global test accuracy: 57.64
Round  74, Train loss: 0.532, Test loss: 1.146, Test accuracy: 66.80
Round  74, Global train loss: 0.532, Global test loss: 1.267, Global test accuracy: 61.16
Round  75, Train loss: 0.539, Test loss: 1.110, Test accuracy: 67.42
Round  75, Global train loss: 0.539, Global test loss: 1.314, Global test accuracy: 59.23
Round  76, Train loss: 0.548, Test loss: 1.098, Test accuracy: 67.76
Round  76, Global train loss: 0.548, Global test loss: 1.276, Global test accuracy: 60.55
Round  77, Train loss: 0.519, Test loss: 1.093, Test accuracy: 67.87
Round  77, Global train loss: 0.519, Global test loss: 1.491, Global test accuracy: 55.89
Round  78, Train loss: 0.574, Test loss: 1.125, Test accuracy: 67.34
Round  78, Global train loss: 0.574, Global test loss: 1.339, Global test accuracy: 58.97
Round  79, Train loss: 0.496, Test loss: 1.179, Test accuracy: 66.36
Round  79, Global train loss: 0.496, Global test loss: 1.507, Global test accuracy: 55.78
Round  80, Train loss: 0.455, Test loss: 1.179, Test accuracy: 66.30
Round  80, Global train loss: 0.455, Global test loss: 1.276, Global test accuracy: 60.81
Round  81, Train loss: 0.475, Test loss: 1.172, Test accuracy: 66.63
Round  81, Global train loss: 0.475, Global test loss: 1.341, Global test accuracy: 60.18
Round  82, Train loss: 0.474, Test loss: 1.166, Test accuracy: 66.67
Round  82, Global train loss: 0.474, Global test loss: 1.331, Global test accuracy: 59.50
Round  83, Train loss: 0.442, Test loss: 1.206, Test accuracy: 66.30
Round  83, Global train loss: 0.442, Global test loss: 1.498, Global test accuracy: 58.72
Round  84, Train loss: 0.408, Test loss: 1.165, Test accuracy: 66.73
Round  84, Global train loss: 0.408, Global test loss: 1.303, Global test accuracy: 62.66
Round  85, Train loss: 0.530, Test loss: 1.168, Test accuracy: 66.97
Round  85, Global train loss: 0.530, Global test loss: 1.300, Global test accuracy: 60.09
Round  86, Train loss: 0.453, Test loss: 1.148, Test accuracy: 67.72
Round  86, Global train loss: 0.453, Global test loss: 1.413, Global test accuracy: 59.28
Round  87, Train loss: 0.432, Test loss: 1.150, Test accuracy: 67.45
Round  87, Global train loss: 0.432, Global test loss: 1.279, Global test accuracy: 61.56
Round  88, Train loss: 0.469, Test loss: 1.151, Test accuracy: 67.59
Round  88, Global train loss: 0.469, Global test loss: 1.347, Global test accuracy: 60.04
Round  89, Train loss: 0.409, Test loss: 1.180, Test accuracy: 67.26
Round  89, Global train loss: 0.409, Global test loss: 1.364, Global test accuracy: 60.60
Round  90, Train loss: 0.494, Test loss: 1.184, Test accuracy: 67.36
Round  90, Global train loss: 0.494, Global test loss: 1.282, Global test accuracy: 61.52
Round  91, Train loss: 0.401, Test loss: 1.202, Test accuracy: 67.39
Round  91, Global train loss: 0.401, Global test loss: 1.318, Global test accuracy: 61.83
Round  92, Train loss: 0.456, Test loss: 1.233, Test accuracy: 67.04
Round  92, Global train loss: 0.456, Global test loss: 1.342, Global test accuracy: 60.73
Round  93, Train loss: 0.356, Test loss: 1.189, Test accuracy: 68.34
Round  93, Global train loss: 0.356, Global test loss: 1.417, Global test accuracy: 61.11
Round  94, Train loss: 0.488, Test loss: 1.188, Test accuracy: 68.36
Round  94, Global train loss: 0.488, Global test loss: 1.349, Global test accuracy: 60.40
Round  95, Train loss: 0.467, Test loss: 1.160, Test accuracy: 69.01
Round  95, Global train loss: 0.467, Global test loss: 1.230, Global test accuracy: 62.40
Round  96, Train loss: 0.418, Test loss: 1.189, Test accuracy: 68.83
Round  96, Global train loss: 0.418, Global test loss: 1.371, Global test accuracy: 60.58
Round  97, Train loss: 0.455, Test loss: 1.193, Test accuracy: 68.41
Round  97, Global train loss: 0.455, Global test loss: 1.326, Global test accuracy: 60.86
Round  98, Train loss: 0.425, Test loss: 1.192, Test accuracy: 68.69
Round  98, Global train loss: 0.425, Global test loss: 1.442, Global test accuracy: 59.86
Round  99, Train loss: 0.461, Test loss: 1.186, Test accuracy: 68.44
Round  99, Global train loss: 0.461, Global test loss: 1.628, Global test accuracy: 56.79
Final Round, Train loss: 0.342, Test loss: 1.334, Test accuracy: 67.84
Final Round, Global train loss: 0.342, Global test loss: 1.628, Global test accuracy: 56.79
Average accuracy final 10 rounds: 68.18700000000001 

Average global accuracy final 10 rounds: 60.608 

1344.6984906196594
[1.3953866958618164, 2.790773391723633, 3.915980100631714, 5.041186809539795, 6.161819219589233, 7.282451629638672, 8.40979552268982, 9.537139415740967, 10.663061618804932, 11.788983821868896, 12.915512084960938, 14.042040348052979, 15.167541265487671, 16.293042182922363, 17.42025089263916, 18.547459602355957, 19.669227600097656, 20.790995597839355, 21.918713569641113, 23.04643154144287, 24.177551984786987, 25.308672428131104, 26.43863797187805, 27.568603515625, 28.697257041931152, 29.825910568237305, 30.952277660369873, 32.07864475250244, 33.20816516876221, 34.33768558502197, 35.466649770736694, 36.595613956451416, 37.720155239105225, 38.84469652175903, 39.97875452041626, 41.112812519073486, 42.235888957977295, 43.3589653968811, 44.48300552368164, 45.60704565048218, 46.73345947265625, 47.85987329483032, 48.98319864273071, 50.1065239906311, 51.23268795013428, 52.35885190963745, 53.48277401924133, 54.606696128845215, 55.72635245323181, 56.84600877761841, 57.97735929489136, 59.10870981216431, 60.23758602142334, 61.36646223068237, 62.49629759788513, 63.62613296508789, 64.7520899772644, 65.87804698944092, 67.00333070755005, 68.12861442565918, 69.25339579582214, 70.37817716598511, 71.50575256347656, 72.63332796096802, 73.75809264183044, 74.88285732269287, 76.006276845932, 77.12969636917114, 78.25273585319519, 79.37577533721924, 80.49968004226685, 81.62358474731445, 82.75015473365784, 83.87672472000122, 85.00917172431946, 86.1416187286377, 87.26795935630798, 88.39429998397827, 89.52211117744446, 90.64992237091064, 91.76757550239563, 92.88522863388062, 93.99951410293579, 95.11379957199097, 96.22500896453857, 97.33621835708618, 98.45165419578552, 99.56709003448486, 100.67624688148499, 101.78540372848511, 102.89642333984375, 104.00744295120239, 105.1218626499176, 106.23628234863281, 107.34480166435242, 108.45332098007202, 109.55813550949097, 110.66295003890991, 111.778400182724, 112.89385032653809, 114.00888967514038, 115.12392902374268, 116.23125553131104, 117.3385820388794, 118.45278787612915, 119.5669937133789, 120.68267011642456, 121.79834651947021, 122.90934371948242, 124.02034091949463, 125.13297963142395, 126.24561834335327, 127.35743999481201, 128.46926164627075, 129.58881974220276, 130.70837783813477, 131.82197260856628, 132.9355673789978, 134.05491399765015, 135.1742606163025, 136.2952480316162, 137.41623544692993, 138.52776050567627, 139.6392855644226, 140.75166082382202, 141.86403608322144, 142.98048543930054, 144.09693479537964, 145.206613779068, 146.31629276275635, 147.43310165405273, 148.54991054534912, 149.5159149169922, 150.48191928863525, 151.45212864875793, 152.42233800888062, 153.39382600784302, 154.36531400680542, 155.33127212524414, 156.29723024368286, 157.2656753063202, 158.23412036895752, 159.20751571655273, 160.18091106414795, 161.15377354621887, 162.1266360282898, 163.0921070575714, 164.05757808685303, 165.0318958759308, 166.00621366500854, 166.9762146472931, 167.94621562957764, 168.91448378562927, 169.8827519416809, 170.84981536865234, 171.81687879562378, 172.7900197505951, 173.7631607055664, 174.73606514930725, 175.7089695930481, 176.67587423324585, 177.6427788734436, 178.61538362503052, 179.58798837661743, 180.5593822002411, 181.53077602386475, 182.49548745155334, 183.46019887924194, 184.42697381973267, 185.3937487602234, 186.36450266838074, 187.3352565765381, 188.30529880523682, 189.27534103393555, 190.24152398109436, 191.20770692825317, 192.1805350780487, 193.15336322784424, 194.12121653556824, 195.08906984329224, 196.05404114723206, 197.01901245117188, 197.98692297935486, 198.95483350753784, 199.92585706710815, 200.89688062667847, 201.867041349411, 202.83720207214355, 203.802969455719, 204.76873683929443, 205.73991227149963, 206.71108770370483, 207.6826992034912, 208.6543107032776, 209.62302780151367, 210.59174489974976, 211.5617117881775, 212.53167867660522, 213.5042018890381, 214.47672510147095, 216.41802763938904, 218.35933017730713]
[24.42, 24.42, 35.71, 35.71, 39.54, 39.54, 45.06, 45.06, 47.27, 47.27, 50.16, 50.16, 52.55, 52.55, 54.13, 54.13, 55.49, 55.49, 56.78, 56.78, 57.88, 57.88, 58.0, 58.0, 58.49, 58.49, 58.58, 58.58, 58.56, 58.56, 59.25, 59.25, 58.99, 58.99, 60.46, 60.46, 61.34, 61.34, 62.08, 62.08, 63.17, 63.17, 63.27, 63.27, 63.58, 63.58, 64.49, 64.49, 63.95, 63.95, 64.39, 64.39, 64.39, 64.39, 64.6, 64.6, 65.3, 65.3, 65.2, 65.2, 65.14, 65.14, 64.82, 64.82, 65.11, 65.11, 65.6, 65.6, 66.05, 66.05, 65.34, 65.34, 64.8, 64.8, 65.16, 65.16, 64.98, 64.98, 65.24, 65.24, 65.29, 65.29, 66.49, 66.49, 66.32, 66.32, 66.06, 66.06, 66.32, 66.32, 65.68, 65.68, 65.97, 65.97, 66.14, 66.14, 66.3, 66.3, 66.03, 66.03, 66.49, 66.49, 66.23, 66.23, 65.87, 65.87, 66.32, 66.32, 66.58, 66.58, 65.68, 65.68, 65.84, 65.84, 66.04, 66.04, 66.18, 66.18, 66.75, 66.75, 67.54, 67.54, 67.44, 67.44, 67.28, 67.28, 67.98, 67.98, 67.96, 67.96, 67.82, 67.82, 68.59, 68.59, 68.85, 68.85, 67.64, 67.64, 67.0, 67.0, 67.61, 67.61, 66.77, 66.77, 65.91, 65.91, 66.63, 66.63, 66.8, 66.8, 67.42, 67.42, 67.76, 67.76, 67.87, 67.87, 67.34, 67.34, 66.36, 66.36, 66.3, 66.3, 66.63, 66.63, 66.67, 66.67, 66.3, 66.3, 66.73, 66.73, 66.97, 66.97, 67.72, 67.72, 67.45, 67.45, 67.59, 67.59, 67.26, 67.26, 67.36, 67.36, 67.39, 67.39, 67.04, 67.04, 68.34, 68.34, 68.36, 68.36, 69.01, 69.01, 68.83, 68.83, 68.41, 68.41, 68.69, 68.69, 68.44, 68.44, 67.84, 67.84]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.6 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 19, noise    level: 0.8000 
   Client 18, noise    level: 0.8000 
   Client 11, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 10, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 17, noise    level: 0.8000 
   Client 14, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.632, Test loss: 2.041, Test accuracy: 17.96
Round   0, Global train loss: 1.632, Global test loss: 2.257, Global test accuracy: 12.52
Round   1, Train loss: 1.535, Test loss: 1.781, Test accuracy: 35.57
Round   1, Global train loss: 1.535, Global test loss: 2.068, Global test accuracy: 28.25
Round   2, Train loss: 1.492, Test loss: 1.587, Test accuracy: 37.94
Round   2, Global train loss: 1.492, Global test loss: 2.038, Global test accuracy: 24.26
Round   3, Train loss: 1.389, Test loss: 1.408, Test accuracy: 44.39
Round   3, Global train loss: 1.389, Global test loss: 1.977, Global test accuracy: 29.94
Round   4, Train loss: 1.402, Test loss: 1.324, Test accuracy: 47.06
Round   4, Global train loss: 1.402, Global test loss: 1.805, Global test accuracy: 33.72
Round   5, Train loss: 1.206, Test loss: 1.264, Test accuracy: 49.21
Round   5, Global train loss: 1.206, Global test loss: 1.733, Global test accuracy: 38.71
Round   6, Train loss: 1.138, Test loss: 1.214, Test accuracy: 51.53
Round   6, Global train loss: 1.138, Global test loss: 1.747, Global test accuracy: 36.57
Round   7, Train loss: 1.179, Test loss: 1.174, Test accuracy: 53.42
Round   7, Global train loss: 1.179, Global test loss: 1.774, Global test accuracy: 34.96
Round   8, Train loss: 1.144, Test loss: 1.144, Test accuracy: 55.05
Round   8, Global train loss: 1.144, Global test loss: 1.623, Global test accuracy: 40.99
Round   9, Train loss: 1.071, Test loss: 1.132, Test accuracy: 56.10
Round   9, Global train loss: 1.071, Global test loss: 1.609, Global test accuracy: 41.96
Round  10, Train loss: 1.060, Test loss: 1.100, Test accuracy: 57.32
Round  10, Global train loss: 1.060, Global test loss: 1.531, Global test accuracy: 46.08
Round  11, Train loss: 1.097, Test loss: 1.079, Test accuracy: 57.94
Round  11, Global train loss: 1.097, Global test loss: 1.502, Global test accuracy: 46.18
Round  12, Train loss: 1.077, Test loss: 1.067, Test accuracy: 58.70
Round  12, Global train loss: 1.077, Global test loss: 1.642, Global test accuracy: 38.80
Round  13, Train loss: 1.273, Test loss: 1.063, Test accuracy: 58.90
Round  13, Global train loss: 1.273, Global test loss: 1.813, Global test accuracy: 39.93
Round  14, Train loss: 1.090, Test loss: 1.047, Test accuracy: 59.34
Round  14, Global train loss: 1.090, Global test loss: 1.592, Global test accuracy: 41.81
Round  15, Train loss: 0.986, Test loss: 1.030, Test accuracy: 60.41
Round  15, Global train loss: 0.986, Global test loss: 1.448, Global test accuracy: 47.47
Round  16, Train loss: 1.177, Test loss: 1.027, Test accuracy: 60.62
Round  16, Global train loss: 1.177, Global test loss: 1.537, Global test accuracy: 44.62
Round  17, Train loss: 0.966, Test loss: 1.015, Test accuracy: 61.23
Round  17, Global train loss: 0.966, Global test loss: 1.443, Global test accuracy: 47.74
Round  18, Train loss: 0.896, Test loss: 1.011, Test accuracy: 61.69
Round  18, Global train loss: 0.896, Global test loss: 1.599, Global test accuracy: 44.25
Round  19, Train loss: 0.868, Test loss: 0.990, Test accuracy: 62.64
Round  19, Global train loss: 0.868, Global test loss: 1.546, Global test accuracy: 46.43
Round  20, Train loss: 0.963, Test loss: 0.976, Test accuracy: 63.32
Round  20, Global train loss: 0.963, Global test loss: 1.612, Global test accuracy: 46.22
Round  21, Train loss: 0.916, Test loss: 0.983, Test accuracy: 63.58
Round  21, Global train loss: 0.916, Global test loss: 1.413, Global test accuracy: 51.17
Round  22, Train loss: 0.912, Test loss: 0.952, Test accuracy: 64.88
Round  22, Global train loss: 0.912, Global test loss: 1.465, Global test accuracy: 49.87
Round  23, Train loss: 0.796, Test loss: 0.935, Test accuracy: 65.50
Round  23, Global train loss: 0.796, Global test loss: 1.512, Global test accuracy: 50.07
Round  24, Train loss: 0.897, Test loss: 0.946, Test accuracy: 64.94
Round  24, Global train loss: 0.897, Global test loss: 1.441, Global test accuracy: 50.63
Round  25, Train loss: 0.843, Test loss: 0.940, Test accuracy: 65.67
Round  25, Global train loss: 0.843, Global test loss: 1.357, Global test accuracy: 53.85
Round  26, Train loss: 0.919, Test loss: 0.939, Test accuracy: 65.74
Round  26, Global train loss: 0.919, Global test loss: 1.368, Global test accuracy: 52.92
Round  27, Train loss: 0.769, Test loss: 0.936, Test accuracy: 65.86
Round  27, Global train loss: 0.769, Global test loss: 1.468, Global test accuracy: 51.14
Round  28, Train loss: 0.775, Test loss: 0.933, Test accuracy: 66.45
Round  28, Global train loss: 0.775, Global test loss: 1.371, Global test accuracy: 53.36
Round  29, Train loss: 0.840, Test loss: 0.946, Test accuracy: 65.95
Round  29, Global train loss: 0.840, Global test loss: 1.273, Global test accuracy: 55.95
Round  30, Train loss: 0.774, Test loss: 0.922, Test accuracy: 66.70
Round  30, Global train loss: 0.774, Global test loss: 1.278, Global test accuracy: 56.83
Round  31, Train loss: 0.689, Test loss: 0.920, Test accuracy: 66.62
Round  31, Global train loss: 0.689, Global test loss: 1.382, Global test accuracy: 53.58
Round  32, Train loss: 0.919, Test loss: 0.932, Test accuracy: 66.86
Round  32, Global train loss: 0.919, Global test loss: 1.295, Global test accuracy: 53.09
Round  33, Train loss: 0.709, Test loss: 0.948, Test accuracy: 66.51
Round  33, Global train loss: 0.709, Global test loss: 1.416, Global test accuracy: 52.08
Round  34, Train loss: 0.744, Test loss: 0.941, Test accuracy: 66.71
Round  34, Global train loss: 0.744, Global test loss: 1.249, Global test accuracy: 56.93
Round  35, Train loss: 0.891, Test loss: 0.946, Test accuracy: 66.91
Round  35, Global train loss: 0.891, Global test loss: 1.242, Global test accuracy: 56.07
Round  36, Train loss: 0.920, Test loss: 0.947, Test accuracy: 67.00
Round  36, Global train loss: 0.920, Global test loss: 1.363, Global test accuracy: 54.40
Round  37, Train loss: 0.737, Test loss: 0.939, Test accuracy: 66.95
Round  37, Global train loss: 0.737, Global test loss: 1.211, Global test accuracy: 59.52
Round  38, Train loss: 0.753, Test loss: 0.921, Test accuracy: 67.25
Round  38, Global train loss: 0.753, Global test loss: 1.274, Global test accuracy: 56.42
Round  39, Train loss: 0.651, Test loss: 0.905, Test accuracy: 68.04
Round  39, Global train loss: 0.651, Global test loss: 1.244, Global test accuracy: 56.42
Round  40, Train loss: 0.558, Test loss: 0.904, Test accuracy: 68.02
Round  40, Global train loss: 0.558, Global test loss: 1.212, Global test accuracy: 59.96
Round  41, Train loss: 0.751, Test loss: 0.898, Test accuracy: 68.29
Round  41, Global train loss: 0.751, Global test loss: 1.255, Global test accuracy: 56.44
Round  42, Train loss: 0.628, Test loss: 0.904, Test accuracy: 68.42
Round  42, Global train loss: 0.628, Global test loss: 1.193, Global test accuracy: 58.89
Round  43, Train loss: 0.649, Test loss: 0.904, Test accuracy: 68.56
Round  43, Global train loss: 0.649, Global test loss: 1.260, Global test accuracy: 58.31
Round  44, Train loss: 0.593, Test loss: 0.882, Test accuracy: 69.27
Round  44, Global train loss: 0.593, Global test loss: 1.224, Global test accuracy: 59.81
Round  45, Train loss: 0.823, Test loss: 0.900, Test accuracy: 68.59
Round  45, Global train loss: 0.823, Global test loss: 1.243, Global test accuracy: 58.15
Round  46, Train loss: 0.774, Test loss: 0.918, Test accuracy: 68.77
Round  46, Global train loss: 0.774, Global test loss: 1.223, Global test accuracy: 57.60
Round  47, Train loss: 0.665, Test loss: 0.928, Test accuracy: 68.29
Round  47, Global train loss: 0.665, Global test loss: 1.189, Global test accuracy: 59.22
Round  48, Train loss: 0.713, Test loss: 0.923, Test accuracy: 68.43
Round  48, Global train loss: 0.713, Global test loss: 1.214, Global test accuracy: 58.04
Round  49, Train loss: 0.701, Test loss: 0.938, Test accuracy: 68.05
Round  49, Global train loss: 0.701, Global test loss: 1.272, Global test accuracy: 56.51
Round  50, Train loss: 0.705, Test loss: 0.919, Test accuracy: 68.43
Round  50, Global train loss: 0.705, Global test loss: 1.326, Global test accuracy: 55.79
Round  51, Train loss: 0.679, Test loss: 0.921, Test accuracy: 68.38
Round  51, Global train loss: 0.679, Global test loss: 1.235, Global test accuracy: 58.28
Round  52, Train loss: 0.635, Test loss: 0.923, Test accuracy: 69.02
Round  52, Global train loss: 0.635, Global test loss: 1.196, Global test accuracy: 59.25
Round  53, Train loss: 0.641, Test loss: 0.939, Test accuracy: 68.75
Round  53, Global train loss: 0.641, Global test loss: 1.223, Global test accuracy: 59.61
Round  54, Train loss: 0.587, Test loss: 0.911, Test accuracy: 69.85
Round  54, Global train loss: 0.587, Global test loss: 1.301, Global test accuracy: 58.40
Round  55, Train loss: 0.569, Test loss: 0.923, Test accuracy: 69.76
Round  55, Global train loss: 0.569, Global test loss: 1.335, Global test accuracy: 59.00
Round  56, Train loss: 0.548, Test loss: 0.905, Test accuracy: 70.07
Round  56, Global train loss: 0.548, Global test loss: 1.106, Global test accuracy: 63.30
Round  57, Train loss: 0.733, Test loss: 0.919, Test accuracy: 69.54
Round  57, Global train loss: 0.733, Global test loss: 1.221, Global test accuracy: 59.02
Round  58, Train loss: 0.738, Test loss: 0.933, Test accuracy: 69.47
Round  58, Global train loss: 0.738, Global test loss: 1.193, Global test accuracy: 58.86
Round  59, Train loss: 0.525, Test loss: 0.940, Test accuracy: 69.54
Round  59, Global train loss: 0.525, Global test loss: 1.202, Global test accuracy: 59.94
Round  60, Train loss: 0.559, Test loss: 0.952, Test accuracy: 69.31
Round  60, Global train loss: 0.559, Global test loss: 1.257, Global test accuracy: 59.00
Round  61, Train loss: 0.504, Test loss: 0.958, Test accuracy: 69.16
Round  61, Global train loss: 0.504, Global test loss: 1.174, Global test accuracy: 61.74
Round  62, Train loss: 0.514, Test loss: 0.952, Test accuracy: 69.07
Round  62, Global train loss: 0.514, Global test loss: 1.113, Global test accuracy: 62.19
Round  63, Train loss: 0.562, Test loss: 0.939, Test accuracy: 69.18
Round  63, Global train loss: 0.562, Global test loss: 1.119, Global test accuracy: 63.19
Round  64, Train loss: 0.662, Test loss: 0.944, Test accuracy: 69.24
Round  64, Global train loss: 0.662, Global test loss: 1.159, Global test accuracy: 60.87
Round  65, Train loss: 0.466, Test loss: 0.947, Test accuracy: 69.53
Round  65, Global train loss: 0.466, Global test loss: 1.301, Global test accuracy: 60.78
Round  66, Train loss: 0.654, Test loss: 0.915, Test accuracy: 70.43
Round  66, Global train loss: 0.654, Global test loss: 1.170, Global test accuracy: 61.89
Round  67, Train loss: 0.544, Test loss: 0.953, Test accuracy: 69.53
Round  67, Global train loss: 0.544, Global test loss: 1.201, Global test accuracy: 61.18
Round  68, Train loss: 0.553, Test loss: 0.960, Test accuracy: 69.64
Round  68, Global train loss: 0.553, Global test loss: 1.249, Global test accuracy: 59.26
Round  69, Train loss: 0.587, Test loss: 0.947, Test accuracy: 69.83
Round  69, Global train loss: 0.587, Global test loss: 1.138, Global test accuracy: 61.99
Round  70, Train loss: 0.473, Test loss: 0.944, Test accuracy: 70.05
Round  70, Global train loss: 0.473, Global test loss: 1.153, Global test accuracy: 61.79
Round  71, Train loss: 0.462, Test loss: 0.959, Test accuracy: 69.67
Round  71, Global train loss: 0.462, Global test loss: 1.326, Global test accuracy: 57.54
Round  72, Train loss: 0.628, Test loss: 0.958, Test accuracy: 70.14
Round  72, Global train loss: 0.628, Global test loss: 1.309, Global test accuracy: 57.96
Round  73, Train loss: 0.621, Test loss: 0.976, Test accuracy: 70.14
Round  73, Global train loss: 0.621, Global test loss: 1.350, Global test accuracy: 57.64
Round  74, Train loss: 0.574, Test loss: 0.980, Test accuracy: 69.64
Round  74, Global train loss: 0.574, Global test loss: 1.212, Global test accuracy: 61.23
Round  75, Train loss: 0.423, Test loss: 0.962, Test accuracy: 70.29
Round  75, Global train loss: 0.423, Global test loss: 1.249, Global test accuracy: 61.70
Round  76, Train loss: 0.545, Test loss: 0.976, Test accuracy: 70.50
Round  76, Global train loss: 0.545, Global test loss: 1.271, Global test accuracy: 59.39
Round  77, Train loss: 0.454, Test loss: 0.985, Test accuracy: 70.29
Round  77, Global train loss: 0.454, Global test loss: 1.401, Global test accuracy: 57.63
Round  78, Train loss: 0.420, Test loss: 0.988, Test accuracy: 70.51
Round  78, Global train loss: 0.420, Global test loss: 1.203, Global test accuracy: 61.85
Round  79, Train loss: 0.456, Test loss: 0.970, Test accuracy: 70.53
Round  79, Global train loss: 0.456, Global test loss: 1.282, Global test accuracy: 59.26
Round  80, Train loss: 0.421, Test loss: 0.950, Test accuracy: 70.83
Round  80, Global train loss: 0.421, Global test loss: 1.144, Global test accuracy: 62.88
Round  81, Train loss: 0.495, Test loss: 0.946, Test accuracy: 70.69
Round  81, Global train loss: 0.495, Global test loss: 1.117, Global test accuracy: 65.02
Round  82, Train loss: 0.395, Test loss: 0.949, Test accuracy: 70.75
Round  82, Global train loss: 0.395, Global test loss: 1.164, Global test accuracy: 63.53
Round  83, Train loss: 0.521, Test loss: 0.943, Test accuracy: 71.12
Round  83, Global train loss: 0.521, Global test loss: 1.272, Global test accuracy: 60.34
Round  84, Train loss: 0.420, Test loss: 0.957, Test accuracy: 70.91
Round  84, Global train loss: 0.420, Global test loss: 1.194, Global test accuracy: 63.23
Round  85, Train loss: 0.572, Test loss: 0.973, Test accuracy: 70.70
Round  85, Global train loss: 0.572, Global test loss: 1.179, Global test accuracy: 62.01
Round  86, Train loss: 0.495, Test loss: 0.952, Test accuracy: 71.22
Round  86, Global train loss: 0.495, Global test loss: 1.246, Global test accuracy: 60.96
Round  87, Train loss: 0.358, Test loss: 0.961, Test accuracy: 71.45
Round  87, Global train loss: 0.358, Global test loss: 1.272, Global test accuracy: 62.23
Round  88, Train loss: 0.556, Test loss: 0.986, Test accuracy: 71.31
Round  88, Global train loss: 0.556, Global test loss: 1.173, Global test accuracy: 62.43
Round  89, Train loss: 0.498, Test loss: 1.020, Test accuracy: 70.91
Round  89, Global train loss: 0.498, Global test loss: 1.270, Global test accuracy: 60.84
Round  90, Train loss: 0.460, Test loss: 1.028, Test accuracy: 70.72
Round  90, Global train loss: 0.460, Global test loss: 1.279, Global test accuracy: 60.47
Round  91, Train loss: 0.449, Test loss: 1.045, Test accuracy: 70.19
Round  91, Global train loss: 0.449, Global test loss: 1.291, Global test accuracy: 61.67
Round  92, Train loss: 0.393, Test loss: 1.066, Test accuracy: 70.28
Round  92, Global train loss: 0.393, Global test loss: 1.267, Global test accuracy: 62.58/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  93, Train loss: 0.414, Test loss: 1.060, Test accuracy: 70.43
Round  93, Global train loss: 0.414, Global test loss: 1.314, Global test accuracy: 61.68
Round  94, Train loss: 0.474, Test loss: 1.041, Test accuracy: 70.78
Round  94, Global train loss: 0.474, Global test loss: 1.206, Global test accuracy: 63.06
Round  95, Train loss: 0.401, Test loss: 1.040, Test accuracy: 70.50
Round  95, Global train loss: 0.401, Global test loss: 1.139, Global test accuracy: 64.72
Round  96, Train loss: 0.456, Test loss: 1.064, Test accuracy: 70.59
Round  96, Global train loss: 0.456, Global test loss: 1.247, Global test accuracy: 61.78
Round  97, Train loss: 0.408, Test loss: 1.028, Test accuracy: 71.33
Round  97, Global train loss: 0.408, Global test loss: 1.232, Global test accuracy: 62.97
Round  98, Train loss: 0.458, Test loss: 1.035, Test accuracy: 71.04
Round  98, Global train loss: 0.458, Global test loss: 1.319, Global test accuracy: 61.61
Round  99, Train loss: 0.428, Test loss: 1.045, Test accuracy: 70.94
Round  99, Global train loss: 0.428, Global test loss: 1.369, Global test accuracy: 61.78
Final Round, Train loss: 0.334, Test loss: 1.042, Test accuracy: 71.93
Final Round, Global train loss: 0.334, Global test loss: 1.369, Global test accuracy: 61.78
Average accuracy final 10 rounds: 70.67999999999999 

Average global accuracy final 10 rounds: 62.23199999999999 

1462.5604016780853
[1.4917809963226318, 2.9835619926452637, 4.211582660675049, 5.439603328704834, 6.659961938858032, 7.8803205490112305, 9.115155458450317, 10.349990367889404, 11.584551811218262, 12.81911325454712, 14.054150104522705, 15.289186954498291, 16.529258012771606, 17.769329071044922, 19.010366201400757, 20.251403331756592, 21.49708390235901, 22.742764472961426, 23.98643469810486, 25.23010492324829, 26.47117257118225, 27.71224021911621, 28.956177711486816, 30.200115203857422, 31.442171812057495, 32.68422842025757, 33.92525887489319, 35.16628932952881, 36.40772199630737, 37.64915466308594, 38.893266916275024, 40.13737916946411, 41.38001847267151, 42.622657775878906, 43.864689350128174, 45.10672092437744, 46.3515830039978, 47.596445083618164, 48.836220264434814, 50.075995445251465, 51.322694540023804, 52.56939363479614, 53.81211233139038, 55.05483102798462, 56.294989585876465, 57.53514814376831, 58.77851486206055, 60.02188158035278, 61.26615834236145, 62.51043510437012, 63.74570918083191, 64.9809832572937, 66.21948647499084, 67.45798969268799, 68.69921684265137, 69.94044399261475, 71.17739200592041, 72.41434001922607, 73.65147566795349, 74.88861131668091, 76.12710571289062, 77.36560010910034, 78.5965428352356, 79.82748556137085, 81.06651902198792, 82.30555248260498, 83.54178762435913, 84.77802276611328, 86.00909948348999, 87.2401762008667, 88.47436451911926, 89.70855283737183, 90.94561171531677, 92.18267059326172, 93.42020106315613, 94.65773153305054, 95.9051833152771, 97.15263509750366, 98.3937418460846, 99.63484859466553, 100.86947894096375, 102.10410928726196, 103.34627079963684, 104.58843231201172, 105.83235836029053, 107.07628440856934, 108.319650888443, 109.56301736831665, 110.79458904266357, 112.0261607170105, 113.25673151016235, 114.48730230331421, 115.7180826663971, 116.94886302947998, 118.17933392524719, 119.4098048210144, 120.64488577842712, 121.87996673583984, 123.11698389053345, 124.35400104522705, 125.58503413200378, 126.81606721878052, 128.05167055130005, 129.28727388381958, 130.52425718307495, 131.76124048233032, 132.9916639328003, 134.22208738327026, 135.45595693588257, 136.68982648849487, 137.93108654022217, 139.17234659194946, 140.3981556892395, 141.62396478652954, 142.8578405380249, 144.09171628952026, 145.32885646820068, 146.5659966468811, 147.79660964012146, 149.02722263336182, 150.25903153419495, 151.49084043502808, 152.72519183158875, 153.9595432281494, 155.18873047828674, 156.41791772842407, 157.65347385406494, 158.8890299797058, 160.1262435913086, 161.36345720291138, 162.5921802520752, 163.820903301239, 165.05467104911804, 166.28843879699707, 167.52203941345215, 168.75564002990723, 169.98443818092346, 171.2132363319397, 172.44392943382263, 173.67462253570557, 174.91035676002502, 176.14609098434448, 177.38149905204773, 178.61690711975098, 179.84980463981628, 181.0827021598816, 182.3181049823761, 183.5535078048706, 184.78497076034546, 186.0164337158203, 187.24751114845276, 188.4785885810852, 189.7120382785797, 190.94548797607422, 192.18078780174255, 193.4160876274109, 194.64564657211304, 195.87520551681519, 197.10969281196594, 198.3441801071167, 199.57614064216614, 200.80810117721558, 202.04052639007568, 203.2729516029358, 204.50756907463074, 205.74218654632568, 206.9767017364502, 208.2112169265747, 209.43990325927734, 210.66858959197998, 211.9062762260437, 213.14396286010742, 214.37860226631165, 215.61324167251587, 216.84337997436523, 218.0735182762146, 219.30954003334045, 220.5455617904663, 221.77899622917175, 223.0124306678772, 224.25208735466003, 225.49174404144287, 226.73665475845337, 227.98156547546387, 229.22328662872314, 230.46500778198242, 231.7012321949005, 232.9374566078186, 234.17797589302063, 235.41849517822266, 236.66130590438843, 237.9041166305542, 239.13935589790344, 240.37459516525269, 241.60709285736084, 242.839590549469, 244.07271528244019, 245.30584001541138, 246.53793096542358, 247.7700219154358, 250.2380392551422, 252.70605659484863]
[17.96, 17.96, 35.57, 35.57, 37.94, 37.94, 44.39, 44.39, 47.06, 47.06, 49.21, 49.21, 51.53, 51.53, 53.42, 53.42, 55.05, 55.05, 56.1, 56.1, 57.32, 57.32, 57.94, 57.94, 58.7, 58.7, 58.9, 58.9, 59.34, 59.34, 60.41, 60.41, 60.62, 60.62, 61.23, 61.23, 61.69, 61.69, 62.64, 62.64, 63.32, 63.32, 63.58, 63.58, 64.88, 64.88, 65.5, 65.5, 64.94, 64.94, 65.67, 65.67, 65.74, 65.74, 65.86, 65.86, 66.45, 66.45, 65.95, 65.95, 66.7, 66.7, 66.62, 66.62, 66.86, 66.86, 66.51, 66.51, 66.71, 66.71, 66.91, 66.91, 67.0, 67.0, 66.95, 66.95, 67.25, 67.25, 68.04, 68.04, 68.02, 68.02, 68.29, 68.29, 68.42, 68.42, 68.56, 68.56, 69.27, 69.27, 68.59, 68.59, 68.77, 68.77, 68.29, 68.29, 68.43, 68.43, 68.05, 68.05, 68.43, 68.43, 68.38, 68.38, 69.02, 69.02, 68.75, 68.75, 69.85, 69.85, 69.76, 69.76, 70.07, 70.07, 69.54, 69.54, 69.47, 69.47, 69.54, 69.54, 69.31, 69.31, 69.16, 69.16, 69.07, 69.07, 69.18, 69.18, 69.24, 69.24, 69.53, 69.53, 70.43, 70.43, 69.53, 69.53, 69.64, 69.64, 69.83, 69.83, 70.05, 70.05, 69.67, 69.67, 70.14, 70.14, 70.14, 70.14, 69.64, 69.64, 70.29, 70.29, 70.5, 70.5, 70.29, 70.29, 70.51, 70.51, 70.53, 70.53, 70.83, 70.83, 70.69, 70.69, 70.75, 70.75, 71.12, 71.12, 70.91, 70.91, 70.7, 70.7, 71.22, 71.22, 71.45, 71.45, 71.31, 71.31, 70.91, 70.91, 70.72, 70.72, 70.19, 70.19, 70.28, 70.28, 70.43, 70.43, 70.78, 70.78, 70.5, 70.5, 70.59, 70.59, 71.33, 71.33, 71.04, 71.04, 70.94, 70.94, 71.93, 71.93]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.6 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 13, noise    level: 0.8000 
   Client 14, noise    level: 0.8000 
   Client 16, noise    level: 0.8000 
   Client 11, noise    level: 0.8000 
   Client 12, noise    level: 0.8000 
   Client 18, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 10, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 19, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.923, Test loss: 2.172, Test accuracy: 16.20
Round   1, Train loss: 1.644, Test loss: 1.916, Test accuracy: 28.68
Round   2, Train loss: 1.566, Test loss: 1.758, Test accuracy: 33.04
Round   3, Train loss: 1.482, Test loss: 1.602, Test accuracy: 38.20
Round   4, Train loss: 1.424, Test loss: 1.507, Test accuracy: 42.42
Round   5, Train loss: 1.232, Test loss: 1.410, Test accuracy: 46.65
Round   6, Train loss: 1.167, Test loss: 1.306, Test accuracy: 50.39
Round   7, Train loss: 1.158, Test loss: 1.235, Test accuracy: 53.10
Round   8, Train loss: 1.140, Test loss: 1.215, Test accuracy: 53.60
Round   9, Train loss: 1.134, Test loss: 1.169, Test accuracy: 55.66
Round  10, Train loss: 1.078, Test loss: 1.150, Test accuracy: 56.98
Round  11, Train loss: 1.113, Test loss: 1.135, Test accuracy: 57.47
Round  12, Train loss: 1.107, Test loss: 1.118, Test accuracy: 58.09
Round  13, Train loss: 1.232, Test loss: 1.126, Test accuracy: 58.22
Round  14, Train loss: 1.084, Test loss: 1.106, Test accuracy: 58.36
Round  15, Train loss: 1.055, Test loss: 1.083, Test accuracy: 58.90
Round  16, Train loss: 1.141, Test loss: 1.083, Test accuracy: 59.43
Round  17, Train loss: 1.082, Test loss: 1.059, Test accuracy: 59.71
Round  18, Train loss: 0.997, Test loss: 1.041, Test accuracy: 60.46
Round  19, Train loss: 0.982, Test loss: 1.034, Test accuracy: 61.13
Round  20, Train loss: 0.989, Test loss: 1.018, Test accuracy: 61.15
Round  21, Train loss: 0.975, Test loss: 1.002, Test accuracy: 61.86
Round  22, Train loss: 1.039, Test loss: 1.007, Test accuracy: 62.32
Round  23, Train loss: 0.986, Test loss: 1.004, Test accuracy: 62.72
Round  24, Train loss: 0.929, Test loss: 0.994, Test accuracy: 62.39
Round  25, Train loss: 1.010, Test loss: 1.001, Test accuracy: 62.81
Round  26, Train loss: 1.008, Test loss: 0.987, Test accuracy: 63.03
Round  27, Train loss: 1.008, Test loss: 0.993, Test accuracy: 63.14
Round  28, Train loss: 0.920, Test loss: 0.977, Test accuracy: 63.21
Round  29, Train loss: 0.957, Test loss: 0.966, Test accuracy: 63.80
Round  30, Train loss: 0.939, Test loss: 0.945, Test accuracy: 64.68
Round  31, Train loss: 0.902, Test loss: 0.959, Test accuracy: 64.66
Round  32, Train loss: 1.009, Test loss: 0.948, Test accuracy: 64.96
Round  33, Train loss: 0.815, Test loss: 0.946, Test accuracy: 64.36
Round  34, Train loss: 0.872, Test loss: 0.926, Test accuracy: 65.93
Round  35, Train loss: 1.017, Test loss: 0.925, Test accuracy: 65.63
Round  36, Train loss: 0.925, Test loss: 0.916, Test accuracy: 66.52
Round  37, Train loss: 0.826, Test loss: 0.904, Test accuracy: 66.40
Round  38, Train loss: 0.826, Test loss: 0.908, Test accuracy: 66.62
Round  39, Train loss: 0.771, Test loss: 0.901, Test accuracy: 67.02
Round  40, Train loss: 0.757, Test loss: 0.893, Test accuracy: 67.72
Round  41, Train loss: 0.887, Test loss: 0.918, Test accuracy: 66.75
Round  42, Train loss: 0.841, Test loss: 0.882, Test accuracy: 67.53
Round  43, Train loss: 0.810, Test loss: 0.881, Test accuracy: 67.93
Round  44, Train loss: 0.771, Test loss: 0.870, Test accuracy: 67.74
Round  45, Train loss: 0.926, Test loss: 0.858, Test accuracy: 68.11
Round  46, Train loss: 0.876, Test loss: 0.869, Test accuracy: 67.57
Round  47, Train loss: 0.833, Test loss: 0.854, Test accuracy: 68.66
Round  48, Train loss: 0.865, Test loss: 0.846, Test accuracy: 69.05
Round  49, Train loss: 0.883, Test loss: 0.845, Test accuracy: 68.91
Round  50, Train loss: 0.812, Test loss: 0.849, Test accuracy: 68.76
Round  51, Train loss: 0.831, Test loss: 0.857, Test accuracy: 68.29
Round  52, Train loss: 0.805, Test loss: 0.841, Test accuracy: 69.01
Round  53, Train loss: 0.742, Test loss: 0.831, Test accuracy: 69.21
Round  54, Train loss: 0.736, Test loss: 0.826, Test accuracy: 69.75
Round  55, Train loss: 0.676, Test loss: 0.827, Test accuracy: 69.58
Round  56, Train loss: 0.665, Test loss: 0.825, Test accuracy: 69.98
Round  57, Train loss: 0.774, Test loss: 0.823, Test accuracy: 70.07
Round  58, Train loss: 0.781, Test loss: 0.822, Test accuracy: 70.07
Round  59, Train loss: 0.686, Test loss: 0.812, Test accuracy: 70.48
Round  60, Train loss: 0.693, Test loss: 0.802, Test accuracy: 70.97
Round  61, Train loss: 0.674, Test loss: 0.808, Test accuracy: 70.36
Round  62, Train loss: 0.629, Test loss: 0.811, Test accuracy: 70.61
Round  63, Train loss: 0.743, Test loss: 0.799, Test accuracy: 70.62
Round  64, Train loss: 0.702, Test loss: 0.811, Test accuracy: 70.66
Round  65, Train loss: 0.608, Test loss: 0.799, Test accuracy: 70.59
Round  66, Train loss: 0.771, Test loss: 0.800, Test accuracy: 70.58
Round  67, Train loss: 0.619, Test loss: 0.797, Test accuracy: 71.09
Round  68, Train loss: 0.689, Test loss: 0.807, Test accuracy: 70.89
Round  69, Train loss: 0.757, Test loss: 0.817, Test accuracy: 70.36
Round  70, Train loss: 0.612, Test loss: 0.804, Test accuracy: 70.91
Round  71, Train loss: 0.647, Test loss: 0.796, Test accuracy: 71.16
Round  72, Train loss: 0.720, Test loss: 0.786, Test accuracy: 71.52
Round  73, Train loss: 0.790, Test loss: 0.802, Test accuracy: 71.25
Round  74, Train loss: 0.707, Test loss: 0.799, Test accuracy: 70.79
Round  75, Train loss: 0.680, Test loss: 0.793, Test accuracy: 71.26
Round  76, Train loss: 0.645, Test loss: 0.797, Test accuracy: 71.10
Round  77, Train loss: 0.661, Test loss: 0.782, Test accuracy: 71.59
Round  78, Train loss: 0.584, Test loss: 0.777, Test accuracy: 71.76
Round  79, Train loss: 0.708, Test loss: 0.784, Test accuracy: 71.26
Round  80, Train loss: 0.593, Test loss: 0.770, Test accuracy: 71.49
Round  81, Train loss: 0.607, Test loss: 0.767, Test accuracy: 71.64
Round  82, Train loss: 0.551, Test loss: 0.759, Test accuracy: 72.26
Round  83, Train loss: 0.687, Test loss: 0.772, Test accuracy: 71.83
Round  84, Train loss: 0.632, Test loss: 0.766, Test accuracy: 71.93
Round  85, Train loss: 0.649, Test loss: 0.762, Test accuracy: 71.75
Round  86, Train loss: 0.658, Test loss: 0.764, Test accuracy: 71.83
Round  87, Train loss: 0.589, Test loss: 0.761, Test accuracy: 71.84
Round  88, Train loss: 0.612, Test loss: 0.760, Test accuracy: 72.23
Round  89, Train loss: 0.598, Test loss: 0.779, Test accuracy: 71.48
Round  90, Train loss: 0.669, Test loss: 0.766, Test accuracy: 72.67
Round  91, Train loss: 0.660, Test loss: 0.772, Test accuracy: 72.23
Round  92, Train loss: 0.558, Test loss: 0.777, Test accuracy: 71.65
Round  93, Train loss: 0.566, Test loss: 0.778, Test accuracy: 71.98
Round  94, Train loss: 0.575, Test loss: 0.766, Test accuracy: 72.23
Round  95, Train loss: 0.504, Test loss: 0.767, Test accuracy: 72.11
Round  96, Train loss: 0.627, Test loss: 0.771, Test accuracy: 72.26
Round  97, Train loss: 0.518, Test loss: 0.780, Test accuracy: 72.14
Round  98, Train loss: 0.548, Test loss: 0.771, Test accuracy: 71.88
Round  99, Train loss: 0.632, Test loss: 0.772, Test accuracy: 72.47
Final Round, Train loss: 0.505, Test loss: 0.763, Test accuracy: 72.60
Average accuracy final 10 rounds: 72.16199999999999
1706.4380748271942
[2.8309171199798584, 5.355270624160767, 7.875335931777954, 10.38933777809143, 12.911503553390503, 15.438379049301147, 17.93778395652771, 20.467158317565918, 22.991078853607178, 25.51797842979431, 28.045201778411865, 30.55043625831604, 33.077168226242065, 35.598363161087036, 38.1202187538147, 40.642170667648315, 43.14417290687561, 45.66773819923401, 48.18754696846008, 50.70595049858093, 53.23038601875305, 55.73460555076599, 58.26080536842346, 60.78460502624512, 63.30627918243408, 65.83047318458557, 68.32837867736816, 70.85067057609558, 73.37288069725037, 75.89269733428955, 78.41671895980835, 80.91757369041443, 83.4465765953064, 85.97540616989136, 88.50191330909729, 91.03211641311646, 93.52437400817871, 96.04803013801575, 98.32149887084961, 100.59055924415588, 102.8623833656311, 105.13479924201965, 107.39917325973511, 109.67865586280823, 111.9254424571991, 114.2017822265625, 116.50133299827576, 118.74842762947083, 121.03141641616821, 123.31420016288757, 125.57205390930176, 127.86362600326538, 130.13261580467224, 132.40521097183228, 134.68507504463196, 136.92257714271545, 139.19047021865845, 141.46426129341125, 143.7102403640747, 145.9917287826538, 148.27259612083435, 150.53948426246643, 152.80946850776672, 155.08158946037292, 157.34327149391174, 159.61067056655884, 161.85680389404297, 164.13130354881287, 166.4071545600891, 168.64297890663147, 170.92025136947632, 173.19846415519714, 175.48959231376648, 177.79651927947998, 180.08490705490112, 182.37108325958252, 184.67919731140137, 186.91350674629211, 189.18887877464294, 191.45854377746582, 193.70258808135986, 195.97477006912231, 198.25820469856262, 200.52540493011475, 202.79442691802979, 205.06404209136963, 207.34150385856628, 209.61278223991394, 211.85608530044556, 214.12652349472046, 216.41312503814697, 218.65348505973816, 220.93474531173706, 223.2160301208496, 225.47970485687256, 227.7543022632599, 230.0323052406311, 232.31144213676453, 234.5812542438507, 236.82209515571594, 240.41515254974365]
[16.2, 28.68, 33.04, 38.2, 42.42, 46.65, 50.39, 53.1, 53.6, 55.66, 56.98, 57.47, 58.09, 58.22, 58.36, 58.9, 59.43, 59.71, 60.46, 61.13, 61.15, 61.86, 62.32, 62.72, 62.39, 62.81, 63.03, 63.14, 63.21, 63.8, 64.68, 64.66, 64.96, 64.36, 65.93, 65.63, 66.52, 66.4, 66.62, 67.02, 67.72, 66.75, 67.53, 67.93, 67.74, 68.11, 67.57, 68.66, 69.05, 68.91, 68.76, 68.29, 69.01, 69.21, 69.75, 69.58, 69.98, 70.07, 70.07, 70.48, 70.97, 70.36, 70.61, 70.62, 70.66, 70.59, 70.58, 71.09, 70.89, 70.36, 70.91, 71.16, 71.52, 71.25, 70.79, 71.26, 71.1, 71.59, 71.76, 71.26, 71.49, 71.64, 72.26, 71.83, 71.93, 71.75, 71.83, 71.84, 72.23, 71.48, 72.67, 72.23, 71.65, 71.98, 72.23, 72.11, 72.26, 72.14, 71.88, 72.47, 72.6]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 15, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
   Client 11, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 17, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 13, noise    level: 0.8000 
   Client 16, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
   Client 18, noise    level: 0.8000 
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  16.3100
Round 1 global test acc  22.9100
Round 2 global test acc  20.9400
Round 3 global test acc  21.5400
Round 4 global test acc  16.3500
Round 5 global test acc  25.2200
Round 6 global test acc  23.6400
Round 7 global test acc  29.2100
Round 8 global test acc  28.7200
Round 9 global test acc  34.4100
Round 10 global test acc  30.4400
Round 11 global test acc  36.4200
Round 12 global test acc  40.7000
Round 13 global test acc  34.3600
Round 14 global test acc  31.3100
Round 15 global test acc  34.9600
Round 16 global test acc  34.9800
Round 17 global test acc  32.4100
Round 18 global test acc  34.7200
Round 19 global test acc  35.4000
Round 20 global test acc  35.5200
Round 21 global test acc  31.7300
Round 22 global test acc  29.6100
Round 23 global test acc  31.4700
Round 24 global test acc  32.7200
Round 25 global test acc  37.3800
Round 26 global test acc  30.3700
Round 27 global test acc  36.8400
Round 28 global test acc  44.7900
Round 29 global test acc  34.2700
Round 30 global test acc  33.6300
Round 31 global test acc  36.6800
Round 32 global test acc  28.2800
Round 33 global test acc  42.3300
Round 34 global test acc  32.3200
Round 35 global test acc  40.1200
Round 36 global test acc  37.8500
Round 37 global test acc  37.6600
Round 38 global test acc  37.6100
Round 39 global test acc  35.1600
Round 40 global test acc  40.5600
Round 41 global test acc  35.6200
Round 42 global test acc  38.4700
Round 43 global test acc  40.3200
Round 44 global test acc  37.6300
Round 45 global test acc  36.3700
Round 46 global test acc  36.7100
Round 47 global test acc  39.2600
Round 48 global test acc  35.5900
Round 49 global test acc  32.8700
Round 50 global test acc  44.0100
Round 51 global test acc  38.7900
Round 52 global test acc  39.1800
Round 53 global test acc  31.3500
Round 54 global test acc  37.9400
Round 55 global test acc  41.1600
Round 56 global test acc  38.6100
Round 57 global test acc  31.7100
Round 58 global test acc  37.9400
Round 59 global test acc  38.2100
Round 60 global test acc  38.8300
Round 61 global test acc  37.4200
Round 62 global test acc  31.5100
Round 63 global test acc  40.0900
Round 64 global test acc  47.9500
Round 65 global test acc  44.4900
Round 66 global test acc  41.6700
Round 67 global test acc  40.1700
Round 68 global test acc  45.6900
Round 69 global test acc  39.2400
Round 70 global test acc  40.9500
Round 71 global test acc  34.6000
Round 72 global test acc  43.9500
Round 73 global test acc  37.1900
Round 74 global test acc  46.2800
Round 75 global test acc  42.1800
Round 76 global test acc  42.0600
Round 77 global test acc  42.9700
Round 78 global test acc  39.6800
Round 79 global test acc  40.4700
Round 80 global test acc  38.5900
Round 81 global test acc  38.0300
Round 82 global test acc  36.7400
Round 83 global test acc  36.2200
Round 84 global test acc  34.4300
Round 85 global test acc  33.7700
Round 86 global test acc  32.3400
Round 87 global test acc  30.9500
Round 88 global test acc  28.3300
Round 89 global test acc  28.9600
Round 90 global test acc  28.7100
Round 91 global test acc  27.9000
Round 92 global test acc  27.2000
Round 93 global test acc  26.3000
Round 94 global test acc  26.0300
Round 95 global test acc  25.5300
Round 96 global test acc  25.1300
Round 97 global test acc  24.4200
Round 98 global test acc  24.1000
Round 99 global test acc  23.7700
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 7, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 16, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 17, noise    level: 0.8000 
   Client 19, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 14, noise    level: 0.8000 
   Client 12, noise    level: 0.8000 
   Client 10, noise    level: 0.8000 
   Client 11, noise    level: 0.8000 
   Client 15, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.971, Test loss: 2.126, Test accuracy: 22.08
Round   1, Train loss: 1.531, Test loss: 1.970, Test accuracy: 29.64
Round   2, Train loss: 1.542, Test loss: 1.711, Test accuracy: 35.40
Round   3, Train loss: 1.506, Test loss: 1.484, Test accuracy: 41.66
Round   4, Train loss: 1.361, Test loss: 1.412, Test accuracy: 45.35
Round   5, Train loss: 1.274, Test loss: 1.285, Test accuracy: 50.36
Round   6, Train loss: 1.243, Test loss: 1.229, Test accuracy: 51.10
Round   7, Train loss: 1.211, Test loss: 1.190, Test accuracy: 52.62
Round   8, Train loss: 1.185, Test loss: 1.156, Test accuracy: 54.79
Round   9, Train loss: 1.091, Test loss: 1.083, Test accuracy: 58.05
Round  10, Train loss: 1.106, Test loss: 1.068, Test accuracy: 59.10
Round  11, Train loss: 1.116, Test loss: 1.063, Test accuracy: 59.33
Round  12, Train loss: 1.077, Test loss: 1.065, Test accuracy: 60.87
Round  13, Train loss: 1.148, Test loss: 1.016, Test accuracy: 61.48
Round  14, Train loss: 1.086, Test loss: 1.001, Test accuracy: 61.86
Round  15, Train loss: 1.014, Test loss: 0.971, Test accuracy: 63.50
Round  16, Train loss: 1.104, Test loss: 0.980, Test accuracy: 63.33
Round  17, Train loss: 0.997, Test loss: 0.971, Test accuracy: 63.75
Round  18, Train loss: 1.029, Test loss: 0.945, Test accuracy: 64.58
Round  19, Train loss: 1.014, Test loss: 0.956, Test accuracy: 64.44
Round  20, Train loss: 0.987, Test loss: 0.937, Test accuracy: 65.28
Round  21, Train loss: 0.993, Test loss: 0.914, Test accuracy: 66.22
Round  22, Train loss: 0.950, Test loss: 0.909, Test accuracy: 66.20
Round  23, Train loss: 0.993, Test loss: 0.901, Test accuracy: 66.68
Round  24, Train loss: 0.929, Test loss: 0.880, Test accuracy: 67.05
Round  25, Train loss: 0.965, Test loss: 0.872, Test accuracy: 67.46
Round  26, Train loss: 0.860, Test loss: 0.880, Test accuracy: 67.61
Round  27, Train loss: 0.897, Test loss: 0.859, Test accuracy: 67.84
Round  28, Train loss: 0.861, Test loss: 0.862, Test accuracy: 67.32
Round  29, Train loss: 0.833, Test loss: 0.848, Test accuracy: 68.37
Round  30, Train loss: 0.857, Test loss: 0.864, Test accuracy: 67.56
Round  31, Train loss: 0.867, Test loss: 0.863, Test accuracy: 68.05
Round  32, Train loss: 0.805, Test loss: 0.857, Test accuracy: 68.37
Round  33, Train loss: 0.822, Test loss: 0.818, Test accuracy: 69.74
Round  34, Train loss: 0.880, Test loss: 0.815, Test accuracy: 70.41
Round  35, Train loss: 0.835, Test loss: 0.809, Test accuracy: 70.32
Round  36, Train loss: 0.865, Test loss: 0.812, Test accuracy: 70.56
Round  37, Train loss: 0.712, Test loss: 0.811, Test accuracy: 71.09
Round  38, Train loss: 0.851, Test loss: 0.800, Test accuracy: 70.94
Round  39, Train loss: 0.751, Test loss: 0.793, Test accuracy: 71.54
Round  40, Train loss: 0.731, Test loss: 0.794, Test accuracy: 71.30
Round  41, Train loss: 0.768, Test loss: 0.792, Test accuracy: 71.45
Round  42, Train loss: 0.686, Test loss: 0.779, Test accuracy: 71.47
Round  43, Train loss: 0.790, Test loss: 0.776, Test accuracy: 71.98
Round  44, Train loss: 0.707, Test loss: 0.767, Test accuracy: 72.26
Round  45, Train loss: 0.888, Test loss: 0.770, Test accuracy: 71.72
Round  46, Train loss: 0.859, Test loss: 0.768, Test accuracy: 72.25
Round  47, Train loss: 0.697, Test loss: 0.770, Test accuracy: 72.14
Round  48, Train loss: 0.756, Test loss: 0.760, Test accuracy: 72.46
Round  49, Train loss: 0.810, Test loss: 0.766, Test accuracy: 72.01
Round  50, Train loss: 0.804, Test loss: 0.757, Test accuracy: 72.51
Round  51, Train loss: 0.714, Test loss: 0.742, Test accuracy: 72.91
Round  52, Train loss: 0.777, Test loss: 0.735, Test accuracy: 73.29
Round  53, Train loss: 0.774, Test loss: 0.745, Test accuracy: 72.82
Round  54, Train loss: 0.722, Test loss: 0.738, Test accuracy: 73.18
Round  55, Train loss: 0.663, Test loss: 0.732, Test accuracy: 73.61
Round  56, Train loss: 0.673, Test loss: 0.743, Test accuracy: 73.43
Round  57, Train loss: 0.830, Test loss: 0.729, Test accuracy: 73.92
Round  58, Train loss: 0.724, Test loss: 0.743, Test accuracy: 73.66
Round  59, Train loss: 0.691, Test loss: 0.741, Test accuracy: 72.99
Round  60, Train loss: 0.559, Test loss: 0.735, Test accuracy: 73.28
Round  61, Train loss: 0.672, Test loss: 0.744, Test accuracy: 73.19
Round  62, Train loss: 0.591, Test loss: 0.734, Test accuracy: 73.84
Round  63, Train loss: 0.711, Test loss: 0.716, Test accuracy: 74.42
Round  64, Train loss: 0.609, Test loss: 0.710, Test accuracy: 74.28
Round  65, Train loss: 0.646, Test loss: 0.720, Test accuracy: 74.19
Round  66, Train loss: 0.647, Test loss: 0.723, Test accuracy: 74.39
Round  67, Train loss: 0.634, Test loss: 0.718, Test accuracy: 74.44
Round  68, Train loss: 0.617, Test loss: 0.714, Test accuracy: 74.52
Round  69, Train loss: 0.604, Test loss: 0.709, Test accuracy: 74.56
Round  70, Train loss: 0.612, Test loss: 0.710, Test accuracy: 74.48
Round  71, Train loss: 0.606, Test loss: 0.716, Test accuracy: 74.50
Round  72, Train loss: 0.699, Test loss: 0.707, Test accuracy: 74.86
Round  73, Train loss: 0.651, Test loss: 0.716, Test accuracy: 74.58
Round  74, Train loss: 0.517, Test loss: 0.714, Test accuracy: 74.81
Round  75, Train loss: 0.548, Test loss: 0.708, Test accuracy: 74.52
Round  76, Train loss: 0.568, Test loss: 0.707, Test accuracy: 74.44
Round  77, Train loss: 0.694, Test loss: 0.712, Test accuracy: 74.83
Round  78, Train loss: 0.538, Test loss: 0.705, Test accuracy: 74.78
Round  79, Train loss: 0.594, Test loss: 0.695, Test accuracy: 75.17
Round  80, Train loss: 0.540, Test loss: 0.711, Test accuracy: 74.58
Round  81, Train loss: 0.478, Test loss: 0.704, Test accuracy: 74.96
Round  82, Train loss: 0.526, Test loss: 0.699, Test accuracy: 75.10
Round  83, Train loss: 0.529, Test loss: 0.704, Test accuracy: 74.86
Round  84, Train loss: 0.552, Test loss: 0.698, Test accuracy: 74.69
Round  85, Train loss: 0.515, Test loss: 0.696, Test accuracy: 75.17
Round  86, Train loss: 0.592, Test loss: 0.698, Test accuracy: 75.22
Round  87, Train loss: 0.524, Test loss: 0.702, Test accuracy: 75.11
Round  88, Train loss: 0.586, Test loss: 0.700, Test accuracy: 75.08
Round  89, Train loss: 0.510, Test loss: 0.707, Test accuracy: 74.95
Round  90, Train loss: 0.589, Test loss: 0.707, Test accuracy: 75.14
Round  91, Train loss: 0.548, Test loss: 0.708, Test accuracy: 74.93
Round  92, Train loss: 0.539, Test loss: 0.696, Test accuracy: 75.26
Round  93, Train loss: 0.494, Test loss: 0.699, Test accuracy: 75.63
Round  94, Train loss: 0.488, Test loss: 0.701, Test accuracy: 75.23
Round  95, Train loss: 0.456, Test loss: 0.712, Test accuracy: 75.00
Round  96, Train loss: 0.455, Test loss: 0.711, Test accuracy: 74.81
Round  97, Train loss: 0.564, Test loss: 0.704, Test accuracy: 74.91
Round  98, Train loss: 0.497, Test loss: 0.704, Test accuracy: 75.18
Round  99, Train loss: 0.577, Test loss: 0.705, Test accuracy: 75.33
Final Round, Train loss: 0.449, Test loss: 0.693, Test accuracy: 75.71
Average accuracy final 10 rounds: 75.14200000000001
1072.7011144161224
[1.7096712589263916, 3.06191086769104, 4.370060920715332, 5.6830384731292725, 7.041986465454102, 8.405855894088745, 9.766064405441284, 11.121243000030518, 12.481367111206055, 13.844173669815063, 15.20525312423706, 16.55581521987915, 17.905496835708618, 19.265876531600952, 20.62313199043274, 21.979679346084595, 23.329768657684326, 24.692038774490356, 26.05280303955078, 27.40728259086609, 28.738797426223755, 30.078911781311035, 31.421798944473267, 32.78257918357849, 34.13583779335022, 35.48965525627136, 36.846829652786255, 38.20543885231018, 39.56309723854065, 40.91430401802063, 42.27090096473694, 43.62627673149109, 44.97921538352966, 46.3246910572052, 47.68301033973694, 49.04766654968262, 50.41078209877014, 51.75909900665283, 53.13533616065979, 54.49290370941162, 55.86405682563782, 57.234375953674316, 58.60461688041687, 59.974422454833984, 61.33200526237488, 62.68473482131958, 64.0398759841919, 65.39424443244934, 66.74971413612366, 68.0973379611969, 69.45336771011353, 70.81404876708984, 72.17216682434082, 73.53055453300476, 74.88131928443909, 76.24759697914124, 77.60623693466187, 78.96190619468689, 80.30818200111389, 81.66918778419495, 83.03430986404419, 84.40074634552002, 85.76014137268066, 87.11749911308289, 88.48277473449707, 89.84545230865479, 91.19948625564575, 92.5570330619812, 93.92158627510071, 95.28452730178833, 96.64750528335571, 98.0173659324646, 99.39216661453247, 100.75185871124268, 102.10877513885498, 103.46000385284424, 104.82138848304749, 106.18273830413818, 107.53920793533325, 108.88801288604736, 110.24695420265198, 111.60634112358093, 112.97292876243591, 114.33352780342102, 115.69796681404114, 117.06536674499512, 118.4196126461029, 119.77269697189331, 121.1257803440094, 122.4094762802124, 123.75875306129456, 125.1102032661438, 126.45929908752441, 127.83555030822754, 129.193701505661, 130.57098960876465, 131.93578433990479, 133.30923581123352, 134.6774604320526, 136.0501742362976, 138.0823266506195]
[22.08, 29.64, 35.4, 41.66, 45.35, 50.36, 51.1, 52.62, 54.79, 58.05, 59.1, 59.33, 60.87, 61.48, 61.86, 63.5, 63.33, 63.75, 64.58, 64.44, 65.28, 66.22, 66.2, 66.68, 67.05, 67.46, 67.61, 67.84, 67.32, 68.37, 67.56, 68.05, 68.37, 69.74, 70.41, 70.32, 70.56, 71.09, 70.94, 71.54, 71.3, 71.45, 71.47, 71.98, 72.26, 71.72, 72.25, 72.14, 72.46, 72.01, 72.51, 72.91, 73.29, 72.82, 73.18, 73.61, 73.43, 73.92, 73.66, 72.99, 73.28, 73.19, 73.84, 74.42, 74.28, 74.19, 74.39, 74.44, 74.52, 74.56, 74.48, 74.5, 74.86, 74.58, 74.81, 74.52, 74.44, 74.83, 74.78, 75.17, 74.58, 74.96, 75.1, 74.86, 74.69, 75.17, 75.22, 75.11, 75.08, 74.95, 75.14, 74.93, 75.26, 75.63, 75.23, 75.0, 74.81, 74.91, 75.18, 75.33, 75.71]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.6 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 11, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 17, noise    level: 0.8000 
   Client 12, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 15, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
   Client 16, noise    level: 0.8000 
   Client 19, noise    level: 0.8000 
   Client 14, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.950, Test loss: 2.240, Test accuracy: 10.35
Round   1, Train loss: 1.547, Test loss: 1.989, Test accuracy: 29.26
Round   2, Train loss: 1.467, Test loss: 1.684, Test accuracy: 36.24
Round   3, Train loss: 1.384, Test loss: 1.464, Test accuracy: 43.25
Round   4, Train loss: 1.384, Test loss: 1.381, Test accuracy: 46.50
Round   5, Train loss: 1.238, Test loss: 1.266, Test accuracy: 50.69
Round   6, Train loss: 1.223, Test loss: 1.203, Test accuracy: 52.88
Round   7, Train loss: 1.272, Test loss: 1.157, Test accuracy: 53.33
Round   8, Train loss: 1.201, Test loss: 1.106, Test accuracy: 56.00
Round   9, Train loss: 1.084, Test loss: 1.082, Test accuracy: 56.93
Round  10, Train loss: 1.030, Test loss: 1.067, Test accuracy: 57.97
Round  11, Train loss: 1.069, Test loss: 1.056, Test accuracy: 58.58
Round  12, Train loss: 1.137, Test loss: 1.034, Test accuracy: 59.28
Round  13, Train loss: 1.101, Test loss: 1.028, Test accuracy: 59.87
Round  14, Train loss: 1.016, Test loss: 1.013, Test accuracy: 61.25
Round  15, Train loss: 1.126, Test loss: 0.996, Test accuracy: 61.61
Round  16, Train loss: 1.167, Test loss: 1.006, Test accuracy: 61.91
Round  17, Train loss: 0.955, Test loss: 0.975, Test accuracy: 62.69
Round  18, Train loss: 1.034, Test loss: 0.977, Test accuracy: 62.35
Round  19, Train loss: 0.931, Test loss: 0.957, Test accuracy: 62.87
Round  20, Train loss: 1.000, Test loss: 0.958, Test accuracy: 62.87
Round  21, Train loss: 0.965, Test loss: 0.943, Test accuracy: 63.75
Round  22, Train loss: 0.939, Test loss: 0.931, Test accuracy: 64.23
Round  23, Train loss: 0.915, Test loss: 0.909, Test accuracy: 65.13
Round  24, Train loss: 0.889, Test loss: 0.897, Test accuracy: 66.00
Round  25, Train loss: 0.807, Test loss: 0.887, Test accuracy: 66.55
Round  26, Train loss: 0.836, Test loss: 0.884, Test accuracy: 66.47
Round  27, Train loss: 0.899, Test loss: 0.887, Test accuracy: 66.08
Round  28, Train loss: 0.856, Test loss: 0.884, Test accuracy: 66.51
Round  29, Train loss: 0.933, Test loss: 0.862, Test accuracy: 67.31
Round  30, Train loss: 0.829, Test loss: 0.862, Test accuracy: 67.56
Round  31, Train loss: 0.918, Test loss: 0.845, Test accuracy: 68.45
Round  32, Train loss: 0.878, Test loss: 0.839, Test accuracy: 68.60
Round  33, Train loss: 0.984, Test loss: 0.828, Test accuracy: 68.77
Round  34, Train loss: 0.841, Test loss: 0.828, Test accuracy: 69.00
Round  35, Train loss: 0.998, Test loss: 0.823, Test accuracy: 69.30
Round  36, Train loss: 0.811, Test loss: 0.822, Test accuracy: 69.05
Round  37, Train loss: 0.743, Test loss: 0.807, Test accuracy: 69.56
Round  38, Train loss: 0.816, Test loss: 0.805, Test accuracy: 69.60
Round  39, Train loss: 0.887, Test loss: 0.804, Test accuracy: 70.17
Round  40, Train loss: 0.700, Test loss: 0.801, Test accuracy: 69.88
Round  41, Train loss: 0.873, Test loss: 0.810, Test accuracy: 69.94
Round  42, Train loss: 0.692, Test loss: 0.794, Test accuracy: 70.61
Round  43, Train loss: 0.759, Test loss: 0.780, Test accuracy: 71.24
Round  44, Train loss: 0.740, Test loss: 0.773, Test accuracy: 71.64
Round  45, Train loss: 0.845, Test loss: 0.757, Test accuracy: 71.91
Round  46, Train loss: 0.802, Test loss: 0.773, Test accuracy: 71.22
Round  47, Train loss: 0.757, Test loss: 0.776, Test accuracy: 71.29
Round  48, Train loss: 0.659, Test loss: 0.773, Test accuracy: 71.35
Round  49, Train loss: 0.701, Test loss: 0.769, Test accuracy: 71.38
Round  50, Train loss: 0.672, Test loss: 0.768, Test accuracy: 71.33
Round  51, Train loss: 0.714, Test loss: 0.764, Test accuracy: 71.78
Round  52, Train loss: 0.736, Test loss: 0.758, Test accuracy: 72.32
Round  53, Train loss: 0.696, Test loss: 0.746, Test accuracy: 72.46
Round  54, Train loss: 0.685, Test loss: 0.749, Test accuracy: 72.08
Round  55, Train loss: 0.642, Test loss: 0.749, Test accuracy: 72.34
Round  56, Train loss: 0.580, Test loss: 0.733, Test accuracy: 73.28
Round  57, Train loss: 0.735, Test loss: 0.735, Test accuracy: 73.12
Round  58, Train loss: 0.719, Test loss: 0.740, Test accuracy: 72.77
Round  59, Train loss: 0.651, Test loss: 0.749, Test accuracy: 72.58
Round  60, Train loss: 0.593, Test loss: 0.733, Test accuracy: 73.35
Round  61, Train loss: 0.590, Test loss: 0.730, Test accuracy: 73.22
Round  62, Train loss: 0.590, Test loss: 0.742, Test accuracy: 72.34
Round  63, Train loss: 0.679, Test loss: 0.732, Test accuracy: 72.92
Round  64, Train loss: 0.685, Test loss: 0.727, Test accuracy: 73.36
Round  65, Train loss: 0.561, Test loss: 0.726, Test accuracy: 73.46
Round  66, Train loss: 0.622, Test loss: 0.736, Test accuracy: 73.17
Round  67, Train loss: 0.548, Test loss: 0.738, Test accuracy: 73.02
Round  68, Train loss: 0.575, Test loss: 0.725, Test accuracy: 73.45
Round  69, Train loss: 0.722, Test loss: 0.722, Test accuracy: 73.62
Round  70, Train loss: 0.516, Test loss: 0.714, Test accuracy: 74.06
Round  71, Train loss: 0.529, Test loss: 0.716, Test accuracy: 73.93
Round  72, Train loss: 0.645, Test loss: 0.711, Test accuracy: 73.95
Round  73, Train loss: 0.639, Test loss: 0.716, Test accuracy: 73.67
Round  74, Train loss: 0.558, Test loss: 0.715, Test accuracy: 74.03
Round  75, Train loss: 0.591, Test loss: 0.719, Test accuracy: 73.78
Round  76, Train loss: 0.603, Test loss: 0.707, Test accuracy: 74.42
Round  77, Train loss: 0.569, Test loss: 0.706, Test accuracy: 74.49
Round  78, Train loss: 0.587, Test loss: 0.699, Test accuracy: 74.57
Round  79, Train loss: 0.554, Test loss: 0.702, Test accuracy: 74.51
Round  80, Train loss: 0.536, Test loss: 0.695, Test accuracy: 74.67
Round  81, Train loss: 0.512, Test loss: 0.711, Test accuracy: 74.26
Round  82, Train loss: 0.493, Test loss: 0.708, Test accuracy: 74.44
Round  83, Train loss: 0.520, Test loss: 0.707, Test accuracy: 74.20
Round  84, Train loss: 0.640, Test loss: 0.703, Test accuracy: 74.55
Round  85, Train loss: 0.638, Test loss: 0.687, Test accuracy: 75.06
Round  86, Train loss: 0.516, Test loss: 0.707, Test accuracy: 74.62
Round  87, Train loss: 0.522, Test loss: 0.705, Test accuracy: 74.52
Round  88, Train loss: 0.525, Test loss: 0.707, Test accuracy: 74.57
Round  89, Train loss: 0.540, Test loss: 0.703, Test accuracy: 74.61
Round  90, Train loss: 0.502, Test loss: 0.702, Test accuracy: 75.04
Round  91, Train loss: 0.643, Test loss: 0.710, Test accuracy: 74.59
Round  92, Train loss: 0.528, Test loss: 0.708, Test accuracy: 74.38
Round  93, Train loss: 0.407, Test loss: 0.703, Test accuracy: 74.97
Round  94, Train loss: 0.467, Test loss: 0.705, Test accuracy: 75.05
Round  95, Train loss: 0.458, Test loss: 0.702, Test accuracy: 75.26
Round  96, Train loss: 0.494, Test loss: 0.707, Test accuracy: 74.79
Round  97, Train loss: 0.535, Test loss: 0.706, Test accuracy: 75.20
Round  98, Train loss: 0.483, Test loss: 0.707, Test accuracy: 75.02
Round  99, Train loss: 0.565, Test loss: 0.705, Test accuracy: 75.28
Final Round, Train loss: 0.305, Test loss: 0.699, Test accuracy: 75.35
Average accuracy final 10 rounds: 74.95800000000001
1392.921852350235
[1.6073668003082275, 2.8863394260406494, 4.165245532989502, 5.44346809387207, 6.708823919296265, 7.978657007217407, 9.248625755310059, 10.519394874572754, 11.786517858505249, 13.053236722946167, 14.331230878829956, 15.6108717918396, 16.8911771774292, 18.164763927459717, 19.443207025527954, 20.72121286392212, 21.998616456985474, 23.276581525802612, 24.552582025527954, 25.82498049736023, 27.098365545272827, 29.179434537887573, 31.269782781600952, 33.38122534751892, 35.47012805938721, 37.58663606643677, 39.699928998947144, 41.791420221328735, 43.90653467178345, 46.01825499534607, 48.10429835319519, 50.21370768547058, 52.338847398757935, 54.421791315078735, 56.528929233551025, 58.638185262680054, 60.7234525680542, 62.83104753494263, 64.94166779518127, 67.03061628341675, 69.14408683776855, 71.25611543655396, 73.34540295600891, 75.45818066596985, 77.57096266746521, 79.65972638130188, 81.7725088596344, 83.88459348678589, 86.05183458328247, 88.1668643951416, 90.27559351921082, 92.36268758773804, 94.47712516784668, 96.59660720825195, 98.68046045303345, 100.7923572063446, 102.9087462425232, 105.0010576248169, 107.11999750137329, 109.23498153686523, 111.3454225063324, 113.45790553092957, 115.57104015350342, 117.68523669242859, 119.79569745063782, 121.88297963142395, 123.96958899497986, 126.0573661327362, 128.14654183387756, 130.2313756942749, 132.3229625225067, 134.4101779460907, 136.48753428459167, 138.57719898223877, 140.66843008995056, 142.75166511535645, 144.84081387519836, 146.92569851875305, 149.00917530059814, 151.09847235679626, 153.18819093704224, 155.2725875377655, 157.35978269577026, 159.45090317726135, 161.5421507358551, 163.6322660446167, 165.71953797340393, 167.80014514923096, 169.88680386543274, 171.9742832183838, 174.05606818199158, 176.21357250213623, 178.3029294013977, 180.39433670043945, 182.4856822490692, 184.57231187820435, 186.66060137748718, 188.74850821495056, 190.8301727771759, 192.9183120727539, 194.94463872909546]
[10.35, 29.26, 36.24, 43.25, 46.5, 50.69, 52.88, 53.33, 56.0, 56.93, 57.97, 58.58, 59.28, 59.87, 61.25, 61.61, 61.91, 62.69, 62.35, 62.87, 62.87, 63.75, 64.23, 65.13, 66.0, 66.55, 66.47, 66.08, 66.51, 67.31, 67.56, 68.45, 68.6, 68.77, 69.0, 69.3, 69.05, 69.56, 69.6, 70.17, 69.88, 69.94, 70.61, 71.24, 71.64, 71.91, 71.22, 71.29, 71.35, 71.38, 71.33, 71.78, 72.32, 72.46, 72.08, 72.34, 73.28, 73.12, 72.77, 72.58, 73.35, 73.22, 72.34, 72.92, 73.36, 73.46, 73.17, 73.02, 73.45, 73.62, 74.06, 73.93, 73.95, 73.67, 74.03, 73.78, 74.42, 74.49, 74.57, 74.51, 74.67, 74.26, 74.44, 74.2, 74.55, 75.06, 74.62, 74.52, 74.57, 74.61, 75.04, 74.59, 74.38, 74.97, 75.05, 75.26, 74.79, 75.2, 75.02, 75.28, 75.35]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: none, level_n_system: 0.6 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 14, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 13, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 15, noise    level: 0.8000 
   Client 10, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 11, noise    level: 0.8000 
   Client 12, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 17, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.957, Test loss: 1.846, Test accuracy: 31.08
Round   1, Train loss: 1.579, Test loss: 1.461, Test accuracy: 41.40
Round   2, Train loss: 1.450, Test loss: 1.361, Test accuracy: 44.75
Round   3, Train loss: 1.385, Test loss: 1.293, Test accuracy: 48.83
Round   4, Train loss: 1.328, Test loss: 1.233, Test accuracy: 51.19
Round   5, Train loss: 1.281, Test loss: 1.174, Test accuracy: 53.44
Round   6, Train loss: 1.239, Test loss: 1.146, Test accuracy: 55.23
Round   7, Train loss: 1.208, Test loss: 1.110, Test accuracy: 56.71
Round   8, Train loss: 1.181, Test loss: 1.084, Test accuracy: 57.85
Round   9, Train loss: 1.156, Test loss: 1.055, Test accuracy: 58.78
Round  10, Train loss: 1.133, Test loss: 1.033, Test accuracy: 60.40
Round  11, Train loss: 1.114, Test loss: 1.008, Test accuracy: 61.06
Round  12, Train loss: 1.095, Test loss: 1.001, Test accuracy: 61.76
Round  13, Train loss: 1.080, Test loss: 0.978, Test accuracy: 62.52
Round  14, Train loss: 1.060, Test loss: 0.968, Test accuracy: 62.68
Round  15, Train loss: 1.045, Test loss: 0.964, Test accuracy: 62.90
Round  16, Train loss: 1.035, Test loss: 0.943, Test accuracy: 63.96
Round  17, Train loss: 1.017, Test loss: 0.934, Test accuracy: 64.34
Round  18, Train loss: 1.003, Test loss: 0.921, Test accuracy: 64.97
Round  19, Train loss: 0.990, Test loss: 0.900, Test accuracy: 65.43
Round  20, Train loss: 0.987, Test loss: 0.907, Test accuracy: 65.29
Round  21, Train loss: 0.899, Test loss: 0.897, Test accuracy: 65.85
Round  22, Train loss: 0.978, Test loss: 0.889, Test accuracy: 66.23
Round  23, Train loss: 0.839, Test loss: 0.885, Test accuracy: 66.25
Round  24, Train loss: 0.860, Test loss: 0.882, Test accuracy: 66.70
Round  25, Train loss: 1.009, Test loss: 0.876, Test accuracy: 66.74
Round  26, Train loss: 0.958, Test loss: 0.883, Test accuracy: 67.06
Round  27, Train loss: 0.825, Test loss: 0.860, Test accuracy: 67.61
Round  28, Train loss: 0.992, Test loss: 0.861, Test accuracy: 67.59
Round  29, Train loss: 0.889, Test loss: 0.855, Test accuracy: 67.96
Round  30, Train loss: 0.930, Test loss: 0.858, Test accuracy: 67.66
Round  31, Train loss: 0.869, Test loss: 0.840, Test accuracy: 68.13
Round  32, Train loss: 0.923, Test loss: 0.843, Test accuracy: 67.94
Round  33, Train loss: 0.717, Test loss: 0.835, Test accuracy: 68.36
Round  34, Train loss: 0.813, Test loss: 0.833, Test accuracy: 68.44
Round  35, Train loss: 0.831, Test loss: 0.822, Test accuracy: 69.06
Round  36, Train loss: 0.849, Test loss: 0.816, Test accuracy: 69.32
Round  37, Train loss: 0.807, Test loss: 0.801, Test accuracy: 70.15
Round  38, Train loss: 0.897, Test loss: 0.797, Test accuracy: 69.77
Round  39, Train loss: 0.737, Test loss: 0.795, Test accuracy: 70.05
Round  40, Train loss: 0.798, Test loss: 0.793, Test accuracy: 69.85
Round  41, Train loss: 0.825, Test loss: 0.780, Test accuracy: 70.64
Round  42, Train loss: 0.840, Test loss: 0.790, Test accuracy: 70.55
Round  43, Train loss: 0.791, Test loss: 0.795, Test accuracy: 70.30
Round  44, Train loss: 0.684, Test loss: 0.793, Test accuracy: 70.26
Round  45, Train loss: 0.724, Test loss: 0.780, Test accuracy: 70.32
Round  46, Train loss: 0.795, Test loss: 0.775, Test accuracy: 70.86
Round  47, Train loss: 0.802, Test loss: 0.773, Test accuracy: 70.93
Round  48, Train loss: 0.826, Test loss: 0.769, Test accuracy: 71.03
Round  49, Train loss: 0.828, Test loss: 0.771, Test accuracy: 71.23
Round  50, Train loss: 0.719, Test loss: 0.771, Test accuracy: 71.34
Round  51, Train loss: 0.756, Test loss: 0.764, Test accuracy: 71.49
Round  52, Train loss: 0.642, Test loss: 0.757, Test accuracy: 71.73
Round  53, Train loss: 0.719, Test loss: 0.756, Test accuracy: 72.01
Round  54, Train loss: 0.741, Test loss: 0.760, Test accuracy: 71.80
Round  55, Train loss: 0.543, Test loss: 0.758, Test accuracy: 71.94
Round  56, Train loss: 0.724, Test loss: 0.752, Test accuracy: 72.16
Round  57, Train loss: 0.681, Test loss: 0.763, Test accuracy: 71.88
Round  58, Train loss: 0.783, Test loss: 0.771, Test accuracy: 71.84
Round  59, Train loss: 0.759, Test loss: 0.766, Test accuracy: 72.10
Round  60, Train loss: 0.642, Test loss: 0.765, Test accuracy: 72.14
Round  61, Train loss: 0.664, Test loss: 0.752, Test accuracy: 72.56
Round  62, Train loss: 0.661, Test loss: 0.744, Test accuracy: 72.76
Round  63, Train loss: 0.639, Test loss: 0.745, Test accuracy: 72.82
Round  64, Train loss: 0.677, Test loss: 0.747, Test accuracy: 72.46
Round  65, Train loss: 0.667, Test loss: 0.741, Test accuracy: 72.90
Round  66, Train loss: 0.620, Test loss: 0.739, Test accuracy: 72.96
Round  67, Train loss: 0.606, Test loss: 0.735, Test accuracy: 72.86
Round  68, Train loss: 0.679, Test loss: 0.751, Test accuracy: 72.16
Round  69, Train loss: 0.640, Test loss: 0.746, Test accuracy: 72.68
Round  70, Train loss: 0.665, Test loss: 0.741, Test accuracy: 73.22
Round  71, Train loss: 0.576, Test loss: 0.750, Test accuracy: 72.81
Round  72, Train loss: 0.609, Test loss: 0.734, Test accuracy: 73.37
Round  73, Train loss: 0.553, Test loss: 0.733, Test accuracy: 73.42
Round  74, Train loss: 0.654, Test loss: 0.735, Test accuracy: 73.16
Round  75, Train loss: 0.601, Test loss: 0.726, Test accuracy: 73.86
Round  76, Train loss: 0.630, Test loss: 0.729, Test accuracy: 73.33
Round  77, Train loss: 0.569, Test loss: 0.727, Test accuracy: 73.52
Round  78, Train loss: 0.556, Test loss: 0.730, Test accuracy: 73.53
Round  79, Train loss: 0.535, Test loss: 0.725, Test accuracy: 73.60
Round  80, Train loss: 0.429, Test loss: 0.718, Test accuracy: 73.88
Round  81, Train loss: 0.414, Test loss: 0.722, Test accuracy: 73.68
Round  82, Train loss: 0.396, Test loss: 0.722, Test accuracy: 74.20
Round  83, Train loss: 0.390, Test loss: 0.716, Test accuracy: 74.40
Round  84, Train loss: 0.381, Test loss: 0.726, Test accuracy: 73.81
Round  85, Train loss: 0.365, Test loss: 0.719, Test accuracy: 73.96
Round  86, Train loss: 0.355, Test loss: 0.724, Test accuracy: 74.19
Round  87, Train loss: 0.346, Test loss: 0.722, Test accuracy: 74.23
Round  88, Train loss: 0.348, Test loss: 0.724, Test accuracy: 74.10
Round  89, Train loss: 0.337, Test loss: 0.723, Test accuracy: 74.38
Round  90, Train loss: 0.333, Test loss: 0.740, Test accuracy: 73.73
Round  91, Train loss: 0.324, Test loss: 0.735, Test accuracy: 74.05
Round  92, Train loss: 0.320, Test loss: 0.733, Test accuracy: 74.06
Round  93, Train loss: 0.310, Test loss: 0.739, Test accuracy: 73.67
Round  94, Train loss: 0.302, Test loss: 0.738, Test accuracy: 74.16
Round  95, Train loss: 0.301, Test loss: 0.736, Test accuracy: 74.22
Round  96, Train loss: 0.298, Test loss: 0.739, Test accuracy: 73.79
Round  97, Train loss: 0.288, Test loss: 0.738, Test accuracy: 74.08
Round  98, Train loss: 0.284, Test loss: 0.746, Test accuracy: 74.10
Round  99, Train loss: 0.283, Test loss: 0.743, Test accuracy: 74.05
Final Round, Train loss: 0.213, Test loss: 0.747, Test accuracy: 74.04
Average accuracy final 10 rounds: 73.991
1427.160736322403
[1.6217153072357178, 2.927680253982544, 4.228788614273071, 5.515712738037109, 6.799696683883667, 8.086281299591064, 9.380965232849121, 10.674580097198486, 11.965264558792114, 13.255845546722412, 14.552898168563843, 15.839720726013184, 17.127803564071655, 18.418009996414185, 19.707945823669434, 21.001118421554565, 22.29239797592163, 23.580820083618164, 24.87146019935608, 26.15789246559143, 27.4480562210083, 28.731669425964355, 30.01661968231201, 31.29582381248474, 32.57679867744446, 33.858235359191895, 35.138057231903076, 36.41917705535889, 37.697527170181274, 38.980013847351074, 40.264862060546875, 41.545016288757324, 42.82236671447754, 44.105674028396606, 45.3878653049469, 46.66847372055054, 47.94660711288452, 49.22517251968384, 50.50683331489563, 51.786582469940186, 53.06879758834839, 54.34751033782959, 55.626976013183594, 56.90908694267273, 58.19137120246887, 59.46913194656372, 60.7491090297699, 61.91583514213562, 63.08371162414551, 64.24540781974792, 65.41268038749695, 66.58438229560852, 67.75355911254883, 68.91291379928589, 70.07612633705139, 71.2391746044159, 72.41424250602722, 73.58196640014648, 74.75788402557373, 75.92078971862793, 77.0904393196106, 78.25622344017029, 79.41192436218262, 80.56688952445984, 81.7166817188263, 82.86698937416077, 84.03385329246521, 85.19746804237366, 86.36033058166504, 87.52440428733826, 88.67763876914978, 89.84273767471313, 91.01938772201538, 92.18151640892029, 93.34194588661194, 94.49719142913818, 95.65194320678711, 96.82185888290405, 97.98509216308594, 99.14501953125, 100.30030059814453, 101.4592752456665, 102.62784075737, 103.78714323043823, 104.94511294364929, 106.10065007209778, 107.25692319869995, 108.43045687675476, 109.59517908096313, 110.76755261421204, 111.94134736061096, 113.1100172996521, 114.27925825119019, 115.45429611206055, 116.62446546554565, 117.8013346195221, 118.96983051300049, 120.14431428909302, 121.31286096572876, 122.47378540039062, 124.37703728675842]
[31.08, 41.4, 44.75, 48.83, 51.19, 53.44, 55.23, 56.71, 57.85, 58.78, 60.4, 61.06, 61.76, 62.52, 62.68, 62.9, 63.96, 64.34, 64.97, 65.43, 65.29, 65.85, 66.23, 66.25, 66.7, 66.74, 67.06, 67.61, 67.59, 67.96, 67.66, 68.13, 67.94, 68.36, 68.44, 69.06, 69.32, 70.15, 69.77, 70.05, 69.85, 70.64, 70.55, 70.3, 70.26, 70.32, 70.86, 70.93, 71.03, 71.23, 71.34, 71.49, 71.73, 72.01, 71.8, 71.94, 72.16, 71.88, 71.84, 72.1, 72.14, 72.56, 72.76, 72.82, 72.46, 72.9, 72.96, 72.86, 72.16, 72.68, 73.22, 72.81, 73.37, 73.42, 73.16, 73.86, 73.33, 73.52, 73.53, 73.6, 73.88, 73.68, 74.2, 74.4, 73.81, 73.96, 74.19, 74.23, 74.1, 74.38, 73.73, 74.05, 74.06, 73.67, 74.16, 74.22, 73.79, 74.08, 74.1, 74.05, 74.04]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.6 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 14, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
   Client 16, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 11, noise    level: 0.8000 
   Client 13, noise    level: 0.8000 
   Client 12, noise    level: 0.8000 
   Client 15, noise    level: 0.8000 
   Client 17, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 19, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.999, Test loss: 1.935, Test accuracy: 28.00
Round   1, Train loss: 1.638, Test loss: 1.508, Test accuracy: 40.36
Round   2, Train loss: 1.490, Test loss: 1.390, Test accuracy: 45.24
Round   3, Train loss: 1.416, Test loss: 1.315, Test accuracy: 48.70
Round   4, Train loss: 1.358, Test loss: 1.263, Test accuracy: 50.91
Round   5, Train loss: 1.312, Test loss: 1.206, Test accuracy: 53.34
Round   6, Train loss: 1.269, Test loss: 1.164, Test accuracy: 55.32
Round   7, Train loss: 1.238, Test loss: 1.142, Test accuracy: 56.44
Round   8, Train loss: 1.213, Test loss: 1.119, Test accuracy: 57.20
Round   9, Train loss: 1.185, Test loss: 1.097, Test accuracy: 58.48
Round  10, Train loss: 1.164, Test loss: 1.072, Test accuracy: 59.63
Round  11, Train loss: 1.144, Test loss: 1.061, Test accuracy: 60.59
Round  12, Train loss: 1.127, Test loss: 1.035, Test accuracy: 61.51
Round  13, Train loss: 1.107, Test loss: 1.026, Test accuracy: 61.83
Round  14, Train loss: 1.095, Test loss: 1.009, Test accuracy: 62.60
Round  15, Train loss: 1.078, Test loss: 0.993, Test accuracy: 63.54
Round  16, Train loss: 1.065, Test loss: 0.990, Test accuracy: 63.41
Round  17, Train loss: 1.052, Test loss: 0.974, Test accuracy: 64.45
Round  18, Train loss: 1.036, Test loss: 0.968, Test accuracy: 64.72
Round  19, Train loss: 1.021, Test loss: 0.945, Test accuracy: 65.26
Round  20, Train loss: 0.968, Test loss: 0.946, Test accuracy: 65.07
Round  21, Train loss: 0.975, Test loss: 0.952, Test accuracy: 64.90
Round  22, Train loss: 0.930, Test loss: 0.933, Test accuracy: 65.51
Round  23, Train loss: 0.904, Test loss: 0.917, Test accuracy: 65.96
Round  24, Train loss: 0.929, Test loss: 0.912, Test accuracy: 66.09
Round  25, Train loss: 0.923, Test loss: 0.922, Test accuracy: 65.42
Round  26, Train loss: 0.947, Test loss: 0.914, Test accuracy: 65.87
Round  27, Train loss: 0.929, Test loss: 0.911, Test accuracy: 66.47
Round  28, Train loss: 0.941, Test loss: 0.889, Test accuracy: 67.67
Round  29, Train loss: 0.999, Test loss: 0.895, Test accuracy: 67.17
Round  30, Train loss: 0.916, Test loss: 0.883, Test accuracy: 67.33
Round  31, Train loss: 0.866, Test loss: 0.874, Test accuracy: 67.82
Round  32, Train loss: 1.058, Test loss: 0.870, Test accuracy: 68.16
Round  33, Train loss: 0.758, Test loss: 0.870, Test accuracy: 68.11
Round  34, Train loss: 0.760, Test loss: 0.865, Test accuracy: 68.41
Round  35, Train loss: 0.977, Test loss: 0.863, Test accuracy: 68.60
Round  36, Train loss: 0.856, Test loss: 0.846, Test accuracy: 69.37
Round  37, Train loss: 0.820, Test loss: 0.845, Test accuracy: 69.25
Round  38, Train loss: 0.909, Test loss: 0.848, Test accuracy: 69.11
Round  39, Train loss: 0.751, Test loss: 0.840, Test accuracy: 69.37
Round  40, Train loss: 0.729, Test loss: 0.845, Test accuracy: 69.23
Round  41, Train loss: 0.947, Test loss: 0.842, Test accuracy: 69.92
Round  42, Train loss: 0.886, Test loss: 0.849, Test accuracy: 69.25
Round  43, Train loss: 0.832, Test loss: 0.829, Test accuracy: 69.63
Round  44, Train loss: 0.728, Test loss: 0.823, Test accuracy: 69.80
Round  45, Train loss: 0.820, Test loss: 0.828, Test accuracy: 69.98
Round  46, Train loss: 0.817, Test loss: 0.822, Test accuracy: 70.52
Round  47, Train loss: 0.867, Test loss: 0.813, Test accuracy: 71.18
Round  48, Train loss: 0.753, Test loss: 0.807, Test accuracy: 71.01
Round  49, Train loss: 0.899, Test loss: 0.812, Test accuracy: 71.20
Round  50, Train loss: 0.779, Test loss: 0.816, Test accuracy: 71.00
Round  51, Train loss: 0.830, Test loss: 0.804, Test accuracy: 71.15
Round  52, Train loss: 0.660, Test loss: 0.803, Test accuracy: 70.99
Round  53, Train loss: 0.694, Test loss: 0.792, Test accuracy: 71.82
Round  54, Train loss: 0.813, Test loss: 0.798, Test accuracy: 71.47
Round  55, Train loss: 0.587, Test loss: 0.794, Test accuracy: 71.65
Round  56, Train loss: 0.784, Test loss: 0.795, Test accuracy: 71.48
Round  57, Train loss: 0.659, Test loss: 0.784, Test accuracy: 71.88
Round  58, Train loss: 0.810, Test loss: 0.793, Test accuracy: 71.53
Round  59, Train loss: 0.675, Test loss: 0.786, Test accuracy: 71.84
Round  60, Train loss: 0.645, Test loss: 0.799, Test accuracy: 71.25
Round  61, Train loss: 0.631, Test loss: 0.802, Test accuracy: 71.33
Round  62, Train loss: 0.720, Test loss: 0.797, Test accuracy: 71.53
Round  63, Train loss: 0.671, Test loss: 0.795, Test accuracy: 71.96
Round  64, Train loss: 0.714, Test loss: 0.789, Test accuracy: 72.00
Round  65, Train loss: 0.621, Test loss: 0.787, Test accuracy: 72.13
Round  66, Train loss: 0.654, Test loss: 0.789, Test accuracy: 71.93
Round  67, Train loss: 0.669, Test loss: 0.793, Test accuracy: 71.86
Round  68, Train loss: 0.830, Test loss: 0.783, Test accuracy: 71.92
Round  69, Train loss: 0.638, Test loss: 0.779, Test accuracy: 72.56
Round  70, Train loss: 0.670, Test loss: 0.784, Test accuracy: 72.08
Round  71, Train loss: 0.579, Test loss: 0.797, Test accuracy: 71.67
Round  72, Train loss: 0.542, Test loss: 0.787, Test accuracy: 72.10
Round  73, Train loss: 0.621, Test loss: 0.788, Test accuracy: 72.06
Round  74, Train loss: 0.693, Test loss: 0.784, Test accuracy: 72.13
Round  75, Train loss: 0.651, Test loss: 0.784, Test accuracy: 72.13
Round  76, Train loss: 0.609, Test loss: 0.786, Test accuracy: 72.15
Round  77, Train loss: 0.604, Test loss: 0.771, Test accuracy: 72.73
Round  78, Train loss: 0.624, Test loss: 0.769, Test accuracy: 72.56
Round  79, Train loss: 0.671, Test loss: 0.773, Test accuracy: 72.60
Round  80, Train loss: 0.447, Test loss: 0.764, Test accuracy: 73.02
Round  81, Train loss: 0.426, Test loss: 0.763, Test accuracy: 73.08
Round  82, Train loss: 0.411, Test loss: 0.758, Test accuracy: 73.14
Round  83, Train loss: 0.392, Test loss: 0.760, Test accuracy: 73.02
Round  84, Train loss: 0.384, Test loss: 0.760, Test accuracy: 73.31
Round  85, Train loss: 0.377, Test loss: 0.757, Test accuracy: 73.11
Round  86, Train loss: 0.371, Test loss: 0.763, Test accuracy: 73.15
Round  87, Train loss: 0.366, Test loss: 0.757, Test accuracy: 73.34
Round  88, Train loss: 0.348, Test loss: 0.758, Test accuracy: 73.44
Round  89, Train loss: 0.343, Test loss: 0.760, Test accuracy: 73.24
Round  90, Train loss: 0.343, Test loss: 0.764, Test accuracy: 73.48
Round  91, Train loss: 0.334, Test loss: 0.765, Test accuracy: 73.41
Round  92, Train loss: 0.328, Test loss: 0.765, Test accuracy: 73.63
Round  93, Train loss: 0.321, Test loss: 0.769, Test accuracy: 73.09
Round  94, Train loss: 0.313, Test loss: 0.771, Test accuracy: 72.89
Round  95, Train loss: 0.313, Test loss: 0.772, Test accuracy: 72.82
Round  96, Train loss: 0.304, Test loss: 0.770, Test accuracy: 73.36
Round  97, Train loss: 0.297, Test loss: 0.779, Test accuracy: 73.07
Round  98, Train loss: 0.289, Test loss: 0.780, Test accuracy: 73.26
Round  99, Train loss: 0.289, Test loss: 0.778, Test accuracy: 73.02
Final Round, Train loss: 0.221, Test loss: 0.785, Test accuracy: 72.91
Average accuracy final 10 rounds: 73.203
1840.17866396904
[1.5885612964630127, 2.886061191558838, 4.184723138809204, 5.495255708694458, 6.791360139846802, 8.091925621032715, 9.396759033203125, 10.694153308868408, 11.876522064208984, 13.05881381034851, 14.244916915893555, 15.427755117416382, 16.608464002609253, 17.78196358680725, 18.95514702796936, 20.12730860710144, 21.30264925956726, 22.47440242767334, 23.640097856521606, 24.808648347854614, 25.976807832717896, 27.998274087905884, 29.97719097137451, 31.97740888595581, 33.9794602394104, 35.95920133590698, 37.95988082885742, 39.96419811248779, 41.94232249259949, 43.94366645812988, 45.94628119468689, 47.92300629615784, 49.923940658569336, 51.93064069747925, 53.91139817237854, 55.91366505622864, 57.914942264556885, 59.8943772315979, 61.89271807670593, 63.89231276512146, 65.89308643341064, 67.89302849769592, 69.89673089981079, 71.90162563323975, 73.90342020988464, 75.90337824821472, 77.90452766418457, 79.90688800811768, 81.9134361743927, 83.95341300964355, 85.94758820533752, 87.95170879364014, 89.95852756500244, 91.95929408073425, 93.96281671524048, 95.96611380577087, 97.94568395614624, 99.95258402824402, 101.9554352760315, 103.93487572669983, 105.93896794319153, 107.94229650497437, 109.921879529953, 111.92281889915466, 113.92735290527344, 115.91262578964233, 117.91522169113159, 119.92053747177124, 121.9044017791748, 123.9075403213501, 125.91050505638123, 127.88854551315308, 129.89347791671753, 131.8969111442566, 133.8727948665619, 135.87487053871155, 137.87779426574707, 139.88183426856995, 141.88599395751953, 143.89328694343567, 145.89836478233337, 147.90555500984192, 149.8999137878418, 151.90537905693054, 153.90465664863586, 155.90454936027527, 157.89036107063293, 159.88490223884583, 161.8615424633026, 163.92632341384888, 165.9316017627716, 167.92870211601257, 169.9296646118164, 171.9273509979248, 173.9145188331604, 175.913147687912, 177.91221237182617, 179.92450332641602, 181.91803407669067, 183.9146168231964, 185.83250737190247]
[28.0, 40.36, 45.24, 48.7, 50.91, 53.34, 55.32, 56.44, 57.2, 58.48, 59.63, 60.59, 61.51, 61.83, 62.6, 63.54, 63.41, 64.45, 64.72, 65.26, 65.07, 64.9, 65.51, 65.96, 66.09, 65.42, 65.87, 66.47, 67.67, 67.17, 67.33, 67.82, 68.16, 68.11, 68.41, 68.6, 69.37, 69.25, 69.11, 69.37, 69.23, 69.92, 69.25, 69.63, 69.8, 69.98, 70.52, 71.18, 71.01, 71.2, 71.0, 71.15, 70.99, 71.82, 71.47, 71.65, 71.48, 71.88, 71.53, 71.84, 71.25, 71.33, 71.53, 71.96, 72.0, 72.13, 71.93, 71.86, 71.92, 72.56, 72.08, 71.67, 72.1, 72.06, 72.13, 72.13, 72.15, 72.73, 72.56, 72.6, 73.02, 73.08, 73.14, 73.02, 73.31, 73.11, 73.15, 73.34, 73.44, 73.24, 73.48, 73.41, 73.63, 73.09, 72.89, 72.82, 73.36, 73.07, 73.26, 73.02, 72.91]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.8 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 12, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
   Client 10, noise    level: 0.4000 
   Client 16, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 14, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 17, noise    level: 0.4000 
   Client 11, noise    level: 0.4000 
   Client 15, noise    level: 0.4000 
   Client 13, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 19, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.790, Test loss: 2.114, Test accuracy: 18.08
Round   0, Global train loss: 1.790, Global test loss: 2.303, Global test accuracy: 13.00
Round   1, Train loss: 1.652, Test loss: 1.935, Test accuracy: 26.98
Round   1, Global train loss: 1.652, Global test loss: 2.266, Global test accuracy: 20.81
Round   2, Train loss: 1.695, Test loss: 1.753, Test accuracy: 33.04
Round   2, Global train loss: 1.695, Global test loss: 2.210, Global test accuracy: 19.26
Round   3, Train loss: 1.716, Test loss: 1.611, Test accuracy: 36.41
Round   3, Global train loss: 1.716, Global test loss: 2.178, Global test accuracy: 21.57
Round   4, Train loss: 1.554, Test loss: 1.527, Test accuracy: 39.61
Round   4, Global train loss: 1.554, Global test loss: 2.095, Global test accuracy: 25.14
Round   5, Train loss: 1.591, Test loss: 1.523, Test accuracy: 40.54
Round   5, Global train loss: 1.591, Global test loss: 2.228, Global test accuracy: 23.25
Round   6, Train loss: 1.638, Test loss: 1.436, Test accuracy: 42.84
Round   6, Global train loss: 1.638, Global test loss: 2.169, Global test accuracy: 19.24
Round   7, Train loss: 1.521, Test loss: 1.431, Test accuracy: 43.03
Round   7, Global train loss: 1.521, Global test loss: 2.092, Global test accuracy: 23.74
Round   8, Train loss: 1.447, Test loss: 1.408, Test accuracy: 43.74
Round   8, Global train loss: 1.447, Global test loss: 2.074, Global test accuracy: 24.25
Round   9, Train loss: 1.492, Test loss: 1.397, Test accuracy: 44.02
Round   9, Global train loss: 1.492, Global test loss: 2.101, Global test accuracy: 23.06
Round  10, Train loss: 1.574, Test loss: 1.378, Test accuracy: 46.18
Round  10, Global train loss: 1.574, Global test loss: 2.098, Global test accuracy: 26.72
Round  11, Train loss: 1.460, Test loss: 1.382, Test accuracy: 45.00
Round  11, Global train loss: 1.460, Global test loss: 2.094, Global test accuracy: 23.20
Round  12, Train loss: 1.530, Test loss: 1.363, Test accuracy: 47.23
Round  12, Global train loss: 1.530, Global test loss: 2.024, Global test accuracy: 32.10
Round  13, Train loss: 1.338, Test loss: 1.308, Test accuracy: 48.89
Round  13, Global train loss: 1.338, Global test loss: 2.037, Global test accuracy: 31.31
Round  14, Train loss: 1.302, Test loss: 1.307, Test accuracy: 49.31
Round  14, Global train loss: 1.302, Global test loss: 1.988, Global test accuracy: 28.11
Round  15, Train loss: 1.451, Test loss: 1.303, Test accuracy: 49.73
Round  15, Global train loss: 1.451, Global test loss: 2.072, Global test accuracy: 23.35
Round  16, Train loss: 1.407, Test loss: 1.290, Test accuracy: 51.01
Round  16, Global train loss: 1.407, Global test loss: 2.080, Global test accuracy: 30.69
Round  17, Train loss: 1.382, Test loss: 1.287, Test accuracy: 51.47
Round  17, Global train loss: 1.382, Global test loss: 2.122, Global test accuracy: 30.81
Round  18, Train loss: 1.281, Test loss: 1.294, Test accuracy: 50.55
Round  18, Global train loss: 1.281, Global test loss: 2.073, Global test accuracy: 26.70
Round  19, Train loss: 1.264, Test loss: 1.283, Test accuracy: 50.61
Round  19, Global train loss: 1.264, Global test loss: 2.022, Global test accuracy: 29.62
Round  20, Train loss: 1.344, Test loss: 1.278, Test accuracy: 50.29
Round  20, Global train loss: 1.344, Global test loss: 2.054, Global test accuracy: 29.45
Round  21, Train loss: 1.409, Test loss: 1.280, Test accuracy: 50.17
Round  21, Global train loss: 1.409, Global test loss: 2.054, Global test accuracy: 30.13
Round  22, Train loss: 1.189, Test loss: 1.271, Test accuracy: 51.00
Round  22, Global train loss: 1.189, Global test loss: 2.021, Global test accuracy: 25.16
Round  23, Train loss: 1.242, Test loss: 1.275, Test accuracy: 51.14
Round  23, Global train loss: 1.242, Global test loss: 2.005, Global test accuracy: 32.94
Round  24, Train loss: 1.178, Test loss: 1.286, Test accuracy: 50.84
Round  24, Global train loss: 1.178, Global test loss: 1.937, Global test accuracy: 29.56
Round  25, Train loss: 1.245, Test loss: 1.285, Test accuracy: 51.22
Round  25, Global train loss: 1.245, Global test loss: 2.145, Global test accuracy: 23.99
Round  26, Train loss: 1.316, Test loss: 1.288, Test accuracy: 51.26
Round  26, Global train loss: 1.316, Global test loss: 2.175, Global test accuracy: 22.35
Round  27, Train loss: 1.280, Test loss: 1.283, Test accuracy: 50.02
Round  27, Global train loss: 1.280, Global test loss: 1.976, Global test accuracy: 32.47
Round  28, Train loss: 1.091, Test loss: 1.306, Test accuracy: 49.66
Round  28, Global train loss: 1.091, Global test loss: 2.088, Global test accuracy: 29.05
Round  29, Train loss: 1.188, Test loss: 1.297, Test accuracy: 50.79
Round  29, Global train loss: 1.188, Global test loss: 1.943, Global test accuracy: 36.86
Round  30, Train loss: 1.047, Test loss: 1.299, Test accuracy: 50.75
Round  30, Global train loss: 1.047, Global test loss: 2.027, Global test accuracy: 31.49
Round  31, Train loss: 1.057, Test loss: 1.305, Test accuracy: 51.20
Round  31, Global train loss: 1.057, Global test loss: 1.989, Global test accuracy: 32.24
Round  32, Train loss: 1.029, Test loss: 1.325, Test accuracy: 50.85
Round  32, Global train loss: 1.029, Global test loss: 2.020, Global test accuracy: 30.52
Round  33, Train loss: 1.044, Test loss: 1.352, Test accuracy: 50.42
Round  33, Global train loss: 1.044, Global test loss: 1.981, Global test accuracy: 30.80
Round  34, Train loss: 1.075, Test loss: 1.354, Test accuracy: 50.46
Round  34, Global train loss: 1.075, Global test loss: 2.053, Global test accuracy: 30.29
Round  35, Train loss: 1.074, Test loss: 1.372, Test accuracy: 49.90
Round  35, Global train loss: 1.074, Global test loss: 1.921, Global test accuracy: 33.86
Round  36, Train loss: 1.065, Test loss: 1.377, Test accuracy: 50.47
Round  36, Global train loss: 1.065, Global test loss: 2.041, Global test accuracy: 29.83
Round  37, Train loss: 1.009, Test loss: 1.393, Test accuracy: 50.87
Round  37, Global train loss: 1.009, Global test loss: 2.023, Global test accuracy: 30.18
Round  38, Train loss: 0.933, Test loss: 1.412, Test accuracy: 50.72
Round  38, Global train loss: 0.933, Global test loss: 2.067, Global test accuracy: 29.60
Round  39, Train loss: 1.002, Test loss: 1.421, Test accuracy: 50.10
Round  39, Global train loss: 1.002, Global test loss: 2.055, Global test accuracy: 28.15
Round  40, Train loss: 0.988, Test loss: 1.459, Test accuracy: 49.93
Round  40, Global train loss: 0.988, Global test loss: 2.082, Global test accuracy: 27.74
Round  41, Train loss: 0.852, Test loss: 1.506, Test accuracy: 49.20
Round  41, Global train loss: 0.852, Global test loss: 1.954, Global test accuracy: 31.27
Round  42, Train loss: 0.753, Test loss: 1.541, Test accuracy: 48.23
Round  42, Global train loss: 0.753, Global test loss: 2.026, Global test accuracy: 29.60
Round  43, Train loss: 0.984, Test loss: 1.544, Test accuracy: 48.22
Round  43, Global train loss: 0.984, Global test loss: 2.081, Global test accuracy: 26.70
Round  44, Train loss: 0.913, Test loss: 1.566, Test accuracy: 47.86
Round  44, Global train loss: 0.913, Global test loss: 2.002, Global test accuracy: 32.38
Round  45, Train loss: 0.798, Test loss: 1.574, Test accuracy: 48.18
Round  45, Global train loss: 0.798, Global test loss: 2.020, Global test accuracy: 29.34
Round  46, Train loss: 0.937, Test loss: 1.576, Test accuracy: 48.39
Round  46, Global train loss: 0.937, Global test loss: 2.058, Global test accuracy: 30.39
Round  47, Train loss: 1.038, Test loss: 1.583, Test accuracy: 49.40
Round  47, Global train loss: 1.038, Global test loss: 2.133, Global test accuracy: 27.25
Round  48, Train loss: 0.826, Test loss: 1.627, Test accuracy: 49.11
Round  48, Global train loss: 0.826, Global test loss: 2.071, Global test accuracy: 29.86
Round  49, Train loss: 0.818, Test loss: 1.636, Test accuracy: 48.74
Round  49, Global train loss: 0.818, Global test loss: 2.034, Global test accuracy: 34.96
Round  50, Train loss: 0.769, Test loss: 1.687, Test accuracy: 48.66
Round  50, Global train loss: 0.769, Global test loss: 2.019, Global test accuracy: 26.37
Round  51, Train loss: 0.743, Test loss: 1.707, Test accuracy: 48.19
Round  51, Global train loss: 0.743, Global test loss: 2.065, Global test accuracy: 29.70
Round  52, Train loss: 0.641, Test loss: 1.757, Test accuracy: 47.64
Round  52, Global train loss: 0.641, Global test loss: 2.163, Global test accuracy: 24.05
Round  53, Train loss: 0.647, Test loss: 1.783, Test accuracy: 47.99
Round  53, Global train loss: 0.647, Global test loss: 2.083, Global test accuracy: 29.89
Round  54, Train loss: 0.737, Test loss: 1.800, Test accuracy: 47.87
Round  54, Global train loss: 0.737, Global test loss: 2.064, Global test accuracy: 22.49
Round  55, Train loss: 0.711, Test loss: 1.789, Test accuracy: 48.47
Round  55, Global train loss: 0.711, Global test loss: 2.009, Global test accuracy: 33.75
Round  56, Train loss: 0.761, Test loss: 1.810, Test accuracy: 47.91
Round  56, Global train loss: 0.761, Global test loss: 2.009, Global test accuracy: 31.18
Round  57, Train loss: 0.676, Test loss: 1.850, Test accuracy: 48.09
Round  57, Global train loss: 0.676, Global test loss: 2.106, Global test accuracy: 29.22
Round  58, Train loss: 0.459, Test loss: 1.868, Test accuracy: 47.77
Round  58, Global train loss: 0.459, Global test loss: 1.938, Global test accuracy: 31.95
Round  59, Train loss: 0.521, Test loss: 1.902, Test accuracy: 47.38
Round  59, Global train loss: 0.521, Global test loss: 2.077, Global test accuracy: 23.12
Round  60, Train loss: 0.594, Test loss: 1.945, Test accuracy: 46.92
Round  60, Global train loss: 0.594, Global test loss: 1.999, Global test accuracy: 28.01
Round  61, Train loss: 0.615, Test loss: 1.964, Test accuracy: 47.33
Round  61, Global train loss: 0.615, Global test loss: 2.044, Global test accuracy: 31.94
Round  62, Train loss: 0.596, Test loss: 1.990, Test accuracy: 46.99
Round  62, Global train loss: 0.596, Global test loss: 2.002, Global test accuracy: 30.95
Round  63, Train loss: 0.371, Test loss: 2.032, Test accuracy: 47.37
Round  63, Global train loss: 0.371, Global test loss: 1.900, Global test accuracy: 32.88
Round  64, Train loss: 0.477, Test loss: 2.031, Test accuracy: 48.08
Round  64, Global train loss: 0.477, Global test loss: 1.999, Global test accuracy: 30.84
Round  65, Train loss: 0.447, Test loss: 2.080, Test accuracy: 47.54
Round  65, Global train loss: 0.447, Global test loss: 1.995, Global test accuracy: 31.28
Round  66, Train loss: 0.459, Test loss: 2.072, Test accuracy: 47.69
Round  66, Global train loss: 0.459, Global test loss: 1.946, Global test accuracy: 34.76
Round  67, Train loss: 0.555, Test loss: 2.153, Test accuracy: 46.72
Round  67, Global train loss: 0.555, Global test loss: 2.039, Global test accuracy: 28.07
Round  68, Train loss: 0.342, Test loss: 2.212, Test accuracy: 46.29
Round  68, Global train loss: 0.342, Global test loss: 1.915, Global test accuracy: 33.34
Round  69, Train loss: 0.541, Test loss: 2.244, Test accuracy: 45.70
Round  69, Global train loss: 0.541, Global test loss: 2.030, Global test accuracy: 30.03
Round  70, Train loss: 0.443, Test loss: 2.250, Test accuracy: 46.17
Round  70, Global train loss: 0.443, Global test loss: 2.041, Global test accuracy: 29.81
Round  71, Train loss: 0.440, Test loss: 2.284, Test accuracy: 46.28
Round  71, Global train loss: 0.440, Global test loss: 2.054, Global test accuracy: 30.77
Round  72, Train loss: 0.397, Test loss: 2.368, Test accuracy: 46.46
Round  72, Global train loss: 0.397, Global test loss: 2.000, Global test accuracy: 30.24
Round  73, Train loss: 0.391, Test loss: 2.390, Test accuracy: 46.58
Round  73, Global train loss: 0.391, Global test loss: 1.941, Global test accuracy: 30.01
Round  74, Train loss: 0.360, Test loss: 2.365, Test accuracy: 46.51
Round  74, Global train loss: 0.360, Global test loss: 1.987, Global test accuracy: 27.34
Round  75, Train loss: 0.460, Test loss: 2.388, Test accuracy: 46.61
Round  75, Global train loss: 0.460, Global test loss: 2.080, Global test accuracy: 29.07
Round  76, Train loss: 0.337, Test loss: 2.413, Test accuracy: 46.91
Round  76, Global train loss: 0.337, Global test loss: 1.988, Global test accuracy: 33.58
Round  77, Train loss: 0.336, Test loss: 2.444, Test accuracy: 46.75
Round  77, Global train loss: 0.336, Global test loss: 2.011, Global test accuracy: 31.85
Round  78, Train loss: 0.297, Test loss: 2.446, Test accuracy: 46.65
Round  78, Global train loss: 0.297, Global test loss: 2.033, Global test accuracy: 28.37
Round  79, Train loss: 0.418, Test loss: 2.413, Test accuracy: 46.78
Round  79, Global train loss: 0.418, Global test loss: 2.004, Global test accuracy: 31.42
Round  80, Train loss: 0.331, Test loss: 2.481, Test accuracy: 46.27
Round  80, Global train loss: 0.331, Global test loss: 2.025, Global test accuracy: 29.87
Round  81, Train loss: 0.305, Test loss: 2.564, Test accuracy: 45.94
Round  81, Global train loss: 0.305, Global test loss: 1.932, Global test accuracy: 36.70
Round  82, Train loss: 0.361, Test loss: 2.578, Test accuracy: 46.25
Round  82, Global train loss: 0.361, Global test loss: 1.952, Global test accuracy: 32.37
Round  83, Train loss: 0.352, Test loss: 2.586, Test accuracy: 46.83
Round  83, Global train loss: 0.352, Global test loss: 2.037, Global test accuracy: 30.01
Round  84, Train loss: 0.288, Test loss: 2.623, Test accuracy: 46.95
Round  84, Global train loss: 0.288, Global test loss: 2.096, Global test accuracy: 20.89
Round  85, Train loss: 0.272, Test loss: 2.672, Test accuracy: 46.43
Round  85, Global train loss: 0.272, Global test loss: 2.069, Global test accuracy: 28.70
Round  86, Train loss: 0.330, Test loss: 2.649, Test accuracy: 46.07
Round  86, Global train loss: 0.330, Global test loss: 2.022, Global test accuracy: 31.92
Round  87, Train loss: 0.258, Test loss: 2.767, Test accuracy: 45.68
Round  87, Global train loss: 0.258, Global test loss: 1.951, Global test accuracy: 32.84
Round  88, Train loss: 0.308, Test loss: 2.785, Test accuracy: 46.02
Round  88, Global train loss: 0.308, Global test loss: 1.994, Global test accuracy: 32.81
Round  89, Train loss: 0.235, Test loss: 2.830, Test accuracy: 45.34
Round  89, Global train loss: 0.235, Global test loss: 2.020, Global test accuracy: 27.06
Round  90, Train loss: 0.308, Test loss: 2.856, Test accuracy: 45.30
Round  90, Global train loss: 0.308, Global test loss: 2.033, Global test accuracy: 31.38
Round  91, Train loss: 0.242, Test loss: 2.834, Test accuracy: 45.35
Round  91, Global train loss: 0.242, Global test loss: 2.049, Global test accuracy: 26.52
Round  92, Train loss: 0.255, Test loss: 2.798, Test accuracy: 45.64
Round  92, Global train loss: 0.255, Global test loss: 1.994, Global test accuracy: 31.03
Round  93, Train loss: 0.254, Test loss: 2.843, Test accuracy: 45.92
Round  93, Global train loss: 0.254, Global test loss: 2.105, Global test accuracy: 23.64
Round  94, Train loss: 0.245, Test loss: 2.844, Test accuracy: 46.19
Round  94, Global train loss: 0.245, Global test loss: 2.044, Global test accuracy: 29.85
Round  95, Train loss: 0.251, Test loss: 2.948, Test accuracy: 45.61
Round  95, Global train loss: 0.251, Global test loss: 1.973, Global test accuracy: 32.66
Round  96, Train loss: 0.241, Test loss: 2.853, Test accuracy: 46.23
Round  96, Global train loss: 0.241, Global test loss: 2.043, Global test accuracy: 27.99
Round  97, Train loss: 0.211, Test loss: 2.875, Test accuracy: 46.54
Round  97, Global train loss: 0.211, Global test loss: 1.974, Global test accuracy: 28.82
Round  98, Train loss: 0.288, Test loss: 2.918, Test accuracy: 46.36
Round  98, Global train loss: 0.288, Global test loss: 2.003, Global test accuracy: 34.01
Round  99, Train loss: 0.201, Test loss: 2.931, Test accuracy: 46.37
Round  99, Global train loss: 0.201, Global test loss: 2.102, Global test accuracy: 24.56
Final Round, Train loss: 0.208, Test loss: 3.087, Test accuracy: 46.20
Final Round, Global train loss: 0.208, Global test loss: 2.102, Global test accuracy: 24.56
Average accuracy final 10 rounds: 45.951 

Average global accuracy final 10 rounds: 29.046 

1332.0732326507568
[1.3954617977142334, 2.790923595428467, 3.9296884536743164, 5.068453311920166, 6.207125186920166, 7.345797061920166, 8.480308294296265, 9.614819526672363, 10.748876094818115, 11.882932662963867, 13.00794005393982, 14.132947444915771, 15.255240678787231, 16.37753391265869, 17.502877950668335, 18.62822198867798, 19.75471782684326, 20.881213665008545, 22.010489463806152, 23.13976526260376, 24.262850284576416, 25.385935306549072, 26.511940956115723, 27.637946605682373, 28.764533758163452, 29.89112091064453, 31.02165722846985, 32.152193546295166, 33.28508400917053, 34.4179744720459, 35.5488703250885, 36.6797661781311, 37.80239415168762, 38.92502212524414, 40.045944929122925, 41.16686773300171, 42.292290687561035, 43.41771364212036, 44.545114278793335, 45.67251491546631, 46.79512095451355, 47.91772699356079, 49.04221200942993, 50.16669702529907, 51.290051221847534, 52.413405418395996, 53.53998923301697, 54.66657304763794, 55.792543172836304, 56.91851329803467, 58.042243242263794, 59.16597318649292, 60.28659701347351, 61.4072208404541, 62.529640436172485, 63.65206003189087, 64.77225995063782, 65.89245986938477, 67.01364707946777, 68.13483428955078, 69.25472974777222, 70.37462520599365, 71.49683141708374, 72.61903762817383, 73.74185681343079, 74.86467599868774, 75.99276781082153, 77.12085962295532, 78.25718784332275, 79.39351606369019, 80.51988172531128, 81.64624738693237, 82.7736029624939, 83.90095853805542, 85.0287094116211, 86.15646028518677, 87.27674579620361, 88.39703130722046, 89.51424026489258, 90.6314492225647, 91.6068046092987, 92.58215999603271, 93.55364847183228, 94.52513694763184, 95.50291681289673, 96.48069667816162, 97.45697164535522, 98.43324661254883, 99.40585350990295, 100.37846040725708, 101.35869884490967, 102.33893728256226, 103.31928086280823, 104.2996244430542, 105.27735352516174, 106.25508260726929, 107.22885870933533, 108.20263481140137, 109.18212985992432, 110.16162490844727, 111.14144468307495, 112.12126445770264, 113.0912652015686, 114.06126594543457, 115.04011631011963, 116.01896667480469, 116.99749326705933, 117.97601985931396, 118.95626211166382, 119.93650436401367, 120.9112617969513, 121.88601922988892, 122.86778473854065, 123.84955024719238, 124.83158755302429, 125.8136248588562, 126.80872845649719, 127.80383205413818, 128.7828061580658, 129.7617802619934, 130.74626278877258, 131.73074531555176, 132.71118187904358, 133.6916184425354, 134.6732997894287, 135.65498113632202, 136.63851284980774, 137.62204456329346, 138.59921956062317, 139.57639455795288, 140.54608273506165, 141.5157709121704, 142.48918104171753, 143.46259117126465, 144.4388313293457, 145.41507148742676, 146.3926682472229, 147.37026500701904, 148.34750485420227, 149.3247447013855, 150.29624819755554, 151.2677516937256, 152.2395555973053, 153.211359500885, 154.18789744377136, 155.16443538665771, 156.14006209373474, 157.11568880081177, 158.09008812904358, 159.0644874572754, 160.0390396118164, 161.01359176635742, 161.98942279815674, 162.96525382995605, 163.9420039653778, 164.91875410079956, 165.89665603637695, 166.87455797195435, 167.84907269477844, 168.82358741760254, 169.79675221443176, 170.769917011261, 171.74460911750793, 172.71930122375488, 173.6967978477478, 174.67429447174072, 175.65036010742188, 176.62642574310303, 177.60098481178284, 178.57554388046265, 179.54854154586792, 180.5215392112732, 181.49570417404175, 182.4698691368103, 183.44515657424927, 184.42044401168823, 185.39724040031433, 186.37403678894043, 187.34792613983154, 188.32181549072266, 189.29542589187622, 190.26903629302979, 191.24209022521973, 192.21514415740967, 193.1865589618683, 194.1579737663269, 195.13119316101074, 196.10441255569458, 197.07966542243958, 198.05491828918457, 199.03108406066895, 200.00724983215332, 200.97821068763733, 201.94917154312134, 202.92146968841553, 203.89376783370972, 204.87317609786987, 205.85258436203003, 206.82802724838257, 207.8034701347351, 209.75394415855408, 211.70441818237305]
[18.08, 18.08, 26.98, 26.98, 33.04, 33.04, 36.41, 36.41, 39.61, 39.61, 40.54, 40.54, 42.84, 42.84, 43.03, 43.03, 43.74, 43.74, 44.02, 44.02, 46.18, 46.18, 45.0, 45.0, 47.23, 47.23, 48.89, 48.89, 49.31, 49.31, 49.73, 49.73, 51.01, 51.01, 51.47, 51.47, 50.55, 50.55, 50.61, 50.61, 50.29, 50.29, 50.17, 50.17, 51.0, 51.0, 51.14, 51.14, 50.84, 50.84, 51.22, 51.22, 51.26, 51.26, 50.02, 50.02, 49.66, 49.66, 50.79, 50.79, 50.75, 50.75, 51.2, 51.2, 50.85, 50.85, 50.42, 50.42, 50.46, 50.46, 49.9, 49.9, 50.47, 50.47, 50.87, 50.87, 50.72, 50.72, 50.1, 50.1, 49.93, 49.93, 49.2, 49.2, 48.23, 48.23, 48.22, 48.22, 47.86, 47.86, 48.18, 48.18, 48.39, 48.39, 49.4, 49.4, 49.11, 49.11, 48.74, 48.74, 48.66, 48.66, 48.19, 48.19, 47.64, 47.64, 47.99, 47.99, 47.87, 47.87, 48.47, 48.47, 47.91, 47.91, 48.09, 48.09, 47.77, 47.77, 47.38, 47.38, 46.92, 46.92, 47.33, 47.33, 46.99, 46.99, 47.37, 47.37, 48.08, 48.08, 47.54, 47.54, 47.69, 47.69, 46.72, 46.72, 46.29, 46.29, 45.7, 45.7, 46.17, 46.17, 46.28, 46.28, 46.46, 46.46, 46.58, 46.58, 46.51, 46.51, 46.61, 46.61, 46.91, 46.91, 46.75, 46.75, 46.65, 46.65, 46.78, 46.78, 46.27, 46.27, 45.94, 45.94, 46.25, 46.25, 46.83, 46.83, 46.95, 46.95, 46.43, 46.43, 46.07, 46.07, 45.68, 45.68, 46.02, 46.02, 45.34, 45.34, 45.3, 45.3, 45.35, 45.35, 45.64, 45.64, 45.92, 45.92, 46.19, 46.19, 45.61, 45.61, 46.23, 46.23, 46.54, 46.54, 46.36, 46.36, 46.37, 46.37, 46.2, 46.2]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.8 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 19, noise    level: 0.4000 
   Client 10, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 16, noise    level: 0.4000 
   Client 17, noise    level: 0.4000 
   Client 13, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 14, noise    level: 0.4000 
   Client 15, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 18, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 11, noise    level: 0.4000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.672, Test loss: 2.039, Test accuracy: 21.75
Round   0, Global train loss: 1.672, Global test loss: 2.227, Global test accuracy: 17.74
Round   1, Train loss: 1.483, Test loss: 1.763, Test accuracy: 32.00
Round   1, Global train loss: 1.483, Global test loss: 2.066, Global test accuracy: 27.09
Round   2, Train loss: 1.362, Test loss: 1.608, Test accuracy: 39.44
Round   2, Global train loss: 1.362, Global test loss: 2.121, Global test accuracy: 25.71
Round   3, Train loss: 1.354, Test loss: 1.359, Test accuracy: 45.70
Round   3, Global train loss: 1.354, Global test loss: 1.805, Global test accuracy: 30.46
Round   4, Train loss: 1.216, Test loss: 1.252, Test accuracy: 50.84
Round   4, Global train loss: 1.216, Global test loss: 1.774, Global test accuracy: 38.26
Round   5, Train loss: 1.112, Test loss: 1.237, Test accuracy: 53.70
Round   5, Global train loss: 1.112, Global test loss: 1.871, Global test accuracy: 37.59
Round   6, Train loss: 1.218, Test loss: 1.142, Test accuracy: 55.84
Round   6, Global train loss: 1.218, Global test loss: 1.715, Global test accuracy: 37.22
Round   7, Train loss: 1.154, Test loss: 1.123, Test accuracy: 57.25
Round   7, Global train loss: 1.154, Global test loss: 1.589, Global test accuracy: 42.66
Round   8, Train loss: 1.170, Test loss: 1.119, Test accuracy: 57.10
Round   8, Global train loss: 1.170, Global test loss: 1.633, Global test accuracy: 39.89
Round   9, Train loss: 1.099, Test loss: 1.103, Test accuracy: 57.98
Round   9, Global train loss: 1.099, Global test loss: 1.550, Global test accuracy: 46.20
Round  10, Train loss: 1.039, Test loss: 1.090, Test accuracy: 58.56
Round  10, Global train loss: 1.039, Global test loss: 1.511, Global test accuracy: 45.13
Round  11, Train loss: 1.095, Test loss: 1.074, Test accuracy: 59.55
Round  11, Global train loss: 1.095, Global test loss: 1.525, Global test accuracy: 46.46
Round  12, Train loss: 1.114, Test loss: 1.049, Test accuracy: 60.44
Round  12, Global train loss: 1.114, Global test loss: 1.443, Global test accuracy: 48.06
Round  13, Train loss: 1.039, Test loss: 1.019, Test accuracy: 61.67
Round  13, Global train loss: 1.039, Global test loss: 1.462, Global test accuracy: 47.03
Round  14, Train loss: 1.050, Test loss: 1.008, Test accuracy: 62.15
Round  14, Global train loss: 1.050, Global test loss: 1.473, Global test accuracy: 49.10
Round  15, Train loss: 0.913, Test loss: 1.012, Test accuracy: 62.30
Round  15, Global train loss: 0.913, Global test loss: 1.360, Global test accuracy: 50.33
Round  16, Train loss: 0.992, Test loss: 1.012, Test accuracy: 62.49
Round  16, Global train loss: 0.992, Global test loss: 1.326, Global test accuracy: 53.59
Round  17, Train loss: 0.862, Test loss: 1.004, Test accuracy: 62.84
Round  17, Global train loss: 0.862, Global test loss: 1.687, Global test accuracy: 44.20
Round  18, Train loss: 0.933, Test loss: 1.015, Test accuracy: 62.63
Round  18, Global train loss: 0.933, Global test loss: 1.481, Global test accuracy: 48.62
Round  19, Train loss: 0.978, Test loss: 0.977, Test accuracy: 63.65
Round  19, Global train loss: 0.978, Global test loss: 1.400, Global test accuracy: 50.16
Round  20, Train loss: 0.866, Test loss: 0.963, Test accuracy: 64.24
Round  20, Global train loss: 0.866, Global test loss: 1.517, Global test accuracy: 47.47
Round  21, Train loss: 0.841, Test loss: 0.951, Test accuracy: 64.79
Round  21, Global train loss: 0.841, Global test loss: 1.426, Global test accuracy: 50.19
Round  22, Train loss: 0.968, Test loss: 0.941, Test accuracy: 65.45
Round  22, Global train loss: 0.968, Global test loss: 1.371, Global test accuracy: 50.44
Round  23, Train loss: 0.826, Test loss: 0.913, Test accuracy: 66.71
Round  23, Global train loss: 0.826, Global test loss: 1.333, Global test accuracy: 54.36
Round  24, Train loss: 0.875, Test loss: 0.913, Test accuracy: 66.95
Round  24, Global train loss: 0.875, Global test loss: 1.250, Global test accuracy: 56.59
Round  25, Train loss: 0.737, Test loss: 0.923, Test accuracy: 66.63
Round  25, Global train loss: 0.737, Global test loss: 1.416, Global test accuracy: 52.24
Round  26, Train loss: 0.785, Test loss: 0.932, Test accuracy: 66.11
Round  26, Global train loss: 0.785, Global test loss: 1.340, Global test accuracy: 54.22
Round  27, Train loss: 0.726, Test loss: 0.935, Test accuracy: 66.42
Round  27, Global train loss: 0.726, Global test loss: 1.368, Global test accuracy: 55.30
Round  28, Train loss: 0.745, Test loss: 0.922, Test accuracy: 67.18
Round  28, Global train loss: 0.745, Global test loss: 1.425, Global test accuracy: 53.03
Round  29, Train loss: 0.910, Test loss: 0.912, Test accuracy: 67.42
Round  29, Global train loss: 0.910, Global test loss: 1.218, Global test accuracy: 57.22
Round  30, Train loss: 0.786, Test loss: 0.893, Test accuracy: 68.13
Round  30, Global train loss: 0.786, Global test loss: 1.364, Global test accuracy: 52.39
Round  31, Train loss: 0.696, Test loss: 0.905, Test accuracy: 67.76
Round  31, Global train loss: 0.696, Global test loss: 1.391, Global test accuracy: 52.07
Round  32, Train loss: 0.786, Test loss: 0.892, Test accuracy: 68.18
Round  32, Global train loss: 0.786, Global test loss: 1.385, Global test accuracy: 53.61
Round  33, Train loss: 0.761, Test loss: 0.883, Test accuracy: 68.39
Round  33, Global train loss: 0.761, Global test loss: 1.309, Global test accuracy: 56.11
Round  34, Train loss: 0.696, Test loss: 0.893, Test accuracy: 68.30
Round  34, Global train loss: 0.696, Global test loss: 1.235, Global test accuracy: 58.91
Round  35, Train loss: 0.764, Test loss: 0.881, Test accuracy: 68.86
Round  35, Global train loss: 0.764, Global test loss: 1.224, Global test accuracy: 57.95
Round  36, Train loss: 0.789, Test loss: 0.891, Test accuracy: 68.56
Round  36, Global train loss: 0.789, Global test loss: 1.232, Global test accuracy: 57.33
Round  37, Train loss: 0.632, Test loss: 0.892, Test accuracy: 68.76
Round  37, Global train loss: 0.632, Global test loss: 1.255, Global test accuracy: 58.48
Round  38, Train loss: 0.716, Test loss: 0.886, Test accuracy: 69.42
Round  38, Global train loss: 0.716, Global test loss: 1.229, Global test accuracy: 57.51
Round  39, Train loss: 0.628, Test loss: 0.885, Test accuracy: 69.44
Round  39, Global train loss: 0.628, Global test loss: 1.251, Global test accuracy: 57.71
Round  40, Train loss: 0.760, Test loss: 0.890, Test accuracy: 69.50
Round  40, Global train loss: 0.760, Global test loss: 1.361, Global test accuracy: 55.81
Round  41, Train loss: 0.740, Test loss: 0.883, Test accuracy: 69.72
Round  41, Global train loss: 0.740, Global test loss: 1.295, Global test accuracy: 56.84
Round  42, Train loss: 0.572, Test loss: 0.885, Test accuracy: 69.73
Round  42, Global train loss: 0.572, Global test loss: 1.314, Global test accuracy: 59.04
Round  43, Train loss: 0.647, Test loss: 0.876, Test accuracy: 69.99
Round  43, Global train loss: 0.647, Global test loss: 1.280, Global test accuracy: 57.36
Round  44, Train loss: 0.753, Test loss: 0.881, Test accuracy: 70.28
Round  44, Global train loss: 0.753, Global test loss: 1.202, Global test accuracy: 59.45
Round  45, Train loss: 0.719, Test loss: 0.880, Test accuracy: 70.59
Round  45, Global train loss: 0.719, Global test loss: 1.320, Global test accuracy: 56.40
Round  46, Train loss: 0.579, Test loss: 0.883, Test accuracy: 70.54
Round  46, Global train loss: 0.579, Global test loss: 1.176, Global test accuracy: 60.75
Round  47, Train loss: 0.673, Test loss: 0.901, Test accuracy: 70.19
Round  47, Global train loss: 0.673, Global test loss: 1.359, Global test accuracy: 56.39
Round  48, Train loss: 0.708, Test loss: 0.889, Test accuracy: 70.40
Round  48, Global train loss: 0.708, Global test loss: 1.230, Global test accuracy: 57.91
Round  49, Train loss: 0.470, Test loss: 0.878, Test accuracy: 71.01
Round  49, Global train loss: 0.470, Global test loss: 1.272, Global test accuracy: 60.43
Round  50, Train loss: 0.594, Test loss: 0.854, Test accuracy: 71.66
Round  50, Global train loss: 0.594, Global test loss: 1.375, Global test accuracy: 56.14
Round  51, Train loss: 0.559, Test loss: 0.889, Test accuracy: 70.57
Round  51, Global train loss: 0.559, Global test loss: 1.260, Global test accuracy: 60.88
Round  52, Train loss: 0.553, Test loss: 0.906, Test accuracy: 70.43
Round  52, Global train loss: 0.553, Global test loss: 1.547, Global test accuracy: 53.71
Round  53, Train loss: 0.550, Test loss: 0.905, Test accuracy: 70.24
Round  53, Global train loss: 0.550, Global test loss: 1.276, Global test accuracy: 59.41
Round  54, Train loss: 0.483, Test loss: 0.905, Test accuracy: 70.35
Round  54, Global train loss: 0.483, Global test loss: 1.131, Global test accuracy: 62.10
Round  55, Train loss: 0.424, Test loss: 0.900, Test accuracy: 70.39
Round  55, Global train loss: 0.424, Global test loss: 1.234, Global test accuracy: 61.79
Round  56, Train loss: 0.700, Test loss: 0.882, Test accuracy: 71.28
Round  56, Global train loss: 0.700, Global test loss: 1.236, Global test accuracy: 59.03
Round  57, Train loss: 0.533, Test loss: 0.887, Test accuracy: 71.26
Round  57, Global train loss: 0.533, Global test loss: 1.211, Global test accuracy: 60.42
Round  58, Train loss: 0.584, Test loss: 0.903, Test accuracy: 71.00
Round  58, Global train loss: 0.584, Global test loss: 1.131, Global test accuracy: 63.17
Round  59, Train loss: 0.460, Test loss: 0.882, Test accuracy: 71.37
Round  59, Global train loss: 0.460, Global test loss: 1.221, Global test accuracy: 61.64
Round  60, Train loss: 0.645, Test loss: 0.866, Test accuracy: 71.67
Round  60, Global train loss: 0.645, Global test loss: 1.137, Global test accuracy: 61.51
Round  61, Train loss: 0.506, Test loss: 0.895, Test accuracy: 71.19
Round  61, Global train loss: 0.506, Global test loss: 1.162, Global test accuracy: 62.20
Round  62, Train loss: 0.561, Test loss: 0.891, Test accuracy: 71.15
Round  62, Global train loss: 0.561, Global test loss: 1.246, Global test accuracy: 60.27
Round  63, Train loss: 0.616, Test loss: 0.872, Test accuracy: 71.82
Round  63, Global train loss: 0.616, Global test loss: 1.301, Global test accuracy: 59.63
Round  64, Train loss: 0.499, Test loss: 0.870, Test accuracy: 71.66
Round  64, Global train loss: 0.499, Global test loss: 1.219, Global test accuracy: 61.86
Round  65, Train loss: 0.536, Test loss: 0.881, Test accuracy: 71.77
Round  65, Global train loss: 0.536, Global test loss: 1.240, Global test accuracy: 61.32
Round  66, Train loss: 0.526, Test loss: 0.901, Test accuracy: 71.45
Round  66, Global train loss: 0.526, Global test loss: 1.226, Global test accuracy: 60.92
Round  67, Train loss: 0.628, Test loss: 0.916, Test accuracy: 71.20
Round  67, Global train loss: 0.628, Global test loss: 1.277, Global test accuracy: 57.89
Round  68, Train loss: 0.570, Test loss: 0.913, Test accuracy: 71.76
Round  68, Global train loss: 0.570, Global test loss: 1.221, Global test accuracy: 60.08
Round  69, Train loss: 0.492, Test loss: 0.910, Test accuracy: 71.76
Round  69, Global train loss: 0.492, Global test loss: 1.280, Global test accuracy: 58.84
Round  70, Train loss: 0.493, Test loss: 0.932, Test accuracy: 71.60
Round  70, Global train loss: 0.493, Global test loss: 1.296, Global test accuracy: 60.38
Round  71, Train loss: 0.421, Test loss: 0.931, Test accuracy: 71.59
Round  71, Global train loss: 0.421, Global test loss: 1.165, Global test accuracy: 64.14
Round  72, Train loss: 0.533, Test loss: 0.928, Test accuracy: 71.59
Round  72, Global train loss: 0.533, Global test loss: 1.219, Global test accuracy: 62.14
Round  73, Train loss: 0.487, Test loss: 0.933, Test accuracy: 71.18
Round  73, Global train loss: 0.487, Global test loss: 1.327, Global test accuracy: 60.47
Round  74, Train loss: 0.503, Test loss: 0.960, Test accuracy: 70.96
Round  74, Global train loss: 0.503, Global test loss: 1.227, Global test accuracy: 61.64
Round  75, Train loss: 0.535, Test loss: 0.967, Test accuracy: 71.01
Round  75, Global train loss: 0.535, Global test loss: 1.285, Global test accuracy: 60.00
Round  76, Train loss: 0.462, Test loss: 0.959, Test accuracy: 71.40
Round  76, Global train loss: 0.462, Global test loss: 1.329, Global test accuracy: 61.22
Round  77, Train loss: 0.450, Test loss: 0.926, Test accuracy: 72.33
Round  77, Global train loss: 0.450, Global test loss: 1.210, Global test accuracy: 63.08
Round  78, Train loss: 0.468, Test loss: 0.949, Test accuracy: 71.64
Round  78, Global train loss: 0.468, Global test loss: 1.683, Global test accuracy: 56.81
Round  79, Train loss: 0.443, Test loss: 0.950, Test accuracy: 71.70
Round  79, Global train loss: 0.443, Global test loss: 1.198, Global test accuracy: 63.17
Round  80, Train loss: 0.586, Test loss: 0.952, Test accuracy: 71.88
Round  80, Global train loss: 0.586, Global test loss: 1.220, Global test accuracy: 60.92
Round  81, Train loss: 0.418, Test loss: 0.944, Test accuracy: 71.93
Round  81, Global train loss: 0.418, Global test loss: 1.220, Global test accuracy: 63.23
Round  82, Train loss: 0.395, Test loss: 0.953, Test accuracy: 71.93
Round  82, Global train loss: 0.395, Global test loss: 1.253, Global test accuracy: 62.33
Round  83, Train loss: 0.325, Test loss: 0.978, Test accuracy: 71.66
Round  83, Global train loss: 0.325, Global test loss: 1.351, Global test accuracy: 61.34
Round  84, Train loss: 0.409, Test loss: 0.959, Test accuracy: 71.88
Round  84, Global train loss: 0.409, Global test loss: 1.429, Global test accuracy: 60.07
Round  85, Train loss: 0.364, Test loss: 0.974, Test accuracy: 71.64
Round  85, Global train loss: 0.364, Global test loss: 1.594, Global test accuracy: 59.44
Round  86, Train loss: 0.443, Test loss: 0.991, Test accuracy: 71.35
Round  86, Global train loss: 0.443, Global test loss: 1.394, Global test accuracy: 59.50
Round  87, Train loss: 0.333, Test loss: 0.997, Test accuracy: 71.38
Round  87, Global train loss: 0.333, Global test loss: 1.282, Global test accuracy: 61.39
Round  88, Train loss: 0.423, Test loss: 0.994, Test accuracy: 71.84
Round  88, Global train loss: 0.423, Global test loss: 1.283, Global test accuracy: 61.57
Round  89, Train loss: 0.514, Test loss: 0.977, Test accuracy: 71.95
Round  89, Global train loss: 0.514, Global test loss: 1.288, Global test accuracy: 59.93
Round  90, Train loss: 0.479, Test loss: 0.995, Test accuracy: 71.49
Round  90, Global train loss: 0.479, Global test loss: 1.451, Global test accuracy: 59.05
Round  91, Train loss: 0.372, Test loss: 0.982, Test accuracy: 72.07
Round  91, Global train loss: 0.372, Global test loss: 1.333, Global test accuracy: 61.26
Round  92, Train loss: 0.381, Test loss: 0.992, Test accuracy: 72.15
Round  92, Global train loss: 0.381, Global test loss: 1.328, Global test accuracy: 61.23
Round  93, Train loss: 0.390, Test loss: 1.022, Test accuracy: 71.08
Round  93, Global train loss: 0.390, Global test loss: 1.411, Global test accuracy: 59.17
Round  94, Train loss: 0.346, Test loss: 1.008, Test accuracy: 71.31
Round  94, Global train loss: 0.346, Global test loss: 1.296, Global test accuracy: 62.90
Round  95, Train loss: 0.376, Test loss: 1.032, Test accuracy: 71.35
Round  95, Global train loss: 0.376, Global test loss: 1.503, Global test accuracy: 60.19
Round  96, Train loss: 0.357, Test loss: 1.013, Test accuracy: 71.78
Round  96, Global train loss: 0.357, Global test loss: 1.390, Global test accuracy: 60.72
Round  97, Train loss: 0.425, Test loss: 1.006, Test accuracy: 72.04
Round  97, Global train loss: 0.425, Global test loss: 1.229, Global test accuracy: 63.53
Round  98, Train loss: 0.435, Test loss: 1.019, Test accuracy: 71.73
Round  98, Global train loss: 0.435, Global test loss: 1.159, Global test accuracy: 63.31
Round  99, Train loss: 0.367, Test loss: 1.013, Test accuracy: 71.49
Round  99, Global train loss: 0.367, Global test loss: 1.301, Global test accuracy: 62.18
Final Round, Train loss: 0.310, Test loss: 1.098, Test accuracy: 71.73
Final Round, Global train loss: 0.310, Global test loss: 1.301, Global test accuracy: 62.18
Average accuracy final 10 rounds: 71.649 

Average global accuracy final 10 rounds: 61.354 

1415.2970747947693
[1.365400791168213, 2.730801582336426, 3.8263707160949707, 4.921939849853516, 6.020956993103027, 7.119974136352539, 8.219133615493774, 9.31829309463501, 10.41941499710083, 11.52053689956665, 12.614895343780518, 13.709253787994385, 14.802464246749878, 15.895674705505371, 16.98613953590393, 18.07660436630249, 19.16909885406494, 20.261593341827393, 21.40193247795105, 22.542271614074707, 23.68274974822998, 24.823227882385254, 25.956507921218872, 27.08978796005249, 28.22170662879944, 29.353625297546387, 30.49001383781433, 31.626402378082275, 32.76373839378357, 33.90107440948486, 35.03537583351135, 36.16967725753784, 37.3019700050354, 38.43426275253296, 39.56725358963013, 40.700244426727295, 41.83682870864868, 42.97341299057007, 44.10988903045654, 45.24636507034302, 46.38197946548462, 47.51759386062622, 48.654319763183594, 49.79104566574097, 50.927289724349976, 52.063533782958984, 53.20584297180176, 54.34815216064453, 55.48735332489014, 56.62655448913574, 57.764575481414795, 58.90259647369385, 60.03985047340393, 61.177104473114014, 62.318949937820435, 63.460795402526855, 64.60299563407898, 65.7451958656311, 66.88384652137756, 68.02249717712402, 69.16199111938477, 70.30148506164551, 71.44614505767822, 72.59080505371094, 73.73132538795471, 74.87184572219849, 76.01375722885132, 77.15566873550415, 78.29747414588928, 79.43927955627441, 80.57743382453918, 81.71558809280396, 82.8516321182251, 83.98767614364624, 85.13260889053345, 86.27754163742065, 87.42143750190735, 88.56533336639404, 89.70357513427734, 90.84181690216064, 91.9810848236084, 93.12035274505615, 94.26409673690796, 95.40784072875977, 96.54829740524292, 97.68875408172607, 98.8285014629364, 99.96824884414673, 101.1064784526825, 102.24470806121826, 103.38104224205017, 104.51737642288208, 105.65833473205566, 106.79929304122925, 107.9466142654419, 109.09393548965454, 110.23287320137024, 111.37181091308594, 112.50952434539795, 113.64723777770996, 114.78744292259216, 115.92764806747437, 117.06764602661133, 118.20764398574829, 119.34737539291382, 120.48710680007935, 121.62291669845581, 122.75872659683228, 123.90013599395752, 125.04154539108276, 126.18093371391296, 127.32032203674316, 128.46523308753967, 129.61014413833618, 130.74665212631226, 131.88316011428833, 133.02301287651062, 134.1628656387329, 135.30137419700623, 136.43988275527954, 137.58084344863892, 138.7218041419983, 139.86489367485046, 141.00798320770264, 142.14422917366028, 143.28047513961792, 144.4166178703308, 145.5527606010437, 146.69323444366455, 147.8337082862854, 148.97548818588257, 150.11726808547974, 151.260409116745, 152.40355014801025, 153.5400414466858, 154.67653274536133, 155.81340551376343, 156.95027828216553, 158.09039616584778, 159.23051404953003, 160.36911487579346, 161.50771570205688, 162.64254903793335, 163.77738237380981, 164.91379809379578, 166.05021381378174, 167.19163131713867, 168.3330488204956, 169.4747633934021, 170.6164779663086, 171.76078629493713, 172.90509462356567, 174.04744267463684, 175.189790725708, 176.32167291641235, 177.4535551071167, 178.58902144432068, 179.72448778152466, 180.86277532577515, 182.00106287002563, 183.1432158946991, 184.28536891937256, 185.43079376220703, 186.5762186050415, 187.71501421928406, 188.8538098335266, 189.98601126670837, 191.11821269989014, 192.2477765083313, 193.37734031677246, 194.51345586776733, 195.6495714187622, 196.78398323059082, 197.91839504241943, 199.0570204257965, 200.19564580917358, 201.335777759552, 202.47590970993042, 203.60991644859314, 204.74392318725586, 205.87878823280334, 207.01365327835083, 208.1514916419983, 209.28933000564575, 210.4225788116455, 211.55582761764526, 212.68916130065918, 213.8224949836731, 214.96340942382812, 216.10432386398315, 217.2457456588745, 218.38716745376587, 219.52598524093628, 220.6648030281067, 221.7979257106781, 222.9310483932495, 224.07093977928162, 225.21083116531372, 226.35202836990356, 227.4932255744934, 229.77911949157715, 232.0650134086609]
[21.75, 21.75, 32.0, 32.0, 39.44, 39.44, 45.7, 45.7, 50.84, 50.84, 53.7, 53.7, 55.84, 55.84, 57.25, 57.25, 57.1, 57.1, 57.98, 57.98, 58.56, 58.56, 59.55, 59.55, 60.44, 60.44, 61.67, 61.67, 62.15, 62.15, 62.3, 62.3, 62.49, 62.49, 62.84, 62.84, 62.63, 62.63, 63.65, 63.65, 64.24, 64.24, 64.79, 64.79, 65.45, 65.45, 66.71, 66.71, 66.95, 66.95, 66.63, 66.63, 66.11, 66.11, 66.42, 66.42, 67.18, 67.18, 67.42, 67.42, 68.13, 68.13, 67.76, 67.76, 68.18, 68.18, 68.39, 68.39, 68.3, 68.3, 68.86, 68.86, 68.56, 68.56, 68.76, 68.76, 69.42, 69.42, 69.44, 69.44, 69.5, 69.5, 69.72, 69.72, 69.73, 69.73, 69.99, 69.99, 70.28, 70.28, 70.59, 70.59, 70.54, 70.54, 70.19, 70.19, 70.4, 70.4, 71.01, 71.01, 71.66, 71.66, 70.57, 70.57, 70.43, 70.43, 70.24, 70.24, 70.35, 70.35, 70.39, 70.39, 71.28, 71.28, 71.26, 71.26, 71.0, 71.0, 71.37, 71.37, 71.67, 71.67, 71.19, 71.19, 71.15, 71.15, 71.82, 71.82, 71.66, 71.66, 71.77, 71.77, 71.45, 71.45, 71.2, 71.2, 71.76, 71.76, 71.76, 71.76, 71.6, 71.6, 71.59, 71.59, 71.59, 71.59, 71.18, 71.18, 70.96, 70.96, 71.01, 71.01, 71.4, 71.4, 72.33, 72.33, 71.64, 71.64, 71.7, 71.7, 71.88, 71.88, 71.93, 71.93, 71.93, 71.93, 71.66, 71.66, 71.88, 71.88, 71.64, 71.64, 71.35, 71.35, 71.38, 71.38, 71.84, 71.84, 71.95, 71.95, 71.49, 71.49, 72.07, 72.07, 72.15, 72.15, 71.08, 71.08, 71.31, 71.31, 71.35, 71.35, 71.78, 71.78, 72.04, 72.04, 71.73, 71.73, 71.49, 71.49, 71.73, 71.73]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.8 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 5, noise    level: 0.4000 
   Client 11, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 15, noise    level: 0.4000 
   Client 17, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 14, noise    level: 0.4000 
   Client 19, noise    level: 0.4000 
   Client 10, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 12, noise    level: 0.4000 
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.665, Test loss: 2.014, Test accuracy: 24.36
Round   0, Global train loss: 1.665, Global test loss: 2.210, Global test accuracy: 21.35
Round   1, Train loss: 1.484, Test loss: 1.781, Test accuracy: 32.67
Round   1, Global train loss: 1.484, Global test loss: 2.083, Global test accuracy: 26.79
Round   2, Train loss: 1.431, Test loss: 1.602, Test accuracy: 39.26
Round   2, Global train loss: 1.431, Global test loss: 2.037, Global test accuracy: 25.20
Round   3, Train loss: 1.392, Test loss: 1.392, Test accuracy: 45.43
Round   3, Global train loss: 1.392, Global test loss: 1.866, Global test accuracy: 31.25
Round   4, Train loss: 1.316, Test loss: 1.321, Test accuracy: 48.76
Round   4, Global train loss: 1.316, Global test loss: 1.779, Global test accuracy: 36.14
Round   5, Train loss: 1.310, Test loss: 1.269, Test accuracy: 51.71
Round   5, Global train loss: 1.310, Global test loss: 1.749, Global test accuracy: 38.51
Round   6, Train loss: 1.291, Test loss: 1.184, Test accuracy: 54.73
Round   6, Global train loss: 1.291, Global test loss: 1.662, Global test accuracy: 38.30
Round   7, Train loss: 1.229, Test loss: 1.178, Test accuracy: 55.11
Round   7, Global train loss: 1.229, Global test loss: 1.601, Global test accuracy: 41.12
Round   8, Train loss: 1.224, Test loss: 1.169, Test accuracy: 55.74
Round   8, Global train loss: 1.224, Global test loss: 1.728, Global test accuracy: 38.62
Round   9, Train loss: 1.054, Test loss: 1.110, Test accuracy: 58.03
Round   9, Global train loss: 1.054, Global test loss: 1.538, Global test accuracy: 45.60
Round  10, Train loss: 1.153, Test loss: 1.093, Test accuracy: 58.85
Round  10, Global train loss: 1.153, Global test loss: 1.493, Global test accuracy: 45.79
Round  11, Train loss: 0.992, Test loss: 1.071, Test accuracy: 59.47
Round  11, Global train loss: 0.992, Global test loss: 1.502, Global test accuracy: 46.74
Round  12, Train loss: 1.097, Test loss: 1.066, Test accuracy: 60.32
Round  12, Global train loss: 1.097, Global test loss: 1.417, Global test accuracy: 49.83
Round  13, Train loss: 1.057, Test loss: 1.043, Test accuracy: 61.42
Round  13, Global train loss: 1.057, Global test loss: 1.482, Global test accuracy: 46.61
Round  14, Train loss: 1.009, Test loss: 1.039, Test accuracy: 61.23
Round  14, Global train loss: 1.009, Global test loss: 1.383, Global test accuracy: 51.64
Round  15, Train loss: 0.987, Test loss: 1.008, Test accuracy: 62.22
Round  15, Global train loss: 0.987, Global test loss: 1.384, Global test accuracy: 49.27
Round  16, Train loss: 1.007, Test loss: 0.993, Test accuracy: 62.86
Round  16, Global train loss: 1.007, Global test loss: 1.338, Global test accuracy: 52.04
Round  17, Train loss: 0.890, Test loss: 0.994, Test accuracy: 62.97
Round  17, Global train loss: 0.890, Global test loss: 1.580, Global test accuracy: 46.06
Round  18, Train loss: 0.912, Test loss: 0.976, Test accuracy: 63.79
Round  18, Global train loss: 0.912, Global test loss: 1.444, Global test accuracy: 49.68
Round  19, Train loss: 1.000, Test loss: 0.942, Test accuracy: 65.46
Round  19, Global train loss: 1.000, Global test loss: 1.398, Global test accuracy: 47.95
Round  20, Train loss: 1.000, Test loss: 0.940, Test accuracy: 65.18
Round  20, Global train loss: 1.000, Global test loss: 1.398, Global test accuracy: 50.24
Round  21, Train loss: 0.874, Test loss: 0.928, Test accuracy: 65.95
Round  21, Global train loss: 0.874, Global test loss: 1.453, Global test accuracy: 47.58
Round  22, Train loss: 0.937, Test loss: 0.932, Test accuracy: 65.70
Round  22, Global train loss: 0.937, Global test loss: 1.368, Global test accuracy: 48.90
Round  23, Train loss: 0.827, Test loss: 0.905, Test accuracy: 66.50
Round  23, Global train loss: 0.827, Global test loss: 1.272, Global test accuracy: 54.52
Round  24, Train loss: 0.876, Test loss: 0.914, Test accuracy: 66.62
Round  24, Global train loss: 0.876, Global test loss: 1.248, Global test accuracy: 55.50
Round  25, Train loss: 0.747, Test loss: 0.911, Test accuracy: 66.16
Round  25, Global train loss: 0.747, Global test loss: 1.335, Global test accuracy: 54.39
Round  26, Train loss: 0.745, Test loss: 0.912, Test accuracy: 66.63
Round  26, Global train loss: 0.745, Global test loss: 1.323, Global test accuracy: 54.09
Round  27, Train loss: 0.948, Test loss: 0.898, Test accuracy: 67.26
Round  27, Global train loss: 0.948, Global test loss: 1.319, Global test accuracy: 55.35
Round  28, Train loss: 0.813, Test loss: 0.898, Test accuracy: 67.25
Round  28, Global train loss: 0.813, Global test loss: 1.356, Global test accuracy: 53.78
Round  29, Train loss: 0.848, Test loss: 0.892, Test accuracy: 67.26
Round  29, Global train loss: 0.848, Global test loss: 1.218, Global test accuracy: 57.62
Round  30, Train loss: 0.805, Test loss: 0.881, Test accuracy: 67.95
Round  30, Global train loss: 0.805, Global test loss: 1.369, Global test accuracy: 52.54
Round  31, Train loss: 0.777, Test loss: 0.877, Test accuracy: 67.90
Round  31, Global train loss: 0.777, Global test loss: 1.338, Global test accuracy: 53.61
Round  32, Train loss: 0.931, Test loss: 0.871, Test accuracy: 68.21
Round  32, Global train loss: 0.931, Global test loss: 1.258, Global test accuracy: 57.47
Round  33, Train loss: 0.801, Test loss: 0.889, Test accuracy: 67.77
Round  33, Global train loss: 0.801, Global test loss: 1.240, Global test accuracy: 56.16
Round  34, Train loss: 0.738, Test loss: 0.871, Test accuracy: 68.30
Round  34, Global train loss: 0.738, Global test loss: 1.192, Global test accuracy: 58.57
Round  35, Train loss: 0.837, Test loss: 0.877, Test accuracy: 68.43
Round  35, Global train loss: 0.837, Global test loss: 1.209, Global test accuracy: 58.27
Round  36, Train loss: 0.782, Test loss: 0.880, Test accuracy: 68.69
Round  36, Global train loss: 0.782, Global test loss: 1.185, Global test accuracy: 59.30
Round  37, Train loss: 0.753, Test loss: 0.887, Test accuracy: 68.87
Round  37, Global train loss: 0.753, Global test loss: 1.195, Global test accuracy: 59.59
Round  38, Train loss: 0.780, Test loss: 0.886, Test accuracy: 69.08
Round  38, Global train loss: 0.780, Global test loss: 1.185, Global test accuracy: 58.32
Round  39, Train loss: 0.770, Test loss: 0.879, Test accuracy: 68.74
Round  39, Global train loss: 0.770, Global test loss: 1.230, Global test accuracy: 57.56
Round  40, Train loss: 0.687, Test loss: 0.872, Test accuracy: 69.35
Round  40, Global train loss: 0.687, Global test loss: 1.298, Global test accuracy: 56.41
Round  41, Train loss: 0.750, Test loss: 0.878, Test accuracy: 69.12
Round  41, Global train loss: 0.750, Global test loss: 1.274, Global test accuracy: 56.79
Round  42, Train loss: 0.653, Test loss: 0.868, Test accuracy: 69.50
Round  42, Global train loss: 0.653, Global test loss: 1.248, Global test accuracy: 59.38
Round  43, Train loss: 0.638, Test loss: 0.869, Test accuracy: 69.60
Round  43, Global train loss: 0.638, Global test loss: 1.229, Global test accuracy: 58.49
Round  44, Train loss: 0.703, Test loss: 0.858, Test accuracy: 69.58
Round  44, Global train loss: 0.703, Global test loss: 1.170, Global test accuracy: 59.84
Round  45, Train loss: 0.711, Test loss: 0.862, Test accuracy: 69.62
Round  45, Global train loss: 0.711, Global test loss: 1.181, Global test accuracy: 59.05
Round  46, Train loss: 0.629, Test loss: 0.861, Test accuracy: 70.34
Round  46, Global train loss: 0.629, Global test loss: 1.083, Global test accuracy: 61.94
Round  47, Train loss: 0.739, Test loss: 0.856, Test accuracy: 70.53
Round  47, Global train loss: 0.739, Global test loss: 1.257, Global test accuracy: 57.44
Round  48, Train loss: 0.740, Test loss: 0.865, Test accuracy: 70.59
Round  48, Global train loss: 0.740, Global test loss: 1.194, Global test accuracy: 58.75
Round  49, Train loss: 0.649, Test loss: 0.867, Test accuracy: 70.22
Round  49, Global train loss: 0.649, Global test loss: 1.176, Global test accuracy: 61.35
Round  50, Train loss: 0.718, Test loss: 0.867, Test accuracy: 70.50
Round  50, Global train loss: 0.718, Global test loss: 1.245, Global test accuracy: 58.33
Round  51, Train loss: 0.541, Test loss: 0.866, Test accuracy: 70.82
Round  51, Global train loss: 0.541, Global test loss: 1.265, Global test accuracy: 61.30
Round  52, Train loss: 0.748, Test loss: 0.856, Test accuracy: 70.72
Round  52, Global train loss: 0.748, Global test loss: 1.328, Global test accuracy: 56.45
Round  53, Train loss: 0.644, Test loss: 0.861, Test accuracy: 70.61
Round  53, Global train loss: 0.644, Global test loss: 1.156, Global test accuracy: 60.79
Round  54, Train loss: 0.649, Test loss: 0.872, Test accuracy: 71.11
Round  54, Global train loss: 0.649, Global test loss: 1.138, Global test accuracy: 60.58
Round  55, Train loss: 0.636, Test loss: 0.860, Test accuracy: 71.16
Round  55, Global train loss: 0.636, Global test loss: 1.170, Global test accuracy: 61.26
Round  56, Train loss: 0.713, Test loss: 0.871, Test accuracy: 71.25
Round  56, Global train loss: 0.713, Global test loss: 1.171, Global test accuracy: 59.55
Round  57, Train loss: 0.585, Test loss: 0.862, Test accuracy: 71.14
Round  57, Global train loss: 0.585, Global test loss: 1.156, Global test accuracy: 59.40
Round  58, Train loss: 0.627, Test loss: 0.877, Test accuracy: 71.18
Round  58, Global train loss: 0.627, Global test loss: 1.096, Global test accuracy: 63.08
Round  59, Train loss: 0.509, Test loss: 0.886, Test accuracy: 70.83
Round  59, Global train loss: 0.509, Global test loss: 1.160, Global test accuracy: 61.81
Round  60, Train loss: 0.603, Test loss: 0.887, Test accuracy: 70.63
Round  60, Global train loss: 0.603, Global test loss: 1.107, Global test accuracy: 62.55
Round  61, Train loss: 0.542, Test loss: 0.893, Test accuracy: 70.55
Round  61, Global train loss: 0.542, Global test loss: 1.128, Global test accuracy: 60.84
Round  62, Train loss: 0.660, Test loss: 0.882, Test accuracy: 70.91
Round  62, Global train loss: 0.660, Global test loss: 1.142, Global test accuracy: 61.25
Round  63, Train loss: 0.628, Test loss: 0.861, Test accuracy: 71.73
Round  63, Global train loss: 0.628, Global test loss: 1.153, Global test accuracy: 61.44
Round  64, Train loss: 0.522, Test loss: 0.862, Test accuracy: 71.81
Round  64, Global train loss: 0.522, Global test loss: 1.134, Global test accuracy: 63.57
Round  65, Train loss: 0.596, Test loss: 0.895, Test accuracy: 70.90
Round  65, Global train loss: 0.596, Global test loss: 1.243, Global test accuracy: 60.05
Round  66, Train loss: 0.610, Test loss: 0.879, Test accuracy: 71.26
Round  66, Global train loss: 0.610, Global test loss: 1.090, Global test accuracy: 63.50
Round  67, Train loss: 0.584, Test loss: 0.867, Test accuracy: 71.43
Round  67, Global train loss: 0.584, Global test loss: 1.191, Global test accuracy: 60.69
Round  68, Train loss: 0.633, Test loss: 0.887, Test accuracy: 71.30
Round  68, Global train loss: 0.633, Global test loss: 1.108, Global test accuracy: 62.25
Round  69, Train loss: 0.549, Test loss: 0.882, Test accuracy: 71.52
Round  69, Global train loss: 0.549, Global test loss: 1.173, Global test accuracy: 60.14
Round  70, Train loss: 0.495, Test loss: 0.879, Test accuracy: 71.80
Round  70, Global train loss: 0.495, Global test loss: 1.209, Global test accuracy: 61.76
Round  71, Train loss: 0.511, Test loss: 0.891, Test accuracy: 71.86
Round  71, Global train loss: 0.511, Global test loss: 1.150, Global test accuracy: 63.37
Round  72, Train loss: 0.551, Test loss: 0.877, Test accuracy: 72.05
Round  72, Global train loss: 0.551, Global test loss: 1.167, Global test accuracy: 62.18
Round  73, Train loss: 0.576, Test loss: 0.877, Test accuracy: 72.10
Round  73, Global train loss: 0.576, Global test loss: 1.170, Global test accuracy: 61.96
Round  74, Train loss: 0.541, Test loss: 0.864, Test accuracy: 72.50
Round  74, Global train loss: 0.541, Global test loss: 1.181, Global test accuracy: 61.90
Round  75, Train loss: 0.533, Test loss: 0.880, Test accuracy: 71.95
Round  75, Global train loss: 0.533, Global test loss: 1.254, Global test accuracy: 59.36
Round  76, Train loss: 0.561, Test loss: 0.880, Test accuracy: 72.24
Round  76, Global train loss: 0.561, Global test loss: 1.172, Global test accuracy: 62.08
Round  77, Train loss: 0.466, Test loss: 0.895, Test accuracy: 72.18
Round  77, Global train loss: 0.466, Global test loss: 1.147, Global test accuracy: 62.23
Round  78, Train loss: 0.553, Test loss: 0.887, Test accuracy: 72.24
Round  78, Global train loss: 0.553, Global test loss: 1.381, Global test accuracy: 59.00
Round  79, Train loss: 0.485, Test loss: 0.901, Test accuracy: 71.99
Round  79, Global train loss: 0.485, Global test loss: 1.176, Global test accuracy: 62.73
Round  80, Train loss: 0.538, Test loss: 0.889, Test accuracy: 72.72
Round  80, Global train loss: 0.538, Global test loss: 1.230, Global test accuracy: 61.44
Round  81, Train loss: 0.514, Test loss: 0.888, Test accuracy: 72.46
Round  81, Global train loss: 0.514, Global test loss: 1.141, Global test accuracy: 63.94
Round  82, Train loss: 0.547, Test loss: 0.883, Test accuracy: 72.76
Round  82, Global train loss: 0.547, Global test loss: 1.150, Global test accuracy: 63.01
Round  83, Train loss: 0.532, Test loss: 0.891, Test accuracy: 72.69
Round  83, Global train loss: 0.532, Global test loss: 1.221, Global test accuracy: 61.69
Round  84, Train loss: 0.512, Test loss: 0.913, Test accuracy: 71.91
Round  84, Global train loss: 0.512, Global test loss: 1.401, Global test accuracy: 57.70
Round  85, Train loss: 0.475, Test loss: 0.918, Test accuracy: 71.58
Round  85, Global train loss: 0.475, Global test loss: 1.408, Global test accuracy: 58.30
Round  86, Train loss: 0.472, Test loss: 0.916, Test accuracy: 71.56
Round  86, Global train loss: 0.472, Global test loss: 1.252, Global test accuracy: 61.11
Round  87, Train loss: 0.472, Test loss: 0.907, Test accuracy: 71.83
Round  87, Global train loss: 0.472, Global test loss: 1.232, Global test accuracy: 61.51
Round  88, Train loss: 0.455, Test loss: 0.903, Test accuracy: 71.89
Round  88, Global train loss: 0.455, Global test loss: 1.185, Global test accuracy: 62.49
Round  89, Train loss: 0.479, Test loss: 0.907, Test accuracy: 72.43
Round  89, Global train loss: 0.479, Global test loss: 1.235, Global test accuracy: 61.14
Round  90, Train loss: 0.527, Test loss: 0.922, Test accuracy: 72.60
Round  90, Global train loss: 0.527, Global test loss: 1.334, Global test accuracy: 59.18
Round  91, Train loss: 0.410, Test loss: 0.897, Test accuracy: 72.85
Round  91, Global train loss: 0.410, Global test loss: 1.182, Global test accuracy: 63.59/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  92, Train loss: 0.458, Test loss: 0.912, Test accuracy: 72.46
Round  92, Global train loss: 0.458, Global test loss: 1.172, Global test accuracy: 63.62
Round  93, Train loss: 0.400, Test loss: 0.920, Test accuracy: 72.45
Round  93, Global train loss: 0.400, Global test loss: 1.295, Global test accuracy: 61.80
Round  94, Train loss: 0.389, Test loss: 0.931, Test accuracy: 72.33
Round  94, Global train loss: 0.389, Global test loss: 1.229, Global test accuracy: 63.97
Round  95, Train loss: 0.444, Test loss: 0.961, Test accuracy: 71.60
Round  95, Global train loss: 0.444, Global test loss: 1.277, Global test accuracy: 61.79
Round  96, Train loss: 0.430, Test loss: 0.958, Test accuracy: 71.94
Round  96, Global train loss: 0.430, Global test loss: 1.318, Global test accuracy: 61.11
Round  97, Train loss: 0.463, Test loss: 0.962, Test accuracy: 71.65
Round  97, Global train loss: 0.463, Global test loss: 1.220, Global test accuracy: 61.94
Round  98, Train loss: 0.490, Test loss: 0.955, Test accuracy: 72.05
Round  98, Global train loss: 0.490, Global test loss: 1.157, Global test accuracy: 62.59
Round  99, Train loss: 0.372, Test loss: 0.944, Test accuracy: 72.33
Round  99, Global train loss: 0.372, Global test loss: 1.226, Global test accuracy: 63.79
Final Round, Train loss: 0.353, Test loss: 0.965, Test accuracy: 72.64
Final Round, Global train loss: 0.353, Global test loss: 1.226, Global test accuracy: 63.79
Average accuracy final 10 rounds: 72.226 

Average global accuracy final 10 rounds: 62.338 

1531.9930279254913
[1.596585988998413, 3.193171977996826, 4.537048578262329, 5.880925178527832, 7.228785037994385, 8.576644897460938, 9.91875696182251, 11.260869026184082, 12.585720300674438, 13.910571575164795, 15.24000859260559, 16.569445610046387, 17.902116775512695, 19.234787940979004, 20.56326651573181, 21.89174509048462, 23.215777158737183, 24.539809226989746, 25.859674215316772, 27.1795392036438, 28.502641439437866, 29.825743675231934, 31.154855728149414, 32.483967781066895, 33.80561375617981, 35.127259731292725, 36.449458837509155, 37.771657943725586, 39.098832845687866, 40.42600774765015, 41.75788331031799, 43.08975887298584, 44.419750928878784, 45.74974298477173, 47.07160305976868, 48.393463134765625, 49.71676564216614, 51.04006814956665, 52.37482523918152, 53.70958232879639, 55.0505805015564, 56.391578674316406, 57.7334680557251, 59.07535743713379, 60.41259241104126, 61.74982738494873, 63.0914192199707, 64.43301105499268, 65.76945662498474, 67.1059021949768, 68.43449854850769, 69.76309490203857, 71.08653450012207, 72.40997409820557, 73.74616861343384, 75.08236312866211, 76.41944909095764, 77.75653505325317, 79.06590747833252, 80.37527990341187, 81.70315504074097, 83.03103017807007, 84.36715626716614, 85.7032823562622, 87.03603148460388, 88.36878061294556, 89.70582890510559, 91.04287719726562, 92.3838381767273, 93.72479915618896, 95.06579303741455, 96.40678691864014, 97.75144600868225, 99.09610509872437, 100.41901540756226, 101.74192571640015, 103.06510066986084, 104.38827562332153, 105.71165442466736, 107.03503322601318, 108.36395788192749, 109.6928825378418, 111.02303791046143, 112.35319328308105, 113.6765787601471, 114.99996423721313, 116.32668423652649, 117.65340423583984, 118.9825873374939, 120.31177043914795, 121.63838005065918, 122.96498966217041, 124.29039239883423, 125.61579513549805, 126.94302892684937, 128.27026271820068, 129.59459018707275, 130.91891765594482, 132.2427327632904, 133.566547870636, 134.88600730895996, 136.20546674728394, 137.5239975452423, 138.84252834320068, 140.1611397266388, 141.4797511100769, 142.80197978019714, 144.12420845031738, 145.4463770389557, 146.768545627594, 148.08820629119873, 149.40786695480347, 150.72908902168274, 152.050311088562, 153.37064719200134, 154.69098329544067, 156.0345959663391, 157.37820863723755, 158.714421749115, 160.05063486099243, 161.39111804962158, 162.73160123825073, 164.0827088356018, 165.43381643295288, 166.77205610275269, 168.1102957725525, 169.45395803451538, 170.79762029647827, 172.13870811462402, 173.47979593276978, 174.82079792022705, 176.16179990768433, 177.4928789138794, 178.82395792007446, 180.13902521133423, 181.454092502594, 182.79267621040344, 184.1312599182129, 185.471777677536, 186.81229543685913, 188.13502144813538, 189.45774745941162, 190.79438853263855, 192.13102960586548, 193.46834111213684, 194.8056526184082, 196.1351010799408, 197.4645495414734, 198.5362708568573, 199.6079921722412, 200.93140816688538, 202.25482416152954, 203.5889856815338, 204.9231472015381, 206.2523376941681, 207.5815281867981, 208.91595268249512, 210.25037717819214, 211.58936500549316, 212.9283528327942, 214.26074719429016, 215.59314155578613, 216.9263129234314, 218.25948429107666, 219.5965120792389, 220.93353986740112, 222.2743661403656, 223.61519241333008, 224.95237135887146, 226.28955030441284, 227.60872101783752, 228.9278917312622, 230.25589394569397, 231.58389616012573, 232.91350173950195, 234.24310731887817, 235.56649923324585, 236.88989114761353, 238.21295142173767, 239.53601169586182, 240.85638403892517, 242.17675638198853, 243.50709629058838, 244.83743619918823, 246.1735315322876, 247.50962686538696, 248.83824133872986, 250.16685581207275, 251.50121402740479, 252.83557224273682, 254.17389130592346, 255.5122103691101, 256.85059452056885, 258.1889786720276, 259.51401138305664, 260.8390440940857, 262.17566776275635, 263.512291431427, 264.848566532135, 266.184841632843, 268.8380973339081, 271.49135303497314]
[24.36, 24.36, 32.67, 32.67, 39.26, 39.26, 45.43, 45.43, 48.76, 48.76, 51.71, 51.71, 54.73, 54.73, 55.11, 55.11, 55.74, 55.74, 58.03, 58.03, 58.85, 58.85, 59.47, 59.47, 60.32, 60.32, 61.42, 61.42, 61.23, 61.23, 62.22, 62.22, 62.86, 62.86, 62.97, 62.97, 63.79, 63.79, 65.46, 65.46, 65.18, 65.18, 65.95, 65.95, 65.7, 65.7, 66.5, 66.5, 66.62, 66.62, 66.16, 66.16, 66.63, 66.63, 67.26, 67.26, 67.25, 67.25, 67.26, 67.26, 67.95, 67.95, 67.9, 67.9, 68.21, 68.21, 67.77, 67.77, 68.3, 68.3, 68.43, 68.43, 68.69, 68.69, 68.87, 68.87, 69.08, 69.08, 68.74, 68.74, 69.35, 69.35, 69.12, 69.12, 69.5, 69.5, 69.6, 69.6, 69.58, 69.58, 69.62, 69.62, 70.34, 70.34, 70.53, 70.53, 70.59, 70.59, 70.22, 70.22, 70.5, 70.5, 70.82, 70.82, 70.72, 70.72, 70.61, 70.61, 71.11, 71.11, 71.16, 71.16, 71.25, 71.25, 71.14, 71.14, 71.18, 71.18, 70.83, 70.83, 70.63, 70.63, 70.55, 70.55, 70.91, 70.91, 71.73, 71.73, 71.81, 71.81, 70.9, 70.9, 71.26, 71.26, 71.43, 71.43, 71.3, 71.3, 71.52, 71.52, 71.8, 71.8, 71.86, 71.86, 72.05, 72.05, 72.1, 72.1, 72.5, 72.5, 71.95, 71.95, 72.24, 72.24, 72.18, 72.18, 72.24, 72.24, 71.99, 71.99, 72.72, 72.72, 72.46, 72.46, 72.76, 72.76, 72.69, 72.69, 71.91, 71.91, 71.58, 71.58, 71.56, 71.56, 71.83, 71.83, 71.89, 71.89, 72.43, 72.43, 72.6, 72.6, 72.85, 72.85, 72.46, 72.46, 72.45, 72.45, 72.33, 72.33, 71.6, 71.6, 71.94, 71.94, 71.65, 71.65, 72.05, 72.05, 72.33, 72.33, 72.64, 72.64]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.8 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 16, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 14, noise    level: 0.4000 
   Client 10, noise    level: 0.4000 
   Client 12, noise    level: 0.4000 
   Client 11, noise    level: 0.4000 
   Client 17, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 15, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 19, noise    level: 0.4000 
   Client 18, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.957, Test loss: 2.200, Test accuracy: 17.01
Round   1, Train loss: 1.647, Test loss: 1.947, Test accuracy: 27.13
Round   2, Train loss: 1.459, Test loss: 1.775, Test accuracy: 35.90
Round   3, Train loss: 1.384, Test loss: 1.460, Test accuracy: 41.66
Round   4, Train loss: 1.348, Test loss: 1.393, Test accuracy: 45.58
Round   5, Train loss: 1.309, Test loss: 1.307, Test accuracy: 50.31
Round   6, Train loss: 1.213, Test loss: 1.206, Test accuracy: 53.81
Round   7, Train loss: 1.206, Test loss: 1.162, Test accuracy: 55.51
Round   8, Train loss: 1.119, Test loss: 1.167, Test accuracy: 55.60
Round   9, Train loss: 1.148, Test loss: 1.122, Test accuracy: 56.22
Round  10, Train loss: 1.072, Test loss: 1.087, Test accuracy: 58.09
Round  11, Train loss: 1.101, Test loss: 1.079, Test accuracy: 59.17
Round  12, Train loss: 1.031, Test loss: 1.037, Test accuracy: 60.83
Round  13, Train loss: 1.115, Test loss: 1.018, Test accuracy: 61.38
Round  14, Train loss: 1.039, Test loss: 1.010, Test accuracy: 62.37
Round  15, Train loss: 1.030, Test loss: 0.983, Test accuracy: 62.93
Round  16, Train loss: 1.043, Test loss: 0.974, Test accuracy: 63.27
Round  17, Train loss: 0.986, Test loss: 0.978, Test accuracy: 63.26
Round  18, Train loss: 1.095, Test loss: 0.961, Test accuracy: 64.01
Round  19, Train loss: 0.979, Test loss: 0.950, Test accuracy: 64.32
Round  20, Train loss: 0.959, Test loss: 0.935, Test accuracy: 64.89
Round  21, Train loss: 0.916, Test loss: 0.921, Test accuracy: 64.78
Round  22, Train loss: 0.972, Test loss: 0.920, Test accuracy: 65.25
Round  23, Train loss: 0.998, Test loss: 0.909, Test accuracy: 66.40
Round  24, Train loss: 0.968, Test loss: 0.914, Test accuracy: 66.38
Round  25, Train loss: 0.906, Test loss: 0.883, Test accuracy: 67.08
Round  26, Train loss: 0.972, Test loss: 0.895, Test accuracy: 66.83
Round  27, Train loss: 0.969, Test loss: 0.883, Test accuracy: 66.74
Round  28, Train loss: 0.852, Test loss: 0.902, Test accuracy: 67.04
Round  29, Train loss: 1.079, Test loss: 0.874, Test accuracy: 67.96
Round  30, Train loss: 0.946, Test loss: 0.868, Test accuracy: 68.67
Round  31, Train loss: 0.929, Test loss: 0.874, Test accuracy: 68.63
Round  32, Train loss: 0.874, Test loss: 0.854, Test accuracy: 68.94
Round  33, Train loss: 0.889, Test loss: 0.837, Test accuracy: 69.06
Round  34, Train loss: 0.821, Test loss: 0.840, Test accuracy: 68.91
Round  35, Train loss: 0.951, Test loss: 0.846, Test accuracy: 68.85
Round  36, Train loss: 0.819, Test loss: 0.839, Test accuracy: 69.38
Round  37, Train loss: 0.763, Test loss: 0.819, Test accuracy: 70.19
Round  38, Train loss: 0.832, Test loss: 0.801, Test accuracy: 70.48
Round  39, Train loss: 0.744, Test loss: 0.809, Test accuracy: 70.40
Round  40, Train loss: 0.862, Test loss: 0.796, Test accuracy: 71.00
Round  41, Train loss: 0.853, Test loss: 0.792, Test accuracy: 71.40
Round  42, Train loss: 0.922, Test loss: 0.787, Test accuracy: 71.49
Round  43, Train loss: 0.823, Test loss: 0.798, Test accuracy: 71.48
Round  44, Train loss: 0.849, Test loss: 0.778, Test accuracy: 71.82
Round  45, Train loss: 0.697, Test loss: 0.777, Test accuracy: 72.03
Round  46, Train loss: 0.742, Test loss: 0.763, Test accuracy: 72.22
Round  47, Train loss: 0.827, Test loss: 0.770, Test accuracy: 71.99
Round  48, Train loss: 0.875, Test loss: 0.770, Test accuracy: 71.99
Round  49, Train loss: 0.787, Test loss: 0.751, Test accuracy: 73.10
Round  50, Train loss: 0.852, Test loss: 0.760, Test accuracy: 72.50
Round  51, Train loss: 0.867, Test loss: 0.750, Test accuracy: 73.14
Round  52, Train loss: 0.863, Test loss: 0.745, Test accuracy: 72.97
Round  53, Train loss: 0.775, Test loss: 0.748, Test accuracy: 72.74
Round  54, Train loss: 0.655, Test loss: 0.743, Test accuracy: 73.42
Round  55, Train loss: 0.728, Test loss: 0.752, Test accuracy: 73.28
Round  56, Train loss: 0.785, Test loss: 0.744, Test accuracy: 72.96
Round  57, Train loss: 0.657, Test loss: 0.733, Test accuracy: 73.71
Round  58, Train loss: 0.678, Test loss: 0.746, Test accuracy: 73.37
Round  59, Train loss: 0.627, Test loss: 0.721, Test accuracy: 74.11
Round  60, Train loss: 0.701, Test loss: 0.728, Test accuracy: 73.84
Round  61, Train loss: 0.633, Test loss: 0.735, Test accuracy: 73.53
Round  62, Train loss: 0.731, Test loss: 0.715, Test accuracy: 73.99
Round  63, Train loss: 0.720, Test loss: 0.724, Test accuracy: 74.21
Round  64, Train loss: 0.576, Test loss: 0.715, Test accuracy: 74.73
Round  65, Train loss: 0.690, Test loss: 0.716, Test accuracy: 74.59
Round  66, Train loss: 0.586, Test loss: 0.711, Test accuracy: 74.46
Round  67, Train loss: 0.708, Test loss: 0.709, Test accuracy: 74.89
Round  68, Train loss: 0.690, Test loss: 0.725, Test accuracy: 74.46
Round  69, Train loss: 0.697, Test loss: 0.716, Test accuracy: 74.47
Round  70, Train loss: 0.707, Test loss: 0.709, Test accuracy: 74.61
Round  71, Train loss: 0.639, Test loss: 0.709, Test accuracy: 74.74
Round  72, Train loss: 0.655, Test loss: 0.703, Test accuracy: 74.99
Round  73, Train loss: 0.641, Test loss: 0.699, Test accuracy: 75.71
Round  74, Train loss: 0.717, Test loss: 0.699, Test accuracy: 75.32
Round  75, Train loss: 0.751, Test loss: 0.698, Test accuracy: 75.20
Round  76, Train loss: 0.714, Test loss: 0.710, Test accuracy: 74.91
Round  77, Train loss: 0.585, Test loss: 0.706, Test accuracy: 74.72
Round  78, Train loss: 0.644, Test loss: 0.715, Test accuracy: 74.60
Round  79, Train loss: 0.558, Test loss: 0.707, Test accuracy: 75.02
Round  80, Train loss: 0.703, Test loss: 0.709, Test accuracy: 74.81
Round  81, Train loss: 0.630, Test loss: 0.688, Test accuracy: 75.33
Round  82, Train loss: 0.610, Test loss: 0.697, Test accuracy: 75.44
Round  83, Train loss: 0.608, Test loss: 0.702, Test accuracy: 75.11
Round  84, Train loss: 0.574, Test loss: 0.707, Test accuracy: 74.67
Round  85, Train loss: 0.614, Test loss: 0.704, Test accuracy: 75.01
Round  86, Train loss: 0.620, Test loss: 0.715, Test accuracy: 74.56
Round  87, Train loss: 0.524, Test loss: 0.696, Test accuracy: 75.42
Round  88, Train loss: 0.473, Test loss: 0.689, Test accuracy: 75.72
Round  89, Train loss: 0.547, Test loss: 0.687, Test accuracy: 75.42
Round  90, Train loss: 0.717, Test loss: 0.681, Test accuracy: 75.77
Round  91, Train loss: 0.492, Test loss: 0.685, Test accuracy: 75.69
Round  92, Train loss: 0.489, Test loss: 0.690, Test accuracy: 75.57
Round  93, Train loss: 0.529, Test loss: 0.689, Test accuracy: 75.58
Round  94, Train loss: 0.571, Test loss: 0.698, Test accuracy: 75.09
Round  95, Train loss: 0.615, Test loss: 0.702, Test accuracy: 74.80
Round  96, Train loss: 0.588, Test loss: 0.714, Test accuracy: 74.71
Round  97, Train loss: 0.628, Test loss: 0.698, Test accuracy: 75.40
Round  98, Train loss: 0.645, Test loss: 0.692, Test accuracy: 75.44
Round  99, Train loss: 0.513, Test loss: 0.690, Test accuracy: 75.76
Final Round, Train loss: 0.490, Test loss: 0.697, Test accuracy: 75.48
Average accuracy final 10 rounds: 75.381
1752.3393471240997
[2.835157632827759, 5.344794034957886, 7.856168985366821, 10.366658926010132, 12.87162971496582, 15.299195289611816, 17.811472177505493, 20.326903820037842, 22.844327926635742, 25.3606915473938, 27.887496948242188, 30.40766477584839, 32.92666530609131, 35.44781041145325, 37.967546701431274, 40.48398566246033, 42.99981999397278, 45.526052713394165, 48.04321789741516, 50.558130741119385, 53.074005365371704, 55.598052978515625, 58.11632490158081, 60.63092827796936, 63.157854318618774, 65.66870975494385, 68.18617987632751, 70.70705461502075, 73.22901844978333, 75.72756814956665, 78.22295784950256, 80.71702027320862, 83.21393752098083, 85.70695400238037, 88.19878029823303, 90.69781303405762, 93.19603109359741, 95.69192886352539, 98.19051575660706, 100.69151186943054, 103.18749594688416, 105.67891430854797, 108.17558407783508, 110.67354393005371, 113.16874957084656, 115.6626513004303, 118.15667271614075, 120.65333962440491, 123.1513729095459, 125.64442420005798, 128.13915300369263, 130.63453674316406, 133.12788939476013, 135.62041234970093, 138.11425518989563, 140.61140751838684, 143.10322976112366, 145.59783124923706, 148.09183883666992, 150.58785676956177, 153.0890233516693, 155.58124423027039, 158.09415197372437, 160.61009168624878, 163.12894988059998, 165.63933277130127, 168.1258988380432, 170.4168095588684, 172.70164608955383, 174.9621458053589, 177.21969485282898, 179.49469923973083, 181.77650260925293, 184.05901432037354, 186.34970355033875, 188.6442415714264, 190.92652368545532, 193.2049744129181, 195.492107629776, 197.77840065956116, 200.03903222084045, 202.30203342437744, 204.56347918510437, 206.83085918426514, 209.1136372089386, 211.39377856254578, 213.65962195396423, 215.91986680030823, 218.18374300003052, 220.47472858428955, 222.76680040359497, 225.05869555473328, 227.34593391418457, 229.624596118927, 231.88724160194397, 234.15049505233765, 236.41275477409363, 238.67152881622314, 240.93551325798035, 243.19101476669312, 246.79277181625366]
[17.01, 27.13, 35.9, 41.66, 45.58, 50.31, 53.81, 55.51, 55.6, 56.22, 58.09, 59.17, 60.83, 61.38, 62.37, 62.93, 63.27, 63.26, 64.01, 64.32, 64.89, 64.78, 65.25, 66.4, 66.38, 67.08, 66.83, 66.74, 67.04, 67.96, 68.67, 68.63, 68.94, 69.06, 68.91, 68.85, 69.38, 70.19, 70.48, 70.4, 71.0, 71.4, 71.49, 71.48, 71.82, 72.03, 72.22, 71.99, 71.99, 73.1, 72.5, 73.14, 72.97, 72.74, 73.42, 73.28, 72.96, 73.71, 73.37, 74.11, 73.84, 73.53, 73.99, 74.21, 74.73, 74.59, 74.46, 74.89, 74.46, 74.47, 74.61, 74.74, 74.99, 75.71, 75.32, 75.2, 74.91, 74.72, 74.6, 75.02, 74.81, 75.33, 75.44, 75.11, 74.67, 75.01, 74.56, 75.42, 75.72, 75.42, 75.77, 75.69, 75.57, 75.58, 75.09, 74.8, 74.71, 75.4, 75.44, 75.76, 75.48]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 3, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 10, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 16, noise    level: 0.4000 
   Client 18, noise    level: 0.4000 
   Client 13, noise    level: 0.4000 
   Client 17, noise    level: 0.4000 
   Client 15, noise    level: 0.4000 
   Client 12, noise    level: 0.4000 
   Client 19, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 11, noise    level: 0.4000 
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  14.8800
Round 1 global test acc  17.6400
Round 2 global test acc  20.0800
Round 3 global test acc  24.8600
Round 4 global test acc  29.5900
Round 5 global test acc  29.2500
Round 6 global test acc  24.3500
Round 7 global test acc  32.0300
Round 8 global test acc  33.3000
Round 9 global test acc  24.9900
Round 10 global test acc  29.2200
Round 11 global test acc  33.5300
Round 12 global test acc  27.9000
Round 13 global test acc  26.6700
Round 14 global test acc  26.5400
Round 15 global test acc  31.3100
Round 16 global test acc  36.4200
Round 17 global test acc  33.3700
Round 18 global test acc  31.0500
Round 19 global test acc  31.5100
Round 20 global test acc  30.4100
Round 21 global test acc  33.2100
Round 22 global test acc  30.4200
Round 23 global test acc  40.4500
Round 24 global test acc  41.9500
Round 25 global test acc  37.2200
Round 26 global test acc  41.6000
Round 27 global test acc  41.6300
Round 28 global test acc  46.4600
Round 29 global test acc  41.4500
Round 30 global test acc  40.3900
Round 31 global test acc  41.0100
Round 32 global test acc  33.9100
Round 33 global test acc  40.7800
Round 34 global test acc  34.8200
Round 35 global test acc  37.3900
Round 36 global test acc  37.0400
Round 37 global test acc  46.6100
Round 38 global test acc  34.5700
Round 39 global test acc  40.3000
Round 40 global test acc  39.9800
Round 41 global test acc  38.7400
Round 42 global test acc  44.1200
Round 43 global test acc  39.8500
Round 44 global test acc  36.2200
Round 45 global test acc  43.2800
Round 46 global test acc  46.1800
Round 47 global test acc  36.4200
Round 48 global test acc  40.8200
Round 49 global test acc  42.7200
Round 50 global test acc  40.0500
Round 51 global test acc  36.0400
Round 52 global test acc  42.9100
Round 53 global test acc  37.0900
Round 54 global test acc  39.3900
Round 55 global test acc  37.2600
Round 56 global test acc  36.5100
Round 57 global test acc  38.9900
Round 58 global test acc  43.8900
Round 59 global test acc  45.2700
Round 60 global test acc  43.4200
Round 61 global test acc  44.3300
Round 62 global test acc  39.7000
Round 63 global test acc  45.8200
Round 64 global test acc  37.9400
Round 65 global test acc  37.1600
Round 66 global test acc  38.4400
Round 67 global test acc  46.8200
Round 68 global test acc  40.4400
Round 69 global test acc  42.8700
Round 70 global test acc  36.3600
Round 71 global test acc  40.3500
Round 72 global test acc  41.7200
Round 73 global test acc  43.2800
Round 74 global test acc  43.1700
Round 75 global test acc  45.7100
Round 76 global test acc  43.4100
Round 77 global test acc  44.1500
Round 78 global test acc  40.4100
Round 79 global test acc  36.3900
Round 80 global test acc  34.3100
Round 81 global test acc  31.6700
Round 82 global test acc  30.0900
Round 83 global test acc  29.2100
Round 84 global test acc  26.9100
Round 85 global test acc  26.4000
Round 86 global test acc  29.3400
Round 87 global test acc  28.2300
Round 88 global test acc  27.2100
Round 89 global test acc  26.0200
Round 90 global test acc  24.8300
Round 91 global test acc  24.4400
Round 92 global test acc  25.0000
Round 93 global test acc  25.2100
Round 94 global test acc  24.7400
Round 95 global test acc  24.4900
Round 96 global test acc  24.0900
Round 97 global test acc  23.7500
Round 98 global test acc  23.5400
Round 99 global test acc  23.8000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 13, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 17, noise    level: 0.4000 
   Client 15, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 19, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 10, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 14, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 16, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.996, Test loss: 2.202, Test accuracy: 18.79
Round   1, Train loss: 1.651, Test loss: 1.905, Test accuracy: 29.65
Round   2, Train loss: 1.489, Test loss: 1.700, Test accuracy: 37.08
Round   3, Train loss: 1.502, Test loss: 1.446, Test accuracy: 43.64
Round   4, Train loss: 1.377, Test loss: 1.297, Test accuracy: 49.05
Round   5, Train loss: 1.277, Test loss: 1.241, Test accuracy: 53.97
Round   6, Train loss: 1.253, Test loss: 1.131, Test accuracy: 57.13
Round   7, Train loss: 1.252, Test loss: 1.124, Test accuracy: 58.08
Round   8, Train loss: 1.141, Test loss: 1.128, Test accuracy: 57.31
Round   9, Train loss: 1.214, Test loss: 1.071, Test accuracy: 59.27
Round  10, Train loss: 1.190, Test loss: 1.038, Test accuracy: 60.79
Round  11, Train loss: 1.128, Test loss: 1.050, Test accuracy: 61.76
Round  12, Train loss: 1.089, Test loss: 1.013, Test accuracy: 62.18
Round  13, Train loss: 1.116, Test loss: 0.989, Test accuracy: 63.24
Round  14, Train loss: 1.080, Test loss: 0.992, Test accuracy: 62.71
Round  15, Train loss: 1.157, Test loss: 0.956, Test accuracy: 63.83
Round  16, Train loss: 1.211, Test loss: 0.941, Test accuracy: 64.96
Round  17, Train loss: 1.038, Test loss: 0.953, Test accuracy: 63.76
Round  18, Train loss: 1.022, Test loss: 0.934, Test accuracy: 65.08
Round  19, Train loss: 1.078, Test loss: 0.915, Test accuracy: 65.66
Round  20, Train loss: 0.939, Test loss: 0.910, Test accuracy: 66.03
Round  21, Train loss: 1.064, Test loss: 0.883, Test accuracy: 67.66
Round  22, Train loss: 0.944, Test loss: 0.885, Test accuracy: 68.20
Round  23, Train loss: 0.874, Test loss: 0.879, Test accuracy: 68.33
Round  24, Train loss: 0.945, Test loss: 0.860, Test accuracy: 69.06
Round  25, Train loss: 0.887, Test loss: 0.846, Test accuracy: 68.87
Round  26, Train loss: 0.978, Test loss: 0.846, Test accuracy: 69.13
Round  27, Train loss: 0.936, Test loss: 0.836, Test accuracy: 69.47
Round  28, Train loss: 0.977, Test loss: 0.828, Test accuracy: 69.56
Round  29, Train loss: 0.960, Test loss: 0.809, Test accuracy: 70.39
Round  30, Train loss: 0.821, Test loss: 0.811, Test accuracy: 70.08
Round  31, Train loss: 0.863, Test loss: 0.812, Test accuracy: 69.63
Round  32, Train loss: 0.897, Test loss: 0.802, Test accuracy: 70.65
Round  33, Train loss: 0.784, Test loss: 0.812, Test accuracy: 70.24
Round  34, Train loss: 0.855, Test loss: 0.793, Test accuracy: 70.77
Round  35, Train loss: 0.934, Test loss: 0.780, Test accuracy: 71.74
Round  36, Train loss: 0.951, Test loss: 0.780, Test accuracy: 72.28
Round  37, Train loss: 0.819, Test loss: 0.777, Test accuracy: 72.19
Round  38, Train loss: 0.838, Test loss: 0.752, Test accuracy: 73.18
Round  39, Train loss: 0.801, Test loss: 0.754, Test accuracy: 72.56
Round  40, Train loss: 0.798, Test loss: 0.750, Test accuracy: 72.68
Round  41, Train loss: 0.805, Test loss: 0.750, Test accuracy: 72.65
Round  42, Train loss: 0.749, Test loss: 0.759, Test accuracy: 73.01
Round  43, Train loss: 0.870, Test loss: 0.740, Test accuracy: 73.50
Round  44, Train loss: 0.852, Test loss: 0.736, Test accuracy: 73.47
Round  45, Train loss: 0.857, Test loss: 0.738, Test accuracy: 73.36
Round  46, Train loss: 0.827, Test loss: 0.731, Test accuracy: 74.18
Round  47, Train loss: 0.774, Test loss: 0.734, Test accuracy: 74.12
Round  48, Train loss: 0.841, Test loss: 0.740, Test accuracy: 73.63
Round  49, Train loss: 0.721, Test loss: 0.730, Test accuracy: 74.28
Round  50, Train loss: 0.720, Test loss: 0.728, Test accuracy: 74.51
Round  51, Train loss: 0.691, Test loss: 0.726, Test accuracy: 74.30
Round  52, Train loss: 0.619, Test loss: 0.727, Test accuracy: 74.38
Round  53, Train loss: 0.717, Test loss: 0.715, Test accuracy: 75.05
Round  54, Train loss: 0.665, Test loss: 0.721, Test accuracy: 74.78
Round  55, Train loss: 0.700, Test loss: 0.721, Test accuracy: 74.86
Round  56, Train loss: 0.809, Test loss: 0.712, Test accuracy: 75.43
Round  57, Train loss: 0.792, Test loss: 0.716, Test accuracy: 75.03
Round  58, Train loss: 0.612, Test loss: 0.710, Test accuracy: 75.09
Round  59, Train loss: 0.652, Test loss: 0.705, Test accuracy: 75.41
Round  60, Train loss: 0.718, Test loss: 0.703, Test accuracy: 75.30
Round  61, Train loss: 0.776, Test loss: 0.707, Test accuracy: 75.48
Round  62, Train loss: 0.783, Test loss: 0.706, Test accuracy: 75.18
Round  63, Train loss: 0.604, Test loss: 0.709, Test accuracy: 75.24
Round  64, Train loss: 0.714, Test loss: 0.701, Test accuracy: 75.63
Round  65, Train loss: 0.595, Test loss: 0.706, Test accuracy: 75.37
Round  66, Train loss: 0.679, Test loss: 0.698, Test accuracy: 75.60
Round  67, Train loss: 0.669, Test loss: 0.703, Test accuracy: 75.55
Round  68, Train loss: 0.722, Test loss: 0.690, Test accuracy: 76.14
Round  69, Train loss: 0.605, Test loss: 0.697, Test accuracy: 75.87
Round  70, Train loss: 0.757, Test loss: 0.695, Test accuracy: 76.01
Round  71, Train loss: 0.726, Test loss: 0.695, Test accuracy: 75.98
Round  72, Train loss: 0.704, Test loss: 0.694, Test accuracy: 76.40
Round  73, Train loss: 0.641, Test loss: 0.687, Test accuracy: 76.10
Round  74, Train loss: 0.637, Test loss: 0.694, Test accuracy: 76.10
Round  75, Train loss: 0.720, Test loss: 0.701, Test accuracy: 75.62
Round  76, Train loss: 0.663, Test loss: 0.693, Test accuracy: 76.08
Round  77, Train loss: 0.678, Test loss: 0.692, Test accuracy: 76.06
Round  78, Train loss: 0.567, Test loss: 0.699, Test accuracy: 76.06
Round  79, Train loss: 0.558, Test loss: 0.698, Test accuracy: 76.14
Round  80, Train loss: 0.694, Test loss: 0.693, Test accuracy: 76.19
Round  81, Train loss: 0.598, Test loss: 0.695, Test accuracy: 76.34
Round  82, Train loss: 0.597, Test loss: 0.690, Test accuracy: 76.26
Round  83, Train loss: 0.587, Test loss: 0.692, Test accuracy: 75.99
Round  84, Train loss: 0.554, Test loss: 0.696, Test accuracy: 76.39
Round  85, Train loss: 0.591, Test loss: 0.703, Test accuracy: 75.93
Round  86, Train loss: 0.599, Test loss: 0.703, Test accuracy: 76.07
Round  87, Train loss: 0.454, Test loss: 0.698, Test accuracy: 75.85
Round  88, Train loss: 0.643, Test loss: 0.696, Test accuracy: 76.21
Round  89, Train loss: 0.595, Test loss: 0.694, Test accuracy: 76.39
Round  90, Train loss: 0.614, Test loss: 0.697, Test accuracy: 75.90
Round  91, Train loss: 0.522, Test loss: 0.690, Test accuracy: 76.46
Round  92, Train loss: 0.506, Test loss: 0.701, Test accuracy: 76.02
Round  93, Train loss: 0.628, Test loss: 0.689, Test accuracy: 76.70
Round  94, Train loss: 0.499, Test loss: 0.699, Test accuracy: 76.62
Round  95, Train loss: 0.388, Test loss: 0.683, Test accuracy: 76.74
Round  96, Train loss: 0.509, Test loss: 0.688, Test accuracy: 76.74
Round  97, Train loss: 0.549, Test loss: 0.688, Test accuracy: 76.67
Round  98, Train loss: 0.649, Test loss: 0.696, Test accuracy: 76.22
Round  99, Train loss: 0.591, Test loss: 0.695, Test accuracy: 76.38
Final Round, Train loss: 0.494, Test loss: 0.702, Test accuracy: 76.90
Average accuracy final 10 rounds: 76.44500000000001
999.1256968975067
[1.6193740367889404, 2.9240245819091797, 4.229444265365601, 5.544698476791382, 6.858296632766724, 8.173804998397827, 9.463046789169312, 10.756851196289062, 12.053477764129639, 13.358681917190552, 14.660043239593506, 15.957086086273193, 17.247324466705322, 18.5356764793396, 19.820173263549805, 21.11148691177368, 22.40218424797058, 23.697657346725464, 24.99436855316162, 26.282389163970947, 27.568519592285156, 28.860970497131348, 30.153971195220947, 31.44959330558777, 32.740763425827026, 34.03152537345886, 35.31420874595642, 36.603753328323364, 37.90289354324341, 39.19699954986572, 40.485915660858154, 41.76966071128845, 43.05509948730469, 44.34180212020874, 45.63462972640991, 46.92314839363098, 48.2149703502655, 49.49919605255127, 50.7874870300293, 52.076318979263306, 53.36720013618469, 54.65598177909851, 55.946497678756714, 57.23686146736145, 58.52295517921448, 59.8145010471344, 61.10415768623352, 62.38768553733826, 63.564526081085205, 64.73526859283447, 65.90894627571106, 67.07009983062744, 68.22747540473938, 69.38449883460999, 70.55826926231384, 71.72764039039612, 72.9010283946991, 74.05734753608704, 75.2143075466156, 76.38181948661804, 77.54713582992554, 78.71258544921875, 79.87999296188354, 81.040442943573, 82.19608688354492, 83.3640079498291, 84.53386998176575, 85.7040696144104, 86.87152552604675, 88.03342700004578, 89.19189763069153, 90.36342692375183, 91.5356502532959, 92.70478105545044, 93.87157773971558, 95.03658366203308, 96.20414805412292, 97.36740064620972, 98.53633213043213, 99.70522975921631, 100.86303734779358, 102.01903486251831, 103.19001746177673, 104.36168479919434, 105.52868986129761, 106.6920280456543, 107.85111212730408, 109.00820064544678, 110.17729592323303, 111.34635496139526, 112.51596784591675, 113.68578267097473, 114.8544499874115, 116.01208829879761, 117.18259787559509, 118.35284686088562, 119.53369569778442, 120.70948362350464, 121.86843371391296, 123.03235268592834, 124.99437665939331]
[18.79, 29.65, 37.08, 43.64, 49.05, 53.97, 57.13, 58.08, 57.31, 59.27, 60.79, 61.76, 62.18, 63.24, 62.71, 63.83, 64.96, 63.76, 65.08, 65.66, 66.03, 67.66, 68.2, 68.33, 69.06, 68.87, 69.13, 69.47, 69.56, 70.39, 70.08, 69.63, 70.65, 70.24, 70.77, 71.74, 72.28, 72.19, 73.18, 72.56, 72.68, 72.65, 73.01, 73.5, 73.47, 73.36, 74.18, 74.12, 73.63, 74.28, 74.51, 74.3, 74.38, 75.05, 74.78, 74.86, 75.43, 75.03, 75.09, 75.41, 75.3, 75.48, 75.18, 75.24, 75.63, 75.37, 75.6, 75.55, 76.14, 75.87, 76.01, 75.98, 76.4, 76.1, 76.1, 75.62, 76.08, 76.06, 76.06, 76.14, 76.19, 76.34, 76.26, 75.99, 76.39, 75.93, 76.07, 75.85, 76.21, 76.39, 75.9, 76.46, 76.02, 76.7, 76.62, 76.74, 76.74, 76.67, 76.22, 76.38, 76.9]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.8 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 0, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 18, noise    level: 0.4000 
   Client 11, noise    level: 0.4000 
   Client 17, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 16, noise    level: 0.4000 
   Client 19, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 10, noise    level: 0.4000 
   Client 13, noise    level: 0.4000 
   Client 12, noise    level: 0.4000 
   Client 15, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 2.001, Test loss: 2.133, Test accuracy: 21.73
Round   1, Train loss: 1.609, Test loss: 1.910, Test accuracy: 30.42
Round   2, Train loss: 1.472, Test loss: 1.708, Test accuracy: 38.58
Round   3, Train loss: 1.438, Test loss: 1.410, Test accuracy: 42.40
Round   4, Train loss: 1.340, Test loss: 1.317, Test accuracy: 48.69
Round   5, Train loss: 1.325, Test loss: 1.262, Test accuracy: 53.10
Round   6, Train loss: 1.325, Test loss: 1.164, Test accuracy: 55.98
Round   7, Train loss: 1.289, Test loss: 1.151, Test accuracy: 56.46
Round   8, Train loss: 1.223, Test loss: 1.154, Test accuracy: 57.42
Round   9, Train loss: 1.145, Test loss: 1.097, Test accuracy: 59.01
Round  10, Train loss: 1.149, Test loss: 1.047, Test accuracy: 61.31
Round  11, Train loss: 1.061, Test loss: 1.049, Test accuracy: 60.75
Round  12, Train loss: 1.218, Test loss: 1.023, Test accuracy: 61.42
Round  13, Train loss: 1.100, Test loss: 0.990, Test accuracy: 62.52
Round  14, Train loss: 1.099, Test loss: 0.979, Test accuracy: 63.27
Round  15, Train loss: 1.067, Test loss: 0.948, Test accuracy: 64.02
Round  16, Train loss: 1.081, Test loss: 0.938, Test accuracy: 65.15
Round  17, Train loss: 1.008, Test loss: 0.948, Test accuracy: 64.76
Round  18, Train loss: 1.038, Test loss: 0.925, Test accuracy: 65.74
Round  19, Train loss: 1.042, Test loss: 0.908, Test accuracy: 66.92
Round  20, Train loss: 1.058, Test loss: 0.910, Test accuracy: 66.23
Round  21, Train loss: 1.063, Test loss: 0.898, Test accuracy: 67.16
Round  22, Train loss: 1.060, Test loss: 0.901, Test accuracy: 67.42
Round  23, Train loss: 0.882, Test loss: 0.880, Test accuracy: 68.04
Round  24, Train loss: 0.985, Test loss: 0.865, Test accuracy: 68.93
Round  25, Train loss: 0.802, Test loss: 0.864, Test accuracy: 68.63
Round  26, Train loss: 0.894, Test loss: 0.842, Test accuracy: 69.10
Round  27, Train loss: 0.937, Test loss: 0.836, Test accuracy: 69.85
Round  28, Train loss: 0.871, Test loss: 0.843, Test accuracy: 70.07
Round  29, Train loss: 0.939, Test loss: 0.825, Test accuracy: 69.93
Round  30, Train loss: 0.863, Test loss: 0.833, Test accuracy: 69.84
Round  31, Train loss: 0.819, Test loss: 0.814, Test accuracy: 69.47
Round  32, Train loss: 1.039, Test loss: 0.807, Test accuracy: 70.47
Round  33, Train loss: 0.889, Test loss: 0.809, Test accuracy: 70.82
Round  34, Train loss: 0.832, Test loss: 0.805, Test accuracy: 71.35
Round  35, Train loss: 0.882, Test loss: 0.794, Test accuracy: 71.67
Round  36, Train loss: 0.934, Test loss: 0.788, Test accuracy: 71.93
Round  37, Train loss: 0.830, Test loss: 0.791, Test accuracy: 72.12
Round  38, Train loss: 0.855, Test loss: 0.777, Test accuracy: 72.48
Round  39, Train loss: 0.855, Test loss: 0.774, Test accuracy: 72.24
Round  40, Train loss: 0.803, Test loss: 0.761, Test accuracy: 72.92
Round  41, Train loss: 0.892, Test loss: 0.764, Test accuracy: 73.22
Round  42, Train loss: 0.711, Test loss: 0.771, Test accuracy: 72.93
Round  43, Train loss: 0.731, Test loss: 0.751, Test accuracy: 73.29
Round  44, Train loss: 0.817, Test loss: 0.733, Test accuracy: 74.15
Round  45, Train loss: 0.897, Test loss: 0.747, Test accuracy: 73.58
Round  46, Train loss: 0.710, Test loss: 0.755, Test accuracy: 73.15
Round  47, Train loss: 0.856, Test loss: 0.751, Test accuracy: 73.12
Round  48, Train loss: 0.924, Test loss: 0.743, Test accuracy: 73.56
Round  49, Train loss: 0.703, Test loss: 0.745, Test accuracy: 73.94
Round  50, Train loss: 0.768, Test loss: 0.744, Test accuracy: 73.55
Round  51, Train loss: 0.677, Test loss: 0.746, Test accuracy: 73.80
Round  52, Train loss: 0.751, Test loss: 0.744, Test accuracy: 73.75
Round  53, Train loss: 0.687, Test loss: 0.730, Test accuracy: 73.93
Round  54, Train loss: 0.709, Test loss: 0.729, Test accuracy: 74.09
Round  55, Train loss: 0.708, Test loss: 0.730, Test accuracy: 74.62
Round  56, Train loss: 0.870, Test loss: 0.714, Test accuracy: 74.58
Round  57, Train loss: 0.688, Test loss: 0.711, Test accuracy: 74.71
Round  58, Train loss: 0.700, Test loss: 0.734, Test accuracy: 74.13
Round  59, Train loss: 0.634, Test loss: 0.720, Test accuracy: 74.91
Round  60, Train loss: 0.746, Test loss: 0.723, Test accuracy: 74.83
Round  61, Train loss: 0.676, Test loss: 0.709, Test accuracy: 75.07
Round  62, Train loss: 0.703, Test loss: 0.719, Test accuracy: 74.63
Round  63, Train loss: 0.737, Test loss: 0.716, Test accuracy: 75.02
Round  64, Train loss: 0.707, Test loss: 0.721, Test accuracy: 74.48
Round  65, Train loss: 0.644, Test loss: 0.713, Test accuracy: 74.97
Round  66, Train loss: 0.772, Test loss: 0.722, Test accuracy: 74.64
Round  67, Train loss: 0.807, Test loss: 0.716, Test accuracy: 74.63
Round  68, Train loss: 0.738, Test loss: 0.708, Test accuracy: 75.27
Round  69, Train loss: 0.639, Test loss: 0.704, Test accuracy: 75.56
Round  70, Train loss: 0.577, Test loss: 0.699, Test accuracy: 75.53
Round  71, Train loss: 0.652, Test loss: 0.704, Test accuracy: 74.83
Round  72, Train loss: 0.670, Test loss: 0.711, Test accuracy: 74.78
Round  73, Train loss: 0.687, Test loss: 0.696, Test accuracy: 75.63
Round  74, Train loss: 0.655, Test loss: 0.694, Test accuracy: 75.63
Round  75, Train loss: 0.648, Test loss: 0.707, Test accuracy: 75.31
Round  76, Train loss: 0.635, Test loss: 0.702, Test accuracy: 75.33
Round  77, Train loss: 0.638, Test loss: 0.703, Test accuracy: 75.39
Round  78, Train loss: 0.650, Test loss: 0.691, Test accuracy: 75.70
Round  79, Train loss: 0.648, Test loss: 0.696, Test accuracy: 75.48
Round  80, Train loss: 0.733, Test loss: 0.697, Test accuracy: 75.61
Round  81, Train loss: 0.587, Test loss: 0.695, Test accuracy: 75.74
Round  82, Train loss: 0.583, Test loss: 0.705, Test accuracy: 75.10
Round  83, Train loss: 0.614, Test loss: 0.688, Test accuracy: 75.96
Round  84, Train loss: 0.629, Test loss: 0.691, Test accuracy: 75.58
Round  85, Train loss: 0.528, Test loss: 0.701, Test accuracy: 75.40
Round  86, Train loss: 0.594, Test loss: 0.709, Test accuracy: 74.95
Round  87, Train loss: 0.562, Test loss: 0.702, Test accuracy: 75.22
Round  88, Train loss: 0.618, Test loss: 0.696, Test accuracy: 75.79
Round  89, Train loss: 0.651, Test loss: 0.687, Test accuracy: 75.85
Round  90, Train loss: 0.644, Test loss: 0.697, Test accuracy: 75.52
Round  91, Train loss: 0.528, Test loss: 0.692, Test accuracy: 75.73
Round  92, Train loss: 0.606, Test loss: 0.696, Test accuracy: 75.53
Round  93, Train loss: 0.525, Test loss: 0.701, Test accuracy: 75.60
Round  94, Train loss: 0.410, Test loss: 0.696, Test accuracy: 75.90
Round  95, Train loss: 0.540, Test loss: 0.694, Test accuracy: 75.66
Round  96, Train loss: 0.521, Test loss: 0.696, Test accuracy: 76.10
Round  97, Train loss: 0.602, Test loss: 0.694, Test accuracy: 76.47
Round  98, Train loss: 0.620, Test loss: 0.685, Test accuracy: 76.71
Round  99, Train loss: 0.514, Test loss: 0.695, Test accuracy: 75.83
Final Round, Train loss: 0.354, Test loss: 0.700, Test accuracy: 75.71
Average accuracy final 10 rounds: 75.905
1395.8201293945312
[1.609266757965088, 2.9306581020355225, 4.224908828735352, 5.506855726242065, 6.789044618606567, 8.080660581588745, 9.377963066101074, 10.680081367492676, 11.987794160842896, 13.28433346748352, 14.589611291885376, 15.891774654388428, 17.199430465698242, 18.50980281829834, 19.800822734832764, 21.097991466522217, 22.39913558959961, 23.69662857055664, 24.99857258796692, 26.290698289871216, 27.5865216255188, 29.716004133224487, 31.843945741653442, 33.95218348503113, 36.07368206977844, 38.19124412536621, 40.29324960708618, 42.4049072265625, 44.52632188796997, 46.63847231864929, 48.747554540634155, 50.8711884021759, 52.99053430557251, 55.1072154045105, 57.22579264640808, 59.34883451461792, 61.45863604545593, 63.575597047805786, 65.67617869377136, 67.76711511611938, 69.85326409339905, 71.94368267059326, 74.03753900527954, 76.12001967430115, 78.2116003036499, 80.31192946434021, 82.40235447883606, 84.48682594299316, 86.64952254295349, 88.7441918849945, 90.83245706558228, 92.92347693443298, 95.01950073242188, 97.11000537872314, 99.20340037345886, 101.3040246963501, 103.39615535736084, 105.48047423362732, 107.57749128341675, 109.67543339729309, 111.7598729133606, 113.85006856918335, 115.95169472694397, 118.04266715049744, 120.1286313533783, 122.2251968383789, 124.31867814064026, 126.40008568763733, 128.491464138031, 130.58870935440063, 132.68392157554626, 134.76914167404175, 136.8733024597168, 138.97010254859924, 141.05182766914368, 143.15505862236023, 145.25517344474792, 147.34525513648987, 149.43094110488892, 151.53145217895508, 153.62280440330505, 155.7052435874939, 157.79434299468994, 159.8939290046692, 161.97587275505066, 164.0617322921753, 166.15762281417847, 168.2649383544922, 170.3506190776825, 172.43995642662048, 174.53923416137695, 176.68819189071655, 178.77602219581604, 180.8794755935669, 182.97102427482605, 185.05515027046204, 187.15016222000122, 189.2470726966858, 191.33204650878906, 193.42309761047363, 195.40503811836243]
[21.73, 30.42, 38.58, 42.4, 48.69, 53.1, 55.98, 56.46, 57.42, 59.01, 61.31, 60.75, 61.42, 62.52, 63.27, 64.02, 65.15, 64.76, 65.74, 66.92, 66.23, 67.16, 67.42, 68.04, 68.93, 68.63, 69.1, 69.85, 70.07, 69.93, 69.84, 69.47, 70.47, 70.82, 71.35, 71.67, 71.93, 72.12, 72.48, 72.24, 72.92, 73.22, 72.93, 73.29, 74.15, 73.58, 73.15, 73.12, 73.56, 73.94, 73.55, 73.8, 73.75, 73.93, 74.09, 74.62, 74.58, 74.71, 74.13, 74.91, 74.83, 75.07, 74.63, 75.02, 74.48, 74.97, 74.64, 74.63, 75.27, 75.56, 75.53, 74.83, 74.78, 75.63, 75.63, 75.31, 75.33, 75.39, 75.7, 75.48, 75.61, 75.74, 75.1, 75.96, 75.58, 75.4, 74.95, 75.22, 75.79, 75.85, 75.52, 75.73, 75.53, 75.6, 75.9, 75.66, 76.1, 76.47, 76.71, 75.83, 75.71]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: none, level_n_system: 0.8 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 11, noise    level: 0.4000 
   Client 19, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 13, noise    level: 0.4000 
   Client 18, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 15, noise    level: 0.4000 
   Client 12, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 16, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 17, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.987, Test loss: 1.890, Test accuracy: 28.49
Round   1, Train loss: 1.646, Test loss: 1.465, Test accuracy: 39.48
Round   2, Train loss: 1.504, Test loss: 1.332, Test accuracy: 45.16
Round   3, Train loss: 1.416, Test loss: 1.254, Test accuracy: 49.34
Round   4, Train loss: 1.349, Test loss: 1.182, Test accuracy: 53.15
Round   5, Train loss: 1.293, Test loss: 1.122, Test accuracy: 55.43
Round   6, Train loss: 1.250, Test loss: 1.082, Test accuracy: 58.18
Round   7, Train loss: 1.214, Test loss: 1.057, Test accuracy: 59.35
Round   8, Train loss: 1.188, Test loss: 1.032, Test accuracy: 61.22
Round   9, Train loss: 1.163, Test loss: 1.009, Test accuracy: 61.80
Round  10, Train loss: 1.145, Test loss: 0.988, Test accuracy: 63.18
Round  11, Train loss: 1.124, Test loss: 0.975, Test accuracy: 63.71
Round  12, Train loss: 1.107, Test loss: 0.969, Test accuracy: 64.18
Round  13, Train loss: 1.097, Test loss: 0.950, Test accuracy: 64.81
Round  14, Train loss: 1.079, Test loss: 0.929, Test accuracy: 65.27
Round  15, Train loss: 1.065, Test loss: 0.918, Test accuracy: 65.57
Round  16, Train loss: 1.048, Test loss: 0.905, Test accuracy: 66.42
Round  17, Train loss: 1.038, Test loss: 0.900, Test accuracy: 66.98
Round  18, Train loss: 1.023, Test loss: 0.899, Test accuracy: 67.37
Round  19, Train loss: 1.016, Test loss: 0.885, Test accuracy: 67.50
Round  20, Train loss: 0.937, Test loss: 0.889, Test accuracy: 67.22
Round  21, Train loss: 0.955, Test loss: 0.896, Test accuracy: 67.77
Round  22, Train loss: 1.026, Test loss: 0.875, Test accuracy: 68.24
Round  23, Train loss: 0.947, Test loss: 0.864, Test accuracy: 68.54
Round  24, Train loss: 0.880, Test loss: 0.860, Test accuracy: 69.08
Round  25, Train loss: 0.957, Test loss: 0.841, Test accuracy: 69.23
Round  26, Train loss: 0.924, Test loss: 0.841, Test accuracy: 69.27
Round  27, Train loss: 0.911, Test loss: 0.840, Test accuracy: 69.01
Round  28, Train loss: 0.902, Test loss: 0.833, Test accuracy: 69.67
Round  29, Train loss: 0.876, Test loss: 0.818, Test accuracy: 70.44
Round  30, Train loss: 0.948, Test loss: 0.820, Test accuracy: 70.40
Round  31, Train loss: 0.845, Test loss: 0.817, Test accuracy: 70.27
Round  32, Train loss: 0.861, Test loss: 0.804, Test accuracy: 70.93
Round  33, Train loss: 0.796, Test loss: 0.801, Test accuracy: 71.49
Round  34, Train loss: 0.786, Test loss: 0.800, Test accuracy: 71.57
Round  35, Train loss: 1.006, Test loss: 0.797, Test accuracy: 71.61
Round  36, Train loss: 0.888, Test loss: 0.802, Test accuracy: 71.73
Round  37, Train loss: 0.804, Test loss: 0.793, Test accuracy: 71.41
Round  38, Train loss: 0.917, Test loss: 0.773, Test accuracy: 72.03
Round  39, Train loss: 0.753, Test loss: 0.784, Test accuracy: 72.32
Round  40, Train loss: 0.899, Test loss: 0.770, Test accuracy: 72.46
Round  41, Train loss: 0.951, Test loss: 0.776, Test accuracy: 72.16
Round  42, Train loss: 0.794, Test loss: 0.768, Test accuracy: 72.85
Round  43, Train loss: 0.835, Test loss: 0.765, Test accuracy: 72.71
Round  44, Train loss: 0.936, Test loss: 0.754, Test accuracy: 73.09
Round  45, Train loss: 0.779, Test loss: 0.750, Test accuracy: 73.58
Round  46, Train loss: 0.748, Test loss: 0.745, Test accuracy: 73.55
Round  47, Train loss: 0.776, Test loss: 0.750, Test accuracy: 73.54
Round  48, Train loss: 0.781, Test loss: 0.739, Test accuracy: 73.71
Round  49, Train loss: 0.668, Test loss: 0.744, Test accuracy: 73.76
Round  50, Train loss: 0.770, Test loss: 0.747, Test accuracy: 73.29
Round  51, Train loss: 0.803, Test loss: 0.746, Test accuracy: 73.47
Round  52, Train loss: 0.780, Test loss: 0.741, Test accuracy: 73.76
Round  53, Train loss: 0.783, Test loss: 0.736, Test accuracy: 73.88
Round  54, Train loss: 0.667, Test loss: 0.727, Test accuracy: 74.49
Round  55, Train loss: 0.658, Test loss: 0.731, Test accuracy: 74.65
Round  56, Train loss: 0.761, Test loss: 0.719, Test accuracy: 74.66
Round  57, Train loss: 0.761, Test loss: 0.725, Test accuracy: 74.63
Round  58, Train loss: 0.802, Test loss: 0.726, Test accuracy: 74.56
Round  59, Train loss: 0.652, Test loss: 0.716, Test accuracy: 74.51
Round  60, Train loss: 0.715, Test loss: 0.716, Test accuracy: 74.79
Round  61, Train loss: 0.623, Test loss: 0.718, Test accuracy: 74.99
Round  62, Train loss: 0.782, Test loss: 0.718, Test accuracy: 74.60
Round  63, Train loss: 0.715, Test loss: 0.722, Test accuracy: 75.14
Round  64, Train loss: 0.585, Test loss: 0.709, Test accuracy: 75.42
Round  65, Train loss: 0.692, Test loss: 0.716, Test accuracy: 75.36
Round  66, Train loss: 0.663, Test loss: 0.711, Test accuracy: 75.21
Round  67, Train loss: 0.688, Test loss: 0.715, Test accuracy: 75.15
Round  68, Train loss: 0.652, Test loss: 0.706, Test accuracy: 75.21
Round  69, Train loss: 0.633, Test loss: 0.728, Test accuracy: 74.72
Round  70, Train loss: 0.762, Test loss: 0.716, Test accuracy: 75.19
Round  71, Train loss: 0.709, Test loss: 0.722, Test accuracy: 74.87
Round  72, Train loss: 0.774, Test loss: 0.721, Test accuracy: 74.83
Round  73, Train loss: 0.593, Test loss: 0.714, Test accuracy: 75.50
Round  74, Train loss: 0.711, Test loss: 0.707, Test accuracy: 75.79
Round  75, Train loss: 0.643, Test loss: 0.725, Test accuracy: 75.29
Round  76, Train loss: 0.664, Test loss: 0.720, Test accuracy: 75.22
Round  77, Train loss: 0.588, Test loss: 0.703, Test accuracy: 75.76
Round  78, Train loss: 0.616, Test loss: 0.724, Test accuracy: 74.91
Round  79, Train loss: 0.538, Test loss: 0.716, Test accuracy: 75.06
Round  80, Train loss: 0.461, Test loss: 0.705, Test accuracy: 76.06
Round  81, Train loss: 0.442, Test loss: 0.707, Test accuracy: 75.99
Round  82, Train loss: 0.427, Test loss: 0.710, Test accuracy: 75.92
Round  83, Train loss: 0.421, Test loss: 0.711, Test accuracy: 76.05
Round  84, Train loss: 0.410, Test loss: 0.715, Test accuracy: 75.79
Round  85, Train loss: 0.398, Test loss: 0.706, Test accuracy: 76.11
Round  86, Train loss: 0.392, Test loss: 0.710, Test accuracy: 75.81
Round  87, Train loss: 0.380, Test loss: 0.712, Test accuracy: 76.02
Round  88, Train loss: 0.378, Test loss: 0.708, Test accuracy: 76.02
Round  89, Train loss: 0.366, Test loss: 0.723, Test accuracy: 75.63
Round  90, Train loss: 0.360, Test loss: 0.716, Test accuracy: 75.79
Round  91, Train loss: 0.353, Test loss: 0.719, Test accuracy: 75.82
Round  92, Train loss: 0.346, Test loss: 0.727, Test accuracy: 75.48
Round  93, Train loss: 0.338, Test loss: 0.728, Test accuracy: 75.38
Round  94, Train loss: 0.326, Test loss: 0.727, Test accuracy: 75.68
Round  95, Train loss: 0.329, Test loss: 0.728, Test accuracy: 75.44
Round  96, Train loss: 0.312, Test loss: 0.727, Test accuracy: 75.63
Round  97, Train loss: 0.315, Test loss: 0.728, Test accuracy: 75.51
Round  98, Train loss: 0.313, Test loss: 0.736, Test accuracy: 75.45
Round  99, Train loss: 0.301, Test loss: 0.731, Test accuracy: 75.51
Final Round, Train loss: 0.234, Test loss: 0.737, Test accuracy: 75.42
Average accuracy final 10 rounds: 75.569
1355.9799761772156
[1.5994014739990234, 2.882096290588379, 4.168565511703491, 5.451315402984619, 6.731941223144531, 7.883720636367798, 9.032255411148071, 10.178800344467163, 11.32960557937622, 12.474735498428345, 13.624072790145874, 14.768017768859863, 15.918054103851318, 17.06448769569397, 18.21468234062195, 19.36106777191162, 20.51265859603882, 21.657631158828735, 22.808323621749878, 23.95390272140503, 25.10426950454712, 26.251846075057983, 27.401403665542603, 28.549925327301025, 29.698886156082153, 30.847960948944092, 31.993614673614502, 33.14139175415039, 34.29184556007385, 35.44091463088989, 36.58934950828552, 37.73953580856323, 38.888431787490845, 40.03579497337341, 41.186304569244385, 42.336321115493774, 43.4865243434906, 44.63609457015991, 45.78227877616882, 46.92419695854187, 48.06720733642578, 49.21394181251526, 50.36223220825195, 51.50873780250549, 52.65640735626221, 53.80336952209473, 54.95292687416077, 56.10460925102234, 57.25202298164368, 58.400925397872925, 59.542574882507324, 60.687530517578125, 61.835386753082275, 62.984379529953, 64.13230037689209, 65.27769732475281, 66.42030572891235, 67.56366801261902, 68.7105405330658, 69.85753965377808, 71.00396466255188, 72.15033411979675, 73.2979347705841, 74.44405460357666, 75.59436082839966, 76.74175477027893, 77.89718294143677, 79.04056024551392, 80.18250870704651, 81.33063244819641, 82.48170757293701, 83.63167452812195, 84.77996134757996, 85.92901992797852, 87.07855415344238, 88.22792768478394, 89.37584733963013, 90.523432970047, 91.6685152053833, 92.81211256980896, 93.96084547042847, 95.10987186431885, 96.2517945766449, 97.39721012115479, 98.54666757583618, 99.69301986694336, 100.83610320091248, 101.98459649085999, 103.1329517364502, 104.28149080276489, 105.42946195602417, 106.57925271987915, 107.73011112213135, 108.87223362922668, 110.02032375335693, 111.17009663581848, 112.31919455528259, 113.46730947494507, 114.61520528793335, 115.7639389038086, 117.63495540618896]
[28.49, 39.48, 45.16, 49.34, 53.15, 55.43, 58.18, 59.35, 61.22, 61.8, 63.18, 63.71, 64.18, 64.81, 65.27, 65.57, 66.42, 66.98, 67.37, 67.5, 67.22, 67.77, 68.24, 68.54, 69.08, 69.23, 69.27, 69.01, 69.67, 70.44, 70.4, 70.27, 70.93, 71.49, 71.57, 71.61, 71.73, 71.41, 72.03, 72.32, 72.46, 72.16, 72.85, 72.71, 73.09, 73.58, 73.55, 73.54, 73.71, 73.76, 73.29, 73.47, 73.76, 73.88, 74.49, 74.65, 74.66, 74.63, 74.56, 74.51, 74.79, 74.99, 74.6, 75.14, 75.42, 75.36, 75.21, 75.15, 75.21, 74.72, 75.19, 74.87, 74.83, 75.5, 75.79, 75.29, 75.22, 75.76, 74.91, 75.06, 76.06, 75.99, 75.92, 76.05, 75.79, 76.11, 75.81, 76.02, 76.02, 75.63, 75.79, 75.82, 75.48, 75.38, 75.68, 75.44, 75.63, 75.51, 75.45, 75.51, 75.42]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.8 , level_n_lowerb:0.4  

Files already downloaded and verified
Files already downloaded and verified
   Client 6, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 12, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
   Client 14, noise    level: 0.4000 
   Client 10, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 17, noise    level: 0.4000 
   Client 18, noise    level: 0.4000 
   Client 16, noise    level: 0.4000 
   Client 15, noise    level: 0.4000 
   Client 13, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.991, Test loss: 1.860, Test accuracy: 36.27
Round   1, Train loss: 1.567, Test loss: 1.359, Test accuracy: 44.01
Round   2, Train loss: 1.402, Test loss: 1.241, Test accuracy: 50.08
Round   3, Train loss: 1.322, Test loss: 1.175, Test accuracy: 52.15
Round   4, Train loss: 1.263, Test loss: 1.118, Test accuracy: 55.46
Round   5, Train loss: 1.216, Test loss: 1.073, Test accuracy: 58.61
Round   6, Train loss: 1.176, Test loss: 1.041, Test accuracy: 59.63
Round   7, Train loss: 1.146, Test loss: 1.005, Test accuracy: 61.56
Round   8, Train loss: 1.118, Test loss: 0.996, Test accuracy: 62.40
Round   9, Train loss: 1.097, Test loss: 0.962, Test accuracy: 63.26
Round  10, Train loss: 1.073, Test loss: 0.947, Test accuracy: 63.98
Round  11, Train loss: 1.055, Test loss: 0.925, Test accuracy: 65.11
Round  12, Train loss: 1.034, Test loss: 0.916, Test accuracy: 65.62
Round  13, Train loss: 1.018, Test loss: 0.895, Test accuracy: 66.39
Round  14, Train loss: 1.003, Test loss: 0.884, Test accuracy: 66.80
Round  15, Train loss: 0.991, Test loss: 0.877, Test accuracy: 67.38
Round  16, Train loss: 0.976, Test loss: 0.865, Test accuracy: 68.03
Round  17, Train loss: 0.960, Test loss: 0.855, Test accuracy: 68.30
Round  18, Train loss: 0.946, Test loss: 0.843, Test accuracy: 68.89
Round  19, Train loss: 0.937, Test loss: 0.828, Test accuracy: 69.09
Round  20, Train loss: 0.898, Test loss: 0.831, Test accuracy: 68.78
Round  21, Train loss: 0.998, Test loss: 0.837, Test accuracy: 68.40
Round  22, Train loss: 0.867, Test loss: 0.827, Test accuracy: 69.03
Round  23, Train loss: 0.817, Test loss: 0.809, Test accuracy: 69.72
Round  24, Train loss: 0.907, Test loss: 0.809, Test accuracy: 69.51
Round  25, Train loss: 0.855, Test loss: 0.808, Test accuracy: 69.50
Round  26, Train loss: 0.952, Test loss: 0.789, Test accuracy: 70.71
Round  27, Train loss: 0.931, Test loss: 0.786, Test accuracy: 70.85
Round  28, Train loss: 0.816, Test loss: 0.778, Test accuracy: 71.39
Round  29, Train loss: 0.935, Test loss: 0.772, Test accuracy: 71.14
Round  30, Train loss: 0.774, Test loss: 0.770, Test accuracy: 71.83
Round  31, Train loss: 0.765, Test loss: 0.763, Test accuracy: 71.75
Round  32, Train loss: 0.810, Test loss: 0.749, Test accuracy: 72.42
Round  33, Train loss: 0.821, Test loss: 0.746, Test accuracy: 72.75
Round  34, Train loss: 0.894, Test loss: 0.756, Test accuracy: 72.46
Round  35, Train loss: 0.848, Test loss: 0.750, Test accuracy: 72.47
Round  36, Train loss: 0.884, Test loss: 0.749, Test accuracy: 72.36
Round  37, Train loss: 0.740, Test loss: 0.740, Test accuracy: 72.73
Round  38, Train loss: 0.706, Test loss: 0.731, Test accuracy: 73.51
Round  39, Train loss: 0.830, Test loss: 0.736, Test accuracy: 72.96
Round  40, Train loss: 0.773, Test loss: 0.727, Test accuracy: 73.11
Round  41, Train loss: 0.792, Test loss: 0.725, Test accuracy: 73.62
Round  42, Train loss: 0.702, Test loss: 0.730, Test accuracy: 73.72
Round  43, Train loss: 0.688, Test loss: 0.725, Test accuracy: 73.78
Round  44, Train loss: 0.713, Test loss: 0.724, Test accuracy: 73.95
Round  45, Train loss: 0.826, Test loss: 0.732, Test accuracy: 73.43
Round  46, Train loss: 0.740, Test loss: 0.714, Test accuracy: 74.72
Round  47, Train loss: 0.707, Test loss: 0.709, Test accuracy: 74.25
Round  48, Train loss: 0.732, Test loss: 0.705, Test accuracy: 74.16
Round  49, Train loss: 0.724, Test loss: 0.689, Test accuracy: 74.53
Round  50, Train loss: 0.726, Test loss: 0.705, Test accuracy: 74.49
Round  51, Train loss: 0.693, Test loss: 0.705, Test accuracy: 73.91
Round  52, Train loss: 0.603, Test loss: 0.715, Test accuracy: 73.77
Round  53, Train loss: 0.598, Test loss: 0.703, Test accuracy: 74.38
Round  54, Train loss: 0.570, Test loss: 0.697, Test accuracy: 75.13
Round  55, Train loss: 0.735, Test loss: 0.688, Test accuracy: 75.21
Round  56, Train loss: 0.745, Test loss: 0.695, Test accuracy: 75.15
Round  57, Train loss: 0.617, Test loss: 0.681, Test accuracy: 75.50
Round  58, Train loss: 0.506, Test loss: 0.679, Test accuracy: 75.52
Round  59, Train loss: 0.565, Test loss: 0.687, Test accuracy: 75.53
Round  60, Train loss: 0.698, Test loss: 0.675, Test accuracy: 75.68
Round  61, Train loss: 0.710, Test loss: 0.680, Test accuracy: 75.60
Round  62, Train loss: 0.670, Test loss: 0.688, Test accuracy: 75.26
Round  63, Train loss: 0.565, Test loss: 0.678, Test accuracy: 75.95
Round  64, Train loss: 0.719, Test loss: 0.681, Test accuracy: 75.49
Round  65, Train loss: 0.522, Test loss: 0.679, Test accuracy: 75.96
Round  66, Train loss: 0.600, Test loss: 0.675, Test accuracy: 76.04
Round  67, Train loss: 0.649, Test loss: 0.688, Test accuracy: 75.03
Round  68, Train loss: 0.591, Test loss: 0.667, Test accuracy: 76.23
Round  69, Train loss: 0.607, Test loss: 0.677, Test accuracy: 76.12
Round  70, Train loss: 0.601, Test loss: 0.660, Test accuracy: 76.34
Round  71, Train loss: 0.641, Test loss: 0.674, Test accuracy: 75.98
Round  72, Train loss: 0.499, Test loss: 0.668, Test accuracy: 76.45
Round  73, Train loss: 0.619, Test loss: 0.661, Test accuracy: 76.57
Round  74, Train loss: 0.560, Test loss: 0.667, Test accuracy: 76.24
Round  75, Train loss: 0.608, Test loss: 0.669, Test accuracy: 76.50
Round  76, Train loss: 0.598, Test loss: 0.683, Test accuracy: 75.88
Round  77, Train loss: 0.641, Test loss: 0.679, Test accuracy: 76.23
Round  78, Train loss: 0.519, Test loss: 0.679, Test accuracy: 75.79
Round  79, Train loss: 0.575, Test loss: 0.681, Test accuracy: 75.74
Round  80, Train loss: 0.441, Test loss: 0.674, Test accuracy: 75.92
Round  81, Train loss: 0.421, Test loss: 0.669, Test accuracy: 76.14
Round  82, Train loss: 0.411, Test loss: 0.668, Test accuracy: 76.32
Round  83, Train loss: 0.400, Test loss: 0.672, Test accuracy: 76.41
Round  84, Train loss: 0.391, Test loss: 0.672, Test accuracy: 76.49
Round  85, Train loss: 0.378, Test loss: 0.667, Test accuracy: 76.41
Round  86, Train loss: 0.372, Test loss: 0.680, Test accuracy: 76.28
Round  87, Train loss: 0.364, Test loss: 0.678, Test accuracy: 76.14
Round  88, Train loss: 0.360, Test loss: 0.682, Test accuracy: 75.92
Round  89, Train loss: 0.355, Test loss: 0.682, Test accuracy: 75.97
Round  90, Train loss: 0.342, Test loss: 0.690, Test accuracy: 75.68
Round  91, Train loss: 0.342, Test loss: 0.692, Test accuracy: 75.66
Round  92, Train loss: 0.333, Test loss: 0.689, Test accuracy: 75.68
Round  93, Train loss: 0.326, Test loss: 0.696, Test accuracy: 75.79
Round  94, Train loss: 0.323, Test loss: 0.690, Test accuracy: 75.80
Round  95, Train loss: 0.312, Test loss: 0.708, Test accuracy: 75.58
Round  96, Train loss: 0.313, Test loss: 0.713, Test accuracy: 74.94
Round  97, Train loss: 0.310, Test loss: 0.718, Test accuracy: 75.07
Round  98, Train loss: 0.296, Test loss: 0.716, Test accuracy: 75.27
Round  99, Train loss: 0.301, Test loss: 0.717, Test accuracy: 75.12
Final Round, Train loss: 0.234, Test loss: 0.720, Test accuracy: 75.27
Average accuracy final 10 rounds: 75.459
1912.3574168682098
[1.6168711185455322, 2.902838706970215, 4.2022316455841064, 5.487579584121704, 6.7817606925964355, 8.06784439086914, 9.357420206069946, 10.643086433410645, 11.933382034301758, 13.22146487236023, 14.509120464324951, 15.795037508010864, 17.071061372756958, 18.351311206817627, 19.637064933776855, 20.926295518875122, 22.213663578033447, 23.504497051239014, 24.792604684829712, 26.08874273300171, 27.380815505981445, 29.5060818195343, 31.602158784866333, 33.707940340042114, 35.821996212005615, 37.918203830718994, 40.02104997634888, 42.13359713554382, 44.24378561973572, 46.34606909751892, 48.456997871398926, 50.56382703781128, 52.663233280181885, 54.7841796875, 56.892738819122314, 58.99444246292114, 61.09827733039856, 63.20544457435608, 65.29286646842957, 67.37394595146179, 69.46689105033875, 71.57360696792603, 73.65307307243347, 75.75423908233643, 77.86200213432312, 79.95492434501648, 82.03537082672119, 84.14654970169067, 86.25446152687073, 88.3857147693634, 90.48574185371399, 92.58408164978027, 94.67566514015198, 96.75669407844543, 98.85649585723877, 100.9459822177887, 103.02966594696045, 105.12041878700256, 107.22262120246887, 109.30606698989868, 111.39438819885254, 113.51162815093994, 115.62399911880493, 117.7202684879303, 119.83280372619629, 121.92650842666626, 124.00868773460388, 126.09817600250244, 128.19914531707764, 130.2922818660736, 132.37022280693054, 134.4649703502655, 136.55545139312744, 138.63807773590088, 140.72443389892578, 142.81984782218933, 144.91140794754028, 146.98528909683228, 149.07750988006592, 151.1678946018219, 153.25582671165466, 155.3623445034027, 157.44453048706055, 159.54842972755432, 161.6418809890747, 163.62021684646606, 165.58191871643066, 167.53921175003052, 169.50775694847107, 171.61501502990723, 173.73552870750427, 175.81738448143005, 177.916081905365, 180.00882267951965, 182.09521579742432, 184.18971276283264, 186.29116535186768, 188.42738962173462, 190.56274676322937, 192.69827818870544, 194.76306200027466]
[36.27, 44.01, 50.08, 52.15, 55.46, 58.61, 59.63, 61.56, 62.4, 63.26, 63.98, 65.11, 65.62, 66.39, 66.8, 67.38, 68.03, 68.3, 68.89, 69.09, 68.78, 68.4, 69.03, 69.72, 69.51, 69.5, 70.71, 70.85, 71.39, 71.14, 71.83, 71.75, 72.42, 72.75, 72.46, 72.47, 72.36, 72.73, 73.51, 72.96, 73.11, 73.62, 73.72, 73.78, 73.95, 73.43, 74.72, 74.25, 74.16, 74.53, 74.49, 73.91, 73.77, 74.38, 75.13, 75.21, 75.15, 75.5, 75.52, 75.53, 75.68, 75.6, 75.26, 75.95, 75.49, 75.96, 76.04, 75.03, 76.23, 76.12, 76.34, 75.98, 76.45, 76.57, 76.24, 76.5, 75.88, 76.23, 75.79, 75.74, 75.92, 76.14, 76.32, 76.41, 76.49, 76.41, 76.28, 76.14, 75.92, 75.97, 75.68, 75.66, 75.68, 75.79, 75.8, 75.58, 74.94, 75.07, 75.27, 75.12, 75.27]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.8 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 4, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 18, noise    level: 0.8000 
   Client 15, noise    level: 0.8000 
   Client 10, noise    level: 0.8000 
   Client 14, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 16, noise    level: 0.8000 
   Client 17, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 12, noise    level: 0.8000 
   Client 19, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.788, Test loss: 2.115, Test accuracy: 15.72
Round   0, Global train loss: 1.788, Global test loss: 2.271, Global test accuracy: 14.30
Round   1, Train loss: 1.741, Test loss: 1.960, Test accuracy: 19.84
Round   1, Global train loss: 1.741, Global test loss: 2.283, Global test accuracy: 13.20
Round   2, Train loss: 1.705, Test loss: 1.791, Test accuracy: 26.33
Round   2, Global train loss: 1.705, Global test loss: 2.212, Global test accuracy: 23.83
Round   3, Train loss: 1.618, Test loss: 1.783, Test accuracy: 24.74
Round   3, Global train loss: 1.618, Global test loss: 2.227, Global test accuracy: 21.50
Round   4, Train loss: 1.619, Test loss: 1.776, Test accuracy: 27.09
Round   4, Global train loss: 1.619, Global test loss: 2.267, Global test accuracy: 23.12
Round   5, Train loss: 1.617, Test loss: 1.637, Test accuracy: 28.32
Round   5, Global train loss: 1.617, Global test loss: 2.176, Global test accuracy: 14.65
Round   6, Train loss: 1.549, Test loss: 1.693, Test accuracy: 28.88
Round   6, Global train loss: 1.549, Global test loss: 2.400, Global test accuracy: 12.47
Round   7, Train loss: 1.590, Test loss: 1.620, Test accuracy: 31.63
Round   7, Global train loss: 1.590, Global test loss: 2.206, Global test accuracy: 20.23
Round   8, Train loss: 1.621, Test loss: 1.620, Test accuracy: 31.41
Round   8, Global train loss: 1.621, Global test loss: 2.215, Global test accuracy: 15.59
Round   9, Train loss: 1.627, Test loss: 1.634, Test accuracy: 32.29
Round   9, Global train loss: 1.627, Global test loss: 2.201, Global test accuracy: 20.79
Round  10, Train loss: 1.569, Test loss: 1.561, Test accuracy: 33.29
Round  10, Global train loss: 1.569, Global test loss: 2.218, Global test accuracy: 23.96
Round  11, Train loss: 1.536, Test loss: 1.552, Test accuracy: 33.79
Round  11, Global train loss: 1.536, Global test loss: 2.231, Global test accuracy: 25.58
Round  12, Train loss: 1.580, Test loss: 1.543, Test accuracy: 34.30
Round  12, Global train loss: 1.580, Global test loss: 2.237, Global test accuracy: 16.87
Round  13, Train loss: 1.573, Test loss: 1.532, Test accuracy: 34.34
Round  13, Global train loss: 1.573, Global test loss: 2.181, Global test accuracy: 14.59
Round  14, Train loss: 1.420, Test loss: 1.536, Test accuracy: 34.41
Round  14, Global train loss: 1.420, Global test loss: 2.160, Global test accuracy: 27.58
Round  15, Train loss: 1.440, Test loss: 1.534, Test accuracy: 35.46
Round  15, Global train loss: 1.440, Global test loss: 2.115, Global test accuracy: 16.61
Round  16, Train loss: 1.477, Test loss: 1.534, Test accuracy: 34.62
Round  16, Global train loss: 1.477, Global test loss: 2.217, Global test accuracy: 22.79
Round  17, Train loss: 1.398, Test loss: 1.530, Test accuracy: 35.39
Round  17, Global train loss: 1.398, Global test loss: 2.139, Global test accuracy: 25.33
Round  18, Train loss: 1.620, Test loss: 1.532, Test accuracy: 35.21
Round  18, Global train loss: 1.620, Global test loss: 2.264, Global test accuracy: 16.09
Round  19, Train loss: 1.377, Test loss: 1.532, Test accuracy: 35.26
Round  19, Global train loss: 1.377, Global test loss: 2.092, Global test accuracy: 27.90
Round  20, Train loss: 1.473, Test loss: 1.534, Test accuracy: 35.01
Round  20, Global train loss: 1.473, Global test loss: 2.151, Global test accuracy: 21.21
Round  21, Train loss: 1.421, Test loss: 1.536, Test accuracy: 34.79
Round  21, Global train loss: 1.421, Global test loss: 2.123, Global test accuracy: 24.07
Round  22, Train loss: 1.423, Test loss: 1.525, Test accuracy: 35.47
Round  22, Global train loss: 1.423, Global test loss: 2.139, Global test accuracy: 16.27
Round  23, Train loss: 1.399, Test loss: 1.533, Test accuracy: 34.80
Round  23, Global train loss: 1.399, Global test loss: 2.135, Global test accuracy: 24.83
Round  24, Train loss: 1.489, Test loss: 1.543, Test accuracy: 34.85
Round  24, Global train loss: 1.489, Global test loss: 2.189, Global test accuracy: 27.98
Round  25, Train loss: 1.134, Test loss: 1.557, Test accuracy: 34.83
Round  25, Global train loss: 1.134, Global test loss: 2.104, Global test accuracy: 31.32
Round  26, Train loss: 1.301, Test loss: 1.564, Test accuracy: 34.53
Round  26, Global train loss: 1.301, Global test loss: 2.155, Global test accuracy: 21.91
Round  27, Train loss: 1.352, Test loss: 1.585, Test accuracy: 34.49
Round  27, Global train loss: 1.352, Global test loss: 2.131, Global test accuracy: 24.84
Round  28, Train loss: 1.347, Test loss: 1.617, Test accuracy: 34.32
Round  28, Global train loss: 1.347, Global test loss: 2.161, Global test accuracy: 23.55
Round  29, Train loss: 1.386, Test loss: 1.623, Test accuracy: 34.23
Round  29, Global train loss: 1.386, Global test loss: 2.226, Global test accuracy: 20.08
Round  30, Train loss: 1.453, Test loss: 1.628, Test accuracy: 34.61
Round  30, Global train loss: 1.453, Global test loss: 2.153, Global test accuracy: 22.40
Round  31, Train loss: 1.147, Test loss: 1.615, Test accuracy: 34.79
Round  31, Global train loss: 1.147, Global test loss: 2.137, Global test accuracy: 29.67
Round  32, Train loss: 1.113, Test loss: 1.616, Test accuracy: 35.50
Round  32, Global train loss: 1.113, Global test loss: 2.092, Global test accuracy: 26.94
Round  33, Train loss: 1.260, Test loss: 1.625, Test accuracy: 35.05
Round  33, Global train loss: 1.260, Global test loss: 2.159, Global test accuracy: 25.90
Round  34, Train loss: 1.275, Test loss: 1.634, Test accuracy: 34.05
Round  34, Global train loss: 1.275, Global test loss: 2.164, Global test accuracy: 22.48
Round  35, Train loss: 1.283, Test loss: 1.641, Test accuracy: 34.13
Round  35, Global train loss: 1.283, Global test loss: 2.206, Global test accuracy: 15.62
Round  36, Train loss: 1.235, Test loss: 1.681, Test accuracy: 33.51
Round  36, Global train loss: 1.235, Global test loss: 2.094, Global test accuracy: 25.45
Round  37, Train loss: 1.450, Test loss: 1.694, Test accuracy: 33.90
Round  37, Global train loss: 1.450, Global test loss: 2.243, Global test accuracy: 17.72
Round  38, Train loss: 1.258, Test loss: 1.707, Test accuracy: 33.58
Round  38, Global train loss: 1.258, Global test loss: 2.203, Global test accuracy: 24.62
Round  39, Train loss: 1.062, Test loss: 1.725, Test accuracy: 33.59
Round  39, Global train loss: 1.062, Global test loss: 2.163, Global test accuracy: 22.03
Round  40, Train loss: 1.083, Test loss: 1.737, Test accuracy: 33.48
Round  40, Global train loss: 1.083, Global test loss: 2.091, Global test accuracy: 32.62
Round  41, Train loss: 1.175, Test loss: 1.771, Test accuracy: 33.89
Round  41, Global train loss: 1.175, Global test loss: 2.123, Global test accuracy: 25.11
Round  42, Train loss: 1.143, Test loss: 1.783, Test accuracy: 34.15
Round  42, Global train loss: 1.143, Global test loss: 2.113, Global test accuracy: 29.00
Round  43, Train loss: 1.411, Test loss: 1.792, Test accuracy: 34.14
Round  43, Global train loss: 1.411, Global test loss: 2.150, Global test accuracy: 21.57
Round  44, Train loss: 1.397, Test loss: 1.806, Test accuracy: 33.69
Round  44, Global train loss: 1.397, Global test loss: 2.188, Global test accuracy: 15.93
Round  45, Train loss: 1.223, Test loss: 1.808, Test accuracy: 34.20
Round  45, Global train loss: 1.223, Global test loss: 2.201, Global test accuracy: 27.03
Round  46, Train loss: 1.031, Test loss: 1.815, Test accuracy: 34.17
Round  46, Global train loss: 1.031, Global test loss: 2.201, Global test accuracy: 22.96
Round  47, Train loss: 1.164, Test loss: 1.846, Test accuracy: 33.27
Round  47, Global train loss: 1.164, Global test loss: 2.174, Global test accuracy: 21.51
Round  48, Train loss: 1.114, Test loss: 1.863, Test accuracy: 33.19
Round  48, Global train loss: 1.114, Global test loss: 2.149, Global test accuracy: 22.89
Round  49, Train loss: 1.011, Test loss: 1.914, Test accuracy: 33.44
Round  49, Global train loss: 1.011, Global test loss: 2.108, Global test accuracy: 23.13
Round  50, Train loss: 0.883, Test loss: 1.935, Test accuracy: 33.00
Round  50, Global train loss: 0.883, Global test loss: 2.187, Global test accuracy: 23.12
Round  51, Train loss: 0.901, Test loss: 1.957, Test accuracy: 33.54
Round  51, Global train loss: 0.901, Global test loss: 2.379, Global test accuracy: 21.47
Round  52, Train loss: 0.975, Test loss: 1.990, Test accuracy: 33.76
Round  52, Global train loss: 0.975, Global test loss: 2.108, Global test accuracy: 26.33
Round  53, Train loss: 0.757, Test loss: 2.001, Test accuracy: 33.45
Round  53, Global train loss: 0.757, Global test loss: 2.038, Global test accuracy: 30.05
Round  54, Train loss: 1.263, Test loss: 2.027, Test accuracy: 33.42
Round  54, Global train loss: 1.263, Global test loss: 2.174, Global test accuracy: 23.71
Round  55, Train loss: 1.125, Test loss: 2.037, Test accuracy: 33.94
Round  55, Global train loss: 1.125, Global test loss: 2.218, Global test accuracy: 18.13
Round  56, Train loss: 1.120, Test loss: 2.088, Test accuracy: 33.91
Round  56, Global train loss: 1.120, Global test loss: 2.236, Global test accuracy: 15.86
Round  57, Train loss: 0.829, Test loss: 2.119, Test accuracy: 33.79
Round  57, Global train loss: 0.829, Global test loss: 2.130, Global test accuracy: 25.25
Round  58, Train loss: 0.859, Test loss: 2.159, Test accuracy: 33.86
Round  58, Global train loss: 0.859, Global test loss: 2.196, Global test accuracy: 22.41
Round  59, Train loss: 0.797, Test loss: 2.221, Test accuracy: 33.14
Round  59, Global train loss: 0.797, Global test loss: 2.128, Global test accuracy: 23.84
Round  60, Train loss: 0.782, Test loss: 2.252, Test accuracy: 33.00
Round  60, Global train loss: 0.782, Global test loss: 2.126, Global test accuracy: 29.29
Round  61, Train loss: 0.734, Test loss: 2.305, Test accuracy: 33.27
Round  61, Global train loss: 0.734, Global test loss: 2.170, Global test accuracy: 26.72
Round  62, Train loss: 0.778, Test loss: 2.329, Test accuracy: 33.05
Round  62, Global train loss: 0.778, Global test loss: 2.127, Global test accuracy: 24.89
Round  63, Train loss: 0.739, Test loss: 2.379, Test accuracy: 32.71
Round  63, Global train loss: 0.739, Global test loss: 2.158, Global test accuracy: 23.80
Round  64, Train loss: 0.677, Test loss: 2.423, Test accuracy: 32.39
Round  64, Global train loss: 0.677, Global test loss: 2.149, Global test accuracy: 21.49
Round  65, Train loss: 1.059, Test loss: 2.440, Test accuracy: 32.08
Round  65, Global train loss: 1.059, Global test loss: 2.173, Global test accuracy: 22.12
Round  66, Train loss: 0.734, Test loss: 2.476, Test accuracy: 31.70
Round  66, Global train loss: 0.734, Global test loss: 2.116, Global test accuracy: 25.85
Round  67, Train loss: 0.831, Test loss: 2.485, Test accuracy: 31.86
Round  67, Global train loss: 0.831, Global test loss: 2.239, Global test accuracy: 17.71
Round  68, Train loss: 0.668, Test loss: 2.551, Test accuracy: 32.39
Round  68, Global train loss: 0.668, Global test loss: 2.244, Global test accuracy: 24.69
Round  69, Train loss: 0.588, Test loss: 2.615, Test accuracy: 32.70
Round  69, Global train loss: 0.588, Global test loss: 2.229, Global test accuracy: 20.63
Round  70, Train loss: 0.485, Test loss: 2.688, Test accuracy: 32.50
Round  70, Global train loss: 0.485, Global test loss: 2.086, Global test accuracy: 26.37
Round  71, Train loss: 0.470, Test loss: 2.666, Test accuracy: 32.76
Round  71, Global train loss: 0.470, Global test loss: 2.135, Global test accuracy: 25.00
Round  72, Train loss: 0.614, Test loss: 2.663, Test accuracy: 33.00
Round  72, Global train loss: 0.614, Global test loss: 2.203, Global test accuracy: 22.03
Round  73, Train loss: 0.741, Test loss: 2.658, Test accuracy: 33.77
Round  73, Global train loss: 0.741, Global test loss: 2.174, Global test accuracy: 22.74
Round  74, Train loss: 0.680, Test loss: 2.776, Test accuracy: 33.24
Round  74, Global train loss: 0.680, Global test loss: 2.222, Global test accuracy: 19.91
Round  75, Train loss: 0.339, Test loss: 2.860, Test accuracy: 32.20
Round  75, Global train loss: 0.339, Global test loss: 2.084, Global test accuracy: 28.14
Round  76, Train loss: 0.313, Test loss: 2.913, Test accuracy: 32.17
Round  76, Global train loss: 0.313, Global test loss: 2.095, Global test accuracy: 30.63
Round  77, Train loss: 0.492, Test loss: 2.959, Test accuracy: 31.85
Round  77, Global train loss: 0.492, Global test loss: 2.191, Global test accuracy: 23.83
Round  78, Train loss: 0.552, Test loss: 2.921, Test accuracy: 32.07
Round  78, Global train loss: 0.552, Global test loss: 2.194, Global test accuracy: 20.91
Round  79, Train loss: 0.707, Test loss: 2.944, Test accuracy: 32.60
Round  79, Global train loss: 0.707, Global test loss: 2.247, Global test accuracy: 21.55
Round  80, Train loss: 0.567, Test loss: 2.925, Test accuracy: 33.03
Round  80, Global train loss: 0.567, Global test loss: 2.190, Global test accuracy: 17.70
Round  81, Train loss: 0.491, Test loss: 3.029, Test accuracy: 32.37
Round  81, Global train loss: 0.491, Global test loss: 2.133, Global test accuracy: 23.11
Round  82, Train loss: 0.535, Test loss: 3.068, Test accuracy: 32.48
Round  82, Global train loss: 0.535, Global test loss: 2.132, Global test accuracy: 23.51
Round  83, Train loss: 0.586, Test loss: 3.076, Test accuracy: 32.82
Round  83, Global train loss: 0.586, Global test loss: 2.183, Global test accuracy: 22.90
Round  84, Train loss: 0.753, Test loss: 3.161, Test accuracy: 32.27
Round  84, Global train loss: 0.753, Global test loss: 2.240, Global test accuracy: 13.65
Round  85, Train loss: 0.446, Test loss: 3.191, Test accuracy: 32.75
Round  85, Global train loss: 0.446, Global test loss: 2.148, Global test accuracy: 24.92
Round  86, Train loss: 0.468, Test loss: 3.227, Test accuracy: 32.85
Round  86, Global train loss: 0.468, Global test loss: 2.190, Global test accuracy: 20.69
Round  87, Train loss: 0.544, Test loss: 3.223, Test accuracy: 32.33
Round  87, Global train loss: 0.544, Global test loss: 2.235, Global test accuracy: 18.34
Round  88, Train loss: 0.444, Test loss: 3.337, Test accuracy: 31.59
Round  88, Global train loss: 0.444, Global test loss: 2.223, Global test accuracy: 19.80
Round  89, Train loss: 0.347, Test loss: 3.400, Test accuracy: 31.61
Round  89, Global train loss: 0.347, Global test loss: 2.235, Global test accuracy: 20.53
Round  90, Train loss: 0.455, Test loss: 3.403, Test accuracy: 31.54
Round  90, Global train loss: 0.455, Global test loss: 2.193, Global test accuracy: 19.37
Round  91, Train loss: 0.453, Test loss: 3.493, Test accuracy: 31.45
Round  91, Global train loss: 0.453, Global test loss: 2.169, Global test accuracy: 17.07
Round  92, Train loss: 0.464, Test loss: 3.482, Test accuracy: 31.33
Round  92, Global train loss: 0.464, Global test loss: 2.183, Global test accuracy: 23.11
Round  93, Train loss: 0.354, Test loss: 3.437, Test accuracy: 31.57
Round  93, Global train loss: 0.354, Global test loss: 2.181, Global test accuracy: 23.17
Round  94, Train loss: 0.312, Test loss: 3.471, Test accuracy: 31.70
Round  94, Global train loss: 0.312, Global test loss: 2.198, Global test accuracy: 20.94
Round  95, Train loss: 0.330, Test loss: 3.560, Test accuracy: 31.51
Round  95, Global train loss: 0.330, Global test loss: 2.165, Global test accuracy: 20.72
Round  96, Train loss: 0.463, Test loss: 3.656, Test accuracy: 31.67
Round  96, Global train loss: 0.463, Global test loss: 2.228, Global test accuracy: 18.39
Round  97, Train loss: 0.285, Test loss: 3.676, Test accuracy: 32.57
Round  97, Global train loss: 0.285, Global test loss: 2.180, Global test accuracy: 21.63
Round  98, Train loss: 0.352, Test loss: 3.725, Test accuracy: 32.53
Round  98, Global train loss: 0.352, Global test loss: 2.195, Global test accuracy: 20.23
Round  99, Train loss: 0.401, Test loss: 3.783, Test accuracy: 32.18
Round  99, Global train loss: 0.401, Global test loss: 2.185, Global test accuracy: 22.18
Final Round, Train loss: 0.339, Test loss: 4.013, Test accuracy: 31.67
Final Round, Global train loss: 0.339, Global test loss: 2.185, Global test accuracy: 22.18
Average accuracy final 10 rounds: 31.805000000000003 

Average global accuracy final 10 rounds: 20.680999999999997 

1453.1910543441772
[1.374504566192627, 2.749009132385254, 3.8399465084075928, 4.930883884429932, 6.0227673053741455, 7.114650726318359, 8.20995044708252, 9.30525016784668, 10.460943460464478, 11.616636753082275, 12.779634952545166, 13.942633152008057, 15.111069440841675, 16.279505729675293, 17.450135707855225, 18.620765686035156, 19.784664154052734, 20.948562622070312, 22.11294460296631, 23.277326583862305, 24.439337253570557, 25.60134792327881, 26.754406690597534, 27.90746545791626, 29.072124242782593, 30.236783027648926, 31.398681640625, 32.560580253601074, 33.79034066200256, 35.02010107040405, 36.19609975814819, 37.372098445892334, 38.617433309555054, 39.86276817321777, 41.10938000679016, 42.35599184036255, 43.597915172576904, 44.83983850479126, 46.08232378959656, 47.324809074401855, 48.57050037384033, 49.81619167327881, 51.05902624130249, 52.30186080932617, 53.54349160194397, 54.78512239456177, 56.028390407562256, 57.271658420562744, 58.514031410217285, 59.756404399871826, 60.901646852493286, 62.046889305114746, 63.19167876243591, 64.33646821975708, 65.56923007965088, 66.80199193954468, 68.02588272094727, 69.24977350234985, 70.51485657691956, 71.77993965148926, 72.97202634811401, 74.16411304473877, 75.4710624217987, 76.77801179885864, 78.0101273059845, 79.24224281311035, 80.43292212486267, 81.62360143661499, 82.86266207695007, 84.10172271728516, 85.29168581962585, 86.48164892196655, 87.72581195831299, 88.96997499465942, 90.14428496360779, 91.31859493255615, 92.50372505187988, 93.68885517120361, 94.87654566764832, 96.06423616409302, 97.07267665863037, 98.08111715316772, 99.08908796310425, 100.09705877304077, 101.10436034202576, 102.11166191101074, 103.12154579162598, 104.13142967224121, 105.13869976997375, 106.1459698677063, 107.15455198287964, 108.16313409805298, 109.17437386512756, 110.18561363220215, 111.19529318809509, 112.20497274398804, 113.31528878211975, 114.42560482025146, 115.58193302154541, 116.73826122283936, 117.89512085914612, 119.05198049545288, 120.22076749801636, 121.38955450057983, 122.55336618423462, 123.7171778678894, 124.87791442871094, 126.03865098953247, 127.05720543861389, 128.0757598876953, 129.09419202804565, 130.112624168396, 131.1277995109558, 132.14297485351562, 133.30493640899658, 134.46689796447754, 135.65921831130981, 136.8515386581421, 138.0368525981903, 139.22216653823853, 140.41512656211853, 141.60808658599854, 142.73378252983093, 143.85947847366333, 144.9671905040741, 146.07490253448486, 147.17760014533997, 148.28029775619507, 149.38814759254456, 150.49599742889404, 151.60112595558167, 152.7062544822693, 153.81206250190735, 154.9178705215454, 156.025573015213, 157.13327550888062, 158.2444944381714, 159.35571336746216, 160.4641396999359, 161.57256603240967, 162.68660378456116, 163.80064153671265, 164.82024002075195, 165.83983850479126, 166.86251711845398, 167.8851957321167, 168.90571641921997, 169.92623710632324, 171.0246388912201, 172.12304067611694, 173.27459502220154, 174.42614936828613, 175.52247881889343, 176.61880826950073, 177.7250919342041, 178.83137559890747, 179.94204473495483, 181.0527138710022, 182.15355396270752, 183.25439405441284, 184.35892724990845, 185.46346044540405, 186.5650508403778, 187.66664123535156, 188.76971125602722, 189.87278127670288, 190.97230553627014, 192.0718297958374, 193.1737105846405, 194.2755913734436, 195.37172746658325, 196.4678635597229, 197.56976985931396, 198.67167615890503, 199.77170848846436, 200.87174081802368, 201.97253227233887, 203.07332372665405, 204.17939352989197, 205.28546333312988, 206.46950602531433, 207.65354871749878, 208.83322548866272, 210.01290225982666, 211.20928502082825, 212.40566778182983, 213.5895402431488, 214.77341270446777, 215.95690822601318, 217.1404037475586, 218.31689405441284, 219.4933843612671, 220.6755886077881, 221.85779285430908, 223.0365605354309, 224.21532821655273, 225.39462113380432, 226.5739140510559, 227.76362586021423, 228.95333766937256, 231.35395097732544, 233.75456428527832]
[15.72, 15.72, 19.84, 19.84, 26.33, 26.33, 24.74, 24.74, 27.09, 27.09, 28.32, 28.32, 28.88, 28.88, 31.63, 31.63, 31.41, 31.41, 32.29, 32.29, 33.29, 33.29, 33.79, 33.79, 34.3, 34.3, 34.34, 34.34, 34.41, 34.41, 35.46, 35.46, 34.62, 34.62, 35.39, 35.39, 35.21, 35.21, 35.26, 35.26, 35.01, 35.01, 34.79, 34.79, 35.47, 35.47, 34.8, 34.8, 34.85, 34.85, 34.83, 34.83, 34.53, 34.53, 34.49, 34.49, 34.32, 34.32, 34.23, 34.23, 34.61, 34.61, 34.79, 34.79, 35.5, 35.5, 35.05, 35.05, 34.05, 34.05, 34.13, 34.13, 33.51, 33.51, 33.9, 33.9, 33.58, 33.58, 33.59, 33.59, 33.48, 33.48, 33.89, 33.89, 34.15, 34.15, 34.14, 34.14, 33.69, 33.69, 34.2, 34.2, 34.17, 34.17, 33.27, 33.27, 33.19, 33.19, 33.44, 33.44, 33.0, 33.0, 33.54, 33.54, 33.76, 33.76, 33.45, 33.45, 33.42, 33.42, 33.94, 33.94, 33.91, 33.91, 33.79, 33.79, 33.86, 33.86, 33.14, 33.14, 33.0, 33.0, 33.27, 33.27, 33.05, 33.05, 32.71, 32.71, 32.39, 32.39, 32.08, 32.08, 31.7, 31.7, 31.86, 31.86, 32.39, 32.39, 32.7, 32.7, 32.5, 32.5, 32.76, 32.76, 33.0, 33.0, 33.77, 33.77, 33.24, 33.24, 32.2, 32.2, 32.17, 32.17, 31.85, 31.85, 32.07, 32.07, 32.6, 32.6, 33.03, 33.03, 32.37, 32.37, 32.48, 32.48, 32.82, 32.82, 32.27, 32.27, 32.75, 32.75, 32.85, 32.85, 32.33, 32.33, 31.59, 31.59, 31.61, 31.61, 31.54, 31.54, 31.45, 31.45, 31.33, 31.33, 31.57, 31.57, 31.7, 31.7, 31.51, 31.51, 31.67, 31.67, 32.57, 32.57, 32.53, 32.53, 32.18, 32.18, 31.67, 31.67]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.8 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 14, noise    level: 0.8000 
   Client 17, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 15, noise    level: 0.8000 
   Client 10, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 12, noise    level: 0.8000 
   Client 19, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 16, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 18, noise    level: 0.8000 
   Client 13, noise    level: 0.8000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.685, Test loss: 2.017, Test accuracy: 25.25
Round   0, Global train loss: 1.685, Global test loss: 2.203, Global test accuracy: 21.04
Round   1, Train loss: 1.629, Test loss: 1.783, Test accuracy: 34.08
Round   1, Global train loss: 1.629, Global test loss: 2.076, Global test accuracy: 27.35
Round   2, Train loss: 1.367, Test loss: 1.550, Test accuracy: 40.93
Round   2, Global train loss: 1.367, Global test loss: 1.949, Global test accuracy: 31.95
Round   3, Train loss: 1.304, Test loss: 1.514, Test accuracy: 42.65
Round   3, Global train loss: 1.304, Global test loss: 1.885, Global test accuracy: 32.95
Round   4, Train loss: 1.250, Test loss: 1.470, Test accuracy: 46.02
Round   4, Global train loss: 1.250, Global test loss: 1.794, Global test accuracy: 39.84
Round   5, Train loss: 1.214, Test loss: 1.331, Test accuracy: 49.68
Round   5, Global train loss: 1.214, Global test loss: 1.676, Global test accuracy: 39.37
Round   6, Train loss: 1.103, Test loss: 1.384, Test accuracy: 50.31
Round   6, Global train loss: 1.103, Global test loss: 1.953, Global test accuracy: 40.96
Round   7, Train loss: 1.244, Test loss: 1.279, Test accuracy: 53.11
Round   7, Global train loss: 1.244, Global test loss: 1.628, Global test accuracy: 44.67
Round   8, Train loss: 1.128, Test loss: 1.246, Test accuracy: 54.42
Round   8, Global train loss: 1.128, Global test loss: 1.875, Global test accuracy: 36.05
Round   9, Train loss: 1.207, Test loss: 1.273, Test accuracy: 55.15
Round   9, Global train loss: 1.207, Global test loss: 1.846, Global test accuracy: 41.14
Round  10, Train loss: 1.094, Test loss: 1.163, Test accuracy: 57.44
Round  10, Global train loss: 1.094, Global test loss: 1.807, Global test accuracy: 38.60
Round  11, Train loss: 0.978, Test loss: 1.150, Test accuracy: 57.97
Round  11, Global train loss: 0.978, Global test loss: 1.743, Global test accuracy: 44.83
Round  12, Train loss: 1.142, Test loss: 1.148, Test accuracy: 57.78
Round  12, Global train loss: 1.142, Global test loss: 1.484, Global test accuracy: 48.06
Round  13, Train loss: 1.152, Test loss: 1.140, Test accuracy: 58.42
Round  13, Global train loss: 1.152, Global test loss: 1.489, Global test accuracy: 47.10
Round  14, Train loss: 1.043, Test loss: 1.126, Test accuracy: 58.87
Round  14, Global train loss: 1.043, Global test loss: 1.660, Global test accuracy: 42.05
Round  15, Train loss: 1.031, Test loss: 1.115, Test accuracy: 59.15
Round  15, Global train loss: 1.031, Global test loss: 1.464, Global test accuracy: 48.40
Round  16, Train loss: 1.018, Test loss: 1.107, Test accuracy: 59.36
Round  16, Global train loss: 1.018, Global test loss: 1.502, Global test accuracy: 49.55
Round  17, Train loss: 1.017, Test loss: 1.100, Test accuracy: 59.82
Round  17, Global train loss: 1.017, Global test loss: 1.550, Global test accuracy: 46.49
Round  18, Train loss: 1.042, Test loss: 1.093, Test accuracy: 60.26
Round  18, Global train loss: 1.042, Global test loss: 1.478, Global test accuracy: 49.18
Round  19, Train loss: 0.913, Test loss: 1.091, Test accuracy: 60.67
Round  19, Global train loss: 0.913, Global test loss: 1.381, Global test accuracy: 51.52
Round  20, Train loss: 0.988, Test loss: 1.072, Test accuracy: 61.93
Round  20, Global train loss: 0.988, Global test loss: 1.335, Global test accuracy: 52.28
Round  21, Train loss: 0.998, Test loss: 1.084, Test accuracy: 61.18
Round  21, Global train loss: 0.998, Global test loss: 1.333, Global test accuracy: 52.78
Round  22, Train loss: 0.893, Test loss: 1.095, Test accuracy: 60.71
Round  22, Global train loss: 0.893, Global test loss: 1.371, Global test accuracy: 53.67
Round  23, Train loss: 0.827, Test loss: 1.084, Test accuracy: 61.05
Round  23, Global train loss: 0.827, Global test loss: 1.400, Global test accuracy: 52.38
Round  24, Train loss: 0.852, Test loss: 1.071, Test accuracy: 61.33
Round  24, Global train loss: 0.852, Global test loss: 1.379, Global test accuracy: 51.29
Round  25, Train loss: 0.783, Test loss: 1.071, Test accuracy: 61.56
Round  25, Global train loss: 0.783, Global test loss: 1.426, Global test accuracy: 52.19
Round  26, Train loss: 0.767, Test loss: 1.081, Test accuracy: 61.50
Round  26, Global train loss: 0.767, Global test loss: 1.441, Global test accuracy: 50.90
Round  27, Train loss: 0.982, Test loss: 1.081, Test accuracy: 61.50
Round  27, Global train loss: 0.982, Global test loss: 1.294, Global test accuracy: 54.70
Round  28, Train loss: 0.740, Test loss: 1.084, Test accuracy: 61.52
Round  28, Global train loss: 0.740, Global test loss: 1.371, Global test accuracy: 54.11
Round  29, Train loss: 0.852, Test loss: 1.072, Test accuracy: 61.81
Round  29, Global train loss: 0.852, Global test loss: 1.377, Global test accuracy: 52.45
Round  30, Train loss: 0.895, Test loss: 1.069, Test accuracy: 62.03
Round  30, Global train loss: 0.895, Global test loss: 1.334, Global test accuracy: 54.06
Round  31, Train loss: 0.873, Test loss: 1.057, Test accuracy: 62.07
Round  31, Global train loss: 0.873, Global test loss: 1.433, Global test accuracy: 51.95
Round  32, Train loss: 0.812, Test loss: 1.090, Test accuracy: 61.42
Round  32, Global train loss: 0.812, Global test loss: 1.329, Global test accuracy: 54.12
Round  33, Train loss: 0.760, Test loss: 1.080, Test accuracy: 61.89
Round  33, Global train loss: 0.760, Global test loss: 1.395, Global test accuracy: 53.03
Round  34, Train loss: 0.798, Test loss: 1.066, Test accuracy: 62.48
Round  34, Global train loss: 0.798, Global test loss: 1.244, Global test accuracy: 56.97
Round  35, Train loss: 0.844, Test loss: 1.079, Test accuracy: 62.54
Round  35, Global train loss: 0.844, Global test loss: 1.300, Global test accuracy: 55.24
Round  36, Train loss: 0.858, Test loss: 1.086, Test accuracy: 62.30
Round  36, Global train loss: 0.858, Global test loss: 1.462, Global test accuracy: 51.63
Round  37, Train loss: 0.875, Test loss: 1.075, Test accuracy: 63.14
Round  37, Global train loss: 0.875, Global test loss: 1.267, Global test accuracy: 56.83
Round  38, Train loss: 0.709, Test loss: 1.051, Test accuracy: 63.36
Round  38, Global train loss: 0.709, Global test loss: 1.375, Global test accuracy: 55.41
Round  39, Train loss: 0.769, Test loss: 1.050, Test accuracy: 63.45
Round  39, Global train loss: 0.769, Global test loss: 1.359, Global test accuracy: 55.27
Round  40, Train loss: 0.835, Test loss: 1.026, Test accuracy: 64.55
Round  40, Global train loss: 0.835, Global test loss: 1.295, Global test accuracy: 55.75
Round  41, Train loss: 0.765, Test loss: 1.042, Test accuracy: 64.09
Round  41, Global train loss: 0.765, Global test loss: 1.252, Global test accuracy: 57.96
Round  42, Train loss: 0.811, Test loss: 1.058, Test accuracy: 63.39
Round  42, Global train loss: 0.811, Global test loss: 1.298, Global test accuracy: 55.54
Round  43, Train loss: 0.899, Test loss: 1.051, Test accuracy: 63.60
Round  43, Global train loss: 0.899, Global test loss: 1.251, Global test accuracy: 57.04
Round  44, Train loss: 0.794, Test loss: 1.054, Test accuracy: 63.53
Round  44, Global train loss: 0.794, Global test loss: 1.351, Global test accuracy: 55.00
Round  45, Train loss: 0.704, Test loss: 1.041, Test accuracy: 64.01
Round  45, Global train loss: 0.704, Global test loss: 1.431, Global test accuracy: 54.25
Round  46, Train loss: 0.781, Test loss: 1.053, Test accuracy: 63.88
Round  46, Global train loss: 0.781, Global test loss: 1.491, Global test accuracy: 53.28
Round  47, Train loss: 0.642, Test loss: 1.056, Test accuracy: 64.05
Round  47, Global train loss: 0.642, Global test loss: 1.463, Global test accuracy: 52.53
Round  48, Train loss: 0.702, Test loss: 1.069, Test accuracy: 63.53
Round  48, Global train loss: 0.702, Global test loss: 1.491, Global test accuracy: 51.82
Round  49, Train loss: 0.728, Test loss: 1.061, Test accuracy: 63.96
Round  49, Global train loss: 0.728, Global test loss: 1.399, Global test accuracy: 54.27
Round  50, Train loss: 0.742, Test loss: 1.098, Test accuracy: 63.50
Round  50, Global train loss: 0.742, Global test loss: 1.372, Global test accuracy: 55.50
Round  51, Train loss: 0.666, Test loss: 1.081, Test accuracy: 64.17
Round  51, Global train loss: 0.666, Global test loss: 1.814, Global test accuracy: 50.64
Round  52, Train loss: 0.624, Test loss: 1.103, Test accuracy: 63.65
Round  52, Global train loss: 0.624, Global test loss: 1.349, Global test accuracy: 56.37
Round  53, Train loss: 0.638, Test loss: 1.095, Test accuracy: 63.88
Round  53, Global train loss: 0.638, Global test loss: 1.361, Global test accuracy: 56.54
Round  54, Train loss: 0.782, Test loss: 1.109, Test accuracy: 63.91
Round  54, Global train loss: 0.782, Global test loss: 1.239, Global test accuracy: 58.51
Round  55, Train loss: 0.728, Test loss: 1.129, Test accuracy: 63.80
Round  55, Global train loss: 0.728, Global test loss: 1.294, Global test accuracy: 56.78
Round  56, Train loss: 0.712, Test loss: 1.139, Test accuracy: 63.45
Round  56, Global train loss: 0.712, Global test loss: 1.438, Global test accuracy: 52.42
Round  57, Train loss: 0.630, Test loss: 1.164, Test accuracy: 63.26
Round  57, Global train loss: 0.630, Global test loss: 1.466, Global test accuracy: 55.47
Round  58, Train loss: 0.570, Test loss: 1.151, Test accuracy: 63.27
Round  58, Global train loss: 0.570, Global test loss: 1.598, Global test accuracy: 53.06
Round  59, Train loss: 0.631, Test loss: 1.155, Test accuracy: 63.14
Round  59, Global train loss: 0.631, Global test loss: 1.382, Global test accuracy: 55.58
Round  60, Train loss: 0.514, Test loss: 1.157, Test accuracy: 63.12
Round  60, Global train loss: 0.514, Global test loss: 1.505, Global test accuracy: 54.88
Round  61, Train loss: 0.661, Test loss: 1.145, Test accuracy: 63.71
Round  61, Global train loss: 0.661, Global test loss: 1.351, Global test accuracy: 56.72
Round  62, Train loss: 0.528, Test loss: 1.139, Test accuracy: 64.11
Round  62, Global train loss: 0.528, Global test loss: 1.384, Global test accuracy: 57.18
Round  63, Train loss: 0.644, Test loss: 1.152, Test accuracy: 64.58
Round  63, Global train loss: 0.644, Global test loss: 1.298, Global test accuracy: 57.86
Round  64, Train loss: 0.627, Test loss: 1.167, Test accuracy: 63.91
Round  64, Global train loss: 0.627, Global test loss: 1.246, Global test accuracy: 59.35
Round  65, Train loss: 0.670, Test loss: 1.165, Test accuracy: 64.08
Round  65, Global train loss: 0.670, Global test loss: 1.332, Global test accuracy: 57.39
Round  66, Train loss: 0.605, Test loss: 1.179, Test accuracy: 64.29
Round  66, Global train loss: 0.605, Global test loss: 1.476, Global test accuracy: 54.15
Round  67, Train loss: 0.636, Test loss: 1.168, Test accuracy: 64.09
Round  67, Global train loss: 0.636, Global test loss: 1.575, Global test accuracy: 53.75
Round  68, Train loss: 0.562, Test loss: 1.194, Test accuracy: 64.37
Round  68, Global train loss: 0.562, Global test loss: 1.583, Global test accuracy: 55.00
Round  69, Train loss: 0.552, Test loss: 1.193, Test accuracy: 64.19
Round  69, Global train loss: 0.552, Global test loss: 1.536, Global test accuracy: 54.40
Round  70, Train loss: 0.550, Test loss: 1.170, Test accuracy: 64.48
Round  70, Global train loss: 0.550, Global test loss: 1.359, Global test accuracy: 57.81
Round  71, Train loss: 0.533, Test loss: 1.193, Test accuracy: 64.77
Round  71, Global train loss: 0.533, Global test loss: 1.642, Global test accuracy: 53.51
Round  72, Train loss: 0.621, Test loss: 1.191, Test accuracy: 65.02
Round  72, Global train loss: 0.621, Global test loss: 1.387, Global test accuracy: 56.87
Round  73, Train loss: 0.517, Test loss: 1.207, Test accuracy: 64.89
Round  73, Global train loss: 0.517, Global test loss: 1.383, Global test accuracy: 58.11
Round  74, Train loss: 0.577, Test loss: 1.212, Test accuracy: 64.53
Round  74, Global train loss: 0.577, Global test loss: 1.299, Global test accuracy: 59.74
Round  75, Train loss: 0.493, Test loss: 1.206, Test accuracy: 64.58
Round  75, Global train loss: 0.493, Global test loss: 1.542, Global test accuracy: 55.18
Round  76, Train loss: 0.474, Test loss: 1.237, Test accuracy: 63.97
Round  76, Global train loss: 0.474, Global test loss: 1.459, Global test accuracy: 57.44
Round  77, Train loss: 0.494, Test loss: 1.262, Test accuracy: 63.79
Round  77, Global train loss: 0.494, Global test loss: 1.530, Global test accuracy: 55.79
Round  78, Train loss: 0.519, Test loss: 1.261, Test accuracy: 64.20
Round  78, Global train loss: 0.519, Global test loss: 1.507, Global test accuracy: 57.50
Round  79, Train loss: 0.497, Test loss: 1.265, Test accuracy: 64.14
Round  79, Global train loss: 0.497, Global test loss: 1.660, Global test accuracy: 53.62
Round  80, Train loss: 0.615, Test loss: 1.237, Test accuracy: 64.86
Round  80, Global train loss: 0.615, Global test loss: 1.417, Global test accuracy: 56.56
Round  81, Train loss: 0.504, Test loss: 1.259, Test accuracy: 64.44
Round  81, Global train loss: 0.504, Global test loss: 1.503, Global test accuracy: 54.81
Round  82, Train loss: 0.532, Test loss: 1.270, Test accuracy: 64.61
Round  82, Global train loss: 0.532, Global test loss: 1.462, Global test accuracy: 56.80
Round  83, Train loss: 0.514, Test loss: 1.252, Test accuracy: 64.71
Round  83, Global train loss: 0.514, Global test loss: 1.563, Global test accuracy: 54.97
Round  84, Train loss: 0.398, Test loss: 1.257, Test accuracy: 64.96
Round  84, Global train loss: 0.398, Global test loss: 1.539, Global test accuracy: 56.60
Round  85, Train loss: 0.485, Test loss: 1.252, Test accuracy: 64.69
Round  85, Global train loss: 0.485, Global test loss: 1.320, Global test accuracy: 59.61
Round  86, Train loss: 0.445, Test loss: 1.241, Test accuracy: 65.09
Round  86, Global train loss: 0.445, Global test loss: 1.573, Global test accuracy: 55.29
Round  87, Train loss: 0.433, Test loss: 1.215, Test accuracy: 65.86
Round  87, Global train loss: 0.433, Global test loss: 1.350, Global test accuracy: 60.67
Round  88, Train loss: 0.513, Test loss: 1.221, Test accuracy: 65.79
Round  88, Global train loss: 0.513, Global test loss: 1.346, Global test accuracy: 59.37
Round  89, Train loss: 0.491, Test loss: 1.214, Test accuracy: 65.76
Round  89, Global train loss: 0.491, Global test loss: 1.668, Global test accuracy: 53.23
Round  90, Train loss: 0.518, Test loss: 1.202, Test accuracy: 65.94
Round  90, Global train loss: 0.518, Global test loss: 1.473, Global test accuracy: 56.07
Round  91, Train loss: 0.538, Test loss: 1.218, Test accuracy: 65.88
Round  91, Global train loss: 0.538, Global test loss: 1.386, Global test accuracy: 57.86
Round  92, Train loss: 0.496, Test loss: 1.247, Test accuracy: 65.42
Round  92, Global train loss: 0.496, Global test loss: 1.405, Global test accuracy: 58.21
Round  93, Train loss: 0.430, Test loss: 1.282, Test accuracy: 65.01
Round  93, Global train loss: 0.430, Global test loss: 1.414, Global test accuracy: 58.74
Round  94, Train loss: 0.359, Test loss: 1.291, Test accuracy: 65.09
Round  94, Global train loss: 0.359, Global test loss: 1.634, Global test accuracy: 57.85
Round  95, Train loss: 0.405, Test loss: 1.277, Test accuracy: 65.32
Round  95, Global train loss: 0.405, Global test loss: 1.466, Global test accuracy: 59.00
Round  96, Train loss: 0.368, Test loss: 1.305, Test accuracy: 64.31
Round  96, Global train loss: 0.368, Global test loss: 1.671, Global test accuracy: 56.36
Round  97, Train loss: 0.428, Test loss: 1.301, Test accuracy: 64.90
Round  97, Global train loss: 0.428, Global test loss: 1.483, Global test accuracy: 57.96
Round  98, Train loss: 0.388, Test loss: 1.295, Test accuracy: 65.02
Round  98, Global train loss: 0.388, Global test loss: 1.572, Global test accuracy: 56.39
Round  99, Train loss: 0.460, Test loss: 1.314, Test accuracy: 65.14
Round  99, Global train loss: 0.460, Global test loss: 1.548, Global test accuracy: 56.56
Final Round, Train loss: 0.356, Test loss: 1.433, Test accuracy: 65.09
Final Round, Global train loss: 0.356, Global test loss: 1.548, Global test accuracy: 56.56
Average accuracy final 10 rounds: 65.20299999999999 

Average global accuracy final 10 rounds: 57.50000000000001 

1407.5259339809418
[1.3899297714233398, 2.7798595428466797, 3.911375045776367, 5.042890548706055, 6.1667397022247314, 7.290588855743408, 8.423930406570435, 9.557271957397461, 10.68643856048584, 11.815605163574219, 12.944155931472778, 14.072706699371338, 15.203618288040161, 16.334529876708984, 17.467550039291382, 18.60057020187378, 19.728333473205566, 20.856096744537354, 21.981711387634277, 23.1073260307312, 24.23594570159912, 25.36456537246704, 26.492329835891724, 27.620094299316406, 28.746734857559204, 29.873375415802002, 30.99712824821472, 32.12088108062744, 33.2501277923584, 34.379374504089355, 35.445839643478394, 36.51230478286743, 37.68244194984436, 38.85257911682129, 40.05483651161194, 41.25709390640259, 42.460002183914185, 43.66291046142578, 44.826788902282715, 45.99066734313965, 47.20214128494263, 48.413615226745605, 49.62763810157776, 50.84166097640991, 51.88813257217407, 52.93460416793823, 54.208303451538086, 55.48200273513794, 56.64512276649475, 57.80824279785156, 59.05561566352844, 60.30298852920532, 61.41417384147644, 62.52535915374756, 63.95867943763733, 65.3919997215271, 66.59266090393066, 67.79332208633423, 69.06649327278137, 70.33966445922852, 71.73709344863892, 73.13452243804932, 74.25793671607971, 75.38135099411011, 76.58378767967224, 77.78622436523438, 79.2649462223053, 80.74366807937622, 81.98646235466003, 83.22925662994385, 84.48998761177063, 85.75071859359741, 86.85742020606995, 87.96412181854248, 89.17170262336731, 90.37928342819214, 91.49655842781067, 92.6138334274292, 93.66514873504639, 94.71646404266357, 95.77099275588989, 96.82552146911621, 97.87329339981079, 98.92106533050537, 100.0184736251831, 101.11588191986084, 102.18119931221008, 103.24651670455933, 104.29999303817749, 105.35346937179565, 106.42596769332886, 107.49846601486206, 108.56135535240173, 109.6242446899414, 110.59203815460205, 111.5598316192627, 112.52858638763428, 113.49734115600586, 114.4632179737091, 115.42909479141235, 116.39220905303955, 117.35532331466675, 118.32456874847412, 119.2938141822815, 120.2555181980133, 121.21722221374512, 122.17916750907898, 123.14111280441284, 124.10333180427551, 125.06555080413818, 126.02894854545593, 126.99234628677368, 127.95760893821716, 128.92287158966064, 129.8892376422882, 130.85560369491577, 131.8181664943695, 132.78072929382324, 133.8327751159668, 134.88482093811035, 135.939067363739, 136.99331378936768, 138.04387784004211, 139.09444189071655, 140.15114879608154, 141.20785570144653, 142.26438331604004, 143.32091093063354, 144.4429841041565, 145.56505727767944, 146.69262075424194, 147.82018423080444, 148.95311617851257, 150.0860481262207, 151.21521878242493, 152.34438943862915, 153.48009967803955, 154.61580991744995, 155.7377426624298, 156.85967540740967, 157.9900460243225, 159.12041664123535, 160.3473744392395, 161.57433223724365, 162.72311186790466, 163.87189149856567, 164.99496841430664, 166.1180453300476, 167.33785319328308, 168.55766105651855, 169.82930779457092, 171.1009545326233, 172.22989177703857, 173.35882902145386, 174.48004388809204, 175.60125875473022, 176.65805339813232, 177.71484804153442, 178.85117268562317, 179.9874973297119, 181.08620381355286, 182.1849102973938, 183.24883437156677, 184.31275844573975, 185.40528106689453, 186.49780368804932, 187.57728004455566, 188.656756401062, 189.8121497631073, 190.9675431251526, 192.07410550117493, 193.18066787719727, 194.2512834072113, 195.32189893722534, 196.37484502792358, 197.42779111862183, 198.39569902420044, 199.36360692977905, 200.32961797714233, 201.29562902450562, 202.26368474960327, 203.23174047470093, 204.19550943374634, 205.15927839279175, 206.12531280517578, 207.09134721755981, 208.05572152137756, 209.0200958251953, 209.98803853988647, 210.95598125457764, 211.92056369781494, 212.88514614105225, 213.8537414073944, 214.82233667373657, 215.78564405441284, 216.7489514350891, 217.71135711669922, 218.67376279830933, 219.63463258743286, 220.5955023765564, 222.5275535583496, 224.45960474014282]
[25.25, 25.25, 34.08, 34.08, 40.93, 40.93, 42.65, 42.65, 46.02, 46.02, 49.68, 49.68, 50.31, 50.31, 53.11, 53.11, 54.42, 54.42, 55.15, 55.15, 57.44, 57.44, 57.97, 57.97, 57.78, 57.78, 58.42, 58.42, 58.87, 58.87, 59.15, 59.15, 59.36, 59.36, 59.82, 59.82, 60.26, 60.26, 60.67, 60.67, 61.93, 61.93, 61.18, 61.18, 60.71, 60.71, 61.05, 61.05, 61.33, 61.33, 61.56, 61.56, 61.5, 61.5, 61.5, 61.5, 61.52, 61.52, 61.81, 61.81, 62.03, 62.03, 62.07, 62.07, 61.42, 61.42, 61.89, 61.89, 62.48, 62.48, 62.54, 62.54, 62.3, 62.3, 63.14, 63.14, 63.36, 63.36, 63.45, 63.45, 64.55, 64.55, 64.09, 64.09, 63.39, 63.39, 63.6, 63.6, 63.53, 63.53, 64.01, 64.01, 63.88, 63.88, 64.05, 64.05, 63.53, 63.53, 63.96, 63.96, 63.5, 63.5, 64.17, 64.17, 63.65, 63.65, 63.88, 63.88, 63.91, 63.91, 63.8, 63.8, 63.45, 63.45, 63.26, 63.26, 63.27, 63.27, 63.14, 63.14, 63.12, 63.12, 63.71, 63.71, 64.11, 64.11, 64.58, 64.58, 63.91, 63.91, 64.08, 64.08, 64.29, 64.29, 64.09, 64.09, 64.37, 64.37, 64.19, 64.19, 64.48, 64.48, 64.77, 64.77, 65.02, 65.02, 64.89, 64.89, 64.53, 64.53, 64.58, 64.58, 63.97, 63.97, 63.79, 63.79, 64.2, 64.2, 64.14, 64.14, 64.86, 64.86, 64.44, 64.44, 64.61, 64.61, 64.71, 64.71, 64.96, 64.96, 64.69, 64.69, 65.09, 65.09, 65.86, 65.86, 65.79, 65.79, 65.76, 65.76, 65.94, 65.94, 65.88, 65.88, 65.42, 65.42, 65.01, 65.01, 65.09, 65.09, 65.32, 65.32, 64.31, 64.31, 64.9, 64.9, 65.02, 65.02, 65.14, 65.14, 65.09, 65.09]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.8 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 8, noise    level: 0.8000 
   Client 13, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
   Client 16, noise    level: 0.8000 
   Client 14, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 11, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 17, noise    level: 0.8000 
   Client 15, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.754, Test loss: 2.106, Test accuracy: 16.44
Round   0, Global train loss: 1.754, Global test loss: 2.277, Global test accuracy: 11.28
Round   1, Train loss: 1.608, Test loss: 1.843, Test accuracy: 32.24
Round   1, Global train loss: 1.608, Global test loss: 2.130, Global test accuracy: 25.30
Round   2, Train loss: 1.457, Test loss: 1.612, Test accuracy: 39.08
Round   2, Global train loss: 1.457, Global test loss: 1.944, Global test accuracy: 30.35
Round   3, Train loss: 1.395, Test loss: 1.562, Test accuracy: 40.76
Round   3, Global train loss: 1.395, Global test loss: 1.874, Global test accuracy: 35.76
Round   4, Train loss: 1.410, Test loss: 1.478, Test accuracy: 43.59
Round   4, Global train loss: 1.410, Global test loss: 1.807, Global test accuracy: 37.83
Round   5, Train loss: 1.421, Test loss: 1.368, Test accuracy: 47.46
Round   5, Global train loss: 1.421, Global test loss: 1.715, Global test accuracy: 39.02
Round   6, Train loss: 1.230, Test loss: 1.400, Test accuracy: 48.28
Round   6, Global train loss: 1.230, Global test loss: 1.920, Global test accuracy: 38.40
Round   7, Train loss: 1.230, Test loss: 1.312, Test accuracy: 50.20
Round   7, Global train loss: 1.230, Global test loss: 1.688, Global test accuracy: 42.26
Round   8, Train loss: 1.251, Test loss: 1.281, Test accuracy: 52.78
Round   8, Global train loss: 1.251, Global test loss: 1.753, Global test accuracy: 38.12
Round   9, Train loss: 1.151, Test loss: 1.284, Test accuracy: 53.83
Round   9, Global train loss: 1.151, Global test loss: 1.795, Global test accuracy: 40.95
Round  10, Train loss: 1.172, Test loss: 1.187, Test accuracy: 55.71
Round  10, Global train loss: 1.172, Global test loss: 1.789, Global test accuracy: 37.51
Round  11, Train loss: 1.252, Test loss: 1.163, Test accuracy: 56.77
Round  11, Global train loss: 1.252, Global test loss: 1.652, Global test accuracy: 44.73
Round  12, Train loss: 1.173, Test loss: 1.168, Test accuracy: 56.51
Round  12, Global train loss: 1.173, Global test loss: 1.527, Global test accuracy: 46.30
Round  13, Train loss: 1.115, Test loss: 1.149, Test accuracy: 57.03
Round  13, Global train loss: 1.115, Global test loss: 1.472, Global test accuracy: 47.78
Round  14, Train loss: 1.159, Test loss: 1.145, Test accuracy: 57.81
Round  14, Global train loss: 1.159, Global test loss: 1.595, Global test accuracy: 42.88
Round  15, Train loss: 1.172, Test loss: 1.118, Test accuracy: 59.02
Round  15, Global train loss: 1.172, Global test loss: 1.421, Global test accuracy: 51.23
Round  16, Train loss: 1.063, Test loss: 1.102, Test accuracy: 59.35
Round  16, Global train loss: 1.063, Global test loss: 1.459, Global test accuracy: 47.95
Round  17, Train loss: 1.043, Test loss: 1.100, Test accuracy: 59.93
Round  17, Global train loss: 1.043, Global test loss: 1.484, Global test accuracy: 47.14
Round  18, Train loss: 1.067, Test loss: 1.096, Test accuracy: 59.86
Round  18, Global train loss: 1.067, Global test loss: 1.482, Global test accuracy: 46.94
Round  19, Train loss: 1.042, Test loss: 1.087, Test accuracy: 60.24
Round  19, Global train loss: 1.042, Global test loss: 1.368, Global test accuracy: 52.11
Round  20, Train loss: 1.071, Test loss: 1.098, Test accuracy: 60.15
Round  20, Global train loss: 1.071, Global test loss: 1.363, Global test accuracy: 52.70
Round  21, Train loss: 1.021, Test loss: 1.114, Test accuracy: 59.65
Round  21, Global train loss: 1.021, Global test loss: 1.343, Global test accuracy: 53.59
Round  22, Train loss: 1.091, Test loss: 1.108, Test accuracy: 59.96
Round  22, Global train loss: 1.091, Global test loss: 1.408, Global test accuracy: 52.75
Round  23, Train loss: 0.966, Test loss: 1.099, Test accuracy: 60.15
Round  23, Global train loss: 0.966, Global test loss: 1.353, Global test accuracy: 53.86
Round  24, Train loss: 0.955, Test loss: 1.056, Test accuracy: 61.65
Round  24, Global train loss: 0.955, Global test loss: 1.374, Global test accuracy: 52.17
Round  25, Train loss: 1.003, Test loss: 1.054, Test accuracy: 61.61
Round  25, Global train loss: 1.003, Global test loss: 1.394, Global test accuracy: 52.13
Round  26, Train loss: 1.033, Test loss: 1.062, Test accuracy: 61.71
Round  26, Global train loss: 1.033, Global test loss: 1.469, Global test accuracy: 50.33
Round  27, Train loss: 0.998, Test loss: 1.060, Test accuracy: 61.92
Round  27, Global train loss: 0.998, Global test loss: 1.310, Global test accuracy: 54.04
Round  28, Train loss: 0.905, Test loss: 1.061, Test accuracy: 62.02
Round  28, Global train loss: 0.905, Global test loss: 1.366, Global test accuracy: 54.50
Round  29, Train loss: 0.939, Test loss: 1.048, Test accuracy: 62.73
Round  29, Global train loss: 0.939, Global test loss: 1.487, Global test accuracy: 49.32
Round  30, Train loss: 0.861, Test loss: 1.062, Test accuracy: 62.18
Round  30, Global train loss: 0.861, Global test loss: 1.371, Global test accuracy: 53.22
Round  31, Train loss: 0.888, Test loss: 1.067, Test accuracy: 62.31
Round  31, Global train loss: 0.888, Global test loss: 1.358, Global test accuracy: 54.31
Round  32, Train loss: 0.946, Test loss: 1.061, Test accuracy: 62.33
Round  32, Global train loss: 0.946, Global test loss: 1.314, Global test accuracy: 54.07
Round  33, Train loss: 0.777, Test loss: 1.074, Test accuracy: 61.83
Round  33, Global train loss: 0.777, Global test loss: 1.481, Global test accuracy: 51.39
Round  34, Train loss: 0.876, Test loss: 1.053, Test accuracy: 62.77
Round  34, Global train loss: 0.876, Global test loss: 1.294, Global test accuracy: 55.09
Round  35, Train loss: 0.913, Test loss: 1.052, Test accuracy: 62.49
Round  35, Global train loss: 0.913, Global test loss: 1.323, Global test accuracy: 54.72
Round  36, Train loss: 0.851, Test loss: 1.048, Test accuracy: 62.43
Round  36, Global train loss: 0.851, Global test loss: 1.437, Global test accuracy: 52.04
Round  37, Train loss: 0.886, Test loss: 1.034, Test accuracy: 63.33
Round  37, Global train loss: 0.886, Global test loss: 1.302, Global test accuracy: 55.70
Round  38, Train loss: 0.787, Test loss: 1.034, Test accuracy: 63.45
Round  38, Global train loss: 0.787, Global test loss: 1.383, Global test accuracy: 56.17
Round  39, Train loss: 0.814, Test loss: 1.030, Test accuracy: 63.55
Round  39, Global train loss: 0.814, Global test loss: 1.368, Global test accuracy: 55.05
Round  40, Train loss: 0.736, Test loss: 1.018, Test accuracy: 63.77
Round  40, Global train loss: 0.736, Global test loss: 1.321, Global test accuracy: 54.77
Round  41, Train loss: 0.821, Test loss: 1.022, Test accuracy: 64.01
Round  41, Global train loss: 0.821, Global test loss: 1.239, Global test accuracy: 57.16
Round  42, Train loss: 0.701, Test loss: 1.043, Test accuracy: 63.45
Round  42, Global train loss: 0.701, Global test loss: 1.302, Global test accuracy: 54.89
Round  43, Train loss: 0.799, Test loss: 1.039, Test accuracy: 64.02
Round  43, Global train loss: 0.799, Global test loss: 1.245, Global test accuracy: 56.05
Round  44, Train loss: 0.770, Test loss: 1.035, Test accuracy: 64.23
Round  44, Global train loss: 0.770, Global test loss: 1.218, Global test accuracy: 58.39
Round  45, Train loss: 0.808, Test loss: 1.012, Test accuracy: 65.00
Round  45, Global train loss: 0.808, Global test loss: 1.410, Global test accuracy: 53.41
Round  46, Train loss: 0.766, Test loss: 1.005, Test accuracy: 65.24
Round  46, Global train loss: 0.766, Global test loss: 1.404, Global test accuracy: 54.10
Round  47, Train loss: 0.704, Test loss: 0.992, Test accuracy: 65.53
Round  47, Global train loss: 0.704, Global test loss: 1.396, Global test accuracy: 54.50
Round  48, Train loss: 0.702, Test loss: 0.979, Test accuracy: 66.26
Round  48, Global train loss: 0.702, Global test loss: 1.292, Global test accuracy: 56.45
Round  49, Train loss: 0.727, Test loss: 0.996, Test accuracy: 65.67
Round  49, Global train loss: 0.727, Global test loss: 1.282, Global test accuracy: 56.82
Round  50, Train loss: 0.784, Test loss: 1.018, Test accuracy: 65.01
Round  50, Global train loss: 0.784, Global test loss: 1.284, Global test accuracy: 55.92
Round  51, Train loss: 0.779, Test loss: 1.025, Test accuracy: 64.73
Round  51, Global train loss: 0.779, Global test loss: 1.659, Global test accuracy: 51.28
Round  52, Train loss: 0.790, Test loss: 1.023, Test accuracy: 65.05
Round  52, Global train loss: 0.790, Global test loss: 1.218, Global test accuracy: 58.28
Round  53, Train loss: 0.632, Test loss: 1.051, Test accuracy: 64.46
Round  53, Global train loss: 0.632, Global test loss: 1.254, Global test accuracy: 59.08
Round  54, Train loss: 0.837, Test loss: 1.056, Test accuracy: 64.04
Round  54, Global train loss: 0.837, Global test loss: 1.175, Global test accuracy: 59.07
Round  55, Train loss: 0.672, Test loss: 1.044, Test accuracy: 64.39
Round  55, Global train loss: 0.672, Global test loss: 1.203, Global test accuracy: 58.49
Round  56, Train loss: 0.668, Test loss: 1.050, Test accuracy: 63.78
Round  56, Global train loss: 0.668, Global test loss: 1.354, Global test accuracy: 55.12
Round  57, Train loss: 0.601, Test loss: 1.054, Test accuracy: 64.16
Round  57, Global train loss: 0.601, Global test loss: 1.239, Global test accuracy: 59.12
Round  58, Train loss: 0.840, Test loss: 1.040, Test accuracy: 64.74
Round  58, Global train loss: 0.840, Global test loss: 1.330, Global test accuracy: 56.04
Round  59, Train loss: 0.559, Test loss: 1.053, Test accuracy: 64.84
Round  59, Global train loss: 0.559, Global test loss: 1.245, Global test accuracy: 58.24
Round  60, Train loss: 0.666, Test loss: 1.047, Test accuracy: 64.90
Round  60, Global train loss: 0.666, Global test loss: 1.332, Global test accuracy: 55.99
Round  61, Train loss: 0.628, Test loss: 1.070, Test accuracy: 64.57
Round  61, Global train loss: 0.628, Global test loss: 1.273, Global test accuracy: 58.27
Round  62, Train loss: 0.683, Test loss: 1.078, Test accuracy: 64.37
Round  62, Global train loss: 0.683, Global test loss: 1.255, Global test accuracy: 58.09
Round  63, Train loss: 0.653, Test loss: 1.081, Test accuracy: 64.46
Round  63, Global train loss: 0.653, Global test loss: 1.299, Global test accuracy: 55.84
Round  64, Train loss: 0.747, Test loss: 1.059, Test accuracy: 64.78
Round  64, Global train loss: 0.747, Global test loss: 1.270, Global test accuracy: 57.76
Round  65, Train loss: 0.698, Test loss: 1.062, Test accuracy: 64.77
Round  65, Global train loss: 0.698, Global test loss: 1.254, Global test accuracy: 58.10
Round  66, Train loss: 0.722, Test loss: 1.077, Test accuracy: 64.59
Round  66, Global train loss: 0.722, Global test loss: 1.316, Global test accuracy: 55.90
Round  67, Train loss: 0.612, Test loss: 1.083, Test accuracy: 64.95
Round  67, Global train loss: 0.612, Global test loss: 1.388, Global test accuracy: 56.51
Round  68, Train loss: 0.779, Test loss: 1.122, Test accuracy: 64.11
Round  68, Global train loss: 0.779, Global test loss: 1.583, Global test accuracy: 50.92
Round  69, Train loss: 0.524, Test loss: 1.133, Test accuracy: 64.12
Round  69, Global train loss: 0.524, Global test loss: 1.561, Global test accuracy: 53.45
Round  70, Train loss: 0.594, Test loss: 1.124, Test accuracy: 64.77
Round  70, Global train loss: 0.594, Global test loss: 1.226, Global test accuracy: 59.49
Round  71, Train loss: 0.509, Test loss: 1.146, Test accuracy: 64.23
Round  71, Global train loss: 0.509, Global test loss: 1.326, Global test accuracy: 59.02
Round  72, Train loss: 0.715, Test loss: 1.162, Test accuracy: 64.31
Round  72, Global train loss: 0.715, Global test loss: 1.279, Global test accuracy: 56.93
Round  73, Train loss: 0.675, Test loss: 1.146, Test accuracy: 64.55
Round  73, Global train loss: 0.675, Global test loss: 1.302, Global test accuracy: 58.30
Round  74, Train loss: 0.696, Test loss: 1.129, Test accuracy: 64.62
Round  74, Global train loss: 0.696, Global test loss: 1.266, Global test accuracy: 57.93
Round  75, Train loss: 0.543, Test loss: 1.138, Test accuracy: 64.90
Round  75, Global train loss: 0.543, Global test loss: 1.295, Global test accuracy: 59.14
Round  76, Train loss: 0.526, Test loss: 1.118, Test accuracy: 65.32
Round  76, Global train loss: 0.526, Global test loss: 1.377, Global test accuracy: 57.52
Round  77, Train loss: 0.594, Test loss: 1.141, Test accuracy: 65.56
Round  77, Global train loss: 0.594, Global test loss: 1.423, Global test accuracy: 55.77
Round  78, Train loss: 0.562, Test loss: 1.150, Test accuracy: 64.79
Round  78, Global train loss: 0.562, Global test loss: 1.362, Global test accuracy: 57.51
Round  79, Train loss: 0.625, Test loss: 1.156, Test accuracy: 64.89
Round  79, Global train loss: 0.625, Global test loss: 1.376, Global test accuracy: 57.18
Round  80, Train loss: 0.540, Test loss: 1.166, Test accuracy: 64.75
Round  80, Global train loss: 0.540, Global test loss: 1.395, Global test accuracy: 57.43
Round  81, Train loss: 0.481, Test loss: 1.171, Test accuracy: 64.50
Round  81, Global train loss: 0.481, Global test loss: 1.295, Global test accuracy: 59.67
Round  82, Train loss: 0.505, Test loss: 1.148, Test accuracy: 64.84
Round  82, Global train loss: 0.505, Global test loss: 1.293, Global test accuracy: 59.16
Round  83, Train loss: 0.611, Test loss: 1.128, Test accuracy: 65.66
Round  83, Global train loss: 0.611, Global test loss: 1.368, Global test accuracy: 57.34
Round  84, Train loss: 0.599, Test loss: 1.137, Test accuracy: 65.84
Round  84, Global train loss: 0.599, Global test loss: 1.330, Global test accuracy: 57.05
Round  85, Train loss: 0.608, Test loss: 1.134, Test accuracy: 65.90
Round  85, Global train loss: 0.608, Global test loss: 1.251, Global test accuracy: 59.72
Round  86, Train loss: 0.496, Test loss: 1.167, Test accuracy: 65.82
Round  86, Global train loss: 0.496, Global test loss: 1.350, Global test accuracy: 58.76
Round  87, Train loss: 0.519, Test loss: 1.174, Test accuracy: 66.21
Round  87, Global train loss: 0.519, Global test loss: 1.357, Global test accuracy: 58.89
Round  88, Train loss: 0.503, Test loss: 1.180, Test accuracy: 66.08
Round  88, Global train loss: 0.503, Global test loss: 1.343, Global test accuracy: 57.88
Round  89, Train loss: 0.489, Test loss: 1.179, Test accuracy: 66.37
Round  89, Global train loss: 0.489, Global test loss: 1.458, Global test accuracy: 58.22
Round  90, Train loss: 0.504, Test loss: 1.184, Test accuracy: 66.00
Round  90, Global train loss: 0.504, Global test loss: 1.397, Global test accuracy: 58.29
Round  91, Train loss: 0.553, Test loss: 1.172, Test accuracy: 66.10
Round  91, Global train loss: 0.553, Global test loss: 1.259, Global test accuracy: 60.44/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  92, Train loss: 0.554, Test loss: 1.160, Test accuracy: 66.74
Round  92, Global train loss: 0.554, Global test loss: 1.322, Global test accuracy: 59.24
Round  93, Train loss: 0.491, Test loss: 1.179, Test accuracy: 66.95
Round  93, Global train loss: 0.491, Global test loss: 1.311, Global test accuracy: 60.58
Round  94, Train loss: 0.458, Test loss: 1.200, Test accuracy: 66.28
Round  94, Global train loss: 0.458, Global test loss: 1.418, Global test accuracy: 58.28
Round  95, Train loss: 0.589, Test loss: 1.225, Test accuracy: 66.10
Round  95, Global train loss: 0.589, Global test loss: 1.313, Global test accuracy: 59.10
Round  96, Train loss: 0.431, Test loss: 1.210, Test accuracy: 66.35
Round  96, Global train loss: 0.431, Global test loss: 1.405, Global test accuracy: 57.85
Round  97, Train loss: 0.405, Test loss: 1.197, Test accuracy: 66.19
Round  97, Global train loss: 0.405, Global test loss: 1.280, Global test accuracy: 60.60
Round  98, Train loss: 0.376, Test loss: 1.210, Test accuracy: 66.12
Round  98, Global train loss: 0.376, Global test loss: 1.392, Global test accuracy: 58.62
Round  99, Train loss: 0.437, Test loss: 1.183, Test accuracy: 66.42
Round  99, Global train loss: 0.437, Global test loss: 1.475, Global test accuracy: 57.68
Final Round, Train loss: 0.419, Test loss: 1.353, Test accuracy: 65.12
Final Round, Global train loss: 0.419, Global test loss: 1.475, Global test accuracy: 57.68
Average accuracy final 10 rounds: 66.325 

Average global accuracy final 10 rounds: 59.068000000000005 

1470.3496301174164
[1.4901533126831055, 2.980306625366211, 4.200467348098755, 5.420628070831299, 6.640831708908081, 7.861035346984863, 9.078875303268433, 10.296715259552002, 11.531989812850952, 12.767264366149902, 14.009074449539185, 15.250884532928467, 16.49208641052246, 17.733288288116455, 18.97029685974121, 20.207305431365967, 21.44376230239868, 22.680219173431396, 23.91819667816162, 25.156174182891846, 26.391441106796265, 27.626708030700684, 28.86178684234619, 30.0968656539917, 31.32647156715393, 32.55607748031616, 33.78608441352844, 35.01609134674072, 36.240861654281616, 37.46563196182251, 38.69320631027222, 39.920780658721924, 41.15324544906616, 42.3857102394104, 43.61593055725098, 44.84615087509155, 46.070717573165894, 47.295284271240234, 48.52661943435669, 49.757954597473145, 50.99088644981384, 52.22381830215454, 53.455856800079346, 54.68789529800415, 55.9172477722168, 57.14660024642944, 58.37731957435608, 59.608038902282715, 60.839133501052856, 62.070228099823, 63.30423903465271, 64.53824996948242, 65.76331090927124, 66.98837184906006, 68.21843385696411, 69.44849586486816, 70.6816258430481, 71.91475582122803, 73.14439916610718, 74.37404251098633, 75.6010389328003, 76.82803535461426, 78.05962109565735, 79.29120683670044, 80.52129077911377, 81.7513747215271, 82.97836399078369, 84.20535326004028, 85.42710399627686, 86.64885473251343, 87.874187707901, 89.09952068328857, 90.32441449165344, 91.54930830001831, 92.77343940734863, 93.99757051467896, 95.22608184814453, 96.45459318161011, 97.68495225906372, 98.91531133651733, 100.13743829727173, 101.35956525802612, 102.57473921775818, 103.78991317749023, 105.0077075958252, 106.22550201416016, 107.44130802154541, 108.65711402893066, 109.87601232528687, 111.09491062164307, 112.3105673789978, 113.52622413635254, 114.74440956115723, 115.96259498596191, 117.1808876991272, 118.39918041229248, 119.61819982528687, 120.83721923828125, 122.0546064376831, 123.27199363708496, 124.48993229866028, 125.7078709602356, 126.9263060092926, 128.1447410583496, 129.35625553131104, 130.56777000427246, 131.78510880470276, 133.00244760513306, 134.2234697341919, 135.44449186325073, 136.66350054740906, 137.88250923156738, 139.09677147865295, 140.31103372573853, 141.52994799613953, 142.74886226654053, 143.96624565124512, 145.1836290359497, 146.4029896259308, 147.62235021591187, 148.8378176689148, 150.05328512191772, 151.2689974308014, 152.48470973968506, 153.70498919487, 154.92526865005493, 156.14255166053772, 157.3598346710205, 158.57852745056152, 159.79722023010254, 161.01752614974976, 162.23783206939697, 163.46848821640015, 164.69914436340332, 165.92330312728882, 167.14746189117432, 168.3798758983612, 169.6122899055481, 170.84280800819397, 172.07332611083984, 173.3046772480011, 174.53602838516235, 175.76714277267456, 176.99825716018677, 178.22999501228333, 179.46173286437988, 180.6924066543579, 181.92308044433594, 183.15290760993958, 184.3827347755432, 185.61210918426514, 186.84148359298706, 188.07093334197998, 189.3003830909729, 190.52919387817383, 191.75800466537476, 192.98797035217285, 194.21793603897095, 195.44502878189087, 196.6721215248108, 197.89932441711426, 199.12652730941772, 200.35811805725098, 201.58970880508423, 202.8141098022461, 204.03851079940796, 205.26930856704712, 206.50010633468628, 207.72866225242615, 208.95721817016602, 210.18251776695251, 211.407817363739, 212.63949871063232, 213.87118005752563, 215.09900975227356, 216.32683944702148, 217.55405521392822, 218.78127098083496, 220.0163905620575, 221.25151014328003, 222.48425006866455, 223.71698999404907, 224.95100831985474, 226.1850266456604, 227.41632747650146, 228.64762830734253, 229.88113284111023, 231.11463737487793, 232.34819722175598, 233.58175706863403, 234.82047080993652, 236.059184551239, 237.2940375804901, 238.5288906097412, 239.75355577468872, 240.97822093963623, 242.21381306648254, 243.44940519332886, 244.68289017677307, 245.91637516021729, 248.36185717582703, 250.80733919143677]
[16.44, 16.44, 32.24, 32.24, 39.08, 39.08, 40.76, 40.76, 43.59, 43.59, 47.46, 47.46, 48.28, 48.28, 50.2, 50.2, 52.78, 52.78, 53.83, 53.83, 55.71, 55.71, 56.77, 56.77, 56.51, 56.51, 57.03, 57.03, 57.81, 57.81, 59.02, 59.02, 59.35, 59.35, 59.93, 59.93, 59.86, 59.86, 60.24, 60.24, 60.15, 60.15, 59.65, 59.65, 59.96, 59.96, 60.15, 60.15, 61.65, 61.65, 61.61, 61.61, 61.71, 61.71, 61.92, 61.92, 62.02, 62.02, 62.73, 62.73, 62.18, 62.18, 62.31, 62.31, 62.33, 62.33, 61.83, 61.83, 62.77, 62.77, 62.49, 62.49, 62.43, 62.43, 63.33, 63.33, 63.45, 63.45, 63.55, 63.55, 63.77, 63.77, 64.01, 64.01, 63.45, 63.45, 64.02, 64.02, 64.23, 64.23, 65.0, 65.0, 65.24, 65.24, 65.53, 65.53, 66.26, 66.26, 65.67, 65.67, 65.01, 65.01, 64.73, 64.73, 65.05, 65.05, 64.46, 64.46, 64.04, 64.04, 64.39, 64.39, 63.78, 63.78, 64.16, 64.16, 64.74, 64.74, 64.84, 64.84, 64.9, 64.9, 64.57, 64.57, 64.37, 64.37, 64.46, 64.46, 64.78, 64.78, 64.77, 64.77, 64.59, 64.59, 64.95, 64.95, 64.11, 64.11, 64.12, 64.12, 64.77, 64.77, 64.23, 64.23, 64.31, 64.31, 64.55, 64.55, 64.62, 64.62, 64.9, 64.9, 65.32, 65.32, 65.56, 65.56, 64.79, 64.79, 64.89, 64.89, 64.75, 64.75, 64.5, 64.5, 64.84, 64.84, 65.66, 65.66, 65.84, 65.84, 65.9, 65.9, 65.82, 65.82, 66.21, 66.21, 66.08, 66.08, 66.37, 66.37, 66.0, 66.0, 66.1, 66.1, 66.74, 66.74, 66.95, 66.95, 66.28, 66.28, 66.1, 66.1, 66.35, 66.35, 66.19, 66.19, 66.12, 66.12, 66.42, 66.42, 65.12, 65.12]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.8 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 6, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 14, noise    level: 0.8000 
   Client 11, noise    level: 0.8000 
   Client 15, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
   Client 13, noise    level: 0.8000 
   Client 17, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 16, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 18, noise    level: 0.8000 
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 2.009, Test loss: 2.144, Test accuracy: 17.35
Round   1, Train loss: 1.638, Test loss: 2.025, Test accuracy: 28.51
Round   2, Train loss: 1.445, Test loss: 1.735, Test accuracy: 35.49
Round   3, Train loss: 1.339, Test loss: 1.658, Test accuracy: 38.93
Round   4, Train loss: 1.252, Test loss: 1.562, Test accuracy: 43.96
Round   5, Train loss: 1.377, Test loss: 1.416, Test accuracy: 47.58
Round   6, Train loss: 1.198, Test loss: 1.442, Test accuracy: 49.48
Round   7, Train loss: 1.221, Test loss: 1.304, Test accuracy: 51.71
Round   8, Train loss: 1.247, Test loss: 1.256, Test accuracy: 52.91
Round   9, Train loss: 1.221, Test loss: 1.269, Test accuracy: 54.44
Round  10, Train loss: 1.248, Test loss: 1.144, Test accuracy: 58.15
Round  11, Train loss: 1.084, Test loss: 1.148, Test accuracy: 57.55
Round  12, Train loss: 1.080, Test loss: 1.124, Test accuracy: 58.98
Round  13, Train loss: 1.085, Test loss: 1.101, Test accuracy: 59.20
Round  14, Train loss: 1.033, Test loss: 1.080, Test accuracy: 60.13
Round  15, Train loss: 1.073, Test loss: 1.060, Test accuracy: 60.66
Round  16, Train loss: 1.051, Test loss: 1.053, Test accuracy: 60.75
Round  17, Train loss: 1.095, Test loss: 1.053, Test accuracy: 60.59
Round  18, Train loss: 1.127, Test loss: 1.017, Test accuracy: 61.55
Round  19, Train loss: 1.037, Test loss: 1.030, Test accuracy: 61.62
Round  20, Train loss: 1.184, Test loss: 1.018, Test accuracy: 61.97
Round  21, Train loss: 1.024, Test loss: 1.010, Test accuracy: 63.09
Round  22, Train loss: 1.059, Test loss: 0.991, Test accuracy: 63.49
Round  23, Train loss: 1.098, Test loss: 0.997, Test accuracy: 63.53
Round  24, Train loss: 0.872, Test loss: 0.947, Test accuracy: 65.27
Round  25, Train loss: 0.918, Test loss: 0.962, Test accuracy: 64.91
Round  26, Train loss: 0.896, Test loss: 0.958, Test accuracy: 64.80
Round  27, Train loss: 1.137, Test loss: 0.958, Test accuracy: 65.04
Round  28, Train loss: 0.856, Test loss: 0.947, Test accuracy: 64.98
Round  29, Train loss: 0.893, Test loss: 0.944, Test accuracy: 64.66
Round  30, Train loss: 0.939, Test loss: 0.935, Test accuracy: 64.92
Round  31, Train loss: 0.782, Test loss: 0.929, Test accuracy: 65.55
Round  32, Train loss: 0.936, Test loss: 0.923, Test accuracy: 65.85
Round  33, Train loss: 0.746, Test loss: 0.904, Test accuracy: 66.24
Round  34, Train loss: 1.002, Test loss: 0.898, Test accuracy: 66.38
Round  35, Train loss: 0.927, Test loss: 0.893, Test accuracy: 66.86
Round  36, Train loss: 0.916, Test loss: 0.902, Test accuracy: 66.99
Round  37, Train loss: 0.933, Test loss: 0.879, Test accuracy: 67.67
Round  38, Train loss: 0.738, Test loss: 0.874, Test accuracy: 67.91
Round  39, Train loss: 0.875, Test loss: 0.873, Test accuracy: 67.70
Round  40, Train loss: 0.785, Test loss: 0.868, Test accuracy: 68.21
Round  41, Train loss: 0.860, Test loss: 0.859, Test accuracy: 68.51
Round  42, Train loss: 0.852, Test loss: 0.842, Test accuracy: 69.17
Round  43, Train loss: 0.899, Test loss: 0.858, Test accuracy: 68.71
Round  44, Train loss: 0.859, Test loss: 0.854, Test accuracy: 68.71
Round  45, Train loss: 0.735, Test loss: 0.845, Test accuracy: 68.94
Round  46, Train loss: 0.679, Test loss: 0.832, Test accuracy: 69.17
Round  47, Train loss: 0.838, Test loss: 0.835, Test accuracy: 69.08
Round  48, Train loss: 0.744, Test loss: 0.837, Test accuracy: 69.16
Round  49, Train loss: 0.832, Test loss: 0.821, Test accuracy: 69.93
Round  50, Train loss: 0.861, Test loss: 0.839, Test accuracy: 69.29
Round  51, Train loss: 0.704, Test loss: 0.823, Test accuracy: 69.61
Round  52, Train loss: 0.637, Test loss: 0.822, Test accuracy: 70.22
Round  53, Train loss: 0.622, Test loss: 0.815, Test accuracy: 70.15
Round  54, Train loss: 0.929, Test loss: 0.816, Test accuracy: 70.49
Round  55, Train loss: 0.868, Test loss: 0.815, Test accuracy: 69.80
Round  56, Train loss: 0.883, Test loss: 0.821, Test accuracy: 69.99
Round  57, Train loss: 0.609, Test loss: 0.797, Test accuracy: 70.86
Round  58, Train loss: 0.668, Test loss: 0.807, Test accuracy: 70.41
Round  59, Train loss: 0.696, Test loss: 0.796, Test accuracy: 70.99
Round  60, Train loss: 0.548, Test loss: 0.798, Test accuracy: 70.66
Round  61, Train loss: 0.731, Test loss: 0.803, Test accuracy: 71.02
Round  62, Train loss: 0.641, Test loss: 0.790, Test accuracy: 71.03
Round  63, Train loss: 0.677, Test loss: 0.788, Test accuracy: 71.11
Round  64, Train loss: 0.708, Test loss: 0.792, Test accuracy: 70.79
Round  65, Train loss: 0.616, Test loss: 0.783, Test accuracy: 71.24
Round  66, Train loss: 0.659, Test loss: 0.789, Test accuracy: 70.73
Round  67, Train loss: 0.648, Test loss: 0.786, Test accuracy: 71.16
Round  68, Train loss: 0.700, Test loss: 0.789, Test accuracy: 71.05
Round  69, Train loss: 0.603, Test loss: 0.783, Test accuracy: 71.17
Round  70, Train loss: 0.601, Test loss: 0.784, Test accuracy: 71.43
Round  71, Train loss: 0.539, Test loss: 0.780, Test accuracy: 71.67
Round  72, Train loss: 0.731, Test loss: 0.783, Test accuracy: 71.30
Round  73, Train loss: 0.666, Test loss: 0.785, Test accuracy: 71.39
Round  74, Train loss: 0.781, Test loss: 0.788, Test accuracy: 71.34
Round  75, Train loss: 0.541, Test loss: 0.781, Test accuracy: 71.70
Round  76, Train loss: 0.458, Test loss: 0.783, Test accuracy: 71.55
Round  77, Train loss: 0.488, Test loss: 0.783, Test accuracy: 71.77
Round  78, Train loss: 0.630, Test loss: 0.779, Test accuracy: 72.06
Round  79, Train loss: 0.687, Test loss: 0.770, Test accuracy: 72.30
Round  80, Train loss: 0.579, Test loss: 0.773, Test accuracy: 72.18
Round  81, Train loss: 0.602, Test loss: 0.773, Test accuracy: 72.24
Round  82, Train loss: 0.579, Test loss: 0.777, Test accuracy: 72.25
Round  83, Train loss: 0.584, Test loss: 0.768, Test accuracy: 72.48
Round  84, Train loss: 0.596, Test loss: 0.774, Test accuracy: 71.95
Round  85, Train loss: 0.707, Test loss: 0.781, Test accuracy: 71.88
Round  86, Train loss: 0.620, Test loss: 0.776, Test accuracy: 71.82
Round  87, Train loss: 0.465, Test loss: 0.779, Test accuracy: 71.73
Round  88, Train loss: 0.657, Test loss: 0.778, Test accuracy: 71.88
Round  89, Train loss: 0.557, Test loss: 0.778, Test accuracy: 71.83
Round  90, Train loss: 0.576, Test loss: 0.765, Test accuracy: 72.47
Round  91, Train loss: 0.753, Test loss: 0.770, Test accuracy: 72.42
Round  92, Train loss: 0.683, Test loss: 0.785, Test accuracy: 72.08
Round  93, Train loss: 0.547, Test loss: 0.766, Test accuracy: 72.37
Round  94, Train loss: 0.455, Test loss: 0.767, Test accuracy: 72.27
Round  95, Train loss: 0.611, Test loss: 0.772, Test accuracy: 72.21
Round  96, Train loss: 0.437, Test loss: 0.765, Test accuracy: 72.93
Round  97, Train loss: 0.484, Test loss: 0.775, Test accuracy: 72.16
Round  98, Train loss: 0.413, Test loss: 0.774, Test accuracy: 72.17
Round  99, Train loss: 0.480, Test loss: 0.775, Test accuracy: 72.21
Final Round, Train loss: 0.498, Test loss: 0.779, Test accuracy: 72.32
Average accuracy final 10 rounds: 72.32900000000001
1718.2311792373657
[2.7917418479919434, 5.288581848144531, 7.7763731479644775, 10.268667936325073, 12.759830951690674, 15.231022357940674, 17.722374200820923, 20.209951400756836, 22.70130157470703, 25.194000482559204, 27.681251525878906, 30.168631076812744, 32.664427518844604, 35.16049766540527, 37.65495443344116, 40.14500594139099, 42.63585352897644, 45.127615451812744, 47.62492752075195, 50.11599564552307, 52.61227321624756, 55.09529185295105, 57.58268165588379, 60.084996461868286, 62.58348321914673, 65.0867133140564, 67.58999037742615, 70.09409856796265, 72.59347438812256, 75.10705709457397, 77.60996317863464, 80.10302948951721, 82.61113548278809, 85.11963081359863, 87.62805390357971, 90.1431040763855, 92.64315843582153, 95.15983724594116, 97.66664910316467, 100.17052221298218, 102.68062996864319, 105.18211722373962, 107.6621401309967, 110.12710070610046, 112.59288239479065, 115.06262755393982, 117.34397077560425, 119.63040494918823, 121.91691088676453, 124.20256090164185, 126.48456239700317, 128.74751162528992, 131.00989413261414, 133.28958868980408, 135.56965041160583, 137.84006452560425, 140.09974455833435, 142.38245368003845, 144.63843536376953, 146.93984532356262, 149.22214198112488, 151.50376081466675, 153.7861864566803, 156.06500267982483, 158.3387529850006, 160.60496759414673, 162.8673484325409, 165.12822008132935, 167.40161299705505, 169.67635703086853, 171.95511174201965, 174.23808360099792, 176.5193018913269, 178.8010606765747, 181.07633638381958, 183.3447723388672, 185.62236666679382, 187.8992395401001, 190.1729941368103, 192.45430755615234, 194.7280011177063, 197.0093870162964, 199.28809642791748, 201.56071043014526, 203.83369421958923, 206.10786271095276, 208.37992429733276, 210.65522384643555, 212.93107509613037, 215.20130395889282, 217.47279930114746, 219.74513626098633, 222.01625537872314, 224.29900574684143, 226.58043026924133, 228.86207628250122, 231.13442945480347, 233.40603971481323, 235.68154406547546, 237.9537708759308, 241.58319687843323]
[17.35, 28.51, 35.49, 38.93, 43.96, 47.58, 49.48, 51.71, 52.91, 54.44, 58.15, 57.55, 58.98, 59.2, 60.13, 60.66, 60.75, 60.59, 61.55, 61.62, 61.97, 63.09, 63.49, 63.53, 65.27, 64.91, 64.8, 65.04, 64.98, 64.66, 64.92, 65.55, 65.85, 66.24, 66.38, 66.86, 66.99, 67.67, 67.91, 67.7, 68.21, 68.51, 69.17, 68.71, 68.71, 68.94, 69.17, 69.08, 69.16, 69.93, 69.29, 69.61, 70.22, 70.15, 70.49, 69.8, 69.99, 70.86, 70.41, 70.99, 70.66, 71.02, 71.03, 71.11, 70.79, 71.24, 70.73, 71.16, 71.05, 71.17, 71.43, 71.67, 71.3, 71.39, 71.34, 71.7, 71.55, 71.77, 72.06, 72.3, 72.18, 72.24, 72.25, 72.48, 71.95, 71.88, 71.82, 71.73, 71.88, 71.83, 72.47, 72.42, 72.08, 72.37, 72.27, 72.21, 72.93, 72.16, 72.17, 72.21, 72.32]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 1, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 15, noise    level: 0.8000 
   Client 13, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
   Client 12, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 19, noise    level: 0.8000 
   Client 16, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 17, noise    level: 0.8000 
   Client 10, noise    level: 0.8000 
   Client 14, noise    level: 0.8000 
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  16.8200
Round 1 global test acc  17.1300
Round 2 global test acc  17.6300
Round 3 global test acc  27.0100
Round 4 global test acc  27.2900
Round 5 global test acc  29.9500
Round 6 global test acc  28.9000
Round 7 global test acc  24.8400
Round 8 global test acc  24.4200
Round 9 global test acc  29.6400
Round 10 global test acc  31.6300
Round 11 global test acc  27.4200
Round 12 global test acc  36.5900
Round 13 global test acc  31.9800
Round 14 global test acc  38.0000
Round 15 global test acc  35.5400
Round 16 global test acc  39.6200
Round 17 global test acc  23.9100
Round 18 global test acc  31.9300
Round 19 global test acc  37.5700
Round 20 global test acc  33.6100
Round 21 global test acc  32.9900
Round 22 global test acc  42.0200
Round 23 global test acc  47.3200
Round 24 global test acc  32.5800
Round 25 global test acc  32.2900
Round 26 global test acc  37.0500
Round 27 global test acc  31.8800
Round 28 global test acc  30.5200
Round 29 global test acc  38.3300
Round 30 global test acc  41.9400
Round 31 global test acc  36.8400
Round 32 global test acc  37.4500
Round 33 global test acc  42.4300
Round 34 global test acc  37.9200
Round 35 global test acc  40.9800
Round 36 global test acc  41.6100
Round 37 global test acc  31.7200
Round 38 global test acc  43.4900
Round 39 global test acc  36.3900
Round 40 global test acc  38.9500
Round 41 global test acc  38.4000
Round 42 global test acc  35.2800
Round 43 global test acc  38.8000
Round 44 global test acc  46.9100
Round 45 global test acc  46.5500
Round 46 global test acc  39.5400
Round 47 global test acc  47.1100
Round 48 global test acc  38.7700
Round 49 global test acc  36.5600
Round 50 global test acc  44.3800
Round 51 global test acc  40.1600
Round 52 global test acc  41.5000
Round 53 global test acc  36.7000
Round 54 global test acc  35.6000
Round 55 global test acc  43.8000
Round 56 global test acc  38.4400
Round 57 global test acc  44.1000
Round 58 global test acc  44.6000
Round 59 global test acc  41.5000
Round 60 global test acc  44.1500
Round 61 global test acc  38.1600
Round 62 global test acc  42.2100
Round 63 global test acc  38.2400
Round 64 global test acc  41.2700
Round 65 global test acc  39.2700
Round 66 global test acc  40.7000
Round 67 global test acc  37.8500
Round 68 global test acc  42.1500
Round 69 global test acc  37.4300
Round 70 global test acc  40.0700
Round 71 global test acc  41.3900
Round 72 global test acc  40.5200
Round 73 global test acc  45.4100
Round 74 global test acc  42.1600
Round 75 global test acc  38.5700
Round 76 global test acc  38.3600
Round 77 global test acc  45.1100
Round 78 global test acc  45.5500
Round 79 global test acc  45.1000
Round 80 global test acc  45.5500
Round 81 global test acc  44.3500
Round 82 global test acc  43.6400
Round 83 global test acc  39.8200
Round 84 global test acc  37.8500
Round 85 global test acc  36.3000
Round 86 global test acc  33.4700
Round 87 global test acc  32.8000
Round 88 global test acc  30.3100
Round 89 global test acc  29.0100
Round 90 global test acc  28.5800
Round 91 global test acc  27.4900
Round 92 global test acc  26.2100
Round 93 global test acc  25.4700
Round 94 global test acc  24.9100
Round 95 global test acc  24.7400
Round 96 global test acc  24.2600
Round 97 global test acc  24.5500
Round 98 global test acc  24.2300
Round 99 global test acc  24.3400
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 13, noise    level: 0.8000 
   Client 16, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 18, noise    level: 0.8000 
   Client 12, noise    level: 0.8000 
   Client 15, noise    level: 0.8000 
   Client 14, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 11, noise    level: 0.8000 
   Client 10, noise    level: 0.8000 
   Client 19, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 2.011, Test loss: 2.152, Test accuracy: 24.08
Round   1, Train loss: 1.662, Test loss: 1.983, Test accuracy: 29.65
Round   2, Train loss: 1.474, Test loss: 1.655, Test accuracy: 36.68
Round   3, Train loss: 1.394, Test loss: 1.635, Test accuracy: 38.22
Round   4, Train loss: 1.302, Test loss: 1.557, Test accuracy: 42.40
Round   5, Train loss: 1.349, Test loss: 1.334, Test accuracy: 47.29
Round   6, Train loss: 1.231, Test loss: 1.389, Test accuracy: 49.18
Round   7, Train loss: 1.254, Test loss: 1.273, Test accuracy: 50.80
Round   8, Train loss: 1.099, Test loss: 1.282, Test accuracy: 52.15
Round   9, Train loss: 1.217, Test loss: 1.262, Test accuracy: 53.33
Round  10, Train loss: 1.242, Test loss: 1.161, Test accuracy: 55.25
Round  11, Train loss: 1.111, Test loss: 1.146, Test accuracy: 55.88
Round  12, Train loss: 1.206, Test loss: 1.128, Test accuracy: 57.86
Round  13, Train loss: 1.220, Test loss: 1.104, Test accuracy: 57.55
Round  14, Train loss: 1.167, Test loss: 1.105, Test accuracy: 57.98
Round  15, Train loss: 1.211, Test loss: 1.098, Test accuracy: 58.00
Round  16, Train loss: 1.102, Test loss: 1.070, Test accuracy: 59.06
Round  17, Train loss: 1.129, Test loss: 1.039, Test accuracy: 60.56
Round  18, Train loss: 1.059, Test loss: 1.029, Test accuracy: 61.12
Round  19, Train loss: 1.010, Test loss: 1.019, Test accuracy: 61.89
Round  20, Train loss: 1.095, Test loss: 1.018, Test accuracy: 61.89
Round  21, Train loss: 1.143, Test loss: 1.006, Test accuracy: 62.30
Round  22, Train loss: 1.038, Test loss: 1.014, Test accuracy: 62.62
Round  23, Train loss: 0.897, Test loss: 1.001, Test accuracy: 62.60
Round  24, Train loss: 0.860, Test loss: 0.968, Test accuracy: 63.23
Round  25, Train loss: 1.043, Test loss: 0.965, Test accuracy: 64.06
Round  26, Train loss: 0.891, Test loss: 0.970, Test accuracy: 63.99
Round  27, Train loss: 1.161, Test loss: 0.959, Test accuracy: 64.57
Round  28, Train loss: 0.876, Test loss: 0.951, Test accuracy: 64.64
Round  29, Train loss: 0.952, Test loss: 0.955, Test accuracy: 64.68
Round  30, Train loss: 0.948, Test loss: 0.942, Test accuracy: 65.08
Round  31, Train loss: 1.069, Test loss: 0.937, Test accuracy: 64.67
Round  32, Train loss: 0.940, Test loss: 0.935, Test accuracy: 65.19
Round  33, Train loss: 0.953, Test loss: 0.927, Test accuracy: 65.69
Round  34, Train loss: 0.947, Test loss: 0.926, Test accuracy: 65.94
Round  35, Train loss: 0.927, Test loss: 0.925, Test accuracy: 65.58
Round  36, Train loss: 0.919, Test loss: 0.910, Test accuracy: 65.92
Round  37, Train loss: 0.990, Test loss: 0.917, Test accuracy: 65.71
Round  38, Train loss: 0.815, Test loss: 0.898, Test accuracy: 66.54
Round  39, Train loss: 0.904, Test loss: 0.904, Test accuracy: 66.71
Round  40, Train loss: 1.016, Test loss: 0.908, Test accuracy: 66.70
Round  41, Train loss: 0.963, Test loss: 0.904, Test accuracy: 67.24
Round  42, Train loss: 1.025, Test loss: 0.900, Test accuracy: 66.90
Round  43, Train loss: 0.919, Test loss: 0.891, Test accuracy: 67.10
Round  44, Train loss: 0.808, Test loss: 0.884, Test accuracy: 67.51
Round  45, Train loss: 0.829, Test loss: 0.881, Test accuracy: 67.86
Round  46, Train loss: 0.785, Test loss: 0.866, Test accuracy: 68.01
Round  47, Train loss: 0.765, Test loss: 0.863, Test accuracy: 68.53
Round  48, Train loss: 0.903, Test loss: 0.866, Test accuracy: 67.91
Round  49, Train loss: 0.865, Test loss: 0.863, Test accuracy: 68.15
Round  50, Train loss: 0.922, Test loss: 0.864, Test accuracy: 68.10
Round  51, Train loss: 0.808, Test loss: 0.859, Test accuracy: 68.45
Round  52, Train loss: 0.748, Test loss: 0.860, Test accuracy: 68.27
Round  53, Train loss: 0.746, Test loss: 0.863, Test accuracy: 67.82
Round  54, Train loss: 0.839, Test loss: 0.869, Test accuracy: 67.67
Round  55, Train loss: 0.832, Test loss: 0.861, Test accuracy: 68.01
Round  56, Train loss: 0.844, Test loss: 0.858, Test accuracy: 68.20
Round  57, Train loss: 0.758, Test loss: 0.857, Test accuracy: 68.42
Round  58, Train loss: 0.764, Test loss: 0.857, Test accuracy: 67.96
Round  59, Train loss: 0.829, Test loss: 0.863, Test accuracy: 68.05
Round  60, Train loss: 0.683, Test loss: 0.864, Test accuracy: 67.64
Round  61, Train loss: 0.807, Test loss: 0.864, Test accuracy: 68.30
Round  62, Train loss: 0.732, Test loss: 0.863, Test accuracy: 68.11
Round  63, Train loss: 0.698, Test loss: 0.865, Test accuracy: 67.71
Round  64, Train loss: 0.804, Test loss: 0.858, Test accuracy: 68.31
Round  65, Train loss: 0.694, Test loss: 0.848, Test accuracy: 68.44
Round  66, Train loss: 0.807, Test loss: 0.844, Test accuracy: 68.86
Round  67, Train loss: 0.665, Test loss: 0.848, Test accuracy: 69.11
Round  68, Train loss: 0.810, Test loss: 0.843, Test accuracy: 69.26
Round  69, Train loss: 0.790, Test loss: 0.843, Test accuracy: 68.69
Round  70, Train loss: 0.695, Test loss: 0.851, Test accuracy: 68.68
Round  71, Train loss: 0.746, Test loss: 0.844, Test accuracy: 68.98
Round  72, Train loss: 0.793, Test loss: 0.841, Test accuracy: 69.18
Round  73, Train loss: 0.630, Test loss: 0.844, Test accuracy: 69.39
Round  74, Train loss: 0.702, Test loss: 0.849, Test accuracy: 69.21
Round  75, Train loss: 0.702, Test loss: 0.858, Test accuracy: 68.85
Round  76, Train loss: 0.708, Test loss: 0.860, Test accuracy: 68.99
Round  77, Train loss: 0.633, Test loss: 0.857, Test accuracy: 68.54
Round  78, Train loss: 0.548, Test loss: 0.843, Test accuracy: 68.90
Round  79, Train loss: 0.629, Test loss: 0.835, Test accuracy: 69.15
Round  80, Train loss: 0.724, Test loss: 0.843, Test accuracy: 68.72
Round  81, Train loss: 0.733, Test loss: 0.840, Test accuracy: 69.34
Round  82, Train loss: 0.700, Test loss: 0.843, Test accuracy: 69.32
Round  83, Train loss: 0.694, Test loss: 0.838, Test accuracy: 69.39
Round  84, Train loss: 0.550, Test loss: 0.840, Test accuracy: 69.63
Round  85, Train loss: 0.648, Test loss: 0.835, Test accuracy: 69.52
Round  86, Train loss: 0.632, Test loss: 0.831, Test accuracy: 70.19
Round  87, Train loss: 0.600, Test loss: 0.837, Test accuracy: 69.77
Round  88, Train loss: 0.622, Test loss: 0.843, Test accuracy: 69.68
Round  89, Train loss: 0.619, Test loss: 0.845, Test accuracy: 69.48
Round  90, Train loss: 0.617, Test loss: 0.853, Test accuracy: 69.60
Round  91, Train loss: 0.641, Test loss: 0.848, Test accuracy: 69.34
Round  92, Train loss: 0.586, Test loss: 0.853, Test accuracy: 69.40
Round  93, Train loss: 0.599, Test loss: 0.848, Test accuracy: 69.47
Round  94, Train loss: 0.570, Test loss: 0.858, Test accuracy: 68.94
Round  95, Train loss: 0.500, Test loss: 0.842, Test accuracy: 69.83
Round  96, Train loss: 0.516, Test loss: 0.844, Test accuracy: 69.76
Round  97, Train loss: 0.575, Test loss: 0.840, Test accuracy: 69.72
Round  98, Train loss: 0.563, Test loss: 0.845, Test accuracy: 69.23
Round  99, Train loss: 0.654, Test loss: 0.850, Test accuracy: 69.47
Final Round, Train loss: 0.552, Test loss: 0.863, Test accuracy: 68.90
Average accuracy final 10 rounds: 69.476
996.2283878326416
[1.613447904586792, 2.8984134197235107, 4.181241035461426, 5.468992710113525, 6.753523826599121, 8.034929752349854, 9.318427324295044, 10.60258150100708, 11.896620512008667, 13.182135343551636, 14.466046571731567, 15.746808290481567, 17.028767585754395, 18.312564373016357, 19.5937077999115, 20.87690281867981, 22.159574508666992, 23.443279504776, 24.727768421173096, 26.0103600025177, 27.29436731338501, 28.5766179561615, 29.858508586883545, 31.14085817337036, 32.42530632019043, 33.71072435379028, 34.99952936172485, 36.28441333770752, 37.571483850479126, 38.857961654663086, 40.14224076271057, 41.42676377296448, 42.70767331123352, 43.99342679977417, 45.27878379821777, 46.562877893447876, 47.846519231796265, 49.13278603553772, 50.416651487350464, 51.70053195953369, 52.978240728378296, 54.26070785522461, 55.54676055908203, 56.83398652076721, 58.121419191360474, 59.404828786849976, 60.57958436012268, 61.75141215324402, 62.92226529121399, 64.07512426376343, 65.24369359016418, 66.40224409103394, 67.5671706199646, 68.72832918167114, 69.88898205757141, 71.03746914863586, 72.19186162948608, 73.3568389415741, 74.51016736030579, 75.66194033622742, 76.8299491405487, 78.00238919258118, 79.16638517379761, 80.33181619644165, 81.48447966575623, 82.65462064743042, 83.81932425498962, 84.98618340492249, 86.13827395439148, 87.30623698234558, 88.47694873809814, 89.64755725860596, 90.821284532547, 91.9862892627716, 93.1431143283844, 94.31229424476624, 95.48632454872131, 96.64099025726318, 97.81097078323364, 98.9771146774292, 100.13666534423828, 101.30526113510132, 102.45800161361694, 103.61777591705322, 104.777902841568, 105.9254994392395, 107.07435154914856, 108.21269726753235, 109.3765869140625, 110.54006600379944, 111.70440626144409, 112.87932062149048, 114.03274655342102, 115.17839908599854, 116.33422040939331, 117.49797248840332, 118.64960551261902, 119.80091404914856, 120.9623019695282, 122.11850833892822, 124.00448966026306]
[24.08, 29.65, 36.68, 38.22, 42.4, 47.29, 49.18, 50.8, 52.15, 53.33, 55.25, 55.88, 57.86, 57.55, 57.98, 58.0, 59.06, 60.56, 61.12, 61.89, 61.89, 62.3, 62.62, 62.6, 63.23, 64.06, 63.99, 64.57, 64.64, 64.68, 65.08, 64.67, 65.19, 65.69, 65.94, 65.58, 65.92, 65.71, 66.54, 66.71, 66.7, 67.24, 66.9, 67.1, 67.51, 67.86, 68.01, 68.53, 67.91, 68.15, 68.1, 68.45, 68.27, 67.82, 67.67, 68.01, 68.2, 68.42, 67.96, 68.05, 67.64, 68.3, 68.11, 67.71, 68.31, 68.44, 68.86, 69.11, 69.26, 68.69, 68.68, 68.98, 69.18, 69.39, 69.21, 68.85, 68.99, 68.54, 68.9, 69.15, 68.72, 69.34, 69.32, 69.39, 69.63, 69.52, 70.19, 69.77, 69.68, 69.48, 69.6, 69.34, 69.4, 69.47, 68.94, 69.83, 69.76, 69.72, 69.23, 69.47, 68.9]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.8 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 13, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 10, noise    level: 0.8000 
   Client 15, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 14, noise    level: 0.8000 
   Client 16, noise    level: 0.8000 
   Client 18, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 17, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 2.009, Test loss: 2.179, Test accuracy: 16.81
Round   1, Train loss: 1.708, Test loss: 1.973, Test accuracy: 28.28
Round   2, Train loss: 1.541, Test loss: 1.707, Test accuracy: 36.21
Round   3, Train loss: 1.441, Test loss: 1.623, Test accuracy: 38.94
Round   4, Train loss: 1.397, Test loss: 1.535, Test accuracy: 44.66
Round   5, Train loss: 1.376, Test loss: 1.369, Test accuracy: 48.34
Round   6, Train loss: 1.178, Test loss: 1.376, Test accuracy: 50.54
Round   7, Train loss: 1.315, Test loss: 1.281, Test accuracy: 52.63
Round   8, Train loss: 1.281, Test loss: 1.261, Test accuracy: 53.09
Round   9, Train loss: 1.341, Test loss: 1.230, Test accuracy: 54.27
Round  10, Train loss: 1.245, Test loss: 1.186, Test accuracy: 55.06
Round  11, Train loss: 1.177, Test loss: 1.176, Test accuracy: 56.37
Round  12, Train loss: 1.105, Test loss: 1.142, Test accuracy: 57.37
Round  13, Train loss: 1.153, Test loss: 1.134, Test accuracy: 57.85
Round  14, Train loss: 1.213, Test loss: 1.123, Test accuracy: 57.96
Round  15, Train loss: 1.092, Test loss: 1.082, Test accuracy: 60.13
Round  16, Train loss: 1.014, Test loss: 1.073, Test accuracy: 60.47
Round  17, Train loss: 1.091, Test loss: 1.059, Test accuracy: 60.64
Round  18, Train loss: 1.142, Test loss: 1.061, Test accuracy: 60.59
Round  19, Train loss: 1.025, Test loss: 1.049, Test accuracy: 61.16
Round  20, Train loss: 1.068, Test loss: 1.047, Test accuracy: 61.69
Round  21, Train loss: 1.014, Test loss: 1.030, Test accuracy: 62.06
Round  22, Train loss: 1.074, Test loss: 1.051, Test accuracy: 61.35
Round  23, Train loss: 0.950, Test loss: 1.023, Test accuracy: 61.92
Round  24, Train loss: 1.074, Test loss: 0.973, Test accuracy: 63.89
Round  25, Train loss: 0.959, Test loss: 0.985, Test accuracy: 64.24
Round  26, Train loss: 1.010, Test loss: 0.970, Test accuracy: 64.53
Round  27, Train loss: 1.014, Test loss: 0.973, Test accuracy: 64.73
Round  28, Train loss: 0.996, Test loss: 0.958, Test accuracy: 65.86
Round  29, Train loss: 1.034, Test loss: 0.957, Test accuracy: 65.70
Round  30, Train loss: 0.929, Test loss: 0.944, Test accuracy: 66.40
Round  31, Train loss: 1.002, Test loss: 0.937, Test accuracy: 66.26
Round  32, Train loss: 0.998, Test loss: 0.944, Test accuracy: 66.16
Round  33, Train loss: 0.954, Test loss: 0.930, Test accuracy: 66.82
Round  34, Train loss: 0.892, Test loss: 0.917, Test accuracy: 66.89
Round  35, Train loss: 0.836, Test loss: 0.910, Test accuracy: 66.94
Round  36, Train loss: 1.059, Test loss: 0.906, Test accuracy: 67.08
Round  37, Train loss: 0.866, Test loss: 0.899, Test accuracy: 67.50
Round  38, Train loss: 0.803, Test loss: 0.884, Test accuracy: 68.51
Round  39, Train loss: 0.871, Test loss: 0.902, Test accuracy: 67.52
Round  40, Train loss: 0.906, Test loss: 0.892, Test accuracy: 68.07
Round  41, Train loss: 0.802, Test loss: 0.882, Test accuracy: 68.67
Round  42, Train loss: 0.819, Test loss: 0.888, Test accuracy: 68.62
Round  43, Train loss: 0.963, Test loss: 0.873, Test accuracy: 69.43
Round  44, Train loss: 0.907, Test loss: 0.887, Test accuracy: 68.67
Round  45, Train loss: 0.849, Test loss: 0.867, Test accuracy: 69.24
Round  46, Train loss: 0.912, Test loss: 0.861, Test accuracy: 69.55
Round  47, Train loss: 0.848, Test loss: 0.863, Test accuracy: 69.53
Round  48, Train loss: 0.935, Test loss: 0.852, Test accuracy: 69.72
Round  49, Train loss: 0.781, Test loss: 0.867, Test accuracy: 69.50
Round  50, Train loss: 0.838, Test loss: 0.869, Test accuracy: 69.31
Round  51, Train loss: 0.747, Test loss: 0.861, Test accuracy: 69.98
Round  52, Train loss: 0.953, Test loss: 0.851, Test accuracy: 69.97
Round  53, Train loss: 0.720, Test loss: 0.849, Test accuracy: 70.31
Round  54, Train loss: 0.902, Test loss: 0.847, Test accuracy: 70.56
Round  55, Train loss: 0.832, Test loss: 0.851, Test accuracy: 70.08
Round  56, Train loss: 0.916, Test loss: 0.842, Test accuracy: 70.21
Round  57, Train loss: 0.751, Test loss: 0.826, Test accuracy: 70.93
Round  58, Train loss: 0.819, Test loss: 0.833, Test accuracy: 70.81
Round  59, Train loss: 0.737, Test loss: 0.832, Test accuracy: 70.78
Round  60, Train loss: 0.843, Test loss: 0.836, Test accuracy: 70.49
Round  61, Train loss: 0.793, Test loss: 0.829, Test accuracy: 70.60
Round  62, Train loss: 0.890, Test loss: 0.825, Test accuracy: 71.17
Round  63, Train loss: 0.799, Test loss: 0.816, Test accuracy: 71.36
Round  64, Train loss: 0.765, Test loss: 0.824, Test accuracy: 71.09
Round  65, Train loss: 0.840, Test loss: 0.817, Test accuracy: 71.12
Round  66, Train loss: 0.833, Test loss: 0.819, Test accuracy: 71.20
Round  67, Train loss: 0.822, Test loss: 0.832, Test accuracy: 70.89
Round  68, Train loss: 0.715, Test loss: 0.831, Test accuracy: 71.17
Round  69, Train loss: 0.727, Test loss: 0.824, Test accuracy: 71.22
Round  70, Train loss: 0.747, Test loss: 0.832, Test accuracy: 70.63
Round  71, Train loss: 0.765, Test loss: 0.828, Test accuracy: 70.78
Round  72, Train loss: 0.777, Test loss: 0.833, Test accuracy: 70.67
Round  73, Train loss: 0.694, Test loss: 0.831, Test accuracy: 70.89
Round  74, Train loss: 0.807, Test loss: 0.818, Test accuracy: 71.43
Round  75, Train loss: 0.714, Test loss: 0.836, Test accuracy: 70.17
Round  76, Train loss: 0.727, Test loss: 0.834, Test accuracy: 70.58
Round  77, Train loss: 0.714, Test loss: 0.828, Test accuracy: 70.60
Round  78, Train loss: 0.809, Test loss: 0.819, Test accuracy: 71.07
Round  79, Train loss: 0.754, Test loss: 0.820, Test accuracy: 71.40
Round  80, Train loss: 0.686, Test loss: 0.823, Test accuracy: 71.12
Round  81, Train loss: 0.641, Test loss: 0.822, Test accuracy: 71.14
Round  82, Train loss: 0.581, Test loss: 0.824, Test accuracy: 70.87
Round  83, Train loss: 0.642, Test loss: 0.835, Test accuracy: 70.29
Round  84, Train loss: 0.656, Test loss: 0.818, Test accuracy: 71.37
Round  85, Train loss: 0.665, Test loss: 0.822, Test accuracy: 71.51
Round  86, Train loss: 0.549, Test loss: 0.816, Test accuracy: 71.44
Round  87, Train loss: 0.610, Test loss: 0.804, Test accuracy: 71.86
Round  88, Train loss: 0.739, Test loss: 0.815, Test accuracy: 71.55
Round  89, Train loss: 0.572, Test loss: 0.815, Test accuracy: 71.55
Round  90, Train loss: 0.569, Test loss: 0.819, Test accuracy: 71.35
Round  91, Train loss: 0.744, Test loss: 0.818, Test accuracy: 71.32
Round  92, Train loss: 0.643, Test loss: 0.824, Test accuracy: 71.04
Round  93, Train loss: 0.624, Test loss: 0.824, Test accuracy: 71.10
Round  94, Train loss: 0.554, Test loss: 0.819, Test accuracy: 71.85
Round  95, Train loss: 0.691, Test loss: 0.832, Test accuracy: 70.95
Round  96, Train loss: 0.582, Test loss: 0.819, Test accuracy: 71.06
Round  97, Train loss: 0.595, Test loss: 0.826, Test accuracy: 71.39
Round  98, Train loss: 0.495, Test loss: 0.815, Test accuracy: 71.80
Round  99, Train loss: 0.488, Test loss: 0.826, Test accuracy: 71.35
Final Round, Train loss: 0.399, Test loss: 0.825, Test accuracy: 71.49
Average accuracy final 10 rounds: 71.32100000000001
1376.8177947998047
[1.5291247367858887, 2.761596202850342, 3.9921512603759766, 5.227876663208008, 6.504236698150635, 7.779915809631348, 9.058136224746704, 10.335056781768799, 11.604619026184082, 12.8723464012146, 14.139952421188354, 15.40683889389038, 16.674233436584473, 17.95260739326477, 19.227538347244263, 20.504485607147217, 21.779112815856934, 23.056065559387207, 24.331664085388184, 25.60330319404602, 26.878183841705322, 29.038578510284424, 31.18915820121765, 33.33461952209473, 35.479257345199585, 37.626035928726196, 39.76641249656677, 41.914635181427, 44.05481934547424, 46.19710421562195, 48.3428053855896, 50.491920709609985, 52.630842447280884, 54.7754020690918, 56.92351198196411, 59.07182335853577, 61.218483686447144, 63.361793756484985, 65.50006318092346, 67.64181399345398, 69.78082656860352, 71.92941308021545, 74.07549715042114, 76.22162914276123, 78.36122465133667, 80.50433778762817, 82.6457588672638, 84.79316258430481, 87.01000738143921, 89.16132521629333, 91.30639433860779, 93.45344948768616, 95.59629321098328, 97.7379629611969, 99.88932943344116, 101.9129467010498, 103.90500807762146, 105.89931297302246, 107.89851140975952, 109.89294004440308, 111.89221787452698, 113.89500188827515, 115.88836431503296, 117.8950548171997, 119.89783430099487, 121.88956832885742, 123.8810920715332, 125.87283873558044, 127.86005067825317, 129.86740279197693, 131.8774857521057, 133.88795566558838, 135.89804911613464, 137.9120328426361, 139.85933017730713, 141.86571598052979, 143.8708095550537, 145.87872076034546, 147.88697004318237, 149.89624214172363, 151.91328835487366, 153.92271661758423, 155.9368999004364, 157.9521505832672, 159.96022653579712, 161.96675157546997, 163.9814257621765, 165.9843466281891, 168.00565767288208, 170.0242977142334, 172.03998231887817, 174.0962302684784, 176.1069962978363, 178.08931374549866, 180.10601949691772, 182.12259125709534, 184.1407127380371, 186.15157532691956, 188.1616427898407, 190.10837388038635, 191.97958827018738]
[16.81, 28.28, 36.21, 38.94, 44.66, 48.34, 50.54, 52.63, 53.09, 54.27, 55.06, 56.37, 57.37, 57.85, 57.96, 60.13, 60.47, 60.64, 60.59, 61.16, 61.69, 62.06, 61.35, 61.92, 63.89, 64.24, 64.53, 64.73, 65.86, 65.7, 66.4, 66.26, 66.16, 66.82, 66.89, 66.94, 67.08, 67.5, 68.51, 67.52, 68.07, 68.67, 68.62, 69.43, 68.67, 69.24, 69.55, 69.53, 69.72, 69.5, 69.31, 69.98, 69.97, 70.31, 70.56, 70.08, 70.21, 70.93, 70.81, 70.78, 70.49, 70.6, 71.17, 71.36, 71.09, 71.12, 71.2, 70.89, 71.17, 71.22, 70.63, 70.78, 70.67, 70.89, 71.43, 70.17, 70.58, 70.6, 71.07, 71.4, 71.12, 71.14, 70.87, 70.29, 71.37, 71.51, 71.44, 71.86, 71.55, 71.55, 71.35, 71.32, 71.04, 71.1, 71.85, 70.95, 71.06, 71.39, 71.8, 71.35, 71.49]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: none, level_n_system: 0.8 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 9, noise    level: 0.8000 
   Client 11, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
   Client 17, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 12, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 13, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 19, noise    level: 0.8000 
   Client 16, noise    level: 0.8000 
   Client 18, noise    level: 0.8000 
   Client 15, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 10, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.983, Test loss: 1.918, Test accuracy: 27.86
Round   1, Train loss: 1.646, Test loss: 1.532, Test accuracy: 38.96
Round   2, Train loss: 1.484, Test loss: 1.365, Test accuracy: 44.61
Round   3, Train loss: 1.381, Test loss: 1.266, Test accuracy: 50.00
Round   4, Train loss: 1.309, Test loss: 1.213, Test accuracy: 51.95
Round   5, Train loss: 1.256, Test loss: 1.165, Test accuracy: 53.89
Round   6, Train loss: 1.218, Test loss: 1.130, Test accuracy: 56.05
Round   7, Train loss: 1.185, Test loss: 1.094, Test accuracy: 57.63
Round   8, Train loss: 1.155, Test loss: 1.066, Test accuracy: 58.93
Round   9, Train loss: 1.133, Test loss: 1.047, Test accuracy: 60.04
Round  10, Train loss: 1.112, Test loss: 1.019, Test accuracy: 61.13
Round  11, Train loss: 1.090, Test loss: 1.009, Test accuracy: 61.69
Round  12, Train loss: 1.075, Test loss: 0.995, Test accuracy: 62.19
Round  13, Train loss: 1.058, Test loss: 0.978, Test accuracy: 63.23
Round  14, Train loss: 1.045, Test loss: 0.961, Test accuracy: 63.84
Round  15, Train loss: 1.023, Test loss: 0.949, Test accuracy: 64.41
Round  16, Train loss: 1.012, Test loss: 0.932, Test accuracy: 64.78
Round  17, Train loss: 0.996, Test loss: 0.932, Test accuracy: 64.93
Round  18, Train loss: 0.983, Test loss: 0.918, Test accuracy: 65.72
Round  19, Train loss: 0.971, Test loss: 0.903, Test accuracy: 65.85
Round  20, Train loss: 0.972, Test loss: 0.913, Test accuracy: 65.29
Round  21, Train loss: 0.913, Test loss: 0.910, Test accuracy: 65.21
Round  22, Train loss: 0.961, Test loss: 0.904, Test accuracy: 65.57
Round  23, Train loss: 0.890, Test loss: 0.896, Test accuracy: 65.65
Round  24, Train loss: 0.876, Test loss: 0.877, Test accuracy: 67.04
Round  25, Train loss: 0.967, Test loss: 0.875, Test accuracy: 67.39
Round  26, Train loss: 0.858, Test loss: 0.879, Test accuracy: 67.34
Round  27, Train loss: 0.925, Test loss: 0.867, Test accuracy: 67.64
Round  28, Train loss: 0.790, Test loss: 0.862, Test accuracy: 67.85
Round  29, Train loss: 0.717, Test loss: 0.864, Test accuracy: 67.60
Round  30, Train loss: 0.788, Test loss: 0.859, Test accuracy: 67.26
Round  31, Train loss: 0.839, Test loss: 0.851, Test accuracy: 68.28
Round  32, Train loss: 0.863, Test loss: 0.839, Test accuracy: 68.62
Round  33, Train loss: 0.867, Test loss: 0.834, Test accuracy: 68.90
Round  34, Train loss: 0.828, Test loss: 0.839, Test accuracy: 68.55
Round  35, Train loss: 0.765, Test loss: 0.832, Test accuracy: 69.09
Round  36, Train loss: 0.778, Test loss: 0.828, Test accuracy: 69.33
Round  37, Train loss: 0.924, Test loss: 0.821, Test accuracy: 69.64
Round  38, Train loss: 0.824, Test loss: 0.820, Test accuracy: 69.57
Round  39, Train loss: 0.822, Test loss: 0.806, Test accuracy: 69.85
Round  40, Train loss: 0.700, Test loss: 0.814, Test accuracy: 69.51
Round  41, Train loss: 0.673, Test loss: 0.805, Test accuracy: 69.90
Round  42, Train loss: 0.704, Test loss: 0.796, Test accuracy: 70.38
Round  43, Train loss: 0.788, Test loss: 0.793, Test accuracy: 70.69
Round  44, Train loss: 0.842, Test loss: 0.798, Test accuracy: 70.69
Round  45, Train loss: 0.808, Test loss: 0.801, Test accuracy: 70.26
Round  46, Train loss: 0.697, Test loss: 0.792, Test accuracy: 70.83
Round  47, Train loss: 0.828, Test loss: 0.787, Test accuracy: 71.04
Round  48, Train loss: 0.776, Test loss: 0.795, Test accuracy: 70.42
Round  49, Train loss: 0.751, Test loss: 0.789, Test accuracy: 70.81
Round  50, Train loss: 0.810, Test loss: 0.787, Test accuracy: 71.10
Round  51, Train loss: 0.702, Test loss: 0.800, Test accuracy: 70.21
Round  52, Train loss: 0.696, Test loss: 0.798, Test accuracy: 70.35
Round  53, Train loss: 0.588, Test loss: 0.789, Test accuracy: 70.89
Round  54, Train loss: 0.791, Test loss: 0.779, Test accuracy: 71.31
Round  55, Train loss: 0.713, Test loss: 0.778, Test accuracy: 70.90
Round  56, Train loss: 0.740, Test loss: 0.778, Test accuracy: 71.06
Round  57, Train loss: 0.674, Test loss: 0.784, Test accuracy: 71.29
Round  58, Train loss: 0.721, Test loss: 0.785, Test accuracy: 71.03
Round  59, Train loss: 0.484, Test loss: 0.776, Test accuracy: 71.43
Round  60, Train loss: 0.633, Test loss: 0.787, Test accuracy: 71.11
Round  61, Train loss: 0.535, Test loss: 0.779, Test accuracy: 71.21
Round  62, Train loss: 0.736, Test loss: 0.775, Test accuracy: 71.55
Round  63, Train loss: 0.635, Test loss: 0.770, Test accuracy: 71.90
Round  64, Train loss: 0.654, Test loss: 0.784, Test accuracy: 71.08
Round  65, Train loss: 0.665, Test loss: 0.777, Test accuracy: 71.52
Round  66, Train loss: 0.721, Test loss: 0.775, Test accuracy: 71.57
Round  67, Train loss: 0.785, Test loss: 0.779, Test accuracy: 71.57
Round  68, Train loss: 0.583, Test loss: 0.773, Test accuracy: 72.09
Round  69, Train loss: 0.578, Test loss: 0.766, Test accuracy: 72.00
Round  70, Train loss: 0.583, Test loss: 0.776, Test accuracy: 71.88
Round  71, Train loss: 0.621, Test loss: 0.771, Test accuracy: 72.02
Round  72, Train loss: 0.626, Test loss: 0.772, Test accuracy: 71.84
Round  73, Train loss: 0.693, Test loss: 0.771, Test accuracy: 72.17
Round  74, Train loss: 0.619, Test loss: 0.782, Test accuracy: 71.40
Round  75, Train loss: 0.724, Test loss: 0.776, Test accuracy: 71.51
Round  76, Train loss: 0.502, Test loss: 0.762, Test accuracy: 72.51
Round  77, Train loss: 0.587, Test loss: 0.772, Test accuracy: 72.32
Round  78, Train loss: 0.601, Test loss: 0.762, Test accuracy: 72.62
Round  79, Train loss: 0.633, Test loss: 0.765, Test accuracy: 72.57
Round  80, Train loss: 0.426, Test loss: 0.763, Test accuracy: 72.16
Round  81, Train loss: 0.401, Test loss: 0.775, Test accuracy: 72.01
Round  82, Train loss: 0.390, Test loss: 0.759, Test accuracy: 72.38
Round  83, Train loss: 0.382, Test loss: 0.768, Test accuracy: 72.15
Round  84, Train loss: 0.370, Test loss: 0.773, Test accuracy: 72.06
Round  85, Train loss: 0.367, Test loss: 0.773, Test accuracy: 72.05
Round  86, Train loss: 0.359, Test loss: 0.766, Test accuracy: 72.54
Round  87, Train loss: 0.349, Test loss: 0.772, Test accuracy: 72.51
Round  88, Train loss: 0.344, Test loss: 0.784, Test accuracy: 72.19
Round  89, Train loss: 0.341, Test loss: 0.782, Test accuracy: 72.06
Round  90, Train loss: 0.329, Test loss: 0.792, Test accuracy: 71.98
Round  91, Train loss: 0.321, Test loss: 0.789, Test accuracy: 71.99
Round  92, Train loss: 0.322, Test loss: 0.787, Test accuracy: 71.93
Round  93, Train loss: 0.314, Test loss: 0.785, Test accuracy: 72.03
Round  94, Train loss: 0.315, Test loss: 0.789, Test accuracy: 72.09
Round  95, Train loss: 0.303, Test loss: 0.792, Test accuracy: 71.84
Round  96, Train loss: 0.302, Test loss: 0.796, Test accuracy: 71.81
Round  97, Train loss: 0.292, Test loss: 0.793, Test accuracy: 71.97
Round  98, Train loss: 0.277, Test loss: 0.802, Test accuracy: 72.17
Round  99, Train loss: 0.278, Test loss: 0.794, Test accuracy: 72.26
Final Round, Train loss: 0.209, Test loss: 0.799, Test accuracy: 72.42
Average accuracy final 10 rounds: 72.007
1461.6796457767487
[1.5284905433654785, 2.801482915878296, 4.0769171714782715, 5.35163950920105, 6.626405954360962, 7.899919033050537, 9.173776388168335, 10.447290658950806, 11.720089673995972, 12.99327039718628, 14.260846376419067, 15.526190757751465, 16.795886039733887, 18.06365704536438, 19.33243179321289, 20.599805116653442, 21.868014574050903, 23.136258125305176, 24.404106855392456, 25.682074069976807, 26.94785785675049, 28.21340274810791, 29.48080325126648, 30.744704723358154, 32.01448607444763, 33.282339096069336, 34.550660610198975, 35.81732392311096, 37.08481287956238, 38.34830117225647, 39.61585354804993, 40.88486194610596, 42.14734220504761, 43.41388130187988, 44.68115830421448, 45.949779987335205, 47.215303897857666, 48.48184084892273, 49.74747562408447, 51.014570236206055, 52.280869007110596, 53.543978452682495, 54.81469798088074, 56.085410594940186, 57.35574173927307, 58.62822079658508, 59.897711992263794, 61.166306257247925, 62.43576431274414, 63.70477056503296, 64.97139644622803, 66.24043798446655, 67.50972867012024, 68.77991485595703, 70.0492947101593, 71.3193724155426, 72.5868616104126, 73.85946941375732, 75.13161253929138, 76.39844799041748, 77.66922783851624, 78.93682765960693, 80.20939254760742, 81.48031234741211, 82.74950647354126, 84.01837635040283, 85.28643417358398, 86.5559241771698, 87.8230893611908, 89.09420251846313, 90.36355566978455, 91.63257718086243, 92.90353608131409, 94.17383575439453, 95.44213652610779, 96.71161222457886, 97.98149108886719, 99.24844717979431, 100.51748585700989, 101.78625655174255, 103.05510067939758, 104.3234531879425, 105.59207034111023, 106.8619019985199, 108.13117241859436, 109.406893491745, 110.68311166763306, 111.95257663726807, 113.22349572181702, 114.49291253089905, 115.7640700340271, 117.03826951980591, 118.30842447280884, 119.5788836479187, 120.850093126297, 122.12264204025269, 123.39306116104126, 124.66430163383484, 125.93505907058716, 127.20551085472107, 129.1631202697754]
[27.86, 38.96, 44.61, 50.0, 51.95, 53.89, 56.05, 57.63, 58.93, 60.04, 61.13, 61.69, 62.19, 63.23, 63.84, 64.41, 64.78, 64.93, 65.72, 65.85, 65.29, 65.21, 65.57, 65.65, 67.04, 67.39, 67.34, 67.64, 67.85, 67.6, 67.26, 68.28, 68.62, 68.9, 68.55, 69.09, 69.33, 69.64, 69.57, 69.85, 69.51, 69.9, 70.38, 70.69, 70.69, 70.26, 70.83, 71.04, 70.42, 70.81, 71.1, 70.21, 70.35, 70.89, 71.31, 70.9, 71.06, 71.29, 71.03, 71.43, 71.11, 71.21, 71.55, 71.9, 71.08, 71.52, 71.57, 71.57, 72.09, 72.0, 71.88, 72.02, 71.84, 72.17, 71.4, 71.51, 72.51, 72.32, 72.62, 72.57, 72.16, 72.01, 72.38, 72.15, 72.06, 72.05, 72.54, 72.51, 72.19, 72.06, 71.98, 71.99, 71.93, 72.03, 72.09, 71.84, 71.81, 71.97, 72.17, 72.26, 72.42]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.8 , level_n_lowerb:0.8  

Files already downloaded and verified
Files already downloaded and verified
   Client 15, noise    level: 0.8000 
   Client 17, noise    level: 0.8000 
   Client 12, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 18, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 11, noise    level: 0.8000 
   Client 16, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 14, noise    level: 0.8000 
   Client 10, noise    level: 0.8000 
   Client 13, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 2.000, Test loss: 1.915, Test accuracy: 26.51
Round   1, Train loss: 1.665, Test loss: 1.540, Test accuracy: 37.96
Round   2, Train loss: 1.519, Test loss: 1.399, Test accuracy: 43.99
Round   3, Train loss: 1.415, Test loss: 1.278, Test accuracy: 50.13
Round   4, Train loss: 1.338, Test loss: 1.218, Test accuracy: 53.48
Round   5, Train loss: 1.286, Test loss: 1.176, Test accuracy: 54.69
Round   6, Train loss: 1.246, Test loss: 1.135, Test accuracy: 57.07
Round   7, Train loss: 1.214, Test loss: 1.119, Test accuracy: 57.34
Round   8, Train loss: 1.191, Test loss: 1.101, Test accuracy: 58.38
Round   9, Train loss: 1.171, Test loss: 1.075, Test accuracy: 58.82
Round  10, Train loss: 1.150, Test loss: 1.061, Test accuracy: 60.13
Round  11, Train loss: 1.130, Test loss: 1.035, Test accuracy: 61.62
Round  12, Train loss: 1.110, Test loss: 1.034, Test accuracy: 61.22
Round  13, Train loss: 1.094, Test loss: 1.007, Test accuracy: 62.31
Round  14, Train loss: 1.080, Test loss: 1.003, Test accuracy: 62.74
Round  15, Train loss: 1.063, Test loss: 0.989, Test accuracy: 63.05
Round  16, Train loss: 1.045, Test loss: 0.976, Test accuracy: 63.72
Round  17, Train loss: 1.038, Test loss: 0.972, Test accuracy: 63.82
Round  18, Train loss: 1.025, Test loss: 0.950, Test accuracy: 64.42
Round  19, Train loss: 1.011, Test loss: 0.946, Test accuracy: 65.08
Round  20, Train loss: 1.053, Test loss: 0.940, Test accuracy: 65.36
Round  21, Train loss: 1.002, Test loss: 0.941, Test accuracy: 65.02
Round  22, Train loss: 1.032, Test loss: 0.937, Test accuracy: 65.02
Round  23, Train loss: 1.007, Test loss: 0.929, Test accuracy: 65.51
Round  24, Train loss: 0.943, Test loss: 0.922, Test accuracy: 65.64
Round  25, Train loss: 0.817, Test loss: 0.936, Test accuracy: 64.98
Round  26, Train loss: 0.793, Test loss: 0.922, Test accuracy: 65.87
Round  27, Train loss: 1.037, Test loss: 0.910, Test accuracy: 66.20
Round  28, Train loss: 0.763, Test loss: 0.901, Test accuracy: 66.85
Round  29, Train loss: 0.926, Test loss: 0.891, Test accuracy: 66.95
Round  30, Train loss: 0.852, Test loss: 0.896, Test accuracy: 66.82
Round  31, Train loss: 0.806, Test loss: 0.889, Test accuracy: 67.18
Round  32, Train loss: 1.029, Test loss: 0.889, Test accuracy: 67.13
Round  33, Train loss: 0.823, Test loss: 0.885, Test accuracy: 66.97
Round  34, Train loss: 0.888, Test loss: 0.882, Test accuracy: 67.19
Round  35, Train loss: 0.915, Test loss: 0.877, Test accuracy: 67.49
Round  36, Train loss: 0.805, Test loss: 0.876, Test accuracy: 67.45
Round  37, Train loss: 0.869, Test loss: 0.873, Test accuracy: 67.82
Round  38, Train loss: 0.798, Test loss: 0.861, Test accuracy: 68.16
Round  39, Train loss: 0.823, Test loss: 0.869, Test accuracy: 68.38
Round  40, Train loss: 0.867, Test loss: 0.851, Test accuracy: 68.48
Round  41, Train loss: 0.799, Test loss: 0.849, Test accuracy: 69.01
Round  42, Train loss: 0.894, Test loss: 0.849, Test accuracy: 68.82
Round  43, Train loss: 0.935, Test loss: 0.844, Test accuracy: 69.22
Round  44, Train loss: 0.910, Test loss: 0.855, Test accuracy: 68.98
Round  45, Train loss: 0.796, Test loss: 0.844, Test accuracy: 69.22
Round  46, Train loss: 0.790, Test loss: 0.835, Test accuracy: 69.71
Round  47, Train loss: 0.739, Test loss: 0.836, Test accuracy: 69.26
Round  48, Train loss: 0.691, Test loss: 0.837, Test accuracy: 69.38
Round  49, Train loss: 0.794, Test loss: 0.840, Test accuracy: 69.33
Round  50, Train loss: 0.965, Test loss: 0.839, Test accuracy: 68.91
Round  51, Train loss: 0.750, Test loss: 0.843, Test accuracy: 69.19
Round  52, Train loss: 0.672, Test loss: 0.831, Test accuracy: 68.96
Round  53, Train loss: 0.637, Test loss: 0.835, Test accuracy: 69.06
Round  54, Train loss: 1.025, Test loss: 0.813, Test accuracy: 70.40
Round  55, Train loss: 0.864, Test loss: 0.838, Test accuracy: 69.36
Round  56, Train loss: 0.889, Test loss: 0.828, Test accuracy: 69.74
Round  57, Train loss: 0.640, Test loss: 0.826, Test accuracy: 69.83
Round  58, Train loss: 0.772, Test loss: 0.829, Test accuracy: 69.77
Round  59, Train loss: 0.648, Test loss: 0.823, Test accuracy: 69.90
Round  60, Train loss: 0.615, Test loss: 0.831, Test accuracy: 69.72
Round  61, Train loss: 0.812, Test loss: 0.832, Test accuracy: 69.78
Round  62, Train loss: 0.704, Test loss: 0.838, Test accuracy: 69.43
Round  63, Train loss: 0.760, Test loss: 0.824, Test accuracy: 69.99
Round  64, Train loss: 0.693, Test loss: 0.828, Test accuracy: 70.11
Round  65, Train loss: 0.785, Test loss: 0.806, Test accuracy: 70.73
Round  66, Train loss: 0.678, Test loss: 0.817, Test accuracy: 70.58
Round  67, Train loss: 0.779, Test loss: 0.819, Test accuracy: 70.30
Round  68, Train loss: 0.760, Test loss: 0.839, Test accuracy: 69.89
Round  69, Train loss: 0.612, Test loss: 0.823, Test accuracy: 70.24
Round  70, Train loss: 0.622, Test loss: 0.842, Test accuracy: 69.91
Round  71, Train loss: 0.596, Test loss: 0.841, Test accuracy: 70.19
Round  72, Train loss: 0.816, Test loss: 0.832, Test accuracy: 69.92
Round  73, Train loss: 0.610, Test loss: 0.824, Test accuracy: 70.22
Round  74, Train loss: 0.796, Test loss: 0.821, Test accuracy: 71.17
Round  75, Train loss: 0.610, Test loss: 0.822, Test accuracy: 70.22
Round  76, Train loss: 0.501, Test loss: 0.811, Test accuracy: 70.95
Round  77, Train loss: 0.553, Test loss: 0.829, Test accuracy: 70.49
Round  78, Train loss: 0.635, Test loss: 0.809, Test accuracy: 71.14
Round  79, Train loss: 0.604, Test loss: 0.811, Test accuracy: 70.88
Round  80, Train loss: 0.427, Test loss: 0.805, Test accuracy: 71.05
Round  81, Train loss: 0.408, Test loss: 0.809, Test accuracy: 70.84
Round  82, Train loss: 0.400, Test loss: 0.809, Test accuracy: 71.00
Round  83, Train loss: 0.389, Test loss: 0.817, Test accuracy: 70.73
Round  84, Train loss: 0.378, Test loss: 0.820, Test accuracy: 70.46
Round  85, Train loss: 0.369, Test loss: 0.817, Test accuracy: 70.71
Round  86, Train loss: 0.365, Test loss: 0.815, Test accuracy: 70.47
Round  87, Train loss: 0.353, Test loss: 0.823, Test accuracy: 70.59
Round  88, Train loss: 0.355, Test loss: 0.828, Test accuracy: 70.45
Round  89, Train loss: 0.350, Test loss: 0.825, Test accuracy: 70.77
Round  90, Train loss: 0.337, Test loss: 0.827, Test accuracy: 70.57
Round  91, Train loss: 0.326, Test loss: 0.831, Test accuracy: 70.63
Round  92, Train loss: 0.322, Test loss: 0.833, Test accuracy: 70.89
Round  93, Train loss: 0.319, Test loss: 0.828, Test accuracy: 70.87
Round  94, Train loss: 0.313, Test loss: 0.837, Test accuracy: 70.75
Round  95, Train loss: 0.312, Test loss: 0.845, Test accuracy: 70.29
Round  96, Train loss: 0.302, Test loss: 0.846, Test accuracy: 70.46
Round  97, Train loss: 0.301, Test loss: 0.849, Test accuracy: 70.52
Round  98, Train loss: 0.294, Test loss: 0.847, Test accuracy: 70.72
Round  99, Train loss: 0.290, Test loss: 0.846, Test accuracy: 70.73
Final Round, Train loss: 0.220, Test loss: 0.853, Test accuracy: 70.61
Average accuracy final 10 rounds: 70.643
1957.4193148612976
[1.6251521110534668, 2.9373068809509277, 4.243179082870483, 5.549447298049927, 6.852689743041992, 8.153772592544556, 9.452374696731567, 10.740838527679443, 12.026641368865967, 13.311272859573364, 14.59761095046997, 15.893839836120605, 17.20580554008484, 18.518903493881226, 19.813204288482666, 21.105420351028442, 22.399677276611328, 23.71400260925293, 25.03352665901184, 26.356544256210327, 27.673933506011963, 29.882112979888916, 32.07156538963318, 34.25194525718689, 36.431108474731445, 38.60305833816528, 40.79707908630371, 42.98708438873291, 45.17206621170044, 47.353230237960815, 49.530975341796875, 51.67923069000244, 53.83745265007019, 55.98457098007202, 58.13564443588257, 60.28836750984192, 62.44237160682678, 64.59168148040771, 66.74637722969055, 68.89699053764343, 71.04517912864685, 73.20221543312073, 75.35861301422119, 77.5084936618805, 79.65759420394897, 81.81260800361633, 83.96163868904114, 86.11757373809814, 88.34738898277283, 90.50397968292236, 92.6537504196167, 94.80354118347168, 96.95996713638306, 99.11719942092896, 101.26939272880554, 103.42276167869568, 105.57424449920654, 107.73529100418091, 109.88954663276672, 112.04674124717712, 114.15031409263611, 116.30268740653992, 118.45139932632446, 120.60980224609375, 122.76824164390564, 124.93294191360474, 127.04957365989685, 129.21295428276062, 131.3817982673645, 133.546044588089, 135.70518040657043, 137.86049151420593, 139.98176383972168, 142.1382133960724, 144.30280232429504, 146.45735335350037, 148.6069519519806, 150.76374006271362, 152.8968584537506, 155.05584168434143, 157.21842312812805, 159.3739194869995, 161.52102994918823, 163.67258191108704, 165.82409024238586, 167.97586369514465, 170.1970133781433, 172.35165762901306, 174.50005269050598, 176.64901733398438, 178.80586433410645, 180.9539783000946, 183.1044921875, 185.26133751869202, 187.40139293670654, 189.5597529411316, 191.71250224113464, 193.86668586730957, 196.01320600509644, 198.16953802108765, 200.2297158241272]
[26.51, 37.96, 43.99, 50.13, 53.48, 54.69, 57.07, 57.34, 58.38, 58.82, 60.13, 61.62, 61.22, 62.31, 62.74, 63.05, 63.72, 63.82, 64.42, 65.08, 65.36, 65.02, 65.02, 65.51, 65.64, 64.98, 65.87, 66.2, 66.85, 66.95, 66.82, 67.18, 67.13, 66.97, 67.19, 67.49, 67.45, 67.82, 68.16, 68.38, 68.48, 69.01, 68.82, 69.22, 68.98, 69.22, 69.71, 69.26, 69.38, 69.33, 68.91, 69.19, 68.96, 69.06, 70.4, 69.36, 69.74, 69.83, 69.77, 69.9, 69.72, 69.78, 69.43, 69.99, 70.11, 70.73, 70.58, 70.3, 69.89, 70.24, 69.91, 70.19, 69.92, 70.22, 71.17, 70.22, 70.95, 70.49, 71.14, 70.88, 71.05, 70.84, 71.0, 70.73, 70.46, 70.71, 70.47, 70.59, 70.45, 70.77, 70.57, 70.63, 70.89, 70.87, 70.75, 70.29, 70.46, 70.52, 70.72, 70.73, 70.61]
