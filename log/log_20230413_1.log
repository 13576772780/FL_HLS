nohup: 忽略输入
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.438, Test loss: 1.348, Test accuracy: 48.52 

Round   0, Global train loss: 1.438, Global test loss: 2.369, Global test accuracy: 15.08 

Round   1, Train loss: 1.116, Test loss: 1.459, Test accuracy: 54.84 

Round   1, Global train loss: 1.116, Global test loss: 2.498, Global test accuracy: 15.32 

Round   2, Train loss: 0.955, Test loss: 1.223, Test accuracy: 56.96 

Round   2, Global train loss: 0.955, Global test loss: 2.557, Global test accuracy: 13.20 

Round   3, Train loss: 0.832, Test loss: 1.065, Test accuracy: 61.80 

Round   3, Global train loss: 0.832, Global test loss: 2.552, Global test accuracy: 13.96 

Round   4, Train loss: 0.706, Test loss: 1.388, Test accuracy: 58.36 

Round   4, Global train loss: 0.706, Global test loss: 2.518, Global test accuracy: 12.12 

Round   5, Train loss: 0.599, Test loss: 1.300, Test accuracy: 61.60 

Round   5, Global train loss: 0.599, Global test loss: 2.713, Global test accuracy: 14.92 

Round   6, Train loss: 0.500, Test loss: 1.577, Test accuracy: 61.36 

Round   6, Global train loss: 0.500, Global test loss: 2.734, Global test accuracy: 13.00 

Round   7, Train loss: 0.449, Test loss: 1.571, Test accuracy: 59.88 

Round   7, Global train loss: 0.449, Global test loss: 2.703, Global test accuracy: 15.24 

Round   8, Train loss: 0.356, Test loss: 1.517, Test accuracy: 62.60 

Round   8, Global train loss: 0.356, Global test loss: 2.841, Global test accuracy: 13.44 

Round   9, Train loss: 0.327, Test loss: 1.499, Test accuracy: 64.44 

Round   9, Global train loss: 0.327, Global test loss: 2.732, Global test accuracy: 13.36 

Round  10, Train loss: 0.263, Test loss: 1.550, Test accuracy: 64.48 

Round  10, Global train loss: 0.263, Global test loss: 2.867, Global test accuracy: 14.84 

Round  11, Train loss: 0.226, Test loss: 1.470, Test accuracy: 67.32 

Round  11, Global train loss: 0.226, Global test loss: 2.805, Global test accuracy: 12.28 

Round  12, Train loss: 0.201, Test loss: 1.561, Test accuracy: 66.60 

Round  12, Global train loss: 0.201, Global test loss: 2.999, Global test accuracy: 13.48 

Round  13, Train loss: 0.169, Test loss: 1.587, Test accuracy: 66.60 

Round  13, Global train loss: 0.169, Global test loss: 2.887, Global test accuracy: 12.00 

Round  14, Train loss: 0.147, Test loss: 1.687, Test accuracy: 64.44 

Round  14, Global train loss: 0.147, Global test loss: 2.992, Global test accuracy: 16.00 

Round  15, Train loss: 0.130, Test loss: 1.639, Test accuracy: 66.20 

Round  15, Global train loss: 0.130, Global test loss: 2.997, Global test accuracy: 13.00 

Round  16, Train loss: 0.120, Test loss: 1.605, Test accuracy: 67.08 

Round  16, Global train loss: 0.120, Global test loss: 2.971, Global test accuracy: 13.00 

Round  17, Train loss: 0.080, Test loss: 1.715, Test accuracy: 67.08 

Round  17, Global train loss: 0.080, Global test loss: 2.965, Global test accuracy: 12.20 

Round  18, Train loss: 0.071, Test loss: 1.619, Test accuracy: 67.52 

Round  18, Global train loss: 0.071, Global test loss: 2.969, Global test accuracy: 12.04 

Round  19, Train loss: 0.075, Test loss: 1.681, Test accuracy: 68.56 

Round  19, Global train loss: 0.075, Global test loss: 2.911, Global test accuracy: 12.48 

Round  20, Train loss: 0.056, Test loss: 1.681, Test accuracy: 68.64 

Round  20, Global train loss: 0.056, Global test loss: 3.072, Global test accuracy: 12.04 

Round  21, Train loss: 0.091, Test loss: 1.734, Test accuracy: 68.40 

Round  21, Global train loss: 0.091, Global test loss: 3.033, Global test accuracy: 12.00 

Round  22, Train loss: 0.073, Test loss: 1.921, Test accuracy: 66.72 

Round  22, Global train loss: 0.073, Global test loss: 3.027, Global test accuracy: 12.36 

Round  23, Train loss: 0.057, Test loss: 1.723, Test accuracy: 68.52 

Round  23, Global train loss: 0.057, Global test loss: 3.059, Global test accuracy: 12.00 

Round  24, Train loss: 0.060, Test loss: 1.635, Test accuracy: 69.36 

Round  24, Global train loss: 0.060, Global test loss: 2.985, Global test accuracy: 12.08 

Round  25, Train loss: 0.037, Test loss: 1.763, Test accuracy: 69.16 

Round  25, Global train loss: 0.037, Global test loss: 3.055, Global test accuracy: 12.24 

Round  26, Train loss: 0.035, Test loss: 1.703, Test accuracy: 68.76 

Round  26, Global train loss: 0.035, Global test loss: 3.077, Global test accuracy: 12.00 

Round  27, Train loss: 0.033, Test loss: 1.677, Test accuracy: 69.20 

Round  27, Global train loss: 0.033, Global test loss: 3.052, Global test accuracy: 12.00 

Round  28, Train loss: 0.026, Test loss: 1.886, Test accuracy: 67.00 

Round  28, Global train loss: 0.026, Global test loss: 3.109, Global test accuracy: 12.00 

Round  29, Train loss: 0.037, Test loss: 1.775, Test accuracy: 69.00 

Round  29, Global train loss: 0.037, Global test loss: 3.081, Global test accuracy: 12.04 

Round  30, Train loss: 0.043, Test loss: 1.839, Test accuracy: 68.12 

Round  30, Global train loss: 0.043, Global test loss: 3.042, Global test accuracy: 12.04 

Round  31, Train loss: 0.044, Test loss: 1.752, Test accuracy: 69.64 

Round  31, Global train loss: 0.044, Global test loss: 3.039, Global test accuracy: 12.00 

Round  32, Train loss: 0.028, Test loss: 1.688, Test accuracy: 70.32 

Round  32, Global train loss: 0.028, Global test loss: 3.044, Global test accuracy: 12.00 

Round  33, Train loss: 0.028, Test loss: 1.745, Test accuracy: 70.04 

Round  33, Global train loss: 0.028, Global test loss: 3.076, Global test accuracy: 12.04 

Round  34, Train loss: 0.031, Test loss: 1.719, Test accuracy: 69.80 

Round  34, Global train loss: 0.031, Global test loss: 2.989, Global test accuracy: 12.04 

Final Round, Train loss: 0.021, Test loss: 1.769, Test accuracy: 68.80 

Final Round, Global train loss: 0.021, Global test loss: 2.989, Global test accuracy: 12.04 

Average accuracy final 10 rounds: 69.10399999999998 

Average global accuracy final 10 rounds: 12.04 

1144.3078558444977
[7.401806116104126, 13.098067045211792, 18.939460277557373, 24.810028076171875, 30.464232921600342, 36.139851570129395, 41.84897422790527, 47.39470410346985, 52.98636436462402, 58.513880491256714, 64.1204686164856, 70.02928185462952, 75.59925484657288, 81.18229961395264, 86.93971681594849, 92.54138255119324, 98.06922554969788, 103.83319973945618, 109.43496775627136, 115.01077651977539, 120.66677284240723, 126.37871766090393, 131.94837594032288, 137.68162512779236, 143.24223518371582, 149.0307114124298, 154.5695514678955, 160.20506715774536, 165.93713927268982, 171.64078378677368, 177.35289359092712, 182.86334657669067, 188.57605028152466, 194.1710147857666, 199.83824753761292, 211.00348114967346]
[48.52, 54.84, 56.96, 61.8, 58.36, 61.6, 61.36, 59.88, 62.6, 64.44, 64.48, 67.32, 66.6, 66.6, 64.44, 66.2, 67.08, 67.08, 67.52, 68.56, 68.64, 68.4, 66.72, 68.52, 69.36, 69.16, 68.76, 69.2, 67.0, 69.0, 68.12, 69.64, 70.32, 70.04, 69.8, 68.8]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.438, Test loss: 1.431, Test accuracy: 48.08 

Round   0, Global train loss: 1.438, Global test loss: 2.295, Global test accuracy: 14.40 

Round   1, Train loss: 1.325, Test loss: 1.258, Test accuracy: 52.72 

Round   1, Global train loss: 1.325, Global test loss: 1.874, Global test accuracy: 29.36 

Round   2, Train loss: 1.181, Test loss: 1.253, Test accuracy: 53.04 

Round   2, Global train loss: 1.181, Global test loss: 1.673, Global test accuracy: 41.72 

Round   3, Train loss: 1.051, Test loss: 1.345, Test accuracy: 54.64 

Round   3, Global train loss: 1.051, Global test loss: 1.621, Global test accuracy: 44.00 

Round   4, Train loss: 0.960, Test loss: 1.170, Test accuracy: 58.88 

Round   4, Global train loss: 0.960, Global test loss: 1.544, Global test accuracy: 48.12 

Round   5, Train loss: 0.898, Test loss: 1.051, Test accuracy: 62.72 

Round   5, Global train loss: 0.898, Global test loss: 1.438, Global test accuracy: 52.52 

Round   6, Train loss: 0.833, Test loss: 1.082, Test accuracy: 63.08 

Round   6, Global train loss: 0.833, Global test loss: 1.401, Global test accuracy: 53.48 

Round   7, Train loss: 0.736, Test loss: 1.110, Test accuracy: 65.08 

Round   7, Global train loss: 0.736, Global test loss: 1.322, Global test accuracy: 58.88 

Round   8, Train loss: 0.700, Test loss: 1.002, Test accuracy: 66.68 

Round   8, Global train loss: 0.700, Global test loss: 1.251, Global test accuracy: 61.12 

Round   9, Train loss: 0.640, Test loss: 1.344, Test accuracy: 62.60 

Round   9, Global train loss: 0.640, Global test loss: 1.326, Global test accuracy: 58.48 

Round  10, Train loss: 0.608, Test loss: 1.076, Test accuracy: 67.68 

Round  10, Global train loss: 0.608, Global test loss: 1.207, Global test accuracy: 62.04 

Round  11, Train loss: 0.551, Test loss: 1.283, Test accuracy: 65.44 

Round  11, Global train loss: 0.551, Global test loss: 1.320, Global test accuracy: 61.12 

Round  12, Train loss: 0.523, Test loss: 0.950, Test accuracy: 70.92 

Round  12, Global train loss: 0.523, Global test loss: 1.172, Global test accuracy: 63.80 

Round  13, Train loss: 0.471, Test loss: 1.087, Test accuracy: 69.28 

Round  13, Global train loss: 0.471, Global test loss: 1.273, Global test accuracy: 62.16 

Round  14, Train loss: 0.452, Test loss: 0.991, Test accuracy: 70.32 

Round  14, Global train loss: 0.452, Global test loss: 1.194, Global test accuracy: 63.60 

Round  15, Train loss: 0.422, Test loss: 0.942, Test accuracy: 73.12 

Round  15, Global train loss: 0.422, Global test loss: 1.239, Global test accuracy: 63.16 

Round  16, Train loss: 0.370, Test loss: 1.210, Test accuracy: 69.60 

Round  16, Global train loss: 0.370, Global test loss: 1.177, Global test accuracy: 64.92 

Round  17, Train loss: 0.358, Test loss: 1.029, Test accuracy: 71.36 

Round  17, Global train loss: 0.358, Global test loss: 1.126, Global test accuracy: 66.04 

Round  18, Train loss: 0.349, Test loss: 0.939, Test accuracy: 73.96 

Round  18, Global train loss: 0.349, Global test loss: 1.183, Global test accuracy: 65.60 

Round  19, Train loss: 0.309, Test loss: 1.174, Test accuracy: 70.44 

Round  19, Global train loss: 0.309, Global test loss: 1.182, Global test accuracy: 66.60 

Round  20, Train loss: 0.299, Test loss: 0.985, Test accuracy: 73.28 

Round  20, Global train loss: 0.299, Global test loss: 1.167, Global test accuracy: 66.16 

Round  21, Train loss: 0.265, Test loss: 1.121, Test accuracy: 71.88 

Round  21, Global train loss: 0.265, Global test loss: 1.139, Global test accuracy: 67.20 

Round  22, Train loss: 0.258, Test loss: 1.031, Test accuracy: 72.40 

Round  22, Global train loss: 0.258, Global test loss: 1.120, Global test accuracy: 67.24 

Round  23, Train loss: 0.232, Test loss: 1.524, Test accuracy: 69.72 

Round  23, Global train loss: 0.232, Global test loss: 1.151, Global test accuracy: 68.48 

Round  24, Train loss: 0.232, Test loss: 1.221, Test accuracy: 71.12 

Round  24, Global train loss: 0.232, Global test loss: 1.115, Global test accuracy: 68.00 

Round  25, Train loss: 0.207, Test loss: 1.207, Test accuracy: 71.80 

Round  25, Global train loss: 0.207, Global test loss: 1.170, Global test accuracy: 67.92 

Round  26, Train loss: 0.198, Test loss: 1.072, Test accuracy: 75.44 

Round  26, Global train loss: 0.198, Global test loss: 1.120, Global test accuracy: 69.04 

Round  27, Train loss: 0.205, Test loss: 0.977, Test accuracy: 75.44 

Round  27, Global train loss: 0.205, Global test loss: 1.152, Global test accuracy: 68.24 

Round  28, Train loss: 0.163, Test loss: 1.298, Test accuracy: 72.68 

Round  28, Global train loss: 0.163, Global test loss: 1.209, Global test accuracy: 66.72 

Round  29, Train loss: 0.176, Test loss: 1.041, Test accuracy: 74.40 

Round  29, Global train loss: 0.176, Global test loss: 1.132, Global test accuracy: 68.40 

Round  30, Train loss: 0.154, Test loss: 1.003, Test accuracy: 77.40 

Round  30, Global train loss: 0.154, Global test loss: 1.219, Global test accuracy: 68.20 

Round  31, Train loss: 0.143, Test loss: 1.024, Test accuracy: 75.60 

Round  31, Global train loss: 0.143, Global test loss: 1.213, Global test accuracy: 68.40 

Round  32, Train loss: 0.135, Test loss: 1.357, Test accuracy: 72.08 

Round  32, Global train loss: 0.135, Global test loss: 1.218, Global test accuracy: 67.72 

Round  33, Train loss: 0.127, Test loss: 1.089, Test accuracy: 75.76 

Round  33, Global train loss: 0.127, Global test loss: 1.140, Global test accuracy: 69.12 

Round  34, Train loss: 0.127, Test loss: 1.218, Test accuracy: 74.32 

Round  34, Global train loss: 0.127, Global test loss: 1.215, Global test accuracy: 68.76 

Round  35, Train loss: 0.101, Test loss: 1.326, Test accuracy: 72.48 

Round  35, Global train loss: 0.101, Global test loss: 1.148, Global test accuracy: 70.12 

Round  36, Train loss: 0.100, Test loss: 1.102, Test accuracy: 76.12 

Round  36, Global train loss: 0.100, Global test loss: 1.237, Global test accuracy: 68.72 

Round  37, Train loss: 0.103, Test loss: 1.182, Test accuracy: 74.48 

Round  37, Global train loss: 0.103, Global test loss: 1.170, Global test accuracy: 69.40 

Round  38, Train loss: 0.090, Test loss: 1.023, Test accuracy: 76.72 

Round  38, Global train loss: 0.090, Global test loss: 1.183, Global test accuracy: 69.44 

Round  39, Train loss: 0.109, Test loss: 1.122, Test accuracy: 75.80 

Round  39, Global train loss: 0.109, Global test loss: 1.163, Global test accuracy: 69.72 

Round  40, Train loss: 0.091, Test loss: 1.065, Test accuracy: 75.88 

Round  40, Global train loss: 0.091, Global test loss: 1.183, Global test accuracy: 69.08 

Round  41, Train loss: 0.081, Test loss: 1.042, Test accuracy: 77.44 

Round  41, Global train loss: 0.081, Global test loss: 1.189, Global test accuracy: 69.80 

Round  42, Train loss: 0.072, Test loss: 1.148, Test accuracy: 77.04 

Round  42, Global train loss: 0.072, Global test loss: 1.230, Global test accuracy: 69.92 

Round  43, Train loss: 0.089, Test loss: 1.124, Test accuracy: 75.44 

Round  43, Global train loss: 0.089, Global test loss: 1.200, Global test accuracy: 70.24 

Round  44, Train loss: 0.056, Test loss: 1.222, Test accuracy: 76.80 

Round  44, Global train loss: 0.056, Global test loss: 1.240, Global test accuracy: 69.44 

Round  45, Train loss: 0.063, Test loss: 1.241, Test accuracy: 75.40 

Round  45, Global train loss: 0.063, Global test loss: 1.213, Global test accuracy: 69.36 

Round  46, Train loss: 0.050, Test loss: 1.036, Test accuracy: 78.68 

Round  46, Global train loss: 0.050, Global test loss: 1.234, Global test accuracy: 70.04 

Round  47, Train loss: 0.063, Test loss: 1.233, Test accuracy: 74.76 

Round  47, Global train loss: 0.063, Global test loss: 1.243, Global test accuracy: 69.24 

Round  48, Train loss: 0.058, Test loss: 1.157, Test accuracy: 77.00 

Round  48, Global train loss: 0.058, Global test loss: 1.226, Global test accuracy: 70.04 

Round  49, Train loss: 0.063, Test loss: 1.296, Test accuracy: 75.28 

Round  49, Global train loss: 0.063, Global test loss: 1.238, Global test accuracy: 70.52 

Final Round, Train loss: 0.071, Test loss: 1.193, Test accuracy: 76.28 

Final Round, Global train loss: 0.071, Global test loss: 1.238, Global test accuracy: 70.52 

Average accuracy final 10 rounds: 76.37200000000001 

Average global accuracy final 10 rounds: 69.768 

1625.26917552948
[7.624438047409058, 13.246325969696045, 18.90268635749817, 24.61813259124756, 30.17944836616516, 35.74919104576111, 41.602497577667236, 47.61417198181152, 53.60665702819824, 59.17257499694824, 65.0205397605896, 70.9778823852539, 76.82530450820923, 82.38471102714539, 87.92956018447876, 93.69171190261841, 99.8059310913086, 105.50317931175232, 111.00587391853333, 116.65246486663818, 122.35880899429321, 127.90553116798401, 133.61743593215942, 139.25253224372864, 144.749169588089, 150.66842103004456, 156.41650986671448, 162.17121195793152, 167.7845025062561, 173.71694207191467, 179.44575786590576, 185.12693810462952, 190.93332862854004, 196.57170009613037, 202.17495346069336, 207.7919406890869, 213.39727473258972, 219.1420636177063, 224.796879529953, 230.67606377601624, 236.30178427696228, 242.0771610736847, 247.9178717136383, 253.63320517539978, 259.9818835258484, 265.7740032672882, 271.6335301399231, 277.17995524406433, 282.75702023506165, 288.36279821395874, 299.5007345676422]
[48.08, 52.72, 53.04, 54.64, 58.88, 62.72, 63.08, 65.08, 66.68, 62.6, 67.68, 65.44, 70.92, 69.28, 70.32, 73.12, 69.6, 71.36, 73.96, 70.44, 73.28, 71.88, 72.4, 69.72, 71.12, 71.8, 75.44, 75.44, 72.68, 74.4, 77.4, 75.6, 72.08, 75.76, 74.32, 72.48, 76.12, 74.48, 76.72, 75.8, 75.88, 77.44, 77.04, 75.44, 76.8, 75.4, 78.68, 74.76, 77.0, 75.28, 76.28]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.530, Test loss: 1.857, Test accuracy: 24.72 

Round   1, Train loss: 1.334, Test loss: 1.532, Test accuracy: 34.72 

Round   2, Train loss: 1.215, Test loss: 1.139, Test accuracy: 51.44 

Round   3, Train loss: 1.109, Test loss: 1.063, Test accuracy: 54.44 

Round   4, Train loss: 1.060, Test loss: 1.137, Test accuracy: 52.48 

Round   5, Train loss: 0.972, Test loss: 1.081, Test accuracy: 58.24 

Round   6, Train loss: 0.905, Test loss: 0.957, Test accuracy: 59.84 

Round   7, Train loss: 0.861, Test loss: 0.934, Test accuracy: 62.52 

Round   8, Train loss: 0.800, Test loss: 0.868, Test accuracy: 65.00 

Round   9, Train loss: 0.751, Test loss: 0.851, Test accuracy: 66.64 

Round  10, Train loss: 0.708, Test loss: 0.796, Test accuracy: 68.96 

Round  11, Train loss: 0.691, Test loss: 0.842, Test accuracy: 66.68 

Round  12, Train loss: 0.641, Test loss: 0.765, Test accuracy: 69.88 

Round  13, Train loss: 0.596, Test loss: 0.841, Test accuracy: 69.20 

Round  14, Train loss: 0.554, Test loss: 0.714, Test accuracy: 73.92 

Round  15, Train loss: 0.529, Test loss: 0.785, Test accuracy: 72.32 

Round  16, Train loss: 0.484, Test loss: 0.681, Test accuracy: 74.80 

Round  17, Train loss: 0.467, Test loss: 0.717, Test accuracy: 73.92 

Round  18, Train loss: 0.442, Test loss: 0.681, Test accuracy: 75.64 

Round  19, Train loss: 0.414, Test loss: 0.699, Test accuracy: 74.36 

Round  20, Train loss: 0.395, Test loss: 0.732, Test accuracy: 73.92 

Round  21, Train loss: 0.358, Test loss: 0.659, Test accuracy: 76.48 

Round  22, Train loss: 0.330, Test loss: 0.660, Test accuracy: 77.24 

Round  23, Train loss: 0.315, Test loss: 0.667, Test accuracy: 77.68 

Round  24, Train loss: 0.315, Test loss: 0.655, Test accuracy: 77.20 

Round  25, Train loss: 0.283, Test loss: 0.711, Test accuracy: 75.36 

Round  26, Train loss: 0.266, Test loss: 0.665, Test accuracy: 77.96 

Round  27, Train loss: 0.244, Test loss: 0.674, Test accuracy: 77.72 

Round  28, Train loss: 0.244, Test loss: 0.675, Test accuracy: 77.84 

Round  29, Train loss: 0.227, Test loss: 0.652, Test accuracy: 78.52 

Round  30, Train loss: 0.206, Test loss: 0.654, Test accuracy: 78.48 

Round  31, Train loss: 0.199, Test loss: 0.689, Test accuracy: 77.92 

Round  32, Train loss: 0.180, Test loss: 0.716, Test accuracy: 77.08 

Round  33, Train loss: 0.183, Test loss: 0.712, Test accuracy: 77.72 

Round  34, Train loss: 0.166, Test loss: 0.684, Test accuracy: 79.32 

Round  35, Train loss: 0.144, Test loss: 0.693, Test accuracy: 78.48 

Round  36, Train loss: 0.150, Test loss: 0.698, Test accuracy: 78.12 

Round  37, Train loss: 0.136, Test loss: 0.685, Test accuracy: 78.32 

Round  38, Train loss: 0.123, Test loss: 0.762, Test accuracy: 77.84 

Round  39, Train loss: 0.115, Test loss: 0.732, Test accuracy: 78.36 

Round  40, Train loss: 0.113, Test loss: 0.712, Test accuracy: 79.56 

Round  41, Train loss: 0.111, Test loss: 0.699, Test accuracy: 79.16 

Round  42, Train loss: 0.096, Test loss: 0.720, Test accuracy: 78.40 

Round  43, Train loss: 0.100, Test loss: 0.723, Test accuracy: 78.40 

Round  44, Train loss: 0.098, Test loss: 0.708, Test accuracy: 79.88 

Round  45, Train loss: 0.089, Test loss: 0.723, Test accuracy: 78.80 

Round  46, Train loss: 0.079, Test loss: 0.698, Test accuracy: 79.40 

Round  47, Train loss: 0.075, Test loss: 0.736, Test accuracy: 78.20 

Round  48, Train loss: 0.074, Test loss: 0.712, Test accuracy: 79.96 

Round  49, Train loss: 0.073, Test loss: 0.712, Test accuracy: 79.96 

Final Round, Train loss: 0.040, Test loss: 0.712, Test accuracy: 80.48 

Average accuracy final 10 rounds: 79.172 

1195.2147870063782
[6.295757293701172, 10.718631029129028, 15.179773807525635, 19.69187569618225, 24.146602869033813, 28.671197414398193, 33.122262477874756, 37.68255090713501, 42.06631565093994, 46.79618167877197, 51.20363759994507, 55.693904876708984, 60.15764617919922, 64.61003923416138, 69.12282085418701, 73.54402136802673, 78.05100512504578, 82.48222804069519, 86.8930995464325, 91.33129334449768, 95.68100714683533, 100.12236022949219, 104.57747006416321, 109.0586895942688, 113.40340161323547, 117.74687671661377, 122.12334084510803, 126.85858726501465, 131.62059354782104, 135.9466474056244, 140.5311574935913, 144.82198023796082, 149.20177841186523, 153.64877247810364, 158.2963888645172, 162.7184808254242, 167.16772961616516, 171.61714911460876, 176.09060287475586, 180.5606484413147, 185.06149911880493, 189.7680892944336, 194.12381649017334, 198.73722076416016, 203.2218313217163, 208.21455001831055, 212.46872544288635, 216.8937747478485, 221.2164671421051, 225.66298365592957, 230.05658435821533]
[24.72, 34.72, 51.44, 54.44, 52.48, 58.24, 59.84, 62.52, 65.0, 66.64, 68.96, 66.68, 69.88, 69.2, 73.92, 72.32, 74.8, 73.92, 75.64, 74.36, 73.92, 76.48, 77.24, 77.68, 77.2, 75.36, 77.96, 77.72, 77.84, 78.52, 78.48, 77.92, 77.08, 77.72, 79.32, 78.48, 78.12, 78.32, 77.84, 78.36, 79.56, 79.16, 78.4, 78.4, 79.88, 78.8, 79.4, 78.2, 79.96, 79.96, 80.48]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
Round   0, Train loss: 1.537, Test loss: 1.857, Test accuracy: 24.04
Round   1, Train loss: 1.324, Test loss: 1.487, Test accuracy: 32.36
Round   2, Train loss: 1.221, Test loss: 1.459, Test accuracy: 42.48
Round   3, Train loss: 1.129, Test loss: 1.183, Test accuracy: 50.28
Round   4, Train loss: 1.043, Test loss: 1.003, Test accuracy: 58.88
Round   5, Train loss: 0.989, Test loss: 1.019, Test accuracy: 58.24
Round   6, Train loss: 0.924, Test loss: 0.904, Test accuracy: 63.52
Round   7, Train loss: 0.881, Test loss: 0.922, Test accuracy: 61.72
Round   8, Train loss: 0.827, Test loss: 0.875, Test accuracy: 65.08
Round   9, Train loss: 0.783, Test loss: 0.834, Test accuracy: 68.64
Round  10, Train loss: 0.742, Test loss: 0.846, Test accuracy: 66.56
Round  11, Train loss: 0.703, Test loss: 0.830, Test accuracy: 67.20
Round  12, Train loss: 0.657, Test loss: 0.723, Test accuracy: 71.96
Round  13, Train loss: 0.611, Test loss: 0.756, Test accuracy: 70.56
Round  14, Train loss: 0.574, Test loss: 0.766, Test accuracy: 71.40
Round  15, Train loss: 0.536, Test loss: 0.726, Test accuracy: 73.32
Round  16, Train loss: 0.518, Test loss: 0.737, Test accuracy: 72.68
Round  17, Train loss: 0.473, Test loss: 0.708, Test accuracy: 74.16
Round  18, Train loss: 0.450, Test loss: 0.691, Test accuracy: 75.16
Round  19, Train loss: 0.413, Test loss: 0.658, Test accuracy: 76.68
Round  20, Train loss: 0.399, Test loss: 0.672, Test accuracy: 74.88
Round  21, Train loss: 0.370, Test loss: 0.711, Test accuracy: 74.80
Round  22, Train loss: 0.353, Test loss: 0.697, Test accuracy: 75.96
Round  23, Train loss: 0.329, Test loss: 0.673, Test accuracy: 77.44
Round  24, Train loss: 0.312, Test loss: 0.649, Test accuracy: 78.00
Round  25, Train loss: 0.293, Test loss: 0.713, Test accuracy: 77.24
Round  26, Train loss: 0.267, Test loss: 0.657, Test accuracy: 77.48
Round  27, Train loss: 0.258, Test loss: 0.717, Test accuracy: 76.76
Round  28, Train loss: 0.244, Test loss: 0.655, Test accuracy: 77.80
Round  29, Train loss: 0.224, Test loss: 0.710, Test accuracy: 77.48
Round  30, Train loss: 0.229, Test loss: 0.664, Test accuracy: 77.64
Round  31, Train loss: 0.195, Test loss: 0.691, Test accuracy: 76.84
Round  32, Train loss: 0.188, Test loss: 0.704, Test accuracy: 77.44
Round  33, Train loss: 0.175, Test loss: 0.664, Test accuracy: 78.00
Round  34, Train loss: 0.168, Test loss: 0.688, Test accuracy: 78.20
Round  35, Train loss: 0.154, Test loss: 0.691, Test accuracy: 79.04
Round  36, Train loss: 0.142, Test loss: 0.694, Test accuracy: 78.80
Round  37, Train loss: 0.143, Test loss: 0.686, Test accuracy: 78.76
Round  38, Train loss: 0.132, Test loss: 0.684, Test accuracy: 79.40
Round  39, Train loss: 0.132, Test loss: 0.691, Test accuracy: 78.48
Round  40, Train loss: 0.106, Test loss: 0.678, Test accuracy: 79.64
Round  41, Train loss: 0.105, Test loss: 0.728, Test accuracy: 79.36
Round  42, Train loss: 0.100, Test loss: 0.714, Test accuracy: 78.64
Round  43, Train loss: 0.093, Test loss: 0.713, Test accuracy: 79.36
Round  44, Train loss: 0.103, Test loss: 0.721, Test accuracy: 78.44
Round  45, Train loss: 0.082, Test loss: 0.739, Test accuracy: 79.36
Round  46, Train loss: 0.085, Test loss: 0.725, Test accuracy: 79.08
Round  47, Train loss: 0.072, Test loss: 0.720, Test accuracy: 79.80
Round  48, Train loss: 0.075, Test loss: 0.725, Test accuracy: 79.64
Round  49, Train loss: 0.074, Test loss: 0.738, Test accuracy: 79.36
Final Round, Train loss: 0.036, Test loss: 0.725, Test accuracy: 79.16
Average accuracy final 10 rounds: 79.268
1354.0088872909546
[7.005920886993408, 12.049164056777954, 17.20798134803772, 22.686183214187622, 27.743730545043945, 32.6891610622406, 37.92430067062378, 43.04330635070801, 48.155890464782715, 53.250608682632446, 58.32303023338318, 63.45123839378357, 68.55243134498596, 73.66487693786621, 78.66501927375793, 83.94180703163147, 88.93224930763245, 94.05806875228882, 99.51885271072388, 104.49842596054077, 109.68219041824341, 114.87965106964111, 119.87258625030518, 124.9747200012207, 130.01930046081543, 135.65806412696838, 140.59729385375977, 145.6966052055359, 150.7270543575287, 155.75957608222961, 160.7591426372528, 165.79958534240723, 170.71986961364746, 176.02983593940735, 181.00281929969788, 186.0879876613617, 191.11315894126892, 196.1311616897583, 201.13860297203064, 206.1764898300171, 211.22878313064575, 216.13517713546753, 221.20061683654785, 226.38427233695984, 231.61813235282898, 236.6906177997589, 241.60862851142883, 246.96272158622742, 252.4515118598938, 257.4444544315338, 262.7338650226593]
[24.04, 32.36, 42.48, 50.28, 58.88, 58.24, 63.52, 61.72, 65.08, 68.64, 66.56, 67.2, 71.96, 70.56, 71.4, 73.32, 72.68, 74.16, 75.16, 76.68, 74.88, 74.8, 75.96, 77.44, 78.0, 77.24, 77.48, 76.76, 77.8, 77.48, 77.64, 76.84, 77.44, 78.0, 78.2, 79.04, 78.8, 78.76, 79.4, 78.48, 79.64, 79.36, 78.64, 79.36, 78.44, 79.36, 79.08, 79.8, 79.64, 79.36, 79.16]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

        init --> train local model(freeze embeding):client   0,  Train loss: 1.078, Train accuracy: 55.800, Test loss: 1.202, Test accuracy: 52.80 

        train local model (freeze embeding):client   0,  Train loss: 0.912, Train accuracy: 62.800, Test loss: 1.113, Test accuracy: 54.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.873, Train accuracy: 63.400, Test loss: 1.116, Test accuracy: 56.60 

Round   0, Train loss: 0.873, Test loss: 1.116, Test accuracy: 56.60 

        train local model (freeze embeding):client   0,  Train loss: 0.851, Train accuracy: 67.800, Test loss: 1.136, Test accuracy: 58.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.872, Train accuracy: 65.800, Test loss: 1.199, Test accuracy: 53.80 

Round   1, Train loss: 0.872, Test loss: 1.199, Test accuracy: 53.80 

        train local model (freeze embeding):client   0,  Train loss: 0.876, Train accuracy: 70.000, Test loss: 1.247, Test accuracy: 60.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.622, Train accuracy: 79.200, Test loss: 1.141, Test accuracy: 60.00 

Round   2, Train loss: 0.622, Test loss: 1.141, Test accuracy: 60.00 

        train local model (freeze embeding):client   0,  Train loss: 0.446, Train accuracy: 85.000, Test loss: 1.073, Test accuracy: 62.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.434, Train accuracy: 84.200, Test loss: 1.210, Test accuracy: 59.60 

Round   3, Train loss: 0.434, Test loss: 1.210, Test accuracy: 59.60 

        train local model (freeze embeding):client   0,  Train loss: 0.327, Train accuracy: 89.000, Test loss: 1.139, Test accuracy: 67.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.260, Train accuracy: 92.400, Test loss: 1.188, Test accuracy: 65.60 

Round   4, Train loss: 0.260, Test loss: 1.188, Test accuracy: 65.60 

        train local model (freeze embeding):client   0,  Train loss: 0.248, Train accuracy: 91.200, Test loss: 1.266, Test accuracy: 63.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.208, Train accuracy: 92.600, Test loss: 1.192, Test accuracy: 67.80 

Round   5, Train loss: 0.208, Test loss: 1.192, Test accuracy: 67.80 

        train local model (freeze embeding):client   0,  Train loss: 0.139, Train accuracy: 95.800, Test loss: 1.277, Test accuracy: 67.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.175, Train accuracy: 93.600, Test loss: 1.292, Test accuracy: 64.20 

Round   6, Train loss: 0.175, Test loss: 1.292, Test accuracy: 64.20 

        train local model (freeze embeding):client   0,  Train loss: 0.128, Train accuracy: 96.000, Test loss: 1.320, Test accuracy: 66.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.077, Train accuracy: 97.600, Test loss: 1.331, Test accuracy: 66.80 

Round   7, Train loss: 0.077, Test loss: 1.331, Test accuracy: 66.80 

        train local model (freeze embeding):client   0,  Train loss: 0.052, Train accuracy: 98.600, Test loss: 1.352, Test accuracy: 67.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.078, Train accuracy: 97.400, Test loss: 1.469, Test accuracy: 68.80 

Round   8, Train loss: 0.078, Test loss: 1.469, Test accuracy: 68.80 

        train local model (freeze embeding):client   0,  Train loss: 0.055, Train accuracy: 98.600, Test loss: 1.451, Test accuracy: 67.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.056, Train accuracy: 97.800, Test loss: 1.504, Test accuracy: 70.80 

Round   9, Train loss: 0.056, Test loss: 1.504, Test accuracy: 70.80 

        train local model (freeze embeding):client   0,  Train loss: 0.061, Train accuracy: 98.000, Test loss: 1.700, Test accuracy: 68.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.037, Train accuracy: 98.200, Test loss: 1.643, Test accuracy: 69.20 

Round  10, Train loss: 0.037, Test loss: 1.643, Test accuracy: 69.20 

        train local model (freeze embeding):client   0,  Train loss: 0.031, Train accuracy: 99.200, Test loss: 1.554, Test accuracy: 70.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.295, Train accuracy: 89.400, Test loss: 2.135, Test accuracy: 60.60 

Round  11, Train loss: 0.295, Test loss: 2.135, Test accuracy: 60.60 

        train local model (freeze embeding):client   0,  Train loss: 0.082, Train accuracy: 96.600, Test loss: 1.483, Test accuracy: 69.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.024, Train accuracy: 99.400, Test loss: 1.607, Test accuracy: 70.40 

Round  12, Train loss: 0.024, Test loss: 1.607, Test accuracy: 70.40 

        train local model (freeze embeding):client   0,  Train loss: 0.015, Train accuracy: 99.600, Test loss: 1.548, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.034, Train accuracy: 99.200, Test loss: 1.558, Test accuracy: 69.80 

Round  13, Train loss: 0.034, Test loss: 1.558, Test accuracy: 69.80 

        train local model (freeze embeding):client   0,  Train loss: 0.033, Train accuracy: 99.200, Test loss: 1.641, Test accuracy: 70.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.021, Train accuracy: 99.400, Test loss: 1.701, Test accuracy: 70.80 

Round  14, Train loss: 0.021, Test loss: 1.701, Test accuracy: 70.80 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.569, Test accuracy: 70.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.028, Train accuracy: 99.400, Test loss: 1.891, Test accuracy: 69.20 

Round  15, Train loss: 0.028, Test loss: 1.891, Test accuracy: 69.20 

        train local model (freeze embeding):client   0,  Train loss: 0.035, Train accuracy: 98.800, Test loss: 1.823, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.764, Test accuracy: 69.20 

Round  16, Train loss: 0.007, Test loss: 1.764, Test accuracy: 69.20 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.661, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.010, Train accuracy: 99.400, Test loss: 1.786, Test accuracy: 71.40 

Round  17, Train loss: 0.010, Test loss: 1.786, Test accuracy: 71.40 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.877, Test accuracy: 71.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.010, Train accuracy: 99.400, Test loss: 1.706, Test accuracy: 68.20 

Round  18, Train loss: 0.010, Test loss: 1.706, Test accuracy: 68.20 

        train local model (freeze embeding):client   0,  Train loss: 0.013, Train accuracy: 99.600, Test loss: 1.718, Test accuracy: 68.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.015, Train accuracy: 99.600, Test loss: 1.766, Test accuracy: 72.40 

Round  19, Train loss: 0.015, Test loss: 1.766, Test accuracy: 72.40 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.805, Test accuracy: 71.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.013, Train accuracy: 99.800, Test loss: 1.670, Test accuracy: 70.60 

Final Round, Train loss: 0.013, Test loss: 1.782, Test accuracy: 72.20 

---------------------------------------------train_client: [0, 1] 

        init --> train local model(freeze embeding):client   1,  Train loss: 1.016, Train accuracy: 59.600, Test loss: 1.060, Test accuracy: 60.20 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.804, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 1.711, Test accuracy: 72.00 

        train local model (freeze embeding):client   1,  Train loss: 0.975, Train accuracy: 59.400, Test loss: 1.301, Test accuracy: 54.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.268, Train accuracy: 91.000, Test loss: 1.018, Test accuracy: 69.60 

Round   0, Train loss: 0.138, Test loss: 1.409, Test accuracy: 67.60 

        train local model (freeze embeding):client   0,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.692, Test accuracy: 71.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 1.702, Test accuracy: 70.00 

        train local model (freeze embeding):client   1,  Train loss: 0.416, Train accuracy: 84.600, Test loss: 0.997, Test accuracy: 67.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.106, Train accuracy: 97.400, Test loss: 1.019, Test accuracy: 70.60 

Round   1, Train loss: 0.056, Test loss: 1.355, Test accuracy: 70.70 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.698, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.597, Test accuracy: 72.40 

        train local model (freeze embeding):client   1,  Train loss: 0.153, Train accuracy: 94.400, Test loss: 0.851, Test accuracy: 72.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.096, Train accuracy: 96.400, Test loss: 1.118, Test accuracy: 67.20 

Round   2, Train loss: 0.049, Test loss: 1.305, Test accuracy: 70.90 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.619, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.018, Train accuracy: 99.600, Test loss: 1.716, Test accuracy: 68.80 

        train local model (freeze embeding):client   1,  Train loss: 0.088, Train accuracy: 97.800, Test loss: 0.949, Test accuracy: 70.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.141, Train accuracy: 95.800, Test loss: 1.395, Test accuracy: 68.80 

Round   3, Train loss: 0.080, Test loss: 1.226, Test accuracy: 73.00 

        train local model (freeze embeding):client   0,  Train loss: 0.010, Train accuracy: 99.600, Test loss: 1.478, Test accuracy: 74.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.008, Train accuracy: 99.600, Test loss: 1.880, Test accuracy: 71.60 

        train local model (freeze embeding):client   1,  Train loss: 0.083, Train accuracy: 97.400, Test loss: 1.077, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.101, Train accuracy: 95.800, Test loss: 1.473, Test accuracy: 69.80 

Round   4, Train loss: 0.055, Test loss: 1.489, Test accuracy: 70.50 

        train local model (freeze embeding):client   0,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.679, Test accuracy: 71.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.017, Train accuracy: 99.600, Test loss: 1.628, Test accuracy: 69.40 

        train local model (freeze embeding):client   1,  Train loss: 0.051, Train accuracy: 98.200, Test loss: 1.194, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.047, Train accuracy: 99.000, Test loss: 1.077, Test accuracy: 73.00 

Round   5, Train loss: 0.032, Test loss: 1.321, Test accuracy: 70.90 

        train local model (freeze embeding):client   0,  Train loss: 0.006, Train accuracy: 99.600, Test loss: 1.467, Test accuracy: 73.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.829, Test accuracy: 71.60 

        train local model (freeze embeding):client   1,  Train loss: 0.019, Train accuracy: 99.800, Test loss: 1.107, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.026, Train accuracy: 99.400, Test loss: 1.232, Test accuracy: 71.00 

Round   6, Train loss: 0.016, Test loss: 1.389, Test accuracy: 73.50 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.591, Test accuracy: 73.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.893, Test accuracy: 72.20 

        train local model (freeze embeding):client   1,  Train loss: 0.013, Train accuracy: 99.800, Test loss: 1.132, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.017, Train accuracy: 99.000, Test loss: 1.372, Test accuracy: 71.40 

Round   7, Train loss: 0.009, Test loss: 1.478, Test accuracy: 71.30 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.656, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.009, Train accuracy: 99.800, Test loss: 1.607, Test accuracy: 70.60 

        train local model (freeze embeding):client   1,  Train loss: 0.010, Train accuracy: 100.000, Test loss: 1.275, Test accuracy: 70.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.034, Train accuracy: 98.600, Test loss: 1.271, Test accuracy: 71.80 

Round   8, Train loss: 0.022, Test loss: 1.341, Test accuracy: 72.50 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.571, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.679, Test accuracy: 71.00 

        train local model (freeze embeding):client   1,  Train loss: 0.017, Train accuracy: 99.600, Test loss: 1.192, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.036, Train accuracy: 98.800, Test loss: 1.299, Test accuracy: 72.00 

Round   9, Train loss: 0.019, Test loss: 1.317, Test accuracy: 73.30 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.468, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.600, Test accuracy: 74.80 

        train local model (freeze embeding):client   1,  Train loss: 0.012, Train accuracy: 99.800, Test loss: 1.180, Test accuracy: 71.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 1.493, Test accuracy: 71.00 

Round  10, Train loss: 0.005, Test loss: 1.437, Test accuracy: 71.90 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.573, Test accuracy: 72.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 99.800, Test loss: 1.672, Test accuracy: 73.20 

        train local model (freeze embeding):client   1,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.405, Test accuracy: 71.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.020, Train accuracy: 99.600, Test loss: 1.541, Test accuracy: 70.60 

Round  11, Train loss: 0.011, Test loss: 1.413, Test accuracy: 72.80 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.572, Test accuracy: 75.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.584, Test accuracy: 74.20 

        train local model (freeze embeding):client   1,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.327, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.086, Train accuracy: 97.200, Test loss: 1.787, Test accuracy: 68.60 

Round  12, Train loss: 0.044, Test loss: 1.501, Test accuracy: 71.80 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.578, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.557, Test accuracy: 74.40 

        train local model (freeze embeding):client   1,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.253, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.037, Train accuracy: 98.600, Test loss: 1.492, Test accuracy: 71.40 

Round  13, Train loss: 0.019, Test loss: 1.360, Test accuracy: 74.20 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.551, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.662, Test accuracy: 73.80 

        train local model (freeze embeding):client   1,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.273, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.285, Test accuracy: 73.00 

Round  14, Train loss: 0.002, Test loss: 1.357, Test accuracy: 74.80 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.529, Test accuracy: 74.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.537, Test accuracy: 74.60 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.263, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.012, Train accuracy: 99.600, Test loss: 1.487, Test accuracy: 69.80 

Round  15, Train loss: 0.006, Test loss: 1.344, Test accuracy: 73.80 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.485, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.018, Train accuracy: 99.600, Test loss: 1.872, Test accuracy: 70.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.212, Test accuracy: 75.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.041, Train accuracy: 99.200, Test loss: 1.541, Test accuracy: 69.60 

Round  16, Train loss: 0.030, Test loss: 1.423, Test accuracy: 71.50 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.450, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.037, Train accuracy: 99.200, Test loss: 1.693, Test accuracy: 70.20 

        train local model (freeze embeding):client   1,  Train loss: 0.009, Train accuracy: 100.000, Test loss: 1.285, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.454, Test accuracy: 72.80 

Round  17, Train loss: 0.021, Test loss: 1.411, Test accuracy: 73.40 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.588, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 99.800, Test loss: 1.610, Test accuracy: 74.40 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.427, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.057, Train accuracy: 98.400, Test loss: 1.824, Test accuracy: 69.80 

Round  18, Train loss: 0.030, Test loss: 1.545, Test accuracy: 72.00 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.564, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.573, Test accuracy: 73.40 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.297, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.330, Test accuracy: 73.00 

Round  19, Train loss: 0.001, Test loss: 1.402, Test accuracy: 74.10 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.535, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.606, Test accuracy: 73.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.241, Test accuracy: 74.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.424, Test accuracy: 72.80 

Final Round, Train loss: 0.001, Test loss: 1.374, Test accuracy: 74.10 

---------------------------------------------train_client: [0, 1, 2] 

        init --> train local model(freeze embeding):client   2,  Train loss: 0.603, Train accuracy: 77.200, Test loss: 0.901, Test accuracy: 71.60 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.496, Test accuracy: 75.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.487, Test accuracy: 74.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.198, Test accuracy: 73.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.013, Train accuracy: 99.800, Test loss: 1.553, Test accuracy: 72.80 

        train local model (freeze embeding):client   2,  Train loss: 0.411, Train accuracy: 84.800, Test loss: 0.756, Test accuracy: 77.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.050, Train accuracy: 98.200, Test loss: 0.656, Test accuracy: 82.00 

Round   0, Train loss: 0.021, Test loss: 1.131, Test accuracy: 75.87 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.386, Test accuracy: 76.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.624, Test accuracy: 72.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.132, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.022, Train accuracy: 98.600, Test loss: 1.442, Test accuracy: 70.20 

        train local model (freeze embeding):client   2,  Train loss: 0.145, Train accuracy: 95.800, Test loss: 0.654, Test accuracy: 80.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.096, Train accuracy: 96.800, Test loss: 0.833, Test accuracy: 80.80 

Round   1, Train loss: 0.041, Test loss: 1.059, Test accuracy: 77.80 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.323, Test accuracy: 76.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.402, Test accuracy: 75.20 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.152, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.017, Train accuracy: 99.600, Test loss: 1.286, Test accuracy: 76.00 

        train local model (freeze embeding):client   2,  Train loss: 0.062, Train accuracy: 98.000, Test loss: 0.651, Test accuracy: 81.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.034, Train accuracy: 99.200, Test loss: 1.083, Test accuracy: 76.60 

Round   2, Train loss: 0.017, Test loss: 1.090, Test accuracy: 76.93 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.342, Test accuracy: 75.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.399, Test accuracy: 75.60 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.112, Test accuracy: 77.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.057, Train accuracy: 98.200, Test loss: 1.442, Test accuracy: 70.60 

        train local model (freeze embeding):client   2,  Train loss: 0.032, Train accuracy: 99.600, Test loss: 0.802, Test accuracy: 81.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.029, Train accuracy: 99.400, Test loss: 0.796, Test accuracy: 80.00 

Round   3, Train loss: 0.029, Test loss: 0.990, Test accuracy: 78.47 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.286, Test accuracy: 77.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.433, Test accuracy: 75.40 

        train local model (freeze embeding):client   1,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.080, Test accuracy: 75.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.179, Train accuracy: 94.800, Test loss: 1.591, Test accuracy: 69.40 

        train local model (freeze embeding):client   2,  Train loss: 0.028, Train accuracy: 99.800, Test loss: 0.666, Test accuracy: 82.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.024, Train accuracy: 99.600, Test loss: 0.892, Test accuracy: 79.60 

Round   4, Train loss: 0.068, Test loss: 1.015, Test accuracy: 77.93 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.313, Test accuracy: 77.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.366, Test accuracy: 76.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.985, Test accuracy: 77.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.090, Test accuracy: 76.40 

        train local model (freeze embeding):client   2,  Train loss: 0.020, Train accuracy: 100.000, Test loss: 0.734, Test accuracy: 81.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.020, Train accuracy: 99.600, Test loss: 0.755, Test accuracy: 81.00 

Round   5, Train loss: 0.007, Test loss: 1.002, Test accuracy: 77.60 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.265, Test accuracy: 77.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.395, Test accuracy: 76.00 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.978, Test accuracy: 77.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.103, Test accuracy: 75.20 

        train local model (freeze embeding):client   2,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 0.717, Test accuracy: 81.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.026, Train accuracy: 99.400, Test loss: 1.083, Test accuracy: 79.60 

Round   6, Train loss: 0.010, Test loss: 1.023, Test accuracy: 78.20 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.345, Test accuracy: 76.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.353, Test accuracy: 77.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.975, Test accuracy: 77.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.134, Test accuracy: 76.20 

        train local model (freeze embeding):client   2,  Train loss: 0.013, Train accuracy: 99.800, Test loss: 0.783, Test accuracy: 82.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.025, Train accuracy: 99.200, Test loss: 0.886, Test accuracy: 82.00 

Round   7, Train loss: 0.009, Test loss: 1.018, Test accuracy: 78.80 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.265, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.028, Train accuracy: 99.000, Test loss: 1.606, Test accuracy: 72.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.913, Test accuracy: 77.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.016, Train accuracy: 99.400, Test loss: 1.490, Test accuracy: 71.80 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.752, Test accuracy: 81.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.077, Train accuracy: 97.400, Test loss: 1.050, Test accuracy: 74.00 

Round   8, Train loss: 0.040, Test loss: 0.987, Test accuracy: 78.60 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.314, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.350, Test accuracy: 75.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.001, Test accuracy: 77.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.980, Test accuracy: 78.60 

        train local model (freeze embeding):client   2,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 0.706, Test accuracy: 83.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 0.843, Test accuracy: 82.20 

Round   9, Train loss: 0.002, Test loss: 1.009, Test accuracy: 79.73 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.283, Test accuracy: 77.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.577, Test accuracy: 72.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.974, Test accuracy: 77.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.055, Test accuracy: 78.00 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.706, Test accuracy: 83.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.028, Train accuracy: 98.800, Test loss: 1.008, Test accuracy: 79.20 

Round  10, Train loss: 0.010, Test loss: 1.035, Test accuracy: 78.60 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.474, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.441, Test accuracy: 74.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.991, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.013, Train accuracy: 99.600, Test loss: 0.988, Test accuracy: 75.80 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.705, Test accuracy: 83.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.901, Test accuracy: 81.00 

Round  11, Train loss: 0.007, Test loss: 0.947, Test accuracy: 79.07 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.262, Test accuracy: 78.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 1.525, Test accuracy: 73.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.881, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.940, Test accuracy: 80.40 

        train local model (freeze embeding):client   2,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 0.765, Test accuracy: 79.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.004, Train accuracy: 99.600, Test loss: 0.808, Test accuracy: 81.80 

Round  12, Train loss: 0.003, Test loss: 0.992, Test accuracy: 79.20 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.318, Test accuracy: 77.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.559, Test accuracy: 77.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.900, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.974, Test accuracy: 79.40 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.722, Test accuracy: 82.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 0.825, Test accuracy: 79.60 

Round  13, Train loss: 0.003, Test loss: 0.974, Test accuracy: 79.53 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.321, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.409, Test accuracy: 74.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.876, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.335, Test accuracy: 71.20 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.716, Test accuracy: 82.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.011, Train accuracy: 99.400, Test loss: 0.927, Test accuracy: 79.80 

Round  14, Train loss: 0.006, Test loss: 1.016, Test accuracy: 78.07 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.334, Test accuracy: 78.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.312, Test accuracy: 76.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.027, Test accuracy: 77.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.159, Test accuracy: 75.20 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.777, Test accuracy: 82.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.008, Train accuracy: 99.600, Test loss: 0.827, Test accuracy: 80.80 

Round  15, Train loss: 0.003, Test loss: 1.008, Test accuracy: 78.73 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.263, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.336, Test accuracy: 76.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.952, Test accuracy: 77.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.047, Test accuracy: 78.20 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.746, Test accuracy: 81.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.759, Test accuracy: 83.60 

Round  16, Train loss: 0.000, Test loss: 1.004, Test accuracy: 79.27 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.382, Test accuracy: 76.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.280, Test accuracy: 77.40 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.993, Test accuracy: 76.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.042, Test accuracy: 78.20 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.764, Test accuracy: 82.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.009, Train accuracy: 100.000, Test loss: 1.055, Test accuracy: 79.60 

Round  17, Train loss: 0.003, Test loss: 1.016, Test accuracy: 79.47 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.293, Test accuracy: 75.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 99.800, Test loss: 1.371, Test accuracy: 75.80 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.951, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.964, Test accuracy: 79.00 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.759, Test accuracy: 83.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.795, Test accuracy: 82.60 

Round  18, Train loss: 0.001, Test loss: 0.983, Test accuracy: 79.13 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.296, Test accuracy: 77.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.332, Test accuracy: 76.40 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.926, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.983, Test accuracy: 78.40 

        train local model (freeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.814, Test accuracy: 82.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.820, Test accuracy: 82.00 

Round  19, Train loss: 0.001, Test loss: 1.025, Test accuracy: 79.33 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.245, Test accuracy: 77.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.479, Test accuracy: 73.60 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.929, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.941, Test accuracy: 78.80 

        train local model (freeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.758, Test accuracy: 82.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.939, Test accuracy: 80.40 

Final Round, Train loss: 0.002, Test loss: 1.001, Test accuracy: 79.27 

---------------------------------------------train_client: [0, 1, 2, 3] 

        init --> train local model(freeze embeding):client   3,  Train loss: 0.675, Train accuracy: 74.800, Test loss: 0.979, Test accuracy: 64.00 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.293, Test accuracy: 77.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.316, Test accuracy: 76.60 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.924, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.096, Test accuracy: 74.80 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.763, Test accuracy: 82.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.047, Train accuracy: 98.800, Test loss: 0.982, Test accuracy: 79.20 

        train local model (freeze embeding):client   3,  Train loss: 0.719, Train accuracy: 71.200, Test loss: 1.076, Test accuracy: 62.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.142, Train accuracy: 94.800, Test loss: 1.112, Test accuracy: 64.20 

Round   0, Train loss: 0.048, Test loss: 0.934, Test accuracy: 76.10 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.163, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.299, Test accuracy: 75.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.844, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.115, Test accuracy: 74.80 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.690, Test accuracy: 82.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.891, Test accuracy: 81.40 

        train local model (freeze embeding):client   3,  Train loss: 0.349, Train accuracy: 88.400, Test loss: 1.001, Test accuracy: 67.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.090, Train accuracy: 97.400, Test loss: 1.379, Test accuracy: 66.40 

Round   1, Train loss: 0.025, Test loss: 0.986, Test accuracy: 76.00 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.156, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.477, Test accuracy: 75.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.862, Test accuracy: 79.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.931, Test accuracy: 77.60 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.713, Test accuracy: 84.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.740, Test accuracy: 82.60 

        train local model (freeze embeding):client   3,  Train loss: 0.205, Train accuracy: 94.000, Test loss: 1.040, Test accuracy: 68.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.076, Train accuracy: 96.600, Test loss: 1.395, Test accuracy: 65.80 

Round   2, Train loss: 0.020, Test loss: 1.012, Test accuracy: 76.70 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.209, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.304, Test accuracy: 77.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.818, Test accuracy: 78.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.108, Test accuracy: 73.80 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.715, Test accuracy: 84.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.865, Test accuracy: 82.80 

        train local model (freeze embeding):client   3,  Train loss: 0.115, Train accuracy: 96.600, Test loss: 1.119, Test accuracy: 69.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.060, Train accuracy: 98.400, Test loss: 1.307, Test accuracy: 68.00 

Round   3, Train loss: 0.016, Test loss: 0.927, Test accuracy: 77.55 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.189, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.515, Test accuracy: 73.60 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.851, Test accuracy: 77.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.004, Test accuracy: 78.60 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.715, Test accuracy: 83.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.895, Test accuracy: 80.40 

        train local model (freeze embeding):client   3,  Train loss: 0.052, Train accuracy: 99.800, Test loss: 1.094, Test accuracy: 70.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.038, Train accuracy: 99.200, Test loss: 1.423, Test accuracy: 67.60 

Round   4, Train loss: 0.010, Test loss: 0.957, Test accuracy: 77.85 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.210, Test accuracy: 77.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.418, Test accuracy: 75.00 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.852, Test accuracy: 78.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.109, Test accuracy: 76.00 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.729, Test accuracy: 84.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.885, Test accuracy: 81.40 

        train local model (freeze embeding):client   3,  Train loss: 0.040, Train accuracy: 99.400, Test loss: 1.127, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.146, Train accuracy: 94.200, Test loss: 1.952, Test accuracy: 59.40 

Round   5, Train loss: 0.039, Test loss: 0.950, Test accuracy: 77.75 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.165, Test accuracy: 78.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.327, Test accuracy: 77.20 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.874, Test accuracy: 78.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.076, Test accuracy: 75.80 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.669, Test accuracy: 83.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.012, Train accuracy: 99.600, Test loss: 0.814, Test accuracy: 82.00 

        train local model (freeze embeding):client   3,  Train loss: 0.043, Train accuracy: 99.000, Test loss: 1.231, Test accuracy: 68.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.235, Train accuracy: 91.000, Test loss: 1.930, Test accuracy: 61.60 

Round   6, Train loss: 0.062, Test loss: 0.945, Test accuracy: 77.05 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.092, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 1.253, Test accuracy: 76.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.796, Test accuracy: 77.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.014, Train accuracy: 99.600, Test loss: 1.238, Test accuracy: 74.20 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.683, Test accuracy: 84.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.012, Train accuracy: 99.600, Test loss: 0.824, Test accuracy: 83.80 

        train local model (freeze embeding):client   3,  Train loss: 0.020, Train accuracy: 99.800, Test loss: 1.223, Test accuracy: 70.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.098, Train accuracy: 97.000, Test loss: 1.640, Test accuracy: 62.40 

Round   7, Train loss: 0.032, Test loss: 0.921, Test accuracy: 77.65 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.073, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.195, Test accuracy: 77.20 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.822, Test accuracy: 79.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.094, Test accuracy: 77.00 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.724, Test accuracy: 83.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.829, Test accuracy: 84.20 

        train local model (freeze embeding):client   3,  Train loss: 0.015, Train accuracy: 100.000, Test loss: 1.245, Test accuracy: 69.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.082, Train accuracy: 97.200, Test loss: 1.668, Test accuracy: 63.60 

Round   8, Train loss: 0.022, Test loss: 0.952, Test accuracy: 77.40 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.151, Test accuracy: 78.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.298, Test accuracy: 75.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.827, Test accuracy: 77.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.042, Train accuracy: 98.800, Test loss: 1.228, Test accuracy: 74.80 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.737, Test accuracy: 84.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.782, Test accuracy: 83.40 

        train local model (freeze embeding):client   3,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 1.218, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.056, Train accuracy: 98.400, Test loss: 1.691, Test accuracy: 66.20 

Round   9, Train loss: 0.027, Test loss: 0.968, Test accuracy: 77.50 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.106, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.195, Test accuracy: 78.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.839, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.926, Test accuracy: 77.20 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.740, Test accuracy: 83.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.875, Test accuracy: 82.20 

        train local model (freeze embeding):client   3,  Train loss: 0.009, Train accuracy: 100.000, Test loss: 1.194, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.009, Train accuracy: 99.800, Test loss: 1.557, Test accuracy: 69.00 

Round  10, Train loss: 0.003, Test loss: 0.979, Test accuracy: 77.75 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.125, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.014, Train accuracy: 99.400, Test loss: 1.442, Test accuracy: 74.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.839, Test accuracy: 78.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.896, Test accuracy: 79.40 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.773, Test accuracy: 84.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.047, Train accuracy: 98.200, Test loss: 0.865, Test accuracy: 80.80 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.271, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.185, Train accuracy: 94.200, Test loss: 1.932, Test accuracy: 59.80 

Round  11, Train loss: 0.062, Test loss: 0.927, Test accuracy: 78.45 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.119, Test accuracy: 78.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.187, Test accuracy: 78.20 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.758, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.009, Train accuracy: 99.800, Test loss: 0.988, Test accuracy: 76.80 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.713, Test accuracy: 83.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.889, Test accuracy: 81.80 

        train local model (freeze embeding):client   3,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.202, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.038, Train accuracy: 99.200, Test loss: 1.716, Test accuracy: 63.60 

Round  12, Train loss: 0.012, Test loss: 0.948, Test accuracy: 78.45 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.151, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.283, Test accuracy: 75.60 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.780, Test accuracy: 78.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.843, Test accuracy: 78.80 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.724, Test accuracy: 82.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.791, Test accuracy: 83.40 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.202, Test accuracy: 71.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.212, Train accuracy: 93.800, Test loss: 1.884, Test accuracy: 60.60 

Round  13, Train loss: 0.053, Test loss: 0.990, Test accuracy: 78.15 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.187, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.032, Train accuracy: 98.600, Test loss: 1.814, Test accuracy: 71.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.825, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.009, Train accuracy: 99.600, Test loss: 1.126, Test accuracy: 75.40 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.810, Test accuracy: 81.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.831, Test accuracy: 82.00 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.243, Test accuracy: 71.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.555, Test accuracy: 68.00 

Round  14, Train loss: 0.011, Test loss: 1.013, Test accuracy: 77.35 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.243, Test accuracy: 78.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 1.315, Test accuracy: 76.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.861, Test accuracy: 78.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.877, Test accuracy: 79.40 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.773, Test accuracy: 82.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.758, Test accuracy: 82.60 

        train local model (freeze embeding):client   3,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.279, Test accuracy: 70.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.043, Train accuracy: 98.800, Test loss: 1.919, Test accuracy: 63.00 

Round  15, Train loss: 0.013, Test loss: 1.016, Test accuracy: 77.50 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.180, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.223, Test accuracy: 77.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.818, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.018, Train accuracy: 99.600, Test loss: 1.187, Test accuracy: 74.40 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.727, Test accuracy: 84.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.794, Test accuracy: 84.20 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.279, Test accuracy: 69.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.038, Train accuracy: 98.400, Test loss: 1.718, Test accuracy: 67.40 

Round  16, Train loss: 0.014, Test loss: 0.984, Test accuracy: 77.85 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.154, Test accuracy: 78.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.246, Test accuracy: 79.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.836, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.959, Test accuracy: 78.00 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.750, Test accuracy: 84.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.861, Test accuracy: 82.80 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.324, Test accuracy: 71.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.457, Test accuracy: 71.20 

Round  17, Train loss: 0.001, Test loss: 1.004, Test accuracy: 78.80 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.145, Test accuracy: 77.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.018, Train accuracy: 99.400, Test loss: 1.363, Test accuracy: 74.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.835, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.952, Test accuracy: 76.80 

        train local model (freeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.781, Test accuracy: 84.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.032, Train accuracy: 98.800, Test loss: 0.849, Test accuracy: 82.40 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.303, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.391, Test accuracy: 72.60 

Round  18, Train loss: 0.013, Test loss: 0.981, Test accuracy: 78.05 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.108, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.489, Test accuracy: 75.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.859, Test accuracy: 78.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 1.083, Test accuracy: 77.00 

        train local model (freeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.769, Test accuracy: 84.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.762, Test accuracy: 84.00 

        train local model (freeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.284, Test accuracy: 71.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.461, Test accuracy: 73.20 

Round  19, Train loss: 0.002, Test loss: 1.028, Test accuracy: 77.95 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.153, Test accuracy: 78.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.326, Test accuracy: 77.80 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.832, Test accuracy: 78.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.949, Test accuracy: 78.20 

        train local model (freeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.765, Test accuracy: 84.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.781, Test accuracy: 83.40 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.396, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.089, Train accuracy: 96.800, Test loss: 1.912, Test accuracy: 63.20 

Final Round, Train loss: 0.022, Test loss: 1.016, Test accuracy: 78.40 

---------------------------------------------train_client: [0, 1, 2, 3, 4] 

        init --> train local model(freeze embeding):client   4,  Train loss: 0.478, Train accuracy: 81.600, Test loss: 0.741, Test accuracy: 75.40 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.178, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.356, Test accuracy: 77.80 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.864, Test accuracy: 78.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.923, Test accuracy: 78.00 

        train local model (freeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.780, Test accuracy: 84.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.796, Test accuracy: 83.80 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.405, Test accuracy: 70.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.060, Train accuracy: 97.200, Test loss: 1.837, Test accuracy: 63.00 

        train local model (freeze embeding):client   4,  Train loss: 0.427, Train accuracy: 83.600, Test loss: 0.682, Test accuracy: 77.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.069, Train accuracy: 98.200, Test loss: 0.981, Test accuracy: 73.60 

Round   0, Train loss: 0.026, Test loss: 0.897, Test accuracy: 78.72 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.099, Test accuracy: 80.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.291, Test accuracy: 79.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.808, Test accuracy: 78.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.997, Test accuracy: 76.60 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.711, Test accuracy: 85.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.751, Test accuracy: 83.60 

        train local model (freeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.336, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.040, Train accuracy: 99.000, Test loss: 1.899, Test accuracy: 66.80 

        train local model (freeze embeding):client   4,  Train loss: 0.236, Train accuracy: 93.000, Test loss: 0.717, Test accuracy: 78.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.055, Train accuracy: 98.800, Test loss: 0.977, Test accuracy: 73.40 

Round   1, Train loss: 0.020, Test loss: 0.941, Test accuracy: 78.00 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.115, Test accuracy: 80.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.179, Test accuracy: 80.00 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.772, Test accuracy: 78.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.879, Test accuracy: 79.00 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.685, Test accuracy: 85.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.723, Test accuracy: 85.40 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.310, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.603, Test accuracy: 69.80 

        train local model (freeze embeding):client   4,  Train loss: 0.175, Train accuracy: 94.600, Test loss: 0.713, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.047, Train accuracy: 98.400, Test loss: 1.088, Test accuracy: 73.40 

Round   2, Train loss: 0.010, Test loss: 0.913, Test accuracy: 78.88 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.145, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.173, Test accuracy: 80.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.813, Test accuracy: 78.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.023, Test accuracy: 76.80 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.696, Test accuracy: 85.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 0.717, Test accuracy: 85.40 

        train local model (freeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.305, Test accuracy: 72.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.501, Test accuracy: 71.20 

        train local model (freeze embeding):client   4,  Train loss: 0.055, Train accuracy: 98.600, Test loss: 0.721, Test accuracy: 78.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.070, Train accuracy: 98.600, Test loss: 1.341, Test accuracy: 71.80 

Round   3, Train loss: 0.016, Test loss: 0.929, Test accuracy: 79.68 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.074, Test accuracy: 82.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.021, Train accuracy: 99.400, Test loss: 1.375, Test accuracy: 73.20 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.823, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.996, Test accuracy: 77.40 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.713, Test accuracy: 84.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.761, Test accuracy: 85.80 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.313, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.084, Train accuracy: 97.400, Test loss: 1.821, Test accuracy: 63.80 

        train local model (freeze embeding):client   4,  Train loss: 0.030, Train accuracy: 99.800, Test loss: 0.781, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.027, Train accuracy: 99.600, Test loss: 1.093, Test accuracy: 75.60 

Round   4, Train loss: 0.027, Test loss: 0.871, Test accuracy: 79.28 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.038, Test accuracy: 81.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.138, Test accuracy: 79.60 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.803, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.969, Test accuracy: 76.60 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.693, Test accuracy: 85.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.780, Test accuracy: 82.60 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.245, Test accuracy: 72.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.363, Test accuracy: 73.40 

        train local model (freeze embeding):client   4,  Train loss: 0.025, Train accuracy: 99.800, Test loss: 0.766, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.101, Train accuracy: 96.400, Test loss: 1.434, Test accuracy: 70.00 

Round   5, Train loss: 0.022, Test loss: 0.913, Test accuracy: 79.40 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.058, Test accuracy: 80.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.123, Test accuracy: 79.40 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.778, Test accuracy: 78.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 0.975, Test accuracy: 77.00 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.702, Test accuracy: 85.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.714, Test accuracy: 84.80 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.328, Test accuracy: 71.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.057, Train accuracy: 98.800, Test loss: 1.647, Test accuracy: 65.20 

        train local model (freeze embeding):client   4,  Train loss: 0.016, Train accuracy: 100.000, Test loss: 0.806, Test accuracy: 77.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.179, Train accuracy: 94.000, Test loss: 1.641, Test accuracy: 65.80 

Round   6, Train loss: 0.048, Test loss: 0.883, Test accuracy: 79.80 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.056, Test accuracy: 80.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.128, Train accuracy: 96.400, Test loss: 1.585, Test accuracy: 67.00 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.760, Test accuracy: 78.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.003, Test accuracy: 76.80 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.687, Test accuracy: 85.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.730, Test accuracy: 85.60 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.232, Test accuracy: 73.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.495, Test accuracy: 71.80 

        train local model (freeze embeding):client   4,  Train loss: 0.011, Train accuracy: 100.000, Test loss: 0.808, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.143, Train accuracy: 94.800, Test loss: 1.461, Test accuracy: 68.20 

Round   7, Train loss: 0.055, Test loss: 0.896, Test accuracy: 79.60 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.061, Test accuracy: 80.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.129, Test accuracy: 79.00 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.787, Test accuracy: 78.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.031, Train accuracy: 98.600, Test loss: 1.250, Test accuracy: 73.80 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.675, Test accuracy: 86.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.739, Test accuracy: 83.20 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.233, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.024, Train accuracy: 98.600, Test loss: 1.561, Test accuracy: 66.80 

        train local model (freeze embeding):client   4,  Train loss: 0.009, Train accuracy: 100.000, Test loss: 0.812, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.239, Train accuracy: 92.200, Test loss: 1.436, Test accuracy: 69.20 

Round   8, Train loss: 0.060, Test loss: 0.862, Test accuracy: 79.56 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.988, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.110, Test accuracy: 79.20 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.731, Test accuracy: 80.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.898, Test accuracy: 78.40 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.668, Test accuracy: 85.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.827, Test accuracy: 82.80 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.216, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.018, Train accuracy: 99.600, Test loss: 1.668, Test accuracy: 67.20 

        train local model (freeze embeding):client   4,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 0.835, Test accuracy: 78.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.053, Train accuracy: 99.000, Test loss: 1.290, Test accuracy: 70.60 

Round   9, Train loss: 0.015, Test loss: 0.893, Test accuracy: 79.20 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.016, Test accuracy: 81.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.054, Train accuracy: 98.200, Test loss: 1.349, Test accuracy: 71.00 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.754, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.007, Train accuracy: 99.600, Test loss: 0.973, Test accuracy: 80.40 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.683, Test accuracy: 84.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.772, Test accuracy: 85.80 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.282, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.508, Test accuracy: 70.20 

        train local model (freeze embeding):client   4,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.837, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.029, Train accuracy: 99.200, Test loss: 1.410, Test accuracy: 73.20 

Round  10, Train loss: 0.018, Test loss: 0.925, Test accuracy: 79.28 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.022, Test accuracy: 80.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.113, Test accuracy: 80.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.798, Test accuracy: 79.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.033, Train accuracy: 99.200, Test loss: 1.178, Test accuracy: 75.80 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.713, Test accuracy: 85.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.791, Test accuracy: 84.40 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.300, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.404, Test accuracy: 71.40 

        train local model (freeze embeding):client   4,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.871, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.067, Train accuracy: 97.600, Test loss: 1.090, Test accuracy: 71.80 

Round  11, Train loss: 0.021, Test loss: 0.884, Test accuracy: 79.04 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.989, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 1.182, Test accuracy: 78.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.786, Test accuracy: 79.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.829, Test accuracy: 79.20 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.653, Test accuracy: 84.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.012, Train accuracy: 100.000, Test loss: 0.743, Test accuracy: 83.00 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.248, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.039, Train accuracy: 98.800, Test loss: 1.732, Test accuracy: 62.80 

        train local model (freeze embeding):client   4,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 0.865, Test accuracy: 77.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 1.154, Test accuracy: 76.60 

Round  12, Train loss: 0.013, Test loss: 0.904, Test accuracy: 78.76 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.984, Test accuracy: 80.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.009, Train accuracy: 99.800, Test loss: 1.273, Test accuracy: 76.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.742, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.912, Test accuracy: 78.20 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.660, Test accuracy: 85.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.715, Test accuracy: 86.00 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.312, Test accuracy: 70.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 1.376, Test accuracy: 72.80 

        train local model (freeze embeding):client   4,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.886, Test accuracy: 76.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.009, Train accuracy: 99.600, Test loss: 1.095, Test accuracy: 76.00 

Round  13, Train loss: 0.005, Test loss: 0.901, Test accuracy: 79.08 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.007, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.174, Test accuracy: 77.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.758, Test accuracy: 80.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.879, Test accuracy: 79.00 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.695, Test accuracy: 85.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.737, Test accuracy: 84.20 

        train local model (freeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.279, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.467, Test accuracy: 72.20 

        train local model (freeze embeding):client   4,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.916, Test accuracy: 76.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.081, Train accuracy: 96.800, Test loss: 1.213, Test accuracy: 71.00 

Round  14, Train loss: 0.017, Test loss: 0.928, Test accuracy: 79.20 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.022, Test accuracy: 80.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.084, Test accuracy: 79.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.766, Test accuracy: 80.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.010, Test accuracy: 78.00 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.694, Test accuracy: 85.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.733, Test accuracy: 85.80 

        train local model (freeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.282, Test accuracy: 71.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.034, Train accuracy: 99.400, Test loss: 1.613, Test accuracy: 69.00 

        train local model (freeze embeding):client   4,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.904, Test accuracy: 77.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.083, Train accuracy: 96.600, Test loss: 1.351, Test accuracy: 70.60 

Round  15, Train loss: 0.024, Test loss: 0.904, Test accuracy: 79.48 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.962, Test accuracy: 80.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.017, Train accuracy: 99.400, Test loss: 1.203, Test accuracy: 77.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.801, Test accuracy: 78.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.027, Train accuracy: 99.200, Test loss: 1.075, Test accuracy: 76.40 

        train local model (freeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.676, Test accuracy: 86.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.815, Test accuracy: 83.80 

        train local model (freeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.296, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.026, Train accuracy: 99.000, Test loss: 1.862, Test accuracy: 63.80 

        train local model (freeze embeding):client   4,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.874, Test accuracy: 77.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.017, Train accuracy: 99.600, Test loss: 1.226, Test accuracy: 73.60 

Round  16, Train loss: 0.017, Test loss: 0.921, Test accuracy: 79.40 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.010, Test accuracy: 80.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.091, Test accuracy: 81.00 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.804, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.890, Test accuracy: 79.60 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.654, Test accuracy: 85.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.680, Test accuracy: 85.20 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.275, Test accuracy: 71.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.049, Train accuracy: 98.000, Test loss: 1.892, Test accuracy: 64.80 

        train local model (freeze embeding):client   4,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.904, Test accuracy: 77.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.093, Test accuracy: 76.00 

Round  17, Train loss: 0.010, Test loss: 0.944, Test accuracy: 79.08 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.981, Test accuracy: 81.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.034, Train accuracy: 98.800, Test loss: 1.496, Test accuracy: 74.40 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.781, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.882, Test accuracy: 77.80 

        train local model (freeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.684, Test accuracy: 85.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.754, Test accuracy: 83.40 

        train local model (freeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.292, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.033, Train accuracy: 98.600, Test loss: 1.619, Test accuracy: 69.20 

        train local model (freeze embeding):client   4,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.878, Test accuracy: 78.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.059, Train accuracy: 98.000, Test loss: 1.349, Test accuracy: 69.00 

Round  18, Train loss: 0.025, Test loss: 0.899, Test accuracy: 79.56 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.964, Test accuracy: 81.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.067, Test accuracy: 79.40 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.747, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.034, Test accuracy: 77.80 

        train local model (freeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.693, Test accuracy: 85.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 0.671, Test accuracy: 85.20 

        train local model (freeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.244, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.046, Train accuracy: 98.000, Test loss: 1.586, Test accuracy: 68.40 

        train local model (freeze embeding):client   4,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.897, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.994, Test accuracy: 77.60 

Round  19, Train loss: 0.012, Test loss: 0.874, Test accuracy: 79.72 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.922, Test accuracy: 81.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.033, Test accuracy: 79.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.764, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.874, Test accuracy: 80.00 

        train local model (freeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.650, Test accuracy: 86.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.003, Train accuracy: 99.800, Test loss: 0.844, Test accuracy: 82.40 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.185, Test accuracy: 74.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.412, Test accuracy: 71.80 

        train local model (freeze embeding):client   4,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.879, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.037, Train accuracy: 99.200, Test loss: 1.282, Test accuracy: 71.80 

Final Round, Train loss: 0.008, Test loss: 0.877, Test accuracy: 80.16 

Average accuracy final 10 rounds: 378.48 

4818.990147590637
[14.348748445510864, 29.458852291107178, 44.32052564620972, 58.90518069267273, 74.113929271698, 89.05239152908325, 103.51147603988647, 117.86067056655884, 132.45529294013977, 147.52163767814636, 161.6751847267151, 176.4660120010376, 190.89404487609863, 205.33592057228088, 220.30058407783508, 234.9446337223053, 249.86098527908325, 264.1597957611084, 279.0002875328064, 293.938645362854, 308.43590331077576, 323.45474886894226, 338.6567714214325, 352.8856728076935, 367.63812375068665, 382.4446406364441, 397.464013338089, 412.0968463420868, 427.2999224662781, 442.05118131637573, 456.5464701652527, 472.27536940574646, 487.7659184932709, 502.623899936676, 517.3061299324036, 532.445395231247, 546.9957051277161, 562.2224187850952, 577.5298941135406, 592.479510307312, 607.5473480224609, 621.888213634491, 636.8586189746857, 652.1042313575745, 667.0839447975159, 681.9814188480377, 697.5098562240601, 712.7268998622894, 727.2963845729828, 742.2599275112152, 757.3010082244873, 771.7882037162781, 786.6268870830536, 801.2271642684937, 815.9342470169067, 831.1018023490906, 846.0726819038391, 860.6086349487305, 875.9683434963226, 890.8713290691376, 905.9454007148743, 920.3760669231415, 935.107696056366, 950.6718878746033, 966.0777504444122, 981.8563838005066, 997.1002426147461, 1012.4504208564758, 1027.3114175796509, 1042.4325881004333, 1057.6397953033447, 1073.1646621227264, 1088.5507953166962, 1103.8068828582764, 1119.3875410556793, 1134.6934642791748, 1149.5956161022186, 1165.1907939910889, 1180.7884047031403, 1195.8154590129852, 1210.513644695282, 1225.5803298950195, 1241.4240646362305, 1257.3002746105194, 1272.2957379817963, 1287.6903820037842, 1302.7548973560333, 1318.1922550201416, 1333.1176226139069, 1348.0756068229675, 1362.9613242149353, 1378.5791687965393, 1393.4736776351929, 1408.5935101509094, 1423.8951497077942, 1439.0674781799316, 1453.488665819168, 1468.6369247436523, 1483.1850357055664, 1498.7207350730896, 1514.6715636253357, 1529.9645285606384, 1545.233463525772, 1560.5212407112122, 1575.3847920894623]
[56.6, 53.8, 60.0, 59.6, 65.6, 67.8, 64.2, 66.8, 68.8, 70.8, 69.2, 60.6, 70.4, 69.8, 70.8, 69.2, 69.2, 71.4, 68.2, 72.4, 72.2, 67.6, 70.7, 70.9, 73.0, 70.5, 70.9, 73.5, 71.3, 72.5, 73.3, 71.9, 72.8, 71.8, 74.2, 74.8, 73.8, 71.5, 73.4, 72.0, 74.1, 74.1, 75.86666666666666, 77.8, 76.93333333333334, 78.46666666666667, 77.93333333333334, 77.6, 78.2, 78.8, 78.6, 79.73333333333333, 78.6, 79.06666666666666, 79.2, 79.53333333333333, 78.06666666666666, 78.73333333333333, 79.26666666666667, 79.46666666666667, 79.13333333333334, 79.33333333333333, 79.26666666666667, 76.1, 76.0, 76.7, 77.55, 77.85, 77.75, 77.05, 77.65, 77.4, 77.5, 77.75, 78.45, 78.45, 78.15, 77.35, 77.5, 77.85, 78.8, 78.05, 77.95, 78.4, 78.72, 78.0, 78.88, 79.68, 79.28, 79.4, 79.8, 79.6, 79.56, 79.2, 79.28, 79.04, 78.76, 79.08, 79.2, 79.48, 79.4, 79.08, 79.56, 79.72, 80.16]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.446, Test loss: 1.294, Test accuracy: 51.88 

Round   0, Global train loss: 1.446, Global test loss: 2.294, Global test accuracy: 16.08 

Round   1, Train loss: 1.139, Test loss: 1.326, Test accuracy: 52.40 

Round   1, Global train loss: 1.139, Global test loss: 2.432, Global test accuracy: 16.00 

Round   2, Train loss: 0.956, Test loss: 1.327, Test accuracy: 55.12 

Round   2, Global train loss: 0.956, Global test loss: 2.389, Global test accuracy: 16.08 

Round   3, Train loss: 0.820, Test loss: 1.559, Test accuracy: 56.40 

Round   3, Global train loss: 0.820, Global test loss: 2.492, Global test accuracy: 16.00 

Round   4, Train loss: 0.703, Test loss: 1.340, Test accuracy: 60.52 

Round   4, Global train loss: 0.703, Global test loss: 2.547, Global test accuracy: 16.00 

Round   5, Train loss: 0.605, Test loss: 1.301, Test accuracy: 61.68 

Round   5, Global train loss: 0.605, Global test loss: 2.637, Global test accuracy: 16.00 

Round   6, Train loss: 0.502, Test loss: 1.201, Test accuracy: 65.76 

Round   6, Global train loss: 0.502, Global test loss: 2.675, Global test accuracy: 16.00 

Round   7, Train loss: 0.446, Test loss: 1.384, Test accuracy: 63.44 

Round   7, Global train loss: 0.446, Global test loss: 2.753, Global test accuracy: 16.00 

Round   8, Train loss: 0.365, Test loss: 1.399, Test accuracy: 64.80 

Round   8, Global train loss: 0.365, Global test loss: 2.719, Global test accuracy: 16.00 

Round   9, Train loss: 0.305, Test loss: 1.384, Test accuracy: 66.92 

Round   9, Global train loss: 0.305, Global test loss: 2.960, Global test accuracy: 16.00 

Round  10, Train loss: 0.270, Test loss: 1.418, Test accuracy: 66.88 

Round  10, Global train loss: 0.270, Global test loss: 2.898, Global test accuracy: 16.00 

Round  11, Train loss: 0.218, Test loss: 1.551, Test accuracy: 66.04 

Round  11, Global train loss: 0.218, Global test loss: 2.930, Global test accuracy: 16.00 

Round  12, Train loss: 0.193, Test loss: 1.565, Test accuracy: 65.56 

Round  12, Global train loss: 0.193, Global test loss: 2.914, Global test accuracy: 16.00 

Round  13, Train loss: 0.166, Test loss: 1.435, Test accuracy: 69.48 

Round  13, Global train loss: 0.166, Global test loss: 2.950, Global test accuracy: 16.00 

Round  14, Train loss: 0.150, Test loss: 1.471, Test accuracy: 68.60 

Round  14, Global train loss: 0.150, Global test loss: 2.955, Global test accuracy: 16.00 

Round  15, Train loss: 0.129, Test loss: 1.687, Test accuracy: 67.20 

Round  15, Global train loss: 0.129, Global test loss: 2.880, Global test accuracy: 16.00 

Round  16, Train loss: 0.105, Test loss: 1.486, Test accuracy: 69.28 

Round  16, Global train loss: 0.105, Global test loss: 2.769, Global test accuracy: 16.08 

Round  17, Train loss: 0.102, Test loss: 1.695, Test accuracy: 66.92 

Round  17, Global train loss: 0.102, Global test loss: 2.959, Global test accuracy: 16.00 

Round  18, Train loss: 0.081, Test loss: 1.685, Test accuracy: 67.28 

Round  18, Global train loss: 0.081, Global test loss: 2.785, Global test accuracy: 16.04 

Round  19, Train loss: 0.076, Test loss: 1.670, Test accuracy: 69.08 

Round  19, Global train loss: 0.076, Global test loss: 2.965, Global test accuracy: 16.00 

Round  20, Train loss: 0.055, Test loss: 1.673, Test accuracy: 69.60 

Round  20, Global train loss: 0.055, Global test loss: 2.914, Global test accuracy: 16.04 

Round  21, Train loss: 0.062, Test loss: 1.673, Test accuracy: 69.44 

Round  21, Global train loss: 0.062, Global test loss: 2.875, Global test accuracy: 16.00 

Round  22, Train loss: 0.064, Test loss: 1.511, Test accuracy: 70.84 

Round  22, Global train loss: 0.064, Global test loss: 2.887, Global test accuracy: 16.04 

Round  23, Train loss: 0.058, Test loss: 1.596, Test accuracy: 69.56 

Round  23, Global train loss: 0.058, Global test loss: 2.775, Global test accuracy: 16.04 

Round  24, Train loss: 0.047, Test loss: 1.809, Test accuracy: 68.40 

Round  24, Global train loss: 0.047, Global test loss: 2.885, Global test accuracy: 16.04 

Round  25, Train loss: 0.050, Test loss: 1.639, Test accuracy: 70.32 

Round  25, Global train loss: 0.050, Global test loss: 2.785, Global test accuracy: 16.04 

Round  26, Train loss: 0.052, Test loss: 1.635, Test accuracy: 69.60 

Round  26, Global train loss: 0.052, Global test loss: 2.803, Global test accuracy: 16.00 

Round  27, Train loss: 0.033, Test loss: 1.650, Test accuracy: 70.24 

Round  27, Global train loss: 0.033, Global test loss: 2.817, Global test accuracy: 16.04 

Round  28, Train loss: 0.043, Test loss: 1.695, Test accuracy: 70.12 

Round  28, Global train loss: 0.043, Global test loss: 2.865, Global test accuracy: 16.00 

Round  29, Train loss: 0.030, Test loss: 1.635, Test accuracy: 71.44 

Round  29, Global train loss: 0.030, Global test loss: 3.042, Global test accuracy: 16.00 

Round  30, Train loss: 0.029, Test loss: 1.638, Test accuracy: 70.76 

Round  30, Global train loss: 0.029, Global test loss: 2.919, Global test accuracy: 16.04 

Round  31, Train loss: 0.028, Test loss: 1.612, Test accuracy: 72.20 

Round  31, Global train loss: 0.028, Global test loss: 2.969, Global test accuracy: 16.00 

Round  32, Train loss: 0.029, Test loss: 1.789, Test accuracy: 71.00 

Round  32, Global train loss: 0.029, Global test loss: 3.111, Global test accuracy: 16.00 

Round  33, Train loss: 0.024, Test loss: 1.732, Test accuracy: 71.28 

Round  33, Global train loss: 0.024, Global test loss: 3.041, Global test accuracy: 16.00 

Round  34, Train loss: 0.022, Test loss: 1.684, Test accuracy: 70.92 

Round  34, Global train loss: 0.022, Global test loss: 2.926, Global test accuracy: 16.00 

Final Round, Train loss: 0.032, Test loss: 1.845, Test accuracy: 70.20 

Final Round, Global train loss: 0.032, Global test loss: 2.926, Global test accuracy: 16.00 

Average accuracy final 10 rounds: 70.788 

Average global accuracy final 10 rounds: 16.011999999999997 

1148.2296080589294
[7.640861749649048, 13.566645860671997, 19.351405382156372, 25.26048731803894, 31.167356967926025, 37.047492027282715, 42.71034097671509, 48.30732560157776, 54.017212867736816, 60.087130308151245, 66.10203266143799, 71.8300633430481, 77.68156027793884, 83.24050402641296, 88.9917585849762, 94.61883664131165, 100.43899369239807, 106.0225396156311, 111.64126920700073, 117.2094714641571, 122.85793232917786, 128.60191130638123, 134.23564743995667, 139.92930817604065, 145.48768615722656, 151.15311312675476, 156.89625668525696, 162.50501656532288, 167.93034648895264, 173.5004608631134, 179.15478944778442, 184.74172377586365, 190.53082847595215, 196.23303508758545, 201.96442079544067, 213.17628717422485]
[51.88, 52.4, 55.12, 56.4, 60.52, 61.68, 65.76, 63.44, 64.8, 66.92, 66.88, 66.04, 65.56, 69.48, 68.6, 67.2, 69.28, 66.92, 67.28, 69.08, 69.6, 69.44, 70.84, 69.56, 68.4, 70.32, 69.6, 70.24, 70.12, 71.44, 70.76, 72.2, 71.0, 71.28, 70.92, 70.2]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.455, Test loss: 1.240, Test accuracy: 51.92 

Round   0, Global train loss: 1.455, Global test loss: 2.277, Global test accuracy: 16.04 

Round   1, Train loss: 1.318, Test loss: 1.256, Test accuracy: 52.16 

Round   1, Global train loss: 1.318, Global test loss: 1.905, Global test accuracy: 34.80 

Round   2, Train loss: 1.152, Test loss: 1.043, Test accuracy: 59.64 

Round   2, Global train loss: 1.152, Global test loss: 1.628, Global test accuracy: 45.28 

Round   3, Train loss: 1.036, Test loss: 1.259, Test accuracy: 57.48 

Round   3, Global train loss: 1.036, Global test loss: 1.508, Global test accuracy: 50.72 

Round   4, Train loss: 0.937, Test loss: 1.014, Test accuracy: 62.68 

Round   4, Global train loss: 0.937, Global test loss: 1.353, Global test accuracy: 58.36 

Round   5, Train loss: 0.845, Test loss: 1.152, Test accuracy: 63.64 

Round   5, Global train loss: 0.845, Global test loss: 1.502, Global test accuracy: 57.64 

Round   6, Train loss: 0.779, Test loss: 1.110, Test accuracy: 64.28 

Round   6, Global train loss: 0.779, Global test loss: 1.258, Global test accuracy: 61.84 

Round   7, Train loss: 0.707, Test loss: 1.084, Test accuracy: 65.48 

Round   7, Global train loss: 0.707, Global test loss: 1.195, Global test accuracy: 63.36 

Round   8, Train loss: 0.656, Test loss: 0.907, Test accuracy: 70.72 

Round   8, Global train loss: 0.656, Global test loss: 1.362, Global test accuracy: 62.84 

Round   9, Train loss: 0.604, Test loss: 0.925, Test accuracy: 71.64 

Round   9, Global train loss: 0.604, Global test loss: 1.220, Global test accuracy: 65.28 

Round  10, Train loss: 0.555, Test loss: 1.137, Test accuracy: 67.72 

Round  10, Global train loss: 0.555, Global test loss: 1.177, Global test accuracy: 65.76 

Round  11, Train loss: 0.520, Test loss: 0.982, Test accuracy: 70.60 

Round  11, Global train loss: 0.520, Global test loss: 1.180, Global test accuracy: 67.40 

Round  12, Train loss: 0.469, Test loss: 1.173, Test accuracy: 67.64 

Round  12, Global train loss: 0.469, Global test loss: 1.066, Global test accuracy: 68.56 

Round  13, Train loss: 0.448, Test loss: 0.955, Test accuracy: 72.76 

Round  13, Global train loss: 0.448, Global test loss: 1.223, Global test accuracy: 68.44 

Round  14, Train loss: 0.412, Test loss: 1.020, Test accuracy: 70.72 

Round  14, Global train loss: 0.412, Global test loss: 1.132, Global test accuracy: 69.08 

Round  15, Train loss: 0.363, Test loss: 1.210, Test accuracy: 69.32 

Round  15, Global train loss: 0.363, Global test loss: 1.191, Global test accuracy: 69.12 

Round  16, Train loss: 0.348, Test loss: 1.041, Test accuracy: 71.80 

Round  16, Global train loss: 0.348, Global test loss: 1.054, Global test accuracy: 70.48 

Round  17, Train loss: 0.329, Test loss: 0.982, Test accuracy: 73.08 

Round  17, Global train loss: 0.329, Global test loss: 1.041, Global test accuracy: 71.24 

Round  18, Train loss: 0.309, Test loss: 1.227, Test accuracy: 69.72 

Round  18, Global train loss: 0.309, Global test loss: 1.109, Global test accuracy: 70.60 

Round  19, Train loss: 0.292, Test loss: 0.960, Test accuracy: 74.96 

Round  19, Global train loss: 0.292, Global test loss: 1.090, Global test accuracy: 71.48 

Round  20, Train loss: 0.265, Test loss: 1.081, Test accuracy: 74.04 

Round  20, Global train loss: 0.265, Global test loss: 1.180, Global test accuracy: 70.60 

Round  21, Train loss: 0.248, Test loss: 0.983, Test accuracy: 75.88 

Round  21, Global train loss: 0.248, Global test loss: 1.144, Global test accuracy: 70.80 

Round  22, Train loss: 0.228, Test loss: 1.079, Test accuracy: 74.80 

Round  22, Global train loss: 0.228, Global test loss: 1.014, Global test accuracy: 72.48 

Round  23, Train loss: 0.211, Test loss: 1.176, Test accuracy: 73.04 

Round  23, Global train loss: 0.211, Global test loss: 1.016, Global test accuracy: 72.84 

Round  24, Train loss: 0.211, Test loss: 1.089, Test accuracy: 73.92 

Round  24, Global train loss: 0.211, Global test loss: 1.084, Global test accuracy: 71.52 

Round  25, Train loss: 0.180, Test loss: 0.963, Test accuracy: 76.28 

Round  25, Global train loss: 0.180, Global test loss: 1.062, Global test accuracy: 72.00 

Round  26, Train loss: 0.195, Test loss: 0.935, Test accuracy: 77.36 

Round  26, Global train loss: 0.195, Global test loss: 1.037, Global test accuracy: 72.60 

Round  27, Train loss: 0.163, Test loss: 1.181, Test accuracy: 75.40 

Round  27, Global train loss: 0.163, Global test loss: 1.136, Global test accuracy: 72.60 

Round  28, Train loss: 0.161, Test loss: 1.007, Test accuracy: 76.92 

Round  28, Global train loss: 0.161, Global test loss: 1.018, Global test accuracy: 73.20 

Round  29, Train loss: 0.157, Test loss: 1.026, Test accuracy: 76.32 

Round  29, Global train loss: 0.157, Global test loss: 1.091, Global test accuracy: 73.40 

Round  30, Train loss: 0.145, Test loss: 1.006, Test accuracy: 76.00 

Round  30, Global train loss: 0.145, Global test loss: 1.048, Global test accuracy: 71.92 

Round  31, Train loss: 0.122, Test loss: 1.078, Test accuracy: 76.76 

Round  31, Global train loss: 0.122, Global test loss: 1.076, Global test accuracy: 72.60 

Round  32, Train loss: 0.123, Test loss: 1.011, Test accuracy: 76.12 

Round  32, Global train loss: 0.123, Global test loss: 1.151, Global test accuracy: 72.40 

Round  33, Train loss: 0.127, Test loss: 1.143, Test accuracy: 76.60 

Round  33, Global train loss: 0.127, Global test loss: 1.038, Global test accuracy: 73.44 

Round  34, Train loss: 0.105, Test loss: 0.957, Test accuracy: 78.84 

Round  34, Global train loss: 0.105, Global test loss: 1.044, Global test accuracy: 72.36 

Round  35, Train loss: 0.091, Test loss: 1.291, Test accuracy: 74.56 

Round  35, Global train loss: 0.091, Global test loss: 1.007, Global test accuracy: 74.40 

Round  36, Train loss: 0.096, Test loss: 0.891, Test accuracy: 79.16 

Round  36, Global train loss: 0.096, Global test loss: 1.070, Global test accuracy: 73.28 

Round  37, Train loss: 0.081, Test loss: 1.317, Test accuracy: 75.52 

Round  37, Global train loss: 0.081, Global test loss: 1.050, Global test accuracy: 73.08 

Round  38, Train loss: 0.116, Test loss: 1.119, Test accuracy: 76.00 

Round  38, Global train loss: 0.116, Global test loss: 1.120, Global test accuracy: 73.24 

Round  39, Train loss: 0.069, Test loss: 0.960, Test accuracy: 79.48 

Round  39, Global train loss: 0.069, Global test loss: 1.057, Global test accuracy: 73.96 

Round  40, Train loss: 0.086, Test loss: 1.224, Test accuracy: 75.44 

Round  40, Global train loss: 0.086, Global test loss: 1.055, Global test accuracy: 73.68 

Round  41, Train loss: 0.084, Test loss: 0.896, Test accuracy: 80.52 

Round  41, Global train loss: 0.084, Global test loss: 1.111, Global test accuracy: 73.68 

Round  42, Train loss: 0.067, Test loss: 0.974, Test accuracy: 79.40 

Round  42, Global train loss: 0.067, Global test loss: 1.038, Global test accuracy: 74.56 

Round  43, Train loss: 0.061, Test loss: 0.989, Test accuracy: 79.00 

Round  43, Global train loss: 0.061, Global test loss: 1.061, Global test accuracy: 74.40 

Round  44, Train loss: 0.075, Test loss: 1.290, Test accuracy: 75.80 

Round  44, Global train loss: 0.075, Global test loss: 1.154, Global test accuracy: 72.36 

Round  45, Train loss: 0.057, Test loss: 1.080, Test accuracy: 77.92 

Round  45, Global train loss: 0.057, Global test loss: 1.015, Global test accuracy: 74.44 

Round  46, Train loss: 0.042, Test loss: 0.827, Test accuracy: 81.52 

Round  46, Global train loss: 0.042, Global test loss: 1.052, Global test accuracy: 74.76 

Round  47, Train loss: 0.056, Test loss: 1.070, Test accuracy: 78.24 

Round  47, Global train loss: 0.056, Global test loss: 1.030, Global test accuracy: 75.40 

Round  48, Train loss: 0.076, Test loss: 1.064, Test accuracy: 77.52 

Round  48, Global train loss: 0.076, Global test loss: 1.184, Global test accuracy: 72.36 

Round  49, Train loss: 0.052, Test loss: 0.870, Test accuracy: 81.20 

Round  49, Global train loss: 0.052, Global test loss: 1.040, Global test accuracy: 75.08 

Final Round, Train loss: 0.055, Test loss: 1.134, Test accuracy: 78.56 

Final Round, Global train loss: 0.055, Global test loss: 1.040, Global test accuracy: 75.08 

Average accuracy final 10 rounds: 78.656 

Average global accuracy final 10 rounds: 74.072 

1616.8835480213165
[7.649861097335815, 13.303147792816162, 18.89423179626465, 24.434524536132812, 30.27809166908264, 36.30986499786377, 42.04342269897461, 47.78609895706177, 53.44622492790222, 59.07420206069946, 64.83146238327026, 70.40876150131226, 75.97113299369812, 81.44153165817261, 87.30774021148682, 92.96583127975464, 98.4388210773468, 104.35218381881714, 110.20228242874146, 116.14161086082458, 121.71845555305481, 127.33085083961487, 132.98815155029297, 138.6935875415802, 144.27593731880188, 149.95315432548523, 155.63300013542175, 161.2765998840332, 166.9542679786682, 172.69188785552979, 178.37585139274597, 184.0321900844574, 189.82255101203918, 195.57891201972961, 201.54924201965332, 207.34885048866272, 212.94556498527527, 218.90605878829956, 224.68821716308594, 230.82136583328247, 236.5032935142517, 242.01386880874634, 247.93980431556702, 253.67352509498596, 259.4636161327362, 265.1548960208893, 271.21544885635376, 276.7984607219696, 282.49869322776794, 288.16287660598755, 299.3293209075928]
[51.92, 52.16, 59.64, 57.48, 62.68, 63.64, 64.28, 65.48, 70.72, 71.64, 67.72, 70.6, 67.64, 72.76, 70.72, 69.32, 71.8, 73.08, 69.72, 74.96, 74.04, 75.88, 74.8, 73.04, 73.92, 76.28, 77.36, 75.4, 76.92, 76.32, 76.0, 76.76, 76.12, 76.6, 78.84, 74.56, 79.16, 75.52, 76.0, 79.48, 75.44, 80.52, 79.4, 79.0, 75.8, 77.92, 81.52, 78.24, 77.52, 81.2, 78.56]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.524, Test loss: 1.651, Test accuracy: 30.52 

Round   1, Train loss: 1.355, Test loss: 1.521, Test accuracy: 36.80 

Round   2, Train loss: 1.220, Test loss: 1.248, Test accuracy: 49.24 

Round   3, Train loss: 1.101, Test loss: 1.082, Test accuracy: 55.88 

Round   4, Train loss: 1.000, Test loss: 1.102, Test accuracy: 57.16 

Round   5, Train loss: 0.927, Test loss: 0.901, Test accuracy: 64.24 

Round   6, Train loss: 0.882, Test loss: 0.889, Test accuracy: 64.40 

Round   7, Train loss: 0.822, Test loss: 0.937, Test accuracy: 65.08 

Round   8, Train loss: 0.774, Test loss: 0.953, Test accuracy: 65.80 

Round   9, Train loss: 0.719, Test loss: 0.788, Test accuracy: 69.60 

Round  10, Train loss: 0.684, Test loss: 0.903, Test accuracy: 67.08 

Round  11, Train loss: 0.643, Test loss: 0.737, Test accuracy: 71.88 

Round  12, Train loss: 0.592, Test loss: 0.794, Test accuracy: 70.56 

Round  13, Train loss: 0.560, Test loss: 0.734, Test accuracy: 72.80 

Round  14, Train loss: 0.526, Test loss: 0.667, Test accuracy: 75.24 

Round  15, Train loss: 0.499, Test loss: 0.689, Test accuracy: 75.60 

Round  16, Train loss: 0.476, Test loss: 0.721, Test accuracy: 74.72 

Round  17, Train loss: 0.453, Test loss: 0.697, Test accuracy: 75.32 

Round  18, Train loss: 0.427, Test loss: 0.664, Test accuracy: 76.24 

Round  19, Train loss: 0.397, Test loss: 0.675, Test accuracy: 76.64 

Round  20, Train loss: 0.371, Test loss: 0.665, Test accuracy: 77.56 

Round  21, Train loss: 0.354, Test loss: 0.604, Test accuracy: 79.04 

Round  22, Train loss: 0.340, Test loss: 0.679, Test accuracy: 76.48 

Round  23, Train loss: 0.309, Test loss: 0.615, Test accuracy: 79.28 

Round  24, Train loss: 0.291, Test loss: 0.609, Test accuracy: 79.48 

Round  25, Train loss: 0.281, Test loss: 0.660, Test accuracy: 78.48 

Round  26, Train loss: 0.267, Test loss: 0.680, Test accuracy: 77.40 

Round  27, Train loss: 0.261, Test loss: 0.625, Test accuracy: 79.12 

Round  28, Train loss: 0.237, Test loss: 0.639, Test accuracy: 79.60 

Round  29, Train loss: 0.230, Test loss: 0.601, Test accuracy: 80.44 

Round  30, Train loss: 0.204, Test loss: 0.602, Test accuracy: 80.96 

Round  31, Train loss: 0.197, Test loss: 0.594, Test accuracy: 81.04 

Round  32, Train loss: 0.173, Test loss: 0.584, Test accuracy: 81.16 

Round  33, Train loss: 0.175, Test loss: 0.590, Test accuracy: 81.32 

Round  34, Train loss: 0.170, Test loss: 0.615, Test accuracy: 81.36 

Round  35, Train loss: 0.153, Test loss: 0.637, Test accuracy: 81.48 

Round  36, Train loss: 0.152, Test loss: 0.612, Test accuracy: 81.76 

Round  37, Train loss: 0.137, Test loss: 0.620, Test accuracy: 81.52 

Round  38, Train loss: 0.127, Test loss: 0.662, Test accuracy: 80.48 

Round  39, Train loss: 0.123, Test loss: 0.582, Test accuracy: 82.52 

Round  40, Train loss: 0.118, Test loss: 0.666, Test accuracy: 81.32 

Round  41, Train loss: 0.109, Test loss: 0.616, Test accuracy: 82.40 

Round  42, Train loss: 0.095, Test loss: 0.646, Test accuracy: 82.24 

Round  43, Train loss: 0.099, Test loss: 0.650, Test accuracy: 81.40 

Round  44, Train loss: 0.097, Test loss: 0.634, Test accuracy: 82.68 

Round  45, Train loss: 0.075, Test loss: 0.625, Test accuracy: 83.80 

Round  46, Train loss: 0.093, Test loss: 0.603, Test accuracy: 82.52 

Round  47, Train loss: 0.075, Test loss: 0.624, Test accuracy: 83.04 

Round  48, Train loss: 0.069, Test loss: 0.633, Test accuracy: 82.88 

Round  49, Train loss: 0.075, Test loss: 0.679, Test accuracy: 82.16 

Final Round, Train loss: 0.039, Test loss: 0.668, Test accuracy: 82.48 

Average accuracy final 10 rounds: 82.44399999999999 

1182.1904134750366
[6.225069284439087, 10.928850650787354, 15.334718704223633, 19.677693367004395, 24.05313992500305, 28.73244071006775, 33.1976797580719, 37.61352229118347, 42.054606914520264, 46.57078313827515, 50.95861744880676, 55.35647511482239, 59.94663453102112, 64.3973503112793, 68.8243670463562, 73.0847008228302, 77.45753240585327, 81.80145859718323, 86.22291159629822, 90.62270474433899, 95.1285469532013, 100.11908984184265, 104.59915280342102, 109.241868019104, 113.56293177604675, 118.02847528457642, 122.311115026474, 127.02940273284912, 131.45908975601196, 135.8729944229126, 140.14430165290833, 144.83086037635803, 149.2883551120758, 153.96384406089783, 158.33838176727295, 162.83407306671143, 167.28074717521667, 171.7135968208313, 175.90037274360657, 180.26058268547058, 184.73975491523743, 189.19977235794067, 193.56892371177673, 198.2555797100067, 202.61397743225098, 206.94480276107788, 211.24256229400635, 215.69174456596375, 220.10964226722717, 224.57557344436646, 229.3665885925293]
[30.52, 36.8, 49.24, 55.88, 57.16, 64.24, 64.4, 65.08, 65.8, 69.6, 67.08, 71.88, 70.56, 72.8, 75.24, 75.6, 74.72, 75.32, 76.24, 76.64, 77.56, 79.04, 76.48, 79.28, 79.48, 78.48, 77.4, 79.12, 79.6, 80.44, 80.96, 81.04, 81.16, 81.32, 81.36, 81.48, 81.76, 81.52, 80.48, 82.52, 81.32, 82.4, 82.24, 81.4, 82.68, 83.8, 82.52, 83.04, 82.88, 82.16, 82.48]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
Round   0, Train loss: 1.539, Test loss: 1.926, Test accuracy: 28.24
Round   1, Train loss: 1.326, Test loss: 1.414, Test accuracy: 41.56
Round   2, Train loss: 1.177, Test loss: 1.148, Test accuracy: 53.00
Round   3, Train loss: 1.069, Test loss: 1.112, Test accuracy: 55.32
Round   4, Train loss: 0.994, Test loss: 1.079, Test accuracy: 57.36
Round   5, Train loss: 0.905, Test loss: 0.887, Test accuracy: 64.12
Round   6, Train loss: 0.844, Test loss: 0.883, Test accuracy: 64.56
Round   7, Train loss: 0.776, Test loss: 0.858, Test accuracy: 66.96
Round   8, Train loss: 0.739, Test loss: 0.798, Test accuracy: 69.04
Round   9, Train loss: 0.695, Test loss: 0.812, Test accuracy: 71.24
Round  10, Train loss: 0.640, Test loss: 0.785, Test accuracy: 70.72
Round  11, Train loss: 0.607, Test loss: 0.690, Test accuracy: 74.92
Round  12, Train loss: 0.571, Test loss: 0.656, Test accuracy: 75.16
Round  13, Train loss: 0.553, Test loss: 0.795, Test accuracy: 70.80
Round  14, Train loss: 0.516, Test loss: 0.636, Test accuracy: 76.64
Round  15, Train loss: 0.481, Test loss: 0.678, Test accuracy: 76.20
Round  16, Train loss: 0.442, Test loss: 0.615, Test accuracy: 77.64
Round  17, Train loss: 0.419, Test loss: 0.663, Test accuracy: 76.96
Round  18, Train loss: 0.405, Test loss: 0.637, Test accuracy: 76.08
Round  19, Train loss: 0.372, Test loss: 0.599, Test accuracy: 79.28
Round  20, Train loss: 0.354, Test loss: 0.591, Test accuracy: 79.12
Round  21, Train loss: 0.329, Test loss: 0.605, Test accuracy: 78.36
Round  22, Train loss: 0.313, Test loss: 0.594, Test accuracy: 78.76
Round  23, Train loss: 0.298, Test loss: 0.600, Test accuracy: 79.48
Round  24, Train loss: 0.275, Test loss: 0.612, Test accuracy: 79.28
Round  25, Train loss: 0.269, Test loss: 0.616, Test accuracy: 79.56
Round  26, Train loss: 0.248, Test loss: 0.607, Test accuracy: 79.12
Round  27, Train loss: 0.230, Test loss: 0.611, Test accuracy: 80.04
Round  28, Train loss: 0.227, Test loss: 0.644, Test accuracy: 79.44
Round  29, Train loss: 0.201, Test loss: 0.631, Test accuracy: 79.60
Round  30, Train loss: 0.194, Test loss: 0.617, Test accuracy: 79.64
Round  31, Train loss: 0.186, Test loss: 0.601, Test accuracy: 81.04
Round  32, Train loss: 0.169, Test loss: 0.600, Test accuracy: 80.40
Round  33, Train loss: 0.154, Test loss: 0.597, Test accuracy: 81.84
Round  34, Train loss: 0.144, Test loss: 0.613, Test accuracy: 80.84
Round  35, Train loss: 0.141, Test loss: 0.618, Test accuracy: 81.04
Round  36, Train loss: 0.124, Test loss: 0.588, Test accuracy: 82.08
Round  37, Train loss: 0.138, Test loss: 0.628, Test accuracy: 81.04
Round  38, Train loss: 0.137, Test loss: 0.620, Test accuracy: 80.76
Round  39, Train loss: 0.118, Test loss: 0.597, Test accuracy: 81.88
Round  40, Train loss: 0.105, Test loss: 0.612, Test accuracy: 81.88
Round  41, Train loss: 0.108, Test loss: 0.624, Test accuracy: 80.92
Round  42, Train loss: 0.089, Test loss: 0.617, Test accuracy: 81.60
Round  43, Train loss: 0.086, Test loss: 0.631, Test accuracy: 81.80
Round  44, Train loss: 0.084, Test loss: 0.647, Test accuracy: 81.40
Round  45, Train loss: 0.077, Test loss: 0.616, Test accuracy: 82.36
Round  46, Train loss: 0.074, Test loss: 0.665, Test accuracy: 81.52
Round  47, Train loss: 0.066, Test loss: 0.625, Test accuracy: 82.60
Round  48, Train loss: 0.079, Test loss: 0.644, Test accuracy: 81.84
Round  49, Train loss: 0.054, Test loss: 0.652, Test accuracy: 81.72
Final Round, Train loss: 0.032, Test loss: 0.642, Test accuracy: 82.52
Average accuracy final 10 rounds: 81.76400000000001
1331.1000945568085
[6.773088455200195, 11.865238666534424, 17.056241035461426, 22.56701922416687, 27.68976593017578, 32.752585649490356, 37.91529417037964, 42.83776593208313, 47.962844133377075, 52.98539185523987, 58.15607762336731, 63.02506899833679, 68.17082810401917, 73.11361265182495, 78.10149478912354, 83.54798817634583, 88.5110776424408, 93.49838709831238, 98.53954291343689, 103.52556109428406, 108.34657979011536, 113.30482578277588, 118.7190215587616, 123.70704245567322, 128.66224431991577, 133.52808046340942, 138.81118273735046, 143.8221080303192, 148.6670801639557, 153.65077805519104, 158.66709804534912, 163.81764006614685, 168.774001121521, 173.68473267555237, 178.6618049144745, 183.46829056739807, 188.5222897529602, 193.42369055747986, 198.48655438423157, 203.4628541469574, 208.41028904914856, 213.23519706726074, 218.23448991775513, 223.37728881835938, 228.3995225429535, 233.50944757461548, 238.5418186187744, 243.58927822113037, 248.51450896263123, 253.4651699066162, 258.73364305496216]
[28.24, 41.56, 53.0, 55.32, 57.36, 64.12, 64.56, 66.96, 69.04, 71.24, 70.72, 74.92, 75.16, 70.8, 76.64, 76.2, 77.64, 76.96, 76.08, 79.28, 79.12, 78.36, 78.76, 79.48, 79.28, 79.56, 79.12, 80.04, 79.44, 79.6, 79.64, 81.04, 80.4, 81.84, 80.84, 81.04, 82.08, 81.04, 80.76, 81.88, 81.88, 80.92, 81.6, 81.8, 81.4, 82.36, 81.52, 82.6, 81.84, 81.72, 82.52]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11183582 (local), 11178452 (global); Percentage 99.95 (11178452/11183582 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

        init --> train local model(freeze embeding):client   0,  Train loss: 0.816, Train accuracy: 67.000, Test loss: 1.098, Test accuracy: 58.20 

        train local model (freeze embeding):client   0,  Train loss: 0.706, Train accuracy: 72.000, Test loss: 1.071, Test accuracy: 60.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.627, Train accuracy: 77.000, Test loss: 1.059, Test accuracy: 60.80 

Round   0, Train loss: 0.627, Test loss: 1.059, Test accuracy: 60.80 

        train local model (freeze embeding):client   0,  Train loss: 0.510, Train accuracy: 78.200, Test loss: 1.110, Test accuracy: 63.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.473, Train accuracy: 82.600, Test loss: 1.050, Test accuracy: 66.80 

Round   1, Train loss: 0.473, Test loss: 1.050, Test accuracy: 66.80 

        train local model (freeze embeding):client   0,  Train loss: 0.341, Train accuracy: 85.600, Test loss: 0.978, Test accuracy: 67.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.507, Train accuracy: 78.600, Test loss: 1.250, Test accuracy: 63.80 

Round   2, Train loss: 0.507, Test loss: 1.250, Test accuracy: 63.80 

        train local model (freeze embeding):client   0,  Train loss: 0.269, Train accuracy: 90.600, Test loss: 0.997, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.436, Train accuracy: 84.400, Test loss: 1.488, Test accuracy: 64.20 

Round   3, Train loss: 0.436, Test loss: 1.488, Test accuracy: 64.20 

        train local model (freeze embeding):client   0,  Train loss: 0.213, Train accuracy: 92.600, Test loss: 1.102, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.303, Train accuracy: 88.000, Test loss: 1.283, Test accuracy: 66.80 

Round   4, Train loss: 0.303, Test loss: 1.283, Test accuracy: 66.80 

        train local model (freeze embeding):client   0,  Train loss: 0.164, Train accuracy: 94.000, Test loss: 1.004, Test accuracy: 76.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.154, Train accuracy: 94.400, Test loss: 1.198, Test accuracy: 71.20 

Round   5, Train loss: 0.154, Test loss: 1.198, Test accuracy: 71.20 

        train local model (freeze embeding):client   0,  Train loss: 0.057, Train accuracy: 98.400, Test loss: 1.111, Test accuracy: 73.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.052, Train accuracy: 99.000, Test loss: 1.073, Test accuracy: 75.40 

Round   6, Train loss: 0.052, Test loss: 1.073, Test accuracy: 75.40 

        train local model (freeze embeding):client   0,  Train loss: 0.037, Train accuracy: 98.800, Test loss: 1.116, Test accuracy: 76.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.081, Train accuracy: 96.400, Test loss: 1.196, Test accuracy: 70.40 

Round   7, Train loss: 0.081, Test loss: 1.196, Test accuracy: 70.40 

        train local model (freeze embeding):client   0,  Train loss: 0.031, Train accuracy: 99.000, Test loss: 1.140, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.051, Train accuracy: 98.400, Test loss: 1.207, Test accuracy: 72.80 

Round   8, Train loss: 0.051, Test loss: 1.207, Test accuracy: 72.80 

        train local model (freeze embeding):client   0,  Train loss: 0.029, Train accuracy: 99.200, Test loss: 1.126, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.022, Train accuracy: 99.400, Test loss: 1.243, Test accuracy: 75.40 

Round   9, Train loss: 0.022, Test loss: 1.243, Test accuracy: 75.40 

        train local model (freeze embeding):client   0,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 1.060, Test accuracy: 78.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.034, Train accuracy: 99.000, Test loss: 1.551, Test accuracy: 73.20 

Round  10, Train loss: 0.034, Test loss: 1.551, Test accuracy: 73.20 

        train local model (freeze embeding):client   0,  Train loss: 0.012, Train accuracy: 99.600, Test loss: 1.374, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.017, Train accuracy: 99.800, Test loss: 1.229, Test accuracy: 74.80 

Round  11, Train loss: 0.017, Test loss: 1.229, Test accuracy: 74.80 

        train local model (freeze embeding):client   0,  Train loss: 0.030, Train accuracy: 99.200, Test loss: 1.058, Test accuracy: 78.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.035, Train accuracy: 98.400, Test loss: 1.266, Test accuracy: 77.40 

Round  12, Train loss: 0.035, Test loss: 1.266, Test accuracy: 77.40 

        train local model (freeze embeding):client   0,  Train loss: 0.012, Train accuracy: 99.800, Test loss: 1.146, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.148, Test accuracy: 76.60 

Round  13, Train loss: 0.001, Test loss: 1.148, Test accuracy: 76.60 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.134, Test accuracy: 77.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 1.407, Test accuracy: 75.80 

Round  14, Train loss: 0.008, Test loss: 1.407, Test accuracy: 75.80 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.310, Test accuracy: 75.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.182, Test accuracy: 78.00 

Round  15, Train loss: 0.003, Test loss: 1.182, Test accuracy: 78.00 

        train local model (freeze embeding):client   0,  Train loss: 0.017, Train accuracy: 99.400, Test loss: 1.303, Test accuracy: 76.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.024, Train accuracy: 99.200, Test loss: 1.255, Test accuracy: 76.20 

Round  16, Train loss: 0.024, Test loss: 1.255, Test accuracy: 76.20 

        train local model (freeze embeding):client   0,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.232, Test accuracy: 76.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.011, Train accuracy: 99.800, Test loss: 1.111, Test accuracy: 79.40 

Round  17, Train loss: 0.011, Test loss: 1.111, Test accuracy: 79.40 

        train local model (freeze embeding):client   0,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 1.096, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.179, Test accuracy: 79.20 

Round  18, Train loss: 0.002, Test loss: 1.179, Test accuracy: 79.20 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.182, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.063, Test accuracy: 80.80 

Round  19, Train loss: 0.001, Test loss: 1.063, Test accuracy: 80.80 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.058, Test accuracy: 81.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.300, Test accuracy: 77.80 

Final Round, Train loss: 0.004, Test loss: 1.081, Test accuracy: 80.00 

---------------------------------------------train_client: [0, 1] 

        init --> train local model(freeze embeding):client   1,  Train loss: 0.725, Train accuracy: 72.200, Test loss: 1.121, Test accuracy: 62.80 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.060, Test accuracy: 80.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.310, Test accuracy: 78.00 

        train local model (freeze embeding):client   1,  Train loss: 1.121, Train accuracy: 62.600, Test loss: 1.599, Test accuracy: 57.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.306, Train accuracy: 88.200, Test loss: 1.255, Test accuracy: 66.40 

Round   0, Train loss: 0.155, Test loss: 1.138, Test accuracy: 70.60 

        train local model (freeze embeding):client   0,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.019, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.031, Test accuracy: 80.40 

        train local model (freeze embeding):client   1,  Train loss: 0.244, Train accuracy: 91.000, Test loss: 1.087, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.105, Train accuracy: 96.800, Test loss: 1.091, Test accuracy: 70.40 

Round   1, Train loss: 0.053, Test loss: 1.007, Test accuracy: 76.20 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.923, Test accuracy: 81.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.033, Test accuracy: 80.40 

        train local model (freeze embeding):client   1,  Train loss: 0.101, Train accuracy: 97.000, Test loss: 1.138, Test accuracy: 71.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.138, Train accuracy: 95.200, Test loss: 1.591, Test accuracy: 64.40 

Round   2, Train loss: 0.069, Test loss: 1.142, Test accuracy: 73.70 

        train local model (freeze embeding):client   0,  Train loss: 0.018, Train accuracy: 99.200, Test loss: 0.944, Test accuracy: 81.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.014, Test accuracy: 80.60 

        train local model (freeze embeding):client   1,  Train loss: 0.046, Train accuracy: 99.200, Test loss: 1.276, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.063, Train accuracy: 97.800, Test loss: 1.297, Test accuracy: 71.20 

Round   3, Train loss: 0.033, Test loss: 1.051, Test accuracy: 74.70 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.888, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.984, Test accuracy: 82.00 

        train local model (freeze embeding):client   1,  Train loss: 0.043, Train accuracy: 98.800, Test loss: 1.231, Test accuracy: 70.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.102, Train accuracy: 97.000, Test loss: 1.483, Test accuracy: 70.80 

Round   4, Train loss: 0.051, Test loss: 1.081, Test accuracy: 75.60 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.919, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.068, Test accuracy: 80.00 

        train local model (freeze embeding):client   1,  Train loss: 0.018, Train accuracy: 100.000, Test loss: 1.268, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.202, Train accuracy: 92.000, Test loss: 1.815, Test accuracy: 61.00 

Round   5, Train loss: 0.102, Test loss: 1.241, Test accuracy: 71.80 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.922, Test accuracy: 80.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.024, Train accuracy: 99.400, Test loss: 1.080, Test accuracy: 79.80 

        train local model (freeze embeding):client   1,  Train loss: 0.019, Train accuracy: 99.800, Test loss: 1.372, Test accuracy: 70.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.100, Train accuracy: 96.800, Test loss: 1.728, Test accuracy: 66.40 

Round   6, Train loss: 0.062, Test loss: 1.240, Test accuracy: 74.60 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.038, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.131, Test accuracy: 80.00 

        train local model (freeze embeding):client   1,  Train loss: 0.012, Train accuracy: 100.000, Test loss: 1.388, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.070, Train accuracy: 97.200, Test loss: 1.763, Test accuracy: 67.80 

Round   7, Train loss: 0.036, Test loss: 1.198, Test accuracy: 74.90 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 99.800, Test loss: 0.975, Test accuracy: 79.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.007, Test accuracy: 80.80 

        train local model (freeze embeding):client   1,  Train loss: 0.009, Train accuracy: 100.000, Test loss: 1.340, Test accuracy: 70.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.013, Train accuracy: 100.000, Test loss: 1.443, Test accuracy: 71.40 

Round   8, Train loss: 0.007, Test loss: 1.119, Test accuracy: 77.20 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.872, Test accuracy: 80.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.031, Test accuracy: 80.60 

        train local model (freeze embeding):client   1,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.406, Test accuracy: 72.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.025, Train accuracy: 99.200, Test loss: 1.628, Test accuracy: 70.40 

Round   9, Train loss: 0.014, Test loss: 1.144, Test accuracy: 76.60 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.951, Test accuracy: 81.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.895, Test accuracy: 82.40 

        train local model (freeze embeding):client   1,  Train loss: 0.011, Train accuracy: 99.800, Test loss: 1.396, Test accuracy: 72.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.031, Train accuracy: 98.800, Test loss: 1.670, Test accuracy: 69.20 

Round  10, Train loss: 0.017, Test loss: 1.129, Test accuracy: 77.60 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.874, Test accuracy: 82.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.137, Test accuracy: 79.40 

        train local model (freeze embeding):client   1,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 1.401, Test accuracy: 73.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.035, Train accuracy: 98.800, Test loss: 1.829, Test accuracy: 68.40 

Round  11, Train loss: 0.018, Test loss: 1.265, Test accuracy: 75.30 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.946, Test accuracy: 81.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.942, Test accuracy: 80.80 

        train local model (freeze embeding):client   1,  Train loss: 0.011, Train accuracy: 99.800, Test loss: 1.556, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.087, Train accuracy: 96.600, Test loss: 1.761, Test accuracy: 67.80 

Round  12, Train loss: 0.044, Test loss: 1.172, Test accuracy: 76.80 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.850, Test accuracy: 81.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.978, Test accuracy: 81.20 

        train local model (freeze embeding):client   1,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.463, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.017, Train accuracy: 99.800, Test loss: 1.597, Test accuracy: 68.20 

Round  13, Train loss: 0.009, Test loss: 1.170, Test accuracy: 76.10 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.938, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.980, Test accuracy: 82.00 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.569, Test accuracy: 70.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.462, Test accuracy: 73.40 

Round  14, Train loss: 0.000, Test loss: 1.219, Test accuracy: 76.90 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.948, Test accuracy: 81.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.972, Test accuracy: 82.20 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.502, Test accuracy: 72.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.032, Train accuracy: 99.000, Test loss: 1.773, Test accuracy: 67.00 

Round  15, Train loss: 0.017, Test loss: 1.269, Test accuracy: 76.50 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.952, Test accuracy: 81.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.893, Test accuracy: 82.80 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.488, Test accuracy: 69.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.599, Test accuracy: 71.80 

Round  16, Train loss: 0.002, Test loss: 1.201, Test accuracy: 76.20 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.900, Test accuracy: 81.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.989, Test accuracy: 81.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.532, Test accuracy: 69.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.310, Test accuracy: 73.40 

Round  17, Train loss: 0.001, Test loss: 1.138, Test accuracy: 77.30 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.940, Test accuracy: 82.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.957, Test accuracy: 82.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.406, Test accuracy: 71.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.594, Test accuracy: 72.20 

Round  18, Train loss: 0.001, Test loss: 1.176, Test accuracy: 77.50 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.947, Test accuracy: 82.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.937, Test accuracy: 82.40 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.483, Test accuracy: 71.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.050, Train accuracy: 98.000, Test loss: 1.799, Test accuracy: 66.80 

Round  19, Train loss: 0.025, Test loss: 1.251, Test accuracy: 76.70 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.963, Test accuracy: 82.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.974, Test accuracy: 82.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.537, Test accuracy: 71.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.027, Train accuracy: 98.800, Test loss: 1.905, Test accuracy: 65.40 

Final Round, Train loss: 0.014, Test loss: 1.277, Test accuracy: 76.00 

---------------------------------------------train_client: [0, 1, 2] 

        init --> train local model(freeze embeding):client   2,  Train loss: 0.659, Train accuracy: 72.000, Test loss: 0.707, Test accuracy: 75.40 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.980, Test accuracy: 82.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.995, Test accuracy: 81.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.492, Test accuracy: 72.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.013, Train accuracy: 99.600, Test loss: 1.611, Test accuracy: 70.20 

        train local model (freeze embeding):client   2,  Train loss: 0.581, Train accuracy: 75.200, Test loss: 0.706, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.163, Train accuracy: 93.000, Test loss: 0.928, Test accuracy: 74.80 

Round   0, Train loss: 0.059, Test loss: 1.017, Test accuracy: 76.60 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.888, Test accuracy: 81.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.031, Test accuracy: 79.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.336, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 1.399, Test accuracy: 73.40 

        train local model (freeze embeding):client   2,  Train loss: 0.296, Train accuracy: 88.400, Test loss: 0.625, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.056, Train accuracy: 98.600, Test loss: 0.761, Test accuracy: 77.40 

Round   1, Train loss: 0.021, Test loss: 1.031, Test accuracy: 77.07 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.953, Test accuracy: 80.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.991, Test accuracy: 81.40 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.296, Test accuracy: 73.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.389, Test accuracy: 74.20 

        train local model (freeze embeding):client   2,  Train loss: 0.109, Train accuracy: 96.600, Test loss: 0.620, Test accuracy: 82.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.108, Train accuracy: 96.400, Test loss: 0.940, Test accuracy: 73.00 

Round   2, Train loss: 0.036, Test loss: 0.991, Test accuracy: 78.67 

        train local model (freeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.985, Test accuracy: 81.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.942, Test accuracy: 83.00 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.172, Test accuracy: 75.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.361, Test accuracy: 75.20 

        train local model (freeze embeding):client   2,  Train loss: 0.051, Train accuracy: 98.800, Test loss: 0.640, Test accuracy: 83.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.037, Train accuracy: 99.400, Test loss: 0.992, Test accuracy: 77.40 

Round   3, Train loss: 0.013, Test loss: 0.996, Test accuracy: 79.87 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.951, Test accuracy: 81.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.023, Train accuracy: 98.800, Test loss: 1.148, Test accuracy: 77.60 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.146, Test accuracy: 78.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.014, Train accuracy: 99.600, Test loss: 1.347, Test accuracy: 74.40 

        train local model (freeze embeding):client   2,  Train loss: 0.036, Train accuracy: 99.000, Test loss: 0.731, Test accuracy: 82.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.053, Train accuracy: 98.800, Test loss: 0.890, Test accuracy: 77.80 

Round   4, Train loss: 0.030, Test loss: 0.942, Test accuracy: 80.13 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.881, Test accuracy: 83.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.000, Test accuracy: 82.60 

        train local model (freeze embeding):client   1,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.276, Test accuracy: 76.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.251, Test accuracy: 75.40 

        train local model (freeze embeding):client   2,  Train loss: 0.036, Train accuracy: 99.000, Test loss: 0.772, Test accuracy: 82.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.026, Train accuracy: 99.000, Test loss: 0.999, Test accuracy: 79.40 

Round   5, Train loss: 0.010, Test loss: 0.950, Test accuracy: 80.47 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.847, Test accuracy: 84.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.009, Train accuracy: 99.800, Test loss: 0.937, Test accuracy: 79.40 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.215, Test accuracy: 76.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.264, Test accuracy: 73.80 

        train local model (freeze embeding):client   2,  Train loss: 0.011, Train accuracy: 100.000, Test loss: 0.742, Test accuracy: 82.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.029, Train accuracy: 99.200, Test loss: 1.068, Test accuracy: 76.60 

Round   6, Train loss: 0.013, Test loss: 0.868, Test accuracy: 80.20 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.823, Test accuracy: 82.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.006, Test accuracy: 81.00 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.187, Test accuracy: 75.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.423, Test accuracy: 72.80 

        train local model (freeze embeding):client   2,  Train loss: 0.011, Train accuracy: 100.000, Test loss: 0.742, Test accuracy: 82.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.035, Train accuracy: 98.800, Test loss: 1.171, Test accuracy: 74.00 

Round   7, Train loss: 0.013, Test loss: 0.977, Test accuracy: 79.20 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.890, Test accuracy: 83.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.117, Test accuracy: 81.00 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.225, Test accuracy: 76.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 1.553, Test accuracy: 71.20 

        train local model (freeze embeding):client   2,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 0.723, Test accuracy: 81.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.049, Train accuracy: 98.000, Test loss: 1.210, Test accuracy: 76.40 

Round   8, Train loss: 0.020, Test loss: 0.940, Test accuracy: 80.47 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.946, Test accuracy: 83.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.886, Test accuracy: 83.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.168, Test accuracy: 76.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.221, Test accuracy: 75.80 

        train local model (freeze embeding):client   2,  Train loss: 0.010, Train accuracy: 100.000, Test loss: 0.837, Test accuracy: 81.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.014, Train accuracy: 99.600, Test loss: 1.102, Test accuracy: 79.00 

Round   9, Train loss: 0.005, Test loss: 0.945, Test accuracy: 80.47 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.872, Test accuracy: 82.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.978, Test accuracy: 82.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.196, Test accuracy: 77.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.341, Test accuracy: 74.00 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.820, Test accuracy: 82.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.085, Train accuracy: 97.200, Test loss: 1.155, Test accuracy: 76.20 

Round  10, Train loss: 0.029, Test loss: 0.894, Test accuracy: 80.53 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.852, Test accuracy: 82.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.904, Test accuracy: 82.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.116, Test accuracy: 77.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.226, Test accuracy: 75.80 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.790, Test accuracy: 81.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.849, Test accuracy: 82.20 

Round  11, Train loss: 0.001, Test loss: 0.907, Test accuracy: 81.00 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.837, Test accuracy: 83.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.889, Test accuracy: 83.60 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.133, Test accuracy: 78.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.326, Test accuracy: 75.60 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.823, Test accuracy: 81.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 0.991, Test accuracy: 81.40 

Round  12, Train loss: 0.004, Test loss: 0.948, Test accuracy: 80.33 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.861, Test accuracy: 82.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.916, Test accuracy: 83.00 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.162, Test accuracy: 76.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.235, Test accuracy: 76.80 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 0.812, Test accuracy: 82.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.008, Train accuracy: 99.800, Test loss: 0.916, Test accuracy: 79.80 

Round  13, Train loss: 0.003, Test loss: 0.936, Test accuracy: 81.20 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.880, Test accuracy: 82.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.993, Test accuracy: 81.60 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.162, Test accuracy: 76.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.199, Test accuracy: 76.80 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.811, Test accuracy: 83.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.025, Train accuracy: 99.400, Test loss: 0.917, Test accuracy: 77.60 

Round  14, Train loss: 0.009, Test loss: 0.870, Test accuracy: 81.20 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.815, Test accuracy: 83.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.859, Test accuracy: 82.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.167, Test accuracy: 76.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.213, Test accuracy: 77.00 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.725, Test accuracy: 84.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.957, Test accuracy: 81.40 

Round  15, Train loss: 0.002, Test loss: 0.901, Test accuracy: 81.73 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.850, Test accuracy: 83.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.947, Test accuracy: 82.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.200, Test accuracy: 76.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.007, Train accuracy: 99.800, Test loss: 1.273, Test accuracy: 75.40 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.758, Test accuracy: 82.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.924, Test accuracy: 78.40 

Round  16, Train loss: 0.004, Test loss: 0.898, Test accuracy: 81.53 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.877, Test accuracy: 82.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.910, Test accuracy: 82.20 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.204, Test accuracy: 77.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.265, Test accuracy: 76.00 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.711, Test accuracy: 82.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.055, Train accuracy: 97.800, Test loss: 1.164, Test accuracy: 74.60 

Round  17, Train loss: 0.019, Test loss: 0.923, Test accuracy: 80.47 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.895, Test accuracy: 84.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.954, Test accuracy: 81.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.173, Test accuracy: 77.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.260, Test accuracy: 73.60 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.827, Test accuracy: 81.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.012, Train accuracy: 99.400, Test loss: 0.872, Test accuracy: 80.20 

Round  18, Train loss: 0.006, Test loss: 0.864, Test accuracy: 81.67 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.840, Test accuracy: 82.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.901, Test accuracy: 83.80 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.117, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.149, Test accuracy: 77.80 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 0.719, Test accuracy: 84.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.865, Test accuracy: 81.40 

Round  19, Train loss: 0.000, Test loss: 0.888, Test accuracy: 82.47 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.851, Test accuracy: 83.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.884, Test accuracy: 83.60 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.065, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.168, Test accuracy: 78.00 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.781, Test accuracy: 85.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.821, Test accuracy: 81.40 

Final Round, Train loss: 0.000, Test loss: 0.877, Test accuracy: 82.33 

---------------------------------------------train_client: [0, 1, 2, 3] 

        init --> train local model(freeze embeding):client   3,  Train loss: 0.543, Train accuracy: 75.400, Test loss: 0.796, Test accuracy: 71.40 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.846, Test accuracy: 83.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.896, Test accuracy: 82.00 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.073, Test accuracy: 78.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.149, Test accuracy: 77.20 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.760, Test accuracy: 84.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.888, Test accuracy: 81.80 

        train local model (freeze embeding):client   3,  Train loss: 0.514, Train accuracy: 78.800, Test loss: 0.809, Test accuracy: 69.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.091, Train accuracy: 98.200, Test loss: 0.953, Test accuracy: 69.80 

Round   0, Train loss: 0.023, Test loss: 0.907, Test accuracy: 77.95 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.811, Test accuracy: 83.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.910, Test accuracy: 82.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.040, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.113, Test accuracy: 77.60 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.746, Test accuracy: 83.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.807, Test accuracy: 82.60 

        train local model (freeze embeding):client   3,  Train loss: 0.272, Train accuracy: 89.400, Test loss: 0.802, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.132, Train accuracy: 96.400, Test loss: 1.136, Test accuracy: 71.60 

Round   1, Train loss: 0.033, Test loss: 1.153, Test accuracy: 74.90 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.751, Test accuracy: 84.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.881, Test accuracy: 81.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.000, Test accuracy: 78.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.152, Test accuracy: 77.20 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.730, Test accuracy: 83.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 0.944, Test accuracy: 80.20 

        train local model (freeze embeding):client   3,  Train loss: 0.167, Train accuracy: 95.200, Test loss: 0.947, Test accuracy: 72.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.054, Train accuracy: 98.400, Test loss: 1.043, Test accuracy: 71.40 

Round   2, Train loss: 0.016, Test loss: 0.874, Test accuracy: 78.85 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.780, Test accuracy: 83.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.842, Test accuracy: 82.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.022, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.251, Test accuracy: 77.60 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.761, Test accuracy: 83.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.817, Test accuracy: 82.20 

        train local model (freeze embeding):client   3,  Train loss: 0.098, Train accuracy: 96.600, Test loss: 0.965, Test accuracy: 72.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.040, Train accuracy: 99.000, Test loss: 1.170, Test accuracy: 71.80 

Round   3, Train loss: 0.011, Test loss: 0.858, Test accuracy: 78.90 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.717, Test accuracy: 85.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.833, Test accuracy: 83.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.952, Test accuracy: 80.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.123, Test accuracy: 77.40 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.709, Test accuracy: 82.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.852, Test accuracy: 81.00 

        train local model (freeze embeding):client   3,  Train loss: 0.061, Train accuracy: 99.200, Test loss: 0.979, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.084, Train accuracy: 97.200, Test loss: 1.324, Test accuracy: 70.20 

Round   4, Train loss: 0.022, Test loss: 0.841, Test accuracy: 80.20 

        train local model (freeze embeding):client   0,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 0.710, Test accuracy: 84.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.933, Test accuracy: 81.20 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.019, Test accuracy: 77.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.120, Test accuracy: 77.80 

        train local model (freeze embeding):client   2,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.693, Test accuracy: 84.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.835, Test accuracy: 81.20 

        train local model (freeze embeding):client   3,  Train loss: 0.033, Train accuracy: 99.400, Test loss: 0.998, Test accuracy: 73.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.037, Train accuracy: 99.000, Test loss: 1.187, Test accuracy: 71.60 

Round   5, Train loss: 0.011, Test loss: 0.842, Test accuracy: 79.85 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.698, Test accuracy: 85.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.811, Test accuracy: 83.20 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.960, Test accuracy: 79.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.016, Train accuracy: 99.800, Test loss: 1.336, Test accuracy: 73.40 

        train local model (freeze embeding):client   2,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.702, Test accuracy: 83.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.023, Train accuracy: 99.000, Test loss: 0.871, Test accuracy: 79.20 

        train local model (freeze embeding):client   3,  Train loss: 0.017, Train accuracy: 100.000, Test loss: 0.923, Test accuracy: 73.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.164, Train accuracy: 95.000, Test loss: 1.762, Test accuracy: 66.40 

Round   6, Train loss: 0.051, Test loss: 0.788, Test accuracy: 81.50 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.684, Test accuracy: 84.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.978, Test accuracy: 82.40 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.918, Test accuracy: 79.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.061, Test accuracy: 80.20 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.639, Test accuracy: 85.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.863, Test accuracy: 82.60 

        train local model (freeze embeding):client   3,  Train loss: 0.018, Train accuracy: 100.000, Test loss: 1.010, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.143, Train accuracy: 96.400, Test loss: 1.465, Test accuracy: 67.00 

Round   7, Train loss: 0.037, Test loss: 0.835, Test accuracy: 80.60 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.692, Test accuracy: 85.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.014, Train accuracy: 99.800, Test loss: 0.800, Test accuracy: 82.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.965, Test accuracy: 78.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.116, Test accuracy: 77.60 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.705, Test accuracy: 85.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.910, Test accuracy: 80.80 

        train local model (freeze embeding):client   3,  Train loss: 0.014, Train accuracy: 99.600, Test loss: 1.043, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.050, Train accuracy: 98.400, Test loss: 1.571, Test accuracy: 70.00 

Round   8, Train loss: 0.017, Test loss: 0.848, Test accuracy: 80.70 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.682, Test accuracy: 84.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.725, Test accuracy: 84.40 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.946, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.201, Test accuracy: 76.00 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.722, Test accuracy: 83.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.814, Test accuracy: 80.00 

        train local model (freeze embeding):client   3,  Train loss: 0.009, Train accuracy: 100.000, Test loss: 1.145, Test accuracy: 74.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.136, Train accuracy: 95.800, Test loss: 1.496, Test accuracy: 69.20 

Round   9, Train loss: 0.035, Test loss: 0.862, Test accuracy: 80.05 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.711, Test accuracy: 83.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.851, Test accuracy: 82.00 

        train local model (freeze embeding):client   1,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.031, Test accuracy: 78.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.045, Test accuracy: 79.00 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.693, Test accuracy: 84.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.016, Train accuracy: 99.600, Test loss: 0.908, Test accuracy: 79.00 

        train local model (freeze embeding):client   3,  Train loss: 0.007, Train accuracy: 100.000, Test loss: 1.061, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.126, Train accuracy: 97.000, Test loss: 1.597, Test accuracy: 67.80 

Round  10, Train loss: 0.036, Test loss: 0.878, Test accuracy: 80.00 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.715, Test accuracy: 83.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.786, Test accuracy: 83.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.982, Test accuracy: 78.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.110, Test accuracy: 77.00 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.742, Test accuracy: 83.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.896, Test accuracy: 80.80 

        train local model (freeze embeding):client   3,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.098, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.013, Train accuracy: 99.600, Test loss: 1.278, Test accuracy: 73.40 

Round  11, Train loss: 0.004, Test loss: 0.878, Test accuracy: 80.70 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.737, Test accuracy: 83.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.009, Train accuracy: 99.800, Test loss: 1.010, Test accuracy: 80.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.004, Test accuracy: 78.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 1.277, Test accuracy: 75.40 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.755, Test accuracy: 82.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.909, Test accuracy: 81.60 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.065, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.026, Train accuracy: 99.200, Test loss: 1.614, Test accuracy: 71.00 

Round  12, Train loss: 0.011, Test loss: 0.899, Test accuracy: 80.30 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.734, Test accuracy: 84.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.875, Test accuracy: 84.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.090, Test accuracy: 78.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.132, Test accuracy: 78.60 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.755, Test accuracy: 83.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.809, Test accuracy: 82.40 

        train local model (freeze embeding):client   3,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.107, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.027, Train accuracy: 99.000, Test loss: 1.673, Test accuracy: 72.00 

Round  13, Train loss: 0.007, Test loss: 0.903, Test accuracy: 81.40 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.730, Test accuracy: 83.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.807, Test accuracy: 85.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.985, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.125, Test accuracy: 77.00 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.730, Test accuracy: 84.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.016, Train accuracy: 99.800, Test loss: 0.953, Test accuracy: 79.20 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.159, Test accuracy: 76.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.423, Train accuracy: 88.800, Test loss: 2.395, Test accuracy: 59.80 

Round  14, Train loss: 0.110, Test loss: 0.892, Test accuracy: 80.15 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.721, Test accuracy: 85.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.780, Test accuracy: 84.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.966, Test accuracy: 78.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.289, Test accuracy: 75.60 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.701, Test accuracy: 84.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.088, Train accuracy: 96.000, Test loss: 1.316, Test accuracy: 75.80 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.115, Test accuracy: 77.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.442, Test accuracy: 72.20 

Round  15, Train loss: 0.024, Test loss: 0.909, Test accuracy: 79.95 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.704, Test accuracy: 84.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.816, Test accuracy: 83.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.012, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.073, Test accuracy: 79.20 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.799, Test accuracy: 82.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.015, Train accuracy: 99.800, Test loss: 1.135, Test accuracy: 79.40 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.169, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.044, Train accuracy: 98.600, Test loss: 1.627, Test accuracy: 68.20 

Round  16, Train loss: 0.015, Test loss: 0.916, Test accuracy: 80.50 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.688, Test accuracy: 84.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.751, Test accuracy: 85.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.026, Test accuracy: 78.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 1.404, Test accuracy: 76.80 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.780, Test accuracy: 83.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.890, Test accuracy: 83.80 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.183, Test accuracy: 76.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.025, Train accuracy: 98.800, Test loss: 1.354, Test accuracy: 73.40 

Round  17, Train loss: 0.009, Test loss: 0.916, Test accuracy: 80.80 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.682, Test accuracy: 84.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.928, Test accuracy: 80.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.026, Test accuracy: 78.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.160, Test accuracy: 76.60 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.774, Test accuracy: 84.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.793, Test accuracy: 84.80 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.147, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.314, Test accuracy: 74.40 

Round  18, Train loss: 0.001, Test loss: 0.898, Test accuracy: 80.70 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.716, Test accuracy: 85.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.836, Test accuracy: 82.20 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.007, Test accuracy: 79.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.111, Test accuracy: 79.40 

        train local model (freeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.793, Test accuracy: 84.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.931, Test accuracy: 81.60 

        train local model (freeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.198, Test accuracy: 75.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.352, Test accuracy: 74.00 

Round  19, Train loss: 0.001, Test loss: 0.906, Test accuracy: 81.20 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.711, Test accuracy: 85.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.784, Test accuracy: 83.80 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.007, Test accuracy: 79.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.019, Train accuracy: 99.200, Test loss: 1.478, Test accuracy: 75.20 

        train local model (freeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.777, Test accuracy: 83.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.868, Test accuracy: 82.00 

        train local model (freeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.197, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.084, Train accuracy: 96.800, Test loss: 1.334, Test accuracy: 72.20 

Final Round, Train loss: 0.026, Test loss: 0.909, Test accuracy: 81.45 

---------------------------------------------train_client: [0, 1, 2, 3, 4] 

        init --> train local model(freeze embeding):client   4,  Train loss: 0.417, Train accuracy: 87.200, Test loss: 0.687, Test accuracy: 75.40 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.710, Test accuracy: 84.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.801, Test accuracy: 84.40 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.986, Test accuracy: 80.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.033, Train accuracy: 98.400, Test loss: 1.509, Test accuracy: 74.00 

        train local model (freeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.757, Test accuracy: 83.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 1.011, Test accuracy: 79.80 

        train local model (freeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.214, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.285, Test accuracy: 74.20 

        train local model (freeze embeding):client   4,  Train loss: 0.429, Train accuracy: 84.000, Test loss: 0.733, Test accuracy: 73.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.046, Train accuracy: 99.200, Test loss: 0.991, Test accuracy: 72.20 

Round   0, Train loss: 0.017, Test loss: 0.907, Test accuracy: 78.64 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.670, Test accuracy: 85.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.820, Test accuracy: 83.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.977, Test accuracy: 81.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.989, Test accuracy: 79.00 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.737, Test accuracy: 84.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.861, Test accuracy: 82.20 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.119, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.053, Train accuracy: 97.600, Test loss: 1.338, Test accuracy: 72.80 

        train local model (freeze embeding):client   4,  Train loss: 0.289, Train accuracy: 90.800, Test loss: 0.845, Test accuracy: 74.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.085, Train accuracy: 97.000, Test loss: 0.919, Test accuracy: 75.20 

Round   1, Train loss: 0.028, Test loss: 0.862, Test accuracy: 79.20 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.670, Test accuracy: 85.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.924, Test accuracy: 80.60 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.024, Test accuracy: 79.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.029, Train accuracy: 99.200, Test loss: 1.311, Test accuracy: 75.00 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.725, Test accuracy: 83.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.016, Train accuracy: 99.600, Test loss: 0.932, Test accuracy: 80.40 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.125, Test accuracy: 76.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.151, Train accuracy: 94.800, Test loss: 1.437, Test accuracy: 70.60 

        train local model (freeze embeding):client   4,  Train loss: 0.111, Train accuracy: 97.600, Test loss: 0.723, Test accuracy: 78.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.111, Train accuracy: 96.600, Test loss: 1.231, Test accuracy: 71.00 

Round   2, Train loss: 0.062, Test loss: 0.825, Test accuracy: 79.92 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.678, Test accuracy: 85.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.790, Test accuracy: 83.00 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.915, Test accuracy: 80.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.058, Test accuracy: 77.60 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.673, Test accuracy: 85.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.005, Train accuracy: 99.800, Test loss: 0.865, Test accuracy: 81.40 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.041, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.318, Test accuracy: 72.20 

        train local model (freeze embeding):client   4,  Train loss: 0.093, Train accuracy: 97.600, Test loss: 0.839, Test accuracy: 76.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.050, Train accuracy: 98.200, Test loss: 1.296, Test accuracy: 71.80 

Round   3, Train loss: 0.011, Test loss: 0.880, Test accuracy: 79.08 

        train local model (freeze embeding):client   0,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.637, Test accuracy: 85.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.764, Test accuracy: 85.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.908, Test accuracy: 77.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.037, Train accuracy: 98.600, Test loss: 1.257, Test accuracy: 75.20 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.708, Test accuracy: 84.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.845, Test accuracy: 82.00 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.073, Test accuracy: 75.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.017, Train accuracy: 99.600, Test loss: 1.404, Test accuracy: 73.20 

        train local model (freeze embeding):client   4,  Train loss: 0.037, Train accuracy: 99.400, Test loss: 0.750, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.044, Train accuracy: 97.800, Test loss: 1.171, Test accuracy: 71.80 

Round   4, Train loss: 0.020, Test loss: 0.836, Test accuracy: 80.60 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.702, Test accuracy: 85.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.854, Test accuracy: 83.40 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.930, Test accuracy: 78.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.059, Test accuracy: 77.80 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.735, Test accuracy: 84.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.829, Test accuracy: 82.40 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.118, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.113, Train accuracy: 96.800, Test loss: 1.435, Test accuracy: 69.00 

        train local model (freeze embeding):client   4,  Train loss: 0.020, Train accuracy: 100.000, Test loss: 0.780, Test accuracy: 80.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.040, Train accuracy: 98.400, Test loss: 1.168, Test accuracy: 73.80 

Round   5, Train loss: 0.031, Test loss: 0.822, Test accuracy: 80.52 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.680, Test accuracy: 85.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 0.870, Test accuracy: 82.20 

        train local model (freeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.899, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.045, Test accuracy: 78.60 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.740, Test accuracy: 83.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.006, Train accuracy: 100.000, Test loss: 0.938, Test accuracy: 80.40 

        train local model (freeze embeding):client   3,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 1.089, Test accuracy: 75.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.009, Train accuracy: 99.800, Test loss: 1.346, Test accuracy: 71.60 

        train local model (freeze embeding):client   4,  Train loss: 0.015, Train accuracy: 100.000, Test loss: 0.820, Test accuracy: 80.00 

        train local model (unfreeze embeding):client   4,  Train loss: 0.018, Train accuracy: 99.400, Test loss: 1.126, Test accuracy: 73.60 

Round   6, Train loss: 0.008, Test loss: 0.834, Test accuracy: 80.60 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.671, Test accuracy: 86.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.020, Train accuracy: 99.400, Test loss: 0.948, Test accuracy: 82.80 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.943, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.002, Test accuracy: 79.40 

        train local model (freeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.741, Test accuracy: 84.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.028, Train accuracy: 98.800, Test loss: 1.000, Test accuracy: 79.40 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.092, Test accuracy: 76.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.265, Test accuracy: 74.60 

        train local model (freeze embeding):client   4,  Train loss: 0.008, Train accuracy: 100.000, Test loss: 0.815, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.131, Train accuracy: 95.800, Test loss: 1.336, Test accuracy: 72.00 

Round   7, Train loss: 0.036, Test loss: 0.856, Test accuracy: 80.68 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.665, Test accuracy: 85.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.737, Test accuracy: 86.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.936, Test accuracy: 79.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.006, Train accuracy: 99.800, Test loss: 1.023, Test accuracy: 79.60 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.664, Test accuracy: 86.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.023, Train accuracy: 99.200, Test loss: 0.921, Test accuracy: 80.40 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.115, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.015, Train accuracy: 99.600, Test loss: 1.237, Test accuracy: 72.60 

        train local model (freeze embeding):client   4,  Train loss: 0.009, Train accuracy: 100.000, Test loss: 0.814, Test accuracy: 78.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.035, Train accuracy: 98.000, Test loss: 1.219, Test accuracy: 74.60 

Round   8, Train loss: 0.016, Test loss: 0.833, Test accuracy: 80.76 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.686, Test accuracy: 85.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.789, Test accuracy: 85.00 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.897, Test accuracy: 80.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.037, Test accuracy: 78.80 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.703, Test accuracy: 84.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.871, Test accuracy: 83.00 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.131, Test accuracy: 75.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.392, Test accuracy: 72.60 

        train local model (freeze embeding):client   4,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.792, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.114, Train accuracy: 95.600, Test loss: 1.625, Test accuracy: 69.80 

Round   9, Train loss: 0.024, Test loss: 0.840, Test accuracy: 80.92 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.678, Test accuracy: 85.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.870, Test accuracy: 82.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.938, Test accuracy: 81.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.017, Test accuracy: 79.00 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.671, Test accuracy: 84.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.017, Train accuracy: 99.200, Test loss: 0.949, Test accuracy: 79.00 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.087, Test accuracy: 76.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.256, Test accuracy: 73.60 

        train local model (freeze embeding):client   4,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.867, Test accuracy: 78.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.342, Train accuracy: 87.800, Test loss: 1.842, Test accuracy: 64.20 

Round  10, Train loss: 0.072, Test loss: 0.830, Test accuracy: 80.40 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.685, Test accuracy: 85.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.782, Test accuracy: 83.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.913, Test accuracy: 79.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.005, Test accuracy: 80.60 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.665, Test accuracy: 85.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.780, Test accuracy: 82.60 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.053, Test accuracy: 75.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.162, Test accuracy: 76.20 

        train local model (freeze embeding):client   4,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.840, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.220, Train accuracy: 93.400, Test loss: 1.513, Test accuracy: 70.80 

Round  11, Train loss: 0.045, Test loss: 0.858, Test accuracy: 80.44 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.652, Test accuracy: 87.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.799, Test accuracy: 84.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.928, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.017, Train accuracy: 99.400, Test loss: 1.159, Test accuracy: 76.20 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.666, Test accuracy: 85.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.793, Test accuracy: 85.20 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.090, Test accuracy: 74.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.045, Train accuracy: 98.200, Test loss: 1.364, Test accuracy: 71.60 

        train local model (freeze embeding):client   4,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.879, Test accuracy: 78.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.029, Train accuracy: 99.200, Test loss: 1.062, Test accuracy: 75.80 

Round  12, Train loss: 0.019, Test loss: 0.828, Test accuracy: 81.20 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.667, Test accuracy: 85.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.826, Test accuracy: 83.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.935, Test accuracy: 81.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.002, Train accuracy: 99.800, Test loss: 1.037, Test accuracy: 81.00 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.733, Test accuracy: 84.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.846, Test accuracy: 82.80 

        train local model (freeze embeding):client   3,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 1.080, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.082, Train accuracy: 97.200, Test loss: 1.581, Test accuracy: 68.20 

        train local model (freeze embeding):client   4,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.881, Test accuracy: 79.80 

        train local model (unfreeze embeding):client   4,  Train loss: 0.038, Train accuracy: 98.800, Test loss: 1.253, Test accuracy: 72.20 

Round  13, Train loss: 0.025, Test loss: 0.814, Test accuracy: 81.72 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.645, Test accuracy: 85.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.020, Train accuracy: 99.600, Test loss: 0.937, Test accuracy: 82.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.883, Test accuracy: 80.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.130, Test accuracy: 78.20 

        train local model (freeze embeding):client   2,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.685, Test accuracy: 84.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.004, Train accuracy: 99.800, Test loss: 0.745, Test accuracy: 82.40 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.051, Test accuracy: 76.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.021, Train accuracy: 99.400, Test loss: 1.352, Test accuracy: 72.40 

        train local model (freeze embeding):client   4,  Train loss: 0.004, Train accuracy: 100.000, Test loss: 0.884, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.985, Test accuracy: 77.60 

Round  14, Train loss: 0.010, Test loss: 0.832, Test accuracy: 80.76 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.661, Test accuracy: 85.80 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.809, Test accuracy: 84.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.927, Test accuracy: 79.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.011, Train accuracy: 99.800, Test loss: 1.195, Test accuracy: 76.40 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.649, Test accuracy: 86.40 

        train local model (unfreeze embeding):client   2,  Train loss: 0.086, Train accuracy: 96.600, Test loss: 1.073, Test accuracy: 79.20 

        train local model (freeze embeding):client   3,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 1.043, Test accuracy: 76.20 

        train local model (unfreeze embeding):client   3,  Train loss: 0.097, Train accuracy: 97.200, Test loss: 1.413, Test accuracy: 69.80 

        train local model (freeze embeding):client   4,  Train loss: 0.003, Train accuracy: 100.000, Test loss: 0.840, Test accuracy: 80.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.010, Train accuracy: 99.800, Test loss: 1.188, Test accuracy: 75.60 

Round  15, Train loss: 0.041, Test loss: 0.827, Test accuracy: 80.44 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.687, Test accuracy: 85.60 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.727, Test accuracy: 84.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.876, Test accuracy: 80.00 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.151, Test accuracy: 77.80 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.662, Test accuracy: 85.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.793, Test accuracy: 84.00 

        train local model (freeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.039, Test accuracy: 75.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.167, Test accuracy: 74.00 

        train local model (freeze embeding):client   4,  Train loss: 0.005, Train accuracy: 100.000, Test loss: 0.906, Test accuracy: 77.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.025, Train accuracy: 99.400, Test loss: 1.275, Test accuracy: 73.80 

Round  16, Train loss: 0.005, Test loss: 0.846, Test accuracy: 80.20 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.659, Test accuracy: 86.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.730, Test accuracy: 86.60 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.897, Test accuracy: 80.60 

        train local model (unfreeze embeding):client   1,  Train loss: 0.018, Train accuracy: 99.400, Test loss: 1.185, Test accuracy: 78.00 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.677, Test accuracy: 84.80 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.785, Test accuracy: 84.60 

        train local model (freeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.088, Test accuracy: 75.40 

        train local model (unfreeze embeding):client   3,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.184, Test accuracy: 74.20 

        train local model (freeze embeding):client   4,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.908, Test accuracy: 78.20 

        train local model (unfreeze embeding):client   4,  Train loss: 0.105, Train accuracy: 96.200, Test loss: 1.326, Test accuracy: 74.00 

Round  17, Train loss: 0.025, Test loss: 0.854, Test accuracy: 80.52 

        train local model (freeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.645, Test accuracy: 85.20 

        train local model (unfreeze embeding):client   0,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.737, Test accuracy: 85.20 

        train local model (freeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.898, Test accuracy: 80.20 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.010, Test accuracy: 80.00 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.703, Test accuracy: 86.20 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.737, Test accuracy: 83.60 

        train local model (freeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.128, Test accuracy: 76.00 

        train local model (unfreeze embeding):client   3,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.218, Test accuracy: 75.80 

        train local model (freeze embeding):client   4,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 0.864, Test accuracy: 79.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.003, Train accuracy: 99.800, Test loss: 1.066, Test accuracy: 77.60 

Round  18, Train loss: 0.001, Test loss: 0.850, Test accuracy: 81.60 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.654, Test accuracy: 86.00 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.687, Test accuracy: 86.00 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.933, Test accuracy: 81.40 

        train local model (unfreeze embeding):client   1,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.147, Test accuracy: 77.60 

        train local model (freeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.666, Test accuracy: 87.00 

        train local model (unfreeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.775, Test accuracy: 84.00 

        train local model (freeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.067, Test accuracy: 75.60 

        train local model (unfreeze embeding):client   3,  Train loss: 0.002, Train accuracy: 100.000, Test loss: 1.327, Test accuracy: 72.40 

        train local model (freeze embeding):client   4,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.877, Test accuracy: 80.40 

        train local model (unfreeze embeding):client   4,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.997, Test accuracy: 77.80 

Round  19, Train loss: 0.001, Test loss: 0.859, Test accuracy: 81.12 

        train local model (freeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.654, Test accuracy: 85.40 

        train local model (unfreeze embeding):client   0,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.691, Test accuracy: 85.80 

        train local model (freeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.963, Test accuracy: 80.80 

        train local model (unfreeze embeding):client   1,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.962, Test accuracy: 80.20 

        train local model (freeze embeding):client   2,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 0.671, Test accuracy: 85.60 

        train local model (unfreeze embeding):client   2,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.788, Test accuracy: 84.60 

        train local model (freeze embeding):client   3,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 1.147, Test accuracy: 74.80 

        train local model (unfreeze embeding):client   3,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.172, Test accuracy: 75.60 

        train local model (freeze embeding):client   4,  Train loss: 0.001, Train accuracy: 100.000, Test loss: 0.876, Test accuracy: 80.60 

        train local model (unfreeze embeding):client   4,  Train loss: 0.000, Train accuracy: 100.000, Test loss: 1.103, Test accuracy: 78.80 

Final Round, Train loss: 0.000, Test loss: 0.860, Test accuracy: 81.20 

Average accuracy final 10 rounds: 396.4533333333334 

4929.127998828888
[15.189521551132202, 30.44753885269165, 45.803807735443115, 61.13638377189636, 75.67478084564209, 90.5104866027832, 105.89281177520752, 120.81562924385071, 135.62409138679504, 150.50149059295654, 165.26812100410461, 180.84606218338013, 195.88487601280212, 210.7290163040161, 225.48249769210815, 240.47616457939148, 255.88817691802979, 270.87544083595276, 285.5254168510437, 300.21650981903076, 315.3147828578949, 330.1682188510895, 344.9382698535919, 359.7120089530945, 374.5266845226288, 389.69123220443726, 404.80828881263733, 419.6958796977997, 434.54931640625, 449.39005994796753, 464.10839009284973, 478.68741369247437, 494.1943120956421, 509.6842751502991, 525.0097479820251, 540.5108547210693, 555.4735040664673, 570.3025269508362, 585.4338550567627, 600.6447751522064, 615.7763459682465, 631.6411309242249, 646.93807721138, 662.6766085624695, 678.4272408485413, 694.0799462795258, 709.4981579780579, 724.6854603290558, 740.0830907821655, 755.594043970108, 771.3315012454987, 786.5923926830292, 801.847825050354, 817.334451675415, 832.7061712741852, 847.7298460006714, 863.1384813785553, 878.5787160396576, 893.5995514392853, 908.8550112247467, 923.7371273040771, 938.4804837703705, 953.3912148475647, 968.6188328266144, 984.0102891921997, 998.8941259384155, 1014.3882622718811, 1029.4940280914307, 1044.624086856842, 1059.7059445381165, 1075.1682834625244, 1090.2057292461395, 1105.9554605484009, 1121.13143324852, 1136.3634269237518, 1152.0877623558044, 1167.32626080513, 1182.641610622406, 1198.0505156517029, 1213.8777344226837, 1229.7596898078918, 1245.2473430633545, 1260.940511226654, 1276.8339521884918, 1292.3639435768127, 1308.3821167945862, 1324.0002989768982, 1339.613618850708, 1354.878925561905, 1369.8572993278503, 1385.3569169044495, 1400.8764276504517, 1416.2517788410187, 1432.1682405471802, 1447.7018773555756, 1463.017830133438, 1478.6619758605957, 1494.7333014011383, 1509.7877101898193, 1525.4948716163635, 1541.2211487293243, 1557.3800067901611, 1573.3345358371735, 1589.0439403057098, 1605.0793583393097]
[60.8, 66.8, 63.8, 64.2, 66.8, 71.2, 75.4, 70.4, 72.8, 75.4, 73.2, 74.8, 77.4, 76.6, 75.8, 78.0, 76.2, 79.4, 79.2, 80.8, 80.0, 70.6, 76.2, 73.7, 74.7, 75.6, 71.8, 74.6, 74.9, 77.2, 76.6, 77.6, 75.3, 76.8, 76.1, 76.9, 76.5, 76.2, 77.3, 77.5, 76.7, 76.0, 76.6, 77.06666666666666, 78.66666666666667, 79.86666666666666, 80.13333333333334, 80.46666666666667, 80.2, 79.2, 80.46666666666667, 80.46666666666667, 80.53333333333333, 81.0, 80.33333333333333, 81.2, 81.2, 81.73333333333333, 81.53333333333333, 80.46666666666667, 81.66666666666667, 82.46666666666667, 82.33333333333333, 77.95, 74.9, 78.85, 78.9, 80.2, 79.85, 81.5, 80.6, 80.7, 80.05, 80.0, 80.7, 80.3, 81.4, 80.15, 79.95, 80.5, 80.8, 80.7, 81.2, 81.45, 78.64, 79.2, 79.92, 79.08, 80.6, 80.52, 80.6, 80.68, 80.76, 80.92, 80.4, 80.44, 81.2, 81.72, 80.76, 80.44, 80.2, 80.52, 81.6, 81.12, 81.2]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.627, Test loss: 0.748, Test accuracy: 74.00 

Round   0, Global train loss: 0.627, Global test loss: 0.699, Global test accuracy: 50.10 

Round   1, Train loss: 0.454, Test loss: 0.519, Test accuracy: 77.00 

Round   1, Global train loss: 0.454, Global test loss: 0.694, Global test accuracy: 51.00 

Round   2, Train loss: 0.416, Test loss: 0.526, Test accuracy: 80.40 

Round   2, Global train loss: 0.416, Global test loss: 0.691, Global test accuracy: 51.90 

Round   3, Train loss: 0.328, Test loss: 0.624, Test accuracy: 78.80 

Round   3, Global train loss: 0.328, Global test loss: 0.705, Global test accuracy: 50.10 

Round   4, Train loss: 0.287, Test loss: 0.746, Test accuracy: 77.50 

Round   4, Global train loss: 0.287, Global test loss: 0.712, Global test accuracy: 50.00 

Round   5, Train loss: 0.242, Test loss: 0.592, Test accuracy: 83.50 

Round   5, Global train loss: 0.242, Global test loss: 0.708, Global test accuracy: 50.10 

Round   6, Train loss: 0.222, Test loss: 0.546, Test accuracy: 81.80 

Round   6, Global train loss: 0.222, Global test loss: 0.708, Global test accuracy: 50.10 

Round   7, Train loss: 0.183, Test loss: 0.776, Test accuracy: 79.40 

Round   7, Global train loss: 0.183, Global test loss: 0.730, Global test accuracy: 50.00 

Round   8, Train loss: 0.163, Test loss: 0.614, Test accuracy: 82.10 

Round   8, Global train loss: 0.163, Global test loss: 0.698, Global test accuracy: 50.10 

Round   9, Train loss: 0.152, Test loss: 0.510, Test accuracy: 83.10 

Round   9, Global train loss: 0.152, Global test loss: 0.706, Global test accuracy: 50.10 

Round  10, Train loss: 0.119, Test loss: 0.787, Test accuracy: 79.30 

Round  10, Global train loss: 0.119, Global test loss: 0.713, Global test accuracy: 50.00 

Round  11, Train loss: 0.104, Test loss: 0.800, Test accuracy: 81.50 

Round  11, Global train loss: 0.104, Global test loss: 0.708, Global test accuracy: 50.10 

Round  12, Train loss: 0.109, Test loss: 0.696, Test accuracy: 82.70 

Round  12, Global train loss: 0.109, Global test loss: 0.741, Global test accuracy: 50.00 

Round  13, Train loss: 0.099, Test loss: 0.800, Test accuracy: 83.50 

Round  13, Global train loss: 0.099, Global test loss: 0.711, Global test accuracy: 50.00 

Round  14, Train loss: 0.092, Test loss: 1.180, Test accuracy: 80.30 

Round  14, Global train loss: 0.092, Global test loss: 0.710, Global test accuracy: 50.00 

Round  15, Train loss: 0.074, Test loss: 0.823, Test accuracy: 82.30 

Round  15, Global train loss: 0.074, Global test loss: 0.739, Global test accuracy: 50.00 

Round  16, Train loss: 0.060, Test loss: 0.674, Test accuracy: 82.50 

Round  16, Global train loss: 0.060, Global test loss: 0.734, Global test accuracy: 50.00 

Round  17, Train loss: 0.075, Test loss: 0.960, Test accuracy: 79.40 

Round  17, Global train loss: 0.075, Global test loss: 0.781, Global test accuracy: 50.00 

Round  18, Train loss: 0.078, Test loss: 0.763, Test accuracy: 84.30 

Round  18, Global train loss: 0.078, Global test loss: 0.722, Global test accuracy: 50.00 

Round  19, Train loss: 0.040, Test loss: 0.819, Test accuracy: 82.80 

Round  19, Global train loss: 0.040, Global test loss: 0.691, Global test accuracy: 51.90 

Round  20, Train loss: 0.054, Test loss: 0.716, Test accuracy: 82.10 

Round  20, Global train loss: 0.054, Global test loss: 0.712, Global test accuracy: 50.00 

Round  21, Train loss: 0.049, Test loss: 0.718, Test accuracy: 83.50 

Round  21, Global train loss: 0.049, Global test loss: 0.705, Global test accuracy: 50.00 

Round  22, Train loss: 0.026, Test loss: 0.819, Test accuracy: 82.80 

Round  22, Global train loss: 0.026, Global test loss: 0.702, Global test accuracy: 50.20 

Round  23, Train loss: 0.045, Test loss: 0.761, Test accuracy: 83.70 

Round  23, Global train loss: 0.045, Global test loss: 0.690, Global test accuracy: 51.30 

Round  24, Train loss: 0.033, Test loss: 0.838, Test accuracy: 84.50 

Round  24, Global train loss: 0.033, Global test loss: 0.704, Global test accuracy: 50.00 

Round  25, Train loss: 0.028, Test loss: 0.826, Test accuracy: 83.10 

Round  25, Global train loss: 0.028, Global test loss: 0.701, Global test accuracy: 50.00 

Round  26, Train loss: 0.032, Test loss: 0.992, Test accuracy: 81.30 

Round  26, Global train loss: 0.032, Global test loss: 0.704, Global test accuracy: 50.00 

Round  27, Train loss: 0.041, Test loss: 0.753, Test accuracy: 82.60 

Round  27, Global train loss: 0.041, Global test loss: 0.693, Global test accuracy: 51.10 

Round  28, Train loss: 0.013, Test loss: 0.798, Test accuracy: 82.40 

Round  28, Global train loss: 0.013, Global test loss: 0.724, Global test accuracy: 50.00 

Round  29, Train loss: 0.015, Test loss: 0.807, Test accuracy: 83.20 

Round  29, Global train loss: 0.015, Global test loss: 0.727, Global test accuracy: 50.00 

Round  30, Train loss: 0.023, Test loss: 0.727, Test accuracy: 83.20 

Round  30, Global train loss: 0.023, Global test loss: 0.707, Global test accuracy: 50.00 

Round  31, Train loss: 0.023, Test loss: 0.743, Test accuracy: 83.80 

Round  31, Global train loss: 0.023, Global test loss: 0.711, Global test accuracy: 50.10 

Round  32, Train loss: 0.013, Test loss: 0.730, Test accuracy: 83.60 

Round  32, Global train loss: 0.013, Global test loss: 0.701, Global test accuracy: 50.50 

Round  33, Train loss: 0.008, Test loss: 0.734, Test accuracy: 83.40 

Round  33, Global train loss: 0.008, Global test loss: 0.739, Global test accuracy: 50.00 

Round  34, Train loss: 0.006, Test loss: 0.741, Test accuracy: 84.50 

Round  34, Global train loss: 0.006, Global test loss: 0.718, Global test accuracy: 50.00 

Final Round, Train loss: 0.014, Test loss: 0.790, Test accuracy: 84.70 

Final Round, Global train loss: 0.014, Global test loss: 0.718, Global test accuracy: 50.00 

Average accuracy final 10 rounds: 83.11 

Average global accuracy final 10 rounds: 50.169999999999995 

470.2101991176605
[4.403834342956543, 6.785834550857544, 9.019788026809692, 11.36707353591919, 13.642091989517212, 16.056507110595703, 18.740787744522095, 21.28685426712036, 23.609654664993286, 26.048280239105225, 28.438770532608032, 30.675761938095093, 32.905744552612305, 35.14411664009094, 37.37031030654907, 39.58358144760132, 41.86957883834839, 44.14689064025879, 46.492396116256714, 48.83479905128479, 51.08546853065491, 53.324321269989014, 55.68585538864136, 58.12225961685181, 60.390082597732544, 62.67402720451355, 64.97016763687134, 67.25279664993286, 69.57122874259949, 71.92513012886047, 74.2805347442627, 76.52449488639832, 78.92909908294678, 81.35896825790405, 83.757483959198, 88.25541138648987]
[74.0, 77.0, 80.4, 78.8, 77.5, 83.5, 81.8, 79.4, 82.1, 83.1, 79.3, 81.5, 82.7, 83.5, 80.3, 82.3, 82.5, 79.4, 84.3, 82.8, 82.1, 83.5, 82.8, 83.7, 84.5, 83.1, 81.3, 82.6, 82.4, 83.2, 83.2, 83.8, 83.6, 83.4, 84.5, 84.7]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.650, Test loss: 0.660, Test accuracy: 72.40 

Round   0, Global train loss: 0.650, Global test loss: 0.705, Global test accuracy: 50.00 

Round   1, Train loss: 0.566, Test loss: 0.775, Test accuracy: 77.20 

Round   1, Global train loss: 0.566, Global test loss: 0.698, Global test accuracy: 53.30 

Round   2, Train loss: 0.536, Test loss: 0.655, Test accuracy: 74.80 

Round   2, Global train loss: 0.536, Global test loss: 0.694, Global test accuracy: 56.70 

Round   3, Train loss: 0.486, Test loss: 0.601, Test accuracy: 75.10 

Round   3, Global train loss: 0.486, Global test loss: 0.712, Global test accuracy: 55.90 

Round   4, Train loss: 0.453, Test loss: 0.487, Test accuracy: 80.60 

Round   4, Global train loss: 0.453, Global test loss: 0.726, Global test accuracy: 58.70 

Round   5, Train loss: 0.441, Test loss: 0.523, Test accuracy: 80.10 

Round   5, Global train loss: 0.441, Global test loss: 0.687, Global test accuracy: 60.60 

Round   6, Train loss: 0.405, Test loss: 0.530, Test accuracy: 81.90 

Round   6, Global train loss: 0.405, Global test loss: 0.701, Global test accuracy: 59.30 

Round   7, Train loss: 0.382, Test loss: 0.569, Test accuracy: 78.50 

Round   7, Global train loss: 0.382, Global test loss: 0.697, Global test accuracy: 60.10 

Round   8, Train loss: 0.345, Test loss: 0.481, Test accuracy: 81.50 

Round   8, Global train loss: 0.345, Global test loss: 0.736, Global test accuracy: 62.10 

Round   9, Train loss: 0.330, Test loss: 0.638, Test accuracy: 77.00 

Round   9, Global train loss: 0.330, Global test loss: 0.771, Global test accuracy: 59.50 

Round  10, Train loss: 0.315, Test loss: 0.557, Test accuracy: 81.10 

Round  10, Global train loss: 0.315, Global test loss: 0.743, Global test accuracy: 62.30 

Round  11, Train loss: 0.279, Test loss: 0.572, Test accuracy: 81.00 

Round  11, Global train loss: 0.279, Global test loss: 0.754, Global test accuracy: 61.80 

Round  12, Train loss: 0.285, Test loss: 0.585, Test accuracy: 80.60 

Round  12, Global train loss: 0.285, Global test loss: 0.770, Global test accuracy: 62.30 

Round  13, Train loss: 0.278, Test loss: 0.617, Test accuracy: 79.90 

Round  13, Global train loss: 0.278, Global test loss: 0.799, Global test accuracy: 63.70 

Round  14, Train loss: 0.247, Test loss: 0.462, Test accuracy: 84.30 

Round  14, Global train loss: 0.247, Global test loss: 0.754, Global test accuracy: 62.20 

Round  15, Train loss: 0.233, Test loss: 0.596, Test accuracy: 81.20 

Round  15, Global train loss: 0.233, Global test loss: 0.825, Global test accuracy: 63.00 

Round  16, Train loss: 0.218, Test loss: 0.559, Test accuracy: 81.30 

Round  16, Global train loss: 0.218, Global test loss: 0.841, Global test accuracy: 61.90 

Round  17, Train loss: 0.219, Test loss: 0.580, Test accuracy: 84.50 

Round  17, Global train loss: 0.219, Global test loss: 0.760, Global test accuracy: 62.90 

Round  18, Train loss: 0.195, Test loss: 0.697, Test accuracy: 80.50 

Round  18, Global train loss: 0.195, Global test loss: 0.819, Global test accuracy: 63.10 

Round  19, Train loss: 0.205, Test loss: 0.605, Test accuracy: 80.80 

Round  19, Global train loss: 0.205, Global test loss: 0.800, Global test accuracy: 62.40 

Round  20, Train loss: 0.172, Test loss: 0.770, Test accuracy: 79.50 

Round  20, Global train loss: 0.172, Global test loss: 0.873, Global test accuracy: 61.80 

Round  21, Train loss: 0.191, Test loss: 0.592, Test accuracy: 82.10 

Round  21, Global train loss: 0.191, Global test loss: 0.863, Global test accuracy: 62.10 

Round  22, Train loss: 0.164, Test loss: 0.533, Test accuracy: 83.40 

Round  22, Global train loss: 0.164, Global test loss: 0.859, Global test accuracy: 64.70 

Round  23, Train loss: 0.152, Test loss: 0.622, Test accuracy: 79.90 

Round  23, Global train loss: 0.152, Global test loss: 0.895, Global test accuracy: 63.60 

Round  24, Train loss: 0.134, Test loss: 0.663, Test accuracy: 82.40 

Round  24, Global train loss: 0.134, Global test loss: 1.018, Global test accuracy: 62.10 

Round  25, Train loss: 0.124, Test loss: 0.974, Test accuracy: 80.10 

Round  25, Global train loss: 0.124, Global test loss: 0.937, Global test accuracy: 64.10 

Round  26, Train loss: 0.126, Test loss: 0.753, Test accuracy: 82.20 

Round  26, Global train loss: 0.126, Global test loss: 0.919, Global test accuracy: 63.30 

Round  27, Train loss: 0.150, Test loss: 0.583, Test accuracy: 82.50 

Round  27, Global train loss: 0.150, Global test loss: 0.930, Global test accuracy: 62.70 

Round  28, Train loss: 0.122, Test loss: 0.544, Test accuracy: 85.20 

Round  28, Global train loss: 0.122, Global test loss: 0.992, Global test accuracy: 63.00 

Round  29, Train loss: 0.095, Test loss: 0.516, Test accuracy: 83.90 

Round  29, Global train loss: 0.095, Global test loss: 0.883, Global test accuracy: 65.10 

Round  30, Train loss: 0.120, Test loss: 0.834, Test accuracy: 81.60 

Round  30, Global train loss: 0.120, Global test loss: 1.008, Global test accuracy: 62.60 

Round  31, Train loss: 0.096, Test loss: 0.663, Test accuracy: 83.30 

Round  31, Global train loss: 0.096, Global test loss: 0.966, Global test accuracy: 64.00 

Round  32, Train loss: 0.076, Test loss: 0.582, Test accuracy: 84.20 

Round  32, Global train loss: 0.076, Global test loss: 1.034, Global test accuracy: 64.60 

Round  33, Train loss: 0.116, Test loss: 0.576, Test accuracy: 83.70 

Round  33, Global train loss: 0.116, Global test loss: 0.992, Global test accuracy: 62.00 

Round  34, Train loss: 0.093, Test loss: 0.628, Test accuracy: 84.80 

Round  34, Global train loss: 0.093, Global test loss: 1.044, Global test accuracy: 62.60 

Final Round, Train loss: 0.076, Test loss: 0.650, Test accuracy: 83.90 

Final Round, Global train loss: 0.076, Global test loss: 1.044, Global test accuracy: 62.60 

Average accuracy final 10 rounds: 83.15 

Average global accuracy final 10 rounds: 63.4 

469.3459486961365
[4.337669372558594, 6.6277406215667725, 9.022026777267456, 11.391126155853271, 13.735601425170898, 16.01283597946167, 18.26840353012085, 20.510189056396484, 22.83126926422119, 25.159106731414795, 27.352705001831055, 29.623939275741577, 31.904993534088135, 34.31493139266968, 36.519492387771606, 38.87774729728699, 41.35834980010986, 43.63239073753357, 45.90011382102966, 48.119223833084106, 50.3575177192688, 52.706303358078, 54.92348384857178, 57.26141548156738, 59.732261419296265, 62.08692789077759, 64.36979484558105, 66.7191846370697, 68.96998167037964, 71.2704381942749, 73.49701857566833, 75.76455783843994, 78.29392695426941, 80.67493271827698, 82.97345638275146, 87.58376455307007]
[72.4, 77.2, 74.8, 75.1, 80.6, 80.1, 81.9, 78.5, 81.5, 77.0, 81.1, 81.0, 80.6, 79.9, 84.3, 81.2, 81.3, 84.5, 80.5, 80.8, 79.5, 82.1, 83.4, 79.9, 82.4, 80.1, 82.2, 82.5, 85.2, 83.9, 81.6, 83.3, 84.2, 83.7, 84.8, 83.9]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.703, Test loss: 1.109, Test accuracy: 50.20 

Round   1, Train loss: 0.661, Test loss: 0.726, Test accuracy: 63.00 

Round   2, Train loss: 0.561, Test loss: 0.707, Test accuracy: 67.20 

Round   3, Train loss: 0.550, Test loss: 1.037, Test accuracy: 63.70 

Round   4, Train loss: 0.510, Test loss: 0.595, Test accuracy: 71.00 

Round   5, Train loss: 0.457, Test loss: 0.596, Test accuracy: 69.60 

Round   6, Train loss: 0.431, Test loss: 0.387, Test accuracy: 81.40 

Round   7, Train loss: 0.413, Test loss: 0.451, Test accuracy: 79.10 

Round   8, Train loss: 0.423, Test loss: 0.403, Test accuracy: 80.40 

Round   9, Train loss: 0.374, Test loss: 0.512, Test accuracy: 76.90 

Round  10, Train loss: 0.357, Test loss: 0.460, Test accuracy: 78.60 

Round  11, Train loss: 0.354, Test loss: 0.499, Test accuracy: 79.70 

Round  12, Train loss: 0.331, Test loss: 0.372, Test accuracy: 83.90 

Round  13, Train loss: 0.306, Test loss: 0.478, Test accuracy: 79.00 

Round  14, Train loss: 0.298, Test loss: 0.405, Test accuracy: 83.60 

Round  15, Train loss: 0.280, Test loss: 0.384, Test accuracy: 82.20 

Round  16, Train loss: 0.293, Test loss: 0.588, Test accuracy: 78.60 

Round  17, Train loss: 0.244, Test loss: 0.417, Test accuracy: 83.40 

Round  18, Train loss: 0.238, Test loss: 0.466, Test accuracy: 81.90 

Round  19, Train loss: 0.215, Test loss: 0.426, Test accuracy: 82.90 

Round  20, Train loss: 0.205, Test loss: 0.426, Test accuracy: 82.90 

Round  21, Train loss: 0.215, Test loss: 0.433, Test accuracy: 82.00 

Round  22, Train loss: 0.202, Test loss: 0.406, Test accuracy: 82.80 

Round  23, Train loss: 0.187, Test loss: 0.398, Test accuracy: 84.40 

Round  24, Train loss: 0.182, Test loss: 0.449, Test accuracy: 83.50 

Round  25, Train loss: 0.191, Test loss: 0.383, Test accuracy: 84.60 

Round  26, Train loss: 0.156, Test loss: 0.424, Test accuracy: 83.90 

Round  27, Train loss: 0.134, Test loss: 0.460, Test accuracy: 83.60 

Round  28, Train loss: 0.160, Test loss: 0.495, Test accuracy: 83.20 

Round  29, Train loss: 0.139, Test loss: 0.542, Test accuracy: 83.00 

Round  30, Train loss: 0.137, Test loss: 0.485, Test accuracy: 84.20 

Round  31, Train loss: 0.131, Test loss: 0.462, Test accuracy: 84.60 

Round  32, Train loss: 0.130, Test loss: 0.403, Test accuracy: 85.90 

Round  33, Train loss: 0.109, Test loss: 0.458, Test accuracy: 84.40 

Round  34, Train loss: 0.105, Test loss: 0.440, Test accuracy: 85.20 

Round  35, Train loss: 0.104, Test loss: 0.432, Test accuracy: 83.70 

Round  36, Train loss: 0.099, Test loss: 0.438, Test accuracy: 84.10 

Round  37, Train loss: 0.094, Test loss: 0.493, Test accuracy: 83.90 

Round  38, Train loss: 0.076, Test loss: 0.465, Test accuracy: 84.40 

Round  39, Train loss: 0.084, Test loss: 0.454, Test accuracy: 84.00 

Round  40, Train loss: 0.088, Test loss: 0.456, Test accuracy: 84.40 

Round  41, Train loss: 0.081, Test loss: 0.478, Test accuracy: 83.80 

Round  42, Train loss: 0.077, Test loss: 0.508, Test accuracy: 84.30 

Round  43, Train loss: 0.077, Test loss: 0.454, Test accuracy: 84.90 

Round  44, Train loss: 0.073, Test loss: 0.437, Test accuracy: 85.20 

Round  45, Train loss: 0.047, Test loss: 0.454, Test accuracy: 85.40 

Round  46, Train loss: 0.049, Test loss: 0.517, Test accuracy: 85.10 

Round  47, Train loss: 0.071, Test loss: 0.501, Test accuracy: 84.60 

Round  48, Train loss: 0.046, Test loss: 0.466, Test accuracy: 85.60 

Round  49, Train loss: 0.048, Test loss: 0.482, Test accuracy: 85.40 

Final Round, Train loss: 0.031, Test loss: 0.499, Test accuracy: 84.90 

Average accuracy final 10 rounds: 84.87 

490.15043354034424
[3.8370745182037354, 5.682917356491089, 7.468074321746826, 9.277449131011963, 11.049018144607544, 12.885030508041382, 14.790432691574097, 16.56251096725464, 18.386038064956665, 20.228604078292847, 22.180877447128296, 24.00191879272461, 25.79343867301941, 27.638394117355347, 29.471323013305664, 31.281996250152588, 33.11358976364136, 34.9220016002655, 36.913368701934814, 38.721590518951416, 40.502254486083984, 42.29430818557739, 44.1704843044281, 46.03994107246399, 47.82797431945801, 49.704808950424194, 51.50430083274841, 53.333595991134644, 55.18200135231018, 57.02363395690918, 58.85225582122803, 60.64400029182434, 62.468685150146484, 64.39362120628357, 66.33461856842041, 68.18382120132446, 70.0625319480896, 71.92460060119629, 73.72153186798096, 75.59632515907288, 77.41740322113037, 79.25264573097229, 81.0115282535553, 82.76619529724121, 84.60609030723572, 86.61790108680725, 88.35250544548035, 90.1972496509552, 92.2683334350586, 94.13073110580444, 96.03122305870056]
[50.2, 63.0, 67.2, 63.7, 71.0, 69.6, 81.4, 79.1, 80.4, 76.9, 78.6, 79.7, 83.9, 79.0, 83.6, 82.2, 78.6, 83.4, 81.9, 82.9, 82.9, 82.0, 82.8, 84.4, 83.5, 84.6, 83.9, 83.6, 83.2, 83.0, 84.2, 84.6, 85.9, 84.4, 85.2, 83.7, 84.1, 83.9, 84.4, 84.0, 84.4, 83.8, 84.3, 84.9, 85.2, 85.4, 85.1, 84.6, 85.6, 85.4, 84.9]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
Round   0, Train loss: 0.727, Test loss: 0.898, Test accuracy: 50.80
Round   1, Train loss: 0.638, Test loss: 1.025, Test accuracy: 51.70
Round   2, Train loss: 0.588, Test loss: 0.821, Test accuracy: 58.70
Round   3, Train loss: 0.527, Test loss: 0.801, Test accuracy: 60.10
Round   4, Train loss: 0.522, Test loss: 0.812, Test accuracy: 61.50
Round   5, Train loss: 0.456, Test loss: 0.628, Test accuracy: 68.60
Round   6, Train loss: 0.468, Test loss: 0.649, Test accuracy: 73.20
Round   7, Train loss: 0.424, Test loss: 0.703, Test accuracy: 70.40
Round   8, Train loss: 0.401, Test loss: 0.520, Test accuracy: 77.10
Round   9, Train loss: 0.379, Test loss: 0.466, Test accuracy: 78.30
Round  10, Train loss: 0.358, Test loss: 0.553, Test accuracy: 75.50
Round  11, Train loss: 0.349, Test loss: 0.530, Test accuracy: 78.40
Round  12, Train loss: 0.325, Test loss: 0.735, Test accuracy: 77.90
Round  13, Train loss: 0.316, Test loss: 0.423, Test accuracy: 80.60
Round  14, Train loss: 0.285, Test loss: 0.396, Test accuracy: 81.30
Round  15, Train loss: 0.270, Test loss: 0.385, Test accuracy: 82.90
Round  16, Train loss: 0.258, Test loss: 0.419, Test accuracy: 80.90
Round  17, Train loss: 0.253, Test loss: 0.552, Test accuracy: 78.70
Round  18, Train loss: 0.236, Test loss: 0.493, Test accuracy: 81.40
Round  19, Train loss: 0.223, Test loss: 0.441, Test accuracy: 81.10
Round  20, Train loss: 0.218, Test loss: 0.439, Test accuracy: 82.30
Round  21, Train loss: 0.202, Test loss: 0.507, Test accuracy: 82.50
Round  22, Train loss: 0.186, Test loss: 0.489, Test accuracy: 81.80
Round  23, Train loss: 0.184, Test loss: 0.486, Test accuracy: 81.30
Round  24, Train loss: 0.177, Test loss: 0.465, Test accuracy: 81.80
Round  25, Train loss: 0.161, Test loss: 0.454, Test accuracy: 83.00
Round  26, Train loss: 0.160, Test loss: 0.454, Test accuracy: 83.70
Round  27, Train loss: 0.159, Test loss: 0.426, Test accuracy: 83.90
Round  28, Train loss: 0.138, Test loss: 0.440, Test accuracy: 83.50
Round  29, Train loss: 0.127, Test loss: 0.396, Test accuracy: 85.00
Round  30, Train loss: 0.124, Test loss: 0.457, Test accuracy: 84.70
Round  31, Train loss: 0.127, Test loss: 0.418, Test accuracy: 83.60
Round  32, Train loss: 0.121, Test loss: 0.624, Test accuracy: 83.30
Round  33, Train loss: 0.101, Test loss: 0.450, Test accuracy: 83.60
Round  34, Train loss: 0.091, Test loss: 0.493, Test accuracy: 83.90
Round  35, Train loss: 0.104, Test loss: 0.455, Test accuracy: 83.80
Round  36, Train loss: 0.109, Test loss: 0.462, Test accuracy: 84.90
Round  37, Train loss: 0.083, Test loss: 0.474, Test accuracy: 83.90
Round  38, Train loss: 0.091, Test loss: 0.448, Test accuracy: 84.10
Round  39, Train loss: 0.076, Test loss: 0.465, Test accuracy: 84.40
Round  40, Train loss: 0.078, Test loss: 0.457, Test accuracy: 84.40
Round  41, Train loss: 0.076, Test loss: 0.457, Test accuracy: 84.80
Round  42, Train loss: 0.066, Test loss: 0.430, Test accuracy: 85.30
Round  43, Train loss: 0.048, Test loss: 0.486, Test accuracy: 85.40
Round  44, Train loss: 0.075, Test loss: 0.457, Test accuracy: 85.40
Round  45, Train loss: 0.055, Test loss: 0.510, Test accuracy: 85.90
Round  46, Train loss: 0.045, Test loss: 0.489, Test accuracy: 85.60
Round  47, Train loss: 0.054, Test loss: 0.481, Test accuracy: 85.00
Round  48, Train loss: 0.058, Test loss: 0.556, Test accuracy: 84.00
Round  49, Train loss: 0.056, Test loss: 0.486, Test accuracy: 84.10
Final Round, Train loss: 0.041, Test loss: 0.503, Test accuracy: 83.80
Average accuracy final 10 rounds: 84.99000000000001
556.2506074905396
[4.163273572921753, 6.233851194381714, 8.32679557800293, 10.461215496063232, 12.524177312850952, 14.598721027374268, 16.64901876449585, 18.744465112686157, 21.028720140457153, 23.205869913101196, 25.3307044506073, 27.337311506271362, 29.412874221801758, 31.41888999938965, 33.42724967002869, 35.753629207611084, 37.82913422584534, 39.883431911468506, 42.03879404067993, 44.0705680847168, 46.15083718299866, 48.311054706573486, 50.38797354698181, 52.44792032241821, 54.542001247406006, 56.67334818840027, 58.871729373931885, 60.952369689941406, 62.99170637130737, 65.09243965148926, 67.17708110809326, 69.2549180984497, 71.27602529525757, 73.39956903457642, 75.50155878067017, 77.69035363197327, 79.8292305469513, 81.98398470878601, 84.1462914943695, 86.19700074195862, 88.3624815940857, 90.4168632030487, 92.54800128936768, 94.63201522827148, 96.74335050582886, 98.88925862312317, 101.02247524261475, 103.19717764854431, 105.32389998435974, 107.29739308357239, 109.82897901535034]
[50.8, 51.7, 58.7, 60.1, 61.5, 68.6, 73.2, 70.4, 77.1, 78.3, 75.5, 78.4, 77.9, 80.6, 81.3, 82.9, 80.9, 78.7, 81.4, 81.1, 82.3, 82.5, 81.8, 81.3, 81.8, 83.0, 83.7, 83.9, 83.5, 85.0, 84.7, 83.6, 83.3, 83.6, 83.9, 83.8, 84.9, 83.9, 84.1, 84.4, 84.4, 84.8, 85.3, 85.4, 85.4, 85.9, 85.6, 85.0, 84.0, 84.1, 83.8]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
Traceback (most recent call last):
  File "main_fedrep_increment2.py", line 219, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[c], first=True,isNew=True, local_eps=20)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 788, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.703, Test loss: 0.672, Test accuracy: 69.20 

Round   0, Global train loss: 0.703, Global test loss: 0.700, Global test accuracy: 50.00 

Round   1, Train loss: 0.536, Test loss: 0.732, Test accuracy: 74.40 

Round   1, Global train loss: 0.536, Global test loss: 0.691, Global test accuracy: 52.50 

Round   2, Train loss: 0.444, Test loss: 0.576, Test accuracy: 80.40 

Round   2, Global train loss: 0.444, Global test loss: 0.696, Global test accuracy: 50.20 

Round   3, Train loss: 0.387, Test loss: 0.644, Test accuracy: 78.20 

Round   3, Global train loss: 0.387, Global test loss: 0.745, Global test accuracy: 50.00 

Round   4, Train loss: 0.316, Test loss: 0.741, Test accuracy: 80.30 

Round   4, Global train loss: 0.316, Global test loss: 0.719, Global test accuracy: 50.00 

Round   5, Train loss: 0.312, Test loss: 0.643, Test accuracy: 78.00 

Round   5, Global train loss: 0.312, Global test loss: 0.764, Global test accuracy: 50.00 

Round   6, Train loss: 0.270, Test loss: 0.558, Test accuracy: 81.70 

Round   6, Global train loss: 0.270, Global test loss: 0.733, Global test accuracy: 50.00 

Round   7, Train loss: 0.215, Test loss: 0.621, Test accuracy: 81.30 

Round   7, Global train loss: 0.215, Global test loss: 0.721, Global test accuracy: 50.00 

Round   8, Train loss: 0.169, Test loss: 0.778, Test accuracy: 80.90 

Round   8, Global train loss: 0.169, Global test loss: 0.764, Global test accuracy: 50.00 

Round   9, Train loss: 0.211, Test loss: 0.721, Test accuracy: 80.30 

Round   9, Global train loss: 0.211, Global test loss: 0.720, Global test accuracy: 50.00 

Round  10, Train loss: 0.150, Test loss: 0.569, Test accuracy: 83.30 

Round  10, Global train loss: 0.150, Global test loss: 0.732, Global test accuracy: 50.00 

Round  11, Train loss: 0.136, Test loss: 0.617, Test accuracy: 82.50 

Round  11, Global train loss: 0.136, Global test loss: 0.768, Global test accuracy: 50.00 

Round  12, Train loss: 0.121, Test loss: 0.668, Test accuracy: 81.70 

Round  12, Global train loss: 0.121, Global test loss: 0.768, Global test accuracy: 50.00 

Round  13, Train loss: 0.098, Test loss: 0.677, Test accuracy: 83.60 

Round  13, Global train loss: 0.098, Global test loss: 0.776, Global test accuracy: 50.00 

Round  14, Train loss: 0.074, Test loss: 0.660, Test accuracy: 82.30 

Round  14, Global train loss: 0.074, Global test loss: 0.768, Global test accuracy: 50.00 

Round  15, Train loss: 0.090, Test loss: 0.765, Test accuracy: 82.80 

Round  15, Global train loss: 0.090, Global test loss: 0.770, Global test accuracy: 50.00 

Round  16, Train loss: 0.072, Test loss: 0.703, Test accuracy: 83.00 

Round  16, Global train loss: 0.072, Global test loss: 0.810, Global test accuracy: 50.00 

Round  17, Train loss: 0.065, Test loss: 0.654, Test accuracy: 83.70 

Round  17, Global train loss: 0.065, Global test loss: 0.818, Global test accuracy: 50.00 

Round  18, Train loss: 0.073, Test loss: 0.658, Test accuracy: 82.00 

Round  18, Global train loss: 0.073, Global test loss: 0.814, Global test accuracy: 50.00 

Round  19, Train loss: 0.079, Test loss: 0.571, Test accuracy: 84.10 

Round  19, Global train loss: 0.079, Global test loss: 0.742, Global test accuracy: 50.00 

Round  20, Train loss: 0.049, Test loss: 0.654, Test accuracy: 83.30 

Round  20, Global train loss: 0.049, Global test loss: 0.764, Global test accuracy: 50.00 

Round  21, Train loss: 0.039, Test loss: 0.676, Test accuracy: 83.60 

Round  21, Global train loss: 0.039, Global test loss: 0.766, Global test accuracy: 50.00 

Round  22, Train loss: 0.060, Test loss: 0.559, Test accuracy: 84.20 

Round  22, Global train loss: 0.060, Global test loss: 0.738, Global test accuracy: 49.80 

Round  23, Train loss: 0.026, Test loss: 0.611, Test accuracy: 84.70 

Round  23, Global train loss: 0.026, Global test loss: 0.740, Global test accuracy: 50.10 

Round  24, Train loss: 0.036, Test loss: 0.648, Test accuracy: 85.00 

Round  24, Global train loss: 0.036, Global test loss: 0.763, Global test accuracy: 50.00 

Round  25, Train loss: 0.029, Test loss: 0.727, Test accuracy: 82.60 

Round  25, Global train loss: 0.029, Global test loss: 0.749, Global test accuracy: 50.00 

Round  26, Train loss: 0.031, Test loss: 0.676, Test accuracy: 83.80 

Round  26, Global train loss: 0.031, Global test loss: 0.812, Global test accuracy: 50.00 

Round  27, Train loss: 0.034, Test loss: 0.636, Test accuracy: 83.90 

Round  27, Global train loss: 0.034, Global test loss: 0.798, Global test accuracy: 50.00 

Round  28, Train loss: 0.023, Test loss: 0.663, Test accuracy: 84.30 

Round  28, Global train loss: 0.023, Global test loss: 0.801, Global test accuracy: 50.00 

Round  29, Train loss: 0.021, Test loss: 0.626, Test accuracy: 84.10 

Round  29, Global train loss: 0.021, Global test loss: 0.788, Global test accuracy: 50.00 

Round  30, Train loss: 0.019, Test loss: 0.649, Test accuracy: 84.20 

Round  30, Global train loss: 0.019, Global test loss: 0.786, Global test accuracy: 50.00 

Round  31, Train loss: 0.016, Test loss: 0.711, Test accuracy: 83.70 

Round  31, Global train loss: 0.016, Global test loss: 0.774, Global test accuracy: 50.00 

Round  32, Train loss: 0.012, Test loss: 0.709, Test accuracy: 84.60 

Round  32, Global train loss: 0.012, Global test loss: 0.804, Global test accuracy: 50.00 

Round  33, Train loss: 0.019, Test loss: 0.750, Test accuracy: 83.90 

Round  33, Global train loss: 0.019, Global test loss: 0.764, Global test accuracy: 50.00 

Round  34, Train loss: 0.018, Test loss: 0.624, Test accuracy: 84.70 

Round  34, Global train loss: 0.018, Global test loss: 0.765, Global test accuracy: 50.00 

Final Round, Train loss: 0.006, Test loss: 0.673, Test accuracy: 85.10 

Final Round, Global train loss: 0.006, Global test loss: 0.765, Global test accuracy: 50.00 

Average accuracy final 10 rounds: 83.98 

Average global accuracy final 10 rounds: 50.0 

468.9805631637573
[4.488675117492676, 6.846513748168945, 9.094999074935913, 11.438060283660889, 13.653410911560059, 15.94823694229126, 18.290415287017822, 20.589685201644897, 22.85368847846985, 25.104843616485596, 27.534884691238403, 29.839298963546753, 32.263039112091064, 34.61045217514038, 36.91501808166504, 39.1581757068634, 41.38322830200195, 43.73471283912659, 46.16371393203735, 48.44790005683899, 50.73486828804016, 53.12105393409729, 55.40974688529968, 57.81078886985779, 60.03660988807678, 62.426411390304565, 64.78206396102905, 67.083744764328, 69.34068441390991, 71.7781355381012, 74.13296580314636, 76.39131283760071, 78.62695527076721, 80.98586058616638, 83.47527551651001, 88.16585779190063]
[69.2, 74.4, 80.4, 78.2, 80.3, 78.0, 81.7, 81.3, 80.9, 80.3, 83.3, 82.5, 81.7, 83.6, 82.3, 82.8, 83.0, 83.7, 82.0, 84.1, 83.3, 83.6, 84.2, 84.7, 85.0, 82.6, 83.8, 83.9, 84.3, 84.1, 84.2, 83.7, 84.6, 83.9, 84.7, 85.1]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.687, Test loss: 0.678, Test accuracy: 68.80 

Round   0, Global train loss: 0.687, Global test loss: 0.709, Global test accuracy: 50.00 

Round   1, Train loss: 0.637, Test loss: 0.556, Test accuracy: 75.60 

Round   1, Global train loss: 0.637, Global test loss: 0.696, Global test accuracy: 53.60 

Round   2, Train loss: 0.586, Test loss: 0.697, Test accuracy: 70.80 

Round   2, Global train loss: 0.586, Global test loss: 0.739, Global test accuracy: 55.70 

Round   3, Train loss: 0.549, Test loss: 0.731, Test accuracy: 73.00 

Round   3, Global train loss: 0.549, Global test loss: 0.663, Global test accuracy: 60.10 

Round   4, Train loss: 0.516, Test loss: 0.621, Test accuracy: 75.10 

Round   4, Global train loss: 0.516, Global test loss: 0.658, Global test accuracy: 59.70 

Round   5, Train loss: 0.475, Test loss: 0.586, Test accuracy: 78.00 

Round   5, Global train loss: 0.475, Global test loss: 0.653, Global test accuracy: 60.60 

Round   6, Train loss: 0.459, Test loss: 0.558, Test accuracy: 78.80 

Round   6, Global train loss: 0.459, Global test loss: 0.695, Global test accuracy: 60.50 

Round   7, Train loss: 0.415, Test loss: 0.697, Test accuracy: 79.80 

Round   7, Global train loss: 0.415, Global test loss: 0.660, Global test accuracy: 62.70 

Round   8, Train loss: 0.410, Test loss: 0.715, Test accuracy: 76.10 

Round   8, Global train loss: 0.410, Global test loss: 0.682, Global test accuracy: 62.30 

Round   9, Train loss: 0.370, Test loss: 0.506, Test accuracy: 81.00 

Round   9, Global train loss: 0.370, Global test loss: 0.670, Global test accuracy: 65.40 

Round  10, Train loss: 0.379, Test loss: 0.597, Test accuracy: 79.40 

Round  10, Global train loss: 0.379, Global test loss: 0.692, Global test accuracy: 62.30 

Round  11, Train loss: 0.353, Test loss: 0.751, Test accuracy: 76.20 

Round  11, Global train loss: 0.353, Global test loss: 0.648, Global test accuracy: 64.70 

Round  12, Train loss: 0.353, Test loss: 0.635, Test accuracy: 75.40 

Round  12, Global train loss: 0.353, Global test loss: 0.654, Global test accuracy: 65.20 

Round  13, Train loss: 0.302, Test loss: 0.394, Test accuracy: 85.80 

Round  13, Global train loss: 0.302, Global test loss: 0.687, Global test accuracy: 65.70 

Round  14, Train loss: 0.317, Test loss: 0.466, Test accuracy: 81.90 

Round  14, Global train loss: 0.317, Global test loss: 0.642, Global test accuracy: 66.20 

Round  15, Train loss: 0.284, Test loss: 0.396, Test accuracy: 84.30 

Round  15, Global train loss: 0.284, Global test loss: 0.648, Global test accuracy: 67.40 

Round  16, Train loss: 0.273, Test loss: 0.774, Test accuracy: 78.10 

Round  16, Global train loss: 0.273, Global test loss: 0.717, Global test accuracy: 65.90 

Round  17, Train loss: 0.238, Test loss: 0.528, Test accuracy: 80.80 

Round  17, Global train loss: 0.238, Global test loss: 0.673, Global test accuracy: 66.30 

Round  18, Train loss: 0.238, Test loss: 0.508, Test accuracy: 83.00 

Round  18, Global train loss: 0.238, Global test loss: 0.717, Global test accuracy: 66.50 

Round  19, Train loss: 0.250, Test loss: 0.669, Test accuracy: 81.40 

Round  19, Global train loss: 0.250, Global test loss: 0.789, Global test accuracy: 64.90 

Round  20, Train loss: 0.243, Test loss: 0.688, Test accuracy: 82.70 

Round  20, Global train loss: 0.243, Global test loss: 0.692, Global test accuracy: 67.70 

Round  21, Train loss: 0.221, Test loss: 0.654, Test accuracy: 80.70 

Round  21, Global train loss: 0.221, Global test loss: 0.662, Global test accuracy: 68.50 

Round  22, Train loss: 0.194, Test loss: 0.576, Test accuracy: 83.40 

Round  22, Global train loss: 0.194, Global test loss: 0.764, Global test accuracy: 66.10 

Round  23, Train loss: 0.185, Test loss: 0.555, Test accuracy: 82.70 

Round  23, Global train loss: 0.185, Global test loss: 0.759, Global test accuracy: 67.00 

Round  24, Train loss: 0.210, Test loss: 0.594, Test accuracy: 83.60 

Round  24, Global train loss: 0.210, Global test loss: 0.734, Global test accuracy: 65.50 

Round  25, Train loss: 0.183, Test loss: 0.512, Test accuracy: 85.10 

Round  25, Global train loss: 0.183, Global test loss: 0.832, Global test accuracy: 68.10 

Round  26, Train loss: 0.175, Test loss: 0.926, Test accuracy: 80.40 

Round  26, Global train loss: 0.175, Global test loss: 0.749, Global test accuracy: 67.40 

Round  27, Train loss: 0.152, Test loss: 0.716, Test accuracy: 82.00 

Round  27, Global train loss: 0.152, Global test loss: 0.726, Global test accuracy: 68.20 

Round  28, Train loss: 0.158, Test loss: 0.778, Test accuracy: 80.00 

Round  28, Global train loss: 0.158, Global test loss: 0.738, Global test accuracy: 68.70 

Round  29, Train loss: 0.133, Test loss: 0.491, Test accuracy: 85.90 

Round  29, Global train loss: 0.133, Global test loss: 0.706, Global test accuracy: 67.60 

Round  30, Train loss: 0.143, Test loss: 0.687, Test accuracy: 83.90 

Round  30, Global train loss: 0.143, Global test loss: 0.858, Global test accuracy: 64.10 

Round  31, Train loss: 0.140, Test loss: 0.571, Test accuracy: 82.10 

Round  31, Global train loss: 0.140, Global test loss: 0.784, Global test accuracy: 65.10 

Round  32, Train loss: 0.125, Test loss: 0.528, Test accuracy: 84.10 

Round  32, Global train loss: 0.125, Global test loss: 0.892, Global test accuracy: 65.60 

Round  33, Train loss: 0.133, Test loss: 0.683, Test accuracy: 82.50 

Round  33, Global train loss: 0.133, Global test loss: 0.787, Global test accuracy: 67.90 

Round  34, Train loss: 0.112, Test loss: 0.679, Test accuracy: 83.40 

Round  34, Global train loss: 0.112, Global test loss: 0.787, Global test accuracy: 68.50 

Final Round, Train loss: 0.093, Test loss: 0.672, Test accuracy: 83.90 

Final Round, Global train loss: 0.093, Global test loss: 0.787, Global test accuracy: 68.50 

Average accuracy final 10 rounds: 82.94000000000001 

Average global accuracy final 10 rounds: 67.11999999999999 

474.3397991657257
[4.384886026382446, 6.809321880340576, 9.130714416503906, 11.455918312072754, 13.916075229644775, 16.448744297027588, 18.71760392189026, 21.100630521774292, 23.392844676971436, 25.688965559005737, 28.19027018547058, 30.47832179069519, 32.79623794555664, 35.09666204452515, 37.38281178474426, 39.67329740524292, 41.97317147254944, 44.26425862312317, 46.55876588821411, 48.78954887390137, 51.3520233631134, 53.885427474975586, 56.271456718444824, 58.54859638214111, 61.00950336456299, 63.35061240196228, 65.94394254684448, 68.28628253936768, 70.64267921447754, 73.09056830406189, 75.37109041213989, 77.68390560150146, 80.08858799934387, 82.38808393478394, 84.74836802482605, 89.39787793159485]
[68.8, 75.6, 70.8, 73.0, 75.1, 78.0, 78.8, 79.8, 76.1, 81.0, 79.4, 76.2, 75.4, 85.8, 81.9, 84.3, 78.1, 80.8, 83.0, 81.4, 82.7, 80.7, 83.4, 82.7, 83.6, 85.1, 80.4, 82.0, 80.0, 85.9, 83.9, 82.1, 84.1, 82.5, 83.4, 83.9]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.744, Test loss: 0.988, Test accuracy: 50.00 

Round   1, Train loss: 0.678, Test loss: 0.843, Test accuracy: 56.50 

Round   2, Train loss: 0.652, Test loss: 0.689, Test accuracy: 62.10 

Round   3, Train loss: 0.615, Test loss: 0.677, Test accuracy: 61.30 

Round   4, Train loss: 0.585, Test loss: 0.647, Test accuracy: 68.00 

Round   5, Train loss: 0.552, Test loss: 0.631, Test accuracy: 67.60 

Round   6, Train loss: 0.551, Test loss: 0.647, Test accuracy: 67.00 

Round   7, Train loss: 0.496, Test loss: 0.669, Test accuracy: 74.70 

Round   8, Train loss: 0.510, Test loss: 0.537, Test accuracy: 71.60 

Round   9, Train loss: 0.454, Test loss: 0.440, Test accuracy: 79.20 

Round  10, Train loss: 0.448, Test loss: 0.651, Test accuracy: 71.90 

Round  11, Train loss: 0.428, Test loss: 0.738, Test accuracy: 76.70 

Round  12, Train loss: 0.416, Test loss: 0.712, Test accuracy: 73.20 

Round  13, Train loss: 0.378, Test loss: 0.400, Test accuracy: 81.80 

Round  14, Train loss: 0.364, Test loss: 0.563, Test accuracy: 77.20 

Round  15, Train loss: 0.343, Test loss: 0.457, Test accuracy: 80.70 

Round  16, Train loss: 0.325, Test loss: 0.573, Test accuracy: 76.80 

Round  17, Train loss: 0.320, Test loss: 0.523, Test accuracy: 79.70 

Round  18, Train loss: 0.312, Test loss: 0.462, Test accuracy: 80.80 

Round  19, Train loss: 0.280, Test loss: 0.404, Test accuracy: 83.00 

Round  20, Train loss: 0.258, Test loss: 0.408, Test accuracy: 83.60 

Round  21, Train loss: 0.241, Test loss: 0.417, Test accuracy: 82.20 

Round  22, Train loss: 0.250, Test loss: 0.387, Test accuracy: 84.20 

Round  23, Train loss: 0.230, Test loss: 0.391, Test accuracy: 85.00 

Round  24, Train loss: 0.241, Test loss: 0.409, Test accuracy: 83.90 

Round  25, Train loss: 0.211, Test loss: 0.358, Test accuracy: 86.10 

Round  26, Train loss: 0.219, Test loss: 0.433, Test accuracy: 83.30 

Round  27, Train loss: 0.189, Test loss: 0.561, Test accuracy: 79.10 

Round  28, Train loss: 0.189, Test loss: 0.577, Test accuracy: 80.00 

Round  29, Train loss: 0.161, Test loss: 0.449, Test accuracy: 83.50 

Round  30, Train loss: 0.179, Test loss: 0.405, Test accuracy: 84.20 

Round  31, Train loss: 0.148, Test loss: 0.428, Test accuracy: 84.90 

Round  32, Train loss: 0.162, Test loss: 0.352, Test accuracy: 86.40 

Round  33, Train loss: 0.137, Test loss: 0.354, Test accuracy: 85.10 

Round  34, Train loss: 0.141, Test loss: 0.417, Test accuracy: 84.60 

Round  35, Train loss: 0.133, Test loss: 0.378, Test accuracy: 85.30 

Round  36, Train loss: 0.118, Test loss: 0.390, Test accuracy: 86.00 

Round  37, Train loss: 0.106, Test loss: 0.398, Test accuracy: 86.30 

Round  38, Train loss: 0.108, Test loss: 0.435, Test accuracy: 85.00 

Round  39, Train loss: 0.114, Test loss: 0.511, Test accuracy: 83.60 

Round  40, Train loss: 0.097, Test loss: 0.383, Test accuracy: 87.10 

Round  41, Train loss: 0.096, Test loss: 0.387, Test accuracy: 86.30 

Round  42, Train loss: 0.077, Test loss: 0.454, Test accuracy: 85.70 

Round  43, Train loss: 0.089, Test loss: 0.447, Test accuracy: 85.80 

Round  44, Train loss: 0.079, Test loss: 0.433, Test accuracy: 85.40 

Round  45, Train loss: 0.081, Test loss: 0.470, Test accuracy: 85.40 

Round  46, Train loss: 0.074, Test loss: 0.444, Test accuracy: 86.60 

Round  47, Train loss: 0.067, Test loss: 0.371, Test accuracy: 86.80 

Round  48, Train loss: 0.063, Test loss: 0.439, Test accuracy: 86.20 

Round  49, Train loss: 0.067, Test loss: 0.466, Test accuracy: 85.80 

Final Round, Train loss: 0.037, Test loss: 0.503, Test accuracy: 85.10 

Average accuracy final 10 rounds: 86.11 

492.8532061576843
[3.99336314201355, 5.804894924163818, 7.66668176651001, 9.596280336380005, 11.419351577758789, 13.290328979492188, 15.092923879623413, 16.91057252883911, 18.72560954093933, 20.438718557357788, 22.220378160476685, 23.981420040130615, 25.804698705673218, 27.69019651412964, 29.668700218200684, 31.47252106666565, 33.472633600234985, 35.273496866226196, 37.10421562194824, 38.929168701171875, 40.76394319534302, 42.60067844390869, 44.40421223640442, 46.18862462043762, 48.08933901786804, 50.07576608657837, 51.95955181121826, 53.93844676017761, 55.80249786376953, 57.6403591632843, 59.444748878479004, 61.28797221183777, 63.12199783325195, 65.00844430923462, 66.8421835899353, 68.68773126602173, 70.5464837551117, 72.46355295181274, 74.25866675376892, 76.10086035728455, 77.94263553619385, 79.82511830329895, 81.64033603668213, 83.62686967849731, 85.42386627197266, 87.27936005592346, 89.04731035232544, 90.85648655891418, 92.70860886573792, 94.52633738517761, 96.8501148223877]
[50.0, 56.5, 62.1, 61.3, 68.0, 67.6, 67.0, 74.7, 71.6, 79.2, 71.9, 76.7, 73.2, 81.8, 77.2, 80.7, 76.8, 79.7, 80.8, 83.0, 83.6, 82.2, 84.2, 85.0, 83.9, 86.1, 83.3, 79.1, 80.0, 83.5, 84.2, 84.9, 86.4, 85.1, 84.6, 85.3, 86.0, 86.3, 85.0, 83.6, 87.1, 86.3, 85.7, 85.8, 85.4, 85.4, 86.6, 86.8, 86.2, 85.8, 85.1]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 50, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
Round   0, Train loss: 0.748, Test loss: 0.855, Test accuracy: 50.10
Round   1, Train loss: 0.712, Test loss: 0.856, Test accuracy: 52.60
Round   2, Train loss: 0.625, Test loss: 0.565, Test accuracy: 67.40
Round   3, Train loss: 0.632, Test loss: 0.845, Test accuracy: 60.30
Round   4, Train loss: 0.609, Test loss: 0.733, Test accuracy: 63.70
Round   5, Train loss: 0.597, Test loss: 0.879, Test accuracy: 61.60
Round   6, Train loss: 0.534, Test loss: 0.546, Test accuracy: 73.80
Round   7, Train loss: 0.510, Test loss: 0.629, Test accuracy: 68.80
Round   8, Train loss: 0.501, Test loss: 0.766, Test accuracy: 71.40
Round   9, Train loss: 0.476, Test loss: 0.669, Test accuracy: 72.70
Round  10, Train loss: 0.429, Test loss: 0.667, Test accuracy: 72.80
Round  11, Train loss: 0.422, Test loss: 0.609, Test accuracy: 73.50
Round  12, Train loss: 0.409, Test loss: 0.372, Test accuracy: 83.30
Round  13, Train loss: 0.395, Test loss: 0.600, Test accuracy: 73.30
Round  14, Train loss: 0.385, Test loss: 0.521, Test accuracy: 77.10
Round  15, Train loss: 0.344, Test loss: 0.369, Test accuracy: 82.90
Round  16, Train loss: 0.324, Test loss: 0.549, Test accuracy: 76.80
Round  17, Train loss: 0.317, Test loss: 0.399, Test accuracy: 82.90
Round  18, Train loss: 0.315, Test loss: 0.374, Test accuracy: 83.40
Round  19, Train loss: 0.298, Test loss: 0.455, Test accuracy: 80.30
Round  20, Train loss: 0.286, Test loss: 0.375, Test accuracy: 83.90
Round  21, Train loss: 0.283, Test loss: 0.623, Test accuracy: 77.10
Round  22, Train loss: 0.264, Test loss: 0.351, Test accuracy: 84.60
Round  23, Train loss: 0.251, Test loss: 0.437, Test accuracy: 82.40
Round  24, Train loss: 0.217, Test loss: 0.377, Test accuracy: 83.60
Round  25, Train loss: 0.221, Test loss: 0.379, Test accuracy: 85.00
Round  26, Train loss: 0.202, Test loss: 0.480, Test accuracy: 82.80
Round  27, Train loss: 0.197, Test loss: 0.408, Test accuracy: 84.00
Round  28, Train loss: 0.185, Test loss: 0.371, Test accuracy: 84.70
Round  29, Train loss: 0.168, Test loss: 0.404, Test accuracy: 84.30
Round  30, Train loss: 0.171, Test loss: 0.366, Test accuracy: 85.50
Round  31, Train loss: 0.167, Test loss: 0.440, Test accuracy: 83.60
Round  32, Train loss: 0.162, Test loss: 0.338, Test accuracy: 86.00
Round  33, Train loss: 0.155, Test loss: 0.346, Test accuracy: 84.90
Round  34, Train loss: 0.144, Test loss: 0.382, Test accuracy: 84.30
Round  35, Train loss: 0.122, Test loss: 0.385, Test accuracy: 85.50
Round  36, Train loss: 0.105, Test loss: 0.392, Test accuracy: 85.80
Round  37, Train loss: 0.122, Test loss: 0.366, Test accuracy: 86.30
Round  38, Train loss: 0.120, Test loss: 0.373, Test accuracy: 86.70
Round  39, Train loss: 0.112, Test loss: 0.382, Test accuracy: 86.00
Round  40, Train loss: 0.102, Test loss: 0.417, Test accuracy: 85.30
Round  41, Train loss: 0.092, Test loss: 0.353, Test accuracy: 87.40
Round  42, Train loss: 0.103, Test loss: 0.385, Test accuracy: 85.60
Round  43, Train loss: 0.091, Test loss: 0.403, Test accuracy: 86.70
Round  44, Train loss: 0.078, Test loss: 0.382, Test accuracy: 86.10
Round  45, Train loss: 0.062, Test loss: 0.405, Test accuracy: 85.40
Round  46, Train loss: 0.054, Test loss: 0.370, Test accuracy: 87.10
Round  47, Train loss: 0.063, Test loss: 0.359, Test accuracy: 86.90
Round  48, Train loss: 0.080, Test loss: 0.370, Test accuracy: 86.60
Round  49, Train loss: 0.076, Test loss: 0.426, Test accuracy: 85.00
Final Round, Train loss: 0.036, Test loss: 0.386, Test accuracy: 86.40
Average accuracy final 10 rounds: 86.21
556.8375668525696
[4.265461683273315, 6.4422338008880615, 8.49853229522705, 10.531184434890747, 12.614473342895508, 14.663553476333618, 16.812352895736694, 18.874727725982666, 20.983478546142578, 23.069297313690186, 25.12345862388611, 27.21345090866089, 29.221198797225952, 31.365743160247803, 33.59070444107056, 35.71714186668396, 37.933690547943115, 39.96828508377075, 42.15659856796265, 44.33767318725586, 46.50151467323303, 48.63731932640076, 50.7882444858551, 52.870176553726196, 54.9139609336853, 57.01932621002197, 59.12089991569519, 61.251938343048096, 63.482574462890625, 65.53575086593628, 67.70661520957947, 69.83107566833496, 71.93416619300842, 74.00694060325623, 76.08450841903687, 78.16009664535522, 80.26950073242188, 82.36293697357178, 84.46891641616821, 86.59433960914612, 88.65967416763306, 90.69433069229126, 92.78191995620728, 94.98042941093445, 97.13075065612793, 99.2845389842987, 101.3595929145813, 103.55281138420105, 105.6635639667511, 107.97988319396973, 110.22394490242004]
[50.1, 52.6, 67.4, 60.3, 63.7, 61.6, 73.8, 68.8, 71.4, 72.7, 72.8, 73.5, 83.3, 73.3, 77.1, 82.9, 76.8, 82.9, 83.4, 80.3, 83.9, 77.1, 84.6, 82.4, 83.6, 85.0, 82.8, 84.0, 84.7, 84.3, 85.5, 83.6, 86.0, 84.9, 84.3, 85.5, 85.8, 86.3, 86.7, 86.0, 85.3, 87.4, 85.6, 86.7, 86.1, 85.4, 87.1, 86.9, 86.6, 85.0, 86.4]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 2, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=2, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11179478 (local), 11178452 (global); Percentage 99.99 (11178452/11179478 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

Traceback (most recent call last):
  File "main_fedrep_increment2.py", line 219, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[c], first=True,isNew=True, local_eps=20)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 788, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.471, Test loss: 1.150, Test accuracy: 54.40 

Round   0, Global train loss: 1.471, Global test loss: 1.724, Global test accuracy: 24.30 

Round   1, Train loss: 1.164, Test loss: 1.345, Test accuracy: 49.20 

Round   1, Global train loss: 1.164, Global test loss: 1.766, Global test accuracy: 22.60 

Round   2, Train loss: 1.019, Test loss: 1.097, Test accuracy: 57.90 

Round   2, Global train loss: 1.019, Global test loss: 1.662, Global test accuracy: 25.60 

Round   3, Train loss: 0.897, Test loss: 1.299, Test accuracy: 56.70 

Round   3, Global train loss: 0.897, Global test loss: 1.635, Global test accuracy: 24.10 

Round   4, Train loss: 0.763, Test loss: 1.207, Test accuracy: 59.60 

Round   4, Global train loss: 0.763, Global test loss: 1.809, Global test accuracy: 27.20 

Round   5, Train loss: 0.659, Test loss: 1.331, Test accuracy: 59.80 

Round   5, Global train loss: 0.659, Global test loss: 1.948, Global test accuracy: 24.80 

Round   6, Train loss: 0.536, Test loss: 1.203, Test accuracy: 60.80 

Round   6, Global train loss: 0.536, Global test loss: 1.791, Global test accuracy: 23.70 

Round   7, Train loss: 0.464, Test loss: 1.246, Test accuracy: 62.70 

Round   7, Global train loss: 0.464, Global test loss: 1.743, Global test accuracy: 22.50 

Round   8, Train loss: 0.421, Test loss: 1.606, Test accuracy: 61.10 

Round   8, Global train loss: 0.421, Global test loss: 1.903, Global test accuracy: 21.40 

Round   9, Train loss: 0.353, Test loss: 1.265, Test accuracy: 66.50 

Round   9, Global train loss: 0.353, Global test loss: 1.905, Global test accuracy: 20.50 

Round  10, Train loss: 0.293, Test loss: 1.308, Test accuracy: 64.80 

Round  10, Global train loss: 0.293, Global test loss: 2.038, Global test accuracy: 20.40 

Round  11, Train loss: 0.243, Test loss: 1.979, Test accuracy: 57.70 

Round  11, Global train loss: 0.243, Global test loss: 2.204, Global test accuracy: 25.10 

Round  12, Train loss: 0.184, Test loss: 1.340, Test accuracy: 67.70 

Round  12, Global train loss: 0.184, Global test loss: 1.755, Global test accuracy: 27.00 

Round  13, Train loss: 0.200, Test loss: 1.567, Test accuracy: 65.30 

Round  13, Global train loss: 0.200, Global test loss: 2.150, Global test accuracy: 25.70 

Round  14, Train loss: 0.157, Test loss: 1.580, Test accuracy: 63.80 

Round  14, Global train loss: 0.157, Global test loss: 2.391, Global test accuracy: 24.10 

Round  15, Train loss: 0.126, Test loss: 1.356, Test accuracy: 69.80 

Round  15, Global train loss: 0.126, Global test loss: 2.113, Global test accuracy: 23.50 

Round  16, Train loss: 0.131, Test loss: 1.506, Test accuracy: 66.30 

Round  16, Global train loss: 0.131, Global test loss: 2.201, Global test accuracy: 25.50 

Round  17, Train loss: 0.079, Test loss: 1.848, Test accuracy: 62.50 

Round  17, Global train loss: 0.079, Global test loss: 2.134, Global test accuracy: 26.90 

Round  18, Train loss: 0.070, Test loss: 1.904, Test accuracy: 62.80 

Round  18, Global train loss: 0.070, Global test loss: 2.446, Global test accuracy: 24.90 

Round  19, Train loss: 0.089, Test loss: 1.513, Test accuracy: 70.10 

Round  19, Global train loss: 0.089, Global test loss: 2.160, Global test accuracy: 25.00 

Round  20, Train loss: 0.061, Test loss: 1.428, Test accuracy: 68.70 

Round  20, Global train loss: 0.061, Global test loss: 2.400, Global test accuracy: 23.20 

Round  21, Train loss: 0.041, Test loss: 1.633, Test accuracy: 68.80 

Round  21, Global train loss: 0.041, Global test loss: 2.411, Global test accuracy: 25.30 

Round  22, Train loss: 0.094, Test loss: 1.679, Test accuracy: 66.00 

Round  22, Global train loss: 0.094, Global test loss: 2.435, Global test accuracy: 24.80 

Round  23, Train loss: 0.059, Test loss: 1.615, Test accuracy: 68.10 

Round  23, Global train loss: 0.059, Global test loss: 2.143, Global test accuracy: 24.50 

Round  24, Train loss: 0.055, Test loss: 2.061, Test accuracy: 61.90 

Round  24, Global train loss: 0.055, Global test loss: 2.423, Global test accuracy: 25.00 

Round  25, Train loss: 0.061, Test loss: 1.783, Test accuracy: 68.10 

Round  25, Global train loss: 0.061, Global test loss: 2.007, Global test accuracy: 27.00 

Round  26, Train loss: 0.058, Test loss: 1.476, Test accuracy: 70.00 

Round  26, Global train loss: 0.058, Global test loss: 2.271, Global test accuracy: 24.80 

Round  27, Train loss: 0.032, Test loss: 1.707, Test accuracy: 68.70 

Round  27, Global train loss: 0.032, Global test loss: 2.114, Global test accuracy: 24.80 

Round  28, Train loss: 0.025, Test loss: 1.608, Test accuracy: 70.80 

Round  28, Global train loss: 0.025, Global test loss: 2.039, Global test accuracy: 26.60 

Round  29, Train loss: 0.037, Test loss: 1.733, Test accuracy: 69.40 

Round  29, Global train loss: 0.037, Global test loss: 2.098, Global test accuracy: 25.50 

Round  30, Train loss: 0.029, Test loss: 1.535, Test accuracy: 71.50 

Round  30, Global train loss: 0.029, Global test loss: 2.390, Global test accuracy: 24.90 

Round  31, Train loss: 0.020, Test loss: 1.689, Test accuracy: 69.00 

Round  31, Global train loss: 0.020, Global test loss: 2.383, Global test accuracy: 26.00 

Round  32, Train loss: 0.023, Test loss: 1.638, Test accuracy: 70.10 

Round  32, Global train loss: 0.023, Global test loss: 2.272, Global test accuracy: 25.90 

Round  33, Train loss: 0.020, Test loss: 1.905, Test accuracy: 66.90 

Round  33, Global train loss: 0.020, Global test loss: 2.328, Global test accuracy: 24.10 

Round  34, Train loss: 0.041, Test loss: 1.787, Test accuracy: 68.80 

Round  34, Global train loss: 0.041, Global test loss: 2.352, Global test accuracy: 25.50 

Final Round, Train loss: 0.026, Test loss: 1.664, Test accuracy: 67.90 

Final Round, Global train loss: 0.026, Global test loss: 2.352, Global test accuracy: 25.50 

Average accuracy final 10 rounds: 69.32999999999998 

Average global accuracy final 10 rounds: 25.51 

473.6481201648712
[7.797065496444702, 13.382354974746704, 18.937071323394775, 24.626060009002686, 30.386578798294067, 35.99360466003418, 41.53687357902527, 46.97959852218628, 52.750688314437866, 58.47311210632324, 64.0888843536377, 69.61563658714294, 75.28481984138489, 80.90845274925232, 86.48679232597351, 92.12620711326599, 97.73134016990662, 103.64773464202881, 109.5154082775116, 115.00472378730774, 120.62316703796387, 126.3045756816864, 131.9424328804016, 137.7165277004242, 143.3835961818695, 149.12126302719116, 155.17004251480103, 160.7593650817871, 166.42008328437805, 172.12910676002502, 177.83770656585693, 183.4910707473755, 189.35152053833008, 195.14905071258545, 200.60780787467957, 212.02000546455383]
[54.4, 49.2, 57.9, 56.7, 59.6, 59.8, 60.8, 62.7, 61.1, 66.5, 64.8, 57.7, 67.7, 65.3, 63.8, 69.8, 66.3, 62.5, 62.8, 70.1, 68.7, 68.8, 66.0, 68.1, 61.9, 68.1, 70.0, 68.7, 70.8, 69.4, 71.5, 69.0, 70.1, 66.9, 68.8, 67.9]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.472, Test loss: 1.190, Test accuracy: 50.50 

Round   0, Global train loss: 1.472, Global test loss: 1.672, Global test accuracy: 24.80 

Round   1, Train loss: 1.275, Test loss: 1.104, Test accuracy: 52.40 

Round   1, Global train loss: 1.275, Global test loss: 1.451, Global test accuracy: 33.30 

Round   2, Train loss: 1.145, Test loss: 1.191, Test accuracy: 58.70 

Round   2, Global train loss: 1.145, Global test loss: 1.318, Global test accuracy: 44.70 

Round   3, Train loss: 1.059, Test loss: 1.212, Test accuracy: 59.10 

Round   3, Global train loss: 1.059, Global test loss: 1.284, Global test accuracy: 48.30 

Round   4, Train loss: 0.955, Test loss: 1.087, Test accuracy: 58.90 

Round   4, Global train loss: 0.955, Global test loss: 1.209, Global test accuracy: 48.60 

Round   5, Train loss: 0.868, Test loss: 1.120, Test accuracy: 60.70 

Round   5, Global train loss: 0.868, Global test loss: 1.134, Global test accuracy: 54.00 

Round   6, Train loss: 0.794, Test loss: 1.156, Test accuracy: 62.00 

Round   6, Global train loss: 0.794, Global test loss: 1.278, Global test accuracy: 52.60 

Round   7, Train loss: 0.727, Test loss: 1.128, Test accuracy: 63.80 

Round   7, Global train loss: 0.727, Global test loss: 1.222, Global test accuracy: 52.70 

Round   8, Train loss: 0.663, Test loss: 1.168, Test accuracy: 63.20 

Round   8, Global train loss: 0.663, Global test loss: 1.430, Global test accuracy: 51.50 

Round   9, Train loss: 0.572, Test loss: 1.265, Test accuracy: 62.00 

Round   9, Global train loss: 0.572, Global test loss: 1.279, Global test accuracy: 54.30 

Round  10, Train loss: 0.517, Test loss: 1.290, Test accuracy: 62.80 

Round  10, Global train loss: 0.517, Global test loss: 1.378, Global test accuracy: 54.30 

Round  11, Train loss: 0.458, Test loss: 1.340, Test accuracy: 63.70 

Round  11, Global train loss: 0.458, Global test loss: 1.456, Global test accuracy: 53.30 

Round  12, Train loss: 0.420, Test loss: 1.383, Test accuracy: 63.20 

Round  12, Global train loss: 0.420, Global test loss: 1.363, Global test accuracy: 55.20 

Round  13, Train loss: 0.397, Test loss: 1.412, Test accuracy: 64.90 

Round  13, Global train loss: 0.397, Global test loss: 1.525, Global test accuracy: 56.00 

Round  14, Train loss: 0.291, Test loss: 1.328, Test accuracy: 66.10 

Round  14, Global train loss: 0.291, Global test loss: 1.546, Global test accuracy: 56.70 

Round  15, Train loss: 0.283, Test loss: 1.466, Test accuracy: 64.70 

Round  15, Global train loss: 0.283, Global test loss: 1.562, Global test accuracy: 54.90 

Round  16, Train loss: 0.315, Test loss: 1.470, Test accuracy: 65.40 

Round  16, Global train loss: 0.315, Global test loss: 1.454, Global test accuracy: 59.20 

Round  17, Train loss: 0.232, Test loss: 1.604, Test accuracy: 64.70 

Round  17, Global train loss: 0.232, Global test loss: 1.818, Global test accuracy: 55.90 

Round  18, Train loss: 0.211, Test loss: 1.400, Test accuracy: 67.70 

Round  18, Global train loss: 0.211, Global test loss: 1.628, Global test accuracy: 57.00 

Round  19, Train loss: 0.192, Test loss: 1.668, Test accuracy: 65.60 

Round  19, Global train loss: 0.192, Global test loss: 1.946, Global test accuracy: 55.10 

Round  20, Train loss: 0.180, Test loss: 1.312, Test accuracy: 66.80 

Round  20, Global train loss: 0.180, Global test loss: 1.660, Global test accuracy: 56.60 

Round  21, Train loss: 0.143, Test loss: 2.179, Test accuracy: 59.90 

Round  21, Global train loss: 0.143, Global test loss: 2.030, Global test accuracy: 55.40 

Round  22, Train loss: 0.164, Test loss: 1.589, Test accuracy: 64.00 

Round  22, Global train loss: 0.164, Global test loss: 1.826, Global test accuracy: 53.90 

Round  23, Train loss: 0.115, Test loss: 1.572, Test accuracy: 65.90 

Round  23, Global train loss: 0.115, Global test loss: 1.845, Global test accuracy: 58.10 

Round  24, Train loss: 0.148, Test loss: 1.483, Test accuracy: 67.40 

Round  24, Global train loss: 0.148, Global test loss: 1.710, Global test accuracy: 57.30 

Round  25, Train loss: 0.119, Test loss: 1.537, Test accuracy: 68.10 

Round  25, Global train loss: 0.119, Global test loss: 1.796, Global test accuracy: 59.60 

Round  26, Train loss: 0.137, Test loss: 2.226, Test accuracy: 61.00 

Round  26, Global train loss: 0.137, Global test loss: 1.960, Global test accuracy: 55.10 

Round  27, Train loss: 0.119, Test loss: 1.802, Test accuracy: 64.70 

Round  27, Global train loss: 0.119, Global test loss: 1.926, Global test accuracy: 57.00 

Round  28, Train loss: 0.083, Test loss: 1.717, Test accuracy: 66.40 

Round  28, Global train loss: 0.083, Global test loss: 1.900, Global test accuracy: 59.40 

Round  29, Train loss: 0.065, Test loss: 1.577, Test accuracy: 68.30 

Round  29, Global train loss: 0.065, Global test loss: 2.025, Global test accuracy: 57.00 

Round  30, Train loss: 0.064, Test loss: 1.618, Test accuracy: 67.60 

Round  30, Global train loss: 0.064, Global test loss: 2.081, Global test accuracy: 56.20 

Round  31, Train loss: 0.075, Test loss: 1.668, Test accuracy: 68.50 

Round  31, Global train loss: 0.075, Global test loss: 1.989, Global test accuracy: 57.90 

Round  32, Train loss: 0.027, Test loss: 1.637, Test accuracy: 67.80 

Round  32, Global train loss: 0.027, Global test loss: 2.028, Global test accuracy: 58.70 

Round  33, Train loss: 0.067, Test loss: 1.650, Test accuracy: 68.30 

Round  33, Global train loss: 0.067, Global test loss: 1.944, Global test accuracy: 58.10 

Round  34, Train loss: 0.073, Test loss: 1.801, Test accuracy: 68.20 

Round  34, Global train loss: 0.073, Global test loss: 2.055, Global test accuracy: 57.70 

Final Round, Train loss: 0.040, Test loss: 1.858, Test accuracy: 65.20 

Final Round, Global train loss: 0.040, Global test loss: 2.055, Global test accuracy: 57.70 

Average accuracy final 10 rounds: 66.89 

Average global accuracy final 10 rounds: 57.67 

467.5449860095978
[7.494718551635742, 13.266437768936157, 19.191433906555176, 24.750053882598877, 30.108649253845215, 35.76370906829834, 41.25431227684021, 46.93984842300415, 52.42542314529419, 58.53781294822693, 64.00842261314392, 69.80630993843079, 75.2946515083313, 80.96302843093872, 86.58305501937866, 92.01477003097534, 98.05027222633362, 104.02334856987, 109.61419248580933, 115.18940305709839, 121.0280237197876, 126.58894801139832, 131.9277777671814, 137.55549359321594, 143.23871183395386, 148.7383439540863, 154.30498623847961, 159.98917818069458, 165.60059881210327, 171.16201615333557, 177.0895893573761, 182.58691430091858, 187.96474719047546, 193.63541960716248, 199.11807990074158, 210.1596314907074]
[50.5, 52.4, 58.7, 59.1, 58.9, 60.7, 62.0, 63.8, 63.2, 62.0, 62.8, 63.7, 63.2, 64.9, 66.1, 64.7, 65.4, 64.7, 67.7, 65.6, 66.8, 59.9, 64.0, 65.9, 67.4, 68.1, 61.0, 64.7, 66.4, 68.3, 67.6, 68.5, 67.8, 68.3, 68.2, 65.2]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 40, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.533, Test loss: 1.804, Test accuracy: 27.70 

Round   1, Train loss: 1.332, Test loss: 1.378, Test accuracy: 40.80 

Round   2, Train loss: 1.245, Test loss: 1.208, Test accuracy: 46.20 

Round   3, Train loss: 1.128, Test loss: 1.151, Test accuracy: 47.00 

Round   4, Train loss: 1.060, Test loss: 1.060, Test accuracy: 57.10 

Round   5, Train loss: 0.989, Test loss: 1.030, Test accuracy: 57.30 

Round   6, Train loss: 0.899, Test loss: 0.989, Test accuracy: 59.00 

Round   7, Train loss: 0.854, Test loss: 1.039, Test accuracy: 59.00 

Round   8, Train loss: 0.761, Test loss: 0.997, Test accuracy: 59.60 

Round   9, Train loss: 0.698, Test loss: 0.952, Test accuracy: 62.70 

Round  10, Train loss: 0.665, Test loss: 0.985, Test accuracy: 61.70 

Round  11, Train loss: 0.581, Test loss: 0.930, Test accuracy: 64.70 

Round  12, Train loss: 0.553, Test loss: 1.098, Test accuracy: 62.30 

Round  13, Train loss: 0.493, Test loss: 1.113, Test accuracy: 60.90 

Round  14, Train loss: 0.484, Test loss: 0.946, Test accuracy: 65.30 

Round  15, Train loss: 0.436, Test loss: 0.979, Test accuracy: 66.00 

Round  16, Train loss: 0.400, Test loss: 1.056, Test accuracy: 62.70 

Round  17, Train loss: 0.359, Test loss: 1.045, Test accuracy: 64.10 

Round  18, Train loss: 0.334, Test loss: 1.021, Test accuracy: 66.20 

Round  19, Train loss: 0.287, Test loss: 0.983, Test accuracy: 69.80 

Round  20, Train loss: 0.266, Test loss: 1.229, Test accuracy: 62.60 

Round  21, Train loss: 0.246, Test loss: 0.990, Test accuracy: 69.00 

Round  22, Train loss: 0.228, Test loss: 1.094, Test accuracy: 67.30 

Round  23, Train loss: 0.196, Test loss: 1.084, Test accuracy: 68.50 

Round  24, Train loss: 0.177, Test loss: 1.104, Test accuracy: 69.20 

Round  25, Train loss: 0.163, Test loss: 1.083, Test accuracy: 68.40 

Round  26, Train loss: 0.176, Test loss: 1.216, Test accuracy: 66.80 

Round  27, Train loss: 0.182, Test loss: 1.163, Test accuracy: 68.50 

Round  28, Train loss: 0.140, Test loss: 1.239, Test accuracy: 66.20 

Round  29, Train loss: 0.137, Test loss: 1.134, Test accuracy: 69.70 

Round  30, Train loss: 0.096, Test loss: 1.132, Test accuracy: 69.90 

Round  31, Train loss: 0.113, Test loss: 1.184, Test accuracy: 69.30 

Round  32, Train loss: 0.104, Test loss: 1.130, Test accuracy: 70.00 

Round  33, Train loss: 0.086, Test loss: 1.235, Test accuracy: 68.30 

Round  34, Train loss: 0.096, Test loss: 1.240, Test accuracy: 69.40 

Round  35, Train loss: 0.070, Test loss: 1.241, Test accuracy: 69.80 

Round  36, Train loss: 0.067, Test loss: 1.194, Test accuracy: 69.70 

Round  37, Train loss: 0.074, Test loss: 1.206, Test accuracy: 69.90 

Round  38, Train loss: 0.079, Test loss: 1.386, Test accuracy: 65.80 

Round  39, Train loss: 0.061, Test loss: 1.306, Test accuracy: 69.60 

Final Round, Train loss: 0.047, Test loss: 1.355, Test accuracy: 70.00 

Average accuracy final 10 rounds: 69.16999999999999 

390.5273599624634
[6.274481534957886, 10.597374439239502, 15.058646440505981, 19.436835289001465, 23.78431987762451, 28.043328046798706, 32.47050642967224, 36.89358353614807, 41.53092408180237, 46.06037473678589, 50.60814118385315, 54.96816325187683, 59.182512044906616, 63.723044633865356, 67.95906805992126, 72.35499811172485, 76.6159656047821, 81.11818766593933, 85.36120176315308, 89.68829298019409, 94.09368944168091, 98.42693877220154, 102.84222364425659, 107.13198852539062, 111.58849668502808, 116.03259515762329, 120.52710294723511, 124.90523910522461, 129.2534053325653, 133.60173416137695, 137.9017777442932, 142.44148445129395, 146.94452023506165, 151.56556630134583, 155.9952850341797, 160.63381385803223, 165.00772833824158, 169.23303318023682, 173.64954113960266, 178.01153016090393, 182.90225315093994]
[27.7, 40.8, 46.2, 47.0, 57.1, 57.3, 59.0, 59.0, 59.6, 62.7, 61.7, 64.7, 62.3, 60.9, 65.3, 66.0, 62.7, 64.1, 66.2, 69.8, 62.6, 69.0, 67.3, 68.5, 69.2, 68.4, 66.8, 68.5, 66.2, 69.7, 69.9, 69.3, 70.0, 68.3, 69.4, 69.8, 69.7, 69.9, 65.8, 69.6, 70.0]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 40, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
Round   0, Train loss: 1.534, Test loss: 1.731, Test accuracy: 25.40
Round   1, Train loss: 1.370, Test loss: 1.416, Test accuracy: 39.20
Round   2, Train loss: 1.231, Test loss: 1.216, Test accuracy: 47.30
Round   3, Train loss: 1.119, Test loss: 1.133, Test accuracy: 54.00
Round   4, Train loss: 1.035, Test loss: 1.036, Test accuracy: 57.30
Round   5, Train loss: 0.957, Test loss: 1.197, Test accuracy: 51.90
Round   6, Train loss: 0.897, Test loss: 1.037, Test accuracy: 60.50
Round   7, Train loss: 0.823, Test loss: 0.882, Test accuracy: 63.80
Round   8, Train loss: 0.754, Test loss: 0.966, Test accuracy: 62.00
Round   9, Train loss: 0.707, Test loss: 0.984, Test accuracy: 63.20
Round  10, Train loss: 0.650, Test loss: 0.910, Test accuracy: 65.50
Round  11, Train loss: 0.592, Test loss: 0.894, Test accuracy: 65.60
Round  12, Train loss: 0.542, Test loss: 0.853, Test accuracy: 66.60
Round  13, Train loss: 0.497, Test loss: 0.931, Test accuracy: 65.40
Round  14, Train loss: 0.462, Test loss: 0.958, Test accuracy: 64.00
Round  15, Train loss: 0.416, Test loss: 0.946, Test accuracy: 66.50
Round  16, Train loss: 0.402, Test loss: 0.951, Test accuracy: 65.40
Round  17, Train loss: 0.349, Test loss: 0.946, Test accuracy: 68.70
Round  18, Train loss: 0.333, Test loss: 0.943, Test accuracy: 68.70
Round  19, Train loss: 0.298, Test loss: 0.972, Test accuracy: 68.20
Round  20, Train loss: 0.266, Test loss: 0.975, Test accuracy: 68.30
Round  21, Train loss: 0.257, Test loss: 1.088, Test accuracy: 66.10
Round  22, Train loss: 0.244, Test loss: 0.982, Test accuracy: 68.40
Round  23, Train loss: 0.188, Test loss: 1.083, Test accuracy: 66.60
Round  24, Train loss: 0.189, Test loss: 1.050, Test accuracy: 67.90
Round  25, Train loss: 0.158, Test loss: 1.004, Test accuracy: 69.40
Round  26, Train loss: 0.168, Test loss: 1.059, Test accuracy: 69.00
Round  27, Train loss: 0.124, Test loss: 1.066, Test accuracy: 69.90
Round  28, Train loss: 0.145, Test loss: 1.078, Test accuracy: 68.00
Round  29, Train loss: 0.134, Test loss: 1.119, Test accuracy: 67.80
Round  30, Train loss: 0.108, Test loss: 1.111, Test accuracy: 68.60
Round  31, Train loss: 0.102, Test loss: 1.171, Test accuracy: 67.60
Round  32, Train loss: 0.097, Test loss: 1.145, Test accuracy: 67.50
Round  33, Train loss: 0.093, Test loss: 1.087, Test accuracy: 70.10
Round  34, Train loss: 0.098, Test loss: 1.125, Test accuracy: 68.70
Round  35, Train loss: 0.075, Test loss: 1.218, Test accuracy: 68.90
Round  36, Train loss: 0.059, Test loss: 1.249, Test accuracy: 68.50
Round  37, Train loss: 0.064, Test loss: 1.221, Test accuracy: 68.60
Round  38, Train loss: 0.074, Test loss: 1.200, Test accuracy: 68.40
Round  39, Train loss: 0.064, Test loss: 1.244, Test accuracy: 68.30
Final Round, Train loss: 0.045, Test loss: 1.252, Test accuracy: 67.80
Average accuracy final 10 rounds: 68.52
438.70242619514465
[6.755494117736816, 11.854047298431396, 16.821781158447266, 21.834201335906982, 27.065402030944824, 32.56138324737549, 37.560263872146606, 42.55591940879822, 47.48626375198364, 52.68281364440918, 57.56851601600647, 62.464465618133545, 67.79145383834839, 72.98289108276367, 78.2817702293396, 83.30160808563232, 87.99487257003784, 93.21078991889954, 98.20128774642944, 103.20833969116211, 108.18433451652527, 113.29924011230469, 118.12342953681946, 122.98942613601685, 127.91868424415588, 133.01976537704468, 137.96188473701477, 142.74660515785217, 147.4720742702484, 152.4656388759613, 157.4722023010254, 162.41577076911926, 167.33072519302368, 172.3558852672577, 177.71021914482117, 182.95265555381775, 188.27838349342346, 193.3597068786621, 198.8747217655182, 204.06760168075562, 208.8485813140869]
[25.4, 39.2, 47.3, 54.0, 57.3, 51.9, 60.5, 63.8, 62.0, 63.2, 65.5, 65.6, 66.6, 65.4, 64.0, 66.5, 65.4, 68.7, 68.7, 68.2, 68.3, 66.1, 68.4, 66.6, 67.9, 69.4, 69.0, 69.9, 68.0, 67.8, 68.6, 67.6, 67.5, 70.1, 68.7, 68.9, 68.5, 68.6, 68.4, 68.3, 67.8]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

Traceback (most recent call last):
  File "main_fedrep_increment2.py", line 219, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[c], first=True,isNew=True, local_eps=20)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 788, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.440, Test loss: 1.388, Test accuracy: 49.30 

Round   0, Global train loss: 1.440, Global test loss: 1.545, Global test accuracy: 32.60 

Round   1, Train loss: 1.143, Test loss: 1.401, Test accuracy: 53.20 

Round   1, Global train loss: 1.143, Global test loss: 1.629, Global test accuracy: 32.00 

Round   2, Train loss: 0.949, Test loss: 1.287, Test accuracy: 59.30 

Round   2, Global train loss: 0.949, Global test loss: 1.572, Global test accuracy: 30.40 

Round   3, Train loss: 0.839, Test loss: 1.165, Test accuracy: 61.40 

Round   3, Global train loss: 0.839, Global test loss: 1.514, Global test accuracy: 32.30 

Round   4, Train loss: 0.699, Test loss: 1.215, Test accuracy: 62.70 

Round   4, Global train loss: 0.699, Global test loss: 1.588, Global test accuracy: 27.40 

Round   5, Train loss: 0.599, Test loss: 1.256, Test accuracy: 60.30 

Round   5, Global train loss: 0.599, Global test loss: 1.487, Global test accuracy: 33.70 

Round   6, Train loss: 0.494, Test loss: 1.489, Test accuracy: 63.00 

Round   6, Global train loss: 0.494, Global test loss: 1.632, Global test accuracy: 30.00 

Round   7, Train loss: 0.439, Test loss: 1.347, Test accuracy: 64.90 

Round   7, Global train loss: 0.439, Global test loss: 1.530, Global test accuracy: 32.70 

Round   8, Train loss: 0.347, Test loss: 1.665, Test accuracy: 62.30 

Round   8, Global train loss: 0.347, Global test loss: 1.577, Global test accuracy: 25.30 

Round   9, Train loss: 0.309, Test loss: 1.550, Test accuracy: 63.90 

Round   9, Global train loss: 0.309, Global test loss: 1.599, Global test accuracy: 29.90 

Round  10, Train loss: 0.239, Test loss: 1.530, Test accuracy: 66.40 

Round  10, Global train loss: 0.239, Global test loss: 1.686, Global test accuracy: 23.40 

Round  11, Train loss: 0.234, Test loss: 1.812, Test accuracy: 62.70 

Round  11, Global train loss: 0.234, Global test loss: 1.557, Global test accuracy: 32.70 

Round  12, Train loss: 0.161, Test loss: 1.603, Test accuracy: 66.20 

Round  12, Global train loss: 0.161, Global test loss: 1.548, Global test accuracy: 31.80 

Round  13, Train loss: 0.156, Test loss: 1.766, Test accuracy: 63.70 

Round  13, Global train loss: 0.156, Global test loss: 1.637, Global test accuracy: 23.50 

Round  14, Train loss: 0.147, Test loss: 1.968, Test accuracy: 63.40 

Round  14, Global train loss: 0.147, Global test loss: 1.552, Global test accuracy: 27.90 

Round  15, Train loss: 0.123, Test loss: 1.786, Test accuracy: 67.10 

Round  15, Global train loss: 0.123, Global test loss: 1.767, Global test accuracy: 21.70 

Round  16, Train loss: 0.123, Test loss: 1.566, Test accuracy: 68.40 

Round  16, Global train loss: 0.123, Global test loss: 1.626, Global test accuracy: 28.70 

Round  17, Train loss: 0.119, Test loss: 1.610, Test accuracy: 67.80 

Round  17, Global train loss: 0.119, Global test loss: 1.741, Global test accuracy: 24.40 

Round  18, Train loss: 0.075, Test loss: 1.540, Test accuracy: 70.00 

Round  18, Global train loss: 0.075, Global test loss: 1.644, Global test accuracy: 24.90 

Round  19, Train loss: 0.092, Test loss: 1.679, Test accuracy: 68.20 

Round  19, Global train loss: 0.092, Global test loss: 1.535, Global test accuracy: 31.30 

Round  20, Train loss: 0.059, Test loss: 1.782, Test accuracy: 67.40 

Round  20, Global train loss: 0.059, Global test loss: 1.561, Global test accuracy: 27.10 

Round  21, Train loss: 0.077, Test loss: 1.559, Test accuracy: 69.00 

Round  21, Global train loss: 0.077, Global test loss: 1.669, Global test accuracy: 25.70 

Round  22, Train loss: 0.053, Test loss: 1.781, Test accuracy: 67.00 

Round  22, Global train loss: 0.053, Global test loss: 1.565, Global test accuracy: 30.30 

Round  23, Train loss: 0.035, Test loss: 1.717, Test accuracy: 68.60 

Round  23, Global train loss: 0.035, Global test loss: 1.612, Global test accuracy: 28.90 

Round  24, Train loss: 0.061, Test loss: 1.755, Test accuracy: 67.00 

Round  24, Global train loss: 0.061, Global test loss: 1.550, Global test accuracy: 33.20 

Round  25, Train loss: 0.049, Test loss: 1.595, Test accuracy: 70.10 

Round  25, Global train loss: 0.049, Global test loss: 1.518, Global test accuracy: 30.60 

Round  26, Train loss: 0.023, Test loss: 1.674, Test accuracy: 69.30 

Round  26, Global train loss: 0.023, Global test loss: 1.485, Global test accuracy: 35.10 

Round  27, Train loss: 0.036, Test loss: 1.913, Test accuracy: 68.50 

Round  27, Global train loss: 0.036, Global test loss: 1.552, Global test accuracy: 34.70 

Round  28, Train loss: 0.023, Test loss: 1.749, Test accuracy: 69.20 

Round  28, Global train loss: 0.023, Global test loss: 1.626, Global test accuracy: 29.90 

Round  29, Train loss: 0.030, Test loss: 1.914, Test accuracy: 67.40 

Round  29, Global train loss: 0.030, Global test loss: 1.676, Global test accuracy: 25.50 

Round  30, Train loss: 0.029, Test loss: 1.741, Test accuracy: 69.10 

Round  30, Global train loss: 0.029, Global test loss: 1.566, Global test accuracy: 31.40 

Round  31, Train loss: 0.033, Test loss: 1.807, Test accuracy: 67.30 

Round  31, Global train loss: 0.033, Global test loss: 1.615, Global test accuracy: 30.50 

Round  32, Train loss: 0.026, Test loss: 1.765, Test accuracy: 68.30 

Round  32, Global train loss: 0.026, Global test loss: 1.579, Global test accuracy: 30.40 

Round  33, Train loss: 0.026, Test loss: 1.878, Test accuracy: 68.80 

Round  33, Global train loss: 0.026, Global test loss: 1.627, Global test accuracy: 29.00 

Round  34, Train loss: 0.030, Test loss: 1.920, Test accuracy: 67.40 

Round  34, Global train loss: 0.030, Global test loss: 1.783, Global test accuracy: 26.60 

Final Round, Train loss: 0.019, Test loss: 2.064, Test accuracy: 68.20 

Final Round, Global train loss: 0.019, Global test loss: 1.783, Global test accuracy: 26.60 

Average accuracy final 10 rounds: 68.53999999999999 

Average global accuracy final 10 rounds: 30.37 

470.8482563495636
[7.58193302154541, 13.223634958267212, 18.839152812957764, 24.236088275909424, 29.767098903656006, 35.42893362045288, 41.07764673233032, 46.553855419158936, 52.102198362350464, 57.75032901763916, 63.66082286834717, 69.29572939872742, 74.84777045249939, 80.41093897819519, 86.1103286743164, 91.72037982940674, 97.31783056259155, 103.08592486381531, 108.67830967903137, 114.26318168640137, 119.80067539215088, 125.3397262096405, 131.14017295837402, 136.67278409004211, 142.24504232406616, 147.76457166671753, 153.40949892997742, 158.956374168396, 164.5577585697174, 170.39048957824707, 176.214049577713, 182.1600480079651, 187.92786598205566, 193.6433870792389, 199.46634674072266, 210.43735671043396]
[49.3, 53.2, 59.3, 61.4, 62.7, 60.3, 63.0, 64.9, 62.3, 63.9, 66.4, 62.7, 66.2, 63.7, 63.4, 67.1, 68.4, 67.8, 70.0, 68.2, 67.4, 69.0, 67.0, 68.6, 67.0, 70.1, 69.3, 68.5, 69.2, 67.4, 69.1, 67.3, 68.3, 68.8, 67.4, 68.2]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 35, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
[]
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.441, Test loss: 1.323, Test accuracy: 45.90 

Round   0, Global train loss: 1.441, Global test loss: 1.739, Global test accuracy: 24.00 

Round   1, Train loss: 1.242, Test loss: 1.202, Test accuracy: 56.30 

Round   1, Global train loss: 1.242, Global test loss: 1.485, Global test accuracy: 37.00 

Round   2, Train loss: 1.109, Test loss: 1.267, Test accuracy: 54.70 

Round   2, Global train loss: 1.109, Global test loss: 1.371, Global test accuracy: 44.50 

Round   3, Train loss: 0.952, Test loss: 1.159, Test accuracy: 60.50 

Round   3, Global train loss: 0.952, Global test loss: 1.429, Global test accuracy: 42.70 

Round   4, Train loss: 0.840, Test loss: 1.307, Test accuracy: 60.70 

Round   4, Global train loss: 0.840, Global test loss: 1.584, Global test accuracy: 41.10 

Round   5, Train loss: 0.757, Test loss: 1.115, Test accuracy: 62.70 

Round   5, Global train loss: 0.757, Global test loss: 1.424, Global test accuracy: 46.10 

Round   6, Train loss: 0.686, Test loss: 1.107, Test accuracy: 63.80 

Round   6, Global train loss: 0.686, Global test loss: 1.451, Global test accuracy: 46.90 

Round   7, Train loss: 0.623, Test loss: 1.321, Test accuracy: 58.80 

Round   7, Global train loss: 0.623, Global test loss: 1.664, Global test accuracy: 45.30 

Round   8, Train loss: 0.520, Test loss: 1.107, Test accuracy: 65.40 

Round   8, Global train loss: 0.520, Global test loss: 1.564, Global test accuracy: 48.00 

Round   9, Train loss: 0.473, Test loss: 1.535, Test accuracy: 62.30 

Round   9, Global train loss: 0.473, Global test loss: 1.881, Global test accuracy: 46.60 

Round  10, Train loss: 0.438, Test loss: 1.519, Test accuracy: 62.60 

Round  10, Global train loss: 0.438, Global test loss: 1.861, Global test accuracy: 49.90 

Round  11, Train loss: 0.385, Test loss: 1.374, Test accuracy: 65.70 

Round  11, Global train loss: 0.385, Global test loss: 1.907, Global test accuracy: 47.50 

Round  12, Train loss: 0.356, Test loss: 1.411, Test accuracy: 65.30 

Round  12, Global train loss: 0.356, Global test loss: 1.781, Global test accuracy: 50.20 

Round  13, Train loss: 0.312, Test loss: 2.124, Test accuracy: 56.90 

Round  13, Global train loss: 0.312, Global test loss: 1.929, Global test accuracy: 50.50 

Round  14, Train loss: 0.276, Test loss: 1.312, Test accuracy: 68.80 

Round  14, Global train loss: 0.276, Global test loss: 1.787, Global test accuracy: 50.70 

Round  15, Train loss: 0.242, Test loss: 1.705, Test accuracy: 63.20 

Round  15, Global train loss: 0.242, Global test loss: 1.875, Global test accuracy: 49.40 

Round  16, Train loss: 0.240, Test loss: 2.101, Test accuracy: 57.90 

Round  16, Global train loss: 0.240, Global test loss: 2.184, Global test accuracy: 47.00 

Round  17, Train loss: 0.182, Test loss: 1.477, Test accuracy: 64.90 

Round  17, Global train loss: 0.182, Global test loss: 1.998, Global test accuracy: 49.50 

Round  18, Train loss: 0.195, Test loss: 1.540, Test accuracy: 66.70 

Round  18, Global train loss: 0.195, Global test loss: 1.943, Global test accuracy: 49.40 

Round  19, Train loss: 0.172, Test loss: 1.616, Test accuracy: 64.60 

Round  19, Global train loss: 0.172, Global test loss: 1.941, Global test accuracy: 51.30 

Round  20, Train loss: 0.127, Test loss: 1.960, Test accuracy: 64.20 

Round  20, Global train loss: 0.127, Global test loss: 2.344, Global test accuracy: 49.10 

Round  21, Train loss: 0.141, Test loss: 1.577, Test accuracy: 65.10 

Round  21, Global train loss: 0.141, Global test loss: 2.176, Global test accuracy: 49.30 

Round  22, Train loss: 0.106, Test loss: 1.604, Test accuracy: 67.40 

Round  22, Global train loss: 0.106, Global test loss: 2.353, Global test accuracy: 50.00 

Round  23, Train loss: 0.098, Test loss: 1.420, Test accuracy: 70.20 

Round  23, Global train loss: 0.098, Global test loss: 2.072, Global test accuracy: 53.50 

Round  24, Train loss: 0.121, Test loss: 1.728, Test accuracy: 67.10 

Round  24, Global train loss: 0.121, Global test loss: 2.111, Global test accuracy: 52.60 

Round  25, Train loss: 0.096, Test loss: 1.321, Test accuracy: 71.80 

Round  25, Global train loss: 0.096, Global test loss: 2.021, Global test accuracy: 53.90 

Round  26, Train loss: 0.102, Test loss: 1.748, Test accuracy: 63.90 

Round  26, Global train loss: 0.102, Global test loss: 2.152, Global test accuracy: 51.50 

Round  27, Train loss: 0.085, Test loss: 1.682, Test accuracy: 68.50 

Round  27, Global train loss: 0.085, Global test loss: 2.193, Global test accuracy: 52.60 

Round  28, Train loss: 0.091, Test loss: 1.495, Test accuracy: 70.10 

Round  28, Global train loss: 0.091, Global test loss: 2.154, Global test accuracy: 54.50 

Round  29, Train loss: 0.074, Test loss: 1.496, Test accuracy: 70.70 

Round  29, Global train loss: 0.074, Global test loss: 2.274, Global test accuracy: 52.10 

Round  30, Train loss: 0.088, Test loss: 1.805, Test accuracy: 67.20 

Round  30, Global train loss: 0.088, Global test loss: 2.312, Global test accuracy: 51.90 

Round  31, Train loss: 0.061, Test loss: 1.707, Test accuracy: 69.10 

Round  31, Global train loss: 0.061, Global test loss: 2.337, Global test accuracy: 51.30 

Round  32, Train loss: 0.058, Test loss: 1.672, Test accuracy: 68.90 

Round  32, Global train loss: 0.058, Global test loss: 2.472, Global test accuracy: 53.60 

Round  33, Train loss: 0.062, Test loss: 1.614, Test accuracy: 71.70 

Round  33, Global train loss: 0.062, Global test loss: 2.239, Global test accuracy: 53.20 

Round  34, Train loss: 0.063, Test loss: 1.627, Test accuracy: 69.00 

Round  34, Global train loss: 0.063, Global test loss: 2.300, Global test accuracy: 53.90 

Final Round, Train loss: 0.055, Test loss: 1.631, Test accuracy: 69.90 

Final Round, Global train loss: 0.055, Global test loss: 2.300, Global test accuracy: 53.90 

Average accuracy final 10 rounds: 69.09 

Average global accuracy final 10 rounds: 52.85 

468.7255971431732
[7.630236864089966, 13.301707744598389, 19.137086391448975, 24.856403827667236, 30.459288597106934, 35.88630986213684, 41.51653265953064, 47.309176206588745, 52.798476457595825, 58.29139995574951, 63.8409686088562, 69.3480429649353, 75.05816912651062, 80.91369652748108, 86.59074783325195, 92.18339037895203, 97.95053744316101, 103.76966857910156, 109.60363245010376, 115.12109160423279, 120.45148730278015, 126.28863453865051, 132.11076545715332, 137.78424525260925, 143.6484019756317, 149.30262756347656, 155.20212054252625, 160.7576916217804, 166.2453236579895, 171.86924505233765, 177.49060797691345, 183.04712009429932, 188.6403136253357, 194.3877158164978, 199.83580493927002, 210.8867154121399]
[45.9, 56.3, 54.7, 60.5, 60.7, 62.7, 63.8, 58.8, 65.4, 62.3, 62.6, 65.7, 65.3, 56.9, 68.8, 63.2, 57.9, 64.9, 66.7, 64.6, 64.2, 65.1, 67.4, 70.2, 67.1, 71.8, 63.9, 68.5, 70.1, 70.7, 67.2, 69.1, 68.9, 71.7, 69.0, 69.9]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 40, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.498, Test loss: 1.437, Test accuracy: 34.20 

Round   1, Train loss: 1.312, Test loss: 1.398, Test accuracy: 41.60 

Round   2, Train loss: 1.155, Test loss: 1.092, Test accuracy: 56.50 

Round   3, Train loss: 1.037, Test loss: 1.023, Test accuracy: 58.80 

Round   4, Train loss: 0.936, Test loss: 0.890, Test accuracy: 64.50 

Round   5, Train loss: 0.866, Test loss: 0.961, Test accuracy: 62.80 

Round   6, Train loss: 0.793, Test loss: 0.950, Test accuracy: 66.10 

Round   7, Train loss: 0.726, Test loss: 0.822, Test accuracy: 68.50 

Round   8, Train loss: 0.668, Test loss: 0.922, Test accuracy: 64.60 

Round   9, Train loss: 0.616, Test loss: 0.881, Test accuracy: 66.30 

Round  10, Train loss: 0.535, Test loss: 0.880, Test accuracy: 68.20 

Round  11, Train loss: 0.495, Test loss: 0.904, Test accuracy: 67.60 

Round  12, Train loss: 0.453, Test loss: 0.897, Test accuracy: 68.80 

Round  13, Train loss: 0.405, Test loss: 0.815, Test accuracy: 71.40 

Round  14, Train loss: 0.379, Test loss: 0.869, Test accuracy: 70.50 

Round  15, Train loss: 0.332, Test loss: 0.906, Test accuracy: 71.30 

Round  16, Train loss: 0.305, Test loss: 0.848, Test accuracy: 73.40 

Round  17, Train loss: 0.268, Test loss: 1.013, Test accuracy: 70.00 

Round  18, Train loss: 0.261, Test loss: 0.906, Test accuracy: 71.90 

Round  19, Train loss: 0.236, Test loss: 0.864, Test accuracy: 74.30 

Round  20, Train loss: 0.207, Test loss: 0.921, Test accuracy: 73.30 

Round  21, Train loss: 0.170, Test loss: 1.046, Test accuracy: 72.00 

Round  22, Train loss: 0.187, Test loss: 0.949, Test accuracy: 72.10 

Round  23, Train loss: 0.162, Test loss: 0.932, Test accuracy: 73.40 

Round  24, Train loss: 0.140, Test loss: 1.043, Test accuracy: 71.00 

Round  25, Train loss: 0.122, Test loss: 1.002, Test accuracy: 72.40 

Round  26, Train loss: 0.120, Test loss: 1.004, Test accuracy: 72.40 

Round  27, Train loss: 0.127, Test loss: 0.935, Test accuracy: 73.10 

Round  28, Train loss: 0.107, Test loss: 0.969, Test accuracy: 73.80 

Round  29, Train loss: 0.080, Test loss: 0.974, Test accuracy: 73.30 

Round  30, Train loss: 0.099, Test loss: 1.051, Test accuracy: 74.30 

Round  31, Train loss: 0.096, Test loss: 0.993, Test accuracy: 73.00 

Round  32, Train loss: 0.071, Test loss: 1.053, Test accuracy: 72.40 

Round  33, Train loss: 0.071, Test loss: 0.989, Test accuracy: 73.90 

Round  34, Train loss: 0.057, Test loss: 1.064, Test accuracy: 73.40 

Round  35, Train loss: 0.050, Test loss: 1.043, Test accuracy: 75.30 

Round  36, Train loss: 0.093, Test loss: 1.060, Test accuracy: 74.50 

Round  37, Train loss: 0.058, Test loss: 1.072, Test accuracy: 73.10 

Round  38, Train loss: 0.052, Test loss: 1.139, Test accuracy: 72.80 

Round  39, Train loss: 0.059, Test loss: 1.158, Test accuracy: 73.70 

Final Round, Train loss: 0.042, Test loss: 1.141, Test accuracy: 74.90 

Average accuracy final 10 rounds: 73.64000000000001 

386.56797194480896
[6.477412700653076, 10.956749200820923, 15.310382843017578, 19.652108192443848, 23.98387050628662, 28.495621919631958, 33.0537371635437, 37.48507833480835, 41.853254556655884, 46.191364765167236, 50.341344118118286, 54.86371111869812, 58.956981897354126, 63.22977161407471, 67.84266710281372, 72.39745116233826, 76.84611010551453, 81.09816765785217, 85.58317852020264, 90.01097846031189, 94.48687815666199, 98.84674167633057, 103.2633855342865, 107.60174989700317, 111.89782071113586, 116.25175595283508, 120.457111120224, 124.66863107681274, 128.91663932800293, 133.33184957504272, 137.79658699035645, 142.27626490592957, 146.734858751297, 151.1519603729248, 155.4308819770813, 159.745032787323, 164.16739106178284, 168.4084484577179, 172.73898220062256, 176.98812246322632, 181.68088293075562]
[34.2, 41.6, 56.5, 58.8, 64.5, 62.8, 66.1, 68.5, 64.6, 66.3, 68.2, 67.6, 68.8, 71.4, 70.5, 71.3, 73.4, 70.0, 71.9, 74.3, 73.3, 72.0, 72.1, 73.4, 71.0, 72.4, 72.4, 73.1, 73.8, 73.3, 74.3, 73.0, 72.4, 73.9, 73.4, 75.3, 74.5, 73.1, 72.8, 73.7, 74.9]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 40, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017)
learning rate, batch size: 0.01, 10
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
Round   0, Train loss: 1.512, Test loss: 1.678, Test accuracy: 27.50
Round   1, Train loss: 1.310, Test loss: 1.333, Test accuracy: 42.30
Round   2, Train loss: 1.162, Test loss: 1.220, Test accuracy: 48.00
Round   3, Train loss: 1.070, Test loss: 1.233, Test accuracy: 51.20
Round   4, Train loss: 0.950, Test loss: 0.988, Test accuracy: 60.30
Round   5, Train loss: 0.887, Test loss: 0.999, Test accuracy: 60.60
Round   6, Train loss: 0.836, Test loss: 0.937, Test accuracy: 63.90
Round   7, Train loss: 0.758, Test loss: 1.158, Test accuracy: 57.60
Round   8, Train loss: 0.682, Test loss: 0.939, Test accuracy: 64.30
Round   9, Train loss: 0.631, Test loss: 0.876, Test accuracy: 67.40
Round  10, Train loss: 0.565, Test loss: 0.912, Test accuracy: 67.40
Round  11, Train loss: 0.522, Test loss: 0.920, Test accuracy: 67.50
Round  12, Train loss: 0.482, Test loss: 0.911, Test accuracy: 66.10
Round  13, Train loss: 0.438, Test loss: 0.808, Test accuracy: 71.20
Round  14, Train loss: 0.380, Test loss: 0.890, Test accuracy: 70.50
Round  15, Train loss: 0.362, Test loss: 0.850, Test accuracy: 70.90
Round  16, Train loss: 0.313, Test loss: 0.884, Test accuracy: 70.80
Round  17, Train loss: 0.302, Test loss: 0.865, Test accuracy: 71.10
Round  18, Train loss: 0.262, Test loss: 0.825, Test accuracy: 72.50
Round  19, Train loss: 0.257, Test loss: 0.865, Test accuracy: 73.30
Round  20, Train loss: 0.212, Test loss: 0.872, Test accuracy: 72.90
Round  21, Train loss: 0.208, Test loss: 0.941, Test accuracy: 71.50
Round  22, Train loss: 0.163, Test loss: 0.979, Test accuracy: 72.60
Round  23, Train loss: 0.165, Test loss: 0.907, Test accuracy: 72.10
Round  24, Train loss: 0.151, Test loss: 0.990, Test accuracy: 71.90
Round  25, Train loss: 0.155, Test loss: 0.960, Test accuracy: 74.60
Round  26, Train loss: 0.140, Test loss: 1.066, Test accuracy: 71.40
Round  27, Train loss: 0.120, Test loss: 1.008, Test accuracy: 73.00
Round  28, Train loss: 0.113, Test loss: 0.980, Test accuracy: 72.00
Round  29, Train loss: 0.093, Test loss: 0.956, Test accuracy: 74.80
Round  30, Train loss: 0.076, Test loss: 0.995, Test accuracy: 73.60
Round  31, Train loss: 0.093, Test loss: 0.998, Test accuracy: 74.10
Round  32, Train loss: 0.091, Test loss: 1.028, Test accuracy: 72.10
Round  33, Train loss: 0.084, Test loss: 0.980, Test accuracy: 74.20
Round  34, Train loss: 0.069, Test loss: 1.012, Test accuracy: 74.20
Round  35, Train loss: 0.053, Test loss: 1.042, Test accuracy: 74.40
Round  36, Train loss: 0.050, Test loss: 1.020, Test accuracy: 73.90
Round  37, Train loss: 0.073, Test loss: 1.063, Test accuracy: 72.70
Round  38, Train loss: 0.061, Test loss: 0.998, Test accuracy: 75.10
Round  39, Train loss: 0.055, Test loss: 1.083, Test accuracy: 73.20
Final Round, Train loss: 0.040, Test loss: 1.161, Test accuracy: 71.80
Average accuracy final 10 rounds: 73.75
436.7010679244995
[7.0118327140808105, 11.971465826034546, 16.991355895996094, 21.940545558929443, 27.132427215576172, 31.95492959022522, 36.740236043930054, 41.82921314239502, 46.62325739860535, 51.336432218551636, 56.62174701690674, 61.769320249557495, 66.55665254592896, 71.32110548019409, 76.31367206573486, 81.41695499420166, 86.69712042808533, 92.23840761184692, 97.4158570766449, 102.55379366874695, 107.94909024238586, 112.84303665161133, 117.79746627807617, 122.72225642204285, 127.94385385513306, 132.94468784332275, 138.00242280960083, 143.06699466705322, 147.96202087402344, 152.9984610080719, 157.98440051078796, 163.03013134002686, 167.8630702495575, 172.715815782547, 178.00337505340576, 182.9288010597229, 187.72297644615173, 192.78732085227966, 197.98469519615173, 203.0019142627716, 207.91135239601135]
[27.5, 42.3, 48.0, 51.2, 60.3, 60.6, 63.9, 57.6, 64.3, 67.4, 67.4, 67.5, 66.1, 71.2, 70.5, 70.9, 70.8, 71.1, 72.5, 73.3, 72.9, 71.5, 72.6, 72.1, 71.9, 74.6, 71.4, 73.0, 72.0, 74.8, 73.6, 74.1, 72.1, 74.2, 74.2, 74.4, 73.9, 72.7, 75.1, 73.2, 71.8]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedIncrement%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 20, shard_per_user: 5, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (linear): Linear(in_features=512, out_features=5, bias=True)
)
odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias'])
122
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked']
['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.0.shortcut.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'linear.weight', 'linear.bias']
# Params: 11181017 (local), 11178452 (global); Percentage 99.98 (11178452/11181017 
)
learning rate, batch size: 0.01, 10 

---------------------------------------------train_client: [0] 

Traceback (most recent call last):
  File "main_fedrep_increment2.py", line 219, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[c], first=True,isNew=True, local_eps=20)
  File "/data/jij/csm/code/FL_HLS/models/Update.py", line 788, in train
    loss.backward()
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/data/jij/install/anaconda/envs/gflownets/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
