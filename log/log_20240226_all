nohup: ignoring input
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.227, Test loss: 2.082, Test accuracy: 25.67 

Round   0, Global train loss: 2.227, Global test loss: 2.083, Global test accuracy: 26.66 

Round   1, Train loss: 2.010, Test loss: 1.965, Test accuracy: 29.06 

Round   1, Global train loss: 2.010, Global test loss: 1.923, Global test accuracy: 31.22 

Round   2, Train loss: 1.890, Test loss: 1.878, Test accuracy: 31.46 

Round   2, Global train loss: 1.890, Global test loss: 1.787, Global test accuracy: 35.40 

Round   3, Train loss: 1.850, Test loss: 1.838, Test accuracy: 32.56 

Round   3, Global train loss: 1.850, Global test loss: 1.733, Global test accuracy: 37.27 

Round   4, Train loss: 1.748, Test loss: 1.815, Test accuracy: 33.73 

Round   4, Global train loss: 1.748, Global test loss: 1.697, Global test accuracy: 38.77 

Round   5, Train loss: 1.779, Test loss: 1.798, Test accuracy: 34.55 

Round   5, Global train loss: 1.779, Global test loss: 1.724, Global test accuracy: 38.71 

Round   6, Train loss: 1.702, Test loss: 1.778, Test accuracy: 35.07 

Round   6, Global train loss: 1.702, Global test loss: 1.681, Global test accuracy: 38.89 

Round   7, Train loss: 1.602, Test loss: 1.771, Test accuracy: 35.41 

Round   7, Global train loss: 1.602, Global test loss: 1.600, Global test accuracy: 41.74 

Round   8, Train loss: 1.543, Test loss: 1.760, Test accuracy: 35.98 

Round   8, Global train loss: 1.543, Global test loss: 1.573, Global test accuracy: 42.58 

Round   9, Train loss: 1.531, Test loss: 1.743, Test accuracy: 36.46 

Round   9, Global train loss: 1.531, Global test loss: 1.571, Global test accuracy: 42.81 

Round  10, Train loss: 1.470, Test loss: 1.764, Test accuracy: 36.67 

Round  10, Global train loss: 1.470, Global test loss: 1.560, Global test accuracy: 41.79 

Round  11, Train loss: 1.506, Test loss: 1.747, Test accuracy: 37.48 

Round  11, Global train loss: 1.506, Global test loss: 1.586, Global test accuracy: 41.95 

Round  12, Train loss: 1.530, Test loss: 1.738, Test accuracy: 38.26 

Round  12, Global train loss: 1.530, Global test loss: 1.615, Global test accuracy: 42.35 

Round  13, Train loss: 1.517, Test loss: 1.726, Test accuracy: 39.02 

Round  13, Global train loss: 1.517, Global test loss: 1.546, Global test accuracy: 43.80 

Round  14, Train loss: 1.470, Test loss: 1.700, Test accuracy: 39.90 

Round  14, Global train loss: 1.470, Global test loss: 1.536, Global test accuracy: 43.80 

Round  15, Train loss: 1.365, Test loss: 1.719, Test accuracy: 39.65 

Round  15, Global train loss: 1.365, Global test loss: 1.527, Global test accuracy: 44.70 

Round  16, Train loss: 1.311, Test loss: 1.761, Test accuracy: 38.96 

Round  16, Global train loss: 1.311, Global test loss: 1.522, Global test accuracy: 43.90 

Round  17, Train loss: 1.273, Test loss: 1.780, Test accuracy: 38.94 

Round  17, Global train loss: 1.273, Global test loss: 1.487, Global test accuracy: 45.93 

Round  18, Train loss: 1.172, Test loss: 1.785, Test accuracy: 39.31 

Round  18, Global train loss: 1.172, Global test loss: 1.470, Global test accuracy: 46.25 

Round  19, Train loss: 1.220, Test loss: 1.763, Test accuracy: 40.36 

Round  19, Global train loss: 1.220, Global test loss: 1.470, Global test accuracy: 45.79 

Round  20, Train loss: 1.127, Test loss: 1.780, Test accuracy: 40.17 

Round  20, Global train loss: 1.127, Global test loss: 1.469, Global test accuracy: 46.36 

Round  21, Train loss: 1.005, Test loss: 1.816, Test accuracy: 40.29 

Round  21, Global train loss: 1.005, Global test loss: 1.479, Global test accuracy: 46.02 

Round  22, Train loss: 1.281, Test loss: 1.817, Test accuracy: 40.87 

Round  22, Global train loss: 1.281, Global test loss: 1.527, Global test accuracy: 45.15 

Round  23, Train loss: 1.038, Test loss: 1.824, Test accuracy: 40.91 

Round  23, Global train loss: 1.038, Global test loss: 1.457, Global test accuracy: 47.82 

Round  24, Train loss: 0.956, Test loss: 1.847, Test accuracy: 41.02 

Round  24, Global train loss: 0.956, Global test loss: 1.451, Global test accuracy: 48.19 

Round  25, Train loss: 1.015, Test loss: 1.892, Test accuracy: 40.86 

Round  25, Global train loss: 1.015, Global test loss: 1.502, Global test accuracy: 45.63 

Round  26, Train loss: 1.002, Test loss: 1.910, Test accuracy: 40.81 

Round  26, Global train loss: 1.002, Global test loss: 1.474, Global test accuracy: 46.68 

Round  27, Train loss: 1.091, Test loss: 1.931, Test accuracy: 40.96 

Round  27, Global train loss: 1.091, Global test loss: 1.502, Global test accuracy: 45.18 

Round  28, Train loss: 0.978, Test loss: 1.966, Test accuracy: 40.86 

Round  28, Global train loss: 0.978, Global test loss: 1.479, Global test accuracy: 46.12 

Round  29, Train loss: 0.979, Test loss: 1.991, Test accuracy: 40.87 

Round  29, Global train loss: 0.979, Global test loss: 1.443, Global test accuracy: 47.96 

Round  30, Train loss: 0.841, Test loss: 2.028, Test accuracy: 40.79 

Round  30, Global train loss: 0.841, Global test loss: 1.468, Global test accuracy: 47.35 

Round  31, Train loss: 1.005, Test loss: 2.067, Test accuracy: 40.47 

Round  31, Global train loss: 1.005, Global test loss: 1.476, Global test accuracy: 46.05 

Round  32, Train loss: 0.758, Test loss: 2.079, Test accuracy: 40.69 

Round  32, Global train loss: 0.758, Global test loss: 1.471, Global test accuracy: 48.34 

Round  33, Train loss: 0.829, Test loss: 2.128, Test accuracy: 40.55 

Round  33, Global train loss: 0.829, Global test loss: 1.461, Global test accuracy: 47.41 

Round  34, Train loss: 0.832, Test loss: 2.152, Test accuracy: 40.72 

Round  34, Global train loss: 0.832, Global test loss: 1.475, Global test accuracy: 46.63 

Round  35, Train loss: 0.795, Test loss: 2.215, Test accuracy: 40.62 

Round  35, Global train loss: 0.795, Global test loss: 1.486, Global test accuracy: 47.74 

Round  36, Train loss: 0.802, Test loss: 2.234, Test accuracy: 41.09 

Round  36, Global train loss: 0.802, Global test loss: 1.464, Global test accuracy: 49.02 

Round  37, Train loss: 0.807, Test loss: 2.271, Test accuracy: 41.21 

Round  37, Global train loss: 0.807, Global test loss: 1.462, Global test accuracy: 48.94 

Round  38, Train loss: 0.684, Test loss: 2.277, Test accuracy: 41.47 

Round  38, Global train loss: 0.684, Global test loss: 1.503, Global test accuracy: 46.90 

Round  39, Train loss: 0.742, Test loss: 2.325, Test accuracy: 41.27 

Round  39, Global train loss: 0.742, Global test loss: 1.475, Global test accuracy: 48.13 

Round  40, Train loss: 0.646, Test loss: 2.333, Test accuracy: 41.50 

Round  40, Global train loss: 0.646, Global test loss: 1.492, Global test accuracy: 49.16 

Round  41, Train loss: 0.601, Test loss: 2.407, Test accuracy: 41.26 

Round  41, Global train loss: 0.601, Global test loss: 1.495, Global test accuracy: 46.38 

Round  42, Train loss: 0.619, Test loss: 2.406, Test accuracy: 41.67 

Round  42, Global train loss: 0.619, Global test loss: 1.469, Global test accuracy: 49.20 

Round  43, Train loss: 0.666, Test loss: 2.432, Test accuracy: 41.84 

Round  43, Global train loss: 0.666, Global test loss: 1.455, Global test accuracy: 47.89 

Round  44, Train loss: 0.677, Test loss: 2.466, Test accuracy: 41.66 

Round  44, Global train loss: 0.677, Global test loss: 1.469, Global test accuracy: 46.63 

Round  45, Train loss: 0.672, Test loss: 2.476, Test accuracy: 41.89 

Round  45, Global train loss: 0.672, Global test loss: 1.501, Global test accuracy: 47.07 

Round  46, Train loss: 0.435, Test loss: 2.522, Test accuracy: 41.87 

Round  46, Global train loss: 0.435, Global test loss: 1.520, Global test accuracy: 47.39 

Round  47, Train loss: 0.514, Test loss: 2.607, Test accuracy: 41.45 

Round  47, Global train loss: 0.514, Global test loss: 1.559, Global test accuracy: 48.11 

Round  48, Train loss: 0.426, Test loss: 2.635, Test accuracy: 41.43 

Round  48, Global train loss: 0.426, Global test loss: 1.503, Global test accuracy: 47.74 

Round  49, Train loss: 0.483, Test loss: 2.688, Test accuracy: 41.39 

Round  49, Global train loss: 0.483, Global test loss: 1.512, Global test accuracy: 47.23 

Round  50, Train loss: 0.447, Test loss: 2.692, Test accuracy: 41.41 

Round  50, Global train loss: 0.447, Global test loss: 1.519, Global test accuracy: 48.84 

Round  51, Train loss: 0.507, Test loss: 2.695, Test accuracy: 41.58 

Round  51, Global train loss: 0.507, Global test loss: 1.492, Global test accuracy: 46.96 

Round  52, Train loss: 0.420, Test loss: 2.732, Test accuracy: 41.61 

Round  52, Global train loss: 0.420, Global test loss: 1.554, Global test accuracy: 46.77 

Round  53, Train loss: 0.428, Test loss: 2.774, Test accuracy: 41.37 

Round  53, Global train loss: 0.428, Global test loss: 1.497, Global test accuracy: 47.44 

Round  54, Train loss: 0.396, Test loss: 2.838, Test accuracy: 41.30 

Round  54, Global train loss: 0.396, Global test loss: 1.570, Global test accuracy: 48.10 

Round  55, Train loss: 0.522, Test loss: 2.863, Test accuracy: 41.38 

Round  55, Global train loss: 0.522, Global test loss: 1.480, Global test accuracy: 48.26 

Round  56, Train loss: 0.372, Test loss: 2.919, Test accuracy: 41.45 

Round  56, Global train loss: 0.372, Global test loss: 1.575, Global test accuracy: 48.04 

Round  57, Train loss: 0.413, Test loss: 2.929, Test accuracy: 41.48 

Round  57, Global train loss: 0.413, Global test loss: 1.590, Global test accuracy: 48.26 

Round  58, Train loss: 0.405, Test loss: 2.951, Test accuracy: 41.11 

Round  58, Global train loss: 0.405, Global test loss: 1.561, Global test accuracy: 47.60 

Round  59, Train loss: 0.344, Test loss: 2.987, Test accuracy: 41.30 

Round  59, Global train loss: 0.344, Global test loss: 1.561, Global test accuracy: 48.65 

Round  60, Train loss: 0.363, Test loss: 3.057, Test accuracy: 41.31 

Round  60, Global train loss: 0.363, Global test loss: 1.570, Global test accuracy: 47.75 

Round  61, Train loss: 0.336, Test loss: 3.079, Test accuracy: 41.13 

Round  61, Global train loss: 0.336, Global test loss: 1.591, Global test accuracy: 47.31 

Round  62, Train loss: 0.361, Test loss: 3.091, Test accuracy: 41.43 

Round  62, Global train loss: 0.361, Global test loss: 1.537, Global test accuracy: 48.99 

Round  63, Train loss: 0.353, Test loss: 3.131, Test accuracy: 41.40 

Round  63, Global train loss: 0.353, Global test loss: 1.537, Global test accuracy: 47.99 

Round  64, Train loss: 0.299, Test loss: 3.212, Test accuracy: 41.12 

Round  64, Global train loss: 0.299, Global test loss: 1.581, Global test accuracy: 48.04 

Round  65, Train loss: 0.285, Test loss: 3.236, Test accuracy: 41.42 

Round  65, Global train loss: 0.285, Global test loss: 1.588, Global test accuracy: 47.69 

Round  66, Train loss: 0.272, Test loss: 3.245, Test accuracy: 41.57 

Round  66, Global train loss: 0.272, Global test loss: 1.556, Global test accuracy: 46.81 

Round  67, Train loss: 0.335, Test loss: 3.331, Test accuracy: 41.45 

Round  67, Global train loss: 0.335, Global test loss: 1.531, Global test accuracy: 46.65 

Round  68, Train loss: 0.287, Test loss: 3.362, Test accuracy: 41.61 

Round  68, Global train loss: 0.287, Global test loss: 1.627, Global test accuracy: 48.89 

Round  69, Train loss: 0.300, Test loss: 3.417, Test accuracy: 41.67 

Round  69, Global train loss: 0.300, Global test loss: 1.617, Global test accuracy: 46.33 

Round  70, Train loss: 0.272, Test loss: 3.400, Test accuracy: 41.26 

Round  70, Global train loss: 0.272, Global test loss: 1.561, Global test accuracy: 48.78 

Round  71, Train loss: 0.283, Test loss: 3.324, Test accuracy: 41.63 

Round  71, Global train loss: 0.283, Global test loss: 1.602, Global test accuracy: 46.30 

Round  72, Train loss: 0.233, Test loss: 3.396, Test accuracy: 41.80 

Round  72, Global train loss: 0.233, Global test loss: 1.565, Global test accuracy: 46.20 

Round  73, Train loss: 0.286, Test loss: 3.475, Test accuracy: 41.65 

Round  73, Global train loss: 0.286, Global test loss: 1.541, Global test accuracy: 47.37 

Round  74, Train loss: 0.249, Test loss: 3.501, Test accuracy: 41.64 

Round  74, Global train loss: 0.249, Global test loss: 1.562, Global test accuracy: 48.09 

Round  75, Train loss: 0.286, Test loss: 3.481, Test accuracy: 41.92 

Round  75, Global train loss: 0.286, Global test loss: 1.579, Global test accuracy: 47.41 

Round  76, Train loss: 0.258, Test loss: 3.535, Test accuracy: 41.83 

Round  76, Global train loss: 0.258, Global test loss: 1.537, Global test accuracy: 46.61 

Round  77, Train loss: 0.242, Test loss: 3.634, Test accuracy: 41.64 

Round  77, Global train loss: 0.242, Global test loss: 1.575, Global test accuracy: 48.66 

Round  78, Train loss: 0.234, Test loss: 3.617, Test accuracy: 41.68 

Round  78, Global train loss: 0.234, Global test loss: 1.533, Global test accuracy: 47.05 

Round  79, Train loss: 0.250, Test loss: 3.625, Test accuracy: 41.69 

Round  79, Global train loss: 0.250, Global test loss: 1.555, Global test accuracy: 49.80 

Round  80, Train loss: 0.177, Test loss: 3.699, Test accuracy: 41.71 

Round  80, Global train loss: 0.177, Global test loss: 1.625, Global test accuracy: 45.63 

Round  81, Train loss: 0.221, Test loss: 3.661, Test accuracy: 41.81 

Round  81, Global train loss: 0.221, Global test loss: 1.539, Global test accuracy: 47.81 

Round  82, Train loss: 0.173, Test loss: 3.772, Test accuracy: 41.48 

Round  82, Global train loss: 0.173, Global test loss: 1.641, Global test accuracy: 47.77 

Round  83, Train loss: 0.194, Test loss: 3.783, Test accuracy: 41.51 

Round  83, Global train loss: 0.194, Global test loss: 1.574, Global test accuracy: 46.82 

Round  84, Train loss: 0.201, Test loss: 3.836, Test accuracy: 41.47 

Round  84, Global train loss: 0.201, Global test loss: 1.653, Global test accuracy: 46.96 

Round  85, Train loss: 0.222, Test loss: 3.820, Test accuracy: 41.30 

Round  85, Global train loss: 0.222, Global test loss: 1.573, Global test accuracy: 47.81 

Round  86, Train loss: 0.230, Test loss: 3.843, Test accuracy: 41.42 

Round  86, Global train loss: 0.230, Global test loss: 1.587, Global test accuracy: 48.02 

Round  87, Train loss: 0.152, Test loss: 3.874, Test accuracy: 41.62 

Round  87, Global train loss: 0.152, Global test loss: 1.551, Global test accuracy: 45.95 

Round  88, Train loss: 0.182, Test loss: 3.812, Test accuracy: 41.63 

Round  88, Global train loss: 0.182, Global test loss: 1.622, Global test accuracy: 48.55 

Round  89, Train loss: 0.167, Test loss: 3.815, Test accuracy: 42.10 

Round  89, Global train loss: 0.167, Global test loss: 1.688, Global test accuracy: 48.44 

Round  90, Train loss: 0.148, Test loss: 3.841, Test accuracy: 42.05 

Round  90, Global train loss: 0.148, Global test loss: 1.760, Global test accuracy: 45.91 

Round  91, Train loss: 0.223, Test loss: 3.878, Test accuracy: 42.15 

Round  91, Global train loss: 0.223, Global test loss: 1.722, Global test accuracy: 47.41 

Round  92, Train loss: 0.220, Test loss: 3.872, Test accuracy: 41.96 

Round  92, Global train loss: 0.220, Global test loss: 1.593, Global test accuracy: 48.70 

Round  93, Train loss: 0.156, Test loss: 3.822, Test accuracy: 42.30 

Round  93, Global train loss: 0.156, Global test loss: 1.621, Global test accuracy: 47.30 

Round  94, Train loss: 0.153, Test loss: 3.937, Test accuracy: 42.11 

Round  94, Global train loss: 0.153, Global test loss: 1.637, Global test accuracy: 48.25 

Round  95, Train loss: 0.192, Test loss: 3.979, Test accuracy: 41.75 

Round  95, Global train loss: 0.192, Global test loss: 1.690, Global test accuracy: 49.84 

Round  96, Train loss: 0.173, Test loss: 4.046, Test accuracy: 41.63 

Round  96, Global train loss: 0.173, Global test loss: 1.566, Global test accuracy: 46.50 

Round  97, Train loss: 0.210, Test loss: 3.975, Test accuracy: 41.85 

Round  97, Global train loss: 0.210, Global test loss: 1.647, Global test accuracy: 47.86 

Round  98, Train loss: 0.129, Test loss: 3.970, Test accuracy: 42.06 

Round  98, Global train loss: 0.129, Global test loss: 1.603, Global test accuracy: 47.30 

Round  99, Train loss: 0.142, Test loss: 4.026, Test accuracy: 41.97 

Round  99, Global train loss: 0.142, Global test loss: 1.642, Global test accuracy: 46.92 

Final Round, Train loss: 0.154, Test loss: 4.276, Test accuracy: 41.48 

Final Round, Global train loss: 0.154, Global test loss: 1.642, Global test accuracy: 46.92 

Average accuracy final 10 rounds: 41.98333333333333 

Average global accuracy final 10 rounds: 47.59833333333333 

3442.9786751270294
[1.4078669548034668, 2.5854790210723877, 3.7604782581329346, 4.9379494190216064, 6.107939958572388, 7.272692918777466, 8.441473722457886, 9.610953569412231, 10.776527166366577, 11.945287942886353, 13.09828233718872, 14.240771293640137, 15.379443883895874, 16.51565194129944, 17.647135972976685, 18.78426456451416, 19.917388200759888, 21.04986071586609, 22.1911039352417, 23.330859422683716, 24.475985050201416, 25.62272810935974, 26.770379781723022, 27.91938614845276, 28.92496967315674, 29.91848063468933, 30.91738724708557, 31.911640644073486, 32.9051673412323, 33.904743671417236, 34.89936327934265, 35.89938306808472, 36.892348289489746, 37.886805295944214, 38.89080810546875, 39.88302779197693, 40.88598895072937, 41.891775608062744, 42.88705539703369, 43.89154505729675, 44.880207777023315, 45.86846470832825, 46.86656141281128, 47.86129117012024, 48.86022734642029, 49.8576717376709, 50.853628158569336, 51.85283637046814, 52.848334550857544, 53.84715819358826, 54.843159437179565, 55.83540678024292, 56.83438205718994, 57.82746148109436, 58.82485389709473, 59.82559657096863, 60.835541009902954, 61.834484815597534, 62.82829928398132, 63.82154130935669, 64.82110047340393, 65.81278324127197, 66.81351971626282, 67.80993962287903, 68.80279040336609, 69.80295658111572, 70.79630255699158, 71.79446291923523, 72.79431056976318, 73.78757691383362, 74.7860472202301, 75.77963304519653, 76.77489566802979, 77.77491116523743, 78.77174401283264, 79.77115821838379, 80.76643657684326, 81.75693535804749, 82.75815868377686, 83.7512423992157, 84.75070524215698, 85.74408078193665, 86.73797965049744, 87.73900723457336, 88.73198390007019, 89.73365044593811, 90.72552514076233, 91.71859574317932, 92.71919536590576, 93.71364903450012, 94.71454524993896, 95.71265602111816, 96.71064782142639, 97.70477986335754, 98.70005249977112, 99.70440006256104, 100.70353436470032, 101.69878911972046, 102.70150899887085, 103.69736647605896, 105.6984293460846]
[25.67, 29.063333333333333, 31.461666666666666, 32.565, 33.735, 34.54666666666667, 35.07333333333333, 35.406666666666666, 35.98166666666667, 36.46, 36.666666666666664, 37.483333333333334, 38.25833333333333, 39.01833333333333, 39.89666666666667, 39.645, 38.958333333333336, 38.94, 39.306666666666665, 40.36, 40.166666666666664, 40.29, 40.87, 40.90833333333333, 41.02333333333333, 40.861666666666665, 40.815, 40.95666666666666, 40.861666666666665, 40.86666666666667, 40.79, 40.47, 40.69166666666667, 40.545, 40.723333333333336, 40.625, 41.09, 41.211666666666666, 41.465, 41.275, 41.498333333333335, 41.25666666666667, 41.675, 41.83833333333333, 41.665, 41.891666666666666, 41.87166666666667, 41.445, 41.431666666666665, 41.388333333333335, 41.41166666666667, 41.583333333333336, 41.61, 41.373333333333335, 41.295, 41.38166666666667, 41.455, 41.47833333333333, 41.108333333333334, 41.303333333333335, 41.306666666666665, 41.126666666666665, 41.428333333333335, 41.39833333333333, 41.12166666666667, 41.42, 41.57333333333333, 41.44833333333333, 41.60666666666667, 41.675, 41.25666666666667, 41.62833333333333, 41.795, 41.64833333333333, 41.64, 41.91833333333334, 41.833333333333336, 41.638333333333335, 41.681666666666665, 41.69, 41.708333333333336, 41.81166666666667, 41.48166666666667, 41.51166666666666, 41.47, 41.3, 41.42, 41.615, 41.626666666666665, 42.10166666666667, 42.053333333333335, 42.14833333333333, 41.96333333333333, 42.3, 42.10666666666667, 41.748333333333335, 41.635, 41.855, 42.05833333333333, 41.965, 41.47666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.233, Test loss: 2.123, Test accuracy: 23.85 

Round   0, Global train loss: 2.233, Global test loss: 2.127, Global test accuracy: 24.82 

Round   1, Train loss: 2.035, Test loss: 1.954, Test accuracy: 27.77 

Round   1, Global train loss: 2.035, Global test loss: 1.913, Global test accuracy: 29.68 

Round   2, Train loss: 1.885, Test loss: 1.827, Test accuracy: 33.09 

Round   2, Global train loss: 1.885, Global test loss: 1.742, Global test accuracy: 37.07 

Round   3, Train loss: 1.781, Test loss: 1.775, Test accuracy: 34.77 

Round   3, Global train loss: 1.781, Global test loss: 1.647, Global test accuracy: 40.05 

Round   4, Train loss: 1.718, Test loss: 1.695, Test accuracy: 38.11 

Round   4, Global train loss: 1.718, Global test loss: 1.550, Global test accuracy: 44.14 

Round   5, Train loss: 1.650, Test loss: 1.644, Test accuracy: 39.99 

Round   5, Global train loss: 1.650, Global test loss: 1.507, Global test accuracy: 46.20 

Round   6, Train loss: 1.568, Test loss: 1.631, Test accuracy: 40.71 

Round   6, Global train loss: 1.568, Global test loss: 1.463, Global test accuracy: 47.44 

Round   7, Train loss: 1.539, Test loss: 1.616, Test accuracy: 41.19 

Round   7, Global train loss: 1.539, Global test loss: 1.427, Global test accuracy: 48.74 

Round   8, Train loss: 1.487, Test loss: 1.595, Test accuracy: 42.05 

Round   8, Global train loss: 1.487, Global test loss: 1.377, Global test accuracy: 50.98 

Round   9, Train loss: 1.445, Test loss: 1.558, Test accuracy: 43.78 

Round   9, Global train loss: 1.445, Global test loss: 1.350, Global test accuracy: 52.18 

Round  10, Train loss: 1.396, Test loss: 1.548, Test accuracy: 44.39 

Round  10, Global train loss: 1.396, Global test loss: 1.330, Global test accuracy: 53.21 

Round  11, Train loss: 1.377, Test loss: 1.509, Test accuracy: 46.00 

Round  11, Global train loss: 1.377, Global test loss: 1.298, Global test accuracy: 53.99 

Round  12, Train loss: 1.325, Test loss: 1.492, Test accuracy: 46.88 

Round  12, Global train loss: 1.325, Global test loss: 1.274, Global test accuracy: 54.84 

Round  13, Train loss: 1.323, Test loss: 1.461, Test accuracy: 48.13 

Round  13, Global train loss: 1.323, Global test loss: 1.237, Global test accuracy: 55.97 

Round  14, Train loss: 1.262, Test loss: 1.464, Test accuracy: 48.31 

Round  14, Global train loss: 1.262, Global test loss: 1.225, Global test accuracy: 56.49 

Round  15, Train loss: 1.247, Test loss: 1.465, Test accuracy: 48.41 

Round  15, Global train loss: 1.247, Global test loss: 1.197, Global test accuracy: 57.52 

Round  16, Train loss: 1.169, Test loss: 1.449, Test accuracy: 49.30 

Round  16, Global train loss: 1.169, Global test loss: 1.180, Global test accuracy: 58.21 

Round  17, Train loss: 1.139, Test loss: 1.449, Test accuracy: 49.49 

Round  17, Global train loss: 1.139, Global test loss: 1.190, Global test accuracy: 58.26 

Round  18, Train loss: 1.139, Test loss: 1.439, Test accuracy: 49.98 

Round  18, Global train loss: 1.139, Global test loss: 1.161, Global test accuracy: 59.03 

Round  19, Train loss: 1.161, Test loss: 1.408, Test accuracy: 51.34 

Round  19, Global train loss: 1.161, Global test loss: 1.163, Global test accuracy: 59.35 

Round  20, Train loss: 1.110, Test loss: 1.389, Test accuracy: 52.20 

Round  20, Global train loss: 1.110, Global test loss: 1.132, Global test accuracy: 60.53 

Round  21, Train loss: 1.080, Test loss: 1.391, Test accuracy: 52.53 

Round  21, Global train loss: 1.080, Global test loss: 1.122, Global test accuracy: 60.54 

Round  22, Train loss: 1.041, Test loss: 1.384, Test accuracy: 53.08 

Round  22, Global train loss: 1.041, Global test loss: 1.134, Global test accuracy: 60.74 

Round  23, Train loss: 1.017, Test loss: 1.398, Test accuracy: 52.92 

Round  23, Global train loss: 1.017, Global test loss: 1.133, Global test accuracy: 61.08 

Round  24, Train loss: 1.031, Test loss: 1.389, Test accuracy: 53.59 

Round  24, Global train loss: 1.031, Global test loss: 1.105, Global test accuracy: 61.74 

Round  25, Train loss: 0.982, Test loss: 1.402, Test accuracy: 53.50 

Round  25, Global train loss: 0.982, Global test loss: 1.106, Global test accuracy: 61.85 

Round  26, Train loss: 0.960, Test loss: 1.403, Test accuracy: 53.54 

Round  26, Global train loss: 0.960, Global test loss: 1.125, Global test accuracy: 60.97 

Round  27, Train loss: 0.947, Test loss: 1.406, Test accuracy: 53.71 

Round  27, Global train loss: 0.947, Global test loss: 1.106, Global test accuracy: 61.40 

Round  28, Train loss: 0.934, Test loss: 1.391, Test accuracy: 54.35 

Round  28, Global train loss: 0.934, Global test loss: 1.095, Global test accuracy: 62.51 

Round  29, Train loss: 0.977, Test loss: 1.380, Test accuracy: 54.83 

Round  29, Global train loss: 0.977, Global test loss: 1.085, Global test accuracy: 62.37 

Round  30, Train loss: 0.915, Test loss: 1.381, Test accuracy: 55.05 

Round  30, Global train loss: 0.915, Global test loss: 1.095, Global test accuracy: 62.82 

Round  31, Train loss: 0.877, Test loss: 1.370, Test accuracy: 55.39 

Round  31, Global train loss: 0.877, Global test loss: 1.089, Global test accuracy: 62.59 

Round  32, Train loss: 0.929, Test loss: 1.359, Test accuracy: 55.98 

Round  32, Global train loss: 0.929, Global test loss: 1.061, Global test accuracy: 63.50 

Round  33, Train loss: 0.845, Test loss: 1.357, Test accuracy: 56.23 

Round  33, Global train loss: 0.845, Global test loss: 1.075, Global test accuracy: 63.72 

Round  34, Train loss: 0.879, Test loss: 1.369, Test accuracy: 56.24 

Round  34, Global train loss: 0.879, Global test loss: 1.059, Global test accuracy: 63.85 

Round  35, Train loss: 0.874, Test loss: 1.365, Test accuracy: 56.45 

Round  35, Global train loss: 0.874, Global test loss: 1.047, Global test accuracy: 64.37 

Round  36, Train loss: 0.848, Test loss: 1.367, Test accuracy: 56.67 

Round  36, Global train loss: 0.848, Global test loss: 1.068, Global test accuracy: 64.02 

Round  37, Train loss: 0.796, Test loss: 1.370, Test accuracy: 56.91 

Round  37, Global train loss: 0.796, Global test loss: 1.068, Global test accuracy: 64.40 

Round  38, Train loss: 0.803, Test loss: 1.372, Test accuracy: 57.07 

Round  38, Global train loss: 0.803, Global test loss: 1.071, Global test accuracy: 64.49 

Round  39, Train loss: 0.823, Test loss: 1.369, Test accuracy: 57.30 

Round  39, Global train loss: 0.823, Global test loss: 1.066, Global test accuracy: 64.48 

Round  40, Train loss: 0.764, Test loss: 1.377, Test accuracy: 57.45 

Round  40, Global train loss: 0.764, Global test loss: 1.065, Global test accuracy: 65.10 

Round  41, Train loss: 0.743, Test loss: 1.389, Test accuracy: 57.39 

Round  41, Global train loss: 0.743, Global test loss: 1.080, Global test accuracy: 64.93 

Round  42, Train loss: 0.770, Test loss: 1.401, Test accuracy: 57.53 

Round  42, Global train loss: 0.770, Global test loss: 1.080, Global test accuracy: 64.47 

Round  43, Train loss: 0.761, Test loss: 1.378, Test accuracy: 57.80 

Round  43, Global train loss: 0.761, Global test loss: 1.040, Global test accuracy: 65.33 

Round  44, Train loss: 0.761, Test loss: 1.368, Test accuracy: 58.08 

Round  44, Global train loss: 0.761, Global test loss: 1.057, Global test accuracy: 65.20 

Round  45, Train loss: 0.762, Test loss: 1.386, Test accuracy: 58.09 

Round  45, Global train loss: 0.762, Global test loss: 1.049, Global test accuracy: 65.82 

Round  46, Train loss: 0.732, Test loss: 1.388, Test accuracy: 58.22 

Round  46, Global train loss: 0.732, Global test loss: 1.046, Global test accuracy: 65.38 

Round  47, Train loss: 0.704, Test loss: 1.381, Test accuracy: 58.67 

Round  47, Global train loss: 0.704, Global test loss: 1.058, Global test accuracy: 66.13 

Round  48, Train loss: 0.715, Test loss: 1.378, Test accuracy: 58.59 

Round  48, Global train loss: 0.715, Global test loss: 1.056, Global test accuracy: 65.54 

Round  49, Train loss: 0.695, Test loss: 1.377, Test accuracy: 58.70 

Round  49, Global train loss: 0.695, Global test loss: 1.053, Global test accuracy: 66.08 

Round  50, Train loss: 0.691, Test loss: 1.382, Test accuracy: 58.72 

Round  50, Global train loss: 0.691, Global test loss: 1.070, Global test accuracy: 65.64 

Round  51, Train loss: 0.710, Test loss: 1.404, Test accuracy: 58.74 

Round  51, Global train loss: 0.710, Global test loss: 1.049, Global test accuracy: 66.35 

Round  52, Train loss: 0.675, Test loss: 1.413, Test accuracy: 58.66 

Round  52, Global train loss: 0.675, Global test loss: 1.058, Global test accuracy: 66.07 

Round  53, Train loss: 0.668, Test loss: 1.426, Test accuracy: 58.82 

Round  53, Global train loss: 0.668, Global test loss: 1.073, Global test accuracy: 66.52 

Round  54, Train loss: 0.617, Test loss: 1.412, Test accuracy: 59.30 

Round  54, Global train loss: 0.617, Global test loss: 1.065, Global test accuracy: 66.44 

Round  55, Train loss: 0.636, Test loss: 1.429, Test accuracy: 59.27 

Round  55, Global train loss: 0.636, Global test loss: 1.063, Global test accuracy: 66.69 

Round  56, Train loss: 0.619, Test loss: 1.437, Test accuracy: 59.20 

Round  56, Global train loss: 0.619, Global test loss: 1.077, Global test accuracy: 66.17 

Round  57, Train loss: 0.621, Test loss: 1.452, Test accuracy: 58.92 

Round  57, Global train loss: 0.621, Global test loss: 1.063, Global test accuracy: 66.22 

Round  58, Train loss: 0.628, Test loss: 1.461, Test accuracy: 58.73 

Round  58, Global train loss: 0.628, Global test loss: 1.061, Global test accuracy: 66.44 

Round  59, Train loss: 0.598, Test loss: 1.471, Test accuracy: 59.11 

Round  59, Global train loss: 0.598, Global test loss: 1.095, Global test accuracy: 66.40 

Round  60, Train loss: 0.626, Test loss: 1.470, Test accuracy: 59.16 

Round  60, Global train loss: 0.626, Global test loss: 1.078, Global test accuracy: 66.55 

Round  61, Train loss: 0.585, Test loss: 1.473, Test accuracy: 59.36 

Round  61, Global train loss: 0.585, Global test loss: 1.094, Global test accuracy: 66.53 

Round  62, Train loss: 0.635, Test loss: 1.454, Test accuracy: 59.86 

Round  62, Global train loss: 0.635, Global test loss: 1.082, Global test accuracy: 66.52 

Round  63, Train loss: 0.623, Test loss: 1.466, Test accuracy: 59.86 

Round  63, Global train loss: 0.623, Global test loss: 1.079, Global test accuracy: 66.71 

Round  64, Train loss: 0.551, Test loss: 1.464, Test accuracy: 60.03 

Round  64, Global train loss: 0.551, Global test loss: 1.091, Global test accuracy: 66.64 

Round  65, Train loss: 0.523, Test loss: 1.472, Test accuracy: 59.98 

Round  65, Global train loss: 0.523, Global test loss: 1.130, Global test accuracy: 66.34 

Round  66, Train loss: 0.579, Test loss: 1.465, Test accuracy: 60.28 

Round  66, Global train loss: 0.579, Global test loss: 1.104, Global test accuracy: 66.70 

Round  67, Train loss: 0.590, Test loss: 1.474, Test accuracy: 60.08 

Round  67, Global train loss: 0.590, Global test loss: 1.093, Global test accuracy: 66.46 

Round  68, Train loss: 0.556, Test loss: 1.477, Test accuracy: 59.95 

Round  68, Global train loss: 0.556, Global test loss: 1.108, Global test accuracy: 66.30 

Round  69, Train loss: 0.561, Test loss: 1.484, Test accuracy: 60.06 

Round  69, Global train loss: 0.561, Global test loss: 1.099, Global test accuracy: 67.10 

Round  70, Train loss: 0.533, Test loss: 1.474, Test accuracy: 60.06 

Round  70, Global train loss: 0.533, Global test loss: 1.111, Global test accuracy: 66.70 

Round  71, Train loss: 0.533, Test loss: 1.480, Test accuracy: 60.07 

Round  71, Global train loss: 0.533, Global test loss: 1.109, Global test accuracy: 66.53 

Round  72, Train loss: 0.542, Test loss: 1.492, Test accuracy: 59.84 

Round  72, Global train loss: 0.542, Global test loss: 1.119, Global test accuracy: 66.31 

Round  73, Train loss: 0.510, Test loss: 1.479, Test accuracy: 60.21 

Round  73, Global train loss: 0.510, Global test loss: 1.129, Global test accuracy: 67.00 

Round  74, Train loss: 0.545, Test loss: 1.470, Test accuracy: 60.37 

Round  74, Global train loss: 0.545, Global test loss: 1.094, Global test accuracy: 66.69 

Round  75, Train loss: 0.547, Test loss: 1.470, Test accuracy: 60.48 

Round  75, Global train loss: 0.547, Global test loss: 1.079, Global test accuracy: 67.39 

Round  76, Train loss: 0.535, Test loss: 1.460, Test accuracy: 60.78 

Round  76, Global train loss: 0.535, Global test loss: 1.100, Global test accuracy: 67.27 

Round  77, Train loss: 0.558, Test loss: 1.465, Test accuracy: 60.64 

Round  77, Global train loss: 0.558, Global test loss: 1.110, Global test accuracy: 66.87 

Round  78, Train loss: 0.522, Test loss: 1.470, Test accuracy: 60.79 

Round  78, Global train loss: 0.522, Global test loss: 1.087, Global test accuracy: 67.18 

Round  79, Train loss: 0.526, Test loss: 1.471, Test accuracy: 60.91 

Round  79, Global train loss: 0.526, Global test loss: 1.089, Global test accuracy: 67.69 

Round  80, Train loss: 0.480, Test loss: 1.479, Test accuracy: 60.77 

Round  80, Global train loss: 0.480, Global test loss: 1.134, Global test accuracy: 67.05 

Round  81, Train loss: 0.521, Test loss: 1.481, Test accuracy: 60.83 

Round  81, Global train loss: 0.521, Global test loss: 1.103, Global test accuracy: 67.08 

Round  82, Train loss: 0.531, Test loss: 1.512, Test accuracy: 60.38 

Round  82, Global train loss: 0.531, Global test loss: 1.094, Global test accuracy: 67.36 

Round  83, Train loss: 0.514, Test loss: 1.513, Test accuracy: 60.53 

Round  83, Global train loss: 0.514, Global test loss: 1.123, Global test accuracy: 66.73 

Round  84, Train loss: 0.477, Test loss: 1.503, Test accuracy: 60.62 

Round  84, Global train loss: 0.477, Global test loss: 1.117, Global test accuracy: 67.23 

Round  85, Train loss: 0.471, Test loss: 1.507, Test accuracy: 60.78 

Round  85, Global train loss: 0.471, Global test loss: 1.134, Global test accuracy: 67.14 

Round  86, Train loss: 0.480, Test loss: 1.514, Test accuracy: 60.93 

Round  86, Global train loss: 0.480, Global test loss: 1.121, Global test accuracy: 67.25 

Round  87, Train loss: 0.446, Test loss: 1.511, Test accuracy: 60.93 

Round  87, Global train loss: 0.446, Global test loss: 1.117, Global test accuracy: 67.46 

Round  88, Train loss: 0.503, Test loss: 1.515, Test accuracy: 61.16 

Round  88, Global train loss: 0.503, Global test loss: 1.126, Global test accuracy: 67.40 

Round  89, Train loss: 0.473, Test loss: 1.524, Test accuracy: 61.05 

Round  89, Global train loss: 0.473, Global test loss: 1.125, Global test accuracy: 67.17 

Round  90, Train loss: 0.456, Test loss: 1.519, Test accuracy: 61.10 

Round  90, Global train loss: 0.456, Global test loss: 1.120, Global test accuracy: 67.67 

Round  91, Train loss: 0.411, Test loss: 1.511, Test accuracy: 61.34 

Round  91, Global train loss: 0.411, Global test loss: 1.148, Global test accuracy: 67.26 

Round  92, Train loss: 0.481, Test loss: 1.499, Test accuracy: 61.36 

Round  92, Global train loss: 0.481, Global test loss: 1.146, Global test accuracy: 67.34 

Round  93, Train loss: 0.448, Test loss: 1.531, Test accuracy: 61.17 

Round  93, Global train loss: 0.448, Global test loss: 1.144, Global test accuracy: 67.13 

Round  94, Train loss: 0.440, Test loss: 1.540, Test accuracy: 61.12 

Round  94, Global train loss: 0.440, Global test loss: 1.169, Global test accuracy: 67.16 

Round  95, Train loss: 0.454, Test loss: 1.555, Test accuracy: 61.12 

Round  95, Global train loss: 0.454, Global test loss: 1.144, Global test accuracy: 68.45 

Round  96, Train loss: 0.446, Test loss: 1.564, Test accuracy: 61.01 

Round  96, Global train loss: 0.446, Global test loss: 1.167, Global test accuracy: 67.31 

Round  97, Train loss: 0.448, Test loss: 1.548, Test accuracy: 61.37 

Round  97, Global train loss: 0.448, Global test loss: 1.165, Global test accuracy: 67.46 

Round  98, Train loss: 0.417, Test loss: 1.528, Test accuracy: 61.77 

Round  98, Global train loss: 0.417, Global test loss: 1.169, Global test accuracy: 67.87 

Round  99, Train loss: 0.461, Test loss: 1.525, Test accuracy: 61.95 

Round  99, Global train loss: 0.461, Global test loss: 1.139, Global test accuracy: 67.65 

Final Round, Train loss: 0.351, Test loss: 1.711, Test accuracy: 61.26 

Final Round, Global train loss: 0.351, Global test loss: 1.139, Global test accuracy: 67.65 

Average accuracy final 10 rounds: 61.33083333333333 

Average global accuracy final 10 rounds: 67.53016666666666 

3453.364027261734
[1.3996696472167969, 2.4088425636291504, 3.413928270339966, 4.420943260192871, 5.42512845993042, 6.4323296546936035, 7.441100120544434, 8.447503089904785, 9.44956636428833, 10.454710006713867, 11.459614276885986, 12.467694997787476, 13.474336385726929, 14.478411436080933, 15.481841564178467, 16.488852977752686, 17.491909742355347, 18.501903295516968, 19.507856130599976, 20.519784450531006, 21.523810386657715, 22.531126260757446, 23.538840770721436, 24.544251441955566, 25.55176544189453, 26.560953855514526, 27.565232038497925, 28.560646295547485, 29.565725088119507, 30.596500873565674, 31.601721048355103, 32.60662889480591, 33.61142539978027, 34.61560082435608, 35.60765886306763, 36.61202692985535, 37.63307309150696, 38.636852979660034, 39.64160490036011, 40.64617085456848, 41.65173959732056, 42.652570962905884, 43.65549850463867, 44.66055393218994, 45.66671323776245, 46.672954082489014, 47.66888642311096, 48.675517082214355, 49.682923555374146, 50.68649625778198, 51.692721366882324, 52.686723947525024, 53.69279098510742, 54.69905948638916, 55.705379486083984, 56.71157479286194, 57.70839786529541, 58.714224100112915, 59.72197151184082, 60.72349286079407, 61.73013687133789, 62.73429250717163, 63.73783302307129, 64.74312925338745, 65.74878978729248, 66.75491428375244, 67.76111507415771, 68.7703025341034, 69.77781677246094, 70.7835042476654, 71.79204225540161, 72.79929876327515, 73.80336928367615, 74.81154584884644, 75.8144063949585, 76.8126871585846, 77.81282806396484, 78.81186628341675, 79.80808687210083, 80.81193542480469, 81.81808304786682, 82.8246955871582, 83.82934641838074, 84.83737444877625, 85.83266305923462, 86.83138799667358, 87.83801794052124, 88.84308314323425, 89.84879207611084, 90.85501551628113, 91.8570384979248, 92.85151743888855, 93.84900259971619, 94.85332441329956, 95.85953617095947, 96.86594843864441, 97.86899781227112, 98.8743507862091, 99.87786269187927, 100.88449215888977, 102.89004826545715]
[23.846666666666668, 27.766666666666666, 33.09166666666667, 34.766666666666666, 38.10666666666667, 39.98833333333334, 40.70666666666666, 41.19, 42.055, 43.781666666666666, 44.38666666666666, 45.99666666666667, 46.88, 48.12833333333333, 48.31166666666667, 48.415, 49.303333333333335, 49.48833333333334, 49.975, 51.34, 52.19833333333333, 52.528333333333336, 53.07666666666667, 52.92, 53.585, 53.5, 53.538333333333334, 53.70666666666666, 54.35, 54.83, 55.055, 55.391666666666666, 55.97666666666667, 56.233333333333334, 56.24166666666667, 56.445, 56.67166666666667, 56.905, 57.071666666666665, 57.295, 57.445, 57.388333333333335, 57.531666666666666, 57.805, 58.07666666666667, 58.085, 58.215, 58.66833333333334, 58.595, 58.70333333333333, 58.71666666666667, 58.745, 58.66166666666667, 58.821666666666665, 59.305, 59.265, 59.2, 58.925, 58.72666666666667, 59.10666666666667, 59.165, 59.361666666666665, 59.861666666666665, 59.86, 60.03333333333333, 59.98166666666667, 60.28, 60.08166666666666, 59.94833333333333, 60.056666666666665, 60.06166666666667, 60.07, 59.84, 60.211666666666666, 60.37166666666667, 60.48, 60.785, 60.64, 60.791666666666664, 60.913333333333334, 60.766666666666666, 60.825, 60.38333333333333, 60.53, 60.623333333333335, 60.78, 60.931666666666665, 60.93, 61.16166666666667, 61.05166666666667, 61.10333333333333, 61.343333333333334, 61.36, 61.166666666666664, 61.12, 61.12166666666667, 61.00833333333333, 61.36833333333333, 61.77166666666667, 61.945, 61.25833333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.263, Test loss: 2.156, Test accuracy: 20.19 

Round   1, Train loss: 2.102, Test loss: 1.985, Test accuracy: 27.95 

Round   2, Train loss: 1.954, Test loss: 1.884, Test accuracy: 31.16 

Round   3, Train loss: 1.898, Test loss: 1.816, Test accuracy: 33.28 

Round   4, Train loss: 1.811, Test loss: 1.755, Test accuracy: 35.46 

Round   5, Train loss: 1.774, Test loss: 1.698, Test accuracy: 37.59 

Round   6, Train loss: 1.689, Test loss: 1.641, Test accuracy: 39.82 

Round   7, Train loss: 1.645, Test loss: 1.615, Test accuracy: 41.14 

Round   8, Train loss: 1.635, Test loss: 1.613, Test accuracy: 41.35 

Round   9, Train loss: 1.584, Test loss: 1.584, Test accuracy: 41.95 

Round  10, Train loss: 1.569, Test loss: 1.568, Test accuracy: 43.06 

Round  11, Train loss: 1.556, Test loss: 1.522, Test accuracy: 44.66 

Round  12, Train loss: 1.491, Test loss: 1.495, Test accuracy: 45.72 

Round  13, Train loss: 1.506, Test loss: 1.474, Test accuracy: 46.44 

Round  14, Train loss: 1.458, Test loss: 1.464, Test accuracy: 46.60 

Round  15, Train loss: 1.469, Test loss: 1.455, Test accuracy: 46.95 

Round  16, Train loss: 1.410, Test loss: 1.433, Test accuracy: 47.72 

Round  17, Train loss: 1.418, Test loss: 1.419, Test accuracy: 48.27 

Round  18, Train loss: 1.400, Test loss: 1.422, Test accuracy: 48.62 

Round  19, Train loss: 1.324, Test loss: 1.398, Test accuracy: 49.27 

Round  20, Train loss: 1.363, Test loss: 1.361, Test accuracy: 50.62 

Round  21, Train loss: 1.344, Test loss: 1.356, Test accuracy: 51.33 

Round  22, Train loss: 1.292, Test loss: 1.344, Test accuracy: 51.98 

Round  23, Train loss: 1.292, Test loss: 1.329, Test accuracy: 52.06 

Round  24, Train loss: 1.282, Test loss: 1.325, Test accuracy: 52.37 

Round  25, Train loss: 1.263, Test loss: 1.310, Test accuracy: 53.02 

Round  26, Train loss: 1.223, Test loss: 1.302, Test accuracy: 53.49 

Round  27, Train loss: 1.238, Test loss: 1.279, Test accuracy: 54.48 

Round  28, Train loss: 1.209, Test loss: 1.284, Test accuracy: 54.20 

Round  29, Train loss: 1.180, Test loss: 1.304, Test accuracy: 53.24 

Round  30, Train loss: 1.205, Test loss: 1.308, Test accuracy: 53.30 

Round  31, Train loss: 1.170, Test loss: 1.301, Test accuracy: 54.03 

Round  32, Train loss: 1.137, Test loss: 1.283, Test accuracy: 54.37 

Round  33, Train loss: 1.120, Test loss: 1.281, Test accuracy: 54.45 

Round  34, Train loss: 1.129, Test loss: 1.275, Test accuracy: 54.88 

Round  35, Train loss: 1.123, Test loss: 1.262, Test accuracy: 55.45 

Round  36, Train loss: 1.136, Test loss: 1.253, Test accuracy: 55.96 

Round  37, Train loss: 1.044, Test loss: 1.237, Test accuracy: 56.63 

Round  38, Train loss: 1.102, Test loss: 1.223, Test accuracy: 57.18 

Round  39, Train loss: 1.080, Test loss: 1.211, Test accuracy: 57.78 

Round  40, Train loss: 0.995, Test loss: 1.227, Test accuracy: 57.20 

Round  41, Train loss: 1.023, Test loss: 1.212, Test accuracy: 57.76 

Round  42, Train loss: 1.011, Test loss: 1.222, Test accuracy: 57.71 

Round  43, Train loss: 0.991, Test loss: 1.203, Test accuracy: 58.38 

Round  44, Train loss: 0.959, Test loss: 1.205, Test accuracy: 58.57 

Round  45, Train loss: 1.018, Test loss: 1.203, Test accuracy: 58.50 

Round  46, Train loss: 1.010, Test loss: 1.211, Test accuracy: 57.98 

Round  47, Train loss: 0.979, Test loss: 1.177, Test accuracy: 59.33 

Round  48, Train loss: 0.965, Test loss: 1.173, Test accuracy: 59.24 

Round  49, Train loss: 0.954, Test loss: 1.176, Test accuracy: 59.50 

Round  50, Train loss: 0.904, Test loss: 1.189, Test accuracy: 59.22 

Round  51, Train loss: 0.930, Test loss: 1.187, Test accuracy: 59.74 

Round  52, Train loss: 0.907, Test loss: 1.185, Test accuracy: 59.88 

Round  53, Train loss: 0.847, Test loss: 1.172, Test accuracy: 60.10 

Round  54, Train loss: 0.841, Test loss: 1.183, Test accuracy: 59.93 

Round  55, Train loss: 0.884, Test loss: 1.175, Test accuracy: 60.42 

Round  56, Train loss: 0.858, Test loss: 1.167, Test accuracy: 60.92 

Round  57, Train loss: 0.866, Test loss: 1.183, Test accuracy: 60.60 

Round  58, Train loss: 0.877, Test loss: 1.181, Test accuracy: 60.46 

Round  59, Train loss: 0.854, Test loss: 1.190, Test accuracy: 60.45 

Round  60, Train loss: 0.838, Test loss: 1.208, Test accuracy: 59.98 

Round  61, Train loss: 0.873, Test loss: 1.186, Test accuracy: 60.63 

Round  62, Train loss: 0.814, Test loss: 1.199, Test accuracy: 60.54 

Round  63, Train loss: 0.841, Test loss: 1.188, Test accuracy: 60.57 

Round  64, Train loss: 0.806, Test loss: 1.154, Test accuracy: 60.92 

Round  65, Train loss: 0.811, Test loss: 1.166, Test accuracy: 61.19 

Round  66, Train loss: 0.802, Test loss: 1.159, Test accuracy: 61.38 

Round  67, Train loss: 0.764, Test loss: 1.165, Test accuracy: 61.81 

Round  68, Train loss: 0.815, Test loss: 1.180, Test accuracy: 61.23 

Round  69, Train loss: 0.749, Test loss: 1.186, Test accuracy: 60.95 

Round  70, Train loss: 0.766, Test loss: 1.173, Test accuracy: 61.94 

Round  71, Train loss: 0.714, Test loss: 1.199, Test accuracy: 61.24 

Round  72, Train loss: 0.700, Test loss: 1.188, Test accuracy: 61.42 

Round  73, Train loss: 0.744, Test loss: 1.201, Test accuracy: 61.45 

Round  74, Train loss: 0.722, Test loss: 1.193, Test accuracy: 61.74 

Round  75, Train loss: 0.692, Test loss: 1.202, Test accuracy: 62.23 

Round  76, Train loss: 0.678, Test loss: 1.205, Test accuracy: 61.81 

Round  77, Train loss: 0.711, Test loss: 1.208, Test accuracy: 61.24 

Round  78, Train loss: 0.694, Test loss: 1.208, Test accuracy: 61.27 

Round  79, Train loss: 0.706, Test loss: 1.188, Test accuracy: 62.08 

Round  80, Train loss: 0.651, Test loss: 1.201, Test accuracy: 62.11 

Round  81, Train loss: 0.681, Test loss: 1.231, Test accuracy: 61.93 

Round  82, Train loss: 0.691, Test loss: 1.227, Test accuracy: 61.52 

Round  83, Train loss: 0.667, Test loss: 1.201, Test accuracy: 62.03 

Round  84, Train loss: 0.643, Test loss: 1.228, Test accuracy: 61.94 

Round  85, Train loss: 0.635, Test loss: 1.225, Test accuracy: 62.07 

Round  86, Train loss: 0.641, Test loss: 1.223, Test accuracy: 62.22 

Round  87, Train loss: 0.643, Test loss: 1.208, Test accuracy: 62.66 

Round  88, Train loss: 0.664, Test loss: 1.230, Test accuracy: 62.32 

Round  89, Train loss: 0.623, Test loss: 1.232, Test accuracy: 62.21 

Round  90, Train loss: 0.645, Test loss: 1.224, Test accuracy: 62.49 

Round  91, Train loss: 0.633, Test loss: 1.247, Test accuracy: 62.48 

Round  92, Train loss: 0.609, Test loss: 1.255, Test accuracy: 62.25 

Round  93, Train loss: 0.579, Test loss: 1.222, Test accuracy: 62.43 

Round  94, Train loss: 0.563, Test loss: 1.243, Test accuracy: 62.05 

Round  95, Train loss: 0.606, Test loss: 1.252, Test accuracy: 62.58 

Round  96, Train loss: 0.561, Test loss: 1.254, Test accuracy: 62.48 

Round  97, Train loss: 0.539, Test loss: 1.277, Test accuracy: 62.62 

Round  98, Train loss: 0.676, Test loss: 1.240, Test accuracy: 62.27 

Round  99, Train loss: 0.633, Test loss: 1.256, Test accuracy: 62.45 

Final Round, Train loss: 0.509, Test loss: 1.266, Test accuracy: 62.48 

Average accuracy final 10 rounds: 62.409666666666666 

1978.087975025177
[1.2612972259521484, 2.1998026371002197, 3.137249231338501, 4.0763304233551025, 5.025578260421753, 5.969166278839111, 6.919104814529419, 7.8568267822265625, 8.79644775390625, 9.736024856567383, 10.6759934425354, 11.612808465957642, 12.55042839050293, 13.488256931304932, 14.4254469871521, 15.364811182022095, 16.304996728897095, 17.241984367370605, 18.181551218032837, 19.122812271118164, 20.060551404953003, 20.999353885650635, 21.933598041534424, 22.870227336883545, 23.801589488983154, 24.74324083328247, 25.678647994995117, 26.616060495376587, 27.552356004714966, 28.491068124771118, 29.432178020477295, 30.375479698181152, 31.322359085083008, 32.25810742378235, 33.19541120529175, 34.13572144508362, 35.07382392883301, 36.01326894760132, 36.95319175720215, 37.893123626708984, 38.83312153816223, 39.76996731758118, 40.71206259727478, 41.64363765716553, 42.57828164100647, 43.51313638687134, 44.447752237319946, 45.38651895523071, 46.32499575614929, 47.25737714767456, 48.191009283065796, 49.12472891807556, 50.055196046829224, 50.98782777786255, 51.91867017745972, 52.847418546676636, 53.77908492088318, 54.710708141326904, 55.64304971694946, 56.57876634597778, 57.51132416725159, 58.4463005065918, 59.37574005126953, 60.30806350708008, 61.24308133125305, 62.176427125930786, 63.11015510559082, 64.04629802703857, 64.98154044151306, 65.91451001167297, 66.8477110862732, 67.78109669685364, 68.71624398231506, 69.65143179893494, 70.5844087600708, 71.52027988433838, 72.45388746261597, 73.3877866268158, 74.32528066635132, 75.26555156707764, 76.20383667945862, 77.14482688903809, 78.08161330223083, 79.01935958862305, 79.95858097076416, 80.89793539047241, 81.83630776405334, 82.77362990379333, 83.71199035644531, 84.6503574848175, 85.582444190979, 86.51657199859619, 87.44637894630432, 88.37685942649841, 89.30608463287354, 90.23789930343628, 91.16828656196594, 92.1044991016388, 93.04406595230103, 93.98601365089417, 95.74356818199158]
[20.191666666666666, 27.955, 31.156666666666666, 33.278333333333336, 35.46333333333333, 37.59166666666667, 39.82, 41.14, 41.35166666666667, 41.946666666666665, 43.06, 44.665, 45.718333333333334, 46.44, 46.60166666666667, 46.94833333333333, 47.723333333333336, 48.266666666666666, 48.61833333333333, 49.27333333333333, 50.615, 51.33166666666666, 51.975, 52.056666666666665, 52.37, 53.01833333333333, 53.486666666666665, 54.485, 54.20333333333333, 53.245, 53.30166666666667, 54.03, 54.36666666666667, 54.445, 54.88, 55.446666666666665, 55.96333333333333, 56.635, 57.181666666666665, 57.776666666666664, 57.2, 57.76, 57.70666666666666, 58.38166666666667, 58.56666666666667, 58.501666666666665, 57.975, 59.33166666666666, 59.23833333333334, 59.49666666666667, 59.218333333333334, 59.74166666666667, 59.87833333333333, 60.10166666666667, 59.928333333333335, 60.42333333333333, 60.92, 60.598333333333336, 60.45666666666666, 60.45166666666667, 59.983333333333334, 60.62833333333333, 60.541666666666664, 60.56666666666667, 60.92, 61.19166666666667, 61.37833333333333, 61.81166666666667, 61.23166666666667, 60.955, 61.935, 61.23833333333334, 61.416666666666664, 61.445, 61.74333333333333, 62.23, 61.815, 61.24333333333333, 61.266666666666666, 62.07666666666667, 62.10666666666667, 61.93, 61.52333333333333, 62.035, 61.94166666666667, 62.068333333333335, 62.223333333333336, 62.655, 62.32, 62.21333333333333, 62.486666666666665, 62.483333333333334, 62.25333333333333, 62.431666666666665, 62.04666666666667, 62.57833333333333, 62.483333333333334, 62.62, 62.266666666666666, 62.446666666666665, 62.483333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedper
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.211, Test loss: 2.065, Test accuracy: 23.54 

Round   1, Train loss: 1.997, Test loss: 1.880, Test accuracy: 30.92 

Round   2, Train loss: 1.847, Test loss: 1.775, Test accuracy: 34.87 

Round   3, Train loss: 1.781, Test loss: 1.683, Test accuracy: 38.62 

Round   4, Train loss: 1.694, Test loss: 1.607, Test accuracy: 40.91 

Round   5, Train loss: 1.647, Test loss: 1.555, Test accuracy: 42.85 

Round   6, Train loss: 1.601, Test loss: 1.513, Test accuracy: 44.02 

Round   7, Train loss: 1.553, Test loss: 1.478, Test accuracy: 45.87 

Round   8, Train loss: 1.506, Test loss: 1.459, Test accuracy: 46.62 

Round   9, Train loss: 1.471, Test loss: 1.432, Test accuracy: 47.81 

Round  10, Train loss: 1.433, Test loss: 1.411, Test accuracy: 48.82 

Round  11, Train loss: 1.412, Test loss: 1.369, Test accuracy: 50.33 

Round  12, Train loss: 1.389, Test loss: 1.351, Test accuracy: 50.93 

Round  13, Train loss: 1.356, Test loss: 1.337, Test accuracy: 51.80 

Round  14, Train loss: 1.335, Test loss: 1.311, Test accuracy: 52.91 

Round  15, Train loss: 1.277, Test loss: 1.302, Test accuracy: 53.25 

Round  16, Train loss: 1.262, Test loss: 1.284, Test accuracy: 53.81 

Round  17, Train loss: 1.250, Test loss: 1.265, Test accuracy: 54.48 

Round  18, Train loss: 1.200, Test loss: 1.252, Test accuracy: 55.20 

Round  19, Train loss: 1.168, Test loss: 1.249, Test accuracy: 55.55 

Round  20, Train loss: 1.141, Test loss: 1.233, Test accuracy: 56.25 

Round  21, Train loss: 1.143, Test loss: 1.217, Test accuracy: 56.96 

Round  22, Train loss: 1.095, Test loss: 1.205, Test accuracy: 57.36 

Round  23, Train loss: 1.064, Test loss: 1.202, Test accuracy: 57.48 

Round  24, Train loss: 1.064, Test loss: 1.191, Test accuracy: 58.12 

Round  25, Train loss: 1.042, Test loss: 1.204, Test accuracy: 57.85 

Round  26, Train loss: 1.042, Test loss: 1.176, Test accuracy: 58.83 

Round  27, Train loss: 0.983, Test loss: 1.181, Test accuracy: 59.03 

Round  28, Train loss: 0.949, Test loss: 1.196, Test accuracy: 58.35 

Round  29, Train loss: 0.979, Test loss: 1.185, Test accuracy: 58.96 

Round  30, Train loss: 0.898, Test loss: 1.179, Test accuracy: 59.21 

Round  31, Train loss: 0.897, Test loss: 1.188, Test accuracy: 59.49 

Round  32, Train loss: 0.871, Test loss: 1.197, Test accuracy: 59.40 

Round  33, Train loss: 0.967, Test loss: 1.186, Test accuracy: 60.16 

Round  34, Train loss: 0.854, Test loss: 1.186, Test accuracy: 60.05 

Round  35, Train loss: 0.860, Test loss: 1.193, Test accuracy: 60.23 

Round  36, Train loss: 0.864, Test loss: 1.192, Test accuracy: 60.05 

Round  37, Train loss: 0.902, Test loss: 1.165, Test accuracy: 61.16 

Round  38, Train loss: 0.849, Test loss: 1.182, Test accuracy: 60.87 

Round  39, Train loss: 0.807, Test loss: 1.175, Test accuracy: 61.08 

Round  40, Train loss: 0.776, Test loss: 1.213, Test accuracy: 60.69 

Round  41, Train loss: 0.797, Test loss: 1.176, Test accuracy: 61.43 

Round  42, Train loss: 0.745, Test loss: 1.209, Test accuracy: 61.14 

Round  43, Train loss: 0.821, Test loss: 1.176, Test accuracy: 61.73 

Round  44, Train loss: 0.739, Test loss: 1.213, Test accuracy: 60.92 

Round  45, Train loss: 0.732, Test loss: 1.204, Test accuracy: 61.09 

Round  46, Train loss: 0.738, Test loss: 1.203, Test accuracy: 61.18 

Round  47, Train loss: 0.727, Test loss: 1.202, Test accuracy: 61.51 

Round  48, Train loss: 0.730, Test loss: 1.200, Test accuracy: 61.54 

Round  49, Train loss: 0.694, Test loss: 1.232, Test accuracy: 61.48 

Round  50, Train loss: 0.707, Test loss: 1.200, Test accuracy: 61.71 

Round  51, Train loss: 0.682, Test loss: 1.240, Test accuracy: 61.78 

Round  52, Train loss: 0.688, Test loss: 1.247, Test accuracy: 61.80 

Round  53, Train loss: 0.645, Test loss: 1.244, Test accuracy: 61.98 

Round  54, Train loss: 0.657, Test loss: 1.242, Test accuracy: 62.21 

Round  55, Train loss: 0.625, Test loss: 1.262, Test accuracy: 62.12 

Round  56, Train loss: 0.608, Test loss: 1.276, Test accuracy: 61.95 

Round  57, Train loss: 0.623, Test loss: 1.263, Test accuracy: 62.05 

Round  58, Train loss: 0.602, Test loss: 1.271, Test accuracy: 62.12 

Round  59, Train loss: 0.551, Test loss: 1.284, Test accuracy: 62.12 

Round  60, Train loss: 0.571, Test loss: 1.297, Test accuracy: 62.12 

Round  61, Train loss: 0.599, Test loss: 1.313, Test accuracy: 62.48 

Round  62, Train loss: 0.509, Test loss: 1.311, Test accuracy: 62.31 

Round  63, Train loss: 0.594, Test loss: 1.288, Test accuracy: 62.77 

Round  64, Train loss: 0.585, Test loss: 1.309, Test accuracy: 62.51 

Round  65, Train loss: 0.524, Test loss: 1.341, Test accuracy: 62.26 

Round  66, Train loss: 0.525, Test loss: 1.329, Test accuracy: 62.48 

Round  67, Train loss: 0.533, Test loss: 1.327, Test accuracy: 62.31 

Round  68, Train loss: 0.544, Test loss: 1.366, Test accuracy: 61.41 

Round  69, Train loss: 0.555, Test loss: 1.350, Test accuracy: 62.56 

Round  70, Train loss: 0.464, Test loss: 1.370, Test accuracy: 62.25 

Round  71, Train loss: 0.551, Test loss: 1.358, Test accuracy: 62.12 

Round  72, Train loss: 0.532, Test loss: 1.344, Test accuracy: 62.64 

Round  73, Train loss: 0.523, Test loss: 1.370, Test accuracy: 62.09 

Round  74, Train loss: 0.539, Test loss: 1.389, Test accuracy: 62.22 

Round  75, Train loss: 0.519, Test loss: 1.413, Test accuracy: 62.16 

Round  76, Train loss: 0.479, Test loss: 1.412, Test accuracy: 62.00 

Round  77, Train loss: 0.426, Test loss: 1.430, Test accuracy: 62.15 

Round  78, Train loss: 0.522, Test loss: 1.419, Test accuracy: 62.91 

Round  79, Train loss: 0.498, Test loss: 1.410, Test accuracy: 62.74 

Round  80, Train loss: 0.480, Test loss: 1.416, Test accuracy: 62.91 

Round  81, Train loss: 0.508, Test loss: 1.388, Test accuracy: 62.47 

Round  82, Train loss: 0.477, Test loss: 1.410, Test accuracy: 62.70 

Round  83, Train loss: 0.447, Test loss: 1.399, Test accuracy: 62.89 

Round  84, Train loss: 0.455, Test loss: 1.430, Test accuracy: 62.70 

Round  85, Train loss: 0.409, Test loss: 1.426, Test accuracy: 62.63 

Round  86, Train loss: 0.421, Test loss: 1.478, Test accuracy: 62.19 

Round  87, Train loss: 0.439, Test loss: 1.488, Test accuracy: 62.29 

Round  88, Train loss: 0.433, Test loss: 1.485, Test accuracy: 62.35 

Round  89, Train loss: 0.406, Test loss: 1.493, Test accuracy: 61.96 

Round  90, Train loss: 0.447, Test loss: 1.511, Test accuracy: 62.09 

Round  91, Train loss: 0.441, Test loss: 1.486, Test accuracy: 62.27 

Round  92, Train loss: 0.434, Test loss: 1.522, Test accuracy: 62.42 

Round  93, Train loss: 0.429, Test loss: 1.508, Test accuracy: 61.94 

Round  94, Train loss: 0.419, Test loss: 1.488, Test accuracy: 62.35 

Round  95, Train loss: 0.476, Test loss: 1.492, Test accuracy: 62.44 

Round  96, Train loss: 0.407, Test loss: 1.536, Test accuracy: 62.82 

Round  97, Train loss: 0.419, Test loss: 1.525, Test accuracy: 62.88 

Round  98, Train loss: 0.399, Test loss: 1.542, Test accuracy: 62.58 

Round  99, Train loss: 0.413, Test loss: 1.546, Test accuracy: 62.88 

Final Round, Train loss: 0.318, Test loss: 1.575, Test accuracy: 62.47 

Average accuracy final 10 rounds: 62.46666666666667 

2181.5166161060333
[1.3940134048461914, 2.5664145946502686, 3.600034475326538, 4.635284185409546, 5.6704652309417725, 6.705831050872803, 7.742094278335571, 8.779372453689575, 9.815118312835693, 10.848108530044556, 11.881092071533203, 12.915398359298706, 13.949086904525757, 14.983534097671509, 16.01602005958557, 17.052123546600342, 18.088430881500244, 19.127342462539673, 20.15912699699402, 21.1911678314209, 22.22221565246582, 23.393304347991943, 24.56608271598816, 25.73358416557312, 26.904709577560425, 28.075764179229736, 29.243566274642944, 30.407238960266113, 31.57857394218445, 32.74590444564819, 33.91030287742615, 35.066681146621704, 36.237942695617676, 37.40628147125244, 38.50429654121399, 39.605961084365845, 40.70229959487915, 41.87053322792053, 43.01431751251221, 44.16188907623291, 45.30739498138428, 46.448004961013794, 47.59537863731384, 48.751145124435425, 49.90610980987549, 51.060327768325806, 52.21438932418823, 53.23041033744812, 54.23123097419739, 55.23229670524597, 56.24023509025574, 57.24628806114197, 58.245924949645996, 59.24372720718384, 60.24342656135559, 61.24486494064331, 62.24527668952942, 63.26448106765747, 64.2721815109253, 65.28156208992004, 66.28794693946838, 67.29511213302612, 68.30078482627869, 69.48483037948608, 70.62953805923462, 71.78881359100342, 72.95011329650879, 74.15184140205383, 75.34395551681519, 76.50362491607666, 77.64581871032715, 78.76858115196228, 79.91882658004761, 81.13393568992615, 82.34067893028259, 83.61955261230469, 84.82321119308472, 86.071204662323, 87.30402207374573, 88.59463477134705, 89.8847439289093, 91.17030096054077, 92.46344542503357, 93.75542116165161, 95.06299328804016, 96.37076020240784, 97.66569638252258, 98.93499302864075, 100.08890128135681, 101.24121451377869, 102.39225625991821, 103.53846073150635, 104.72195792198181, 105.9095230102539, 107.09743022918701, 108.28625512123108, 109.4818320274353, 110.66473269462585, 111.85246419906616, 113.03805375099182, 114.97884893417358]
[23.54, 30.921666666666667, 34.86833333333333, 38.61833333333333, 40.915, 42.85, 44.02166666666667, 45.87166666666667, 46.625, 47.80833333333333, 48.821666666666665, 50.33166666666666, 50.92666666666667, 51.795, 52.91, 53.25333333333333, 53.815, 54.47666666666667, 55.196666666666665, 55.55, 56.25, 56.95666666666666, 57.35666666666667, 57.47666666666667, 58.125, 57.85166666666667, 58.82666666666667, 59.035, 58.35166666666667, 58.95666666666666, 59.211666666666666, 59.486666666666665, 59.403333333333336, 60.15833333333333, 60.053333333333335, 60.22666666666667, 60.04666666666667, 61.15833333333333, 60.873333333333335, 61.07833333333333, 60.693333333333335, 61.43333333333333, 61.14333333333333, 61.725, 60.92, 61.08833333333333, 61.17666666666667, 61.50666666666667, 61.541666666666664, 61.48166666666667, 61.71, 61.78, 61.80166666666667, 61.97666666666667, 62.21, 62.123333333333335, 61.95166666666667, 62.04666666666667, 62.125, 62.115, 62.12, 62.483333333333334, 62.30833333333333, 62.77333333333333, 62.513333333333335, 62.25666666666667, 62.475, 62.31, 61.415, 62.556666666666665, 62.25, 62.12, 62.638333333333335, 62.09, 62.218333333333334, 62.165, 62.0, 62.145, 62.905, 62.736666666666665, 62.905, 62.465, 62.70166666666667, 62.891666666666666, 62.695, 62.63333333333333, 62.193333333333335, 62.288333333333334, 62.35166666666667, 61.95666666666666, 62.095, 62.266666666666666, 62.41833333333334, 61.935, 62.35, 62.44, 62.82333333333333, 62.88333333333333, 62.575, 62.88, 62.47]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
lg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 8394 (global); Percentage 2.73 (8394/307842 
)
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_fedrep.py", line 237, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 656, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 54992 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
Traceback (most recent call last):
  File "main_apfl.py", line 147, in <module>
    w_global, w_local, loss, indd = local.train(net=net_local.to(args.device),w_local=w_local, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 354, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 53519 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Traceback (most recent call last):
  File "main_scaffold.py", line 150, in <module>
    w_local, loss, indd, count = local.train(net=net_local.to(args.device), idx=idx, lr=lr, c_list=c_list, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 237, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 56247 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
Traceback (most recent call last):
  File "main_ditto.py", line 182, in <module>
    w_k, loss, indd = local.train(net=net_global.to(args.device), idx=idx, lr=args.lr, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 504, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 53517 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 300, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_pfedme.py", line 236, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx],w_locals = w_locals)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 825, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 52198 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Traceback (most recent call last):
  File "main_fedpac.py", line 232, in <module>
    w_local, loss, indd, class_center_local, class_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1272, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 54431 is out of bounds for axis 0 with size 50000
Traceback (most recent call last):
  File "main_fedpac_k_means.py", line 18, in <module>
    from sklearn.cluster import KMeans
ModuleNotFoundError: No module named 'sklearn'
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.123, Test loss: 1.936, Test accuracy: 25.93 

Round   0, Global train loss: 1.123, Global test loss: 2.317, Global test accuracy: 15.36 

Round   1, Train loss: 0.974, Test loss: 2.040, Test accuracy: 36.19 

Round   1, Global train loss: 0.974, Global test loss: 3.055, Global test accuracy: 15.00 

Round   2, Train loss: 0.935, Test loss: 1.200, Test accuracy: 52.70 

Round   2, Global train loss: 0.935, Global test loss: 2.301, Global test accuracy: 22.65 

Round   3, Train loss: 0.792, Test loss: 1.165, Test accuracy: 50.83 

Round   3, Global train loss: 0.792, Global test loss: 2.288, Global test accuracy: 13.62 

Round   4, Train loss: 0.781, Test loss: 0.911, Test accuracy: 62.21 

Round   4, Global train loss: 0.781, Global test loss: 2.096, Global test accuracy: 23.06 

Round   5, Train loss: 0.686, Test loss: 0.845, Test accuracy: 64.23 

Round   5, Global train loss: 0.686, Global test loss: 2.009, Global test accuracy: 28.93 

Round   6, Train loss: 0.676, Test loss: 0.846, Test accuracy: 63.19 

Round   6, Global train loss: 0.676, Global test loss: 2.154, Global test accuracy: 16.83 

Round   7, Train loss: 0.656, Test loss: 0.831, Test accuracy: 64.93 

Round   7, Global train loss: 0.656, Global test loss: 2.277, Global test accuracy: 16.40 

Round   8, Train loss: 0.704, Test loss: 0.812, Test accuracy: 65.33 

Round   8, Global train loss: 0.704, Global test loss: 2.318, Global test accuracy: 16.11 

Round   9, Train loss: 0.664, Test loss: 0.815, Test accuracy: 64.89 

Round   9, Global train loss: 0.664, Global test loss: 2.257, Global test accuracy: 16.48 

Round  10, Train loss: 0.598, Test loss: 0.780, Test accuracy: 67.66 

Round  10, Global train loss: 0.598, Global test loss: 2.153, Global test accuracy: 24.66 

Round  11, Train loss: 0.650, Test loss: 0.792, Test accuracy: 68.17 

Round  11, Global train loss: 0.650, Global test loss: 2.137, Global test accuracy: 24.69 

Traceback (most recent call last):
  File "main_fedrep.py", line 237, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 682, in train
    batch_loss.append(loss.item())
RuntimeError: CUDA error: unspecified launch failure
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.133, Test loss: 1.998, Test accuracy: 25.38 

Round   0, Global train loss: 1.133, Global test loss: 2.366, Global test accuracy: 14.95 

Round   1, Train loss: 0.944, Test loss: 1.644, Test accuracy: 39.01 

Round   1, Global train loss: 0.944, Global test loss: 2.262, Global test accuracy: 21.18 

Round   2, Train loss: 0.838, Test loss: 1.521, Test accuracy: 45.09 

Round   2, Global train loss: 0.838, Global test loss: 2.188, Global test accuracy: 26.27 

Round   3, Train loss: 0.877, Test loss: 1.368, Test accuracy: 52.99 

Round   3, Global train loss: 0.877, Global test loss: 2.169, Global test accuracy: 34.48 

Round   4, Train loss: 0.712, Test loss: 1.401, Test accuracy: 53.37 

Round   4, Global train loss: 0.712, Global test loss: 2.386, Global test accuracy: 28.81 

Round   5, Train loss: 0.747, Test loss: 0.914, Test accuracy: 64.04 

Round   5, Global train loss: 0.747, Global test loss: 1.765, Global test accuracy: 40.13 

Round   6, Train loss: 0.723, Test loss: 0.797, Test accuracy: 66.79 

Round   6, Global train loss: 0.723, Global test loss: 1.728, Global test accuracy: 36.80 

Round   7, Train loss: 0.743, Test loss: 0.752, Test accuracy: 68.54 

Round   7, Global train loss: 0.743, Global test loss: 1.631, Global test accuracy: 42.61 

Round   8, Train loss: 0.689, Test loss: 0.757, Test accuracy: 70.04 

Round   8, Global train loss: 0.689, Global test loss: 1.900, Global test accuracy: 36.51 

Round   9, Train loss: 0.612, Test loss: 0.724, Test accuracy: 70.75 

Round   9, Global train loss: 0.612, Global test loss: 1.796, Global test accuracy: 38.43 

Round  10, Train loss: 0.632, Test loss: 0.696, Test accuracy: 72.11 

Round  10, Global train loss: 0.632, Global test loss: 1.647, Global test accuracy: 43.44 

Round  11, Train loss: 0.664, Test loss: 0.685, Test accuracy: 73.04 

Round  11, Global train loss: 0.664, Global test loss: 1.519, Global test accuracy: 48.68 

Round  12, Train loss: 0.658, Test loss: 0.711, Test accuracy: 72.60 

Round  12, Global train loss: 0.658, Global test loss: 1.795, Global test accuracy: 37.94 

Round  13, Train loss: 0.624, Test loss: 0.662, Test accuracy: 73.97 

Round  13, Global train loss: 0.624, Global test loss: 1.501, Global test accuracy: 49.11 

Round  14, Train loss: 0.595, Test loss: 0.592, Test accuracy: 75.38 

Round  14, Global train loss: 0.595, Global test loss: 1.648, Global test accuracy: 43.77 

Round  15, Train loss: 0.605, Test loss: 0.587, Test accuracy: 75.69 

Round  15, Global train loss: 0.605, Global test loss: 1.707, Global test accuracy: 45.22 

Round  16, Train loss: 0.590, Test loss: 0.582, Test accuracy: 75.96 

Round  16, Global train loss: 0.590, Global test loss: 1.482, Global test accuracy: 47.75 

Round  17, Train loss: 0.595, Test loss: 0.564, Test accuracy: 77.18 

Round  17, Global train loss: 0.595, Global test loss: 1.441, Global test accuracy: 49.16 

Round  18, Train loss: 0.581, Test loss: 0.559, Test accuracy: 77.46 

Round  18, Global train loss: 0.581, Global test loss: 1.785, Global test accuracy: 45.18 

Round  19, Train loss: 0.524, Test loss: 0.564, Test accuracy: 77.09 

Round  19, Global train loss: 0.524, Global test loss: 1.523, Global test accuracy: 47.46 

Round  20, Train loss: 0.498, Test loss: 0.554, Test accuracy: 77.59 

Round  20, Global train loss: 0.498, Global test loss: 1.601, Global test accuracy: 46.82 

Round  21, Train loss: 0.496, Test loss: 0.541, Test accuracy: 78.02 

Round  21, Global train loss: 0.496, Global test loss: 1.795, Global test accuracy: 47.18 

Round  22, Train loss: 0.545, Test loss: 0.536, Test accuracy: 78.37 

Round  22, Global train loss: 0.545, Global test loss: 1.566, Global test accuracy: 46.27 

Round  23, Train loss: 0.605, Test loss: 0.529, Test accuracy: 78.59 

Round  23, Global train loss: 0.605, Global test loss: 1.527, Global test accuracy: 46.72 

Round  24, Train loss: 0.462, Test loss: 0.529, Test accuracy: 78.99 

Round  24, Global train loss: 0.462, Global test loss: 1.499, Global test accuracy: 49.62 

Round  25, Train loss: 0.486, Test loss: 0.526, Test accuracy: 79.42 

Round  25, Global train loss: 0.486, Global test loss: 1.397, Global test accuracy: 51.36 

Round  26, Train loss: 0.510, Test loss: 0.530, Test accuracy: 78.99 

Round  26, Global train loss: 0.510, Global test loss: 1.430, Global test accuracy: 50.48 

Round  27, Train loss: 0.555, Test loss: 0.531, Test accuracy: 78.91 

Round  27, Global train loss: 0.555, Global test loss: 1.407, Global test accuracy: 50.47 

Round  28, Train loss: 0.552, Test loss: 0.525, Test accuracy: 79.16 

Round  28, Global train loss: 0.552, Global test loss: 1.419, Global test accuracy: 49.99 

Round  29, Train loss: 0.418, Test loss: 0.554, Test accuracy: 78.21 

Round  29, Global train loss: 0.418, Global test loss: 1.506, Global test accuracy: 49.66 

Round  30, Train loss: 0.414, Test loss: 0.535, Test accuracy: 79.00 

Round  30, Global train loss: 0.414, Global test loss: 1.310, Global test accuracy: 56.11 

Round  31, Train loss: 0.417, Test loss: 0.533, Test accuracy: 79.05 

Round  31, Global train loss: 0.417, Global test loss: 1.413, Global test accuracy: 53.46 

Round  32, Train loss: 0.416, Test loss: 0.511, Test accuracy: 79.95 

Round  32, Global train loss: 0.416, Global test loss: 1.510, Global test accuracy: 53.10 

Round  33, Train loss: 0.380, Test loss: 0.509, Test accuracy: 80.01 

Round  33, Global train loss: 0.380, Global test loss: 1.308, Global test accuracy: 57.76 

Round  34, Train loss: 0.504, Test loss: 0.497, Test accuracy: 80.65 

Round  34, Global train loss: 0.504, Global test loss: 1.333, Global test accuracy: 55.98 

Round  35, Train loss: 0.424, Test loss: 0.514, Test accuracy: 80.06 

Round  35, Global train loss: 0.424, Global test loss: 1.235, Global test accuracy: 58.39 

Round  36, Train loss: 0.468, Test loss: 0.513, Test accuracy: 80.40 

Round  36, Global train loss: 0.468, Global test loss: 1.286, Global test accuracy: 56.71 

Round  37, Train loss: 0.412, Test loss: 0.511, Test accuracy: 80.66 

Round  37, Global train loss: 0.412, Global test loss: 1.416, Global test accuracy: 53.30 

Round  38, Train loss: 0.477, Test loss: 0.524, Test accuracy: 80.08 

Round  38, Global train loss: 0.477, Global test loss: 1.231, Global test accuracy: 59.11 

Round  39, Train loss: 0.403, Test loss: 0.521, Test accuracy: 80.28 

Round  39, Global train loss: 0.403, Global test loss: 1.338, Global test accuracy: 56.24 

Round  40, Train loss: 0.353, Test loss: 0.503, Test accuracy: 81.03 

Round  40, Global train loss: 0.353, Global test loss: 1.301, Global test accuracy: 58.65 

Round  41, Train loss: 0.355, Test loss: 0.503, Test accuracy: 81.27 

Round  41, Global train loss: 0.355, Global test loss: 1.528, Global test accuracy: 50.89 

Round  42, Train loss: 0.348, Test loss: 0.507, Test accuracy: 81.23 

Round  42, Global train loss: 0.348, Global test loss: 1.332, Global test accuracy: 57.29 

Round  43, Train loss: 0.316, Test loss: 0.504, Test accuracy: 81.34 

Round  43, Global train loss: 0.316, Global test loss: 1.255, Global test accuracy: 58.79 

Round  44, Train loss: 0.401, Test loss: 0.496, Test accuracy: 81.59 

Round  44, Global train loss: 0.401, Global test loss: 1.119, Global test accuracy: 61.76 

Round  45, Train loss: 0.417, Test loss: 0.489, Test accuracy: 81.84 

Round  45, Global train loss: 0.417, Global test loss: 1.225, Global test accuracy: 58.84 

Round  46, Train loss: 0.311, Test loss: 0.484, Test accuracy: 81.98 

Round  46, Global train loss: 0.311, Global test loss: 1.295, Global test accuracy: 59.76 

Round  47, Train loss: 0.454, Test loss: 0.479, Test accuracy: 82.12 

Round  47, Global train loss: 0.454, Global test loss: 1.419, Global test accuracy: 53.01 

Round  48, Train loss: 0.370, Test loss: 0.475, Test accuracy: 82.53 

Round  48, Global train loss: 0.370, Global test loss: 1.310, Global test accuracy: 57.54 

Round  49, Train loss: 0.349, Test loss: 0.480, Test accuracy: 82.42 

Round  49, Global train loss: 0.349, Global test loss: 1.758, Global test accuracy: 50.54 

Round  50, Train loss: 0.344, Test loss: 0.507, Test accuracy: 81.57 

Round  50, Global train loss: 0.344, Global test loss: 1.274, Global test accuracy: 58.21 

Round  51, Train loss: 0.345, Test loss: 0.497, Test accuracy: 82.04 

Round  51, Global train loss: 0.345, Global test loss: 1.446, Global test accuracy: 54.64 

Round  52, Train loss: 0.349, Test loss: 0.480, Test accuracy: 82.58 

Round  52, Global train loss: 0.349, Global test loss: 1.234, Global test accuracy: 59.33 

Round  53, Train loss: 0.335, Test loss: 0.487, Test accuracy: 82.46 

Round  53, Global train loss: 0.335, Global test loss: 1.094, Global test accuracy: 63.17 

Round  54, Train loss: 0.318, Test loss: 0.507, Test accuracy: 81.79 

Round  54, Global train loss: 0.318, Global test loss: 1.190, Global test accuracy: 61.53 

Round  55, Train loss: 0.277, Test loss: 0.507, Test accuracy: 81.91 

Round  55, Global train loss: 0.277, Global test loss: 1.286, Global test accuracy: 58.32 

Round  56, Train loss: 0.354, Test loss: 0.512, Test accuracy: 81.64 

Round  56, Global train loss: 0.354, Global test loss: 1.324, Global test accuracy: 57.23 

Round  57, Train loss: 0.329, Test loss: 0.508, Test accuracy: 81.94 

Round  57, Global train loss: 0.329, Global test loss: 1.240, Global test accuracy: 59.46 

Round  58, Train loss: 0.324, Test loss: 0.489, Test accuracy: 82.56 

Round  58, Global train loss: 0.324, Global test loss: 1.185, Global test accuracy: 60.64 

Round  59, Train loss: 0.307, Test loss: 0.486, Test accuracy: 82.70 

Round  59, Global train loss: 0.307, Global test loss: 1.215, Global test accuracy: 61.22 

Round  60, Train loss: 0.285, Test loss: 0.503, Test accuracy: 82.63 

Round  60, Global train loss: 0.285, Global test loss: 1.190, Global test accuracy: 62.65 

Round  61, Train loss: 0.322, Test loss: 0.496, Test accuracy: 82.67 

Round  61, Global train loss: 0.322, Global test loss: 1.292, Global test accuracy: 58.17 

Round  62, Train loss: 0.269, Test loss: 0.484, Test accuracy: 83.00 

Round  62, Global train loss: 0.269, Global test loss: 1.113, Global test accuracy: 63.61 

Round  63, Train loss: 0.309, Test loss: 0.484, Test accuracy: 83.16 

Round  63, Global train loss: 0.309, Global test loss: 1.216, Global test accuracy: 60.60 

Round  64, Train loss: 0.362, Test loss: 0.490, Test accuracy: 82.99 

Round  64, Global train loss: 0.362, Global test loss: 1.411, Global test accuracy: 55.94 

Round  65, Train loss: 0.228, Test loss: 0.470, Test accuracy: 83.60 

Round  65, Global train loss: 0.228, Global test loss: 1.303, Global test accuracy: 60.98 

Round  66, Train loss: 0.277, Test loss: 0.479, Test accuracy: 83.58 

Round  66, Global train loss: 0.277, Global test loss: 1.161, Global test accuracy: 63.76 

Round  67, Train loss: 0.293, Test loss: 0.492, Test accuracy: 83.24 

Round  67, Global train loss: 0.293, Global test loss: 1.445, Global test accuracy: 56.58 

Round  68, Train loss: 0.302, Test loss: 0.479, Test accuracy: 83.52 

Round  68, Global train loss: 0.302, Global test loss: 1.160, Global test accuracy: 61.89 

Round  69, Train loss: 0.278, Test loss: 0.483, Test accuracy: 83.59 

Round  69, Global train loss: 0.278, Global test loss: 1.339, Global test accuracy: 58.36 

Round  70, Train loss: 0.260, Test loss: 0.507, Test accuracy: 83.06 

Round  70, Global train loss: 0.260, Global test loss: 1.447, Global test accuracy: 57.01 

Round  71, Train loss: 0.262, Test loss: 0.509, Test accuracy: 83.18 

Round  71, Global train loss: 0.262, Global test loss: 1.297, Global test accuracy: 60.57 

Round  72, Train loss: 0.215, Test loss: 0.493, Test accuracy: 83.72 

Round  72, Global train loss: 0.215, Global test loss: 1.130, Global test accuracy: 64.23 

Round  73, Train loss: 0.287, Test loss: 0.498, Test accuracy: 83.28 

Round  73, Global train loss: 0.287, Global test loss: 1.257, Global test accuracy: 60.56 

Round  74, Train loss: 0.246, Test loss: 0.481, Test accuracy: 83.84 

Round  74, Global train loss: 0.246, Global test loss: 1.336, Global test accuracy: 59.56 

Round  75, Train loss: 0.257, Test loss: 0.495, Test accuracy: 83.52 

Round  75, Global train loss: 0.257, Global test loss: 1.202, Global test accuracy: 62.96 

Round  76, Train loss: 0.251, Test loss: 0.495, Test accuracy: 83.48 

Round  76, Global train loss: 0.251, Global test loss: 1.482, Global test accuracy: 58.12 

Round  77, Train loss: 0.255, Test loss: 0.497, Test accuracy: 83.70 

Round  77, Global train loss: 0.255, Global test loss: 1.253, Global test accuracy: 62.41 

Round  78, Train loss: 0.212, Test loss: 0.497, Test accuracy: 83.74 

Round  78, Global train loss: 0.212, Global test loss: 1.296, Global test accuracy: 62.68 

Round  79, Train loss: 0.259, Test loss: 0.479, Test accuracy: 83.95 

Round  79, Global train loss: 0.259, Global test loss: 1.218, Global test accuracy: 62.53 

Round  80, Train loss: 0.217, Test loss: 0.512, Test accuracy: 82.99 

Round  80, Global train loss: 0.217, Global test loss: 1.296, Global test accuracy: 61.93 

Round  81, Train loss: 0.289, Test loss: 0.506, Test accuracy: 83.52 

Round  81, Global train loss: 0.289, Global test loss: 1.155, Global test accuracy: 63.66 

Round  82, Train loss: 0.196, Test loss: 0.503, Test accuracy: 83.67 

Round  82, Global train loss: 0.196, Global test loss: 1.129, Global test accuracy: 64.52 

Round  83, Train loss: 0.218, Test loss: 0.491, Test accuracy: 84.12 

Round  83, Global train loss: 0.218, Global test loss: 1.404, Global test accuracy: 58.66 

Round  84, Train loss: 0.277, Test loss: 0.496, Test accuracy: 83.96 

Round  84, Global train loss: 0.277, Global test loss: 1.230, Global test accuracy: 61.38 

Round  85, Train loss: 0.225, Test loss: 0.490, Test accuracy: 84.05 

Round  85, Global train loss: 0.225, Global test loss: 1.460, Global test accuracy: 58.39 

Round  86, Train loss: 0.222, Test loss: 0.505, Test accuracy: 83.91 

Round  86, Global train loss: 0.222, Global test loss: 1.296, Global test accuracy: 61.10 

Round  87, Train loss: 0.203, Test loss: 0.502, Test accuracy: 84.16 

Round  87, Global train loss: 0.203, Global test loss: 1.478, Global test accuracy: 59.33 

Round  88, Train loss: 0.203, Test loss: 0.498, Test accuracy: 84.25 

Round  88, Global train loss: 0.203, Global test loss: 1.271, Global test accuracy: 64.10 

Round  89, Train loss: 0.211, Test loss: 0.502, Test accuracy: 83.92 

Round  89, Global train loss: 0.211, Global test loss: 1.304, Global test accuracy: 63.16 

Round  90, Train loss: 0.164, Test loss: 0.512, Test accuracy: 83.79 

Round  90, Global train loss: 0.164, Global test loss: 1.332, Global test accuracy: 63.36 

Round  91, Train loss: 0.274, Test loss: 0.519, Test accuracy: 83.77 

Round  91, Global train loss: 0.274, Global test loss: 1.270, Global test accuracy: 62.31 

Round  92, Train loss: 0.228, Test loss: 0.510, Test accuracy: 84.04 

Round  92, Global train loss: 0.228, Global test loss: 1.458, Global test accuracy: 59.84 

Round  93, Train loss: 0.186, Test loss: 0.508, Test accuracy: 84.19 

Round  93, Global train loss: 0.186, Global test loss: 1.248, Global test accuracy: 62.07 

Round  94, Train loss: 0.158, Test loss: 0.493, Test accuracy: 84.66 

Round  94, Global train loss: 0.158, Global test loss: 1.509, Global test accuracy: 59.07 

Round  95, Train loss: 0.261, Test loss: 0.505, Test accuracy: 84.28 

Round  95, Global train loss: 0.261, Global test loss: 1.437, Global test accuracy: 58.93 

Round  96, Train loss: 0.197, Test loss: 0.506, Test accuracy: 84.41 

Round  96, Global train loss: 0.197, Global test loss: 1.584, Global test accuracy: 58.16 

Round  97, Train loss: 0.220, Test loss: 0.506, Test accuracy: 84.42 

Round  97, Global train loss: 0.220, Global test loss: 1.731, Global test accuracy: 56.36 

Round  98, Train loss: 0.199, Test loss: 0.500, Test accuracy: 84.41 

Round  98, Global train loss: 0.199, Global test loss: 1.276, Global test accuracy: 62.11 

Round  99, Train loss: 0.210, Test loss: 0.509, Test accuracy: 84.24 

Round  99, Global train loss: 0.210, Global test loss: 1.190, Global test accuracy: 63.18 

Final Round, Train loss: 0.170, Test loss: 0.546, Test accuracy: 84.31 

Final Round, Global train loss: 0.170, Global test loss: 1.190, Global test accuracy: 63.18 

Average accuracy final 10 rounds: 84.22 

Average global accuracy final 10 rounds: 60.53777777777778 

1642.2921442985535
[1.3841865062713623, 2.512662887573242, 3.633185386657715, 4.759441375732422, 5.891201972961426, 7.02735161781311, 8.166226148605347, 9.302679538726807, 10.413006067276001, 11.546401023864746, 12.691011905670166, 13.834249019622803, 14.975878953933716, 16.12107229232788, 17.265312671661377, 18.430400848388672, 19.58908987045288, 20.75281834602356, 21.91059374809265, 23.075018644332886, 24.237796783447266, 25.391573429107666, 26.555130004882812, 27.719260454177856, 28.887518167495728, 30.04073452949524, 31.199530124664307, 32.35765051841736, 33.515514850616455, 34.67626953125, 35.836872577667236, 36.99534749984741, 38.153804302215576, 39.31138253211975, 40.464823961257935, 41.628228187561035, 42.78530430793762, 43.94817137718201, 45.112555503845215, 46.27526021003723, 47.432326316833496, 48.573758363723755, 49.71905708312988, 50.85980272293091, 52.01257276535034, 53.15682935714722, 54.30032014846802, 55.4476592540741, 56.607786893844604, 57.77309989929199, 58.93305683135986, 60.0810124874115, 61.244351387023926, 62.41871476173401, 63.601147413253784, 64.79079127311707, 65.98303508758545, 67.17586660385132, 68.35955786705017, 69.54143047332764, 70.7297830581665, 71.91004800796509, 73.10261702537537, 74.29830265045166, 75.48677706718445, 76.66923022270203, 77.85310339927673, 79.03153944015503, 80.22517776489258, 81.40743851661682, 82.57710671424866, 83.75099992752075, 84.91439723968506, 86.08160924911499, 87.24761390686035, 88.41806101799011, 89.58845233917236, 90.7593183517456, 91.93234658241272, 93.11410617828369, 94.28093957901001, 95.44518828392029, 96.61566591262817, 97.79125380516052, 98.95566821098328, 100.12130880355835, 101.29372477531433, 102.45951819419861, 103.6184949874878, 104.8052225112915, 105.99253463745117, 107.1721625328064, 108.36187195777893, 109.55980038642883, 110.75725078582764, 111.94773364067078, 113.13679099082947, 114.33547186851501, 115.52021169662476, 116.7057409286499, 119.03360986709595]
[25.383333333333333, 39.01111111111111, 45.08888888888889, 52.98888888888889, 53.36666666666667, 64.04444444444445, 66.79444444444445, 68.54444444444445, 70.03888888888889, 70.75, 72.11111111111111, 73.04444444444445, 72.6, 73.97222222222223, 75.38333333333334, 75.68888888888888, 75.95555555555555, 77.17777777777778, 77.45555555555555, 77.08888888888889, 77.58888888888889, 78.02222222222223, 78.36666666666666, 78.58888888888889, 78.99444444444444, 79.41666666666667, 78.9888888888889, 78.90555555555555, 79.16111111111111, 78.21111111111111, 79.0, 79.05, 79.95, 80.00555555555556, 80.65, 80.05555555555556, 80.4, 80.66111111111111, 80.07777777777778, 80.28333333333333, 81.02777777777777, 81.26666666666667, 81.23333333333333, 81.34444444444445, 81.58888888888889, 81.84444444444445, 81.98333333333333, 82.11666666666666, 82.53333333333333, 82.41666666666667, 81.57222222222222, 82.03888888888889, 82.57777777777778, 82.45555555555555, 81.78888888888889, 81.91111111111111, 81.63888888888889, 81.94444444444444, 82.56111111111112, 82.7, 82.62777777777778, 82.67222222222222, 83.0, 83.16111111111111, 82.99444444444444, 83.6, 83.58333333333333, 83.24444444444444, 83.51666666666667, 83.58888888888889, 83.06111111111112, 83.18333333333334, 83.72222222222223, 83.28333333333333, 83.83888888888889, 83.52222222222223, 83.48333333333333, 83.7, 83.7388888888889, 83.95, 82.9888888888889, 83.52222222222223, 83.67222222222222, 84.11666666666666, 83.96111111111111, 84.05, 83.91111111111111, 84.15555555555555, 84.25, 83.91666666666667, 83.79444444444445, 83.76666666666667, 84.03888888888889, 84.18888888888888, 84.65555555555555, 84.27777777777777, 84.41111111111111, 84.41666666666667, 84.41111111111111, 84.2388888888889, 84.31111111111112]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.285, Test loss: 2.230, Test accuracy: 17.89 

Round   1, Train loss: 2.161, Test loss: 2.023, Test accuracy: 27.14 

Round   2, Train loss: 2.032, Test loss: 1.917, Test accuracy: 30.28 

Round   3, Train loss: 1.920, Test loss: 1.853, Test accuracy: 32.72 

Round   4, Train loss: 1.832, Test loss: 1.764, Test accuracy: 35.89 

Round   5, Train loss: 1.764, Test loss: 1.706, Test accuracy: 37.06 

Round   6, Train loss: 1.709, Test loss: 1.670, Test accuracy: 38.80 

Round   7, Train loss: 1.667, Test loss: 1.634, Test accuracy: 40.34 

Round   8, Train loss: 1.635, Test loss: 1.592, Test accuracy: 41.59 

Round   9, Train loss: 1.598, Test loss: 1.560, Test accuracy: 42.71 

Round  10, Train loss: 1.536, Test loss: 1.537, Test accuracy: 43.71 

Round  11, Train loss: 1.516, Test loss: 1.513, Test accuracy: 45.07 

Round  12, Train loss: 1.500, Test loss: 1.488, Test accuracy: 45.69 

Round  13, Train loss: 1.459, Test loss: 1.480, Test accuracy: 46.07 

Round  14, Train loss: 1.451, Test loss: 1.461, Test accuracy: 46.81 

Round  15, Train loss: 1.443, Test loss: 1.448, Test accuracy: 47.56 

Round  16, Train loss: 1.409, Test loss: 1.451, Test accuracy: 47.66 

Round  17, Train loss: 1.422, Test loss: 1.433, Test accuracy: 48.30 

Round  18, Train loss: 1.389, Test loss: 1.397, Test accuracy: 49.60 

Round  19, Train loss: 1.375, Test loss: 1.386, Test accuracy: 49.96 

Round  20, Train loss: 1.357, Test loss: 1.371, Test accuracy: 50.84 

Round  21, Train loss: 1.323, Test loss: 1.368, Test accuracy: 50.91 

Round  22, Train loss: 1.306, Test loss: 1.350, Test accuracy: 51.45 

Round  23, Train loss: 1.282, Test loss: 1.331, Test accuracy: 52.21 

Round  24, Train loss: 1.251, Test loss: 1.333, Test accuracy: 52.31 

Round  25, Train loss: 1.233, Test loss: 1.314, Test accuracy: 53.06 

Round  26, Train loss: 1.253, Test loss: 1.313, Test accuracy: 53.33 

Round  27, Train loss: 1.264, Test loss: 1.285, Test accuracy: 54.65 

Round  28, Train loss: 1.215, Test loss: 1.304, Test accuracy: 53.86 

Round  29, Train loss: 1.186, Test loss: 1.285, Test accuracy: 54.64 

Round  30, Train loss: 1.130, Test loss: 1.288, Test accuracy: 54.28 

Round  31, Train loss: 1.151, Test loss: 1.258, Test accuracy: 55.35 

Round  32, Train loss: 1.151, Test loss: 1.241, Test accuracy: 56.19 

Round  33, Train loss: 1.112, Test loss: 1.230, Test accuracy: 56.47 

Round  34, Train loss: 1.121, Test loss: 1.220, Test accuracy: 57.09 

Round  35, Train loss: 1.085, Test loss: 1.226, Test accuracy: 57.39 

Round  36, Train loss: 1.115, Test loss: 1.219, Test accuracy: 57.60 

Round  37, Train loss: 1.061, Test loss: 1.199, Test accuracy: 58.20 

Round  38, Train loss: 1.042, Test loss: 1.191, Test accuracy: 58.45 

Round  39, Train loss: 1.025, Test loss: 1.197, Test accuracy: 58.06 

Round  40, Train loss: 1.045, Test loss: 1.201, Test accuracy: 58.15 

Round  41, Train loss: 1.029, Test loss: 1.186, Test accuracy: 58.65 

Round  42, Train loss: 1.050, Test loss: 1.185, Test accuracy: 59.23 

Round  43, Train loss: 0.977, Test loss: 1.183, Test accuracy: 59.11 

Round  44, Train loss: 1.014, Test loss: 1.192, Test accuracy: 58.87 

Round  45, Train loss: 0.981, Test loss: 1.183, Test accuracy: 59.79 

Round  46, Train loss: 0.983, Test loss: 1.185, Test accuracy: 59.67 

Round  47, Train loss: 0.965, Test loss: 1.172, Test accuracy: 59.66 

Round  48, Train loss: 0.938, Test loss: 1.159, Test accuracy: 60.00 

Round  49, Train loss: 0.975, Test loss: 1.153, Test accuracy: 60.29 

Round  50, Train loss: 0.931, Test loss: 1.142, Test accuracy: 60.66 

Round  51, Train loss: 0.916, Test loss: 1.152, Test accuracy: 60.48 

Round  52, Train loss: 0.911, Test loss: 1.157, Test accuracy: 60.67 

Round  53, Train loss: 0.890, Test loss: 1.162, Test accuracy: 60.65 

Round  54, Train loss: 0.877, Test loss: 1.170, Test accuracy: 60.67 

Round  55, Train loss: 0.880, Test loss: 1.163, Test accuracy: 60.70 

Round  56, Train loss: 0.858, Test loss: 1.153, Test accuracy: 60.83 

Round  57, Train loss: 0.811, Test loss: 1.185, Test accuracy: 60.08 

Round  58, Train loss: 0.863, Test loss: 1.186, Test accuracy: 60.29 

Round  59, Train loss: 0.857, Test loss: 1.195, Test accuracy: 60.42 

Round  60, Train loss: 0.848, Test loss: 1.172, Test accuracy: 60.70 

Round  61, Train loss: 0.799, Test loss: 1.174, Test accuracy: 60.62 

Round  62, Train loss: 0.789, Test loss: 1.163, Test accuracy: 61.01 

Round  63, Train loss: 0.834, Test loss: 1.172, Test accuracy: 61.09 

Round  64, Train loss: 0.760, Test loss: 1.177, Test accuracy: 60.98 

Round  65, Train loss: 0.766, Test loss: 1.181, Test accuracy: 61.22 

Round  66, Train loss: 0.773, Test loss: 1.183, Test accuracy: 60.98 

Round  67, Train loss: 0.735, Test loss: 1.185, Test accuracy: 61.12 

Round  68, Train loss: 0.729, Test loss: 1.204, Test accuracy: 61.21 

Round  69, Train loss: 0.772, Test loss: 1.162, Test accuracy: 61.69 

Round  70, Train loss: 0.730, Test loss: 1.175, Test accuracy: 61.90 

Round  71, Train loss: 0.741, Test loss: 1.195, Test accuracy: 61.70 

Round  72, Train loss: 0.746, Test loss: 1.181, Test accuracy: 61.72 

Round  73, Train loss: 0.743, Test loss: 1.189, Test accuracy: 61.62 

Round  74, Train loss: 0.726, Test loss: 1.184, Test accuracy: 61.70 

Round  75, Train loss: 0.763, Test loss: 1.186, Test accuracy: 61.44 

Round  76, Train loss: 0.763, Test loss: 1.195, Test accuracy: 61.70 

Round  77, Train loss: 0.712, Test loss: 1.190, Test accuracy: 62.20 

Round  78, Train loss: 0.641, Test loss: 1.193, Test accuracy: 61.99 

Round  79, Train loss: 0.730, Test loss: 1.186, Test accuracy: 62.00 

Round  80, Train loss: 0.656, Test loss: 1.178, Test accuracy: 62.26 

Round  81, Train loss: 0.667, Test loss: 1.204, Test accuracy: 61.92 

Round  82, Train loss: 0.657, Test loss: 1.195, Test accuracy: 62.27 

Round  83, Train loss: 0.697, Test loss: 1.214, Test accuracy: 61.95 

Round  84, Train loss: 0.663, Test loss: 1.217, Test accuracy: 62.30 

Round  85, Train loss: 0.659, Test loss: 1.223, Test accuracy: 62.10 

Round  86, Train loss: 0.666, Test loss: 1.210, Test accuracy: 62.60 

Round  87, Train loss: 0.608, Test loss: 1.208, Test accuracy: 62.55 

Round  88, Train loss: 0.618, Test loss: 1.240, Test accuracy: 62.32 

Round  89, Train loss: 0.609, Test loss: 1.261, Test accuracy: 62.07 

Round  90, Train loss: 0.645, Test loss: 1.243, Test accuracy: 62.63 

Round  91, Train loss: 0.671, Test loss: 1.245, Test accuracy: 62.05 

Round  92, Train loss: 0.618, Test loss: 1.280, Test accuracy: 61.98 

Round  93, Train loss: 0.606, Test loss: 1.234, Test accuracy: 62.13 

Round  94, Train loss: 0.636, Test loss: 1.258, Test accuracy: 62.47 

Round  95, Train loss: 0.592, Test loss: 1.241, Test accuracy: 62.71 

Round  96, Train loss: 0.654, Test loss: 1.263, Test accuracy: 62.25 

Round  97, Train loss: 0.554, Test loss: 1.284, Test accuracy: 61.85 

Round  98, Train loss: 0.566, Test loss: 1.289, Test accuracy: 62.14 

Round  99, Train loss: 0.582, Test loss: 1.256, Test accuracy: 62.13 

Final Round, Train loss: 0.513, Test loss: 1.265, Test accuracy: 62.40 

Average accuracy final 10 rounds: 62.235 

2234.060107946396
[1.3277359008789062, 2.417482614517212, 3.5147950649261475, 4.60839581489563, 5.709510564804077, 6.811692237854004, 7.90868878364563, 9.015716791152954, 10.11358380317688, 11.221843242645264, 12.336708068847656, 13.432828187942505, 14.537271976470947, 15.639048099517822, 16.73820686340332, 17.84095811843872, 18.944258213043213, 20.03695583343506, 21.139198541641235, 22.227400064468384, 23.320839166641235, 24.417381286621094, 25.51654863357544, 26.60979151725769, 27.71080780029297, 28.724185943603516, 29.72004270553589, 30.718636512756348, 31.71294093132019, 32.707990884780884, 33.70763182640076, 34.70954895019531, 35.711464166641235, 36.71444034576416, 37.71541905403137, 38.71226453781128, 39.710538387298584, 40.712217569351196, 41.70223259925842, 42.70621609687805, 43.7063090801239, 44.70139956474304, 45.701677083969116, 46.69629406929016, 47.70205760002136, 48.699594020843506, 49.70474720001221, 50.70689296722412, 51.70780801773071, 52.705944538116455, 53.70889115333557, 54.70366668701172, 55.70463752746582, 56.7056941986084, 57.70055890083313, 58.70222592353821, 59.70799493789673, 60.70552372932434, 61.69984316825867, 62.70099329948425, 63.69531989097595, 64.69213390350342, 65.68343949317932, 66.6837112903595, 67.68493008613586, 68.67182469367981, 69.66716456413269, 70.65335655212402, 71.65015840530396, 72.64655661582947, 73.64126992225647, 74.63186764717102, 75.62261056900024, 76.61100387573242, 77.60679745674133, 78.59516835212708, 79.58564400672913, 80.5958092212677, 81.59627437591553, 82.59801745414734, 83.59803676605225, 84.59764337539673, 85.61177968978882, 86.61218190193176, 87.61541199684143, 88.6155481338501, 89.64932298660278, 90.68326783180237, 91.72091674804688, 92.74902153015137, 93.82960200309753, 94.92543315887451, 96.00988674163818, 97.10284399986267, 98.18763256072998, 99.26843428611755, 100.35819935798645, 101.44025540351868, 102.5317907333374, 103.62096095085144, 105.59962487220764]
[17.888333333333332, 27.14, 30.281666666666666, 32.72, 35.891666666666666, 37.056666666666665, 38.795, 40.34, 41.593333333333334, 42.71, 43.70666666666666, 45.06666666666667, 45.69166666666667, 46.06666666666667, 46.81166666666667, 47.55833333333333, 47.65833333333333, 48.305, 49.596666666666664, 49.958333333333336, 50.836666666666666, 50.91166666666667, 51.45166666666667, 52.208333333333336, 52.31333333333333, 53.065, 53.325, 54.65, 53.858333333333334, 54.638333333333335, 54.28333333333333, 55.35333333333333, 56.185, 56.471666666666664, 57.095, 57.39333333333333, 57.60166666666667, 58.205, 58.445, 58.06166666666667, 58.15, 58.651666666666664, 59.22833333333333, 59.10666666666667, 58.865, 59.788333333333334, 59.666666666666664, 59.66, 59.998333333333335, 60.291666666666664, 60.656666666666666, 60.483333333333334, 60.666666666666664, 60.651666666666664, 60.67333333333333, 60.70166666666667, 60.83, 60.07833333333333, 60.29333333333334, 60.425, 60.705, 60.625, 61.00833333333333, 61.085, 60.98, 61.22, 60.97833333333333, 61.11666666666667, 61.208333333333336, 61.685, 61.89666666666667, 61.70333333333333, 61.721666666666664, 61.61666666666667, 61.705, 61.435, 61.7, 62.20333333333333, 61.98833333333334, 62.00333333333333, 62.25666666666667, 61.916666666666664, 62.26833333333333, 61.946666666666665, 62.295, 62.105, 62.605, 62.545, 62.321666666666665, 62.068333333333335, 62.63, 62.053333333333335, 61.985, 62.13, 62.47, 62.708333333333336, 62.251666666666665, 61.85333333333333, 62.14, 62.12833333333333, 62.4]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedper
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.204, Test loss: 2.065, Test accuracy: 24.27 

Round   1, Train loss: 2.010, Test loss: 1.923, Test accuracy: 30.27 

Round   2, Train loss: 1.899, Test loss: 1.780, Test accuracy: 35.47 

Round   3, Train loss: 1.781, Test loss: 1.687, Test accuracy: 38.25 

Round   4, Train loss: 1.707, Test loss: 1.633, Test accuracy: 39.81 

Round   5, Train loss: 1.660, Test loss: 1.568, Test accuracy: 42.33 

Round   6, Train loss: 1.603, Test loss: 1.540, Test accuracy: 44.16 

Round   7, Train loss: 1.536, Test loss: 1.494, Test accuracy: 45.82 

Round   8, Train loss: 1.520, Test loss: 1.493, Test accuracy: 45.86 

Round   9, Train loss: 1.471, Test loss: 1.432, Test accuracy: 48.17 

Round  10, Train loss: 1.420, Test loss: 1.414, Test accuracy: 48.47 

Round  11, Train loss: 1.424, Test loss: 1.386, Test accuracy: 50.23 

Round  12, Train loss: 1.371, Test loss: 1.363, Test accuracy: 50.67 

Round  13, Train loss: 1.341, Test loss: 1.353, Test accuracy: 51.51 

Round  14, Train loss: 1.314, Test loss: 1.322, Test accuracy: 52.43 

Round  15, Train loss: 1.341, Test loss: 1.304, Test accuracy: 52.84 

Round  16, Train loss: 1.280, Test loss: 1.282, Test accuracy: 53.80 

Round  17, Train loss: 1.206, Test loss: 1.280, Test accuracy: 54.23 

Round  18, Train loss: 1.213, Test loss: 1.257, Test accuracy: 54.96 

Round  19, Train loss: 1.180, Test loss: 1.246, Test accuracy: 55.73 

Round  20, Train loss: 1.129, Test loss: 1.234, Test accuracy: 56.39 

Round  21, Train loss: 1.118, Test loss: 1.217, Test accuracy: 56.72 

Round  22, Train loss: 1.089, Test loss: 1.223, Test accuracy: 56.91 

Round  23, Train loss: 1.066, Test loss: 1.208, Test accuracy: 57.67 

Round  24, Train loss: 1.064, Test loss: 1.210, Test accuracy: 57.21 

Round  25, Train loss: 1.041, Test loss: 1.196, Test accuracy: 58.34 

Round  26, Train loss: 0.993, Test loss: 1.213, Test accuracy: 57.71 

Round  27, Train loss: 0.988, Test loss: 1.197, Test accuracy: 58.74 

Round  28, Train loss: 0.973, Test loss: 1.205, Test accuracy: 58.85 

Round  29, Train loss: 0.978, Test loss: 1.197, Test accuracy: 58.69 

Round  30, Train loss: 0.951, Test loss: 1.204, Test accuracy: 58.90 

Round  31, Train loss: 0.928, Test loss: 1.199, Test accuracy: 59.21 

Round  32, Train loss: 0.921, Test loss: 1.193, Test accuracy: 59.87 

Round  33, Train loss: 0.857, Test loss: 1.212, Test accuracy: 59.62 

Round  34, Train loss: 0.842, Test loss: 1.192, Test accuracy: 59.89 

Round  35, Train loss: 0.835, Test loss: 1.207, Test accuracy: 59.80 

Round  36, Train loss: 0.831, Test loss: 1.215, Test accuracy: 60.49 

Round  37, Train loss: 0.849, Test loss: 1.207, Test accuracy: 60.09 

Round  38, Train loss: 0.881, Test loss: 1.204, Test accuracy: 60.06 

Round  39, Train loss: 0.818, Test loss: 1.200, Test accuracy: 60.48 

Round  40, Train loss: 0.767, Test loss: 1.208, Test accuracy: 60.64 

Round  41, Train loss: 0.780, Test loss: 1.214, Test accuracy: 60.40 

Round  42, Train loss: 0.773, Test loss: 1.213, Test accuracy: 60.86 

Round  43, Train loss: 0.718, Test loss: 1.255, Test accuracy: 60.03 

Round  44, Train loss: 0.734, Test loss: 1.252, Test accuracy: 60.44 

Round  45, Train loss: 0.702, Test loss: 1.250, Test accuracy: 60.52 

Round  46, Train loss: 0.731, Test loss: 1.220, Test accuracy: 61.23 

Round  47, Train loss: 0.689, Test loss: 1.242, Test accuracy: 60.95 

Round  48, Train loss: 0.671, Test loss: 1.261, Test accuracy: 61.24 

Round  49, Train loss: 0.633, Test loss: 1.281, Test accuracy: 60.77 

Round  50, Train loss: 0.668, Test loss: 1.305, Test accuracy: 61.00 

Round  51, Train loss: 0.702, Test loss: 1.283, Test accuracy: 61.00 

Round  52, Train loss: 0.646, Test loss: 1.282, Test accuracy: 61.18 

Round  53, Train loss: 0.678, Test loss: 1.289, Test accuracy: 61.44 

Round  54, Train loss: 0.632, Test loss: 1.280, Test accuracy: 61.24 

Round  55, Train loss: 0.653, Test loss: 1.313, Test accuracy: 61.41 

Round  56, Train loss: 0.653, Test loss: 1.315, Test accuracy: 61.25 

Round  57, Train loss: 0.617, Test loss: 1.318, Test accuracy: 61.50 

Round  58, Train loss: 0.570, Test loss: 1.364, Test accuracy: 61.32 

Round  59, Train loss: 0.612, Test loss: 1.316, Test accuracy: 61.51 

Round  60, Train loss: 0.582, Test loss: 1.357, Test accuracy: 61.07 

Round  61, Train loss: 0.580, Test loss: 1.348, Test accuracy: 61.59 

Round  62, Train loss: 0.573, Test loss: 1.341, Test accuracy: 61.57 

Round  63, Train loss: 0.528, Test loss: 1.384, Test accuracy: 61.11 

Round  64, Train loss: 0.518, Test loss: 1.380, Test accuracy: 61.50 

Round  65, Train loss: 0.534, Test loss: 1.400, Test accuracy: 61.32 

Round  66, Train loss: 0.581, Test loss: 1.395, Test accuracy: 61.24 

Round  67, Train loss: 0.514, Test loss: 1.410, Test accuracy: 61.06 

Round  68, Train loss: 0.538, Test loss: 1.417, Test accuracy: 61.27 

Round  69, Train loss: 0.499, Test loss: 1.432, Test accuracy: 61.79 

Round  70, Train loss: 0.529, Test loss: 1.428, Test accuracy: 61.02 

Round  71, Train loss: 0.487, Test loss: 1.457, Test accuracy: 61.30 

Round  72, Train loss: 0.458, Test loss: 1.471, Test accuracy: 61.19 

Round  73, Train loss: 0.469, Test loss: 1.465, Test accuracy: 61.27 

Round  74, Train loss: 0.494, Test loss: 1.461, Test accuracy: 61.54 

Round  75, Train loss: 0.465, Test loss: 1.448, Test accuracy: 61.39 

Round  76, Train loss: 0.453, Test loss: 1.458, Test accuracy: 61.65 

Round  77, Train loss: 0.431, Test loss: 1.509, Test accuracy: 61.52 

Round  78, Train loss: 0.485, Test loss: 1.485, Test accuracy: 61.21 

Round  79, Train loss: 0.436, Test loss: 1.538, Test accuracy: 61.30 

Round  80, Train loss: 0.457, Test loss: 1.554, Test accuracy: 60.97 

Round  81, Train loss: 0.421, Test loss: 1.560, Test accuracy: 61.06 

Round  82, Train loss: 0.472, Test loss: 1.544, Test accuracy: 60.93 

Round  83, Train loss: 0.486, Test loss: 1.533, Test accuracy: 61.34 

Round  84, Train loss: 0.451, Test loss: 1.558, Test accuracy: 61.00 

Round  85, Train loss: 0.456, Test loss: 1.543, Test accuracy: 61.38 

Round  86, Train loss: 0.501, Test loss: 1.568, Test accuracy: 61.32 

Round  87, Train loss: 0.429, Test loss: 1.529, Test accuracy: 61.48 

Round  88, Train loss: 0.488, Test loss: 1.560, Test accuracy: 61.40 

Round  89, Train loss: 0.445, Test loss: 1.602, Test accuracy: 61.24 

Round  90, Train loss: 0.404, Test loss: 1.590, Test accuracy: 61.36 

Round  91, Train loss: 0.423, Test loss: 1.539, Test accuracy: 61.27 

Round  92, Train loss: 0.392, Test loss: 1.585, Test accuracy: 61.35 

Round  93, Train loss: 0.383, Test loss: 1.624, Test accuracy: 61.60 

Round  94, Train loss: 0.384, Test loss: 1.635, Test accuracy: 61.65 

Round  95, Train loss: 0.440, Test loss: 1.596, Test accuracy: 61.19 

Round  96, Train loss: 0.351, Test loss: 1.651, Test accuracy: 61.50 

Round  97, Train loss: 0.389, Test loss: 1.658, Test accuracy: 61.09 

Round  98, Train loss: 0.396, Test loss: 1.626, Test accuracy: 61.44 

Round  99, Train loss: 0.368, Test loss: 1.684, Test accuracy: 61.11 

Final Round, Train loss: 0.323, Test loss: 1.693, Test accuracy: 61.01 

Average accuracy final 10 rounds: 61.354499999999994 

2144.549221277237
[1.421419382095337, 2.6139066219329834, 3.6600916385650635, 4.74504017829895, 5.83903694152832, 6.919524192810059, 7.987534284591675, 9.028585195541382, 10.071781396865845, 11.171489477157593, 12.246649980545044, 13.315767288208008, 14.402595281600952, 19.735239505767822, 20.74830913543701, 21.76162052154541, 22.77318000793457, 23.788278341293335, 24.801318168640137, 25.81744956970215, 26.83296251296997, 27.881223440170288, 28.927148580551147, 29.97541093826294, 31.006531238555908, 32.0230770111084, 33.03856086730957, 34.05407381057739, 35.069687366485596, 36.08390188217163, 37.10645627975464, 38.12036943435669, 39.1365647315979, 40.155694246292114, 41.16866993904114, 42.20071363449097, 43.217488288879395, 44.23319435119629, 45.24675416946411, 46.26701641082764, 47.31939101219177, 48.37635374069214, 49.41633439064026, 50.4602484703064, 51.4883930683136, 52.503031730651855, 53.51271390914917, 54.524978160858154, 55.53698110580444, 56.55107140541077, 57.56407022476196, 58.57572364807129, 59.5886435508728, 60.59802293777466, 61.61096405982971, 62.62133002281189, 63.63500690460205, 64.6461238861084, 65.6581244468689, 66.66794633865356, 67.67813396453857, 68.69092559814453, 69.70226311683655, 70.71138381958008, 71.72184801101685, 72.73561453819275, 73.74642515182495, 74.75784492492676, 75.7884681224823, 76.83546328544617, 77.85060930252075, 78.87072944641113, 79.87882113456726, 80.87198090553284, 81.86703324317932, 82.86019277572632, 83.86411595344543, 84.8577446937561, 85.856036901474, 86.85529232025146, 87.85313868522644, 88.84960985183716, 89.84530115127563, 90.84133219718933, 91.83489942550659, 92.8294107913971, 93.82354259490967, 94.82669687271118, 95.83082389831543, 96.82492518424988, 97.8194944858551, 98.81558799743652, 99.81249785423279, 100.81262159347534, 101.80710220336914, 102.80205130577087, 103.79664301872253, 104.79350781440735, 105.7905330657959, 106.78500175476074, 108.54847478866577]
[24.265, 30.27, 35.47, 38.248333333333335, 39.81166666666667, 42.325, 44.15833333333333, 45.821666666666665, 45.86, 48.17333333333333, 48.46666666666667, 50.235, 50.66833333333334, 51.513333333333335, 52.43, 52.843333333333334, 53.805, 54.23166666666667, 54.958333333333336, 55.73166666666667, 56.39, 56.718333333333334, 56.91166666666667, 57.67166666666667, 57.211666666666666, 58.345, 57.71333333333333, 58.73833333333334, 58.848333333333336, 58.69, 58.89833333333333, 59.211666666666666, 59.865, 59.61666666666667, 59.891666666666666, 59.79666666666667, 60.48833333333334, 60.093333333333334, 60.06166666666667, 60.47833333333333, 60.64, 60.395, 60.861666666666665, 60.026666666666664, 60.443333333333335, 60.52333333333333, 61.233333333333334, 60.95, 61.245, 60.77166666666667, 61.0, 61.001666666666665, 61.17666666666667, 61.43833333333333, 61.236666666666665, 61.415, 61.25333333333333, 61.498333333333335, 61.321666666666665, 61.51, 61.07, 61.58833333333333, 61.571666666666665, 61.10666666666667, 61.5, 61.321666666666665, 61.236666666666665, 61.06333333333333, 61.27, 61.788333333333334, 61.02, 61.295, 61.193333333333335, 61.275, 61.53666666666667, 61.39, 61.64833333333333, 61.52166666666667, 61.208333333333336, 61.29666666666667, 60.96666666666667, 61.06333333333333, 60.92666666666667, 61.34, 61.00333333333333, 61.385, 61.32, 61.48166666666667, 61.403333333333336, 61.236666666666665, 61.36, 61.27, 61.348333333333336, 61.596666666666664, 61.645, 61.185, 61.5, 61.09166666666667, 61.43833333333333, 61.11, 61.01]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
lg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 8394 (global); Percentage 2.73 (8394/307842 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.225, Test loss: 2.105, Test accuracy: 21.67 

Round   1, Train loss: 2.026, Test loss: 1.959, Test accuracy: 28.47 

Round   2, Train loss: 1.892, Test loss: 1.865, Test accuracy: 31.73 

Round   3, Train loss: 1.830, Test loss: 1.812, Test accuracy: 34.00 

Round   4, Train loss: 1.721, Test loss: 1.767, Test accuracy: 35.61 

Round   5, Train loss: 1.734, Test loss: 1.755, Test accuracy: 36.63 

Round   6, Train loss: 1.695, Test loss: 1.724, Test accuracy: 37.57 

Round   7, Train loss: 1.600, Test loss: 1.711, Test accuracy: 38.03 

Round   8, Train loss: 1.499, Test loss: 1.719, Test accuracy: 38.55 

Round   9, Train loss: 1.513, Test loss: 1.706, Test accuracy: 39.03 

Round  10, Train loss: 1.472, Test loss: 1.693, Test accuracy: 39.63 

Round  11, Train loss: 1.371, Test loss: 1.692, Test accuracy: 39.96 

Round  12, Train loss: 1.367, Test loss: 1.691, Test accuracy: 39.96 

Round  13, Train loss: 1.386, Test loss: 1.705, Test accuracy: 40.35 

Round  14, Train loss: 1.402, Test loss: 1.703, Test accuracy: 40.48 

Round  15, Train loss: 1.279, Test loss: 1.700, Test accuracy: 40.70 

Round  16, Train loss: 1.232, Test loss: 1.727, Test accuracy: 40.99 

Round  17, Train loss: 1.241, Test loss: 1.750, Test accuracy: 40.85 

Round  18, Train loss: 1.212, Test loss: 1.730, Test accuracy: 41.63 

Round  19, Train loss: 1.139, Test loss: 1.770, Test accuracy: 41.48 

Round  20, Train loss: 1.070, Test loss: 1.797, Test accuracy: 41.81 

Round  21, Train loss: 1.082, Test loss: 1.823, Test accuracy: 41.61 

Round  22, Train loss: 1.032, Test loss: 1.864, Test accuracy: 41.94 

Round  23, Train loss: 1.089, Test loss: 1.909, Test accuracy: 41.89 

Round  24, Train loss: 1.069, Test loss: 1.891, Test accuracy: 41.87 

Round  25, Train loss: 0.986, Test loss: 1.945, Test accuracy: 41.83 

Round  26, Train loss: 0.876, Test loss: 1.986, Test accuracy: 41.62 

Round  27, Train loss: 0.912, Test loss: 2.026, Test accuracy: 41.59 

Round  28, Train loss: 0.824, Test loss: 2.072, Test accuracy: 41.49 

Round  29, Train loss: 0.753, Test loss: 2.063, Test accuracy: 41.71 

Round  30, Train loss: 0.777, Test loss: 2.131, Test accuracy: 41.59 

Round  31, Train loss: 0.768, Test loss: 2.158, Test accuracy: 41.98 

Round  32, Train loss: 0.664, Test loss: 2.208, Test accuracy: 41.86 

Round  33, Train loss: 0.708, Test loss: 2.232, Test accuracy: 42.28 

Round  34, Train loss: 0.633, Test loss: 2.270, Test accuracy: 42.38 

Round  35, Train loss: 0.621, Test loss: 2.311, Test accuracy: 41.94 

Round  36, Train loss: 0.652, Test loss: 2.327, Test accuracy: 41.80 

Round  37, Train loss: 0.580, Test loss: 2.382, Test accuracy: 41.91 

Round  38, Train loss: 0.576, Test loss: 2.399, Test accuracy: 42.05 

Round  39, Train loss: 0.567, Test loss: 2.431, Test accuracy: 41.88 

Round  40, Train loss: 0.528, Test loss: 2.457, Test accuracy: 42.13 

Round  41, Train loss: 0.519, Test loss: 2.477, Test accuracy: 42.12 

Round  42, Train loss: 0.520, Test loss: 2.456, Test accuracy: 42.47 

Round  43, Train loss: 0.466, Test loss: 2.478, Test accuracy: 42.12 

Round  44, Train loss: 0.466, Test loss: 2.544, Test accuracy: 41.99 

Round  45, Train loss: 0.472, Test loss: 2.626, Test accuracy: 42.05 

Round  46, Train loss: 0.441, Test loss: 2.654, Test accuracy: 42.20 

Round  47, Train loss: 0.410, Test loss: 2.691, Test accuracy: 42.54 

Round  48, Train loss: 0.397, Test loss: 2.732, Test accuracy: 42.33 

Round  49, Train loss: 0.414, Test loss: 2.806, Test accuracy: 42.34 

Round  50, Train loss: 0.352, Test loss: 2.868, Test accuracy: 42.34 

Round  51, Train loss: 0.365, Test loss: 2.859, Test accuracy: 42.24 

Round  52, Train loss: 0.394, Test loss: 2.905, Test accuracy: 42.23 

Round  53, Train loss: 0.380, Test loss: 2.926, Test accuracy: 42.09 

Round  54, Train loss: 0.317, Test loss: 2.953, Test accuracy: 42.17 

Round  55, Train loss: 0.336, Test loss: 3.002, Test accuracy: 42.25 

Round  56, Train loss: 0.379, Test loss: 3.010, Test accuracy: 42.41 

Round  57, Train loss: 0.329, Test loss: 3.082, Test accuracy: 42.56 

Round  58, Train loss: 0.284, Test loss: 3.139, Test accuracy: 42.27 

Round  59, Train loss: 0.281, Test loss: 3.147, Test accuracy: 42.52 

Round  60, Train loss: 0.331, Test loss: 3.199, Test accuracy: 42.58 

Round  61, Train loss: 0.280, Test loss: 3.231, Test accuracy: 42.60 

Round  62, Train loss: 0.230, Test loss: 3.229, Test accuracy: 42.26 

Round  63, Train loss: 0.277, Test loss: 3.260, Test accuracy: 42.53 

Round  64, Train loss: 0.298, Test loss: 3.309, Test accuracy: 42.59 

Round  65, Train loss: 0.250, Test loss: 3.315, Test accuracy: 42.58 

Round  66, Train loss: 0.265, Test loss: 3.332, Test accuracy: 42.53 

Round  67, Train loss: 0.232, Test loss: 3.367, Test accuracy: 42.25 

Round  68, Train loss: 0.218, Test loss: 3.377, Test accuracy: 42.62 

Round  69, Train loss: 0.210, Test loss: 3.419, Test accuracy: 42.43 

Round  70, Train loss: 0.231, Test loss: 3.414, Test accuracy: 42.78 

Round  71, Train loss: 0.200, Test loss: 3.492, Test accuracy: 42.28 

Round  72, Train loss: 0.195, Test loss: 3.493, Test accuracy: 42.26 

Round  73, Train loss: 0.226, Test loss: 3.533, Test accuracy: 42.54 

Round  74, Train loss: 0.211, Test loss: 3.517, Test accuracy: 42.79 

Round  75, Train loss: 0.210, Test loss: 3.539, Test accuracy: 42.62 

Round  76, Train loss: 0.195, Test loss: 3.583, Test accuracy: 42.61 

Round  77, Train loss: 0.200, Test loss: 3.567, Test accuracy: 42.76 

Round  78, Train loss: 0.215, Test loss: 3.661, Test accuracy: 42.44 

Round  79, Train loss: 0.156, Test loss: 3.710, Test accuracy: 42.74 

Round  80, Train loss: 0.193, Test loss: 3.703, Test accuracy: 42.96 

Round  81, Train loss: 0.167, Test loss: 3.760, Test accuracy: 42.87 

Round  82, Train loss: 0.171, Test loss: 3.842, Test accuracy: 42.78 

Round  83, Train loss: 0.205, Test loss: 3.746, Test accuracy: 42.71 

Round  84, Train loss: 0.160, Test loss: 3.778, Test accuracy: 42.76 

Round  85, Train loss: 0.146, Test loss: 3.822, Test accuracy: 42.57 

Round  86, Train loss: 0.150, Test loss: 3.840, Test accuracy: 42.60 

Round  87, Train loss: 0.168, Test loss: 3.855, Test accuracy: 42.65 

Round  88, Train loss: 0.155, Test loss: 3.856, Test accuracy: 42.70 

Round  89, Train loss: 0.125, Test loss: 3.944, Test accuracy: 42.45 

Round  90, Train loss: 0.130, Test loss: 3.910, Test accuracy: 42.70 

Round  91, Train loss: 0.169, Test loss: 3.893, Test accuracy: 42.87 

Round  92, Train loss: 0.139, Test loss: 3.904, Test accuracy: 43.02 

Round  93, Train loss: 0.123, Test loss: 3.868, Test accuracy: 43.27 

Round  94, Train loss: 0.165, Test loss: 3.887, Test accuracy: 43.05 

Round  95, Train loss: 0.156, Test loss: 3.919, Test accuracy: 42.86 

Round  96, Train loss: 0.105, Test loss: 3.972, Test accuracy: 42.85 

Round  97, Train loss: 0.175, Test loss: 3.971, Test accuracy: 42.73 

Round  98, Train loss: 0.128, Test loss: 4.029, Test accuracy: 42.66 

Round  99, Train loss: 0.113, Test loss: 4.093, Test accuracy: 42.65 

Final Round, Train loss: 0.097, Test loss: 4.328, Test accuracy: 43.01 

Average accuracy final 10 rounds: 42.865 

2231.336713552475
[1.3304238319396973, 2.4322867393493652, 3.5476365089416504, 4.795315265655518, 6.0762269496917725, 7.342791795730591, 8.590996265411377, 9.843725204467773, 11.086467742919922, 12.334092140197754, 13.590384721755981, 14.837871551513672, 16.083794593811035, 17.333787202835083, 18.530807495117188, 19.77526545524597, 21.032931327819824, 22.291165590286255, 23.547566413879395, 24.800355911254883, 26.058130979537964, 27.299522161483765, 28.538647890090942, 29.790956258773804, 31.033756256103516, 32.276204347610474, 33.52128887176514, 34.7653443813324, 36.0078558921814, 37.25276064872742, 38.49959421157837, 39.75206208229065, 41.00242066383362, 42.24808096885681, 43.49965047836304, 44.747740030288696, 45.98686456680298, 47.225762605667114, 48.47893667221069, 49.742642641067505, 50.97808599472046, 52.22487187385559, 53.467204570770264, 54.71454334259033, 55.9639310836792, 57.216195583343506, 58.481571435928345, 59.752849817276, 61.00271034240723, 62.25337195396423, 63.51900291442871, 64.76980996131897, 66.0211112499237, 67.28166270256042, 68.54003953933716, 69.79621267318726, 71.04152846336365, 72.29684019088745, 73.56320929527283, 74.82069230079651, 76.10153460502625, 77.3603904247284, 78.6125020980835, 79.85984134674072, 81.11162424087524, 82.36591410636902, 83.61317491531372, 84.86127877235413, 86.1153678894043, 87.36397528648376, 88.61575889587402, 89.86212801933289, 91.11060357093811, 92.36115789413452, 93.60886979103088, 94.86379837989807, 96.11482858657837, 97.36033821105957, 98.607492685318, 99.8533353805542, 101.10254859924316, 102.3474543094635, 103.59087109565735, 104.83994626998901, 106.09079551696777, 107.33740210533142, 108.5689902305603, 109.80458211898804, 111.04170346260071, 112.27787804603577, 113.51797318458557, 114.76122212409973, 116.0022337436676, 117.23760962486267, 118.476149559021, 119.71525239944458, 120.95678758621216, 122.19762015342712, 123.44538450241089, 124.69109463691711, 127.00450348854065]
[21.671666666666667, 28.471666666666668, 31.733333333333334, 34.00333333333333, 35.611666666666665, 36.63333333333333, 37.568333333333335, 38.028333333333336, 38.553333333333335, 39.03, 39.62833333333333, 39.96333333333333, 39.961666666666666, 40.35, 40.47666666666667, 40.705, 40.99333333333333, 40.85333333333333, 41.63166666666667, 41.47833333333333, 41.80833333333333, 41.611666666666665, 41.935, 41.89333333333333, 41.86666666666667, 41.833333333333336, 41.61833333333333, 41.59, 41.49333333333333, 41.708333333333336, 41.59, 41.97666666666667, 41.86, 42.28333333333333, 42.37833333333333, 41.935, 41.79666666666667, 41.90833333333333, 42.05166666666667, 41.88166666666667, 42.13, 42.11833333333333, 42.473333333333336, 42.12166666666667, 41.99, 42.04833333333333, 42.2, 42.54, 42.325, 42.34166666666667, 42.343333333333334, 42.245, 42.23, 42.085, 42.17333333333333, 42.248333333333335, 42.41, 42.565, 42.26833333333333, 42.516666666666666, 42.575, 42.6, 42.25666666666667, 42.53333333333333, 42.59166666666667, 42.58, 42.528333333333336, 42.24666666666667, 42.61833333333333, 42.428333333333335, 42.776666666666664, 42.278333333333336, 42.26166666666666, 42.54333333333334, 42.788333333333334, 42.623333333333335, 42.608333333333334, 42.755, 42.443333333333335, 42.74, 42.95666666666666, 42.865, 42.776666666666664, 42.70666666666666, 42.76166666666666, 42.568333333333335, 42.60166666666667, 42.645, 42.70333333333333, 42.445, 42.696666666666665, 42.87166666666667, 43.02333333333333, 43.265, 43.04833333333333, 42.85666666666667, 42.85333333333333, 42.72666666666667, 42.66, 42.64833333333333, 43.00666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
Round   0, Train loss: 1.404, Test loss: 1.841, Test accuracy: 34.58
Round   1, Train loss: 1.212, Test loss: 1.858, Test accuracy: 32.29
Round   2, Train loss: 1.089, Test loss: 1.881, Test accuracy: 32.08
Round   3, Train loss: 1.008, Test loss: 1.893, Test accuracy: 32.29
Round   4, Train loss: 0.982, Test loss: 2.023, Test accuracy: 26.53
Round   5, Train loss: 0.916, Test loss: 2.005, Test accuracy: 26.89
Round   6, Train loss: 0.860, Test loss: 1.995, Test accuracy: 27.04
Round   7, Train loss: 0.837, Test loss: 1.979, Test accuracy: 27.94
Round   8, Train loss: 0.789, Test loss: 2.021, Test accuracy: 26.53
Round   9, Train loss: 0.764, Test loss: 2.067, Test accuracy: 24.90
Round  10, Train loss: 0.698, Test loss: 2.056, Test accuracy: 26.11
Round  11, Train loss: 0.670, Test loss: 2.046, Test accuracy: 26.97
Round  12, Train loss: 0.658, Test loss: 2.043, Test accuracy: 26.86
Round  13, Train loss: 0.670, Test loss: 2.041, Test accuracy: 27.53
Round  14, Train loss: 0.601, Test loss: 2.029, Test accuracy: 28.57
Round  15, Train loss: 0.553, Test loss: 2.017, Test accuracy: 29.31
Round  16, Train loss: 0.590, Test loss: 2.022, Test accuracy: 29.20
Round  17, Train loss: 0.545, Test loss: 2.010, Test accuracy: 30.64
Round  18, Train loss: 0.536, Test loss: 2.011, Test accuracy: 29.82
Round  19, Train loss: 0.501, Test loss: 2.006, Test accuracy: 29.70
Round  20, Train loss: 0.493, Test loss: 1.994, Test accuracy: 30.12
Round  21, Train loss: 0.444, Test loss: 1.987, Test accuracy: 31.19
Round  22, Train loss: 0.498, Test loss: 1.982, Test accuracy: 30.88
Round  23, Train loss: 0.463, Test loss: 1.978, Test accuracy: 31.67
Round  24, Train loss: 0.420, Test loss: 1.966, Test accuracy: 32.84
Round  25, Train loss: 0.468, Test loss: 1.958, Test accuracy: 33.27
Round  26, Train loss: 0.415, Test loss: 1.943, Test accuracy: 34.28
Round  27, Train loss: 0.411, Test loss: 1.939, Test accuracy: 34.55
Round  28, Train loss: 0.371, Test loss: 1.932, Test accuracy: 34.48
Round  29, Train loss: 0.384, Test loss: 1.926, Test accuracy: 34.78
Round  30, Train loss: 0.411, Test loss: 1.929, Test accuracy: 33.72
Round  31, Train loss: 0.344, Test loss: 1.920, Test accuracy: 34.83
Round  32, Train loss: 0.366, Test loss: 1.914, Test accuracy: 35.91
Round  33, Train loss: 0.350, Test loss: 1.904, Test accuracy: 36.75
Round  34, Train loss: 0.335, Test loss: 1.901, Test accuracy: 36.85
Round  35, Train loss: 0.324, Test loss: 1.893, Test accuracy: 37.23
Round  36, Train loss: 0.339, Test loss: 1.888, Test accuracy: 37.32
Round  37, Train loss: 0.327, Test loss: 1.885, Test accuracy: 37.03
Round  38, Train loss: 0.350, Test loss: 1.875, Test accuracy: 38.17
Round  39, Train loss: 0.294, Test loss: 1.867, Test accuracy: 38.48
Round  40, Train loss: 0.311, Test loss: 1.857, Test accuracy: 39.11
Round  41, Train loss: 0.281, Test loss: 1.851, Test accuracy: 39.19
Round  42, Train loss: 0.266, Test loss: 1.839, Test accuracy: 39.70
Round  43, Train loss: 0.274, Test loss: 1.843, Test accuracy: 39.72
Round  44, Train loss: 0.257, Test loss: 1.845, Test accuracy: 39.09
Round  45, Train loss: 0.281, Test loss: 1.837, Test accuracy: 39.13
Round  46, Train loss: 0.257, Test loss: 1.829, Test accuracy: 40.53
Round  47, Train loss: 0.268, Test loss: 1.836, Test accuracy: 39.57
Round  48, Train loss: 0.261, Test loss: 1.826, Test accuracy: 40.12
Round  49, Train loss: 0.248, Test loss: 1.819, Test accuracy: 40.14
Round  50, Train loss: 0.252, Test loss: 1.817, Test accuracy: 40.33
Round  51, Train loss: 0.241, Test loss: 1.811, Test accuracy: 40.47
Round  52, Train loss: 0.231, Test loss: 1.819, Test accuracy: 39.78
Round  53, Train loss: 0.236, Test loss: 1.812, Test accuracy: 40.25
Round  54, Train loss: 0.232, Test loss: 1.811, Test accuracy: 40.18
Round  55, Train loss: 0.222, Test loss: 1.803, Test accuracy: 41.04
Round  56, Train loss: 0.216, Test loss: 1.796, Test accuracy: 41.34
Round  57, Train loss: 0.228, Test loss: 1.791, Test accuracy: 40.96
Round  58, Train loss: 0.215, Test loss: 1.786, Test accuracy: 41.53
Round  59, Train loss: 0.223, Test loss: 1.782, Test accuracy: 41.58
Round  60, Train loss: 0.213, Test loss: 1.781, Test accuracy: 41.66
Round  61, Train loss: 0.198, Test loss: 1.780, Test accuracy: 41.40
Round  62, Train loss: 0.199, Test loss: 1.784, Test accuracy: 40.92
Round  63, Train loss: 0.229, Test loss: 1.780, Test accuracy: 40.70
Round  64, Train loss: 0.198, Test loss: 1.780, Test accuracy: 40.64
Round  65, Train loss: 0.195, Test loss: 1.773, Test accuracy: 41.20
Round  66, Train loss: 0.196, Test loss: 1.764, Test accuracy: 42.17
Round  67, Train loss: 0.189, Test loss: 1.759, Test accuracy: 41.73
Round  68, Train loss: 0.189, Test loss: 1.753, Test accuracy: 41.83
Round  69, Train loss: 0.196, Test loss: 1.741, Test accuracy: 42.62
Round  70, Train loss: 0.189, Test loss: 1.750, Test accuracy: 41.89
Round  71, Train loss: 0.181, Test loss: 1.748, Test accuracy: 42.31
Round  72, Train loss: 0.182, Test loss: 1.734, Test accuracy: 43.22
Round  73, Train loss: 0.194, Test loss: 1.737, Test accuracy: 42.69
Round  74, Train loss: 0.178, Test loss: 1.725, Test accuracy: 43.42
Round  75, Train loss: 0.188, Test loss: 1.729, Test accuracy: 43.12
Round  76, Train loss: 0.189, Test loss: 1.725, Test accuracy: 43.56
Round  77, Train loss: 0.179, Test loss: 1.721, Test accuracy: 43.68
Round  78, Train loss: 0.169, Test loss: 1.718, Test accuracy: 43.61
Round  79, Train loss: 0.178, Test loss: 1.722, Test accuracy: 43.05
Round  80, Train loss: 0.187, Test loss: 1.715, Test accuracy: 43.54
Round  81, Train loss: 0.170, Test loss: 1.720, Test accuracy: 42.76
Round  82, Train loss: 0.164, Test loss: 1.714, Test accuracy: 42.92
Round  83, Train loss: 0.163, Test loss: 1.709, Test accuracy: 43.18
Round  84, Train loss: 0.170, Test loss: 1.701, Test accuracy: 43.59
Round  85, Train loss: 0.161, Test loss: 1.702, Test accuracy: 43.57
Round  86, Train loss: 0.159, Test loss: 1.693, Test accuracy: 43.98
Round  87, Train loss: 0.165, Test loss: 1.695, Test accuracy: 43.93
Round  88, Train loss: 0.170, Test loss: 1.687, Test accuracy: 44.33
Round  89, Train loss: 0.163, Test loss: 1.700, Test accuracy: 44.10
Round  90, Train loss: 0.164, Test loss: 1.695, Test accuracy: 44.48
Round  91, Train loss: 0.151, Test loss: 1.688, Test accuracy: 44.88
Round  92, Train loss: 0.152, Test loss: 1.680, Test accuracy: 45.28
Round  93, Train loss: 0.153, Test loss: 1.679, Test accuracy: 45.10
Round  94, Train loss: 0.149, Test loss: 1.675, Test accuracy: 45.28
Round  95, Train loss: 0.158, Test loss: 1.685, Test accuracy: 44.31
Round  96, Train loss: 0.152, Test loss: 1.667, Test accuracy: 45.48
Round  97, Train loss: 0.151, Test loss: 1.665, Test accuracy: 45.30
Round  98, Train loss: 0.150, Test loss: 1.674, Test accuracy: 44.54
Round  99, Train loss: 0.145, Test loss: 1.675, Test accuracy: 44.34
Final Round, Train loss: 0.150, Test loss: 1.672, Test accuracy: 44.93
Average accuracy final 10 rounds: 44.90016666666667
8445.137856006622
[]
[34.58166666666666, 32.291666666666664, 32.08166666666666, 32.29, 26.53, 26.885, 27.041666666666668, 27.94333333333333, 26.526666666666667, 24.89666666666667, 26.108333333333334, 26.97, 26.855, 27.526666666666667, 28.57, 29.308333333333334, 29.198333333333334, 30.641666666666666, 29.823333333333334, 29.698333333333334, 30.125, 31.19333333333333, 30.876666666666665, 31.668333333333333, 32.84, 33.27166666666667, 34.28, 34.55, 34.47833333333333, 34.78333333333333, 33.723333333333336, 34.83166666666666, 35.905, 36.75, 36.848333333333336, 37.233333333333334, 37.321666666666665, 37.031666666666666, 38.166666666666664, 38.485, 39.11333333333334, 39.18833333333333, 39.695, 39.721666666666664, 39.093333333333334, 39.13166666666667, 40.53, 39.57, 40.11833333333333, 40.14, 40.33, 40.465, 39.78, 40.25, 40.17666666666667, 41.04333333333334, 41.345, 40.95666666666666, 41.53333333333333, 41.575, 41.66, 41.395, 40.92166666666667, 40.705, 40.641666666666666, 41.20166666666667, 42.17166666666667, 41.735, 41.833333333333336, 42.615, 41.88666666666666, 42.306666666666665, 43.215, 42.68833333333333, 43.41833333333334, 43.115, 43.56333333333333, 43.68333333333333, 43.60666666666667, 43.05166666666667, 43.54333333333334, 42.763333333333335, 42.91833333333334, 43.181666666666665, 43.595, 43.571666666666665, 43.97666666666667, 43.92666666666667, 44.32666666666667, 44.10166666666667, 44.485, 44.885, 45.278333333333336, 45.098333333333336, 45.281666666666666, 44.31333333333333, 45.48, 45.29666666666667, 44.541666666666664, 44.34166666666667, 44.93333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.907, Test loss: 2.087, Test accuracy: 19.26
Round   0: Global train loss: 1.907, Global test loss: 2.291, Global test accuracy: 10.11
Round   1, Train loss: 1.615, Test loss: 1.934, Test accuracy: 27.55
Round   1: Global train loss: 1.615, Global test loss: 2.277, Global test accuracy: 13.81
Round   2, Train loss: 1.353, Test loss: 1.808, Test accuracy: 34.09
Round   2: Global train loss: 1.353, Global test loss: 2.259, Global test accuracy: 18.95
Round   3, Train loss: 1.088, Test loss: 1.683, Test accuracy: 39.21
Round   3: Global train loss: 1.088, Global test loss: 2.237, Global test accuracy: 21.25
Round   4, Train loss: 1.094, Test loss: 1.621, Test accuracy: 42.60
Round   4: Global train loss: 1.094, Global test loss: 2.213, Global test accuracy: 26.84
Round   5, Train loss: 0.704, Test loss: 1.570, Test accuracy: 44.09
Round   5: Global train loss: 0.704, Global test loss: 2.202, Global test accuracy: 26.65
Round   6, Train loss: 0.500, Test loss: 1.519, Test accuracy: 46.13
Round   6: Global train loss: 0.500, Global test loss: 2.170, Global test accuracy: 30.94
Round   7, Train loss: 1.187, Test loss: 1.520, Test accuracy: 46.10
Round   7: Global train loss: 1.187, Global test loss: 2.148, Global test accuracy: 33.73
Round   8, Train loss: 0.436, Test loss: 1.443, Test accuracy: 48.91
Round   8: Global train loss: 0.436, Global test loss: 2.116, Global test accuracy: 36.77
Round   9, Train loss: 0.419, Test loss: 1.457, Test accuracy: 48.85
Round   9: Global train loss: 0.419, Global test loss: 2.090, Global test accuracy: 38.48
Round  10, Train loss: 0.263, Test loss: 1.424, Test accuracy: 49.50
Round  10: Global train loss: 0.263, Global test loss: 2.062, Global test accuracy: 39.60
Round  11, Train loss: -0.158, Test loss: 1.387, Test accuracy: 50.67
Round  11: Global train loss: -0.158, Global test loss: 2.034, Global test accuracy: 41.52
Round  12, Train loss: -0.207, Test loss: 1.370, Test accuracy: 51.38
Round  12: Global train loss: -0.207, Global test loss: 2.001, Global test accuracy: 43.06
Round  13, Train loss: -0.258, Test loss: 1.354, Test accuracy: 52.31
Round  13: Global train loss: -0.258, Global test loss: 1.968, Global test accuracy: 43.77
Round  14, Train loss: -0.780, Test loss: 1.337, Test accuracy: 53.08
Round  14: Global train loss: -0.780, Global test loss: 1.938, Global test accuracy: 45.52
Round  15, Train loss: -1.139, Test loss: 1.350, Test accuracy: 52.84
Round  15: Global train loss: -1.139, Global test loss: 1.911, Global test accuracy: 45.25
Round  16, Train loss: -1.076, Test loss: 1.341, Test accuracy: 53.50
Round  16: Global train loss: -1.076, Global test loss: 1.873, Global test accuracy: 46.98
Round  17, Train loss: -0.537, Test loss: 1.340, Test accuracy: 53.87
Round  17: Global train loss: -0.537, Global test loss: 1.837, Global test accuracy: 48.65
Round  18, Train loss: -0.989, Test loss: 1.351, Test accuracy: 53.39
Round  18: Global train loss: -0.989, Global test loss: 1.799, Global test accuracy: 49.88
Round  19, Train loss: -1.135, Test loss: 1.337, Test accuracy: 53.88
Round  19: Global train loss: -1.135, Global test loss: 1.777, Global test accuracy: 50.08
Round  20, Train loss: -1.168, Test loss: 1.316, Test accuracy: 54.83
Round  20: Global train loss: -1.168, Global test loss: 1.753, Global test accuracy: 50.63
Round  21, Train loss: -2.025, Test loss: 1.317, Test accuracy: 55.15
Round  21: Global train loss: -2.025, Global test loss: 1.721, Global test accuracy: 51.56
Round  22, Train loss: -1.636, Test loss: 1.305, Test accuracy: 55.64
Round  22: Global train loss: -1.636, Global test loss: 1.693, Global test accuracy: 52.65
Round  23, Train loss: -0.226, Test loss: 1.313, Test accuracy: 55.10
Round  23: Global train loss: -0.226, Global test loss: 1.685, Global test accuracy: 52.43
Round  24, Train loss: -2.266, Test loss: 1.303, Test accuracy: 55.83
Round  24: Global train loss: -2.266, Global test loss: 1.667, Global test accuracy: 52.27
Round  25, Train loss: -2.505, Test loss: 1.286, Test accuracy: 55.86
Round  25: Global train loss: -2.505, Global test loss: 1.649, Global test accuracy: 52.53
Round  26, Train loss: -2.328, Test loss: 1.285, Test accuracy: 55.86
Round  26: Global train loss: -2.328, Global test loss: 1.634, Global test accuracy: 52.96
Round  27, Train loss: -2.083, Test loss: 1.288, Test accuracy: 55.87
Round  27: Global train loss: -2.083, Global test loss: 1.619, Global test accuracy: 53.13
Round  28, Train loss: -2.344, Test loss: 1.294, Test accuracy: 55.77
Round  28: Global train loss: -2.344, Global test loss: 1.595, Global test accuracy: 53.70
Round  29, Train loss: -2.701, Test loss: 1.305, Test accuracy: 55.67
Round  29: Global train loss: -2.701, Global test loss: 1.582, Global test accuracy: 53.97
Round  30, Train loss: -3.185, Test loss: 1.301, Test accuracy: 56.26
Round  30: Global train loss: -3.185, Global test loss: 1.561, Global test accuracy: 54.67
Round  31, Train loss: -2.526, Test loss: 1.291, Test accuracy: 56.59
Round  31: Global train loss: -2.526, Global test loss: 1.543, Global test accuracy: 55.17
Round  32, Train loss: -2.346, Test loss: 1.296, Test accuracy: 56.67
Round  32: Global train loss: -2.346, Global test loss: 1.525, Global test accuracy: 55.61
Round  33, Train loss: -2.474, Test loss: 1.294, Test accuracy: 57.04
Round  33: Global train loss: -2.474, Global test loss: 1.498, Global test accuracy: 56.66
Round  34, Train loss: -2.876, Test loss: 1.300, Test accuracy: 57.14
Round  34: Global train loss: -2.876, Global test loss: 1.470, Global test accuracy: 57.76
Round  35, Train loss: -3.298, Test loss: 1.285, Test accuracy: 57.77
Round  35: Global train loss: -3.298, Global test loss: 1.441, Global test accuracy: 58.61
Round  36, Train loss: -2.798, Test loss: 1.282, Test accuracy: 57.91
Round  36: Global train loss: -2.798, Global test loss: 1.429, Global test accuracy: 58.99
Round  37, Train loss: -2.266, Test loss: 1.283, Test accuracy: 57.62
Round  37: Global train loss: -2.266, Global test loss: 1.422, Global test accuracy: 58.95
Round  38, Train loss: -2.683, Test loss: 1.282, Test accuracy: 57.52
Round  38: Global train loss: -2.683, Global test loss: 1.400, Global test accuracy: 59.77
Round  39, Train loss: -2.804, Test loss: 1.287, Test accuracy: 57.43
Round  39: Global train loss: -2.804, Global test loss: 1.382, Global test accuracy: 60.02
Round  40, Train loss: -3.019, Test loss: 1.292, Test accuracy: 57.42
Round  40: Global train loss: -3.019, Global test loss: 1.372, Global test accuracy: 60.27
Round  41, Train loss: -3.546, Test loss: 1.292, Test accuracy: 57.42
Round  41: Global train loss: -3.546, Global test loss: 1.354, Global test accuracy: 60.73
Round  42, Train loss: -3.076, Test loss: 1.285, Test accuracy: 57.64
Round  42: Global train loss: -3.076, Global test loss: 1.333, Global test accuracy: 61.45
Round  43, Train loss: -3.109, Test loss: 1.290, Test accuracy: 57.60
Round  43: Global train loss: -3.109, Global test loss: 1.319, Global test accuracy: 61.69
Round  44, Train loss: -3.549, Test loss: 1.286, Test accuracy: 57.65
Round  44: Global train loss: -3.549, Global test loss: 1.308, Global test accuracy: 62.10
Round  45, Train loss: -3.850, Test loss: 1.281, Test accuracy: 57.95
Round  45: Global train loss: -3.850, Global test loss: 1.296, Global test accuracy: 62.36
Round  46, Train loss: -4.138, Test loss: 1.289, Test accuracy: 58.02
Round  46: Global train loss: -4.138, Global test loss: 1.280, Global test accuracy: 62.49
Round  47, Train loss: -4.197, Test loss: 1.283, Test accuracy: 58.53
Round  47: Global train loss: -4.197, Global test loss: 1.261, Global test accuracy: 62.90
Round  48, Train loss: -3.279, Test loss: 1.276, Test accuracy: 58.34
Round  48: Global train loss: -3.279, Global test loss: 1.255, Global test accuracy: 62.98
Round  49, Train loss: -3.295, Test loss: 1.275, Test accuracy: 58.41
Round  49: Global train loss: -3.295, Global test loss: 1.248, Global test accuracy: 62.69
Round  50, Train loss: -3.623, Test loss: 1.275, Test accuracy: 58.71
Round  50: Global train loss: -3.623, Global test loss: 1.232, Global test accuracy: 63.22
Round  51, Train loss: -3.744, Test loss: 1.292, Test accuracy: 58.16
Round  51: Global train loss: -3.744, Global test loss: 1.223, Global test accuracy: 63.62
Round  52, Train loss: -3.750, Test loss: 1.271, Test accuracy: 58.71
Round  52: Global train loss: -3.750, Global test loss: 1.213, Global test accuracy: 63.57
Round  53, Train loss: -3.753, Test loss: 1.257, Test accuracy: 58.92
Round  53: Global train loss: -3.753, Global test loss: 1.207, Global test accuracy: 63.92
Round  54, Train loss: -3.739, Test loss: 1.259, Test accuracy: 59.08
Round  54: Global train loss: -3.739, Global test loss: 1.195, Global test accuracy: 64.14
Round  55, Train loss: -4.376, Test loss: 1.272, Test accuracy: 58.89
Round  55: Global train loss: -4.376, Global test loss: 1.186, Global test accuracy: 64.42
Round  56, Train loss: -4.458, Test loss: 1.267, Test accuracy: 59.28
Round  56: Global train loss: -4.458, Global test loss: 1.176, Global test accuracy: 64.73
Round  57, Train loss: -3.760, Test loss: 1.263, Test accuracy: 59.39
Round  57: Global train loss: -3.760, Global test loss: 1.168, Global test accuracy: 64.91
Round  58, Train loss: -4.594, Test loss: 1.278, Test accuracy: 59.10
Round  58: Global train loss: -4.594, Global test loss: 1.162, Global test accuracy: 64.77
Round  59, Train loss: -3.803, Test loss: 1.265, Test accuracy: 59.62
Round  59: Global train loss: -3.803, Global test loss: 1.155, Global test accuracy: 64.86
Round  60, Train loss: -3.897, Test loss: 1.272, Test accuracy: 59.30
Round  60: Global train loss: -3.897, Global test loss: 1.148, Global test accuracy: 65.11
Round  61, Train loss: -3.830, Test loss: 1.289, Test accuracy: 58.89
Round  61: Global train loss: -3.830, Global test loss: 1.141, Global test accuracy: 65.08
Round  62, Train loss: -4.358, Test loss: 1.304, Test accuracy: 58.50
Round  62: Global train loss: -4.358, Global test loss: 1.135, Global test accuracy: 65.21
Round  63, Train loss: -3.868, Test loss: 1.293, Test accuracy: 58.82
Round  63: Global train loss: -3.868, Global test loss: 1.130, Global test accuracy: 65.30
Round  64, Train loss: -4.107, Test loss: 1.297, Test accuracy: 59.09
Round  64: Global train loss: -4.107, Global test loss: 1.121, Global test accuracy: 65.47
Round  65, Train loss: -4.594, Test loss: 1.287, Test accuracy: 59.56
Round  65: Global train loss: -4.594, Global test loss: 1.110, Global test accuracy: 65.81
Round  66, Train loss: -3.856, Test loss: 1.286, Test accuracy: 59.33
Round  66: Global train loss: -3.856, Global test loss: 1.103, Global test accuracy: 65.42
Round  67, Train loss: -3.844, Test loss: 1.272, Test accuracy: 59.58
Round  67: Global train loss: -3.844, Global test loss: 1.095, Global test accuracy: 65.71
Round  68, Train loss: -4.209, Test loss: 1.260, Test accuracy: 59.91
Round  68: Global train loss: -4.209, Global test loss: 1.089, Global test accuracy: 65.94
Round  69, Train loss: -3.958, Test loss: 1.257, Test accuracy: 59.91
Round  69: Global train loss: -3.958, Global test loss: 1.082, Global test accuracy: 65.97
Round  70, Train loss: -4.289, Test loss: 1.271, Test accuracy: 59.77
Round  70: Global train loss: -4.289, Global test loss: 1.073, Global test accuracy: 66.11
Round  71, Train loss: -4.517, Test loss: 1.263, Test accuracy: 59.91
Round  71: Global train loss: -4.517, Global test loss: 1.065, Global test accuracy: 66.28
Round  72, Train loss: -4.414, Test loss: 1.257, Test accuracy: 59.94
Round  72: Global train loss: -4.414, Global test loss: 1.057, Global test accuracy: 66.47
Round  73, Train loss: -3.831, Test loss: 1.258, Test accuracy: 59.75
Round  73: Global train loss: -3.831, Global test loss: 1.055, Global test accuracy: 66.81
Round  74, Train loss: -4.198, Test loss: 1.267, Test accuracy: 59.98
Round  74: Global train loss: -4.198, Global test loss: 1.048, Global test accuracy: 66.94
Round  75, Train loss: -3.924, Test loss: 1.268, Test accuracy: 60.14
Round  75: Global train loss: -3.924, Global test loss: 1.040, Global test accuracy: 67.08
Round  76, Train loss: -4.185, Test loss: 1.251, Test accuracy: 60.74
Round  76: Global train loss: -4.185, Global test loss: 1.035, Global test accuracy: 67.28
Round  77, Train loss: -4.336, Test loss: 1.258, Test accuracy: 60.85
Round  77: Global train loss: -4.336, Global test loss: 1.026, Global test accuracy: 67.30
Round  78, Train loss: -4.000, Test loss: 1.254, Test accuracy: 60.83
Round  78: Global train loss: -4.000, Global test loss: 1.016, Global test accuracy: 67.53
Round  79, Train loss: -4.212, Test loss: 1.246, Test accuracy: 60.99
Round  79: Global train loss: -4.212, Global test loss: 1.009, Global test accuracy: 67.75
Round  80, Train loss: -4.118, Test loss: 1.245, Test accuracy: 60.77
Round  80: Global train loss: -4.118, Global test loss: 1.001, Global test accuracy: 68.05
Round  81, Train loss: -3.938, Test loss: 1.245, Test accuracy: 60.82
Round  81: Global train loss: -3.938, Global test loss: 0.996, Global test accuracy: 68.31
Round  82, Train loss: -4.325, Test loss: 1.251, Test accuracy: 60.74
Round  82: Global train loss: -4.325, Global test loss: 0.990, Global test accuracy: 68.12
Round  83, Train loss: -4.431, Test loss: 1.248, Test accuracy: 60.89
Round  83: Global train loss: -4.431, Global test loss: 0.984, Global test accuracy: 68.21
Round  84, Train loss: -4.262, Test loss: 1.250, Test accuracy: 60.95
Round  84: Global train loss: -4.262, Global test loss: 0.978, Global test accuracy: 68.33
Round  85, Train loss: -4.314, Test loss: 1.248, Test accuracy: 61.20
Round  85: Global train loss: -4.314, Global test loss: 0.972, Global test accuracy: 68.49
Round  86, Train loss: -4.008, Test loss: 1.250, Test accuracy: 61.05
Round  86: Global train loss: -4.008, Global test loss: 0.968, Global test accuracy: 68.66
Round  87, Train loss: -4.654, Test loss: 1.263, Test accuracy: 61.02
Round  87: Global train loss: -4.654, Global test loss: 0.962, Global test accuracy: 68.77
Round  88, Train loss: -3.848, Test loss: 1.258, Test accuracy: 60.80
Round  88: Global train loss: -3.848, Global test loss: 0.959, Global test accuracy: 68.91
Round  89, Train loss: -4.394, Test loss: 1.261, Test accuracy: 60.78
Round  89: Global train loss: -4.394, Global test loss: 0.955, Global test accuracy: 69.02
Round  90, Train loss: -4.526, Test loss: 1.246, Test accuracy: 61.08
Round  90: Global train loss: -4.526, Global test loss: 0.951, Global test accuracy: 69.02
Round  91, Train loss: -4.218, Test loss: 1.236, Test accuracy: 61.41
Round  91: Global train loss: -4.218, Global test loss: 0.944, Global test accuracy: 69.19
Round  92, Train loss: -4.094, Test loss: 1.230, Test accuracy: 61.46
Round  92: Global train loss: -4.094, Global test loss: 0.941, Global test accuracy: 69.32
Round  93, Train loss: -4.185, Test loss: 1.245, Test accuracy: 61.18
Round  93: Global train loss: -4.185, Global test loss: 0.938, Global test accuracy: 69.42
Round  94, Train loss: -4.307, Test loss: 1.246, Test accuracy: 61.36
Round  94: Global train loss: -4.307, Global test loss: 0.933, Global test accuracy: 69.53
Round  95, Train loss: -4.075, Test loss: 1.237, Test accuracy: 61.74
Round  95: Global train loss: -4.075, Global test loss: 0.928, Global test accuracy: 69.53
Round  96, Train loss: -3.766, Test loss: 1.228, Test accuracy: 61.99
Round  96: Global train loss: -3.766, Global test loss: 0.925, Global test accuracy: 69.96
Round  97, Train loss: -4.133, Test loss: 1.234, Test accuracy: 61.62
Round  97: Global train loss: -4.133, Global test loss: 0.922, Global test accuracy: 70.10
Round  98, Train loss: -3.884, Test loss: 1.211, Test accuracy: 62.08
Round  98: Global train loss: -3.884, Global test loss: 0.920, Global test accuracy: 69.89
Round  99, Train loss: -3.986, Test loss: 1.213, Test accuracy: 62.09
Round  99: Global train loss: -3.986, Global test loss: 0.917, Global test accuracy: 69.95
Final Round: Train loss: 0.855, Test loss: 1.019, Test accuracy: 65.89
Final Round: Global train loss: 0.855, Global test loss: 0.897, Global test accuracy: 70.48
Average accuracy final 10 rounds: 61.599500000000006
Average global accuracy final 10 rounds: 69.59183333333334
8608.780770540237
[]
[19.26, 27.548333333333332, 34.09166666666667, 39.211666666666666, 42.605, 44.086666666666666, 46.12833333333333, 46.098333333333336, 48.91, 48.85166666666667, 49.50333333333333, 50.67333333333333, 51.38, 52.306666666666665, 53.08166666666666, 52.843333333333334, 53.498333333333335, 53.865, 53.388333333333335, 53.87833333333333, 54.82833333333333, 55.14666666666667, 55.64, 55.1, 55.83166666666666, 55.861666666666665, 55.86333333333334, 55.873333333333335, 55.76833333333333, 55.67333333333333, 56.26166666666666, 56.595, 56.67333333333333, 57.038333333333334, 57.13666666666666, 57.775, 57.90833333333333, 57.61833333333333, 57.515, 57.43, 57.416666666666664, 57.42, 57.641666666666666, 57.605, 57.653333333333336, 57.946666666666665, 58.02, 58.535, 58.34, 58.406666666666666, 58.71, 58.165, 58.711666666666666, 58.916666666666664, 59.08, 58.888333333333335, 59.276666666666664, 59.39, 59.098333333333336, 59.615, 59.29666666666667, 58.888333333333335, 58.49666666666667, 58.81666666666667, 59.093333333333334, 59.56, 59.32666666666667, 59.58166666666666, 59.91, 59.906666666666666, 59.765, 59.913333333333334, 59.935, 59.748333333333335, 59.98166666666667, 60.13666666666666, 60.74333333333333, 60.848333333333336, 60.82666666666667, 60.98833333333334, 60.77, 60.82, 60.74, 60.88666666666666, 60.95166666666667, 61.20166666666667, 61.053333333333335, 61.02166666666667, 60.795, 60.776666666666664, 61.08, 61.415, 61.458333333333336, 61.18333333333333, 61.358333333333334, 61.736666666666665, 61.986666666666665, 61.61666666666667, 62.075, 62.085, 65.89333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 300, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.304, Test loss: 2.303, Test accuracy: 10.00 

Round   0, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 10.00 

Round   1, Train loss: 2.304, Test loss: 2.303, Test accuracy: 10.00 

Round   1, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 10.00 

Round   2, Train loss: 2.303, Test loss: 2.303, Test accuracy: 10.00 

Round   2, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.00 

Round   3, Train loss: 2.303, Test loss: 2.303, Test accuracy: 10.00 

Round   3, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.00 

Round   4, Train loss: 2.302, Test loss: 2.303, Test accuracy: 10.00 

Round   4, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00 

Round   5, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.00 

Round   5, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.00 

Round   6, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.00 

Round   6, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 10.00 

Round   7, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00 

Round   7, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 10.00 

Round   8, Train loss: 2.302, Test loss: 2.301, Test accuracy: 10.00 

Round   8, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 10.00 

Round   9, Train loss: 2.302, Test loss: 2.301, Test accuracy: 10.00 

Round   9, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 10.00 

Round  10, Train loss: 2.302, Test loss: 2.301, Test accuracy: 10.00 

Round  10, Global train loss: 2.302, Global test loss: 2.300, Global test accuracy: 10.00 

Round  11, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.00 

Round  11, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.00 

Round  12, Train loss: 2.301, Test loss: 2.300, Test accuracy: 10.00 

Round  12, Global train loss: 2.301, Global test loss: 2.299, Global test accuracy: 10.00 

Round  13, Train loss: 2.300, Test loss: 2.299, Test accuracy: 10.00 

Round  13, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 10.00 

Round  14, Train loss: 2.298, Test loss: 2.299, Test accuracy: 10.00 

Round  14, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.00 

Round  15, Train loss: 2.298, Test loss: 2.299, Test accuracy: 10.00 

Round  15, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.00 

Round  16, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.00 

Round  16, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 10.00 

Round  17, Train loss: 2.299, Test loss: 2.298, Test accuracy: 10.00 

Round  17, Global train loss: 2.299, Global test loss: 2.297, Global test accuracy: 10.00 

Round  18, Train loss: 2.297, Test loss: 2.298, Test accuracy: 10.00 

Round  18, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.00 

Round  19, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.00 

Round  19, Global train loss: 2.297, Global test loss: 2.296, Global test accuracy: 10.00 

Round  20, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.00 

Round  20, Global train loss: 2.297, Global test loss: 2.296, Global test accuracy: 10.00 

Round  21, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.00 

Round  21, Global train loss: 2.296, Global test loss: 2.295, Global test accuracy: 10.00 

Round  22, Train loss: 2.297, Test loss: 2.296, Test accuracy: 10.00 

Round  22, Global train loss: 2.297, Global test loss: 2.295, Global test accuracy: 10.00 

Round  23, Train loss: 2.296, Test loss: 2.295, Test accuracy: 10.00 

Round  23, Global train loss: 2.296, Global test loss: 2.294, Global test accuracy: 10.00 

Round  24, Train loss: 2.296, Test loss: 2.295, Test accuracy: 10.00 

Round  24, Global train loss: 2.296, Global test loss: 2.294, Global test accuracy: 10.00 

Round  25, Train loss: 2.296, Test loss: 2.295, Test accuracy: 10.00 

Round  25, Global train loss: 2.296, Global test loss: 2.294, Global test accuracy: 10.00 

Round  26, Train loss: 2.295, Test loss: 2.294, Test accuracy: 10.00 

Round  26, Global train loss: 2.295, Global test loss: 2.293, Global test accuracy: 10.00 

Round  27, Train loss: 2.296, Test loss: 2.294, Test accuracy: 10.00 

Round  27, Global train loss: 2.296, Global test loss: 2.293, Global test accuracy: 10.00 

Round  28, Train loss: 2.294, Test loss: 2.293, Test accuracy: 10.00 

Round  28, Global train loss: 2.294, Global test loss: 2.292, Global test accuracy: 10.00 

Round  29, Train loss: 2.293, Test loss: 2.293, Test accuracy: 10.00 

Round  29, Global train loss: 2.293, Global test loss: 2.292, Global test accuracy: 10.00 

Round  30, Train loss: 2.294, Test loss: 2.292, Test accuracy: 10.00 

Round  30, Global train loss: 2.294, Global test loss: 2.291, Global test accuracy: 10.00 

Round  31, Train loss: 2.294, Test loss: 2.292, Test accuracy: 10.01 

Round  31, Global train loss: 2.294, Global test loss: 2.291, Global test accuracy: 10.00 

Round  32, Train loss: 2.292, Test loss: 2.292, Test accuracy: 10.03 

Round  32, Global train loss: 2.292, Global test loss: 2.290, Global test accuracy: 10.04 

Round  33, Train loss: 2.292, Test loss: 2.291, Test accuracy: 10.05 

Round  33, Global train loss: 2.292, Global test loss: 2.290, Global test accuracy: 10.04 

Round  34, Train loss: 2.291, Test loss: 2.290, Test accuracy: 10.09 

Round  34, Global train loss: 2.291, Global test loss: 2.289, Global test accuracy: 10.07 

Round  35, Train loss: 2.292, Test loss: 2.290, Test accuracy: 10.08 

Round  35, Global train loss: 2.292, Global test loss: 2.289, Global test accuracy: 10.11 

Round  36, Train loss: 2.291, Test loss: 2.290, Test accuracy: 10.11 

Round  36, Global train loss: 2.291, Global test loss: 2.288, Global test accuracy: 10.15 

Round  37, Train loss: 2.290, Test loss: 2.289, Test accuracy: 10.15 

Round  37, Global train loss: 2.290, Global test loss: 2.288, Global test accuracy: 10.16 

Round  38, Train loss: 2.290, Test loss: 2.289, Test accuracy: 10.27 

Round  38, Global train loss: 2.290, Global test loss: 2.287, Global test accuracy: 10.55 

Round  39, Train loss: 2.290, Test loss: 2.289, Test accuracy: 10.38 

Round  39, Global train loss: 2.290, Global test loss: 2.287, Global test accuracy: 10.84 

Round  40, Train loss: 2.287, Test loss: 2.288, Test accuracy: 10.58 

Round  40, Global train loss: 2.287, Global test loss: 2.286, Global test accuracy: 10.99 

Round  41, Train loss: 2.287, Test loss: 2.288, Test accuracy: 10.86 

Round  41, Global train loss: 2.287, Global test loss: 2.285, Global test accuracy: 11.59 

Round  42, Train loss: 2.287, Test loss: 2.287, Test accuracy: 11.13 

Round  42, Global train loss: 2.287, Global test loss: 2.284, Global test accuracy: 11.81 

Round  43, Train loss: 2.287, Test loss: 2.286, Test accuracy: 11.44 

Round  43, Global train loss: 2.287, Global test loss: 2.284, Global test accuracy: 12.14 

Round  44, Train loss: 2.287, Test loss: 2.285, Test accuracy: 11.83 

Round  44, Global train loss: 2.287, Global test loss: 2.283, Global test accuracy: 12.40 

Round  45, Train loss: 2.283, Test loss: 2.285, Test accuracy: 12.27 

Round  45, Global train loss: 2.283, Global test loss: 2.282, Global test accuracy: 13.14 

Round  46, Train loss: 2.282, Test loss: 2.284, Test accuracy: 12.43 

Round  46, Global train loss: 2.282, Global test loss: 2.282, Global test accuracy: 13.28 

Round  47, Train loss: 2.285, Test loss: 2.283, Test accuracy: 12.91 

Round  47, Global train loss: 2.285, Global test loss: 2.281, Global test accuracy: 13.26 

Round  48, Train loss: 2.285, Test loss: 2.282, Test accuracy: 12.99 

Round  48, Global train loss: 2.285, Global test loss: 2.280, Global test accuracy: 13.24 

Round  49, Train loss: 2.283, Test loss: 2.282, Test accuracy: 13.33 

Round  49, Global train loss: 2.283, Global test loss: 2.279, Global test accuracy: 13.80 

Round  50, Train loss: 2.282, Test loss: 2.280, Test accuracy: 13.61 

Round  50, Global train loss: 2.282, Global test loss: 2.278, Global test accuracy: 13.86 

Round  51, Train loss: 2.281, Test loss: 2.279, Test accuracy: 13.75 

Round  51, Global train loss: 2.281, Global test loss: 2.277, Global test accuracy: 13.87 

Round  52, Train loss: 2.281, Test loss: 2.279, Test accuracy: 13.88 

Round  52, Global train loss: 2.281, Global test loss: 2.276, Global test accuracy: 14.33 

Round  53, Train loss: 2.281, Test loss: 2.277, Test accuracy: 14.19 

Round  53, Global train loss: 2.281, Global test loss: 2.275, Global test accuracy: 14.49 

Round  54, Train loss: 2.281, Test loss: 2.276, Test accuracy: 14.44 

Round  54, Global train loss: 2.281, Global test loss: 2.273, Global test accuracy: 14.65 

Round  55, Train loss: 2.280, Test loss: 2.275, Test accuracy: 14.40 

Round  55, Global train loss: 2.280, Global test loss: 2.273, Global test accuracy: 14.71 

Round  56, Train loss: 2.276, Test loss: 2.274, Test accuracy: 14.49 

Round  56, Global train loss: 2.276, Global test loss: 2.271, Global test accuracy: 14.69 

Round  57, Train loss: 2.278, Test loss: 2.273, Test accuracy: 14.64 

Round  57, Global train loss: 2.278, Global test loss: 2.271, Global test accuracy: 14.77 

Round  58, Train loss: 2.279, Test loss: 2.272, Test accuracy: 14.63 

Round  58, Global train loss: 2.279, Global test loss: 2.269, Global test accuracy: 14.88 

Round  59, Train loss: 2.273, Test loss: 2.271, Test accuracy: 14.72 

Round  59, Global train loss: 2.273, Global test loss: 2.269, Global test accuracy: 14.87 

Round  60, Train loss: 2.278, Test loss: 2.270, Test accuracy: 14.84 

Round  60, Global train loss: 2.278, Global test loss: 2.268, Global test accuracy: 15.06 

Round  61, Train loss: 2.274, Test loss: 2.269, Test accuracy: 15.19 

Round  61, Global train loss: 2.274, Global test loss: 2.266, Global test accuracy: 15.15 

Round  62, Train loss: 2.275, Test loss: 2.268, Test accuracy: 15.18 

Round  62, Global train loss: 2.275, Global test loss: 2.265, Global test accuracy: 15.22 

Round  63, Train loss: 2.271, Test loss: 2.266, Test accuracy: 15.08 

Round  63, Global train loss: 2.271, Global test loss: 2.263, Global test accuracy: 14.84 

Round  64, Train loss: 2.276, Test loss: 2.265, Test accuracy: 15.31 

Round  64, Global train loss: 2.276, Global test loss: 2.261, Global test accuracy: 15.59 

Round  65, Train loss: 2.271, Test loss: 2.263, Test accuracy: 15.76 

Round  65, Global train loss: 2.271, Global test loss: 2.261, Global test accuracy: 16.53 

Round  66, Train loss: 2.277, Test loss: 2.262, Test accuracy: 15.70 

Round  66, Global train loss: 2.277, Global test loss: 2.258, Global test accuracy: 15.61 

Round  67, Train loss: 2.270, Test loss: 2.260, Test accuracy: 15.42 

Round  67, Global train loss: 2.270, Global test loss: 2.257, Global test accuracy: 15.20 

Round  68, Train loss: 2.270, Test loss: 2.259, Test accuracy: 15.60 

Round  68, Global train loss: 2.270, Global test loss: 2.255, Global test accuracy: 15.96 

Round  69, Train loss: 2.266, Test loss: 2.258, Test accuracy: 15.86 

Round  69, Global train loss: 2.266, Global test loss: 2.255, Global test accuracy: 16.36 

Round  70, Train loss: 2.267, Test loss: 2.256, Test accuracy: 15.81 

Round  70, Global train loss: 2.267, Global test loss: 2.254, Global test accuracy: 16.23 

Round  71, Train loss: 2.268, Test loss: 2.256, Test accuracy: 16.14 

Round  71, Global train loss: 2.268, Global test loss: 2.254, Global test accuracy: 16.76 

Round  72, Train loss: 2.264, Test loss: 2.255, Test accuracy: 16.38 

Round  72, Global train loss: 2.264, Global test loss: 2.253, Global test accuracy: 17.01 

Round  73, Train loss: 2.266, Test loss: 2.254, Test accuracy: 16.67 

Round  73, Global train loss: 2.266, Global test loss: 2.252, Global test accuracy: 16.97 

Round  74, Train loss: 2.266, Test loss: 2.253, Test accuracy: 16.75 

Round  74, Global train loss: 2.266, Global test loss: 2.251, Global test accuracy: 17.02 

Round  75, Train loss: 2.268, Test loss: 2.252, Test accuracy: 16.76 

Round  75, Global train loss: 2.268, Global test loss: 2.250, Global test accuracy: 17.18 

Round  76, Train loss: 2.266, Test loss: 2.252, Test accuracy: 17.17 

Round  76, Global train loss: 2.266, Global test loss: 2.251, Global test accuracy: 18.15 

Round  77, Train loss: 2.264, Test loss: 2.251, Test accuracy: 17.74 

Round  77, Global train loss: 2.264, Global test loss: 2.250, Global test accuracy: 18.57 

Round  78, Train loss: 2.262, Test loss: 2.250, Test accuracy: 17.68 

Round  78, Global train loss: 2.262, Global test loss: 2.248, Global test accuracy: 18.63 

Round  79, Train loss: 2.262, Test loss: 2.249, Test accuracy: 17.76 

Round  79, Global train loss: 2.262, Global test loss: 2.247, Global test accuracy: 18.74 

Round  80, Train loss: 2.261, Test loss: 2.249, Test accuracy: 17.86 

Round  80, Global train loss: 2.261, Global test loss: 2.246, Global test accuracy: 18.66 

Round  81, Train loss: 2.259, Test loss: 2.247, Test accuracy: 18.24 

Round  81, Global train loss: 2.259, Global test loss: 2.245, Global test accuracy: 18.87 

Round  82, Train loss: 2.257, Test loss: 2.246, Test accuracy: 18.32 

Round  82, Global train loss: 2.257, Global test loss: 2.243, Global test accuracy: 18.87 

Round  83, Train loss: 2.260, Test loss: 2.246, Test accuracy: 18.72 

Round  83, Global train loss: 2.260, Global test loss: 2.243, Global test accuracy: 19.32 

Round  84, Train loss: 2.258, Test loss: 2.245, Test accuracy: 19.12 

Round  84, Global train loss: 2.258, Global test loss: 2.242, Global test accuracy: 19.79 

Round  85, Train loss: 2.261, Test loss: 2.243, Test accuracy: 19.48 

Round  85, Global train loss: 2.261, Global test loss: 2.241, Global test accuracy: 19.89 

Round  86, Train loss: 2.253, Test loss: 2.243, Test accuracy: 19.73 

Round  86, Global train loss: 2.253, Global test loss: 2.242, Global test accuracy: 20.29 

Round  87, Train loss: 2.254, Test loss: 2.242, Test accuracy: 19.79 

Round  87, Global train loss: 2.254, Global test loss: 2.239, Global test accuracy: 20.40 

Round  88, Train loss: 2.252, Test loss: 2.241, Test accuracy: 19.89 

Round  88, Global train loss: 2.252, Global test loss: 2.238, Global test accuracy: 20.34 

Round  89, Train loss: 2.257, Test loss: 2.241, Test accuracy: 19.99 

Round  89, Global train loss: 2.257, Global test loss: 2.239, Global test accuracy: 20.79 

Round  90, Train loss: 2.250, Test loss: 2.240, Test accuracy: 20.08 

Round  90, Global train loss: 2.250, Global test loss: 2.238, Global test accuracy: 20.83 

Round  91, Train loss: 2.254, Test loss: 2.238, Test accuracy: 20.11 

Round  91, Global train loss: 2.254, Global test loss: 2.235, Global test accuracy: 20.72 

Round  92, Train loss: 2.253, Test loss: 2.237, Test accuracy: 20.18 

Round  92, Global train loss: 2.253, Global test loss: 2.233, Global test accuracy: 20.46 

Round  93, Train loss: 2.251, Test loss: 2.236, Test accuracy: 20.31 

Round  93, Global train loss: 2.251, Global test loss: 2.233, Global test accuracy: 21.14 

Round  94, Train loss: 2.248, Test loss: 2.236, Test accuracy: 20.43 

Round  94, Global train loss: 2.248, Global test loss: 2.233, Global test accuracy: 20.82 

Round  95, Train loss: 2.245, Test loss: 2.235, Test accuracy: 20.41 

Round  95, Global train loss: 2.245, Global test loss: 2.231, Global test accuracy: 21.01 

Round  96, Train loss: nan, Test loss: nan, Test accuracy: 19.93 

Round  96, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  97, Train loss: nan, Test loss: nan, Test accuracy: 17.43 

Round  97, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  98, Train loss: nan, Test loss: nan, Test accuracy: 15.95 

Round  98, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round  99, Train loss: nan, Test loss: nan, Test accuracy: 14.28 

Round  99, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 100, Train loss: nan, Test loss: nan, Test accuracy: 13.77 

Round 100, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 101, Train loss: nan, Test loss: nan, Test accuracy: 12.16 

Round 101, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 102, Train loss: nan, Test loss: nan, Test accuracy: 11.54 

Round 102, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 103, Train loss: nan, Test loss: nan, Test accuracy: 10.49 

Round 103, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 104, Train loss: nan, Test loss: nan, Test accuracy: 10.49 

Round 104, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 105, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 105, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 106, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 106, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 107, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 107, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 108, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 108, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 109, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 109, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 110, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 110, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 111, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 111, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 112, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 112, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 113, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 113, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 114, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 114, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 115, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 115, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 116, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 116, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 117, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 117, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 118, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 118, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 119, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 119, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 120, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 120, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 121, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 121, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 122, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 122, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 123, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 123, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 124, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 124, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 125, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 125, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 126, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 126, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 127, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 127, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 128, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 128, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 129, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 129, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 130, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 130, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 131, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 131, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 132, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 132, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 133, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 133, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 134, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 134, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 135, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 135, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 136, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 136, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 137, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 137, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 138, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 138, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 139, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 139, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 140, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 140, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 141, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 141, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 142, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 142, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 143, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 143, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 144, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 144, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 145, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 145, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 146, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 146, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 147, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 147, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 148, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 148, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 149, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 149, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 150, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 150, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 151, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 151, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 152, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 152, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 153, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 153, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 154, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 154, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 155, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 155, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 156, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 156, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 157, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 157, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 158, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 158, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 159, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 159, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 160, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 160, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 161, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 161, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 162, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 162, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 163, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 163, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 164, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 164, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 165, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 165, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 166, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 166, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 167, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 167, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 168, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 168, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 169, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 169, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 170, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 170, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 171, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 171, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 172, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 172, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 173, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 173, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 174, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 174, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 175, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 175, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 176, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 176, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 177, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 177, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 178, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 178, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 179, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 179, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 180, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 180, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 181, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 181, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 182, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 182, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 183, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 183, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 184, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 184, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 185, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 185, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 186, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 186, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 187, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 187, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 188, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 188, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 189, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 189, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 190, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 190, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 191, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 191, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 192, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 192, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 193, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 193, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 194, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 194, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 195, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 195, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 196, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 196, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 197, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 197, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 198, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 198, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 199, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 199, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 200, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 200, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 201, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 201, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 202, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 202, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 203, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 203, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 204, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 204, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 205, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 205, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 206, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 206, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 207, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 207, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 208, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 208, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 209, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 209, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 210, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 210, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 211, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 211, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 212, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 212, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 213, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 213, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 214, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 214, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 215, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 215, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 216, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 216, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 217, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 217, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 218, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 218, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 219, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 219, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 220, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 220, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 221, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 221, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 222, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 222, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 223, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 223, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 224, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 224, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 225, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 225, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 226, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 226, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 227, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 227, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 228, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 228, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 229, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 229, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 230, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 230, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 231, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 231, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 232, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 232, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 233, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 233, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 234, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 234, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 235, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 235, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 236, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 236, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 237, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 237, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 238, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 238, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 239, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 239, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 240, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 240, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 241, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 241, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 242, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 242, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 243, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 243, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 244, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 244, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 245, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 245, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 246, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 246, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 247, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 247, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 248, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 248, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 249, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 249, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 250, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 250, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 251, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 251, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 252, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 252, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 253, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 253, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 254, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 254, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 255, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 255, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 256, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 256, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 257, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 257, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 258, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 258, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 259, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 259, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 260, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 260, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 261, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 261, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 262, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 262, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 263, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 263, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 264, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 264, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 265, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 265, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 266, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 266, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 267, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 267, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 268, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 268, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 269, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 269, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 270, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 270, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 271, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 271, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 272, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 272, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 273, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 273, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 274, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 274, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 275, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 275, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 276, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 276, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 277, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 277, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 278, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 278, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 279, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 279, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 280, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 280, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 281, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 281, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 282, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 282, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 283, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 283, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 284, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 284, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 285, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 285, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 286, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 286, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 287, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 287, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 288, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 288, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 289, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 289, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 290, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 290, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 291, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 291, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 292, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 292, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 293, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 293, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 294, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 294, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 295, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 295, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 296, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 296, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 297, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 297, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 298, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 298, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Round 299, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Round 299, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Final Round, Train loss: nan, Test loss: nan, Test accuracy: 10.00 

Final Round, Global train loss: nan, Global test loss: nan, Global test accuracy: 10.00 

Average accuracy final 10 rounds: 10.0 

Average global accuracy final 10 rounds: 10.0 

9100.784269809723
[1.5366737842559814, 2.8666718006134033, 4.291596174240112, 5.712687253952026, 7.121082305908203, 8.561850786209106, 9.963548421859741, 11.386133909225464, 12.807939291000366, 14.236128807067871, 15.677605867385864, 17.092681884765625, 18.537366151809692, 19.970504999160767, 21.39927864074707, 22.81325078010559, 24.27887463569641, 25.677322387695312, 27.059053897857666, 28.519235849380493, 29.945374011993408, 31.3674418926239, 32.83940863609314, 34.282021045684814, 35.720353841781616, 37.1489052772522, 38.56895613670349, 40.02143979072571, 41.437506437301636, 42.88278007507324, 44.32652235031128, 45.74311542510986, 47.15468168258667, 48.58602595329285, 50.025062799453735, 51.44630694389343, 52.87824892997742, 54.29046678543091, 55.71108675003052, 57.11770749092102, 58.53237271308899, 59.949806928634644, 61.36241841316223, 62.78919172286987, 64.21219110488892, 65.66727328300476, 67.07689619064331, 68.47737956047058, 69.90794587135315, 71.27786684036255, 72.6406774520874, 74.00808644294739, 75.35545015335083, 76.74322962760925, 78.15264058113098, 79.5107274055481, 80.87064671516418, 82.26103448867798, 83.67616033554077, 85.03740239143372, 86.46554613113403, 87.8666684627533, 89.27410769462585, 90.61653566360474, 92.05212903022766, 93.46179938316345, 94.88125038146973, 96.30057001113892, 97.67337417602539, 99.07886099815369, 100.51066255569458, 101.89711093902588, 103.27853298187256, 104.6461775302887, 106.00914025306702, 107.40325832366943, 108.76241326332092, 110.12538266181946, 111.55125451087952, 112.93300867080688, 114.29872679710388, 115.67339301109314, 117.03759837150574, 118.44807457923889, 119.80142664909363, 121.16758728027344, 122.55375266075134, 123.92812490463257, 125.30699849128723, 126.74473071098328, 128.1160225868225, 129.51276874542236, 130.90729880332947, 132.31913876533508, 133.71625566482544, 135.0581135749817, 136.40203046798706, 137.7490735054016, 139.11020588874817, 140.469806432724, 141.8232913017273, 143.21946740150452, 144.5806279182434, 145.95236945152283, 147.31610870361328, 148.6856427192688, 150.01800060272217, 151.38005805015564, 152.73196363449097, 154.11093759536743, 155.46598625183105, 156.8154661655426, 158.17094802856445, 159.58304119110107, 160.97983288764954, 162.32864427566528, 163.71656942367554, 165.16622161865234, 166.5486524105072, 167.9546926021576, 169.392169713974, 170.79185438156128, 172.18830728530884, 173.6298999786377, 175.04240822792053, 176.45056676864624, 177.82756733894348, 179.17625999450684, 180.59902453422546, 182.04035639762878, 183.40609121322632, 184.78882002830505, 186.13038682937622, 187.53691697120667, 188.95886516571045, 190.32410550117493, 191.72816801071167, 193.17569541931152, 194.53741097450256, 195.89475083351135, 197.3132348060608, 198.69652318954468, 200.10125756263733, 201.50333714485168, 202.87056255340576, 204.2127435207367, 205.68615818023682, 207.10349869728088, 208.49085402488708, 209.8346767425537, 211.19778108596802, 212.54568600654602, 213.88362884521484, 215.27079939842224, 216.57141208648682, 217.91670274734497, 219.22988200187683, 220.63422417640686, 222.01510643959045, 223.34762525558472, 224.70903491973877, 226.08807682991028, 227.41700387001038, 228.75091934204102, 230.07661175727844, 231.3936107158661, 232.76183485984802, 234.14400362968445, 235.5312077999115, 236.90484261512756, 238.294673204422, 239.548166513443, 240.87534070014954, 242.21238541603088, 243.56258034706116, 244.9276978969574, 246.29232692718506, 247.6572458744049, 249.03148913383484, 250.3860421180725, 251.7495219707489, 253.0948486328125, 254.4532287120819, 255.81922149658203, 257.1822278499603, 258.52848529815674, 259.9061665534973, 261.25897002220154, 262.63507604599, 264.0041913986206, 265.37489557266235, 266.7563588619232, 268.1334090232849, 269.5022859573364, 270.88102746009827, 272.25850534439087, 273.6333131790161, 275.00999999046326, 276.38831853866577, 277.75269627571106, 279.1220872402191, 280.48793601989746, 281.8483214378357, 283.2181046009064, 284.5776424407959, 285.9363293647766, 287.3025395870209, 288.65756845474243, 290.0255491733551, 291.39824748039246, 292.7623836994171, 294.13360929489136, 295.516104221344, 296.88176822662354, 298.2340714931488, 299.6056830883026, 300.96766567230225, 302.3284282684326, 303.6959025859833, 305.06145763397217, 306.4335262775421, 307.80629444122314, 309.1821711063385, 310.5514323711395, 311.9095392227173, 313.2703113555908, 314.648353099823, 316.0184667110443, 317.39555191993713, 318.77214097976685, 320.1519134044647, 321.53074073791504, 322.9155695438385, 324.30657482147217, 325.6908071041107, 327.0730028152466, 328.4523696899414, 329.8202953338623, 331.1945950984955, 332.5621292591095, 333.9388048648834, 335.30636072158813, 336.68026900291443, 338.0519745349884, 339.4270586967468, 340.8039698600769, 342.17240357398987, 343.55408549308777, 344.9418113231659, 346.31665658950806, 347.6968195438385, 349.06084299087524, 350.4318106174469, 351.80166935920715, 353.16631293296814, 354.5272116661072, 355.90533995628357, 357.26539635658264, 358.63330936431885, 360.0023498535156, 361.3679368495941, 362.736839056015, 364.11169695854187, 365.47385478019714, 366.8289496898651, 368.1890730857849, 369.5562047958374, 370.91749477386475, 372.2844030857086, 373.66935110092163, 375.0382168292999, 376.4067587852478, 377.7815010547638, 379.13549304008484, 380.5147624015808, 381.8878102302551, 383.2606327533722, 384.620076417923, 385.9638042449951, 387.3309271335602, 388.68965220451355, 390.04551339149475, 391.4046332836151, 392.7597978115082, 394.1084122657776, 395.4734926223755, 396.8374309539795, 398.1966907978058, 399.5667374134064, 400.9224154949188, 402.29253339767456, 403.66390800476074, 405.0249807834625, 406.39503479003906, 407.7553596496582, 409.11796164512634, 410.4799335002899, 411.8493700027466, 413.2160656452179, 414.5786862373352, 417.3153831958771]
[10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.005, 10.0275, 10.05, 10.085, 10.08, 10.1075, 10.155, 10.27, 10.375, 10.58, 10.855, 11.135, 11.4425, 11.83, 12.2725, 12.43, 12.91, 12.9925, 13.33, 13.61, 13.7525, 13.885, 14.1875, 14.4375, 14.405, 14.4875, 14.6425, 14.6275, 14.725, 14.84, 15.185, 15.18, 15.0775, 15.3075, 15.7575, 15.6975, 15.42, 15.5975, 15.8575, 15.8125, 16.145, 16.3825, 16.6725, 16.7525, 16.7575, 17.1725, 17.7375, 17.675, 17.7575, 17.8625, 18.2375, 18.3175, 18.72, 19.1175, 19.475, 19.7275, 19.7875, 19.89, 19.99, 20.0825, 20.1075, 20.175, 20.3125, 20.425, 20.415, 19.9275, 17.425, 15.9475, 14.28, 13.7675, 12.16, 11.535, 10.49, 10.49, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
Round   0, Train loss: 2.251, Test loss: 2.070, Test accuracy: 26.21
Round   1, Train loss: 2.056, Test loss: 1.869, Test accuracy: 32.59
Round   2, Train loss: 1.915, Test loss: 1.713, Test accuracy: 37.52
Round   3, Train loss: 1.824, Test loss: 1.625, Test accuracy: 40.85
Round   4, Train loss: 1.695, Test loss: 1.529, Test accuracy: 44.74
Round   5, Train loss: 1.677, Test loss: 1.501, Test accuracy: 45.09
Round   6, Train loss: 1.616, Test loss: 1.458, Test accuracy: 46.88
Round   7, Train loss: 1.587, Test loss: 1.407, Test accuracy: 49.52
Round   8, Train loss: 1.557, Test loss: 1.394, Test accuracy: 49.55
Round   9, Train loss: 1.488, Test loss: 1.355, Test accuracy: 50.94
Round  10, Train loss: 1.490, Test loss: 1.331, Test accuracy: 51.76
Round  11, Train loss: 1.391, Test loss: 1.306, Test accuracy: 52.59
Round  12, Train loss: 1.372, Test loss: 1.267, Test accuracy: 54.07
Round  13, Train loss: 1.340, Test loss: 1.250, Test accuracy: 55.33
Round  14, Train loss: 1.285, Test loss: 1.230, Test accuracy: 56.03
Round  15, Train loss: 1.331, Test loss: 1.189, Test accuracy: 57.79
Round  16, Train loss: 1.236, Test loss: 1.202, Test accuracy: 57.29
Round  17, Train loss: 1.204, Test loss: 1.172, Test accuracy: 58.86
Round  18, Train loss: 1.235, Test loss: 1.138, Test accuracy: 59.43
Round  19, Train loss: 1.179, Test loss: 1.124, Test accuracy: 59.66
Round  20, Train loss: 1.138, Test loss: 1.124, Test accuracy: 60.09
Round  21, Train loss: 1.132, Test loss: 1.112, Test accuracy: 61.01
Round  22, Train loss: 1.082, Test loss: 1.113, Test accuracy: 60.77
Round  23, Train loss: 1.080, Test loss: 1.083, Test accuracy: 61.55
Round  24, Train loss: 1.058, Test loss: 1.080, Test accuracy: 61.91
Round  25, Train loss: 1.038, Test loss: 1.074, Test accuracy: 62.04
Round  26, Train loss: 1.012, Test loss: 1.078, Test accuracy: 61.88
Round  27, Train loss: 0.943, Test loss: 1.078, Test accuracy: 62.35
Round  28, Train loss: 0.942, Test loss: 1.065, Test accuracy: 62.81
Round  29, Train loss: 0.964, Test loss: 1.054, Test accuracy: 63.91
Round  30, Train loss: 0.902, Test loss: 1.054, Test accuracy: 63.51
Round  31, Train loss: 0.918, Test loss: 1.063, Test accuracy: 63.11
Round  32, Train loss: 0.848, Test loss: 1.053, Test accuracy: 64.09
Round  33, Train loss: 0.901, Test loss: 1.038, Test accuracy: 64.20
Round  34, Train loss: 0.874, Test loss: 1.032, Test accuracy: 64.86
Round  35, Train loss: 0.872, Test loss: 1.016, Test accuracy: 65.03
Round  36, Train loss: 0.812, Test loss: 1.015, Test accuracy: 65.66
Round  37, Train loss: 0.837, Test loss: 1.007, Test accuracy: 65.11
Round  38, Train loss: 0.784, Test loss: 1.016, Test accuracy: 65.02
Round  39, Train loss: 0.780, Test loss: 1.017, Test accuracy: 65.49
Round  40, Train loss: 0.785, Test loss: 1.016, Test accuracy: 65.27
Round  41, Train loss: 0.727, Test loss: 1.017, Test accuracy: 65.49
Round  42, Train loss: 0.755, Test loss: 1.031, Test accuracy: 65.42
Round  43, Train loss: 0.740, Test loss: 1.027, Test accuracy: 65.47
Round  44, Train loss: 0.737, Test loss: 1.030, Test accuracy: 65.88
Round  45, Train loss: 0.701, Test loss: 1.013, Test accuracy: 65.92
Round  46, Train loss: 0.690, Test loss: 1.032, Test accuracy: 66.04
Round  47, Train loss: 0.683, Test loss: 1.030, Test accuracy: 66.47
Round  48, Train loss: 0.670, Test loss: 1.010, Test accuracy: 66.66
Round  49, Train loss: 0.668, Test loss: 1.010, Test accuracy: 66.53
Round  50, Train loss: 0.618, Test loss: 1.023, Test accuracy: 66.28
Round  51, Train loss: 0.668, Test loss: 1.016, Test accuracy: 66.47
Round  52, Train loss: 0.641, Test loss: 1.025, Test accuracy: 67.14
Round  53, Train loss: 0.615, Test loss: 1.023, Test accuracy: 67.02
Round  54, Train loss: 0.625, Test loss: 1.019, Test accuracy: 66.84
Round  55, Train loss: 0.604, Test loss: 1.045, Test accuracy: 66.84
Round  56, Train loss: 0.592, Test loss: 1.042, Test accuracy: 66.89
Round  57, Train loss: 0.575, Test loss: 1.043, Test accuracy: 67.14
Round  58, Train loss: 0.637, Test loss: 1.014, Test accuracy: 66.92
Round  59, Train loss: 0.653, Test loss: 1.003, Test accuracy: 67.63
Round  60, Train loss: 0.569, Test loss: 1.026, Test accuracy: 67.45
Round  61, Train loss: 0.556, Test loss: 1.015, Test accuracy: 67.39
Round  62, Train loss: 0.564, Test loss: 1.050, Test accuracy: 66.76
Round  63, Train loss: 0.503, Test loss: 1.042, Test accuracy: 66.92
Round  64, Train loss: 0.578, Test loss: 1.036, Test accuracy: 67.14
Round  65, Train loss: 0.502, Test loss: 1.051, Test accuracy: 67.33
Round  66, Train loss: 0.483, Test loss: 1.088, Test accuracy: 66.48
Round  67, Train loss: 0.545, Test loss: 1.038, Test accuracy: 67.34
Round  68, Train loss: 0.533, Test loss: 1.044, Test accuracy: 67.78
Round  69, Train loss: 0.514, Test loss: 1.033, Test accuracy: 67.51
Round  70, Train loss: 0.468, Test loss: 1.083, Test accuracy: 67.59
Round  71, Train loss: 0.448, Test loss: 1.072, Test accuracy: 67.94
Round  72, Train loss: 0.494, Test loss: 1.048, Test accuracy: 67.75
Round  73, Train loss: 0.532, Test loss: 1.059, Test accuracy: 67.37
Round  74, Train loss: 0.486, Test loss: 1.079, Test accuracy: 67.92
Round  75, Train loss: 0.457, Test loss: 1.074, Test accuracy: 68.02
Round  76, Train loss: 0.495, Test loss: 1.043, Test accuracy: 68.32
Round  77, Train loss: 0.475, Test loss: 1.065, Test accuracy: 68.13
Round  78, Train loss: 0.444, Test loss: 1.072, Test accuracy: 67.86
Round  79, Train loss: 0.425, Test loss: 1.076, Test accuracy: 67.99
Round  80, Train loss: 0.401, Test loss: 1.105, Test accuracy: 67.83
Round  81, Train loss: 0.500, Test loss: 1.052, Test accuracy: 68.43
Round  82, Train loss: 0.457, Test loss: 1.039, Test accuracy: 68.39
Round  83, Train loss: 0.432, Test loss: 1.040, Test accuracy: 68.66
Round  84, Train loss: 0.457, Test loss: 1.054, Test accuracy: 68.27
Round  85, Train loss: 0.430, Test loss: 1.070, Test accuracy: 68.33
Round  86, Train loss: 0.414, Test loss: 1.070, Test accuracy: 68.86
Round  87, Train loss: 0.408, Test loss: 1.099, Test accuracy: 68.22
Round  88, Train loss: 0.416, Test loss: 1.060, Test accuracy: 68.69
Round  89, Train loss: 0.443, Test loss: 1.057, Test accuracy: 68.79
Round  90, Train loss: 0.391, Test loss: 1.064, Test accuracy: 68.89
Round  91, Train loss: 0.426, Test loss: 1.052, Test accuracy: 69.28
Round  92, Train loss: 0.386, Test loss: 1.076, Test accuracy: 68.71
Round  93, Train loss: 0.381, Test loss: 1.095, Test accuracy: 68.58
Round  94, Train loss: 0.410, Test loss: 1.084, Test accuracy: 68.94
Round  95, Train loss: 0.408, Test loss: 1.085, Test accuracy: 68.83
Round  96, Train loss: 0.402, Test loss: 1.087, Test accuracy: 68.51
Round  97, Train loss: 0.410, Test loss: 1.078, Test accuracy: 68.93
Round  98, Train loss: 0.348, Test loss: 1.101, Test accuracy: 69.09
Round  99, Train loss: 0.372, Test loss: 1.117, Test accuracy: 68.36
Final Round, Train loss: 0.356, Test loss: 1.067, Test accuracy: 69.52
Average accuracy final 10 rounds: 68.81099999999999
2654.6636390686035
[3.391216993331909, 6.510867595672607, 9.627904176712036, 12.758474349975586, 15.405935764312744, 18.05504059791565, 20.710093021392822, 23.37925386428833, 26.018192529678345, 28.668302536010742, 31.316418647766113, 33.96986103057861, 36.617799043655396, 39.26742959022522, 41.911357402801514, 44.52457666397095, 47.16256785392761, 49.79901170730591, 52.448546171188354, 55.09377598762512, 57.75675129890442, 60.41999816894531, 63.062193155288696, 65.70619559288025, 68.3485734462738, 70.98742985725403, 73.62404823303223, 76.26889777183533, 78.92654967308044, 81.58596634864807, 84.21492099761963, 86.87558031082153, 89.51191544532776, 92.14417147636414, 94.76355409622192, 97.3886559009552, 100.02300000190735, 102.65499973297119, 105.28667116165161, 107.93743228912354, 110.58640336990356, 113.25687456130981, 116.2213888168335, 119.17467761039734, 122.14585423469543, 125.09185647964478, 128.04859399795532, 131.0196168422699, 133.98932790756226, 136.91852140426636, 139.86138105392456, 142.80178880691528, 145.472261428833, 148.13433814048767, 150.8150827884674, 153.4735119342804, 156.14671564102173, 158.80476355552673, 161.7787573337555, 164.74611735343933, 167.72637343406677, 170.36703634262085, 173.00465631484985, 175.65180325508118, 178.29632782936096, 180.94431042671204, 183.59679007530212, 186.24911618232727, 188.8688509464264, 191.50142908096313, 194.13728070259094, 196.78619360923767, 199.41509628295898, 202.05049777030945, 204.6861605644226, 207.32844591140747, 209.95688319206238, 212.59271621704102, 215.2356195449829, 217.86853075027466, 220.5061902999878, 223.14267492294312, 225.78175926208496, 228.39532113075256, 231.01201033592224, 233.65180730819702, 236.2832372188568, 238.91540837287903, 241.54478931427002, 244.15342235565186, 246.77290630340576, 249.39795637130737, 252.04078316688538, 254.6743528842926, 257.31438660621643, 259.94207286834717, 262.58381605148315, 265.2210736274719, 267.85962772369385, 270.49908685684204, 273.4669134616852]
[26.2125, 32.5875, 37.5225, 40.85, 44.7425, 45.085, 46.8775, 49.5225, 49.545, 50.935, 51.76, 52.5925, 54.07, 55.325, 56.0275, 57.79, 57.2875, 58.8575, 59.43, 59.665, 60.095, 61.01, 60.7725, 61.555, 61.9125, 62.0425, 61.88, 62.3475, 62.815, 63.9075, 63.5125, 63.11, 64.0875, 64.2025, 64.865, 65.025, 65.66, 65.11, 65.02, 65.4925, 65.2675, 65.49, 65.42, 65.4675, 65.875, 65.925, 66.04, 66.47, 66.6575, 66.535, 66.2775, 66.47, 67.1425, 67.0175, 66.8375, 66.845, 66.8875, 67.1375, 66.9175, 67.63, 67.455, 67.3875, 66.7625, 66.925, 67.145, 67.335, 66.485, 67.345, 67.7825, 67.5125, 67.59, 67.935, 67.755, 67.37, 67.925, 68.0225, 68.3225, 68.1325, 67.855, 67.9925, 67.83, 68.4325, 68.39, 68.6625, 68.2725, 68.33, 68.865, 68.22, 68.695, 68.79, 68.8875, 69.28, 68.71, 68.58, 68.94, 68.825, 68.5125, 68.9275, 69.0875, 68.36, 69.5225]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 2.304, Test loss: 2.247, Test accuracy: 18.90
Round   1, Train loss: 2.193, Test loss: 2.068, Test accuracy: 25.72
Round   2, Train loss: 2.038, Test loss: 1.962, Test accuracy: 29.33
Round   3, Train loss: 1.958, Test loss: 1.875, Test accuracy: 31.92
Round   4, Train loss: 1.872, Test loss: 1.794, Test accuracy: 34.85
Round   5, Train loss: 1.784, Test loss: 1.736, Test accuracy: 36.92
Round   6, Train loss: 1.746, Test loss: 1.670, Test accuracy: 39.51
Round   7, Train loss: 1.686, Test loss: 1.632, Test accuracy: 40.80
Round   8, Train loss: 1.652, Test loss: 1.601, Test accuracy: 42.07
Round   9, Train loss: 1.632, Test loss: 1.553, Test accuracy: 43.90
Round  10, Train loss: 1.592, Test loss: 1.518, Test accuracy: 44.68
Round  11, Train loss: 1.553, Test loss: 1.488, Test accuracy: 45.92
Round  12, Train loss: 1.521, Test loss: 1.472, Test accuracy: 46.67
Round  13, Train loss: 1.493, Test loss: 1.453, Test accuracy: 47.45
Round  14, Train loss: 1.457, Test loss: 1.455, Test accuracy: 48.02
Round  15, Train loss: 1.465, Test loss: 1.426, Test accuracy: 48.77
Round  16, Train loss: 1.425, Test loss: 1.419, Test accuracy: 49.14
Round  17, Train loss: 1.410, Test loss: 1.394, Test accuracy: 49.99
Round  18, Train loss: 1.391, Test loss: 1.371, Test accuracy: 50.89
Round  19, Train loss: 1.403, Test loss: 1.357, Test accuracy: 51.98
Round  20, Train loss: 1.363, Test loss: 1.344, Test accuracy: 51.98
Round  21, Train loss: 1.326, Test loss: 1.331, Test accuracy: 52.19
Round  22, Train loss: 1.333, Test loss: 1.308, Test accuracy: 52.93
Round  23, Train loss: 1.302, Test loss: 1.310, Test accuracy: 52.91
Round  24, Train loss: 1.315, Test loss: 1.282, Test accuracy: 53.99
Round  25, Train loss: 1.242, Test loss: 1.265, Test accuracy: 54.53
Round  26, Train loss: 1.273, Test loss: 1.249, Test accuracy: 55.12
Round  27, Train loss: 1.238, Test loss: 1.248, Test accuracy: 55.31
Round  28, Train loss: 1.217, Test loss: 1.238, Test accuracy: 55.95
Round  29, Train loss: 1.206, Test loss: 1.229, Test accuracy: 56.38
Round  30, Train loss: 1.212, Test loss: 1.209, Test accuracy: 57.17
Round  31, Train loss: 1.170, Test loss: 1.198, Test accuracy: 57.31
Round  32, Train loss: 1.165, Test loss: 1.180, Test accuracy: 57.87
Round  33, Train loss: 1.190, Test loss: 1.167, Test accuracy: 58.48
Round  34, Train loss: 1.140, Test loss: 1.172, Test accuracy: 58.16
Round  35, Train loss: 1.149, Test loss: 1.169, Test accuracy: 58.61
Round  36, Train loss: 1.126, Test loss: 1.153, Test accuracy: 58.74
Round  37, Train loss: 1.099, Test loss: 1.143, Test accuracy: 59.20
Round  38, Train loss: 1.072, Test loss: 1.135, Test accuracy: 59.62
Round  39, Train loss: 1.070, Test loss: 1.125, Test accuracy: 59.88
Round  40, Train loss: 1.060, Test loss: 1.109, Test accuracy: 60.86
Round  41, Train loss: 1.073, Test loss: 1.121, Test accuracy: 60.25
Round  42, Train loss: 1.031, Test loss: 1.126, Test accuracy: 59.65
Round  43, Train loss: 1.080, Test loss: 1.111, Test accuracy: 60.48
Round  44, Train loss: 1.021, Test loss: 1.112, Test accuracy: 60.66
Round  45, Train loss: 1.005, Test loss: 1.096, Test accuracy: 61.27
Round  46, Train loss: 1.046, Test loss: 1.086, Test accuracy: 61.74
Round  47, Train loss: 1.003, Test loss: 1.079, Test accuracy: 62.37
Round  48, Train loss: 0.973, Test loss: 1.081, Test accuracy: 62.13
Round  49, Train loss: 0.994, Test loss: 1.066, Test accuracy: 62.44
Round  50, Train loss: 0.983, Test loss: 1.063, Test accuracy: 62.76
Round  51, Train loss: 0.924, Test loss: 1.063, Test accuracy: 62.81
Round  52, Train loss: 0.971, Test loss: 1.058, Test accuracy: 63.23
Round  53, Train loss: 0.955, Test loss: 1.057, Test accuracy: 62.80
Round  54, Train loss: 0.939, Test loss: 1.061, Test accuracy: 62.75
Round  55, Train loss: 0.906, Test loss: 1.069, Test accuracy: 61.91
Round  56, Train loss: 0.910, Test loss: 1.064, Test accuracy: 62.03
Round  57, Train loss: 0.928, Test loss: 1.046, Test accuracy: 63.16
Round  58, Train loss: 0.884, Test loss: 1.054, Test accuracy: 63.06
Round  59, Train loss: 0.909, Test loss: 1.041, Test accuracy: 63.44
Round  60, Train loss: 0.870, Test loss: 1.034, Test accuracy: 63.41
Round  61, Train loss: 0.845, Test loss: 1.032, Test accuracy: 63.29
Round  62, Train loss: 0.851, Test loss: 1.036, Test accuracy: 63.27
Round  63, Train loss: 0.873, Test loss: 1.038, Test accuracy: 63.18
Round  64, Train loss: 0.874, Test loss: 1.035, Test accuracy: 63.65
Round  65, Train loss: 0.837, Test loss: 1.039, Test accuracy: 63.55
Round  66, Train loss: 0.814, Test loss: 1.008, Test accuracy: 64.75
Round  67, Train loss: 0.833, Test loss: 1.013, Test accuracy: 64.89
Round  68, Train loss: 0.834, Test loss: 1.000, Test accuracy: 65.17
Round  69, Train loss: 0.808, Test loss: 0.998, Test accuracy: 65.44
Round  70, Train loss: 0.781, Test loss: 1.014, Test accuracy: 64.78
Round  71, Train loss: 0.819, Test loss: 1.005, Test accuracy: 64.86
Round  72, Train loss: 0.805, Test loss: 0.994, Test accuracy: 65.48
Round  73, Train loss: 0.786, Test loss: 0.999, Test accuracy: 65.58
Round  74, Train loss: 0.806, Test loss: 0.995, Test accuracy: 65.78
Round  75, Train loss: 0.769, Test loss: 0.987, Test accuracy: 65.72
Round  76, Train loss: 0.797, Test loss: 0.984, Test accuracy: 66.02
Round  77, Train loss: 0.768, Test loss: 0.979, Test accuracy: 66.11
Round  78, Train loss: 0.755, Test loss: 0.990, Test accuracy: 65.83
Round  79, Train loss: 0.767, Test loss: 0.975, Test accuracy: 66.25
Round  80, Train loss: 0.742, Test loss: 0.976, Test accuracy: 65.95
Round  81, Train loss: 0.769, Test loss: 0.981, Test accuracy: 66.21
Round  82, Train loss: 0.717, Test loss: 0.971, Test accuracy: 66.72
Round  83, Train loss: 0.725, Test loss: 0.971, Test accuracy: 66.46
Round  84, Train loss: 0.716, Test loss: 0.969, Test accuracy: 66.65
Round  85, Train loss: 0.720, Test loss: 0.969, Test accuracy: 66.78
Round  86, Train loss: 0.679, Test loss: 0.978, Test accuracy: 66.63
Round  87, Train loss: 0.698, Test loss: 0.980, Test accuracy: 66.67
Round  88, Train loss: 0.723, Test loss: 0.986, Test accuracy: 66.44
Round  89, Train loss: 0.687, Test loss: 0.983, Test accuracy: 66.31
Round  90, Train loss: 0.667, Test loss: 0.985, Test accuracy: 66.47
Round  91, Train loss: 0.686, Test loss: 0.974, Test accuracy: 66.64
Round  92, Train loss: 0.684, Test loss: 0.985, Test accuracy: 66.12
Round  93, Train loss: 0.676, Test loss: 0.969, Test accuracy: 67.17
Round  94, Train loss: 0.700, Test loss: 0.958, Test accuracy: 67.28
Round  95, Train loss: 0.640, Test loss: 0.963, Test accuracy: 67.19
Round  96, Train loss: 0.647, Test loss: 0.977, Test accuracy: 66.70
Round  97, Train loss: 0.688, Test loss: 0.965, Test accuracy: 67.03
Round  98, Train loss: 0.635, Test loss: 0.972, Test accuracy: 67.14
Round  99, Train loss: 0.654, Test loss: 0.967, Test accuracy: 67.03
Final Round, Train loss: 0.557, Test loss: 0.964, Test accuracy: 67.29
Average accuracy final 10 rounds: 66.87875
1787.9132134914398
[1.6487712860107422, 2.9931936264038086, 4.352847576141357, 5.681507349014282, 7.004239559173584, 8.337772846221924, 9.656641960144043, 10.949867725372314, 12.293158531188965, 13.641947031021118, 14.952504396438599, 16.314541816711426, 17.646867752075195, 18.96052646636963, 20.305304527282715, 21.624603986740112, 22.92322087287903, 24.249229192733765, 25.574799060821533, 26.875356674194336, 28.206486225128174, 29.556062936782837, 30.883919715881348, 32.210134983062744, 33.53318643569946, 34.85143041610718, 36.20713663101196, 37.55802369117737, 38.88243341445923, 40.23321747779846, 41.5705041885376, 42.875213861465454, 44.21522903442383, 45.57059836387634, 46.871559858322144, 48.1946485042572, 49.53984594345093, 50.8627655506134, 52.213727951049805, 53.56584167480469, 54.893717527389526, 56.243042945861816, 57.603447675704956, 58.9409601688385, 60.292325496673584, 61.647855281829834, 62.96824312210083, 64.29674100875854, 65.63834547996521, 66.97518134117126, 68.31615352630615, 69.66333174705505, 71.02466917037964, 72.36432194709778, 73.69875812530518, 75.03395104408264, 76.37981724739075, 77.72036457061768, 79.06035327911377, 80.40453624725342, 81.7296953201294, 83.06903409957886, 84.40116167068481, 85.70294737815857, 86.92602252960205, 88.15572428703308, 89.46191883087158, 90.79407835006714, 92.12492537498474, 93.4205846786499, 94.75116395950317, 96.07460689544678, 97.3797960281372, 98.58751320838928, 99.78058099746704, 100.97178339958191, 102.1799008846283, 103.3711428642273, 104.56792187690735, 105.77842330932617, 106.97197484970093, 108.1678192615509, 109.37505674362183, 110.56742310523987, 111.76087307929993, 112.96550512313843, 114.15499758720398, 115.35108423233032, 116.55656051635742, 117.74582052230835, 118.94256353378296, 120.1340684890747, 121.32332563400269, 122.53498864173889, 123.73027658462524, 124.9255063533783, 126.12433052062988, 127.3152494430542, 128.51235818862915, 129.71503710746765, 131.6641001701355]
[18.9, 25.7225, 29.33, 31.9225, 34.8475, 36.9225, 39.51, 40.7975, 42.0675, 43.9, 44.6775, 45.92, 46.6725, 47.4475, 48.0175, 48.7725, 49.1375, 49.99, 50.8875, 51.98, 51.975, 52.1925, 52.9325, 52.915, 53.995, 54.5325, 55.12, 55.3125, 55.9525, 56.385, 57.1725, 57.31, 57.8675, 58.475, 58.1625, 58.61, 58.74, 59.1975, 59.62, 59.88, 60.86, 60.25, 59.6525, 60.48, 60.6625, 61.27, 61.745, 62.3725, 62.1325, 62.4375, 62.7625, 62.815, 63.2325, 62.795, 62.7475, 61.915, 62.0325, 63.165, 63.0575, 63.435, 63.415, 63.2925, 63.2675, 63.1775, 63.6475, 63.55, 64.75, 64.8925, 65.175, 65.445, 64.775, 64.8575, 65.48, 65.5775, 65.78, 65.7225, 66.0225, 66.115, 65.825, 66.2525, 65.9525, 66.2125, 66.715, 66.4575, 66.6525, 66.7775, 66.6325, 66.67, 66.435, 66.3125, 66.475, 66.6375, 66.12, 67.1725, 67.2825, 67.1925, 66.705, 67.0325, 67.145, 67.025, 67.29]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
4800
4864
107264
107328
299328
299448
307128
307192
307832
307842
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 2.303, Test loss: 2.216, Test accuracy: 20.67
Round   1, Train loss: 2.158, Test loss: 2.023, Test accuracy: 27.61
Round   2, Train loss: 2.023, Test loss: 1.934, Test accuracy: 30.50
Round   3, Train loss: 1.934, Test loss: 1.825, Test accuracy: 34.42
Round   4, Train loss: 1.844, Test loss: 1.757, Test accuracy: 36.93
Round   5, Train loss: 1.775, Test loss: 1.713, Test accuracy: 38.43
Round   6, Train loss: 1.722, Test loss: 1.652, Test accuracy: 40.42
Round   7, Train loss: 1.687, Test loss: 1.628, Test accuracy: 40.94
Round   8, Train loss: 1.679, Test loss: 1.580, Test accuracy: 43.20
Round   9, Train loss: 1.624, Test loss: 1.578, Test accuracy: 42.69
Round  10, Train loss: 1.628, Test loss: 1.524, Test accuracy: 44.66
Round  11, Train loss: 1.588, Test loss: 1.495, Test accuracy: 45.52
Round  12, Train loss: 1.541, Test loss: 1.466, Test accuracy: 47.01
Round  13, Train loss: 1.503, Test loss: 1.448, Test accuracy: 47.82
Round  14, Train loss: 1.483, Test loss: 1.430, Test accuracy: 48.55
Round  15, Train loss: 1.496, Test loss: 1.408, Test accuracy: 48.82
Round  16, Train loss: 1.457, Test loss: 1.398, Test accuracy: 49.99
Round  17, Train loss: 1.431, Test loss: 1.367, Test accuracy: 50.53
Round  18, Train loss: 1.413, Test loss: 1.354, Test accuracy: 51.73
Round  19, Train loss: 1.397, Test loss: 1.351, Test accuracy: 52.09
Round  20, Train loss: 1.394, Test loss: 1.320, Test accuracy: 53.24
Round  21, Train loss: 1.347, Test loss: 1.300, Test accuracy: 54.14
Round  22, Train loss: 1.329, Test loss: 1.280, Test accuracy: 54.72
Round  23, Train loss: 1.287, Test loss: 1.268, Test accuracy: 55.14
Round  24, Train loss: 1.280, Test loss: 1.255, Test accuracy: 55.77
Round  25, Train loss: 1.260, Test loss: 1.257, Test accuracy: 55.33
Round  26, Train loss: 1.256, Test loss: 1.241, Test accuracy: 56.14
Round  27, Train loss: 1.263, Test loss: 1.227, Test accuracy: 56.44
Round  28, Train loss: 1.259, Test loss: 1.217, Test accuracy: 56.74
Round  29, Train loss: 1.213, Test loss: 1.204, Test accuracy: 57.15
Round  30, Train loss: 1.173, Test loss: 1.211, Test accuracy: 57.52
Round  31, Train loss: 1.160, Test loss: 1.182, Test accuracy: 58.47
Round  32, Train loss: 1.170, Test loss: 1.173, Test accuracy: 59.00
Round  33, Train loss: 1.154, Test loss: 1.169, Test accuracy: 58.65
Round  34, Train loss: 1.164, Test loss: 1.142, Test accuracy: 59.83
Round  35, Train loss: 1.120, Test loss: 1.147, Test accuracy: 59.20
Round  36, Train loss: 1.120, Test loss: 1.132, Test accuracy: 60.12
Round  37, Train loss: 1.096, Test loss: 1.142, Test accuracy: 59.64
Round  38, Train loss: 1.116, Test loss: 1.117, Test accuracy: 60.49
Round  39, Train loss: 1.063, Test loss: 1.118, Test accuracy: 60.72
Round  40, Train loss: 1.079, Test loss: 1.098, Test accuracy: 61.37
Round  41, Train loss: 1.068, Test loss: 1.105, Test accuracy: 61.26
Round  42, Train loss: 1.081, Test loss: 1.100, Test accuracy: 61.38
Round  43, Train loss: 1.047, Test loss: 1.104, Test accuracy: 61.45
Round  44, Train loss: 1.041, Test loss: 1.091, Test accuracy: 61.17
Round  45, Train loss: 1.031, Test loss: 1.086, Test accuracy: 61.91
Round  46, Train loss: 1.009, Test loss: 1.093, Test accuracy: 61.79
Round  47, Train loss: 0.998, Test loss: 1.093, Test accuracy: 61.95
Round  48, Train loss: 0.959, Test loss: 1.087, Test accuracy: 62.10
Round  49, Train loss: 0.972, Test loss: 1.047, Test accuracy: 63.72
Round  50, Train loss: 0.944, Test loss: 1.046, Test accuracy: 63.60
Round  51, Train loss: 0.943, Test loss: 1.039, Test accuracy: 64.18
Round  52, Train loss: 0.946, Test loss: 1.041, Test accuracy: 63.79
Round  53, Train loss: 0.910, Test loss: 1.030, Test accuracy: 64.10
Round  54, Train loss: 0.914, Test loss: 1.029, Test accuracy: 64.32
Round  55, Train loss: 0.893, Test loss: 1.027, Test accuracy: 64.49
Round  56, Train loss: 0.896, Test loss: 1.024, Test accuracy: 64.63
Round  57, Train loss: 0.871, Test loss: 1.020, Test accuracy: 64.64
Round  58, Train loss: 0.900, Test loss: 1.029, Test accuracy: 64.50
Round  59, Train loss: 0.915, Test loss: 1.014, Test accuracy: 64.94
Round  60, Train loss: 0.906, Test loss: 1.010, Test accuracy: 64.99
Round  61, Train loss: 0.877, Test loss: 1.016, Test accuracy: 64.91
Round  62, Train loss: 0.846, Test loss: 1.015, Test accuracy: 65.04
Round  63, Train loss: 0.832, Test loss: 1.007, Test accuracy: 65.23
Round  64, Train loss: 0.833, Test loss: 1.002, Test accuracy: 65.44
Round  65, Train loss: 0.818, Test loss: 1.006, Test accuracy: 65.17
Round  66, Train loss: 0.830, Test loss: 1.003, Test accuracy: 65.56
Round  67, Train loss: 0.840, Test loss: 1.001, Test accuracy: 65.37
Round  68, Train loss: 0.849, Test loss: 1.003, Test accuracy: 65.20
Round  69, Train loss: 0.795, Test loss: 1.000, Test accuracy: 65.72
Round  70, Train loss: 0.780, Test loss: 0.989, Test accuracy: 66.05
Round  71, Train loss: 0.834, Test loss: 0.995, Test accuracy: 65.52
Round  72, Train loss: 0.756, Test loss: 1.000, Test accuracy: 65.76
Round  73, Train loss: 0.757, Test loss: 0.997, Test accuracy: 65.52
Round  74, Train loss: 0.773, Test loss: 0.993, Test accuracy: 65.75
Round  75, Train loss: 0.762, Test loss: 1.002, Test accuracy: 65.49
Round  76, Train loss: 0.782, Test loss: 0.993, Test accuracy: 65.98
Round  77, Train loss: 0.800, Test loss: 0.982, Test accuracy: 66.28
Round  78, Train loss: 0.757, Test loss: 0.979, Test accuracy: 66.61
Round  79, Train loss: 0.742, Test loss: 0.996, Test accuracy: 65.96
Round  80, Train loss: 0.713, Test loss: 0.999, Test accuracy: 65.91
Round  81, Train loss: 0.734, Test loss: 0.995, Test accuracy: 65.83
Round  82, Train loss: 0.733, Test loss: 0.987, Test accuracy: 66.03
Round  83, Train loss: 0.694, Test loss: 0.990, Test accuracy: 66.23
Round  84, Train loss: 0.677, Test loss: 1.000, Test accuracy: 65.78
Round  85, Train loss: 0.685, Test loss: 0.994, Test accuracy: 66.00
Round  86, Train loss: 0.685, Test loss: 0.983, Test accuracy: 66.28
Round  87, Train loss: 0.669, Test loss: 0.972, Test accuracy: 66.78
Round  88, Train loss: 0.659, Test loss: 0.987, Test accuracy: 66.28
Round  89, Train loss: 0.678, Test loss: 0.976, Test accuracy: 66.53
Round  90, Train loss: 0.701, Test loss: 0.965, Test accuracy: 67.08
Round  91, Train loss: 0.669, Test loss: 0.968, Test accuracy: 67.11
Round  92, Train loss: 0.725, Test loss: 0.977, Test accuracy: 66.77
Round  93, Train loss: 0.666, Test loss: 0.962, Test accuracy: 66.97
Round  94, Train loss: 0.628, Test loss: 0.958, Test accuracy: 67.37
Round  95, Train loss: 0.681, Test loss: 0.970, Test accuracy: 67.08
Round  96, Train loss: 0.659, Test loss: 0.958, Test accuracy: 67.81
Round  97, Train loss: 0.645, Test loss: 0.962, Test accuracy: 67.58
Round  98, Train loss: 0.636, Test loss: 0.957, Test accuracy: 67.46
Round  99, Train loss: 0.588, Test loss: 0.962, Test accuracy: 67.22
Final Round, Train loss: 0.564, Test loss: 0.963, Test accuracy: 67.47
Average accuracy final 10 rounds: 67.245
1787.5808215141296
[1.7045114040374756, 3.0415074825286865, 4.397817373275757, 5.7288007736206055, 7.039016246795654, 8.396040439605713, 9.760920524597168, 11.071078538894653, 12.421535015106201, 13.750141143798828, 15.05875849723816, 16.409377574920654, 17.738054513931274, 19.074547290802002, 20.429669857025146, 21.771230220794678, 23.11348247528076, 24.463698148727417, 25.820094347000122, 27.176501035690308, 28.53590178489685, 29.889007568359375, 31.246040105819702, 32.60482454299927, 33.966991901397705, 35.31806778907776, 36.68272805213928, 38.04035520553589, 39.38191032409668, 40.74312400817871, 42.096261739730835, 43.43114519119263, 44.79427218437195, 46.15520358085632, 47.500895738601685, 48.85998773574829, 50.21801710128784, 51.4126091003418, 52.61147451400757, 53.81813073158264, 55.01661419868469, 56.21754336357117, 57.426552295684814, 58.623146057128906, 59.821346044540405, 61.01857805252075, 62.21694231033325, 63.41817545890808, 64.61811828613281, 65.81904125213623, 67.0335328578949, 68.23303389549255, 69.44347357749939, 70.65883898735046, 71.85581588745117, 73.0666024684906, 74.27500009536743, 75.47600150108337, 76.69155311584473, 77.89349842071533, 79.09521460533142, 80.30345726013184, 81.5046980381012, 82.70581483840942, 83.92082023620605, 85.11958146095276, 86.33503651618958, 87.54934740066528, 88.748370885849, 89.965651512146, 91.18344950675964, 92.38312578201294, 93.59428930282593, 94.79888105392456, 96.0009834766388, 97.2142424583435, 98.41900038719177, 99.62119770050049, 100.85800313949585, 102.0621235370636, 103.26216959953308, 104.46286916732788, 105.66848921775818, 106.88472199440002, 108.0910906791687, 109.29487895965576, 110.50584650039673, 111.70528435707092, 112.90531802177429, 114.12299036979675, 115.32083010673523, 116.52434206008911, 117.73059701919556, 118.92855262756348, 120.13356184959412, 121.34280514717102, 122.54140448570251, 123.7418282032013, 124.95524787902832, 126.16196203231812, 128.1443738937378]
[20.67, 27.6125, 30.4975, 34.4175, 36.93, 38.4275, 40.4175, 40.94, 43.195, 42.685, 44.665, 45.525, 47.01, 47.8225, 48.55, 48.8225, 49.99, 50.5275, 51.725, 52.095, 53.2425, 54.1375, 54.7225, 55.14, 55.7725, 55.325, 56.1375, 56.4425, 56.74, 57.145, 57.5175, 58.465, 59.0, 58.6475, 59.8325, 59.1975, 60.1225, 59.6425, 60.4875, 60.715, 61.37, 61.2575, 61.385, 61.4475, 61.175, 61.9075, 61.7925, 61.9475, 62.0975, 63.7225, 63.6025, 64.1825, 63.7875, 64.0975, 64.32, 64.4925, 64.6325, 64.6425, 64.5, 64.9425, 64.99, 64.9125, 65.04, 65.2275, 65.445, 65.1725, 65.5625, 65.37, 65.2025, 65.72, 66.0475, 65.52, 65.7575, 65.52, 65.7475, 65.49, 65.985, 66.285, 66.605, 65.9625, 65.905, 65.835, 66.0325, 66.2325, 65.7825, 66.0, 66.28, 66.785, 66.285, 66.5275, 67.085, 67.105, 66.765, 66.97, 67.37, 67.075, 67.815, 67.5825, 67.46, 67.2225, 67.47]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 1, is_concept_shift: 1, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.965, Test loss: 1.055, Test accuracy: 39.90 

Round   0, Global train loss: 0.965, Global test loss: 1.121, Global test accuracy: 34.55 

Round   1, Train loss: 0.762, Test loss: 0.969, Test accuracy: 51.12 

Round   1, Global train loss: 0.762, Global test loss: 1.191, Global test accuracy: 37.68 

Round   2, Train loss: 0.661, Test loss: 0.843, Test accuracy: 57.25 

Round   2, Global train loss: 0.661, Global test loss: 1.120, Global test accuracy: 38.59 

Round   3, Train loss: 0.687, Test loss: 0.822, Test accuracy: 58.29 

Round   3, Global train loss: 0.687, Global test loss: 1.160, Global test accuracy: 33.71 

Round   4, Train loss: 0.704, Test loss: 0.806, Test accuracy: 61.25 

Round   4, Global train loss: 0.704, Global test loss: 1.233, Global test accuracy: 34.51 

Round   5, Train loss: 0.623, Test loss: 0.722, Test accuracy: 65.13 

Round   5, Global train loss: 0.623, Global test loss: 1.147, Global test accuracy: 35.77 

Round   6, Train loss: 0.559, Test loss: 0.670, Test accuracy: 69.73 

Round   6, Global train loss: 0.559, Global test loss: 1.120, Global test accuracy: 38.48 

Round   7, Train loss: 0.566, Test loss: 0.648, Test accuracy: 71.42 

Round   7, Global train loss: 0.566, Global test loss: 1.160, Global test accuracy: 35.42 

Round   8, Train loss: 0.574, Test loss: 0.627, Test accuracy: 72.29 

Round   8, Global train loss: 0.574, Global test loss: 1.247, Global test accuracy: 36.02 

Round   9, Train loss: 0.488, Test loss: 0.619, Test accuracy: 73.18 

Round   9, Global train loss: 0.488, Global test loss: 1.329, Global test accuracy: 38.83 

Round  10, Train loss: 0.472, Test loss: 0.631, Test accuracy: 72.61 

Round  10, Global train loss: 0.472, Global test loss: 1.224, Global test accuracy: 37.75 

Round  11, Train loss: 0.461, Test loss: 0.619, Test accuracy: 72.19 

Round  11, Global train loss: 0.461, Global test loss: 1.133, Global test accuracy: 35.25 

Round  12, Train loss: 0.440, Test loss: 0.613, Test accuracy: 73.30 

Round  12, Global train loss: 0.440, Global test loss: 1.244, Global test accuracy: 39.15 

Round  13, Train loss: 0.335, Test loss: 0.591, Test accuracy: 74.03 

Round  13, Global train loss: 0.335, Global test loss: 1.148, Global test accuracy: 35.79 

Round  14, Train loss: 0.407, Test loss: 0.587, Test accuracy: 74.18 

Round  14, Global train loss: 0.407, Global test loss: 1.424, Global test accuracy: 31.38 

Round  15, Train loss: 0.375, Test loss: 0.594, Test accuracy: 74.58 

Round  15, Global train loss: 0.375, Global test loss: 1.271, Global test accuracy: 37.86 

Round  16, Train loss: 0.501, Test loss: 0.599, Test accuracy: 73.92 

Round  16, Global train loss: 0.501, Global test loss: 1.239, Global test accuracy: 37.50 

Round  17, Train loss: 0.439, Test loss: 0.571, Test accuracy: 75.97 

Round  17, Global train loss: 0.439, Global test loss: 1.154, Global test accuracy: 35.62 

Round  18, Train loss: 0.360, Test loss: 0.592, Test accuracy: 74.56 

Round  18, Global train loss: 0.360, Global test loss: 1.164, Global test accuracy: 34.46 

Round  19, Train loss: 0.341, Test loss: 0.626, Test accuracy: 74.94 

Round  19, Global train loss: 0.341, Global test loss: 1.387, Global test accuracy: 39.19 

Round  20, Train loss: 0.360, Test loss: 0.605, Test accuracy: 74.37 

Round  20, Global train loss: 0.360, Global test loss: 1.233, Global test accuracy: 34.83 

Round  21, Train loss: 0.401, Test loss: 0.578, Test accuracy: 76.30 

Round  21, Global train loss: 0.401, Global test loss: 1.216, Global test accuracy: 39.12 

Round  22, Train loss: 0.409, Test loss: 0.542, Test accuracy: 78.25 

Round  22, Global train loss: 0.409, Global test loss: 1.180, Global test accuracy: 34.74 

Round  23, Train loss: 0.326, Test loss: 0.545, Test accuracy: 78.09 

Round  23, Global train loss: 0.326, Global test loss: 1.289, Global test accuracy: 35.52 

Round  24, Train loss: 0.294, Test loss: 0.547, Test accuracy: 78.38 

Round  24, Global train loss: 0.294, Global test loss: 1.310, Global test accuracy: 37.58 

Round  25, Train loss: 0.343, Test loss: 0.545, Test accuracy: 78.62 

Round  25, Global train loss: 0.343, Global test loss: 1.159, Global test accuracy: 38.30 

Round  26, Train loss: 0.298, Test loss: 0.556, Test accuracy: 79.12 

Round  26, Global train loss: 0.298, Global test loss: 1.220, Global test accuracy: 32.45 

Round  27, Train loss: 0.432, Test loss: 0.555, Test accuracy: 79.03 

Round  27, Global train loss: 0.432, Global test loss: 1.159, Global test accuracy: 33.82 

Round  28, Train loss: 0.429, Test loss: 0.559, Test accuracy: 79.46 

Round  28, Global train loss: 0.429, Global test loss: 1.204, Global test accuracy: 34.77 

Round  29, Train loss: 0.279, Test loss: 0.552, Test accuracy: 79.88 

Round  29, Global train loss: 0.279, Global test loss: 1.220, Global test accuracy: 35.42 

Round  30, Train loss: 0.320, Test loss: 0.561, Test accuracy: 79.72 

Round  30, Global train loss: 0.320, Global test loss: 1.308, Global test accuracy: 30.61 

Round  31, Train loss: 0.346, Test loss: 0.558, Test accuracy: 79.62 

Round  31, Global train loss: 0.346, Global test loss: 1.426, Global test accuracy: 38.34 

Round  32, Train loss: 0.251, Test loss: 0.556, Test accuracy: 79.92 

Round  32, Global train loss: 0.251, Global test loss: 1.352, Global test accuracy: 38.59 

Round  33, Train loss: 0.227, Test loss: 0.588, Test accuracy: 79.62 

Round  33, Global train loss: 0.227, Global test loss: 1.261, Global test accuracy: 35.35 

Round  34, Train loss: 0.231, Test loss: 0.614, Test accuracy: 79.32 

Round  34, Global train loss: 0.231, Global test loss: 1.449, Global test accuracy: 38.51 

Round  35, Train loss: 0.227, Test loss: 0.623, Test accuracy: 79.28 

Round  35, Global train loss: 0.227, Global test loss: 1.298, Global test accuracy: 33.23 

Round  36, Train loss: 0.219, Test loss: 0.622, Test accuracy: 79.42 

Round  36, Global train loss: 0.219, Global test loss: 1.354, Global test accuracy: 35.96 

Round  37, Train loss: 0.271, Test loss: 0.613, Test accuracy: 79.85 

Round  37, Global train loss: 0.271, Global test loss: 1.228, Global test accuracy: 39.27 

Round  38, Train loss: 0.148, Test loss: 0.611, Test accuracy: 79.85 

Round  38, Global train loss: 0.148, Global test loss: 1.307, Global test accuracy: 38.98 

Round  39, Train loss: 0.188, Test loss: 0.610, Test accuracy: 79.96 

Round  39, Global train loss: 0.188, Global test loss: 1.171, Global test accuracy: 38.60 

Round  40, Train loss: 0.239, Test loss: 0.596, Test accuracy: 80.33 

Round  40, Global train loss: 0.239, Global test loss: 1.476, Global test accuracy: 32.97 

Round  41, Train loss: 0.182, Test loss: 0.615, Test accuracy: 80.72 

Round  41, Global train loss: 0.182, Global test loss: 1.207, Global test accuracy: 36.90 

Round  42, Train loss: 0.210, Test loss: 0.618, Test accuracy: 80.71 

Round  42, Global train loss: 0.210, Global test loss: 1.578, Global test accuracy: 37.70 

Round  43, Train loss: 0.153, Test loss: 0.644, Test accuracy: 80.03 

Round  43, Global train loss: 0.153, Global test loss: 1.417, Global test accuracy: 38.28 

Round  44, Train loss: 0.190, Test loss: 0.660, Test accuracy: 80.12 

Round  44, Global train loss: 0.190, Global test loss: 1.328, Global test accuracy: 32.98 

Round  45, Train loss: 0.201, Test loss: 0.662, Test accuracy: 79.96 

Round  45, Global train loss: 0.201, Global test loss: 1.276, Global test accuracy: 38.32 

Round  46, Train loss: 0.228, Test loss: 0.671, Test accuracy: 80.25 

Round  46, Global train loss: 0.228, Global test loss: 1.213, Global test accuracy: 33.64 

Round  47, Train loss: 0.177, Test loss: 0.674, Test accuracy: 80.26 

Round  47, Global train loss: 0.177, Global test loss: 1.285, Global test accuracy: 34.65 

Round  48, Train loss: 0.197, Test loss: 0.690, Test accuracy: 80.06 

Round  48, Global train loss: 0.197, Global test loss: 1.302, Global test accuracy: 37.59 

Round  49, Train loss: 0.146, Test loss: 0.686, Test accuracy: 80.24 

Round  49, Global train loss: 0.146, Global test loss: 1.175, Global test accuracy: 39.59 

Round  50, Train loss: 0.170, Test loss: 0.691, Test accuracy: 80.06 

Round  50, Global train loss: 0.170, Global test loss: 1.286, Global test accuracy: 37.23 

Round  51, Train loss: 0.195, Test loss: 0.717, Test accuracy: 79.62 

Round  51, Global train loss: 0.195, Global test loss: 1.405, Global test accuracy: 36.98 

Round  52, Train loss: 0.184, Test loss: 0.700, Test accuracy: 79.86 

Round  52, Global train loss: 0.184, Global test loss: 1.310, Global test accuracy: 38.17 

Round  53, Train loss: 0.094, Test loss: 0.720, Test accuracy: 79.94 

Round  53, Global train loss: 0.094, Global test loss: 1.347, Global test accuracy: 32.33 

Round  54, Train loss: 0.110, Test loss: 0.734, Test accuracy: 79.90 

Round  54, Global train loss: 0.110, Global test loss: 1.704, Global test accuracy: 38.23 

Round  55, Train loss: 0.126, Test loss: 0.761, Test accuracy: 80.00 

Round  55, Global train loss: 0.126, Global test loss: 1.453, Global test accuracy: 38.67 

Round  56, Train loss: 0.153, Test loss: 0.765, Test accuracy: 80.19 

Round  56, Global train loss: 0.153, Global test loss: 1.322, Global test accuracy: 34.70 

Round  57, Train loss: 0.192, Test loss: 0.773, Test accuracy: 80.04 

Round  57, Global train loss: 0.192, Global test loss: 1.232, Global test accuracy: 36.15 

Round  58, Train loss: 0.123, Test loss: 0.762, Test accuracy: 80.49 

Round  58, Global train loss: 0.123, Global test loss: 1.421, Global test accuracy: 31.67 

Round  59, Train loss: 0.142, Test loss: 0.779, Test accuracy: 80.07 

Round  59, Global train loss: 0.142, Global test loss: 1.486, Global test accuracy: 38.44 

Round  60, Train loss: 0.095, Test loss: 0.734, Test accuracy: 80.40 

Round  60, Global train loss: 0.095, Global test loss: 1.938, Global test accuracy: 37.91 

Round  61, Train loss: 0.155, Test loss: 0.743, Test accuracy: 80.44 

Round  61, Global train loss: 0.155, Global test loss: 1.214, Global test accuracy: 39.23 

Round  62, Train loss: 0.089, Test loss: 0.772, Test accuracy: 80.06 

Round  62, Global train loss: 0.089, Global test loss: 1.578, Global test accuracy: 33.31 

Round  63, Train loss: 0.100, Test loss: 0.776, Test accuracy: 80.49 

Round  63, Global train loss: 0.100, Global test loss: 1.380, Global test accuracy: 33.98 

Round  64, Train loss: 0.139, Test loss: 0.795, Test accuracy: 80.32 

Round  64, Global train loss: 0.139, Global test loss: 1.305, Global test accuracy: 37.40 

Round  65, Train loss: 0.119, Test loss: 0.749, Test accuracy: 80.91 

Round  65, Global train loss: 0.119, Global test loss: 1.468, Global test accuracy: 34.31 

Round  66, Train loss: 0.098, Test loss: 0.767, Test accuracy: 80.65 

Round  66, Global train loss: 0.098, Global test loss: 1.723, Global test accuracy: 39.08 

Round  67, Train loss: 0.113, Test loss: 0.757, Test accuracy: 81.24 

Round  67, Global train loss: 0.113, Global test loss: 1.447, Global test accuracy: 37.57 

Round  68, Train loss: 0.072, Test loss: 0.784, Test accuracy: 81.07 

Round  68, Global train loss: 0.072, Global test loss: 1.220, Global test accuracy: 37.51 

Round  69, Train loss: 0.120, Test loss: 0.811, Test accuracy: 81.17 

Round  69, Global train loss: 0.120, Global test loss: 1.348, Global test accuracy: 33.27 

Round  70, Train loss: 0.083, Test loss: 0.812, Test accuracy: 81.22 

Round  70, Global train loss: 0.083, Global test loss: 1.645, Global test accuracy: 39.48 

Round  71, Train loss: 0.089, Test loss: 0.821, Test accuracy: 80.85 

Round  71, Global train loss: 0.089, Global test loss: 1.300, Global test accuracy: 38.20 

Round  72, Train loss: 0.100, Test loss: 0.801, Test accuracy: 80.58 

Round  72, Global train loss: 0.100, Global test loss: 1.340, Global test accuracy: 33.28 

Round  73, Train loss: 0.063, Test loss: 0.795, Test accuracy: 80.61 

Round  73, Global train loss: 0.063, Global test loss: 1.264, Global test accuracy: 37.56 

Round  74, Train loss: 0.105, Test loss: 0.806, Test accuracy: 80.63 

Round  74, Global train loss: 0.105, Global test loss: 1.200, Global test accuracy: 37.11 

Round  75, Train loss: 0.110, Test loss: 0.835, Test accuracy: 80.56 

Round  75, Global train loss: 0.110, Global test loss: 1.190, Global test accuracy: 37.67 

Round  76, Train loss: 0.118, Test loss: 0.817, Test accuracy: 80.89 

Round  76, Global train loss: 0.118, Global test loss: 1.903, Global test accuracy: 39.49 

Round  77, Train loss: 0.040, Test loss: 0.832, Test accuracy: 80.92 

Round  77, Global train loss: 0.040, Global test loss: 1.367, Global test accuracy: 39.21 

Round  78, Train loss: 0.076, Test loss: 0.841, Test accuracy: 80.89 

Round  78, Global train loss: 0.076, Global test loss: 1.351, Global test accuracy: 37.54 

Round  79, Train loss: 0.073, Test loss: 0.856, Test accuracy: 80.71 

Round  79, Global train loss: 0.073, Global test loss: 1.253, Global test accuracy: 35.70 

Round  80, Train loss: 0.060, Test loss: 0.856, Test accuracy: 80.82 

Round  80, Global train loss: 0.060, Global test loss: 1.575, Global test accuracy: 39.18 

Round  81, Train loss: 0.069, Test loss: 0.856, Test accuracy: 80.92 

Round  81, Global train loss: 0.069, Global test loss: 1.501, Global test accuracy: 37.86 

Round  82, Train loss: 0.086, Test loss: 0.876, Test accuracy: 80.66 

Round  82, Global train loss: 0.086, Global test loss: 1.282, Global test accuracy: 38.21 

Round  83, Train loss: 0.082, Test loss: 0.866, Test accuracy: 80.73 

Round  83, Global train loss: 0.082, Global test loss: 1.648, Global test accuracy: 38.12 

Round  84, Train loss: 0.044, Test loss: 0.886, Test accuracy: 80.95 

Round  84, Global train loss: 0.044, Global test loss: 1.453, Global test accuracy: 34.39 

Round  85, Train loss: 0.068, Test loss: 0.884, Test accuracy: 81.03 

Round  85, Global train loss: 0.068, Global test loss: 1.494, Global test accuracy: 38.69 

Round  86, Train loss: 0.056, Test loss: 0.903, Test accuracy: 80.78 

Round  86, Global train loss: 0.056, Global test loss: 1.929, Global test accuracy: 38.93 

Round  87, Train loss: 0.075, Test loss: 0.899, Test accuracy: 80.85 

Round  87, Global train loss: 0.075, Global test loss: 1.275, Global test accuracy: 35.97 

Round  88, Train loss: 0.080, Test loss: 0.893, Test accuracy: 80.71 

Round  88, Global train loss: 0.080, Global test loss: 1.407, Global test accuracy: 37.52 

Round  89, Train loss: 0.056, Test loss: 0.910, Test accuracy: 80.77 

Round  89, Global train loss: 0.056, Global test loss: 1.676, Global test accuracy: 35.31 

Round  90, Train loss: 0.060, Test loss: 0.891, Test accuracy: 81.17 

Round  90, Global train loss: 0.060, Global test loss: 1.298, Global test accuracy: 36.45 

Round  91, Train loss: 0.042, Test loss: 0.940, Test accuracy: 80.74 

Round  91, Global train loss: 0.042, Global test loss: 1.303, Global test accuracy: 37.32 

Round  92, Train loss: 0.053, Test loss: 0.939, Test accuracy: 80.49 

Round  92, Global train loss: 0.053, Global test loss: 1.250, Global test accuracy: 37.53 

Round  93, Train loss: 0.060, Test loss: 0.919, Test accuracy: 80.79 

Round  93, Global train loss: 0.060, Global test loss: 1.651, Global test accuracy: 32.43 

Round  94, Train loss: 0.045, Test loss: 0.941, Test accuracy: 80.85 

Round  94, Global train loss: 0.045, Global test loss: 1.294, Global test accuracy: 37.87 

Round  95, Train loss: 0.079, Test loss: 0.944, Test accuracy: 80.67 

Round  95, Global train loss: 0.079, Global test loss: 1.240, Global test accuracy: 38.52 

Round  96, Train loss: 0.083, Test loss: 0.970, Test accuracy: 80.33 

Round  96, Global train loss: 0.083, Global test loss: 1.399, Global test accuracy: 39.56 

Round  97, Train loss: 0.058, Test loss: 0.992, Test accuracy: 80.29 

Round  97, Global train loss: 0.058, Global test loss: 1.638, Global test accuracy: 34.48 

Round  98, Train loss: 0.049, Test loss: 0.959, Test accuracy: 80.71 

Round  98, Global train loss: 0.049, Global test loss: 1.820, Global test accuracy: 39.21 

Round  99, Train loss: 0.061, Test loss: 0.964, Test accuracy: 80.68 

Round  99, Global train loss: 0.061, Global test loss: 1.232, Global test accuracy: 37.86 

Final Round, Train loss: 0.054, Test loss: 0.976, Test accuracy: 81.25 

Final Round, Global train loss: 0.054, Global test loss: 1.232, Global test accuracy: 37.86 

Average accuracy final 10 rounds: 80.67249999999999 

Average global accuracy final 10 rounds: 37.1225 

1264.9675703048706
[1.4278230667114258, 2.61007022857666, 3.7999649047851562, 4.974779367446899, 6.151605606079102, 7.33823037147522, 8.525569915771484, 9.715970516204834, 10.906156301498413, 12.099567890167236, 13.290263652801514, 14.475017070770264, 15.666982650756836, 16.853055715560913, 18.039665937423706, 19.222195386886597, 20.40958333015442, 21.59206199645996, 22.702178478240967, 23.879872798919678, 25.064852237701416, 26.239757776260376, 27.4243905544281, 28.444967031478882, 29.463196992874146, 30.476447105407715, 31.486693143844604, 32.50047206878662, 33.51507377624512, 34.52866268157959, 35.54560136795044, 36.56482672691345, 37.58888864517212, 38.61366248130798, 39.6379508972168, 40.655882358551025, 41.67352604866028, 42.69095826148987, 43.70682668685913, 44.71861934661865, 45.732476472854614, 46.755919456481934, 47.7720730304718, 48.79042100906372, 49.82924675941467, 50.86553382873535, 51.90370440483093, 52.93635010719299, 53.96812844276428, 54.9875123500824, 56.0052707195282, 57.01976943016052, 58.03326201438904, 59.048551082611084, 60.06442093849182, 61.0916588306427, 62.123873710632324, 63.161821365356445, 64.19920134544373, 65.23739433288574, 66.26770305633545, 67.28304076194763, 68.30396342277527, 69.32795739173889, 70.34507608413696, 71.36438226699829, 72.37878251075745, 73.40110802650452, 74.42320203781128, 75.44296884536743, 76.46796464920044, 77.49544715881348, 78.51929306983948, 79.53841042518616, 80.5622923374176, 81.58001518249512, 82.59758353233337, 83.6084337234497, 84.6172547340393, 85.64035677909851, 86.66614699363708, 87.70356464385986, 88.72226691246033, 89.74390077590942, 90.76665091514587, 91.79068279266357, 92.81519794464111, 93.83190512657166, 94.8580584526062, 95.88319325447083, 96.90546822547913, 97.92650389671326, 98.9456639289856, 99.9648175239563, 100.98220038414001, 102.00087857246399, 103.02547359466553, 104.08137226104736, 105.10222887992859, 106.12454962730408, 108.16347575187683]
[39.9, 51.125, 57.25, 58.291666666666664, 61.25, 65.13333333333334, 69.73333333333333, 71.41666666666667, 72.29166666666667, 73.18333333333334, 72.60833333333333, 72.19166666666666, 73.3, 74.03333333333333, 74.18333333333334, 74.575, 73.925, 75.96666666666667, 74.55833333333334, 74.94166666666666, 74.36666666666666, 76.3, 78.25, 78.09166666666667, 78.375, 78.61666666666666, 79.11666666666666, 79.025, 79.45833333333333, 79.875, 79.71666666666667, 79.61666666666666, 79.925, 79.61666666666666, 79.31666666666666, 79.275, 79.41666666666667, 79.85, 79.85, 79.95833333333333, 80.33333333333333, 80.71666666666667, 80.70833333333333, 80.025, 80.11666666666666, 79.95833333333333, 80.25, 80.25833333333334, 80.05833333333334, 80.24166666666666, 80.05833333333334, 79.61666666666666, 79.85833333333333, 79.94166666666666, 79.9, 80.0, 80.19166666666666, 80.04166666666667, 80.49166666666666, 80.06666666666666, 80.4, 80.44166666666666, 80.05833333333334, 80.49166666666666, 80.31666666666666, 80.90833333333333, 80.65, 81.24166666666666, 81.06666666666666, 81.16666666666667, 81.21666666666667, 80.85, 80.575, 80.60833333333333, 80.63333333333334, 80.55833333333334, 80.89166666666667, 80.91666666666667, 80.89166666666667, 80.70833333333333, 80.81666666666666, 80.925, 80.65833333333333, 80.73333333333333, 80.95, 81.025, 80.78333333333333, 80.85, 80.70833333333333, 80.76666666666667, 81.16666666666667, 80.74166666666666, 80.49166666666666, 80.79166666666667, 80.85, 80.675, 80.325, 80.29166666666667, 80.70833333333333, 80.68333333333334, 81.25]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.905, Test loss: 1.039, Test accuracy: 44.62 

Round   0, Global train loss: 0.905, Global test loss: 1.122, Global test accuracy: 37.32 

Round   1, Train loss: 0.766, Test loss: 0.976, Test accuracy: 48.84 

Round   1, Global train loss: 0.766, Global test loss: 1.154, Global test accuracy: 35.80 

Round   2, Train loss: 0.717, Test loss: 0.936, Test accuracy: 54.82 

Round   2, Global train loss: 0.717, Global test loss: 1.234, Global test accuracy: 36.07 

Round   3, Train loss: 0.615, Test loss: 0.930, Test accuracy: 56.54 

Round   3, Global train loss: 0.615, Global test loss: 1.280, Global test accuracy: 36.67 

Round   4, Train loss: 0.745, Test loss: 0.773, Test accuracy: 64.29 

Round   4, Global train loss: 0.745, Global test loss: 1.165, Global test accuracy: 39.21 

Round   5, Train loss: 0.605, Test loss: 0.834, Test accuracy: 64.52 

Round   5, Global train loss: 0.605, Global test loss: 1.522, Global test accuracy: 38.67 

Round   6, Train loss: 0.645, Test loss: 0.759, Test accuracy: 67.12 

Round   6, Global train loss: 0.645, Global test loss: 1.360, Global test accuracy: 39.62 

Round   7, Train loss: 0.575, Test loss: 0.647, Test accuracy: 70.29 

Round   7, Global train loss: 0.575, Global test loss: 1.137, Global test accuracy: 39.03 

Round   8, Train loss: 0.553, Test loss: 0.602, Test accuracy: 73.55 

Round   8, Global train loss: 0.553, Global test loss: 1.548, Global test accuracy: 34.89 

Round   9, Train loss: 0.586, Test loss: 0.594, Test accuracy: 74.21 

Round   9, Global train loss: 0.586, Global test loss: 1.352, Global test accuracy: 36.08 

Round  10, Train loss: 0.549, Test loss: 0.598, Test accuracy: 74.01 

Round  10, Global train loss: 0.549, Global test loss: 1.280, Global test accuracy: 34.20 

Round  11, Train loss: 0.616, Test loss: 0.581, Test accuracy: 74.77 

Round  11, Global train loss: 0.616, Global test loss: 1.439, Global test accuracy: 34.88 

Round  12, Train loss: 0.589, Test loss: 0.576, Test accuracy: 75.39 

Round  12, Global train loss: 0.589, Global test loss: 1.133, Global test accuracy: 40.34 

Round  13, Train loss: 0.594, Test loss: 0.566, Test accuracy: 75.90 

Round  13, Global train loss: 0.594, Global test loss: 1.498, Global test accuracy: 39.94 

Round  14, Train loss: 0.552, Test loss: 0.552, Test accuracy: 76.72 

Round  14, Global train loss: 0.552, Global test loss: 1.236, Global test accuracy: 41.00 

Round  15, Train loss: 0.556, Test loss: 0.550, Test accuracy: 77.01 

Round  15, Global train loss: 0.556, Global test loss: 1.284, Global test accuracy: 35.75 

Round  16, Train loss: 0.482, Test loss: 0.542, Test accuracy: 77.53 

Round  16, Global train loss: 0.482, Global test loss: 1.301, Global test accuracy: 36.58 

Round  17, Train loss: 0.523, Test loss: 0.541, Test accuracy: 77.58 

Round  17, Global train loss: 0.523, Global test loss: 1.296, Global test accuracy: 36.88 

Round  18, Train loss: 0.494, Test loss: 0.542, Test accuracy: 77.74 

Round  18, Global train loss: 0.494, Global test loss: 1.561, Global test accuracy: 38.93 

Round  19, Train loss: 0.565, Test loss: 0.547, Test accuracy: 77.72 

Round  19, Global train loss: 0.565, Global test loss: 1.444, Global test accuracy: 38.40 

Round  20, Train loss: 0.477, Test loss: 0.547, Test accuracy: 77.53 

Round  20, Global train loss: 0.477, Global test loss: 1.348, Global test accuracy: 39.73 

Round  21, Train loss: 0.422, Test loss: 0.539, Test accuracy: 77.74 

Round  21, Global train loss: 0.422, Global test loss: 1.514, Global test accuracy: 40.19 

Round  22, Train loss: 0.527, Test loss: 0.555, Test accuracy: 76.97 

Round  22, Global train loss: 0.527, Global test loss: 1.387, Global test accuracy: 37.34 

Round  23, Train loss: 0.449, Test loss: 0.546, Test accuracy: 77.63 

Round  23, Global train loss: 0.449, Global test loss: 1.226, Global test accuracy: 39.74 

Round  24, Train loss: 0.485, Test loss: 0.534, Test accuracy: 78.13 

Round  24, Global train loss: 0.485, Global test loss: 1.340, Global test accuracy: 37.69 

Round  25, Train loss: 0.534, Test loss: 0.527, Test accuracy: 78.73 

Round  25, Global train loss: 0.534, Global test loss: 1.164, Global test accuracy: 40.48 

Round  26, Train loss: 0.491, Test loss: 0.520, Test accuracy: 78.90 

Round  26, Global train loss: 0.491, Global test loss: 1.330, Global test accuracy: 36.86 

Round  27, Train loss: 0.473, Test loss: 0.517, Test accuracy: 79.29 

Round  27, Global train loss: 0.473, Global test loss: 1.228, Global test accuracy: 40.70 

Round  28, Train loss: 0.412, Test loss: 0.502, Test accuracy: 79.77 

Round  28, Global train loss: 0.412, Global test loss: 1.592, Global test accuracy: 38.59 

Round  29, Train loss: 0.444, Test loss: 0.500, Test accuracy: 79.93 

Round  29, Global train loss: 0.444, Global test loss: 1.322, Global test accuracy: 37.16 

Round  30, Train loss: 0.384, Test loss: 0.504, Test accuracy: 79.93 

Round  30, Global train loss: 0.384, Global test loss: 1.590, Global test accuracy: 37.27 

Round  31, Train loss: 0.450, Test loss: 0.492, Test accuracy: 80.33 

Round  31, Global train loss: 0.450, Global test loss: 1.547, Global test accuracy: 41.17 

Round  32, Train loss: 0.421, Test loss: 0.501, Test accuracy: 80.16 

Round  32, Global train loss: 0.421, Global test loss: 1.309, Global test accuracy: 40.38 

Round  33, Train loss: 0.442, Test loss: 0.496, Test accuracy: 80.29 

Round  33, Global train loss: 0.442, Global test loss: 1.429, Global test accuracy: 41.18 

Round  34, Train loss: 0.418, Test loss: 0.504, Test accuracy: 80.15 

Round  34, Global train loss: 0.418, Global test loss: 1.608, Global test accuracy: 38.60 

Round  35, Train loss: 0.422, Test loss: 0.495, Test accuracy: 80.39 

Round  35, Global train loss: 0.422, Global test loss: 1.497, Global test accuracy: 40.12 

Round  36, Train loss: 0.426, Test loss: 0.505, Test accuracy: 80.34 

Round  36, Global train loss: 0.426, Global test loss: 1.478, Global test accuracy: 40.23 

Round  37, Train loss: 0.418, Test loss: 0.501, Test accuracy: 80.34 

Round  37, Global train loss: 0.418, Global test loss: 1.391, Global test accuracy: 37.64 

Round  38, Train loss: 0.394, Test loss: 0.493, Test accuracy: 80.49 

Round  38, Global train loss: 0.394, Global test loss: 1.443, Global test accuracy: 40.67 

Round  39, Train loss: 0.470, Test loss: 0.505, Test accuracy: 80.22 

Round  39, Global train loss: 0.470, Global test loss: 1.812, Global test accuracy: 35.12 

Round  40, Train loss: 0.346, Test loss: 0.507, Test accuracy: 80.33 

Round  40, Global train loss: 0.346, Global test loss: 1.397, Global test accuracy: 40.65 

Round  41, Train loss: 0.404, Test loss: 0.494, Test accuracy: 80.66 

Round  41, Global train loss: 0.404, Global test loss: 1.458, Global test accuracy: 36.28 

Round  42, Train loss: 0.371, Test loss: 0.481, Test accuracy: 81.11 

Round  42, Global train loss: 0.371, Global test loss: 1.459, Global test accuracy: 41.24 

Round  43, Train loss: 0.366, Test loss: 0.486, Test accuracy: 81.37 

Round  43, Global train loss: 0.366, Global test loss: 1.620, Global test accuracy: 39.83 

Round  44, Train loss: 0.352, Test loss: 0.486, Test accuracy: 81.43 

Round  44, Global train loss: 0.352, Global test loss: 1.954, Global test accuracy: 38.23 

Round  45, Train loss: 0.360, Test loss: 0.490, Test accuracy: 81.45 

Round  45, Global train loss: 0.360, Global test loss: 1.356, Global test accuracy: 37.84 

Round  46, Train loss: 0.367, Test loss: 0.487, Test accuracy: 81.31 

Round  46, Global train loss: 0.367, Global test loss: 1.395, Global test accuracy: 41.67 

Round  47, Train loss: 0.367, Test loss: 0.489, Test accuracy: 81.47 

Round  47, Global train loss: 0.367, Global test loss: 1.414, Global test accuracy: 39.86 

Round  48, Train loss: 0.402, Test loss: 0.477, Test accuracy: 81.85 

Round  48, Global train loss: 0.402, Global test loss: 1.385, Global test accuracy: 39.47 

Round  49, Train loss: 0.341, Test loss: 0.475, Test accuracy: 81.88 

Round  49, Global train loss: 0.341, Global test loss: 1.858, Global test accuracy: 39.48 

Round  50, Train loss: 0.356, Test loss: 0.486, Test accuracy: 81.61 

Round  50, Global train loss: 0.356, Global test loss: 1.558, Global test accuracy: 40.37 

Round  51, Train loss: 0.338, Test loss: 0.492, Test accuracy: 81.67 

Round  51, Global train loss: 0.338, Global test loss: 1.758, Global test accuracy: 40.38 

Round  52, Train loss: 0.295, Test loss: 0.493, Test accuracy: 81.57 

Round  52, Global train loss: 0.295, Global test loss: 1.658, Global test accuracy: 41.42 

Round  53, Train loss: 0.362, Test loss: 0.500, Test accuracy: 81.71 

Round  53, Global train loss: 0.362, Global test loss: 1.359, Global test accuracy: 39.48 

Round  54, Train loss: 0.315, Test loss: 0.505, Test accuracy: 81.52 

Round  54, Global train loss: 0.315, Global test loss: 1.453, Global test accuracy: 38.73 

Round  55, Train loss: 0.383, Test loss: 0.491, Test accuracy: 81.72 

Round  55, Global train loss: 0.383, Global test loss: 1.406, Global test accuracy: 38.76 

Round  56, Train loss: 0.289, Test loss: 0.496, Test accuracy: 81.67 

Round  56, Global train loss: 0.289, Global test loss: 1.611, Global test accuracy: 41.57 

Round  57, Train loss: 0.390, Test loss: 0.478, Test accuracy: 82.32 

Round  57, Global train loss: 0.390, Global test loss: 1.522, Global test accuracy: 37.73 

Round  58, Train loss: 0.304, Test loss: 0.482, Test accuracy: 82.38 

Round  58, Global train loss: 0.304, Global test loss: 2.343, Global test accuracy: 41.12 

Round  59, Train loss: 0.312, Test loss: 0.472, Test accuracy: 82.67 

Round  59, Global train loss: 0.312, Global test loss: 1.829, Global test accuracy: 39.16 

Round  60, Train loss: 0.339, Test loss: 0.467, Test accuracy: 82.86 

Round  60, Global train loss: 0.339, Global test loss: 1.464, Global test accuracy: 39.29 

Round  61, Train loss: 0.281, Test loss: 0.487, Test accuracy: 82.21 

Round  61, Global train loss: 0.281, Global test loss: 1.587, Global test accuracy: 39.59 

Round  62, Train loss: 0.267, Test loss: 0.479, Test accuracy: 82.58 

Round  62, Global train loss: 0.267, Global test loss: 1.564, Global test accuracy: 41.14 

Round  63, Train loss: 0.282, Test loss: 0.495, Test accuracy: 82.20 

Round  63, Global train loss: 0.282, Global test loss: 1.927, Global test accuracy: 39.41 

Round  64, Train loss: 0.274, Test loss: 0.494, Test accuracy: 82.09 

Round  64, Global train loss: 0.274, Global test loss: 1.468, Global test accuracy: 39.71 

Round  65, Train loss: 0.292, Test loss: 0.492, Test accuracy: 82.11 

Round  65, Global train loss: 0.292, Global test loss: 1.590, Global test accuracy: 40.41 

Round  66, Train loss: 0.266, Test loss: 0.497, Test accuracy: 82.11 

Round  66, Global train loss: 0.266, Global test loss: 1.486, Global test accuracy: 42.67 

Round  67, Train loss: 0.302, Test loss: 0.504, Test accuracy: 81.83 

Round  67, Global train loss: 0.302, Global test loss: 1.602, Global test accuracy: 42.68 

Round  68, Train loss: 0.323, Test loss: 0.507, Test accuracy: 81.73 

Round  68, Global train loss: 0.323, Global test loss: 1.883, Global test accuracy: 36.71 

Round  69, Train loss: 0.261, Test loss: 0.500, Test accuracy: 82.05 

Round  69, Global train loss: 0.261, Global test loss: 1.917, Global test accuracy: 37.87 

Round  70, Train loss: 0.246, Test loss: 0.501, Test accuracy: 82.18 

Round  70, Global train loss: 0.246, Global test loss: 1.769, Global test accuracy: 39.64 

Round  71, Train loss: 0.328, Test loss: 0.497, Test accuracy: 82.54 

Round  71, Global train loss: 0.328, Global test loss: 1.434, Global test accuracy: 39.48 

Round  72, Train loss: 0.277, Test loss: 0.499, Test accuracy: 82.52 

Round  72, Global train loss: 0.277, Global test loss: 1.727, Global test accuracy: 40.86 

Round  73, Train loss: 0.263, Test loss: 0.494, Test accuracy: 82.67 

Round  73, Global train loss: 0.263, Global test loss: 1.755, Global test accuracy: 38.15 

Round  74, Train loss: 0.220, Test loss: 0.502, Test accuracy: 82.44 

Round  74, Global train loss: 0.220, Global test loss: 1.826, Global test accuracy: 39.30 

Round  75, Train loss: 0.362, Test loss: 0.501, Test accuracy: 82.49 

Round  75, Global train loss: 0.362, Global test loss: 1.501, Global test accuracy: 41.02 

Round  76, Train loss: 0.304, Test loss: 0.490, Test accuracy: 82.83 

Round  76, Global train loss: 0.304, Global test loss: 1.471, Global test accuracy: 38.23 

Round  77, Train loss: 0.235, Test loss: 0.496, Test accuracy: 82.67 

Round  77, Global train loss: 0.235, Global test loss: 1.553, Global test accuracy: 40.80 

Round  78, Train loss: 0.232, Test loss: 0.491, Test accuracy: 82.92 

Round  78, Global train loss: 0.232, Global test loss: 1.555, Global test accuracy: 40.12 

Round  79, Train loss: 0.272, Test loss: 0.500, Test accuracy: 82.58 

Round  79, Global train loss: 0.272, Global test loss: 1.915, Global test accuracy: 42.48 

Round  80, Train loss: 0.205, Test loss: 0.504, Test accuracy: 82.63 

Round  80, Global train loss: 0.205, Global test loss: 2.252, Global test accuracy: 43.14 

Round  81, Train loss: 0.314, Test loss: 0.504, Test accuracy: 82.60 

Round  81, Global train loss: 0.314, Global test loss: 1.528, Global test accuracy: 42.24 

Round  82, Train loss: 0.331, Test loss: 0.508, Test accuracy: 82.67 

Round  82, Global train loss: 0.331, Global test loss: 1.623, Global test accuracy: 40.28 

Round  83, Train loss: 0.240, Test loss: 0.503, Test accuracy: 82.87 

Round  83, Global train loss: 0.240, Global test loss: 1.685, Global test accuracy: 38.65 

Round  84, Train loss: 0.224, Test loss: 0.505, Test accuracy: 82.54 

Round  84, Global train loss: 0.224, Global test loss: 1.623, Global test accuracy: 39.29 

Round  85, Train loss: 0.274, Test loss: 0.498, Test accuracy: 82.44 

Round  85, Global train loss: 0.274, Global test loss: 1.855, Global test accuracy: 40.52 

Round  86, Train loss: 0.333, Test loss: 0.507, Test accuracy: 82.38 

Round  86, Global train loss: 0.333, Global test loss: 1.563, Global test accuracy: 39.14 

Round  87, Train loss: 0.225, Test loss: 0.525, Test accuracy: 82.06 

Round  87, Global train loss: 0.225, Global test loss: 1.624, Global test accuracy: 38.56 

Round  88, Train loss: 0.215, Test loss: 0.546, Test accuracy: 81.85 

Round  88, Global train loss: 0.215, Global test loss: 1.589, Global test accuracy: 40.05 

Round  89, Train loss: 0.226, Test loss: 0.529, Test accuracy: 82.54 

Round  89, Global train loss: 0.226, Global test loss: 1.725, Global test accuracy: 40.25 

Round  90, Train loss: 0.275, Test loss: 0.528, Test accuracy: 82.66 

Round  90, Global train loss: 0.275, Global test loss: 1.820, Global test accuracy: 42.57 

Round  91, Train loss: 0.234, Test loss: 0.523, Test accuracy: 82.00 

Round  91, Global train loss: 0.234, Global test loss: 2.452, Global test accuracy: 41.62 

Round  92, Train loss: 0.282, Test loss: 0.530, Test accuracy: 82.18 

Round  92, Global train loss: 0.282, Global test loss: 1.739, Global test accuracy: 39.36 

Round  93, Train loss: 0.267, Test loss: 0.520, Test accuracy: 82.42 

Round  93, Global train loss: 0.267, Global test loss: 1.683, Global test accuracy: 42.84 

Round  94, Train loss: 0.229, Test loss: 0.517, Test accuracy: 82.77 

Round  94, Global train loss: 0.229, Global test loss: 1.955, Global test accuracy: 43.13 

Round  95, Train loss: 0.207, Test loss: 0.518, Test accuracy: 83.00 

Round  95, Global train loss: 0.207, Global test loss: 1.844, Global test accuracy: 42.37 

Round  96, Train loss: 0.240, Test loss: 0.518, Test accuracy: 82.86 

Round  96, Global train loss: 0.240, Global test loss: 1.508, Global test accuracy: 40.53 

Round  97, Train loss: 0.232, Test loss: 0.512, Test accuracy: 82.66 

Round  97, Global train loss: 0.232, Global test loss: 1.696, Global test accuracy: 42.77 

Round  98, Train loss: 0.260, Test loss: 0.518, Test accuracy: 82.71 

Round  98, Global train loss: 0.260, Global test loss: 1.578, Global test accuracy: 40.35 

Round  99, Train loss: 0.219, Test loss: 0.505, Test accuracy: 82.72 

Round  99, Global train loss: 0.219, Global test loss: 1.788, Global test accuracy: 41.83 

Final Round, Train loss: 0.183, Test loss: 0.585, Test accuracy: 82.83 

Final Round, Global train loss: 0.183, Global test loss: 1.788, Global test accuracy: 41.83 

Average accuracy final 10 rounds: 82.59749999999998 

Average global accuracy final 10 rounds: 41.735833333333325 

1299.0341801643372
[1.4136595726013184, 2.555959701538086, 3.70005202293396, 4.877057313919067, 6.05763053894043, 7.23851203918457, 8.514435052871704, 9.693271160125732, 10.876097679138184, 12.056430101394653, 13.233677625656128, 14.416636228561401, 15.59741497039795, 16.772165536880493, 17.95469617843628, 19.133273363113403, 20.320720911026, 21.506773471832275, 22.68581199645996, 23.860824823379517, 25.024349689483643, 26.19184398651123, 27.36655020713806, 28.540284633636475, 29.710453271865845, 30.885844469070435, 32.05654001235962, 33.226828813552856, 34.40903854370117, 35.583348989486694, 36.76107740402222, 37.93502974510193, 39.11172795295715, 40.290971755981445, 41.465496301651, 42.64035964012146, 43.826205253601074, 45.00919008255005, 46.18731451034546, 47.361982107162476, 48.53847408294678, 49.710753440856934, 50.885703563690186, 52.06529378890991, 53.24968433380127, 54.42208695411682, 55.59842801094055, 56.77740478515625, 57.95222544670105, 59.12928652763367, 60.306135416030884, 61.47935771942139, 62.66123962402344, 63.83714723587036, 65.01719284057617, 66.19469356536865, 67.37672853469849, 68.55839228630066, 69.73547315597534, 70.91760921478271, 72.10105848312378, 73.28565049171448, 74.458016872406, 75.63361763954163, 76.81295895576477, 77.98746752738953, 79.16191840171814, 80.33697438240051, 81.51660585403442, 82.69971060752869, 83.88085699081421, 85.06028628349304, 86.23637819290161, 87.32712435722351, 88.3396360874176, 89.3547215461731, 90.36841773986816, 91.38451957702637, 92.39936351776123, 93.41793298721313, 94.4312093257904, 95.44393491744995, 96.45737266540527, 97.47327089309692, 98.48705530166626, 99.50268888473511, 100.51673436164856, 101.5318169593811, 102.54800653457642, 103.56232953071594, 104.57875156402588, 105.59526038169861, 106.61680316925049, 107.63820910453796, 108.66318798065186, 109.68952560424805, 110.71048259735107, 111.73672556877136, 112.7542839050293, 113.77577924728394, 115.8034155368805]
[44.625, 48.84166666666667, 54.81666666666667, 56.541666666666664, 64.29166666666667, 64.51666666666667, 67.125, 70.29166666666667, 73.55, 74.20833333333333, 74.00833333333334, 74.76666666666667, 75.39166666666667, 75.9, 76.725, 77.00833333333334, 77.525, 77.575, 77.74166666666666, 77.725, 77.525, 77.74166666666666, 76.96666666666667, 77.63333333333334, 78.13333333333334, 78.73333333333333, 78.9, 79.29166666666667, 79.76666666666667, 79.93333333333334, 79.93333333333334, 80.33333333333333, 80.15833333333333, 80.29166666666667, 80.15, 80.39166666666667, 80.34166666666667, 80.34166666666667, 80.49166666666666, 80.225, 80.33333333333333, 80.65833333333333, 81.10833333333333, 81.36666666666666, 81.43333333333334, 81.45, 81.30833333333334, 81.46666666666667, 81.85, 81.88333333333334, 81.60833333333333, 81.66666666666667, 81.56666666666666, 81.70833333333333, 81.51666666666667, 81.71666666666667, 81.66666666666667, 82.31666666666666, 82.38333333333334, 82.675, 82.85833333333333, 82.20833333333333, 82.58333333333333, 82.2, 82.09166666666667, 82.10833333333333, 82.10833333333333, 81.825, 81.73333333333333, 82.05, 82.18333333333334, 82.54166666666667, 82.51666666666667, 82.675, 82.44166666666666, 82.49166666666666, 82.83333333333333, 82.675, 82.91666666666667, 82.575, 82.63333333333334, 82.6, 82.675, 82.86666666666666, 82.54166666666667, 82.44166666666666, 82.38333333333334, 82.05833333333334, 81.85, 82.54166666666667, 82.65833333333333, 82.0, 82.18333333333334, 82.425, 82.76666666666667, 83.0, 82.85833333333333, 82.65833333333333, 82.70833333333333, 82.71666666666667, 82.825]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307387 (local), 307192 (global); Percentage 99.94 (307192/307387 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.045, Test loss: 1.102, Test accuracy: 36.81 

Round   1, Train loss: 0.939, Test loss: 1.129, Test accuracy: 38.74 

Round   2, Train loss: 0.881, Test loss: 1.019, Test accuracy: 47.27 

Round   3, Train loss: 0.767, Test loss: 1.006, Test accuracy: 50.67 

Round   4, Train loss: 0.709, Test loss: 0.991, Test accuracy: 51.44 

Round   5, Train loss: 0.759, Test loss: 0.914, Test accuracy: 55.30 

Round   6, Train loss: 0.728, Test loss: 0.800, Test accuracy: 60.47 

Round   7, Train loss: 0.661, Test loss: 0.742, Test accuracy: 65.10 

Round   8, Train loss: 0.619, Test loss: 0.744, Test accuracy: 64.83 

Round   9, Train loss: 0.615, Test loss: 0.678, Test accuracy: 67.30 

Round  10, Train loss: 0.613, Test loss: 0.714, Test accuracy: 66.87 

Round  11, Train loss: 0.639, Test loss: 0.668, Test accuracy: 69.21 

Round  12, Train loss: 0.573, Test loss: 0.661, Test accuracy: 70.31 

Round  13, Train loss: 0.546, Test loss: 0.609, Test accuracy: 72.09 

Round  14, Train loss: 0.530, Test loss: 0.582, Test accuracy: 74.24 

Round  15, Train loss: 0.545, Test loss: 0.566, Test accuracy: 75.26 

Round  16, Train loss: 0.534, Test loss: 0.554, Test accuracy: 75.59 

Round  17, Train loss: 0.578, Test loss: 0.537, Test accuracy: 76.75 

Round  18, Train loss: 0.534, Test loss: 0.523, Test accuracy: 77.67 

Round  19, Train loss: 0.510, Test loss: 0.520, Test accuracy: 77.51 

Round  20, Train loss: 0.527, Test loss: 0.520, Test accuracy: 77.82 

Round  21, Train loss: 0.468, Test loss: 0.513, Test accuracy: 78.39 

Round  22, Train loss: 0.541, Test loss: 0.506, Test accuracy: 78.64 

Round  23, Train loss: 0.515, Test loss: 0.502, Test accuracy: 78.78 

Round  24, Train loss: 0.493, Test loss: 0.492, Test accuracy: 79.12 

Round  25, Train loss: 0.534, Test loss: 0.493, Test accuracy: 79.47 

Round  26, Train loss: 0.438, Test loss: 0.492, Test accuracy: 79.44 

Round  27, Train loss: 0.483, Test loss: 0.480, Test accuracy: 79.72 

Round  28, Train loss: 0.513, Test loss: 0.485, Test accuracy: 79.20 

Round  29, Train loss: 0.473, Test loss: 0.477, Test accuracy: 79.53 

Round  30, Train loss: 0.529, Test loss: 0.475, Test accuracy: 80.09 

Round  31, Train loss: 0.422, Test loss: 0.459, Test accuracy: 80.76 

Round  32, Train loss: 0.463, Test loss: 0.456, Test accuracy: 80.90 

Round  33, Train loss: 0.483, Test loss: 0.459, Test accuracy: 80.60 

Round  34, Train loss: 0.477, Test loss: 0.466, Test accuracy: 80.42 

Round  35, Train loss: 0.451, Test loss: 0.458, Test accuracy: 80.79 

Round  36, Train loss: 0.403, Test loss: 0.444, Test accuracy: 81.34 

Round  37, Train loss: 0.435, Test loss: 0.439, Test accuracy: 81.82 

Round  38, Train loss: 0.378, Test loss: 0.438, Test accuracy: 81.77 

Round  39, Train loss: 0.380, Test loss: 0.439, Test accuracy: 81.50 

Round  40, Train loss: 0.399, Test loss: 0.428, Test accuracy: 82.16 

Round  41, Train loss: 0.455, Test loss: 0.438, Test accuracy: 81.70 

Round  42, Train loss: 0.479, Test loss: 0.435, Test accuracy: 81.98 

Round  43, Train loss: 0.395, Test loss: 0.433, Test accuracy: 82.28 

Round  44, Train loss: 0.446, Test loss: 0.432, Test accuracy: 82.23 

Round  45, Train loss: 0.339, Test loss: 0.422, Test accuracy: 82.50 

Round  46, Train loss: 0.370, Test loss: 0.422, Test accuracy: 82.58 

Round  47, Train loss: 0.385, Test loss: 0.415, Test accuracy: 83.10 

Round  48, Train loss: 0.388, Test loss: 0.421, Test accuracy: 83.00 

Round  49, Train loss: 0.335, Test loss: 0.424, Test accuracy: 82.61 

Round  50, Train loss: 0.418, Test loss: 0.410, Test accuracy: 83.00 

Round  51, Train loss: 0.413, Test loss: 0.404, Test accuracy: 83.14 

Round  52, Train loss: 0.408, Test loss: 0.406, Test accuracy: 83.33 

Round  53, Train loss: 0.295, Test loss: 0.409, Test accuracy: 82.87 

Round  54, Train loss: 0.386, Test loss: 0.405, Test accuracy: 83.34 

Round  55, Train loss: 0.337, Test loss: 0.403, Test accuracy: 83.51 

Round  56, Train loss: 0.314, Test loss: 0.409, Test accuracy: 83.46 

Round  57, Train loss: 0.339, Test loss: 0.399, Test accuracy: 83.70 

Round  58, Train loss: 0.292, Test loss: 0.401, Test accuracy: 83.42 

Round  59, Train loss: 0.352, Test loss: 0.398, Test accuracy: 83.73 

Round  60, Train loss: 0.402, Test loss: 0.393, Test accuracy: 84.17 

Round  61, Train loss: 0.342, Test loss: 0.393, Test accuracy: 84.07 

Round  62, Train loss: 0.361, Test loss: 0.390, Test accuracy: 84.22 

Round  63, Train loss: 0.365, Test loss: 0.387, Test accuracy: 84.25 

Round  64, Train loss: 0.314, Test loss: 0.392, Test accuracy: 83.99 

Round  65, Train loss: 0.330, Test loss: 0.384, Test accuracy: 84.64 

Round  66, Train loss: 0.356, Test loss: 0.389, Test accuracy: 84.06 

Round  67, Train loss: 0.315, Test loss: 0.388, Test accuracy: 84.01 

Round  68, Train loss: 0.363, Test loss: 0.385, Test accuracy: 84.25 

Round  69, Train loss: 0.297, Test loss: 0.386, Test accuracy: 84.43 

Round  70, Train loss: 0.290, Test loss: 0.390, Test accuracy: 84.26 

Round  71, Train loss: 0.270, Test loss: 0.387, Test accuracy: 84.47 

Round  72, Train loss: 0.323, Test loss: 0.381, Test accuracy: 84.53 

Round  73, Train loss: 0.250, Test loss: 0.389, Test accuracy: 84.32 

Round  74, Train loss: 0.292, Test loss: 0.389, Test accuracy: 84.42 

Round  75, Train loss: 0.281, Test loss: 0.383, Test accuracy: 84.31 

Round  76, Train loss: 0.325, Test loss: 0.379, Test accuracy: 84.78 

Round  77, Train loss: 0.217, Test loss: 0.379, Test accuracy: 84.77 

Round  78, Train loss: 0.315, Test loss: 0.375, Test accuracy: 85.02 

Round  79, Train loss: 0.296, Test loss: 0.376, Test accuracy: 85.08 

Round  80, Train loss: 0.276, Test loss: 0.385, Test accuracy: 84.81 

Round  81, Train loss: 0.299, Test loss: 0.375, Test accuracy: 85.12 

Round  82, Train loss: 0.231, Test loss: 0.378, Test accuracy: 85.11 

Round  83, Train loss: 0.281, Test loss: 0.376, Test accuracy: 84.79 

Round  84, Train loss: 0.257, Test loss: 0.370, Test accuracy: 85.28 

Round  85, Train loss: 0.261, Test loss: 0.383, Test accuracy: 84.85 

Round  86, Train loss: 0.229, Test loss: 0.382, Test accuracy: 84.85 

Round  87, Train loss: 0.263, Test loss: 0.375, Test accuracy: 84.86 

Round  88, Train loss: 0.234, Test loss: 0.378, Test accuracy: 85.43 

Round  89, Train loss: 0.319, Test loss: 0.370, Test accuracy: 85.70 

Round  90, Train loss: 0.222, Test loss: 0.376, Test accuracy: 85.33 

Round  91, Train loss: 0.245, Test loss: 0.376, Test accuracy: 85.56 

Round  92, Train loss: 0.205, Test loss: 0.376, Test accuracy: 85.47 

Round  93, Train loss: 0.271, Test loss: 0.374, Test accuracy: 85.65 

Round  94, Train loss: 0.260, Test loss: 0.371, Test accuracy: 85.83 

Round  95, Train loss: 0.222, Test loss: 0.390, Test accuracy: 85.16 

Round  96, Train loss: 0.233, Test loss: 0.385, Test accuracy: 85.48 

Round  97, Train loss: 0.256, Test loss: 0.375, Test accuracy: 85.66 

Round  98, Train loss: 0.216, Test loss: 0.368, Test accuracy: 85.80 

Round  99, Train loss: 0.227, Test loss: 0.373, Test accuracy: 85.33 

Final Round, Train loss: 0.210, Test loss: 0.377, Test accuracy: 85.76 

Average accuracy final 10 rounds: 85.52666666666666 

943.7484905719757
[1.3009612560272217, 2.3456428050994873, 3.394474506378174, 4.442238092422485, 5.489205598831177, 6.53584361076355, 7.581589221954346, 8.627515316009521, 9.677824020385742, 10.724499464035034, 11.777747631072998, 12.825876474380493, 13.872684955596924, 14.917826175689697, 15.966173648834229, 16.98021936416626, 17.995350122451782, 19.010651111602783, 20.031586170196533, 21.04910397529602, 22.065792083740234, 23.081255674362183, 24.118056297302246, 25.13053607940674, 26.157315969467163, 27.165915966033936, 28.183246850967407, 29.195776224136353, 30.21437096595764, 31.22411346435547, 32.241771936416626, 33.25701594352722, 34.27337718009949, 35.287023067474365, 36.327900409698486, 37.37494611740112, 38.41756248474121, 39.46416926383972, 40.50888419151306, 41.55661869049072, 42.60311412811279, 43.65085291862488, 44.696396827697754, 45.742135763168335, 46.79074430465698, 47.838643074035645, 48.88570857048035, 49.931926012039185, 50.98214936256409, 52.02621340751648, 53.03699827194214, 54.05355787277222, 55.0827362537384, 56.125842571258545, 57.16685223579407, 58.20571231842041, 59.252032995224, 60.2942578792572, 61.333401679992676, 62.38113594055176, 63.43076205253601, 64.47386598587036, 65.51765370368958, 66.56971859931946, 67.61247777938843, 68.65978860855103, 69.70179486274719, 70.74428343772888, 71.78972387313843, 72.83803677558899, 73.89569926261902, 74.94767999649048, 75.99455118179321, 77.03728771209717, 78.08531093597412, 79.1257004737854, 80.17172145843506, 81.20858097076416, 82.25031876564026, 83.2919328212738, 84.33361005783081, 85.37891840934753, 86.3921446800232, 87.40263724327087, 88.41282725334167, 89.42702651023865, 90.44108462333679, 91.45847654342651, 92.47209334373474, 93.48292636871338, 94.494713306427, 95.5070948600769, 96.51996803283691, 97.56206607818604, 98.61194586753845, 99.6606957912445, 100.70665645599365, 101.7511854171753, 102.80267763137817, 103.84978413581848, 105.71806406974792]
[36.80833333333333, 38.74166666666667, 47.275, 50.675, 51.44166666666667, 55.3, 60.46666666666667, 65.1, 64.825, 67.3, 66.86666666666666, 69.20833333333333, 70.30833333333334, 72.09166666666667, 74.24166666666666, 75.25833333333334, 75.59166666666667, 76.75, 77.66666666666667, 77.50833333333334, 77.81666666666666, 78.39166666666667, 78.64166666666667, 78.78333333333333, 79.125, 79.475, 79.44166666666666, 79.71666666666667, 79.2, 79.525, 80.09166666666667, 80.75833333333334, 80.9, 80.6, 80.425, 80.79166666666667, 81.34166666666667, 81.81666666666666, 81.76666666666667, 81.5, 82.15833333333333, 81.7, 81.98333333333333, 82.275, 82.23333333333333, 82.5, 82.575, 83.1, 83.0, 82.60833333333333, 83.0, 83.14166666666667, 83.33333333333333, 82.86666666666666, 83.34166666666667, 83.50833333333334, 83.45833333333333, 83.7, 83.425, 83.73333333333333, 84.16666666666667, 84.06666666666666, 84.21666666666667, 84.25, 83.99166666666666, 84.64166666666667, 84.05833333333334, 84.00833333333334, 84.25, 84.43333333333334, 84.25833333333334, 84.46666666666667, 84.525, 84.31666666666666, 84.425, 84.30833333333334, 84.78333333333333, 84.76666666666667, 85.01666666666667, 85.08333333333333, 84.80833333333334, 85.11666666666666, 85.10833333333333, 84.79166666666667, 85.275, 84.85, 84.85, 84.85833333333333, 85.43333333333334, 85.7, 85.33333333333333, 85.55833333333334, 85.475, 85.65, 85.825, 85.15833333333333, 85.48333333333333, 85.65833333333333, 85.8, 85.325, 85.75833333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
fedper
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307387 (local), 307192 (global); Percentage 99.94 (307192/307387 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.958, Test loss: 1.115, Test accuracy: 33.85 

Round   1, Train loss: 0.800, Test loss: 1.116, Test accuracy: 40.19 

Round   2, Train loss: 0.723, Test loss: 1.184, Test accuracy: 41.34 

Round   3, Train loss: 0.745, Test loss: 1.039, Test accuracy: 47.38 

Round   4, Train loss: 0.670, Test loss: 1.114, Test accuracy: 42.59 

Round   5, Train loss: 0.618, Test loss: 1.022, Test accuracy: 48.32 

Round   6, Train loss: 0.599, Test loss: 0.951, Test accuracy: 53.12 

Round   7, Train loss: 0.603, Test loss: 0.936, Test accuracy: 54.53 

Round   8, Train loss: 0.503, Test loss: 0.833, Test accuracy: 61.78 

Round   9, Train loss: 0.573, Test loss: 0.817, Test accuracy: 61.05 

Round  10, Train loss: 0.549, Test loss: 0.862, Test accuracy: 60.61 

Round  11, Train loss: 0.543, Test loss: 0.712, Test accuracy: 66.42 

Round  12, Train loss: 0.564, Test loss: 0.737, Test accuracy: 65.43 

Round  13, Train loss: 0.574, Test loss: 0.732, Test accuracy: 65.93 

Round  14, Train loss: 0.491, Test loss: 0.689, Test accuracy: 68.32 

Round  15, Train loss: 0.498, Test loss: 0.659, Test accuracy: 69.95 

Round  16, Train loss: 0.537, Test loss: 0.657, Test accuracy: 69.91 

Round  17, Train loss: 0.554, Test loss: 0.623, Test accuracy: 71.88 

Round  18, Train loss: 0.507, Test loss: 0.610, Test accuracy: 73.09 

Round  19, Train loss: 0.444, Test loss: 0.625, Test accuracy: 72.69 

Round  20, Train loss: 0.527, Test loss: 0.588, Test accuracy: 73.71 

Round  21, Train loss: 0.411, Test loss: 0.613, Test accuracy: 72.99 

Round  22, Train loss: 0.493, Test loss: 0.571, Test accuracy: 75.18 

Round  23, Train loss: 0.426, Test loss: 0.555, Test accuracy: 75.92 

Round  24, Train loss: 0.428, Test loss: 0.558, Test accuracy: 76.08 

Round  25, Train loss: 0.431, Test loss: 0.562, Test accuracy: 75.57 

Round  26, Train loss: 0.368, Test loss: 0.537, Test accuracy: 76.71 

Round  27, Train loss: 0.356, Test loss: 0.527, Test accuracy: 77.31 

Round  28, Train loss: 0.372, Test loss: 0.522, Test accuracy: 77.37 

Round  29, Train loss: 0.375, Test loss: 0.513, Test accuracy: 78.24 

Round  30, Train loss: 0.394, Test loss: 0.507, Test accuracy: 78.37 

Round  31, Train loss: 0.320, Test loss: 0.485, Test accuracy: 79.20 

Round  32, Train loss: 0.373, Test loss: 0.489, Test accuracy: 79.04 

Round  33, Train loss: 0.310, Test loss: 0.484, Test accuracy: 79.33 

Round  34, Train loss: 0.340, Test loss: 0.488, Test accuracy: 79.62 

Round  35, Train loss: 0.332, Test loss: 0.476, Test accuracy: 80.20 

Round  36, Train loss: 0.359, Test loss: 0.478, Test accuracy: 80.11 

Round  37, Train loss: 0.387, Test loss: 0.475, Test accuracy: 80.11 

Round  38, Train loss: 0.315, Test loss: 0.448, Test accuracy: 81.41 

Round  39, Train loss: 0.370, Test loss: 0.463, Test accuracy: 81.12 

Round  40, Train loss: 0.317, Test loss: 0.459, Test accuracy: 81.33 

Round  41, Train loss: 0.301, Test loss: 0.446, Test accuracy: 81.69 

Round  42, Train loss: 0.339, Test loss: 0.461, Test accuracy: 81.30 

Round  43, Train loss: 0.342, Test loss: 0.456, Test accuracy: 81.53 

Round  44, Train loss: 0.294, Test loss: 0.460, Test accuracy: 81.26 

Round  45, Train loss: 0.255, Test loss: 0.447, Test accuracy: 82.24 

Round  46, Train loss: 0.258, Test loss: 0.447, Test accuracy: 81.83 

Round  47, Train loss: 0.262, Test loss: 0.450, Test accuracy: 81.68 

Round  48, Train loss: 0.266, Test loss: 0.438, Test accuracy: 82.33 

Round  49, Train loss: 0.286, Test loss: 0.443, Test accuracy: 82.07 

Round  50, Train loss: 0.250, Test loss: 0.463, Test accuracy: 81.59 

Round  51, Train loss: 0.279, Test loss: 0.437, Test accuracy: 82.38 

Round  52, Train loss: 0.225, Test loss: 0.455, Test accuracy: 82.22 

Round  53, Train loss: 0.244, Test loss: 0.431, Test accuracy: 82.80 

Round  54, Train loss: 0.302, Test loss: 0.443, Test accuracy: 82.23 

Round  55, Train loss: 0.261, Test loss: 0.429, Test accuracy: 82.65 

Round  56, Train loss: 0.292, Test loss: 0.434, Test accuracy: 82.90 

Round  57, Train loss: 0.250, Test loss: 0.425, Test accuracy: 83.52 

Round  58, Train loss: 0.245, Test loss: 0.411, Test accuracy: 83.84 

Round  59, Train loss: 0.254, Test loss: 0.431, Test accuracy: 83.00 

Round  60, Train loss: 0.230, Test loss: 0.427, Test accuracy: 83.21 

Round  61, Train loss: 0.277, Test loss: 0.428, Test accuracy: 82.97 

Round  62, Train loss: 0.189, Test loss: 0.435, Test accuracy: 83.59 

Round  63, Train loss: 0.259, Test loss: 0.428, Test accuracy: 83.28 

Round  64, Train loss: 0.233, Test loss: 0.433, Test accuracy: 83.25 

Round  65, Train loss: 0.250, Test loss: 0.418, Test accuracy: 83.72 

Round  66, Train loss: 0.234, Test loss: 0.415, Test accuracy: 83.90 

Round  67, Train loss: 0.261, Test loss: 0.415, Test accuracy: 84.09 

Round  68, Train loss: 0.211, Test loss: 0.440, Test accuracy: 83.26 

Round  69, Train loss: 0.246, Test loss: 0.427, Test accuracy: 84.18 

Round  70, Train loss: 0.186, Test loss: 0.423, Test accuracy: 84.07 

Round  71, Train loss: 0.198, Test loss: 0.420, Test accuracy: 84.62 

Round  72, Train loss: 0.271, Test loss: 0.425, Test accuracy: 84.02 

Round  73, Train loss: 0.200, Test loss: 0.433, Test accuracy: 84.06 

Round  74, Train loss: 0.180, Test loss: 0.426, Test accuracy: 84.38 

Round  75, Train loss: 0.179, Test loss: 0.420, Test accuracy: 84.56 

Round  76, Train loss: 0.194, Test loss: 0.432, Test accuracy: 84.39 

Round  77, Train loss: 0.222, Test loss: 0.434, Test accuracy: 83.92 

Round  78, Train loss: 0.188, Test loss: 0.435, Test accuracy: 84.47 

Round  79, Train loss: 0.212, Test loss: 0.428, Test accuracy: 84.68 

Round  80, Train loss: 0.228, Test loss: 0.425, Test accuracy: 84.40 

Round  81, Train loss: 0.220, Test loss: 0.430, Test accuracy: 84.16 

Round  82, Train loss: 0.188, Test loss: 0.414, Test accuracy: 84.50 

Round  83, Train loss: 0.141, Test loss: 0.428, Test accuracy: 84.75 

Round  84, Train loss: 0.195, Test loss: 0.417, Test accuracy: 84.52 

Round  85, Train loss: 0.145, Test loss: 0.422, Test accuracy: 84.64 

Round  86, Train loss: 0.168, Test loss: 0.435, Test accuracy: 84.33 

Round  87, Train loss: 0.181, Test loss: 0.421, Test accuracy: 84.92 

Round  88, Train loss: 0.160, Test loss: 0.430, Test accuracy: 84.86 

Round  89, Train loss: 0.237, Test loss: 0.428, Test accuracy: 84.51 

Round  90, Train loss: 0.209, Test loss: 0.431, Test accuracy: 84.89 

Round  91, Train loss: 0.148, Test loss: 0.437, Test accuracy: 84.67 

Round  92, Train loss: 0.164, Test loss: 0.443, Test accuracy: 84.79 

Round  93, Train loss: 0.214, Test loss: 0.442, Test accuracy: 84.65 

Round  94, Train loss: 0.214, Test loss: 0.448, Test accuracy: 84.43 

Round  95, Train loss: 0.222, Test loss: 0.441, Test accuracy: 84.62 

Round  96, Train loss: 0.140, Test loss: 0.449, Test accuracy: 84.57 

Round  97, Train loss: 0.162, Test loss: 0.434, Test accuracy: 84.69 

Round  98, Train loss: 0.169, Test loss: 0.443, Test accuracy: 84.58 

Round  99, Train loss: 0.151, Test loss: 0.462, Test accuracy: 84.39 

Final Round, Train loss: 0.152, Test loss: 0.430, Test accuracy: 85.40 

Average accuracy final 10 rounds: 84.62916666666666 

998.9166803359985
[1.4085090160369873, 2.5901942253112793, 3.7717905044555664, 4.947521924972534, 6.118747711181641, 7.290632009506226, 8.460937738418579, 9.631439924240112, 10.80173134803772, 11.972764015197754, 13.143340349197388, 14.319161176681519, 15.48944902420044, 16.666112661361694, 17.84020686149597, 19.013636112213135, 20.186256408691406, 21.356943130493164, 22.51974129676819, 23.68726873397827, 24.85544514656067, 26.030997276306152, 27.2097384929657, 28.386578798294067, 29.568939924240112, 30.74777579307556, 31.923850774765015, 33.1014986038208, 34.280696868896484, 35.4580352306366, 36.63169550895691, 37.810856342315674, 38.98966145515442, 40.16828417778015, 41.348604679107666, 42.528897523880005, 43.70624852180481, 44.88362789154053, 46.066184520721436, 47.24885034561157, 48.427539587020874, 49.60358738899231, 50.781264305114746, 51.95056676864624, 53.12036156654358, 54.29147005081177, 55.464146852493286, 56.636860370635986, 57.809197425842285, 58.989086866378784, 60.1667594909668, 61.34241342544556, 62.51440668106079, 63.684160232543945, 64.85339522361755, 66.02288722991943, 67.19371128082275, 68.36122226715088, 69.5300886631012, 70.69880676269531, 71.86772060394287, 73.03893041610718, 74.20987057685852, 75.37513065338135, 76.53219056129456, 77.69051885604858, 78.84786319732666, 80.00457167625427, 81.15838146209717, 82.32045388221741, 83.32124352455139, 84.32499241828918, 85.32964396476746, 86.32960605621338, 87.33585214614868, 88.33821392059326, 89.33717966079712, 90.34098935127258, 91.34441900253296, 92.34354186058044, 93.34468626976013, 94.34829211235046, 95.35561943054199, 96.3576648235321, 97.35460209846497, 98.35438799858093, 99.35573053359985, 100.35546255111694, 101.35947227478027, 102.36605167388916, 103.37003636360168, 104.37153267860413, 105.3788423538208, 106.38334035873413, 107.38468432426453, 108.39137482643127, 109.39714431762695, 110.3999547958374, 111.40350580215454, 112.41079640388489, 114.19190549850464]
[33.85, 40.19166666666667, 41.34166666666667, 47.375, 42.59166666666667, 48.31666666666667, 53.125, 54.53333333333333, 61.78333333333333, 61.05, 60.608333333333334, 66.41666666666667, 65.43333333333334, 65.93333333333334, 68.31666666666666, 69.95, 69.90833333333333, 71.875, 73.09166666666667, 72.69166666666666, 73.70833333333333, 72.99166666666666, 75.18333333333334, 75.925, 76.08333333333333, 75.56666666666666, 76.70833333333333, 77.30833333333334, 77.36666666666666, 78.24166666666666, 78.36666666666666, 79.2, 79.04166666666667, 79.33333333333333, 79.61666666666666, 80.2, 80.10833333333333, 80.10833333333333, 81.40833333333333, 81.125, 81.325, 81.69166666666666, 81.3, 81.53333333333333, 81.25833333333334, 82.24166666666666, 81.83333333333333, 81.68333333333334, 82.325, 82.06666666666666, 81.59166666666667, 82.375, 82.21666666666667, 82.8, 82.23333333333333, 82.65, 82.9, 83.51666666666667, 83.84166666666667, 83.0, 83.20833333333333, 82.96666666666667, 83.59166666666667, 83.28333333333333, 83.25, 83.725, 83.9, 84.09166666666667, 83.25833333333334, 84.18333333333334, 84.06666666666666, 84.61666666666666, 84.01666666666667, 84.05833333333334, 84.38333333333334, 84.55833333333334, 84.39166666666667, 83.925, 84.46666666666667, 84.68333333333334, 84.4, 84.15833333333333, 84.5, 84.75, 84.51666666666667, 84.64166666666667, 84.33333333333333, 84.91666666666667, 84.85833333333333, 84.50833333333334, 84.89166666666667, 84.675, 84.79166666666667, 84.65, 84.43333333333334, 84.61666666666666, 84.56666666666666, 84.69166666666666, 84.58333333333333, 84.39166666666667, 85.4]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.2  

Files already downloaded and verified
Files already downloaded and verified
lg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307387 (local), 7939 (global); Percentage 2.58 (7939/307387 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 0.897, Test loss: 1.004, Test accuracy: 44.82 

Round   1, Train loss: 0.788, Test loss: 0.998, Test accuracy: 49.98 

Round   2, Train loss: 0.663, Test loss: 0.866, Test accuracy: 56.74 

Round   3, Train loss: 0.684, Test loss: 0.819, Test accuracy: 61.35 

Round   4, Train loss: 0.624, Test loss: 0.712, Test accuracy: 66.10 

Round   5, Train loss: 0.595, Test loss: 0.717, Test accuracy: 68.38 

Round   6, Train loss: 0.646, Test loss: 0.665, Test accuracy: 70.31 

Round   7, Train loss: 0.531, Test loss: 0.604, Test accuracy: 73.97 

Round   8, Train loss: 0.517, Test loss: 0.598, Test accuracy: 74.66 

Round   9, Train loss: 0.476, Test loss: 0.582, Test accuracy: 75.58 

Round  10, Train loss: 0.510, Test loss: 0.591, Test accuracy: 75.45 

Round  11, Train loss: 0.429, Test loss: 0.578, Test accuracy: 75.89 

Round  12, Train loss: 0.453, Test loss: 0.566, Test accuracy: 76.25 

Round  13, Train loss: 0.478, Test loss: 0.557, Test accuracy: 76.60 

Round  14, Train loss: 0.443, Test loss: 0.572, Test accuracy: 76.40 

Round  15, Train loss: 0.445, Test loss: 0.580, Test accuracy: 76.40 

Round  16, Train loss: 0.446, Test loss: 0.562, Test accuracy: 77.18 

Round  17, Train loss: 0.374, Test loss: 0.571, Test accuracy: 77.35 

Round  18, Train loss: 0.350, Test loss: 0.579, Test accuracy: 77.18 

Round  19, Train loss: 0.451, Test loss: 0.572, Test accuracy: 78.09 

Round  20, Train loss: 0.431, Test loss: 0.572, Test accuracy: 78.17 

Round  21, Train loss: 0.364, Test loss: 0.563, Test accuracy: 78.89 

Round  22, Train loss: 0.332, Test loss: 0.557, Test accuracy: 79.35 

Round  23, Train loss: 0.293, Test loss: 0.581, Test accuracy: 79.03 

Round  24, Train loss: 0.268, Test loss: 0.597, Test accuracy: 78.69 

Round  25, Train loss: 0.336, Test loss: 0.603, Test accuracy: 78.65 

Round  26, Train loss: 0.322, Test loss: 0.618, Test accuracy: 78.72 

Round  27, Train loss: 0.256, Test loss: 0.618, Test accuracy: 79.00 

Round  28, Train loss: 0.272, Test loss: 0.610, Test accuracy: 79.43 

Round  29, Train loss: 0.247, Test loss: 0.644, Test accuracy: 78.63 

Round  30, Train loss: 0.250, Test loss: 0.634, Test accuracy: 78.80 

Round  31, Train loss: 0.228, Test loss: 0.630, Test accuracy: 79.47 

Round  32, Train loss: 0.217, Test loss: 0.615, Test accuracy: 79.69 

Round  33, Train loss: 0.208, Test loss: 0.623, Test accuracy: 79.47 

Round  34, Train loss: 0.267, Test loss: 0.646, Test accuracy: 79.83 

Round  35, Train loss: 0.227, Test loss: 0.666, Test accuracy: 79.70 

Round  36, Train loss: 0.276, Test loss: 0.695, Test accuracy: 79.24 

Round  37, Train loss: 0.175, Test loss: 0.687, Test accuracy: 79.59 

Round  38, Train loss: 0.250, Test loss: 0.675, Test accuracy: 79.72 

Round  39, Train loss: 0.202, Test loss: 0.685, Test accuracy: 79.69 

Round  40, Train loss: 0.198, Test loss: 0.700, Test accuracy: 79.79 

Round  41, Train loss: 0.217, Test loss: 0.685, Test accuracy: 80.09 

Round  42, Train loss: 0.163, Test loss: 0.702, Test accuracy: 79.91 

Round  43, Train loss: 0.192, Test loss: 0.721, Test accuracy: 79.40 

Round  44, Train loss: 0.182, Test loss: 0.728, Test accuracy: 78.99 

Round  45, Train loss: 0.158, Test loss: 0.723, Test accuracy: 79.43 

Round  46, Train loss: 0.198, Test loss: 0.722, Test accuracy: 79.84 

Round  47, Train loss: 0.136, Test loss: 0.746, Test accuracy: 79.74 

Round  48, Train loss: 0.152, Test loss: 0.738, Test accuracy: 80.22 

Round  49, Train loss: 0.118, Test loss: 0.748, Test accuracy: 80.22 

Round  50, Train loss: 0.171, Test loss: 0.757, Test accuracy: 80.24 

Round  51, Train loss: 0.114, Test loss: 0.771, Test accuracy: 80.52 

Round  52, Train loss: 0.164, Test loss: 0.767, Test accuracy: 80.55 

Round  53, Train loss: 0.133, Test loss: 0.817, Test accuracy: 80.24 

Round  54, Train loss: 0.092, Test loss: 0.831, Test accuracy: 80.43 

Round  55, Train loss: 0.107, Test loss: 0.852, Test accuracy: 80.51 

Round  56, Train loss: 0.128, Test loss: 0.828, Test accuracy: 80.47 

Round  57, Train loss: 0.147, Test loss: 0.821, Test accuracy: 80.29 

Round  58, Train loss: 0.114, Test loss: 0.845, Test accuracy: 79.82 

Round  59, Train loss: 0.102, Test loss: 0.835, Test accuracy: 80.21 

Round  60, Train loss: 0.115, Test loss: 0.865, Test accuracy: 79.99 

Round  61, Train loss: 0.105, Test loss: 0.868, Test accuracy: 79.46 

Round  62, Train loss: 0.101, Test loss: 0.857, Test accuracy: 80.11 

Round  63, Train loss: 0.079, Test loss: 0.901, Test accuracy: 79.68 

Round  64, Train loss: 0.072, Test loss: 0.936, Test accuracy: 79.32 

Round  65, Train loss: 0.089, Test loss: 0.913, Test accuracy: 79.70 

Round  66, Train loss: 0.097, Test loss: 0.901, Test accuracy: 79.99 

Round  67, Train loss: 0.082, Test loss: 0.918, Test accuracy: 79.83 

Round  68, Train loss: 0.076, Test loss: 0.924, Test accuracy: 79.70 

Round  69, Train loss: 0.091, Test loss: 0.916, Test accuracy: 79.96 

Round  70, Train loss: 0.075, Test loss: 0.926, Test accuracy: 80.17 

Round  71, Train loss: 0.097, Test loss: 0.902, Test accuracy: 80.45 

Round  72, Train loss: 0.078, Test loss: 0.909, Test accuracy: 80.51 

Round  73, Train loss: 0.064, Test loss: 0.940, Test accuracy: 80.55 

Round  74, Train loss: 0.065, Test loss: 0.955, Test accuracy: 80.48 

Round  75, Train loss: 0.075, Test loss: 0.936, Test accuracy: 80.17 

Round  76, Train loss: 0.057, Test loss: 0.937, Test accuracy: 80.15 

Round  77, Train loss: 0.093, Test loss: 0.942, Test accuracy: 80.34 

Round  78, Train loss: 0.082, Test loss: 0.983, Test accuracy: 80.17 

Round  79, Train loss: 0.091, Test loss: 0.972, Test accuracy: 80.32 

Round  80, Train loss: 0.084, Test loss: 0.975, Test accuracy: 80.34 

Round  81, Train loss: 0.057, Test loss: 0.968, Test accuracy: 80.69 

Round  82, Train loss: 0.051, Test loss: 0.987, Test accuracy: 80.51 

Round  83, Train loss: 0.064, Test loss: 1.009, Test accuracy: 80.47 

Round  84, Train loss: 0.056, Test loss: 1.021, Test accuracy: 80.23 

Round  85, Train loss: 0.072, Test loss: 1.038, Test accuracy: 79.89 

Round  86, Train loss: 0.063, Test loss: 1.025, Test accuracy: 80.01 

Round  87, Train loss: 0.067, Test loss: 0.993, Test accuracy: 80.35 

Round  88, Train loss: 0.038, Test loss: 1.023, Test accuracy: 80.22 

Round  89, Train loss: 0.050, Test loss: 1.012, Test accuracy: 80.48 

Round  90, Train loss: 0.056, Test loss: 0.989, Test accuracy: 80.53 

Round  91, Train loss: 0.034, Test loss: 1.020, Test accuracy: 80.45 

Round  92, Train loss: 0.034, Test loss: 1.032, Test accuracy: 80.67 

Round  93, Train loss: 0.073, Test loss: 1.039, Test accuracy: 80.56 

Round  94, Train loss: 0.050, Test loss: 1.023, Test accuracy: 80.67 

Round  95, Train loss: 0.038, Test loss: 1.062, Test accuracy: 80.57 

Round  96, Train loss: 0.057, Test loss: 1.042, Test accuracy: 80.53 

Round  97, Train loss: 0.051, Test loss: 1.048, Test accuracy: 80.86 

Round  98, Train loss: 0.044, Test loss: 1.062, Test accuracy: 80.73 

Round  99, Train loss: 0.040, Test loss: 1.053, Test accuracy: 80.97 

Final Round, Train loss: 0.042, Test loss: 1.089, Test accuracy: 80.88 

Average accuracy final 10 rounds: 80.65416666666665 

937.005669593811
[1.4098539352416992, 2.4158058166503906, 3.4216089248657227, 4.428410291671753, 5.435052156448364, 6.444446563720703, 7.449214220046997, 8.453679084777832, 9.461769104003906, 10.471785545349121, 11.47831654548645, 12.487751007080078, 13.496224880218506, 14.50154709815979, 15.513338565826416, 16.524377584457397, 17.532420873641968, 18.54372811317444, 19.55321502685547, 20.563546657562256, 21.572382926940918, 22.583727836608887, 23.589641571044922, 24.59340190887451, 25.604132413864136, 26.614034175872803, 27.621422052383423, 28.631205081939697, 29.638116359710693, 30.64224410057068, 31.648173570632935, 32.65319585800171, 33.66315054893494, 34.67139720916748, 35.677531003952026, 36.68837881088257, 37.696349143981934, 38.70346188545227, 39.718096017837524, 40.72945237159729, 41.73827648162842, 42.74496626853943, 43.756500482559204, 44.76528453826904, 45.771955490112305, 46.78225326538086, 47.78989362716675, 48.8039186000824, 49.81739830970764, 50.82647705078125, 51.833635091781616, 52.839104652404785, 53.84592628479004, 54.851417541503906, 55.86699151992798, 56.87211847305298, 57.87715530395508, 58.89114189147949, 59.89658546447754, 60.90212035179138, 61.91001081466675, 62.91647124290466, 63.92545127868652, 64.93907070159912, 65.95753574371338, 66.96382594108582, 67.97474455833435, 68.98419380187988, 69.99170589447021, 71.00402092933655, 72.01293110847473, 73.01830720901489, 74.02392864227295, 75.03561449050903, 76.0446400642395, 77.04865407943726, 78.06041860580444, 79.06732559204102, 80.0919041633606, 81.1044397354126, 82.11010408401489, 83.11414766311646, 84.11846542358398, 85.12079882621765, 86.12780928611755, 87.13494729995728, 88.13496279716492, 89.14336657524109, 90.15049648284912, 91.15417838096619, 92.16356301307678, 93.17098498344421, 94.1776933670044, 95.1859622001648, 96.19542694091797, 97.20220470428467, 98.2130823135376, 99.22365021705627, 100.23233580589294, 101.2394073009491, 103.20514512062073]
[44.81666666666667, 49.975, 56.74166666666667, 61.35, 66.1, 68.38333333333334, 70.30833333333334, 73.96666666666667, 74.65833333333333, 75.58333333333333, 75.45, 75.89166666666667, 76.25, 76.6, 76.4, 76.4, 77.18333333333334, 77.35, 77.18333333333334, 78.09166666666667, 78.16666666666667, 78.89166666666667, 79.35, 79.03333333333333, 78.69166666666666, 78.65, 78.725, 79.0, 79.43333333333334, 78.63333333333334, 78.8, 79.46666666666667, 79.69166666666666, 79.475, 79.825, 79.7, 79.24166666666666, 79.59166666666667, 79.71666666666667, 79.69166666666666, 79.79166666666667, 80.09166666666667, 79.90833333333333, 79.4, 78.99166666666666, 79.43333333333334, 79.84166666666667, 79.74166666666666, 80.225, 80.21666666666667, 80.24166666666666, 80.51666666666667, 80.55, 80.24166666666666, 80.43333333333334, 80.50833333333334, 80.475, 80.29166666666667, 79.81666666666666, 80.20833333333333, 79.99166666666666, 79.45833333333333, 80.10833333333333, 79.68333333333334, 79.31666666666666, 79.7, 79.99166666666666, 79.825, 79.7, 79.95833333333333, 80.175, 80.45, 80.50833333333334, 80.55, 80.48333333333333, 80.16666666666667, 80.15, 80.34166666666667, 80.16666666666667, 80.31666666666666, 80.34166666666667, 80.69166666666666, 80.50833333333334, 80.475, 80.23333333333333, 79.89166666666667, 80.00833333333334, 80.35, 80.21666666666667, 80.48333333333333, 80.53333333333333, 80.45, 80.66666666666667, 80.55833333333334, 80.675, 80.56666666666666, 80.53333333333333, 80.85833333333333, 80.73333333333333, 80.96666666666667, 80.875]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
Round   0, Train loss: 0.635, Test loss: 1.104, Test accuracy: 35.71
Round   1, Train loss: 0.511, Test loss: 1.117, Test accuracy: 44.25
Round   2, Train loss: 0.527, Test loss: 1.125, Test accuracy: 44.76
Round   3, Train loss: 0.478, Test loss: 1.065, Test accuracy: 48.25
Round   4, Train loss: 0.470, Test loss: 1.113, Test accuracy: 49.14
Round   5, Train loss: 0.377, Test loss: 1.126, Test accuracy: 52.38
Round   6, Train loss: 0.438, Test loss: 1.145, Test accuracy: 52.02
Round   7, Train loss: 0.410, Test loss: 1.041, Test accuracy: 53.57
Round   8, Train loss: 0.353, Test loss: 1.046, Test accuracy: 56.03
Round   9, Train loss: 0.366, Test loss: 1.034, Test accuracy: 56.10
Round  10, Train loss: 0.411, Test loss: 0.972, Test accuracy: 58.49
Round  11, Train loss: 0.325, Test loss: 0.962, Test accuracy: 61.03
Round  12, Train loss: 0.317, Test loss: 0.951, Test accuracy: 63.16
Round  13, Train loss: 0.294, Test loss: 0.939, Test accuracy: 63.92
Round  14, Train loss: 0.328, Test loss: 0.937, Test accuracy: 63.89
Round  15, Train loss: 0.319, Test loss: 0.929, Test accuracy: 64.01
Round  16, Train loss: 0.324, Test loss: 0.927, Test accuracy: 63.96
Round  17, Train loss: 0.249, Test loss: 0.913, Test accuracy: 65.23
Round  18, Train loss: 0.296, Test loss: 0.910, Test accuracy: 64.68
Round  19, Train loss: 0.280, Test loss: 0.893, Test accuracy: 67.00
Round  20, Train loss: 0.270, Test loss: 0.888, Test accuracy: 66.84
Round  21, Train loss: 0.199, Test loss: 0.875, Test accuracy: 67.02
Round  22, Train loss: 0.302, Test loss: 0.872, Test accuracy: 67.54
Round  23, Train loss: 0.243, Test loss: 0.862, Test accuracy: 67.94
Round  24, Train loss: 0.251, Test loss: 0.859, Test accuracy: 68.42
Round  25, Train loss: 0.225, Test loss: 0.859, Test accuracy: 68.07
Round  26, Train loss: 0.234, Test loss: 0.858, Test accuracy: 67.62
Round  27, Train loss: 0.243, Test loss: 0.849, Test accuracy: 67.28
Round  28, Train loss: 0.223, Test loss: 0.844, Test accuracy: 67.62
Round  29, Train loss: 0.191, Test loss: 0.829, Test accuracy: 68.51
Round  30, Train loss: 0.228, Test loss: 0.825, Test accuracy: 68.90
Round  31, Train loss: 0.176, Test loss: 0.828, Test accuracy: 68.10
Round  32, Train loss: 0.241, Test loss: 0.815, Test accuracy: 68.26
Round  33, Train loss: 0.152, Test loss: 0.809, Test accuracy: 68.62
Round  34, Train loss: 0.190, Test loss: 0.809, Test accuracy: 68.72
Round  35, Train loss: 0.212, Test loss: 0.805, Test accuracy: 68.59
Round  36, Train loss: 0.129, Test loss: 0.792, Test accuracy: 69.70
Round  37, Train loss: 0.175, Test loss: 0.791, Test accuracy: 69.91
Round  38, Train loss: 0.158, Test loss: 0.785, Test accuracy: 69.91
Round  39, Train loss: 0.141, Test loss: 0.786, Test accuracy: 69.69
Round  40, Train loss: 0.203, Test loss: 0.794, Test accuracy: 68.48
Round  41, Train loss: 0.143, Test loss: 0.790, Test accuracy: 67.78
Round  42, Train loss: 0.156, Test loss: 0.782, Test accuracy: 69.26
Round  43, Train loss: 0.132, Test loss: 0.779, Test accuracy: 68.90
Round  44, Train loss: 0.119, Test loss: 0.773, Test accuracy: 69.18
Round  45, Train loss: 0.153, Test loss: 0.769, Test accuracy: 69.52
Round  46, Train loss: 0.103, Test loss: 0.772, Test accuracy: 69.36
Round  47, Train loss: 0.123, Test loss: 0.774, Test accuracy: 68.20
Round  48, Train loss: 0.122, Test loss: 0.763, Test accuracy: 69.06
Round  49, Train loss: 0.118, Test loss: 0.758, Test accuracy: 69.45
Round  50, Train loss: 0.165, Test loss: 0.751, Test accuracy: 70.67
Round  51, Train loss: 0.132, Test loss: 0.749, Test accuracy: 70.33
Round  52, Train loss: 0.137, Test loss: 0.749, Test accuracy: 69.70
Round  53, Train loss: 0.154, Test loss: 0.745, Test accuracy: 69.93
Round  54, Train loss: 0.087, Test loss: 0.750, Test accuracy: 69.18
Round  55, Train loss: 0.078, Test loss: 0.738, Test accuracy: 69.99
Round  56, Train loss: 0.107, Test loss: 0.747, Test accuracy: 69.02
Round  57, Train loss: 0.080, Test loss: 0.742, Test accuracy: 69.16
Round  58, Train loss: 0.078, Test loss: 0.729, Test accuracy: 70.01
Round  59, Train loss: 0.132, Test loss: 0.733, Test accuracy: 69.98
Round  60, Train loss: 0.128, Test loss: 0.725, Test accuracy: 70.28
Round  61, Train loss: 0.082, Test loss: 0.714, Test accuracy: 71.16
Round  62, Train loss: 0.078, Test loss: 0.713, Test accuracy: 70.97
Round  63, Train loss: 0.126, Test loss: 0.720, Test accuracy: 70.62
Round  64, Train loss: 0.087, Test loss: 0.716, Test accuracy: 70.88
Round  65, Train loss: 0.090, Test loss: 0.714, Test accuracy: 70.43
Round  66, Train loss: 0.084, Test loss: 0.723, Test accuracy: 69.53
Round  67, Train loss: 0.084, Test loss: 0.712, Test accuracy: 70.38
Round  68, Train loss: 0.118, Test loss: 0.714, Test accuracy: 69.92
Round  69, Train loss: 0.123, Test loss: 0.712, Test accuracy: 70.27
Round  70, Train loss: 0.076, Test loss: 0.709, Test accuracy: 70.66
Round  71, Train loss: 0.093, Test loss: 0.727, Test accuracy: 68.92
Round  72, Train loss: 0.097, Test loss: 0.715, Test accuracy: 69.53
Round  73, Train loss: 0.071, Test loss: 0.711, Test accuracy: 69.18
Round  74, Train loss: 0.094, Test loss: 0.699, Test accuracy: 70.00
Round  75, Train loss: 0.079, Test loss: 0.706, Test accuracy: 69.63
Round  76, Train loss: 0.097, Test loss: 0.700, Test accuracy: 69.88
Round  77, Train loss: 0.088, Test loss: 0.703, Test accuracy: 69.67
Round  78, Train loss: 0.077, Test loss: 0.702, Test accuracy: 69.47
Round  79, Train loss: 0.085, Test loss: 0.705, Test accuracy: 69.11
Round  80, Train loss: 0.056, Test loss: 0.699, Test accuracy: 69.28
Round  81, Train loss: 0.071, Test loss: 0.700, Test accuracy: 68.93
Round  82, Train loss: 0.057, Test loss: 0.691, Test accuracy: 69.62
Round  83, Train loss: 0.056, Test loss: 0.693, Test accuracy: 69.50
Round  84, Train loss: 0.090, Test loss: 0.699, Test accuracy: 69.03
Round  85, Train loss: 0.064, Test loss: 0.696, Test accuracy: 69.35
Round  86, Train loss: 0.051, Test loss: 0.694, Test accuracy: 69.68
Round  87, Train loss: 0.056, Test loss: 0.691, Test accuracy: 70.01
Round  88, Train loss: 0.064, Test loss: 0.701, Test accuracy: 68.42
Round  89, Train loss: 0.093, Test loss: 0.707, Test accuracy: 68.42
Round  90, Train loss: 0.088, Test loss: 0.693, Test accuracy: 68.84
Round  91, Train loss: 0.053, Test loss: 0.683, Test accuracy: 69.72
Round  92, Train loss: 0.069, Test loss: 0.686, Test accuracy: 69.08
Round  93, Train loss: 0.068, Test loss: 0.677, Test accuracy: 70.50
Round  94, Train loss: 0.069, Test loss: 0.673, Test accuracy: 70.71
Round  95, Train loss: 0.056, Test loss: 0.668, Test accuracy: 71.21
Round  96, Train loss: 0.064, Test loss: 0.676, Test accuracy: 70.99
Round  97, Train loss: 0.071, Test loss: 0.686, Test accuracy: 70.17
Round  98, Train loss: 0.080, Test loss: 0.677, Test accuracy: 70.97
Round  99, Train loss: 0.076, Test loss: 0.683, Test accuracy: 70.70
Final Round, Train loss: 0.058, Test loss: 0.697, Test accuracy: 69.34
Average accuracy final 10 rounds: 70.29083333333332
1770.3711578845978
[]
[35.708333333333336, 44.25, 44.75833333333333, 48.25, 49.141666666666666, 52.375, 52.016666666666666, 53.56666666666667, 56.03333333333333, 56.1, 58.49166666666667, 61.03333333333333, 63.15833333333333, 63.925, 63.891666666666666, 64.00833333333334, 63.958333333333336, 65.23333333333333, 64.68333333333334, 67.0, 66.84166666666667, 67.01666666666667, 67.54166666666667, 67.94166666666666, 68.41666666666667, 68.06666666666666, 67.625, 67.28333333333333, 67.625, 68.50833333333334, 68.9, 68.1, 68.25833333333334, 68.625, 68.71666666666667, 68.59166666666667, 69.7, 69.90833333333333, 69.90833333333333, 69.69166666666666, 68.48333333333333, 67.775, 69.25833333333334, 68.9, 69.18333333333334, 69.51666666666667, 69.35833333333333, 68.2, 69.05833333333334, 69.45, 70.66666666666667, 70.33333333333333, 69.7, 69.93333333333334, 69.18333333333334, 69.99166666666666, 69.01666666666667, 69.15833333333333, 70.00833333333334, 69.98333333333333, 70.275, 71.15833333333333, 70.975, 70.625, 70.88333333333334, 70.43333333333334, 69.53333333333333, 70.375, 69.91666666666667, 70.26666666666667, 70.65833333333333, 68.91666666666667, 69.525, 69.18333333333334, 70.0, 69.63333333333334, 69.875, 69.66666666666667, 69.46666666666667, 69.10833333333333, 69.275, 68.93333333333334, 69.61666666666666, 69.5, 69.025, 69.35, 69.68333333333334, 70.00833333333334, 68.41666666666667, 68.41666666666667, 68.84166666666667, 69.725, 69.08333333333333, 70.5, 70.70833333333333, 71.20833333333333, 70.99166666666666, 70.175, 70.975, 70.7, 69.34166666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
Round   0, Train loss: 0.910, Test loss: 0.999, Test accuracy: 42.65
Round   0: Global train loss: 0.910, Global test loss: 1.099, Global test accuracy: 32.88
Round   1, Train loss: 0.738, Test loss: 0.964, Test accuracy: 46.02
Round   1: Global train loss: 0.738, Global test loss: 1.099, Global test accuracy: 33.17
Round   2, Train loss: 0.680, Test loss: 0.900, Test accuracy: 50.87
Round   2: Global train loss: 0.680, Global test loss: 1.099, Global test accuracy: 32.36
Round   3, Train loss: 0.522, Test loss: 0.844, Test accuracy: 55.77
Round   3: Global train loss: 0.522, Global test loss: 1.099, Global test accuracy: 32.94
Round   4, Train loss: 0.551, Test loss: 0.824, Test accuracy: 57.69
Round   4: Global train loss: 0.551, Global test loss: 1.099, Global test accuracy: 32.63
Round   5, Train loss: 0.027, Test loss: 0.794, Test accuracy: 59.42
Round   5: Global train loss: 0.027, Global test loss: 1.098, Global test accuracy: 32.88
Round   6, Train loss: 0.527, Test loss: 0.766, Test accuracy: 61.67
Round   6: Global train loss: 0.527, Global test loss: 1.098, Global test accuracy: 32.15
Round   7, Train loss: -0.160, Test loss: 0.748, Test accuracy: 62.32
Round   7: Global train loss: -0.160, Global test loss: 1.098, Global test accuracy: 32.70
Round   8, Train loss: 0.067, Test loss: 0.748, Test accuracy: 62.12
Round   8: Global train loss: 0.067, Global test loss: 1.099, Global test accuracy: 32.02
Round   9, Train loss: -0.426, Test loss: 0.707, Test accuracy: 64.42
Round   9: Global train loss: -0.426, Global test loss: 1.098, Global test accuracy: 32.46
Round  10, Train loss: -0.359, Test loss: 0.730, Test accuracy: 63.94
Round  10: Global train loss: -0.359, Global test loss: 1.099, Global test accuracy: 32.29
Round  11, Train loss: -0.697, Test loss: 0.715, Test accuracy: 65.83
Round  11: Global train loss: -0.697, Global test loss: 1.096, Global test accuracy: 33.46
Round  12, Train loss: -0.085, Test loss: 0.681, Test accuracy: 69.01
Round  12: Global train loss: -0.085, Global test loss: 1.095, Global test accuracy: 35.67
Round  13, Train loss: -0.804, Test loss: 0.664, Test accuracy: 70.38
Round  13: Global train loss: -0.804, Global test loss: 1.095, Global test accuracy: 35.85
Round  14, Train loss: -0.311, Test loss: 0.670, Test accuracy: 69.91
Round  14: Global train loss: -0.311, Global test loss: 1.095, Global test accuracy: 35.91
Round  15, Train loss: -1.058, Test loss: 0.664, Test accuracy: 70.44
Round  15: Global train loss: -1.058, Global test loss: 1.094, Global test accuracy: 36.52
Round  16, Train loss: -0.899, Test loss: 0.657, Test accuracy: 70.50
Round  16: Global train loss: -0.899, Global test loss: 1.094, Global test accuracy: 36.83
Round  17, Train loss: -1.202, Test loss: 0.656, Test accuracy: 70.22
Round  17: Global train loss: -1.202, Global test loss: 1.093, Global test accuracy: 37.62
Round  18, Train loss: -1.190, Test loss: 0.662, Test accuracy: 70.29
Round  18: Global train loss: -1.190, Global test loss: 1.093, Global test accuracy: 37.90
Round  19, Train loss: -0.888, Test loss: 0.662, Test accuracy: 70.36
Round  19: Global train loss: -0.888, Global test loss: 1.093, Global test accuracy: 38.17
Round  20, Train loss: -1.027, Test loss: 0.659, Test accuracy: 70.92
Round  20: Global train loss: -1.027, Global test loss: 1.093, Global test accuracy: 38.08
Round  21, Train loss: -1.325, Test loss: 0.652, Test accuracy: 71.81
Round  21: Global train loss: -1.325, Global test loss: 1.092, Global test accuracy: 38.05
Round  22, Train loss: -1.170, Test loss: 0.635, Test accuracy: 72.63
Round  22: Global train loss: -1.170, Global test loss: 1.092, Global test accuracy: 38.18
Round  23, Train loss: -1.767, Test loss: 0.630, Test accuracy: 72.88
Round  23: Global train loss: -1.767, Global test loss: 1.091, Global test accuracy: 38.13
Round  24, Train loss: -1.481, Test loss: 0.639, Test accuracy: 72.48
Round  24: Global train loss: -1.481, Global test loss: 1.091, Global test accuracy: 38.50
Round  25, Train loss: -1.625, Test loss: 0.613, Test accuracy: 74.60
Round  25: Global train loss: -1.625, Global test loss: 1.090, Global test accuracy: 38.67
Round  26, Train loss: -1.522, Test loss: 0.599, Test accuracy: 75.04
Round  26: Global train loss: -1.522, Global test loss: 1.090, Global test accuracy: 38.58
Round  27, Train loss: -2.424, Test loss: 0.606, Test accuracy: 75.32
Round  27: Global train loss: -2.424, Global test loss: 1.089, Global test accuracy: 38.55
Round  28, Train loss: -1.942, Test loss: 0.602, Test accuracy: 75.09
Round  28: Global train loss: -1.942, Global test loss: 1.089, Global test accuracy: 38.37
Round  29, Train loss: -1.533, Test loss: 0.598, Test accuracy: 75.23
Round  29: Global train loss: -1.533, Global test loss: 1.088, Global test accuracy: 39.07
Round  30, Train loss: -2.304, Test loss: 0.594, Test accuracy: 75.58
Round  30: Global train loss: -2.304, Global test loss: 1.088, Global test accuracy: 38.77
Round  31, Train loss: -2.209, Test loss: 0.574, Test accuracy: 76.67
Round  31: Global train loss: -2.209, Global test loss: 1.088, Global test accuracy: 38.42
Round  32, Train loss: -2.393, Test loss: 0.589, Test accuracy: 75.90
Round  32: Global train loss: -2.393, Global test loss: 1.088, Global test accuracy: 38.77
Round  33, Train loss: -2.258, Test loss: 0.591, Test accuracy: 75.96
Round  33: Global train loss: -2.258, Global test loss: 1.087, Global test accuracy: 38.88
Round  34, Train loss: -2.756, Test loss: 0.622, Test accuracy: 75.00
Round  34: Global train loss: -2.756, Global test loss: 1.087, Global test accuracy: 38.90
Round  35, Train loss: -3.007, Test loss: 0.608, Test accuracy: 75.10
Round  35: Global train loss: -3.007, Global test loss: 1.087, Global test accuracy: 39.23
Round  36, Train loss: -2.295, Test loss: 0.610, Test accuracy: 75.77
Round  36: Global train loss: -2.295, Global test loss: 1.086, Global test accuracy: 39.11
Round  37, Train loss: -2.561, Test loss: 0.608, Test accuracy: 76.18
Round  37: Global train loss: -2.561, Global test loss: 1.086, Global test accuracy: 39.13
Round  38, Train loss: -2.488, Test loss: 0.600, Test accuracy: 76.03
Round  38: Global train loss: -2.488, Global test loss: 1.086, Global test accuracy: 39.17
Round  39, Train loss: -2.458, Test loss: 0.575, Test accuracy: 76.92
Round  39: Global train loss: -2.458, Global test loss: 1.086, Global test accuracy: 39.01
Round  40, Train loss: -2.848, Test loss: 0.562, Test accuracy: 77.51
Round  40: Global train loss: -2.848, Global test loss: 1.086, Global test accuracy: 39.23
Round  41, Train loss: -2.566, Test loss: 0.569, Test accuracy: 77.36
Round  41: Global train loss: -2.566, Global test loss: 1.087, Global test accuracy: 39.21
Round  42, Train loss: -3.249, Test loss: 0.574, Test accuracy: 77.02
Round  42: Global train loss: -3.249, Global test loss: 1.086, Global test accuracy: 39.23
Round  43, Train loss: -3.506, Test loss: 0.574, Test accuracy: 77.08
Round  43: Global train loss: -3.506, Global test loss: 1.086, Global test accuracy: 39.19
Round  44, Train loss: -3.341, Test loss: 0.583, Test accuracy: 77.19
Round  44: Global train loss: -3.341, Global test loss: 1.086, Global test accuracy: 39.08
Round  45, Train loss: -3.651, Test loss: 0.589, Test accuracy: 76.93
Round  45: Global train loss: -3.651, Global test loss: 1.086, Global test accuracy: 38.82
Round  46, Train loss: -3.833, Test loss: 0.602, Test accuracy: 76.71
Round  46: Global train loss: -3.833, Global test loss: 1.086, Global test accuracy: 38.87
Round  47, Train loss: -4.500, Test loss: 0.594, Test accuracy: 77.42
Round  47: Global train loss: -4.500, Global test loss: 1.086, Global test accuracy: 38.77
Round  48, Train loss: -2.985, Test loss: 0.587, Test accuracy: 77.49
Round  48: Global train loss: -2.985, Global test loss: 1.086, Global test accuracy: 38.78
Round  49, Train loss: -3.278, Test loss: 0.586, Test accuracy: 77.22
Round  49: Global train loss: -3.278, Global test loss: 1.086, Global test accuracy: 38.82
Round  50, Train loss: -3.466, Test loss: 0.581, Test accuracy: 77.89
Round  50: Global train loss: -3.466, Global test loss: 1.087, Global test accuracy: 38.63
Round  51, Train loss: -3.965, Test loss: 0.573, Test accuracy: 78.12
Round  51: Global train loss: -3.965, Global test loss: 1.087, Global test accuracy: 38.20
Round  52, Train loss: -4.883, Test loss: 0.569, Test accuracy: 78.67
Round  52: Global train loss: -4.883, Global test loss: 1.087, Global test accuracy: 38.14
Round  53, Train loss: -4.278, Test loss: 0.575, Test accuracy: 78.25
Round  53: Global train loss: -4.278, Global test loss: 1.086, Global test accuracy: 38.14
Round  54, Train loss: -4.584, Test loss: 0.574, Test accuracy: 77.87
Round  54: Global train loss: -4.584, Global test loss: 1.086, Global test accuracy: 38.51
Round  55, Train loss: -3.850, Test loss: 0.594, Test accuracy: 77.29
Round  55: Global train loss: -3.850, Global test loss: 1.086, Global test accuracy: 38.07
Round  56, Train loss: -3.762, Test loss: 0.593, Test accuracy: 77.53
Round  56: Global train loss: -3.762, Global test loss: 1.086, Global test accuracy: 38.52
Round  57, Train loss: -3.585, Test loss: 0.606, Test accuracy: 77.03
Round  57: Global train loss: -3.585, Global test loss: 1.084, Global test accuracy: 38.93
Round  58, Train loss: -4.543, Test loss: 0.593, Test accuracy: 77.58
Round  58: Global train loss: -4.543, Global test loss: 1.084, Global test accuracy: 38.67
Round  59, Train loss: -3.263, Test loss: 0.601, Test accuracy: 76.85
Round  59: Global train loss: -3.263, Global test loss: 1.084, Global test accuracy: 38.59
Round  60, Train loss: -4.482, Test loss: 0.622, Test accuracy: 76.89
Round  60: Global train loss: -4.482, Global test loss: 1.085, Global test accuracy: 38.61
Round  61, Train loss: -4.356, Test loss: 0.608, Test accuracy: 77.55
Round  61: Global train loss: -4.356, Global test loss: 1.084, Global test accuracy: 38.83
Round  62, Train loss: -4.062, Test loss: 0.609, Test accuracy: 77.86
Round  62: Global train loss: -4.062, Global test loss: 1.086, Global test accuracy: 38.27
Round  63, Train loss: -4.152, Test loss: 0.633, Test accuracy: 77.44
Round  63: Global train loss: -4.152, Global test loss: 1.085, Global test accuracy: 38.69
Round  64, Train loss: -3.975, Test loss: 0.661, Test accuracy: 77.19
Round  64: Global train loss: -3.975, Global test loss: 1.085, Global test accuracy: 38.67
Round  65, Train loss: -4.937, Test loss: 0.642, Test accuracy: 77.26
Round  65: Global train loss: -4.937, Global test loss: 1.086, Global test accuracy: 38.42
Round  66, Train loss: -3.976, Test loss: 0.651, Test accuracy: 76.56
Round  66: Global train loss: -3.976, Global test loss: 1.086, Global test accuracy: 38.44
Round  67, Train loss: -5.099, Test loss: 0.621, Test accuracy: 77.82
Round  67: Global train loss: -5.099, Global test loss: 1.087, Global test accuracy: 38.62
Round  68, Train loss: -4.643, Test loss: 0.634, Test accuracy: 77.17
Round  68: Global train loss: -4.643, Global test loss: 1.087, Global test accuracy: 38.55
Round  69, Train loss: -5.288, Test loss: 0.621, Test accuracy: 78.19
Round  69: Global train loss: -5.288, Global test loss: 1.087, Global test accuracy: 38.98
Round  70, Train loss: -4.791, Test loss: 0.596, Test accuracy: 78.40
Round  70: Global train loss: -4.791, Global test loss: 1.086, Global test accuracy: 38.91
Round  71, Train loss: -4.223, Test loss: 0.589, Test accuracy: 78.31
Round  71: Global train loss: -4.223, Global test loss: 1.086, Global test accuracy: 38.95
Round  72, Train loss: -5.740, Test loss: 0.621, Test accuracy: 77.61
Round  72: Global train loss: -5.740, Global test loss: 1.086, Global test accuracy: 39.35
Round  73, Train loss: -5.222, Test loss: 0.616, Test accuracy: 77.98
Round  73: Global train loss: -5.222, Global test loss: 1.086, Global test accuracy: 39.09
Round  74, Train loss: -4.521, Test loss: 0.640, Test accuracy: 77.12
Round  74: Global train loss: -4.521, Global test loss: 1.086, Global test accuracy: 39.12
Round  75, Train loss: -5.354, Test loss: 0.665, Test accuracy: 77.11
Round  75: Global train loss: -5.354, Global test loss: 1.085, Global test accuracy: 39.20
Round  76, Train loss: -5.605, Test loss: 0.646, Test accuracy: 77.53
Round  76: Global train loss: -5.605, Global test loss: 1.084, Global test accuracy: 39.40
Round  77, Train loss: -4.721, Test loss: 0.637, Test accuracy: 77.51
Round  77: Global train loss: -4.721, Global test loss: 1.084, Global test accuracy: 39.06
Round  78, Train loss: -4.090, Test loss: 0.644, Test accuracy: 76.98
Round  78: Global train loss: -4.090, Global test loss: 1.083, Global test accuracy: 39.42
Round  79, Train loss: -5.637, Test loss: 0.670, Test accuracy: 76.86
Round  79: Global train loss: -5.637, Global test loss: 1.084, Global test accuracy: 39.46
Round  80, Train loss: -5.588, Test loss: 0.667, Test accuracy: 76.57
Round  80: Global train loss: -5.588, Global test loss: 1.085, Global test accuracy: 39.68
Round  81, Train loss: -6.163, Test loss: 0.644, Test accuracy: 77.50
Round  81: Global train loss: -6.163, Global test loss: 1.088, Global test accuracy: 39.62
Round  82, Train loss: -5.047, Test loss: 0.646, Test accuracy: 77.40
Round  82: Global train loss: -5.047, Global test loss: 1.087, Global test accuracy: 39.39
Round  83, Train loss: -5.328, Test loss: 0.615, Test accuracy: 78.34
Round  83: Global train loss: -5.328, Global test loss: 1.087, Global test accuracy: 39.36
Round  84, Train loss: -5.663, Test loss: 0.609, Test accuracy: 78.79
Round  84: Global train loss: -5.663, Global test loss: 1.089, Global test accuracy: 39.67
Round  85, Train loss: -5.281, Test loss: 0.613, Test accuracy: 78.64
Round  85: Global train loss: -5.281, Global test loss: 1.088, Global test accuracy: 39.63
Round  86, Train loss: -4.716, Test loss: 0.629, Test accuracy: 78.28
Round  86: Global train loss: -4.716, Global test loss: 1.088, Global test accuracy: 39.51
Round  87, Train loss: -5.556, Test loss: 0.639, Test accuracy: 77.58
Round  87: Global train loss: -5.556, Global test loss: 1.087, Global test accuracy: 39.71
Round  88, Train loss: -5.669, Test loss: 0.638, Test accuracy: 78.40
Round  88: Global train loss: -5.669, Global test loss: 1.086, Global test accuracy: 39.80
Round  89, Train loss: -5.928, Test loss: 0.632, Test accuracy: 78.76
Round  89: Global train loss: -5.928, Global test loss: 1.088, Global test accuracy: 39.80
Round  90, Train loss: -5.323, Test loss: 0.651, Test accuracy: 78.26
Round  90: Global train loss: -5.323, Global test loss: 1.090, Global test accuracy: 39.52
Round  91, Train loss: -5.374, Test loss: 0.610, Test accuracy: 78.81
Round  91: Global train loss: -5.374, Global test loss: 1.088, Global test accuracy: 39.48
Round  92, Train loss: -5.802, Test loss: 0.619, Test accuracy: 78.03
Round  92: Global train loss: -5.802, Global test loss: 1.089, Global test accuracy: 39.76
Round  93, Train loss: -5.048, Test loss: 0.626, Test accuracy: 77.74
Round  93: Global train loss: -5.048, Global test loss: 1.088, Global test accuracy: 40.18
Round  94, Train loss: -5.777, Test loss: 0.642, Test accuracy: 77.83
Round  94: Global train loss: -5.777, Global test loss: 1.089, Global test accuracy: 39.85
Round  95, Train loss: -5.663, Test loss: 0.618, Test accuracy: 77.72
Round  95: Global train loss: -5.663, Global test loss: 1.091, Global test accuracy: 39.95
Round  96, Train loss: -5.121, Test loss: 0.626, Test accuracy: 78.08
Round  96: Global train loss: -5.121, Global test loss: 1.093, Global test accuracy: 40.02
Round  97, Train loss: -4.801, Test loss: 0.615, Test accuracy: 78.69
Round  97: Global train loss: -4.801, Global test loss: 1.091, Global test accuracy: 39.98
Round  98, Train loss: -4.720, Test loss: 0.614, Test accuracy: 78.30
Round  98: Global train loss: -4.720, Global test loss: 1.089, Global test accuracy: 39.90
Round  99, Train loss: -5.252, Test loss: 0.625, Test accuracy: 78.11
Round  99: Global train loss: -5.252, Global test loss: 1.088, Global test accuracy: 39.76
Final Round: Train loss: 0.530, Test loss: 0.536, Test accuracy: 78.06
Final Round: Global train loss: 0.530, Global test loss: 1.090, Global test accuracy: 39.87
Average accuracy final 10 rounds: 78.1575
Average global accuracy final 10 rounds: 39.84
1718.725626707077
[]
[42.65, 46.016666666666666, 50.86666666666667, 55.775, 57.69166666666667, 59.416666666666664, 61.675, 62.31666666666667, 62.11666666666667, 64.41666666666667, 63.94166666666667, 65.83333333333333, 69.00833333333334, 70.38333333333334, 69.90833333333333, 70.44166666666666, 70.5, 70.225, 70.29166666666667, 70.35833333333333, 70.925, 71.80833333333334, 72.63333333333334, 72.88333333333334, 72.48333333333333, 74.6, 75.04166666666667, 75.31666666666666, 75.09166666666667, 75.23333333333333, 75.575, 76.675, 75.9, 75.95833333333333, 75.0, 75.1, 75.76666666666667, 76.18333333333334, 76.03333333333333, 76.925, 77.50833333333334, 77.35833333333333, 77.01666666666667, 77.08333333333333, 77.19166666666666, 76.93333333333334, 76.70833333333333, 77.41666666666667, 77.49166666666666, 77.21666666666667, 77.89166666666667, 78.11666666666666, 78.675, 78.25, 77.86666666666666, 77.29166666666667, 77.53333333333333, 77.025, 77.575, 76.85, 76.89166666666667, 77.55, 77.85833333333333, 77.44166666666666, 77.19166666666666, 77.25833333333334, 76.55833333333334, 77.81666666666666, 77.175, 78.19166666666666, 78.4, 78.30833333333334, 77.60833333333333, 77.98333333333333, 77.11666666666666, 77.10833333333333, 77.53333333333333, 77.50833333333334, 76.98333333333333, 76.85833333333333, 76.56666666666666, 77.5, 77.4, 78.34166666666667, 78.79166666666667, 78.64166666666667, 78.275, 77.575, 78.4, 78.75833333333334, 78.25833333333334, 78.80833333333334, 78.03333333333333, 77.74166666666666, 77.825, 77.725, 78.08333333333333, 78.69166666666666, 78.3, 78.10833333333333, 78.05833333333334]
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 300, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Traceback (most recent call last):
  File "main_pfedme.py", line 236, in <module>
    w_local, loss, indd = local.train(net=net_local.to(args.device), idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx],w_locals = w_locals)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 849, in train
    loss.backward()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 259, in backward
    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 142, in _make_grads
    torch.ones_like(out, memory_format=torch.preserve_format)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

Files already downloaded and verified
Files already downloaded and verified
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
Traceback (most recent call last):
  File "main_ditto.py", line 182, in <module>
    w_k, loss, indd = local.train(net=net_global.to(args.device), idx=idx, lr=args.lr, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 541, in train
    loss.backward()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 259, in backward
    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 142, in _make_grads
    torch.ones_like(out, memory_format=torch.preserve_format)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

python: can't open file 'main_fedpac_k.py': [Errno 2] No such file or directory
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.
../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 1, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
4800
4864
107264
107328
299328
299448
307128
307192
307384
307387
# Params: 307387 (local), 307192 (global); Percentage 99.94 (307192/307387)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=3, bias=True)
)
Traceback (most recent call last):
  File "main_fedpac_k_means.py", line 293, in <module>
    w_local, loss, indd, class_center_local, class_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_grob_local, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2223, in train
    loss.backward()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 259, in backward
    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/autograd/__init__.py", line 142, in _make_grads
    torch.ones_like(out, memory_format=torch.preserve_format)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.301, Test loss: 2.299, Test accuracy: 16.44 

Round   0, Global train loss: 2.301, Global test loss: 2.299, Global test accuracy: 16.18 

Round   1, Train loss: 2.296, Test loss: 2.294, Test accuracy: 16.96 

Round   1, Global train loss: 2.296, Global test loss: 2.293, Global test accuracy: 16.50 

Round   2, Train loss: 2.286, Test loss: 2.281, Test accuracy: 16.57 

Round   2, Global train loss: 2.286, Global test loss: 2.275, Global test accuracy: 13.84 

Round   3, Train loss: 2.258, Test loss: 2.259, Test accuracy: 19.82 

Round   3, Global train loss: 2.258, Global test loss: 2.240, Global test accuracy: 22.30 

Round   4, Train loss: 2.206, Test loss: 2.223, Test accuracy: 28.05 

Round   4, Global train loss: 2.206, Global test loss: 2.183, Global test accuracy: 37.28 

Round   5, Train loss: 2.260, Test loss: 2.232, Test accuracy: 27.75 

Round   5, Global train loss: 2.260, Global test loss: 2.258, Global test accuracy: 33.15 

Round   6, Train loss: 2.137, Test loss: 2.177, Test accuracy: 33.58 

Round   6, Global train loss: 2.137, Global test loss: 2.146, Global test accuracy: 39.84 

Round   7, Train loss: 2.144, Test loss: 2.124, Test accuracy: 41.48 

Round   7, Global train loss: 2.144, Global test loss: 2.099, Global test accuracy: 54.68 

Round   8, Train loss: 1.984, Test loss: 2.075, Test accuracy: 44.19 

Round   8, Global train loss: 1.984, Global test loss: 1.988, Global test accuracy: 60.05 

Round   9, Train loss: 1.964, Test loss: 2.032, Test accuracy: 47.01 

Round   9, Global train loss: 1.964, Global test loss: 1.911, Global test accuracy: 66.80 

Round  10, Train loss: 2.070, Test loss: 2.003, Test accuracy: 48.77 

Round  10, Global train loss: 2.070, Global test loss: 2.088, Global test accuracy: 55.77 

Round  11, Train loss: 1.888, Test loss: 1.974, Test accuracy: 52.00 

Round  11, Global train loss: 1.888, Global test loss: 1.877, Global test accuracy: 65.92 

Round  12, Train loss: 1.977, Test loss: 1.940, Test accuracy: 56.35 

Round  12, Global train loss: 1.977, Global test loss: 1.984, Global test accuracy: 57.78 

Round  13, Train loss: 1.830, Test loss: 1.920, Test accuracy: 57.94 

Round  13, Global train loss: 1.830, Global test loss: 1.858, Global test accuracy: 62.62 

Round  14, Train loss: 1.756, Test loss: 1.901, Test accuracy: 59.93 

Round  14, Global train loss: 1.756, Global test loss: 1.821, Global test accuracy: 67.50 

Round  15, Train loss: 1.760, Test loss: 1.876, Test accuracy: 62.31 

Round  15, Global train loss: 1.760, Global test loss: 1.777, Global test accuracy: 71.73 

Round  16, Train loss: 1.907, Test loss: 1.844, Test accuracy: 65.97 

Round  16, Global train loss: 1.907, Global test loss: 1.890, Global test accuracy: 66.67 

Round  17, Train loss: 1.778, Test loss: 1.821, Test accuracy: 68.03 

Round  17, Global train loss: 1.778, Global test loss: 1.814, Global test accuracy: 65.85 

Round  18, Train loss: 1.703, Test loss: 1.810, Test accuracy: 68.89 

Round  18, Global train loss: 1.703, Global test loss: 1.818, Global test accuracy: 64.95 

Round  19, Train loss: 1.778, Test loss: 1.788, Test accuracy: 70.79 

Round  19, Global train loss: 1.778, Global test loss: 1.834, Global test accuracy: 66.24 

Round  20, Train loss: 1.668, Test loss: 1.778, Test accuracy: 71.72 

Round  20, Global train loss: 1.668, Global test loss: 1.784, Global test accuracy: 67.91 

Round  21, Train loss: 1.695, Test loss: 1.765, Test accuracy: 73.14 

Round  21, Global train loss: 1.695, Global test loss: 1.783, Global test accuracy: 70.23 

Round  22, Train loss: 1.675, Test loss: 1.758, Test accuracy: 73.35 

Round  22, Global train loss: 1.675, Global test loss: 1.788, Global test accuracy: 68.01 

Round  23, Train loss: 1.631, Test loss: 1.745, Test accuracy: 74.23 

Round  23, Global train loss: 1.631, Global test loss: 1.710, Global test accuracy: 77.24 

Round  24, Train loss: 1.639, Test loss: 1.740, Test accuracy: 74.61 

Round  24, Global train loss: 1.639, Global test loss: 1.772, Global test accuracy: 71.49 

Round  25, Train loss: 1.651, Test loss: 1.731, Test accuracy: 75.39 

Round  25, Global train loss: 1.651, Global test loss: 1.753, Global test accuracy: 72.72 

Round  26, Train loss: 1.611, Test loss: 1.728, Test accuracy: 75.47 

Round  26, Global train loss: 1.611, Global test loss: 1.729, Global test accuracy: 75.27 

Round  27, Train loss: 1.595, Test loss: 1.723, Test accuracy: 75.63 

Round  27, Global train loss: 1.595, Global test loss: 1.699, Global test accuracy: 78.11 

Round  28, Train loss: 1.609, Test loss: 1.719, Test accuracy: 76.06 

Round  28, Global train loss: 1.609, Global test loss: 1.701, Global test accuracy: 78.74 

Round  29, Train loss: 1.618, Test loss: 1.715, Test accuracy: 76.31 

Round  29, Global train loss: 1.618, Global test loss: 1.725, Global test accuracy: 76.36 

Round  30, Train loss: 1.592, Test loss: 1.712, Test accuracy: 76.54 

Round  30, Global train loss: 1.592, Global test loss: 1.710, Global test accuracy: 76.82 

Round  31, Train loss: 1.572, Test loss: 1.705, Test accuracy: 77.19 

Round  31, Global train loss: 1.572, Global test loss: 1.672, Global test accuracy: 80.72 

Round  32, Train loss: 1.595, Test loss: 1.703, Test accuracy: 77.42 

Round  32, Global train loss: 1.595, Global test loss: 1.705, Global test accuracy: 78.70 

Round  33, Train loss: 1.542, Test loss: 1.698, Test accuracy: 77.96 

Round  33, Global train loss: 1.542, Global test loss: 1.635, Global test accuracy: 84.82 

Round  34, Train loss: 1.573, Test loss: 1.696, Test accuracy: 78.07 

Round  34, Global train loss: 1.573, Global test loss: 1.692, Global test accuracy: 77.86 

Round  35, Train loss: 1.619, Test loss: 1.693, Test accuracy: 78.29 

Round  35, Global train loss: 1.619, Global test loss: 1.762, Global test accuracy: 70.31 

Round  36, Train loss: 1.576, Test loss: 1.692, Test accuracy: 78.30 

Round  36, Global train loss: 1.576, Global test loss: 1.741, Global test accuracy: 72.09 

Round  37, Train loss: 1.599, Test loss: 1.690, Test accuracy: 78.50 

Round  37, Global train loss: 1.599, Global test loss: 1.752, Global test accuracy: 71.26 

Round  38, Train loss: 1.574, Test loss: 1.687, Test accuracy: 78.78 

Round  38, Global train loss: 1.574, Global test loss: 1.693, Global test accuracy: 78.27 

Round  39, Train loss: 1.525, Test loss: 1.686, Test accuracy: 78.87 

Round  39, Global train loss: 1.525, Global test loss: 1.651, Global test accuracy: 82.30 

Round  40, Train loss: 1.545, Test loss: 1.685, Test accuracy: 78.91 

Round  40, Global train loss: 1.545, Global test loss: 1.676, Global test accuracy: 79.98 

Round  41, Train loss: 1.543, Test loss: 1.685, Test accuracy: 78.87 

Round  41, Global train loss: 1.543, Global test loss: 1.713, Global test accuracy: 74.32 

Round  42, Train loss: 1.533, Test loss: 1.682, Test accuracy: 79.03 

Round  42, Global train loss: 1.533, Global test loss: 1.659, Global test accuracy: 81.90 

Round  43, Train loss: 1.553, Test loss: 1.682, Test accuracy: 79.08 

Round  43, Global train loss: 1.553, Global test loss: 1.687, Global test accuracy: 77.84 

Round  44, Train loss: 1.493, Test loss: 1.680, Test accuracy: 79.18 

Round  44, Global train loss: 1.493, Global test loss: 1.601, Global test accuracy: 87.65 

Round  45, Train loss: 1.547, Test loss: 1.678, Test accuracy: 79.44 

Round  45, Global train loss: 1.547, Global test loss: 1.693, Global test accuracy: 77.24 

Round  46, Train loss: 1.529, Test loss: 1.677, Test accuracy: 79.50 

Round  46, Global train loss: 1.529, Global test loss: 1.663, Global test accuracy: 81.19 

Round  47, Train loss: 1.561, Test loss: 1.676, Test accuracy: 79.61 

Round  47, Global train loss: 1.561, Global test loss: 1.736, Global test accuracy: 72.80 

Round  48, Train loss: 1.568, Test loss: 1.675, Test accuracy: 79.66 

Round  48, Global train loss: 1.568, Global test loss: 1.709, Global test accuracy: 76.97 

Round  49, Train loss: 1.547, Test loss: 1.673, Test accuracy: 79.95 

Round  49, Global train loss: 1.547, Global test loss: 1.683, Global test accuracy: 78.45 

Round  50, Train loss: 1.501, Test loss: 1.672, Test accuracy: 79.89 

Round  50, Global train loss: 1.501, Global test loss: 1.626, Global test accuracy: 84.65 

Round  51, Train loss: 1.564, Test loss: 1.672, Test accuracy: 79.93 

Round  51, Global train loss: 1.564, Global test loss: 1.732, Global test accuracy: 73.94 

Round  52, Train loss: 1.540, Test loss: 1.671, Test accuracy: 79.97 

Round  52, Global train loss: 1.540, Global test loss: 1.685, Global test accuracy: 78.39 

Round  53, Train loss: 1.501, Test loss: 1.671, Test accuracy: 79.96 

Round  53, Global train loss: 1.501, Global test loss: 1.617, Global test accuracy: 85.44 

Round  54, Train loss: 1.527, Test loss: 1.671, Test accuracy: 79.94 

Round  54, Global train loss: 1.527, Global test loss: 1.673, Global test accuracy: 79.30 

Round  55, Train loss: 1.529, Test loss: 1.671, Test accuracy: 79.95 

Round  55, Global train loss: 1.529, Global test loss: 1.647, Global test accuracy: 82.33 

Round  56, Train loss: 1.516, Test loss: 1.670, Test accuracy: 80.01 

Round  56, Global train loss: 1.516, Global test loss: 1.639, Global test accuracy: 83.12 

Round  57, Train loss: 1.554, Test loss: 1.670, Test accuracy: 79.95 

Round  57, Global train loss: 1.554, Global test loss: 1.708, Global test accuracy: 76.01 

Round  58, Train loss: 1.546, Test loss: 1.668, Test accuracy: 80.26 

Round  58, Global train loss: 1.546, Global test loss: 1.706, Global test accuracy: 76.16 

Round  59, Train loss: 1.533, Test loss: 1.668, Test accuracy: 80.28 

Round  59, Global train loss: 1.533, Global test loss: 1.677, Global test accuracy: 79.06 

Round  60, Train loss: 1.525, Test loss: 1.667, Test accuracy: 80.28 

Round  60, Global train loss: 1.525, Global test loss: 1.666, Global test accuracy: 80.06 

Round  61, Train loss: 1.512, Test loss: 1.667, Test accuracy: 80.34 

Round  61, Global train loss: 1.512, Global test loss: 1.637, Global test accuracy: 83.53 

Round  62, Train loss: 1.493, Test loss: 1.666, Test accuracy: 80.35 

Round  62, Global train loss: 1.493, Global test loss: 1.615, Global test accuracy: 85.65 

Round  63, Train loss: 1.549, Test loss: 1.666, Test accuracy: 80.36 

Round  63, Global train loss: 1.549, Global test loss: 1.732, Global test accuracy: 73.28 

Round  64, Train loss: 1.498, Test loss: 1.666, Test accuracy: 80.38 

Round  64, Global train loss: 1.498, Global test loss: 1.617, Global test accuracy: 85.48 

Round  65, Train loss: 1.539, Test loss: 1.666, Test accuracy: 80.39 

Round  65, Global train loss: 1.539, Global test loss: 1.679, Global test accuracy: 79.10 

Round  66, Train loss: 1.535, Test loss: 1.666, Test accuracy: 80.35 

Round  66, Global train loss: 1.535, Global test loss: 1.692, Global test accuracy: 77.31 

Round  67, Train loss: 1.495, Test loss: 1.665, Test accuracy: 80.39 

Round  67, Global train loss: 1.495, Global test loss: 1.620, Global test accuracy: 85.54 

Round  68, Train loss: 1.534, Test loss: 1.665, Test accuracy: 80.39 

Round  68, Global train loss: 1.534, Global test loss: 1.699, Global test accuracy: 76.50 

Round  69, Train loss: 1.501, Test loss: 1.665, Test accuracy: 80.40 

Round  69, Global train loss: 1.501, Global test loss: 1.623, Global test accuracy: 84.83 

Round  70, Train loss: 1.510, Test loss: 1.665, Test accuracy: 80.39 

Round  70, Global train loss: 1.510, Global test loss: 1.638, Global test accuracy: 82.96 

Round  71, Train loss: 1.497, Test loss: 1.665, Test accuracy: 80.39 

Round  71, Global train loss: 1.497, Global test loss: 1.639, Global test accuracy: 82.99 

Round  72, Train loss: 1.559, Test loss: 1.664, Test accuracy: 80.39 

Round  72, Global train loss: 1.559, Global test loss: 1.727, Global test accuracy: 74.33 

Round  73, Train loss: 1.512, Test loss: 1.664, Test accuracy: 80.41 

Round  73, Global train loss: 1.512, Global test loss: 1.638, Global test accuracy: 83.19 

Round  74, Train loss: 1.548, Test loss: 1.664, Test accuracy: 80.42 

Round  74, Global train loss: 1.548, Global test loss: 1.724, Global test accuracy: 73.43 

Round  75, Train loss: 1.525, Test loss: 1.664, Test accuracy: 80.43 

Round  75, Global train loss: 1.525, Global test loss: 1.663, Global test accuracy: 80.91 

Round  76, Train loss: 1.492, Test loss: 1.664, Test accuracy: 80.42 

Round  76, Global train loss: 1.492, Global test loss: 1.622, Global test accuracy: 84.79 

Round  77, Train loss: 1.521, Test loss: 1.663, Test accuracy: 80.42 

Round  77, Global train loss: 1.521, Global test loss: 1.669, Global test accuracy: 80.11 

Round  78, Train loss: 1.576, Test loss: 1.663, Test accuracy: 80.41 

Round  78, Global train loss: 1.576, Global test loss: 1.747, Global test accuracy: 72.16 

Round  79, Train loss: 1.535, Test loss: 1.663, Test accuracy: 80.39 

Round  79, Global train loss: 1.535, Global test loss: 1.702, Global test accuracy: 76.27 

Round  80, Train loss: 1.495, Test loss: 1.663, Test accuracy: 80.41 

Round  80, Global train loss: 1.495, Global test loss: 1.617, Global test accuracy: 85.29 

Round  81, Train loss: 1.484, Test loss: 1.663, Test accuracy: 80.39 

Round  81, Global train loss: 1.484, Global test loss: 1.598, Global test accuracy: 87.40 

Round  82, Train loss: 1.535, Test loss: 1.663, Test accuracy: 80.39 

Round  82, Global train loss: 1.535, Global test loss: 1.707, Global test accuracy: 75.09 

Round  83, Train loss: 1.533, Test loss: 1.663, Test accuracy: 80.36 

Round  83, Global train loss: 1.533, Global test loss: 1.697, Global test accuracy: 76.75 

Round  84, Train loss: 1.520, Test loss: 1.663, Test accuracy: 80.36 

Round  84, Global train loss: 1.520, Global test loss: 1.672, Global test accuracy: 79.35 

Round  85, Train loss: 1.560, Test loss: 1.663, Test accuracy: 80.36 

Round  85, Global train loss: 1.560, Global test loss: 1.702, Global test accuracy: 76.64 

Round  86, Train loss: 1.494, Test loss: 1.663, Test accuracy: 80.37 

Round  86, Global train loss: 1.494, Global test loss: 1.614, Global test accuracy: 85.69 

Round  87, Train loss: 1.522, Test loss: 1.663, Test accuracy: 80.40 

Round  87, Global train loss: 1.522, Global test loss: 1.675, Global test accuracy: 79.03 

Round  88, Train loss: 1.523, Test loss: 1.663, Test accuracy: 80.42 

Round  88, Global train loss: 1.523, Global test loss: 1.655, Global test accuracy: 81.35 

Round  89, Train loss: 1.545, Test loss: 1.663, Test accuracy: 80.41 

Round  89, Global train loss: 1.545, Global test loss: 1.710, Global test accuracy: 75.38 

Round  90, Train loss: 1.521, Test loss: 1.663, Test accuracy: 80.38 

Round  90, Global train loss: 1.521, Global test loss: 1.673, Global test accuracy: 79.03 

Round  91, Train loss: 1.521, Test loss: 1.663, Test accuracy: 80.37 

Round  91, Global train loss: 1.521, Global test loss: 1.665, Global test accuracy: 80.25 

Round  92, Train loss: 1.519, Test loss: 1.663, Test accuracy: 80.34 

Round  92, Global train loss: 1.519, Global test loss: 1.669, Global test accuracy: 79.98 

Round  93, Train loss: 1.520, Test loss: 1.663, Test accuracy: 80.33 

Round  93, Global train loss: 1.520, Global test loss: 1.679, Global test accuracy: 78.36 
/home/ChenSM/code/FL_HLS/utils/sampling.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Train loss: 1.522, Test loss: 1.663, Test accuracy: 80.35 

Round  94, Global train loss: 1.522, Global test loss: 1.663, Global test accuracy: 80.42 

Round  95, Train loss: 1.503, Test loss: 1.663, Test accuracy: 80.37 

Round  95, Global train loss: 1.503, Global test loss: 1.639, Global test accuracy: 83.05 

Round  96, Train loss: 1.517, Test loss: 1.663, Test accuracy: 80.37 

Round  96, Global train loss: 1.517, Global test loss: 1.670, Global test accuracy: 79.58 

Round  97, Train loss: 1.503, Test loss: 1.663, Test accuracy: 80.38 

Round  97, Global train loss: 1.503, Global test loss: 1.632, Global test accuracy: 83.60 

Round  98, Train loss: 1.535, Test loss: 1.663, Test accuracy: 80.38 

Round  98, Global train loss: 1.535, Global test loss: 1.693, Global test accuracy: 76.85 

Round  99, Train loss: 1.486, Test loss: 1.663, Test accuracy: 80.34 

Round  99, Global train loss: 1.486, Global test loss: 1.590, Global test accuracy: 88.06 

Final Round, Train loss: 1.523, Test loss: 1.662, Test accuracy: 80.35 

Final Round, Global train loss: 1.523, Global test loss: 1.590, Global test accuracy: 88.06 

Average accuracy final 10 rounds: 80.36175 

Average global accuracy final 10 rounds: 80.919 

2108.165360212326
[0.8355996608734131, 1.5845181941986084, 2.334195375442505, 3.087692975997925, 3.8513028621673584, 4.6018407344818115, 5.350720643997192, 6.101351737976074, 6.851322889328003, 7.603301763534546, 8.347714185714722, 9.089219093322754, 9.837637186050415, 10.5889413356781, 11.33078384399414, 12.080727815628052, 12.827370882034302, 13.574724197387695, 14.330241203308105, 15.07575511932373, 15.830928564071655, 16.584962844848633, 17.334152698516846, 18.083654165267944, 18.830393075942993, 19.58276081085205, 20.33340835571289, 21.084737539291382, 21.838294506072998, 22.58740997314453, 23.334511756896973, 24.088112592697144, 24.837799072265625, 25.58543372154236, 26.330329656600952, 27.078204870224, 27.829265594482422, 28.581746339797974, 29.328667640686035, 30.080888986587524, 30.83284020423889, 31.588260889053345, 32.35140037536621, 33.09996771812439, 33.851526498794556, 34.60350728034973, 35.3541202545166, 36.10665678977966, 36.857775926589966, 37.60702466964722, 38.35429906845093, 39.08951807022095, 39.87700629234314, 40.638922452926636, 41.442710638046265, 42.24369239807129, 43.04380798339844, 43.84220266342163, 44.649057149887085, 45.456358432769775, 46.25765538215637, 47.06411957740784, 47.86730194091797, 48.66986536979675, 49.47037124633789, 50.26891756057739, 51.07203793525696, 51.868653774261475, 52.67118430137634, 53.473209381103516, 54.27626943588257, 55.074970960617065, 55.873136043548584, 56.6790132522583, 57.48073959350586, 58.275704860687256, 59.07356023788452, 59.86854648590088, 60.67164587974548, 61.47897386550903, 62.27925395965576, 63.07581615447998, 63.88023591041565, 64.68689322471619, 65.48319816589355, 66.27619409561157, 67.08249616622925, 67.88472557067871, 68.68357872962952, 69.48618292808533, 70.28708100318909, 71.0872118473053, 71.8855562210083, 72.684077501297, 73.48223328590393, 74.28362941741943, 75.0856351852417, 75.88178610801697, 76.68109893798828, 77.48627781867981, 79.08658790588379]
[16.44, 16.9575, 16.57, 19.8175, 28.05, 27.7475, 33.5825, 41.475, 44.185, 47.005, 48.765, 51.9975, 56.3525, 57.9375, 59.93, 62.3075, 65.975, 68.0325, 68.8875, 70.7875, 71.72, 73.1425, 73.3525, 74.235, 74.615, 75.39, 75.4725, 75.63, 76.055, 76.305, 76.5425, 77.19, 77.42, 77.9625, 78.07, 78.2875, 78.295, 78.495, 78.785, 78.8725, 78.9125, 78.8725, 79.025, 79.08, 79.1825, 79.4425, 79.5025, 79.605, 79.655, 79.95, 79.89, 79.9325, 79.965, 79.96, 79.9425, 79.955, 80.0125, 79.9525, 80.2575, 80.28, 80.2825, 80.34, 80.3475, 80.3575, 80.3775, 80.385, 80.3525, 80.3875, 80.3925, 80.3975, 80.39, 80.385, 80.385, 80.4125, 80.4225, 80.43, 80.4175, 80.42, 80.4075, 80.3925, 80.4075, 80.39, 80.3875, 80.355, 80.365, 80.36, 80.37, 80.4, 80.415, 80.405, 80.38, 80.3675, 80.3425, 80.335, 80.3475, 80.3675, 80.3725, 80.3825, 80.3775, 80.345, 80.35]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.301, Test loss: 2.300, Test accuracy: 17.13 

Round   0, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 16.93 

Round   1, Train loss: 2.298, Test loss: 2.297, Test accuracy: 27.57 

Round   1, Global train loss: 2.298, Global test loss: 2.296, Global test accuracy: 30.96 

Round   2, Train loss: 2.291, Test loss: 2.291, Test accuracy: 37.55 

Round   2, Global train loss: 2.291, Global test loss: 2.287, Global test accuracy: 48.12 

Round   3, Train loss: 2.274, Test loss: 2.271, Test accuracy: 38.08 

Round   3, Global train loss: 2.274, Global test loss: 2.255, Global test accuracy: 47.82 

Round   4, Train loss: 2.149, Test loss: 2.161, Test accuracy: 43.07 

Round   4, Global train loss: 2.149, Global test loss: 2.039, Global test accuracy: 48.06 

Round   5, Train loss: 1.962, Test loss: 2.058, Test accuracy: 48.75 

Round   5, Global train loss: 1.962, Global test loss: 1.922, Global test accuracy: 56.42 

Round   6, Train loss: 1.892, Test loss: 2.012, Test accuracy: 52.02 

Round   6, Global train loss: 1.892, Global test loss: 1.900, Global test accuracy: 57.02 

Round   7, Train loss: 1.881, Test loss: 2.002, Test accuracy: 52.32 

Round   7, Global train loss: 1.881, Global test loss: 1.892, Global test accuracy: 57.33 

Round   8, Train loss: 1.874, Test loss: 1.963, Test accuracy: 53.69 

Round   8, Global train loss: 1.874, Global test loss: 1.887, Global test accuracy: 57.41 

Round   9, Train loss: 1.851, Test loss: 1.915, Test accuracy: 56.05 

Round   9, Global train loss: 1.851, Global test loss: 1.860, Global test accuracy: 60.17 

Round  10, Train loss: 1.817, Test loss: 1.885, Test accuracy: 59.14 

Round  10, Global train loss: 1.817, Global test loss: 1.804, Global test accuracy: 67.45 

Round  11, Train loss: 1.743, Test loss: 1.843, Test accuracy: 63.74 

Round  11, Global train loss: 1.743, Global test loss: 1.711, Global test accuracy: 78.05 

Round  12, Train loss: 1.668, Test loss: 1.803, Test accuracy: 68.14 

Round  12, Global train loss: 1.668, Global test loss: 1.668, Global test accuracy: 81.39 

Round  13, Train loss: 1.625, Test loss: 1.752, Test accuracy: 73.67 

Round  13, Global train loss: 1.625, Global test loss: 1.628, Global test accuracy: 86.09 

Round  14, Train loss: 1.609, Test loss: 1.715, Test accuracy: 77.32 

Round  14, Global train loss: 1.609, Global test loss: 1.602, Global test accuracy: 87.97 

Round  15, Train loss: 1.577, Test loss: 1.699, Test accuracy: 78.67 

Round  15, Global train loss: 1.577, Global test loss: 1.588, Global test accuracy: 88.62 

Round  16, Train loss: 1.574, Test loss: 1.675, Test accuracy: 80.74 

Round  16, Global train loss: 1.574, Global test loss: 1.579, Global test accuracy: 89.53 

Round  17, Train loss: 1.553, Test loss: 1.668, Test accuracy: 81.26 

Round  17, Global train loss: 1.553, Global test loss: 1.574, Global test accuracy: 89.67 

Round  18, Train loss: 1.546, Test loss: 1.643, Test accuracy: 83.70 

Round  18, Global train loss: 1.546, Global test loss: 1.569, Global test accuracy: 90.14 

Round  19, Train loss: 1.542, Test loss: 1.635, Test accuracy: 84.32 

Round  19, Global train loss: 1.542, Global test loss: 1.564, Global test accuracy: 90.82 

Round  20, Train loss: 1.546, Test loss: 1.629, Test accuracy: 84.74 

Round  20, Global train loss: 1.546, Global test loss: 1.561, Global test accuracy: 90.83 

Round  21, Train loss: 1.544, Test loss: 1.614, Test accuracy: 86.08 

Round  21, Global train loss: 1.544, Global test loss: 1.560, Global test accuracy: 91.02 

Round  22, Train loss: 1.540, Test loss: 1.609, Test accuracy: 86.48 

Round  22, Global train loss: 1.540, Global test loss: 1.557, Global test accuracy: 91.03 

Round  23, Train loss: 1.532, Test loss: 1.569, Test accuracy: 90.03 

Round  23, Global train loss: 1.532, Global test loss: 1.555, Global test accuracy: 91.27 

Round  24, Train loss: 1.524, Test loss: 1.566, Test accuracy: 90.27 

Round  24, Global train loss: 1.524, Global test loss: 1.554, Global test accuracy: 91.52 

Round  25, Train loss: 1.527, Test loss: 1.564, Test accuracy: 90.35 

Round  25, Global train loss: 1.527, Global test loss: 1.552, Global test accuracy: 91.34 

Round  26, Train loss: 1.533, Test loss: 1.563, Test accuracy: 90.49 

Round  26, Global train loss: 1.533, Global test loss: 1.552, Global test accuracy: 91.54 

Round  27, Train loss: 1.525, Test loss: 1.561, Test accuracy: 90.58 

Round  27, Global train loss: 1.525, Global test loss: 1.550, Global test accuracy: 91.51 

Round  28, Train loss: 1.522, Test loss: 1.560, Test accuracy: 90.72 

Round  28, Global train loss: 1.522, Global test loss: 1.549, Global test accuracy: 91.62 

Round  29, Train loss: 1.518, Test loss: 1.559, Test accuracy: 90.83 

Round  29, Global train loss: 1.518, Global test loss: 1.548, Global test accuracy: 91.53 

Round  30, Train loss: 1.517, Test loss: 1.556, Test accuracy: 91.08 

Round  30, Global train loss: 1.517, Global test loss: 1.546, Global test accuracy: 91.78 

Round  31, Train loss: 1.513, Test loss: 1.555, Test accuracy: 91.11 

Round  31, Global train loss: 1.513, Global test loss: 1.546, Global test accuracy: 91.87 

Round  32, Train loss: 1.514, Test loss: 1.553, Test accuracy: 91.12 

Round  32, Global train loss: 1.514, Global test loss: 1.544, Global test accuracy: 92.03 

Round  33, Train loss: 1.515, Test loss: 1.551, Test accuracy: 91.38 

Round  33, Global train loss: 1.515, Global test loss: 1.544, Global test accuracy: 92.13 

Round  34, Train loss: 1.511, Test loss: 1.550, Test accuracy: 91.57 

Round  34, Global train loss: 1.511, Global test loss: 1.542, Global test accuracy: 92.21 

Round  35, Train loss: 1.508, Test loss: 1.548, Test accuracy: 91.70 

Round  35, Global train loss: 1.508, Global test loss: 1.541, Global test accuracy: 92.33 

Round  36, Train loss: 1.512, Test loss: 1.547, Test accuracy: 91.86 

Round  36, Global train loss: 1.512, Global test loss: 1.541, Global test accuracy: 92.38 

Round  37, Train loss: 1.507, Test loss: 1.546, Test accuracy: 91.91 

Round  37, Global train loss: 1.507, Global test loss: 1.540, Global test accuracy: 92.43 

Round  38, Train loss: 1.506, Test loss: 1.546, Test accuracy: 91.83 

Round  38, Global train loss: 1.506, Global test loss: 1.541, Global test accuracy: 92.54 

Round  39, Train loss: 1.506, Test loss: 1.546, Test accuracy: 91.91 

Round  39, Global train loss: 1.506, Global test loss: 1.539, Global test accuracy: 92.51 

Round  40, Train loss: 1.506, Test loss: 1.545, Test accuracy: 91.84 

Round  40, Global train loss: 1.506, Global test loss: 1.538, Global test accuracy: 92.53 

Round  41, Train loss: 1.506, Test loss: 1.545, Test accuracy: 91.87 

Round  41, Global train loss: 1.506, Global test loss: 1.537, Global test accuracy: 92.85 

Round  42, Train loss: 1.503, Test loss: 1.545, Test accuracy: 91.88 

Round  42, Global train loss: 1.503, Global test loss: 1.536, Global test accuracy: 92.95 

Round  43, Train loss: 1.501, Test loss: 1.544, Test accuracy: 92.03 

Round  43, Global train loss: 1.501, Global test loss: 1.536, Global test accuracy: 92.91 

Round  44, Train loss: 1.503, Test loss: 1.544, Test accuracy: 91.99 

Round  44, Global train loss: 1.503, Global test loss: 1.536, Global test accuracy: 92.65 

Round  45, Train loss: 1.497, Test loss: 1.543, Test accuracy: 92.13 

Round  45, Global train loss: 1.497, Global test loss: 1.534, Global test accuracy: 93.08 

Round  46, Train loss: 1.496, Test loss: 1.541, Test accuracy: 92.28 

Round  46, Global train loss: 1.496, Global test loss: 1.535, Global test accuracy: 92.91 

Round  47, Train loss: 1.503, Test loss: 1.540, Test accuracy: 92.51 

Round  47, Global train loss: 1.503, Global test loss: 1.533, Global test accuracy: 93.14 

Round  48, Train loss: 1.496, Test loss: 1.539, Test accuracy: 92.65 

Round  48, Global train loss: 1.496, Global test loss: 1.532, Global test accuracy: 93.33 

Round  49, Train loss: 1.496, Test loss: 1.539, Test accuracy: 92.58 

Round  49, Global train loss: 1.496, Global test loss: 1.532, Global test accuracy: 93.25 

Round  50, Train loss: 1.500, Test loss: 1.538, Test accuracy: 92.65 

Round  50, Global train loss: 1.500, Global test loss: 1.531, Global test accuracy: 93.31 

Round  51, Train loss: 1.499, Test loss: 1.537, Test accuracy: 92.70 

Round  51, Global train loss: 1.499, Global test loss: 1.529, Global test accuracy: 93.46 

Round  52, Train loss: 1.502, Test loss: 1.536, Test accuracy: 92.73 

Round  52, Global train loss: 1.502, Global test loss: 1.530, Global test accuracy: 93.39 

Round  53, Train loss: 1.498, Test loss: 1.536, Test accuracy: 92.78 

Round  53, Global train loss: 1.498, Global test loss: 1.529, Global test accuracy: 93.38 

Round  54, Train loss: 1.493, Test loss: 1.535, Test accuracy: 92.89 

Round  54, Global train loss: 1.493, Global test loss: 1.528, Global test accuracy: 93.66 

Round  55, Train loss: 1.495, Test loss: 1.535, Test accuracy: 92.97 

Round  55, Global train loss: 1.495, Global test loss: 1.529, Global test accuracy: 93.49 

Round  56, Train loss: 1.494, Test loss: 1.534, Test accuracy: 93.06 

Round  56, Global train loss: 1.494, Global test loss: 1.528, Global test accuracy: 93.66 

Round  57, Train loss: 1.494, Test loss: 1.534, Test accuracy: 93.17 

Round  57, Global train loss: 1.494, Global test loss: 1.527, Global test accuracy: 93.80 

Round  58, Train loss: 1.494, Test loss: 1.533, Test accuracy: 93.25 

Round  58, Global train loss: 1.494, Global test loss: 1.526, Global test accuracy: 93.70 

Round  59, Train loss: 1.495, Test loss: 1.533, Test accuracy: 93.21 

Round  59, Global train loss: 1.495, Global test loss: 1.527, Global test accuracy: 93.69 

Round  60, Train loss: 1.494, Test loss: 1.532, Test accuracy: 93.20 

Round  60, Global train loss: 1.494, Global test loss: 1.527, Global test accuracy: 93.69 

Round  61, Train loss: 1.496, Test loss: 1.531, Test accuracy: 93.28 

Round  61, Global train loss: 1.496, Global test loss: 1.527, Global test accuracy: 93.81 

Round  62, Train loss: 1.491, Test loss: 1.532, Test accuracy: 93.18 

Round  62, Global train loss: 1.491, Global test loss: 1.526, Global test accuracy: 93.87 

Round  63, Train loss: 1.493, Test loss: 1.532, Test accuracy: 93.22 

Round  63, Global train loss: 1.493, Global test loss: 1.526, Global test accuracy: 93.69 

Round  64, Train loss: 1.489, Test loss: 1.531, Test accuracy: 93.28 

Round  64, Global train loss: 1.489, Global test loss: 1.527, Global test accuracy: 93.64 

Round  65, Train loss: 1.493, Test loss: 1.531, Test accuracy: 93.31 

Round  65, Global train loss: 1.493, Global test loss: 1.526, Global test accuracy: 93.92 

Round  66, Train loss: 1.492, Test loss: 1.531, Test accuracy: 93.33 

Round  66, Global train loss: 1.492, Global test loss: 1.525, Global test accuracy: 93.95 

Round  67, Train loss: 1.491, Test loss: 1.531, Test accuracy: 93.38 

Round  67, Global train loss: 1.491, Global test loss: 1.526, Global test accuracy: 93.78 

Round  68, Train loss: 1.488, Test loss: 1.530, Test accuracy: 93.47 

Round  68, Global train loss: 1.488, Global test loss: 1.525, Global test accuracy: 93.89 

Round  69, Train loss: 1.490, Test loss: 1.530, Test accuracy: 93.52 

Round  69, Global train loss: 1.490, Global test loss: 1.525, Global test accuracy: 93.79 

Round  70, Train loss: 1.491, Test loss: 1.529, Test accuracy: 93.60 

Round  70, Global train loss: 1.491, Global test loss: 1.524, Global test accuracy: 94.08 

Round  71, Train loss: 1.489, Test loss: 1.529, Test accuracy: 93.62 

Round  71, Global train loss: 1.489, Global test loss: 1.523, Global test accuracy: 94.28 

Round  72, Train loss: 1.484, Test loss: 1.528, Test accuracy: 93.67 

Round  72, Global train loss: 1.484, Global test loss: 1.523, Global test accuracy: 94.20 

Round  73, Train loss: 1.489, Test loss: 1.528, Test accuracy: 93.72 

Round  73, Global train loss: 1.489, Global test loss: 1.523, Global test accuracy: 94.03 

Round  74, Train loss: 1.491, Test loss: 1.528, Test accuracy: 93.71 

Round  74, Global train loss: 1.491, Global test loss: 1.523, Global test accuracy: 94.12 

Round  75, Train loss: 1.489, Test loss: 1.527, Test accuracy: 93.68 

Round  75, Global train loss: 1.489, Global test loss: 1.523, Global test accuracy: 94.00 

Round  76, Train loss: 1.487, Test loss: 1.527, Test accuracy: 93.75 

Round  76, Global train loss: 1.487, Global test loss: 1.522, Global test accuracy: 94.13 

Round  77, Train loss: 1.483, Test loss: 1.526, Test accuracy: 93.83 

Round  77, Global train loss: 1.483, Global test loss: 1.522, Global test accuracy: 94.16 

Round  78, Train loss: 1.485, Test loss: 1.527, Test accuracy: 93.73 

Round  78, Global train loss: 1.485, Global test loss: 1.523, Global test accuracy: 94.17 

Round  79, Train loss: 1.483, Test loss: 1.526, Test accuracy: 93.73 

Round  79, Global train loss: 1.483, Global test loss: 1.522, Global test accuracy: 94.12 

Round  80, Train loss: 1.489, Test loss: 1.526, Test accuracy: 93.72 

Round  80, Global train loss: 1.489, Global test loss: 1.522, Global test accuracy: 94.18 

Round  81, Train loss: 1.484, Test loss: 1.526, Test accuracy: 93.72 

Round  81, Global train loss: 1.484, Global test loss: 1.522, Global test accuracy: 94.22 

Round  82, Train loss: 1.483, Test loss: 1.526, Test accuracy: 93.72 

Round  82, Global train loss: 1.483, Global test loss: 1.521, Global test accuracy: 94.28 

Round  83, Train loss: 1.481, Test loss: 1.526, Test accuracy: 93.73 

Round  83, Global train loss: 1.481, Global test loss: 1.521, Global test accuracy: 94.34 

Round  84, Train loss: 1.484, Test loss: 1.526, Test accuracy: 93.74 

Round  84, Global train loss: 1.484, Global test loss: 1.521, Global test accuracy: 94.22 

Round  85, Train loss: 1.489, Test loss: 1.525, Test accuracy: 93.74 

Round  85, Global train loss: 1.489, Global test loss: 1.521, Global test accuracy: 94.32 

Round  86, Train loss: 1.484, Test loss: 1.525, Test accuracy: 93.75 

Round  86, Global train loss: 1.484, Global test loss: 1.521, Global test accuracy: 94.27 

Round  87, Train loss: 1.482, Test loss: 1.525, Test accuracy: 93.77 

Round  87, Global train loss: 1.482, Global test loss: 1.521, Global test accuracy: 94.21 

Round  88, Train loss: 1.482, Test loss: 1.525, Test accuracy: 93.73 

Round  88, Global train loss: 1.482, Global test loss: 1.520, Global test accuracy: 94.35 

Round  89, Train loss: 1.482, Test loss: 1.525, Test accuracy: 93.76 

Round  89, Global train loss: 1.482, Global test loss: 1.521, Global test accuracy: 94.27 

Round  90, Train loss: 1.483, Test loss: 1.525, Test accuracy: 93.77 

Round  90, Global train loss: 1.483, Global test loss: 1.520, Global test accuracy: 94.45 

Round  91, Train loss: 1.483, Test loss: 1.524, Test accuracy: 93.84 

Round  91, Global train loss: 1.483, Global test loss: 1.520, Global test accuracy: 94.51 

Round  92, Train loss: 1.487, Test loss: 1.524, Test accuracy: 93.90 

Round  92, Global train loss: 1.487, Global test loss: 1.520, Global test accuracy: 94.38 

Round  93, Train loss: 1.483, Test loss: 1.524, Test accuracy: 93.92 

Round  93, Global train loss: 1.483, Global test loss: 1.521, Global test accuracy: 94.34 
/home/ChenSM/code/FL_HLS/utils/sampling.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Train loss: 1.480, Test loss: 1.523, Test accuracy: 93.97 

Round  94, Global train loss: 1.480, Global test loss: 1.520, Global test accuracy: 94.42 

Round  95, Train loss: 1.485, Test loss: 1.523, Test accuracy: 93.97 

Round  95, Global train loss: 1.485, Global test loss: 1.521, Global test accuracy: 94.30 

Round  96, Train loss: 1.480, Test loss: 1.523, Test accuracy: 93.94 

Round  96, Global train loss: 1.480, Global test loss: 1.519, Global test accuracy: 94.58 

Round  97, Train loss: 1.484, Test loss: 1.523, Test accuracy: 93.96 

Round  97, Global train loss: 1.484, Global test loss: 1.520, Global test accuracy: 94.40 

Round  98, Train loss: 1.490, Test loss: 1.524, Test accuracy: 93.88 

Round  98, Global train loss: 1.490, Global test loss: 1.520, Global test accuracy: 94.42 

Round  99, Train loss: 1.482, Test loss: 1.524, Test accuracy: 93.92 

Round  99, Global train loss: 1.482, Global test loss: 1.519, Global test accuracy: 94.66 

Final Round, Train loss: 1.482, Test loss: 1.523, Test accuracy: 94.08 

Final Round, Global train loss: 1.482, Global test loss: 1.519, Global test accuracy: 94.66 

Average accuracy final 10 rounds: 93.90666666666667 

Average global accuracy final 10 rounds: 94.445 

902.440863609314
[0.8706974983215332, 1.6337158679962158, 2.3895342350006104, 3.1409213542938232, 3.898002862930298, 4.653726816177368, 5.4068522453308105, 6.155097246170044, 6.800069093704224, 7.450962781906128, 8.09106731414795, 8.736228227615356, 9.383744716644287, 10.01888370513916, 10.664761066436768, 11.312366485595703, 11.948491334915161, 12.59598708152771, 13.242346286773682, 13.886168241500854, 14.534566640853882, 15.184273481369019, 15.824649333953857, 16.470887899398804, 17.124910354614258, 17.762377500534058, 18.414175033569336, 19.068559169769287, 19.70612120628357, 20.358710289001465, 21.010528087615967, 21.648688077926636, 22.302201509475708, 22.952276706695557, 23.597309112548828, 24.250380992889404, 24.903517484664917, 25.549514293670654, 26.20813822746277, 26.858492374420166, 27.50499653816223, 28.152613878250122, 28.807862997055054, 29.450304746627808, 30.093129634857178, 30.743393182754517, 31.396703720092773, 32.03622913360596, 32.691269397735596, 33.34561562538147, 33.98407459259033, 34.63578128814697, 35.28372931480408, 35.92406439781189, 36.57233762741089, 37.22589564323425, 37.86478304862976, 38.515586614608765, 39.16550254821777, 39.81177520751953, 40.45845818519592, 41.1038293838501, 41.74457049369812, 42.387794733047485, 43.0533971786499, 43.698869466781616, 44.33725166320801, 44.99091935157776, 45.64238905906677, 46.279078006744385, 46.93131375312805, 47.58245015144348, 48.23124885559082, 48.88110280036926, 49.536768436431885, 50.182437896728516, 50.828099727630615, 51.474461793899536, 52.11971831321716, 52.76824641227722, 53.41747188568115, 54.069409132003784, 54.71498417854309, 55.36205291748047, 56.019296407699585, 56.666020154953, 57.31776285171509, 57.97271251678467, 58.61862063407898, 59.26128530502319, 59.91285014152527, 60.56709384918213, 61.20573902130127, 61.85770225524902, 62.501851081848145, 63.14770174026489, 63.797605991363525, 64.44561624526978, 65.10168695449829, 65.75303959846497, 67.05821442604065]
[17.133333333333333, 27.566666666666666, 37.55, 38.083333333333336, 43.06666666666667, 48.75, 52.016666666666666, 52.31666666666667, 53.69166666666667, 56.05, 59.141666666666666, 63.74166666666667, 68.14166666666667, 73.66666666666667, 77.31666666666666, 78.66666666666667, 80.74166666666666, 81.25833333333334, 83.7, 84.31666666666666, 84.74166666666666, 86.075, 86.48333333333333, 90.03333333333333, 90.26666666666667, 90.35, 90.49166666666666, 90.575, 90.725, 90.825, 91.075, 91.10833333333333, 91.11666666666666, 91.38333333333334, 91.56666666666666, 91.7, 91.85833333333333, 91.90833333333333, 91.825, 91.90833333333333, 91.84166666666667, 91.86666666666666, 91.875, 92.025, 91.99166666666666, 92.13333333333334, 92.275, 92.50833333333334, 92.65, 92.575, 92.65, 92.7, 92.73333333333333, 92.78333333333333, 92.89166666666667, 92.975, 93.05833333333334, 93.16666666666667, 93.25, 93.20833333333333, 93.2, 93.28333333333333, 93.18333333333334, 93.21666666666667, 93.28333333333333, 93.30833333333334, 93.325, 93.375, 93.46666666666667, 93.51666666666667, 93.6, 93.61666666666666, 93.66666666666667, 93.71666666666667, 93.70833333333333, 93.68333333333334, 93.75, 93.83333333333333, 93.73333333333333, 93.73333333333333, 93.71666666666667, 93.725, 93.71666666666667, 93.73333333333333, 93.74166666666666, 93.74166666666666, 93.75, 93.76666666666667, 93.73333333333333, 93.75833333333334, 93.76666666666667, 93.84166666666667, 93.9, 93.91666666666667, 93.975, 93.96666666666667, 93.94166666666666, 93.95833333333333, 93.88333333333334, 93.91666666666667, 94.08333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.302, Test loss: 2.300, Test accuracy: 16.64 

Round   1, Train loss: 2.300, Test loss: 2.299, Test accuracy: 26.22 

Round   2, Train loss: 2.298, Test loss: 2.296, Test accuracy: 35.90 

Round   3, Train loss: 2.295, Test loss: 2.293, Test accuracy: 40.47 

Round   4, Train loss: 2.291, Test loss: 2.287, Test accuracy: 45.62 

Round   5, Train loss: 2.284, Test loss: 2.278, Test accuracy: 45.69 

Round   6, Train loss: 2.274, Test loss: 2.261, Test accuracy: 44.92 

Round   7, Train loss: 2.239, Test loss: 2.204, Test accuracy: 40.42 

Round   8, Train loss: 2.155, Test loss: 2.099, Test accuracy: 46.72 

Round   9, Train loss: 2.039, Test loss: 1.998, Test accuracy: 59.47 

Round  10, Train loss: 1.924, Test loss: 1.914, Test accuracy: 62.33 

Round  11, Train loss: 1.863, Test loss: 1.854, Test accuracy: 66.15 

Round  12, Train loss: 1.804, Test loss: 1.811, Test accuracy: 69.13 

Round  13, Train loss: 1.751, Test loss: 1.767, Test accuracy: 73.18 

Round  14, Train loss: 1.729, Test loss: 1.736, Test accuracy: 75.72 

Round  15, Train loss: 1.689, Test loss: 1.712, Test accuracy: 77.74 

Round  16, Train loss: 1.685, Test loss: 1.690, Test accuracy: 79.79 

Round  17, Train loss: 1.665, Test loss: 1.682, Test accuracy: 80.21 

Round  18, Train loss: 1.656, Test loss: 1.672, Test accuracy: 80.90 

Round  19, Train loss: 1.644, Test loss: 1.668, Test accuracy: 81.19 

Round  20, Train loss: 1.652, Test loss: 1.665, Test accuracy: 81.28 

Round  21, Train loss: 1.654, Test loss: 1.656, Test accuracy: 82.15 

Round  22, Train loss: 1.645, Test loss: 1.652, Test accuracy: 82.37 

Round  23, Train loss: 1.640, Test loss: 1.650, Test accuracy: 82.49 

Round  24, Train loss: 1.636, Test loss: 1.644, Test accuracy: 83.06 

Round  25, Train loss: 1.623, Test loss: 1.642, Test accuracy: 83.01 

Round  26, Train loss: 1.632, Test loss: 1.639, Test accuracy: 83.35 

Round  27, Train loss: 1.616, Test loss: 1.636, Test accuracy: 83.88 

Round  28, Train loss: 1.605, Test loss: 1.628, Test accuracy: 84.62 

Round  29, Train loss: 1.595, Test loss: 1.621, Test accuracy: 85.42 

Round  30, Train loss: 1.592, Test loss: 1.616, Test accuracy: 85.99 

Round  31, Train loss: 1.578, Test loss: 1.613, Test accuracy: 86.26 

Round  32, Train loss: 1.576, Test loss: 1.611, Test accuracy: 86.25 

Round  33, Train loss: 1.566, Test loss: 1.599, Test accuracy: 87.64 

Round  34, Train loss: 1.564, Test loss: 1.590, Test accuracy: 88.57 

Round  35, Train loss: 1.563, Test loss: 1.587, Test accuracy: 88.66 

Round  36, Train loss: 1.553, Test loss: 1.581, Test accuracy: 89.17 

Round  37, Train loss: 1.548, Test loss: 1.580, Test accuracy: 89.28 

Round  38, Train loss: 1.554, Test loss: 1.579, Test accuracy: 89.31 

Round  39, Train loss: 1.544, Test loss: 1.581, Test accuracy: 88.99 

Round  40, Train loss: 1.537, Test loss: 1.578, Test accuracy: 89.24 

Round  41, Train loss: 1.533, Test loss: 1.577, Test accuracy: 89.31 

Round  42, Train loss: 1.532, Test loss: 1.574, Test accuracy: 89.63 

Round  43, Train loss: 1.541, Test loss: 1.573, Test accuracy: 89.58 

Round  44, Train loss: 1.538, Test loss: 1.575, Test accuracy: 89.50 

Round  45, Train loss: 1.533, Test loss: 1.574, Test accuracy: 89.47 

Round  46, Train loss: 1.532, Test loss: 1.573, Test accuracy: 89.62 

Round  47, Train loss: 1.525, Test loss: 1.570, Test accuracy: 89.88 

Round  48, Train loss: 1.525, Test loss: 1.568, Test accuracy: 90.01 

Round  49, Train loss: 1.531, Test loss: 1.568, Test accuracy: 89.94 

Round  50, Train loss: 1.528, Test loss: 1.568, Test accuracy: 89.93 

Round  51, Train loss: 1.523, Test loss: 1.566, Test accuracy: 90.12 

Round  52, Train loss: 1.527, Test loss: 1.565, Test accuracy: 90.18 

Round  53, Train loss: 1.522, Test loss: 1.565, Test accuracy: 90.33 

Round  54, Train loss: 1.523, Test loss: 1.563, Test accuracy: 90.44 

Round  55, Train loss: 1.516, Test loss: 1.562, Test accuracy: 90.50 

Round  56, Train loss: 1.520, Test loss: 1.563, Test accuracy: 90.42 

Round  57, Train loss: 1.519, Test loss: 1.562, Test accuracy: 90.49 

Round  58, Train loss: 1.517, Test loss: 1.562, Test accuracy: 90.46 

Round  59, Train loss: 1.518, Test loss: 1.561, Test accuracy: 90.49 

Round  60, Train loss: 1.517, Test loss: 1.561, Test accuracy: 90.46 

Round  61, Train loss: 1.513, Test loss: 1.560, Test accuracy: 90.62 

Round  62, Train loss: 1.512, Test loss: 1.561, Test accuracy: 90.47 

Round  63, Train loss: 1.505, Test loss: 1.559, Test accuracy: 90.65 

Round  64, Train loss: 1.514, Test loss: 1.559, Test accuracy: 90.59 

Round  65, Train loss: 1.512, Test loss: 1.559, Test accuracy: 90.56 

Round  66, Train loss: 1.509, Test loss: 1.558, Test accuracy: 90.67 

Round  67, Train loss: 1.512, Test loss: 1.558, Test accuracy: 90.69 

Round  68, Train loss: 1.503, Test loss: 1.557, Test accuracy: 90.82 

Round  69, Train loss: 1.507, Test loss: 1.557, Test accuracy: 90.75 

Round  70, Train loss: 1.512, Test loss: 1.558, Test accuracy: 90.68 

Round  71, Train loss: 1.508, Test loss: 1.557, Test accuracy: 90.67 

Round  72, Train loss: 1.510, Test loss: 1.557, Test accuracy: 90.61 

Round  73, Train loss: 1.510, Test loss: 1.557, Test accuracy: 90.72 

Round  74, Train loss: 1.506, Test loss: 1.556, Test accuracy: 90.84 

Round  75, Train loss: 1.506, Test loss: 1.555, Test accuracy: 90.88 

Round  76, Train loss: 1.509, Test loss: 1.556, Test accuracy: 90.86 

Round  77, Train loss: 1.507, Test loss: 1.556, Test accuracy: 90.91 

Round  78, Train loss: 1.508, Test loss: 1.556, Test accuracy: 90.83 

Round  79, Train loss: 1.505, Test loss: 1.555, Test accuracy: 90.92 

Round  80, Train loss: 1.507, Test loss: 1.556, Test accuracy: 90.65 

Round  81, Train loss: 1.500, Test loss: 1.556, Test accuracy: 90.79 

Round  82, Train loss: 1.505, Test loss: 1.556, Test accuracy: 90.75 

Round  83, Train loss: 1.502, Test loss: 1.556, Test accuracy: 90.90 

Round  84, Train loss: 1.508, Test loss: 1.555, Test accuracy: 90.87 

Round  85, Train loss: 1.504, Test loss: 1.554, Test accuracy: 90.96 

Round  86, Train loss: 1.500, Test loss: 1.554, Test accuracy: 90.88 

Round  87, Train loss: 1.503, Test loss: 1.554, Test accuracy: 91.07 

Round  88, Train loss: 1.506, Test loss: 1.554, Test accuracy: 90.97 

Round  89, Train loss: 1.503, Test loss: 1.555, Test accuracy: 90.92 

Round  90, Train loss: 1.502, Test loss: 1.555, Test accuracy: 90.89 

Round  91, Train loss: 1.502, Test loss: 1.555, Test accuracy: 90.92 

Round  92, Train loss: 1.497, Test loss: 1.554, Test accuracy: 91.04 

Round  93, Train loss: 1.502, Test loss: 1.553, Test accuracy: 90.97 

Round  94, Train loss: 1.500, Test loss: 1.553, Test accuracy: 91.08 

Round  95, Train loss: 1.500, Test loss: 1.553, Test accuracy: 91.16 

Round  96, Train loss: 1.498, Test loss: 1.553, Test accuracy: 90.96 
/home/ChenSM/code/FL_HLS/utils/sampling.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  97, Train loss: 1.500, Test loss: 1.553, Test accuracy: 90.95 

Round  98, Train loss: 1.502, Test loss: 1.553, Test accuracy: 91.03 

Round  99, Train loss: 1.500, Test loss: 1.553, Test accuracy: 91.08 

Final Round, Train loss: 1.500, Test loss: 1.554, Test accuracy: 90.91 

Average accuracy final 10 rounds: 91.00666666666667 

671.8655269145966
[0.8284201622009277, 1.5808742046356201, 2.2562928199768066, 2.9397847652435303, 3.6191065311431885, 4.302206039428711, 4.987476348876953, 5.671797752380371, 6.351391315460205, 7.03665566444397, 7.717416763305664, 8.39799427986145, 9.077645301818848, 9.759738206863403, 10.44271731376648, 11.12128758430481, 11.803993463516235, 12.48388934135437, 13.165602445602417, 13.846582412719727, 14.524216413497925, 15.206094741821289, 15.884248495101929, 16.567954301834106, 17.24797010421753, 17.92730212211609, 18.606048107147217, 19.285614728927612, 19.967992544174194, 20.647236108779907, 21.333252906799316, 22.010868549346924, 22.69489288330078, 23.36824917793274, 24.050581455230713, 24.727408170700073, 25.40682101249695, 26.086579084396362, 26.765724182128906, 27.444292783737183, 28.120254278182983, 28.803292989730835, 29.476354360580444, 30.162471771240234, 30.84123706817627, 31.52344560623169, 32.20387816429138, 32.89117169380188, 33.57138419151306, 34.24808740615845, 34.93130302429199, 35.602009534835815, 36.28995728492737, 36.965280532836914, 37.65488910675049, 38.33257532119751, 39.01177763938904, 39.6927330493927, 40.37038969993591, 41.054131269454956, 41.73199510574341, 42.42032861709595, 43.09664511680603, 43.774433612823486, 44.45280051231384, 45.1314058303833, 45.81408381462097, 46.502036333084106, 47.18502712249756, 47.86600708961487, 48.551276206970215, 49.22857451438904, 49.90937685966492, 50.586830377578735, 51.27281308174133, 51.95215702056885, 52.638993978500366, 53.321682929992676, 54.00330424308777, 54.68397092819214, 55.36530613899231, 56.0462327003479, 56.72940945625305, 57.40892052650452, 58.09569525718689, 58.78016400337219, 59.458574295043945, 60.13758063316345, 60.804977893829346, 61.4850697517395, 62.156519651412964, 62.82826900482178, 63.500186920166016, 64.17297697067261, 64.8459644317627, 65.51599311828613, 66.19143486022949, 66.86851000785828, 67.5429892539978, 68.22444200515747, 69.43384718894958]
[16.641666666666666, 26.216666666666665, 35.9, 40.46666666666667, 45.61666666666667, 45.69166666666667, 44.916666666666664, 40.425, 46.71666666666667, 59.46666666666667, 62.333333333333336, 66.15, 69.13333333333334, 73.18333333333334, 75.725, 77.74166666666666, 79.79166666666667, 80.20833333333333, 80.9, 81.19166666666666, 81.275, 82.15, 82.36666666666666, 82.49166666666666, 83.05833333333334, 83.00833333333334, 83.35, 83.875, 84.61666666666666, 85.41666666666667, 85.99166666666666, 86.25833333333334, 86.25, 87.64166666666667, 88.56666666666666, 88.65833333333333, 89.175, 89.275, 89.30833333333334, 88.99166666666666, 89.24166666666666, 89.30833333333334, 89.63333333333334, 89.58333333333333, 89.5, 89.46666666666667, 89.625, 89.875, 90.00833333333334, 89.94166666666666, 89.93333333333334, 90.11666666666666, 90.18333333333334, 90.325, 90.44166666666666, 90.5, 90.41666666666667, 90.49166666666666, 90.45833333333333, 90.49166666666666, 90.45833333333333, 90.625, 90.475, 90.65, 90.59166666666667, 90.55833333333334, 90.675, 90.69166666666666, 90.81666666666666, 90.75, 90.68333333333334, 90.66666666666667, 90.60833333333333, 90.725, 90.84166666666667, 90.875, 90.85833333333333, 90.90833333333333, 90.83333333333333, 90.91666666666667, 90.65, 90.79166666666667, 90.75, 90.9, 90.86666666666666, 90.95833333333333, 90.88333333333334, 91.06666666666666, 90.975, 90.925, 90.89166666666667, 90.91666666666667, 91.04166666666667, 90.975, 91.075, 91.15833333333333, 90.95833333333333, 90.95, 91.025, 91.075, 90.90833333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedper
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.300, Test loss: 2.299, Test accuracy: 12.93 

Round   1, Train loss: 2.295, Test loss: 2.292, Test accuracy: 29.68 

Round   2, Train loss: 2.282, Test loss: 2.271, Test accuracy: 30.24 

Round   3, Train loss: 2.221, Test loss: 2.180, Test accuracy: 41.55 

Round   4, Train loss: 2.081, Test loss: 2.054, Test accuracy: 45.21 

Round   5, Train loss: 1.983, Test loss: 1.970, Test accuracy: 51.17 

Round   6, Train loss: 1.880, Test loss: 1.892, Test accuracy: 58.70 

Round   7, Train loss: 1.779, Test loss: 1.820, Test accuracy: 66.76 

Round   8, Train loss: 1.725, Test loss: 1.762, Test accuracy: 72.41 

Round   9, Train loss: 1.686, Test loss: 1.723, Test accuracy: 75.53 

Round  10, Train loss: 1.672, Test loss: 1.682, Test accuracy: 79.67 

Round  11, Train loss: 1.647, Test loss: 1.663, Test accuracy: 81.44 

Round  12, Train loss: 1.645, Test loss: 1.649, Test accuracy: 82.56 

Round  13, Train loss: 1.626, Test loss: 1.643, Test accuracy: 82.97 

Round  14, Train loss: 1.625, Test loss: 1.638, Test accuracy: 83.39 

Round  15, Train loss: 1.616, Test loss: 1.636, Test accuracy: 83.52 

Round  16, Train loss: 1.625, Test loss: 1.630, Test accuracy: 83.97 

Round  17, Train loss: 1.620, Test loss: 1.628, Test accuracy: 84.05 

Round  18, Train loss: 1.607, Test loss: 1.626, Test accuracy: 84.12 

Round  19, Train loss: 1.610, Test loss: 1.625, Test accuracy: 84.23 

Round  20, Train loss: 1.602, Test loss: 1.624, Test accuracy: 84.44 

Round  21, Train loss: 1.603, Test loss: 1.622, Test accuracy: 84.46 

Round  22, Train loss: 1.608, Test loss: 1.621, Test accuracy: 84.56 

Round  23, Train loss: 1.606, Test loss: 1.620, Test accuracy: 84.51 

Round  24, Train loss: 1.592, Test loss: 1.619, Test accuracy: 84.54 

Round  25, Train loss: 1.597, Test loss: 1.617, Test accuracy: 84.77 

Round  26, Train loss: 1.590, Test loss: 1.617, Test accuracy: 84.84 

Round  27, Train loss: 1.603, Test loss: 1.617, Test accuracy: 84.91 

Round  28, Train loss: 1.599, Test loss: 1.616, Test accuracy: 84.89 

Round  29, Train loss: 1.594, Test loss: 1.616, Test accuracy: 84.89 

Round  30, Train loss: 1.586, Test loss: 1.616, Test accuracy: 84.95 

Round  31, Train loss: 1.589, Test loss: 1.615, Test accuracy: 84.95 

Round  32, Train loss: 1.594, Test loss: 1.615, Test accuracy: 85.00 

Round  33, Train loss: 1.591, Test loss: 1.615, Test accuracy: 84.91 

Round  34, Train loss: 1.600, Test loss: 1.615, Test accuracy: 84.96 

Round  35, Train loss: 1.585, Test loss: 1.615, Test accuracy: 84.96 

Round  36, Train loss: 1.589, Test loss: 1.614, Test accuracy: 85.02 

Round  37, Train loss: 1.589, Test loss: 1.614, Test accuracy: 85.00 

Round  38, Train loss: 1.589, Test loss: 1.614, Test accuracy: 85.10 

Round  39, Train loss: 1.592, Test loss: 1.612, Test accuracy: 85.14 

Round  40, Train loss: 1.587, Test loss: 1.613, Test accuracy: 85.12 

Round  41, Train loss: 1.586, Test loss: 1.613, Test accuracy: 85.13 

Round  42, Train loss: 1.584, Test loss: 1.612, Test accuracy: 85.14 

Round  43, Train loss: 1.583, Test loss: 1.612, Test accuracy: 85.17 

Round  44, Train loss: 1.585, Test loss: 1.612, Test accuracy: 85.19 

Round  45, Train loss: 1.582, Test loss: 1.612, Test accuracy: 85.25 

Round  46, Train loss: 1.580, Test loss: 1.612, Test accuracy: 85.19 

Round  47, Train loss: 1.580, Test loss: 1.611, Test accuracy: 85.29 

Round  48, Train loss: 1.590, Test loss: 1.611, Test accuracy: 85.30 

Round  49, Train loss: 1.578, Test loss: 1.611, Test accuracy: 85.28 

Round  50, Train loss: 1.589, Test loss: 1.611, Test accuracy: 85.33 

Round  51, Train loss: 1.584, Test loss: 1.611, Test accuracy: 85.22 

Round  52, Train loss: 1.580, Test loss: 1.611, Test accuracy: 85.28 

Round  53, Train loss: 1.586, Test loss: 1.610, Test accuracy: 85.33 

Round  54, Train loss: 1.589, Test loss: 1.610, Test accuracy: 85.30 

Round  55, Train loss: 1.578, Test loss: 1.610, Test accuracy: 85.31 

Round  56, Train loss: 1.584, Test loss: 1.610, Test accuracy: 85.37 

Round  57, Train loss: 1.578, Test loss: 1.610, Test accuracy: 85.42 

Round  58, Train loss: 1.574, Test loss: 1.609, Test accuracy: 85.38 

Round  59, Train loss: 1.574, Test loss: 1.609, Test accuracy: 85.35 

Round  60, Train loss: 1.575, Test loss: 1.609, Test accuracy: 85.37 

Round  61, Train loss: 1.578, Test loss: 1.609, Test accuracy: 85.42 

Round  62, Train loss: 1.574, Test loss: 1.609, Test accuracy: 85.42 

Round  63, Train loss: 1.573, Test loss: 1.609, Test accuracy: 85.45 

Round  64, Train loss: 1.574, Test loss: 1.609, Test accuracy: 85.41 

Round  65, Train loss: 1.590, Test loss: 1.609, Test accuracy: 85.31 

Round  66, Train loss: 1.574, Test loss: 1.609, Test accuracy: 85.37 

Round  67, Train loss: 1.584, Test loss: 1.609, Test accuracy: 85.37 

Round  68, Train loss: 1.583, Test loss: 1.609, Test accuracy: 85.35 

Round  69, Train loss: 1.574, Test loss: 1.609, Test accuracy: 85.45 

Round  70, Train loss: 1.582, Test loss: 1.608, Test accuracy: 85.46 

Round  71, Train loss: 1.580, Test loss: 1.608, Test accuracy: 85.53 

Round  72, Train loss: 1.580, Test loss: 1.607, Test accuracy: 85.57 

Round  73, Train loss: 1.573, Test loss: 1.607, Test accuracy: 85.62 

Round  74, Train loss: 1.563, Test loss: 1.606, Test accuracy: 85.73 

Round  75, Train loss: 1.569, Test loss: 1.606, Test accuracy: 85.83 

Round  76, Train loss: 1.567, Test loss: 1.606, Test accuracy: 85.78 

Round  77, Train loss: 1.563, Test loss: 1.604, Test accuracy: 85.88 

Round  78, Train loss: 1.574, Test loss: 1.604, Test accuracy: 85.95 

Round  79, Train loss: 1.562, Test loss: 1.603, Test accuracy: 86.01 

Round  80, Train loss: 1.568, Test loss: 1.603, Test accuracy: 85.96 

Round  81, Train loss: 1.551, Test loss: 1.601, Test accuracy: 86.13 

Round  82, Train loss: 1.571, Test loss: 1.602, Test accuracy: 86.20 

Round  83, Train loss: 1.562, Test loss: 1.602, Test accuracy: 86.15 

Round  84, Train loss: 1.569, Test loss: 1.601, Test accuracy: 86.21 

Round  85, Train loss: 1.577, Test loss: 1.602, Test accuracy: 86.15 

Round  86, Train loss: 1.553, Test loss: 1.601, Test accuracy: 86.19 

Round  87, Train loss: 1.569, Test loss: 1.601, Test accuracy: 86.16 

Round  88, Train loss: 1.538, Test loss: 1.600, Test accuracy: 86.25 

Round  89, Train loss: 1.555, Test loss: 1.600, Test accuracy: 86.19 

Round  90, Train loss: 1.549, Test loss: 1.600, Test accuracy: 86.28 

Round  91, Train loss: 1.573, Test loss: 1.600, Test accuracy: 86.28 

Round  92, Train loss: 1.558, Test loss: 1.599, Test accuracy: 86.35 

Round  93, Train loss: 1.555, Test loss: 1.599, Test accuracy: 86.38 

Round  94, Train loss: 1.565, Test loss: 1.599, Test accuracy: 86.37 

Round  95, Train loss: 1.568, Test loss: 1.598, Test accuracy: 86.49 

Round  96, Train loss: 1.551, Test loss: 1.598, Test accuracy: 86.46 
/home/ChenSM/code/FL_HLS/utils/sampling.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  97, Train loss: 1.551, Test loss: 1.598, Test accuracy: 86.51 

Round  98, Train loss: 1.553, Test loss: 1.597, Test accuracy: 86.54 

Round  99, Train loss: 1.559, Test loss: 1.596, Test accuracy: 86.72 

Final Round, Train loss: 1.552, Test loss: 1.592, Test accuracy: 87.15 

Average accuracy final 10 rounds: 86.43750000000001 

688.5101847648621
[0.8061695098876953, 1.5195808410644531, 2.2590489387512207, 3.009612560272217, 3.758556842803955, 4.506368398666382, 5.251147031784058, 6.00141167640686, 6.74948787689209, 7.499538421630859, 8.248693704605103, 8.991097211837769, 9.741246938705444, 10.483635187149048, 11.228221416473389, 11.971707344055176, 12.715337991714478, 13.461381435394287, 14.201412200927734, 14.94640588760376, 15.716569423675537, 16.526384115219116, 17.18184781074524, 17.83115315437317, 18.49340057373047, 19.14484453201294, 19.78812289237976, 20.444938898086548, 21.09439182281494, 21.749844074249268, 22.403055429458618, 23.056220054626465, 23.711101531982422, 24.371881246566772, 25.03167414665222, 25.686737775802612, 26.34176254272461, 27.00040888786316, 27.655211448669434, 28.307394981384277, 28.969502687454224, 29.63071846961975, 30.280019521713257, 30.93987536430359, 31.60033631324768, 32.25731325149536, 32.91072702407837, 33.56332778930664, 34.21190571784973, 34.86906433105469, 35.526167154312134, 36.17361283302307, 36.83070707321167, 37.48408317565918, 38.13920068740845, 38.78706765174866, 39.44002294540405, 40.090794801712036, 40.737573862075806, 41.39773869514465, 42.047592878341675, 42.68906903266907, 43.343236684799194, 43.99772810935974, 44.64776825904846, 45.40807247161865, 46.16866397857666, 46.92659902572632, 47.68542194366455, 48.447818994522095, 49.200361490249634, 49.95525407791138, 50.71217894554138, 51.466997146606445, 52.22749471664429, 52.989712953567505, 53.746742725372314, 54.50406622886658, 55.26313614845276, 56.01879167556763, 56.77999997138977, 57.54423379898071, 58.303027391433716, 59.060178995132446, 59.81424045562744, 60.57519316673279, 61.33608269691467, 62.09181475639343, 62.84661650657654, 63.598387241363525, 64.35198593139648, 65.10608720779419, 65.8605408668518, 66.61901235580444, 67.37372255325317, 68.02795481681824, 68.67596888542175, 69.33012700080872, 69.98802280426025, 70.6348078250885, 71.78760814666748]
[12.933333333333334, 29.675, 30.241666666666667, 41.55, 45.208333333333336, 51.175, 58.7, 66.75833333333334, 72.40833333333333, 75.53333333333333, 79.675, 81.44166666666666, 82.55833333333334, 82.96666666666667, 83.39166666666667, 83.51666666666667, 83.96666666666667, 84.05, 84.125, 84.23333333333333, 84.44166666666666, 84.45833333333333, 84.55833333333334, 84.50833333333334, 84.54166666666667, 84.76666666666667, 84.84166666666667, 84.90833333333333, 84.89166666666667, 84.89166666666667, 84.95, 84.95, 85.0, 84.90833333333333, 84.95833333333333, 84.95833333333333, 85.01666666666667, 85.0, 85.1, 85.14166666666667, 85.125, 85.13333333333334, 85.14166666666667, 85.16666666666667, 85.19166666666666, 85.25, 85.19166666666666, 85.29166666666667, 85.3, 85.28333333333333, 85.33333333333333, 85.225, 85.28333333333333, 85.325, 85.3, 85.30833333333334, 85.36666666666666, 85.41666666666667, 85.38333333333334, 85.35, 85.36666666666666, 85.425, 85.41666666666667, 85.45, 85.40833333333333, 85.30833333333334, 85.36666666666666, 85.36666666666666, 85.35, 85.45, 85.45833333333333, 85.525, 85.56666666666666, 85.61666666666666, 85.73333333333333, 85.825, 85.78333333333333, 85.875, 85.95, 86.00833333333334, 85.95833333333333, 86.13333333333334, 86.2, 86.15, 86.20833333333333, 86.15, 86.19166666666666, 86.15833333333333, 86.25, 86.19166666666666, 86.275, 86.28333333333333, 86.35, 86.38333333333334, 86.36666666666666, 86.49166666666666, 86.45833333333333, 86.50833333333334, 86.54166666666667, 86.71666666666667, 87.15]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

lg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 17098 (global); Percentage 3.11 (17098/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.300, Test loss: 2.299, Test accuracy: 9.81 

Round   1, Train loss: 2.295, Test loss: 2.293, Test accuracy: 20.72 

Round   2, Train loss: 2.279, Test loss: 2.271, Test accuracy: 21.09 

Round   3, Train loss: 2.249, Test loss: 2.234, Test accuracy: 26.47 

Round   4, Train loss: 2.174, Test loss: 2.166, Test accuracy: 38.14 

Round   5, Train loss: 2.081, Test loss: 2.072, Test accuracy: 47.25 

Round   6, Train loss: 1.969, Test loss: 1.981, Test accuracy: 55.27 

Round   7, Train loss: 1.841, Test loss: 1.912, Test accuracy: 65.04 

Round   8, Train loss: 1.786, Test loss: 1.841, Test accuracy: 69.37 

Round   9, Train loss: 1.745, Test loss: 1.787, Test accuracy: 72.62 

Round  10, Train loss: 1.663, Test loss: 1.773, Test accuracy: 73.08 

Round  11, Train loss: 1.686, Test loss: 1.741, Test accuracy: 75.03 

Round  12, Train loss: 1.656, Test loss: 1.722, Test accuracy: 76.47 

Round  13, Train loss: 1.624, Test loss: 1.714, Test accuracy: 76.95 

Round  14, Train loss: 1.609, Test loss: 1.708, Test accuracy: 77.22 

Round  15, Train loss: 1.629, Test loss: 1.703, Test accuracy: 77.45 

Round  16, Train loss: 1.608, Test loss: 1.699, Test accuracy: 77.69 

Round  17, Train loss: 1.606, Test loss: 1.697, Test accuracy: 77.88 

Round  18, Train loss: 1.595, Test loss: 1.695, Test accuracy: 77.83 

Round  19, Train loss: 1.586, Test loss: 1.693, Test accuracy: 78.00 

Round  20, Train loss: 1.604, Test loss: 1.688, Test accuracy: 78.45 

Round  21, Train loss: 1.577, Test loss: 1.687, Test accuracy: 78.49 

Round  22, Train loss: 1.585, Test loss: 1.686, Test accuracy: 78.47 

Round  23, Train loss: 1.582, Test loss: 1.686, Test accuracy: 78.48 

Round  24, Train loss: 1.593, Test loss: 1.685, Test accuracy: 78.53 

Round  25, Train loss: 1.580, Test loss: 1.685, Test accuracy: 78.46 

Round  26, Train loss: 1.577, Test loss: 1.685, Test accuracy: 78.36 

Round  27, Train loss: 1.575, Test loss: 1.685, Test accuracy: 78.39 

Round  28, Train loss: 1.577, Test loss: 1.684, Test accuracy: 78.46 

Round  29, Train loss: 1.572, Test loss: 1.684, Test accuracy: 78.46 

Round  30, Train loss: 1.572, Test loss: 1.683, Test accuracy: 78.42 

Round  31, Train loss: 1.563, Test loss: 1.673, Test accuracy: 79.54 

Round  32, Train loss: 1.524, Test loss: 1.659, Test accuracy: 81.82 

Round  33, Train loss: 1.523, Test loss: 1.649, Test accuracy: 82.74 

Round  34, Train loss: 1.507, Test loss: 1.642, Test accuracy: 83.40 

Round  35, Train loss: 1.500, Test loss: 1.637, Test accuracy: 83.88 

Round  36, Train loss: 1.511, Test loss: 1.629, Test accuracy: 84.63 

Round  37, Train loss: 1.506, Test loss: 1.624, Test accuracy: 85.38 

Round  38, Train loss: 1.493, Test loss: 1.622, Test accuracy: 85.31 

Round  39, Train loss: 1.485, Test loss: 1.620, Test accuracy: 85.53 

Round  40, Train loss: 1.488, Test loss: 1.619, Test accuracy: 85.44 

Round  41, Train loss: 1.485, Test loss: 1.618, Test accuracy: 85.53 

Round  42, Train loss: 1.487, Test loss: 1.618, Test accuracy: 85.47 

Round  43, Train loss: 1.493, Test loss: 1.616, Test accuracy: 85.52 

Round  44, Train loss: 1.487, Test loss: 1.616, Test accuracy: 85.52 

Round  45, Train loss: 1.484, Test loss: 1.616, Test accuracy: 85.52 

Round  46, Train loss: 1.485, Test loss: 1.615, Test accuracy: 85.61 

Round  47, Train loss: 1.486, Test loss: 1.615, Test accuracy: 85.67 

Round  48, Train loss: 1.477, Test loss: 1.614, Test accuracy: 85.67 

Round  49, Train loss: 1.488, Test loss: 1.614, Test accuracy: 85.58 

Round  50, Train loss: 1.489, Test loss: 1.613, Test accuracy: 85.64 

Round  51, Train loss: 1.481, Test loss: 1.613, Test accuracy: 85.69 

Round  52, Train loss: 1.482, Test loss: 1.612, Test accuracy: 85.65 

Round  53, Train loss: 1.480, Test loss: 1.612, Test accuracy: 85.68 

Round  54, Train loss: 1.485, Test loss: 1.612, Test accuracy: 85.66 

Round  55, Train loss: 1.486, Test loss: 1.612, Test accuracy: 85.72 

Round  56, Train loss: 1.486, Test loss: 1.611, Test accuracy: 85.75 

Round  57, Train loss: 1.483, Test loss: 1.611, Test accuracy: 85.67 

Round  58, Train loss: 1.482, Test loss: 1.611, Test accuracy: 85.78 

Round  59, Train loss: 1.483, Test loss: 1.611, Test accuracy: 85.69 

Round  60, Train loss: 1.482, Test loss: 1.611, Test accuracy: 85.63 

Round  61, Train loss: 1.483, Test loss: 1.611, Test accuracy: 85.78 

Round  62, Train loss: 1.484, Test loss: 1.611, Test accuracy: 85.72 

Round  63, Train loss: 1.484, Test loss: 1.611, Test accuracy: 85.73 

Round  64, Train loss: 1.484, Test loss: 1.611, Test accuracy: 85.73 

Round  65, Train loss: 1.484, Test loss: 1.610, Test accuracy: 85.67 

Round  66, Train loss: 1.484, Test loss: 1.610, Test accuracy: 85.71 

Round  67, Train loss: 1.483, Test loss: 1.610, Test accuracy: 85.69 

Round  68, Train loss: 1.480, Test loss: 1.610, Test accuracy: 85.69 

Round  69, Train loss: 1.484, Test loss: 1.610, Test accuracy: 85.72 

Round  70, Train loss: 1.484, Test loss: 1.610, Test accuracy: 85.67 

Round  71, Train loss: 1.483, Test loss: 1.610, Test accuracy: 85.72 

Round  72, Train loss: 1.480, Test loss: 1.610, Test accuracy: 85.70 

Round  73, Train loss: 1.484, Test loss: 1.610, Test accuracy: 85.67 

Round  74, Train loss: 1.483, Test loss: 1.610, Test accuracy: 85.65 

Round  75, Train loss: 1.486, Test loss: 1.610, Test accuracy: 85.65 

Round  76, Train loss: 1.484, Test loss: 1.610, Test accuracy: 85.67 

Round  77, Train loss: 1.481, Test loss: 1.610, Test accuracy: 85.67 

Round  78, Train loss: 1.481, Test loss: 1.610, Test accuracy: 85.67 

Round  79, Train loss: 1.483, Test loss: 1.610, Test accuracy: 85.66 

Round  80, Train loss: 1.483, Test loss: 1.610, Test accuracy: 85.64 

Round  81, Train loss: 1.482, Test loss: 1.610, Test accuracy: 85.65 

Round  82, Train loss: 1.483, Test loss: 1.610, Test accuracy: 85.72 

Round  83, Train loss: 1.482, Test loss: 1.610, Test accuracy: 85.72 

Round  84, Train loss: 1.484, Test loss: 1.610, Test accuracy: 85.70 

Round  85, Train loss: 1.484, Test loss: 1.610, Test accuracy: 85.72 

Round  86, Train loss: 1.482, Test loss: 1.610, Test accuracy: 85.69 

Round  87, Train loss: 1.481, Test loss: 1.610, Test accuracy: 85.67 

Round  88, Train loss: 1.481, Test loss: 1.610, Test accuracy: 85.62 

Round  89, Train loss: 1.483, Test loss: 1.610, Test accuracy: 85.62 

Round  90, Train loss: 1.484, Test loss: 1.609, Test accuracy: 85.68 

Round  91, Train loss: 1.478, Test loss: 1.609, Test accuracy: 85.71 

Round  92, Train loss: 1.480, Test loss: 1.609, Test accuracy: 85.71 

Round  93, Train loss: 1.480, Test loss: 1.609, Test accuracy: 85.70 

Round  94, Train loss: 1.481, Test loss: 1.609, Test accuracy: 85.67 

Round  95, Train loss: 1.480, Test loss: 1.609, Test accuracy: 85.72 

Round  96, Train loss: 1.481, Test loss: 1.609, Test accuracy: 85.66 

Round  97, Train loss: 1.479, Test loss: 1.609, Test accuracy: 85.72 
/home/ChenSM/code/FL_HLS/utils/sampling.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  98, Train loss: 1.484, Test loss: 1.609, Test accuracy: 85.70 

Round  99, Train loss: 1.483, Test loss: 1.609, Test accuracy: 85.70 

Final Round, Train loss: 1.481, Test loss: 1.609, Test accuracy: 85.67 

Average accuracy final 10 rounds: 85.69666666666666 

725.2032697200775
[0.8952627182006836, 1.6957783699035645, 2.5038020610809326, 3.323000907897949, 4.094758749008179, 4.859174013137817, 5.630231857299805, 6.399234771728516, 7.163597345352173, 7.934328079223633, 8.69733190536499, 9.458141326904297, 10.22089958190918, 10.987489938735962, 11.748006582260132, 12.511425495147705, 13.272780418395996, 14.034607410430908, 14.798208713531494, 15.551633358001709, 16.311479806900024, 17.066861152648926, 17.82231068611145, 18.54719090461731, 19.28226590156555, 20.02179718017578, 20.742634534835815, 21.461727142333984, 22.19013738632202, 22.915400743484497, 23.681495189666748, 24.448994159698486, 25.211061239242554, 25.970027446746826, 26.736559867858887, 27.496475219726562, 28.26299548149109, 29.025734186172485, 29.790919065475464, 30.554016590118408, 31.31709051132202, 32.084226846694946, 32.849984645843506, 33.61026382446289, 34.37408113479614, 35.136029958724976, 35.896583557128906, 36.6560845375061, 37.41767477989197, 38.18197441101074, 38.941144943237305, 39.69689083099365, 40.44187355041504, 41.18695688247681, 41.935351848602295, 42.67730450630188, 43.41784381866455, 44.166494369506836, 44.91233992576599, 45.652092933654785, 46.397329568862915, 47.14816474914551, 47.8983850479126, 48.64562726020813, 49.38654446601868, 50.12947201728821, 50.86373448371887, 51.60953116416931, 52.355180740356445, 53.09939646720886, 53.85795283317566, 54.623464584350586, 55.38299870491028, 56.144296407699585, 56.905216693878174, 57.6628315448761, 58.42604160308838, 59.18472099304199, 59.94461464881897, 60.70698380470276, 61.46656608581543, 62.2250337600708, 62.985721826553345, 63.74002289772034, 64.50499486923218, 65.26466274261475, 66.02658677101135, 66.78217220306396, 67.53727173805237, 68.29415726661682, 69.05239868164062, 69.80689764022827, 70.571608543396, 71.33178067207336, 72.09131336212158, 72.85097002983093, 73.61159133911133, 74.37021350860596, 75.13132524490356, 75.88795375823975, 77.30201172828674]
[9.808333333333334, 20.716666666666665, 21.091666666666665, 26.466666666666665, 38.141666666666666, 47.25, 55.266666666666666, 65.04166666666667, 69.36666666666666, 72.625, 73.08333333333333, 75.025, 76.46666666666667, 76.95, 77.21666666666667, 77.45, 77.69166666666666, 77.88333333333334, 77.825, 78.0, 78.45, 78.49166666666666, 78.46666666666667, 78.48333333333333, 78.525, 78.45833333333333, 78.35833333333333, 78.39166666666667, 78.45833333333333, 78.45833333333333, 78.425, 79.54166666666667, 81.81666666666666, 82.74166666666666, 83.4, 83.875, 84.63333333333334, 85.38333333333334, 85.30833333333334, 85.525, 85.44166666666666, 85.525, 85.46666666666667, 85.51666666666667, 85.51666666666667, 85.51666666666667, 85.60833333333333, 85.675, 85.66666666666667, 85.58333333333333, 85.64166666666667, 85.69166666666666, 85.65, 85.68333333333334, 85.65833333333333, 85.71666666666667, 85.75, 85.66666666666667, 85.775, 85.69166666666666, 85.63333333333334, 85.78333333333333, 85.725, 85.73333333333333, 85.73333333333333, 85.675, 85.70833333333333, 85.69166666666666, 85.69166666666666, 85.71666666666667, 85.675, 85.725, 85.7, 85.66666666666667, 85.65, 85.65, 85.66666666666667, 85.675, 85.675, 85.65833333333333, 85.64166666666667, 85.65, 85.71666666666667, 85.725, 85.7, 85.725, 85.69166666666666, 85.675, 85.625, 85.625, 85.68333333333334, 85.70833333333333, 85.70833333333333, 85.7, 85.675, 85.71666666666667, 85.65833333333333, 85.71666666666667, 85.7, 85.7, 85.66666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
Round   0, Train loss: 1.703, Test loss: 2.291, Test accuracy: 32.17
Round   1, Train loss: 1.561, Test loss: 2.235, Test accuracy: 52.07
Round   2, Train loss: 1.378, Test loss: 2.102, Test accuracy: 62.74
Round   3, Train loss: 1.270, Test loss: 1.973, Test accuracy: 74.04
Round   4, Train loss: 1.225, Test loss: 1.922, Test accuracy: 77.13
Round   5, Train loss: 1.220, Test loss: 1.902, Test accuracy: 77.92
Round   6, Train loss: 1.216, Test loss: 1.886, Test accuracy: 80.02
Round   7, Train loss: 1.211, Test loss: 1.873, Test accuracy: 81.36
Round   8, Train loss: 1.197, Test loss: 1.864, Test accuracy: 81.38
Round   9, Train loss: 1.201, Test loss: 1.859, Test accuracy: 81.22
Round  10, Train loss: 1.201, Test loss: 1.856, Test accuracy: 81.12
Round  11, Train loss: 1.186, Test loss: 1.853, Test accuracy: 81.13
Round  12, Train loss: 1.187, Test loss: 1.850, Test accuracy: 80.82
Round  13, Train loss: 1.195, Test loss: 1.849, Test accuracy: 80.81
Round  14, Train loss: 1.189, Test loss: 1.848, Test accuracy: 80.73
Round  15, Train loss: 1.184, Test loss: 1.846, Test accuracy: 80.51
Round  16, Train loss: 1.183, Test loss: 1.845, Test accuracy: 80.42
Round  17, Train loss: 1.183, Test loss: 1.844, Test accuracy: 80.41
Round  18, Train loss: 1.190, Test loss: 1.844, Test accuracy: 80.26
Round  19, Train loss: 1.182, Test loss: 1.843, Test accuracy: 80.14
Round  20, Train loss: 1.187, Test loss: 1.842, Test accuracy: 80.05
Round  21, Train loss: 1.178, Test loss: 1.843, Test accuracy: 79.88
Round  22, Train loss: 1.177, Test loss: 1.842, Test accuracy: 79.66
Round  23, Train loss: 1.181, Test loss: 1.841, Test accuracy: 79.45
Round  24, Train loss: 1.183, Test loss: 1.841, Test accuracy: 79.42
Round  25, Train loss: 1.182, Test loss: 1.842, Test accuracy: 79.15
Round  26, Train loss: 1.187, Test loss: 1.843, Test accuracy: 78.93
Round  27, Train loss: 1.183, Test loss: 1.843, Test accuracy: 78.90
Round  28, Train loss: 1.180, Test loss: 1.843, Test accuracy: 78.74
Round  29, Train loss: 1.177, Test loss: 1.844, Test accuracy: 78.53
Round  30, Train loss: 1.185, Test loss: 1.846, Test accuracy: 77.98
Round  31, Train loss: 1.182, Test loss: 1.847, Test accuracy: 77.78
Round  32, Train loss: 1.183, Test loss: 1.848, Test accuracy: 77.53
Round  33, Train loss: 1.178, Test loss: 1.848, Test accuracy: 77.28
Round  34, Train loss: 1.180, Test loss: 1.849, Test accuracy: 77.14
Round  35, Train loss: 1.172, Test loss: 1.850, Test accuracy: 77.00
Round  36, Train loss: 1.175, Test loss: 1.851, Test accuracy: 76.71
Round  37, Train loss: 1.175, Test loss: 1.851, Test accuracy: 76.70
Round  38, Train loss: 1.182, Test loss: 1.852, Test accuracy: 76.62
Round  39, Train loss: 1.174, Test loss: 1.851, Test accuracy: 76.58
Round  40, Train loss: 1.179, Test loss: 1.852, Test accuracy: 76.46
Round  41, Train loss: 1.184, Test loss: 1.853, Test accuracy: 76.29
Round  42, Train loss: 1.180, Test loss: 1.854, Test accuracy: 76.04
Round  43, Train loss: 1.181, Test loss: 1.853, Test accuracy: 76.00
Round  44, Train loss: 1.177, Test loss: 1.854, Test accuracy: 75.81
Round  45, Train loss: 1.182, Test loss: 1.855, Test accuracy: 75.76
Round  46, Train loss: 1.178, Test loss: 1.855, Test accuracy: 75.47
Round  47, Train loss: 1.183, Test loss: 1.856, Test accuracy: 75.46
Round  48, Train loss: 1.183, Test loss: 1.856, Test accuracy: 75.29
Round  49, Train loss: 1.178, Test loss: 1.856, Test accuracy: 75.24
Round  50, Train loss: 1.173, Test loss: 1.856, Test accuracy: 74.90
Round  51, Train loss: 1.182, Test loss: 1.857, Test accuracy: 74.72
Round  52, Train loss: 1.177, Test loss: 1.859, Test accuracy: 74.59
Round  53, Train loss: 1.184, Test loss: 1.860, Test accuracy: 74.52
Round  54, Train loss: 1.175, Test loss: 1.860, Test accuracy: 74.46
Round  55, Train loss: 1.178, Test loss: 1.860, Test accuracy: 74.36
Round  56, Train loss: 1.176, Test loss: 1.860, Test accuracy: 74.39
Round  57, Train loss: 1.177, Test loss: 1.861, Test accuracy: 74.17
Round  58, Train loss: 1.177, Test loss: 1.862, Test accuracy: 74.05
Round  59, Train loss: 1.181, Test loss: 1.862, Test accuracy: 73.92
Round  60, Train loss: 1.172, Test loss: 1.862, Test accuracy: 73.86
Round  61, Train loss: 1.167, Test loss: 1.864, Test accuracy: 73.77
Round  62, Train loss: 1.180, Test loss: 1.864, Test accuracy: 73.58
Round  63, Train loss: 1.182, Test loss: 1.865, Test accuracy: 73.50
Round  64, Train loss: 1.173, Test loss: 1.865, Test accuracy: 73.36
Round  65, Train loss: 1.174, Test loss: 1.865, Test accuracy: 73.38
Round  66, Train loss: 1.171, Test loss: 1.865, Test accuracy: 73.42
Round  67, Train loss: 1.180, Test loss: 1.867, Test accuracy: 73.07
Round  68, Train loss: 1.176, Test loss: 1.867, Test accuracy: 73.11
Round  69, Train loss: 1.180, Test loss: 1.867, Test accuracy: 73.12
Round  70, Train loss: 1.178, Test loss: 1.867, Test accuracy: 72.98
Round  71, Train loss: 1.174, Test loss: 1.867, Test accuracy: 72.85
Round  72, Train loss: 1.173, Test loss: 1.868, Test accuracy: 72.71
Round  73, Train loss: 1.179, Test loss: 1.869, Test accuracy: 72.50
Round  74, Train loss: 1.173, Test loss: 1.869, Test accuracy: 72.52
Round  75, Train loss: 1.176, Test loss: 1.869, Test accuracy: 72.28
Round  76, Train loss: 1.171, Test loss: 1.870, Test accuracy: 72.21
Round  77, Train loss: 1.174, Test loss: 1.870, Test accuracy: 72.03
Round  78, Train loss: 1.175, Test loss: 1.871, Test accuracy: 71.77
Round  79, Train loss: 1.174, Test loss: 1.872, Test accuracy: 71.72
Round  80, Train loss: 1.176, Test loss: 1.872, Test accuracy: 71.79
Round  81, Train loss: 1.178, Test loss: 1.873, Test accuracy: 71.72
Round  82, Train loss: 1.175, Test loss: 1.874, Test accuracy: 71.57
Round  83, Train loss: 1.174, Test loss: 1.874, Test accuracy: 71.60
Round  84, Train loss: 1.173, Test loss: 1.875, Test accuracy: 71.60
Round  85, Train loss: 1.177, Test loss: 1.875, Test accuracy: 71.53
Round  86, Train loss: 1.172, Test loss: 1.875, Test accuracy: 71.43
Round  87, Train loss: 1.175, Test loss: 1.876, Test accuracy: 71.37
Round  88, Train loss: 1.171, Test loss: 1.876, Test accuracy: 71.19
Round  89, Train loss: 1.174, Test loss: 1.876, Test accuracy: 71.34
Round  90, Train loss: 1.177, Test loss: 1.879, Test accuracy: 71.28
Round  91, Train loss: 1.164, Test loss: 1.879, Test accuracy: 71.43
Round  92, Train loss: 1.163, Test loss: 1.875, Test accuracy: 72.47
Round  93, Train loss: 1.134, Test loss: 1.872, Test accuracy: 73.65
Round  94, Train loss: 1.129, Test loss: 1.869, Test accuracy: 74.22
Round  95, Train loss: 1.121, Test loss: 1.868, Test accuracy: 74.47
Round  96, Train loss: 1.125, Test loss: 1.864, Test accuracy: 75.25
Round  97, Train loss: 1.114, Test loss: 1.862, Test accuracy: 75.58
Round  98, Train loss: 1.110, Test loss: 1.862, Test accuracy: 75.62
Round  99, Train loss: 1.112, Test loss: 1.860, Test accuracy: 75.80
Final Round, Train loss: 1.115, Test loss: 1.860, Test accuracy: 76.12
Average accuracy final 10 rounds: 73.97749999999999
1302.0514051914215
[]
[32.175, 52.06666666666667, 62.74166666666667, 74.04166666666667, 77.13333333333334, 77.91666666666667, 80.01666666666667, 81.35833333333333, 81.38333333333334, 81.21666666666667, 81.11666666666666, 81.13333333333334, 80.81666666666666, 80.80833333333334, 80.73333333333333, 80.50833333333334, 80.41666666666667, 80.40833333333333, 80.25833333333334, 80.14166666666667, 80.05, 79.875, 79.65833333333333, 79.45, 79.41666666666667, 79.15, 78.93333333333334, 78.9, 78.74166666666666, 78.525, 77.98333333333333, 77.78333333333333, 77.53333333333333, 77.28333333333333, 77.14166666666667, 77.0, 76.70833333333333, 76.7, 76.61666666666666, 76.575, 76.45833333333333, 76.29166666666667, 76.04166666666667, 76.0, 75.80833333333334, 75.75833333333334, 75.475, 75.45833333333333, 75.29166666666667, 75.24166666666666, 74.9, 74.71666666666667, 74.59166666666667, 74.51666666666667, 74.45833333333333, 74.35833333333333, 74.39166666666667, 74.16666666666667, 74.05, 73.91666666666667, 73.85833333333333, 73.76666666666667, 73.58333333333333, 73.5, 73.35833333333333, 73.38333333333334, 73.41666666666667, 73.06666666666666, 73.10833333333333, 73.11666666666666, 72.98333333333333, 72.85, 72.70833333333333, 72.5, 72.51666666666667, 72.275, 72.20833333333333, 72.025, 71.76666666666667, 71.71666666666667, 71.79166666666667, 71.71666666666667, 71.56666666666666, 71.6, 71.6, 71.53333333333333, 71.43333333333334, 71.36666666666666, 71.19166666666666, 71.34166666666667, 71.275, 71.43333333333334, 72.475, 73.65, 74.225, 74.46666666666667, 75.25, 75.575, 75.625, 75.8, 76.11666666666666]/home/ChenSM/code/FL_HLS/utils/sampling.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.33
Round   0: Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 8.18
Round   1, Train loss: 2.305, Test loss: 2.300, Test accuracy: 18.49
Round   1: Global train loss: 2.305, Global test loss: 2.302, Global test accuracy: 10.59
Round   2, Train loss: 2.288, Test loss: 2.300, Test accuracy: 18.23
Round   2: Global train loss: 2.288, Global test loss: 2.302, Global test accuracy: 11.46
Round   3, Train loss: 2.302, Test loss: 2.298, Test accuracy: 20.82
Round   3: Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.38
Round   4, Train loss: 2.301, Test loss: 2.298, Test accuracy: 17.38
Round   4: Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 15.06
Round   5, Train loss: 2.292, Test loss: 2.297, Test accuracy: 17.88
Round   5: Global train loss: 2.292, Global test loss: 2.301, Global test accuracy: 16.43
Round   6, Train loss: 2.272, Test loss: 2.290, Test accuracy: 22.26
Round   6: Global train loss: 2.272, Global test loss: 2.300, Global test accuracy: 20.61
Round   7, Train loss: 2.269, Test loss: 2.288, Test accuracy: 22.28
Round   7: Global train loss: 2.269, Global test loss: 2.300, Global test accuracy: 22.28
Round   8, Train loss: 2.282, Test loss: 2.290, Test accuracy: 19.68
Round   8: Global train loss: 2.282, Global test loss: 2.300, Global test accuracy: 23.77
Round   9, Train loss: 2.251, Test loss: 2.283, Test accuracy: 21.18
Round   9: Global train loss: 2.251, Global test loss: 2.299, Global test accuracy: 27.16
Round  10, Train loss: 2.264, Test loss: 2.278, Test accuracy: 21.79
Round  10: Global train loss: 2.264, Global test loss: 2.299, Global test accuracy: 30.32
Round  11, Train loss: 2.295, Test loss: 2.280, Test accuracy: 21.76
Round  11: Global train loss: 2.295, Global test loss: 2.299, Global test accuracy: 30.60
Round  12, Train loss: 2.193, Test loss: 2.261, Test accuracy: 24.03
Round  12: Global train loss: 2.193, Global test loss: 2.298, Global test accuracy: 33.77
Round  13, Train loss: 2.271, Test loss: 2.278, Test accuracy: 19.82
Round  13: Global train loss: 2.271, Global test loss: 2.299, Global test accuracy: 32.02
Round  14, Train loss: 2.263, Test loss: 2.277, Test accuracy: 18.14
Round  14: Global train loss: 2.263, Global test loss: 2.299, Global test accuracy: 29.07
Round  15, Train loss: 2.284, Test loss: 2.285, Test accuracy: 17.04
Round  15: Global train loss: 2.284, Global test loss: 2.300, Global test accuracy: 23.02
Round  16, Train loss: 2.226, Test loss: 2.287, Test accuracy: 16.78
Round  16: Global train loss: 2.226, Global test loss: 2.301, Global test accuracy: 20.32
Round  17, Train loss: 2.227, Test loss: 2.276, Test accuracy: 16.37
Round  17: Global train loss: 2.227, Global test loss: 2.301, Global test accuracy: 20.68
Round  18, Train loss: 2.168, Test loss: 2.280, Test accuracy: 14.11
Round  18: Global train loss: 2.168, Global test loss: 2.302, Global test accuracy: 13.91
Round  19, Train loss: 2.137, Test loss: 2.258, Test accuracy: 16.70
Round  19: Global train loss: 2.137, Global test loss: 2.301, Global test accuracy: 17.83
Round  20, Train loss: 1.919, Test loss: 2.247, Test accuracy: 18.55
Round  20: Global train loss: 1.919, Global test loss: 2.301, Global test accuracy: 21.68
Round  21, Train loss: 1.806, Test loss: 2.204, Test accuracy: 24.86
Round  21: Global train loss: 1.806, Global test loss: 2.299, Global test accuracy: 30.50
Round  22, Train loss: 2.148, Test loss: 2.200, Test accuracy: 25.98
Round  22: Global train loss: 2.148, Global test loss: 2.299, Global test accuracy: 33.29
Round  23, Train loss: 1.706, Test loss: 2.161, Test accuracy: 32.19
Round  23: Global train loss: 1.706, Global test loss: 2.297, Global test accuracy: 40.07
Round  24, Train loss: 1.537, Test loss: 2.140, Test accuracy: 34.28
Round  24: Global train loss: 1.537, Global test loss: 2.296, Global test accuracy: 46.82
Round  25, Train loss: 1.526, Test loss: 2.119, Test accuracy: 36.64
Round  25: Global train loss: 1.526, Global test loss: 2.294, Global test accuracy: 50.43
Round  26, Train loss: 0.817, Test loss: 2.054, Test accuracy: 43.57
Round  26: Global train loss: 0.817, Global test loss: 2.287, Global test accuracy: 54.35
Round  27, Train loss: 1.507, Test loss: 2.083, Test accuracy: 39.77
Round  27: Global train loss: 1.507, Global test loss: 2.286, Global test accuracy: 54.67
Round  28, Train loss: 1.579, Test loss: 2.180, Test accuracy: 28.88
Round  28: Global train loss: 1.579, Global test loss: 2.293, Global test accuracy: 48.52
Round  29, Train loss: 0.883, Test loss: 2.119, Test accuracy: 36.07
Round  29: Global train loss: 0.883, Global test loss: 2.291, Global test accuracy: 50.47
Round  30, Train loss: 0.860, Test loss: 2.082, Test accuracy: 38.11
Round  30: Global train loss: 0.860, Global test loss: 2.286, Global test accuracy: 55.30
Round  31, Train loss: 1.473, Test loss: 2.117, Test accuracy: 34.02
Round  31: Global train loss: 1.473, Global test loss: 2.290, Global test accuracy: 53.53
Round  32, Train loss: 1.725, Test loss: 2.224, Test accuracy: 22.11
Round  32: Global train loss: 1.725, Global test loss: 2.298, Global test accuracy: 30.76
Round  33, Train loss: 1.103, Test loss: 2.104, Test accuracy: 37.78
Round  33: Global train loss: 1.103, Global test loss: 2.292, Global test accuracy: 49.97
Round  34, Train loss: 0.866, Test loss: 2.110, Test accuracy: 37.60
Round  34: Global train loss: 0.866, Global test loss: 2.292, Global test accuracy: 53.71
Round  35, Train loss: 1.290, Test loss: 2.107, Test accuracy: 37.27
Round  35: Global train loss: 1.290, Global test loss: 2.292, Global test accuracy: 52.42
Round  36, Train loss: 1.336, Test loss: 2.098, Test accuracy: 37.88
Round  36: Global train loss: 1.336, Global test loss: 2.291, Global test accuracy: 54.91
Round  37, Train loss: 0.756, Test loss: 2.059, Test accuracy: 40.47
Round  37: Global train loss: 0.756, Global test loss: 2.289, Global test accuracy: 57.16
Round  38, Train loss: 0.589, Test loss: 2.080, Test accuracy: 38.12
Round  38: Global train loss: 0.589, Global test loss: 2.289, Global test accuracy: 58.37
Round  39, Train loss: -0.705, Test loss: 1.981, Test accuracy: 48.29
Round  39: Global train loss: -0.705, Global test loss: 2.272, Global test accuracy: 66.29
Round  40, Train loss: 1.091, Test loss: 2.034, Test accuracy: 43.07
Round  40: Global train loss: 1.091, Global test loss: 2.277, Global test accuracy: 66.27
Round  41, Train loss: 0.534, Test loss: 2.036, Test accuracy: 44.46
Round  41: Global train loss: 0.534, Global test loss: 2.274, Global test accuracy: 66.74
Round  42, Train loss: 1.604, Test loss: 2.124, Test accuracy: 36.54
Round  42: Global train loss: 1.604, Global test loss: 2.285, Global test accuracy: 56.93
Round  43, Train loss: -0.240, Test loss: 2.052, Test accuracy: 43.10
Round  43: Global train loss: -0.240, Global test loss: 2.274, Global test accuracy: 65.47
Round  44, Train loss: 0.264, Test loss: 2.056, Test accuracy: 40.85
Round  44: Global train loss: 0.264, Global test loss: 2.271, Global test accuracy: 63.00
Round  45, Train loss: -0.097, Test loss: 2.045, Test accuracy: 43.02
Round  45: Global train loss: -0.097, Global test loss: 2.266, Global test accuracy: 63.57
Round  46, Train loss: 0.718, Test loss: 2.063, Test accuracy: 39.54
Round  46: Global train loss: 0.718, Global test loss: 2.272, Global test accuracy: 62.87
Round  47, Train loss: 0.064, Test loss: 2.054, Test accuracy: 40.29
Round  47: Global train loss: 0.064, Global test loss: 2.272, Global test accuracy: 63.77
Round  48, Train loss: 1.234, Test loss: 2.112, Test accuracy: 34.31
Round  48: Global train loss: 1.234, Global test loss: 2.285, Global test accuracy: 59.09
Round  49, Train loss: 0.057, Test loss: 2.078, Test accuracy: 38.14
Round  49: Global train loss: 0.057, Global test loss: 2.285, Global test accuracy: 58.68
Round  50, Train loss: -0.247, Test loss: 2.009, Test accuracy: 45.27
Round  50: Global train loss: -0.247, Global test loss: 2.276, Global test accuracy: 60.04
Round  51, Train loss: -1.780, Test loss: 1.944, Test accuracy: 51.99
Round  51: Global train loss: -1.780, Global test loss: 2.250, Global test accuracy: 61.94
Round  52, Train loss: -2.026, Test loss: 1.932, Test accuracy: 54.21
Round  52: Global train loss: -2.026, Global test loss: 2.209, Global test accuracy: 64.28
Round  53, Train loss: 0.546, Test loss: 1.989, Test accuracy: 49.15
Round  53: Global train loss: 0.546, Global test loss: 2.213, Global test accuracy: 62.24
Round  54, Train loss: -0.675, Test loss: 1.985, Test accuracy: 50.77
Round  54: Global train loss: -0.675, Global test loss: 2.206, Global test accuracy: 63.61
Round  55, Train loss: 0.263, Test loss: 2.018, Test accuracy: 47.20
Round  55: Global train loss: 0.263, Global test loss: 2.208, Global test accuracy: 61.10
Round  56, Train loss: 0.489, Test loss: 2.021, Test accuracy: 45.43
Round  56: Global train loss: 0.489, Global test loss: 2.211, Global test accuracy: 59.38
Round  57, Train loss: 0.454, Test loss: 2.063, Test accuracy: 40.36
Round  57: Global train loss: 0.454, Global test loss: 2.234, Global test accuracy: 57.58
Round  58, Train loss: -0.534, Test loss: 2.044, Test accuracy: 42.61
Round  58: Global train loss: -0.534, Global test loss: 2.237, Global test accuracy: 58.32
Round  59, Train loss: 0.027, Test loss: 2.014, Test accuracy: 45.42
Round  59: Global train loss: 0.027, Global test loss: 2.236, Global test accuracy: 57.52
Round  60, Train loss: -1.098, Test loss: 2.012, Test accuracy: 44.56
Round  60: Global train loss: -1.098, Global test loss: 2.234, Global test accuracy: 56.49
Round  61, Train loss: -0.489, Test loss: 1.993, Test accuracy: 47.98
Round  61: Global train loss: -0.489, Global test loss: 2.236, Global test accuracy: 55.11
Round  62, Train loss: -0.838, Test loss: 1.946, Test accuracy: 52.85
Round  62: Global train loss: -0.838, Global test loss: 2.217, Global test accuracy: 55.94
Round  63, Train loss: -3.267, Test loss: 1.880, Test accuracy: 59.80
Round  63: Global train loss: -3.267, Global test loss: 2.165, Global test accuracy: 60.35
Round  64, Train loss: -1.952, Test loss: 1.911, Test accuracy: 56.08
Round  64: Global train loss: -1.952, Global test loss: 2.154, Global test accuracy: 60.05
Round  65, Train loss: -2.432, Test loss: 1.868, Test accuracy: 60.19
Round  65: Global train loss: -2.432, Global test loss: 2.116, Global test accuracy: 61.12
Round  66, Train loss: 0.056, Test loss: 1.907, Test accuracy: 56.27
Round  66: Global train loss: 0.056, Global test loss: 2.136, Global test accuracy: 59.86
Round  67, Train loss: -2.553, Test loss: 1.838, Test accuracy: 63.41
Round  67: Global train loss: -2.553, Global test loss: 2.071, Global test accuracy: 63.68
Round  68, Train loss: -0.347, Test loss: 1.854, Test accuracy: 62.13
Round  68: Global train loss: -0.347, Global test loss: 2.045, Global test accuracy: 64.08
Round  69, Train loss: -0.427, Test loss: 1.858, Test accuracy: 62.38
Round  69: Global train loss: -0.427, Global test loss: 2.052, Global test accuracy: 62.62
Round  70, Train loss: -0.350, Test loss: 1.881, Test accuracy: 61.54
Round  70: Global train loss: -0.350, Global test loss: 2.071, Global test accuracy: 55.88
Round  71, Train loss: -1.063, Test loss: 1.844, Test accuracy: 64.84
Round  71: Global train loss: -1.063, Global test loss: 2.045, Global test accuracy: 58.44
Round  72, Train loss: -1.961, Test loss: 1.794, Test accuracy: 68.74
Round  72: Global train loss: -1.961, Global test loss: 2.006, Global test accuracy: 62.12
Round  73, Train loss: -0.787, Test loss: 1.809, Test accuracy: 67.14
Round  73: Global train loss: -0.787, Global test loss: 1.998, Global test accuracy: 61.66
Round  74, Train loss: -0.056, Test loss: 1.792, Test accuracy: 68.28
Round  74: Global train loss: -0.056, Global test loss: 1.988, Global test accuracy: 62.52
Round  75, Train loss: -1.261, Test loss: 1.759, Test accuracy: 72.10
Round  75: Global train loss: -1.261, Global test loss: 1.957, Global test accuracy: 63.92
Round  76, Train loss: -0.647, Test loss: 1.770, Test accuracy: 70.83
Round  76: Global train loss: -0.647, Global test loss: 1.950, Global test accuracy: 62.55
Round  77, Train loss: -0.189, Test loss: 1.772, Test accuracy: 70.42
Round  77: Global train loss: -0.189, Global test loss: 1.948, Global test accuracy: 62.94
Round  78, Train loss: -1.924, Test loss: 1.724, Test accuracy: 74.52
Round  78: Global train loss: -1.924, Global test loss: 1.922, Global test accuracy: 66.05
Round  79, Train loss: 0.069, Test loss: 1.736, Test accuracy: 73.54
Round  79: Global train loss: 0.069, Global test loss: 1.923, Global test accuracy: 66.28
Round  80, Train loss: -0.342, Test loss: 1.725, Test accuracy: 74.87
Round  80: Global train loss: -0.342, Global test loss: 1.912, Global test accuracy: 67.64
Round  81, Train loss: -1.893, Test loss: 1.703, Test accuracy: 76.58
Round  81: Global train loss: -1.893, Global test loss: 1.886, Global test accuracy: 69.17
Round  82, Train loss: -0.098, Test loss: 1.702, Test accuracy: 76.45
Round  82: Global train loss: -0.098, Global test loss: 1.883, Global test accuracy: 69.33
Round  83, Train loss: -0.707, Test loss: 1.692, Test accuracy: 77.47
Round  83: Global train loss: -0.707, Global test loss: 1.868, Global test accuracy: 70.53
Round  84, Train loss: -0.432, Test loss: 1.696, Test accuracy: 77.29
Round  84: Global train loss: -0.432, Global test loss: 1.863, Global test accuracy: 71.86
Round  85, Train loss: -2.189, Test loss: 1.682, Test accuracy: 78.44
Round  85: Global train loss: -2.189, Global test loss: 1.842, Global test accuracy: 72.69
Round  86, Train loss: -0.524, Test loss: 1.685, Test accuracy: 78.38
Round  86: Global train loss: -0.524, Global test loss: 1.849, Global test accuracy: 72.94
Round  87, Train loss: -0.887, Test loss: 1.684, Test accuracy: 78.28
Round  87: Global train loss: -0.887, Global test loss: 1.841, Global test accuracy: 73.70
Round  88, Train loss: -0.796, Test loss: 1.684, Test accuracy: 78.36
Round  88: Global train loss: -0.796, Global test loss: 1.827, Global test accuracy: 75.24
Round  89, Train loss: -1.006, Test loss: 1.688, Test accuracy: 77.87
Round  89: Global train loss: -1.006, Global test loss: 1.817, Global test accuracy: 75.95
Round  90, Train loss: 0.071, Test loss: 1.685, Test accuracy: 78.16
Round  90: Global train loss: 0.071, Global test loss: 1.811, Global test accuracy: 75.94
Round  91, Train loss: -1.596, Test loss: 1.676, Test accuracy: 78.85
Round  91: Global train loss: -1.596, Global test loss: 1.797, Global test accuracy: 76.27
Round  92, Train loss: -0.512, Test loss: 1.672, Test accuracy: 79.18
Round  92: Global train loss: -0.512, Global test loss: 1.787, Global test accuracy: 76.68
Round  93, Train loss: -1.120, Test loss: 1.670, Test accuracy: 79.34
Round  93: Global train loss: -1.120, Global test loss: 1.782, Global test accuracy: 77.02
Round  94, Train loss: -1.292, Test loss: 1.671, Test accuracy: 79.25
Round  94: Global train loss: -1.292, Global test loss: 1.771, Global test accuracy: 77.45
Round  95, Train loss: -0.582, Test loss: 1.668, Test accuracy: 79.59
Round  95: Global train loss: -0.582, Global test loss: 1.768, Global test accuracy: 77.67
Round  96, Train loss: -0.877, Test loss: 1.666, Test accuracy: 79.71
Round  96: Global train loss: -0.877, Global test loss: 1.761, Global test accuracy: 77.97
Round  97, Train loss: -0.824, Test loss: 1.668, Test accuracy: 79.58
Round  97: Global train loss: -0.824, Global test loss: 1.756, Global test accuracy: 78.33
Round  98, Train loss: -0.679, Test loss: 1.668, Test accuracy: 79.61
Round  98: Global train loss: -0.679, Global test loss: 1.751, Global test accuracy: 78.63
Round  99, Train loss: -0.451, Test loss: 1.666, Test accuracy: 79.92/home/ChenSM/code/FL_HLS/utils/sampling.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  99: Global train loss: -0.451, Global test loss: 1.746, Global test accuracy: 78.99
Final Round: Train loss: 1.662, Test loss: 1.667, Test accuracy: 81.38
Final Round: Global train loss: 1.662, Global test loss: 1.731, Global test accuracy: 79.78
Average accuracy final 10 rounds: 79.31916666666666
Average global accuracy final 10 rounds: 77.49666666666667
1226.409749031067
[]
[12.333333333333334, 18.491666666666667, 18.233333333333334, 20.816666666666666, 17.375, 17.883333333333333, 22.258333333333333, 22.283333333333335, 19.675, 21.175, 21.791666666666668, 21.758333333333333, 24.033333333333335, 19.825, 18.141666666666666, 17.041666666666668, 16.783333333333335, 16.366666666666667, 14.108333333333333, 16.7, 18.55, 24.858333333333334, 25.975, 32.19166666666667, 34.28333333333333, 36.641666666666666, 43.56666666666667, 39.766666666666666, 28.875, 36.06666666666667, 38.108333333333334, 34.016666666666666, 22.108333333333334, 37.78333333333333, 37.6, 37.275, 37.875, 40.46666666666667, 38.11666666666667, 48.291666666666664, 43.06666666666667, 44.458333333333336, 36.541666666666664, 43.1, 40.85, 43.016666666666666, 39.541666666666664, 40.291666666666664, 34.30833333333333, 38.141666666666666, 45.266666666666666, 51.99166666666667, 54.208333333333336, 49.15, 50.766666666666666, 47.2, 45.43333333333333, 40.358333333333334, 42.608333333333334, 45.416666666666664, 44.55833333333333, 47.975, 52.85, 59.8, 56.075, 60.19166666666667, 56.275, 63.40833333333333, 62.13333333333333, 62.375, 61.541666666666664, 64.84166666666667, 68.74166666666666, 67.14166666666667, 68.28333333333333, 72.1, 70.83333333333333, 70.41666666666667, 74.51666666666667, 73.54166666666667, 74.86666666666666, 76.58333333333333, 76.45, 77.475, 77.29166666666667, 78.44166666666666, 78.38333333333334, 78.275, 78.35833333333333, 77.86666666666666, 78.15833333333333, 78.85, 79.18333333333334, 79.34166666666667, 79.25, 79.59166666666667, 79.70833333333333, 79.58333333333333, 79.60833333333333, 79.91666666666667, 81.38333333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.88 

Round   0, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.89 

Round   1, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.92 

Round   1, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.84 

Round   2, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.92 

Round   2, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.84 

Round   3, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.95 

Round   3, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.92 

Round   4, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.99 

Round   4, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.03 

Round   5, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.06 

Round   5, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.16 

Round   6, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.09 

Round   6, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.21 

Round   7, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.15 

Round   7, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.27 

Round   8, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.16 

Round   8, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.27 

Round   9, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.18 

Round   9, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.33 

Round  10, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.24 

Round  10, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.44 

Round  11, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.34 

Round  11, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.53 

Round  12, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.46 

Round  12, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.64 

Round  13, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.54 

Round  13, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.72 

Round  14, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.61 

Round  14, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.78 

Round  15, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.74 

Round  15, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.89 

Round  16, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.77 

Round  16, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.93 

Round  17, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.88 

Round  17, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.93 

Round  18, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.91 

Round  18, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.03 

Round  19, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.96 

Round  19, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.05 

Round  20, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.99 

Round  20, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.12 

Round  21, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.09 

Round  21, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.33 

Round  22, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.15 

Round  22, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.35 

Round  23, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.21 

Round  23, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.43 

Round  24, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.44 

Round  24, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.63 

Round  25, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.51 

Round  25, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.66 

Round  26, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.58 

Round  26, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.66 

Round  27, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.62 

Round  27, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.72 

Round  28, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.62 

Round  28, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.66 

Round  29, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.62 

Round  29, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.62 

Round  30, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.62 

Round  30, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.53 

Round  31, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.65 

Round  31, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.63 

Round  32, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.67 

Round  32, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.65 

Round  33, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.69 

Round  33, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.84 

Round  34, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.73 

Round  34, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.77 

Round  35, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.77 

Round  35, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.86 

Round  36, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.79 

Round  36, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.88 

Round  37, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.81 

Round  37, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.89 

Round  38, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.82 

Round  38, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.91 

Round  39, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.85 

Round  39, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.93 

Round  40, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.87 

Round  40, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.96 

Round  41, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.89 

Round  41, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.97 

Round  42, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.86 

Round  42, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.96 

Round  43, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.95 

Round  43, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.07 

Round  44, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.98 

Round  44, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.07 

Round  45, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.98 

Round  45, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.08 

Round  46, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.99 

Round  46, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.07 

Round  47, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.09 

Round  47, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.10 

Round  48, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.07 

Round  48, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.17 

Round  49, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.12 

Round  49, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.28 

Round  50, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.14 

Round  50, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.25 

Round  51, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.18 

Round  51, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.26 

Round  52, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.14 

Round  52, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.14 

Round  53, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.16 

Round  53, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.16 

Round  54, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.18 

Round  54, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.29 

Round  55, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.18 

Round  55, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.32 

Round  56, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.23 

Round  56, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.43 

Round  57, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.28 

Round  57, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.50 

Round  58, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.38 

Round  58, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.51 

Round  59, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.37 

Round  59, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.49 

Round  60, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.40 

Round  60, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.50 

Round  61, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.40 

Round  61, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.52 

Round  62, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.50 

Round  62, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.57 

Round  63, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.54 

Round  63, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.61 

Round  64, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.61 

Round  64, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.66 

Round  65, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.67 

Round  65, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.73 

Round  66, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.72 

Round  66, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.79 

Round  67, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.75 

Round  67, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 14.87 

Round  68, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.72 

Round  68, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.90 

Round  69, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.78 

Round  69, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.89 

Round  70, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.84 

Round  70, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.97 

Round  71, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.96 

Round  71, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.07 

Round  72, Train loss: 2.302, Test loss: 2.302, Test accuracy: 15.02 

Round  72, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.12 

Round  73, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.00 

Round  73, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.12 

Round  74, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.97 

Round  74, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.08 

Round  75, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.95 

Round  75, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.12 

Round  76, Train loss: 2.302, Test loss: 2.302, Test accuracy: 15.01 

Round  76, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.12 

Round  77, Train loss: 2.302, Test loss: 2.302, Test accuracy: 15.08 

Round  77, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.18 

Round  78, Train loss: 2.302, Test loss: 2.302, Test accuracy: 15.09 

Round  78, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.14 

Round  79, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.12 

Round  79, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.18 

Round  80, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.13 

Round  80, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.16 

Round  81, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.21 

Round  81, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.18 

Round  82, Train loss: 2.302, Test loss: 2.302, Test accuracy: 15.14 

Round  82, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.16 

Round  83, Train loss: 2.302, Test loss: 2.302, Test accuracy: 15.21 

Round  83, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.41 

Round  84, Train loss: 2.302, Test loss: 2.302, Test accuracy: 15.32 

Round  84, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.49 

Round  85, Train loss: 2.302, Test loss: 2.302, Test accuracy: 15.40 

Round  85, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.62 

Round  86, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.41 

Round  86, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.62 

Round  87, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.49 

Round  87, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.66 

Round  88, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.52 

Round  88, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.67 

Round  89, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.55 

Round  89, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.70 

Round  90, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.56 

Round  90, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.68 

Round  91, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.62 

Round  91, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.68 

Round  92, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.62 

Round  92, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.78 

Round  93, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.65 

Round  93, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.80 

Round  94, Train loss: 2.302, Test loss: 2.302, Test accuracy: 15.71 
/home/ChenSM/code/FL_HLS/utils/sampling.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.82 

Round  95, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.72 

Round  95, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.82 

Round  96, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.72 

Round  96, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.82 

Round  97, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.76 

Round  97, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.82 

Round  98, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.77 

Round  98, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 15.85 

Round  99, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.85 

Round  99, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 15.88 

Final Round, Train loss: 2.301, Test loss: 2.301, Test accuracy: 15.91 

Final Round, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 15.88 

Average accuracy final 10 rounds: 15.696666666666665 

Average global accuracy final 10 rounds: 15.796666666666665 

1069.9331767559052
[0.9948136806488037, 1.9044773578643799, 2.8056466579437256, 3.709818124771118, 4.617498874664307, 5.51695990562439, 6.425658464431763, 7.3310866355896, 8.232603311538696, 9.130309820175171, 10.02309775352478, 10.917522192001343, 11.819297552108765, 12.713798522949219, 13.609523057937622, 14.511911153793335, 15.405327796936035, 16.30492925643921, 17.207752227783203, 18.102900505065918, 18.994044065475464, 19.87519884109497, 20.770816326141357, 21.670939922332764, 22.56002140045166, 23.4436297416687, 24.33533787727356, 25.222499132156372, 26.116400718688965, 27.00336480140686, 27.903281688690186, 28.801918268203735, 29.699143409729004, 30.59444570541382, 31.49195957183838, 32.38708972930908, 33.28420662879944, 34.182488679885864, 35.08455944061279, 35.98224759101868, 36.877622842788696, 37.77047514915466, 38.668336391448975, 39.56378626823425, 40.4574134349823, 41.351677656173706, 42.249478816986084, 43.14258027076721, 44.03402376174927, 44.93423914909363, 45.83326768875122, 46.72789549827576, 47.61736345291138, 48.511921882629395, 49.40498900413513, 50.29779839515686, 51.179293394088745, 52.07563924789429, 52.97710871696472, 53.85505127906799, 54.74189043045044, 55.6303985118866, 56.5206139087677, 57.403796911239624, 58.26931977272034, 59.151588678359985, 60.027730226516724, 60.89597034454346, 61.77942943572998, 62.66111779212952, 63.55032229423523, 64.4267828464508, 65.29331350326538, 66.17112445831299, 67.06339764595032, 67.93639802932739, 68.81863355636597, 69.69332885742188, 70.58620476722717, 71.47169256210327, 72.35263085365295, 73.24271893501282, 74.12374138832092, 75.02087759971619, 75.90391206741333, 76.7930679321289, 77.68400549888611, 78.57566666603088, 79.46834015846252, 80.36047530174255, 81.25004434585571, 82.13960456848145, 83.02544474601746, 83.90783476829529, 84.79281759262085, 85.66969680786133, 86.55340313911438, 87.43167781829834, 88.31696844100952, 89.20176100730896, 90.97389841079712]
[11.883333333333333, 11.916666666666666, 11.916666666666666, 11.95, 11.991666666666667, 12.058333333333334, 12.091666666666667, 12.15, 12.158333333333333, 12.175, 12.241666666666667, 12.341666666666667, 12.458333333333334, 12.541666666666666, 12.608333333333333, 12.741666666666667, 12.766666666666667, 12.875, 12.908333333333333, 12.958333333333334, 12.991666666666667, 13.091666666666667, 13.15, 13.208333333333334, 13.441666666666666, 13.508333333333333, 13.583333333333334, 13.625, 13.625, 13.625, 13.616666666666667, 13.65, 13.666666666666666, 13.691666666666666, 13.733333333333333, 13.766666666666667, 13.791666666666666, 13.808333333333334, 13.816666666666666, 13.85, 13.866666666666667, 13.891666666666667, 13.858333333333333, 13.95, 13.983333333333333, 13.983333333333333, 13.991666666666667, 14.091666666666667, 14.066666666666666, 14.116666666666667, 14.141666666666667, 14.175, 14.141666666666667, 14.158333333333333, 14.175, 14.183333333333334, 14.233333333333333, 14.283333333333333, 14.375, 14.366666666666667, 14.4, 14.4, 14.5, 14.541666666666666, 14.608333333333333, 14.666666666666666, 14.725, 14.75, 14.716666666666667, 14.783333333333333, 14.841666666666667, 14.958333333333334, 15.016666666666667, 15.0, 14.966666666666667, 14.95, 15.008333333333333, 15.083333333333334, 15.091666666666667, 15.116666666666667, 15.133333333333333, 15.208333333333334, 15.141666666666667, 15.208333333333334, 15.316666666666666, 15.4, 15.408333333333333, 15.491666666666667, 15.516666666666667, 15.55, 15.558333333333334, 15.625, 15.616666666666667, 15.65, 15.708333333333334, 15.716666666666667, 15.716666666666667, 15.758333333333333, 15.766666666666667, 15.85, 15.908333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
Round   0, Train loss: 2.302, Test loss: 2.299, Test accuracy: 11.69
Round   1, Train loss: 2.298, Test loss: 2.294, Test accuracy: 26.81
Round   2, Train loss: 2.293, Test loss: 2.280, Test accuracy: 25.44
Round   3, Train loss: 2.282, Test loss: 2.203, Test accuracy: 29.62
Round   4, Train loss: 2.213, Test loss: 2.037, Test accuracy: 46.44
Round   5, Train loss: 2.031, Test loss: 1.866, Test accuracy: 64.92
Round   6, Train loss: 1.897, Test loss: 1.818, Test accuracy: 66.38
Round   7, Train loss: 1.865, Test loss: 1.762, Test accuracy: 73.38
Round   8, Train loss: 1.784, Test loss: 1.684, Test accuracy: 81.71
Round   9, Train loss: 1.734, Test loss: 1.658, Test accuracy: 82.61
Round  10, Train loss: 1.680, Test loss: 1.649, Test accuracy: 83.10
Round  11, Train loss: 1.684, Test loss: 1.638, Test accuracy: 83.75
Round  12, Train loss: 1.711, Test loss: 1.613, Test accuracy: 86.87
Round  13, Train loss: 1.612, Test loss: 1.594, Test accuracy: 88.33
Round  14, Train loss: 1.593, Test loss: 1.583, Test accuracy: 89.22
Round  15, Train loss: 1.610, Test loss: 1.574, Test accuracy: 89.94
Round  16, Train loss: 1.578, Test loss: 1.569, Test accuracy: 90.13
Round  17, Train loss: 1.565, Test loss: 1.565, Test accuracy: 90.56
Round  18, Train loss: 1.549, Test loss: 1.562, Test accuracy: 90.81
Round  19, Train loss: 1.540, Test loss: 1.560, Test accuracy: 90.97
Round  20, Train loss: 1.546, Test loss: 1.557, Test accuracy: 91.28
Round  21, Train loss: 1.549, Test loss: 1.554, Test accuracy: 91.44
Round  22, Train loss: 1.540, Test loss: 1.554, Test accuracy: 91.45
Round  23, Train loss: 1.531, Test loss: 1.551, Test accuracy: 91.41
Round  24, Train loss: 1.529, Test loss: 1.549, Test accuracy: 91.77
Round  25, Train loss: 1.528, Test loss: 1.548, Test accuracy: 91.77
Round  26, Train loss: 1.525, Test loss: 1.549, Test accuracy: 91.59
Round  27, Train loss: 1.520, Test loss: 1.548, Test accuracy: 91.65
Round  28, Train loss: 1.520, Test loss: 1.546, Test accuracy: 91.91
Round  29, Train loss: 1.527, Test loss: 1.545, Test accuracy: 92.20
Round  30, Train loss: 1.519, Test loss: 1.545, Test accuracy: 92.03
Round  31, Train loss: 1.513, Test loss: 1.542, Test accuracy: 92.35
Round  32, Train loss: 1.518, Test loss: 1.543, Test accuracy: 92.21
Round  33, Train loss: 1.516, Test loss: 1.542, Test accuracy: 92.42
Round  34, Train loss: 1.513, Test loss: 1.542, Test accuracy: 92.30
Round  35, Train loss: 1.510, Test loss: 1.541, Test accuracy: 92.42
Round  36, Train loss: 1.507, Test loss: 1.540, Test accuracy: 92.62
Round  37, Train loss: 1.508, Test loss: 1.538, Test accuracy: 92.74
Round  38, Train loss: 1.506, Test loss: 1.537, Test accuracy: 92.69
Round  39, Train loss: 1.508, Test loss: 1.537, Test accuracy: 92.77
Round  40, Train loss: 1.504, Test loss: 1.537, Test accuracy: 92.83
Round  41, Train loss: 1.507, Test loss: 1.536, Test accuracy: 92.83
Round  42, Train loss: 1.503, Test loss: 1.536, Test accuracy: 92.89
Round  43, Train loss: 1.505, Test loss: 1.536, Test accuracy: 92.99
Round  44, Train loss: 1.500, Test loss: 1.536, Test accuracy: 92.96
Round  45, Train loss: 1.500, Test loss: 1.535, Test accuracy: 92.97
Round  46, Train loss: 1.500, Test loss: 1.534, Test accuracy: 93.28
Round  47, Train loss: 1.499, Test loss: 1.533, Test accuracy: 93.12
Round  48, Train loss: 1.498, Test loss: 1.533, Test accuracy: 93.28
Round  49, Train loss: 1.502, Test loss: 1.533, Test accuracy: 93.28
Round  50, Train loss: 1.496, Test loss: 1.532, Test accuracy: 93.28
Round  51, Train loss: 1.496, Test loss: 1.531, Test accuracy: 93.23
Round  52, Train loss: 1.497, Test loss: 1.531, Test accuracy: 93.37
Round  53, Train loss: 1.494, Test loss: 1.530, Test accuracy: 93.41
Round  54, Train loss: 1.498, Test loss: 1.530, Test accuracy: 93.53
Round  55, Train loss: 1.497, Test loss: 1.531, Test accuracy: 93.38
Round  56, Train loss: 1.496, Test loss: 1.529, Test accuracy: 93.53
Round  57, Train loss: 1.496, Test loss: 1.531, Test accuracy: 93.60
Round  58, Train loss: 1.498, Test loss: 1.530, Test accuracy: 93.46
Round  59, Train loss: 1.491, Test loss: 1.529, Test accuracy: 93.55
Round  60, Train loss: 1.494, Test loss: 1.529, Test accuracy: 93.45
Round  61, Train loss: 1.493, Test loss: 1.528, Test accuracy: 93.61
Round  62, Train loss: 1.493, Test loss: 1.528, Test accuracy: 93.52
Round  63, Train loss: 1.493, Test loss: 1.527, Test accuracy: 93.72
Round  64, Train loss: 1.490, Test loss: 1.528, Test accuracy: 93.82
Round  65, Train loss: 1.490, Test loss: 1.528, Test accuracy: 93.65
Round  66, Train loss: 1.492, Test loss: 1.527, Test accuracy: 93.73
Round  67, Train loss: 1.494, Test loss: 1.527, Test accuracy: 93.79
Round  68, Train loss: 1.492, Test loss: 1.526, Test accuracy: 93.92
Round  69, Train loss: 1.490, Test loss: 1.526, Test accuracy: 94.01
Round  70, Train loss: 1.489, Test loss: 1.525, Test accuracy: 94.05
Round  71, Train loss: 1.490, Test loss: 1.525, Test accuracy: 93.78
Round  72, Train loss: 1.491, Test loss: 1.525, Test accuracy: 94.03
Round  73, Train loss: 1.491, Test loss: 1.525, Test accuracy: 94.01
Round  74, Train loss: 1.489, Test loss: 1.524, Test accuracy: 93.99
Round  75, Train loss: 1.485, Test loss: 1.524, Test accuracy: 94.08
Round  76, Train loss: 1.491, Test loss: 1.524, Test accuracy: 94.11
Round  77, Train loss: 1.487, Test loss: 1.523, Test accuracy: 94.23
Round  78, Train loss: 1.488, Test loss: 1.523, Test accuracy: 94.26
Round  79, Train loss: 1.489, Test loss: 1.524, Test accuracy: 94.12
Round  80, Train loss: 1.487, Test loss: 1.523, Test accuracy: 94.12
Round  81, Train loss: 1.486, Test loss: 1.524, Test accuracy: 94.14
Round  82, Train loss: 1.486, Test loss: 1.523, Test accuracy: 94.08
Round  83, Train loss: 1.486, Test loss: 1.523, Test accuracy: 94.25
Round  84, Train loss: 1.488, Test loss: 1.522, Test accuracy: 94.30
Round  85, Train loss: 1.486, Test loss: 1.522, Test accuracy: 94.29
Round  86, Train loss: 1.483, Test loss: 1.522, Test accuracy: 94.28
Round  87, Train loss: 1.485, Test loss: 1.522, Test accuracy: 94.17
Round  88, Train loss: 1.485, Test loss: 1.522, Test accuracy: 94.23
Round  89, Train loss: 1.483, Test loss: 1.522, Test accuracy: 94.13
Round  90, Train loss: 1.485, Test loss: 1.522, Test accuracy: 94.22
Round  91, Train loss: 1.486, Test loss: 1.522, Test accuracy: 94.21
Round  92, Train loss: 1.483, Test loss: 1.521, Test accuracy: 94.33
Round  93, Train loss: 1.485, Test loss: 1.521, Test accuracy: 94.34
Round  94, Train loss: 1.484, Test loss: 1.522, Test accuracy: 94.24
Round  95, Train loss: 1.483, Test loss: 1.521, Test accuracy: 94.22
Round  96, Train loss: 1.485, Test loss: 1.522, Test accuracy: 94.22
Round  97, Train loss: 1.484, Test loss: 1.520, Test accuracy: 94.33
Round  98, Train loss: 1.484, Test loss: 1.520, Test accuracy: 94.46
Round  99, Train loss: 1.483, Test loss: 1.520, Test accuracy: 94.25
Final Round, Train loss: 1.483, Test loss: 1.520, Test accuracy: 94.33
Average accuracy final 10 rounds: 94.28249999999998
1374.7758951187134
[2.167560577392578, 4.187452554702759, 6.206372261047363, 8.13611626625061, 9.943491220474243, 11.772181987762451, 13.592665433883667, 15.436760902404785, 17.27616286277771, 19.093870401382446, 20.911854028701782, 22.732297897338867, 24.55814242362976, 26.38431692123413, 28.206812620162964, 30.027338981628418, 31.854971170425415, 33.697856187820435, 35.54997277259827, 37.37813901901245, 39.20071816444397, 41.04007935523987, 42.883721113204956, 44.733420610427856, 46.584619998931885, 48.43765997886658, 50.29206037521362, 52.10723614692688, 53.93441128730774, 55.78668999671936, 57.63603591918945, 59.468424558639526, 61.31986904144287, 63.152496337890625, 64.99055433273315, 66.82794094085693, 68.65861868858337, 70.48722243309021, 72.30945110321045, 74.13305735588074, 75.96314215660095, 77.79056596755981, 79.60504674911499, 81.433518409729, 83.26300358772278, 85.11545038223267, 86.96679377555847, 88.82262873649597, 90.67402935028076, 92.52325916290283, 94.3672091960907, 96.2171847820282, 98.04463958740234, 99.86787247657776, 101.69869089126587, 103.55353808403015, 105.38002967834473, 107.20612812042236, 109.03360509872437, 110.86336755752563, 112.68400692939758, 114.49940347671509, 116.33822679519653, 118.19349145889282, 120.04941439628601, 121.878253698349, 123.70870542526245, 125.53497529029846, 127.35242772102356, 129.17893409729004, 131.02926921844482, 132.85492777824402, 134.67797875404358, 136.50734400749207, 138.35346460342407, 140.18091106414795, 142.3080062866211, 144.4326298236847, 146.2587070465088, 148.0845308303833, 149.915531873703, 151.72329950332642, 153.53722476959229, 155.34362626075745, 157.1577010154724, 158.95815896987915, 160.77066588401794, 162.58046746253967, 164.39083075523376, 166.19850039482117, 168.01381993293762, 169.8220202922821, 171.60012221336365, 173.37460494041443, 175.1544268131256, 176.93489265441895, 178.7523193359375, 180.5451443195343, 182.35528755187988, 184.13167524337769, 185.9490625858307]/home/ChenSM/code/FL_HLS/utils/sampling.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[11.691666666666666, 26.808333333333334, 25.441666666666666, 29.625, 46.44166666666667, 64.91666666666667, 66.38333333333334, 73.375, 81.70833333333333, 82.60833333333333, 83.1, 83.75, 86.86666666666666, 88.33333333333333, 89.21666666666667, 89.94166666666666, 90.13333333333334, 90.55833333333334, 90.80833333333334, 90.975, 91.28333333333333, 91.44166666666666, 91.45, 91.40833333333333, 91.76666666666667, 91.76666666666667, 91.59166666666667, 91.65, 91.90833333333333, 92.2, 92.025, 92.35, 92.20833333333333, 92.425, 92.3, 92.425, 92.61666666666666, 92.74166666666666, 92.69166666666666, 92.76666666666667, 92.825, 92.83333333333333, 92.89166666666667, 92.99166666666666, 92.95833333333333, 92.975, 93.275, 93.11666666666666, 93.275, 93.275, 93.275, 93.23333333333333, 93.36666666666666, 93.40833333333333, 93.525, 93.38333333333334, 93.525, 93.6, 93.45833333333333, 93.55, 93.45, 93.60833333333333, 93.51666666666667, 93.725, 93.81666666666666, 93.65, 93.73333333333333, 93.79166666666667, 93.91666666666667, 94.00833333333334, 94.05, 93.775, 94.025, 94.00833333333334, 93.99166666666666, 94.075, 94.10833333333333, 94.23333333333333, 94.25833333333334, 94.125, 94.125, 94.14166666666667, 94.075, 94.25, 94.3, 94.29166666666667, 94.275, 94.16666666666667, 94.23333333333333, 94.13333333333334, 94.225, 94.20833333333333, 94.325, 94.34166666666667, 94.24166666666666, 94.21666666666667, 94.225, 94.33333333333333, 94.45833333333333, 94.25, 94.33333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.322, Test loss: 2.302, Test accuracy: 8.77
Round   1, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.67
Round   2, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.30
Round   3, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.06
Round   4, Train loss: 2.302, Test loss: 2.302, Test accuracy: 7.51
Round   5, Train loss: 2.302, Test loss: 2.302, Test accuracy: 7.42
Round   6, Train loss: 2.303, Test loss: 2.302, Test accuracy: 7.34
Round   7, Train loss: 2.302, Test loss: 2.302, Test accuracy: 6.85
Round   8, Train loss: 2.302, Test loss: 2.302, Test accuracy: 6.67
Round   9, Train loss: 2.302, Test loss: 2.302, Test accuracy: 6.75
Round  10, Train loss: 2.302, Test loss: 2.302, Test accuracy: 6.73
Round  11, Train loss: 2.302, Test loss: 2.302, Test accuracy: 7.08
Round  12, Train loss: 2.302, Test loss: 2.302, Test accuracy: 7.15
Round  13, Train loss: 2.302, Test loss: 2.302, Test accuracy: 7.23
Round  14, Train loss: 2.302, Test loss: 2.302, Test accuracy: 7.12
Round  15, Train loss: 2.302, Test loss: 2.302, Test accuracy: 6.87
Round  16, Train loss: 2.302, Test loss: 2.302, Test accuracy: 6.61
Round  17, Train loss: 2.302, Test loss: 2.302, Test accuracy: 6.71
Round  18, Train loss: 2.302, Test loss: 2.302, Test accuracy: 7.00
Round  19, Train loss: 2.302, Test loss: 2.302, Test accuracy: 7.02
Round  20, Train loss: 2.302, Test loss: 2.302, Test accuracy: 7.01
Round  21, Train loss: 2.302, Test loss: 2.302, Test accuracy: 7.13
Round  22, Train loss: 2.302, Test loss: 2.302, Test accuracy: 7.26
Round  23, Train loss: 2.302, Test loss: 2.302, Test accuracy: 7.30
Round  24, Train loss: 2.302, Test loss: 2.302, Test accuracy: 7.35
Round  25, Train loss: 2.302, Test loss: 2.302, Test accuracy: 7.34
Round  26, Train loss: 2.301, Test loss: 2.302, Test accuracy: 7.69
Round  27, Train loss: 2.301, Test loss: 2.302, Test accuracy: 7.69
Round  28, Train loss: 2.302, Test loss: 2.303, Test accuracy: 7.58
Round  29, Train loss: 2.301, Test loss: 2.303, Test accuracy: 7.78
Round  30, Train loss: 2.302, Test loss: 2.303, Test accuracy: 7.41
Round  31, Train loss: 2.302, Test loss: 2.303, Test accuracy: 7.43
Round  32, Train loss: 2.301, Test loss: 2.303, Test accuracy: 7.37
Round  33, Train loss: 2.301, Test loss: 2.303, Test accuracy: 7.33
Round  34, Train loss: 2.301, Test loss: 2.303, Test accuracy: 7.41
Round  35, Train loss: 2.301, Test loss: 2.303, Test accuracy: 7.32
Round  36, Train loss: 2.301, Test loss: 2.303, Test accuracy: 7.29
Round  37, Train loss: 2.301, Test loss: 2.303, Test accuracy: 7.04
Round  38, Train loss: 2.301, Test loss: 2.303, Test accuracy: 7.32
Round  39, Train loss: 2.301, Test loss: 2.303, Test accuracy: 7.45
Round  40, Train loss: 2.301, Test loss: 2.303, Test accuracy: 7.54
Round  41, Train loss: 2.301, Test loss: 2.303, Test accuracy: 7.55
Round  42, Train loss: 2.301, Test loss: 2.303, Test accuracy: 7.40
Round  43, Train loss: 2.301, Test loss: 2.303, Test accuracy: 7.39
Round  44, Train loss: 2.301, Test loss: 2.303, Test accuracy: 7.27
Round  45, Train loss: 2.301, Test loss: 2.303, Test accuracy: 7.33
Round  46, Train loss: 2.301, Test loss: 2.303, Test accuracy: 7.28
Round  47, Train loss: 2.301, Test loss: 2.303, Test accuracy: 7.43
Round  48, Train loss: 2.301, Test loss: 2.303, Test accuracy: 7.30
Round  49, Train loss: 2.301, Test loss: 2.303, Test accuracy: 7.29
Round  50, Train loss: 2.301, Test loss: 2.303, Test accuracy: 7.30
Round  51, Train loss: 2.300, Test loss: 2.303, Test accuracy: 7.55
Round  52, Train loss: 2.300, Test loss: 2.303, Test accuracy: 7.38
Round  53, Train loss: 2.300, Test loss: 2.303, Test accuracy: 7.32
Round  54, Train loss: 2.300, Test loss: 2.303, Test accuracy: 7.19
Round  55, Train loss: 2.300, Test loss: 2.303, Test accuracy: 7.23
Round  56, Train loss: 2.300, Test loss: 2.303, Test accuracy: 7.35
Round  57, Train loss: 2.299, Test loss: 2.303, Test accuracy: 7.36
Round  58, Train loss: 2.300, Test loss: 2.303, Test accuracy: 7.45
Round  59, Train loss: 2.300, Test loss: 2.303, Test accuracy: 7.33
Round  60, Train loss: 2.299, Test loss: 2.303, Test accuracy: 7.43
Round  61, Train loss: 2.299, Test loss: 2.303, Test accuracy: 7.64
Round  62, Train loss: 2.299, Test loss: 2.303, Test accuracy: 7.59
Round  63, Train loss: 2.299, Test loss: 2.303, Test accuracy: 7.58
Round  64, Train loss: 2.299, Test loss: 2.304, Test accuracy: 7.62
Round  65, Train loss: 2.300, Test loss: 2.304, Test accuracy: 7.62
Round  66, Train loss: 2.299, Test loss: 2.304, Test accuracy: 7.69
Round  67, Train loss: 2.299, Test loss: 2.304, Test accuracy: 7.83
Round  68, Train loss: 2.298, Test loss: 2.304, Test accuracy: 7.79
Round  69, Train loss: 2.298, Test loss: 2.304, Test accuracy: 7.77
Round  70, Train loss: 2.298, Test loss: 2.304, Test accuracy: 7.80
Round  71, Train loss: 2.298, Test loss: 2.304, Test accuracy: 7.99
Round  72, Train loss: 2.299, Test loss: 2.304, Test accuracy: 8.08
Round  73, Train loss: 2.298, Test loss: 2.304, Test accuracy: 8.13
Round  74, Train loss: 2.298, Test loss: 2.305, Test accuracy: 8.21
Round  75, Train loss: 2.297, Test loss: 2.305, Test accuracy: 8.35
Round  76, Train loss: 2.298, Test loss: 2.305, Test accuracy: 8.37
Round  77, Train loss: 2.298, Test loss: 2.305, Test accuracy: 8.42
Round  78, Train loss: 2.298, Test loss: 2.305, Test accuracy: 8.59
Round  79, Train loss: 2.297, Test loss: 2.305, Test accuracy: 8.57
Round  80, Train loss: 2.297, Test loss: 2.305, Test accuracy: 8.61
Round  81, Train loss: 2.297, Test loss: 2.305, Test accuracy: 8.68
Round  82, Train loss: 2.298, Test loss: 2.305, Test accuracy: 8.74
Round  83, Train loss: 2.298, Test loss: 2.305, Test accuracy: 8.73
Round  84, Train loss: 2.297, Test loss: 2.305, Test accuracy: 8.79
Round  85, Train loss: 2.297, Test loss: 2.305, Test accuracy: 8.81
Round  86, Train loss: 2.296, Test loss: 2.305, Test accuracy: 8.87
Round  87, Train loss: 2.297, Test loss: 2.306, Test accuracy: 8.91
Round  88, Train loss: 2.296, Test loss: 2.306, Test accuracy: 8.91
Round  89, Train loss: 2.296, Test loss: 2.306, Test accuracy: 8.95
Round  90, Train loss: 2.296, Test loss: 2.306, Test accuracy: 9.00
Round  91, Train loss: 2.294, Test loss: 2.306, Test accuracy: 8.99
Round  92, Train loss: 2.296, Test loss: 2.306, Test accuracy: 8.95
Round  93, Train loss: 2.297, Test loss: 2.306, Test accuracy: 8.94
Round  94, Train loss: 2.295, Test loss: 2.306, Test accuracy: 8.95
Round  95, Train loss: 2.296, Test loss: 2.307, Test accuracy: 8.98/home/ChenSM/code/FL_HLS/utils/sampling.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 2.296, Test loss: 2.307, Test accuracy: 9.06
Round  97, Train loss: 2.293, Test loss: 2.307, Test accuracy: 9.06
Round  98, Train loss: 2.296, Test loss: 2.307, Test accuracy: 9.06
Round  99, Train loss: 2.294, Test loss: 2.307, Test accuracy: 9.05
Final Round, Train loss: 2.294, Test loss: 2.308, Test accuracy: 9.04
Average accuracy final 10 rounds: 9.0045
1348.3984599113464
[1.0372323989868164, 1.9125072956085205, 2.7745518684387207, 3.6463794708251953, 4.511243581771851, 5.38986873626709, 6.256757974624634, 7.156548976898193, 7.932474374771118, 8.794819355010986, 9.65129566192627, 10.51368761062622, 11.374762296676636, 12.24022364616394, 13.106030225753784, 13.974013805389404, 14.842626333236694, 15.708485126495361, 16.575552463531494, 17.437601804733276, 18.306498527526855, 19.17211604118347, 20.039499521255493, 20.902031898498535, 21.76968026161194, 22.633233308792114, 23.500731945037842, 24.36290168762207, 25.231526374816895, 26.09182596206665, 26.958958625793457, 27.82048773765564, 28.68865990638733, 29.549376487731934, 30.419408321380615, 31.279245615005493, 32.14899182319641, 33.00840640068054, 33.87479281425476, 34.73414659500122, 35.604206562042236, 36.46461892127991, 37.33252811431885, 38.19390630722046, 39.06109595298767, 39.918835163116455, 40.78565979003906, 41.645100116729736, 42.51009678840637, 43.37534999847412, 44.23873043060303, 45.095316648483276, 45.95754909515381, 46.81556510925293, 47.680503606796265, 48.53944659233093, 49.40231657028198, 50.260008573532104, 51.12319493293762, 51.98584032058716, 52.848642110824585, 53.70542311668396, 54.56607532501221, 55.420079708099365, 56.28310036659241, 57.13651132583618, 57.99785614013672, 58.85055112838745, 59.70962429046631, 60.56537342071533, 61.42164969444275, 62.27472805976868, 63.13483953475952, 63.98958230018616, 64.85216999053955, 65.70507311820984, 66.56238341331482, 67.42151498794556, 68.28436779975891, 69.14706325531006, 70.0064845085144, 70.87285852432251, 71.73210263252258, 72.59786462783813, 73.4579131603241, 74.33195090293884, 75.1945686340332, 76.06310057640076, 76.92774200439453, 77.79499506950378, 78.65703582763672, 79.5246012210846, 80.38877606391907, 81.25526309013367, 82.11486768722534, 82.98404717445374, 83.84589171409607, 84.71115970611572, 85.57690834999084, 86.44857406616211, 87.7477195262909]
[8.7725, 8.67, 8.2975, 8.06, 7.51, 7.4225, 7.345, 6.8475, 6.6725, 6.7525, 6.73, 7.0825, 7.1475, 7.2275, 7.125, 6.87, 6.6125, 6.715, 7.0, 7.0175, 7.01, 7.1325, 7.26, 7.305, 7.3475, 7.34, 7.6875, 7.6875, 7.585, 7.7775, 7.405, 7.435, 7.365, 7.3325, 7.405, 7.315, 7.2925, 7.0375, 7.3225, 7.445, 7.535, 7.5475, 7.3975, 7.39, 7.2725, 7.33, 7.275, 7.4325, 7.305, 7.2875, 7.3025, 7.5475, 7.385, 7.315, 7.19, 7.23, 7.3525, 7.3625, 7.45, 7.33, 7.4275, 7.645, 7.5875, 7.585, 7.625, 7.6175, 7.69, 7.835, 7.7925, 7.7675, 7.7975, 7.985, 8.0825, 8.13, 8.2125, 8.345, 8.3725, 8.4225, 8.585, 8.5725, 8.6075, 8.68, 8.745, 8.735, 8.795, 8.815, 8.8725, 8.915, 8.9125, 8.95, 8.9975, 8.9875, 8.9475, 8.9375, 8.9525, 8.9825, 9.0625, 9.0625, 9.06, 9.055, 9.045]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
401408
401920
532992
533248
549632
549696
550336
550346
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.321, Test loss: 2.301, Test accuracy: 12.09
Round   1, Train loss: 2.316, Test loss: 2.298, Test accuracy: 14.86
Round   2, Train loss: 2.308, Test loss: 2.292, Test accuracy: 19.79
Round   3, Train loss: 2.296, Test loss: 2.281, Test accuracy: 25.61
Round   4, Train loss: 2.273, Test loss: 2.250, Test accuracy: 26.62
Round   5, Train loss: 2.235, Test loss: 2.199, Test accuracy: 33.48
Round   6, Train loss: 2.183, Test loss: 2.145, Test accuracy: 43.23
Round   7, Train loss: 2.121, Test loss: 2.074, Test accuracy: 46.75
Round   8, Train loss: 2.047, Test loss: 2.027, Test accuracy: 50.49
Round   9, Train loss: 2.018, Test loss: 1.996, Test accuracy: 55.17
Round  10, Train loss: 2.004, Test loss: 1.971, Test accuracy: 58.96
Round  11, Train loss: 1.987, Test loss: 1.942, Test accuracy: 62.26
Round  12, Train loss: 1.947, Test loss: 1.913, Test accuracy: 63.95
Round  13, Train loss: 1.915, Test loss: 1.887, Test accuracy: 66.59
Round  14, Train loss: 1.893, Test loss: 1.864, Test accuracy: 68.11
Round  15, Train loss: 1.873, Test loss: 1.842, Test accuracy: 70.89
Round  16, Train loss: 1.861, Test loss: 1.821, Test accuracy: 72.85
Round  17, Train loss: 1.827, Test loss: 1.806, Test accuracy: 74.50
Round  18, Train loss: 1.822, Test loss: 1.786, Test accuracy: 76.45
Round  19, Train loss: 1.794, Test loss: 1.773, Test accuracy: 79.27
Round  20, Train loss: 1.778, Test loss: 1.751, Test accuracy: 82.89
Round  21, Train loss: 1.771, Test loss: 1.719, Test accuracy: 86.25
Round  22, Train loss: 1.722, Test loss: 1.700, Test accuracy: 87.71
Round  23, Train loss: 1.710, Test loss: 1.684, Test accuracy: 89.00
Round  24, Train loss: 1.696, Test loss: 1.669, Test accuracy: 89.91
Round  25, Train loss: 1.692, Test loss: 1.653, Test accuracy: 90.57
Round  26, Train loss: 1.685, Test loss: 1.639, Test accuracy: 90.94
Round  27, Train loss: 1.672, Test loss: 1.631, Test accuracy: 91.29
Round  28, Train loss: 1.655, Test loss: 1.626, Test accuracy: 91.48
Round  29, Train loss: 1.650, Test loss: 1.621, Test accuracy: 91.76
Round  30, Train loss: 1.639, Test loss: 1.618, Test accuracy: 91.98
Round  31, Train loss: 1.642, Test loss: 1.613, Test accuracy: 92.16
Round  32, Train loss: 1.624, Test loss: 1.611, Test accuracy: 92.33
Round  33, Train loss: 1.622, Test loss: 1.608, Test accuracy: 92.44
Round  34, Train loss: 1.632, Test loss: 1.600, Test accuracy: 92.64
Round  35, Train loss: 1.616, Test loss: 1.600, Test accuracy: 92.70
Round  36, Train loss: 1.618, Test loss: 1.595, Test accuracy: 92.85
Round  37, Train loss: 1.611, Test loss: 1.591, Test accuracy: 93.07
Round  38, Train loss: 1.604, Test loss: 1.589, Test accuracy: 93.22
Round  39, Train loss: 1.615, Test loss: 1.584, Test accuracy: 93.36
Round  40, Train loss: 1.596, Test loss: 1.585, Test accuracy: 93.42
Round  41, Train loss: 1.598, Test loss: 1.582, Test accuracy: 93.51
Round  42, Train loss: 1.601, Test loss: 1.577, Test accuracy: 93.68
Round  43, Train loss: 1.592, Test loss: 1.577, Test accuracy: 93.85
Round  44, Train loss: 1.577, Test loss: 1.578, Test accuracy: 93.86
Round  45, Train loss: 1.579, Test loss: 1.576, Test accuracy: 93.82
Round  46, Train loss: 1.589, Test loss: 1.572, Test accuracy: 93.98
Round  47, Train loss: 1.583, Test loss: 1.570, Test accuracy: 94.00
Round  48, Train loss: 1.573, Test loss: 1.571, Test accuracy: 94.12
Round  49, Train loss: 1.573, Test loss: 1.569, Test accuracy: 94.15
Round  50, Train loss: 1.581, Test loss: 1.566, Test accuracy: 94.24
Round  51, Train loss: 1.566, Test loss: 1.566, Test accuracy: 94.40
Round  52, Train loss: 1.572, Test loss: 1.564, Test accuracy: 94.38
Round  53, Train loss: 1.578, Test loss: 1.561, Test accuracy: 94.41
Round  54, Train loss: 1.561, Test loss: 1.563, Test accuracy: 94.37
Round  55, Train loss: 1.565, Test loss: 1.562, Test accuracy: 94.40
Round  56, Train loss: 1.562, Test loss: 1.560, Test accuracy: 94.48
Round  57, Train loss: 1.560, Test loss: 1.559, Test accuracy: 94.56
Round  58, Train loss: 1.561, Test loss: 1.557, Test accuracy: 94.63
Round  59, Train loss: 1.553, Test loss: 1.557, Test accuracy: 94.70
Round  60, Train loss: 1.553, Test loss: 1.558, Test accuracy: 94.67
Round  61, Train loss: 1.553, Test loss: 1.556, Test accuracy: 94.72
Round  62, Train loss: 1.548, Test loss: 1.556, Test accuracy: 94.78
Round  63, Train loss: 1.544, Test loss: 1.556, Test accuracy: 94.77
Round  64, Train loss: 1.552, Test loss: 1.553, Test accuracy: 94.79
Round  65, Train loss: 1.544, Test loss: 1.554, Test accuracy: 94.82
Round  66, Train loss: 1.545, Test loss: 1.552, Test accuracy: 94.95
Round  67, Train loss: 1.545, Test loss: 1.552, Test accuracy: 94.93
Round  68, Train loss: 1.546, Test loss: 1.551, Test accuracy: 94.94
Round  69, Train loss: 1.550, Test loss: 1.548, Test accuracy: 94.98
Round  70, Train loss: 1.539, Test loss: 1.550, Test accuracy: 94.98
Round  71, Train loss: 1.541, Test loss: 1.549, Test accuracy: 95.02
Round  72, Train loss: 1.538, Test loss: 1.549, Test accuracy: 95.01
Round  73, Train loss: 1.539, Test loss: 1.548, Test accuracy: 95.09
Round  74, Train loss: 1.543, Test loss: 1.546, Test accuracy: 95.07
Round  75, Train loss: 1.535, Test loss: 1.547, Test accuracy: 95.18
Round  76, Train loss: 1.541, Test loss: 1.544, Test accuracy: 95.17
Round  77, Train loss: 1.539, Test loss: 1.544, Test accuracy: 95.18
Round  78, Train loss: 1.537, Test loss: 1.544, Test accuracy: 95.18
Round  79, Train loss: 1.531, Test loss: 1.546, Test accuracy: 95.28
Round  80, Train loss: 1.538, Test loss: 1.543, Test accuracy: 95.27
Round  81, Train loss: 1.532, Test loss: 1.543, Test accuracy: 95.39
Round  82, Train loss: 1.533, Test loss: 1.542, Test accuracy: 95.43
Round  83, Train loss: 1.534, Test loss: 1.541, Test accuracy: 95.42
Round  84, Train loss: 1.528, Test loss: 1.542, Test accuracy: 95.39
Round  85, Train loss: 1.530, Test loss: 1.541, Test accuracy: 95.42
Round  86, Train loss: 1.527, Test loss: 1.541, Test accuracy: 95.43
Round  87, Train loss: 1.524, Test loss: 1.541, Test accuracy: 95.54
Round  88, Train loss: 1.523, Test loss: 1.541, Test accuracy: 95.55
Round  89, Train loss: 1.523, Test loss: 1.540, Test accuracy: 95.64
Round  90, Train loss: 1.523, Test loss: 1.540, Test accuracy: 95.63
Round  91, Train loss: 1.525, Test loss: 1.539, Test accuracy: 95.68
Round  92, Train loss: 1.522, Test loss: 1.539, Test accuracy: 95.70
Round  93, Train loss: 1.520, Test loss: 1.539, Test accuracy: 95.72/home/ChenSM/code/FL_HLS/utils/sampling.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Train loss: 1.521, Test loss: 1.540, Test accuracy: 95.72
Round  95, Train loss: 1.527, Test loss: 1.536, Test accuracy: 95.72
Round  96, Train loss: 1.521, Test loss: 1.537, Test accuracy: 95.73
Round  97, Train loss: 1.520, Test loss: 1.537, Test accuracy: 95.74
Round  98, Train loss: 1.519, Test loss: 1.537, Test accuracy: 95.74
Round  99, Train loss: 1.515, Test loss: 1.538, Test accuracy: 95.78
Final Round, Train loss: 1.495, Test loss: 1.532, Test accuracy: 95.77
Average accuracy final 10 rounds: 95.71475000000001
1321.87154006958
[0.9835460186004639, 1.8451042175292969, 2.7020857334136963, 3.5609114170074463, 4.418253183364868, 5.279950380325317, 6.140278577804565, 6.997110605239868, 7.8564605712890625, 8.724778175354004, 9.581104516983032, 10.447983503341675, 11.311675310134888, 12.177855730056763, 13.044528722763062, 13.905204772949219, 14.777242183685303, 15.638170957565308, 16.505834579467773, 17.366734266281128, 18.224811792373657, 19.08313012123108, 19.949543714523315, 20.808690071105957, 21.67358088493347, 22.52927327156067, 23.392956495285034, 24.247897148132324, 25.110564947128296, 25.962742567062378, 26.825227737426758, 27.67964816093445, 28.543838024139404, 29.39844250679016, 30.2702898979187, 31.12434673309326, 32.00019454956055, 32.85400581359863, 33.731001138687134, 34.58234477043152, 35.4597430229187, 36.31439661979675, 37.1915009021759, 38.04280161857605, 38.91740441322327, 39.77880668640137, 40.65808391571045, 41.51383185386658, 42.39049172401428, 43.24687314033508, 44.12210130691528, 44.97822904586792, 45.84621858596802, 46.70668292045593, 47.60627102851868, 48.394174337387085, 49.19890284538269, 49.98069620132446, 50.78219127655029, 51.56544876098633, 52.35594177246094, 53.14208769798279, 53.930503606796265, 54.71644067764282, 55.50067067146301, 56.2905957698822, 57.0777792930603, 57.860004901885986, 58.64324593544006, 59.42679190635681, 60.21247363090515, 60.997589111328125, 61.78375506401062, 62.58319139480591, 63.36949419975281, 64.16598176956177, 64.94766449928284, 65.73461675643921, 66.51329731941223, 67.30468320846558, 68.08885979652405, 68.87180423736572, 69.65102982521057, 70.43931293487549, 71.2244622707367, 72.0147910118103, 72.81078290939331, 73.59855556488037, 74.38722133636475, 75.17268538475037, 75.96339344978333, 76.74326825141907, 77.53306317329407, 78.31861138343811, 79.10362577438354, 79.88593435287476, 80.6758246421814, 81.46194529533386, 82.24741220474243, 83.03685474395752, 84.35057497024536]
[12.0925, 14.8625, 19.7925, 25.6125, 26.6225, 33.475, 43.2275, 46.7475, 50.4925, 55.175, 58.96, 62.26, 63.955, 66.5925, 68.105, 70.8875, 72.85, 74.4975, 76.4525, 79.265, 82.89, 86.2525, 87.71, 88.9975, 89.9075, 90.5725, 90.94, 91.29, 91.48, 91.76, 91.9775, 92.1625, 92.335, 92.44, 92.635, 92.6975, 92.85, 93.0675, 93.2225, 93.3575, 93.415, 93.51, 93.6775, 93.85, 93.8625, 93.8225, 93.985, 94.0025, 94.125, 94.15, 94.2425, 94.3975, 94.375, 94.405, 94.3725, 94.3975, 94.48, 94.5575, 94.6325, 94.7025, 94.6725, 94.7225, 94.7825, 94.765, 94.7875, 94.8175, 94.9475, 94.9275, 94.945, 94.9775, 94.98, 95.0225, 95.01, 95.095, 95.07, 95.1775, 95.165, 95.18, 95.1825, 95.275, 95.2675, 95.385, 95.43, 95.42, 95.385, 95.42, 95.4325, 95.54, 95.545, 95.635, 95.6275, 95.68, 95.6975, 95.715, 95.72, 95.7175, 95.7275, 95.74, 95.7425, 95.78, 95.7675]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.226, Test loss: 2.194, Test accuracy: 35.85 

Round   0, Global train loss: 2.226, Global test loss: 2.283, Global test accuracy: 28.64 

Round   1, Train loss: 1.767, Test loss: 2.051, Test accuracy: 38.91 

Round   1, Global train loss: 1.767, Global test loss: 2.243, Global test accuracy: 17.64 

Round   2, Train loss: 1.867, Test loss: 1.895, Test accuracy: 63.51 

Round   2, Global train loss: 1.867, Global test loss: 2.161, Global test accuracy: 39.24 

Round   3, Train loss: 1.660, Test loss: 1.835, Test accuracy: 65.17 

Round   3, Global train loss: 1.660, Global test loss: 2.202, Global test accuracy: 27.46 

Round   4, Train loss: 1.589, Test loss: 1.699, Test accuracy: 80.38 

Round   4, Global train loss: 1.589, Global test loss: 2.126, Global test accuracy: 37.63 

Round   5, Train loss: 1.712, Test loss: 1.651, Test accuracy: 84.39 

Round   5, Global train loss: 1.712, Global test loss: 2.203, Global test accuracy: 23.41 

Round   6, Train loss: 1.645, Test loss: 1.636, Test accuracy: 84.60 

Round   6, Global train loss: 1.645, Global test loss: 2.196, Global test accuracy: 20.68 

Round   7, Train loss: 1.748, Test loss: 1.634, Test accuracy: 84.65 

Round   7, Global train loss: 1.748, Global test loss: 2.217, Global test accuracy: 25.37 

Round   8, Train loss: 1.638, Test loss: 1.612, Test accuracy: 86.45 

Round   8, Global train loss: 1.638, Global test loss: 2.098, Global test accuracy: 34.37 

Round   9, Train loss: 1.554, Test loss: 1.603, Test accuracy: 86.94 

Round   9, Global train loss: 1.554, Global test loss: 2.243, Global test accuracy: 15.43 

Round  10, Train loss: 1.589, Test loss: 1.599, Test accuracy: 86.98 

Round  10, Global train loss: 1.589, Global test loss: 2.098, Global test accuracy: 34.99 

Round  11, Train loss: 1.579, Test loss: 1.598, Test accuracy: 87.01 

Round  11, Global train loss: 1.579, Global test loss: 2.083, Global test accuracy: 40.40 

Round  12, Train loss: 1.591, Test loss: 1.597, Test accuracy: 87.08 

Round  12, Global train loss: 1.591, Global test loss: 2.187, Global test accuracy: 22.09 

Round  13, Train loss: 1.636, Test loss: 1.597, Test accuracy: 87.08 

Round  13, Global train loss: 1.636, Global test loss: 2.212, Global test accuracy: 19.72 

Round  14, Train loss: 1.683, Test loss: 1.596, Test accuracy: 87.11 

Round  14, Global train loss: 1.683, Global test loss: 2.180, Global test accuracy: 30.12 

Round  15, Train loss: 1.533, Test loss: 1.594, Test accuracy: 87.17 

Round  15, Global train loss: 1.533, Global test loss: 2.110, Global test accuracy: 34.68 

Round  16, Train loss: 1.523, Test loss: 1.594, Test accuracy: 87.12 

Round  16, Global train loss: 1.523, Global test loss: 2.156, Global test accuracy: 25.77 

Round  17, Train loss: 1.553, Test loss: 1.581, Test accuracy: 88.44 

Round  17, Global train loss: 1.553, Global test loss: 2.141, Global test accuracy: 30.95 

Round  18, Train loss: 1.524, Test loss: 1.581, Test accuracy: 88.52 

Round  18, Global train loss: 1.524, Global test loss: 2.080, Global test accuracy: 49.48 

Round  19, Train loss: 1.608, Test loss: 1.568, Test accuracy: 90.02 

Round  19, Global train loss: 1.608, Global test loss: 2.201, Global test accuracy: 28.93 

Round  20, Train loss: 1.526, Test loss: 1.566, Test accuracy: 90.04 

Round  20, Global train loss: 1.526, Global test loss: 2.153, Global test accuracy: 27.99 

Round  21, Train loss: 1.576, Test loss: 1.566, Test accuracy: 90.06 

Round  21, Global train loss: 1.576, Global test loss: 2.115, Global test accuracy: 38.40 

Round  22, Train loss: 1.528, Test loss: 1.565, Test accuracy: 90.08 

Round  22, Global train loss: 1.528, Global test loss: 2.200, Global test accuracy: 23.88 

Round  23, Train loss: 1.467, Test loss: 1.565, Test accuracy: 90.05 

Round  23, Global train loss: 1.467, Global test loss: 2.125, Global test accuracy: 39.06 

Round  24, Train loss: 1.530, Test loss: 1.564, Test accuracy: 90.02 

Round  24, Global train loss: 1.530, Global test loss: 2.100, Global test accuracy: 36.98 

Round  25, Train loss: 1.580, Test loss: 1.564, Test accuracy: 90.06 

Round  25, Global train loss: 1.580, Global test loss: 2.178, Global test accuracy: 28.22 

Round  26, Train loss: 1.578, Test loss: 1.564, Test accuracy: 89.98 

Round  26, Global train loss: 1.578, Global test loss: 2.064, Global test accuracy: 45.32 

Round  27, Train loss: 1.523, Test loss: 1.564, Test accuracy: 89.97 

Round  27, Global train loss: 1.523, Global test loss: 2.154, Global test accuracy: 38.33 

Round  28, Train loss: 1.521, Test loss: 1.564, Test accuracy: 90.03 

Round  28, Global train loss: 1.521, Global test loss: 2.070, Global test accuracy: 40.58 

Round  29, Train loss: 1.518, Test loss: 1.551, Test accuracy: 91.50 

Round  29, Global train loss: 1.518, Global test loss: 2.102, Global test accuracy: 42.62 

Round  30, Train loss: 1.465, Test loss: 1.551, Test accuracy: 91.53 

Round  30, Global train loss: 1.465, Global test loss: 2.115, Global test accuracy: 31.77 

Round  31, Train loss: 1.476, Test loss: 1.547, Test accuracy: 91.66 

Round  31, Global train loss: 1.476, Global test loss: 2.014, Global test accuracy: 45.28 

Round  32, Train loss: 1.604, Test loss: 1.534, Test accuracy: 93.13 

Round  32, Global train loss: 1.604, Global test loss: 2.153, Global test accuracy: 27.53 

Round  33, Train loss: 1.525, Test loss: 1.534, Test accuracy: 93.14 

Round  33, Global train loss: 1.525, Global test loss: 2.155, Global test accuracy: 27.01 

Round  34, Train loss: 1.469, Test loss: 1.532, Test accuracy: 93.17 

Round  34, Global train loss: 1.469, Global test loss: 2.069, Global test accuracy: 38.96 

Round  35, Train loss: 1.467, Test loss: 1.532, Test accuracy: 93.21 

Round  35, Global train loss: 1.467, Global test loss: 2.150, Global test accuracy: 27.62 

Round  36, Train loss: 1.522, Test loss: 1.532, Test accuracy: 93.23 

Round  36, Global train loss: 1.522, Global test loss: 2.213, Global test accuracy: 21.08 

Round  37, Train loss: 1.520, Test loss: 1.532, Test accuracy: 93.22 

Round  37, Global train loss: 1.520, Global test loss: 2.206, Global test accuracy: 24.67 

Round  38, Train loss: 1.468, Test loss: 1.532, Test accuracy: 93.20 

Round  38, Global train loss: 1.468, Global test loss: 2.025, Global test accuracy: 42.92 

Round  39, Train loss: 1.519, Test loss: 1.532, Test accuracy: 93.20 

Round  39, Global train loss: 1.519, Global test loss: 2.038, Global test accuracy: 48.63 

Round  40, Train loss: 1.519, Test loss: 1.532, Test accuracy: 93.21 

Round  40, Global train loss: 1.519, Global test loss: 2.124, Global test accuracy: 34.42 

Round  41, Train loss: 1.518, Test loss: 1.532, Test accuracy: 93.23 

Round  41, Global train loss: 1.518, Global test loss: 2.076, Global test accuracy: 39.93 

Round  42, Train loss: 1.518, Test loss: 1.532, Test accuracy: 93.26 

Round  42, Global train loss: 1.518, Global test loss: 2.160, Global test accuracy: 22.79 

Round  43, Train loss: 1.525, Test loss: 1.531, Test accuracy: 93.30 

Round  43, Global train loss: 1.525, Global test loss: 2.135, Global test accuracy: 34.67 

Round  44, Train loss: 1.521, Test loss: 1.531, Test accuracy: 93.32 

Round  44, Global train loss: 1.521, Global test loss: 2.131, Global test accuracy: 36.33 

Round  45, Train loss: 1.523, Test loss: 1.531, Test accuracy: 93.32 

Round  45, Global train loss: 1.523, Global test loss: 2.088, Global test accuracy: 36.12 

Round  46, Train loss: 1.521, Test loss: 1.531, Test accuracy: 93.32 

Round  46, Global train loss: 1.521, Global test loss: 2.080, Global test accuracy: 51.90 

Round  47, Train loss: 1.467, Test loss: 1.531, Test accuracy: 93.33 

Round  47, Global train loss: 1.467, Global test loss: 2.254, Global test accuracy: 16.47 

Round  48, Train loss: 1.520, Test loss: 1.531, Test accuracy: 93.37 

Round  48, Global train loss: 1.520, Global test loss: 2.188, Global test accuracy: 22.87 

Round  49, Train loss: 1.467, Test loss: 1.531, Test accuracy: 93.34 

Round  49, Global train loss: 1.467, Global test loss: 2.261, Global test accuracy: 13.63 

Round  50, Train loss: 1.465, Test loss: 1.531, Test accuracy: 93.33 

Round  50, Global train loss: 1.465, Global test loss: 2.210, Global test accuracy: 20.98 

Round  51, Train loss: 1.464, Test loss: 1.531, Test accuracy: 93.34 

Round  51, Global train loss: 1.464, Global test loss: 2.152, Global test accuracy: 30.38 

Round  52, Train loss: 1.517, Test loss: 1.531, Test accuracy: 93.33 

Round  52, Global train loss: 1.517, Global test loss: 2.146, Global test accuracy: 31.12 

Round  53, Train loss: 1.521, Test loss: 1.531, Test accuracy: 93.34 

Round  53, Global train loss: 1.521, Global test loss: 1.993, Global test accuracy: 50.54 

Round  54, Train loss: 1.466, Test loss: 1.531, Test accuracy: 93.37 

Round  54, Global train loss: 1.466, Global test loss: 2.080, Global test accuracy: 36.88 

Round  55, Train loss: 1.506, Test loss: 1.519, Test accuracy: 94.66 

Round  55, Global train loss: 1.506, Global test loss: 2.205, Global test accuracy: 24.13 

Round  56, Train loss: 1.523, Test loss: 1.519, Test accuracy: 94.64 

Round  56, Global train loss: 1.523, Global test loss: 2.103, Global test accuracy: 34.14 

Round  57, Train loss: 1.466, Test loss: 1.519, Test accuracy: 94.64 

Round  57, Global train loss: 1.466, Global test loss: 2.143, Global test accuracy: 31.74 

Round  58, Train loss: 1.465, Test loss: 1.519, Test accuracy: 94.65 

Round  58, Global train loss: 1.465, Global test loss: 2.082, Global test accuracy: 41.95 

Round  59, Train loss: 1.522, Test loss: 1.519, Test accuracy: 94.65 

Round  59, Global train loss: 1.522, Global test loss: 2.115, Global test accuracy: 37.10 

Round  60, Train loss: 1.464, Test loss: 1.519, Test accuracy: 94.64 

Round  60, Global train loss: 1.464, Global test loss: 2.037, Global test accuracy: 48.17 

Round  61, Train loss: 1.474, Test loss: 1.517, Test accuracy: 94.70 

Round  61, Global train loss: 1.474, Global test loss: 2.186, Global test accuracy: 20.34 

Round  62, Train loss: 1.467, Test loss: 1.518, Test accuracy: 94.69 

Round  62, Global train loss: 1.467, Global test loss: 2.194, Global test accuracy: 24.22 

Round  63, Train loss: 1.525, Test loss: 1.517, Test accuracy: 94.77 

Round  63, Global train loss: 1.525, Global test loss: 2.152, Global test accuracy: 29.91 

Round  64, Train loss: 1.467, Test loss: 1.517, Test accuracy: 94.77 

Round  64, Global train loss: 1.467, Global test loss: 2.076, Global test accuracy: 34.95 

Round  65, Train loss: 1.522, Test loss: 1.516, Test accuracy: 94.77 

Round  65, Global train loss: 1.522, Global test loss: 2.191, Global test accuracy: 24.84 

Round  66, Train loss: 1.469, Test loss: 1.517, Test accuracy: 94.70 

Round  66, Global train loss: 1.469, Global test loss: 2.277, Global test accuracy: 16.18 

Round  67, Train loss: 1.464, Test loss: 1.517, Test accuracy: 94.70 

Round  67, Global train loss: 1.464, Global test loss: 2.062, Global test accuracy: 38.28 

Round  68, Train loss: 1.522, Test loss: 1.516, Test accuracy: 94.71 

Round  68, Global train loss: 1.522, Global test loss: 2.109, Global test accuracy: 39.24 

Round  69, Train loss: 1.522, Test loss: 1.516, Test accuracy: 94.71 

Round  69, Global train loss: 1.522, Global test loss: 2.092, Global test accuracy: 44.51 

Round  70, Train loss: 1.464, Test loss: 1.516, Test accuracy: 94.72 

Round  70, Global train loss: 1.464, Global test loss: 2.058, Global test accuracy: 43.92 

Round  71, Train loss: 1.468, Test loss: 1.516, Test accuracy: 94.72 

Round  71, Global train loss: 1.468, Global test loss: 2.254, Global test accuracy: 17.24 

Round  72, Train loss: 1.523, Test loss: 1.516, Test accuracy: 94.73 

Round  72, Global train loss: 1.523, Global test loss: 2.102, Global test accuracy: 31.70 

Round  73, Train loss: 1.465, Test loss: 1.516, Test accuracy: 94.74 

Round  73, Global train loss: 1.465, Global test loss: 2.162, Global test accuracy: 22.64 

Round  74, Train loss: 1.462, Test loss: 1.516, Test accuracy: 94.74 

Round  74, Global train loss: 1.462, Global test loss: 2.081, Global test accuracy: 40.91 

Round  75, Train loss: 1.466, Test loss: 1.516, Test accuracy: 94.73 

Round  75, Global train loss: 1.466, Global test loss: 2.261, Global test accuracy: 13.91 

Round  76, Train loss: 1.465, Test loss: 1.516, Test accuracy: 94.73 

Round  76, Global train loss: 1.465, Global test loss: 2.144, Global test accuracy: 27.88 

Round  77, Train loss: 1.464, Test loss: 1.516, Test accuracy: 94.73 

Round  77, Global train loss: 1.464, Global test loss: 2.076, Global test accuracy: 45.16 

Round  78, Train loss: 1.462, Test loss: 1.516, Test accuracy: 94.73 

Round  78, Global train loss: 1.462, Global test loss: 2.097, Global test accuracy: 41.56 

Round  79, Train loss: 1.522, Test loss: 1.516, Test accuracy: 94.74 

Round  79, Global train loss: 1.522, Global test loss: 2.169, Global test accuracy: 28.43 

Round  80, Train loss: 1.521, Test loss: 1.516, Test accuracy: 94.74 

Round  80, Global train loss: 1.521, Global test loss: 2.093, Global test accuracy: 38.70 

Round  81, Train loss: 1.523, Test loss: 1.516, Test accuracy: 94.74 

Round  81, Global train loss: 1.523, Global test loss: 2.115, Global test accuracy: 41.20 

Round  82, Train loss: 1.464, Test loss: 1.516, Test accuracy: 94.75 

Round  82, Global train loss: 1.464, Global test loss: 2.108, Global test accuracy: 35.20 

Round  83, Train loss: 1.522, Test loss: 1.516, Test accuracy: 94.70 

Round  83, Global train loss: 1.522, Global test loss: 2.259, Global test accuracy: 19.65 

Round  84, Train loss: 1.522, Test loss: 1.517, Test accuracy: 94.67 

Round  84, Global train loss: 1.522, Global test loss: 2.157, Global test accuracy: 29.08 

Round  85, Train loss: 1.466, Test loss: 1.516, Test accuracy: 94.70 

Round  85, Global train loss: 1.466, Global test loss: 2.114, Global test accuracy: 33.76 

Round  86, Train loss: 1.464, Test loss: 1.516, Test accuracy: 94.70 

Round  86, Global train loss: 1.464, Global test loss: 2.044, Global test accuracy: 42.33 

Round  87, Train loss: 1.462, Test loss: 1.516, Test accuracy: 94.70 

Round  87, Global train loss: 1.462, Global test loss: 2.038, Global test accuracy: 45.34 

Round  88, Train loss: 1.465, Test loss: 1.516, Test accuracy: 94.70 

Round  88, Global train loss: 1.465, Global test loss: 2.188, Global test accuracy: 28.00 

Round  89, Train loss: 1.464, Test loss: 1.516, Test accuracy: 94.72 

Round  89, Global train loss: 1.464, Global test loss: 2.193, Global test accuracy: 21.00 

Round  90, Train loss: 1.464, Test loss: 1.516, Test accuracy: 94.72 

Round  90, Global train loss: 1.464, Global test loss: 2.202, Global test accuracy: 25.42 

Round  91, Train loss: 1.464, Test loss: 1.516, Test accuracy: 94.71 

Round  91, Global train loss: 1.464, Global test loss: 2.128, Global test accuracy: 32.64 

Round  92, Train loss: 1.521, Test loss: 1.516, Test accuracy: 94.67 

Round  92, Global train loss: 1.521, Global test loss: 2.206, Global test accuracy: 21.62 

Round  93, Train loss: 1.465, Test loss: 1.516, Test accuracy: 94.67 

Round  93, Global train loss: 1.465, Global test loss: 2.161, Global test accuracy: 24.97 
/home/ChenSM/code/FL_HLS/utils/sampling.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Train loss: 1.464, Test loss: 1.516, Test accuracy: 94.70 

Round  94, Global train loss: 1.464, Global test loss: 2.032, Global test accuracy: 46.91 

Round  95, Train loss: 1.464, Test loss: 1.516, Test accuracy: 94.70 

Round  95, Global train loss: 1.464, Global test loss: 2.103, Global test accuracy: 36.86 

Round  96, Train loss: 1.464, Test loss: 1.516, Test accuracy: 94.69 

Round  96, Global train loss: 1.464, Global test loss: 2.036, Global test accuracy: 41.34 

Round  97, Train loss: 1.464, Test loss: 1.516, Test accuracy: 94.69 

Round  97, Global train loss: 1.464, Global test loss: 2.124, Global test accuracy: 29.43 

Round  98, Train loss: 1.466, Test loss: 1.516, Test accuracy: 94.68 

Round  98, Global train loss: 1.466, Global test loss: 2.077, Global test accuracy: 42.17 

Round  99, Train loss: 1.466, Test loss: 1.516, Test accuracy: 94.68 

Round  99, Global train loss: 1.466, Global test loss: 2.183, Global test accuracy: 23.57 

Final Round, Train loss: 1.482, Test loss: 1.516, Test accuracy: 94.71 

Final Round, Global train loss: 1.482, Global test loss: 2.183, Global test accuracy: 23.57 

Average accuracy final 10 rounds: 94.6925 

Average global accuracy final 10 rounds: 32.49333333333334 

949.7276291847229
[0.8246917724609375, 1.5636649131774902, 2.300971031188965, 3.0324037075042725, 3.770650625228882, 4.515578746795654, 5.252824783325195, 5.990726947784424, 6.742670297622681, 7.480889797210693, 8.217970132827759, 8.968200445175171, 9.707202196121216, 10.444408893585205, 11.192769050598145, 11.92981481552124, 12.66389536857605, 13.416408777236938, 14.156615495681763, 14.891223192214966, 15.640198469161987, 16.37914729118347, 17.116074323654175, 17.864531993865967, 18.605958938598633, 19.344679594039917, 20.088707208633423, 20.828411102294922, 21.566513538360596, 22.319811582565308, 23.055299520492554, 23.794392347335815, 24.546466827392578, 25.282646656036377, 26.02553701400757, 26.77276301383972, 27.512327909469604, 28.252593755722046, 29.004347562789917, 29.744654655456543, 30.485228776931763, 31.235632181167603, 31.973567724227905, 32.7116482257843, 33.45187306404114, 34.19294333457947, 34.938727378845215, 35.68393516540527, 36.419413328170776, 37.160619020462036, 37.89783811569214, 38.63385486602783, 39.376805782318115, 40.11631536483765, 40.852635860443115, 41.60102677345276, 42.3389036655426, 43.080830574035645, 43.82691526412964, 44.56602668762207, 45.30404996871948, 46.04948711395264, 46.79249978065491, 47.5294668674469, 48.27772521972656, 49.016003131866455, 49.75576996803284, 50.50100231170654, 51.242483615875244, 51.99053597450256, 52.72710728645325, 53.468756914138794, 54.21456480026245, 54.95151662826538, 55.693074464797974, 56.43904781341553, 57.18124222755432, 57.92129611968994, 58.6706120967865, 59.411147594451904, 60.145620584487915, 60.89630365371704, 61.63397574424744, 62.37221908569336, 63.12007403373718, 63.86166000366211, 64.61085724830627, 65.35291719436646, 66.09031796455383, 66.83171439170837, 67.57030153274536, 68.30934524536133, 69.05807852745056, 69.79678797721863, 70.53563451766968, 71.28788542747498, 72.02949023246765, 72.76687288284302, 73.51042985916138, 74.24630856513977, 75.73575139045715]
[35.85, 38.90833333333333, 63.50833333333333, 65.16666666666667, 80.38333333333334, 84.39166666666667, 84.6, 84.65, 86.45, 86.94166666666666, 86.98333333333333, 87.00833333333334, 87.08333333333333, 87.075, 87.10833333333333, 87.175, 87.125, 88.44166666666666, 88.51666666666667, 90.01666666666667, 90.04166666666667, 90.05833333333334, 90.075, 90.05, 90.01666666666667, 90.05833333333334, 89.98333333333333, 89.975, 90.025, 91.5, 91.525, 91.65833333333333, 93.13333333333334, 93.14166666666667, 93.16666666666667, 93.20833333333333, 93.23333333333333, 93.225, 93.2, 93.2, 93.20833333333333, 93.23333333333333, 93.25833333333334, 93.3, 93.31666666666666, 93.31666666666666, 93.31666666666666, 93.325, 93.36666666666666, 93.34166666666667, 93.33333333333333, 93.34166666666667, 93.33333333333333, 93.34166666666667, 93.36666666666666, 94.65833333333333, 94.64166666666667, 94.64166666666667, 94.65, 94.65, 94.64166666666667, 94.7, 94.69166666666666, 94.76666666666667, 94.76666666666667, 94.76666666666667, 94.7, 94.7, 94.70833333333333, 94.70833333333333, 94.725, 94.71666666666667, 94.73333333333333, 94.74166666666666, 94.74166666666666, 94.73333333333333, 94.73333333333333, 94.73333333333333, 94.73333333333333, 94.74166666666666, 94.74166666666666, 94.74166666666666, 94.75, 94.7, 94.675, 94.7, 94.7, 94.7, 94.7, 94.71666666666667, 94.71666666666667, 94.70833333333333, 94.675, 94.675, 94.7, 94.7, 94.69166666666666, 94.69166666666666, 94.68333333333334, 94.68333333333334, 94.70833333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.233, Test loss: 2.223, Test accuracy: 16.96 

Round   0, Global train loss: 2.233, Global test loss: 2.293, Global test accuracy: 8.33 

Round   1, Train loss: 1.959, Test loss: 2.053, Test accuracy: 44.71 

Round   1, Global train loss: 1.959, Global test loss: 2.257, Global test accuracy: 25.62 

Round   2, Train loss: 1.735, Test loss: 1.843, Test accuracy: 64.03 

Round   2, Global train loss: 1.735, Global test loss: 2.156, Global test accuracy: 30.84 

Round   3, Train loss: 1.618, Test loss: 1.792, Test accuracy: 68.63 

Round   3, Global train loss: 1.618, Global test loss: 2.166, Global test accuracy: 28.12 

Round   4, Train loss: 1.584, Test loss: 1.719, Test accuracy: 75.52 

Round   4, Global train loss: 1.584, Global test loss: 2.098, Global test accuracy: 35.96 

Round   5, Train loss: 1.520, Test loss: 1.646, Test accuracy: 83.82 

Round   5, Global train loss: 1.520, Global test loss: 1.934, Global test accuracy: 55.75 

Round   6, Train loss: 1.538, Test loss: 1.611, Test accuracy: 86.28 

Round   6, Global train loss: 1.538, Global test loss: 1.896, Global test accuracy: 57.19 

Round   7, Train loss: 1.555, Test loss: 1.546, Test accuracy: 93.23 

Round   7, Global train loss: 1.555, Global test loss: 1.819, Global test accuracy: 68.10 

Round   8, Train loss: 1.502, Test loss: 1.543, Test accuracy: 93.43 

Round   8, Global train loss: 1.502, Global test loss: 1.833, Global test accuracy: 63.26 

Round   9, Train loss: 1.513, Test loss: 1.542, Test accuracy: 93.49 

Round   9, Global train loss: 1.513, Global test loss: 1.794, Global test accuracy: 72.58 

Round  10, Train loss: 1.504, Test loss: 1.540, Test accuracy: 93.50 

Round  10, Global train loss: 1.504, Global test loss: 1.760, Global test accuracy: 72.84 

Round  11, Train loss: 1.506, Test loss: 1.539, Test accuracy: 93.65 

Round  11, Global train loss: 1.506, Global test loss: 1.705, Global test accuracy: 78.91 

Round  12, Train loss: 1.496, Test loss: 1.506, Test accuracy: 96.37 

Round  12, Global train loss: 1.496, Global test loss: 1.778, Global test accuracy: 69.91 

Round  13, Train loss: 1.506, Test loss: 1.506, Test accuracy: 96.26 

Round  13, Global train loss: 1.506, Global test loss: 1.698, Global test accuracy: 79.10 

Round  14, Train loss: 1.491, Test loss: 1.505, Test accuracy: 96.30 

Round  14, Global train loss: 1.491, Global test loss: 1.663, Global test accuracy: 83.16 

Round  15, Train loss: 1.491, Test loss: 1.506, Test accuracy: 96.14 

Round  15, Global train loss: 1.491, Global test loss: 1.710, Global test accuracy: 77.04 

Round  16, Train loss: 1.490, Test loss: 1.506, Test accuracy: 96.20 

Round  16, Global train loss: 1.490, Global test loss: 1.667, Global test accuracy: 82.10 

Round  17, Train loss: 1.506, Test loss: 1.503, Test accuracy: 96.38 

Round  17, Global train loss: 1.506, Global test loss: 1.649, Global test accuracy: 84.88 

Round  18, Train loss: 1.495, Test loss: 1.501, Test accuracy: 96.64 

Round  18, Global train loss: 1.495, Global test loss: 1.642, Global test accuracy: 85.33 

Round  19, Train loss: 1.488, Test loss: 1.502, Test accuracy: 96.54 

Round  19, Global train loss: 1.488, Global test loss: 1.682, Global test accuracy: 79.93 

Round  20, Train loss: 1.495, Test loss: 1.501, Test accuracy: 96.61 

Round  20, Global train loss: 1.495, Global test loss: 1.696, Global test accuracy: 77.72 

Round  21, Train loss: 1.488, Test loss: 1.500, Test accuracy: 96.70 

Round  21, Global train loss: 1.488, Global test loss: 1.638, Global test accuracy: 84.62 

Round  22, Train loss: 1.488, Test loss: 1.499, Test accuracy: 96.68 

Round  22, Global train loss: 1.488, Global test loss: 1.662, Global test accuracy: 82.33 

Round  23, Train loss: 1.485, Test loss: 1.499, Test accuracy: 96.69 

Round  23, Global train loss: 1.485, Global test loss: 1.652, Global test accuracy: 82.82 

Round  24, Train loss: 1.489, Test loss: 1.500, Test accuracy: 96.66 

Round  24, Global train loss: 1.489, Global test loss: 1.639, Global test accuracy: 84.54 

Round  25, Train loss: 1.485, Test loss: 1.499, Test accuracy: 96.66 

Round  25, Global train loss: 1.485, Global test loss: 1.637, Global test accuracy: 84.20 

Round  26, Train loss: 1.485, Test loss: 1.500, Test accuracy: 96.53 

Round  26, Global train loss: 1.485, Global test loss: 1.629, Global test accuracy: 84.97 

Round  27, Train loss: 1.488, Test loss: 1.499, Test accuracy: 96.63 

Round  27, Global train loss: 1.488, Global test loss: 1.650, Global test accuracy: 82.80 

Round  28, Train loss: 1.483, Test loss: 1.499, Test accuracy: 96.66 

Round  28, Global train loss: 1.483, Global test loss: 1.627, Global test accuracy: 85.16 

Round  29, Train loss: 1.485, Test loss: 1.499, Test accuracy: 96.64 

Round  29, Global train loss: 1.485, Global test loss: 1.604, Global test accuracy: 87.72 

Round  30, Train loss: 1.483, Test loss: 1.498, Test accuracy: 96.67 

Round  30, Global train loss: 1.483, Global test loss: 1.677, Global test accuracy: 79.06 

Round  31, Train loss: 1.487, Test loss: 1.498, Test accuracy: 96.62 

Round  31, Global train loss: 1.487, Global test loss: 1.622, Global test accuracy: 85.77 

Round  32, Train loss: 1.477, Test loss: 1.498, Test accuracy: 96.59 

Round  32, Global train loss: 1.477, Global test loss: 1.645, Global test accuracy: 82.97 

Round  33, Train loss: 1.481, Test loss: 1.498, Test accuracy: 96.69 

Round  33, Global train loss: 1.481, Global test loss: 1.652, Global test accuracy: 82.27 

Round  34, Train loss: 1.485, Test loss: 1.497, Test accuracy: 96.83 

Round  34, Global train loss: 1.485, Global test loss: 1.608, Global test accuracy: 87.38 

Round  35, Train loss: 1.478, Test loss: 1.497, Test accuracy: 96.79 

Round  35, Global train loss: 1.478, Global test loss: 1.593, Global test accuracy: 88.39 

Round  36, Train loss: 1.479, Test loss: 1.498, Test accuracy: 96.62 

Round  36, Global train loss: 1.479, Global test loss: 1.619, Global test accuracy: 85.84 

Round  37, Train loss: 1.478, Test loss: 1.499, Test accuracy: 96.60 

Round  37, Global train loss: 1.478, Global test loss: 1.607, Global test accuracy: 87.33 

Round  38, Train loss: 1.477, Test loss: 1.498, Test accuracy: 96.58 

Round  38, Global train loss: 1.477, Global test loss: 1.610, Global test accuracy: 86.74 

Round  39, Train loss: 1.476, Test loss: 1.498, Test accuracy: 96.56 

Round  39, Global train loss: 1.476, Global test loss: 1.600, Global test accuracy: 87.50 

Round  40, Train loss: 1.479, Test loss: 1.499, Test accuracy: 96.54 

Round  40, Global train loss: 1.479, Global test loss: 1.622, Global test accuracy: 85.47 

Round  41, Train loss: 1.477, Test loss: 1.499, Test accuracy: 96.53 

Round  41, Global train loss: 1.477, Global test loss: 1.612, Global test accuracy: 86.38 

Round  42, Train loss: 1.478, Test loss: 1.499, Test accuracy: 96.47 

Round  42, Global train loss: 1.478, Global test loss: 1.631, Global test accuracy: 84.51 

Round  43, Train loss: 1.478, Test loss: 1.498, Test accuracy: 96.64 

Round  43, Global train loss: 1.478, Global test loss: 1.587, Global test accuracy: 88.92 

Round  44, Train loss: 1.480, Test loss: 1.497, Test accuracy: 96.71 

Round  44, Global train loss: 1.480, Global test loss: 1.703, Global test accuracy: 76.21 

Round  45, Train loss: 1.478, Test loss: 1.496, Test accuracy: 96.73 

Round  45, Global train loss: 1.478, Global test loss: 1.622, Global test accuracy: 84.83 

Round  46, Train loss: 1.478, Test loss: 1.496, Test accuracy: 96.77 

Round  46, Global train loss: 1.478, Global test loss: 1.615, Global test accuracy: 85.82 

Round  47, Train loss: 1.477, Test loss: 1.497, Test accuracy: 96.80 

Round  47, Global train loss: 1.477, Global test loss: 1.608, Global test accuracy: 86.17 

Round  48, Train loss: 1.476, Test loss: 1.497, Test accuracy: 96.78 

Round  48, Global train loss: 1.476, Global test loss: 1.585, Global test accuracy: 89.00 

Round  49, Train loss: 1.477, Test loss: 1.496, Test accuracy: 96.85 

Round  49, Global train loss: 1.477, Global test loss: 1.602, Global test accuracy: 86.95 

Round  50, Train loss: 1.476, Test loss: 1.497, Test accuracy: 96.80 

Round  50, Global train loss: 1.476, Global test loss: 1.602, Global test accuracy: 87.06 

Round  51, Train loss: 1.474, Test loss: 1.496, Test accuracy: 96.83 

Round  51, Global train loss: 1.474, Global test loss: 1.620, Global test accuracy: 84.88 

Round  52, Train loss: 1.478, Test loss: 1.496, Test accuracy: 96.84 

Round  52, Global train loss: 1.478, Global test loss: 1.604, Global test accuracy: 86.98 

Round  53, Train loss: 1.476, Test loss: 1.496, Test accuracy: 96.79 

Round  53, Global train loss: 1.476, Global test loss: 1.619, Global test accuracy: 85.45 

Round  54, Train loss: 1.473, Test loss: 1.496, Test accuracy: 96.85 

Round  54, Global train loss: 1.473, Global test loss: 1.626, Global test accuracy: 84.22 

Round  55, Train loss: 1.475, Test loss: 1.496, Test accuracy: 96.85 

Round  55, Global train loss: 1.475, Global test loss: 1.620, Global test accuracy: 84.83 

Round  56, Train loss: 1.474, Test loss: 1.496, Test accuracy: 96.82 

Round  56, Global train loss: 1.474, Global test loss: 1.593, Global test accuracy: 87.68 

Round  57, Train loss: 1.474, Test loss: 1.495, Test accuracy: 96.85 

Round  57, Global train loss: 1.474, Global test loss: 1.601, Global test accuracy: 86.98 

Round  58, Train loss: 1.473, Test loss: 1.495, Test accuracy: 96.78 

Round  58, Global train loss: 1.473, Global test loss: 1.579, Global test accuracy: 89.50 

Round  59, Train loss: 1.473, Test loss: 1.495, Test accuracy: 96.77 

Round  59, Global train loss: 1.473, Global test loss: 1.611, Global test accuracy: 85.92 

Round  60, Train loss: 1.479, Test loss: 1.495, Test accuracy: 96.87 

Round  60, Global train loss: 1.479, Global test loss: 1.569, Global test accuracy: 90.46 

Round  61, Train loss: 1.476, Test loss: 1.494, Test accuracy: 96.93 

Round  61, Global train loss: 1.476, Global test loss: 1.615, Global test accuracy: 85.29 

Round  62, Train loss: 1.472, Test loss: 1.494, Test accuracy: 96.97 

Round  62, Global train loss: 1.472, Global test loss: 1.611, Global test accuracy: 85.97 

Round  63, Train loss: 1.475, Test loss: 1.495, Test accuracy: 96.92 

Round  63, Global train loss: 1.475, Global test loss: 1.600, Global test accuracy: 87.12 

Round  64, Train loss: 1.476, Test loss: 1.495, Test accuracy: 96.85 

Round  64, Global train loss: 1.476, Global test loss: 1.585, Global test accuracy: 88.37 

Round  65, Train loss: 1.470, Test loss: 1.495, Test accuracy: 96.88 

Round  65, Global train loss: 1.470, Global test loss: 1.576, Global test accuracy: 89.55 

Round  66, Train loss: 1.471, Test loss: 1.495, Test accuracy: 96.92 

Round  66, Global train loss: 1.471, Global test loss: 1.585, Global test accuracy: 88.71 

Round  67, Train loss: 1.473, Test loss: 1.495, Test accuracy: 96.88 

Round  67, Global train loss: 1.473, Global test loss: 1.569, Global test accuracy: 90.17 

Round  68, Train loss: 1.471, Test loss: 1.495, Test accuracy: 96.88 

Round  68, Global train loss: 1.471, Global test loss: 1.568, Global test accuracy: 90.33 

Round  69, Train loss: 1.476, Test loss: 1.494, Test accuracy: 97.00 

Round  69, Global train loss: 1.476, Global test loss: 1.594, Global test accuracy: 87.47 

Round  70, Train loss: 1.473, Test loss: 1.494, Test accuracy: 96.99 

Round  70, Global train loss: 1.473, Global test loss: 1.577, Global test accuracy: 89.50 

Round  71, Train loss: 1.471, Test loss: 1.494, Test accuracy: 97.01 

Round  71, Global train loss: 1.471, Global test loss: 1.572, Global test accuracy: 89.71 

Round  72, Train loss: 1.474, Test loss: 1.494, Test accuracy: 96.94 

Round  72, Global train loss: 1.474, Global test loss: 1.562, Global test accuracy: 91.08 

Round  73, Train loss: 1.470, Test loss: 1.494, Test accuracy: 96.99 

Round  73, Global train loss: 1.470, Global test loss: 1.579, Global test accuracy: 88.97 

Round  74, Train loss: 1.472, Test loss: 1.494, Test accuracy: 96.96 

Round  74, Global train loss: 1.472, Global test loss: 1.601, Global test accuracy: 87.10 

Round  75, Train loss: 1.472, Test loss: 1.494, Test accuracy: 96.98 

Round  75, Global train loss: 1.472, Global test loss: 1.587, Global test accuracy: 88.51 

Round  76, Train loss: 1.474, Test loss: 1.494, Test accuracy: 97.02 

Round  76, Global train loss: 1.474, Global test loss: 1.591, Global test accuracy: 88.03 

Round  77, Train loss: 1.474, Test loss: 1.493, Test accuracy: 97.04 

Round  77, Global train loss: 1.474, Global test loss: 1.567, Global test accuracy: 90.42 

Round  78, Train loss: 1.469, Test loss: 1.493, Test accuracy: 97.07 

Round  78, Global train loss: 1.469, Global test loss: 1.598, Global test accuracy: 87.14 

Round  79, Train loss: 1.471, Test loss: 1.493, Test accuracy: 97.06 

Round  79, Global train loss: 1.471, Global test loss: 1.591, Global test accuracy: 87.85 

Round  80, Train loss: 1.470, Test loss: 1.493, Test accuracy: 97.12 

Round  80, Global train loss: 1.470, Global test loss: 1.605, Global test accuracy: 86.51 

Round  81, Train loss: 1.473, Test loss: 1.493, Test accuracy: 97.11 

Round  81, Global train loss: 1.473, Global test loss: 1.591, Global test accuracy: 87.92 

Round  82, Train loss: 1.473, Test loss: 1.493, Test accuracy: 97.12 

Round  82, Global train loss: 1.473, Global test loss: 1.586, Global test accuracy: 88.64 

Round  83, Train loss: 1.472, Test loss: 1.493, Test accuracy: 97.12 

Round  83, Global train loss: 1.472, Global test loss: 1.575, Global test accuracy: 89.91 

Round  84, Train loss: 1.474, Test loss: 1.493, Test accuracy: 97.16 

Round  84, Global train loss: 1.474, Global test loss: 1.572, Global test accuracy: 89.97 

Round  85, Train loss: 1.470, Test loss: 1.493, Test accuracy: 97.16 

Round  85, Global train loss: 1.470, Global test loss: 1.582, Global test accuracy: 88.60 

Round  86, Train loss: 1.471, Test loss: 1.493, Test accuracy: 97.13 

Round  86, Global train loss: 1.471, Global test loss: 1.573, Global test accuracy: 89.45 

Round  87, Train loss: 1.471, Test loss: 1.493, Test accuracy: 97.17 

Round  87, Global train loss: 1.471, Global test loss: 1.578, Global test accuracy: 89.47 

Round  88, Train loss: 1.470, Test loss: 1.493, Test accuracy: 97.13 

Round  88, Global train loss: 1.470, Global test loss: 1.582, Global test accuracy: 88.85 

Round  89, Train loss: 1.471, Test loss: 1.492, Test accuracy: 97.14 

Round  89, Global train loss: 1.471, Global test loss: 1.573, Global test accuracy: 89.60 

Round  90, Train loss: 1.470, Test loss: 1.493, Test accuracy: 97.09 

Round  90, Global train loss: 1.470, Global test loss: 1.580, Global test accuracy: 88.97 

Round  91, Train loss: 1.471, Test loss: 1.493, Test accuracy: 97.09 

Round  91, Global train loss: 1.471, Global test loss: 1.589, Global test accuracy: 88.13 

Round  92, Train loss: 1.469, Test loss: 1.493, Test accuracy: 97.14 

Round  92, Global train loss: 1.469, Global test loss: 1.568, Global test accuracy: 90.17 

Round  93, Train loss: 1.470, Test loss: 1.493, Test accuracy: 97.12 

Round  93, Global train loss: 1.470, Global test loss: 1.559, Global test accuracy: 91.08 
/home/ChenSM/code/FL_HLS/utils/sampling.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Train loss: 1.470, Test loss: 1.493, Test accuracy: 97.08 

Round  94, Global train loss: 1.470, Global test loss: 1.579, Global test accuracy: 88.89 

Round  95, Train loss: 1.472, Test loss: 1.493, Test accuracy: 97.09 

Round  95, Global train loss: 1.472, Global test loss: 1.585, Global test accuracy: 88.47 

Round  96, Train loss: 1.470, Test loss: 1.492, Test accuracy: 97.08 

Round  96, Global train loss: 1.470, Global test loss: 1.590, Global test accuracy: 88.09 

Round  97, Train loss: 1.469, Test loss: 1.492, Test accuracy: 97.10 

Round  97, Global train loss: 1.469, Global test loss: 1.604, Global test accuracy: 86.14 

Round  98, Train loss: 1.471, Test loss: 1.492, Test accuracy: 97.12 

Round  98, Global train loss: 1.471, Global test loss: 1.568, Global test accuracy: 90.17 

Round  99, Train loss: 1.472, Test loss: 1.492, Test accuracy: 97.13 

Round  99, Global train loss: 1.472, Global test loss: 1.573, Global test accuracy: 89.78 

Final Round, Train loss: 1.469, Test loss: 1.491, Test accuracy: 97.27 

Final Round, Global train loss: 1.469, Global test loss: 1.573, Global test accuracy: 89.78 

Average accuracy final 10 rounds: 97.10583333333334 

Average global accuracy final 10 rounds: 88.99083333333334 

940.6393694877625
[0.8495545387268066, 1.5989887714385986, 2.353464126586914, 3.1047637462615967, 3.8526265621185303, 4.607360601425171, 5.357455730438232, 6.111208200454712, 6.869455814361572, 7.6169373989105225, 8.368174076080322, 9.12178921699524, 9.873459100723267, 10.624867916107178, 11.380621194839478, 12.128995418548584, 12.881164789199829, 13.632563829421997, 14.379873752593994, 15.129658460617065, 15.872927904129028, 16.614463806152344, 17.369447708129883, 18.10988759994507, 18.852219343185425, 19.59948444366455, 20.336974620819092, 21.08057475090027, 21.83209252357483, 22.578015565872192, 23.328310012817383, 24.07796621322632, 24.822295904159546, 25.57413625717163, 26.329962491989136, 27.07239031791687, 27.820801496505737, 28.56352972984314, 29.30432677268982, 30.05466055870056, 30.797905206680298, 31.50767159461975, 32.23776841163635, 32.941234827041626, 33.654696464538574, 34.37002158164978, 35.089149713516235, 35.8142511844635, 36.56772589683533, 37.31328749656677, 38.0635142326355, 38.81698417663574, 39.56486988067627, 40.30910611152649, 41.064525842666626, 41.81228971481323, 42.55870270729065, 43.31342625617981, 44.05543327331543, 44.80208683013916, 45.560176849365234, 46.30375099182129, 47.046382427215576, 47.80505633354187, 48.54774022102356, 49.3031485080719, 50.06130504608154, 50.80450654029846, 51.46443462371826, 52.12601447105408, 52.76889395713806, 53.41200804710388, 54.05748701095581, 54.69651198387146, 55.333810806274414, 55.99091553688049, 56.635117530822754, 57.27971863746643, 57.93502449989319, 58.58136296272278, 59.224441051483154, 59.87535309791565, 60.52038764953613, 61.15942668914795, 61.81259536743164, 62.451908111572266, 63.094576835632324, 63.7451856136322, 64.38158297538757, 65.01901984214783, 65.67355799674988, 66.31081914901733, 66.95319390296936, 67.60431575775146, 68.26004338264465, 68.90269732475281, 69.5466058254242, 70.19917011260986, 70.83591556549072, 71.48204493522644, 72.78256869316101]
[16.958333333333332, 44.708333333333336, 64.025, 68.63333333333334, 75.51666666666667, 83.81666666666666, 86.275, 93.23333333333333, 93.43333333333334, 93.49166666666666, 93.5, 93.65, 96.36666666666666, 96.25833333333334, 96.3, 96.14166666666667, 96.2, 96.38333333333334, 96.64166666666667, 96.54166666666667, 96.60833333333333, 96.7, 96.68333333333334, 96.69166666666666, 96.65833333333333, 96.65833333333333, 96.53333333333333, 96.63333333333334, 96.65833333333333, 96.64166666666667, 96.675, 96.625, 96.59166666666667, 96.69166666666666, 96.825, 96.79166666666667, 96.625, 96.6, 96.575, 96.55833333333334, 96.54166666666667, 96.525, 96.46666666666667, 96.64166666666667, 96.70833333333333, 96.73333333333333, 96.76666666666667, 96.8, 96.78333333333333, 96.85, 96.8, 96.83333333333333, 96.84166666666667, 96.79166666666667, 96.85, 96.85, 96.81666666666666, 96.85, 96.78333333333333, 96.76666666666667, 96.86666666666666, 96.93333333333334, 96.975, 96.925, 96.85, 96.875, 96.925, 96.875, 96.875, 97.0, 96.99166666666666, 97.00833333333334, 96.94166666666666, 96.99166666666666, 96.95833333333333, 96.98333333333333, 97.01666666666667, 97.04166666666667, 97.06666666666666, 97.05833333333334, 97.11666666666666, 97.10833333333333, 97.11666666666666, 97.11666666666666, 97.15833333333333, 97.15833333333333, 97.13333333333334, 97.16666666666667, 97.13333333333334, 97.14166666666667, 97.09166666666667, 97.09166666666667, 97.14166666666667, 97.11666666666666, 97.08333333333333, 97.09166666666667, 97.08333333333333, 97.1, 97.125, 97.13333333333334, 97.26666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.303, Test loss: 2.302, Test accuracy: 7.92 

Round   1, Train loss: 2.301, Test loss: 2.301, Test accuracy: 12.13 

Round   2, Train loss: 2.301, Test loss: 2.300, Test accuracy: 15.88 

Round   3, Train loss: 2.299, Test loss: 2.299, Test accuracy: 20.87 

Round   4, Train loss: 2.298, Test loss: 2.297, Test accuracy: 26.80 

Round   5, Train loss: 2.296, Test loss: 2.295, Test accuracy: 31.08 

Round   6, Train loss: 2.294, Test loss: 2.293, Test accuracy: 34.98 

Round   7, Train loss: 2.292, Test loss: 2.290, Test accuracy: 37.00 

Round   8, Train loss: 2.288, Test loss: 2.285, Test accuracy: 37.48 

Round   9, Train loss: 2.281, Test loss: 2.277, Test accuracy: 33.80 

Round  10, Train loss: 2.268, Test loss: 2.261, Test accuracy: 27.70 

Round  11, Train loss: 2.253, Test loss: 2.238, Test accuracy: 30.10 

Round  12, Train loss: 2.215, Test loss: 2.205, Test accuracy: 32.28 

Round  13, Train loss: 2.170, Test loss: 2.159, Test accuracy: 37.42 

Round  14, Train loss: 2.128, Test loss: 2.117, Test accuracy: 42.47 

Round  15, Train loss: 2.091, Test loss: 2.076, Test accuracy: 44.67 

Round  16, Train loss: 2.035, Test loss: 2.035, Test accuracy: 46.80 

Round  17, Train loss: 2.014, Test loss: 1.995, Test accuracy: 50.87 

Round  18, Train loss: 1.963, Test loss: 1.954, Test accuracy: 55.48 

Round  19, Train loss: 1.938, Test loss: 1.918, Test accuracy: 58.63 

Round  20, Train loss: 1.889, Test loss: 1.886, Test accuracy: 62.55 

Round  21, Train loss: 1.851, Test loss: 1.854, Test accuracy: 65.88 

Round  22, Train loss: 1.810, Test loss: 1.821, Test accuracy: 68.70 

Round  23, Train loss: 1.789, Test loss: 1.789, Test accuracy: 71.73 

Round  24, Train loss: 1.761, Test loss: 1.764, Test accuracy: 73.83 

Round  25, Train loss: 1.733, Test loss: 1.742, Test accuracy: 76.12 

Round  26, Train loss: 1.715, Test loss: 1.730, Test accuracy: 76.78 

Round  27, Train loss: 1.704, Test loss: 1.712, Test accuracy: 78.70 

Round  28, Train loss: 1.686, Test loss: 1.700, Test accuracy: 79.37 

Round  29, Train loss: 1.673, Test loss: 1.692, Test accuracy: 79.83 

Round  30, Train loss: 1.685, Test loss: 1.686, Test accuracy: 80.12 

Round  31, Train loss: 1.657, Test loss: 1.681, Test accuracy: 80.73 

Round  32, Train loss: 1.649, Test loss: 1.675, Test accuracy: 80.90 

Round  33, Train loss: 1.658, Test loss: 1.670, Test accuracy: 81.22 

Round  34, Train loss: 1.636, Test loss: 1.667, Test accuracy: 81.32 

Round  35, Train loss: 1.648, Test loss: 1.666, Test accuracy: 81.43 

Round  36, Train loss: 1.635, Test loss: 1.662, Test accuracy: 81.60 

Round  37, Train loss: 1.640, Test loss: 1.663, Test accuracy: 81.43 

Round  38, Train loss: 1.637, Test loss: 1.660, Test accuracy: 81.70 

Round  39, Train loss: 1.639, Test loss: 1.656, Test accuracy: 82.05 

Round  40, Train loss: 1.631, Test loss: 1.652, Test accuracy: 82.37 

Round  41, Train loss: 1.617, Test loss: 1.651, Test accuracy: 82.25 

Round  42, Train loss: 1.637, Test loss: 1.649, Test accuracy: 82.27 

Round  43, Train loss: 1.608, Test loss: 1.648, Test accuracy: 82.28 

Round  44, Train loss: 1.618, Test loss: 1.646, Test accuracy: 82.37 

Round  45, Train loss: 1.604, Test loss: 1.645, Test accuracy: 82.38 

Round  46, Train loss: 1.625, Test loss: 1.645, Test accuracy: 82.47 

Round  47, Train loss: 1.604, Test loss: 1.645, Test accuracy: 82.53 

Round  48, Train loss: 1.620, Test loss: 1.644, Test accuracy: 82.73 

Round  49, Train loss: 1.614, Test loss: 1.643, Test accuracy: 82.77 

Round  50, Train loss: 1.616, Test loss: 1.642, Test accuracy: 82.92 

Round  51, Train loss: 1.607, Test loss: 1.642, Test accuracy: 82.88 

Round  52, Train loss: 1.589, Test loss: 1.641, Test accuracy: 83.07 

Round  53, Train loss: 1.622, Test loss: 1.640, Test accuracy: 83.03 

Round  54, Train loss: 1.601, Test loss: 1.640, Test accuracy: 83.05 

Round  55, Train loss: 1.604, Test loss: 1.640, Test accuracy: 82.80 

Round  56, Train loss: 1.594, Test loss: 1.639, Test accuracy: 83.12 

Round  57, Train loss: 1.622, Test loss: 1.639, Test accuracy: 82.93 

Round  58, Train loss: 1.595, Test loss: 1.638, Test accuracy: 82.95 

Round  59, Train loss: 1.591, Test loss: 1.637, Test accuracy: 82.95 

Round  60, Train loss: 1.600, Test loss: 1.637, Test accuracy: 83.18 

Round  61, Train loss: 1.598, Test loss: 1.637, Test accuracy: 83.00 

Round  62, Train loss: 1.598, Test loss: 1.636, Test accuracy: 83.08 

Round  63, Train loss: 1.588, Test loss: 1.638, Test accuracy: 82.93 

Round  64, Train loss: 1.596, Test loss: 1.638, Test accuracy: 82.92 

Round  65, Train loss: 1.593, Test loss: 1.637, Test accuracy: 82.88 

Round  66, Train loss: 1.600, Test loss: 1.636, Test accuracy: 83.02 

Round  67, Train loss: 1.569, Test loss: 1.636, Test accuracy: 82.97 

Round  68, Train loss: 1.591, Test loss: 1.635, Test accuracy: 83.18 

Round  69, Train loss: 1.578, Test loss: 1.632, Test accuracy: 83.47 

Round  70, Train loss: 1.573, Test loss: 1.631, Test accuracy: 83.52 

Round  71, Train loss: 1.597, Test loss: 1.630, Test accuracy: 83.60 

Round  72, Train loss: 1.587, Test loss: 1.630, Test accuracy: 83.62 

Round  73, Train loss: 1.577, Test loss: 1.629, Test accuracy: 83.77 

Round  74, Train loss: 1.591, Test loss: 1.629, Test accuracy: 83.83 

Round  75, Train loss: 1.585, Test loss: 1.630, Test accuracy: 83.63 

Round  76, Train loss: 1.553, Test loss: 1.630, Test accuracy: 83.63 

Round  77, Train loss: 1.552, Test loss: 1.630, Test accuracy: 83.47 

Round  78, Train loss: 1.589, Test loss: 1.630, Test accuracy: 83.40 

Round  79, Train loss: 1.593, Test loss: 1.629, Test accuracy: 83.47 

Round  80, Train loss: 1.577, Test loss: 1.628, Test accuracy: 83.62 

Round  81, Train loss: 1.578, Test loss: 1.628, Test accuracy: 83.53 

Round  82, Train loss: 1.568, Test loss: 1.627, Test accuracy: 84.00 

Round  83, Train loss: 1.590, Test loss: 1.627, Test accuracy: 84.05 

Round  84, Train loss: 1.590, Test loss: 1.627, Test accuracy: 83.93 

Round  85, Train loss: 1.574, Test loss: 1.627, Test accuracy: 83.88 

Round  86, Train loss: 1.559, Test loss: 1.626, Test accuracy: 83.87 

Round  87, Train loss: 1.589, Test loss: 1.626, Test accuracy: 83.95 

Round  88, Train loss: 1.577, Test loss: 1.626, Test accuracy: 83.80 

Round  89, Train loss: 1.578, Test loss: 1.625, Test accuracy: 84.15 

Round  90, Train loss: 1.598, Test loss: 1.625, Test accuracy: 84.00 

Round  91, Train loss: 1.550, Test loss: 1.625, Test accuracy: 84.10 

Round  92, Train loss: 1.576, Test loss: 1.624, Test accuracy: 84.33 

Round  93, Train loss: 1.579, Test loss: 1.624, Test accuracy: 84.27 

Round  94, Train loss: 1.559, Test loss: 1.623, Test accuracy: 84.27 

Round  95, Train loss: 1.594, Test loss: 1.623, Test accuracy: 84.38 

Round  96, Train loss: 1.573, Test loss: 1.622, Test accuracy: 84.35 
/home/ChenSM/code/FL_HLS/utils/sampling.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  97, Train loss: 1.569, Test loss: 1.622, Test accuracy: 84.25 

Round  98, Train loss: 1.550, Test loss: 1.622, Test accuracy: 84.33 

Round  99, Train loss: 1.582, Test loss: 1.622, Test accuracy: 84.22 

Final Round, Train loss: 1.570, Test loss: 1.621, Test accuracy: 84.52 

Average accuracy final 10 rounds: 84.25 

362.12333941459656
[0.487257719039917, 0.8807661533355713, 1.2864437103271484, 1.6951119899749756, 2.1076161861419678, 2.5192348957061768, 2.9374043941497803, 3.3588149547576904, 3.7692418098449707, 4.177155494689941, 4.585704803466797, 4.994160413742065, 5.407101392745972, 5.820838689804077, 6.2397754192352295, 6.646289587020874, 7.059704542160034, 7.464690208435059, 7.838522434234619, 8.205855131149292, 8.581127405166626, 8.959025144577026, 9.335022211074829, 9.705747842788696, 10.072954893112183, 10.439764499664307, 10.806702613830566, 11.179539442062378, 11.552603006362915, 11.928205490112305, 12.300095319747925, 12.666860342025757, 13.038381099700928, 13.4075186252594, 13.775705337524414, 14.14623475074768, 14.517895460128784, 14.892140865325928, 15.2618989944458, 15.632987976074219, 16.00127625465393, 16.370402574539185, 16.73993945121765, 17.115269899368286, 17.490248680114746, 17.865710496902466, 18.23459553718567, 18.601896286010742, 18.973117351531982, 19.342201232910156, 19.7140371799469, 20.088976860046387, 20.46270179748535, 20.834066152572632, 21.204919576644897, 21.57714557647705, 21.945763111114502, 22.315165042877197, 22.685413360595703, 23.04484486579895, 23.415126085281372, 23.781002521514893, 24.15441060066223, 24.522000789642334, 24.889681339263916, 25.25770378112793, 25.62743377685547, 25.997681856155396, 26.369651317596436, 26.738161325454712, 27.106258630752563, 27.475406646728516, 27.846681594848633, 28.217375993728638, 28.58841371536255, 28.960510730743408, 29.327869415283203, 29.696969509124756, 30.069279193878174, 30.438191413879395, 30.805190801620483, 31.17475962638855, 31.543932914733887, 31.914803504943848, 32.28459358215332, 32.65467953681946, 33.02501606941223, 33.39382839202881, 33.76118445396423, 34.12858772277832, 34.50068664550781, 34.8686957359314, 35.24222683906555, 35.609458208084106, 35.98339557647705, 36.35342812538147, 36.72155261039734, 37.095008850097656, 37.46636176109314, 37.84040975570679, 38.55731248855591]
[7.916666666666667, 12.133333333333333, 15.883333333333333, 20.866666666666667, 26.8, 31.083333333333332, 34.983333333333334, 37.0, 37.483333333333334, 33.8, 27.7, 30.1, 32.28333333333333, 37.416666666666664, 42.46666666666667, 44.666666666666664, 46.8, 50.86666666666667, 55.483333333333334, 58.63333333333333, 62.55, 65.88333333333334, 68.7, 71.73333333333333, 73.83333333333333, 76.11666666666666, 76.78333333333333, 78.7, 79.36666666666666, 79.83333333333333, 80.11666666666666, 80.73333333333333, 80.9, 81.21666666666667, 81.31666666666666, 81.43333333333334, 81.6, 81.43333333333334, 81.7, 82.05, 82.36666666666666, 82.25, 82.26666666666667, 82.28333333333333, 82.36666666666666, 82.38333333333334, 82.46666666666667, 82.53333333333333, 82.73333333333333, 82.76666666666667, 82.91666666666667, 82.88333333333334, 83.06666666666666, 83.03333333333333, 83.05, 82.8, 83.11666666666666, 82.93333333333334, 82.95, 82.95, 83.18333333333334, 83.0, 83.08333333333333, 82.93333333333334, 82.91666666666667, 82.88333333333334, 83.01666666666667, 82.96666666666667, 83.18333333333334, 83.46666666666667, 83.51666666666667, 83.6, 83.61666666666666, 83.76666666666667, 83.83333333333333, 83.63333333333334, 83.63333333333334, 83.46666666666667, 83.4, 83.46666666666667, 83.61666666666666, 83.53333333333333, 84.0, 84.05, 83.93333333333334, 83.88333333333334, 83.86666666666666, 83.95, 83.8, 84.15, 84.0, 84.1, 84.33333333333333, 84.26666666666667, 84.26666666666667, 84.38333333333334, 84.35, 84.25, 84.33333333333333, 84.21666666666667, 84.51666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

fedper
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.301, Test loss: 2.300, Test accuracy: 18.80 

Round   1, Train loss: 2.299, Test loss: 2.298, Test accuracy: 30.00 

Round   2, Train loss: 2.296, Test loss: 2.294, Test accuracy: 44.45 

Round   3, Train loss: 2.291, Test loss: 2.289, Test accuracy: 50.58 

Round   4, Train loss: 2.283, Test loss: 2.280, Test accuracy: 52.38 

Round   5, Train loss: 2.264, Test loss: 2.251, Test accuracy: 46.17 

Round   6, Train loss: 2.186, Test loss: 2.175, Test accuracy: 46.83 

Round   7, Train loss: 2.093, Test loss: 2.068, Test accuracy: 48.38 

Round   8, Train loss: 1.979, Test loss: 1.982, Test accuracy: 54.12 

Round   9, Train loss: 1.913, Test loss: 1.920, Test accuracy: 59.23 

Round  10, Train loss: 1.856, Test loss: 1.875, Test accuracy: 62.22 

Round  11, Train loss: 1.817, Test loss: 1.829, Test accuracy: 66.78 

Round  12, Train loss: 1.788, Test loss: 1.798, Test accuracy: 69.48 

Round  13, Train loss: 1.759, Test loss: 1.780, Test accuracy: 70.98 

Round  14, Train loss: 1.743, Test loss: 1.761, Test accuracy: 72.47 

Round  15, Train loss: 1.737, Test loss: 1.748, Test accuracy: 73.35 

Round  16, Train loss: 1.717, Test loss: 1.744, Test accuracy: 73.58 

Round  17, Train loss: 1.725, Test loss: 1.737, Test accuracy: 73.95 

Round  18, Train loss: 1.708, Test loss: 1.735, Test accuracy: 73.95 

Round  19, Train loss: 1.707, Test loss: 1.731, Test accuracy: 74.07 

Round  20, Train loss: 1.709, Test loss: 1.726, Test accuracy: 74.43 

Round  21, Train loss: 1.697, Test loss: 1.724, Test accuracy: 74.65 

Round  22, Train loss: 1.689, Test loss: 1.723, Test accuracy: 74.62 

Round  23, Train loss: 1.695, Test loss: 1.721, Test accuracy: 74.92 

Round  24, Train loss: 1.683, Test loss: 1.720, Test accuracy: 74.85 

Round  25, Train loss: 1.680, Test loss: 1.719, Test accuracy: 74.73 

Round  26, Train loss: 1.687, Test loss: 1.718, Test accuracy: 74.80 

Round  27, Train loss: 1.692, Test loss: 1.718, Test accuracy: 74.80 

Round  28, Train loss: 1.699, Test loss: 1.718, Test accuracy: 74.82 

Round  29, Train loss: 1.688, Test loss: 1.716, Test accuracy: 74.97 

Round  30, Train loss: 1.675, Test loss: 1.715, Test accuracy: 74.80 

Round  31, Train loss: 1.675, Test loss: 1.715, Test accuracy: 75.05 

Round  32, Train loss: 1.674, Test loss: 1.716, Test accuracy: 74.90 

Round  33, Train loss: 1.689, Test loss: 1.714, Test accuracy: 75.02 

Round  34, Train loss: 1.671, Test loss: 1.712, Test accuracy: 75.37 

Round  35, Train loss: 1.690, Test loss: 1.712, Test accuracy: 75.40 

Round  36, Train loss: 1.682, Test loss: 1.712, Test accuracy: 75.33 

Round  37, Train loss: 1.687, Test loss: 1.711, Test accuracy: 75.50 

Round  38, Train loss: 1.679, Test loss: 1.711, Test accuracy: 75.45 

Round  39, Train loss: 1.668, Test loss: 1.709, Test accuracy: 75.68 

Round  40, Train loss: 1.675, Test loss: 1.708, Test accuracy: 75.73 

Round  41, Train loss: 1.668, Test loss: 1.707, Test accuracy: 75.82 

Round  42, Train loss: 1.667, Test loss: 1.707, Test accuracy: 75.83 

Round  43, Train loss: 1.652, Test loss: 1.706, Test accuracy: 76.05 

Round  44, Train loss: 1.668, Test loss: 1.705, Test accuracy: 76.15 

Round  45, Train loss: 1.669, Test loss: 1.706, Test accuracy: 75.90 

Round  46, Train loss: 1.657, Test loss: 1.705, Test accuracy: 76.05 

Round  47, Train loss: 1.629, Test loss: 1.704, Test accuracy: 76.13 

Round  48, Train loss: 1.661, Test loss: 1.701, Test accuracy: 76.60 

Round  49, Train loss: 1.637, Test loss: 1.700, Test accuracy: 76.67 

Round  50, Train loss: 1.674, Test loss: 1.700, Test accuracy: 76.70 

Round  51, Train loss: 1.643, Test loss: 1.699, Test accuracy: 76.72 

Round  52, Train loss: 1.653, Test loss: 1.694, Test accuracy: 77.13 

Round  53, Train loss: 1.640, Test loss: 1.692, Test accuracy: 77.42 

Round  54, Train loss: 1.643, Test loss: 1.690, Test accuracy: 77.82 

Round  55, Train loss: 1.628, Test loss: 1.688, Test accuracy: 77.90 

Round  56, Train loss: 1.623, Test loss: 1.684, Test accuracy: 78.27 

Round  57, Train loss: 1.603, Test loss: 1.680, Test accuracy: 78.60 

Round  58, Train loss: 1.647, Test loss: 1.679, Test accuracy: 78.63 

Round  59, Train loss: 1.612, Test loss: 1.675, Test accuracy: 79.15 

Round  60, Train loss: 1.607, Test loss: 1.672, Test accuracy: 79.33 

Round  61, Train loss: 1.619, Test loss: 1.668, Test accuracy: 79.70 

Round  62, Train loss: 1.610, Test loss: 1.664, Test accuracy: 80.27 

Round  63, Train loss: 1.593, Test loss: 1.662, Test accuracy: 80.42 

Round  64, Train loss: 1.602, Test loss: 1.659, Test accuracy: 80.80 

Round  65, Train loss: 1.567, Test loss: 1.655, Test accuracy: 81.10 

Round  66, Train loss: 1.593, Test loss: 1.654, Test accuracy: 81.27 

Round  67, Train loss: 1.581, Test loss: 1.649, Test accuracy: 81.72 

Round  68, Train loss: 1.583, Test loss: 1.646, Test accuracy: 81.97 

Round  69, Train loss: 1.585, Test loss: 1.646, Test accuracy: 81.95 

Round  70, Train loss: 1.600, Test loss: 1.638, Test accuracy: 82.78 

Round  71, Train loss: 1.562, Test loss: 1.637, Test accuracy: 83.13 

Round  72, Train loss: 1.579, Test loss: 1.631, Test accuracy: 83.73 

Round  73, Train loss: 1.566, Test loss: 1.629, Test accuracy: 83.85 

Round  74, Train loss: 1.546, Test loss: 1.627, Test accuracy: 83.97 

Round  75, Train loss: 1.573, Test loss: 1.619, Test accuracy: 84.82 

Round  76, Train loss: 1.567, Test loss: 1.615, Test accuracy: 85.35 

Round  77, Train loss: 1.524, Test loss: 1.611, Test accuracy: 85.63 

Round  78, Train loss: 1.555, Test loss: 1.604, Test accuracy: 86.35 

Round  79, Train loss: 1.524, Test loss: 1.601, Test accuracy: 86.57 

Round  80, Train loss: 1.533, Test loss: 1.598, Test accuracy: 86.87 

Round  81, Train loss: 1.526, Test loss: 1.597, Test accuracy: 86.87 

Round  82, Train loss: 1.529, Test loss: 1.597, Test accuracy: 86.75 

Round  83, Train loss: 1.550, Test loss: 1.590, Test accuracy: 87.70 

Round  84, Train loss: 1.504, Test loss: 1.589, Test accuracy: 87.73 

Round  85, Train loss: 1.531, Test loss: 1.580, Test accuracy: 88.67 

Round  86, Train loss: 1.512, Test loss: 1.576, Test accuracy: 89.38 

Round  87, Train loss: 1.494, Test loss: 1.574, Test accuracy: 89.33 

Round  88, Train loss: 1.516, Test loss: 1.572, Test accuracy: 89.35 

Round  89, Train loss: 1.506, Test loss: 1.570, Test accuracy: 89.58 

Round  90, Train loss: 1.513, Test loss: 1.570, Test accuracy: 89.72 

Round  91, Train loss: 1.524, Test loss: 1.570, Test accuracy: 89.63 

Round  92, Train loss: 1.496, Test loss: 1.569, Test accuracy: 89.72 

Round  93, Train loss: 1.513, Test loss: 1.568, Test accuracy: 89.75 

Round  94, Train loss: 1.510, Test loss: 1.568, Test accuracy: 89.77 

Round  95, Train loss: 1.495, Test loss: 1.566, Test accuracy: 89.98 

Round  96, Train loss: 1.486, Test loss: 1.566, Test accuracy: 90.15 
/home/ChenSM/code/FL_HLS/utils/sampling.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  97, Train loss: 1.498, Test loss: 1.565, Test accuracy: 90.08 

Round  98, Train loss: 1.494, Test loss: 1.565, Test accuracy: 90.05 

Round  99, Train loss: 1.494, Test loss: 1.565, Test accuracy: 90.07 

Final Round, Train loss: 1.500, Test loss: 1.566, Test accuracy: 89.92 

Average accuracy final 10 rounds: 89.89166666666665 

407.7642397880554
[0.5409283638000488, 0.9951682090759277, 1.4496374130249023, 1.9033453464508057, 2.3562018871307373, 2.806838274002075, 3.26350736618042, 3.720792055130005, 4.171487808227539, 4.621882200241089, 5.0731751918792725, 5.525545358657837, 5.979192495346069, 6.434047222137451, 6.8924572467803955, 7.34738564491272, 7.79965353012085, 8.25204086303711, 8.703572750091553, 9.159320831298828, 9.615415334701538, 10.067798614501953, 10.520601511001587, 10.97398591041565, 11.42657208442688, 11.878801584243774, 12.335839033126831, 12.790773868560791, 13.244305849075317, 13.696988582611084, 14.150573015213013, 14.605364561080933, 15.05793309211731, 15.519176721572876, 15.976807832717896, 16.428571224212646, 16.880488395690918, 17.333880186080933, 17.78596782684326, 18.24272394180298, 18.698538303375244, 19.151719570159912, 19.60590934753418, 20.05986785888672, 20.51058340072632, 20.963435173034668, 21.421310901641846, 21.88039255142212, 22.32953953742981, 22.782142877578735, 23.232200622558594, 23.681597232818604, 24.13169765472412, 24.587992429733276, 25.042754411697388, 25.494540691375732, 25.944847106933594, 26.398128271102905, 26.8487389087677, 27.302436351776123, 27.760578393936157, 28.218326330184937, 28.67420768737793, 29.127081632614136, 29.577536582946777, 30.030967473983765, 30.485533237457275, 30.943575859069824, 31.400180339813232, 31.851250886917114, 32.306663036346436, 32.761958837509155, 33.21228551864624, 33.668293952941895, 34.126468896865845, 34.58388710021973, 35.034740924835205, 35.48683047294617, 35.93685483932495, 36.388373136520386, 36.84572911262512, 37.30368518829346, 37.75614619255066, 38.206968784332275, 38.658958435058594, 39.11135506629944, 39.56113338470459, 40.01998686790466, 40.48167634010315, 40.934945821762085, 41.388474464416504, 41.83856439590454, 42.29126334190369, 42.74170732498169, 43.197608947753906, 43.65294671058655, 44.10233116149902, 44.55244588851929, 45.00233054161072, 45.451380014419556, 46.1934757232666]
[18.8, 30.0, 44.45, 50.583333333333336, 52.38333333333333, 46.166666666666664, 46.833333333333336, 48.38333333333333, 54.11666666666667, 59.233333333333334, 62.21666666666667, 66.78333333333333, 69.48333333333333, 70.98333333333333, 72.46666666666667, 73.35, 73.58333333333333, 73.95, 73.95, 74.06666666666666, 74.43333333333334, 74.65, 74.61666666666666, 74.91666666666667, 74.85, 74.73333333333333, 74.8, 74.8, 74.81666666666666, 74.96666666666667, 74.8, 75.05, 74.9, 75.01666666666667, 75.36666666666666, 75.4, 75.33333333333333, 75.5, 75.45, 75.68333333333334, 75.73333333333333, 75.81666666666666, 75.83333333333333, 76.05, 76.15, 75.9, 76.05, 76.13333333333334, 76.6, 76.66666666666667, 76.7, 76.71666666666667, 77.13333333333334, 77.41666666666667, 77.81666666666666, 77.9, 78.26666666666667, 78.6, 78.63333333333334, 79.15, 79.33333333333333, 79.7, 80.26666666666667, 80.41666666666667, 80.8, 81.1, 81.26666666666667, 81.71666666666667, 81.96666666666667, 81.95, 82.78333333333333, 83.13333333333334, 83.73333333333333, 83.85, 83.96666666666667, 84.81666666666666, 85.35, 85.63333333333334, 86.35, 86.56666666666666, 86.86666666666666, 86.86666666666666, 86.75, 87.7, 87.73333333333333, 88.66666666666667, 89.38333333333334, 89.33333333333333, 89.35, 89.58333333333333, 89.71666666666667, 89.63333333333334, 89.71666666666667, 89.75, 89.76666666666667, 89.98333333333333, 90.15, 90.08333333333333, 90.05, 90.06666666666666, 89.91666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.2  

lg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 17098 (global); Percentage 3.11 (17098/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.302, Test loss: 2.301, Test accuracy: 17.32 

Round   1, Train loss: 2.300, Test loss: 2.300, Test accuracy: 22.92 

Round   2, Train loss: 2.298, Test loss: 2.298, Test accuracy: 30.78 

Round   3, Train loss: 2.299, Test loss: 2.297, Test accuracy: 31.62 

Round   4, Train loss: 2.296, Test loss: 2.295, Test accuracy: 41.18 

Round   5, Train loss: 2.293, Test loss: 2.293, Test accuracy: 42.57 

Round   6, Train loss: 2.288, Test loss: 2.289, Test accuracy: 43.43 

Round   7, Train loss: 2.285, Test loss: 2.285, Test accuracy: 45.58 

Round   8, Train loss: 2.264, Test loss: 2.271, Test accuracy: 44.37 

Round   9, Train loss: 2.213, Test loss: 2.236, Test accuracy: 42.85 

Round  10, Train loss: 2.215, Test loss: 2.194, Test accuracy: 41.73 

Round  11, Train loss: 2.106, Test loss: 2.132, Test accuracy: 45.35 

Round  12, Train loss: 2.108, Test loss: 2.076, Test accuracy: 48.42 

Round  13, Train loss: 1.983, Test loss: 2.012, Test accuracy: 56.38 

Round  14, Train loss: 1.900, Test loss: 1.960, Test accuracy: 61.77 

Round  15, Train loss: 1.852, Test loss: 1.907, Test accuracy: 64.48 

Round  16, Train loss: 1.834, Test loss: 1.858, Test accuracy: 67.43 

Round  17, Train loss: 1.740, Test loss: 1.814, Test accuracy: 72.08 

Round  18, Train loss: 1.713, Test loss: 1.775, Test accuracy: 74.88 

Round  19, Train loss: 1.665, Test loss: 1.751, Test accuracy: 76.02 

Round  20, Train loss: 1.641, Test loss: 1.734, Test accuracy: 76.67 

Round  21, Train loss: 1.614, Test loss: 1.726, Test accuracy: 76.93 

Round  22, Train loss: 1.627, Test loss: 1.719, Test accuracy: 77.18 

Round  23, Train loss: 1.623, Test loss: 1.704, Test accuracy: 78.32 

Round  24, Train loss: 1.614, Test loss: 1.697, Test accuracy: 78.70 

Round  25, Train loss: 1.597, Test loss: 1.695, Test accuracy: 78.62 

Round  26, Train loss: 1.580, Test loss: 1.693, Test accuracy: 78.62 

Round  27, Train loss: 1.605, Test loss: 1.690, Test accuracy: 78.57 

Round  28, Train loss: 1.584, Test loss: 1.683, Test accuracy: 80.62 

Round  29, Train loss: 1.559, Test loss: 1.675, Test accuracy: 81.78 

Round  30, Train loss: 1.527, Test loss: 1.674, Test accuracy: 81.48 

Round  31, Train loss: 1.529, Test loss: 1.667, Test accuracy: 81.98 

Round  32, Train loss: 1.513, Test loss: 1.660, Test accuracy: 82.58 

Round  33, Train loss: 1.508, Test loss: 1.659, Test accuracy: 82.23 

Round  34, Train loss: 1.515, Test loss: 1.655, Test accuracy: 82.30 

Round  35, Train loss: 1.516, Test loss: 1.652, Test accuracy: 82.55 

Round  36, Train loss: 1.500, Test loss: 1.650, Test accuracy: 82.58 

Round  37, Train loss: 1.505, Test loss: 1.646, Test accuracy: 82.90 

Round  38, Train loss: 1.499, Test loss: 1.646, Test accuracy: 82.95 

Round  39, Train loss: 1.492, Test loss: 1.645, Test accuracy: 82.93 

Round  40, Train loss: 1.498, Test loss: 1.645, Test accuracy: 82.87 

Round  41, Train loss: 1.488, Test loss: 1.644, Test accuracy: 82.92 

Round  42, Train loss: 1.491, Test loss: 1.643, Test accuracy: 82.90 

Round  43, Train loss: 1.494, Test loss: 1.643, Test accuracy: 82.88 

Round  44, Train loss: 1.490, Test loss: 1.642, Test accuracy: 83.02 

Round  45, Train loss: 1.487, Test loss: 1.642, Test accuracy: 83.02 

Round  46, Train loss: 1.486, Test loss: 1.641, Test accuracy: 83.03 

Round  47, Train loss: 1.490, Test loss: 1.641, Test accuracy: 82.90 

Round  48, Train loss: 1.480, Test loss: 1.640, Test accuracy: 83.00 

Round  49, Train loss: 1.490, Test loss: 1.640, Test accuracy: 82.93 

Round  50, Train loss: 1.485, Test loss: 1.639, Test accuracy: 82.92 

Round  51, Train loss: 1.493, Test loss: 1.640, Test accuracy: 82.87 

Round  52, Train loss: 1.485, Test loss: 1.640, Test accuracy: 82.98 

Round  53, Train loss: 1.483, Test loss: 1.639, Test accuracy: 82.95 

Round  54, Train loss: 1.491, Test loss: 1.639, Test accuracy: 83.00 

Round  55, Train loss: 1.480, Test loss: 1.639, Test accuracy: 83.05 

Round  56, Train loss: 1.482, Test loss: 1.638, Test accuracy: 82.97 

Round  57, Train loss: 1.481, Test loss: 1.638, Test accuracy: 83.05 

Round  58, Train loss: 1.481, Test loss: 1.638, Test accuracy: 83.05 

Round  59, Train loss: 1.486, Test loss: 1.638, Test accuracy: 83.13 

Round  60, Train loss: 1.478, Test loss: 1.638, Test accuracy: 83.13 

Round  61, Train loss: 1.492, Test loss: 1.638, Test accuracy: 83.03 

Round  62, Train loss: 1.489, Test loss: 1.638, Test accuracy: 83.03 

Round  63, Train loss: 1.487, Test loss: 1.638, Test accuracy: 83.10 

Round  64, Train loss: 1.482, Test loss: 1.638, Test accuracy: 83.05 

Round  65, Train loss: 1.487, Test loss: 1.638, Test accuracy: 83.00 

Round  66, Train loss: 1.484, Test loss: 1.638, Test accuracy: 82.95 

Round  67, Train loss: 1.476, Test loss: 1.638, Test accuracy: 82.98 

Round  68, Train loss: 1.476, Test loss: 1.637, Test accuracy: 82.98 

Round  69, Train loss: 1.485, Test loss: 1.637, Test accuracy: 83.00 

Round  70, Train loss: 1.479, Test loss: 1.637, Test accuracy: 83.12 

Round  71, Train loss: 1.483, Test loss: 1.637, Test accuracy: 83.00 

Round  72, Train loss: 1.486, Test loss: 1.637, Test accuracy: 83.03 

Round  73, Train loss: 1.485, Test loss: 1.637, Test accuracy: 83.03 

Round  74, Train loss: 1.483, Test loss: 1.637, Test accuracy: 83.12 

Round  75, Train loss: 1.479, Test loss: 1.637, Test accuracy: 83.10 

Round  76, Train loss: 1.482, Test loss: 1.637, Test accuracy: 83.13 

Round  77, Train loss: 1.482, Test loss: 1.636, Test accuracy: 83.12 

Round  78, Train loss: 1.481, Test loss: 1.636, Test accuracy: 83.12 

Round  79, Train loss: 1.483, Test loss: 1.636, Test accuracy: 83.15 

Round  80, Train loss: 1.486, Test loss: 1.636, Test accuracy: 83.20 

Round  81, Train loss: 1.480, Test loss: 1.636, Test accuracy: 83.18 

Round  82, Train loss: 1.481, Test loss: 1.636, Test accuracy: 83.17 

Round  83, Train loss: 1.482, Test loss: 1.636, Test accuracy: 83.20 

Round  84, Train loss: 1.483, Test loss: 1.636, Test accuracy: 83.17 

Round  85, Train loss: 1.488, Test loss: 1.636, Test accuracy: 83.18 

Round  86, Train loss: 1.489, Test loss: 1.636, Test accuracy: 83.17 

Round  87, Train loss: 1.481, Test loss: 1.636, Test accuracy: 83.08 

Round  88, Train loss: 1.484, Test loss: 1.636, Test accuracy: 83.10 

Round  89, Train loss: 1.479, Test loss: 1.636, Test accuracy: 83.08 

Round  90, Train loss: 1.480, Test loss: 1.636, Test accuracy: 83.08 

Round  91, Train loss: 1.482, Test loss: 1.635, Test accuracy: 83.08 

Round  92, Train loss: 1.485, Test loss: 1.635, Test accuracy: 83.15 

Round  93, Train loss: 1.483, Test loss: 1.635, Test accuracy: 83.15 

Round  94, Train loss: 1.477, Test loss: 1.635, Test accuracy: 83.15 

Round  95, Train loss: 1.484, Test loss: 1.635, Test accuracy: 83.12 

Round  96, Train loss: 1.482, Test loss: 1.635, Test accuracy: 83.15 

Round  97, Train loss: 1.481, Test loss: 1.635, Test accuracy: 83.20 
/home/ChenSM/code/FL_HLS/utils/sampling.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  98, Train loss: 1.482, Test loss: 1.635, Test accuracy: 83.18 

Round  99, Train loss: 1.480, Test loss: 1.635, Test accuracy: 83.20 

Final Round, Train loss: 1.481, Test loss: 1.635, Test accuracy: 83.20 

Average accuracy final 10 rounds: 83.14666666666665 

410.8892707824707
[0.5448095798492432, 0.9981906414031982, 1.4524812698364258, 1.9109585285186768, 2.3652782440185547, 2.8234245777130127, 3.278489112854004, 3.734861373901367, 4.189744234085083, 4.642908811569214, 5.102741718292236, 5.558742046356201, 6.008871078491211, 6.465338945388794, 6.920605897903442, 7.371825695037842, 7.82998514175415, 8.28705358505249, 8.748699188232422, 9.202770233154297, 9.652282953262329, 10.109473466873169, 10.56213665008545, 11.016321420669556, 11.476469278335571, 11.931370258331299, 12.382124185562134, 12.831827402114868, 13.28219747543335, 13.740391492843628, 14.198841333389282, 14.655132055282593, 15.109740734100342, 15.559993743896484, 16.010509729385376, 16.463931560516357, 16.91633105278015, 17.36921501159668, 17.823713541030884, 18.275415658950806, 18.73323369026184, 19.186420679092407, 19.634690284729004, 20.0886390209198, 20.54794430732727, 21.0012686252594, 21.456902027130127, 21.905627727508545, 22.35375690460205, 22.80568027496338, 23.25927233695984, 23.722382307052612, 24.17821979522705, 24.62627625465393, 25.079612493515015, 25.530165433883667, 25.97908306121826, 26.440272092819214, 26.90222716331482, 27.356069803237915, 27.809022426605225, 28.25953197479248, 28.711256742477417, 29.16358709335327, 29.621794939041138, 30.084471225738525, 30.541677951812744, 30.990527391433716, 31.443198919296265, 31.895172119140625, 32.35231351852417, 32.81340479850769, 33.269262075424194, 33.72020769119263, 34.171326637268066, 34.620113372802734, 35.073755979537964, 35.526028871536255, 35.982627391815186, 36.44149827957153, 36.89650869369507, 37.35051918029785, 37.80409526824951, 38.25378942489624, 38.707932233810425, 39.16657638549805, 39.62257194519043, 40.0737738609314, 40.5228545665741, 40.981436252593994, 41.43133592605591, 41.881524324417114, 42.33999538421631, 42.79662275314331, 43.247201442718506, 43.69836139678955, 44.15268039703369, 44.60392785072327, 45.05818176269531, 45.51664876937866, 46.366199016571045]
[17.316666666666666, 22.916666666666668, 30.783333333333335, 31.616666666666667, 41.18333333333333, 42.56666666666667, 43.43333333333333, 45.583333333333336, 44.36666666666667, 42.85, 41.733333333333334, 45.35, 48.416666666666664, 56.38333333333333, 61.766666666666666, 64.48333333333333, 67.43333333333334, 72.08333333333333, 74.88333333333334, 76.01666666666667, 76.66666666666667, 76.93333333333334, 77.18333333333334, 78.31666666666666, 78.7, 78.61666666666666, 78.61666666666666, 78.56666666666666, 80.61666666666666, 81.78333333333333, 81.48333333333333, 81.98333333333333, 82.58333333333333, 82.23333333333333, 82.3, 82.55, 82.58333333333333, 82.9, 82.95, 82.93333333333334, 82.86666666666666, 82.91666666666667, 82.9, 82.88333333333334, 83.01666666666667, 83.01666666666667, 83.03333333333333, 82.9, 83.0, 82.93333333333334, 82.91666666666667, 82.86666666666666, 82.98333333333333, 82.95, 83.0, 83.05, 82.96666666666667, 83.05, 83.05, 83.13333333333334, 83.13333333333334, 83.03333333333333, 83.03333333333333, 83.1, 83.05, 83.0, 82.95, 82.98333333333333, 82.98333333333333, 83.0, 83.11666666666666, 83.0, 83.03333333333333, 83.03333333333333, 83.11666666666666, 83.1, 83.13333333333334, 83.11666666666666, 83.11666666666666, 83.15, 83.2, 83.18333333333334, 83.16666666666667, 83.2, 83.16666666666667, 83.18333333333334, 83.16666666666667, 83.08333333333333, 83.1, 83.08333333333333, 83.08333333333333, 83.08333333333333, 83.15, 83.15, 83.15, 83.11666666666666, 83.15, 83.2, 83.18333333333334, 83.2, 83.2]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
Round   0, Train loss: 1.714, Test loss: 2.297, Test accuracy: 38.18
Round   1, Train loss: 1.652, Test loss: 2.283, Test accuracy: 40.68
Round   2, Train loss: 1.551, Test loss: 2.258, Test accuracy: 45.52
Round   3, Train loss: 1.490, Test loss: 2.214, Test accuracy: 50.80
Round   4, Train loss: 1.393, Test loss: 2.181, Test accuracy: 56.70
Round   5, Train loss: 1.353, Test loss: 2.146, Test accuracy: 60.77
Round   6, Train loss: 1.318, Test loss: 2.120, Test accuracy: 62.62
Round   7, Train loss: 1.308, Test loss: 2.098, Test accuracy: 65.40
Round   8, Train loss: 1.280, Test loss: 2.082, Test accuracy: 67.08
Round   9, Train loss: 1.278, Test loss: 2.068, Test accuracy: 68.38
Round  10, Train loss: 1.285, Test loss: 2.059, Test accuracy: 69.75
Round  11, Train loss: 1.260, Test loss: 2.049, Test accuracy: 70.43
Round  12, Train loss: 1.260, Test loss: 2.045, Test accuracy: 70.30
Round  13, Train loss: 1.267, Test loss: 2.039, Test accuracy: 70.70
Round  14, Train loss: 1.254, Test loss: 2.035, Test accuracy: 70.98
Round  15, Train loss: 1.253, Test loss: 2.034, Test accuracy: 70.63
Round  16, Train loss: 1.257, Test loss: 2.029, Test accuracy: 70.63
Round  17, Train loss: 1.246, Test loss: 2.025, Test accuracy: 70.62
Round  18, Train loss: 1.261, Test loss: 2.024, Test accuracy: 70.43
Round  19, Train loss: 1.251, Test loss: 2.022, Test accuracy: 69.83
Round  20, Train loss: 1.249, Test loss: 2.020, Test accuracy: 69.68
Round  21, Train loss: 1.249, Test loss: 2.019, Test accuracy: 69.67
Round  22, Train loss: 1.255, Test loss: 2.018, Test accuracy: 69.62
Round  23, Train loss: 1.254, Test loss: 2.017, Test accuracy: 69.07
Round  24, Train loss: 1.245, Test loss: 2.016, Test accuracy: 69.03
Round  25, Train loss: 1.254, Test loss: 2.016, Test accuracy: 68.95
Round  26, Train loss: 1.247, Test loss: 2.014, Test accuracy: 68.78
Round  27, Train loss: 1.247, Test loss: 2.014, Test accuracy: 68.55
Round  28, Train loss: 1.245, Test loss: 2.014, Test accuracy: 68.13
Round  29, Train loss: 1.249, Test loss: 2.013, Test accuracy: 67.85
Round  30, Train loss: 1.249, Test loss: 2.013, Test accuracy: 67.70
Round  31, Train loss: 1.248, Test loss: 2.012, Test accuracy: 67.55
Round  32, Train loss: 1.244, Test loss: 2.013, Test accuracy: 67.32
Round  33, Train loss: 1.247, Test loss: 2.012, Test accuracy: 67.27
Round  34, Train loss: 1.245, Test loss: 2.011, Test accuracy: 67.02
Round  35, Train loss: 1.248, Test loss: 2.012, Test accuracy: 66.47
Round  36, Train loss: 1.253, Test loss: 2.012, Test accuracy: 66.13
Round  37, Train loss: 1.245, Test loss: 2.012, Test accuracy: 65.78
Round  38, Train loss: 1.255, Test loss: 2.012, Test accuracy: 66.00
Round  39, Train loss: 1.250, Test loss: 2.013, Test accuracy: 65.43
Round  40, Train loss: 1.249, Test loss: 2.013, Test accuracy: 65.45
Round  41, Train loss: 1.249, Test loss: 2.011, Test accuracy: 65.43
Round  42, Train loss: 1.242, Test loss: 2.011, Test accuracy: 65.28
Round  43, Train loss: 1.247, Test loss: 2.011, Test accuracy: 65.13
Round  44, Train loss: 1.243, Test loss: 2.012, Test accuracy: 64.98
Round  45, Train loss: 1.254, Test loss: 2.011, Test accuracy: 64.80
Round  46, Train loss: 1.251, Test loss: 2.012, Test accuracy: 64.63
Round  47, Train loss: 1.241, Test loss: 2.010, Test accuracy: 64.77
Round  48, Train loss: 1.243, Test loss: 2.011, Test accuracy: 64.43
Round  49, Train loss: 1.242, Test loss: 2.011, Test accuracy: 64.23
Round  50, Train loss: 1.241, Test loss: 2.010, Test accuracy: 64.42
Round  51, Train loss: 1.244, Test loss: 2.010, Test accuracy: 64.22
Round  52, Train loss: 1.241, Test loss: 2.011, Test accuracy: 63.82
Round  53, Train loss: 1.250, Test loss: 2.012, Test accuracy: 63.58
Round  54, Train loss: 1.246, Test loss: 2.012, Test accuracy: 63.32
Round  55, Train loss: 1.241, Test loss: 2.012, Test accuracy: 63.43
Round  56, Train loss: 1.233, Test loss: 2.011, Test accuracy: 63.33
Round  57, Train loss: 1.240, Test loss: 2.012, Test accuracy: 62.88
Round  58, Train loss: 1.247, Test loss: 2.013, Test accuracy: 62.97
Round  59, Train loss: 1.242, Test loss: 2.013, Test accuracy: 62.95
Round  60, Train loss: 1.239, Test loss: 2.014, Test accuracy: 62.20
Round  61, Train loss: 1.242, Test loss: 2.014, Test accuracy: 61.85
Round  62, Train loss: 1.236, Test loss: 2.014, Test accuracy: 61.50
Round  63, Train loss: 1.249, Test loss: 2.014, Test accuracy: 61.32
Round  64, Train loss: 1.242, Test loss: 2.014, Test accuracy: 61.13
Round  65, Train loss: 1.253, Test loss: 2.014, Test accuracy: 61.12
Round  66, Train loss: 1.251, Test loss: 2.015, Test accuracy: 61.10
Round  67, Train loss: 1.247, Test loss: 2.014, Test accuracy: 61.17
Round  68, Train loss: 1.233, Test loss: 2.014, Test accuracy: 60.83
Round  69, Train loss: 1.243, Test loss: 2.015, Test accuracy: 60.55
Round  70, Train loss: 1.248, Test loss: 2.015, Test accuracy: 60.50
Round  71, Train loss: 1.241, Test loss: 2.016, Test accuracy: 60.35
Round  72, Train loss: 1.247, Test loss: 2.016, Test accuracy: 60.05
Round  73, Train loss: 1.247, Test loss: 2.017, Test accuracy: 59.93
Round  74, Train loss: 1.233, Test loss: 2.016, Test accuracy: 59.87
Round  75, Train loss: 1.246, Test loss: 2.016, Test accuracy: 59.97
Round  76, Train loss: 1.245, Test loss: 2.016, Test accuracy: 59.83
Round  77, Train loss: 1.245, Test loss: 2.017, Test accuracy: 59.80
Round  78, Train loss: 1.241, Test loss: 2.017, Test accuracy: 59.58
Round  79, Train loss: 1.246, Test loss: 2.017, Test accuracy: 59.63
Round  80, Train loss: 1.243, Test loss: 2.017, Test accuracy: 59.38
Round  81, Train loss: 1.248, Test loss: 2.018, Test accuracy: 59.25
Round  82, Train loss: 1.247, Test loss: 2.018, Test accuracy: 59.35
Round  83, Train loss: 1.248, Test loss: 2.018, Test accuracy: 59.22
Round  84, Train loss: 1.239, Test loss: 2.018, Test accuracy: 59.12
Round  85, Train loss: 1.235, Test loss: 2.018, Test accuracy: 59.10
Round  86, Train loss: 1.235, Test loss: 2.018, Test accuracy: 59.15
Round  87, Train loss: 1.227, Test loss: 2.019, Test accuracy: 58.98
Round  88, Train loss: 1.244, Test loss: 2.019, Test accuracy: 58.87
Round  89, Train loss: 1.239, Test loss: 2.020, Test accuracy: 58.85
Round  90, Train loss: 1.241, Test loss: 2.020, Test accuracy: 58.83
Round  91, Train loss: 1.242, Test loss: 2.024, Test accuracy: 58.82
Round  92, Train loss: 1.218, Test loss: 2.024, Test accuracy: 60.35
Round  93, Train loss: 1.201, Test loss: 2.018, Test accuracy: 63.18
Round  94, Train loss: 1.191, Test loss: 2.015, Test accuracy: 64.20
Round  95, Train loss: 1.195, Test loss: 2.015, Test accuracy: 64.75
Round  96, Train loss: 1.189, Test loss: 2.013, Test accuracy: 65.63
Round  97, Train loss: 1.188, Test loss: 2.009, Test accuracy: 66.10
Round  98, Train loss: 1.180, Test loss: 2.010, Test accuracy: 66.22
Round  99, Train loss: 1.183, Test loss: 2.008, Test accuracy: 66.33
Final Round, Train loss: 1.182, Test loss: 2.008, Test accuracy: 65.60
Average accuracy final 10 rounds: 63.44166666666667
665.707957983017
[]
[38.18333333333333, 40.68333333333333, 45.516666666666666, 50.8, 56.7, 60.766666666666666, 62.61666666666667, 65.4, 67.08333333333333, 68.38333333333334, 69.75, 70.43333333333334, 70.3, 70.7, 70.98333333333333, 70.63333333333334, 70.63333333333334, 70.61666666666666, 70.43333333333334, 69.83333333333333, 69.68333333333334, 69.66666666666667, 69.61666666666666, 69.06666666666666, 69.03333333333333, 68.95, 68.78333333333333, 68.55, 68.13333333333334, 67.85, 67.7, 67.55, 67.31666666666666, 67.26666666666667, 67.01666666666667, 66.46666666666667, 66.13333333333334, 65.78333333333333, 66.0, 65.43333333333334, 65.45, 65.43333333333334, 65.28333333333333, 65.13333333333334, 64.98333333333333, 64.8, 64.63333333333334, 64.76666666666667, 64.43333333333334, 64.23333333333333, 64.41666666666667, 64.21666666666667, 63.81666666666667, 63.583333333333336, 63.31666666666667, 63.43333333333333, 63.333333333333336, 62.88333333333333, 62.96666666666667, 62.95, 62.2, 61.85, 61.5, 61.31666666666667, 61.13333333333333, 61.11666666666667, 61.1, 61.166666666666664, 60.833333333333336, 60.55, 60.5, 60.35, 60.05, 59.93333333333333, 59.86666666666667, 59.96666666666667, 59.833333333333336, 59.8, 59.583333333333336, 59.63333333333333, 59.38333333333333, 59.25, 59.35, 59.21666666666667, 59.11666666666667, 59.1, 59.15, 58.983333333333334, 58.86666666666667, 58.85, 58.833333333333336, 58.81666666666667, 60.35, 63.18333333333333, 64.2, 64.75, 65.63333333333334, 66.1, 66.21666666666667, 66.33333333333333, 65.6]/home/ChenSM/code/FL_HLS/utils/sampling.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.82
Round   0: Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.73
Round   1, Train loss: 2.298, Test loss: 2.302, Test accuracy: 9.70
Round   1: Global train loss: 2.298, Global test loss: 2.303, Global test accuracy: 8.77
Round   2, Train loss: 2.305, Test loss: 2.301, Test accuracy: 11.18
Round   2: Global train loss: 2.305, Global test loss: 2.303, Global test accuracy: 8.77
Round   3, Train loss: 2.303, Test loss: 2.301, Test accuracy: 12.33
Round   3: Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 8.77
Round   4, Train loss: 2.291, Test loss: 2.301, Test accuracy: 11.60
Round   4: Global train loss: 2.291, Global test loss: 2.302, Global test accuracy: 8.78
Round   5, Train loss: 2.296, Test loss: 2.301, Test accuracy: 11.85
Round   5: Global train loss: 2.296, Global test loss: 2.302, Global test accuracy: 8.78
Round   6, Train loss: 2.305, Test loss: 2.301, Test accuracy: 12.68
Round   6: Global train loss: 2.305, Global test loss: 2.302, Global test accuracy: 8.78
Round   7, Train loss: 2.301, Test loss: 2.299, Test accuracy: 15.38
Round   7: Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 8.80
Round   8, Train loss: 2.291, Test loss: 2.299, Test accuracy: 15.02
Round   8: Global train loss: 2.291, Global test loss: 2.301, Global test accuracy: 8.87
Round   9, Train loss: 2.293, Test loss: 2.299, Test accuracy: 14.52
Round   9: Global train loss: 2.293, Global test loss: 2.301, Global test accuracy: 8.88
Round  10, Train loss: 2.293, Test loss: 2.300, Test accuracy: 13.23
Round  10: Global train loss: 2.293, Global test loss: 2.301, Global test accuracy: 8.90
Round  11, Train loss: 2.295, Test loss: 2.298, Test accuracy: 15.38
Round  11: Global train loss: 2.295, Global test loss: 2.301, Global test accuracy: 9.17
Round  12, Train loss: 2.279, Test loss: 2.296, Test accuracy: 17.43
Round  12: Global train loss: 2.279, Global test loss: 2.300, Global test accuracy: 9.67
Round  13, Train loss: 2.276, Test loss: 2.294, Test accuracy: 18.48
Round  13: Global train loss: 2.276, Global test loss: 2.300, Global test accuracy: 11.00
Round  14, Train loss: 2.276, Test loss: 2.293, Test accuracy: 19.02
Round  14: Global train loss: 2.276, Global test loss: 2.300, Global test accuracy: 13.98
Round  15, Train loss: 2.294, Test loss: 2.294, Test accuracy: 18.02
Round  15: Global train loss: 2.294, Global test loss: 2.299, Global test accuracy: 15.32
Round  16, Train loss: 2.282, Test loss: 2.292, Test accuracy: 17.55
Round  16: Global train loss: 2.282, Global test loss: 2.299, Global test accuracy: 15.60
Round  17, Train loss: 2.240, Test loss: 2.288, Test accuracy: 19.57
Round  17: Global train loss: 2.240, Global test loss: 2.299, Global test accuracy: 17.43
Round  18, Train loss: 2.245, Test loss: 2.288, Test accuracy: 18.12
Round  18: Global train loss: 2.245, Global test loss: 2.298, Global test accuracy: 17.87
Round  19, Train loss: 2.281, Test loss: 2.287, Test accuracy: 19.02
Round  19: Global train loss: 2.281, Global test loss: 2.298, Global test accuracy: 19.30
Round  20, Train loss: 2.228, Test loss: 2.282, Test accuracy: 20.92
Round  20: Global train loss: 2.228, Global test loss: 2.297, Global test accuracy: 20.53
Round  21, Train loss: 2.266, Test loss: 2.281, Test accuracy: 20.13
Round  21: Global train loss: 2.266, Global test loss: 2.297, Global test accuracy: 22.18
Round  22, Train loss: 1.992, Test loss: 2.255, Test accuracy: 24.65
Round  22: Global train loss: 1.992, Global test loss: 2.294, Global test accuracy: 25.37
Round  23, Train loss: 2.250, Test loss: 2.258, Test accuracy: 22.52
Round  23: Global train loss: 2.250, Global test loss: 2.293, Global test accuracy: 26.28
Round  24, Train loss: 2.362, Test loss: 2.273, Test accuracy: 21.20
Round  24: Global train loss: 2.362, Global test loss: 2.294, Global test accuracy: 25.05
Round  25, Train loss: 2.141, Test loss: 2.263, Test accuracy: 22.75
Round  25: Global train loss: 2.141, Global test loss: 2.292, Global test accuracy: 26.87
Round  26, Train loss: 2.335, Test loss: 2.273, Test accuracy: 21.83
Round  26: Global train loss: 2.335, Global test loss: 2.293, Global test accuracy: 26.07
Round  27, Train loss: 2.274, Test loss: 2.280, Test accuracy: 21.00
Round  27: Global train loss: 2.274, Global test loss: 2.293, Global test accuracy: 25.82
Round  28, Train loss: 2.156, Test loss: 2.271, Test accuracy: 19.95
Round  28: Global train loss: 2.156, Global test loss: 2.293, Global test accuracy: 26.42
Round  29, Train loss: 1.929, Test loss: 2.258, Test accuracy: 21.27
Round  29: Global train loss: 1.929, Global test loss: 2.292, Global test accuracy: 27.58
Round  30, Train loss: 2.137, Test loss: 2.252, Test accuracy: 23.32
Round  30: Global train loss: 2.137, Global test loss: 2.291, Global test accuracy: 27.87
Round  31, Train loss: 2.096, Test loss: 2.264, Test accuracy: 21.37
Round  31: Global train loss: 2.096, Global test loss: 2.292, Global test accuracy: 27.08
Round  32, Train loss: 1.846, Test loss: 2.243, Test accuracy: 23.18
Round  32: Global train loss: 1.846, Global test loss: 2.290, Global test accuracy: 27.97
Round  33, Train loss: 1.955, Test loss: 2.244, Test accuracy: 24.32
Round  33: Global train loss: 1.955, Global test loss: 2.291, Global test accuracy: 29.77
Round  34, Train loss: 2.131, Test loss: 2.242, Test accuracy: 26.12
Round  34: Global train loss: 2.131, Global test loss: 2.291, Global test accuracy: 28.07
Round  35, Train loss: 2.226, Test loss: 2.255, Test accuracy: 24.85
Round  35: Global train loss: 2.226, Global test loss: 2.292, Global test accuracy: 24.03
Round  36, Train loss: 1.545, Test loss: 2.218, Test accuracy: 28.72
Round  36: Global train loss: 1.545, Global test loss: 2.289, Global test accuracy: 30.58
Round  37, Train loss: 1.886, Test loss: 2.236, Test accuracy: 25.77
Round  37: Global train loss: 1.886, Global test loss: 2.290, Global test accuracy: 28.05
Round  38, Train loss: 2.046, Test loss: 2.225, Test accuracy: 26.95
Round  38: Global train loss: 2.046, Global test loss: 2.289, Global test accuracy: 28.77
Round  39, Train loss: 1.430, Test loss: 2.211, Test accuracy: 29.67
Round  39: Global train loss: 1.430, Global test loss: 2.288, Global test accuracy: 29.40
Round  40, Train loss: 2.004, Test loss: 2.232, Test accuracy: 27.12
Round  40: Global train loss: 2.004, Global test loss: 2.290, Global test accuracy: 27.47
Round  41, Train loss: 2.368, Test loss: 2.248, Test accuracy: 23.07
Round  41: Global train loss: 2.368, Global test loss: 2.292, Global test accuracy: 23.02
Round  42, Train loss: 1.580, Test loss: 2.224, Test accuracy: 23.50
Round  42: Global train loss: 1.580, Global test loss: 2.291, Global test accuracy: 22.35
Round  43, Train loss: 1.606, Test loss: 2.191, Test accuracy: 30.50
Round  43: Global train loss: 1.606, Global test loss: 2.287, Global test accuracy: 26.88
Round  44, Train loss: 2.312, Test loss: 2.212, Test accuracy: 25.73
Round  44: Global train loss: 2.312, Global test loss: 2.289, Global test accuracy: 26.08
Round  45, Train loss: 1.533, Test loss: 2.205, Test accuracy: 26.63
Round  45: Global train loss: 1.533, Global test loss: 2.289, Global test accuracy: 25.57
Round  46, Train loss: 1.301, Test loss: 2.199, Test accuracy: 25.70
Round  46: Global train loss: 1.301, Global test loss: 2.288, Global test accuracy: 27.58
Round  47, Train loss: 1.717, Test loss: 2.167, Test accuracy: 30.22
Round  47: Global train loss: 1.717, Global test loss: 2.286, Global test accuracy: 30.82
Round  48, Train loss: 1.186, Test loss: 2.174, Test accuracy: 27.32
Round  48: Global train loss: 1.186, Global test loss: 2.286, Global test accuracy: 29.45
Round  49, Train loss: 1.387, Test loss: 2.161, Test accuracy: 28.33
Round  49: Global train loss: 1.387, Global test loss: 2.284, Global test accuracy: 29.92
Round  50, Train loss: 1.367, Test loss: 2.161, Test accuracy: 27.93
Round  50: Global train loss: 1.367, Global test loss: 2.285, Global test accuracy: 29.72
Round  51, Train loss: 1.082, Test loss: 2.117, Test accuracy: 33.53
Round  51: Global train loss: 1.082, Global test loss: 2.281, Global test accuracy: 33.38
Round  52, Train loss: 0.221, Test loss: 2.099, Test accuracy: 35.75
Round  52: Global train loss: 0.221, Global test loss: 2.274, Global test accuracy: 41.57
Round  53, Train loss: 0.447, Test loss: 2.072, Test accuracy: 38.88
Round  53: Global train loss: 0.447, Global test loss: 2.266, Global test accuracy: 44.57
Round  54, Train loss: 1.419, Test loss: 2.080, Test accuracy: 36.97
Round  54: Global train loss: 1.419, Global test loss: 2.262, Global test accuracy: 44.88
Round  55, Train loss: 1.420, Test loss: 2.076, Test accuracy: 37.73
Round  55: Global train loss: 1.420, Global test loss: 2.262, Global test accuracy: 44.75
Round  56, Train loss: 1.268, Test loss: 2.101, Test accuracy: 34.42
Round  56: Global train loss: 1.268, Global test loss: 2.260, Global test accuracy: 43.13
Round  57, Train loss: 2.221, Test loss: 2.177, Test accuracy: 26.40
Round  57: Global train loss: 2.221, Global test loss: 2.273, Global test accuracy: 38.47
Round  58, Train loss: 1.504, Test loss: 2.177, Test accuracy: 26.45
Round  58: Global train loss: 1.504, Global test loss: 2.276, Global test accuracy: 34.93
Round  59, Train loss: 1.110, Test loss: 2.164, Test accuracy: 27.70
Round  59: Global train loss: 1.110, Global test loss: 2.277, Global test accuracy: 36.27
Round  60, Train loss: 1.363, Test loss: 2.118, Test accuracy: 34.77
Round  60: Global train loss: 1.363, Global test loss: 2.274, Global test accuracy: 38.73
Round  61, Train loss: 0.878, Test loss: 2.113, Test accuracy: 34.97
Round  61: Global train loss: 0.878, Global test loss: 2.273, Global test accuracy: 39.52
Round  62, Train loss: 1.636, Test loss: 2.154, Test accuracy: 30.62
Round  62: Global train loss: 1.636, Global test loss: 2.280, Global test accuracy: 36.05
Round  63, Train loss: 0.674, Test loss: 2.114, Test accuracy: 34.58
Round  63: Global train loss: 0.674, Global test loss: 2.277, Global test accuracy: 39.00
Round  64, Train loss: -0.307, Test loss: 2.067, Test accuracy: 40.20
Round  64: Global train loss: -0.307, Global test loss: 2.269, Global test accuracy: 42.97
Round  65, Train loss: 0.801, Test loss: 2.066, Test accuracy: 39.57
Round  65: Global train loss: 0.801, Global test loss: 2.269, Global test accuracy: 43.18
Round  66, Train loss: 1.183, Test loss: 2.116, Test accuracy: 33.83
Round  66: Global train loss: 1.183, Global test loss: 2.274, Global test accuracy: 42.53
Round  67, Train loss: 0.388, Test loss: 2.107, Test accuracy: 34.77
Round  67: Global train loss: 0.388, Global test loss: 2.277, Global test accuracy: 43.03
Round  68, Train loss: -0.299, Test loss: 2.096, Test accuracy: 36.08
Round  68: Global train loss: -0.299, Global test loss: 2.275, Global test accuracy: 43.05
Round  69, Train loss: 1.007, Test loss: 2.115, Test accuracy: 33.60
Round  69: Global train loss: 1.007, Global test loss: 2.279, Global test accuracy: 34.70
Round  70, Train loss: -0.424, Test loss: 2.031, Test accuracy: 43.53
Round  70: Global train loss: -0.424, Global test loss: 2.267, Global test accuracy: 47.20
Round  71, Train loss: -0.375, Test loss: 2.061, Test accuracy: 39.12
Round  71: Global train loss: -0.375, Global test loss: 2.267, Global test accuracy: 49.30
Round  72, Train loss: -1.189, Test loss: 1.971, Test accuracy: 48.25
Round  72: Global train loss: -1.189, Global test loss: 2.244, Global test accuracy: 54.90
Round  73, Train loss: 0.141, Test loss: 2.009, Test accuracy: 44.20
Round  73: Global train loss: 0.141, Global test loss: 2.237, Global test accuracy: 53.78
Round  74, Train loss: 0.766, Test loss: 2.079, Test accuracy: 38.03
Round  74: Global train loss: 0.766, Global test loss: 2.243, Global test accuracy: 51.00
Round  75, Train loss: -0.113, Test loss: 2.028, Test accuracy: 44.40
Round  75: Global train loss: -0.113, Global test loss: 2.230, Global test accuracy: 53.18
Round  76, Train loss: -0.546, Test loss: 1.989, Test accuracy: 49.17
Round  76: Global train loss: -0.546, Global test loss: 2.213, Global test accuracy: 54.42
Round  77, Train loss: -0.725, Test loss: 1.989, Test accuracy: 47.80
Round  77: Global train loss: -0.725, Global test loss: 2.204, Global test accuracy: 54.13
Round  78, Train loss: 0.760, Test loss: 2.021, Test accuracy: 44.73
Round  78: Global train loss: 0.760, Global test loss: 2.205, Global test accuracy: 52.20
Round  79, Train loss: -2.178, Test loss: 1.936, Test accuracy: 54.07
Round  79: Global train loss: -2.178, Global test loss: 2.154, Global test accuracy: 52.53
Round  80, Train loss: -1.358, Test loss: 1.950, Test accuracy: 52.70
Round  80: Global train loss: -1.358, Global test loss: 2.130, Global test accuracy: 50.02
Round  81, Train loss: 0.832, Test loss: 2.004, Test accuracy: 49.42
Round  81: Global train loss: 0.832, Global test loss: 2.144, Global test accuracy: 49.93
Round  82, Train loss: -2.141, Test loss: 1.936, Test accuracy: 55.03
Round  82: Global train loss: -2.141, Global test loss: 2.096, Global test accuracy: 51.98
Round  83, Train loss: 0.631, Test loss: 1.951, Test accuracy: 54.60
Round  83: Global train loss: 0.631, Global test loss: 2.087, Global test accuracy: 51.32
Round  84, Train loss: 0.970, Test loss: 1.985, Test accuracy: 51.05
Round  84: Global train loss: 0.970, Global test loss: 2.091, Global test accuracy: 50.07
Round  85, Train loss: -0.735, Test loss: 1.933, Test accuracy: 54.85
Round  85: Global train loss: -0.735, Global test loss: 2.055, Global test accuracy: 51.03
Round  86, Train loss: 1.715, Test loss: 1.988, Test accuracy: 50.65
Round  86: Global train loss: 1.715, Global test loss: 2.063, Global test accuracy: 50.15
Round  87, Train loss: -0.533, Test loss: 1.952, Test accuracy: 53.63
Round  87: Global train loss: -0.533, Global test loss: 2.053, Global test accuracy: 52.63
Round  88, Train loss: -0.251, Test loss: 1.949, Test accuracy: 54.93
Round  88: Global train loss: -0.251, Global test loss: 2.035, Global test accuracy: 52.17
Round  89, Train loss: -0.826, Test loss: 1.881, Test accuracy: 59.30
Round  89: Global train loss: -0.826, Global test loss: 2.004, Global test accuracy: 53.20
Round  90, Train loss: 1.367, Test loss: 1.925, Test accuracy: 55.83
Round  90: Global train loss: 1.367, Global test loss: 2.010, Global test accuracy: 52.48
Round  91, Train loss: 0.078, Test loss: 1.911, Test accuracy: 56.98
Round  91: Global train loss: 0.078, Global test loss: 2.000, Global test accuracy: 52.87
Round  92, Train loss: 0.576, Test loss: 1.909, Test accuracy: 57.85
Round  92: Global train loss: 0.576, Global test loss: 1.995, Global test accuracy: 53.02
Round  93, Train loss: 1.310, Test loss: 1.944, Test accuracy: 55.03
Round  93: Global train loss: 1.310, Global test loss: 2.003, Global test accuracy: 52.13
Round  94, Train loss: 0.790, Test loss: 1.933, Test accuracy: 56.52
Round  94: Global train loss: 0.790, Global test loss: 1.999, Global test accuracy: 51.73
Round  95, Train loss: 0.099, Test loss: 1.890, Test accuracy: 59.60
Round  95: Global train loss: 0.099, Global test loss: 1.986, Global test accuracy: 52.43
Round  96, Train loss: 0.171, Test loss: 1.874, Test accuracy: 61.13
Round  96: Global train loss: 0.171, Global test loss: 1.979, Global test accuracy: 52.83
Round  97, Train loss: -0.726, Test loss: 1.816, Test accuracy: 66.45
Round  97: Global train loss: -0.726, Global test loss: 1.956, Global test accuracy: 54.10
Round  98, Train loss: -0.309, Test loss: 1.813, Test accuracy: 66.63
Round  98: Global train loss: -0.309, Global test loss: 1.942, Global test accuracy: 55.72
Round  99, Train loss: -0.643, Test loss: 1.776, Test accuracy: 69.77
Round  99: Global train loss: -0.643, Global test loss: 1.925, Global test accuracy: 57.03/home/ChenSM/code/FL_HLS/utils/sampling.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Final Round: Train loss: 1.783, Test loss: 1.731, Test accuracy: 79.15
Final Round: Global train loss: 1.783, Global test loss: 1.907, Global test accuracy: 58.57
Average accuracy final 10 rounds: 60.580000000000005
Average global accuracy final 10 rounds: 53.434999999999995
631.5837082862854
[]
[8.816666666666666, 9.7, 11.183333333333334, 12.333333333333334, 11.6, 11.85, 12.683333333333334, 15.383333333333333, 15.016666666666667, 14.516666666666667, 13.233333333333333, 15.383333333333333, 17.433333333333334, 18.483333333333334, 19.016666666666666, 18.016666666666666, 17.55, 19.566666666666666, 18.116666666666667, 19.016666666666666, 20.916666666666668, 20.133333333333333, 24.65, 22.516666666666666, 21.2, 22.75, 21.833333333333332, 21.0, 19.95, 21.266666666666666, 23.316666666666666, 21.366666666666667, 23.183333333333334, 24.316666666666666, 26.116666666666667, 24.85, 28.716666666666665, 25.766666666666666, 26.95, 29.666666666666668, 27.116666666666667, 23.066666666666666, 23.5, 30.5, 25.733333333333334, 26.633333333333333, 25.7, 30.216666666666665, 27.316666666666666, 28.333333333333332, 27.933333333333334, 33.53333333333333, 35.75, 38.88333333333333, 36.96666666666667, 37.733333333333334, 34.416666666666664, 26.4, 26.45, 27.7, 34.766666666666666, 34.96666666666667, 30.616666666666667, 34.583333333333336, 40.2, 39.56666666666667, 33.833333333333336, 34.766666666666666, 36.083333333333336, 33.6, 43.53333333333333, 39.11666666666667, 48.25, 44.2, 38.03333333333333, 44.4, 49.166666666666664, 47.8, 44.733333333333334, 54.06666666666667, 52.7, 49.416666666666664, 55.03333333333333, 54.6, 51.05, 54.85, 50.65, 53.63333333333333, 54.93333333333333, 59.3, 55.833333333333336, 56.983333333333334, 57.85, 55.03333333333333, 56.516666666666666, 59.6, 61.13333333333333, 66.45, 66.63333333333334, 69.76666666666667, 79.15]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.302, Test loss: 2.303, Test accuracy: 13.67 

Round   0, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 13.70 

Round   1, Train loss: 2.302, Test loss: 2.303, Test accuracy: 13.90 

Round   1, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 13.93 

Round   2, Train loss: 2.302, Test loss: 2.303, Test accuracy: 13.92 

Round   2, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 14.02 

Round   3, Train loss: 2.302, Test loss: 2.303, Test accuracy: 14.00 

Round   3, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 14.10 

Round   4, Train loss: 2.302, Test loss: 2.303, Test accuracy: 14.05 

Round   4, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 14.22 

Round   5, Train loss: 2.302, Test loss: 2.303, Test accuracy: 14.17 

Round   5, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 14.45 

Round   6, Train loss: 2.302, Test loss: 2.303, Test accuracy: 14.35 

Round   6, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 14.62 

Round   7, Train loss: 2.302, Test loss: 2.303, Test accuracy: 14.48 

Round   7, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 14.87 

Round   8, Train loss: 2.302, Test loss: 2.303, Test accuracy: 14.60 

Round   8, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 15.03 

Round   9, Train loss: 2.302, Test loss: 2.303, Test accuracy: 14.87 

Round   9, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.25 

Round  10, Train loss: 2.302, Test loss: 2.303, Test accuracy: 14.95 

Round  10, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.35 

Round  11, Train loss: 2.302, Test loss: 2.302, Test accuracy: 15.20 

Round  11, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.53 

Round  12, Train loss: 2.302, Test loss: 2.302, Test accuracy: 15.22 

Round  12, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.43 

Round  13, Train loss: 2.302, Test loss: 2.302, Test accuracy: 15.33 

Round  13, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.67 

Round  14, Train loss: 2.302, Test loss: 2.302, Test accuracy: 15.57 

Round  14, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.73 

Round  15, Train loss: 2.302, Test loss: 2.302, Test accuracy: 15.57 

Round  15, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.82 

Round  16, Train loss: 2.302, Test loss: 2.302, Test accuracy: 15.72 

Round  16, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.92 

Round  17, Train loss: 2.302, Test loss: 2.302, Test accuracy: 15.83 

Round  17, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.97 

Round  18, Train loss: 2.302, Test loss: 2.302, Test accuracy: 15.90 

Round  18, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 16.13 

Round  19, Train loss: 2.302, Test loss: 2.302, Test accuracy: 16.03 

Round  19, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 16.27 

Round  20, Train loss: 2.302, Test loss: 2.302, Test accuracy: 16.12 

Round  20, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 16.32 

Round  21, Train loss: 2.302, Test loss: 2.302, Test accuracy: 16.38 

Round  21, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 16.60 

Round  22, Train loss: 2.302, Test loss: 2.302, Test accuracy: 16.43 

Round  22, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 16.67 

Round  23, Train loss: 2.302, Test loss: 2.302, Test accuracy: 16.43 

Round  23, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 16.72 

Round  24, Train loss: 2.302, Test loss: 2.302, Test accuracy: 16.58 

Round  24, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 16.75 

Round  25, Train loss: 2.302, Test loss: 2.302, Test accuracy: 16.67 

Round  25, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 16.90 

Round  26, Train loss: 2.302, Test loss: 2.302, Test accuracy: 16.88 

Round  26, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 16.93 

Round  27, Train loss: 2.302, Test loss: 2.302, Test accuracy: 16.93 

Round  27, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 16.92 

Round  28, Train loss: 2.302, Test loss: 2.302, Test accuracy: 16.98 

Round  28, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 16.95 

Round  29, Train loss: 2.302, Test loss: 2.302, Test accuracy: 16.98 

Round  29, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 17.02 

Round  30, Train loss: 2.302, Test loss: 2.302, Test accuracy: 17.03 

Round  30, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 17.42 

Round  31, Train loss: 2.302, Test loss: 2.302, Test accuracy: 17.17 

Round  31, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 17.38 

Round  32, Train loss: 2.302, Test loss: 2.302, Test accuracy: 17.33 

Round  32, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 17.52 

Round  33, Train loss: 2.302, Test loss: 2.302, Test accuracy: 17.47 

Round  33, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 17.58 

Round  34, Train loss: 2.302, Test loss: 2.302, Test accuracy: 17.45 

Round  34, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 17.63 

Round  35, Train loss: 2.302, Test loss: 2.302, Test accuracy: 17.55 

Round  35, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 17.88 

Round  36, Train loss: 2.302, Test loss: 2.302, Test accuracy: 17.65 

Round  36, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 17.98 

Round  37, Train loss: 2.302, Test loss: 2.302, Test accuracy: 17.78 

Round  37, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 18.03 

Round  38, Train loss: 2.302, Test loss: 2.302, Test accuracy: 17.92 

Round  38, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 18.17 

Round  39, Train loss: 2.302, Test loss: 2.302, Test accuracy: 18.07 

Round  39, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 18.25 

Round  40, Train loss: 2.302, Test loss: 2.302, Test accuracy: 18.10 

Round  40, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 18.30 

Round  41, Train loss: 2.302, Test loss: 2.302, Test accuracy: 18.40 

Round  41, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 18.32 

Round  42, Train loss: 2.301, Test loss: 2.302, Test accuracy: 18.37 

Round  42, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 18.47 

Round  43, Train loss: 2.301, Test loss: 2.302, Test accuracy: 18.38 

Round  43, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 18.57 

Round  44, Train loss: 2.302, Test loss: 2.302, Test accuracy: 18.45 

Round  44, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 18.60 

Round  45, Train loss: 2.302, Test loss: 2.302, Test accuracy: 18.57 

Round  45, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 18.63 

Round  46, Train loss: 2.302, Test loss: 2.302, Test accuracy: 18.63 

Round  46, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 18.70 

Round  47, Train loss: 2.301, Test loss: 2.302, Test accuracy: 18.68 

Round  47, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 18.88 

Round  48, Train loss: 2.302, Test loss: 2.302, Test accuracy: 18.77 

Round  48, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 19.00 

Round  49, Train loss: 2.301, Test loss: 2.302, Test accuracy: 18.88 

Round  49, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 19.15 

Round  50, Train loss: 2.301, Test loss: 2.302, Test accuracy: 19.02 

Round  50, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 19.33 

Round  51, Train loss: 2.301, Test loss: 2.302, Test accuracy: 19.13 

Round  51, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 19.35 

Round  52, Train loss: 2.302, Test loss: 2.302, Test accuracy: 19.18 

Round  52, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 19.52 

Round  53, Train loss: 2.301, Test loss: 2.302, Test accuracy: 19.17 

Round  53, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 19.55 

Round  54, Train loss: 2.302, Test loss: 2.302, Test accuracy: 19.32 

Round  54, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 19.62 

Round  55, Train loss: 2.302, Test loss: 2.302, Test accuracy: 19.38 

Round  55, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 19.67 

Round  56, Train loss: 2.301, Test loss: 2.302, Test accuracy: 19.55 

Round  56, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 19.72 

Round  57, Train loss: 2.302, Test loss: 2.302, Test accuracy: 19.63 

Round  57, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 19.78 

Round  58, Train loss: 2.301, Test loss: 2.302, Test accuracy: 19.65 

Round  58, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 19.83 

Round  59, Train loss: 2.301, Test loss: 2.302, Test accuracy: 19.72 

Round  59, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 19.90 

Round  60, Train loss: 2.302, Test loss: 2.302, Test accuracy: 19.78 

Round  60, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 19.97 

Round  61, Train loss: 2.301, Test loss: 2.302, Test accuracy: 19.93 

Round  61, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 20.03 

Round  62, Train loss: 2.301, Test loss: 2.302, Test accuracy: 19.92 

Round  62, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 20.03 

Round  63, Train loss: 2.301, Test loss: 2.302, Test accuracy: 19.93 

Round  63, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 20.03 

Round  64, Train loss: 2.301, Test loss: 2.302, Test accuracy: 20.05 

Round  64, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 20.07 

Round  65, Train loss: 2.301, Test loss: 2.302, Test accuracy: 20.12 

Round  65, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 20.18 

Round  66, Train loss: 2.301, Test loss: 2.302, Test accuracy: 20.12 

Round  66, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 20.25 

Round  67, Train loss: 2.301, Test loss: 2.302, Test accuracy: 20.15 

Round  67, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 20.27 

Round  68, Train loss: 2.301, Test loss: 2.302, Test accuracy: 20.22 

Round  68, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 20.35 

Round  69, Train loss: 2.301, Test loss: 2.302, Test accuracy: 20.22 

Round  69, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 20.38 

Round  70, Train loss: 2.301, Test loss: 2.302, Test accuracy: 20.27 

Round  70, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 20.37 

Round  71, Train loss: 2.301, Test loss: 2.302, Test accuracy: 20.28 

Round  71, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 20.38 

Round  72, Train loss: 2.301, Test loss: 2.302, Test accuracy: 20.32 

Round  72, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 20.53 

Round  73, Train loss: 2.301, Test loss: 2.301, Test accuracy: 20.37 

Round  73, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 20.55 

Round  74, Train loss: 2.301, Test loss: 2.301, Test accuracy: 20.47 

Round  74, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 20.58 

Round  75, Train loss: 2.301, Test loss: 2.301, Test accuracy: 20.53 

Round  75, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 20.60 

Round  76, Train loss: 2.301, Test loss: 2.301, Test accuracy: 20.62 

Round  76, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 20.70 

Round  77, Train loss: 2.301, Test loss: 2.301, Test accuracy: 20.63 

Round  77, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 20.70 

Round  78, Train loss: 2.301, Test loss: 2.301, Test accuracy: 20.75 

Round  78, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 20.82 

Round  79, Train loss: 2.301, Test loss: 2.301, Test accuracy: 20.75 

Round  79, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 20.90 

Round  80, Train loss: 2.301, Test loss: 2.301, Test accuracy: 20.83 

Round  80, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 20.95 

Round  81, Train loss: 2.301, Test loss: 2.301, Test accuracy: 20.88 

Round  81, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 20.97 

Round  82, Train loss: 2.301, Test loss: 2.301, Test accuracy: 20.93 

Round  82, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.07 

Round  83, Train loss: 2.301, Test loss: 2.301, Test accuracy: 20.95 

Round  83, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.05 

Round  84, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.03 

Round  84, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.20 

Round  85, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.12 

Round  85, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.23 

Round  86, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.20 

Round  86, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.28 

Round  87, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.23 

Round  87, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.27 

Round  88, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.23 

Round  88, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.25 

Round  89, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.23 

Round  89, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.35 

Round  90, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.25 

Round  90, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.28 

Round  91, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.30 

Round  91, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.35 

Round  92, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.28 

Round  92, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.40 

Round  93, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.45 

Round  93, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.40 

Round  94, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.45 
/home/ChenSM/code/FL_HLS/utils/sampling.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.48 

Round  95, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.47 

Round  95, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.50 

Round  96, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.50 

Round  96, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.50 

Round  97, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.45 

Round  97, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.48 

Round  98, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.50 

Round  98, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.58 

Round  99, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.48 

Round  99, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.57 

Final Round, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.58 

Final Round, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.57 

Average accuracy final 10 rounds: 21.41333333333333 

Average global accuracy final 10 rounds: 21.455 

528.0413286685944
[0.5943806171417236, 1.0897603034973145, 1.5893924236297607, 2.0896108150482178, 2.5932514667510986, 3.097294807434082, 3.598078489303589, 4.0991740226745605, 4.604261636734009, 5.110774278640747, 5.618943691253662, 6.121859312057495, 6.626470327377319, 7.1284263134002686, 7.635884046554565, 8.124279499053955, 8.557582378387451, 8.989379167556763, 9.421461582183838, 9.85852861404419, 10.29589319229126, 10.729526281356812, 11.163991451263428, 11.59464979171753, 12.030524492263794, 12.473021268844604, 12.903381824493408, 13.33982253074646, 13.773521661758423, 14.204024076461792, 14.644250392913818, 15.082537651062012, 15.513116836547852, 15.947884798049927, 16.380833625793457, 16.81848430633545, 17.25814461708069, 17.691359758377075, 18.121618032455444, 18.555020809173584, 18.991342306137085, 19.427594661712646, 19.85945415496826, 20.292837858200073, 20.722110986709595, 21.1558735370636, 21.59581208229065, 22.02640962600708, 22.458704948425293, 22.89294695854187, 23.323036670684814, 23.762162923812866, 24.202548503875732, 24.633850812911987, 25.067757606506348, 25.50174379348755, 25.93862509727478, 26.378540515899658, 26.813234090805054, 27.244619131088257, 27.676883459091187, 28.11208963394165, 28.548036336898804, 28.976233959197998, 29.40804171562195, 29.838714122772217, 30.26572871208191, 30.70605182647705, 31.13690733909607, 31.563472270965576, 31.997053861618042, 32.42821216583252, 32.86057424545288, 33.29964876174927, 33.730785608291626, 34.15605401992798, 34.590505599975586, 35.02643322944641, 35.458688735961914, 35.89207673072815, 36.323726415634155, 36.74872064590454, 37.18273878097534, 37.61933994293213, 38.046550273895264, 38.48129725456238, 38.91575026512146, 39.34010195732117, 39.78080344200134, 40.21946430206299, 40.64443397521973, 41.079018354415894, 41.51331067085266, 41.9419424533844, 42.38102412223816, 42.81586027145386, 43.23918890953064, 43.67309069633484, 44.10743975639343, 44.54224252700806, 45.406097412109375]
[13.666666666666666, 13.9, 13.916666666666666, 14.0, 14.05, 14.166666666666666, 14.35, 14.483333333333333, 14.6, 14.866666666666667, 14.95, 15.2, 15.216666666666667, 15.333333333333334, 15.566666666666666, 15.566666666666666, 15.716666666666667, 15.833333333333334, 15.9, 16.033333333333335, 16.116666666666667, 16.383333333333333, 16.433333333333334, 16.433333333333334, 16.583333333333332, 16.666666666666668, 16.883333333333333, 16.933333333333334, 16.983333333333334, 16.983333333333334, 17.033333333333335, 17.166666666666668, 17.333333333333332, 17.466666666666665, 17.45, 17.55, 17.65, 17.783333333333335, 17.916666666666668, 18.066666666666666, 18.1, 18.4, 18.366666666666667, 18.383333333333333, 18.45, 18.566666666666666, 18.633333333333333, 18.683333333333334, 18.766666666666666, 18.883333333333333, 19.016666666666666, 19.133333333333333, 19.183333333333334, 19.166666666666668, 19.316666666666666, 19.383333333333333, 19.55, 19.633333333333333, 19.65, 19.716666666666665, 19.783333333333335, 19.933333333333334, 19.916666666666668, 19.933333333333334, 20.05, 20.116666666666667, 20.116666666666667, 20.15, 20.216666666666665, 20.216666666666665, 20.266666666666666, 20.283333333333335, 20.316666666666666, 20.366666666666667, 20.466666666666665, 20.533333333333335, 20.616666666666667, 20.633333333333333, 20.75, 20.75, 20.833333333333332, 20.883333333333333, 20.933333333333334, 20.95, 21.033333333333335, 21.116666666666667, 21.2, 21.233333333333334, 21.233333333333334, 21.233333333333334, 21.25, 21.3, 21.283333333333335, 21.45, 21.45, 21.466666666666665, 21.5, 21.45, 21.5, 21.483333333333334, 21.583333333333332]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
Round   0, Train loss: 2.302, Test loss: 2.301, Test accuracy: 16.95
Round   1, Train loss: 2.300, Test loss: 2.299, Test accuracy: 17.83
Round   2, Train loss: 2.298, Test loss: 2.296, Test accuracy: 22.08
Round   3, Train loss: 2.295, Test loss: 2.291, Test accuracy: 29.95
Round   4, Train loss: 2.293, Test loss: 2.281, Test accuracy: 37.17
Round   5, Train loss: 2.283, Test loss: 2.243, Test accuracy: 29.83
Round   6, Train loss: 2.237, Test loss: 2.170, Test accuracy: 30.33
Round   7, Train loss: 2.196, Test loss: 2.064, Test accuracy: 46.43
Round   8, Train loss: 2.105, Test loss: 1.976, Test accuracy: 49.78
Round   9, Train loss: 2.021, Test loss: 1.915, Test accuracy: 57.78
Round  10, Train loss: 2.005, Test loss: 1.870, Test accuracy: 60.60
Round  11, Train loss: 1.926, Test loss: 1.811, Test accuracy: 68.65
Round  12, Train loss: 1.894, Test loss: 1.744, Test accuracy: 77.53
Round  13, Train loss: 1.780, Test loss: 1.702, Test accuracy: 79.93
Round  14, Train loss: 1.710, Test loss: 1.680, Test accuracy: 80.90
Round  15, Train loss: 1.740, Test loss: 1.669, Test accuracy: 81.23
Round  16, Train loss: 1.698, Test loss: 1.656, Test accuracy: 82.25
Round  17, Train loss: 1.686, Test loss: 1.650, Test accuracy: 82.52
Round  18, Train loss: 1.680, Test loss: 1.645, Test accuracy: 82.78
Round  19, Train loss: 1.687, Test loss: 1.644, Test accuracy: 82.80
Round  20, Train loss: 1.661, Test loss: 1.638, Test accuracy: 83.25
Round  21, Train loss: 1.619, Test loss: 1.637, Test accuracy: 83.43
Round  22, Train loss: 1.635, Test loss: 1.634, Test accuracy: 83.67
Round  23, Train loss: 1.604, Test loss: 1.634, Test accuracy: 83.47
Round  24, Train loss: 1.620, Test loss: 1.630, Test accuracy: 83.78
Round  25, Train loss: 1.612, Test loss: 1.629, Test accuracy: 84.02
Round  26, Train loss: 1.593, Test loss: 1.628, Test accuracy: 83.67
Round  27, Train loss: 1.612, Test loss: 1.626, Test accuracy: 83.97
Round  28, Train loss: 1.594, Test loss: 1.625, Test accuracy: 83.95
Round  29, Train loss: 1.603, Test loss: 1.624, Test accuracy: 84.13
Round  30, Train loss: 1.604, Test loss: 1.624, Test accuracy: 84.23
Round  31, Train loss: 1.594, Test loss: 1.624, Test accuracy: 84.17
Round  32, Train loss: 1.590, Test loss: 1.623, Test accuracy: 84.32
Round  33, Train loss: 1.610, Test loss: 1.622, Test accuracy: 84.33
Round  34, Train loss: 1.596, Test loss: 1.621, Test accuracy: 84.38
Round  35, Train loss: 1.601, Test loss: 1.621, Test accuracy: 84.42
Round  36, Train loss: 1.604, Test loss: 1.620, Test accuracy: 84.52
Round  37, Train loss: 1.585, Test loss: 1.621, Test accuracy: 84.37
Round  38, Train loss: 1.589, Test loss: 1.621, Test accuracy: 84.12
Round  39, Train loss: 1.596, Test loss: 1.620, Test accuracy: 84.40
Round  40, Train loss: 1.594, Test loss: 1.618, Test accuracy: 84.50
Round  41, Train loss: 1.590, Test loss: 1.618, Test accuracy: 84.55
Round  42, Train loss: 1.592, Test loss: 1.619, Test accuracy: 84.67
Round  43, Train loss: 1.589, Test loss: 1.617, Test accuracy: 84.72
Round  44, Train loss: 1.599, Test loss: 1.616, Test accuracy: 84.73
Round  45, Train loss: 1.587, Test loss: 1.615, Test accuracy: 84.80
Round  46, Train loss: 1.587, Test loss: 1.615, Test accuracy: 84.95
Round  47, Train loss: 1.596, Test loss: 1.616, Test accuracy: 84.95
Round  48, Train loss: 1.585, Test loss: 1.616, Test accuracy: 84.83
Round  49, Train loss: 1.580, Test loss: 1.615, Test accuracy: 84.83
Round  50, Train loss: 1.593, Test loss: 1.615, Test accuracy: 85.05
Round  51, Train loss: 1.584, Test loss: 1.615, Test accuracy: 84.92
Round  52, Train loss: 1.582, Test loss: 1.614, Test accuracy: 85.00
Round  53, Train loss: 1.590, Test loss: 1.613, Test accuracy: 84.97
Round  54, Train loss: 1.587, Test loss: 1.613, Test accuracy: 85.05
Round  55, Train loss: 1.582, Test loss: 1.613, Test accuracy: 85.17
Round  56, Train loss: 1.584, Test loss: 1.614, Test accuracy: 84.92
Round  57, Train loss: 1.588, Test loss: 1.613, Test accuracy: 85.13
Round  58, Train loss: 1.585, Test loss: 1.613, Test accuracy: 85.20
Round  59, Train loss: 1.585, Test loss: 1.613, Test accuracy: 85.28
Round  60, Train loss: 1.580, Test loss: 1.612, Test accuracy: 85.23
Round  61, Train loss: 1.588, Test loss: 1.612, Test accuracy: 85.25
Round  62, Train loss: 1.580, Test loss: 1.612, Test accuracy: 85.22
Round  63, Train loss: 1.587, Test loss: 1.613, Test accuracy: 85.15
Round  64, Train loss: 1.578, Test loss: 1.612, Test accuracy: 85.17
Round  65, Train loss: 1.591, Test loss: 1.612, Test accuracy: 85.30
Round  66, Train loss: 1.584, Test loss: 1.612, Test accuracy: 85.28
Round  67, Train loss: 1.581, Test loss: 1.612, Test accuracy: 85.03
Round  68, Train loss: 1.582, Test loss: 1.612, Test accuracy: 84.97
Round  69, Train loss: 1.585, Test loss: 1.611, Test accuracy: 85.30
Round  70, Train loss: 1.584, Test loss: 1.612, Test accuracy: 85.08
Round  71, Train loss: 1.575, Test loss: 1.610, Test accuracy: 85.28
Round  72, Train loss: 1.577, Test loss: 1.611, Test accuracy: 85.18
Round  73, Train loss: 1.582, Test loss: 1.610, Test accuracy: 85.43
Round  74, Train loss: 1.576, Test loss: 1.611, Test accuracy: 85.38
Round  75, Train loss: 1.584, Test loss: 1.611, Test accuracy: 85.33
Round  76, Train loss: 1.579, Test loss: 1.610, Test accuracy: 85.32
Round  77, Train loss: 1.577, Test loss: 1.611, Test accuracy: 85.33
Round  78, Train loss: 1.575, Test loss: 1.610, Test accuracy: 85.33
Round  79, Train loss: 1.574, Test loss: 1.610, Test accuracy: 85.40
Round  80, Train loss: 1.583, Test loss: 1.609, Test accuracy: 85.40
Round  81, Train loss: 1.576, Test loss: 1.610, Test accuracy: 85.25
Round  82, Train loss: 1.571, Test loss: 1.609, Test accuracy: 85.30
Round  83, Train loss: 1.580, Test loss: 1.610, Test accuracy: 85.23
Round  84, Train loss: 1.573, Test loss: 1.610, Test accuracy: 85.42
Round  85, Train loss: 1.579, Test loss: 1.610, Test accuracy: 85.40
Round  86, Train loss: 1.572, Test loss: 1.609, Test accuracy: 85.40
Round  87, Train loss: 1.572, Test loss: 1.609, Test accuracy: 85.40
Round  88, Train loss: 1.574, Test loss: 1.609, Test accuracy: 85.27
Round  89, Train loss: 1.585, Test loss: 1.609, Test accuracy: 85.40
Round  90, Train loss: 1.573, Test loss: 1.609, Test accuracy: 85.40
Round  91, Train loss: 1.573, Test loss: 1.609, Test accuracy: 85.30
Round  92, Train loss: 1.575, Test loss: 1.609, Test accuracy: 85.42
Round  93, Train loss: 1.581, Test loss: 1.610, Test accuracy: 85.37
Round  94, Train loss: 1.574, Test loss: 1.609, Test accuracy: 85.30
Round  95, Train loss: 1.582, Test loss: 1.609, Test accuracy: 85.22
Round  96, Train loss: 1.577, Test loss: 1.608, Test accuracy: 85.55
Round  97, Train loss: 1.573, Test loss: 1.608, Test accuracy: 85.47
Round  98, Train loss: 1.572, Test loss: 1.608, Test accuracy: 85.38
Round  99, Train loss: 1.581, Test loss: 1.608, Test accuracy: 85.57
Final Round, Train loss: 1.576, Test loss: 1.608, Test accuracy: 85.55
Average accuracy final 10 rounds: 85.39666666666668
829.7833926677704
[1.3175828456878662, 2.5213565826416016, 3.7290055751800537, 4.935198783874512, 6.142941236495972, 7.352817535400391, 8.559576988220215, 9.766870021820068, 10.970908641815186, 12.18018364906311, 13.386073112487793, 14.596026420593262, 15.8047776222229, 17.019051551818848, 18.238057136535645, 19.45146155357361, 20.66543459892273, 21.881502866744995, 23.101394653320312, 24.30892038345337, 25.519550323486328, 26.732839584350586, 27.94517707824707, 29.16144871711731, 30.37321400642395, 31.587527990341187, 32.79794645309448, 33.99982285499573, 35.203943729400635, 36.401506185531616, 37.60238528251648, 38.808349609375, 40.00529956817627, 41.20328903198242, 42.414450883865356, 43.60931372642517, 44.80514478683472, 46.01205134391785, 47.21974182128906, 48.42436385154724, 49.62986421585083, 50.83704686164856, 52.03833484649658, 53.2457640171051, 54.462522745132446, 55.693543910980225, 56.78769540786743, 57.89002513885498, 58.98585796356201, 60.08248043060303, 61.18365693092346, 62.27333331108093, 63.369062185287476, 64.46041941642761, 65.5516185760498, 66.64344835281372, 67.73383951187134, 68.82485842704773, 69.91894721984863, 71.0078992843628, 72.10449171066284, 73.19590878486633, 74.29359483718872, 75.38107943534851, 76.47196769714355, 77.56156086921692, 78.65332508087158, 79.74778842926025, 80.84054207801819, 81.932373046875, 83.02109742164612, 84.11371088027954, 85.20077300071716, 86.28850412368774, 87.37902402877808, 88.47108674049377, 89.56728315353394, 90.66284847259521, 91.75548195838928, 92.8502471446991, 93.94390630722046, 95.03262257575989, 96.1230206489563, 97.21535181999207, 98.3050045967102, 99.39742636680603, 100.49477005004883, 101.58608675003052, 102.67570781707764, 103.76417469978333, 104.85070943832397, 105.93842220306396, 107.02647089958191, 108.11950922012329, 109.21083617210388, 110.30034923553467, 111.39379453659058, 112.4861650466919, 113.57774186134338, 114.66959691047668, 115.7630786895752]/home/ChenSM/code/FL_HLS/utils/sampling.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[16.95, 17.833333333333332, 22.083333333333332, 29.95, 37.166666666666664, 29.833333333333332, 30.333333333333332, 46.43333333333333, 49.78333333333333, 57.78333333333333, 60.6, 68.65, 77.53333333333333, 79.93333333333334, 80.9, 81.23333333333333, 82.25, 82.51666666666667, 82.78333333333333, 82.8, 83.25, 83.43333333333334, 83.66666666666667, 83.46666666666667, 83.78333333333333, 84.01666666666667, 83.66666666666667, 83.96666666666667, 83.95, 84.13333333333334, 84.23333333333333, 84.16666666666667, 84.31666666666666, 84.33333333333333, 84.38333333333334, 84.41666666666667, 84.51666666666667, 84.36666666666666, 84.11666666666666, 84.4, 84.5, 84.55, 84.66666666666667, 84.71666666666667, 84.73333333333333, 84.8, 84.95, 84.95, 84.83333333333333, 84.83333333333333, 85.05, 84.91666666666667, 85.0, 84.96666666666667, 85.05, 85.16666666666667, 84.91666666666667, 85.13333333333334, 85.2, 85.28333333333333, 85.23333333333333, 85.25, 85.21666666666667, 85.15, 85.16666666666667, 85.3, 85.28333333333333, 85.03333333333333, 84.96666666666667, 85.3, 85.08333333333333, 85.28333333333333, 85.18333333333334, 85.43333333333334, 85.38333333333334, 85.33333333333333, 85.31666666666666, 85.33333333333333, 85.33333333333333, 85.4, 85.4, 85.25, 85.3, 85.23333333333333, 85.41666666666667, 85.4, 85.4, 85.4, 85.26666666666667, 85.4, 85.4, 85.3, 85.41666666666667, 85.36666666666666, 85.3, 85.21666666666667, 85.55, 85.46666666666667, 85.38333333333334, 85.56666666666666, 85.55]
