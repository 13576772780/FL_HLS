nohup: ignoring input
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.298, Test loss: 2.293, Test accuracy: 40.88
Round   0, Global train loss: 2.298, Global test loss: 2.293, Global test accuracy: 40.98
Round   1, Train loss: 2.265, Test loss: 2.220, Test accuracy: 36.46
Round   1, Global train loss: 2.265, Global test loss: 2.196, Global test accuracy: 34.34
Round   2, Train loss: 2.016, Test loss: 2.045, Test accuracy: 53.44
Round   2, Global train loss: 2.016, Global test loss: 1.844, Global test accuracy: 68.83
Round   3, Train loss: 1.832, Test loss: 1.969, Test accuracy: 59.28
Round   3, Global train loss: 1.832, Global test loss: 1.748, Global test accuracy: 74.31
Round   4, Train loss: 1.837, Test loss: 1.923, Test accuracy: 62.69
Round   4, Global train loss: 1.837, Global test loss: 1.751, Global test accuracy: 76.00
Round   5, Train loss: 1.733, Test loss: 1.877, Test accuracy: 66.95
Round   5, Global train loss: 1.733, Global test loss: 1.691, Global test accuracy: 79.53
Round   6, Train loss: 1.711, Test loss: 1.857, Test accuracy: 67.86
Round   6, Global train loss: 1.711, Global test loss: 1.644, Global test accuracy: 87.03
Round   7, Train loss: 1.846, Test loss: 1.812, Test accuracy: 70.52
Round   7, Global train loss: 1.846, Global test loss: 1.784, Global test accuracy: 73.12
Round   8, Train loss: 1.813, Test loss: 1.768, Test accuracy: 73.94
Round   8, Global train loss: 1.813, Global test loss: 1.734, Global test accuracy: 78.59
Round   9, Train loss: 1.681, Test loss: 1.740, Test accuracy: 76.35
Round   9, Global train loss: 1.681, Global test loss: 1.671, Global test accuracy: 80.56
Round  10, Train loss: 1.602, Test loss: 1.722, Test accuracy: 77.96
Round  10, Global train loss: 1.602, Global test loss: 1.615, Global test accuracy: 86.97
Round  11, Train loss: 1.547, Test loss: 1.716, Test accuracy: 78.30
Round  11, Global train loss: 1.547, Global test loss: 1.612, Global test accuracy: 86.30
Round  12, Train loss: 1.512, Test loss: 1.714, Test accuracy: 78.28
Round  12, Global train loss: 1.512, Global test loss: 1.580, Global test accuracy: 89.21
Round  13, Train loss: 1.531, Test loss: 1.706, Test accuracy: 79.03
Round  13, Global train loss: 1.531, Global test loss: 1.587, Global test accuracy: 88.94
Round  14, Train loss: 1.702, Test loss: 1.688, Test accuracy: 79.94
Round  14, Global train loss: 1.702, Global test loss: 1.659, Global test accuracy: 83.59
Round  15, Train loss: 1.571, Test loss: 1.678, Test accuracy: 80.69
Round  15, Global train loss: 1.571, Global test loss: 1.623, Global test accuracy: 85.47
Round  16, Train loss: 1.503, Test loss: 1.676, Test accuracy: 80.84
Round  16, Global train loss: 1.503, Global test loss: 1.576, Global test accuracy: 89.48
Round  17, Train loss: 1.601, Test loss: 1.656, Test accuracy: 82.38
Round  17, Global train loss: 1.601, Global test loss: 1.624, Global test accuracy: 85.45
Round  18, Train loss: 1.525, Test loss: 1.652, Test accuracy: 82.63
Round  18, Global train loss: 1.525, Global test loss: 1.587, Global test accuracy: 88.64
Round  19, Train loss: 1.561, Test loss: 1.641, Test accuracy: 83.47
Round  19, Global train loss: 1.561, Global test loss: 1.591, Global test accuracy: 88.56
Round  20, Train loss: 1.558, Test loss: 1.634, Test accuracy: 83.80
Round  20, Global train loss: 1.558, Global test loss: 1.595, Global test accuracy: 88.44
Round  21, Train loss: 1.491, Test loss: 1.634, Test accuracy: 83.83
Round  21, Global train loss: 1.491, Global test loss: 1.571, Global test accuracy: 89.83
Round  22, Train loss: 1.532, Test loss: 1.631, Test accuracy: 83.97
Round  22, Global train loss: 1.532, Global test loss: 1.598, Global test accuracy: 87.51
Round  23, Train loss: 1.521, Test loss: 1.627, Test accuracy: 84.53
Round  23, Global train loss: 1.521, Global test loss: 1.583, Global test accuracy: 89.06
Round  24, Train loss: 1.504, Test loss: 1.625, Test accuracy: 84.66
Round  24, Global train loss: 1.504, Global test loss: 1.580, Global test accuracy: 89.22
Round  25, Train loss: 1.545, Test loss: 1.617, Test accuracy: 85.23
Round  25, Global train loss: 1.545, Global test loss: 1.596, Global test accuracy: 87.91
Round  26, Train loss: 1.500, Test loss: 1.616, Test accuracy: 85.24
Round  26, Global train loss: 1.500, Global test loss: 1.574, Global test accuracy: 89.41
Round  27, Train loss: 1.513, Test loss: 1.609, Test accuracy: 85.92
Round  27, Global train loss: 1.513, Global test loss: 1.583, Global test accuracy: 88.94
Round  28, Train loss: 1.495, Test loss: 1.609, Test accuracy: 86.03
Round  28, Global train loss: 1.495, Global test loss: 1.574, Global test accuracy: 89.42
Round  29, Train loss: 1.495, Test loss: 1.608, Test accuracy: 86.19
Round  29, Global train loss: 1.495, Global test loss: 1.578, Global test accuracy: 89.22
Round  30, Train loss: 1.496, Test loss: 1.607, Test accuracy: 86.23
Round  30, Global train loss: 1.496, Global test loss: 1.570, Global test accuracy: 89.91
Round  31, Train loss: 1.501, Test loss: 1.605, Test accuracy: 86.28
Round  31, Global train loss: 1.501, Global test loss: 1.576, Global test accuracy: 89.42
Round  32, Train loss: 1.489, Test loss: 1.604, Test accuracy: 86.38
Round  32, Global train loss: 1.489, Global test loss: 1.576, Global test accuracy: 89.16
Round  33, Train loss: 1.491, Test loss: 1.604, Test accuracy: 86.39
Round  33, Global train loss: 1.491, Global test loss: 1.576, Global test accuracy: 89.57
Round  34, Train loss: 1.489, Test loss: 1.603, Test accuracy: 86.45
Round  34, Global train loss: 1.489, Global test loss: 1.572, Global test accuracy: 89.47
Round  35, Train loss: 1.487, Test loss: 1.602, Test accuracy: 86.50
Round  35, Global train loss: 1.487, Global test loss: 1.577, Global test accuracy: 88.92
Round  36, Train loss: 1.496, Test loss: 1.599, Test accuracy: 86.90
Round  36, Global train loss: 1.496, Global test loss: 1.576, Global test accuracy: 89.17
Round  37, Train loss: 1.485, Test loss: 1.599, Test accuracy: 86.90
Round  37, Global train loss: 1.485, Global test loss: 1.570, Global test accuracy: 89.72
Round  38, Train loss: 1.489, Test loss: 1.599, Test accuracy: 86.89
Round  38, Global train loss: 1.489, Global test loss: 1.569, Global test accuracy: 89.72
Round  39, Train loss: 1.489, Test loss: 1.598, Test accuracy: 86.95
Round  39, Global train loss: 1.489, Global test loss: 1.571, Global test accuracy: 89.68
Round  40, Train loss: 1.487, Test loss: 1.598, Test accuracy: 86.94
Round  40, Global train loss: 1.487, Global test loss: 1.572, Global test accuracy: 89.28
Round  41, Train loss: 1.488, Test loss: 1.598, Test accuracy: 86.92
Round  41, Global train loss: 1.488, Global test loss: 1.570, Global test accuracy: 89.59
Round  42, Train loss: 1.484, Test loss: 1.598, Test accuracy: 86.94
Round  42, Global train loss: 1.484, Global test loss: 1.569, Global test accuracy: 89.57
Round  43, Train loss: 1.487, Test loss: 1.597, Test accuracy: 86.94
Round  43, Global train loss: 1.487, Global test loss: 1.573, Global test accuracy: 89.61
Round  44, Train loss: 1.490, Test loss: 1.597, Test accuracy: 86.92
Round  44, Global train loss: 1.490, Global test loss: 1.574, Global test accuracy: 89.40
Round  45, Train loss: 1.487, Test loss: 1.597, Test accuracy: 86.97
Round  45, Global train loss: 1.487, Global test loss: 1.574, Global test accuracy: 89.34
Round  46, Train loss: 1.488, Test loss: 1.597, Test accuracy: 86.92
Round  46, Global train loss: 1.488, Global test loss: 1.574, Global test accuracy: 89.44
Round  47, Train loss: 1.487, Test loss: 1.597, Test accuracy: 86.95
Round  47, Global train loss: 1.487, Global test loss: 1.570, Global test accuracy: 89.54
Round  48, Train loss: 1.486, Test loss: 1.596, Test accuracy: 86.99
Round  48, Global train loss: 1.486, Global test loss: 1.571, Global test accuracy: 89.44
Round  49, Train loss: 1.488, Test loss: 1.596, Test accuracy: 86.99
Round  49, Global train loss: 1.488, Global test loss: 1.572, Global test accuracy: 89.32
Round  50, Train loss: 1.487, Test loss: 1.596, Test accuracy: 87.02
Round  50, Global train loss: 1.487, Global test loss: 1.571, Global test accuracy: 89.62
Round  51, Train loss: 1.487, Test loss: 1.596, Test accuracy: 87.03
Round  51, Global train loss: 1.487, Global test loss: 1.574, Global test accuracy: 89.25
Round  52, Train loss: 1.485, Test loss: 1.596, Test accuracy: 87.02
Round  52, Global train loss: 1.485, Global test loss: 1.569, Global test accuracy: 89.76
Round  53, Train loss: 1.485, Test loss: 1.595, Test accuracy: 87.04
Round  53, Global train loss: 1.485, Global test loss: 1.569, Global test accuracy: 89.81
Round  54, Train loss: 1.484, Test loss: 1.595, Test accuracy: 87.05
Round  54, Global train loss: 1.484, Global test loss: 1.568, Global test accuracy: 89.75
Round  55, Train loss: 1.484, Test loss: 1.595, Test accuracy: 87.06
Round  55, Global train loss: 1.484, Global test loss: 1.574, Global test accuracy: 89.12
Round  56, Train loss: 1.481, Test loss: 1.595, Test accuracy: 87.07
Round  56, Global train loss: 1.481, Global test loss: 1.571, Global test accuracy: 89.50
Round  57, Train loss: 1.480, Test loss: 1.595, Test accuracy: 87.09
Round  57, Global train loss: 1.480, Global test loss: 1.571, Global test accuracy: 89.62
Round  58, Train loss: 1.483, Test loss: 1.595, Test accuracy: 87.11
Round  58, Global train loss: 1.483, Global test loss: 1.569, Global test accuracy: 89.67
Round  59, Train loss: 1.482, Test loss: 1.595, Test accuracy: 87.08
Round  59, Global train loss: 1.482, Global test loss: 1.573, Global test accuracy: 89.13
Round  60, Train loss: 1.483, Test loss: 1.595, Test accuracy: 87.06
Round  60, Global train loss: 1.483, Global test loss: 1.569, Global test accuracy: 89.80
Round  61, Train loss: 1.481, Test loss: 1.594, Test accuracy: 87.05
Round  61, Global train loss: 1.481, Global test loss: 1.572, Global test accuracy: 89.34
Round  62, Train loss: 1.487, Test loss: 1.594, Test accuracy: 87.03
Round  62, Global train loss: 1.487, Global test loss: 1.571, Global test accuracy: 89.61
Round  63, Train loss: 1.485, Test loss: 1.594, Test accuracy: 87.09
Round  63, Global train loss: 1.485, Global test loss: 1.571, Global test accuracy: 89.40
Round  64, Train loss: 1.487, Test loss: 1.594, Test accuracy: 87.09
Round  64, Global train loss: 1.487, Global test loss: 1.573, Global test accuracy: 89.47
Round  65, Train loss: 1.484, Test loss: 1.594, Test accuracy: 87.11
Round  65, Global train loss: 1.484, Global test loss: 1.571, Global test accuracy: 89.62
Round  66, Train loss: 1.484, Test loss: 1.594, Test accuracy: 87.11
Round  66, Global train loss: 1.484, Global test loss: 1.571, Global test accuracy: 89.51
Round  67, Train loss: 1.484, Test loss: 1.594, Test accuracy: 87.15
Round  67, Global train loss: 1.484, Global test loss: 1.568, Global test accuracy: 89.80
Round  68, Train loss: 1.480, Test loss: 1.594, Test accuracy: 87.14
Round  68, Global train loss: 1.480, Global test loss: 1.571, Global test accuracy: 89.55
Round  69, Train loss: 1.481, Test loss: 1.594, Test accuracy: 87.16
Round  69, Global train loss: 1.481, Global test loss: 1.574, Global test accuracy: 89.14
Round  70, Train loss: 1.482, Test loss: 1.594, Test accuracy: 87.13
Round  70, Global train loss: 1.482, Global test loss: 1.569, Global test accuracy: 89.75
Round  71, Train loss: 1.482, Test loss: 1.594, Test accuracy: 87.13
Round  71, Global train loss: 1.482, Global test loss: 1.570, Global test accuracy: 89.39
Round  72, Train loss: 1.482, Test loss: 1.594, Test accuracy: 87.16
Round  72, Global train loss: 1.482, Global test loss: 1.573, Global test accuracy: 89.16
Round  73, Train loss: 1.486, Test loss: 1.594, Test accuracy: 87.14
Round  73, Global train loss: 1.486, Global test loss: 1.571, Global test accuracy: 89.56
Round  74, Train loss: 1.481, Test loss: 1.594, Test accuracy: 87.09
Round  74, Global train loss: 1.481, Global test loss: 1.568, Global test accuracy: 89.69
Round  75, Train loss: 1.480, Test loss: 1.594, Test accuracy: 87.11
Round  75, Global train loss: 1.480, Global test loss: 1.568, Global test accuracy: 89.64
Round  76, Train loss: 1.485, Test loss: 1.594, Test accuracy: 87.11
Round  76, Global train loss: 1.485, Global test loss: 1.571, Global test accuracy: 89.23
Round  77, Train loss: 1.481, Test loss: 1.594, Test accuracy: 87.11
Round  77, Global train loss: 1.481, Global test loss: 1.567, Global test accuracy: 89.81
Round  78, Train loss: 1.484, Test loss: 1.594, Test accuracy: 87.11
Round  78, Global train loss: 1.484, Global test loss: 1.572, Global test accuracy: 89.39
Round  79, Train loss: 1.485, Test loss: 1.594, Test accuracy: 87.11
Round  79, Global train loss: 1.485, Global test loss: 1.571, Global test accuracy: 89.57
Round  80, Train loss: 1.483, Test loss: 1.594, Test accuracy: 87.11
Round  80, Global train loss: 1.483, Global test loss: 1.567, Global test accuracy: 89.80
Round  81, Train loss: 1.480, Test loss: 1.594, Test accuracy: 87.09
Round  81, Global train loss: 1.480, Global test loss: 1.570, Global test accuracy: 89.60
Round  82, Train loss: 1.483, Test loss: 1.594, Test accuracy: 87.08
Round  82, Global train loss: 1.483, Global test loss: 1.568, Global test accuracy: 89.98
Round  83, Train loss: 1.482, Test loss: 1.594, Test accuracy: 87.08
Round  83, Global train loss: 1.482, Global test loss: 1.570, Global test accuracy: 89.37
Round  84, Train loss: 1.479, Test loss: 1.594, Test accuracy: 87.06
Round  84, Global train loss: 1.479, Global test loss: 1.570, Global test accuracy: 89.41
Round  85, Train loss: 1.482, Test loss: 1.594, Test accuracy: 87.01
Round  85, Global train loss: 1.482, Global test loss: 1.570, Global test accuracy: 89.40
Round  86, Train loss: 1.478, Test loss: 1.594, Test accuracy: 87.03
Round  86, Global train loss: 1.478, Global test loss: 1.572, Global test accuracy: 89.48
Round  87, Train loss: 1.480, Test loss: 1.594, Test accuracy: 87.04
Round  87, Global train loss: 1.480, Global test loss: 1.568, Global test accuracy: 89.44
Round  88, Train loss: 1.482, Test loss: 1.594, Test accuracy: 87.03
Round  88, Global train loss: 1.482, Global test loss: 1.569, Global test accuracy: 89.67
Round  89, Train loss: 1.480, Test loss: 1.594, Test accuracy: 87.04
Round  89, Global train loss: 1.480, Global test loss: 1.574, Global test accuracy: 89.31
Round  90, Train loss: 1.486, Test loss: 1.594, Test accuracy: 87.06
Round  90, Global train loss: 1.486, Global test loss: 1.567, Global test accuracy: 89.92
Round  91, Train loss: 1.481, Test loss: 1.594, Test accuracy: 87.08
Round  91, Global train loss: 1.481, Global test loss: 1.567, Global test accuracy: 89.83
Round  92, Train loss: 1.481, Test loss: 1.594, Test accuracy: 87.08
Round  92, Global train loss: 1.481, Global test loss: 1.568, Global test accuracy: 89.86
Round  93, Train loss: 1.482, Test loss: 1.594, Test accuracy: 87.08
Round  93, Global train loss: 1.482, Global test loss: 1.568, Global test accuracy: 89.64
Round  94, Train loss: 1.479, Test loss: 1.594, Test accuracy: 87.09
Round  94, Global train loss: 1.479, Global test loss: 1.569, Global test accuracy: 89.46
Round  95, Train loss: 1.484, Test loss: 1.594, Test accuracy: 87.09
Round  95, Global train loss: 1.484, Global test loss: 1.572, Global test accuracy: 89.23/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 1.484, Test loss: 1.594, Test accuracy: 87.11
Round  96, Global train loss: 1.484, Global test loss: 1.572, Global test accuracy: 89.30
Round  97, Train loss: 1.479, Test loss: 1.593, Test accuracy: 87.11
Round  97, Global train loss: 1.479, Global test loss: 1.567, Global test accuracy: 89.75
Round  98, Train loss: 1.480, Test loss: 1.594, Test accuracy: 87.11
Round  98, Global train loss: 1.480, Global test loss: 1.567, Global test accuracy: 89.83
Round  99, Train loss: 1.485, Test loss: 1.594, Test accuracy: 87.06
Round  99, Global train loss: 1.485, Global test loss: 1.566, Global test accuracy: 90.01
Final Round, Train loss: 1.481, Test loss: 1.593, Test accuracy: 87.10
Final Round, Global train loss: 1.481, Global test loss: 1.566, Global test accuracy: 90.01
Average accuracy final 10 rounds: 87.08800000000001 

Average global accuracy final 10 rounds: 89.6825 

2792.2774691581726
[1.7051630020141602, 3.4103260040283203, 5.243653059005737, 7.076980113983154, 8.756266832351685, 10.435553550720215, 12.15697431564331, 13.878395080566406, 15.637686967849731, 17.396978855133057, 19.074419498443604, 20.75186014175415, 22.497860431671143, 24.243860721588135, 26.176318407058716, 28.108776092529297, 30.05276346206665, 31.996750831604004, 33.97999715805054, 35.96324348449707, 37.87105846405029, 39.778873443603516, 41.7302463054657, 43.68161916732788, 45.58416295051575, 47.48670673370361, 49.37149739265442, 51.256288051605225, 53.16125774383545, 55.066227436065674, 56.9113335609436, 58.75643968582153, 60.67920279502869, 62.60196590423584, 64.49512934684753, 66.38829278945923, 68.33963108062744, 70.29096937179565, 72.19279980659485, 74.09463024139404, 76.03611993789673, 77.97760963439941, 79.72321701049805, 81.46882438659668, 83.2386646270752, 85.00850486755371, 86.86290621757507, 88.71730756759644, 90.72752714157104, 92.73774671554565, 94.39896392822266, 96.06018114089966, 97.67654657363892, 99.29291200637817, 100.96174621582031, 102.63058042526245, 104.26894283294678, 105.9073052406311, 107.5056209564209, 109.1039366722107, 110.75186395645142, 112.39979124069214, 114.03118944168091, 115.66258764266968, 117.31689023971558, 118.97119283676147, 120.6275041103363, 122.28381538391113, 123.89792656898499, 125.51203775405884, 127.12920594215393, 128.74637413024902, 130.38743662834167, 132.02849912643433, 133.60807371139526, 135.1876482963562, 137.06031394004822, 138.93297958374023, 140.66910552978516, 142.40523147583008, 144.0690155029297, 145.7327995300293, 147.42362093925476, 149.11444234848022, 150.73677325248718, 152.35910415649414, 153.98854446411133, 155.61798477172852, 157.21391582489014, 158.80984687805176, 160.6482276916504, 162.48660850524902, 164.05914735794067, 165.63168621063232, 167.24395728111267, 168.85622835159302, 170.5092167854309, 172.1622052192688, 173.88002514839172, 175.59784507751465, 177.28916907310486, 178.98049306869507, 180.94521594047546, 182.90993881225586, 184.77227234840393, 186.634605884552, 188.4058485031128, 190.17709112167358, 191.8246510028839, 193.47221088409424, 195.0410304069519, 196.60984992980957, 198.45415353775024, 200.29845714569092, 202.26775765419006, 204.2370581626892, 205.87139177322388, 207.50572538375854, 209.1237199306488, 210.74171447753906, 212.42530846595764, 214.10890245437622, 215.79110026359558, 217.47329807281494, 219.08391165733337, 220.6945252418518, 222.31127262115479, 223.92802000045776, 225.5375361442566, 227.14705228805542, 228.83448958396912, 230.5219268798828, 232.2227668762207, 233.9236068725586, 235.79562330245972, 237.66763973236084, 239.5177707672119, 241.367901802063, 242.99596667289734, 244.6240315437317, 246.2572319507599, 247.8904323577881, 249.75670671463013, 251.62298107147217, 253.28081607818604, 254.9386510848999, 256.62341022491455, 258.3081693649292, 260.01045751571655, 261.7127456665039, 263.3658185005188, 265.0188913345337, 266.6476719379425, 268.2764525413513, 269.8797206878662, 271.4829888343811, 273.10759258270264, 274.73219633102417, 276.3323018550873, 277.9324073791504, 279.6012568473816, 281.2701063156128, 282.90951800346375, 284.5489296913147, 286.21495962142944, 287.8809895515442, 289.5215103626251, 291.16203117370605, 292.80571484565735, 294.44939851760864, 296.1540699005127, 297.85874128341675, 299.4826192855835, 301.10649728775024, 302.743225812912, 304.37995433807373, 305.9963505268097, 307.61274671554565, 309.2350935935974, 310.85744047164917, 312.495543718338, 314.13364696502686, 315.75068402290344, 317.36772108078003, 319.0424802303314, 320.7172393798828, 322.4211411476135, 324.12504291534424, 325.7900822162628, 327.4551215171814, 329.11832666397095, 330.7815318107605, 332.67682695388794, 334.5721220970154, 336.4163522720337, 338.260582447052, 339.8777222633362, 341.49486207962036, 343.17942667007446, 344.86399126052856, 346.807555437088, 348.75111961364746]
[40.875, 40.875, 36.46, 36.46, 53.435, 53.435, 59.28, 59.28, 62.685, 62.685, 66.955, 66.955, 67.855, 67.855, 70.515, 70.515, 73.945, 73.945, 76.35, 76.35, 77.96, 77.96, 78.3, 78.3, 78.285, 78.285, 79.03, 79.03, 79.935, 79.935, 80.695, 80.695, 80.845, 80.845, 82.38, 82.38, 82.63, 82.63, 83.47, 83.47, 83.795, 83.795, 83.83, 83.83, 83.97, 83.97, 84.53, 84.53, 84.655, 84.655, 85.23, 85.23, 85.24, 85.24, 85.915, 85.915, 86.035, 86.035, 86.195, 86.195, 86.23, 86.23, 86.285, 86.285, 86.38, 86.38, 86.395, 86.395, 86.455, 86.455, 86.495, 86.495, 86.9, 86.9, 86.9, 86.9, 86.895, 86.895, 86.955, 86.955, 86.94, 86.94, 86.915, 86.915, 86.94, 86.94, 86.94, 86.94, 86.92, 86.92, 86.965, 86.965, 86.925, 86.925, 86.955, 86.955, 86.99, 86.99, 86.99, 86.99, 87.015, 87.015, 87.025, 87.025, 87.015, 87.015, 87.04, 87.04, 87.05, 87.05, 87.065, 87.065, 87.07, 87.07, 87.09, 87.09, 87.115, 87.115, 87.085, 87.085, 87.065, 87.065, 87.05, 87.05, 87.025, 87.025, 87.09, 87.09, 87.09, 87.09, 87.11, 87.11, 87.105, 87.105, 87.15, 87.15, 87.145, 87.145, 87.16, 87.16, 87.13, 87.13, 87.13, 87.13, 87.155, 87.155, 87.135, 87.135, 87.095, 87.095, 87.105, 87.105, 87.11, 87.11, 87.115, 87.115, 87.115, 87.115, 87.115, 87.115, 87.11, 87.11, 87.09, 87.09, 87.075, 87.075, 87.08, 87.08, 87.065, 87.065, 87.01, 87.01, 87.025, 87.025, 87.04, 87.04, 87.035, 87.035, 87.04, 87.04, 87.06, 87.06, 87.075, 87.075, 87.075, 87.075, 87.08, 87.08, 87.095, 87.095, 87.095, 87.095, 87.11, 87.11, 87.11, 87.11, 87.115, 87.115, 87.065, 87.065, 87.1, 87.1]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.298, Test loss: 2.293, Test accuracy: 43.32
Round   0, Global train loss: 2.298, Global test loss: 2.293, Global test accuracy: 44.11
Round   1, Train loss: 2.258, Test loss: 2.197, Test accuracy: 33.30
Round   1, Global train loss: 2.258, Global test loss: 2.173, Global test accuracy: 31.16
Round   2, Train loss: 1.979, Test loss: 1.951, Test accuracy: 57.88
Round   2, Global train loss: 1.979, Global test loss: 1.805, Global test accuracy: 71.11
Round   3, Train loss: 1.715, Test loss: 1.807, Test accuracy: 70.32
Round   3, Global train loss: 1.715, Global test loss: 1.652, Global test accuracy: 84.40
Round   4, Train loss: 1.618, Test loss: 1.754, Test accuracy: 74.86
Round   4, Global train loss: 1.618, Global test loss: 1.605, Global test accuracy: 87.22
Round   5, Train loss: 1.581, Test loss: 1.726, Test accuracy: 77.12
Round   5, Global train loss: 1.581, Global test loss: 1.587, Global test accuracy: 88.69
Round   6, Train loss: 1.569, Test loss: 1.653, Test accuracy: 82.67
Round   6, Global train loss: 1.569, Global test loss: 1.575, Global test accuracy: 89.50
Round   7, Train loss: 1.557, Test loss: 1.647, Test accuracy: 83.03
Round   7, Global train loss: 1.557, Global test loss: 1.568, Global test accuracy: 90.30
Round   8, Train loss: 1.542, Test loss: 1.597, Test accuracy: 87.50
Round   8, Global train loss: 1.542, Global test loss: 1.560, Global test accuracy: 90.72
Round   9, Train loss: 1.534, Test loss: 1.593, Test accuracy: 87.78
Round   9, Global train loss: 1.534, Global test loss: 1.556, Global test accuracy: 91.20
Round  10, Train loss: 1.530, Test loss: 1.587, Test accuracy: 88.30
Round  10, Global train loss: 1.530, Global test loss: 1.552, Global test accuracy: 91.57
Round  11, Train loss: 1.525, Test loss: 1.583, Test accuracy: 88.70
Round  11, Global train loss: 1.525, Global test loss: 1.548, Global test accuracy: 91.72
Round  12, Train loss: 1.515, Test loss: 1.578, Test accuracy: 89.05
Round  12, Global train loss: 1.515, Global test loss: 1.545, Global test accuracy: 92.13
Round  13, Train loss: 1.516, Test loss: 1.574, Test accuracy: 89.42
Round  13, Global train loss: 1.516, Global test loss: 1.544, Global test accuracy: 92.25
Round  14, Train loss: 1.507, Test loss: 1.571, Test accuracy: 89.69
Round  14, Global train loss: 1.507, Global test loss: 1.541, Global test accuracy: 92.45
Round  15, Train loss: 1.512, Test loss: 1.554, Test accuracy: 91.14
Round  15, Global train loss: 1.512, Global test loss: 1.541, Global test accuracy: 92.61
Round  16, Train loss: 1.509, Test loss: 1.553, Test accuracy: 91.26
Round  16, Global train loss: 1.509, Global test loss: 1.538, Global test accuracy: 92.74
Round  17, Train loss: 1.504, Test loss: 1.548, Test accuracy: 91.67
Round  17, Global train loss: 1.504, Global test loss: 1.536, Global test accuracy: 92.95
Round  18, Train loss: 1.503, Test loss: 1.548, Test accuracy: 91.70
Round  18, Global train loss: 1.503, Global test loss: 1.536, Global test accuracy: 92.86
Round  19, Train loss: 1.498, Test loss: 1.545, Test accuracy: 91.92
Round  19, Global train loss: 1.498, Global test loss: 1.534, Global test accuracy: 92.89
Round  20, Train loss: 1.505, Test loss: 1.543, Test accuracy: 92.12
Round  20, Global train loss: 1.505, Global test loss: 1.533, Global test accuracy: 93.09
Round  21, Train loss: 1.497, Test loss: 1.543, Test accuracy: 92.15
Round  21, Global train loss: 1.497, Global test loss: 1.532, Global test accuracy: 93.14
Round  22, Train loss: 1.493, Test loss: 1.542, Test accuracy: 92.17
Round  22, Global train loss: 1.493, Global test loss: 1.530, Global test accuracy: 93.31
Round  23, Train loss: 1.501, Test loss: 1.538, Test accuracy: 92.62
Round  23, Global train loss: 1.501, Global test loss: 1.529, Global test accuracy: 93.67
Round  24, Train loss: 1.497, Test loss: 1.537, Test accuracy: 92.68
Round  24, Global train loss: 1.497, Global test loss: 1.528, Global test accuracy: 93.55
Round  25, Train loss: 1.495, Test loss: 1.535, Test accuracy: 92.85
Round  25, Global train loss: 1.495, Global test loss: 1.527, Global test accuracy: 93.78
Round  26, Train loss: 1.491, Test loss: 1.534, Test accuracy: 92.97
Round  26, Global train loss: 1.491, Global test loss: 1.526, Global test accuracy: 93.84
Round  27, Train loss: 1.493, Test loss: 1.533, Test accuracy: 93.16
Round  27, Global train loss: 1.493, Global test loss: 1.524, Global test accuracy: 94.07
Round  28, Train loss: 1.490, Test loss: 1.532, Test accuracy: 93.30
Round  28, Global train loss: 1.490, Global test loss: 1.524, Global test accuracy: 93.98
Round  29, Train loss: 1.494, Test loss: 1.531, Test accuracy: 93.36
Round  29, Global train loss: 1.494, Global test loss: 1.524, Global test accuracy: 93.89
Round  30, Train loss: 1.493, Test loss: 1.529, Test accuracy: 93.48
Round  30, Global train loss: 1.493, Global test loss: 1.523, Global test accuracy: 94.03
Round  31, Train loss: 1.490, Test loss: 1.528, Test accuracy: 93.61
Round  31, Global train loss: 1.490, Global test loss: 1.522, Global test accuracy: 94.21
Round  32, Train loss: 1.486, Test loss: 1.528, Test accuracy: 93.64
Round  32, Global train loss: 1.486, Global test loss: 1.522, Global test accuracy: 94.25
Round  33, Train loss: 1.488, Test loss: 1.527, Test accuracy: 93.68
Round  33, Global train loss: 1.488, Global test loss: 1.521, Global test accuracy: 94.17
Round  34, Train loss: 1.490, Test loss: 1.526, Test accuracy: 93.74
Round  34, Global train loss: 1.490, Global test loss: 1.519, Global test accuracy: 94.48
Round  35, Train loss: 1.487, Test loss: 1.525, Test accuracy: 93.78
Round  35, Global train loss: 1.487, Global test loss: 1.519, Global test accuracy: 94.42
Round  36, Train loss: 1.489, Test loss: 1.525, Test accuracy: 93.86
Round  36, Global train loss: 1.489, Global test loss: 1.519, Global test accuracy: 94.45
Round  37, Train loss: 1.483, Test loss: 1.524, Test accuracy: 94.03
Round  37, Global train loss: 1.483, Global test loss: 1.518, Global test accuracy: 94.53
Round  38, Train loss: 1.490, Test loss: 1.523, Test accuracy: 94.08
Round  38, Global train loss: 1.490, Global test loss: 1.518, Global test accuracy: 94.52
Round  39, Train loss: 1.483, Test loss: 1.523, Test accuracy: 94.14
Round  39, Global train loss: 1.483, Global test loss: 1.517, Global test accuracy: 94.70
Round  40, Train loss: 1.483, Test loss: 1.523, Test accuracy: 94.13
Round  40, Global train loss: 1.483, Global test loss: 1.517, Global test accuracy: 94.67
Round  41, Train loss: 1.486, Test loss: 1.522, Test accuracy: 94.19
Round  41, Global train loss: 1.486, Global test loss: 1.516, Global test accuracy: 94.66
Round  42, Train loss: 1.482, Test loss: 1.521, Test accuracy: 94.28
Round  42, Global train loss: 1.482, Global test loss: 1.517, Global test accuracy: 94.67
Round  43, Train loss: 1.481, Test loss: 1.520, Test accuracy: 94.37
Round  43, Global train loss: 1.481, Global test loss: 1.516, Global test accuracy: 94.70
Round  44, Train loss: 1.485, Test loss: 1.520, Test accuracy: 94.41
Round  44, Global train loss: 1.485, Global test loss: 1.515, Global test accuracy: 94.86
Round  45, Train loss: 1.483, Test loss: 1.519, Test accuracy: 94.47
Round  45, Global train loss: 1.483, Global test loss: 1.515, Global test accuracy: 94.80
Round  46, Train loss: 1.484, Test loss: 1.519, Test accuracy: 94.45
Round  46, Global train loss: 1.484, Global test loss: 1.516, Global test accuracy: 94.72
Round  47, Train loss: 1.482, Test loss: 1.519, Test accuracy: 94.45
Round  47, Global train loss: 1.482, Global test loss: 1.514, Global test accuracy: 94.96
Round  48, Train loss: 1.482, Test loss: 1.519, Test accuracy: 94.53
Round  48, Global train loss: 1.482, Global test loss: 1.513, Global test accuracy: 94.95
Round  49, Train loss: 1.480, Test loss: 1.518, Test accuracy: 94.53
Round  49, Global train loss: 1.480, Global test loss: 1.514, Global test accuracy: 94.89
Round  50, Train loss: 1.480, Test loss: 1.518, Test accuracy: 94.60
Round  50, Global train loss: 1.480, Global test loss: 1.513, Global test accuracy: 95.06
Round  51, Train loss: 1.480, Test loss: 1.517, Test accuracy: 94.64
Round  51, Global train loss: 1.480, Global test loss: 1.512, Global test accuracy: 95.14
Round  52, Train loss: 1.482, Test loss: 1.516, Test accuracy: 94.70
Round  52, Global train loss: 1.482, Global test loss: 1.512, Global test accuracy: 95.23
Round  53, Train loss: 1.480, Test loss: 1.516, Test accuracy: 94.72
Round  53, Global train loss: 1.480, Global test loss: 1.512, Global test accuracy: 95.21
Round  54, Train loss: 1.480, Test loss: 1.516, Test accuracy: 94.70
Round  54, Global train loss: 1.480, Global test loss: 1.512, Global test accuracy: 95.20
Round  55, Train loss: 1.482, Test loss: 1.516, Test accuracy: 94.69
Round  55, Global train loss: 1.482, Global test loss: 1.512, Global test accuracy: 95.14
Round  56, Train loss: 1.476, Test loss: 1.515, Test accuracy: 94.75
Round  56, Global train loss: 1.476, Global test loss: 1.511, Global test accuracy: 95.07
Round  57, Train loss: 1.476, Test loss: 1.515, Test accuracy: 94.83
Round  57, Global train loss: 1.476, Global test loss: 1.512, Global test accuracy: 95.22
Round  58, Train loss: 1.476, Test loss: 1.515, Test accuracy: 94.88
Round  58, Global train loss: 1.476, Global test loss: 1.511, Global test accuracy: 95.17
Round  59, Train loss: 1.480, Test loss: 1.514, Test accuracy: 94.99
Round  59, Global train loss: 1.480, Global test loss: 1.512, Global test accuracy: 95.13
Round  60, Train loss: 1.475, Test loss: 1.514, Test accuracy: 94.94
Round  60, Global train loss: 1.475, Global test loss: 1.511, Global test accuracy: 95.12
Round  61, Train loss: 1.479, Test loss: 1.514, Test accuracy: 94.94
Round  61, Global train loss: 1.479, Global test loss: 1.511, Global test accuracy: 95.17
Round  62, Train loss: 1.475, Test loss: 1.514, Test accuracy: 95.01
Round  62, Global train loss: 1.475, Global test loss: 1.511, Global test accuracy: 95.22
Round  63, Train loss: 1.478, Test loss: 1.514, Test accuracy: 95.02
Round  63, Global train loss: 1.478, Global test loss: 1.512, Global test accuracy: 95.17
Round  64, Train loss: 1.476, Test loss: 1.514, Test accuracy: 95.02
Round  64, Global train loss: 1.476, Global test loss: 1.511, Global test accuracy: 95.33
Round  65, Train loss: 1.479, Test loss: 1.514, Test accuracy: 94.96
Round  65, Global train loss: 1.479, Global test loss: 1.511, Global test accuracy: 95.17
Round  66, Train loss: 1.476, Test loss: 1.513, Test accuracy: 95.00
Round  66, Global train loss: 1.476, Global test loss: 1.511, Global test accuracy: 95.33
Round  67, Train loss: 1.478, Test loss: 1.513, Test accuracy: 94.95
Round  67, Global train loss: 1.478, Global test loss: 1.511, Global test accuracy: 95.22
Round  68, Train loss: 1.480, Test loss: 1.513, Test accuracy: 94.97
Round  68, Global train loss: 1.480, Global test loss: 1.511, Global test accuracy: 95.33
Round  69, Train loss: 1.477, Test loss: 1.513, Test accuracy: 95.02
Round  69, Global train loss: 1.477, Global test loss: 1.511, Global test accuracy: 95.37
Round  70, Train loss: 1.474, Test loss: 1.513, Test accuracy: 95.05
Round  70, Global train loss: 1.474, Global test loss: 1.511, Global test accuracy: 95.31
Round  71, Train loss: 1.476, Test loss: 1.513, Test accuracy: 95.00
Round  71, Global train loss: 1.476, Global test loss: 1.511, Global test accuracy: 95.18
Round  72, Train loss: 1.474, Test loss: 1.513, Test accuracy: 95.05
Round  72, Global train loss: 1.474, Global test loss: 1.511, Global test accuracy: 95.27
Round  73, Train loss: 1.474, Test loss: 1.513, Test accuracy: 95.05
Round  73, Global train loss: 1.474, Global test loss: 1.511, Global test accuracy: 95.15
Round  74, Train loss: 1.474, Test loss: 1.513, Test accuracy: 95.06
Round  74, Global train loss: 1.474, Global test loss: 1.511, Global test accuracy: 95.23
Round  75, Train loss: 1.472, Test loss: 1.513, Test accuracy: 95.06
Round  75, Global train loss: 1.472, Global test loss: 1.510, Global test accuracy: 95.44
Round  76, Train loss: 1.476, Test loss: 1.512, Test accuracy: 95.10
Round  76, Global train loss: 1.476, Global test loss: 1.510, Global test accuracy: 95.26
Round  77, Train loss: 1.474, Test loss: 1.512, Test accuracy: 95.11
Round  77, Global train loss: 1.474, Global test loss: 1.510, Global test accuracy: 95.23
Round  78, Train loss: 1.478, Test loss: 1.512, Test accuracy: 95.15
Round  78, Global train loss: 1.478, Global test loss: 1.509, Global test accuracy: 95.33
Round  79, Train loss: 1.474, Test loss: 1.511, Test accuracy: 95.16
Round  79, Global train loss: 1.474, Global test loss: 1.510, Global test accuracy: 95.31
Round  80, Train loss: 1.472, Test loss: 1.511, Test accuracy: 95.16
Round  80, Global train loss: 1.472, Global test loss: 1.510, Global test accuracy: 95.25
Round  81, Train loss: 1.477, Test loss: 1.512, Test accuracy: 95.17
Round  81, Global train loss: 1.477, Global test loss: 1.509, Global test accuracy: 95.36
Round  82, Train loss: 1.474, Test loss: 1.512, Test accuracy: 95.16
Round  82, Global train loss: 1.474, Global test loss: 1.509, Global test accuracy: 95.44
Round  83, Train loss: 1.475, Test loss: 1.511, Test accuracy: 95.17
Round  83, Global train loss: 1.475, Global test loss: 1.509, Global test accuracy: 95.40
Round  84, Train loss: 1.476, Test loss: 1.511, Test accuracy: 95.18
Round  84, Global train loss: 1.476, Global test loss: 1.509, Global test accuracy: 95.42
Round  85, Train loss: 1.478, Test loss: 1.511, Test accuracy: 95.15
Round  85, Global train loss: 1.478, Global test loss: 1.509, Global test accuracy: 95.45
Round  86, Train loss: 1.475, Test loss: 1.511, Test accuracy: 95.16
Round  86, Global train loss: 1.475, Global test loss: 1.509, Global test accuracy: 95.37
Round  87, Train loss: 1.474, Test loss: 1.511, Test accuracy: 95.17
Round  87, Global train loss: 1.474, Global test loss: 1.509, Global test accuracy: 95.48
Round  88, Train loss: 1.472, Test loss: 1.511, Test accuracy: 95.18
Round  88, Global train loss: 1.472, Global test loss: 1.509, Global test accuracy: 95.36
Round  89, Train loss: 1.474, Test loss: 1.511, Test accuracy: 95.23
Round  89, Global train loss: 1.474, Global test loss: 1.508, Global test accuracy: 95.43
Round  90, Train loss: 1.475, Test loss: 1.511, Test accuracy: 95.27
Round  90, Global train loss: 1.475, Global test loss: 1.508, Global test accuracy: 95.44
Round  91, Train loss: 1.474, Test loss: 1.511, Test accuracy: 95.28
Round  91, Global train loss: 1.474, Global test loss: 1.509, Global test accuracy: 95.35
Round  92, Train loss: 1.475, Test loss: 1.510, Test accuracy: 95.31
Round  92, Global train loss: 1.475, Global test loss: 1.509, Global test accuracy: 95.40
Round  93, Train loss: 1.474, Test loss: 1.510, Test accuracy: 95.31
Round  93, Global train loss: 1.474, Global test loss: 1.509, Global test accuracy: 95.44
Round  94, Train loss: 1.472, Test loss: 1.510, Test accuracy: 95.28
Round  94, Global train loss: 1.472, Global test loss: 1.508, Global test accuracy: 95.44
Round  95, Train loss: 1.473, Test loss: 1.510, Test accuracy: 95.28
Round  95, Global train loss: 1.473, Global test loss: 1.508, Global test accuracy: 95.55/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 1.476, Test loss: 1.510, Test accuracy: 95.28
Round  96, Global train loss: 1.476, Global test loss: 1.508, Global test accuracy: 95.42
Round  97, Train loss: 1.472, Test loss: 1.510, Test accuracy: 95.35
Round  97, Global train loss: 1.472, Global test loss: 1.508, Global test accuracy: 95.44
Round  98, Train loss: 1.471, Test loss: 1.510, Test accuracy: 95.39
Round  98, Global train loss: 1.471, Global test loss: 1.508, Global test accuracy: 95.43
Round  99, Train loss: 1.474, Test loss: 1.510, Test accuracy: 95.35
Round  99, Global train loss: 1.474, Global test loss: 1.508, Global test accuracy: 95.53
Final Round, Train loss: 1.472, Test loss: 1.509, Test accuracy: 95.33
Final Round, Global train loss: 1.472, Global test loss: 1.508, Global test accuracy: 95.53
Average accuracy final 10 rounds: 95.3095 

Average global accuracy final 10 rounds: 95.444 

2830.919574022293
[1.8966894149780273, 3.7933788299560547, 5.641669988632202, 7.48996114730835, 9.28730320930481, 11.08464527130127, 12.911795854568481, 14.738946437835693, 16.590309858322144, 18.441673278808594, 20.061300039291382, 21.68092679977417, 23.320470333099365, 24.96001386642456, 26.73999333381653, 28.519972801208496, 30.414388418197632, 32.30880403518677, 34.32079792022705, 36.332791805267334, 38.31675338745117, 40.30071496963501, 42.26141428947449, 44.222113609313965, 46.144490242004395, 48.066866874694824, 49.68244409561157, 51.29802131652832, 52.932307958602905, 54.56659460067749, 56.39431810379028, 58.222041606903076, 59.845149993896484, 61.46825838088989, 63.11117219924927, 64.75408601760864, 66.4262170791626, 68.09834814071655, 69.72339510917664, 71.34844207763672, 73.01673650741577, 74.68503093719482, 76.38670611381531, 78.08838129043579, 79.76692152023315, 81.44546175003052, 83.0411548614502, 84.63684797286987, 86.21578621864319, 87.7947244644165, 89.44460940361023, 91.09449434280396, 92.70986413955688, 94.32523393630981, 95.9596700668335, 97.59410619735718, 99.26925849914551, 100.94441080093384, 102.66657900810242, 104.388747215271, 106.04752945899963, 107.70631170272827, 109.32626843452454, 110.9462251663208, 112.55777382850647, 114.16932249069214, 115.7561559677124, 117.34298944473267, 118.98525404930115, 120.62751865386963, 122.33812427520752, 124.04872989654541, 125.75452518463135, 127.46032047271729, 129.17514991760254, 130.8899793624878, 132.59484004974365, 134.2997007369995, 135.92948389053345, 137.55926704406738, 139.24575185775757, 140.93223667144775, 142.55987238883972, 144.1875081062317, 145.84813570976257, 147.50876331329346, 149.1590187549591, 150.80927419662476, 152.4628779888153, 154.11648178100586, 155.7571358680725, 157.39778995513916, 159.09613513946533, 160.7944803237915, 162.4344835281372, 164.0744867324829, 165.69098114967346, 167.307475566864, 168.94867634773254, 170.58987712860107, 172.2448649406433, 173.89985275268555, 175.59469032287598, 177.2895278930664, 178.93857407569885, 180.5876202583313, 182.2307951450348, 183.87397003173828, 185.50649499893188, 187.1390199661255, 188.8117163181305, 190.4844126701355, 192.11016011238098, 193.73590755462646, 195.35925102233887, 196.98259449005127, 198.64835572242737, 200.31411695480347, 202.02163982391357, 203.72916269302368, 205.41717314720154, 207.1051836013794, 208.8106496334076, 210.5161156654358, 212.1799397468567, 213.8437638282776, 215.49266982078552, 217.14157581329346, 218.83413219451904, 220.52668857574463, 222.18449878692627, 223.8423089981079, 225.518550157547, 227.19479131698608, 228.92245173454285, 230.6501121520996, 232.32314944267273, 233.99618673324585, 235.73645210266113, 237.47671747207642, 239.24468898773193, 241.01266050338745, 242.74937748908997, 244.48609447479248, 246.15986371040344, 247.8336329460144, 249.4494116306305, 251.06519031524658, 252.72232866287231, 254.37946701049805, 256.0174996852875, 257.6555323600769, 259.31099367141724, 260.96645498275757, 262.70488357543945, 264.44331216812134, 266.22745299339294, 268.01159381866455, 269.7374007701874, 271.4632077217102, 273.2007586956024, 274.93830966949463, 276.74165415763855, 278.54499864578247, 280.28396129608154, 282.0229239463806, 283.7217073440552, 285.42049074172974, 287.1127281188965, 288.80496549606323, 290.4804513454437, 292.1559371948242, 293.8228130340576, 295.489688873291, 297.20564341545105, 298.9215979576111, 300.6370208263397, 302.35244369506836, 304.12670254707336, 305.90096139907837, 307.685152053833, 309.46934270858765, 311.24583983421326, 313.02233695983887, 314.81306433677673, 316.6037917137146, 318.36773109436035, 320.1316704750061, 321.8994233608246, 323.66717624664307, 325.3450050354004, 327.0228338241577, 328.71797370910645, 330.4131135940552, 332.0912742614746, 333.76943492889404, 335.45941281318665, 337.14939069747925, 338.89696884155273, 340.6445469856262, 342.42359709739685, 344.2026472091675]
[43.32, 43.32, 33.305, 33.305, 57.88, 57.88, 70.32, 70.32, 74.86, 74.86, 77.125, 77.125, 82.67, 82.67, 83.03, 83.03, 87.505, 87.505, 87.775, 87.775, 88.295, 88.295, 88.705, 88.705, 89.05, 89.05, 89.415, 89.415, 89.69, 89.69, 91.145, 91.145, 91.26, 91.26, 91.675, 91.675, 91.705, 91.705, 91.915, 91.915, 92.125, 92.125, 92.15, 92.15, 92.175, 92.175, 92.62, 92.62, 92.68, 92.68, 92.85, 92.85, 92.975, 92.975, 93.155, 93.155, 93.295, 93.295, 93.36, 93.36, 93.48, 93.48, 93.605, 93.605, 93.645, 93.645, 93.68, 93.68, 93.74, 93.74, 93.785, 93.785, 93.86, 93.86, 94.025, 94.025, 94.08, 94.08, 94.135, 94.135, 94.13, 94.13, 94.185, 94.185, 94.275, 94.275, 94.37, 94.37, 94.41, 94.41, 94.475, 94.475, 94.45, 94.45, 94.455, 94.455, 94.525, 94.525, 94.535, 94.535, 94.6, 94.6, 94.645, 94.645, 94.705, 94.705, 94.72, 94.72, 94.7, 94.7, 94.69, 94.69, 94.745, 94.745, 94.83, 94.83, 94.88, 94.88, 94.99, 94.99, 94.945, 94.945, 94.945, 94.945, 95.01, 95.01, 95.02, 95.02, 95.015, 95.015, 94.96, 94.96, 95.005, 95.005, 94.955, 94.955, 94.975, 94.975, 95.015, 95.015, 95.045, 95.045, 95.0, 95.0, 95.045, 95.045, 95.045, 95.045, 95.06, 95.06, 95.055, 95.055, 95.1, 95.1, 95.11, 95.11, 95.15, 95.15, 95.16, 95.16, 95.155, 95.155, 95.165, 95.165, 95.16, 95.16, 95.175, 95.175, 95.18, 95.18, 95.15, 95.15, 95.16, 95.16, 95.165, 95.165, 95.18, 95.18, 95.23, 95.23, 95.265, 95.265, 95.275, 95.275, 95.305, 95.305, 95.31, 95.31, 95.275, 95.275, 95.285, 95.285, 95.285, 95.285, 95.35, 95.35, 95.395, 95.395, 95.35, 95.35, 95.33, 95.33]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.301, Test loss: 2.299, Test accuracy: 24.41
Round   1, Train loss: 2.296, Test loss: 2.291, Test accuracy: 37.18
Round   2, Train loss: 2.284, Test loss: 2.261, Test accuracy: 31.18
Round   3, Train loss: 2.227, Test loss: 2.193, Test accuracy: 45.25
Round   4, Train loss: 2.111, Test loss: 2.002, Test accuracy: 57.81
Round   5, Train loss: 1.917, Test loss: 1.880, Test accuracy: 65.69
Round   6, Train loss: 1.788, Test loss: 1.781, Test accuracy: 73.42
Round   7, Train loss: 1.679, Test loss: 1.708, Test accuracy: 79.67
Round   8, Train loss: 1.633, Test loss: 1.658, Test accuracy: 83.78
Round   9, Train loss: 1.610, Test loss: 1.626, Test accuracy: 85.98
Round  10, Train loss: 1.592, Test loss: 1.610, Test accuracy: 86.95
Round  11, Train loss: 1.570, Test loss: 1.600, Test accuracy: 87.83
Round  12, Train loss: 1.576, Test loss: 1.596, Test accuracy: 87.67
Round  13, Train loss: 1.560, Test loss: 1.590, Test accuracy: 88.21
Round  14, Train loss: 1.560, Test loss: 1.578, Test accuracy: 89.44
Round  15, Train loss: 1.548, Test loss: 1.575, Test accuracy: 89.69
Round  16, Train loss: 1.554, Test loss: 1.570, Test accuracy: 90.08
Round  17, Train loss: 1.544, Test loss: 1.570, Test accuracy: 89.90
Round  18, Train loss: 1.537, Test loss: 1.567, Test accuracy: 90.17
Round  19, Train loss: 1.540, Test loss: 1.566, Test accuracy: 90.26
Round  20, Train loss: 1.543, Test loss: 1.564, Test accuracy: 90.47
Round  21, Train loss: 1.537, Test loss: 1.563, Test accuracy: 90.60
Round  22, Train loss: 1.532, Test loss: 1.562, Test accuracy: 90.66
Round  23, Train loss: 1.525, Test loss: 1.561, Test accuracy: 90.72
Round  24, Train loss: 1.525, Test loss: 1.559, Test accuracy: 90.84
Round  25, Train loss: 1.530, Test loss: 1.556, Test accuracy: 91.00
Round  26, Train loss: 1.525, Test loss: 1.557, Test accuracy: 90.81
Round  27, Train loss: 1.513, Test loss: 1.556, Test accuracy: 91.06
Round  28, Train loss: 1.517, Test loss: 1.556, Test accuracy: 91.02
Round  29, Train loss: 1.520, Test loss: 1.553, Test accuracy: 91.22
Round  30, Train loss: 1.515, Test loss: 1.554, Test accuracy: 91.12
Round  31, Train loss: 1.513, Test loss: 1.551, Test accuracy: 91.52
Round  32, Train loss: 1.515, Test loss: 1.550, Test accuracy: 91.59
Round  33, Train loss: 1.506, Test loss: 1.550, Test accuracy: 91.61
Round  34, Train loss: 1.510, Test loss: 1.548, Test accuracy: 91.83
Round  35, Train loss: 1.513, Test loss: 1.549, Test accuracy: 91.63
Round  36, Train loss: 1.508, Test loss: 1.549, Test accuracy: 91.68
Round  37, Train loss: 1.508, Test loss: 1.549, Test accuracy: 91.58
Round  38, Train loss: 1.516, Test loss: 1.548, Test accuracy: 91.61
Round  39, Train loss: 1.515, Test loss: 1.546, Test accuracy: 91.86
Round  40, Train loss: 1.508, Test loss: 1.545, Test accuracy: 91.98
Round  41, Train loss: 1.508, Test loss: 1.544, Test accuracy: 92.00
Round  42, Train loss: 1.506, Test loss: 1.543, Test accuracy: 92.11
Round  43, Train loss: 1.503, Test loss: 1.543, Test accuracy: 92.14
Round  44, Train loss: 1.501, Test loss: 1.543, Test accuracy: 92.08
Round  45, Train loss: 1.504, Test loss: 1.542, Test accuracy: 92.16
Round  46, Train loss: 1.502, Test loss: 1.542, Test accuracy: 92.19
Round  47, Train loss: 1.505, Test loss: 1.544, Test accuracy: 91.97
Round  48, Train loss: 1.505, Test loss: 1.542, Test accuracy: 92.24
Round  49, Train loss: 1.503, Test loss: 1.541, Test accuracy: 92.32
Round  50, Train loss: 1.506, Test loss: 1.542, Test accuracy: 92.32
Round  51, Train loss: 1.501, Test loss: 1.540, Test accuracy: 92.47
Round  52, Train loss: 1.507, Test loss: 1.539, Test accuracy: 92.48
Round  53, Train loss: 1.498, Test loss: 1.539, Test accuracy: 92.53
Round  54, Train loss: 1.497, Test loss: 1.539, Test accuracy: 92.53
Round  55, Train loss: 1.500, Test loss: 1.539, Test accuracy: 92.52
Round  56, Train loss: 1.497, Test loss: 1.539, Test accuracy: 92.39
Round  57, Train loss: 1.501, Test loss: 1.539, Test accuracy: 92.42
Round  58, Train loss: 1.497, Test loss: 1.538, Test accuracy: 92.42
Round  59, Train loss: 1.496, Test loss: 1.538, Test accuracy: 92.51
Round  60, Train loss: 1.496, Test loss: 1.538, Test accuracy: 92.56
Round  61, Train loss: 1.499, Test loss: 1.537, Test accuracy: 92.61
Round  62, Train loss: 1.499, Test loss: 1.536, Test accuracy: 92.66
Round  63, Train loss: 1.495, Test loss: 1.537, Test accuracy: 92.64
Round  64, Train loss: 1.495, Test loss: 1.537, Test accuracy: 92.69
Round  65, Train loss: 1.495, Test loss: 1.537, Test accuracy: 92.57
Round  66, Train loss: 1.494, Test loss: 1.537, Test accuracy: 92.64
Round  67, Train loss: 1.492, Test loss: 1.537, Test accuracy: 92.59
Round  68, Train loss: 1.496, Test loss: 1.536, Test accuracy: 92.69
Round  69, Train loss: 1.490, Test loss: 1.535, Test accuracy: 92.74
Round  70, Train loss: 1.493, Test loss: 1.535, Test accuracy: 92.81
Round  71, Train loss: 1.492, Test loss: 1.535, Test accuracy: 92.81
Round  72, Train loss: 1.495, Test loss: 1.534, Test accuracy: 92.83
Round  73, Train loss: 1.495, Test loss: 1.534, Test accuracy: 92.94
Round  74, Train loss: 1.488, Test loss: 1.534, Test accuracy: 92.98
Round  75, Train loss: 1.488, Test loss: 1.534, Test accuracy: 93.06
Round  76, Train loss: 1.491, Test loss: 1.534, Test accuracy: 92.99
Round  77, Train loss: 1.493, Test loss: 1.533, Test accuracy: 93.01
Round  78, Train loss: 1.490, Test loss: 1.533, Test accuracy: 93.00
Round  79, Train loss: 1.488, Test loss: 1.534, Test accuracy: 92.97
Round  80, Train loss: 1.491, Test loss: 1.533, Test accuracy: 93.03
Round  81, Train loss: 1.487, Test loss: 1.533, Test accuracy: 93.02
Round  82, Train loss: 1.492, Test loss: 1.533, Test accuracy: 93.05
Round  83, Train loss: 1.489, Test loss: 1.533, Test accuracy: 93.02
Round  84, Train loss: 1.485, Test loss: 1.533, Test accuracy: 93.03
Round  85, Train loss: 1.495, Test loss: 1.533, Test accuracy: 93.01
Round  86, Train loss: 1.488, Test loss: 1.533, Test accuracy: 93.01
Round  87, Train loss: 1.488, Test loss: 1.532, Test accuracy: 93.13
Round  88, Train loss: 1.490, Test loss: 1.532, Test accuracy: 93.02
Round  89, Train loss: 1.489, Test loss: 1.532, Test accuracy: 93.03
Round  90, Train loss: 1.493, Test loss: 1.532, Test accuracy: 93.13
Round  91, Train loss: 1.488, Test loss: 1.531, Test accuracy: 93.15
Round  92, Train loss: 1.486, Test loss: 1.532, Test accuracy: 93.03
Round  93, Train loss: 1.490, Test loss: 1.531, Test accuracy: 93.18
Round  94, Train loss: 1.490, Test loss: 1.531, Test accuracy: 93.20
Round  95, Train loss: 1.486, Test loss: 1.531, Test accuracy: 93.23
Round  96, Train loss: 1.486, Test loss: 1.531, Test accuracy: 93.23
Round  97, Train loss: 1.488, Test loss: 1.530, Test accuracy: 93.30
Round  98, Train loss: 1.487, Test loss: 1.530, Test accuracy: 93.23/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  99, Train loss: 1.489, Test loss: 1.530, Test accuracy: 93.31
Final Round, Train loss: 1.485, Test loss: 1.530, Test accuracy: 93.30
Average accuracy final 10 rounds: 93.199 

2255.792654275894
[1.8827075958251953, 3.7654151916503906, 5.57317852973938, 7.380941867828369, 9.19786286354065, 11.01478385925293, 12.848543405532837, 14.682302951812744, 16.545608282089233, 18.408913612365723, 20.243564128875732, 22.078214645385742, 23.917928457260132, 25.75764226913452, 27.60248899459839, 29.447335720062256, 31.26759147644043, 33.0878472328186, 34.89922213554382, 36.71059703826904, 38.46985626220703, 40.22911548614502, 42.01841473579407, 43.807713985443115, 45.6992392539978, 47.59076452255249, 49.393144607543945, 51.1955246925354, 52.942896366119385, 54.69026803970337, 56.55122447013855, 58.41218090057373, 60.20360708236694, 61.995033264160156, 63.758564472198486, 65.52209568023682, 67.32644581794739, 69.13079595565796, 70.92306470870972, 72.71533346176147, 74.46405076980591, 76.21276807785034, 77.93150210380554, 79.65023612976074, 81.46450924873352, 83.2787823677063, 85.10510087013245, 86.9314193725586, 88.69612097740173, 90.46082258224487, 92.24873399734497, 94.03664541244507, 95.80620551109314, 97.57576560974121, 99.24201846122742, 100.90827131271362, 102.59338164329529, 104.27849197387695, 105.94097208976746, 107.60345220565796, 109.26700401306152, 110.93055582046509, 112.6162359714508, 114.30191612243652, 116.004065990448, 117.70621585845947, 119.31411290168762, 120.92200994491577, 122.52378702163696, 124.12556409835815, 125.91315603256226, 127.70074796676636, 129.55006551742554, 131.39938306808472, 133.12900376319885, 134.858624458313, 136.61345529556274, 138.3682861328125, 140.18715739250183, 142.00602865219116, 143.77439832687378, 145.5427680015564, 147.29057455062866, 149.03838109970093, 150.67734456062317, 152.3163080215454, 153.98852396011353, 155.66073989868164, 157.29239153862, 158.92404317855835, 160.57301926612854, 162.22199535369873, 163.84720420837402, 165.47241306304932, 167.0869333744049, 168.7014536857605, 170.38534951210022, 172.06924533843994, 173.74919772148132, 175.4291501045227, 177.0862922668457, 178.7434344291687, 180.41347336769104, 182.08351230621338, 183.72597789764404, 185.3684434890747, 186.94770169258118, 188.52695989608765, 190.11372900009155, 191.70049810409546, 193.32018041610718, 194.9398627281189, 196.56912779808044, 198.198392868042, 199.87433433532715, 201.5502758026123, 203.15781664848328, 204.76535749435425, 206.4040870666504, 208.04281663894653, 209.70743107795715, 211.37204551696777, 212.991051197052, 214.61005687713623, 216.3498866558075, 218.08971643447876, 219.8943736553192, 221.69903087615967, 223.523681640625, 225.34833240509033, 227.13679218292236, 228.9252519607544, 230.69049501419067, 232.45573806762695, 234.23567748069763, 236.0156168937683, 237.8379282951355, 239.66023969650269, 241.47369837760925, 243.28715705871582, 245.07902455329895, 246.87089204788208, 248.6646511554718, 250.45841026306152, 252.2619616985321, 254.06551313400269, 255.85645508766174, 257.6473970413208, 259.38943552970886, 261.1314740180969, 262.83954405784607, 264.5476140975952, 266.1328866481781, 267.718159198761, 269.36690974235535, 271.0156602859497, 272.63270592689514, 274.2497515678406, 275.91556429862976, 277.58137702941895, 279.2423315048218, 280.9032859802246, 282.5203046798706, 284.1373233795166, 285.7840657234192, 287.4308080673218, 289.0895380973816, 290.7482681274414, 292.37268137931824, 293.99709463119507, 295.6507430076599, 297.30439138412476, 298.96140360832214, 300.61841583251953, 302.2514374256134, 303.8844590187073, 305.51912093162537, 307.15378284454346, 308.8276631832123, 310.5015435218811, 312.14956188201904, 313.797580242157, 315.44440960884094, 317.0912389755249, 318.77160143852234, 320.4519639015198, 322.0677297115326, 323.6834955215454, 325.30708599090576, 326.9306764602661, 328.57029008865356, 330.209903717041, 331.8524737358093, 333.49504375457764, 335.13172245025635, 336.76840114593506, 338.4392650127411, 340.1101288795471, 341.79089164733887, 343.4716544151306, 345.01235246658325, 346.5530505180359]
[24.415, 24.415, 37.18, 37.18, 31.175, 31.175, 45.25, 45.25, 57.815, 57.815, 65.685, 65.685, 73.42, 73.42, 79.67, 79.67, 83.785, 83.785, 85.98, 85.98, 86.955, 86.955, 87.825, 87.825, 87.675, 87.675, 88.21, 88.21, 89.445, 89.445, 89.695, 89.695, 90.08, 90.08, 89.9, 89.9, 90.165, 90.165, 90.26, 90.26, 90.465, 90.465, 90.6, 90.6, 90.66, 90.66, 90.725, 90.725, 90.845, 90.845, 91.005, 91.005, 90.81, 90.81, 91.06, 91.06, 91.02, 91.02, 91.225, 91.225, 91.125, 91.125, 91.515, 91.515, 91.595, 91.595, 91.605, 91.605, 91.83, 91.83, 91.63, 91.63, 91.68, 91.68, 91.585, 91.585, 91.61, 91.61, 91.855, 91.855, 91.985, 91.985, 92.0, 92.0, 92.11, 92.11, 92.14, 92.14, 92.085, 92.085, 92.16, 92.16, 92.19, 92.19, 91.975, 91.975, 92.24, 92.24, 92.32, 92.32, 92.32, 92.32, 92.465, 92.465, 92.485, 92.485, 92.535, 92.535, 92.535, 92.535, 92.515, 92.515, 92.395, 92.395, 92.425, 92.425, 92.42, 92.42, 92.51, 92.51, 92.555, 92.555, 92.605, 92.605, 92.655, 92.655, 92.645, 92.645, 92.685, 92.685, 92.57, 92.57, 92.64, 92.64, 92.59, 92.59, 92.69, 92.69, 92.74, 92.74, 92.81, 92.81, 92.81, 92.81, 92.835, 92.835, 92.935, 92.935, 92.985, 92.985, 93.06, 93.06, 92.99, 92.99, 93.01, 93.01, 92.995, 92.995, 92.965, 92.965, 93.035, 93.035, 93.015, 93.015, 93.045, 93.045, 93.02, 93.02, 93.035, 93.035, 93.01, 93.01, 93.01, 93.01, 93.13, 93.13, 93.015, 93.015, 93.035, 93.035, 93.13, 93.13, 93.15, 93.15, 93.03, 93.03, 93.18, 93.18, 93.205, 93.205, 93.23, 93.23, 93.23, 93.23, 93.295, 93.295, 93.23, 93.23, 93.31, 93.31, 93.3, 93.3]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedper
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.298, Test loss: 2.293, Test accuracy: 35.68
Round   1, Train loss: 2.255, Test loss: 2.201, Test accuracy: 41.03
Round   2, Train loss: 2.045, Test loss: 1.914, Test accuracy: 62.76
Round   3, Train loss: 1.732, Test loss: 1.764, Test accuracy: 74.78
Round   4, Train loss: 1.648, Test loss: 1.659, Test accuracy: 82.78
Round   5, Train loss: 1.591, Test loss: 1.626, Test accuracy: 85.51
Round   6, Train loss: 1.573, Test loss: 1.612, Test accuracy: 86.22
Round   7, Train loss: 1.557, Test loss: 1.601, Test accuracy: 87.00
Round   8, Train loss: 1.550, Test loss: 1.586, Test accuracy: 88.29
Round   9, Train loss: 1.548, Test loss: 1.570, Test accuracy: 89.97
Round  10, Train loss: 1.535, Test loss: 1.566, Test accuracy: 90.24
Round  11, Train loss: 1.535, Test loss: 1.562, Test accuracy: 90.53
Round  12, Train loss: 1.529, Test loss: 1.560, Test accuracy: 90.77
Round  13, Train loss: 1.522, Test loss: 1.558, Test accuracy: 90.94
Round  14, Train loss: 1.523, Test loss: 1.556, Test accuracy: 91.05
Round  15, Train loss: 1.521, Test loss: 1.552, Test accuracy: 91.42
Round  16, Train loss: 1.515, Test loss: 1.550, Test accuracy: 91.67
Round  17, Train loss: 1.514, Test loss: 1.549, Test accuracy: 91.71
Round  18, Train loss: 1.509, Test loss: 1.548, Test accuracy: 91.72
Round  19, Train loss: 1.508, Test loss: 1.547, Test accuracy: 91.82
Round  20, Train loss: 1.504, Test loss: 1.546, Test accuracy: 91.97
Round  21, Train loss: 1.508, Test loss: 1.545, Test accuracy: 92.09
Round  22, Train loss: 1.507, Test loss: 1.543, Test accuracy: 92.17
Round  23, Train loss: 1.505, Test loss: 1.542, Test accuracy: 92.31
Round  24, Train loss: 1.498, Test loss: 1.540, Test accuracy: 92.42
Round  25, Train loss: 1.500, Test loss: 1.539, Test accuracy: 92.56
Round  26, Train loss: 1.500, Test loss: 1.538, Test accuracy: 92.56
Round  27, Train loss: 1.493, Test loss: 1.538, Test accuracy: 92.66
Round  28, Train loss: 1.501, Test loss: 1.537, Test accuracy: 92.72
Round  29, Train loss: 1.496, Test loss: 1.536, Test accuracy: 92.71
Round  30, Train loss: 1.495, Test loss: 1.535, Test accuracy: 92.86
Round  31, Train loss: 1.493, Test loss: 1.534, Test accuracy: 92.97
Round  32, Train loss: 1.495, Test loss: 1.534, Test accuracy: 93.11
Round  33, Train loss: 1.488, Test loss: 1.533, Test accuracy: 93.12
Round  34, Train loss: 1.496, Test loss: 1.532, Test accuracy: 93.20
Round  35, Train loss: 1.492, Test loss: 1.531, Test accuracy: 93.33
Round  36, Train loss: 1.495, Test loss: 1.530, Test accuracy: 93.36
Round  37, Train loss: 1.487, Test loss: 1.530, Test accuracy: 93.39
Round  38, Train loss: 1.486, Test loss: 1.530, Test accuracy: 93.41
Round  39, Train loss: 1.491, Test loss: 1.530, Test accuracy: 93.35
Round  40, Train loss: 1.490, Test loss: 1.529, Test accuracy: 93.37
Round  41, Train loss: 1.485, Test loss: 1.529, Test accuracy: 93.44
Round  42, Train loss: 1.486, Test loss: 1.529, Test accuracy: 93.44
Round  43, Train loss: 1.484, Test loss: 1.528, Test accuracy: 93.54
Round  44, Train loss: 1.486, Test loss: 1.528, Test accuracy: 93.60
Round  45, Train loss: 1.485, Test loss: 1.528, Test accuracy: 93.62
Round  46, Train loss: 1.484, Test loss: 1.527, Test accuracy: 93.62
Round  47, Train loss: 1.486, Test loss: 1.527, Test accuracy: 93.65
Round  48, Train loss: 1.489, Test loss: 1.526, Test accuracy: 93.75
Round  49, Train loss: 1.480, Test loss: 1.526, Test accuracy: 93.65
Round  50, Train loss: 1.483, Test loss: 1.526, Test accuracy: 93.73
Round  51, Train loss: 1.484, Test loss: 1.526, Test accuracy: 93.70
Round  52, Train loss: 1.488, Test loss: 1.526, Test accuracy: 93.78
Round  53, Train loss: 1.486, Test loss: 1.525, Test accuracy: 93.88
Round  54, Train loss: 1.486, Test loss: 1.525, Test accuracy: 93.83
Round  55, Train loss: 1.479, Test loss: 1.525, Test accuracy: 93.78
Round  56, Train loss: 1.484, Test loss: 1.525, Test accuracy: 93.80
Round  57, Train loss: 1.486, Test loss: 1.525, Test accuracy: 93.84
Round  58, Train loss: 1.486, Test loss: 1.524, Test accuracy: 93.94
Round  59, Train loss: 1.482, Test loss: 1.524, Test accuracy: 93.97
Round  60, Train loss: 1.481, Test loss: 1.523, Test accuracy: 93.95
Round  61, Train loss: 1.481, Test loss: 1.524, Test accuracy: 93.94
Round  62, Train loss: 1.483, Test loss: 1.524, Test accuracy: 93.91
Round  63, Train loss: 1.481, Test loss: 1.523, Test accuracy: 93.88
Round  64, Train loss: 1.481, Test loss: 1.523, Test accuracy: 93.94
Round  65, Train loss: 1.485, Test loss: 1.523, Test accuracy: 93.96
Round  66, Train loss: 1.480, Test loss: 1.523, Test accuracy: 93.89
Round  67, Train loss: 1.482, Test loss: 1.523, Test accuracy: 93.92
Round  68, Train loss: 1.483, Test loss: 1.523, Test accuracy: 93.94
Round  69, Train loss: 1.481, Test loss: 1.522, Test accuracy: 93.99
Round  70, Train loss: 1.479, Test loss: 1.522, Test accuracy: 94.01
Round  71, Train loss: 1.480, Test loss: 1.522, Test accuracy: 94.01
Round  72, Train loss: 1.485, Test loss: 1.522, Test accuracy: 93.94
Round  73, Train loss: 1.480, Test loss: 1.522, Test accuracy: 94.03
Round  74, Train loss: 1.481, Test loss: 1.522, Test accuracy: 94.03
Round  75, Train loss: 1.481, Test loss: 1.522, Test accuracy: 94.04
Round  76, Train loss: 1.478, Test loss: 1.522, Test accuracy: 94.09
Round  77, Train loss: 1.479, Test loss: 1.522, Test accuracy: 94.01
Round  78, Train loss: 1.480, Test loss: 1.522, Test accuracy: 94.02
Round  79, Train loss: 1.481, Test loss: 1.522, Test accuracy: 94.07
Round  80, Train loss: 1.483, Test loss: 1.522, Test accuracy: 94.07
Round  81, Train loss: 1.476, Test loss: 1.521, Test accuracy: 94.15
Round  82, Train loss: 1.475, Test loss: 1.521, Test accuracy: 94.17
Round  83, Train loss: 1.477, Test loss: 1.521, Test accuracy: 94.16
Round  84, Train loss: 1.477, Test loss: 1.521, Test accuracy: 94.12
Round  85, Train loss: 1.478, Test loss: 1.521, Test accuracy: 94.16
Round  86, Train loss: 1.475, Test loss: 1.520, Test accuracy: 94.21
Round  87, Train loss: 1.477, Test loss: 1.521, Test accuracy: 94.17
Round  88, Train loss: 1.478, Test loss: 1.521, Test accuracy: 94.16
Round  89, Train loss: 1.477, Test loss: 1.521, Test accuracy: 94.12
Round  90, Train loss: 1.479, Test loss: 1.521, Test accuracy: 94.19
Round  91, Train loss: 1.478, Test loss: 1.521, Test accuracy: 94.13
Round  92, Train loss: 1.477, Test loss: 1.521, Test accuracy: 94.21
Round  93, Train loss: 1.477, Test loss: 1.520, Test accuracy: 94.20
Round  94, Train loss: 1.479, Test loss: 1.520, Test accuracy: 94.20
Round  95, Train loss: 1.478, Test loss: 1.520, Test accuracy: 94.16
Round  96, Train loss: 1.481, Test loss: 1.520, Test accuracy: 94.22
Round  97, Train loss: 1.476, Test loss: 1.520, Test accuracy: 94.22
Round  98, Train loss: 1.478, Test loss: 1.520, Test accuracy: 94.22/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  99, Train loss: 1.477, Test loss: 1.520, Test accuracy: 94.26
Final Round, Train loss: 1.478, Test loss: 1.521, Test accuracy: 94.15
Average accuracy final 10 rounds: 94.202 

2270.638415336609
[2.073667049407959, 4.147334098815918, 6.117791414260864, 8.08824872970581, 10.047679662704468, 12.007110595703125, 13.941454648971558, 15.87579870223999, 17.80206036567688, 19.72832202911377, 21.690807342529297, 23.653292655944824, 25.63025689125061, 27.607221126556396, 29.54704523086548, 31.48686933517456, 33.438469886779785, 35.39007043838501, 37.34103727340698, 39.292004108428955, 41.246960163116455, 43.201916217803955, 45.162720680236816, 47.12352514266968, 49.0603289604187, 50.997132778167725, 52.95611548423767, 54.91509819030762, 56.85408091545105, 58.79306364059448, 60.75438404083252, 62.71570444107056, 64.61184692382812, 66.5079894065857, 68.46077013015747, 70.41355085372925, 72.15155982971191, 73.88956880569458, 75.56779837608337, 77.24602794647217, 78.96412777900696, 80.68222761154175, 82.43958878517151, 84.19694995880127, 85.93965816497803, 87.68236637115479, 89.39821600914001, 91.11406564712524, 92.78106760978699, 94.44806957244873, 96.13883256912231, 97.8295955657959, 99.46438670158386, 101.09917783737183, 102.79051995277405, 104.48186206817627, 106.21096181869507, 107.94006156921387, 109.66033029556274, 111.38059902191162, 113.13114428520203, 114.88168954849243, 116.59542059898376, 118.3091516494751, 120.03573036193848, 121.76230907440186, 123.51274871826172, 125.26318836212158, 126.9885482788086, 128.7139081954956, 130.4001269340515, 132.08634567260742, 133.76984858512878, 135.45335149765015, 137.13713192939758, 138.82091236114502, 140.56211924552917, 142.30332612991333, 144.04763388633728, 145.79194164276123, 147.52296662330627, 149.25399160385132, 150.9533588886261, 152.65272617340088, 154.38571214675903, 156.1186981201172, 157.83520436286926, 159.55171060562134, 161.23245573043823, 162.91320085525513, 164.63645339012146, 166.3597059249878, 168.0944788455963, 169.82925176620483, 171.56784534454346, 173.30643892288208, 175.00365233421326, 176.70086574554443, 178.45180797576904, 180.20275020599365, 181.8583950996399, 183.51403999328613, 185.19569325447083, 186.87734651565552, 188.6655149459839, 190.45368337631226, 192.2351472377777, 194.01661109924316, 195.7765233516693, 197.53643560409546, 199.1810178756714, 200.82560014724731, 202.52956676483154, 204.23353338241577, 205.80660033226013, 207.3796672821045, 209.06489157676697, 210.75011587142944, 212.444673538208, 214.13923120498657, 215.8493766784668, 217.55952215194702, 219.2749969959259, 220.99047183990479, 222.68837356567383, 224.38627529144287, 226.00525641441345, 227.62423753738403, 229.19692945480347, 230.7696213722229, 232.48711037635803, 234.20459938049316, 235.88443422317505, 237.56426906585693, 239.23668384552002, 240.9090986251831, 242.545414686203, 244.1817307472229, 245.84585785865784, 247.50998497009277, 249.24280762672424, 250.9756302833557, 252.59618592262268, 254.21674156188965, 255.8558783531189, 257.49501514434814, 259.16912627220154, 260.84323740005493, 262.5417728424072, 264.2403082847595, 265.94650959968567, 267.6527109146118, 269.33071303367615, 271.0087151527405, 272.6528205871582, 274.2969260215759, 275.89709091186523, 277.49725580215454, 279.1458897590637, 280.7945237159729, 282.4646825790405, 284.13484144210815, 285.8227961063385, 287.51075077056885, 289.16206550598145, 290.81338024139404, 292.43976402282715, 294.06614780426025, 295.71111035346985, 297.35607290267944, 299.03069829940796, 300.7053236961365, 302.4070384502411, 304.1087532043457, 305.8156101703644, 307.52246713638306, 309.2304437160492, 310.93842029571533, 312.8512713909149, 314.7641224861145, 316.63819551467896, 318.5122685432434, 320.3847358226776, 322.2572031021118, 324.09758281707764, 325.93796253204346, 327.8452911376953, 329.75261974334717, 331.6557967662811, 333.5589737892151, 335.4781038761139, 337.3972339630127, 339.32319164276123, 341.24914932250977, 343.1758828163147, 345.10261631011963, 347.0271911621094, 348.9517660140991, 350.65776348114014, 352.36376094818115, 353.95664167404175, 355.54952239990234]
[35.68, 35.68, 41.035, 41.035, 62.76, 62.76, 74.78, 74.78, 82.78, 82.78, 85.51, 85.51, 86.22, 86.22, 87.005, 87.005, 88.29, 88.29, 89.965, 89.965, 90.24, 90.24, 90.53, 90.53, 90.77, 90.77, 90.94, 90.94, 91.045, 91.045, 91.415, 91.415, 91.675, 91.675, 91.71, 91.71, 91.715, 91.715, 91.82, 91.82, 91.97, 91.97, 92.095, 92.095, 92.165, 92.165, 92.315, 92.315, 92.425, 92.425, 92.565, 92.565, 92.56, 92.56, 92.66, 92.66, 92.725, 92.725, 92.71, 92.71, 92.855, 92.855, 92.965, 92.965, 93.105, 93.105, 93.12, 93.12, 93.205, 93.205, 93.33, 93.33, 93.36, 93.36, 93.395, 93.395, 93.405, 93.405, 93.35, 93.35, 93.37, 93.37, 93.435, 93.435, 93.44, 93.44, 93.54, 93.54, 93.6, 93.6, 93.62, 93.62, 93.625, 93.625, 93.65, 93.65, 93.745, 93.745, 93.65, 93.65, 93.73, 93.73, 93.705, 93.705, 93.785, 93.785, 93.88, 93.88, 93.825, 93.825, 93.785, 93.785, 93.795, 93.795, 93.845, 93.845, 93.94, 93.94, 93.965, 93.965, 93.955, 93.955, 93.94, 93.94, 93.91, 93.91, 93.88, 93.88, 93.935, 93.935, 93.96, 93.96, 93.885, 93.885, 93.925, 93.925, 93.935, 93.935, 93.99, 93.99, 94.01, 94.01, 94.01, 94.01, 93.94, 93.94, 94.03, 94.03, 94.025, 94.025, 94.04, 94.04, 94.095, 94.095, 94.01, 94.01, 94.015, 94.015, 94.07, 94.07, 94.07, 94.07, 94.15, 94.15, 94.165, 94.165, 94.155, 94.155, 94.12, 94.12, 94.16, 94.16, 94.21, 94.21, 94.165, 94.165, 94.155, 94.155, 94.125, 94.125, 94.19, 94.19, 94.13, 94.13, 94.21, 94.21, 94.2, 94.2, 94.2, 94.2, 94.16, 94.16, 94.225, 94.225, 94.22, 94.22, 94.225, 94.225, 94.26, 94.26, 94.15, 94.15]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

lg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 17098 (global); Percentage 3.11 (17098/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.300, Test loss: 2.295, Test accuracy: 31.77
Round   1, Train loss: 2.270, Test loss: 2.230, Test accuracy: 32.97
Round   2, Train loss: 2.111, Test loss: 1.997, Test accuracy: 64.11
Round   3, Train loss: 1.820, Test loss: 1.828, Test accuracy: 71.66
Round   4, Train loss: 1.720, Test loss: 1.737, Test accuracy: 76.96
Round   5, Train loss: 1.652, Test loss: 1.718, Test accuracy: 77.97
Round   6, Train loss: 1.639, Test loss: 1.698, Test accuracy: 78.89
Round   7, Train loss: 1.622, Test loss: 1.690, Test accuracy: 79.33
Round   8, Train loss: 1.641, Test loss: 1.668, Test accuracy: 80.32
Round   9, Train loss: 1.610, Test loss: 1.665, Test accuracy: 80.36
Round  10, Train loss: 1.613, Test loss: 1.665, Test accuracy: 80.19
Round  11, Train loss: 1.597, Test loss: 1.663, Test accuracy: 80.26
Round  12, Train loss: 1.593, Test loss: 1.663, Test accuracy: 80.19
Round  13, Train loss: 1.594, Test loss: 1.662, Test accuracy: 80.26
Round  14, Train loss: 1.589, Test loss: 1.662, Test accuracy: 80.25
Round  15, Train loss: 1.598, Test loss: 1.661, Test accuracy: 80.39
Round  16, Train loss: 1.591, Test loss: 1.660, Test accuracy: 80.42
Round  17, Train loss: 1.587, Test loss: 1.660, Test accuracy: 80.35
Round  18, Train loss: 1.586, Test loss: 1.660, Test accuracy: 80.39
Round  19, Train loss: 1.583, Test loss: 1.660, Test accuracy: 80.34
Round  20, Train loss: 1.581, Test loss: 1.659, Test accuracy: 80.44
Round  21, Train loss: 1.586, Test loss: 1.659, Test accuracy: 80.38
Round  22, Train loss: 1.578, Test loss: 1.659, Test accuracy: 80.42
Round  23, Train loss: 1.582, Test loss: 1.659, Test accuracy: 80.44
Round  24, Train loss: 1.586, Test loss: 1.659, Test accuracy: 80.42
Round  25, Train loss: 1.582, Test loss: 1.658, Test accuracy: 80.42
Round  26, Train loss: 1.584, Test loss: 1.658, Test accuracy: 80.55
Round  27, Train loss: 1.579, Test loss: 1.657, Test accuracy: 80.54
Round  28, Train loss: 1.586, Test loss: 1.657, Test accuracy: 80.58
Round  29, Train loss: 1.578, Test loss: 1.657, Test accuracy: 80.55
Round  30, Train loss: 1.585, Test loss: 1.657, Test accuracy: 80.63
Round  31, Train loss: 1.580, Test loss: 1.657, Test accuracy: 80.63
Round  32, Train loss: 1.585, Test loss: 1.657, Test accuracy: 80.66
Round  33, Train loss: 1.583, Test loss: 1.656, Test accuracy: 80.72
Round  34, Train loss: 1.584, Test loss: 1.656, Test accuracy: 80.69
Round  35, Train loss: 1.579, Test loss: 1.656, Test accuracy: 80.75
Round  36, Train loss: 1.582, Test loss: 1.656, Test accuracy: 80.72
Round  37, Train loss: 1.582, Test loss: 1.657, Test accuracy: 80.61
Round  38, Train loss: 1.577, Test loss: 1.657, Test accuracy: 80.58
Round  39, Train loss: 1.580, Test loss: 1.657, Test accuracy: 80.57
Round  40, Train loss: 1.576, Test loss: 1.657, Test accuracy: 80.56
Round  41, Train loss: 1.574, Test loss: 1.657, Test accuracy: 80.55
Round  42, Train loss: 1.577, Test loss: 1.657, Test accuracy: 80.53
Round  43, Train loss: 1.576, Test loss: 1.657, Test accuracy: 80.56
Round  44, Train loss: 1.578, Test loss: 1.657, Test accuracy: 80.59
Round  45, Train loss: 1.576, Test loss: 1.657, Test accuracy: 80.58
Round  46, Train loss: 1.578, Test loss: 1.656, Test accuracy: 80.58
Round  47, Train loss: 1.574, Test loss: 1.656, Test accuracy: 80.64
Round  48, Train loss: 1.576, Test loss: 1.656, Test accuracy: 80.62
Round  49, Train loss: 1.576, Test loss: 1.656, Test accuracy: 80.61
Round  50, Train loss: 1.573, Test loss: 1.656, Test accuracy: 80.60
Round  51, Train loss: 1.574, Test loss: 1.656, Test accuracy: 80.61
Round  52, Train loss: 1.576, Test loss: 1.656, Test accuracy: 80.63
Round  53, Train loss: 1.573, Test loss: 1.656, Test accuracy: 80.62
Round  54, Train loss: 1.573, Test loss: 1.656, Test accuracy: 80.66
Round  55, Train loss: 1.574, Test loss: 1.656, Test accuracy: 80.66
Round  56, Train loss: 1.575, Test loss: 1.656, Test accuracy: 80.67
Round  57, Train loss: 1.575, Test loss: 1.656, Test accuracy: 80.67
Round  58, Train loss: 1.575, Test loss: 1.656, Test accuracy: 80.64
Round  59, Train loss: 1.578, Test loss: 1.656, Test accuracy: 80.67
Round  60, Train loss: 1.572, Test loss: 1.656, Test accuracy: 80.66
Round  61, Train loss: 1.575, Test loss: 1.656, Test accuracy: 80.71
Round  62, Train loss: 1.573, Test loss: 1.655, Test accuracy: 80.72
Round  63, Train loss: 1.579, Test loss: 1.655, Test accuracy: 80.70
Round  64, Train loss: 1.574, Test loss: 1.655, Test accuracy: 80.72
Round  65, Train loss: 1.572, Test loss: 1.655, Test accuracy: 80.72
Round  66, Train loss: 1.577, Test loss: 1.655, Test accuracy: 80.73
Round  67, Train loss: 1.573, Test loss: 1.655, Test accuracy: 80.73
Round  68, Train loss: 1.572, Test loss: 1.655, Test accuracy: 80.75
Round  69, Train loss: 1.574, Test loss: 1.655, Test accuracy: 80.73
Round  70, Train loss: 1.574, Test loss: 1.655, Test accuracy: 80.76
Round  71, Train loss: 1.576, Test loss: 1.655, Test accuracy: 80.72
Round  72, Train loss: 1.574, Test loss: 1.655, Test accuracy: 80.72
Round  73, Train loss: 1.576, Test loss: 1.655, Test accuracy: 80.72
Round  74, Train loss: 1.572, Test loss: 1.655, Test accuracy: 80.76
Round  75, Train loss: 1.576, Test loss: 1.655, Test accuracy: 80.73
Round  76, Train loss: 1.571, Test loss: 1.655, Test accuracy: 80.77
Round  77, Train loss: 1.571, Test loss: 1.655, Test accuracy: 80.77
Round  78, Train loss: 1.576, Test loss: 1.655, Test accuracy: 80.75
Round  79, Train loss: 1.571, Test loss: 1.655, Test accuracy: 80.74
Round  80, Train loss: 1.573, Test loss: 1.655, Test accuracy: 80.75
Round  81, Train loss: 1.573, Test loss: 1.655, Test accuracy: 80.74
Round  82, Train loss: 1.575, Test loss: 1.655, Test accuracy: 80.77
Round  83, Train loss: 1.571, Test loss: 1.655, Test accuracy: 80.75
Round  84, Train loss: 1.573, Test loss: 1.655, Test accuracy: 80.77
Round  85, Train loss: 1.572, Test loss: 1.655, Test accuracy: 80.72
Round  86, Train loss: 1.571, Test loss: 1.655, Test accuracy: 80.75
Round  87, Train loss: 1.573, Test loss: 1.655, Test accuracy: 80.75
Round  88, Train loss: 1.572, Test loss: 1.655, Test accuracy: 80.76
Round  89, Train loss: 1.573, Test loss: 1.655, Test accuracy: 80.76
Round  90, Train loss: 1.573, Test loss: 1.655, Test accuracy: 80.77
Round  91, Train loss: 1.572, Test loss: 1.655, Test accuracy: 80.72
Round  92, Train loss: 1.571, Test loss: 1.655, Test accuracy: 80.72
Round  93, Train loss: 1.573, Test loss: 1.655, Test accuracy: 80.72
Round  94, Train loss: 1.573, Test loss: 1.655, Test accuracy: 80.72
Round  95, Train loss: 1.571, Test loss: 1.655, Test accuracy: 80.72
Round  96, Train loss: 1.572, Test loss: 1.655, Test accuracy: 80.72
Round  97, Train loss: 1.571, Test loss: 1.655, Test accuracy: 80.74
Round  98, Train loss: 1.572, Test loss: 1.655, Test accuracy: 80.75
Round  99, Train loss: 1.574, Test loss: 1.655, Test accuracy: 80.74/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Final Round, Train loss: 1.573, Test loss: 1.655, Test accuracy: 80.70
Average accuracy final 10 rounds: 80.732 

2262.7407932281494
[1.9902732372283936, 3.980546474456787, 5.648498773574829, 7.316451072692871, 9.147616386413574, 10.978781700134277, 12.851006984710693, 14.72323226928711, 16.65095090866089, 18.578669548034668, 20.520677089691162, 22.462684631347656, 24.345733165740967, 26.228781700134277, 28.112011671066284, 29.99524164199829, 31.802502870559692, 33.609764099121094, 35.2616171836853, 36.91347026824951, 38.65572810173035, 40.39798593521118, 42.075523853302, 43.75306177139282, 45.40030097961426, 47.04754018783569, 48.75127410888672, 50.455008029937744, 52.10890221595764, 53.76279640197754, 55.39310646057129, 57.02341651916504, 58.670037269592285, 60.31665802001953, 61.98276233673096, 63.64886665344238, 65.30073618888855, 66.95260572433472, 68.675852060318, 70.39909839630127, 72.11919093132019, 73.83928346633911, 75.56316709518433, 77.28705072402954, 78.97764563560486, 80.66824054718018, 82.34688258171082, 84.02552461624146, 85.7072479724884, 87.38897132873535, 89.12503123283386, 90.86109113693237, 92.5461356639862, 94.23118019104004, 95.98705172538757, 97.74292325973511, 99.56157541275024, 101.38022756576538, 103.19176721572876, 105.00330686569214, 106.70158362388611, 108.39986038208008, 110.09199094772339, 111.7841215133667, 113.48455715179443, 115.18499279022217, 116.87060475349426, 118.55621671676636, 120.24066376686096, 121.92511081695557, 123.70640659332275, 125.48770236968994, 127.27301526069641, 129.05832815170288, 130.84674286842346, 132.63515758514404, 134.42233848571777, 136.2095193862915, 137.92776560783386, 139.64601182937622, 141.34417080879211, 143.042329788208, 144.7756462097168, 146.5089626312256, 148.2165400981903, 149.92411756515503, 151.62008118629456, 153.31604480743408, 155.15260577201843, 156.98916673660278, 158.81740617752075, 160.64564561843872, 162.40329122543335, 164.16093683242798, 165.93216252326965, 167.70338821411133, 169.37747645378113, 171.05156469345093, 172.71948051452637, 174.3873963356018, 176.12434840202332, 177.86130046844482, 179.59149956703186, 181.3216986656189, 183.0303566455841, 184.73901462554932, 186.5697524547577, 188.40049028396606, 190.17895078659058, 191.9574112892151, 193.72782015800476, 195.49822902679443, 197.1661033630371, 198.83397769927979, 200.54659366607666, 202.25920963287354, 203.98265838623047, 205.7061071395874, 207.41609358787537, 209.12608003616333, 210.95642471313477, 212.7867693901062, 214.46507740020752, 216.14338541030884, 217.80497288703918, 219.46656036376953, 221.1614363193512, 222.85631227493286, 224.62034559249878, 226.3843789100647, 228.05588126182556, 229.72738361358643, 231.41953015327454, 233.11167669296265, 234.85961627960205, 236.60755586624146, 238.26977610588074, 239.93199634552002, 241.72998046875, 243.52796459197998, 245.31095242500305, 247.09394025802612, 248.84201550483704, 250.59009075164795, 252.35877108573914, 254.12745141983032, 255.96301341056824, 257.79857540130615, 259.51610231399536, 261.23362922668457, 262.9079225063324, 264.5822157859802, 266.30978655815125, 268.03735733032227, 269.73131489753723, 271.4252724647522, 273.0620656013489, 274.69885873794556, 276.3664309978485, 278.03400325775146, 279.68311858177185, 281.33223390579224, 283.0323255062103, 284.7324171066284, 286.4507465362549, 288.16907596588135, 289.86211347579956, 291.5551509857178, 293.2569420337677, 294.9587330818176, 296.6236128807068, 298.28849267959595, 299.98983573913574, 301.69117879867554, 303.3328504562378, 304.97452211380005, 306.7448539733887, 308.5151858329773, 310.21578001976013, 311.91637420654297, 313.5687041282654, 315.2210340499878, 316.9616811275482, 318.70232820510864, 320.4401972293854, 322.1780662536621, 323.82568430900574, 325.47330236434937, 327.1882565021515, 328.9032106399536, 330.57935404777527, 332.2554974555969, 333.9356219768524, 335.6157464981079, 337.4182143211365, 339.22068214416504, 340.99474358558655, 342.76880502700806, 344.4488949775696, 346.1289849281311, 347.85934233665466, 349.5896997451782]
[31.775, 31.775, 32.97, 32.97, 64.11, 64.11, 71.66, 71.66, 76.96, 76.96, 77.97, 77.97, 78.89, 78.89, 79.325, 79.325, 80.32, 80.32, 80.365, 80.365, 80.185, 80.185, 80.26, 80.26, 80.195, 80.195, 80.26, 80.26, 80.25, 80.25, 80.385, 80.385, 80.425, 80.425, 80.35, 80.35, 80.395, 80.395, 80.34, 80.34, 80.44, 80.44, 80.375, 80.375, 80.425, 80.425, 80.445, 80.445, 80.42, 80.42, 80.42, 80.42, 80.545, 80.545, 80.54, 80.54, 80.585, 80.585, 80.545, 80.545, 80.63, 80.63, 80.63, 80.63, 80.655, 80.655, 80.715, 80.715, 80.695, 80.695, 80.75, 80.75, 80.72, 80.72, 80.61, 80.61, 80.575, 80.575, 80.57, 80.57, 80.565, 80.565, 80.55, 80.55, 80.53, 80.53, 80.56, 80.56, 80.59, 80.59, 80.585, 80.585, 80.585, 80.585, 80.635, 80.635, 80.62, 80.62, 80.61, 80.61, 80.6, 80.6, 80.61, 80.61, 80.63, 80.63, 80.625, 80.625, 80.655, 80.655, 80.66, 80.66, 80.665, 80.665, 80.665, 80.665, 80.635, 80.635, 80.67, 80.67, 80.66, 80.66, 80.71, 80.71, 80.715, 80.715, 80.705, 80.705, 80.715, 80.715, 80.715, 80.715, 80.735, 80.735, 80.735, 80.735, 80.75, 80.75, 80.73, 80.73, 80.76, 80.76, 80.72, 80.72, 80.72, 80.72, 80.715, 80.715, 80.76, 80.76, 80.735, 80.735, 80.77, 80.77, 80.77, 80.77, 80.755, 80.755, 80.74, 80.74, 80.75, 80.75, 80.74, 80.74, 80.77, 80.77, 80.75, 80.75, 80.765, 80.765, 80.725, 80.725, 80.75, 80.75, 80.755, 80.755, 80.76, 80.76, 80.76, 80.76, 80.765, 80.765, 80.72, 80.72, 80.715, 80.715, 80.725, 80.725, 80.72, 80.72, 80.72, 80.72, 80.725, 80.725, 80.74, 80.74, 80.75, 80.75, 80.74, 80.74, 80.7, 80.7]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
Round   0, Train loss: 1.670, Test loss: 2.261, Test accuracy: 32.34
Round   1, Train loss: 1.445, Test loss: 2.082, Test accuracy: 59.16
Round   2, Train loss: 1.306, Test loss: 1.926, Test accuracy: 69.44
Round   3, Train loss: 1.281, Test loss: 1.895, Test accuracy: 71.67
Round   4, Train loss: 1.277, Test loss: 1.883, Test accuracy: 72.29
Round   5, Train loss: 1.263, Test loss: 1.869, Test accuracy: 74.38
Round   6, Train loss: 1.225, Test loss: 1.848, Test accuracy: 76.86
Round   7, Train loss: 1.178, Test loss: 1.827, Test accuracy: 80.38
Round   8, Train loss: 1.153, Test loss: 1.813, Test accuracy: 83.02
Round   9, Train loss: 1.142, Test loss: 1.803, Test accuracy: 84.05
Round  10, Train loss: 1.139, Test loss: 1.796, Test accuracy: 84.77
Round  11, Train loss: 1.133, Test loss: 1.789, Test accuracy: 85.00
Round  12, Train loss: 1.131, Test loss: 1.784, Test accuracy: 85.50
Round  13, Train loss: 1.126, Test loss: 1.783, Test accuracy: 85.04
Round  14, Train loss: 1.126, Test loss: 1.778, Test accuracy: 85.59
Round  15, Train loss: 1.128, Test loss: 1.775, Test accuracy: 85.52
Round  16, Train loss: 1.122, Test loss: 1.774, Test accuracy: 85.33
Round  17, Train loss: 1.124, Test loss: 1.771, Test accuracy: 85.66
Round  18, Train loss: 1.121, Test loss: 1.771, Test accuracy: 86.17
Round  19, Train loss: 1.113, Test loss: 1.771, Test accuracy: 85.88
Round  20, Train loss: 1.121, Test loss: 1.769, Test accuracy: 85.79
Round  21, Train loss: 1.114, Test loss: 1.769, Test accuracy: 85.56
Round  22, Train loss: 1.112, Test loss: 1.769, Test accuracy: 85.25
Round  23, Train loss: 1.117, Test loss: 1.769, Test accuracy: 85.14
Round  24, Train loss: 1.115, Test loss: 1.770, Test accuracy: 84.84
Round  25, Train loss: 1.116, Test loss: 1.771, Test accuracy: 84.69
Round  26, Train loss: 1.112, Test loss: 1.772, Test accuracy: 84.41
Round  27, Train loss: 1.110, Test loss: 1.772, Test accuracy: 84.36
Round  28, Train loss: 1.115, Test loss: 1.772, Test accuracy: 84.17
Round  29, Train loss: 1.111, Test loss: 1.770, Test accuracy: 84.03
Round  30, Train loss: 1.111, Test loss: 1.772, Test accuracy: 83.84
Round  31, Train loss: 1.110, Test loss: 1.773, Test accuracy: 83.49
Round  32, Train loss: 1.114, Test loss: 1.772, Test accuracy: 83.59
Round  33, Train loss: 1.110, Test loss: 1.775, Test accuracy: 83.09
Round  34, Train loss: 1.110, Test loss: 1.775, Test accuracy: 82.93
Round  35, Train loss: 1.110, Test loss: 1.775, Test accuracy: 82.81
Round  36, Train loss: 1.111, Test loss: 1.776, Test accuracy: 82.44
Round  37, Train loss: 1.109, Test loss: 1.778, Test accuracy: 82.38
Round  38, Train loss: 1.110, Test loss: 1.777, Test accuracy: 82.15
Round  39, Train loss: 1.108, Test loss: 1.779, Test accuracy: 81.83
Round  40, Train loss: 1.110, Test loss: 1.779, Test accuracy: 81.67
Round  41, Train loss: 1.108, Test loss: 1.779, Test accuracy: 81.66
Round  42, Train loss: 1.108, Test loss: 1.781, Test accuracy: 81.31
Round  43, Train loss: 1.106, Test loss: 1.781, Test accuracy: 81.27
Round  44, Train loss: 1.106, Test loss: 1.782, Test accuracy: 81.12
Round  45, Train loss: 1.108, Test loss: 1.782, Test accuracy: 80.86
Round  46, Train loss: 1.105, Test loss: 1.783, Test accuracy: 80.70
Round  47, Train loss: 1.105, Test loss: 1.783, Test accuracy: 80.52
Round  48, Train loss: 1.104, Test loss: 1.784, Test accuracy: 80.43
Round  49, Train loss: 1.107, Test loss: 1.784, Test accuracy: 80.46
Round  50, Train loss: 1.108, Test loss: 1.785, Test accuracy: 80.23
Round  51, Train loss: 1.109, Test loss: 1.787, Test accuracy: 80.00
Round  52, Train loss: 1.107, Test loss: 1.788, Test accuracy: 79.83
Round  53, Train loss: 1.107, Test loss: 1.789, Test accuracy: 79.72
Round  54, Train loss: 1.106, Test loss: 1.789, Test accuracy: 79.55
Round  55, Train loss: 1.105, Test loss: 1.790, Test accuracy: 79.38
Round  56, Train loss: 1.106, Test loss: 1.790, Test accuracy: 79.31
Round  57, Train loss: 1.107, Test loss: 1.791, Test accuracy: 79.25
Round  58, Train loss: 1.107, Test loss: 1.792, Test accuracy: 79.08
Round  59, Train loss: 1.107, Test loss: 1.793, Test accuracy: 78.94
Round  60, Train loss: 1.106, Test loss: 1.793, Test accuracy: 78.91
Round  61, Train loss: 1.107, Test loss: 1.794, Test accuracy: 78.78
Round  62, Train loss: 1.109, Test loss: 1.796, Test accuracy: 78.57
Round  63, Train loss: 1.106, Test loss: 1.795, Test accuracy: 78.55
Round  64, Train loss: 1.106, Test loss: 1.797, Test accuracy: 78.46
Round  65, Train loss: 1.106, Test loss: 1.797, Test accuracy: 78.39
Round  66, Train loss: 1.107, Test loss: 1.798, Test accuracy: 78.24
Round  67, Train loss: 1.106, Test loss: 1.798, Test accuracy: 78.03
Round  68, Train loss: 1.104, Test loss: 1.798, Test accuracy: 77.91
Round  69, Train loss: 1.105, Test loss: 1.800, Test accuracy: 77.75
Round  70, Train loss: 1.107, Test loss: 1.800, Test accuracy: 77.63
Round  71, Train loss: 1.104, Test loss: 1.800, Test accuracy: 77.55
Round  72, Train loss: 1.103, Test loss: 1.801, Test accuracy: 77.45
Round  73, Train loss: 1.108, Test loss: 1.802, Test accuracy: 77.39
Round  74, Train loss: 1.105, Test loss: 1.802, Test accuracy: 77.36
Round  75, Train loss: 1.105, Test loss: 1.802, Test accuracy: 77.25
Round  76, Train loss: 1.105, Test loss: 1.802, Test accuracy: 77.18
Round  77, Train loss: 1.105, Test loss: 1.803, Test accuracy: 77.05
Round  78, Train loss: 1.102, Test loss: 1.804, Test accuracy: 76.97
Round  79, Train loss: 1.105, Test loss: 1.806, Test accuracy: 76.81
Round  80, Train loss: 1.104, Test loss: 1.807, Test accuracy: 76.60
Round  81, Train loss: 1.102, Test loss: 1.807, Test accuracy: 76.55
Round  82, Train loss: 1.103, Test loss: 1.807, Test accuracy: 76.59
Round  83, Train loss: 1.106, Test loss: 1.808, Test accuracy: 76.38
Round  84, Train loss: 1.103, Test loss: 1.807, Test accuracy: 76.36
Round  85, Train loss: 1.106, Test loss: 1.808, Test accuracy: 76.32
Round  86, Train loss: 1.106, Test loss: 1.809, Test accuracy: 76.31
Round  87, Train loss: 1.103, Test loss: 1.810, Test accuracy: 76.17
Round  88, Train loss: 1.103, Test loss: 1.809, Test accuracy: 76.30
Round  89, Train loss: 1.102, Test loss: 1.810, Test accuracy: 76.12
Round  90, Train loss: 1.103, Test loss: 1.810, Test accuracy: 76.19
Round  91, Train loss: 1.106, Test loss: 1.810, Test accuracy: 76.03
Round  92, Train loss: 1.105, Test loss: 1.811, Test accuracy: 75.95
Round  93, Train loss: 1.103, Test loss: 1.811, Test accuracy: 75.81
Round  94, Train loss: 1.104, Test loss: 1.812, Test accuracy: 75.79
Round  95, Train loss: 1.104, Test loss: 1.812, Test accuracy: 75.74
Round  96, Train loss: 1.103, Test loss: 1.811, Test accuracy: 75.83
Round  97, Train loss: 1.106, Test loss: 1.812, Test accuracy: 75.82
Round  98, Train loss: 1.104, Test loss: 1.812, Test accuracy: 75.73
Round  99, Train loss: 1.105, Test loss: 1.812, Test accuracy: 75.62
Final Round, Train loss: 1.104, Test loss: 1.813, Test accuracy: 75.45
Average accuracy final 10 rounds: 75.8515
2608.5394010543823
[]
[32.34, 59.155, 69.44, 71.665, 72.29, 74.375, 76.855, 80.38, 83.015, 84.045, 84.765, 85.0, 85.495, 85.04, 85.595, 85.515, 85.335, 85.66, 86.17, 85.88, 85.79, 85.565, 85.255, 85.14, 84.845, 84.695, 84.41, 84.365, 84.175, 84.025, 83.845, 83.49, 83.595, 83.095, 82.93, 82.805, 82.435, 82.38, 82.15, 81.825, 81.67, 81.655, 81.305, 81.265, 81.125, 80.86, 80.705, 80.515, 80.43, 80.46, 80.23, 80.0, 79.83, 79.72, 79.545, 79.375, 79.31, 79.245, 79.085, 78.945, 78.905, 78.775, 78.57, 78.55, 78.46, 78.395, 78.24, 78.035, 77.905, 77.745, 77.63, 77.545, 77.455, 77.39, 77.365, 77.245, 77.18, 77.045, 76.965, 76.815, 76.6, 76.545, 76.59, 76.38, 76.355, 76.32, 76.31, 76.175, 76.3, 76.125, 76.185, 76.03, 75.955, 75.815, 75.79, 75.74, 75.825, 75.82, 75.73, 75.625, 75.45]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.298, Test loss: 2.298, Test accuracy: 18.18
Round   1, Train loss: 2.287, Test loss: 2.290, Test accuracy: 19.77
Round   2, Train loss: 2.251, Test loss: 2.266, Test accuracy: 22.66
Round   3, Train loss: 2.256, Test loss: 2.260, Test accuracy: 21.27
Round   4, Train loss: 2.262, Test loss: 2.258, Test accuracy: 19.16
Round   5, Train loss: 2.125, Test loss: 2.208, Test accuracy: 28.38
Round   6, Train loss: 2.163, Test loss: 2.181, Test accuracy: 27.28
Round   7, Train loss: 1.921, Test loss: 2.159, Test accuracy: 28.91
Round   8, Train loss: 1.504, Test loss: 2.075, Test accuracy: 39.92
Round   9, Train loss: 1.698, Test loss: 2.062, Test accuracy: 41.59
Round  10, Train loss: 1.425, Test loss: 1.992, Test accuracy: 48.23
Round  11, Train loss: 2.329, Test loss: 2.066, Test accuracy: 41.63
Round  12, Train loss: 1.434, Test loss: 2.058, Test accuracy: 41.78
Round  13, Train loss: 1.846, Test loss: 2.087, Test accuracy: 37.26
Round  14, Train loss: 0.619, Test loss: 1.957, Test accuracy: 50.36
Round  15, Train loss: 0.314, Test loss: 1.863, Test accuracy: 59.55
Round  16, Train loss: 1.241, Test loss: 1.817, Test accuracy: 64.89
Round  17, Train loss: 1.304, Test loss: 1.822, Test accuracy: 65.10
Round  18, Train loss: 1.229, Test loss: 1.798, Test accuracy: 67.65
Round  19, Train loss: 1.184, Test loss: 1.777, Test accuracy: 69.43
Round  20, Train loss: 1.247, Test loss: 1.767, Test accuracy: 71.11
Round  21, Train loss: 0.839, Test loss: 1.724, Test accuracy: 75.69
Round  22, Train loss: 1.569, Test loss: 1.737, Test accuracy: 75.03
Round  23, Train loss: 1.026, Test loss: 1.717, Test accuracy: 76.55
Round  24, Train loss: 1.226, Test loss: 1.702, Test accuracy: 78.26
Round  25, Train loss: 1.073, Test loss: 1.691, Test accuracy: 78.69
Round  26, Train loss: 1.178, Test loss: 1.708, Test accuracy: 77.56
Round  27, Train loss: 1.144, Test loss: 1.700, Test accuracy: 78.80
Round  28, Train loss: 0.940, Test loss: 1.694, Test accuracy: 79.52
Round  29, Train loss: 1.108, Test loss: 1.676, Test accuracy: 80.62
Round  30, Train loss: 0.884, Test loss: 1.680, Test accuracy: 79.97
Round  31, Train loss: 1.210, Test loss: 1.676, Test accuracy: 80.14
Round  32, Train loss: 0.912, Test loss: 1.670, Test accuracy: 80.28
Round  33, Train loss: 0.668, Test loss: 1.638, Test accuracy: 83.22
Round  34, Train loss: 0.885, Test loss: 1.638, Test accuracy: 83.23
Round  35, Train loss: 0.813, Test loss: 1.644, Test accuracy: 82.70
Round  36, Train loss: 0.937, Test loss: 1.653, Test accuracy: 81.66
Round  37, Train loss: 0.542, Test loss: 1.627, Test accuracy: 84.20
Round  38, Train loss: 0.533, Test loss: 1.629, Test accuracy: 83.97
Round  39, Train loss: 0.705, Test loss: 1.627, Test accuracy: 84.06
Round  40, Train loss: 0.702, Test loss: 1.626, Test accuracy: 84.34
Round  41, Train loss: 0.695, Test loss: 1.617, Test accuracy: 85.30
Round  42, Train loss: 0.388, Test loss: 1.611, Test accuracy: 86.00
Round  43, Train loss: 0.852, Test loss: 1.613, Test accuracy: 85.71
Round  44, Train loss: 0.500, Test loss: 1.608, Test accuracy: 86.17
Round  45, Train loss: 0.569, Test loss: 1.605, Test accuracy: 86.45
Round  46, Train loss: 0.531, Test loss: 1.599, Test accuracy: 86.94
Round  47, Train loss: 0.445, Test loss: 1.597, Test accuracy: 87.10
Round  48, Train loss: 0.572, Test loss: 1.599, Test accuracy: 86.86
Round  49, Train loss: 0.234, Test loss: 1.598, Test accuracy: 86.92
Round  50, Train loss: 0.565, Test loss: 1.596, Test accuracy: 87.02
Round  51, Train loss: 0.420, Test loss: 1.596, Test accuracy: 86.95
Round  52, Train loss: 0.525, Test loss: 1.595, Test accuracy: 87.11
Round  53, Train loss: 0.612, Test loss: 1.598, Test accuracy: 86.91
Round  54, Train loss: 0.383, Test loss: 1.595, Test accuracy: 87.17
Round  55, Train loss: 0.320, Test loss: 1.597, Test accuracy: 86.89
Round  56, Train loss: 0.529, Test loss: 1.595, Test accuracy: 86.95
Round  57, Train loss: 0.479, Test loss: 1.596, Test accuracy: 87.06
Round  58, Train loss: 0.266, Test loss: 1.595, Test accuracy: 87.12
Round  59, Train loss: 0.289, Test loss: 1.593, Test accuracy: 87.29
Round  60, Train loss: 0.448, Test loss: 1.591, Test accuracy: 87.42
Round  61, Train loss: 0.138, Test loss: 1.589, Test accuracy: 87.58
Round  62, Train loss: 0.372, Test loss: 1.592, Test accuracy: 87.33
Round  63, Train loss: 0.414, Test loss: 1.592, Test accuracy: 87.36
Round  64, Train loss: 0.385, Test loss: 1.591, Test accuracy: 87.42
Round  65, Train loss: 0.357, Test loss: 1.592, Test accuracy: 87.30
Round  66, Train loss: 0.140, Test loss: 1.592, Test accuracy: 87.29
Round  67, Train loss: 0.299, Test loss: 1.590, Test accuracy: 87.36
Round  68, Train loss: 0.500, Test loss: 1.591, Test accuracy: 87.28
Round  69, Train loss: 0.476, Test loss: 1.591, Test accuracy: 87.34
Round  70, Train loss: 0.438, Test loss: 1.592, Test accuracy: 87.34
Round  71, Train loss: 0.228, Test loss: 1.592, Test accuracy: 87.27
Round  72, Train loss: 0.375, Test loss: 1.591, Test accuracy: 87.39
Round  73, Train loss: 0.101, Test loss: 1.590, Test accuracy: 87.37
Round  74, Train loss: 0.433, Test loss: 1.588, Test accuracy: 87.61
Round  75, Train loss: 0.342, Test loss: 1.590, Test accuracy: 87.47
Round  76, Train loss: 0.179, Test loss: 1.591, Test accuracy: 87.41
Round  77, Train loss: 0.450, Test loss: 1.593, Test accuracy: 87.12
Round  78, Train loss: 0.377, Test loss: 1.589, Test accuracy: 87.56
Round  79, Train loss: 0.365, Test loss: 1.587, Test accuracy: 87.76
Round  80, Train loss: 0.296, Test loss: 1.588, Test accuracy: 87.70
Round  81, Train loss: 0.312, Test loss: 1.587, Test accuracy: 87.81
Round  82, Train loss: 0.281, Test loss: 1.586, Test accuracy: 87.89
Round  83, Train loss: 0.228, Test loss: 1.588, Test accuracy: 87.68
Round  84, Train loss: 0.293, Test loss: 1.586, Test accuracy: 87.89
Round  85, Train loss: 0.121, Test loss: 1.586, Test accuracy: 87.86
Round  86, Train loss: 0.326, Test loss: 1.583, Test accuracy: 88.16
Round  87, Train loss: 0.366, Test loss: 1.586, Test accuracy: 87.92
Round  88, Train loss: 0.037, Test loss: 1.586, Test accuracy: 87.90
Round  89, Train loss: 0.399, Test loss: 1.589, Test accuracy: 87.70
Round  90, Train loss: 0.389, Test loss: 1.589, Test accuracy: 87.65
Round  91, Train loss: 0.179, Test loss: 1.588, Test accuracy: 87.67
Round  92, Train loss: 0.439, Test loss: 1.589, Test accuracy: 87.65
Round  93, Train loss: 0.209, Test loss: 1.587, Test accuracy: 87.92
Round  94, Train loss: 0.389, Test loss: 1.590, Test accuracy: 87.64
Round  95, Train loss: 0.385, Test loss: 1.588, Test accuracy: 87.78
Round  96, Train loss: 0.210, Test loss: 1.587, Test accuracy: 87.89
Round  97, Train loss: 0.375, Test loss: 1.587, Test accuracy: 87.81
Round  98, Train loss: 0.217, Test loss: 1.583, Test accuracy: 88.16
Round  99, Train loss: 0.442, Test loss: 1.584, Test accuracy: 88.05
Final Round, Train loss: 1.523, Test loss: 1.568, Test accuracy: 90.05
Average accuracy final 10 rounds: 87.82300000000001
Average global accuracy final 10 rounds: 87.82300000000001
2113.9409685134888
[]
[18.175, 19.765, 22.655, 21.275, 19.16, 28.38, 27.28, 28.91, 39.925, 41.585, 48.235, 41.63, 41.78, 37.26, 50.36, 59.55, 64.885, 65.1, 67.65, 69.43, 71.11, 75.685, 75.03, 76.55, 78.26, 78.685, 77.56, 78.8, 79.52, 80.62, 79.97, 80.14, 80.285, 83.225, 83.235, 82.705, 81.66, 84.2, 83.965, 84.065, 84.34, 85.295, 86.005, 85.71, 86.165, 86.455, 86.94, 87.1, 86.855, 86.915, 87.015, 86.955, 87.105, 86.91, 87.175, 86.895, 86.95, 87.06, 87.125, 87.29, 87.42, 87.585, 87.33, 87.355, 87.42, 87.295, 87.29, 87.355, 87.275, 87.34, 87.34, 87.265, 87.39, 87.37, 87.61, 87.475, 87.41, 87.12, 87.56, 87.76, 87.705, 87.805, 87.895, 87.68, 87.895, 87.865, 88.155, 87.925, 87.9, 87.7, 87.65, 87.675, 87.65, 87.925, 87.635, 87.785, 87.895, 87.805, 88.16, 88.05, 90.05]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

prox
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.301, Test loss: 2.299, Test accuracy: 27.59
Round   0, Global train loss: 2.301, Global test loss: 2.299, Global test accuracy: 27.79
Round   1, Train loss: 2.295, Test loss: 2.292, Test accuracy: 26.54
Round   1, Global train loss: 2.295, Global test loss: 2.290, Global test accuracy: 26.38
Round   2, Train loss: 2.256, Test loss: 2.248, Test accuracy: 23.04
Round   2, Global train loss: 2.256, Global test loss: 2.215, Global test accuracy: 20.02
Round   3, Train loss: 2.153, Test loss: 2.157, Test accuracy: 36.17
Round   3, Global train loss: 2.153, Global test loss: 2.065, Global test accuracy: 45.34
Round   4, Train loss: 1.947, Test loss: 2.020, Test accuracy: 51.16
Round   4, Global train loss: 1.947, Global test loss: 1.820, Global test accuracy: 72.28
Round   5, Train loss: 1.740, Test loss: 1.907, Test accuracy: 61.01
Round   5, Global train loss: 1.740, Global test loss: 1.704, Global test accuracy: 79.79
Round   6, Train loss: 1.673, Test loss: 1.868, Test accuracy: 64.34
Round   6, Global train loss: 1.673, Global test loss: 1.645, Global test accuracy: 84.88
Round   7, Train loss: 1.621, Test loss: 1.786, Test accuracy: 72.03
Round   7, Global train loss: 1.621, Global test loss: 1.610, Global test accuracy: 87.38
Round   8, Train loss: 1.582, Test loss: 1.691, Test accuracy: 80.94
Round   8, Global train loss: 1.582, Global test loss: 1.592, Global test accuracy: 88.67
Round   9, Train loss: 1.568, Test loss: 1.668, Test accuracy: 82.41
Round   9, Global train loss: 1.568, Global test loss: 1.583, Global test accuracy: 89.28
Round  10, Train loss: 1.567, Test loss: 1.624, Test accuracy: 86.12
Round  10, Global train loss: 1.567, Global test loss: 1.576, Global test accuracy: 89.67
Round  11, Train loss: 1.553, Test loss: 1.601, Test accuracy: 87.56
Round  11, Global train loss: 1.553, Global test loss: 1.569, Global test accuracy: 90.47
Round  12, Train loss: 1.547, Test loss: 1.584, Test accuracy: 89.02
Round  12, Global train loss: 1.547, Global test loss: 1.565, Global test accuracy: 90.57
Round  13, Train loss: 1.542, Test loss: 1.580, Test accuracy: 89.31
Round  13, Global train loss: 1.542, Global test loss: 1.562, Global test accuracy: 90.80
Round  14, Train loss: 1.538, Test loss: 1.573, Test accuracy: 89.89
Round  14, Global train loss: 1.538, Global test loss: 1.557, Global test accuracy: 91.27
Round  15, Train loss: 1.531, Test loss: 1.572, Test accuracy: 89.86
Round  15, Global train loss: 1.531, Global test loss: 1.555, Global test accuracy: 91.33
Round  16, Train loss: 1.533, Test loss: 1.570, Test accuracy: 90.11
Round  16, Global train loss: 1.533, Global test loss: 1.552, Global test accuracy: 91.39
Round  17, Train loss: 1.524, Test loss: 1.565, Test accuracy: 90.43
Round  17, Global train loss: 1.524, Global test loss: 1.549, Global test accuracy: 91.74
Round  18, Train loss: 1.526, Test loss: 1.561, Test accuracy: 90.69
Round  18, Global train loss: 1.526, Global test loss: 1.548, Global test accuracy: 91.72
Round  19, Train loss: 1.523, Test loss: 1.556, Test accuracy: 91.12
Round  19, Global train loss: 1.523, Global test loss: 1.546, Global test accuracy: 92.00
Round  20, Train loss: 1.521, Test loss: 1.555, Test accuracy: 91.30
Round  20, Global train loss: 1.521, Global test loss: 1.543, Global test accuracy: 92.29
Round  21, Train loss: 1.516, Test loss: 1.553, Test accuracy: 91.55
Round  21, Global train loss: 1.516, Global test loss: 1.542, Global test accuracy: 92.44
Round  22, Train loss: 1.513, Test loss: 1.552, Test accuracy: 91.59
Round  22, Global train loss: 1.513, Global test loss: 1.541, Global test accuracy: 92.42
Round  23, Train loss: 1.511, Test loss: 1.550, Test accuracy: 91.73
Round  23, Global train loss: 1.511, Global test loss: 1.540, Global test accuracy: 92.48
Round  24, Train loss: 1.512, Test loss: 1.549, Test accuracy: 91.82
Round  24, Global train loss: 1.512, Global test loss: 1.538, Global test accuracy: 92.81
Round  25, Train loss: 1.507, Test loss: 1.546, Test accuracy: 91.97
Round  25, Global train loss: 1.507, Global test loss: 1.537, Global test accuracy: 92.77
Round  26, Train loss: 1.506, Test loss: 1.545, Test accuracy: 92.08
Round  26, Global train loss: 1.506, Global test loss: 1.536, Global test accuracy: 92.77
Round  27, Train loss: 1.505, Test loss: 1.544, Test accuracy: 92.22
Round  27, Global train loss: 1.505, Global test loss: 1.535, Global test accuracy: 92.94
Round  28, Train loss: 1.506, Test loss: 1.543, Test accuracy: 92.28
Round  28, Global train loss: 1.506, Global test loss: 1.534, Global test accuracy: 93.10
Round  29, Train loss: 1.506, Test loss: 1.541, Test accuracy: 92.47
Round  29, Global train loss: 1.506, Global test loss: 1.533, Global test accuracy: 93.13
Round  30, Train loss: 1.508, Test loss: 1.540, Test accuracy: 92.56
Round  30, Global train loss: 1.508, Global test loss: 1.531, Global test accuracy: 93.33
Round  31, Train loss: 1.503, Test loss: 1.538, Test accuracy: 92.72
Round  31, Global train loss: 1.503, Global test loss: 1.531, Global test accuracy: 93.37
Round  32, Train loss: 1.498, Test loss: 1.538, Test accuracy: 92.78
Round  32, Global train loss: 1.498, Global test loss: 1.530, Global test accuracy: 93.38
Round  33, Train loss: 1.497, Test loss: 1.537, Test accuracy: 92.89
Round  33, Global train loss: 1.497, Global test loss: 1.529, Global test accuracy: 93.48
Round  34, Train loss: 1.498, Test loss: 1.536, Test accuracy: 93.02
Round  34, Global train loss: 1.498, Global test loss: 1.528, Global test accuracy: 93.53
Round  35, Train loss: 1.504, Test loss: 1.536, Test accuracy: 92.97
Round  35, Global train loss: 1.504, Global test loss: 1.527, Global test accuracy: 93.57
Round  36, Train loss: 1.501, Test loss: 1.534, Test accuracy: 93.11
Round  36, Global train loss: 1.501, Global test loss: 1.526, Global test accuracy: 93.76
Round  37, Train loss: 1.497, Test loss: 1.534, Test accuracy: 93.10
Round  37, Global train loss: 1.497, Global test loss: 1.528, Global test accuracy: 93.64
Round  38, Train loss: 1.497, Test loss: 1.533, Test accuracy: 93.19
Round  38, Global train loss: 1.497, Global test loss: 1.525, Global test accuracy: 94.00
Round  39, Train loss: 1.497, Test loss: 1.531, Test accuracy: 93.39
Round  39, Global train loss: 1.497, Global test loss: 1.524, Global test accuracy: 93.95
Round  40, Train loss: 1.495, Test loss: 1.530, Test accuracy: 93.52
Round  40, Global train loss: 1.495, Global test loss: 1.524, Global test accuracy: 93.98
Round  41, Train loss: 1.492, Test loss: 1.530, Test accuracy: 93.53
Round  41, Global train loss: 1.492, Global test loss: 1.523, Global test accuracy: 94.17
Round  42, Train loss: 1.492, Test loss: 1.529, Test accuracy: 93.60
Round  42, Global train loss: 1.492, Global test loss: 1.523, Global test accuracy: 93.97
Round  43, Train loss: 1.490, Test loss: 1.528, Test accuracy: 93.64
Round  43, Global train loss: 1.490, Global test loss: 1.523, Global test accuracy: 94.08
Round  44, Train loss: 1.494, Test loss: 1.527, Test accuracy: 93.73
Round  44, Global train loss: 1.494, Global test loss: 1.522, Global test accuracy: 94.12
Round  45, Train loss: 1.495, Test loss: 1.526, Test accuracy: 93.83
Round  45, Global train loss: 1.495, Global test loss: 1.522, Global test accuracy: 94.19
Round  46, Train loss: 1.487, Test loss: 1.525, Test accuracy: 93.95
Round  46, Global train loss: 1.487, Global test loss: 1.521, Global test accuracy: 94.37
Round  47, Train loss: 1.493, Test loss: 1.525, Test accuracy: 93.87
Round  47, Global train loss: 1.493, Global test loss: 1.521, Global test accuracy: 94.27
Round  48, Train loss: 1.488, Test loss: 1.524, Test accuracy: 94.00
Round  48, Global train loss: 1.488, Global test loss: 1.521, Global test accuracy: 94.36
Round  49, Train loss: 1.486, Test loss: 1.524, Test accuracy: 94.04
Round  49, Global train loss: 1.486, Global test loss: 1.520, Global test accuracy: 94.42
Round  50, Train loss: 1.487, Test loss: 1.523, Test accuracy: 94.17
Round  50, Global train loss: 1.487, Global test loss: 1.519, Global test accuracy: 94.39
Round  51, Train loss: 1.488, Test loss: 1.523, Test accuracy: 94.19
Round  51, Global train loss: 1.488, Global test loss: 1.519, Global test accuracy: 94.58
Round  52, Train loss: 1.486, Test loss: 1.523, Test accuracy: 94.18
Round  52, Global train loss: 1.486, Global test loss: 1.518, Global test accuracy: 94.50
Round  53, Train loss: 1.487, Test loss: 1.522, Test accuracy: 94.19
Round  53, Global train loss: 1.487, Global test loss: 1.518, Global test accuracy: 94.60
Round  54, Train loss: 1.485, Test loss: 1.522, Test accuracy: 94.20
Round  54, Global train loss: 1.485, Global test loss: 1.518, Global test accuracy: 94.68
Round  55, Train loss: 1.483, Test loss: 1.522, Test accuracy: 94.21
Round  55, Global train loss: 1.483, Global test loss: 1.518, Global test accuracy: 94.51
Round  56, Train loss: 1.483, Test loss: 1.521, Test accuracy: 94.25
Round  56, Global train loss: 1.483, Global test loss: 1.517, Global test accuracy: 94.67
Round  57, Train loss: 1.485, Test loss: 1.521, Test accuracy: 94.23
Round  57, Global train loss: 1.485, Global test loss: 1.518, Global test accuracy: 94.56
Round  58, Train loss: 1.484, Test loss: 1.521, Test accuracy: 94.39
Round  58, Global train loss: 1.484, Global test loss: 1.517, Global test accuracy: 94.71
Round  59, Train loss: 1.485, Test loss: 1.520, Test accuracy: 94.44
Round  59, Global train loss: 1.485, Global test loss: 1.516, Global test accuracy: 94.73
Round  60, Train loss: 1.485, Test loss: 1.520, Test accuracy: 94.47
Round  60, Global train loss: 1.485, Global test loss: 1.516, Global test accuracy: 94.89
Round  61, Train loss: 1.483, Test loss: 1.519, Test accuracy: 94.53
Round  61, Global train loss: 1.483, Global test loss: 1.516, Global test accuracy: 94.78
Round  62, Train loss: 1.482, Test loss: 1.519, Test accuracy: 94.53
Round  62, Global train loss: 1.482, Global test loss: 1.515, Global test accuracy: 94.99
Round  63, Train loss: 1.481, Test loss: 1.519, Test accuracy: 94.52
Round  63, Global train loss: 1.481, Global test loss: 1.516, Global test accuracy: 95.05
Round  64, Train loss: 1.480, Test loss: 1.519, Test accuracy: 94.51
Round  64, Global train loss: 1.480, Global test loss: 1.516, Global test accuracy: 94.75
Round  65, Train loss: 1.483, Test loss: 1.519, Test accuracy: 94.58
Round  65, Global train loss: 1.483, Global test loss: 1.515, Global test accuracy: 94.92
Round  66, Train loss: 1.483, Test loss: 1.518, Test accuracy: 94.62
Round  66, Global train loss: 1.483, Global test loss: 1.514, Global test accuracy: 94.91
Round  67, Train loss: 1.478, Test loss: 1.517, Test accuracy: 94.62
Round  67, Global train loss: 1.478, Global test loss: 1.514, Global test accuracy: 94.94
Round  68, Train loss: 1.485, Test loss: 1.517, Test accuracy: 94.61
Round  68, Global train loss: 1.485, Global test loss: 1.514, Global test accuracy: 94.91
Round  69, Train loss: 1.482, Test loss: 1.517, Test accuracy: 94.66
Round  69, Global train loss: 1.482, Global test loss: 1.513, Global test accuracy: 95.00
Round  70, Train loss: 1.480, Test loss: 1.517, Test accuracy: 94.72
Round  70, Global train loss: 1.480, Global test loss: 1.514, Global test accuracy: 95.03
Round  71, Train loss: 1.481, Test loss: 1.516, Test accuracy: 94.77
Round  71, Global train loss: 1.481, Global test loss: 1.514, Global test accuracy: 95.09
Round  72, Train loss: 1.477, Test loss: 1.516, Test accuracy: 94.77
Round  72, Global train loss: 1.477, Global test loss: 1.514, Global test accuracy: 95.05
Round  73, Train loss: 1.483, Test loss: 1.515, Test accuracy: 94.86
Round  73, Global train loss: 1.483, Global test loss: 1.513, Global test accuracy: 95.06
Round  74, Train loss: 1.482, Test loss: 1.515, Test accuracy: 94.86
Round  74, Global train loss: 1.482, Global test loss: 1.512, Global test accuracy: 95.12
Round  75, Train loss: 1.480, Test loss: 1.515, Test accuracy: 94.85
Round  75, Global train loss: 1.480, Global test loss: 1.513, Global test accuracy: 95.04
Round  76, Train loss: 1.477, Test loss: 1.515, Test accuracy: 94.89
Round  76, Global train loss: 1.477, Global test loss: 1.513, Global test accuracy: 95.12
Round  77, Train loss: 1.479, Test loss: 1.515, Test accuracy: 94.89
Round  77, Global train loss: 1.479, Global test loss: 1.512, Global test accuracy: 95.11
Round  78, Train loss: 1.478, Test loss: 1.514, Test accuracy: 94.95
Round  78, Global train loss: 1.478, Global test loss: 1.512, Global test accuracy: 95.14
Round  79, Train loss: 1.478, Test loss: 1.514, Test accuracy: 94.92
Round  79, Global train loss: 1.478, Global test loss: 1.512, Global test accuracy: 95.16
Round  80, Train loss: 1.481, Test loss: 1.514, Test accuracy: 94.92
Round  80, Global train loss: 1.481, Global test loss: 1.512, Global test accuracy: 95.22
Round  81, Train loss: 1.479, Test loss: 1.514, Test accuracy: 94.99
Round  81, Global train loss: 1.479, Global test loss: 1.512, Global test accuracy: 95.17
Round  82, Train loss: 1.478, Test loss: 1.514, Test accuracy: 94.97
Round  82, Global train loss: 1.478, Global test loss: 1.512, Global test accuracy: 95.14
Round  83, Train loss: 1.477, Test loss: 1.514, Test accuracy: 94.94
Round  83, Global train loss: 1.477, Global test loss: 1.512, Global test accuracy: 95.22
Round  84, Train loss: 1.478, Test loss: 1.514, Test accuracy: 94.95
Round  84, Global train loss: 1.478, Global test loss: 1.512, Global test accuracy: 95.13
Round  85, Train loss: 1.481, Test loss: 1.514, Test accuracy: 94.91
Round  85, Global train loss: 1.481, Global test loss: 1.513, Global test accuracy: 95.07
Round  86, Train loss: 1.476, Test loss: 1.514, Test accuracy: 94.94
Round  86, Global train loss: 1.476, Global test loss: 1.512, Global test accuracy: 95.11
Round  87, Train loss: 1.475, Test loss: 1.514, Test accuracy: 94.98
Round  87, Global train loss: 1.475, Global test loss: 1.511, Global test accuracy: 95.17
Round  88, Train loss: 1.478, Test loss: 1.513, Test accuracy: 95.02
Round  88, Global train loss: 1.478, Global test loss: 1.511, Global test accuracy: 95.17
Round  89, Train loss: 1.476, Test loss: 1.513, Test accuracy: 95.00
Round  89, Global train loss: 1.476, Global test loss: 1.511, Global test accuracy: 95.19
Round  90, Train loss: 1.479, Test loss: 1.513, Test accuracy: 95.04
Round  90, Global train loss: 1.479, Global test loss: 1.511, Global test accuracy: 95.22
Round  91, Train loss: 1.477, Test loss: 1.513, Test accuracy: 95.06
Round  91, Global train loss: 1.477, Global test loss: 1.511, Global test accuracy: 95.24
Round  92, Train loss: 1.476, Test loss: 1.513, Test accuracy: 95.06
Round  92, Global train loss: 1.476, Global test loss: 1.511, Global test accuracy: 95.20
Round  93, Train loss: 1.481, Test loss: 1.513, Test accuracy: 95.06
Round  93, Global train loss: 1.481, Global test loss: 1.511, Global test accuracy: 95.21
Round  94, Train loss: 1.478, Test loss: 1.512, Test accuracy: 95.09
Round  94, Global train loss: 1.478, Global test loss: 1.511, Global test accuracy: 95.23
Round  95, Train loss: 1.476, Test loss: 1.512, Test accuracy: 95.09
Round  95, Global train loss: 1.476, Global test loss: 1.511, Global test accuracy: 95.29/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  96, Train loss: 1.475, Test loss: 1.512, Test accuracy: 95.14
Round  96, Global train loss: 1.475, Global test loss: 1.510, Global test accuracy: 95.23
Round  97, Train loss: 1.475, Test loss: 1.512, Test accuracy: 95.10
Round  97, Global train loss: 1.475, Global test loss: 1.510, Global test accuracy: 95.31
Round  98, Train loss: 1.477, Test loss: 1.512, Test accuracy: 95.08
Round  98, Global train loss: 1.477, Global test loss: 1.510, Global test accuracy: 95.20
Round  99, Train loss: 1.475, Test loss: 1.512, Test accuracy: 95.11
Round  99, Global train loss: 1.475, Global test loss: 1.509, Global test accuracy: 95.28
Final Round, Train loss: 1.474, Test loss: 1.511, Test accuracy: 95.12
Final Round, Global train loss: 1.474, Global test loss: 1.509, Global test accuracy: 95.28
Average accuracy final 10 rounds: 95.08350000000002 

Average global accuracy final 10 rounds: 95.24 

3103.1888840198517
[2.221674680709839, 4.443349361419678, 6.646148443222046, 8.848947525024414, 10.995098114013672, 13.14124870300293, 15.380826473236084, 17.62040424346924, 19.80890703201294, 21.99740982055664, 24.18188500404358, 26.366360187530518, 28.55024766921997, 30.734135150909424, 32.71222710609436, 34.6903190612793, 36.701552629470825, 38.71278619766235, 40.82304048538208, 42.93329477310181, 45.08759069442749, 47.241886615753174, 49.37422704696655, 51.50656747817993, 53.47898316383362, 55.451398849487305, 57.599828004837036, 59.74825716018677, 61.9026198387146, 64.05698251724243, 66.33573770523071, 68.614492893219, 70.77511739730835, 72.9357419013977, 75.14914870262146, 77.36255550384521, 79.48140263557434, 81.60024976730347, 83.82934427261353, 86.05843877792358, 88.1953456401825, 90.3322525024414, 92.53583359718323, 94.73941469192505, 96.91638207435608, 99.09334945678711, 101.3098692893982, 103.52638912200928, 105.67471194267273, 107.82303476333618, 109.95451021194458, 112.08598566055298, 114.26680421829224, 116.4476227760315, 118.60127520561218, 120.75492763519287, 122.89145112037659, 125.0279746055603, 127.28602361679077, 129.54407262802124, 131.68055152893066, 133.8170304298401, 135.97250318527222, 138.12797594070435, 140.30645036697388, 142.4849247932434, 144.68460321426392, 146.88428163528442, 149.07421350479126, 151.2641453742981, 153.40935969352722, 155.55457401275635, 157.68170642852783, 159.80883884429932, 162.05857729911804, 164.30831575393677, 166.4100000858307, 168.5116844177246, 170.67011332511902, 172.82854223251343, 174.95994210243225, 177.09134197235107, 179.18597984313965, 181.28061771392822, 183.42076778411865, 185.56091785430908, 187.60985660552979, 189.6587953567505, 191.76404070854187, 193.86928606033325, 196.00703144073486, 198.14477682113647, 200.071861743927, 201.99894666671753, 203.93247747421265, 205.86600828170776, 207.95100569725037, 210.03600311279297, 212.1328809261322, 214.22975873947144, 216.3526794910431, 218.47560024261475, 220.49783515930176, 222.52007007598877, 224.65611672401428, 226.7921633720398, 228.95467495918274, 231.11718654632568, 233.19128155708313, 235.26537656784058, 237.456768989563, 239.6481614112854, 241.52159905433655, 243.3950366973877, 245.20834159851074, 247.0216464996338, 248.83217763900757, 250.64270877838135, 252.55490016937256, 254.46709156036377, 256.3618302345276, 258.2565689086914, 260.12735199928284, 261.99813508987427, 263.95628690719604, 265.9144387245178, 267.75109243392944, 269.58774614334106, 271.4591295719147, 273.3305130004883, 275.22909116744995, 277.1276693344116, 279.07178831100464, 281.01590728759766, 282.8759169578552, 284.7359266281128, 286.7128093242645, 288.68969202041626, 290.61722135543823, 292.5447506904602, 294.63717555999756, 296.7296004295349, 298.7172203063965, 300.70484018325806, 302.5809133052826, 304.45698642730713, 306.32623744010925, 308.1954884529114, 310.13303565979004, 312.0705828666687, 313.95197319984436, 315.83336353302, 317.72447180747986, 319.6155800819397, 321.54424142837524, 323.4729027748108, 325.4336974620819, 327.394492149353, 329.23190999031067, 331.0693278312683, 332.9729609489441, 334.8765940666199, 336.7524371147156, 338.6282801628113, 340.5122125148773, 342.39614486694336, 344.297376871109, 346.19860887527466, 348.15530824661255, 350.11200761795044, 351.96517181396484, 353.81833600997925, 355.669340133667, 357.52034425735474, 359.7440972328186, 361.96785020828247, 364.181188583374, 366.3945269584656, 368.21139430999756, 370.02826166152954, 371.90817856788635, 373.78809547424316, 375.6278483867645, 377.4676012992859, 379.36900639533997, 381.27041149139404, 383.1629378795624, 385.0554642677307, 386.86987805366516, 388.6842918395996, 390.52823781967163, 392.37218379974365, 394.2464346885681, 396.1206855773926, 398.01358103752136, 399.90647649765015, 401.82188081741333, 403.7372851371765, 405.57632970809937, 407.4153742790222, 409.30198073387146, 411.1885871887207]
[27.585, 27.585, 26.54, 26.54, 23.04, 23.04, 36.175, 36.175, 51.16, 51.16, 61.01, 61.01, 64.34, 64.34, 72.025, 72.025, 80.945, 80.945, 82.41, 82.41, 86.12, 86.12, 87.56, 87.56, 89.02, 89.02, 89.315, 89.315, 89.885, 89.885, 89.865, 89.865, 90.11, 90.11, 90.43, 90.43, 90.695, 90.695, 91.12, 91.12, 91.3, 91.3, 91.55, 91.55, 91.595, 91.595, 91.735, 91.735, 91.82, 91.82, 91.975, 91.975, 92.08, 92.08, 92.225, 92.225, 92.275, 92.275, 92.475, 92.475, 92.555, 92.555, 92.725, 92.725, 92.78, 92.78, 92.885, 92.885, 93.015, 93.015, 92.97, 92.97, 93.11, 93.11, 93.1, 93.1, 93.195, 93.195, 93.395, 93.395, 93.515, 93.515, 93.53, 93.53, 93.6, 93.6, 93.635, 93.635, 93.73, 93.73, 93.835, 93.835, 93.955, 93.955, 93.87, 93.87, 93.995, 93.995, 94.04, 94.04, 94.175, 94.175, 94.19, 94.19, 94.18, 94.18, 94.185, 94.185, 94.2, 94.2, 94.21, 94.21, 94.245, 94.245, 94.23, 94.23, 94.385, 94.385, 94.435, 94.435, 94.47, 94.47, 94.535, 94.535, 94.525, 94.525, 94.515, 94.515, 94.51, 94.51, 94.585, 94.585, 94.62, 94.62, 94.62, 94.62, 94.61, 94.61, 94.655, 94.655, 94.715, 94.715, 94.77, 94.77, 94.77, 94.77, 94.865, 94.865, 94.855, 94.855, 94.85, 94.85, 94.895, 94.895, 94.885, 94.885, 94.95, 94.95, 94.925, 94.925, 94.925, 94.925, 94.99, 94.99, 94.965, 94.965, 94.935, 94.935, 94.955, 94.955, 94.91, 94.91, 94.94, 94.94, 94.98, 94.98, 95.02, 95.02, 95.0, 95.0, 95.04, 95.04, 95.055, 95.055, 95.065, 95.065, 95.055, 95.055, 95.09, 95.09, 95.095, 95.095, 95.135, 95.135, 95.1, 95.1, 95.085, 95.085, 95.115, 95.115, 95.12, 95.12]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
Round   0, Train loss: 2.302, Test loss: 2.295, Test accuracy: 27.52
Round   1, Train loss: 2.292, Test loss: 2.210, Test accuracy: 34.62
Round   2, Train loss: 2.186, Test loss: 1.887, Test accuracy: 63.27
Round   3, Train loss: 1.906, Test loss: 1.816, Test accuracy: 65.46
Round   4, Train loss: 1.854, Test loss: 1.761, Test accuracy: 72.05
Round   5, Train loss: 1.766, Test loss: 1.719, Test accuracy: 74.09
Round   6, Train loss: 1.704, Test loss: 1.612, Test accuracy: 86.92
Round   7, Train loss: 1.624, Test loss: 1.594, Test accuracy: 87.92
Round   8, Train loss: 1.593, Test loss: 1.581, Test accuracy: 88.87
Round   9, Train loss: 1.579, Test loss: 1.574, Test accuracy: 89.38
Round  10, Train loss: 1.568, Test loss: 1.567, Test accuracy: 90.16
Round  11, Train loss: 1.546, Test loss: 1.562, Test accuracy: 90.50
Round  12, Train loss: 1.546, Test loss: 1.557, Test accuracy: 90.95
Round  13, Train loss: 1.539, Test loss: 1.555, Test accuracy: 91.24
Round  14, Train loss: 1.542, Test loss: 1.552, Test accuracy: 91.43
Round  15, Train loss: 1.542, Test loss: 1.547, Test accuracy: 91.70
Round  16, Train loss: 1.533, Test loss: 1.545, Test accuracy: 92.06
Round  17, Train loss: 1.521, Test loss: 1.544, Test accuracy: 92.13
Round  18, Train loss: 1.515, Test loss: 1.542, Test accuracy: 92.22
Round  19, Train loss: 1.515, Test loss: 1.541, Test accuracy: 92.29
Round  20, Train loss: 1.514, Test loss: 1.539, Test accuracy: 92.59
Round  21, Train loss: 1.514, Test loss: 1.536, Test accuracy: 92.89
Round  22, Train loss: 1.517, Test loss: 1.535, Test accuracy: 92.91
Round  23, Train loss: 1.506, Test loss: 1.534, Test accuracy: 92.98
Round  24, Train loss: 1.514, Test loss: 1.532, Test accuracy: 93.25
Round  25, Train loss: 1.507, Test loss: 1.530, Test accuracy: 93.43
Round  26, Train loss: 1.498, Test loss: 1.530, Test accuracy: 93.49
Round  27, Train loss: 1.507, Test loss: 1.529, Test accuracy: 93.33
Round  28, Train loss: 1.503, Test loss: 1.527, Test accuracy: 93.69
Round  29, Train loss: 1.507, Test loss: 1.527, Test accuracy: 93.67
Round  30, Train loss: 1.504, Test loss: 1.525, Test accuracy: 93.95
Round  31, Train loss: 1.491, Test loss: 1.525, Test accuracy: 93.90
Round  32, Train loss: 1.495, Test loss: 1.525, Test accuracy: 93.80
Round  33, Train loss: 1.499, Test loss: 1.524, Test accuracy: 93.87
Round  34, Train loss: 1.493, Test loss: 1.523, Test accuracy: 94.06
Round  35, Train loss: 1.497, Test loss: 1.523, Test accuracy: 94.14
Round  36, Train loss: 1.493, Test loss: 1.521, Test accuracy: 94.25
Round  37, Train loss: 1.496, Test loss: 1.520, Test accuracy: 94.44
Round  38, Train loss: 1.495, Test loss: 1.520, Test accuracy: 94.49
Round  39, Train loss: 1.487, Test loss: 1.519, Test accuracy: 94.64
Round  40, Train loss: 1.491, Test loss: 1.518, Test accuracy: 94.59
Round  41, Train loss: 1.492, Test loss: 1.518, Test accuracy: 94.57
Round  42, Train loss: 1.488, Test loss: 1.517, Test accuracy: 94.56
Round  43, Train loss: 1.489, Test loss: 1.518, Test accuracy: 94.53
Round  44, Train loss: 1.488, Test loss: 1.517, Test accuracy: 94.64
Round  45, Train loss: 1.490, Test loss: 1.517, Test accuracy: 94.59
Round  46, Train loss: 1.485, Test loss: 1.517, Test accuracy: 94.61
Round  47, Train loss: 1.490, Test loss: 1.516, Test accuracy: 94.86
Round  48, Train loss: 1.489, Test loss: 1.516, Test accuracy: 94.81
Round  49, Train loss: 1.487, Test loss: 1.516, Test accuracy: 94.81
Round  50, Train loss: 1.483, Test loss: 1.516, Test accuracy: 94.75
Round  51, Train loss: 1.487, Test loss: 1.514, Test accuracy: 94.97
Round  52, Train loss: 1.480, Test loss: 1.514, Test accuracy: 95.05
Round  53, Train loss: 1.483, Test loss: 1.514, Test accuracy: 94.99
Round  54, Train loss: 1.481, Test loss: 1.513, Test accuracy: 95.04
Round  55, Train loss: 1.484, Test loss: 1.513, Test accuracy: 94.94
Round  56, Train loss: 1.480, Test loss: 1.513, Test accuracy: 95.04
Round  57, Train loss: 1.479, Test loss: 1.513, Test accuracy: 94.97
Round  58, Train loss: 1.479, Test loss: 1.513, Test accuracy: 95.03
Round  59, Train loss: 1.484, Test loss: 1.513, Test accuracy: 95.03
Round  60, Train loss: 1.481, Test loss: 1.512, Test accuracy: 95.17
Round  61, Train loss: 1.481, Test loss: 1.512, Test accuracy: 95.14
Round  62, Train loss: 1.481, Test loss: 1.512, Test accuracy: 95.15
Round  63, Train loss: 1.477, Test loss: 1.512, Test accuracy: 95.12
Round  64, Train loss: 1.482, Test loss: 1.512, Test accuracy: 95.11
Round  65, Train loss: 1.483, Test loss: 1.512, Test accuracy: 95.17
Round  66, Train loss: 1.479, Test loss: 1.512, Test accuracy: 95.12
Round  67, Train loss: 1.481, Test loss: 1.511, Test accuracy: 95.22
Round  68, Train loss: 1.478, Test loss: 1.511, Test accuracy: 95.22
Round  69, Train loss: 1.479, Test loss: 1.510, Test accuracy: 95.25
Round  70, Train loss: 1.476, Test loss: 1.511, Test accuracy: 95.22
Round  71, Train loss: 1.478, Test loss: 1.511, Test accuracy: 95.20
Round  72, Train loss: 1.475, Test loss: 1.510, Test accuracy: 95.31
Round  73, Train loss: 1.477, Test loss: 1.510, Test accuracy: 95.28
Round  74, Train loss: 1.479, Test loss: 1.511, Test accuracy: 95.25
Round  75, Train loss: 1.478, Test loss: 1.510, Test accuracy: 95.27
Round  76, Train loss: 1.477, Test loss: 1.510, Test accuracy: 95.31
Round  77, Train loss: 1.476, Test loss: 1.510, Test accuracy: 95.31
Round  78, Train loss: 1.478, Test loss: 1.510, Test accuracy: 95.33
Round  79, Train loss: 1.476, Test loss: 1.510, Test accuracy: 95.28
Round  80, Train loss: 1.475, Test loss: 1.510, Test accuracy: 95.35
Round  81, Train loss: 1.476, Test loss: 1.510, Test accuracy: 95.25
Round  82, Train loss: 1.478, Test loss: 1.510, Test accuracy: 95.28
Round  83, Train loss: 1.476, Test loss: 1.509, Test accuracy: 95.34
Round  84, Train loss: 1.475, Test loss: 1.509, Test accuracy: 95.34
Round  85, Train loss: 1.475, Test loss: 1.509, Test accuracy: 95.33
Round  86, Train loss: 1.475, Test loss: 1.509, Test accuracy: 95.36
Round  87, Train loss: 1.473, Test loss: 1.509, Test accuracy: 95.35
Round  88, Train loss: 1.474, Test loss: 1.509, Test accuracy: 95.40
Round  89, Train loss: 1.475, Test loss: 1.509, Test accuracy: 95.37
Round  90, Train loss: 1.474, Test loss: 1.508, Test accuracy: 95.44
Round  91, Train loss: 1.473, Test loss: 1.508, Test accuracy: 95.51
Round  92, Train loss: 1.475, Test loss: 1.508, Test accuracy: 95.42
Round  93, Train loss: 1.474, Test loss: 1.508, Test accuracy: 95.47
Round  94, Train loss: 1.472, Test loss: 1.508, Test accuracy: 95.47
Round  95, Train loss: 1.473, Test loss: 1.508, Test accuracy: 95.53
Round  96, Train loss: 1.476, Test loss: 1.508, Test accuracy: 95.36
Round  97, Train loss: 1.475, Test loss: 1.508, Test accuracy: 95.47
Round  98, Train loss: 1.474, Test loss: 1.508, Test accuracy: 95.46
Round  99, Train loss: 1.475, Test loss: 1.507, Test accuracy: 95.49
Final Round, Train loss: 1.472, Test loss: 1.507, Test accuracy: 95.48
Average accuracy final 10 rounds: 95.4615
3427.0649316310883
[5.060159206390381, 10.038455724716187, 15.08556866645813, 20.119001388549805, 25.124231815338135, 30.196033477783203, 35.27259635925293, 40.251373291015625, 45.270726680755615, 50.304190158843994, 55.304973125457764, 60.3621141910553, 65.42319059371948, 70.4090256690979, 75.00563359260559, 79.62862944602966, 84.35839128494263, 89.00080513954163, 93.69320774078369, 98.3708872795105, 103.02340912818909, 107.71899747848511, 112.28668212890625, 116.87570571899414, 121.49908709526062, 126.12807512283325, 130.86649632453918, 135.41182327270508, 140.0407145023346, 144.85313439369202, 149.49091029167175, 154.03716325759888, 158.61931228637695, 163.17402386665344, 167.8067729473114, 172.43560457229614, 176.94247889518738, 181.56592440605164, 186.10170674324036, 190.62853407859802, 195.52823162078857, 200.37100625038147, 204.95419263839722, 209.6472237110138, 214.32226848602295, 219.00373935699463, 223.6005368232727, 228.27503609657288, 232.9253306388855, 237.55790209770203, 242.29491233825684, 247.33841848373413, 252.2971897125244, 257.34910130500793, 262.31728768348694, 267.2268521785736, 272.1972813606262, 277.0455856323242, 281.91997480392456, 286.8131048679352, 291.70893144607544, 296.6321804523468, 301.3113052845001, 305.9297504425049, 310.541086435318, 315.23972964286804, 319.9755265712738, 324.5727152824402, 329.23174595832825, 333.8322377204895, 338.4511134624481, 342.98878264427185, 347.6709530353546, 352.226913690567, 356.85153460502625, 361.4487113952637, 366.05065393447876, 370.6482584476471, 375.2630949020386, 379.82237935066223, 384.3998672962189, 388.9304983615875, 393.5504558086395, 398.0939054489136, 402.6434681415558, 407.253525018692, 411.8075931072235, 416.35772037506104, 420.93733954429626, 425.4872486591339, 429.9897689819336, 434.4830856323242, 438.9620370864868, 443.4823327064514, 448.04882168769836, 452.5990300178528, 457.1362295150757, 461.6829092502594, 466.2602093219757, 470.83088302612305, 473.12159991264343]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[27.525, 34.615, 63.27, 65.46, 72.05, 74.09, 86.915, 87.92, 88.87, 89.38, 90.155, 90.5, 90.95, 91.24, 91.43, 91.705, 92.065, 92.13, 92.225, 92.29, 92.59, 92.895, 92.905, 92.985, 93.245, 93.43, 93.49, 93.325, 93.695, 93.675, 93.95, 93.9, 93.8, 93.87, 94.065, 94.14, 94.245, 94.435, 94.49, 94.635, 94.595, 94.57, 94.56, 94.53, 94.645, 94.595, 94.61, 94.855, 94.81, 94.81, 94.755, 94.965, 95.05, 94.99, 95.04, 94.94, 95.04, 94.975, 95.035, 95.03, 95.165, 95.14, 95.15, 95.125, 95.105, 95.175, 95.125, 95.22, 95.22, 95.25, 95.22, 95.2, 95.305, 95.285, 95.245, 95.27, 95.315, 95.31, 95.325, 95.275, 95.35, 95.25, 95.28, 95.345, 95.345, 95.33, 95.36, 95.35, 95.4, 95.37, 95.44, 95.51, 95.42, 95.465, 95.475, 95.525, 95.355, 95.475, 95.46, 95.49, 95.485]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 400, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round   0, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round   1, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round   1, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round   2, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round   2, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round   3, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round   3, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round   4, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round   4, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round   5, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round   5, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round   6, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round   6, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round   7, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round   7, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round   8, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round   8, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round   9, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round   9, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  10, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  10, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  11, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  11, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  12, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  12, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  13, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  13, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  14, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  14, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  15, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  15, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  16, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  16, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  17, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  17, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  18, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  18, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  19, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  19, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  20, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  20, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  21, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  21, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  22, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  22, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  23, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  23, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  24, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  24, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  25, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  25, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  26, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  26, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  27, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  27, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  28, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  28, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  29, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  29, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  30, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  30, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  31, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  31, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  32, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  32, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  33, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  33, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  34, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  34, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  35, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  35, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  36, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  36, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  37, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  37, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  38, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  38, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  39, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  39, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  40, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  40, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  41, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  41, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  42, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  42, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  43, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  43, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  44, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  44, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  45, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  45, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  46, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  46, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  47, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  47, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  48, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  48, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  49, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  49, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  50, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  50, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  51, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  51, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  52, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round  52, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.00
Round  53, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.00
Round  53, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.00
Round  54, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.00
Round  54, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.00
Round  55, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.00
Round  55, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  56, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.00
Round  56, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  57, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.00
Round  57, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  58, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  58, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  59, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  59, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  60, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  60, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  61, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  61, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  62, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  62, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  63, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  63, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  64, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  64, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  65, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  65, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  66, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  66, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  67, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  67, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  68, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  68, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  69, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  69, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  70, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  70, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  71, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  71, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  72, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  72, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  73, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  73, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  74, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  74, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  75, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  75, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  76, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  76, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  77, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  77, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  78, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  78, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  79, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  79, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  80, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  80, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  81, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  81, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  82, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  82, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  83, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  83, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  84, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  84, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  85, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  85, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  86, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  86, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  87, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  87, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  88, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  88, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  89, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  89, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  90, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  90, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  91, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  91, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  92, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  92, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  93, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  93, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  94, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  94, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  95, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  95, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  96, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  96, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  97, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  97, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  98, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  98, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round  99, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round  99, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round 100, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round 100, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round 101, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round 101, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round 102, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round 102, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round 103, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round 103, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round 104, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round 104, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round 105, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round 105, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round 106, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round 106, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round 107, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round 107, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round 108, Train loss: 2.300, Test loss: 2.301, Test accuracy: 10.00
Round 108, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 10.00
Round 109, Train loss: 2.301, Test loss: 2.301, Test accuracy: 10.00
Round 109, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 10.00
Round 110, Train loss: 2.300, Test loss: 2.301, Test accuracy: 10.00
Round 110, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 10.00
Round 111, Train loss: 2.300, Test loss: 2.301, Test accuracy: 10.00
Round 111, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 10.00
Round 112, Train loss: 2.300, Test loss: 2.301, Test accuracy: 10.00
Round 112, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.00
Round 113, Train loss: 2.300, Test loss: 2.301, Test accuracy: 10.00
Round 113, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.00
Round 114, Train loss: 2.300, Test loss: 2.301, Test accuracy: 10.00
Round 114, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.00
Round 115, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.00
Round 115, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.00
Round 116, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.00
Round 116, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.00
Round 117, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.00
Round 117, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.00
Round 118, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.00
Round 118, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.00
Round 119, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.00
Round 119, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.00
Round 120, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.00
Round 120, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.00
Round 121, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.00
Round 121, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.00
Round 122, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.00
Round 122, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.00
Round 123, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.00
Round 123, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.00
Round 124, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.00
Round 124, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.00
Round 125, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.00
Round 125, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.00
Round 126, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.00
Round 126, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.00
Round 127, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.00
Round 127, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.00
Round 128, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.00
Round 128, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.00
Round 129, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.00
Round 129, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.00
Round 130, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.00
Round 130, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.00
Round 131, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.00
Round 131, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.00
Round 132, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.01
Round 132, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.00
Round 133, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.01
Round 133, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.01
Round 134, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.01
Round 134, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.01
Round 135, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.01
Round 135, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.01
Round 136, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.01
Round 136, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.01
Round 137, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.01
Round 137, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.01
Round 138, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.01
Round 138, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.01
Round 139, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.01
Round 139, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.01
Round 140, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.01
Round 140, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.01
Round 141, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.01
Round 141, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.01
Round 142, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.01
Round 142, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.01
Round 143, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.01
Round 143, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.01
Round 144, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.01
Round 144, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.01
Round 145, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.01
Round 145, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.01
Round 146, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.01
Round 146, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.01
Round 147, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.01
Round 147, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.01
Round 148, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.01
Round 148, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.01
Round 149, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.01
Round 149, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.02
Round 150, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.01
Round 150, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.02
Round 151, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.01
Round 151, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.02
Round 152, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.02
Round 152, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.02
Round 153, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.02
Round 153, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.02
Round 154, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.02
Round 154, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.02
Round 155, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.02
Round 155, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.02
Round 156, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.02
Round 156, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.02
Round 157, Train loss: 2.299, Test loss: 2.300, Test accuracy: 10.02
Round 157, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 10.02
Round 158, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.02
Round 158, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.02
Round 159, Train loss: 2.300, Test loss: 2.300, Test accuracy: 10.02
Round 159, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.02
Round 160, Train loss: 2.299, Test loss: 2.300, Test accuracy: 10.02
Round 160, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 10.02
Round 161, Train loss: 2.299, Test loss: 2.300, Test accuracy: 10.02
Round 161, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 10.02
Round 162, Train loss: 2.299, Test loss: 2.300, Test accuracy: 10.02
Round 162, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 10.02
Round 163, Train loss: 2.299, Test loss: 2.300, Test accuracy: 10.02
Round 163, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.02
Round 164, Train loss: 2.299, Test loss: 2.300, Test accuracy: 10.02
Round 164, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.02
Round 165, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.02
Round 165, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.02
Round 166, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.02
Round 166, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.02
Round 167, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.02
Round 167, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.02
Round 168, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.02
Round 168, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.02
Round 169, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.02
Round 169, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.02
Round 170, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.02
Round 170, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.02
Round 171, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.02
Round 171, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.02
Round 172, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.02
Round 172, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.02
Round 173, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.02
Round 173, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 174, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 174, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 175, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 175, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 176, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 176, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 177, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 177, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 178, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 178, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 179, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 179, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 180, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 180, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 181, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 181, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 182, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 182, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 183, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 183, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 184, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 184, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 185, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 185, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 186, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 186, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 187, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 187, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 188, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 188, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 189, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 189, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 190, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 190, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 191, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 191, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 192, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 192, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 193, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 193, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 194, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 194, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 195, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 195, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 196, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 196, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 197, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 197, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 198, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 198, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 199, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 199, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 200, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 200, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 201, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 201, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 202, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 202, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 203, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 203, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 204, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 204, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 205, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 205, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 10.03
Round 206, Train loss: 2.298, Test loss: 2.299, Test accuracy: 10.03
Round 206, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 10.03
Round 207, Train loss: 2.299, Test loss: 2.299, Test accuracy: 10.03
Round 207, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 10.03
Round 208, Train loss: 2.298, Test loss: 2.299, Test accuracy: 10.03
Round 208, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.03
Round 209, Train loss: 2.298, Test loss: 2.299, Test accuracy: 10.03
Round 209, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.03
Round 210, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.03
Round 210, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.03
Round 211, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.03
Round 211, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.03
Round 212, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.03
Round 212, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.03
Round 213, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.03
Round 213, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.03
Round 214, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.03
Round 214, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.03
Round 215, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.03
Round 215, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.03
Round 216, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.03
Round 216, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.03
Round 217, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.03
Round 217, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.04
Round 218, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.03
Round 218, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.04
Round 219, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.03
Round 219, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.04
Round 220, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.04
Round 220, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.04
Round 221, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.04
Round 221, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.04
Round 222, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.04
Round 222, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.04
Round 223, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.04
Round 223, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.04
Round 224, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.04
Round 224, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.04
Round 225, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.04
Round 225, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.04
Round 226, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.04
Round 226, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.04
Round 227, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.04
Round 227, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.04
Round 228, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.04
Round 228, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.04
Round 229, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.04
Round 229, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.04
Round 230, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.04
Round 230, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.04
Round 231, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.04
Round 231, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.04
Round 232, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.04
Round 232, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.04
Round 233, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.04
Round 233, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.04
Round 234, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.04
Round 234, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.04
Round 235, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.04
Round 235, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.05
Round 236, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.04
Round 236, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.05
Round 237, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.05
Round 237, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.05
Round 238, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.05
Round 238, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.05
Round 239, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.05
Round 239, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.05
Round 240, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.05
Round 240, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.05
Round 241, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.05
Round 241, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.05
Round 242, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.05
Round 242, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.05
Round 243, Train loss: 2.297, Test loss: 2.298, Test accuracy: 10.05
Round 243, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 10.05
Round 244, Train loss: 2.298, Test loss: 2.298, Test accuracy: 10.05
Round 244, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 10.05
Round 245, Train loss: 2.297, Test loss: 2.298, Test accuracy: 10.05
Round 245, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 10.05
Round 246, Train loss: 2.297, Test loss: 2.298, Test accuracy: 10.05
Round 246, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 247, Train loss: 2.297, Test loss: 2.298, Test accuracy: 10.05
Round 247, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 248, Train loss: 2.298, Test loss: 2.297, Test accuracy: 10.05
Round 248, Global train loss: 2.298, Global test loss: 2.297, Global test accuracy: 10.05
Round 249, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 249, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 250, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 250, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 251, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 251, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 252, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 252, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 253, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 253, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 254, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 254, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 255, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 255, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 256, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 256, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 257, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 257, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 258, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 258, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 259, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 259, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 260, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 260, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 261, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 261, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 262, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 262, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 263, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 263, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 264, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 264, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 265, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 265, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 266, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 266, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 267, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 267, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 268, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 268, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 269, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 269, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 270, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 270, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 271, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 271, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 272, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 272, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 273, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 273, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 274, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 274, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 275, Train loss: 2.296, Test loss: 2.297, Test accuracy: 10.05
Round 275, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 10.05
Round 276, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 276, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 277, Train loss: 2.296, Test loss: 2.297, Test accuracy: 10.05
Round 277, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 10.05
Round 278, Train loss: 2.297, Test loss: 2.297, Test accuracy: 10.05
Round 278, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 10.05
Round 279, Train loss: 2.296, Test loss: 2.297, Test accuracy: 10.05
Round 279, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.05
Round 280, Train loss: 2.296, Test loss: 2.297, Test accuracy: 10.05
Round 280, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.05
Round 281, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.05
Round 281, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.05
Round 282, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.05
Round 282, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.05
Round 283, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.05
Round 283, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.05
Round 284, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.05
Round 284, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.05
Round 285, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.05
Round 285, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.05
Round 286, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.05
Round 286, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.05
Round 287, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.05
Round 287, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.05
Round 288, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.05
Round 288, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.05
Round 289, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.05
Round 289, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.05
Round 290, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.05
Round 290, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.05
Round 291, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.05
Round 291, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.05
Round 292, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.05
Round 292, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.05
Round 293, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.05
Round 293, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.05
Round 294, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.05
Round 294, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.05
Round 295, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.05
Round 295, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.05
Round 296, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.06
Round 296, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.05
Round 297, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.05
Round 297, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.08
Round 298, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.06
Round 298, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.08
Round 299, Train loss: 2.295, Test loss: 2.296, Test accuracy: 10.06
Round 299, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 10.08
Round 300, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.07
Round 300, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.08
Round 301, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.07
Round 301, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.08
Round 302, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.08
Round 302, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.08
Round 303, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.08
Round 303, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.08
Round 304, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.08
Round 304, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.08
Round 305, Train loss: 2.296, Test loss: 2.296, Test accuracy: 10.08
Round 305, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.08
Round 306, Train loss: 2.295, Test loss: 2.296, Test accuracy: 10.08
Round 306, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 10.08
Round 307, Train loss: 2.295, Test loss: 2.296, Test accuracy: 10.08
Round 307, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 10.08
Round 308, Train loss: 2.295, Test loss: 2.296, Test accuracy: 10.08
Round 308, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 10.08
Round 309, Train loss: 2.295, Test loss: 2.296, Test accuracy: 10.08
Round 309, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 10.08
Round 310, Train loss: 2.295, Test loss: 2.295, Test accuracy: 10.08
Round 310, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 10.08
Round 311, Train loss: 2.295, Test loss: 2.295, Test accuracy: 10.08
Round 311, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 10.08
Round 312, Train loss: 2.295, Test loss: 2.295, Test accuracy: 10.08
Round 312, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 10.08
Round 313, Train loss: 2.295, Test loss: 2.295, Test accuracy: 10.08
Round 313, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 10.08
Round 314, Train loss: 2.295, Test loss: 2.295, Test accuracy: 10.08
Round 314, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 10.08
Round 315, Train loss: 2.295, Test loss: 2.295, Test accuracy: 10.08
Round 315, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 10.08
Round 316, Train loss: 2.295, Test loss: 2.295, Test accuracy: 10.08
Round 316, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 10.08
Round 317, Train loss: 2.295, Test loss: 2.295, Test accuracy: 10.08
Round 317, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 10.08
Round 318, Train loss: 2.295, Test loss: 2.295, Test accuracy: 10.08
Round 318, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 10.08
Round 319, Train loss: 2.295, Test loss: 2.295, Test accuracy: 10.08
Round 319, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 10.08
Round 320, Train loss: 2.295, Test loss: 2.295, Test accuracy: 10.08
Round 320, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 10.08
Round 321, Train loss: 2.295, Test loss: 2.295, Test accuracy: 10.08
Round 321, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 10.08
Round 322, Train loss: 2.295, Test loss: 2.295, Test accuracy: 10.08
Round 322, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 10.08
Round 323, Train loss: 2.295, Test loss: 2.295, Test accuracy: 10.08
Round 323, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 10.08
Round 324, Train loss: 2.295, Test loss: 2.295, Test accuracy: 10.08
Round 324, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 10.08
Round 325, Train loss: 2.295, Test loss: 2.295, Test accuracy: 10.08
Round 325, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 10.08
Round 326, Train loss: 2.295, Test loss: 2.295, Test accuracy: 10.08
Round 326, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 10.08
Round 327, Train loss: 2.295, Test loss: 2.295, Test accuracy: 10.08
Round 327, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 10.08
Round 328, Train loss: 2.295, Test loss: 2.295, Test accuracy: 10.08
Round 328, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 10.08
Round 329, Train loss: 2.294, Test loss: 2.295, Test accuracy: 10.08
Round 329, Global train loss: 2.294, Global test loss: 2.295, Global test accuracy: 10.08
Round 330, Train loss: 2.294, Test loss: 2.295, Test accuracy: 10.08
Round 330, Global train loss: 2.294, Global test loss: 2.295, Global test accuracy: 10.08
Round 331, Train loss: 2.295, Test loss: 2.295, Test accuracy: 10.08
Round 331, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 10.08
Round 332, Train loss: 2.294, Test loss: 2.295, Test accuracy: 10.09
Round 332, Global train loss: 2.294, Global test loss: 2.295, Global test accuracy: 10.08
Round 333, Train loss: 2.295, Test loss: 2.295, Test accuracy: 10.09
Round 333, Global train loss: 2.295, Global test loss: 2.294, Global test accuracy: 10.08
Round 334, Train loss: 2.294, Test loss: 2.295, Test accuracy: 10.09
Round 334, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 10.11
Round 335, Train loss: 2.294, Test loss: 2.294, Test accuracy: 10.09
Round 335, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 10.11
Round 336, Train loss: 2.294, Test loss: 2.294, Test accuracy: 10.09
Round 336, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 10.11
Round 337, Train loss: 2.294, Test loss: 2.294, Test accuracy: 10.10
Round 337, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 10.11
Round 338, Train loss: 2.294, Test loss: 2.294, Test accuracy: 10.10
Round 338, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 10.11
Round 339, Train loss: 2.294, Test loss: 2.294, Test accuracy: 10.10
Round 339, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 10.11
Round 340, Train loss: 2.294, Test loss: 2.294, Test accuracy: 10.11
Round 340, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 10.11
Round 341, Train loss: 2.294, Test loss: 2.294, Test accuracy: 10.12
Round 341, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 10.11
Round 342, Train loss: 2.294, Test loss: 2.294, Test accuracy: 10.11
Round 342, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 10.11
Round 343, Train loss: 2.294, Test loss: 2.294, Test accuracy: 10.11
Round 343, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 10.12
Round 344, Train loss: 2.294, Test loss: 2.294, Test accuracy: 10.11
Round 344, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 10.11
Round 345, Train loss: 2.294, Test loss: 2.294, Test accuracy: 10.11
Round 345, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 10.11
Round 346, Train loss: 2.294, Test loss: 2.294, Test accuracy: 10.11
Round 346, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 10.12
Round 347, Train loss: 2.294, Test loss: 2.294, Test accuracy: 10.11
Round 347, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 10.09
Round 348, Train loss: 2.294, Test loss: 2.294, Test accuracy: 10.11
Round 348, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 10.11
Round 349, Train loss: 2.294, Test loss: 2.294, Test accuracy: 10.12
Round 349, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 10.13
Round 350, Train loss: 2.294, Test loss: 2.294, Test accuracy: 10.12
Round 350, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 10.13
Round 351, Train loss: 2.294, Test loss: 2.294, Test accuracy: 10.12
Round 351, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 10.13
Round 352, Train loss: 2.293, Test loss: 2.294, Test accuracy: 10.12
Round 352, Global train loss: 2.293, Global test loss: 2.294, Global test accuracy: 10.13
Round 353, Train loss: 2.293, Test loss: 2.294, Test accuracy: 10.11
Round 353, Global train loss: 2.293, Global test loss: 2.294, Global test accuracy: 10.13
Round 354, Train loss: 2.293, Test loss: 2.294, Test accuracy: 10.11
Round 354, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 10.13
Round 355, Train loss: 2.293, Test loss: 2.294, Test accuracy: 10.12
Round 355, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 10.13
Round 356, Train loss: 2.293, Test loss: 2.293, Test accuracy: 10.13
Round 356, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 10.14
Round 357, Train loss: 2.293, Test loss: 2.293, Test accuracy: 10.12
Round 357, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 10.11
Round 358, Train loss: 2.293, Test loss: 2.293, Test accuracy: 10.12
Round 358, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 10.14
Round 359, Train loss: 2.293, Test loss: 2.293, Test accuracy: 10.12
Round 359, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 10.14
Round 360, Train loss: 2.293, Test loss: 2.293, Test accuracy: 10.12
Round 360, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 10.14
Round 361, Train loss: 2.293, Test loss: 2.293, Test accuracy: 10.12
Round 361, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 10.12
Round 362, Train loss: 2.293, Test loss: 2.293, Test accuracy: 10.13
Round 362, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 10.14
Round 363, Train loss: 2.293, Test loss: 2.293, Test accuracy: 10.13
Round 363, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 10.14
Round 364, Train loss: 2.293, Test loss: 2.293, Test accuracy: 10.12
Round 364, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 10.12
Round 365, Train loss: 2.293, Test loss: 2.293, Test accuracy: 10.12
Round 365, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 10.13
Round 366, Train loss: 2.293, Test loss: 2.293, Test accuracy: 10.12
Round 366, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 10.13
Round 367, Train loss: 2.293, Test loss: 2.293, Test accuracy: 10.12
Round 367, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 10.11
Round 368, Train loss: 2.293, Test loss: 2.293, Test accuracy: 10.12
Round 368, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 10.11
Round 369, Train loss: 2.292, Test loss: 2.293, Test accuracy: 10.12
Round 369, Global train loss: 2.292, Global test loss: 2.293, Global test accuracy: 10.09
Round 370, Train loss: 2.293, Test loss: 2.293, Test accuracy: 10.10
Round 370, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 10.09
Round 371, Train loss: 2.293, Test loss: 2.293, Test accuracy: 10.10
Round 371, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 10.09
Round 372, Train loss: 2.293, Test loss: 2.293, Test accuracy: 10.10
Round 372, Global train loss: 2.293, Global test loss: 2.293, Global test accuracy: 10.09
Round 373, Train loss: 2.292, Test loss: 2.293, Test accuracy: 10.10
Round 373, Global train loss: 2.292, Global test loss: 2.292, Global test accuracy: 10.10
Round 374, Train loss: 2.292, Test loss: 2.293, Test accuracy: 10.10
Round 374, Global train loss: 2.292, Global test loss: 2.292, Global test accuracy: 10.09
Round 375, Train loss: 2.292, Test loss: 2.293, Test accuracy: 10.10
Round 375, Global train loss: 2.292, Global test loss: 2.292, Global test accuracy: 10.08
Round 376, Train loss: 2.292, Test loss: 2.292, Test accuracy: 10.09
Round 376, Global train loss: 2.292, Global test loss: 2.292, Global test accuracy: 10.08
Round 377, Train loss: 2.292, Test loss: 2.292, Test accuracy: 10.09
Round 377, Global train loss: 2.292, Global test loss: 2.292, Global test accuracy: 10.08
Round 378, Train loss: 2.292, Test loss: 2.292, Test accuracy: 10.09
Round 378, Global train loss: 2.292, Global test loss: 2.292, Global test accuracy: 10.08
Round 379, Train loss: 2.292, Test loss: 2.292, Test accuracy: 10.08
Round 379, Global train loss: 2.292, Global test loss: 2.292, Global test accuracy: 10.08
Round 380, Train loss: 2.292, Test loss: 2.292, Test accuracy: 10.08
Round 380, Global train loss: 2.292, Global test loss: 2.292, Global test accuracy: 10.08
Round 381, Train loss: 2.292, Test loss: 2.292, Test accuracy: 10.08
Round 381, Global train loss: 2.292, Global test loss: 2.292, Global test accuracy: 10.08
Round 382, Train loss: 2.292, Test loss: 2.292, Test accuracy: 10.08
Round 382, Global train loss: 2.292, Global test loss: 2.292, Global test accuracy: 10.08
Round 383, Train loss: 2.292, Test loss: 2.292, Test accuracy: 10.08
Round 383, Global train loss: 2.292, Global test loss: 2.292, Global test accuracy: 10.08
Round 384, Train loss: 2.292, Test loss: 2.292, Test accuracy: 10.09
Round 384, Global train loss: 2.292, Global test loss: 2.292, Global test accuracy: 10.08
Round 385, Train loss: 2.292, Test loss: 2.292, Test accuracy: 10.09
Round 385, Global train loss: 2.292, Global test loss: 2.292, Global test accuracy: 10.08
Round 386, Train loss: 2.291, Test loss: 2.292, Test accuracy: 10.09
Round 386, Global train loss: 2.291, Global test loss: 2.292, Global test accuracy: 10.10
Round 387, Train loss: 2.291, Test loss: 2.292, Test accuracy: 10.08
Round 387, Global train loss: 2.291, Global test loss: 2.292, Global test accuracy: 10.08
Round 388, Train loss: 2.291, Test loss: 2.292, Test accuracy: 10.09
Round 388, Global train loss: 2.291, Global test loss: 2.291, Global test accuracy: 10.10
Round 389, Train loss: 2.292, Test loss: 2.292, Test accuracy: 10.09
Round 389, Global train loss: 2.292, Global test loss: 2.291, Global test accuracy: 10.10
Round 390, Train loss: 2.291, Test loss: 2.291, Test accuracy: 10.09
Round 390, Global train loss: 2.291, Global test loss: 2.291, Global test accuracy: 10.10
Round 391, Train loss: 2.291, Test loss: 2.291, Test accuracy: 10.09
Round 391, Global train loss: 2.291, Global test loss: 2.291, Global test accuracy: 10.10
Round 392, Train loss: 2.291, Test loss: 2.291, Test accuracy: 10.09
Round 392, Global train loss: 2.291, Global test loss: 2.291, Global test accuracy: 10.10
Round 393, Train loss: 2.291, Test loss: 2.291, Test accuracy: 10.09
Round 393, Global train loss: 2.291, Global test loss: 2.291, Global test accuracy: 10.10
Round 394, Train loss: 2.291, Test loss: 2.291, Test accuracy: 10.09
Round 394, Global train loss: 2.291, Global test loss: 2.291, Global test accuracy: 10.08
Round 395, Train loss: 2.291, Test loss: 2.291, Test accuracy: 10.08
Round 395, Global train loss: 2.291, Global test loss: 2.291, Global test accuracy: 10.08
Round 396, Train loss: 2.291, Test loss: 2.291, Test accuracy: 10.09
Round 396, Global train loss: 2.291, Global test loss: 2.291, Global test accuracy: 10.08
Round 397, Train loss: 2.291, Test loss: 2.291, Test accuracy: 10.08
Round 397, Global train loss: 2.291, Global test loss: 2.291, Global test accuracy: 10.08
Round 398, Train loss: 2.291, Test loss: 2.291, Test accuracy: 10.06
Round 398, Global train loss: 2.291, Global test loss: 2.291, Global test accuracy: 10.07
Round 399, Train loss: 2.291, Test loss: 2.291, Test accuracy: 10.06
Round 399, Global train loss: 2.291, Global test loss: 2.291, Global test accuracy: 10.07
Final Round, Train loss: 2.290, Test loss: 2.291, Test accuracy: 10.07
Final Round, Global train loss: 2.290, Global test loss: 2.291, Global test accuracy: 10.07
Average accuracy final 10 rounds: 10.081499999999998 

Average global accuracy final 10 rounds: 10.084 

9377.81186413765
[2.1006152629852295, 3.9615936279296875, 6.009938478469849, 7.882018089294434, 9.80539870262146, 11.669479608535767, 13.553946018218994, 15.440077781677246, 17.319217443466187, 19.25056743621826, 21.155963897705078, 23.073059558868408, 25.00664186477661, 26.918464183807373, 29.02375030517578, 31.161410570144653, 33.24550199508667, 35.287647008895874, 37.31881904602051, 39.29591727256775, 41.216612815856934, 43.115230560302734, 45.02863836288452, 46.93217182159424, 48.820106744766235, 50.695398807525635, 52.67121434211731, 54.505412340164185, 56.379459857940674, 58.301812171936035, 60.151763677597046, 61.95761013031006, 63.8702118396759, 65.79708433151245, 67.60803389549255, 69.50903367996216, 71.4151496887207, 73.3804202079773, 75.28388094902039, 77.13301610946655, 79.26807260513306, 81.37133049964905, 83.40736293792725, 85.51978278160095, 87.72548174858093, 89.81525778770447, 91.92185688018799, 93.83383011817932, 95.80559992790222, 97.65379929542542, 99.49596738815308, 101.44955134391785, 103.3896234035492, 105.28571224212646, 107.25249123573303, 109.34607934951782, 111.56104922294617, 113.66319680213928, 115.68820214271545, 117.86996006965637, 120.00813603401184, 122.09002494812012, 124.1542136669159, 126.36865210533142, 128.49982166290283, 130.6409294605255, 132.63378930091858, 134.76689672470093, 136.88591980934143, 138.9634187221527, 141.0266993045807, 143.07842826843262, 145.22639346122742, 147.31751108169556, 149.4458873271942, 151.52408576011658, 153.67987084388733, 155.56931018829346, 157.4257972240448, 159.2806236743927, 161.17371034622192, 162.98549151420593, 164.8735649585724, 166.8496150970459, 168.7720115184784, 170.6125328540802, 172.5201554298401, 174.47011995315552, 176.28828978538513, 178.1986494064331, 180.12250995635986, 181.92713713645935, 183.7828197479248, 185.7036988735199, 187.54946756362915, 189.44681239128113, 191.38022327423096, 193.20370173454285, 195.02858424186707, 196.91713953018188, 198.76870799064636, 200.65068936347961, 202.47381806373596, 204.36682653427124, 206.20942163467407, 208.05904984474182, 209.89857172966003, 211.72831559181213, 213.67699551582336, 215.53450441360474, 217.47416973114014, 219.37808203697205, 221.21618676185608, 223.0619888305664, 224.98055171966553, 226.80303382873535, 228.68776392936707, 230.58697152137756, 232.4645233154297, 234.40569305419922, 236.31238198280334, 238.18815660476685, 240.05007123947144, 241.9738326072693, 243.80468010902405, 245.69331002235413, 247.56719160079956, 249.36950612068176, 251.1837773323059, 253.0518443584442, 254.90488243103027, 256.75762701034546, 258.63228964805603, 260.43084740638733, 262.2510943412781, 264.11732053756714, 265.9512405395508, 267.79935336112976, 269.6438322067261, 271.47092509269714, 273.318519115448, 275.17913031578064, 277.07191038131714, 278.91687178611755, 280.7081620693207, 282.5384428501129, 284.3400707244873, 286.23221015930176, 288.10760855674744, 289.93399572372437, 291.7687864303589, 293.5752420425415, 295.3674416542053, 297.2187433242798, 299.1460313796997, 300.9538838863373, 302.7953977584839, 304.67487478256226, 306.51894307136536, 308.31783270835876, 310.2004919052124, 312.0639503002167, 313.8755748271942, 315.7368347644806, 317.60281229019165, 319.3931088447571, 321.2719647884369, 323.15959119796753, 325.0384294986725, 326.9228894710541, 328.6838927268982, 330.6789131164551, 332.74485540390015, 334.7919192314148, 336.83862686157227, 338.8569641113281, 340.822598695755, 342.66337847709656, 344.506796836853, 346.3730375766754, 348.23821330070496, 350.0918583869934, 351.9287004470825, 354.0854778289795, 355.88301849365234, 357.65270161628723, 359.5812373161316, 361.5250189304352, 363.4201512336731, 365.3480386734009, 367.2825093269348, 369.05180764198303, 370.87077260017395, 372.71731758117676, 374.5859444141388, 376.39362955093384, 378.26491689682007, 380.14857935905457, 382.00905680656433, 383.89050579071045, 385.68851685523987, 387.5769121646881, 389.4629399776459, 391.3326458930969, 393.2516713142395, 395.114289522171, 396.92642307281494, 398.73853278160095, 400.59354543685913, 402.4468472003937, 404.3255078792572, 406.21647334098816, 408.1943175792694, 410.1881203651428, 412.18648648262024, 414.05952405929565, 415.82968759536743, 417.7230393886566, 419.6164493560791, 421.5134541988373, 423.35521721839905, 425.1948685646057, 427.0729899406433, 428.9289503097534, 430.79183769226074, 432.71386528015137, 434.5751271247864, 436.49312376976013, 438.40571570396423, 440.33201909065247, 442.27386832237244, 444.14847779273987, 445.93628549575806, 447.71184945106506, 449.5877914428711, 451.45588755607605, 453.4240691661835, 455.36403632164, 457.2662887573242, 459.131694316864, 461.0299246311188, 462.85333013534546, 464.7643005847931, 466.67000246047974, 468.5844831466675, 470.4823377132416, 472.324006319046, 474.20557928085327, 476.0755846500397, 477.8732645511627, 479.6421148777008, 481.48365449905396, 483.4339382648468, 485.4163534641266, 487.3709990978241, 489.33735370635986, 491.20245337486267, 493.0845229625702, 494.95299243927, 496.82216119766235, 498.68478417396545, 500.4882893562317, 502.359561920166, 504.25866651535034, 506.16297459602356, 508.02584075927734, 509.8348467350006, 511.68193459510803, 513.581577539444, 515.4802374839783, 517.4018979072571, 519.3066761493683, 521.2262308597565, 523.1407980918884, 525.0157191753387, 526.8609235286713, 528.6336348056793, 530.4427285194397, 532.4691145420074, 534.6294012069702, 536.6730051040649, 538.7616438865662, 540.8624219894409, 543.0924384593964, 545.2926528453827, 547.4463815689087, 549.5833313465118, 551.674135684967, 553.7503576278687, 555.8058316707611, 557.8479416370392, 560.1096289157867, 562.3467786312103, 564.5040109157562, 566.6040709018707, 568.6898257732391, 570.8283276557922, 572.9249291419983, 574.7859485149384, 576.6534221172333, 578.4512755870819, 580.2040555477142, 582.0184442996979, 583.8888719081879, 585.7868008613586, 587.622677564621, 589.4750092029572, 591.2715284824371, 593.0617961883545, 594.8925654888153, 596.7420511245728, 598.6130027770996, 600.4563484191895, 602.2632787227631, 604.0603408813477, 605.8861203193665, 607.740873336792, 609.608172416687, 611.4367260932922, 613.3122618198395, 615.1059167385101, 616.9150629043579, 618.7312297821045, 620.5560266971588, 622.362574338913, 624.192423582077, 626.051962852478, 627.8862736225128, 629.6563131809235, 631.4136199951172, 633.2603883743286, 635.1364483833313, 637.0170977115631, 638.805233001709, 640.5335133075714, 642.3645288944244, 644.22016954422, 646.0848610401154, 647.915465593338, 649.7234456539154, 651.5303230285645, 653.3915033340454, 655.1893856525421, 656.9518134593964, 658.7733271121979, 660.6043016910553, 662.406821012497, 664.1577255725861, 665.9730412960052, 667.876496553421, 669.7379140853882, 671.6368854045868, 673.486575126648, 675.3399121761322, 677.4519777297974, 679.5118367671967, 681.5582759380341, 683.6554129123688, 685.7606465816498, 687.9110496044159, 690.0556049346924, 692.1613085269928, 694.2597119808197, 696.3483994007111, 698.4106268882751, 700.3580951690674, 702.1913824081421, 704.0288960933685, 705.8843240737915, 707.7371506690979, 709.6099450588226, 711.4082171916962, 713.2197103500366, 715.0689122676849, 716.9218389987946, 718.7548613548279, 720.5685217380524, 722.3531949520111, 724.168276309967, 726.0556046962738, 727.9576649665833, 729.9233453273773, 731.7442579269409, 733.5703883171082, 735.3956637382507, 737.2981972694397, 739.250284910202, 741.4336609840393, 743.3512151241302, 745.2042768001556, 747.1300115585327, 749.0037877559662, 750.943416595459, 752.8566801548004, 754.8386721611023, 756.7243173122406, 758.6416440010071, 760.471848487854, 762.3436737060547, 764.2939548492432, 766.2547566890717]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.005, 10.005, 10.005, 10.005, 10.005, 10.005, 10.005, 10.005, 10.005, 10.005, 10.005, 10.005, 10.005, 10.005, 10.005, 10.005, 10.005, 10.005, 10.005, 10.005, 10.015, 10.015, 10.015, 10.015, 10.015, 10.015, 10.015, 10.015, 10.015, 10.015, 10.015, 10.015, 10.015, 10.015, 10.015, 10.015, 10.015, 10.02, 10.02, 10.02, 10.02, 10.02, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.025, 10.035, 10.035, 10.035, 10.035, 10.035, 10.035, 10.04, 10.04, 10.04, 10.04, 10.045, 10.04, 10.04, 10.04, 10.04, 10.04, 10.045, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.05, 10.06, 10.055, 10.065, 10.065, 10.075, 10.075, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.08, 10.085, 10.09, 10.09, 10.09, 10.09, 10.095, 10.1, 10.1, 10.105, 10.115, 10.11, 10.11, 10.11, 10.11, 10.11, 10.11, 10.11, 10.115, 10.115, 10.115, 10.115, 10.105, 10.11, 10.12, 10.135, 10.125, 10.125, 10.125, 10.125, 10.12, 10.13, 10.13, 10.125, 10.12, 10.12, 10.12, 10.12, 10.125, 10.1, 10.095, 10.095, 10.1, 10.1, 10.1, 10.09, 10.085, 10.085, 10.08, 10.08, 10.08, 10.08, 10.08, 10.085, 10.085, 10.085, 10.08, 10.085, 10.09, 10.09, 10.09, 10.085, 10.09, 10.085, 10.08, 10.085, 10.08, 10.065, 10.065, 10.07]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.317, Test loss: 2.296, Test accuracy: 17.80
Round   1, Train loss: 2.292, Test loss: 2.282, Test accuracy: 33.45
Round   2, Train loss: 2.262, Test loss: 2.219, Test accuracy: 40.76
Round   3, Train loss: 2.178, Test loss: 2.138, Test accuracy: 55.53
Round   4, Train loss: 2.085, Test loss: 1.992, Test accuracy: 62.37
Round   5, Train loss: 1.922, Test loss: 1.877, Test accuracy: 71.19
Round   6, Train loss: 1.822, Test loss: 1.813, Test accuracy: 73.09
Round   7, Train loss: 1.777, Test loss: 1.776, Test accuracy: 75.77
Round   8, Train loss: 1.741, Test loss: 1.738, Test accuracy: 78.50
Round   9, Train loss: 1.714, Test loss: 1.711, Test accuracy: 80.09
Round  10, Train loss: 1.695, Test loss: 1.691, Test accuracy: 81.26
Round  11, Train loss: 1.683, Test loss: 1.678, Test accuracy: 82.21
Round  12, Train loss: 1.665, Test loss: 1.672, Test accuracy: 82.58
Round  13, Train loss: 1.660, Test loss: 1.665, Test accuracy: 82.94
Round  14, Train loss: 1.647, Test loss: 1.662, Test accuracy: 83.08
Round  15, Train loss: 1.661, Test loss: 1.650, Test accuracy: 83.89
Round  16, Train loss: 1.639, Test loss: 1.647, Test accuracy: 84.04
Round  17, Train loss: 1.632, Test loss: 1.642, Test accuracy: 84.36
Round  18, Train loss: 1.625, Test loss: 1.632, Test accuracy: 85.12
Round  19, Train loss: 1.588, Test loss: 1.613, Test accuracy: 87.44
Round  20, Train loss: 1.572, Test loss: 1.598, Test accuracy: 89.14
Round  21, Train loss: 1.583, Test loss: 1.569, Test accuracy: 92.14
Round  22, Train loss: 1.551, Test loss: 1.560, Test accuracy: 92.98
Round  23, Train loss: 1.549, Test loss: 1.556, Test accuracy: 93.21
Round  24, Train loss: 1.545, Test loss: 1.553, Test accuracy: 93.38
Round  25, Train loss: 1.536, Test loss: 1.551, Test accuracy: 93.68
Round  26, Train loss: 1.539, Test loss: 1.545, Test accuracy: 93.99
Round  27, Train loss: 1.527, Test loss: 1.544, Test accuracy: 94.06
Round  28, Train loss: 1.531, Test loss: 1.541, Test accuracy: 94.26
Round  29, Train loss: 1.531, Test loss: 1.540, Test accuracy: 94.32
Round  30, Train loss: 1.526, Test loss: 1.537, Test accuracy: 94.52
Round  31, Train loss: 1.520, Test loss: 1.537, Test accuracy: 94.55
Round  32, Train loss: 1.526, Test loss: 1.533, Test accuracy: 94.83
Round  33, Train loss: 1.519, Test loss: 1.532, Test accuracy: 94.84
Round  34, Train loss: 1.527, Test loss: 1.530, Test accuracy: 94.98
Round  35, Train loss: 1.514, Test loss: 1.528, Test accuracy: 95.03
Round  36, Train loss: 1.508, Test loss: 1.528, Test accuracy: 95.06
Round  37, Train loss: 1.519, Test loss: 1.527, Test accuracy: 95.16
Round  38, Train loss: 1.506, Test loss: 1.526, Test accuracy: 95.19
Round  39, Train loss: 1.506, Test loss: 1.525, Test accuracy: 95.27
Round  40, Train loss: 1.506, Test loss: 1.524, Test accuracy: 95.33
Round  41, Train loss: 1.501, Test loss: 1.524, Test accuracy: 95.39
Round  42, Train loss: 1.506, Test loss: 1.523, Test accuracy: 95.44
Round  43, Train loss: 1.504, Test loss: 1.522, Test accuracy: 95.51
Round  44, Train loss: 1.505, Test loss: 1.521, Test accuracy: 95.56
Round  45, Train loss: 1.500, Test loss: 1.521, Test accuracy: 95.50
Round  46, Train loss: 1.503, Test loss: 1.520, Test accuracy: 95.52
Round  47, Train loss: 1.502, Test loss: 1.519, Test accuracy: 95.63
Round  48, Train loss: 1.493, Test loss: 1.519, Test accuracy: 95.67
Round  49, Train loss: 1.491, Test loss: 1.518, Test accuracy: 95.64
Round  50, Train loss: 1.493, Test loss: 1.518, Test accuracy: 95.75
Round  51, Train loss: 1.496, Test loss: 1.517, Test accuracy: 95.75
Round  52, Train loss: 1.491, Test loss: 1.517, Test accuracy: 95.82
Round  53, Train loss: 1.497, Test loss: 1.516, Test accuracy: 95.86
Round  54, Train loss: 1.494, Test loss: 1.516, Test accuracy: 95.84
Round  55, Train loss: 1.491, Test loss: 1.515, Test accuracy: 95.89
Round  56, Train loss: 1.493, Test loss: 1.515, Test accuracy: 95.89
Round  57, Train loss: 1.491, Test loss: 1.514, Test accuracy: 95.89
Round  58, Train loss: 1.489, Test loss: 1.514, Test accuracy: 95.92
Round  59, Train loss: 1.488, Test loss: 1.513, Test accuracy: 96.00
Round  60, Train loss: 1.488, Test loss: 1.513, Test accuracy: 96.02
Round  61, Train loss: 1.486, Test loss: 1.513, Test accuracy: 95.98
Round  62, Train loss: 1.491, Test loss: 1.512, Test accuracy: 96.07
Round  63, Train loss: 1.488, Test loss: 1.512, Test accuracy: 96.08
Round  64, Train loss: 1.488, Test loss: 1.512, Test accuracy: 96.05
Round  65, Train loss: 1.485, Test loss: 1.512, Test accuracy: 96.05
Round  66, Train loss: 1.487, Test loss: 1.511, Test accuracy: 96.16
Round  67, Train loss: 1.483, Test loss: 1.510, Test accuracy: 96.18
Round  68, Train loss: 1.485, Test loss: 1.510, Test accuracy: 96.22
Round  69, Train loss: 1.483, Test loss: 1.510, Test accuracy: 96.19
Round  70, Train loss: 1.485, Test loss: 1.509, Test accuracy: 96.20
Round  71, Train loss: 1.484, Test loss: 1.510, Test accuracy: 96.28
Round  72, Train loss: 1.481, Test loss: 1.509, Test accuracy: 96.28
Round  73, Train loss: 1.482, Test loss: 1.509, Test accuracy: 96.23
Round  74, Train loss: 1.479, Test loss: 1.509, Test accuracy: 96.28
Round  75, Train loss: 1.482, Test loss: 1.508, Test accuracy: 96.31
Round  76, Train loss: 1.478, Test loss: 1.508, Test accuracy: 96.36
Round  77, Train loss: 1.481, Test loss: 1.508, Test accuracy: 96.34
Round  78, Train loss: 1.481, Test loss: 1.508, Test accuracy: 96.36
Round  79, Train loss: 1.478, Test loss: 1.508, Test accuracy: 96.45
Round  80, Train loss: 1.478, Test loss: 1.508, Test accuracy: 96.41
Round  81, Train loss: 1.478, Test loss: 1.508, Test accuracy: 96.38
Round  82, Train loss: 1.477, Test loss: 1.507, Test accuracy: 96.43
Round  83, Train loss: 1.481, Test loss: 1.507, Test accuracy: 96.44
Round  84, Train loss: 1.479, Test loss: 1.507, Test accuracy: 96.42
Round  85, Train loss: 1.480, Test loss: 1.506, Test accuracy: 96.50
Round  86, Train loss: 1.479, Test loss: 1.506, Test accuracy: 96.50
Round  87, Train loss: 1.478, Test loss: 1.506, Test accuracy: 96.50
Round  88, Train loss: 1.477, Test loss: 1.506, Test accuracy: 96.49
Round  89, Train loss: 1.476, Test loss: 1.506, Test accuracy: 96.56
Round  90, Train loss: 1.477, Test loss: 1.506, Test accuracy: 96.48
Round  91, Train loss: 1.476, Test loss: 1.506, Test accuracy: 96.51
Round  92, Train loss: 1.478, Test loss: 1.505, Test accuracy: 96.50
Round  93, Train loss: 1.474, Test loss: 1.506, Test accuracy: 96.53
Round  94, Train loss: 1.477, Test loss: 1.505, Test accuracy: 96.55/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  95, Train loss: 1.474, Test loss: 1.505, Test accuracy: 96.52
Round  96, Train loss: 1.478, Test loss: 1.505, Test accuracy: 96.53
Round  97, Train loss: 1.475, Test loss: 1.505, Test accuracy: 96.58
Round  98, Train loss: 1.475, Test loss: 1.505, Test accuracy: 96.54
Round  99, Train loss: 1.475, Test loss: 1.505, Test accuracy: 96.57
Final Round, Train loss: 1.471, Test loss: 1.504, Test accuracy: 96.57
Average accuracy final 10 rounds: 96.53
2087.7940516471863
[2.558619976043701, 4.945653438568115, 7.371271371841431, 9.876899242401123, 12.24923324584961, 14.587373495101929, 16.816978693008423, 19.05869722366333, 21.380029916763306, 23.705730438232422, 26.007455348968506, 28.328292846679688, 30.870087146759033, 33.27443599700928, 35.63274812698364, 37.984123945236206, 40.40620732307434, 42.810911893844604, 45.27934122085571, 47.79120397567749, 50.2534065246582, 53.12486410140991, 55.53390288352966, 58.019877195358276, 60.489038705825806, 63.25537347793579, 65.55646204948425, 67.9331259727478, 70.39114999771118, 72.8969087600708, 75.44209313392639, 77.88676190376282, 80.73558259010315, 83.24567103385925, 86.00654864311218, 88.43552732467651, 91.09160923957825, 93.62635493278503, 96.13612151145935, 98.66747570037842, 101.31140756607056, 103.89495253562927, 106.3764295578003, 109.12336611747742, 111.83692574501038, 114.6238579750061, 117.44574093818665, 120.29665660858154, 123.16012477874756, 125.64991092681885, 128.06703853607178, 130.69583702087402, 133.2514259815216, 135.77105379104614, 138.46936774253845, 141.34167289733887, 143.810941696167, 146.2156949043274, 148.39617609977722, 150.92895078659058, 153.4118492603302, 155.92676210403442, 158.30415558815002, 160.77042269706726, 163.28556537628174, 165.6973786354065, 168.16855764389038, 170.67947268486023, 173.21608662605286, 175.61756825447083, 178.08213996887207, 180.49999570846558, 183.00502276420593, 185.45696544647217, 187.82630395889282, 190.15961337089539, 192.541827917099, 195.06297278404236, 197.50851321220398, 200.53763127326965, 202.890851020813, 205.45856285095215, 207.79417181015015, 210.31713151931763, 212.66320776939392, 215.02988171577454, 217.39134645462036, 219.850980758667, 222.15022253990173, 224.4408574104309, 226.71152710914612, 228.9965786933899, 231.31417512893677, 233.6069598197937, 235.8054678440094, 238.1356542110443, 240.44114542007446, 242.65965676307678, 244.94609999656677, 247.3333330154419, 249.0924379825592]
[17.795, 33.455, 40.76, 55.53, 62.37, 71.185, 73.09, 75.77, 78.505, 80.09, 81.26, 82.21, 82.575, 82.935, 83.085, 83.895, 84.04, 84.365, 85.125, 87.435, 89.145, 92.135, 92.985, 93.21, 93.375, 93.68, 93.99, 94.06, 94.26, 94.32, 94.52, 94.545, 94.835, 94.845, 94.98, 95.03, 95.06, 95.16, 95.195, 95.265, 95.335, 95.39, 95.445, 95.51, 95.555, 95.505, 95.515, 95.63, 95.67, 95.645, 95.745, 95.755, 95.82, 95.865, 95.845, 95.895, 95.885, 95.89, 95.925, 96.0, 96.02, 95.98, 96.07, 96.075, 96.05, 96.05, 96.155, 96.18, 96.225, 96.185, 96.205, 96.275, 96.275, 96.23, 96.285, 96.305, 96.36, 96.34, 96.36, 96.45, 96.41, 96.38, 96.43, 96.445, 96.42, 96.495, 96.495, 96.495, 96.49, 96.555, 96.485, 96.51, 96.495, 96.525, 96.55, 96.515, 96.53, 96.58, 96.54, 96.57, 96.57]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
401408
401920
532992
533248
549632
549696
550336
550346
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.319, Test loss: 2.297, Test accuracy: 20.11
Round   1, Train loss: 2.304, Test loss: 2.280, Test accuracy: 43.42
Round   2, Train loss: 2.263, Test loss: 2.194, Test accuracy: 50.34
Round   3, Train loss: 2.142, Test loss: 2.031, Test accuracy: 57.45
Round   4, Train loss: 1.981, Test loss: 1.926, Test accuracy: 65.80
Round   5, Train loss: 1.898, Test loss: 1.872, Test accuracy: 71.36
Round   6, Train loss: 1.838, Test loss: 1.844, Test accuracy: 72.92
Round   7, Train loss: 1.826, Test loss: 1.812, Test accuracy: 75.64
Round   8, Train loss: 1.792, Test loss: 1.778, Test accuracy: 80.01
Round   9, Train loss: 1.763, Test loss: 1.746, Test accuracy: 81.20
Round  10, Train loss: 1.743, Test loss: 1.724, Test accuracy: 82.28
Round  11, Train loss: 1.719, Test loss: 1.709, Test accuracy: 84.23
Round  12, Train loss: 1.705, Test loss: 1.680, Test accuracy: 88.11
Round  13, Train loss: 1.683, Test loss: 1.651, Test accuracy: 89.66
Round  14, Train loss: 1.643, Test loss: 1.646, Test accuracy: 90.47
Round  15, Train loss: 1.637, Test loss: 1.632, Test accuracy: 91.34
Round  16, Train loss: 1.633, Test loss: 1.618, Test accuracy: 91.98
Round  17, Train loss: 1.633, Test loss: 1.601, Test accuracy: 92.20
Round  18, Train loss: 1.609, Test loss: 1.597, Test accuracy: 92.78
Round  19, Train loss: 1.608, Test loss: 1.589, Test accuracy: 93.16
Round  20, Train loss: 1.603, Test loss: 1.585, Test accuracy: 93.38
Round  21, Train loss: 1.586, Test loss: 1.581, Test accuracy: 93.72
Round  22, Train loss: 1.585, Test loss: 1.580, Test accuracy: 93.81
Round  23, Train loss: 1.573, Test loss: 1.579, Test accuracy: 93.95
Round  24, Train loss: 1.588, Test loss: 1.569, Test accuracy: 94.16
Round  25, Train loss: 1.588, Test loss: 1.563, Test accuracy: 94.50
Round  26, Train loss: 1.566, Test loss: 1.564, Test accuracy: 94.70
Round  27, Train loss: 1.571, Test loss: 1.558, Test accuracy: 94.74
Round  28, Train loss: 1.557, Test loss: 1.558, Test accuracy: 94.94
Round  29, Train loss: 1.552, Test loss: 1.559, Test accuracy: 95.05
Round  30, Train loss: 1.558, Test loss: 1.554, Test accuracy: 95.19
Round  31, Train loss: 1.570, Test loss: 1.548, Test accuracy: 95.35
Round  32, Train loss: 1.552, Test loss: 1.549, Test accuracy: 95.39
Round  33, Train loss: 1.546, Test loss: 1.550, Test accuracy: 95.50
Round  34, Train loss: 1.550, Test loss: 1.546, Test accuracy: 95.58
Round  35, Train loss: 1.552, Test loss: 1.542, Test accuracy: 95.76
Round  36, Train loss: 1.540, Test loss: 1.545, Test accuracy: 95.68
Round  37, Train loss: 1.545, Test loss: 1.542, Test accuracy: 95.76
Round  38, Train loss: 1.531, Test loss: 1.544, Test accuracy: 95.77
Round  39, Train loss: 1.543, Test loss: 1.540, Test accuracy: 95.84
Round  40, Train loss: 1.545, Test loss: 1.536, Test accuracy: 95.91
Round  41, Train loss: 1.541, Test loss: 1.535, Test accuracy: 95.88
Round  42, Train loss: 1.540, Test loss: 1.534, Test accuracy: 95.98
Round  43, Train loss: 1.533, Test loss: 1.535, Test accuracy: 95.98
Round  44, Train loss: 1.533, Test loss: 1.532, Test accuracy: 96.12
Round  45, Train loss: 1.527, Test loss: 1.532, Test accuracy: 96.11
Round  46, Train loss: 1.531, Test loss: 1.531, Test accuracy: 96.12
Round  47, Train loss: 1.529, Test loss: 1.530, Test accuracy: 96.19
Round  48, Train loss: 1.527, Test loss: 1.529, Test accuracy: 96.22
Round  49, Train loss: 1.521, Test loss: 1.529, Test accuracy: 96.31
Round  50, Train loss: 1.529, Test loss: 1.527, Test accuracy: 96.25
Round  51, Train loss: 1.522, Test loss: 1.527, Test accuracy: 96.36
Round  52, Train loss: 1.521, Test loss: 1.527, Test accuracy: 96.41
Round  53, Train loss: 1.521, Test loss: 1.527, Test accuracy: 96.42
Round  54, Train loss: 1.517, Test loss: 1.527, Test accuracy: 96.47
Round  55, Train loss: 1.523, Test loss: 1.525, Test accuracy: 96.49
Round  56, Train loss: 1.516, Test loss: 1.524, Test accuracy: 96.53
Round  57, Train loss: 1.514, Test loss: 1.525, Test accuracy: 96.44
Round  58, Train loss: 1.515, Test loss: 1.525, Test accuracy: 96.47
Round  59, Train loss: 1.516, Test loss: 1.524, Test accuracy: 96.44
Round  60, Train loss: 1.514, Test loss: 1.523, Test accuracy: 96.53
Round  61, Train loss: 1.515, Test loss: 1.522, Test accuracy: 96.64
Round  62, Train loss: 1.512, Test loss: 1.523, Test accuracy: 96.50
Round  63, Train loss: 1.515, Test loss: 1.521, Test accuracy: 96.48
Round  64, Train loss: 1.513, Test loss: 1.521, Test accuracy: 96.56
Round  65, Train loss: 1.510, Test loss: 1.521, Test accuracy: 96.62
Round  66, Train loss: 1.507, Test loss: 1.521, Test accuracy: 96.56
Round  67, Train loss: 1.507, Test loss: 1.521, Test accuracy: 96.55
Round  68, Train loss: 1.510, Test loss: 1.520, Test accuracy: 96.61
Round  69, Train loss: 1.507, Test loss: 1.520, Test accuracy: 96.64
Round  70, Train loss: 1.504, Test loss: 1.520, Test accuracy: 96.62
Round  71, Train loss: 1.506, Test loss: 1.519, Test accuracy: 96.69
Round  72, Train loss: 1.504, Test loss: 1.520, Test accuracy: 96.67
Round  73, Train loss: 1.511, Test loss: 1.518, Test accuracy: 96.67
Round  74, Train loss: 1.504, Test loss: 1.519, Test accuracy: 96.77
Round  75, Train loss: 1.507, Test loss: 1.517, Test accuracy: 96.81
Round  76, Train loss: 1.503, Test loss: 1.518, Test accuracy: 96.81
Round  77, Train loss: 1.505, Test loss: 1.517, Test accuracy: 96.83
Round  78, Train loss: 1.504, Test loss: 1.518, Test accuracy: 96.83
Round  79, Train loss: 1.501, Test loss: 1.518, Test accuracy: 96.84
Round  80, Train loss: 1.504, Test loss: 1.516, Test accuracy: 96.91
Round  81, Train loss: 1.504, Test loss: 1.516, Test accuracy: 96.89
Round  82, Train loss: 1.504, Test loss: 1.516, Test accuracy: 96.86
Round  83, Train loss: 1.501, Test loss: 1.516, Test accuracy: 96.92
Round  84, Train loss: 1.500, Test loss: 1.516, Test accuracy: 96.90
Round  85, Train loss: 1.499, Test loss: 1.516, Test accuracy: 96.83
Round  86, Train loss: 1.500, Test loss: 1.516, Test accuracy: 96.95
Round  87, Train loss: 1.499, Test loss: 1.515, Test accuracy: 96.94
Round  88, Train loss: 1.499, Test loss: 1.515, Test accuracy: 96.99
Round  89, Train loss: 1.501, Test loss: 1.515, Test accuracy: 97.00
Round  90, Train loss: 1.499, Test loss: 1.515, Test accuracy: 97.06
Round  91, Train loss: 1.502, Test loss: 1.514, Test accuracy: 97.03
Round  92, Train loss: 1.498, Test loss: 1.515, Test accuracy: 97.02
Round  93, Train loss: 1.498, Test loss: 1.515, Test accuracy: 96.98/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Train loss: 1.498, Test loss: 1.515, Test accuracy: 97.06
Round  95, Train loss: 1.499, Test loss: 1.514, Test accuracy: 97.06
Round  96, Train loss: 1.495, Test loss: 1.514, Test accuracy: 97.06
Round  97, Train loss: 1.501, Test loss: 1.512, Test accuracy: 97.00
Round  98, Train loss: 1.497, Test loss: 1.513, Test accuracy: 97.00
Round  99, Train loss: 1.498, Test loss: 1.512, Test accuracy: 97.06
Final Round, Train loss: 1.477, Test loss: 1.511, Test accuracy: 97.06
Average accuracy final 10 rounds: 97.03250000000001
2662.8962450027466
[2.619086980819702, 5.238173961639404, 7.63128137588501, 10.024388790130615, 12.408787727355957, 14.793186664581299, 17.121568202972412, 19.449949741363525, 22.07154083251953, 24.693131923675537, 27.02153730392456, 29.349942684173584, 31.7551372051239, 34.16033172607422, 36.46876287460327, 38.777194023132324, 41.09050703048706, 43.4038200378418, 45.809696435928345, 48.21557283401489, 50.46519446372986, 52.714816093444824, 55.143054723739624, 57.571293354034424, 59.77898454666138, 61.98667573928833, 64.42005777359009, 66.85343980789185, 69.16672968864441, 71.48001956939697, 73.8108901977539, 76.14176082611084, 78.47206258773804, 80.80236434936523, 83.19555473327637, 85.5887451171875, 87.98843812942505, 90.3881311416626, 92.75511527061462, 95.12209939956665, 97.4489233493805, 99.77574729919434, 102.22446417808533, 104.67318105697632, 107.00484156608582, 109.33650207519531, 111.78969120979309, 114.24288034439087, 116.57166290283203, 118.9004454612732, 121.42111849784851, 123.94179153442383, 126.36097359657288, 128.78015565872192, 131.28243947029114, 133.78472328186035, 136.25992894172668, 138.73513460159302, 141.33398389816284, 143.93283319473267, 146.25491333007812, 148.57699346542358, 150.91930675506592, 153.26162004470825, 155.65925645828247, 158.0568928718567, 160.4127917289734, 162.7686905860901, 165.1266634464264, 167.4846363067627, 169.795907497406, 172.10717868804932, 174.54586052894592, 176.98454236984253, 179.34895539283752, 181.71336841583252, 184.02940845489502, 186.34544849395752, 188.6757984161377, 191.00614833831787, 193.35576248168945, 195.70537662506104, 197.9758698940277, 200.24636316299438, 202.57321405410767, 204.90006494522095, 207.17237877845764, 209.44469261169434, 211.7713713645935, 214.09805011749268, 216.25987434387207, 218.42169857025146, 220.7485761642456, 223.07545375823975, 225.2911138534546, 227.50677394866943, 229.88162183761597, 232.2564697265625, 234.60105681419373, 236.94564390182495, 239.2598011493683, 241.57395839691162, 243.95034742355347, 246.3267364501953, 248.67417001724243, 251.02160358428955, 253.39839482307434, 255.77518606185913, 258.10864663124084, 260.44210720062256, 262.74188017845154, 265.0416531562805, 267.409423828125, 269.7771944999695, 272.04728865623474, 274.3173828125, 276.67705154418945, 279.0367202758789, 281.4032006263733, 283.7696809768677, 286.1732985973358, 288.57691621780396, 290.92566323280334, 293.27441024780273, 295.6091001033783, 297.94378995895386, 300.2896692752838, 302.63554859161377, 304.90813159942627, 307.18071460723877, 309.490939617157, 311.8011646270752, 314.10270619392395, 316.4042477607727, 318.8018248081207, 321.19940185546875, 323.51970529556274, 325.84000873565674, 328.2049584388733, 330.56990814208984, 332.7862958908081, 335.00268363952637, 337.2995328903198, 339.5963821411133, 341.8980941772461, 344.1998062133789, 346.4810223579407, 348.76223850250244, 351.0945973396301, 353.4269561767578, 355.81022572517395, 358.1934952735901, 360.5843710899353, 362.9752469062805, 365.62899923324585, 368.2827515602112, 370.71457266807556, 373.14639377593994, 375.5530619621277, 377.95973014831543, 380.40377974510193, 382.8478293418884, 385.25658440589905, 387.66533946990967, 390.0780556201935, 392.4907717704773, 394.88458347320557, 397.27839517593384, 399.6838357448578, 402.08927631378174, 404.5444920063019, 406.999707698822, 409.36066341400146, 411.7216191291809, 414.0175256729126, 416.3134322166443, 418.6456444263458, 420.97785663604736, 423.439040184021, 425.90022373199463, 428.20504808425903, 430.50987243652344, 432.8772523403168, 435.2446322441101, 437.6757493019104, 440.1068663597107, 442.39229941368103, 444.67773246765137, 446.97989320755005, 449.28205394744873, 451.5858836174011, 453.8897132873535, 456.2555673122406, 458.6214213371277, 460.87709283828735, 463.132764339447, 465.3828475475311, 467.63293075561523, 470.06254148483276, 472.4921522140503, 474.3088674545288, 476.1255826950073]
[20.105, 20.105, 43.42, 43.42, 50.34, 50.34, 57.445, 57.445, 65.795, 65.795, 71.365, 71.365, 72.925, 72.925, 75.635, 75.635, 80.01, 80.01, 81.2, 81.2, 82.28, 82.28, 84.235, 84.235, 88.11, 88.11, 89.66, 89.66, 90.47, 90.47, 91.34, 91.34, 91.98, 91.98, 92.2, 92.2, 92.785, 92.785, 93.16, 93.16, 93.375, 93.375, 93.72, 93.72, 93.805, 93.805, 93.955, 93.955, 94.155, 94.155, 94.505, 94.505, 94.7, 94.7, 94.74, 94.74, 94.945, 94.945, 95.05, 95.05, 95.195, 95.195, 95.35, 95.35, 95.385, 95.385, 95.505, 95.505, 95.585, 95.585, 95.76, 95.76, 95.68, 95.68, 95.76, 95.76, 95.765, 95.765, 95.845, 95.845, 95.91, 95.91, 95.88, 95.88, 95.985, 95.985, 95.98, 95.98, 96.125, 96.125, 96.11, 96.11, 96.12, 96.12, 96.19, 96.19, 96.22, 96.22, 96.305, 96.305, 96.245, 96.245, 96.36, 96.36, 96.405, 96.405, 96.425, 96.425, 96.47, 96.47, 96.49, 96.49, 96.525, 96.525, 96.445, 96.445, 96.465, 96.465, 96.435, 96.435, 96.53, 96.53, 96.64, 96.64, 96.505, 96.505, 96.485, 96.485, 96.555, 96.555, 96.62, 96.62, 96.555, 96.555, 96.545, 96.545, 96.615, 96.615, 96.64, 96.64, 96.625, 96.625, 96.69, 96.69, 96.665, 96.665, 96.67, 96.67, 96.765, 96.765, 96.805, 96.805, 96.815, 96.815, 96.825, 96.825, 96.825, 96.825, 96.845, 96.845, 96.91, 96.91, 96.895, 96.895, 96.86, 96.86, 96.925, 96.925, 96.9, 96.9, 96.83, 96.83, 96.955, 96.955, 96.935, 96.935, 96.99, 96.99, 96.995, 96.995, 97.065, 97.065, 97.03, 97.03, 97.015, 97.015, 96.985, 96.985, 97.06, 97.06, 97.055, 97.055, 97.055, 97.055, 96.995, 96.995, 97.0, 97.0, 97.065, 97.065, 97.06, 97.06]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.289, Test loss: 2.287, Test accuracy: 23.88
Round   0, Global train loss: 2.289, Global test loss: 2.296, Global test accuracy: 22.30
Round   1, Train loss: 2.198, Test loss: 2.206, Test accuracy: 30.21
Round   1, Global train loss: 2.198, Global test loss: 2.245, Global test accuracy: 26.27
Round   2, Train loss: 1.980, Test loss: 2.065, Test accuracy: 47.24
Round   2, Global train loss: 1.980, Global test loss: 2.143, Global test accuracy: 40.81
Round   3, Train loss: 1.838, Test loss: 1.998, Test accuracy: 51.72
Round   3, Global train loss: 1.838, Global test loss: 2.109, Global test accuracy: 38.46
Round   4, Train loss: 1.862, Test loss: 1.883, Test accuracy: 63.94
Round   4, Global train loss: 1.862, Global test loss: 2.038, Global test accuracy: 49.71
Round   5, Train loss: 1.694, Test loss: 1.815, Test accuracy: 70.13
Round   5, Global train loss: 1.694, Global test loss: 1.944, Global test accuracy: 60.64
Round   6, Train loss: 1.752, Test loss: 1.784, Test accuracy: 72.63
Round   6, Global train loss: 1.752, Global test loss: 1.983, Global test accuracy: 58.68
Round   7, Train loss: 1.610, Test loss: 1.750, Test accuracy: 74.87
Round   7, Global train loss: 1.610, Global test loss: 1.902, Global test accuracy: 56.59
Round   8, Train loss: 1.647, Test loss: 1.723, Test accuracy: 77.58
Round   8, Global train loss: 1.647, Global test loss: 2.046, Global test accuracy: 44.24
Round   9, Train loss: 1.610, Test loss: 1.708, Test accuracy: 79.05
Round   9, Global train loss: 1.610, Global test loss: 2.029, Global test accuracy: 45.20
Round  10, Train loss: 1.620, Test loss: 1.698, Test accuracy: 79.61
Round  10, Global train loss: 1.620, Global test loss: 1.998, Global test accuracy: 53.57
Round  11, Train loss: 1.636, Test loss: 1.672, Test accuracy: 81.31
Round  11, Global train loss: 1.636, Global test loss: 2.024, Global test accuracy: 45.84
Round  12, Train loss: 1.558, Test loss: 1.651, Test accuracy: 83.48
Round  12, Global train loss: 1.558, Global test loss: 2.102, Global test accuracy: 32.53
Round  13, Train loss: 1.574, Test loss: 1.631, Test accuracy: 85.05
Round  13, Global train loss: 1.574, Global test loss: 2.005, Global test accuracy: 43.99
Round  14, Train loss: 1.562, Test loss: 1.627, Test accuracy: 85.20
Round  14, Global train loss: 1.562, Global test loss: 2.009, Global test accuracy: 45.85
Round  15, Train loss: 1.565, Test loss: 1.619, Test accuracy: 85.87
Round  15, Global train loss: 1.565, Global test loss: 2.029, Global test accuracy: 42.49
Round  16, Train loss: 1.543, Test loss: 1.609, Test accuracy: 86.62
Round  16, Global train loss: 1.543, Global test loss: 1.964, Global test accuracy: 52.26
Round  17, Train loss: 1.526, Test loss: 1.607, Test accuracy: 86.87
Round  17, Global train loss: 1.526, Global test loss: 1.988, Global test accuracy: 51.69
Round  18, Train loss: 1.573, Test loss: 1.599, Test accuracy: 87.31
Round  18, Global train loss: 1.573, Global test loss: 1.983, Global test accuracy: 45.44
Round  19, Train loss: 1.483, Test loss: 1.597, Test accuracy: 87.39
Round  19, Global train loss: 1.483, Global test loss: 1.952, Global test accuracy: 56.05
Round  20, Train loss: 1.510, Test loss: 1.593, Test accuracy: 87.73
Round  20, Global train loss: 1.510, Global test loss: 2.050, Global test accuracy: 41.98
Round  21, Train loss: 1.545, Test loss: 1.592, Test accuracy: 87.88
Round  21, Global train loss: 1.545, Global test loss: 2.030, Global test accuracy: 44.23
Round  22, Train loss: 1.486, Test loss: 1.587, Test accuracy: 88.31
Round  22, Global train loss: 1.486, Global test loss: 1.989, Global test accuracy: 44.68
Round  23, Train loss: 1.475, Test loss: 1.587, Test accuracy: 88.29
Round  23, Global train loss: 1.475, Global test loss: 2.047, Global test accuracy: 40.74
Round  24, Train loss: 1.479, Test loss: 1.585, Test accuracy: 88.29
Round  24, Global train loss: 1.479, Global test loss: 2.070, Global test accuracy: 37.26
Round  25, Train loss: 1.505, Test loss: 1.579, Test accuracy: 89.00
Round  25, Global train loss: 1.505, Global test loss: 1.924, Global test accuracy: 54.32
Round  26, Train loss: 1.472, Test loss: 1.579, Test accuracy: 89.04
Round  26, Global train loss: 1.472, Global test loss: 1.869, Global test accuracy: 64.59
Round  27, Train loss: 1.474, Test loss: 1.579, Test accuracy: 89.15
Round  27, Global train loss: 1.474, Global test loss: 1.925, Global test accuracy: 56.88
Round  28, Train loss: 1.539, Test loss: 1.578, Test accuracy: 89.16
Round  28, Global train loss: 1.539, Global test loss: 2.005, Global test accuracy: 44.10
Round  29, Train loss: 1.505, Test loss: 1.578, Test accuracy: 89.16
Round  29, Global train loss: 1.505, Global test loss: 1.994, Global test accuracy: 48.50
Round  30, Train loss: 1.483, Test loss: 1.575, Test accuracy: 89.31
Round  30, Global train loss: 1.483, Global test loss: 1.965, Global test accuracy: 50.71
Round  31, Train loss: 1.502, Test loss: 1.575, Test accuracy: 89.33
Round  31, Global train loss: 1.502, Global test loss: 1.973, Global test accuracy: 48.78
Round  32, Train loss: 1.570, Test loss: 1.575, Test accuracy: 89.29
Round  32, Global train loss: 1.570, Global test loss: 2.022, Global test accuracy: 44.80
Round  33, Train loss: 1.503, Test loss: 1.574, Test accuracy: 89.30
Round  33, Global train loss: 1.503, Global test loss: 2.018, Global test accuracy: 45.30
Round  34, Train loss: 1.474, Test loss: 1.573, Test accuracy: 89.41
Round  34, Global train loss: 1.474, Global test loss: 1.969, Global test accuracy: 51.13
Round  35, Train loss: 1.506, Test loss: 1.573, Test accuracy: 89.49
Round  35, Global train loss: 1.506, Global test loss: 1.958, Global test accuracy: 51.87
Round  36, Train loss: 1.487, Test loss: 1.568, Test accuracy: 90.08
Round  36, Global train loss: 1.487, Global test loss: 1.958, Global test accuracy: 49.07
Round  37, Train loss: 1.477, Test loss: 1.566, Test accuracy: 90.12
Round  37, Global train loss: 1.477, Global test loss: 1.994, Global test accuracy: 46.47
Round  38, Train loss: 1.534, Test loss: 1.566, Test accuracy: 90.16
Round  38, Global train loss: 1.534, Global test loss: 2.024, Global test accuracy: 42.80
Round  39, Train loss: 1.507, Test loss: 1.566, Test accuracy: 90.07
Round  39, Global train loss: 1.507, Global test loss: 2.041, Global test accuracy: 40.45
Round  40, Train loss: 1.503, Test loss: 1.566, Test accuracy: 90.06
Round  40, Global train loss: 1.503, Global test loss: 1.920, Global test accuracy: 56.31
Round  41, Train loss: 1.501, Test loss: 1.565, Test accuracy: 90.10
Round  41, Global train loss: 1.501, Global test loss: 1.908, Global test accuracy: 64.47
Round  42, Train loss: 1.499, Test loss: 1.565, Test accuracy: 90.08
Round  42, Global train loss: 1.499, Global test loss: 1.933, Global test accuracy: 55.99
Round  43, Train loss: 1.470, Test loss: 1.565, Test accuracy: 90.02
Round  43, Global train loss: 1.470, Global test loss: 2.054, Global test accuracy: 40.07
Round  44, Train loss: 1.470, Test loss: 1.565, Test accuracy: 90.02
Round  44, Global train loss: 1.470, Global test loss: 1.924, Global test accuracy: 55.57
Round  45, Train loss: 1.503, Test loss: 1.565, Test accuracy: 90.04
Round  45, Global train loss: 1.503, Global test loss: 2.202, Global test accuracy: 22.17
Round  46, Train loss: 1.502, Test loss: 1.564, Test accuracy: 90.06
Round  46, Global train loss: 1.502, Global test loss: 1.948, Global test accuracy: 54.55
Round  47, Train loss: 1.470, Test loss: 1.564, Test accuracy: 90.08
Round  47, Global train loss: 1.470, Global test loss: 1.978, Global test accuracy: 48.34
Round  48, Train loss: 1.469, Test loss: 1.564, Test accuracy: 90.11
Round  48, Global train loss: 1.469, Global test loss: 2.078, Global test accuracy: 37.19
Round  49, Train loss: 1.470, Test loss: 1.564, Test accuracy: 90.11
Round  49, Global train loss: 1.470, Global test loss: 2.030, Global test accuracy: 44.31
Round  50, Train loss: 1.533, Test loss: 1.564, Test accuracy: 90.15
Round  50, Global train loss: 1.533, Global test loss: 2.048, Global test accuracy: 40.14
Round  51, Train loss: 1.500, Test loss: 1.563, Test accuracy: 90.14
Round  51, Global train loss: 1.500, Global test loss: 1.995, Global test accuracy: 52.72
Round  52, Train loss: 1.500, Test loss: 1.563, Test accuracy: 90.15
Round  52, Global train loss: 1.500, Global test loss: 1.960, Global test accuracy: 51.28
Round  53, Train loss: 1.467, Test loss: 1.563, Test accuracy: 90.16
Round  53, Global train loss: 1.467, Global test loss: 1.925, Global test accuracy: 56.22
Round  54, Train loss: 1.499, Test loss: 1.563, Test accuracy: 90.19
Round  54, Global train loss: 1.499, Global test loss: 2.040, Global test accuracy: 43.00
Round  55, Train loss: 1.499, Test loss: 1.563, Test accuracy: 90.20
Round  55, Global train loss: 1.499, Global test loss: 1.922, Global test accuracy: 54.11
Round  56, Train loss: 1.500, Test loss: 1.563, Test accuracy: 90.19
Round  56, Global train loss: 1.500, Global test loss: 1.910, Global test accuracy: 57.54
Round  57, Train loss: 1.500, Test loss: 1.563, Test accuracy: 90.18
Round  57, Global train loss: 1.500, Global test loss: 2.057, Global test accuracy: 40.66
Round  58, Train loss: 1.469, Test loss: 1.563, Test accuracy: 90.20
Round  58, Global train loss: 1.469, Global test loss: 1.982, Global test accuracy: 50.61
Round  59, Train loss: 1.501, Test loss: 1.563, Test accuracy: 90.19
Round  59, Global train loss: 1.501, Global test loss: 2.050, Global test accuracy: 40.64
Round  60, Train loss: 1.469, Test loss: 1.563, Test accuracy: 90.18
Round  60, Global train loss: 1.469, Global test loss: 1.951, Global test accuracy: 51.83
Round  61, Train loss: 1.500, Test loss: 1.563, Test accuracy: 90.18
Round  61, Global train loss: 1.500, Global test loss: 1.985, Global test accuracy: 51.27
Round  62, Train loss: 1.467, Test loss: 1.563, Test accuracy: 90.16
Round  62, Global train loss: 1.467, Global test loss: 2.044, Global test accuracy: 39.74
Round  63, Train loss: 1.499, Test loss: 1.562, Test accuracy: 90.23
Round  63, Global train loss: 1.499, Global test loss: 1.933, Global test accuracy: 58.66
Round  64, Train loss: 1.468, Test loss: 1.562, Test accuracy: 90.24
Round  64, Global train loss: 1.468, Global test loss: 1.935, Global test accuracy: 56.30
Round  65, Train loss: 1.468, Test loss: 1.562, Test accuracy: 90.25
Round  65, Global train loss: 1.468, Global test loss: 2.005, Global test accuracy: 43.96
Round  66, Train loss: 1.500, Test loss: 1.562, Test accuracy: 90.28
Round  66, Global train loss: 1.500, Global test loss: 1.995, Global test accuracy: 46.75
Round  67, Train loss: 1.466, Test loss: 1.562, Test accuracy: 90.27
Round  67, Global train loss: 1.466, Global test loss: 2.027, Global test accuracy: 42.94
Round  68, Train loss: 1.498, Test loss: 1.562, Test accuracy: 90.27
Round  68, Global train loss: 1.498, Global test loss: 1.891, Global test accuracy: 63.69
Round  69, Train loss: 1.465, Test loss: 1.562, Test accuracy: 90.30
Round  69, Global train loss: 1.465, Global test loss: 1.929, Global test accuracy: 54.48
Round  70, Train loss: 1.467, Test loss: 1.562, Test accuracy: 90.28
Round  70, Global train loss: 1.467, Global test loss: 1.985, Global test accuracy: 49.11
Round  71, Train loss: 1.533, Test loss: 1.562, Test accuracy: 90.22
Round  71, Global train loss: 1.533, Global test loss: 2.026, Global test accuracy: 47.30
Round  72, Train loss: 1.502, Test loss: 1.562, Test accuracy: 90.21
Round  72, Global train loss: 1.502, Global test loss: 1.999, Global test accuracy: 44.28
Round  73, Train loss: 1.467, Test loss: 1.562, Test accuracy: 90.23
Round  73, Global train loss: 1.467, Global test loss: 2.000, Global test accuracy: 46.10
Round  74, Train loss: 1.500, Test loss: 1.562, Test accuracy: 90.21
Round  74, Global train loss: 1.500, Global test loss: 2.003, Global test accuracy: 43.07
Round  75, Train loss: 1.498, Test loss: 1.562, Test accuracy: 90.21
Round  75, Global train loss: 1.498, Global test loss: 1.995, Global test accuracy: 44.01
Round  76, Train loss: 1.498, Test loss: 1.562, Test accuracy: 90.23
Round  76, Global train loss: 1.498, Global test loss: 2.057, Global test accuracy: 36.45
Round  77, Train loss: 1.468, Test loss: 1.562, Test accuracy: 90.22
Round  77, Global train loss: 1.468, Global test loss: 1.968, Global test accuracy: 55.47
Round  78, Train loss: 1.466, Test loss: 1.562, Test accuracy: 90.24
Round  78, Global train loss: 1.466, Global test loss: 2.027, Global test accuracy: 43.83
Round  79, Train loss: 1.466, Test loss: 1.562, Test accuracy: 90.26
Round  79, Global train loss: 1.466, Global test loss: 1.922, Global test accuracy: 54.26
Round  80, Train loss: 1.465, Test loss: 1.562, Test accuracy: 90.21
Round  80, Global train loss: 1.465, Global test loss: 2.044, Global test accuracy: 42.79
Round  81, Train loss: 1.533, Test loss: 1.562, Test accuracy: 90.23
Round  81, Global train loss: 1.533, Global test loss: 2.014, Global test accuracy: 42.63
Round  82, Train loss: 1.499, Test loss: 1.562, Test accuracy: 90.21
Round  82, Global train loss: 1.499, Global test loss: 1.946, Global test accuracy: 51.61
Round  83, Train loss: 1.499, Test loss: 1.562, Test accuracy: 90.22
Round  83, Global train loss: 1.499, Global test loss: 1.975, Global test accuracy: 48.37
Round  84, Train loss: 1.468, Test loss: 1.562, Test accuracy: 90.21
Round  84, Global train loss: 1.468, Global test loss: 2.013, Global test accuracy: 45.70
Round  85, Train loss: 1.468, Test loss: 1.562, Test accuracy: 90.21
Round  85, Global train loss: 1.468, Global test loss: 2.068, Global test accuracy: 39.31
Round  86, Train loss: 1.467, Test loss: 1.562, Test accuracy: 90.20
Round  86, Global train loss: 1.467, Global test loss: 1.923, Global test accuracy: 56.19
Round  87, Train loss: 1.467, Test loss: 1.562, Test accuracy: 90.17
Round  87, Global train loss: 1.467, Global test loss: 1.999, Global test accuracy: 43.91
Round  88, Train loss: 1.533, Test loss: 1.562, Test accuracy: 90.18
Round  88, Global train loss: 1.533, Global test loss: 1.945, Global test accuracy: 55.86
Round  89, Train loss: 1.501, Test loss: 1.562, Test accuracy: 90.18
Round  89, Global train loss: 1.501, Global test loss: 1.956, Global test accuracy: 51.92
Round  90, Train loss: 1.501, Test loss: 1.562, Test accuracy: 90.20
Round  90, Global train loss: 1.501, Global test loss: 1.882, Global test accuracy: 59.96
Round  91, Train loss: 1.466, Test loss: 1.562, Test accuracy: 90.17
Round  91, Global train loss: 1.466, Global test loss: 1.940, Global test accuracy: 53.52
Round  92, Train loss: 1.468, Test loss: 1.562, Test accuracy: 90.17
Round  92, Global train loss: 1.468, Global test loss: 2.026, Global test accuracy: 42.39
Round  93, Train loss: 1.469, Test loss: 1.562, Test accuracy: 90.18
Round  93, Global train loss: 1.469, Global test loss: 1.949, Global test accuracy: 50.25
Round  94, Train loss: 1.465, Test loss: 1.562, Test accuracy: 90.18
Round  94, Global train loss: 1.465, Global test loss: 1.949, Global test accuracy: 52.41
Round  95, Train loss: 1.466, Test loss: 1.562, Test accuracy: 90.17
Round  95, Global train loss: 1.466, Global test loss: 1.968, Global test accuracy: 50.01/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 1.466, Test loss: 1.562, Test accuracy: 90.17
Round  96, Global train loss: 1.466, Global test loss: 1.997, Global test accuracy: 44.88
Round  97, Train loss: 1.498, Test loss: 1.562, Test accuracy: 90.22
Round  97, Global train loss: 1.498, Global test loss: 1.885, Global test accuracy: 61.31
Round  98, Train loss: 1.466, Test loss: 1.562, Test accuracy: 90.22
Round  98, Global train loss: 1.466, Global test loss: 1.979, Global test accuracy: 49.87
Round  99, Train loss: 1.500, Test loss: 1.561, Test accuracy: 90.18
Round  99, Global train loss: 1.500, Global test loss: 1.923, Global test accuracy: 54.86
Final Round, Train loss: 1.480, Test loss: 1.554, Test accuracy: 90.99
Final Round, Global train loss: 1.480, Global test loss: 1.923, Global test accuracy: 54.86
Average accuracy final 10 rounds: 90.186 

Average global accuracy final 10 rounds: 51.946 

1506.6660087108612
[1.0672900676727295, 2.134580135345459, 3.1076598167419434, 4.080739498138428, 5.139653205871582, 6.198566913604736, 7.077422142028809, 7.956277370452881, 8.927875757217407, 9.899474143981934, 10.87882399559021, 11.858173847198486, 12.900050163269043, 13.9419264793396, 14.936149597167969, 15.930372714996338, 16.924726724624634, 17.91908073425293, 18.92925524711609, 19.939429759979248, 20.960714101791382, 21.981998443603516, 22.96578884124756, 23.9495792388916, 24.9513156414032, 25.953052043914795, 26.95292353630066, 27.952795028686523, 28.935384273529053, 29.917973518371582, 30.937696933746338, 31.957420349121094, 32.938138008117676, 33.91885566711426, 35.11367750167847, 36.308499336242676, 37.303722620010376, 38.298945903778076, 39.33651351928711, 40.37408113479614, 41.27057504653931, 42.16706895828247, 43.121549129486084, 44.0760293006897, 45.04860043525696, 46.02117156982422, 47.033238887786865, 48.04530620574951, 49.04813051223755, 50.050954818725586, 51.14479088783264, 52.2386269569397, 53.21288537979126, 54.18714380264282, 55.1677885055542, 56.148433208465576, 57.129663705825806, 58.110894203186035, 59.12496614456177, 60.1390380859375, 61.121225357055664, 62.10341262817383, 63.1071400642395, 64.11086750030518, 65.12044858932495, 66.13002967834473, 67.09140610694885, 68.05278253555298, 69.04968547821045, 70.04658842086792, 71.02774381637573, 72.00889921188354, 73.02498364448547, 74.0410680770874, 74.95085525512695, 75.8606424331665, 76.81413745880127, 77.76763248443604, 78.64683628082275, 79.52604007720947, 80.52737855911255, 81.52871704101562, 82.4222321510315, 83.31574726104736, 84.36934566497803, 85.42294406890869, 86.36393237113953, 87.30492067337036, 88.24978590011597, 89.19465112686157, 90.1003646850586, 91.00607824325562, 92.03613138198853, 93.06618452072144, 93.99800848960876, 94.9298324584961, 95.82260417938232, 96.71537590026855, 97.62610197067261, 98.53682804107666, 99.41581082344055, 100.29479360580444, 101.15949416160583, 102.02419471740723, 102.84030055999756, 103.65640640258789, 104.49928283691406, 105.34215927124023, 106.32731127738953, 107.31246328353882, 108.15173149108887, 108.99099969863892, 109.85356903076172, 110.71613836288452, 111.58178877830505, 112.44743919372559, 113.31053709983826, 114.17363500595093, 115.03824138641357, 115.90284776687622, 116.77127981185913, 117.63971185684204, 118.50769639015198, 119.37568092346191, 120.21706891059875, 121.0584568977356, 121.90394520759583, 122.74943351745605, 123.64840579032898, 124.5473780632019, 125.44886445999146, 126.350350856781, 127.2259030342102, 128.1014552116394, 128.98947286605835, 129.8774905204773, 130.75762295722961, 131.63775539398193, 132.48560857772827, 133.3334617614746, 134.17251181602478, 135.01156187057495, 135.87382078170776, 136.73607969284058, 137.60136556625366, 138.46665143966675, 139.3287537097931, 140.19085597991943, 141.0729637145996, 141.95507144927979, 142.83488082885742, 143.71469020843506, 144.56784558296204, 145.421000957489, 146.22412943840027, 147.02725791931152, 147.903067111969, 148.77887630462646, 149.6390905380249, 150.49930477142334, 151.3562936782837, 152.21328258514404, 153.04286551475525, 153.87244844436646, 154.7555956840515, 155.63874292373657, 156.44987440109253, 157.2610058784485, 158.1310715675354, 159.00113725662231, 159.88162851333618, 160.76211977005005, 161.61494970321655, 162.46777963638306, 163.34486865997314, 164.22195768356323, 165.1544704437256, 166.08698320388794, 167.00123405456543, 167.91548490524292, 168.78010821342468, 169.64473152160645, 170.61520791053772, 171.585684299469, 172.5740029811859, 173.56232166290283, 174.5442340373993, 175.52614641189575, 176.50513625144958, 177.48412609100342, 178.47903394699097, 179.47394180297852, 180.39319467544556, 181.3124475479126, 182.24046802520752, 183.16848850250244, 184.11413264274597, 185.0597767829895, 185.91848421096802, 186.77719163894653, 188.50433349609375, 190.23147535324097]
[23.88, 23.88, 30.21, 30.21, 47.24, 47.24, 51.72, 51.72, 63.94, 63.94, 70.13, 70.13, 72.63, 72.63, 74.87, 74.87, 77.58, 77.58, 79.05, 79.05, 79.61, 79.61, 81.31, 81.31, 83.48, 83.48, 85.05, 85.05, 85.2, 85.2, 85.87, 85.87, 86.62, 86.62, 86.87, 86.87, 87.31, 87.31, 87.39, 87.39, 87.73, 87.73, 87.88, 87.88, 88.31, 88.31, 88.29, 88.29, 88.29, 88.29, 89.0, 89.0, 89.04, 89.04, 89.15, 89.15, 89.16, 89.16, 89.16, 89.16, 89.31, 89.31, 89.33, 89.33, 89.29, 89.29, 89.3, 89.3, 89.41, 89.41, 89.49, 89.49, 90.08, 90.08, 90.12, 90.12, 90.16, 90.16, 90.07, 90.07, 90.06, 90.06, 90.1, 90.1, 90.08, 90.08, 90.02, 90.02, 90.02, 90.02, 90.04, 90.04, 90.06, 90.06, 90.08, 90.08, 90.11, 90.11, 90.11, 90.11, 90.15, 90.15, 90.14, 90.14, 90.15, 90.15, 90.16, 90.16, 90.19, 90.19, 90.2, 90.2, 90.19, 90.19, 90.18, 90.18, 90.2, 90.2, 90.19, 90.19, 90.18, 90.18, 90.18, 90.18, 90.16, 90.16, 90.23, 90.23, 90.24, 90.24, 90.25, 90.25, 90.28, 90.28, 90.27, 90.27, 90.27, 90.27, 90.3, 90.3, 90.28, 90.28, 90.22, 90.22, 90.21, 90.21, 90.23, 90.23, 90.21, 90.21, 90.21, 90.21, 90.23, 90.23, 90.22, 90.22, 90.24, 90.24, 90.26, 90.26, 90.21, 90.21, 90.23, 90.23, 90.21, 90.21, 90.22, 90.22, 90.21, 90.21, 90.21, 90.21, 90.2, 90.2, 90.17, 90.17, 90.18, 90.18, 90.18, 90.18, 90.2, 90.2, 90.17, 90.17, 90.17, 90.17, 90.18, 90.18, 90.18, 90.18, 90.17, 90.17, 90.17, 90.17, 90.22, 90.22, 90.22, 90.22, 90.18, 90.18, 90.99, 90.99]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.292, Test loss: 2.292, Test accuracy: 29.53
Round   0, Global train loss: 2.292, Global test loss: 2.299, Global test accuracy: 22.01
Round   1, Train loss: 2.259, Test loss: 2.242, Test accuracy: 28.75
Round   1, Global train loss: 2.259, Global test loss: 2.266, Global test accuracy: 20.20
Round   2, Train loss: 2.059, Test loss: 2.090, Test accuracy: 43.96
Round   2, Global train loss: 2.059, Global test loss: 2.121, Global test accuracy: 39.86
Round   3, Train loss: 1.875, Test loss: 1.955, Test accuracy: 56.43
Round   3, Global train loss: 1.875, Global test loss: 2.005, Global test accuracy: 49.67
Round   4, Train loss: 1.724, Test loss: 1.843, Test accuracy: 66.99
Round   4, Global train loss: 1.724, Global test loss: 1.837, Global test accuracy: 68.23
Round   5, Train loss: 1.738, Test loss: 1.779, Test accuracy: 70.66
Round   5, Global train loss: 1.738, Global test loss: 1.834, Global test accuracy: 63.78
Round   6, Train loss: 1.711, Test loss: 1.732, Test accuracy: 75.31
Round   6, Global train loss: 1.711, Global test loss: 1.785, Global test accuracy: 70.85
Round   7, Train loss: 1.647, Test loss: 1.707, Test accuracy: 77.86
Round   7, Global train loss: 1.647, Global test loss: 1.736, Global test accuracy: 75.36
Round   8, Train loss: 1.621, Test loss: 1.680, Test accuracy: 79.95
Round   8, Global train loss: 1.621, Global test loss: 1.736, Global test accuracy: 74.72
Round   9, Train loss: 1.615, Test loss: 1.677, Test accuracy: 79.90
Round   9, Global train loss: 1.615, Global test loss: 1.715, Global test accuracy: 76.35
Round  10, Train loss: 1.617, Test loss: 1.663, Test accuracy: 81.22
Round  10, Global train loss: 1.617, Global test loss: 1.678, Global test accuracy: 80.52
Round  11, Train loss: 1.582, Test loss: 1.642, Test accuracy: 83.12
Round  11, Global train loss: 1.582, Global test loss: 1.693, Global test accuracy: 78.28
Round  12, Train loss: 1.630, Test loss: 1.626, Test accuracy: 84.30
Round  12, Global train loss: 1.630, Global test loss: 1.673, Global test accuracy: 80.04
Round  13, Train loss: 1.661, Test loss: 1.623, Test accuracy: 84.53
Round  13, Global train loss: 1.661, Global test loss: 1.678, Global test accuracy: 79.52
Round  14, Train loss: 1.579, Test loss: 1.621, Test accuracy: 84.68
Round  14, Global train loss: 1.579, Global test loss: 1.650, Global test accuracy: 82.87
Round  15, Train loss: 1.568, Test loss: 1.618, Test accuracy: 84.85
Round  15, Global train loss: 1.568, Global test loss: 1.637, Global test accuracy: 83.37
Round  16, Train loss: 1.627, Test loss: 1.618, Test accuracy: 84.80
Round  16, Global train loss: 1.627, Global test loss: 1.644, Global test accuracy: 82.66
Round  17, Train loss: 1.591, Test loss: 1.616, Test accuracy: 85.03
Round  17, Global train loss: 1.591, Global test loss: 1.637, Global test accuracy: 83.67
Round  18, Train loss: 1.534, Test loss: 1.615, Test accuracy: 85.04
Round  18, Global train loss: 1.534, Global test loss: 1.674, Global test accuracy: 79.34
Round  19, Train loss: 1.624, Test loss: 1.613, Test accuracy: 85.17
Round  19, Global train loss: 1.624, Global test loss: 1.656, Global test accuracy: 81.32
Round  20, Train loss: 1.655, Test loss: 1.612, Test accuracy: 85.26
Round  20, Global train loss: 1.655, Global test loss: 1.647, Global test accuracy: 82.02
Round  21, Train loss: 1.561, Test loss: 1.611, Test accuracy: 85.32
Round  21, Global train loss: 1.561, Global test loss: 1.630, Global test accuracy: 83.98
Round  22, Train loss: 1.585, Test loss: 1.610, Test accuracy: 85.35
Round  22, Global train loss: 1.585, Global test loss: 1.636, Global test accuracy: 83.22
Round  23, Train loss: 1.556, Test loss: 1.610, Test accuracy: 85.36
Round  23, Global train loss: 1.556, Global test loss: 1.625, Global test accuracy: 84.27
Round  24, Train loss: 1.582, Test loss: 1.609, Test accuracy: 85.47
Round  24, Global train loss: 1.582, Global test loss: 1.642, Global test accuracy: 82.61
Round  25, Train loss: 1.586, Test loss: 1.607, Test accuracy: 85.53
Round  25, Global train loss: 1.586, Global test loss: 1.634, Global test accuracy: 83.29
Round  26, Train loss: 1.554, Test loss: 1.607, Test accuracy: 85.56
Round  26, Global train loss: 1.554, Global test loss: 1.644, Global test accuracy: 82.27
Round  27, Train loss: 1.618, Test loss: 1.607, Test accuracy: 85.58
Round  27, Global train loss: 1.618, Global test loss: 1.633, Global test accuracy: 83.45
Round  28, Train loss: 1.554, Test loss: 1.605, Test accuracy: 85.86
Round  28, Global train loss: 1.554, Global test loss: 1.632, Global test accuracy: 83.59
Round  29, Train loss: 1.516, Test loss: 1.605, Test accuracy: 85.73
Round  29, Global train loss: 1.516, Global test loss: 1.642, Global test accuracy: 82.36
Round  30, Train loss: 1.582, Test loss: 1.605, Test accuracy: 85.71
Round  30, Global train loss: 1.582, Global test loss: 1.620, Global test accuracy: 84.71
Round  31, Train loss: 1.583, Test loss: 1.605, Test accuracy: 85.77
Round  31, Global train loss: 1.583, Global test loss: 1.626, Global test accuracy: 84.16
Round  32, Train loss: 1.580, Test loss: 1.605, Test accuracy: 85.83
Round  32, Global train loss: 1.580, Global test loss: 1.627, Global test accuracy: 83.84
Round  33, Train loss: 1.581, Test loss: 1.603, Test accuracy: 86.01
Round  33, Global train loss: 1.581, Global test loss: 1.634, Global test accuracy: 83.34
Round  34, Train loss: 1.515, Test loss: 1.603, Test accuracy: 86.04
Round  34, Global train loss: 1.515, Global test loss: 1.624, Global test accuracy: 84.23
Round  35, Train loss: 1.612, Test loss: 1.603, Test accuracy: 86.06
Round  35, Global train loss: 1.612, Global test loss: 1.625, Global test accuracy: 84.05
Round  36, Train loss: 1.580, Test loss: 1.604, Test accuracy: 85.92
Round  36, Global train loss: 1.580, Global test loss: 1.625, Global test accuracy: 84.21
Round  37, Train loss: 1.512, Test loss: 1.602, Test accuracy: 86.10
Round  37, Global train loss: 1.512, Global test loss: 1.625, Global test accuracy: 84.04
Round  38, Train loss: 1.551, Test loss: 1.604, Test accuracy: 85.97
Round  38, Global train loss: 1.551, Global test loss: 1.623, Global test accuracy: 84.25
Round  39, Train loss: 1.543, Test loss: 1.603, Test accuracy: 86.00
Round  39, Global train loss: 1.543, Global test loss: 1.616, Global test accuracy: 84.91
Round  40, Train loss: 1.546, Test loss: 1.603, Test accuracy: 86.09
Round  40, Global train loss: 1.546, Global test loss: 1.617, Global test accuracy: 84.92
Round  41, Train loss: 1.579, Test loss: 1.601, Test accuracy: 86.32
Round  41, Global train loss: 1.579, Global test loss: 1.623, Global test accuracy: 84.28
Round  42, Train loss: 1.579, Test loss: 1.600, Test accuracy: 86.37
Round  42, Global train loss: 1.579, Global test loss: 1.616, Global test accuracy: 84.94
Round  43, Train loss: 1.574, Test loss: 1.600, Test accuracy: 86.35
Round  43, Global train loss: 1.574, Global test loss: 1.626, Global test accuracy: 83.95
Round  44, Train loss: 1.574, Test loss: 1.600, Test accuracy: 86.32
Round  44, Global train loss: 1.574, Global test loss: 1.621, Global test accuracy: 84.38
Round  45, Train loss: 1.575, Test loss: 1.600, Test accuracy: 86.31
Round  45, Global train loss: 1.575, Global test loss: 1.629, Global test accuracy: 83.56
Round  46, Train loss: 1.575, Test loss: 1.600, Test accuracy: 86.34
Round  46, Global train loss: 1.575, Global test loss: 1.629, Global test accuracy: 83.59
Round  47, Train loss: 1.575, Test loss: 1.600, Test accuracy: 86.34
Round  47, Global train loss: 1.575, Global test loss: 1.628, Global test accuracy: 83.86
Round  48, Train loss: 1.603, Test loss: 1.600, Test accuracy: 86.35
Round  48, Global train loss: 1.603, Global test loss: 1.616, Global test accuracy: 84.80
Round  49, Train loss: 1.574, Test loss: 1.600, Test accuracy: 86.32
Round  49, Global train loss: 1.574, Global test loss: 1.616, Global test accuracy: 84.78
Round  50, Train loss: 1.578, Test loss: 1.600, Test accuracy: 86.23
Round  50, Global train loss: 1.578, Global test loss: 1.612, Global test accuracy: 85.27
Round  51, Train loss: 1.608, Test loss: 1.599, Test accuracy: 86.33
Round  51, Global train loss: 1.608, Global test loss: 1.625, Global test accuracy: 84.08
Round  52, Train loss: 1.543, Test loss: 1.598, Test accuracy: 86.44
Round  52, Global train loss: 1.543, Global test loss: 1.615, Global test accuracy: 85.12
Round  53, Train loss: 1.574, Test loss: 1.598, Test accuracy: 86.52
Round  53, Global train loss: 1.574, Global test loss: 1.612, Global test accuracy: 85.29
Round  54, Train loss: 1.607, Test loss: 1.598, Test accuracy: 86.49
Round  54, Global train loss: 1.607, Global test loss: 1.618, Global test accuracy: 84.72
Round  55, Train loss: 1.572, Test loss: 1.598, Test accuracy: 86.51
Round  55, Global train loss: 1.572, Global test loss: 1.614, Global test accuracy: 84.95
Round  56, Train loss: 1.605, Test loss: 1.598, Test accuracy: 86.56
Round  56, Global train loss: 1.605, Global test loss: 1.612, Global test accuracy: 85.11
Round  57, Train loss: 1.541, Test loss: 1.597, Test accuracy: 86.62
Round  57, Global train loss: 1.541, Global test loss: 1.618, Global test accuracy: 84.59
Round  58, Train loss: 1.637, Test loss: 1.597, Test accuracy: 86.61
Round  58, Global train loss: 1.637, Global test loss: 1.614, Global test accuracy: 84.80
Round  59, Train loss: 1.607, Test loss: 1.597, Test accuracy: 86.60
Round  59, Global train loss: 1.607, Global test loss: 1.611, Global test accuracy: 85.48
Round  60, Train loss: 1.541, Test loss: 1.597, Test accuracy: 86.66
Round  60, Global train loss: 1.541, Global test loss: 1.612, Global test accuracy: 85.08
Round  61, Train loss: 1.572, Test loss: 1.597, Test accuracy: 86.67
Round  61, Global train loss: 1.572, Global test loss: 1.614, Global test accuracy: 84.94
Round  62, Train loss: 1.604, Test loss: 1.597, Test accuracy: 86.65
Round  62, Global train loss: 1.604, Global test loss: 1.608, Global test accuracy: 85.85
Round  63, Train loss: 1.507, Test loss: 1.597, Test accuracy: 86.61
Round  63, Global train loss: 1.507, Global test loss: 1.610, Global test accuracy: 85.45
Round  64, Train loss: 1.537, Test loss: 1.597, Test accuracy: 86.52
Round  64, Global train loss: 1.537, Global test loss: 1.613, Global test accuracy: 85.22
Round  65, Train loss: 1.539, Test loss: 1.597, Test accuracy: 86.55
Round  65, Global train loss: 1.539, Global test loss: 1.615, Global test accuracy: 84.81
Round  66, Train loss: 1.604, Test loss: 1.597, Test accuracy: 86.54
Round  66, Global train loss: 1.604, Global test loss: 1.610, Global test accuracy: 85.35
Round  67, Train loss: 1.572, Test loss: 1.597, Test accuracy: 86.60
Round  67, Global train loss: 1.572, Global test loss: 1.617, Global test accuracy: 84.83
Round  68, Train loss: 1.605, Test loss: 1.596, Test accuracy: 86.60
Round  68, Global train loss: 1.605, Global test loss: 1.609, Global test accuracy: 85.40
Round  69, Train loss: 1.539, Test loss: 1.596, Test accuracy: 86.62
Round  69, Global train loss: 1.539, Global test loss: 1.612, Global test accuracy: 85.15
Round  70, Train loss: 1.569, Test loss: 1.596, Test accuracy: 86.61
Round  70, Global train loss: 1.569, Global test loss: 1.608, Global test accuracy: 85.58
Round  71, Train loss: 1.570, Test loss: 1.596, Test accuracy: 86.63
Round  71, Global train loss: 1.570, Global test loss: 1.609, Global test accuracy: 85.41
Round  72, Train loss: 1.568, Test loss: 1.596, Test accuracy: 86.63
Round  72, Global train loss: 1.568, Global test loss: 1.609, Global test accuracy: 85.49
Round  73, Train loss: 1.537, Test loss: 1.596, Test accuracy: 86.67
Round  73, Global train loss: 1.537, Global test loss: 1.610, Global test accuracy: 85.45
Round  74, Train loss: 1.603, Test loss: 1.596, Test accuracy: 86.65
Round  74, Global train loss: 1.603, Global test loss: 1.610, Global test accuracy: 85.37
Round  75, Train loss: 1.604, Test loss: 1.596, Test accuracy: 86.65
Round  75, Global train loss: 1.604, Global test loss: 1.619, Global test accuracy: 84.65
Round  76, Train loss: 1.538, Test loss: 1.596, Test accuracy: 86.76
Round  76, Global train loss: 1.538, Global test loss: 1.609, Global test accuracy: 85.62
Round  77, Train loss: 1.569, Test loss: 1.596, Test accuracy: 86.74
Round  77, Global train loss: 1.569, Global test loss: 1.607, Global test accuracy: 85.48
Round  78, Train loss: 1.569, Test loss: 1.596, Test accuracy: 86.71
Round  78, Global train loss: 1.569, Global test loss: 1.608, Global test accuracy: 85.50
Round  79, Train loss: 1.536, Test loss: 1.596, Test accuracy: 86.66
Round  79, Global train loss: 1.536, Global test loss: 1.609, Global test accuracy: 85.63
Round  80, Train loss: 1.603, Test loss: 1.596, Test accuracy: 86.59
Round  80, Global train loss: 1.603, Global test loss: 1.608, Global test accuracy: 85.44
Round  81, Train loss: 1.600, Test loss: 1.596, Test accuracy: 86.61
Round  81, Global train loss: 1.600, Global test loss: 1.608, Global test accuracy: 85.42
Round  82, Train loss: 1.602, Test loss: 1.596, Test accuracy: 86.63
Round  82, Global train loss: 1.602, Global test loss: 1.610, Global test accuracy: 85.29
Round  83, Train loss: 1.571, Test loss: 1.596, Test accuracy: 86.67
Round  83, Global train loss: 1.571, Global test loss: 1.617, Global test accuracy: 84.56
Round  84, Train loss: 1.507, Test loss: 1.596, Test accuracy: 86.65
Round  84, Global train loss: 1.507, Global test loss: 1.609, Global test accuracy: 85.36
Round  85, Train loss: 1.599, Test loss: 1.596, Test accuracy: 86.62
Round  85, Global train loss: 1.599, Global test loss: 1.606, Global test accuracy: 85.61
Round  86, Train loss: 1.502, Test loss: 1.596, Test accuracy: 86.69
Round  86, Global train loss: 1.502, Global test loss: 1.606, Global test accuracy: 85.71
Round  87, Train loss: 1.537, Test loss: 1.595, Test accuracy: 86.66
Round  87, Global train loss: 1.537, Global test loss: 1.609, Global test accuracy: 85.38
Round  88, Train loss: 1.569, Test loss: 1.595, Test accuracy: 86.69
Round  88, Global train loss: 1.569, Global test loss: 1.606, Global test accuracy: 85.61
Round  89, Train loss: 1.539, Test loss: 1.595, Test accuracy: 86.69
Round  89, Global train loss: 1.539, Global test loss: 1.608, Global test accuracy: 85.55
Round  90, Train loss: 1.567, Test loss: 1.595, Test accuracy: 86.69
Round  90, Global train loss: 1.567, Global test loss: 1.607, Global test accuracy: 85.52
Round  91, Train loss: 1.570, Test loss: 1.595, Test accuracy: 86.68
Round  91, Global train loss: 1.570, Global test loss: 1.622, Global test accuracy: 84.13
Round  92, Train loss: 1.599, Test loss: 1.595, Test accuracy: 86.68
Round  92, Global train loss: 1.599, Global test loss: 1.614, Global test accuracy: 85.05
Round  93, Train loss: 1.569, Test loss: 1.595, Test accuracy: 86.62
Round  93, Global train loss: 1.569, Global test loss: 1.608, Global test accuracy: 85.58
Round  94, Train loss: 1.538, Test loss: 1.595, Test accuracy: 86.66
Round  94, Global train loss: 1.538, Global test loss: 1.609, Global test accuracy: 85.49
Round  95, Train loss: 1.603, Test loss: 1.595, Test accuracy: 86.61
Round  95, Global train loss: 1.603, Global test loss: 1.606, Global test accuracy: 85.69/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 1.600, Test loss: 1.595, Test accuracy: 86.64
Round  96, Global train loss: 1.600, Global test loss: 1.610, Global test accuracy: 85.23
Round  97, Train loss: 1.502, Test loss: 1.595, Test accuracy: 86.66
Round  97, Global train loss: 1.502, Global test loss: 1.610, Global test accuracy: 85.27
Round  98, Train loss: 1.600, Test loss: 1.595, Test accuracy: 86.65
Round  98, Global train loss: 1.600, Global test loss: 1.607, Global test accuracy: 85.71
Round  99, Train loss: 1.536, Test loss: 1.595, Test accuracy: 86.69
Round  99, Global train loss: 1.536, Global test loss: 1.611, Global test accuracy: 85.28
Final Round, Train loss: 1.567, Test loss: 1.595, Test accuracy: 86.71
Final Round, Global train loss: 1.567, Global test loss: 1.611, Global test accuracy: 85.28
Average accuracy final 10 rounds: 86.658 

Average global accuracy final 10 rounds: 85.295 

1425.8375265598297
[0.9893934726715088, 1.9787869453430176, 2.9208600521087646, 3.8629331588745117, 4.8120973110198975, 5.761261463165283, 6.574173927307129, 7.387086391448975, 8.211080551147461, 9.035074710845947, 9.854676246643066, 10.674277782440186, 11.539776086807251, 12.405274391174316, 13.252771615982056, 14.100268840789795, 14.91670846939087, 15.733148097991943, 16.59774136543274, 17.462334632873535, 18.26219081878662, 19.062047004699707, 19.918434381484985, 20.774821758270264, 21.678487300872803, 22.582152843475342, 23.42244601249695, 24.262739181518555, 25.187352180480957, 26.11196517944336, 27.056918382644653, 28.001871585845947, 28.956946849822998, 29.91202211380005, 30.855682134628296, 31.799342155456543, 32.727439403533936, 33.65553665161133, 34.6368305683136, 35.61812448501587, 36.479567527770996, 37.34101057052612, 38.278209924697876, 39.21540927886963, 40.13904166221619, 41.062674045562744, 41.893146991729736, 42.72361993789673, 43.5818247795105, 44.44002962112427, 45.27589297294617, 46.111756324768066, 46.96796178817749, 47.824167251586914, 48.69271183013916, 49.561256408691406, 50.37056803703308, 51.179879665374756, 52.06726551055908, 52.95465135574341, 53.87765121459961, 54.80065107345581, 55.758917808532715, 56.71718454360962, 57.65445923805237, 58.59173393249512, 59.43619108200073, 60.28064823150635, 61.13496208190918, 61.98927593231201, 62.838815689086914, 63.688355445861816, 64.52313470840454, 65.35791397094727, 66.20363593101501, 67.04935789108276, 67.91013288497925, 68.77090787887573, 69.65947318077087, 70.54803848266602, 71.41630339622498, 72.28456830978394, 73.15282607078552, 74.02108383178711, 74.94172716140747, 75.86237049102783, 76.7742166519165, 77.68606281280518, 78.55551242828369, 79.4249620437622, 80.24489235877991, 81.06482267379761, 81.90490126609802, 82.74497985839844, 83.6286129951477, 84.51224613189697, 85.33696031570435, 86.16167449951172, 87.00019454956055, 87.83871459960938, 88.66091132164001, 89.48310804367065, 90.33346462249756, 91.18382120132446, 92.05973958969116, 92.93565797805786, 93.72419357299805, 94.51272916793823, 95.40987062454224, 96.30701208114624, 97.2776107788086, 98.24820947647095, 99.1898148059845, 100.13142013549805, 100.97848439216614, 101.82554864883423, 102.62210416793823, 103.41865968704224, 104.26683926582336, 105.11501884460449, 105.93495225906372, 106.75488567352295, 107.60626816749573, 108.4576506614685, 109.29961800575256, 110.14158535003662, 110.9456856250763, 111.74978590011597, 112.57516837120056, 113.40055084228516, 114.21765303611755, 115.03475522994995, 115.82785081863403, 116.62094640731812, 117.50325345993042, 118.38556051254272, 119.20702195167542, 120.0284833908081, 120.8090832233429, 121.58968305587769, 122.42438459396362, 123.25908613204956, 124.13187003135681, 125.00465393066406, 125.80357718467712, 126.60250043869019, 127.45693588256836, 128.31137132644653, 129.13399529457092, 129.9566192626953, 130.7729525566101, 131.5892858505249, 132.4626817703247, 133.3360776901245, 134.16798615455627, 134.99989461898804, 135.8872263431549, 136.77455806732178, 137.65266799926758, 138.53077793121338, 139.3418629169464, 140.15294790267944, 140.9725534915924, 141.79215908050537, 142.6363959312439, 143.48063278198242, 144.29573845863342, 145.11084413528442, 145.99909448623657, 146.88734483718872, 147.72940397262573, 148.57146310806274, 149.3899383544922, 150.20841360092163, 151.05758047103882, 151.906747341156, 152.696537733078, 153.486328125, 154.34965682029724, 155.21298551559448, 156.05148196220398, 156.88997840881348, 157.71909880638123, 158.54821920394897, 159.52631402015686, 160.50440883636475, 161.34839153289795, 162.19237422943115, 163.03201150894165, 163.87164878845215, 164.70481991767883, 165.53799104690552, 166.41619515419006, 167.2943992614746, 168.1765115261078, 169.05862379074097, 169.91290068626404, 170.7671775817871, 171.6078643798828, 172.44855117797852, 174.15608167648315, 175.8636121749878]
[29.53, 29.53, 28.75, 28.75, 43.96, 43.96, 56.43, 56.43, 66.99, 66.99, 70.66, 70.66, 75.31, 75.31, 77.86, 77.86, 79.95, 79.95, 79.9, 79.9, 81.22, 81.22, 83.12, 83.12, 84.3, 84.3, 84.53, 84.53, 84.68, 84.68, 84.85, 84.85, 84.8, 84.8, 85.03, 85.03, 85.04, 85.04, 85.17, 85.17, 85.26, 85.26, 85.32, 85.32, 85.35, 85.35, 85.36, 85.36, 85.47, 85.47, 85.53, 85.53, 85.56, 85.56, 85.58, 85.58, 85.86, 85.86, 85.73, 85.73, 85.71, 85.71, 85.77, 85.77, 85.83, 85.83, 86.01, 86.01, 86.04, 86.04, 86.06, 86.06, 85.92, 85.92, 86.1, 86.1, 85.97, 85.97, 86.0, 86.0, 86.09, 86.09, 86.32, 86.32, 86.37, 86.37, 86.35, 86.35, 86.32, 86.32, 86.31, 86.31, 86.34, 86.34, 86.34, 86.34, 86.35, 86.35, 86.32, 86.32, 86.23, 86.23, 86.33, 86.33, 86.44, 86.44, 86.52, 86.52, 86.49, 86.49, 86.51, 86.51, 86.56, 86.56, 86.62, 86.62, 86.61, 86.61, 86.6, 86.6, 86.66, 86.66, 86.67, 86.67, 86.65, 86.65, 86.61, 86.61, 86.52, 86.52, 86.55, 86.55, 86.54, 86.54, 86.6, 86.6, 86.6, 86.6, 86.62, 86.62, 86.61, 86.61, 86.63, 86.63, 86.63, 86.63, 86.67, 86.67, 86.65, 86.65, 86.65, 86.65, 86.76, 86.76, 86.74, 86.74, 86.71, 86.71, 86.66, 86.66, 86.59, 86.59, 86.61, 86.61, 86.63, 86.63, 86.67, 86.67, 86.65, 86.65, 86.62, 86.62, 86.69, 86.69, 86.66, 86.66, 86.69, 86.69, 86.69, 86.69, 86.69, 86.69, 86.68, 86.68, 86.68, 86.68, 86.62, 86.62, 86.66, 86.66, 86.61, 86.61, 86.64, 86.64, 86.66, 86.66, 86.65, 86.65, 86.69, 86.69, 86.71, 86.71]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.297, Test loss: 2.300, Test accuracy: 12.51
Round   1, Train loss: 2.295, Test loss: 2.295, Test accuracy: 30.59
Round   2, Train loss: 2.287, Test loss: 2.287, Test accuracy: 36.46
Round   3, Train loss: 2.262, Test loss: 2.258, Test accuracy: 35.84
Round   4, Train loss: 2.160, Test loss: 2.148, Test accuracy: 34.40
Round   5, Train loss: 2.004, Test loss: 2.027, Test accuracy: 56.73
Round   6, Train loss: 1.865, Test loss: 1.910, Test accuracy: 64.98
Round   7, Train loss: 1.825, Test loss: 1.833, Test accuracy: 70.49
Round   8, Train loss: 1.740, Test loss: 1.786, Test accuracy: 73.72
Round   9, Train loss: 1.635, Test loss: 1.737, Test accuracy: 76.53
Round  10, Train loss: 1.661, Test loss: 1.701, Test accuracy: 78.90
Round  11, Train loss: 1.623, Test loss: 1.687, Test accuracy: 79.98
Round  12, Train loss: 1.606, Test loss: 1.664, Test accuracy: 81.51
Round  13, Train loss: 1.653, Test loss: 1.654, Test accuracy: 82.54
Round  14, Train loss: 1.644, Test loss: 1.638, Test accuracy: 84.04
Round  15, Train loss: 1.617, Test loss: 1.633, Test accuracy: 84.31
Round  16, Train loss: 1.562, Test loss: 1.625, Test accuracy: 84.94
Round  17, Train loss: 1.623, Test loss: 1.619, Test accuracy: 85.43
Round  18, Train loss: 1.611, Test loss: 1.619, Test accuracy: 85.44
Round  19, Train loss: 1.605, Test loss: 1.617, Test accuracy: 85.48
Round  20, Train loss: 1.582, Test loss: 1.616, Test accuracy: 85.53
Round  21, Train loss: 1.556, Test loss: 1.607, Test accuracy: 86.35
Round  22, Train loss: 1.605, Test loss: 1.605, Test accuracy: 86.34
Round  23, Train loss: 1.547, Test loss: 1.604, Test accuracy: 86.59
Round  24, Train loss: 1.583, Test loss: 1.596, Test accuracy: 87.29
Round  25, Train loss: 1.553, Test loss: 1.594, Test accuracy: 87.52
Round  26, Train loss: 1.505, Test loss: 1.594, Test accuracy: 87.39
Round  27, Train loss: 1.636, Test loss: 1.592, Test accuracy: 87.48
Round  28, Train loss: 1.559, Test loss: 1.592, Test accuracy: 87.51
Round  29, Train loss: 1.564, Test loss: 1.591, Test accuracy: 87.66
Round  30, Train loss: 1.592, Test loss: 1.591, Test accuracy: 87.56
Round  31, Train loss: 1.594, Test loss: 1.592, Test accuracy: 87.37
Round  32, Train loss: 1.625, Test loss: 1.592, Test accuracy: 87.41
Round  33, Train loss: 1.532, Test loss: 1.591, Test accuracy: 87.51
Round  34, Train loss: 1.533, Test loss: 1.587, Test accuracy: 87.83
Round  35, Train loss: 1.585, Test loss: 1.588, Test accuracy: 87.86
Round  36, Train loss: 1.541, Test loss: 1.588, Test accuracy: 87.68
Round  37, Train loss: 1.532, Test loss: 1.588, Test accuracy: 87.70
Round  38, Train loss: 1.597, Test loss: 1.586, Test accuracy: 87.87
Round  39, Train loss: 1.521, Test loss: 1.586, Test accuracy: 87.77
Round  40, Train loss: 1.554, Test loss: 1.585, Test accuracy: 87.88
Round  41, Train loss: 1.556, Test loss: 1.585, Test accuracy: 87.88
Round  42, Train loss: 1.527, Test loss: 1.584, Test accuracy: 87.96
Round  43, Train loss: 1.587, Test loss: 1.585, Test accuracy: 87.85
Round  44, Train loss: 1.523, Test loss: 1.584, Test accuracy: 88.03
Round  45, Train loss: 1.551, Test loss: 1.585, Test accuracy: 87.96
Round  46, Train loss: 1.619, Test loss: 1.583, Test accuracy: 88.02
Round  47, Train loss: 1.583, Test loss: 1.583, Test accuracy: 88.12
Round  48, Train loss: 1.521, Test loss: 1.584, Test accuracy: 88.01
Round  49, Train loss: 1.590, Test loss: 1.582, Test accuracy: 88.26
Round  50, Train loss: 1.582, Test loss: 1.582, Test accuracy: 88.26
Round  51, Train loss: 1.581, Test loss: 1.583, Test accuracy: 88.06
Round  52, Train loss: 1.524, Test loss: 1.583, Test accuracy: 88.04
Round  53, Train loss: 1.563, Test loss: 1.578, Test accuracy: 88.55
Round  54, Train loss: 1.553, Test loss: 1.577, Test accuracy: 88.53
Round  55, Train loss: 1.529, Test loss: 1.577, Test accuracy: 88.67
Round  56, Train loss: 1.520, Test loss: 1.577, Test accuracy: 88.60
Round  57, Train loss: 1.523, Test loss: 1.577, Test accuracy: 88.70
Round  58, Train loss: 1.509, Test loss: 1.571, Test accuracy: 89.45
Round  59, Train loss: 1.531, Test loss: 1.562, Test accuracy: 90.17
Round  60, Train loss: 1.530, Test loss: 1.561, Test accuracy: 90.38
Round  61, Train loss: 1.535, Test loss: 1.561, Test accuracy: 90.37
Round  62, Train loss: 1.566, Test loss: 1.559, Test accuracy: 90.47
Round  63, Train loss: 1.497, Test loss: 1.559, Test accuracy: 90.68
Round  64, Train loss: 1.513, Test loss: 1.558, Test accuracy: 90.65
Round  65, Train loss: 1.529, Test loss: 1.558, Test accuracy: 90.70
Round  66, Train loss: 1.485, Test loss: 1.558, Test accuracy: 90.50
Round  67, Train loss: 1.517, Test loss: 1.558, Test accuracy: 90.57
Round  68, Train loss: 1.489, Test loss: 1.557, Test accuracy: 90.62
Round  69, Train loss: 1.547, Test loss: 1.557, Test accuracy: 90.67
Round  70, Train loss: 1.558, Test loss: 1.556, Test accuracy: 90.87
Round  71, Train loss: 1.517, Test loss: 1.556, Test accuracy: 90.81
Round  72, Train loss: 1.533, Test loss: 1.555, Test accuracy: 90.78
Round  73, Train loss: 1.486, Test loss: 1.554, Test accuracy: 90.92
Round  74, Train loss: 1.556, Test loss: 1.555, Test accuracy: 90.95
Round  75, Train loss: 1.486, Test loss: 1.555, Test accuracy: 90.98
Round  76, Train loss: 1.488, Test loss: 1.555, Test accuracy: 90.98
Round  77, Train loss: 1.519, Test loss: 1.555, Test accuracy: 91.00
Round  78, Train loss: 1.515, Test loss: 1.555, Test accuracy: 90.98
Round  79, Train loss: 1.512, Test loss: 1.555, Test accuracy: 90.87
Round  80, Train loss: 1.482, Test loss: 1.556, Test accuracy: 90.86
Round  81, Train loss: 1.522, Test loss: 1.555, Test accuracy: 90.88
Round  82, Train loss: 1.480, Test loss: 1.555, Test accuracy: 90.92
Round  83, Train loss: 1.517, Test loss: 1.554, Test accuracy: 91.01
Round  84, Train loss: 1.486, Test loss: 1.553, Test accuracy: 91.10
Round  85, Train loss: 1.485, Test loss: 1.553, Test accuracy: 91.01
Round  86, Train loss: 1.546, Test loss: 1.553, Test accuracy: 91.05
Round  87, Train loss: 1.542, Test loss: 1.553, Test accuracy: 91.00
Round  88, Train loss: 1.478, Test loss: 1.553, Test accuracy: 91.04
Round  89, Train loss: 1.585, Test loss: 1.553, Test accuracy: 90.99
Round  90, Train loss: 1.543, Test loss: 1.552, Test accuracy: 91.13
Round  91, Train loss: 1.476, Test loss: 1.552, Test accuracy: 91.10
Round  92, Train loss: 1.484, Test loss: 1.553, Test accuracy: 90.93
Round  93, Train loss: 1.477, Test loss: 1.553, Test accuracy: 90.99
Round  94, Train loss: 1.540, Test loss: 1.553, Test accuracy: 91.02
Round  95, Train loss: 1.519, Test loss: 1.552, Test accuracy: 91.16
Round  96, Train loss: 1.544, Test loss: 1.552, Test accuracy: 91.13
Round  97, Train loss: 1.483, Test loss: 1.552, Test accuracy: 91.00
Round  98, Train loss: 1.608, Test loss: 1.553, Test accuracy: 91.06/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  99, Train loss: 1.514, Test loss: 1.554, Test accuracy: 90.96
Final Round, Train loss: 1.516, Test loss: 1.546, Test accuracy: 91.75
Average accuracy final 10 rounds: 91.04799999999999 

1117.599608182907
[0.8995027542114258, 1.7990055084228516, 2.7199342250823975, 3.6408629417419434, 4.5330727100372314, 5.4252824783325195, 6.293851137161255, 7.16241979598999, 7.948780059814453, 8.735140323638916, 9.567275047302246, 10.399409770965576, 11.215192079544067, 12.030974388122559, 12.831717729568481, 13.632461071014404, 14.425569772720337, 15.21867847442627, 16.026885271072388, 16.835092067718506, 17.66100573539734, 18.486919403076172, 19.337005376815796, 20.18709135055542, 21.04936647415161, 21.911641597747803, 22.79190158843994, 23.67216157913208, 24.563749074935913, 25.455336570739746, 26.3752601146698, 27.295183658599854, 28.159957885742188, 29.02473211288452, 29.82684016227722, 30.628948211669922, 31.416285037994385, 32.20362186431885, 33.077472448349, 33.95132303237915, 34.739142417907715, 35.52696180343628, 36.35140252113342, 37.175843238830566, 37.96941018104553, 38.7629771232605, 39.584622621536255, 40.40626811981201, 41.22258901596069, 42.038909912109375, 42.86136245727539, 43.683815002441406, 44.52112698554993, 45.35843896865845, 46.17270517349243, 46.986971378326416, 47.78979206085205, 48.592612743377686, 49.43327760696411, 50.27394247055054, 51.083245277404785, 51.89254808425903, 52.684346199035645, 53.476144313812256, 54.26233148574829, 55.048518657684326, 55.88935947418213, 56.73020029067993, 57.57865285873413, 58.42710542678833, 59.2436044216156, 60.06010341644287, 60.887150287628174, 61.71419715881348, 62.56860685348511, 63.42301654815674, 64.23735022544861, 65.05168390274048, 65.87039303779602, 66.68910217285156, 67.51619839668274, 68.34329462051392, 69.15919637680054, 69.97509813308716, 70.78043293952942, 71.58576774597168, 72.45440316200256, 73.32303857803345, 74.1358597278595, 74.94868087768555, 75.75520539283752, 76.5617299079895, 77.3702507019043, 78.17877149581909, 79.01084232330322, 79.84291315078735, 80.68906950950623, 81.5352258682251, 82.37435936927795, 83.21349287033081, 84.02957153320312, 84.84565019607544, 85.68625068664551, 86.52685117721558, 87.37256932258606, 88.21828746795654, 89.06269836425781, 89.90710926055908, 90.81729221343994, 91.7274751663208, 92.57388424873352, 93.42029333114624, 94.27841663360596, 95.13653993606567, 96.0308575630188, 96.92517518997192, 97.78511166572571, 98.64504814147949, 99.46652960777283, 100.28801107406616, 101.13456869125366, 101.98112630844116, 102.82528138160706, 103.66943645477295, 104.58469247817993, 105.49994850158691, 106.32165551185608, 107.14336252212524, 107.96443009376526, 108.78549766540527, 109.62029457092285, 110.45509147644043, 111.28408813476562, 112.11308479309082, 112.95369386672974, 113.79430294036865, 114.65907716751099, 115.52385139465332, 116.3168740272522, 117.10989665985107, 117.92689061164856, 118.74388456344604, 119.61770248413086, 120.49152040481567, 121.32021188735962, 122.14890336990356, 122.96231412887573, 123.7757248878479, 124.60359692573547, 125.43146896362305, 126.262460231781, 127.09345149993896, 127.92410850524902, 128.75476551055908, 129.57560086250305, 130.39643621444702, 131.21678709983826, 132.0371379852295, 132.80364537239075, 133.570152759552, 134.3627655506134, 135.1553783416748, 136.01349449157715, 136.8716106414795, 137.66753935813904, 138.46346807479858, 139.27155828475952, 140.07964849472046, 140.9035804271698, 141.72751235961914, 142.55911111831665, 143.39070987701416, 144.23446559906006, 145.07822132110596, 145.94434905052185, 146.81047677993774, 147.65514469146729, 148.49981260299683, 149.32669687271118, 150.15358114242554, 150.9443702697754, 151.73515939712524, 152.66447520256042, 153.5937910079956, 154.4596390724182, 155.32548713684082, 156.16471147537231, 157.0039358139038, 157.7660083770752, 158.52808094024658, 159.44924354553223, 160.37040615081787, 161.20738792419434, 162.0443696975708, 162.8736765384674, 163.702983379364, 164.47552585601807, 165.24806833267212, 166.1104609966278, 166.9728536605835, 168.59046387672424, 170.208074092865]
[12.51, 12.51, 30.59, 30.59, 36.46, 36.46, 35.84, 35.84, 34.4, 34.4, 56.73, 56.73, 64.98, 64.98, 70.49, 70.49, 73.72, 73.72, 76.53, 76.53, 78.9, 78.9, 79.98, 79.98, 81.51, 81.51, 82.54, 82.54, 84.04, 84.04, 84.31, 84.31, 84.94, 84.94, 85.43, 85.43, 85.44, 85.44, 85.48, 85.48, 85.53, 85.53, 86.35, 86.35, 86.34, 86.34, 86.59, 86.59, 87.29, 87.29, 87.52, 87.52, 87.39, 87.39, 87.48, 87.48, 87.51, 87.51, 87.66, 87.66, 87.56, 87.56, 87.37, 87.37, 87.41, 87.41, 87.51, 87.51, 87.83, 87.83, 87.86, 87.86, 87.68, 87.68, 87.7, 87.7, 87.87, 87.87, 87.77, 87.77, 87.88, 87.88, 87.88, 87.88, 87.96, 87.96, 87.85, 87.85, 88.03, 88.03, 87.96, 87.96, 88.02, 88.02, 88.12, 88.12, 88.01, 88.01, 88.26, 88.26, 88.26, 88.26, 88.06, 88.06, 88.04, 88.04, 88.55, 88.55, 88.53, 88.53, 88.67, 88.67, 88.6, 88.6, 88.7, 88.7, 89.45, 89.45, 90.17, 90.17, 90.38, 90.38, 90.37, 90.37, 90.47, 90.47, 90.68, 90.68, 90.65, 90.65, 90.7, 90.7, 90.5, 90.5, 90.57, 90.57, 90.62, 90.62, 90.67, 90.67, 90.87, 90.87, 90.81, 90.81, 90.78, 90.78, 90.92, 90.92, 90.95, 90.95, 90.98, 90.98, 90.98, 90.98, 91.0, 91.0, 90.98, 90.98, 90.87, 90.87, 90.86, 90.86, 90.88, 90.88, 90.92, 90.92, 91.01, 91.01, 91.1, 91.1, 91.01, 91.01, 91.05, 91.05, 91.0, 91.0, 91.04, 91.04, 90.99, 90.99, 91.13, 91.13, 91.1, 91.1, 90.93, 90.93, 90.99, 90.99, 91.02, 91.02, 91.16, 91.16, 91.13, 91.13, 91.0, 91.0, 91.06, 91.06, 90.96, 90.96, 91.75, 91.75]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedper
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.289, Test loss: 2.291, Test accuracy: 16.97
Round   1, Train loss: 2.197, Test loss: 2.207, Test accuracy: 20.78
Round   2, Train loss: 1.932, Test loss: 2.016, Test accuracy: 48.64
Round   3, Train loss: 1.750, Test loss: 1.888, Test accuracy: 61.50
Round   4, Train loss: 1.762, Test loss: 1.799, Test accuracy: 70.15
Round   5, Train loss: 1.685, Test loss: 1.764, Test accuracy: 72.65
Round   6, Train loss: 1.606, Test loss: 1.685, Test accuracy: 79.64
Round   7, Train loss: 1.548, Test loss: 1.661, Test accuracy: 81.34
Round   8, Train loss: 1.601, Test loss: 1.630, Test accuracy: 84.82
Round   9, Train loss: 1.560, Test loss: 1.617, Test accuracy: 85.85
Round  10, Train loss: 1.604, Test loss: 1.603, Test accuracy: 87.03
Round  11, Train loss: 1.555, Test loss: 1.590, Test accuracy: 88.27
Round  12, Train loss: 1.522, Test loss: 1.585, Test accuracy: 88.65
Round  13, Train loss: 1.527, Test loss: 1.582, Test accuracy: 88.86
Round  14, Train loss: 1.565, Test loss: 1.578, Test accuracy: 89.21
Round  15, Train loss: 1.533, Test loss: 1.577, Test accuracy: 89.13
Round  16, Train loss: 1.535, Test loss: 1.575, Test accuracy: 89.35
Round  17, Train loss: 1.560, Test loss: 1.573, Test accuracy: 89.45
Round  18, Train loss: 1.554, Test loss: 1.572, Test accuracy: 89.43
Round  19, Train loss: 1.532, Test loss: 1.571, Test accuracy: 89.56
Round  20, Train loss: 1.557, Test loss: 1.571, Test accuracy: 89.59
Round  21, Train loss: 1.525, Test loss: 1.569, Test accuracy: 89.65
Round  22, Train loss: 1.531, Test loss: 1.568, Test accuracy: 89.80
Round  23, Train loss: 1.527, Test loss: 1.568, Test accuracy: 89.78
Round  24, Train loss: 1.524, Test loss: 1.567, Test accuracy: 89.97
Round  25, Train loss: 1.584, Test loss: 1.567, Test accuracy: 89.92
Round  26, Train loss: 1.521, Test loss: 1.566, Test accuracy: 89.93
Round  27, Train loss: 1.516, Test loss: 1.565, Test accuracy: 89.94
Round  28, Train loss: 1.520, Test loss: 1.566, Test accuracy: 89.83
Round  29, Train loss: 1.551, Test loss: 1.565, Test accuracy: 90.07
Round  30, Train loss: 1.513, Test loss: 1.565, Test accuracy: 90.03
Round  31, Train loss: 1.531, Test loss: 1.561, Test accuracy: 90.41
Round  32, Train loss: 1.517, Test loss: 1.560, Test accuracy: 90.51
Round  33, Train loss: 1.490, Test loss: 1.557, Test accuracy: 90.75
Round  34, Train loss: 1.523, Test loss: 1.556, Test accuracy: 90.89
Round  35, Train loss: 1.512, Test loss: 1.556, Test accuracy: 90.95
Round  36, Train loss: 1.526, Test loss: 1.556, Test accuracy: 90.79
Round  37, Train loss: 1.550, Test loss: 1.555, Test accuracy: 90.90
Round  38, Train loss: 1.513, Test loss: 1.556, Test accuracy: 90.85
Round  39, Train loss: 1.512, Test loss: 1.555, Test accuracy: 90.92
Round  40, Train loss: 1.515, Test loss: 1.555, Test accuracy: 90.90
Round  41, Train loss: 1.518, Test loss: 1.554, Test accuracy: 90.96
Round  42, Train loss: 1.476, Test loss: 1.554, Test accuracy: 90.96
Round  43, Train loss: 1.547, Test loss: 1.554, Test accuracy: 90.91
Round  44, Train loss: 1.482, Test loss: 1.553, Test accuracy: 91.08
Round  45, Train loss: 1.509, Test loss: 1.554, Test accuracy: 91.04
Round  46, Train loss: 1.510, Test loss: 1.553, Test accuracy: 91.11
Round  47, Train loss: 1.518, Test loss: 1.553, Test accuracy: 91.01
Round  48, Train loss: 1.547, Test loss: 1.553, Test accuracy: 91.10
Round  49, Train loss: 1.512, Test loss: 1.553, Test accuracy: 91.15
Round  50, Train loss: 1.510, Test loss: 1.552, Test accuracy: 91.14
Round  51, Train loss: 1.516, Test loss: 1.552, Test accuracy: 91.09
Round  52, Train loss: 1.510, Test loss: 1.552, Test accuracy: 91.11
Round  53, Train loss: 1.514, Test loss: 1.552, Test accuracy: 91.07
Round  54, Train loss: 1.544, Test loss: 1.552, Test accuracy: 91.20
Round  55, Train loss: 1.511, Test loss: 1.552, Test accuracy: 91.19
Round  56, Train loss: 1.514, Test loss: 1.552, Test accuracy: 91.09
Round  57, Train loss: 1.547, Test loss: 1.552, Test accuracy: 91.15
Round  58, Train loss: 1.509, Test loss: 1.552, Test accuracy: 91.24
Round  59, Train loss: 1.507, Test loss: 1.551, Test accuracy: 91.24
Round  60, Train loss: 1.475, Test loss: 1.551, Test accuracy: 91.24
Round  61, Train loss: 1.479, Test loss: 1.551, Test accuracy: 91.26
Round  62, Train loss: 1.510, Test loss: 1.551, Test accuracy: 91.34
Round  63, Train loss: 1.572, Test loss: 1.551, Test accuracy: 91.32
Round  64, Train loss: 1.480, Test loss: 1.551, Test accuracy: 91.22
Round  65, Train loss: 1.542, Test loss: 1.551, Test accuracy: 91.33
Round  66, Train loss: 1.512, Test loss: 1.551, Test accuracy: 91.28
Round  67, Train loss: 1.576, Test loss: 1.551, Test accuracy: 91.18
Round  68, Train loss: 1.541, Test loss: 1.551, Test accuracy: 91.29
Round  69, Train loss: 1.543, Test loss: 1.551, Test accuracy: 91.26
Round  70, Train loss: 1.541, Test loss: 1.551, Test accuracy: 91.32
Round  71, Train loss: 1.541, Test loss: 1.551, Test accuracy: 91.30
Round  72, Train loss: 1.508, Test loss: 1.551, Test accuracy: 91.33
Round  73, Train loss: 1.507, Test loss: 1.551, Test accuracy: 91.30
Round  74, Train loss: 1.506, Test loss: 1.550, Test accuracy: 91.32
Round  75, Train loss: 1.508, Test loss: 1.550, Test accuracy: 91.36
Round  76, Train loss: 1.506, Test loss: 1.551, Test accuracy: 91.33
Round  77, Train loss: 1.508, Test loss: 1.550, Test accuracy: 91.29
Round  78, Train loss: 1.478, Test loss: 1.550, Test accuracy: 91.32
Round  79, Train loss: 1.542, Test loss: 1.550, Test accuracy: 91.35
Round  80, Train loss: 1.508, Test loss: 1.550, Test accuracy: 91.39
Round  81, Train loss: 1.538, Test loss: 1.550, Test accuracy: 91.39
Round  82, Train loss: 1.541, Test loss: 1.550, Test accuracy: 91.35
Round  83, Train loss: 1.538, Test loss: 1.550, Test accuracy: 91.32
Round  84, Train loss: 1.540, Test loss: 1.550, Test accuracy: 91.38
Round  85, Train loss: 1.506, Test loss: 1.549, Test accuracy: 91.34
Round  86, Train loss: 1.571, Test loss: 1.550, Test accuracy: 91.32
Round  87, Train loss: 1.569, Test loss: 1.550, Test accuracy: 91.34
Round  88, Train loss: 1.507, Test loss: 1.549, Test accuracy: 91.46
Round  89, Train loss: 1.503, Test loss: 1.549, Test accuracy: 91.39
Round  90, Train loss: 1.507, Test loss: 1.549, Test accuracy: 91.51
Round  91, Train loss: 1.476, Test loss: 1.548, Test accuracy: 91.50
Round  92, Train loss: 1.536, Test loss: 1.548, Test accuracy: 91.56
Round  93, Train loss: 1.569, Test loss: 1.549, Test accuracy: 91.57
Round  94, Train loss: 1.475, Test loss: 1.548, Test accuracy: 91.52
Round  95, Train loss: 1.504, Test loss: 1.548, Test accuracy: 91.57
Round  96, Train loss: 1.539, Test loss: 1.549, Test accuracy: 91.54
Round  97, Train loss: 1.536, Test loss: 1.548, Test accuracy: 91.60
Round  98, Train loss: 1.518, Test loss: 1.540, Test accuracy: 92.32/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  99, Train loss: 1.473, Test loss: 1.540, Test accuracy: 92.42
Final Round, Train loss: 1.505, Test loss: 1.540, Test accuracy: 92.44
Average accuracy final 10 rounds: 91.711 

1126.3949785232544
[1.0622339248657227, 2.1244678497314453, 3.0357155799865723, 3.946963310241699, 4.861309766769409, 5.775656223297119, 6.639455795288086, 7.503255367279053, 8.416320562362671, 9.329385757446289, 10.304528951644897, 11.279672145843506, 12.209454774856567, 13.139237403869629, 14.080390691757202, 15.021543979644775, 15.94789743423462, 16.874250888824463, 17.819925785064697, 18.76560068130493, 19.600630521774292, 20.435660362243652, 21.330867290496826, 22.22607421875, 23.08634877204895, 23.9466233253479, 24.78355312347412, 25.620482921600342, 26.446550846099854, 27.272618770599365, 28.132672548294067, 28.99272632598877, 29.7877516746521, 30.58277702331543, 31.4533052444458, 32.32383346557617, 33.12722182273865, 33.93061017990112, 34.75564002990723, 35.58066987991333, 36.421528816223145, 37.26238775253296, 38.125444173812866, 38.98850059509277, 39.842586040496826, 40.69667148590088, 41.6079580783844, 42.51924467086792, 43.340604066848755, 44.16196346282959, 45.02764534950256, 45.89332723617554, 46.71605038642883, 47.53877353668213, 48.402068853378296, 49.26536417007446, 50.110554218292236, 50.95574426651001, 51.7863883972168, 52.617032527923584, 53.44526290893555, 54.27349328994751, 55.144251108169556, 56.0150089263916, 56.84492349624634, 57.674838066101074, 58.54278635978699, 59.4107346534729, 60.19867920875549, 60.986623764038086, 61.84397029876709, 62.701316833496094, 63.57066369056702, 64.44001054763794, 65.29087209701538, 66.14173364639282, 67.00498056411743, 67.86822748184204, 68.72416424751282, 69.5801010131836, 70.37453198432922, 71.16896295547485, 72.06809616088867, 72.96722936630249, 73.82561707496643, 74.68400478363037, 75.51231098175049, 76.3406171798706, 77.16023087501526, 77.97984457015991, 78.85600876808167, 79.73217296600342, 80.58971428871155, 81.44725561141968, 82.30451035499573, 83.16176509857178, 84.08828806877136, 85.01481103897095, 85.9360773563385, 86.85734367370605, 87.77065658569336, 88.68396949768066, 89.62460255622864, 90.56523561477661, 91.52253222465515, 92.47982883453369, 93.4680688381195, 94.45630884170532, 95.37723660469055, 96.29816436767578, 97.1945903301239, 98.09101629257202, 99.02852153778076, 99.9660267829895, 100.89803171157837, 101.83003664016724, 102.64992928504944, 103.46982192993164, 104.34637212753296, 105.22292232513428, 106.09249305725098, 106.96206378936768, 107.82337641716003, 108.68468904495239, 109.55488872528076, 110.42508840560913, 111.28963494300842, 112.15418148040771, 112.9785807132721, 113.80297994613647, 114.68442106246948, 115.56586217880249, 116.41034603118896, 117.25482988357544, 118.10493016242981, 118.95503044128418, 119.7902307510376, 120.62543106079102, 121.51355528831482, 122.40167951583862, 123.2683629989624, 124.13504648208618, 124.96500015258789, 125.7949538230896, 126.6411509513855, 127.4873480796814, 128.35311937332153, 129.21889066696167, 130.0683250427246, 130.91775941848755, 131.81709480285645, 132.71643018722534, 133.57025408744812, 134.4240779876709, 135.27495861053467, 136.12583923339844, 136.9327530860901, 137.73966693878174, 138.56430864334106, 139.3889503479004, 140.18869352340698, 140.98843669891357, 141.77749490737915, 142.56655311584473, 143.38945364952087, 144.21235418319702, 145.04153990745544, 145.87072563171387, 146.65754342079163, 147.44436120986938, 148.26367831230164, 149.0829954147339, 149.89594507217407, 150.70889472961426, 151.53763246536255, 152.36637020111084, 153.16039085388184, 153.95441150665283, 154.7518699169159, 155.54932832717896, 156.45411658287048, 157.358904838562, 158.2050769329071, 159.0512490272522, 159.8221151828766, 160.59298133850098, 161.5095624923706, 162.42614364624023, 163.34821486473083, 164.27028608322144, 165.16432237625122, 166.058358669281, 167.02406334877014, 167.98976802825928, 168.8209319114685, 169.65209579467773, 170.42061519622803, 171.18913459777832, 172.00680255889893, 172.82447052001953, 174.38388991355896, 175.9433093070984]
[16.97, 16.97, 20.78, 20.78, 48.64, 48.64, 61.5, 61.5, 70.15, 70.15, 72.65, 72.65, 79.64, 79.64, 81.34, 81.34, 84.82, 84.82, 85.85, 85.85, 87.03, 87.03, 88.27, 88.27, 88.65, 88.65, 88.86, 88.86, 89.21, 89.21, 89.13, 89.13, 89.35, 89.35, 89.45, 89.45, 89.43, 89.43, 89.56, 89.56, 89.59, 89.59, 89.65, 89.65, 89.8, 89.8, 89.78, 89.78, 89.97, 89.97, 89.92, 89.92, 89.93, 89.93, 89.94, 89.94, 89.83, 89.83, 90.07, 90.07, 90.03, 90.03, 90.41, 90.41, 90.51, 90.51, 90.75, 90.75, 90.89, 90.89, 90.95, 90.95, 90.79, 90.79, 90.9, 90.9, 90.85, 90.85, 90.92, 90.92, 90.9, 90.9, 90.96, 90.96, 90.96, 90.96, 90.91, 90.91, 91.08, 91.08, 91.04, 91.04, 91.11, 91.11, 91.01, 91.01, 91.1, 91.1, 91.15, 91.15, 91.14, 91.14, 91.09, 91.09, 91.11, 91.11, 91.07, 91.07, 91.2, 91.2, 91.19, 91.19, 91.09, 91.09, 91.15, 91.15, 91.24, 91.24, 91.24, 91.24, 91.24, 91.24, 91.26, 91.26, 91.34, 91.34, 91.32, 91.32, 91.22, 91.22, 91.33, 91.33, 91.28, 91.28, 91.18, 91.18, 91.29, 91.29, 91.26, 91.26, 91.32, 91.32, 91.3, 91.3, 91.33, 91.33, 91.3, 91.3, 91.32, 91.32, 91.36, 91.36, 91.33, 91.33, 91.29, 91.29, 91.32, 91.32, 91.35, 91.35, 91.39, 91.39, 91.39, 91.39, 91.35, 91.35, 91.32, 91.32, 91.38, 91.38, 91.34, 91.34, 91.32, 91.32, 91.34, 91.34, 91.46, 91.46, 91.39, 91.39, 91.51, 91.51, 91.5, 91.5, 91.56, 91.56, 91.57, 91.57, 91.52, 91.52, 91.57, 91.57, 91.54, 91.54, 91.6, 91.6, 92.32, 92.32, 92.42, 92.42, 92.44, 92.44]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

lg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 17098 (global); Percentage 3.11 (17098/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.291, Test loss: 2.293, Test accuracy: 36.92
Round   1, Train loss: 2.222, Test loss: 2.245, Test accuracy: 45.87
Round   2, Train loss: 2.071, Test loss: 2.099, Test accuracy: 55.42
Round   3, Train loss: 1.799, Test loss: 1.964, Test accuracy: 63.59
Round   4, Train loss: 1.745, Test loss: 1.862, Test accuracy: 71.97
Round   5, Train loss: 1.669, Test loss: 1.752, Test accuracy: 79.65
Round   6, Train loss: 1.588, Test loss: 1.689, Test accuracy: 81.15
Round   7, Train loss: 1.535, Test loss: 1.672, Test accuracy: 81.40
Round   8, Train loss: 1.501, Test loss: 1.659, Test accuracy: 82.72
Round   9, Train loss: 1.509, Test loss: 1.635, Test accuracy: 84.82
Round  10, Train loss: 1.569, Test loss: 1.626, Test accuracy: 85.67
Round  11, Train loss: 1.600, Test loss: 1.614, Test accuracy: 86.61
Round  12, Train loss: 1.538, Test loss: 1.596, Test accuracy: 88.05
Round  13, Train loss: 1.519, Test loss: 1.593, Test accuracy: 88.11
Round  14, Train loss: 1.491, Test loss: 1.588, Test accuracy: 88.39
Round  15, Train loss: 1.479, Test loss: 1.586, Test accuracy: 88.58
Round  16, Train loss: 1.539, Test loss: 1.584, Test accuracy: 88.62
Round  17, Train loss: 1.513, Test loss: 1.583, Test accuracy: 88.66
Round  18, Train loss: 1.478, Test loss: 1.582, Test accuracy: 88.69
Round  19, Train loss: 1.542, Test loss: 1.582, Test accuracy: 88.70
Round  20, Train loss: 1.507, Test loss: 1.581, Test accuracy: 88.78
Round  21, Train loss: 1.504, Test loss: 1.581, Test accuracy: 88.77
Round  22, Train loss: 1.506, Test loss: 1.580, Test accuracy: 88.83
Round  23, Train loss: 1.508, Test loss: 1.580, Test accuracy: 88.78
Round  24, Train loss: 1.539, Test loss: 1.579, Test accuracy: 88.77
Round  25, Train loss: 1.478, Test loss: 1.578, Test accuracy: 88.82
Round  26, Train loss: 1.505, Test loss: 1.578, Test accuracy: 88.84
Round  27, Train loss: 1.509, Test loss: 1.578, Test accuracy: 88.86
Round  28, Train loss: 1.505, Test loss: 1.577, Test accuracy: 88.86
Round  29, Train loss: 1.536, Test loss: 1.577, Test accuracy: 88.90
Round  30, Train loss: 1.503, Test loss: 1.577, Test accuracy: 89.03
Round  31, Train loss: 1.474, Test loss: 1.577, Test accuracy: 88.98
Round  32, Train loss: 1.506, Test loss: 1.577, Test accuracy: 88.98
Round  33, Train loss: 1.474, Test loss: 1.576, Test accuracy: 88.99
Round  34, Train loss: 1.507, Test loss: 1.576, Test accuracy: 88.97
Round  35, Train loss: 1.475, Test loss: 1.576, Test accuracy: 89.00
Round  36, Train loss: 1.537, Test loss: 1.576, Test accuracy: 88.97
Round  37, Train loss: 1.473, Test loss: 1.576, Test accuracy: 88.92
Round  38, Train loss: 1.507, Test loss: 1.576, Test accuracy: 88.89
Round  39, Train loss: 1.538, Test loss: 1.576, Test accuracy: 88.94
Round  40, Train loss: 1.535, Test loss: 1.576, Test accuracy: 88.92
Round  41, Train loss: 1.533, Test loss: 1.576, Test accuracy: 88.89
Round  42, Train loss: 1.534, Test loss: 1.576, Test accuracy: 88.92
Round  43, Train loss: 1.535, Test loss: 1.576, Test accuracy: 88.92
Round  44, Train loss: 1.503, Test loss: 1.576, Test accuracy: 88.92
Round  45, Train loss: 1.540, Test loss: 1.576, Test accuracy: 88.83
Round  46, Train loss: 1.535, Test loss: 1.576, Test accuracy: 88.85
Round  47, Train loss: 1.536, Test loss: 1.576, Test accuracy: 88.85
Round  48, Train loss: 1.501, Test loss: 1.576, Test accuracy: 88.84
Round  49, Train loss: 1.503, Test loss: 1.576, Test accuracy: 88.86
Round  50, Train loss: 1.533, Test loss: 1.576, Test accuracy: 88.84
Round  51, Train loss: 1.503, Test loss: 1.576, Test accuracy: 88.84
Round  52, Train loss: 1.566, Test loss: 1.576, Test accuracy: 88.85
Round  53, Train loss: 1.535, Test loss: 1.576, Test accuracy: 88.88
Round  54, Train loss: 1.500, Test loss: 1.576, Test accuracy: 88.87
Round  55, Train loss: 1.569, Test loss: 1.576, Test accuracy: 88.84
Round  56, Train loss: 1.534, Test loss: 1.576, Test accuracy: 88.87
Round  57, Train loss: 1.503, Test loss: 1.576, Test accuracy: 88.91
Round  58, Train loss: 1.502, Test loss: 1.575, Test accuracy: 88.91
Round  59, Train loss: 1.536, Test loss: 1.575, Test accuracy: 88.86
Round  60, Train loss: 1.566, Test loss: 1.575, Test accuracy: 88.86
Round  61, Train loss: 1.469, Test loss: 1.575, Test accuracy: 88.89
Round  62, Train loss: 1.535, Test loss: 1.575, Test accuracy: 88.93
Round  63, Train loss: 1.500, Test loss: 1.575, Test accuracy: 88.95
Round  64, Train loss: 1.500, Test loss: 1.575, Test accuracy: 88.90
Round  65, Train loss: 1.501, Test loss: 1.575, Test accuracy: 88.96
Round  66, Train loss: 1.472, Test loss: 1.575, Test accuracy: 88.98
Round  67, Train loss: 1.503, Test loss: 1.575, Test accuracy: 88.97
Round  68, Train loss: 1.502, Test loss: 1.575, Test accuracy: 88.92
Round  69, Train loss: 1.597, Test loss: 1.575, Test accuracy: 88.93
Round  70, Train loss: 1.470, Test loss: 1.575, Test accuracy: 88.92
Round  71, Train loss: 1.504, Test loss: 1.575, Test accuracy: 88.90
Round  72, Train loss: 1.531, Test loss: 1.575, Test accuracy: 88.92
Round  73, Train loss: 1.536, Test loss: 1.575, Test accuracy: 88.89
Round  74, Train loss: 1.534, Test loss: 1.575, Test accuracy: 88.90
Round  75, Train loss: 1.535, Test loss: 1.575, Test accuracy: 88.90
Round  76, Train loss: 1.499, Test loss: 1.575, Test accuracy: 88.89
Round  77, Train loss: 1.503, Test loss: 1.575, Test accuracy: 88.92
Round  78, Train loss: 1.468, Test loss: 1.575, Test accuracy: 88.94
Round  79, Train loss: 1.534, Test loss: 1.574, Test accuracy: 88.91
Round  80, Train loss: 1.534, Test loss: 1.574, Test accuracy: 88.86
Round  81, Train loss: 1.499, Test loss: 1.574, Test accuracy: 88.92
Round  82, Train loss: 1.532, Test loss: 1.574, Test accuracy: 88.92
Round  83, Train loss: 1.500, Test loss: 1.574, Test accuracy: 88.88
Round  84, Train loss: 1.504, Test loss: 1.574, Test accuracy: 88.93
Round  85, Train loss: 1.531, Test loss: 1.574, Test accuracy: 88.91
Round  86, Train loss: 1.534, Test loss: 1.574, Test accuracy: 88.91
Round  87, Train loss: 1.503, Test loss: 1.574, Test accuracy: 88.92
Round  88, Train loss: 1.490, Test loss: 1.573, Test accuracy: 88.98
Round  89, Train loss: 1.493, Test loss: 1.573, Test accuracy: 89.03
Round  90, Train loss: 1.477, Test loss: 1.571, Test accuracy: 89.35
Round  91, Train loss: 1.504, Test loss: 1.571, Test accuracy: 89.32
Round  92, Train loss: 1.493, Test loss: 1.568, Test accuracy: 89.73
Round  93, Train loss: 1.473, Test loss: 1.564, Test accuracy: 90.10
Round  94, Train loss: 1.469, Test loss: 1.562, Test accuracy: 90.39
Round  95, Train loss: 1.468, Test loss: 1.562, Test accuracy: 90.36
Round  96, Train loss: 1.471, Test loss: 1.560, Test accuracy: 90.53
Round  97, Train loss: 1.470, Test loss: 1.561, Test accuracy: 90.40
Round  98, Train loss: 1.485, Test loss: 1.557, Test accuracy: 90.98
Round  99, Train loss: 1.470, Test loss: 1.556, Test accuracy: 91.08/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Final Round, Train loss: 1.472, Test loss: 1.546, Test accuracy: 92.07
Average accuracy final 10 rounds: 90.224 

1065.6843292713165
[0.8910269737243652, 1.7820539474487305, 2.5985000133514404, 3.4149460792541504, 4.178418397903442, 4.941890716552734, 5.770207643508911, 6.598524570465088, 7.439515113830566, 8.280505657196045, 9.17861270904541, 10.076719760894775, 11.02544116973877, 11.974162578582764, 12.898396015167236, 13.822629451751709, 14.662718296051025, 15.502807140350342, 16.35432481765747, 17.2058424949646, 18.021664142608643, 18.837485790252686, 19.678091049194336, 20.518696308135986, 21.364691257476807, 22.210686206817627, 23.03700089454651, 23.86331558227539, 24.715304374694824, 25.567293167114258, 26.373981475830078, 27.1806697845459, 28.01583766937256, 28.85100555419922, 29.68176579475403, 30.512526035308838, 31.340583086013794, 32.16864013671875, 32.97779154777527, 33.78694295883179, 34.645225524902344, 35.5035080909729, 36.30826711654663, 37.11302614212036, 37.92111325263977, 38.72920036315918, 39.51864671707153, 40.30809307098389, 41.1116406917572, 41.91518831253052, 42.750211000442505, 43.58523368835449, 44.34399461746216, 45.102755546569824, 45.94763660430908, 46.79251766204834, 47.73056697845459, 48.66861629486084, 49.54041028022766, 50.41220426559448, 51.33240270614624, 52.252601146698, 53.163830280303955, 54.07505941390991, 54.907023906707764, 55.738988399505615, 56.57620882987976, 57.413429260253906, 58.23517346382141, 59.056917667388916, 59.91250228881836, 60.7680869102478, 61.608893632888794, 62.449700355529785, 63.27826523780823, 64.10683012008667, 64.95798516273499, 65.8091402053833, 66.59744596481323, 67.38575172424316, 68.19997763633728, 69.0142035484314, 69.82184529304504, 70.62948703765869, 71.45510768890381, 72.28072834014893, 73.10106205940247, 73.921395778656, 74.7214925289154, 75.5215892791748, 76.34420108795166, 77.16681289672852, 78.0255491733551, 78.88428544998169, 79.73597311973572, 80.58766078948975, 81.42009162902832, 82.2525224685669, 83.15800523757935, 84.0634880065918, 84.82583427429199, 85.58818054199219, 86.41784381866455, 87.24750709533691, 88.08345866203308, 88.91941022872925, 89.71926832199097, 90.51912641525269, 91.34389185905457, 92.16865730285645, 93.00821471214294, 93.84777212142944, 94.63338208198547, 95.4189920425415, 96.26506090164185, 97.11112976074219, 98.02784013748169, 98.94455051422119, 99.79278016090393, 100.64100980758667, 101.48914909362793, 102.33728837966919, 103.15045070648193, 103.96361303329468, 104.81203365325928, 105.66045427322388, 106.50370359420776, 107.34695291519165, 108.2561571598053, 109.16536140441895, 110.10106706619263, 111.03677272796631, 111.95959162712097, 112.88241052627563, 113.71251559257507, 114.54262065887451, 115.37833833694458, 116.21405601501465, 116.97375822067261, 117.73346042633057, 118.56117248535156, 119.38888454437256, 120.26250410079956, 121.13612365722656, 121.88840365409851, 122.64068365097046, 123.40739178657532, 124.17409992218018, 124.99490857124329, 125.8157172203064, 126.59259939193726, 127.36948156356812, 128.1649875640869, 128.9604935646057, 129.7297248840332, 130.4989562034607, 131.31838536262512, 132.13781452178955, 132.9220950603485, 133.70637559890747, 134.5448830127716, 135.38339042663574, 136.2339494228363, 137.08450841903687, 137.93413519859314, 138.7837619781494, 139.57818794250488, 140.37261390686035, 141.22514843940735, 142.07768297195435, 142.85949897766113, 143.64131498336792, 144.4459593296051, 145.25060367584229, 146.1488916873932, 147.0471796989441, 147.91439294815063, 148.78160619735718, 149.6478352546692, 150.5140643119812, 151.41025638580322, 152.30644845962524, 153.0809075832367, 153.85536670684814, 154.69007635116577, 155.5247859954834, 156.29043912887573, 157.05609226226807, 157.84490942955017, 158.63372659683228, 159.44210124015808, 160.2504758834839, 161.04382705688477, 161.83717823028564, 162.6606035232544, 163.48402881622314, 164.35571122169495, 165.22739362716675, 166.00594902038574, 166.78450441360474, 168.38131761550903, 169.97813081741333]
[36.92, 36.92, 45.87, 45.87, 55.42, 55.42, 63.59, 63.59, 71.97, 71.97, 79.65, 79.65, 81.15, 81.15, 81.4, 81.4, 82.72, 82.72, 84.82, 84.82, 85.67, 85.67, 86.61, 86.61, 88.05, 88.05, 88.11, 88.11, 88.39, 88.39, 88.58, 88.58, 88.62, 88.62, 88.66, 88.66, 88.69, 88.69, 88.7, 88.7, 88.78, 88.78, 88.77, 88.77, 88.83, 88.83, 88.78, 88.78, 88.77, 88.77, 88.82, 88.82, 88.84, 88.84, 88.86, 88.86, 88.86, 88.86, 88.9, 88.9, 89.03, 89.03, 88.98, 88.98, 88.98, 88.98, 88.99, 88.99, 88.97, 88.97, 89.0, 89.0, 88.97, 88.97, 88.92, 88.92, 88.89, 88.89, 88.94, 88.94, 88.92, 88.92, 88.89, 88.89, 88.92, 88.92, 88.92, 88.92, 88.92, 88.92, 88.83, 88.83, 88.85, 88.85, 88.85, 88.85, 88.84, 88.84, 88.86, 88.86, 88.84, 88.84, 88.84, 88.84, 88.85, 88.85, 88.88, 88.88, 88.87, 88.87, 88.84, 88.84, 88.87, 88.87, 88.91, 88.91, 88.91, 88.91, 88.86, 88.86, 88.86, 88.86, 88.89, 88.89, 88.93, 88.93, 88.95, 88.95, 88.9, 88.9, 88.96, 88.96, 88.98, 88.98, 88.97, 88.97, 88.92, 88.92, 88.93, 88.93, 88.92, 88.92, 88.9, 88.9, 88.92, 88.92, 88.89, 88.89, 88.9, 88.9, 88.9, 88.9, 88.89, 88.89, 88.92, 88.92, 88.94, 88.94, 88.91, 88.91, 88.86, 88.86, 88.92, 88.92, 88.92, 88.92, 88.88, 88.88, 88.93, 88.93, 88.91, 88.91, 88.91, 88.91, 88.92, 88.92, 88.98, 88.98, 89.03, 89.03, 89.35, 89.35, 89.32, 89.32, 89.73, 89.73, 90.1, 90.1, 90.39, 90.39, 90.36, 90.36, 90.53, 90.53, 90.4, 90.4, 90.98, 90.98, 91.08, 91.08, 92.07, 92.07]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
Round   0, Train loss: 1.594, Test loss: 2.257, Test accuracy: 47.95
Round   1, Train loss: 1.349, Test loss: 2.116, Test accuracy: 49.97
Round   2, Train loss: 1.293, Test loss: 1.984, Test accuracy: 66.38
Round   3, Train loss: 1.218, Test loss: 1.919, Test accuracy: 69.39
Round   4, Train loss: 1.252, Test loss: 1.826, Test accuracy: 79.75
Round   5, Train loss: 1.218, Test loss: 1.787, Test accuracy: 80.81
Round   6, Train loss: 1.242, Test loss: 1.775, Test accuracy: 80.97
Round   7, Train loss: 1.195, Test loss: 1.755, Test accuracy: 82.58
Round   8, Train loss: 1.184, Test loss: 1.741, Test accuracy: 82.84
Round   9, Train loss: 1.190, Test loss: 1.730, Test accuracy: 83.03
Round  10, Train loss: 1.160, Test loss: 1.724, Test accuracy: 83.37
Round  11, Train loss: 1.180, Test loss: 1.718, Test accuracy: 83.23
Round  12, Train loss: 1.185, Test loss: 1.715, Test accuracy: 83.24
Round  13, Train loss: 1.140, Test loss: 1.711, Test accuracy: 83.23
Round  14, Train loss: 1.208, Test loss: 1.710, Test accuracy: 83.19
Round  15, Train loss: 1.183, Test loss: 1.708, Test accuracy: 82.89
Round  16, Train loss: 1.160, Test loss: 1.707, Test accuracy: 83.08
Round  17, Train loss: 1.179, Test loss: 1.706, Test accuracy: 82.67
Round  18, Train loss: 1.206, Test loss: 1.705, Test accuracy: 82.66
Round  19, Train loss: 1.229, Test loss: 1.706, Test accuracy: 82.49
Round  20, Train loss: 1.207, Test loss: 1.705, Test accuracy: 82.38
Round  21, Train loss: 1.178, Test loss: 1.705, Test accuracy: 82.21
Round  22, Train loss: 1.132, Test loss: 1.704, Test accuracy: 82.07
Round  23, Train loss: 1.226, Test loss: 1.703, Test accuracy: 82.16
Round  24, Train loss: 1.202, Test loss: 1.702, Test accuracy: 82.09
Round  25, Train loss: 1.153, Test loss: 1.701, Test accuracy: 81.93
Round  26, Train loss: 1.156, Test loss: 1.704, Test accuracy: 81.83
Round  27, Train loss: 1.155, Test loss: 1.703, Test accuracy: 81.73
Round  28, Train loss: 1.108, Test loss: 1.703, Test accuracy: 81.71
Round  29, Train loss: 1.153, Test loss: 1.702, Test accuracy: 81.63
Round  30, Train loss: 1.202, Test loss: 1.702, Test accuracy: 81.68
Round  31, Train loss: 1.177, Test loss: 1.704, Test accuracy: 81.47
Round  32, Train loss: 1.155, Test loss: 1.702, Test accuracy: 81.78
Round  33, Train loss: 1.226, Test loss: 1.702, Test accuracy: 81.60
Round  34, Train loss: 1.203, Test loss: 1.705, Test accuracy: 81.22
Round  35, Train loss: 1.177, Test loss: 1.704, Test accuracy: 81.19
Round  36, Train loss: 1.178, Test loss: 1.705, Test accuracy: 81.07
Round  37, Train loss: 1.155, Test loss: 1.706, Test accuracy: 80.90
Round  38, Train loss: 1.201, Test loss: 1.706, Test accuracy: 81.00
Round  39, Train loss: 1.152, Test loss: 1.706, Test accuracy: 80.87
Round  40, Train loss: 1.201, Test loss: 1.707, Test accuracy: 80.54
Round  41, Train loss: 1.203, Test loss: 1.707, Test accuracy: 80.70
Round  42, Train loss: 1.178, Test loss: 1.707, Test accuracy: 80.63
Round  43, Train loss: 1.179, Test loss: 1.708, Test accuracy: 80.54
Round  44, Train loss: 1.251, Test loss: 1.709, Test accuracy: 80.54
Round  45, Train loss: 1.176, Test loss: 1.709, Test accuracy: 80.41
Round  46, Train loss: 1.177, Test loss: 1.709, Test accuracy: 80.27
Round  47, Train loss: 1.176, Test loss: 1.710, Test accuracy: 80.23
Round  48, Train loss: 1.154, Test loss: 1.709, Test accuracy: 80.28
Round  49, Train loss: 1.201, Test loss: 1.708, Test accuracy: 80.35
Round  50, Train loss: 1.203, Test loss: 1.708, Test accuracy: 80.36
Round  51, Train loss: 1.177, Test loss: 1.710, Test accuracy: 80.06
Round  52, Train loss: 1.176, Test loss: 1.710, Test accuracy: 79.96
Round  53, Train loss: 1.178, Test loss: 1.712, Test accuracy: 79.67
Round  54, Train loss: 1.177, Test loss: 1.710, Test accuracy: 79.84
Round  55, Train loss: 1.199, Test loss: 1.712, Test accuracy: 79.86
Round  56, Train loss: 1.176, Test loss: 1.713, Test accuracy: 79.71
Round  57, Train loss: 1.178, Test loss: 1.714, Test accuracy: 79.52
Round  58, Train loss: 1.177, Test loss: 1.715, Test accuracy: 79.44
Round  59, Train loss: 1.175, Test loss: 1.715, Test accuracy: 79.50
Round  60, Train loss: 1.177, Test loss: 1.717, Test accuracy: 79.18
Round  61, Train loss: 1.151, Test loss: 1.716, Test accuracy: 79.43
Round  62, Train loss: 1.200, Test loss: 1.716, Test accuracy: 79.41
Round  63, Train loss: 1.176, Test loss: 1.716, Test accuracy: 79.43
Round  64, Train loss: 1.150, Test loss: 1.717, Test accuracy: 79.29
Round  65, Train loss: 1.175, Test loss: 1.717, Test accuracy: 79.17
Round  66, Train loss: 1.176, Test loss: 1.719, Test accuracy: 78.90
Round  67, Train loss: 1.200, Test loss: 1.720, Test accuracy: 78.69
Round  68, Train loss: 1.222, Test loss: 1.719, Test accuracy: 78.46
Round  69, Train loss: 1.176, Test loss: 1.720, Test accuracy: 78.49
Round  70, Train loss: 1.150, Test loss: 1.721, Test accuracy: 78.51
Round  71, Train loss: 1.174, Test loss: 1.722, Test accuracy: 78.34
Round  72, Train loss: 1.175, Test loss: 1.723, Test accuracy: 78.08
Round  73, Train loss: 1.149, Test loss: 1.722, Test accuracy: 78.15
Round  74, Train loss: 1.174, Test loss: 1.722, Test accuracy: 78.07
Round  75, Train loss: 1.173, Test loss: 1.722, Test accuracy: 78.12
Round  76, Train loss: 1.175, Test loss: 1.723, Test accuracy: 77.92
Round  77, Train loss: 1.198, Test loss: 1.723, Test accuracy: 78.01
Round  78, Train loss: 1.150, Test loss: 1.724, Test accuracy: 77.94
Round  79, Train loss: 1.224, Test loss: 1.724, Test accuracy: 77.85
Round  80, Train loss: 1.175, Test loss: 1.724, Test accuracy: 77.95
Round  81, Train loss: 1.175, Test loss: 1.724, Test accuracy: 77.89
Round  82, Train loss: 1.174, Test loss: 1.723, Test accuracy: 77.92
Round  83, Train loss: 1.198, Test loss: 1.722, Test accuracy: 77.93
Round  84, Train loss: 1.174, Test loss: 1.722, Test accuracy: 77.93
Round  85, Train loss: 1.224, Test loss: 1.722, Test accuracy: 77.78
Round  86, Train loss: 1.199, Test loss: 1.722, Test accuracy: 77.71
Round  87, Train loss: 1.174, Test loss: 1.722, Test accuracy: 77.72
Round  88, Train loss: 1.152, Test loss: 1.724, Test accuracy: 77.57
Round  89, Train loss: 1.151, Test loss: 1.723, Test accuracy: 77.66
Round  90, Train loss: 1.149, Test loss: 1.724, Test accuracy: 77.58
Round  91, Train loss: 1.151, Test loss: 1.724, Test accuracy: 77.39
Round  92, Train loss: 1.126, Test loss: 1.724, Test accuracy: 77.46
Round  93, Train loss: 1.125, Test loss: 1.723, Test accuracy: 77.64
Round  94, Train loss: 1.174, Test loss: 1.725, Test accuracy: 77.33
Round  95, Train loss: 1.175, Test loss: 1.725, Test accuracy: 77.21
Round  96, Train loss: 1.248, Test loss: 1.726, Test accuracy: 77.18
Round  97, Train loss: 1.149, Test loss: 1.727, Test accuracy: 77.07
Round  98, Train loss: 1.199, Test loss: 1.726, Test accuracy: 77.13
Round  99, Train loss: 1.150, Test loss: 1.727, Test accuracy: 77.11
Final Round, Train loss: 1.174, Test loss: 1.728, Test accuracy: 76.87
Average accuracy final 10 rounds: 77.30999999999999
1261.1000924110413
[]
[47.95, 49.97, 66.38, 69.39, 79.75, 80.81, 80.97, 82.58, 82.84, 83.03, 83.37, 83.23, 83.24, 83.23, 83.19, 82.89, 83.08, 82.67, 82.66, 82.49, 82.38, 82.21, 82.07, 82.16, 82.09, 81.93, 81.83, 81.73, 81.71, 81.63, 81.68, 81.47, 81.78, 81.6, 81.22, 81.19, 81.07, 80.9, 81.0, 80.87, 80.54, 80.7, 80.63, 80.54, 80.54, 80.41, 80.27, 80.23, 80.28, 80.35, 80.36, 80.06, 79.96, 79.67, 79.84, 79.86, 79.71, 79.52, 79.44, 79.5, 79.18, 79.43, 79.41, 79.43, 79.29, 79.17, 78.9, 78.69, 78.46, 78.49, 78.51, 78.34, 78.08, 78.15, 78.07, 78.12, 77.92, 78.01, 77.94, 77.85, 77.95, 77.89, 77.92, 77.93, 77.93, 77.78, 77.71, 77.72, 77.57, 77.66, 77.58, 77.39, 77.46, 77.64, 77.33, 77.21, 77.18, 77.07, 77.13, 77.11, 76.87]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.287, Test loss: 2.292, Test accuracy: 12.51
Round   1, Train loss: 2.278, Test loss: 2.276, Test accuracy: 20.30
Round   2, Train loss: 2.258, Test loss: 2.269, Test accuracy: 17.17
Round   3, Train loss: 2.151, Test loss: 2.225, Test accuracy: 24.62
Round   4, Train loss: 1.958, Test loss: 2.143, Test accuracy: 37.94
Round   5, Train loss: 1.952, Test loss: 2.093, Test accuracy: 43.51
Round   6, Train loss: 1.791, Test loss: 2.033, Test accuracy: 46.16
Round   7, Train loss: 2.021, Test loss: 2.069, Test accuracy: 39.76
Round   8, Train loss: 1.775, Test loss: 2.108, Test accuracy: 34.25
Round   9, Train loss: 1.926, Test loss: 2.124, Test accuracy: 30.82
Round  10, Train loss: 0.994, Test loss: 1.999, Test accuracy: 45.75
Round  11, Train loss: 1.461, Test loss: 1.971, Test accuracy: 49.27
Round  12, Train loss: 1.516, Test loss: 2.004, Test accuracy: 44.32
Round  13, Train loss: 1.077, Test loss: 2.001, Test accuracy: 44.64
Round  14, Train loss: 0.142, Test loss: 1.903, Test accuracy: 54.82
Round  15, Train loss: 1.733, Test loss: 1.993, Test accuracy: 46.87
Round  16, Train loss: 0.821, Test loss: 1.977, Test accuracy: 48.65
Round  17, Train loss: 0.621, Test loss: 1.959, Test accuracy: 51.14
Round  18, Train loss: 0.480, Test loss: 1.941, Test accuracy: 51.98
Round  19, Train loss: -0.232, Test loss: 1.889, Test accuracy: 57.25
Round  20, Train loss: 0.162, Test loss: 1.838, Test accuracy: 62.92
Round  21, Train loss: 1.502, Test loss: 1.913, Test accuracy: 56.47
Round  22, Train loss: 0.075, Test loss: 1.864, Test accuracy: 60.80
Round  23, Train loss: 0.344, Test loss: 1.890, Test accuracy: 58.81
Round  24, Train loss: 0.770, Test loss: 1.886, Test accuracy: 59.67
Round  25, Train loss: -0.206, Test loss: 1.822, Test accuracy: 65.75
Round  26, Train loss: 0.461, Test loss: 1.868, Test accuracy: 60.99
Round  27, Train loss: -0.036, Test loss: 1.812, Test accuracy: 66.65
Round  28, Train loss: 0.742, Test loss: 1.812, Test accuracy: 65.72
Round  29, Train loss: 0.110, Test loss: 1.799, Test accuracy: 66.80
Round  30, Train loss: 0.108, Test loss: 1.780, Test accuracy: 68.94
Round  31, Train loss: -0.541, Test loss: 1.734, Test accuracy: 73.55
Round  32, Train loss: 0.360, Test loss: 1.764, Test accuracy: 70.90
Round  33, Train loss: -0.497, Test loss: 1.789, Test accuracy: 68.38
Round  34, Train loss: -0.537, Test loss: 1.775, Test accuracy: 70.04
Round  35, Train loss: -0.082, Test loss: 1.779, Test accuracy: 69.90
Round  36, Train loss: -0.313, Test loss: 1.788, Test accuracy: 69.02
Round  37, Train loss: -0.491, Test loss: 1.724, Test accuracy: 74.78
Round  38, Train loss: -0.637, Test loss: 1.731, Test accuracy: 73.33
Round  39, Train loss: -1.525, Test loss: 1.677, Test accuracy: 78.68
Round  40, Train loss: -1.190, Test loss: 1.694, Test accuracy: 76.96
Round  41, Train loss: -1.311, Test loss: 1.667, Test accuracy: 79.68
Round  42, Train loss: -0.544, Test loss: 1.726, Test accuracy: 73.91
Round  43, Train loss: -1.388, Test loss: 1.694, Test accuracy: 76.83
Round  44, Train loss: -0.841, Test loss: 1.676, Test accuracy: 78.50
Round  45, Train loss: -0.947, Test loss: 1.648, Test accuracy: 81.57
Round  46, Train loss: -0.972, Test loss: 1.651, Test accuracy: 81.33
Round  47, Train loss: -1.020, Test loss: 1.644, Test accuracy: 81.98
Round  48, Train loss: -0.914, Test loss: 1.646, Test accuracy: 81.56
Round  49, Train loss: -1.096, Test loss: 1.647, Test accuracy: 81.50
Round  50, Train loss: -1.840, Test loss: 1.636, Test accuracy: 82.67
Round  51, Train loss: -1.166, Test loss: 1.630, Test accuracy: 83.17
Round  52, Train loss: -1.796, Test loss: 1.645, Test accuracy: 81.63
Round  53, Train loss: -1.569, Test loss: 1.637, Test accuracy: 82.50
Round  54, Train loss: -1.469, Test loss: 1.649, Test accuracy: 81.28
Round  55, Train loss: -1.814, Test loss: 1.630, Test accuracy: 83.11
Round  56, Train loss: -1.637, Test loss: 1.624, Test accuracy: 83.65
Round  57, Train loss: -0.895, Test loss: 1.629, Test accuracy: 83.31
Round  58, Train loss: -1.001, Test loss: 1.618, Test accuracy: 84.41
Round  59, Train loss: -1.944, Test loss: 1.610, Test accuracy: 85.23
Round  60, Train loss: -1.495, Test loss: 1.620, Test accuracy: 84.13
Round  61, Train loss: -1.048, Test loss: 1.620, Test accuracy: 84.16
Round  62, Train loss: -1.532, Test loss: 1.605, Test accuracy: 85.70
Round  63, Train loss: -1.292, Test loss: 1.610, Test accuracy: 85.21
Round  64, Train loss: -1.403, Test loss: 1.603, Test accuracy: 85.82
Round  65, Train loss: -1.258, Test loss: 1.605, Test accuracy: 85.71
Round  66, Train loss: -1.262, Test loss: 1.615, Test accuracy: 84.71
Round  67, Train loss: -1.769, Test loss: 1.607, Test accuracy: 85.50
Round  68, Train loss: -1.263, Test loss: 1.609, Test accuracy: 85.25
Round  69, Train loss: -1.667, Test loss: 1.611, Test accuracy: 85.10
Round  70, Train loss: -1.847, Test loss: 1.580, Test accuracy: 88.34
Round  71, Train loss: -1.548, Test loss: 1.588, Test accuracy: 87.52
Round  72, Train loss: -1.002, Test loss: 1.578, Test accuracy: 88.52
Round  73, Train loss: -1.508, Test loss: 1.575, Test accuracy: 88.79
Round  74, Train loss: -1.217, Test loss: 1.586, Test accuracy: 87.62
Round  75, Train loss: -1.555, Test loss: 1.569, Test accuracy: 89.34
Round  76, Train loss: -1.121, Test loss: 1.593, Test accuracy: 86.95
Round  77, Train loss: -1.409, Test loss: 1.593, Test accuracy: 86.90
Round  78, Train loss: -1.167, Test loss: 1.616, Test accuracy: 84.59
Round  79, Train loss: -1.135, Test loss: 1.608, Test accuracy: 85.34
Round  80, Train loss: -1.083, Test loss: 1.611, Test accuracy: 85.01
Round  81, Train loss: -0.920, Test loss: 1.611, Test accuracy: 84.92
Round  82, Train loss: -1.319, Test loss: 1.595, Test accuracy: 86.55
Round  83, Train loss: -0.751, Test loss: 1.584, Test accuracy: 87.68
Round  84, Train loss: -1.417, Test loss: 1.584, Test accuracy: 87.74
Round  85, Train loss: -1.318, Test loss: 1.574, Test accuracy: 88.68
Round  86, Train loss: -0.442, Test loss: 1.567, Test accuracy: 89.45
Round  87, Train loss: -0.901, Test loss: 1.575, Test accuracy: 88.60
Round  88, Train loss: -1.538, Test loss: 1.583, Test accuracy: 87.80
Round  89, Train loss: -0.206, Test loss: 1.595, Test accuracy: 86.66
Round  90, Train loss: -1.091, Test loss: 1.590, Test accuracy: 87.17
Round  91, Train loss: -0.451, Test loss: 1.592, Test accuracy: 87.09
Round  92, Train loss: -1.069, Test loss: 1.596, Test accuracy: 86.58
Round  93, Train loss: -1.068, Test loss: 1.590, Test accuracy: 87.22
Round  94, Train loss: -0.715, Test loss: 1.612, Test accuracy: 85.02
Round  95, Train loss: -0.490, Test loss: 1.594, Test accuracy: 86.81
Round  96, Train loss: -1.489, Test loss: 1.573, Test accuracy: 88.84
Round  97, Train loss: -0.655, Test loss: 1.589, Test accuracy: 87.26
Round  98, Train loss: -0.390, Test loss: 1.579, Test accuracy: 88.32
Round  99, Train loss: -0.539, Test loss: 1.581, Test accuracy: 88.13
Final Round, Train loss: 1.576, Test loss: 1.591, Test accuracy: 87.95
Average accuracy final 10 rounds: 87.244
Average global accuracy final 10 rounds: 87.244
949.5955696105957
[]
[12.51, 20.3, 17.17, 24.62, 37.94, 43.51, 46.16, 39.76, 34.25, 30.82, 45.75, 49.27, 44.32, 44.64, 54.82, 46.87, 48.65, 51.14, 51.98, 57.25, 62.92, 56.47, 60.8, 58.81, 59.67, 65.75, 60.99, 66.65, 65.72, 66.8, 68.94, 73.55, 70.9, 68.38, 70.04, 69.9, 69.02, 74.78, 73.33, 78.68, 76.96, 79.68, 73.91, 76.83, 78.5, 81.57, 81.33, 81.98, 81.56, 81.5, 82.67, 83.17, 81.63, 82.5, 81.28, 83.11, 83.65, 83.31, 84.41, 85.23, 84.13, 84.16, 85.7, 85.21, 85.82, 85.71, 84.71, 85.5, 85.25, 85.1, 88.34, 87.52, 88.52, 88.79, 87.62, 89.34, 86.95, 86.9, 84.59, 85.34, 85.01, 84.92, 86.55, 87.68, 87.74, 88.68, 89.45, 88.6, 87.8, 86.66, 87.17, 87.09, 86.58, 87.22, 85.02, 86.81, 88.84, 87.26, 88.32, 88.13, 87.95]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

prox
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.292, Test loss: 2.292, Test accuracy: 26.72
Round   0, Global train loss: 2.292, Global test loss: 2.297, Global test accuracy: 24.37
Round   1, Train loss: 2.270, Test loss: 2.266, Test accuracy: 29.40
Round   1, Global train loss: 2.270, Global test loss: 2.279, Global test accuracy: 26.28
Round   2, Train loss: 2.133, Test loss: 2.161, Test accuracy: 37.41
Round   2, Global train loss: 2.133, Global test loss: 2.173, Global test accuracy: 33.83
Round   3, Train loss: 1.957, Test loss: 2.028, Test accuracy: 51.57
Round   3, Global train loss: 1.957, Global test loss: 2.055, Global test accuracy: 48.17
Round   4, Train loss: 1.787, Test loss: 1.917, Test accuracy: 61.06
Round   4, Global train loss: 1.787, Global test loss: 1.917, Global test accuracy: 62.55
Round   5, Train loss: 1.680, Test loss: 1.865, Test accuracy: 65.93
Round   5, Global train loss: 1.680, Global test loss: 1.852, Global test accuracy: 67.63
Round   6, Train loss: 1.682, Test loss: 1.821, Test accuracy: 70.19
Round   6, Global train loss: 1.682, Global test loss: 1.890, Global test accuracy: 56.50
Round   7, Train loss: 1.688, Test loss: 1.784, Test accuracy: 72.98
Round   7, Global train loss: 1.688, Global test loss: 1.778, Global test accuracy: 72.69
Round   8, Train loss: 1.646, Test loss: 1.757, Test accuracy: 75.06
Round   8, Global train loss: 1.646, Global test loss: 1.792, Global test accuracy: 69.37
Round   9, Train loss: 1.610, Test loss: 1.699, Test accuracy: 79.80
Round   9, Global train loss: 1.610, Global test loss: 1.711, Global test accuracy: 79.01
Round  10, Train loss: 1.590, Test loss: 1.695, Test accuracy: 80.12
Round  10, Global train loss: 1.590, Global test loss: 1.697, Global test accuracy: 80.08
Round  11, Train loss: 1.559, Test loss: 1.684, Test accuracy: 80.68
Round  11, Global train loss: 1.559, Global test loss: 1.673, Global test accuracy: 81.41
Round  12, Train loss: 1.618, Test loss: 1.631, Test accuracy: 84.25
Round  12, Global train loss: 1.618, Global test loss: 1.676, Global test accuracy: 81.04
Round  13, Train loss: 1.638, Test loss: 1.628, Test accuracy: 84.35
Round  13, Global train loss: 1.638, Global test loss: 1.655, Global test accuracy: 82.54
Round  14, Train loss: 1.626, Test loss: 1.629, Test accuracy: 84.14
Round  14, Global train loss: 1.626, Global test loss: 1.668, Global test accuracy: 81.05
Round  15, Train loss: 1.598, Test loss: 1.627, Test accuracy: 84.16
Round  15, Global train loss: 1.598, Global test loss: 1.674, Global test accuracy: 80.19
Round  16, Train loss: 1.599, Test loss: 1.625, Test accuracy: 84.28
Round  16, Global train loss: 1.599, Global test loss: 1.646, Global test accuracy: 82.93
Round  17, Train loss: 1.632, Test loss: 1.623, Test accuracy: 84.44
Round  17, Global train loss: 1.632, Global test loss: 1.641, Global test accuracy: 83.08
Round  18, Train loss: 1.623, Test loss: 1.620, Test accuracy: 84.66
Round  18, Global train loss: 1.623, Global test loss: 1.660, Global test accuracy: 80.90
Round  19, Train loss: 1.601, Test loss: 1.615, Test accuracy: 85.29
Round  19, Global train loss: 1.601, Global test loss: 1.663, Global test accuracy: 81.19
Round  20, Train loss: 1.617, Test loss: 1.614, Test accuracy: 85.36
Round  20, Global train loss: 1.617, Global test loss: 1.651, Global test accuracy: 81.99
Round  21, Train loss: 1.595, Test loss: 1.613, Test accuracy: 85.41
Round  21, Global train loss: 1.595, Global test loss: 1.638, Global test accuracy: 83.48
Round  22, Train loss: 1.530, Test loss: 1.611, Test accuracy: 85.62
Round  22, Global train loss: 1.530, Global test loss: 1.638, Global test accuracy: 83.49
Round  23, Train loss: 1.589, Test loss: 1.612, Test accuracy: 85.51
Round  23, Global train loss: 1.589, Global test loss: 1.635, Global test accuracy: 83.29
Round  24, Train loss: 1.620, Test loss: 1.611, Test accuracy: 85.46
Round  24, Global train loss: 1.620, Global test loss: 1.630, Global test accuracy: 83.79
Round  25, Train loss: 1.560, Test loss: 1.611, Test accuracy: 85.42
Round  25, Global train loss: 1.560, Global test loss: 1.634, Global test accuracy: 83.53
Round  26, Train loss: 1.588, Test loss: 1.610, Test accuracy: 85.49
Round  26, Global train loss: 1.588, Global test loss: 1.635, Global test accuracy: 83.57
Round  27, Train loss: 1.588, Test loss: 1.610, Test accuracy: 85.47
Round  27, Global train loss: 1.588, Global test loss: 1.633, Global test accuracy: 83.64
Round  28, Train loss: 1.555, Test loss: 1.608, Test accuracy: 85.53
Round  28, Global train loss: 1.555, Global test loss: 1.626, Global test accuracy: 84.27
Round  29, Train loss: 1.527, Test loss: 1.609, Test accuracy: 85.53
Round  29, Global train loss: 1.527, Global test loss: 1.631, Global test accuracy: 83.84
Round  30, Train loss: 1.551, Test loss: 1.608, Test accuracy: 85.70
Round  30, Global train loss: 1.551, Global test loss: 1.626, Global test accuracy: 84.10
Round  31, Train loss: 1.608, Test loss: 1.608, Test accuracy: 85.65
Round  31, Global train loss: 1.608, Global test loss: 1.628, Global test accuracy: 84.05
Round  32, Train loss: 1.550, Test loss: 1.607, Test accuracy: 85.67
Round  32, Global train loss: 1.550, Global test loss: 1.627, Global test accuracy: 83.94
Round  33, Train loss: 1.558, Test loss: 1.608, Test accuracy: 85.58
Round  33, Global train loss: 1.558, Global test loss: 1.632, Global test accuracy: 83.70
Round  34, Train loss: 1.581, Test loss: 1.608, Test accuracy: 85.57
Round  34, Global train loss: 1.581, Global test loss: 1.629, Global test accuracy: 83.72
Round  35, Train loss: 1.555, Test loss: 1.606, Test accuracy: 85.79
Round  35, Global train loss: 1.555, Global test loss: 1.623, Global test accuracy: 84.20
Round  36, Train loss: 1.581, Test loss: 1.606, Test accuracy: 85.78
Round  36, Global train loss: 1.581, Global test loss: 1.634, Global test accuracy: 83.23
Round  37, Train loss: 1.615, Test loss: 1.606, Test accuracy: 85.82
Round  37, Global train loss: 1.615, Global test loss: 1.621, Global test accuracy: 84.73
Round  38, Train loss: 1.582, Test loss: 1.606, Test accuracy: 85.81
Round  38, Global train loss: 1.582, Global test loss: 1.623, Global test accuracy: 84.28
Round  39, Train loss: 1.543, Test loss: 1.605, Test accuracy: 85.82
Round  39, Global train loss: 1.543, Global test loss: 1.627, Global test accuracy: 83.89
Round  40, Train loss: 1.584, Test loss: 1.604, Test accuracy: 85.99
Round  40, Global train loss: 1.584, Global test loss: 1.634, Global test accuracy: 83.05
Round  41, Train loss: 1.578, Test loss: 1.604, Test accuracy: 85.98
Round  41, Global train loss: 1.578, Global test loss: 1.631, Global test accuracy: 83.52
Round  42, Train loss: 1.550, Test loss: 1.604, Test accuracy: 86.03
Round  42, Global train loss: 1.550, Global test loss: 1.620, Global test accuracy: 84.64
Round  43, Train loss: 1.608, Test loss: 1.603, Test accuracy: 86.04
Round  43, Global train loss: 1.608, Global test loss: 1.630, Global test accuracy: 83.65
Round  44, Train loss: 1.548, Test loss: 1.603, Test accuracy: 86.06
Round  44, Global train loss: 1.548, Global test loss: 1.621, Global test accuracy: 84.44
Round  45, Train loss: 1.551, Test loss: 1.603, Test accuracy: 86.04
Round  45, Global train loss: 1.551, Global test loss: 1.619, Global test accuracy: 84.90
Round  46, Train loss: 1.640, Test loss: 1.603, Test accuracy: 86.10
Round  46, Global train loss: 1.640, Global test loss: 1.616, Global test accuracy: 85.02
Round  47, Train loss: 1.542, Test loss: 1.603, Test accuracy: 86.07
Round  47, Global train loss: 1.542, Global test loss: 1.633, Global test accuracy: 83.17
Round  48, Train loss: 1.544, Test loss: 1.603, Test accuracy: 86.06
Round  48, Global train loss: 1.544, Global test loss: 1.618, Global test accuracy: 84.82
Round  49, Train loss: 1.544, Test loss: 1.603, Test accuracy: 86.02
Round  49, Global train loss: 1.544, Global test loss: 1.615, Global test accuracy: 84.99
Round  50, Train loss: 1.544, Test loss: 1.604, Test accuracy: 85.95
Round  50, Global train loss: 1.544, Global test loss: 1.622, Global test accuracy: 84.23
Round  51, Train loss: 1.547, Test loss: 1.604, Test accuracy: 85.83
Round  51, Global train loss: 1.547, Global test loss: 1.619, Global test accuracy: 84.62
Round  52, Train loss: 1.577, Test loss: 1.604, Test accuracy: 85.85
Round  52, Global train loss: 1.577, Global test loss: 1.613, Global test accuracy: 85.27
Round  53, Train loss: 1.512, Test loss: 1.604, Test accuracy: 85.79
Round  53, Global train loss: 1.512, Global test loss: 1.617, Global test accuracy: 84.66
Round  54, Train loss: 1.608, Test loss: 1.604, Test accuracy: 85.82
Round  54, Global train loss: 1.608, Global test loss: 1.617, Global test accuracy: 84.61
Round  55, Train loss: 1.576, Test loss: 1.603, Test accuracy: 85.93
Round  55, Global train loss: 1.576, Global test loss: 1.615, Global test accuracy: 84.76
Round  56, Train loss: 1.575, Test loss: 1.603, Test accuracy: 86.00
Round  56, Global train loss: 1.575, Global test loss: 1.616, Global test accuracy: 84.78
Round  57, Train loss: 1.544, Test loss: 1.602, Test accuracy: 86.02
Round  57, Global train loss: 1.544, Global test loss: 1.613, Global test accuracy: 85.20
Round  58, Train loss: 1.605, Test loss: 1.602, Test accuracy: 86.05
Round  58, Global train loss: 1.605, Global test loss: 1.615, Global test accuracy: 85.19
Round  59, Train loss: 1.576, Test loss: 1.602, Test accuracy: 86.10
Round  59, Global train loss: 1.576, Global test loss: 1.614, Global test accuracy: 85.06
Round  60, Train loss: 1.543, Test loss: 1.601, Test accuracy: 86.13
Round  60, Global train loss: 1.543, Global test loss: 1.615, Global test accuracy: 85.07
Round  61, Train loss: 1.572, Test loss: 1.601, Test accuracy: 86.17
Round  61, Global train loss: 1.572, Global test loss: 1.615, Global test accuracy: 84.90
Round  62, Train loss: 1.573, Test loss: 1.601, Test accuracy: 86.24
Round  62, Global train loss: 1.573, Global test loss: 1.623, Global test accuracy: 84.03
Round  63, Train loss: 1.510, Test loss: 1.600, Test accuracy: 86.30
Round  63, Global train loss: 1.510, Global test loss: 1.613, Global test accuracy: 85.11
Round  64, Train loss: 1.642, Test loss: 1.600, Test accuracy: 86.36
Round  64, Global train loss: 1.642, Global test loss: 1.614, Global test accuracy: 85.03
Round  65, Train loss: 1.607, Test loss: 1.600, Test accuracy: 86.36
Round  65, Global train loss: 1.607, Global test loss: 1.615, Global test accuracy: 84.81
Round  66, Train loss: 1.573, Test loss: 1.600, Test accuracy: 86.30
Round  66, Global train loss: 1.573, Global test loss: 1.615, Global test accuracy: 84.99
Round  67, Train loss: 1.640, Test loss: 1.600, Test accuracy: 86.26
Round  67, Global train loss: 1.640, Global test loss: 1.617, Global test accuracy: 84.68
Round  68, Train loss: 1.508, Test loss: 1.600, Test accuracy: 86.26
Round  68, Global train loss: 1.508, Global test loss: 1.610, Global test accuracy: 85.36
Round  69, Train loss: 1.574, Test loss: 1.600, Test accuracy: 86.28
Round  69, Global train loss: 1.574, Global test loss: 1.609, Global test accuracy: 85.39
Round  70, Train loss: 1.605, Test loss: 1.599, Test accuracy: 86.38
Round  70, Global train loss: 1.605, Global test loss: 1.613, Global test accuracy: 85.04
Round  71, Train loss: 1.570, Test loss: 1.599, Test accuracy: 86.37
Round  71, Global train loss: 1.570, Global test loss: 1.614, Global test accuracy: 84.92
Round  72, Train loss: 1.606, Test loss: 1.599, Test accuracy: 86.41
Round  72, Global train loss: 1.606, Global test loss: 1.612, Global test accuracy: 85.30
Round  73, Train loss: 1.603, Test loss: 1.599, Test accuracy: 86.40
Round  73, Global train loss: 1.603, Global test loss: 1.614, Global test accuracy: 85.18
Round  74, Train loss: 1.543, Test loss: 1.599, Test accuracy: 86.33
Round  74, Global train loss: 1.543, Global test loss: 1.608, Global test accuracy: 85.54
Round  75, Train loss: 1.633, Test loss: 1.600, Test accuracy: 86.28
Round  75, Global train loss: 1.633, Global test loss: 1.610, Global test accuracy: 85.41
Round  76, Train loss: 1.508, Test loss: 1.599, Test accuracy: 86.31
Round  76, Global train loss: 1.508, Global test loss: 1.613, Global test accuracy: 85.08
Round  77, Train loss: 1.639, Test loss: 1.600, Test accuracy: 86.21
Round  77, Global train loss: 1.639, Global test loss: 1.615, Global test accuracy: 84.82
Round  78, Train loss: 1.571, Test loss: 1.599, Test accuracy: 86.35
Round  78, Global train loss: 1.571, Global test loss: 1.610, Global test accuracy: 85.35
Round  79, Train loss: 1.536, Test loss: 1.599, Test accuracy: 86.29
Round  79, Global train loss: 1.536, Global test loss: 1.609, Global test accuracy: 85.63
Round  80, Train loss: 1.540, Test loss: 1.599, Test accuracy: 86.33
Round  80, Global train loss: 1.540, Global test loss: 1.610, Global test accuracy: 85.53
Round  81, Train loss: 1.536, Test loss: 1.598, Test accuracy: 86.34
Round  81, Global train loss: 1.536, Global test loss: 1.609, Global test accuracy: 85.56
Round  82, Train loss: 1.536, Test loss: 1.599, Test accuracy: 86.32
Round  82, Global train loss: 1.536, Global test loss: 1.610, Global test accuracy: 85.46
Round  83, Train loss: 1.601, Test loss: 1.598, Test accuracy: 86.37
Round  83, Global train loss: 1.601, Global test loss: 1.611, Global test accuracy: 85.32
Round  84, Train loss: 1.538, Test loss: 1.598, Test accuracy: 86.40
Round  84, Global train loss: 1.538, Global test loss: 1.611, Global test accuracy: 85.17
Round  85, Train loss: 1.637, Test loss: 1.598, Test accuracy: 86.48
Round  85, Global train loss: 1.637, Global test loss: 1.610, Global test accuracy: 85.54
Round  86, Train loss: 1.569, Test loss: 1.597, Test accuracy: 86.47
Round  86, Global train loss: 1.569, Global test loss: 1.609, Global test accuracy: 85.36
Round  87, Train loss: 1.539, Test loss: 1.597, Test accuracy: 86.51
Round  87, Global train loss: 1.539, Global test loss: 1.610, Global test accuracy: 85.20
Round  88, Train loss: 1.509, Test loss: 1.598, Test accuracy: 86.53
Round  88, Global train loss: 1.509, Global test loss: 1.610, Global test accuracy: 85.51
Round  89, Train loss: 1.538, Test loss: 1.598, Test accuracy: 86.46
Round  89, Global train loss: 1.538, Global test loss: 1.612, Global test accuracy: 85.18
Round  90, Train loss: 1.536, Test loss: 1.598, Test accuracy: 86.48
Round  90, Global train loss: 1.536, Global test loss: 1.613, Global test accuracy: 85.18
Round  91, Train loss: 1.536, Test loss: 1.598, Test accuracy: 86.46
Round  91, Global train loss: 1.536, Global test loss: 1.609, Global test accuracy: 85.53
Round  92, Train loss: 1.571, Test loss: 1.598, Test accuracy: 86.48
Round  92, Global train loss: 1.571, Global test loss: 1.613, Global test accuracy: 85.07
Round  93, Train loss: 1.568, Test loss: 1.598, Test accuracy: 86.45
Round  93, Global train loss: 1.568, Global test loss: 1.610, Global test accuracy: 85.19
Round  94, Train loss: 1.632, Test loss: 1.597, Test accuracy: 86.49
Round  94, Global train loss: 1.632, Global test loss: 1.609, Global test accuracy: 85.50
Round  95, Train loss: 1.508, Test loss: 1.597, Test accuracy: 86.51
Round  95, Global train loss: 1.508, Global test loss: 1.607, Global test accuracy: 85.79/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  96, Train loss: 1.569, Test loss: 1.597, Test accuracy: 86.55
Round  96, Global train loss: 1.569, Global test loss: 1.607, Global test accuracy: 85.64
Round  97, Train loss: 1.572, Test loss: 1.597, Test accuracy: 86.53
Round  97, Global train loss: 1.572, Global test loss: 1.608, Global test accuracy: 85.80
Round  98, Train loss: 1.632, Test loss: 1.597, Test accuracy: 86.55
Round  98, Global train loss: 1.632, Global test loss: 1.608, Global test accuracy: 85.63
Round  99, Train loss: 1.603, Test loss: 1.597, Test accuracy: 86.58
Round  99, Global train loss: 1.603, Global test loss: 1.611, Global test accuracy: 85.27
Final Round, Train loss: 1.569, Test loss: 1.597, Test accuracy: 86.51
Final Round, Global train loss: 1.569, Global test loss: 1.611, Global test accuracy: 85.27
Average accuracy final 10 rounds: 86.50800000000001 

Average global accuracy final 10 rounds: 85.46000000000001 

1410.5199716091156
[0.9380216598510742, 1.8760433197021484, 2.743894100189209, 3.6117448806762695, 4.520286798477173, 5.428828716278076, 6.349851608276367, 7.270874500274658, 8.287476778030396, 9.304079055786133, 10.37460446357727, 11.445129871368408, 12.499711275100708, 13.554292678833008, 14.550136804580688, 15.54598093032837, 16.42342972755432, 17.300878524780273, 18.21717858314514, 19.13347864151001, 19.969439029693604, 20.805399417877197, 21.730467796325684, 22.65553617477417, 23.56858205795288, 24.481627941131592, 25.395824909210205, 26.31002187728882, 27.188525676727295, 28.06702947616577, 28.970998525619507, 29.874967575073242, 30.68208932876587, 31.489211082458496, 32.4418523311615, 33.3944935798645, 34.381489276885986, 35.36848497390747, 36.33735918998718, 37.306233406066895, 38.20936179161072, 39.11249017715454, 40.03484487533569, 40.957199573516846, 41.87026596069336, 42.78333234786987, 43.71135425567627, 44.639376163482666, 45.555415868759155, 46.471455574035645, 47.330275774002075, 48.189095973968506, 49.09299612045288, 49.996896266937256, 50.88108849525452, 51.76528072357178, 52.663010358810425, 53.56073999404907, 54.47556257247925, 55.390385150909424, 56.25250315666199, 57.11462116241455, 58.04574108123779, 58.976861000061035, 59.86041855812073, 60.74397611618042, 61.65271306037903, 62.56145000457764, 63.441713094711304, 64.32197618484497, 65.22408246994019, 66.1261887550354, 66.98408198356628, 67.84197521209717, 68.74052381515503, 69.63907241821289, 70.51866817474365, 71.39826393127441, 72.2938334941864, 73.18940305709839, 74.03279852867126, 74.87619400024414, 75.72862124443054, 76.58104848861694, 77.45140719413757, 78.3217658996582, 79.16074299812317, 79.99972009658813, 80.84970545768738, 81.69969081878662, 82.53350806236267, 83.36732530593872, 84.23136687278748, 85.09540843963623, 85.967276096344, 86.83914375305176, 87.72161960601807, 88.60409545898438, 89.48041653633118, 90.35673761367798, 91.22718644142151, 92.09763526916504, 92.97795605659485, 93.85827684402466, 94.84770703315735, 95.83713722229004, 96.84284806251526, 97.84855890274048, 98.82814311981201, 99.80772733688354, 100.80143523216248, 101.7951431274414, 102.76926827430725, 103.7433934211731, 104.74787425994873, 105.75235509872437, 106.74574184417725, 107.73912858963013, 108.7310700416565, 109.72301149368286, 110.74031949043274, 111.75762748718262, 112.70927214622498, 113.66091680526733, 114.60415315628052, 115.5473895072937, 116.44445085525513, 117.34151220321655, 118.22886657714844, 119.11622095108032, 119.98453688621521, 120.8528528213501, 121.74014639854431, 122.62743997573853, 123.51863312721252, 124.40982627868652, 125.30645084381104, 126.20307540893555, 127.0940318107605, 127.98498821258545, 128.87846875190735, 129.77194929122925, 130.78833556175232, 131.8047218322754, 132.78156447410583, 133.75840711593628, 134.6921091079712, 135.6258111000061, 136.57992792129517, 137.53404474258423, 138.42004466056824, 139.30604457855225, 140.16180396080017, 141.0175633430481, 141.90214204788208, 142.78672075271606, 143.77163863182068, 144.7565565109253, 145.61830472946167, 146.48005294799805, 147.36742329597473, 148.25479364395142, 149.08962965011597, 149.92446565628052, 150.80263757705688, 151.68080949783325, 152.51136684417725, 153.34192419052124, 154.25401091575623, 155.1660976409912, 156.06080222129822, 156.95550680160522, 157.83647537231445, 158.71744394302368, 159.64591217041016, 160.57438039779663, 161.54503321647644, 162.51568603515625, 163.42534112930298, 164.3349962234497, 165.209326505661, 166.08365678787231, 166.96009707450867, 167.83653736114502, 168.6877760887146, 169.53901481628418, 170.4204547405243, 171.3018946647644, 172.18079280853271, 173.05969095230103, 173.93482422828674, 174.80995750427246, 175.716153383255, 176.62234926223755, 177.44578862190247, 178.26922798156738, 179.1514856815338, 180.03374338150024, 180.90165162086487, 181.7695598602295, 183.7360053062439, 185.7024507522583]
[26.72, 26.72, 29.4, 29.4, 37.41, 37.41, 51.57, 51.57, 61.06, 61.06, 65.93, 65.93, 70.19, 70.19, 72.98, 72.98, 75.06, 75.06, 79.8, 79.8, 80.12, 80.12, 80.68, 80.68, 84.25, 84.25, 84.35, 84.35, 84.14, 84.14, 84.16, 84.16, 84.28, 84.28, 84.44, 84.44, 84.66, 84.66, 85.29, 85.29, 85.36, 85.36, 85.41, 85.41, 85.62, 85.62, 85.51, 85.51, 85.46, 85.46, 85.42, 85.42, 85.49, 85.49, 85.47, 85.47, 85.53, 85.53, 85.53, 85.53, 85.7, 85.7, 85.65, 85.65, 85.67, 85.67, 85.58, 85.58, 85.57, 85.57, 85.79, 85.79, 85.78, 85.78, 85.82, 85.82, 85.81, 85.81, 85.82, 85.82, 85.99, 85.99, 85.98, 85.98, 86.03, 86.03, 86.04, 86.04, 86.06, 86.06, 86.04, 86.04, 86.1, 86.1, 86.07, 86.07, 86.06, 86.06, 86.02, 86.02, 85.95, 85.95, 85.83, 85.83, 85.85, 85.85, 85.79, 85.79, 85.82, 85.82, 85.93, 85.93, 86.0, 86.0, 86.02, 86.02, 86.05, 86.05, 86.1, 86.1, 86.13, 86.13, 86.17, 86.17, 86.24, 86.24, 86.3, 86.3, 86.36, 86.36, 86.36, 86.36, 86.3, 86.3, 86.26, 86.26, 86.26, 86.26, 86.28, 86.28, 86.38, 86.38, 86.37, 86.37, 86.41, 86.41, 86.4, 86.4, 86.33, 86.33, 86.28, 86.28, 86.31, 86.31, 86.21, 86.21, 86.35, 86.35, 86.29, 86.29, 86.33, 86.33, 86.34, 86.34, 86.32, 86.32, 86.37, 86.37, 86.4, 86.4, 86.48, 86.48, 86.47, 86.47, 86.51, 86.51, 86.53, 86.53, 86.46, 86.46, 86.48, 86.48, 86.46, 86.46, 86.48, 86.48, 86.45, 86.45, 86.49, 86.49, 86.51, 86.51, 86.55, 86.55, 86.53, 86.53, 86.55, 86.55, 86.58, 86.58, 86.51, 86.51]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
Round   0, Train loss: 2.298, Test loss: 2.298, Test accuracy: 24.66
Round   1, Train loss: 2.290, Test loss: 2.281, Test accuracy: 31.70
Round   2, Train loss: 2.171, Test loss: 2.133, Test accuracy: 32.55
Round   3, Train loss: 1.980, Test loss: 2.014, Test accuracy: 46.53
Round   4, Train loss: 1.879, Test loss: 1.903, Test accuracy: 60.11
Round   5, Train loss: 1.740, Test loss: 1.884, Test accuracy: 58.25
Round   6, Train loss: 1.765, Test loss: 1.784, Test accuracy: 70.86
Round   7, Train loss: 1.701, Test loss: 1.741, Test accuracy: 75.72
Round   8, Train loss: 1.628, Test loss: 1.673, Test accuracy: 83.55
Round   9, Train loss: 1.623, Test loss: 1.692, Test accuracy: 79.09
Round  10, Train loss: 1.658, Test loss: 1.675, Test accuracy: 80.29
Round  11, Train loss: 1.578, Test loss: 1.649, Test accuracy: 82.39
Round  12, Train loss: 1.615, Test loss: 1.642, Test accuracy: 82.90
Round  13, Train loss: 1.611, Test loss: 1.627, Test accuracy: 85.18
Round  14, Train loss: 1.571, Test loss: 1.633, Test accuracy: 84.60
Round  15, Train loss: 1.595, Test loss: 1.624, Test accuracy: 85.00
Round  16, Train loss: 1.581, Test loss: 1.631, Test accuracy: 84.53
Round  17, Train loss: 1.582, Test loss: 1.622, Test accuracy: 84.77
Round  18, Train loss: 1.542, Test loss: 1.599, Test accuracy: 87.43
Round  19, Train loss: 1.532, Test loss: 1.600, Test accuracy: 87.20
Round  20, Train loss: 1.530, Test loss: 1.603, Test accuracy: 86.62
Round  21, Train loss: 1.513, Test loss: 1.604, Test accuracy: 86.45
Round  22, Train loss: 1.565, Test loss: 1.586, Test accuracy: 88.64
Round  23, Train loss: 1.562, Test loss: 1.598, Test accuracy: 87.36
Round  24, Train loss: 1.554, Test loss: 1.604, Test accuracy: 86.44
Round  25, Train loss: 1.588, Test loss: 1.603, Test accuracy: 86.37
Round  26, Train loss: 1.531, Test loss: 1.596, Test accuracy: 87.26
Round  27, Train loss: 1.524, Test loss: 1.582, Test accuracy: 88.81
Round  28, Train loss: 1.525, Test loss: 1.591, Test accuracy: 87.97
Round  29, Train loss: 1.534, Test loss: 1.610, Test accuracy: 85.82
Round  30, Train loss: 1.526, Test loss: 1.597, Test accuracy: 87.08
Round  31, Train loss: 1.524, Test loss: 1.583, Test accuracy: 88.70
Round  32, Train loss: 1.520, Test loss: 1.584, Test accuracy: 88.55
Round  33, Train loss: 1.549, Test loss: 1.594, Test accuracy: 87.35
Round  34, Train loss: 1.549, Test loss: 1.583, Test accuracy: 88.63
Round  35, Train loss: 1.523, Test loss: 1.588, Test accuracy: 88.15
Round  36, Train loss: 1.495, Test loss: 1.577, Test accuracy: 89.13
Round  37, Train loss: 1.519, Test loss: 1.585, Test accuracy: 88.25
Round  38, Train loss: 1.521, Test loss: 1.577, Test accuracy: 89.07
Round  39, Train loss: 1.517, Test loss: 1.602, Test accuracy: 86.63
Round  40, Train loss: 1.516, Test loss: 1.582, Test accuracy: 88.42
Round  41, Train loss: 1.513, Test loss: 1.577, Test accuracy: 88.97
Round  42, Train loss: 1.483, Test loss: 1.582, Test accuracy: 88.65
Round  43, Train loss: 1.523, Test loss: 1.601, Test accuracy: 86.34
Round  44, Train loss: 1.578, Test loss: 1.574, Test accuracy: 89.32
Round  45, Train loss: 1.517, Test loss: 1.580, Test accuracy: 88.60
Round  46, Train loss: 1.545, Test loss: 1.595, Test accuracy: 87.08
Round  47, Train loss: 1.514, Test loss: 1.593, Test accuracy: 87.02
Round  48, Train loss: 1.514, Test loss: 1.588, Test accuracy: 87.81
Round  49, Train loss: 1.483, Test loss: 1.578, Test accuracy: 89.05
Round  50, Train loss: 1.481, Test loss: 1.575, Test accuracy: 89.16
Round  51, Train loss: 1.550, Test loss: 1.567, Test accuracy: 89.98
Round  52, Train loss: 1.516, Test loss: 1.579, Test accuracy: 88.87
Round  53, Train loss: 1.480, Test loss: 1.590, Test accuracy: 87.55
Round  54, Train loss: 1.511, Test loss: 1.572, Test accuracy: 89.38
Round  55, Train loss: 1.542, Test loss: 1.574, Test accuracy: 89.30
Round  56, Train loss: 1.544, Test loss: 1.579, Test accuracy: 88.67
Round  57, Train loss: 1.479, Test loss: 1.569, Test accuracy: 89.63
Round  58, Train loss: 1.543, Test loss: 1.567, Test accuracy: 89.98
Round  59, Train loss: 1.545, Test loss: 1.573, Test accuracy: 89.19
Round  60, Train loss: 1.572, Test loss: 1.577, Test accuracy: 88.72
Round  61, Train loss: 1.509, Test loss: 1.573, Test accuracy: 89.39
Round  62, Train loss: 1.544, Test loss: 1.573, Test accuracy: 89.20
Round  63, Train loss: 1.480, Test loss: 1.571, Test accuracy: 89.32
Round  64, Train loss: 1.540, Test loss: 1.572, Test accuracy: 89.47
Round  65, Train loss: 1.508, Test loss: 1.564, Test accuracy: 89.98
Round  66, Train loss: 1.510, Test loss: 1.565, Test accuracy: 90.02
Round  67, Train loss: 1.508, Test loss: 1.569, Test accuracy: 89.63
Round  68, Train loss: 1.478, Test loss: 1.571, Test accuracy: 89.29
Round  69, Train loss: 1.539, Test loss: 1.566, Test accuracy: 90.07
Round  70, Train loss: 1.509, Test loss: 1.565, Test accuracy: 90.13
Round  71, Train loss: 1.478, Test loss: 1.567, Test accuracy: 89.74
Round  72, Train loss: 1.475, Test loss: 1.569, Test accuracy: 89.64
Round  73, Train loss: 1.542, Test loss: 1.561, Test accuracy: 90.45
Round  74, Train loss: 1.506, Test loss: 1.567, Test accuracy: 89.82
Round  75, Train loss: 1.476, Test loss: 1.574, Test accuracy: 89.16
Round  76, Train loss: 1.508, Test loss: 1.571, Test accuracy: 89.41
Round  77, Train loss: 1.539, Test loss: 1.570, Test accuracy: 89.45
Round  78, Train loss: 1.476, Test loss: 1.566, Test accuracy: 90.02
Round  79, Train loss: 1.509, Test loss: 1.561, Test accuracy: 90.35
Round  80, Train loss: 1.572, Test loss: 1.564, Test accuracy: 90.02
Round  81, Train loss: 1.507, Test loss: 1.563, Test accuracy: 90.07
Round  82, Train loss: 1.539, Test loss: 1.575, Test accuracy: 88.96
Round  83, Train loss: 1.474, Test loss: 1.567, Test accuracy: 89.47
Round  84, Train loss: 1.507, Test loss: 1.561, Test accuracy: 90.44
Round  85, Train loss: 1.505, Test loss: 1.570, Test accuracy: 89.56
Round  86, Train loss: 1.508, Test loss: 1.559, Test accuracy: 90.51
Round  87, Train loss: 1.570, Test loss: 1.569, Test accuracy: 89.65
Round  88, Train loss: 1.507, Test loss: 1.573, Test accuracy: 89.17
Round  89, Train loss: 1.537, Test loss: 1.564, Test accuracy: 90.32
Round  90, Train loss: 1.473, Test loss: 1.561, Test accuracy: 90.39
Round  91, Train loss: 1.507, Test loss: 1.570, Test accuracy: 89.60
Round  92, Train loss: 1.505, Test loss: 1.574, Test accuracy: 89.13
Round  93, Train loss: 1.538, Test loss: 1.563, Test accuracy: 90.31
Round  94, Train loss: 1.538, Test loss: 1.559, Test accuracy: 90.48
Round  95, Train loss: 1.508, Test loss: 1.566, Test accuracy: 89.86
Round  96, Train loss: 1.505, Test loss: 1.565, Test accuracy: 90.27
Round  97, Train loss: 1.506, Test loss: 1.559, Test accuracy: 90.56
Round  98, Train loss: 1.505, Test loss: 1.566, Test accuracy: 89.83
Round  99, Train loss: 1.506, Test loss: 1.572, Test accuracy: 89.38
Final Round, Train loss: 1.511, Test loss: 1.557, Test accuracy: 90.69
Average accuracy final 10 rounds: 89.98100000000001
1589.0993571281433
[2.2946250438690186, 4.521846294403076, 6.648696422576904, 8.895065546035767, 11.069690704345703, 13.252877712249756, 15.381926774978638, 17.58837080001831, 19.808364868164062, 22.04139757156372, 24.151399612426758, 26.340156316757202, 28.533692359924316, 30.686626195907593, 32.82673263549805, 35.06253170967102, 37.262123823165894, 39.40754437446594, 41.54703712463379, 43.7562210559845, 45.92090177536011, 48.13442659378052, 50.373616218566895, 52.545525312423706, 54.91640830039978, 57.29749870300293, 59.72744274139404, 61.99425435066223, 64.22064161300659, 66.34938168525696, 68.58838057518005, 70.75708270072937, 73.0552625656128, 75.26520729064941, 77.53183579444885, 79.70403170585632, 81.97149467468262, 84.18343544006348, 86.38034319877625, 88.51312184333801, 90.74478888511658, 92.87173366546631, 95.12842297554016, 97.43838548660278, 99.77738285064697, 102.05027318000793, 104.34748840332031, 106.73072743415833, 109.04057693481445, 111.37063694000244, 113.47479677200317, 115.53644728660583, 117.63401341438293, 119.72731447219849, 121.80198669433594, 123.91894435882568, 126.00403499603271, 128.09908843040466, 130.14591193199158, 132.26972913742065, 134.38316655158997, 136.5090560913086, 138.65082120895386, 140.7657687664032, 142.8507537841797, 144.96821999549866, 147.0503067970276, 149.16391444206238, 151.2794473171234, 153.36914825439453, 155.46466827392578, 157.5579195022583, 159.64818930625916, 161.7690441608429, 163.8726990222931, 165.95374846458435, 168.053138256073, 170.17352676391602, 172.28397369384766, 174.38045954704285, 176.5116307735443, 178.64579439163208, 180.7273280620575, 182.81619429588318, 184.93084454536438, 187.01994347572327, 189.12024068832397, 191.24533772468567, 193.3612995147705, 195.47409772872925, 197.59140396118164, 199.67862796783447, 201.805025100708, 203.91849088668823, 206.05534052848816, 208.19623637199402, 210.38595986366272, 212.50783348083496, 214.63638305664062, 216.76585006713867, 218.9453387260437]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[24.66, 31.7, 32.55, 46.53, 60.11, 58.25, 70.86, 75.72, 83.55, 79.09, 80.29, 82.39, 82.9, 85.18, 84.6, 85.0, 84.53, 84.77, 87.43, 87.2, 86.62, 86.45, 88.64, 87.36, 86.44, 86.37, 87.26, 88.81, 87.97, 85.82, 87.08, 88.7, 88.55, 87.35, 88.63, 88.15, 89.13, 88.25, 89.07, 86.63, 88.42, 88.97, 88.65, 86.34, 89.32, 88.6, 87.08, 87.02, 87.81, 89.05, 89.16, 89.98, 88.87, 87.55, 89.38, 89.3, 88.67, 89.63, 89.98, 89.19, 88.72, 89.39, 89.2, 89.32, 89.47, 89.98, 90.02, 89.63, 89.29, 90.07, 90.13, 89.74, 89.64, 90.45, 89.82, 89.16, 89.41, 89.45, 90.02, 90.35, 90.02, 90.07, 88.96, 89.47, 90.44, 89.56, 90.51, 89.65, 89.17, 90.32, 90.39, 89.6, 89.13, 90.31, 90.48, 89.86, 90.27, 90.56, 89.83, 89.38, 90.69]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 400, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.301, Test loss: 2.303, Test accuracy: 7.56
Round   0, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 7.48
Round   1, Train loss: 2.302, Test loss: 2.303, Test accuracy: 7.72
Round   1, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.61
Round   2, Train loss: 2.302, Test loss: 2.303, Test accuracy: 7.81
Round   2, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.64
Round   3, Train loss: 2.304, Test loss: 2.303, Test accuracy: 7.82
Round   3, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 7.73
Round   4, Train loss: 2.304, Test loss: 2.303, Test accuracy: 7.81
Round   4, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 7.79
Round   5, Train loss: 2.301, Test loss: 2.303, Test accuracy: 8.03
Round   5, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 7.77
Round   6, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.06
Round   6, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.78
Round   7, Train loss: 2.304, Test loss: 2.303, Test accuracy: 8.05
Round   7, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 7.76
Round   8, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.07
Round   8, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.77
Round   9, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.15
Round   9, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.81
Round  10, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.12
Round  10, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.87
Round  11, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.19
Round  11, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.90
Round  12, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.24
Round  12, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.92
Round  13, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.26
Round  13, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.98
Round  14, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.45
Round  14, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.99
Round  15, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.55
Round  15, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.15
Round  16, Train loss: 2.304, Test loss: 2.303, Test accuracy: 8.58
Round  16, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 8.21
Round  17, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.60
Round  17, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.33
Round  18, Train loss: 2.301, Test loss: 2.303, Test accuracy: 8.76
Round  18, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 8.50
Round  19, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.77
Round  19, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.46
Round  20, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.77
Round  20, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.49
Round  21, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.80
Round  21, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.49
Round  22, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.90
Round  22, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.57
Round  23, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.91
Round  23, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.73
Round  24, Train loss: 2.304, Test loss: 2.303, Test accuracy: 8.91
Round  24, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 8.73
Round  25, Train loss: 2.303, Test loss: 2.303, Test accuracy: 9.06
Round  25, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.90
Round  26, Train loss: 2.304, Test loss: 2.303, Test accuracy: 9.00
Round  26, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 8.98
Round  27, Train loss: 2.303, Test loss: 2.303, Test accuracy: 9.00
Round  27, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.99
Round  28, Train loss: 2.304, Test loss: 2.303, Test accuracy: 9.02
Round  28, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 9.18
Round  29, Train loss: 2.303, Test loss: 2.303, Test accuracy: 9.17
Round  29, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 9.22
Round  30, Train loss: 2.303, Test loss: 2.303, Test accuracy: 9.32
Round  30, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 9.22
Round  31, Train loss: 2.301, Test loss: 2.303, Test accuracy: 9.38
Round  31, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 9.37
Round  32, Train loss: 2.305, Test loss: 2.303, Test accuracy: 9.44
Round  32, Global train loss: 2.305, Global test loss: 2.303, Global test accuracy: 9.41
Round  33, Train loss: 2.304, Test loss: 2.303, Test accuracy: 9.49
Round  33, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 9.50
Round  34, Train loss: 2.302, Test loss: 2.303, Test accuracy: 9.72
Round  34, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 9.59
Round  35, Train loss: 2.301, Test loss: 2.303, Test accuracy: 9.95
Round  35, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 9.76
Round  36, Train loss: 2.300, Test loss: 2.303, Test accuracy: 10.08
Round  36, Global train loss: 2.300, Global test loss: 2.303, Global test accuracy: 9.96
Round  37, Train loss: 2.302, Test loss: 2.303, Test accuracy: 10.09
Round  37, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 10.04
Round  38, Train loss: 2.303, Test loss: 2.303, Test accuracy: 10.21
Round  38, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.23
Round  39, Train loss: 2.303, Test loss: 2.303, Test accuracy: 10.31
Round  39, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.22
Round  40, Train loss: 2.302, Test loss: 2.303, Test accuracy: 10.43
Round  40, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 10.32
Round  41, Train loss: 2.301, Test loss: 2.303, Test accuracy: 10.53
Round  41, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 10.33
Round  42, Train loss: 2.302, Test loss: 2.303, Test accuracy: 10.58
Round  42, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 10.51
Round  43, Train loss: 2.302, Test loss: 2.303, Test accuracy: 10.69
Round  43, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 10.56
Round  44, Train loss: 2.304, Test loss: 2.303, Test accuracy: 10.78
Round  44, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 10.65
Round  45, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.85
Round  45, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 10.78
Round  46, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.95
Round  46, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 10.92
Round  47, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.08
Round  47, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.02
Round  48, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.17
Round  48, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.98
Round  49, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.20
Round  49, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.03
Round  50, Train loss: 2.300, Test loss: 2.302, Test accuracy: 11.30
Round  50, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 11.23
Round  51, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.42
Round  51, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.31
Round  52, Train loss: 2.304, Test loss: 2.302, Test accuracy: 11.49
Round  52, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 11.41
Round  53, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.60
Round  53, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.52
Round  54, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.80
Round  54, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.68
Round  55, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.94
Round  55, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.79
Round  56, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.09
Round  56, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.82
Round  57, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.20
Round  57, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.07
Round  58, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.34
Round  58, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.21
Round  59, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.50
Round  59, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.23
Round  60, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.60
Round  60, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.47
Round  61, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.68
Round  61, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.58
Round  62, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.80
Round  62, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.76
Round  63, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.88
Round  63, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.99
Round  64, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.15
Round  64, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.06
Round  65, Train loss: 2.303, Test loss: 2.302, Test accuracy: 13.28
Round  65, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 13.24
Round  66, Train loss: 2.303, Test loss: 2.302, Test accuracy: 13.36
Round  66, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 13.33
Round  67, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.51
Round  67, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.44
Round  68, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.70
Round  68, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.50
Round  69, Train loss: 2.303, Test loss: 2.302, Test accuracy: 13.88
Round  69, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 13.75
Round  70, Train loss: 2.301, Test loss: 2.302, Test accuracy: 14.04
Round  70, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.79
Round  71, Train loss: 2.300, Test loss: 2.302, Test accuracy: 14.09
Round  71, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.88
Round  72, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.20
Round  72, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.04
Round  73, Train loss: 2.303, Test loss: 2.302, Test accuracy: 14.29
Round  73, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 14.19
Round  74, Train loss: 2.303, Test loss: 2.302, Test accuracy: 14.41
Round  74, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 14.26
Round  75, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.47
Round  75, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.44
Round  76, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.64
Round  76, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.55
Round  77, Train loss: 2.303, Test loss: 2.302, Test accuracy: 14.76
Round  77, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 14.81
Round  78, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.88
Round  78, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 14.85
Round  79, Train loss: 2.302, Test loss: 2.302, Test accuracy: 15.13
Round  79, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.14
Round  80, Train loss: 2.300, Test loss: 2.302, Test accuracy: 15.32
Round  80, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 15.16
Round  81, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.53
Round  81, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.36
Round  82, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.59
Round  82, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.48
Round  83, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.69
Round  83, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.69
Round  84, Train loss: 2.301, Test loss: 2.302, Test accuracy: 15.81
Round  84, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.76
Round  85, Train loss: 2.302, Test loss: 2.302, Test accuracy: 15.96
Round  85, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 15.93
Round  86, Train loss: 2.301, Test loss: 2.302, Test accuracy: 16.05
Round  86, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 15.99
Round  87, Train loss: 2.302, Test loss: 2.302, Test accuracy: 16.23
Round  87, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 16.02
Round  88, Train loss: 2.300, Test loss: 2.302, Test accuracy: 16.35
Round  88, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 16.27
Round  89, Train loss: 2.301, Test loss: 2.302, Test accuracy: 16.51
Round  89, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 16.35
Round  90, Train loss: 2.301, Test loss: 2.302, Test accuracy: 16.59
Round  90, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 16.42
Round  91, Train loss: 2.299, Test loss: 2.302, Test accuracy: 16.67
Round  91, Global train loss: 2.299, Global test loss: 2.302, Global test accuracy: 16.47
Round  92, Train loss: 2.302, Test loss: 2.302, Test accuracy: 16.79
Round  92, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 16.69
Round  93, Train loss: 2.302, Test loss: 2.302, Test accuracy: 16.94
Round  93, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 16.82
Round  94, Train loss: 2.302, Test loss: 2.302, Test accuracy: 16.97
Round  94, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 16.99
Round  95, Train loss: 2.301, Test loss: 2.302, Test accuracy: 17.03
Round  95, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 16.93
Round  96, Train loss: 2.303, Test loss: 2.302, Test accuracy: 17.10
Round  96, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 17.15
Round  97, Train loss: 2.301, Test loss: 2.302, Test accuracy: 17.23
Round  97, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 17.26
Round  98, Train loss: 2.303, Test loss: 2.302, Test accuracy: 17.45
Round  98, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 17.42
Round  99, Train loss: 2.299, Test loss: 2.302, Test accuracy: 17.68
Round  99, Global train loss: 2.299, Global test loss: 2.302, Global test accuracy: 17.34
Round 100, Train loss: 2.299, Test loss: 2.302, Test accuracy: 17.77
Round 100, Global train loss: 2.299, Global test loss: 2.302, Global test accuracy: 17.54
Round 101, Train loss: 2.301, Test loss: 2.301, Test accuracy: 17.83
Round 101, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 17.60
Round 102, Train loss: 2.299, Test loss: 2.301, Test accuracy: 17.89
Round 102, Global train loss: 2.299, Global test loss: 2.302, Global test accuracy: 17.66
Round 103, Train loss: 2.301, Test loss: 2.301, Test accuracy: 18.06
Round 103, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 17.97
Round 104, Train loss: 2.302, Test loss: 2.301, Test accuracy: 18.19
Round 104, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 18.01
Round 105, Train loss: 2.300, Test loss: 2.301, Test accuracy: 18.31
Round 105, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 18.16
Round 106, Train loss: 2.301, Test loss: 2.301, Test accuracy: 18.40
Round 106, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 18.24
Round 107, Train loss: 2.301, Test loss: 2.301, Test accuracy: 18.52
Round 107, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 18.46
Round 108, Train loss: 2.302, Test loss: 2.301, Test accuracy: 18.69
Round 108, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 18.48
Round 109, Train loss: 2.302, Test loss: 2.301, Test accuracy: 18.78
Round 109, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 18.84
Round 110, Train loss: 2.302, Test loss: 2.301, Test accuracy: 18.87
Round 110, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 18.80
Round 111, Train loss: 2.300, Test loss: 2.301, Test accuracy: 18.89
Round 111, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 18.83
Round 112, Train loss: 2.301, Test loss: 2.301, Test accuracy: 19.06
Round 112, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 19.04
Round 113, Train loss: 2.300, Test loss: 2.301, Test accuracy: 19.16
Round 113, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 19.23
Round 114, Train loss: 2.302, Test loss: 2.301, Test accuracy: 19.27
Round 114, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 19.28
Round 115, Train loss: 2.301, Test loss: 2.301, Test accuracy: 19.37
Round 115, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 19.36
Round 116, Train loss: 2.302, Test loss: 2.301, Test accuracy: 19.48
Round 116, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 19.34
Round 117, Train loss: 2.302, Test loss: 2.301, Test accuracy: 19.61
Round 117, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 19.52
Round 118, Train loss: 2.300, Test loss: 2.301, Test accuracy: 19.69
Round 118, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 19.64
Round 119, Train loss: 2.300, Test loss: 2.301, Test accuracy: 19.82
Round 119, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 19.76
Round 120, Train loss: 2.301, Test loss: 2.301, Test accuracy: 19.91
Round 120, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 19.83
Round 121, Train loss: 2.301, Test loss: 2.301, Test accuracy: 20.06
Round 121, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 19.93
Round 122, Train loss: 2.302, Test loss: 2.301, Test accuracy: 20.20
Round 122, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 20.12
Round 123, Train loss: 2.302, Test loss: 2.301, Test accuracy: 20.26
Round 123, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 20.21
Round 124, Train loss: 2.302, Test loss: 2.301, Test accuracy: 20.33
Round 124, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 20.24
Round 125, Train loss: 2.300, Test loss: 2.301, Test accuracy: 20.38
Round 125, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 20.31
Round 126, Train loss: 2.301, Test loss: 2.301, Test accuracy: 20.44
Round 126, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 20.40
Round 127, Train loss: 2.300, Test loss: 2.301, Test accuracy: 20.53
Round 127, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 20.36
Round 128, Train loss: 2.300, Test loss: 2.301, Test accuracy: 20.70
Round 128, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 20.53
Round 129, Train loss: 2.300, Test loss: 2.301, Test accuracy: 20.80
Round 129, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 20.51
Round 130, Train loss: 2.301, Test loss: 2.301, Test accuracy: 20.87
Round 130, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 20.48
Round 131, Train loss: 2.302, Test loss: 2.301, Test accuracy: 20.97
Round 131, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 20.61
Round 132, Train loss: 2.302, Test loss: 2.301, Test accuracy: 21.00
Round 132, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 20.80
Round 133, Train loss: 2.300, Test loss: 2.301, Test accuracy: 21.05
Round 133, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 20.87
Round 134, Train loss: 2.302, Test loss: 2.301, Test accuracy: 21.07
Round 134, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 20.99
Round 135, Train loss: 2.302, Test loss: 2.301, Test accuracy: 21.11
Round 135, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 21.00
Round 136, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.22
Round 136, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.08
Round 137, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.42
Round 137, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.11
Round 138, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.47
Round 138, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.34
Round 139, Train loss: 2.299, Test loss: 2.301, Test accuracy: 21.51
Round 139, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 21.42
Round 140, Train loss: 2.299, Test loss: 2.301, Test accuracy: 21.68
Round 140, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 21.34
Round 141, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.66
Round 141, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.40
Round 142, Train loss: 2.302, Test loss: 2.301, Test accuracy: 21.68
Round 142, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 21.49
Round 143, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.74
Round 143, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.48
Round 144, Train loss: 2.301, Test loss: 2.301, Test accuracy: 21.80
Round 144, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.56
Round 145, Train loss: 2.299, Test loss: 2.301, Test accuracy: 21.93
Round 145, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 21.77
Round 146, Train loss: 2.301, Test loss: 2.301, Test accuracy: 22.01
Round 146, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.68
Round 147, Train loss: 2.302, Test loss: 2.301, Test accuracy: 22.13
Round 147, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 21.76
Round 148, Train loss: 2.301, Test loss: 2.301, Test accuracy: 22.18
Round 148, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 21.81
Round 149, Train loss: 2.298, Test loss: 2.301, Test accuracy: 22.28
Round 149, Global train loss: 2.298, Global test loss: 2.301, Global test accuracy: 21.90
Round 150, Train loss: 2.299, Test loss: 2.301, Test accuracy: 22.36
Round 150, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 22.16
Round 151, Train loss: 2.302, Test loss: 2.301, Test accuracy: 22.40
Round 151, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 22.35
Round 152, Train loss: 2.301, Test loss: 2.301, Test accuracy: 22.57
Round 152, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 22.51
Round 153, Train loss: 2.298, Test loss: 2.301, Test accuracy: 22.77
Round 153, Global train loss: 2.298, Global test loss: 2.301, Global test accuracy: 22.42
Round 154, Train loss: 2.300, Test loss: 2.301, Test accuracy: 22.95
Round 154, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 22.57
Round 155, Train loss: 2.300, Test loss: 2.301, Test accuracy: 22.98
Round 155, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 22.65
Round 156, Train loss: 2.300, Test loss: 2.301, Test accuracy: 23.06
Round 156, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 23.07
Round 157, Train loss: 2.298, Test loss: 2.300, Test accuracy: 23.26
Round 157, Global train loss: 2.298, Global test loss: 2.301, Global test accuracy: 23.12
Round 158, Train loss: 2.300, Test loss: 2.300, Test accuracy: 23.41
Round 158, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 23.45
Round 159, Train loss: 2.299, Test loss: 2.300, Test accuracy: 23.59
Round 159, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 23.52
Round 160, Train loss: 2.301, Test loss: 2.300, Test accuracy: 23.83
Round 160, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 23.61
Round 161, Train loss: 2.301, Test loss: 2.300, Test accuracy: 23.93
Round 161, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 23.90
Round 162, Train loss: 2.300, Test loss: 2.300, Test accuracy: 24.11
Round 162, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 24.01
Round 163, Train loss: 2.298, Test loss: 2.300, Test accuracy: 24.17
Round 163, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 24.05
Round 164, Train loss: 2.302, Test loss: 2.300, Test accuracy: 24.19
Round 164, Global train loss: 2.302, Global test loss: 2.300, Global test accuracy: 24.10
Round 165, Train loss: 2.301, Test loss: 2.300, Test accuracy: 24.28
Round 165, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 24.36
Round 166, Train loss: 2.302, Test loss: 2.300, Test accuracy: 24.47
Round 166, Global train loss: 2.302, Global test loss: 2.300, Global test accuracy: 24.46
Round 167, Train loss: 2.301, Test loss: 2.300, Test accuracy: 24.52
Round 167, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 24.51
Round 168, Train loss: 2.302, Test loss: 2.300, Test accuracy: 24.57
Round 168, Global train loss: 2.302, Global test loss: 2.300, Global test accuracy: 24.55
Round 169, Train loss: 2.301, Test loss: 2.300, Test accuracy: 24.72
Round 169, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 24.55
Round 170, Train loss: 2.301, Test loss: 2.300, Test accuracy: 24.80
Round 170, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 24.60
Round 171, Train loss: 2.301, Test loss: 2.300, Test accuracy: 24.83
Round 171, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 24.61
Round 172, Train loss: 2.299, Test loss: 2.300, Test accuracy: 24.84
Round 172, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 24.69
Round 173, Train loss: 2.301, Test loss: 2.300, Test accuracy: 24.91
Round 173, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 24.68
Round 174, Train loss: 2.298, Test loss: 2.300, Test accuracy: 24.98
Round 174, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 24.85
Round 175, Train loss: 2.301, Test loss: 2.300, Test accuracy: 25.06
Round 175, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 25.02
Round 176, Train loss: 2.300, Test loss: 2.300, Test accuracy: 25.13
Round 176, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 25.02
Round 177, Train loss: 2.300, Test loss: 2.300, Test accuracy: 25.18
Round 177, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 24.96
Round 178, Train loss: 2.300, Test loss: 2.300, Test accuracy: 25.21
Round 178, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 25.13
Round 179, Train loss: 2.302, Test loss: 2.300, Test accuracy: 25.23
Round 179, Global train loss: 2.302, Global test loss: 2.300, Global test accuracy: 24.97
Round 180, Train loss: 2.300, Test loss: 2.300, Test accuracy: 25.26
Round 180, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 25.01
Round 181, Train loss: 2.298, Test loss: 2.300, Test accuracy: 25.32
Round 181, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 25.17
Round 182, Train loss: 2.300, Test loss: 2.300, Test accuracy: 25.41
Round 182, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 25.32
Round 183, Train loss: 2.301, Test loss: 2.300, Test accuracy: 25.45
Round 183, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 25.40
Round 184, Train loss: 2.300, Test loss: 2.300, Test accuracy: 25.52
Round 184, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 25.37
Round 185, Train loss: 2.299, Test loss: 2.300, Test accuracy: 25.51
Round 185, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 25.40
Round 186, Train loss: 2.297, Test loss: 2.300, Test accuracy: 25.57
Round 186, Global train loss: 2.297, Global test loss: 2.300, Global test accuracy: 25.42
Round 187, Train loss: 2.300, Test loss: 2.300, Test accuracy: 25.79
Round 187, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 25.56
Round 188, Train loss: 2.298, Test loss: 2.300, Test accuracy: 25.87
Round 188, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 25.62
Round 189, Train loss: 2.300, Test loss: 2.300, Test accuracy: 25.96
Round 189, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 25.66
Round 190, Train loss: 2.298, Test loss: 2.300, Test accuracy: 26.07
Round 190, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 25.82
Round 191, Train loss: 2.299, Test loss: 2.300, Test accuracy: 26.15
Round 191, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 25.99
Round 192, Train loss: 2.299, Test loss: 2.300, Test accuracy: 26.21
Round 192, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 25.98
Round 193, Train loss: 2.299, Test loss: 2.300, Test accuracy: 26.30
Round 193, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 26.06
Round 194, Train loss: 2.299, Test loss: 2.300, Test accuracy: 26.35
Round 194, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 26.22
Round 195, Train loss: 2.300, Test loss: 2.300, Test accuracy: 26.48
Round 195, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 26.20
Round 196, Train loss: 2.299, Test loss: 2.300, Test accuracy: 26.50
Round 196, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 26.33
Round 197, Train loss: 2.298, Test loss: 2.300, Test accuracy: 26.60
Round 197, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 26.55
Round 198, Train loss: 2.298, Test loss: 2.300, Test accuracy: 26.79
Round 198, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 26.65
Round 199, Train loss: 2.300, Test loss: 2.300, Test accuracy: 26.84
Round 199, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 26.66
Round 200, Train loss: 2.299, Test loss: 2.300, Test accuracy: 26.94
Round 200, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 26.87
Round 201, Train loss: 2.298, Test loss: 2.300, Test accuracy: 27.07
Round 201, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 26.88
Round 202, Train loss: 2.301, Test loss: 2.300, Test accuracy: 27.13
Round 202, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 26.97
Round 203, Train loss: 2.298, Test loss: 2.300, Test accuracy: 27.33
Round 203, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 27.08
Round 204, Train loss: 2.300, Test loss: 2.300, Test accuracy: 27.37
Round 204, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 27.34
Round 205, Train loss: 2.299, Test loss: 2.300, Test accuracy: 27.43
Round 205, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 27.32
Round 206, Train loss: 2.300, Test loss: 2.300, Test accuracy: 27.48
Round 206, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 27.35
Round 207, Train loss: 2.298, Test loss: 2.300, Test accuracy: 27.51
Round 207, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 27.35
Round 208, Train loss: 2.299, Test loss: 2.299, Test accuracy: 27.49
Round 208, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 27.36
Round 209, Train loss: 2.301, Test loss: 2.299, Test accuracy: 27.52
Round 209, Global train loss: 2.301, Global test loss: 2.299, Global test accuracy: 27.41
Round 210, Train loss: 2.299, Test loss: 2.299, Test accuracy: 27.56
Round 210, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 27.48
Round 211, Train loss: 2.300, Test loss: 2.299, Test accuracy: 27.67
Round 211, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 27.57
Round 212, Train loss: 2.299, Test loss: 2.299, Test accuracy: 27.77
Round 212, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 27.65
Round 213, Train loss: 2.302, Test loss: 2.299, Test accuracy: 27.82
Round 213, Global train loss: 2.302, Global test loss: 2.299, Global test accuracy: 27.68
Round 214, Train loss: 2.298, Test loss: 2.299, Test accuracy: 28.00
Round 214, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 27.73
Round 215, Train loss: 2.300, Test loss: 2.299, Test accuracy: 28.03
Round 215, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 27.89
Round 216, Train loss: 2.298, Test loss: 2.299, Test accuracy: 28.11
Round 216, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 27.83
Round 217, Train loss: 2.299, Test loss: 2.299, Test accuracy: 28.09
Round 217, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 27.75
Round 218, Train loss: 2.300, Test loss: 2.299, Test accuracy: 28.12
Round 218, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 27.79
Round 219, Train loss: 2.299, Test loss: 2.299, Test accuracy: 28.24
Round 219, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 27.84
Round 220, Train loss: 2.299, Test loss: 2.299, Test accuracy: 28.21
Round 220, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 27.86
Round 221, Train loss: 2.300, Test loss: 2.299, Test accuracy: 28.24
Round 221, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 27.93
Round 222, Train loss: 2.299, Test loss: 2.299, Test accuracy: 28.31
Round 222, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 27.90
Round 223, Train loss: 2.299, Test loss: 2.299, Test accuracy: 28.26
Round 223, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 28.01
Round 224, Train loss: 2.301, Test loss: 2.299, Test accuracy: 28.27
Round 224, Global train loss: 2.301, Global test loss: 2.299, Global test accuracy: 28.12
Round 225, Train loss: 2.301, Test loss: 2.299, Test accuracy: 28.33
Round 225, Global train loss: 2.301, Global test loss: 2.299, Global test accuracy: 28.16
Round 226, Train loss: 2.299, Test loss: 2.299, Test accuracy: 28.42
Round 226, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 28.12
Round 227, Train loss: 2.299, Test loss: 2.299, Test accuracy: 28.47
Round 227, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 27.88
Round 228, Train loss: 2.299, Test loss: 2.299, Test accuracy: 28.53
Round 228, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 28.08
Round 229, Train loss: 2.300, Test loss: 2.299, Test accuracy: 28.51
Round 229, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 28.20
Round 230, Train loss: 2.300, Test loss: 2.299, Test accuracy: 28.45
Round 230, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 28.25
Round 231, Train loss: 2.300, Test loss: 2.299, Test accuracy: 28.53
Round 231, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 28.22
Round 232, Train loss: 2.300, Test loss: 2.299, Test accuracy: 28.59
Round 232, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 28.18
Round 233, Train loss: 2.299, Test loss: 2.299, Test accuracy: 28.60
Round 233, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 28.26
Round 234, Train loss: 2.297, Test loss: 2.299, Test accuracy: 28.62
Round 234, Global train loss: 2.297, Global test loss: 2.299, Global test accuracy: 28.34
Round 235, Train loss: 2.299, Test loss: 2.299, Test accuracy: 28.62
Round 235, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 28.32
Round 236, Train loss: 2.299, Test loss: 2.299, Test accuracy: 28.65
Round 236, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 28.44
Round 237, Train loss: 2.297, Test loss: 2.299, Test accuracy: 28.78
Round 237, Global train loss: 2.297, Global test loss: 2.299, Global test accuracy: 28.40
Round 238, Train loss: 2.298, Test loss: 2.299, Test accuracy: 28.82
Round 238, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 28.45
Round 239, Train loss: 2.298, Test loss: 2.299, Test accuracy: 28.88
Round 239, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 28.57
Round 240, Train loss: 2.299, Test loss: 2.299, Test accuracy: 28.89
Round 240, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 28.23
Round 241, Train loss: 2.299, Test loss: 2.299, Test accuracy: 28.89
Round 241, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 28.39
Round 242, Train loss: 2.299, Test loss: 2.299, Test accuracy: 28.90
Round 242, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 28.67
Round 243, Train loss: 2.299, Test loss: 2.299, Test accuracy: 28.94
Round 243, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 28.70
Round 244, Train loss: 2.298, Test loss: 2.299, Test accuracy: 28.98
Round 244, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 28.66
Round 245, Train loss: 2.297, Test loss: 2.299, Test accuracy: 29.01
Round 245, Global train loss: 2.297, Global test loss: 2.299, Global test accuracy: 28.64
Round 246, Train loss: 2.300, Test loss: 2.299, Test accuracy: 29.05
Round 246, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 28.76
Round 247, Train loss: 2.299, Test loss: 2.299, Test accuracy: 29.02
Round 247, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 28.98
Round 248, Train loss: 2.297, Test loss: 2.299, Test accuracy: 29.19
Round 248, Global train loss: 2.297, Global test loss: 2.299, Global test accuracy: 28.91
Round 249, Train loss: 2.296, Test loss: 2.299, Test accuracy: 29.22
Round 249, Global train loss: 2.296, Global test loss: 2.299, Global test accuracy: 28.89
Round 250, Train loss: 2.298, Test loss: 2.299, Test accuracy: 29.29
Round 250, Global train loss: 2.298, Global test loss: 2.299, Global test accuracy: 28.89
Round 251, Train loss: 2.300, Test loss: 2.299, Test accuracy: 29.35
Round 251, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 29.19
Round 252, Train loss: 2.297, Test loss: 2.299, Test accuracy: 29.47
Round 252, Global train loss: 2.297, Global test loss: 2.299, Global test accuracy: 29.10
Round 253, Train loss: 2.297, Test loss: 2.298, Test accuracy: 29.46
Round 253, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 29.08
Round 254, Train loss: 2.296, Test loss: 2.298, Test accuracy: 29.42
Round 254, Global train loss: 2.296, Global test loss: 2.298, Global test accuracy: 28.74
Round 255, Train loss: 2.299, Test loss: 2.298, Test accuracy: 29.38
Round 255, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 28.97
Round 256, Train loss: 2.297, Test loss: 2.298, Test accuracy: 29.38
Round 256, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 28.87
Round 257, Train loss: 2.296, Test loss: 2.298, Test accuracy: 29.37
Round 257, Global train loss: 2.296, Global test loss: 2.298, Global test accuracy: 29.02
Round 258, Train loss: 2.299, Test loss: 2.298, Test accuracy: 29.39
Round 258, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 29.25
Round 259, Train loss: 2.298, Test loss: 2.298, Test accuracy: 29.46
Round 259, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 29.28
Round 260, Train loss: 2.298, Test loss: 2.298, Test accuracy: 29.56
Round 260, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 29.48
Round 261, Train loss: 2.298, Test loss: 2.298, Test accuracy: 29.64
Round 261, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 29.56
Round 262, Train loss: 2.299, Test loss: 2.298, Test accuracy: 29.71
Round 262, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 29.61
Round 263, Train loss: 2.296, Test loss: 2.298, Test accuracy: 29.88
Round 263, Global train loss: 2.296, Global test loss: 2.298, Global test accuracy: 29.69
Round 264, Train loss: 2.297, Test loss: 2.298, Test accuracy: 29.93
Round 264, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 29.69
Round 265, Train loss: 2.298, Test loss: 2.298, Test accuracy: 30.01
Round 265, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 29.74
Round 266, Train loss: 2.297, Test loss: 2.298, Test accuracy: 30.07
Round 266, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 29.74
Round 267, Train loss: 2.298, Test loss: 2.298, Test accuracy: 30.12
Round 267, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 29.75
Round 268, Train loss: 2.296, Test loss: 2.298, Test accuracy: 30.15
Round 268, Global train loss: 2.296, Global test loss: 2.298, Global test accuracy: 29.85
Round 269, Train loss: 2.299, Test loss: 2.298, Test accuracy: 30.18
Round 269, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 29.93
Round 270, Train loss: 2.296, Test loss: 2.298, Test accuracy: 30.23
Round 270, Global train loss: 2.296, Global test loss: 2.298, Global test accuracy: 29.87
Round 271, Train loss: 2.298, Test loss: 2.298, Test accuracy: 30.25
Round 271, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 29.88
Round 272, Train loss: 2.297, Test loss: 2.298, Test accuracy: 30.18
Round 272, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 30.03
Round 273, Train loss: 2.297, Test loss: 2.298, Test accuracy: 30.22
Round 273, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 30.03
Round 274, Train loss: 2.297, Test loss: 2.298, Test accuracy: 30.24
Round 274, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 30.02
Round 275, Train loss: 2.299, Test loss: 2.298, Test accuracy: 30.28
Round 275, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 29.95
Round 276, Train loss: 2.297, Test loss: 2.298, Test accuracy: 30.25
Round 276, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 30.05
Round 277, Train loss: 2.298, Test loss: 2.298, Test accuracy: 30.23
Round 277, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 29.92
Round 278, Train loss: 2.299, Test loss: 2.298, Test accuracy: 30.24
Round 278, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 29.89
Round 279, Train loss: 2.298, Test loss: 2.298, Test accuracy: 30.21
Round 279, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 29.81
Round 280, Train loss: 2.299, Test loss: 2.298, Test accuracy: 30.16
Round 280, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 29.86
Round 281, Train loss: 2.298, Test loss: 2.298, Test accuracy: 30.22
Round 281, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 29.89
Round 282, Train loss: 2.297, Test loss: 2.298, Test accuracy: 30.21
Round 282, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 30.01
Round 283, Train loss: 2.297, Test loss: 2.298, Test accuracy: 30.29
Round 283, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 30.05
Round 284, Train loss: 2.299, Test loss: 2.298, Test accuracy: 30.30
Round 284, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 30.00
Round 285, Train loss: 2.297, Test loss: 2.298, Test accuracy: 30.33
Round 285, Global train loss: 2.297, Global test loss: 2.298, Global test accuracy: 30.17
Round 286, Train loss: 2.296, Test loss: 2.298, Test accuracy: 30.37
Round 286, Global train loss: 2.296, Global test loss: 2.298, Global test accuracy: 30.13
Round 287, Train loss: 2.299, Test loss: 2.298, Test accuracy: 30.40
Round 287, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 30.17
Round 288, Train loss: 2.299, Test loss: 2.298, Test accuracy: 30.42
Round 288, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 30.42
Round 289, Train loss: 2.298, Test loss: 2.298, Test accuracy: 30.48
Round 289, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 30.71
Round 290, Train loss: 2.295, Test loss: 2.298, Test accuracy: 30.74
Round 290, Global train loss: 2.295, Global test loss: 2.298, Global test accuracy: 30.74
Round 291, Train loss: 2.294, Test loss: 2.298, Test accuracy: 30.83
Round 291, Global train loss: 2.294, Global test loss: 2.298, Global test accuracy: 30.80
Round 292, Train loss: 2.298, Test loss: 2.297, Test accuracy: 30.86
Round 292, Global train loss: 2.298, Global test loss: 2.298, Global test accuracy: 30.95
Round 293, Train loss: 2.296, Test loss: 2.297, Test accuracy: 30.94
Round 293, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 31.06
Round 294, Train loss: 2.299, Test loss: 2.297, Test accuracy: 31.09
Round 294, Global train loss: 2.299, Global test loss: 2.297, Global test accuracy: 31.14
Round 295, Train loss: 2.296, Test loss: 2.297, Test accuracy: 31.30
Round 295, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 31.18
Round 296, Train loss: 2.299, Test loss: 2.297, Test accuracy: 31.30
Round 296, Global train loss: 2.299, Global test loss: 2.297, Global test accuracy: 31.09
Round 297, Train loss: 2.298, Test loss: 2.297, Test accuracy: 31.35
Round 297, Global train loss: 2.298, Global test loss: 2.297, Global test accuracy: 31.16
Round 298, Train loss: 2.297, Test loss: 2.297, Test accuracy: 31.36
Round 298, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 31.07
Round 299, Train loss: 2.296, Test loss: 2.297, Test accuracy: 31.32
Round 299, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 30.97
Round 300, Train loss: 2.296, Test loss: 2.297, Test accuracy: 31.26
Round 300, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 30.99
Round 301, Train loss: 2.298, Test loss: 2.297, Test accuracy: 31.23
Round 301, Global train loss: 2.298, Global test loss: 2.297, Global test accuracy: 31.10
Round 302, Train loss: 2.298, Test loss: 2.297, Test accuracy: 31.24
Round 302, Global train loss: 2.298, Global test loss: 2.297, Global test accuracy: 30.99
Round 303, Train loss: 2.297, Test loss: 2.297, Test accuracy: 31.23
Round 303, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 31.09
Round 304, Train loss: 2.295, Test loss: 2.297, Test accuracy: 31.24
Round 304, Global train loss: 2.295, Global test loss: 2.297, Global test accuracy: 31.08
Round 305, Train loss: 2.299, Test loss: 2.297, Test accuracy: 31.33
Round 305, Global train loss: 2.299, Global test loss: 2.297, Global test accuracy: 31.33
Round 306, Train loss: 2.296, Test loss: 2.297, Test accuracy: 31.53
Round 306, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 31.51
Round 307, Train loss: 2.297, Test loss: 2.297, Test accuracy: 31.59
Round 307, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 31.43
Round 308, Train loss: 2.297, Test loss: 2.297, Test accuracy: 31.66
Round 308, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 31.54
Round 309, Train loss: 2.296, Test loss: 2.297, Test accuracy: 31.73
Round 309, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 31.73
Round 310, Train loss: 2.296, Test loss: 2.297, Test accuracy: 31.87
Round 310, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 31.81
Round 311, Train loss: 2.295, Test loss: 2.297, Test accuracy: 31.95
Round 311, Global train loss: 2.295, Global test loss: 2.297, Global test accuracy: 31.88
Round 312, Train loss: 2.298, Test loss: 2.297, Test accuracy: 31.97
Round 312, Global train loss: 2.298, Global test loss: 2.297, Global test accuracy: 31.87
Round 313, Train loss: 2.297, Test loss: 2.297, Test accuracy: 32.00
Round 313, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 31.82
Round 314, Train loss: 2.296, Test loss: 2.297, Test accuracy: 32.07
Round 314, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 31.86
Round 315, Train loss: 2.297, Test loss: 2.297, Test accuracy: 32.09
Round 315, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 32.01
Round 316, Train loss: 2.297, Test loss: 2.297, Test accuracy: 32.14
Round 316, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 31.94
Round 317, Train loss: 2.296, Test loss: 2.297, Test accuracy: 32.19
Round 317, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 31.99
Round 318, Train loss: 2.293, Test loss: 2.297, Test accuracy: 32.27
Round 318, Global train loss: 2.293, Global test loss: 2.297, Global test accuracy: 32.15
Round 319, Train loss: 2.297, Test loss: 2.297, Test accuracy: 32.33
Round 319, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 32.33
Round 320, Train loss: 2.296, Test loss: 2.297, Test accuracy: 32.45
Round 320, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 32.42
Round 321, Train loss: 2.298, Test loss: 2.297, Test accuracy: 32.53
Round 321, Global train loss: 2.298, Global test loss: 2.297, Global test accuracy: 32.48
Round 322, Train loss: 2.298, Test loss: 2.297, Test accuracy: 32.61
Round 322, Global train loss: 2.298, Global test loss: 2.297, Global test accuracy: 32.50
Round 323, Train loss: 2.298, Test loss: 2.297, Test accuracy: 32.62
Round 323, Global train loss: 2.298, Global test loss: 2.297, Global test accuracy: 32.53
Round 324, Train loss: 2.294, Test loss: 2.297, Test accuracy: 32.70
Round 324, Global train loss: 2.294, Global test loss: 2.297, Global test accuracy: 32.53
Round 325, Train loss: 2.295, Test loss: 2.297, Test accuracy: 32.81
Round 325, Global train loss: 2.295, Global test loss: 2.297, Global test accuracy: 32.59
Round 326, Train loss: 2.295, Test loss: 2.297, Test accuracy: 32.86
Round 326, Global train loss: 2.295, Global test loss: 2.297, Global test accuracy: 32.69
Round 327, Train loss: 2.297, Test loss: 2.297, Test accuracy: 32.90
Round 327, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 32.82
Round 328, Train loss: 2.299, Test loss: 2.297, Test accuracy: 32.91
Round 328, Global train loss: 2.299, Global test loss: 2.297, Global test accuracy: 32.80
Round 329, Train loss: 2.300, Test loss: 2.297, Test accuracy: 33.01
Round 329, Global train loss: 2.300, Global test loss: 2.297, Global test accuracy: 32.99
Round 330, Train loss: 2.298, Test loss: 2.296, Test accuracy: 33.05
Round 330, Global train loss: 2.298, Global test loss: 2.297, Global test accuracy: 32.92
Round 331, Train loss: 2.299, Test loss: 2.296, Test accuracy: 33.07
Round 331, Global train loss: 2.299, Global test loss: 2.296, Global test accuracy: 32.84
Round 332, Train loss: 2.293, Test loss: 2.296, Test accuracy: 33.09
Round 332, Global train loss: 2.293, Global test loss: 2.296, Global test accuracy: 32.78
Round 333, Train loss: 2.298, Test loss: 2.296, Test accuracy: 33.11
Round 333, Global train loss: 2.298, Global test loss: 2.296, Global test accuracy: 32.77
Round 334, Train loss: 2.297, Test loss: 2.296, Test accuracy: 33.12
Round 334, Global train loss: 2.297, Global test loss: 2.296, Global test accuracy: 32.79
Round 335, Train loss: 2.297, Test loss: 2.296, Test accuracy: 33.08
Round 335, Global train loss: 2.297, Global test loss: 2.296, Global test accuracy: 32.74
Round 336, Train loss: 2.295, Test loss: 2.296, Test accuracy: 32.97
Round 336, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 32.78
Round 337, Train loss: 2.295, Test loss: 2.296, Test accuracy: 32.94
Round 337, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 32.74
Round 338, Train loss: 2.296, Test loss: 2.296, Test accuracy: 32.90
Round 338, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 32.75
Round 339, Train loss: 2.295, Test loss: 2.296, Test accuracy: 32.93
Round 339, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 32.80
Round 340, Train loss: 2.297, Test loss: 2.296, Test accuracy: 32.96
Round 340, Global train loss: 2.297, Global test loss: 2.296, Global test accuracy: 32.76
Round 341, Train loss: 2.298, Test loss: 2.296, Test accuracy: 32.96
Round 341, Global train loss: 2.298, Global test loss: 2.296, Global test accuracy: 32.76
Round 342, Train loss: 2.296, Test loss: 2.296, Test accuracy: 32.92
Round 342, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 32.68
Round 343, Train loss: 2.298, Test loss: 2.296, Test accuracy: 32.92
Round 343, Global train loss: 2.298, Global test loss: 2.296, Global test accuracy: 32.76
Round 344, Train loss: 2.297, Test loss: 2.296, Test accuracy: 32.90
Round 344, Global train loss: 2.297, Global test loss: 2.296, Global test accuracy: 32.76
Round 345, Train loss: 2.297, Test loss: 2.296, Test accuracy: 32.86
Round 345, Global train loss: 2.297, Global test loss: 2.296, Global test accuracy: 32.83
Round 346, Train loss: 2.294, Test loss: 2.296, Test accuracy: 32.94
Round 346, Global train loss: 2.294, Global test loss: 2.296, Global test accuracy: 32.94
Round 347, Train loss: 2.295, Test loss: 2.296, Test accuracy: 33.00
Round 347, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 33.02
Round 348, Train loss: 2.295, Test loss: 2.296, Test accuracy: 33.07
Round 348, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 33.14
Round 349, Train loss: 2.297, Test loss: 2.296, Test accuracy: 33.16
Round 349, Global train loss: 2.297, Global test loss: 2.296, Global test accuracy: 33.18
Round 350, Train loss: 2.295, Test loss: 2.296, Test accuracy: 33.17
Round 350, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 33.21
Round 351, Train loss: 2.299, Test loss: 2.296, Test accuracy: 33.31
Round 351, Global train loss: 2.299, Global test loss: 2.296, Global test accuracy: 33.31
Round 352, Train loss: 2.293, Test loss: 2.296, Test accuracy: 33.44
Round 352, Global train loss: 2.293, Global test loss: 2.296, Global test accuracy: 33.40
Round 353, Train loss: 2.294, Test loss: 2.296, Test accuracy: 33.53
Round 353, Global train loss: 2.294, Global test loss: 2.296, Global test accuracy: 33.43
Round 354, Train loss: 2.293, Test loss: 2.296, Test accuracy: 33.60
Round 354, Global train loss: 2.293, Global test loss: 2.296, Global test accuracy: 33.32
Round 355, Train loss: 2.296, Test loss: 2.296, Test accuracy: 33.60
Round 355, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 33.34
Round 356, Train loss: 2.295, Test loss: 2.296, Test accuracy: 33.59
Round 356, Global train loss: 2.295, Global test loss: 2.296, Global test accuracy: 33.29
Round 357, Train loss: 2.296, Test loss: 2.296, Test accuracy: 33.62
Round 357, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 33.46
Round 358, Train loss: 2.298, Test loss: 2.296, Test accuracy: 33.63
Round 358, Global train loss: 2.298, Global test loss: 2.296, Global test accuracy: 33.47
Round 359, Train loss: 2.296, Test loss: 2.296, Test accuracy: 33.65
Round 359, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 33.37
Round 360, Train loss: 2.298, Test loss: 2.296, Test accuracy: 33.65
Round 360, Global train loss: 2.298, Global test loss: 2.296, Global test accuracy: 33.66
Round 361, Train loss: 2.293, Test loss: 2.296, Test accuracy: 33.78
Round 361, Global train loss: 2.293, Global test loss: 2.296, Global test accuracy: 33.55
Round 362, Train loss: 2.296, Test loss: 2.296, Test accuracy: 33.77
Round 362, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 33.58
Round 363, Train loss: 2.299, Test loss: 2.296, Test accuracy: 33.76
Round 363, Global train loss: 2.299, Global test loss: 2.296, Global test accuracy: 33.47
Round 364, Train loss: 2.294, Test loss: 2.295, Test accuracy: 33.76
Round 364, Global train loss: 2.294, Global test loss: 2.296, Global test accuracy: 33.54
Round 365, Train loss: 2.293, Test loss: 2.295, Test accuracy: 33.76
Round 365, Global train loss: 2.293, Global test loss: 2.295, Global test accuracy: 33.34
Round 366, Train loss: 2.292, Test loss: 2.295, Test accuracy: 33.64
Round 366, Global train loss: 2.292, Global test loss: 2.295, Global test accuracy: 33.34
Round 367, Train loss: 2.295, Test loss: 2.295, Test accuracy: 33.62
Round 367, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 33.34
Round 368, Train loss: 2.293, Test loss: 2.295, Test accuracy: 33.63
Round 368, Global train loss: 2.293, Global test loss: 2.295, Global test accuracy: 33.38
Round 369, Train loss: 2.295, Test loss: 2.295, Test accuracy: 33.65
Round 369, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 33.39
Round 370, Train loss: 2.296, Test loss: 2.295, Test accuracy: 33.68
Round 370, Global train loss: 2.296, Global test loss: 2.295, Global test accuracy: 33.56
Round 371, Train loss: 2.293, Test loss: 2.295, Test accuracy: 33.75
Round 371, Global train loss: 2.293, Global test loss: 2.295, Global test accuracy: 33.49
Round 372, Train loss: 2.295, Test loss: 2.295, Test accuracy: 33.80
Round 372, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 33.61
Round 373, Train loss: 2.292, Test loss: 2.295, Test accuracy: 33.85
Round 373, Global train loss: 2.292, Global test loss: 2.295, Global test accuracy: 33.58
Round 374, Train loss: 2.294, Test loss: 2.295, Test accuracy: 33.84
Round 374, Global train loss: 2.294, Global test loss: 2.295, Global test accuracy: 33.63
Round 375, Train loss: 2.295, Test loss: 2.295, Test accuracy: 33.85
Round 375, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 33.57
Round 376, Train loss: 2.293, Test loss: 2.295, Test accuracy: 33.83
Round 376, Global train loss: 2.293, Global test loss: 2.295, Global test accuracy: 33.59
Round 377, Train loss: 2.296, Test loss: 2.295, Test accuracy: 33.86
Round 377, Global train loss: 2.296, Global test loss: 2.295, Global test accuracy: 33.67
Round 378, Train loss: 2.294, Test loss: 2.295, Test accuracy: 33.87
Round 378, Global train loss: 2.294, Global test loss: 2.295, Global test accuracy: 33.78
Round 379, Train loss: 2.296, Test loss: 2.295, Test accuracy: 33.89
Round 379, Global train loss: 2.296, Global test loss: 2.295, Global test accuracy: 33.78
Round 380, Train loss: 2.295, Test loss: 2.295, Test accuracy: 33.91
Round 380, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 33.78
Round 381, Train loss: 2.293, Test loss: 2.295, Test accuracy: 33.96
Round 381, Global train loss: 2.293, Global test loss: 2.295, Global test accuracy: 33.73
Round 382, Train loss: 2.296, Test loss: 2.295, Test accuracy: 33.99
Round 382, Global train loss: 2.296, Global test loss: 2.295, Global test accuracy: 33.81
Round 383, Train loss: 2.295, Test loss: 2.295, Test accuracy: 34.06
Round 383, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 33.78
Round 384, Train loss: 2.296, Test loss: 2.295, Test accuracy: 34.06
Round 384, Global train loss: 2.296, Global test loss: 2.295, Global test accuracy: 33.85
Round 385, Train loss: 2.294, Test loss: 2.295, Test accuracy: 34.04
Round 385, Global train loss: 2.294, Global test loss: 2.295, Global test accuracy: 33.79
Round 386, Train loss: 2.294, Test loss: 2.295, Test accuracy: 34.07
Round 386, Global train loss: 2.294, Global test loss: 2.295, Global test accuracy: 33.81
Round 387, Train loss: 2.294, Test loss: 2.295, Test accuracy: 34.07
Round 387, Global train loss: 2.294, Global test loss: 2.295, Global test accuracy: 33.81
Round 388, Train loss: 2.297, Test loss: 2.295, Test accuracy: 34.05
Round 388, Global train loss: 2.297, Global test loss: 2.295, Global test accuracy: 33.96
Round 389, Train loss: 2.297, Test loss: 2.295, Test accuracy: 34.09
Round 389, Global train loss: 2.297, Global test loss: 2.295, Global test accuracy: 34.03
Round 390, Train loss: 2.292, Test loss: 2.295, Test accuracy: 34.16
Round 390, Global train loss: 2.292, Global test loss: 2.295, Global test accuracy: 34.05
Round 391, Train loss: 2.296, Test loss: 2.295, Test accuracy: 34.23
Round 391, Global train loss: 2.296, Global test loss: 2.295, Global test accuracy: 34.10
Round 392, Train loss: 2.293, Test loss: 2.295, Test accuracy: 34.24
Round 392, Global train loss: 2.293, Global test loss: 2.295, Global test accuracy: 34.00
Round 393, Train loss: 2.295, Test loss: 2.295, Test accuracy: 34.22
Round 393, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 34.13
Round 394, Train loss: 2.296, Test loss: 2.295, Test accuracy: 34.28
Round 394, Global train loss: 2.296, Global test loss: 2.295, Global test accuracy: 34.11
Round 395, Train loss: 2.297, Test loss: 2.294, Test accuracy: 34.31
Round 395, Global train loss: 2.297, Global test loss: 2.295, Global test accuracy: 34.28
Round 396, Train loss: 2.293, Test loss: 2.294, Test accuracy: 34.35
Round 396, Global train loss: 2.293, Global test loss: 2.294, Global test accuracy: 34.21
Round 397, Train loss: 2.295, Test loss: 2.294, Test accuracy: 34.40
Round 397, Global train loss: 2.295, Global test loss: 2.294, Global test accuracy: 34.30
Round 398, Train loss: 2.291, Test loss: 2.294, Test accuracy: 34.47
Round 398, Global train loss: 2.291, Global test loss: 2.294, Global test accuracy: 34.38
Round 399, Train loss: 2.294, Test loss: 2.294, Test accuracy: 34.50
Round 399, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 34.32
Final Round, Train loss: 2.294, Test loss: 2.294, Test accuracy: 34.84
Final Round, Global train loss: 2.294, Global test loss: 2.294, Global test accuracy: 34.32
Average accuracy final 10 rounds: 34.316 

Average global accuracy final 10 rounds: 34.188 

4379.39431476593
[1.0449495315551758, 1.9942240715026855, 2.9148294925689697, 3.773946762084961, 4.67900013923645, 5.587450981140137, 6.461469411849976, 7.366991758346558, 8.246066331863403, 9.068321228027344, 9.926655054092407, 10.779064893722534, 11.633442163467407, 12.535452842712402, 13.39794135093689, 14.249801874160767, 15.133018016815186, 15.967291355133057, 16.82261610031128, 17.715334177017212, 18.57706356048584, 19.444487810134888, 20.345439434051514, 21.188394784927368, 22.041500091552734, 22.923330545425415, 23.728471279144287, 24.584606170654297, 25.471766710281372, 26.324014902114868, 27.20352602005005, 28.099443912506104, 28.92728042602539, 29.779922008514404, 30.617082834243774, 31.486196756362915, 32.3702449798584, 33.242228507995605, 34.13764786720276, 35.03704595565796, 35.860771894454956, 36.70035243034363, 37.554776191711426, 38.414838552474976, 39.26976537704468, 40.191463232040405, 41.033199310302734, 41.90778470039368, 42.787517786026, 43.61604619026184, 44.48339104652405, 45.33226823806763, 46.19787907600403, 47.057029485702515, 47.9088499546051, 48.7570915222168, 49.615752935409546, 50.44952130317688, 51.312418699264526, 52.21960473060608, 53.09177613258362, 53.9655921459198, 54.84919214248657, 55.69755005836487, 56.595542669296265, 57.46231651306152, 58.32106041908264, 59.1620979309082, 60.05778169631958, 60.91898059844971, 61.78882646560669, 62.68842530250549, 63.51585245132446, 64.37888383865356, 65.23906183242798, 66.09037399291992, 66.96307849884033, 67.82178211212158, 68.69026136398315, 69.57685542106628, 70.47119379043579, 71.33317375183105, 72.21014952659607, 73.05230140686035, 73.88279867172241, 74.8512053489685, 75.82732033729553, 76.71395063400269, 77.59022903442383, 78.50551986694336, 79.30849289894104, 80.25278234481812, 81.14881753921509, 82.03570866584778, 83.07836508750916, 83.9566388130188, 84.81590533256531, 85.66883659362793, 86.51605129241943, 87.37673592567444, 88.29651641845703, 89.15900468826294, 90.01861882209778, 90.90464997291565, 91.74305868148804, 92.59469032287598, 93.46412658691406, 94.30228114128113, 95.15560722351074, 96.05749225616455, 96.91103005409241, 97.78594660758972, 98.66927313804626, 99.55007457733154, 100.425053358078, 101.30346894264221, 102.1759901046753, 103.04643821716309, 103.93609261512756, 104.78035068511963, 105.6931939125061, 106.57800436019897, 107.44906330108643, 108.28341054916382, 109.12152862548828, 109.9755756855011, 110.84444546699524, 111.75737047195435, 112.61547899246216, 113.49408030509949, 114.35239934921265, 115.20391607284546, 116.09692668914795, 116.988924741745, 117.89538550376892, 118.89427328109741, 119.8927149772644, 120.8822705745697, 121.74693560600281, 122.59156370162964, 123.46338057518005, 124.3297438621521, 125.23798608779907, 126.15979313850403, 127.08674240112305, 128.1140158176422, 129.20963311195374, 130.13754868507385, 131.1203737258911, 132.24912905693054, 133.39589977264404, 134.54493474960327, 135.63892030715942, 137.02042627334595, 138.1329526901245, 139.18488788604736, 140.3217203617096, 141.4170036315918, 142.47149085998535, 143.58738255500793, 144.73668026924133, 145.82319569587708, 146.94374299049377, 148.09377908706665, 149.22693276405334, 150.38467001914978, 151.51388788223267, 152.55976057052612, 153.57953691482544, 154.60112047195435, 155.59062027931213, 156.5763132572174, 157.53119325637817, 158.49591517448425, 159.49158239364624, 160.47859621047974, 161.44231009483337, 162.45732355117798, 163.4308886528015, 164.2931625843048, 165.138765335083, 166.0187976360321, 166.88225841522217, 167.76052618026733, 168.62273621559143, 169.49904537200928, 170.34533548355103, 171.21115016937256, 172.09769487380981, 172.97195529937744, 173.8537302017212, 174.73513913154602, 175.61116480827332, 176.45005631446838, 177.33198022842407, 178.21966218948364, 179.05209279060364, 179.9361855983734, 180.8236482143402, 181.66502404212952, 182.54367685317993, 183.39120602607727, 184.25933837890625, 185.1182792186737, 186.01136112213135, 186.86223769187927, 187.74807453155518, 188.61065340042114, 189.45051622390747, 190.31280159950256, 191.1687421798706, 192.0250997543335, 192.88626766204834, 193.75692915916443, 194.60966300964355, 195.46491718292236, 196.33442783355713, 197.21554970741272, 198.0981798171997, 199.0246217250824, 199.9776566028595, 200.9355411529541, 201.91214752197266, 202.8711154460907, 203.8758602142334, 204.8558042049408, 205.84459376335144, 206.78956079483032, 207.69271802902222, 208.54072499275208, 209.4250373840332, 210.31282305717468, 211.17248487472534, 212.0484118461609, 212.9100911617279, 213.78497624397278, 214.6676902770996, 215.55279231071472, 216.4129900932312, 217.29873728752136, 218.1376073360443, 219.01867771148682, 219.9272060394287, 220.79533863067627, 221.6693136692047, 222.54550576210022, 223.43116116523743, 224.27457118034363, 225.14482498168945, 226.0297224521637, 226.89306664466858, 227.76242637634277, 228.6265048980713, 229.49459528923035, 230.35897421836853, 231.21703720092773, 232.07188391685486, 232.95249891281128, 233.80868554115295, 234.67822909355164, 235.53829860687256, 236.42774939537048, 237.2936351299286, 238.16082048416138, 239.01904582977295, 239.8935878276825, 240.75494408607483, 241.61383938789368, 242.49312496185303, 243.37578058242798, 244.17950344085693, 245.06217217445374, 245.94604802131653, 246.8010847568512, 247.66425895690918, 248.57173705101013, 249.4336016178131, 250.29498958587646, 251.18514919281006, 252.06096386909485, 252.9286549091339, 253.77950596809387, 254.65517735481262, 255.52960538864136, 256.4107668399811, 257.2957456111908, 258.1825592517853, 259.0552616119385, 259.92735528945923, 260.8077347278595, 261.6851980686188, 262.5802125930786, 263.4475750923157, 264.3053033351898, 265.17781615257263, 266.0698666572571, 266.932710647583, 267.8181004524231, 268.69937539100647, 269.56886887550354, 270.44421577453613, 271.3429927825928, 272.24777460098267, 273.1292893886566, 274.00751185417175, 274.9070301055908, 275.7805576324463, 276.6912670135498, 277.6066689491272, 278.47793197631836, 279.4893276691437, 280.5300476551056, 281.5198600292206, 282.38472747802734, 283.27609276771545, 284.2313759326935, 285.2145664691925, 286.20165967941284, 287.2050120830536, 288.20007586479187, 289.1751880645752, 290.1545670032501, 291.10772371292114, 292.01078057289124, 292.8746199607849, 293.7364892959595, 294.59913897514343, 295.46001982688904, 296.35066270828247, 297.2296040058136, 298.0943088531494, 299.0231454372406, 299.9266242980957, 300.89403009414673, 301.85073041915894, 302.7577233314514, 303.63091373443604, 304.5016586780548, 305.35411167144775, 306.21614933013916, 307.0854506492615, 307.94789457321167, 308.82461428642273, 309.6685063838959, 310.5366973876953, 311.3955156803131, 312.27637100219727, 313.1530010700226, 314.0430648326874, 314.9102954864502, 315.7960090637207, 316.6504728794098, 317.53922176361084, 318.41988801956177, 319.2883222103119, 320.13599824905396, 321.0236678123474, 321.9064087867737, 322.7881193161011, 323.65903902053833, 324.5180675983429, 325.40875244140625, 326.31174874305725, 327.2211055755615, 328.15591955184937, 329.114798784256, 330.1143946647644, 331.06667375564575, 332.02580285072327, 332.9545841217041, 333.895135641098, 335.0587260723114, 336.2468886375427, 337.15046310424805, 338.01232147216797, 338.9727575778961, 339.92884612083435, 340.84522104263306, 341.80734753608704, 343.021582365036, 344.00920844078064, 344.92413115501404, 345.97763204574585, 346.91716480255127, 347.9322340488434, 348.93369007110596, 349.86096477508545, 350.8612713813782, 351.86638951301575, 352.8379969596863, 353.8569598197937, 354.8281846046448, 355.7674162387848, 356.83807158470154, 357.8051657676697, 358.80986189842224, 359.9624755382538, 360.955778837204, 361.8665220737457, 362.79171204566956, 365.0273394584656]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[7.56, 7.72, 7.81, 7.82, 7.81, 8.03, 8.06, 8.05, 8.07, 8.15, 8.12, 8.19, 8.24, 8.26, 8.45, 8.55, 8.58, 8.6, 8.76, 8.77, 8.77, 8.8, 8.9, 8.91, 8.91, 9.06, 9.0, 9.0, 9.02, 9.17, 9.32, 9.38, 9.44, 9.49, 9.72, 9.95, 10.08, 10.09, 10.21, 10.31, 10.43, 10.53, 10.58, 10.69, 10.78, 10.85, 10.95, 11.08, 11.17, 11.2, 11.3, 11.42, 11.49, 11.6, 11.8, 11.94, 12.09, 12.2, 12.34, 12.5, 12.6, 12.68, 12.8, 12.88, 13.15, 13.28, 13.36, 13.51, 13.7, 13.88, 14.04, 14.09, 14.2, 14.29, 14.41, 14.47, 14.64, 14.76, 14.88, 15.13, 15.32, 15.53, 15.59, 15.69, 15.81, 15.96, 16.05, 16.23, 16.35, 16.51, 16.59, 16.67, 16.79, 16.94, 16.97, 17.03, 17.1, 17.23, 17.45, 17.68, 17.77, 17.83, 17.89, 18.06, 18.19, 18.31, 18.4, 18.52, 18.69, 18.78, 18.87, 18.89, 19.06, 19.16, 19.27, 19.37, 19.48, 19.61, 19.69, 19.82, 19.91, 20.06, 20.2, 20.26, 20.33, 20.38, 20.44, 20.53, 20.7, 20.8, 20.87, 20.97, 21.0, 21.05, 21.07, 21.11, 21.22, 21.42, 21.47, 21.51, 21.68, 21.66, 21.68, 21.74, 21.8, 21.93, 22.01, 22.13, 22.18, 22.28, 22.36, 22.4, 22.57, 22.77, 22.95, 22.98, 23.06, 23.26, 23.41, 23.59, 23.83, 23.93, 24.11, 24.17, 24.19, 24.28, 24.47, 24.52, 24.57, 24.72, 24.8, 24.83, 24.84, 24.91, 24.98, 25.06, 25.13, 25.18, 25.21, 25.23, 25.26, 25.32, 25.41, 25.45, 25.52, 25.51, 25.57, 25.79, 25.87, 25.96, 26.07, 26.15, 26.21, 26.3, 26.35, 26.48, 26.5, 26.6, 26.79, 26.84, 26.94, 27.07, 27.13, 27.33, 27.37, 27.43, 27.48, 27.51, 27.49, 27.52, 27.56, 27.67, 27.77, 27.82, 28.0, 28.03, 28.11, 28.09, 28.12, 28.24, 28.21, 28.24, 28.31, 28.26, 28.27, 28.33, 28.42, 28.47, 28.53, 28.51, 28.45, 28.53, 28.59, 28.6, 28.62, 28.62, 28.65, 28.78, 28.82, 28.88, 28.89, 28.89, 28.9, 28.94, 28.98, 29.01, 29.05, 29.02, 29.19, 29.22, 29.29, 29.35, 29.47, 29.46, 29.42, 29.38, 29.38, 29.37, 29.39, 29.46, 29.56, 29.64, 29.71, 29.88, 29.93, 30.01, 30.07, 30.12, 30.15, 30.18, 30.23, 30.25, 30.18, 30.22, 30.24, 30.28, 30.25, 30.23, 30.24, 30.21, 30.16, 30.22, 30.21, 30.29, 30.3, 30.33, 30.37, 30.4, 30.42, 30.48, 30.74, 30.83, 30.86, 30.94, 31.09, 31.3, 31.3, 31.35, 31.36, 31.32, 31.26, 31.23, 31.24, 31.23, 31.24, 31.33, 31.53, 31.59, 31.66, 31.73, 31.87, 31.95, 31.97, 32.0, 32.07, 32.09, 32.14, 32.19, 32.27, 32.33, 32.45, 32.53, 32.61, 32.62, 32.7, 32.81, 32.86, 32.9, 32.91, 33.01, 33.05, 33.07, 33.09, 33.11, 33.12, 33.08, 32.97, 32.94, 32.9, 32.93, 32.96, 32.96, 32.92, 32.92, 32.9, 32.86, 32.94, 33.0, 33.07, 33.16, 33.17, 33.31, 33.44, 33.53, 33.6, 33.6, 33.59, 33.62, 33.63, 33.65, 33.65, 33.78, 33.77, 33.76, 33.76, 33.76, 33.64, 33.62, 33.63, 33.65, 33.68, 33.75, 33.8, 33.85, 33.84, 33.85, 33.83, 33.86, 33.87, 33.89, 33.91, 33.96, 33.99, 34.06, 34.06, 34.04, 34.07, 34.07, 34.05, 34.09, 34.16, 34.23, 34.24, 34.22, 34.28, 34.31, 34.35, 34.4, 34.47, 34.5, 34.84]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.316, Test loss: 2.300, Test accuracy: 13.11
Round   1, Train loss: 2.290, Test loss: 2.293, Test accuracy: 18.40
Round   2, Train loss: 2.269, Test loss: 2.269, Test accuracy: 16.83
Round   3, Train loss: 2.221, Test loss: 2.222, Test accuracy: 36.42
Round   4, Train loss: 2.143, Test loss: 2.135, Test accuracy: 47.56
Round   5, Train loss: 1.971, Test loss: 2.020, Test accuracy: 61.17
Round   6, Train loss: 1.821, Test loss: 1.907, Test accuracy: 68.74
Round   7, Train loss: 1.768, Test loss: 1.845, Test accuracy: 72.72
Round   8, Train loss: 1.719, Test loss: 1.793, Test accuracy: 76.29
Round   9, Train loss: 1.649, Test loss: 1.740, Test accuracy: 80.84
Round  10, Train loss: 1.615, Test loss: 1.708, Test accuracy: 83.36
Round  11, Train loss: 1.652, Test loss: 1.672, Test accuracy: 84.64
Round  12, Train loss: 1.605, Test loss: 1.654, Test accuracy: 86.39
Round  13, Train loss: 1.656, Test loss: 1.645, Test accuracy: 87.18
Round  14, Train loss: 1.637, Test loss: 1.637, Test accuracy: 87.67
Round  15, Train loss: 1.610, Test loss: 1.624, Test accuracy: 88.53
Round  16, Train loss: 1.624, Test loss: 1.608, Test accuracy: 89.10
Round  17, Train loss: 1.552, Test loss: 1.603, Test accuracy: 89.42
Round  18, Train loss: 1.547, Test loss: 1.598, Test accuracy: 89.70
Round  19, Train loss: 1.570, Test loss: 1.594, Test accuracy: 89.95
Round  20, Train loss: 1.574, Test loss: 1.590, Test accuracy: 90.22
Round  21, Train loss: 1.598, Test loss: 1.587, Test accuracy: 90.34
Round  22, Train loss: 1.594, Test loss: 1.585, Test accuracy: 90.58
Round  23, Train loss: 1.545, Test loss: 1.580, Test accuracy: 90.85
Round  24, Train loss: 1.563, Test loss: 1.576, Test accuracy: 91.10
Round  25, Train loss: 1.553, Test loss: 1.575, Test accuracy: 91.19
Round  26, Train loss: 1.533, Test loss: 1.572, Test accuracy: 91.21
Round  27, Train loss: 1.619, Test loss: 1.571, Test accuracy: 91.23
Round  28, Train loss: 1.580, Test loss: 1.570, Test accuracy: 91.37
Round  29, Train loss: 1.640, Test loss: 1.570, Test accuracy: 91.41
Round  30, Train loss: 1.545, Test loss: 1.568, Test accuracy: 91.51
Round  31, Train loss: 1.557, Test loss: 1.567, Test accuracy: 91.44
Round  32, Train loss: 1.539, Test loss: 1.567, Test accuracy: 91.35
Round  33, Train loss: 1.582, Test loss: 1.565, Test accuracy: 91.61
Round  34, Train loss: 1.582, Test loss: 1.563, Test accuracy: 91.70
Round  35, Train loss: 1.539, Test loss: 1.563, Test accuracy: 91.78
Round  36, Train loss: 1.578, Test loss: 1.560, Test accuracy: 92.03
Round  37, Train loss: 1.570, Test loss: 1.560, Test accuracy: 91.89
Round  38, Train loss: 1.568, Test loss: 1.558, Test accuracy: 92.16
Round  39, Train loss: 1.544, Test loss: 1.557, Test accuracy: 92.10
Round  40, Train loss: 1.538, Test loss: 1.557, Test accuracy: 92.18
Round  41, Train loss: 1.531, Test loss: 1.557, Test accuracy: 92.05
Round  42, Train loss: 1.534, Test loss: 1.555, Test accuracy: 92.35
Round  43, Train loss: 1.534, Test loss: 1.555, Test accuracy: 92.34
Round  44, Train loss: 1.531, Test loss: 1.555, Test accuracy: 92.25
Round  45, Train loss: 1.528, Test loss: 1.553, Test accuracy: 92.42
Round  46, Train loss: 1.547, Test loss: 1.548, Test accuracy: 93.12
Round  47, Train loss: 1.542, Test loss: 1.547, Test accuracy: 93.14
Round  48, Train loss: 1.495, Test loss: 1.546, Test accuracy: 93.23
Round  49, Train loss: 1.558, Test loss: 1.546, Test accuracy: 93.14
Round  50, Train loss: 1.525, Test loss: 1.541, Test accuracy: 93.70
Round  51, Train loss: 1.559, Test loss: 1.537, Test accuracy: 94.02
Round  52, Train loss: 1.498, Test loss: 1.536, Test accuracy: 94.12
Round  53, Train loss: 1.499, Test loss: 1.535, Test accuracy: 94.09
Round  54, Train loss: 1.519, Test loss: 1.530, Test accuracy: 94.73
Round  55, Train loss: 1.495, Test loss: 1.530, Test accuracy: 94.72
Round  56, Train loss: 1.491, Test loss: 1.529, Test accuracy: 94.71
Round  57, Train loss: 1.496, Test loss: 1.529, Test accuracy: 94.61
Round  58, Train loss: 1.505, Test loss: 1.524, Test accuracy: 95.49
Round  59, Train loss: 1.489, Test loss: 1.523, Test accuracy: 95.56
Round  60, Train loss: 1.507, Test loss: 1.517, Test accuracy: 95.99
Round  61, Train loss: 1.504, Test loss: 1.516, Test accuracy: 95.95
Round  62, Train loss: 1.490, Test loss: 1.515, Test accuracy: 96.13
Round  63, Train loss: 1.489, Test loss: 1.515, Test accuracy: 96.16
Round  64, Train loss: 1.491, Test loss: 1.515, Test accuracy: 96.10
Round  65, Train loss: 1.487, Test loss: 1.514, Test accuracy: 96.17
Round  66, Train loss: 1.486, Test loss: 1.514, Test accuracy: 96.21
Round  67, Train loss: 1.484, Test loss: 1.514, Test accuracy: 96.28
Round  68, Train loss: 1.485, Test loss: 1.514, Test accuracy: 96.29
Round  69, Train loss: 1.487, Test loss: 1.513, Test accuracy: 96.45
Round  70, Train loss: 1.490, Test loss: 1.513, Test accuracy: 96.29
Round  71, Train loss: 1.491, Test loss: 1.512, Test accuracy: 96.39
Round  72, Train loss: 1.487, Test loss: 1.512, Test accuracy: 96.36
Round  73, Train loss: 1.486, Test loss: 1.511, Test accuracy: 96.40
Round  74, Train loss: 1.485, Test loss: 1.511, Test accuracy: 96.42
Round  75, Train loss: 1.487, Test loss: 1.510, Test accuracy: 96.55
Round  76, Train loss: 1.492, Test loss: 1.509, Test accuracy: 96.57
Round  77, Train loss: 1.482, Test loss: 1.509, Test accuracy: 96.65
Round  78, Train loss: 1.487, Test loss: 1.508, Test accuracy: 96.65
Round  79, Train loss: 1.487, Test loss: 1.508, Test accuracy: 96.68
Round  80, Train loss: 1.480, Test loss: 1.508, Test accuracy: 96.69
Round  81, Train loss: 1.484, Test loss: 1.507, Test accuracy: 96.64
Round  82, Train loss: 1.478, Test loss: 1.507, Test accuracy: 96.64
Round  83, Train loss: 1.481, Test loss: 1.507, Test accuracy: 96.71
Round  84, Train loss: 1.482, Test loss: 1.506, Test accuracy: 96.80
Round  85, Train loss: 1.480, Test loss: 1.506, Test accuracy: 96.78
Round  86, Train loss: 1.481, Test loss: 1.506, Test accuracy: 96.81
Round  87, Train loss: 1.478, Test loss: 1.506, Test accuracy: 96.81
Round  88, Train loss: 1.480, Test loss: 1.505, Test accuracy: 96.72
Round  89, Train loss: 1.480, Test loss: 1.505, Test accuracy: 96.82
Round  90, Train loss: 1.479, Test loss: 1.505, Test accuracy: 96.87
Round  91, Train loss: 1.479, Test loss: 1.505, Test accuracy: 96.94
Round  92, Train loss: 1.476, Test loss: 1.505, Test accuracy: 96.93
Round  93, Train loss: 1.478, Test loss: 1.505, Test accuracy: 96.88
Round  94, Train loss: 1.478, Test loss: 1.505, Test accuracy: 96.84/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  95, Train loss: 1.477, Test loss: 1.504, Test accuracy: 96.83
Round  96, Train loss: 1.475, Test loss: 1.504, Test accuracy: 96.85
Round  97, Train loss: 1.474, Test loss: 1.504, Test accuracy: 96.86
Round  98, Train loss: 1.479, Test loss: 1.503, Test accuracy: 96.87
Round  99, Train loss: 1.477, Test loss: 1.503, Test accuracy: 96.87
Final Round, Train loss: 1.473, Test loss: 1.502, Test accuracy: 96.85
Average accuracy final 10 rounds: 96.874
966.6080191135406
[1.3135037422180176, 2.453695058822632, 3.6006081104278564, 4.704869985580444, 5.761510372161865, 6.831893444061279, 7.979883670806885, 9.137123107910156, 10.262211561203003, 11.392329454421997, 12.531022787094116, 13.630239725112915, 14.75552749633789, 15.802471399307251, 16.91469144821167, 18.063279390335083, 19.38017463684082, 20.61748957633972, 21.787221670150757, 22.919623136520386, 23.997722387313843, 25.144686937332153, 26.250336170196533, 27.366761922836304, 28.440869569778442, 29.578723907470703, 30.725382328033447, 31.760706186294556, 32.817341804504395, 33.91306161880493, 34.98182678222656, 36.08865547180176, 37.19933295249939, 38.31751322746277, 39.43811011314392, 40.90625214576721, 42.033613443374634, 43.1967077255249, 44.35871458053589, 45.562313079833984, 46.66629767417908, 47.75104594230652, 48.86027479171753, 49.9353609085083, 51.065555572509766, 52.187949419021606, 53.32965707778931, 54.3303542137146, 55.532854318618774, 56.652899742126465, 57.85016703605652, 59.008692264556885, 60.06070399284363, 61.17159557342529, 62.33495259284973, 63.43016791343689, 64.50479197502136, 65.7251386642456, 66.97617530822754, 68.0802686214447, 69.48900985717773, 70.63618350028992, 71.70160031318665, 72.8304443359375, 74.01130700111389, 75.20589756965637, 76.30480980873108, 77.43659973144531, 78.59478831291199, 79.73109817504883, 80.84499216079712, 81.97087001800537, 83.12296390533447, 84.30505132675171, 85.42455387115479, 86.54194569587708, 87.71678686141968, 88.8567407131195, 90.07661509513855, 91.14976572990417, 92.18557596206665, 93.23502969741821, 94.29215955734253, 95.3744547367096, 96.40006375312805, 97.44714260101318, 98.49054861068726, 99.58585906028748, 100.61924767494202, 101.66225242614746, 102.7022762298584, 103.75805878639221, 104.81909132003784, 105.83739423751831, 106.90734004974365, 107.99498987197876, 109.03233766555786, 110.10356211662292, 111.18063306808472, 112.27570247650146, 113.9947464466095]
[13.11, 18.4, 16.83, 36.42, 47.56, 61.17, 68.74, 72.72, 76.29, 80.84, 83.36, 84.64, 86.39, 87.18, 87.67, 88.53, 89.1, 89.42, 89.7, 89.95, 90.22, 90.34, 90.58, 90.85, 91.1, 91.19, 91.21, 91.23, 91.37, 91.41, 91.51, 91.44, 91.35, 91.61, 91.7, 91.78, 92.03, 91.89, 92.16, 92.1, 92.18, 92.05, 92.35, 92.34, 92.25, 92.42, 93.12, 93.14, 93.23, 93.14, 93.7, 94.02, 94.12, 94.09, 94.73, 94.72, 94.71, 94.61, 95.49, 95.56, 95.99, 95.95, 96.13, 96.16, 96.1, 96.17, 96.21, 96.28, 96.29, 96.45, 96.29, 96.39, 96.36, 96.4, 96.42, 96.55, 96.57, 96.65, 96.65, 96.68, 96.69, 96.64, 96.64, 96.71, 96.8, 96.78, 96.81, 96.81, 96.72, 96.82, 96.87, 96.94, 96.93, 96.88, 96.84, 96.83, 96.85, 96.86, 96.87, 96.87, 96.85]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
401408
401920
532992
533248
549632
549696
550336
550346
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.319, Test loss: 2.300, Test accuracy: 11.49
Round   1, Train loss: 2.305, Test loss: 2.293, Test accuracy: 29.75
Round   2, Train loss: 2.270, Test loss: 2.253, Test accuracy: 29.92
Round   3, Train loss: 2.195, Test loss: 2.179, Test accuracy: 48.07
Round   4, Train loss: 2.040, Test loss: 2.070, Test accuracy: 53.01
Round   5, Train loss: 1.950, Test loss: 1.974, Test accuracy: 58.55
Round   6, Train loss: 1.902, Test loss: 1.911, Test accuracy: 66.14
Round   7, Train loss: 1.800, Test loss: 1.838, Test accuracy: 74.17
Round   8, Train loss: 1.752, Test loss: 1.787, Test accuracy: 80.22
Round   9, Train loss: 1.717, Test loss: 1.742, Test accuracy: 84.08
Round  10, Train loss: 1.679, Test loss: 1.710, Test accuracy: 87.30
Round  11, Train loss: 1.661, Test loss: 1.690, Test accuracy: 89.08
Round  12, Train loss: 1.639, Test loss: 1.666, Test accuracy: 91.01
Round  13, Train loss: 1.653, Test loss: 1.636, Test accuracy: 92.92
Round  14, Train loss: 1.659, Test loss: 1.608, Test accuracy: 93.63
Round  15, Train loss: 1.610, Test loss: 1.606, Test accuracy: 93.87
Round  16, Train loss: 1.595, Test loss: 1.602, Test accuracy: 94.05
Round  17, Train loss: 1.594, Test loss: 1.595, Test accuracy: 94.09
Round  18, Train loss: 1.601, Test loss: 1.591, Test accuracy: 94.36
Round  19, Train loss: 1.598, Test loss: 1.583, Test accuracy: 94.77
Round  20, Train loss: 1.587, Test loss: 1.577, Test accuracy: 94.79
Round  21, Train loss: 1.586, Test loss: 1.572, Test accuracy: 94.89
Round  22, Train loss: 1.585, Test loss: 1.569, Test accuracy: 94.94
Round  23, Train loss: 1.580, Test loss: 1.565, Test accuracy: 95.26
Round  24, Train loss: 1.566, Test loss: 1.563, Test accuracy: 95.26
Round  25, Train loss: 1.553, Test loss: 1.561, Test accuracy: 95.42
Round  26, Train loss: 1.559, Test loss: 1.561, Test accuracy: 95.48
Round  27, Train loss: 1.561, Test loss: 1.557, Test accuracy: 95.56
Round  28, Train loss: 1.561, Test loss: 1.556, Test accuracy: 95.67
Round  29, Train loss: 1.559, Test loss: 1.553, Test accuracy: 95.69
Round  30, Train loss: 1.553, Test loss: 1.550, Test accuracy: 95.78
Round  31, Train loss: 1.550, Test loss: 1.550, Test accuracy: 95.86
Round  32, Train loss: 1.543, Test loss: 1.549, Test accuracy: 95.98
Round  33, Train loss: 1.557, Test loss: 1.545, Test accuracy: 96.02
Round  34, Train loss: 1.549, Test loss: 1.543, Test accuracy: 96.09
Round  35, Train loss: 1.541, Test loss: 1.544, Test accuracy: 96.06
Round  36, Train loss: 1.538, Test loss: 1.541, Test accuracy: 96.16
Round  37, Train loss: 1.536, Test loss: 1.541, Test accuracy: 96.18
Round  38, Train loss: 1.536, Test loss: 1.540, Test accuracy: 96.14
Round  39, Train loss: 1.534, Test loss: 1.539, Test accuracy: 96.22
Round  40, Train loss: 1.536, Test loss: 1.537, Test accuracy: 96.14
Round  41, Train loss: 1.534, Test loss: 1.537, Test accuracy: 96.37
Round  42, Train loss: 1.531, Test loss: 1.536, Test accuracy: 96.39
Round  43, Train loss: 1.534, Test loss: 1.535, Test accuracy: 96.33
Round  44, Train loss: 1.532, Test loss: 1.533, Test accuracy: 96.36
Round  45, Train loss: 1.536, Test loss: 1.531, Test accuracy: 96.37
Round  46, Train loss: 1.527, Test loss: 1.531, Test accuracy: 96.41
Round  47, Train loss: 1.525, Test loss: 1.531, Test accuracy: 96.43
Round  48, Train loss: 1.518, Test loss: 1.530, Test accuracy: 96.50
Round  49, Train loss: 1.522, Test loss: 1.529, Test accuracy: 96.51
Round  50, Train loss: 1.521, Test loss: 1.529, Test accuracy: 96.50
Round  51, Train loss: 1.526, Test loss: 1.528, Test accuracy: 96.51
Round  52, Train loss: 1.522, Test loss: 1.528, Test accuracy: 96.49
Round  53, Train loss: 1.514, Test loss: 1.527, Test accuracy: 96.63
Round  54, Train loss: 1.516, Test loss: 1.526, Test accuracy: 96.55
Round  55, Train loss: 1.518, Test loss: 1.526, Test accuracy: 96.65
Round  56, Train loss: 1.515, Test loss: 1.526, Test accuracy: 96.61
Round  57, Train loss: 1.511, Test loss: 1.526, Test accuracy: 96.71
Round  58, Train loss: 1.518, Test loss: 1.525, Test accuracy: 96.68
Round  59, Train loss: 1.514, Test loss: 1.524, Test accuracy: 96.75
Round  60, Train loss: 1.512, Test loss: 1.524, Test accuracy: 96.71
Round  61, Train loss: 1.511, Test loss: 1.523, Test accuracy: 96.74
Round  62, Train loss: 1.509, Test loss: 1.524, Test accuracy: 96.75
Round  63, Train loss: 1.513, Test loss: 1.522, Test accuracy: 96.76
Round  64, Train loss: 1.508, Test loss: 1.522, Test accuracy: 96.79
Round  65, Train loss: 1.511, Test loss: 1.522, Test accuracy: 96.72
Round  66, Train loss: 1.506, Test loss: 1.522, Test accuracy: 96.88
Round  67, Train loss: 1.504, Test loss: 1.522, Test accuracy: 96.94
Round  68, Train loss: 1.509, Test loss: 1.521, Test accuracy: 96.82
Round  69, Train loss: 1.505, Test loss: 1.521, Test accuracy: 96.92
Round  70, Train loss: 1.506, Test loss: 1.521, Test accuracy: 96.79
Round  71, Train loss: 1.512, Test loss: 1.519, Test accuracy: 96.87
Round  72, Train loss: 1.503, Test loss: 1.519, Test accuracy: 96.98
Round  73, Train loss: 1.504, Test loss: 1.520, Test accuracy: 96.85
Round  74, Train loss: 1.501, Test loss: 1.520, Test accuracy: 96.96
Round  75, Train loss: 1.503, Test loss: 1.519, Test accuracy: 96.95
Round  76, Train loss: 1.501, Test loss: 1.519, Test accuracy: 96.95
Round  77, Train loss: 1.501, Test loss: 1.519, Test accuracy: 96.97
Round  78, Train loss: 1.502, Test loss: 1.519, Test accuracy: 96.90
Round  79, Train loss: 1.500, Test loss: 1.518, Test accuracy: 97.06
Round  80, Train loss: 1.501, Test loss: 1.518, Test accuracy: 96.96
Round  81, Train loss: 1.504, Test loss: 1.517, Test accuracy: 97.03
Round  82, Train loss: 1.502, Test loss: 1.517, Test accuracy: 96.95
Round  83, Train loss: 1.503, Test loss: 1.516, Test accuracy: 97.06
Round  84, Train loss: 1.501, Test loss: 1.515, Test accuracy: 97.07
Round  85, Train loss: 1.499, Test loss: 1.516, Test accuracy: 97.01
Round  86, Train loss: 1.504, Test loss: 1.514, Test accuracy: 97.24
Round  87, Train loss: 1.496, Test loss: 1.515, Test accuracy: 97.08
Round  88, Train loss: 1.498, Test loss: 1.515, Test accuracy: 97.19
Round  89, Train loss: 1.497, Test loss: 1.515, Test accuracy: 97.13
Round  90, Train loss: 1.498, Test loss: 1.514, Test accuracy: 97.13
Round  91, Train loss: 1.495, Test loss: 1.515, Test accuracy: 97.20
Round  92, Train loss: 1.496, Test loss: 1.515, Test accuracy: 97.17
Round  93, Train loss: 1.494, Test loss: 1.515, Test accuracy: 97.13/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Train loss: 1.495, Test loss: 1.515, Test accuracy: 97.11
Round  95, Train loss: 1.495, Test loss: 1.514, Test accuracy: 97.18
Round  96, Train loss: 1.494, Test loss: 1.513, Test accuracy: 97.24
Round  97, Train loss: 1.497, Test loss: 1.513, Test accuracy: 97.25
Round  98, Train loss: 1.494, Test loss: 1.513, Test accuracy: 97.19
Round  99, Train loss: 1.498, Test loss: 1.513, Test accuracy: 97.18
Final Round, Train loss: 1.478, Test loss: 1.509, Test accuracy: 97.23
Average accuracy final 10 rounds: 97.178
1256.0557796955109
[1.284339427947998, 2.568678855895996, 3.7481467723846436, 4.927614688873291, 5.935810804367065, 6.94400691986084, 7.96399450302124, 8.98398208618164, 10.069665670394897, 11.155349254608154, 12.292956352233887, 13.43056344985962, 14.574107885360718, 15.717652320861816, 16.81809425354004, 17.91853618621826, 19.061997175216675, 20.205458164215088, 21.361116647720337, 22.516775131225586, 23.612491846084595, 24.708208560943604, 25.73597502708435, 26.763741493225098, 27.80417513847351, 28.844608783721924, 29.87548804283142, 30.906367301940918, 31.98759937286377, 33.06883144378662, 34.15802550315857, 35.24721956253052, 36.301156997680664, 37.35509443283081, 38.43544054031372, 39.51578664779663, 40.60145163536072, 41.687116622924805, 42.81020450592041, 43.933292388916016, 44.991164684295654, 46.04903697967529, 47.09464716911316, 48.140257358551025, 49.21765375137329, 50.29505014419556, 51.361974239349365, 52.428898334503174, 53.52921104431152, 54.62952375411987, 55.68212056159973, 56.73471736907959, 57.78565526008606, 58.83659315109253, 59.895063161849976, 60.95353317260742, 62.03007793426514, 63.10662269592285, 64.12067580223083, 65.13472890853882, 66.09869146347046, 67.0626540184021, 68.14850664138794, 69.23435926437378, 70.30731511116028, 71.38027095794678, 72.36097645759583, 73.34168195724487, 74.40676259994507, 75.47184324264526, 76.57741856575012, 77.68299388885498, 78.7468810081482, 79.8107681274414, 80.9406909942627, 82.07061386108398, 83.08476662635803, 84.09891939163208, 85.26193189620972, 86.42494440078735, 87.62331557273865, 88.82168674468994, 89.96267604827881, 91.10366535186768, 92.15399479866028, 93.20432424545288, 94.32143425941467, 95.43854427337646, 96.60658431053162, 97.77462434768677, 98.92256283760071, 100.07050132751465, 101.18558359146118, 102.30066585540771, 103.42012643814087, 104.53958702087402, 105.65355372428894, 106.76752042770386, 107.90921473503113, 109.0509090423584, 110.13460421562195, 111.2182993888855, 112.26666522026062, 113.31503105163574, 114.38436508178711, 115.45369911193848, 116.52837872505188, 117.60305833816528, 118.74556469917297, 119.88807106018066, 120.88399958610535, 121.87992811203003, 122.87752676010132, 123.87512540817261, 124.96742057800293, 126.05971574783325, 127.13044381141663, 128.201171875, 129.23102498054504, 130.2608780860901, 131.42878198623657, 132.59668588638306, 133.79085230827332, 134.98501873016357, 136.15552735328674, 137.3260359764099, 138.46002173423767, 139.59400749206543, 140.7541561126709, 141.91430473327637, 143.04202795028687, 144.16975116729736, 145.28656125068665, 146.40337133407593, 147.50957775115967, 148.6157841682434, 149.7860288619995, 150.95627355575562, 152.0732500553131, 153.1902265548706, 154.2560031414032, 155.3217797279358, 156.43762731552124, 157.5534749031067, 158.70244026184082, 159.85140562057495, 160.94495916366577, 162.0385127067566, 163.11319661140442, 164.18788051605225, 165.36358451843262, 166.539288520813, 167.70520877838135, 168.8711290359497, 170.0231204032898, 171.17511177062988, 172.25548219680786, 173.33585262298584, 174.41856026649475, 175.50126791000366, 176.66232776641846, 177.82338762283325, 179.04690742492676, 180.27042722702026, 181.48236322402954, 182.69429922103882, 183.81005573272705, 184.92581224441528, 186.08151984214783, 187.23722743988037, 188.4242296218872, 189.61123180389404, 190.73507690429688, 191.8589220046997, 192.99243187904358, 194.12594175338745, 195.30312991142273, 196.480318069458, 197.6336750984192, 198.78703212738037, 199.90341806411743, 201.0198040008545, 202.20270037651062, 203.38559675216675, 204.55480694770813, 205.7240171432495, 206.8144862651825, 207.90495538711548, 209.0355408191681, 210.1661262512207, 211.2705271244049, 212.3749279975891, 213.44782209396362, 214.52071619033813, 215.64153337478638, 216.76235055923462, 217.90296483039856, 219.0435791015625, 220.19240593910217, 221.34123277664185, 223.0772385597229, 224.81324434280396]
[11.49, 11.49, 29.75, 29.75, 29.92, 29.92, 48.07, 48.07, 53.01, 53.01, 58.55, 58.55, 66.14, 66.14, 74.17, 74.17, 80.22, 80.22, 84.08, 84.08, 87.3, 87.3, 89.08, 89.08, 91.01, 91.01, 92.92, 92.92, 93.63, 93.63, 93.87, 93.87, 94.05, 94.05, 94.09, 94.09, 94.36, 94.36, 94.77, 94.77, 94.79, 94.79, 94.89, 94.89, 94.94, 94.94, 95.26, 95.26, 95.26, 95.26, 95.42, 95.42, 95.48, 95.48, 95.56, 95.56, 95.67, 95.67, 95.69, 95.69, 95.78, 95.78, 95.86, 95.86, 95.98, 95.98, 96.02, 96.02, 96.09, 96.09, 96.06, 96.06, 96.16, 96.16, 96.18, 96.18, 96.14, 96.14, 96.22, 96.22, 96.14, 96.14, 96.37, 96.37, 96.39, 96.39, 96.33, 96.33, 96.36, 96.36, 96.37, 96.37, 96.41, 96.41, 96.43, 96.43, 96.5, 96.5, 96.51, 96.51, 96.5, 96.5, 96.51, 96.51, 96.49, 96.49, 96.63, 96.63, 96.55, 96.55, 96.65, 96.65, 96.61, 96.61, 96.71, 96.71, 96.68, 96.68, 96.75, 96.75, 96.71, 96.71, 96.74, 96.74, 96.75, 96.75, 96.76, 96.76, 96.79, 96.79, 96.72, 96.72, 96.88, 96.88, 96.94, 96.94, 96.82, 96.82, 96.92, 96.92, 96.79, 96.79, 96.87, 96.87, 96.98, 96.98, 96.85, 96.85, 96.96, 96.96, 96.95, 96.95, 96.95, 96.95, 96.97, 96.97, 96.9, 96.9, 97.06, 97.06, 96.96, 96.96, 97.03, 97.03, 96.95, 96.95, 97.06, 97.06, 97.07, 97.07, 97.01, 97.01, 97.24, 97.24, 97.08, 97.08, 97.19, 97.19, 97.13, 97.13, 97.13, 97.13, 97.2, 97.2, 97.17, 97.17, 97.13, 97.13, 97.11, 97.11, 97.18, 97.18, 97.24, 97.24, 97.25, 97.25, 97.19, 97.19, 97.18, 97.18, 97.23, 97.23]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.286, Test loss: 2.286, Test accuracy: 15.96
Round   0, Global train loss: 2.286, Global test loss: 2.299, Global test accuracy: 11.00
Round   1, Train loss: 2.199, Test loss: 2.232, Test accuracy: 22.50
Round   1, Global train loss: 2.199, Global test loss: 2.285, Global test accuracy: 15.74
Round   2, Train loss: 2.059, Test loss: 2.138, Test accuracy: 33.88
Round   2, Global train loss: 2.059, Global test loss: 2.271, Global test accuracy: 14.93
Round   3, Train loss: 1.993, Test loss: 2.042, Test accuracy: 44.47
Round   3, Global train loss: 1.993, Global test loss: 2.285, Global test accuracy: 13.55
Round   4, Train loss: 1.755, Test loss: 1.990, Test accuracy: 50.22
Round   4, Global train loss: 1.755, Global test loss: 2.272, Global test accuracy: 15.17
Round   5, Train loss: 1.937, Test loss: 1.904, Test accuracy: 59.34
Round   5, Global train loss: 1.937, Global test loss: 2.264, Global test accuracy: 16.98
Round   6, Train loss: 1.694, Test loss: 1.880, Test accuracy: 61.35
Round   6, Global train loss: 1.694, Global test loss: 2.275, Global test accuracy: 14.78
Round   7, Train loss: 1.819, Test loss: 1.826, Test accuracy: 66.50
Round   7, Global train loss: 1.819, Global test loss: 2.252, Global test accuracy: 19.55
Round   8, Train loss: 1.769, Test loss: 1.779, Test accuracy: 71.47
Round   8, Global train loss: 1.769, Global test loss: 2.276, Global test accuracy: 14.33
Round   9, Train loss: 1.616, Test loss: 1.766, Test accuracy: 71.82
Round   9, Global train loss: 1.616, Global test loss: 2.263, Global test accuracy: 16.76
Round  10, Train loss: 1.705, Test loss: 1.727, Test accuracy: 76.30
Round  10, Global train loss: 1.705, Global test loss: 2.271, Global test accuracy: 15.25
Round  11, Train loss: 1.637, Test loss: 1.718, Test accuracy: 76.48
Round  11, Global train loss: 1.637, Global test loss: 2.260, Global test accuracy: 17.95
Round  12, Train loss: 1.638, Test loss: 1.709, Test accuracy: 77.31
Round  12, Global train loss: 1.638, Global test loss: 2.252, Global test accuracy: 20.08
Round  13, Train loss: 1.684, Test loss: 1.689, Test accuracy: 79.25
Round  13, Global train loss: 1.684, Global test loss: 2.265, Global test accuracy: 16.16
Round  14, Train loss: 1.644, Test loss: 1.688, Test accuracy: 79.24
Round  14, Global train loss: 1.644, Global test loss: 2.262, Global test accuracy: 17.25
Round  15, Train loss: 1.657, Test loss: 1.673, Test accuracy: 81.01
Round  15, Global train loss: 1.657, Global test loss: 2.268, Global test accuracy: 16.48
Round  16, Train loss: 1.527, Test loss: 1.670, Test accuracy: 81.14
Round  16, Global train loss: 1.527, Global test loss: 2.282, Global test accuracy: 14.73
Round  17, Train loss: 1.578, Test loss: 1.652, Test accuracy: 82.24
Round  17, Global train loss: 1.578, Global test loss: 2.278, Global test accuracy: 16.94
Round  18, Train loss: 1.517, Test loss: 1.651, Test accuracy: 82.30
Round  18, Global train loss: 1.517, Global test loss: 2.261, Global test accuracy: 17.83
Round  19, Train loss: 1.578, Test loss: 1.648, Test accuracy: 82.41
Round  19, Global train loss: 1.578, Global test loss: 2.283, Global test accuracy: 15.57
Round  20, Train loss: 1.546, Test loss: 1.647, Test accuracy: 82.55
Round  20, Global train loss: 1.546, Global test loss: 2.290, Global test accuracy: 14.22
Round  21, Train loss: 1.585, Test loss: 1.637, Test accuracy: 83.39
Round  21, Global train loss: 1.585, Global test loss: 2.258, Global test accuracy: 17.20
Round  22, Train loss: 1.626, Test loss: 1.628, Test accuracy: 84.40
Round  22, Global train loss: 1.626, Global test loss: 2.268, Global test accuracy: 17.85
Round  23, Train loss: 1.578, Test loss: 1.625, Test accuracy: 84.64
Round  23, Global train loss: 1.578, Global test loss: 2.260, Global test accuracy: 17.79
Round  24, Train loss: 1.544, Test loss: 1.624, Test accuracy: 84.65
Round  24, Global train loss: 1.544, Global test loss: 2.263, Global test accuracy: 17.45
Round  25, Train loss: 1.488, Test loss: 1.621, Test accuracy: 84.94
Round  25, Global train loss: 1.488, Global test loss: 2.259, Global test accuracy: 17.93
Round  26, Train loss: 1.536, Test loss: 1.620, Test accuracy: 84.97
Round  26, Global train loss: 1.536, Global test loss: 2.243, Global test accuracy: 21.05
Round  27, Train loss: 1.541, Test loss: 1.620, Test accuracy: 84.98
Round  27, Global train loss: 1.541, Global test loss: 2.294, Global test accuracy: 14.45
Round  28, Train loss: 1.568, Test loss: 1.612, Test accuracy: 85.76
Round  28, Global train loss: 1.568, Global test loss: 2.256, Global test accuracy: 17.56
Round  29, Train loss: 1.547, Test loss: 1.610, Test accuracy: 85.80
Round  29, Global train loss: 1.547, Global test loss: 2.289, Global test accuracy: 14.64
Round  30, Train loss: 1.507, Test loss: 1.610, Test accuracy: 85.81
Round  30, Global train loss: 1.507, Global test loss: 2.249, Global test accuracy: 19.77
Round  31, Train loss: 1.553, Test loss: 1.603, Test accuracy: 86.58
Round  31, Global train loss: 1.553, Global test loss: 2.296, Global test accuracy: 14.73
Round  32, Train loss: 1.509, Test loss: 1.602, Test accuracy: 86.67
Round  32, Global train loss: 1.509, Global test loss: 2.261, Global test accuracy: 17.95
Round  33, Train loss: 1.513, Test loss: 1.601, Test accuracy: 86.78
Round  33, Global train loss: 1.513, Global test loss: 2.273, Global test accuracy: 15.72
Round  34, Train loss: 1.535, Test loss: 1.601, Test accuracy: 86.77
Round  34, Global train loss: 1.535, Global test loss: 2.256, Global test accuracy: 17.10
Round  35, Train loss: 1.475, Test loss: 1.600, Test accuracy: 86.75
Round  35, Global train loss: 1.475, Global test loss: 2.292, Global test accuracy: 13.79
Round  36, Train loss: 1.569, Test loss: 1.600, Test accuracy: 86.71
Round  36, Global train loss: 1.569, Global test loss: 2.278, Global test accuracy: 16.23
Round  37, Train loss: 1.539, Test loss: 1.600, Test accuracy: 86.75
Round  37, Global train loss: 1.539, Global test loss: 2.247, Global test accuracy: 20.13
Round  38, Train loss: 1.536, Test loss: 1.599, Test accuracy: 86.83
Round  38, Global train loss: 1.536, Global test loss: 2.272, Global test accuracy: 15.23
Round  39, Train loss: 1.565, Test loss: 1.599, Test accuracy: 86.84
Round  39, Global train loss: 1.565, Global test loss: 2.260, Global test accuracy: 17.09
Round  40, Train loss: 1.504, Test loss: 1.598, Test accuracy: 86.84
Round  40, Global train loss: 1.504, Global test loss: 2.261, Global test accuracy: 17.19
Round  41, Train loss: 1.504, Test loss: 1.598, Test accuracy: 86.84
Round  41, Global train loss: 1.504, Global test loss: 2.266, Global test accuracy: 17.03
Round  42, Train loss: 1.484, Test loss: 1.591, Test accuracy: 87.60
Round  42, Global train loss: 1.484, Global test loss: 2.288, Global test accuracy: 14.71
Round  43, Train loss: 1.535, Test loss: 1.591, Test accuracy: 87.64
Round  43, Global train loss: 1.535, Global test loss: 2.266, Global test accuracy: 17.01
Round  44, Train loss: 1.503, Test loss: 1.590, Test accuracy: 87.65
Round  44, Global train loss: 1.503, Global test loss: 2.287, Global test accuracy: 13.11
Round  45, Train loss: 1.536, Test loss: 1.590, Test accuracy: 87.63
Round  45, Global train loss: 1.536, Global test loss: 2.290, Global test accuracy: 15.33
Round  46, Train loss: 1.533, Test loss: 1.590, Test accuracy: 87.67
Round  46, Global train loss: 1.533, Global test loss: 2.314, Global test accuracy: 12.04
Round  47, Train loss: 1.534, Test loss: 1.589, Test accuracy: 87.66
Round  47, Global train loss: 1.534, Global test loss: 2.276, Global test accuracy: 15.98
Round  48, Train loss: 1.473, Test loss: 1.589, Test accuracy: 87.71
Round  48, Global train loss: 1.473, Global test loss: 2.251, Global test accuracy: 19.08
Round  49, Train loss: 1.534, Test loss: 1.588, Test accuracy: 87.75
Round  49, Global train loss: 1.534, Global test loss: 2.265, Global test accuracy: 17.41
Round  50, Train loss: 1.502, Test loss: 1.588, Test accuracy: 87.74
Round  50, Global train loss: 1.502, Global test loss: 2.259, Global test accuracy: 17.58
Round  51, Train loss: 1.567, Test loss: 1.588, Test accuracy: 87.76
Round  51, Global train loss: 1.567, Global test loss: 2.242, Global test accuracy: 19.46
Round  52, Train loss: 1.472, Test loss: 1.588, Test accuracy: 87.78
Round  52, Global train loss: 1.472, Global test loss: 2.264, Global test accuracy: 18.07
Round  53, Train loss: 1.503, Test loss: 1.588, Test accuracy: 87.79
Round  53, Global train loss: 1.503, Global test loss: 2.267, Global test accuracy: 16.09
Round  54, Train loss: 1.502, Test loss: 1.588, Test accuracy: 87.82
Round  54, Global train loss: 1.502, Global test loss: 2.236, Global test accuracy: 21.22
Round  55, Train loss: 1.564, Test loss: 1.587, Test accuracy: 87.84
Round  55, Global train loss: 1.564, Global test loss: 2.267, Global test accuracy: 15.88
Round  56, Train loss: 1.502, Test loss: 1.587, Test accuracy: 87.78
Round  56, Global train loss: 1.502, Global test loss: 2.246, Global test accuracy: 18.56
Round  57, Train loss: 1.502, Test loss: 1.587, Test accuracy: 87.83
Round  57, Global train loss: 1.502, Global test loss: 2.262, Global test accuracy: 17.53
Round  58, Train loss: 1.530, Test loss: 1.587, Test accuracy: 87.80
Round  58, Global train loss: 1.530, Global test loss: 2.291, Global test accuracy: 14.25
Round  59, Train loss: 1.500, Test loss: 1.587, Test accuracy: 87.84
Round  59, Global train loss: 1.500, Global test loss: 2.270, Global test accuracy: 16.27
Round  60, Train loss: 1.501, Test loss: 1.587, Test accuracy: 87.77
Round  60, Global train loss: 1.501, Global test loss: 2.284, Global test accuracy: 15.99
Round  61, Train loss: 1.535, Test loss: 1.587, Test accuracy: 87.76
Round  61, Global train loss: 1.535, Global test loss: 2.267, Global test accuracy: 16.24
Round  62, Train loss: 1.498, Test loss: 1.587, Test accuracy: 87.72
Round  62, Global train loss: 1.498, Global test loss: 2.285, Global test accuracy: 14.57
Round  63, Train loss: 1.534, Test loss: 1.587, Test accuracy: 87.77
Round  63, Global train loss: 1.534, Global test loss: 2.247, Global test accuracy: 19.72
Round  64, Train loss: 1.566, Test loss: 1.587, Test accuracy: 87.80
Round  64, Global train loss: 1.566, Global test loss: 2.255, Global test accuracy: 18.71
Round  65, Train loss: 1.532, Test loss: 1.587, Test accuracy: 87.81
Round  65, Global train loss: 1.532, Global test loss: 2.292, Global test accuracy: 15.41
Round  66, Train loss: 1.532, Test loss: 1.587, Test accuracy: 87.82
Round  66, Global train loss: 1.532, Global test loss: 2.275, Global test accuracy: 16.61
Round  67, Train loss: 1.533, Test loss: 1.587, Test accuracy: 87.82
Round  67, Global train loss: 1.533, Global test loss: 2.289, Global test accuracy: 15.17
Round  68, Train loss: 1.501, Test loss: 1.587, Test accuracy: 87.79
Round  68, Global train loss: 1.501, Global test loss: 2.274, Global test accuracy: 14.07
Round  69, Train loss: 1.532, Test loss: 1.587, Test accuracy: 87.76
Round  69, Global train loss: 1.532, Global test loss: 2.254, Global test accuracy: 18.13
Round  70, Train loss: 1.534, Test loss: 1.586, Test accuracy: 87.77
Round  70, Global train loss: 1.534, Global test loss: 2.258, Global test accuracy: 18.54
Round  71, Train loss: 1.500, Test loss: 1.586, Test accuracy: 87.77
Round  71, Global train loss: 1.500, Global test loss: 2.265, Global test accuracy: 18.15
Round  72, Train loss: 1.499, Test loss: 1.586, Test accuracy: 87.78
Round  72, Global train loss: 1.499, Global test loss: 2.280, Global test accuracy: 15.50
Round  73, Train loss: 1.501, Test loss: 1.586, Test accuracy: 87.77
Round  73, Global train loss: 1.501, Global test loss: 2.250, Global test accuracy: 18.85
Round  74, Train loss: 1.566, Test loss: 1.586, Test accuracy: 87.77
Round  74, Global train loss: 1.566, Global test loss: 2.282, Global test accuracy: 16.17
Round  75, Train loss: 1.531, Test loss: 1.586, Test accuracy: 87.78
Round  75, Global train loss: 1.531, Global test loss: 2.259, Global test accuracy: 17.21
Round  76, Train loss: 1.500, Test loss: 1.586, Test accuracy: 87.77
Round  76, Global train loss: 1.500, Global test loss: 2.239, Global test accuracy: 20.33
Round  77, Train loss: 1.516, Test loss: 1.582, Test accuracy: 88.34
Round  77, Global train loss: 1.516, Global test loss: 2.283, Global test accuracy: 16.24
Round  78, Train loss: 1.535, Test loss: 1.582, Test accuracy: 88.34
Round  78, Global train loss: 1.535, Global test loss: 2.250, Global test accuracy: 18.74
Round  79, Train loss: 1.504, Test loss: 1.581, Test accuracy: 88.35
Round  79, Global train loss: 1.504, Global test loss: 2.256, Global test accuracy: 17.87
Round  80, Train loss: 1.500, Test loss: 1.581, Test accuracy: 88.36
Round  80, Global train loss: 1.500, Global test loss: 2.264, Global test accuracy: 19.17
Round  81, Train loss: 1.504, Test loss: 1.581, Test accuracy: 88.28
Round  81, Global train loss: 1.504, Global test loss: 2.259, Global test accuracy: 18.42
Round  82, Train loss: 1.472, Test loss: 1.581, Test accuracy: 88.36
Round  82, Global train loss: 1.472, Global test loss: 2.292, Global test accuracy: 14.44
Round  83, Train loss: 1.501, Test loss: 1.581, Test accuracy: 88.35
Round  83, Global train loss: 1.501, Global test loss: 2.279, Global test accuracy: 15.65
Round  84, Train loss: 1.504, Test loss: 1.581, Test accuracy: 88.35
Round  84, Global train loss: 1.504, Global test loss: 2.261, Global test accuracy: 17.66
Round  85, Train loss: 1.533, Test loss: 1.581, Test accuracy: 88.36
Round  85, Global train loss: 1.533, Global test loss: 2.246, Global test accuracy: 19.63
Round  86, Train loss: 1.500, Test loss: 1.581, Test accuracy: 88.35
Round  86, Global train loss: 1.500, Global test loss: 2.263, Global test accuracy: 17.70
Round  87, Train loss: 1.536, Test loss: 1.581, Test accuracy: 88.34
Round  87, Global train loss: 1.536, Global test loss: 2.257, Global test accuracy: 18.77
Round  88, Train loss: 1.498, Test loss: 1.581, Test accuracy: 88.36
Round  88, Global train loss: 1.498, Global test loss: 2.294, Global test accuracy: 12.90
Round  89, Train loss: 1.534, Test loss: 1.580, Test accuracy: 88.31
Round  89, Global train loss: 1.534, Global test loss: 2.284, Global test accuracy: 15.30
Round  90, Train loss: 1.502, Test loss: 1.580, Test accuracy: 88.38
Round  90, Global train loss: 1.502, Global test loss: 2.265, Global test accuracy: 17.28
Round  91, Train loss: 1.467, Test loss: 1.580, Test accuracy: 88.34
Round  91, Global train loss: 1.467, Global test loss: 2.265, Global test accuracy: 17.58
Round  92, Train loss: 1.502, Test loss: 1.580, Test accuracy: 88.36
Round  92, Global train loss: 1.502, Global test loss: 2.262, Global test accuracy: 16.34
Round  93, Train loss: 1.467, Test loss: 1.580, Test accuracy: 88.37
Round  93, Global train loss: 1.467, Global test loss: 2.287, Global test accuracy: 13.69
Round  94, Train loss: 1.466, Test loss: 1.580, Test accuracy: 88.37
Round  94, Global train loss: 1.466, Global test loss: 2.273, Global test accuracy: 16.22
Round  95, Train loss: 1.471, Test loss: 1.580, Test accuracy: 88.37
Round  95, Global train loss: 1.471, Global test loss: 2.297, Global test accuracy: 14.08/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 1.532, Test loss: 1.580, Test accuracy: 88.37
Round  96, Global train loss: 1.532, Global test loss: 2.265, Global test accuracy: 16.94
Round  97, Train loss: 1.533, Test loss: 1.580, Test accuracy: 88.36
Round  97, Global train loss: 1.533, Global test loss: 2.282, Global test accuracy: 15.80
Round  98, Train loss: 1.501, Test loss: 1.580, Test accuracy: 88.39
Round  98, Global train loss: 1.501, Global test loss: 2.260, Global test accuracy: 18.34
Round  99, Train loss: 1.531, Test loss: 1.580, Test accuracy: 88.38
Round  99, Global train loss: 1.531, Global test loss: 2.279, Global test accuracy: 16.38
Final Round, Train loss: 1.507, Test loss: 1.580, Test accuracy: 88.37
Final Round, Global train loss: 1.507, Global test loss: 2.279, Global test accuracy: 16.38
Average accuracy final 10 rounds: 88.369 

Average global accuracy final 10 rounds: 16.265 

1489.3528051376343
[1.0655808448791504, 2.131161689758301, 3.096579074859619, 4.0619964599609375, 5.057861328125, 6.0537261962890625, 7.019923448562622, 7.986120700836182, 8.974021673202515, 9.961922645568848, 11.135384798049927, 12.308846950531006, 13.290651559829712, 14.272456169128418, 15.243741273880005, 16.215026378631592, 17.116905450820923, 18.018784523010254, 19.00097942352295, 19.983174324035645, 21.031132698059082, 22.07909107208252, 23.30627965927124, 24.53346824645996, 25.521884202957153, 26.510300159454346, 27.43791699409485, 28.36553382873535, 29.38682460784912, 30.40811538696289, 31.374773025512695, 32.3414306640625, 33.34970307350159, 34.357975482940674, 35.36626863479614, 36.37456178665161, 37.5576696395874, 38.74077749252319, 39.80304741859436, 40.86531734466553, 41.874921798706055, 42.88452625274658, 44.01403737068176, 45.14354848861694, 46.06937098503113, 46.99519348144531, 48.004475355148315, 49.01375722885132, 50.03535795211792, 51.05695867538452, 52.30174946784973, 53.54654026031494, 54.521902322769165, 55.49726438522339, 56.48393440246582, 57.47060441970825, 58.483980655670166, 59.49735689163208, 60.40718650817871, 61.31701612472534, 62.2502646446228, 63.183513164520264, 64.06053304672241, 64.93755292892456, 65.84622883796692, 66.75490474700928, 67.6586229801178, 68.56234121322632, 69.45560002326965, 70.34885883331299, 71.2250828742981, 72.1013069152832, 73.01076579093933, 73.92022466659546, 74.83112978935242, 75.74203491210938, 76.64885401725769, 77.555673122406, 78.47744941711426, 79.39922571182251, 80.30710744857788, 81.21498918533325, 82.11381483078003, 83.0126404762268, 83.88095569610596, 84.74927091598511, 85.69165897369385, 86.63404703140259, 87.57041525840759, 88.5067834854126, 89.39616870880127, 90.28555393218994, 91.16471314430237, 92.0438723564148, 92.9138457775116, 93.7838191986084, 94.63102102279663, 95.47822284698486, 96.36951756477356, 97.26081228256226, 98.09182405471802, 98.92283582687378, 99.78847289085388, 100.65410995483398, 101.53881883621216, 102.42352771759033, 103.33667516708374, 104.24982261657715, 105.15565013885498, 106.06147766113281, 106.9104573726654, 107.759437084198, 108.72034335136414, 109.68124961853027, 110.60521292686462, 111.52917623519897, 112.45504832267761, 113.38092041015625, 114.28180718421936, 115.18269395828247, 116.06502676010132, 116.94735956192017, 117.95781064033508, 118.96826171875, 119.90654921531677, 120.84483671188354, 121.69053101539612, 122.53622531890869, 123.41472935676575, 124.2932333946228, 125.24757313728333, 126.20191287994385, 127.09696841239929, 127.99202394485474, 128.87436389923096, 129.75670385360718, 130.66079473495483, 131.5648856163025, 132.4567096233368, 133.3485336303711, 134.263352394104, 135.1781711578369, 136.11271905899048, 137.04726696014404, 137.97944569587708, 138.9116244316101, 139.76093792915344, 140.61025142669678, 141.46428418159485, 142.31831693649292, 143.27309155464172, 144.22786617279053, 145.21272778511047, 146.19758939743042, 147.08828687667847, 147.9789843559265, 148.88967442512512, 149.80036449432373, 150.6511414051056, 151.50191831588745, 152.38354992866516, 153.26518154144287, 154.16418528556824, 155.0631890296936, 156.00024843215942, 156.93730783462524, 157.85678911209106, 158.77627038955688, 159.68651604652405, 160.5967617034912, 161.4754514694214, 162.35414123535156, 163.22677063941956, 164.09940004348755, 164.9830198287964, 165.86663961410522, 166.83765769004822, 167.8086757659912, 168.73361587524414, 169.65855598449707, 170.55926847457886, 171.45998096466064, 172.30998253822327, 173.1599841117859, 174.00564408302307, 174.85130405426025, 175.74609303474426, 176.64088201522827, 177.49841117858887, 178.35594034194946, 179.17761611938477, 179.99929189682007, 180.84111213684082, 181.68293237686157, 182.50792169570923, 183.33291101455688, 184.15780687332153, 184.98270273208618, 185.8782033920288, 186.77370405197144, 188.513676404953, 190.25364875793457]
[15.96, 15.96, 22.5, 22.5, 33.88, 33.88, 44.47, 44.47, 50.22, 50.22, 59.34, 59.34, 61.35, 61.35, 66.5, 66.5, 71.47, 71.47, 71.82, 71.82, 76.3, 76.3, 76.48, 76.48, 77.31, 77.31, 79.25, 79.25, 79.24, 79.24, 81.01, 81.01, 81.14, 81.14, 82.24, 82.24, 82.3, 82.3, 82.41, 82.41, 82.55, 82.55, 83.39, 83.39, 84.4, 84.4, 84.64, 84.64, 84.65, 84.65, 84.94, 84.94, 84.97, 84.97, 84.98, 84.98, 85.76, 85.76, 85.8, 85.8, 85.81, 85.81, 86.58, 86.58, 86.67, 86.67, 86.78, 86.78, 86.77, 86.77, 86.75, 86.75, 86.71, 86.71, 86.75, 86.75, 86.83, 86.83, 86.84, 86.84, 86.84, 86.84, 86.84, 86.84, 87.6, 87.6, 87.64, 87.64, 87.65, 87.65, 87.63, 87.63, 87.67, 87.67, 87.66, 87.66, 87.71, 87.71, 87.75, 87.75, 87.74, 87.74, 87.76, 87.76, 87.78, 87.78, 87.79, 87.79, 87.82, 87.82, 87.84, 87.84, 87.78, 87.78, 87.83, 87.83, 87.8, 87.8, 87.84, 87.84, 87.77, 87.77, 87.76, 87.76, 87.72, 87.72, 87.77, 87.77, 87.8, 87.8, 87.81, 87.81, 87.82, 87.82, 87.82, 87.82, 87.79, 87.79, 87.76, 87.76, 87.77, 87.77, 87.77, 87.77, 87.78, 87.78, 87.77, 87.77, 87.77, 87.77, 87.78, 87.78, 87.77, 87.77, 88.34, 88.34, 88.34, 88.34, 88.35, 88.35, 88.36, 88.36, 88.28, 88.28, 88.36, 88.36, 88.35, 88.35, 88.35, 88.35, 88.36, 88.36, 88.35, 88.35, 88.34, 88.34, 88.36, 88.36, 88.31, 88.31, 88.38, 88.38, 88.34, 88.34, 88.36, 88.36, 88.37, 88.37, 88.37, 88.37, 88.37, 88.37, 88.37, 88.37, 88.36, 88.36, 88.39, 88.39, 88.38, 88.38, 88.37, 88.37]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.288, Test loss: 2.289, Test accuracy: 21.40
Round   0, Global train loss: 2.288, Global test loss: 2.297, Global test accuracy: 15.08
Round   1, Train loss: 2.251, Test loss: 2.246, Test accuracy: 22.79
Round   1, Global train loss: 2.251, Global test loss: 2.284, Global test accuracy: 14.83
Round   2, Train loss: 2.129, Test loss: 2.175, Test accuracy: 31.30
Round   2, Global train loss: 2.129, Global test loss: 2.277, Global test accuracy: 14.98
Round   3, Train loss: 2.034, Test loss: 2.101, Test accuracy: 37.59
Round   3, Global train loss: 2.034, Global test loss: 2.274, Global test accuracy: 16.13
Round   4, Train loss: 1.954, Test loss: 2.023, Test accuracy: 45.47
Round   4, Global train loss: 1.954, Global test loss: 2.254, Global test accuracy: 17.80
Round   5, Train loss: 1.863, Test loss: 1.935, Test accuracy: 54.70
Round   5, Global train loss: 1.863, Global test loss: 2.227, Global test accuracy: 22.13
Round   6, Train loss: 1.767, Test loss: 1.880, Test accuracy: 60.28
Round   6, Global train loss: 1.767, Global test loss: 2.233, Global test accuracy: 21.01
Round   7, Train loss: 1.778, Test loss: 1.852, Test accuracy: 62.90
Round   7, Global train loss: 1.778, Global test loss: 2.230, Global test accuracy: 21.48
Round   8, Train loss: 1.852, Test loss: 1.877, Test accuracy: 59.71
Round   8, Global train loss: 1.852, Global test loss: 2.223, Global test accuracy: 22.16
Round   9, Train loss: 1.874, Test loss: 1.863, Test accuracy: 61.22
Round   9, Global train loss: 1.874, Global test loss: 2.220, Global test accuracy: 22.76
Round  10, Train loss: 1.749, Test loss: 1.866, Test accuracy: 60.94
Round  10, Global train loss: 1.749, Global test loss: 2.224, Global test accuracy: 22.25
Round  11, Train loss: 1.776, Test loss: 1.843, Test accuracy: 63.30
Round  11, Global train loss: 1.776, Global test loss: 2.218, Global test accuracy: 22.65
Round  12, Train loss: 1.977, Test loss: 1.844, Test accuracy: 62.90
Round  12, Global train loss: 1.977, Global test loss: 2.244, Global test accuracy: 19.96
Round  13, Train loss: 1.737, Test loss: 1.836, Test accuracy: 63.34
Round  13, Global train loss: 1.737, Global test loss: 2.209, Global test accuracy: 23.55
Round  14, Train loss: 1.841, Test loss: 1.810, Test accuracy: 66.09
Round  14, Global train loss: 1.841, Global test loss: 2.221, Global test accuracy: 22.22
Round  15, Train loss: 1.901, Test loss: 1.824, Test accuracy: 64.42
Round  15, Global train loss: 1.901, Global test loss: 2.245, Global test accuracy: 20.02
Round  16, Train loss: 1.878, Test loss: 1.843, Test accuracy: 61.90
Round  16, Global train loss: 1.878, Global test loss: 2.218, Global test accuracy: 22.46
Round  17, Train loss: 1.873, Test loss: 1.843, Test accuracy: 61.95
Round  17, Global train loss: 1.873, Global test loss: 2.239, Global test accuracy: 20.49
Round  18, Train loss: 1.877, Test loss: 1.834, Test accuracy: 62.91
Round  18, Global train loss: 1.877, Global test loss: 2.234, Global test accuracy: 21.09
Round  19, Train loss: 1.919, Test loss: 1.833, Test accuracy: 63.00
Round  19, Global train loss: 1.919, Global test loss: 2.232, Global test accuracy: 20.88
Round  20, Train loss: 1.767, Test loss: 1.825, Test accuracy: 63.67
Round  20, Global train loss: 1.767, Global test loss: 2.226, Global test accuracy: 22.66
Round  21, Train loss: 1.826, Test loss: 1.836, Test accuracy: 62.51
Round  21, Global train loss: 1.826, Global test loss: 2.211, Global test accuracy: 23.60
Round  22, Train loss: 1.879, Test loss: 1.835, Test accuracy: 62.55
Round  22, Global train loss: 1.879, Global test loss: 2.214, Global test accuracy: 23.35
Round  23, Train loss: 1.803, Test loss: 1.827, Test accuracy: 63.32
Round  23, Global train loss: 1.803, Global test loss: 2.211, Global test accuracy: 22.94
Round  24, Train loss: 1.856, Test loss: 1.827, Test accuracy: 63.39
Round  24, Global train loss: 1.856, Global test loss: 2.229, Global test accuracy: 21.64
Round  25, Train loss: 1.894, Test loss: 1.825, Test accuracy: 63.44
Round  25, Global train loss: 1.894, Global test loss: 2.234, Global test accuracy: 21.32
Round  26, Train loss: 1.738, Test loss: 1.825, Test accuracy: 63.45
Round  26, Global train loss: 1.738, Global test loss: 2.229, Global test accuracy: 21.92
Round  27, Train loss: 1.777, Test loss: 1.834, Test accuracy: 62.55
Round  27, Global train loss: 1.777, Global test loss: 2.206, Global test accuracy: 24.19
Round  28, Train loss: 1.855, Test loss: 1.835, Test accuracy: 62.44
Round  28, Global train loss: 1.855, Global test loss: 2.206, Global test accuracy: 24.13
Round  29, Train loss: 1.784, Test loss: 1.823, Test accuracy: 63.73
Round  29, Global train loss: 1.784, Global test loss: 2.200, Global test accuracy: 25.00
Round  30, Train loss: 1.718, Test loss: 1.814, Test accuracy: 64.66
Round  30, Global train loss: 1.718, Global test loss: 2.216, Global test accuracy: 22.67
Round  31, Train loss: 1.856, Test loss: 1.814, Test accuracy: 64.63
Round  31, Global train loss: 1.856, Global test loss: 2.207, Global test accuracy: 23.98
Round  32, Train loss: 1.757, Test loss: 1.814, Test accuracy: 64.74
Round  32, Global train loss: 1.757, Global test loss: 2.218, Global test accuracy: 22.34
Round  33, Train loss: 1.894, Test loss: 1.812, Test accuracy: 64.86
Round  33, Global train loss: 1.894, Global test loss: 2.232, Global test accuracy: 21.00
Round  34, Train loss: 1.704, Test loss: 1.812, Test accuracy: 64.80
Round  34, Global train loss: 1.704, Global test loss: 2.229, Global test accuracy: 22.30
Round  35, Train loss: 1.713, Test loss: 1.806, Test accuracy: 65.49
Round  35, Global train loss: 1.713, Global test loss: 2.202, Global test accuracy: 24.66
Round  36, Train loss: 1.820, Test loss: 1.805, Test accuracy: 65.50
Round  36, Global train loss: 1.820, Global test loss: 2.216, Global test accuracy: 23.00
Round  37, Train loss: 1.740, Test loss: 1.805, Test accuracy: 65.60
Round  37, Global train loss: 1.740, Global test loss: 2.205, Global test accuracy: 24.10
Round  38, Train loss: 1.830, Test loss: 1.805, Test accuracy: 65.56
Round  38, Global train loss: 1.830, Global test loss: 2.215, Global test accuracy: 23.07
Round  39, Train loss: 1.879, Test loss: 1.809, Test accuracy: 65.26
Round  39, Global train loss: 1.879, Global test loss: 2.207, Global test accuracy: 23.94
Round  40, Train loss: 1.868, Test loss: 1.805, Test accuracy: 65.52
Round  40, Global train loss: 1.868, Global test loss: 2.214, Global test accuracy: 23.48
Round  41, Train loss: 1.860, Test loss: 1.806, Test accuracy: 65.35
Round  41, Global train loss: 1.860, Global test loss: 2.224, Global test accuracy: 22.27
Round  42, Train loss: 1.732, Test loss: 1.796, Test accuracy: 66.41
Round  42, Global train loss: 1.732, Global test loss: 2.220, Global test accuracy: 22.63
Round  43, Train loss: 1.729, Test loss: 1.796, Test accuracy: 66.37
Round  43, Global train loss: 1.729, Global test loss: 2.213, Global test accuracy: 23.92
Round  44, Train loss: 1.671, Test loss: 1.797, Test accuracy: 66.28
Round  44, Global train loss: 1.671, Global test loss: 2.207, Global test accuracy: 23.83
Round  45, Train loss: 1.759, Test loss: 1.796, Test accuracy: 66.47
Round  45, Global train loss: 1.759, Global test loss: 2.202, Global test accuracy: 24.44
Round  46, Train loss: 1.698, Test loss: 1.796, Test accuracy: 66.49
Round  46, Global train loss: 1.698, Global test loss: 2.208, Global test accuracy: 23.93
Round  47, Train loss: 1.832, Test loss: 1.812, Test accuracy: 64.77
Round  47, Global train loss: 1.832, Global test loss: 2.205, Global test accuracy: 24.61
Round  48, Train loss: 1.727, Test loss: 1.811, Test accuracy: 64.80
Round  48, Global train loss: 1.727, Global test loss: 2.212, Global test accuracy: 23.42
Round  49, Train loss: 1.733, Test loss: 1.803, Test accuracy: 65.73
Round  49, Global train loss: 1.733, Global test loss: 2.209, Global test accuracy: 23.39
Round  50, Train loss: 1.748, Test loss: 1.794, Test accuracy: 66.65
Round  50, Global train loss: 1.748, Global test loss: 2.214, Global test accuracy: 23.14
Round  51, Train loss: 1.785, Test loss: 1.794, Test accuracy: 66.65
Round  51, Global train loss: 1.785, Global test loss: 2.215, Global test accuracy: 23.05
Round  52, Train loss: 1.819, Test loss: 1.794, Test accuracy: 66.66
Round  52, Global train loss: 1.819, Global test loss: 2.205, Global test accuracy: 24.31
Round  53, Train loss: 1.647, Test loss: 1.794, Test accuracy: 66.68
Round  53, Global train loss: 1.647, Global test loss: 2.197, Global test accuracy: 24.87
Round  54, Train loss: 1.820, Test loss: 1.786, Test accuracy: 67.48
Round  54, Global train loss: 1.820, Global test loss: 2.204, Global test accuracy: 24.13
Round  55, Train loss: 1.745, Test loss: 1.786, Test accuracy: 67.52
Round  55, Global train loss: 1.745, Global test loss: 2.197, Global test accuracy: 25.16
Round  56, Train loss: 1.876, Test loss: 1.794, Test accuracy: 66.60
Round  56, Global train loss: 1.876, Global test loss: 2.208, Global test accuracy: 24.24
Round  57, Train loss: 1.721, Test loss: 1.793, Test accuracy: 66.70
Round  57, Global train loss: 1.721, Global test loss: 2.209, Global test accuracy: 23.81
Round  58, Train loss: 1.765, Test loss: 1.794, Test accuracy: 66.65
Round  58, Global train loss: 1.765, Global test loss: 2.202, Global test accuracy: 24.76
Round  59, Train loss: 1.692, Test loss: 1.793, Test accuracy: 66.68
Round  59, Global train loss: 1.692, Global test loss: 2.204, Global test accuracy: 24.37
Round  60, Train loss: 1.719, Test loss: 1.792, Test accuracy: 66.76
Round  60, Global train loss: 1.719, Global test loss: 2.206, Global test accuracy: 24.28
Round  61, Train loss: 1.827, Test loss: 1.784, Test accuracy: 67.66
Round  61, Global train loss: 1.827, Global test loss: 2.209, Global test accuracy: 23.63
Round  62, Train loss: 1.750, Test loss: 1.784, Test accuracy: 67.71
Round  62, Global train loss: 1.750, Global test loss: 2.208, Global test accuracy: 23.76
Round  63, Train loss: 1.745, Test loss: 1.784, Test accuracy: 67.59
Round  63, Global train loss: 1.745, Global test loss: 2.197, Global test accuracy: 25.13
Round  64, Train loss: 1.824, Test loss: 1.786, Test accuracy: 67.41
Round  64, Global train loss: 1.824, Global test loss: 2.209, Global test accuracy: 23.96
Round  65, Train loss: 1.811, Test loss: 1.786, Test accuracy: 67.44
Round  65, Global train loss: 1.811, Global test loss: 2.200, Global test accuracy: 24.77
Round  66, Train loss: 1.874, Test loss: 1.786, Test accuracy: 67.36
Round  66, Global train loss: 1.874, Global test loss: 2.211, Global test accuracy: 23.82
Round  67, Train loss: 1.714, Test loss: 1.786, Test accuracy: 67.32
Round  67, Global train loss: 1.714, Global test loss: 2.201, Global test accuracy: 24.52
Round  68, Train loss: 1.715, Test loss: 1.787, Test accuracy: 67.28
Round  68, Global train loss: 1.715, Global test loss: 2.214, Global test accuracy: 23.35
Round  69, Train loss: 1.762, Test loss: 1.785, Test accuracy: 67.42
Round  69, Global train loss: 1.762, Global test loss: 2.211, Global test accuracy: 23.11
Round  70, Train loss: 1.803, Test loss: 1.783, Test accuracy: 67.64
Round  70, Global train loss: 1.803, Global test loss: 2.232, Global test accuracy: 20.65
Round  71, Train loss: 1.863, Test loss: 1.783, Test accuracy: 67.70
Round  71, Global train loss: 1.863, Global test loss: 2.222, Global test accuracy: 21.94
Round  72, Train loss: 1.650, Test loss: 1.783, Test accuracy: 67.63
Round  72, Global train loss: 1.650, Global test loss: 2.205, Global test accuracy: 24.35
Round  73, Train loss: 1.686, Test loss: 1.782, Test accuracy: 67.66
Round  73, Global train loss: 1.686, Global test loss: 2.210, Global test accuracy: 23.93
Round  74, Train loss: 1.719, Test loss: 1.781, Test accuracy: 67.73
Round  74, Global train loss: 1.719, Global test loss: 2.225, Global test accuracy: 21.67
Round  75, Train loss: 1.825, Test loss: 1.774, Test accuracy: 68.50
Round  75, Global train loss: 1.825, Global test loss: 2.221, Global test accuracy: 22.44
Round  76, Train loss: 1.698, Test loss: 1.774, Test accuracy: 68.55
Round  76, Global train loss: 1.698, Global test loss: 2.215, Global test accuracy: 22.71
Round  77, Train loss: 1.754, Test loss: 1.773, Test accuracy: 68.70
Round  77, Global train loss: 1.754, Global test loss: 2.211, Global test accuracy: 23.50
Round  78, Train loss: 1.660, Test loss: 1.773, Test accuracy: 68.73
Round  78, Global train loss: 1.660, Global test loss: 2.201, Global test accuracy: 24.76
Round  79, Train loss: 1.819, Test loss: 1.773, Test accuracy: 68.76
Round  79, Global train loss: 1.819, Global test loss: 2.216, Global test accuracy: 22.74
Round  80, Train loss: 1.838, Test loss: 1.774, Test accuracy: 68.61
Round  80, Global train loss: 1.838, Global test loss: 2.222, Global test accuracy: 21.93
Round  81, Train loss: 1.812, Test loss: 1.773, Test accuracy: 68.61
Round  81, Global train loss: 1.812, Global test loss: 2.217, Global test accuracy: 22.85
Round  82, Train loss: 1.732, Test loss: 1.766, Test accuracy: 69.33
Round  82, Global train loss: 1.732, Global test loss: 2.198, Global test accuracy: 25.20
Round  83, Train loss: 1.741, Test loss: 1.765, Test accuracy: 69.35
Round  83, Global train loss: 1.741, Global test loss: 2.204, Global test accuracy: 24.44
Round  84, Train loss: 1.833, Test loss: 1.766, Test accuracy: 69.35
Round  84, Global train loss: 1.833, Global test loss: 2.211, Global test accuracy: 23.29
Round  85, Train loss: 1.652, Test loss: 1.765, Test accuracy: 69.38
Round  85, Global train loss: 1.652, Global test loss: 2.197, Global test accuracy: 25.29
Round  86, Train loss: 1.613, Test loss: 1.765, Test accuracy: 69.27
Round  86, Global train loss: 1.613, Global test loss: 2.194, Global test accuracy: 25.26
Round  87, Train loss: 1.680, Test loss: 1.765, Test accuracy: 69.19
Round  87, Global train loss: 1.680, Global test loss: 2.193, Global test accuracy: 25.58
Round  88, Train loss: 1.773, Test loss: 1.763, Test accuracy: 69.43
Round  88, Global train loss: 1.773, Global test loss: 2.217, Global test accuracy: 22.93
Round  89, Train loss: 1.890, Test loss: 1.756, Test accuracy: 70.17
Round  89, Global train loss: 1.890, Global test loss: 2.207, Global test accuracy: 24.01
Round  90, Train loss: 1.689, Test loss: 1.756, Test accuracy: 70.28
Round  90, Global train loss: 1.689, Global test loss: 2.194, Global test accuracy: 25.77
Round  91, Train loss: 1.716, Test loss: 1.756, Test accuracy: 70.33
Round  91, Global train loss: 1.716, Global test loss: 2.201, Global test accuracy: 25.10
Round  92, Train loss: 1.715, Test loss: 1.763, Test accuracy: 69.63
Round  92, Global train loss: 1.715, Global test loss: 2.201, Global test accuracy: 25.17
Round  93, Train loss: 1.796, Test loss: 1.763, Test accuracy: 69.54
Round  93, Global train loss: 1.796, Global test loss: 2.193, Global test accuracy: 25.86
Round  94, Train loss: 1.900, Test loss: 1.771, Test accuracy: 68.76
Round  94, Global train loss: 1.900, Global test loss: 2.212, Global test accuracy: 23.26
Round  95, Train loss: 1.763, Test loss: 1.763, Test accuracy: 69.53
Round  95, Global train loss: 1.763, Global test loss: 2.209, Global test accuracy: 24.04/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 1.673, Test loss: 1.763, Test accuracy: 69.58
Round  96, Global train loss: 1.673, Global test loss: 2.198, Global test accuracy: 25.24
Round  97, Train loss: 1.720, Test loss: 1.763, Test accuracy: 69.59
Round  97, Global train loss: 1.720, Global test loss: 2.205, Global test accuracy: 24.15
Round  98, Train loss: 1.648, Test loss: 1.764, Test accuracy: 69.52
Round  98, Global train loss: 1.648, Global test loss: 2.190, Global test accuracy: 25.70
Round  99, Train loss: 1.771, Test loss: 1.763, Test accuracy: 69.66
Round  99, Global train loss: 1.771, Global test loss: 2.215, Global test accuracy: 22.66
Final Round, Train loss: 1.722, Test loss: 1.752, Test accuracy: 70.64
Final Round, Global train loss: 1.722, Global test loss: 2.215, Global test accuracy: 22.66
Average accuracy final 10 rounds: 69.642 

Average global accuracy final 10 rounds: 24.695 

1448.4386458396912
[1.103917121887207, 2.207834243774414, 3.211329936981201, 4.214825630187988, 5.2456278800964355, 6.276430130004883, 7.263145685195923, 8.249861240386963, 9.255244255065918, 10.260627269744873, 11.279393434524536, 12.2981595993042, 13.273556232452393, 14.248952865600586, 15.259380578994751, 16.269808292388916, 17.22294282913208, 18.176077365875244, 19.170262098312378, 20.16444683074951, 21.183310985565186, 22.20217514038086, 23.20422649383545, 24.20627784729004, 25.196757316589355, 26.187236785888672, 27.176889181137085, 28.166541576385498, 29.1417555809021, 30.1169695854187, 31.10642647743225, 32.0958833694458, 32.91722393035889, 33.73856449127197, 34.668351888656616, 35.59813928604126, 36.481624126434326, 37.36510896682739, 38.23368811607361, 39.102267265319824, 39.993828535079956, 40.88538980484009, 41.734490394592285, 42.58359098434448, 43.46497344970703, 44.34635591506958, 45.20957612991333, 46.07279634475708, 46.922975063323975, 47.77315378189087, 48.61794996261597, 49.462746143341064, 50.37505769729614, 51.28736925125122, 52.243271589279175, 53.19917392730713, 54.050350189208984, 54.90152645111084, 55.77948212623596, 56.657437801361084, 57.4959819316864, 58.33452606201172, 59.16704773902893, 59.99956941604614, 60.865004777908325, 61.73044013977051, 62.656524658203125, 63.58260917663574, 64.47940468788147, 65.3762001991272, 66.24516582489014, 67.11413145065308, 68.000981092453, 68.88783073425293, 69.73784852027893, 70.58786630630493, 71.46566963195801, 72.34347295761108, 73.28551292419434, 74.22755289077759, 75.1375105381012, 76.0474681854248, 76.93373537063599, 77.82000255584717, 78.72717428207397, 79.63434600830078, 80.49931025505066, 81.36427450180054, 82.22278451919556, 83.08129453659058, 83.94098210334778, 84.80066967010498, 85.63691759109497, 86.47316551208496, 87.35380625724792, 88.23444700241089, 89.09208250045776, 89.94971799850464, 90.80811262130737, 91.66650724411011, 92.53839373588562, 93.41028022766113, 94.24676132202148, 95.08324241638184, 95.96303963661194, 96.84283685684204, 97.72167801856995, 98.60051918029785, 99.46456146240234, 100.32860374450684, 101.19394779205322, 102.05929183959961, 102.94656419754028, 103.83383655548096, 104.77131414413452, 105.70879173278809, 106.58143138885498, 107.45407104492188, 108.34885883331299, 109.2436466217041, 110.09987616539001, 110.95610570907593, 111.81811690330505, 112.68012809753418, 113.64745926856995, 114.61479043960571, 115.45838236808777, 116.30197429656982, 117.17837953567505, 118.05478477478027, 118.9089024066925, 119.76302003860474, 120.5896418094635, 121.41626358032227, 122.26496171951294, 123.11365985870361, 123.94913148880005, 124.78460311889648, 125.60253119468689, 126.4204592704773, 127.38312196731567, 128.34578466415405, 129.30813097953796, 130.27047729492188, 131.17751479148865, 132.08455228805542, 132.97347116470337, 133.86239004135132, 134.67833876609802, 135.49428749084473, 136.27624821662903, 137.05820894241333, 137.8939917087555, 138.72977447509766, 139.5526638031006, 140.37555313110352, 141.21463537216187, 142.05371761322021, 142.91394519805908, 143.77417278289795, 144.60988998413086, 145.44560718536377, 146.31312155723572, 147.18063592910767, 148.04832243919373, 148.91600894927979, 149.74274587631226, 150.56948280334473, 151.40547060966492, 152.2414584159851, 153.10852193832397, 153.97558546066284, 154.81038618087769, 155.64518690109253, 156.4713089466095, 157.29743099212646, 158.11725687980652, 158.93708276748657, 159.75487446784973, 160.5726661682129, 161.42483019828796, 162.27699422836304, 163.10082983970642, 163.9246654510498, 164.78169798851013, 165.63873052597046, 166.4910707473755, 167.34341096878052, 168.1523678302765, 168.96132469177246, 169.80576848983765, 170.65021228790283, 171.48868227005005, 172.32715225219727, 173.13192439079285, 173.93669652938843, 174.76163625717163, 175.58657598495483, 176.4271981716156, 177.26782035827637, 179.00578260421753, 180.7437448501587]
[21.4, 21.4, 22.79, 22.79, 31.3, 31.3, 37.59, 37.59, 45.47, 45.47, 54.7, 54.7, 60.28, 60.28, 62.9, 62.9, 59.71, 59.71, 61.22, 61.22, 60.94, 60.94, 63.3, 63.3, 62.9, 62.9, 63.34, 63.34, 66.09, 66.09, 64.42, 64.42, 61.9, 61.9, 61.95, 61.95, 62.91, 62.91, 63.0, 63.0, 63.67, 63.67, 62.51, 62.51, 62.55, 62.55, 63.32, 63.32, 63.39, 63.39, 63.44, 63.44, 63.45, 63.45, 62.55, 62.55, 62.44, 62.44, 63.73, 63.73, 64.66, 64.66, 64.63, 64.63, 64.74, 64.74, 64.86, 64.86, 64.8, 64.8, 65.49, 65.49, 65.5, 65.5, 65.6, 65.6, 65.56, 65.56, 65.26, 65.26, 65.52, 65.52, 65.35, 65.35, 66.41, 66.41, 66.37, 66.37, 66.28, 66.28, 66.47, 66.47, 66.49, 66.49, 64.77, 64.77, 64.8, 64.8, 65.73, 65.73, 66.65, 66.65, 66.65, 66.65, 66.66, 66.66, 66.68, 66.68, 67.48, 67.48, 67.52, 67.52, 66.6, 66.6, 66.7, 66.7, 66.65, 66.65, 66.68, 66.68, 66.76, 66.76, 67.66, 67.66, 67.71, 67.71, 67.59, 67.59, 67.41, 67.41, 67.44, 67.44, 67.36, 67.36, 67.32, 67.32, 67.28, 67.28, 67.42, 67.42, 67.64, 67.64, 67.7, 67.7, 67.63, 67.63, 67.66, 67.66, 67.73, 67.73, 68.5, 68.5, 68.55, 68.55, 68.7, 68.7, 68.73, 68.73, 68.76, 68.76, 68.61, 68.61, 68.61, 68.61, 69.33, 69.33, 69.35, 69.35, 69.35, 69.35, 69.38, 69.38, 69.27, 69.27, 69.19, 69.19, 69.43, 69.43, 70.17, 70.17, 70.28, 70.28, 70.33, 70.33, 69.63, 69.63, 69.54, 69.54, 68.76, 68.76, 69.53, 69.53, 69.58, 69.58, 69.59, 69.59, 69.52, 69.52, 69.66, 69.66, 70.64, 70.64]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.299, Test loss: 2.303, Test accuracy: 11.88
Round   1, Train loss: 2.296, Test loss: 2.301, Test accuracy: 15.65
Round   2, Train loss: 2.293, Test loss: 2.299, Test accuracy: 15.01
Round   3, Train loss: 2.280, Test loss: 2.291, Test accuracy: 15.24
Round   4, Train loss: 2.241, Test loss: 2.269, Test accuracy: 18.61
Round   5, Train loss: 2.214, Test loss: 2.244, Test accuracy: 19.90
Round   6, Train loss: 2.164, Test loss: 2.221, Test accuracy: 22.30
Round   7, Train loss: 2.107, Test loss: 2.176, Test accuracy: 28.29
Round   8, Train loss: 2.043, Test loss: 2.124, Test accuracy: 34.37
Round   9, Train loss: 1.973, Test loss: 2.086, Test accuracy: 38.08
Round  10, Train loss: 1.915, Test loss: 2.019, Test accuracy: 44.44
Round  11, Train loss: 1.913, Test loss: 1.979, Test accuracy: 49.64
Round  12, Train loss: 1.835, Test loss: 1.942, Test accuracy: 53.12
Round  13, Train loss: 1.790, Test loss: 1.919, Test accuracy: 55.27
Round  14, Train loss: 1.831, Test loss: 1.890, Test accuracy: 58.39
Round  15, Train loss: 1.748, Test loss: 1.871, Test accuracy: 59.92
Round  16, Train loss: 1.869, Test loss: 1.838, Test accuracy: 63.56
Round  17, Train loss: 1.792, Test loss: 1.824, Test accuracy: 64.96
Round  18, Train loss: 1.710, Test loss: 1.809, Test accuracy: 66.71
Round  19, Train loss: 1.821, Test loss: 1.807, Test accuracy: 66.68
Round  20, Train loss: 1.709, Test loss: 1.795, Test accuracy: 67.82
Round  21, Train loss: 1.774, Test loss: 1.795, Test accuracy: 67.78
Round  22, Train loss: 1.803, Test loss: 1.788, Test accuracy: 68.34
Round  23, Train loss: 1.778, Test loss: 1.787, Test accuracy: 68.38
Round  24, Train loss: 1.783, Test loss: 1.783, Test accuracy: 68.74
Round  25, Train loss: 1.709, Test loss: 1.773, Test accuracy: 69.56
Round  26, Train loss: 1.741, Test loss: 1.775, Test accuracy: 69.36
Round  27, Train loss: 1.710, Test loss: 1.771, Test accuracy: 69.73
Round  28, Train loss: 1.771, Test loss: 1.767, Test accuracy: 70.20
Round  29, Train loss: 1.741, Test loss: 1.765, Test accuracy: 70.23
Round  30, Train loss: 1.791, Test loss: 1.765, Test accuracy: 70.32
Round  31, Train loss: 1.711, Test loss: 1.760, Test accuracy: 70.72
Round  32, Train loss: 1.764, Test loss: 1.758, Test accuracy: 71.00
Round  33, Train loss: 1.771, Test loss: 1.758, Test accuracy: 70.82
Round  34, Train loss: 1.786, Test loss: 1.758, Test accuracy: 70.81
Round  35, Train loss: 1.666, Test loss: 1.755, Test accuracy: 71.16
Round  36, Train loss: 1.677, Test loss: 1.754, Test accuracy: 71.23
Round  37, Train loss: 1.661, Test loss: 1.754, Test accuracy: 71.31
Round  38, Train loss: 1.765, Test loss: 1.753, Test accuracy: 71.32
Round  39, Train loss: 1.784, Test loss: 1.753, Test accuracy: 71.24
Round  40, Train loss: 1.671, Test loss: 1.751, Test accuracy: 71.46
Round  41, Train loss: 1.719, Test loss: 1.749, Test accuracy: 71.53
Round  42, Train loss: 1.713, Test loss: 1.748, Test accuracy: 71.76
Round  43, Train loss: 1.732, Test loss: 1.745, Test accuracy: 72.04
Round  44, Train loss: 1.633, Test loss: 1.740, Test accuracy: 72.67
Round  45, Train loss: 1.667, Test loss: 1.738, Test accuracy: 72.68
Round  46, Train loss: 1.733, Test loss: 1.737, Test accuracy: 72.64
Round  47, Train loss: 1.667, Test loss: 1.737, Test accuracy: 72.69
Round  48, Train loss: 1.690, Test loss: 1.736, Test accuracy: 72.87
Round  49, Train loss: 1.741, Test loss: 1.735, Test accuracy: 73.00
Round  50, Train loss: 1.656, Test loss: 1.734, Test accuracy: 73.10
Round  51, Train loss: 1.686, Test loss: 1.733, Test accuracy: 73.05
Round  52, Train loss: 1.686, Test loss: 1.734, Test accuracy: 73.02
Round  53, Train loss: 1.718, Test loss: 1.734, Test accuracy: 73.06
Round  54, Train loss: 1.694, Test loss: 1.727, Test accuracy: 73.91
Round  55, Train loss: 1.661, Test loss: 1.726, Test accuracy: 73.92
Round  56, Train loss: 1.739, Test loss: 1.726, Test accuracy: 73.92
Round  57, Train loss: 1.684, Test loss: 1.724, Test accuracy: 74.03
Round  58, Train loss: 1.716, Test loss: 1.724, Test accuracy: 73.93
Round  59, Train loss: 1.714, Test loss: 1.724, Test accuracy: 73.84
Round  60, Train loss: 1.715, Test loss: 1.724, Test accuracy: 74.01
Round  61, Train loss: 1.720, Test loss: 1.724, Test accuracy: 74.05
Round  62, Train loss: 1.652, Test loss: 1.723, Test accuracy: 74.00
Round  63, Train loss: 1.742, Test loss: 1.723, Test accuracy: 74.03
Round  64, Train loss: 1.711, Test loss: 1.722, Test accuracy: 74.04
Round  65, Train loss: 1.676, Test loss: 1.722, Test accuracy: 74.21
Round  66, Train loss: 1.772, Test loss: 1.722, Test accuracy: 74.22
Round  67, Train loss: 1.685, Test loss: 1.721, Test accuracy: 74.16
Round  68, Train loss: 1.741, Test loss: 1.722, Test accuracy: 74.08
Round  69, Train loss: 1.741, Test loss: 1.721, Test accuracy: 74.11
Round  70, Train loss: 1.648, Test loss: 1.721, Test accuracy: 74.16
Round  71, Train loss: 1.679, Test loss: 1.720, Test accuracy: 74.33
Round  72, Train loss: 1.681, Test loss: 1.719, Test accuracy: 74.37
Round  73, Train loss: 1.708, Test loss: 1.719, Test accuracy: 74.42
Round  74, Train loss: 1.708, Test loss: 1.719, Test accuracy: 74.47
Round  75, Train loss: 1.703, Test loss: 1.720, Test accuracy: 74.40
Round  76, Train loss: 1.740, Test loss: 1.720, Test accuracy: 74.36
Round  77, Train loss: 1.682, Test loss: 1.719, Test accuracy: 74.36
Round  78, Train loss: 1.648, Test loss: 1.719, Test accuracy: 74.42
Round  79, Train loss: 1.676, Test loss: 1.719, Test accuracy: 74.35
Round  80, Train loss: 1.679, Test loss: 1.718, Test accuracy: 74.37
Round  81, Train loss: 1.713, Test loss: 1.719, Test accuracy: 74.31
Round  82, Train loss: 1.708, Test loss: 1.719, Test accuracy: 74.31
Round  83, Train loss: 1.646, Test loss: 1.718, Test accuracy: 74.40
Round  84, Train loss: 1.650, Test loss: 1.718, Test accuracy: 74.48
Round  85, Train loss: 1.705, Test loss: 1.718, Test accuracy: 74.43
Round  86, Train loss: 1.771, Test loss: 1.717, Test accuracy: 74.51
Round  87, Train loss: 1.671, Test loss: 1.717, Test accuracy: 74.55
Round  88, Train loss: 1.611, Test loss: 1.716, Test accuracy: 74.64
Round  89, Train loss: 1.737, Test loss: 1.716, Test accuracy: 74.66
Round  90, Train loss: 1.642, Test loss: 1.716, Test accuracy: 74.58
Round  91, Train loss: 1.704, Test loss: 1.716, Test accuracy: 74.56
Round  92, Train loss: 1.612, Test loss: 1.716, Test accuracy: 74.55
Round  93, Train loss: 1.671, Test loss: 1.716, Test accuracy: 74.58
Round  94, Train loss: 1.703, Test loss: 1.716, Test accuracy: 74.61
Round  95, Train loss: 1.704, Test loss: 1.716, Test accuracy: 74.67
Round  96, Train loss: 1.705, Test loss: 1.716, Test accuracy: 74.66
Round  97, Train loss: 1.705, Test loss: 1.716, Test accuracy: 74.63
Round  98, Train loss: 1.674, Test loss: 1.716, Test accuracy: 74.63/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  99, Train loss: 1.702, Test loss: 1.716, Test accuracy: 74.64
Final Round, Train loss: 1.676, Test loss: 1.706, Test accuracy: 75.61
Average accuracy final 10 rounds: 74.61099999999999 

1131.4856595993042
[1.0657901763916016, 2.131580352783203, 3.0005857944488525, 3.869591236114502, 4.75189995765686, 5.634208679199219, 6.5113537311553955, 7.388498783111572, 8.289003372192383, 9.189507961273193, 10.05410099029541, 10.918694019317627, 11.804507970809937, 12.690321922302246, 13.590640306472778, 14.49095869064331, 15.411609172821045, 16.33225965499878, 17.178855657577515, 18.02545166015625, 18.91056227684021, 19.79567289352417, 20.620280504226685, 21.4448881149292, 22.316347122192383, 23.187806129455566, 23.9802565574646, 24.772706985473633, 25.657047748565674, 26.541388511657715, 27.411502599716187, 28.281616687774658, 29.163676500320435, 30.04573631286621, 30.91801118850708, 31.79028606414795, 32.66613841056824, 33.541990756988525, 34.36015462875366, 35.1783185005188, 36.09562969207764, 37.012940883636475, 37.95504307746887, 38.89714527130127, 39.75647521018982, 40.61580514907837, 41.455955505371094, 42.29610586166382, 43.090927600860596, 43.88574934005737, 44.73759889602661, 45.58944845199585, 46.441264629364014, 47.29308080673218, 48.100494146347046, 48.907907485961914, 49.73760485649109, 50.567302227020264, 51.39540910720825, 52.22351598739624, 53.043107748031616, 53.86269950866699, 54.76253390312195, 55.662368297576904, 56.497872829437256, 57.33337736129761, 58.10096216201782, 58.86854696273804, 59.67705726623535, 60.485567569732666, 61.30816650390625, 62.130765438079834, 62.98584198951721, 63.84091854095459, 64.65220141410828, 65.46348428726196, 66.28792691230774, 67.11236953735352, 67.99621629714966, 68.8800630569458, 69.80619072914124, 70.73231840133667, 71.6571717262268, 72.58202505111694, 73.4323205947876, 74.28261613845825, 75.12513709068298, 75.96765804290771, 76.84251189231873, 77.71736574172974, 78.55758666992188, 79.39780759811401, 80.2297101020813, 81.06161260604858, 81.95297455787659, 82.84433650970459, 83.64888143539429, 84.45342636108398, 85.3229660987854, 86.19250583648682, 87.21089720726013, 88.22928857803345, 89.12904167175293, 90.02879476547241, 90.92926406860352, 91.82973337173462, 92.74424767494202, 93.65876197814941, 94.53280925750732, 95.40685653686523, 96.34860110282898, 97.29034566879272, 98.21948218345642, 99.14861869812012, 100.06609845161438, 100.98357820510864, 101.9301528930664, 102.87672758102417, 103.70910477638245, 104.54148197174072, 105.40535521507263, 106.26922845840454, 107.2016327381134, 108.13403701782227, 109.00628089904785, 109.87852478027344, 110.67749404907227, 111.4764633178711, 112.33890676498413, 113.20135021209717, 114.07481360435486, 114.94827699661255, 115.80176949501038, 116.6552619934082, 117.43082094192505, 118.2063798904419, 118.98530888557434, 119.76423788070679, 120.6306746006012, 121.4971113204956, 122.30254936218262, 123.10798740386963, 123.96108198165894, 124.81417655944824, 125.6512234210968, 126.48827028274536, 127.34417867660522, 128.2000870704651, 129.04607367515564, 129.8920602798462, 130.68702602386475, 131.4819917678833, 132.31553602218628, 133.14908027648926, 133.9807586669922, 134.81243705749512, 135.62385964393616, 136.4352822303772, 137.34206771850586, 138.24885320663452, 139.17736673355103, 140.10588026046753, 140.9827175140381, 141.85955476760864, 142.76274514198303, 143.66593551635742, 144.55427646636963, 145.44261741638184, 146.2772707939148, 147.11192417144775, 147.95178174972534, 148.79163932800293, 149.5826380252838, 150.3736367225647, 151.21728229522705, 152.0609278678894, 152.94114637374878, 153.82136487960815, 154.62600111961365, 155.43063735961914, 156.28429651260376, 157.13795566558838, 158.01903533935547, 158.90011501312256, 159.7512514591217, 160.60238790512085, 161.44478106498718, 162.28717422485352, 163.07216262817383, 163.85715103149414, 164.7390124797821, 165.62087392807007, 166.51105427742004, 167.40123462677002, 168.22468662261963, 169.04813861846924, 169.88306307792664, 170.71798753738403, 171.57801270484924, 172.43803787231445, 174.07816219329834, 175.71828651428223]
[11.88, 11.88, 15.65, 15.65, 15.01, 15.01, 15.24, 15.24, 18.61, 18.61, 19.9, 19.9, 22.3, 22.3, 28.29, 28.29, 34.37, 34.37, 38.08, 38.08, 44.44, 44.44, 49.64, 49.64, 53.12, 53.12, 55.27, 55.27, 58.39, 58.39, 59.92, 59.92, 63.56, 63.56, 64.96, 64.96, 66.71, 66.71, 66.68, 66.68, 67.82, 67.82, 67.78, 67.78, 68.34, 68.34, 68.38, 68.38, 68.74, 68.74, 69.56, 69.56, 69.36, 69.36, 69.73, 69.73, 70.2, 70.2, 70.23, 70.23, 70.32, 70.32, 70.72, 70.72, 71.0, 71.0, 70.82, 70.82, 70.81, 70.81, 71.16, 71.16, 71.23, 71.23, 71.31, 71.31, 71.32, 71.32, 71.24, 71.24, 71.46, 71.46, 71.53, 71.53, 71.76, 71.76, 72.04, 72.04, 72.67, 72.67, 72.68, 72.68, 72.64, 72.64, 72.69, 72.69, 72.87, 72.87, 73.0, 73.0, 73.1, 73.1, 73.05, 73.05, 73.02, 73.02, 73.06, 73.06, 73.91, 73.91, 73.92, 73.92, 73.92, 73.92, 74.03, 74.03, 73.93, 73.93, 73.84, 73.84, 74.01, 74.01, 74.05, 74.05, 74.0, 74.0, 74.03, 74.03, 74.04, 74.04, 74.21, 74.21, 74.22, 74.22, 74.16, 74.16, 74.08, 74.08, 74.11, 74.11, 74.16, 74.16, 74.33, 74.33, 74.37, 74.37, 74.42, 74.42, 74.47, 74.47, 74.4, 74.4, 74.36, 74.36, 74.36, 74.36, 74.42, 74.42, 74.35, 74.35, 74.37, 74.37, 74.31, 74.31, 74.31, 74.31, 74.4, 74.4, 74.48, 74.48, 74.43, 74.43, 74.51, 74.51, 74.55, 74.55, 74.64, 74.64, 74.66, 74.66, 74.58, 74.58, 74.56, 74.56, 74.55, 74.55, 74.58, 74.58, 74.61, 74.61, 74.67, 74.67, 74.66, 74.66, 74.63, 74.63, 74.63, 74.63, 74.64, 74.64, 75.61, 75.61]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedper
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.290, Test loss: 2.299, Test accuracy: 13.49
Round   1, Train loss: 2.263, Test loss: 2.289, Test accuracy: 16.08
Round   2, Train loss: 2.173, Test loss: 2.260, Test accuracy: 15.24
Round   3, Train loss: 2.044, Test loss: 2.221, Test accuracy: 22.45
Round   4, Train loss: 1.960, Test loss: 2.180, Test accuracy: 26.75
Round   5, Train loss: 1.819, Test loss: 2.126, Test accuracy: 33.27
Round   6, Train loss: 1.875, Test loss: 2.059, Test accuracy: 42.39
Round   7, Train loss: 1.813, Test loss: 2.033, Test accuracy: 44.20
Round   8, Train loss: 1.796, Test loss: 1.997, Test accuracy: 47.77
Round   9, Train loss: 1.817, Test loss: 1.970, Test accuracy: 49.81
Round  10, Train loss: 1.859, Test loss: 1.929, Test accuracy: 54.76
Round  11, Train loss: 1.796, Test loss: 1.888, Test accuracy: 59.20
Round  12, Train loss: 1.672, Test loss: 1.876, Test accuracy: 59.59
Round  13, Train loss: 1.798, Test loss: 1.868, Test accuracy: 60.25
Round  14, Train loss: 1.814, Test loss: 1.855, Test accuracy: 61.33
Round  15, Train loss: 1.816, Test loss: 1.846, Test accuracy: 62.33
Round  16, Train loss: 1.761, Test loss: 1.839, Test accuracy: 63.18
Round  17, Train loss: 1.700, Test loss: 1.814, Test accuracy: 65.47
Round  18, Train loss: 1.782, Test loss: 1.791, Test accuracy: 67.66
Round  19, Train loss: 1.689, Test loss: 1.777, Test accuracy: 69.28
Round  20, Train loss: 1.671, Test loss: 1.772, Test accuracy: 69.63
Round  21, Train loss: 1.694, Test loss: 1.765, Test accuracy: 70.45
Round  22, Train loss: 1.711, Test loss: 1.763, Test accuracy: 70.75
Round  23, Train loss: 1.793, Test loss: 1.755, Test accuracy: 71.35
Round  24, Train loss: 1.663, Test loss: 1.747, Test accuracy: 72.11
Round  25, Train loss: 1.653, Test loss: 1.746, Test accuracy: 72.11
Round  26, Train loss: 1.658, Test loss: 1.738, Test accuracy: 72.89
Round  27, Train loss: 1.587, Test loss: 1.736, Test accuracy: 72.98
Round  28, Train loss: 1.742, Test loss: 1.730, Test accuracy: 73.55
Round  29, Train loss: 1.645, Test loss: 1.729, Test accuracy: 73.63
Round  30, Train loss: 1.647, Test loss: 1.728, Test accuracy: 73.73
Round  31, Train loss: 1.674, Test loss: 1.727, Test accuracy: 73.69
Round  32, Train loss: 1.556, Test loss: 1.725, Test accuracy: 73.70
Round  33, Train loss: 1.737, Test loss: 1.718, Test accuracy: 74.52
Round  34, Train loss: 1.620, Test loss: 1.714, Test accuracy: 74.93
Round  35, Train loss: 1.640, Test loss: 1.715, Test accuracy: 74.83
Round  36, Train loss: 1.673, Test loss: 1.713, Test accuracy: 75.11
Round  37, Train loss: 1.710, Test loss: 1.713, Test accuracy: 75.11
Round  38, Train loss: 1.642, Test loss: 1.713, Test accuracy: 75.26
Round  39, Train loss: 1.669, Test loss: 1.712, Test accuracy: 75.22
Round  40, Train loss: 1.685, Test loss: 1.710, Test accuracy: 75.36
Round  41, Train loss: 1.612, Test loss: 1.708, Test accuracy: 75.43
Round  42, Train loss: 1.700, Test loss: 1.708, Test accuracy: 75.33
Round  43, Train loss: 1.604, Test loss: 1.707, Test accuracy: 75.59
Round  44, Train loss: 1.704, Test loss: 1.706, Test accuracy: 75.68
Round  45, Train loss: 1.702, Test loss: 1.705, Test accuracy: 75.65
Round  46, Train loss: 1.606, Test loss: 1.705, Test accuracy: 75.74
Round  47, Train loss: 1.638, Test loss: 1.703, Test accuracy: 75.92
Round  48, Train loss: 1.669, Test loss: 1.703, Test accuracy: 75.89
Round  49, Train loss: 1.638, Test loss: 1.703, Test accuracy: 75.91
Round  50, Train loss: 1.606, Test loss: 1.702, Test accuracy: 75.99
Round  51, Train loss: 1.577, Test loss: 1.701, Test accuracy: 76.12
Round  52, Train loss: 1.677, Test loss: 1.698, Test accuracy: 76.42
Round  53, Train loss: 1.639, Test loss: 1.698, Test accuracy: 76.45
Round  54, Train loss: 1.641, Test loss: 1.698, Test accuracy: 76.42
Round  55, Train loss: 1.636, Test loss: 1.699, Test accuracy: 76.25
Round  56, Train loss: 1.642, Test loss: 1.696, Test accuracy: 76.65
Round  57, Train loss: 1.664, Test loss: 1.698, Test accuracy: 76.34
Round  58, Train loss: 1.575, Test loss: 1.696, Test accuracy: 76.57
Round  59, Train loss: 1.587, Test loss: 1.699, Test accuracy: 76.25
Round  60, Train loss: 1.641, Test loss: 1.695, Test accuracy: 76.62
Round  61, Train loss: 1.677, Test loss: 1.693, Test accuracy: 77.02
Round  62, Train loss: 1.603, Test loss: 1.691, Test accuracy: 77.08
Round  63, Train loss: 1.675, Test loss: 1.689, Test accuracy: 77.19
Round  64, Train loss: 1.667, Test loss: 1.689, Test accuracy: 77.24
Round  65, Train loss: 1.576, Test loss: 1.687, Test accuracy: 77.41
Round  66, Train loss: 1.668, Test loss: 1.687, Test accuracy: 77.52
Round  67, Train loss: 1.601, Test loss: 1.687, Test accuracy: 77.49
Round  68, Train loss: 1.540, Test loss: 1.686, Test accuracy: 77.47
Round  69, Train loss: 1.605, Test loss: 1.686, Test accuracy: 77.54
Round  70, Train loss: 1.604, Test loss: 1.685, Test accuracy: 77.64
Round  71, Train loss: 1.634, Test loss: 1.685, Test accuracy: 77.68
Round  72, Train loss: 1.634, Test loss: 1.685, Test accuracy: 77.68
Round  73, Train loss: 1.637, Test loss: 1.684, Test accuracy: 77.69
Round  74, Train loss: 1.601, Test loss: 1.684, Test accuracy: 77.74
Round  75, Train loss: 1.666, Test loss: 1.684, Test accuracy: 77.75
Round  76, Train loss: 1.667, Test loss: 1.684, Test accuracy: 77.74
Round  77, Train loss: 1.569, Test loss: 1.683, Test accuracy: 77.87
Round  78, Train loss: 1.667, Test loss: 1.683, Test accuracy: 77.81
Round  79, Train loss: 1.667, Test loss: 1.683, Test accuracy: 77.90
Round  80, Train loss: 1.702, Test loss: 1.683, Test accuracy: 77.82
Round  81, Train loss: 1.696, Test loss: 1.683, Test accuracy: 77.87
Round  82, Train loss: 1.571, Test loss: 1.683, Test accuracy: 77.83
Round  83, Train loss: 1.569, Test loss: 1.683, Test accuracy: 77.79
Round  84, Train loss: 1.662, Test loss: 1.683, Test accuracy: 77.83
Round  85, Train loss: 1.667, Test loss: 1.683, Test accuracy: 77.88
Round  86, Train loss: 1.634, Test loss: 1.682, Test accuracy: 77.95
Round  87, Train loss: 1.602, Test loss: 1.682, Test accuracy: 77.90
Round  88, Train loss: 1.567, Test loss: 1.683, Test accuracy: 77.89
Round  89, Train loss: 1.633, Test loss: 1.683, Test accuracy: 77.85
Round  90, Train loss: 1.666, Test loss: 1.682, Test accuracy: 77.88
Round  91, Train loss: 1.600, Test loss: 1.682, Test accuracy: 77.87
Round  92, Train loss: 1.761, Test loss: 1.682, Test accuracy: 77.89
Round  93, Train loss: 1.644, Test loss: 1.675, Test accuracy: 78.60
Round  94, Train loss: 1.698, Test loss: 1.674, Test accuracy: 78.70
Round  95, Train loss: 1.598, Test loss: 1.674, Test accuracy: 78.79
Round  96, Train loss: 1.714, Test loss: 1.667, Test accuracy: 79.57
Round  97, Train loss: 1.601, Test loss: 1.664, Test accuracy: 80.01
Round  98, Train loss: 1.636, Test loss: 1.662, Test accuracy: 80.17/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  99, Train loss: 1.600, Test loss: 1.662, Test accuracy: 80.10
Final Round, Train loss: 1.622, Test loss: 1.659, Test accuracy: 80.25
Average accuracy final 10 rounds: 78.958 

1075.9387693405151
[0.9448068141937256, 1.8896136283874512, 2.764711618423462, 3.6398096084594727, 4.458358287811279, 5.276906967163086, 6.137500286102295, 6.998093605041504, 7.831369400024414, 8.664645195007324, 9.53174638748169, 10.398847579956055, 11.291049718856812, 12.183251857757568, 13.096710443496704, 14.01016902923584, 14.813117265701294, 15.616065502166748, 16.693156242370605, 17.770246982574463, 18.72955846786499, 19.688869953155518, 20.89876675605774, 22.10866355895996, 23.358426809310913, 24.608190059661865, 25.59823489189148, 26.588279724121094, 27.36178755760193, 28.135295391082764, 28.936251401901245, 29.737207412719727, 30.551762342453003, 31.36631727218628, 32.16434621810913, 32.96237516403198, 33.74000287055969, 34.5176305770874, 35.27817344665527, 36.038716316223145, 36.85178852081299, 37.66486072540283, 38.469993591308594, 39.275126457214355, 40.016573429107666, 40.75802040100098, 41.530038833618164, 42.30205726623535, 43.06454420089722, 43.82703113555908, 44.62113618850708, 45.41524124145508, 46.20371460914612, 46.99218797683716, 47.75026249885559, 48.50833702087402, 49.31344389915466, 50.1185507774353, 50.932724475860596, 51.74689817428589, 52.52452492713928, 53.302151679992676, 54.11740303039551, 54.93265438079834, 55.73016571998596, 56.527677059173584, 57.29308080673218, 58.05848455429077, 58.85282802581787, 59.64717149734497, 60.473198652267456, 61.29922580718994, 62.09404158592224, 62.88885736465454, 63.69995403289795, 64.51105070114136, 65.28327488899231, 66.05549907684326, 66.88176536560059, 67.70803165435791, 68.46273136138916, 69.21743106842041, 70.00758171081543, 70.79773235321045, 71.60465574264526, 72.41157913208008, 73.21176218986511, 74.01194524765015, 74.83621287345886, 75.66048049926758, 76.39733505249023, 77.13418960571289, 77.94163775444031, 78.74908590316772, 79.5943751335144, 80.43966436386108, 81.24177193641663, 82.04387950897217, 82.79737520217896, 83.55087089538574, 84.357754945755, 85.16463899612427, 85.95892834663391, 86.75321769714355, 87.55312705039978, 88.353036403656, 89.0886754989624, 89.8243145942688, 90.62247443199158, 91.42063426971436, 92.25353646278381, 93.08643865585327, 94.00334143638611, 94.92024421691895, 95.68714737892151, 96.45405054092407, 97.26020884513855, 98.06636714935303, 98.82809782028198, 99.58982849121094, 100.39228630065918, 101.19474411010742, 101.97140002250671, 102.748055934906, 103.56670999526978, 104.38536405563354, 105.19797396659851, 106.01058387756348, 106.76395463943481, 107.51732540130615, 108.3668999671936, 109.21647453308105, 110.05061769485474, 110.88476085662842, 111.67484211921692, 112.46492338180542, 113.24874949455261, 114.0325756072998, 114.82708358764648, 115.62159156799316, 116.44734025001526, 117.27308893203735, 118.13039708137512, 118.98770523071289, 119.7488751411438, 120.5100450515747, 121.31017351150513, 122.11030197143555, 123.03254556655884, 123.95478916168213, 124.71197295188904, 125.46915674209595, 126.22396969795227, 126.9787826538086, 127.75360918045044, 128.52843570709229, 129.42482900619507, 130.32122230529785, 131.1777708530426, 132.03431940078735, 132.81080651283264, 133.58729362487793, 134.4229335784912, 135.2585735321045, 136.04984307289124, 136.84111261367798, 137.64274835586548, 138.44438409805298, 139.26102709770203, 140.07767009735107, 140.87417483329773, 141.67067956924438, 142.43994855880737, 143.20921754837036, 143.96508049964905, 144.72094345092773, 145.52501893043518, 146.32909440994263, 147.16405987739563, 147.99902534484863, 148.78714847564697, 149.5752716064453, 150.351407289505, 151.1275429725647, 151.95090317726135, 152.774263381958, 153.5718114376068, 154.36935949325562, 155.16937947273254, 155.96939945220947, 156.74721455574036, 157.52502965927124, 158.32707023620605, 159.12911081314087, 159.96482706069946, 160.80054330825806, 161.55539989471436, 162.31025648117065, 163.09058713912964, 163.87091779708862, 165.46941113471985, 167.06790447235107]
[13.49, 13.49, 16.08, 16.08, 15.24, 15.24, 22.45, 22.45, 26.75, 26.75, 33.27, 33.27, 42.39, 42.39, 44.2, 44.2, 47.77, 47.77, 49.81, 49.81, 54.76, 54.76, 59.2, 59.2, 59.59, 59.59, 60.25, 60.25, 61.33, 61.33, 62.33, 62.33, 63.18, 63.18, 65.47, 65.47, 67.66, 67.66, 69.28, 69.28, 69.63, 69.63, 70.45, 70.45, 70.75, 70.75, 71.35, 71.35, 72.11, 72.11, 72.11, 72.11, 72.89, 72.89, 72.98, 72.98, 73.55, 73.55, 73.63, 73.63, 73.73, 73.73, 73.69, 73.69, 73.7, 73.7, 74.52, 74.52, 74.93, 74.93, 74.83, 74.83, 75.11, 75.11, 75.11, 75.11, 75.26, 75.26, 75.22, 75.22, 75.36, 75.36, 75.43, 75.43, 75.33, 75.33, 75.59, 75.59, 75.68, 75.68, 75.65, 75.65, 75.74, 75.74, 75.92, 75.92, 75.89, 75.89, 75.91, 75.91, 75.99, 75.99, 76.12, 76.12, 76.42, 76.42, 76.45, 76.45, 76.42, 76.42, 76.25, 76.25, 76.65, 76.65, 76.34, 76.34, 76.57, 76.57, 76.25, 76.25, 76.62, 76.62, 77.02, 77.02, 77.08, 77.08, 77.19, 77.19, 77.24, 77.24, 77.41, 77.41, 77.52, 77.52, 77.49, 77.49, 77.47, 77.47, 77.54, 77.54, 77.64, 77.64, 77.68, 77.68, 77.68, 77.68, 77.69, 77.69, 77.74, 77.74, 77.75, 77.75, 77.74, 77.74, 77.87, 77.87, 77.81, 77.81, 77.9, 77.9, 77.82, 77.82, 77.87, 77.87, 77.83, 77.83, 77.79, 77.79, 77.83, 77.83, 77.88, 77.88, 77.95, 77.95, 77.9, 77.9, 77.89, 77.89, 77.85, 77.85, 77.88, 77.88, 77.87, 77.87, 77.89, 77.89, 78.6, 78.6, 78.7, 78.7, 78.79, 78.79, 79.57, 79.57, 80.01, 80.01, 80.17, 80.17, 80.1, 80.1, 80.25, 80.25]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

lg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 17098 (global); Percentage 3.11 (17098/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.288, Test loss: 2.298, Test accuracy: 20.73
Round   1, Train loss: 2.255, Test loss: 2.279, Test accuracy: 27.33
Round   2, Train loss: 2.127, Test loss: 2.217, Test accuracy: 38.03
Round   3, Train loss: 1.940, Test loss: 2.123, Test accuracy: 44.76
Round   4, Train loss: 1.952, Test loss: 2.004, Test accuracy: 57.34
Round   5, Train loss: 1.777, Test loss: 1.924, Test accuracy: 64.03
Round   6, Train loss: 1.620, Test loss: 1.870, Test accuracy: 68.10
Round   7, Train loss: 1.605, Test loss: 1.829, Test accuracy: 71.42
Round   8, Train loss: 1.648, Test loss: 1.750, Test accuracy: 76.45
Round   9, Train loss: 1.553, Test loss: 1.722, Test accuracy: 78.14
Round  10, Train loss: 1.571, Test loss: 1.699, Test accuracy: 79.69
Round  11, Train loss: 1.648, Test loss: 1.674, Test accuracy: 82.19
Round  12, Train loss: 1.543, Test loss: 1.661, Test accuracy: 83.38
Round  13, Train loss: 1.525, Test loss: 1.651, Test accuracy: 84.09
Round  14, Train loss: 1.579, Test loss: 1.646, Test accuracy: 84.16
Round  15, Train loss: 1.565, Test loss: 1.606, Test accuracy: 87.05
Round  16, Train loss: 1.480, Test loss: 1.604, Test accuracy: 87.13
Round  17, Train loss: 1.484, Test loss: 1.601, Test accuracy: 87.16
Round  18, Train loss: 1.480, Test loss: 1.599, Test accuracy: 87.25
Round  19, Train loss: 1.518, Test loss: 1.597, Test accuracy: 87.36
Round  20, Train loss: 1.563, Test loss: 1.589, Test accuracy: 88.13
Round  21, Train loss: 1.539, Test loss: 1.588, Test accuracy: 88.25
Round  22, Train loss: 1.538, Test loss: 1.587, Test accuracy: 88.24
Round  23, Train loss: 1.507, Test loss: 1.587, Test accuracy: 88.20
Round  24, Train loss: 1.504, Test loss: 1.587, Test accuracy: 88.25
Round  25, Train loss: 1.472, Test loss: 1.587, Test accuracy: 88.21
Round  26, Train loss: 1.536, Test loss: 1.586, Test accuracy: 88.28
Round  27, Train loss: 1.510, Test loss: 1.583, Test accuracy: 88.56
Round  28, Train loss: 1.472, Test loss: 1.583, Test accuracy: 88.56
Round  29, Train loss: 1.564, Test loss: 1.581, Test accuracy: 88.70
Round  30, Train loss: 1.472, Test loss: 1.579, Test accuracy: 88.81
Round  31, Train loss: 1.499, Test loss: 1.574, Test accuracy: 89.41
Round  32, Train loss: 1.535, Test loss: 1.572, Test accuracy: 89.66
Round  33, Train loss: 1.471, Test loss: 1.572, Test accuracy: 89.61
Round  34, Train loss: 1.470, Test loss: 1.571, Test accuracy: 89.74
Round  35, Train loss: 1.476, Test loss: 1.565, Test accuracy: 90.26
Round  36, Train loss: 1.468, Test loss: 1.565, Test accuracy: 90.30
Round  37, Train loss: 1.532, Test loss: 1.565, Test accuracy: 90.31
Round  38, Train loss: 1.503, Test loss: 1.563, Test accuracy: 90.42
Round  39, Train loss: 1.470, Test loss: 1.563, Test accuracy: 90.43
Round  40, Train loss: 1.484, Test loss: 1.558, Test accuracy: 90.97
Round  41, Train loss: 1.469, Test loss: 1.558, Test accuracy: 90.91
Round  42, Train loss: 1.470, Test loss: 1.558, Test accuracy: 91.02
Round  43, Train loss: 1.467, Test loss: 1.558, Test accuracy: 90.99
Round  44, Train loss: 1.469, Test loss: 1.558, Test accuracy: 90.98
Round  45, Train loss: 1.503, Test loss: 1.555, Test accuracy: 91.15
Round  46, Train loss: 1.499, Test loss: 1.555, Test accuracy: 91.12
Round  47, Train loss: 1.469, Test loss: 1.555, Test accuracy: 91.14
Round  48, Train loss: 1.470, Test loss: 1.554, Test accuracy: 91.22
Round  49, Train loss: 1.499, Test loss: 1.554, Test accuracy: 91.23
Round  50, Train loss: 1.499, Test loss: 1.554, Test accuracy: 91.23
Round  51, Train loss: 1.469, Test loss: 1.554, Test accuracy: 91.16
Round  52, Train loss: 1.468, Test loss: 1.554, Test accuracy: 91.22
Round  53, Train loss: 1.468, Test loss: 1.554, Test accuracy: 91.23
Round  54, Train loss: 1.467, Test loss: 1.553, Test accuracy: 91.21
Round  55, Train loss: 1.469, Test loss: 1.553, Test accuracy: 91.26
Round  56, Train loss: 1.500, Test loss: 1.553, Test accuracy: 91.22
Round  57, Train loss: 1.500, Test loss: 1.553, Test accuracy: 91.30
Round  58, Train loss: 1.468, Test loss: 1.553, Test accuracy: 91.29
Round  59, Train loss: 1.468, Test loss: 1.553, Test accuracy: 91.27
Round  60, Train loss: 1.468, Test loss: 1.553, Test accuracy: 91.29
Round  61, Train loss: 1.467, Test loss: 1.553, Test accuracy: 91.31
Round  62, Train loss: 1.467, Test loss: 1.553, Test accuracy: 91.33
Round  63, Train loss: 1.499, Test loss: 1.553, Test accuracy: 91.34
Round  64, Train loss: 1.468, Test loss: 1.552, Test accuracy: 91.34
Round  65, Train loss: 1.467, Test loss: 1.552, Test accuracy: 91.37
Round  66, Train loss: 1.467, Test loss: 1.552, Test accuracy: 91.34
Round  67, Train loss: 1.466, Test loss: 1.552, Test accuracy: 91.35
Round  68, Train loss: 1.466, Test loss: 1.552, Test accuracy: 91.36
Round  69, Train loss: 1.498, Test loss: 1.552, Test accuracy: 91.33
Round  70, Train loss: 1.468, Test loss: 1.552, Test accuracy: 91.33
Round  71, Train loss: 1.467, Test loss: 1.552, Test accuracy: 91.34
Round  72, Train loss: 1.498, Test loss: 1.552, Test accuracy: 91.35
Round  73, Train loss: 1.467, Test loss: 1.552, Test accuracy: 91.34
Round  74, Train loss: 1.467, Test loss: 1.552, Test accuracy: 91.35
Round  75, Train loss: 1.500, Test loss: 1.552, Test accuracy: 91.33
Round  76, Train loss: 1.466, Test loss: 1.552, Test accuracy: 91.36
Round  77, Train loss: 1.467, Test loss: 1.552, Test accuracy: 91.34
Round  78, Train loss: 1.468, Test loss: 1.552, Test accuracy: 91.34
Round  79, Train loss: 1.500, Test loss: 1.552, Test accuracy: 91.33
Round  80, Train loss: 1.498, Test loss: 1.552, Test accuracy: 91.37
Round  81, Train loss: 1.467, Test loss: 1.552, Test accuracy: 91.30
Round  82, Train loss: 1.466, Test loss: 1.552, Test accuracy: 91.31
Round  83, Train loss: 1.466, Test loss: 1.552, Test accuracy: 91.37
Round  84, Train loss: 1.466, Test loss: 1.552, Test accuracy: 91.37
Round  85, Train loss: 1.467, Test loss: 1.552, Test accuracy: 91.39
Round  86, Train loss: 1.466, Test loss: 1.552, Test accuracy: 91.40
Round  87, Train loss: 1.497, Test loss: 1.552, Test accuracy: 91.40
Round  88, Train loss: 1.499, Test loss: 1.552, Test accuracy: 91.42
Round  89, Train loss: 1.468, Test loss: 1.552, Test accuracy: 91.43
Round  90, Train loss: 1.499, Test loss: 1.552, Test accuracy: 91.42
Round  91, Train loss: 1.468, Test loss: 1.552, Test accuracy: 91.44
Round  92, Train loss: 1.467, Test loss: 1.551, Test accuracy: 91.41
Round  93, Train loss: 1.468, Test loss: 1.551, Test accuracy: 91.42
Round  94, Train loss: 1.468, Test loss: 1.551, Test accuracy: 91.42
Round  95, Train loss: 1.466, Test loss: 1.551, Test accuracy: 91.39
Round  96, Train loss: 1.466, Test loss: 1.551, Test accuracy: 91.41
Round  97, Train loss: 1.467, Test loss: 1.552, Test accuracy: 91.40
Round  98, Train loss: 1.465, Test loss: 1.552, Test accuracy: 91.39
Round  99, Train loss: 1.467, Test loss: 1.552, Test accuracy: 91.39/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Final Round, Train loss: 1.476, Test loss: 1.551, Test accuracy: 91.42
Average accuracy final 10 rounds: 91.40899999999999 

1170.2049701213837
[1.0615463256835938, 2.1230926513671875, 3.083158493041992, 4.043224334716797, 4.9860310554504395, 5.928837776184082, 6.859054088592529, 7.789270401000977, 8.727680683135986, 9.666090965270996, 10.570094585418701, 11.474098205566406, 12.412919521331787, 13.351740837097168, 14.301827907562256, 15.251914978027344, 16.2058744430542, 17.159833908081055, 18.12244176864624, 19.085049629211426, 20.076860427856445, 21.068671226501465, 22.02474069595337, 22.980810165405273, 23.9122474193573, 24.843684673309326, 25.79996681213379, 26.756248950958252, 27.702950477600098, 28.649652004241943, 29.591753482818604, 30.533854961395264, 31.458261489868164, 32.382668018341064, 33.327840089797974, 34.27301216125488, 35.195852756500244, 36.118693351745605, 37.005666732788086, 37.892640113830566, 38.84923577308655, 39.80583143234253, 40.76080107688904, 41.71577072143555, 42.652528285980225, 43.5892858505249, 44.48763132095337, 45.385976791381836, 46.317941665649414, 47.24990653991699, 48.190632343292236, 49.13135814666748, 50.08813190460205, 51.04490566253662, 52.0199818611145, 52.99505805969238, 53.96214008331299, 54.929222106933594, 55.902554750442505, 56.875887393951416, 57.82080674171448, 58.76572608947754, 59.70010256767273, 60.63447904586792, 61.614269971847534, 62.59406089782715, 63.569119453430176, 64.5441780090332, 65.51280331611633, 66.48142862319946, 67.45126509666443, 68.4211015701294, 69.36239457130432, 70.30368757247925, 71.27828931808472, 72.25289106369019, 73.19843649864197, 74.14398193359375, 75.09099650382996, 76.03801107406616, 77.0015435218811, 77.96507596969604, 78.92685770988464, 79.88863945007324, 80.89763641357422, 81.9066333770752, 82.82998633384705, 83.7533392906189, 84.70153045654297, 85.64972162246704, 86.64850282669067, 87.6472840309143, 88.5805115699768, 89.5137391090393, 90.47385478019714, 91.43397045135498, 92.40210390090942, 93.37023735046387, 94.37004518508911, 95.36985301971436, 96.29508876800537, 97.22032451629639, 98.17235970497131, 99.12439489364624, 100.05707812309265, 100.98976135253906, 101.98538899421692, 102.98101663589478, 103.9355640411377, 104.89011144638062, 105.86935663223267, 106.84860181808472, 107.82056427001953, 108.79252672195435, 109.76156187057495, 110.73059701919556, 111.74282479286194, 112.75505256652832, 113.73170256614685, 114.70835256576538, 115.6487627029419, 116.58917284011841, 117.54855585098267, 118.50793886184692, 119.51523923873901, 120.5225396156311, 121.47241640090942, 122.42229318618774, 123.34093523025513, 124.25957727432251, 125.23117160797119, 126.20276594161987, 127.17509007453918, 128.1474142074585, 129.07741522789001, 130.00741624832153, 130.9714493751526, 131.93548250198364, 132.9441328048706, 133.95278310775757, 134.91425108909607, 135.87571907043457, 136.83040189743042, 137.78508472442627, 138.68495273590088, 139.5848207473755, 140.52215576171875, 141.459490776062, 142.34733271598816, 143.2351746559143, 144.20159888267517, 145.16802310943604, 146.1451461315155, 147.12226915359497, 148.1041283607483, 149.0859875679016, 150.0569143295288, 151.027841091156, 151.98039531707764, 152.93294954299927, 153.8818814754486, 154.83081340789795, 155.76108694076538, 156.6913604736328, 157.65115904808044, 158.61095762252808, 159.54083514213562, 160.47071266174316, 161.44287633895874, 162.41504001617432, 163.32648611068726, 164.2379322052002, 165.2191972732544, 166.2004623413086, 167.12963461875916, 168.05880689620972, 168.99225044250488, 169.92569398880005, 170.88380670547485, 171.84191942214966, 172.83037614822388, 173.8188328742981, 174.77611112594604, 175.733389377594, 176.6588203907013, 177.5842514038086, 178.5573570728302, 179.5304627418518, 180.48258543014526, 181.43470811843872, 182.38332390785217, 183.33193969726562, 184.27905249595642, 185.22616529464722, 186.2389988899231, 187.25183248519897, 188.21144247055054, 189.1710524559021, 190.10782551765442, 191.04459857940674, 192.8746829032898, 194.70476722717285]
[20.73, 20.73, 27.33, 27.33, 38.03, 38.03, 44.76, 44.76, 57.34, 57.34, 64.03, 64.03, 68.1, 68.1, 71.42, 71.42, 76.45, 76.45, 78.14, 78.14, 79.69, 79.69, 82.19, 82.19, 83.38, 83.38, 84.09, 84.09, 84.16, 84.16, 87.05, 87.05, 87.13, 87.13, 87.16, 87.16, 87.25, 87.25, 87.36, 87.36, 88.13, 88.13, 88.25, 88.25, 88.24, 88.24, 88.2, 88.2, 88.25, 88.25, 88.21, 88.21, 88.28, 88.28, 88.56, 88.56, 88.56, 88.56, 88.7, 88.7, 88.81, 88.81, 89.41, 89.41, 89.66, 89.66, 89.61, 89.61, 89.74, 89.74, 90.26, 90.26, 90.3, 90.3, 90.31, 90.31, 90.42, 90.42, 90.43, 90.43, 90.97, 90.97, 90.91, 90.91, 91.02, 91.02, 90.99, 90.99, 90.98, 90.98, 91.15, 91.15, 91.12, 91.12, 91.14, 91.14, 91.22, 91.22, 91.23, 91.23, 91.23, 91.23, 91.16, 91.16, 91.22, 91.22, 91.23, 91.23, 91.21, 91.21, 91.26, 91.26, 91.22, 91.22, 91.3, 91.3, 91.29, 91.29, 91.27, 91.27, 91.29, 91.29, 91.31, 91.31, 91.33, 91.33, 91.34, 91.34, 91.34, 91.34, 91.37, 91.37, 91.34, 91.34, 91.35, 91.35, 91.36, 91.36, 91.33, 91.33, 91.33, 91.33, 91.34, 91.34, 91.35, 91.35, 91.34, 91.34, 91.35, 91.35, 91.33, 91.33, 91.36, 91.36, 91.34, 91.34, 91.34, 91.34, 91.33, 91.33, 91.37, 91.37, 91.3, 91.3, 91.31, 91.31, 91.37, 91.37, 91.37, 91.37, 91.39, 91.39, 91.4, 91.4, 91.4, 91.4, 91.42, 91.42, 91.43, 91.43, 91.42, 91.42, 91.44, 91.44, 91.41, 91.41, 91.42, 91.42, 91.42, 91.42, 91.39, 91.39, 91.41, 91.41, 91.4, 91.4, 91.39, 91.39, 91.39, 91.39, 91.42, 91.42]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
Round   0, Train loss: 1.630, Test loss: 2.279, Test accuracy: 28.66
Round   1, Train loss: 1.403, Test loss: 2.207, Test accuracy: 41.28
Round   2, Train loss: 1.425, Test loss: 2.129, Test accuracy: 53.47
Round   3, Train loss: 1.344, Test loss: 2.055, Test accuracy: 59.47
Round   4, Train loss: 1.277, Test loss: 1.985, Test accuracy: 62.65
Round   5, Train loss: 1.223, Test loss: 1.937, Test accuracy: 64.95
Round   6, Train loss: 1.343, Test loss: 1.914, Test accuracy: 65.84
Round   7, Train loss: 1.272, Test loss: 1.864, Test accuracy: 69.98
Round   8, Train loss: 1.177, Test loss: 1.834, Test accuracy: 71.79
Round   9, Train loss: 1.210, Test loss: 1.818, Test accuracy: 72.61
Round  10, Train loss: 1.251, Test loss: 1.811, Test accuracy: 73.56
Round  11, Train loss: 1.245, Test loss: 1.785, Test accuracy: 75.29
Round  12, Train loss: 1.263, Test loss: 1.778, Test accuracy: 75.52
Round  13, Train loss: 1.281, Test loss: 1.781, Test accuracy: 74.67
Round  14, Train loss: 1.167, Test loss: 1.780, Test accuracy: 73.96
Round  15, Train loss: 1.191, Test loss: 1.779, Test accuracy: 74.04
Round  16, Train loss: 1.222, Test loss: 1.773, Test accuracy: 74.28
Round  17, Train loss: 1.282, Test loss: 1.769, Test accuracy: 74.13
Round  18, Train loss: 1.193, Test loss: 1.747, Test accuracy: 76.70
Round  19, Train loss: 1.278, Test loss: 1.739, Test accuracy: 77.23
Round  20, Train loss: 1.261, Test loss: 1.733, Test accuracy: 78.19
Round  21, Train loss: 1.211, Test loss: 1.731, Test accuracy: 78.10
Round  22, Train loss: 1.196, Test loss: 1.725, Test accuracy: 78.89
Round  23, Train loss: 1.167, Test loss: 1.725, Test accuracy: 78.22
Round  24, Train loss: 1.181, Test loss: 1.721, Test accuracy: 78.61
Round  25, Train loss: 1.188, Test loss: 1.719, Test accuracy: 78.70
Round  26, Train loss: 1.161, Test loss: 1.722, Test accuracy: 78.08
Round  27, Train loss: 1.183, Test loss: 1.726, Test accuracy: 77.26
Round  28, Train loss: 1.207, Test loss: 1.726, Test accuracy: 77.34
Round  29, Train loss: 1.200, Test loss: 1.717, Test accuracy: 78.29
Round  30, Train loss: 1.160, Test loss: 1.716, Test accuracy: 78.25
Round  31, Train loss: 1.135, Test loss: 1.716, Test accuracy: 78.07
Round  32, Train loss: 1.199, Test loss: 1.716, Test accuracy: 77.85
Round  33, Train loss: 1.137, Test loss: 1.713, Test accuracy: 78.24
Round  34, Train loss: 1.114, Test loss: 1.712, Test accuracy: 78.31
Round  35, Train loss: 1.163, Test loss: 1.713, Test accuracy: 78.19
Round  36, Train loss: 1.209, Test loss: 1.715, Test accuracy: 77.69
Round  37, Train loss: 1.162, Test loss: 1.713, Test accuracy: 77.93
Round  38, Train loss: 1.209, Test loss: 1.714, Test accuracy: 77.80
Round  39, Train loss: 1.179, Test loss: 1.716, Test accuracy: 77.50
Round  40, Train loss: 1.205, Test loss: 1.716, Test accuracy: 77.30
Round  41, Train loss: 1.231, Test loss: 1.715, Test accuracy: 77.38
Round  42, Train loss: 1.158, Test loss: 1.720, Test accuracy: 76.69
Round  43, Train loss: 1.158, Test loss: 1.716, Test accuracy: 76.95
Round  44, Train loss: 1.179, Test loss: 1.721, Test accuracy: 76.21
Round  45, Train loss: 1.131, Test loss: 1.717, Test accuracy: 76.90
Round  46, Train loss: 1.205, Test loss: 1.720, Test accuracy: 76.27
Round  47, Train loss: 1.156, Test loss: 1.722, Test accuracy: 76.27
Round  48, Train loss: 1.156, Test loss: 1.724, Test accuracy: 75.95
Round  49, Train loss: 1.110, Test loss: 1.731, Test accuracy: 74.71
Round  50, Train loss: 1.134, Test loss: 1.728, Test accuracy: 75.35
Round  51, Train loss: 1.131, Test loss: 1.728, Test accuracy: 75.34
Round  52, Train loss: 1.179, Test loss: 1.725, Test accuracy: 75.51
Round  53, Train loss: 1.159, Test loss: 1.726, Test accuracy: 75.19
Round  54, Train loss: 1.156, Test loss: 1.724, Test accuracy: 75.32
Round  55, Train loss: 1.231, Test loss: 1.725, Test accuracy: 75.30
Round  56, Train loss: 1.202, Test loss: 1.727, Test accuracy: 75.00
Round  57, Train loss: 1.230, Test loss: 1.726, Test accuracy: 75.40
Round  58, Train loss: 1.229, Test loss: 1.727, Test accuracy: 75.27
Round  59, Train loss: 1.202, Test loss: 1.732, Test accuracy: 74.50
Round  60, Train loss: 1.130, Test loss: 1.728, Test accuracy: 74.91
Round  61, Train loss: 1.227, Test loss: 1.733, Test accuracy: 74.42
Round  62, Train loss: 1.203, Test loss: 1.735, Test accuracy: 74.09
Round  63, Train loss: 1.154, Test loss: 1.738, Test accuracy: 73.83
Round  64, Train loss: 1.181, Test loss: 1.742, Test accuracy: 73.29
Round  65, Train loss: 1.180, Test loss: 1.744, Test accuracy: 72.76
Round  66, Train loss: 1.207, Test loss: 1.743, Test accuracy: 72.65
Round  67, Train loss: 1.154, Test loss: 1.747, Test accuracy: 72.41
Round  68, Train loss: 1.202, Test loss: 1.749, Test accuracy: 71.87
Round  69, Train loss: 1.204, Test loss: 1.749, Test accuracy: 71.96
Round  70, Train loss: 1.178, Test loss: 1.745, Test accuracy: 72.26
Round  71, Train loss: 1.130, Test loss: 1.750, Test accuracy: 71.63
Round  72, Train loss: 1.177, Test loss: 1.754, Test accuracy: 71.28
Round  73, Train loss: 1.152, Test loss: 1.756, Test accuracy: 70.81
Round  74, Train loss: 1.178, Test loss: 1.751, Test accuracy: 71.58
Round  75, Train loss: 1.203, Test loss: 1.757, Test accuracy: 70.86
Round  76, Train loss: 1.204, Test loss: 1.759, Test accuracy: 70.77
Round  77, Train loss: 1.251, Test loss: 1.759, Test accuracy: 70.72
Round  78, Train loss: 1.130, Test loss: 1.759, Test accuracy: 70.79
Round  79, Train loss: 1.157, Test loss: 1.759, Test accuracy: 70.91
Round  80, Train loss: 1.129, Test loss: 1.757, Test accuracy: 70.97
Round  81, Train loss: 1.154, Test loss: 1.756, Test accuracy: 71.05
Round  82, Train loss: 1.178, Test loss: 1.764, Test accuracy: 70.20
Round  83, Train loss: 1.127, Test loss: 1.762, Test accuracy: 70.52
Round  84, Train loss: 1.152, Test loss: 1.763, Test accuracy: 70.29
Round  85, Train loss: 1.145, Test loss: 1.757, Test accuracy: 70.83
Round  86, Train loss: 1.180, Test loss: 1.762, Test accuracy: 70.35
Round  87, Train loss: 1.180, Test loss: 1.766, Test accuracy: 70.01
Round  88, Train loss: 1.155, Test loss: 1.767, Test accuracy: 69.65
Round  89, Train loss: 1.129, Test loss: 1.768, Test accuracy: 69.68
Round  90, Train loss: 1.227, Test loss: 1.774, Test accuracy: 69.05
Round  91, Train loss: 1.176, Test loss: 1.765, Test accuracy: 70.08
Round  92, Train loss: 1.204, Test loss: 1.764, Test accuracy: 70.11
Round  93, Train loss: 1.128, Test loss: 1.764, Test accuracy: 70.22
Round  94, Train loss: 1.154, Test loss: 1.771, Test accuracy: 69.27
Round  95, Train loss: 1.128, Test loss: 1.768, Test accuracy: 69.76
Round  96, Train loss: 1.178, Test loss: 1.771, Test accuracy: 69.31
Round  97, Train loss: 1.228, Test loss: 1.766, Test accuracy: 69.74
Round  98, Train loss: 1.157, Test loss: 1.771, Test accuracy: 69.21
Round  99, Train loss: 1.178, Test loss: 1.769, Test accuracy: 69.27
Final Round, Train loss: 1.163, Test loss: 1.782, Test accuracy: 68.19
Average accuracy final 10 rounds: 69.60199999999999
1247.1716606616974
[]
[28.66, 41.28, 53.47, 59.47, 62.65, 64.95, 65.84, 69.98, 71.79, 72.61, 73.56, 75.29, 75.52, 74.67, 73.96, 74.04, 74.28, 74.13, 76.7, 77.23, 78.19, 78.1, 78.89, 78.22, 78.61, 78.7, 78.08, 77.26, 77.34, 78.29, 78.25, 78.07, 77.85, 78.24, 78.31, 78.19, 77.69, 77.93, 77.8, 77.5, 77.3, 77.38, 76.69, 76.95, 76.21, 76.9, 76.27, 76.27, 75.95, 74.71, 75.35, 75.34, 75.51, 75.19, 75.32, 75.3, 75.0, 75.4, 75.27, 74.5, 74.91, 74.42, 74.09, 73.83, 73.29, 72.76, 72.65, 72.41, 71.87, 71.96, 72.26, 71.63, 71.28, 70.81, 71.58, 70.86, 70.77, 70.72, 70.79, 70.91, 70.97, 71.05, 70.2, 70.52, 70.29, 70.83, 70.35, 70.01, 69.65, 69.68, 69.05, 70.08, 70.11, 70.22, 69.27, 69.76, 69.31, 69.74, 69.21, 69.27, 68.19]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.280, Test loss: 2.283, Test accuracy: 17.49
Round   1, Train loss: 2.255, Test loss: 2.265, Test accuracy: 18.28
Round   2, Train loss: 2.233, Test loss: 2.251, Test accuracy: 14.63
Round   3, Train loss: 2.116, Test loss: 2.208, Test accuracy: 19.20
Round   4, Train loss: 2.103, Test loss: 2.218, Test accuracy: 17.87
Round   5, Train loss: 2.076, Test loss: 2.188, Test accuracy: 26.18
Round   6, Train loss: 1.906, Test loss: 2.160, Test accuracy: 26.85
Round   7, Train loss: 1.786, Test loss: 2.102, Test accuracy: 36.79
Round   8, Train loss: 1.673, Test loss: 2.114, Test accuracy: 34.47
Round   9, Train loss: 1.577, Test loss: 2.103, Test accuracy: 36.70
Round  10, Train loss: 1.063, Test loss: 1.995, Test accuracy: 48.58
Round  11, Train loss: 1.395, Test loss: 2.034, Test accuracy: 45.42
Round  12, Train loss: 1.082, Test loss: 1.980, Test accuracy: 50.59
Round  13, Train loss: 1.903, Test loss: 2.067, Test accuracy: 40.10
Round  14, Train loss: 0.615, Test loss: 1.966, Test accuracy: 51.33
Round  15, Train loss: 0.413, Test loss: 2.014, Test accuracy: 47.10
Round  16, Train loss: 1.180, Test loss: 2.078, Test accuracy: 41.38
Round  17, Train loss: 0.567, Test loss: 2.000, Test accuracy: 48.42
Round  18, Train loss: 1.309, Test loss: 2.062, Test accuracy: 43.32
Round  19, Train loss: 0.185, Test loss: 2.056, Test accuracy: 42.09
Round  20, Train loss: 1.017, Test loss: 2.068, Test accuracy: 42.58
Round  21, Train loss: 0.124, Test loss: 2.050, Test accuracy: 42.82
Round  22, Train loss: 0.051, Test loss: 1.974, Test accuracy: 49.09
Round  23, Train loss: -0.603, Test loss: 1.917, Test accuracy: 55.22
Round  24, Train loss: -0.472, Test loss: 1.928, Test accuracy: 54.45
Round  25, Train loss: 0.214, Test loss: 2.027, Test accuracy: 45.32
Round  26, Train loss: -0.013, Test loss: 1.974, Test accuracy: 48.34
Round  27, Train loss: -1.672, Test loss: 1.874, Test accuracy: 59.50
Round  28, Train loss: -0.937, Test loss: 1.887, Test accuracy: 60.94
Round  29, Train loss: 0.690, Test loss: 2.016, Test accuracy: 48.71
Round  30, Train loss: -0.057, Test loss: 1.885, Test accuracy: 61.32
Round  31, Train loss: 0.131, Test loss: 1.949, Test accuracy: 57.32
Round  32, Train loss: -0.446, Test loss: 1.888, Test accuracy: 58.86
Round  33, Train loss: -0.585, Test loss: 1.879, Test accuracy: 56.94
Round  34, Train loss: -1.289, Test loss: 1.860, Test accuracy: 59.47
Round  35, Train loss: -0.855, Test loss: 1.816, Test accuracy: 64.38
Round  36, Train loss: -1.255, Test loss: 1.814, Test accuracy: 64.82
Round  37, Train loss: -1.658, Test loss: 1.789, Test accuracy: 66.75
Round  38, Train loss: -1.245, Test loss: 1.793, Test accuracy: 67.81
Round  39, Train loss: -0.799, Test loss: 1.833, Test accuracy: 62.82
Round  40, Train loss: -1.905, Test loss: 1.838, Test accuracy: 61.91
Round  41, Train loss: -0.858, Test loss: 1.836, Test accuracy: 62.92
Round  42, Train loss: -2.543, Test loss: 1.749, Test accuracy: 71.87
Round  43, Train loss: -2.848, Test loss: 1.710, Test accuracy: 75.63
Round  44, Train loss: -1.561, Test loss: 1.716, Test accuracy: 75.25
Round  45, Train loss: -1.429, Test loss: 1.721, Test accuracy: 75.07
Round  46, Train loss: -2.315, Test loss: 1.747, Test accuracy: 73.02
Round  47, Train loss: -3.150, Test loss: 1.716, Test accuracy: 76.50
Round  48, Train loss: -2.599, Test loss: 1.715, Test accuracy: 75.85
Round  49, Train loss: -2.544, Test loss: 1.701, Test accuracy: 77.46
Round  50, Train loss: -2.890, Test loss: 1.688, Test accuracy: 77.92
Round  51, Train loss: -2.562, Test loss: 1.704, Test accuracy: 76.29
Round  52, Train loss: -3.820, Test loss: 1.658, Test accuracy: 80.58
Round  53, Train loss: -3.127, Test loss: 1.674, Test accuracy: 78.91
Round  54, Train loss: -3.564, Test loss: 1.696, Test accuracy: 76.56
Round  55, Train loss: -3.958, Test loss: 1.683, Test accuracy: 77.79
Round  56, Train loss: -4.796, Test loss: 1.664, Test accuracy: 79.72
Round  57, Train loss: -3.248, Test loss: 1.646, Test accuracy: 81.51
Round  58, Train loss: -3.885, Test loss: 1.641, Test accuracy: 82.07
Round  59, Train loss: -3.880, Test loss: 1.636, Test accuracy: 82.47
Round  60, Train loss: -4.454, Test loss: 1.637, Test accuracy: 82.37
Round  61, Train loss: -4.556, Test loss: 1.632, Test accuracy: 82.86
Round  62, Train loss: -3.858, Test loss: 1.662, Test accuracy: 80.20
Round  63, Train loss: -4.234, Test loss: 1.641, Test accuracy: 82.01
Round  64, Train loss: -3.712, Test loss: 1.657, Test accuracy: 80.43
Round  65, Train loss: -2.702, Test loss: 1.693, Test accuracy: 76.73
Round  66, Train loss: -3.162, Test loss: 1.680, Test accuracy: 78.18
Round  67, Train loss: -4.967, Test loss: 1.657, Test accuracy: 80.41
Round  68, Train loss: -2.107, Test loss: 1.646, Test accuracy: 81.53
Round  69, Train loss: -3.701, Test loss: 1.642, Test accuracy: 81.90
Round  70, Train loss: -4.473, Test loss: 1.636, Test accuracy: 82.51
Round  71, Train loss: -4.347, Test loss: 1.638, Test accuracy: 82.28
Round  72, Train loss: -4.331, Test loss: 1.633, Test accuracy: 82.79
Round  73, Train loss: -3.324, Test loss: 1.659, Test accuracy: 80.15
Round  74, Train loss: -3.133, Test loss: 1.662, Test accuracy: 79.75
Round  75, Train loss: -4.147, Test loss: 1.650, Test accuracy: 81.06
Round  76, Train loss: -3.501, Test loss: 1.621, Test accuracy: 83.98
Round  77, Train loss: -3.690, Test loss: 1.622, Test accuracy: 83.88
Round  78, Train loss: -4.595, Test loss: 1.653, Test accuracy: 80.72
Round  79, Train loss: -3.712, Test loss: 1.607, Test accuracy: 85.37
Round  80, Train loss: -4.604, Test loss: 1.621, Test accuracy: 83.93
Round  81, Train loss: -3.228, Test loss: 1.641, Test accuracy: 81.94
Round  82, Train loss: -3.524, Test loss: 1.640, Test accuracy: 81.99
Round  83, Train loss: -4.553, Test loss: 1.651, Test accuracy: 80.92
Round  84, Train loss: -3.756, Test loss: 1.647, Test accuracy: 81.28
Round  85, Train loss: -3.639, Test loss: 1.628, Test accuracy: 83.21
Round  86, Train loss: -3.348, Test loss: 1.627, Test accuracy: 83.26
Round  87, Train loss: -3.790, Test loss: 1.601, Test accuracy: 85.89
Round  88, Train loss: -3.947, Test loss: 1.627, Test accuracy: 83.37
Round  89, Train loss: -4.363, Test loss: 1.637, Test accuracy: 82.34
Round  90, Train loss: -3.306, Test loss: 1.660, Test accuracy: 80.10
Round  91, Train loss: -3.210, Test loss: 1.636, Test accuracy: 82.45
Round  92, Train loss: -3.292, Test loss: 1.640, Test accuracy: 82.05
Round  93, Train loss: -3.870, Test loss: 1.634, Test accuracy: 82.66
Round  94, Train loss: -3.187, Test loss: 1.599, Test accuracy: 86.16
Round  95, Train loss: -3.585, Test loss: 1.614, Test accuracy: 84.68
Round  96, Train loss: -3.639, Test loss: 1.609, Test accuracy: 85.14
Round  97, Train loss: -3.210, Test loss: 1.617, Test accuracy: 84.41
Round  98, Train loss: -2.939, Test loss: 1.616, Test accuracy: 84.49
Round  99, Train loss: -3.393, Test loss: 1.639, Test accuracy: 82.12
Final Round, Train loss: 1.735, Test loss: 1.689, Test accuracy: 78.21
Average accuracy final 10 rounds: 83.426
Average global accuracy final 10 rounds: 83.426
931.1926918029785
[]
[17.49, 18.28, 14.63, 19.2, 17.87, 26.18, 26.85, 36.79, 34.47, 36.7, 48.58, 45.42, 50.59, 40.1, 51.33, 47.1, 41.38, 48.42, 43.32, 42.09, 42.58, 42.82, 49.09, 55.22, 54.45, 45.32, 48.34, 59.5, 60.94, 48.71, 61.32, 57.32, 58.86, 56.94, 59.47, 64.38, 64.82, 66.75, 67.81, 62.82, 61.91, 62.92, 71.87, 75.63, 75.25, 75.07, 73.02, 76.5, 75.85, 77.46, 77.92, 76.29, 80.58, 78.91, 76.56, 77.79, 79.72, 81.51, 82.07, 82.47, 82.37, 82.86, 80.2, 82.01, 80.43, 76.73, 78.18, 80.41, 81.53, 81.9, 82.51, 82.28, 82.79, 80.15, 79.75, 81.06, 83.98, 83.88, 80.72, 85.37, 83.93, 81.94, 81.99, 80.92, 81.28, 83.21, 83.26, 85.89, 83.37, 82.34, 80.1, 82.45, 82.05, 82.66, 86.16, 84.68, 85.14, 84.41, 84.49, 82.12, 78.21]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

prox
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.294, Test loss: 2.296, Test accuracy: 18.33
Round   0, Global train loss: 2.294, Global test loss: 2.301, Global test accuracy: 14.00
Round   1, Train loss: 2.286, Test loss: 2.283, Test accuracy: 23.40
Round   1, Global train loss: 2.286, Global test loss: 2.297, Global test accuracy: 14.02
Round   2, Train loss: 2.213, Test loss: 2.237, Test accuracy: 23.98
Round   2, Global train loss: 2.213, Global test loss: 2.277, Global test accuracy: 14.59
Round   3, Train loss: 2.152, Test loss: 2.184, Test accuracy: 28.30
Round   3, Global train loss: 2.152, Global test loss: 2.269, Global test accuracy: 16.46
Round   4, Train loss: 2.062, Test loss: 2.117, Test accuracy: 37.13
Round   4, Global train loss: 2.062, Global test loss: 2.256, Global test accuracy: 17.44
Round   5, Train loss: 1.985, Test loss: 2.066, Test accuracy: 42.52
Round   5, Global train loss: 1.985, Global test loss: 2.248, Global test accuracy: 20.60
Round   6, Train loss: 1.980, Test loss: 2.002, Test accuracy: 48.41
Round   6, Global train loss: 1.980, Global test loss: 2.240, Global test accuracy: 20.94
Round   7, Train loss: 2.005, Test loss: 1.985, Test accuracy: 49.12
Round   7, Global train loss: 2.005, Global test loss: 2.243, Global test accuracy: 20.83
Round   8, Train loss: 1.918, Test loss: 1.952, Test accuracy: 52.81
Round   8, Global train loss: 1.918, Global test loss: 2.245, Global test accuracy: 20.08
Round   9, Train loss: 1.927, Test loss: 1.937, Test accuracy: 53.82
Round   9, Global train loss: 1.927, Global test loss: 2.254, Global test accuracy: 18.12
Round  10, Train loss: 1.928, Test loss: 1.911, Test accuracy: 56.44
Round  10, Global train loss: 1.928, Global test loss: 2.234, Global test accuracy: 21.52
Round  11, Train loss: 1.839, Test loss: 1.904, Test accuracy: 56.64
Round  11, Global train loss: 1.839, Global test loss: 2.239, Global test accuracy: 20.79
Round  12, Train loss: 1.911, Test loss: 1.887, Test accuracy: 58.40
Round  12, Global train loss: 1.911, Global test loss: 2.242, Global test accuracy: 20.07
Round  13, Train loss: 1.898, Test loss: 1.878, Test accuracy: 59.24
Round  13, Global train loss: 1.898, Global test loss: 2.233, Global test accuracy: 20.72
Round  14, Train loss: 1.854, Test loss: 1.874, Test accuracy: 59.52
Round  14, Global train loss: 1.854, Global test loss: 2.246, Global test accuracy: 19.29
Round  15, Train loss: 1.830, Test loss: 1.871, Test accuracy: 59.66
Round  15, Global train loss: 1.830, Global test loss: 2.235, Global test accuracy: 20.97
Round  16, Train loss: 1.907, Test loss: 1.869, Test accuracy: 59.96
Round  16, Global train loss: 1.907, Global test loss: 2.240, Global test accuracy: 20.14
Round  17, Train loss: 1.861, Test loss: 1.849, Test accuracy: 61.99
Round  17, Global train loss: 1.861, Global test loss: 2.246, Global test accuracy: 19.52
Round  18, Train loss: 1.748, Test loss: 1.848, Test accuracy: 61.97
Round  18, Global train loss: 1.748, Global test loss: 2.234, Global test accuracy: 21.50
Round  19, Train loss: 1.785, Test loss: 1.841, Test accuracy: 62.57
Round  19, Global train loss: 1.785, Global test loss: 2.230, Global test accuracy: 21.83
Round  20, Train loss: 1.908, Test loss: 1.840, Test accuracy: 62.65
Round  20, Global train loss: 1.908, Global test loss: 2.233, Global test accuracy: 21.35
Round  21, Train loss: 1.852, Test loss: 1.838, Test accuracy: 62.80
Round  21, Global train loss: 1.852, Global test loss: 2.240, Global test accuracy: 19.73
Round  22, Train loss: 1.836, Test loss: 1.837, Test accuracy: 62.90
Round  22, Global train loss: 1.836, Global test loss: 2.229, Global test accuracy: 21.75
Round  23, Train loss: 1.908, Test loss: 1.840, Test accuracy: 62.52
Round  23, Global train loss: 1.908, Global test loss: 2.237, Global test accuracy: 21.25
Round  24, Train loss: 1.833, Test loss: 1.839, Test accuracy: 62.65
Round  24, Global train loss: 1.833, Global test loss: 2.235, Global test accuracy: 21.20
Round  25, Train loss: 1.900, Test loss: 1.845, Test accuracy: 61.87
Round  25, Global train loss: 1.900, Global test loss: 2.229, Global test accuracy: 21.97
Round  26, Train loss: 1.822, Test loss: 1.835, Test accuracy: 62.87
Round  26, Global train loss: 1.822, Global test loss: 2.232, Global test accuracy: 21.75
Round  27, Train loss: 1.863, Test loss: 1.834, Test accuracy: 63.00
Round  27, Global train loss: 1.863, Global test loss: 2.245, Global test accuracy: 19.10
Round  28, Train loss: 1.926, Test loss: 1.833, Test accuracy: 63.07
Round  28, Global train loss: 1.926, Global test loss: 2.227, Global test accuracy: 22.59
Round  29, Train loss: 1.806, Test loss: 1.841, Test accuracy: 62.23
Round  29, Global train loss: 1.806, Global test loss: 2.224, Global test accuracy: 22.81
Round  30, Train loss: 1.823, Test loss: 1.851, Test accuracy: 61.10
Round  30, Global train loss: 1.823, Global test loss: 2.229, Global test accuracy: 21.99
Round  31, Train loss: 1.793, Test loss: 1.850, Test accuracy: 61.20
Round  31, Global train loss: 1.793, Global test loss: 2.230, Global test accuracy: 22.18
Round  32, Train loss: 1.816, Test loss: 1.841, Test accuracy: 62.10
Round  32, Global train loss: 1.816, Global test loss: 2.236, Global test accuracy: 21.34
Round  33, Train loss: 1.863, Test loss: 1.835, Test accuracy: 62.76
Round  33, Global train loss: 1.863, Global test loss: 2.248, Global test accuracy: 19.50
Round  34, Train loss: 1.885, Test loss: 1.832, Test accuracy: 63.06
Round  34, Global train loss: 1.885, Global test loss: 2.242, Global test accuracy: 20.36
Round  35, Train loss: 1.790, Test loss: 1.829, Test accuracy: 63.33
Round  35, Global train loss: 1.790, Global test loss: 2.243, Global test accuracy: 20.32
Round  36, Train loss: 1.907, Test loss: 1.829, Test accuracy: 63.40
Round  36, Global train loss: 1.907, Global test loss: 2.237, Global test accuracy: 20.61
Round  37, Train loss: 1.780, Test loss: 1.822, Test accuracy: 64.17
Round  37, Global train loss: 1.780, Global test loss: 2.224, Global test accuracy: 22.74
Round  38, Train loss: 1.850, Test loss: 1.815, Test accuracy: 64.92
Round  38, Global train loss: 1.850, Global test loss: 2.224, Global test accuracy: 22.23
Round  39, Train loss: 1.826, Test loss: 1.821, Test accuracy: 64.21
Round  39, Global train loss: 1.826, Global test loss: 2.226, Global test accuracy: 22.23
Round  40, Train loss: 1.819, Test loss: 1.821, Test accuracy: 64.24
Round  40, Global train loss: 1.819, Global test loss: 2.240, Global test accuracy: 19.98
Round  41, Train loss: 1.776, Test loss: 1.820, Test accuracy: 64.29
Round  41, Global train loss: 1.776, Global test loss: 2.224, Global test accuracy: 22.38
Round  42, Train loss: 1.793, Test loss: 1.819, Test accuracy: 64.40
Round  42, Global train loss: 1.793, Global test loss: 2.229, Global test accuracy: 21.51
Round  43, Train loss: 1.827, Test loss: 1.816, Test accuracy: 64.59
Round  43, Global train loss: 1.827, Global test loss: 2.235, Global test accuracy: 20.98
Round  44, Train loss: 1.828, Test loss: 1.816, Test accuracy: 64.67
Round  44, Global train loss: 1.828, Global test loss: 2.219, Global test accuracy: 22.71
Round  45, Train loss: 1.856, Test loss: 1.816, Test accuracy: 64.56
Round  45, Global train loss: 1.856, Global test loss: 2.221, Global test accuracy: 22.38
Round  46, Train loss: 1.773, Test loss: 1.808, Test accuracy: 65.54
Round  46, Global train loss: 1.773, Global test loss: 2.227, Global test accuracy: 21.83
Round  47, Train loss: 1.859, Test loss: 1.807, Test accuracy: 65.66
Round  47, Global train loss: 1.859, Global test loss: 2.217, Global test accuracy: 22.88
Round  48, Train loss: 1.741, Test loss: 1.807, Test accuracy: 65.68
Round  48, Global train loss: 1.741, Global test loss: 2.245, Global test accuracy: 19.27
Round  49, Train loss: 1.777, Test loss: 1.806, Test accuracy: 65.83
Round  49, Global train loss: 1.777, Global test loss: 2.235, Global test accuracy: 20.93
Round  50, Train loss: 1.858, Test loss: 1.815, Test accuracy: 64.70
Round  50, Global train loss: 1.858, Global test loss: 2.229, Global test accuracy: 21.97
Round  51, Train loss: 1.694, Test loss: 1.816, Test accuracy: 64.65
Round  51, Global train loss: 1.694, Global test loss: 2.219, Global test accuracy: 22.96
Round  52, Train loss: 1.821, Test loss: 1.805, Test accuracy: 65.73
Round  52, Global train loss: 1.821, Global test loss: 2.230, Global test accuracy: 21.38
Round  53, Train loss: 1.911, Test loss: 1.803, Test accuracy: 65.87
Round  53, Global train loss: 1.911, Global test loss: 2.258, Global test accuracy: 17.66
Round  54, Train loss: 1.823, Test loss: 1.803, Test accuracy: 65.94
Round  54, Global train loss: 1.823, Global test loss: 2.223, Global test accuracy: 22.60
Round  55, Train loss: 1.762, Test loss: 1.802, Test accuracy: 65.94
Round  55, Global train loss: 1.762, Global test loss: 2.221, Global test accuracy: 22.60
Round  56, Train loss: 1.837, Test loss: 1.803, Test accuracy: 66.00
Round  56, Global train loss: 1.837, Global test loss: 2.227, Global test accuracy: 21.97
Round  57, Train loss: 1.821, Test loss: 1.803, Test accuracy: 65.92
Round  57, Global train loss: 1.821, Global test loss: 2.225, Global test accuracy: 21.98
Round  58, Train loss: 1.747, Test loss: 1.803, Test accuracy: 65.97
Round  58, Global train loss: 1.747, Global test loss: 2.218, Global test accuracy: 23.12
Round  59, Train loss: 1.785, Test loss: 1.812, Test accuracy: 64.96
Round  59, Global train loss: 1.785, Global test loss: 2.233, Global test accuracy: 20.70
Round  60, Train loss: 1.884, Test loss: 1.812, Test accuracy: 64.96
Round  60, Global train loss: 1.884, Global test loss: 2.224, Global test accuracy: 22.88
Round  61, Train loss: 1.900, Test loss: 1.803, Test accuracy: 65.81
Round  61, Global train loss: 1.900, Global test loss: 2.241, Global test accuracy: 19.71
Round  62, Train loss: 1.844, Test loss: 1.803, Test accuracy: 65.94
Round  62, Global train loss: 1.844, Global test loss: 2.227, Global test accuracy: 22.34
Round  63, Train loss: 1.784, Test loss: 1.804, Test accuracy: 65.83
Round  63, Global train loss: 1.784, Global test loss: 2.235, Global test accuracy: 21.09
Round  64, Train loss: 1.821, Test loss: 1.805, Test accuracy: 65.71
Round  64, Global train loss: 1.821, Global test loss: 2.237, Global test accuracy: 20.22
Round  65, Train loss: 1.814, Test loss: 1.814, Test accuracy: 64.73
Round  65, Global train loss: 1.814, Global test loss: 2.235, Global test accuracy: 20.41
Round  66, Train loss: 1.717, Test loss: 1.815, Test accuracy: 64.67
Round  66, Global train loss: 1.717, Global test loss: 2.238, Global test accuracy: 20.42
Round  67, Train loss: 1.780, Test loss: 1.813, Test accuracy: 64.85
Round  67, Global train loss: 1.780, Global test loss: 2.242, Global test accuracy: 20.08
Round  68, Train loss: 1.841, Test loss: 1.805, Test accuracy: 65.57
Round  68, Global train loss: 1.841, Global test loss: 2.246, Global test accuracy: 19.53
Round  69, Train loss: 1.763, Test loss: 1.797, Test accuracy: 66.56
Round  69, Global train loss: 1.763, Global test loss: 2.230, Global test accuracy: 21.44
Round  70, Train loss: 1.800, Test loss: 1.796, Test accuracy: 66.62
Round  70, Global train loss: 1.800, Global test loss: 2.254, Global test accuracy: 18.16
Round  71, Train loss: 1.956, Test loss: 1.797, Test accuracy: 66.51
Round  71, Global train loss: 1.956, Global test loss: 2.212, Global test accuracy: 23.74
Round  72, Train loss: 1.720, Test loss: 1.796, Test accuracy: 66.58
Round  72, Global train loss: 1.720, Global test loss: 2.227, Global test accuracy: 22.29
Round  73, Train loss: 1.748, Test loss: 1.795, Test accuracy: 66.75
Round  73, Global train loss: 1.748, Global test loss: 2.215, Global test accuracy: 23.48
Round  74, Train loss: 1.726, Test loss: 1.802, Test accuracy: 66.03
Round  74, Global train loss: 1.726, Global test loss: 2.231, Global test accuracy: 21.75
Round  75, Train loss: 1.752, Test loss: 1.802, Test accuracy: 66.00
Round  75, Global train loss: 1.752, Global test loss: 2.230, Global test accuracy: 21.92
Round  76, Train loss: 1.841, Test loss: 1.802, Test accuracy: 66.00
Round  76, Global train loss: 1.841, Global test loss: 2.223, Global test accuracy: 22.93
Round  77, Train loss: 1.846, Test loss: 1.802, Test accuracy: 65.98
Round  77, Global train loss: 1.846, Global test loss: 2.254, Global test accuracy: 18.18
Round  78, Train loss: 1.743, Test loss: 1.802, Test accuracy: 65.89
Round  78, Global train loss: 1.743, Global test loss: 2.241, Global test accuracy: 19.66
Round  79, Train loss: 1.808, Test loss: 1.803, Test accuracy: 65.87
Round  79, Global train loss: 1.808, Global test loss: 2.241, Global test accuracy: 19.63
Round  80, Train loss: 1.842, Test loss: 1.811, Test accuracy: 64.88
Round  80, Global train loss: 1.842, Global test loss: 2.250, Global test accuracy: 18.68
Round  81, Train loss: 1.779, Test loss: 1.819, Test accuracy: 64.02
Round  81, Global train loss: 1.779, Global test loss: 2.221, Global test accuracy: 22.82
Round  82, Train loss: 1.815, Test loss: 1.820, Test accuracy: 63.94
Round  82, Global train loss: 1.815, Global test loss: 2.229, Global test accuracy: 21.55
Round  83, Train loss: 1.733, Test loss: 1.806, Test accuracy: 65.31
Round  83, Global train loss: 1.733, Global test loss: 2.242, Global test accuracy: 19.08
Round  84, Train loss: 1.716, Test loss: 1.802, Test accuracy: 65.79
Round  84, Global train loss: 1.716, Global test loss: 2.237, Global test accuracy: 20.46
Round  85, Train loss: 1.841, Test loss: 1.793, Test accuracy: 66.84
Round  85, Global train loss: 1.841, Global test loss: 2.228, Global test accuracy: 21.60
Round  86, Train loss: 1.873, Test loss: 1.786, Test accuracy: 67.60
Round  86, Global train loss: 1.873, Global test loss: 2.225, Global test accuracy: 21.81
Round  87, Train loss: 1.773, Test loss: 1.792, Test accuracy: 66.96
Round  87, Global train loss: 1.773, Global test loss: 2.222, Global test accuracy: 22.47
Round  88, Train loss: 1.720, Test loss: 1.778, Test accuracy: 68.43
Round  88, Global train loss: 1.720, Global test loss: 2.222, Global test accuracy: 22.51
Round  89, Train loss: 1.793, Test loss: 1.775, Test accuracy: 68.69
Round  89, Global train loss: 1.793, Global test loss: 2.227, Global test accuracy: 21.76
Round  90, Train loss: 1.842, Test loss: 1.776, Test accuracy: 68.71
Round  90, Global train loss: 1.842, Global test loss: 2.224, Global test accuracy: 22.29
Round  91, Train loss: 1.779, Test loss: 1.775, Test accuracy: 68.80
Round  91, Global train loss: 1.779, Global test loss: 2.212, Global test accuracy: 23.46
Round  92, Train loss: 1.729, Test loss: 1.775, Test accuracy: 68.83
Round  92, Global train loss: 1.729, Global test loss: 2.221, Global test accuracy: 23.09
Round  93, Train loss: 1.797, Test loss: 1.777, Test accuracy: 68.51
Round  93, Global train loss: 1.797, Global test loss: 2.224, Global test accuracy: 22.42
Round  94, Train loss: 1.836, Test loss: 1.774, Test accuracy: 68.78
Round  94, Global train loss: 1.836, Global test loss: 2.228, Global test accuracy: 21.40
Round  95, Train loss: 1.724, Test loss: 1.775, Test accuracy: 68.64
Round  95, Global train loss: 1.724, Global test loss: 2.225, Global test accuracy: 22.04/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  96, Train loss: 1.818, Test loss: 1.776, Test accuracy: 68.59
Round  96, Global train loss: 1.818, Global test loss: 2.224, Global test accuracy: 22.14
Round  97, Train loss: 1.717, Test loss: 1.776, Test accuracy: 68.51
Round  97, Global train loss: 1.717, Global test loss: 2.231, Global test accuracy: 21.12
Round  98, Train loss: 1.659, Test loss: 1.775, Test accuracy: 68.61
Round  98, Global train loss: 1.659, Global test loss: 2.227, Global test accuracy: 21.92
Round  99, Train loss: 1.822, Test loss: 1.775, Test accuracy: 68.66
Round  99, Global train loss: 1.822, Global test loss: 2.217, Global test accuracy: 22.77
Final Round, Train loss: 1.745, Test loss: 1.776, Test accuracy: 68.62
Final Round, Global train loss: 1.745, Global test loss: 2.217, Global test accuracy: 22.77
Average accuracy final 10 rounds: 68.66399999999999 

Average global accuracy final 10 rounds: 22.265000000000004 

1490.658281803131
[1.0376760959625244, 2.075352191925049, 3.078634023666382, 4.081915855407715, 4.991257190704346, 5.900598526000977, 6.8230438232421875, 7.745489120483398, 8.667117595672607, 9.588746070861816, 10.72665810585022, 11.864570140838623, 12.943427085876465, 14.022284030914307, 14.938167333602905, 15.854050636291504, 16.71284508705139, 17.57163953781128, 18.441067695617676, 19.310495853424072, 20.165464401245117, 21.020432949066162, 21.873323917388916, 22.72621488571167, 23.60079312324524, 24.47537136077881, 25.30847954750061, 26.141587734222412, 27.03234338760376, 27.923099040985107, 28.772361040115356, 29.621623039245605, 30.51505398750305, 31.408484935760498, 32.33569002151489, 33.26289510726929, 34.20467805862427, 35.14646100997925, 36.20057702064514, 37.254693031311035, 38.51400542259216, 39.77331781387329, 40.97979974746704, 42.18628168106079, 43.176263093948364, 44.16624450683594, 45.39820337295532, 46.63016223907471, 47.93085694313049, 49.23155164718628, 50.14870572090149, 51.0658597946167, 51.93965983390808, 52.81345987319946, 53.753867864608765, 54.694275856018066, 55.61078977584839, 56.52730369567871, 57.44287109375, 58.35843849182129, 59.32601737976074, 60.293596267700195, 61.25205421447754, 62.21051216125488, 63.14671206474304, 64.0829119682312, 65.19413256645203, 66.30535316467285, 67.14903616905212, 67.9927191734314, 68.88175201416016, 69.77078485488892, 70.6801209449768, 71.5894570350647, 72.5807249546051, 73.57199287414551, 74.46896529197693, 75.36593770980835, 76.3966817855835, 77.42742586135864, 78.34251141548157, 79.25759696960449, 80.21620607376099, 81.17481517791748, 82.30649757385254, 83.4381799697876, 84.45233464241028, 85.46648931503296, 86.39506673812866, 87.32364416122437, 88.46833038330078, 89.6130166053772, 90.81141567230225, 92.0098147392273, 92.95043301582336, 93.89105129241943, 94.81750845909119, 95.74396562576294, 96.9767394065857, 98.20951318740845, 99.48051357269287, 100.7515139579773, 101.90999627113342, 103.06847858428955, 103.97697591781616, 104.88547325134277, 105.77866315841675, 106.67185306549072, 107.85471940040588, 109.03758573532104, 110.19520711898804, 111.35282850265503, 112.52573728561401, 113.698646068573, 114.85082292556763, 116.00299978256226, 117.25328254699707, 118.50356531143188, 119.55430364608765, 120.60504198074341, 121.6974184513092, 122.789794921875, 123.75216507911682, 124.71453523635864, 125.6876802444458, 126.66082525253296, 127.59518265724182, 128.52954006195068, 129.47145462036133, 130.41336917877197, 131.34687733650208, 132.28038549423218, 133.27318334579468, 134.26598119735718, 135.2579803466797, 136.2499794960022, 137.2565245628357, 138.2630696296692, 139.2530677318573, 140.2430658340454, 141.21520376205444, 142.18734169006348, 143.19226551055908, 144.1971893310547, 145.13081169128418, 146.06443405151367, 147.05673575401306, 148.04903745651245, 149.03134059906006, 150.01364374160767, 150.9905481338501, 151.96745252609253, 152.97564673423767, 153.9838409423828, 154.94907879829407, 155.91431665420532, 156.90063738822937, 157.88695812225342, 159.124840259552, 160.3627223968506, 161.54251384735107, 162.72230529785156, 163.68437480926514, 164.6464443206787, 165.59541296958923, 166.54438161849976, 167.79131293296814, 169.03824424743652, 170.00089597702026, 170.963547706604, 172.09582829475403, 173.22810888290405, 174.43709921836853, 175.646089553833, 176.90878200531006, 178.1714744567871, 179.32535910606384, 180.47924375534058, 181.6796636581421, 182.8800835609436, 183.868266582489, 184.85644960403442, 185.81972670555115, 186.78300380706787, 187.7331817150116, 188.68335962295532, 189.95873498916626, 191.2341103553772, 192.17103219032288, 193.10795402526855, 194.10153317451477, 195.095112323761, 196.1495578289032, 197.2040033340454, 198.1435582637787, 199.08311319351196, 199.99252343177795, 200.90193367004395, 202.12754368782043, 203.35315370559692, 205.6042823791504, 207.85541105270386]
[18.33, 18.33, 23.4, 23.4, 23.98, 23.98, 28.3, 28.3, 37.13, 37.13, 42.52, 42.52, 48.41, 48.41, 49.12, 49.12, 52.81, 52.81, 53.82, 53.82, 56.44, 56.44, 56.64, 56.64, 58.4, 58.4, 59.24, 59.24, 59.52, 59.52, 59.66, 59.66, 59.96, 59.96, 61.99, 61.99, 61.97, 61.97, 62.57, 62.57, 62.65, 62.65, 62.8, 62.8, 62.9, 62.9, 62.52, 62.52, 62.65, 62.65, 61.87, 61.87, 62.87, 62.87, 63.0, 63.0, 63.07, 63.07, 62.23, 62.23, 61.1, 61.1, 61.2, 61.2, 62.1, 62.1, 62.76, 62.76, 63.06, 63.06, 63.33, 63.33, 63.4, 63.4, 64.17, 64.17, 64.92, 64.92, 64.21, 64.21, 64.24, 64.24, 64.29, 64.29, 64.4, 64.4, 64.59, 64.59, 64.67, 64.67, 64.56, 64.56, 65.54, 65.54, 65.66, 65.66, 65.68, 65.68, 65.83, 65.83, 64.7, 64.7, 64.65, 64.65, 65.73, 65.73, 65.87, 65.87, 65.94, 65.94, 65.94, 65.94, 66.0, 66.0, 65.92, 65.92, 65.97, 65.97, 64.96, 64.96, 64.96, 64.96, 65.81, 65.81, 65.94, 65.94, 65.83, 65.83, 65.71, 65.71, 64.73, 64.73, 64.67, 64.67, 64.85, 64.85, 65.57, 65.57, 66.56, 66.56, 66.62, 66.62, 66.51, 66.51, 66.58, 66.58, 66.75, 66.75, 66.03, 66.03, 66.0, 66.0, 66.0, 66.0, 65.98, 65.98, 65.89, 65.89, 65.87, 65.87, 64.88, 64.88, 64.02, 64.02, 63.94, 63.94, 65.31, 65.31, 65.79, 65.79, 66.84, 66.84, 67.6, 67.6, 66.96, 66.96, 68.43, 68.43, 68.69, 68.69, 68.71, 68.71, 68.8, 68.8, 68.83, 68.83, 68.51, 68.51, 68.78, 68.78, 68.64, 68.64, 68.59, 68.59, 68.51, 68.51, 68.61, 68.61, 68.66, 68.66, 68.62, 68.62]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
Round   0, Train loss: 2.299, Test loss: 2.301, Test accuracy: 11.25
Round   1, Train loss: 2.290, Test loss: 2.298, Test accuracy: 12.07
Round   2, Train loss: 2.252, Test loss: 2.297, Test accuracy: 12.76
Round   3, Train loss: 2.150, Test loss: 2.291, Test accuracy: 13.27
Round   4, Train loss: 2.036, Test loss: 2.288, Test accuracy: 14.54
Round   5, Train loss: 2.033, Test loss: 2.283, Test accuracy: 15.77
Round   6, Train loss: 1.975, Test loss: 2.286, Test accuracy: 14.00
Round   7, Train loss: 2.043, Test loss: 2.284, Test accuracy: 15.12
Round   8, Train loss: 1.918, Test loss: 2.273, Test accuracy: 15.61
Round   9, Train loss: 1.900, Test loss: 2.270, Test accuracy: 16.84
Round  10, Train loss: 1.826, Test loss: 2.261, Test accuracy: 18.25
Round  11, Train loss: 1.925, Test loss: 2.273, Test accuracy: 16.57
Round  12, Train loss: 1.828, Test loss: 2.267, Test accuracy: 17.56
Round  13, Train loss: 1.756, Test loss: 2.267, Test accuracy: 17.39
Round  14, Train loss: 1.785, Test loss: 2.268, Test accuracy: 17.57
Round  15, Train loss: 1.816, Test loss: 2.280, Test accuracy: 16.21
Round  16, Train loss: 1.753, Test loss: 2.261, Test accuracy: 18.35
Round  17, Train loss: 1.755, Test loss: 2.272, Test accuracy: 16.51
Round  18, Train loss: 1.790, Test loss: 2.269, Test accuracy: 17.23
Round  19, Train loss: 1.793, Test loss: 2.282, Test accuracy: 15.78
Round  20, Train loss: 1.756, Test loss: 2.267, Test accuracy: 17.78
Round  21, Train loss: 1.695, Test loss: 2.258, Test accuracy: 18.53
Round  22, Train loss: 1.787, Test loss: 2.251, Test accuracy: 19.09
Round  23, Train loss: 1.727, Test loss: 2.259, Test accuracy: 18.48
Round  24, Train loss: 1.736, Test loss: 2.261, Test accuracy: 18.28
Round  25, Train loss: 1.728, Test loss: 2.262, Test accuracy: 18.35
Round  26, Train loss: 1.664, Test loss: 2.263, Test accuracy: 18.20
Round  27, Train loss: 1.755, Test loss: 2.263, Test accuracy: 18.48
Round  28, Train loss: 1.762, Test loss: 2.267, Test accuracy: 17.29
Round  29, Train loss: 1.799, Test loss: 2.257, Test accuracy: 18.62
Round  30, Train loss: 1.676, Test loss: 2.274, Test accuracy: 17.37
Round  31, Train loss: 1.749, Test loss: 2.263, Test accuracy: 18.20
Round  32, Train loss: 1.720, Test loss: 2.276, Test accuracy: 17.05
Round  33, Train loss: 1.722, Test loss: 2.273, Test accuracy: 17.03
Round  34, Train loss: 1.681, Test loss: 2.269, Test accuracy: 17.40
Round  35, Train loss: 1.763, Test loss: 2.282, Test accuracy: 16.21
Round  36, Train loss: 1.743, Test loss: 2.264, Test accuracy: 17.88
Round  37, Train loss: 1.720, Test loss: 2.264, Test accuracy: 17.92
Round  38, Train loss: 1.690, Test loss: 2.277, Test accuracy: 16.41
Round  39, Train loss: 1.671, Test loss: 2.254, Test accuracy: 19.35
Round  40, Train loss: 1.644, Test loss: 2.263, Test accuracy: 18.00
Round  41, Train loss: 1.766, Test loss: 2.265, Test accuracy: 17.96
Round  42, Train loss: 1.672, Test loss: 2.267, Test accuracy: 17.85
Round  43, Train loss: 1.707, Test loss: 2.263, Test accuracy: 17.86
Round  44, Train loss: 1.738, Test loss: 2.258, Test accuracy: 18.48
Round  45, Train loss: 1.643, Test loss: 2.254, Test accuracy: 19.14
Round  46, Train loss: 1.696, Test loss: 2.249, Test accuracy: 19.46
Round  47, Train loss: 1.733, Test loss: 2.252, Test accuracy: 19.01
Round  48, Train loss: 1.729, Test loss: 2.273, Test accuracy: 17.03
Round  49, Train loss: 1.648, Test loss: 2.257, Test accuracy: 18.70
Round  50, Train loss: 1.645, Test loss: 2.264, Test accuracy: 17.41
Round  51, Train loss: 1.612, Test loss: 2.254, Test accuracy: 19.19
Round  52, Train loss: 1.848, Test loss: 2.262, Test accuracy: 18.34
Round  53, Train loss: 1.682, Test loss: 2.271, Test accuracy: 16.87
Round  54, Train loss: 1.675, Test loss: 2.262, Test accuracy: 17.80
Round  55, Train loss: 1.753, Test loss: 2.272, Test accuracy: 17.07
Round  56, Train loss: 1.697, Test loss: 2.258, Test accuracy: 18.51
Round  57, Train loss: 1.761, Test loss: 2.251, Test accuracy: 19.36
Round  58, Train loss: 1.666, Test loss: 2.259, Test accuracy: 18.63
Round  59, Train loss: 1.659, Test loss: 2.273, Test accuracy: 16.92
Round  60, Train loss: 1.657, Test loss: 2.258, Test accuracy: 18.54
Round  61, Train loss: 1.756, Test loss: 2.254, Test accuracy: 18.71
Round  62, Train loss: 1.623, Test loss: 2.258, Test accuracy: 18.42
Round  63, Train loss: 1.662, Test loss: 2.255, Test accuracy: 18.53
Round  64, Train loss: 1.689, Test loss: 2.260, Test accuracy: 18.20
Round  65, Train loss: 1.629, Test loss: 2.271, Test accuracy: 17.59
Round  66, Train loss: 1.689, Test loss: 2.263, Test accuracy: 18.10
Round  67, Train loss: 1.592, Test loss: 2.263, Test accuracy: 17.92
Round  68, Train loss: 1.612, Test loss: 2.262, Test accuracy: 18.25
Round  69, Train loss: 1.675, Test loss: 2.253, Test accuracy: 18.46
Round  70, Train loss: 1.685, Test loss: 2.247, Test accuracy: 19.61
Round  71, Train loss: 1.636, Test loss: 2.251, Test accuracy: 18.99
Round  72, Train loss: 1.667, Test loss: 2.268, Test accuracy: 17.14
Round  73, Train loss: 1.692, Test loss: 2.257, Test accuracy: 18.39
Round  74, Train loss: 1.638, Test loss: 2.274, Test accuracy: 16.98
Round  75, Train loss: 1.696, Test loss: 2.262, Test accuracy: 17.93
Round  76, Train loss: 1.634, Test loss: 2.256, Test accuracy: 18.55
Round  77, Train loss: 1.601, Test loss: 2.253, Test accuracy: 19.01
Round  78, Train loss: 1.656, Test loss: 2.261, Test accuracy: 17.63
Round  79, Train loss: 1.689, Test loss: 2.254, Test accuracy: 18.68
Round  80, Train loss: 1.662, Test loss: 2.262, Test accuracy: 17.98
Round  81, Train loss: 1.569, Test loss: 2.271, Test accuracy: 17.49
Round  82, Train loss: 1.598, Test loss: 2.245, Test accuracy: 20.32
Round  83, Train loss: 1.602, Test loss: 2.251, Test accuracy: 19.49
Round  84, Train loss: 1.601, Test loss: 2.256, Test accuracy: 18.66
Round  85, Train loss: 1.606, Test loss: 2.272, Test accuracy: 16.73
Round  86, Train loss: 1.648, Test loss: 2.250, Test accuracy: 19.59
Round  87, Train loss: 1.598, Test loss: 2.245, Test accuracy: 19.65
Round  88, Train loss: 1.589, Test loss: 2.247, Test accuracy: 19.62
Round  89, Train loss: 1.599, Test loss: 2.248, Test accuracy: 19.84
Round  90, Train loss: 1.608, Test loss: 2.261, Test accuracy: 18.29
Round  91, Train loss: 1.666, Test loss: 2.262, Test accuracy: 17.85
Round  92, Train loss: 1.662, Test loss: 2.250, Test accuracy: 19.53
Round  93, Train loss: 1.591, Test loss: 2.247, Test accuracy: 19.83
Round  94, Train loss: 1.588, Test loss: 2.254, Test accuracy: 19.09
Round  95, Train loss: 1.682, Test loss: 2.254, Test accuracy: 19.13
Round  96, Train loss: 1.642, Test loss: 2.238, Test accuracy: 20.88
Round  97, Train loss: 1.605, Test loss: 2.251, Test accuracy: 19.26
Round  98, Train loss: 1.663, Test loss: 2.259, Test accuracy: 18.93
Round  99, Train loss: 1.590, Test loss: 2.257, Test accuracy: 18.49
Final Round, Train loss: 1.605, Test loss: 2.237, Test accuracy: 20.64
Average accuracy final 10 rounds: 19.128
1610.3048861026764
[2.4107983112335205, 4.692083835601807, 7.042697191238403, 9.344190835952759, 11.627159833908081, 13.983634233474731, 16.365633726119995, 18.750228881835938, 21.05439805984497, 23.36127781867981, 25.69701099395752, 27.976529598236084, 30.291192293167114, 32.60964775085449, 34.88566970825195, 37.04766345024109, 39.136208057403564, 41.28101205825806, 43.46626687049866, 45.581509828567505, 47.75303387641907, 49.88898587226868, 52.01308059692383, 54.17577409744263, 56.31184673309326, 58.47693109512329, 60.65451002120972, 62.82746767997742, 65.01278901100159, 67.14569640159607, 69.2826931476593, 71.45451474189758, 73.62035632133484, 75.81827354431152, 77.99108982086182, 80.10524153709412, 82.28645491600037, 84.43495965003967, 86.64532017707825, 88.76780152320862, 90.88872408866882, 93.02196455001831, 95.18912863731384, 97.30830430984497, 99.46264243125916, 101.67155075073242, 103.821613073349, 106.00834584236145, 108.14266562461853, 110.32040238380432, 112.48869919776917, 114.63279485702515, 116.80579543113708, 118.97806000709534, 121.08334279060364, 123.22980403900146, 125.37224507331848, 127.53650617599487, 129.70021057128906, 131.85246920585632, 134.03793621063232, 136.18799018859863, 138.31404447555542, 140.48108530044556, 142.6385407447815, 144.85255575180054, 146.99551558494568, 149.14439463615417, 151.31708669662476, 153.52788043022156, 155.6820411682129, 157.87788796424866, 160.0256164073944, 162.23980379104614, 164.3783152103424, 166.50173592567444, 168.70417094230652, 170.84059834480286, 173.00107073783875, 175.18359851837158, 177.4319908618927, 179.6001627445221, 181.75078177452087, 183.92204785346985, 186.14545512199402, 188.30203413963318, 190.47474765777588, 192.6349594593048, 194.79701280593872, 197.02660155296326, 199.217120885849, 201.40273451805115, 203.5673315525055, 205.73245310783386, 207.82882928848267, 209.9424159526825, 212.08128380775452, 214.20647859573364, 216.37170553207397, 218.51839208602905, 220.80832958221436]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[11.25, 12.07, 12.76, 13.27, 14.54, 15.77, 14.0, 15.12, 15.61, 16.84, 18.25, 16.57, 17.56, 17.39, 17.57, 16.21, 18.35, 16.51, 17.23, 15.78, 17.78, 18.53, 19.09, 18.48, 18.28, 18.35, 18.2, 18.48, 17.29, 18.62, 17.37, 18.2, 17.05, 17.03, 17.4, 16.21, 17.88, 17.92, 16.41, 19.35, 18.0, 17.96, 17.85, 17.86, 18.48, 19.14, 19.46, 19.01, 17.03, 18.7, 17.41, 19.19, 18.34, 16.87, 17.8, 17.07, 18.51, 19.36, 18.63, 16.92, 18.54, 18.71, 18.42, 18.53, 18.2, 17.59, 18.1, 17.92, 18.25, 18.46, 19.61, 18.99, 17.14, 18.39, 16.98, 17.93, 18.55, 19.01, 17.63, 18.68, 17.98, 17.49, 20.32, 19.49, 18.66, 16.73, 19.59, 19.65, 19.62, 19.84, 18.29, 17.85, 19.53, 19.83, 19.09, 19.13, 20.88, 19.26, 18.93, 18.49, 20.64]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 400, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.303, Test loss: 2.303, Test accuracy: 7.78
Round   0, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.75
Round   1, Train loss: 2.303, Test loss: 2.303, Test accuracy: 7.82
Round   1, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.75
Round   2, Train loss: 2.303, Test loss: 2.303, Test accuracy: 7.87
Round   2, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.75
Round   3, Train loss: 2.303, Test loss: 2.303, Test accuracy: 7.88
Round   3, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.75
Round   4, Train loss: 2.302, Test loss: 2.303, Test accuracy: 7.92
Round   4, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.75
Round   5, Train loss: 2.305, Test loss: 2.303, Test accuracy: 7.92
Round   5, Global train loss: 2.305, Global test loss: 2.303, Global test accuracy: 7.75
Round   6, Train loss: 2.302, Test loss: 2.303, Test accuracy: 7.96
Round   6, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.76
Round   7, Train loss: 2.304, Test loss: 2.303, Test accuracy: 7.93
Round   7, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 7.77
Round   8, Train loss: 2.302, Test loss: 2.303, Test accuracy: 7.95
Round   8, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.76
Round   9, Train loss: 2.302, Test loss: 2.303, Test accuracy: 7.97
Round   9, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.79
Round  10, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.04
Round  10, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.80
Round  11, Train loss: 2.304, Test loss: 2.303, Test accuracy: 8.00
Round  11, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 7.81
Round  12, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.02
Round  12, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.79
Round  13, Train loss: 2.302, Test loss: 2.303, Test accuracy: 7.98
Round  13, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.78
Round  14, Train loss: 2.302, Test loss: 2.303, Test accuracy: 7.96
Round  14, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.81
Round  15, Train loss: 2.303, Test loss: 2.303, Test accuracy: 7.98
Round  15, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.82
Round  16, Train loss: 2.304, Test loss: 2.303, Test accuracy: 7.99
Round  16, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 7.86
Round  17, Train loss: 2.302, Test loss: 2.303, Test accuracy: 7.98
Round  17, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.89
Round  18, Train loss: 2.302, Test loss: 2.303, Test accuracy: 7.95
Round  18, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.86
Round  19, Train loss: 2.304, Test loss: 2.303, Test accuracy: 8.00
Round  19, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 7.90
Round  20, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.06
Round  20, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.91
Round  21, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.07
Round  21, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.92
Round  22, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.10
Round  22, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.92
Round  23, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.15
Round  23, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.94
Round  24, Train loss: 2.304, Test loss: 2.303, Test accuracy: 8.16
Round  24, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 7.98
Round  25, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.17
Round  25, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.98
Round  26, Train loss: 2.304, Test loss: 2.303, Test accuracy: 8.18
Round  26, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 8.00
Round  27, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.16
Round  27, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.01
Round  28, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.17
Round  28, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.03
Round  29, Train loss: 2.304, Test loss: 2.303, Test accuracy: 8.14
Round  29, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 8.03
Round  30, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.17
Round  30, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.00
Round  31, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.19
Round  31, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.01
Round  32, Train loss: 2.304, Test loss: 2.303, Test accuracy: 8.24
Round  32, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 8.04
Round  33, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.26
Round  33, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.09
Round  34, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.26
Round  34, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.09
Round  35, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.25
Round  35, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.09
Round  36, Train loss: 2.301, Test loss: 2.303, Test accuracy: 8.25
Round  36, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 8.04
Round  37, Train loss: 2.301, Test loss: 2.303, Test accuracy: 8.28
Round  37, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 8.10
Round  38, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.30
Round  38, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.11
Round  39, Train loss: 2.304, Test loss: 2.303, Test accuracy: 8.30
Round  39, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 8.10
Round  40, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.28
Round  40, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.11
Round  41, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.26
Round  41, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.13
Round  42, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.25
Round  42, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.16
Round  43, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.26
Round  43, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.18
Round  44, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.25
Round  44, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.18
Round  45, Train loss: 2.301, Test loss: 2.303, Test accuracy: 8.30
Round  45, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 8.20
Round  46, Train loss: 2.304, Test loss: 2.303, Test accuracy: 8.40
Round  46, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 8.24
Round  47, Train loss: 2.301, Test loss: 2.303, Test accuracy: 8.45
Round  47, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 8.23
Round  48, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.44
Round  48, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.23
Round  49, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.43
Round  49, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.27
Round  50, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.41
Round  50, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.25
Round  51, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.46
Round  51, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.25
Round  52, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.46
Round  52, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.28
Round  53, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.45
Round  53, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.32
Round  54, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.51
Round  54, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.35
Round  55, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.53
Round  55, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.35
Round  56, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.56
Round  56, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.32
Round  57, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.61
Round  57, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.33
Round  58, Train loss: 2.304, Test loss: 2.302, Test accuracy: 8.59
Round  58, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 8.38
Round  59, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.68
Round  59, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.38
Round  60, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.69
Round  60, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.39
Round  61, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.64
Round  61, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.44
Round  62, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.67
Round  62, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.53
Round  63, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.70
Round  63, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.50
Round  64, Train loss: 2.301, Test loss: 2.302, Test accuracy: 8.66
Round  64, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 8.49
Round  65, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.70
Round  65, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.43
Round  66, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.78
Round  66, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.47
Round  67, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.79
Round  67, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.46
Round  68, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.78
Round  68, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.46
Round  69, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.77
Round  69, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.55
Round  70, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.80
Round  70, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.54
Round  71, Train loss: 2.301, Test loss: 2.302, Test accuracy: 8.80
Round  71, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 8.63
Round  72, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.85
Round  72, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.66
Round  73, Train loss: 2.301, Test loss: 2.302, Test accuracy: 8.86
Round  73, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 8.64
Round  74, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.89
Round  74, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.66
Round  75, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.83
Round  75, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.77
Round  76, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.86
Round  76, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 8.70
Round  77, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.87
Round  77, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.79
Round  78, Train loss: 2.301, Test loss: 2.302, Test accuracy: 8.88
Round  78, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 8.80
Round  79, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.95
Round  79, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 8.76
Round  80, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.02
Round  80, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 8.79
Round  81, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.04
Round  81, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.82
Round  82, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.00
Round  82, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 8.83
Round  83, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.03
Round  83, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 8.75
Round  84, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.04
Round  84, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.88
Round  85, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.06
Round  85, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 8.83
Round  86, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.07
Round  86, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.90
Round  87, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.08
Round  87, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 8.91
Round  88, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.09
Round  88, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.93
Round  89, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.09
Round  89, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.93
Round  90, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.20
Round  90, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.99
Round  91, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.18
Round  91, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.98
Round  92, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.31
Round  92, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.04
Round  93, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.37
Round  93, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.11
Round  94, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.29
Round  94, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.11
Round  95, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.33
Round  95, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.16
Round  96, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.36
Round  96, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.16
Round  97, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.39
Round  97, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.20
Round  98, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.53
Round  98, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.20
Round  99, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.50
Round  99, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.24
Round 100, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.48
Round 100, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.26
Round 101, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.50
Round 101, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.25
Round 102, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.50
Round 102, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.31
Round 103, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.54
Round 103, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.32
Round 104, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.62
Round 104, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.45
Round 105, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.70
Round 105, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.50
Round 106, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.80
Round 106, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.50
Round 107, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.74
Round 107, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.52
Round 108, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.71
Round 108, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.55
Round 109, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.74
Round 109, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.51
Round 110, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.77
Round 110, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.51
Round 111, Train loss: 2.304, Test loss: 2.302, Test accuracy: 9.77
Round 111, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 9.56
Round 112, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.78
Round 112, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.54
Round 113, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.77
Round 113, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.62
Round 114, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.79
Round 114, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.62
Round 115, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.87
Round 115, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.60
Round 116, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.90
Round 116, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.58
Round 117, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.92
Round 117, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.65
Round 118, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.99
Round 118, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.64
Round 119, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.04
Round 119, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.74
Round 120, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.04
Round 120, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.75
Round 121, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.12
Round 121, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.76
Round 122, Train loss: 2.300, Test loss: 2.302, Test accuracy: 10.18
Round 122, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 9.80
Round 123, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.20
Round 123, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.79
Round 124, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.14
Round 124, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.80
Round 125, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.09
Round 125, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.80
Round 126, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.07
Round 126, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.81
Round 127, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.09
Round 127, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.82
Round 128, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.11
Round 128, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.85
Round 129, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.07
Round 129, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.89
Round 130, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.13
Round 130, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.90
Round 131, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.21
Round 131, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.93
Round 132, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.30
Round 132, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.04
Round 133, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.20
Round 133, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.02
Round 134, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.28
Round 134, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.09
Round 135, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.35
Round 135, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.07
Round 136, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.40
Round 136, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.10
Round 137, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.40
Round 137, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.14
Round 138, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.45
Round 138, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.16
Round 139, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.52
Round 139, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.18
Round 140, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.55
Round 140, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.20
Round 141, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.52
Round 141, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.22
Round 142, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.52
Round 142, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.23
Round 143, Train loss: 2.304, Test loss: 2.302, Test accuracy: 10.53
Round 143, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 10.22
Round 144, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.54
Round 144, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.25
Round 145, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.54
Round 145, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.27
Round 146, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.55
Round 146, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.20
Round 147, Train loss: 2.300, Test loss: 2.302, Test accuracy: 10.58
Round 147, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 10.29
Round 148, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.67
Round 148, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.28
Round 149, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.61
Round 149, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.27
Round 150, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.62
Round 150, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.29
Round 151, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.64
Round 151, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.30
Round 152, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.58
Round 152, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.37
Round 153, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.65
Round 153, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.36
Round 154, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.69
Round 154, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.39
Round 155, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.64
Round 155, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.34
Round 156, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.66
Round 156, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.40
Round 157, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.68
Round 157, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.40
Round 158, Train loss: 2.300, Test loss: 2.302, Test accuracy: 10.74
Round 158, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 10.44
Round 159, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.76
Round 159, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.40
Round 160, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.80
Round 160, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.46
Round 161, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.86
Round 161, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.49
Round 162, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.92
Round 162, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.48
Round 163, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.94
Round 163, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.45
Round 164, Train loss: 2.300, Test loss: 2.302, Test accuracy: 10.91
Round 164, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 10.49
Round 165, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.97
Round 165, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.59
Round 166, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.95
Round 166, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.68
Round 167, Train loss: 2.304, Test loss: 2.302, Test accuracy: 10.98
Round 167, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 10.72
Round 168, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.99
Round 168, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.76
Round 169, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.04
Round 169, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.74
Round 170, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.11
Round 170, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.76
Round 171, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.14
Round 171, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.76
Round 172, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.17
Round 172, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.78
Round 173, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.19
Round 173, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.80
Round 174, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.17
Round 174, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.78
Round 175, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.15
Round 175, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.88
Round 176, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.20
Round 176, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.89
Round 177, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.17
Round 177, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.86
Round 178, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.17
Round 178, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.89
Round 179, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.22
Round 179, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.99
Round 180, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.32
Round 180, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.98
Round 181, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.28
Round 181, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.04
Round 182, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.39
Round 182, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.14
Round 183, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.43
Round 183, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.12
Round 184, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.47
Round 184, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.22
Round 185, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.49
Round 185, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.31
Round 186, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.56
Round 186, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.37
Round 187, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.62
Round 187, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.41
Round 188, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.68
Round 188, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.42
Round 189, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.73
Round 189, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.51
Round 190, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.77
Round 190, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.55
Round 191, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.80
Round 191, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.58
Round 192, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.84
Round 192, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.63
Round 193, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.89
Round 193, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.59
Round 194, Train loss: 2.300, Test loss: 2.302, Test accuracy: 11.98
Round 194, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 11.60
Round 195, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.98
Round 195, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.62
Round 196, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.01
Round 196, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.63
Round 197, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.03
Round 197, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.65
Round 198, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.10
Round 198, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.75
Round 199, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.15
Round 199, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.72
Round 200, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.19
Round 200, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.73
Round 201, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.15
Round 201, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.77
Round 202, Train loss: 2.300, Test loss: 2.302, Test accuracy: 12.17
Round 202, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 11.78
Round 203, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.20
Round 203, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.86
Round 204, Train loss: 2.300, Test loss: 2.302, Test accuracy: 12.19
Round 204, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 11.88
Round 205, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.22
Round 205, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.02
Round 206, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.29
Round 206, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.16
Round 207, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.27
Round 207, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.10
Round 208, Train loss: 2.300, Test loss: 2.302, Test accuracy: 12.41
Round 208, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 12.19
Round 209, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.42
Round 209, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.15
Round 210, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.42
Round 210, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.18
Round 211, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.54
Round 211, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.23
Round 212, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.57
Round 212, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.21
Round 213, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.56
Round 213, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.22
Round 214, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.58
Round 214, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.24
Round 215, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.57
Round 215, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.19
Round 216, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.58
Round 216, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.22
Round 217, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.59
Round 217, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.28
Round 218, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.61
Round 218, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.33
Round 219, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.61
Round 219, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.31
Round 220, Train loss: 2.300, Test loss: 2.302, Test accuracy: 12.66
Round 220, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 12.36
Round 221, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.61
Round 221, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.41
Round 222, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.69
Round 222, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.46
Round 223, Train loss: 2.304, Test loss: 2.302, Test accuracy: 12.68
Round 223, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 12.39
Round 224, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.74
Round 224, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.44
Round 225, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.78
Round 225, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.48
Round 226, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.85
Round 226, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.53
Round 227, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.88
Round 227, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.57
Round 228, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.95
Round 228, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.61
Round 229, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.94
Round 229, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.67
Round 230, Train loss: 2.303, Test loss: 2.302, Test accuracy: 12.94
Round 230, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.71
Round 231, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.97
Round 231, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.72
Round 232, Train loss: 2.302, Test loss: 2.302, Test accuracy: 12.94
Round 232, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.73
Round 233, Train loss: 2.301, Test loss: 2.302, Test accuracy: 12.96
Round 233, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.75
Round 234, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.02
Round 234, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.78
Round 235, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.01
Round 235, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.79
Round 236, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.03
Round 236, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.80
Round 237, Train loss: 2.303, Test loss: 2.302, Test accuracy: 13.04
Round 237, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.85
Round 238, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.10
Round 238, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.82
Round 239, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.13
Round 239, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 12.87
Round 240, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.13
Round 240, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.92
Round 241, Train loss: 2.303, Test loss: 2.302, Test accuracy: 13.20
Round 241, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.91
Round 242, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.21
Round 242, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.97
Round 243, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.25
Round 243, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.96
Round 244, Train loss: 2.300, Test loss: 2.302, Test accuracy: 13.24
Round 244, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 12.99
Round 245, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.28
Round 245, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.96
Round 246, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.26
Round 246, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.96
Round 247, Train loss: 2.303, Test loss: 2.302, Test accuracy: 13.28
Round 247, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 12.98
Round 248, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.24
Round 248, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.96
Round 249, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.20
Round 249, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 12.96
Round 250, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.28
Round 250, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.00
Round 251, Train loss: 2.300, Test loss: 2.302, Test accuracy: 13.37
Round 251, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 12.95
Round 252, Train loss: 2.300, Test loss: 2.302, Test accuracy: 13.41
Round 252, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.00
Round 253, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.44
Round 253, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.13
Round 254, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.49
Round 254, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.13
Round 255, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.44
Round 255, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.14
Round 256, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.45
Round 256, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.16
Round 257, Train loss: 2.300, Test loss: 2.302, Test accuracy: 13.43
Round 257, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.20
Round 258, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.47
Round 258, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.25
Round 259, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.47
Round 259, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.31
Round 260, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.67
Round 260, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.32
Round 261, Train loss: 2.300, Test loss: 2.302, Test accuracy: 13.66
Round 261, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.32
Round 262, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.71
Round 262, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.38
Round 263, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.71
Round 263, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.31
Round 264, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.70
Round 264, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.39
Round 265, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.68
Round 265, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.37
Round 266, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.73
Round 266, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.39
Round 267, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.76
Round 267, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.45
Round 268, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.76
Round 268, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.49
Round 269, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.84
Round 269, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.49
Round 270, Train loss: 2.301, Test loss: 2.302, Test accuracy: 13.82
Round 270, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.52
Round 271, Train loss: 2.303, Test loss: 2.302, Test accuracy: 13.83
Round 271, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 13.47
Round 272, Train loss: 2.300, Test loss: 2.302, Test accuracy: 13.89
Round 272, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.56
Round 273, Train loss: 2.302, Test loss: 2.302, Test accuracy: 13.96
Round 273, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.61
Round 274, Train loss: 2.302, Test loss: 2.302, Test accuracy: 14.00
Round 274, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.57
Round 275, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.02
Round 275, Global train loss: 2.299, Global test loss: 2.302, Global test accuracy: 13.63
Round 276, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.02
Round 276, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.66
Round 277, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.03
Round 277, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.68
Round 278, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.05
Round 278, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.64
Round 279, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.05
Round 279, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.63
Round 280, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.08
Round 280, Global train loss: 2.299, Global test loss: 2.302, Global test accuracy: 13.66
Round 281, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.05
Round 281, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.69
Round 282, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.10
Round 282, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.73
Round 283, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.12
Round 283, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 13.76
Round 284, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.19
Round 284, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.79
Round 285, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.13
Round 285, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.77
Round 286, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.12
Round 286, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 13.80
Round 287, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.10
Round 287, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.83
Round 288, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.15
Round 288, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 13.81
Round 289, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.19
Round 289, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.85
Round 290, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.23
Round 290, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.87
Round 291, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.26
Round 291, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.91
Round 292, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.30
Round 292, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.95
Round 293, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.25
Round 293, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.96
Round 294, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.27
Round 294, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.97
Round 295, Train loss: 2.304, Test loss: 2.301, Test accuracy: 14.28
Round 295, Global train loss: 2.304, Global test loss: 2.301, Global test accuracy: 13.94
Round 296, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.25
Round 296, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.93
Round 297, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.31
Round 297, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.97
Round 298, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.24
Round 298, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.99
Round 299, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.29
Round 299, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.96
Round 300, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.26
Round 300, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.00
Round 301, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.35
Round 301, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.04
Round 302, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.38
Round 302, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.99
Round 303, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.38
Round 303, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.02
Round 304, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.43
Round 304, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.04
Round 305, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.40
Round 305, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.03
Round 306, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.34
Round 306, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.02
Round 307, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.38
Round 307, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.02
Round 308, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.43
Round 308, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.08
Round 309, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.41
Round 309, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.09
Round 310, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.46
Round 310, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.11
Round 311, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.47
Round 311, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.14
Round 312, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.47
Round 312, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.13
Round 313, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.44
Round 313, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.13
Round 314, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.48
Round 314, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.15
Round 315, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.57
Round 315, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.19
Round 316, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.55
Round 316, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.26
Round 317, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.60
Round 317, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.28
Round 318, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.56
Round 318, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.25
Round 319, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.47
Round 319, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.27
Round 320, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.50
Round 320, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.29
Round 321, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.57
Round 321, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.32
Round 322, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.57
Round 322, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.34
Round 323, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.59
Round 323, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.37
Round 324, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.58
Round 324, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.46
Round 325, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.62
Round 325, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.48
Round 326, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.60
Round 326, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.48
Round 327, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.63
Round 327, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.48
Round 328, Train loss: 2.303, Test loss: 2.301, Test accuracy: 14.67
Round 328, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 14.50
Round 329, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.72
Round 329, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.50
Round 330, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.73
Round 330, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.49
Round 331, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.80
Round 331, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.53
Round 332, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.80
Round 332, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.61
Round 333, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.81
Round 333, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.61
Round 334, Train loss: 2.303, Test loss: 2.301, Test accuracy: 14.82
Round 334, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 14.63
Round 335, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.82
Round 335, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.61
Round 336, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.87
Round 336, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.59
Round 337, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.95
Round 337, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.55
Round 338, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.93
Round 338, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.52
Round 339, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.92
Round 339, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.51
Round 340, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.86
Round 340, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.53
Round 341, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.88
Round 341, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.51
Round 342, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.81
Round 342, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.56
Round 343, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.80
Round 343, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.54
Round 344, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.86
Round 344, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.53
Round 345, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.88
Round 345, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.48
Round 346, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.92
Round 346, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.52
Round 347, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.89
Round 347, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.53
Round 348, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.92
Round 348, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.54
Round 349, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.87
Round 349, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.54
Round 350, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.88
Round 350, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.58
Round 351, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.98
Round 351, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.56
Round 352, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.94
Round 352, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.62
Round 353, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.85
Round 353, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.64
Round 354, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.84
Round 354, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.65
Round 355, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.86
Round 355, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.65
Round 356, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.84
Round 356, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.67
Round 357, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.82
Round 357, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.66
Round 358, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.77
Round 358, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.64
Round 359, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.79
Round 359, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.68
Round 360, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.82
Round 360, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.68
Round 361, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.91
Round 361, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.69
Round 362, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.90
Round 362, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.71
Round 363, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.92
Round 363, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.76
Round 364, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.96
Round 364, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.84
Round 365, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.99
Round 365, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.83
Round 366, Train loss: 2.300, Test loss: 2.301, Test accuracy: 15.01
Round 366, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.82
Round 367, Train loss: 2.299, Test loss: 2.301, Test accuracy: 14.98
Round 367, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.81
Round 368, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.98
Round 368, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.85
Round 369, Train loss: 2.302, Test loss: 2.301, Test accuracy: 15.01
Round 369, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.81
Round 370, Train loss: 2.303, Test loss: 2.301, Test accuracy: 15.05
Round 370, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 14.86
Round 371, Train loss: 2.301, Test loss: 2.301, Test accuracy: 15.08
Round 371, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.91
Round 372, Train loss: 2.300, Test loss: 2.301, Test accuracy: 15.06
Round 372, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.89
Round 373, Train loss: 2.301, Test loss: 2.301, Test accuracy: 15.04
Round 373, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.89
Round 374, Train loss: 2.301, Test loss: 2.301, Test accuracy: 15.08
Round 374, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.89
Round 375, Train loss: 2.299, Test loss: 2.301, Test accuracy: 15.08
Round 375, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.93
Round 376, Train loss: 2.301, Test loss: 2.301, Test accuracy: 15.08
Round 376, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.94
Round 377, Train loss: 2.300, Test loss: 2.301, Test accuracy: 15.10
Round 377, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.91
Round 378, Train loss: 2.302, Test loss: 2.301, Test accuracy: 15.14
Round 378, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.91
Round 379, Train loss: 2.300, Test loss: 2.301, Test accuracy: 15.17
Round 379, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.90
Round 380, Train loss: 2.302, Test loss: 2.301, Test accuracy: 15.16
Round 380, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.90
Round 381, Train loss: 2.298, Test loss: 2.301, Test accuracy: 15.20
Round 381, Global train loss: 2.298, Global test loss: 2.301, Global test accuracy: 14.97
Round 382, Train loss: 2.301, Test loss: 2.301, Test accuracy: 15.21
Round 382, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.99
Round 383, Train loss: 2.300, Test loss: 2.301, Test accuracy: 15.18
Round 383, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 15.00
Round 384, Train loss: 2.300, Test loss: 2.301, Test accuracy: 15.25
Round 384, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.98
Round 385, Train loss: 2.300, Test loss: 2.301, Test accuracy: 15.19
Round 385, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 15.02
Round 386, Train loss: 2.301, Test loss: 2.301, Test accuracy: 15.25
Round 386, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 15.00
Round 387, Train loss: 2.300, Test loss: 2.301, Test accuracy: 15.21
Round 387, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.99
Round 388, Train loss: 2.299, Test loss: 2.301, Test accuracy: 15.22
Round 388, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 15.02
Round 389, Train loss: 2.300, Test loss: 2.301, Test accuracy: 15.21
Round 389, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.99
Round 390, Train loss: 2.299, Test loss: 2.301, Test accuracy: 15.23
Round 390, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 14.99
Round 391, Train loss: 2.300, Test loss: 2.301, Test accuracy: 15.20
Round 391, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 15.02
Round 392, Train loss: 2.300, Test loss: 2.301, Test accuracy: 15.18
Round 392, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.97
Round 393, Train loss: 2.301, Test loss: 2.301, Test accuracy: 15.22
Round 393, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 15.02
Round 394, Train loss: 2.300, Test loss: 2.301, Test accuracy: 15.22
Round 394, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 15.01
Round 395, Train loss: 2.299, Test loss: 2.301, Test accuracy: 15.21
Round 395, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 15.00
Round 396, Train loss: 2.302, Test loss: 2.301, Test accuracy: 15.26
Round 396, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.96
Round 397, Train loss: 2.301, Test loss: 2.301, Test accuracy: 15.29
Round 397, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.98
Round 398, Train loss: 2.302, Test loss: 2.301, Test accuracy: 15.28
Round 398, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 14.97
Round 399, Train loss: 2.300, Test loss: 2.301, Test accuracy: 15.28
Round 399, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 14.96
Final Round, Train loss: 2.301, Test loss: 2.301, Test accuracy: 15.47
Final Round, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 14.96
Average accuracy final 10 rounds: 15.237000000000002 

Average global accuracy final 10 rounds: 14.988 

4293.496855735779
[1.0361661911010742, 2.0563747882843018, 3.110605478286743, 4.136460304260254, 5.1211748123168945, 6.119674921035767, 7.0970683097839355, 8.078957557678223, 9.135507345199585, 10.16203784942627, 11.165606260299683, 12.19623064994812, 13.212581157684326, 14.156347513198853, 15.147497653961182, 16.129261016845703, 17.186089038848877, 18.19810152053833, 19.314218521118164, 20.32608675956726, 21.32350754737854, 22.432207822799683, 23.45141053199768, 24.444272994995117, 25.427246809005737, 26.44440507888794, 27.448233127593994, 28.48870611190796, 29.507386684417725, 30.56918954849243, 31.53016996383667, 32.47559070587158, 33.46979093551636, 34.49302649497986, 35.553059816360474, 36.66390895843506, 37.7751247882843, 38.76042342185974, 39.64817690849304, 40.53696870803833, 41.39142394065857, 42.28633761405945, 43.12484836578369, 44.00706624984741, 44.90277886390686, 45.81720018386841, 46.70076107978821, 47.57046341896057, 48.44381642341614, 49.2885799407959, 50.23250412940979, 51.11810255050659, 51.97667574882507, 52.857900857925415, 53.66374635696411, 54.49791359901428, 55.384796380996704, 56.249311685562134, 57.11011791229248, 57.947059869766235, 58.806920766830444, 59.67865991592407, 60.56125617027283, 61.4202094078064, 62.300763845443726, 63.22172021865845, 64.04520893096924, 64.95967817306519, 65.84287524223328, 66.67171096801758, 67.54845809936523, 68.40023636817932, 69.29970049858093, 70.15743827819824, 71.0673463344574, 72.0008807182312, 72.8638014793396, 73.87868809700012, 74.74674558639526, 75.80050492286682, 76.61237692832947, 77.48341393470764, 78.5507173538208, 79.54872632026672, 80.55850172042847, 81.42422223091125, 82.48531413078308, 83.52459001541138, 84.58665060997009, 85.68835949897766, 86.66840648651123, 87.6564211845398, 88.75757074356079, 89.8297176361084, 90.85945701599121, 91.87532019615173, 92.91069412231445, 93.92367100715637, 94.90683388710022, 95.97501564025879, 96.84757971763611, 97.71145439147949, 98.55161190032959, 99.47021484375, 100.28424215316772, 101.26779127120972, 102.32927989959717, 103.3881402015686, 104.25235772132874, 105.08690786361694, 105.99983930587769, 106.89282464981079, 107.73325729370117, 108.63904786109924, 109.47672891616821, 110.29405164718628, 111.16830587387085, 112.05800294876099, 112.94641304016113, 113.76239800453186, 114.63525605201721, 115.513662815094, 116.35867977142334, 117.19608616828918, 118.04399251937866, 118.91634798049927, 119.81852531433105, 120.69589042663574, 121.54738759994507, 122.41206502914429, 123.32564568519592, 124.17134857177734, 125.02681279182434, 125.89995241165161, 126.72108602523804, 127.56701946258545, 128.45339632034302, 129.31382846832275, 130.19113397598267, 131.05500078201294, 131.89204263687134, 132.75468158721924, 133.63350439071655, 134.4981324672699, 135.4597430229187, 136.38032388687134, 137.31620955467224, 138.26126742362976, 139.28482961654663, 140.29201912879944, 141.2977170944214, 142.42613315582275, 143.54580640792847, 144.62830185890198, 145.76627779006958, 146.87791776657104, 147.995751619339, 149.0368082523346, 150.15966629981995, 151.28893971443176, 152.4391851425171, 153.52351808547974, 154.63228511810303, 155.718985080719, 156.79214882850647, 157.90691375732422, 159.0276756286621, 159.99113130569458, 160.97206568717957, 161.9794282913208, 162.97993278503418, 163.9797978401184, 164.92161798477173, 165.90315628051758, 166.8838267326355, 167.85148787498474, 168.8510718345642, 169.86716961860657, 170.86801195144653, 171.8329849243164, 172.80677223205566, 173.80608940124512, 174.76470518112183, 175.7148838043213, 176.70280623435974, 177.68705248832703, 178.6618618965149, 179.65681052207947, 180.6563847064972, 181.6482653617859, 182.5820963382721, 183.5159523487091, 184.49842071533203, 185.5131938457489, 186.48830890655518, 187.44609379768372, 188.40287113189697, 189.37672591209412, 190.35704469680786, 191.29357481002808, 192.24811577796936, 193.24378418922424, 194.22208380699158, 195.20520663261414, 196.20381498336792, 197.20870184898376, 198.2013635635376, 199.15859365463257, 200.1582429409027, 201.16672015190125, 202.15040230751038, 203.1275975704193, 204.11224365234375, 205.1307816505432, 206.14417791366577, 207.14291834831238, 208.11668062210083, 209.09010815620422, 210.08509039878845, 211.0759027004242, 212.05139803886414, 213.04478859901428, 214.04769277572632, 215.050532579422, 216.06819534301758, 217.05320119857788, 218.07846856117249, 219.08723187446594, 220.0711100101471, 221.04098987579346, 222.05475211143494, 223.06879353523254, 224.06793212890625, 225.04087710380554, 226.0256154537201, 227.03498649597168, 228.0499083995819, 229.0710678100586, 230.03744792938232, 231.01741671562195, 231.99609375, 232.98872113227844, 233.97929334640503, 234.99562740325928, 236.01183128356934, 237.01482558250427, 238.02022004127502, 239.01015710830688, 239.98945450782776, 240.97391319274902, 241.95214223861694, 242.92152523994446, 243.9342360496521, 244.95835614204407, 245.9646074771881, 246.94035530090332, 247.91977787017822, 248.93913412094116, 249.94178199768066, 250.9462285041809, 251.92800545692444, 252.94259333610535, 253.945326089859, 254.96493363380432, 255.95071053504944, 256.93432664871216, 257.918826341629, 258.9161169528961, 259.929368019104, 260.9130415916443, 261.83097982406616, 262.73982429504395, 263.63911414146423, 264.5901930332184, 265.603408575058, 266.62174344062805, 267.5899875164032, 268.56964564323425, 269.5599675178528, 270.579137802124, 271.58140230178833, 272.5486705303192, 273.5411310195923, 274.50727891921997, 275.50978565216064, 276.5263092517853, 277.5353829860687, 278.5229752063751, 279.49140763282776, 280.4892702102661, 281.4949097633362, 282.47336602211, 283.43397998809814, 284.43403339385986, 285.4376027584076, 286.45506525039673, 287.4465522766113, 288.4218592643738, 289.4108431339264, 290.4172685146332, 291.41464352607727, 292.3997972011566, 293.3597676753998, 294.32321882247925, 295.24432492256165, 296.21105432510376, 297.18765091896057, 298.16530871391296, 299.125137090683, 300.0844793319702, 301.0969886779785, 302.08464908599854, 303.03447461128235, 303.8786714076996, 304.7210419178009, 305.5487334728241, 306.3833210468292, 307.212641954422, 308.02629685401917, 308.868501663208, 309.71011114120483, 310.5377049446106, 311.36182475090027, 312.2214231491089, 313.0481731891632, 313.86756777763367, 314.69529962539673, 315.5367226600647, 316.36028504371643, 317.19122838974, 318.0165345668793, 318.8329815864563, 319.68449354171753, 320.54226660728455, 321.36404848098755, 322.1803858280182, 323.0163207054138, 323.8414874076843, 324.6864640712738, 325.51565051078796, 326.3436236381531, 327.1730537414551, 328.0127124786377, 328.83988404273987, 329.68291115760803, 330.51147651672363, 331.3377523422241, 332.1782937049866, 333.01039576530457, 333.8447816371918, 334.6853380203247, 335.5334258079529, 336.35966873168945, 337.18455386161804, 338.00731778144836, 338.8493642807007, 339.67297625541687, 340.5183355808258, 341.3354842662811, 342.15309143066406, 342.992285490036, 343.8383822441101, 344.66677927970886, 345.49293422698975, 346.31577348709106, 347.1398026943207, 347.9861581325531, 348.8273916244507, 349.6565201282501, 350.49109172821045, 351.32730293273926, 352.1509573459625, 352.9952938556671, 353.8244729042053, 354.65735125541687, 355.48758602142334, 356.3300232887268, 357.1616220474243, 357.97420048713684, 358.82021260261536, 359.6534352302551, 360.48077869415283, 361.31936502456665, 362.1617863178253, 362.9968681335449, 363.86031770706177, 364.70843863487244, 365.5176532268524, 366.3349723815918, 367.175749540329, 368.0048952102661, 368.85498094558716, 369.6984510421753, 370.5134952068329, 371.33335876464844, 372.1760447025299, 373.0160689353943, 373.84149980545044, 374.6825861930847, 375.51977920532227, 377.1948001384735]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[7.78, 7.82, 7.87, 7.88, 7.92, 7.92, 7.96, 7.93, 7.95, 7.97, 8.04, 8.0, 8.02, 7.98, 7.96, 7.98, 7.99, 7.98, 7.95, 8.0, 8.06, 8.07, 8.1, 8.15, 8.16, 8.17, 8.18, 8.16, 8.17, 8.14, 8.17, 8.19, 8.24, 8.26, 8.26, 8.25, 8.25, 8.28, 8.3, 8.3, 8.28, 8.26, 8.25, 8.26, 8.25, 8.3, 8.4, 8.45, 8.44, 8.43, 8.41, 8.46, 8.46, 8.45, 8.51, 8.53, 8.56, 8.61, 8.59, 8.68, 8.69, 8.64, 8.67, 8.7, 8.66, 8.7, 8.78, 8.79, 8.78, 8.77, 8.8, 8.8, 8.85, 8.86, 8.89, 8.83, 8.86, 8.87, 8.88, 8.95, 9.02, 9.04, 9.0, 9.03, 9.04, 9.06, 9.07, 9.08, 9.09, 9.09, 9.2, 9.18, 9.31, 9.37, 9.29, 9.33, 9.36, 9.39, 9.53, 9.5, 9.48, 9.5, 9.5, 9.54, 9.62, 9.7, 9.8, 9.74, 9.71, 9.74, 9.77, 9.77, 9.78, 9.77, 9.79, 9.87, 9.9, 9.92, 9.99, 10.04, 10.04, 10.12, 10.18, 10.2, 10.14, 10.09, 10.07, 10.09, 10.11, 10.07, 10.13, 10.21, 10.3, 10.2, 10.28, 10.35, 10.4, 10.4, 10.45, 10.52, 10.55, 10.52, 10.52, 10.53, 10.54, 10.54, 10.55, 10.58, 10.67, 10.61, 10.62, 10.64, 10.58, 10.65, 10.69, 10.64, 10.66, 10.68, 10.74, 10.76, 10.8, 10.86, 10.92, 10.94, 10.91, 10.97, 10.95, 10.98, 10.99, 11.04, 11.11, 11.14, 11.17, 11.19, 11.17, 11.15, 11.2, 11.17, 11.17, 11.22, 11.32, 11.28, 11.39, 11.43, 11.47, 11.49, 11.56, 11.62, 11.68, 11.73, 11.77, 11.8, 11.84, 11.89, 11.98, 11.98, 12.01, 12.03, 12.1, 12.15, 12.19, 12.15, 12.17, 12.2, 12.19, 12.22, 12.29, 12.27, 12.41, 12.42, 12.42, 12.54, 12.57, 12.56, 12.58, 12.57, 12.58, 12.59, 12.61, 12.61, 12.66, 12.61, 12.69, 12.68, 12.74, 12.78, 12.85, 12.88, 12.95, 12.94, 12.94, 12.97, 12.94, 12.96, 13.02, 13.01, 13.03, 13.04, 13.1, 13.13, 13.13, 13.2, 13.21, 13.25, 13.24, 13.28, 13.26, 13.28, 13.24, 13.2, 13.28, 13.37, 13.41, 13.44, 13.49, 13.44, 13.45, 13.43, 13.47, 13.47, 13.67, 13.66, 13.71, 13.71, 13.7, 13.68, 13.73, 13.76, 13.76, 13.84, 13.82, 13.83, 13.89, 13.96, 14.0, 14.02, 14.02, 14.03, 14.05, 14.05, 14.08, 14.05, 14.1, 14.12, 14.19, 14.13, 14.12, 14.1, 14.15, 14.19, 14.23, 14.26, 14.3, 14.25, 14.27, 14.28, 14.25, 14.31, 14.24, 14.29, 14.26, 14.35, 14.38, 14.38, 14.43, 14.4, 14.34, 14.38, 14.43, 14.41, 14.46, 14.47, 14.47, 14.44, 14.48, 14.57, 14.55, 14.6, 14.56, 14.47, 14.5, 14.57, 14.57, 14.59, 14.58, 14.62, 14.6, 14.63, 14.67, 14.72, 14.73, 14.8, 14.8, 14.81, 14.82, 14.82, 14.87, 14.95, 14.93, 14.92, 14.86, 14.88, 14.81, 14.8, 14.86, 14.88, 14.92, 14.89, 14.92, 14.87, 14.88, 14.98, 14.94, 14.85, 14.84, 14.86, 14.84, 14.82, 14.77, 14.79, 14.82, 14.91, 14.9, 14.92, 14.96, 14.99, 15.01, 14.98, 14.98, 15.01, 15.05, 15.08, 15.06, 15.04, 15.08, 15.08, 15.08, 15.1, 15.14, 15.17, 15.16, 15.2, 15.21, 15.18, 15.25, 15.19, 15.25, 15.21, 15.22, 15.21, 15.23, 15.2, 15.18, 15.22, 15.22, 15.21, 15.26, 15.29, 15.28, 15.28, 15.47]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.315, Test loss: 2.302, Test accuracy: 12.53
Round   1, Train loss: 2.292, Test loss: 2.300, Test accuracy: 14.14
Round   2, Train loss: 2.292, Test loss: 2.297, Test accuracy: 16.25
Round   3, Train loss: 2.282, Test loss: 2.291, Test accuracy: 14.48
Round   4, Train loss: 2.249, Test loss: 2.280, Test accuracy: 17.15
Round   5, Train loss: 2.213, Test loss: 2.253, Test accuracy: 20.23
Round   6, Train loss: 2.158, Test loss: 2.224, Test accuracy: 21.79
Round   7, Train loss: 2.106, Test loss: 2.185, Test accuracy: 30.07
Round   8, Train loss: 2.072, Test loss: 2.144, Test accuracy: 34.94
Round   9, Train loss: 2.037, Test loss: 2.112, Test accuracy: 37.32
Round  10, Train loss: 1.977, Test loss: 2.078, Test accuracy: 40.59
Round  11, Train loss: 1.982, Test loss: 2.053, Test accuracy: 43.90
Round  12, Train loss: 1.885, Test loss: 2.020, Test accuracy: 47.43
Round  13, Train loss: 1.946, Test loss: 1.992, Test accuracy: 50.15
Round  14, Train loss: 1.916, Test loss: 1.965, Test accuracy: 52.77
Round  15, Train loss: 1.899, Test loss: 1.947, Test accuracy: 56.17
Round  16, Train loss: 1.919, Test loss: 1.930, Test accuracy: 57.93
Round  17, Train loss: 1.819, Test loss: 1.900, Test accuracy: 61.56
Round  18, Train loss: 1.888, Test loss: 1.889, Test accuracy: 62.17
Round  19, Train loss: 1.881, Test loss: 1.874, Test accuracy: 64.24
Round  20, Train loss: 1.835, Test loss: 1.878, Test accuracy: 63.62
Round  21, Train loss: 1.812, Test loss: 1.863, Test accuracy: 64.50
Round  22, Train loss: 1.834, Test loss: 1.853, Test accuracy: 66.23
Round  23, Train loss: 1.794, Test loss: 1.836, Test accuracy: 67.25
Round  24, Train loss: 1.834, Test loss: 1.834, Test accuracy: 68.03
Round  25, Train loss: 1.733, Test loss: 1.820, Test accuracy: 69.63
Round  26, Train loss: 1.796, Test loss: 1.814, Test accuracy: 70.06
Round  27, Train loss: 1.847, Test loss: 1.799, Test accuracy: 72.32
Round  28, Train loss: 1.738, Test loss: 1.785, Test accuracy: 72.52
Round  29, Train loss: 1.776, Test loss: 1.778, Test accuracy: 73.79
Round  30, Train loss: 1.713, Test loss: 1.772, Test accuracy: 74.11
Round  31, Train loss: 1.765, Test loss: 1.777, Test accuracy: 73.69
Round  32, Train loss: 1.708, Test loss: 1.767, Test accuracy: 74.67
Round  33, Train loss: 1.688, Test loss: 1.758, Test accuracy: 75.26
Round  34, Train loss: 1.742, Test loss: 1.741, Test accuracy: 77.75
Round  35, Train loss: 1.697, Test loss: 1.743, Test accuracy: 77.72
Round  36, Train loss: 1.686, Test loss: 1.726, Test accuracy: 78.76
Round  37, Train loss: 1.671, Test loss: 1.715, Test accuracy: 78.96
Round  38, Train loss: 1.679, Test loss: 1.719, Test accuracy: 78.82
Round  39, Train loss: 1.649, Test loss: 1.714, Test accuracy: 79.34
Round  40, Train loss: 1.652, Test loss: 1.703, Test accuracy: 79.82
Round  41, Train loss: 1.663, Test loss: 1.700, Test accuracy: 80.26
Round  42, Train loss: 1.678, Test loss: 1.702, Test accuracy: 80.23
Round  43, Train loss: 1.661, Test loss: 1.698, Test accuracy: 80.58
Round  44, Train loss: 1.718, Test loss: 1.697, Test accuracy: 80.51
Round  45, Train loss: 1.647, Test loss: 1.697, Test accuracy: 80.41
Round  46, Train loss: 1.599, Test loss: 1.684, Test accuracy: 81.30
Round  47, Train loss: 1.706, Test loss: 1.687, Test accuracy: 81.26
Round  48, Train loss: 1.651, Test loss: 1.686, Test accuracy: 81.46
Round  49, Train loss: 1.708, Test loss: 1.688, Test accuracy: 81.24
Round  50, Train loss: 1.706, Test loss: 1.693, Test accuracy: 81.09
Round  51, Train loss: 1.760, Test loss: 1.704, Test accuracy: 80.29
Round  52, Train loss: 1.671, Test loss: 1.704, Test accuracy: 79.50
Round  53, Train loss: 1.627, Test loss: 1.690, Test accuracy: 80.52
Round  54, Train loss: 1.623, Test loss: 1.671, Test accuracy: 82.82
Round  55, Train loss: 1.615, Test loss: 1.666, Test accuracy: 83.14
Round  56, Train loss: 1.659, Test loss: 1.668, Test accuracy: 83.49
Round  57, Train loss: 1.586, Test loss: 1.656, Test accuracy: 84.26
Round  58, Train loss: 1.603, Test loss: 1.662, Test accuracy: 84.04
Round  59, Train loss: 1.632, Test loss: 1.660, Test accuracy: 84.04
Round  60, Train loss: 1.601, Test loss: 1.658, Test accuracy: 84.13
Round  61, Train loss: 1.647, Test loss: 1.660, Test accuracy: 84.11
Round  62, Train loss: 1.672, Test loss: 1.655, Test accuracy: 84.05
Round  63, Train loss: 1.641, Test loss: 1.652, Test accuracy: 84.34
Round  64, Train loss: 1.635, Test loss: 1.648, Test accuracy: 84.67
Round  65, Train loss: 1.690, Test loss: 1.652, Test accuracy: 84.66
Round  66, Train loss: 1.631, Test loss: 1.658, Test accuracy: 84.33
Round  67, Train loss: 1.576, Test loss: 1.648, Test accuracy: 84.50
Round  68, Train loss: 1.566, Test loss: 1.643, Test accuracy: 84.66
Round  69, Train loss: 1.597, Test loss: 1.641, Test accuracy: 84.90
Round  70, Train loss: 1.568, Test loss: 1.639, Test accuracy: 84.90
Round  71, Train loss: 1.605, Test loss: 1.630, Test accuracy: 85.97
Round  72, Train loss: 1.601, Test loss: 1.631, Test accuracy: 86.09
Round  73, Train loss: 1.572, Test loss: 1.631, Test accuracy: 86.04
Round  74, Train loss: 1.572, Test loss: 1.626, Test accuracy: 86.19
Round  75, Train loss: 1.607, Test loss: 1.619, Test accuracy: 86.86
Round  76, Train loss: 1.655, Test loss: 1.631, Test accuracy: 86.63
Round  77, Train loss: 1.565, Test loss: 1.625, Test accuracy: 86.57
Round  78, Train loss: 1.587, Test loss: 1.627, Test accuracy: 86.45
Round  79, Train loss: 1.664, Test loss: 1.626, Test accuracy: 86.93
Round  80, Train loss: 1.559, Test loss: 1.627, Test accuracy: 86.38
Round  81, Train loss: 1.620, Test loss: 1.615, Test accuracy: 87.72
Round  82, Train loss: 1.552, Test loss: 1.611, Test accuracy: 88.35
Round  83, Train loss: 1.521, Test loss: 1.599, Test accuracy: 89.02
Round  84, Train loss: 1.602, Test loss: 1.603, Test accuracy: 89.47
Round  85, Train loss: 1.561, Test loss: 1.602, Test accuracy: 89.63
Round  86, Train loss: 1.615, Test loss: 1.594, Test accuracy: 90.07
Round  87, Train loss: 1.526, Test loss: 1.595, Test accuracy: 89.84
Round  88, Train loss: 1.540, Test loss: 1.593, Test accuracy: 89.71
Round  89, Train loss: 1.568, Test loss: 1.592, Test accuracy: 89.98
Round  90, Train loss: 1.595, Test loss: 1.595, Test accuracy: 90.02
Round  91, Train loss: 1.567, Test loss: 1.588, Test accuracy: 90.04
Round  92, Train loss: 1.559, Test loss: 1.590, Test accuracy: 90.03
Round  93, Train loss: 1.562, Test loss: 1.593, Test accuracy: 89.70
Round  94, Train loss: 1.591, Test loss: 1.589, Test accuracy: 90.15/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  95, Train loss: 1.527, Test loss: 1.590, Test accuracy: 89.86
Round  96, Train loss: 1.563, Test loss: 1.590, Test accuracy: 89.98
Round  97, Train loss: 1.593, Test loss: 1.590, Test accuracy: 89.80
Round  98, Train loss: 1.559, Test loss: 1.591, Test accuracy: 90.04
Round  99, Train loss: 1.587, Test loss: 1.592, Test accuracy: 89.93
Final Round, Train loss: 1.551, Test loss: 1.583, Test accuracy: 90.07
Average accuracy final 10 rounds: 89.95500000000001
828.2977287769318
[1.197500467300415, 2.255162000656128, 3.260899305343628, 4.309065580368042, 5.3441002368927, 6.3626697063446045, 7.39000129699707, 8.400226831436157, 9.446269750595093, 10.477925777435303, 11.54884958267212, 12.596354007720947, 13.612905740737915, 14.63454270362854, 15.608878374099731, 16.535622596740723, 17.519296169281006, 18.51061725616455, 19.446211576461792, 20.39324450492859, 21.372926950454712, 22.336132764816284, 23.312891244888306, 24.32537817955017, 25.300767421722412, 26.236878156661987, 27.193992137908936, 28.175567626953125, 29.090088844299316, 30.067312002182007, 31.047675132751465, 31.992878675460815, 32.94687032699585, 33.89113163948059, 34.86445379257202, 35.83442711830139, 36.82827186584473, 37.82599949836731, 38.838366746902466, 39.82170391082764, 40.76664352416992, 41.66475200653076, 42.569052934646606, 43.478984117507935, 44.40833926200867, 45.331377029418945, 46.2111337184906, 47.11443543434143, 47.99434518814087, 48.89401698112488, 49.83738565444946, 50.7407808303833, 51.686790227890015, 52.56728720664978, 53.47948980331421, 54.40206289291382, 55.29381799697876, 56.22526288032532, 57.13955736160278, 58.04557204246521, 58.961878538131714, 59.86343598365784, 60.749776124954224, 61.66880512237549, 62.57422232627869, 63.493080615997314, 64.41644740104675, 65.29639840126038, 66.20462083816528, 67.10527420043945, 68.0239405632019, 68.94494724273682, 69.85332155227661, 70.77392220497131, 71.65279388427734, 72.55208492279053, 73.46556425094604, 74.34772682189941, 75.26289057731628, 76.19321656227112, 77.10570216178894, 78.00316977500916, 78.9242570400238, 79.83259439468384, 80.74633193016052, 81.68898272514343, 82.60429525375366, 83.5488121509552, 84.44408130645752, 85.35932087898254, 86.26850056648254, 87.14996862411499, 88.08298850059509, 88.99137377738953, 89.915531873703, 90.82500052452087, 91.70388579368591, 92.61123824119568, 93.49756789207458, 94.42227125167847, 95.8638265132904]
[12.53, 14.14, 16.25, 14.48, 17.15, 20.23, 21.79, 30.07, 34.94, 37.32, 40.59, 43.9, 47.43, 50.15, 52.77, 56.17, 57.93, 61.56, 62.17, 64.24, 63.62, 64.5, 66.23, 67.25, 68.03, 69.63, 70.06, 72.32, 72.52, 73.79, 74.11, 73.69, 74.67, 75.26, 77.75, 77.72, 78.76, 78.96, 78.82, 79.34, 79.82, 80.26, 80.23, 80.58, 80.51, 80.41, 81.3, 81.26, 81.46, 81.24, 81.09, 80.29, 79.5, 80.52, 82.82, 83.14, 83.49, 84.26, 84.04, 84.04, 84.13, 84.11, 84.05, 84.34, 84.67, 84.66, 84.33, 84.5, 84.66, 84.9, 84.9, 85.97, 86.09, 86.04, 86.19, 86.86, 86.63, 86.57, 86.45, 86.93, 86.38, 87.72, 88.35, 89.02, 89.47, 89.63, 90.07, 89.84, 89.71, 89.98, 90.02, 90.04, 90.03, 89.7, 90.15, 89.86, 89.98, 89.8, 90.04, 89.93, 90.07]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
401408
401920
532992
533248
549632
549696
550336
550346
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.316, Test loss: 2.301, Test accuracy: 12.48
Round   1, Train loss: 2.303, Test loss: 2.297, Test accuracy: 13.66
Round   2, Train loss: 2.270, Test loss: 2.287, Test accuracy: 15.73
Round   3, Train loss: 2.237, Test loss: 2.269, Test accuracy: 18.97
Round   4, Train loss: 2.202, Test loss: 2.247, Test accuracy: 20.69
Round   5, Train loss: 2.163, Test loss: 2.220, Test accuracy: 23.34
Round   6, Train loss: 2.131, Test loss: 2.192, Test accuracy: 25.85
Round   7, Train loss: 2.128, Test loss: 2.165, Test accuracy: 31.13
Round   8, Train loss: 2.109, Test loss: 2.120, Test accuracy: 40.18
Round   9, Train loss: 1.987, Test loss: 2.086, Test accuracy: 43.34
Round  10, Train loss: 1.968, Test loss: 2.058, Test accuracy: 45.73
Round  11, Train loss: 1.914, Test loss: 2.028, Test accuracy: 48.96
Round  12, Train loss: 1.926, Test loss: 1.963, Test accuracy: 56.47
Round  13, Train loss: 1.914, Test loss: 1.952, Test accuracy: 59.33
Round  14, Train loss: 1.780, Test loss: 1.908, Test accuracy: 61.38
Round  15, Train loss: 1.825, Test loss: 1.870, Test accuracy: 66.23
Round  16, Train loss: 1.783, Test loss: 1.839, Test accuracy: 70.45
Round  17, Train loss: 1.707, Test loss: 1.811, Test accuracy: 72.89
Round  18, Train loss: 1.700, Test loss: 1.795, Test accuracy: 75.16
Round  19, Train loss: 1.793, Test loss: 1.778, Test accuracy: 76.49
Round  20, Train loss: 1.673, Test loss: 1.767, Test accuracy: 78.36
Round  21, Train loss: 1.707, Test loss: 1.755, Test accuracy: 78.79
Round  22, Train loss: 1.714, Test loss: 1.752, Test accuracy: 79.09
Round  23, Train loss: 1.673, Test loss: 1.740, Test accuracy: 79.12
Round  24, Train loss: 1.682, Test loss: 1.731, Test accuracy: 80.09
Round  25, Train loss: 1.657, Test loss: 1.714, Test accuracy: 81.76
Round  26, Train loss: 1.675, Test loss: 1.691, Test accuracy: 83.56
Round  27, Train loss: 1.606, Test loss: 1.684, Test accuracy: 83.78
Round  28, Train loss: 1.621, Test loss: 1.689, Test accuracy: 83.67
Round  29, Train loss: 1.653, Test loss: 1.683, Test accuracy: 83.69
Round  30, Train loss: 1.632, Test loss: 1.681, Test accuracy: 83.99
Round  31, Train loss: 1.657, Test loss: 1.666, Test accuracy: 85.71
Round  32, Train loss: 1.626, Test loss: 1.654, Test accuracy: 86.31
Round  33, Train loss: 1.695, Test loss: 1.663, Test accuracy: 86.26
Round  34, Train loss: 1.620, Test loss: 1.651, Test accuracy: 86.38
Round  35, Train loss: 1.620, Test loss: 1.640, Test accuracy: 86.84
Round  36, Train loss: 1.684, Test loss: 1.648, Test accuracy: 86.75
Round  37, Train loss: 1.571, Test loss: 1.643, Test accuracy: 86.89
Round  38, Train loss: 1.638, Test loss: 1.635, Test accuracy: 88.01
Round  39, Train loss: 1.599, Test loss: 1.621, Test accuracy: 88.80
Round  40, Train loss: 1.666, Test loss: 1.620, Test accuracy: 89.01
Round  41, Train loss: 1.632, Test loss: 1.619, Test accuracy: 89.04
Round  42, Train loss: 1.634, Test loss: 1.615, Test accuracy: 89.16
Round  43, Train loss: 1.599, Test loss: 1.611, Test accuracy: 89.26
Round  44, Train loss: 1.595, Test loss: 1.611, Test accuracy: 89.21
Round  45, Train loss: 1.599, Test loss: 1.610, Test accuracy: 89.19
Round  46, Train loss: 1.563, Test loss: 1.607, Test accuracy: 89.22
Round  47, Train loss: 1.615, Test loss: 1.607, Test accuracy: 89.34
Round  48, Train loss: 1.614, Test loss: 1.609, Test accuracy: 89.36
Round  49, Train loss: 1.617, Test loss: 1.606, Test accuracy: 89.38
Round  50, Train loss: 1.558, Test loss: 1.601, Test accuracy: 89.56
Round  51, Train loss: 1.554, Test loss: 1.602, Test accuracy: 89.36
Round  52, Train loss: 1.584, Test loss: 1.599, Test accuracy: 89.54
Round  53, Train loss: 1.552, Test loss: 1.599, Test accuracy: 89.55
Round  54, Train loss: 1.572, Test loss: 1.597, Test accuracy: 89.51
Round  55, Train loss: 1.578, Test loss: 1.598, Test accuracy: 89.61
Round  56, Train loss: 1.556, Test loss: 1.595, Test accuracy: 89.71
Round  57, Train loss: 1.550, Test loss: 1.594, Test accuracy: 89.75
Round  58, Train loss: 1.546, Test loss: 1.592, Test accuracy: 89.82
Round  59, Train loss: 1.588, Test loss: 1.587, Test accuracy: 90.65
Round  60, Train loss: 1.604, Test loss: 1.590, Test accuracy: 90.70
Round  61, Train loss: 1.544, Test loss: 1.588, Test accuracy: 90.69
Round  62, Train loss: 1.570, Test loss: 1.590, Test accuracy: 90.57
Round  63, Train loss: 1.597, Test loss: 1.592, Test accuracy: 90.61
Round  64, Train loss: 1.607, Test loss: 1.588, Test accuracy: 90.89
Round  65, Train loss: 1.550, Test loss: 1.583, Test accuracy: 90.73
Round  66, Train loss: 1.545, Test loss: 1.582, Test accuracy: 90.86
Round  67, Train loss: 1.604, Test loss: 1.583, Test accuracy: 90.78
Round  68, Train loss: 1.601, Test loss: 1.586, Test accuracy: 90.78
Round  69, Train loss: 1.599, Test loss: 1.583, Test accuracy: 90.93
Round  70, Train loss: 1.567, Test loss: 1.583, Test accuracy: 90.90
Round  71, Train loss: 1.629, Test loss: 1.584, Test accuracy: 91.09
Round  72, Train loss: 1.539, Test loss: 1.582, Test accuracy: 90.98
Round  73, Train loss: 1.597, Test loss: 1.582, Test accuracy: 91.01
Round  74, Train loss: 1.568, Test loss: 1.579, Test accuracy: 91.16
Round  75, Train loss: 1.568, Test loss: 1.581, Test accuracy: 90.94
Round  76, Train loss: 1.594, Test loss: 1.581, Test accuracy: 91.09
Round  77, Train loss: 1.560, Test loss: 1.580, Test accuracy: 91.04
Round  78, Train loss: 1.504, Test loss: 1.577, Test accuracy: 91.11
Round  79, Train loss: 1.505, Test loss: 1.576, Test accuracy: 91.05
Round  80, Train loss: 1.589, Test loss: 1.580, Test accuracy: 90.95
Round  81, Train loss: 1.560, Test loss: 1.579, Test accuracy: 91.07
Round  82, Train loss: 1.530, Test loss: 1.577, Test accuracy: 91.11
Round  83, Train loss: 1.557, Test loss: 1.575, Test accuracy: 91.10
Round  84, Train loss: 1.543, Test loss: 1.566, Test accuracy: 92.11
Round  85, Train loss: 1.553, Test loss: 1.566, Test accuracy: 92.16
Round  86, Train loss: 1.500, Test loss: 1.568, Test accuracy: 92.01
Round  87, Train loss: 1.563, Test loss: 1.566, Test accuracy: 92.12
Round  88, Train loss: 1.508, Test loss: 1.561, Test accuracy: 92.98
Round  89, Train loss: 1.543, Test loss: 1.557, Test accuracy: 92.96
Round  90, Train loss: 1.565, Test loss: 1.558, Test accuracy: 93.15
Round  91, Train loss: 1.561, Test loss: 1.559, Test accuracy: 93.16
Round  92, Train loss: 1.529, Test loss: 1.561, Test accuracy: 93.06
Round  93, Train loss: 1.537, Test loss: 1.556, Test accuracy: 93.12/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Train loss: 1.524, Test loss: 1.559, Test accuracy: 93.24
Round  95, Train loss: 1.554, Test loss: 1.562, Test accuracy: 93.05
Round  96, Train loss: 1.497, Test loss: 1.558, Test accuracy: 93.10
Round  97, Train loss: 1.500, Test loss: 1.555, Test accuracy: 93.21
Round  98, Train loss: 1.532, Test loss: 1.554, Test accuracy: 93.06
Round  99, Train loss: 1.551, Test loss: 1.558, Test accuracy: 93.17
Final Round, Train loss: 1.514, Test loss: 1.541, Test accuracy: 94.77
Average accuracy final 10 rounds: 93.132
1056.2051937580109
[1.128199815750122, 2.256399631500244, 3.173003911972046, 4.089608192443848, 5.028078079223633, 5.966547966003418, 6.8955912590026855, 7.824634552001953, 8.735816717147827, 9.646998882293701, 10.556653261184692, 11.466307640075684, 12.3493013381958, 13.232295036315918, 14.138720750808716, 15.045146465301514, 15.939658641815186, 16.834170818328857, 17.740485668182373, 18.64680051803589, 19.561262130737305, 20.47572374343872, 21.3802752494812, 22.28482675552368, 23.199533462524414, 24.114240169525146, 25.017852544784546, 25.921464920043945, 26.828712940216064, 27.735960960388184, 28.617464780807495, 29.498968601226807, 30.401647806167603, 31.3043270111084, 32.24572038650513, 33.187113761901855, 34.104058027267456, 35.02100229263306, 35.9240665435791, 36.82713079452515, 37.73410677909851, 38.641082763671875, 39.55846881866455, 40.47585487365723, 41.369869232177734, 42.26388359069824, 43.173447370529175, 44.08301115036011, 44.97952318191528, 45.87603521347046, 46.77314853668213, 47.6702618598938, 48.57898020744324, 49.487698554992676, 50.39109683036804, 51.29449510574341, 52.23461675643921, 53.17473840713501, 54.080549240112305, 54.9863600730896, 55.88004517555237, 56.77373027801514, 57.65864062309265, 58.543550968170166, 59.454909563064575, 60.366268157958984, 61.29598879814148, 62.225709438323975, 63.1631965637207, 64.10068368911743, 65.00839757919312, 65.9161114692688, 66.82324981689453, 67.73038816452026, 68.63127136230469, 69.53215456008911, 70.43339109420776, 71.33462762832642, 72.26664590835571, 73.19866418838501, 74.11397433280945, 75.02928447723389, 75.92005062103271, 76.81081676483154, 77.7011411190033, 78.59146547317505, 79.49716901779175, 80.40287256240845, 81.32329821586609, 82.24372386932373, 83.14571595191956, 84.04770803451538, 84.95754146575928, 85.86737489700317, 86.75554776191711, 87.64372062683105, 88.54442405700684, 89.44512748718262, 90.36243486404419, 91.27974224090576, 92.18726658821106, 93.09479093551636, 94.01740765571594, 94.94002437591553, 95.8446273803711, 96.74923038482666, 97.65216946601868, 98.5551085472107, 99.44974064826965, 100.34437274932861, 101.27417731285095, 102.20398187637329, 103.10716319084167, 104.01034450531006, 104.9236524105072, 105.83696031570435, 106.75127124786377, 107.6655821800232, 108.56423854827881, 109.46289491653442, 110.39105868339539, 111.31922245025635, 112.21146440505981, 113.10370635986328, 114.01913142204285, 114.93455648422241, 115.82745361328125, 116.72035074234009, 117.64174818992615, 118.5631456375122, 119.47797298431396, 120.39280033111572, 121.32796549797058, 122.26313066482544, 123.17161345481873, 124.08009624481201, 124.96222352981567, 125.84435081481934, 126.74602174758911, 127.64769268035889, 128.55052828788757, 129.45336389541626, 130.37728905677795, 131.30121421813965, 132.22531700134277, 133.1494197845459, 134.04689693450928, 134.94437408447266, 135.875004529953, 136.80563497543335, 137.75034308433533, 138.6950511932373, 139.64258122444153, 140.59011125564575, 141.52203941345215, 142.45396757125854, 143.39932918548584, 144.34469079971313, 145.28014612197876, 146.21560144424438, 147.1343994140625, 148.05319738388062, 148.97995042800903, 149.90670347213745, 150.85715985298157, 151.80761623382568, 152.7422411441803, 153.6768660545349, 154.5985984802246, 155.5203309059143, 156.41993832588196, 157.3195457458496, 158.24989104270935, 159.1802363395691, 160.12908101081848, 161.07792568206787, 162.0092809200287, 162.9406361579895, 163.8954565525055, 164.85027694702148, 165.75176525115967, 166.65325355529785, 167.58499598503113, 168.5167384147644, 169.4394655227661, 170.36219263076782, 171.3049783706665, 172.24776411056519, 173.19151663780212, 174.13526916503906, 175.0507516860962, 175.96623420715332, 176.8770787715912, 177.78792333602905, 178.71822810173035, 179.64853286743164, 180.6032636165619, 181.55799436569214, 182.52799487113953, 183.4979953765869, 184.9579963684082, 186.4179973602295]
[12.48, 12.48, 13.66, 13.66, 15.73, 15.73, 18.97, 18.97, 20.69, 20.69, 23.34, 23.34, 25.85, 25.85, 31.13, 31.13, 40.18, 40.18, 43.34, 43.34, 45.73, 45.73, 48.96, 48.96, 56.47, 56.47, 59.33, 59.33, 61.38, 61.38, 66.23, 66.23, 70.45, 70.45, 72.89, 72.89, 75.16, 75.16, 76.49, 76.49, 78.36, 78.36, 78.79, 78.79, 79.09, 79.09, 79.12, 79.12, 80.09, 80.09, 81.76, 81.76, 83.56, 83.56, 83.78, 83.78, 83.67, 83.67, 83.69, 83.69, 83.99, 83.99, 85.71, 85.71, 86.31, 86.31, 86.26, 86.26, 86.38, 86.38, 86.84, 86.84, 86.75, 86.75, 86.89, 86.89, 88.01, 88.01, 88.8, 88.8, 89.01, 89.01, 89.04, 89.04, 89.16, 89.16, 89.26, 89.26, 89.21, 89.21, 89.19, 89.19, 89.22, 89.22, 89.34, 89.34, 89.36, 89.36, 89.38, 89.38, 89.56, 89.56, 89.36, 89.36, 89.54, 89.54, 89.55, 89.55, 89.51, 89.51, 89.61, 89.61, 89.71, 89.71, 89.75, 89.75, 89.82, 89.82, 90.65, 90.65, 90.7, 90.7, 90.69, 90.69, 90.57, 90.57, 90.61, 90.61, 90.89, 90.89, 90.73, 90.73, 90.86, 90.86, 90.78, 90.78, 90.78, 90.78, 90.93, 90.93, 90.9, 90.9, 91.09, 91.09, 90.98, 90.98, 91.01, 91.01, 91.16, 91.16, 90.94, 90.94, 91.09, 91.09, 91.04, 91.04, 91.11, 91.11, 91.05, 91.05, 90.95, 90.95, 91.07, 91.07, 91.11, 91.11, 91.1, 91.1, 92.11, 92.11, 92.16, 92.16, 92.01, 92.01, 92.12, 92.12, 92.98, 92.98, 92.96, 92.96, 93.15, 93.15, 93.16, 93.16, 93.06, 93.06, 93.12, 93.12, 93.24, 93.24, 93.05, 93.05, 93.1, 93.1, 93.21, 93.21, 93.06, 93.06, 93.17, 93.17, 94.77, 94.77]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.290, Test loss: 2.291, Test accuracy: 19.65
Round   0, Global train loss: 2.290, Global test loss: 2.299, Global test accuracy: 15.41
Round   1, Train loss: 2.197, Test loss: 2.227, Test accuracy: 24.86
Round   1, Global train loss: 2.197, Global test loss: 2.281, Global test accuracy: 15.87
Round   2, Train loss: 2.076, Test loss: 2.129, Test accuracy: 35.86
Round   2, Global train loss: 2.076, Global test loss: 2.272, Global test accuracy: 13.10
Round   3, Train loss: 1.873, Test loss: 2.035, Test accuracy: 45.81
Round   3, Global train loss: 1.873, Global test loss: 2.275, Global test accuracy: 14.74
Round   4, Train loss: 1.932, Test loss: 1.957, Test accuracy: 55.18
Round   4, Global train loss: 1.932, Global test loss: 2.261, Global test accuracy: 16.46
Round   5, Train loss: 1.781, Test loss: 1.868, Test accuracy: 63.74
Round   5, Global train loss: 1.781, Global test loss: 2.250, Global test accuracy: 19.23
Round   6, Train loss: 1.859, Test loss: 1.812, Test accuracy: 69.81
Round   6, Global train loss: 1.859, Global test loss: 2.242, Global test accuracy: 22.02
Round   7, Train loss: 1.690, Test loss: 1.766, Test accuracy: 74.38
Round   7, Global train loss: 1.690, Global test loss: 2.275, Global test accuracy: 13.63
Round   8, Train loss: 1.617, Test loss: 1.747, Test accuracy: 74.60
Round   8, Global train loss: 1.617, Global test loss: 2.263, Global test accuracy: 16.53
Round   9, Train loss: 1.591, Test loss: 1.745, Test accuracy: 74.91
Round   9, Global train loss: 1.591, Global test loss: 2.250, Global test accuracy: 19.48
Round  10, Train loss: 1.605, Test loss: 1.741, Test accuracy: 74.92
Round  10, Global train loss: 1.605, Global test loss: 2.273, Global test accuracy: 16.67
Round  11, Train loss: 1.717, Test loss: 1.700, Test accuracy: 78.90
Round  11, Global train loss: 1.717, Global test loss: 2.253, Global test accuracy: 19.73
Round  12, Train loss: 1.583, Test loss: 1.698, Test accuracy: 79.00
Round  12, Global train loss: 1.583, Global test loss: 2.270, Global test accuracy: 16.31
Round  13, Train loss: 1.602, Test loss: 1.689, Test accuracy: 79.75
Round  13, Global train loss: 1.602, Global test loss: 2.241, Global test accuracy: 20.65
Round  14, Train loss: 1.672, Test loss: 1.676, Test accuracy: 79.42
Round  14, Global train loss: 1.672, Global test loss: 2.281, Global test accuracy: 14.92
Round  15, Train loss: 1.613, Test loss: 1.670, Test accuracy: 79.96
Round  15, Global train loss: 1.613, Global test loss: 2.237, Global test accuracy: 21.28
Round  16, Train loss: 1.591, Test loss: 1.661, Test accuracy: 80.95
Round  16, Global train loss: 1.591, Global test loss: 2.224, Global test accuracy: 20.95
Round  17, Train loss: 1.562, Test loss: 1.648, Test accuracy: 82.37
Round  17, Global train loss: 1.562, Global test loss: 2.257, Global test accuracy: 18.15
Round  18, Train loss: 1.602, Test loss: 1.637, Test accuracy: 83.54
Round  18, Global train loss: 1.602, Global test loss: 2.244, Global test accuracy: 19.31
Round  19, Train loss: 1.616, Test loss: 1.634, Test accuracy: 83.74
Round  19, Global train loss: 1.616, Global test loss: 2.254, Global test accuracy: 17.88
Round  20, Train loss: 1.543, Test loss: 1.632, Test accuracy: 83.89
Round  20, Global train loss: 1.543, Global test loss: 2.245, Global test accuracy: 20.85
Round  21, Train loss: 1.551, Test loss: 1.629, Test accuracy: 84.05
Round  21, Global train loss: 1.551, Global test loss: 2.280, Global test accuracy: 14.85
Round  22, Train loss: 1.575, Test loss: 1.628, Test accuracy: 84.01
Round  22, Global train loss: 1.575, Global test loss: 2.301, Global test accuracy: 10.82
Round  23, Train loss: 1.583, Test loss: 1.625, Test accuracy: 84.26
Round  23, Global train loss: 1.583, Global test loss: 2.260, Global test accuracy: 18.79
Round  24, Train loss: 1.539, Test loss: 1.624, Test accuracy: 84.32
Round  24, Global train loss: 1.539, Global test loss: 2.248, Global test accuracy: 19.04
Round  25, Train loss: 1.575, Test loss: 1.623, Test accuracy: 84.32
Round  25, Global train loss: 1.575, Global test loss: 2.258, Global test accuracy: 17.59
Round  26, Train loss: 1.577, Test loss: 1.623, Test accuracy: 84.43
Round  26, Global train loss: 1.577, Global test loss: 2.245, Global test accuracy: 18.12
Round  27, Train loss: 1.603, Test loss: 1.622, Test accuracy: 84.45
Round  27, Global train loss: 1.603, Global test loss: 2.257, Global test accuracy: 16.98
Round  28, Train loss: 1.569, Test loss: 1.622, Test accuracy: 84.49
Round  28, Global train loss: 1.569, Global test loss: 2.298, Global test accuracy: 11.69
Round  29, Train loss: 1.539, Test loss: 1.621, Test accuracy: 84.50
Round  29, Global train loss: 1.539, Global test loss: 2.275, Global test accuracy: 15.87
Round  30, Train loss: 1.602, Test loss: 1.621, Test accuracy: 84.54
Round  30, Global train loss: 1.602, Global test loss: 2.276, Global test accuracy: 16.22
Round  31, Train loss: 1.566, Test loss: 1.621, Test accuracy: 84.55
Round  31, Global train loss: 1.566, Global test loss: 2.266, Global test accuracy: 16.88
Round  32, Train loss: 1.603, Test loss: 1.621, Test accuracy: 84.53
Round  32, Global train loss: 1.603, Global test loss: 2.244, Global test accuracy: 18.99
Round  33, Train loss: 1.602, Test loss: 1.620, Test accuracy: 84.51
Round  33, Global train loss: 1.602, Global test loss: 2.261, Global test accuracy: 18.36
Round  34, Train loss: 1.537, Test loss: 1.620, Test accuracy: 84.50
Round  34, Global train loss: 1.537, Global test loss: 2.255, Global test accuracy: 17.47
Round  35, Train loss: 1.600, Test loss: 1.620, Test accuracy: 84.48
Round  35, Global train loss: 1.600, Global test loss: 2.239, Global test accuracy: 21.11
Round  36, Train loss: 1.567, Test loss: 1.620, Test accuracy: 84.56
Round  36, Global train loss: 1.567, Global test loss: 2.258, Global test accuracy: 17.83
Round  37, Train loss: 1.504, Test loss: 1.620, Test accuracy: 84.55
Round  37, Global train loss: 1.504, Global test loss: 2.257, Global test accuracy: 17.16
Round  38, Train loss: 1.533, Test loss: 1.620, Test accuracy: 84.58
Round  38, Global train loss: 1.533, Global test loss: 2.268, Global test accuracy: 16.62
Round  39, Train loss: 1.567, Test loss: 1.620, Test accuracy: 84.57
Round  39, Global train loss: 1.567, Global test loss: 2.273, Global test accuracy: 16.27
Round  40, Train loss: 1.534, Test loss: 1.620, Test accuracy: 84.58
Round  40, Global train loss: 1.534, Global test loss: 2.270, Global test accuracy: 16.83
Round  41, Train loss: 1.549, Test loss: 1.612, Test accuracy: 85.61
Round  41, Global train loss: 1.549, Global test loss: 2.260, Global test accuracy: 18.83
Round  42, Train loss: 1.565, Test loss: 1.612, Test accuracy: 85.60
Round  42, Global train loss: 1.565, Global test loss: 2.251, Global test accuracy: 19.38
Round  43, Train loss: 1.533, Test loss: 1.612, Test accuracy: 85.62
Round  43, Global train loss: 1.533, Global test loss: 2.269, Global test accuracy: 17.50
Round  44, Train loss: 1.510, Test loss: 1.609, Test accuracy: 85.91
Round  44, Global train loss: 1.510, Global test loss: 2.263, Global test accuracy: 16.45
Round  45, Train loss: 1.598, Test loss: 1.609, Test accuracy: 85.91
Round  45, Global train loss: 1.598, Global test loss: 2.244, Global test accuracy: 19.90
Round  46, Train loss: 1.469, Test loss: 1.609, Test accuracy: 85.88
Round  46, Global train loss: 1.469, Global test loss: 2.328, Global test accuracy: 11.00
Round  47, Train loss: 1.502, Test loss: 1.602, Test accuracy: 86.58
Round  47, Global train loss: 1.502, Global test loss: 2.268, Global test accuracy: 16.36
Round  48, Train loss: 1.558, Test loss: 1.593, Test accuracy: 87.61
Round  48, Global train loss: 1.558, Global test loss: 2.255, Global test accuracy: 18.35
Round  49, Train loss: 1.469, Test loss: 1.593, Test accuracy: 87.62
Round  49, Global train loss: 1.469, Global test loss: 2.265, Global test accuracy: 16.86
Round  50, Train loss: 1.537, Test loss: 1.593, Test accuracy: 87.64
Round  50, Global train loss: 1.537, Global test loss: 2.237, Global test accuracy: 21.58
Round  51, Train loss: 1.534, Test loss: 1.593, Test accuracy: 87.65
Round  51, Global train loss: 1.534, Global test loss: 2.297, Global test accuracy: 13.88
Round  52, Train loss: 1.477, Test loss: 1.592, Test accuracy: 87.58
Round  52, Global train loss: 1.477, Global test loss: 2.253, Global test accuracy: 18.67
Round  53, Train loss: 1.470, Test loss: 1.592, Test accuracy: 87.56
Round  53, Global train loss: 1.470, Global test loss: 2.266, Global test accuracy: 17.89
Round  54, Train loss: 1.499, Test loss: 1.592, Test accuracy: 87.54
Round  54, Global train loss: 1.499, Global test loss: 2.306, Global test accuracy: 12.57
Round  55, Train loss: 1.598, Test loss: 1.591, Test accuracy: 87.53
Round  55, Global train loss: 1.598, Global test loss: 2.249, Global test accuracy: 19.44
Round  56, Train loss: 1.503, Test loss: 1.591, Test accuracy: 87.54
Round  56, Global train loss: 1.503, Global test loss: 2.241, Global test accuracy: 20.12
Round  57, Train loss: 1.501, Test loss: 1.590, Test accuracy: 87.52
Round  57, Global train loss: 1.501, Global test loss: 2.255, Global test accuracy: 19.39
Round  58, Train loss: 1.500, Test loss: 1.590, Test accuracy: 87.51
Round  58, Global train loss: 1.500, Global test loss: 2.246, Global test accuracy: 19.55
Round  59, Train loss: 1.501, Test loss: 1.590, Test accuracy: 87.52
Round  59, Global train loss: 1.501, Global test loss: 2.245, Global test accuracy: 19.46
Round  60, Train loss: 1.500, Test loss: 1.590, Test accuracy: 87.56
Round  60, Global train loss: 1.500, Global test loss: 2.259, Global test accuracy: 18.26
Round  61, Train loss: 1.501, Test loss: 1.590, Test accuracy: 87.56
Round  61, Global train loss: 1.501, Global test loss: 2.251, Global test accuracy: 19.93
Round  62, Train loss: 1.532, Test loss: 1.590, Test accuracy: 87.55
Round  62, Global train loss: 1.532, Global test loss: 2.242, Global test accuracy: 20.48
Round  63, Train loss: 1.513, Test loss: 1.583, Test accuracy: 88.34
Round  63, Global train loss: 1.513, Global test loss: 2.273, Global test accuracy: 16.75
Round  64, Train loss: 1.535, Test loss: 1.582, Test accuracy: 88.39
Round  64, Global train loss: 1.535, Global test loss: 2.256, Global test accuracy: 18.54
Round  65, Train loss: 1.504, Test loss: 1.582, Test accuracy: 88.41
Round  65, Global train loss: 1.504, Global test loss: 2.244, Global test accuracy: 20.00
Round  66, Train loss: 1.500, Test loss: 1.582, Test accuracy: 88.40
Round  66, Global train loss: 1.500, Global test loss: 2.280, Global test accuracy: 14.81
Round  67, Train loss: 1.469, Test loss: 1.581, Test accuracy: 88.40
Round  67, Global train loss: 1.469, Global test loss: 2.238, Global test accuracy: 20.66
Round  68, Train loss: 1.564, Test loss: 1.581, Test accuracy: 88.39
Round  68, Global train loss: 1.564, Global test loss: 2.259, Global test accuracy: 16.79
Round  69, Train loss: 1.468, Test loss: 1.581, Test accuracy: 88.39
Round  69, Global train loss: 1.468, Global test loss: 2.300, Global test accuracy: 14.08
Round  70, Train loss: 1.485, Test loss: 1.575, Test accuracy: 89.04
Round  70, Global train loss: 1.485, Global test loss: 2.294, Global test accuracy: 12.30
Round  71, Train loss: 1.499, Test loss: 1.575, Test accuracy: 89.05
Round  71, Global train loss: 1.499, Global test loss: 2.253, Global test accuracy: 18.68
Round  72, Train loss: 1.537, Test loss: 1.574, Test accuracy: 89.14
Round  72, Global train loss: 1.537, Global test loss: 2.257, Global test accuracy: 17.94
Round  73, Train loss: 1.503, Test loss: 1.573, Test accuracy: 89.19
Round  73, Global train loss: 1.503, Global test loss: 2.239, Global test accuracy: 21.70
Round  74, Train loss: 1.469, Test loss: 1.573, Test accuracy: 89.23
Round  74, Global train loss: 1.469, Global test loss: 2.256, Global test accuracy: 19.08
Round  75, Train loss: 1.534, Test loss: 1.573, Test accuracy: 89.25
Round  75, Global train loss: 1.534, Global test loss: 2.243, Global test accuracy: 19.73
Round  76, Train loss: 1.500, Test loss: 1.573, Test accuracy: 89.23
Round  76, Global train loss: 1.500, Global test loss: 2.262, Global test accuracy: 17.77
Round  77, Train loss: 1.468, Test loss: 1.572, Test accuracy: 89.23
Round  77, Global train loss: 1.468, Global test loss: 2.249, Global test accuracy: 19.52
Round  78, Train loss: 1.468, Test loss: 1.572, Test accuracy: 89.25
Round  78, Global train loss: 1.468, Global test loss: 2.235, Global test accuracy: 21.10
Round  79, Train loss: 1.467, Test loss: 1.572, Test accuracy: 89.25
Round  79, Global train loss: 1.467, Global test loss: 2.253, Global test accuracy: 18.49
Round  80, Train loss: 1.533, Test loss: 1.572, Test accuracy: 89.23
Round  80, Global train loss: 1.533, Global test loss: 2.245, Global test accuracy: 19.68
Round  81, Train loss: 1.532, Test loss: 1.572, Test accuracy: 89.22
Round  81, Global train loss: 1.532, Global test loss: 2.214, Global test accuracy: 24.27
Round  82, Train loss: 1.468, Test loss: 1.572, Test accuracy: 89.23
Round  82, Global train loss: 1.468, Global test loss: 2.260, Global test accuracy: 17.00
Round  83, Train loss: 1.498, Test loss: 1.572, Test accuracy: 89.23
Round  83, Global train loss: 1.498, Global test loss: 2.273, Global test accuracy: 17.01
Round  84, Train loss: 1.467, Test loss: 1.572, Test accuracy: 89.23
Round  84, Global train loss: 1.467, Global test loss: 2.263, Global test accuracy: 17.29
Round  85, Train loss: 1.468, Test loss: 1.572, Test accuracy: 89.24
Round  85, Global train loss: 1.468, Global test loss: 2.288, Global test accuracy: 14.20
Round  86, Train loss: 1.500, Test loss: 1.572, Test accuracy: 89.24
Round  86, Global train loss: 1.500, Global test loss: 2.265, Global test accuracy: 17.47
Round  87, Train loss: 1.468, Test loss: 1.572, Test accuracy: 89.23
Round  87, Global train loss: 1.468, Global test loss: 2.266, Global test accuracy: 17.42
Round  88, Train loss: 1.499, Test loss: 1.572, Test accuracy: 89.26
Round  88, Global train loss: 1.499, Global test loss: 2.282, Global test accuracy: 14.67
Round  89, Train loss: 1.466, Test loss: 1.572, Test accuracy: 89.26
Round  89, Global train loss: 1.466, Global test loss: 2.244, Global test accuracy: 19.89
Round  90, Train loss: 1.467, Test loss: 1.572, Test accuracy: 89.25
Round  90, Global train loss: 1.467, Global test loss: 2.282, Global test accuracy: 15.50
Round  91, Train loss: 1.499, Test loss: 1.572, Test accuracy: 89.25
Round  91, Global train loss: 1.499, Global test loss: 2.259, Global test accuracy: 18.04
Round  92, Train loss: 1.497, Test loss: 1.572, Test accuracy: 89.27
Round  92, Global train loss: 1.497, Global test loss: 2.248, Global test accuracy: 19.10
Round  93, Train loss: 1.466, Test loss: 1.572, Test accuracy: 89.28
Round  93, Global train loss: 1.466, Global test loss: 2.286, Global test accuracy: 14.18
Round  94, Train loss: 1.468, Test loss: 1.572, Test accuracy: 89.27
Round  94, Global train loss: 1.468, Global test loss: 2.240, Global test accuracy: 18.87
Round  95, Train loss: 1.499, Test loss: 1.571, Test accuracy: 89.26
Round  95, Global train loss: 1.499, Global test loss: 2.279, Global test accuracy: 16.45/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 1.483, Test loss: 1.567, Test accuracy: 89.80
Round  96, Global train loss: 1.483, Global test loss: 2.242, Global test accuracy: 21.38
Round  97, Train loss: 1.466, Test loss: 1.567, Test accuracy: 89.81
Round  97, Global train loss: 1.466, Global test loss: 2.264, Global test accuracy: 17.80
Round  98, Train loss: 1.507, Test loss: 1.566, Test accuracy: 89.95
Round  98, Global train loss: 1.507, Global test loss: 2.228, Global test accuracy: 22.25
Round  99, Train loss: 1.466, Test loss: 1.566, Test accuracy: 89.94
Round  99, Global train loss: 1.466, Global test loss: 2.256, Global test accuracy: 18.37
Final Round, Train loss: 1.487, Test loss: 1.564, Test accuracy: 90.04
Final Round, Global train loss: 1.487, Global test loss: 2.256, Global test accuracy: 18.37
Average accuracy final 10 rounds: 89.508 

Average global accuracy final 10 rounds: 18.194 

1199.7167174816132
[0.928635835647583, 1.857271671295166, 2.6892454624176025, 3.521219253540039, 4.330104827880859, 5.13899040222168, 5.954557657241821, 6.770124912261963, 7.512764930725098, 8.255404949188232, 8.985074043273926, 9.71474313735962, 10.410840272903442, 11.106937408447266, 11.83405327796936, 12.561169147491455, 13.278141736984253, 13.99511432647705, 14.739201545715332, 15.483288764953613, 16.229334831237793, 16.975380897521973, 17.686926126480103, 18.398471355438232, 19.137123346328735, 19.87577533721924, 20.606980800628662, 21.338186264038086, 22.088667392730713, 22.83914852142334, 23.56282901763916, 24.28650951385498, 25.019532680511475, 25.75255584716797, 26.491013288497925, 27.22947072982788, 27.966881036758423, 28.704291343688965, 29.3944149017334, 30.084538459777832, 30.824803113937378, 31.565067768096924, 32.298768043518066, 33.03246831893921, 33.7686562538147, 34.504844188690186, 35.2576630115509, 36.01048183441162, 36.74511408805847, 37.47974634170532, 38.21606206893921, 38.952377796173096, 39.67566204071045, 40.3989462852478, 41.13502597808838, 41.871105670928955, 42.621376752853394, 43.37164783477783, 44.120805501937866, 44.8699631690979, 45.60763478279114, 46.345306396484375, 47.06631016731262, 47.78731393814087, 48.50805854797363, 49.2288031578064, 49.96344995498657, 50.69809675216675, 51.44281530380249, 52.18753385543823, 52.91367959976196, 53.63982534408569, 54.35718274116516, 55.07454013824463, 55.78023338317871, 56.48592662811279, 57.225499629974365, 57.96507263183594, 58.704792976379395, 59.44451332092285, 60.16995358467102, 60.89539384841919, 61.61550259590149, 62.33561134338379, 63.03888559341431, 63.742159843444824, 64.47304511070251, 65.2039303779602, 65.94350981712341, 66.68308925628662, 67.41929602622986, 68.1555027961731, 68.88328957557678, 69.61107635498047, 70.32220673561096, 71.03333711624146, 71.76836490631104, 72.50339269638062, 73.21056199073792, 73.91773128509521, 74.6295371055603, 75.34134292602539, 76.06018400192261, 76.77902507781982, 77.52086305618286, 78.2627010345459, 79.00745868682861, 79.75221633911133, 80.45964455604553, 81.16707277297974, 81.8755874633789, 82.58410215377808, 83.31214189529419, 84.0401816368103, 84.78296542167664, 85.52574920654297, 86.2718780040741, 87.01800680160522, 87.74531412124634, 88.47262144088745, 89.17939972877502, 89.8861780166626, 90.59492421150208, 91.30367040634155, 92.05074167251587, 92.79781293869019, 93.53712821006775, 94.27644348144531, 95.0046136379242, 95.73278379440308, 96.4541392326355, 97.17549467086792, 97.90180253982544, 98.62811040878296, 99.35806083679199, 100.08801126480103, 100.82933402061462, 101.57065677642822, 102.3031439781189, 103.03563117980957, 103.76767992973328, 104.49972867965698, 105.23731899261475, 105.97490930557251, 106.70624589920044, 107.43758249282837, 108.15371322631836, 108.86984395980835, 109.57054138183594, 110.27123880386353, 111.00087428092957, 111.7305097579956, 112.47457194328308, 113.21863412857056, 113.96591687202454, 114.71319961547852, 115.4390299320221, 116.16486024856567, 116.87993216514587, 117.59500408172607, 118.32286238670349, 119.05072069168091, 119.77592158317566, 120.50112247467041, 121.24439764022827, 121.98767280578613, 122.72437381744385, 123.46107482910156, 124.18302750587463, 124.9049801826477, 125.61801171302795, 126.3310432434082, 127.06798267364502, 127.80492210388184, 128.55129957199097, 129.2976770401001, 130.03364443778992, 130.76961183547974, 131.48352217674255, 132.19743251800537, 132.9319932460785, 133.6665539741516, 134.39209246635437, 135.11763095855713, 135.82222032546997, 136.5268096923828, 137.23328757286072, 137.93976545333862, 138.6879849433899, 139.43620443344116, 140.18589329719543, 140.9355821609497, 141.66065788269043, 142.38573360443115, 143.0932719707489, 143.80081033706665, 144.5432538986206, 145.28569746017456, 146.0337257385254, 146.78175401687622, 148.23582816123962, 149.68990230560303]
[19.65, 19.65, 24.86, 24.86, 35.86, 35.86, 45.81, 45.81, 55.18, 55.18, 63.74, 63.74, 69.81, 69.81, 74.38, 74.38, 74.6, 74.6, 74.91, 74.91, 74.92, 74.92, 78.9, 78.9, 79.0, 79.0, 79.75, 79.75, 79.42, 79.42, 79.96, 79.96, 80.95, 80.95, 82.37, 82.37, 83.54, 83.54, 83.74, 83.74, 83.89, 83.89, 84.05, 84.05, 84.01, 84.01, 84.26, 84.26, 84.32, 84.32, 84.32, 84.32, 84.43, 84.43, 84.45, 84.45, 84.49, 84.49, 84.5, 84.5, 84.54, 84.54, 84.55, 84.55, 84.53, 84.53, 84.51, 84.51, 84.5, 84.5, 84.48, 84.48, 84.56, 84.56, 84.55, 84.55, 84.58, 84.58, 84.57, 84.57, 84.58, 84.58, 85.61, 85.61, 85.6, 85.6, 85.62, 85.62, 85.91, 85.91, 85.91, 85.91, 85.88, 85.88, 86.58, 86.58, 87.61, 87.61, 87.62, 87.62, 87.64, 87.64, 87.65, 87.65, 87.58, 87.58, 87.56, 87.56, 87.54, 87.54, 87.53, 87.53, 87.54, 87.54, 87.52, 87.52, 87.51, 87.51, 87.52, 87.52, 87.56, 87.56, 87.56, 87.56, 87.55, 87.55, 88.34, 88.34, 88.39, 88.39, 88.41, 88.41, 88.4, 88.4, 88.4, 88.4, 88.39, 88.39, 88.39, 88.39, 89.04, 89.04, 89.05, 89.05, 89.14, 89.14, 89.19, 89.19, 89.23, 89.23, 89.25, 89.25, 89.23, 89.23, 89.23, 89.23, 89.25, 89.25, 89.25, 89.25, 89.23, 89.23, 89.22, 89.22, 89.23, 89.23, 89.23, 89.23, 89.23, 89.23, 89.24, 89.24, 89.24, 89.24, 89.23, 89.23, 89.26, 89.26, 89.26, 89.26, 89.25, 89.25, 89.25, 89.25, 89.27, 89.27, 89.28, 89.28, 89.27, 89.27, 89.26, 89.26, 89.8, 89.8, 89.81, 89.81, 89.95, 89.95, 89.94, 89.94, 90.04, 90.04]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.287, Test loss: 2.289, Test accuracy: 15.92
Round   0, Global train loss: 2.287, Global test loss: 2.301, Global test accuracy: 11.00
Round   1, Train loss: 2.252, Test loss: 2.251, Test accuracy: 21.15
Round   1, Global train loss: 2.252, Global test loss: 2.297, Global test accuracy: 14.03
Round   2, Train loss: 2.152, Test loss: 2.177, Test accuracy: 28.90
Round   2, Global train loss: 2.152, Global test loss: 2.280, Global test accuracy: 15.86
Round   3, Train loss: 2.079, Test loss: 2.103, Test accuracy: 37.19
Round   3, Global train loss: 2.079, Global test loss: 2.277, Global test accuracy: 16.12
Round   4, Train loss: 1.988, Test loss: 2.063, Test accuracy: 40.35
Round   4, Global train loss: 1.988, Global test loss: 2.277, Global test accuracy: 14.65
Round   5, Train loss: 1.978, Test loss: 2.024, Test accuracy: 44.32
Round   5, Global train loss: 1.978, Global test loss: 2.274, Global test accuracy: 15.88
Round   6, Train loss: 1.921, Test loss: 2.001, Test accuracy: 46.62
Round   6, Global train loss: 1.921, Global test loss: 2.265, Global test accuracy: 16.79
Round   7, Train loss: 2.000, Test loss: 1.969, Test accuracy: 49.80
Round   7, Global train loss: 2.000, Global test loss: 2.268, Global test accuracy: 17.28
Round   8, Train loss: 1.968, Test loss: 1.936, Test accuracy: 53.01
Round   8, Global train loss: 1.968, Global test loss: 2.268, Global test accuracy: 17.42
Round   9, Train loss: 1.963, Test loss: 1.926, Test accuracy: 53.90
Round   9, Global train loss: 1.963, Global test loss: 2.262, Global test accuracy: 17.99
Round  10, Train loss: 1.943, Test loss: 1.926, Test accuracy: 53.88
Round  10, Global train loss: 1.943, Global test loss: 2.275, Global test accuracy: 15.24
Round  11, Train loss: 1.926, Test loss: 1.907, Test accuracy: 55.86
Round  11, Global train loss: 1.926, Global test loss: 2.271, Global test accuracy: 16.71
Round  12, Train loss: 1.913, Test loss: 1.898, Test accuracy: 56.62
Round  12, Global train loss: 1.913, Global test loss: 2.286, Global test accuracy: 14.86
Round  13, Train loss: 1.938, Test loss: 1.904, Test accuracy: 55.84
Round  13, Global train loss: 1.938, Global test loss: 2.267, Global test accuracy: 17.51
Round  14, Train loss: 1.972, Test loss: 1.903, Test accuracy: 55.83
Round  14, Global train loss: 1.972, Global test loss: 2.277, Global test accuracy: 16.09
Round  15, Train loss: 1.988, Test loss: 1.920, Test accuracy: 54.02
Round  15, Global train loss: 1.988, Global test loss: 2.274, Global test accuracy: 16.41
Round  16, Train loss: 1.888, Test loss: 1.910, Test accuracy: 55.01
Round  16, Global train loss: 1.888, Global test loss: 2.288, Global test accuracy: 14.16
Round  17, Train loss: 1.908, Test loss: 1.909, Test accuracy: 55.16
Round  17, Global train loss: 1.908, Global test loss: 2.264, Global test accuracy: 17.10
Round  18, Train loss: 1.919, Test loss: 1.899, Test accuracy: 56.15
Round  18, Global train loss: 1.919, Global test loss: 2.262, Global test accuracy: 18.07
Round  19, Train loss: 1.965, Test loss: 1.899, Test accuracy: 56.13
Round  19, Global train loss: 1.965, Global test loss: 2.267, Global test accuracy: 17.11
Round  20, Train loss: 1.878, Test loss: 1.890, Test accuracy: 57.12
Round  20, Global train loss: 1.878, Global test loss: 2.260, Global test accuracy: 18.08
Round  21, Train loss: 1.930, Test loss: 1.883, Test accuracy: 57.90
Round  21, Global train loss: 1.930, Global test loss: 2.249, Global test accuracy: 19.72
Round  22, Train loss: 1.982, Test loss: 1.883, Test accuracy: 57.88
Round  22, Global train loss: 1.982, Global test loss: 2.247, Global test accuracy: 19.91
Round  23, Train loss: 1.850, Test loss: 1.866, Test accuracy: 59.74
Round  23, Global train loss: 1.850, Global test loss: 2.269, Global test accuracy: 16.57
Round  24, Train loss: 1.899, Test loss: 1.864, Test accuracy: 59.80
Round  24, Global train loss: 1.899, Global test loss: 2.249, Global test accuracy: 19.25
Round  25, Train loss: 1.882, Test loss: 1.865, Test accuracy: 59.67
Round  25, Global train loss: 1.882, Global test loss: 2.266, Global test accuracy: 17.61
Round  26, Train loss: 1.791, Test loss: 1.864, Test accuracy: 59.71
Round  26, Global train loss: 1.791, Global test loss: 2.243, Global test accuracy: 20.09
Round  27, Train loss: 1.798, Test loss: 1.864, Test accuracy: 59.70
Round  27, Global train loss: 1.798, Global test loss: 2.243, Global test accuracy: 19.91
Round  28, Train loss: 1.829, Test loss: 1.872, Test accuracy: 58.81
Round  28, Global train loss: 1.829, Global test loss: 2.248, Global test accuracy: 18.90
Round  29, Train loss: 1.872, Test loss: 1.864, Test accuracy: 59.60
Round  29, Global train loss: 1.872, Global test loss: 2.247, Global test accuracy: 19.31
Round  30, Train loss: 1.773, Test loss: 1.840, Test accuracy: 62.07
Round  30, Global train loss: 1.773, Global test loss: 2.248, Global test accuracy: 19.59
Round  31, Train loss: 1.808, Test loss: 1.838, Test accuracy: 62.29
Round  31, Global train loss: 1.808, Global test loss: 2.264, Global test accuracy: 17.91
Round  32, Train loss: 1.843, Test loss: 1.839, Test accuracy: 62.29
Round  32, Global train loss: 1.843, Global test loss: 2.246, Global test accuracy: 20.46
Round  33, Train loss: 1.905, Test loss: 1.821, Test accuracy: 63.99
Round  33, Global train loss: 1.905, Global test loss: 2.263, Global test accuracy: 17.86
Round  34, Train loss: 1.879, Test loss: 1.821, Test accuracy: 63.99
Round  34, Global train loss: 1.879, Global test loss: 2.240, Global test accuracy: 20.78
Round  35, Train loss: 1.787, Test loss: 1.821, Test accuracy: 63.90
Round  35, Global train loss: 1.787, Global test loss: 2.242, Global test accuracy: 19.89
Round  36, Train loss: 1.834, Test loss: 1.821, Test accuracy: 63.98
Round  36, Global train loss: 1.834, Global test loss: 2.260, Global test accuracy: 18.98
Round  37, Train loss: 1.832, Test loss: 1.819, Test accuracy: 64.20
Round  37, Global train loss: 1.832, Global test loss: 2.244, Global test accuracy: 19.81
Round  38, Train loss: 1.728, Test loss: 1.810, Test accuracy: 65.08
Round  38, Global train loss: 1.728, Global test loss: 2.245, Global test accuracy: 19.88
Round  39, Train loss: 1.883, Test loss: 1.800, Test accuracy: 66.12
Round  39, Global train loss: 1.883, Global test loss: 2.244, Global test accuracy: 19.88
Round  40, Train loss: 1.763, Test loss: 1.801, Test accuracy: 66.04
Round  40, Global train loss: 1.763, Global test loss: 2.254, Global test accuracy: 18.87
Round  41, Train loss: 1.837, Test loss: 1.794, Test accuracy: 66.72
Round  41, Global train loss: 1.837, Global test loss: 2.266, Global test accuracy: 17.05
Round  42, Train loss: 1.781, Test loss: 1.793, Test accuracy: 66.73
Round  42, Global train loss: 1.781, Global test loss: 2.257, Global test accuracy: 18.95
Round  43, Train loss: 1.809, Test loss: 1.793, Test accuracy: 66.86
Round  43, Global train loss: 1.809, Global test loss: 2.261, Global test accuracy: 17.97
Round  44, Train loss: 1.895, Test loss: 1.802, Test accuracy: 65.96
Round  44, Global train loss: 1.895, Global test loss: 2.260, Global test accuracy: 17.86
Round  45, Train loss: 1.757, Test loss: 1.792, Test accuracy: 66.95
Round  45, Global train loss: 1.757, Global test loss: 2.255, Global test accuracy: 19.37
Round  46, Train loss: 1.806, Test loss: 1.796, Test accuracy: 66.69
Round  46, Global train loss: 1.806, Global test loss: 2.269, Global test accuracy: 17.44
Round  47, Train loss: 1.733, Test loss: 1.796, Test accuracy: 66.62
Round  47, Global train loss: 1.733, Global test loss: 2.253, Global test accuracy: 18.66
Round  48, Train loss: 1.809, Test loss: 1.792, Test accuracy: 66.84
Round  48, Global train loss: 1.809, Global test loss: 2.273, Global test accuracy: 16.31
Round  49, Train loss: 1.837, Test loss: 1.803, Test accuracy: 65.78
Round  49, Global train loss: 1.837, Global test loss: 2.275, Global test accuracy: 16.46
Round  50, Train loss: 1.720, Test loss: 1.789, Test accuracy: 67.20
Round  50, Global train loss: 1.720, Global test loss: 2.248, Global test accuracy: 19.72
Round  51, Train loss: 1.802, Test loss: 1.797, Test accuracy: 66.33
Round  51, Global train loss: 1.802, Global test loss: 2.243, Global test accuracy: 20.30
Round  52, Train loss: 1.756, Test loss: 1.805, Test accuracy: 65.51
Round  52, Global train loss: 1.756, Global test loss: 2.251, Global test accuracy: 20.16
Round  53, Train loss: 1.938, Test loss: 1.798, Test accuracy: 66.47
Round  53, Global train loss: 1.938, Global test loss: 2.269, Global test accuracy: 16.89
Round  54, Train loss: 1.770, Test loss: 1.797, Test accuracy: 66.48
Round  54, Global train loss: 1.770, Global test loss: 2.278, Global test accuracy: 15.80
Round  55, Train loss: 1.762, Test loss: 1.784, Test accuracy: 67.73
Round  55, Global train loss: 1.762, Global test loss: 2.253, Global test accuracy: 19.18
Round  56, Train loss: 1.615, Test loss: 1.777, Test accuracy: 68.45
Round  56, Global train loss: 1.615, Global test loss: 2.254, Global test accuracy: 18.97
Round  57, Train loss: 1.791, Test loss: 1.776, Test accuracy: 68.59
Round  57, Global train loss: 1.791, Global test loss: 2.251, Global test accuracy: 19.14
Round  58, Train loss: 1.834, Test loss: 1.781, Test accuracy: 68.13
Round  58, Global train loss: 1.834, Global test loss: 2.236, Global test accuracy: 21.24
Round  59, Train loss: 1.760, Test loss: 1.762, Test accuracy: 70.07
Round  59, Global train loss: 1.760, Global test loss: 2.239, Global test accuracy: 20.52
Round  60, Train loss: 1.774, Test loss: 1.748, Test accuracy: 71.40
Round  60, Global train loss: 1.774, Global test loss: 2.252, Global test accuracy: 19.08
Round  61, Train loss: 1.792, Test loss: 1.752, Test accuracy: 70.97
Round  61, Global train loss: 1.792, Global test loss: 2.234, Global test accuracy: 21.09
Round  62, Train loss: 1.770, Test loss: 1.751, Test accuracy: 71.09
Round  62, Global train loss: 1.770, Global test loss: 2.239, Global test accuracy: 20.23
Round  63, Train loss: 1.745, Test loss: 1.767, Test accuracy: 69.48
Round  63, Global train loss: 1.745, Global test loss: 2.250, Global test accuracy: 19.44
Round  64, Train loss: 1.814, Test loss: 1.774, Test accuracy: 68.79
Round  64, Global train loss: 1.814, Global test loss: 2.255, Global test accuracy: 18.71
Round  65, Train loss: 1.805, Test loss: 1.773, Test accuracy: 68.88
Round  65, Global train loss: 1.805, Global test loss: 2.252, Global test accuracy: 18.81
Round  66, Train loss: 1.729, Test loss: 1.774, Test accuracy: 68.79
Round  66, Global train loss: 1.729, Global test loss: 2.276, Global test accuracy: 16.25
Round  67, Train loss: 1.767, Test loss: 1.759, Test accuracy: 70.34
Round  67, Global train loss: 1.767, Global test loss: 2.272, Global test accuracy: 16.48
Round  68, Train loss: 1.763, Test loss: 1.751, Test accuracy: 71.20
Round  68, Global train loss: 1.763, Global test loss: 2.243, Global test accuracy: 19.73
Round  69, Train loss: 1.709, Test loss: 1.752, Test accuracy: 71.11
Round  69, Global train loss: 1.709, Global test loss: 2.251, Global test accuracy: 18.78
Round  70, Train loss: 1.729, Test loss: 1.743, Test accuracy: 71.88
Round  70, Global train loss: 1.729, Global test loss: 2.254, Global test accuracy: 18.59
Round  71, Train loss: 1.723, Test loss: 1.737, Test accuracy: 72.54
Round  71, Global train loss: 1.723, Global test loss: 2.247, Global test accuracy: 19.47
Round  72, Train loss: 1.764, Test loss: 1.735, Test accuracy: 72.73
Round  72, Global train loss: 1.764, Global test loss: 2.261, Global test accuracy: 18.06
Round  73, Train loss: 1.777, Test loss: 1.767, Test accuracy: 69.41
Round  73, Global train loss: 1.777, Global test loss: 2.273, Global test accuracy: 16.72
Round  74, Train loss: 1.776, Test loss: 1.760, Test accuracy: 70.16
Round  74, Global train loss: 1.776, Global test loss: 2.270, Global test accuracy: 16.37
Round  75, Train loss: 1.680, Test loss: 1.751, Test accuracy: 71.08
Round  75, Global train loss: 1.680, Global test loss: 2.254, Global test accuracy: 19.10
Round  76, Train loss: 1.752, Test loss: 1.722, Test accuracy: 74.10
Round  76, Global train loss: 1.752, Global test loss: 2.258, Global test accuracy: 18.67
Round  77, Train loss: 1.832, Test loss: 1.716, Test accuracy: 74.75
Round  77, Global train loss: 1.832, Global test loss: 2.258, Global test accuracy: 18.29
Round  78, Train loss: 1.639, Test loss: 1.694, Test accuracy: 76.89
Round  78, Global train loss: 1.639, Global test loss: 2.273, Global test accuracy: 17.08
Round  79, Train loss: 1.698, Test loss: 1.695, Test accuracy: 76.82
Round  79, Global train loss: 1.698, Global test loss: 2.249, Global test accuracy: 19.36
Round  80, Train loss: 1.751, Test loss: 1.693, Test accuracy: 77.12
Round  80, Global train loss: 1.751, Global test loss: 2.257, Global test accuracy: 18.70
Round  81, Train loss: 1.694, Test loss: 1.700, Test accuracy: 76.39
Round  81, Global train loss: 1.694, Global test loss: 2.268, Global test accuracy: 17.19
Round  82, Train loss: 1.667, Test loss: 1.692, Test accuracy: 77.30
Round  82, Global train loss: 1.667, Global test loss: 2.265, Global test accuracy: 17.92
Round  83, Train loss: 1.654, Test loss: 1.700, Test accuracy: 76.44
Round  83, Global train loss: 1.654, Global test loss: 2.271, Global test accuracy: 17.52
Round  84, Train loss: 1.745, Test loss: 1.732, Test accuracy: 73.05
Round  84, Global train loss: 1.745, Global test loss: 2.276, Global test accuracy: 15.76
Round  85, Train loss: 1.709, Test loss: 1.717, Test accuracy: 74.62
Round  85, Global train loss: 1.709, Global test loss: 2.264, Global test accuracy: 17.69
Round  86, Train loss: 1.678, Test loss: 1.692, Test accuracy: 77.23
Round  86, Global train loss: 1.678, Global test loss: 2.259, Global test accuracy: 18.33
Round  87, Train loss: 1.687, Test loss: 1.692, Test accuracy: 77.10
Round  87, Global train loss: 1.687, Global test loss: 2.248, Global test accuracy: 19.80
Round  88, Train loss: 1.722, Test loss: 1.681, Test accuracy: 78.28
Round  88, Global train loss: 1.722, Global test loss: 2.236, Global test accuracy: 20.78
Round  89, Train loss: 1.602, Test loss: 1.680, Test accuracy: 78.37
Round  89, Global train loss: 1.602, Global test loss: 2.254, Global test accuracy: 18.76
Round  90, Train loss: 1.717, Test loss: 1.681, Test accuracy: 78.32
Round  90, Global train loss: 1.717, Global test loss: 2.259, Global test accuracy: 17.68
Round  91, Train loss: 1.650, Test loss: 1.675, Test accuracy: 78.95
Round  91, Global train loss: 1.650, Global test loss: 2.258, Global test accuracy: 18.49
Round  92, Train loss: 1.688, Test loss: 1.669, Test accuracy: 79.59
Round  92, Global train loss: 1.688, Global test loss: 2.233, Global test accuracy: 21.11
Round  93, Train loss: 1.724, Test loss: 1.695, Test accuracy: 76.88
Round  93, Global train loss: 1.724, Global test loss: 2.255, Global test accuracy: 18.18
Round  94, Train loss: 1.687, Test loss: 1.694, Test accuracy: 76.87
Round  94, Global train loss: 1.687, Global test loss: 2.251, Global test accuracy: 19.16
Round  95, Train loss: 1.733, Test loss: 1.699, Test accuracy: 76.35
Round  95, Global train loss: 1.733, Global test loss: 2.249, Global test accuracy: 19.77/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 1.631, Test loss: 1.688, Test accuracy: 77.52
Round  96, Global train loss: 1.631, Global test loss: 2.242, Global test accuracy: 19.40
Round  97, Train loss: 1.672, Test loss: 1.696, Test accuracy: 76.69
Round  97, Global train loss: 1.672, Global test loss: 2.238, Global test accuracy: 20.61
Round  98, Train loss: 1.652, Test loss: 1.697, Test accuracy: 76.55
Round  98, Global train loss: 1.652, Global test loss: 2.240, Global test accuracy: 19.85
Round  99, Train loss: 1.697, Test loss: 1.697, Test accuracy: 76.44
Round  99, Global train loss: 1.697, Global test loss: 2.264, Global test accuracy: 17.33
Final Round, Train loss: 1.652, Test loss: 1.678, Test accuracy: 78.54
Final Round, Global train loss: 1.652, Global test loss: 2.264, Global test accuracy: 17.33
Average accuracy final 10 rounds: 77.416 

Average global accuracy final 10 rounds: 19.158 

1170.591626882553
[0.9053869247436523, 1.8107738494873047, 2.6480350494384766, 3.4852962493896484, 4.325146436691284, 5.16499662399292, 6.015503644943237, 6.866010665893555, 7.725646495819092, 8.585282325744629, 9.368652820587158, 10.152023315429688, 10.879101753234863, 11.606180191040039, 12.33479642868042, 13.0634126663208, 13.775938034057617, 14.488463401794434, 15.224759101867676, 15.961054801940918, 16.707913398742676, 17.454771995544434, 18.1854190826416, 18.91606616973877, 19.610484838485718, 20.304903507232666, 21.020081996917725, 21.735260486602783, 22.45604157447815, 23.176822662353516, 23.87746000289917, 24.578097343444824, 25.271193742752075, 25.964290142059326, 26.677115440368652, 27.38994073867798, 28.102272510528564, 28.81460428237915, 29.50694465637207, 30.19928503036499, 30.897068977355957, 31.594852924346924, 32.3151752948761, 33.03549766540527, 33.76059317588806, 34.48568868637085, 35.182122230529785, 35.87855577468872, 36.57426929473877, 37.26998281478882, 37.99212431907654, 38.71426582336426, 39.44105124473572, 40.16783666610718, 40.89214468002319, 41.61645269393921, 42.33820152282715, 43.05995035171509, 43.79124903678894, 44.52254772186279, 45.216060638427734, 45.909573554992676, 46.60559415817261, 47.30161476135254, 48.00248050689697, 48.703346252441406, 49.42021298408508, 50.13707971572876, 50.85753083229065, 51.57798194885254, 52.277904748916626, 52.97782754898071, 53.69406795501709, 54.41030836105347, 55.132587909698486, 55.854867458343506, 56.563963890075684, 57.27306032180786, 57.96749019622803, 58.66192007064819, 59.36175727844238, 60.06159448623657, 60.78058958053589, 61.499584674835205, 62.2311692237854, 62.962753772735596, 63.68250250816345, 64.40225124359131, 65.11065125465393, 65.81905126571655, 66.53084301948547, 67.2426347732544, 67.96216297149658, 68.68169116973877, 69.39861845970154, 70.1155457496643, 70.84246468544006, 71.56938362121582, 72.29604506492615, 73.02270650863647, 73.72098016738892, 74.41925382614136, 75.1431052684784, 75.86695671081543, 76.6006805896759, 77.33440446853638, 78.05051565170288, 78.76662683486938, 79.44980335235596, 80.13297986984253, 80.8263328075409, 81.51968574523926, 82.2506730556488, 82.98166036605835, 83.71167778968811, 84.44169521331787, 85.14703917503357, 85.85238313674927, 86.53853678703308, 87.2246904373169, 87.93026876449585, 88.6358470916748, 89.35194754600525, 90.0680480003357, 90.78577709197998, 91.50350618362427, 92.22922420501709, 92.95494222640991, 93.66971254348755, 94.38448286056519, 95.09615969657898, 95.80783653259277, 96.52552652359009, 97.2432165145874, 97.96117639541626, 98.67913627624512, 99.41039705276489, 100.14165782928467, 100.84350085258484, 101.54534387588501, 102.25187373161316, 102.95840358734131, 103.68712496757507, 104.41584634780884, 105.14742159843445, 105.87899684906006, 106.5842797756195, 107.28956270217896, 107.9880747795105, 108.68658685684204, 109.39347648620605, 110.10036611557007, 110.8304557800293, 111.56054544448853, 112.27894830703735, 112.99735116958618, 113.69570136070251, 114.39405155181885, 115.14445495605469, 115.89485836029053, 116.59361171722412, 117.29236507415771, 117.98181104660034, 118.67125701904297, 119.38929510116577, 120.10733318328857, 120.83130359649658, 121.55527400970459, 122.26602506637573, 122.97677612304688, 123.67079782485962, 124.36481952667236, 125.07785320281982, 125.79088687896729, 126.523690700531, 127.25649452209473, 127.97265529632568, 128.68881607055664, 129.38364243507385, 130.07846879959106, 130.79382038116455, 131.50917196273804, 132.23719716072083, 132.9652223587036, 133.67583179473877, 134.38644123077393, 135.09066891670227, 135.79489660263062, 136.51062726974487, 137.22635793685913, 137.93873238563538, 138.65110683441162, 139.35415863990784, 140.05721044540405, 140.76812839508057, 141.47904634475708, 142.1944601535797, 142.90987396240234, 143.61623311042786, 144.32259225845337, 145.7603521347046, 147.1981120109558]
[15.92, 15.92, 21.15, 21.15, 28.9, 28.9, 37.19, 37.19, 40.35, 40.35, 44.32, 44.32, 46.62, 46.62, 49.8, 49.8, 53.01, 53.01, 53.9, 53.9, 53.88, 53.88, 55.86, 55.86, 56.62, 56.62, 55.84, 55.84, 55.83, 55.83, 54.02, 54.02, 55.01, 55.01, 55.16, 55.16, 56.15, 56.15, 56.13, 56.13, 57.12, 57.12, 57.9, 57.9, 57.88, 57.88, 59.74, 59.74, 59.8, 59.8, 59.67, 59.67, 59.71, 59.71, 59.7, 59.7, 58.81, 58.81, 59.6, 59.6, 62.07, 62.07, 62.29, 62.29, 62.29, 62.29, 63.99, 63.99, 63.99, 63.99, 63.9, 63.9, 63.98, 63.98, 64.2, 64.2, 65.08, 65.08, 66.12, 66.12, 66.04, 66.04, 66.72, 66.72, 66.73, 66.73, 66.86, 66.86, 65.96, 65.96, 66.95, 66.95, 66.69, 66.69, 66.62, 66.62, 66.84, 66.84, 65.78, 65.78, 67.2, 67.2, 66.33, 66.33, 65.51, 65.51, 66.47, 66.47, 66.48, 66.48, 67.73, 67.73, 68.45, 68.45, 68.59, 68.59, 68.13, 68.13, 70.07, 70.07, 71.4, 71.4, 70.97, 70.97, 71.09, 71.09, 69.48, 69.48, 68.79, 68.79, 68.88, 68.88, 68.79, 68.79, 70.34, 70.34, 71.2, 71.2, 71.11, 71.11, 71.88, 71.88, 72.54, 72.54, 72.73, 72.73, 69.41, 69.41, 70.16, 70.16, 71.08, 71.08, 74.1, 74.1, 74.75, 74.75, 76.89, 76.89, 76.82, 76.82, 77.12, 77.12, 76.39, 76.39, 77.3, 77.3, 76.44, 76.44, 73.05, 73.05, 74.62, 74.62, 77.23, 77.23, 77.1, 77.1, 78.28, 78.28, 78.37, 78.37, 78.32, 78.32, 78.95, 78.95, 79.59, 79.59, 76.88, 76.88, 76.87, 76.87, 76.35, 76.35, 77.52, 77.52, 76.69, 76.69, 76.55, 76.55, 76.44, 76.44, 78.54, 78.54]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedrep  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedrep
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.296, Test loss: 2.300, Test accuracy: 12.00
Round   1, Train loss: 2.295, Test loss: 2.298, Test accuracy: 12.35
Round   2, Train loss: 2.287, Test loss: 2.295, Test accuracy: 14.03
Round   3, Train loss: 2.282, Test loss: 2.288, Test accuracy: 19.51
Round   4, Train loss: 2.254, Test loss: 2.271, Test accuracy: 14.87
Round   5, Train loss: 2.221, Test loss: 2.241, Test accuracy: 18.94
Round   6, Train loss: 2.189, Test loss: 2.216, Test accuracy: 22.89
Round   7, Train loss: 2.164, Test loss: 2.194, Test accuracy: 24.73
Round   8, Train loss: 2.100, Test loss: 2.167, Test accuracy: 28.79
Round   9, Train loss: 2.048, Test loss: 2.130, Test accuracy: 32.72
Round  10, Train loss: 2.048, Test loss: 2.092, Test accuracy: 36.26
Round  11, Train loss: 1.999, Test loss: 2.071, Test accuracy: 37.93
Round  12, Train loss: 1.903, Test loss: 2.016, Test accuracy: 45.08
Round  13, Train loss: 1.953, Test loss: 1.973, Test accuracy: 49.45
Round  14, Train loss: 1.917, Test loss: 1.964, Test accuracy: 50.18
Round  15, Train loss: 1.917, Test loss: 1.957, Test accuracy: 50.71
Round  16, Train loss: 1.833, Test loss: 1.946, Test accuracy: 52.08
Round  17, Train loss: 1.912, Test loss: 1.914, Test accuracy: 55.93
Round  18, Train loss: 1.843, Test loss: 1.902, Test accuracy: 56.88
Round  19, Train loss: 1.845, Test loss: 1.885, Test accuracy: 58.72
Round  20, Train loss: 1.892, Test loss: 1.878, Test accuracy: 59.37
Round  21, Train loss: 1.882, Test loss: 1.877, Test accuracy: 59.49
Round  22, Train loss: 1.806, Test loss: 1.873, Test accuracy: 59.52
Round  23, Train loss: 1.804, Test loss: 1.871, Test accuracy: 59.48
Round  24, Train loss: 1.832, Test loss: 1.869, Test accuracy: 59.72
Round  25, Train loss: 1.828, Test loss: 1.867, Test accuracy: 59.84
Round  26, Train loss: 1.871, Test loss: 1.867, Test accuracy: 59.80
Round  27, Train loss: 1.853, Test loss: 1.867, Test accuracy: 59.66
Round  28, Train loss: 1.832, Test loss: 1.866, Test accuracy: 59.86
Round  29, Train loss: 1.881, Test loss: 1.864, Test accuracy: 60.01
Round  30, Train loss: 1.792, Test loss: 1.863, Test accuracy: 60.04
Round  31, Train loss: 1.853, Test loss: 1.860, Test accuracy: 60.27
Round  32, Train loss: 1.853, Test loss: 1.859, Test accuracy: 60.33
Round  33, Train loss: 1.772, Test loss: 1.858, Test accuracy: 60.54
Round  34, Train loss: 1.792, Test loss: 1.858, Test accuracy: 60.44
Round  35, Train loss: 1.881, Test loss: 1.857, Test accuracy: 60.55
Round  36, Train loss: 1.744, Test loss: 1.856, Test accuracy: 60.64
Round  37, Train loss: 1.815, Test loss: 1.855, Test accuracy: 60.70
Round  38, Train loss: 1.825, Test loss: 1.851, Test accuracy: 61.15
Round  39, Train loss: 1.768, Test loss: 1.850, Test accuracy: 61.25
Round  40, Train loss: 1.770, Test loss: 1.849, Test accuracy: 61.38
Round  41, Train loss: 1.775, Test loss: 1.844, Test accuracy: 61.74
Round  42, Train loss: 1.771, Test loss: 1.840, Test accuracy: 62.40
Round  43, Train loss: 1.850, Test loss: 1.834, Test accuracy: 62.93
Round  44, Train loss: 1.809, Test loss: 1.834, Test accuracy: 62.95
Round  45, Train loss: 1.940, Test loss: 1.834, Test accuracy: 62.97
Round  46, Train loss: 1.840, Test loss: 1.834, Test accuracy: 62.91
Round  47, Train loss: 1.822, Test loss: 1.829, Test accuracy: 63.37
Round  48, Train loss: 1.732, Test loss: 1.830, Test accuracy: 63.37
Round  49, Train loss: 1.711, Test loss: 1.831, Test accuracy: 63.28
Round  50, Train loss: 1.759, Test loss: 1.829, Test accuracy: 63.40
Round  51, Train loss: 1.818, Test loss: 1.828, Test accuracy: 63.50
Round  52, Train loss: 1.746, Test loss: 1.827, Test accuracy: 63.66
Round  53, Train loss: 1.869, Test loss: 1.827, Test accuracy: 63.57
Round  54, Train loss: 1.798, Test loss: 1.821, Test accuracy: 64.39
Round  55, Train loss: 1.837, Test loss: 1.815, Test accuracy: 65.10
Round  56, Train loss: 1.754, Test loss: 1.815, Test accuracy: 65.07
Round  57, Train loss: 1.815, Test loss: 1.814, Test accuracy: 65.12
Round  58, Train loss: 1.695, Test loss: 1.811, Test accuracy: 65.27
Round  59, Train loss: 1.843, Test loss: 1.810, Test accuracy: 65.36
Round  60, Train loss: 1.690, Test loss: 1.809, Test accuracy: 65.40
Round  61, Train loss: 1.850, Test loss: 1.808, Test accuracy: 65.49
Round  62, Train loss: 1.810, Test loss: 1.809, Test accuracy: 65.45
Round  63, Train loss: 1.804, Test loss: 1.809, Test accuracy: 65.37
Round  64, Train loss: 1.805, Test loss: 1.809, Test accuracy: 65.43
Round  65, Train loss: 1.870, Test loss: 1.808, Test accuracy: 65.52
Round  66, Train loss: 1.818, Test loss: 1.807, Test accuracy: 65.62
Round  67, Train loss: 1.792, Test loss: 1.805, Test accuracy: 65.76
Round  68, Train loss: 1.839, Test loss: 1.805, Test accuracy: 65.70
Round  69, Train loss: 1.745, Test loss: 1.804, Test accuracy: 65.86
Round  70, Train loss: 1.714, Test loss: 1.804, Test accuracy: 65.89
Round  71, Train loss: 1.772, Test loss: 1.803, Test accuracy: 65.94
Round  72, Train loss: 1.870, Test loss: 1.803, Test accuracy: 65.93
Round  73, Train loss: 1.806, Test loss: 1.802, Test accuracy: 66.04
Round  74, Train loss: 1.689, Test loss: 1.803, Test accuracy: 65.93
Round  75, Train loss: 1.781, Test loss: 1.801, Test accuracy: 65.96
Round  76, Train loss: 1.715, Test loss: 1.801, Test accuracy: 66.00
Round  77, Train loss: 1.742, Test loss: 1.801, Test accuracy: 66.06
Round  78, Train loss: 1.768, Test loss: 1.801, Test accuracy: 66.05
Round  79, Train loss: 1.686, Test loss: 1.800, Test accuracy: 66.09
Round  80, Train loss: 1.805, Test loss: 1.800, Test accuracy: 66.19
Round  81, Train loss: 1.770, Test loss: 1.799, Test accuracy: 66.20
Round  82, Train loss: 1.709, Test loss: 1.799, Test accuracy: 66.24
Round  83, Train loss: 1.738, Test loss: 1.798, Test accuracy: 66.31
Round  84, Train loss: 1.832, Test loss: 1.799, Test accuracy: 66.21
Round  85, Train loss: 1.773, Test loss: 1.799, Test accuracy: 66.28
Round  86, Train loss: 1.716, Test loss: 1.798, Test accuracy: 66.33
Round  87, Train loss: 1.708, Test loss: 1.798, Test accuracy: 66.37
Round  88, Train loss: 1.869, Test loss: 1.798, Test accuracy: 66.28
Round  89, Train loss: 1.683, Test loss: 1.798, Test accuracy: 66.29
Round  90, Train loss: 1.735, Test loss: 1.798, Test accuracy: 66.24
Round  91, Train loss: 1.833, Test loss: 1.798, Test accuracy: 66.32
Round  92, Train loss: 1.710, Test loss: 1.798, Test accuracy: 66.32
Round  93, Train loss: 1.894, Test loss: 1.798, Test accuracy: 66.34
Round  94, Train loss: 1.834, Test loss: 1.797, Test accuracy: 66.32
Round  95, Train loss: 1.773, Test loss: 1.797, Test accuracy: 66.35
Round  96, Train loss: 1.809, Test loss: 1.796, Test accuracy: 66.49
Round  97, Train loss: 1.642, Test loss: 1.797, Test accuracy: 66.40
Round  98, Train loss: 1.768, Test loss: 1.796, Test accuracy: 66.50/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  99, Train loss: 1.706, Test loss: 1.796, Test accuracy: 66.47
Final Round, Train loss: 1.763, Test loss: 1.787, Test accuracy: 67.39
Average accuracy final 10 rounds: 66.375 

935.368524312973
[0.8548486232757568, 1.7096972465515137, 2.4466614723205566, 3.1836256980895996, 3.9106502532958984, 4.637674808502197, 5.34378457069397, 6.049894332885742, 6.707251310348511, 7.364608287811279, 8.064305305480957, 8.764002323150635, 9.439337491989136, 10.114672660827637, 10.754497528076172, 11.394322395324707, 12.08683729171753, 12.779352188110352, 13.450170755386353, 14.120989322662354, 14.79842495918274, 15.475860595703125, 16.139369010925293, 16.80287742614746, 17.490254402160645, 18.177631378173828, 18.885300159454346, 19.592968940734863, 20.26787543296814, 20.942781925201416, 21.643996000289917, 22.345210075378418, 23.00729537010193, 23.66938066482544, 24.319501399993896, 24.969622135162354, 25.686416625976562, 26.40321111679077, 27.058441400527954, 27.713671684265137, 28.373915672302246, 29.034159660339355, 29.76374888420105, 30.493338108062744, 31.222225189208984, 31.951112270355225, 32.69195890426636, 33.43280553817749, 34.19123148918152, 34.94965744018555, 35.673534870147705, 36.39741230010986, 37.131468772888184, 37.865525245666504, 38.5998215675354, 39.3341178894043, 40.079669713974, 40.8252215385437, 41.580100774765015, 42.33498001098633, 43.068169593811035, 43.80135917663574, 44.54219079017639, 45.28302240371704, 46.06386160850525, 46.84470081329346, 47.57115602493286, 48.297611236572266, 48.982492208480835, 49.667373180389404, 50.335036516189575, 51.002699851989746, 51.680309534072876, 52.357919216156006, 53.06053280830383, 53.76314640045166, 54.44070386886597, 55.11826133728027, 55.79249572753906, 56.46673011779785, 57.140661001205444, 57.81459188461304, 58.48985576629639, 59.165119647979736, 59.852471113204956, 60.539822578430176, 61.23560380935669, 61.9313850402832, 62.64284920692444, 63.354313373565674, 64.03155541419983, 64.70879745483398, 65.39143943786621, 66.07408142089844, 66.80428194999695, 67.53448247909546, 68.26915836334229, 69.00383424758911, 69.73268866539001, 70.46154308319092, 71.1660828590393, 71.8706226348877, 72.61248517036438, 73.35434770584106, 74.05647325515747, 74.75859880447388, 75.47504448890686, 76.19149017333984, 76.89999508857727, 77.6085000038147, 78.31299304962158, 79.01748609542847, 79.76063084602356, 80.50377559661865, 81.2374997138977, 81.97122383117676, 82.72705745697021, 83.48289108276367, 84.23603105545044, 84.9891710281372, 85.68582463264465, 86.3824782371521, 87.12242722511292, 87.86237621307373, 88.57109546661377, 89.27981472015381, 90.01279997825623, 90.74578523635864, 91.47667741775513, 92.20756959915161, 92.92015314102173, 93.63273668289185, 94.35207343101501, 95.07141017913818, 95.76362419128418, 96.45583820343018, 97.19997358322144, 97.9441089630127, 98.6718590259552, 99.3996090888977, 100.13218069076538, 100.86475229263306, 101.59607315063477, 102.32739400863647, 103.03897023200989, 103.7505464553833, 104.46440315246582, 105.17825984954834, 105.86166524887085, 106.54507064819336, 107.26493048667908, 107.9847903251648, 108.6927478313446, 109.40070533752441, 110.16882038116455, 110.93693542480469, 111.6547179222107, 112.3725004196167, 113.09277367591858, 113.81304693222046, 114.53506255149841, 115.25707817077637, 115.96740746498108, 116.67773675918579, 117.40297293663025, 118.1282091140747, 118.86345934867859, 119.59870958328247, 120.31749653816223, 121.03628349304199, 121.78546190261841, 122.53464031219482, 123.24303126335144, 123.95142221450806, 124.72082567214966, 125.49022912979126, 126.24864673614502, 127.00706434249878, 127.78612184524536, 128.56517934799194, 129.3137423992157, 130.06230545043945, 130.80785965919495, 131.55341386795044, 132.3245620727539, 133.09571027755737, 133.85941100120544, 134.62311172485352, 135.39661622047424, 136.17012071609497, 136.93460845947266, 137.69909620285034, 138.43322086334229, 139.16734552383423, 139.9457221031189, 140.72409868240356, 141.48773884773254, 142.25137901306152, 143.005042552948, 143.75870609283447, 145.15250420570374, 146.546302318573]
[12.0, 12.0, 12.35, 12.35, 14.03, 14.03, 19.51, 19.51, 14.87, 14.87, 18.94, 18.94, 22.89, 22.89, 24.73, 24.73, 28.79, 28.79, 32.72, 32.72, 36.26, 36.26, 37.93, 37.93, 45.08, 45.08, 49.45, 49.45, 50.18, 50.18, 50.71, 50.71, 52.08, 52.08, 55.93, 55.93, 56.88, 56.88, 58.72, 58.72, 59.37, 59.37, 59.49, 59.49, 59.52, 59.52, 59.48, 59.48, 59.72, 59.72, 59.84, 59.84, 59.8, 59.8, 59.66, 59.66, 59.86, 59.86, 60.01, 60.01, 60.04, 60.04, 60.27, 60.27, 60.33, 60.33, 60.54, 60.54, 60.44, 60.44, 60.55, 60.55, 60.64, 60.64, 60.7, 60.7, 61.15, 61.15, 61.25, 61.25, 61.38, 61.38, 61.74, 61.74, 62.4, 62.4, 62.93, 62.93, 62.95, 62.95, 62.97, 62.97, 62.91, 62.91, 63.37, 63.37, 63.37, 63.37, 63.28, 63.28, 63.4, 63.4, 63.5, 63.5, 63.66, 63.66, 63.57, 63.57, 64.39, 64.39, 65.1, 65.1, 65.07, 65.07, 65.12, 65.12, 65.27, 65.27, 65.36, 65.36, 65.4, 65.4, 65.49, 65.49, 65.45, 65.45, 65.37, 65.37, 65.43, 65.43, 65.52, 65.52, 65.62, 65.62, 65.76, 65.76, 65.7, 65.7, 65.86, 65.86, 65.89, 65.89, 65.94, 65.94, 65.93, 65.93, 66.04, 66.04, 65.93, 65.93, 65.96, 65.96, 66.0, 66.0, 66.06, 66.06, 66.05, 66.05, 66.09, 66.09, 66.19, 66.19, 66.2, 66.2, 66.24, 66.24, 66.31, 66.31, 66.21, 66.21, 66.28, 66.28, 66.33, 66.33, 66.37, 66.37, 66.28, 66.28, 66.29, 66.29, 66.24, 66.24, 66.32, 66.32, 66.32, 66.32, 66.34, 66.34, 66.32, 66.32, 66.35, 66.35, 66.49, 66.49, 66.4, 66.4, 66.5, 66.5, 66.47, 66.47, 67.39, 67.39]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedper  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedper , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

fedper
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.291, Test loss: 2.299, Test accuracy: 13.01
Round   1, Train loss: 2.262, Test loss: 2.290, Test accuracy: 13.00
Round   2, Train loss: 2.206, Test loss: 2.272, Test accuracy: 16.26
Round   3, Train loss: 2.085, Test loss: 2.231, Test accuracy: 22.35
Round   4, Train loss: 1.962, Test loss: 2.190, Test accuracy: 28.43
Round   5, Train loss: 1.898, Test loss: 2.129, Test accuracy: 33.52
Round   6, Train loss: 1.798, Test loss: 2.086, Test accuracy: 37.67
Round   7, Train loss: 1.879, Test loss: 2.029, Test accuracy: 45.40
Round   8, Train loss: 1.881, Test loss: 1.985, Test accuracy: 49.95
Round   9, Train loss: 1.913, Test loss: 1.960, Test accuracy: 51.21
Round  10, Train loss: 1.729, Test loss: 1.932, Test accuracy: 53.89
Round  11, Train loss: 1.834, Test loss: 1.906, Test accuracy: 57.31
Round  12, Train loss: 1.601, Test loss: 1.858, Test accuracy: 61.63
Round  13, Train loss: 1.706, Test loss: 1.837, Test accuracy: 63.89
Round  14, Train loss: 1.690, Test loss: 1.820, Test accuracy: 65.42
Round  15, Train loss: 1.642, Test loss: 1.813, Test accuracy: 65.91
Round  16, Train loss: 1.767, Test loss: 1.804, Test accuracy: 66.64
Round  17, Train loss: 1.669, Test loss: 1.793, Test accuracy: 67.97
Round  18, Train loss: 1.635, Test loss: 1.786, Test accuracy: 68.46
Round  19, Train loss: 1.722, Test loss: 1.778, Test accuracy: 69.18
Round  20, Train loss: 1.752, Test loss: 1.767, Test accuracy: 70.40
Round  21, Train loss: 1.689, Test loss: 1.761, Test accuracy: 70.59
Round  22, Train loss: 1.825, Test loss: 1.743, Test accuracy: 72.51
Round  23, Train loss: 1.597, Test loss: 1.736, Test accuracy: 73.21
Round  24, Train loss: 1.787, Test loss: 1.733, Test accuracy: 73.44
Round  25, Train loss: 1.657, Test loss: 1.731, Test accuracy: 73.63
Round  26, Train loss: 1.670, Test loss: 1.722, Test accuracy: 74.59
Round  27, Train loss: 1.745, Test loss: 1.721, Test accuracy: 74.66
Round  28, Train loss: 1.688, Test loss: 1.717, Test accuracy: 74.92
Round  29, Train loss: 1.685, Test loss: 1.713, Test accuracy: 75.37
Round  30, Train loss: 1.677, Test loss: 1.713, Test accuracy: 75.29
Round  31, Train loss: 1.749, Test loss: 1.711, Test accuracy: 75.60
Round  32, Train loss: 1.682, Test loss: 1.710, Test accuracy: 75.62
Round  33, Train loss: 1.623, Test loss: 1.709, Test accuracy: 75.60
Round  34, Train loss: 1.716, Test loss: 1.708, Test accuracy: 75.72
Round  35, Train loss: 1.710, Test loss: 1.707, Test accuracy: 75.79
Round  36, Train loss: 1.683, Test loss: 1.705, Test accuracy: 75.95
Round  37, Train loss: 1.584, Test loss: 1.707, Test accuracy: 75.70
Round  38, Train loss: 1.676, Test loss: 1.704, Test accuracy: 76.06
Round  39, Train loss: 1.649, Test loss: 1.702, Test accuracy: 76.25
Round  40, Train loss: 1.737, Test loss: 1.701, Test accuracy: 76.32
Round  41, Train loss: 1.645, Test loss: 1.701, Test accuracy: 76.26
Round  42, Train loss: 1.708, Test loss: 1.702, Test accuracy: 76.18
Round  43, Train loss: 1.708, Test loss: 1.700, Test accuracy: 76.43
Round  44, Train loss: 1.677, Test loss: 1.700, Test accuracy: 76.34
Round  45, Train loss: 1.705, Test loss: 1.699, Test accuracy: 76.54
Round  46, Train loss: 1.673, Test loss: 1.699, Test accuracy: 76.49
Round  47, Train loss: 1.612, Test loss: 1.698, Test accuracy: 76.44
Round  48, Train loss: 1.737, Test loss: 1.697, Test accuracy: 76.67
Round  49, Train loss: 1.642, Test loss: 1.698, Test accuracy: 76.50
Round  50, Train loss: 1.643, Test loss: 1.697, Test accuracy: 76.72
Round  51, Train loss: 1.577, Test loss: 1.697, Test accuracy: 76.65
Round  52, Train loss: 1.644, Test loss: 1.696, Test accuracy: 76.77
Round  53, Train loss: 1.641, Test loss: 1.696, Test accuracy: 76.65
Round  54, Train loss: 1.768, Test loss: 1.696, Test accuracy: 76.67
Round  55, Train loss: 1.671, Test loss: 1.695, Test accuracy: 76.78
Round  56, Train loss: 1.639, Test loss: 1.694, Test accuracy: 76.85
Round  57, Train loss: 1.673, Test loss: 1.694, Test accuracy: 76.96
Round  58, Train loss: 1.606, Test loss: 1.695, Test accuracy: 76.88
Round  59, Train loss: 1.736, Test loss: 1.695, Test accuracy: 76.84
Round  60, Train loss: 1.608, Test loss: 1.695, Test accuracy: 76.85
Round  61, Train loss: 1.734, Test loss: 1.693, Test accuracy: 76.96
Round  62, Train loss: 1.733, Test loss: 1.693, Test accuracy: 76.94
Round  63, Train loss: 1.751, Test loss: 1.689, Test accuracy: 77.30
Round  64, Train loss: 1.572, Test loss: 1.689, Test accuracy: 77.42
Round  65, Train loss: 1.637, Test loss: 1.689, Test accuracy: 77.36
Round  66, Train loss: 1.670, Test loss: 1.689, Test accuracy: 77.47
Round  67, Train loss: 1.574, Test loss: 1.688, Test accuracy: 77.49
Round  68, Train loss: 1.669, Test loss: 1.677, Test accuracy: 78.56
Round  69, Train loss: 1.607, Test loss: 1.676, Test accuracy: 78.75
Round  70, Train loss: 1.675, Test loss: 1.673, Test accuracy: 78.96
Round  71, Train loss: 1.608, Test loss: 1.672, Test accuracy: 78.96
Round  72, Train loss: 1.699, Test loss: 1.673, Test accuracy: 78.95
Round  73, Train loss: 1.603, Test loss: 1.672, Test accuracy: 78.93
Round  74, Train loss: 1.571, Test loss: 1.671, Test accuracy: 79.05
Round  75, Train loss: 1.642, Test loss: 1.672, Test accuracy: 79.06
Round  76, Train loss: 1.669, Test loss: 1.670, Test accuracy: 79.22
Round  77, Train loss: 1.604, Test loss: 1.670, Test accuracy: 79.16
Round  78, Train loss: 1.569, Test loss: 1.671, Test accuracy: 79.12
Round  79, Train loss: 1.668, Test loss: 1.670, Test accuracy: 79.21
Round  80, Train loss: 1.670, Test loss: 1.669, Test accuracy: 79.36
Round  81, Train loss: 1.538, Test loss: 1.668, Test accuracy: 79.47
Round  82, Train loss: 1.667, Test loss: 1.668, Test accuracy: 79.43
Round  83, Train loss: 1.604, Test loss: 1.669, Test accuracy: 79.33
Round  84, Train loss: 1.601, Test loss: 1.669, Test accuracy: 79.34
Round  85, Train loss: 1.601, Test loss: 1.669, Test accuracy: 79.33
Round  86, Train loss: 1.702, Test loss: 1.668, Test accuracy: 79.37
Round  87, Train loss: 1.541, Test loss: 1.668, Test accuracy: 79.36
Round  88, Train loss: 1.537, Test loss: 1.668, Test accuracy: 79.35
Round  89, Train loss: 1.572, Test loss: 1.668, Test accuracy: 79.35
Round  90, Train loss: 1.601, Test loss: 1.668, Test accuracy: 79.25
Round  91, Train loss: 1.667, Test loss: 1.668, Test accuracy: 79.29
Round  92, Train loss: 1.632, Test loss: 1.668, Test accuracy: 79.35
Round  93, Train loss: 1.669, Test loss: 1.667, Test accuracy: 79.46
Round  94, Train loss: 1.633, Test loss: 1.667, Test accuracy: 79.50
Round  95, Train loss: 1.636, Test loss: 1.667, Test accuracy: 79.53
Round  96, Train loss: 1.601, Test loss: 1.667, Test accuracy: 79.44
Round  97, Train loss: 1.632, Test loss: 1.667, Test accuracy: 79.51
Round  98, Train loss: 1.634, Test loss: 1.667, Test accuracy: 79.52/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  99, Train loss: 1.634, Test loss: 1.666, Test accuracy: 79.57
Final Round, Train loss: 1.629, Test loss: 1.665, Test accuracy: 79.67
Average accuracy final 10 rounds: 79.44200000000001 

1004.5992114543915
[0.8888607025146484, 1.7777214050292969, 2.597498655319214, 3.417275905609131, 4.2455432415008545, 5.073810577392578, 5.897896766662598, 6.721982955932617, 7.549953937530518, 8.377924919128418, 9.189838171005249, 10.00175142288208, 10.81869912147522, 11.63564682006836, 12.466655969619751, 13.297665119171143, 14.111524820327759, 14.925384521484375, 15.743149280548096, 16.560914039611816, 17.389258861541748, 18.21760368347168, 19.018510580062866, 19.819417476654053, 20.646482467651367, 21.47354745864868, 22.29846739768982, 23.123387336730957, 23.924269199371338, 24.72515106201172, 25.534327268600464, 26.34350347518921, 27.166435718536377, 27.989367961883545, 28.801743507385254, 29.614119052886963, 30.446099996566772, 31.278080940246582, 32.086427211761475, 32.89477348327637, 33.71585822105408, 34.53694295883179, 35.358949184417725, 36.18095541000366, 36.995895862579346, 37.81083631515503, 38.62705755233765, 39.443278789520264, 40.25864315032959, 41.074007511138916, 41.88444519042969, 42.69488286972046, 43.5287971496582, 44.36271142959595, 45.17475366592407, 45.9867959022522, 46.792675256729126, 47.598554611206055, 48.42739725112915, 49.256239891052246, 50.06214380264282, 50.8680477142334, 51.6884708404541, 52.508893966674805, 53.33136510848999, 54.153836250305176, 54.85011124610901, 55.54638624191284, 56.25201749801636, 56.95764875411987, 57.676875829696655, 58.39610290527344, 59.08697175979614, 59.77784061431885, 60.482927083969116, 61.188013553619385, 61.87378764152527, 62.55956172943115, 63.27973961830139, 63.99991750717163, 64.69579553604126, 65.39167356491089, 66.24302959442139, 67.09438562393188, 67.94638562202454, 68.79838562011719, 69.71544408798218, 70.63250255584717, 71.43649649620056, 72.24049043655396, 73.06234288215637, 73.88419532775879, 74.66547203063965, 75.44674873352051, 76.26166462898254, 77.07658052444458, 77.8825695514679, 78.68855857849121, 79.48349714279175, 80.27843570709229, 81.0825183391571, 81.88660097122192, 82.68594098091125, 83.48528099060059, 84.26506423950195, 85.04484748840332, 85.76133108139038, 86.47781467437744, 87.26573491096497, 88.05365514755249, 88.85261869430542, 89.65158224105835, 90.4452531337738, 91.23892402648926, 92.01520133018494, 92.79147863388062, 93.5967059135437, 94.40193319320679, 95.202716588974, 96.00349998474121, 96.8674590587616, 97.73141813278198, 98.5639820098877, 99.39654588699341, 100.1909716129303, 100.98539733886719, 102.01048183441162, 103.03556632995605, 104.11436724662781, 105.19316816329956, 106.07425498962402, 106.95534181594849, 107.7341206073761, 108.51289939880371, 109.60796117782593, 110.70302295684814, 111.90161657333374, 113.10021018981934, 114.30638766288757, 115.51256513595581, 116.5477077960968, 117.5828504562378, 118.76887512207031, 119.95489978790283, 120.7968373298645, 121.63877487182617, 122.73354625701904, 123.82831764221191, 124.72314548492432, 125.61797332763672, 126.74665069580078, 127.87532806396484, 128.965083360672, 130.05483865737915, 131.08207440376282, 132.10931015014648, 133.0547902584076, 134.0002703666687, 134.69861030578613, 135.39695024490356, 136.08818244934082, 136.77941465377808, 137.48311710357666, 138.18681955337524, 138.87693166732788, 139.56704378128052, 140.26732325553894, 140.96760272979736, 141.6573464870453, 142.3470902442932, 143.0478973388672, 143.74870443344116, 144.44384145736694, 145.13897848129272, 145.83962392807007, 146.5402693748474, 147.238055229187, 147.9358410835266, 148.62581157684326, 149.3157820701599, 150.0163357257843, 150.7168893814087, 151.42068028450012, 152.12447118759155, 152.82803750038147, 153.5316038131714, 154.22549533843994, 154.9193868637085, 155.61326622962952, 156.30714559555054, 157.03219652175903, 157.75724744796753, 158.47559142112732, 159.1939353942871, 159.89900064468384, 160.60406589508057, 161.2947199344635, 161.98537397384644, 162.68802189826965, 163.39066982269287, 164.68510460853577, 165.97953939437866]
[13.01, 13.01, 13.0, 13.0, 16.26, 16.26, 22.35, 22.35, 28.43, 28.43, 33.52, 33.52, 37.67, 37.67, 45.4, 45.4, 49.95, 49.95, 51.21, 51.21, 53.89, 53.89, 57.31, 57.31, 61.63, 61.63, 63.89, 63.89, 65.42, 65.42, 65.91, 65.91, 66.64, 66.64, 67.97, 67.97, 68.46, 68.46, 69.18, 69.18, 70.4, 70.4, 70.59, 70.59, 72.51, 72.51, 73.21, 73.21, 73.44, 73.44, 73.63, 73.63, 74.59, 74.59, 74.66, 74.66, 74.92, 74.92, 75.37, 75.37, 75.29, 75.29, 75.6, 75.6, 75.62, 75.62, 75.6, 75.6, 75.72, 75.72, 75.79, 75.79, 75.95, 75.95, 75.7, 75.7, 76.06, 76.06, 76.25, 76.25, 76.32, 76.32, 76.26, 76.26, 76.18, 76.18, 76.43, 76.43, 76.34, 76.34, 76.54, 76.54, 76.49, 76.49, 76.44, 76.44, 76.67, 76.67, 76.5, 76.5, 76.72, 76.72, 76.65, 76.65, 76.77, 76.77, 76.65, 76.65, 76.67, 76.67, 76.78, 76.78, 76.85, 76.85, 76.96, 76.96, 76.88, 76.88, 76.84, 76.84, 76.85, 76.85, 76.96, 76.96, 76.94, 76.94, 77.3, 77.3, 77.42, 77.42, 77.36, 77.36, 77.47, 77.47, 77.49, 77.49, 78.56, 78.56, 78.75, 78.75, 78.96, 78.96, 78.96, 78.96, 78.95, 78.95, 78.93, 78.93, 79.05, 79.05, 79.06, 79.06, 79.22, 79.22, 79.16, 79.16, 79.12, 79.12, 79.21, 79.21, 79.36, 79.36, 79.47, 79.47, 79.43, 79.43, 79.33, 79.33, 79.34, 79.34, 79.33, 79.33, 79.37, 79.37, 79.36, 79.36, 79.35, 79.35, 79.35, 79.35, 79.25, 79.25, 79.29, 79.29, 79.35, 79.35, 79.46, 79.46, 79.5, 79.5, 79.53, 79.53, 79.44, 79.44, 79.51, 79.51, 79.52, 79.52, 79.57, 79.57, 79.67, 79.67]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  lg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: lg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

lg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 17098 (global); Percentage 3.11 (17098/550346 
)
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.285, Test loss: 2.296, Test accuracy: 15.17
Round   1, Train loss: 2.216, Test loss: 2.267, Test accuracy: 27.20
Round   2, Train loss: 2.033, Test loss: 2.184, Test accuracy: 31.91
Round   3, Train loss: 1.906, Test loss: 2.098, Test accuracy: 40.57
Round   4, Train loss: 1.714, Test loss: 2.005, Test accuracy: 52.80
Round   5, Train loss: 1.771, Test loss: 1.942, Test accuracy: 57.70
Round   6, Train loss: 1.718, Test loss: 1.869, Test accuracy: 60.94
Round   7, Train loss: 1.616, Test loss: 1.766, Test accuracy: 72.61
Round   8, Train loss: 1.571, Test loss: 1.754, Test accuracy: 72.85
Round   9, Train loss: 1.580, Test loss: 1.744, Test accuracy: 73.36
Round  10, Train loss: 1.506, Test loss: 1.722, Test accuracy: 75.10
Round  11, Train loss: 1.704, Test loss: 1.692, Test accuracy: 78.64
Round  12, Train loss: 1.511, Test loss: 1.680, Test accuracy: 79.66
Round  13, Train loss: 1.584, Test loss: 1.676, Test accuracy: 79.66
Round  14, Train loss: 1.556, Test loss: 1.643, Test accuracy: 83.33
Round  15, Train loss: 1.569, Test loss: 1.630, Test accuracy: 84.35
Round  16, Train loss: 1.515, Test loss: 1.626, Test accuracy: 84.67
Round  17, Train loss: 1.512, Test loss: 1.623, Test accuracy: 84.80
Round  18, Train loss: 1.509, Test loss: 1.622, Test accuracy: 84.84
Round  19, Train loss: 1.540, Test loss: 1.619, Test accuracy: 84.91
Round  20, Train loss: 1.538, Test loss: 1.618, Test accuracy: 84.87
Round  21, Train loss: 1.526, Test loss: 1.612, Test accuracy: 85.55
Round  22, Train loss: 1.506, Test loss: 1.611, Test accuracy: 85.66
Round  23, Train loss: 1.593, Test loss: 1.600, Test accuracy: 86.98
Round  24, Train loss: 1.514, Test loss: 1.595, Test accuracy: 87.20
Round  25, Train loss: 1.573, Test loss: 1.594, Test accuracy: 87.31
Round  26, Train loss: 1.541, Test loss: 1.594, Test accuracy: 87.30
Round  27, Train loss: 1.472, Test loss: 1.594, Test accuracy: 87.35
Round  28, Train loss: 1.476, Test loss: 1.593, Test accuracy: 87.43
Round  29, Train loss: 1.536, Test loss: 1.593, Test accuracy: 87.41
Round  30, Train loss: 1.504, Test loss: 1.592, Test accuracy: 87.48
Round  31, Train loss: 1.503, Test loss: 1.591, Test accuracy: 87.49
Round  32, Train loss: 1.532, Test loss: 1.588, Test accuracy: 87.85
Round  33, Train loss: 1.474, Test loss: 1.581, Test accuracy: 88.61
Round  34, Train loss: 1.502, Test loss: 1.580, Test accuracy: 88.68
Round  35, Train loss: 1.472, Test loss: 1.580, Test accuracy: 88.70
Round  36, Train loss: 1.469, Test loss: 1.579, Test accuracy: 88.74
Round  37, Train loss: 1.500, Test loss: 1.579, Test accuracy: 88.84
Round  38, Train loss: 1.501, Test loss: 1.579, Test accuracy: 88.88
Round  39, Train loss: 1.500, Test loss: 1.578, Test accuracy: 88.89
Round  40, Train loss: 1.499, Test loss: 1.578, Test accuracy: 88.87
Round  41, Train loss: 1.500, Test loss: 1.578, Test accuracy: 88.89
Round  42, Train loss: 1.498, Test loss: 1.578, Test accuracy: 88.78
Round  43, Train loss: 1.504, Test loss: 1.578, Test accuracy: 88.84
Round  44, Train loss: 1.478, Test loss: 1.573, Test accuracy: 89.35
Round  45, Train loss: 1.534, Test loss: 1.573, Test accuracy: 89.26
Round  46, Train loss: 1.533, Test loss: 1.573, Test accuracy: 89.20
Round  47, Train loss: 1.536, Test loss: 1.573, Test accuracy: 89.29
Round  48, Train loss: 1.532, Test loss: 1.573, Test accuracy: 89.25
Round  49, Train loss: 1.500, Test loss: 1.572, Test accuracy: 89.24
Round  50, Train loss: 1.502, Test loss: 1.572, Test accuracy: 89.25
Round  51, Train loss: 1.500, Test loss: 1.572, Test accuracy: 89.29
Round  52, Train loss: 1.469, Test loss: 1.572, Test accuracy: 89.31
Round  53, Train loss: 1.500, Test loss: 1.572, Test accuracy: 89.32
Round  54, Train loss: 1.532, Test loss: 1.572, Test accuracy: 89.32
Round  55, Train loss: 1.498, Test loss: 1.571, Test accuracy: 89.32
Round  56, Train loss: 1.530, Test loss: 1.571, Test accuracy: 89.33
Round  57, Train loss: 1.469, Test loss: 1.571, Test accuracy: 89.33
Round  58, Train loss: 1.497, Test loss: 1.571, Test accuracy: 89.34
Round  59, Train loss: 1.470, Test loss: 1.571, Test accuracy: 89.32
Round  60, Train loss: 1.530, Test loss: 1.571, Test accuracy: 89.32
Round  61, Train loss: 1.498, Test loss: 1.571, Test accuracy: 89.32
Round  62, Train loss: 1.498, Test loss: 1.571, Test accuracy: 89.30
Round  63, Train loss: 1.500, Test loss: 1.571, Test accuracy: 89.30
Round  64, Train loss: 1.468, Test loss: 1.571, Test accuracy: 89.29
Round  65, Train loss: 1.530, Test loss: 1.571, Test accuracy: 89.31
Round  66, Train loss: 1.467, Test loss: 1.571, Test accuracy: 89.32
Round  67, Train loss: 1.500, Test loss: 1.570, Test accuracy: 89.37
Round  68, Train loss: 1.500, Test loss: 1.570, Test accuracy: 89.36
Round  69, Train loss: 1.468, Test loss: 1.570, Test accuracy: 89.40
Round  70, Train loss: 1.468, Test loss: 1.570, Test accuracy: 89.39
Round  71, Train loss: 1.467, Test loss: 1.570, Test accuracy: 89.39
Round  72, Train loss: 1.498, Test loss: 1.570, Test accuracy: 89.44
Round  73, Train loss: 1.504, Test loss: 1.564, Test accuracy: 90.08
Round  74, Train loss: 1.499, Test loss: 1.564, Test accuracy: 90.07
Round  75, Train loss: 1.498, Test loss: 1.564, Test accuracy: 90.10
Round  76, Train loss: 1.530, Test loss: 1.564, Test accuracy: 90.11
Round  77, Train loss: 1.500, Test loss: 1.564, Test accuracy: 90.09
Round  78, Train loss: 1.466, Test loss: 1.563, Test accuracy: 90.22
Round  79, Train loss: 1.466, Test loss: 1.563, Test accuracy: 90.14
Round  80, Train loss: 1.498, Test loss: 1.563, Test accuracy: 90.13
Round  81, Train loss: 1.466, Test loss: 1.563, Test accuracy: 90.19
Round  82, Train loss: 1.497, Test loss: 1.563, Test accuracy: 90.23
Round  83, Train loss: 1.466, Test loss: 1.563, Test accuracy: 90.24
Round  84, Train loss: 1.499, Test loss: 1.563, Test accuracy: 90.18
Round  85, Train loss: 1.530, Test loss: 1.563, Test accuracy: 90.20
Round  86, Train loss: 1.498, Test loss: 1.563, Test accuracy: 90.16
Round  87, Train loss: 1.500, Test loss: 1.563, Test accuracy: 90.13
Round  88, Train loss: 1.466, Test loss: 1.563, Test accuracy: 90.13
Round  89, Train loss: 1.498, Test loss: 1.563, Test accuracy: 90.16
Round  90, Train loss: 1.499, Test loss: 1.563, Test accuracy: 90.15
Round  91, Train loss: 1.499, Test loss: 1.563, Test accuracy: 90.11
Round  92, Train loss: 1.496, Test loss: 1.563, Test accuracy: 90.16
Round  93, Train loss: 1.497, Test loss: 1.563, Test accuracy: 90.16
Round  94, Train loss: 1.466, Test loss: 1.563, Test accuracy: 90.15
Round  95, Train loss: 1.497, Test loss: 1.563, Test accuracy: 90.15
Round  96, Train loss: 1.466, Test loss: 1.563, Test accuracy: 90.15
Round  97, Train loss: 1.499, Test loss: 1.563, Test accuracy: 90.15
Round  98, Train loss: 1.467, Test loss: 1.562, Test accuracy: 90.18
Round  99, Train loss: 1.464, Test loss: 1.562, Test accuracy: 90.17/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Final Round, Train loss: 1.485, Test loss: 1.562, Test accuracy: 90.18
Average accuracy final 10 rounds: 90.15299999999999 

1002.2711832523346
[0.9557464122772217, 1.9114928245544434, 2.781271457672119, 3.651050090789795, 4.520360469818115, 5.3896708488464355, 6.243619918823242, 7.097568988800049, 7.964713096618652, 8.831857204437256, 9.707237720489502, 10.582618236541748, 11.467517375946045, 12.352416515350342, 13.15262484550476, 13.95283317565918, 14.817914247512817, 15.682995319366455, 16.55715322494507, 17.43131113052368, 18.3104407787323, 19.189570426940918, 20.069623708724976, 20.949676990509033, 21.818143606185913, 22.686610221862793, 23.55421257019043, 24.421814918518066, 25.30212640762329, 26.182437896728516, 27.059967517852783, 27.93749713897705, 28.794957399368286, 29.65241765975952, 30.51599645614624, 31.37957525253296, 32.250452756881714, 33.12133026123047, 33.998472452163696, 34.875614643096924, 35.73942279815674, 36.60323095321655, 37.47323656082153, 38.343242168426514, 39.222187757492065, 40.10113334655762, 40.94852137565613, 41.79590940475464, 42.630282402038574, 43.46465539932251, 44.3240647315979, 45.18347406387329, 46.04884076118469, 46.914207458496094, 47.794456005096436, 48.67470455169678, 49.55636763572693, 50.43803071975708, 51.30441474914551, 52.170798778533936, 53.040969371795654, 53.91113996505737, 54.78349852561951, 55.65585708618164, 56.5377094745636, 57.41956186294556, 58.27761769294739, 59.13567352294922, 59.894094944000244, 60.65251636505127, 61.52157711982727, 62.39063787460327, 63.26618313789368, 64.14172840118408, 65.02246379852295, 65.90319919586182, 66.77691888809204, 67.65063858032227, 68.5275330543518, 69.40442752838135, 70.2740113735199, 71.14359521865845, 72.00719213485718, 72.87078905105591, 73.6071286201477, 74.3434681892395, 75.17528867721558, 76.00710916519165, 76.85485482215881, 77.70260047912598, 78.46299195289612, 79.22338342666626, 79.97619390487671, 80.72900438308716, 81.51725196838379, 82.30549955368042, 83.06668210029602, 83.82786464691162, 84.59210133552551, 85.3563380241394, 86.10928988456726, 86.86224174499512, 87.62357115745544, 88.38490056991577, 89.13830375671387, 89.89170694351196, 90.65289378166199, 91.41408061981201, 92.16958284378052, 92.92508506774902, 93.6740038394928, 94.42292261123657, 95.17101454734802, 95.91910648345947, 96.6724214553833, 97.42573642730713, 98.1879665851593, 98.95019674301147, 99.73068356513977, 100.51117038726807, 101.2639479637146, 102.01672554016113, 102.73297905921936, 103.44923257827759, 104.19755268096924, 104.94587278366089, 105.70401072502136, 106.46214866638184, 107.23340964317322, 108.0046706199646, 108.77044010162354, 109.53620958328247, 110.29619073867798, 111.05617189407349, 111.82452869415283, 112.59288549423218, 113.37918305397034, 114.1654806137085, 114.9394760131836, 115.71347141265869, 116.49039673805237, 117.26732206344604, 118.09038162231445, 118.91344118118286, 119.97171831130981, 121.02999544143677, 122.16941928863525, 123.30884313583374, 124.05525064468384, 124.80165815353394, 125.78555107116699, 126.76944398880005, 127.85155177116394, 128.93365955352783, 130.06692624092102, 131.2001929283142, 132.23362255096436, 133.2670521736145, 134.41910076141357, 135.57114934921265, 136.28608345985413, 137.0010175704956, 137.72509241104126, 138.4491672515869, 139.18325448036194, 139.91734170913696, 140.63986682891846, 141.36239194869995, 142.09228038787842, 142.82216882705688, 143.54972386360168, 144.27727890014648, 145.00455975532532, 145.73184061050415, 146.46440076828003, 147.1969609260559, 147.93335437774658, 148.66974782943726, 149.39237451553345, 150.11500120162964, 150.83622670173645, 151.55745220184326, 152.2818684577942, 153.00628471374512, 153.74652862548828, 154.48677253723145, 155.21291279792786, 155.93905305862427, 156.64977097511292, 157.36048889160156, 158.0672163963318, 158.773943901062, 159.511461019516, 160.24897813796997, 160.9767906665802, 161.70460319519043, 162.429039478302, 163.15347576141357, 163.86177515983582, 164.57007455825806, 165.97465229034424, 167.37923002243042]
[15.17, 15.17, 27.2, 27.2, 31.91, 31.91, 40.57, 40.57, 52.8, 52.8, 57.7, 57.7, 60.94, 60.94, 72.61, 72.61, 72.85, 72.85, 73.36, 73.36, 75.1, 75.1, 78.64, 78.64, 79.66, 79.66, 79.66, 79.66, 83.33, 83.33, 84.35, 84.35, 84.67, 84.67, 84.8, 84.8, 84.84, 84.84, 84.91, 84.91, 84.87, 84.87, 85.55, 85.55, 85.66, 85.66, 86.98, 86.98, 87.2, 87.2, 87.31, 87.31, 87.3, 87.3, 87.35, 87.35, 87.43, 87.43, 87.41, 87.41, 87.48, 87.48, 87.49, 87.49, 87.85, 87.85, 88.61, 88.61, 88.68, 88.68, 88.7, 88.7, 88.74, 88.74, 88.84, 88.84, 88.88, 88.88, 88.89, 88.89, 88.87, 88.87, 88.89, 88.89, 88.78, 88.78, 88.84, 88.84, 89.35, 89.35, 89.26, 89.26, 89.2, 89.2, 89.29, 89.29, 89.25, 89.25, 89.24, 89.24, 89.25, 89.25, 89.29, 89.29, 89.31, 89.31, 89.32, 89.32, 89.32, 89.32, 89.32, 89.32, 89.33, 89.33, 89.33, 89.33, 89.34, 89.34, 89.32, 89.32, 89.32, 89.32, 89.32, 89.32, 89.3, 89.3, 89.3, 89.3, 89.29, 89.29, 89.31, 89.31, 89.32, 89.32, 89.37, 89.37, 89.36, 89.36, 89.4, 89.4, 89.39, 89.39, 89.39, 89.39, 89.44, 89.44, 90.08, 90.08, 90.07, 90.07, 90.1, 90.1, 90.11, 90.11, 90.09, 90.09, 90.22, 90.22, 90.14, 90.14, 90.13, 90.13, 90.19, 90.19, 90.23, 90.23, 90.24, 90.24, 90.18, 90.18, 90.2, 90.2, 90.16, 90.16, 90.13, 90.13, 90.13, 90.13, 90.16, 90.16, 90.15, 90.15, 90.11, 90.11, 90.16, 90.16, 90.16, 90.16, 90.15, 90.15, 90.15, 90.15, 90.15, 90.15, 90.15, 90.15, 90.18, 90.18, 90.17, 90.17, 90.18, 90.18]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_apfl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
Round   0, Train loss: 1.593, Test loss: 2.276, Test accuracy: 26.18
Round   1, Train loss: 1.464, Test loss: 2.217, Test accuracy: 36.84
Round   2, Train loss: 1.417, Test loss: 2.159, Test accuracy: 41.35
Round   3, Train loss: 1.358, Test loss: 2.104, Test accuracy: 45.83
Round   4, Train loss: 1.301, Test loss: 2.061, Test accuracy: 49.19
Round   5, Train loss: 1.370, Test loss: 1.985, Test accuracy: 59.19
Round   6, Train loss: 1.264, Test loss: 1.955, Test accuracy: 62.15
Round   7, Train loss: 1.384, Test loss: 1.913, Test accuracy: 65.91
Round   8, Train loss: 1.268, Test loss: 1.893, Test accuracy: 66.56
Round   9, Train loss: 1.310, Test loss: 1.886, Test accuracy: 66.42
Round  10, Train loss: 1.307, Test loss: 1.881, Test accuracy: 65.69
Round  11, Train loss: 1.286, Test loss: 1.839, Test accuracy: 69.59
Round  12, Train loss: 1.222, Test loss: 1.832, Test accuracy: 69.47
Round  13, Train loss: 1.314, Test loss: 1.814, Test accuracy: 70.37
Round  14, Train loss: 1.226, Test loss: 1.807, Test accuracy: 70.28
Round  15, Train loss: 1.213, Test loss: 1.807, Test accuracy: 69.44
Round  16, Train loss: 1.214, Test loss: 1.800, Test accuracy: 69.71
Round  17, Train loss: 1.285, Test loss: 1.798, Test accuracy: 69.51
Round  18, Train loss: 1.282, Test loss: 1.797, Test accuracy: 69.47
Round  19, Train loss: 1.273, Test loss: 1.790, Test accuracy: 70.28
Round  20, Train loss: 1.259, Test loss: 1.787, Test accuracy: 70.40
Round  21, Train loss: 1.192, Test loss: 1.781, Test accuracy: 71.07
Round  22, Train loss: 1.236, Test loss: 1.773, Test accuracy: 71.99
Round  23, Train loss: 1.235, Test loss: 1.775, Test accuracy: 71.61
Round  24, Train loss: 1.184, Test loss: 1.774, Test accuracy: 71.74
Round  25, Train loss: 1.266, Test loss: 1.765, Test accuracy: 72.41
Round  26, Train loss: 1.184, Test loss: 1.767, Test accuracy: 71.87
Round  27, Train loss: 1.280, Test loss: 1.767, Test accuracy: 71.83
Round  28, Train loss: 1.235, Test loss: 1.765, Test accuracy: 72.00
Round  29, Train loss: 1.163, Test loss: 1.763, Test accuracy: 72.27
Round  30, Train loss: 1.202, Test loss: 1.764, Test accuracy: 72.40
Round  31, Train loss: 1.255, Test loss: 1.761, Test accuracy: 72.55
Round  32, Train loss: 1.183, Test loss: 1.760, Test accuracy: 72.66
Round  33, Train loss: 1.156, Test loss: 1.758, Test accuracy: 72.81
Round  34, Train loss: 1.207, Test loss: 1.756, Test accuracy: 72.85
Round  35, Train loss: 1.109, Test loss: 1.757, Test accuracy: 72.65
Round  36, Train loss: 1.159, Test loss: 1.762, Test accuracy: 72.06
Round  37, Train loss: 1.133, Test loss: 1.757, Test accuracy: 72.39
Round  38, Train loss: 1.206, Test loss: 1.762, Test accuracy: 72.01
Round  39, Train loss: 1.204, Test loss: 1.762, Test accuracy: 72.00
Round  40, Train loss: 1.205, Test loss: 1.758, Test accuracy: 72.58
Round  41, Train loss: 1.136, Test loss: 1.759, Test accuracy: 72.21
Round  42, Train loss: 1.179, Test loss: 1.755, Test accuracy: 72.51
Round  43, Train loss: 1.181, Test loss: 1.756, Test accuracy: 72.25
Round  44, Train loss: 1.157, Test loss: 1.762, Test accuracy: 71.60
Round  45, Train loss: 1.181, Test loss: 1.760, Test accuracy: 71.58
Round  46, Train loss: 1.230, Test loss: 1.766, Test accuracy: 71.03
Round  47, Train loss: 1.203, Test loss: 1.767, Test accuracy: 70.78
Round  48, Train loss: 1.228, Test loss: 1.765, Test accuracy: 71.18
Round  49, Train loss: 1.255, Test loss: 1.763, Test accuracy: 71.08
Round  50, Train loss: 1.155, Test loss: 1.765, Test accuracy: 71.03
Round  51, Train loss: 1.180, Test loss: 1.769, Test accuracy: 70.33
Round  52, Train loss: 1.207, Test loss: 1.767, Test accuracy: 70.45
Round  53, Train loss: 1.204, Test loss: 1.766, Test accuracy: 70.41
Round  54, Train loss: 1.107, Test loss: 1.770, Test accuracy: 70.02
Round  55, Train loss: 1.106, Test loss: 1.772, Test accuracy: 69.70
Round  56, Train loss: 1.206, Test loss: 1.779, Test accuracy: 68.96
Round  57, Train loss: 1.250, Test loss: 1.777, Test accuracy: 69.21
Round  58, Train loss: 1.253, Test loss: 1.774, Test accuracy: 69.63
Round  59, Train loss: 1.105, Test loss: 1.776, Test accuracy: 69.31
Round  60, Train loss: 1.204, Test loss: 1.778, Test accuracy: 69.21
Round  61, Train loss: 1.280, Test loss: 1.781, Test accuracy: 68.80
Round  62, Train loss: 1.230, Test loss: 1.779, Test accuracy: 68.97
Round  63, Train loss: 1.278, Test loss: 1.781, Test accuracy: 68.67
Round  64, Train loss: 1.133, Test loss: 1.783, Test accuracy: 68.56
Round  65, Train loss: 1.155, Test loss: 1.782, Test accuracy: 68.70
Round  66, Train loss: 1.205, Test loss: 1.782, Test accuracy: 68.79
Round  67, Train loss: 1.181, Test loss: 1.785, Test accuracy: 68.18
Round  68, Train loss: 1.131, Test loss: 1.784, Test accuracy: 68.45
Round  69, Train loss: 1.153, Test loss: 1.787, Test accuracy: 68.42
Round  70, Train loss: 1.226, Test loss: 1.792, Test accuracy: 67.69
Round  71, Train loss: 1.154, Test loss: 1.791, Test accuracy: 67.80
Round  72, Train loss: 1.182, Test loss: 1.797, Test accuracy: 67.14
Round  73, Train loss: 1.202, Test loss: 1.797, Test accuracy: 67.11
Round  74, Train loss: 1.127, Test loss: 1.798, Test accuracy: 67.10
Round  75, Train loss: 1.276, Test loss: 1.798, Test accuracy: 67.16
Round  76, Train loss: 1.228, Test loss: 1.800, Test accuracy: 66.86
Round  77, Train loss: 1.178, Test loss: 1.801, Test accuracy: 66.69
Round  78, Train loss: 1.229, Test loss: 1.800, Test accuracy: 66.85
Round  79, Train loss: 1.156, Test loss: 1.801, Test accuracy: 66.59
Round  80, Train loss: 1.130, Test loss: 1.800, Test accuracy: 66.79
Round  81, Train loss: 1.154, Test loss: 1.803, Test accuracy: 66.52
Round  82, Train loss: 1.205, Test loss: 1.805, Test accuracy: 66.24
Round  83, Train loss: 1.154, Test loss: 1.812, Test accuracy: 65.62
Round  84, Train loss: 1.254, Test loss: 1.813, Test accuracy: 65.32
Round  85, Train loss: 1.250, Test loss: 1.812, Test accuracy: 65.54
Round  86, Train loss: 1.180, Test loss: 1.813, Test accuracy: 65.34
Round  87, Train loss: 1.179, Test loss: 1.813, Test accuracy: 65.32
Round  88, Train loss: 1.154, Test loss: 1.815, Test accuracy: 64.97
Round  89, Train loss: 1.157, Test loss: 1.818, Test accuracy: 64.79
Round  90, Train loss: 1.104, Test loss: 1.816, Test accuracy: 64.90
Round  91, Train loss: 1.207, Test loss: 1.817, Test accuracy: 64.71
Round  92, Train loss: 1.177, Test loss: 1.815, Test accuracy: 64.72
Round  93, Train loss: 1.156, Test loss: 1.813, Test accuracy: 65.05
Round  94, Train loss: 1.130, Test loss: 1.814, Test accuracy: 64.96
Round  95, Train loss: 1.178, Test loss: 1.815, Test accuracy: 64.92
Round  96, Train loss: 1.156, Test loss: 1.816, Test accuracy: 64.85
Round  97, Train loss: 1.201, Test loss: 1.819, Test accuracy: 64.50
Round  98, Train loss: 1.189, Test loss: 1.811, Test accuracy: 65.35
Round  99, Train loss: 1.127, Test loss: 1.811, Test accuracy: 65.12
Final Round, Train loss: 1.183, Test loss: 1.816, Test accuracy: 64.63
Average accuracy final 10 rounds: 64.90799999999999
1194.7611496448517
[]
[26.18, 36.84, 41.35, 45.83, 49.19, 59.19, 62.15, 65.91, 66.56, 66.42, 65.69, 69.59, 69.47, 70.37, 70.28, 69.44, 69.71, 69.51, 69.47, 70.28, 70.4, 71.07, 71.99, 71.61, 71.74, 72.41, 71.87, 71.83, 72.0, 72.27, 72.4, 72.55, 72.66, 72.81, 72.85, 72.65, 72.06, 72.39, 72.01, 72.0, 72.58, 72.21, 72.51, 72.25, 71.6, 71.58, 71.03, 70.78, 71.18, 71.08, 71.03, 70.33, 70.45, 70.41, 70.02, 69.7, 68.96, 69.21, 69.63, 69.31, 69.21, 68.8, 68.97, 68.67, 68.56, 68.7, 68.79, 68.18, 68.45, 68.42, 67.69, 67.8, 67.14, 67.11, 67.1, 67.16, 66.86, 66.69, 66.85, 66.59, 66.79, 66.52, 66.24, 65.62, 65.32, 65.54, 65.34, 65.32, 64.97, 64.79, 64.9, 64.71, 64.72, 65.05, 64.96, 64.92, 64.85, 64.5, 65.35, 65.12, 64.63]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Fed_scaffold %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.283, Test loss: 2.284, Test accuracy: 18.78
Round   1, Train loss: 2.249, Test loss: 2.259, Test accuracy: 19.86
Round   2, Train loss: 2.235, Test loss: 2.260, Test accuracy: 17.22
Round   3, Train loss: 2.057, Test loss: 2.216, Test accuracy: 22.47
Round   4, Train loss: 2.199, Test loss: 2.236, Test accuracy: 14.94
Round   5, Train loss: 2.181, Test loss: 2.235, Test accuracy: 15.45
Round   6, Train loss: 2.081, Test loss: 2.167, Test accuracy: 30.36
Round   7, Train loss: 1.821, Test loss: 2.134, Test accuracy: 33.24
Round   8, Train loss: 1.673, Test loss: 2.106, Test accuracy: 35.02
Round   9, Train loss: 1.456, Test loss: 2.052, Test accuracy: 42.45
Round  10, Train loss: 1.678, Test loss: 2.140, Test accuracy: 33.49
Round  11, Train loss: 1.264, Test loss: 2.117, Test accuracy: 35.70
Round  12, Train loss: 1.391, Test loss: 2.134, Test accuracy: 33.92
Round  13, Train loss: 1.464, Test loss: 2.132, Test accuracy: 34.58
Round  14, Train loss: 0.811, Test loss: 2.080, Test accuracy: 39.46
Round  15, Train loss: 1.468, Test loss: 2.086, Test accuracy: 40.50
Round  16, Train loss: 1.190, Test loss: 2.090, Test accuracy: 40.95
Round  17, Train loss: 0.845, Test loss: 2.034, Test accuracy: 44.59
Round  18, Train loss: 0.776, Test loss: 2.030, Test accuracy: 44.01
Round  19, Train loss: -0.663, Test loss: 1.891, Test accuracy: 58.03
Round  20, Train loss: 0.745, Test loss: 1.992, Test accuracy: 52.80
Round  21, Train loss: -0.557, Test loss: 1.884, Test accuracy: 59.48
Round  22, Train loss: 0.417, Test loss: 1.940, Test accuracy: 53.62
Round  23, Train loss: 0.570, Test loss: 1.973, Test accuracy: 51.90
Round  24, Train loss: -0.013, Test loss: 1.889, Test accuracy: 59.80
Round  25, Train loss: -1.294, Test loss: 1.828, Test accuracy: 65.02
Round  26, Train loss: -1.153, Test loss: 1.838, Test accuracy: 64.22
Round  27, Train loss: -0.965, Test loss: 1.780, Test accuracy: 69.51
Round  28, Train loss: -0.123, Test loss: 1.819, Test accuracy: 65.56
Round  29, Train loss: -0.559, Test loss: 1.813, Test accuracy: 67.40
Round  30, Train loss: 0.311, Test loss: 1.828, Test accuracy: 65.49
Round  31, Train loss: -0.325, Test loss: 1.818, Test accuracy: 65.17
Round  32, Train loss: -1.714, Test loss: 1.779, Test accuracy: 68.69
Round  33, Train loss: -2.151, Test loss: 1.705, Test accuracy: 75.59
Round  34, Train loss: -0.047, Test loss: 1.734, Test accuracy: 73.95
Round  35, Train loss: -0.709, Test loss: 1.699, Test accuracy: 78.55
Round  36, Train loss: -1.243, Test loss: 1.717, Test accuracy: 76.74
Round  37, Train loss: -1.601, Test loss: 1.733, Test accuracy: 74.97
Round  38, Train loss: -1.087, Test loss: 1.755, Test accuracy: 72.26
Round  39, Train loss: -1.539, Test loss: 1.706, Test accuracy: 76.89
Round  40, Train loss: -2.549, Test loss: 1.682, Test accuracy: 79.08
Round  41, Train loss: -3.270, Test loss: 1.668, Test accuracy: 80.25
Round  42, Train loss: -1.336, Test loss: 1.670, Test accuracy: 79.59
Round  43, Train loss: -2.954, Test loss: 1.657, Test accuracy: 80.96
Round  44, Train loss: -1.888, Test loss: 1.687, Test accuracy: 77.66
Round  45, Train loss: -2.577, Test loss: 1.653, Test accuracy: 80.85
Round  46, Train loss: -2.557, Test loss: 1.659, Test accuracy: 80.67
Round  47, Train loss: -2.798, Test loss: 1.644, Test accuracy: 82.02
Round  48, Train loss: -2.595, Test loss: 1.642, Test accuracy: 82.07
Round  49, Train loss: -1.675, Test loss: 1.653, Test accuracy: 80.94
Round  50, Train loss: -3.267, Test loss: 1.659, Test accuracy: 80.22
Round  51, Train loss: -3.071, Test loss: 1.668, Test accuracy: 79.37
Round  52, Train loss: -2.450, Test loss: 1.659, Test accuracy: 80.27
Round  53, Train loss: -3.537, Test loss: 1.633, Test accuracy: 82.92
Round  54, Train loss: -2.533, Test loss: 1.661, Test accuracy: 80.04
Round  55, Train loss: -2.779, Test loss: 1.653, Test accuracy: 80.85
Round  56, Train loss: -3.420, Test loss: 1.634, Test accuracy: 82.69
Round  57, Train loss: -3.210, Test loss: 1.643, Test accuracy: 81.69
Round  58, Train loss: -2.216, Test loss: 1.655, Test accuracy: 80.55
Round  59, Train loss: -2.834, Test loss: 1.632, Test accuracy: 82.80
Round  60, Train loss: -3.090, Test loss: 1.647, Test accuracy: 81.43
Round  61, Train loss: -2.736, Test loss: 1.633, Test accuracy: 82.80
Round  62, Train loss: -3.340, Test loss: 1.615, Test accuracy: 84.61
Round  63, Train loss: -3.272, Test loss: 1.640, Test accuracy: 82.13
Round  64, Train loss: -3.259, Test loss: 1.648, Test accuracy: 81.29
Round  65, Train loss: -3.854, Test loss: 1.638, Test accuracy: 82.29
Round  66, Train loss: -3.495, Test loss: 1.623, Test accuracy: 83.77
Round  67, Train loss: -3.530, Test loss: 1.630, Test accuracy: 83.07
Round  68, Train loss: -3.776, Test loss: 1.608, Test accuracy: 85.36
Round  69, Train loss: -3.502, Test loss: 1.604, Test accuracy: 85.68
Round  70, Train loss: -3.467, Test loss: 1.609, Test accuracy: 85.25
Round  71, Train loss: -3.414, Test loss: 1.612, Test accuracy: 84.89
Round  72, Train loss: -3.315, Test loss: 1.640, Test accuracy: 82.10
Round  73, Train loss: -2.775, Test loss: 1.663, Test accuracy: 79.77
Round  74, Train loss: -3.607, Test loss: 1.653, Test accuracy: 80.77
Round  75, Train loss: -3.433, Test loss: 1.646, Test accuracy: 81.48
Round  76, Train loss: -3.740, Test loss: 1.623, Test accuracy: 83.78
Round  77, Train loss: -3.177, Test loss: 1.637, Test accuracy: 82.34
Round  78, Train loss: -2.807, Test loss: 1.635, Test accuracy: 82.58
Round  79, Train loss: -3.730, Test loss: 1.645, Test accuracy: 81.55
Round  80, Train loss: -3.830, Test loss: 1.613, Test accuracy: 84.79
Round  81, Train loss: -4.094, Test loss: 1.623, Test accuracy: 83.70
Round  82, Train loss: -3.247, Test loss: 1.615, Test accuracy: 84.51
Round  83, Train loss: -3.312, Test loss: 1.616, Test accuracy: 84.46
Round  84, Train loss: -3.324, Test loss: 1.624, Test accuracy: 83.67
Round  85, Train loss: -3.705, Test loss: 1.645, Test accuracy: 81.59
Round  86, Train loss: -2.537, Test loss: 1.661, Test accuracy: 79.95
Round  87, Train loss: -4.007, Test loss: 1.635, Test accuracy: 82.64
Round  88, Train loss: -3.576, Test loss: 1.629, Test accuracy: 83.13
Round  89, Train loss: -3.799, Test loss: 1.636, Test accuracy: 82.44
Round  90, Train loss: -3.026, Test loss: 1.650, Test accuracy: 81.15
Round  91, Train loss: -3.496, Test loss: 1.610, Test accuracy: 85.15
Round  92, Train loss: -3.256, Test loss: 1.614, Test accuracy: 84.71
Round  93, Train loss: -3.182, Test loss: 1.644, Test accuracy: 81.61
Round  94, Train loss: -3.737, Test loss: 1.619, Test accuracy: 84.17
Round  95, Train loss: -3.528, Test loss: 1.637, Test accuracy: 82.35
Round  96, Train loss: -2.654, Test loss: 1.637, Test accuracy: 82.32
Round  97, Train loss: -3.491, Test loss: 1.620, Test accuracy: 83.98
Round  98, Train loss: -2.569, Test loss: 1.615, Test accuracy: 84.50
Round  99, Train loss: -3.540, Test loss: 1.636, Test accuracy: 82.44
Final Round, Train loss: 1.800, Test loss: 1.771, Test accuracy: 69.75
Average accuracy final 10 rounds: 83.238
Average global accuracy final 10 rounds: 83.238
878.0407774448395
[]
[18.78, 19.86, 17.22, 22.47, 14.94, 15.45, 30.36, 33.24, 35.02, 42.45, 33.49, 35.7, 33.92, 34.58, 39.46, 40.5, 40.95, 44.59, 44.01, 58.03, 52.8, 59.48, 53.62, 51.9, 59.8, 65.02, 64.22, 69.51, 65.56, 67.4, 65.49, 65.17, 68.69, 75.59, 73.95, 78.55, 76.74, 74.97, 72.26, 76.89, 79.08, 80.25, 79.59, 80.96, 77.66, 80.85, 80.67, 82.02, 82.07, 80.94, 80.22, 79.37, 80.27, 82.92, 80.04, 80.85, 82.69, 81.69, 80.55, 82.8, 81.43, 82.8, 84.61, 82.13, 81.29, 82.29, 83.77, 83.07, 85.36, 85.68, 85.25, 84.89, 82.1, 79.77, 80.77, 81.48, 83.78, 82.34, 82.58, 81.55, 84.79, 83.7, 84.51, 84.46, 83.67, 81.59, 79.95, 82.64, 83.13, 82.44, 81.15, 85.15, 84.71, 81.61, 84.17, 82.35, 82.32, 83.98, 84.5, 82.44, 69.75]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.0  

prox
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.291, Test loss: 2.295, Test accuracy: 17.51
Round   0, Global train loss: 2.291, Global test loss: 2.301, Global test accuracy: 10.33
Round   1, Train loss: 2.275, Test loss: 2.275, Test accuracy: 21.79
Round   1, Global train loss: 2.275, Global test loss: 2.301, Global test accuracy: 13.54
Round   2, Train loss: 2.213, Test loss: 2.216, Test accuracy: 29.27
Round   2, Global train loss: 2.213, Global test loss: 2.289, Global test accuracy: 13.69
Round   3, Train loss: 2.105, Test loss: 2.123, Test accuracy: 38.18
Round   3, Global train loss: 2.105, Global test loss: 2.287, Global test accuracy: 12.79
Round   4, Train loss: 1.978, Test loss: 2.047, Test accuracy: 45.51
Round   4, Global train loss: 1.978, Global test loss: 2.264, Global test accuracy: 18.47
Round   5, Train loss: 1.954, Test loss: 2.034, Test accuracy: 45.39
Round   5, Global train loss: 1.954, Global test loss: 2.271, Global test accuracy: 16.16
Round   6, Train loss: 1.969, Test loss: 1.985, Test accuracy: 48.94
Round   6, Global train loss: 1.969, Global test loss: 2.284, Global test accuracy: 14.70
Round   7, Train loss: 1.939, Test loss: 1.958, Test accuracy: 51.99
Round   7, Global train loss: 1.939, Global test loss: 2.269, Global test accuracy: 17.80
Round   8, Train loss: 1.843, Test loss: 1.891, Test accuracy: 58.97
Round   8, Global train loss: 1.843, Global test loss: 2.246, Global test accuracy: 20.27
Round   9, Train loss: 1.989, Test loss: 1.891, Test accuracy: 58.36
Round   9, Global train loss: 1.989, Global test loss: 2.252, Global test accuracy: 19.36
Round  10, Train loss: 1.915, Test loss: 1.860, Test accuracy: 61.71
Round  10, Global train loss: 1.915, Global test loss: 2.237, Global test accuracy: 20.84
Round  11, Train loss: 1.905, Test loss: 1.859, Test accuracy: 61.69
Round  11, Global train loss: 1.905, Global test loss: 2.238, Global test accuracy: 20.95
Round  12, Train loss: 1.850, Test loss: 1.856, Test accuracy: 61.66
Round  12, Global train loss: 1.850, Global test loss: 2.254, Global test accuracy: 18.55
Round  13, Train loss: 1.924, Test loss: 1.862, Test accuracy: 60.93
Round  13, Global train loss: 1.924, Global test loss: 2.247, Global test accuracy: 19.81
Round  14, Train loss: 1.896, Test loss: 1.859, Test accuracy: 60.96
Round  14, Global train loss: 1.896, Global test loss: 2.261, Global test accuracy: 17.90
Round  15, Train loss: 1.923, Test loss: 1.852, Test accuracy: 61.77
Round  15, Global train loss: 1.923, Global test loss: 2.279, Global test accuracy: 16.72
Round  16, Train loss: 1.870, Test loss: 1.852, Test accuracy: 61.77
Round  16, Global train loss: 1.870, Global test loss: 2.268, Global test accuracy: 17.45
Round  17, Train loss: 1.817, Test loss: 1.844, Test accuracy: 62.55
Round  17, Global train loss: 1.817, Global test loss: 2.246, Global test accuracy: 20.19
Round  18, Train loss: 1.865, Test loss: 1.840, Test accuracy: 62.80
Round  18, Global train loss: 1.865, Global test loss: 2.248, Global test accuracy: 20.05
Round  19, Train loss: 1.798, Test loss: 1.831, Test accuracy: 63.68
Round  19, Global train loss: 1.798, Global test loss: 2.260, Global test accuracy: 18.87
Round  20, Train loss: 1.878, Test loss: 1.829, Test accuracy: 63.93
Round  20, Global train loss: 1.878, Global test loss: 2.248, Global test accuracy: 20.11
Round  21, Train loss: 1.883, Test loss: 1.838, Test accuracy: 62.97
Round  21, Global train loss: 1.883, Global test loss: 2.256, Global test accuracy: 18.63
Round  22, Train loss: 1.842, Test loss: 1.836, Test accuracy: 63.03
Round  22, Global train loss: 1.842, Global test loss: 2.257, Global test accuracy: 19.01
Round  23, Train loss: 1.862, Test loss: 1.852, Test accuracy: 61.29
Round  23, Global train loss: 1.862, Global test loss: 2.279, Global test accuracy: 15.18
Round  24, Train loss: 1.829, Test loss: 1.835, Test accuracy: 62.96
Round  24, Global train loss: 1.829, Global test loss: 2.246, Global test accuracy: 19.99
Round  25, Train loss: 1.921, Test loss: 1.844, Test accuracy: 62.13
Round  25, Global train loss: 1.921, Global test loss: 2.243, Global test accuracy: 20.90
Round  26, Train loss: 1.881, Test loss: 1.843, Test accuracy: 62.13
Round  26, Global train loss: 1.881, Global test loss: 2.268, Global test accuracy: 16.78
Round  27, Train loss: 1.795, Test loss: 1.846, Test accuracy: 61.85
Round  27, Global train loss: 1.795, Global test loss: 2.239, Global test accuracy: 20.78
Round  28, Train loss: 1.939, Test loss: 1.855, Test accuracy: 60.81
Round  28, Global train loss: 1.939, Global test loss: 2.266, Global test accuracy: 16.78
Round  29, Train loss: 1.779, Test loss: 1.852, Test accuracy: 61.02
Round  29, Global train loss: 1.779, Global test loss: 2.238, Global test accuracy: 20.98
Round  30, Train loss: 1.886, Test loss: 1.853, Test accuracy: 61.00
Round  30, Global train loss: 1.886, Global test loss: 2.260, Global test accuracy: 17.55
Round  31, Train loss: 1.869, Test loss: 1.853, Test accuracy: 60.99
Round  31, Global train loss: 1.869, Global test loss: 2.257, Global test accuracy: 18.02
Round  32, Train loss: 1.796, Test loss: 1.852, Test accuracy: 61.11
Round  32, Global train loss: 1.796, Global test loss: 2.260, Global test accuracy: 17.84
Round  33, Train loss: 1.969, Test loss: 1.851, Test accuracy: 61.04
Round  33, Global train loss: 1.969, Global test loss: 2.264, Global test accuracy: 17.64
Round  34, Train loss: 1.774, Test loss: 1.851, Test accuracy: 61.11
Round  34, Global train loss: 1.774, Global test loss: 2.265, Global test accuracy: 17.80
Round  35, Train loss: 1.746, Test loss: 1.850, Test accuracy: 61.21
Round  35, Global train loss: 1.746, Global test loss: 2.246, Global test accuracy: 19.88
Round  36, Train loss: 1.852, Test loss: 1.857, Test accuracy: 60.35
Round  36, Global train loss: 1.852, Global test loss: 2.247, Global test accuracy: 19.83
Round  37, Train loss: 1.791, Test loss: 1.857, Test accuracy: 60.44
Round  37, Global train loss: 1.791, Global test loss: 2.257, Global test accuracy: 19.11
Round  38, Train loss: 1.911, Test loss: 1.848, Test accuracy: 61.36
Round  38, Global train loss: 1.911, Global test loss: 2.251, Global test accuracy: 19.42
Round  39, Train loss: 1.824, Test loss: 1.848, Test accuracy: 61.32
Round  39, Global train loss: 1.824, Global test loss: 2.247, Global test accuracy: 19.50
Round  40, Train loss: 1.821, Test loss: 1.848, Test accuracy: 61.40
Round  40, Global train loss: 1.821, Global test loss: 2.262, Global test accuracy: 18.13
Round  41, Train loss: 1.815, Test loss: 1.847, Test accuracy: 61.43
Round  41, Global train loss: 1.815, Global test loss: 2.250, Global test accuracy: 19.24
Round  42, Train loss: 1.769, Test loss: 1.839, Test accuracy: 62.39
Round  42, Global train loss: 1.769, Global test loss: 2.248, Global test accuracy: 19.83
Round  43, Train loss: 1.806, Test loss: 1.830, Test accuracy: 63.23
Round  43, Global train loss: 1.806, Global test loss: 2.269, Global test accuracy: 17.41
Round  44, Train loss: 1.888, Test loss: 1.829, Test accuracy: 63.23
Round  44, Global train loss: 1.888, Global test loss: 2.241, Global test accuracy: 20.58
Round  45, Train loss: 1.867, Test loss: 1.829, Test accuracy: 63.28
Round  45, Global train loss: 1.867, Global test loss: 2.252, Global test accuracy: 18.78
Round  46, Train loss: 1.844, Test loss: 1.828, Test accuracy: 63.36
Round  46, Global train loss: 1.844, Global test loss: 2.273, Global test accuracy: 15.87
Round  47, Train loss: 1.778, Test loss: 1.829, Test accuracy: 63.23
Round  47, Global train loss: 1.778, Global test loss: 2.263, Global test accuracy: 17.93
Round  48, Train loss: 1.898, Test loss: 1.821, Test accuracy: 64.10
Round  48, Global train loss: 1.898, Global test loss: 2.263, Global test accuracy: 17.36
Round  49, Train loss: 1.787, Test loss: 1.820, Test accuracy: 64.12
Round  49, Global train loss: 1.787, Global test loss: 2.248, Global test accuracy: 19.39
Round  50, Train loss: 1.770, Test loss: 1.819, Test accuracy: 64.18
Round  50, Global train loss: 1.770, Global test loss: 2.283, Global test accuracy: 15.57
Round  51, Train loss: 1.821, Test loss: 1.820, Test accuracy: 64.17
Round  51, Global train loss: 1.821, Global test loss: 2.264, Global test accuracy: 17.63
Round  52, Train loss: 1.875, Test loss: 1.819, Test accuracy: 64.30
Round  52, Global train loss: 1.875, Global test loss: 2.251, Global test accuracy: 18.82
Round  53, Train loss: 1.895, Test loss: 1.819, Test accuracy: 64.28
Round  53, Global train loss: 1.895, Global test loss: 2.253, Global test accuracy: 18.38
Round  54, Train loss: 1.721, Test loss: 1.819, Test accuracy: 64.31
Round  54, Global train loss: 1.721, Global test loss: 2.234, Global test accuracy: 20.95
Round  55, Train loss: 1.702, Test loss: 1.819, Test accuracy: 64.23
Round  55, Global train loss: 1.702, Global test loss: 2.231, Global test accuracy: 21.70
Round  56, Train loss: 1.810, Test loss: 1.819, Test accuracy: 64.20
Round  56, Global train loss: 1.810, Global test loss: 2.248, Global test accuracy: 19.52
Round  57, Train loss: 1.858, Test loss: 1.820, Test accuracy: 64.16
Round  57, Global train loss: 1.858, Global test loss: 2.245, Global test accuracy: 20.23
Round  58, Train loss: 1.869, Test loss: 1.821, Test accuracy: 64.09
Round  58, Global train loss: 1.869, Global test loss: 2.253, Global test accuracy: 18.94
Round  59, Train loss: 1.796, Test loss: 1.816, Test accuracy: 64.67
Round  59, Global train loss: 1.796, Global test loss: 2.266, Global test accuracy: 17.32
Round  60, Train loss: 1.705, Test loss: 1.812, Test accuracy: 65.05
Round  60, Global train loss: 1.705, Global test loss: 2.255, Global test accuracy: 18.37
Round  61, Train loss: 1.784, Test loss: 1.812, Test accuracy: 65.05
Round  61, Global train loss: 1.784, Global test loss: 2.252, Global test accuracy: 18.92
Round  62, Train loss: 1.755, Test loss: 1.811, Test accuracy: 65.18
Round  62, Global train loss: 1.755, Global test loss: 2.248, Global test accuracy: 19.69
Round  63, Train loss: 1.873, Test loss: 1.819, Test accuracy: 64.28
Round  63, Global train loss: 1.873, Global test loss: 2.244, Global test accuracy: 20.23
Round  64, Train loss: 1.701, Test loss: 1.819, Test accuracy: 64.22
Round  64, Global train loss: 1.701, Global test loss: 2.238, Global test accuracy: 21.24
Round  65, Train loss: 1.801, Test loss: 1.815, Test accuracy: 64.97
Round  65, Global train loss: 1.801, Global test loss: 2.266, Global test accuracy: 17.03
Round  66, Train loss: 1.839, Test loss: 1.807, Test accuracy: 65.77
Round  66, Global train loss: 1.839, Global test loss: 2.253, Global test accuracy: 18.59
Round  67, Train loss: 1.726, Test loss: 1.804, Test accuracy: 66.02
Round  67, Global train loss: 1.726, Global test loss: 2.255, Global test accuracy: 18.93
Round  68, Train loss: 1.790, Test loss: 1.793, Test accuracy: 67.34
Round  68, Global train loss: 1.790, Global test loss: 2.245, Global test accuracy: 20.42
Round  69, Train loss: 1.734, Test loss: 1.795, Test accuracy: 67.01
Round  69, Global train loss: 1.734, Global test loss: 2.239, Global test accuracy: 21.16
Round  70, Train loss: 1.699, Test loss: 1.786, Test accuracy: 67.83
Round  70, Global train loss: 1.699, Global test loss: 2.287, Global test accuracy: 13.61
Round  71, Train loss: 1.783, Test loss: 1.777, Test accuracy: 68.86
Round  71, Global train loss: 1.783, Global test loss: 2.282, Global test accuracy: 14.65
Round  72, Train loss: 1.762, Test loss: 1.770, Test accuracy: 69.63
Round  72, Global train loss: 1.762, Global test loss: 2.263, Global test accuracy: 17.21
Round  73, Train loss: 1.799, Test loss: 1.764, Test accuracy: 70.26
Round  73, Global train loss: 1.799, Global test loss: 2.280, Global test accuracy: 15.17
Round  74, Train loss: 1.706, Test loss: 1.762, Test accuracy: 70.38
Round  74, Global train loss: 1.706, Global test loss: 2.307, Global test accuracy: 12.37
Round  75, Train loss: 1.799, Test loss: 1.771, Test accuracy: 69.44
Round  75, Global train loss: 1.799, Global test loss: 2.275, Global test accuracy: 16.26
Round  76, Train loss: 1.742, Test loss: 1.772, Test accuracy: 69.35
Round  76, Global train loss: 1.742, Global test loss: 2.278, Global test accuracy: 15.47
Round  77, Train loss: 1.817, Test loss: 1.764, Test accuracy: 70.18
Round  77, Global train loss: 1.817, Global test loss: 2.259, Global test accuracy: 17.71
Round  78, Train loss: 1.799, Test loss: 1.754, Test accuracy: 71.23
Round  78, Global train loss: 1.799, Global test loss: 2.256, Global test accuracy: 18.61
Round  79, Train loss: 1.759, Test loss: 1.744, Test accuracy: 72.28
Round  79, Global train loss: 1.759, Global test loss: 2.280, Global test accuracy: 14.94
Round  80, Train loss: 1.717, Test loss: 1.744, Test accuracy: 72.34
Round  80, Global train loss: 1.717, Global test loss: 2.272, Global test accuracy: 15.68
Round  81, Train loss: 1.596, Test loss: 1.744, Test accuracy: 72.40
Round  81, Global train loss: 1.596, Global test loss: 2.268, Global test accuracy: 17.57
Round  82, Train loss: 1.637, Test loss: 1.745, Test accuracy: 72.32
Round  82, Global train loss: 1.637, Global test loss: 2.268, Global test accuracy: 16.82
Round  83, Train loss: 1.714, Test loss: 1.752, Test accuracy: 71.56
Round  83, Global train loss: 1.714, Global test loss: 2.271, Global test accuracy: 16.31
Round  84, Train loss: 1.700, Test loss: 1.751, Test accuracy: 71.60
Round  84, Global train loss: 1.700, Global test loss: 2.279, Global test accuracy: 16.32
Round  85, Train loss: 1.632, Test loss: 1.751, Test accuracy: 71.52
Round  85, Global train loss: 1.632, Global test loss: 2.288, Global test accuracy: 14.10
Round  86, Train loss: 1.804, Test loss: 1.758, Test accuracy: 70.74
Round  86, Global train loss: 1.804, Global test loss: 2.261, Global test accuracy: 17.83
Round  87, Train loss: 1.840, Test loss: 1.759, Test accuracy: 70.53
Round  87, Global train loss: 1.840, Global test loss: 2.242, Global test accuracy: 20.00
Round  88, Train loss: 1.712, Test loss: 1.758, Test accuracy: 70.68
Round  88, Global train loss: 1.712, Global test loss: 2.262, Global test accuracy: 17.80
Round  89, Train loss: 1.688, Test loss: 1.757, Test accuracy: 70.69
Round  89, Global train loss: 1.688, Global test loss: 2.243, Global test accuracy: 20.50
Round  90, Train loss: 1.761, Test loss: 1.733, Test accuracy: 73.17
Round  90, Global train loss: 1.761, Global test loss: 2.252, Global test accuracy: 18.44
Round  91, Train loss: 1.815, Test loss: 1.742, Test accuracy: 72.36
Round  91, Global train loss: 1.815, Global test loss: 2.248, Global test accuracy: 19.32
Round  92, Train loss: 1.749, Test loss: 1.741, Test accuracy: 72.44
Round  92, Global train loss: 1.749, Global test loss: 2.236, Global test accuracy: 20.83
Round  93, Train loss: 1.725, Test loss: 1.741, Test accuracy: 72.41
Round  93, Global train loss: 1.725, Global test loss: 2.263, Global test accuracy: 17.27
Round  94, Train loss: 1.687, Test loss: 1.741, Test accuracy: 72.45
Round  94, Global train loss: 1.687, Global test loss: 2.254, Global test accuracy: 18.55
Round  95, Train loss: 1.792, Test loss: 1.745, Test accuracy: 71.98
Round  95, Global train loss: 1.792, Global test loss: 2.241, Global test accuracy: 20.07/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  96, Train loss: 1.726, Test loss: 1.744, Test accuracy: 72.12
Round  96, Global train loss: 1.726, Global test loss: 2.281, Global test accuracy: 14.88
Round  97, Train loss: 1.730, Test loss: 1.745, Test accuracy: 72.01
Round  97, Global train loss: 1.730, Global test loss: 2.270, Global test accuracy: 17.15
Round  98, Train loss: 1.764, Test loss: 1.746, Test accuracy: 71.86
Round  98, Global train loss: 1.764, Global test loss: 2.246, Global test accuracy: 19.80
Round  99, Train loss: 1.714, Test loss: 1.746, Test accuracy: 71.90
Round  99, Global train loss: 1.714, Global test loss: 2.242, Global test accuracy: 20.19
Final Round, Train loss: 1.701, Test loss: 1.734, Test accuracy: 73.24
Final Round, Global train loss: 1.701, Global test loss: 2.242, Global test accuracy: 20.19
Average accuracy final 10 rounds: 72.27000000000001 

Average global accuracy final 10 rounds: 18.65 

1256.6444227695465
[0.987339973449707, 1.974679946899414, 2.8884403705596924, 3.8022007942199707, 4.710017442703247, 5.617834091186523, 6.5321245193481445, 7.446414947509766, 8.367722034454346, 9.289029121398926, 10.20950436592102, 11.129979610443115, 12.063485860824585, 12.996992111206055, 13.941964626312256, 14.886937141418457, 15.824840784072876, 16.762744426727295, 17.69009804725647, 18.617451667785645, 19.53554105758667, 20.453630447387695, 21.240758180618286, 22.027885913848877, 22.854247093200684, 23.68060827255249, 24.508678436279297, 25.336748600006104, 26.145731210708618, 26.954713821411133, 27.768983125686646, 28.583252429962158, 29.398574590682983, 30.21389675140381, 31.021124601364136, 31.828352451324463, 32.6178514957428, 33.40735054016113, 34.23858880996704, 35.06982707977295, 35.88647198677063, 36.70311689376831, 37.51846647262573, 38.333816051483154, 39.14586782455444, 39.95791959762573, 40.77127766609192, 41.584635734558105, 42.40592908859253, 43.22722244262695, 44.02263689041138, 44.8180513381958, 45.63574242591858, 46.45343351364136, 47.25176453590393, 48.050095558166504, 48.86222982406616, 49.67436408996582, 50.49105477333069, 51.30774545669556, 52.13171172142029, 52.95567798614502, 53.75694704055786, 54.5582160949707, 55.369853258132935, 56.181490421295166, 56.97509217262268, 57.768693923950195, 58.56766986846924, 59.36664581298828, 60.179322242736816, 60.99199867248535, 61.822997093200684, 62.653995513916016, 63.45718574523926, 64.2603759765625, 65.07585120201111, 65.89132642745972, 66.71924948692322, 67.54717254638672, 68.36426401138306, 69.1813554763794, 69.98828554153442, 70.79521560668945, 71.60776162147522, 72.42030763626099, 73.23841333389282, 74.05651903152466, 74.87880253791809, 75.70108604431152, 76.5256335735321, 77.35018110275269, 78.1752598285675, 79.00033855438232, 79.81241822242737, 80.62449789047241, 81.41798210144043, 82.21146631240845, 83.0156261920929, 83.81978607177734, 84.64032626152039, 85.46086645126343, 86.25518417358398, 87.04950189590454, 87.85288596153259, 88.65627002716064, 89.46578526496887, 90.2753005027771, 91.06324815750122, 91.85119581222534, 92.64749026298523, 93.44378471374512, 94.24666666984558, 95.04954862594604, 95.84380769729614, 96.63806676864624, 97.44802212715149, 98.25797748565674, 99.06043291091919, 99.86288833618164, 100.6691906452179, 101.47549295425415, 102.26600074768066, 103.05650854110718, 103.8687539100647, 104.68099927902222, 105.49603724479675, 106.31107521057129, 107.13594388961792, 107.96081256866455, 108.75539207458496, 109.54997158050537, 110.33709239959717, 111.12421321868896, 111.92311811447144, 112.7220230102539, 113.51941108703613, 114.31679916381836, 115.12023830413818, 115.92367744445801, 116.71674680709839, 117.50981616973877, 118.2785234451294, 119.04723072052002, 119.83299231529236, 120.6187539100647, 121.40830159187317, 122.19784927368164, 122.98716878890991, 123.77648830413818, 124.59350228309631, 125.41051626205444, 126.20825004577637, 127.00598382949829, 127.80314588546753, 128.60030794143677, 129.3786883354187, 130.15706872940063, 130.96027874946594, 131.76348876953125, 132.56770181655884, 133.37191486358643, 134.16423296928406, 134.9565510749817, 135.75216007232666, 136.54776906967163, 137.34385704994202, 138.1399450302124, 138.93582844734192, 139.73171186447144, 140.5465772151947, 141.36144256591797, 142.166512966156, 142.97158336639404, 143.77042269706726, 144.56926202774048, 145.35081028938293, 146.1323585510254, 146.92189121246338, 147.71142387390137, 148.50912857055664, 149.3068332672119, 150.0982484817505, 150.88966369628906, 151.68100500106812, 152.47234630584717, 153.266259431839, 154.0601725578308, 154.85800099372864, 155.65582942962646, 156.44010758399963, 157.2243857383728, 158.01736617088318, 158.81034660339355, 159.60066390037537, 160.39098119735718, 161.18426132202148, 161.9775414466858, 162.77962255477905, 163.58170366287231, 165.18458938598633, 166.78747510910034]
[17.51, 17.51, 21.79, 21.79, 29.27, 29.27, 38.18, 38.18, 45.51, 45.51, 45.39, 45.39, 48.94, 48.94, 51.99, 51.99, 58.97, 58.97, 58.36, 58.36, 61.71, 61.71, 61.69, 61.69, 61.66, 61.66, 60.93, 60.93, 60.96, 60.96, 61.77, 61.77, 61.77, 61.77, 62.55, 62.55, 62.8, 62.8, 63.68, 63.68, 63.93, 63.93, 62.97, 62.97, 63.03, 63.03, 61.29, 61.29, 62.96, 62.96, 62.13, 62.13, 62.13, 62.13, 61.85, 61.85, 60.81, 60.81, 61.02, 61.02, 61.0, 61.0, 60.99, 60.99, 61.11, 61.11, 61.04, 61.04, 61.11, 61.11, 61.21, 61.21, 60.35, 60.35, 60.44, 60.44, 61.36, 61.36, 61.32, 61.32, 61.4, 61.4, 61.43, 61.43, 62.39, 62.39, 63.23, 63.23, 63.23, 63.23, 63.28, 63.28, 63.36, 63.36, 63.23, 63.23, 64.1, 64.1, 64.12, 64.12, 64.18, 64.18, 64.17, 64.17, 64.3, 64.3, 64.28, 64.28, 64.31, 64.31, 64.23, 64.23, 64.2, 64.2, 64.16, 64.16, 64.09, 64.09, 64.67, 64.67, 65.05, 65.05, 65.05, 65.05, 65.18, 65.18, 64.28, 64.28, 64.22, 64.22, 64.97, 64.97, 65.77, 65.77, 66.02, 66.02, 67.34, 67.34, 67.01, 67.01, 67.83, 67.83, 68.86, 68.86, 69.63, 69.63, 70.26, 70.26, 70.38, 70.38, 69.44, 69.44, 69.35, 69.35, 70.18, 70.18, 71.23, 71.23, 72.28, 72.28, 72.34, 72.34, 72.4, 72.4, 72.32, 72.32, 71.56, 71.56, 71.6, 71.6, 71.52, 71.52, 70.74, 70.74, 70.53, 70.53, 70.68, 70.68, 70.69, 70.69, 73.17, 73.17, 72.36, 72.36, 72.44, 72.44, 72.41, 72.41, 72.45, 72.45, 71.98, 71.98, 72.12, 72.12, 72.01, 72.01, 71.86, 71.86, 71.9, 71.9, 73.24, 73.24]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fed_ditto%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
Round   0, Train loss: 2.297, Test loss: 2.303, Test accuracy: 9.39
Round   1, Train loss: 2.288, Test loss: 2.298, Test accuracy: 10.37
Round   2, Train loss: 2.234, Test loss: 2.287, Test accuracy: 15.43
Round   3, Train loss: 2.130, Test loss: 2.269, Test accuracy: 17.04
Round   4, Train loss: 1.976, Test loss: 2.253, Test accuracy: 19.36
Round   5, Train loss: 2.007, Test loss: 2.248, Test accuracy: 19.95
Round   6, Train loss: 1.927, Test loss: 2.245, Test accuracy: 20.14
Round   7, Train loss: 1.999, Test loss: 2.237, Test accuracy: 21.10
Round   8, Train loss: 1.967, Test loss: 2.230, Test accuracy: 22.27
Round   9, Train loss: 1.970, Test loss: 2.218, Test accuracy: 23.36
Round  10, Train loss: 1.839, Test loss: 2.221, Test accuracy: 23.31
Round  11, Train loss: 1.816, Test loss: 2.234, Test accuracy: 21.29
Round  12, Train loss: 1.808, Test loss: 2.238, Test accuracy: 20.97
Round  13, Train loss: 1.681, Test loss: 2.225, Test accuracy: 22.90
Round  14, Train loss: 1.881, Test loss: 2.229, Test accuracy: 21.79
Round  15, Train loss: 1.839, Test loss: 2.239, Test accuracy: 20.64
Round  16, Train loss: 1.794, Test loss: 2.222, Test accuracy: 22.67
Round  17, Train loss: 1.868, Test loss: 2.219, Test accuracy: 23.20
Round  18, Train loss: 1.683, Test loss: 2.224, Test accuracy: 22.51
Round  19, Train loss: 1.750, Test loss: 2.227, Test accuracy: 22.55
Round  20, Train loss: 1.815, Test loss: 2.236, Test accuracy: 21.71
Round  21, Train loss: 1.815, Test loss: 2.240, Test accuracy: 20.29
Round  22, Train loss: 1.868, Test loss: 2.227, Test accuracy: 22.54
Round  23, Train loss: 1.689, Test loss: 2.229, Test accuracy: 22.14
Round  24, Train loss: 1.802, Test loss: 2.223, Test accuracy: 22.92
Round  25, Train loss: 1.748, Test loss: 2.218, Test accuracy: 23.67
Round  26, Train loss: 1.713, Test loss: 2.210, Test accuracy: 23.78
Round  27, Train loss: 1.760, Test loss: 2.219, Test accuracy: 22.91
Round  28, Train loss: 1.805, Test loss: 2.218, Test accuracy: 23.56
Round  29, Train loss: 1.858, Test loss: 2.220, Test accuracy: 23.15
Round  30, Train loss: 1.716, Test loss: 2.263, Test accuracy: 17.54
Round  31, Train loss: 1.890, Test loss: 2.225, Test accuracy: 22.45
Round  32, Train loss: 1.716, Test loss: 2.224, Test accuracy: 22.45
Round  33, Train loss: 1.798, Test loss: 2.239, Test accuracy: 20.60
Round  34, Train loss: 1.827, Test loss: 2.231, Test accuracy: 21.73
Round  35, Train loss: 1.739, Test loss: 2.257, Test accuracy: 18.20
Round  36, Train loss: 1.735, Test loss: 2.216, Test accuracy: 23.37
Round  37, Train loss: 1.759, Test loss: 2.212, Test accuracy: 23.98
Round  38, Train loss: 1.727, Test loss: 2.230, Test accuracy: 21.62
Round  39, Train loss: 1.782, Test loss: 2.247, Test accuracy: 20.56
Round  40, Train loss: 1.703, Test loss: 2.231, Test accuracy: 21.79
Round  41, Train loss: 1.677, Test loss: 2.229, Test accuracy: 21.66
Round  42, Train loss: 1.748, Test loss: 2.202, Test accuracy: 25.31
Round  43, Train loss: 1.784, Test loss: 2.215, Test accuracy: 23.75
Round  44, Train loss: 1.752, Test loss: 2.265, Test accuracy: 17.93
Round  45, Train loss: 1.756, Test loss: 2.251, Test accuracy: 19.21
Round  46, Train loss: 1.904, Test loss: 2.235, Test accuracy: 20.85
Round  47, Train loss: 1.761, Test loss: 2.232, Test accuracy: 21.16
Round  48, Train loss: 1.723, Test loss: 2.217, Test accuracy: 23.42
Round  49, Train loss: 1.751, Test loss: 2.229, Test accuracy: 21.82
Round  50, Train loss: 1.695, Test loss: 2.233, Test accuracy: 21.01
Round  51, Train loss: 1.811, Test loss: 2.234, Test accuracy: 21.15
Round  52, Train loss: 1.715, Test loss: 2.244, Test accuracy: 19.80
Round  53, Train loss: 1.641, Test loss: 2.252, Test accuracy: 19.32
Round  54, Train loss: 1.782, Test loss: 2.240, Test accuracy: 20.62
Round  55, Train loss: 1.731, Test loss: 2.246, Test accuracy: 19.47
Round  56, Train loss: 1.630, Test loss: 2.247, Test accuracy: 19.38
Round  57, Train loss: 1.694, Test loss: 2.246, Test accuracy: 19.65
Round  58, Train loss: 1.658, Test loss: 2.250, Test accuracy: 19.20
Round  59, Train loss: 1.718, Test loss: 2.243, Test accuracy: 19.77
Round  60, Train loss: 1.774, Test loss: 2.235, Test accuracy: 21.33
Round  61, Train loss: 1.747, Test loss: 2.228, Test accuracy: 22.14
Round  62, Train loss: 1.746, Test loss: 2.248, Test accuracy: 19.37
Round  63, Train loss: 1.701, Test loss: 2.257, Test accuracy: 18.56
Round  64, Train loss: 1.717, Test loss: 2.245, Test accuracy: 19.81
Round  65, Train loss: 1.749, Test loss: 2.217, Test accuracy: 23.33
Round  66, Train loss: 1.732, Test loss: 2.249, Test accuracy: 19.29
Round  67, Train loss: 1.627, Test loss: 2.244, Test accuracy: 19.85
Round  68, Train loss: 1.682, Test loss: 2.212, Test accuracy: 24.07
Round  69, Train loss: 1.712, Test loss: 2.259, Test accuracy: 17.98
Round  70, Train loss: 1.655, Test loss: 2.243, Test accuracy: 20.00
Round  71, Train loss: 1.680, Test loss: 2.241, Test accuracy: 20.84
Round  72, Train loss: 1.774, Test loss: 2.222, Test accuracy: 22.79
Round  73, Train loss: 1.687, Test loss: 2.237, Test accuracy: 21.24
Round  74, Train loss: 1.676, Test loss: 2.239, Test accuracy: 20.30
Round  75, Train loss: 1.659, Test loss: 2.246, Test accuracy: 19.54
Round  76, Train loss: 1.772, Test loss: 2.237, Test accuracy: 20.60
Round  77, Train loss: 1.737, Test loss: 2.233, Test accuracy: 21.15
Round  78, Train loss: 1.739, Test loss: 2.246, Test accuracy: 19.27
Round  79, Train loss: 1.656, Test loss: 2.253, Test accuracy: 18.37
Round  80, Train loss: 1.649, Test loss: 2.250, Test accuracy: 19.43
Round  81, Train loss: 1.679, Test loss: 2.244, Test accuracy: 19.55
Round  82, Train loss: 1.681, Test loss: 2.231, Test accuracy: 21.63
Round  83, Train loss: 1.645, Test loss: 2.223, Test accuracy: 22.32
Round  84, Train loss: 1.740, Test loss: 2.242, Test accuracy: 20.20
Round  85, Train loss: 1.677, Test loss: 2.226, Test accuracy: 21.75
Round  86, Train loss: 1.615, Test loss: 2.258, Test accuracy: 17.95
Round  87, Train loss: 1.798, Test loss: 2.245, Test accuracy: 19.84
Round  88, Train loss: 1.680, Test loss: 2.241, Test accuracy: 20.29
Round  89, Train loss: 1.644, Test loss: 2.234, Test accuracy: 21.50
Round  90, Train loss: 1.704, Test loss: 2.204, Test accuracy: 24.56
Round  91, Train loss: 1.647, Test loss: 2.250, Test accuracy: 19.74
Round  92, Train loss: 1.681, Test loss: 2.213, Test accuracy: 23.65
Round  93, Train loss: 1.740, Test loss: 2.219, Test accuracy: 23.19
Round  94, Train loss: 1.621, Test loss: 2.246, Test accuracy: 19.21
Round  95, Train loss: 1.740, Test loss: 2.207, Test accuracy: 24.57
Round  96, Train loss: 1.644, Test loss: 2.258, Test accuracy: 18.97
Round  97, Train loss: 1.770, Test loss: 2.211, Test accuracy: 23.77
Round  98, Train loss: 1.796, Test loss: 2.221, Test accuracy: 22.71
Round  99, Train loss: 1.734, Test loss: 2.235, Test accuracy: 21.30
Final Round, Train loss: 1.693, Test loss: 2.215, Test accuracy: 23.08
Average accuracy final 10 rounds: 22.167
1501.1252717971802
[2.33990740776062, 4.5281500816345215, 6.712185859680176, 8.914319276809692, 11.097195625305176, 13.279017448425293, 15.45993423461914, 17.64772868156433, 19.842292308807373, 22.024921417236328, 24.20342469215393, 26.37727189064026, 28.552215814590454, 30.729415893554688, 32.92723751068115, 35.12658214569092, 37.29351258277893, 39.45375084877014, 41.615811586380005, 43.78796672821045, 45.96116757392883, 48.14282536506653, 50.30552363395691, 52.508415937423706, 54.67237973213196, 56.839911222457886, 59.03898882865906, 61.2106819152832, 63.38732838630676, 65.56553983688354, 67.73927736282349, 69.92230129241943, 72.09488940238953, 74.2682716846466, 76.46636462211609, 78.63564205169678, 80.80646347999573, 82.97165036201477, 85.14012336730957, 87.29875540733337, 89.45406889915466, 91.60275840759277, 93.594309091568, 95.55455231666565, 97.51921582221985, 99.50159549713135, 101.4728045463562, 103.45433473587036, 105.43777680397034, 107.40532755851746, 109.38582754135132, 111.36920475959778, 113.35174322128296, 115.32495594024658, 117.30092263221741, 119.28068614006042, 121.28107762336731, 123.26380467414856, 125.22767543792725, 127.21898293495178, 129.2061460018158, 131.1706097126007, 133.13605880737305, 135.26717829704285, 137.42968940734863, 139.55449056625366, 141.53862118721008, 143.54408431053162, 145.5366666316986, 147.52058506011963, 149.49465417861938, 151.46258354187012, 153.4445276260376, 155.42909288406372, 157.40516901016235, 159.39310836791992, 161.3748278617859, 163.35387063026428, 165.33022379875183, 167.31723880767822, 169.3202965259552, 171.30548119544983, 173.2940468788147, 175.29869484901428, 177.28684043884277, 179.27662539482117, 181.26261186599731, 183.26588487625122, 185.25779724121094, 187.23843121528625, 189.2200207710266, 191.20374083518982, 193.1881067752838, 195.1614329814911, 197.15279293060303, 199.13735389709473, 201.09724736213684, 203.06612920761108, 205.06065702438354, 207.0523443222046, 209.04189729690552]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[9.39, 10.37, 15.43, 17.04, 19.36, 19.95, 20.14, 21.1, 22.27, 23.36, 23.31, 21.29, 20.97, 22.9, 21.79, 20.64, 22.67, 23.2, 22.51, 22.55, 21.71, 20.29, 22.54, 22.14, 22.92, 23.67, 23.78, 22.91, 23.56, 23.15, 17.54, 22.45, 22.45, 20.6, 21.73, 18.2, 23.37, 23.98, 21.62, 20.56, 21.79, 21.66, 25.31, 23.75, 17.93, 19.21, 20.85, 21.16, 23.42, 21.82, 21.01, 21.15, 19.8, 19.32, 20.62, 19.47, 19.38, 19.65, 19.2, 19.77, 21.33, 22.14, 19.37, 18.56, 19.81, 23.33, 19.29, 19.85, 24.07, 17.98, 20.0, 20.84, 22.79, 21.24, 20.3, 19.54, 20.6, 21.15, 19.27, 18.37, 19.43, 19.55, 21.63, 22.32, 20.2, 21.75, 17.95, 19.84, 20.29, 21.5, 24.56, 19.74, 23.65, 23.19, 19.21, 24.57, 18.97, 23.77, 22.71, 21.3, 23.08]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  pFedMe   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 400, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.302, Test loss: 2.303, Test accuracy: 7.88
Round   0, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.83
Round   1, Train loss: 2.302, Test loss: 2.303, Test accuracy: 7.88
Round   1, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.84
Round   2, Train loss: 2.302, Test loss: 2.303, Test accuracy: 7.90
Round   2, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.85
Round   3, Train loss: 2.302, Test loss: 2.303, Test accuracy: 7.91
Round   3, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.85
Round   4, Train loss: 2.303, Test loss: 2.303, Test accuracy: 7.95
Round   4, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.85
Round   5, Train loss: 2.303, Test loss: 2.303, Test accuracy: 7.99
Round   5, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.87
Round   6, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.03
Round   6, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.89
Round   7, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.06
Round   7, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.89
Round   8, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.12
Round   8, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.89
Round   9, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.12
Round   9, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.95
Round  10, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.13
Round  10, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.96
Round  11, Train loss: 2.305, Test loss: 2.303, Test accuracy: 8.14
Round  11, Global train loss: 2.305, Global test loss: 2.303, Global test accuracy: 7.96
Round  12, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.17
Round  12, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 7.94
Round  13, Train loss: 2.301, Test loss: 2.303, Test accuracy: 8.16
Round  13, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 7.95
Round  14, Train loss: 2.304, Test loss: 2.303, Test accuracy: 8.15
Round  14, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 7.96
Round  15, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.12
Round  15, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 7.95
Round  16, Train loss: 2.304, Test loss: 2.303, Test accuracy: 8.13
Round  16, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 7.98
Round  17, Train loss: 2.301, Test loss: 2.303, Test accuracy: 8.08
Round  17, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 7.99
Round  18, Train loss: 2.301, Test loss: 2.303, Test accuracy: 8.12
Round  18, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 7.98
Round  19, Train loss: 2.305, Test loss: 2.303, Test accuracy: 8.11
Round  19, Global train loss: 2.305, Global test loss: 2.303, Global test accuracy: 7.99
Round  20, Train loss: 2.301, Test loss: 2.303, Test accuracy: 8.16
Round  20, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 8.01
Round  21, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.22
Round  21, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.07
Round  22, Train loss: 2.301, Test loss: 2.303, Test accuracy: 8.31
Round  22, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 8.07
Round  23, Train loss: 2.301, Test loss: 2.303, Test accuracy: 8.35
Round  23, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 8.10
Round  24, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.32
Round  24, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.13
Round  25, Train loss: 2.304, Test loss: 2.303, Test accuracy: 8.34
Round  25, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 8.11
Round  26, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.37
Round  26, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.15
Round  27, Train loss: 2.305, Test loss: 2.303, Test accuracy: 8.37
Round  27, Global train loss: 2.305, Global test loss: 2.303, Global test accuracy: 8.16
Round  28, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.33
Round  28, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.11
Round  29, Train loss: 2.304, Test loss: 2.303, Test accuracy: 8.31
Round  29, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 8.12
Round  30, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.29
Round  30, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.13
Round  31, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.29
Round  31, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.22
Round  32, Train loss: 2.305, Test loss: 2.303, Test accuracy: 8.31
Round  32, Global train loss: 2.305, Global test loss: 2.303, Global test accuracy: 8.23
Round  33, Train loss: 2.302, Test loss: 2.303, Test accuracy: 8.35
Round  33, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.26
Round  34, Train loss: 2.301, Test loss: 2.303, Test accuracy: 8.48
Round  34, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 8.24
Round  35, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.47
Round  35, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.26
Round  36, Train loss: 2.301, Test loss: 2.303, Test accuracy: 8.50
Round  36, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 8.26
Round  37, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.53
Round  37, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.29
Round  38, Train loss: 2.304, Test loss: 2.303, Test accuracy: 8.56
Round  38, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 8.29
Round  39, Train loss: 2.304, Test loss: 2.303, Test accuracy: 8.58
Round  39, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 8.30
Round  40, Train loss: 2.305, Test loss: 2.303, Test accuracy: 8.59
Round  40, Global train loss: 2.305, Global test loss: 2.303, Global test accuracy: 8.28
Round  41, Train loss: 2.301, Test loss: 2.303, Test accuracy: 8.59
Round  41, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 8.31
Round  42, Train loss: 2.301, Test loss: 2.303, Test accuracy: 8.57
Round  42, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 8.29
Round  43, Train loss: 2.303, Test loss: 2.303, Test accuracy: 8.50
Round  43, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.28
Round  44, Train loss: 2.301, Test loss: 2.303, Test accuracy: 8.52
Round  44, Global train loss: 2.301, Global test loss: 2.303, Global test accuracy: 8.27
Round  45, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.53
Round  45, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.33
Round  46, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.57
Round  46, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.32
Round  47, Train loss: 2.300, Test loss: 2.302, Test accuracy: 8.56
Round  47, Global train loss: 2.300, Global test loss: 2.303, Global test accuracy: 8.33
Round  48, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.56
Round  48, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.33
Round  49, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.57
Round  49, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.38
Round  50, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.64
Round  50, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.39
Round  51, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.68
Round  51, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.37
Round  52, Train loss: 2.304, Test loss: 2.302, Test accuracy: 8.67
Round  52, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 8.36
Round  53, Train loss: 2.304, Test loss: 2.302, Test accuracy: 8.65
Round  53, Global train loss: 2.304, Global test loss: 2.303, Global test accuracy: 8.37
Round  54, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.68
Round  54, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.40
Round  55, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.72
Round  55, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.39
Round  56, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.65
Round  56, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.42
Round  57, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.65
Round  57, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.37
Round  58, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.66
Round  58, Global train loss: 2.302, Global test loss: 2.303, Global test accuracy: 8.40
Round  59, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.65
Round  59, Global train loss: 2.303, Global test loss: 2.303, Global test accuracy: 8.39
Round  60, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.68
Round  60, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 8.38
Round  61, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.71
Round  61, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.41
Round  62, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.70
Round  62, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.36
Round  63, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.70
Round  63, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.38
Round  64, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.70
Round  64, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.43
Round  65, Train loss: 2.301, Test loss: 2.302, Test accuracy: 8.71
Round  65, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 8.50
Round  66, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.70
Round  66, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.51
Round  67, Train loss: 2.300, Test loss: 2.302, Test accuracy: 8.71
Round  67, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 8.49
Round  68, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.73
Round  68, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 8.53
Round  69, Train loss: 2.300, Test loss: 2.302, Test accuracy: 8.77
Round  69, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 8.52
Round  70, Train loss: 2.299, Test loss: 2.302, Test accuracy: 8.81
Round  70, Global train loss: 2.299, Global test loss: 2.302, Global test accuracy: 8.54
Round  71, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.82
Round  71, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 8.51
Round  72, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.87
Round  72, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.57
Round  73, Train loss: 2.301, Test loss: 2.302, Test accuracy: 8.94
Round  73, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 8.59
Round  74, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.86
Round  74, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 8.58
Round  75, Train loss: 2.304, Test loss: 2.302, Test accuracy: 8.88
Round  75, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 8.56
Round  76, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.87
Round  76, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.62
Round  77, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.88
Round  77, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.64
Round  78, Train loss: 2.302, Test loss: 2.302, Test accuracy: 8.95
Round  78, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.63
Round  79, Train loss: 2.301, Test loss: 2.302, Test accuracy: 8.95
Round  79, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 8.66
Round  80, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.89
Round  80, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 8.66
Round  81, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.95
Round  81, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 8.65
Round  82, Train loss: 2.304, Test loss: 2.302, Test accuracy: 8.96
Round  82, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 8.70
Round  83, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.96
Round  83, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 8.71
Round  84, Train loss: 2.304, Test loss: 2.302, Test accuracy: 8.93
Round  84, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 8.74
Round  85, Train loss: 2.303, Test loss: 2.302, Test accuracy: 8.91
Round  85, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 8.79
Round  86, Train loss: 2.301, Test loss: 2.302, Test accuracy: 8.94
Round  86, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 8.77
Round  87, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.05
Round  87, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 8.81
Round  88, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.06
Round  88, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 8.82
Round  89, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.10
Round  89, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 8.82
Round  90, Train loss: 2.300, Test loss: 2.302, Test accuracy: 9.18
Round  90, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 8.89
Round  91, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.25
Round  91, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.93
Round  92, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.20
Round  92, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 8.92
Round  93, Train loss: 2.299, Test loss: 2.302, Test accuracy: 9.26
Round  93, Global train loss: 2.299, Global test loss: 2.302, Global test accuracy: 8.93
Round  94, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.28
Round  94, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.94
Round  95, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.27
Round  95, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 8.96
Round  96, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.30
Round  96, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 8.96
Round  97, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.32
Round  97, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 8.99
Round  98, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.33
Round  98, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 8.99
Round  99, Train loss: 2.305, Test loss: 2.302, Test accuracy: 9.32
Round  99, Global train loss: 2.305, Global test loss: 2.302, Global test accuracy: 9.02
Round 100, Train loss: 2.300, Test loss: 2.302, Test accuracy: 9.35
Round 100, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 9.01
Round 101, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.37
Round 101, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.01
Round 102, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.27
Round 102, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.02
Round 103, Train loss: 2.305, Test loss: 2.302, Test accuracy: 9.29
Round 103, Global train loss: 2.305, Global test loss: 2.302, Global test accuracy: 9.04
Round 104, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.31
Round 104, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.04
Round 105, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.31
Round 105, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.06
Round 106, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.36
Round 106, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.07
Round 107, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.37
Round 107, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.10
Round 108, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.38
Round 108, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.07
Round 109, Train loss: 2.304, Test loss: 2.302, Test accuracy: 9.33
Round 109, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 9.09
Round 110, Train loss: 2.304, Test loss: 2.302, Test accuracy: 9.38
Round 110, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 9.07
Round 111, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.39
Round 111, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.04
Round 112, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.39
Round 112, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.02
Round 113, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.41
Round 113, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.03
Round 114, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.44
Round 114, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 8.99
Round 115, Train loss: 2.300, Test loss: 2.302, Test accuracy: 9.39
Round 115, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 9.01
Round 116, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.45
Round 116, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.97
Round 117, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.44
Round 117, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.97
Round 118, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.43
Round 118, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 8.95
Round 119, Train loss: 2.300, Test loss: 2.302, Test accuracy: 9.42
Round 119, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 8.97
Round 120, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.43
Round 120, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.01
Round 121, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.50
Round 121, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 8.97
Round 122, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.47
Round 122, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.00
Round 123, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.50
Round 123, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.03
Round 124, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.47
Round 124, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.08
Round 125, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.50
Round 125, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.10
Round 126, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.54
Round 126, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.05
Round 127, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.49
Round 127, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.08
Round 128, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.53
Round 128, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.08
Round 129, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.57
Round 129, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.17
Round 130, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.63
Round 130, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.17
Round 131, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.55
Round 131, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.22
Round 132, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.60
Round 132, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.26
Round 133, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.58
Round 133, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.23
Round 134, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.70
Round 134, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.30
Round 135, Train loss: 2.304, Test loss: 2.302, Test accuracy: 9.78
Round 135, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 9.35
Round 136, Train loss: 2.300, Test loss: 2.302, Test accuracy: 9.77
Round 136, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 9.38
Round 137, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.80
Round 137, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.40
Round 138, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.80
Round 138, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.35
Round 139, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.86
Round 139, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.32
Round 140, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.89
Round 140, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.42
Round 141, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.93
Round 141, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.46
Round 142, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.01
Round 142, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.52
Round 143, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.00
Round 143, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.51
Round 144, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.00
Round 144, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.50
Round 145, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.93
Round 145, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.53
Round 146, Train loss: 2.301, Test loss: 2.302, Test accuracy: 9.92
Round 146, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.53
Round 147, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.02
Round 147, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.57
Round 148, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.02
Round 148, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.58
Round 149, Train loss: 2.302, Test loss: 2.302, Test accuracy: 9.98
Round 149, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.65
Round 150, Train loss: 2.300, Test loss: 2.302, Test accuracy: 10.02
Round 150, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 9.62
Round 151, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.04
Round 151, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.64
Round 152, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.11
Round 152, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.68
Round 153, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.07
Round 153, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.70
Round 154, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.11
Round 154, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.71
Round 155, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.09
Round 155, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.66
Round 156, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.09
Round 156, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.69
Round 157, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.13
Round 157, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.71
Round 158, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.13
Round 158, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.72
Round 159, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.17
Round 159, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.75
Round 160, Train loss: 2.304, Test loss: 2.302, Test accuracy: 10.17
Round 160, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 9.76
Round 161, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.13
Round 161, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.76
Round 162, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.16
Round 162, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.76
Round 163, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.18
Round 163, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.72
Round 164, Train loss: 2.304, Test loss: 2.302, Test accuracy: 10.20
Round 164, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 9.74
Round 165, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.29
Round 165, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.81
Round 166, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.22
Round 166, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.90
Round 167, Train loss: 2.300, Test loss: 2.302, Test accuracy: 10.23
Round 167, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 9.86
Round 168, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.27
Round 168, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.97
Round 169, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.38
Round 169, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.97
Round 170, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.47
Round 170, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 9.96
Round 171, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.55
Round 171, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 9.95
Round 172, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.55
Round 172, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 9.95
Round 173, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.61
Round 173, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.00
Round 174, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.61
Round 174, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.07
Round 175, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.64
Round 175, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.07
Round 176, Train loss: 2.304, Test loss: 2.302, Test accuracy: 10.68
Round 176, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 10.13
Round 177, Train loss: 2.299, Test loss: 2.302, Test accuracy: 10.56
Round 177, Global train loss: 2.299, Global test loss: 2.302, Global test accuracy: 10.11
Round 178, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.57
Round 178, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.12
Round 179, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.56
Round 179, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.10
Round 180, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.57
Round 180, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.09
Round 181, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.67
Round 181, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.11
Round 182, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.63
Round 182, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.17
Round 183, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.61
Round 183, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.10
Round 184, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.62
Round 184, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.19
Round 185, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.57
Round 185, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.10
Round 186, Train loss: 2.300, Test loss: 2.302, Test accuracy: 10.60
Round 186, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 10.09
Round 187, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.55
Round 187, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.09
Round 188, Train loss: 2.304, Test loss: 2.302, Test accuracy: 10.54
Round 188, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 10.10
Round 189, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.50
Round 189, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.05
Round 190, Train loss: 2.304, Test loss: 2.302, Test accuracy: 10.56
Round 190, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 10.10
Round 191, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.43
Round 191, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.17
Round 192, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.47
Round 192, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.19
Round 193, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.52
Round 193, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.20
Round 194, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.53
Round 194, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.26
Round 195, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.58
Round 195, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.30
Round 196, Train loss: 2.300, Test loss: 2.302, Test accuracy: 10.57
Round 196, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 10.26
Round 197, Train loss: 2.300, Test loss: 2.302, Test accuracy: 10.65
Round 197, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 10.26
Round 198, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.72
Round 198, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.26
Round 199, Train loss: 2.304, Test loss: 2.302, Test accuracy: 10.74
Round 199, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 10.29
Round 200, Train loss: 2.299, Test loss: 2.302, Test accuracy: 10.76
Round 200, Global train loss: 2.299, Global test loss: 2.302, Global test accuracy: 10.30
Round 201, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.77
Round 201, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.32
Round 202, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.78
Round 202, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.38
Round 203, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.88
Round 203, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.37
Round 204, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.88
Round 204, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.39
Round 205, Train loss: 2.300, Test loss: 2.302, Test accuracy: 10.88
Round 205, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 10.40
Round 206, Train loss: 2.299, Test loss: 2.302, Test accuracy: 10.90
Round 206, Global train loss: 2.299, Global test loss: 2.302, Global test accuracy: 10.45
Round 207, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.98
Round 207, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.45
Round 208, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.01
Round 208, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.41
Round 209, Train loss: 2.304, Test loss: 2.302, Test accuracy: 10.99
Round 209, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 10.47
Round 210, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.00
Round 210, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.48
Round 211, Train loss: 2.303, Test loss: 2.302, Test accuracy: 10.96
Round 211, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.50
Round 212, Train loss: 2.302, Test loss: 2.302, Test accuracy: 10.92
Round 212, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.56
Round 213, Train loss: 2.299, Test loss: 2.302, Test accuracy: 11.02
Round 213, Global train loss: 2.299, Global test loss: 2.302, Global test accuracy: 10.57
Round 214, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.05
Round 214, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.56
Round 215, Train loss: 2.300, Test loss: 2.302, Test accuracy: 11.02
Round 215, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 10.59
Round 216, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.03
Round 216, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.50
Round 217, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.03
Round 217, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.49
Round 218, Train loss: 2.300, Test loss: 2.302, Test accuracy: 11.08
Round 218, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 10.47
Round 219, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.04
Round 219, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.48
Round 220, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.02
Round 220, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.58
Round 221, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.98
Round 221, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.61
Round 222, Train loss: 2.300, Test loss: 2.302, Test accuracy: 11.05
Round 222, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 10.61
Round 223, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.08
Round 223, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.62
Round 224, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.10
Round 224, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.63
Round 225, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.13
Round 225, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.67
Round 226, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.19
Round 226, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.73
Round 227, Train loss: 2.304, Test loss: 2.302, Test accuracy: 11.18
Round 227, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 10.75
Round 228, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.19
Round 228, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.79
Round 229, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.22
Round 229, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.80
Round 230, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.25
Round 230, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.76
Round 231, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.24
Round 231, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.73
Round 232, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.29
Round 232, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.83
Round 233, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.26
Round 233, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.81
Round 234, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.33
Round 234, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.81
Round 235, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.33
Round 235, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.83
Round 236, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.33
Round 236, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.82
Round 237, Train loss: 2.300, Test loss: 2.302, Test accuracy: 11.30
Round 237, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 10.80
Round 238, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.40
Round 238, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.88
Round 239, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.41
Round 239, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.89
Round 240, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.40
Round 240, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.92
Round 241, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.45
Round 241, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 10.98
Round 242, Train loss: 2.300, Test loss: 2.302, Test accuracy: 11.47
Round 242, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 10.90
Round 243, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.48
Round 243, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.90
Round 244, Train loss: 2.299, Test loss: 2.302, Test accuracy: 11.49
Round 244, Global train loss: 2.299, Global test loss: 2.302, Global test accuracy: 10.91
Round 245, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.49
Round 245, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 10.98
Round 246, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.50
Round 246, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.09
Round 247, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.51
Round 247, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.08
Round 248, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.55
Round 248, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.16
Round 249, Train loss: 2.303, Test loss: 2.302, Test accuracy: 11.59
Round 249, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.14
Round 250, Train loss: 2.301, Test loss: 2.302, Test accuracy: 11.62
Round 250, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.19
Round 251, Train loss: 2.300, Test loss: 2.301, Test accuracy: 11.65
Round 251, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 11.21
Round 252, Train loss: 2.301, Test loss: 2.301, Test accuracy: 11.67
Round 252, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.18
Round 253, Train loss: 2.302, Test loss: 2.301, Test accuracy: 11.77
Round 253, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.22
Round 254, Train loss: 2.301, Test loss: 2.301, Test accuracy: 11.75
Round 254, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.24
Round 255, Train loss: 2.301, Test loss: 2.301, Test accuracy: 11.80
Round 255, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.24
Round 256, Train loss: 2.304, Test loss: 2.301, Test accuracy: 11.85
Round 256, Global train loss: 2.304, Global test loss: 2.302, Global test accuracy: 11.30
Round 257, Train loss: 2.301, Test loss: 2.301, Test accuracy: 11.83
Round 257, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 11.33
Round 258, Train loss: 2.302, Test loss: 2.301, Test accuracy: 11.85
Round 258, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.29
Round 259, Train loss: 2.303, Test loss: 2.301, Test accuracy: 11.86
Round 259, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 11.37
Round 260, Train loss: 2.302, Test loss: 2.301, Test accuracy: 11.90
Round 260, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.40
Round 261, Train loss: 2.300, Test loss: 2.301, Test accuracy: 11.92
Round 261, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 11.41
Round 262, Train loss: 2.302, Test loss: 2.301, Test accuracy: 11.94
Round 262, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.33
Round 263, Train loss: 2.300, Test loss: 2.301, Test accuracy: 11.95
Round 263, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 11.32
Round 264, Train loss: 2.299, Test loss: 2.301, Test accuracy: 11.99
Round 264, Global train loss: 2.299, Global test loss: 2.302, Global test accuracy: 11.36
Round 265, Train loss: 2.299, Test loss: 2.301, Test accuracy: 11.96
Round 265, Global train loss: 2.299, Global test loss: 2.302, Global test accuracy: 11.31
Round 266, Train loss: 2.300, Test loss: 2.301, Test accuracy: 11.92
Round 266, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 11.34
Round 267, Train loss: 2.302, Test loss: 2.301, Test accuracy: 11.92
Round 267, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 11.30
Round 268, Train loss: 2.300, Test loss: 2.301, Test accuracy: 11.96
Round 268, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 11.29
Round 269, Train loss: 2.302, Test loss: 2.301, Test accuracy: 11.90
Round 269, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 11.30
Round 270, Train loss: 2.303, Test loss: 2.301, Test accuracy: 11.95
Round 270, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 11.35
Round 271, Train loss: 2.301, Test loss: 2.301, Test accuracy: 11.90
Round 271, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 11.32
Round 272, Train loss: 2.300, Test loss: 2.301, Test accuracy: 11.92
Round 272, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 11.35
Round 273, Train loss: 2.303, Test loss: 2.301, Test accuracy: 11.92
Round 273, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 11.39
Round 274, Train loss: 2.302, Test loss: 2.301, Test accuracy: 11.96
Round 274, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 11.45
Round 275, Train loss: 2.301, Test loss: 2.301, Test accuracy: 11.96
Round 275, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 11.44
Round 276, Train loss: 2.303, Test loss: 2.301, Test accuracy: 12.03
Round 276, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 11.46
Round 277, Train loss: 2.303, Test loss: 2.301, Test accuracy: 12.03
Round 277, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 11.54
Round 278, Train loss: 2.301, Test loss: 2.301, Test accuracy: 12.00
Round 278, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 11.53
Round 279, Train loss: 2.300, Test loss: 2.301, Test accuracy: 12.04
Round 279, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 11.51
Round 280, Train loss: 2.301, Test loss: 2.301, Test accuracy: 12.07
Round 280, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 11.52
Round 281, Train loss: 2.300, Test loss: 2.301, Test accuracy: 12.01
Round 281, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 11.52
Round 282, Train loss: 2.303, Test loss: 2.301, Test accuracy: 12.07
Round 282, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 11.54
Round 283, Train loss: 2.299, Test loss: 2.301, Test accuracy: 12.05
Round 283, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 11.54
Round 284, Train loss: 2.301, Test loss: 2.301, Test accuracy: 12.13
Round 284, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 11.58
Round 285, Train loss: 2.300, Test loss: 2.301, Test accuracy: 12.21
Round 285, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 11.59
Round 286, Train loss: 2.302, Test loss: 2.301, Test accuracy: 12.29
Round 286, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 11.78
Round 287, Train loss: 2.302, Test loss: 2.301, Test accuracy: 12.26
Round 287, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 11.77
Round 288, Train loss: 2.300, Test loss: 2.301, Test accuracy: 12.29
Round 288, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 11.78
Round 289, Train loss: 2.301, Test loss: 2.301, Test accuracy: 12.23
Round 289, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 11.80
Round 290, Train loss: 2.302, Test loss: 2.301, Test accuracy: 12.30
Round 290, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 11.80
Round 291, Train loss: 2.302, Test loss: 2.301, Test accuracy: 12.32
Round 291, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 11.78
Round 292, Train loss: 2.300, Test loss: 2.301, Test accuracy: 12.31
Round 292, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 11.89
Round 293, Train loss: 2.300, Test loss: 2.301, Test accuracy: 12.32
Round 293, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 11.90
Round 294, Train loss: 2.302, Test loss: 2.301, Test accuracy: 12.36
Round 294, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 11.93
Round 295, Train loss: 2.301, Test loss: 2.301, Test accuracy: 12.32
Round 295, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 11.92
Round 296, Train loss: 2.302, Test loss: 2.301, Test accuracy: 12.38
Round 296, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 11.93
Round 297, Train loss: 2.303, Test loss: 2.301, Test accuracy: 12.35
Round 297, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 12.01
Round 298, Train loss: 2.300, Test loss: 2.301, Test accuracy: 12.42
Round 298, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 11.92
Round 299, Train loss: 2.303, Test loss: 2.301, Test accuracy: 12.45
Round 299, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 12.04
Round 300, Train loss: 2.298, Test loss: 2.301, Test accuracy: 12.46
Round 300, Global train loss: 2.298, Global test loss: 2.301, Global test accuracy: 11.99
Round 301, Train loss: 2.302, Test loss: 2.301, Test accuracy: 12.50
Round 301, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 12.09
Round 302, Train loss: 2.303, Test loss: 2.301, Test accuracy: 12.54
Round 302, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 12.13
Round 303, Train loss: 2.300, Test loss: 2.301, Test accuracy: 12.55
Round 303, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 12.12
Round 304, Train loss: 2.303, Test loss: 2.301, Test accuracy: 12.59
Round 304, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 12.06
Round 305, Train loss: 2.302, Test loss: 2.301, Test accuracy: 12.57
Round 305, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 12.13
Round 306, Train loss: 2.300, Test loss: 2.301, Test accuracy: 12.58
Round 306, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 12.11
Round 307, Train loss: 2.303, Test loss: 2.301, Test accuracy: 12.62
Round 307, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 12.18
Round 308, Train loss: 2.301, Test loss: 2.301, Test accuracy: 12.70
Round 308, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.19
Round 309, Train loss: 2.300, Test loss: 2.301, Test accuracy: 12.79
Round 309, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 12.27
Round 310, Train loss: 2.303, Test loss: 2.301, Test accuracy: 12.79
Round 310, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 12.27
Round 311, Train loss: 2.299, Test loss: 2.301, Test accuracy: 12.80
Round 311, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 12.25
Round 312, Train loss: 2.300, Test loss: 2.301, Test accuracy: 12.86
Round 312, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 12.21
Round 313, Train loss: 2.301, Test loss: 2.301, Test accuracy: 12.87
Round 313, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.22
Round 314, Train loss: 2.303, Test loss: 2.301, Test accuracy: 12.89
Round 314, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 12.30
Round 315, Train loss: 2.303, Test loss: 2.301, Test accuracy: 12.89
Round 315, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 12.31
Round 316, Train loss: 2.301, Test loss: 2.301, Test accuracy: 12.94
Round 316, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.31
Round 317, Train loss: 2.301, Test loss: 2.301, Test accuracy: 12.94
Round 317, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.40
Round 318, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.03
Round 318, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.40
Round 319, Train loss: 2.303, Test loss: 2.301, Test accuracy: 13.02
Round 319, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 12.46
Round 320, Train loss: 2.303, Test loss: 2.301, Test accuracy: 13.03
Round 320, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 12.48
Round 321, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.01
Round 321, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 12.48
Round 322, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.02
Round 322, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 12.49
Round 323, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.07
Round 323, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 12.49
Round 324, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.09
Round 324, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 12.50
Round 325, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.05
Round 325, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.61
Round 326, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.05
Round 326, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 12.58
Round 327, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.06
Round 327, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 12.60
Round 328, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.07
Round 328, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.58
Round 329, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.10
Round 329, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 12.62
Round 330, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.08
Round 330, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.67
Round 331, Train loss: 2.303, Test loss: 2.301, Test accuracy: 13.17
Round 331, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 12.66
Round 332, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.16
Round 332, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 12.69
Round 333, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.26
Round 333, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 12.75
Round 334, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.24
Round 334, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.71
Round 335, Train loss: 2.299, Test loss: 2.301, Test accuracy: 13.26
Round 335, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 12.74
Round 336, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.28
Round 336, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.73
Round 337, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.33
Round 337, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.73
Round 338, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.44
Round 338, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.81
Round 339, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.36
Round 339, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 12.76
Round 340, Train loss: 2.303, Test loss: 2.301, Test accuracy: 13.27
Round 340, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 12.81
Round 341, Train loss: 2.304, Test loss: 2.301, Test accuracy: 13.34
Round 341, Global train loss: 2.304, Global test loss: 2.301, Global test accuracy: 12.79
Round 342, Train loss: 2.299, Test loss: 2.301, Test accuracy: 13.31
Round 342, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 12.83
Round 343, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.33
Round 343, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.88
Round 344, Train loss: 2.297, Test loss: 2.301, Test accuracy: 13.33
Round 344, Global train loss: 2.297, Global test loss: 2.301, Global test accuracy: 12.82
Round 345, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.40
Round 345, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.90
Round 346, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.31
Round 346, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 12.84
Round 347, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.32
Round 347, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.90
Round 348, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.36
Round 348, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.85
Round 349, Train loss: 2.304, Test loss: 2.301, Test accuracy: 13.44
Round 349, Global train loss: 2.304, Global test loss: 2.301, Global test accuracy: 12.91
Round 350, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.49
Round 350, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.92
Round 351, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.61
Round 351, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 12.93
Round 352, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.56
Round 352, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.97
Round 353, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.51
Round 353, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.95
Round 354, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.54
Round 354, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.03
Round 355, Train loss: 2.303, Test loss: 2.301, Test accuracy: 13.50
Round 355, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 13.08
Round 356, Train loss: 2.298, Test loss: 2.301, Test accuracy: 13.54
Round 356, Global train loss: 2.298, Global test loss: 2.301, Global test accuracy: 13.04
Round 357, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.50
Round 357, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.07
Round 358, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.46
Round 358, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.09
Round 359, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.38
Round 359, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.04
Round 360, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.40
Round 360, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.10
Round 361, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.49
Round 361, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.16
Round 362, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.61
Round 362, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.19
Round 363, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.60
Round 363, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.15
Round 364, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.58
Round 364, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.10
Round 365, Train loss: 2.303, Test loss: 2.301, Test accuracy: 13.62
Round 365, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 13.17
Round 366, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.62
Round 366, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.13
Round 367, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.66
Round 367, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.09
Round 368, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.74
Round 368, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.23
Round 369, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.77
Round 369, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.24
Round 370, Train loss: 2.298, Test loss: 2.301, Test accuracy: 13.71
Round 370, Global train loss: 2.298, Global test loss: 2.301, Global test accuracy: 13.23
Round 371, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.81
Round 371, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.23
Round 372, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.79
Round 372, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.21
Round 373, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.80
Round 373, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.29
Round 374, Train loss: 2.303, Test loss: 2.301, Test accuracy: 13.86
Round 374, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 13.28
Round 375, Train loss: 2.299, Test loss: 2.301, Test accuracy: 13.81
Round 375, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 13.32
Round 376, Train loss: 2.299, Test loss: 2.301, Test accuracy: 13.82
Round 376, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 13.27
Round 377, Train loss: 2.299, Test loss: 2.301, Test accuracy: 13.83
Round 377, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 13.30
Round 378, Train loss: 2.299, Test loss: 2.301, Test accuracy: 13.81
Round 378, Global train loss: 2.299, Global test loss: 2.301, Global test accuracy: 13.32
Round 379, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.86
Round 379, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.32
Round 380, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.96
Round 380, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.34
Round 381, Train loss: 2.300, Test loss: 2.301, Test accuracy: 13.97
Round 381, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.37
Round 382, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.99
Round 382, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.41
Round 383, Train loss: 2.303, Test loss: 2.301, Test accuracy: 14.00
Round 383, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 13.33
Round 384, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.00
Round 384, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.36
Round 385, Train loss: 2.301, Test loss: 2.301, Test accuracy: 13.98
Round 385, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.42
Round 386, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.00
Round 386, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.40
Round 387, Train loss: 2.302, Test loss: 2.301, Test accuracy: 13.97
Round 387, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.43
Round 388, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.11
Round 388, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.46
Round 389, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.10
Round 389, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.49
Round 390, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.00
Round 390, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.47
Round 391, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.07
Round 391, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.45
Round 392, Train loss: 2.303, Test loss: 2.301, Test accuracy: 14.08
Round 392, Global train loss: 2.303, Global test loss: 2.301, Global test accuracy: 13.45
Round 393, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.08
Round 393, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.42
Round 394, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.20
Round 394, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.43
Round 395, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.18
Round 395, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.55
Round 396, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.21
Round 396, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.54
Round 397, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.19
Round 397, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.46
Round 398, Train loss: 2.302, Test loss: 2.301, Test accuracy: 14.14
Round 398, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 13.46
Round 399, Train loss: 2.300, Test loss: 2.301, Test accuracy: 14.10
Round 399, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 13.46
Final Round, Train loss: 2.301, Test loss: 2.301, Test accuracy: 14.70
Final Round, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 13.46
Average accuracy final 10 rounds: 14.124999999999998 

Average global accuracy final 10 rounds: 13.469 

3881.8310110569
[0.9750156402587891, 1.8691558837890625, 2.7869837284088135, 3.5857717990875244, 4.404591083526611, 5.219532489776611, 6.010690689086914, 6.830414533615112, 7.619234800338745, 8.425501346588135, 9.241519689559937, 10.031292200088501, 10.849970817565918, 11.672527074813843, 12.47296690940857, 13.278184413909912, 14.072009801864624, 14.862521886825562, 15.69032335281372, 16.493528604507446, 17.296983242034912, 18.0971040725708, 18.89213752746582, 19.710954904556274, 20.518670797348022, 21.313082695007324, 22.098785161972046, 22.88848614692688, 23.706986665725708, 24.53522777557373, 25.336474895477295, 26.149434566497803, 26.960246562957764, 27.77145552635193, 28.596423387527466, 29.38586115837097, 30.17014980316162, 30.979578018188477, 31.78425145149231, 32.58856678009033, 33.385069847106934, 34.18689250946045, 35.005592823028564, 35.813692808151245, 36.60366702079773, 37.41090536117554, 38.214327573776245, 39.03889751434326, 39.85347557067871, 40.64833378791809, 41.45789647102356, 42.253708362579346, 43.05717873573303, 43.86729574203491, 44.67033886909485, 45.47485661506653, 46.28098130226135, 47.079490184783936, 47.90059995651245, 48.71021771430969, 49.500988483428955, 50.31060457229614, 51.11800837516785, 51.908461570739746, 52.71880626678467, 53.505159854888916, 54.33050847053528, 55.13772416114807, 55.940470457077026, 56.76981711387634, 57.57944297790527, 58.41044044494629, 59.227089405059814, 60.05425453186035, 60.86437797546387, 61.66667342185974, 62.495009899139404, 63.32502031326294, 64.14879250526428, 64.96591138839722, 65.95135712623596, 66.74957609176636, 67.58403372764587, 68.3966748714447, 69.4020836353302, 70.41499471664429, 71.42045283317566, 72.36413621902466, 73.3426296710968, 74.31864404678345, 75.31469559669495, 76.31599950790405, 77.3264548778534, 78.2785153388977, 79.27805948257446, 80.26070713996887, 81.20611143112183, 82.20104813575745, 83.17806720733643, 84.17100429534912, 85.1550555229187, 86.15120673179626, 87.15177464485168, 88.13256168365479, 89.09253668785095, 90.06081414222717, 91.02414751052856, 91.97247886657715, 92.95919632911682, 93.90746784210205, 94.85932350158691, 95.82937383651733, 96.75301623344421, 97.70579814910889, 98.67005157470703, 99.58893656730652, 100.41007494926453, 101.25568389892578, 102.21639347076416, 103.19799041748047, 103.99143290519714, 104.8128457069397, 105.62899613380432, 106.60768103599548, 107.4221351146698, 108.21794247627258, 109.03233361244202, 109.85346627235413, 110.63950300216675, 111.45783734321594, 112.443195104599, 113.26462960243225, 114.09594202041626, 114.9021246433258, 115.71485304832458, 116.51834297180176, 117.43681240081787, 118.25381898880005, 119.06655645370483, 119.88028764724731, 120.70271754264832, 121.59571433067322, 122.41600275039673, 123.30879211425781, 124.10453987121582, 124.91755747795105, 125.72322940826416, 126.53137874603271, 127.35699820518494, 128.16031193733215, 128.98977303504944, 129.806645154953, 130.71854877471924, 131.65960550308228, 132.58798742294312, 133.40429019927979, 134.21989798545837, 135.02589178085327, 135.97465538978577, 136.78314995765686, 137.75536513328552, 138.75432705879211, 139.6656575202942, 140.5872311592102, 141.58524680137634, 142.55396485328674, 143.5441722869873, 144.52360010147095, 145.48036193847656, 146.30029487609863, 147.25444722175598, 148.06535291671753, 148.88135838508606, 149.68381881713867, 150.48919582366943, 151.28333687782288, 152.0758125782013, 152.89159202575684, 153.7012870311737, 154.52299547195435, 155.34081435203552, 156.14235305786133, 156.96145510673523, 157.76481533050537, 158.57024550437927, 159.3924376964569, 160.19624042510986, 161.0141794681549, 161.83007884025574, 162.63418555259705, 163.45459413528442, 164.2566123008728, 165.0667107105255, 165.8838346004486, 166.68640208244324, 167.5038022994995, 168.32317662239075, 169.13325929641724, 169.95687866210938, 170.74746918678284, 171.55133295059204, 172.35958123207092, 173.15093874931335, 173.9528033733368, 174.7642936706543, 175.56043457984924, 176.36925864219666, 177.15971040725708, 177.96395874023438, 178.78097677230835, 179.58429312705994, 180.40116834640503, 181.19991898536682, 182.0034430027008, 182.81829857826233, 183.62821888923645, 184.42103815078735, 185.23156881332397, 186.03334760665894, 186.84605717658997, 187.6590974330902, 188.4652898311615, 189.26907086372375, 190.0866150856018, 190.882239818573, 191.69490933418274, 192.50273084640503, 193.31208777427673, 194.1199553012848, 194.92520475387573, 195.740234375, 196.5478219985962, 197.3544042110443, 198.1558220386505, 198.97699904441833, 199.7683665752411, 200.59047889709473, 201.39767837524414, 202.21096444129944, 203.02381873130798, 203.82940196990967, 204.64013504981995, 205.45314645767212, 206.27075839042664, 207.09310603141785, 207.88993668556213, 208.7103295326233, 209.53051280975342, 210.32544803619385, 211.14192247390747, 211.9402084350586, 212.75202631950378, 213.55698132514954, 214.36337780952454, 215.18252611160278, 216.0016393661499, 216.80265712738037, 217.61762738227844, 218.4090542793274, 219.21425032615662, 220.04011416435242, 220.86776614189148, 221.67959713935852, 222.48340320587158, 223.3206844329834, 224.1461217403412, 224.96892881393433, 225.7819309234619, 226.60937404632568, 227.44341278076172, 228.27638792991638, 229.1016025543213, 229.91463327407837, 230.7449598312378, 231.56390976905823, 232.37807774543762, 233.21189332008362, 234.03907370567322, 234.8597605228424, 235.68299531936646, 236.48129439353943, 237.30438709259033, 238.12317538261414, 238.91807103157043, 239.74094009399414, 240.56749057769775, 241.3858244419098, 242.18743252754211, 243.01220989227295, 243.83363556861877, 244.64823412895203, 245.4485628604889, 246.27933359146118, 247.11405968666077, 247.93515253067017, 248.73577857017517, 249.55199432373047, 250.3762912750244, 251.18196535110474, 251.95388221740723, 252.7756335735321, 253.59277391433716, 254.40199613571167, 255.19168972969055, 256.01845264434814, 256.83875918388367, 257.6499180793762, 258.43520855903625, 259.26839089393616, 260.1016798019409, 260.9253990650177, 261.73819303512573, 262.56936526298523, 263.38820362091064, 264.2035150527954, 264.9988281726837, 265.82119274139404, 266.64152669906616, 267.44469833374023, 268.2490756511688, 269.05889892578125, 269.88271617889404, 270.678923368454, 271.4920163154602, 272.30036449432373, 273.10846519470215, 273.90939593315125, 274.7439835071564, 275.57350850105286, 276.40469551086426, 277.2167181968689, 278.038010597229, 278.8633916378021, 279.6688952445984, 280.483393907547, 281.29416680336, 282.1243488788605, 282.9361045360565, 283.74540543556213, 284.5577335357666, 285.383239030838, 286.18661165237427, 287.00021600723267, 287.80182123184204, 288.6198661327362, 289.4389989376068, 290.2563304901123, 291.06929898262024, 291.84854435920715, 292.6337571144104, 293.42958903312683, 294.208945274353, 294.99301743507385, 295.779189825058, 296.5582330226898, 297.3459122180939, 298.13117241859436, 298.91078066825867, 299.7089054584503, 300.4961140155792, 301.27575039863586, 302.0575313568115, 302.8388388156891, 303.62445855140686, 304.406409740448, 305.19788122177124, 305.9779963493347, 306.75347685813904, 307.5278091430664, 308.3247437477112, 309.120121717453, 309.8908486366272, 310.6752052307129, 311.46761298179626, 312.2518627643585, 313.0450382232666, 313.82755637168884, 314.6076214313507, 315.3972382545471, 316.1850335597992, 316.9754340648651, 317.7511336803436, 318.5299389362335, 319.31778025627136, 320.0987207889557, 320.88995575904846, 321.63795280456543, 322.4221365451813, 323.20997524261475, 324.0036954879761, 324.7869520187378, 325.5627295970917, 326.36009430885315, 327.1498475074768, 327.94400453567505, 328.71987652778625, 329.49832916259766, 330.2844138145447, 331.08004570007324, 331.87352538108826, 333.4418089389801]/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

[7.88, 7.88, 7.9, 7.91, 7.95, 7.99, 8.03, 8.06, 8.12, 8.12, 8.13, 8.14, 8.17, 8.16, 8.15, 8.12, 8.13, 8.08, 8.12, 8.11, 8.16, 8.22, 8.31, 8.35, 8.32, 8.34, 8.37, 8.37, 8.33, 8.31, 8.29, 8.29, 8.31, 8.35, 8.48, 8.47, 8.5, 8.53, 8.56, 8.58, 8.59, 8.59, 8.57, 8.5, 8.52, 8.53, 8.57, 8.56, 8.56, 8.57, 8.64, 8.68, 8.67, 8.65, 8.68, 8.72, 8.65, 8.65, 8.66, 8.65, 8.68, 8.71, 8.7, 8.7, 8.7, 8.71, 8.7, 8.71, 8.73, 8.77, 8.81, 8.82, 8.87, 8.94, 8.86, 8.88, 8.87, 8.88, 8.95, 8.95, 8.89, 8.95, 8.96, 8.96, 8.93, 8.91, 8.94, 9.05, 9.06, 9.1, 9.18, 9.25, 9.2, 9.26, 9.28, 9.27, 9.3, 9.32, 9.33, 9.32, 9.35, 9.37, 9.27, 9.29, 9.31, 9.31, 9.36, 9.37, 9.38, 9.33, 9.38, 9.39, 9.39, 9.41, 9.44, 9.39, 9.45, 9.44, 9.43, 9.42, 9.43, 9.5, 9.47, 9.5, 9.47, 9.5, 9.54, 9.49, 9.53, 9.57, 9.63, 9.55, 9.6, 9.58, 9.7, 9.78, 9.77, 9.8, 9.8, 9.86, 9.89, 9.93, 10.01, 10.0, 10.0, 9.93, 9.92, 10.02, 10.02, 9.98, 10.02, 10.04, 10.11, 10.07, 10.11, 10.09, 10.09, 10.13, 10.13, 10.17, 10.17, 10.13, 10.16, 10.18, 10.2, 10.29, 10.22, 10.23, 10.27, 10.38, 10.47, 10.55, 10.55, 10.61, 10.61, 10.64, 10.68, 10.56, 10.57, 10.56, 10.57, 10.67, 10.63, 10.61, 10.62, 10.57, 10.6, 10.55, 10.54, 10.5, 10.56, 10.43, 10.47, 10.52, 10.53, 10.58, 10.57, 10.65, 10.72, 10.74, 10.76, 10.77, 10.78, 10.88, 10.88, 10.88, 10.9, 10.98, 11.01, 10.99, 11.0, 10.96, 10.92, 11.02, 11.05, 11.02, 11.03, 11.03, 11.08, 11.04, 11.02, 10.98, 11.05, 11.08, 11.1, 11.13, 11.19, 11.18, 11.19, 11.22, 11.25, 11.24, 11.29, 11.26, 11.33, 11.33, 11.33, 11.3, 11.4, 11.41, 11.4, 11.45, 11.47, 11.48, 11.49, 11.49, 11.5, 11.51, 11.55, 11.59, 11.62, 11.65, 11.67, 11.77, 11.75, 11.8, 11.85, 11.83, 11.85, 11.86, 11.9, 11.92, 11.94, 11.95, 11.99, 11.96, 11.92, 11.92, 11.96, 11.9, 11.95, 11.9, 11.92, 11.92, 11.96, 11.96, 12.03, 12.03, 12.0, 12.04, 12.07, 12.01, 12.07, 12.05, 12.13, 12.21, 12.29, 12.26, 12.29, 12.23, 12.3, 12.32, 12.31, 12.32, 12.36, 12.32, 12.38, 12.35, 12.42, 12.45, 12.46, 12.5, 12.54, 12.55, 12.59, 12.57, 12.58, 12.62, 12.7, 12.79, 12.79, 12.8, 12.86, 12.87, 12.89, 12.89, 12.94, 12.94, 13.03, 13.02, 13.03, 13.01, 13.02, 13.07, 13.09, 13.05, 13.05, 13.06, 13.07, 13.1, 13.08, 13.17, 13.16, 13.26, 13.24, 13.26, 13.28, 13.33, 13.44, 13.36, 13.27, 13.34, 13.31, 13.33, 13.33, 13.4, 13.31, 13.32, 13.36, 13.44, 13.49, 13.61, 13.56, 13.51, 13.54, 13.5, 13.54, 13.5, 13.46, 13.38, 13.4, 13.49, 13.61, 13.6, 13.58, 13.62, 13.62, 13.66, 13.74, 13.77, 13.71, 13.81, 13.79, 13.8, 13.86, 13.81, 13.82, 13.83, 13.81, 13.86, 13.96, 13.97, 13.99, 14.0, 14.0, 13.98, 14.0, 13.97, 14.11, 14.1, 14.0, 14.07, 14.08, 14.08, 14.2, 14.18, 14.21, 14.19, 14.14, 14.1, 14.7]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.316, Test loss: 2.302, Test accuracy: 11.36
Round   1, Train loss: 2.296, Test loss: 2.300, Test accuracy: 13.35
Round   2, Train loss: 2.289, Test loss: 2.296, Test accuracy: 17.07
Round   3, Train loss: 2.276, Test loss: 2.288, Test accuracy: 18.69
Round   4, Train loss: 2.240, Test loss: 2.270, Test accuracy: 20.17
Round   5, Train loss: 2.202, Test loss: 2.247, Test accuracy: 21.45
Round   6, Train loss: 2.165, Test loss: 2.222, Test accuracy: 23.35
Round   7, Train loss: 2.089, Test loss: 2.181, Test accuracy: 29.13
Round   8, Train loss: 2.056, Test loss: 2.144, Test accuracy: 33.53
Round   9, Train loss: 2.022, Test loss: 2.100, Test accuracy: 39.45
Round  10, Train loss: 1.988, Test loss: 2.061, Test accuracy: 44.74
Round  11, Train loss: 1.932, Test loss: 2.017, Test accuracy: 49.35
Round  12, Train loss: 1.931, Test loss: 1.984, Test accuracy: 52.73
Round  13, Train loss: 1.930, Test loss: 1.943, Test accuracy: 57.50
Round  14, Train loss: 1.912, Test loss: 1.931, Test accuracy: 58.99
Round  15, Train loss: 1.821, Test loss: 1.911, Test accuracy: 61.18
Round  16, Train loss: 1.812, Test loss: 1.897, Test accuracy: 61.96
Round  17, Train loss: 1.828, Test loss: 1.890, Test accuracy: 62.36
Round  18, Train loss: 1.807, Test loss: 1.860, Test accuracy: 65.64
Round  19, Train loss: 1.830, Test loss: 1.851, Test accuracy: 65.93
Round  20, Train loss: 1.819, Test loss: 1.836, Test accuracy: 68.56
Round  21, Train loss: 1.852, Test loss: 1.807, Test accuracy: 71.81
Round  22, Train loss: 1.705, Test loss: 1.791, Test accuracy: 72.54
Round  23, Train loss: 1.769, Test loss: 1.783, Test accuracy: 74.06
Round  24, Train loss: 1.719, Test loss: 1.783, Test accuracy: 74.04
Round  25, Train loss: 1.723, Test loss: 1.770, Test accuracy: 75.51
Round  26, Train loss: 1.793, Test loss: 1.774, Test accuracy: 75.69
Round  27, Train loss: 1.708, Test loss: 1.759, Test accuracy: 76.35
Round  28, Train loss: 1.724, Test loss: 1.749, Test accuracy: 77.21
Round  29, Train loss: 1.709, Test loss: 1.741, Test accuracy: 78.12
Round  30, Train loss: 1.716, Test loss: 1.730, Test accuracy: 78.26
Round  31, Train loss: 1.662, Test loss: 1.720, Test accuracy: 78.52
Round  32, Train loss: 1.706, Test loss: 1.722, Test accuracy: 78.63
Round  33, Train loss: 1.745, Test loss: 1.721, Test accuracy: 78.95
Round  34, Train loss: 1.612, Test loss: 1.715, Test accuracy: 79.22
Round  35, Train loss: 1.701, Test loss: 1.714, Test accuracy: 79.35
Round  36, Train loss: 1.739, Test loss: 1.709, Test accuracy: 79.77
Round  37, Train loss: 1.633, Test loss: 1.702, Test accuracy: 79.91
Round  38, Train loss: 1.695, Test loss: 1.702, Test accuracy: 80.28
Round  39, Train loss: 1.659, Test loss: 1.697, Test accuracy: 80.59
Round  40, Train loss: 1.629, Test loss: 1.694, Test accuracy: 80.50
Round  41, Train loss: 1.638, Test loss: 1.693, Test accuracy: 80.68
Round  42, Train loss: 1.681, Test loss: 1.693, Test accuracy: 80.74
Round  43, Train loss: 1.633, Test loss: 1.685, Test accuracy: 81.37
Round  44, Train loss: 1.670, Test loss: 1.685, Test accuracy: 81.35
Round  45, Train loss: 1.750, Test loss: 1.688, Test accuracy: 81.22
Round  46, Train loss: 1.616, Test loss: 1.685, Test accuracy: 81.22
Round  47, Train loss: 1.722, Test loss: 1.685, Test accuracy: 81.73
Round  48, Train loss: 1.666, Test loss: 1.683, Test accuracy: 81.67
Round  49, Train loss: 1.612, Test loss: 1.679, Test accuracy: 81.89
Round  50, Train loss: 1.619, Test loss: 1.674, Test accuracy: 81.92
Round  51, Train loss: 1.706, Test loss: 1.676, Test accuracy: 81.91
Round  52, Train loss: 1.633, Test loss: 1.676, Test accuracy: 81.96
Round  53, Train loss: 1.643, Test loss: 1.673, Test accuracy: 82.39
Round  54, Train loss: 1.652, Test loss: 1.667, Test accuracy: 82.51
Round  55, Train loss: 1.638, Test loss: 1.669, Test accuracy: 82.28
Round  56, Train loss: 1.722, Test loss: 1.678, Test accuracy: 82.20
Round  57, Train loss: 1.641, Test loss: 1.662, Test accuracy: 83.12
Round  58, Train loss: 1.646, Test loss: 1.658, Test accuracy: 83.26
Round  59, Train loss: 1.611, Test loss: 1.648, Test accuracy: 84.48
Round  60, Train loss: 1.554, Test loss: 1.641, Test accuracy: 84.52
Round  61, Train loss: 1.670, Test loss: 1.647, Test accuracy: 84.26
Round  62, Train loss: 1.571, Test loss: 1.642, Test accuracy: 84.52
Round  63, Train loss: 1.582, Test loss: 1.637, Test accuracy: 85.37
Round  64, Train loss: 1.667, Test loss: 1.645, Test accuracy: 85.05
Round  65, Train loss: 1.600, Test loss: 1.639, Test accuracy: 85.21
Round  66, Train loss: 1.573, Test loss: 1.638, Test accuracy: 85.27
Round  67, Train loss: 1.594, Test loss: 1.637, Test accuracy: 85.28
Round  68, Train loss: 1.605, Test loss: 1.639, Test accuracy: 85.25
Round  69, Train loss: 1.599, Test loss: 1.639, Test accuracy: 85.24
Round  70, Train loss: 1.636, Test loss: 1.638, Test accuracy: 85.18
Round  71, Train loss: 1.572, Test loss: 1.636, Test accuracy: 85.34
Round  72, Train loss: 1.657, Test loss: 1.640, Test accuracy: 85.39
Round  73, Train loss: 1.540, Test loss: 1.632, Test accuracy: 85.66
Round  74, Train loss: 1.562, Test loss: 1.630, Test accuracy: 85.65
Round  75, Train loss: 1.592, Test loss: 1.633, Test accuracy: 85.60
Round  76, Train loss: 1.595, Test loss: 1.632, Test accuracy: 85.60
Round  77, Train loss: 1.623, Test loss: 1.632, Test accuracy: 85.51
Round  78, Train loss: 1.688, Test loss: 1.638, Test accuracy: 85.41
Round  79, Train loss: 1.601, Test loss: 1.632, Test accuracy: 85.74
Round  80, Train loss: 1.623, Test loss: 1.629, Test accuracy: 85.75
Round  81, Train loss: 1.681, Test loss: 1.635, Test accuracy: 85.63
Round  82, Train loss: 1.572, Test loss: 1.630, Test accuracy: 85.63
Round  83, Train loss: 1.617, Test loss: 1.629, Test accuracy: 85.65
Round  84, Train loss: 1.627, Test loss: 1.635, Test accuracy: 85.51
Round  85, Train loss: 1.592, Test loss: 1.627, Test accuracy: 85.75
Round  86, Train loss: 1.558, Test loss: 1.624, Test accuracy: 85.87
Round  87, Train loss: 1.586, Test loss: 1.627, Test accuracy: 85.71
Round  88, Train loss: 1.616, Test loss: 1.628, Test accuracy: 85.72
Round  89, Train loss: 1.559, Test loss: 1.626, Test accuracy: 85.79
Round  90, Train loss: 1.523, Test loss: 1.622, Test accuracy: 85.78
Round  91, Train loss: 1.588, Test loss: 1.626, Test accuracy: 85.87
Round  92, Train loss: 1.635, Test loss: 1.623, Test accuracy: 86.74
Round  93, Train loss: 1.555, Test loss: 1.619, Test accuracy: 86.62
Round  94, Train loss: 1.555, Test loss: 1.621, Test accuracy: 86.67/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  95, Train loss: 1.685, Test loss: 1.627, Test accuracy: 86.52
Round  96, Train loss: 1.589, Test loss: 1.622, Test accuracy: 86.73
Round  97, Train loss: 1.661, Test loss: 1.626, Test accuracy: 86.64
Round  98, Train loss: 1.619, Test loss: 1.627, Test accuracy: 86.51
Round  99, Train loss: 1.591, Test loss: 1.620, Test accuracy: 86.76
Final Round, Train loss: 1.577, Test loss: 1.611, Test accuracy: 86.89
Average accuracy final 10 rounds: 86.484
848.552572965622
[1.1182141304016113, 2.136176347732544, 3.135390520095825, 4.163943290710449, 5.206979036331177, 6.228381156921387, 7.241728067398071, 8.262003421783447, 9.275404453277588, 10.304370880126953, 11.318572998046875, 12.345810174942017, 13.34209394454956, 14.341888189315796, 15.35617733001709, 16.341788053512573, 17.348715782165527, 18.374809980392456, 19.39536690711975, 20.391036987304688, 21.372913360595703, 22.379775524139404, 23.37636637687683, 24.37475299835205, 25.397935390472412, 26.42632484436035, 27.446523189544678, 28.45352578163147, 29.476916313171387, 30.481197357177734, 31.50727152824402, 32.51639938354492, 33.54934620857239, 34.566298961639404, 35.58331751823425, 36.619818925857544, 37.61729335784912, 38.61744475364685, 39.64131021499634, 40.658804178237915, 41.64569807052612, 42.62589883804321, 43.643245458602905, 44.63593029975891, 45.66420006752014, 46.69232201576233, 47.70111036300659, 48.69964146614075, 49.7192862033844, 50.746028661727905, 51.743255376815796, 52.74808120727539, 53.77961874008179, 54.80061721801758, 55.81985020637512, 56.837695360183716, 57.86625051498413, 58.878496408462524, 59.90517210960388, 60.93083429336548, 61.944191694259644, 62.93964385986328, 63.96394658088684, 64.98962259292603, 65.99083614349365, 67.00323414802551, 68.012033700943, 69.03334307670593, 70.02953219413757, 71.0470278263092, 72.03222060203552, 73.02393960952759, 74.03137373924255, 75.0580644607544, 76.07883906364441, 77.0744161605835, 78.08951902389526, 79.09659433364868, 80.0741400718689, 81.04489541053772, 82.06325554847717, 83.07731246948242, 84.09465837478638, 85.11115384101868, 86.12146711349487, 87.10448813438416, 88.11266899108887, 89.10995197296143, 90.06117296218872, 91.01406335830688, 92.03932881355286, 93.06244421005249, 94.05454993247986, 95.07582139968872, 96.08746099472046, 97.08877158164978, 98.10272741317749, 99.11086440086365, 100.12204575538635, 101.1206316947937, 102.61802792549133]
[11.36, 13.35, 17.07, 18.69, 20.17, 21.45, 23.35, 29.13, 33.53, 39.45, 44.74, 49.35, 52.73, 57.5, 58.99, 61.18, 61.96, 62.36, 65.64, 65.93, 68.56, 71.81, 72.54, 74.06, 74.04, 75.51, 75.69, 76.35, 77.21, 78.12, 78.26, 78.52, 78.63, 78.95, 79.22, 79.35, 79.77, 79.91, 80.28, 80.59, 80.5, 80.68, 80.74, 81.37, 81.35, 81.22, 81.22, 81.73, 81.67, 81.89, 81.92, 81.91, 81.96, 82.39, 82.51, 82.28, 82.2, 83.12, 83.26, 84.48, 84.52, 84.26, 84.52, 85.37, 85.05, 85.21, 85.27, 85.28, 85.25, 85.24, 85.18, 85.34, 85.39, 85.66, 85.65, 85.6, 85.6, 85.51, 85.41, 85.74, 85.75, 85.63, 85.63, 85.65, 85.51, 85.75, 85.87, 85.71, 85.72, 85.79, 85.78, 85.87, 86.74, 86.62, 86.67, 86.52, 86.73, 86.64, 86.51, 86.76, 86.89]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC-K-Means%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 1, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
401408
401920
532992
533248
549632
549696
550336
550346
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.315, Test loss: 2.301, Test accuracy: 13.09
Round   1, Train loss: 2.301, Test loss: 2.299, Test accuracy: 14.96
Round   2, Train loss: 2.270, Test loss: 2.290, Test accuracy: 13.67
Round   3, Train loss: 2.238, Test loss: 2.269, Test accuracy: 21.06
Round   4, Train loss: 2.171, Test loss: 2.247, Test accuracy: 20.05
Round   5, Train loss: 2.177, Test loss: 2.221, Test accuracy: 24.91
Round   6, Train loss: 2.149, Test loss: 2.192, Test accuracy: 28.44
Round   7, Train loss: 2.113, Test loss: 2.155, Test accuracy: 35.92
Round   8, Train loss: 2.077, Test loss: 2.114, Test accuracy: 40.08
Round   9, Train loss: 2.013, Test loss: 2.075, Test accuracy: 42.91
Round  10, Train loss: 2.013, Test loss: 2.031, Test accuracy: 49.29
Round  11, Train loss: 1.917, Test loss: 1.998, Test accuracy: 51.61
Round  12, Train loss: 1.884, Test loss: 1.970, Test accuracy: 55.08
Round  13, Train loss: 1.937, Test loss: 1.963, Test accuracy: 56.37
Round  14, Train loss: 1.908, Test loss: 1.938, Test accuracy: 59.23
Round  15, Train loss: 1.905, Test loss: 1.913, Test accuracy: 60.79
Round  16, Train loss: 1.889, Test loss: 1.903, Test accuracy: 62.31
Round  17, Train loss: 1.913, Test loss: 1.890, Test accuracy: 64.17
Round  18, Train loss: 1.783, Test loss: 1.857, Test accuracy: 67.18
Round  19, Train loss: 1.790, Test loss: 1.833, Test accuracy: 68.88
Round  20, Train loss: 1.780, Test loss: 1.812, Test accuracy: 70.74
Round  21, Train loss: 1.744, Test loss: 1.800, Test accuracy: 72.23
Round  22, Train loss: 1.772, Test loss: 1.794, Test accuracy: 73.56
Round  23, Train loss: 1.730, Test loss: 1.764, Test accuracy: 76.12
Round  24, Train loss: 1.719, Test loss: 1.771, Test accuracy: 76.29
Round  25, Train loss: 1.684, Test loss: 1.749, Test accuracy: 77.11
Round  26, Train loss: 1.701, Test loss: 1.746, Test accuracy: 76.95
Round  27, Train loss: 1.703, Test loss: 1.747, Test accuracy: 76.99
Round  28, Train loss: 1.719, Test loss: 1.741, Test accuracy: 77.82
Round  29, Train loss: 1.741, Test loss: 1.730, Test accuracy: 78.42
Round  30, Train loss: 1.698, Test loss: 1.712, Test accuracy: 80.12
Round  31, Train loss: 1.696, Test loss: 1.707, Test accuracy: 80.18
Round  32, Train loss: 1.696, Test loss: 1.710, Test accuracy: 80.38
Round  33, Train loss: 1.673, Test loss: 1.693, Test accuracy: 81.83
Round  34, Train loss: 1.668, Test loss: 1.686, Test accuracy: 82.58
Round  35, Train loss: 1.679, Test loss: 1.681, Test accuracy: 83.54
Round  36, Train loss: 1.684, Test loss: 1.684, Test accuracy: 83.36
Round  37, Train loss: 1.668, Test loss: 1.674, Test accuracy: 83.92
Round  38, Train loss: 1.687, Test loss: 1.669, Test accuracy: 84.20
Round  39, Train loss: 1.618, Test loss: 1.663, Test accuracy: 85.10
Round  40, Train loss: 1.559, Test loss: 1.659, Test accuracy: 85.08
Round  41, Train loss: 1.601, Test loss: 1.656, Test accuracy: 85.30
Round  42, Train loss: 1.597, Test loss: 1.658, Test accuracy: 85.30
Round  43, Train loss: 1.652, Test loss: 1.652, Test accuracy: 85.21
Round  44, Train loss: 1.613, Test loss: 1.645, Test accuracy: 86.30
Round  45, Train loss: 1.571, Test loss: 1.641, Test accuracy: 86.21
Round  46, Train loss: 1.571, Test loss: 1.637, Test accuracy: 86.45
Round  47, Train loss: 1.650, Test loss: 1.639, Test accuracy: 86.37
Round  48, Train loss: 1.656, Test loss: 1.643, Test accuracy: 86.29
Round  49, Train loss: 1.581, Test loss: 1.633, Test accuracy: 87.12
Round  50, Train loss: 1.631, Test loss: 1.633, Test accuracy: 86.93
Round  51, Train loss: 1.632, Test loss: 1.631, Test accuracy: 87.04
Round  52, Train loss: 1.647, Test loss: 1.635, Test accuracy: 86.80
Round  53, Train loss: 1.534, Test loss: 1.626, Test accuracy: 87.20
Round  54, Train loss: 1.628, Test loss: 1.624, Test accuracy: 87.49
Round  55, Train loss: 1.582, Test loss: 1.624, Test accuracy: 87.65
Round  56, Train loss: 1.641, Test loss: 1.629, Test accuracy: 87.53
Round  57, Train loss: 1.709, Test loss: 1.630, Test accuracy: 87.48
Round  58, Train loss: 1.615, Test loss: 1.624, Test accuracy: 87.68
Round  59, Train loss: 1.616, Test loss: 1.621, Test accuracy: 87.71
Round  60, Train loss: 1.600, Test loss: 1.618, Test accuracy: 87.58
Round  61, Train loss: 1.548, Test loss: 1.615, Test accuracy: 87.67
Round  62, Train loss: 1.527, Test loss: 1.608, Test accuracy: 88.67
Round  63, Train loss: 1.633, Test loss: 1.611, Test accuracy: 88.64
Round  64, Train loss: 1.568, Test loss: 1.605, Test accuracy: 88.97
Round  65, Train loss: 1.611, Test loss: 1.607, Test accuracy: 88.81
Round  66, Train loss: 1.605, Test loss: 1.609, Test accuracy: 88.82
Round  67, Train loss: 1.620, Test loss: 1.601, Test accuracy: 89.57
Round  68, Train loss: 1.571, Test loss: 1.601, Test accuracy: 89.68
Round  69, Train loss: 1.602, Test loss: 1.603, Test accuracy: 89.56
Round  70, Train loss: 1.546, Test loss: 1.599, Test accuracy: 89.65
Round  71, Train loss: 1.543, Test loss: 1.597, Test accuracy: 89.75
Round  72, Train loss: 1.538, Test loss: 1.594, Test accuracy: 89.84
Round  73, Train loss: 1.574, Test loss: 1.593, Test accuracy: 89.92
Round  74, Train loss: 1.579, Test loss: 1.590, Test accuracy: 90.61
Round  75, Train loss: 1.548, Test loss: 1.586, Test accuracy: 90.73
Round  76, Train loss: 1.568, Test loss: 1.589, Test accuracy: 90.59
Round  77, Train loss: 1.541, Test loss: 1.585, Test accuracy: 90.82
Round  78, Train loss: 1.564, Test loss: 1.586, Test accuracy: 90.68
Round  79, Train loss: 1.580, Test loss: 1.582, Test accuracy: 91.20
Round  80, Train loss: 1.541, Test loss: 1.582, Test accuracy: 91.25
Round  81, Train loss: 1.600, Test loss: 1.582, Test accuracy: 91.11
Round  82, Train loss: 1.520, Test loss: 1.574, Test accuracy: 91.59
Round  83, Train loss: 1.549, Test loss: 1.571, Test accuracy: 91.65
Round  84, Train loss: 1.526, Test loss: 1.568, Test accuracy: 92.04
Round  85, Train loss: 1.547, Test loss: 1.564, Test accuracy: 92.82
Round  86, Train loss: 1.501, Test loss: 1.565, Test accuracy: 92.77
Round  87, Train loss: 1.513, Test loss: 1.562, Test accuracy: 92.69
Round  88, Train loss: 1.574, Test loss: 1.563, Test accuracy: 92.83
Round  89, Train loss: 1.566, Test loss: 1.563, Test accuracy: 92.92
Round  90, Train loss: 1.563, Test loss: 1.564, Test accuracy: 92.72
Round  91, Train loss: 1.568, Test loss: 1.564, Test accuracy: 92.89
Round  92, Train loss: 1.505, Test loss: 1.558, Test accuracy: 93.02
Round  93, Train loss: 1.500, Test loss: 1.560, Test accuracy: 92.86/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Train loss: 1.508, Test loss: 1.559, Test accuracy: 92.84
Round  95, Train loss: 1.558, Test loss: 1.561, Test accuracy: 92.77
Round  96, Train loss: 1.533, Test loss: 1.559, Test accuracy: 92.92
Round  97, Train loss: 1.497, Test loss: 1.558, Test accuracy: 92.88
Round  98, Train loss: 1.528, Test loss: 1.558, Test accuracy: 92.93
Round  99, Train loss: 1.527, Test loss: 1.558, Test accuracy: 92.83
Final Round, Train loss: 1.512, Test loss: 1.540, Test accuracy: 94.59
Average accuracy final 10 rounds: 92.866
981.4910106658936
[1.0836660861968994, 2.167332172393799, 3.123673439025879, 4.080014705657959, 4.97744345664978, 5.874872207641602, 6.800286293029785, 7.725700378417969, 8.587482929229736, 9.449265480041504, 10.28662919998169, 11.123992919921875, 11.989686250686646, 12.855379581451416, 13.723166942596436, 14.590954303741455, 15.458310842514038, 16.32566738128662, 17.192747354507446, 18.05982732772827, 18.895514965057373, 19.731202602386475, 20.573683977127075, 21.416165351867676, 22.28261137008667, 23.149057388305664, 24.00888156890869, 24.86870574951172, 25.73256492614746, 26.596424102783203, 27.45498013496399, 28.313536167144775, 29.17284607887268, 30.032155990600586, 30.89571714401245, 31.759278297424316, 32.6258544921875, 33.492430686950684, 34.343056201934814, 35.193681716918945, 36.05814790725708, 36.922614097595215, 37.775869607925415, 38.629125118255615, 39.495529651641846, 40.361934185028076, 41.224366903305054, 42.08679962158203, 42.95183706283569, 43.816874504089355, 44.67835450172424, 45.53983449935913, 46.39699983596802, 47.254165172576904, 48.10032033920288, 48.94647550582886, 49.7893283367157, 50.63218116760254, 51.49773335456848, 52.363285541534424, 53.23002576828003, 54.096765995025635, 54.95405149459839, 55.81133699417114, 56.66892671585083, 57.52651643753052, 58.38594365119934, 59.245370864868164, 60.11531138420105, 60.985251903533936, 61.84518504142761, 62.70511817932129, 63.56125044822693, 64.41738271713257, 65.27610182762146, 66.13482093811035, 66.9800751209259, 67.82532930374146, 68.68400740623474, 69.54268550872803, 70.40297889709473, 71.26327228546143, 72.12526369094849, 72.98725509643555, 73.85191535949707, 74.7165756225586, 75.57503414154053, 76.43349266052246, 77.28352570533752, 78.13355875015259, 78.98277640342712, 79.83199405670166, 80.69061017036438, 81.5492262840271, 82.41301727294922, 83.27680826187134, 84.14074110984802, 85.0046739578247, 85.8471999168396, 86.68972587585449, 87.52705574035645, 88.3643856048584, 89.21608257293701, 90.06777954101562, 90.92637729644775, 91.78497505187988, 92.64452075958252, 93.50406646728516, 94.34916234016418, 95.19425821304321, 96.05310106277466, 96.9119439125061, 97.76601457595825, 98.6200852394104, 99.47715258598328, 100.33421993255615, 101.19337272644043, 102.0525255203247, 102.90725517272949, 103.76198482513428, 104.61908173561096, 105.47617864608765, 106.31215071678162, 107.14812278747559, 107.982666015625, 108.81720924377441, 109.67188310623169, 110.52655696868896, 111.37931847572327, 112.23207998275757, 113.08567142486572, 113.93926286697388, 114.79118514060974, 115.6431074142456, 116.48782515525818, 117.33254289627075, 118.19366478919983, 119.0547866821289, 119.92208194732666, 120.78937721252441, 121.64551973342896, 122.5016622543335, 123.36640739440918, 124.23115253448486, 125.09747195243835, 125.96379137039185, 126.8219039440155, 127.68001651763916, 128.5472800731659, 129.41454362869263, 130.27812147140503, 131.14169931411743, 132.00518608093262, 132.8686728477478, 133.72819137573242, 134.58770990371704, 135.42799758911133, 136.26828527450562, 137.10847997665405, 137.9486746788025, 138.81004428863525, 139.67141389846802, 140.5333058834076, 141.39519786834717, 142.25313758850098, 143.11107730865479, 143.96666169166565, 144.8222460746765, 145.66562819480896, 146.5090103149414, 147.32284688949585, 148.1366834640503, 148.95147347450256, 149.76626348495483, 150.60206484794617, 151.4378662109375, 152.26922464370728, 153.10058307647705, 153.93816113471985, 154.77573919296265, 155.61153435707092, 156.4473295211792, 157.28416061401367, 158.12099170684814, 158.9632556438446, 159.80551958084106, 160.64288425445557, 161.48024892807007, 162.2883961200714, 163.09654331207275, 163.91409730911255, 164.73165130615234, 165.5608344078064, 166.39001750946045, 167.219176530838, 168.04833555221558, 168.87465167045593, 169.7009677886963, 170.52112746238708, 171.34128713607788, 172.66712617874146, 173.99296522140503]
[13.09, 13.09, 14.96, 14.96, 13.67, 13.67, 21.06, 21.06, 20.05, 20.05, 24.91, 24.91, 28.44, 28.44, 35.92, 35.92, 40.08, 40.08, 42.91, 42.91, 49.29, 49.29, 51.61, 51.61, 55.08, 55.08, 56.37, 56.37, 59.23, 59.23, 60.79, 60.79, 62.31, 62.31, 64.17, 64.17, 67.18, 67.18, 68.88, 68.88, 70.74, 70.74, 72.23, 72.23, 73.56, 73.56, 76.12, 76.12, 76.29, 76.29, 77.11, 77.11, 76.95, 76.95, 76.99, 76.99, 77.82, 77.82, 78.42, 78.42, 80.12, 80.12, 80.18, 80.18, 80.38, 80.38, 81.83, 81.83, 82.58, 82.58, 83.54, 83.54, 83.36, 83.36, 83.92, 83.92, 84.2, 84.2, 85.1, 85.1, 85.08, 85.08, 85.3, 85.3, 85.3, 85.3, 85.21, 85.21, 86.3, 86.3, 86.21, 86.21, 86.45, 86.45, 86.37, 86.37, 86.29, 86.29, 87.12, 87.12, 86.93, 86.93, 87.04, 87.04, 86.8, 86.8, 87.2, 87.2, 87.49, 87.49, 87.65, 87.65, 87.53, 87.53, 87.48, 87.48, 87.68, 87.68, 87.71, 87.71, 87.58, 87.58, 87.67, 87.67, 88.67, 88.67, 88.64, 88.64, 88.97, 88.97, 88.81, 88.81, 88.82, 88.82, 89.57, 89.57, 89.68, 89.68, 89.56, 89.56, 89.65, 89.65, 89.75, 89.75, 89.84, 89.84, 89.92, 89.92, 90.61, 90.61, 90.73, 90.73, 90.59, 90.59, 90.82, 90.82, 90.68, 90.68, 91.2, 91.2, 91.25, 91.25, 91.11, 91.11, 91.59, 91.59, 91.65, 91.65, 92.04, 92.04, 92.82, 92.82, 92.77, 92.77, 92.69, 92.69, 92.83, 92.83, 92.92, 92.92, 92.72, 92.72, 92.89, 92.89, 93.02, 93.02, 92.86, 92.86, 92.84, 92.84, 92.77, 92.77, 92.92, 92.92, 92.88, 92.88, 92.93, 92.93, 92.83, 92.83, 94.59, 94.59]
