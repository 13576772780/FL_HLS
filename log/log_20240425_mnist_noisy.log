nohup: ignoring input
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.4  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.589, Test loss: 1.551, Test accuracy: 57.92
Round   0, Global train loss: 1.589, Global test loss: 1.552, Global test accuracy: 57.30
Round   1, Train loss: 1.267, Test loss: 1.131, Test accuracy: 85.74
Round   1, Global train loss: 1.267, Global test loss: 1.025, Global test accuracy: 94.32
Round   2, Train loss: 0.972, Test loss: 1.096, Test accuracy: 86.38
Round   2, Global train loss: 0.972, Global test loss: 0.972, Global test accuracy: 95.14
Round   3, Train loss: 1.168, Test loss: 1.006, Test accuracy: 93.68
Round   3, Global train loss: 1.168, Global test loss: 1.004, Global test accuracy: 94.04
Round   4, Train loss: 0.961, Test loss: 0.980, Test accuracy: 95.10
Round   4, Global train loss: 0.961, Global test loss: 0.959, Global test accuracy: 95.98
Round   5, Train loss: 0.950, Test loss: 0.973, Test accuracy: 95.08
Round   5, Global train loss: 0.950, Global test loss: 0.958, Global test accuracy: 95.98
Round   6, Train loss: 0.948, Test loss: 0.963, Test accuracy: 95.34
Round   6, Global train loss: 0.948, Global test loss: 0.958, Global test accuracy: 95.74
Round   7, Train loss: 0.939, Test loss: 0.960, Test accuracy: 95.54
Round   7, Global train loss: 0.939, Global test loss: 0.952, Global test accuracy: 95.88
Round   8, Train loss: 0.930, Test loss: 0.959, Test accuracy: 95.48
Round   8, Global train loss: 0.930, Global test loss: 0.953, Global test accuracy: 96.04
Round   9, Train loss: 0.934, Test loss: 0.958, Test accuracy: 95.56
Round   9, Global train loss: 0.934, Global test loss: 0.949, Global test accuracy: 96.20
Round  10, Train loss: 0.928, Test loss: 0.957, Test accuracy: 95.44
Round  10, Global train loss: 0.928, Global test loss: 0.949, Global test accuracy: 96.22
Round  11, Train loss: 0.922, Test loss: 0.955, Test accuracy: 95.60
Round  11, Global train loss: 0.922, Global test loss: 0.944, Global test accuracy: 96.40
Round  12, Train loss: 0.939, Test loss: 0.957, Test accuracy: 95.40
Round  12, Global train loss: 0.939, Global test loss: 0.944, Global test accuracy: 96.60
Round  13, Train loss: 0.921, Test loss: 0.956, Test accuracy: 95.48
Round  13, Global train loss: 0.921, Global test loss: 0.951, Global test accuracy: 95.94
Round  14, Train loss: 0.920, Test loss: 0.956, Test accuracy: 95.48
Round  14, Global train loss: 0.920, Global test loss: 0.949, Global test accuracy: 95.84
Round  15, Train loss: 0.926, Test loss: 0.955, Test accuracy: 95.58
Round  15, Global train loss: 0.926, Global test loss: 0.945, Global test accuracy: 96.48
Round  16, Train loss: 0.924, Test loss: 0.955, Test accuracy: 95.66
Round  16, Global train loss: 0.924, Global test loss: 0.946, Global test accuracy: 96.48
Round  17, Train loss: 0.917, Test loss: 0.954, Test accuracy: 95.56
Round  17, Global train loss: 0.917, Global test loss: 0.944, Global test accuracy: 96.34
Round  18, Train loss: 0.922, Test loss: 0.954, Test accuracy: 95.54
Round  18, Global train loss: 0.922, Global test loss: 0.945, Global test accuracy: 96.44
Round  19, Train loss: 0.915, Test loss: 0.954, Test accuracy: 95.50
Round  19, Global train loss: 0.915, Global test loss: 0.946, Global test accuracy: 96.24
Round  20, Train loss: 0.917, Test loss: 0.954, Test accuracy: 95.54
Round  20, Global train loss: 0.917, Global test loss: 0.945, Global test accuracy: 96.56
Round  21, Train loss: 0.916, Test loss: 0.954, Test accuracy: 95.48
Round  21, Global train loss: 0.916, Global test loss: 0.945, Global test accuracy: 96.46
Round  22, Train loss: 0.920, Test loss: 0.954, Test accuracy: 95.42
Round  22, Global train loss: 0.920, Global test loss: 0.943, Global test accuracy: 96.64
Round  23, Train loss: 0.916, Test loss: 0.954, Test accuracy: 95.40
Round  23, Global train loss: 0.916, Global test loss: 0.940, Global test accuracy: 96.78
Round  24, Train loss: 0.913, Test loss: 0.954, Test accuracy: 95.34
Round  24, Global train loss: 0.913, Global test loss: 0.946, Global test accuracy: 96.12
Round  25, Train loss: 0.916, Test loss: 0.954, Test accuracy: 95.28
Round  25, Global train loss: 0.916, Global test loss: 0.944, Global test accuracy: 96.28
Round  26, Train loss: 0.916, Test loss: 0.954, Test accuracy: 95.26
Round  26, Global train loss: 0.916, Global test loss: 0.949, Global test accuracy: 95.82
Round  27, Train loss: 0.912, Test loss: 0.954, Test accuracy: 95.30
Round  27, Global train loss: 0.912, Global test loss: 0.943, Global test accuracy: 96.46
Round  28, Train loss: 0.918, Test loss: 0.953, Test accuracy: 95.36
Round  28, Global train loss: 0.918, Global test loss: 0.940, Global test accuracy: 96.76
Round  29, Train loss: 0.913, Test loss: 0.953, Test accuracy: 95.40
Round  29, Global train loss: 0.913, Global test loss: 0.943, Global test accuracy: 96.40
Round  30, Train loss: 0.912, Test loss: 0.953, Test accuracy: 95.36
Round  30, Global train loss: 0.912, Global test loss: 0.941, Global test accuracy: 96.70
Round  31, Train loss: 0.915, Test loss: 0.953, Test accuracy: 95.38
Round  31, Global train loss: 0.915, Global test loss: 0.946, Global test accuracy: 95.98
Round  32, Train loss: 0.913, Test loss: 0.953, Test accuracy: 95.40
Round  32, Global train loss: 0.913, Global test loss: 0.943, Global test accuracy: 96.46
Round  33, Train loss: 0.914, Test loss: 0.953, Test accuracy: 95.38
Round  33, Global train loss: 0.914, Global test loss: 0.941, Global test accuracy: 96.62
Round  34, Train loss: 0.916, Test loss: 0.953, Test accuracy: 95.40
Round  34, Global train loss: 0.916, Global test loss: 0.944, Global test accuracy: 96.46
Round  35, Train loss: 0.911, Test loss: 0.953, Test accuracy: 95.40
Round  35, Global train loss: 0.911, Global test loss: 0.943, Global test accuracy: 96.42
Round  36, Train loss: 0.914, Test loss: 0.953, Test accuracy: 95.38
Round  36, Global train loss: 0.914, Global test loss: 0.941, Global test accuracy: 96.74
Round  37, Train loss: 0.918, Test loss: 0.953, Test accuracy: 95.34
Round  37, Global train loss: 0.918, Global test loss: 0.948, Global test accuracy: 95.96
Round  38, Train loss: 0.913, Test loss: 0.953, Test accuracy: 95.34
Round  38, Global train loss: 0.913, Global test loss: 0.939, Global test accuracy: 96.58
Round  39, Train loss: 0.909, Test loss: 0.953, Test accuracy: 95.40
Round  39, Global train loss: 0.909, Global test loss: 0.943, Global test accuracy: 96.32
Round  40, Train loss: 0.913, Test loss: 0.953, Test accuracy: 95.38
Round  40, Global train loss: 0.913, Global test loss: 0.945, Global test accuracy: 96.26
Round  41, Train loss: 0.911, Test loss: 0.953, Test accuracy: 95.38
Round  41, Global train loss: 0.911, Global test loss: 0.941, Global test accuracy: 96.70
Round  42, Train loss: 0.913, Test loss: 0.953, Test accuracy: 95.38
Round  42, Global train loss: 0.913, Global test loss: 0.946, Global test accuracy: 96.16
Round  43, Train loss: 0.914, Test loss: 0.953, Test accuracy: 95.38
Round  43, Global train loss: 0.914, Global test loss: 0.944, Global test accuracy: 96.36
Round  44, Train loss: 0.917, Test loss: 0.953, Test accuracy: 95.38
Round  44, Global train loss: 0.917, Global test loss: 0.941, Global test accuracy: 96.58
Round  45, Train loss: 0.908, Test loss: 0.953, Test accuracy: 95.34
Round  45, Global train loss: 0.908, Global test loss: 0.943, Global test accuracy: 96.34
Round  46, Train loss: 0.915, Test loss: 0.953, Test accuracy: 95.38
Round  46, Global train loss: 0.915, Global test loss: 0.943, Global test accuracy: 96.18
Round  47, Train loss: 0.916, Test loss: 0.953, Test accuracy: 95.42
Round  47, Global train loss: 0.916, Global test loss: 0.946, Global test accuracy: 96.08
Round  48, Train loss: 0.913, Test loss: 0.953, Test accuracy: 95.42
Round  48, Global train loss: 0.913, Global test loss: 0.943, Global test accuracy: 96.46
Round  49, Train loss: 0.911, Test loss: 0.953, Test accuracy: 95.40
Round  49, Global train loss: 0.911, Global test loss: 0.941, Global test accuracy: 96.58
Round  50, Train loss: 0.914, Test loss: 0.953, Test accuracy: 95.38
Round  50, Global train loss: 0.914, Global test loss: 0.942, Global test accuracy: 96.44
Round  51, Train loss: 0.913, Test loss: 0.953, Test accuracy: 95.40
Round  51, Global train loss: 0.913, Global test loss: 0.943, Global test accuracy: 96.66
Round  52, Train loss: 0.914, Test loss: 0.953, Test accuracy: 95.36
Round  52, Global train loss: 0.914, Global test loss: 0.948, Global test accuracy: 95.86
Round  53, Train loss: 0.914, Test loss: 0.953, Test accuracy: 95.30
Round  53, Global train loss: 0.914, Global test loss: 0.943, Global test accuracy: 96.58
Round  54, Train loss: 0.915, Test loss: 0.953, Test accuracy: 95.30
Round  54, Global train loss: 0.915, Global test loss: 0.941, Global test accuracy: 96.58
Round  55, Train loss: 0.914, Test loss: 0.953, Test accuracy: 95.28
Round  55, Global train loss: 0.914, Global test loss: 0.941, Global test accuracy: 96.46
Round  56, Train loss: 0.914, Test loss: 0.953, Test accuracy: 95.28
Round  56, Global train loss: 0.914, Global test loss: 0.944, Global test accuracy: 96.18
Round  57, Train loss: 0.909, Test loss: 0.953, Test accuracy: 95.28
Round  57, Global train loss: 0.909, Global test loss: 0.940, Global test accuracy: 96.44
Round  58, Train loss: 0.912, Test loss: 0.953, Test accuracy: 95.28
Round  58, Global train loss: 0.912, Global test loss: 0.941, Global test accuracy: 96.32
Round  59, Train loss: 0.914, Test loss: 0.953, Test accuracy: 95.36
Round  59, Global train loss: 0.914, Global test loss: 0.942, Global test accuracy: 96.28
Round  60, Train loss: 0.913, Test loss: 0.953, Test accuracy: 95.36
Round  60, Global train loss: 0.913, Global test loss: 0.941, Global test accuracy: 96.64
Round  61, Train loss: 0.909, Test loss: 0.953, Test accuracy: 95.38
Round  61, Global train loss: 0.909, Global test loss: 0.946, Global test accuracy: 96.28
Round  62, Train loss: 0.914, Test loss: 0.952, Test accuracy: 95.34
Round  62, Global train loss: 0.914, Global test loss: 0.940, Global test accuracy: 96.72
Round  63, Train loss: 0.914, Test loss: 0.952, Test accuracy: 95.38
Round  63, Global train loss: 0.914, Global test loss: 0.940, Global test accuracy: 96.62
Round  64, Train loss: 0.912, Test loss: 0.952, Test accuracy: 95.40
Round  64, Global train loss: 0.912, Global test loss: 0.945, Global test accuracy: 95.86
Round  65, Train loss: 0.914, Test loss: 0.952, Test accuracy: 95.38
Round  65, Global train loss: 0.914, Global test loss: 0.943, Global test accuracy: 96.22
Round  66, Train loss: 0.910, Test loss: 0.952, Test accuracy: 95.38
Round  66, Global train loss: 0.910, Global test loss: 0.945, Global test accuracy: 96.22
Round  67, Train loss: 0.910, Test loss: 0.952, Test accuracy: 95.38
Round  67, Global train loss: 0.910, Global test loss: 0.945, Global test accuracy: 96.08
Round  68, Train loss: 0.915, Test loss: 0.952, Test accuracy: 95.36
Round  68, Global train loss: 0.915, Global test loss: 0.940, Global test accuracy: 96.60
Round  69, Train loss: 0.913, Test loss: 0.952, Test accuracy: 95.38
Round  69, Global train loss: 0.913, Global test loss: 0.941, Global test accuracy: 96.54
Round  70, Train loss: 0.908, Test loss: 0.952, Test accuracy: 95.36
Round  70, Global train loss: 0.908, Global test loss: 0.943, Global test accuracy: 96.34
Round  71, Train loss: 0.912, Test loss: 0.952, Test accuracy: 95.32
Round  71, Global train loss: 0.912, Global test loss: 0.938, Global test accuracy: 96.76
Round  72, Train loss: 0.910, Test loss: 0.952, Test accuracy: 95.34
Round  72, Global train loss: 0.910, Global test loss: 0.942, Global test accuracy: 96.44
Round  73, Train loss: 0.910, Test loss: 0.952, Test accuracy: 95.36
Round  73, Global train loss: 0.910, Global test loss: 0.944, Global test accuracy: 96.28
Round  74, Train loss: 0.910, Test loss: 0.952, Test accuracy: 95.36
Round  74, Global train loss: 0.910, Global test loss: 0.946, Global test accuracy: 95.98
Round  75, Train loss: 0.912, Test loss: 0.952, Test accuracy: 95.40
Round  75, Global train loss: 0.912, Global test loss: 0.950, Global test accuracy: 95.54
Round  76, Train loss: 0.912, Test loss: 0.952, Test accuracy: 95.40
Round  76, Global train loss: 0.912, Global test loss: 0.943, Global test accuracy: 96.32
Round  77, Train loss: 0.913, Test loss: 0.952, Test accuracy: 95.42
Round  77, Global train loss: 0.913, Global test loss: 0.944, Global test accuracy: 96.30
Round  78, Train loss: 0.912, Test loss: 0.952, Test accuracy: 95.42
Round  78, Global train loss: 0.912, Global test loss: 0.944, Global test accuracy: 96.26
Round  79, Train loss: 0.912, Test loss: 0.952, Test accuracy: 95.44
Round  79, Global train loss: 0.912, Global test loss: 0.944, Global test accuracy: 96.16
Round  80, Train loss: 0.913, Test loss: 0.952, Test accuracy: 95.44
Round  80, Global train loss: 0.913, Global test loss: 0.943, Global test accuracy: 96.66
Round  81, Train loss: 0.914, Test loss: 0.952, Test accuracy: 95.44
Round  81, Global train loss: 0.914, Global test loss: 0.940, Global test accuracy: 96.66
Round  82, Train loss: 0.909, Test loss: 0.952, Test accuracy: 95.46
Round  82, Global train loss: 0.909, Global test loss: 0.945, Global test accuracy: 96.02
Round  83, Train loss: 0.909, Test loss: 0.952, Test accuracy: 95.46
Round  83, Global train loss: 0.909, Global test loss: 0.939, Global test accuracy: 96.92
Round  84, Train loss: 0.911, Test loss: 0.952, Test accuracy: 95.46
Round  84, Global train loss: 0.911, Global test loss: 0.939, Global test accuracy: 96.76
Round  85, Train loss: 0.909, Test loss: 0.952, Test accuracy: 95.44
Round  85, Global train loss: 0.909, Global test loss: 0.943, Global test accuracy: 96.48
Round  86, Train loss: 0.912, Test loss: 0.952, Test accuracy: 95.44
Round  86, Global train loss: 0.912, Global test loss: 0.943, Global test accuracy: 96.28
Round  87, Train loss: 0.908, Test loss: 0.952, Test accuracy: 95.46
Round  87, Global train loss: 0.908, Global test loss: 0.940, Global test accuracy: 96.46
Round  88, Train loss: 0.915, Test loss: 0.952, Test accuracy: 95.46
Round  88, Global train loss: 0.915, Global test loss: 0.943, Global test accuracy: 96.22
Round  89, Train loss: 0.911, Test loss: 0.952, Test accuracy: 95.44
Round  89, Global train loss: 0.911, Global test loss: 0.945, Global test accuracy: 96.30
Round  90, Train loss: 0.912, Test loss: 0.952, Test accuracy: 95.50
Round  90, Global train loss: 0.912, Global test loss: 0.938, Global test accuracy: 96.96
Round  91, Train loss: 0.912, Test loss: 0.952, Test accuracy: 95.46
Round  91, Global train loss: 0.912, Global test loss: 0.941, Global test accuracy: 96.56
Round  92, Train loss: 0.911, Test loss: 0.952, Test accuracy: 95.46
Round  92, Global train loss: 0.911, Global test loss: 0.938, Global test accuracy: 96.72
Round  93, Train loss: 0.913, Test loss: 0.952, Test accuracy: 95.44
Round  93, Global train loss: 0.913, Global test loss: 0.945, Global test accuracy: 96.16
Round  94, Train loss: 0.911, Test loss: 0.952, Test accuracy: 95.44
Round  94, Global train loss: 0.911, Global test loss: 0.945, Global test accuracy: 96.30
Round  95, Train loss: 0.915, Test loss: 0.952, Test accuracy: 95.44
Round  95, Global train loss: 0.915, Global test loss: 0.942, Global test accuracy: 96.54/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 0.913, Test loss: 0.952, Test accuracy: 95.44
Round  96, Global train loss: 0.913, Global test loss: 0.943, Global test accuracy: 96.72
Round  97, Train loss: 0.910, Test loss: 0.952, Test accuracy: 95.44
Round  97, Global train loss: 0.910, Global test loss: 0.941, Global test accuracy: 96.34
Round  98, Train loss: 0.910, Test loss: 0.952, Test accuracy: 95.42
Round  98, Global train loss: 0.910, Global test loss: 0.942, Global test accuracy: 96.32
Round  99, Train loss: 0.913, Test loss: 0.952, Test accuracy: 95.42
Round  99, Global train loss: 0.913, Global test loss: 0.939, Global test accuracy: 96.62
Final Round, Train loss: 0.911, Test loss: 0.952, Test accuracy: 95.42
Final Round, Global train loss: 0.911, Global test loss: 0.939, Global test accuracy: 96.62
Average accuracy final 10 rounds: 95.446 

Average global accuracy final 10 rounds: 96.524 

532.4603736400604
[0.8285951614379883, 1.6571903228759766, 2.3881173133850098, 3.119044303894043, 3.856877326965332, 4.594710350036621, 5.335245370864868, 6.075780391693115, 6.806362152099609, 7.5369439125061035, 8.270156860351562, 9.003369808197021, 9.738238334655762, 10.473106861114502, 11.21151351928711, 11.949920177459717, 12.685896396636963, 13.421872615814209, 14.155690670013428, 14.889508724212646, 15.625514268875122, 16.361519813537598, 17.097891092300415, 17.834262371063232, 18.57156538963318, 19.308868408203125, 20.0440092086792, 20.779150009155273, 21.511258363723755, 22.243366718292236, 22.993862628936768, 23.7443585395813, 24.497771978378296, 25.251185417175293, 25.999616622924805, 26.748047828674316, 27.482722282409668, 28.21739673614502, 28.97242522239685, 29.72745370864868, 30.477839469909668, 31.228225231170654, 31.979271173477173, 32.73031711578369, 33.46417474746704, 34.19803237915039, 34.94740128517151, 35.69677019119263, 36.449015855789185, 37.20126152038574, 37.94723463058472, 38.69320774078369, 39.42774701118469, 40.16228628158569, 40.907341957092285, 41.65239763259888, 42.403024435043335, 43.15365123748779, 43.90102171897888, 44.64839220046997, 45.38063311576843, 46.112874031066895, 46.8560152053833, 47.59915637969971, 48.349674701690674, 49.10019302368164, 49.84828186035156, 50.596370697021484, 51.332974910736084, 52.069579124450684, 52.810662508010864, 53.551745891571045, 54.300615072250366, 55.04948425292969, 55.80080056190491, 56.55211687088013, 57.29228234291077, 58.032447814941406, 58.76603174209595, 59.49961566925049, 60.252949714660645, 61.0062837600708, 61.756120443344116, 62.50595712661743, 63.25333762168884, 64.00071811676025, 64.73342990875244, 65.46614170074463, 66.21699213981628, 66.96784257888794, 67.71917366981506, 68.47050476074219, 69.21957659721375, 69.9686484336853, 70.70262694358826, 71.43660545349121, 72.18887424468994, 72.94114303588867, 73.69048571586609, 74.4398283958435, 75.17877268791199, 75.91771697998047, 76.65079951286316, 77.38388204574585, 78.13073825836182, 78.87759447097778, 79.62656688690186, 80.37553930282593, 81.12542009353638, 81.87530088424683, 82.60705924034119, 83.33881759643555, 84.09028124809265, 84.84174489974976, 85.59211444854736, 86.34248399734497, 87.08760714530945, 87.83273029327393, 88.56534886360168, 89.29796743392944, 90.0447723865509, 90.79157733917236, 91.53968358039856, 92.28778982162476, 93.03717756271362, 93.78656530380249, 94.51863050460815, 95.25069570541382, 95.99307322502136, 96.7354507446289, 97.48297953605652, 98.23050832748413, 98.9677312374115, 99.70495414733887, 100.4378342628479, 101.17071437835693, 101.90306401252747, 102.635413646698, 103.36901760101318, 104.10262155532837, 104.83604884147644, 105.56947612762451, 106.30762839317322, 107.04578065872192, 107.77909588813782, 108.51241111755371, 109.2439022064209, 109.97539329528809, 110.71115016937256, 111.44690704345703, 112.1811695098877, 112.91543197631836, 113.64881300926208, 114.38219404220581, 115.17841458320618, 115.97463512420654, 116.74752283096313, 117.52041053771973, 118.25408792495728, 118.98776531219482, 119.72229146957397, 120.45681762695312, 121.19085812568665, 121.92489862442017, 122.65937662124634, 123.39385461807251, 124.1275053024292, 124.86115598678589, 125.59474110603333, 126.32832622528076, 127.06280469894409, 127.79728317260742, 128.5357005596161, 129.27411794662476, 130.0086669921875, 130.74321603775024, 131.47676157951355, 132.21030712127686, 132.94428300857544, 133.67825889587402, 134.4131519794464, 135.1480450630188, 135.8828568458557, 136.61766862869263, 137.35296630859375, 138.08826398849487, 138.8224663734436, 139.55666875839233, 140.28980422019958, 141.02293968200684, 141.7552387714386, 142.48753786087036, 143.22077870368958, 143.9540195465088, 144.68996000289917, 145.42590045928955, 146.16086673736572, 146.8958330154419, 147.6305410861969, 148.3652491569519, 149.97592663764954, 151.58660411834717]
[57.92, 57.92, 85.74, 85.74, 86.38, 86.38, 93.68, 93.68, 95.1, 95.1, 95.08, 95.08, 95.34, 95.34, 95.54, 95.54, 95.48, 95.48, 95.56, 95.56, 95.44, 95.44, 95.6, 95.6, 95.4, 95.4, 95.48, 95.48, 95.48, 95.48, 95.58, 95.58, 95.66, 95.66, 95.56, 95.56, 95.54, 95.54, 95.5, 95.5, 95.54, 95.54, 95.48, 95.48, 95.42, 95.42, 95.4, 95.4, 95.34, 95.34, 95.28, 95.28, 95.26, 95.26, 95.3, 95.3, 95.36, 95.36, 95.4, 95.4, 95.36, 95.36, 95.38, 95.38, 95.4, 95.4, 95.38, 95.38, 95.4, 95.4, 95.4, 95.4, 95.38, 95.38, 95.34, 95.34, 95.34, 95.34, 95.4, 95.4, 95.38, 95.38, 95.38, 95.38, 95.38, 95.38, 95.38, 95.38, 95.38, 95.38, 95.34, 95.34, 95.38, 95.38, 95.42, 95.42, 95.42, 95.42, 95.4, 95.4, 95.38, 95.38, 95.4, 95.4, 95.36, 95.36, 95.3, 95.3, 95.3, 95.3, 95.28, 95.28, 95.28, 95.28, 95.28, 95.28, 95.28, 95.28, 95.36, 95.36, 95.36, 95.36, 95.38, 95.38, 95.34, 95.34, 95.38, 95.38, 95.4, 95.4, 95.38, 95.38, 95.38, 95.38, 95.38, 95.38, 95.36, 95.36, 95.38, 95.38, 95.36, 95.36, 95.32, 95.32, 95.34, 95.34, 95.36, 95.36, 95.36, 95.36, 95.4, 95.4, 95.4, 95.4, 95.42, 95.42, 95.42, 95.42, 95.44, 95.44, 95.44, 95.44, 95.44, 95.44, 95.46, 95.46, 95.46, 95.46, 95.46, 95.46, 95.44, 95.44, 95.44, 95.44, 95.46, 95.46, 95.46, 95.46, 95.44, 95.44, 95.5, 95.5, 95.46, 95.46, 95.46, 95.46, 95.44, 95.44, 95.44, 95.44, 95.44, 95.44, 95.44, 95.44, 95.44, 95.44, 95.42, 95.42, 95.42, 95.42, 95.42, 95.42]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.4  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.590, Test loss: 1.549, Test accuracy: 57.82
Round   0, Global train loss: 1.590, Global test loss: 1.549, Global test accuracy: 58.32
Round   1, Train loss: 1.339, Test loss: 1.271, Test accuracy: 72.58
Round   1, Global train loss: 1.339, Global test loss: 1.149, Global test accuracy: 78.04
Round   2, Train loss: 1.043, Test loss: 1.131, Test accuracy: 84.04
Round   2, Global train loss: 1.043, Global test loss: 0.983, Global test accuracy: 94.78
Round   3, Train loss: 0.966, Test loss: 1.103, Test accuracy: 85.98
Round   3, Global train loss: 0.966, Global test loss: 0.956, Global test accuracy: 96.06
Round   4, Train loss: 0.944, Test loss: 1.082, Test accuracy: 87.92
Round   4, Global train loss: 0.944, Global test loss: 0.949, Global test accuracy: 96.50
Round   5, Train loss: 0.939, Test loss: 1.077, Test accuracy: 88.06
Round   5, Global train loss: 0.939, Global test loss: 0.946, Global test accuracy: 96.64
Round   6, Train loss: 0.939, Test loss: 0.949, Test accuracy: 96.32
Round   6, Global train loss: 0.939, Global test loss: 0.942, Global test accuracy: 96.76
Round   7, Train loss: 0.927, Test loss: 0.948, Test accuracy: 96.30
Round   7, Global train loss: 0.927, Global test loss: 0.939, Global test accuracy: 96.84
Round   8, Train loss: 0.936, Test loss: 0.943, Test accuracy: 96.64
Round   8, Global train loss: 0.936, Global test loss: 0.937, Global test accuracy: 97.16
Round   9, Train loss: 0.934, Test loss: 0.940, Test accuracy: 96.78
Round   9, Global train loss: 0.934, Global test loss: 0.936, Global test accuracy: 97.06
Round  10, Train loss: 0.926, Test loss: 0.939, Test accuracy: 96.84
Round  10, Global train loss: 0.926, Global test loss: 0.936, Global test accuracy: 97.22
Round  11, Train loss: 0.928, Test loss: 0.938, Test accuracy: 96.84
Round  11, Global train loss: 0.928, Global test loss: 0.936, Global test accuracy: 97.04
Round  12, Train loss: 0.930, Test loss: 0.938, Test accuracy: 96.74
Round  12, Global train loss: 0.930, Global test loss: 0.936, Global test accuracy: 97.04
Round  13, Train loss: 0.929, Test loss: 0.937, Test accuracy: 96.80
Round  13, Global train loss: 0.929, Global test loss: 0.934, Global test accuracy: 97.24
Round  14, Train loss: 0.926, Test loss: 0.937, Test accuracy: 96.82
Round  14, Global train loss: 0.926, Global test loss: 0.933, Global test accuracy: 97.32
Round  15, Train loss: 0.927, Test loss: 0.938, Test accuracy: 96.72
Round  15, Global train loss: 0.927, Global test loss: 0.937, Global test accuracy: 97.10
Round  16, Train loss: 0.923, Test loss: 0.938, Test accuracy: 96.76
Round  16, Global train loss: 0.923, Global test loss: 0.934, Global test accuracy: 97.18
Round  17, Train loss: 0.926, Test loss: 0.938, Test accuracy: 96.78
Round  17, Global train loss: 0.926, Global test loss: 0.933, Global test accuracy: 97.40
Round  18, Train loss: 0.924, Test loss: 0.937, Test accuracy: 96.88
Round  18, Global train loss: 0.924, Global test loss: 0.933, Global test accuracy: 97.22
Round  19, Train loss: 0.924, Test loss: 0.934, Test accuracy: 97.22
Round  19, Global train loss: 0.924, Global test loss: 0.933, Global test accuracy: 97.26
Round  20, Train loss: 0.926, Test loss: 0.934, Test accuracy: 97.18
Round  20, Global train loss: 0.926, Global test loss: 0.933, Global test accuracy: 97.28
Round  21, Train loss: 0.919, Test loss: 0.934, Test accuracy: 97.18
Round  21, Global train loss: 0.919, Global test loss: 0.933, Global test accuracy: 97.26
Round  22, Train loss: 0.919, Test loss: 0.934, Test accuracy: 97.12
Round  22, Global train loss: 0.919, Global test loss: 0.934, Global test accuracy: 97.12
Round  23, Train loss: 0.922, Test loss: 0.934, Test accuracy: 97.12
Round  23, Global train loss: 0.922, Global test loss: 0.932, Global test accuracy: 97.40
Round  24, Train loss: 0.920, Test loss: 0.933, Test accuracy: 97.20
Round  24, Global train loss: 0.920, Global test loss: 0.932, Global test accuracy: 97.26
Round  25, Train loss: 0.925, Test loss: 0.933, Test accuracy: 97.22
Round  25, Global train loss: 0.925, Global test loss: 0.932, Global test accuracy: 97.30
Round  26, Train loss: 0.921, Test loss: 0.933, Test accuracy: 97.22
Round  26, Global train loss: 0.921, Global test loss: 0.932, Global test accuracy: 97.36
Round  27, Train loss: 0.919, Test loss: 0.933, Test accuracy: 97.24
Round  27, Global train loss: 0.919, Global test loss: 0.931, Global test accuracy: 97.24
Round  28, Train loss: 0.917, Test loss: 0.933, Test accuracy: 97.28
Round  28, Global train loss: 0.917, Global test loss: 0.931, Global test accuracy: 97.36
Round  29, Train loss: 0.919, Test loss: 0.933, Test accuracy: 97.32
Round  29, Global train loss: 0.919, Global test loss: 0.932, Global test accuracy: 97.38
Round  30, Train loss: 0.917, Test loss: 0.933, Test accuracy: 97.28
Round  30, Global train loss: 0.917, Global test loss: 0.931, Global test accuracy: 97.30
Round  31, Train loss: 0.916, Test loss: 0.933, Test accuracy: 97.28
Round  31, Global train loss: 0.916, Global test loss: 0.931, Global test accuracy: 97.50
Round  32, Train loss: 0.920, Test loss: 0.932, Test accuracy: 97.30
Round  32, Global train loss: 0.920, Global test loss: 0.931, Global test accuracy: 97.42
Round  33, Train loss: 0.913, Test loss: 0.932, Test accuracy: 97.36
Round  33, Global train loss: 0.913, Global test loss: 0.932, Global test accuracy: 97.36
Round  34, Train loss: 0.919, Test loss: 0.932, Test accuracy: 97.38
Round  34, Global train loss: 0.919, Global test loss: 0.931, Global test accuracy: 97.54
Round  35, Train loss: 0.913, Test loss: 0.932, Test accuracy: 97.42
Round  35, Global train loss: 0.913, Global test loss: 0.931, Global test accuracy: 97.38
Round  36, Train loss: 0.921, Test loss: 0.932, Test accuracy: 97.42
Round  36, Global train loss: 0.921, Global test loss: 0.932, Global test accuracy: 97.52
Round  37, Train loss: 0.916, Test loss: 0.932, Test accuracy: 97.40
Round  37, Global train loss: 0.916, Global test loss: 0.931, Global test accuracy: 97.50
Round  38, Train loss: 0.913, Test loss: 0.932, Test accuracy: 97.38
Round  38, Global train loss: 0.913, Global test loss: 0.932, Global test accuracy: 97.46
Round  39, Train loss: 0.920, Test loss: 0.932, Test accuracy: 97.38
Round  39, Global train loss: 0.920, Global test loss: 0.932, Global test accuracy: 97.46
Round  40, Train loss: 0.920, Test loss: 0.932, Test accuracy: 97.42
Round  40, Global train loss: 0.920, Global test loss: 0.932, Global test accuracy: 97.44
Round  41, Train loss: 0.922, Test loss: 0.932, Test accuracy: 97.42
Round  41, Global train loss: 0.922, Global test loss: 0.931, Global test accuracy: 97.42
Round  42, Train loss: 0.919, Test loss: 0.932, Test accuracy: 97.36
Round  42, Global train loss: 0.919, Global test loss: 0.931, Global test accuracy: 97.40
Round  43, Train loss: 0.912, Test loss: 0.932, Test accuracy: 97.42
Round  43, Global train loss: 0.912, Global test loss: 0.931, Global test accuracy: 97.42
Round  44, Train loss: 0.916, Test loss: 0.932, Test accuracy: 97.40
Round  44, Global train loss: 0.916, Global test loss: 0.932, Global test accuracy: 97.26
Round  45, Train loss: 0.918, Test loss: 0.932, Test accuracy: 97.38
Round  45, Global train loss: 0.918, Global test loss: 0.931, Global test accuracy: 97.36
Round  46, Train loss: 0.916, Test loss: 0.932, Test accuracy: 97.40
Round  46, Global train loss: 0.916, Global test loss: 0.930, Global test accuracy: 97.50
Round  47, Train loss: 0.917, Test loss: 0.932, Test accuracy: 97.42
Round  47, Global train loss: 0.917, Global test loss: 0.930, Global test accuracy: 97.64
Round  48, Train loss: 0.914, Test loss: 0.932, Test accuracy: 97.38
Round  48, Global train loss: 0.914, Global test loss: 0.930, Global test accuracy: 97.40
Round  49, Train loss: 0.919, Test loss: 0.931, Test accuracy: 97.46
Round  49, Global train loss: 0.919, Global test loss: 0.930, Global test accuracy: 97.54
Round  50, Train loss: 0.919, Test loss: 0.931, Test accuracy: 97.50
Round  50, Global train loss: 0.919, Global test loss: 0.930, Global test accuracy: 97.56
Round  51, Train loss: 0.918, Test loss: 0.931, Test accuracy: 97.50
Round  51, Global train loss: 0.918, Global test loss: 0.930, Global test accuracy: 97.64
Round  52, Train loss: 0.922, Test loss: 0.931, Test accuracy: 97.48
Round  52, Global train loss: 0.922, Global test loss: 0.930, Global test accuracy: 97.58
Round  53, Train loss: 0.916, Test loss: 0.931, Test accuracy: 97.46
Round  53, Global train loss: 0.916, Global test loss: 0.930, Global test accuracy: 97.46
Round  54, Train loss: 0.914, Test loss: 0.931, Test accuracy: 97.46
Round  54, Global train loss: 0.914, Global test loss: 0.931, Global test accuracy: 97.44
Round  55, Train loss: 0.918, Test loss: 0.931, Test accuracy: 97.44
Round  55, Global train loss: 0.918, Global test loss: 0.930, Global test accuracy: 97.52
Round  56, Train loss: 0.914, Test loss: 0.931, Test accuracy: 97.50
Round  56, Global train loss: 0.914, Global test loss: 0.930, Global test accuracy: 97.46
Round  57, Train loss: 0.914, Test loss: 0.931, Test accuracy: 97.56
Round  57, Global train loss: 0.914, Global test loss: 0.930, Global test accuracy: 97.56
Round  58, Train loss: 0.914, Test loss: 0.931, Test accuracy: 97.52
Round  58, Global train loss: 0.914, Global test loss: 0.930, Global test accuracy: 97.54
Round  59, Train loss: 0.918, Test loss: 0.931, Test accuracy: 97.52
Round  59, Global train loss: 0.918, Global test loss: 0.930, Global test accuracy: 97.60
Round  60, Train loss: 0.913, Test loss: 0.931, Test accuracy: 97.52
Round  60, Global train loss: 0.913, Global test loss: 0.930, Global test accuracy: 97.50
Round  61, Train loss: 0.918, Test loss: 0.931, Test accuracy: 97.52
Round  61, Global train loss: 0.918, Global test loss: 0.930, Global test accuracy: 97.60
Round  62, Train loss: 0.914, Test loss: 0.931, Test accuracy: 97.56
Round  62, Global train loss: 0.914, Global test loss: 0.930, Global test accuracy: 97.60
Round  63, Train loss: 0.918, Test loss: 0.931, Test accuracy: 97.58
Round  63, Global train loss: 0.918, Global test loss: 0.930, Global test accuracy: 97.48
Round  64, Train loss: 0.917, Test loss: 0.930, Test accuracy: 97.58
Round  64, Global train loss: 0.917, Global test loss: 0.930, Global test accuracy: 97.50
Round  65, Train loss: 0.915, Test loss: 0.930, Test accuracy: 97.60
Round  65, Global train loss: 0.915, Global test loss: 0.930, Global test accuracy: 97.54
Round  66, Train loss: 0.919, Test loss: 0.931, Test accuracy: 97.60
Round  66, Global train loss: 0.919, Global test loss: 0.929, Global test accuracy: 97.54
Round  67, Train loss: 0.915, Test loss: 0.930, Test accuracy: 97.58
Round  67, Global train loss: 0.915, Global test loss: 0.930, Global test accuracy: 97.50
Round  68, Train loss: 0.914, Test loss: 0.931, Test accuracy: 97.54
Round  68, Global train loss: 0.914, Global test loss: 0.930, Global test accuracy: 97.44
Round  69, Train loss: 0.917, Test loss: 0.931, Test accuracy: 97.56
Round  69, Global train loss: 0.917, Global test loss: 0.930, Global test accuracy: 97.64
Round  70, Train loss: 0.918, Test loss: 0.931, Test accuracy: 97.58
Round  70, Global train loss: 0.918, Global test loss: 0.930, Global test accuracy: 97.46
Round  71, Train loss: 0.916, Test loss: 0.931, Test accuracy: 97.58
Round  71, Global train loss: 0.916, Global test loss: 0.929, Global test accuracy: 97.70
Round  72, Train loss: 0.911, Test loss: 0.931, Test accuracy: 97.58
Round  72, Global train loss: 0.911, Global test loss: 0.929, Global test accuracy: 97.74
Round  73, Train loss: 0.914, Test loss: 0.930, Test accuracy: 97.62
Round  73, Global train loss: 0.914, Global test loss: 0.929, Global test accuracy: 97.54
Round  74, Train loss: 0.917, Test loss: 0.930, Test accuracy: 97.64
Round  74, Global train loss: 0.917, Global test loss: 0.929, Global test accuracy: 97.70
Round  75, Train loss: 0.914, Test loss: 0.930, Test accuracy: 97.62
Round  75, Global train loss: 0.914, Global test loss: 0.929, Global test accuracy: 97.58
Round  76, Train loss: 0.915, Test loss: 0.930, Test accuracy: 97.58
Round  76, Global train loss: 0.915, Global test loss: 0.929, Global test accuracy: 97.72
Round  77, Train loss: 0.916, Test loss: 0.930, Test accuracy: 97.58
Round  77, Global train loss: 0.916, Global test loss: 0.929, Global test accuracy: 97.62
Round  78, Train loss: 0.917, Test loss: 0.930, Test accuracy: 97.58
Round  78, Global train loss: 0.917, Global test loss: 0.929, Global test accuracy: 97.72
Round  79, Train loss: 0.916, Test loss: 0.930, Test accuracy: 97.60
Round  79, Global train loss: 0.916, Global test loss: 0.929, Global test accuracy: 97.60
Round  80, Train loss: 0.918, Test loss: 0.930, Test accuracy: 97.66
Round  80, Global train loss: 0.918, Global test loss: 0.929, Global test accuracy: 97.60
Round  81, Train loss: 0.915, Test loss: 0.930, Test accuracy: 97.62
Round  81, Global train loss: 0.915, Global test loss: 0.929, Global test accuracy: 97.54
Round  82, Train loss: 0.916, Test loss: 0.930, Test accuracy: 97.62
Round  82, Global train loss: 0.916, Global test loss: 0.929, Global test accuracy: 97.48
Round  83, Train loss: 0.916, Test loss: 0.930, Test accuracy: 97.64
Round  83, Global train loss: 0.916, Global test loss: 0.929, Global test accuracy: 97.60
Round  84, Train loss: 0.918, Test loss: 0.930, Test accuracy: 97.64
Round  84, Global train loss: 0.918, Global test loss: 0.929, Global test accuracy: 97.56
Round  85, Train loss: 0.913, Test loss: 0.930, Test accuracy: 97.62
Round  85, Global train loss: 0.913, Global test loss: 0.929, Global test accuracy: 97.58
Round  86, Train loss: 0.915, Test loss: 0.930, Test accuracy: 97.64
Round  86, Global train loss: 0.915, Global test loss: 0.929, Global test accuracy: 97.58
Round  87, Train loss: 0.911, Test loss: 0.930, Test accuracy: 97.60
Round  87, Global train loss: 0.911, Global test loss: 0.929, Global test accuracy: 97.80
Round  88, Train loss: 0.913, Test loss: 0.930, Test accuracy: 97.60
Round  88, Global train loss: 0.913, Global test loss: 0.929, Global test accuracy: 97.66
Round  89, Train loss: 0.917, Test loss: 0.930, Test accuracy: 97.64
Round  89, Global train loss: 0.917, Global test loss: 0.929, Global test accuracy: 97.66
Round  90, Train loss: 0.916, Test loss: 0.930, Test accuracy: 97.62
Round  90, Global train loss: 0.916, Global test loss: 0.929, Global test accuracy: 97.68
Round  91, Train loss: 0.914, Test loss: 0.930, Test accuracy: 97.62
Round  91, Global train loss: 0.914, Global test loss: 0.929, Global test accuracy: 97.58
Round  92, Train loss: 0.913, Test loss: 0.930, Test accuracy: 97.62
Round  92, Global train loss: 0.913, Global test loss: 0.929, Global test accuracy: 97.66
Round  93, Train loss: 0.915, Test loss: 0.930, Test accuracy: 97.62
Round  93, Global train loss: 0.915, Global test loss: 0.929, Global test accuracy: 97.64
Round  94, Train loss: 0.914, Test loss: 0.930, Test accuracy: 97.60
Round  94, Global train loss: 0.914, Global test loss: 0.929, Global test accuracy: 97.52
Round  95, Train loss: 0.911, Test loss: 0.930, Test accuracy: 97.56
Round  95, Global train loss: 0.911, Global test loss: 0.929, Global test accuracy: 97.68/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 0.915, Test loss: 0.930, Test accuracy: 97.60
Round  96, Global train loss: 0.915, Global test loss: 0.929, Global test accuracy: 97.66
Round  97, Train loss: 0.913, Test loss: 0.930, Test accuracy: 97.56
Round  97, Global train loss: 0.913, Global test loss: 0.929, Global test accuracy: 97.68
Round  98, Train loss: 0.914, Test loss: 0.930, Test accuracy: 97.58
Round  98, Global train loss: 0.914, Global test loss: 0.930, Global test accuracy: 97.54
Round  99, Train loss: 0.915, Test loss: 0.929, Test accuracy: 97.60
Round  99, Global train loss: 0.915, Global test loss: 0.929, Global test accuracy: 97.62
Final Round, Train loss: 0.915, Test loss: 0.929, Test accuracy: 97.64
Final Round, Global train loss: 0.915, Global test loss: 0.929, Global test accuracy: 97.62
Average accuracy final 10 rounds: 97.598 

Average global accuracy final 10 rounds: 97.626 

506.48511576652527
[0.8649544715881348, 1.7299089431762695, 2.5010132789611816, 3.2721176147460938, 4.04518461227417, 4.818251609802246, 5.594811201095581, 6.371370792388916, 7.149622678756714, 7.927874565124512, 8.70515489578247, 9.48243522644043, 10.255232334136963, 11.028029441833496, 11.803988695144653, 12.57994794845581, 13.356300592422485, 14.13265323638916, 14.907447576522827, 15.682241916656494, 16.44873285293579, 17.215223789215088, 17.984501600265503, 18.753779411315918, 19.52122974395752, 20.28868007659912, 21.08016037940979, 21.87164068222046, 22.648394346237183, 23.425148010253906, 24.199820518493652, 24.9744930267334, 25.75224256515503, 26.52999210357666, 27.304115772247314, 28.07823944091797, 28.852164268493652, 29.626089096069336, 30.396628856658936, 31.167168617248535, 31.94330596923828, 32.71944332122803, 33.49432015419006, 34.2691969871521, 35.046133041381836, 35.82306909561157, 36.596009254455566, 37.36894941329956, 38.142855405807495, 38.91676139831543, 39.64201855659485, 40.36727571487427, 41.092472553253174, 41.81766939163208, 42.43208146095276, 43.04649353027344, 43.77940583229065, 44.51231813430786, 45.20604205131531, 45.899765968322754, 46.629441261291504, 47.359116554260254, 48.09328484535217, 48.82745313644409, 49.52866196632385, 50.22987079620361, 50.96330761909485, 51.696744441986084, 52.39381790161133, 53.09089136123657, 53.819395303726196, 54.54789924621582, 55.278974771499634, 56.01005029678345, 56.74046015739441, 57.47087001800537, 58.19467759132385, 58.918485164642334, 59.63922119140625, 60.359957218170166, 61.09701490402222, 61.83407258987427, 62.524102210998535, 63.2141318321228, 63.93204641342163, 64.64996099472046, 65.36955332756042, 66.08914566040039, 66.82028865814209, 67.55143165588379, 68.27493834495544, 68.9984450340271, 69.73541116714478, 70.47237730026245, 71.20784664154053, 71.9433159828186, 72.68200373649597, 73.42069149017334, 74.11602878570557, 74.8113660812378, 75.50465178489685, 76.19793748855591, 76.8881425857544, 77.57834768295288, 78.24277138710022, 78.90719509124756, 79.61380791664124, 80.32042074203491, 81.01055932044983, 81.70069789886475, 82.39261221885681, 83.08452653884888, 83.82013082504272, 84.55573511123657, 85.29703974723816, 86.03834438323975, 86.77353692054749, 87.50872945785522, 88.24830484390259, 88.98788022994995, 89.71696090698242, 90.44604158401489, 91.18698477745056, 91.92792797088623, 92.66902613639832, 93.4101243019104, 94.13049960136414, 94.85087490081787, 95.59683585166931, 96.34279680252075, 97.07960915565491, 97.81642150878906, 98.53973865509033, 99.2630558013916, 99.98706126213074, 100.71106672286987, 101.43036007881165, 102.14965343475342, 102.87178349494934, 103.59391355514526, 104.31797671318054, 105.04203987121582, 105.76636505126953, 106.49069023132324, 107.21231174468994, 107.93393325805664, 108.65854620933533, 109.38315916061401, 110.1078851222992, 110.83261108398438, 111.55655527114868, 112.28049945831299, 113.00614380836487, 113.73178815841675, 114.46593499183655, 115.20008182525635, 115.94180154800415, 116.68352127075195, 117.41923260688782, 118.15494394302368, 118.88984632492065, 119.62474870681763, 120.36110091209412, 121.0974531173706, 121.83312726020813, 122.56880140304565, 123.30174779891968, 124.0346941947937, 124.76884508132935, 125.50299596786499, 126.23709225654602, 126.97118854522705, 127.70218396186829, 128.43317937850952, 129.16630506515503, 129.89943075180054, 130.6308295726776, 131.3622283935547, 132.0954294204712, 132.8286304473877, 133.56262063980103, 134.29661083221436, 135.03080248832703, 135.7649941444397, 136.50097608566284, 137.236958026886, 137.96986508369446, 138.70277214050293, 139.43421530723572, 140.1656584739685, 140.8988003730774, 141.63194227218628, 142.36465001106262, 143.09735774993896, 143.8313865661621, 144.56541538238525, 145.302503824234, 146.03959226608276, 146.77648997306824, 147.5133876800537, 148.98576283454895, 150.4581379890442]
[57.82, 57.82, 72.58, 72.58, 84.04, 84.04, 85.98, 85.98, 87.92, 87.92, 88.06, 88.06, 96.32, 96.32, 96.3, 96.3, 96.64, 96.64, 96.78, 96.78, 96.84, 96.84, 96.84, 96.84, 96.74, 96.74, 96.8, 96.8, 96.82, 96.82, 96.72, 96.72, 96.76, 96.76, 96.78, 96.78, 96.88, 96.88, 97.22, 97.22, 97.18, 97.18, 97.18, 97.18, 97.12, 97.12, 97.12, 97.12, 97.2, 97.2, 97.22, 97.22, 97.22, 97.22, 97.24, 97.24, 97.28, 97.28, 97.32, 97.32, 97.28, 97.28, 97.28, 97.28, 97.3, 97.3, 97.36, 97.36, 97.38, 97.38, 97.42, 97.42, 97.42, 97.42, 97.4, 97.4, 97.38, 97.38, 97.38, 97.38, 97.42, 97.42, 97.42, 97.42, 97.36, 97.36, 97.42, 97.42, 97.4, 97.4, 97.38, 97.38, 97.4, 97.4, 97.42, 97.42, 97.38, 97.38, 97.46, 97.46, 97.5, 97.5, 97.5, 97.5, 97.48, 97.48, 97.46, 97.46, 97.46, 97.46, 97.44, 97.44, 97.5, 97.5, 97.56, 97.56, 97.52, 97.52, 97.52, 97.52, 97.52, 97.52, 97.52, 97.52, 97.56, 97.56, 97.58, 97.58, 97.58, 97.58, 97.6, 97.6, 97.6, 97.6, 97.58, 97.58, 97.54, 97.54, 97.56, 97.56, 97.58, 97.58, 97.58, 97.58, 97.58, 97.58, 97.62, 97.62, 97.64, 97.64, 97.62, 97.62, 97.58, 97.58, 97.58, 97.58, 97.58, 97.58, 97.6, 97.6, 97.66, 97.66, 97.62, 97.62, 97.62, 97.62, 97.64, 97.64, 97.64, 97.64, 97.62, 97.62, 97.64, 97.64, 97.6, 97.6, 97.6, 97.6, 97.64, 97.64, 97.62, 97.62, 97.62, 97.62, 97.62, 97.62, 97.62, 97.62, 97.6, 97.6, 97.56, 97.56, 97.6, 97.6, 97.56, 97.56, 97.58, 97.58, 97.6, 97.6, 97.64, 97.64]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.4  

prox
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.583, Test loss: 1.531, Test accuracy: 36.38
Round   0, Global train loss: 1.583, Global test loss: 1.531, Global test accuracy: 36.46
Round   1, Train loss: 1.430, Test loss: 1.338, Test accuracy: 68.40
Round   1, Global train loss: 1.430, Global test loss: 1.288, Global test accuracy: 75.94
Round   2, Train loss: 1.118, Test loss: 1.204, Test accuracy: 77.34
Round   2, Global train loss: 1.118, Global test loss: 1.019, Global test accuracy: 94.34
Round   3, Train loss: 0.980, Test loss: 1.157, Test accuracy: 80.14
Round   3, Global train loss: 0.980, Global test loss: 0.969, Global test accuracy: 95.92
Round   4, Train loss: 0.953, Test loss: 1.154, Test accuracy: 79.98
Round   4, Global train loss: 0.953, Global test loss: 0.959, Global test accuracy: 95.80
Round   5, Train loss: 0.956, Test loss: 1.035, Test accuracy: 91.76
Round   5, Global train loss: 0.956, Global test loss: 0.947, Global test accuracy: 96.56
Round   6, Train loss: 0.947, Test loss: 0.996, Test accuracy: 94.36
Round   6, Global train loss: 0.947, Global test loss: 0.943, Global test accuracy: 96.88
Round   7, Train loss: 0.930, Test loss: 0.957, Test accuracy: 96.30
Round   7, Global train loss: 0.930, Global test loss: 0.941, Global test accuracy: 96.90
Round   8, Train loss: 0.936, Test loss: 0.946, Test accuracy: 96.92
Round   8, Global train loss: 0.936, Global test loss: 0.938, Global test accuracy: 97.02
Round   9, Train loss: 0.940, Test loss: 0.943, Test accuracy: 96.98
Round   9, Global train loss: 0.940, Global test loss: 0.937, Global test accuracy: 97.28
Round  10, Train loss: 0.929, Test loss: 0.942, Test accuracy: 96.94
Round  10, Global train loss: 0.929, Global test loss: 0.937, Global test accuracy: 97.12
Round  11, Train loss: 0.931, Test loss: 0.941, Test accuracy: 96.90
Round  11, Global train loss: 0.931, Global test loss: 0.936, Global test accuracy: 97.28
Round  12, Train loss: 0.926, Test loss: 0.939, Test accuracy: 97.06
Round  12, Global train loss: 0.926, Global test loss: 0.935, Global test accuracy: 97.26
Round  13, Train loss: 0.920, Test loss: 0.938, Test accuracy: 97.14
Round  13, Global train loss: 0.920, Global test loss: 0.934, Global test accuracy: 97.32
Round  14, Train loss: 0.927, Test loss: 0.937, Test accuracy: 97.24
Round  14, Global train loss: 0.927, Global test loss: 0.935, Global test accuracy: 97.34
Round  15, Train loss: 0.928, Test loss: 0.937, Test accuracy: 97.20
Round  15, Global train loss: 0.928, Global test loss: 0.934, Global test accuracy: 97.36
Round  16, Train loss: 0.923, Test loss: 0.936, Test accuracy: 97.24
Round  16, Global train loss: 0.923, Global test loss: 0.934, Global test accuracy: 97.46
Round  17, Train loss: 0.922, Test loss: 0.935, Test accuracy: 97.34
Round  17, Global train loss: 0.922, Global test loss: 0.934, Global test accuracy: 97.36
Round  18, Train loss: 0.929, Test loss: 0.935, Test accuracy: 97.34
Round  18, Global train loss: 0.929, Global test loss: 0.934, Global test accuracy: 97.36
Round  19, Train loss: 0.920, Test loss: 0.936, Test accuracy: 97.30
Round  19, Global train loss: 0.920, Global test loss: 0.934, Global test accuracy: 97.28
Round  20, Train loss: 0.923, Test loss: 0.935, Test accuracy: 97.36
Round  20, Global train loss: 0.923, Global test loss: 0.934, Global test accuracy: 97.22
Round  21, Train loss: 0.915, Test loss: 0.935, Test accuracy: 97.32
Round  21, Global train loss: 0.915, Global test loss: 0.933, Global test accuracy: 97.40
Round  22, Train loss: 0.923, Test loss: 0.935, Test accuracy: 97.34
Round  22, Global train loss: 0.923, Global test loss: 0.932, Global test accuracy: 97.52
Round  23, Train loss: 0.918, Test loss: 0.935, Test accuracy: 97.34
Round  23, Global train loss: 0.918, Global test loss: 0.933, Global test accuracy: 97.34
Round  24, Train loss: 0.924, Test loss: 0.934, Test accuracy: 97.32
Round  24, Global train loss: 0.924, Global test loss: 0.934, Global test accuracy: 97.08
Round  25, Train loss: 0.923, Test loss: 0.934, Test accuracy: 97.28
Round  25, Global train loss: 0.923, Global test loss: 0.933, Global test accuracy: 97.22
Round  26, Train loss: 0.923, Test loss: 0.934, Test accuracy: 97.30
Round  26, Global train loss: 0.923, Global test loss: 0.933, Global test accuracy: 97.18
Round  27, Train loss: 0.923, Test loss: 0.934, Test accuracy: 97.26
Round  27, Global train loss: 0.923, Global test loss: 0.933, Global test accuracy: 97.32
Round  28, Train loss: 0.920, Test loss: 0.934, Test accuracy: 97.28
Round  28, Global train loss: 0.920, Global test loss: 0.932, Global test accuracy: 97.38
Round  29, Train loss: 0.920, Test loss: 0.934, Test accuracy: 97.26
Round  29, Global train loss: 0.920, Global test loss: 0.931, Global test accuracy: 97.42
Round  30, Train loss: 0.917, Test loss: 0.933, Test accuracy: 97.28
Round  30, Global train loss: 0.917, Global test loss: 0.932, Global test accuracy: 97.30
Round  31, Train loss: 0.920, Test loss: 0.933, Test accuracy: 97.30
Round  31, Global train loss: 0.920, Global test loss: 0.931, Global test accuracy: 97.46
Round  32, Train loss: 0.917, Test loss: 0.933, Test accuracy: 97.34
Round  32, Global train loss: 0.917, Global test loss: 0.931, Global test accuracy: 97.48
Round  33, Train loss: 0.917, Test loss: 0.933, Test accuracy: 97.34
Round  33, Global train loss: 0.917, Global test loss: 0.931, Global test accuracy: 97.44
Round  34, Train loss: 0.922, Test loss: 0.932, Test accuracy: 97.32
Round  34, Global train loss: 0.922, Global test loss: 0.931, Global test accuracy: 97.38
Round  35, Train loss: 0.919, Test loss: 0.932, Test accuracy: 97.32
Round  35, Global train loss: 0.919, Global test loss: 0.930, Global test accuracy: 97.50
Round  36, Train loss: 0.918, Test loss: 0.932, Test accuracy: 97.32
Round  36, Global train loss: 0.918, Global test loss: 0.930, Global test accuracy: 97.44
Round  37, Train loss: 0.918, Test loss: 0.932, Test accuracy: 97.32
Round  37, Global train loss: 0.918, Global test loss: 0.931, Global test accuracy: 97.38
Round  38, Train loss: 0.922, Test loss: 0.932, Test accuracy: 97.36
Round  38, Global train loss: 0.922, Global test loss: 0.931, Global test accuracy: 97.38
Round  39, Train loss: 0.916, Test loss: 0.932, Test accuracy: 97.38
Round  39, Global train loss: 0.916, Global test loss: 0.930, Global test accuracy: 97.54
Round  40, Train loss: 0.915, Test loss: 0.932, Test accuracy: 97.34
Round  40, Global train loss: 0.915, Global test loss: 0.930, Global test accuracy: 97.54
Round  41, Train loss: 0.921, Test loss: 0.932, Test accuracy: 97.32
Round  41, Global train loss: 0.921, Global test loss: 0.930, Global test accuracy: 97.44
Round  42, Train loss: 0.920, Test loss: 0.932, Test accuracy: 97.30
Round  42, Global train loss: 0.920, Global test loss: 0.931, Global test accuracy: 97.40
Round  43, Train loss: 0.918, Test loss: 0.932, Test accuracy: 97.30
Round  43, Global train loss: 0.918, Global test loss: 0.931, Global test accuracy: 97.46
Round  44, Train loss: 0.918, Test loss: 0.932, Test accuracy: 97.30
Round  44, Global train loss: 0.918, Global test loss: 0.930, Global test accuracy: 97.50
Round  45, Train loss: 0.920, Test loss: 0.932, Test accuracy: 97.30
Round  45, Global train loss: 0.920, Global test loss: 0.931, Global test accuracy: 97.34
Round  46, Train loss: 0.917, Test loss: 0.932, Test accuracy: 97.28
Round  46, Global train loss: 0.917, Global test loss: 0.931, Global test accuracy: 97.22
Round  47, Train loss: 0.919, Test loss: 0.932, Test accuracy: 97.26
Round  47, Global train loss: 0.919, Global test loss: 0.931, Global test accuracy: 97.32
Round  48, Train loss: 0.914, Test loss: 0.932, Test accuracy: 97.28
Round  48, Global train loss: 0.914, Global test loss: 0.931, Global test accuracy: 97.18
Round  49, Train loss: 0.913, Test loss: 0.932, Test accuracy: 97.28
Round  49, Global train loss: 0.913, Global test loss: 0.931, Global test accuracy: 97.36
Round  50, Train loss: 0.920, Test loss: 0.932, Test accuracy: 97.28
Round  50, Global train loss: 0.920, Global test loss: 0.931, Global test accuracy: 97.30
Round  51, Train loss: 0.919, Test loss: 0.932, Test accuracy: 97.28
Round  51, Global train loss: 0.919, Global test loss: 0.930, Global test accuracy: 97.32
Round  52, Train loss: 0.915, Test loss: 0.932, Test accuracy: 97.36
Round  52, Global train loss: 0.915, Global test loss: 0.931, Global test accuracy: 97.32
Round  53, Train loss: 0.916, Test loss: 0.932, Test accuracy: 97.40
Round  53, Global train loss: 0.916, Global test loss: 0.931, Global test accuracy: 97.38
Round  54, Train loss: 0.918, Test loss: 0.932, Test accuracy: 97.32
Round  54, Global train loss: 0.918, Global test loss: 0.931, Global test accuracy: 97.30
Round  55, Train loss: 0.918, Test loss: 0.932, Test accuracy: 97.30
Round  55, Global train loss: 0.918, Global test loss: 0.932, Global test accuracy: 97.10
Round  56, Train loss: 0.913, Test loss: 0.932, Test accuracy: 97.30
Round  56, Global train loss: 0.913, Global test loss: 0.931, Global test accuracy: 97.32
Round  57, Train loss: 0.921, Test loss: 0.932, Test accuracy: 97.28
Round  57, Global train loss: 0.921, Global test loss: 0.931, Global test accuracy: 97.36
Round  58, Train loss: 0.920, Test loss: 0.932, Test accuracy: 97.32
Round  58, Global train loss: 0.920, Global test loss: 0.931, Global test accuracy: 97.38
Round  59, Train loss: 0.916, Test loss: 0.932, Test accuracy: 97.32
Round  59, Global train loss: 0.916, Global test loss: 0.931, Global test accuracy: 97.38
Round  60, Train loss: 0.919, Test loss: 0.932, Test accuracy: 97.28
Round  60, Global train loss: 0.919, Global test loss: 0.930, Global test accuracy: 97.42
Round  61, Train loss: 0.914, Test loss: 0.932, Test accuracy: 97.30
Round  61, Global train loss: 0.914, Global test loss: 0.930, Global test accuracy: 97.40
Round  62, Train loss: 0.915, Test loss: 0.931, Test accuracy: 97.32
Round  62, Global train loss: 0.915, Global test loss: 0.930, Global test accuracy: 97.46
Round  63, Train loss: 0.916, Test loss: 0.931, Test accuracy: 97.30
Round  63, Global train loss: 0.916, Global test loss: 0.930, Global test accuracy: 97.48
Round  64, Train loss: 0.916, Test loss: 0.931, Test accuracy: 97.34
Round  64, Global train loss: 0.916, Global test loss: 0.930, Global test accuracy: 97.42
Round  65, Train loss: 0.914, Test loss: 0.931, Test accuracy: 97.36
Round  65, Global train loss: 0.914, Global test loss: 0.931, Global test accuracy: 97.30
Round  66, Train loss: 0.917, Test loss: 0.931, Test accuracy: 97.36
Round  66, Global train loss: 0.917, Global test loss: 0.930, Global test accuracy: 97.44
Round  67, Train loss: 0.918, Test loss: 0.931, Test accuracy: 97.34
Round  67, Global train loss: 0.918, Global test loss: 0.931, Global test accuracy: 97.26
Round  68, Train loss: 0.914, Test loss: 0.931, Test accuracy: 97.34
Round  68, Global train loss: 0.914, Global test loss: 0.930, Global test accuracy: 97.40
Round  69, Train loss: 0.918, Test loss: 0.931, Test accuracy: 97.36
Round  69, Global train loss: 0.918, Global test loss: 0.930, Global test accuracy: 97.52
Round  70, Train loss: 0.914, Test loss: 0.931, Test accuracy: 97.36
Round  70, Global train loss: 0.914, Global test loss: 0.930, Global test accuracy: 97.42
Round  71, Train loss: 0.914, Test loss: 0.931, Test accuracy: 97.36
Round  71, Global train loss: 0.914, Global test loss: 0.930, Global test accuracy: 97.42
Round  72, Train loss: 0.916, Test loss: 0.931, Test accuracy: 97.38
Round  72, Global train loss: 0.916, Global test loss: 0.930, Global test accuracy: 97.40
Round  73, Train loss: 0.917, Test loss: 0.931, Test accuracy: 97.42
Round  73, Global train loss: 0.917, Global test loss: 0.930, Global test accuracy: 97.46
Round  74, Train loss: 0.917, Test loss: 0.931, Test accuracy: 97.44
Round  74, Global train loss: 0.917, Global test loss: 0.930, Global test accuracy: 97.52
Round  75, Train loss: 0.916, Test loss: 0.931, Test accuracy: 97.48
Round  75, Global train loss: 0.916, Global test loss: 0.930, Global test accuracy: 97.42
Round  76, Train loss: 0.918, Test loss: 0.931, Test accuracy: 97.42
Round  76, Global train loss: 0.918, Global test loss: 0.930, Global test accuracy: 97.44
Round  77, Train loss: 0.917, Test loss: 0.931, Test accuracy: 97.44
Round  77, Global train loss: 0.917, Global test loss: 0.930, Global test accuracy: 97.42
Round  78, Train loss: 0.917, Test loss: 0.931, Test accuracy: 97.42
Round  78, Global train loss: 0.917, Global test loss: 0.930, Global test accuracy: 97.54
Round  79, Train loss: 0.914, Test loss: 0.931, Test accuracy: 97.44
Round  79, Global train loss: 0.914, Global test loss: 0.929, Global test accuracy: 97.64
Round  80, Train loss: 0.916, Test loss: 0.931, Test accuracy: 97.38
Round  80, Global train loss: 0.916, Global test loss: 0.930, Global test accuracy: 97.38
Round  81, Train loss: 0.914, Test loss: 0.931, Test accuracy: 97.38
Round  81, Global train loss: 0.914, Global test loss: 0.930, Global test accuracy: 97.54
Round  82, Train loss: 0.916, Test loss: 0.931, Test accuracy: 97.44
Round  82, Global train loss: 0.916, Global test loss: 0.930, Global test accuracy: 97.40
Round  83, Train loss: 0.916, Test loss: 0.931, Test accuracy: 97.42
Round  83, Global train loss: 0.916, Global test loss: 0.930, Global test accuracy: 97.36
Round  84, Train loss: 0.917, Test loss: 0.931, Test accuracy: 97.36
Round  84, Global train loss: 0.917, Global test loss: 0.930, Global test accuracy: 97.46
Round  85, Train loss: 0.915, Test loss: 0.931, Test accuracy: 97.38
Round  85, Global train loss: 0.915, Global test loss: 0.929, Global test accuracy: 97.48
Round  86, Train loss: 0.917, Test loss: 0.931, Test accuracy: 97.42
Round  86, Global train loss: 0.917, Global test loss: 0.930, Global test accuracy: 97.42
Round  87, Train loss: 0.914, Test loss: 0.930, Test accuracy: 97.44
Round  87, Global train loss: 0.914, Global test loss: 0.930, Global test accuracy: 97.46
Round  88, Train loss: 0.916, Test loss: 0.930, Test accuracy: 97.50
Round  88, Global train loss: 0.916, Global test loss: 0.929, Global test accuracy: 97.54
Round  89, Train loss: 0.919, Test loss: 0.930, Test accuracy: 97.52
Round  89, Global train loss: 0.919, Global test loss: 0.929, Global test accuracy: 97.56
Round  90, Train loss: 0.921, Test loss: 0.930, Test accuracy: 97.54
Round  90, Global train loss: 0.921, Global test loss: 0.930, Global test accuracy: 97.48
Round  91, Train loss: 0.913, Test loss: 0.930, Test accuracy: 97.54
Round  91, Global train loss: 0.913, Global test loss: 0.930, Global test accuracy: 97.56
Round  92, Train loss: 0.919, Test loss: 0.930, Test accuracy: 97.56
Round  92, Global train loss: 0.919, Global test loss: 0.929, Global test accuracy: 97.54
Round  93, Train loss: 0.912, Test loss: 0.930, Test accuracy: 97.52
Round  93, Global train loss: 0.912, Global test loss: 0.929, Global test accuracy: 97.64
Round  94, Train loss: 0.913, Test loss: 0.930, Test accuracy: 97.52
Round  94, Global train loss: 0.913, Global test loss: 0.929, Global test accuracy: 97.56
Round  95, Train loss: 0.913, Test loss: 0.930, Test accuracy: 97.50
Round  95, Global train loss: 0.913, Global test loss: 0.929, Global test accuracy: 97.60/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  96, Train loss: 0.916, Test loss: 0.930, Test accuracy: 97.48
Round  96, Global train loss: 0.916, Global test loss: 0.929, Global test accuracy: 97.50
Round  97, Train loss: 0.912, Test loss: 0.930, Test accuracy: 97.52
Round  97, Global train loss: 0.912, Global test loss: 0.930, Global test accuracy: 97.52
Round  98, Train loss: 0.923, Test loss: 0.930, Test accuracy: 97.50
Round  98, Global train loss: 0.923, Global test loss: 0.929, Global test accuracy: 97.56
Round  99, Train loss: 0.919, Test loss: 0.930, Test accuracy: 97.48
Round  99, Global train loss: 0.919, Global test loss: 0.929, Global test accuracy: 97.60
Final Round, Train loss: 0.916, Test loss: 0.930, Test accuracy: 97.44
Final Round, Global train loss: 0.916, Global test loss: 0.929, Global test accuracy: 97.60
Average accuracy final 10 rounds: 97.516 

Average global accuracy final 10 rounds: 97.55600000000001 

486.6960382461548
[0.8243696689605713, 1.6487393379211426, 2.415893793106079, 3.1830482482910156, 3.958441734313965, 4.733835220336914, 5.505807638168335, 6.277780055999756, 7.052688360214233, 7.827596664428711, 8.632445812225342, 9.437294960021973, 10.208995819091797, 10.980696678161621, 11.74855637550354, 12.516416072845459, 13.28575611114502, 14.05509614944458, 14.82154655456543, 15.58799695968628, 16.35643768310547, 17.124878406524658, 17.896356344223022, 18.667834281921387, 19.439262628555298, 20.21069097518921, 20.981106519699097, 21.751522064208984, 22.521639347076416, 23.291756629943848, 24.0346736907959, 24.77759075164795, 25.441209077835083, 26.104827404022217, 26.787424087524414, 27.47002077102661, 28.125617504119873, 28.781214237213135, 29.43610453605652, 30.090994834899902, 30.747039079666138, 31.403083324432373, 32.05801963806152, 32.712955951690674, 33.36668944358826, 34.02042293548584, 34.67495679855347, 35.329490661621094, 35.98446726799011, 36.63944387435913, 37.295665979385376, 37.95188808441162, 38.606656551361084, 39.26142501831055, 39.91531705856323, 40.56920909881592, 41.22376799583435, 41.87832689285278, 42.53361415863037, 43.18890142440796, 43.84197402000427, 44.495046615600586, 45.1538519859314, 45.81265735626221, 46.46752595901489, 47.12239456176758, 47.779945373535156, 48.437496185302734, 49.092294692993164, 49.747093200683594, 50.401628255844116, 51.05616331100464, 51.71136474609375, 52.36656618118286, 53.02060270309448, 53.6746392250061, 54.33236074447632, 54.99008226394653, 55.64548707008362, 56.3008918762207, 56.95649027824402, 57.612088680267334, 58.268388986587524, 58.924689292907715, 59.580105781555176, 60.23552227020264, 60.89166498184204, 61.547807693481445, 62.20388865470886, 62.85996961593628, 63.51778841018677, 64.17560720443726, 64.8322696685791, 65.48893213272095, 66.14886450767517, 66.8087968826294, 67.46688604354858, 68.12497520446777, 68.78109574317932, 69.43721628189087, 70.08926701545715, 70.74131774902344, 71.39622974395752, 72.0511417388916, 72.70706391334534, 73.36298608779907, 74.01814675331116, 74.67330741882324, 75.32799935340881, 75.98269128799438, 76.63724684715271, 77.29180240631104, 77.94494557380676, 78.59808874130249, 79.3740463256836, 80.1500039100647, 80.83262038230896, 81.51523685455322, 82.19049286842346, 82.8657488822937, 83.5482280254364, 84.2307071685791, 84.89339590072632, 85.55608463287354, 86.23088097572327, 86.905677318573, 87.59282994270325, 88.2799825668335, 88.95237922668457, 89.62477588653564, 90.30274987220764, 90.98072385787964, 91.65494441986084, 92.32916498184204, 93.01393485069275, 93.69870471954346, 94.38581442832947, 95.07292413711548, 95.74771046638489, 96.4224967956543, 97.08411860466003, 97.74574041366577, 98.42682480812073, 99.10790920257568, 99.79415154457092, 100.48039388656616, 101.15002512931824, 101.81965637207031, 102.4851508140564, 103.15064525604248, 103.81950759887695, 104.48836994171143, 105.17235684394836, 105.8563437461853, 106.54137420654297, 107.22640466690063, 107.89594912528992, 108.5654935836792, 109.23511409759521, 109.90473461151123, 110.58785510063171, 111.2709755897522, 111.95526170730591, 112.63954782485962, 113.31441879272461, 113.9892897605896, 114.64518475532532, 115.30107975006104, 115.97240877151489, 116.64373779296875, 117.32977724075317, 118.0158166885376, 118.68700385093689, 119.35819101333618, 120.02950191497803, 120.70081281661987, 121.37405323982239, 122.0472936630249, 122.73662543296814, 123.42595720291138, 124.09817171096802, 124.77038621902466, 125.45181608200073, 126.1332459449768, 126.79355597496033, 127.45386600494385, 128.1302034854889, 128.80654096603394, 129.48501420021057, 130.1634874343872, 130.8397195339203, 131.51595163345337, 132.17609643936157, 132.83624124526978, 133.5100474357605, 134.18385362625122, 134.8651626110077, 135.54647159576416, 136.21406316757202, 136.88165473937988, 138.2206587791443, 139.5596628189087]
[36.38, 36.38, 68.4, 68.4, 77.34, 77.34, 80.14, 80.14, 79.98, 79.98, 91.76, 91.76, 94.36, 94.36, 96.3, 96.3, 96.92, 96.92, 96.98, 96.98, 96.94, 96.94, 96.9, 96.9, 97.06, 97.06, 97.14, 97.14, 97.24, 97.24, 97.2, 97.2, 97.24, 97.24, 97.34, 97.34, 97.34, 97.34, 97.3, 97.3, 97.36, 97.36, 97.32, 97.32, 97.34, 97.34, 97.34, 97.34, 97.32, 97.32, 97.28, 97.28, 97.3, 97.3, 97.26, 97.26, 97.28, 97.28, 97.26, 97.26, 97.28, 97.28, 97.3, 97.3, 97.34, 97.34, 97.34, 97.34, 97.32, 97.32, 97.32, 97.32, 97.32, 97.32, 97.32, 97.32, 97.36, 97.36, 97.38, 97.38, 97.34, 97.34, 97.32, 97.32, 97.3, 97.3, 97.3, 97.3, 97.3, 97.3, 97.3, 97.3, 97.28, 97.28, 97.26, 97.26, 97.28, 97.28, 97.28, 97.28, 97.28, 97.28, 97.28, 97.28, 97.36, 97.36, 97.4, 97.4, 97.32, 97.32, 97.3, 97.3, 97.3, 97.3, 97.28, 97.28, 97.32, 97.32, 97.32, 97.32, 97.28, 97.28, 97.3, 97.3, 97.32, 97.32, 97.3, 97.3, 97.34, 97.34, 97.36, 97.36, 97.36, 97.36, 97.34, 97.34, 97.34, 97.34, 97.36, 97.36, 97.36, 97.36, 97.36, 97.36, 97.38, 97.38, 97.42, 97.42, 97.44, 97.44, 97.48, 97.48, 97.42, 97.42, 97.44, 97.44, 97.42, 97.42, 97.44, 97.44, 97.38, 97.38, 97.38, 97.38, 97.44, 97.44, 97.42, 97.42, 97.36, 97.36, 97.38, 97.38, 97.42, 97.42, 97.44, 97.44, 97.5, 97.5, 97.52, 97.52, 97.54, 97.54, 97.54, 97.54, 97.56, 97.56, 97.52, 97.52, 97.52, 97.52, 97.5, 97.5, 97.48, 97.48, 97.52, 97.52, 97.5, 97.5, 97.48, 97.48, 97.44, 97.44]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.4  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Traceback (most recent call last):
  File "main_fedpac_co_teaching.py", line 250, in <module>
    local.filter_data(net=net_local.to(args.device), net2=net_local2.to(args.device), concept_matrix_local = concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1587, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550021 (local), 549696 (global); Percentage 99.94 (549696/550021)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 1.625, Test loss: 1.589, Test accuracy: 37.40
Round   0, Global train loss: 1.625, Global test loss: 1.589, Global test accuracy: 37.44
Round   1, Train loss: 1.574, Test loss: 1.529, Test accuracy: 81.82
Round   1, Global train loss: 1.574, Global test loss: 1.527, Global test accuracy: 82.24
Round   2, Train loss: 1.436, Test loss: 1.238, Test accuracy: 93.02
Round   2, Global train loss: 1.436, Global test loss: 1.211, Global test accuracy: 93.36
Round   3, Train loss: 1.122, Test loss: 1.071, Test accuracy: 95.32
Round   3, Global train loss: 1.122, Global test loss: 1.021, Global test accuracy: 95.24
Round   4, Train loss: 1.011, Test loss: 1.023, Test accuracy: 96.12
Round   4, Global train loss: 1.011, Global test loss: 0.986, Global test accuracy: 96.16
Round   5, Train loss: 1.008, Test loss: 0.993, Test accuracy: 96.40
Round   5, Global train loss: 1.008, Global test loss: 0.975, Global test accuracy: 96.56
Round   6, Train loss: 0.999, Test loss: 0.975, Test accuracy: 96.46
Round   6, Global train loss: 0.999, Global test loss: 0.975, Global test accuracy: 96.46
Round   7, Train loss: 0.983, Test loss: 0.966, Test accuracy: 96.62
Round   7, Global train loss: 0.983, Global test loss: 0.964, Global test accuracy: 96.68
Round   8, Train loss: 0.987, Test loss: 0.959, Test accuracy: 96.90
Round   8, Global train loss: 0.987, Global test loss: 0.958, Global test accuracy: 96.92
Round   9, Train loss: 0.977, Test loss: 0.957, Test accuracy: 96.94
Round   9, Global train loss: 0.977, Global test loss: 0.954, Global test accuracy: 96.88
Round  10, Train loss: 0.964, Test loss: 0.955, Test accuracy: 96.90
Round  10, Global train loss: 0.964, Global test loss: 0.952, Global test accuracy: 96.88
Round  11, Train loss: 0.970, Test loss: 0.950, Test accuracy: 97.00
Round  11, Global train loss: 0.970, Global test loss: 0.950, Global test accuracy: 96.96
Round  12, Train loss: 0.969, Test loss: 0.949, Test accuracy: 97.02
Round  12, Global train loss: 0.969, Global test loss: 0.950, Global test accuracy: 97.04
Round  13, Train loss: 0.967, Test loss: 0.947, Test accuracy: 97.10
Round  13, Global train loss: 0.967, Global test loss: 0.948, Global test accuracy: 97.04
Round  14, Train loss: 0.949, Test loss: 0.946, Test accuracy: 97.24
Round  14, Global train loss: 0.949, Global test loss: 0.942, Global test accuracy: 97.10
Round  15, Train loss: 0.948, Test loss: 0.944, Test accuracy: 97.22
Round  15, Global train loss: 0.948, Global test loss: 0.942, Global test accuracy: 97.04
Round  16, Train loss: 0.947, Test loss: 0.944, Test accuracy: 97.22
Round  16, Global train loss: 0.947, Global test loss: 0.942, Global test accuracy: 97.28
Round  17, Train loss: 0.952, Test loss: 0.943, Test accuracy: 97.40
Round  17, Global train loss: 0.952, Global test loss: 0.941, Global test accuracy: 97.42
Round  18, Train loss: 0.940, Test loss: 0.942, Test accuracy: 97.32
Round  18, Global train loss: 0.940, Global test loss: 0.941, Global test accuracy: 97.30
Round  19, Train loss: 0.946, Test loss: 0.942, Test accuracy: 97.48
Round  19, Global train loss: 0.946, Global test loss: 0.942, Global test accuracy: 97.38
Round  20, Train loss: 0.939, Test loss: 0.941, Test accuracy: 97.48
Round  20, Global train loss: 0.939, Global test loss: 0.940, Global test accuracy: 97.40
Round  21, Train loss: 0.937, Test loss: 0.940, Test accuracy: 97.44
Round  21, Global train loss: 0.937, Global test loss: 0.937, Global test accuracy: 97.50
Round  22, Train loss: 0.949, Test loss: 0.939, Test accuracy: 97.50
Round  22, Global train loss: 0.949, Global test loss: 0.938, Global test accuracy: 97.46
Round  23, Train loss: 0.930, Test loss: 0.939, Test accuracy: 97.54
Round  23, Global train loss: 0.930, Global test loss: 0.936, Global test accuracy: 97.36
Round  24, Train loss: 0.946, Test loss: 0.938, Test accuracy: 97.48
Round  24, Global train loss: 0.946, Global test loss: 0.937, Global test accuracy: 97.46
Round  25, Train loss: 0.940, Test loss: 0.938, Test accuracy: 97.50
Round  25, Global train loss: 0.940, Global test loss: 0.936, Global test accuracy: 97.62
Round  26, Train loss: 0.930, Test loss: 0.937, Test accuracy: 97.62
Round  26, Global train loss: 0.930, Global test loss: 0.936, Global test accuracy: 97.62
Round  27, Train loss: 0.928, Test loss: 0.937, Test accuracy: 97.60
Round  27, Global train loss: 0.928, Global test loss: 0.934, Global test accuracy: 97.70
Round  28, Train loss: 0.932, Test loss: 0.936, Test accuracy: 97.70
Round  28, Global train loss: 0.932, Global test loss: 0.934, Global test accuracy: 97.74
Round  29, Train loss: 0.935, Test loss: 0.935, Test accuracy: 97.72
Round  29, Global train loss: 0.935, Global test loss: 0.933, Global test accuracy: 97.52
Round  30, Train loss: 0.940, Test loss: 0.935, Test accuracy: 97.72
Round  30, Global train loss: 0.940, Global test loss: 0.935, Global test accuracy: 97.82
Round  31, Train loss: 0.932, Test loss: 0.934, Test accuracy: 97.66
Round  31, Global train loss: 0.932, Global test loss: 0.933, Global test accuracy: 97.76
Round  32, Train loss: 0.922, Test loss: 0.934, Test accuracy: 97.80
Round  32, Global train loss: 0.922, Global test loss: 0.933, Global test accuracy: 97.72
Round  33, Train loss: 0.936, Test loss: 0.934, Test accuracy: 97.80
Round  33, Global train loss: 0.936, Global test loss: 0.933, Global test accuracy: 97.62
Round  34, Train loss: 0.924, Test loss: 0.933, Test accuracy: 97.82
Round  34, Global train loss: 0.924, Global test loss: 0.931, Global test accuracy: 97.88
Round  35, Train loss: 0.932, Test loss: 0.933, Test accuracy: 97.82
Round  35, Global train loss: 0.932, Global test loss: 0.931, Global test accuracy: 97.96
Round  36, Train loss: 0.925, Test loss: 0.933, Test accuracy: 97.82
Round  36, Global train loss: 0.925, Global test loss: 0.930, Global test accuracy: 97.96
Round  37, Train loss: 0.929, Test loss: 0.933, Test accuracy: 97.96
Round  37, Global train loss: 0.929, Global test loss: 0.933, Global test accuracy: 97.88
Round  38, Train loss: 0.929, Test loss: 0.932, Test accuracy: 97.98
Round  38, Global train loss: 0.929, Global test loss: 0.932, Global test accuracy: 97.90
Round  39, Train loss: 0.924, Test loss: 0.932, Test accuracy: 97.92
Round  39, Global train loss: 0.924, Global test loss: 0.931, Global test accuracy: 97.94
Round  40, Train loss: 0.934, Test loss: 0.931, Test accuracy: 97.92
Round  40, Global train loss: 0.934, Global test loss: 0.931, Global test accuracy: 98.00
Round  41, Train loss: 0.924, Test loss: 0.931, Test accuracy: 97.94
Round  41, Global train loss: 0.924, Global test loss: 0.929, Global test accuracy: 98.00
Round  42, Train loss: 0.927, Test loss: 0.931, Test accuracy: 97.94
Round  42, Global train loss: 0.927, Global test loss: 0.931, Global test accuracy: 97.94
Round  43, Train loss: 0.926, Test loss: 0.931, Test accuracy: 97.92
Round  43, Global train loss: 0.926, Global test loss: 0.930, Global test accuracy: 97.96
Round  44, Train loss: 0.932, Test loss: 0.931, Test accuracy: 98.04
Round  44, Global train loss: 0.932, Global test loss: 0.930, Global test accuracy: 98.10
Round  45, Train loss: 0.925, Test loss: 0.931, Test accuracy: 97.96
Round  45, Global train loss: 0.925, Global test loss: 0.929, Global test accuracy: 98.08
Round  46, Train loss: 0.929, Test loss: 0.931, Test accuracy: 97.98
Round  46, Global train loss: 0.929, Global test loss: 0.930, Global test accuracy: 98.06
Round  47, Train loss: 0.926, Test loss: 0.931, Test accuracy: 97.98
Round  47, Global train loss: 0.926, Global test loss: 0.930, Global test accuracy: 98.12
Round  48, Train loss: 0.927, Test loss: 0.930, Test accuracy: 97.98
Round  48, Global train loss: 0.927, Global test loss: 0.930, Global test accuracy: 98.08
Round  49, Train loss: 0.924, Test loss: 0.930, Test accuracy: 98.02
Round  49, Global train loss: 0.924, Global test loss: 0.929, Global test accuracy: 98.08
Round  50, Train loss: 0.921, Test loss: 0.930, Test accuracy: 98.04
Round  50, Global train loss: 0.921, Global test loss: 0.929, Global test accuracy: 98.08
Round  51, Train loss: 0.917, Test loss: 0.930, Test accuracy: 98.06
Round  51, Global train loss: 0.917, Global test loss: 0.929, Global test accuracy: 98.08
Round  52, Train loss: 0.923, Test loss: 0.929, Test accuracy: 98.08
Round  52, Global train loss: 0.923, Global test loss: 0.929, Global test accuracy: 98.10
Round  53, Train loss: 0.922, Test loss: 0.929, Test accuracy: 98.06
Round  53, Global train loss: 0.922, Global test loss: 0.929, Global test accuracy: 98.18
Round  54, Train loss: 0.920, Test loss: 0.929, Test accuracy: 98.14
Round  54, Global train loss: 0.920, Global test loss: 0.928, Global test accuracy: 98.20
Round  55, Train loss: 0.917, Test loss: 0.928, Test accuracy: 98.06
Round  55, Global train loss: 0.917, Global test loss: 0.927, Global test accuracy: 98.12
Round  56, Train loss: 0.916, Test loss: 0.929, Test accuracy: 98.12
Round  56, Global train loss: 0.916, Global test loss: 0.928, Global test accuracy: 98.10
Round  57, Train loss: 0.925, Test loss: 0.928, Test accuracy: 98.14
Round  57, Global train loss: 0.925, Global test loss: 0.927, Global test accuracy: 98.24
Round  58, Train loss: 0.920, Test loss: 0.928, Test accuracy: 98.18
Round  58, Global train loss: 0.920, Global test loss: 0.927, Global test accuracy: 98.16
Round  59, Train loss: 0.918, Test loss: 0.928, Test accuracy: 98.18
Round  59, Global train loss: 0.918, Global test loss: 0.927, Global test accuracy: 98.28
Round  60, Train loss: 0.921, Test loss: 0.928, Test accuracy: 98.14
Round  60, Global train loss: 0.921, Global test loss: 0.927, Global test accuracy: 98.28
Round  61, Train loss: 0.916, Test loss: 0.928, Test accuracy: 98.18
Round  61, Global train loss: 0.916, Global test loss: 0.927, Global test accuracy: 98.00
Round  62, Train loss: 0.920, Test loss: 0.928, Test accuracy: 98.24
Round  62, Global train loss: 0.920, Global test loss: 0.927, Global test accuracy: 98.22
Round  63, Train loss: 0.916, Test loss: 0.927, Test accuracy: 98.12
Round  63, Global train loss: 0.916, Global test loss: 0.927, Global test accuracy: 98.30
Round  64, Train loss: 0.919, Test loss: 0.928, Test accuracy: 98.14
Round  64, Global train loss: 0.919, Global test loss: 0.926, Global test accuracy: 98.26
Round  65, Train loss: 0.921, Test loss: 0.927, Test accuracy: 98.20
Round  65, Global train loss: 0.921, Global test loss: 0.927, Global test accuracy: 98.20
Round  66, Train loss: 0.915, Test loss: 0.928, Test accuracy: 98.14
Round  66, Global train loss: 0.915, Global test loss: 0.927, Global test accuracy: 98.22
Round  67, Train loss: 0.918, Test loss: 0.927, Test accuracy: 98.08
Round  67, Global train loss: 0.918, Global test loss: 0.926, Global test accuracy: 98.26
Round  68, Train loss: 0.919, Test loss: 0.927, Test accuracy: 98.20
Round  68, Global train loss: 0.919, Global test loss: 0.926, Global test accuracy: 98.32
Round  69, Train loss: 0.920, Test loss: 0.927, Test accuracy: 98.18
Round  69, Global train loss: 0.920, Global test loss: 0.926, Global test accuracy: 98.24
Round  70, Train loss: 0.919, Test loss: 0.927, Test accuracy: 98.14
Round  70, Global train loss: 0.919, Global test loss: 0.926, Global test accuracy: 98.26
Round  71, Train loss: 0.920, Test loss: 0.927, Test accuracy: 98.16
Round  71, Global train loss: 0.920, Global test loss: 0.926, Global test accuracy: 98.32
Round  72, Train loss: 0.920, Test loss: 0.926, Test accuracy: 98.20
Round  72, Global train loss: 0.920, Global test loss: 0.927, Global test accuracy: 98.22
Round  73, Train loss: 0.921, Test loss: 0.926, Test accuracy: 98.22
Round  73, Global train loss: 0.921, Global test loss: 0.926, Global test accuracy: 98.32
Round  74, Train loss: 0.916, Test loss: 0.926, Test accuracy: 98.18
Round  74, Global train loss: 0.916, Global test loss: 0.926, Global test accuracy: 98.22
Round  75, Train loss: 0.916, Test loss: 0.926, Test accuracy: 98.22
Round  75, Global train loss: 0.916, Global test loss: 0.925, Global test accuracy: 98.28
Round  76, Train loss: 0.915, Test loss: 0.926, Test accuracy: 98.20
Round  76, Global train loss: 0.915, Global test loss: 0.925, Global test accuracy: 98.26
Round  77, Train loss: 0.917, Test loss: 0.926, Test accuracy: 98.20
Round  77, Global train loss: 0.917, Global test loss: 0.926, Global test accuracy: 98.36
Round  78, Train loss: 0.918, Test loss: 0.926, Test accuracy: 98.18
Round  78, Global train loss: 0.918, Global test loss: 0.925, Global test accuracy: 98.38
Round  79, Train loss: 0.915, Test loss: 0.926, Test accuracy: 98.16
Round  79, Global train loss: 0.915, Global test loss: 0.925, Global test accuracy: 98.24
Round  80, Train loss: 0.916, Test loss: 0.926, Test accuracy: 98.18
Round  80, Global train loss: 0.916, Global test loss: 0.925, Global test accuracy: 98.20
Round  81, Train loss: 0.915, Test loss: 0.926, Test accuracy: 98.14
Round  81, Global train loss: 0.915, Global test loss: 0.925, Global test accuracy: 98.26
Round  82, Train loss: 0.917, Test loss: 0.926, Test accuracy: 98.16
Round  82, Global train loss: 0.917, Global test loss: 0.926, Global test accuracy: 98.14
Round  83, Train loss: 0.915, Test loss: 0.926, Test accuracy: 98.26
Round  83, Global train loss: 0.915, Global test loss: 0.925, Global test accuracy: 98.34
Round  84, Train loss: 0.915, Test loss: 0.926, Test accuracy: 98.16
Round  84, Global train loss: 0.915, Global test loss: 0.925, Global test accuracy: 98.24
Round  85, Train loss: 0.917, Test loss: 0.925, Test accuracy: 98.24
Round  85, Global train loss: 0.917, Global test loss: 0.925, Global test accuracy: 98.26
Round  86, Train loss: 0.914, Test loss: 0.926, Test accuracy: 98.24
Round  86, Global train loss: 0.914, Global test loss: 0.924, Global test accuracy: 98.30
Round  87, Train loss: 0.911, Test loss: 0.925, Test accuracy: 98.22
Round  87, Global train loss: 0.911, Global test loss: 0.924, Global test accuracy: 98.36
Round  88, Train loss: 0.915, Test loss: 0.925, Test accuracy: 98.22
Round  88, Global train loss: 0.915, Global test loss: 0.925, Global test accuracy: 98.28
Round  89, Train loss: 0.917, Test loss: 0.925, Test accuracy: 98.26
Round  89, Global train loss: 0.917, Global test loss: 0.924, Global test accuracy: 98.34
Round  90, Train loss: 0.913, Test loss: 0.926, Test accuracy: 98.26
Round  90, Global train loss: 0.913, Global test loss: 0.924, Global test accuracy: 98.42
Round  91, Train loss: 0.913, Test loss: 0.926, Test accuracy: 98.30
Round  91, Global train loss: 0.913, Global test loss: 0.925, Global test accuracy: 98.46
Round  92, Train loss: 0.911, Test loss: 0.925, Test accuracy: 98.26
Round  92, Global train loss: 0.911, Global test loss: 0.925, Global test accuracy: 98.28/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  93, Train loss: 0.916, Test loss: 0.925, Test accuracy: 98.34
Round  93, Global train loss: 0.916, Global test loss: 0.924, Global test accuracy: 98.36
Round  94, Train loss: 0.915, Test loss: 0.925, Test accuracy: 98.34
Round  94, Global train loss: 0.915, Global test loss: 0.925, Global test accuracy: 98.40
Round  95, Train loss: 0.912, Test loss: 0.925, Test accuracy: 98.24
Round  95, Global train loss: 0.912, Global test loss: 0.925, Global test accuracy: 98.34
Round  96, Train loss: 0.913, Test loss: 0.925, Test accuracy: 98.32
Round  96, Global train loss: 0.913, Global test loss: 0.925, Global test accuracy: 98.48
Round  97, Train loss: 0.912, Test loss: 0.925, Test accuracy: 98.26
Round  97, Global train loss: 0.912, Global test loss: 0.924, Global test accuracy: 98.42
Round  98, Train loss: 0.915, Test loss: 0.925, Test accuracy: 98.26
Round  98, Global train loss: 0.915, Global test loss: 0.925, Global test accuracy: 98.38
Round  99, Train loss: 0.913, Test loss: 0.925, Test accuracy: 98.30
Round  99, Global train loss: 0.913, Global test loss: 0.924, Global test accuracy: 98.48
Final Round, Train loss: 0.910, Test loss: 0.925, Test accuracy: 98.30
Final Round, Global train loss: 0.910, Global test loss: 0.924, Global test accuracy: 98.48
Average accuracy final 10 rounds: 98.288
451.6701331138611
[0.9904258251190186, 1.864192247390747, 2.729170322418213, 3.593825101852417, 4.457329988479614, 5.309346914291382, 6.190272092819214, 7.055082321166992, 7.925912380218506, 8.774329900741577, 9.641294479370117, 10.52662444114685, 11.411268949508667, 12.281949520111084, 13.121116876602173, 13.980116128921509, 14.85154914855957, 15.728220224380493, 16.58118224143982, 17.447789430618286, 18.306477069854736, 19.17529058456421, 20.051034212112427, 20.889345407485962, 21.75104260444641, 22.62860083580017, 23.498927354812622, 24.353818655014038, 25.208075761795044, 26.07302689552307, 26.946892738342285, 27.792263507843018, 28.624516487121582, 29.474974155426025, 30.314619541168213, 31.158186674118042, 32.00837802886963, 32.839194774627686, 33.68544268608093, 34.537781715393066, 35.38677406311035, 36.25615358352661, 37.08904504776001, 37.94231963157654, 38.80067300796509, 39.653733253479004, 40.50374674797058, 41.33723282814026, 42.18964385986328, 43.06644296646118, 43.9109628200531, 44.76467180252075, 45.61331343650818, 46.47568964958191, 47.324604749679565, 48.178404092788696, 49.03309464454651, 49.89170742034912, 50.76410937309265, 51.6385498046875, 52.46918869018555, 53.30088567733765, 54.138532876968384, 54.97751021385193, 55.822617530822754, 56.65659832954407, 57.511921644210815, 58.35659575462341, 59.20159292221069, 60.04927921295166, 60.87748694419861, 61.73787999153137, 62.578386545181274, 63.44491386413574, 64.28453588485718, 65.075603723526, 65.90020155906677, 66.75116109848022, 67.58598589897156, 68.40666055679321, 69.24949169158936, 70.11010932922363, 70.95793890953064, 71.80201554298401, 72.61552143096924, 73.47053003311157, 74.3117163181305, 75.15976357460022, 76.00744724273682, 76.84037613868713, 77.70114922523499, 78.5501856803894, 79.39294481277466, 80.23414134979248, 81.09222197532654, 81.98377108573914, 82.84605121612549, 83.69046306610107, 84.52505898475647, 85.37104940414429, 86.64974164962769]
[37.4, 81.82, 93.02, 95.32, 96.12, 96.4, 96.46, 96.62, 96.9, 96.94, 96.9, 97.0, 97.02, 97.1, 97.24, 97.22, 97.22, 97.4, 97.32, 97.48, 97.48, 97.44, 97.5, 97.54, 97.48, 97.5, 97.62, 97.6, 97.7, 97.72, 97.72, 97.66, 97.8, 97.8, 97.82, 97.82, 97.82, 97.96, 97.98, 97.92, 97.92, 97.94, 97.94, 97.92, 98.04, 97.96, 97.98, 97.98, 97.98, 98.02, 98.04, 98.06, 98.08, 98.06, 98.14, 98.06, 98.12, 98.14, 98.18, 98.18, 98.14, 98.18, 98.24, 98.12, 98.14, 98.2, 98.14, 98.08, 98.2, 98.18, 98.14, 98.16, 98.2, 98.22, 98.18, 98.22, 98.2, 98.2, 98.18, 98.16, 98.18, 98.14, 98.16, 98.26, 98.16, 98.24, 98.24, 98.22, 98.22, 98.26, 98.26, 98.3, 98.26, 98.34, 98.34, 98.24, 98.32, 98.26, 98.26, 98.3, 98.3]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fedpac_copsl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist,  filter_alg: loss_psl, level_n_system: 0.0 , level_n_lowerb:0.4  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550021 (local), 549696 (global); Percentage 99.94 (549696/550021)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 1.619, Test loss: 1.578, Test accuracy: 51.44
Round   0, Global train loss: 1.619, Global test loss: 1.578, Global test accuracy: 51.22
Round   1, Train loss: 1.540, Test loss: 1.436, Test accuracy: 74.48
Round   1, Global train loss: 1.540, Global test loss: 1.435, Global test accuracy: 74.32
Round   2, Train loss: 1.350, Test loss: 1.196, Test accuracy: 81.48
Round   2, Global train loss: 1.350, Global test loss: 1.196, Global test accuracy: 81.46
Round   3, Train loss: 1.122, Test loss: 1.030, Test accuracy: 93.96
Round   3, Global train loss: 1.122, Global test loss: 1.030, Global test accuracy: 94.24
Round   4, Train loss: 1.016, Test loss: 0.982, Test accuracy: 95.96
Round   4, Global train loss: 1.016, Global test loss: 0.981, Global test accuracy: 95.98
Round   5, Train loss: 0.987, Test loss: 0.967, Test accuracy: 96.34
Round   5, Global train loss: 0.987, Global test loss: 0.965, Global test accuracy: 96.44
Round   6, Train loss: 0.973, Test loss: 0.958, Test accuracy: 96.66
Round   6, Global train loss: 0.973, Global test loss: 0.956, Global test accuracy: 96.74
Round   7, Train loss: 0.965, Test loss: 0.953, Test accuracy: 96.96
Round   7, Global train loss: 0.965, Global test loss: 0.952, Global test accuracy: 97.00
Round   8, Train loss: 0.960, Test loss: 0.949, Test accuracy: 97.04
Round   8, Global train loss: 0.960, Global test loss: 0.948, Global test accuracy: 97.22
Round   9, Train loss: 0.955, Test loss: 0.947, Test accuracy: 97.14
Round   9, Global train loss: 0.955, Global test loss: 0.946, Global test accuracy: 97.26
Round  10, Train loss: 0.942, Test loss: 0.947, Test accuracy: 97.02
Round  10, Global train loss: 0.942, Global test loss: 0.945, Global test accuracy: 96.94
Traceback (most recent call last):
  File "main_fedpac_copsl.py", line 280, in <module>
    w_local, loss, indd, class_center_local, class_num, noisy_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys,
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2559, in train
    self.filter_data(net, local_net, iter2-head_eps+1, local_eps-head_eps+1, concept_matrix_local)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2396, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist, level_n_system: 0.2 , level_n_lowerb:0.4  

   Client 6, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.572, Test loss: 1.480, Test accuracy: 61.30
Round   0, Global train loss: 1.572, Global test loss: 1.482, Global test accuracy: 61.42
Round   1, Train loss: 1.248, Test loss: 1.171, Test accuracy: 83.48
Round   1, Global train loss: 1.248, Global test loss: 1.038, Global test accuracy: 93.54
Round   2, Train loss: 1.035, Test loss: 1.093, Test accuracy: 87.78
Round   2, Global train loss: 1.035, Global test loss: 0.983, Global test accuracy: 95.08
Round   3, Train loss: 1.168, Test loss: 1.041, Test accuracy: 91.40
Round   3, Global train loss: 1.168, Global test loss: 0.984, Global test accuracy: 95.32
Round   4, Train loss: 1.051, Test loss: 1.033, Test accuracy: 91.68
Round   4, Global train loss: 1.051, Global test loss: 0.960, Global test accuracy: 96.22
Round   5, Train loss: 1.055, Test loss: 0.990, Test accuracy: 94.74
Round   5, Global train loss: 1.055, Global test loss: 0.962, Global test accuracy: 96.64
Round   6, Train loss: 0.948, Test loss: 0.979, Test accuracy: 94.94
Round   6, Global train loss: 0.948, Global test loss: 0.958, Global test accuracy: 96.26
Round   7, Train loss: 1.045, Test loss: 0.969, Test accuracy: 95.08
Round   7, Global train loss: 1.045, Global test loss: 0.960, Global test accuracy: 96.10
Round   8, Train loss: 0.928, Test loss: 0.967, Test accuracy: 95.30
Round   8, Global train loss: 0.928, Global test loss: 0.948, Global test accuracy: 96.70
Round   9, Train loss: 0.931, Test loss: 0.965, Test accuracy: 95.34
Round   9, Global train loss: 0.931, Global test loss: 0.949, Global test accuracy: 96.54
Round  10, Train loss: 1.030, Test loss: 0.964, Test accuracy: 95.24
Round  10, Global train loss: 1.030, Global test loss: 0.951, Global test accuracy: 96.32
Round  11, Train loss: 0.921, Test loss: 0.964, Test accuracy: 95.24
Round  11, Global train loss: 0.921, Global test loss: 0.950, Global test accuracy: 96.44
Round  12, Train loss: 0.924, Test loss: 0.962, Test accuracy: 95.32
Round  12, Global train loss: 0.924, Global test loss: 0.954, Global test accuracy: 96.02
Round  13, Train loss: 1.022, Test loss: 0.962, Test accuracy: 95.20
Round  13, Global train loss: 1.022, Global test loss: 0.951, Global test accuracy: 96.18
Round  14, Train loss: 1.013, Test loss: 0.962, Test accuracy: 95.02
Round  14, Global train loss: 1.013, Global test loss: 0.953, Global test accuracy: 96.12
Round  15, Train loss: 0.918, Test loss: 0.962, Test accuracy: 94.98
Round  15, Global train loss: 0.918, Global test loss: 0.947, Global test accuracy: 96.48
Round  16, Train loss: 0.919, Test loss: 0.961, Test accuracy: 95.00
Round  16, Global train loss: 0.919, Global test loss: 0.953, Global test accuracy: 96.06
Round  17, Train loss: 1.005, Test loss: 0.961, Test accuracy: 95.02
Round  17, Global train loss: 1.005, Global test loss: 0.949, Global test accuracy: 95.96
Round  18, Train loss: 0.914, Test loss: 0.961, Test accuracy: 95.00
Round  18, Global train loss: 0.914, Global test loss: 0.943, Global test accuracy: 96.66
Round  19, Train loss: 1.010, Test loss: 0.961, Test accuracy: 94.94
Round  19, Global train loss: 1.010, Global test loss: 0.948, Global test accuracy: 96.62
Round  20, Train loss: 1.008, Test loss: 0.961, Test accuracy: 94.88
Round  20, Global train loss: 1.008, Global test loss: 0.952, Global test accuracy: 96.18
Round  21, Train loss: 0.913, Test loss: 0.961, Test accuracy: 94.96
Round  21, Global train loss: 0.913, Global test loss: 0.943, Global test accuracy: 96.54
Round  22, Train loss: 0.912, Test loss: 0.961, Test accuracy: 94.94
Round  22, Global train loss: 0.912, Global test loss: 0.944, Global test accuracy: 96.60
Round  23, Train loss: 0.919, Test loss: 0.960, Test accuracy: 95.08
Round  23, Global train loss: 0.919, Global test loss: 0.947, Global test accuracy: 96.56
Round  24, Train loss: 1.016, Test loss: 0.959, Test accuracy: 95.26
Round  24, Global train loss: 1.016, Global test loss: 0.945, Global test accuracy: 96.44
Round  25, Train loss: 0.916, Test loss: 0.958, Test accuracy: 95.26
Round  25, Global train loss: 0.916, Global test loss: 0.944, Global test accuracy: 96.62
Round  26, Train loss: 0.910, Test loss: 0.958, Test accuracy: 95.30
Round  26, Global train loss: 0.910, Global test loss: 0.948, Global test accuracy: 96.14
Round  27, Train loss: 0.916, Test loss: 0.958, Test accuracy: 95.22
Round  27, Global train loss: 0.916, Global test loss: 0.945, Global test accuracy: 96.40
Round  28, Train loss: 0.912, Test loss: 0.958, Test accuracy: 95.24
Round  28, Global train loss: 0.912, Global test loss: 0.948, Global test accuracy: 95.80
Round  29, Train loss: 0.912, Test loss: 0.958, Test accuracy: 95.24
Round  29, Global train loss: 0.912, Global test loss: 0.945, Global test accuracy: 96.18
Round  30, Train loss: 0.911, Test loss: 0.957, Test accuracy: 95.18
Round  30, Global train loss: 0.911, Global test loss: 0.944, Global test accuracy: 96.42
Round  31, Train loss: 0.910, Test loss: 0.957, Test accuracy: 95.18
Round  31, Global train loss: 0.910, Global test loss: 0.943, Global test accuracy: 96.60
Round  32, Train loss: 0.912, Test loss: 0.957, Test accuracy: 95.20
Round  32, Global train loss: 0.912, Global test loss: 0.943, Global test accuracy: 96.78
Round  33, Train loss: 0.908, Test loss: 0.957, Test accuracy: 95.20
Round  33, Global train loss: 0.908, Global test loss: 0.945, Global test accuracy: 96.56
Round  34, Train loss: 0.911, Test loss: 0.957, Test accuracy: 95.16
Round  34, Global train loss: 0.911, Global test loss: 0.946, Global test accuracy: 96.10
Round  35, Train loss: 0.915, Test loss: 0.957, Test accuracy: 95.18
Round  35, Global train loss: 0.915, Global test loss: 0.942, Global test accuracy: 96.40
Round  36, Train loss: 1.015, Test loss: 0.957, Test accuracy: 95.24
Round  36, Global train loss: 1.015, Global test loss: 0.944, Global test accuracy: 96.60
Round  37, Train loss: 0.914, Test loss: 0.957, Test accuracy: 95.20
Round  37, Global train loss: 0.914, Global test loss: 0.942, Global test accuracy: 96.48
Round  38, Train loss: 0.910, Test loss: 0.957, Test accuracy: 95.18
Round  38, Global train loss: 0.910, Global test loss: 0.942, Global test accuracy: 96.38
Round  39, Train loss: 1.013, Test loss: 0.957, Test accuracy: 95.14
Round  39, Global train loss: 1.013, Global test loss: 0.950, Global test accuracy: 96.20
Round  40, Train loss: 0.911, Test loss: 0.957, Test accuracy: 95.12
Round  40, Global train loss: 0.911, Global test loss: 0.944, Global test accuracy: 96.72
Round  41, Train loss: 1.002, Test loss: 0.957, Test accuracy: 95.14
Round  41, Global train loss: 1.002, Global test loss: 0.947, Global test accuracy: 96.22
Round  42, Train loss: 1.101, Test loss: 0.957, Test accuracy: 95.12
Round  42, Global train loss: 1.101, Global test loss: 0.948, Global test accuracy: 96.12
Round  43, Train loss: 1.005, Test loss: 0.957, Test accuracy: 95.12
Round  43, Global train loss: 1.005, Global test loss: 0.946, Global test accuracy: 96.64
Round  44, Train loss: 0.909, Test loss: 0.957, Test accuracy: 95.12
Round  44, Global train loss: 0.909, Global test loss: 0.942, Global test accuracy: 96.60
Round  45, Train loss: 1.010, Test loss: 0.957, Test accuracy: 95.14
Round  45, Global train loss: 1.010, Global test loss: 0.944, Global test accuracy: 96.42
Round  46, Train loss: 0.910, Test loss: 0.957, Test accuracy: 95.14
Round  46, Global train loss: 0.910, Global test loss: 0.943, Global test accuracy: 96.44
Round  47, Train loss: 0.911, Test loss: 0.957, Test accuracy: 95.14
Round  47, Global train loss: 0.911, Global test loss: 0.948, Global test accuracy: 96.18
Round  48, Train loss: 1.002, Test loss: 0.957, Test accuracy: 95.10
Round  48, Global train loss: 1.002, Global test loss: 0.947, Global test accuracy: 96.10
Round  49, Train loss: 0.908, Test loss: 0.957, Test accuracy: 95.10
Round  49, Global train loss: 0.908, Global test loss: 0.946, Global test accuracy: 95.98
Round  50, Train loss: 0.915, Test loss: 0.957, Test accuracy: 95.10
Round  50, Global train loss: 0.915, Global test loss: 0.945, Global test accuracy: 96.40
Round  51, Train loss: 1.000, Test loss: 0.957, Test accuracy: 95.08
Round  51, Global train loss: 1.000, Global test loss: 0.945, Global test accuracy: 96.46
Round  52, Train loss: 0.911, Test loss: 0.957, Test accuracy: 95.08
Round  52, Global train loss: 0.911, Global test loss: 0.941, Global test accuracy: 96.80
Round  53, Train loss: 1.098, Test loss: 0.957, Test accuracy: 95.02
Round  53, Global train loss: 1.098, Global test loss: 0.945, Global test accuracy: 96.44
Round  54, Train loss: 1.004, Test loss: 0.957, Test accuracy: 94.98
Round  54, Global train loss: 1.004, Global test loss: 0.942, Global test accuracy: 96.46
Round  55, Train loss: 0.911, Test loss: 0.957, Test accuracy: 95.00
Round  55, Global train loss: 0.911, Global test loss: 0.944, Global test accuracy: 96.18
Round  56, Train loss: 1.092, Test loss: 0.958, Test accuracy: 94.90
Round  56, Global train loss: 1.092, Global test loss: 0.948, Global test accuracy: 96.18
Round  57, Train loss: 0.999, Test loss: 0.958, Test accuracy: 94.88
Round  57, Global train loss: 0.999, Global test loss: 0.945, Global test accuracy: 96.28
Round  58, Train loss: 0.914, Test loss: 0.958, Test accuracy: 94.88
Round  58, Global train loss: 0.914, Global test loss: 0.943, Global test accuracy: 96.42
Round  59, Train loss: 0.907, Test loss: 0.958, Test accuracy: 94.88
Round  59, Global train loss: 0.907, Global test loss: 0.941, Global test accuracy: 96.62
Round  60, Train loss: 0.910, Test loss: 0.958, Test accuracy: 94.90
Round  60, Global train loss: 0.910, Global test loss: 0.943, Global test accuracy: 96.32
Round  61, Train loss: 0.910, Test loss: 0.958, Test accuracy: 94.90
Round  61, Global train loss: 0.910, Global test loss: 0.941, Global test accuracy: 96.66
Round  62, Train loss: 1.006, Test loss: 0.958, Test accuracy: 94.92
Round  62, Global train loss: 1.006, Global test loss: 0.944, Global test accuracy: 96.32
Round  63, Train loss: 1.093, Test loss: 0.958, Test accuracy: 95.00
Round  63, Global train loss: 1.093, Global test loss: 0.946, Global test accuracy: 96.20
Round  64, Train loss: 0.912, Test loss: 0.958, Test accuracy: 95.00
Round  64, Global train loss: 0.912, Global test loss: 0.941, Global test accuracy: 96.62
Round  65, Train loss: 1.000, Test loss: 0.958, Test accuracy: 95.00
Round  65, Global train loss: 1.000, Global test loss: 0.948, Global test accuracy: 95.98
Round  66, Train loss: 0.996, Test loss: 0.958, Test accuracy: 95.02
Round  66, Global train loss: 0.996, Global test loss: 0.946, Global test accuracy: 96.16
Round  67, Train loss: 1.003, Test loss: 0.958, Test accuracy: 94.96
Round  67, Global train loss: 1.003, Global test loss: 0.941, Global test accuracy: 96.42
Round  68, Train loss: 1.090, Test loss: 0.958, Test accuracy: 94.96
Round  68, Global train loss: 1.090, Global test loss: 0.950, Global test accuracy: 95.82
Round  69, Train loss: 0.999, Test loss: 0.958, Test accuracy: 94.94
Round  69, Global train loss: 0.999, Global test loss: 0.947, Global test accuracy: 96.00
Round  70, Train loss: 1.000, Test loss: 0.958, Test accuracy: 94.94
Round  70, Global train loss: 1.000, Global test loss: 0.947, Global test accuracy: 95.94
Round  71, Train loss: 1.001, Test loss: 0.958, Test accuracy: 94.92
Round  71, Global train loss: 1.001, Global test loss: 0.945, Global test accuracy: 96.24
Round  72, Train loss: 0.910, Test loss: 0.958, Test accuracy: 94.96
Round  72, Global train loss: 0.910, Global test loss: 0.942, Global test accuracy: 96.76
Round  73, Train loss: 0.911, Test loss: 0.958, Test accuracy: 94.94
Round  73, Global train loss: 0.911, Global test loss: 0.940, Global test accuracy: 96.56
Round  74, Train loss: 0.910, Test loss: 0.958, Test accuracy: 94.94
Round  74, Global train loss: 0.910, Global test loss: 0.944, Global test accuracy: 96.12
Round  75, Train loss: 1.000, Test loss: 0.958, Test accuracy: 94.92
Round  75, Global train loss: 1.000, Global test loss: 0.944, Global test accuracy: 96.32
Round  76, Train loss: 1.001, Test loss: 0.958, Test accuracy: 94.86
Round  76, Global train loss: 1.001, Global test loss: 0.946, Global test accuracy: 96.08
Round  77, Train loss: 1.003, Test loss: 0.958, Test accuracy: 94.86
Round  77, Global train loss: 1.003, Global test loss: 0.944, Global test accuracy: 96.30
Round  78, Train loss: 1.002, Test loss: 0.958, Test accuracy: 94.90
Round  78, Global train loss: 1.002, Global test loss: 0.943, Global test accuracy: 96.50
Round  79, Train loss: 1.089, Test loss: 0.958, Test accuracy: 94.86
Round  79, Global train loss: 1.089, Global test loss: 0.947, Global test accuracy: 96.06
Round  80, Train loss: 1.002, Test loss: 0.958, Test accuracy: 94.86
Round  80, Global train loss: 1.002, Global test loss: 0.944, Global test accuracy: 96.36
Round  81, Train loss: 1.001, Test loss: 0.958, Test accuracy: 94.88
Round  81, Global train loss: 1.001, Global test loss: 0.946, Global test accuracy: 96.34
Round  82, Train loss: 1.090, Test loss: 0.958, Test accuracy: 94.88
Round  82, Global train loss: 1.090, Global test loss: 0.950, Global test accuracy: 95.62
Round  83, Train loss: 0.996, Test loss: 0.958, Test accuracy: 94.90
Round  83, Global train loss: 0.996, Global test loss: 0.945, Global test accuracy: 96.16
Round  84, Train loss: 1.089, Test loss: 0.959, Test accuracy: 94.82
Round  84, Global train loss: 1.089, Global test loss: 0.950, Global test accuracy: 95.62
Round  85, Train loss: 0.994, Test loss: 0.959, Test accuracy: 94.86
Round  85, Global train loss: 0.994, Global test loss: 0.952, Global test accuracy: 95.52
Round  86, Train loss: 0.997, Test loss: 0.958, Test accuracy: 94.84
Round  86, Global train loss: 0.997, Global test loss: 0.948, Global test accuracy: 95.88
Round  87, Train loss: 1.087, Test loss: 0.959, Test accuracy: 94.84
Round  87, Global train loss: 1.087, Global test loss: 0.947, Global test accuracy: 95.98
Round  88, Train loss: 0.995, Test loss: 0.959, Test accuracy: 94.82
Round  88, Global train loss: 0.995, Global test loss: 0.947, Global test accuracy: 95.86
Round  89, Train loss: 0.992, Test loss: 0.959, Test accuracy: 94.82
Round  89, Global train loss: 0.992, Global test loss: 0.952, Global test accuracy: 95.44
Round  90, Train loss: 0.910, Test loss: 0.959, Test accuracy: 94.82
Round  90, Global train loss: 0.910, Global test loss: 0.943, Global test accuracy: 96.30
Round  91, Train loss: 0.910, Test loss: 0.959, Test accuracy: 94.80
Round  91, Global train loss: 0.910, Global test loss: 0.944, Global test accuracy: 96.10
Round  92, Train loss: 0.995, Test loss: 0.959, Test accuracy: 94.82
Round  92, Global train loss: 0.995, Global test loss: 0.945, Global test accuracy: 96.20
Round  93, Train loss: 0.909, Test loss: 0.959, Test accuracy: 94.82
Round  93, Global train loss: 0.909, Global test loss: 0.942, Global test accuracy: 96.64
Round  94, Train loss: 0.910, Test loss: 0.959, Test accuracy: 94.82
Round  94, Global train loss: 0.910, Global test loss: 0.942, Global test accuracy: 96.36
Round  95, Train loss: 0.995, Test loss: 0.959, Test accuracy: 94.80
Round  95, Global train loss: 0.995, Global test loss: 0.947, Global test accuracy: 95.92/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 1.085, Test loss: 0.959, Test accuracy: 94.82
Round  96, Global train loss: 1.085, Global test loss: 0.950, Global test accuracy: 95.60
Round  97, Train loss: 0.911, Test loss: 0.959, Test accuracy: 94.84
Round  97, Global train loss: 0.911, Global test loss: 0.943, Global test accuracy: 96.50
Round  98, Train loss: 0.914, Test loss: 0.959, Test accuracy: 94.84
Round  98, Global train loss: 0.914, Global test loss: 0.940, Global test accuracy: 96.78
Round  99, Train loss: 0.912, Test loss: 0.959, Test accuracy: 94.84
Round  99, Global train loss: 0.912, Global test loss: 0.942, Global test accuracy: 96.76
Final Round, Train loss: 0.963, Test loss: 0.959, Test accuracy: 94.74
Final Round, Global train loss: 0.963, Global test loss: 0.942, Global test accuracy: 96.76
Average accuracy final 10 rounds: 94.82199999999999 

Average global accuracy final 10 rounds: 96.316 

499.7311108112335
[0.8238508701324463, 1.6477017402648926, 2.379852771759033, 3.112003803253174, 3.8187994956970215, 4.525595188140869, 5.212195873260498, 5.898796558380127, 6.612161874771118, 7.325527191162109, 8.068337678909302, 8.811148166656494, 9.533599853515625, 10.256051540374756, 10.985080480575562, 11.714109420776367, 12.475385665893555, 13.236661911010742, 13.969501256942749, 14.702340602874756, 15.440008878707886, 16.177677154541016, 16.94149661064148, 17.705316066741943, 18.407304048538208, 19.109292030334473, 19.82040786743164, 20.53152370452881, 21.242135763168335, 21.95274782180786, 22.68982696533203, 23.4269061088562, 24.158480167388916, 24.89005422592163, 25.611358642578125, 26.33266305923462, 27.07719898223877, 27.82173490524292, 28.543388843536377, 29.265042781829834, 29.980391025543213, 30.695739269256592, 31.42503595352173, 32.154332637786865, 32.89075994491577, 33.62718725204468, 34.37170624732971, 35.116225242614746, 35.8611159324646, 36.60600662231445, 37.349472999572754, 38.092939376831055, 38.83169937133789, 39.57045936584473, 40.31434345245361, 41.0582275390625, 41.80166554450989, 42.545103549957275, 43.281410694122314, 44.01771783828735, 44.75926351547241, 45.50080919265747, 46.23794078826904, 46.975072383880615, 47.7348735332489, 48.49467468261719, 49.21585178375244, 49.937028884887695, 50.66845178604126, 51.399874687194824, 52.12149667739868, 52.84311866760254, 53.56580352783203, 54.28848838806152, 55.00909924507141, 55.7297101020813, 56.46845769882202, 57.207205295562744, 57.916605710983276, 58.62600612640381, 59.33006930351257, 60.03413248062134, 60.7212290763855, 61.40832567214966, 62.11228156089783, 62.816237449645996, 63.5156307220459, 64.2150239944458, 64.94889760017395, 65.6827712059021, 66.39884233474731, 67.11491346359253, 67.81297087669373, 68.51102828979492, 69.24060273170471, 69.9701771736145, 70.67112040519714, 71.37206363677979, 72.07878708839417, 72.78551054000854, 73.49318933486938, 74.20086812973022, 74.90136384963989, 75.60185956954956, 76.30245518684387, 77.00305080413818, 77.70824956893921, 78.41344833374023, 79.09982299804688, 79.78619766235352, 80.4892086982727, 81.1922197341919, 81.91942358016968, 82.64662742614746, 83.34490323066711, 84.04317903518677, 84.73665857315063, 85.4301381111145, 86.13162088394165, 86.8331036567688, 87.53026270866394, 88.22742176055908, 88.9226427078247, 89.61786365509033, 90.3218035697937, 91.02574348449707, 91.74127459526062, 92.45680570602417, 93.15938210487366, 93.86195850372314, 94.5714282989502, 95.28089809417725, 95.9985339641571, 96.71616983413696, 97.42975544929504, 98.14334106445312, 98.87772274017334, 99.61210441589355, 100.32938933372498, 101.0466742515564, 101.77435088157654, 102.50202751159668, 103.23343586921692, 103.96484422683716, 104.67001581192017, 105.37518739700317, 106.08265733718872, 106.79012727737427, 107.49324631690979, 108.19636535644531, 108.92207455635071, 109.6477837562561, 110.36338901519775, 111.0789942741394, 111.7842812538147, 112.48956823348999, 113.1930079460144, 113.89644765853882, 114.59423184394836, 115.29201602935791, 115.97026872634888, 116.64852142333984, 117.35224032402039, 118.05595922470093, 118.76317429542542, 119.4703893661499, 120.19265031814575, 120.9149112701416, 121.60720658302307, 122.29950189590454, 123.0337142944336, 123.76792669296265, 124.48758602142334, 125.20724534988403, 125.91476845741272, 126.6222915649414, 127.35412240028381, 128.08595323562622, 128.79462695121765, 129.50330066680908, 130.20340585708618, 130.90351104736328, 131.6177408695221, 132.3319706916809, 133.03611373901367, 133.74025678634644, 134.42404794692993, 135.10783910751343, 135.81935667991638, 136.53087425231934, 137.23678135871887, 137.9426884651184, 138.66575646400452, 139.38882446289062, 140.07062816619873, 140.75243186950684, 141.4572651386261, 142.16209840774536, 142.86515021324158, 143.5682020187378, 144.9945468902588, 146.42089176177979]
[61.3, 61.3, 83.48, 83.48, 87.78, 87.78, 91.4, 91.4, 91.68, 91.68, 94.74, 94.74, 94.94, 94.94, 95.08, 95.08, 95.3, 95.3, 95.34, 95.34, 95.24, 95.24, 95.24, 95.24, 95.32, 95.32, 95.2, 95.2, 95.02, 95.02, 94.98, 94.98, 95.0, 95.0, 95.02, 95.02, 95.0, 95.0, 94.94, 94.94, 94.88, 94.88, 94.96, 94.96, 94.94, 94.94, 95.08, 95.08, 95.26, 95.26, 95.26, 95.26, 95.3, 95.3, 95.22, 95.22, 95.24, 95.24, 95.24, 95.24, 95.18, 95.18, 95.18, 95.18, 95.2, 95.2, 95.2, 95.2, 95.16, 95.16, 95.18, 95.18, 95.24, 95.24, 95.2, 95.2, 95.18, 95.18, 95.14, 95.14, 95.12, 95.12, 95.14, 95.14, 95.12, 95.12, 95.12, 95.12, 95.12, 95.12, 95.14, 95.14, 95.14, 95.14, 95.14, 95.14, 95.1, 95.1, 95.1, 95.1, 95.1, 95.1, 95.08, 95.08, 95.08, 95.08, 95.02, 95.02, 94.98, 94.98, 95.0, 95.0, 94.9, 94.9, 94.88, 94.88, 94.88, 94.88, 94.88, 94.88, 94.9, 94.9, 94.9, 94.9, 94.92, 94.92, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.02, 95.02, 94.96, 94.96, 94.96, 94.96, 94.94, 94.94, 94.94, 94.94, 94.92, 94.92, 94.96, 94.96, 94.94, 94.94, 94.94, 94.94, 94.92, 94.92, 94.86, 94.86, 94.86, 94.86, 94.9, 94.9, 94.86, 94.86, 94.86, 94.86, 94.88, 94.88, 94.88, 94.88, 94.9, 94.9, 94.82, 94.82, 94.86, 94.86, 94.84, 94.84, 94.84, 94.84, 94.82, 94.82, 94.82, 94.82, 94.82, 94.82, 94.8, 94.8, 94.82, 94.82, 94.82, 94.82, 94.82, 94.82, 94.8, 94.8, 94.82, 94.82, 94.84, 94.84, 94.84, 94.84, 94.84, 94.84, 94.74, 94.74]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.2 , level_n_lowerb:0.4  

   Client 4, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.595, Test loss: 1.568, Test accuracy: 70.02
Round   0, Global train loss: 1.595, Global test loss: 1.569, Global test accuracy: 71.64
Round   1, Train loss: 1.375, Test loss: 1.238, Test accuracy: 83.26
Round   1, Global train loss: 1.375, Global test loss: 1.095, Global test accuracy: 91.90
Round   2, Train loss: 1.115, Test loss: 1.116, Test accuracy: 88.80
Round   2, Global train loss: 1.115, Global test loss: 0.989, Global test accuracy: 94.22
Round   3, Train loss: 0.971, Test loss: 1.029, Test accuracy: 92.68
Round   3, Global train loss: 0.971, Global test loss: 0.955, Global test accuracy: 96.20
Round   4, Train loss: 0.952, Test loss: 1.022, Test accuracy: 93.16
Round   4, Global train loss: 0.952, Global test loss: 0.947, Global test accuracy: 96.64
Round   5, Train loss: 1.039, Test loss: 0.960, Test accuracy: 96.02
Round   5, Global train loss: 1.039, Global test loss: 0.943, Global test accuracy: 96.98
Round   6, Train loss: 1.131, Test loss: 0.955, Test accuracy: 96.20
Round   6, Global train loss: 1.131, Global test loss: 0.943, Global test accuracy: 97.00
Round   7, Train loss: 0.926, Test loss: 0.954, Test accuracy: 96.14
Round   7, Global train loss: 0.926, Global test loss: 0.940, Global test accuracy: 97.18
Round   8, Train loss: 0.934, Test loss: 0.952, Test accuracy: 96.30
Round   8, Global train loss: 0.934, Global test loss: 0.939, Global test accuracy: 97.10
Round   9, Train loss: 0.933, Test loss: 0.950, Test accuracy: 96.44
Round   9, Global train loss: 0.933, Global test loss: 0.937, Global test accuracy: 97.26
Round  10, Train loss: 0.931, Test loss: 0.948, Test accuracy: 96.56
Round  10, Global train loss: 0.931, Global test loss: 0.936, Global test accuracy: 97.22
Round  11, Train loss: 1.035, Test loss: 0.947, Test accuracy: 96.60
Round  11, Global train loss: 1.035, Global test loss: 0.937, Global test accuracy: 97.00
Round  12, Train loss: 1.058, Test loss: 0.940, Test accuracy: 96.88
Round  12, Global train loss: 1.058, Global test loss: 0.937, Global test accuracy: 96.88
Round  13, Train loss: 1.045, Test loss: 0.940, Test accuracy: 96.90
Round  13, Global train loss: 1.045, Global test loss: 0.936, Global test accuracy: 97.16
Round  14, Train loss: 0.944, Test loss: 0.939, Test accuracy: 96.96
Round  14, Global train loss: 0.944, Global test loss: 0.935, Global test accuracy: 97.14
Round  15, Train loss: 0.927, Test loss: 0.940, Test accuracy: 96.84
Round  15, Global train loss: 0.927, Global test loss: 0.936, Global test accuracy: 97.20
Round  16, Train loss: 1.032, Test loss: 0.940, Test accuracy: 96.86
Round  16, Global train loss: 1.032, Global test loss: 0.940, Global test accuracy: 96.46
Round  17, Train loss: 0.916, Test loss: 0.940, Test accuracy: 96.88
Round  17, Global train loss: 0.916, Global test loss: 0.934, Global test accuracy: 97.38
Round  18, Train loss: 0.922, Test loss: 0.939, Test accuracy: 96.84
Round  18, Global train loss: 0.922, Global test loss: 0.934, Global test accuracy: 97.28
Round  19, Train loss: 0.924, Test loss: 0.938, Test accuracy: 96.94
Round  19, Global train loss: 0.924, Global test loss: 0.934, Global test accuracy: 97.34
Round  20, Train loss: 1.028, Test loss: 0.937, Test accuracy: 97.00
Round  20, Global train loss: 1.028, Global test loss: 0.936, Global test accuracy: 96.98
Round  21, Train loss: 0.919, Test loss: 0.937, Test accuracy: 96.98
Round  21, Global train loss: 0.919, Global test loss: 0.934, Global test accuracy: 97.36
Round  22, Train loss: 1.014, Test loss: 0.937, Test accuracy: 97.00
Round  22, Global train loss: 1.014, Global test loss: 0.934, Global test accuracy: 97.38
Round  23, Train loss: 1.056, Test loss: 0.937, Test accuracy: 96.98
Round  23, Global train loss: 1.056, Global test loss: 0.935, Global test accuracy: 97.16
Round  24, Train loss: 0.920, Test loss: 0.937, Test accuracy: 96.98
Round  24, Global train loss: 0.920, Global test loss: 0.933, Global test accuracy: 97.48
Round  25, Train loss: 1.043, Test loss: 0.936, Test accuracy: 96.98
Round  25, Global train loss: 1.043, Global test loss: 0.933, Global test accuracy: 97.36
Round  26, Train loss: 1.025, Test loss: 0.935, Test accuracy: 97.08
Round  26, Global train loss: 1.025, Global test loss: 0.934, Global test accuracy: 97.38
Round  27, Train loss: 0.948, Test loss: 0.935, Test accuracy: 97.08
Round  27, Global train loss: 0.948, Global test loss: 0.933, Global test accuracy: 97.32
Round  28, Train loss: 1.122, Test loss: 0.935, Test accuracy: 97.14
Round  28, Global train loss: 1.122, Global test loss: 0.935, Global test accuracy: 97.30
Round  29, Train loss: 0.943, Test loss: 0.935, Test accuracy: 97.12
Round  29, Global train loss: 0.943, Global test loss: 0.933, Global test accuracy: 97.36
Round  30, Train loss: 1.119, Test loss: 0.935, Test accuracy: 97.04
Round  30, Global train loss: 1.119, Global test loss: 0.935, Global test accuracy: 97.06
Round  31, Train loss: 1.010, Test loss: 0.935, Test accuracy: 97.04
Round  31, Global train loss: 1.010, Global test loss: 0.934, Global test accuracy: 97.28
Round  32, Train loss: 1.025, Test loss: 0.935, Test accuracy: 97.06
Round  32, Global train loss: 1.025, Global test loss: 0.935, Global test accuracy: 97.14
Round  33, Train loss: 1.021, Test loss: 0.935, Test accuracy: 97.02
Round  33, Global train loss: 1.021, Global test loss: 0.935, Global test accuracy: 97.14
Round  34, Train loss: 0.941, Test loss: 0.936, Test accuracy: 96.92
Round  34, Global train loss: 0.941, Global test loss: 0.933, Global test accuracy: 97.34
Round  35, Train loss: 0.922, Test loss: 0.935, Test accuracy: 96.94
Round  35, Global train loss: 0.922, Global test loss: 0.933, Global test accuracy: 97.28
Round  36, Train loss: 0.922, Test loss: 0.935, Test accuracy: 96.94
Round  36, Global train loss: 0.922, Global test loss: 0.934, Global test accuracy: 97.06
Round  37, Train loss: 0.921, Test loss: 0.935, Test accuracy: 97.00
Round  37, Global train loss: 0.921, Global test loss: 0.933, Global test accuracy: 97.32
Round  38, Train loss: 0.915, Test loss: 0.935, Test accuracy: 96.98
Round  38, Global train loss: 0.915, Global test loss: 0.933, Global test accuracy: 97.38
Round  39, Train loss: 1.054, Test loss: 0.934, Test accuracy: 97.06
Round  39, Global train loss: 1.054, Global test loss: 0.933, Global test accuracy: 97.36
Round  40, Train loss: 1.023, Test loss: 0.934, Test accuracy: 97.04
Round  40, Global train loss: 1.023, Global test loss: 0.934, Global test accuracy: 96.98
Round  41, Train loss: 1.119, Test loss: 0.934, Test accuracy: 97.08
Round  41, Global train loss: 1.119, Global test loss: 0.934, Global test accuracy: 97.06
Round  42, Train loss: 0.921, Test loss: 0.935, Test accuracy: 97.02
Round  42, Global train loss: 0.921, Global test loss: 0.934, Global test accuracy: 97.08
Round  43, Train loss: 0.919, Test loss: 0.934, Test accuracy: 97.06
Round  43, Global train loss: 0.919, Global test loss: 0.933, Global test accuracy: 97.24
Round  44, Train loss: 1.008, Test loss: 0.934, Test accuracy: 97.08
Round  44, Global train loss: 1.008, Global test loss: 0.933, Global test accuracy: 97.30
Round  45, Train loss: 1.016, Test loss: 0.934, Test accuracy: 97.10
Round  45, Global train loss: 1.016, Global test loss: 0.934, Global test accuracy: 97.22
Round  46, Train loss: 1.118, Test loss: 0.934, Test accuracy: 97.16
Round  46, Global train loss: 1.118, Global test loss: 0.934, Global test accuracy: 97.04
Round  47, Train loss: 1.049, Test loss: 0.934, Test accuracy: 97.12
Round  47, Global train loss: 1.049, Global test loss: 0.933, Global test accuracy: 97.22
Round  48, Train loss: 0.917, Test loss: 0.934, Test accuracy: 97.16
Round  48, Global train loss: 0.917, Global test loss: 0.932, Global test accuracy: 97.42
Round  49, Train loss: 1.019, Test loss: 0.934, Test accuracy: 97.04
Round  49, Global train loss: 1.019, Global test loss: 0.933, Global test accuracy: 97.22
Round  50, Train loss: 1.051, Test loss: 0.934, Test accuracy: 97.06
Round  50, Global train loss: 1.051, Global test loss: 0.933, Global test accuracy: 97.20
Round  51, Train loss: 0.913, Test loss: 0.934, Test accuracy: 97.12
Round  51, Global train loss: 0.913, Global test loss: 0.933, Global test accuracy: 97.24
Round  52, Train loss: 0.917, Test loss: 0.934, Test accuracy: 97.16
Round  52, Global train loss: 0.917, Global test loss: 0.931, Global test accuracy: 97.48
Round  53, Train loss: 0.919, Test loss: 0.934, Test accuracy: 97.16
Round  53, Global train loss: 0.919, Global test loss: 0.931, Global test accuracy: 97.48
Round  54, Train loss: 0.916, Test loss: 0.934, Test accuracy: 97.10
Round  54, Global train loss: 0.916, Global test loss: 0.931, Global test accuracy: 97.44
Round  55, Train loss: 0.940, Test loss: 0.934, Test accuracy: 97.10
Round  55, Global train loss: 0.940, Global test loss: 0.931, Global test accuracy: 97.52
Round  56, Train loss: 0.913, Test loss: 0.933, Test accuracy: 97.12
Round  56, Global train loss: 0.913, Global test loss: 0.931, Global test accuracy: 97.54
Round  57, Train loss: 0.913, Test loss: 0.933, Test accuracy: 97.16
Round  57, Global train loss: 0.913, Global test loss: 0.932, Global test accuracy: 97.32
Round  58, Train loss: 0.943, Test loss: 0.933, Test accuracy: 97.20
Round  58, Global train loss: 0.943, Global test loss: 0.930, Global test accuracy: 97.52
Round  59, Train loss: 0.911, Test loss: 0.933, Test accuracy: 97.20
Round  59, Global train loss: 0.911, Global test loss: 0.930, Global test accuracy: 97.48
Round  60, Train loss: 0.939, Test loss: 0.933, Test accuracy: 97.24
Round  60, Global train loss: 0.939, Global test loss: 0.930, Global test accuracy: 97.46
Round  61, Train loss: 0.915, Test loss: 0.933, Test accuracy: 97.22
Round  61, Global train loss: 0.915, Global test loss: 0.931, Global test accuracy: 97.50
Round  62, Train loss: 1.015, Test loss: 0.932, Test accuracy: 97.26
Round  62, Global train loss: 1.015, Global test loss: 0.932, Global test accuracy: 97.30
Round  63, Train loss: 1.009, Test loss: 0.932, Test accuracy: 97.26
Round  63, Global train loss: 1.009, Global test loss: 0.932, Global test accuracy: 97.28
Round  64, Train loss: 1.036, Test loss: 0.932, Test accuracy: 97.24
Round  64, Global train loss: 1.036, Global test loss: 0.931, Global test accuracy: 97.38
Round  65, Train loss: 0.939, Test loss: 0.933, Test accuracy: 97.14
Round  65, Global train loss: 0.939, Global test loss: 0.930, Global test accuracy: 97.46
Round  66, Train loss: 0.909, Test loss: 0.933, Test accuracy: 97.18
Round  66, Global train loss: 0.909, Global test loss: 0.931, Global test accuracy: 97.56
Round  67, Train loss: 1.011, Test loss: 0.933, Test accuracy: 97.18
Round  67, Global train loss: 1.011, Global test loss: 0.932, Global test accuracy: 97.32
Round  68, Train loss: 1.020, Test loss: 0.933, Test accuracy: 97.12
Round  68, Global train loss: 1.020, Global test loss: 0.934, Global test accuracy: 97.12
Round  69, Train loss: 0.936, Test loss: 0.933, Test accuracy: 97.20
Round  69, Global train loss: 0.936, Global test loss: 0.931, Global test accuracy: 97.44
Round  70, Train loss: 1.022, Test loss: 0.933, Test accuracy: 97.22
Round  70, Global train loss: 1.022, Global test loss: 0.933, Global test accuracy: 97.16
Round  71, Train loss: 1.019, Test loss: 0.933, Test accuracy: 97.24
Round  71, Global train loss: 1.019, Global test loss: 0.934, Global test accuracy: 97.16
Round  72, Train loss: 1.021, Test loss: 0.933, Test accuracy: 97.22
Round  72, Global train loss: 1.021, Global test loss: 0.934, Global test accuracy: 97.10
Round  73, Train loss: 1.010, Test loss: 0.933, Test accuracy: 97.22
Round  73, Global train loss: 1.010, Global test loss: 0.933, Global test accuracy: 97.16
Round  74, Train loss: 0.939, Test loss: 0.933, Test accuracy: 97.18
Round  74, Global train loss: 0.939, Global test loss: 0.931, Global test accuracy: 97.36
Round  75, Train loss: 0.914, Test loss: 0.933, Test accuracy: 97.16
Round  75, Global train loss: 0.914, Global test loss: 0.931, Global test accuracy: 97.40
Round  76, Train loss: 1.020, Test loss: 0.933, Test accuracy: 97.12
Round  76, Global train loss: 1.020, Global test loss: 0.933, Global test accuracy: 97.22
Round  77, Train loss: 0.939, Test loss: 0.933, Test accuracy: 97.10
Round  77, Global train loss: 0.939, Global test loss: 0.930, Global test accuracy: 97.52
Round  78, Train loss: 0.915, Test loss: 0.933, Test accuracy: 97.10
Round  78, Global train loss: 0.915, Global test loss: 0.931, Global test accuracy: 97.34
Round  79, Train loss: 0.913, Test loss: 0.933, Test accuracy: 97.10
Round  79, Global train loss: 0.913, Global test loss: 0.931, Global test accuracy: 97.36
Round  80, Train loss: 0.915, Test loss: 0.933, Test accuracy: 97.12
Round  80, Global train loss: 0.915, Global test loss: 0.931, Global test accuracy: 97.44
Round  81, Train loss: 0.917, Test loss: 0.933, Test accuracy: 97.12
Round  81, Global train loss: 0.917, Global test loss: 0.931, Global test accuracy: 97.38
Round  82, Train loss: 0.939, Test loss: 0.933, Test accuracy: 97.14
Round  82, Global train loss: 0.939, Global test loss: 0.930, Global test accuracy: 97.62
Round  83, Train loss: 0.911, Test loss: 0.933, Test accuracy: 97.16
Round  83, Global train loss: 0.911, Global test loss: 0.931, Global test accuracy: 97.44
Round  84, Train loss: 0.939, Test loss: 0.933, Test accuracy: 97.18
Round  84, Global train loss: 0.939, Global test loss: 0.930, Global test accuracy: 97.56
Round  85, Train loss: 1.016, Test loss: 0.932, Test accuracy: 97.18
Round  85, Global train loss: 1.016, Global test loss: 0.932, Global test accuracy: 97.32
Round  86, Train loss: 0.916, Test loss: 0.932, Test accuracy: 97.18
Round  86, Global train loss: 0.916, Global test loss: 0.931, Global test accuracy: 97.38
Round  87, Train loss: 1.008, Test loss: 0.932, Test accuracy: 97.22
Round  87, Global train loss: 1.008, Global test loss: 0.931, Global test accuracy: 97.36
Round  88, Train loss: 1.033, Test loss: 0.932, Test accuracy: 97.22
Round  88, Global train loss: 1.033, Global test loss: 0.931, Global test accuracy: 97.30
Round  89, Train loss: 1.016, Test loss: 0.932, Test accuracy: 97.28
Round  89, Global train loss: 1.016, Global test loss: 0.933, Global test accuracy: 97.24
Round  90, Train loss: 0.939, Test loss: 0.932, Test accuracy: 97.22
Round  90, Global train loss: 0.939, Global test loss: 0.931, Global test accuracy: 97.38
Round  91, Train loss: 1.033, Test loss: 0.932, Test accuracy: 97.22
Round  91, Global train loss: 1.033, Global test loss: 0.931, Global test accuracy: 97.34
Round  92, Train loss: 0.914, Test loss: 0.933, Test accuracy: 97.18
Round  92, Global train loss: 0.914, Global test loss: 0.931, Global test accuracy: 97.40
Round  93, Train loss: 1.020, Test loss: 0.932, Test accuracy: 97.18
Round  93, Global train loss: 1.020, Global test loss: 0.933, Global test accuracy: 97.12
Round  94, Train loss: 1.008, Test loss: 0.932, Test accuracy: 97.20
Round  94, Global train loss: 1.008, Global test loss: 0.932, Global test accuracy: 97.30
Round  95, Train loss: 1.032, Test loss: 0.932, Test accuracy: 97.16
Round  95, Global train loss: 1.032, Global test loss: 0.931, Global test accuracy: 97.34/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 0.937, Test loss: 0.932, Test accuracy: 97.16
Round  96, Global train loss: 0.937, Global test loss: 0.931, Global test accuracy: 97.30
Round  97, Train loss: 1.116, Test loss: 0.932, Test accuracy: 97.14
Round  97, Global train loss: 1.116, Global test loss: 0.934, Global test accuracy: 97.18
Round  98, Train loss: 1.013, Test loss: 0.932, Test accuracy: 97.14
Round  98, Global train loss: 1.013, Global test loss: 0.932, Global test accuracy: 97.26
Round  99, Train loss: 0.919, Test loss: 0.933, Test accuracy: 97.12
Round  99, Global train loss: 0.919, Global test loss: 0.932, Global test accuracy: 97.22
Final Round, Train loss: 0.981, Test loss: 0.933, Test accuracy: 97.12
Final Round, Global train loss: 0.981, Global test loss: 0.932, Global test accuracy: 97.22
Average accuracy final 10 rounds: 97.172 

Average global accuracy final 10 rounds: 97.284 

499.9415819644928
[0.8008575439453125, 1.601715087890625, 2.3035452365875244, 3.005375385284424, 3.707406997680664, 4.409438610076904, 5.118727445602417, 5.82801628112793, 6.539952993392944, 7.251889705657959, 7.96462082862854, 8.677351951599121, 9.366647243499756, 10.05594253540039, 10.766926050186157, 11.477909564971924, 12.191396474838257, 12.90488338470459, 13.61464548110962, 14.324407577514648, 15.031334400177002, 15.738261222839355, 16.446924686431885, 17.155588150024414, 17.869081020355225, 18.582573890686035, 19.295021295547485, 20.007468700408936, 20.714367389678955, 21.421266078948975, 22.125069856643677, 22.82887363433838, 23.53537082672119, 24.241868019104004, 24.94860553741455, 25.655343055725098, 26.357895612716675, 27.060448169708252, 27.753167390823364, 28.445886611938477, 29.146395206451416, 29.846903800964355, 30.550350189208984, 31.253796577453613, 31.96047830581665, 32.66716003417969, 33.364768981933594, 34.0623779296875, 34.76823163032532, 35.474085330963135, 36.183398723602295, 36.892712116241455, 37.605525493621826, 38.3183388710022, 39.025598764419556, 39.732858657836914, 40.43481469154358, 41.136770725250244, 41.838730573654175, 42.540690422058105, 43.249444246292114, 43.95819807052612, 44.6669704914093, 45.37574291229248, 46.06546115875244, 46.7551794052124, 47.45655632019043, 48.15793323516846, 48.86151647567749, 49.56509971618652, 50.270065784454346, 50.97503185272217, 51.6666305065155, 52.35822916030884, 53.07948541641235, 53.80074167251587, 54.50213122367859, 55.20352077484131, 55.9063515663147, 56.609182357788086, 57.313408613204956, 58.017634868621826, 58.71750521659851, 59.417375564575195, 60.11908793449402, 60.82080030441284, 61.51988625526428, 62.21897220611572, 62.925206422805786, 63.63144063949585, 64.32228112220764, 65.01312160491943, 65.71721982955933, 66.42131805419922, 67.13142848014832, 67.84153890609741, 68.55137324333191, 69.2612075805664, 69.97115969657898, 70.68111181259155, 71.38691329956055, 72.09271478652954, 72.79777073860168, 73.50282669067383, 74.20861887931824, 74.91441106796265, 75.62088632583618, 76.32736158370972, 77.03091478347778, 77.73446798324585, 78.4412133693695, 79.14795875549316, 79.84879922866821, 80.54963970184326, 81.26388716697693, 81.9781346321106, 82.70932626724243, 83.44051790237427, 84.14876246452332, 84.85700702667236, 85.56763052940369, 86.27825403213501, 86.98479580879211, 87.69133758544922, 88.37734651565552, 89.06335544586182, 89.79821920394897, 90.53308296203613, 91.27289891242981, 92.01271486282349, 92.75690913200378, 93.50110340118408, 94.24391722679138, 94.98673105239868, 95.72991466522217, 96.47309827804565, 97.2181465625763, 97.96319484710693, 98.70608019828796, 99.448965549469, 100.19103622436523, 100.93310689926147, 101.67428779602051, 102.41546869277954, 103.16068267822266, 103.90589666366577, 104.64922523498535, 105.39255380630493, 106.13955736160278, 106.88656091690063, 107.6085422039032, 108.33052349090576, 109.0722348690033, 109.81394624710083, 110.55355167388916, 111.29315710067749, 112.03441786766052, 112.77567863464355, 113.49453210830688, 114.21338558197021, 114.9571692943573, 115.70095300674438, 116.44385194778442, 117.18675088882446, 117.92459559440613, 118.6624402999878, 119.39642596244812, 120.13041162490845, 120.87293553352356, 121.61545944213867, 122.3588399887085, 123.10222053527832, 123.84239053726196, 124.5825605392456, 125.32315135002136, 126.06374216079712, 126.79689741134644, 127.53005266189575, 128.2713644504547, 129.01267623901367, 129.7537808418274, 130.4948854446411, 131.23393297195435, 131.97298049926758, 132.71077752113342, 133.44857454299927, 134.19087648391724, 134.9331784248352, 135.67066383361816, 136.40814924240112, 137.14749193191528, 137.88683462142944, 138.61564111709595, 139.34444761276245, 140.08578824996948, 140.8271288871765, 141.56650853157043, 142.30588817596436, 143.0480830669403, 143.79027795791626, 145.34875082969666, 146.90722370147705]
[70.02, 70.02, 83.26, 83.26, 88.8, 88.8, 92.68, 92.68, 93.16, 93.16, 96.02, 96.02, 96.2, 96.2, 96.14, 96.14, 96.3, 96.3, 96.44, 96.44, 96.56, 96.56, 96.6, 96.6, 96.88, 96.88, 96.9, 96.9, 96.96, 96.96, 96.84, 96.84, 96.86, 96.86, 96.88, 96.88, 96.84, 96.84, 96.94, 96.94, 97.0, 97.0, 96.98, 96.98, 97.0, 97.0, 96.98, 96.98, 96.98, 96.98, 96.98, 96.98, 97.08, 97.08, 97.08, 97.08, 97.14, 97.14, 97.12, 97.12, 97.04, 97.04, 97.04, 97.04, 97.06, 97.06, 97.02, 97.02, 96.92, 96.92, 96.94, 96.94, 96.94, 96.94, 97.0, 97.0, 96.98, 96.98, 97.06, 97.06, 97.04, 97.04, 97.08, 97.08, 97.02, 97.02, 97.06, 97.06, 97.08, 97.08, 97.1, 97.1, 97.16, 97.16, 97.12, 97.12, 97.16, 97.16, 97.04, 97.04, 97.06, 97.06, 97.12, 97.12, 97.16, 97.16, 97.16, 97.16, 97.1, 97.1, 97.1, 97.1, 97.12, 97.12, 97.16, 97.16, 97.2, 97.2, 97.2, 97.2, 97.24, 97.24, 97.22, 97.22, 97.26, 97.26, 97.26, 97.26, 97.24, 97.24, 97.14, 97.14, 97.18, 97.18, 97.18, 97.18, 97.12, 97.12, 97.2, 97.2, 97.22, 97.22, 97.24, 97.24, 97.22, 97.22, 97.22, 97.22, 97.18, 97.18, 97.16, 97.16, 97.12, 97.12, 97.1, 97.1, 97.1, 97.1, 97.1, 97.1, 97.12, 97.12, 97.12, 97.12, 97.14, 97.14, 97.16, 97.16, 97.18, 97.18, 97.18, 97.18, 97.18, 97.18, 97.22, 97.22, 97.22, 97.22, 97.28, 97.28, 97.22, 97.22, 97.22, 97.22, 97.18, 97.18, 97.18, 97.18, 97.2, 97.2, 97.16, 97.16, 97.16, 97.16, 97.14, 97.14, 97.14, 97.14, 97.12, 97.12, 97.12, 97.12]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.2 , level_n_lowerb:0.4  

   Client 7, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
prox
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.588, Test loss: 1.560, Test accuracy: 71.32
Round   0, Global train loss: 1.588, Global test loss: 1.561, Global test accuracy: 68.88
Round   1, Train loss: 1.433, Test loss: 1.323, Test accuracy: 83.46
Round   1, Global train loss: 1.433, Global test loss: 1.218, Global test accuracy: 87.24
Round   2, Train loss: 1.128, Test loss: 1.143, Test accuracy: 87.54
Round   2, Global train loss: 1.128, Global test loss: 1.016, Global test accuracy: 93.46
Round   3, Train loss: 1.025, Test loss: 1.044, Test accuracy: 92.96
Round   3, Global train loss: 1.025, Global test loss: 0.968, Global test accuracy: 95.74
Round   4, Train loss: 1.082, Test loss: 1.032, Test accuracy: 93.42
Round   4, Global train loss: 1.082, Global test loss: 0.958, Global test accuracy: 96.18
Round   5, Train loss: 1.044, Test loss: 0.969, Test accuracy: 95.54
Round   5, Global train loss: 1.044, Global test loss: 0.950, Global test accuracy: 96.62
Round   6, Train loss: 0.956, Test loss: 0.961, Test accuracy: 95.76
Round   6, Global train loss: 0.956, Global test loss: 0.946, Global test accuracy: 96.60
Round   7, Train loss: 0.954, Test loss: 0.960, Test accuracy: 95.82
Round   7, Global train loss: 0.954, Global test loss: 0.944, Global test accuracy: 96.72
Round   8, Train loss: 1.154, Test loss: 0.956, Test accuracy: 96.12
Round   8, Global train loss: 1.154, Global test loss: 0.944, Global test accuracy: 96.78
Round   9, Train loss: 1.047, Test loss: 0.954, Test accuracy: 96.28
Round   9, Global train loss: 1.047, Global test loss: 0.942, Global test accuracy: 96.90
Round  10, Train loss: 0.954, Test loss: 0.951, Test accuracy: 96.40
Round  10, Global train loss: 0.954, Global test loss: 0.940, Global test accuracy: 97.00
Round  11, Train loss: 1.039, Test loss: 0.949, Test accuracy: 96.46
Round  11, Global train loss: 1.039, Global test loss: 0.939, Global test accuracy: 97.06
Round  12, Train loss: 0.945, Test loss: 0.942, Test accuracy: 96.76
Round  12, Global train loss: 0.945, Global test loss: 0.939, Global test accuracy: 96.86
Round  13, Train loss: 0.929, Test loss: 0.942, Test accuracy: 96.72
Round  13, Global train loss: 0.929, Global test loss: 0.938, Global test accuracy: 96.76
Round  14, Train loss: 0.944, Test loss: 0.940, Test accuracy: 96.84
Round  14, Global train loss: 0.944, Global test loss: 0.938, Global test accuracy: 96.94
Round  15, Train loss: 1.054, Test loss: 0.940, Test accuracy: 96.70
Round  15, Global train loss: 1.054, Global test loss: 0.939, Global test accuracy: 96.96
Round  16, Train loss: 1.028, Test loss: 0.940, Test accuracy: 96.70
Round  16, Global train loss: 1.028, Global test loss: 0.937, Global test accuracy: 97.00
Round  17, Train loss: 0.941, Test loss: 0.939, Test accuracy: 96.72
Round  17, Global train loss: 0.941, Global test loss: 0.936, Global test accuracy: 96.96
Round  18, Train loss: 1.035, Test loss: 0.939, Test accuracy: 96.76
Round  18, Global train loss: 1.035, Global test loss: 0.936, Global test accuracy: 97.12
Round  19, Train loss: 1.123, Test loss: 0.939, Test accuracy: 96.82
Round  19, Global train loss: 1.123, Global test loss: 0.937, Global test accuracy: 96.98
Round  20, Train loss: 1.024, Test loss: 0.939, Test accuracy: 96.76
Round  20, Global train loss: 1.024, Global test loss: 0.938, Global test accuracy: 96.74
Round  21, Train loss: 1.034, Test loss: 0.940, Test accuracy: 96.58
Round  21, Global train loss: 1.034, Global test loss: 0.937, Global test accuracy: 97.04
Round  22, Train loss: 0.941, Test loss: 0.940, Test accuracy: 96.62
Round  22, Global train loss: 0.941, Global test loss: 0.936, Global test accuracy: 96.94
Round  23, Train loss: 1.015, Test loss: 0.939, Test accuracy: 96.66
Round  23, Global train loss: 1.015, Global test loss: 0.936, Global test accuracy: 97.00
Round  24, Train loss: 0.943, Test loss: 0.939, Test accuracy: 96.70
Round  24, Global train loss: 0.943, Global test loss: 0.935, Global test accuracy: 97.20
Round  25, Train loss: 0.943, Test loss: 0.939, Test accuracy: 96.76
Round  25, Global train loss: 0.943, Global test loss: 0.935, Global test accuracy: 97.06
Round  26, Train loss: 0.935, Test loss: 0.939, Test accuracy: 96.74
Round  26, Global train loss: 0.935, Global test loss: 0.935, Global test accuracy: 96.96
Round  27, Train loss: 1.047, Test loss: 0.939, Test accuracy: 96.72
Round  27, Global train loss: 1.047, Global test loss: 0.936, Global test accuracy: 97.04
Round  28, Train loss: 0.917, Test loss: 0.939, Test accuracy: 96.64
Round  28, Global train loss: 0.917, Global test loss: 0.935, Global test accuracy: 96.96
Round  29, Train loss: 0.938, Test loss: 0.939, Test accuracy: 96.62
Round  29, Global train loss: 0.938, Global test loss: 0.935, Global test accuracy: 97.14
Round  30, Train loss: 0.937, Test loss: 0.939, Test accuracy: 96.62
Round  30, Global train loss: 0.937, Global test loss: 0.935, Global test accuracy: 96.92
Round  31, Train loss: 0.937, Test loss: 0.939, Test accuracy: 96.60
Round  31, Global train loss: 0.937, Global test loss: 0.935, Global test accuracy: 96.96
Round  32, Train loss: 1.031, Test loss: 0.939, Test accuracy: 96.64
Round  32, Global train loss: 1.031, Global test loss: 0.936, Global test accuracy: 97.06
Round  33, Train loss: 0.955, Test loss: 0.939, Test accuracy: 96.58
Round  33, Global train loss: 0.955, Global test loss: 0.935, Global test accuracy: 97.04
Round  34, Train loss: 0.939, Test loss: 0.939, Test accuracy: 96.60
Round  34, Global train loss: 0.939, Global test loss: 0.934, Global test accuracy: 97.24
Round  35, Train loss: 1.118, Test loss: 0.938, Test accuracy: 96.80
Round  35, Global train loss: 1.118, Global test loss: 0.936, Global test accuracy: 97.10
Round  36, Train loss: 1.048, Test loss: 0.938, Test accuracy: 96.86
Round  36, Global train loss: 1.048, Global test loss: 0.936, Global test accuracy: 97.00
Round  37, Train loss: 1.116, Test loss: 0.937, Test accuracy: 96.86
Round  37, Global train loss: 1.116, Global test loss: 0.936, Global test accuracy: 96.96
Round  38, Train loss: 1.042, Test loss: 0.937, Test accuracy: 96.84
Round  38, Global train loss: 1.042, Global test loss: 0.936, Global test accuracy: 96.92
Round  39, Train loss: 0.923, Test loss: 0.938, Test accuracy: 96.80
Round  39, Global train loss: 0.923, Global test loss: 0.935, Global test accuracy: 97.02
Round  40, Train loss: 1.041, Test loss: 0.938, Test accuracy: 96.84
Round  40, Global train loss: 1.041, Global test loss: 0.936, Global test accuracy: 97.08
Round  41, Train loss: 0.916, Test loss: 0.937, Test accuracy: 96.86
Round  41, Global train loss: 0.916, Global test loss: 0.935, Global test accuracy: 96.80
Round  42, Train loss: 1.025, Test loss: 0.937, Test accuracy: 96.88
Round  42, Global train loss: 1.025, Global test loss: 0.936, Global test accuracy: 96.94
Round  43, Train loss: 1.115, Test loss: 0.938, Test accuracy: 96.84
Round  43, Global train loss: 1.115, Global test loss: 0.937, Global test accuracy: 96.82
Round  44, Train loss: 0.936, Test loss: 0.938, Test accuracy: 96.74
Round  44, Global train loss: 0.936, Global test loss: 0.935, Global test accuracy: 97.10
Round  45, Train loss: 1.023, Test loss: 0.938, Test accuracy: 96.78
Round  45, Global train loss: 1.023, Global test loss: 0.938, Global test accuracy: 96.84
Round  46, Train loss: 0.933, Test loss: 0.938, Test accuracy: 96.82
Round  46, Global train loss: 0.933, Global test loss: 0.936, Global test accuracy: 96.94
Round  47, Train loss: 0.936, Test loss: 0.937, Test accuracy: 96.82
Round  47, Global train loss: 0.936, Global test loss: 0.935, Global test accuracy: 97.04
Round  48, Train loss: 1.028, Test loss: 0.937, Test accuracy: 96.86
Round  48, Global train loss: 1.028, Global test loss: 0.935, Global test accuracy: 97.10
Round  49, Train loss: 0.935, Test loss: 0.937, Test accuracy: 96.84
Round  49, Global train loss: 0.935, Global test loss: 0.934, Global test accuracy: 97.14
Round  50, Train loss: 1.012, Test loss: 0.937, Test accuracy: 96.82
Round  50, Global train loss: 1.012, Global test loss: 0.934, Global test accuracy: 97.06
Round  51, Train loss: 1.041, Test loss: 0.937, Test accuracy: 96.84
Round  51, Global train loss: 1.041, Global test loss: 0.936, Global test accuracy: 97.04
Round  52, Train loss: 1.027, Test loss: 0.937, Test accuracy: 96.82
Round  52, Global train loss: 1.027, Global test loss: 0.935, Global test accuracy: 97.06
Round  53, Train loss: 1.012, Test loss: 0.937, Test accuracy: 96.78
Round  53, Global train loss: 1.012, Global test loss: 0.935, Global test accuracy: 96.96
Round  54, Train loss: 0.957, Test loss: 0.937, Test accuracy: 96.78
Round  54, Global train loss: 0.957, Global test loss: 0.935, Global test accuracy: 97.04
Round  55, Train loss: 0.936, Test loss: 0.937, Test accuracy: 96.82
Round  55, Global train loss: 0.936, Global test loss: 0.934, Global test accuracy: 97.28
Round  56, Train loss: 0.916, Test loss: 0.937, Test accuracy: 96.78
Round  56, Global train loss: 0.916, Global test loss: 0.934, Global test accuracy: 97.08
Round  57, Train loss: 1.040, Test loss: 0.937, Test accuracy: 96.80
Round  57, Global train loss: 1.040, Global test loss: 0.935, Global test accuracy: 96.98
Round  58, Train loss: 1.011, Test loss: 0.936, Test accuracy: 96.86
Round  58, Global train loss: 1.011, Global test loss: 0.934, Global test accuracy: 97.24
Round  59, Train loss: 0.952, Test loss: 0.936, Test accuracy: 96.88
Round  59, Global train loss: 0.952, Global test loss: 0.934, Global test accuracy: 97.20
Round  60, Train loss: 0.957, Test loss: 0.936, Test accuracy: 96.84
Round  60, Global train loss: 0.957, Global test loss: 0.934, Global test accuracy: 97.20
Round  61, Train loss: 1.036, Test loss: 0.937, Test accuracy: 96.86
Round  61, Global train loss: 1.036, Global test loss: 0.936, Global test accuracy: 96.98
Round  62, Train loss: 1.022, Test loss: 0.936, Test accuracy: 96.94
Round  62, Global train loss: 1.022, Global test loss: 0.936, Global test accuracy: 96.88
Round  63, Train loss: 0.916, Test loss: 0.936, Test accuracy: 96.92
Round  63, Global train loss: 0.916, Global test loss: 0.935, Global test accuracy: 97.00
Round  64, Train loss: 0.935, Test loss: 0.936, Test accuracy: 96.96
Round  64, Global train loss: 0.935, Global test loss: 0.934, Global test accuracy: 96.96
Round  65, Train loss: 0.935, Test loss: 0.936, Test accuracy: 96.90
Round  65, Global train loss: 0.935, Global test loss: 0.934, Global test accuracy: 97.06
Round  66, Train loss: 0.933, Test loss: 0.936, Test accuracy: 96.94
Round  66, Global train loss: 0.933, Global test loss: 0.934, Global test accuracy: 97.14
Round  67, Train loss: 0.935, Test loss: 0.936, Test accuracy: 96.96
Round  67, Global train loss: 0.935, Global test loss: 0.934, Global test accuracy: 97.10
Round  68, Train loss: 0.915, Test loss: 0.936, Test accuracy: 97.00
Round  68, Global train loss: 0.915, Global test loss: 0.934, Global test accuracy: 97.14
Round  69, Train loss: 0.937, Test loss: 0.936, Test accuracy: 96.98
Round  69, Global train loss: 0.937, Global test loss: 0.933, Global test accuracy: 97.28
Round  70, Train loss: 1.007, Test loss: 0.936, Test accuracy: 96.98
Round  70, Global train loss: 1.007, Global test loss: 0.934, Global test accuracy: 97.16
Round  71, Train loss: 0.937, Test loss: 0.936, Test accuracy: 96.94
Round  71, Global train loss: 0.937, Global test loss: 0.934, Global test accuracy: 97.16
Round  72, Train loss: 1.039, Test loss: 0.935, Test accuracy: 96.96
Round  72, Global train loss: 1.039, Global test loss: 0.934, Global test accuracy: 97.14
Round  73, Train loss: 1.039, Test loss: 0.935, Test accuracy: 96.96
Round  73, Global train loss: 1.039, Global test loss: 0.935, Global test accuracy: 96.90
Round  74, Train loss: 0.934, Test loss: 0.935, Test accuracy: 96.98
Round  74, Global train loss: 0.934, Global test loss: 0.934, Global test accuracy: 97.12
Round  75, Train loss: 1.029, Test loss: 0.935, Test accuracy: 96.94
Round  75, Global train loss: 1.029, Global test loss: 0.934, Global test accuracy: 97.12
Round  76, Train loss: 0.937, Test loss: 0.936, Test accuracy: 96.94
Round  76, Global train loss: 0.937, Global test loss: 0.934, Global test accuracy: 97.10
Round  77, Train loss: 0.940, Test loss: 0.936, Test accuracy: 96.96
Round  77, Global train loss: 0.940, Global test loss: 0.933, Global test accuracy: 97.24
Round  78, Train loss: 1.041, Test loss: 0.936, Test accuracy: 96.98
Round  78, Global train loss: 1.041, Global test loss: 0.935, Global test accuracy: 96.98
Round  79, Train loss: 0.933, Test loss: 0.935, Test accuracy: 96.98
Round  79, Global train loss: 0.933, Global test loss: 0.934, Global test accuracy: 97.00
Round  80, Train loss: 1.018, Test loss: 0.935, Test accuracy: 97.04
Round  80, Global train loss: 1.018, Global test loss: 0.935, Global test accuracy: 96.94
Round  81, Train loss: 1.111, Test loss: 0.935, Test accuracy: 97.00
Round  81, Global train loss: 1.111, Global test loss: 0.935, Global test accuracy: 96.86
Round  82, Train loss: 0.918, Test loss: 0.935, Test accuracy: 96.98
Round  82, Global train loss: 0.918, Global test loss: 0.934, Global test accuracy: 97.04
Round  83, Train loss: 1.038, Test loss: 0.935, Test accuracy: 96.94
Round  83, Global train loss: 1.038, Global test loss: 0.935, Global test accuracy: 96.96
Round  84, Train loss: 0.918, Test loss: 0.935, Test accuracy: 96.94
Round  84, Global train loss: 0.918, Global test loss: 0.934, Global test accuracy: 97.04
Round  85, Train loss: 0.911, Test loss: 0.936, Test accuracy: 96.90
Round  85, Global train loss: 0.911, Global test loss: 0.934, Global test accuracy: 97.04
Round  86, Train loss: 1.026, Test loss: 0.936, Test accuracy: 96.90
Round  86, Global train loss: 1.026, Global test loss: 0.935, Global test accuracy: 97.02
Round  87, Train loss: 0.914, Test loss: 0.936, Test accuracy: 96.88
Round  87, Global train loss: 0.914, Global test loss: 0.935, Global test accuracy: 96.98
Round  88, Train loss: 0.915, Test loss: 0.936, Test accuracy: 96.84
Round  88, Global train loss: 0.915, Global test loss: 0.934, Global test accuracy: 96.98
Round  89, Train loss: 0.911, Test loss: 0.936, Test accuracy: 96.88
Round  89, Global train loss: 0.911, Global test loss: 0.935, Global test accuracy: 96.94
Round  90, Train loss: 1.020, Test loss: 0.936, Test accuracy: 96.84
Round  90, Global train loss: 1.020, Global test loss: 0.935, Global test accuracy: 96.98
Round  91, Train loss: 0.915, Test loss: 0.936, Test accuracy: 96.84
Round  91, Global train loss: 0.915, Global test loss: 0.934, Global test accuracy: 97.04
Round  92, Train loss: 1.028, Test loss: 0.936, Test accuracy: 96.82
Round  92, Global train loss: 1.028, Global test loss: 0.935, Global test accuracy: 96.90
Round  93, Train loss: 1.039, Test loss: 0.936, Test accuracy: 96.80
Round  93, Global train loss: 1.039, Global test loss: 0.936, Global test accuracy: 96.78
Round  94, Train loss: 1.015, Test loss: 0.936, Test accuracy: 96.80
Round  94, Global train loss: 1.015, Global test loss: 0.936, Global test accuracy: 96.84
Round  95, Train loss: 0.915, Test loss: 0.936, Test accuracy: 96.80
Round  95, Global train loss: 0.915, Global test loss: 0.935, Global test accuracy: 96.86/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  96, Train loss: 0.917, Test loss: 0.936, Test accuracy: 96.80
Round  96, Global train loss: 0.917, Global test loss: 0.935, Global test accuracy: 96.88
Round  97, Train loss: 1.017, Test loss: 0.936, Test accuracy: 96.80
Round  97, Global train loss: 1.017, Global test loss: 0.936, Global test accuracy: 96.72
Round  98, Train loss: 1.111, Test loss: 0.936, Test accuracy: 96.80
Round  98, Global train loss: 1.111, Global test loss: 0.936, Global test accuracy: 96.62
Round  99, Train loss: 1.130, Test loss: 0.936, Test accuracy: 96.76
Round  99, Global train loss: 1.130, Global test loss: 0.937, Global test accuracy: 96.78
Final Round, Train loss: 0.985, Test loss: 0.937, Test accuracy: 96.86
Final Round, Global train loss: 0.985, Global test loss: 0.937, Global test accuracy: 96.78
Average accuracy final 10 rounds: 96.80600000000003 

Average global accuracy final 10 rounds: 96.84 

508.2013850212097
[0.8355181217193604, 1.6710362434387207, 2.4017181396484375, 3.1324000358581543, 3.870063066482544, 4.607726097106934, 5.3387839794158936, 6.0698418617248535, 6.833780765533447, 7.597719669342041, 8.347605466842651, 9.097491264343262, 9.8338463306427, 10.570201396942139, 11.311341762542725, 12.05248212814331, 12.789281368255615, 13.52608060836792, 14.29853630065918, 15.07099199295044, 15.838773965835571, 16.606555938720703, 17.344069957733154, 18.081583976745605, 18.81486701965332, 19.548150062561035, 20.28439712524414, 21.020644187927246, 21.75842833518982, 22.496212482452393, 23.23991632461548, 23.983620166778564, 24.72962737083435, 25.475634574890137, 26.21494221687317, 26.9542498588562, 27.704103231430054, 28.453956604003906, 29.202305555343628, 29.95065450668335, 30.68673825263977, 31.42282199859619, 32.19925308227539, 32.97568416595459, 33.75671410560608, 34.53774404525757, 35.318315267562866, 36.098886489868164, 36.867207050323486, 37.63552761077881, 38.364825963974, 39.09412431716919, 39.82347631454468, 40.552828311920166, 41.28348231315613, 42.01413631439209, 42.74217486381531, 43.470213413238525, 44.204521894454956, 44.93883037567139, 45.704955101013184, 46.47107982635498, 47.22149205207825, 47.971904277801514, 48.72483229637146, 49.477760314941406, 50.18995451927185, 50.902148723602295, 51.662734508514404, 52.423320293426514, 53.18726110458374, 53.95120191574097, 54.68577861785889, 55.42035531997681, 56.12677359580994, 56.833191871643066, 57.57692217826843, 58.3206524848938, 59.064255475997925, 59.80785846710205, 60.553536891937256, 61.29921531677246, 62.01317834854126, 62.72714138031006, 63.46115255355835, 64.19516372680664, 64.92693829536438, 65.65871286392212, 66.41416335105896, 67.1696138381958, 67.89387512207031, 68.61813640594482, 69.37010931968689, 70.12208223342896, 70.8718421459198, 71.62160205841064, 72.39252281188965, 73.16344356536865, 73.90624833106995, 74.64905309677124, 75.39943885803223, 76.14982461929321, 76.8862771987915, 77.6227297782898, 78.37779569625854, 79.1328616142273, 79.87471079826355, 80.6165599822998, 81.36424088478088, 82.11192178726196, 82.87787747383118, 83.64383316040039, 84.38063097000122, 85.11742877960205, 85.86446523666382, 86.61150169372559, 87.36629247665405, 88.12108325958252, 88.85048341751099, 89.57988357543945, 90.31468391418457, 91.04948425292969, 91.76452040672302, 92.47955656051636, 93.24119019508362, 94.00282382965088, 94.75268340110779, 95.5025429725647, 96.26989340782166, 97.03724384307861, 97.77284812927246, 98.50845241546631, 99.21429991722107, 99.92014741897583, 100.64551854133606, 101.37088966369629, 102.10534048080444, 102.8397912979126, 103.57869839668274, 104.31760549545288, 105.06430649757385, 105.81100749969482, 106.53170585632324, 107.25240421295166, 107.9856686592102, 108.71893310546875, 109.46830487251282, 110.21767663955688, 110.92773985862732, 111.63780307769775, 112.3685393333435, 113.09927558898926, 113.83977317810059, 114.58027076721191, 115.31985116004944, 116.05943155288696, 116.78986096382141, 117.52029037475586, 118.2655668258667, 119.01084327697754, 119.75049567222595, 120.49014806747437, 121.23051595687866, 121.97088384628296, 122.69511699676514, 123.41935014724731, 124.18218421936035, 124.94501829147339, 125.6965389251709, 126.44805955886841, 127.17412519454956, 127.90019083023071, 128.6275074481964, 129.3548240661621, 130.10414481163025, 130.8534655570984, 131.6086072921753, 132.3637490272522, 133.1204752922058, 133.87720155715942, 134.63406562805176, 135.3909296989441, 136.12468028068542, 136.85843086242676, 137.606849193573, 138.35526752471924, 139.09276747703552, 139.8302674293518, 140.5730221271515, 141.31577682495117, 142.04081535339355, 142.76585388183594, 143.50162887573242, 144.2374038696289, 144.96835231781006, 145.6993007659912, 146.43979692459106, 147.18029308319092, 147.90382528305054, 148.62735748291016, 150.11725401878357, 151.60715055465698]
[71.32, 71.32, 83.46, 83.46, 87.54, 87.54, 92.96, 92.96, 93.42, 93.42, 95.54, 95.54, 95.76, 95.76, 95.82, 95.82, 96.12, 96.12, 96.28, 96.28, 96.4, 96.4, 96.46, 96.46, 96.76, 96.76, 96.72, 96.72, 96.84, 96.84, 96.7, 96.7, 96.7, 96.7, 96.72, 96.72, 96.76, 96.76, 96.82, 96.82, 96.76, 96.76, 96.58, 96.58, 96.62, 96.62, 96.66, 96.66, 96.7, 96.7, 96.76, 96.76, 96.74, 96.74, 96.72, 96.72, 96.64, 96.64, 96.62, 96.62, 96.62, 96.62, 96.6, 96.6, 96.64, 96.64, 96.58, 96.58, 96.6, 96.6, 96.8, 96.8, 96.86, 96.86, 96.86, 96.86, 96.84, 96.84, 96.8, 96.8, 96.84, 96.84, 96.86, 96.86, 96.88, 96.88, 96.84, 96.84, 96.74, 96.74, 96.78, 96.78, 96.82, 96.82, 96.82, 96.82, 96.86, 96.86, 96.84, 96.84, 96.82, 96.82, 96.84, 96.84, 96.82, 96.82, 96.78, 96.78, 96.78, 96.78, 96.82, 96.82, 96.78, 96.78, 96.8, 96.8, 96.86, 96.86, 96.88, 96.88, 96.84, 96.84, 96.86, 96.86, 96.94, 96.94, 96.92, 96.92, 96.96, 96.96, 96.9, 96.9, 96.94, 96.94, 96.96, 96.96, 97.0, 97.0, 96.98, 96.98, 96.98, 96.98, 96.94, 96.94, 96.96, 96.96, 96.96, 96.96, 96.98, 96.98, 96.94, 96.94, 96.94, 96.94, 96.96, 96.96, 96.98, 96.98, 96.98, 96.98, 97.04, 97.04, 97.0, 97.0, 96.98, 96.98, 96.94, 96.94, 96.94, 96.94, 96.9, 96.9, 96.9, 96.9, 96.88, 96.88, 96.84, 96.84, 96.88, 96.88, 96.84, 96.84, 96.84, 96.84, 96.82, 96.82, 96.8, 96.8, 96.8, 96.8, 96.8, 96.8, 96.8, 96.8, 96.8, 96.8, 96.8, 96.8, 96.76, 96.76, 96.86, 96.86]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.2 , level_n_lowerb:0.4  

   Client 9, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Traceback (most recent call last):
  File "main_fedpac_co_teaching.py", line 250, in <module>
    local.filter_data(net=net_local.to(args.device), net2=net_local2.to(args.device), concept_matrix_local = concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1587, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

   Client 4, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550021 (local), 549696 (global); Percentage 99.94 (549696/550021)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 1.623, Test loss: 1.591, Test accuracy: 49.34
Round   0, Global train loss: 1.623, Global test loss: 1.591, Global test accuracy: 49.38
Round   1, Train loss: 1.581, Test loss: 1.541, Test accuracy: 77.24
Round   1, Global train loss: 1.581, Global test loss: 1.540, Global test accuracy: 76.88
Round   2, Train loss: 1.474, Test loss: 1.335, Test accuracy: 91.26
Round   2, Global train loss: 1.474, Global test loss: 1.322, Global test accuracy: 90.68
Round   3, Train loss: 1.290, Test loss: 1.108, Test accuracy: 94.68
Round   3, Global train loss: 1.290, Global test loss: 1.079, Global test accuracy: 94.92
Round   4, Train loss: 1.076, Test loss: 1.033, Test accuracy: 95.62
Round   4, Global train loss: 1.076, Global test loss: 0.998, Global test accuracy: 95.46
Round   5, Train loss: 1.120, Test loss: 1.009, Test accuracy: 95.84
Round   5, Global train loss: 1.120, Global test loss: 0.986, Global test accuracy: 96.16
Round   6, Train loss: 1.197, Test loss: 0.998, Test accuracy: 96.28
Round   6, Global train loss: 1.197, Global test loss: 0.992, Global test accuracy: 96.40
Round   7, Train loss: 1.091, Test loss: 0.988, Test accuracy: 96.30
Round   7, Global train loss: 1.091, Global test loss: 0.977, Global test accuracy: 96.36
Round   8, Train loss: 1.110, Test loss: 0.984, Test accuracy: 96.46
Round   8, Global train loss: 1.110, Global test loss: 0.972, Global test accuracy: 96.60
Round   9, Train loss: 0.980, Test loss: 0.975, Test accuracy: 96.66
Round   9, Global train loss: 0.980, Global test loss: 0.959, Global test accuracy: 96.70
Round  10, Train loss: 0.974, Test loss: 0.966, Test accuracy: 96.76
Round  10, Global train loss: 0.974, Global test loss: 0.954, Global test accuracy: 96.94
Round  11, Train loss: 0.959, Test loss: 0.962, Test accuracy: 96.84
Round  11, Global train loss: 0.959, Global test loss: 0.951, Global test accuracy: 96.96
Round  12, Train loss: 1.006, Test loss: 0.956, Test accuracy: 96.84
Round  12, Global train loss: 1.006, Global test loss: 0.955, Global test accuracy: 96.64
Round  13, Train loss: 1.114, Test loss: 0.956, Test accuracy: 96.88
Round  13, Global train loss: 1.114, Global test loss: 0.955, Global test accuracy: 96.96
Round  14, Train loss: 1.106, Test loss: 0.959, Test accuracy: 96.92
Round  14, Global train loss: 1.106, Global test loss: 0.959, Global test accuracy: 96.88
Round  15, Train loss: 0.983, Test loss: 0.956, Test accuracy: 97.08
Round  15, Global train loss: 0.983, Global test loss: 0.950, Global test accuracy: 97.22
Round  16, Train loss: 0.973, Test loss: 0.953, Test accuracy: 97.02
Round  16, Global train loss: 0.973, Global test loss: 0.952, Global test accuracy: 96.82
Round  17, Train loss: 1.053, Test loss: 0.952, Test accuracy: 97.16
Round  17, Global train loss: 1.053, Global test loss: 0.948, Global test accuracy: 97.18
Round  18, Train loss: 0.945, Test loss: 0.951, Test accuracy: 97.20
Round  18, Global train loss: 0.945, Global test loss: 0.942, Global test accuracy: 97.42
Round  19, Train loss: 0.969, Test loss: 0.949, Test accuracy: 97.32
Round  19, Global train loss: 0.969, Global test loss: 0.943, Global test accuracy: 97.28
Round  20, Train loss: 0.962, Test loss: 0.948, Test accuracy: 97.24
Round  20, Global train loss: 0.962, Global test loss: 0.946, Global test accuracy: 97.14
Round  21, Train loss: 1.050, Test loss: 0.949, Test accuracy: 97.30
Round  21, Global train loss: 1.050, Global test loss: 0.943, Global test accuracy: 97.40
Round  22, Train loss: 1.155, Test loss: 0.952, Test accuracy: 97.32
Round  22, Global train loss: 1.155, Global test loss: 0.949, Global test accuracy: 97.36
Round  23, Train loss: 0.990, Test loss: 0.951, Test accuracy: 97.32
Round  23, Global train loss: 0.990, Global test loss: 0.949, Global test accuracy: 97.20
Round  24, Train loss: 1.051, Test loss: 0.948, Test accuracy: 97.34
Round  24, Global train loss: 1.051, Global test loss: 0.945, Global test accuracy: 97.36
Round  25, Train loss: 1.095, Test loss: 0.948, Test accuracy: 97.36
Round  25, Global train loss: 1.095, Global test loss: 0.946, Global test accuracy: 97.38
Round  26, Train loss: 0.932, Test loss: 0.947, Test accuracy: 97.44
Round  26, Global train loss: 0.932, Global test loss: 0.940, Global test accuracy: 97.52
Round  27, Train loss: 1.008, Test loss: 0.945, Test accuracy: 97.58
Round  27, Global train loss: 1.008, Global test loss: 0.942, Global test accuracy: 97.72
Round  28, Train loss: 1.039, Test loss: 0.945, Test accuracy: 97.48
Round  28, Global train loss: 1.039, Global test loss: 0.942, Global test accuracy: 97.48
Round  29, Train loss: 0.975, Test loss: 0.945, Test accuracy: 97.56
Round  29, Global train loss: 0.975, Global test loss: 0.939, Global test accuracy: 97.70
Round  30, Train loss: 1.145, Test loss: 0.947, Test accuracy: 97.52
Round  30, Global train loss: 1.145, Global test loss: 0.949, Global test accuracy: 97.36
Round  31, Train loss: 1.140, Test loss: 0.951, Test accuracy: 97.54
Round  31, Global train loss: 1.140, Global test loss: 0.946, Global test accuracy: 97.54
Round  32, Train loss: 1.037, Test loss: 0.951, Test accuracy: 97.60
Round  32, Global train loss: 1.037, Global test loss: 0.948, Global test accuracy: 97.34
Round  33, Train loss: 1.031, Test loss: 0.949, Test accuracy: 97.64
Round  33, Global train loss: 1.031, Global test loss: 0.944, Global test accuracy: 97.58
Round  34, Train loss: 1.074, Test loss: 0.949, Test accuracy: 97.50
Round  34, Global train loss: 1.074, Global test loss: 0.946, Global test accuracy: 97.36
Round  35, Train loss: 0.958, Test loss: 0.946, Test accuracy: 97.38
Round  35, Global train loss: 0.958, Global test loss: 0.940, Global test accuracy: 97.80
Round  36, Train loss: 1.064, Test loss: 0.945, Test accuracy: 97.52
Round  36, Global train loss: 1.064, Global test loss: 0.946, Global test accuracy: 97.62
Round  37, Train loss: 0.951, Test loss: 0.944, Test accuracy: 97.54
Round  37, Global train loss: 0.951, Global test loss: 0.938, Global test accuracy: 98.00
Round  38, Train loss: 1.048, Test loss: 0.945, Test accuracy: 97.64
Round  38, Global train loss: 1.048, Global test loss: 0.941, Global test accuracy: 97.82
Round  39, Train loss: 0.977, Test loss: 0.943, Test accuracy: 97.50
Round  39, Global train loss: 0.977, Global test loss: 0.942, Global test accuracy: 97.76
Round  40, Train loss: 1.048, Test loss: 0.945, Test accuracy: 97.60
Round  40, Global train loss: 1.048, Global test loss: 0.944, Global test accuracy: 97.72
Round  41, Train loss: 1.036, Test loss: 0.942, Test accuracy: 97.64
Round  41, Global train loss: 1.036, Global test loss: 0.940, Global test accuracy: 97.80
Round  42, Train loss: 0.954, Test loss: 0.940, Test accuracy: 97.62
Round  42, Global train loss: 0.954, Global test loss: 0.938, Global test accuracy: 97.78
Round  43, Train loss: 0.948, Test loss: 0.940, Test accuracy: 97.64
Round  43, Global train loss: 0.948, Global test loss: 0.936, Global test accuracy: 97.76
Round  44, Train loss: 1.133, Test loss: 0.943, Test accuracy: 97.82
Round  44, Global train loss: 1.133, Global test loss: 0.940, Global test accuracy: 97.72
Round  45, Train loss: 1.057, Test loss: 0.943, Test accuracy: 97.80
Round  45, Global train loss: 1.057, Global test loss: 0.942, Global test accuracy: 97.88
Round  46, Train loss: 1.030, Test loss: 0.942, Test accuracy: 97.78
Round  46, Global train loss: 1.030, Global test loss: 0.938, Global test accuracy: 98.04
Round  47, Train loss: 0.966, Test loss: 0.941, Test accuracy: 97.74
Round  47, Global train loss: 0.966, Global test loss: 0.937, Global test accuracy: 97.90
Round  48, Train loss: 0.925, Test loss: 0.938, Test accuracy: 97.64
Round  48, Global train loss: 0.925, Global test loss: 0.933, Global test accuracy: 97.94
Round  49, Train loss: 1.019, Test loss: 0.940, Test accuracy: 97.66
Round  49, Global train loss: 1.019, Global test loss: 0.938, Global test accuracy: 97.84
Round  50, Train loss: 0.964, Test loss: 0.940, Test accuracy: 97.72
Round  50, Global train loss: 0.964, Global test loss: 0.936, Global test accuracy: 97.96
Round  51, Train loss: 1.041, Test loss: 0.943, Test accuracy: 97.74
Round  51, Global train loss: 1.041, Global test loss: 0.941, Global test accuracy: 97.88
Round  52, Train loss: 0.922, Test loss: 0.940, Test accuracy: 97.72
Round  52, Global train loss: 0.922, Global test loss: 0.933, Global test accuracy: 97.94
Round  53, Train loss: 0.926, Test loss: 0.937, Test accuracy: 97.74
Round  53, Global train loss: 0.926, Global test loss: 0.934, Global test accuracy: 98.02
Round  54, Train loss: 1.022, Test loss: 0.939, Test accuracy: 97.72
Round  54, Global train loss: 1.022, Global test loss: 0.936, Global test accuracy: 97.90
Round  55, Train loss: 0.958, Test loss: 0.940, Test accuracy: 97.58
Round  55, Global train loss: 0.958, Global test loss: 0.934, Global test accuracy: 97.98
Round  56, Train loss: 0.920, Test loss: 0.938, Test accuracy: 97.60
Round  56, Global train loss: 0.920, Global test loss: 0.932, Global test accuracy: 97.84
Round  57, Train loss: 1.037, Test loss: 0.940, Test accuracy: 97.58
Round  57, Global train loss: 1.037, Global test loss: 0.938, Global test accuracy: 97.86
Round  58, Train loss: 0.958, Test loss: 0.940, Test accuracy: 97.66
Round  58, Global train loss: 0.958, Global test loss: 0.934, Global test accuracy: 98.04
Round  59, Train loss: 1.012, Test loss: 0.941, Test accuracy: 97.74
Round  59, Global train loss: 1.012, Global test loss: 0.936, Global test accuracy: 97.86
Round  60, Train loss: 1.050, Test loss: 0.945, Test accuracy: 97.56
Round  60, Global train loss: 1.050, Global test loss: 0.945, Global test accuracy: 97.46
Round  61, Train loss: 0.937, Test loss: 0.942, Test accuracy: 97.66
Round  61, Global train loss: 0.937, Global test loss: 0.936, Global test accuracy: 97.90
Round  62, Train loss: 1.050, Test loss: 0.940, Test accuracy: 97.64
Round  62, Global train loss: 1.050, Global test loss: 0.938, Global test accuracy: 97.96
Round  63, Train loss: 1.027, Test loss: 0.939, Test accuracy: 97.60
Round  63, Global train loss: 1.027, Global test loss: 0.935, Global test accuracy: 98.06
Round  64, Train loss: 1.060, Test loss: 0.941, Test accuracy: 97.72
Round  64, Global train loss: 1.060, Global test loss: 0.938, Global test accuracy: 98.02
Round  65, Train loss: 0.954, Test loss: 0.940, Test accuracy: 97.60
Round  65, Global train loss: 0.954, Global test loss: 0.935, Global test accuracy: 97.98
Round  66, Train loss: 1.009, Test loss: 0.942, Test accuracy: 97.62
Round  66, Global train loss: 1.009, Global test loss: 0.937, Global test accuracy: 97.76
Round  67, Train loss: 1.025, Test loss: 0.940, Test accuracy: 97.62
Round  67, Global train loss: 1.025, Global test loss: 0.936, Global test accuracy: 97.94
Round  68, Train loss: 0.920, Test loss: 0.938, Test accuracy: 97.62
Round  68, Global train loss: 0.920, Global test loss: 0.933, Global test accuracy: 97.88
Round  69, Train loss: 1.045, Test loss: 0.942, Test accuracy: 97.58
Round  69, Global train loss: 1.045, Global test loss: 0.945, Global test accuracy: 97.20
Round  70, Train loss: 0.919, Test loss: 0.939, Test accuracy: 97.64
Round  70, Global train loss: 0.919, Global test loss: 0.933, Global test accuracy: 98.06
Round  71, Train loss: 1.011, Test loss: 0.940, Test accuracy: 97.64
Round  71, Global train loss: 1.011, Global test loss: 0.938, Global test accuracy: 97.86
Round  72, Train loss: 1.025, Test loss: 0.943, Test accuracy: 97.54
Round  72, Global train loss: 1.025, Global test loss: 0.942, Global test accuracy: 97.96
Round  73, Train loss: 1.127, Test loss: 0.949, Test accuracy: 97.32
Round  73, Global train loss: 1.127, Global test loss: 0.947, Global test accuracy: 97.80
Round  74, Train loss: 0.951, Test loss: 0.944, Test accuracy: 97.60
Round  74, Global train loss: 0.951, Global test loss: 0.937, Global test accuracy: 97.78
Round  75, Train loss: 1.005, Test loss: 0.944, Test accuracy: 97.56
Round  75, Global train loss: 1.005, Global test loss: 0.940, Global test accuracy: 97.84
Round  76, Train loss: 1.005, Test loss: 0.945, Test accuracy: 97.30
Round  76, Global train loss: 1.005, Global test loss: 0.941, Global test accuracy: 97.78
Round  77, Train loss: 1.035, Test loss: 0.951, Test accuracy: 96.94
Round  77, Global train loss: 1.035, Global test loss: 0.953, Global test accuracy: 96.70
Round  78, Train loss: 1.017, Test loss: 0.951, Test accuracy: 96.94
Round  78, Global train loss: 1.017, Global test loss: 0.946, Global test accuracy: 97.46
Round  79, Train loss: 0.919, Test loss: 0.941, Test accuracy: 97.46
Round  79, Global train loss: 0.919, Global test loss: 0.934, Global test accuracy: 97.84
Round  80, Train loss: 0.932, Test loss: 0.939, Test accuracy: 97.48
Round  80, Global train loss: 0.932, Global test loss: 0.934, Global test accuracy: 97.86
Round  81, Train loss: 0.932, Test loss: 0.938, Test accuracy: 97.58
Round  81, Global train loss: 0.932, Global test loss: 0.933, Global test accuracy: 97.90
Round  82, Train loss: 0.947, Test loss: 0.938, Test accuracy: 97.48
Round  82, Global train loss: 0.947, Global test loss: 0.934, Global test accuracy: 97.70
Round  83, Train loss: 1.014, Test loss: 0.943, Test accuracy: 97.24
Round  83, Global train loss: 1.014, Global test loss: 0.939, Global test accuracy: 97.74
Round  84, Train loss: 0.945, Test loss: 0.942, Test accuracy: 97.18
Round  84, Global train loss: 0.945, Global test loss: 0.936, Global test accuracy: 97.70
Round  85, Train loss: 0.913, Test loss: 0.938, Test accuracy: 97.40
Round  85, Global train loss: 0.913, Global test loss: 0.932, Global test accuracy: 97.80
Round  86, Train loss: 0.915, Test loss: 0.936, Test accuracy: 97.44
Round  86, Global train loss: 0.915, Global test loss: 0.930, Global test accuracy: 97.90
Round  87, Train loss: 1.020, Test loss: 0.937, Test accuracy: 97.62
Round  87, Global train loss: 1.020, Global test loss: 0.932, Global test accuracy: 98.06
Round  88, Train loss: 1.047, Test loss: 0.942, Test accuracy: 97.42
Round  88, Global train loss: 1.047, Global test loss: 0.938, Global test accuracy: 97.84
Round  89, Train loss: 0.913, Test loss: 0.940, Test accuracy: 97.54
Round  89, Global train loss: 0.913, Global test loss: 0.932, Global test accuracy: 98.06
Round  90, Train loss: 0.960, Test loss: 0.939, Test accuracy: 97.50
Round  90, Global train loss: 0.960, Global test loss: 0.933, Global test accuracy: 97.86
Round  91, Train loss: 1.045, Test loss: 0.943, Test accuracy: 97.38
Round  91, Global train loss: 1.045, Global test loss: 0.938, Global test accuracy: 97.72
Round  92, Train loss: 0.997, Test loss: 0.945, Test accuracy: 97.42
Round  92, Global train loss: 0.997, Global test loss: 0.938, Global test accuracy: 97.92/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  93, Train loss: 1.010, Test loss: 0.949, Test accuracy: 97.04
Round  93, Global train loss: 1.010, Global test loss: 0.945, Global test accuracy: 97.44
Round  94, Train loss: 1.030, Test loss: 0.945, Test accuracy: 97.36
Round  94, Global train loss: 1.030, Global test loss: 0.940, Global test accuracy: 97.68
Round  95, Train loss: 1.040, Test loss: 0.946, Test accuracy: 97.44
Round  95, Global train loss: 1.040, Global test loss: 0.942, Global test accuracy: 97.66
Round  96, Train loss: 0.942, Test loss: 0.943, Test accuracy: 97.56
Round  96, Global train loss: 0.942, Global test loss: 0.936, Global test accuracy: 97.62
Round  97, Train loss: 1.028, Test loss: 0.943, Test accuracy: 97.52
Round  97, Global train loss: 1.028, Global test loss: 0.939, Global test accuracy: 98.00
Round  98, Train loss: 1.027, Test loss: 0.945, Test accuracy: 97.64
Round  98, Global train loss: 1.027, Global test loss: 0.941, Global test accuracy: 97.74
Round  99, Train loss: 0.931, Test loss: 0.941, Test accuracy: 97.60
Round  99, Global train loss: 0.931, Global test loss: 0.935, Global test accuracy: 97.84
Final Round, Train loss: 0.975, Test loss: 0.941, Test accuracy: 97.50
Final Round, Global train loss: 0.975, Global test loss: 0.935, Global test accuracy: 97.84
Average accuracy final 10 rounds: 97.446
427.57501578330994
[0.9372775554656982, 1.7459118366241455, 2.532970905303955, 3.311854124069214, 4.120121479034424, 4.903852224349976, 5.711183547973633, 6.524975299835205, 7.330235242843628, 8.136838674545288, 8.931332349777222, 9.75304627418518, 10.578001737594604, 11.371614217758179, 12.177911043167114, 13.004685878753662, 13.80155062675476, 14.624823808670044, 15.440934419631958, 16.24027395248413, 17.036649465560913, 17.845581769943237, 18.64067554473877, 19.43645739555359, 20.23186945915222, 21.040011644363403, 21.84165334701538, 22.646531105041504, 23.439250469207764, 24.23200488090515, 25.04135298728943, 25.843169689178467, 26.592135190963745, 27.38042163848877, 28.19918704032898, 28.994537830352783, 29.783258199691772, 30.536341428756714, 31.325071334838867, 32.0920672416687, 32.88082313537598, 33.67978477478027, 34.45693612098694, 35.26037812232971, 36.06940531730652, 36.8546416759491, 37.64460277557373, 38.44544768333435, 39.253710985183716, 40.021899700164795, 40.80351185798645, 41.61654829978943, 42.41051411628723, 43.208093881607056, 44.01285791397095, 44.825299978256226, 45.63896441459656, 46.40787172317505, 47.208783864974976, 47.97786331176758, 48.78316259384155, 49.58698749542236, 50.38861632347107, 51.161667346954346, 51.95985150337219, 52.770569801330566, 53.56769347190857, 54.36736583709717, 55.13759922981262, 55.926546812057495, 56.71696615219116, 57.495264530181885, 58.28671979904175, 59.08180809020996, 59.89031982421875, 60.693710803985596, 61.47166466712952, 62.2506160736084, 63.106924295425415, 63.89783573150635, 64.68897128105164, 65.48637270927429, 66.28335356712341, 67.08440256118774, 67.89054822921753, 68.67212796211243, 69.45235538482666, 70.23743510246277, 71.01150178909302, 71.80429816246033, 72.5818362236023, 73.37436056137085, 74.09018039703369, 74.80979180335999, 75.58808326721191, 76.38715600967407, 77.18854784965515, 77.98870587348938, 78.80308103561401, 79.59848475456238, 80.81928730010986]
[49.34, 77.24, 91.26, 94.68, 95.62, 95.84, 96.28, 96.3, 96.46, 96.66, 96.76, 96.84, 96.84, 96.88, 96.92, 97.08, 97.02, 97.16, 97.2, 97.32, 97.24, 97.3, 97.32, 97.32, 97.34, 97.36, 97.44, 97.58, 97.48, 97.56, 97.52, 97.54, 97.6, 97.64, 97.5, 97.38, 97.52, 97.54, 97.64, 97.5, 97.6, 97.64, 97.62, 97.64, 97.82, 97.8, 97.78, 97.74, 97.64, 97.66, 97.72, 97.74, 97.72, 97.74, 97.72, 97.58, 97.6, 97.58, 97.66, 97.74, 97.56, 97.66, 97.64, 97.6, 97.72, 97.6, 97.62, 97.62, 97.62, 97.58, 97.64, 97.64, 97.54, 97.32, 97.6, 97.56, 97.3, 96.94, 96.94, 97.46, 97.48, 97.58, 97.48, 97.24, 97.18, 97.4, 97.44, 97.62, 97.42, 97.54, 97.5, 97.38, 97.42, 97.04, 97.36, 97.44, 97.56, 97.52, 97.64, 97.6, 97.5]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fedpac_copsl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist,  filter_alg: loss_psl, level_n_system: 0.2 , level_n_lowerb:0.4  

   Client 3, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550021 (local), 549696 (global); Percentage 99.94 (549696/550021)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 1.623, Test loss: 1.589, Test accuracy: 42.92
Round   0, Global train loss: 1.623, Global test loss: 1.589, Global test accuracy: 42.84
Round   1, Train loss: 1.569, Test loss: 1.503, Test accuracy: 74.86
Round   1, Global train loss: 1.569, Global test loss: 1.503, Global test accuracy: 74.78
Round   2, Train loss: 1.424, Test loss: 1.245, Test accuracy: 84.28
Round   2, Global train loss: 1.424, Global test loss: 1.243, Global test accuracy: 84.48
Round   3, Train loss: 1.187, Test loss: 1.047, Test accuracy: 93.60
Round   3, Global train loss: 1.187, Global test loss: 1.044, Global test accuracy: 94.00
Round   4, Train loss: 1.084, Test loss: 0.996, Test accuracy: 95.38
Round   4, Global train loss: 1.084, Global test loss: 0.994, Global test accuracy: 95.56
Round   5, Train loss: 1.058, Test loss: 0.978, Test accuracy: 95.94
Round   5, Global train loss: 1.058, Global test loss: 0.976, Global test accuracy: 96.20
Round   6, Train loss: 1.046, Test loss: 0.969, Test accuracy: 96.44
Round   6, Global train loss: 1.046, Global test loss: 0.966, Global test accuracy: 96.34
Round   7, Train loss: 1.038, Test loss: 0.964, Test accuracy: 96.70
Round   7, Global train loss: 1.038, Global test loss: 0.961, Global test accuracy: 96.70
Round   8, Train loss: 1.033, Test loss: 0.960, Test accuracy: 96.80
Round   8, Global train loss: 1.033, Global test loss: 0.957, Global test accuracy: 96.76
Round   9, Train loss: 1.029, Test loss: 0.957, Test accuracy: 96.86
Round   9, Global train loss: 1.029, Global test loss: 0.954, Global test accuracy: 96.98
Round  10, Train loss: 1.085, Test loss: 0.956, Test accuracy: 96.90
Round  10, Global train loss: 1.085, Global test loss: 0.955, Global test accuracy: 96.80
Traceback (most recent call last):
  File "main_fedpac_copsl.py", line 280, in <module>
    w_local, loss, indd, class_center_local, class_num, noisy_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys,
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2559, in train
    self.filter_data(net, local_net, iter2-head_eps+1, local_eps-head_eps+1, concept_matrix_local)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2396, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist, level_n_system: 0.2 , level_n_lowerb:0.8  

   Client 0, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.594, Test loss: 1.564, Test accuracy: 58.82
Round   0, Global train loss: 1.594, Global test loss: 1.567, Global test accuracy: 60.72
Round   1, Train loss: 1.456, Test loss: 1.376, Test accuracy: 65.58
Round   1, Global train loss: 1.456, Global test loss: 1.287, Global test accuracy: 75.46
Round   2, Train loss: 1.135, Test loss: 1.206, Test accuracy: 75.42
Round   2, Global train loss: 1.135, Global test loss: 0.999, Global test accuracy: 94.62
Round   3, Train loss: 1.224, Test loss: 1.190, Test accuracy: 78.44
Round   3, Global train loss: 1.224, Global test loss: 1.078, Global test accuracy: 93.32
Round   4, Train loss: 1.419, Test loss: 1.238, Test accuracy: 76.76
Round   4, Global train loss: 1.419, Global test loss: 1.365, Global test accuracy: 74.54
Round   5, Train loss: 1.180, Test loss: 1.154, Test accuracy: 80.94
Round   5, Global train loss: 1.180, Global test loss: 1.017, Global test accuracy: 93.76
Round   6, Train loss: 1.094, Test loss: 1.097, Test accuracy: 83.48
Round   6, Global train loss: 1.094, Global test loss: 0.980, Global test accuracy: 94.76
Round   7, Train loss: 0.948, Test loss: 1.082, Test accuracy: 84.40
Round   7, Global train loss: 0.948, Global test loss: 0.957, Global test accuracy: 96.22
Round   8, Train loss: 1.163, Test loss: 1.104, Test accuracy: 81.74
Round   8, Global train loss: 1.163, Global test loss: 1.085, Global test accuracy: 84.24
Round   9, Train loss: 1.144, Test loss: 1.100, Test accuracy: 81.56
Round   9, Global train loss: 1.144, Global test loss: 1.074, Global test accuracy: 85.24
Round  10, Train loss: 1.148, Test loss: 1.089, Test accuracy: 85.22
Round  10, Global train loss: 1.148, Global test loss: 1.033, Global test accuracy: 95.12
Round  11, Train loss: 1.090, Test loss: 1.078, Test accuracy: 85.16
Round  11, Global train loss: 1.090, Global test loss: 0.974, Global test accuracy: 95.22
Round  12, Train loss: 0.927, Test loss: 1.073, Test accuracy: 85.42
Round  12, Global train loss: 0.927, Global test loss: 0.949, Global test accuracy: 96.50
Round  13, Train loss: 1.180, Test loss: 1.087, Test accuracy: 85.30
Round  13, Global train loss: 1.180, Global test loss: 1.122, Global test accuracy: 79.68
Round  14, Train loss: 0.977, Test loss: 1.080, Test accuracy: 85.58
Round  14, Global train loss: 0.977, Global test loss: 0.969, Global test accuracy: 94.26
Round  15, Train loss: 1.135, Test loss: 1.071, Test accuracy: 85.84
Round  15, Global train loss: 1.135, Global test loss: 1.000, Global test accuracy: 95.66
Round  16, Train loss: 1.164, Test loss: 1.061, Test accuracy: 86.72
Round  16, Global train loss: 1.164, Global test loss: 1.002, Global test accuracy: 95.20
Round  17, Train loss: 1.154, Test loss: 1.058, Test accuracy: 86.50
Round  17, Global train loss: 1.154, Global test loss: 0.992, Global test accuracy: 94.88
Round  18, Train loss: 1.098, Test loss: 1.063, Test accuracy: 85.74
Round  18, Global train loss: 1.098, Global test loss: 1.064, Global test accuracy: 85.50
Round  19, Train loss: 1.145, Test loss: 1.063, Test accuracy: 85.18
Round  19, Global train loss: 1.145, Global test loss: 1.002, Global test accuracy: 93.80
Round  20, Train loss: 1.087, Test loss: 1.065, Test accuracy: 84.42
Round  20, Global train loss: 1.087, Global test loss: 0.972, Global test accuracy: 95.84
Round  21, Train loss: 1.102, Test loss: 1.067, Test accuracy: 84.04
Round  21, Global train loss: 1.102, Global test loss: 1.082, Global test accuracy: 81.78
Round  22, Train loss: 1.088, Test loss: 1.067, Test accuracy: 84.26
Round  22, Global train loss: 1.088, Global test loss: 0.968, Global test accuracy: 95.56
Round  23, Train loss: 1.039, Test loss: 1.066, Test accuracy: 84.08
Round  23, Global train loss: 1.039, Global test loss: 0.958, Global test accuracy: 95.88
Round  24, Train loss: 0.954, Test loss: 1.066, Test accuracy: 84.16
Round  24, Global train loss: 0.954, Global test loss: 0.948, Global test accuracy: 96.24
Round  25, Train loss: 0.990, Test loss: 1.068, Test accuracy: 83.74
Round  25, Global train loss: 0.990, Global test loss: 0.972, Global test accuracy: 93.72
Round  26, Train loss: 0.945, Test loss: 1.069, Test accuracy: 83.64
Round  26, Global train loss: 0.945, Global test loss: 1.002, Global test accuracy: 90.92
Round  27, Train loss: 1.060, Test loss: 1.066, Test accuracy: 83.82
Round  27, Global train loss: 1.060, Global test loss: 0.970, Global test accuracy: 94.78
Round  28, Train loss: 0.943, Test loss: 1.066, Test accuracy: 83.90
Round  28, Global train loss: 0.943, Global test loss: 0.989, Global test accuracy: 92.66
Round  29, Train loss: 0.913, Test loss: 1.066, Test accuracy: 83.88
Round  29, Global train loss: 0.913, Global test loss: 0.949, Global test accuracy: 95.86
Round  30, Train loss: 1.055, Test loss: 1.064, Test accuracy: 83.88
Round  30, Global train loss: 1.055, Global test loss: 0.996, Global test accuracy: 91.52
Round  31, Train loss: 0.914, Test loss: 1.064, Test accuracy: 83.86
Round  31, Global train loss: 0.914, Global test loss: 0.942, Global test accuracy: 96.52
Round  32, Train loss: 0.941, Test loss: 1.061, Test accuracy: 84.10
Round  32, Global train loss: 0.941, Global test loss: 0.970, Global test accuracy: 94.32
Round  33, Train loss: 0.912, Test loss: 1.061, Test accuracy: 84.12
Round  33, Global train loss: 0.912, Global test loss: 0.948, Global test accuracy: 95.82
Round  34, Train loss: 0.971, Test loss: 1.059, Test accuracy: 84.30
Round  34, Global train loss: 0.971, Global test loss: 0.964, Global test accuracy: 94.74
Round  35, Train loss: 0.932, Test loss: 1.058, Test accuracy: 84.46
Round  35, Global train loss: 0.932, Global test loss: 0.963, Global test accuracy: 94.60
Round  36, Train loss: 1.037, Test loss: 1.064, Test accuracy: 83.76
Round  36, Global train loss: 1.037, Global test loss: 0.986, Global test accuracy: 92.64
Round  37, Train loss: 1.026, Test loss: 1.063, Test accuracy: 83.90
Round  37, Global train loss: 1.026, Global test loss: 0.964, Global test accuracy: 95.16
Round  38, Train loss: 0.947, Test loss: 1.063, Test accuracy: 83.88
Round  38, Global train loss: 0.947, Global test loss: 0.951, Global test accuracy: 95.68
Round  39, Train loss: 0.928, Test loss: 1.063, Test accuracy: 83.90
Round  39, Global train loss: 0.928, Global test loss: 0.962, Global test accuracy: 94.84
Round  40, Train loss: 0.925, Test loss: 1.063, Test accuracy: 83.78
Round  40, Global train loss: 0.925, Global test loss: 0.957, Global test accuracy: 95.44
Round  41, Train loss: 0.947, Test loss: 1.063, Test accuracy: 83.84
Round  41, Global train loss: 0.947, Global test loss: 0.947, Global test accuracy: 95.92
Round  42, Train loss: 0.976, Test loss: 1.061, Test accuracy: 83.88
Round  42, Global train loss: 0.976, Global test loss: 0.963, Global test accuracy: 94.50
Round  43, Train loss: 1.067, Test loss: 1.063, Test accuracy: 83.60
Round  43, Global train loss: 1.067, Global test loss: 1.003, Global test accuracy: 90.46
Round  44, Train loss: 0.923, Test loss: 1.062, Test accuracy: 83.68
Round  44, Global train loss: 0.923, Global test loss: 0.953, Global test accuracy: 95.80
Round  45, Train loss: 0.922, Test loss: 1.062, Test accuracy: 83.76
Round  45, Global train loss: 0.922, Global test loss: 0.955, Global test accuracy: 95.44
Round  46, Train loss: 1.039, Test loss: 1.065, Test accuracy: 83.60
Round  46, Global train loss: 1.039, Global test loss: 0.988, Global test accuracy: 92.48
Round  47, Train loss: 0.945, Test loss: 1.064, Test accuracy: 83.64
Round  47, Global train loss: 0.945, Global test loss: 0.946, Global test accuracy: 96.26
Round  48, Train loss: 1.034, Test loss: 1.066, Test accuracy: 83.58
Round  48, Global train loss: 1.034, Global test loss: 0.956, Global test accuracy: 95.72
Round  49, Train loss: 1.032, Test loss: 1.066, Test accuracy: 83.54
Round  49, Global train loss: 1.032, Global test loss: 0.989, Global test accuracy: 92.34
Round  50, Train loss: 1.026, Test loss: 1.070, Test accuracy: 83.08
Round  50, Global train loss: 1.026, Global test loss: 0.988, Global test accuracy: 92.24
Round  51, Train loss: 1.003, Test loss: 1.072, Test accuracy: 82.72
Round  51, Global train loss: 1.003, Global test loss: 0.971, Global test accuracy: 94.46
Round  52, Train loss: 0.966, Test loss: 1.071, Test accuracy: 82.98
Round  52, Global train loss: 0.966, Global test loss: 0.952, Global test accuracy: 95.96
Round  53, Train loss: 0.987, Test loss: 1.070, Test accuracy: 83.18
Round  53, Global train loss: 0.987, Global test loss: 0.961, Global test accuracy: 94.82
Round  54, Train loss: 0.943, Test loss: 1.069, Test accuracy: 83.26
Round  54, Global train loss: 0.943, Global test loss: 0.971, Global test accuracy: 94.12
Round  55, Train loss: 0.918, Test loss: 1.069, Test accuracy: 83.22
Round  55, Global train loss: 0.918, Global test loss: 0.955, Global test accuracy: 95.16
Round  56, Train loss: 0.983, Test loss: 1.072, Test accuracy: 82.88
Round  56, Global train loss: 0.983, Global test loss: 0.962, Global test accuracy: 95.02
Round  57, Train loss: 0.912, Test loss: 1.072, Test accuracy: 82.88
Round  57, Global train loss: 0.912, Global test loss: 0.941, Global test accuracy: 96.62
Round  58, Train loss: 0.967, Test loss: 1.072, Test accuracy: 82.94
Round  58, Global train loss: 0.967, Global test loss: 0.962, Global test accuracy: 94.42
Round  59, Train loss: 1.001, Test loss: 1.071, Test accuracy: 83.06
Round  59, Global train loss: 1.001, Global test loss: 0.993, Global test accuracy: 91.58
Round  60, Train loss: 0.946, Test loss: 1.071, Test accuracy: 83.04
Round  60, Global train loss: 0.946, Global test loss: 0.943, Global test accuracy: 96.48
Round  61, Train loss: 0.977, Test loss: 1.072, Test accuracy: 83.02
Round  61, Global train loss: 0.977, Global test loss: 0.961, Global test accuracy: 95.20
Round  62, Train loss: 0.941, Test loss: 1.072, Test accuracy: 82.98
Round  62, Global train loss: 0.941, Global test loss: 0.968, Global test accuracy: 93.94
Round  63, Train loss: 0.952, Test loss: 1.072, Test accuracy: 83.10
Round  63, Global train loss: 0.952, Global test loss: 0.952, Global test accuracy: 95.70
Round  64, Train loss: 0.964, Test loss: 1.076, Test accuracy: 82.68
Round  64, Global train loss: 0.964, Global test loss: 0.950, Global test accuracy: 96.12
Round  65, Train loss: 0.951, Test loss: 1.077, Test accuracy: 82.58
Round  65, Global train loss: 0.951, Global test loss: 0.958, Global test accuracy: 94.84
Round  66, Train loss: 0.945, Test loss: 1.077, Test accuracy: 82.60
Round  66, Global train loss: 0.945, Global test loss: 0.942, Global test accuracy: 96.52
Round  67, Train loss: 0.973, Test loss: 1.077, Test accuracy: 82.52
Round  67, Global train loss: 0.973, Global test loss: 0.960, Global test accuracy: 94.86
Round  68, Train loss: 1.000, Test loss: 1.076, Test accuracy: 82.56
Round  68, Global train loss: 1.000, Global test loss: 0.988, Global test accuracy: 92.38
Round  69, Train loss: 1.020, Test loss: 1.072, Test accuracy: 83.20
Round  69, Global train loss: 1.020, Global test loss: 0.990, Global test accuracy: 92.68
Round  70, Train loss: 0.979, Test loss: 1.073, Test accuracy: 83.00
Round  70, Global train loss: 0.979, Global test loss: 0.979, Global test accuracy: 93.46
Round  71, Train loss: 0.935, Test loss: 1.073, Test accuracy: 82.98
Round  71, Global train loss: 0.935, Global test loss: 0.954, Global test accuracy: 95.24
Round  72, Train loss: 0.994, Test loss: 1.074, Test accuracy: 82.82
Round  72, Global train loss: 0.994, Global test loss: 0.996, Global test accuracy: 91.00
Round  73, Train loss: 0.932, Test loss: 1.074, Test accuracy: 82.86
Round  73, Global train loss: 0.932, Global test loss: 0.961, Global test accuracy: 94.56
Round  74, Train loss: 0.970, Test loss: 1.076, Test accuracy: 82.70
Round  74, Global train loss: 0.970, Global test loss: 0.959, Global test accuracy: 94.78
Round  75, Train loss: 0.942, Test loss: 1.076, Test accuracy: 82.72
Round  75, Global train loss: 0.942, Global test loss: 0.968, Global test accuracy: 94.18
Round  76, Train loss: 0.958, Test loss: 1.075, Test accuracy: 82.92
Round  76, Global train loss: 0.958, Global test loss: 0.953, Global test accuracy: 95.66
Round  77, Train loss: 0.950, Test loss: 1.075, Test accuracy: 82.92
Round  77, Global train loss: 0.950, Global test loss: 0.958, Global test accuracy: 94.84
Round  78, Train loss: 1.009, Test loss: 1.071, Test accuracy: 83.22
Round  78, Global train loss: 1.009, Global test loss: 0.982, Global test accuracy: 92.62
Round  79, Train loss: 0.935, Test loss: 1.071, Test accuracy: 83.22
Round  79, Global train loss: 0.935, Global test loss: 0.954, Global test accuracy: 95.30
Round  80, Train loss: 1.010, Test loss: 1.076, Test accuracy: 82.66
Round  80, Global train loss: 1.010, Global test loss: 1.006, Global test accuracy: 90.62
Round  81, Train loss: 0.952, Test loss: 1.076, Test accuracy: 82.64
Round  81, Global train loss: 0.952, Global test loss: 0.957, Global test accuracy: 95.00
Round  82, Train loss: 0.996, Test loss: 1.076, Test accuracy: 82.66
Round  82, Global train loss: 0.996, Global test loss: 1.021, Global test accuracy: 88.66
Round  83, Train loss: 0.919, Test loss: 1.076, Test accuracy: 82.66
Round  83, Global train loss: 0.919, Global test loss: 0.959, Global test accuracy: 94.70
Round  84, Train loss: 0.912, Test loss: 1.076, Test accuracy: 82.68
Round  84, Global train loss: 0.912, Global test loss: 0.944, Global test accuracy: 96.26
Round  85, Train loss: 0.972, Test loss: 1.076, Test accuracy: 82.72
Round  85, Global train loss: 0.972, Global test loss: 0.978, Global test accuracy: 93.14
Round  86, Train loss: 0.932, Test loss: 1.076, Test accuracy: 82.74
Round  86, Global train loss: 0.932, Global test loss: 0.965, Global test accuracy: 94.24
Round  87, Train loss: 0.954, Test loss: 1.078, Test accuracy: 82.42
Round  87, Global train loss: 0.954, Global test loss: 0.957, Global test accuracy: 95.28
Round  88, Train loss: 0.944, Test loss: 1.078, Test accuracy: 82.42
Round  88, Global train loss: 0.944, Global test loss: 0.946, Global test accuracy: 96.22
Round  89, Train loss: 0.931, Test loss: 1.078, Test accuracy: 82.36
Round  89, Global train loss: 0.931, Global test loss: 0.965, Global test accuracy: 94.20
Round  90, Train loss: 0.966, Test loss: 1.078, Test accuracy: 82.44
Round  90, Global train loss: 0.966, Global test loss: 0.952, Global test accuracy: 95.70
Round  91, Train loss: 0.966, Test loss: 1.078, Test accuracy: 82.42
Round  91, Global train loss: 0.966, Global test loss: 0.952, Global test accuracy: 95.64
Round  92, Train loss: 0.958, Test loss: 1.075, Test accuracy: 82.76
Round  92, Global train loss: 0.958, Global test loss: 0.981, Global test accuracy: 93.10
Round  93, Train loss: 0.942, Test loss: 1.075, Test accuracy: 82.74
Round  93, Global train loss: 0.942, Global test loss: 0.948, Global test accuracy: 95.82
Round  94, Train loss: 0.964, Test loss: 1.075, Test accuracy: 82.70
Round  94, Global train loss: 0.964, Global test loss: 0.963, Global test accuracy: 94.46
Round  95, Train loss: 0.987, Test loss: 1.075, Test accuracy: 82.72
Round  95, Global train loss: 0.987, Global test loss: 0.999, Global test accuracy: 90.70/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 0.987, Test loss: 1.075, Test accuracy: 82.70
Round  96, Global train loss: 0.987, Global test loss: 0.999, Global test accuracy: 90.74
Round  97, Train loss: 0.944, Test loss: 1.075, Test accuracy: 82.74
Round  97, Global train loss: 0.944, Global test loss: 0.942, Global test accuracy: 96.58
Round  98, Train loss: 0.958, Test loss: 1.075, Test accuracy: 82.80
Round  98, Global train loss: 0.958, Global test loss: 0.976, Global test accuracy: 93.20
Round  99, Train loss: 0.981, Test loss: 1.076, Test accuracy: 82.54
Round  99, Global train loss: 0.981, Global test loss: 0.961, Global test accuracy: 94.66
Final Round, Train loss: 0.957, Test loss: 1.075, Test accuracy: 82.66
Final Round, Global train loss: 0.957, Global test loss: 0.961, Global test accuracy: 94.66
Average accuracy final 10 rounds: 82.656 

Average global accuracy final 10 rounds: 94.05999999999999 

489.8823239803314
[0.7848601341247559, 1.5697202682495117, 2.3509132862091064, 3.132106304168701, 3.901432752609253, 4.670759201049805, 5.4193360805511475, 6.16791296005249, 6.867082118988037, 7.566251277923584, 8.270624876022339, 8.974998474121094, 9.671596050262451, 10.368193626403809, 11.067931413650513, 11.767669200897217, 12.455131530761719, 13.14259386062622, 13.827942371368408, 14.513290882110596, 15.179335355758667, 15.845379829406738, 16.55505084991455, 17.264721870422363, 17.91191601753235, 18.559110164642334, 19.217039823532104, 19.874969482421875, 20.538286924362183, 21.20160436630249, 21.88149929046631, 22.561394214630127, 23.257229566574097, 23.953064918518066, 24.660817623138428, 25.36857032775879, 26.065020322799683, 26.761470317840576, 27.453486442565918, 28.14550256729126, 28.840670108795166, 29.535837650299072, 30.244804859161377, 30.95377206802368, 31.655240297317505, 32.35670852661133, 33.02858352661133, 33.70045852661133, 34.36511778831482, 35.02977705001831, 35.661541223526, 36.29330539703369, 36.9490909576416, 37.60487651824951, 38.32030534744263, 39.03573417663574, 39.72909951210022, 40.4224648475647, 41.1171555519104, 41.8118462562561, 42.5096755027771, 43.207504749298096, 43.899112701416016, 44.590720653533936, 45.290422201156616, 45.9901237487793, 46.68664622306824, 47.38316869735718, 48.072834491729736, 48.762500286102295, 49.453914165496826, 50.14532804489136, 50.83708333969116, 51.52883863449097, 52.20989489555359, 52.89095115661621, 53.54812026023865, 54.205289363861084, 54.87940979003906, 55.55353021621704, 56.217735290527344, 56.88194036483765, 57.5560359954834, 58.23013162612915, 58.93430209159851, 59.63847255706787, 60.39482402801514, 61.1511754989624, 61.821470737457275, 62.49176597595215, 63.150413036346436, 63.80906009674072, 64.46578550338745, 65.12251091003418, 65.76640009880066, 66.41028928756714, 67.06359767913818, 67.71690607070923, 68.37852740287781, 69.04014873504639, 69.7226014137268, 70.40505409240723, 71.09198546409607, 71.77891683578491, 72.44969058036804, 73.12046432495117, 73.77956891059875, 74.43867349624634, 75.12013697624207, 75.8016004562378, 76.46430230140686, 77.12700414657593, 77.77196168899536, 78.4169192314148, 79.09828114509583, 79.77964305877686, 80.45121121406555, 81.12277936935425, 81.79361295700073, 82.46444654464722, 83.12729668617249, 83.79014682769775, 84.43997621536255, 85.08980560302734, 85.75559759140015, 86.42138957977295, 87.0845696926117, 87.74774980545044, 88.406325340271, 89.06490087509155, 89.70426034927368, 90.34361982345581, 90.99599385261536, 91.6483678817749, 92.31427145004272, 92.98017501831055, 93.65208721160889, 94.32399940490723, 94.98114228248596, 95.6382851600647, 96.30783557891846, 96.97738599777222, 97.63195085525513, 98.28651571273804, 98.98272252082825, 99.67892932891846, 100.34825849533081, 101.01758766174316, 101.6994047164917, 102.38122177124023, 103.0850121974945, 103.78880262374878, 104.49486207962036, 105.20092153549194, 105.89885234832764, 106.59678316116333, 107.25499320030212, 107.91320323944092, 108.58016037940979, 109.24711751937866, 109.90593886375427, 110.56476020812988, 111.22315001487732, 111.88153982162476, 112.53937864303589, 113.19721746444702, 113.90325856208801, 114.609299659729, 115.26787090301514, 115.92644214630127, 116.55340194702148, 117.1803617477417, 117.81723403930664, 118.45410633087158, 119.08366560935974, 119.7132248878479, 120.33782362937927, 120.96242237091064, 121.60787916183472, 122.25333595275879, 122.93510055541992, 123.61686515808105, 124.27602028846741, 124.93517541885376, 125.6243736743927, 126.31357192993164, 126.98250651359558, 127.65144109725952, 128.31927871704102, 128.9871163368225, 129.6461055278778, 130.3050947189331, 130.98738718032837, 131.66967964172363, 132.32964158058167, 132.9896035194397, 133.65539526939392, 134.32118701934814, 135.01237678527832, 135.7035665512085, 137.00954294204712, 138.31551933288574]
[58.82, 58.82, 65.58, 65.58, 75.42, 75.42, 78.44, 78.44, 76.76, 76.76, 80.94, 80.94, 83.48, 83.48, 84.4, 84.4, 81.74, 81.74, 81.56, 81.56, 85.22, 85.22, 85.16, 85.16, 85.42, 85.42, 85.3, 85.3, 85.58, 85.58, 85.84, 85.84, 86.72, 86.72, 86.5, 86.5, 85.74, 85.74, 85.18, 85.18, 84.42, 84.42, 84.04, 84.04, 84.26, 84.26, 84.08, 84.08, 84.16, 84.16, 83.74, 83.74, 83.64, 83.64, 83.82, 83.82, 83.9, 83.9, 83.88, 83.88, 83.88, 83.88, 83.86, 83.86, 84.1, 84.1, 84.12, 84.12, 84.3, 84.3, 84.46, 84.46, 83.76, 83.76, 83.9, 83.9, 83.88, 83.88, 83.9, 83.9, 83.78, 83.78, 83.84, 83.84, 83.88, 83.88, 83.6, 83.6, 83.68, 83.68, 83.76, 83.76, 83.6, 83.6, 83.64, 83.64, 83.58, 83.58, 83.54, 83.54, 83.08, 83.08, 82.72, 82.72, 82.98, 82.98, 83.18, 83.18, 83.26, 83.26, 83.22, 83.22, 82.88, 82.88, 82.88, 82.88, 82.94, 82.94, 83.06, 83.06, 83.04, 83.04, 83.02, 83.02, 82.98, 82.98, 83.1, 83.1, 82.68, 82.68, 82.58, 82.58, 82.6, 82.6, 82.52, 82.52, 82.56, 82.56, 83.2, 83.2, 83.0, 83.0, 82.98, 82.98, 82.82, 82.82, 82.86, 82.86, 82.7, 82.7, 82.72, 82.72, 82.92, 82.92, 82.92, 82.92, 83.22, 83.22, 83.22, 83.22, 82.66, 82.66, 82.64, 82.64, 82.66, 82.66, 82.66, 82.66, 82.68, 82.68, 82.72, 82.72, 82.74, 82.74, 82.42, 82.42, 82.42, 82.42, 82.36, 82.36, 82.44, 82.44, 82.42, 82.42, 82.76, 82.76, 82.74, 82.74, 82.7, 82.7, 82.72, 82.72, 82.7, 82.7, 82.74, 82.74, 82.8, 82.8, 82.54, 82.54, 82.66, 82.66]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.2 , level_n_lowerb:0.8  

   Client 8, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.592, Test loss: 1.559, Test accuracy: 20.10
Round   0, Global train loss: 1.592, Global test loss: 1.560, Global test accuracy: 20.04
Round   1, Train loss: 1.521, Test loss: 1.477, Test accuracy: 49.68
Round   1, Global train loss: 1.521, Global test loss: 1.443, Global test accuracy: 69.38
Round   2, Train loss: 1.378, Test loss: 1.345, Test accuracy: 60.90
Round   2, Global train loss: 1.378, Global test loss: 1.208, Global test accuracy: 83.28
Round   3, Train loss: 1.225, Test loss: 1.205, Test accuracy: 70.74
Round   3, Global train loss: 1.225, Global test loss: 1.018, Global test accuracy: 94.86
Round   4, Train loss: 1.209, Test loss: 1.102, Test accuracy: 83.72
Round   4, Global train loss: 1.209, Global test loss: 0.980, Global test accuracy: 96.06
Round   5, Train loss: 0.964, Test loss: 1.081, Test accuracy: 84.56
Round   5, Global train loss: 0.964, Global test loss: 0.956, Global test accuracy: 96.30
Round   6, Train loss: 0.991, Test loss: 1.002, Test accuracy: 94.32
Round   6, Global train loss: 0.991, Global test loss: 0.951, Global test accuracy: 96.36
Round   7, Train loss: 1.185, Test loss: 0.990, Test accuracy: 93.74
Round   7, Global train loss: 1.185, Global test loss: 0.961, Global test accuracy: 95.78
Round   8, Train loss: 1.180, Test loss: 0.984, Test accuracy: 93.66
Round   8, Global train loss: 1.180, Global test loss: 0.962, Global test accuracy: 95.86
Round   9, Train loss: 1.346, Test loss: 0.992, Test accuracy: 92.84
Round   9, Global train loss: 1.346, Global test loss: 0.973, Global test accuracy: 94.66
Round  10, Train loss: 1.178, Test loss: 0.973, Test accuracy: 94.20
Round  10, Global train loss: 1.178, Global test loss: 0.944, Global test accuracy: 96.68
Round  11, Train loss: 0.970, Test loss: 0.971, Test accuracy: 94.28
Round  11, Global train loss: 0.970, Global test loss: 0.943, Global test accuracy: 96.76
Round  12, Train loss: 1.135, Test loss: 0.968, Test accuracy: 94.52
Round  12, Global train loss: 1.135, Global test loss: 0.941, Global test accuracy: 96.70
Round  13, Train loss: 1.376, Test loss: 0.974, Test accuracy: 94.00
Round  13, Global train loss: 1.376, Global test loss: 0.955, Global test accuracy: 95.96
Round  14, Train loss: 1.131, Test loss: 0.970, Test accuracy: 94.32
Round  14, Global train loss: 1.131, Global test loss: 0.940, Global test accuracy: 96.80
Round  15, Train loss: 0.965, Test loss: 0.970, Test accuracy: 94.26
Round  15, Global train loss: 0.965, Global test loss: 0.937, Global test accuracy: 96.90
Round  16, Train loss: 0.967, Test loss: 0.966, Test accuracy: 94.56
Round  16, Global train loss: 0.967, Global test loss: 0.936, Global test accuracy: 97.14
Round  17, Train loss: 1.004, Test loss: 0.965, Test accuracy: 94.52
Round  17, Global train loss: 1.004, Global test loss: 0.937, Global test accuracy: 97.00
Round  18, Train loss: 1.133, Test loss: 0.960, Test accuracy: 94.90
Round  18, Global train loss: 1.133, Global test loss: 0.939, Global test accuracy: 97.00
Round  19, Train loss: 1.169, Test loss: 0.960, Test accuracy: 94.68
Round  19, Global train loss: 1.169, Global test loss: 0.936, Global test accuracy: 97.26
Round  20, Train loss: 0.960, Test loss: 0.960, Test accuracy: 94.68
Round  20, Global train loss: 0.960, Global test loss: 0.935, Global test accuracy: 96.98
Round  21, Train loss: 1.168, Test loss: 0.961, Test accuracy: 94.54
Round  21, Global train loss: 1.168, Global test loss: 0.938, Global test accuracy: 96.98
Round  22, Train loss: 0.966, Test loss: 0.961, Test accuracy: 94.62
Round  22, Global train loss: 0.966, Global test loss: 0.935, Global test accuracy: 96.86
Round  23, Train loss: 1.134, Test loss: 0.957, Test accuracy: 94.98
Round  23, Global train loss: 1.134, Global test loss: 0.936, Global test accuracy: 97.28
Round  24, Train loss: 0.928, Test loss: 0.957, Test accuracy: 94.96
Round  24, Global train loss: 0.928, Global test loss: 0.933, Global test accuracy: 97.30
Round  25, Train loss: 1.131, Test loss: 0.957, Test accuracy: 94.92
Round  25, Global train loss: 1.131, Global test loss: 0.937, Global test accuracy: 97.02
Round  26, Train loss: 1.333, Test loss: 0.961, Test accuracy: 94.60
Round  26, Global train loss: 1.333, Global test loss: 0.961, Global test accuracy: 94.88
Round  27, Train loss: 1.160, Test loss: 0.958, Test accuracy: 95.04
Round  27, Global train loss: 1.160, Global test loss: 0.936, Global test accuracy: 97.02
Round  28, Train loss: 1.325, Test loss: 0.962, Test accuracy: 94.42
Round  28, Global train loss: 1.325, Global test loss: 0.959, Global test accuracy: 95.66
Round  29, Train loss: 1.118, Test loss: 0.962, Test accuracy: 94.38
Round  29, Global train loss: 1.118, Global test loss: 0.940, Global test accuracy: 96.84
Round  30, Train loss: 1.121, Test loss: 0.961, Test accuracy: 94.62
Round  30, Global train loss: 1.121, Global test loss: 0.939, Global test accuracy: 97.04
Round  31, Train loss: 1.153, Test loss: 0.961, Test accuracy: 94.48
Round  31, Global train loss: 1.153, Global test loss: 0.960, Global test accuracy: 95.62
Round  32, Train loss: 1.347, Test loss: 0.961, Test accuracy: 94.62
Round  32, Global train loss: 1.347, Global test loss: 0.999, Global test accuracy: 91.72
Round  33, Train loss: 1.112, Test loss: 0.960, Test accuracy: 94.68
Round  33, Global train loss: 1.112, Global test loss: 0.940, Global test accuracy: 96.80
Round  34, Train loss: 1.121, Test loss: 0.959, Test accuracy: 94.72
Round  34, Global train loss: 1.121, Global test loss: 0.938, Global test accuracy: 97.22
Round  35, Train loss: 1.145, Test loss: 0.957, Test accuracy: 94.98
Round  35, Global train loss: 1.145, Global test loss: 0.959, Global test accuracy: 95.46
Round  36, Train loss: 1.154, Test loss: 0.956, Test accuracy: 95.10
Round  36, Global train loss: 1.154, Global test loss: 0.936, Global test accuracy: 97.24
Round  37, Train loss: 0.956, Test loss: 0.956, Test accuracy: 95.06
Round  37, Global train loss: 0.956, Global test loss: 0.934, Global test accuracy: 97.22
Round  38, Train loss: 0.950, Test loss: 0.953, Test accuracy: 95.46
Round  38, Global train loss: 0.950, Global test loss: 0.933, Global test accuracy: 97.44
Round  39, Train loss: 1.336, Test loss: 0.959, Test accuracy: 94.74
Round  39, Global train loss: 1.336, Global test loss: 0.996, Global test accuracy: 91.38
Round  40, Train loss: 1.302, Test loss: 0.965, Test accuracy: 94.16
Round  40, Global train loss: 1.302, Global test loss: 0.959, Global test accuracy: 95.34
Round  41, Train loss: 0.946, Test loss: 0.961, Test accuracy: 94.50
Round  41, Global train loss: 0.946, Global test loss: 0.935, Global test accuracy: 97.30
Round  42, Train loss: 0.949, Test loss: 0.959, Test accuracy: 94.76
Round  42, Global train loss: 0.949, Global test loss: 0.935, Global test accuracy: 97.46
Round  43, Train loss: 0.921, Test loss: 0.958, Test accuracy: 94.82
Round  43, Global train loss: 0.921, Global test loss: 0.933, Global test accuracy: 97.32
Round  44, Train loss: 1.111, Test loss: 0.955, Test accuracy: 95.08
Round  44, Global train loss: 1.111, Global test loss: 0.934, Global test accuracy: 97.36
Round  45, Train loss: 1.107, Test loss: 0.956, Test accuracy: 94.98
Round  45, Global train loss: 1.107, Global test loss: 0.937, Global test accuracy: 97.34
Round  46, Train loss: 0.957, Test loss: 0.957, Test accuracy: 94.92
Round  46, Global train loss: 0.957, Global test loss: 0.932, Global test accuracy: 97.36
Round  47, Train loss: 1.110, Test loss: 0.956, Test accuracy: 95.04
Round  47, Global train loss: 1.110, Global test loss: 0.938, Global test accuracy: 96.98
Round  48, Train loss: 0.920, Test loss: 0.955, Test accuracy: 95.10
Round  48, Global train loss: 0.920, Global test loss: 0.933, Global test accuracy: 97.14
Round  49, Train loss: 0.955, Test loss: 0.955, Test accuracy: 95.06
Round  49, Global train loss: 0.955, Global test loss: 0.932, Global test accuracy: 97.34
Round  50, Train loss: 0.954, Test loss: 0.955, Test accuracy: 95.02
Round  50, Global train loss: 0.954, Global test loss: 0.932, Global test accuracy: 97.48
Round  51, Train loss: 1.113, Test loss: 0.952, Test accuracy: 95.32
Round  51, Global train loss: 1.113, Global test loss: 0.933, Global test accuracy: 97.58
Round  52, Train loss: 1.148, Test loss: 0.951, Test accuracy: 95.52
Round  52, Global train loss: 1.148, Global test loss: 0.935, Global test accuracy: 97.14
Round  53, Train loss: 1.109, Test loss: 0.955, Test accuracy: 95.12
Round  53, Global train loss: 1.109, Global test loss: 0.939, Global test accuracy: 96.96
Round  54, Train loss: 1.105, Test loss: 0.958, Test accuracy: 94.76
Round  54, Global train loss: 1.105, Global test loss: 0.935, Global test accuracy: 97.26
Round  55, Train loss: 1.101, Test loss: 0.956, Test accuracy: 94.86
Round  55, Global train loss: 1.101, Global test loss: 0.935, Global test accuracy: 97.28
Round  56, Train loss: 0.914, Test loss: 0.956, Test accuracy: 94.90
Round  56, Global train loss: 0.914, Global test loss: 0.931, Global test accuracy: 97.52
Round  57, Train loss: 1.110, Test loss: 0.957, Test accuracy: 94.84
Round  57, Global train loss: 1.110, Global test loss: 0.938, Global test accuracy: 96.92
Round  58, Train loss: 1.109, Test loss: 0.949, Test accuracy: 95.64
Round  58, Global train loss: 1.109, Global test loss: 0.937, Global test accuracy: 97.02
Round  59, Train loss: 0.916, Test loss: 0.950, Test accuracy: 95.62
Round  59, Global train loss: 0.916, Global test loss: 0.931, Global test accuracy: 97.46
Round  60, Train loss: 0.948, Test loss: 0.951, Test accuracy: 95.46
Round  60, Global train loss: 0.948, Global test loss: 0.934, Global test accuracy: 97.34
Round  61, Train loss: 1.104, Test loss: 0.956, Test accuracy: 94.88
Round  61, Global train loss: 1.104, Global test loss: 0.938, Global test accuracy: 96.82
Round  62, Train loss: 1.105, Test loss: 0.957, Test accuracy: 94.72
Round  62, Global train loss: 1.105, Global test loss: 0.936, Global test accuracy: 97.08
Round  63, Train loss: 1.100, Test loss: 0.958, Test accuracy: 94.82
Round  63, Global train loss: 1.100, Global test loss: 0.936, Global test accuracy: 96.90
Round  64, Train loss: 0.981, Test loss: 0.957, Test accuracy: 94.86
Round  64, Global train loss: 0.981, Global test loss: 0.933, Global test accuracy: 97.44
Round  65, Train loss: 1.100, Test loss: 0.954, Test accuracy: 95.14
Round  65, Global train loss: 1.100, Global test loss: 0.936, Global test accuracy: 96.92
Round  66, Train loss: 1.107, Test loss: 0.958, Test accuracy: 94.70
Round  66, Global train loss: 1.107, Global test loss: 0.943, Global test accuracy: 96.52
Round  67, Train loss: 0.941, Test loss: 0.956, Test accuracy: 94.92
Round  67, Global train loss: 0.941, Global test loss: 0.933, Global test accuracy: 97.50
Round  68, Train loss: 1.137, Test loss: 0.958, Test accuracy: 94.80
Round  68, Global train loss: 1.137, Global test loss: 0.935, Global test accuracy: 97.16
Round  69, Train loss: 1.140, Test loss: 0.957, Test accuracy: 94.88
Round  69, Global train loss: 1.140, Global test loss: 0.937, Global test accuracy: 96.82
Round  70, Train loss: 1.285, Test loss: 0.957, Test accuracy: 94.82
Round  70, Global train loss: 1.285, Global test loss: 0.957, Global test accuracy: 94.78
Round  71, Train loss: 0.944, Test loss: 0.961, Test accuracy: 94.36
Round  71, Global train loss: 0.944, Global test loss: 0.936, Global test accuracy: 97.22
Round  72, Train loss: 0.918, Test loss: 0.960, Test accuracy: 94.44
Round  72, Global train loss: 0.918, Global test loss: 0.932, Global test accuracy: 97.44
Round  73, Train loss: 1.102, Test loss: 0.955, Test accuracy: 95.10
Round  73, Global train loss: 1.102, Global test loss: 0.937, Global test accuracy: 96.94
Round  74, Train loss: 0.940, Test loss: 0.953, Test accuracy: 95.38
Round  74, Global train loss: 0.940, Global test loss: 0.934, Global test accuracy: 97.14
Round  75, Train loss: 1.125, Test loss: 0.955, Test accuracy: 95.16
Round  75, Global train loss: 1.125, Global test loss: 0.960, Global test accuracy: 94.86
Round  76, Train loss: 0.953, Test loss: 0.955, Test accuracy: 95.14
Round  76, Global train loss: 0.953, Global test loss: 0.932, Global test accuracy: 97.30
Round  77, Train loss: 1.098, Test loss: 0.954, Test accuracy: 95.20
Round  77, Global train loss: 1.098, Global test loss: 0.936, Global test accuracy: 97.02
Round  78, Train loss: 1.098, Test loss: 0.954, Test accuracy: 95.28
Round  78, Global train loss: 1.098, Global test loss: 0.936, Global test accuracy: 97.02
Round  79, Train loss: 0.941, Test loss: 0.952, Test accuracy: 95.48
Round  79, Global train loss: 0.941, Global test loss: 0.934, Global test accuracy: 97.24
Round  80, Train loss: 0.950, Test loss: 0.952, Test accuracy: 95.50
Round  80, Global train loss: 0.950, Global test loss: 0.932, Global test accuracy: 97.38
Round  81, Train loss: 1.125, Test loss: 0.951, Test accuracy: 95.52
Round  81, Global train loss: 1.125, Global test loss: 0.950, Global test accuracy: 95.76
Round  82, Train loss: 1.098, Test loss: 0.952, Test accuracy: 95.44
Round  82, Global train loss: 1.098, Global test loss: 0.937, Global test accuracy: 96.86
Round  83, Train loss: 1.308, Test loss: 0.953, Test accuracy: 95.30
Round  83, Global train loss: 1.308, Global test loss: 0.972, Global test accuracy: 93.64
Round  84, Train loss: 1.120, Test loss: 0.952, Test accuracy: 95.42
Round  84, Global train loss: 1.120, Global test loss: 0.944, Global test accuracy: 96.48
Round  85, Train loss: 1.096, Test loss: 0.953, Test accuracy: 95.36
Round  85, Global train loss: 1.096, Global test loss: 0.937, Global test accuracy: 96.96
Round  86, Train loss: 0.913, Test loss: 0.953, Test accuracy: 95.36
Round  86, Global train loss: 0.913, Global test loss: 0.932, Global test accuracy: 97.18
Round  87, Train loss: 1.162, Test loss: 0.956, Test accuracy: 95.16
Round  87, Global train loss: 1.162, Global test loss: 0.944, Global test accuracy: 96.52
Round  88, Train loss: 1.121, Test loss: 0.957, Test accuracy: 94.94
Round  88, Global train loss: 1.121, Global test loss: 0.950, Global test accuracy: 95.98
Round  89, Train loss: 0.914, Test loss: 0.957, Test accuracy: 94.94
Round  89, Global train loss: 0.914, Global test loss: 0.933, Global test accuracy: 97.20
Round  90, Train loss: 1.098, Test loss: 0.955, Test accuracy: 95.18
Round  90, Global train loss: 1.098, Global test loss: 0.939, Global test accuracy: 96.78
Round  91, Train loss: 1.096, Test loss: 0.952, Test accuracy: 95.56
Round  91, Global train loss: 1.096, Global test loss: 0.938, Global test accuracy: 96.76
Round  92, Train loss: 1.315, Test loss: 0.958, Test accuracy: 94.78
Round  92, Global train loss: 1.315, Global test loss: 0.953, Global test accuracy: 95.26
Round  93, Train loss: 1.092, Test loss: 0.955, Test accuracy: 95.08
Round  93, Global train loss: 1.092, Global test loss: 0.941, Global test accuracy: 96.62
Round  94, Train loss: 0.912, Test loss: 0.956, Test accuracy: 95.06
Round  94, Global train loss: 0.912, Global test loss: 0.932, Global test accuracy: 97.44
Round  95, Train loss: 0.941, Test loss: 0.955, Test accuracy: 95.14
Round  95, Global train loss: 0.941, Global test loss: 0.934, Global test accuracy: 97.34/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 0.939, Test loss: 0.955, Test accuracy: 95.10
Round  96, Global train loss: 0.939, Global test loss: 0.934, Global test accuracy: 97.26
Round  97, Train loss: 0.939, Test loss: 0.955, Test accuracy: 95.06
Round  97, Global train loss: 0.939, Global test loss: 0.934, Global test accuracy: 97.18
Round  98, Train loss: 1.136, Test loss: 0.953, Test accuracy: 95.34
Round  98, Global train loss: 1.136, Global test loss: 0.935, Global test accuracy: 96.88
Round  99, Train loss: 1.133, Test loss: 0.955, Test accuracy: 95.08
Round  99, Global train loss: 1.133, Global test loss: 0.937, Global test accuracy: 96.88
Final Round, Train loss: 1.039, Test loss: 0.962, Test accuracy: 94.28
Final Round, Global train loss: 1.039, Global test loss: 0.937, Global test accuracy: 96.88
Average accuracy final 10 rounds: 95.138 

Average global accuracy final 10 rounds: 96.84000000000002 

509.66881275177
[0.8410451412200928, 1.6820902824401855, 2.427276611328125, 3.1724629402160645, 3.9364891052246094, 4.700515270233154, 5.478880405426025, 6.2572455406188965, 7.013512849807739, 7.769780158996582, 8.497975587844849, 9.226171016693115, 9.993017196655273, 10.759863376617432, 11.527320384979248, 12.294777393341064, 13.055693864822388, 13.816610336303711, 14.537903070449829, 15.259195804595947, 16.0182888507843, 16.777381896972656, 17.53536558151245, 18.293349266052246, 19.053667783737183, 19.81398630142212, 20.53719472885132, 21.260403156280518, 22.010276317596436, 22.760149478912354, 23.518337965011597, 24.27652645111084, 25.026541233062744, 25.77655601501465, 26.490963220596313, 27.20537042617798, 27.94528865814209, 28.6852068901062, 29.439401865005493, 30.193596839904785, 30.93338680267334, 31.673176765441895, 32.402549028396606, 33.13192129135132, 33.86976218223572, 34.60760307312012, 35.34348011016846, 36.0793571472168, 36.818838119506836, 37.558319091796875, 38.291459798812866, 39.02460050582886, 39.76414179801941, 40.50368309020996, 41.2475790977478, 41.991475105285645, 42.730151891708374, 43.4688286781311, 44.205992221832275, 44.94315576553345, 45.6834511756897, 46.42374658584595, 47.177810192108154, 47.93187379837036, 48.67270374298096, 49.41353368759155, 50.152289152145386, 50.89104461669922, 51.6227593421936, 52.35447406768799, 53.10593008995056, 53.857386112213135, 54.591357707977295, 55.325329303741455, 56.05876874923706, 56.792208194732666, 57.50144028663635, 58.21067237854004, 58.94559597969055, 59.680519580841064, 60.416240215301514, 61.15196084976196, 61.889304637908936, 62.62664842605591, 63.34814810752869, 64.06964778900146, 64.80360126495361, 65.53755474090576, 66.27217102050781, 67.00678730010986, 67.74398612976074, 68.48118495941162, 69.20758080482483, 69.93397665023804, 70.67319869995117, 71.4124207496643, 72.15138459205627, 72.89034843444824, 73.63270449638367, 74.37506055831909, 75.12251710891724, 75.86997365951538, 76.60622024536133, 77.34246683120728, 78.07912874221802, 78.81579065322876, 79.55203127861023, 80.2882719039917, 81.03002166748047, 81.77177143096924, 82.49983143806458, 83.22789144515991, 83.97079086303711, 84.7136902809143, 85.45160675048828, 86.18952322006226, 86.93318724632263, 87.67685127258301, 88.40369987487793, 89.13054847717285, 89.88482570648193, 90.63910293579102, 91.37617516517639, 92.11324739456177, 92.8494508266449, 93.58565425872803, 94.29582166671753, 95.00598907470703, 95.76589822769165, 96.52580738067627, 97.27756571769714, 98.02932405471802, 98.76511335372925, 99.50090265274048, 100.20603442192078, 100.91116619110107, 101.65522313117981, 102.39928007125854, 103.16480875015259, 103.93033742904663, 104.66468715667725, 105.39903688430786, 106.1253969669342, 106.85175704956055, 107.5992922782898, 108.34682750701904, 109.09214472770691, 109.83746194839478, 110.58345603942871, 111.32945013046265, 112.05624556541443, 112.78304100036621, 113.52795171737671, 114.2728624343872, 115.01542162895203, 115.75798082351685, 116.51259422302246, 117.26720762252808, 118.01077842712402, 118.75434923171997, 119.49521493911743, 120.23608064651489, 120.99926853179932, 121.76245641708374, 122.52896809577942, 123.2954797744751, 124.03285384178162, 124.77022790908813, 125.50729036331177, 126.2443528175354, 126.99426317214966, 127.74417352676392, 128.49733757972717, 129.25050163269043, 130.0079255104065, 130.76534938812256, 131.49656295776367, 132.22777652740479, 132.9712851047516, 133.7147936820984, 134.45817112922668, 135.20154857635498, 135.94853734970093, 136.69552612304688, 137.4121925830841, 138.12885904312134, 138.88110375404358, 139.63334846496582, 140.3725335597992, 141.11171865463257, 141.85016226768494, 142.5886058807373, 143.2947645187378, 144.00092315673828, 144.75234842300415, 145.50377368927002, 146.2651584148407, 147.02654314041138, 147.7895748615265, 148.5526065826416, 150.03685641288757, 151.52110624313354]
[20.1, 20.1, 49.68, 49.68, 60.9, 60.9, 70.74, 70.74, 83.72, 83.72, 84.56, 84.56, 94.32, 94.32, 93.74, 93.74, 93.66, 93.66, 92.84, 92.84, 94.2, 94.2, 94.28, 94.28, 94.52, 94.52, 94.0, 94.0, 94.32, 94.32, 94.26, 94.26, 94.56, 94.56, 94.52, 94.52, 94.9, 94.9, 94.68, 94.68, 94.68, 94.68, 94.54, 94.54, 94.62, 94.62, 94.98, 94.98, 94.96, 94.96, 94.92, 94.92, 94.6, 94.6, 95.04, 95.04, 94.42, 94.42, 94.38, 94.38, 94.62, 94.62, 94.48, 94.48, 94.62, 94.62, 94.68, 94.68, 94.72, 94.72, 94.98, 94.98, 95.1, 95.1, 95.06, 95.06, 95.46, 95.46, 94.74, 94.74, 94.16, 94.16, 94.5, 94.5, 94.76, 94.76, 94.82, 94.82, 95.08, 95.08, 94.98, 94.98, 94.92, 94.92, 95.04, 95.04, 95.1, 95.1, 95.06, 95.06, 95.02, 95.02, 95.32, 95.32, 95.52, 95.52, 95.12, 95.12, 94.76, 94.76, 94.86, 94.86, 94.9, 94.9, 94.84, 94.84, 95.64, 95.64, 95.62, 95.62, 95.46, 95.46, 94.88, 94.88, 94.72, 94.72, 94.82, 94.82, 94.86, 94.86, 95.14, 95.14, 94.7, 94.7, 94.92, 94.92, 94.8, 94.8, 94.88, 94.88, 94.82, 94.82, 94.36, 94.36, 94.44, 94.44, 95.1, 95.1, 95.38, 95.38, 95.16, 95.16, 95.14, 95.14, 95.2, 95.2, 95.28, 95.28, 95.48, 95.48, 95.5, 95.5, 95.52, 95.52, 95.44, 95.44, 95.3, 95.3, 95.42, 95.42, 95.36, 95.36, 95.36, 95.36, 95.16, 95.16, 94.94, 94.94, 94.94, 94.94, 95.18, 95.18, 95.56, 95.56, 94.78, 94.78, 95.08, 95.08, 95.06, 95.06, 95.14, 95.14, 95.1, 95.1, 95.06, 95.06, 95.34, 95.34, 95.08, 95.08, 94.28, 94.28]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.2 , level_n_lowerb:0.8  

   Client 5, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
prox
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.581, Test loss: 1.528, Test accuracy: 46.54
Round   0, Global train loss: 1.581, Global test loss: 1.528, Global test accuracy: 46.46
Round   1, Train loss: 1.456, Test loss: 1.375, Test accuracy: 65.64
Round   1, Global train loss: 1.456, Global test loss: 1.311, Global test accuracy: 75.50
Round   2, Train loss: 1.262, Test loss: 1.237, Test accuracy: 77.00
Round   2, Global train loss: 1.262, Global test loss: 1.070, Global test accuracy: 94.12
Round   3, Train loss: 1.003, Test loss: 1.172, Test accuracy: 80.94
Round   3, Global train loss: 1.003, Global test loss: 0.975, Global test accuracy: 95.46
Round   4, Train loss: 1.192, Test loss: 1.074, Test accuracy: 88.38
Round   4, Global train loss: 1.192, Global test loss: 0.972, Global test accuracy: 95.40
Round   5, Train loss: 0.961, Test loss: 1.060, Test accuracy: 89.14
Round   5, Global train loss: 0.961, Global test loss: 0.953, Global test accuracy: 96.14
Round   6, Train loss: 1.157, Test loss: 0.973, Test accuracy: 94.62
Round   6, Global train loss: 1.157, Global test loss: 0.954, Global test accuracy: 96.00
Round   7, Train loss: 1.145, Test loss: 0.973, Test accuracy: 94.48
Round   7, Global train loss: 1.145, Global test loss: 0.952, Global test accuracy: 96.38
Round   8, Train loss: 1.346, Test loss: 0.973, Test accuracy: 94.48
Round   8, Global train loss: 1.346, Global test loss: 0.956, Global test accuracy: 96.52
Round   9, Train loss: 1.137, Test loss: 0.971, Test accuracy: 94.50
Round   9, Global train loss: 1.137, Global test loss: 0.951, Global test accuracy: 96.66
Round  10, Train loss: 0.967, Test loss: 0.962, Test accuracy: 95.08
Round  10, Global train loss: 0.967, Global test loss: 0.942, Global test accuracy: 96.80
Round  11, Train loss: 1.141, Test loss: 0.961, Test accuracy: 95.04
Round  11, Global train loss: 1.141, Global test loss: 0.945, Global test accuracy: 96.36
Round  12, Train loss: 0.927, Test loss: 0.959, Test accuracy: 95.36
Round  12, Global train loss: 0.927, Global test loss: 0.939, Global test accuracy: 96.92
Round  13, Train loss: 1.164, Test loss: 0.962, Test accuracy: 95.04
Round  13, Global train loss: 1.164, Global test loss: 0.953, Global test accuracy: 95.68
Round  14, Train loss: 0.924, Test loss: 0.960, Test accuracy: 95.22
Round  14, Global train loss: 0.924, Global test loss: 0.938, Global test accuracy: 97.08
Round  15, Train loss: 0.960, Test loss: 0.961, Test accuracy: 95.20
Round  15, Global train loss: 0.960, Global test loss: 0.938, Global test accuracy: 97.00
Round  16, Train loss: 0.961, Test loss: 0.958, Test accuracy: 95.44
Round  16, Global train loss: 0.961, Global test loss: 0.937, Global test accuracy: 96.98
Round  17, Train loss: 1.168, Test loss: 0.954, Test accuracy: 95.68
Round  17, Global train loss: 1.168, Global test loss: 0.940, Global test accuracy: 96.88
Round  18, Train loss: 1.136, Test loss: 0.949, Test accuracy: 96.02
Round  18, Global train loss: 1.136, Global test loss: 0.941, Global test accuracy: 96.94
Round  19, Train loss: 0.956, Test loss: 0.946, Test accuracy: 96.24
Round  19, Global train loss: 0.956, Global test loss: 0.935, Global test accuracy: 97.30
Round  20, Train loss: 0.954, Test loss: 0.946, Test accuracy: 96.18
Round  20, Global train loss: 0.954, Global test loss: 0.936, Global test accuracy: 97.16
Round  21, Train loss: 1.161, Test loss: 0.945, Test accuracy: 96.24
Round  21, Global train loss: 1.161, Global test loss: 0.940, Global test accuracy: 96.76
Round  22, Train loss: 0.960, Test loss: 0.946, Test accuracy: 96.10
Round  22, Global train loss: 0.960, Global test loss: 0.936, Global test accuracy: 97.04
Round  23, Train loss: 0.925, Test loss: 0.946, Test accuracy: 96.18
Round  23, Global train loss: 0.925, Global test loss: 0.934, Global test accuracy: 97.26
Round  24, Train loss: 0.931, Test loss: 0.946, Test accuracy: 96.16
Round  24, Global train loss: 0.931, Global test loss: 0.934, Global test accuracy: 97.22
Round  25, Train loss: 0.925, Test loss: 0.945, Test accuracy: 96.20
Round  25, Global train loss: 0.925, Global test loss: 0.933, Global test accuracy: 97.56
Round  26, Train loss: 1.126, Test loss: 0.947, Test accuracy: 95.98
Round  26, Global train loss: 1.126, Global test loss: 0.936, Global test accuracy: 96.96
Round  27, Train loss: 0.952, Test loss: 0.947, Test accuracy: 96.00
Round  27, Global train loss: 0.952, Global test loss: 0.935, Global test accuracy: 97.22
Round  28, Train loss: 1.124, Test loss: 0.947, Test accuracy: 95.88
Round  28, Global train loss: 1.124, Global test loss: 0.937, Global test accuracy: 96.86
Round  29, Train loss: 0.919, Test loss: 0.948, Test accuracy: 95.84
Round  29, Global train loss: 0.919, Global test loss: 0.933, Global test accuracy: 97.28
Round  30, Train loss: 0.922, Test loss: 0.947, Test accuracy: 95.80
Round  30, Global train loss: 0.922, Global test loss: 0.933, Global test accuracy: 97.24
Round  31, Train loss: 1.127, Test loss: 0.949, Test accuracy: 95.70
Round  31, Global train loss: 1.127, Global test loss: 0.937, Global test accuracy: 96.98
Round  32, Train loss: 1.325, Test loss: 0.951, Test accuracy: 95.68
Round  32, Global train loss: 1.325, Global test loss: 0.941, Global test accuracy: 96.66
Round  33, Train loss: 0.917, Test loss: 0.951, Test accuracy: 95.78
Round  33, Global train loss: 0.917, Global test loss: 0.933, Global test accuracy: 97.28
Round  34, Train loss: 1.125, Test loss: 0.946, Test accuracy: 96.10
Round  34, Global train loss: 1.125, Global test loss: 0.936, Global test accuracy: 97.08
Round  35, Train loss: 1.324, Test loss: 0.948, Test accuracy: 95.80
Round  35, Global train loss: 1.324, Global test loss: 0.944, Global test accuracy: 96.38
Round  36, Train loss: 0.950, Test loss: 0.949, Test accuracy: 95.70
Round  36, Global train loss: 0.950, Global test loss: 0.936, Global test accuracy: 97.34
Round  37, Train loss: 0.950, Test loss: 0.949, Test accuracy: 95.68
Round  37, Global train loss: 0.950, Global test loss: 0.935, Global test accuracy: 97.18
Round  38, Train loss: 1.124, Test loss: 0.951, Test accuracy: 95.48
Round  38, Global train loss: 1.124, Global test loss: 0.934, Global test accuracy: 97.20
Round  39, Train loss: 1.318, Test loss: 0.950, Test accuracy: 95.66
Round  39, Global train loss: 1.318, Global test loss: 0.940, Global test accuracy: 96.80
Round  40, Train loss: 1.117, Test loss: 0.949, Test accuracy: 95.78
Round  40, Global train loss: 1.117, Global test loss: 0.937, Global test accuracy: 96.86
Round  41, Train loss: 1.119, Test loss: 0.948, Test accuracy: 95.92
Round  41, Global train loss: 1.119, Global test loss: 0.936, Global test accuracy: 96.90
Round  42, Train loss: 1.120, Test loss: 0.958, Test accuracy: 94.84
Round  42, Global train loss: 1.120, Global test loss: 0.942, Global test accuracy: 96.62
Round  43, Train loss: 0.923, Test loss: 0.957, Test accuracy: 94.86
Round  43, Global train loss: 0.923, Global test loss: 0.934, Global test accuracy: 97.40
Round  44, Train loss: 1.117, Test loss: 0.958, Test accuracy: 94.76
Round  44, Global train loss: 1.117, Global test loss: 0.936, Global test accuracy: 97.24
Round  45, Train loss: 1.116, Test loss: 0.959, Test accuracy: 94.68
Round  45, Global train loss: 1.116, Global test loss: 0.937, Global test accuracy: 96.94
Round  46, Train loss: 0.949, Test loss: 0.957, Test accuracy: 94.76
Round  46, Global train loss: 0.949, Global test loss: 0.933, Global test accuracy: 97.46
Round  47, Train loss: 0.915, Test loss: 0.957, Test accuracy: 94.80
Round  47, Global train loss: 0.915, Global test loss: 0.933, Global test accuracy: 97.34
Round  48, Train loss: 0.922, Test loss: 0.956, Test accuracy: 94.88
Round  48, Global train loss: 0.922, Global test loss: 0.932, Global test accuracy: 97.42
Round  49, Train loss: 0.948, Test loss: 0.958, Test accuracy: 94.78
Round  49, Global train loss: 0.948, Global test loss: 0.933, Global test accuracy: 97.48
Round  50, Train loss: 0.947, Test loss: 0.957, Test accuracy: 94.78
Round  50, Global train loss: 0.947, Global test loss: 0.933, Global test accuracy: 97.34
Round  51, Train loss: 1.116, Test loss: 0.957, Test accuracy: 94.70
Round  51, Global train loss: 1.116, Global test loss: 0.937, Global test accuracy: 96.96
Round  52, Train loss: 0.946, Test loss: 0.956, Test accuracy: 94.88
Round  52, Global train loss: 0.946, Global test loss: 0.934, Global test accuracy: 97.46
Round  53, Train loss: 0.917, Test loss: 0.956, Test accuracy: 94.90
Round  53, Global train loss: 0.917, Global test loss: 0.931, Global test accuracy: 97.74
Round  54, Train loss: 1.109, Test loss: 0.955, Test accuracy: 95.14
Round  54, Global train loss: 1.109, Global test loss: 0.934, Global test accuracy: 97.28
Round  55, Train loss: 1.104, Test loss: 0.951, Test accuracy: 95.48
Round  55, Global train loss: 1.104, Global test loss: 0.934, Global test accuracy: 97.20
Round  56, Train loss: 0.915, Test loss: 0.951, Test accuracy: 95.46
Round  56, Global train loss: 0.915, Global test loss: 0.931, Global test accuracy: 97.60
Round  57, Train loss: 0.917, Test loss: 0.952, Test accuracy: 95.42
Round  57, Global train loss: 0.917, Global test loss: 0.931, Global test accuracy: 97.76
Round  58, Train loss: 0.917, Test loss: 0.952, Test accuracy: 95.42
Round  58, Global train loss: 0.917, Global test loss: 0.931, Global test accuracy: 97.62
Round  59, Train loss: 0.917, Test loss: 0.952, Test accuracy: 95.46
Round  59, Global train loss: 0.917, Global test loss: 0.930, Global test accuracy: 97.62
Round  60, Train loss: 1.120, Test loss: 0.944, Test accuracy: 96.48
Round  60, Global train loss: 1.120, Global test loss: 0.935, Global test accuracy: 97.16
Round  61, Train loss: 0.915, Test loss: 0.945, Test accuracy: 96.40
Round  61, Global train loss: 0.915, Global test loss: 0.931, Global test accuracy: 97.52
Round  62, Train loss: 1.107, Test loss: 0.947, Test accuracy: 96.14
Round  62, Global train loss: 1.107, Global test loss: 0.935, Global test accuracy: 97.02
Round  63, Train loss: 1.105, Test loss: 0.948, Test accuracy: 96.00
Round  63, Global train loss: 1.105, Global test loss: 0.935, Global test accuracy: 97.10
Round  64, Train loss: 1.145, Test loss: 0.945, Test accuracy: 96.16
Round  64, Global train loss: 1.145, Global test loss: 0.938, Global test accuracy: 97.00
Round  65, Train loss: 1.104, Test loss: 0.947, Test accuracy: 96.06
Round  65, Global train loss: 1.104, Global test loss: 0.936, Global test accuracy: 97.00
Round  66, Train loss: 0.917, Test loss: 0.946, Test accuracy: 96.10
Round  66, Global train loss: 0.917, Global test loss: 0.931, Global test accuracy: 97.78
Round  67, Train loss: 1.113, Test loss: 0.952, Test accuracy: 95.64
Round  67, Global train loss: 1.113, Global test loss: 0.934, Global test accuracy: 97.40
Round  68, Train loss: 1.133, Test loss: 0.950, Test accuracy: 95.76
Round  68, Global train loss: 1.133, Global test loss: 0.944, Global test accuracy: 96.30
Round  69, Train loss: 0.943, Test loss: 0.950, Test accuracy: 95.74
Round  69, Global train loss: 0.943, Global test loss: 0.934, Global test accuracy: 97.40
Round  70, Train loss: 1.102, Test loss: 0.950, Test accuracy: 95.64
Round  70, Global train loss: 1.102, Global test loss: 0.936, Global test accuracy: 97.10
Round  71, Train loss: 1.114, Test loss: 0.948, Test accuracy: 95.88
Round  71, Global train loss: 1.114, Global test loss: 0.936, Global test accuracy: 97.16
Round  72, Train loss: 0.920, Test loss: 0.949, Test accuracy: 95.86
Round  72, Global train loss: 0.920, Global test loss: 0.933, Global test accuracy: 97.34
Round  73, Train loss: 0.913, Test loss: 0.948, Test accuracy: 95.86
Round  73, Global train loss: 0.913, Global test loss: 0.931, Global test accuracy: 97.50
Round  74, Train loss: 1.109, Test loss: 0.959, Test accuracy: 94.58
Round  74, Global train loss: 1.109, Global test loss: 0.940, Global test accuracy: 96.80
Round  75, Train loss: 1.296, Test loss: 0.949, Test accuracy: 95.72
Round  75, Global train loss: 1.296, Global test loss: 0.945, Global test accuracy: 96.68
Round  76, Train loss: 0.944, Test loss: 0.949, Test accuracy: 95.64
Round  76, Global train loss: 0.944, Global test loss: 0.936, Global test accuracy: 97.06
Round  77, Train loss: 1.101, Test loss: 0.946, Test accuracy: 96.04
Round  77, Global train loss: 1.101, Global test loss: 0.937, Global test accuracy: 97.04
Round  78, Train loss: 1.102, Test loss: 0.949, Test accuracy: 95.60
Round  78, Global train loss: 1.102, Global test loss: 0.937, Global test accuracy: 97.10
Round  79, Train loss: 1.110, Test loss: 0.953, Test accuracy: 95.24
Round  79, Global train loss: 1.110, Global test loss: 0.937, Global test accuracy: 97.08
Round  80, Train loss: 0.944, Test loss: 0.953, Test accuracy: 95.24
Round  80, Global train loss: 0.944, Global test loss: 0.934, Global test accuracy: 97.30
Round  81, Train loss: 1.293, Test loss: 0.949, Test accuracy: 95.64
Round  81, Global train loss: 1.293, Global test loss: 0.940, Global test accuracy: 96.90
Round  82, Train loss: 1.102, Test loss: 0.949, Test accuracy: 95.74
Round  82, Global train loss: 1.102, Global test loss: 0.938, Global test accuracy: 97.08
Round  83, Train loss: 1.286, Test loss: 0.954, Test accuracy: 95.18
Round  83, Global train loss: 1.286, Global test loss: 0.951, Global test accuracy: 96.04
Round  84, Train loss: 1.101, Test loss: 0.956, Test accuracy: 95.06
Round  84, Global train loss: 1.101, Global test loss: 0.937, Global test accuracy: 97.04
Round  85, Train loss: 1.097, Test loss: 0.953, Test accuracy: 95.28
Round  85, Global train loss: 1.097, Global test loss: 0.939, Global test accuracy: 96.96
Round  86, Train loss: 0.914, Test loss: 0.953, Test accuracy: 95.38
Round  86, Global train loss: 0.914, Global test loss: 0.933, Global test accuracy: 97.42
Round  87, Train loss: 1.131, Test loss: 0.950, Test accuracy: 95.66
Round  87, Global train loss: 1.131, Global test loss: 0.938, Global test accuracy: 96.76
Round  88, Train loss: 1.101, Test loss: 0.951, Test accuracy: 95.52
Round  88, Global train loss: 1.101, Global test loss: 0.935, Global test accuracy: 97.02
Round  89, Train loss: 0.914, Test loss: 0.951, Test accuracy: 95.52
Round  89, Global train loss: 0.914, Global test loss: 0.933, Global test accuracy: 97.40
Round  90, Train loss: 0.916, Test loss: 0.951, Test accuracy: 95.48
Round  90, Global train loss: 0.916, Global test loss: 0.932, Global test accuracy: 97.44
Round  91, Train loss: 0.915, Test loss: 0.951, Test accuracy: 95.48
Round  91, Global train loss: 0.915, Global test loss: 0.932, Global test accuracy: 97.46
Round  92, Train loss: 1.125, Test loss: 0.951, Test accuracy: 95.42
Round  92, Global train loss: 1.125, Global test loss: 0.945, Global test accuracy: 96.02
Round  93, Train loss: 0.911, Test loss: 0.951, Test accuracy: 95.46
Round  93, Global train loss: 0.911, Global test loss: 0.932, Global test accuracy: 97.54
Round  94, Train loss: 0.912, Test loss: 0.951, Test accuracy: 95.50
Round  94, Global train loss: 0.912, Global test loss: 0.931, Global test accuracy: 97.46
Round  95, Train loss: 1.106, Test loss: 0.952, Test accuracy: 95.48
Round  95, Global train loss: 1.106, Global test loss: 0.935, Global test accuracy: 97.18/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  96, Train loss: 1.104, Test loss: 0.949, Test accuracy: 95.68
Round  96, Global train loss: 1.104, Global test loss: 0.936, Global test accuracy: 96.90
Round  97, Train loss: 1.103, Test loss: 0.953, Test accuracy: 95.38
Round  97, Global train loss: 1.103, Global test loss: 0.937, Global test accuracy: 96.74
Round  98, Train loss: 1.126, Test loss: 0.957, Test accuracy: 94.94
Round  98, Global train loss: 1.126, Global test loss: 0.948, Global test accuracy: 95.98
Round  99, Train loss: 0.940, Test loss: 0.958, Test accuracy: 94.82
Round  99, Global train loss: 0.940, Global test loss: 0.937, Global test accuracy: 96.92
Final Round, Train loss: 1.031, Test loss: 0.957, Test accuracy: 94.84
Final Round, Global train loss: 1.031, Global test loss: 0.937, Global test accuracy: 96.92
Average accuracy final 10 rounds: 95.36399999999999 

Average global accuracy final 10 rounds: 96.964 

529.8134534358978
[0.8460366725921631, 1.6920733451843262, 2.501171588897705, 3.310269832611084, 4.126771688461304, 4.943273544311523, 5.751177072525024, 6.559080600738525, 7.317120552062988, 8.075160503387451, 8.879510164260864, 9.683859825134277, 10.500587463378906, 11.317315101623535, 12.142576217651367, 12.9678373336792, 13.813874244689941, 14.659911155700684, 15.47069001197815, 16.281468868255615, 17.088631629943848, 17.89579439163208, 18.700830221176147, 19.505866050720215, 20.302759408950806, 21.099652767181396, 21.90401601791382, 22.70837926864624, 23.515602588653564, 24.32282590866089, 25.136316537857056, 25.949807167053223, 26.74023199081421, 27.530656814575195, 28.34186863899231, 29.153080463409424, 29.97476291656494, 30.79644536972046, 31.616042613983154, 32.43563985824585, 33.236753702163696, 34.03786754608154, 34.83668231964111, 35.635497093200684, 36.44521498680115, 37.25493288040161, 38.06516909599304, 38.87540531158447, 39.68119215965271, 40.48697900772095, 41.297971963882446, 42.108964920043945, 42.91847515106201, 43.72798538208008, 44.54241371154785, 45.356842041015625, 46.165403604507446, 46.97396516799927, 47.781901836395264, 48.58983850479126, 49.40228295326233, 50.2147274017334, 51.02449154853821, 51.83425569534302, 52.64072132110596, 53.4471869468689, 54.258052825927734, 55.06891870498657, 55.883301973342896, 56.69768524169922, 57.51317739486694, 58.32866954803467, 59.13839077949524, 59.94811201095581, 60.76373600959778, 61.579360008239746, 62.40102934837341, 63.22269868850708, 64.03359842300415, 64.84449815750122, 65.6545398235321, 66.46458148956299, 67.28601026535034, 68.1074390411377, 68.91785264015198, 69.72826623916626, 70.53977012634277, 71.35127401351929, 72.16020965576172, 72.96914529800415, 73.77950549125671, 74.58986568450928, 75.40485668182373, 76.21984767913818, 77.0310447216034, 77.8422417640686, 78.66846179962158, 79.49468183517456, 80.29979205131531, 81.10490226745605, 81.90732192993164, 82.70974159240723, 83.51252365112305, 84.31530570983887, 85.12220692634583, 85.92910814285278, 86.7356276512146, 87.54214715957642, 88.34642195701599, 89.15069675445557, 89.95465922355652, 90.75862169265747, 91.58371162414551, 92.40880155563354, 93.21395826339722, 94.01911497116089, 94.82540893554688, 95.63170289993286, 96.43458986282349, 97.23747682571411, 98.02849841117859, 98.81951999664307, 99.6257598400116, 100.43199968338013, 101.23723125457764, 102.04246282577515, 102.85279893875122, 103.6631350517273, 104.47023725509644, 105.27733945846558, 106.08305072784424, 106.8887619972229, 107.69583702087402, 108.50291204452515, 109.30728030204773, 110.11164855957031, 110.91268420219421, 111.71371984481812, 112.52024269104004, 113.32676553726196, 114.1333441734314, 114.93992280960083, 115.7514979839325, 116.56307315826416, 117.36130404472351, 118.15953493118286, 118.97193050384521, 119.78432607650757, 120.58802509307861, 121.39172410964966, 122.19879841804504, 123.00587272644043, 123.80554914474487, 124.60522556304932, 125.41172695159912, 126.21822834014893, 127.02541446685791, 127.8326005935669, 128.63944172859192, 129.44628286361694, 130.24133563041687, 131.0363883972168, 131.84194707870483, 132.64750576019287, 133.45235180854797, 134.25719785690308, 135.06165766716003, 135.866117477417, 136.66055274009705, 137.4549880027771, 138.26515436172485, 139.0753207206726, 139.88170099258423, 140.68808126449585, 141.4994785785675, 142.31087589263916, 143.11322140693665, 143.91556692123413, 144.72228145599365, 145.52899599075317, 146.3478879928589, 147.1667799949646, 147.97805643081665, 148.7893328666687, 149.5913496017456, 150.3933663368225, 151.20527458190918, 152.01718282699585, 152.82699537277222, 153.63680791854858, 154.45439171791077, 155.27197551727295, 156.0840392112732, 156.89610290527344, 157.71110200881958, 158.52610111236572, 159.3422770500183, 160.1584529876709, 160.97017097473145, 161.781888961792, 163.40307426452637, 165.02425956726074]
[46.54, 46.54, 65.64, 65.64, 77.0, 77.0, 80.94, 80.94, 88.38, 88.38, 89.14, 89.14, 94.62, 94.62, 94.48, 94.48, 94.48, 94.48, 94.5, 94.5, 95.08, 95.08, 95.04, 95.04, 95.36, 95.36, 95.04, 95.04, 95.22, 95.22, 95.2, 95.2, 95.44, 95.44, 95.68, 95.68, 96.02, 96.02, 96.24, 96.24, 96.18, 96.18, 96.24, 96.24, 96.1, 96.1, 96.18, 96.18, 96.16, 96.16, 96.2, 96.2, 95.98, 95.98, 96.0, 96.0, 95.88, 95.88, 95.84, 95.84, 95.8, 95.8, 95.7, 95.7, 95.68, 95.68, 95.78, 95.78, 96.1, 96.1, 95.8, 95.8, 95.7, 95.7, 95.68, 95.68, 95.48, 95.48, 95.66, 95.66, 95.78, 95.78, 95.92, 95.92, 94.84, 94.84, 94.86, 94.86, 94.76, 94.76, 94.68, 94.68, 94.76, 94.76, 94.8, 94.8, 94.88, 94.88, 94.78, 94.78, 94.78, 94.78, 94.7, 94.7, 94.88, 94.88, 94.9, 94.9, 95.14, 95.14, 95.48, 95.48, 95.46, 95.46, 95.42, 95.42, 95.42, 95.42, 95.46, 95.46, 96.48, 96.48, 96.4, 96.4, 96.14, 96.14, 96.0, 96.0, 96.16, 96.16, 96.06, 96.06, 96.1, 96.1, 95.64, 95.64, 95.76, 95.76, 95.74, 95.74, 95.64, 95.64, 95.88, 95.88, 95.86, 95.86, 95.86, 95.86, 94.58, 94.58, 95.72, 95.72, 95.64, 95.64, 96.04, 96.04, 95.6, 95.6, 95.24, 95.24, 95.24, 95.24, 95.64, 95.64, 95.74, 95.74, 95.18, 95.18, 95.06, 95.06, 95.28, 95.28, 95.38, 95.38, 95.66, 95.66, 95.52, 95.52, 95.52, 95.52, 95.48, 95.48, 95.48, 95.48, 95.42, 95.42, 95.46, 95.46, 95.5, 95.5, 95.48, 95.48, 95.68, 95.68, 95.38, 95.38, 94.94, 94.94, 94.82, 94.82, 94.84, 94.84]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.2 , level_n_lowerb:0.8  

   Client 1, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Traceback (most recent call last):
  File "main_fedpac_co_teaching.py", line 250, in <module>
    local.filter_data(net=net_local.to(args.device), net2=net_local2.to(args.device), concept_matrix_local = concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1587, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

   Client 0, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550021 (local), 549696 (global); Percentage 99.94 (549696/550021)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 1.624, Test loss: 1.591, Test accuracy: 51.66
Round   0, Global train loss: 1.624, Global test loss: 1.591, Global test accuracy: 51.78
Round   1, Train loss: 1.579, Test loss: 1.529, Test accuracy: 69.74
Round   1, Global train loss: 1.579, Global test loss: 1.528, Global test accuracy: 69.50
Round   2, Train loss: 1.449, Test loss: 1.286, Test accuracy: 78.72
Round   2, Global train loss: 1.449, Global test loss: 1.268, Global test accuracy: 78.08
Round   3, Train loss: 1.319, Test loss: 1.169, Test accuracy: 87.64
Round   3, Global train loss: 1.319, Global test loss: 1.141, Global test accuracy: 87.10
Round   4, Train loss: 1.253, Test loss: 1.089, Test accuracy: 92.82
Round   4, Global train loss: 1.253, Global test loss: 1.074, Global test accuracy: 93.96
Round   5, Train loss: 1.215, Test loss: 1.045, Test accuracy: 94.34
Round   5, Global train loss: 1.215, Global test loss: 1.028, Global test accuracy: 95.06
Round   6, Train loss: 1.209, Test loss: 1.029, Test accuracy: 95.02
Round   6, Global train loss: 1.209, Global test loss: 1.018, Global test accuracy: 95.50
Round   7, Train loss: 1.195, Test loss: 1.017, Test accuracy: 95.94
Round   7, Global train loss: 1.195, Global test loss: 1.009, Global test accuracy: 96.26
Round   8, Train loss: 1.177, Test loss: 1.012, Test accuracy: 95.78
Round   8, Global train loss: 1.177, Global test loss: 1.003, Global test accuracy: 95.84
Round   9, Train loss: 1.166, Test loss: 1.007, Test accuracy: 96.06
Round   9, Global train loss: 1.166, Global test loss: 0.995, Global test accuracy: 96.12
Round  10, Train loss: 0.979, Test loss: 0.983, Test accuracy: 96.44
Round  10, Global train loss: 0.979, Global test loss: 0.967, Global test accuracy: 96.60
Round  11, Train loss: 1.369, Test loss: 1.009, Test accuracy: 96.06
Round  11, Global train loss: 1.369, Global test loss: 1.018, Global test accuracy: 96.08
Round  12, Train loss: 1.168, Test loss: 1.003, Test accuracy: 96.26
Round  12, Global train loss: 1.168, Global test loss: 0.997, Global test accuracy: 96.60
Round  13, Train loss: 0.963, Test loss: 0.983, Test accuracy: 96.62
Round  13, Global train loss: 0.963, Global test loss: 0.960, Global test accuracy: 96.96
Round  14, Train loss: 0.986, Test loss: 0.978, Test accuracy: 96.10
Round  14, Global train loss: 0.986, Global test loss: 0.958, Global test accuracy: 96.46
Round  15, Train loss: 1.159, Test loss: 0.979, Test accuracy: 96.42
Round  15, Global train loss: 1.159, Global test loss: 0.975, Global test accuracy: 96.78
Round  16, Train loss: 0.953, Test loss: 0.974, Test accuracy: 96.42
Round  16, Global train loss: 0.953, Global test loss: 0.955, Global test accuracy: 96.86
Round  17, Train loss: 0.950, Test loss: 0.968, Test accuracy: 96.52
Round  17, Global train loss: 0.950, Global test loss: 0.949, Global test accuracy: 96.98
Round  18, Train loss: 1.155, Test loss: 0.971, Test accuracy: 96.46
Round  18, Global train loss: 1.155, Global test loss: 0.965, Global test accuracy: 96.84
Round  19, Train loss: 0.974, Test loss: 0.974, Test accuracy: 96.22
Round  19, Global train loss: 0.974, Global test loss: 0.951, Global test accuracy: 96.64
Round  20, Train loss: 1.149, Test loss: 0.977, Test accuracy: 96.52
Round  20, Global train loss: 1.149, Global test loss: 0.966, Global test accuracy: 97.04
Round  21, Train loss: 1.150, Test loss: 0.981, Test accuracy: 96.70
Round  21, Global train loss: 1.150, Global test loss: 0.968, Global test accuracy: 97.10
Round  22, Train loss: 1.151, Test loss: 0.985, Test accuracy: 96.78
Round  22, Global train loss: 1.151, Global test loss: 0.971, Global test accuracy: 97.18
Round  23, Train loss: 1.338, Test loss: 0.998, Test accuracy: 96.56
Round  23, Global train loss: 1.338, Global test loss: 1.011, Global test accuracy: 96.68
Round  24, Train loss: 1.162, Test loss: 0.991, Test accuracy: 96.54
Round  24, Global train loss: 1.162, Global test loss: 0.986, Global test accuracy: 96.82
Round  25, Train loss: 0.980, Test loss: 0.981, Test accuracy: 96.30
Round  25, Global train loss: 0.980, Global test loss: 0.957, Global test accuracy: 96.30
Round  26, Train loss: 1.144, Test loss: 0.980, Test accuracy: 96.60
Round  26, Global train loss: 1.144, Global test loss: 0.966, Global test accuracy: 97.32
Round  27, Train loss: 0.934, Test loss: 0.973, Test accuracy: 96.76
Round  27, Global train loss: 0.934, Global test loss: 0.946, Global test accuracy: 97.24
Round  28, Train loss: 1.141, Test loss: 0.977, Test accuracy: 96.64
Round  28, Global train loss: 1.141, Global test loss: 0.961, Global test accuracy: 97.20
Round  29, Train loss: 0.939, Test loss: 0.969, Test accuracy: 96.70
Round  29, Global train loss: 0.939, Global test loss: 0.946, Global test accuracy: 97.46
Round  30, Train loss: 1.164, Test loss: 0.981, Test accuracy: 96.16
Round  30, Global train loss: 1.164, Global test loss: 0.967, Global test accuracy: 96.28
Round  31, Train loss: 1.137, Test loss: 0.983, Test accuracy: 96.42
Round  31, Global train loss: 1.137, Global test loss: 0.964, Global test accuracy: 97.18
Round  32, Train loss: 0.936, Test loss: 0.974, Test accuracy: 96.36
Round  32, Global train loss: 0.936, Global test loss: 0.946, Global test accuracy: 97.34
Round  33, Train loss: 0.930, Test loss: 0.966, Test accuracy: 96.70
Round  33, Global train loss: 0.930, Global test loss: 0.943, Global test accuracy: 97.38
Round  34, Train loss: 0.939, Test loss: 0.962, Test accuracy: 96.82
Round  34, Global train loss: 0.939, Global test loss: 0.942, Global test accuracy: 97.40
Round  35, Train loss: 0.932, Test loss: 0.960, Test accuracy: 96.78
Round  35, Global train loss: 0.932, Global test loss: 0.940, Global test accuracy: 97.40
Round  36, Train loss: 0.957, Test loss: 0.961, Test accuracy: 96.66
Round  36, Global train loss: 0.957, Global test loss: 0.942, Global test accuracy: 96.94
Round  37, Train loss: 0.927, Test loss: 0.958, Test accuracy: 96.82
Round  37, Global train loss: 0.927, Global test loss: 0.939, Global test accuracy: 97.30
Round  38, Train loss: 0.930, Test loss: 0.957, Test accuracy: 96.94
Round  38, Global train loss: 0.930, Global test loss: 0.938, Global test accuracy: 97.54
Round  39, Train loss: 0.924, Test loss: 0.956, Test accuracy: 96.86
Round  39, Global train loss: 0.924, Global test loss: 0.936, Global test accuracy: 97.52
Round  40, Train loss: 1.136, Test loss: 0.966, Test accuracy: 96.70
Round  40, Global train loss: 1.136, Global test loss: 0.947, Global test accuracy: 97.52
Round  41, Train loss: 0.928, Test loss: 0.965, Test accuracy: 96.72
Round  41, Global train loss: 0.928, Global test loss: 0.941, Global test accuracy: 97.36
Round  42, Train loss: 0.960, Test loss: 0.967, Test accuracy: 96.36
Round  42, Global train loss: 0.960, Global test loss: 0.947, Global test accuracy: 96.76
Round  43, Train loss: 1.156, Test loss: 0.977, Test accuracy: 96.04
Round  43, Global train loss: 1.156, Global test loss: 0.968, Global test accuracy: 96.18
Round  44, Train loss: 1.132, Test loss: 0.979, Test accuracy: 96.46
Round  44, Global train loss: 1.132, Global test loss: 0.964, Global test accuracy: 97.02
Round  45, Train loss: 1.131, Test loss: 0.979, Test accuracy: 96.56
Round  45, Global train loss: 1.131, Global test loss: 0.962, Global test accuracy: 97.38
Round  46, Train loss: 0.956, Test loss: 0.973, Test accuracy: 96.56
Round  46, Global train loss: 0.956, Global test loss: 0.949, Global test accuracy: 96.96
Round  47, Train loss: 0.922, Test loss: 0.965, Test accuracy: 96.60
Round  47, Global train loss: 0.922, Global test loss: 0.939, Global test accuracy: 97.40
Round  48, Train loss: 1.323, Test loss: 0.992, Test accuracy: 96.10
Round  48, Global train loss: 1.323, Global test loss: 1.001, Global test accuracy: 96.26
Round  49, Train loss: 0.956, Test loss: 0.983, Test accuracy: 96.36
Round  49, Global train loss: 0.956, Global test loss: 0.951, Global test accuracy: 96.84
Round  50, Train loss: 0.948, Test loss: 0.975, Test accuracy: 96.36
Round  50, Global train loss: 0.948, Global test loss: 0.948, Global test accuracy: 96.90
Round  51, Train loss: 1.314, Test loss: 0.996, Test accuracy: 95.74
Round  51, Global train loss: 1.314, Global test loss: 1.009, Global test accuracy: 96.30
Round  52, Train loss: 1.117, Test loss: 0.993, Test accuracy: 96.20
Round  52, Global train loss: 1.117, Global test loss: 0.965, Global test accuracy: 96.94
Round  53, Train loss: 1.109, Test loss: 0.988, Test accuracy: 96.06
Round  53, Global train loss: 1.109, Global test loss: 0.963, Global test accuracy: 96.90
Round  54, Train loss: 0.953, Test loss: 0.977, Test accuracy: 96.12
Round  54, Global train loss: 0.953, Global test loss: 0.953, Global test accuracy: 96.70
Round  55, Train loss: 0.924, Test loss: 0.965, Test accuracy: 96.48
Round  55, Global train loss: 0.924, Global test loss: 0.940, Global test accuracy: 97.40
Round  56, Train loss: 1.106, Test loss: 0.975, Test accuracy: 96.20
Round  56, Global train loss: 1.106, Global test loss: 0.956, Global test accuracy: 97.02
Round  57, Train loss: 1.116, Test loss: 0.983, Test accuracy: 96.16
Round  57, Global train loss: 1.116, Global test loss: 0.957, Global test accuracy: 97.22
Round  58, Train loss: 0.945, Test loss: 0.980, Test accuracy: 95.92
Round  58, Global train loss: 0.945, Global test loss: 0.948, Global test accuracy: 96.80
Round  59, Train loss: 1.122, Test loss: 0.991, Test accuracy: 95.26
Round  59, Global train loss: 1.122, Global test loss: 0.981, Global test accuracy: 95.62
Round  60, Train loss: 1.118, Test loss: 0.987, Test accuracy: 95.76
Round  60, Global train loss: 1.118, Global test loss: 0.964, Global test accuracy: 97.16
Round  61, Train loss: 1.094, Test loss: 0.987, Test accuracy: 96.02
Round  61, Global train loss: 1.094, Global test loss: 0.961, Global test accuracy: 96.84
Round  62, Train loss: 0.944, Test loss: 0.977, Test accuracy: 95.98
Round  62, Global train loss: 0.944, Global test loss: 0.951, Global test accuracy: 96.86
Round  63, Train loss: 0.920, Test loss: 0.967, Test accuracy: 96.38
Round  63, Global train loss: 0.920, Global test loss: 0.939, Global test accuracy: 97.46
Round  64, Train loss: 1.113, Test loss: 0.973, Test accuracy: 96.20
Round  64, Global train loss: 1.113, Global test loss: 0.952, Global test accuracy: 97.40
Round  65, Train loss: 0.920, Test loss: 0.970, Test accuracy: 96.30
Round  65, Global train loss: 0.920, Global test loss: 0.939, Global test accuracy: 97.48
Round  66, Train loss: 1.107, Test loss: 0.978, Test accuracy: 96.06
Round  66, Global train loss: 1.107, Global test loss: 0.952, Global test accuracy: 97.18
Round  67, Train loss: 1.094, Test loss: 0.986, Test accuracy: 95.60
Round  67, Global train loss: 1.094, Global test loss: 0.963, Global test accuracy: 96.84
Round  68, Train loss: 0.920, Test loss: 0.973, Test accuracy: 96.20
Round  68, Global train loss: 0.920, Global test loss: 0.940, Global test accuracy: 97.42
Round  69, Train loss: 1.087, Test loss: 0.983, Test accuracy: 95.96
Round  69, Global train loss: 1.087, Global test loss: 0.954, Global test accuracy: 97.06
Round  70, Train loss: 1.082, Test loss: 0.993, Test accuracy: 95.32
Round  70, Global train loss: 1.082, Global test loss: 0.962, Global test accuracy: 96.66
Round  71, Train loss: 1.123, Test loss: 0.996, Test accuracy: 94.94
Round  71, Global train loss: 1.123, Global test loss: 0.978, Global test accuracy: 96.24
Round  72, Train loss: 1.273, Test loss: 1.047, Test accuracy: 91.42
Round  72, Global train loss: 1.273, Global test loss: 1.075, Global test accuracy: 90.38
Round  73, Train loss: 0.948, Test loss: 0.991, Test accuracy: 95.04
Round  73, Global train loss: 0.948, Global test loss: 0.957, Global test accuracy: 96.56
Round  74, Train loss: 1.078, Test loss: 0.989, Test accuracy: 95.14
Round  74, Global train loss: 1.078, Global test loss: 0.964, Global test accuracy: 96.66
Round  75, Train loss: 0.933, Test loss: 0.978, Test accuracy: 95.82
Round  75, Global train loss: 0.933, Global test loss: 0.951, Global test accuracy: 96.98
Round  76, Train loss: 1.096, Test loss: 0.981, Test accuracy: 95.84
Round  76, Global train loss: 1.096, Global test loss: 0.957, Global test accuracy: 97.14
Round  77, Train loss: 0.918, Test loss: 0.973, Test accuracy: 96.02
Round  77, Global train loss: 0.918, Global test loss: 0.941, Global test accuracy: 97.40
Round  78, Train loss: 1.078, Test loss: 0.989, Test accuracy: 95.22
Round  78, Global train loss: 1.078, Global test loss: 0.961, Global test accuracy: 96.62
Round  79, Train loss: 1.103, Test loss: 1.007, Test accuracy: 93.54
Round  79, Global train loss: 1.103, Global test loss: 0.993, Global test accuracy: 94.88
Round  80, Train loss: 1.075, Test loss: 0.997, Test accuracy: 94.68
Round  80, Global train loss: 1.075, Global test loss: 0.970, Global test accuracy: 96.54
Round  81, Train loss: 0.921, Test loss: 0.974, Test accuracy: 95.96
Round  81, Global train loss: 0.921, Global test loss: 0.942, Global test accuracy: 97.46
Round  82, Train loss: 1.081, Test loss: 1.004, Test accuracy: 93.90
Round  82, Global train loss: 1.081, Global test loss: 0.987, Global test accuracy: 94.44
Round  83, Train loss: 0.920, Test loss: 0.978, Test accuracy: 95.72
Round  83, Global train loss: 0.920, Global test loss: 0.942, Global test accuracy: 97.46
Round  84, Train loss: 0.914, Test loss: 0.970, Test accuracy: 96.14
Round  84, Global train loss: 0.914, Global test loss: 0.938, Global test accuracy: 97.44
Round  85, Train loss: 1.069, Test loss: 0.987, Test accuracy: 95.02
Round  85, Global train loss: 1.069, Global test loss: 0.956, Global test accuracy: 97.00
Round  86, Train loss: 0.926, Test loss: 0.981, Test accuracy: 95.34
Round  86, Global train loss: 0.926, Global test loss: 0.952, Global test accuracy: 96.48
Round  87, Train loss: 0.913, Test loss: 0.968, Test accuracy: 96.14
Round  87, Global train loss: 0.913, Global test loss: 0.936, Global test accuracy: 97.54
Round  88, Train loss: 0.913, Test loss: 0.966, Test accuracy: 96.30
Round  88, Global train loss: 0.913, Global test loss: 0.935, Global test accuracy: 97.66
Round  89, Train loss: 0.923, Test loss: 0.971, Test accuracy: 95.70
Round  89, Global train loss: 0.923, Global test loss: 0.946, Global test accuracy: 96.74
Round  90, Train loss: 1.247, Test loss: 1.017, Test accuracy: 92.72
Round  90, Global train loss: 1.247, Global test loss: 1.001, Global test accuracy: 95.30
Round  91, Train loss: 1.218, Test loss: 1.050, Test accuracy: 90.68
Round  91, Global train loss: 1.218, Global test loss: 1.043, Global test accuracy: 93.34
Round  92, Train loss: 0.932, Test loss: 0.985, Test accuracy: 95.42
Round  92, Global train loss: 0.932, Global test loss: 0.946, Global test accuracy: 97.04/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  93, Train loss: 0.915, Test loss: 0.972, Test accuracy: 96.04
Round  93, Global train loss: 0.915, Global test loss: 0.939, Global test accuracy: 97.52
Round  94, Train loss: 1.059, Test loss: 0.987, Test accuracy: 94.84
Round  94, Global train loss: 1.059, Global test loss: 0.957, Global test accuracy: 96.98
Round  95, Train loss: 1.060, Test loss: 1.008, Test accuracy: 93.28
Round  95, Global train loss: 1.060, Global test loss: 0.987, Global test accuracy: 94.60
Round  96, Train loss: 1.052, Test loss: 1.024, Test accuracy: 92.02
Round  96, Global train loss: 1.052, Global test loss: 0.999, Global test accuracy: 93.70
Round  97, Train loss: 1.084, Test loss: 0.999, Test accuracy: 94.12
Round  97, Global train loss: 1.084, Global test loss: 0.972, Global test accuracy: 96.46
Round  98, Train loss: 1.071, Test loss: 1.000, Test accuracy: 94.20
Round  98, Global train loss: 1.071, Global test loss: 0.972, Global test accuracy: 96.40
Round  99, Train loss: 0.917, Test loss: 0.974, Test accuracy: 95.70
Round  99, Global train loss: 0.917, Global test loss: 0.943, Global test accuracy: 97.18
Final Round, Train loss: 1.002, Test loss: 0.983, Test accuracy: 94.80
Final Round, Global train loss: 1.002, Global test loss: 0.943, Global test accuracy: 97.18
Average accuracy final 10 rounds: 93.90200000000002
480.3761034011841
[0.9212100505828857, 1.769624948501587, 2.62009859085083, 3.469583034515381, 4.36408805847168, 5.215525388717651, 6.062286138534546, 6.910872936248779, 7.75910210609436, 8.60563850402832, 9.455322980880737, 10.348848104476929, 11.215090990066528, 12.078289270401001, 13.000210285186768, 13.861923933029175, 14.764033794403076, 15.65928840637207, 16.50966238975525, 17.3619487285614, 18.24247670173645, 19.094661235809326, 19.94277834892273, 20.766950368881226, 21.611870765686035, 22.44608974456787, 23.282462120056152, 24.102617263793945, 24.92462396621704, 25.805700302124023, 26.671137809753418, 27.5175518989563, 28.371748685836792, 29.224900245666504, 30.017005920410156, 30.8574800491333, 31.71933341026306, 32.5754029750824, 33.44319128990173, 34.374151945114136, 35.29243493080139, 36.20150828361511, 37.20875310897827, 38.106175899505615, 39.184995889663696, 40.119192361831665, 41.05403971672058, 41.962114572525024, 42.88124680519104, 43.81972551345825, 44.7634711265564, 45.69257092475891, 46.62739634513855, 47.574378490448, 48.51661014556885, 49.44276189804077, 50.36260271072388, 51.286322355270386, 52.2199273109436, 53.116161823272705, 54.07868790626526, 55.01059556007385, 55.94512152671814, 56.883753538131714, 57.77661681175232, 58.71465539932251, 59.632943868637085, 60.571693420410156, 61.47116565704346, 62.31300473213196, 63.179555892944336, 64.03768372535706, 64.89972567558289, 65.75899577140808, 66.62628412246704, 67.45537376403809, 68.29955196380615, 69.13740587234497, 69.95880842208862, 70.78715658187866, 71.61801719665527, 72.43923163414001, 73.27628684043884, 74.10584235191345, 74.94657158851624, 75.79800009727478, 76.70015144348145, 77.56649923324585, 78.44552898406982, 79.36024355888367, 80.28301429748535, 81.20811247825623, 82.12354707717896, 83.02454400062561, 83.92448616027832, 84.92708039283752, 85.99653434753418, 86.9501941204071, 88.01135754585266, 89.07352447509766, 90.73933029174805]
[51.66, 69.74, 78.72, 87.64, 92.82, 94.34, 95.02, 95.94, 95.78, 96.06, 96.44, 96.06, 96.26, 96.62, 96.1, 96.42, 96.42, 96.52, 96.46, 96.22, 96.52, 96.7, 96.78, 96.56, 96.54, 96.3, 96.6, 96.76, 96.64, 96.7, 96.16, 96.42, 96.36, 96.7, 96.82, 96.78, 96.66, 96.82, 96.94, 96.86, 96.7, 96.72, 96.36, 96.04, 96.46, 96.56, 96.56, 96.6, 96.1, 96.36, 96.36, 95.74, 96.2, 96.06, 96.12, 96.48, 96.2, 96.16, 95.92, 95.26, 95.76, 96.02, 95.98, 96.38, 96.2, 96.3, 96.06, 95.6, 96.2, 95.96, 95.32, 94.94, 91.42, 95.04, 95.14, 95.82, 95.84, 96.02, 95.22, 93.54, 94.68, 95.96, 93.9, 95.72, 96.14, 95.02, 95.34, 96.14, 96.3, 95.7, 92.72, 90.68, 95.42, 96.04, 94.84, 93.28, 92.02, 94.12, 94.2, 95.7, 94.8]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fedpac_copsl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist,  filter_alg: loss_psl, level_n_system: 0.2 , level_n_lowerb:0.8  

   Client 8, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550021 (local), 549696 (global); Percentage 99.94 (549696/550021)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 1.621, Test loss: 1.584, Test accuracy: 36.64
Round   0, Global train loss: 1.621, Global test loss: 1.584, Global test accuracy: 36.80
Round   1, Train loss: 1.565, Test loss: 1.497, Test accuracy: 82.36
Round   1, Global train loss: 1.565, Global test loss: 1.497, Global test accuracy: 82.92
Round   2, Train loss: 1.449, Test loss: 1.280, Test accuracy: 91.44
Round   2, Global train loss: 1.449, Global test loss: 1.273, Global test accuracy: 93.02
Round   3, Train loss: 1.248, Test loss: 1.078, Test accuracy: 94.30
Round   3, Global train loss: 1.248, Global test loss: 1.067, Global test accuracy: 95.06
Round   4, Train loss: 1.149, Test loss: 1.021, Test accuracy: 95.28
Round   4, Global train loss: 1.149, Global test loss: 1.008, Global test accuracy: 95.74
Round   5, Train loss: 1.122, Test loss: 1.002, Test accuracy: 95.82
Round   5, Global train loss: 1.122, Global test loss: 0.987, Global test accuracy: 96.36
Round   6, Train loss: 1.109, Test loss: 0.994, Test accuracy: 95.90
Round   6, Global train loss: 1.109, Global test loss: 0.977, Global test accuracy: 96.44
Round   7, Train loss: 1.102, Test loss: 0.989, Test accuracy: 95.70
Round   7, Global train loss: 1.102, Global test loss: 0.971, Global test accuracy: 96.52
Round   8, Train loss: 1.096, Test loss: 0.985, Test accuracy: 95.84
Round   8, Global train loss: 1.096, Global test loss: 0.966, Global test accuracy: 96.66
Round   9, Train loss: 1.092, Test loss: 0.983, Test accuracy: 95.84
Round   9, Global train loss: 1.092, Global test loss: 0.963, Global test accuracy: 96.70
Round  10, Train loss: 1.183, Test loss: 0.989, Test accuracy: 95.84
Round  10, Global train loss: 1.183, Global test loss: 0.978, Global test accuracy: 96.80
Round  11, Train loss: 0.968, Test loss: 0.978, Test accuracy: 96.26
Round  11, Global train loss: 0.968, Global test loss: 0.952, Global test accuracy: 96.90
Traceback (most recent call last):
  File "main_fedpac_copsl.py", line 280, in <module>
    w_local, loss, indd, class_center_local, class_num, noisy_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys,
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2559, in train
    self.filter_data(net, local_net, iter2-head_eps+1, local_eps-head_eps+1, concept_matrix_local)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2396, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist, level_n_system: 0.4 , level_n_lowerb:0.4  

   Client 0, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.596, Test loss: 1.567, Test accuracy: 58.74
Round   0, Global train loss: 1.596, Global test loss: 1.569, Global test accuracy: 58.58
Round   1, Train loss: 1.457, Test loss: 1.358, Test accuracy: 72.38
Round   1, Global train loss: 1.457, Global test loss: 1.269, Global test accuracy: 82.54
Round   2, Train loss: 1.133, Test loss: 1.195, Test accuracy: 80.44
Round   2, Global train loss: 1.133, Global test loss: 0.996, Global test accuracy: 94.78
Round   3, Train loss: 1.154, Test loss: 1.158, Test accuracy: 83.50
Round   3, Global train loss: 1.154, Global test loss: 1.024, Global test accuracy: 92.60
Round   4, Train loss: 1.314, Test loss: 1.126, Test accuracy: 85.50
Round   4, Global train loss: 1.314, Global test loss: 1.127, Global test accuracy: 89.84
Round   5, Train loss: 1.069, Test loss: 1.088, Test accuracy: 86.70
Round   5, Global train loss: 1.069, Global test loss: 0.968, Global test accuracy: 95.48
Round   6, Train loss: 1.169, Test loss: 1.082, Test accuracy: 86.16
Round   6, Global train loss: 1.169, Global test loss: 1.031, Global test accuracy: 93.98
Round   7, Train loss: 1.094, Test loss: 1.046, Test accuracy: 88.46
Round   7, Global train loss: 1.094, Global test loss: 0.989, Global test accuracy: 94.98
Round   8, Train loss: 1.057, Test loss: 1.038, Test accuracy: 88.50
Round   8, Global train loss: 1.057, Global test loss: 0.965, Global test accuracy: 95.22
Round   9, Train loss: 1.046, Test loss: 1.038, Test accuracy: 88.36
Round   9, Global train loss: 1.046, Global test loss: 0.967, Global test accuracy: 95.08
Round  10, Train loss: 1.084, Test loss: 1.011, Test accuracy: 92.02
Round  10, Global train loss: 1.084, Global test loss: 0.976, Global test accuracy: 95.04
Round  11, Train loss: 1.138, Test loss: 0.995, Test accuracy: 93.86
Round  11, Global train loss: 1.138, Global test loss: 0.964, Global test accuracy: 95.48
Round  12, Train loss: 1.033, Test loss: 0.991, Test accuracy: 93.76
Round  12, Global train loss: 1.033, Global test loss: 0.957, Global test accuracy: 96.26
Round  13, Train loss: 1.062, Test loss: 0.985, Test accuracy: 93.34
Round  13, Global train loss: 1.062, Global test loss: 0.976, Global test accuracy: 94.26
Round  14, Train loss: 1.036, Test loss: 0.985, Test accuracy: 93.28
Round  14, Global train loss: 1.036, Global test loss: 0.952, Global test accuracy: 96.00
Round  15, Train loss: 1.127, Test loss: 0.981, Test accuracy: 93.48
Round  15, Global train loss: 1.127, Global test loss: 0.968, Global test accuracy: 95.36
Round  16, Train loss: 1.043, Test loss: 0.978, Test accuracy: 93.70
Round  16, Global train loss: 1.043, Global test loss: 0.959, Global test accuracy: 95.70
Round  17, Train loss: 1.039, Test loss: 0.980, Test accuracy: 93.38
Round  17, Global train loss: 1.039, Global test loss: 0.956, Global test accuracy: 95.84
Round  18, Train loss: 1.031, Test loss: 0.980, Test accuracy: 93.46
Round  18, Global train loss: 1.031, Global test loss: 0.962, Global test accuracy: 95.02
Round  19, Train loss: 1.125, Test loss: 0.979, Test accuracy: 93.56
Round  19, Global train loss: 1.125, Global test loss: 0.961, Global test accuracy: 95.28
Round  20, Train loss: 1.107, Test loss: 0.980, Test accuracy: 93.36
Round  20, Global train loss: 1.107, Global test loss: 0.960, Global test accuracy: 95.60
Round  21, Train loss: 1.123, Test loss: 0.981, Test accuracy: 93.24
Round  21, Global train loss: 1.123, Global test loss: 0.977, Global test accuracy: 93.70
Round  22, Train loss: 1.120, Test loss: 0.980, Test accuracy: 93.30
Round  22, Global train loss: 1.120, Global test loss: 0.960, Global test accuracy: 95.36
Round  23, Train loss: 1.090, Test loss: 0.980, Test accuracy: 93.22
Round  23, Global train loss: 1.090, Global test loss: 0.958, Global test accuracy: 95.48
Round  24, Train loss: 1.023, Test loss: 0.981, Test accuracy: 93.12
Round  24, Global train loss: 1.023, Global test loss: 0.951, Global test accuracy: 95.74
Round  25, Train loss: 1.048, Test loss: 0.982, Test accuracy: 93.04
Round  25, Global train loss: 1.048, Global test loss: 0.951, Global test accuracy: 95.90
Round  26, Train loss: 1.018, Test loss: 0.981, Test accuracy: 93.06
Round  26, Global train loss: 1.018, Global test loss: 0.958, Global test accuracy: 95.40
Round  27, Train loss: 1.027, Test loss: 0.982, Test accuracy: 92.98
Round  27, Global train loss: 1.027, Global test loss: 0.952, Global test accuracy: 95.88
Round  28, Train loss: 1.016, Test loss: 0.982, Test accuracy: 92.90
Round  28, Global train loss: 1.016, Global test loss: 0.957, Global test accuracy: 95.46
Round  29, Train loss: 0.913, Test loss: 0.982, Test accuracy: 92.92
Round  29, Global train loss: 0.913, Global test loss: 0.947, Global test accuracy: 95.94
Round  30, Train loss: 1.110, Test loss: 0.984, Test accuracy: 92.80
Round  30, Global train loss: 1.110, Global test loss: 0.959, Global test accuracy: 94.86
Round  31, Train loss: 0.996, Test loss: 0.985, Test accuracy: 92.68
Round  31, Global train loss: 0.996, Global test loss: 0.945, Global test accuracy: 96.28
Round  32, Train loss: 0.933, Test loss: 0.984, Test accuracy: 92.72
Round  32, Global train loss: 0.933, Global test loss: 0.953, Global test accuracy: 95.50
Round  33, Train loss: 0.912, Test loss: 0.984, Test accuracy: 92.72
Round  33, Global train loss: 0.912, Global test loss: 0.947, Global test accuracy: 95.92
Round  34, Train loss: 0.954, Test loss: 0.984, Test accuracy: 92.68
Round  34, Global train loss: 0.954, Global test loss: 0.954, Global test accuracy: 95.40
Round  35, Train loss: 0.932, Test loss: 0.985, Test accuracy: 92.64
Round  35, Global train loss: 0.932, Global test loss: 0.953, Global test accuracy: 95.40
Round  36, Train loss: 1.112, Test loss: 0.985, Test accuracy: 92.64
Round  36, Global train loss: 1.112, Global test loss: 0.960, Global test accuracy: 94.88
Round  37, Train loss: 1.025, Test loss: 0.984, Test accuracy: 92.66
Round  37, Global train loss: 1.025, Global test loss: 0.951, Global test accuracy: 95.86
Round  38, Train loss: 0.935, Test loss: 0.984, Test accuracy: 92.66
Round  38, Global train loss: 0.935, Global test loss: 0.948, Global test accuracy: 95.98
Round  39, Train loss: 0.932, Test loss: 0.984, Test accuracy: 92.68
Round  39, Global train loss: 0.932, Global test loss: 0.953, Global test accuracy: 95.32
Round  40, Train loss: 1.012, Test loss: 0.984, Test accuracy: 92.68
Round  40, Global train loss: 1.012, Global test loss: 0.957, Global test accuracy: 95.18
Round  41, Train loss: 0.936, Test loss: 0.984, Test accuracy: 92.68
Round  41, Global train loss: 0.936, Global test loss: 0.946, Global test accuracy: 96.24
Round  42, Train loss: 1.043, Test loss: 0.984, Test accuracy: 92.48
Round  42, Global train loss: 1.043, Global test loss: 0.947, Global test accuracy: 96.06
Round  43, Train loss: 1.126, Test loss: 0.985, Test accuracy: 92.56
Round  43, Global train loss: 1.126, Global test loss: 0.957, Global test accuracy: 95.34
Round  44, Train loss: 1.012, Test loss: 0.985, Test accuracy: 92.52
Round  44, Global train loss: 1.012, Global test loss: 0.954, Global test accuracy: 95.58
Round  45, Train loss: 1.009, Test loss: 0.985, Test accuracy: 92.52
Round  45, Global train loss: 1.009, Global test loss: 0.955, Global test accuracy: 95.62
Round  46, Train loss: 1.128, Test loss: 0.985, Test accuracy: 92.46
Round  46, Global train loss: 1.128, Global test loss: 0.955, Global test accuracy: 95.48
Round  47, Train loss: 0.933, Test loss: 0.985, Test accuracy: 92.44
Round  47, Global train loss: 0.933, Global test loss: 0.946, Global test accuracy: 96.18
Round  48, Train loss: 1.098, Test loss: 0.985, Test accuracy: 92.32
Round  48, Global train loss: 1.098, Global test loss: 0.955, Global test accuracy: 95.72
Round  49, Train loss: 1.125, Test loss: 0.986, Test accuracy: 92.16
Round  49, Global train loss: 1.125, Global test loss: 0.955, Global test accuracy: 95.40
Round  50, Train loss: 1.123, Test loss: 0.986, Test accuracy: 92.12
Round  50, Global train loss: 1.123, Global test loss: 0.955, Global test accuracy: 95.44
Round  51, Train loss: 1.094, Test loss: 0.987, Test accuracy: 92.14
Round  51, Global train loss: 1.094, Global test loss: 0.966, Global test accuracy: 94.46
Round  52, Train loss: 1.078, Test loss: 0.987, Test accuracy: 92.16
Round  52, Global train loss: 1.078, Global test loss: 0.954, Global test accuracy: 95.52
Round  53, Train loss: 0.993, Test loss: 0.987, Test accuracy: 92.14
Round  53, Global train loss: 0.993, Global test loss: 0.950, Global test accuracy: 95.82
Round  54, Train loss: 1.031, Test loss: 0.987, Test accuracy: 92.10
Round  54, Global train loss: 1.031, Global test loss: 0.959, Global test accuracy: 94.80
Round  55, Train loss: 0.929, Test loss: 0.987, Test accuracy: 92.12
Round  55, Global train loss: 0.929, Global test loss: 0.951, Global test accuracy: 95.56
Round  56, Train loss: 0.993, Test loss: 0.987, Test accuracy: 92.04
Round  56, Global train loss: 0.993, Global test loss: 0.953, Global test accuracy: 95.46
Round  57, Train loss: 0.991, Test loss: 0.987, Test accuracy: 92.06
Round  57, Global train loss: 0.991, Global test loss: 0.945, Global test accuracy: 96.48
Round  58, Train loss: 1.032, Test loss: 0.988, Test accuracy: 91.98
Round  58, Global train loss: 1.032, Global test loss: 0.948, Global test accuracy: 95.82
Round  59, Train loss: 1.091, Test loss: 0.988, Test accuracy: 91.90
Round  59, Global train loss: 1.091, Global test loss: 0.956, Global test accuracy: 95.16
Round  60, Train loss: 1.013, Test loss: 0.988, Test accuracy: 91.90
Round  60, Global train loss: 1.013, Global test loss: 0.945, Global test accuracy: 96.26
Round  61, Train loss: 0.992, Test loss: 0.988, Test accuracy: 91.88
Round  61, Global train loss: 0.992, Global test loss: 0.953, Global test accuracy: 95.34
Round  62, Train loss: 1.027, Test loss: 0.988, Test accuracy: 91.90
Round  62, Global train loss: 1.027, Global test loss: 0.960, Global test accuracy: 94.60
Round  63, Train loss: 0.951, Test loss: 0.988, Test accuracy: 91.88
Round  63, Global train loss: 0.951, Global test loss: 0.949, Global test accuracy: 95.90
Round  64, Train loss: 1.078, Test loss: 0.988, Test accuracy: 91.88
Round  64, Global train loss: 1.078, Global test loss: 0.951, Global test accuracy: 95.62
Round  65, Train loss: 0.949, Test loss: 0.988, Test accuracy: 91.92
Round  65, Global train loss: 0.949, Global test loss: 0.952, Global test accuracy: 95.56
Round  66, Train loss: 1.011, Test loss: 0.988, Test accuracy: 91.88
Round  66, Global train loss: 1.011, Global test loss: 0.945, Global test accuracy: 96.00
Round  67, Train loss: 0.991, Test loss: 0.989, Test accuracy: 91.80
Round  67, Global train loss: 0.991, Global test loss: 0.950, Global test accuracy: 95.80
Round  68, Train loss: 1.037, Test loss: 0.989, Test accuracy: 91.84
Round  68, Global train loss: 1.037, Global test loss: 0.964, Global test accuracy: 94.54
Round  69, Train loss: 1.077, Test loss: 0.989, Test accuracy: 91.82
Round  69, Global train loss: 1.077, Global test loss: 0.959, Global test accuracy: 94.80
Round  70, Train loss: 1.008, Test loss: 0.989, Test accuracy: 91.82
Round  70, Global train loss: 1.008, Global test loss: 0.962, Global test accuracy: 94.44
Round  71, Train loss: 1.089, Test loss: 0.988, Test accuracy: 91.80
Round  71, Global train loss: 1.089, Global test loss: 0.947, Global test accuracy: 96.06
Round  72, Train loss: 1.167, Test loss: 0.989, Test accuracy: 91.86
Round  72, Global train loss: 1.167, Global test loss: 0.964, Global test accuracy: 94.56
Round  73, Train loss: 1.008, Test loss: 0.988, Test accuracy: 91.86
Round  73, Global train loss: 1.008, Global test loss: 0.949, Global test accuracy: 95.72
Round  74, Train loss: 0.989, Test loss: 0.988, Test accuracy: 91.82
Round  74, Global train loss: 0.989, Global test loss: 0.949, Global test accuracy: 95.76
Round  75, Train loss: 1.028, Test loss: 0.989, Test accuracy: 91.80
Round  75, Global train loss: 1.028, Global test loss: 0.955, Global test accuracy: 95.08
Round  76, Train loss: 1.074, Test loss: 0.989, Test accuracy: 91.72
Round  76, Global train loss: 1.074, Global test loss: 0.951, Global test accuracy: 95.80
Round  77, Train loss: 0.949, Test loss: 0.989, Test accuracy: 91.72
Round  77, Global train loss: 0.949, Global test loss: 0.952, Global test accuracy: 95.54
Round  78, Train loss: 1.029, Test loss: 0.989, Test accuracy: 91.70
Round  78, Global train loss: 1.029, Global test loss: 0.958, Global test accuracy: 94.90
Round  79, Train loss: 1.088, Test loss: 0.989, Test accuracy: 91.68
Round  79, Global train loss: 1.088, Global test loss: 0.946, Global test accuracy: 96.24
Round  80, Train loss: 1.075, Test loss: 0.989, Test accuracy: 91.74
Round  80, Global train loss: 1.075, Global test loss: 0.961, Global test accuracy: 94.64
Round  81, Train loss: 0.951, Test loss: 0.989, Test accuracy: 91.72
Round  81, Global train loss: 0.951, Global test loss: 0.950, Global test accuracy: 95.66
Round  82, Train loss: 1.105, Test loss: 0.989, Test accuracy: 91.74
Round  82, Global train loss: 1.105, Global test loss: 0.972, Global test accuracy: 93.32
Round  83, Train loss: 0.930, Test loss: 0.989, Test accuracy: 91.72
Round  83, Global train loss: 0.930, Global test loss: 0.952, Global test accuracy: 95.32
Round  84, Train loss: 0.912, Test loss: 0.989, Test accuracy: 91.74
Round  84, Global train loss: 0.912, Global test loss: 0.944, Global test accuracy: 96.42
Round  85, Train loss: 1.006, Test loss: 0.989, Test accuracy: 91.74
Round  85, Global train loss: 1.006, Global test loss: 0.958, Global test accuracy: 94.96
Round  86, Train loss: 1.007, Test loss: 0.989, Test accuracy: 91.72
Round  86, Global train loss: 1.007, Global test loss: 0.948, Global test accuracy: 95.70
Round  87, Train loss: 0.997, Test loss: 0.989, Test accuracy: 91.70
Round  87, Global train loss: 0.997, Global test loss: 0.947, Global test accuracy: 95.76
Round  88, Train loss: 0.933, Test loss: 0.989, Test accuracy: 91.70
Round  88, Global train loss: 0.933, Global test loss: 0.944, Global test accuracy: 96.26
Round  89, Train loss: 1.007, Test loss: 0.989, Test accuracy: 91.70
Round  89, Global train loss: 1.007, Global test loss: 0.948, Global test accuracy: 95.64
Round  90, Train loss: 1.068, Test loss: 0.989, Test accuracy: 91.64
Round  90, Global train loss: 1.068, Global test loss: 0.952, Global test accuracy: 95.72
Round  91, Train loss: 1.067, Test loss: 0.989, Test accuracy: 91.64
Round  91, Global train loss: 1.067, Global test loss: 0.952, Global test accuracy: 95.72
Round  92, Train loss: 1.015, Test loss: 0.989, Test accuracy: 91.66
Round  92, Global train loss: 1.015, Global test loss: 0.966, Global test accuracy: 94.28
Round  93, Train loss: 0.931, Test loss: 0.989, Test accuracy: 91.66
Round  93, Global train loss: 0.931, Global test loss: 0.946, Global test accuracy: 96.12
Round  94, Train loss: 0.988, Test loss: 0.989, Test accuracy: 91.64
Round  94, Global train loss: 0.988, Global test loss: 0.953, Global test accuracy: 95.46/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  95, Train loss: 1.086, Test loss: 0.990, Test accuracy: 91.66
Round  95, Global train loss: 1.086, Global test loss: 0.953, Global test accuracy: 95.26
Round  96, Train loss: 1.086, Test loss: 0.989, Test accuracy: 91.64
Round  96, Global train loss: 1.086, Global test loss: 0.953, Global test accuracy: 95.30
Round  97, Train loss: 1.011, Test loss: 0.989, Test accuracy: 91.70
Round  97, Global train loss: 1.011, Global test loss: 0.944, Global test accuracy: 96.20
Round  98, Train loss: 1.092, Test loss: 0.989, Test accuracy: 91.70
Round  98, Global train loss: 1.092, Global test loss: 0.970, Global test accuracy: 93.56
Round  99, Train loss: 1.018, Test loss: 0.989, Test accuracy: 91.74
Round  99, Global train loss: 1.018, Global test loss: 0.948, Global test accuracy: 95.94
Final Round, Train loss: 1.024, Test loss: 0.989, Test accuracy: 91.62
Final Round, Global train loss: 1.024, Global test loss: 0.948, Global test accuracy: 95.94
Average accuracy final 10 rounds: 91.668 

Average global accuracy final 10 rounds: 95.356 

556.6226232051849
[0.8303074836730957, 1.6606149673461914, 2.3575892448425293, 3.054563522338867, 3.7580294609069824, 4.461495399475098, 5.152374505996704, 5.8432536125183105, 6.531818389892578, 7.220383167266846, 7.906303644180298, 8.59222412109375, 9.28183126449585, 9.97143840789795, 10.665183067321777, 11.358927726745605, 12.048820495605469, 12.738713264465332, 13.424984455108643, 14.111255645751953, 14.79665732383728, 15.482059001922607, 16.166625499725342, 16.851191997528076, 17.518856048583984, 18.186520099639893, 18.84659433364868, 19.50666856765747, 20.151379108428955, 20.79608964920044, 21.45825958251953, 22.120429515838623, 22.785265922546387, 23.45010232925415, 24.110027551651, 24.76995277404785, 25.407819032669067, 26.045685291290283, 26.706162214279175, 27.366639137268066, 28.025644063949585, 28.684648990631104, 29.33340072631836, 29.982152462005615, 30.630122184753418, 31.27809190750122, 31.91450262069702, 32.55091333389282, 33.20108485221863, 33.851256370544434, 34.510210037231445, 35.16916370391846, 35.84433078765869, 36.519497871398926, 37.226877212524414, 37.9342565536499, 38.601786613464355, 39.26931667327881, 39.9821879863739, 40.695059299468994, 41.39469647407532, 42.09433364868164, 42.77796220779419, 43.46159076690674, 44.153087854385376, 44.844584941864014, 45.57972860336304, 46.31487226486206, 46.99998664855957, 47.68510103225708, 48.38759899139404, 49.090096950531006, 49.769819259643555, 50.4495415687561, 51.18920826911926, 51.92887496948242, 52.61409521102905, 53.299315452575684, 54.000728607177734, 54.702141761779785, 55.383716106414795, 56.065290451049805, 56.787596464157104, 57.509902477264404, 58.18944048881531, 58.86897850036621, 59.56673812866211, 60.26449775695801, 60.94490575790405, 61.6253137588501, 62.281031370162964, 62.93674898147583, 63.583725690841675, 64.23070240020752, 64.88491702079773, 65.53913164138794, 66.22534441947937, 66.9115571975708, 67.67577338218689, 68.43998956680298, 69.26066637039185, 70.08134317398071, 70.90591859817505, 71.73049402236938, 72.5121796131134, 73.29386520385742, 74.060138463974, 74.82641172409058, 75.60229015350342, 76.37816858291626, 77.1294584274292, 77.88074827194214, 78.70586490631104, 79.53098154067993, 80.30178999900818, 81.07259845733643, 81.85551500320435, 82.63843154907227, 83.49945902824402, 84.36048650741577, 85.20707654953003, 86.05366659164429, 86.83244395256042, 87.61122131347656, 88.38693284988403, 89.1626443862915, 89.94519233703613, 90.72774028778076, 91.61130952835083, 92.4948787689209, 93.26763916015625, 94.0403995513916, 94.92154383659363, 95.80268812179565, 96.62772059440613, 97.4527530670166, 98.31201481819153, 99.17127656936646, 99.98088264465332, 100.79048871994019, 101.54884052276611, 102.30719232559204, 103.13232970237732, 103.9574670791626, 104.72136735916138, 105.48526763916016, 106.2617597579956, 107.03825187683105, 107.94825100898743, 108.8582501411438, 109.62755751609802, 110.39686489105225, 111.27573847770691, 112.15461206436157, 112.97097659111023, 113.78734111785889, 114.53349995613098, 115.27965879440308, 116.05804634094238, 116.83643388748169, 117.61811590194702, 118.39979791641235, 119.15200901031494, 119.90422010421753, 120.70321226119995, 121.50220441818237, 122.29868841171265, 123.09517240524292, 123.90576577186584, 124.71635913848877, 125.56061935424805, 126.40487957000732, 127.20784258842468, 128.01080560684204, 128.779203414917, 129.54760122299194, 130.38275361061096, 131.21790599822998, 132.07978224754333, 132.9416584968567, 133.74640917778015, 134.5511598587036, 135.4244167804718, 136.29767370224, 137.09767699241638, 137.89768028259277, 138.75766134262085, 139.61764240264893, 140.37438249588013, 141.13112258911133, 141.92968583106995, 142.72824907302856, 143.59797954559326, 144.46771001815796, 145.24528074264526, 146.02285146713257, 146.79656744003296, 147.57028341293335, 148.33946084976196, 149.10863828659058, 150.84834027290344, 152.5880422592163]
[58.74, 58.74, 72.38, 72.38, 80.44, 80.44, 83.5, 83.5, 85.5, 85.5, 86.7, 86.7, 86.16, 86.16, 88.46, 88.46, 88.5, 88.5, 88.36, 88.36, 92.02, 92.02, 93.86, 93.86, 93.76, 93.76, 93.34, 93.34, 93.28, 93.28, 93.48, 93.48, 93.7, 93.7, 93.38, 93.38, 93.46, 93.46, 93.56, 93.56, 93.36, 93.36, 93.24, 93.24, 93.3, 93.3, 93.22, 93.22, 93.12, 93.12, 93.04, 93.04, 93.06, 93.06, 92.98, 92.98, 92.9, 92.9, 92.92, 92.92, 92.8, 92.8, 92.68, 92.68, 92.72, 92.72, 92.72, 92.72, 92.68, 92.68, 92.64, 92.64, 92.64, 92.64, 92.66, 92.66, 92.66, 92.66, 92.68, 92.68, 92.68, 92.68, 92.68, 92.68, 92.48, 92.48, 92.56, 92.56, 92.52, 92.52, 92.52, 92.52, 92.46, 92.46, 92.44, 92.44, 92.32, 92.32, 92.16, 92.16, 92.12, 92.12, 92.14, 92.14, 92.16, 92.16, 92.14, 92.14, 92.1, 92.1, 92.12, 92.12, 92.04, 92.04, 92.06, 92.06, 91.98, 91.98, 91.9, 91.9, 91.9, 91.9, 91.88, 91.88, 91.9, 91.9, 91.88, 91.88, 91.88, 91.88, 91.92, 91.92, 91.88, 91.88, 91.8, 91.8, 91.84, 91.84, 91.82, 91.82, 91.82, 91.82, 91.8, 91.8, 91.86, 91.86, 91.86, 91.86, 91.82, 91.82, 91.8, 91.8, 91.72, 91.72, 91.72, 91.72, 91.7, 91.7, 91.68, 91.68, 91.74, 91.74, 91.72, 91.72, 91.74, 91.74, 91.72, 91.72, 91.74, 91.74, 91.74, 91.74, 91.72, 91.72, 91.7, 91.7, 91.7, 91.7, 91.7, 91.7, 91.64, 91.64, 91.64, 91.64, 91.66, 91.66, 91.66, 91.66, 91.64, 91.64, 91.66, 91.66, 91.64, 91.64, 91.7, 91.7, 91.7, 91.7, 91.74, 91.74, 91.62, 91.62]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.4 , level_n_lowerb:0.4  

   Client 9, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.596, Test loss: 1.571, Test accuracy: 58.64
Round   0, Global train loss: 1.596, Global test loss: 1.572, Global test accuracy: 58.96
Round   1, Train loss: 1.448, Test loss: 1.329, Test accuracy: 75.22
Round   1, Global train loss: 1.448, Global test loss: 1.225, Global test accuracy: 86.54
Round   2, Train loss: 1.124, Test loss: 1.176, Test accuracy: 82.64
Round   2, Global train loss: 1.124, Global test loss: 0.989, Global test accuracy: 94.66
Round   3, Train loss: 1.086, Test loss: 1.111, Test accuracy: 86.88
Round   3, Global train loss: 1.086, Global test loss: 0.965, Global test accuracy: 95.30
Round   4, Train loss: 1.068, Test loss: 1.035, Test accuracy: 90.92
Round   4, Global train loss: 1.068, Global test loss: 0.956, Global test accuracy: 96.08
Round   5, Train loss: 1.164, Test loss: 1.025, Test accuracy: 91.32
Round   5, Global train loss: 1.164, Global test loss: 0.954, Global test accuracy: 95.74
Round   6, Train loss: 1.047, Test loss: 0.956, Test accuracy: 95.72
Round   6, Global train loss: 1.047, Global test loss: 0.948, Global test accuracy: 96.40
Round   7, Train loss: 1.034, Test loss: 0.955, Test accuracy: 95.76
Round   7, Global train loss: 1.034, Global test loss: 0.945, Global test accuracy: 96.38
Round   8, Train loss: 1.053, Test loss: 0.949, Test accuracy: 96.26
Round   8, Global train loss: 1.053, Global test loss: 0.942, Global test accuracy: 96.82
Round   9, Train loss: 1.050, Test loss: 0.950, Test accuracy: 96.08
Round   9, Global train loss: 1.050, Global test loss: 0.942, Global test accuracy: 96.92
Round  10, Train loss: 1.022, Test loss: 0.948, Test accuracy: 96.22
Round  10, Global train loss: 1.022, Global test loss: 0.938, Global test accuracy: 97.02
Round  11, Train loss: 1.147, Test loss: 0.947, Test accuracy: 96.20
Round  11, Global train loss: 1.147, Global test loss: 0.942, Global test accuracy: 96.58
Round  12, Train loss: 1.022, Test loss: 0.946, Test accuracy: 96.18
Round  12, Global train loss: 1.022, Global test loss: 0.939, Global test accuracy: 96.84
Round  13, Train loss: 0.922, Test loss: 0.946, Test accuracy: 96.24
Round  13, Global train loss: 0.922, Global test loss: 0.938, Global test accuracy: 96.98
Round  14, Train loss: 1.029, Test loss: 0.948, Test accuracy: 95.98
Round  14, Global train loss: 1.029, Global test loss: 0.942, Global test accuracy: 96.50
Round  15, Train loss: 1.019, Test loss: 0.948, Test accuracy: 95.98
Round  15, Global train loss: 1.019, Global test loss: 0.940, Global test accuracy: 96.76
Round  16, Train loss: 0.926, Test loss: 0.946, Test accuracy: 96.16
Round  16, Global train loss: 0.926, Global test loss: 0.938, Global test accuracy: 96.92
Round  17, Train loss: 0.925, Test loss: 0.946, Test accuracy: 96.24
Round  17, Global train loss: 0.925, Global test loss: 0.937, Global test accuracy: 96.90
Round  18, Train loss: 1.141, Test loss: 0.945, Test accuracy: 96.18
Round  18, Global train loss: 1.141, Global test loss: 0.938, Global test accuracy: 97.12
Round  19, Train loss: 1.025, Test loss: 0.944, Test accuracy: 96.36
Round  19, Global train loss: 1.025, Global test loss: 0.939, Global test accuracy: 96.70
Round  20, Train loss: 1.017, Test loss: 0.943, Test accuracy: 96.38
Round  20, Global train loss: 1.017, Global test loss: 0.937, Global test accuracy: 97.06
Round  21, Train loss: 1.020, Test loss: 0.943, Test accuracy: 96.42
Round  21, Global train loss: 1.020, Global test loss: 0.938, Global test accuracy: 97.02
Round  22, Train loss: 1.023, Test loss: 0.943, Test accuracy: 96.48
Round  22, Global train loss: 1.023, Global test loss: 0.938, Global test accuracy: 96.80
Round  23, Train loss: 1.136, Test loss: 0.943, Test accuracy: 96.52
Round  23, Global train loss: 1.136, Global test loss: 0.941, Global test accuracy: 96.36
Round  24, Train loss: 1.122, Test loss: 0.943, Test accuracy: 96.40
Round  24, Global train loss: 1.122, Global test loss: 0.939, Global test accuracy: 96.66
Round  25, Train loss: 1.030, Test loss: 0.942, Test accuracy: 96.50
Round  25, Global train loss: 1.030, Global test loss: 0.940, Global test accuracy: 96.56
Round  26, Train loss: 1.018, Test loss: 0.941, Test accuracy: 96.62
Round  26, Global train loss: 1.018, Global test loss: 0.937, Global test accuracy: 96.82
Round  27, Train loss: 0.919, Test loss: 0.941, Test accuracy: 96.56
Round  27, Global train loss: 0.919, Global test loss: 0.936, Global test accuracy: 97.02
Round  28, Train loss: 1.017, Test loss: 0.941, Test accuracy: 96.48
Round  28, Global train loss: 1.017, Global test loss: 0.936, Global test accuracy: 97.08
Round  29, Train loss: 1.012, Test loss: 0.941, Test accuracy: 96.44
Round  29, Global train loss: 1.012, Global test loss: 0.936, Global test accuracy: 97.22
Round  30, Train loss: 1.143, Test loss: 0.942, Test accuracy: 96.34
Round  30, Global train loss: 1.143, Global test loss: 0.945, Global test accuracy: 95.94
Round  31, Train loss: 1.015, Test loss: 0.942, Test accuracy: 96.32
Round  31, Global train loss: 1.015, Global test loss: 0.937, Global test accuracy: 96.78
Round  32, Train loss: 0.917, Test loss: 0.942, Test accuracy: 96.34
Round  32, Global train loss: 0.917, Global test loss: 0.935, Global test accuracy: 97.12
Round  33, Train loss: 1.011, Test loss: 0.942, Test accuracy: 96.34
Round  33, Global train loss: 1.011, Global test loss: 0.936, Global test accuracy: 97.02
Round  34, Train loss: 1.019, Test loss: 0.941, Test accuracy: 96.44
Round  34, Global train loss: 1.019, Global test loss: 0.937, Global test accuracy: 96.90
Round  35, Train loss: 1.013, Test loss: 0.941, Test accuracy: 96.48
Round  35, Global train loss: 1.013, Global test loss: 0.936, Global test accuracy: 97.10
Round  36, Train loss: 1.022, Test loss: 0.942, Test accuracy: 96.48
Round  36, Global train loss: 1.022, Global test loss: 0.940, Global test accuracy: 96.46
Round  37, Train loss: 0.918, Test loss: 0.942, Test accuracy: 96.46
Round  37, Global train loss: 0.918, Global test loss: 0.937, Global test accuracy: 96.88
Round  38, Train loss: 1.014, Test loss: 0.942, Test accuracy: 96.44
Round  38, Global train loss: 1.014, Global test loss: 0.938, Global test accuracy: 96.92
Round  39, Train loss: 0.915, Test loss: 0.943, Test accuracy: 96.36
Round  39, Global train loss: 0.915, Global test loss: 0.935, Global test accuracy: 97.24
Round  40, Train loss: 1.015, Test loss: 0.943, Test accuracy: 96.40
Round  40, Global train loss: 1.015, Global test loss: 0.936, Global test accuracy: 97.08
Round  41, Train loss: 0.917, Test loss: 0.942, Test accuracy: 96.46
Round  41, Global train loss: 0.917, Global test loss: 0.936, Global test accuracy: 96.94
Round  42, Train loss: 1.024, Test loss: 0.942, Test accuracy: 96.48
Round  42, Global train loss: 1.024, Global test loss: 0.940, Global test accuracy: 96.46
Round  43, Train loss: 1.142, Test loss: 0.942, Test accuracy: 96.40
Round  43, Global train loss: 1.142, Global test loss: 0.947, Global test accuracy: 95.70
Round  44, Train loss: 1.015, Test loss: 0.943, Test accuracy: 96.30
Round  44, Global train loss: 1.015, Global test loss: 0.936, Global test accuracy: 97.12
Round  45, Train loss: 1.111, Test loss: 0.942, Test accuracy: 96.38
Round  45, Global train loss: 1.111, Global test loss: 0.938, Global test accuracy: 96.82
Round  46, Train loss: 1.023, Test loss: 0.943, Test accuracy: 96.38
Round  46, Global train loss: 1.023, Global test loss: 0.941, Global test accuracy: 96.48
Round  47, Train loss: 0.915, Test loss: 0.942, Test accuracy: 96.38
Round  47, Global train loss: 0.915, Global test loss: 0.937, Global test accuracy: 96.76
Round  48, Train loss: 1.134, Test loss: 0.942, Test accuracy: 96.36
Round  48, Global train loss: 1.134, Global test loss: 0.942, Global test accuracy: 96.42
Round  49, Train loss: 1.021, Test loss: 0.943, Test accuracy: 96.28
Round  49, Global train loss: 1.021, Global test loss: 0.940, Global test accuracy: 96.46
Round  50, Train loss: 1.020, Test loss: 0.943, Test accuracy: 96.30
Round  50, Global train loss: 1.020, Global test loss: 0.940, Global test accuracy: 96.38
Round  51, Train loss: 1.131, Test loss: 0.943, Test accuracy: 96.30
Round  51, Global train loss: 1.131, Global test loss: 0.940, Global test accuracy: 96.68
Round  52, Train loss: 1.012, Test loss: 0.943, Test accuracy: 96.26
Round  52, Global train loss: 1.012, Global test loss: 0.937, Global test accuracy: 96.72
Round  53, Train loss: 1.127, Test loss: 0.942, Test accuracy: 96.28
Round  53, Global train loss: 1.127, Global test loss: 0.939, Global test accuracy: 96.66
Round  54, Train loss: 1.019, Test loss: 0.942, Test accuracy: 96.30
Round  54, Global train loss: 1.019, Global test loss: 0.938, Global test accuracy: 96.66
Round  55, Train loss: 1.008, Test loss: 0.942, Test accuracy: 96.28
Round  55, Global train loss: 1.008, Global test loss: 0.937, Global test accuracy: 97.02
Round  56, Train loss: 1.126, Test loss: 0.942, Test accuracy: 96.24
Round  56, Global train loss: 1.126, Global test loss: 0.941, Global test accuracy: 96.60
Round  57, Train loss: 1.011, Test loss: 0.943, Test accuracy: 96.28
Round  57, Global train loss: 1.011, Global test loss: 0.938, Global test accuracy: 96.76
Round  58, Train loss: 1.020, Test loss: 0.944, Test accuracy: 96.10
Round  58, Global train loss: 1.020, Global test loss: 0.942, Global test accuracy: 96.60
Round  59, Train loss: 1.231, Test loss: 0.943, Test accuracy: 96.24
Round  59, Global train loss: 1.231, Global test loss: 0.945, Global test accuracy: 96.16
Round  60, Train loss: 1.015, Test loss: 0.943, Test accuracy: 96.24
Round  60, Global train loss: 1.015, Global test loss: 0.938, Global test accuracy: 96.64
Round  61, Train loss: 1.029, Test loss: 0.943, Test accuracy: 96.36
Round  61, Global train loss: 1.029, Global test loss: 0.939, Global test accuracy: 96.62
Round  62, Train loss: 1.113, Test loss: 0.943, Test accuracy: 96.22
Round  62, Global train loss: 1.113, Global test loss: 0.940, Global test accuracy: 96.64
Round  63, Train loss: 0.913, Test loss: 0.943, Test accuracy: 96.22
Round  63, Global train loss: 0.913, Global test loss: 0.937, Global test accuracy: 97.02
Round  64, Train loss: 1.012, Test loss: 0.943, Test accuracy: 96.24
Round  64, Global train loss: 1.012, Global test loss: 0.937, Global test accuracy: 96.82
Round  65, Train loss: 1.008, Test loss: 0.943, Test accuracy: 96.26
Round  65, Global train loss: 1.008, Global test loss: 0.938, Global test accuracy: 96.80
Round  66, Train loss: 1.013, Test loss: 0.943, Test accuracy: 96.30
Round  66, Global train loss: 1.013, Global test loss: 0.937, Global test accuracy: 96.92
Round  67, Train loss: 1.125, Test loss: 0.943, Test accuracy: 96.36
Round  67, Global train loss: 1.125, Global test loss: 0.941, Global test accuracy: 96.66
Round  68, Train loss: 0.913, Test loss: 0.943, Test accuracy: 96.36
Round  68, Global train loss: 0.913, Global test loss: 0.936, Global test accuracy: 97.06
Round  69, Train loss: 1.029, Test loss: 0.942, Test accuracy: 96.36
Round  69, Global train loss: 1.029, Global test loss: 0.939, Global test accuracy: 96.66
Round  70, Train loss: 1.029, Test loss: 0.943, Test accuracy: 96.36
Round  70, Global train loss: 1.029, Global test loss: 0.939, Global test accuracy: 96.82
Round  71, Train loss: 1.118, Test loss: 0.943, Test accuracy: 96.28
Round  71, Global train loss: 1.118, Global test loss: 0.941, Global test accuracy: 96.50
Round  72, Train loss: 1.235, Test loss: 0.943, Test accuracy: 96.28
Round  72, Global train loss: 1.235, Global test loss: 0.948, Global test accuracy: 95.94
Round  73, Train loss: 1.111, Test loss: 0.944, Test accuracy: 96.20
Round  73, Global train loss: 1.111, Global test loss: 0.941, Global test accuracy: 96.54
Round  74, Train loss: 1.124, Test loss: 0.943, Test accuracy: 96.22
Round  74, Global train loss: 1.124, Global test loss: 0.943, Global test accuracy: 96.40
Round  75, Train loss: 1.017, Test loss: 0.943, Test accuracy: 96.26
Round  75, Global train loss: 1.017, Global test loss: 0.940, Global test accuracy: 96.58
Round  76, Train loss: 1.105, Test loss: 0.944, Test accuracy: 96.24
Round  76, Global train loss: 1.105, Global test loss: 0.940, Global test accuracy: 96.64
Round  77, Train loss: 1.006, Test loss: 0.943, Test accuracy: 96.28
Round  77, Global train loss: 1.006, Global test loss: 0.938, Global test accuracy: 96.78
Round  78, Train loss: 1.031, Test loss: 0.943, Test accuracy: 96.18
Round  78, Global train loss: 1.031, Global test loss: 0.942, Global test accuracy: 96.40
Round  79, Train loss: 1.117, Test loss: 0.945, Test accuracy: 95.98
Round  79, Global train loss: 1.117, Global test loss: 0.943, Global test accuracy: 96.22
Round  80, Train loss: 1.028, Test loss: 0.945, Test accuracy: 95.94
Round  80, Global train loss: 1.028, Global test loss: 0.940, Global test accuracy: 96.44
Round  81, Train loss: 0.914, Test loss: 0.945, Test accuracy: 95.94
Round  81, Global train loss: 0.914, Global test loss: 0.936, Global test accuracy: 97.04
Round  82, Train loss: 1.132, Test loss: 0.945, Test accuracy: 95.98
Round  82, Global train loss: 1.132, Global test loss: 0.948, Global test accuracy: 95.80
Round  83, Train loss: 0.912, Test loss: 0.945, Test accuracy: 95.96
Round  83, Global train loss: 0.912, Global test loss: 0.936, Global test accuracy: 97.14
Round  84, Train loss: 0.912, Test loss: 0.945, Test accuracy: 95.98
Round  84, Global train loss: 0.912, Global test loss: 0.936, Global test accuracy: 96.92
Round  85, Train loss: 1.121, Test loss: 0.945, Test accuracy: 96.00
Round  85, Global train loss: 1.121, Global test loss: 0.941, Global test accuracy: 96.50
Round  86, Train loss: 1.107, Test loss: 0.945, Test accuracy: 96.10
Round  86, Global train loss: 1.107, Global test loss: 0.943, Global test accuracy: 96.24
Round  87, Train loss: 0.912, Test loss: 0.945, Test accuracy: 96.00
Round  87, Global train loss: 0.912, Global test loss: 0.937, Global test accuracy: 96.90
Round  88, Train loss: 0.914, Test loss: 0.945, Test accuracy: 96.02
Round  88, Global train loss: 0.914, Global test loss: 0.937, Global test accuracy: 96.84
Round  89, Train loss: 1.107, Test loss: 0.945, Test accuracy: 96.00
Round  89, Global train loss: 1.107, Global test loss: 0.942, Global test accuracy: 96.30
Round  90, Train loss: 1.127, Test loss: 0.945, Test accuracy: 95.98
Round  90, Global train loss: 1.127, Global test loss: 0.942, Global test accuracy: 96.26
Round  91, Train loss: 1.127, Test loss: 0.946, Test accuracy: 95.96
Round  91, Global train loss: 1.127, Global test loss: 0.943, Global test accuracy: 96.26
Round  92, Train loss: 0.911, Test loss: 0.946, Test accuracy: 95.98
Round  92, Global train loss: 0.911, Global test loss: 0.936, Global test accuracy: 97.08
Round  93, Train loss: 1.006, Test loss: 0.945, Test accuracy: 96.04
Round  93, Global train loss: 1.006, Global test loss: 0.938, Global test accuracy: 96.76
Round  94, Train loss: 1.120, Test loss: 0.945, Test accuracy: 96.08
Round  94, Global train loss: 1.120, Global test loss: 0.941, Global test accuracy: 96.50/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  95, Train loss: 1.129, Test loss: 0.945, Test accuracy: 96.02
Round  95, Global train loss: 1.129, Global test loss: 0.953, Global test accuracy: 95.32
Round  96, Train loss: 1.128, Test loss: 0.945, Test accuracy: 96.02
Round  96, Global train loss: 1.128, Global test loss: 0.951, Global test accuracy: 95.46
Round  97, Train loss: 1.013, Test loss: 0.945, Test accuracy: 96.00
Round  97, Global train loss: 1.013, Global test loss: 0.939, Global test accuracy: 96.50
Round  98, Train loss: 1.011, Test loss: 0.945, Test accuracy: 96.04
Round  98, Global train loss: 1.011, Global test loss: 0.937, Global test accuracy: 97.08
Round  99, Train loss: 0.913, Test loss: 0.945, Test accuracy: 96.10
Round  99, Global train loss: 0.913, Global test loss: 0.936, Global test accuracy: 97.02
Final Round, Train loss: 1.034, Test loss: 0.944, Test accuracy: 96.14
Final Round, Global train loss: 1.034, Global test loss: 0.936, Global test accuracy: 97.02
Average accuracy final 10 rounds: 96.022 

Average global accuracy final 10 rounds: 96.424 

596.8776979446411
[0.8766992092132568, 1.7533984184265137, 2.526571035385132, 3.29974365234375, 4.070552110671997, 4.841360569000244, 5.597597599029541, 6.353834629058838, 7.1178765296936035, 7.881918430328369, 8.655815124511719, 9.429711818695068, 10.214066505432129, 10.99842119216919, 11.78768539428711, 12.57694959640503, 13.345874547958374, 14.114799499511719, 14.90670108795166, 15.698602676391602, 16.453652381896973, 17.208702087402344, 17.972874879837036, 18.73704767227173, 19.688624620437622, 20.640201568603516, 21.400304555892944, 22.160407543182373, 22.966262102127075, 23.772116661071777, 24.56343650817871, 25.354756355285645, 26.12004065513611, 26.885324954986572, 27.651625156402588, 28.417925357818604, 29.208190202713013, 29.998455047607422, 30.787484407424927, 31.57651376724243, 32.33827757835388, 33.10004138946533, 33.85224151611328, 34.60444164276123, 35.39061737060547, 36.17679309844971, 36.96690487861633, 37.75701665878296, 38.53186845779419, 39.30672025680542, 40.06229496002197, 40.817869663238525, 41.615909576416016, 42.413949489593506, 43.1566379070282, 43.89932632446289, 44.66487169265747, 45.43041706085205, 46.1858332157135, 46.94124937057495, 47.72133827209473, 48.5014271736145, 49.275057792663574, 50.04868841171265, 50.78898572921753, 51.52928304672241, 52.276864528656006, 53.0244460105896, 53.84876227378845, 54.673078536987305, 55.43398666381836, 56.194894790649414, 56.92557072639465, 57.65624666213989, 58.39539074897766, 59.13453483581543, 59.884058713912964, 60.6335825920105, 61.39282250404358, 62.15206241607666, 62.91276526451111, 63.67346811294556, 64.43545746803284, 65.19744682312012, 65.97744870185852, 66.75745058059692, 67.56808948516846, 68.37872838973999, 69.17508840560913, 69.97144842147827, 70.7245569229126, 71.47766542434692, 72.24106216430664, 73.00445890426636, 73.78333401679993, 74.5622091293335, 75.35184049606323, 76.14147186279297, 76.91961288452148, 77.69775390625, 78.46697497367859, 79.23619604110718, 80.02246522903442, 80.80873441696167, 81.5916268825531, 82.37451934814453, 83.12470769882202, 83.87489604949951, 84.63573956489563, 85.39658308029175, 86.24395728111267, 87.0913314819336, 87.83606147766113, 88.58079147338867, 89.33588194847107, 90.09097242355347, 90.86641883850098, 91.64186525344849, 92.40040993690491, 93.15895462036133, 93.9525203704834, 94.74608612060547, 95.51336884498596, 96.28065156936646, 97.06688117980957, 97.85311079025269, 98.61977744102478, 99.38644409179688, 100.13830256462097, 100.89016103744507, 101.67171859741211, 102.45327615737915, 103.23695659637451, 104.02063703536987, 104.78564548492432, 105.55065393447876, 106.32086563110352, 107.09107732772827, 107.86188793182373, 108.63269853591919, 109.39407348632812, 110.15544843673706, 110.90396356582642, 111.65247869491577, 112.41369676589966, 113.17491483688354, 113.96312212944031, 114.75132942199707, 115.521484375, 116.29163932800293, 117.04459166526794, 117.79754400253296, 118.55610704421997, 119.31467008590698, 120.07676553726196, 120.83886098861694, 121.6182644367218, 122.39766788482666, 123.18504786491394, 123.97242784500122, 124.71082973480225, 125.44923162460327, 126.25342607498169, 127.05762052536011, 127.83763837814331, 128.6176562309265, 129.47224187850952, 130.32682752609253, 131.10062503814697, 131.87442255020142, 132.6361267566681, 133.39783096313477, 134.18819522857666, 134.97855949401855, 135.73350882530212, 136.4884581565857, 137.2602882385254, 138.0321183204651, 138.84233355522156, 139.65254878997803, 140.41378259658813, 141.17501640319824, 141.94471287727356, 142.71440935134888, 143.48152923583984, 144.2486491203308, 145.0264630317688, 145.8042769432068, 146.57634925842285, 147.34842157363892, 148.13243222236633, 148.91644287109375, 149.67749738693237, 150.438551902771, 151.2092034816742, 151.9798550605774, 152.75727772712708, 153.53470039367676, 154.33079195022583, 155.1268835067749, 156.69620299339294, 158.265522480011]
[58.64, 58.64, 75.22, 75.22, 82.64, 82.64, 86.88, 86.88, 90.92, 90.92, 91.32, 91.32, 95.72, 95.72, 95.76, 95.76, 96.26, 96.26, 96.08, 96.08, 96.22, 96.22, 96.2, 96.2, 96.18, 96.18, 96.24, 96.24, 95.98, 95.98, 95.98, 95.98, 96.16, 96.16, 96.24, 96.24, 96.18, 96.18, 96.36, 96.36, 96.38, 96.38, 96.42, 96.42, 96.48, 96.48, 96.52, 96.52, 96.4, 96.4, 96.5, 96.5, 96.62, 96.62, 96.56, 96.56, 96.48, 96.48, 96.44, 96.44, 96.34, 96.34, 96.32, 96.32, 96.34, 96.34, 96.34, 96.34, 96.44, 96.44, 96.48, 96.48, 96.48, 96.48, 96.46, 96.46, 96.44, 96.44, 96.36, 96.36, 96.4, 96.4, 96.46, 96.46, 96.48, 96.48, 96.4, 96.4, 96.3, 96.3, 96.38, 96.38, 96.38, 96.38, 96.38, 96.38, 96.36, 96.36, 96.28, 96.28, 96.3, 96.3, 96.3, 96.3, 96.26, 96.26, 96.28, 96.28, 96.3, 96.3, 96.28, 96.28, 96.24, 96.24, 96.28, 96.28, 96.1, 96.1, 96.24, 96.24, 96.24, 96.24, 96.36, 96.36, 96.22, 96.22, 96.22, 96.22, 96.24, 96.24, 96.26, 96.26, 96.3, 96.3, 96.36, 96.36, 96.36, 96.36, 96.36, 96.36, 96.36, 96.36, 96.28, 96.28, 96.28, 96.28, 96.2, 96.2, 96.22, 96.22, 96.26, 96.26, 96.24, 96.24, 96.28, 96.28, 96.18, 96.18, 95.98, 95.98, 95.94, 95.94, 95.94, 95.94, 95.98, 95.98, 95.96, 95.96, 95.98, 95.98, 96.0, 96.0, 96.1, 96.1, 96.0, 96.0, 96.02, 96.02, 96.0, 96.0, 95.98, 95.98, 95.96, 95.96, 95.98, 95.98, 96.04, 96.04, 96.08, 96.08, 96.02, 96.02, 96.02, 96.02, 96.0, 96.0, 96.04, 96.04, 96.1, 96.1, 96.14, 96.14]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.4 , level_n_lowerb:0.4  

   Client 2, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
prox
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.603, Test loss: 1.593, Test accuracy: 68.36
Round   0, Global train loss: 1.603, Global test loss: 1.593, Global test accuracy: 72.30
Round   1, Train loss: 1.545, Test loss: 1.487, Test accuracy: 59.52
Round   1, Global train loss: 1.545, Global test loss: 1.446, Global test accuracy: 60.98
Round   2, Train loss: 1.242, Test loss: 1.309, Test accuracy: 70.42
Round   2, Global train loss: 1.242, Global test loss: 1.120, Global test accuracy: 84.58
Round   3, Train loss: 1.142, Test loss: 1.185, Test accuracy: 80.64
Round   3, Global train loss: 1.142, Global test loss: 1.005, Global test accuracy: 94.56
Round   4, Train loss: 1.106, Test loss: 1.079, Test accuracy: 88.48
Round   4, Global train loss: 1.106, Global test loss: 0.973, Global test accuracy: 95.74
Round   5, Train loss: 1.079, Test loss: 1.050, Test accuracy: 90.22
Round   5, Global train loss: 1.079, Global test loss: 0.962, Global test accuracy: 96.12
Round   6, Train loss: 1.177, Test loss: 0.969, Test accuracy: 95.48
Round   6, Global train loss: 1.177, Global test loss: 0.956, Global test accuracy: 95.84
Round   7, Train loss: 1.051, Test loss: 0.964, Test accuracy: 95.60
Round   7, Global train loss: 1.051, Global test loss: 0.950, Global test accuracy: 96.58
Round   8, Train loss: 0.963, Test loss: 0.958, Test accuracy: 95.86
Round   8, Global train loss: 0.963, Global test loss: 0.945, Global test accuracy: 96.76
Round   9, Train loss: 0.957, Test loss: 0.958, Test accuracy: 95.90
Round   9, Global train loss: 0.957, Global test loss: 0.943, Global test accuracy: 96.90
Round  10, Train loss: 1.041, Test loss: 0.950, Test accuracy: 96.24
Round  10, Global train loss: 1.041, Global test loss: 0.941, Global test accuracy: 96.82
Round  11, Train loss: 1.042, Test loss: 0.948, Test accuracy: 96.38
Round  11, Global train loss: 1.042, Global test loss: 0.940, Global test accuracy: 97.08
Round  12, Train loss: 1.138, Test loss: 0.948, Test accuracy: 96.34
Round  12, Global train loss: 1.138, Global test loss: 0.940, Global test accuracy: 96.96
Round  13, Train loss: 1.058, Test loss: 0.948, Test accuracy: 96.34
Round  13, Global train loss: 1.058, Global test loss: 0.941, Global test accuracy: 96.78
Round  14, Train loss: 1.031, Test loss: 0.947, Test accuracy: 96.40
Round  14, Global train loss: 1.031, Global test loss: 0.939, Global test accuracy: 96.92
Round  15, Train loss: 1.249, Test loss: 0.947, Test accuracy: 96.42
Round  15, Global train loss: 1.249, Global test loss: 0.940, Global test accuracy: 96.72
Round  16, Train loss: 1.262, Test loss: 0.942, Test accuracy: 96.82
Round  16, Global train loss: 1.262, Global test loss: 0.940, Global test accuracy: 96.80
Round  17, Train loss: 1.154, Test loss: 0.943, Test accuracy: 96.78
Round  17, Global train loss: 1.154, Global test loss: 0.942, Global test accuracy: 96.70
Round  18, Train loss: 0.950, Test loss: 0.944, Test accuracy: 96.62
Round  18, Global train loss: 0.950, Global test loss: 0.940, Global test accuracy: 96.90
Round  19, Train loss: 1.033, Test loss: 0.943, Test accuracy: 96.56
Round  19, Global train loss: 1.033, Global test loss: 0.939, Global test accuracy: 96.88
Round  20, Train loss: 1.243, Test loss: 0.944, Test accuracy: 96.42
Round  20, Global train loss: 1.243, Global test loss: 0.941, Global test accuracy: 96.66
Round  21, Train loss: 1.159, Test loss: 0.944, Test accuracy: 96.42
Round  21, Global train loss: 1.159, Global test loss: 0.941, Global test accuracy: 96.50
Round  22, Train loss: 1.254, Test loss: 0.943, Test accuracy: 96.52
Round  22, Global train loss: 1.254, Global test loss: 0.942, Global test accuracy: 96.58
Round  23, Train loss: 1.028, Test loss: 0.943, Test accuracy: 96.50
Round  23, Global train loss: 1.028, Global test loss: 0.939, Global test accuracy: 96.80
Round  24, Train loss: 1.148, Test loss: 0.943, Test accuracy: 96.46
Round  24, Global train loss: 1.148, Global test loss: 0.940, Global test accuracy: 96.80
Round  25, Train loss: 1.038, Test loss: 0.943, Test accuracy: 96.54
Round  25, Global train loss: 1.038, Global test loss: 0.939, Global test accuracy: 96.86
Round  26, Train loss: 1.047, Test loss: 0.943, Test accuracy: 96.52
Round  26, Global train loss: 1.047, Global test loss: 0.938, Global test accuracy: 97.14
Round  27, Train loss: 1.140, Test loss: 0.942, Test accuracy: 96.54
Round  27, Global train loss: 1.140, Global test loss: 0.940, Global test accuracy: 96.82
Round  28, Train loss: 1.045, Test loss: 0.942, Test accuracy: 96.56
Round  28, Global train loss: 1.045, Global test loss: 0.939, Global test accuracy: 97.00
Round  29, Train loss: 1.022, Test loss: 0.943, Test accuracy: 96.38
Round  29, Global train loss: 1.022, Global test loss: 0.940, Global test accuracy: 96.74
Round  30, Train loss: 0.921, Test loss: 0.943, Test accuracy: 96.38
Round  30, Global train loss: 0.921, Global test loss: 0.936, Global test accuracy: 97.18
Round  31, Train loss: 1.025, Test loss: 0.942, Test accuracy: 96.44
Round  31, Global train loss: 1.025, Global test loss: 0.937, Global test accuracy: 97.00
Round  32, Train loss: 0.937, Test loss: 0.942, Test accuracy: 96.52
Round  32, Global train loss: 0.937, Global test loss: 0.937, Global test accuracy: 97.02
Round  33, Train loss: 1.021, Test loss: 0.941, Test accuracy: 96.56
Round  33, Global train loss: 1.021, Global test loss: 0.937, Global test accuracy: 96.92
Round  34, Train loss: 1.056, Test loss: 0.941, Test accuracy: 96.58
Round  34, Global train loss: 1.056, Global test loss: 0.937, Global test accuracy: 97.02
Round  35, Train loss: 0.939, Test loss: 0.941, Test accuracy: 96.56
Round  35, Global train loss: 0.939, Global test loss: 0.936, Global test accuracy: 96.98
Round  36, Train loss: 1.026, Test loss: 0.941, Test accuracy: 96.52
Round  36, Global train loss: 1.026, Global test loss: 0.936, Global test accuracy: 97.02
Round  37, Train loss: 1.245, Test loss: 0.941, Test accuracy: 96.48
Round  37, Global train loss: 1.245, Global test loss: 0.946, Global test accuracy: 95.94
Round  38, Train loss: 1.033, Test loss: 0.942, Test accuracy: 96.46
Round  38, Global train loss: 1.033, Global test loss: 0.938, Global test accuracy: 96.84
Round  39, Train loss: 0.936, Test loss: 0.942, Test accuracy: 96.48
Round  39, Global train loss: 0.936, Global test loss: 0.937, Global test accuracy: 97.02
Round  40, Train loss: 1.044, Test loss: 0.942, Test accuracy: 96.46
Round  40, Global train loss: 1.044, Global test loss: 0.937, Global test accuracy: 96.94
Round  41, Train loss: 1.136, Test loss: 0.941, Test accuracy: 96.50
Round  41, Global train loss: 1.136, Global test loss: 0.940, Global test accuracy: 96.54
Round  42, Train loss: 1.035, Test loss: 0.941, Test accuracy: 96.50
Round  42, Global train loss: 1.035, Global test loss: 0.937, Global test accuracy: 97.16
Round  43, Train loss: 1.035, Test loss: 0.941, Test accuracy: 96.48
Round  43, Global train loss: 1.035, Global test loss: 0.936, Global test accuracy: 97.04
Round  44, Train loss: 1.150, Test loss: 0.941, Test accuracy: 96.56
Round  44, Global train loss: 1.150, Global test loss: 0.939, Global test accuracy: 96.70
Round  45, Train loss: 1.046, Test loss: 0.941, Test accuracy: 96.56
Round  45, Global train loss: 1.046, Global test loss: 0.936, Global test accuracy: 97.06
Round  46, Train loss: 1.141, Test loss: 0.941, Test accuracy: 96.60
Round  46, Global train loss: 1.141, Global test loss: 0.938, Global test accuracy: 96.84
Round  47, Train loss: 1.133, Test loss: 0.940, Test accuracy: 96.64
Round  47, Global train loss: 1.133, Global test loss: 0.940, Global test accuracy: 96.62
Round  48, Train loss: 1.140, Test loss: 0.941, Test accuracy: 96.60
Round  48, Global train loss: 1.140, Global test loss: 0.938, Global test accuracy: 96.82
Round  49, Train loss: 1.140, Test loss: 0.941, Test accuracy: 96.58
Round  49, Global train loss: 1.140, Global test loss: 0.939, Global test accuracy: 96.62
Round  50, Train loss: 1.139, Test loss: 0.941, Test accuracy: 96.62
Round  50, Global train loss: 1.139, Global test loss: 0.939, Global test accuracy: 96.62
Round  51, Train loss: 1.046, Test loss: 0.941, Test accuracy: 96.56
Round  51, Global train loss: 1.046, Global test loss: 0.936, Global test accuracy: 97.10
Round  52, Train loss: 1.128, Test loss: 0.941, Test accuracy: 96.56
Round  52, Global train loss: 1.128, Global test loss: 0.937, Global test accuracy: 96.88
Round  53, Train loss: 0.915, Test loss: 0.941, Test accuracy: 96.56
Round  53, Global train loss: 0.915, Global test loss: 0.935, Global test accuracy: 97.38
Round  54, Train loss: 1.044, Test loss: 0.940, Test accuracy: 96.60
Round  54, Global train loss: 1.044, Global test loss: 0.939, Global test accuracy: 96.58
Round  55, Train loss: 1.041, Test loss: 0.940, Test accuracy: 96.54
Round  55, Global train loss: 1.041, Global test loss: 0.940, Global test accuracy: 96.60
Round  56, Train loss: 1.019, Test loss: 0.941, Test accuracy: 96.56
Round  56, Global train loss: 1.019, Global test loss: 0.939, Global test accuracy: 96.60
Round  57, Train loss: 1.125, Test loss: 0.941, Test accuracy: 96.44
Round  57, Global train loss: 1.125, Global test loss: 0.939, Global test accuracy: 96.64
Round  58, Train loss: 1.031, Test loss: 0.941, Test accuracy: 96.40
Round  58, Global train loss: 1.031, Global test loss: 0.937, Global test accuracy: 96.74
Round  59, Train loss: 0.919, Test loss: 0.941, Test accuracy: 96.40
Round  59, Global train loss: 0.919, Global test loss: 0.935, Global test accuracy: 97.12
Round  60, Train loss: 1.139, Test loss: 0.941, Test accuracy: 96.40
Round  60, Global train loss: 1.139, Global test loss: 0.938, Global test accuracy: 96.86
Round  61, Train loss: 1.016, Test loss: 0.940, Test accuracy: 96.52
Round  61, Global train loss: 1.016, Global test loss: 0.938, Global test accuracy: 96.62
Round  62, Train loss: 0.940, Test loss: 0.940, Test accuracy: 96.52
Round  62, Global train loss: 0.940, Global test loss: 0.936, Global test accuracy: 96.98
Round  63, Train loss: 1.154, Test loss: 0.940, Test accuracy: 96.54
Round  63, Global train loss: 1.154, Global test loss: 0.941, Global test accuracy: 96.52
Round  64, Train loss: 1.130, Test loss: 0.940, Test accuracy: 96.54
Round  64, Global train loss: 1.130, Global test loss: 0.939, Global test accuracy: 96.74
Round  65, Train loss: 1.051, Test loss: 0.940, Test accuracy: 96.60
Round  65, Global train loss: 1.051, Global test loss: 0.937, Global test accuracy: 96.78
Round  66, Train loss: 1.136, Test loss: 0.940, Test accuracy: 96.64
Round  66, Global train loss: 1.136, Global test loss: 0.937, Global test accuracy: 96.88
Round  67, Train loss: 0.915, Test loss: 0.940, Test accuracy: 96.62
Round  67, Global train loss: 0.915, Global test loss: 0.935, Global test accuracy: 97.20
Round  68, Train loss: 1.157, Test loss: 0.940, Test accuracy: 96.60
Round  68, Global train loss: 1.157, Global test loss: 0.939, Global test accuracy: 96.64
Round  69, Train loss: 1.019, Test loss: 0.940, Test accuracy: 96.60
Round  69, Global train loss: 1.019, Global test loss: 0.937, Global test accuracy: 96.66
Round  70, Train loss: 0.934, Test loss: 0.940, Test accuracy: 96.58
Round  70, Global train loss: 0.934, Global test loss: 0.937, Global test accuracy: 96.94
Round  71, Train loss: 1.025, Test loss: 0.939, Test accuracy: 96.60
Round  71, Global train loss: 1.025, Global test loss: 0.935, Global test accuracy: 97.24
Round  72, Train loss: 1.026, Test loss: 0.939, Test accuracy: 96.62
Round  72, Global train loss: 1.026, Global test loss: 0.935, Global test accuracy: 97.18
Round  73, Train loss: 0.916, Test loss: 0.939, Test accuracy: 96.66
Round  73, Global train loss: 0.916, Global test loss: 0.934, Global test accuracy: 97.30
Round  74, Train loss: 0.914, Test loss: 0.939, Test accuracy: 96.64
Round  74, Global train loss: 0.914, Global test loss: 0.934, Global test accuracy: 97.14
Round  75, Train loss: 0.938, Test loss: 0.939, Test accuracy: 96.66
Round  75, Global train loss: 0.938, Global test loss: 0.935, Global test accuracy: 97.02
Round  76, Train loss: 1.130, Test loss: 0.939, Test accuracy: 96.66
Round  76, Global train loss: 1.130, Global test loss: 0.936, Global test accuracy: 97.02
Round  77, Train loss: 1.051, Test loss: 0.939, Test accuracy: 96.74
Round  77, Global train loss: 1.051, Global test loss: 0.936, Global test accuracy: 96.86
Round  78, Train loss: 1.051, Test loss: 0.939, Test accuracy: 96.70
Round  78, Global train loss: 1.051, Global test loss: 0.936, Global test accuracy: 96.80
Round  79, Train loss: 1.025, Test loss: 0.939, Test accuracy: 96.70
Round  79, Global train loss: 1.025, Global test loss: 0.935, Global test accuracy: 97.24
Round  80, Train loss: 1.125, Test loss: 0.938, Test accuracy: 96.74
Round  80, Global train loss: 1.125, Global test loss: 0.940, Global test accuracy: 96.46
Round  81, Train loss: 1.049, Test loss: 0.939, Test accuracy: 96.76
Round  81, Global train loss: 1.049, Global test loss: 0.937, Global test accuracy: 96.66
Round  82, Train loss: 0.939, Test loss: 0.938, Test accuracy: 96.76
Round  82, Global train loss: 0.939, Global test loss: 0.936, Global test accuracy: 96.88
Round  83, Train loss: 0.933, Test loss: 0.938, Test accuracy: 96.70
Round  83, Global train loss: 0.933, Global test loss: 0.936, Global test accuracy: 96.82
Round  84, Train loss: 1.014, Test loss: 0.939, Test accuracy: 96.70
Round  84, Global train loss: 1.014, Global test loss: 0.938, Global test accuracy: 96.62
Round  85, Train loss: 0.936, Test loss: 0.939, Test accuracy: 96.68
Round  85, Global train loss: 0.936, Global test loss: 0.936, Global test accuracy: 96.88
Round  86, Train loss: 1.021, Test loss: 0.939, Test accuracy: 96.74
Round  86, Global train loss: 1.021, Global test loss: 0.938, Global test accuracy: 96.58
Round  87, Train loss: 1.018, Test loss: 0.939, Test accuracy: 96.74
Round  87, Global train loss: 1.018, Global test loss: 0.937, Global test accuracy: 96.72
Round  88, Train loss: 1.027, Test loss: 0.939, Test accuracy: 96.72
Round  88, Global train loss: 1.027, Global test loss: 0.936, Global test accuracy: 96.86
Round  89, Train loss: 1.020, Test loss: 0.939, Test accuracy: 96.72
Round  89, Global train loss: 1.020, Global test loss: 0.938, Global test accuracy: 96.66
Round  90, Train loss: 1.021, Test loss: 0.939, Test accuracy: 96.74
Round  90, Global train loss: 1.021, Global test loss: 0.935, Global test accuracy: 96.98
Round  91, Train loss: 1.021, Test loss: 0.939, Test accuracy: 96.74
Round  91, Global train loss: 1.021, Global test loss: 0.935, Global test accuracy: 97.12
Round  92, Train loss: 1.040, Test loss: 0.940, Test accuracy: 96.66
Round  92, Global train loss: 1.040, Global test loss: 0.939, Global test accuracy: 96.48
Round  93, Train loss: 1.028, Test loss: 0.940, Test accuracy: 96.56
Round  93, Global train loss: 1.028, Global test loss: 0.937, Global test accuracy: 96.76
Round  94, Train loss: 1.018, Test loss: 0.940, Test accuracy: 96.58
Round  94, Global train loss: 1.018, Global test loss: 0.938, Global test accuracy: 96.60/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  95, Train loss: 0.917, Test loss: 0.940, Test accuracy: 96.60
Round  95, Global train loss: 0.917, Global test loss: 0.935, Global test accuracy: 97.22
Round  96, Train loss: 0.916, Test loss: 0.940, Test accuracy: 96.64
Round  96, Global train loss: 0.916, Global test loss: 0.935, Global test accuracy: 97.24
Round  97, Train loss: 1.136, Test loss: 0.940, Test accuracy: 96.68
Round  97, Global train loss: 1.136, Global test loss: 0.937, Global test accuracy: 96.68
Round  98, Train loss: 1.149, Test loss: 0.939, Test accuracy: 96.76
Round  98, Global train loss: 1.149, Global test loss: 0.938, Global test accuracy: 96.50
Round  99, Train loss: 1.131, Test loss: 0.939, Test accuracy: 96.78
Round  99, Global train loss: 1.131, Global test loss: 0.939, Global test accuracy: 96.42
Final Round, Train loss: 1.049, Test loss: 0.939, Test accuracy: 96.72
Final Round, Global train loss: 1.049, Global test loss: 0.939, Global test accuracy: 96.42
Average accuracy final 10 rounds: 96.674 

Average global accuracy final 10 rounds: 96.80000000000001 

632.9515385627747
[1.0501031875610352, 2.1002063751220703, 2.963085889816284, 3.825965404510498, 4.680279731750488, 5.5345940589904785, 6.385183811187744, 7.23577356338501, 8.089401721954346, 8.943029880523682, 9.768336534500122, 10.593643188476562, 11.458091020584106, 12.32253885269165, 13.178837537765503, 14.035136222839355, 14.865287065505981, 15.695437908172607, 16.54704737663269, 17.398656845092773, 18.25839924812317, 19.118141651153564, 19.96851897239685, 20.818896293640137, 21.671977996826172, 22.525059700012207, 23.376705646514893, 24.228351593017578, 25.103439807891846, 25.978528022766113, 26.855432271957397, 27.73233652114868, 28.657795429229736, 29.58325433731079, 30.459503889083862, 31.335753440856934, 32.21285319328308, 33.08995294570923, 33.9812548160553, 34.87255668640137, 35.73853373527527, 36.60451078414917, 37.460469245910645, 38.31642770767212, 39.18186163902283, 40.047295570373535, 40.903658866882324, 41.76002216339111, 42.601552963256836, 43.44308376312256, 44.24166488647461, 45.04024600982666, 45.889572620391846, 46.73889923095703, 47.57786703109741, 48.41683483123779, 49.27033543586731, 50.123836040496826, 50.967785596847534, 51.81173515319824, 52.65810942649841, 53.504483699798584, 54.3477087020874, 55.19093370437622, 56.04596972465515, 56.90100574493408, 57.75071573257446, 58.600425720214844, 59.457602739334106, 60.31477975845337, 61.16167974472046, 62.00857973098755, 62.85048007965088, 63.69238042831421, 64.55119323730469, 65.41000604629517, 66.26247549057007, 67.11494493484497, 67.9773256778717, 68.83970642089844, 69.69894194602966, 70.55817747116089, 71.39450144767761, 72.23082542419434, 73.12640929222107, 74.0219931602478, 74.88272619247437, 75.74345922470093, 76.59719753265381, 77.45093584060669, 78.29704141616821, 79.14314699172974, 80.0148651599884, 80.88658332824707, 81.74618458747864, 82.6057858467102, 83.469313621521, 84.33284139633179, 85.209148645401, 86.08545589447021, 86.9611611366272, 87.83686637878418, 88.7007429599762, 89.56461954116821, 90.42178630828857, 91.27895307540894, 92.13861989974976, 92.99828672409058, 93.87107491493225, 94.74386310577393, 95.57755827903748, 96.41125345230103, 97.23191475868225, 98.05257606506348, 98.90110993385315, 99.74964380264282, 100.60676789283752, 101.46389198303223, 102.32788014411926, 103.1918683052063, 104.05607032775879, 104.92027235031128, 105.78477692604065, 106.64928150177002, 107.49976658821106, 108.3502516746521, 109.25665497779846, 110.16305828094482, 111.01592469215393, 111.86879110336304, 112.7636821269989, 113.65857315063477, 114.58837151527405, 115.51816987991333, 116.38411736488342, 117.25006484985352, 118.13724851608276, 119.02443218231201, 119.87165641784668, 120.71888065338135, 121.59630990028381, 122.47373914718628, 123.32159686088562, 124.16945457458496, 125.05797457695007, 125.94649457931519, 126.80723905563354, 127.6679835319519, 128.60962581634521, 129.55126810073853, 130.39529371261597, 131.2393193244934, 132.1017587184906, 132.9641981124878, 133.81770062446594, 134.6712031364441, 135.51653003692627, 136.36185693740845, 137.21254682540894, 138.06323671340942, 138.92459201812744, 139.78594732284546, 140.7075068950653, 141.62906646728516, 142.57236170768738, 143.5156569480896, 144.38047337532043, 145.24528980255127, 146.10189294815063, 146.95849609375, 147.8485779762268, 148.7386598587036, 149.5917510986328, 150.444842338562, 151.35845398902893, 152.27206563949585, 153.29220747947693, 154.312349319458, 155.3577902317047, 156.40323114395142, 157.3698432445526, 158.3364553451538, 159.3896563053131, 160.4428572654724, 161.40412735939026, 162.3653974533081, 163.3585991859436, 164.3518009185791, 165.19974827766418, 166.04769563674927, 166.99248600006104, 167.9372763633728, 168.97833895683289, 170.01940155029297, 170.868061542511, 171.716721534729, 172.56795573234558, 173.41918992996216, 174.36556363105774, 175.31193733215332, 177.14575290679932, 178.9795684814453]
[68.36, 68.36, 59.52, 59.52, 70.42, 70.42, 80.64, 80.64, 88.48, 88.48, 90.22, 90.22, 95.48, 95.48, 95.6, 95.6, 95.86, 95.86, 95.9, 95.9, 96.24, 96.24, 96.38, 96.38, 96.34, 96.34, 96.34, 96.34, 96.4, 96.4, 96.42, 96.42, 96.82, 96.82, 96.78, 96.78, 96.62, 96.62, 96.56, 96.56, 96.42, 96.42, 96.42, 96.42, 96.52, 96.52, 96.5, 96.5, 96.46, 96.46, 96.54, 96.54, 96.52, 96.52, 96.54, 96.54, 96.56, 96.56, 96.38, 96.38, 96.38, 96.38, 96.44, 96.44, 96.52, 96.52, 96.56, 96.56, 96.58, 96.58, 96.56, 96.56, 96.52, 96.52, 96.48, 96.48, 96.46, 96.46, 96.48, 96.48, 96.46, 96.46, 96.5, 96.5, 96.5, 96.5, 96.48, 96.48, 96.56, 96.56, 96.56, 96.56, 96.6, 96.6, 96.64, 96.64, 96.6, 96.6, 96.58, 96.58, 96.62, 96.62, 96.56, 96.56, 96.56, 96.56, 96.56, 96.56, 96.6, 96.6, 96.54, 96.54, 96.56, 96.56, 96.44, 96.44, 96.4, 96.4, 96.4, 96.4, 96.4, 96.4, 96.52, 96.52, 96.52, 96.52, 96.54, 96.54, 96.54, 96.54, 96.6, 96.6, 96.64, 96.64, 96.62, 96.62, 96.6, 96.6, 96.6, 96.6, 96.58, 96.58, 96.6, 96.6, 96.62, 96.62, 96.66, 96.66, 96.64, 96.64, 96.66, 96.66, 96.66, 96.66, 96.74, 96.74, 96.7, 96.7, 96.7, 96.7, 96.74, 96.74, 96.76, 96.76, 96.76, 96.76, 96.7, 96.7, 96.7, 96.7, 96.68, 96.68, 96.74, 96.74, 96.74, 96.74, 96.72, 96.72, 96.72, 96.72, 96.74, 96.74, 96.74, 96.74, 96.66, 96.66, 96.56, 96.56, 96.58, 96.58, 96.6, 96.6, 96.64, 96.64, 96.68, 96.68, 96.76, 96.76, 96.78, 96.78, 96.72, 96.72]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.4 , level_n_lowerb:0.4  

   Client 6, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Traceback (most recent call last):
  File "main_fedpac_co_teaching.py", line 250, in <module>
    local.filter_data(net=net_local.to(args.device), net2=net_local2.to(args.device), concept_matrix_local = concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1587, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

   Client 0, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550021 (local), 549696 (global); Percentage 99.94 (549696/550021)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 1.622, Test loss: 1.591, Test accuracy: 50.86
Round   0, Global train loss: 1.622, Global test loss: 1.591, Global test accuracy: 50.70
Round   1, Train loss: 1.575, Test loss: 1.518, Test accuracy: 53.02
Round   1, Global train loss: 1.575, Global test loss: 1.516, Global test accuracy: 51.28
Round   2, Train loss: 1.521, Test loss: 1.425, Test accuracy: 87.74
Round   2, Global train loss: 1.521, Global test loss: 1.417, Global test accuracy: 87.80
Round   3, Train loss: 1.441, Test loss: 1.268, Test accuracy: 92.92
Round   3, Global train loss: 1.441, Global test loss: 1.248, Global test accuracy: 93.24
Round   4, Train loss: 1.250, Test loss: 1.102, Test accuracy: 94.88
Round   4, Global train loss: 1.250, Global test loss: 1.070, Global test accuracy: 94.80
Round   5, Train loss: 1.153, Test loss: 1.039, Test accuracy: 95.16
Round   5, Global train loss: 1.153, Global test loss: 1.013, Global test accuracy: 95.00
Round   6, Train loss: 1.137, Test loss: 1.008, Test accuracy: 95.64
Round   6, Global train loss: 1.137, Global test loss: 1.003, Global test accuracy: 95.64
Round   7, Train loss: 1.214, Test loss: 0.996, Test accuracy: 96.12
Round   7, Global train loss: 1.214, Global test loss: 0.998, Global test accuracy: 96.10
Round   8, Train loss: 1.220, Test loss: 0.996, Test accuracy: 96.20
Round   8, Global train loss: 1.220, Global test loss: 0.994, Global test accuracy: 96.16
Round   9, Train loss: 1.207, Test loss: 0.993, Test accuracy: 96.08
Round   9, Global train loss: 1.207, Global test loss: 0.990, Global test accuracy: 96.28
Round  10, Train loss: 1.085, Test loss: 0.979, Test accuracy: 96.50
Round  10, Global train loss: 1.085, Global test loss: 0.977, Global test accuracy: 96.48
Round  11, Train loss: 1.197, Test loss: 0.976, Test accuracy: 96.72
Round  11, Global train loss: 1.197, Global test loss: 0.975, Global test accuracy: 96.80
Round  12, Train loss: 1.180, Test loss: 0.977, Test accuracy: 96.62
Round  12, Global train loss: 1.180, Global test loss: 0.975, Global test accuracy: 96.56
Round  13, Train loss: 1.083, Test loss: 0.970, Test accuracy: 96.84
Round  13, Global train loss: 1.083, Global test loss: 0.967, Global test accuracy: 97.04
Round  14, Train loss: 1.193, Test loss: 0.974, Test accuracy: 96.74
Round  14, Global train loss: 1.193, Global test loss: 0.971, Global test accuracy: 96.66
Round  15, Train loss: 1.069, Test loss: 0.970, Test accuracy: 96.86
Round  15, Global train loss: 1.069, Global test loss: 0.964, Global test accuracy: 96.96
Round  16, Train loss: 1.068, Test loss: 0.967, Test accuracy: 96.76
Round  16, Global train loss: 1.068, Global test loss: 0.962, Global test accuracy: 96.92
Round  17, Train loss: 1.067, Test loss: 0.963, Test accuracy: 96.86
Round  17, Global train loss: 1.067, Global test loss: 0.958, Global test accuracy: 97.12
Round  18, Train loss: 1.090, Test loss: 0.959, Test accuracy: 96.84
Round  18, Global train loss: 1.090, Global test loss: 0.959, Global test accuracy: 96.96
Round  19, Train loss: 1.070, Test loss: 0.958, Test accuracy: 96.96
Round  19, Global train loss: 1.070, Global test loss: 0.953, Global test accuracy: 97.10
Round  20, Train loss: 1.056, Test loss: 0.958, Test accuracy: 97.00
Round  20, Global train loss: 1.056, Global test loss: 0.953, Global test accuracy: 97.08
Round  21, Train loss: 0.961, Test loss: 0.954, Test accuracy: 97.08
Round  21, Global train loss: 0.961, Global test loss: 0.947, Global test accuracy: 97.16
Round  22, Train loss: 0.944, Test loss: 0.951, Test accuracy: 96.96
Round  22, Global train loss: 0.944, Global test loss: 0.944, Global test accuracy: 97.10
Round  23, Train loss: 1.164, Test loss: 0.953, Test accuracy: 97.00
Round  23, Global train loss: 1.164, Global test loss: 0.951, Global test accuracy: 97.14
Round  24, Train loss: 0.953, Test loss: 0.953, Test accuracy: 97.02
Round  24, Global train loss: 0.953, Global test loss: 0.948, Global test accuracy: 97.16
Round  25, Train loss: 1.071, Test loss: 0.953, Test accuracy: 96.94
Round  25, Global train loss: 1.071, Global test loss: 0.950, Global test accuracy: 97.04
Round  26, Train loss: 1.061, Test loss: 0.954, Test accuracy: 96.98
Round  26, Global train loss: 1.061, Global test loss: 0.948, Global test accuracy: 97.18
Round  27, Train loss: 1.038, Test loss: 0.954, Test accuracy: 97.00
Round  27, Global train loss: 1.038, Global test loss: 0.947, Global test accuracy: 97.22
Round  28, Train loss: 1.057, Test loss: 0.954, Test accuracy: 97.00
Round  28, Global train loss: 1.057, Global test loss: 0.948, Global test accuracy: 97.08
Round  29, Train loss: 1.156, Test loss: 0.956, Test accuracy: 96.98
Round  29, Global train loss: 1.156, Global test loss: 0.956, Global test accuracy: 97.16
Round  30, Train loss: 1.174, Test loss: 0.961, Test accuracy: 96.70
Round  30, Global train loss: 1.174, Global test loss: 0.960, Global test accuracy: 96.70
Round  31, Train loss: 1.150, Test loss: 0.962, Test accuracy: 96.68
Round  31, Global train loss: 1.150, Global test loss: 0.958, Global test accuracy: 96.76
Round  32, Train loss: 1.167, Test loss: 0.962, Test accuracy: 96.72
Round  32, Global train loss: 1.167, Global test loss: 0.961, Global test accuracy: 97.08
Round  33, Train loss: 1.150, Test loss: 0.962, Test accuracy: 96.76
Round  33, Global train loss: 1.150, Global test loss: 0.961, Global test accuracy: 96.74
Round  34, Train loss: 0.964, Test loss: 0.953, Test accuracy: 97.14
Round  34, Global train loss: 0.964, Global test loss: 0.948, Global test accuracy: 97.38
Round  35, Train loss: 1.067, Test loss: 0.951, Test accuracy: 97.12
Round  35, Global train loss: 1.067, Global test loss: 0.948, Global test accuracy: 97.38
Round  36, Train loss: 1.052, Test loss: 0.951, Test accuracy: 97.24
Round  36, Global train loss: 1.052, Global test loss: 0.946, Global test accuracy: 97.36
Round  37, Train loss: 1.046, Test loss: 0.951, Test accuracy: 97.26
Round  37, Global train loss: 1.046, Global test loss: 0.949, Global test accuracy: 97.32
Round  38, Train loss: 1.048, Test loss: 0.950, Test accuracy: 97.16
Round  38, Global train loss: 1.048, Global test loss: 0.947, Global test accuracy: 97.28
Round  39, Train loss: 1.159, Test loss: 0.954, Test accuracy: 97.14
Round  39, Global train loss: 1.159, Global test loss: 0.952, Global test accuracy: 97.32
Round  40, Train loss: 1.047, Test loss: 0.954, Test accuracy: 97.24
Round  40, Global train loss: 1.047, Global test loss: 0.947, Global test accuracy: 97.50
Round  41, Train loss: 1.157, Test loss: 0.956, Test accuracy: 97.12
Round  41, Global train loss: 1.157, Global test loss: 0.957, Global test accuracy: 97.14
Round  42, Train loss: 1.066, Test loss: 0.955, Test accuracy: 96.98
Round  42, Global train loss: 1.066, Global test loss: 0.952, Global test accuracy: 97.12
Round  43, Train loss: 1.070, Test loss: 0.952, Test accuracy: 97.02
Round  43, Global train loss: 1.070, Global test loss: 0.950, Global test accuracy: 97.16
Round  44, Train loss: 1.061, Test loss: 0.952, Test accuracy: 97.22
Round  44, Global train loss: 1.061, Global test loss: 0.948, Global test accuracy: 97.44
Round  45, Train loss: 0.948, Test loss: 0.947, Test accuracy: 97.34
Round  45, Global train loss: 0.948, Global test loss: 0.940, Global test accuracy: 97.60
Round  46, Train loss: 0.949, Test loss: 0.945, Test accuracy: 97.34
Round  46, Global train loss: 0.949, Global test loss: 0.940, Global test accuracy: 97.56
Round  47, Train loss: 1.141, Test loss: 0.949, Test accuracy: 97.30
Round  47, Global train loss: 1.141, Global test loss: 0.947, Global test accuracy: 97.26
Round  48, Train loss: 1.041, Test loss: 0.949, Test accuracy: 97.30
Round  48, Global train loss: 1.041, Global test loss: 0.944, Global test accuracy: 97.56
Round  49, Train loss: 0.946, Test loss: 0.948, Test accuracy: 97.26
Round  49, Global train loss: 0.946, Global test loss: 0.941, Global test accuracy: 97.52
Round  50, Train loss: 0.943, Test loss: 0.946, Test accuracy: 97.28
Round  50, Global train loss: 0.943, Global test loss: 0.939, Global test accuracy: 97.50
Round  51, Train loss: 1.056, Test loss: 0.946, Test accuracy: 97.32
Round  51, Global train loss: 1.056, Global test loss: 0.941, Global test accuracy: 97.72
Round  52, Train loss: 1.021, Test loss: 0.947, Test accuracy: 97.44
Round  52, Global train loss: 1.021, Global test loss: 0.939, Global test accuracy: 97.50
Round  53, Train loss: 1.137, Test loss: 0.948, Test accuracy: 97.24
Round  53, Global train loss: 1.137, Global test loss: 0.946, Global test accuracy: 97.48
Round  54, Train loss: 1.076, Test loss: 0.952, Test accuracy: 97.12
Round  54, Global train loss: 1.076, Global test loss: 0.951, Global test accuracy: 97.20
Round  55, Train loss: 1.054, Test loss: 0.951, Test accuracy: 97.10
Round  55, Global train loss: 1.054, Global test loss: 0.947, Global test accuracy: 97.42
Round  56, Train loss: 1.145, Test loss: 0.953, Test accuracy: 97.04
Round  56, Global train loss: 1.145, Global test loss: 0.954, Global test accuracy: 96.96
Round  57, Train loss: 1.130, Test loss: 0.956, Test accuracy: 96.96
Round  57, Global train loss: 1.130, Global test loss: 0.954, Global test accuracy: 96.96
Round  58, Train loss: 1.043, Test loss: 0.955, Test accuracy: 97.00
Round  58, Global train loss: 1.043, Global test loss: 0.947, Global test accuracy: 97.34
Round  59, Train loss: 1.054, Test loss: 0.952, Test accuracy: 96.98
Round  59, Global train loss: 1.054, Global test loss: 0.948, Global test accuracy: 97.16
Round  60, Train loss: 1.036, Test loss: 0.950, Test accuracy: 97.00
Round  60, Global train loss: 1.036, Global test loss: 0.942, Global test accuracy: 97.74
Round  61, Train loss: 1.237, Test loss: 0.957, Test accuracy: 96.94
Round  61, Global train loss: 1.237, Global test loss: 0.961, Global test accuracy: 96.92
Round  62, Train loss: 0.964, Test loss: 0.954, Test accuracy: 97.00
Round  62, Global train loss: 0.964, Global test loss: 0.945, Global test accuracy: 97.36
Round  63, Train loss: 1.048, Test loss: 0.951, Test accuracy: 97.22
Round  63, Global train loss: 1.048, Global test loss: 0.946, Global test accuracy: 97.60
Round  64, Train loss: 1.032, Test loss: 0.949, Test accuracy: 97.12
Round  64, Global train loss: 1.032, Global test loss: 0.942, Global test accuracy: 97.64
Round  65, Train loss: 0.937, Test loss: 0.947, Test accuracy: 97.18
Round  65, Global train loss: 0.937, Global test loss: 0.937, Global test accuracy: 97.74
Round  66, Train loss: 1.018, Test loss: 0.947, Test accuracy: 97.28
Round  66, Global train loss: 1.018, Global test loss: 0.938, Global test accuracy: 97.84
Round  67, Train loss: 1.138, Test loss: 0.949, Test accuracy: 97.24
Round  67, Global train loss: 1.138, Global test loss: 0.946, Global test accuracy: 97.64
Round  68, Train loss: 0.937, Test loss: 0.949, Test accuracy: 97.24
Round  68, Global train loss: 0.937, Global test loss: 0.939, Global test accuracy: 97.80
Round  69, Train loss: 1.123, Test loss: 0.950, Test accuracy: 97.10
Round  69, Global train loss: 1.123, Global test loss: 0.945, Global test accuracy: 97.64
Round  70, Train loss: 1.136, Test loss: 0.956, Test accuracy: 96.88
Round  70, Global train loss: 1.136, Global test loss: 0.950, Global test accuracy: 97.54
Round  71, Train loss: 1.048, Test loss: 0.956, Test accuracy: 96.88
Round  71, Global train loss: 1.048, Global test loss: 0.949, Global test accuracy: 97.52
Round  72, Train loss: 1.041, Test loss: 0.953, Test accuracy: 97.00
Round  72, Global train loss: 1.041, Global test loss: 0.949, Global test accuracy: 97.24
Round  73, Train loss: 1.030, Test loss: 0.953, Test accuracy: 97.10
Round  73, Global train loss: 1.030, Global test loss: 0.945, Global test accuracy: 97.50
Round  74, Train loss: 1.128, Test loss: 0.956, Test accuracy: 96.74
Round  74, Global train loss: 1.128, Global test loss: 0.951, Global test accuracy: 97.24
Round  75, Train loss: 1.056, Test loss: 0.957, Test accuracy: 96.88
Round  75, Global train loss: 1.056, Global test loss: 0.950, Global test accuracy: 97.46
Round  76, Train loss: 0.918, Test loss: 0.949, Test accuracy: 97.12
Round  76, Global train loss: 0.918, Global test loss: 0.938, Global test accuracy: 97.78
Round  77, Train loss: 0.932, Test loss: 0.946, Test accuracy: 97.16
Round  77, Global train loss: 0.932, Global test loss: 0.936, Global test accuracy: 97.96
Round  78, Train loss: 1.036, Test loss: 0.947, Test accuracy: 97.08
Round  78, Global train loss: 1.036, Global test loss: 0.940, Global test accuracy: 97.78
Round  79, Train loss: 1.037, Test loss: 0.953, Test accuracy: 96.88
Round  79, Global train loss: 1.037, Global test loss: 0.947, Global test accuracy: 97.36
Round  80, Train loss: 1.127, Test loss: 0.954, Test accuracy: 96.90
Round  80, Global train loss: 1.127, Global test loss: 0.954, Global test accuracy: 97.04
Round  81, Train loss: 1.036, Test loss: 0.955, Test accuracy: 96.98
Round  81, Global train loss: 1.036, Global test loss: 0.945, Global test accuracy: 97.84
Round  82, Train loss: 1.046, Test loss: 0.957, Test accuracy: 96.62
Round  82, Global train loss: 1.046, Global test loss: 0.954, Global test accuracy: 96.72
Round  83, Train loss: 1.129, Test loss: 0.960, Test accuracy: 96.74
Round  83, Global train loss: 1.129, Global test loss: 0.954, Global test accuracy: 97.38
Round  84, Train loss: 1.217, Test loss: 0.969, Test accuracy: 96.26
Round  84, Global train loss: 1.217, Global test loss: 0.969, Global test accuracy: 96.66
Round  85, Train loss: 1.032, Test loss: 0.959, Test accuracy: 96.82
Round  85, Global train loss: 1.032, Global test loss: 0.950, Global test accuracy: 97.44
Round  86, Train loss: 1.036, Test loss: 0.955, Test accuracy: 96.80
Round  86, Global train loss: 1.036, Global test loss: 0.957, Global test accuracy: 96.42
Round  87, Train loss: 1.110, Test loss: 0.956, Test accuracy: 96.82
Round  87, Global train loss: 1.110, Global test loss: 0.951, Global test accuracy: 97.40
Round  88, Train loss: 1.105, Test loss: 0.962, Test accuracy: 96.64
Round  88, Global train loss: 1.105, Global test loss: 0.956, Global test accuracy: 97.46
Round  89, Train loss: 1.035, Test loss: 0.956, Test accuracy: 96.76
Round  89, Global train loss: 1.035, Global test loss: 0.958, Global test accuracy: 96.50
Round  90, Train loss: 1.102, Test loss: 0.957, Test accuracy: 96.74
Round  90, Global train loss: 1.102, Global test loss: 0.951, Global test accuracy: 97.14
Round  91, Train loss: 1.096, Test loss: 0.963, Test accuracy: 96.42
Round  91, Global train loss: 1.096, Global test loss: 0.957, Global test accuracy: 96.76/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  92, Train loss: 1.017, Test loss: 0.958, Test accuracy: 96.56
Round  92, Global train loss: 1.017, Global test loss: 0.947, Global test accuracy: 97.26
Round  93, Train loss: 1.001, Test loss: 0.955, Test accuracy: 96.80
Round  93, Global train loss: 1.001, Global test loss: 0.944, Global test accuracy: 97.50
Round  94, Train loss: 1.114, Test loss: 0.958, Test accuracy: 96.50
Round  94, Global train loss: 1.114, Global test loss: 0.959, Global test accuracy: 96.44
Round  95, Train loss: 1.118, Test loss: 0.963, Test accuracy: 96.44
Round  95, Global train loss: 1.118, Global test loss: 0.962, Global test accuracy: 96.44
Round  96, Train loss: 1.112, Test loss: 0.968, Test accuracy: 96.18
Round  96, Global train loss: 1.112, Global test loss: 0.969, Global test accuracy: 96.22
Round  97, Train loss: 1.014, Test loss: 0.959, Test accuracy: 96.58
Round  97, Global train loss: 1.014, Global test loss: 0.949, Global test accuracy: 97.34
Round  98, Train loss: 0.930, Test loss: 0.949, Test accuracy: 97.04
Round  98, Global train loss: 0.930, Global test loss: 0.940, Global test accuracy: 97.60
Round  99, Train loss: 1.001, Test loss: 0.951, Test accuracy: 96.86
Round  99, Global train loss: 1.001, Global test loss: 0.941, Global test accuracy: 97.62
Final Round, Train loss: 1.028, Test loss: 0.952, Test accuracy: 96.72
Final Round, Global train loss: 1.028, Global test loss: 0.941, Global test accuracy: 97.62
Average accuracy final 10 rounds: 96.612
581.10777759552
[1.0572059154510498, 1.9957373142242432, 3.0201971530914307, 3.937234401702881, 4.861351013183594, 5.90742564201355, 6.816513776779175, 7.74570894241333, 8.667014837265015, 9.638412952423096, 10.556458234786987, 11.449284315109253, 12.36769986152649, 13.627776145935059, 15.348838329315186, 16.69262433052063, 17.908038854599, 18.89024043083191, 20.134427309036255, 21.032418966293335, 21.924778699874878, 23.5098295211792, 24.416220903396606, 25.672537803649902, 26.849977731704712, 28.09157943725586, 29.268423080444336, 30.711750745773315, 31.984801292419434, 32.878111600875854, 34.02448511123657, 35.1485550403595, 37.69357442855835, 38.9113974571228, 40.149364709854126, 41.38440704345703, 42.39085364341736, 43.66602277755737, 44.87857246398926, 45.84583568572998, 46.75814652442932, 47.761300802230835, 48.661609172821045, 49.577908992767334, 50.61068415641785, 51.61514973640442, 52.521334409713745, 53.4159574508667, 54.33400082588196, 55.2410614490509, 56.15526461601257, 57.131500005722046, 58.104779958724976, 59.049083948135376, 59.977293252944946, 60.910353660583496, 61.82235360145569, 62.72536063194275, 63.63385367393494, 64.58534359931946, 65.4955358505249, 66.438241481781, 67.32548809051514, 68.6407458782196, 69.72485947608948, 70.62039351463318, 71.62583994865417, 72.85763692855835, 73.75871443748474, 75.04655456542969, 76.06235694885254, 76.97480583190918, 78.14994478225708, 79.30268144607544, 80.20259952545166, 81.4472005367279, 82.62632751464844, 83.7867522239685, 85.02511692047119, 86.29114174842834, 87.46207809448242, 88.50925731658936, 89.59969329833984, 90.91643834114075, 92.23032641410828, 93.34310269355774, 94.52159976959229, 95.62335324287415, 96.89033961296082, 97.77933645248413, 98.93039560317993, 99.96659970283508, 100.88850736618042, 101.77958059310913, 102.73662948608398, 103.65474319458008, 104.59778118133545, 105.51929640769958, 106.42979264259338, 107.33153080940247, 108.77617383003235]
[50.86, 53.02, 87.74, 92.92, 94.88, 95.16, 95.64, 96.12, 96.2, 96.08, 96.5, 96.72, 96.62, 96.84, 96.74, 96.86, 96.76, 96.86, 96.84, 96.96, 97.0, 97.08, 96.96, 97.0, 97.02, 96.94, 96.98, 97.0, 97.0, 96.98, 96.7, 96.68, 96.72, 96.76, 97.14, 97.12, 97.24, 97.26, 97.16, 97.14, 97.24, 97.12, 96.98, 97.02, 97.22, 97.34, 97.34, 97.3, 97.3, 97.26, 97.28, 97.32, 97.44, 97.24, 97.12, 97.1, 97.04, 96.96, 97.0, 96.98, 97.0, 96.94, 97.0, 97.22, 97.12, 97.18, 97.28, 97.24, 97.24, 97.1, 96.88, 96.88, 97.0, 97.1, 96.74, 96.88, 97.12, 97.16, 97.08, 96.88, 96.9, 96.98, 96.62, 96.74, 96.26, 96.82, 96.8, 96.82, 96.64, 96.76, 96.74, 96.42, 96.56, 96.8, 96.5, 96.44, 96.18, 96.58, 97.04, 96.86, 96.72]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fedpac_copsl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist,  filter_alg: loss_psl, level_n_system: 0.4 , level_n_lowerb:0.4  

   Client 2, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550021 (local), 549696 (global); Percentage 99.94 (549696/550021)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 1.622, Test loss: 1.592, Test accuracy: 58.54
Round   0, Global train loss: 1.622, Global test loss: 1.592, Global test accuracy: 58.48
Round   1, Train loss: 1.584, Test loss: 1.544, Test accuracy: 70.44
Round   1, Global train loss: 1.584, Global test loss: 1.544, Global test accuracy: 70.94
Round   2, Train loss: 1.511, Test loss: 1.384, Test accuracy: 74.90
Round   2, Global train loss: 1.511, Global test loss: 1.383, Global test accuracy: 75.74
Round   3, Train loss: 1.353, Test loss: 1.171, Test accuracy: 90.16
Round   3, Global train loss: 1.353, Global test loss: 1.167, Global test accuracy: 90.04
Round   4, Train loss: 1.203, Test loss: 1.033, Test accuracy: 95.20
Round   4, Global train loss: 1.203, Global test loss: 1.030, Global test accuracy: 95.42
Round   5, Train loss: 1.143, Test loss: 0.996, Test accuracy: 95.96
Round   5, Global train loss: 1.143, Global test loss: 0.994, Global test accuracy: 96.10
Round   6, Train loss: 1.124, Test loss: 0.982, Test accuracy: 96.38
Round   6, Global train loss: 1.124, Global test loss: 0.980, Global test accuracy: 96.44
Round   7, Train loss: 1.114, Test loss: 0.973, Test accuracy: 96.80
Round   7, Global train loss: 1.114, Global test loss: 0.971, Global test accuracy: 96.72
Round   8, Train loss: 1.107, Test loss: 0.968, Test accuracy: 96.86
Round   8, Global train loss: 1.107, Global test loss: 0.966, Global test accuracy: 96.84
Round   9, Train loss: 1.102, Test loss: 0.963, Test accuracy: 96.98
Round   9, Global train loss: 1.102, Global test loss: 0.962, Global test accuracy: 96.94
Round  10, Train loss: 1.055, Test loss: 0.962, Test accuracy: 97.00
Round  10, Global train loss: 1.055, Global test loss: 0.956, Global test accuracy: 97.00
Traceback (most recent call last):
  File "main_fedpac_copsl.py", line 280, in <module>
    w_local, loss, indd, class_center_local, class_num, noisy_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys,
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2559, in train
    self.filter_data(net, local_net, iter2-head_eps+1, local_eps-head_eps+1, concept_matrix_local)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2396, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist, level_n_system: 0.4 , level_n_lowerb:0.8  

   Client 1, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.590, Test loss: 1.560, Test accuracy: 39.10
Round   0, Global train loss: 1.590, Global test loss: 1.563, Global test accuracy: 39.52
Round   1, Train loss: 1.401, Test loss: 1.272, Test accuracy: 80.02
Round   1, Global train loss: 1.401, Global test loss: 1.252, Global test accuracy: 91.06
Round   2, Train loss: 1.252, Test loss: 1.154, Test accuracy: 80.52
Round   2, Global train loss: 1.252, Global test loss: 1.028, Global test accuracy: 94.06
Round   3, Train loss: 1.371, Test loss: 1.177, Test accuracy: 80.08
Round   3, Global train loss: 1.371, Global test loss: 1.163, Global test accuracy: 94.78
Round   4, Train loss: 1.154, Test loss: 1.134, Test accuracy: 80.36
Round   4, Global train loss: 1.154, Global test loss: 0.979, Global test accuracy: 95.28
Round   5, Train loss: 1.179, Test loss: 1.140, Test accuracy: 79.56
Round   5, Global train loss: 1.179, Global test loss: 1.008, Global test accuracy: 93.72
Round   6, Train loss: 1.142, Test loss: 1.145, Test accuracy: 80.74
Round   6, Global train loss: 1.142, Global test loss: 1.058, Global test accuracy: 94.22
Round   7, Train loss: 1.137, Test loss: 1.125, Test accuracy: 80.94
Round   7, Global train loss: 1.137, Global test loss: 0.980, Global test accuracy: 95.44
Round   8, Train loss: 1.435, Test loss: 1.115, Test accuracy: 81.48
Round   8, Global train loss: 1.435, Global test loss: 1.154, Global test accuracy: 84.90
Round   9, Train loss: 1.309, Test loss: 1.111, Test accuracy: 83.00
Round   9, Global train loss: 1.309, Global test loss: 1.124, Global test accuracy: 93.70
Round  10, Train loss: 1.327, Test loss: 1.114, Test accuracy: 82.48
Round  10, Global train loss: 1.327, Global test loss: 1.122, Global test accuracy: 89.76
Round  11, Train loss: 0.965, Test loss: 1.112, Test accuracy: 82.44
Round  11, Global train loss: 0.965, Global test loss: 0.958, Global test accuracy: 95.70
Round  12, Train loss: 1.083, Test loss: 1.114, Test accuracy: 82.16
Round  12, Global train loss: 1.083, Global test loss: 0.964, Global test accuracy: 95.52
Round  13, Train loss: 1.313, Test loss: 1.109, Test accuracy: 82.40
Round  13, Global train loss: 1.313, Global test loss: 1.106, Global test accuracy: 88.68
Round  14, Train loss: 1.284, Test loss: 1.113, Test accuracy: 81.90
Round  14, Global train loss: 1.284, Global test loss: 0.990, Global test accuracy: 94.70
Round  15, Train loss: 1.111, Test loss: 1.111, Test accuracy: 81.82
Round  15, Global train loss: 1.111, Global test loss: 0.997, Global test accuracy: 94.88
Round  16, Train loss: 1.123, Test loss: 1.111, Test accuracy: 81.84
Round  16, Global train loss: 1.123, Global test loss: 0.966, Global test accuracy: 95.44
Round  17, Train loss: 0.951, Test loss: 1.112, Test accuracy: 81.50
Round  17, Global train loss: 0.951, Global test loss: 0.952, Global test accuracy: 96.04
Round  18, Train loss: 1.417, Test loss: 1.118, Test accuracy: 79.96
Round  18, Global train loss: 1.417, Global test loss: 1.186, Global test accuracy: 83.90
Round  19, Train loss: 1.080, Test loss: 1.121, Test accuracy: 79.64
Round  19, Global train loss: 1.080, Global test loss: 1.003, Global test accuracy: 93.50
Round  20, Train loss: 1.076, Test loss: 1.123, Test accuracy: 79.38
Round  20, Global train loss: 1.076, Global test loss: 0.963, Global test accuracy: 95.74
Round  21, Train loss: 0.976, Test loss: 1.119, Test accuracy: 79.44
Round  21, Global train loss: 0.976, Global test loss: 1.002, Global test accuracy: 94.28
Round  22, Train loss: 1.332, Test loss: 1.124, Test accuracy: 78.86
Round  22, Global train loss: 1.332, Global test loss: 1.199, Global test accuracy: 74.32
Round  23, Train loss: 1.067, Test loss: 1.130, Test accuracy: 78.08
Round  23, Global train loss: 1.067, Global test loss: 0.964, Global test accuracy: 95.10
Round  24, Train loss: 1.116, Test loss: 1.129, Test accuracy: 77.76
Round  24, Global train loss: 1.116, Global test loss: 1.110, Global test accuracy: 84.58
Round  25, Train loss: 0.991, Test loss: 1.126, Test accuracy: 78.28
Round  25, Global train loss: 0.991, Global test loss: 0.961, Global test accuracy: 95.68
Round  26, Train loss: 1.177, Test loss: 1.128, Test accuracy: 78.12
Round  26, Global train loss: 1.177, Global test loss: 1.006, Global test accuracy: 91.24
Round  27, Train loss: 1.163, Test loss: 1.134, Test accuracy: 77.46
Round  27, Global train loss: 1.163, Global test loss: 1.094, Global test accuracy: 83.72
Round  28, Train loss: 1.056, Test loss: 1.133, Test accuracy: 77.50
Round  28, Global train loss: 1.056, Global test loss: 0.955, Global test accuracy: 95.76
Round  29, Train loss: 1.182, Test loss: 1.129, Test accuracy: 78.24
Round  29, Global train loss: 1.182, Global test loss: 1.037, Global test accuracy: 88.46
Round  30, Train loss: 1.060, Test loss: 1.131, Test accuracy: 77.96
Round  30, Global train loss: 1.060, Global test loss: 0.965, Global test accuracy: 94.86
Round  31, Train loss: 1.133, Test loss: 1.132, Test accuracy: 77.66
Round  31, Global train loss: 1.133, Global test loss: 0.979, Global test accuracy: 94.22
Round  32, Train loss: 1.206, Test loss: 1.137, Test accuracy: 77.22
Round  32, Global train loss: 1.206, Global test loss: 1.012, Global test accuracy: 91.08
Round  33, Train loss: 1.025, Test loss: 1.136, Test accuracy: 77.28
Round  33, Global train loss: 1.025, Global test loss: 0.956, Global test accuracy: 95.62
Round  34, Train loss: 1.024, Test loss: 1.137, Test accuracy: 76.92
Round  34, Global train loss: 1.024, Global test loss: 0.966, Global test accuracy: 95.68
Round  35, Train loss: 1.125, Test loss: 1.137, Test accuracy: 77.16
Round  35, Global train loss: 1.125, Global test loss: 0.989, Global test accuracy: 94.60
Round  36, Train loss: 1.184, Test loss: 1.142, Test accuracy: 76.32
Round  36, Global train loss: 1.184, Global test loss: 1.033, Global test accuracy: 88.66
Round  37, Train loss: 1.171, Test loss: 1.145, Test accuracy: 76.06
Round  37, Global train loss: 1.171, Global test loss: 1.009, Global test accuracy: 91.08
Round  38, Train loss: 1.049, Test loss: 1.145, Test accuracy: 75.98
Round  38, Global train loss: 1.049, Global test loss: 0.974, Global test accuracy: 94.40
Round  39, Train loss: 0.987, Test loss: 1.147, Test accuracy: 75.78
Round  39, Global train loss: 0.987, Global test loss: 0.958, Global test accuracy: 94.96
Round  40, Train loss: 1.061, Test loss: 1.151, Test accuracy: 74.90
Round  40, Global train loss: 1.061, Global test loss: 0.976, Global test accuracy: 95.14
Round  41, Train loss: 1.081, Test loss: 1.152, Test accuracy: 74.68
Round  41, Global train loss: 1.081, Global test loss: 0.998, Global test accuracy: 91.58
Round  42, Train loss: 1.074, Test loss: 1.149, Test accuracy: 75.40
Round  42, Global train loss: 1.074, Global test loss: 0.991, Global test accuracy: 93.06
Round  43, Train loss: 0.938, Test loss: 1.146, Test accuracy: 75.64
Round  43, Global train loss: 0.938, Global test loss: 0.953, Global test accuracy: 95.34
Round  44, Train loss: 0.938, Test loss: 1.147, Test accuracy: 75.58
Round  44, Global train loss: 0.938, Global test loss: 0.951, Global test accuracy: 95.84
Round  45, Train loss: 1.187, Test loss: 1.153, Test accuracy: 74.86
Round  45, Global train loss: 1.187, Global test loss: 1.120, Global test accuracy: 79.78
Round  46, Train loss: 0.938, Test loss: 1.153, Test accuracy: 74.92
Round  46, Global train loss: 0.938, Global test loss: 0.948, Global test accuracy: 96.28
Round  47, Train loss: 0.962, Test loss: 1.156, Test accuracy: 74.50
Round  47, Global train loss: 0.962, Global test loss: 0.959, Global test accuracy: 95.10
Round  48, Train loss: 1.003, Test loss: 1.155, Test accuracy: 74.66
Round  48, Global train loss: 1.003, Global test loss: 0.962, Global test accuracy: 95.38
Round  49, Train loss: 1.046, Test loss: 1.159, Test accuracy: 73.92
Round  49, Global train loss: 1.046, Global test loss: 1.050, Global test accuracy: 86.54
Round  50, Train loss: 1.056, Test loss: 1.157, Test accuracy: 74.20
Round  50, Global train loss: 1.056, Global test loss: 0.990, Global test accuracy: 92.50
Round  51, Train loss: 0.932, Test loss: 1.159, Test accuracy: 74.06
Round  51, Global train loss: 0.932, Global test loss: 0.953, Global test accuracy: 95.88
Round  52, Train loss: 1.012, Test loss: 1.157, Test accuracy: 74.44
Round  52, Global train loss: 1.012, Global test loss: 0.960, Global test accuracy: 95.06
Round  53, Train loss: 0.999, Test loss: 1.158, Test accuracy: 74.30
Round  53, Global train loss: 0.999, Global test loss: 0.963, Global test accuracy: 94.84
Round  54, Train loss: 0.935, Test loss: 1.160, Test accuracy: 74.06
Round  54, Global train loss: 0.935, Global test loss: 0.944, Global test accuracy: 96.46
Round  55, Train loss: 1.005, Test loss: 1.161, Test accuracy: 73.84
Round  55, Global train loss: 1.005, Global test loss: 0.969, Global test accuracy: 93.98
Round  56, Train loss: 1.007, Test loss: 1.163, Test accuracy: 73.48
Round  56, Global train loss: 1.007, Global test loss: 0.949, Global test accuracy: 96.04
Round  57, Train loss: 1.027, Test loss: 1.160, Test accuracy: 73.94
Round  57, Global train loss: 1.027, Global test loss: 0.953, Global test accuracy: 95.54
Round  58, Train loss: 0.968, Test loss: 1.159, Test accuracy: 74.16
Round  58, Global train loss: 0.968, Global test loss: 0.981, Global test accuracy: 93.80
Round  59, Train loss: 1.088, Test loss: 1.158, Test accuracy: 74.22
Round  59, Global train loss: 1.088, Global test loss: 1.035, Global test accuracy: 88.16
Round  60, Train loss: 0.966, Test loss: 1.159, Test accuracy: 74.08
Round  60, Global train loss: 0.966, Global test loss: 0.970, Global test accuracy: 94.48
Round  61, Train loss: 0.910, Test loss: 1.159, Test accuracy: 74.08
Round  61, Global train loss: 0.910, Global test loss: 0.943, Global test accuracy: 96.48
Round  62, Train loss: 1.042, Test loss: 1.163, Test accuracy: 73.46
Round  62, Global train loss: 1.042, Global test loss: 0.993, Global test accuracy: 91.54
Round  63, Train loss: 1.002, Test loss: 1.161, Test accuracy: 73.70
Round  63, Global train loss: 1.002, Global test loss: 0.968, Global test accuracy: 95.04
Round  64, Train loss: 0.932, Test loss: 1.160, Test accuracy: 73.76
Round  64, Global train loss: 0.932, Global test loss: 0.947, Global test accuracy: 96.14
Round  65, Train loss: 1.076, Test loss: 1.159, Test accuracy: 74.18
Round  65, Global train loss: 1.076, Global test loss: 1.056, Global test accuracy: 85.42
Round  66, Train loss: 1.085, Test loss: 1.158, Test accuracy: 74.24
Round  66, Global train loss: 1.085, Global test loss: 0.975, Global test accuracy: 93.72
Round  67, Train loss: 1.087, Test loss: 1.164, Test accuracy: 73.60
Round  67, Global train loss: 1.087, Global test loss: 1.149, Global test accuracy: 77.74
Round  68, Train loss: 0.928, Test loss: 1.164, Test accuracy: 73.56
Round  68, Global train loss: 0.928, Global test loss: 0.945, Global test accuracy: 96.32
Round  69, Train loss: 0.993, Test loss: 1.166, Test accuracy: 73.18
Round  69, Global train loss: 0.993, Global test loss: 0.968, Global test accuracy: 95.12
Round  70, Train loss: 1.076, Test loss: 1.170, Test accuracy: 72.82
Round  70, Global train loss: 1.076, Global test loss: 0.992, Global test accuracy: 92.14
Round  71, Train loss: 1.063, Test loss: 1.170, Test accuracy: 72.88
Round  71, Global train loss: 1.063, Global test loss: 0.998, Global test accuracy: 91.36
Round  72, Train loss: 0.997, Test loss: 1.171, Test accuracy: 72.78
Round  72, Global train loss: 0.997, Global test loss: 0.998, Global test accuracy: 90.78
Round  73, Train loss: 1.036, Test loss: 1.171, Test accuracy: 72.88
Round  73, Global train loss: 1.036, Global test loss: 0.977, Global test accuracy: 93.70
Round  74, Train loss: 0.933, Test loss: 1.170, Test accuracy: 72.92
Round  74, Global train loss: 0.933, Global test loss: 0.941, Global test accuracy: 96.52
Round  75, Train loss: 0.927, Test loss: 1.171, Test accuracy: 72.86
Round  75, Global train loss: 0.927, Global test loss: 0.945, Global test accuracy: 96.32
Round  76, Train loss: 0.978, Test loss: 1.172, Test accuracy: 72.64
Round  76, Global train loss: 0.978, Global test loss: 0.949, Global test accuracy: 95.90
Round  77, Train loss: 0.999, Test loss: 1.170, Test accuracy: 72.86
Round  77, Global train loss: 0.999, Global test loss: 0.953, Global test accuracy: 95.32
Round  78, Train loss: 0.932, Test loss: 1.171, Test accuracy: 72.84
Round  78, Global train loss: 0.932, Global test loss: 0.947, Global test accuracy: 96.14
Round  79, Train loss: 1.030, Test loss: 1.172, Test accuracy: 72.56
Round  79, Global train loss: 1.030, Global test loss: 0.980, Global test accuracy: 93.04
Round  80, Train loss: 0.988, Test loss: 1.173, Test accuracy: 72.28
Round  80, Global train loss: 0.988, Global test loss: 0.972, Global test accuracy: 94.10
Round  81, Train loss: 0.964, Test loss: 1.173, Test accuracy: 72.32
Round  81, Global train loss: 0.964, Global test loss: 0.961, Global test accuracy: 94.78
Round  82, Train loss: 0.997, Test loss: 1.172, Test accuracy: 72.36
Round  82, Global train loss: 0.997, Global test loss: 0.950, Global test accuracy: 95.74
Round  83, Train loss: 0.925, Test loss: 1.173, Test accuracy: 72.24
Round  83, Global train loss: 0.925, Global test loss: 0.945, Global test accuracy: 96.32
Round  84, Train loss: 0.992, Test loss: 1.173, Test accuracy: 72.20
Round  84, Global train loss: 0.992, Global test loss: 0.998, Global test accuracy: 92.24
Round  85, Train loss: 1.020, Test loss: 1.172, Test accuracy: 72.38
Round  85, Global train loss: 1.020, Global test loss: 0.976, Global test accuracy: 93.06
Round  86, Train loss: 0.997, Test loss: 1.171, Test accuracy: 72.38
Round  86, Global train loss: 0.997, Global test loss: 0.961, Global test accuracy: 94.64
Round  87, Train loss: 1.036, Test loss: 1.168, Test accuracy: 72.92
Round  87, Global train loss: 1.036, Global test loss: 1.042, Global test accuracy: 86.72
Round  88, Train loss: 1.018, Test loss: 1.171, Test accuracy: 72.62
Round  88, Global train loss: 1.018, Global test loss: 0.970, Global test accuracy: 94.38
Round  89, Train loss: 0.992, Test loss: 1.172, Test accuracy: 72.54
Round  89, Global train loss: 0.992, Global test loss: 0.951, Global test accuracy: 95.78
Round  90, Train loss: 0.980, Test loss: 1.171, Test accuracy: 72.64
Round  90, Global train loss: 0.980, Global test loss: 0.960, Global test accuracy: 94.94
Round  91, Train loss: 0.979, Test loss: 1.172, Test accuracy: 72.50
Round  91, Global train loss: 0.979, Global test loss: 0.962, Global test accuracy: 95.04
Round  92, Train loss: 0.984, Test loss: 1.171, Test accuracy: 72.56
Round  92, Global train loss: 0.984, Global test loss: 0.966, Global test accuracy: 95.08
Round  93, Train loss: 0.953, Test loss: 1.170, Test accuracy: 72.70
Round  93, Global train loss: 0.953, Global test loss: 0.964, Global test accuracy: 94.62
Round  94, Train loss: 0.925, Test loss: 1.171, Test accuracy: 72.68
Round  94, Global train loss: 0.925, Global test loss: 0.945, Global test accuracy: 96.32/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  95, Train loss: 0.990, Test loss: 1.171, Test accuracy: 72.66
Round  95, Global train loss: 0.990, Global test loss: 0.955, Global test accuracy: 95.08
Round  96, Train loss: 1.076, Test loss: 1.171, Test accuracy: 72.54
Round  96, Global train loss: 1.076, Global test loss: 1.003, Global test accuracy: 90.94
Round  97, Train loss: 0.925, Test loss: 1.171, Test accuracy: 72.52
Round  97, Global train loss: 0.925, Global test loss: 0.944, Global test accuracy: 96.32
Round  98, Train loss: 0.987, Test loss: 1.174, Test accuracy: 72.18
Round  98, Global train loss: 0.987, Global test loss: 0.956, Global test accuracy: 95.08
Round  99, Train loss: 0.966, Test loss: 1.173, Test accuracy: 72.40
Round  99, Global train loss: 0.966, Global test loss: 0.953, Global test accuracy: 95.60
Final Round, Train loss: 0.985, Test loss: 1.176, Test accuracy: 72.20
Final Round, Global train loss: 0.985, Global test loss: 0.953, Global test accuracy: 95.60
Average accuracy final 10 rounds: 72.538 

Average global accuracy final 10 rounds: 94.902 

596.6499481201172
[0.9356262683868408, 1.8712525367736816, 2.6556873321533203, 3.440122127532959, 4.198107004165649, 4.95609188079834, 5.725012302398682, 6.493932723999023, 7.243840217590332, 7.993747711181641, 9.071178913116455, 10.14861011505127, 11.012046337127686, 11.875482559204102, 12.644581079483032, 13.413679599761963, 14.186392068862915, 14.959104537963867, 15.724637031555176, 16.490169525146484, 17.27113366127014, 18.0520977973938, 18.819342613220215, 19.58658742904663, 20.339555501937866, 21.0925235748291, 21.853166341781616, 22.61380910873413, 23.364614963531494, 24.115420818328857, 24.867574214935303, 25.619727611541748, 26.398635387420654, 27.17754316329956, 27.939940929412842, 28.702338695526123, 29.474620819091797, 30.24690294265747, 31.005911827087402, 31.764920711517334, 32.529805183410645, 33.294689655303955, 34.04551362991333, 34.796337604522705, 35.54217720031738, 36.28801679611206, 37.03150177001953, 37.774986743927, 38.76407074928284, 39.75315475463867, 40.516218423843384, 41.279282093048096, 42.03848886489868, 42.79769563674927, 43.56407022476196, 44.33044481277466, 45.083746910095215, 45.83704900741577, 46.57841897010803, 47.31978893280029, 48.08532381057739, 48.85085868835449, 49.62788510322571, 50.404911518096924, 51.16495108604431, 51.9249906539917, 52.74677276611328, 53.56855487823486, 54.352400064468384, 55.136245250701904, 55.913713216781616, 56.69118118286133, 57.43730902671814, 58.18343687057495, 58.932246923446655, 59.68105697631836, 60.49622654914856, 61.31139612197876, 62.12092590332031, 62.930455684661865, 63.70104432106018, 64.4716329574585, 65.25393056869507, 66.03622817993164, 66.81545162200928, 67.59467506408691, 68.39490985870361, 69.19514465332031, 70.22468066215515, 71.25421667098999, 72.07368636131287, 72.89315605163574, 73.69558000564575, 74.49800395965576, 75.2624135017395, 76.02682304382324, 76.77964162826538, 77.53246021270752, 78.31361937522888, 79.09477853775024, 79.84908151626587, 80.6033844947815, 81.36198163032532, 82.12057876586914, 82.87884044647217, 83.6371021270752, 84.40030169487, 85.1635012626648, 86.02648401260376, 86.88946676254272, 87.64156365394592, 88.39366054534912, 89.15003275871277, 89.90640497207642, 90.7172920703888, 91.52817916870117, 92.29553127288818, 93.0628833770752, 93.8459985256195, 94.62911367416382, 95.4058473110199, 96.18258094787598, 96.95983481407166, 97.73708868026733, 98.51194906234741, 99.28680944442749, 100.04358839988708, 100.80036735534668, 101.55107283592224, 102.3017783164978, 103.07913160324097, 103.85648488998413, 104.62733340263367, 105.3981819152832, 106.16126728057861, 106.92435264587402, 107.6916434764862, 108.45893430709839, 109.22548341751099, 109.99203252792358, 110.76164293289185, 111.53125333786011, 112.29103469848633, 113.05081605911255, 113.78528118133545, 114.51974630355835, 115.29919838905334, 116.07865047454834, 116.86417770385742, 117.6497049331665, 118.41544437408447, 119.18118381500244, 119.94306421279907, 120.7049446105957, 121.47080850601196, 122.23667240142822, 123.02050518989563, 123.80433797836304, 124.57932090759277, 125.35430383682251, 126.12300443649292, 126.89170503616333, 127.67104578018188, 128.45038652420044, 129.21792674064636, 129.98546695709229, 130.76554489135742, 131.54562282562256, 132.32708287239075, 133.10854291915894, 133.85666298866272, 134.6047830581665, 135.34974360466003, 136.09470415115356, 136.84684133529663, 137.5989785194397, 138.42601037025452, 139.25304222106934, 140.02730774879456, 140.80157327651978, 141.5544719696045, 142.3073706626892, 143.07417964935303, 143.84098863601685, 144.6200408935547, 145.39909315109253, 146.1395034790039, 146.87991380691528, 147.61648726463318, 148.35306072235107, 149.12335348129272, 149.89364624023438, 150.68718934059143, 151.4807324409485, 152.24085092544556, 153.00096940994263, 153.75523233413696, 154.5094952583313, 155.29342079162598, 156.07734632492065, 157.64935851097107, 159.22137069702148]
[39.1, 39.1, 80.02, 80.02, 80.52, 80.52, 80.08, 80.08, 80.36, 80.36, 79.56, 79.56, 80.74, 80.74, 80.94, 80.94, 81.48, 81.48, 83.0, 83.0, 82.48, 82.48, 82.44, 82.44, 82.16, 82.16, 82.4, 82.4, 81.9, 81.9, 81.82, 81.82, 81.84, 81.84, 81.5, 81.5, 79.96, 79.96, 79.64, 79.64, 79.38, 79.38, 79.44, 79.44, 78.86, 78.86, 78.08, 78.08, 77.76, 77.76, 78.28, 78.28, 78.12, 78.12, 77.46, 77.46, 77.5, 77.5, 78.24, 78.24, 77.96, 77.96, 77.66, 77.66, 77.22, 77.22, 77.28, 77.28, 76.92, 76.92, 77.16, 77.16, 76.32, 76.32, 76.06, 76.06, 75.98, 75.98, 75.78, 75.78, 74.9, 74.9, 74.68, 74.68, 75.4, 75.4, 75.64, 75.64, 75.58, 75.58, 74.86, 74.86, 74.92, 74.92, 74.5, 74.5, 74.66, 74.66, 73.92, 73.92, 74.2, 74.2, 74.06, 74.06, 74.44, 74.44, 74.3, 74.3, 74.06, 74.06, 73.84, 73.84, 73.48, 73.48, 73.94, 73.94, 74.16, 74.16, 74.22, 74.22, 74.08, 74.08, 74.08, 74.08, 73.46, 73.46, 73.7, 73.7, 73.76, 73.76, 74.18, 74.18, 74.24, 74.24, 73.6, 73.6, 73.56, 73.56, 73.18, 73.18, 72.82, 72.82, 72.88, 72.88, 72.78, 72.78, 72.88, 72.88, 72.92, 72.92, 72.86, 72.86, 72.64, 72.64, 72.86, 72.86, 72.84, 72.84, 72.56, 72.56, 72.28, 72.28, 72.32, 72.32, 72.36, 72.36, 72.24, 72.24, 72.2, 72.2, 72.38, 72.38, 72.38, 72.38, 72.92, 72.92, 72.62, 72.62, 72.54, 72.54, 72.64, 72.64, 72.5, 72.5, 72.56, 72.56, 72.7, 72.7, 72.68, 72.68, 72.66, 72.66, 72.54, 72.54, 72.52, 72.52, 72.18, 72.18, 72.4, 72.4, 72.2, 72.2]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.4 , level_n_lowerb:0.8  

   Client 7, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.593, Test loss: 1.562, Test accuracy: 38.80
Round   0, Global train loss: 1.593, Global test loss: 1.566, Global test accuracy: 39.32
Round   1, Train loss: 1.534, Test loss: 1.446, Test accuracy: 60.64
Round   1, Global train loss: 1.534, Global test loss: 1.446, Global test accuracy: 65.86
Round   2, Train loss: 1.323, Test loss: 1.275, Test accuracy: 71.52
Round   2, Global train loss: 1.323, Global test loss: 1.135, Global test accuracy: 85.68
Round   3, Train loss: 1.541, Test loss: 1.183, Test accuracy: 83.78
Round   3, Global train loss: 1.541, Global test loss: 1.097, Global test accuracy: 93.16
Round   4, Train loss: 1.174, Test loss: 1.130, Test accuracy: 85.50
Round   4, Global train loss: 1.174, Global test loss: 0.989, Global test accuracy: 95.52
Round   5, Train loss: 1.380, Test loss: 1.083, Test accuracy: 86.58
Round   5, Global train loss: 1.380, Global test loss: 0.999, Global test accuracy: 93.42
Round   6, Train loss: 1.337, Test loss: 1.065, Test accuracy: 87.02
Round   6, Global train loss: 1.337, Global test loss: 0.973, Global test accuracy: 95.78
Round   7, Train loss: 0.983, Test loss: 1.058, Test accuracy: 87.36
Round   7, Global train loss: 0.983, Global test loss: 0.956, Global test accuracy: 96.12
Round   8, Train loss: 1.170, Test loss: 0.991, Test accuracy: 93.32
Round   8, Global train loss: 1.170, Global test loss: 0.960, Global test accuracy: 95.68
Round   9, Train loss: 1.364, Test loss: 0.987, Test accuracy: 93.28
Round   9, Global train loss: 1.364, Global test loss: 0.959, Global test accuracy: 95.68
Round  10, Train loss: 1.173, Test loss: 0.989, Test accuracy: 93.06
Round  10, Global train loss: 1.173, Global test loss: 0.953, Global test accuracy: 96.08
Round  11, Train loss: 1.335, Test loss: 0.978, Test accuracy: 93.76
Round  11, Global train loss: 1.335, Global test loss: 0.961, Global test accuracy: 95.24
Round  12, Train loss: 0.964, Test loss: 0.977, Test accuracy: 93.72
Round  12, Global train loss: 0.964, Global test loss: 0.952, Global test accuracy: 95.90
Round  13, Train loss: 1.174, Test loss: 0.973, Test accuracy: 93.92
Round  13, Global train loss: 1.174, Global test loss: 0.947, Global test accuracy: 96.44
Round  14, Train loss: 1.159, Test loss: 0.974, Test accuracy: 93.74
Round  14, Global train loss: 1.159, Global test loss: 0.949, Global test accuracy: 96.32
Round  15, Train loss: 1.325, Test loss: 0.975, Test accuracy: 93.68
Round  15, Global train loss: 1.325, Global test loss: 0.950, Global test accuracy: 96.12
Round  16, Train loss: 1.362, Test loss: 0.980, Test accuracy: 93.10
Round  16, Global train loss: 1.362, Global test loss: 0.972, Global test accuracy: 93.76
Round  17, Train loss: 1.318, Test loss: 0.980, Test accuracy: 93.10
Round  17, Global train loss: 1.318, Global test loss: 0.972, Global test accuracy: 93.56
Round  18, Train loss: 1.347, Test loss: 0.984, Test accuracy: 92.54
Round  18, Global train loss: 1.347, Global test loss: 0.977, Global test accuracy: 93.20
Round  19, Train loss: 1.121, Test loss: 0.983, Test accuracy: 92.62
Round  19, Global train loss: 1.121, Global test loss: 0.953, Global test accuracy: 95.66
Round  20, Train loss: 1.152, Test loss: 0.981, Test accuracy: 92.96
Round  20, Global train loss: 1.152, Global test loss: 0.971, Global test accuracy: 93.60
Round  21, Train loss: 0.927, Test loss: 0.979, Test accuracy: 93.02
Round  21, Global train loss: 0.927, Global test loss: 0.942, Global test accuracy: 96.74
Round  22, Train loss: 1.189, Test loss: 0.977, Test accuracy: 93.14
Round  22, Global train loss: 1.189, Global test loss: 0.957, Global test accuracy: 94.94
Round  23, Train loss: 1.152, Test loss: 0.976, Test accuracy: 93.32
Round  23, Global train loss: 1.152, Global test loss: 0.956, Global test accuracy: 95.54
Round  24, Train loss: 1.317, Test loss: 0.979, Test accuracy: 92.96
Round  24, Global train loss: 1.317, Global test loss: 0.977, Global test accuracy: 93.22
Round  25, Train loss: 1.116, Test loss: 0.980, Test accuracy: 92.72
Round  25, Global train loss: 1.116, Global test loss: 0.960, Global test accuracy: 94.62
Round  26, Train loss: 1.141, Test loss: 0.979, Test accuracy: 92.80
Round  26, Global train loss: 1.141, Global test loss: 0.960, Global test accuracy: 94.66
Round  27, Train loss: 1.152, Test loss: 0.978, Test accuracy: 92.76
Round  27, Global train loss: 1.152, Global test loss: 0.958, Global test accuracy: 95.10
Round  28, Train loss: 0.953, Test loss: 0.979, Test accuracy: 92.64
Round  28, Global train loss: 0.953, Global test loss: 0.943, Global test accuracy: 96.48
Round  29, Train loss: 0.983, Test loss: 0.979, Test accuracy: 92.72
Round  29, Global train loss: 0.983, Global test loss: 0.946, Global test accuracy: 96.08
Round  30, Train loss: 1.306, Test loss: 0.981, Test accuracy: 92.40
Round  30, Global train loss: 1.306, Global test loss: 0.956, Global test accuracy: 95.32
Round  31, Train loss: 0.980, Test loss: 0.983, Test accuracy: 92.12
Round  31, Global train loss: 0.980, Global test loss: 0.951, Global test accuracy: 95.52
Round  32, Train loss: 1.332, Test loss: 0.980, Test accuracy: 92.36
Round  32, Global train loss: 1.332, Global test loss: 0.974, Global test accuracy: 92.76
Round  33, Train loss: 1.136, Test loss: 0.981, Test accuracy: 92.24
Round  33, Global train loss: 1.136, Global test loss: 0.975, Global test accuracy: 92.98
Round  34, Train loss: 0.947, Test loss: 0.980, Test accuracy: 92.32
Round  34, Global train loss: 0.947, Global test loss: 0.948, Global test accuracy: 95.90
Round  35, Train loss: 1.295, Test loss: 0.979, Test accuracy: 92.58
Round  35, Global train loss: 1.295, Global test loss: 0.961, Global test accuracy: 94.52
Round  36, Train loss: 1.134, Test loss: 0.981, Test accuracy: 92.52
Round  36, Global train loss: 1.134, Global test loss: 0.951, Global test accuracy: 95.32
Round  37, Train loss: 1.320, Test loss: 0.982, Test accuracy: 92.34
Round  37, Global train loss: 1.320, Global test loss: 0.982, Global test accuracy: 92.18
Round  38, Train loss: 1.097, Test loss: 0.982, Test accuracy: 92.36
Round  38, Global train loss: 1.097, Global test loss: 0.946, Global test accuracy: 96.22
Round  39, Train loss: 0.941, Test loss: 0.980, Test accuracy: 92.50
Round  39, Global train loss: 0.941, Global test loss: 0.945, Global test accuracy: 96.26
Round  40, Train loss: 1.133, Test loss: 0.981, Test accuracy: 92.44
Round  40, Global train loss: 1.133, Global test loss: 0.958, Global test accuracy: 94.86
Round  41, Train loss: 1.138, Test loss: 0.978, Test accuracy: 92.70
Round  41, Global train loss: 1.138, Global test loss: 0.957, Global test accuracy: 94.88
Round  42, Train loss: 1.282, Test loss: 0.983, Test accuracy: 92.24
Round  42, Global train loss: 1.282, Global test loss: 0.966, Global test accuracy: 94.26
Round  43, Train loss: 1.300, Test loss: 0.985, Test accuracy: 92.06
Round  43, Global train loss: 1.300, Global test loss: 0.966, Global test accuracy: 94.08
Round  44, Train loss: 1.292, Test loss: 0.986, Test accuracy: 92.10
Round  44, Global train loss: 1.292, Global test loss: 0.974, Global test accuracy: 92.92
Round  45, Train loss: 1.153, Test loss: 0.986, Test accuracy: 92.18
Round  45, Global train loss: 1.153, Global test loss: 0.969, Global test accuracy: 93.66
Round  46, Train loss: 0.916, Test loss: 0.987, Test accuracy: 92.08
Round  46, Global train loss: 0.916, Global test loss: 0.941, Global test accuracy: 96.70
Round  47, Train loss: 1.100, Test loss: 0.984, Test accuracy: 92.36
Round  47, Global train loss: 1.100, Global test loss: 0.951, Global test accuracy: 95.62
Round  48, Train loss: 0.940, Test loss: 0.983, Test accuracy: 92.46
Round  48, Global train loss: 0.940, Global test loss: 0.947, Global test accuracy: 96.02
Round  49, Train loss: 1.124, Test loss: 0.983, Test accuracy: 92.50
Round  49, Global train loss: 1.124, Global test loss: 0.954, Global test accuracy: 95.54
Round  50, Train loss: 1.271, Test loss: 0.988, Test accuracy: 91.90
Round  50, Global train loss: 1.271, Global test loss: 0.971, Global test accuracy: 93.54
Round  51, Train loss: 1.106, Test loss: 0.993, Test accuracy: 91.20
Round  51, Global train loss: 1.106, Global test loss: 0.953, Global test accuracy: 95.64
Round  52, Train loss: 1.132, Test loss: 0.992, Test accuracy: 91.36
Round  52, Global train loss: 1.132, Global test loss: 0.963, Global test accuracy: 94.62
Round  53, Train loss: 1.124, Test loss: 0.992, Test accuracy: 91.34
Round  53, Global train loss: 1.124, Global test loss: 0.969, Global test accuracy: 93.96
Round  54, Train loss: 1.095, Test loss: 0.992, Test accuracy: 91.22
Round  54, Global train loss: 1.095, Global test loss: 0.962, Global test accuracy: 94.14
Round  55, Train loss: 1.274, Test loss: 0.996, Test accuracy: 90.86
Round  55, Global train loss: 1.274, Global test loss: 0.966, Global test accuracy: 94.16
Round  56, Train loss: 0.944, Test loss: 0.995, Test accuracy: 91.00
Round  56, Global train loss: 0.944, Global test loss: 0.948, Global test accuracy: 95.82
Round  57, Train loss: 1.124, Test loss: 0.996, Test accuracy: 90.96
Round  57, Global train loss: 1.124, Global test loss: 0.965, Global test accuracy: 94.08
Round  58, Train loss: 1.286, Test loss: 0.997, Test accuracy: 90.82
Round  58, Global train loss: 1.286, Global test loss: 0.976, Global test accuracy: 93.40
Round  59, Train loss: 1.111, Test loss: 0.998, Test accuracy: 90.72
Round  59, Global train loss: 1.111, Global test loss: 0.966, Global test accuracy: 93.86
Round  60, Train loss: 1.271, Test loss: 1.004, Test accuracy: 90.00
Round  60, Global train loss: 1.271, Global test loss: 0.998, Global test accuracy: 90.60
Round  61, Train loss: 1.098, Test loss: 1.005, Test accuracy: 89.96
Round  61, Global train loss: 1.098, Global test loss: 0.959, Global test accuracy: 94.78
Round  62, Train loss: 1.119, Test loss: 1.004, Test accuracy: 90.14
Round  62, Global train loss: 1.119, Global test loss: 0.973, Global test accuracy: 93.46
Round  63, Train loss: 1.114, Test loss: 1.003, Test accuracy: 90.24
Round  63, Global train loss: 1.114, Global test loss: 0.968, Global test accuracy: 93.78
Round  64, Train loss: 1.089, Test loss: 1.000, Test accuracy: 90.48
Round  64, Global train loss: 1.089, Global test loss: 0.960, Global test accuracy: 94.60
Round  65, Train loss: 0.964, Test loss: 1.003, Test accuracy: 90.28
Round  65, Global train loss: 0.964, Global test loss: 0.961, Global test accuracy: 94.70
Round  66, Train loss: 1.108, Test loss: 0.999, Test accuracy: 90.62
Round  66, Global train loss: 1.108, Global test loss: 0.966, Global test accuracy: 94.04
Round  67, Train loss: 1.277, Test loss: 1.004, Test accuracy: 90.20
Round  67, Global train loss: 1.277, Global test loss: 0.988, Global test accuracy: 91.84
Round  68, Train loss: 0.914, Test loss: 1.004, Test accuracy: 90.24
Round  68, Global train loss: 0.914, Global test loss: 0.946, Global test accuracy: 96.12
Round  69, Train loss: 1.109, Test loss: 1.004, Test accuracy: 90.30
Round  69, Global train loss: 1.109, Global test loss: 0.960, Global test accuracy: 94.42
Round  70, Train loss: 1.287, Test loss: 1.005, Test accuracy: 90.16
Round  70, Global train loss: 1.287, Global test loss: 0.997, Global test accuracy: 91.04
Round  71, Train loss: 1.136, Test loss: 1.008, Test accuracy: 89.92
Round  71, Global train loss: 1.136, Global test loss: 0.991, Global test accuracy: 91.30
Round  72, Train loss: 0.938, Test loss: 1.008, Test accuracy: 89.74
Round  72, Global train loss: 0.938, Global test loss: 0.957, Global test accuracy: 95.08
Round  73, Train loss: 0.961, Test loss: 1.007, Test accuracy: 89.92
Round  73, Global train loss: 0.961, Global test loss: 0.960, Global test accuracy: 94.58
Round  74, Train loss: 1.088, Test loss: 1.007, Test accuracy: 89.74
Round  74, Global train loss: 1.088, Global test loss: 0.966, Global test accuracy: 93.68
Round  75, Train loss: 0.911, Test loss: 1.008, Test accuracy: 89.72
Round  75, Global train loss: 0.911, Global test loss: 0.946, Global test accuracy: 95.96
Round  76, Train loss: 0.937, Test loss: 1.009, Test accuracy: 89.64
Round  76, Global train loss: 0.937, Global test loss: 0.952, Global test accuracy: 95.30
Round  77, Train loss: 1.111, Test loss: 1.005, Test accuracy: 90.02
Round  77, Global train loss: 1.111, Global test loss: 0.972, Global test accuracy: 93.24
Round  78, Train loss: 1.084, Test loss: 1.006, Test accuracy: 90.00
Round  78, Global train loss: 1.084, Global test loss: 0.961, Global test accuracy: 94.48
Round  79, Train loss: 0.958, Test loss: 1.006, Test accuracy: 89.96
Round  79, Global train loss: 0.958, Global test loss: 0.961, Global test accuracy: 94.42
Round  80, Train loss: 1.104, Test loss: 1.008, Test accuracy: 89.88
Round  80, Global train loss: 1.104, Global test loss: 0.969, Global test accuracy: 93.68
Round  81, Train loss: 1.117, Test loss: 1.005, Test accuracy: 90.06
Round  81, Global train loss: 1.117, Global test loss: 0.962, Global test accuracy: 94.66
Round  82, Train loss: 1.109, Test loss: 1.005, Test accuracy: 90.00
Round  82, Global train loss: 1.109, Global test loss: 0.980, Global test accuracy: 92.56
Round  83, Train loss: 0.910, Test loss: 1.006, Test accuracy: 90.00
Round  83, Global train loss: 0.910, Global test loss: 0.948, Global test accuracy: 95.90
Round  84, Train loss: 1.284, Test loss: 1.006, Test accuracy: 90.04
Round  84, Global train loss: 1.284, Global test loss: 1.014, Global test accuracy: 88.94
Round  85, Train loss: 1.427, Test loss: 1.012, Test accuracy: 89.34
Round  85, Global train loss: 1.427, Global test loss: 1.025, Global test accuracy: 88.14
Round  86, Train loss: 1.246, Test loss: 1.010, Test accuracy: 89.48
Round  86, Global train loss: 1.246, Global test loss: 0.986, Global test accuracy: 91.98
Round  87, Train loss: 1.240, Test loss: 1.012, Test accuracy: 89.30
Round  87, Global train loss: 1.240, Global test loss: 0.982, Global test accuracy: 92.54
Round  88, Train loss: 1.236, Test loss: 1.009, Test accuracy: 89.74
Round  88, Global train loss: 1.236, Global test loss: 0.990, Global test accuracy: 91.70
Round  89, Train loss: 1.105, Test loss: 1.012, Test accuracy: 89.32
Round  89, Global train loss: 1.105, Global test loss: 0.985, Global test accuracy: 92.18
Round  90, Train loss: 0.933, Test loss: 1.013, Test accuracy: 89.22
Round  90, Global train loss: 0.933, Global test loss: 0.959, Global test accuracy: 94.52
Round  91, Train loss: 0.932, Test loss: 1.013, Test accuracy: 89.20
Round  91, Global train loss: 0.932, Global test loss: 0.953, Global test accuracy: 95.58
Round  92, Train loss: 1.099, Test loss: 1.013, Test accuracy: 89.00
Round  92, Global train loss: 1.099, Global test loss: 0.970, Global test accuracy: 93.66
Round  93, Train loss: 1.247, Test loss: 1.014, Test accuracy: 89.04
Round  93, Global train loss: 1.247, Global test loss: 1.009, Global test accuracy: 89.52
Round  94, Train loss: 0.911, Test loss: 1.015, Test accuracy: 88.92
Round  94, Global train loss: 0.911, Global test loss: 0.952, Global test accuracy: 95.60/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  95, Train loss: 1.105, Test loss: 1.012, Test accuracy: 89.22
Round  95, Global train loss: 1.105, Global test loss: 0.974, Global test accuracy: 93.18
Round  96, Train loss: 1.266, Test loss: 1.014, Test accuracy: 89.06
Round  96, Global train loss: 1.266, Global test loss: 1.013, Global test accuracy: 89.22
Round  97, Train loss: 0.911, Test loss: 1.013, Test accuracy: 89.14
Round  97, Global train loss: 0.911, Global test loss: 0.949, Global test accuracy: 95.86
Round  98, Train loss: 1.104, Test loss: 1.011, Test accuracy: 89.38
Round  98, Global train loss: 1.104, Global test loss: 0.973, Global test accuracy: 93.10
Round  99, Train loss: 1.105, Test loss: 1.011, Test accuracy: 89.34
Round  99, Global train loss: 1.105, Global test loss: 0.976, Global test accuracy: 93.14
Final Round, Train loss: 1.118, Test loss: 1.018, Test accuracy: 88.64
Final Round, Global train loss: 1.118, Global test loss: 0.976, Global test accuracy: 93.14
Average accuracy final 10 rounds: 89.15199999999999 

Average global accuracy final 10 rounds: 93.338 

591.8919506072998
[0.870511531829834, 1.741023063659668, 2.497434377670288, 3.253845691680908, 4.006342649459839, 4.7588396072387695, 5.542868614196777, 6.326897621154785, 7.087073802947998, 7.847249984741211, 8.59069275856018, 9.33413553237915, 10.100072860717773, 10.866010189056396, 11.627032041549683, 12.388053894042969, 13.159669399261475, 13.93128490447998, 14.705969333648682, 15.480653762817383, 16.257535696029663, 17.034417629241943, 17.784096002578735, 18.533774375915527, 19.29076361656189, 20.047752857208252, 20.82098960876465, 21.594226360321045, 22.3587167263031, 23.123207092285156, 23.881898403167725, 24.640589714050293, 25.456639289855957, 26.27268886566162, 27.026907920837402, 27.781126976013184, 28.539980173110962, 29.29883337020874, 30.04664659500122, 30.7944598197937, 31.53791117668152, 32.281362533569336, 33.04848861694336, 33.81561470031738, 34.56693124771118, 35.31824779510498, 36.07173228263855, 36.82521677017212, 37.57709884643555, 38.328980922698975, 39.07292556762695, 39.81687021255493, 40.586365938186646, 41.35586166381836, 42.12949752807617, 42.903133392333984, 43.641111850738525, 44.379090309143066, 45.12928891181946, 45.87948751449585, 46.61742925643921, 47.35537099838257, 48.12126183509827, 48.887152671813965, 49.68017530441284, 50.47319793701172, 51.23295617103577, 51.992714405059814, 52.74907398223877, 53.505433559417725, 54.276296615600586, 55.04715967178345, 55.808605432510376, 56.570051193237305, 57.33544611930847, 58.10084104537964, 58.96847152709961, 59.83610200881958, 60.769446849823, 61.702791690826416, 62.45724391937256, 63.2116961479187, 64.04917502403259, 64.88665390014648, 65.65573763847351, 66.42482137680054, 67.19197058677673, 67.95911979675293, 68.720379114151, 69.48163843154907, 70.2231719493866, 70.96470546722412, 71.69858002662659, 72.43245458602905, 73.17383074760437, 73.91520690917969, 74.64920353889465, 75.38320016860962, 76.11653709411621, 76.8498740196228, 77.61107301712036, 78.37227201461792, 79.09286832809448, 79.81346464157104, 80.54198479652405, 81.27050495147705, 82.04065346717834, 82.81080198287964, 83.57295346260071, 84.33510494232178, 85.10197186470032, 85.86883878707886, 86.63133311271667, 87.39382743835449, 88.15286946296692, 88.91191148757935, 89.69117617607117, 90.47044086456299, 91.23169994354248, 91.99295902252197, 92.74536609649658, 93.49777317047119, 94.26751017570496, 95.03724718093872, 95.79214715957642, 96.54704713821411, 97.31679773330688, 98.08654832839966, 98.86342191696167, 99.64029550552368, 100.39901781082153, 101.15774011611938, 101.91402101516724, 102.67030191421509, 103.43432402610779, 104.19834613800049, 104.93789386749268, 105.67744159698486, 106.45904397964478, 107.24064636230469, 107.99236273765564, 108.74407911300659, 109.51666808128357, 110.28925704956055, 111.04591822624207, 111.80257940292358, 112.58441853523254, 113.3662576675415, 114.1607551574707, 114.9552526473999, 115.73142385482788, 116.50759506225586, 117.2742395401001, 118.04088401794434, 118.84553074836731, 119.65017747879028, 120.42268204689026, 121.19518661499023, 121.93200349807739, 122.66882038116455, 123.4509265422821, 124.23303270339966, 125.00676774978638, 125.7805027961731, 126.54678869247437, 127.31307458877563, 128.0797894001007, 128.84650421142578, 129.6240508556366, 130.4015974998474, 131.19311332702637, 131.98462915420532, 132.784912109375, 133.58519506454468, 134.33319473266602, 135.08119440078735, 135.84607553482056, 136.61095666885376, 137.38949632644653, 138.1680359840393, 138.97188711166382, 139.77573823928833, 140.53841710090637, 141.3010959625244, 142.08428525924683, 142.86747455596924, 143.62526297569275, 144.38305139541626, 145.15696144104004, 145.93087148666382, 146.698792219162, 147.46671295166016, 148.21622562408447, 148.9657382965088, 149.7623426914215, 150.55894708633423, 151.32717204093933, 152.09539699554443, 152.8654909133911, 153.6355848312378, 155.15504550933838, 156.67450618743896]
[38.8, 38.8, 60.64, 60.64, 71.52, 71.52, 83.78, 83.78, 85.5, 85.5, 86.58, 86.58, 87.02, 87.02, 87.36, 87.36, 93.32, 93.32, 93.28, 93.28, 93.06, 93.06, 93.76, 93.76, 93.72, 93.72, 93.92, 93.92, 93.74, 93.74, 93.68, 93.68, 93.1, 93.1, 93.1, 93.1, 92.54, 92.54, 92.62, 92.62, 92.96, 92.96, 93.02, 93.02, 93.14, 93.14, 93.32, 93.32, 92.96, 92.96, 92.72, 92.72, 92.8, 92.8, 92.76, 92.76, 92.64, 92.64, 92.72, 92.72, 92.4, 92.4, 92.12, 92.12, 92.36, 92.36, 92.24, 92.24, 92.32, 92.32, 92.58, 92.58, 92.52, 92.52, 92.34, 92.34, 92.36, 92.36, 92.5, 92.5, 92.44, 92.44, 92.7, 92.7, 92.24, 92.24, 92.06, 92.06, 92.1, 92.1, 92.18, 92.18, 92.08, 92.08, 92.36, 92.36, 92.46, 92.46, 92.5, 92.5, 91.9, 91.9, 91.2, 91.2, 91.36, 91.36, 91.34, 91.34, 91.22, 91.22, 90.86, 90.86, 91.0, 91.0, 90.96, 90.96, 90.82, 90.82, 90.72, 90.72, 90.0, 90.0, 89.96, 89.96, 90.14, 90.14, 90.24, 90.24, 90.48, 90.48, 90.28, 90.28, 90.62, 90.62, 90.2, 90.2, 90.24, 90.24, 90.3, 90.3, 90.16, 90.16, 89.92, 89.92, 89.74, 89.74, 89.92, 89.92, 89.74, 89.74, 89.72, 89.72, 89.64, 89.64, 90.02, 90.02, 90.0, 90.0, 89.96, 89.96, 89.88, 89.88, 90.06, 90.06, 90.0, 90.0, 90.0, 90.0, 90.04, 90.04, 89.34, 89.34, 89.48, 89.48, 89.3, 89.3, 89.74, 89.74, 89.32, 89.32, 89.22, 89.22, 89.2, 89.2, 89.0, 89.0, 89.04, 89.04, 88.92, 88.92, 89.22, 89.22, 89.06, 89.06, 89.14, 89.14, 89.38, 89.38, 89.34, 89.34, 88.64, 88.64]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.4 , level_n_lowerb:0.8  

   Client 9, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
prox
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.600, Test loss: 1.587, Test accuracy: 64.78
Round   0, Global train loss: 1.600, Global test loss: 1.588, Global test accuracy: 65.34
Round   1, Train loss: 1.522, Test loss: 1.397, Test accuracy: 82.92
Round   1, Global train loss: 1.522, Global test loss: 1.390, Global test accuracy: 86.76
Round   2, Train loss: 1.320, Test loss: 1.266, Test accuracy: 82.50
Round   2, Global train loss: 1.320, Global test loss: 1.142, Global test accuracy: 88.42
Round   3, Train loss: 1.360, Test loss: 1.184, Test accuracy: 86.38
Round   3, Global train loss: 1.360, Global test loss: 1.064, Global test accuracy: 93.56
Round   4, Train loss: 1.352, Test loss: 1.119, Test accuracy: 89.22
Round   4, Global train loss: 1.352, Global test loss: 1.031, Global test accuracy: 94.04
Round   5, Train loss: 1.043, Test loss: 1.091, Test accuracy: 90.82
Round   5, Global train loss: 1.043, Global test loss: 0.993, Global test accuracy: 93.64
Round   6, Train loss: 1.143, Test loss: 1.069, Test accuracy: 91.38
Round   6, Global train loss: 1.143, Global test loss: 0.965, Global test accuracy: 96.00
Round   7, Train loss: 1.179, Test loss: 1.066, Test accuracy: 91.68
Round   7, Global train loss: 1.179, Global test loss: 0.960, Global test accuracy: 96.28
Round   8, Train loss: 1.180, Test loss: 0.999, Test accuracy: 93.38
Round   8, Global train loss: 1.180, Global test loss: 0.963, Global test accuracy: 95.72
Round   9, Train loss: 1.168, Test loss: 0.998, Test accuracy: 93.10
Round   9, Global train loss: 1.168, Global test loss: 0.972, Global test accuracy: 93.92
Round  10, Train loss: 1.172, Test loss: 1.000, Test accuracy: 92.66
Round  10, Global train loss: 1.172, Global test loss: 0.951, Global test accuracy: 96.68
Round  11, Train loss: 1.175, Test loss: 0.985, Test accuracy: 93.10
Round  11, Global train loss: 1.175, Global test loss: 0.950, Global test accuracy: 96.46
Round  12, Train loss: 1.165, Test loss: 0.974, Test accuracy: 94.06
Round  12, Global train loss: 1.165, Global test loss: 0.947, Global test accuracy: 96.62
Round  13, Train loss: 1.364, Test loss: 0.977, Test accuracy: 93.86
Round  13, Global train loss: 1.364, Global test loss: 0.962, Global test accuracy: 94.70
Round  14, Train loss: 1.169, Test loss: 0.974, Test accuracy: 94.10
Round  14, Global train loss: 1.169, Global test loss: 0.953, Global test accuracy: 96.12
Round  15, Train loss: 1.317, Test loss: 0.971, Test accuracy: 94.32
Round  15, Global train loss: 1.317, Global test loss: 0.959, Global test accuracy: 95.12
Round  16, Train loss: 1.010, Test loss: 0.970, Test accuracy: 94.48
Round  16, Global train loss: 1.010, Global test loss: 0.945, Global test accuracy: 96.58
Round  17, Train loss: 1.163, Test loss: 0.968, Test accuracy: 94.60
Round  17, Global train loss: 1.163, Global test loss: 0.949, Global test accuracy: 96.34
Round  18, Train loss: 1.358, Test loss: 0.965, Test accuracy: 94.64
Round  18, Global train loss: 1.358, Global test loss: 0.957, Global test accuracy: 95.64
Round  19, Train loss: 1.318, Test loss: 0.967, Test accuracy: 94.34
Round  19, Global train loss: 1.318, Global test loss: 0.950, Global test accuracy: 96.36
Round  20, Train loss: 1.198, Test loss: 0.967, Test accuracy: 94.52
Round  20, Global train loss: 1.198, Global test loss: 0.948, Global test accuracy: 96.20
Round  21, Train loss: 1.126, Test loss: 0.965, Test accuracy: 94.66
Round  21, Global train loss: 1.126, Global test loss: 0.944, Global test accuracy: 96.68
Round  22, Train loss: 1.189, Test loss: 0.969, Test accuracy: 94.12
Round  22, Global train loss: 1.189, Global test loss: 0.947, Global test accuracy: 96.18
Round  23, Train loss: 0.957, Test loss: 0.969, Test accuracy: 94.14
Round  23, Global train loss: 0.957, Global test loss: 0.944, Global test accuracy: 96.58
Round  24, Train loss: 1.163, Test loss: 0.971, Test accuracy: 94.02
Round  24, Global train loss: 1.163, Global test loss: 0.945, Global test accuracy: 96.38
Round  25, Train loss: 1.164, Test loss: 0.972, Test accuracy: 93.82
Round  25, Global train loss: 1.164, Global test loss: 0.949, Global test accuracy: 96.12
Round  26, Train loss: 1.156, Test loss: 0.970, Test accuracy: 94.02
Round  26, Global train loss: 1.156, Global test loss: 0.951, Global test accuracy: 95.66
Round  27, Train loss: 1.349, Test loss: 0.968, Test accuracy: 94.18
Round  27, Global train loss: 1.349, Global test loss: 0.950, Global test accuracy: 96.00
Round  28, Train loss: 1.148, Test loss: 0.968, Test accuracy: 94.24
Round  28, Global train loss: 1.148, Global test loss: 0.957, Global test accuracy: 95.12
Round  29, Train loss: 0.990, Test loss: 0.970, Test accuracy: 93.98
Round  29, Global train loss: 0.990, Global test loss: 0.944, Global test accuracy: 96.34
Round  30, Train loss: 1.310, Test loss: 0.970, Test accuracy: 93.82
Round  30, Global train loss: 1.310, Global test loss: 0.953, Global test accuracy: 95.68
Round  31, Train loss: 1.175, Test loss: 0.973, Test accuracy: 93.48
Round  31, Global train loss: 1.175, Global test loss: 0.960, Global test accuracy: 94.80
Round  32, Train loss: 1.191, Test loss: 0.974, Test accuracy: 93.34
Round  32, Global train loss: 1.191, Global test loss: 0.957, Global test accuracy: 95.22
Round  33, Train loss: 1.184, Test loss: 0.972, Test accuracy: 93.56
Round  33, Global train loss: 1.184, Global test loss: 0.949, Global test accuracy: 96.04
Round  34, Train loss: 1.151, Test loss: 0.974, Test accuracy: 93.40
Round  34, Global train loss: 1.151, Global test loss: 0.953, Global test accuracy: 95.44
Round  35, Train loss: 1.493, Test loss: 0.973, Test accuracy: 93.40
Round  35, Global train loss: 1.493, Global test loss: 0.960, Global test accuracy: 94.94
Round  36, Train loss: 1.142, Test loss: 0.973, Test accuracy: 93.44
Round  36, Global train loss: 1.142, Global test loss: 0.956, Global test accuracy: 95.22
Round  37, Train loss: 1.180, Test loss: 0.979, Test accuracy: 92.94
Round  37, Global train loss: 1.180, Global test loss: 0.969, Global test accuracy: 94.02
Round  38, Train loss: 1.302, Test loss: 0.978, Test accuracy: 93.00
Round  38, Global train loss: 1.302, Global test loss: 0.965, Global test accuracy: 94.30
Round  39, Train loss: 1.146, Test loss: 0.980, Test accuracy: 92.70
Round  39, Global train loss: 1.146, Global test loss: 0.955, Global test accuracy: 95.42
Round  40, Train loss: 1.327, Test loss: 0.978, Test accuracy: 92.96
Round  40, Global train loss: 1.327, Global test loss: 0.958, Global test accuracy: 95.16
Round  41, Train loss: 0.997, Test loss: 0.979, Test accuracy: 92.72
Round  41, Global train loss: 0.997, Global test loss: 0.950, Global test accuracy: 95.70
Round  42, Train loss: 1.485, Test loss: 0.979, Test accuracy: 92.80
Round  42, Global train loss: 1.485, Global test loss: 0.970, Global test accuracy: 93.86
Round  43, Train loss: 1.155, Test loss: 0.982, Test accuracy: 92.50
Round  43, Global train loss: 1.155, Global test loss: 0.954, Global test accuracy: 95.44
Round  44, Train loss: 0.959, Test loss: 0.981, Test accuracy: 92.68
Round  44, Global train loss: 0.959, Global test loss: 0.948, Global test accuracy: 95.94
Round  45, Train loss: 1.166, Test loss: 0.983, Test accuracy: 92.36
Round  45, Global train loss: 1.166, Global test loss: 0.957, Global test accuracy: 94.80
Round  46, Train loss: 1.299, Test loss: 0.986, Test accuracy: 92.16
Round  46, Global train loss: 1.299, Global test loss: 0.965, Global test accuracy: 94.40
Round  47, Train loss: 1.152, Test loss: 0.988, Test accuracy: 92.00
Round  47, Global train loss: 1.152, Global test loss: 0.957, Global test accuracy: 95.20
Round  48, Train loss: 1.131, Test loss: 0.985, Test accuracy: 92.24
Round  48, Global train loss: 1.131, Global test loss: 0.954, Global test accuracy: 95.50
Round  49, Train loss: 1.133, Test loss: 0.984, Test accuracy: 92.22
Round  49, Global train loss: 1.133, Global test loss: 0.957, Global test accuracy: 95.08
Round  50, Train loss: 1.138, Test loss: 0.984, Test accuracy: 92.32
Round  50, Global train loss: 1.138, Global test loss: 0.961, Global test accuracy: 94.86
Round  51, Train loss: 0.916, Test loss: 0.984, Test accuracy: 92.12
Round  51, Global train loss: 0.916, Global test loss: 0.948, Global test accuracy: 96.00
Round  52, Train loss: 0.949, Test loss: 0.985, Test accuracy: 92.10
Round  52, Global train loss: 0.949, Global test loss: 0.947, Global test accuracy: 96.06
Round  53, Train loss: 0.984, Test loss: 0.985, Test accuracy: 92.00
Round  53, Global train loss: 0.984, Global test loss: 0.952, Global test accuracy: 95.34
Round  54, Train loss: 1.337, Test loss: 0.982, Test accuracy: 92.28
Round  54, Global train loss: 1.337, Global test loss: 0.957, Global test accuracy: 94.84
Round  55, Train loss: 1.095, Test loss: 0.982, Test accuracy: 92.22
Round  55, Global train loss: 1.095, Global test loss: 0.955, Global test accuracy: 95.34
Round  56, Train loss: 1.324, Test loss: 0.985, Test accuracy: 91.94
Round  56, Global train loss: 1.324, Global test loss: 0.968, Global test accuracy: 94.02
Round  57, Train loss: 0.989, Test loss: 0.984, Test accuracy: 92.04
Round  57, Global train loss: 0.989, Global test loss: 0.952, Global test accuracy: 95.42
Round  58, Train loss: 1.101, Test loss: 0.986, Test accuracy: 91.94
Round  58, Global train loss: 1.101, Global test loss: 0.952, Global test accuracy: 95.46
Round  59, Train loss: 1.121, Test loss: 0.984, Test accuracy: 92.20
Round  59, Global train loss: 1.121, Global test loss: 0.962, Global test accuracy: 94.50
Round  60, Train loss: 1.139, Test loss: 0.983, Test accuracy: 92.28
Round  60, Global train loss: 1.139, Global test loss: 0.957, Global test accuracy: 95.02
Round  61, Train loss: 1.290, Test loss: 0.983, Test accuracy: 92.24
Round  61, Global train loss: 1.290, Global test loss: 0.961, Global test accuracy: 94.26
Round  62, Train loss: 0.988, Test loss: 0.983, Test accuracy: 92.26
Round  62, Global train loss: 0.988, Global test loss: 0.952, Global test accuracy: 95.58
Round  63, Train loss: 1.301, Test loss: 0.981, Test accuracy: 92.48
Round  63, Global train loss: 1.301, Global test loss: 0.965, Global test accuracy: 94.16
Round  64, Train loss: 1.146, Test loss: 0.983, Test accuracy: 92.38
Round  64, Global train loss: 1.146, Global test loss: 0.958, Global test accuracy: 94.82
Round  65, Train loss: 0.972, Test loss: 0.983, Test accuracy: 92.42
Round  65, Global train loss: 0.972, Global test loss: 0.949, Global test accuracy: 95.98
Round  66, Train loss: 1.122, Test loss: 0.983, Test accuracy: 92.24
Round  66, Global train loss: 1.122, Global test loss: 0.957, Global test accuracy: 95.16
Round  67, Train loss: 1.292, Test loss: 0.982, Test accuracy: 92.30
Round  67, Global train loss: 1.292, Global test loss: 0.980, Global test accuracy: 92.78
Round  68, Train loss: 1.287, Test loss: 0.983, Test accuracy: 92.38
Round  68, Global train loss: 1.287, Global test loss: 0.972, Global test accuracy: 93.34
Round  69, Train loss: 1.116, Test loss: 0.988, Test accuracy: 91.88
Round  69, Global train loss: 1.116, Global test loss: 0.967, Global test accuracy: 94.14
Round  70, Train loss: 1.116, Test loss: 0.991, Test accuracy: 91.40
Round  70, Global train loss: 1.116, Global test loss: 0.966, Global test accuracy: 94.44
Round  71, Train loss: 1.010, Test loss: 0.991, Test accuracy: 91.50
Round  71, Global train loss: 1.010, Global test loss: 0.957, Global test accuracy: 95.20
Round  72, Train loss: 0.942, Test loss: 0.990, Test accuracy: 91.52
Round  72, Global train loss: 0.942, Global test loss: 0.951, Global test accuracy: 95.62
Round  73, Train loss: 1.146, Test loss: 0.991, Test accuracy: 91.30
Round  73, Global train loss: 1.146, Global test loss: 0.962, Global test accuracy: 94.50
Round  74, Train loss: 1.129, Test loss: 0.990, Test accuracy: 91.38
Round  74, Global train loss: 1.129, Global test loss: 0.957, Global test accuracy: 94.96
Round  75, Train loss: 1.277, Test loss: 0.995, Test accuracy: 90.88
Round  75, Global train loss: 1.277, Global test loss: 0.970, Global test accuracy: 93.54
Round  76, Train loss: 1.114, Test loss: 0.990, Test accuracy: 91.46
Round  76, Global train loss: 1.114, Global test loss: 0.969, Global test accuracy: 93.76
Round  77, Train loss: 0.983, Test loss: 0.991, Test accuracy: 91.36
Round  77, Global train loss: 0.983, Global test loss: 0.955, Global test accuracy: 95.20
Round  78, Train loss: 1.140, Test loss: 0.989, Test accuracy: 91.48
Round  78, Global train loss: 1.140, Global test loss: 0.960, Global test accuracy: 94.54
Round  79, Train loss: 0.966, Test loss: 0.992, Test accuracy: 91.28
Round  79, Global train loss: 0.966, Global test loss: 0.953, Global test accuracy: 95.68
Round  80, Train loss: 1.303, Test loss: 0.988, Test accuracy: 91.66
Round  80, Global train loss: 1.303, Global test loss: 0.977, Global test accuracy: 92.88
Round  81, Train loss: 1.123, Test loss: 0.987, Test accuracy: 91.70
Round  81, Global train loss: 1.123, Global test loss: 0.971, Global test accuracy: 93.74
Round  82, Train loss: 1.159, Test loss: 0.988, Test accuracy: 91.86
Round  82, Global train loss: 1.159, Global test loss: 0.966, Global test accuracy: 94.32
Round  83, Train loss: 1.269, Test loss: 1.003, Test accuracy: 90.14
Round  83, Global train loss: 1.269, Global test loss: 0.975, Global test accuracy: 93.26
Round  84, Train loss: 1.119, Test loss: 1.005, Test accuracy: 89.94
Round  84, Global train loss: 1.119, Global test loss: 0.965, Global test accuracy: 94.40
Round  85, Train loss: 1.127, Test loss: 1.005, Test accuracy: 90.02
Round  85, Global train loss: 1.127, Global test loss: 0.965, Global test accuracy: 94.14
Round  86, Train loss: 1.252, Test loss: 0.991, Test accuracy: 91.48
Round  86, Global train loss: 1.252, Global test loss: 0.977, Global test accuracy: 93.22
Round  87, Train loss: 1.253, Test loss: 0.994, Test accuracy: 91.10
Round  87, Global train loss: 1.253, Global test loss: 0.980, Global test accuracy: 92.68
Round  88, Train loss: 1.415, Test loss: 0.997, Test accuracy: 90.86
Round  88, Global train loss: 1.415, Global test loss: 1.019, Global test accuracy: 89.00
Round  89, Train loss: 1.150, Test loss: 0.999, Test accuracy: 90.56
Round  89, Global train loss: 1.150, Global test loss: 0.981, Global test accuracy: 92.66
Round  90, Train loss: 1.102, Test loss: 1.000, Test accuracy: 90.40
Round  90, Global train loss: 1.102, Global test loss: 0.967, Global test accuracy: 94.20
Round  91, Train loss: 0.934, Test loss: 1.001, Test accuracy: 90.22
Round  91, Global train loss: 0.934, Global test loss: 0.956, Global test accuracy: 95.06
Round  92, Train loss: 1.104, Test loss: 0.996, Test accuracy: 90.70
Round  92, Global train loss: 1.104, Global test loss: 0.966, Global test accuracy: 94.18
Round  93, Train loss: 1.285, Test loss: 0.995, Test accuracy: 91.00
Round  93, Global train loss: 1.285, Global test loss: 0.979, Global test accuracy: 92.70
Round  94, Train loss: 1.075, Test loss: 0.997, Test accuracy: 90.98
Round  94, Global train loss: 1.075, Global test loss: 0.963, Global test accuracy: 94.44/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  95, Train loss: 1.168, Test loss: 0.998, Test accuracy: 90.86
Round  95, Global train loss: 1.168, Global test loss: 0.966, Global test accuracy: 93.98
Round  96, Train loss: 1.143, Test loss: 0.998, Test accuracy: 90.86
Round  96, Global train loss: 1.143, Global test loss: 0.977, Global test accuracy: 93.04
Round  97, Train loss: 1.073, Test loss: 1.003, Test accuracy: 90.26
Round  97, Global train loss: 1.073, Global test loss: 0.966, Global test accuracy: 94.20
Round  98, Train loss: 1.163, Test loss: 1.011, Test accuracy: 89.50
Round  98, Global train loss: 1.163, Global test loss: 0.977, Global test accuracy: 93.50
Round  99, Train loss: 1.101, Test loss: 1.012, Test accuracy: 89.34
Round  99, Global train loss: 1.101, Global test loss: 0.973, Global test accuracy: 93.48
Final Round, Train loss: 1.135, Test loss: 1.009, Test accuracy: 89.52
Final Round, Global train loss: 1.135, Global test loss: 0.973, Global test accuracy: 93.48
Average accuracy final 10 rounds: 90.41199999999999 

Average global accuracy final 10 rounds: 93.878 

619.5908470153809
[0.9730374813079834, 1.9460749626159668, 2.8418920040130615, 3.7377090454101562, 4.5930023193359375, 5.448295593261719, 6.344249248504639, 7.240202903747559, 8.099393606185913, 8.958584308624268, 9.82344102859497, 10.688297748565674, 11.529443979263306, 12.370590209960938, 13.208436250686646, 14.046282291412354, 14.87761402130127, 15.708945751190186, 16.54767918586731, 17.386412620544434, 18.28246831893921, 19.178524017333984, 20.080750942230225, 20.982977867126465, 21.882739782333374, 22.782501697540283, 23.64916443824768, 24.515827178955078, 25.355048179626465, 26.19426918029785, 27.032264947891235, 27.87026071548462, 28.74218988418579, 29.614119052886963, 30.473589420318604, 31.333059787750244, 32.18489718437195, 33.03673458099365, 33.88738036155701, 34.73802614212036, 35.60104155540466, 36.464056968688965, 37.31258797645569, 38.16111898422241, 39.02536964416504, 39.889620304107666, 40.74761891365051, 41.60561752319336, 42.45704460144043, 43.3084716796875, 44.15923094749451, 45.009990215301514, 45.85844826698303, 46.70690631866455, 47.547051191329956, 48.38719606399536, 49.23691534996033, 50.08663463592529, 50.92840266227722, 51.77017068862915, 52.62428259849548, 53.478394508361816, 54.331862926483154, 55.18533134460449, 56.05186080932617, 56.91839027404785, 57.78503155708313, 58.65167284011841, 59.52057862281799, 60.38948440551758, 61.24864721298218, 62.10781002044678, 62.95755457878113, 63.80729913711548, 64.66006207466125, 65.51282501220703, 66.36141300201416, 67.21000099182129, 68.05648636817932, 68.90297174453735, 69.73573613166809, 70.56850051879883, 71.4116005897522, 72.25470066070557, 73.10857009887695, 73.96243953704834, 74.811776638031, 75.66111373901367, 76.53662538528442, 77.41213703155518, 78.25396633148193, 79.09579563140869, 79.94210171699524, 80.78840780258179, 81.6340913772583, 82.47977495193481, 83.34141254425049, 84.20305013656616, 85.04366612434387, 85.88428211212158, 86.72240400314331, 87.56052589416504, 88.39452147483826, 89.22851705551147, 90.08728098869324, 90.946044921875, 91.79574799537659, 92.64545106887817, 93.49130034446716, 94.33714962005615, 95.20745205879211, 96.07775449752808, 96.93620133399963, 97.79464817047119, 98.65551733970642, 99.51638650894165, 100.36227178573608, 101.20815706253052, 102.05847954750061, 102.9088020324707, 103.75533366203308, 104.60186529159546, 105.44278764724731, 106.28371000289917, 107.13291954994202, 107.98212909698486, 108.81919240951538, 109.6562557220459, 110.50777173042297, 111.35928773880005, 112.18784880638123, 113.0164098739624, 113.85896921157837, 114.70152854919434, 115.57021737098694, 116.43890619277954, 117.35108160972595, 118.26325702667236, 119.1478054523468, 120.03235387802124, 120.91449928283691, 121.79664468765259, 122.6611979007721, 123.5257511138916, 124.40256404876709, 125.27937698364258, 126.13368678092957, 126.98799657821655, 127.82943391799927, 128.67087125778198, 129.5361680984497, 130.40146493911743, 131.2706253528595, 132.13978576660156, 133.00421380996704, 133.86864185333252, 134.72387194633484, 135.57910203933716, 136.40366578102112, 137.22822952270508, 138.08949613571167, 138.95076274871826, 139.77898502349854, 140.6072072982788, 141.4365677833557, 142.26592826843262, 143.0872974395752, 143.90866661071777, 144.72969937324524, 145.5507321357727, 146.41873359680176, 147.2867350578308, 148.10642766952515, 148.92612028121948, 149.78522181510925, 150.64432334899902, 151.49054098129272, 152.33675861358643, 153.1749505996704, 154.0131425857544, 154.87737274169922, 155.74160289764404, 156.60455679893494, 157.46751070022583, 158.33987379074097, 159.2122368812561, 160.29757452011108, 161.38291215896606, 162.21755051612854, 163.05218887329102, 163.88306069374084, 164.71393251419067, 165.53832530975342, 166.36271810531616, 167.21652150154114, 168.0703248977661, 168.87645959854126, 169.6825942993164, 170.53196835517883, 171.38134241104126, 173.10624027252197, 174.83113813400269]
[64.78, 64.78, 82.92, 82.92, 82.5, 82.5, 86.38, 86.38, 89.22, 89.22, 90.82, 90.82, 91.38, 91.38, 91.68, 91.68, 93.38, 93.38, 93.1, 93.1, 92.66, 92.66, 93.1, 93.1, 94.06, 94.06, 93.86, 93.86, 94.1, 94.1, 94.32, 94.32, 94.48, 94.48, 94.6, 94.6, 94.64, 94.64, 94.34, 94.34, 94.52, 94.52, 94.66, 94.66, 94.12, 94.12, 94.14, 94.14, 94.02, 94.02, 93.82, 93.82, 94.02, 94.02, 94.18, 94.18, 94.24, 94.24, 93.98, 93.98, 93.82, 93.82, 93.48, 93.48, 93.34, 93.34, 93.56, 93.56, 93.4, 93.4, 93.4, 93.4, 93.44, 93.44, 92.94, 92.94, 93.0, 93.0, 92.7, 92.7, 92.96, 92.96, 92.72, 92.72, 92.8, 92.8, 92.5, 92.5, 92.68, 92.68, 92.36, 92.36, 92.16, 92.16, 92.0, 92.0, 92.24, 92.24, 92.22, 92.22, 92.32, 92.32, 92.12, 92.12, 92.1, 92.1, 92.0, 92.0, 92.28, 92.28, 92.22, 92.22, 91.94, 91.94, 92.04, 92.04, 91.94, 91.94, 92.2, 92.2, 92.28, 92.28, 92.24, 92.24, 92.26, 92.26, 92.48, 92.48, 92.38, 92.38, 92.42, 92.42, 92.24, 92.24, 92.3, 92.3, 92.38, 92.38, 91.88, 91.88, 91.4, 91.4, 91.5, 91.5, 91.52, 91.52, 91.3, 91.3, 91.38, 91.38, 90.88, 90.88, 91.46, 91.46, 91.36, 91.36, 91.48, 91.48, 91.28, 91.28, 91.66, 91.66, 91.7, 91.7, 91.86, 91.86, 90.14, 90.14, 89.94, 89.94, 90.02, 90.02, 91.48, 91.48, 91.1, 91.1, 90.86, 90.86, 90.56, 90.56, 90.4, 90.4, 90.22, 90.22, 90.7, 90.7, 91.0, 91.0, 90.98, 90.98, 90.86, 90.86, 90.86, 90.86, 90.26, 90.26, 89.5, 89.5, 89.34, 89.34, 89.52, 89.52]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.4 , level_n_lowerb:0.8  

   Client 0, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Traceback (most recent call last):
  File "main_fedpac_co_teaching.py", line 250, in <module>
    local.filter_data(net=net_local.to(args.device), net2=net_local2.to(args.device), concept_matrix_local = concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1587, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

   Client 8, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550021 (local), 549696 (global); Percentage 99.94 (549696/550021)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 1.624, Test loss: 1.587, Test accuracy: 49.02
Round   0, Global train loss: 1.624, Global test loss: 1.587, Global test accuracy: 48.98
Round   1, Train loss: 1.589, Test loss: 1.550, Test accuracy: 66.40
Round   1, Global train loss: 1.589, Global test loss: 1.550, Global test accuracy: 66.44
Round   2, Train loss: 1.528, Test loss: 1.417, Test accuracy: 80.68
Round   2, Global train loss: 1.528, Global test loss: 1.409, Global test accuracy: 78.98
Round   3, Train loss: 1.397, Test loss: 1.249, Test accuracy: 86.50
Round   3, Global train loss: 1.397, Global test loss: 1.221, Global test accuracy: 84.50
Round   4, Train loss: 1.293, Test loss: 1.149, Test accuracy: 87.96
Round   4, Global train loss: 1.293, Global test loss: 1.118, Global test accuracy: 86.74
Round   5, Train loss: 1.405, Test loss: 1.126, Test accuracy: 92.26
Round   5, Global train loss: 1.405, Global test loss: 1.119, Global test accuracy: 93.86
Round   6, Train loss: 1.382, Test loss: 1.110, Test accuracy: 93.62
Round   6, Global train loss: 1.382, Global test loss: 1.099, Global test accuracy: 94.84
Round   7, Train loss: 1.559, Test loss: 1.148, Test accuracy: 93.50
Round   7, Global train loss: 1.559, Global test loss: 1.162, Global test accuracy: 94.80
Round   8, Train loss: 1.264, Test loss: 1.079, Test accuracy: 94.08
Round   8, Global train loss: 1.264, Global test loss: 1.066, Global test accuracy: 93.08
Round   9, Train loss: 1.365, Test loss: 1.078, Test accuracy: 94.58
Round   9, Global train loss: 1.365, Global test loss: 1.068, Global test accuracy: 95.64
Round  10, Train loss: 1.186, Test loss: 1.046, Test accuracy: 95.28
Round  10, Global train loss: 1.186, Global test loss: 1.012, Global test accuracy: 96.46
Round  11, Train loss: 1.195, Test loss: 1.027, Test accuracy: 95.30
Round  11, Global train loss: 1.195, Global test loss: 1.012, Global test accuracy: 95.68
Round  12, Train loss: 1.559, Test loss: 1.070, Test accuracy: 95.00
Round  12, Global train loss: 1.559, Global test loss: 1.103, Global test accuracy: 95.94
Round  13, Train loss: 1.004, Test loss: 1.023, Test accuracy: 96.08
Round  13, Global train loss: 1.004, Global test loss: 0.970, Global test accuracy: 97.18
Round  14, Train loss: 1.199, Test loss: 1.016, Test accuracy: 96.10
Round  14, Global train loss: 1.199, Global test loss: 0.996, Global test accuracy: 95.84
Round  15, Train loss: 1.157, Test loss: 1.016, Test accuracy: 96.20
Round  15, Global train loss: 1.157, Global test loss: 0.980, Global test accuracy: 96.92
Round  16, Train loss: 1.165, Test loss: 1.013, Test accuracy: 96.04
Round  16, Global train loss: 1.165, Global test loss: 0.986, Global test accuracy: 96.94
Round  17, Train loss: 1.160, Test loss: 1.010, Test accuracy: 96.36
Round  17, Global train loss: 1.160, Global test loss: 0.981, Global test accuracy: 97.06
Round  18, Train loss: 1.185, Test loss: 1.013, Test accuracy: 96.28
Round  18, Global train loss: 1.185, Global test loss: 0.981, Global test accuracy: 96.94
Round  19, Train loss: 1.349, Test loss: 1.035, Test accuracy: 95.96
Round  19, Global train loss: 1.349, Global test loss: 1.012, Global test accuracy: 97.32
Round  20, Train loss: 1.159, Test loss: 1.023, Test accuracy: 96.10
Round  20, Global train loss: 1.159, Global test loss: 0.981, Global test accuracy: 97.60
Round  21, Train loss: 1.367, Test loss: 1.025, Test accuracy: 95.92
Round  21, Global train loss: 1.367, Global test loss: 1.034, Global test accuracy: 97.04
Round  22, Train loss: 1.144, Test loss: 1.020, Test accuracy: 96.14
Round  22, Global train loss: 1.144, Global test loss: 0.976, Global test accuracy: 97.36
Round  23, Train loss: 1.338, Test loss: 1.028, Test accuracy: 96.18
Round  23, Global train loss: 1.338, Global test loss: 1.019, Global test accuracy: 97.16
Round  24, Train loss: 0.967, Test loss: 0.996, Test accuracy: 96.62
Round  24, Global train loss: 0.967, Global test loss: 0.952, Global test accuracy: 97.50
Round  25, Train loss: 0.953, Test loss: 0.981, Test accuracy: 96.72
Round  25, Global train loss: 0.953, Global test loss: 0.945, Global test accuracy: 97.66
Round  26, Train loss: 1.381, Test loss: 1.006, Test accuracy: 96.28
Round  26, Global train loss: 1.381, Global test loss: 1.021, Global test accuracy: 95.54
Round  27, Train loss: 1.149, Test loss: 1.018, Test accuracy: 96.32
Round  27, Global train loss: 1.149, Global test loss: 0.969, Global test accuracy: 97.62
Round  28, Train loss: 1.137, Test loss: 1.009, Test accuracy: 96.32
Round  28, Global train loss: 1.137, Global test loss: 0.964, Global test accuracy: 97.58
Round  29, Train loss: 1.140, Test loss: 1.006, Test accuracy: 96.36
Round  29, Global train loss: 1.140, Global test loss: 0.967, Global test accuracy: 97.76
Round  30, Train loss: 1.175, Test loss: 1.007, Test accuracy: 96.12
Round  30, Global train loss: 1.175, Global test loss: 0.987, Global test accuracy: 96.26
Round  31, Train loss: 1.131, Test loss: 1.012, Test accuracy: 96.02
Round  31, Global train loss: 1.131, Global test loss: 0.963, Global test accuracy: 97.70
Round  32, Train loss: 0.977, Test loss: 0.998, Test accuracy: 96.22
Round  32, Global train loss: 0.977, Global test loss: 0.952, Global test accuracy: 97.32
Round  33, Train loss: 1.131, Test loss: 1.003, Test accuracy: 96.04
Round  33, Global train loss: 1.131, Global test loss: 0.960, Global test accuracy: 97.50
Round  34, Train loss: 1.339, Test loss: 1.028, Test accuracy: 94.92
Round  34, Global train loss: 1.339, Global test loss: 1.020, Global test accuracy: 97.28
Round  35, Train loss: 0.968, Test loss: 1.008, Test accuracy: 95.78
Round  35, Global train loss: 0.968, Global test loss: 0.951, Global test accuracy: 97.32
Round  36, Train loss: 0.964, Test loss: 0.992, Test accuracy: 96.24
Round  36, Global train loss: 0.964, Global test loss: 0.945, Global test accuracy: 97.42
Round  37, Train loss: 0.959, Test loss: 0.989, Test accuracy: 96.36
Round  37, Global train loss: 0.959, Global test loss: 0.945, Global test accuracy: 97.28
Round  38, Train loss: 1.171, Test loss: 1.001, Test accuracy: 96.14
Round  38, Global train loss: 1.171, Global test loss: 0.971, Global test accuracy: 96.88
Round  39, Train loss: 1.521, Test loss: 1.061, Test accuracy: 93.10
Round  39, Global train loss: 1.521, Global test loss: 1.119, Global test accuracy: 94.26
Round  40, Train loss: 1.121, Test loss: 1.035, Test accuracy: 94.60
Round  40, Global train loss: 1.121, Global test loss: 0.972, Global test accuracy: 97.60
Round  41, Train loss: 0.944, Test loss: 0.999, Test accuracy: 96.26
Round  41, Global train loss: 0.944, Global test loss: 0.942, Global test accuracy: 97.62
Round  42, Train loss: 1.159, Test loss: 1.007, Test accuracy: 95.92
Round  42, Global train loss: 1.159, Global test loss: 0.971, Global test accuracy: 96.82
Round  43, Train loss: 1.336, Test loss: 1.032, Test accuracy: 94.78
Round  43, Global train loss: 1.336, Global test loss: 1.021, Global test accuracy: 96.76
Round  44, Train loss: 1.318, Test loss: 1.044, Test accuracy: 94.16
Round  44, Global train loss: 1.318, Global test loss: 1.029, Global test accuracy: 96.18
Round  45, Train loss: 1.136, Test loss: 1.033, Test accuracy: 94.50
Round  45, Global train loss: 1.136, Global test loss: 0.990, Global test accuracy: 96.08
Round  46, Train loss: 1.138, Test loss: 1.012, Test accuracy: 96.28
Round  46, Global train loss: 1.138, Global test loss: 0.966, Global test accuracy: 97.78
Round  47, Train loss: 1.130, Test loss: 1.016, Test accuracy: 95.60
Round  47, Global train loss: 1.130, Global test loss: 0.970, Global test accuracy: 97.38
Round  48, Train loss: 1.107, Test loss: 1.013, Test accuracy: 95.66
Round  48, Global train loss: 1.107, Global test loss: 0.961, Global test accuracy: 97.62
Round  49, Train loss: 1.099, Test loss: 1.018, Test accuracy: 95.18
Round  49, Global train loss: 1.099, Global test loss: 0.961, Global test accuracy: 97.50
Round  50, Train loss: 0.948, Test loss: 0.999, Test accuracy: 95.90
Round  50, Global train loss: 0.948, Global test loss: 0.947, Global test accuracy: 97.50
Round  51, Train loss: 1.316, Test loss: 1.025, Test accuracy: 94.56
Round  51, Global train loss: 1.316, Global test loss: 1.000, Global test accuracy: 97.34
Round  52, Train loss: 1.303, Test loss: 1.046, Test accuracy: 93.64
Round  52, Global train loss: 1.303, Global test loss: 1.017, Global test accuracy: 96.96
Round  53, Train loss: 1.277, Test loss: 1.067, Test accuracy: 92.74
Round  53, Global train loss: 1.277, Global test loss: 1.037, Global test accuracy: 95.50
Round  54, Train loss: 1.134, Test loss: 1.033, Test accuracy: 94.30
Round  54, Global train loss: 1.134, Global test loss: 0.979, Global test accuracy: 97.02
Round  55, Train loss: 1.311, Test loss: 1.054, Test accuracy: 92.82
Round  55, Global train loss: 1.311, Global test loss: 1.057, Global test accuracy: 93.06
Round  56, Train loss: 1.128, Test loss: 1.030, Test accuracy: 94.36
Round  56, Global train loss: 1.128, Global test loss: 0.975, Global test accuracy: 97.08
Round  57, Train loss: 1.102, Test loss: 1.025, Test accuracy: 94.46
Round  57, Global train loss: 1.102, Global test loss: 0.971, Global test accuracy: 96.88
Round  58, Train loss: 1.114, Test loss: 1.010, Test accuracy: 95.32
Round  58, Global train loss: 1.114, Global test loss: 0.964, Global test accuracy: 97.62
Round  59, Train loss: 1.110, Test loss: 1.022, Test accuracy: 94.10
Round  59, Global train loss: 1.110, Global test loss: 0.984, Global test accuracy: 96.10
Round  60, Train loss: 1.097, Test loss: 1.024, Test accuracy: 94.14
Round  60, Global train loss: 1.097, Global test loss: 0.970, Global test accuracy: 96.80
Round  61, Train loss: 1.302, Test loss: 1.062, Test accuracy: 91.06
Round  61, Global train loss: 1.302, Global test loss: 1.042, Global test accuracy: 95.08
Round  62, Train loss: 0.934, Test loss: 1.011, Test accuracy: 94.78
Round  62, Global train loss: 0.934, Global test loss: 0.945, Global test accuracy: 97.60
Round  63, Train loss: 1.087, Test loss: 1.011, Test accuracy: 94.66
Round  63, Global train loss: 1.087, Global test loss: 0.956, Global test accuracy: 97.40
Round  64, Train loss: 1.282, Test loss: 1.073, Test accuracy: 89.24
Round  64, Global train loss: 1.282, Global test loss: 1.051, Global test accuracy: 93.84
Round  65, Train loss: 1.087, Test loss: 1.041, Test accuracy: 92.36
Round  65, Global train loss: 1.087, Global test loss: 0.976, Global test accuracy: 96.36
Round  66, Train loss: 1.100, Test loss: 1.042, Test accuracy: 92.06
Round  66, Global train loss: 1.100, Global test loss: 0.995, Global test accuracy: 94.80
Round  67, Train loss: 1.087, Test loss: 1.046, Test accuracy: 91.56
Round  67, Global train loss: 1.087, Global test loss: 0.997, Global test accuracy: 94.72
Round  68, Train loss: 1.112, Test loss: 1.029, Test accuracy: 93.00
Round  68, Global train loss: 1.112, Global test loss: 0.971, Global test accuracy: 97.06
Round  69, Train loss: 1.228, Test loss: 1.091, Test accuracy: 87.28
Round  69, Global train loss: 1.228, Global test loss: 1.049, Global test accuracy: 92.98
Round  70, Train loss: 1.122, Test loss: 1.047, Test accuracy: 91.14
Round  70, Global train loss: 1.122, Global test loss: 1.001, Global test accuracy: 94.14
Round  71, Train loss: 1.066, Test loss: 1.047, Test accuracy: 91.52
Round  71, Global train loss: 1.066, Global test loss: 0.989, Global test accuracy: 95.48
Round  72, Train loss: 1.075, Test loss: 1.037, Test accuracy: 92.62
Round  72, Global train loss: 1.075, Global test loss: 0.983, Global test accuracy: 95.76
Round  73, Train loss: 1.062, Test loss: 1.035, Test accuracy: 92.62
Round  73, Global train loss: 1.062, Global test loss: 0.982, Global test accuracy: 95.78
Round  74, Train loss: 1.070, Test loss: 1.027, Test accuracy: 92.94
Round  74, Global train loss: 1.070, Global test loss: 0.977, Global test accuracy: 95.64
Round  75, Train loss: 1.106, Test loss: 1.032, Test accuracy: 92.68
Round  75, Global train loss: 1.106, Global test loss: 0.979, Global test accuracy: 95.82
Round  76, Train loss: 1.061, Test loss: 1.042, Test accuracy: 91.60
Round  76, Global train loss: 1.061, Global test loss: 0.986, Global test accuracy: 95.08
Round  77, Train loss: 1.050, Test loss: 1.044, Test accuracy: 91.10
Round  77, Global train loss: 1.050, Global test loss: 0.988, Global test accuracy: 94.66
Round  78, Train loss: 1.218, Test loss: 1.137, Test accuracy: 81.80
Round  78, Global train loss: 1.218, Global test loss: 1.094, Global test accuracy: 89.26
Round  79, Train loss: 1.172, Test loss: 1.160, Test accuracy: 80.50
Round  79, Global train loss: 1.172, Global test loss: 1.127, Global test accuracy: 84.02
Round  80, Train loss: 1.224, Test loss: 1.123, Test accuracy: 83.44
Round  80, Global train loss: 1.224, Global test loss: 1.097, Global test accuracy: 87.80
Round  81, Train loss: 1.372, Test loss: 1.251, Test accuracy: 69.70
Round  81, Global train loss: 1.372, Global test loss: 1.263, Global test accuracy: 74.04
Round  82, Train loss: 1.006, Test loss: 1.011, Test accuracy: 93.80
Round  82, Global train loss: 1.006, Global test loss: 0.960, Global test accuracy: 96.26
Round  83, Train loss: 1.079, Test loss: 1.025, Test accuracy: 92.30
Round  83, Global train loss: 1.079, Global test loss: 0.981, Global test accuracy: 95.50
Round  84, Train loss: 1.097, Test loss: 1.026, Test accuracy: 92.06
Round  84, Global train loss: 1.097, Global test loss: 0.978, Global test accuracy: 95.56
Round  85, Train loss: 1.100, Test loss: 1.048, Test accuracy: 89.80
Round  85, Global train loss: 1.100, Global test loss: 1.017, Global test accuracy: 92.24
Round  86, Train loss: 1.084, Test loss: 1.049, Test accuracy: 89.54
Round  86, Global train loss: 1.084, Global test loss: 1.012, Global test accuracy: 92.30
Round  87, Train loss: 0.929, Test loss: 1.002, Test accuracy: 93.60
Round  87, Global train loss: 0.929, Global test loss: 0.958, Global test accuracy: 95.88
Round  88, Train loss: 0.918, Test loss: 0.992, Test accuracy: 94.30
Round  88, Global train loss: 0.918, Global test loss: 0.954, Global test accuracy: 96.16
Round  89, Train loss: 0.915, Test loss: 0.981, Test accuracy: 95.46
Round  89, Global train loss: 0.915, Global test loss: 0.941, Global test accuracy: 97.14
Round  90, Train loss: 1.050, Test loss: 1.019, Test accuracy: 92.18
Round  90, Global train loss: 1.050, Global test loss: 0.964, Global test accuracy: 96.16
Round  91, Train loss: 1.169, Test loss: 1.140, Test accuracy: 80.00
Round  91, Global train loss: 1.169, Global test loss: 1.079, Global test accuracy: 88.10/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  92, Train loss: 1.134, Test loss: 1.156, Test accuracy: 78.30
Round  92, Global train loss: 1.134, Global test loss: 1.101, Global test accuracy: 86.16
Round  93, Train loss: 0.950, Test loss: 1.015, Test accuracy: 92.16
Round  93, Global train loss: 0.950, Global test loss: 0.955, Global test accuracy: 96.40
Round  94, Train loss: 1.032, Test loss: 1.042, Test accuracy: 89.50
Round  94, Global train loss: 1.032, Global test loss: 0.982, Global test accuracy: 94.36
Round  95, Train loss: 1.081, Test loss: 1.046, Test accuracy: 89.70
Round  95, Global train loss: 1.081, Global test loss: 0.997, Global test accuracy: 93.66
Round  96, Train loss: 0.926, Test loss: 1.013, Test accuracy: 92.18
Round  96, Global train loss: 0.926, Global test loss: 0.966, Global test accuracy: 95.20
Round  97, Train loss: 1.023, Test loss: 1.031, Test accuracy: 90.74
Round  97, Global train loss: 1.023, Global test loss: 0.983, Global test accuracy: 94.34
Round  98, Train loss: 1.068, Test loss: 1.056, Test accuracy: 88.44
Round  98, Global train loss: 1.068, Global test loss: 1.002, Global test accuracy: 93.12
Round  99, Train loss: 1.085, Test loss: 1.053, Test accuracy: 89.24
Round  99, Global train loss: 1.085, Global test loss: 0.990, Global test accuracy: 94.42
Final Round, Train loss: 1.082, Test loss: 1.040, Test accuracy: 90.20
Final Round, Global train loss: 1.082, Global test loss: 0.990, Global test accuracy: 94.42
Average accuracy final 10 rounds: 88.244
522.4555387496948
[1.121588945388794, 2.025599718093872, 2.94470477104187, 3.8580667972564697, 4.772845029830933, 5.673392057418823, 6.563035488128662, 7.456368446350098, 8.368284702301025, 9.2881178855896, 10.200745344161987, 11.084929943084717, 11.988526582717896, 12.912249565124512, 13.841816663742065, 14.774356365203857, 15.694828271865845, 16.62575650215149, 17.521729230880737, 18.67867612838745, 19.5811607837677, 20.462177753448486, 21.35239839553833, 22.250961303710938, 23.168188333511353, 24.09398913383484, 25.015851736068726, 25.935474634170532, 26.869328022003174, 27.79690670967102, 28.70770835876465, 29.61987805366516, 30.52770972251892, 31.437814474105835, 32.355926513671875, 33.266923666000366, 34.22292685508728, 35.1968789100647, 36.131901264190674, 37.105445861816406, 38.038671255111694, 38.94089126586914, 39.85830235481262, 40.75525212287903, 41.65819787979126, 42.568089723587036, 43.484450578689575, 44.42793083190918, 45.49738597869873, 46.41607117652893, 47.35457730293274, 48.29022240638733, 49.252236127853394, 50.175925493240356, 51.10777568817139, 52.04035043716431, 52.956528186798096, 53.85563278198242, 54.76087975502014, 55.686604261398315, 56.65422177314758, 57.58450627326965, 58.534259557724, 59.49871206283569, 60.42627477645874, 61.34785318374634, 62.300567865371704, 63.21072959899902, 64.11064219474792, 65.04813385009766, 66.00059700012207, 66.91308641433716, 67.8569507598877, 68.75627422332764, 69.67177295684814, 70.58411955833435, 71.47730350494385, 72.60669255256653, 73.53436756134033, 74.46377611160278, 75.38740253448486, 76.30985975265503, 77.26620268821716, 78.17485690116882, 79.10537099838257, 80.03272843360901, 80.9284598827362, 81.83345293998718, 82.74851441383362, 83.65961408615112, 84.57205128669739, 85.49763226509094, 86.42545914649963, 87.35835123062134, 88.27763295173645, 89.21226716041565, 90.12362003326416, 91.04480409622192, 91.98780560493469, 92.90364694595337, 94.37109971046448]
[49.02, 66.4, 80.68, 86.5, 87.96, 92.26, 93.62, 93.5, 94.08, 94.58, 95.28, 95.3, 95.0, 96.08, 96.1, 96.2, 96.04, 96.36, 96.28, 95.96, 96.1, 95.92, 96.14, 96.18, 96.62, 96.72, 96.28, 96.32, 96.32, 96.36, 96.12, 96.02, 96.22, 96.04, 94.92, 95.78, 96.24, 96.36, 96.14, 93.1, 94.6, 96.26, 95.92, 94.78, 94.16, 94.5, 96.28, 95.6, 95.66, 95.18, 95.9, 94.56, 93.64, 92.74, 94.3, 92.82, 94.36, 94.46, 95.32, 94.1, 94.14, 91.06, 94.78, 94.66, 89.24, 92.36, 92.06, 91.56, 93.0, 87.28, 91.14, 91.52, 92.62, 92.62, 92.94, 92.68, 91.6, 91.1, 81.8, 80.5, 83.44, 69.7, 93.8, 92.3, 92.06, 89.8, 89.54, 93.6, 94.3, 95.46, 92.18, 80.0, 78.3, 92.16, 89.5, 89.7, 92.18, 90.74, 88.44, 89.24, 90.2]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fedpac_copsl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist,  filter_alg: loss_psl, level_n_system: 0.4 , level_n_lowerb:0.8  

   Client 9, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550021 (local), 549696 (global); Percentage 99.94 (549696/550021)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 1.625, Test loss: 1.594, Test accuracy: 44.90
Round   0, Global train loss: 1.625, Global test loss: 1.594, Global test accuracy: 44.30
Round   1, Train loss: 1.586, Test loss: 1.544, Test accuracy: 67.16
Round   1, Global train loss: 1.586, Global test loss: 1.544, Global test accuracy: 66.86
Round   2, Train loss: 1.521, Test loss: 1.410, Test accuracy: 77.06
Round   2, Global train loss: 1.521, Global test loss: 1.409, Global test accuracy: 76.84
Round   3, Train loss: 1.420, Test loss: 1.254, Test accuracy: 89.34
Round   3, Global train loss: 1.420, Global test loss: 1.247, Global test accuracy: 90.38
Round   4, Train loss: 1.317, Test loss: 1.125, Test accuracy: 92.74
Round   4, Global train loss: 1.317, Global test loss: 1.109, Global test accuracy: 94.60
Round   5, Train loss: 1.266, Test loss: 1.075, Test accuracy: 94.08
Round   5, Global train loss: 1.266, Global test loss: 1.052, Global test accuracy: 95.82
Round   6, Train loss: 1.246, Test loss: 1.053, Test accuracy: 95.00
Round   6, Global train loss: 1.246, Global test loss: 1.026, Global test accuracy: 96.48
Round   7, Train loss: 1.236, Test loss: 1.041, Test accuracy: 95.66
Round   7, Global train loss: 1.236, Global test loss: 1.012, Global test accuracy: 96.60
Round   8, Train loss: 1.229, Test loss: 1.036, Test accuracy: 95.96
Round   8, Global train loss: 1.229, Global test loss: 1.004, Global test accuracy: 96.78
Round   9, Train loss: 1.224, Test loss: 1.033, Test accuracy: 96.02
Round   9, Global train loss: 1.224, Global test loss: 0.998, Global test accuracy: 96.82
Round  10, Train loss: 1.192, Test loss: 1.032, Test accuracy: 95.66
Round  10, Global train loss: 1.192, Global test loss: 0.999, Global test accuracy: 96.28
Traceback (most recent call last):
  File "main_fedpac_copsl.py", line 280, in <module>
    w_local, loss, indd, class_center_local, class_num, noisy_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys,
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2559, in train
    self.filter_data(net, local_net, iter2-head_eps+1, local_eps-head_eps+1, concept_matrix_local)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2396, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist, level_n_system: 0.6 , level_n_lowerb:0.4  

   Client 1, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.595, Test loss: 1.566, Test accuracy: 65.64
Round   0, Global train loss: 1.595, Global test loss: 1.568, Global test accuracy: 67.48
Round   1, Train loss: 1.457, Test loss: 1.370, Test accuracy: 72.74
Round   1, Global train loss: 1.457, Global test loss: 1.319, Global test accuracy: 74.82
Round   2, Train loss: 1.300, Test loss: 1.179, Test accuracy: 86.42
Round   2, Global train loss: 1.300, Global test loss: 1.060, Global test accuracy: 93.86
Round   3, Train loss: 1.266, Test loss: 1.172, Test accuracy: 86.70
Round   3, Global train loss: 1.266, Global test loss: 1.094, Global test accuracy: 93.58
Round   4, Train loss: 1.271, Test loss: 1.146, Test accuracy: 85.80
Round   4, Global train loss: 1.271, Global test loss: 1.085, Global test accuracy: 92.86
Round   5, Train loss: 1.110, Test loss: 1.119, Test accuracy: 85.82
Round   5, Global train loss: 1.110, Global test loss: 1.017, Global test accuracy: 91.08
Round   6, Train loss: 1.154, Test loss: 1.088, Test accuracy: 89.50
Round   6, Global train loss: 1.154, Global test loss: 1.018, Global test accuracy: 94.52
Round   7, Train loss: 1.260, Test loss: 1.053, Test accuracy: 90.86
Round   7, Global train loss: 1.260, Global test loss: 1.011, Global test accuracy: 94.62
Round   8, Train loss: 1.162, Test loss: 1.030, Test accuracy: 92.22
Round   8, Global train loss: 1.162, Global test loss: 0.975, Global test accuracy: 95.60
Round   9, Train loss: 1.076, Test loss: 1.014, Test accuracy: 93.02
Round   9, Global train loss: 1.076, Global test loss: 0.972, Global test accuracy: 95.38
Round  10, Train loss: 1.246, Test loss: 1.012, Test accuracy: 92.74
Round  10, Global train loss: 1.246, Global test loss: 0.981, Global test accuracy: 95.04
Round  11, Train loss: 1.212, Test loss: 0.994, Test accuracy: 93.80
Round  11, Global train loss: 1.212, Global test loss: 0.969, Global test accuracy: 96.18
Round  12, Train loss: 1.130, Test loss: 0.995, Test accuracy: 93.60
Round  12, Global train loss: 1.130, Global test loss: 0.965, Global test accuracy: 95.20
Round  13, Train loss: 1.126, Test loss: 0.992, Test accuracy: 93.56
Round  13, Global train loss: 1.126, Global test loss: 0.956, Global test accuracy: 96.38
Round  14, Train loss: 1.058, Test loss: 0.988, Test accuracy: 93.68
Round  14, Global train loss: 1.058, Global test loss: 0.958, Global test accuracy: 95.78
Round  15, Train loss: 1.240, Test loss: 0.990, Test accuracy: 93.20
Round  15, Global train loss: 1.240, Global test loss: 0.982, Global test accuracy: 93.66
Round  16, Train loss: 1.139, Test loss: 0.986, Test accuracy: 93.50
Round  16, Global train loss: 1.139, Global test loss: 0.959, Global test accuracy: 95.72
Round  17, Train loss: 1.119, Test loss: 0.988, Test accuracy: 93.26
Round  17, Global train loss: 1.119, Global test loss: 0.966, Global test accuracy: 95.34
Round  18, Train loss: 1.070, Test loss: 0.987, Test accuracy: 93.28
Round  18, Global train loss: 1.070, Global test loss: 0.956, Global test accuracy: 96.28
Round  19, Train loss: 1.124, Test loss: 0.987, Test accuracy: 93.06
Round  19, Global train loss: 1.124, Global test loss: 0.965, Global test accuracy: 95.64
Round  20, Train loss: 0.925, Test loss: 0.987, Test accuracy: 93.04
Round  20, Global train loss: 0.925, Global test loss: 0.950, Global test accuracy: 95.96
Round  21, Train loss: 1.026, Test loss: 0.986, Test accuracy: 93.04
Round  21, Global train loss: 1.026, Global test loss: 0.953, Global test accuracy: 95.56
Round  22, Train loss: 1.052, Test loss: 0.987, Test accuracy: 92.86
Round  22, Global train loss: 1.052, Global test loss: 0.956, Global test accuracy: 96.06
Round  23, Train loss: 1.124, Test loss: 0.988, Test accuracy: 92.72
Round  23, Global train loss: 1.124, Global test loss: 0.951, Global test accuracy: 96.16
Round  24, Train loss: 1.100, Test loss: 0.989, Test accuracy: 92.60
Round  24, Global train loss: 1.100, Global test loss: 0.957, Global test accuracy: 95.46
Round  25, Train loss: 1.181, Test loss: 0.991, Test accuracy: 92.22
Round  25, Global train loss: 1.181, Global test loss: 0.968, Global test accuracy: 95.02
Round  26, Train loss: 1.041, Test loss: 0.992, Test accuracy: 92.08
Round  26, Global train loss: 1.041, Global test loss: 0.949, Global test accuracy: 96.42
Round  27, Train loss: 1.208, Test loss: 0.995, Test accuracy: 91.52
Round  27, Global train loss: 1.208, Global test loss: 0.970, Global test accuracy: 95.28
Round  28, Train loss: 1.118, Test loss: 0.996, Test accuracy: 91.40
Round  28, Global train loss: 1.118, Global test loss: 0.957, Global test accuracy: 95.20
Round  29, Train loss: 1.091, Test loss: 0.994, Test accuracy: 91.50
Round  29, Global train loss: 1.091, Global test loss: 0.965, Global test accuracy: 95.04
Round  30, Train loss: 1.022, Test loss: 0.995, Test accuracy: 91.34
Round  30, Global train loss: 1.022, Global test loss: 0.954, Global test accuracy: 95.68
Round  31, Train loss: 1.035, Test loss: 0.996, Test accuracy: 91.30
Round  31, Global train loss: 1.035, Global test loss: 0.950, Global test accuracy: 96.14
Round  32, Train loss: 1.073, Test loss: 0.997, Test accuracy: 91.24
Round  32, Global train loss: 1.073, Global test loss: 0.959, Global test accuracy: 95.20
Round  33, Train loss: 1.016, Test loss: 0.998, Test accuracy: 91.18
Round  33, Global train loss: 1.016, Global test loss: 0.956, Global test accuracy: 95.36
Round  34, Train loss: 1.045, Test loss: 1.000, Test accuracy: 91.08
Round  34, Global train loss: 1.045, Global test loss: 0.946, Global test accuracy: 96.34
Round  35, Train loss: 1.022, Test loss: 1.002, Test accuracy: 90.88
Round  35, Global train loss: 1.022, Global test loss: 0.944, Global test accuracy: 96.30
Round  36, Train loss: 1.013, Test loss: 1.002, Test accuracy: 90.80
Round  36, Global train loss: 1.013, Global test loss: 0.955, Global test accuracy: 95.58
Round  37, Train loss: 1.080, Test loss: 1.003, Test accuracy: 90.72
Round  37, Global train loss: 1.080, Global test loss: 0.951, Global test accuracy: 96.06
Round  38, Train loss: 1.078, Test loss: 1.003, Test accuracy: 90.66
Round  38, Global train loss: 1.078, Global test loss: 0.951, Global test accuracy: 96.02
Round  39, Train loss: 1.101, Test loss: 1.003, Test accuracy: 90.64
Round  39, Global train loss: 1.101, Global test loss: 0.965, Global test accuracy: 94.46
Round  40, Train loss: 0.995, Test loss: 1.002, Test accuracy: 90.80
Round  40, Global train loss: 0.995, Global test loss: 0.946, Global test accuracy: 96.58
Round  41, Train loss: 1.080, Test loss: 1.004, Test accuracy: 90.56
Round  41, Global train loss: 1.080, Global test loss: 0.957, Global test accuracy: 95.16
Round  42, Train loss: 1.017, Test loss: 1.004, Test accuracy: 90.64
Round  42, Global train loss: 1.017, Global test loss: 0.954, Global test accuracy: 95.36
Round  43, Train loss: 1.017, Test loss: 1.005, Test accuracy: 90.52
Round  43, Global train loss: 1.017, Global test loss: 0.953, Global test accuracy: 95.50
Round  44, Train loss: 1.108, Test loss: 1.005, Test accuracy: 90.52
Round  44, Global train loss: 1.108, Global test loss: 0.947, Global test accuracy: 96.12
Round  45, Train loss: 1.187, Test loss: 1.007, Test accuracy: 90.18
Round  45, Global train loss: 1.187, Global test loss: 0.970, Global test accuracy: 94.32
Round  46, Train loss: 1.100, Test loss: 1.008, Test accuracy: 90.12
Round  46, Global train loss: 1.100, Global test loss: 0.954, Global test accuracy: 95.64
Round  47, Train loss: 1.098, Test loss: 1.009, Test accuracy: 89.96
Round  47, Global train loss: 1.098, Global test loss: 0.954, Global test accuracy: 95.72
Round  48, Train loss: 1.081, Test loss: 1.009, Test accuracy: 90.06
Round  48, Global train loss: 1.081, Global test loss: 0.947, Global test accuracy: 96.38
Round  49, Train loss: 1.109, Test loss: 1.009, Test accuracy: 90.12
Round  49, Global train loss: 1.109, Global test loss: 0.949, Global test accuracy: 96.12
Round  50, Train loss: 1.019, Test loss: 1.008, Test accuracy: 90.20
Round  50, Global train loss: 1.019, Global test loss: 0.948, Global test accuracy: 96.28
Round  51, Train loss: 1.003, Test loss: 1.008, Test accuracy: 90.12
Round  51, Global train loss: 1.003, Global test loss: 0.947, Global test accuracy: 95.86
Round  52, Train loss: 1.090, Test loss: 1.006, Test accuracy: 90.36
Round  52, Global train loss: 1.090, Global test loss: 0.964, Global test accuracy: 94.44
Round  53, Train loss: 1.100, Test loss: 1.006, Test accuracy: 90.34
Round  53, Global train loss: 1.100, Global test loss: 0.953, Global test accuracy: 95.66
Round  54, Train loss: 1.087, Test loss: 1.006, Test accuracy: 90.24
Round  54, Global train loss: 1.087, Global test loss: 0.952, Global test accuracy: 95.70
Round  55, Train loss: 1.174, Test loss: 1.008, Test accuracy: 89.96
Round  55, Global train loss: 1.174, Global test loss: 0.968, Global test accuracy: 94.32
Round  56, Train loss: 1.068, Test loss: 1.009, Test accuracy: 89.84
Round  56, Global train loss: 1.068, Global test loss: 0.950, Global test accuracy: 95.90
Round  57, Train loss: 1.089, Test loss: 1.009, Test accuracy: 89.84
Round  57, Global train loss: 1.089, Global test loss: 0.962, Global test accuracy: 94.76
Round  58, Train loss: 1.096, Test loss: 1.009, Test accuracy: 89.80
Round  58, Global train loss: 1.096, Global test loss: 0.954, Global test accuracy: 95.60
Round  59, Train loss: 0.916, Test loss: 1.009, Test accuracy: 89.82
Round  59, Global train loss: 0.916, Global test loss: 0.947, Global test accuracy: 95.98
Round  60, Train loss: 1.014, Test loss: 1.009, Test accuracy: 89.78
Round  60, Global train loss: 1.014, Global test loss: 0.952, Global test accuracy: 95.52
Round  61, Train loss: 1.103, Test loss: 1.009, Test accuracy: 89.72
Round  61, Global train loss: 1.103, Global test loss: 0.963, Global test accuracy: 94.82
Round  62, Train loss: 1.088, Test loss: 1.009, Test accuracy: 89.74
Round  62, Global train loss: 1.088, Global test loss: 0.964, Global test accuracy: 94.46
Round  63, Train loss: 1.161, Test loss: 1.009, Test accuracy: 89.76
Round  63, Global train loss: 1.161, Global test loss: 0.958, Global test accuracy: 95.20
Round  64, Train loss: 0.916, Test loss: 1.009, Test accuracy: 89.80
Round  64, Global train loss: 0.916, Global test loss: 0.947, Global test accuracy: 95.98
Round  65, Train loss: 1.170, Test loss: 1.010, Test accuracy: 89.64
Round  65, Global train loss: 1.170, Global test loss: 0.965, Global test accuracy: 94.46
Round  66, Train loss: 1.059, Test loss: 1.011, Test accuracy: 89.36
Round  66, Global train loss: 1.059, Global test loss: 0.957, Global test accuracy: 95.26
Round  67, Train loss: 1.176, Test loss: 1.011, Test accuracy: 89.44
Round  67, Global train loss: 1.176, Global test loss: 0.960, Global test accuracy: 95.00
Round  68, Train loss: 1.152, Test loss: 1.011, Test accuracy: 89.40
Round  68, Global train loss: 1.152, Global test loss: 0.967, Global test accuracy: 94.30
Round  69, Train loss: 1.157, Test loss: 1.012, Test accuracy: 89.30
Round  69, Global train loss: 1.157, Global test loss: 0.958, Global test accuracy: 95.16
Round  70, Train loss: 1.089, Test loss: 1.014, Test accuracy: 89.30
Round  70, Global train loss: 1.089, Global test loss: 0.965, Global test accuracy: 94.24
Round  71, Train loss: 1.008, Test loss: 1.014, Test accuracy: 89.26
Round  71, Global train loss: 1.008, Global test loss: 0.947, Global test accuracy: 95.82
Round  72, Train loss: 1.081, Test loss: 1.013, Test accuracy: 89.38
Round  72, Global train loss: 1.081, Global test loss: 0.952, Global test accuracy: 95.70
Round  73, Train loss: 0.932, Test loss: 1.013, Test accuracy: 89.36
Round  73, Global train loss: 0.932, Global test loss: 0.945, Global test accuracy: 96.22
Round  74, Train loss: 1.091, Test loss: 1.014, Test accuracy: 89.26
Round  74, Global train loss: 1.091, Global test loss: 0.966, Global test accuracy: 94.58
Round  75, Train loss: 1.066, Test loss: 1.015, Test accuracy: 89.26
Round  75, Global train loss: 1.066, Global test loss: 0.961, Global test accuracy: 94.46
Round  76, Train loss: 1.113, Test loss: 1.016, Test accuracy: 89.22
Round  76, Global train loss: 1.113, Global test loss: 0.950, Global test accuracy: 95.92
Round  77, Train loss: 1.095, Test loss: 1.015, Test accuracy: 89.22
Round  77, Global train loss: 1.095, Global test loss: 0.945, Global test accuracy: 96.16
Round  78, Train loss: 0.988, Test loss: 1.014, Test accuracy: 89.14
Round  78, Global train loss: 0.988, Global test loss: 0.953, Global test accuracy: 95.42
Round  79, Train loss: 1.079, Test loss: 1.015, Test accuracy: 89.02
Round  79, Global train loss: 1.079, Global test loss: 0.965, Global test accuracy: 94.36
Round  80, Train loss: 1.060, Test loss: 1.014, Test accuracy: 89.16
Round  80, Global train loss: 1.060, Global test loss: 0.952, Global test accuracy: 95.60
Round  81, Train loss: 1.012, Test loss: 1.014, Test accuracy: 89.18
Round  81, Global train loss: 1.012, Global test loss: 0.951, Global test accuracy: 95.66
Round  82, Train loss: 1.139, Test loss: 1.014, Test accuracy: 89.24
Round  82, Global train loss: 1.139, Global test loss: 0.960, Global test accuracy: 94.86
Round  83, Train loss: 1.064, Test loss: 1.014, Test accuracy: 89.16
Round  83, Global train loss: 1.064, Global test loss: 0.956, Global test accuracy: 95.42
Round  84, Train loss: 1.134, Test loss: 1.015, Test accuracy: 89.08
Round  84, Global train loss: 1.134, Global test loss: 0.965, Global test accuracy: 94.44
Round  85, Train loss: 1.075, Test loss: 1.016, Test accuracy: 88.94
Round  85, Global train loss: 1.075, Global test loss: 0.950, Global test accuracy: 95.82
Round  86, Train loss: 0.939, Test loss: 1.016, Test accuracy: 88.94
Round  86, Global train loss: 0.939, Global test loss: 0.945, Global test accuracy: 95.96
Round  87, Train loss: 1.149, Test loss: 1.016, Test accuracy: 88.96
Round  87, Global train loss: 1.149, Global test loss: 0.956, Global test accuracy: 95.44
Round  88, Train loss: 1.072, Test loss: 1.016, Test accuracy: 89.06
Round  88, Global train loss: 1.072, Global test loss: 0.956, Global test accuracy: 95.28
Round  89, Train loss: 1.132, Test loss: 1.015, Test accuracy: 89.06
Round  89, Global train loss: 1.132, Global test loss: 0.965, Global test accuracy: 94.22
Round  90, Train loss: 1.001, Test loss: 1.016, Test accuracy: 89.02
Round  90, Global train loss: 1.001, Global test loss: 0.949, Global test accuracy: 95.84
Round  91, Train loss: 0.916, Test loss: 1.016, Test accuracy: 89.02
Round  91, Global train loss: 0.916, Global test loss: 0.947, Global test accuracy: 96.00
Round  92, Train loss: 1.084, Test loss: 1.016, Test accuracy: 88.96
Round  92, Global train loss: 1.084, Global test loss: 0.951, Global test accuracy: 95.76
Round  93, Train loss: 1.085, Test loss: 1.015, Test accuracy: 89.00
Round  93, Global train loss: 1.085, Global test loss: 0.952, Global test accuracy: 95.18
Round  94, Train loss: 1.071, Test loss: 1.016, Test accuracy: 88.96
Round  94, Global train loss: 1.071, Global test loss: 0.955, Global test accuracy: 95.38/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  95, Train loss: 1.074, Test loss: 1.016, Test accuracy: 88.92
Round  95, Global train loss: 1.074, Global test loss: 0.952, Global test accuracy: 95.74
Round  96, Train loss: 1.075, Test loss: 1.016, Test accuracy: 88.86
Round  96, Global train loss: 1.075, Global test loss: 0.951, Global test accuracy: 95.34
Round  97, Train loss: 1.055, Test loss: 1.017, Test accuracy: 88.78
Round  97, Global train loss: 1.055, Global test loss: 0.964, Global test accuracy: 94.46
Round  98, Train loss: 1.005, Test loss: 1.017, Test accuracy: 88.76
Round  98, Global train loss: 1.005, Global test loss: 0.945, Global test accuracy: 96.30
Round  99, Train loss: 1.015, Test loss: 1.017, Test accuracy: 88.78
Round  99, Global train loss: 1.015, Global test loss: 0.944, Global test accuracy: 96.12
Final Round, Train loss: 1.059, Test loss: 1.016, Test accuracy: 88.94
Final Round, Global train loss: 1.059, Global test loss: 0.944, Global test accuracy: 96.12
Average accuracy final 10 rounds: 88.90599999999999 

Average global accuracy final 10 rounds: 95.612 

594.5105655193329
[0.8989567756652832, 1.7979135513305664, 2.6618618965148926, 3.5258102416992188, 4.652569770812988, 5.779329299926758, 6.558971405029297, 7.338613510131836, 8.110796451568604, 8.882979393005371, 9.724572658538818, 10.566165924072266, 11.345996856689453, 12.12582778930664, 12.887071371078491, 13.648314952850342, 14.433104276657104, 15.217893600463867, 16.021129608154297, 16.824365615844727, 17.59321427345276, 18.36206293106079, 19.13124680519104, 19.90043067932129, 20.66770887374878, 21.43498706817627, 22.20629644393921, 22.97760581970215, 23.750750303268433, 24.523894786834717, 25.288429260253906, 26.052963733673096, 26.833939790725708, 27.61491584777832, 28.403730869293213, 29.192545890808105, 29.970598697662354, 30.7486515045166, 31.532136917114258, 32.315622329711914, 33.10155940055847, 33.88749647140503, 34.656283378601074, 35.42507028579712, 36.19083833694458, 36.95660638809204, 37.723954916000366, 38.49130344390869, 39.25792932510376, 40.02455520629883, 40.79143452644348, 41.558313846588135, 42.33801984786987, 43.11772584915161, 43.88722491264343, 44.656723976135254, 45.40902614593506, 46.16132831573486, 46.908467292785645, 47.655606269836426, 48.39427208900452, 49.13293790817261, 49.88096499443054, 50.62899208068848, 51.38805079460144, 52.147109508514404, 52.89468502998352, 53.64226055145264, 54.398502826690674, 55.15474510192871, 55.90981578826904, 56.664886474609375, 57.43265748023987, 58.20042848587036, 58.97131872177124, 59.74220895767212, 60.49144387245178, 61.240678787231445, 62.00790095329285, 62.77512311935425, 63.54100203514099, 64.30688095092773, 65.06895852088928, 65.83103609085083, 66.58930468559265, 67.34757328033447, 68.1161093711853, 68.88464546203613, 69.64791703224182, 70.41118860244751, 71.16246294975281, 71.9137372970581, 72.67910242080688, 73.44446754455566, 74.21449375152588, 74.9845199584961, 75.76766157150269, 76.55080318450928, 77.30902695655823, 78.06725072860718, 78.84778308868408, 79.62831544876099, 80.47227954864502, 81.31624364852905, 82.06657385826111, 82.81690406799316, 83.55806589126587, 84.29922771453857, 85.08655405044556, 85.87388038635254, 86.6436812877655, 87.41348218917847, 88.29102969169617, 89.16857719421387, 89.98005700111389, 90.79153680801392, 91.56258130073547, 92.33362579345703, 93.10444355010986, 93.8752613067627, 94.60499024391174, 95.33471918106079, 96.15042567253113, 96.96613216400146, 97.73788523674011, 98.50963830947876, 99.30612468719482, 100.10261106491089, 100.87112164497375, 101.63963222503662, 102.41369390487671, 103.1877555847168, 103.95614242553711, 104.72452926635742, 105.50669240951538, 106.28885555267334, 107.041574716568, 107.79429388046265, 108.54266214370728, 109.2910304069519, 110.04293775558472, 110.79484510421753, 111.5450165271759, 112.29518795013428, 113.04454207420349, 113.7938961982727, 114.54552388191223, 115.29715156555176, 116.05049777030945, 116.80384397506714, 117.58990216255188, 118.37596035003662, 119.21528029441833, 120.05460023880005, 120.83054566383362, 121.60649108886719, 122.38597369194031, 123.16545629501343, 123.91843390464783, 124.67141151428223, 125.44633197784424, 126.22125244140625, 126.98515057563782, 127.74904870986938, 128.51311683654785, 129.27718496322632, 130.0554461479187, 130.83370733261108, 131.6075222492218, 132.38133716583252, 133.11874771118164, 133.85615825653076, 134.6400110721588, 135.42386388778687, 136.16611552238464, 136.90836715698242, 137.65150046348572, 138.394633769989, 139.1430823802948, 139.8915309906006, 140.63925552368164, 141.3869800567627, 142.16569352149963, 142.94440698623657, 143.6893162727356, 144.43422555923462, 145.18350863456726, 145.9327917098999, 146.71961522102356, 147.50643873214722, 148.26948523521423, 149.03253173828125, 149.7885947227478, 150.54465770721436, 151.28291249275208, 152.0211672782898, 152.7607536315918, 153.5003399848938, 154.2784833908081, 155.0566267967224, 156.64738941192627, 158.23815202713013]
[65.64, 65.64, 72.74, 72.74, 86.42, 86.42, 86.7, 86.7, 85.8, 85.8, 85.82, 85.82, 89.5, 89.5, 90.86, 90.86, 92.22, 92.22, 93.02, 93.02, 92.74, 92.74, 93.8, 93.8, 93.6, 93.6, 93.56, 93.56, 93.68, 93.68, 93.2, 93.2, 93.5, 93.5, 93.26, 93.26, 93.28, 93.28, 93.06, 93.06, 93.04, 93.04, 93.04, 93.04, 92.86, 92.86, 92.72, 92.72, 92.6, 92.6, 92.22, 92.22, 92.08, 92.08, 91.52, 91.52, 91.4, 91.4, 91.5, 91.5, 91.34, 91.34, 91.3, 91.3, 91.24, 91.24, 91.18, 91.18, 91.08, 91.08, 90.88, 90.88, 90.8, 90.8, 90.72, 90.72, 90.66, 90.66, 90.64, 90.64, 90.8, 90.8, 90.56, 90.56, 90.64, 90.64, 90.52, 90.52, 90.52, 90.52, 90.18, 90.18, 90.12, 90.12, 89.96, 89.96, 90.06, 90.06, 90.12, 90.12, 90.2, 90.2, 90.12, 90.12, 90.36, 90.36, 90.34, 90.34, 90.24, 90.24, 89.96, 89.96, 89.84, 89.84, 89.84, 89.84, 89.8, 89.8, 89.82, 89.82, 89.78, 89.78, 89.72, 89.72, 89.74, 89.74, 89.76, 89.76, 89.8, 89.8, 89.64, 89.64, 89.36, 89.36, 89.44, 89.44, 89.4, 89.4, 89.3, 89.3, 89.3, 89.3, 89.26, 89.26, 89.38, 89.38, 89.36, 89.36, 89.26, 89.26, 89.26, 89.26, 89.22, 89.22, 89.22, 89.22, 89.14, 89.14, 89.02, 89.02, 89.16, 89.16, 89.18, 89.18, 89.24, 89.24, 89.16, 89.16, 89.08, 89.08, 88.94, 88.94, 88.94, 88.94, 88.96, 88.96, 89.06, 89.06, 89.06, 89.06, 89.02, 89.02, 89.02, 89.02, 88.96, 88.96, 89.0, 89.0, 88.96, 88.96, 88.92, 88.92, 88.86, 88.86, 88.78, 88.78, 88.76, 88.76, 88.78, 88.78, 88.94, 88.94]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.6 , level_n_lowerb:0.4  

   Client 2, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.596, Test loss: 1.563, Test accuracy: 51.26
Round   0, Global train loss: 1.596, Global test loss: 1.564, Global test accuracy: 53.04
Round   1, Train loss: 1.529, Test loss: 1.428, Test accuracy: 68.48
Round   1, Global train loss: 1.529, Global test loss: 1.401, Global test accuracy: 75.18
Round   2, Train loss: 1.312, Test loss: 1.204, Test accuracy: 80.34
Round   2, Global train loss: 1.312, Global test loss: 1.068, Global test accuracy: 92.74
Round   3, Train loss: 1.179, Test loss: 1.104, Test accuracy: 86.60
Round   3, Global train loss: 1.179, Global test loss: 0.987, Global test accuracy: 94.16
Round   4, Train loss: 1.058, Test loss: 1.035, Test accuracy: 91.28
Round   4, Global train loss: 1.058, Global test loss: 0.961, Global test accuracy: 95.74
Round   5, Train loss: 1.092, Test loss: 0.986, Test accuracy: 93.78
Round   5, Global train loss: 1.092, Global test loss: 0.951, Global test accuracy: 96.52
Round   6, Train loss: 1.160, Test loss: 0.978, Test accuracy: 94.12
Round   6, Global train loss: 1.160, Global test loss: 0.950, Global test accuracy: 96.50
Round   7, Train loss: 1.095, Test loss: 0.977, Test accuracy: 94.12
Round   7, Global train loss: 1.095, Global test loss: 0.945, Global test accuracy: 96.82
Round   8, Train loss: 1.135, Test loss: 0.972, Test accuracy: 94.48
Round   8, Global train loss: 1.135, Global test loss: 0.943, Global test accuracy: 96.86
Round   9, Train loss: 1.168, Test loss: 0.949, Test accuracy: 96.18
Round   9, Global train loss: 1.168, Global test loss: 0.942, Global test accuracy: 96.70
Round  10, Train loss: 1.180, Test loss: 0.948, Test accuracy: 96.34
Round  10, Global train loss: 1.180, Global test loss: 0.942, Global test accuracy: 96.82
Round  11, Train loss: 1.171, Test loss: 0.948, Test accuracy: 96.10
Round  11, Global train loss: 1.171, Global test loss: 0.942, Global test accuracy: 96.64
Round  12, Train loss: 1.075, Test loss: 0.948, Test accuracy: 95.98
Round  12, Global train loss: 1.075, Global test loss: 0.940, Global test accuracy: 96.92
Round  13, Train loss: 0.957, Test loss: 0.949, Test accuracy: 96.02
Round  13, Global train loss: 0.957, Global test loss: 0.939, Global test accuracy: 96.68
Round  14, Train loss: 1.151, Test loss: 0.947, Test accuracy: 96.14
Round  14, Global train loss: 1.151, Global test loss: 0.938, Global test accuracy: 96.96
Round  15, Train loss: 1.188, Test loss: 0.946, Test accuracy: 96.34
Round  15, Global train loss: 1.188, Global test loss: 0.942, Global test accuracy: 96.54
Round  16, Train loss: 1.141, Test loss: 0.946, Test accuracy: 96.30
Round  16, Global train loss: 1.141, Global test loss: 0.939, Global test accuracy: 97.08
Round  17, Train loss: 1.143, Test loss: 0.947, Test accuracy: 96.28
Round  17, Global train loss: 1.143, Global test loss: 0.938, Global test accuracy: 97.14
Round  18, Train loss: 1.163, Test loss: 0.948, Test accuracy: 96.10
Round  18, Global train loss: 1.163, Global test loss: 0.940, Global test accuracy: 96.72
Round  19, Train loss: 1.143, Test loss: 0.948, Test accuracy: 96.00
Round  19, Global train loss: 1.143, Global test loss: 0.944, Global test accuracy: 96.46
Round  20, Train loss: 1.035, Test loss: 0.948, Test accuracy: 96.04
Round  20, Global train loss: 1.035, Global test loss: 0.938, Global test accuracy: 97.14
Round  21, Train loss: 1.142, Test loss: 0.946, Test accuracy: 96.14
Round  21, Global train loss: 1.142, Global test loss: 0.937, Global test accuracy: 96.86
Round  22, Train loss: 1.273, Test loss: 0.946, Test accuracy: 96.30
Round  22, Global train loss: 1.273, Global test loss: 0.940, Global test accuracy: 96.84
Round  23, Train loss: 1.035, Test loss: 0.945, Test accuracy: 96.24
Round  23, Global train loss: 1.035, Global test loss: 0.939, Global test accuracy: 96.70
Round  24, Train loss: 1.064, Test loss: 0.945, Test accuracy: 96.20
Round  24, Global train loss: 1.064, Global test loss: 0.939, Global test accuracy: 96.66
Round  25, Train loss: 1.167, Test loss: 0.945, Test accuracy: 96.28
Round  25, Global train loss: 1.167, Global test loss: 0.940, Global test accuracy: 96.62
Round  26, Train loss: 1.155, Test loss: 0.947, Test accuracy: 96.16
Round  26, Global train loss: 1.155, Global test loss: 0.941, Global test accuracy: 96.52
Round  27, Train loss: 1.237, Test loss: 0.946, Test accuracy: 96.18
Round  27, Global train loss: 1.237, Global test loss: 0.940, Global test accuracy: 96.68
Round  28, Train loss: 1.180, Test loss: 0.944, Test accuracy: 96.30
Round  28, Global train loss: 1.180, Global test loss: 0.941, Global test accuracy: 96.52
Round  29, Train loss: 1.250, Test loss: 0.945, Test accuracy: 96.16
Round  29, Global train loss: 1.250, Global test loss: 0.943, Global test accuracy: 96.36
Round  30, Train loss: 1.150, Test loss: 0.946, Test accuracy: 96.16
Round  30, Global train loss: 1.150, Global test loss: 0.942, Global test accuracy: 96.58
Round  31, Train loss: 1.136, Test loss: 0.946, Test accuracy: 96.12
Round  31, Global train loss: 1.136, Global test loss: 0.939, Global test accuracy: 96.76
Round  32, Train loss: 1.133, Test loss: 0.947, Test accuracy: 96.00
Round  32, Global train loss: 1.133, Global test loss: 0.940, Global test accuracy: 96.64
Round  33, Train loss: 1.133, Test loss: 0.947, Test accuracy: 96.00
Round  33, Global train loss: 1.133, Global test loss: 0.940, Global test accuracy: 96.66
Round  34, Train loss: 1.146, Test loss: 0.946, Test accuracy: 96.00
Round  34, Global train loss: 1.146, Global test loss: 0.940, Global test accuracy: 96.88
Round  35, Train loss: 1.059, Test loss: 0.947, Test accuracy: 96.04
Round  35, Global train loss: 1.059, Global test loss: 0.940, Global test accuracy: 96.60
Round  36, Train loss: 1.132, Test loss: 0.946, Test accuracy: 96.02
Round  36, Global train loss: 1.132, Global test loss: 0.939, Global test accuracy: 96.62
Round  37, Train loss: 1.021, Test loss: 0.946, Test accuracy: 96.00
Round  37, Global train loss: 1.021, Global test loss: 0.940, Global test accuracy: 96.66
Round  38, Train loss: 1.020, Test loss: 0.946, Test accuracy: 96.04
Round  38, Global train loss: 1.020, Global test loss: 0.939, Global test accuracy: 96.72
Round  39, Train loss: 1.144, Test loss: 0.946, Test accuracy: 96.12
Round  39, Global train loss: 1.144, Global test loss: 0.943, Global test accuracy: 96.10
Round  40, Train loss: 0.941, Test loss: 0.946, Test accuracy: 96.10
Round  40, Global train loss: 0.941, Global test loss: 0.939, Global test accuracy: 96.56
Round  41, Train loss: 1.119, Test loss: 0.946, Test accuracy: 96.08
Round  41, Global train loss: 1.119, Global test loss: 0.940, Global test accuracy: 96.64
Round  42, Train loss: 1.249, Test loss: 0.946, Test accuracy: 96.04
Round  42, Global train loss: 1.249, Global test loss: 0.942, Global test accuracy: 96.44
Round  43, Train loss: 1.247, Test loss: 0.946, Test accuracy: 96.04
Round  43, Global train loss: 1.247, Global test loss: 0.942, Global test accuracy: 96.42
Round  44, Train loss: 1.060, Test loss: 0.946, Test accuracy: 96.10
Round  44, Global train loss: 1.060, Global test loss: 0.940, Global test accuracy: 96.60
Round  45, Train loss: 1.144, Test loss: 0.946, Test accuracy: 96.10
Round  45, Global train loss: 1.144, Global test loss: 0.944, Global test accuracy: 96.30
Round  46, Train loss: 1.054, Test loss: 0.946, Test accuracy: 96.10
Round  46, Global train loss: 1.054, Global test loss: 0.940, Global test accuracy: 96.62
Round  47, Train loss: 1.052, Test loss: 0.947, Test accuracy: 96.00
Round  47, Global train loss: 1.052, Global test loss: 0.940, Global test accuracy: 96.52
Round  48, Train loss: 0.941, Test loss: 0.947, Test accuracy: 96.00
Round  48, Global train loss: 0.941, Global test loss: 0.940, Global test accuracy: 96.30
Round  49, Train loss: 1.158, Test loss: 0.946, Test accuracy: 95.96
Round  49, Global train loss: 1.158, Global test loss: 0.940, Global test accuracy: 96.34
Round  50, Train loss: 1.141, Test loss: 0.946, Test accuracy: 95.94
Round  50, Global train loss: 1.141, Global test loss: 0.940, Global test accuracy: 96.70
Round  51, Train loss: 1.028, Test loss: 0.946, Test accuracy: 96.00
Round  51, Global train loss: 1.028, Global test loss: 0.939, Global test accuracy: 96.62
Round  52, Train loss: 1.140, Test loss: 0.949, Test accuracy: 95.80
Round  52, Global train loss: 1.140, Global test loss: 0.952, Global test accuracy: 95.32
Round  53, Train loss: 1.127, Test loss: 0.949, Test accuracy: 95.72
Round  53, Global train loss: 1.127, Global test loss: 0.941, Global test accuracy: 96.52
Round  54, Train loss: 1.055, Test loss: 0.950, Test accuracy: 95.64
Round  54, Global train loss: 1.055, Global test loss: 0.942, Global test accuracy: 96.26
Round  55, Train loss: 1.230, Test loss: 0.949, Test accuracy: 95.68
Round  55, Global train loss: 1.230, Global test loss: 0.941, Global test accuracy: 96.34
Round  56, Train loss: 1.017, Test loss: 0.950, Test accuracy: 95.64
Round  56, Global train loss: 1.017, Global test loss: 0.940, Global test accuracy: 96.68
Round  57, Train loss: 1.155, Test loss: 0.949, Test accuracy: 95.76
Round  57, Global train loss: 1.155, Global test loss: 0.943, Global test accuracy: 96.44
Round  58, Train loss: 1.125, Test loss: 0.950, Test accuracy: 95.72
Round  58, Global train loss: 1.125, Global test loss: 0.940, Global test accuracy: 96.56
Round  59, Train loss: 1.025, Test loss: 0.950, Test accuracy: 95.64
Round  59, Global train loss: 1.025, Global test loss: 0.940, Global test accuracy: 96.52
Round  60, Train loss: 1.246, Test loss: 0.950, Test accuracy: 95.66
Round  60, Global train loss: 1.246, Global test loss: 0.942, Global test accuracy: 96.48
Round  61, Train loss: 1.239, Test loss: 0.950, Test accuracy: 95.72
Round  61, Global train loss: 1.239, Global test loss: 0.943, Global test accuracy: 96.32
Round  62, Train loss: 1.136, Test loss: 0.947, Test accuracy: 95.94
Round  62, Global train loss: 1.136, Global test loss: 0.950, Global test accuracy: 95.54
Round  63, Train loss: 1.042, Test loss: 0.947, Test accuracy: 95.88
Round  63, Global train loss: 1.042, Global test loss: 0.945, Global test accuracy: 96.10
Round  64, Train loss: 1.025, Test loss: 0.948, Test accuracy: 95.80
Round  64, Global train loss: 1.025, Global test loss: 0.941, Global test accuracy: 96.32
Round  65, Train loss: 1.137, Test loss: 0.948, Test accuracy: 95.90
Round  65, Global train loss: 1.137, Global test loss: 0.948, Global test accuracy: 95.74
Round  66, Train loss: 1.125, Test loss: 0.949, Test accuracy: 95.78
Round  66, Global train loss: 1.125, Global test loss: 0.942, Global test accuracy: 96.36
Round  67, Train loss: 1.125, Test loss: 0.948, Test accuracy: 95.80
Round  67, Global train loss: 1.125, Global test loss: 0.942, Global test accuracy: 96.40
Round  68, Train loss: 1.150, Test loss: 0.947, Test accuracy: 95.86
Round  68, Global train loss: 1.150, Global test loss: 0.943, Global test accuracy: 96.08
Round  69, Train loss: 1.039, Test loss: 0.947, Test accuracy: 95.84
Round  69, Global train loss: 1.039, Global test loss: 0.945, Global test accuracy: 95.98
Round  70, Train loss: 1.240, Test loss: 0.948, Test accuracy: 95.80
Round  70, Global train loss: 1.240, Global test loss: 0.944, Global test accuracy: 96.12
Round  71, Train loss: 1.021, Test loss: 0.948, Test accuracy: 95.82
Round  71, Global train loss: 1.021, Global test loss: 0.941, Global test accuracy: 96.52
Round  72, Train loss: 1.053, Test loss: 0.947, Test accuracy: 95.94
Round  72, Global train loss: 1.053, Global test loss: 0.942, Global test accuracy: 96.30
Round  73, Train loss: 1.026, Test loss: 0.948, Test accuracy: 95.74
Round  73, Global train loss: 1.026, Global test loss: 0.939, Global test accuracy: 96.58
Round  74, Train loss: 1.248, Test loss: 0.948, Test accuracy: 95.82
Round  74, Global train loss: 1.248, Global test loss: 0.947, Global test accuracy: 95.84
Round  75, Train loss: 1.121, Test loss: 0.948, Test accuracy: 95.78
Round  75, Global train loss: 1.121, Global test loss: 0.942, Global test accuracy: 96.50
Round  76, Train loss: 1.164, Test loss: 0.947, Test accuracy: 95.92
Round  76, Global train loss: 1.164, Global test loss: 0.942, Global test accuracy: 96.32
Round  77, Train loss: 1.052, Test loss: 0.948, Test accuracy: 95.82
Round  77, Global train loss: 1.052, Global test loss: 0.941, Global test accuracy: 96.28
Round  78, Train loss: 1.129, Test loss: 0.947, Test accuracy: 95.88
Round  78, Global train loss: 1.129, Global test loss: 0.942, Global test accuracy: 96.36
Round  79, Train loss: 1.131, Test loss: 0.948, Test accuracy: 95.74
Round  79, Global train loss: 1.131, Global test loss: 0.948, Global test accuracy: 95.72
Round  80, Train loss: 1.021, Test loss: 0.948, Test accuracy: 95.74
Round  80, Global train loss: 1.021, Global test loss: 0.940, Global test accuracy: 96.70
Round  81, Train loss: 1.249, Test loss: 0.948, Test accuracy: 95.78
Round  81, Global train loss: 1.249, Global test loss: 0.943, Global test accuracy: 96.46
Round  82, Train loss: 1.115, Test loss: 0.947, Test accuracy: 95.78
Round  82, Global train loss: 1.115, Global test loss: 0.946, Global test accuracy: 95.84
Round  83, Train loss: 1.135, Test loss: 0.947, Test accuracy: 95.82
Round  83, Global train loss: 1.135, Global test loss: 0.942, Global test accuracy: 96.50
Round  84, Train loss: 1.149, Test loss: 0.948, Test accuracy: 95.76
Round  84, Global train loss: 1.149, Global test loss: 0.942, Global test accuracy: 96.48
Round  85, Train loss: 1.051, Test loss: 0.948, Test accuracy: 95.72
Round  85, Global train loss: 1.051, Global test loss: 0.942, Global test accuracy: 96.30
Round  86, Train loss: 1.137, Test loss: 0.948, Test accuracy: 95.68
Round  86, Global train loss: 1.137, Global test loss: 0.940, Global test accuracy: 96.40
Round  87, Train loss: 1.125, Test loss: 0.948, Test accuracy: 95.72
Round  87, Global train loss: 1.125, Global test loss: 0.941, Global test accuracy: 96.64
Round  88, Train loss: 1.234, Test loss: 0.947, Test accuracy: 95.82
Round  88, Global train loss: 1.234, Global test loss: 0.944, Global test accuracy: 96.18
Round  89, Train loss: 1.148, Test loss: 0.948, Test accuracy: 95.76
Round  89, Global train loss: 1.148, Global test loss: 0.941, Global test accuracy: 96.58
Round  90, Train loss: 1.124, Test loss: 0.948, Test accuracy: 95.80
Round  90, Global train loss: 1.124, Global test loss: 0.941, Global test accuracy: 96.62
Round  91, Train loss: 1.024, Test loss: 0.948, Test accuracy: 95.78
Round  91, Global train loss: 1.024, Global test loss: 0.940, Global test accuracy: 96.70
Round  92, Train loss: 1.135, Test loss: 0.948, Test accuracy: 95.78
Round  92, Global train loss: 1.135, Global test loss: 0.941, Global test accuracy: 96.66
Round  93, Train loss: 1.156, Test loss: 0.948, Test accuracy: 95.74
Round  93, Global train loss: 1.156, Global test loss: 0.945, Global test accuracy: 96.08
Round  94, Train loss: 1.124, Test loss: 0.948, Test accuracy: 95.74
Round  94, Global train loss: 1.124, Global test loss: 0.941, Global test accuracy: 96.64/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  95, Train loss: 1.037, Test loss: 0.948, Test accuracy: 95.74
Round  95, Global train loss: 1.037, Global test loss: 0.943, Global test accuracy: 96.12
Round  96, Train loss: 1.036, Test loss: 0.948, Test accuracy: 95.80
Round  96, Global train loss: 1.036, Global test loss: 0.942, Global test accuracy: 96.24
Round  97, Train loss: 1.236, Test loss: 0.949, Test accuracy: 95.84
Round  97, Global train loss: 1.236, Global test loss: 0.944, Global test accuracy: 96.30
Round  98, Train loss: 1.021, Test loss: 0.948, Test accuracy: 95.90
Round  98, Global train loss: 1.021, Global test loss: 0.941, Global test accuracy: 96.46
Round  99, Train loss: 1.047, Test loss: 0.948, Test accuracy: 95.84
Round  99, Global train loss: 1.047, Global test loss: 0.941, Global test accuracy: 96.52
Final Round, Train loss: 1.112, Test loss: 0.948, Test accuracy: 95.68
Final Round, Global train loss: 1.112, Global test loss: 0.941, Global test accuracy: 96.52
Average accuracy final 10 rounds: 95.796 

Average global accuracy final 10 rounds: 96.434 

630.621199131012
[0.8743927478790283, 1.7487854957580566, 2.536264181137085, 3.3237428665161133, 4.159494638442993, 4.995246410369873, 5.752002239227295, 6.508758068084717, 7.254702091217041, 8.000646114349365, 8.772488117218018, 9.54433012008667, 10.318532466888428, 11.092734813690186, 11.836876392364502, 12.581017971038818, 13.38609766960144, 14.191177368164062, 14.962282419204712, 15.733387470245361, 16.479979991912842, 17.226572513580322, 18.014642477035522, 18.802712440490723, 19.5567843914032, 20.310856342315674, 21.089096069335938, 21.8673357963562, 22.60170030593872, 23.33606481552124, 24.075140476226807, 24.814216136932373, 25.55862593650818, 26.303035736083984, 27.051973581314087, 27.80091142654419, 28.570069551467896, 29.3392276763916, 30.093882083892822, 30.848536491394043, 31.603213787078857, 32.35789108276367, 33.10035228729248, 33.84281349182129, 34.65818643569946, 35.47355937957764, 36.24097800254822, 37.0083966255188, 37.75720143318176, 38.50600624084473, 39.274802684783936, 40.043599128723145, 40.81010293960571, 41.57660675048828, 42.371687173843384, 43.166767597198486, 43.90512466430664, 44.643481731414795, 45.42185091972351, 46.20022010803223, 47.02968072891235, 47.85914134979248, 48.63248109817505, 49.40582084655762, 50.211663246154785, 51.01750564575195, 51.854522466659546, 52.69153928756714, 53.46895790100098, 54.246376514434814, 55.020923376083374, 55.795470237731934, 56.6011438369751, 57.40681743621826, 58.21019649505615, 59.01357555389404, 59.81217622756958, 60.61077690124512, 61.38633394241333, 62.16189098358154, 62.95014572143555, 63.73840045928955, 64.54599404335022, 65.35358762741089, 66.18899631500244, 67.024405002594, 67.82150959968567, 68.61861419677734, 69.62629175186157, 70.6339693069458, 71.41201210021973, 72.19005489349365, 72.93890476226807, 73.68775463104248, 74.45597815513611, 75.22420167922974, 75.99751400947571, 76.77082633972168, 77.55446648597717, 78.33810663223267, 79.10332036018372, 79.86853408813477, 80.65198922157288, 81.43544435501099, 82.22357892990112, 83.01171350479126, 83.78306221961975, 84.55441093444824, 85.32427334785461, 86.09413576126099, 86.88871192932129, 87.68328809738159, 88.4558653831482, 89.2284426689148, 89.99854922294617, 90.76865577697754, 91.53094482421875, 92.29323387145996, 93.06384372711182, 93.83445358276367, 94.59638261795044, 95.3583116531372, 96.67438101768494, 97.99045038223267, 99.20761919021606, 100.42478799819946, 101.64763569831848, 102.8704833984375, 104.25013256072998, 105.62978172302246, 106.87224316596985, 108.11470460891724, 109.29778861999512, 110.480872631073, 111.5016188621521, 112.5223650932312, 113.49535298347473, 114.46834087371826, 115.36871147155762, 116.26908206939697, 117.3294460773468, 118.38981008529663, 119.32885026931763, 120.26789045333862, 121.32237839698792, 122.3768663406372, 123.1458432674408, 123.91482019424438, 124.68431258201599, 125.4538049697876, 126.22635126113892, 126.99889755249023, 127.77817940711975, 128.55746126174927, 129.33152842521667, 130.10559558868408, 130.88476276397705, 131.66392993927002, 132.3956024646759, 133.1272749900818, 133.88797283172607, 134.64867067337036, 135.42934250831604, 136.21001434326172, 136.9722719192505, 137.73452949523926, 138.6859495639801, 139.63736963272095, 140.4024622440338, 141.16755485534668, 141.9298379421234, 142.69212102890015, 143.50325274467468, 144.31438446044922, 145.07995510101318, 145.84552574157715, 146.62410807609558, 147.402690410614, 148.16551637649536, 148.9283423423767, 149.73736929893494, 150.54639625549316, 151.40309047698975, 152.25978469848633, 153.03269457817078, 153.80560445785522, 154.65285563468933, 155.50010681152344, 156.25721883773804, 157.01433086395264, 157.77822399139404, 158.54211711883545, 159.30182099342346, 160.06152486801147, 160.82118964195251, 161.58085441589355, 162.34293270111084, 163.10501098632812, 163.86526942253113, 164.62552785873413, 166.16172695159912, 167.6979260444641]
[51.26, 51.26, 68.48, 68.48, 80.34, 80.34, 86.6, 86.6, 91.28, 91.28, 93.78, 93.78, 94.12, 94.12, 94.12, 94.12, 94.48, 94.48, 96.18, 96.18, 96.34, 96.34, 96.1, 96.1, 95.98, 95.98, 96.02, 96.02, 96.14, 96.14, 96.34, 96.34, 96.3, 96.3, 96.28, 96.28, 96.1, 96.1, 96.0, 96.0, 96.04, 96.04, 96.14, 96.14, 96.3, 96.3, 96.24, 96.24, 96.2, 96.2, 96.28, 96.28, 96.16, 96.16, 96.18, 96.18, 96.3, 96.3, 96.16, 96.16, 96.16, 96.16, 96.12, 96.12, 96.0, 96.0, 96.0, 96.0, 96.0, 96.0, 96.04, 96.04, 96.02, 96.02, 96.0, 96.0, 96.04, 96.04, 96.12, 96.12, 96.1, 96.1, 96.08, 96.08, 96.04, 96.04, 96.04, 96.04, 96.1, 96.1, 96.1, 96.1, 96.1, 96.1, 96.0, 96.0, 96.0, 96.0, 95.96, 95.96, 95.94, 95.94, 96.0, 96.0, 95.8, 95.8, 95.72, 95.72, 95.64, 95.64, 95.68, 95.68, 95.64, 95.64, 95.76, 95.76, 95.72, 95.72, 95.64, 95.64, 95.66, 95.66, 95.72, 95.72, 95.94, 95.94, 95.88, 95.88, 95.8, 95.8, 95.9, 95.9, 95.78, 95.78, 95.8, 95.8, 95.86, 95.86, 95.84, 95.84, 95.8, 95.8, 95.82, 95.82, 95.94, 95.94, 95.74, 95.74, 95.82, 95.82, 95.78, 95.78, 95.92, 95.92, 95.82, 95.82, 95.88, 95.88, 95.74, 95.74, 95.74, 95.74, 95.78, 95.78, 95.78, 95.78, 95.82, 95.82, 95.76, 95.76, 95.72, 95.72, 95.68, 95.68, 95.72, 95.72, 95.82, 95.82, 95.76, 95.76, 95.8, 95.8, 95.78, 95.78, 95.78, 95.78, 95.74, 95.74, 95.74, 95.74, 95.74, 95.74, 95.8, 95.8, 95.84, 95.84, 95.9, 95.9, 95.84, 95.84, 95.68, 95.68]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.6 , level_n_lowerb:0.4  

   Client 3, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
prox
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.593, Test loss: 1.556, Test accuracy: 43.88
Round   0, Global train loss: 1.593, Global test loss: 1.556, Global test accuracy: 44.36
Round   1, Train loss: 1.536, Test loss: 1.452, Test accuracy: 60.20
Round   1, Global train loss: 1.536, Global test loss: 1.432, Global test accuracy: 63.18
Round   2, Train loss: 1.460, Test loss: 1.329, Test accuracy: 72.60
Round   2, Global train loss: 1.460, Global test loss: 1.255, Global test accuracy: 81.74
Round   3, Train loss: 1.264, Test loss: 1.154, Test accuracy: 83.52
Round   3, Global train loss: 1.264, Global test loss: 1.039, Global test accuracy: 93.40
Round   4, Train loss: 1.084, Test loss: 1.068, Test accuracy: 89.50
Round   4, Global train loss: 1.084, Global test loss: 0.978, Global test accuracy: 95.46
Round   5, Train loss: 1.165, Test loss: 1.024, Test accuracy: 92.94
Round   5, Global train loss: 1.165, Global test loss: 0.965, Global test accuracy: 95.86
Round   6, Train loss: 1.173, Test loss: 1.003, Test accuracy: 93.48
Round   6, Global train loss: 1.173, Global test loss: 0.957, Global test accuracy: 96.40
Round   7, Train loss: 1.165, Test loss: 1.000, Test accuracy: 93.54
Round   7, Global train loss: 1.165, Global test loss: 0.951, Global test accuracy: 96.50
Round   8, Train loss: 1.059, Test loss: 0.994, Test accuracy: 93.78
Round   8, Global train loss: 1.059, Global test loss: 0.947, Global test accuracy: 96.60
Round   9, Train loss: 1.258, Test loss: 0.956, Test accuracy: 95.86
Round   9, Global train loss: 1.258, Global test loss: 0.947, Global test accuracy: 96.60
Round  10, Train loss: 1.261, Test loss: 0.954, Test accuracy: 96.10
Round  10, Global train loss: 1.261, Global test loss: 0.947, Global test accuracy: 96.54
Round  11, Train loss: 1.097, Test loss: 0.953, Test accuracy: 96.10
Round  11, Global train loss: 1.097, Global test loss: 0.944, Global test accuracy: 96.38
Round  12, Train loss: 1.255, Test loss: 0.951, Test accuracy: 96.10
Round  12, Global train loss: 1.255, Global test loss: 0.942, Global test accuracy: 96.66
Round  13, Train loss: 1.039, Test loss: 0.952, Test accuracy: 95.98
Round  13, Global train loss: 1.039, Global test loss: 0.942, Global test accuracy: 96.62
Round  14, Train loss: 1.159, Test loss: 0.950, Test accuracy: 96.20
Round  14, Global train loss: 1.159, Global test loss: 0.940, Global test accuracy: 96.82
Round  15, Train loss: 1.197, Test loss: 0.947, Test accuracy: 96.38
Round  15, Global train loss: 1.197, Global test loss: 0.942, Global test accuracy: 96.52
Round  16, Train loss: 0.991, Test loss: 0.947, Test accuracy: 96.40
Round  16, Global train loss: 0.991, Global test loss: 0.939, Global test accuracy: 96.94
Round  17, Train loss: 1.056, Test loss: 0.947, Test accuracy: 96.42
Round  17, Global train loss: 1.056, Global test loss: 0.938, Global test accuracy: 97.04
Round  18, Train loss: 1.143, Test loss: 0.945, Test accuracy: 96.44
Round  18, Global train loss: 1.143, Global test loss: 0.938, Global test accuracy: 96.96
Round  19, Train loss: 1.047, Test loss: 0.945, Test accuracy: 96.38
Round  19, Global train loss: 1.047, Global test loss: 0.939, Global test accuracy: 97.02
Round  20, Train loss: 1.129, Test loss: 0.946, Test accuracy: 96.34
Round  20, Global train loss: 1.129, Global test loss: 0.938, Global test accuracy: 97.06
Round  21, Train loss: 1.151, Test loss: 0.945, Test accuracy: 96.42
Round  21, Global train loss: 1.151, Global test loss: 0.938, Global test accuracy: 96.96
Round  22, Train loss: 1.249, Test loss: 0.945, Test accuracy: 96.40
Round  22, Global train loss: 1.249, Global test loss: 0.939, Global test accuracy: 96.86
Round  23, Train loss: 1.078, Test loss: 0.945, Test accuracy: 96.38
Round  23, Global train loss: 1.078, Global test loss: 0.938, Global test accuracy: 96.90
Round  24, Train loss: 1.246, Test loss: 0.945, Test accuracy: 96.30
Round  24, Global train loss: 1.246, Global test loss: 0.939, Global test accuracy: 96.66
Round  25, Train loss: 1.158, Test loss: 0.945, Test accuracy: 96.32
Round  25, Global train loss: 1.158, Global test loss: 0.939, Global test accuracy: 96.68
Round  26, Train loss: 1.136, Test loss: 0.944, Test accuracy: 96.42
Round  26, Global train loss: 1.136, Global test loss: 0.937, Global test accuracy: 97.02
Round  27, Train loss: 1.092, Test loss: 0.945, Test accuracy: 96.24
Round  27, Global train loss: 1.092, Global test loss: 0.937, Global test accuracy: 97.08
Round  28, Train loss: 1.250, Test loss: 0.945, Test accuracy: 96.12
Round  28, Global train loss: 1.250, Global test loss: 0.940, Global test accuracy: 96.56
Round  29, Train loss: 1.153, Test loss: 0.945, Test accuracy: 96.24
Round  29, Global train loss: 1.153, Global test loss: 0.940, Global test accuracy: 96.70
Round  30, Train loss: 1.142, Test loss: 0.945, Test accuracy: 96.18
Round  30, Global train loss: 1.142, Global test loss: 0.938, Global test accuracy: 96.90
Round  31, Train loss: 1.134, Test loss: 0.945, Test accuracy: 96.20
Round  31, Global train loss: 1.134, Global test loss: 0.938, Global test accuracy: 96.98
Round  32, Train loss: 1.154, Test loss: 0.944, Test accuracy: 96.24
Round  32, Global train loss: 1.154, Global test loss: 0.938, Global test accuracy: 96.92
Round  33, Train loss: 1.231, Test loss: 0.944, Test accuracy: 96.22
Round  33, Global train loss: 1.231, Global test loss: 0.937, Global test accuracy: 96.98
Round  34, Train loss: 1.075, Test loss: 0.945, Test accuracy: 96.16
Round  34, Global train loss: 1.075, Global test loss: 0.938, Global test accuracy: 96.68
Round  35, Train loss: 1.131, Test loss: 0.944, Test accuracy: 96.26
Round  35, Global train loss: 1.131, Global test loss: 0.939, Global test accuracy: 96.54
Round  36, Train loss: 1.232, Test loss: 0.944, Test accuracy: 96.20
Round  36, Global train loss: 1.232, Global test loss: 0.938, Global test accuracy: 96.80
Round  37, Train loss: 0.935, Test loss: 0.944, Test accuracy: 96.24
Round  37, Global train loss: 0.935, Global test loss: 0.938, Global test accuracy: 96.76
Round  38, Train loss: 0.934, Test loss: 0.944, Test accuracy: 96.18
Round  38, Global train loss: 0.934, Global test loss: 0.938, Global test accuracy: 96.86
Round  39, Train loss: 1.080, Test loss: 0.943, Test accuracy: 96.36
Round  39, Global train loss: 1.080, Global test loss: 0.938, Global test accuracy: 96.80
Round  40, Train loss: 1.125, Test loss: 0.943, Test accuracy: 96.22
Round  40, Global train loss: 1.125, Global test loss: 0.939, Global test accuracy: 96.58
Round  41, Train loss: 1.143, Test loss: 0.944, Test accuracy: 96.20
Round  41, Global train loss: 1.143, Global test loss: 0.937, Global test accuracy: 97.08
Round  42, Train loss: 1.142, Test loss: 0.944, Test accuracy: 96.18
Round  42, Global train loss: 1.142, Global test loss: 0.937, Global test accuracy: 96.92
Round  43, Train loss: 1.141, Test loss: 0.944, Test accuracy: 96.22
Round  43, Global train loss: 1.141, Global test loss: 0.938, Global test accuracy: 96.90
Round  44, Train loss: 1.134, Test loss: 0.944, Test accuracy: 96.28
Round  44, Global train loss: 1.134, Global test loss: 0.938, Global test accuracy: 96.88
Round  45, Train loss: 1.084, Test loss: 0.944, Test accuracy: 96.26
Round  45, Global train loss: 1.084, Global test loss: 0.938, Global test accuracy: 96.70
Round  46, Train loss: 1.069, Test loss: 0.944, Test accuracy: 96.26
Round  46, Global train loss: 1.069, Global test loss: 0.940, Global test accuracy: 96.50
Round  47, Train loss: 1.068, Test loss: 0.944, Test accuracy: 96.26
Round  47, Global train loss: 1.068, Global test loss: 0.940, Global test accuracy: 96.38
Round  48, Train loss: 1.128, Test loss: 0.944, Test accuracy: 96.18
Round  48, Global train loss: 1.128, Global test loss: 0.939, Global test accuracy: 96.64
Round  49, Train loss: 1.238, Test loss: 0.943, Test accuracy: 96.44
Round  49, Global train loss: 1.238, Global test loss: 0.939, Global test accuracy: 96.70
Round  50, Train loss: 1.066, Test loss: 0.944, Test accuracy: 96.30
Round  50, Global train loss: 1.066, Global test loss: 0.939, Global test accuracy: 96.54
Round  51, Train loss: 1.124, Test loss: 0.946, Test accuracy: 96.14
Round  51, Global train loss: 1.124, Global test loss: 0.938, Global test accuracy: 96.74
Round  52, Train loss: 1.078, Test loss: 0.945, Test accuracy: 96.14
Round  52, Global train loss: 1.078, Global test loss: 0.939, Global test accuracy: 96.60
Round  53, Train loss: 1.175, Test loss: 0.945, Test accuracy: 96.12
Round  53, Global train loss: 1.175, Global test loss: 0.938, Global test accuracy: 96.76
Round  54, Train loss: 1.126, Test loss: 0.945, Test accuracy: 96.02
Round  54, Global train loss: 1.126, Global test loss: 0.939, Global test accuracy: 96.64
Round  55, Train loss: 1.086, Test loss: 0.945, Test accuracy: 96.06
Round  55, Global train loss: 1.086, Global test loss: 0.938, Global test accuracy: 96.76
Round  56, Train loss: 0.931, Test loss: 0.944, Test accuracy: 96.04
Round  56, Global train loss: 0.931, Global test loss: 0.938, Global test accuracy: 97.04
Round  57, Train loss: 1.229, Test loss: 0.944, Test accuracy: 96.14
Round  57, Global train loss: 1.229, Global test loss: 0.940, Global test accuracy: 96.44
Round  58, Train loss: 1.068, Test loss: 0.945, Test accuracy: 96.06
Round  58, Global train loss: 1.068, Global test loss: 0.940, Global test accuracy: 96.42
Round  59, Train loss: 1.119, Test loss: 0.945, Test accuracy: 96.06
Round  59, Global train loss: 1.119, Global test loss: 0.939, Global test accuracy: 96.54
Round  60, Train loss: 1.140, Test loss: 0.945, Test accuracy: 96.04
Round  60, Global train loss: 1.140, Global test loss: 0.939, Global test accuracy: 96.66
Round  61, Train loss: 1.171, Test loss: 0.944, Test accuracy: 96.08
Round  61, Global train loss: 1.171, Global test loss: 0.940, Global test accuracy: 96.62
Round  62, Train loss: 1.076, Test loss: 0.944, Test accuracy: 96.18
Round  62, Global train loss: 1.076, Global test loss: 0.939, Global test accuracy: 96.60
Round  63, Train loss: 1.129, Test loss: 0.945, Test accuracy: 96.12
Round  63, Global train loss: 1.129, Global test loss: 0.939, Global test accuracy: 96.76
Round  64, Train loss: 1.119, Test loss: 0.944, Test accuracy: 96.08
Round  64, Global train loss: 1.119, Global test loss: 0.939, Global test accuracy: 96.76
Round  65, Train loss: 1.080, Test loss: 0.945, Test accuracy: 96.00
Round  65, Global train loss: 1.080, Global test loss: 0.939, Global test accuracy: 96.52
Round  66, Train loss: 1.043, Test loss: 0.945, Test accuracy: 96.00
Round  66, Global train loss: 1.043, Global test loss: 0.939, Global test accuracy: 96.66
Round  67, Train loss: 1.072, Test loss: 0.945, Test accuracy: 96.04
Round  67, Global train loss: 1.072, Global test loss: 0.938, Global test accuracy: 96.82
Round  68, Train loss: 1.240, Test loss: 0.945, Test accuracy: 96.02
Round  68, Global train loss: 1.240, Global test loss: 0.940, Global test accuracy: 96.56
Round  69, Train loss: 1.127, Test loss: 0.945, Test accuracy: 95.94
Round  69, Global train loss: 1.127, Global test loss: 0.940, Global test accuracy: 96.54
Round  70, Train loss: 1.079, Test loss: 0.945, Test accuracy: 95.98
Round  70, Global train loss: 1.079, Global test loss: 0.940, Global test accuracy: 96.42
Round  71, Train loss: 1.063, Test loss: 0.945, Test accuracy: 95.98
Round  71, Global train loss: 1.063, Global test loss: 0.939, Global test accuracy: 96.60
Round  72, Train loss: 1.122, Test loss: 0.945, Test accuracy: 95.98
Round  72, Global train loss: 1.122, Global test loss: 0.940, Global test accuracy: 96.46
Round  73, Train loss: 1.123, Test loss: 0.945, Test accuracy: 95.98
Round  73, Global train loss: 1.123, Global test loss: 0.938, Global test accuracy: 96.84
Round  74, Train loss: 1.179, Test loss: 0.945, Test accuracy: 95.98
Round  74, Global train loss: 1.179, Global test loss: 0.940, Global test accuracy: 96.50
Round  75, Train loss: 1.134, Test loss: 0.945, Test accuracy: 96.02
Round  75, Global train loss: 1.134, Global test loss: 0.940, Global test accuracy: 96.56
Round  76, Train loss: 1.174, Test loss: 0.945, Test accuracy: 96.04
Round  76, Global train loss: 1.174, Global test loss: 0.941, Global test accuracy: 96.36
Round  77, Train loss: 1.128, Test loss: 0.945, Test accuracy: 96.04
Round  77, Global train loss: 1.128, Global test loss: 0.941, Global test accuracy: 96.46
Round  78, Train loss: 1.029, Test loss: 0.945, Test accuracy: 95.98
Round  78, Global train loss: 1.029, Global test loss: 0.940, Global test accuracy: 96.66
Round  79, Train loss: 1.179, Test loss: 0.945, Test accuracy: 95.98
Round  79, Global train loss: 1.179, Global test loss: 0.940, Global test accuracy: 96.30
Round  80, Train loss: 1.030, Test loss: 0.945, Test accuracy: 96.04
Round  80, Global train loss: 1.030, Global test loss: 0.939, Global test accuracy: 96.72
Round  81, Train loss: 1.239, Test loss: 0.945, Test accuracy: 96.00
Round  81, Global train loss: 1.239, Global test loss: 0.940, Global test accuracy: 96.56
Round  82, Train loss: 1.038, Test loss: 0.945, Test accuracy: 96.00
Round  82, Global train loss: 1.038, Global test loss: 0.939, Global test accuracy: 96.78
Round  83, Train loss: 1.133, Test loss: 0.945, Test accuracy: 96.06
Round  83, Global train loss: 1.133, Global test loss: 0.940, Global test accuracy: 96.66
Round  84, Train loss: 1.146, Test loss: 0.945, Test accuracy: 96.08
Round  84, Global train loss: 1.146, Global test loss: 0.941, Global test accuracy: 96.44
Round  85, Train loss: 1.121, Test loss: 0.945, Test accuracy: 96.10
Round  85, Global train loss: 1.121, Global test loss: 0.941, Global test accuracy: 96.32
Round  86, Train loss: 1.225, Test loss: 0.945, Test accuracy: 96.02
Round  86, Global train loss: 1.225, Global test loss: 0.939, Global test accuracy: 96.70
Round  87, Train loss: 0.978, Test loss: 0.945, Test accuracy: 95.98
Round  87, Global train loss: 0.978, Global test loss: 0.939, Global test accuracy: 96.68
Round  88, Train loss: 1.151, Test loss: 0.946, Test accuracy: 95.96
Round  88, Global train loss: 1.151, Global test loss: 0.939, Global test accuracy: 96.80
Round  89, Train loss: 1.146, Test loss: 0.946, Test accuracy: 95.98
Round  89, Global train loss: 1.146, Global test loss: 0.941, Global test accuracy: 96.38
Round  90, Train loss: 1.135, Test loss: 0.945, Test accuracy: 96.00
Round  90, Global train loss: 1.135, Global test loss: 0.939, Global test accuracy: 96.82
Round  91, Train loss: 1.114, Test loss: 0.945, Test accuracy: 96.12
Round  91, Global train loss: 1.114, Global test loss: 0.939, Global test accuracy: 96.72
Round  92, Train loss: 1.066, Test loss: 0.945, Test accuracy: 96.08
Round  92, Global train loss: 1.066, Global test loss: 0.939, Global test accuracy: 96.80
Round  93, Train loss: 1.239, Test loss: 0.944, Test accuracy: 96.08
Round  93, Global train loss: 1.239, Global test loss: 0.940, Global test accuracy: 96.40
Round  94, Train loss: 1.075, Test loss: 0.945, Test accuracy: 96.02
Round  94, Global train loss: 1.075, Global test loss: 0.939, Global test accuracy: 96.70/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  95, Train loss: 1.223, Test loss: 0.945, Test accuracy: 95.94
Round  95, Global train loss: 1.223, Global test loss: 0.940, Global test accuracy: 96.72
Round  96, Train loss: 1.123, Test loss: 0.945, Test accuracy: 95.96
Round  96, Global train loss: 1.123, Global test loss: 0.940, Global test accuracy: 96.68
Round  97, Train loss: 1.144, Test loss: 0.944, Test accuracy: 96.00
Round  97, Global train loss: 1.144, Global test loss: 0.941, Global test accuracy: 96.44
Round  98, Train loss: 1.122, Test loss: 0.945, Test accuracy: 95.90
Round  98, Global train loss: 1.122, Global test loss: 0.939, Global test accuracy: 96.88
Round  99, Train loss: 1.222, Test loss: 0.945, Test accuracy: 95.94
Round  99, Global train loss: 1.222, Global test loss: 0.940, Global test accuracy: 96.70
Final Round, Train loss: 1.120, Test loss: 0.944, Test accuracy: 96.10
Final Round, Global train loss: 1.120, Global test loss: 0.940, Global test accuracy: 96.70
Average accuracy final 10 rounds: 96.00399999999999 

Average global accuracy final 10 rounds: 96.68600000000002 

629.0900664329529
[0.9945127964019775, 1.989025592803955, 2.8583545684814453, 3.7276835441589355, 4.622464179992676, 5.517244815826416, 6.510400772094727, 7.503556728363037, 8.366206884384155, 9.228857040405273, 10.073258638381958, 10.917660236358643, 11.770941019058228, 12.624221801757812, 13.50926661491394, 14.394311428070068, 15.25078535079956, 16.107259273529053, 16.99161720275879, 17.875975131988525, 18.728300094604492, 19.58062505722046, 20.43796420097351, 21.295303344726562, 22.144001960754395, 22.992700576782227, 23.81870675086975, 24.644712924957275, 25.486915588378906, 26.329118251800537, 27.19357204437256, 28.05802583694458, 29.074235677719116, 30.090445518493652, 30.967422246932983, 31.844398975372314, 32.73285746574402, 33.62131595611572, 34.48013186454773, 35.338947772979736, 36.228835344314575, 37.118722915649414, 37.980571269989014, 38.84241962432861, 39.69943690299988, 40.55645418167114, 41.42450261116028, 42.292551040649414, 43.15337038040161, 44.01418972015381, 44.87049651145935, 45.72680330276489, 46.595845222473145, 47.4648871421814, 48.33757996559143, 49.210272789001465, 50.06476855278015, 50.91926431655884, 51.79407858848572, 52.6688928604126, 53.77538824081421, 54.88188362121582, 55.78157901763916, 56.6812744140625, 57.5689971446991, 58.45671987533569, 59.32070779800415, 60.18469572067261, 61.043649196624756, 61.902602672576904, 62.76876902580261, 63.63493537902832, 64.4918920993805, 65.34884881973267, 66.20101141929626, 67.05317401885986, 67.90589356422424, 68.75861310958862, 69.61991548538208, 70.48121786117554, 71.3495020866394, 72.21778631210327, 73.07691812515259, 73.9360499382019, 74.97386479377747, 76.01167964935303, 76.88279223442078, 77.75390481948853, 78.64463114738464, 79.53535747528076, 80.40499830245972, 81.27463912963867, 82.14197397232056, 83.00930881500244, 83.87123465538025, 84.73316049575806, 85.60027980804443, 86.46739912033081, 87.32730340957642, 88.18720769882202, 89.03962397575378, 89.89204025268555, 90.75103497505188, 91.61002969741821, 92.44507956504822, 93.28012943267822, 94.11866283416748, 94.95719623565674, 95.92124032974243, 96.88528442382812, 97.73494791984558, 98.58461141586304, 99.4176254272461, 100.25063943862915, 101.14054155349731, 102.03044366836548, 102.86210680007935, 103.69376993179321, 104.5326144695282, 105.37145900726318, 106.20168900489807, 107.03191900253296, 107.87475728988647, 108.71759557723999, 109.55123853683472, 110.38488149642944, 111.39250445365906, 112.40012741088867, 113.23707270622253, 114.0740180015564, 114.90023589134216, 115.72645378112793, 116.55481052398682, 117.3831672668457, 118.23135900497437, 119.07955074310303, 119.93157362937927, 120.78359651565552, 121.63649725914001, 122.48939800262451, 123.35773015022278, 124.22606229782104, 125.1071195602417, 125.98817682266235, 126.84204912185669, 127.69592142105103, 128.54187202453613, 129.38782262802124, 130.2520797252655, 131.11633682250977, 131.97554850578308, 132.8347601890564, 133.6691665649414, 134.50357294082642, 135.35869908332825, 136.21382522583008, 137.04826140403748, 137.88269758224487, 138.91000819206238, 139.93731880187988, 140.8012237548828, 141.66512870788574, 142.52759337425232, 143.3900580406189, 144.25156807899475, 145.1130781173706, 146.13794374465942, 147.16280937194824, 148.0189700126648, 148.87513065338135, 149.73357701301575, 150.59202337265015, 151.46282291412354, 152.33362245559692, 153.21568608283997, 154.097749710083, 154.95791864395142, 155.81808757781982, 156.6729655265808, 157.5278434753418, 158.39144444465637, 159.25504541397095, 160.13586449623108, 161.0166835784912, 161.91906929016113, 162.82145500183105, 163.6894154548645, 164.55737590789795, 165.42871022224426, 166.30004453659058, 167.17458844184875, 168.04913234710693, 168.90500283241272, 169.7608733177185, 170.6405472755432, 171.52022123336792, 172.38039255142212, 173.24056386947632, 174.09614992141724, 174.95173597335815, 176.66387486457825, 178.37601375579834]
[43.88, 43.88, 60.2, 60.2, 72.6, 72.6, 83.52, 83.52, 89.5, 89.5, 92.94, 92.94, 93.48, 93.48, 93.54, 93.54, 93.78, 93.78, 95.86, 95.86, 96.1, 96.1, 96.1, 96.1, 96.1, 96.1, 95.98, 95.98, 96.2, 96.2, 96.38, 96.38, 96.4, 96.4, 96.42, 96.42, 96.44, 96.44, 96.38, 96.38, 96.34, 96.34, 96.42, 96.42, 96.4, 96.4, 96.38, 96.38, 96.3, 96.3, 96.32, 96.32, 96.42, 96.42, 96.24, 96.24, 96.12, 96.12, 96.24, 96.24, 96.18, 96.18, 96.2, 96.2, 96.24, 96.24, 96.22, 96.22, 96.16, 96.16, 96.26, 96.26, 96.2, 96.2, 96.24, 96.24, 96.18, 96.18, 96.36, 96.36, 96.22, 96.22, 96.2, 96.2, 96.18, 96.18, 96.22, 96.22, 96.28, 96.28, 96.26, 96.26, 96.26, 96.26, 96.26, 96.26, 96.18, 96.18, 96.44, 96.44, 96.3, 96.3, 96.14, 96.14, 96.14, 96.14, 96.12, 96.12, 96.02, 96.02, 96.06, 96.06, 96.04, 96.04, 96.14, 96.14, 96.06, 96.06, 96.06, 96.06, 96.04, 96.04, 96.08, 96.08, 96.18, 96.18, 96.12, 96.12, 96.08, 96.08, 96.0, 96.0, 96.0, 96.0, 96.04, 96.04, 96.02, 96.02, 95.94, 95.94, 95.98, 95.98, 95.98, 95.98, 95.98, 95.98, 95.98, 95.98, 95.98, 95.98, 96.02, 96.02, 96.04, 96.04, 96.04, 96.04, 95.98, 95.98, 95.98, 95.98, 96.04, 96.04, 96.0, 96.0, 96.0, 96.0, 96.06, 96.06, 96.08, 96.08, 96.1, 96.1, 96.02, 96.02, 95.98, 95.98, 95.96, 95.96, 95.98, 95.98, 96.0, 96.0, 96.12, 96.12, 96.08, 96.08, 96.08, 96.08, 96.02, 96.02, 95.94, 95.94, 95.96, 95.96, 96.0, 96.0, 95.9, 95.9, 95.94, 95.94, 96.1, 96.1]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.6 , level_n_lowerb:0.4  

   Client 3, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Traceback (most recent call last):
  File "main_fedpac_co_teaching.py", line 250, in <module>
    local.filter_data(net=net_local.to(args.device), net2=net_local2.to(args.device), concept_matrix_local = concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1587, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

   Client 8, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550021 (local), 549696 (global); Percentage 99.94 (549696/550021)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 1.629, Test loss: 1.598, Test accuracy: 41.30
Round   0, Global train loss: 1.629, Global test loss: 1.598, Global test accuracy: 41.58
Round   1, Train loss: 1.587, Test loss: 1.552, Test accuracy: 64.72
Round   1, Global train loss: 1.587, Global test loss: 1.552, Global test accuracy: 64.86
Round   2, Train loss: 1.501, Test loss: 1.375, Test accuracy: 81.66
Round   2, Global train loss: 1.501, Global test loss: 1.366, Global test accuracy: 81.24
Round   3, Train loss: 1.364, Test loss: 1.189, Test accuracy: 88.58
Round   3, Global train loss: 1.364, Global test loss: 1.169, Global test accuracy: 88.70
Round   4, Train loss: 1.265, Test loss: 1.082, Test accuracy: 92.70
Round   4, Global train loss: 1.265, Global test loss: 1.052, Global test accuracy: 93.98
Round   5, Train loss: 1.257, Test loss: 1.043, Test accuracy: 94.44
Round   5, Global train loss: 1.257, Global test loss: 1.022, Global test accuracy: 95.18
Round   6, Train loss: 1.308, Test loss: 1.026, Test accuracy: 95.22
Round   6, Global train loss: 1.308, Global test loss: 1.027, Global test accuracy: 95.20
Round   7, Train loss: 1.132, Test loss: 1.007, Test accuracy: 95.60
Round   7, Global train loss: 1.132, Global test loss: 0.993, Global test accuracy: 96.00
Round   8, Train loss: 1.183, Test loss: 1.001, Test accuracy: 95.98
Round   8, Global train loss: 1.183, Global test loss: 0.986, Global test accuracy: 96.06
Round   9, Train loss: 1.217, Test loss: 0.992, Test accuracy: 96.32
Round   9, Global train loss: 1.217, Global test loss: 0.997, Global test accuracy: 96.48
Round  10, Train loss: 1.010, Test loss: 0.984, Test accuracy: 96.38
Round  10, Global train loss: 1.010, Global test loss: 0.972, Global test accuracy: 96.38
Round  11, Train loss: 1.189, Test loss: 0.978, Test accuracy: 96.38
Round  11, Global train loss: 1.189, Global test loss: 0.974, Global test accuracy: 96.56
Round  12, Train loss: 1.106, Test loss: 0.977, Test accuracy: 96.36
Round  12, Global train loss: 1.106, Global test loss: 0.971, Global test accuracy: 96.54
Round  13, Train loss: 1.202, Test loss: 0.977, Test accuracy: 96.52
Round  13, Global train loss: 1.202, Global test loss: 0.971, Global test accuracy: 96.84
Round  14, Train loss: 1.168, Test loss: 0.973, Test accuracy: 96.50
Round  14, Global train loss: 1.168, Global test loss: 0.972, Global test accuracy: 96.64
Round  15, Train loss: 1.100, Test loss: 0.973, Test accuracy: 96.64
Round  15, Global train loss: 1.100, Global test loss: 0.963, Global test accuracy: 96.88
Round  16, Train loss: 1.272, Test loss: 0.974, Test accuracy: 96.66
Round  16, Global train loss: 1.272, Global test loss: 0.970, Global test accuracy: 96.90
Round  17, Train loss: 1.189, Test loss: 0.975, Test accuracy: 96.70
Round  17, Global train loss: 1.189, Global test loss: 0.972, Global test accuracy: 96.84
Round  18, Train loss: 1.182, Test loss: 0.971, Test accuracy: 96.60
Round  18, Global train loss: 1.182, Global test loss: 0.973, Global test accuracy: 96.74
Round  19, Train loss: 1.274, Test loss: 0.973, Test accuracy: 96.58
Round  19, Global train loss: 1.274, Global test loss: 0.980, Global test accuracy: 96.46
Round  20, Train loss: 1.271, Test loss: 0.975, Test accuracy: 96.68
Round  20, Global train loss: 1.271, Global test loss: 0.977, Global test accuracy: 96.94
Round  21, Train loss: 1.152, Test loss: 0.971, Test accuracy: 96.64
Round  21, Global train loss: 1.152, Global test loss: 0.968, Global test accuracy: 96.78
Round  22, Train loss: 1.081, Test loss: 0.967, Test accuracy: 96.60
Round  22, Global train loss: 1.081, Global test loss: 0.962, Global test accuracy: 96.94
Round  23, Train loss: 1.260, Test loss: 0.968, Test accuracy: 96.70
Round  23, Global train loss: 1.260, Global test loss: 0.967, Global test accuracy: 96.90
Round  24, Train loss: 1.086, Test loss: 0.967, Test accuracy: 96.56
Round  24, Global train loss: 1.086, Global test loss: 0.960, Global test accuracy: 96.96
Round  25, Train loss: 1.083, Test loss: 0.964, Test accuracy: 96.64
Round  25, Global train loss: 1.083, Global test loss: 0.958, Global test accuracy: 96.96
Round  26, Train loss: 1.164, Test loss: 0.964, Test accuracy: 96.64
Round  26, Global train loss: 1.164, Global test loss: 0.963, Global test accuracy: 96.86
Round  27, Train loss: 1.142, Test loss: 0.963, Test accuracy: 96.76
Round  27, Global train loss: 1.142, Global test loss: 0.962, Global test accuracy: 96.84
Round  28, Train loss: 0.979, Test loss: 0.959, Test accuracy: 96.78
Round  28, Global train loss: 0.979, Global test loss: 0.949, Global test accuracy: 97.04
Round  29, Train loss: 1.167, Test loss: 0.963, Test accuracy: 96.48
Round  29, Global train loss: 1.167, Global test loss: 0.963, Global test accuracy: 96.56
Round  30, Train loss: 1.069, Test loss: 0.961, Test accuracy: 96.82
Round  30, Global train loss: 1.069, Global test loss: 0.952, Global test accuracy: 96.98
Round  31, Train loss: 1.046, Test loss: 0.958, Test accuracy: 96.80
Round  31, Global train loss: 1.046, Global test loss: 0.951, Global test accuracy: 97.10
Round  32, Train loss: 1.154, Test loss: 0.959, Test accuracy: 96.78
Round  32, Global train loss: 1.154, Global test loss: 0.955, Global test accuracy: 97.04
Round  33, Train loss: 1.142, Test loss: 0.962, Test accuracy: 96.66
Round  33, Global train loss: 1.142, Global test loss: 0.961, Global test accuracy: 96.86
Round  34, Train loss: 1.149, Test loss: 0.960, Test accuracy: 96.92
Round  34, Global train loss: 1.149, Global test loss: 0.953, Global test accuracy: 97.20
Round  35, Train loss: 1.062, Test loss: 0.959, Test accuracy: 96.94
Round  35, Global train loss: 1.062, Global test loss: 0.949, Global test accuracy: 97.24
Round  36, Train loss: 1.141, Test loss: 0.959, Test accuracy: 96.80
Round  36, Global train loss: 1.141, Global test loss: 0.957, Global test accuracy: 97.10
Round  37, Train loss: 1.251, Test loss: 0.963, Test accuracy: 96.68
Round  37, Global train loss: 1.251, Global test loss: 0.964, Global test accuracy: 96.90
Round  38, Train loss: 1.245, Test loss: 0.967, Test accuracy: 96.68
Round  38, Global train loss: 1.245, Global test loss: 0.967, Global test accuracy: 96.62
Round  39, Train loss: 1.165, Test loss: 0.966, Test accuracy: 96.64
Round  39, Global train loss: 1.165, Global test loss: 0.960, Global test accuracy: 96.92
Round  40, Train loss: 1.157, Test loss: 0.963, Test accuracy: 96.82
Round  40, Global train loss: 1.157, Global test loss: 0.955, Global test accuracy: 97.14
Round  41, Train loss: 1.124, Test loss: 0.962, Test accuracy: 96.70
Round  41, Global train loss: 1.124, Global test loss: 0.961, Global test accuracy: 96.66
Round  42, Train loss: 1.129, Test loss: 0.965, Test accuracy: 96.58
Round  42, Global train loss: 1.129, Global test loss: 0.966, Global test accuracy: 96.18
Round  43, Train loss: 1.122, Test loss: 0.968, Test accuracy: 96.36
Round  43, Global train loss: 1.122, Global test loss: 0.968, Global test accuracy: 96.18
Round  44, Train loss: 1.061, Test loss: 0.959, Test accuracy: 96.76
Round  44, Global train loss: 1.061, Global test loss: 0.951, Global test accuracy: 97.00
Round  45, Train loss: 1.164, Test loss: 0.960, Test accuracy: 96.58
Round  45, Global train loss: 1.164, Global test loss: 0.958, Global test accuracy: 96.64
Round  46, Train loss: 1.156, Test loss: 0.961, Test accuracy: 96.70
Round  46, Global train loss: 1.156, Global test loss: 0.954, Global test accuracy: 97.14
Round  47, Train loss: 1.152, Test loss: 0.962, Test accuracy: 96.82
Round  47, Global train loss: 1.152, Global test loss: 0.954, Global test accuracy: 97.18
Round  48, Train loss: 1.152, Test loss: 0.962, Test accuracy: 96.56
Round  48, Global train loss: 1.152, Global test loss: 0.956, Global test accuracy: 96.80
Round  49, Train loss: 0.944, Test loss: 0.956, Test accuracy: 96.68
Round  49, Global train loss: 0.944, Global test loss: 0.946, Global test accuracy: 96.84
Round  50, Train loss: 1.242, Test loss: 0.964, Test accuracy: 96.40
Round  50, Global train loss: 1.242, Global test loss: 0.964, Global test accuracy: 96.60
Round  51, Train loss: 1.234, Test loss: 0.971, Test accuracy: 96.12
Round  51, Global train loss: 1.234, Global test loss: 0.972, Global test accuracy: 96.32
Round  52, Train loss: 1.155, Test loss: 0.967, Test accuracy: 96.20
Round  52, Global train loss: 1.155, Global test loss: 0.961, Global test accuracy: 96.70
Round  53, Train loss: 1.124, Test loss: 0.964, Test accuracy: 96.38
Round  53, Global train loss: 1.124, Global test loss: 0.958, Global test accuracy: 96.76
Round  54, Train loss: 1.149, Test loss: 0.968, Test accuracy: 96.00
Round  54, Global train loss: 1.149, Global test loss: 0.966, Global test accuracy: 96.18
Round  55, Train loss: 1.113, Test loss: 0.967, Test accuracy: 96.00
Round  55, Global train loss: 1.113, Global test loss: 0.967, Global test accuracy: 95.96
Round  56, Train loss: 1.223, Test loss: 0.973, Test accuracy: 95.66
Round  56, Global train loss: 1.223, Global test loss: 0.971, Global test accuracy: 95.96
Round  57, Train loss: 1.039, Test loss: 0.969, Test accuracy: 95.68
Round  57, Global train loss: 1.039, Global test loss: 0.965, Global test accuracy: 95.84
Round  58, Train loss: 1.128, Test loss: 0.965, Test accuracy: 96.10
Round  58, Global train loss: 1.128, Global test loss: 0.957, Global test accuracy: 96.72
Round  59, Train loss: 1.220, Test loss: 0.972, Test accuracy: 95.70
Round  59, Global train loss: 1.220, Global test loss: 0.970, Global test accuracy: 96.04
Round  60, Train loss: 1.104, Test loss: 0.972, Test accuracy: 95.54
Round  60, Global train loss: 1.104, Global test loss: 0.975, Global test accuracy: 95.16
Round  61, Train loss: 1.114, Test loss: 0.971, Test accuracy: 95.70
Round  61, Global train loss: 1.114, Global test loss: 0.969, Global test accuracy: 95.54
Round  62, Train loss: 1.145, Test loss: 0.970, Test accuracy: 95.76
Round  62, Global train loss: 1.145, Global test loss: 0.965, Global test accuracy: 96.18
Round  63, Train loss: 1.045, Test loss: 0.966, Test accuracy: 95.82
Round  63, Global train loss: 1.045, Global test loss: 0.957, Global test accuracy: 96.60
Round  64, Train loss: 1.214, Test loss: 0.975, Test accuracy: 95.38
Round  64, Global train loss: 1.214, Global test loss: 0.971, Global test accuracy: 95.90
Round  65, Train loss: 1.144, Test loss: 0.977, Test accuracy: 95.06
Round  65, Global train loss: 1.144, Global test loss: 0.975, Global test accuracy: 95.46
Round  66, Train loss: 1.125, Test loss: 0.978, Test accuracy: 94.88
Round  66, Global train loss: 1.125, Global test loss: 0.972, Global test accuracy: 95.36
Round  67, Train loss: 1.119, Test loss: 0.976, Test accuracy: 94.98
Round  67, Global train loss: 1.119, Global test loss: 0.968, Global test accuracy: 95.74
Round  68, Train loss: 0.955, Test loss: 0.964, Test accuracy: 95.76
Round  68, Global train loss: 0.955, Global test loss: 0.953, Global test accuracy: 96.32
Round  69, Train loss: 1.035, Test loss: 0.963, Test accuracy: 95.62
Round  69, Global train loss: 1.035, Global test loss: 0.953, Global test accuracy: 96.64
Round  70, Train loss: 1.189, Test loss: 0.981, Test accuracy: 94.58
Round  70, Global train loss: 1.189, Global test loss: 0.992, Global test accuracy: 94.06
Round  71, Train loss: 1.210, Test loss: 0.982, Test accuracy: 94.80
Round  71, Global train loss: 1.210, Global test loss: 0.974, Global test accuracy: 95.58
Round  72, Train loss: 1.125, Test loss: 0.980, Test accuracy: 94.82
Round  72, Global train loss: 1.125, Global test loss: 0.975, Global test accuracy: 95.26
Round  73, Train loss: 1.119, Test loss: 0.971, Test accuracy: 95.26
Round  73, Global train loss: 1.119, Global test loss: 0.962, Global test accuracy: 96.00
Round  74, Train loss: 1.119, Test loss: 0.980, Test accuracy: 94.72
Round  74, Global train loss: 1.119, Global test loss: 0.974, Global test accuracy: 95.26
Round  75, Train loss: 1.037, Test loss: 0.974, Test accuracy: 95.10
Round  75, Global train loss: 1.037, Global test loss: 0.963, Global test accuracy: 95.72
Round  76, Train loss: 1.023, Test loss: 0.966, Test accuracy: 95.58
Round  76, Global train loss: 1.023, Global test loss: 0.954, Global test accuracy: 96.26
Round  77, Train loss: 1.032, Test loss: 0.964, Test accuracy: 95.74
Round  77, Global train loss: 1.032, Global test loss: 0.954, Global test accuracy: 96.28
Round  78, Train loss: 1.189, Test loss: 0.987, Test accuracy: 94.18
Round  78, Global train loss: 1.189, Global test loss: 0.991, Global test accuracy: 94.08
Round  79, Train loss: 1.120, Test loss: 0.981, Test accuracy: 94.74
Round  79, Global train loss: 1.120, Global test loss: 0.975, Global test accuracy: 95.30
Round  80, Train loss: 1.130, Test loss: 0.982, Test accuracy: 94.56
Round  80, Global train loss: 1.130, Global test loss: 0.972, Global test accuracy: 95.54
Round  81, Train loss: 1.023, Test loss: 0.976, Test accuracy: 94.92
Round  81, Global train loss: 1.023, Global test loss: 0.967, Global test accuracy: 95.58
Round  82, Train loss: 1.094, Test loss: 0.971, Test accuracy: 95.38
Round  82, Global train loss: 1.094, Global test loss: 0.967, Global test accuracy: 95.34
Round  83, Train loss: 1.114, Test loss: 0.981, Test accuracy: 94.46
Round  83, Global train loss: 1.114, Global test loss: 0.972, Global test accuracy: 95.38
Round  84, Train loss: 1.021, Test loss: 0.972, Test accuracy: 95.22
Round  84, Global train loss: 1.021, Global test loss: 0.963, Global test accuracy: 95.74
Round  85, Train loss: 1.108, Test loss: 0.983, Test accuracy: 94.52
Round  85, Global train loss: 1.108, Global test loss: 0.973, Global test accuracy: 95.40
Round  86, Train loss: 1.097, Test loss: 0.975, Test accuracy: 94.94
Round  86, Global train loss: 1.097, Global test loss: 0.968, Global test accuracy: 95.60
Round  87, Train loss: 1.169, Test loss: 0.994, Test accuracy: 93.56
Round  87, Global train loss: 1.169, Global test loss: 0.988, Global test accuracy: 94.76
Round  88, Train loss: 1.005, Test loss: 0.977, Test accuracy: 94.92
Round  88, Global train loss: 1.005, Global test loss: 0.968, Global test accuracy: 95.52
Round  89, Train loss: 1.011, Test loss: 0.973, Test accuracy: 95.04
Round  89, Global train loss: 1.011, Global test loss: 0.964, Global test accuracy: 95.46
Round  90, Train loss: 1.077, Test loss: 0.973, Test accuracy: 94.78
Round  90, Global train loss: 1.077, Global test loss: 0.969, Global test accuracy: 95.28
Round  91, Train loss: 1.189, Test loss: 0.995, Test accuracy: 93.40
Round  91, Global train loss: 1.189, Global test loss: 0.989, Global test accuracy: 94.02/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  92, Train loss: 1.173, Test loss: 1.011, Test accuracy: 92.64
Round  92, Global train loss: 1.173, Global test loss: 1.000, Global test accuracy: 93.64
Round  93, Train loss: 0.947, Test loss: 0.973, Test accuracy: 95.14
Round  93, Global train loss: 0.947, Global test loss: 0.958, Global test accuracy: 95.90
Round  94, Train loss: 1.156, Test loss: 0.989, Test accuracy: 94.00
Round  94, Global train loss: 1.156, Global test loss: 0.990, Global test accuracy: 94.06
Round  95, Train loss: 1.018, Test loss: 0.968, Test accuracy: 95.40
Round  95, Global train loss: 1.018, Global test loss: 0.957, Global test accuracy: 96.26
Round  96, Train loss: 1.024, Test loss: 0.966, Test accuracy: 95.42
Round  96, Global train loss: 1.024, Global test loss: 0.957, Global test accuracy: 96.26
Round  97, Train loss: 1.077, Test loss: 0.991, Test accuracy: 93.84
Round  97, Global train loss: 1.077, Global test loss: 0.991, Global test accuracy: 93.84
Round  98, Train loss: 1.095, Test loss: 0.984, Test accuracy: 94.18
Round  98, Global train loss: 1.095, Global test loss: 0.968, Global test accuracy: 95.54
Round  99, Train loss: 1.009, Test loss: 0.975, Test accuracy: 94.98
Round  99, Global train loss: 1.009, Global test loss: 0.958, Global test accuracy: 96.12
Final Round, Train loss: 1.067, Test loss: 0.976, Test accuracy: 94.70
Final Round, Global train loss: 1.067, Global test loss: 0.958, Global test accuracy: 96.12
Average accuracy final 10 rounds: 94.378
518.0050458908081
[1.1168594360351562, 2.01530122756958, 2.9246082305908203, 3.827157735824585, 4.876324653625488, 5.762464284896851, 6.65219521522522, 7.5617170333862305, 8.483155488967896, 9.427024602890015, 10.34372329711914, 11.267365455627441, 12.162700653076172, 13.064531326293945, 13.972418308258057, 14.915499448776245, 15.832701206207275, 16.744327783584595, 17.661779642105103, 18.582438230514526, 19.48387598991394, 20.393664360046387, 21.305251121520996, 22.2284038066864, 23.126830101013184, 24.025144815444946, 24.965404272079468, 25.872103691101074, 26.7582049369812, 27.618123292922974, 28.52668571472168, 29.405787467956543, 30.31471300125122, 31.22807502746582, 32.12849402427673, 33.02361726760864, 33.95859146118164, 34.90485882759094, 35.79094338417053, 36.70018744468689, 37.5879647731781, 38.49093151092529, 39.433231353759766, 40.36100935935974, 41.29261326789856, 42.191940784454346, 43.088462829589844, 43.98748540878296, 44.94308352470398, 45.88572716712952, 46.81626558303833, 47.73387408256531, 48.639554500579834, 49.547122955322266, 50.47575759887695, 51.39120888710022, 52.32061004638672, 53.252840518951416, 54.17888426780701, 55.08893918991089, 56.007086992263794, 56.906155824661255, 57.800374031066895, 58.691259145736694, 59.60278582572937, 60.502472162246704, 61.42133975028992, 62.343283891677856, 63.25814700126648, 64.15792298316956, 65.06997919082642, 65.97590613365173, 66.88465523719788, 67.77560758590698, 68.66092467308044, 69.56032061576843, 70.47731685638428, 71.45073056221008, 72.38354444503784, 73.31330132484436, 74.22454738616943, 75.14914870262146, 76.06714224815369, 76.99120783805847, 77.88700127601624, 78.8089337348938, 79.69478368759155, 80.56692123413086, 81.46560001373291, 82.37136578559875, 83.28503155708313, 84.26109290122986, 85.22611117362976, 86.17807793617249, 87.08509302139282, 87.97566294670105, 88.91155815124512, 89.81378722190857, 90.72068929672241, 91.61453819274902, 93.09704422950745]
[41.3, 64.72, 81.66, 88.58, 92.7, 94.44, 95.22, 95.6, 95.98, 96.32, 96.38, 96.38, 96.36, 96.52, 96.5, 96.64, 96.66, 96.7, 96.6, 96.58, 96.68, 96.64, 96.6, 96.7, 96.56, 96.64, 96.64, 96.76, 96.78, 96.48, 96.82, 96.8, 96.78, 96.66, 96.92, 96.94, 96.8, 96.68, 96.68, 96.64, 96.82, 96.7, 96.58, 96.36, 96.76, 96.58, 96.7, 96.82, 96.56, 96.68, 96.4, 96.12, 96.2, 96.38, 96.0, 96.0, 95.66, 95.68, 96.1, 95.7, 95.54, 95.7, 95.76, 95.82, 95.38, 95.06, 94.88, 94.98, 95.76, 95.62, 94.58, 94.8, 94.82, 95.26, 94.72, 95.1, 95.58, 95.74, 94.18, 94.74, 94.56, 94.92, 95.38, 94.46, 95.22, 94.52, 94.94, 93.56, 94.92, 95.04, 94.78, 93.4, 92.64, 95.14, 94.0, 95.4, 95.42, 93.84, 94.18, 94.98, 94.7]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fedpac_copsl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist,  filter_alg: loss_psl, level_n_system: 0.6 , level_n_lowerb:0.4  

   Client 9, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550021 (local), 549696 (global); Percentage 99.94 (549696/550021)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 1.625, Test loss: 1.593, Test accuracy: 32.94
Round   0, Global train loss: 1.625, Global test loss: 1.593, Global test accuracy: 34.50
Round   1, Train loss: 1.585, Test loss: 1.542, Test accuracy: 41.92
Round   1, Global train loss: 1.585, Global test loss: 1.542, Global test accuracy: 41.42
Round   2, Train loss: 1.526, Test loss: 1.430, Test accuracy: 51.80
Round   2, Global train loss: 1.526, Global test loss: 1.428, Global test accuracy: 52.56
Round   3, Train loss: 1.440, Test loss: 1.299, Test accuracy: 81.10
Round   3, Global train loss: 1.440, Global test loss: 1.294, Global test accuracy: 82.12
Round   4, Train loss: 1.339, Test loss: 1.129, Test accuracy: 92.56
Round   4, Global train loss: 1.339, Global test loss: 1.122, Global test accuracy: 93.14
Round   5, Train loss: 1.245, Test loss: 1.033, Test accuracy: 95.06
Round   5, Global train loss: 1.245, Global test loss: 1.029, Global test accuracy: 95.60
Round   6, Train loss: 1.210, Test loss: 1.004, Test accuracy: 95.68
Round   6, Global train loss: 1.210, Global test loss: 1.000, Global test accuracy: 95.84
Round   7, Train loss: 1.196, Test loss: 0.991, Test accuracy: 96.22
Round   7, Global train loss: 1.196, Global test loss: 0.987, Global test accuracy: 96.44
Round   8, Train loss: 1.188, Test loss: 0.983, Test accuracy: 96.50
Round   8, Global train loss: 1.188, Global test loss: 0.980, Global test accuracy: 96.50
Round   9, Train loss: 1.183, Test loss: 0.978, Test accuracy: 96.52
Round   9, Global train loss: 1.183, Global test loss: 0.975, Global test accuracy: 96.62
Round  10, Train loss: 1.204, Test loss: 0.983, Test accuracy: 96.46
Round  10, Global train loss: 1.204, Global test loss: 0.981, Global test accuracy: 96.64
Traceback (most recent call last):
  File "main_fedpac_copsl.py", line 280, in <module>
    w_local, loss, indd, class_center_local, class_num, noisy_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys,
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2559, in train
    self.filter_data(net, local_net, iter2-head_eps+1, local_eps-head_eps+1, concept_matrix_local)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2396, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist, level_n_system: 0.6 , level_n_lowerb:0.8  

   Client 8, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.603, Test loss: 1.594, Test accuracy: 56.96
Round   0, Global train loss: 1.603, Global test loss: 1.595, Global test accuracy: 63.94
Round   1, Train loss: 1.605, Test loss: 1.587, Test accuracy: 59.72
Round   1, Global train loss: 1.605, Global test loss: 1.589, Global test accuracy: 73.84
Round   2, Train loss: 1.503, Test loss: 1.465, Test accuracy: 63.86
Round   2, Global train loss: 1.503, Global test loss: 1.426, Global test accuracy: 79.90
Round   3, Train loss: 1.303, Test loss: 1.334, Test accuracy: 64.90
Round   3, Global train loss: 1.303, Global test loss: 1.164, Global test accuracy: 91.22
Round   4, Train loss: 1.383, Test loss: 1.366, Test accuracy: 64.42
Round   4, Global train loss: 1.383, Global test loss: 1.370, Global test accuracy: 87.74
Round   5, Train loss: 1.373, Test loss: 1.346, Test accuracy: 66.94
Round   5, Global train loss: 1.373, Global test loss: 1.308, Global test accuracy: 93.00
Round   6, Train loss: 1.390, Test loss: 1.297, Test accuracy: 68.28
Round   6, Global train loss: 1.390, Global test loss: 1.202, Global test accuracy: 94.66
Round   7, Train loss: 1.147, Test loss: 1.285, Test accuracy: 69.48
Round   7, Global train loss: 1.147, Global test loss: 1.013, Global test accuracy: 93.50
Round   8, Train loss: 1.368, Test loss: 1.277, Test accuracy: 69.16
Round   8, Global train loss: 1.368, Global test loss: 1.320, Global test accuracy: 84.96
Round   9, Train loss: 1.389, Test loss: 1.261, Test accuracy: 69.92
Round   9, Global train loss: 1.389, Global test loss: 1.293, Global test accuracy: 84.02
Round  10, Train loss: 1.157, Test loss: 1.246, Test accuracy: 70.62
Round  10, Global train loss: 1.157, Global test loss: 1.055, Global test accuracy: 91.28
Round  11, Train loss: 1.343, Test loss: 1.234, Test accuracy: 73.04
Round  11, Global train loss: 1.343, Global test loss: 1.198, Global test accuracy: 88.90
Round  12, Train loss: 1.513, Test loss: 1.225, Test accuracy: 73.22
Round  12, Global train loss: 1.513, Global test loss: 1.330, Global test accuracy: 75.62
Round  13, Train loss: 1.137, Test loss: 1.221, Test accuracy: 74.08
Round  13, Global train loss: 1.137, Global test loss: 1.042, Global test accuracy: 92.16
Round  14, Train loss: 1.270, Test loss: 1.219, Test accuracy: 73.48
Round  14, Global train loss: 1.270, Global test loss: 1.021, Global test accuracy: 93.28
Round  15, Train loss: 1.372, Test loss: 1.207, Test accuracy: 74.58
Round  15, Global train loss: 1.372, Global test loss: 1.243, Global test accuracy: 90.60
Round  16, Train loss: 1.115, Test loss: 1.210, Test accuracy: 73.78
Round  16, Global train loss: 1.115, Global test loss: 0.982, Global test accuracy: 93.76
Round  17, Train loss: 1.298, Test loss: 1.206, Test accuracy: 74.92
Round  17, Global train loss: 1.298, Global test loss: 1.056, Global test accuracy: 93.94
Round  18, Train loss: 1.112, Test loss: 1.211, Test accuracy: 74.34
Round  18, Global train loss: 1.112, Global test loss: 0.967, Global test accuracy: 95.58
Round  19, Train loss: 1.448, Test loss: 1.205, Test accuracy: 74.18
Round  19, Global train loss: 1.448, Global test loss: 1.294, Global test accuracy: 77.30
Round  20, Train loss: 1.473, Test loss: 1.200, Test accuracy: 73.78
Round  20, Global train loss: 1.473, Global test loss: 1.399, Global test accuracy: 61.46
Round  21, Train loss: 1.160, Test loss: 1.194, Test accuracy: 74.84
Round  21, Global train loss: 1.160, Global test loss: 1.001, Global test accuracy: 93.96
Round  22, Train loss: 1.087, Test loss: 1.196, Test accuracy: 74.34
Round  22, Global train loss: 1.087, Global test loss: 1.026, Global test accuracy: 88.88
Round  23, Train loss: 1.077, Test loss: 1.195, Test accuracy: 74.52
Round  23, Global train loss: 1.077, Global test loss: 0.974, Global test accuracy: 94.22
Round  24, Train loss: 1.031, Test loss: 1.199, Test accuracy: 73.80
Round  24, Global train loss: 1.031, Global test loss: 0.962, Global test accuracy: 95.56
Round  25, Train loss: 1.114, Test loss: 1.193, Test accuracy: 74.24
Round  25, Global train loss: 1.114, Global test loss: 0.967, Global test accuracy: 96.18
Round  26, Train loss: 1.095, Test loss: 1.194, Test accuracy: 74.02
Round  26, Global train loss: 1.095, Global test loss: 0.965, Global test accuracy: 95.52
Round  27, Train loss: 1.074, Test loss: 1.196, Test accuracy: 73.30
Round  27, Global train loss: 1.074, Global test loss: 0.962, Global test accuracy: 95.66
Round  28, Train loss: 1.236, Test loss: 1.203, Test accuracy: 71.46
Round  28, Global train loss: 1.236, Global test loss: 1.110, Global test accuracy: 82.36
Round  29, Train loss: 1.362, Test loss: 1.207, Test accuracy: 71.22
Round  29, Global train loss: 1.362, Global test loss: 1.365, Global test accuracy: 57.94
Round  30, Train loss: 1.159, Test loss: 1.208, Test accuracy: 71.20
Round  30, Global train loss: 1.159, Global test loss: 1.079, Global test accuracy: 83.04
Round  31, Train loss: 1.129, Test loss: 1.212, Test accuracy: 70.68
Round  31, Global train loss: 1.129, Global test loss: 1.007, Global test accuracy: 91.70
Round  32, Train loss: 1.131, Test loss: 1.208, Test accuracy: 71.16
Round  32, Global train loss: 1.131, Global test loss: 0.975, Global test accuracy: 95.56
Round  33, Train loss: 1.017, Test loss: 1.212, Test accuracy: 70.64
Round  33, Global train loss: 1.017, Global test loss: 1.035, Global test accuracy: 87.00
Round  34, Train loss: 1.117, Test loss: 1.213, Test accuracy: 69.76
Round  34, Global train loss: 1.117, Global test loss: 0.967, Global test accuracy: 95.62
Round  35, Train loss: 1.357, Test loss: 1.215, Test accuracy: 69.60
Round  35, Global train loss: 1.357, Global test loss: 1.183, Global test accuracy: 80.38
Round  36, Train loss: 1.206, Test loss: 1.207, Test accuracy: 70.82
Round  36, Global train loss: 1.206, Global test loss: 1.045, Global test accuracy: 89.48
Round  37, Train loss: 1.008, Test loss: 1.207, Test accuracy: 70.88
Round  37, Global train loss: 1.008, Global test loss: 1.034, Global test accuracy: 87.06
Round  38, Train loss: 1.133, Test loss: 1.203, Test accuracy: 71.00
Round  38, Global train loss: 1.133, Global test loss: 1.127, Global test accuracy: 77.92
Round  39, Train loss: 1.163, Test loss: 1.205, Test accuracy: 70.48
Round  39, Global train loss: 1.163, Global test loss: 1.033, Global test accuracy: 92.06
Round  40, Train loss: 1.213, Test loss: 1.207, Test accuracy: 70.02
Round  40, Global train loss: 1.213, Global test loss: 1.247, Global test accuracy: 69.06
Round  41, Train loss: 1.106, Test loss: 1.209, Test accuracy: 69.70
Round  41, Global train loss: 1.106, Global test loss: 1.015, Global test accuracy: 91.10
Round  42, Train loss: 1.100, Test loss: 1.213, Test accuracy: 69.06
Round  42, Global train loss: 1.100, Global test loss: 1.069, Global test accuracy: 84.20
Round  43, Train loss: 1.120, Test loss: 1.221, Test accuracy: 67.78
Round  43, Global train loss: 1.120, Global test loss: 1.028, Global test accuracy: 91.46
Round  44, Train loss: 1.130, Test loss: 1.227, Test accuracy: 67.04
Round  44, Global train loss: 1.130, Global test loss: 1.089, Global test accuracy: 82.50
Round  45, Train loss: 1.108, Test loss: 1.228, Test accuracy: 66.70
Round  45, Global train loss: 1.108, Global test loss: 1.015, Global test accuracy: 91.00
Round  46, Train loss: 1.061, Test loss: 1.235, Test accuracy: 65.86
Round  46, Global train loss: 1.061, Global test loss: 1.100, Global test accuracy: 80.60
Round  47, Train loss: 1.149, Test loss: 1.234, Test accuracy: 66.08
Round  47, Global train loss: 1.149, Global test loss: 1.125, Global test accuracy: 81.14
Round  48, Train loss: 1.066, Test loss: 1.235, Test accuracy: 66.08
Round  48, Global train loss: 1.066, Global test loss: 1.053, Global test accuracy: 86.94
Round  49, Train loss: 1.022, Test loss: 1.232, Test accuracy: 66.42
Round  49, Global train loss: 1.022, Global test loss: 0.966, Global test accuracy: 94.40
Round  50, Train loss: 1.132, Test loss: 1.240, Test accuracy: 65.36
Round  50, Global train loss: 1.132, Global test loss: 1.201, Global test accuracy: 70.62
Round  51, Train loss: 1.072, Test loss: 1.241, Test accuracy: 65.20
Round  51, Global train loss: 1.072, Global test loss: 1.016, Global test accuracy: 89.82
Round  52, Train loss: 1.038, Test loss: 1.243, Test accuracy: 65.10
Round  52, Global train loss: 1.038, Global test loss: 0.990, Global test accuracy: 93.10
Round  53, Train loss: 1.097, Test loss: 1.238, Test accuracy: 65.74
Round  53, Global train loss: 1.097, Global test loss: 1.294, Global test accuracy: 63.80
Round  54, Train loss: 0.985, Test loss: 1.237, Test accuracy: 65.84
Round  54, Global train loss: 0.985, Global test loss: 0.972, Global test accuracy: 94.20
Round  55, Train loss: 1.084, Test loss: 1.241, Test accuracy: 65.66
Round  55, Global train loss: 1.084, Global test loss: 0.996, Global test accuracy: 92.34
Round  56, Train loss: 1.055, Test loss: 1.240, Test accuracy: 65.76
Round  56, Global train loss: 1.055, Global test loss: 1.009, Global test accuracy: 90.74
Round  57, Train loss: 1.025, Test loss: 1.241, Test accuracy: 65.66
Round  57, Global train loss: 1.025, Global test loss: 1.008, Global test accuracy: 90.60
Round  58, Train loss: 0.963, Test loss: 1.235, Test accuracy: 66.22
Round  58, Global train loss: 0.963, Global test loss: 0.958, Global test accuracy: 95.60
Round  59, Train loss: 1.042, Test loss: 1.234, Test accuracy: 66.40
Round  59, Global train loss: 1.042, Global test loss: 0.983, Global test accuracy: 92.86
Round  60, Train loss: 1.028, Test loss: 1.233, Test accuracy: 66.44
Round  60, Global train loss: 1.028, Global test loss: 0.992, Global test accuracy: 91.94
Round  61, Train loss: 1.013, Test loss: 1.238, Test accuracy: 65.80
Round  61, Global train loss: 1.013, Global test loss: 0.981, Global test accuracy: 94.00
Round  62, Train loss: 0.957, Test loss: 1.240, Test accuracy: 65.68
Round  62, Global train loss: 0.957, Global test loss: 0.951, Global test accuracy: 95.96
Round  63, Train loss: 1.025, Test loss: 1.240, Test accuracy: 65.72
Round  63, Global train loss: 1.025, Global test loss: 0.961, Global test accuracy: 94.74
Round  64, Train loss: 0.954, Test loss: 1.239, Test accuracy: 65.62
Round  64, Global train loss: 0.954, Global test loss: 0.952, Global test accuracy: 95.96
Round  65, Train loss: 0.987, Test loss: 1.242, Test accuracy: 65.24
Round  65, Global train loss: 0.987, Global test loss: 0.963, Global test accuracy: 94.18
Round  66, Train loss: 1.070, Test loss: 1.245, Test accuracy: 65.08
Round  66, Global train loss: 1.070, Global test loss: 1.149, Global test accuracy: 77.82
Round  67, Train loss: 1.025, Test loss: 1.245, Test accuracy: 64.98
Round  67, Global train loss: 1.025, Global test loss: 1.074, Global test accuracy: 86.08
Round  68, Train loss: 1.012, Test loss: 1.250, Test accuracy: 64.46
Round  68, Global train loss: 1.012, Global test loss: 1.021, Global test accuracy: 90.40
Round  69, Train loss: 0.996, Test loss: 1.247, Test accuracy: 64.66
Round  69, Global train loss: 0.996, Global test loss: 1.032, Global test accuracy: 88.90
Round  70, Train loss: 1.020, Test loss: 1.249, Test accuracy: 64.56
Round  70, Global train loss: 1.020, Global test loss: 0.956, Global test accuracy: 95.30
Round  71, Train loss: 1.034, Test loss: 1.250, Test accuracy: 64.44
Round  71, Global train loss: 1.034, Global test loss: 1.003, Global test accuracy: 90.74
Round  72, Train loss: 1.053, Test loss: 1.251, Test accuracy: 64.38
Round  72, Global train loss: 1.053, Global test loss: 1.244, Global test accuracy: 67.34
Round  73, Train loss: 1.039, Test loss: 1.250, Test accuracy: 64.48
Round  73, Global train loss: 1.039, Global test loss: 0.973, Global test accuracy: 94.20
Round  74, Train loss: 0.960, Test loss: 1.250, Test accuracy: 64.56
Round  74, Global train loss: 0.960, Global test loss: 0.948, Global test accuracy: 95.98
Round  75, Train loss: 0.971, Test loss: 1.250, Test accuracy: 64.46
Round  75, Global train loss: 0.971, Global test loss: 0.958, Global test accuracy: 95.28
Round  76, Train loss: 0.962, Test loss: 1.251, Test accuracy: 64.38
Round  76, Global train loss: 0.962, Global test loss: 0.980, Global test accuracy: 92.46
Round  77, Train loss: 1.018, Test loss: 1.252, Test accuracy: 64.28
Round  77, Global train loss: 1.018, Global test loss: 1.047, Global test accuracy: 88.02
Round  78, Train loss: 0.940, Test loss: 1.251, Test accuracy: 64.30
Round  78, Global train loss: 0.940, Global test loss: 0.957, Global test accuracy: 95.44
Round  79, Train loss: 1.012, Test loss: 1.249, Test accuracy: 64.54
Round  79, Global train loss: 1.012, Global test loss: 0.990, Global test accuracy: 91.82
Round  80, Train loss: 1.026, Test loss: 1.251, Test accuracy: 64.44
Round  80, Global train loss: 1.026, Global test loss: 1.001, Global test accuracy: 90.66
Round  81, Train loss: 0.940, Test loss: 1.253, Test accuracy: 64.20
Round  81, Global train loss: 0.940, Global test loss: 0.966, Global test accuracy: 94.42
Round  82, Train loss: 0.958, Test loss: 1.254, Test accuracy: 64.10
Round  82, Global train loss: 0.958, Global test loss: 0.972, Global test accuracy: 93.56
Round  83, Train loss: 0.959, Test loss: 1.253, Test accuracy: 64.24
Round  83, Global train loss: 0.959, Global test loss: 0.974, Global test accuracy: 93.54
Round  84, Train loss: 1.035, Test loss: 1.253, Test accuracy: 64.42
Round  84, Global train loss: 1.035, Global test loss: 0.985, Global test accuracy: 92.54
Round  85, Train loss: 1.013, Test loss: 1.254, Test accuracy: 64.28
Round  85, Global train loss: 1.013, Global test loss: 1.003, Global test accuracy: 90.68
Round  86, Train loss: 1.010, Test loss: 1.257, Test accuracy: 64.02
Round  86, Global train loss: 1.010, Global test loss: 0.992, Global test accuracy: 91.74
Round  87, Train loss: 1.043, Test loss: 1.262, Test accuracy: 63.30
Round  87, Global train loss: 1.043, Global test loss: 1.220, Global test accuracy: 70.22
Round  88, Train loss: 0.986, Test loss: 1.267, Test accuracy: 62.72
Round  88, Global train loss: 0.986, Global test loss: 0.971, Global test accuracy: 93.68
Round  89, Train loss: 0.995, Test loss: 1.262, Test accuracy: 63.22
Round  89, Global train loss: 0.995, Global test loss: 1.022, Global test accuracy: 89.42
Round  90, Train loss: 0.981, Test loss: 1.260, Test accuracy: 63.40
Round  90, Global train loss: 0.981, Global test loss: 0.970, Global test accuracy: 93.76
Round  91, Train loss: 0.996, Test loss: 1.261, Test accuracy: 63.42
Round  91, Global train loss: 0.996, Global test loss: 0.991, Global test accuracy: 91.70
Round  92, Train loss: 1.033, Test loss: 1.260, Test accuracy: 63.28
Round  92, Global train loss: 1.033, Global test loss: 0.973, Global test accuracy: 93.50
Round  93, Train loss: 1.034, Test loss: 1.262, Test accuracy: 63.34
Round  93, Global train loss: 1.034, Global test loss: 1.022, Global test accuracy: 89.44
Round  94, Train loss: 0.995, Test loss: 1.261, Test accuracy: 63.72
Round  94, Global train loss: 0.995, Global test loss: 1.006, Global test accuracy: 91.64/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  95, Train loss: 1.035, Test loss: 1.260, Test accuracy: 63.66
Round  95, Global train loss: 1.035, Global test loss: 1.003, Global test accuracy: 90.72
Round  96, Train loss: 0.983, Test loss: 1.261, Test accuracy: 63.46
Round  96, Global train loss: 0.983, Global test loss: 0.951, Global test accuracy: 95.82
Round  97, Train loss: 1.039, Test loss: 1.261, Test accuracy: 63.42
Round  97, Global train loss: 1.039, Global test loss: 1.152, Global test accuracy: 76.40
Round  98, Train loss: 0.910, Test loss: 1.261, Test accuracy: 63.42
Round  98, Global train loss: 0.910, Global test loss: 0.940, Global test accuracy: 96.58
Round  99, Train loss: 1.068, Test loss: 1.259, Test accuracy: 63.74
Round  99, Global train loss: 1.068, Global test loss: 1.137, Global test accuracy: 78.48
Final Round, Train loss: 0.995, Test loss: 1.257, Test accuracy: 63.88
Final Round, Global train loss: 0.995, Global test loss: 1.137, Global test accuracy: 78.48
Average accuracy final 10 rounds: 63.486 

Average global accuracy final 10 rounds: 89.804 

629.8008193969727
[0.9137861728668213, 1.8275723457336426, 2.583142042160034, 3.338711738586426, 4.1237404346466064, 4.908769130706787, 5.674154281616211, 6.439539432525635, 7.215522766113281, 7.991506099700928, 8.746506452560425, 9.501506805419922, 10.306435108184814, 11.111363410949707, 11.887200832366943, 12.66303825378418, 13.452245235443115, 14.24145221710205, 15.04135775566101, 15.84126329421997, 16.62096905708313, 17.40067481994629, 18.244822025299072, 19.088969230651855, 19.862844228744507, 20.636719226837158, 21.413339376449585, 22.18995952606201, 22.99962091445923, 23.809282302856445, 24.55918574333191, 25.309089183807373, 26.09032893180847, 26.87156867980957, 27.602219820022583, 28.332870960235596, 29.129257678985596, 29.925644397735596, 30.687019109725952, 31.44839382171631, 32.20881462097168, 32.96923542022705, 33.75071406364441, 34.53219270706177, 35.29825258255005, 36.06431245803833, 36.84983277320862, 37.635353088378906, 38.39597773551941, 39.15660238265991, 39.934027671813965, 40.71145296096802, 41.48306131362915, 42.25466966629028, 43.0347101688385, 43.81475067138672, 44.59124732017517, 45.36774396896362, 46.14988970756531, 46.93203544616699, 47.713120460510254, 48.494205474853516, 49.268661975860596, 50.043118476867676, 50.81560015678406, 51.58808183670044, 52.361891984939575, 53.13570213317871, 53.88931918144226, 54.64293622970581, 55.39935660362244, 56.15577697753906, 56.911343812942505, 57.66691064834595, 58.69091749191284, 59.714924335479736, 60.47472167015076, 61.23451900482178, 62.00600242614746, 62.777485847473145, 63.55482816696167, 64.3321704864502, 65.08706283569336, 65.84195518493652, 66.61690211296082, 67.39184904098511, 68.19739603996277, 69.00294303894043, 69.7761549949646, 70.54936695098877, 71.75338077545166, 72.95739459991455, 74.27539277076721, 75.59339094161987, 76.86564445495605, 78.13789796829224, 79.38235759735107, 80.62681722640991, 81.86365914344788, 83.10050106048584, 84.48319554328918, 85.86589002609253, 87.18701171875, 88.50813341140747, 89.52656531333923, 90.544997215271, 91.54684257507324, 92.54868793487549, 93.5990080833435, 94.64932823181152, 95.62253212928772, 96.59573602676392, 97.56339383125305, 98.53105163574219, 99.32838606834412, 100.12572050094604, 100.89617276191711, 101.66662502288818, 102.42948126792908, 103.19233751296997, 103.96297216415405, 104.73360681533813, 105.51681733131409, 106.30002784729004, 107.07981038093567, 107.8595929145813, 108.63020014762878, 109.40080738067627, 110.18747472763062, 110.97414207458496, 111.74734807014465, 112.52055406570435, 113.38946199417114, 114.25836992263794, 115.03598189353943, 115.81359386444092, 116.61427402496338, 117.41495418548584, 118.19177341461182, 118.9685926437378, 119.72318887710571, 120.47778511047363, 121.28621077537537, 122.0946364402771, 122.85476112365723, 123.61488580703735, 124.38854360580444, 125.16220140457153, 125.96084570884705, 126.75949001312256, 127.51139783859253, 128.2633056640625, 129.13270354270935, 130.0021014213562, 130.8118085861206, 131.621515750885, 132.38617205619812, 133.15082836151123, 134.04767107963562, 134.94451379776, 135.72295904159546, 136.5014042854309, 137.5184609889984, 138.53551769256592, 139.28985619544983, 140.04419469833374, 140.8138484954834, 141.58350229263306, 142.41522645950317, 143.2469506263733, 144.07791447639465, 144.90887832641602, 145.70018792152405, 146.49149751663208, 147.25858688354492, 148.02567625045776, 148.91147208213806, 149.79726791381836, 150.55822610855103, 151.3191843032837, 152.10300302505493, 152.88682174682617, 153.63683414459229, 154.3868465423584, 155.1620054244995, 155.93716430664062, 156.72125840187073, 157.50535249710083, 158.26482963562012, 159.0243067741394, 159.7766833305359, 160.52905988693237, 161.30797219276428, 162.0868844985962, 162.85428166389465, 163.62167882919312, 164.40614485740662, 165.19061088562012, 165.9632956981659, 166.73598051071167, 168.49306869506836, 170.25015687942505]
[56.96, 56.96, 59.72, 59.72, 63.86, 63.86, 64.9, 64.9, 64.42, 64.42, 66.94, 66.94, 68.28, 68.28, 69.48, 69.48, 69.16, 69.16, 69.92, 69.92, 70.62, 70.62, 73.04, 73.04, 73.22, 73.22, 74.08, 74.08, 73.48, 73.48, 74.58, 74.58, 73.78, 73.78, 74.92, 74.92, 74.34, 74.34, 74.18, 74.18, 73.78, 73.78, 74.84, 74.84, 74.34, 74.34, 74.52, 74.52, 73.8, 73.8, 74.24, 74.24, 74.02, 74.02, 73.3, 73.3, 71.46, 71.46, 71.22, 71.22, 71.2, 71.2, 70.68, 70.68, 71.16, 71.16, 70.64, 70.64, 69.76, 69.76, 69.6, 69.6, 70.82, 70.82, 70.88, 70.88, 71.0, 71.0, 70.48, 70.48, 70.02, 70.02, 69.7, 69.7, 69.06, 69.06, 67.78, 67.78, 67.04, 67.04, 66.7, 66.7, 65.86, 65.86, 66.08, 66.08, 66.08, 66.08, 66.42, 66.42, 65.36, 65.36, 65.2, 65.2, 65.1, 65.1, 65.74, 65.74, 65.84, 65.84, 65.66, 65.66, 65.76, 65.76, 65.66, 65.66, 66.22, 66.22, 66.4, 66.4, 66.44, 66.44, 65.8, 65.8, 65.68, 65.68, 65.72, 65.72, 65.62, 65.62, 65.24, 65.24, 65.08, 65.08, 64.98, 64.98, 64.46, 64.46, 64.66, 64.66, 64.56, 64.56, 64.44, 64.44, 64.38, 64.38, 64.48, 64.48, 64.56, 64.56, 64.46, 64.46, 64.38, 64.38, 64.28, 64.28, 64.3, 64.3, 64.54, 64.54, 64.44, 64.44, 64.2, 64.2, 64.1, 64.1, 64.24, 64.24, 64.42, 64.42, 64.28, 64.28, 64.02, 64.02, 63.3, 63.3, 62.72, 62.72, 63.22, 63.22, 63.4, 63.4, 63.42, 63.42, 63.28, 63.28, 63.34, 63.34, 63.72, 63.72, 63.66, 63.66, 63.46, 63.46, 63.42, 63.42, 63.42, 63.42, 63.74, 63.74, 63.88, 63.88]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.6 , level_n_lowerb:0.8  

   Client 2, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.602, Test loss: 1.589, Test accuracy: 44.68
Round   0, Global train loss: 1.602, Global test loss: 1.592, Global test accuracy: 48.40
Round   1, Train loss: 1.511, Test loss: 1.416, Test accuracy: 59.52
Round   1, Global train loss: 1.511, Global test loss: 1.379, Global test accuracy: 74.20
Round   2, Train loss: 1.448, Test loss: 1.302, Test accuracy: 74.54
Round   2, Global train loss: 1.448, Global test loss: 1.225, Global test accuracy: 92.36
Round   3, Train loss: 1.418, Test loss: 1.218, Test accuracy: 80.54
Round   3, Global train loss: 1.418, Global test loss: 1.084, Global test accuracy: 93.70
Round   4, Train loss: 1.218, Test loss: 1.162, Test accuracy: 81.80
Round   4, Global train loss: 1.218, Global test loss: 1.003, Global test accuracy: 94.62
Round   5, Train loss: 1.037, Test loss: 1.146, Test accuracy: 82.84
Round   5, Global train loss: 1.037, Global test loss: 0.971, Global test accuracy: 95.38
Round   6, Train loss: 1.144, Test loss: 1.144, Test accuracy: 82.94
Round   6, Global train loss: 1.144, Global test loss: 0.956, Global test accuracy: 96.24
Round   7, Train loss: 1.025, Test loss: 1.135, Test accuracy: 83.50
Round   7, Global train loss: 1.025, Global test loss: 0.952, Global test accuracy: 95.92
Round   8, Train loss: 1.394, Test loss: 1.051, Test accuracy: 90.80
Round   8, Global train loss: 1.394, Global test loss: 0.953, Global test accuracy: 96.10
Round   9, Train loss: 1.387, Test loss: 1.034, Test accuracy: 90.38
Round   9, Global train loss: 1.387, Global test loss: 0.954, Global test accuracy: 95.96
Round  10, Train loss: 1.348, Test loss: 0.980, Test accuracy: 93.48
Round  10, Global train loss: 1.348, Global test loss: 0.950, Global test accuracy: 96.38
Round  11, Train loss: 1.175, Test loss: 0.980, Test accuracy: 93.38
Round  11, Global train loss: 1.175, Global test loss: 0.949, Global test accuracy: 96.46
Round  12, Train loss: 1.378, Test loss: 0.973, Test accuracy: 93.78
Round  12, Global train loss: 1.378, Global test loss: 0.960, Global test accuracy: 95.32
Round  13, Train loss: 1.379, Test loss: 0.970, Test accuracy: 94.16
Round  13, Global train loss: 1.379, Global test loss: 0.951, Global test accuracy: 95.90
Round  14, Train loss: 1.168, Test loss: 0.970, Test accuracy: 94.18
Round  14, Global train loss: 1.168, Global test loss: 0.948, Global test accuracy: 96.40
Round  15, Train loss: 1.334, Test loss: 0.965, Test accuracy: 94.82
Round  15, Global train loss: 1.334, Global test loss: 0.945, Global test accuracy: 96.40
Round  16, Train loss: 1.207, Test loss: 0.965, Test accuracy: 94.74
Round  16, Global train loss: 1.207, Global test loss: 0.946, Global test accuracy: 96.44
Round  17, Train loss: 1.334, Test loss: 0.968, Test accuracy: 94.44
Round  17, Global train loss: 1.334, Global test loss: 0.952, Global test accuracy: 95.92
Round  18, Train loss: 1.324, Test loss: 0.967, Test accuracy: 94.40
Round  18, Global train loss: 1.324, Global test loss: 0.948, Global test accuracy: 96.20
Round  19, Train loss: 1.168, Test loss: 0.967, Test accuracy: 94.16
Round  19, Global train loss: 1.168, Global test loss: 0.946, Global test accuracy: 96.26
Round  20, Train loss: 1.328, Test loss: 0.967, Test accuracy: 94.22
Round  20, Global train loss: 1.328, Global test loss: 0.958, Global test accuracy: 94.86
Round  21, Train loss: 1.373, Test loss: 0.964, Test accuracy: 94.64
Round  21, Global train loss: 1.373, Global test loss: 0.947, Global test accuracy: 96.18
Round  22, Train loss: 1.168, Test loss: 0.967, Test accuracy: 94.22
Round  22, Global train loss: 1.168, Global test loss: 0.948, Global test accuracy: 95.98
Round  23, Train loss: 1.163, Test loss: 0.970, Test accuracy: 93.92
Round  23, Global train loss: 1.163, Global test loss: 0.942, Global test accuracy: 96.68
Round  24, Train loss: 1.165, Test loss: 0.970, Test accuracy: 93.80
Round  24, Global train loss: 1.165, Global test loss: 0.942, Global test accuracy: 96.56
Round  25, Train loss: 1.169, Test loss: 0.971, Test accuracy: 93.58
Round  25, Global train loss: 1.169, Global test loss: 0.943, Global test accuracy: 96.70
Round  26, Train loss: 1.524, Test loss: 0.970, Test accuracy: 93.84
Round  26, Global train loss: 1.524, Global test loss: 0.950, Global test accuracy: 96.14
Round  27, Train loss: 0.960, Test loss: 0.970, Test accuracy: 93.86
Round  27, Global train loss: 0.960, Global test loss: 0.941, Global test accuracy: 96.56
Round  28, Train loss: 1.521, Test loss: 0.967, Test accuracy: 94.10
Round  28, Global train loss: 1.521, Global test loss: 0.950, Global test accuracy: 95.90
Round  29, Train loss: 1.324, Test loss: 0.970, Test accuracy: 93.80
Round  29, Global train loss: 1.324, Global test loss: 0.961, Global test accuracy: 94.94
Round  30, Train loss: 1.355, Test loss: 0.973, Test accuracy: 93.38
Round  30, Global train loss: 1.355, Global test loss: 0.956, Global test accuracy: 95.28
Round  31, Train loss: 0.995, Test loss: 0.973, Test accuracy: 93.32
Round  31, Global train loss: 0.995, Global test loss: 0.943, Global test accuracy: 96.48
Round  32, Train loss: 1.527, Test loss: 0.975, Test accuracy: 93.22
Round  32, Global train loss: 1.527, Global test loss: 0.952, Global test accuracy: 95.52
Round  33, Train loss: 1.159, Test loss: 0.978, Test accuracy: 92.96
Round  33, Global train loss: 1.159, Global test loss: 0.951, Global test accuracy: 95.66
Round  34, Train loss: 1.320, Test loss: 0.979, Test accuracy: 92.76
Round  34, Global train loss: 1.320, Global test loss: 0.953, Global test accuracy: 95.74
Round  35, Train loss: 1.517, Test loss: 0.978, Test accuracy: 92.96
Round  35, Global train loss: 1.517, Global test loss: 0.968, Global test accuracy: 94.10
Round  36, Train loss: 1.504, Test loss: 0.985, Test accuracy: 92.36
Round  36, Global train loss: 1.504, Global test loss: 0.973, Global test accuracy: 93.64
Round  37, Train loss: 1.156, Test loss: 0.979, Test accuracy: 93.02
Round  37, Global train loss: 1.156, Global test loss: 0.955, Global test accuracy: 95.30
Round  38, Train loss: 1.342, Test loss: 0.986, Test accuracy: 92.14
Round  38, Global train loss: 1.342, Global test loss: 0.985, Global test accuracy: 92.18
Round  39, Train loss: 1.343, Test loss: 0.989, Test accuracy: 91.90
Round  39, Global train loss: 1.343, Global test loss: 0.970, Global test accuracy: 93.88
Round  40, Train loss: 1.494, Test loss: 0.986, Test accuracy: 92.18
Round  40, Global train loss: 1.494, Global test loss: 0.995, Global test accuracy: 91.48
Round  41, Train loss: 1.497, Test loss: 0.989, Test accuracy: 91.88
Round  41, Global train loss: 1.497, Global test loss: 0.985, Global test accuracy: 92.34
Round  42, Train loss: 1.343, Test loss: 0.991, Test accuracy: 91.70
Round  42, Global train loss: 1.343, Global test loss: 0.969, Global test accuracy: 94.12
Round  43, Train loss: 1.309, Test loss: 0.990, Test accuracy: 91.60
Round  43, Global train loss: 1.309, Global test loss: 0.961, Global test accuracy: 94.94
Round  44, Train loss: 1.496, Test loss: 0.997, Test accuracy: 91.00
Round  44, Global train loss: 1.496, Global test loss: 0.975, Global test accuracy: 93.42
Round  45, Train loss: 1.345, Test loss: 1.000, Test accuracy: 90.66
Round  45, Global train loss: 1.345, Global test loss: 0.961, Global test accuracy: 94.88
Round  46, Train loss: 1.330, Test loss: 0.997, Test accuracy: 91.06
Round  46, Global train loss: 1.330, Global test loss: 0.991, Global test accuracy: 91.78
Round  47, Train loss: 1.481, Test loss: 1.002, Test accuracy: 90.54
Round  47, Global train loss: 1.481, Global test loss: 1.001, Global test accuracy: 90.98
Round  48, Train loss: 1.301, Test loss: 1.005, Test accuracy: 90.26
Round  48, Global train loss: 1.301, Global test loss: 0.971, Global test accuracy: 93.80
Round  49, Train loss: 1.338, Test loss: 1.011, Test accuracy: 89.70
Round  49, Global train loss: 1.338, Global test loss: 0.980, Global test accuracy: 92.76
Round  50, Train loss: 1.334, Test loss: 1.012, Test accuracy: 89.68
Round  50, Global train loss: 1.334, Global test loss: 0.977, Global test accuracy: 93.16
Round  51, Train loss: 1.315, Test loss: 1.018, Test accuracy: 89.02
Round  51, Global train loss: 1.315, Global test loss: 0.993, Global test accuracy: 91.58
Round  52, Train loss: 1.294, Test loss: 1.018, Test accuracy: 88.98
Round  52, Global train loss: 1.294, Global test loss: 0.964, Global test accuracy: 94.84
Round  53, Train loss: 1.275, Test loss: 1.016, Test accuracy: 89.36
Round  53, Global train loss: 1.275, Global test loss: 1.001, Global test accuracy: 91.08
Round  54, Train loss: 1.281, Test loss: 1.014, Test accuracy: 89.36
Round  54, Global train loss: 1.281, Global test loss: 0.981, Global test accuracy: 92.78
Round  55, Train loss: 1.291, Test loss: 1.022, Test accuracy: 88.50
Round  55, Global train loss: 1.291, Global test loss: 0.965, Global test accuracy: 94.70
Round  56, Train loss: 1.458, Test loss: 1.021, Test accuracy: 88.62
Round  56, Global train loss: 1.458, Global test loss: 1.016, Global test accuracy: 89.16
Round  57, Train loss: 1.123, Test loss: 1.021, Test accuracy: 88.64
Round  57, Global train loss: 1.123, Global test loss: 0.972, Global test accuracy: 93.74
Round  58, Train loss: 1.277, Test loss: 1.020, Test accuracy: 88.72
Round  58, Global train loss: 1.277, Global test loss: 0.979, Global test accuracy: 92.80
Round  59, Train loss: 1.327, Test loss: 1.024, Test accuracy: 88.32
Round  59, Global train loss: 1.327, Global test loss: 0.970, Global test accuracy: 94.08
Round  60, Train loss: 0.954, Test loss: 1.025, Test accuracy: 88.34
Round  60, Global train loss: 0.954, Global test loss: 0.946, Global test accuracy: 96.36
Round  61, Train loss: 1.105, Test loss: 1.023, Test accuracy: 88.44
Round  61, Global train loss: 1.105, Global test loss: 0.949, Global test accuracy: 96.10
Round  62, Train loss: 0.943, Test loss: 1.021, Test accuracy: 88.54
Round  62, Global train loss: 0.943, Global test loss: 0.945, Global test accuracy: 96.32
Round  63, Train loss: 1.322, Test loss: 1.019, Test accuracy: 88.84
Round  63, Global train loss: 1.322, Global test loss: 0.983, Global test accuracy: 91.88
Round  64, Train loss: 1.118, Test loss: 1.019, Test accuracy: 88.74
Round  64, Global train loss: 1.118, Global test loss: 0.971, Global test accuracy: 93.94
Round  65, Train loss: 1.310, Test loss: 1.017, Test accuracy: 89.02
Round  65, Global train loss: 1.310, Global test loss: 0.991, Global test accuracy: 91.84
Round  66, Train loss: 1.134, Test loss: 1.018, Test accuracy: 88.76
Round  66, Global train loss: 1.134, Global test loss: 0.957, Global test accuracy: 95.28
Round  67, Train loss: 1.451, Test loss: 1.024, Test accuracy: 88.26
Round  67, Global train loss: 1.451, Global test loss: 1.026, Global test accuracy: 88.12
Round  68, Train loss: 1.263, Test loss: 1.026, Test accuracy: 88.18
Round  68, Global train loss: 1.263, Global test loss: 0.981, Global test accuracy: 93.00
Round  69, Train loss: 1.251, Test loss: 1.031, Test accuracy: 87.54
Round  69, Global train loss: 1.251, Global test loss: 1.012, Global test accuracy: 89.44
Round  70, Train loss: 1.456, Test loss: 1.036, Test accuracy: 87.16
Round  70, Global train loss: 1.456, Global test loss: 1.011, Global test accuracy: 89.84
Round  71, Train loss: 1.296, Test loss: 1.038, Test accuracy: 86.84
Round  71, Global train loss: 1.296, Global test loss: 1.007, Global test accuracy: 90.24
Round  72, Train loss: 1.278, Test loss: 1.044, Test accuracy: 86.36
Round  72, Global train loss: 1.278, Global test loss: 1.025, Global test accuracy: 88.48
Round  73, Train loss: 1.271, Test loss: 1.046, Test accuracy: 86.04
Round  73, Global train loss: 1.271, Global test loss: 0.983, Global test accuracy: 92.88
Round  74, Train loss: 1.128, Test loss: 1.049, Test accuracy: 85.80
Round  74, Global train loss: 1.128, Global test loss: 0.972, Global test accuracy: 93.90
Round  75, Train loss: 1.255, Test loss: 1.053, Test accuracy: 85.42
Round  75, Global train loss: 1.255, Global test loss: 0.999, Global test accuracy: 91.00
Round  76, Train loss: 1.282, Test loss: 1.055, Test accuracy: 84.96
Round  76, Global train loss: 1.282, Global test loss: 1.030, Global test accuracy: 87.78
Round  77, Train loss: 1.237, Test loss: 1.048, Test accuracy: 85.66
Round  77, Global train loss: 1.237, Global test loss: 0.999, Global test accuracy: 91.16
Round  78, Train loss: 1.254, Test loss: 1.057, Test accuracy: 84.72
Round  78, Global train loss: 1.254, Global test loss: 1.028, Global test accuracy: 87.96
Round  79, Train loss: 1.110, Test loss: 1.055, Test accuracy: 84.80
Round  79, Global train loss: 1.110, Global test loss: 0.969, Global test accuracy: 94.32
Round  80, Train loss: 1.291, Test loss: 1.047, Test accuracy: 85.64
Round  80, Global train loss: 1.291, Global test loss: 1.034, Global test accuracy: 86.68
Round  81, Train loss: 1.101, Test loss: 1.050, Test accuracy: 85.54
Round  81, Global train loss: 1.101, Global test loss: 1.006, Global test accuracy: 90.22
Round  82, Train loss: 1.402, Test loss: 1.056, Test accuracy: 84.82
Round  82, Global train loss: 1.402, Global test loss: 1.087, Global test accuracy: 81.84
Round  83, Train loss: 1.096, Test loss: 1.057, Test accuracy: 84.82
Round  83, Global train loss: 1.096, Global test loss: 0.994, Global test accuracy: 91.42
Round  84, Train loss: 1.118, Test loss: 1.059, Test accuracy: 84.64
Round  84, Global train loss: 1.118, Global test loss: 0.972, Global test accuracy: 93.84
Round  85, Train loss: 0.972, Test loss: 1.059, Test accuracy: 84.56
Round  85, Global train loss: 0.972, Global test loss: 0.955, Global test accuracy: 95.38
Round  86, Train loss: 0.946, Test loss: 1.059, Test accuracy: 84.58
Round  86, Global train loss: 0.946, Global test loss: 0.951, Global test accuracy: 95.68
Round  87, Train loss: 1.257, Test loss: 1.055, Test accuracy: 84.88
Round  87, Global train loss: 1.257, Global test loss: 0.981, Global test accuracy: 92.66
Round  88, Train loss: 1.115, Test loss: 1.057, Test accuracy: 84.64
Round  88, Global train loss: 1.115, Global test loss: 0.966, Global test accuracy: 94.30
Round  89, Train loss: 1.240, Test loss: 1.048, Test accuracy: 85.60
Round  89, Global train loss: 1.240, Global test loss: 0.988, Global test accuracy: 92.32
Round  90, Train loss: 1.268, Test loss: 1.049, Test accuracy: 85.34
Round  90, Global train loss: 1.268, Global test loss: 1.011, Global test accuracy: 89.76
Round  91, Train loss: 1.118, Test loss: 1.056, Test accuracy: 84.80
Round  91, Global train loss: 1.118, Global test loss: 0.983, Global test accuracy: 92.36
Round  92, Train loss: 1.428, Test loss: 1.056, Test accuracy: 84.80
Round  92, Global train loss: 1.428, Global test loss: 1.031, Global test accuracy: 88.10
Round  93, Train loss: 1.416, Test loss: 1.065, Test accuracy: 83.90
Round  93, Global train loss: 1.416, Global test loss: 1.088, Global test accuracy: 81.86
Round  94, Train loss: 1.087, Test loss: 1.072, Test accuracy: 82.96
Round  94, Global train loss: 1.087, Global test loss: 1.003, Global test accuracy: 90.44/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  95, Train loss: 1.146, Test loss: 1.069, Test accuracy: 83.44
Round  95, Global train loss: 1.146, Global test loss: 0.986, Global test accuracy: 92.36
Round  96, Train loss: 1.260, Test loss: 1.084, Test accuracy: 81.68
Round  96, Global train loss: 1.260, Global test loss: 1.049, Global test accuracy: 85.90
Round  97, Train loss: 1.124, Test loss: 1.087, Test accuracy: 81.26
Round  97, Global train loss: 1.124, Global test loss: 0.976, Global test accuracy: 93.10
Round  98, Train loss: 1.090, Test loss: 1.087, Test accuracy: 81.30
Round  98, Global train loss: 1.090, Global test loss: 0.995, Global test accuracy: 91.64
Round  99, Train loss: 1.406, Test loss: 1.076, Test accuracy: 82.58
Round  99, Global train loss: 1.406, Global test loss: 1.056, Global test accuracy: 85.34
Final Round, Train loss: 1.205, Test loss: 1.091, Test accuracy: 81.22
Final Round, Global train loss: 1.205, Global test loss: 1.056, Global test accuracy: 85.34
Average accuracy final 10 rounds: 83.20599999999999 

Average global accuracy final 10 rounds: 89.08600000000001 

605.6146051883698
[0.896050214767456, 1.792100429534912, 2.573585033416748, 3.355069637298584, 4.155241966247559, 4.955414295196533, 5.761332988739014, 6.567251682281494, 7.3856847286224365, 8.204117774963379, 9.108227491378784, 10.01233720779419, 10.779046297073364, 11.545755386352539, 12.30305528640747, 13.060355186462402, 13.816137313842773, 14.571919441223145, 15.432865381240845, 16.293811321258545, 17.08500838279724, 17.876205444335938, 18.64314556121826, 19.410085678100586, 20.170384407043457, 20.930683135986328, 21.70434260368347, 22.478002071380615, 23.248666048049927, 24.01933002471924, 24.82423233985901, 25.62913465499878, 26.571075916290283, 27.513017177581787, 28.312320470809937, 29.111623764038086, 29.888487339019775, 30.665350914001465, 31.44569993019104, 32.226048946380615, 33.001609802246094, 33.77717065811157, 34.58933639526367, 35.40150213241577, 36.17356514930725, 36.94562816619873, 37.729737281799316, 38.5138463973999, 39.29251289367676, 40.07117938995361, 40.849061727523804, 41.626944065093994, 42.46293258666992, 43.29892110824585, 44.06858253479004, 44.83824396133423, 45.6284499168396, 46.41865587234497, 47.22797107696533, 48.03728628158569, 48.9290657043457, 49.82084512710571, 50.60569882392883, 51.39055252075195, 52.26094675064087, 53.131340980529785, 53.886714935302734, 54.642088890075684, 55.41383361816406, 56.18557834625244, 56.968674659729004, 57.751770973205566, 58.52753973007202, 59.30330848693848, 60.092530727386475, 60.88175296783447, 61.66588258743286, 62.45001220703125, 63.23813009262085, 64.02624797821045, 64.80529403686523, 65.58434009552002, 66.51394009590149, 67.44354009628296, 68.20617294311523, 68.96880578994751, 69.72233486175537, 70.47586393356323, 71.22292184829712, 71.969979763031, 72.93456625938416, 73.8991527557373, 74.67486214637756, 75.45057153701782, 76.37881803512573, 77.30706453323364, 78.08028745651245, 78.85351037979126, 79.6324725151062, 80.41143465042114, 81.18825054168701, 81.96506643295288, 82.74991774559021, 83.53476905822754, 84.30957984924316, 85.08439064025879, 85.86377787590027, 86.64316511154175, 87.3988950252533, 88.15462493896484, 88.90258002281189, 89.65053510665894, 90.392165184021, 91.13379526138306, 91.89816975593567, 92.66254425048828, 93.43565225601196, 94.20876026153564, 95.0789246559143, 95.94908905029297, 96.89874243736267, 97.84839582443237, 98.63404417037964, 99.4196925163269, 100.23901534080505, 101.0583381652832, 101.86859488487244, 102.67885160446167, 103.46368980407715, 104.24852800369263, 105.04638504981995, 105.84424209594727, 106.72987580299377, 107.61550951004028, 108.38187265396118, 109.14823579788208, 109.9202835559845, 110.69233131408691, 111.45140314102173, 112.21047496795654, 112.95099186897278, 113.69150876998901, 114.68369770050049, 115.67588663101196, 116.44162487983704, 117.20736312866211, 117.97117233276367, 118.73498153686523, 119.51953840255737, 120.30409526824951, 121.07197141647339, 121.83984756469727, 122.66266202926636, 123.48547649383545, 124.29781150817871, 125.11014652252197, 125.88032531738281, 126.65050411224365, 127.41497898101807, 128.17945384979248, 128.95010423660278, 129.7207546234131, 130.5218541622162, 131.3229537010193, 132.0740044116974, 132.8250551223755, 133.5873258113861, 134.34959650039673, 135.12540125846863, 135.90120601654053, 136.6730513572693, 137.44489669799805, 138.20358204841614, 138.96226739883423, 139.71392393112183, 140.46558046340942, 141.22068548202515, 141.97579050064087, 142.73894548416138, 143.50210046768188, 144.27006149291992, 145.03802251815796, 145.95844912528992, 146.87887573242188, 147.6290102005005, 148.3791446685791, 149.15530610084534, 149.93146753311157, 150.76386046409607, 151.59625339508057, 152.39919018745422, 153.20212697982788, 153.98867654800415, 154.77522611618042, 155.5613284111023, 156.34743070602417, 157.11503648757935, 157.88264226913452, 158.6463131904602, 159.4099841117859, 160.97368931770325, 162.5373945236206]
[44.68, 44.68, 59.52, 59.52, 74.54, 74.54, 80.54, 80.54, 81.8, 81.8, 82.84, 82.84, 82.94, 82.94, 83.5, 83.5, 90.8, 90.8, 90.38, 90.38, 93.48, 93.48, 93.38, 93.38, 93.78, 93.78, 94.16, 94.16, 94.18, 94.18, 94.82, 94.82, 94.74, 94.74, 94.44, 94.44, 94.4, 94.4, 94.16, 94.16, 94.22, 94.22, 94.64, 94.64, 94.22, 94.22, 93.92, 93.92, 93.8, 93.8, 93.58, 93.58, 93.84, 93.84, 93.86, 93.86, 94.1, 94.1, 93.8, 93.8, 93.38, 93.38, 93.32, 93.32, 93.22, 93.22, 92.96, 92.96, 92.76, 92.76, 92.96, 92.96, 92.36, 92.36, 93.02, 93.02, 92.14, 92.14, 91.9, 91.9, 92.18, 92.18, 91.88, 91.88, 91.7, 91.7, 91.6, 91.6, 91.0, 91.0, 90.66, 90.66, 91.06, 91.06, 90.54, 90.54, 90.26, 90.26, 89.7, 89.7, 89.68, 89.68, 89.02, 89.02, 88.98, 88.98, 89.36, 89.36, 89.36, 89.36, 88.5, 88.5, 88.62, 88.62, 88.64, 88.64, 88.72, 88.72, 88.32, 88.32, 88.34, 88.34, 88.44, 88.44, 88.54, 88.54, 88.84, 88.84, 88.74, 88.74, 89.02, 89.02, 88.76, 88.76, 88.26, 88.26, 88.18, 88.18, 87.54, 87.54, 87.16, 87.16, 86.84, 86.84, 86.36, 86.36, 86.04, 86.04, 85.8, 85.8, 85.42, 85.42, 84.96, 84.96, 85.66, 85.66, 84.72, 84.72, 84.8, 84.8, 85.64, 85.64, 85.54, 85.54, 84.82, 84.82, 84.82, 84.82, 84.64, 84.64, 84.56, 84.56, 84.58, 84.58, 84.88, 84.88, 84.64, 84.64, 85.6, 85.6, 85.34, 85.34, 84.8, 84.8, 84.8, 84.8, 83.9, 83.9, 82.96, 82.96, 83.44, 83.44, 81.68, 81.68, 81.26, 81.26, 81.3, 81.3, 82.58, 82.58, 81.22, 81.22]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.6 , level_n_lowerb:0.8  

   Client 4, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
prox
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.603, Test loss: 1.592, Test accuracy: 59.14
Round   0, Global train loss: 1.603, Global test loss: 1.593, Global test accuracy: 66.10
Round   1, Train loss: 1.605, Test loss: 1.582, Test accuracy: 65.52
Round   1, Global train loss: 1.605, Global test loss: 1.582, Global test accuracy: 69.20
Round   2, Train loss: 1.549, Test loss: 1.501, Test accuracy: 70.68
Round   2, Global train loss: 1.549, Global test loss: 1.486, Global test accuracy: 77.50
Round   3, Train loss: 1.492, Test loss: 1.417, Test accuracy: 72.00
Round   3, Global train loss: 1.492, Global test loss: 1.331, Global test accuracy: 88.84
Round   4, Train loss: 1.275, Test loss: 1.299, Test accuracy: 77.10
Round   4, Global train loss: 1.275, Global test loss: 1.065, Global test accuracy: 94.76
Round   5, Train loss: 1.391, Test loss: 1.233, Test accuracy: 79.90
Round   5, Global train loss: 1.391, Global test loss: 1.042, Global test accuracy: 94.64
Round   6, Train loss: 1.345, Test loss: 1.226, Test accuracy: 79.52
Round   6, Global train loss: 1.345, Global test loss: 1.010, Global test accuracy: 95.00
Round   7, Train loss: 1.390, Test loss: 1.222, Test accuracy: 79.18
Round   7, Global train loss: 1.390, Global test loss: 1.010, Global test accuracy: 95.04
Round   8, Train loss: 1.197, Test loss: 1.125, Test accuracy: 82.12
Round   8, Global train loss: 1.197, Global test loss: 0.978, Global test accuracy: 95.70
Round   9, Train loss: 1.358, Test loss: 1.094, Test accuracy: 85.74
Round   9, Global train loss: 1.358, Global test loss: 1.001, Global test accuracy: 94.54
Round  10, Train loss: 1.352, Test loss: 1.038, Test accuracy: 89.80
Round  10, Global train loss: 1.352, Global test loss: 0.990, Global test accuracy: 94.20
Round  11, Train loss: 1.177, Test loss: 1.028, Test accuracy: 90.46
Round  11, Global train loss: 1.177, Global test loss: 0.966, Global test accuracy: 95.92
Round  12, Train loss: 1.139, Test loss: 1.022, Test accuracy: 91.12
Round  12, Global train loss: 1.139, Global test loss: 0.961, Global test accuracy: 96.24
Round  13, Train loss: 1.178, Test loss: 1.022, Test accuracy: 90.78
Round  13, Global train loss: 1.178, Global test loss: 0.963, Global test accuracy: 95.64
Round  14, Train loss: 1.333, Test loss: 1.022, Test accuracy: 90.04
Round  14, Global train loss: 1.333, Global test loss: 0.967, Global test accuracy: 95.56
Round  15, Train loss: 1.341, Test loss: 1.024, Test accuracy: 89.16
Round  15, Global train loss: 1.341, Global test loss: 0.971, Global test accuracy: 94.74
Round  16, Train loss: 1.362, Test loss: 1.025, Test accuracy: 88.98
Round  16, Global train loss: 1.362, Global test loss: 1.023, Global test accuracy: 92.50
Round  17, Train loss: 1.335, Test loss: 1.038, Test accuracy: 87.06
Round  17, Global train loss: 1.335, Global test loss: 0.976, Global test accuracy: 94.68
Round  18, Train loss: 1.327, Test loss: 1.035, Test accuracy: 87.62
Round  18, Global train loss: 1.327, Global test loss: 0.973, Global test accuracy: 94.96
Round  19, Train loss: 1.319, Test loss: 1.033, Test accuracy: 87.80
Round  19, Global train loss: 1.319, Global test loss: 0.968, Global test accuracy: 95.46
Round  20, Train loss: 1.125, Test loss: 1.035, Test accuracy: 87.64
Round  20, Global train loss: 1.125, Global test loss: 0.956, Global test accuracy: 96.00
Round  21, Train loss: 1.369, Test loss: 1.017, Test accuracy: 89.56
Round  21, Global train loss: 1.369, Global test loss: 0.982, Global test accuracy: 93.58
Round  22, Train loss: 1.161, Test loss: 1.024, Test accuracy: 88.74
Round  22, Global train loss: 1.161, Global test loss: 0.958, Global test accuracy: 95.50
Round  23, Train loss: 1.515, Test loss: 1.025, Test accuracy: 88.86
Round  23, Global train loss: 1.515, Global test loss: 1.018, Global test accuracy: 91.28
Round  24, Train loss: 1.496, Test loss: 1.027, Test accuracy: 88.76
Round  24, Global train loss: 1.496, Global test loss: 1.043, Global test accuracy: 89.66
Round  25, Train loss: 1.345, Test loss: 1.031, Test accuracy: 88.48
Round  25, Global train loss: 1.345, Global test loss: 0.995, Global test accuracy: 92.52
Round  26, Train loss: 1.315, Test loss: 1.041, Test accuracy: 87.08
Round  26, Global train loss: 1.315, Global test loss: 0.997, Global test accuracy: 92.64
Round  27, Train loss: 1.339, Test loss: 1.043, Test accuracy: 86.76
Round  27, Global train loss: 1.339, Global test loss: 0.984, Global test accuracy: 93.24
Round  28, Train loss: 1.124, Test loss: 1.047, Test accuracy: 86.20
Round  28, Global train loss: 1.124, Global test loss: 0.965, Global test accuracy: 95.20
Round  29, Train loss: 1.118, Test loss: 1.048, Test accuracy: 86.06
Round  29, Global train loss: 1.118, Global test loss: 0.956, Global test accuracy: 95.56
Round  30, Train loss: 0.952, Test loss: 1.046, Test accuracy: 86.20
Round  30, Global train loss: 0.952, Global test loss: 0.948, Global test accuracy: 96.16
Round  31, Train loss: 1.326, Test loss: 1.039, Test accuracy: 87.12
Round  31, Global train loss: 1.326, Global test loss: 0.973, Global test accuracy: 94.42
Round  32, Train loss: 1.506, Test loss: 1.038, Test accuracy: 87.04
Round  32, Global train loss: 1.506, Global test loss: 1.072, Global test accuracy: 86.22
Round  33, Train loss: 1.142, Test loss: 1.040, Test accuracy: 86.94
Round  33, Global train loss: 1.142, Global test loss: 0.963, Global test accuracy: 94.98
Round  34, Train loss: 1.491, Test loss: 1.042, Test accuracy: 86.40
Round  34, Global train loss: 1.491, Global test loss: 1.045, Global test accuracy: 87.38
Round  35, Train loss: 1.110, Test loss: 1.035, Test accuracy: 87.24
Round  35, Global train loss: 1.110, Global test loss: 0.961, Global test accuracy: 95.06
Round  36, Train loss: 1.108, Test loss: 1.039, Test accuracy: 86.64
Round  36, Global train loss: 1.108, Global test loss: 0.959, Global test accuracy: 95.32
Round  37, Train loss: 1.135, Test loss: 1.037, Test accuracy: 86.84
Round  37, Global train loss: 1.135, Global test loss: 0.952, Global test accuracy: 95.96
Round  38, Train loss: 0.947, Test loss: 1.037, Test accuracy: 86.82
Round  38, Global train loss: 0.947, Global test loss: 0.946, Global test accuracy: 96.34
Round  39, Train loss: 1.133, Test loss: 1.038, Test accuracy: 86.74
Round  39, Global train loss: 1.133, Global test loss: 0.958, Global test accuracy: 95.66
Round  40, Train loss: 1.103, Test loss: 1.040, Test accuracy: 86.62
Round  40, Global train loss: 1.103, Global test loss: 0.956, Global test accuracy: 95.34
Round  41, Train loss: 1.110, Test loss: 1.032, Test accuracy: 87.44
Round  41, Global train loss: 1.110, Global test loss: 0.951, Global test accuracy: 95.76
Round  42, Train loss: 1.125, Test loss: 1.034, Test accuracy: 87.06
Round  42, Global train loss: 1.125, Global test loss: 0.961, Global test accuracy: 95.14
Round  43, Train loss: 1.482, Test loss: 1.039, Test accuracy: 86.74
Round  43, Global train loss: 1.482, Global test loss: 1.079, Global test accuracy: 82.48
Round  44, Train loss: 1.107, Test loss: 1.037, Test accuracy: 86.82
Round  44, Global train loss: 1.107, Global test loss: 0.961, Global test accuracy: 95.24
Round  45, Train loss: 1.457, Test loss: 1.040, Test accuracy: 86.62
Round  45, Global train loss: 1.457, Global test loss: 1.117, Global test accuracy: 79.12
Round  46, Train loss: 0.950, Test loss: 1.042, Test accuracy: 86.48
Round  46, Global train loss: 0.950, Global test loss: 0.948, Global test accuracy: 96.18
Round  47, Train loss: 1.090, Test loss: 1.043, Test accuracy: 86.18
Round  47, Global train loss: 1.090, Global test loss: 0.956, Global test accuracy: 95.58
Round  48, Train loss: 1.301, Test loss: 1.043, Test accuracy: 86.16
Round  48, Global train loss: 1.301, Global test loss: 0.967, Global test accuracy: 94.52
Round  49, Train loss: 1.464, Test loss: 1.054, Test accuracy: 84.84
Round  49, Global train loss: 1.464, Global test loss: 1.107, Global test accuracy: 79.28
Round  50, Train loss: 1.258, Test loss: 1.052, Test accuracy: 85.42
Round  50, Global train loss: 1.258, Global test loss: 1.025, Global test accuracy: 89.24
Round  51, Train loss: 0.943, Test loss: 1.053, Test accuracy: 85.36
Round  51, Global train loss: 0.943, Global test loss: 0.951, Global test accuracy: 95.98
Round  52, Train loss: 1.457, Test loss: 1.057, Test accuracy: 85.06
Round  52, Global train loss: 1.457, Global test loss: 1.016, Global test accuracy: 90.34
Round  53, Train loss: 1.098, Test loss: 1.058, Test accuracy: 84.78
Round  53, Global train loss: 1.098, Global test loss: 0.960, Global test accuracy: 95.58
Round  54, Train loss: 1.287, Test loss: 1.058, Test accuracy: 84.98
Round  54, Global train loss: 1.287, Global test loss: 0.987, Global test accuracy: 93.40
Round  55, Train loss: 1.270, Test loss: 1.066, Test accuracy: 84.22
Round  55, Global train loss: 1.270, Global test loss: 0.996, Global test accuracy: 92.10
Round  56, Train loss: 1.094, Test loss: 1.071, Test accuracy: 83.56
Round  56, Global train loss: 1.094, Global test loss: 0.959, Global test accuracy: 95.46
Round  57, Train loss: 1.117, Test loss: 1.063, Test accuracy: 84.30
Round  57, Global train loss: 1.117, Global test loss: 0.961, Global test accuracy: 95.02
Round  58, Train loss: 1.281, Test loss: 1.068, Test accuracy: 83.74
Round  58, Global train loss: 1.281, Global test loss: 0.992, Global test accuracy: 91.92
Round  59, Train loss: 1.428, Test loss: 1.072, Test accuracy: 83.16
Round  59, Global train loss: 1.428, Global test loss: 1.123, Global test accuracy: 78.78
Round  60, Train loss: 1.435, Test loss: 1.076, Test accuracy: 82.80
Round  60, Global train loss: 1.435, Global test loss: 1.067, Global test accuracy: 84.90
Round  61, Train loss: 1.421, Test loss: 1.066, Test accuracy: 83.92
Round  61, Global train loss: 1.421, Global test loss: 1.055, Global test accuracy: 85.76
Round  62, Train loss: 1.275, Test loss: 1.077, Test accuracy: 82.76
Round  62, Global train loss: 1.275, Global test loss: 1.018, Global test accuracy: 89.50
Round  63, Train loss: 1.111, Test loss: 1.078, Test accuracy: 82.60
Round  63, Global train loss: 1.111, Global test loss: 0.986, Global test accuracy: 92.86
Round  64, Train loss: 1.272, Test loss: 1.076, Test accuracy: 82.92
Round  64, Global train loss: 1.272, Global test loss: 1.020, Global test accuracy: 89.30
Round  65, Train loss: 1.265, Test loss: 1.072, Test accuracy: 83.50
Round  65, Global train loss: 1.265, Global test loss: 1.046, Global test accuracy: 87.26
Round  66, Train loss: 1.390, Test loss: 1.074, Test accuracy: 83.44
Round  66, Global train loss: 1.390, Global test loss: 1.110, Global test accuracy: 79.50
Round  67, Train loss: 1.082, Test loss: 1.089, Test accuracy: 81.84
Round  67, Global train loss: 1.082, Global test loss: 0.987, Global test accuracy: 93.50
Round  68, Train loss: 1.230, Test loss: 1.085, Test accuracy: 82.22
Round  68, Global train loss: 1.230, Global test loss: 1.025, Global test accuracy: 89.48
Round  69, Train loss: 1.092, Test loss: 1.084, Test accuracy: 82.60
Round  69, Global train loss: 1.092, Global test loss: 0.973, Global test accuracy: 93.64
Round  70, Train loss: 1.242, Test loss: 1.082, Test accuracy: 82.62
Round  70, Global train loss: 1.242, Global test loss: 1.008, Global test accuracy: 91.12
Round  71, Train loss: 0.939, Test loss: 1.082, Test accuracy: 82.68
Round  71, Global train loss: 0.939, Global test loss: 0.953, Global test accuracy: 95.60
Round  72, Train loss: 1.075, Test loss: 1.086, Test accuracy: 82.06
Round  72, Global train loss: 1.075, Global test loss: 0.963, Global test accuracy: 94.80
Round  73, Train loss: 1.240, Test loss: 1.081, Test accuracy: 82.84
Round  73, Global train loss: 1.240, Global test loss: 0.989, Global test accuracy: 92.52
Round  74, Train loss: 1.268, Test loss: 1.082, Test accuracy: 82.44
Round  74, Global train loss: 1.268, Global test loss: 1.028, Global test accuracy: 88.22
Round  75, Train loss: 1.386, Test loss: 1.100, Test accuracy: 80.50
Round  75, Global train loss: 1.386, Global test loss: 1.130, Global test accuracy: 77.90
Round  76, Train loss: 1.087, Test loss: 1.098, Test accuracy: 80.94
Round  76, Global train loss: 1.087, Global test loss: 0.998, Global test accuracy: 91.84
Round  77, Train loss: 1.205, Test loss: 1.096, Test accuracy: 81.18
Round  77, Global train loss: 1.205, Global test loss: 1.037, Global test accuracy: 87.80
Round  78, Train loss: 1.241, Test loss: 1.103, Test accuracy: 80.30
Round  78, Global train loss: 1.241, Global test loss: 1.031, Global test accuracy: 88.52
Round  79, Train loss: 1.377, Test loss: 1.101, Test accuracy: 80.72
Round  79, Global train loss: 1.377, Global test loss: 1.109, Global test accuracy: 80.80
Round  80, Train loss: 0.939, Test loss: 1.102, Test accuracy: 80.54
Round  80, Global train loss: 0.939, Global test loss: 0.962, Global test accuracy: 94.88
Round  81, Train loss: 1.102, Test loss: 1.106, Test accuracy: 80.04
Round  81, Global train loss: 1.102, Global test loss: 0.981, Global test accuracy: 93.18
Round  82, Train loss: 1.216, Test loss: 1.111, Test accuracy: 79.38
Round  82, Global train loss: 1.216, Global test loss: 1.050, Global test accuracy: 86.70
Round  83, Train loss: 1.091, Test loss: 1.111, Test accuracy: 79.62
Round  83, Global train loss: 1.091, Global test loss: 0.991, Global test accuracy: 92.18
Round  84, Train loss: 1.078, Test loss: 1.116, Test accuracy: 78.90
Round  84, Global train loss: 1.078, Global test loss: 0.991, Global test accuracy: 91.78
Round  85, Train loss: 1.225, Test loss: 1.111, Test accuracy: 79.36
Round  85, Global train loss: 1.225, Global test loss: 1.034, Global test accuracy: 88.14
Round  86, Train loss: 1.347, Test loss: 1.118, Test accuracy: 78.64
Round  86, Global train loss: 1.347, Global test loss: 1.141, Global test accuracy: 77.46
Round  87, Train loss: 1.215, Test loss: 1.116, Test accuracy: 78.86
Round  87, Global train loss: 1.215, Global test loss: 1.044, Global test accuracy: 86.98
Round  88, Train loss: 1.352, Test loss: 1.118, Test accuracy: 78.66
Round  88, Global train loss: 1.352, Global test loss: 1.237, Global test accuracy: 66.16
Round  89, Train loss: 1.183, Test loss: 1.123, Test accuracy: 77.94
Round  89, Global train loss: 1.183, Global test loss: 1.084, Global test accuracy: 82.70
Round  90, Train loss: 1.336, Test loss: 1.127, Test accuracy: 77.52
Round  90, Global train loss: 1.336, Global test loss: 1.199, Global test accuracy: 70.52
Round  91, Train loss: 1.226, Test loss: 1.147, Test accuracy: 75.56
Round  91, Global train loss: 1.226, Global test loss: 1.104, Global test accuracy: 80.76
Round  92, Train loss: 1.211, Test loss: 1.154, Test accuracy: 74.66
Round  92, Global train loss: 1.211, Global test loss: 1.063, Global test accuracy: 84.94
Round  93, Train loss: 1.044, Test loss: 1.154, Test accuracy: 74.82
Round  93, Global train loss: 1.044, Global test loss: 0.991, Global test accuracy: 92.52
Round  94, Train loss: 1.063, Test loss: 1.143, Test accuracy: 75.82
Round  94, Global train loss: 1.063, Global test loss: 0.994, Global test accuracy: 91.70/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  95, Train loss: 1.073, Test loss: 1.146, Test accuracy: 75.40
Round  95, Global train loss: 1.073, Global test loss: 0.998, Global test accuracy: 91.20
Round  96, Train loss: 1.069, Test loss: 1.142, Test accuracy: 75.82
Round  96, Global train loss: 1.069, Global test loss: 0.997, Global test accuracy: 91.42
Round  97, Train loss: 1.338, Test loss: 1.119, Test accuracy: 78.58
Round  97, Global train loss: 1.338, Global test loss: 1.134, Global test accuracy: 77.30
Round  98, Train loss: 1.221, Test loss: 1.127, Test accuracy: 77.72
Round  98, Global train loss: 1.221, Global test loss: 1.089, Global test accuracy: 81.84
Round  99, Train loss: 1.065, Test loss: 1.141, Test accuracy: 75.98
Round  99, Global train loss: 1.065, Global test loss: 1.004, Global test accuracy: 90.74
Final Round, Train loss: 1.150, Test loss: 1.143, Test accuracy: 75.76
Final Round, Global train loss: 1.150, Global test loss: 1.004, Global test accuracy: 90.74
Average accuracy final 10 rounds: 76.188 

Average global accuracy final 10 rounds: 85.294 

653.8078172206879
[1.1169841289520264, 2.2339682579040527, 3.1287097930908203, 4.023451328277588, 4.912542343139648, 5.801633358001709, 6.8405609130859375, 7.879488468170166, 8.785552024841309, 9.691615581512451, 10.586339235305786, 11.481062889099121, 12.38236379623413, 13.28366470336914, 14.16411828994751, 15.044571876525879, 15.930719137191772, 16.816866397857666, 17.71096682548523, 18.605067253112793, 19.498316287994385, 20.391565322875977, 21.314878940582275, 22.238192558288574, 23.13977026939392, 24.041347980499268, 24.926076650619507, 25.810805320739746, 26.71853494644165, 27.626264572143555, 28.50799798965454, 29.389731407165527, 30.29414439201355, 31.198557376861572, 32.13662648200989, 33.0746955871582, 34.004892349243164, 34.935089111328125, 35.834542989730835, 36.733996868133545, 37.689860582351685, 38.645724296569824, 39.541367053985596, 40.43700981140137, 41.34690737724304, 42.25680494308472, 43.161463499069214, 44.06612205505371, 44.942017793655396, 45.81791353225708, 46.70828557014465, 47.59865760803223, 48.480355978012085, 49.36205434799194, 50.26381850242615, 51.16558265686035, 52.05183291435242, 52.93808317184448, 53.825778007507324, 54.713472843170166, 55.858755111694336, 57.004037380218506, 58.04938054084778, 59.09472370147705, 60.33548665046692, 61.57624959945679, 62.688904762268066, 63.801559925079346, 65.00181555747986, 66.20207118988037, 67.3458640575409, 68.48965692520142, 69.41795802116394, 70.34625911712646, 71.24384498596191, 72.14143085479736, 73.01871252059937, 73.89599418640137, 74.77879190444946, 75.66158962249756, 76.59046936035156, 77.51934909820557, 78.41198348999023, 79.3046178817749, 80.20218420028687, 81.09975051879883, 82.00193643569946, 82.9041223526001, 83.8044285774231, 84.7047348022461, 85.61248660087585, 86.52023839950562, 87.41630744934082, 88.31237649917603, 89.21365737915039, 90.11493825912476, 91.01602077484131, 91.91710329055786, 92.82177710533142, 93.72645092010498, 94.61842370033264, 95.5103964805603, 96.38771104812622, 97.26502561569214, 98.17341589927673, 99.08180618286133, 99.96175289154053, 100.84169960021973, 101.73200845718384, 102.62231731414795, 103.556077003479, 104.48983669281006, 105.40592694282532, 106.32201719284058, 107.2177381515503, 108.11345911026001, 108.98164796829224, 109.84983682632446, 110.72614526748657, 111.60245370864868, 112.46266841888428, 113.32288312911987, 114.21001076698303, 115.09713840484619, 115.99528908729553, 116.89343976974487, 117.83491778373718, 118.77639579772949, 119.66703033447266, 120.55766487121582, 121.44933581352234, 122.34100675582886, 123.24816584587097, 124.15532493591309, 125.05509233474731, 125.95485973358154, 126.83521056175232, 127.7155613899231, 128.58992886543274, 129.46429634094238, 130.3647496700287, 131.265202999115, 132.14113759994507, 133.01707220077515, 133.90530729293823, 134.79354238510132, 135.69017243385315, 136.58680248260498, 137.47749662399292, 138.36819076538086, 139.26662468910217, 140.1650586128235, 141.07866144180298, 141.99226427078247, 142.8971266746521, 143.80198907852173, 144.7023320198059, 145.6026749610901, 146.49444699287415, 147.3862190246582, 148.32239747047424, 149.25857591629028, 150.14126133918762, 151.02394676208496, 151.92980527877808, 152.8356637954712, 153.73133659362793, 154.62700939178467, 155.53270840644836, 156.43840742111206, 157.32970905303955, 158.22101068496704, 159.09024047851562, 159.9594702720642, 160.8697214126587, 161.77997255325317, 162.66237998008728, 163.5447874069214, 164.43793535232544, 165.3310832977295, 166.23225831985474, 167.13343334197998, 167.9954695701599, 168.85750579833984, 169.74002957344055, 170.62255334854126, 171.50910806655884, 172.39566278457642, 173.2900266647339, 174.18439054489136, 175.07627129554749, 175.9681520462036, 176.86051893234253, 177.75288581848145, 178.64434480667114, 179.53580379486084, 180.42455911636353, 181.3133144378662, 182.22223949432373, 183.13116455078125, 184.934805393219, 186.73844623565674]
[59.14, 59.14, 65.52, 65.52, 70.68, 70.68, 72.0, 72.0, 77.1, 77.1, 79.9, 79.9, 79.52, 79.52, 79.18, 79.18, 82.12, 82.12, 85.74, 85.74, 89.8, 89.8, 90.46, 90.46, 91.12, 91.12, 90.78, 90.78, 90.04, 90.04, 89.16, 89.16, 88.98, 88.98, 87.06, 87.06, 87.62, 87.62, 87.8, 87.8, 87.64, 87.64, 89.56, 89.56, 88.74, 88.74, 88.86, 88.86, 88.76, 88.76, 88.48, 88.48, 87.08, 87.08, 86.76, 86.76, 86.2, 86.2, 86.06, 86.06, 86.2, 86.2, 87.12, 87.12, 87.04, 87.04, 86.94, 86.94, 86.4, 86.4, 87.24, 87.24, 86.64, 86.64, 86.84, 86.84, 86.82, 86.82, 86.74, 86.74, 86.62, 86.62, 87.44, 87.44, 87.06, 87.06, 86.74, 86.74, 86.82, 86.82, 86.62, 86.62, 86.48, 86.48, 86.18, 86.18, 86.16, 86.16, 84.84, 84.84, 85.42, 85.42, 85.36, 85.36, 85.06, 85.06, 84.78, 84.78, 84.98, 84.98, 84.22, 84.22, 83.56, 83.56, 84.3, 84.3, 83.74, 83.74, 83.16, 83.16, 82.8, 82.8, 83.92, 83.92, 82.76, 82.76, 82.6, 82.6, 82.92, 82.92, 83.5, 83.5, 83.44, 83.44, 81.84, 81.84, 82.22, 82.22, 82.6, 82.6, 82.62, 82.62, 82.68, 82.68, 82.06, 82.06, 82.84, 82.84, 82.44, 82.44, 80.5, 80.5, 80.94, 80.94, 81.18, 81.18, 80.3, 80.3, 80.72, 80.72, 80.54, 80.54, 80.04, 80.04, 79.38, 79.38, 79.62, 79.62, 78.9, 78.9, 79.36, 79.36, 78.64, 78.64, 78.86, 78.86, 78.66, 78.66, 77.94, 77.94, 77.52, 77.52, 75.56, 75.56, 74.66, 74.66, 74.82, 74.82, 75.82, 75.82, 75.4, 75.4, 75.82, 75.82, 78.58, 78.58, 77.72, 77.72, 75.98, 75.98, 75.76, 75.76]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.6 , level_n_lowerb:0.8  

   Client 3, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Traceback (most recent call last):
  File "main_fedpac_co_teaching.py", line 250, in <module>
    local.filter_data(net=net_local.to(args.device), net2=net_local2.to(args.device), concept_matrix_local = concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1587, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

   Client 3, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550021 (local), 549696 (global); Percentage 99.94 (549696/550021)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 1.621, Test loss: 1.593, Test accuracy: 36.68
Round   0, Global train loss: 1.621, Global test loss: 1.593, Global test accuracy: 36.96
Round   1, Train loss: 1.594, Test loss: 1.562, Test accuracy: 46.90
Round   1, Global train loss: 1.594, Global test loss: 1.561, Global test accuracy: 46.34
Round   2, Train loss: 1.573, Test loss: 1.513, Test accuracy: 77.32
Round   2, Global train loss: 1.573, Global test loss: 1.511, Global test accuracy: 76.62
Round   3, Train loss: 1.495, Test loss: 1.374, Test accuracy: 91.46
Round   3, Global train loss: 1.495, Global test loss: 1.358, Global test accuracy: 91.66
Round   4, Train loss: 1.467, Test loss: 1.276, Test accuracy: 93.42
Round   4, Global train loss: 1.467, Global test loss: 1.255, Global test accuracy: 93.92
Round   5, Train loss: 1.415, Test loss: 1.214, Test accuracy: 93.40
Round   5, Global train loss: 1.415, Global test loss: 1.175, Global test accuracy: 93.68
Round   6, Train loss: 1.551, Test loss: 1.225, Test accuracy: 93.94
Round   6, Global train loss: 1.551, Global test loss: 1.194, Global test accuracy: 94.72
Round   7, Train loss: 1.391, Test loss: 1.198, Test accuracy: 93.76
Round   7, Global train loss: 1.391, Global test loss: 1.132, Global test accuracy: 93.46
Round   8, Train loss: 1.109, Test loss: 1.089, Test accuracy: 92.92
Round   8, Global train loss: 1.109, Global test loss: 1.027, Global test accuracy: 92.32
Round   9, Train loss: 1.438, Test loss: 1.120, Test accuracy: 91.22
Round   9, Global train loss: 1.438, Global test loss: 1.154, Global test accuracy: 91.20
Round  10, Train loss: 1.427, Test loss: 1.117, Test accuracy: 91.80
Round  10, Global train loss: 1.427, Global test loss: 1.104, Global test accuracy: 95.40
Round  11, Train loss: 1.372, Test loss: 1.126, Test accuracy: 92.42
Round  11, Global train loss: 1.372, Global test loss: 1.070, Global test accuracy: 96.36
Round  12, Train loss: 1.407, Test loss: 1.131, Test accuracy: 91.70
Round  12, Global train loss: 1.407, Global test loss: 1.130, Global test accuracy: 92.36
Round  13, Train loss: 1.074, Test loss: 1.080, Test accuracy: 92.44
Round  13, Global train loss: 1.074, Global test loss: 1.005, Global test accuracy: 94.52
Round  14, Train loss: 1.553, Test loss: 1.128, Test accuracy: 91.60
Round  14, Global train loss: 1.553, Global test loss: 1.150, Global test accuracy: 93.48
Round  15, Train loss: 1.409, Test loss: 1.140, Test accuracy: 91.20
Round  15, Global train loss: 1.409, Global test loss: 1.119, Global test accuracy: 94.62
Round  16, Train loss: 1.367, Test loss: 1.150, Test accuracy: 90.64
Round  16, Global train loss: 1.367, Global test loss: 1.129, Global test accuracy: 94.30
Round  17, Train loss: 1.365, Test loss: 1.112, Test accuracy: 91.74
Round  17, Global train loss: 1.365, Global test loss: 1.058, Global test accuracy: 96.14
Round  18, Train loss: 1.540, Test loss: 1.156, Test accuracy: 90.16
Round  18, Global train loss: 1.540, Global test loss: 1.174, Global test accuracy: 95.12
Round  19, Train loss: 1.550, Test loss: 1.170, Test accuracy: 89.72
Round  19, Global train loss: 1.550, Global test loss: 1.231, Global test accuracy: 95.46
Round  20, Train loss: 1.404, Test loss: 1.144, Test accuracy: 89.84
Round  20, Global train loss: 1.404, Global test loss: 1.118, Global test accuracy: 93.76
Round  21, Train loss: 1.186, Test loss: 1.102, Test accuracy: 90.72
Round  21, Global train loss: 1.186, Global test loss: 1.018, Global test accuracy: 96.32
Round  22, Train loss: 1.352, Test loss: 1.113, Test accuracy: 90.72
Round  22, Global train loss: 1.352, Global test loss: 1.042, Global test accuracy: 96.20
Round  23, Train loss: 1.538, Test loss: 1.159, Test accuracy: 89.24
Round  23, Global train loss: 1.538, Global test loss: 1.229, Global test accuracy: 85.14
Round  24, Train loss: 1.384, Test loss: 1.131, Test accuracy: 89.94
Round  24, Global train loss: 1.384, Global test loss: 1.112, Global test accuracy: 95.62
Round  25, Train loss: 1.153, Test loss: 1.089, Test accuracy: 90.78
Round  25, Global train loss: 1.153, Global test loss: 0.990, Global test accuracy: 96.34
Round  26, Train loss: 1.389, Test loss: 1.105, Test accuracy: 90.42
Round  26, Global train loss: 1.389, Global test loss: 1.098, Global test accuracy: 95.02
Round  27, Train loss: 1.330, Test loss: 1.113, Test accuracy: 89.76
Round  27, Global train loss: 1.330, Global test loss: 1.037, Global test accuracy: 94.98
Round  28, Train loss: 1.543, Test loss: 1.163, Test accuracy: 87.96
Round  28, Global train loss: 1.543, Global test loss: 1.221, Global test accuracy: 91.84
Round  29, Train loss: 1.394, Test loss: 1.139, Test accuracy: 88.24
Round  29, Global train loss: 1.394, Global test loss: 1.110, Global test accuracy: 93.68
Round  30, Train loss: 1.339, Test loss: 1.131, Test accuracy: 88.92
Round  30, Global train loss: 1.339, Global test loss: 1.054, Global test accuracy: 95.92
Round  31, Train loss: 1.332, Test loss: 1.127, Test accuracy: 89.16
Round  31, Global train loss: 1.332, Global test loss: 1.066, Global test accuracy: 96.30
Round  32, Train loss: 1.203, Test loss: 1.087, Test accuracy: 90.50
Round  32, Global train loss: 1.203, Global test loss: 1.025, Global test accuracy: 96.34
Round  33, Train loss: 1.331, Test loss: 1.114, Test accuracy: 89.42
Round  33, Global train loss: 1.331, Global test loss: 1.038, Global test accuracy: 95.88
Round  34, Train loss: 1.329, Test loss: 1.114, Test accuracy: 89.66
Round  34, Global train loss: 1.329, Global test loss: 1.074, Global test accuracy: 95.18
Round  35, Train loss: 1.180, Test loss: 1.080, Test accuracy: 90.50
Round  35, Global train loss: 1.180, Global test loss: 0.999, Global test accuracy: 95.42
Round  36, Train loss: 1.364, Test loss: 1.118, Test accuracy: 89.12
Round  36, Global train loss: 1.364, Global test loss: 1.100, Global test accuracy: 94.42
Round  37, Train loss: 1.321, Test loss: 1.126, Test accuracy: 88.66
Round  37, Global train loss: 1.321, Global test loss: 1.050, Global test accuracy: 95.08
Round  38, Train loss: 1.173, Test loss: 1.109, Test accuracy: 88.54
Round  38, Global train loss: 1.173, Global test loss: 1.022, Global test accuracy: 94.08
Round  39, Train loss: 0.973, Test loss: 1.058, Test accuracy: 91.10
Round  39, Global train loss: 0.973, Global test loss: 0.963, Global test accuracy: 96.10
Round  40, Train loss: 1.160, Test loss: 1.075, Test accuracy: 90.02
Round  40, Global train loss: 1.160, Global test loss: 0.999, Global test accuracy: 94.94
Round  41, Train loss: 1.186, Test loss: 1.075, Test accuracy: 90.02
Round  41, Global train loss: 1.186, Global test loss: 1.001, Global test accuracy: 95.50
Round  42, Train loss: 1.127, Test loss: 1.081, Test accuracy: 89.96
Round  42, Global train loss: 1.127, Global test loss: 0.980, Global test accuracy: 96.34
Round  43, Train loss: 1.330, Test loss: 1.107, Test accuracy: 89.08
Round  43, Global train loss: 1.330, Global test loss: 1.059, Global test accuracy: 96.18
Round  44, Train loss: 1.497, Test loss: 1.204, Test accuracy: 81.16
Round  44, Global train loss: 1.497, Global test loss: 1.277, Global test accuracy: 81.32
Round  45, Train loss: 1.325, Test loss: 1.156, Test accuracy: 85.56
Round  45, Global train loss: 1.325, Global test loss: 1.164, Global test accuracy: 85.58
Round  46, Train loss: 1.151, Test loss: 1.109, Test accuracy: 87.66
Round  46, Global train loss: 1.151, Global test loss: 1.022, Global test accuracy: 94.16
Round  47, Train loss: 1.134, Test loss: 1.085, Test accuracy: 88.84
Round  47, Global train loss: 1.134, Global test loss: 0.998, Global test accuracy: 94.94
Round  48, Train loss: 1.341, Test loss: 1.127, Test accuracy: 85.96
Round  48, Global train loss: 1.341, Global test loss: 1.104, Global test accuracy: 90.82
Round  49, Train loss: 1.337, Test loss: 1.154, Test accuracy: 83.94
Round  49, Global train loss: 1.337, Global test loss: 1.192, Global test accuracy: 80.92
Round  50, Train loss: 1.291, Test loss: 1.155, Test accuracy: 83.48
Round  50, Global train loss: 1.291, Global test loss: 1.124, Global test accuracy: 89.50
Round  51, Train loss: 1.133, Test loss: 1.095, Test accuracy: 87.82
Round  51, Global train loss: 1.133, Global test loss: 1.005, Global test accuracy: 94.08
Round  52, Train loss: 1.148, Test loss: 1.072, Test accuracy: 89.76
Round  52, Global train loss: 1.148, Global test loss: 1.001, Global test accuracy: 94.56
Round  53, Train loss: 1.298, Test loss: 1.153, Test accuracy: 82.08
Round  53, Global train loss: 1.298, Global test loss: 1.108, Global test accuracy: 87.82
Round  54, Train loss: 1.299, Test loss: 1.162, Test accuracy: 81.94
Round  54, Global train loss: 1.299, Global test loss: 1.140, Global test accuracy: 85.60
Round  55, Train loss: 1.448, Test loss: 1.229, Test accuracy: 74.52
Round  55, Global train loss: 1.448, Global test loss: 1.258, Global test accuracy: 79.62
Round  56, Train loss: 1.149, Test loss: 1.120, Test accuracy: 84.82
Round  56, Global train loss: 1.149, Global test loss: 1.036, Global test accuracy: 91.64
Round  57, Train loss: 1.271, Test loss: 1.142, Test accuracy: 83.56
Round  57, Global train loss: 1.271, Global test loss: 1.086, Global test accuracy: 89.84
Round  58, Train loss: 1.281, Test loss: 1.142, Test accuracy: 83.18
Round  58, Global train loss: 1.281, Global test loss: 1.101, Global test accuracy: 88.66
Round  59, Train loss: 1.141, Test loss: 1.090, Test accuracy: 87.18
Round  59, Global train loss: 1.141, Global test loss: 1.018, Global test accuracy: 94.06
Round  60, Train loss: 1.440, Test loss: 1.203, Test accuracy: 76.22
Round  60, Global train loss: 1.440, Global test loss: 1.234, Global test accuracy: 78.62
Round  61, Train loss: 1.258, Test loss: 1.149, Test accuracy: 81.80
Round  61, Global train loss: 1.258, Global test loss: 1.079, Global test accuracy: 89.38
Round  62, Train loss: 1.234, Test loss: 1.148, Test accuracy: 81.90
Round  62, Global train loss: 1.234, Global test loss: 1.078, Global test accuracy: 88.80
Round  63, Train loss: 1.269, Test loss: 1.169, Test accuracy: 80.10
Round  63, Global train loss: 1.269, Global test loss: 1.128, Global test accuracy: 87.14
Round  64, Train loss: 1.099, Test loss: 1.113, Test accuracy: 85.08
Round  64, Global train loss: 1.099, Global test loss: 1.035, Global test accuracy: 90.80
Round  65, Train loss: 1.089, Test loss: 1.097, Test accuracy: 86.56
Round  65, Global train loss: 1.089, Global test loss: 1.019, Global test accuracy: 92.64
Round  66, Train loss: 1.241, Test loss: 1.162, Test accuracy: 79.86
Round  66, Global train loss: 1.241, Global test loss: 1.116, Global test accuracy: 88.02
Round  67, Train loss: 1.247, Test loss: 1.204, Test accuracy: 74.74
Round  67, Global train loss: 1.247, Global test loss: 1.202, Global test accuracy: 76.96
Round  68, Train loss: 1.331, Test loss: 1.307, Test accuracy: 62.74
Round  68, Global train loss: 1.331, Global test loss: 1.336, Global test accuracy: 63.22
Round  69, Train loss: 1.237, Test loss: 1.180, Test accuracy: 77.00
Round  69, Global train loss: 1.237, Global test loss: 1.134, Global test accuracy: 82.98
Round  70, Train loss: 1.253, Test loss: 1.190, Test accuracy: 76.44
Round  70, Global train loss: 1.253, Global test loss: 1.186, Global test accuracy: 80.54
Round  71, Train loss: 1.211, Test loss: 1.166, Test accuracy: 78.40
Round  71, Global train loss: 1.211, Global test loss: 1.100, Global test accuracy: 86.30
Round  72, Train loss: 1.218, Test loss: 1.203, Test accuracy: 74.68
Round  72, Global train loss: 1.218, Global test loss: 1.199, Global test accuracy: 76.04
Round  73, Train loss: 1.229, Test loss: 1.182, Test accuracy: 76.88
Round  73, Global train loss: 1.229, Global test loss: 1.139, Global test accuracy: 81.66
Round  74, Train loss: 1.103, Test loss: 1.082, Test accuracy: 86.02
Round  74, Global train loss: 1.103, Global test loss: 1.007, Global test accuracy: 92.38
Round  75, Train loss: 1.211, Test loss: 1.196, Test accuracy: 75.22
Round  75, Global train loss: 1.211, Global test loss: 1.181, Global test accuracy: 80.34
Round  76, Train loss: 1.171, Test loss: 1.210, Test accuracy: 73.76
Round  76, Global train loss: 1.171, Global test loss: 1.187, Global test accuracy: 77.62
Round  77, Train loss: 1.169, Test loss: 1.208, Test accuracy: 73.90
Round  77, Global train loss: 1.169, Global test loss: 1.179, Global test accuracy: 79.36
Round  78, Train loss: 1.194, Test loss: 1.200, Test accuracy: 73.86
Round  78, Global train loss: 1.194, Global test loss: 1.161, Global test accuracy: 78.98
Round  79, Train loss: 1.203, Test loss: 1.187, Test accuracy: 75.92
Round  79, Global train loss: 1.203, Global test loss: 1.169, Global test accuracy: 80.62
Round  80, Train loss: 1.190, Test loss: 1.206, Test accuracy: 73.16
Round  80, Global train loss: 1.190, Global test loss: 1.152, Global test accuracy: 79.72
Round  81, Train loss: 1.159, Test loss: 1.213, Test accuracy: 72.44
Round  81, Global train loss: 1.159, Global test loss: 1.161, Global test accuracy: 78.98
Round  82, Train loss: 1.145, Test loss: 1.231, Test accuracy: 70.74
Round  82, Global train loss: 1.145, Global test loss: 1.221, Global test accuracy: 72.96
Round  83, Train loss: 1.082, Test loss: 1.114, Test accuracy: 82.22
Round  83, Global train loss: 1.082, Global test loss: 1.048, Global test accuracy: 88.24
Round  84, Train loss: 1.185, Test loss: 1.188, Test accuracy: 75.38
Round  84, Global train loss: 1.185, Global test loss: 1.126, Global test accuracy: 81.76
Round  85, Train loss: 1.180, Test loss: 1.193, Test accuracy: 74.38
Round  85, Global train loss: 1.180, Global test loss: 1.150, Global test accuracy: 81.32
Round  86, Train loss: 1.266, Test loss: 1.326, Test accuracy: 59.20
Round  86, Global train loss: 1.266, Global test loss: 1.340, Global test accuracy: 59.64
Round  87, Train loss: 1.085, Test loss: 1.117, Test accuracy: 81.74
Round  87, Global train loss: 1.085, Global test loss: 1.050, Global test accuracy: 88.44
Round  88, Train loss: 1.301, Test loss: 1.347, Test accuracy: 57.10
Round  88, Global train loss: 1.301, Global test loss: 1.395, Global test accuracy: 50.32
Round  89, Train loss: 1.203, Test loss: 1.359, Test accuracy: 55.24
Round  89, Global train loss: 1.203, Global test loss: 1.372, Global test accuracy: 54.36
Round  90, Train loss: 1.172, Test loss: 1.287, Test accuracy: 63.98
Round  90, Global train loss: 1.172, Global test loss: 1.324, Global test accuracy: 57.06
Round  91, Train loss: 1.063, Test loss: 1.094, Test accuracy: 84.14
Round  91, Global train loss: 1.063, Global test loss: 1.027, Global test accuracy: 89.76/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  92, Train loss: 1.074, Test loss: 1.084, Test accuracy: 84.54
Round  92, Global train loss: 1.074, Global test loss: 1.023, Global test accuracy: 90.44
Round  93, Train loss: 1.268, Test loss: 1.369, Test accuracy: 54.44
Round  93, Global train loss: 1.268, Global test loss: 1.413, Global test accuracy: 47.66
Round  94, Train loss: 1.074, Test loss: 1.141, Test accuracy: 79.16
Round  94, Global train loss: 1.074, Global test loss: 1.069, Global test accuracy: 86.02
Round  95, Train loss: 1.168, Test loss: 1.205, Test accuracy: 72.68
Round  95, Global train loss: 1.168, Global test loss: 1.182, Global test accuracy: 76.84
Round  96, Train loss: 1.039, Test loss: 1.131, Test accuracy: 80.54
Round  96, Global train loss: 1.039, Global test loss: 1.068, Global test accuracy: 85.66
Round  97, Train loss: 1.138, Test loss: 1.164, Test accuracy: 77.02
Round  97, Global train loss: 1.138, Global test loss: 1.131, Global test accuracy: 82.70
Round  98, Train loss: 1.055, Test loss: 1.116, Test accuracy: 81.80
Round  98, Global train loss: 1.055, Global test loss: 1.061, Global test accuracy: 86.26
Round  99, Train loss: 1.045, Test loss: 1.100, Test accuracy: 83.16
Round  99, Global train loss: 1.045, Global test loss: 1.035, Global test accuracy: 89.48
Final Round, Train loss: 1.141, Test loss: 1.107, Test accuracy: 82.38
Final Round, Global train loss: 1.141, Global test loss: 1.035, Global test accuracy: 89.48
Average accuracy final 10 rounds: 76.146
570.2873976230621
[1.1428406238555908, 2.0741472244262695, 2.9817943572998047, 3.9598515033721924, 4.891557455062866, 5.802964687347412, 6.7308030128479, 7.651374340057373, 8.587464094161987, 9.524759769439697, 10.449840307235718, 11.359638690948486, 12.267538785934448, 13.189813375473022, 14.127219200134277, 15.054776430130005, 15.968856811523438, 16.897540807724, 17.840888738632202, 18.769789695739746, 19.699293851852417, 20.608144521713257, 22.043424129486084, 23.687886238098145, 25.365710020065308, 26.993463039398193, 28.65576672554016, 30.313693046569824, 31.94775104522705, 33.21944308280945, 34.553147315979004, 35.890589475631714, 37.20795464515686, 38.45220184326172, 39.94088339805603, 41.3312771320343, 42.69224715232849, 44.06226897239685, 44.98476839065552, 45.928624868392944, 46.876044034957886, 47.794238567352295, 48.72199869155884, 49.64120078086853, 50.56108331680298, 51.48168325424194, 52.39979338645935, 53.316896200180054, 54.24988412857056, 55.17975378036499, 56.11612606048584, 57.0513973236084, 57.98125433921814, 58.913657426834106, 59.845707654953, 60.764731884002686, 61.69403600692749, 62.62187314033508, 63.54285955429077, 64.45060300827026, 65.35675954818726, 66.2734763622284, 67.17680668830872, 68.09098148345947, 69.00336861610413, 69.93579435348511, 70.85549855232239, 71.78537559509277, 72.7072856426239, 73.63161087036133, 74.56552624702454, 75.5094633102417, 76.45076417922974, 77.38210868835449, 78.31276774406433, 79.23668885231018, 80.15753674507141, 81.06386065483093, 81.98304748535156, 82.89129567146301, 83.79906058311462, 84.70073223114014, 85.62714958190918, 86.5785002708435, 87.50667667388916, 88.43842577934265, 89.35995697975159, 90.29225087165833, 91.22064185142517, 92.14564394950867, 93.07589554786682, 94.01207256317139, 94.94283413887024, 95.86459183692932, 96.79537677764893, 97.71226525306702, 98.6512303352356, 99.59273290634155, 100.53261518478394, 101.48926663398743, 102.99834823608398]
[36.68, 46.9, 77.32, 91.46, 93.42, 93.4, 93.94, 93.76, 92.92, 91.22, 91.8, 92.42, 91.7, 92.44, 91.6, 91.2, 90.64, 91.74, 90.16, 89.72, 89.84, 90.72, 90.72, 89.24, 89.94, 90.78, 90.42, 89.76, 87.96, 88.24, 88.92, 89.16, 90.5, 89.42, 89.66, 90.5, 89.12, 88.66, 88.54, 91.1, 90.02, 90.02, 89.96, 89.08, 81.16, 85.56, 87.66, 88.84, 85.96, 83.94, 83.48, 87.82, 89.76, 82.08, 81.94, 74.52, 84.82, 83.56, 83.18, 87.18, 76.22, 81.8, 81.9, 80.1, 85.08, 86.56, 79.86, 74.74, 62.74, 77.0, 76.44, 78.4, 74.68, 76.88, 86.02, 75.22, 73.76, 73.9, 73.86, 75.92, 73.16, 72.44, 70.74, 82.22, 75.38, 74.38, 59.2, 81.74, 57.1, 55.24, 63.98, 84.14, 84.54, 54.44, 79.16, 72.68, 80.54, 77.02, 81.8, 83.16, 82.38]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fedpac_copsl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist,  filter_alg: loss_psl, level_n_system: 0.6 , level_n_lowerb:0.8  

   Client 9, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550021 (local), 549696 (global); Percentage 99.94 (549696/550021)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 1.626, Test loss: 1.600, Test accuracy: 30.40
Round   0, Global train loss: 1.626, Global test loss: 1.600, Global test accuracy: 28.70
Round   1, Train loss: 1.600, Test loss: 1.585, Test accuracy: 54.12
Round   1, Global train loss: 1.600, Global test loss: 1.585, Global test accuracy: 55.28
Round   2, Train loss: 1.586, Test loss: 1.554, Test accuracy: 66.16
Round   2, Global train loss: 1.586, Global test loss: 1.554, Global test accuracy: 70.84
Round   3, Train loss: 1.561, Test loss: 1.497, Test accuracy: 73.92
Round   3, Global train loss: 1.561, Global test loss: 1.494, Global test accuracy: 78.12
Round   4, Train loss: 1.516, Test loss: 1.404, Test accuracy: 81.66
Round   4, Global train loss: 1.516, Global test loss: 1.396, Global test accuracy: 85.06
Round   5, Train loss: 1.462, Test loss: 1.298, Test accuracy: 85.82
Round   5, Global train loss: 1.462, Global test loss: 1.279, Global test accuracy: 89.54
Round   6, Train loss: 1.421, Test loss: 1.225, Test accuracy: 88.66
Round   6, Global train loss: 1.421, Global test loss: 1.192, Global test accuracy: 93.34
Round   7, Train loss: 1.398, Test loss: 1.182, Test accuracy: 90.42
Round   7, Global train loss: 1.398, Global test loss: 1.140, Global test accuracy: 94.22
Round   8, Train loss: 1.386, Test loss: 1.159, Test accuracy: 91.46
Round   8, Global train loss: 1.386, Global test loss: 1.110, Global test accuracy: 95.10
Round   9, Train loss: 1.378, Test loss: 1.144, Test accuracy: 92.06
Round   9, Global train loss: 1.378, Global test loss: 1.092, Global test accuracy: 95.52
Round  10, Train loss: 1.284, Test loss: 1.136, Test accuracy: 92.26
Round  10, Global train loss: 1.284, Global test loss: 1.070, Global test accuracy: 93.54
Traceback (most recent call last):
  File "main_fedpac_copsl.py", line 280, in <module>
    w_local, loss, indd, class_center_local, class_num, noisy_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys,
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2559, in train
    self.filter_data(net, local_net, iter2-head_eps+1, local_eps-head_eps+1, concept_matrix_local)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2396, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist, level_n_system: 0.8 , level_n_lowerb:0.4  

   Client 7, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.599, Test loss: 1.579, Test accuracy: 38.54
Round   0, Global train loss: 1.599, Global test loss: 1.582, Global test accuracy: 41.10
Round   1, Train loss: 1.572, Test loss: 1.510, Test accuracy: 52.80
Round   1, Global train loss: 1.572, Global test loss: 1.513, Global test accuracy: 62.36
Round   2, Train loss: 1.457, Test loss: 1.355, Test accuracy: 67.66
Round   2, Global train loss: 1.457, Global test loss: 1.246, Global test accuracy: 91.24
Round   3, Train loss: 1.443, Test loss: 1.295, Test accuracy: 72.88
Round   3, Global train loss: 1.443, Global test loss: 1.218, Global test accuracy: 91.76
Round   4, Train loss: 1.267, Test loss: 1.226, Test accuracy: 77.76
Round   4, Global train loss: 1.267, Global test loss: 1.047, Global test accuracy: 94.44
Round   5, Train loss: 1.359, Test loss: 1.172, Test accuracy: 81.28
Round   5, Global train loss: 1.359, Global test loss: 1.073, Global test accuracy: 93.12
Round   6, Train loss: 1.335, Test loss: 1.115, Test accuracy: 84.62
Round   6, Global train loss: 1.335, Global test loss: 1.066, Global test accuracy: 93.36
Round   7, Train loss: 1.254, Test loss: 1.091, Test accuracy: 84.88
Round   7, Global train loss: 1.254, Global test loss: 0.993, Global test accuracy: 94.42
Round   8, Train loss: 1.313, Test loss: 1.071, Test accuracy: 89.30
Round   8, Global train loss: 1.313, Global test loss: 1.057, Global test accuracy: 93.82
Round   9, Train loss: 1.264, Test loss: 1.053, Test accuracy: 89.58
Round   9, Global train loss: 1.264, Global test loss: 1.002, Global test accuracy: 93.80
Round  10, Train loss: 1.273, Test loss: 1.048, Test accuracy: 89.82
Round  10, Global train loss: 1.273, Global test loss: 0.992, Global test accuracy: 94.26
Round  11, Train loss: 1.164, Test loss: 1.037, Test accuracy: 89.94
Round  11, Global train loss: 1.164, Global test loss: 0.983, Global test accuracy: 94.66
Round  12, Train loss: 1.212, Test loss: 1.036, Test accuracy: 89.78
Round  12, Global train loss: 1.212, Global test loss: 0.976, Global test accuracy: 94.48
Round  13, Train loss: 1.162, Test loss: 1.034, Test accuracy: 89.60
Round  13, Global train loss: 1.162, Global test loss: 0.968, Global test accuracy: 95.60
Round  14, Train loss: 1.242, Test loss: 1.035, Test accuracy: 89.32
Round  14, Global train loss: 1.242, Global test loss: 0.971, Global test accuracy: 94.98
Round  15, Train loss: 1.129, Test loss: 1.036, Test accuracy: 89.16
Round  15, Global train loss: 1.129, Global test loss: 0.972, Global test accuracy: 94.92
Round  16, Train loss: 1.245, Test loss: 1.037, Test accuracy: 88.82
Round  16, Global train loss: 1.245, Global test loss: 0.983, Global test accuracy: 94.08
Round  17, Train loss: 1.128, Test loss: 1.038, Test accuracy: 88.68
Round  17, Global train loss: 1.128, Global test loss: 0.968, Global test accuracy: 94.92
Round  18, Train loss: 1.233, Test loss: 1.040, Test accuracy: 88.32
Round  18, Global train loss: 1.233, Global test loss: 0.974, Global test accuracy: 94.86
Round  19, Train loss: 1.203, Test loss: 1.040, Test accuracy: 88.18
Round  19, Global train loss: 1.203, Global test loss: 0.972, Global test accuracy: 94.58
Round  20, Train loss: 1.124, Test loss: 1.045, Test accuracy: 87.64
Round  20, Global train loss: 1.124, Global test loss: 0.960, Global test accuracy: 95.72
Round  21, Train loss: 1.173, Test loss: 1.027, Test accuracy: 89.12
Round  21, Global train loss: 1.173, Global test loss: 0.985, Global test accuracy: 94.78
Round  22, Train loss: 1.211, Test loss: 1.028, Test accuracy: 88.92
Round  22, Global train loss: 1.211, Global test loss: 0.985, Global test accuracy: 93.00
Round  23, Train loss: 1.198, Test loss: 1.029, Test accuracy: 88.72
Round  23, Global train loss: 1.198, Global test loss: 0.976, Global test accuracy: 93.96
Round  24, Train loss: 1.162, Test loss: 1.022, Test accuracy: 89.22
Round  24, Global train loss: 1.162, Global test loss: 0.984, Global test accuracy: 94.34
Round  25, Train loss: 1.048, Test loss: 1.019, Test accuracy: 89.28
Round  25, Global train loss: 1.048, Global test loss: 0.958, Global test accuracy: 95.68
Round  26, Train loss: 1.198, Test loss: 1.021, Test accuracy: 89.06
Round  26, Global train loss: 1.198, Global test loss: 0.975, Global test accuracy: 94.04
Round  27, Train loss: 1.201, Test loss: 1.020, Test accuracy: 89.28
Round  27, Global train loss: 1.201, Global test loss: 0.975, Global test accuracy: 93.74
Round  28, Train loss: 1.106, Test loss: 1.019, Test accuracy: 89.34
Round  28, Global train loss: 1.106, Global test loss: 0.954, Global test accuracy: 96.04
Round  29, Train loss: 1.125, Test loss: 1.019, Test accuracy: 89.16
Round  29, Global train loss: 1.125, Global test loss: 0.962, Global test accuracy: 95.02
Round  30, Train loss: 1.108, Test loss: 1.018, Test accuracy: 89.22
Round  30, Global train loss: 1.108, Global test loss: 0.971, Global test accuracy: 93.96
Round  31, Train loss: 1.101, Test loss: 1.019, Test accuracy: 89.22
Round  31, Global train loss: 1.101, Global test loss: 0.955, Global test accuracy: 95.42
Round  32, Train loss: 1.222, Test loss: 1.019, Test accuracy: 89.14
Round  32, Global train loss: 1.222, Global test loss: 0.969, Global test accuracy: 94.22
Round  33, Train loss: 1.097, Test loss: 1.019, Test accuracy: 89.10
Round  33, Global train loss: 1.097, Global test loss: 0.955, Global test accuracy: 95.56
Round  34, Train loss: 1.104, Test loss: 1.020, Test accuracy: 88.94
Round  34, Global train loss: 1.104, Global test loss: 0.959, Global test accuracy: 95.22
Round  35, Train loss: 1.108, Test loss: 1.023, Test accuracy: 88.60
Round  35, Global train loss: 1.108, Global test loss: 0.951, Global test accuracy: 96.60
Round  36, Train loss: 1.136, Test loss: 1.023, Test accuracy: 88.64
Round  36, Global train loss: 1.136, Global test loss: 0.957, Global test accuracy: 95.34
Round  37, Train loss: 1.210, Test loss: 1.023, Test accuracy: 88.62
Round  37, Global train loss: 1.210, Global test loss: 0.969, Global test accuracy: 93.88
Round  38, Train loss: 1.115, Test loss: 1.023, Test accuracy: 88.58
Round  38, Global train loss: 1.115, Global test loss: 0.959, Global test accuracy: 94.88
Round  39, Train loss: 1.165, Test loss: 1.023, Test accuracy: 88.56
Round  39, Global train loss: 1.165, Global test loss: 0.964, Global test accuracy: 94.42
Round  40, Train loss: 1.085, Test loss: 1.022, Test accuracy: 88.80
Round  40, Global train loss: 1.085, Global test loss: 0.952, Global test accuracy: 96.00
Round  41, Train loss: 1.132, Test loss: 1.024, Test accuracy: 88.52
Round  41, Global train loss: 1.132, Global test loss: 0.963, Global test accuracy: 94.78
Round  42, Train loss: 1.177, Test loss: 1.025, Test accuracy: 88.28
Round  42, Global train loss: 1.177, Global test loss: 0.961, Global test accuracy: 94.90
Round  43, Train loss: 1.176, Test loss: 1.025, Test accuracy: 88.24
Round  43, Global train loss: 1.176, Global test loss: 0.972, Global test accuracy: 94.16
Round  44, Train loss: 1.178, Test loss: 1.026, Test accuracy: 88.18
Round  44, Global train loss: 1.178, Global test loss: 0.977, Global test accuracy: 93.58
Round  45, Train loss: 1.189, Test loss: 1.024, Test accuracy: 88.38
Round  45, Global train loss: 1.189, Global test loss: 0.974, Global test accuracy: 93.56
Round  46, Train loss: 1.015, Test loss: 1.024, Test accuracy: 88.38
Round  46, Global train loss: 1.015, Global test loss: 0.946, Global test accuracy: 96.30
Round  47, Train loss: 1.107, Test loss: 1.025, Test accuracy: 88.10
Round  47, Global train loss: 1.107, Global test loss: 0.960, Global test accuracy: 95.02
Round  48, Train loss: 1.014, Test loss: 1.026, Test accuracy: 88.02
Round  48, Global train loss: 1.014, Global test loss: 0.946, Global test accuracy: 96.36
Round  49, Train loss: 1.099, Test loss: 1.026, Test accuracy: 87.88
Round  49, Global train loss: 1.099, Global test loss: 0.959, Global test accuracy: 95.26
Round  50, Train loss: 1.117, Test loss: 1.026, Test accuracy: 87.90
Round  50, Global train loss: 1.117, Global test loss: 0.960, Global test accuracy: 94.84
Round  51, Train loss: 1.101, Test loss: 1.027, Test accuracy: 87.72
Round  51, Global train loss: 1.101, Global test loss: 0.967, Global test accuracy: 94.52
Round  52, Train loss: 1.181, Test loss: 1.027, Test accuracy: 87.70
Round  52, Global train loss: 1.181, Global test loss: 0.976, Global test accuracy: 93.48
Round  53, Train loss: 1.169, Test loss: 1.028, Test accuracy: 87.68
Round  53, Global train loss: 1.169, Global test loss: 0.969, Global test accuracy: 94.06
Round  54, Train loss: 1.084, Test loss: 1.029, Test accuracy: 87.68
Round  54, Global train loss: 1.084, Global test loss: 0.952, Global test accuracy: 95.64
Round  55, Train loss: 1.170, Test loss: 1.028, Test accuracy: 87.72
Round  55, Global train loss: 1.170, Global test loss: 0.976, Global test accuracy: 93.46
Round  56, Train loss: 1.092, Test loss: 1.029, Test accuracy: 87.70
Round  56, Global train loss: 1.092, Global test loss: 0.953, Global test accuracy: 95.66
Round  57, Train loss: 1.184, Test loss: 1.030, Test accuracy: 87.68
Round  57, Global train loss: 1.184, Global test loss: 0.969, Global test accuracy: 93.84
Round  58, Train loss: 1.098, Test loss: 1.030, Test accuracy: 87.58
Round  58, Global train loss: 1.098, Global test loss: 0.969, Global test accuracy: 94.34
Round  59, Train loss: 1.104, Test loss: 1.030, Test accuracy: 87.66
Round  59, Global train loss: 1.104, Global test loss: 0.956, Global test accuracy: 95.32
Round  60, Train loss: 1.166, Test loss: 1.031, Test accuracy: 87.48
Round  60, Global train loss: 1.166, Global test loss: 0.975, Global test accuracy: 93.44
Round  61, Train loss: 1.072, Test loss: 1.032, Test accuracy: 87.38
Round  61, Global train loss: 1.072, Global test loss: 0.959, Global test accuracy: 94.94
Round  62, Train loss: 1.118, Test loss: 1.033, Test accuracy: 87.30
Round  62, Global train loss: 1.118, Global test loss: 0.962, Global test accuracy: 94.98
Round  63, Train loss: 1.076, Test loss: 1.033, Test accuracy: 87.18
Round  63, Global train loss: 1.076, Global test loss: 0.950, Global test accuracy: 96.04
Round  64, Train loss: 1.156, Test loss: 1.034, Test accuracy: 87.04
Round  64, Global train loss: 1.156, Global test loss: 0.971, Global test accuracy: 93.72
Round  65, Train loss: 1.112, Test loss: 1.034, Test accuracy: 86.92
Round  65, Global train loss: 1.112, Global test loss: 0.959, Global test accuracy: 94.62
Round  66, Train loss: 1.183, Test loss: 1.034, Test accuracy: 87.00
Round  66, Global train loss: 1.183, Global test loss: 0.963, Global test accuracy: 94.68
Round  67, Train loss: 1.164, Test loss: 1.034, Test accuracy: 87.12
Round  67, Global train loss: 1.164, Global test loss: 0.964, Global test accuracy: 94.60
Round  68, Train loss: 1.008, Test loss: 1.034, Test accuracy: 86.92
Round  68, Global train loss: 1.008, Global test loss: 0.945, Global test accuracy: 96.36
Round  69, Train loss: 1.153, Test loss: 1.035, Test accuracy: 87.02
Round  69, Global train loss: 1.153, Global test loss: 0.966, Global test accuracy: 94.02
Round  70, Train loss: 1.182, Test loss: 1.035, Test accuracy: 86.94
Round  70, Global train loss: 1.182, Global test loss: 0.979, Global test accuracy: 93.00
Round  71, Train loss: 1.175, Test loss: 1.035, Test accuracy: 86.86
Round  71, Global train loss: 1.175, Global test loss: 0.972, Global test accuracy: 93.40
Round  72, Train loss: 1.110, Test loss: 1.035, Test accuracy: 86.84
Round  72, Global train loss: 1.110, Global test loss: 0.956, Global test accuracy: 95.42
Round  73, Train loss: 1.089, Test loss: 1.036, Test accuracy: 86.86
Round  73, Global train loss: 1.089, Global test loss: 0.954, Global test accuracy: 95.42
Round  74, Train loss: 1.076, Test loss: 1.037, Test accuracy: 86.80
Round  74, Global train loss: 1.076, Global test loss: 0.956, Global test accuracy: 95.32
Round  75, Train loss: 1.007, Test loss: 1.037, Test accuracy: 86.92
Round  75, Global train loss: 1.007, Global test loss: 0.945, Global test accuracy: 96.42
Round  76, Train loss: 1.090, Test loss: 1.037, Test accuracy: 86.92
Round  76, Global train loss: 1.090, Global test loss: 0.950, Global test accuracy: 95.82
Round  77, Train loss: 1.173, Test loss: 1.037, Test accuracy: 86.88
Round  77, Global train loss: 1.173, Global test loss: 0.972, Global test accuracy: 93.74
Round  78, Train loss: 1.149, Test loss: 1.037, Test accuracy: 86.76
Round  78, Global train loss: 1.149, Global test loss: 0.971, Global test accuracy: 93.62
Round  79, Train loss: 1.166, Test loss: 1.038, Test accuracy: 86.84
Round  79, Global train loss: 1.166, Global test loss: 0.967, Global test accuracy: 94.06
Round  80, Train loss: 1.144, Test loss: 1.038, Test accuracy: 86.68
Round  80, Global train loss: 1.144, Global test loss: 0.966, Global test accuracy: 94.34
Round  81, Train loss: 1.144, Test loss: 1.039, Test accuracy: 86.68
Round  81, Global train loss: 1.144, Global test loss: 0.976, Global test accuracy: 93.32
Round  82, Train loss: 1.092, Test loss: 1.040, Test accuracy: 86.66
Round  82, Global train loss: 1.092, Global test loss: 0.954, Global test accuracy: 95.46
Round  83, Train loss: 1.006, Test loss: 1.040, Test accuracy: 86.64
Round  83, Global train loss: 1.006, Global test loss: 0.945, Global test accuracy: 96.32
Round  84, Train loss: 1.169, Test loss: 1.041, Test accuracy: 86.56
Round  84, Global train loss: 1.169, Global test loss: 0.992, Global test accuracy: 91.56
Round  85, Train loss: 1.163, Test loss: 1.041, Test accuracy: 86.42
Round  85, Global train loss: 1.163, Global test loss: 0.977, Global test accuracy: 93.16
Round  86, Train loss: 1.081, Test loss: 1.041, Test accuracy: 86.40
Round  86, Global train loss: 1.081, Global test loss: 0.961, Global test accuracy: 94.56
Round  87, Train loss: 1.098, Test loss: 1.042, Test accuracy: 86.38
Round  87, Global train loss: 1.098, Global test loss: 0.952, Global test accuracy: 95.92
Round  88, Train loss: 1.077, Test loss: 1.042, Test accuracy: 86.24
Round  88, Global train loss: 1.077, Global test loss: 0.946, Global test accuracy: 96.28
Round  89, Train loss: 1.092, Test loss: 1.042, Test accuracy: 86.32
Round  89, Global train loss: 1.092, Global test loss: 0.954, Global test accuracy: 95.36
Round  90, Train loss: 1.007, Test loss: 1.044, Test accuracy: 86.16
Round  90, Global train loss: 1.007, Global test loss: 0.945, Global test accuracy: 96.32
Round  91, Train loss: 1.083, Test loss: 1.043, Test accuracy: 86.20
Round  91, Global train loss: 1.083, Global test loss: 0.955, Global test accuracy: 95.46
Round  92, Train loss: 1.141, Test loss: 1.044, Test accuracy: 86.28
Round  92, Global train loss: 1.141, Global test loss: 0.967, Global test accuracy: 94.00
Round  93, Train loss: 1.071, Test loss: 1.043, Test accuracy: 86.34
Round  93, Global train loss: 1.071, Global test loss: 0.956, Global test accuracy: 95.20/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Train loss: 1.007, Test loss: 1.043, Test accuracy: 86.38
Round  94, Global train loss: 1.007, Global test loss: 0.944, Global test accuracy: 96.32
Round  95, Train loss: 1.166, Test loss: 1.043, Test accuracy: 86.38
Round  95, Global train loss: 1.166, Global test loss: 0.968, Global test accuracy: 93.80
Round  96, Train loss: 1.177, Test loss: 1.043, Test accuracy: 86.36
Round  96, Global train loss: 1.177, Global test loss: 0.967, Global test accuracy: 94.10
Round  97, Train loss: 1.006, Test loss: 1.043, Test accuracy: 86.34
Round  97, Global train loss: 1.006, Global test loss: 0.945, Global test accuracy: 96.32
Round  98, Train loss: 1.165, Test loss: 1.043, Test accuracy: 86.38
Round  98, Global train loss: 1.165, Global test loss: 0.968, Global test accuracy: 93.84
Round  99, Train loss: 1.089, Test loss: 1.043, Test accuracy: 86.36
Round  99, Global train loss: 1.089, Global test loss: 0.962, Global test accuracy: 94.68
Final Round, Train loss: 1.110, Test loss: 1.043, Test accuracy: 86.12
Final Round, Global train loss: 1.110, Global test loss: 0.962, Global test accuracy: 94.68
Average accuracy final 10 rounds: 86.318 

Average global accuracy final 10 rounds: 95.004 

608.2671022415161
[0.9036002159118652, 1.8072004318237305, 2.583418130874634, 3.359635829925537, 4.133321046829224, 4.90700626373291, 5.676839828491211, 6.446673393249512, 7.212652683258057, 7.978631973266602, 8.753925323486328, 9.529218673706055, 10.306873083114624, 11.084527492523193, 11.849135637283325, 12.613743782043457, 13.38871455192566, 14.163685321807861, 14.928422451019287, 15.693159580230713, 16.456138849258423, 17.219118118286133, 17.986454010009766, 18.7537899017334, 19.523890018463135, 20.29399013519287, 21.06924033164978, 21.84449052810669, 22.616000652313232, 23.387510776519775, 24.16084361076355, 24.934176445007324, 25.968788146972656, 27.00339984893799, 28.070983409881592, 29.138566970825195, 30.247331380844116, 31.356095790863037, 32.40637469291687, 33.4566535949707, 34.209397077560425, 34.96214056015015, 35.714658975601196, 36.467177391052246, 37.20812749862671, 37.94907760620117, 38.72835874557495, 39.50763988494873, 40.27833652496338, 41.04903316497803, 41.8206250667572, 42.59221696853638, 43.37002635002136, 44.14783573150635, 44.913100242614746, 45.678364753723145, 46.43955945968628, 47.200754165649414, 47.96823072433472, 48.73570728302002, 49.51747441291809, 50.29924154281616, 51.06466603279114, 51.83009052276611, 52.6115620136261, 53.393033504486084, 54.17005801200867, 54.94708251953125, 55.713387966156006, 56.47969341278076, 57.25454592704773, 58.0293984413147, 58.8174467086792, 59.6054949760437, 60.390856981277466, 61.17621898651123, 61.94293689727783, 62.709654808044434, 63.48261737823486, 64.2555799484253, 65.02091860771179, 65.78625726699829, 66.55398774147034, 67.32171821594238, 68.08598303794861, 68.85024785995483, 69.62637543678284, 70.40250301361084, 71.17523312568665, 71.94796323776245, 72.7242865562439, 73.50060987472534, 74.27149724960327, 75.0423846244812, 75.81137919425964, 76.58037376403809, 77.3507342338562, 78.12109470367432, 78.89174962043762, 79.66240453720093, 80.44595074653625, 81.22949695587158, 82.00622391700745, 82.78295087814331, 83.55116510391235, 84.3193793296814, 85.08985733985901, 85.86033535003662, 86.62618041038513, 87.39202547073364, 88.17934083938599, 88.96665620803833, 89.73198866844177, 90.49732112884521, 91.27100586891174, 92.04469060897827, 92.81575012207031, 93.58680963516235, 94.35683298110962, 95.12685632705688, 95.89073276519775, 96.65460920333862, 97.46824145317078, 98.28187370300293, 99.06442594528198, 99.84697818756104, 100.64845323562622, 101.4499282836914, 102.2237389087677, 102.997549533844, 103.77088117599487, 104.54421281814575, 105.32440781593323, 106.1046028137207, 106.87517023086548, 107.64573764801025, 108.41340732574463, 109.181077003479, 109.95016837120056, 110.71925973892212, 111.4878580570221, 112.25645637512207, 113.01620149612427, 113.77594661712646, 114.54979181289673, 115.32363700866699, 116.06129288673401, 116.79894876480103, 117.54420161247253, 118.28945446014404, 119.05043315887451, 119.81141185760498, 120.58242774009705, 121.35344362258911, 122.12119960784912, 122.88895559310913, 123.67295622825623, 124.45695686340332, 125.22359108924866, 125.990225315094, 126.76158452033997, 127.53294372558594, 128.33628273010254, 129.13962173461914, 129.90787291526794, 130.67612409591675, 131.4561505317688, 132.23617696762085, 133.01701188087463, 133.79784679412842, 134.56853222846985, 135.33921766281128, 136.09398889541626, 136.84876012802124, 137.60221552848816, 138.35567092895508, 139.11629819869995, 139.87692546844482, 140.64396047592163, 141.41099548339844, 142.18262791633606, 142.95426034927368, 143.7229290008545, 144.4915976524353, 145.2555661201477, 146.0195345878601, 146.8575348854065, 147.69553518295288, 148.4713900089264, 149.2472448348999, 150.01108765602112, 150.77493047714233, 151.53226590156555, 152.28960132598877, 153.05887603759766, 153.82815074920654, 154.60150742530823, 155.3748641014099, 156.14687943458557, 156.91889476776123, 158.4638111591339, 160.0087275505066]
[38.54, 38.54, 52.8, 52.8, 67.66, 67.66, 72.88, 72.88, 77.76, 77.76, 81.28, 81.28, 84.62, 84.62, 84.88, 84.88, 89.3, 89.3, 89.58, 89.58, 89.82, 89.82, 89.94, 89.94, 89.78, 89.78, 89.6, 89.6, 89.32, 89.32, 89.16, 89.16, 88.82, 88.82, 88.68, 88.68, 88.32, 88.32, 88.18, 88.18, 87.64, 87.64, 89.12, 89.12, 88.92, 88.92, 88.72, 88.72, 89.22, 89.22, 89.28, 89.28, 89.06, 89.06, 89.28, 89.28, 89.34, 89.34, 89.16, 89.16, 89.22, 89.22, 89.22, 89.22, 89.14, 89.14, 89.1, 89.1, 88.94, 88.94, 88.6, 88.6, 88.64, 88.64, 88.62, 88.62, 88.58, 88.58, 88.56, 88.56, 88.8, 88.8, 88.52, 88.52, 88.28, 88.28, 88.24, 88.24, 88.18, 88.18, 88.38, 88.38, 88.38, 88.38, 88.1, 88.1, 88.02, 88.02, 87.88, 87.88, 87.9, 87.9, 87.72, 87.72, 87.7, 87.7, 87.68, 87.68, 87.68, 87.68, 87.72, 87.72, 87.7, 87.7, 87.68, 87.68, 87.58, 87.58, 87.66, 87.66, 87.48, 87.48, 87.38, 87.38, 87.3, 87.3, 87.18, 87.18, 87.04, 87.04, 86.92, 86.92, 87.0, 87.0, 87.12, 87.12, 86.92, 86.92, 87.02, 87.02, 86.94, 86.94, 86.86, 86.86, 86.84, 86.84, 86.86, 86.86, 86.8, 86.8, 86.92, 86.92, 86.92, 86.92, 86.88, 86.88, 86.76, 86.76, 86.84, 86.84, 86.68, 86.68, 86.68, 86.68, 86.66, 86.66, 86.64, 86.64, 86.56, 86.56, 86.42, 86.42, 86.4, 86.4, 86.38, 86.38, 86.24, 86.24, 86.32, 86.32, 86.16, 86.16, 86.2, 86.2, 86.28, 86.28, 86.34, 86.34, 86.38, 86.38, 86.38, 86.38, 86.36, 86.36, 86.34, 86.34, 86.38, 86.38, 86.36, 86.36, 86.12, 86.12]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.8 , level_n_lowerb:0.4  

   Client 8, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.604, Test loss: 1.592, Test accuracy: 55.84
Round   0, Global train loss: 1.604, Global test loss: 1.592, Global test accuracy: 56.36
Round   1, Train loss: 1.584, Test loss: 1.529, Test accuracy: 69.82
Round   1, Global train loss: 1.584, Global test loss: 1.524, Global test accuracy: 74.64
Round   2, Train loss: 1.492, Test loss: 1.364, Test accuracy: 71.96
Round   2, Global train loss: 1.492, Global test loss: 1.242, Global test accuracy: 77.26
Round   3, Train loss: 1.276, Test loss: 1.205, Test accuracy: 81.50
Round   3, Global train loss: 1.276, Global test loss: 1.028, Global test accuracy: 93.86
Round   4, Train loss: 1.198, Test loss: 1.109, Test accuracy: 85.98
Round   4, Global train loss: 1.198, Global test loss: 0.974, Global test accuracy: 95.60
Round   5, Train loss: 1.259, Test loss: 1.047, Test accuracy: 89.06
Round   5, Global train loss: 1.259, Global test loss: 0.966, Global test accuracy: 95.70
Round   6, Train loss: 1.270, Test loss: 1.034, Test accuracy: 89.34
Round   6, Global train loss: 1.270, Global test loss: 0.962, Global test accuracy: 95.64
Round   7, Train loss: 1.146, Test loss: 1.031, Test accuracy: 89.68
Round   7, Global train loss: 1.146, Global test loss: 0.952, Global test accuracy: 96.32
Round   8, Train loss: 1.178, Test loss: 0.962, Test accuracy: 95.62
Round   8, Global train loss: 1.178, Global test loss: 0.950, Global test accuracy: 96.54
Round   9, Train loss: 1.263, Test loss: 0.960, Test accuracy: 95.72
Round   9, Global train loss: 1.263, Global test loss: 0.952, Global test accuracy: 96.08
Round  10, Train loss: 1.299, Test loss: 0.961, Test accuracy: 95.64
Round  10, Global train loss: 1.299, Global test loss: 0.952, Global test accuracy: 95.86
Round  11, Train loss: 1.244, Test loss: 0.957, Test accuracy: 95.72
Round  11, Global train loss: 1.244, Global test loss: 0.948, Global test accuracy: 96.16
Round  12, Train loss: 1.135, Test loss: 0.955, Test accuracy: 95.78
Round  12, Global train loss: 1.135, Global test loss: 0.943, Global test accuracy: 96.68
Round  13, Train loss: 1.297, Test loss: 0.956, Test accuracy: 95.68
Round  13, Global train loss: 1.297, Global test loss: 0.948, Global test accuracy: 96.22
Round  14, Train loss: 1.184, Test loss: 0.954, Test accuracy: 95.66
Round  14, Global train loss: 1.184, Global test loss: 0.943, Global test accuracy: 96.76
Round  15, Train loss: 1.255, Test loss: 0.954, Test accuracy: 95.60
Round  15, Global train loss: 1.255, Global test loss: 0.947, Global test accuracy: 96.02
Round  16, Train loss: 1.269, Test loss: 0.954, Test accuracy: 95.48
Round  16, Global train loss: 1.269, Global test loss: 0.950, Global test accuracy: 95.76
Round  17, Train loss: 1.233, Test loss: 0.954, Test accuracy: 95.66
Round  17, Global train loss: 1.233, Global test loss: 0.945, Global test accuracy: 96.32
Round  18, Train loss: 1.179, Test loss: 0.953, Test accuracy: 95.76
Round  18, Global train loss: 1.179, Global test loss: 0.945, Global test accuracy: 96.42
Round  19, Train loss: 1.157, Test loss: 0.952, Test accuracy: 95.72
Round  19, Global train loss: 1.157, Global test loss: 0.943, Global test accuracy: 96.54
Round  20, Train loss: 1.236, Test loss: 0.952, Test accuracy: 95.64
Round  20, Global train loss: 1.236, Global test loss: 0.943, Global test accuracy: 96.50
Round  21, Train loss: 1.143, Test loss: 0.951, Test accuracy: 95.76
Round  21, Global train loss: 1.143, Global test loss: 0.939, Global test accuracy: 97.14
Round  22, Train loss: 1.286, Test loss: 0.951, Test accuracy: 95.76
Round  22, Global train loss: 1.286, Global test loss: 0.951, Global test accuracy: 95.64
Round  23, Train loss: 1.249, Test loss: 0.951, Test accuracy: 95.72
Round  23, Global train loss: 1.249, Global test loss: 0.948, Global test accuracy: 96.14
Round  24, Train loss: 1.276, Test loss: 0.951, Test accuracy: 95.78
Round  24, Global train loss: 1.276, Global test loss: 0.943, Global test accuracy: 96.60
Round  25, Train loss: 1.246, Test loss: 0.952, Test accuracy: 95.64
Round  25, Global train loss: 1.246, Global test loss: 0.942, Global test accuracy: 96.74
Round  26, Train loss: 1.143, Test loss: 0.951, Test accuracy: 95.80
Round  26, Global train loss: 1.143, Global test loss: 0.943, Global test accuracy: 96.68
Round  27, Train loss: 1.183, Test loss: 0.951, Test accuracy: 95.78
Round  27, Global train loss: 1.183, Global test loss: 0.946, Global test accuracy: 96.14
Round  28, Train loss: 1.249, Test loss: 0.951, Test accuracy: 95.78
Round  28, Global train loss: 1.249, Global test loss: 0.943, Global test accuracy: 96.48
Round  29, Train loss: 1.265, Test loss: 0.951, Test accuracy: 95.76
Round  29, Global train loss: 1.265, Global test loss: 0.947, Global test accuracy: 96.26
Round  30, Train loss: 1.140, Test loss: 0.951, Test accuracy: 95.78
Round  30, Global train loss: 1.140, Global test loss: 0.942, Global test accuracy: 96.50
Round  31, Train loss: 1.248, Test loss: 0.950, Test accuracy: 95.84
Round  31, Global train loss: 1.248, Global test loss: 0.947, Global test accuracy: 95.98
Round  32, Train loss: 1.181, Test loss: 0.950, Test accuracy: 95.86
Round  32, Global train loss: 1.181, Global test loss: 0.946, Global test accuracy: 96.18
Round  33, Train loss: 1.226, Test loss: 0.950, Test accuracy: 95.90
Round  33, Global train loss: 1.226, Global test loss: 0.945, Global test accuracy: 96.12
Round  34, Train loss: 1.136, Test loss: 0.951, Test accuracy: 95.72
Round  34, Global train loss: 1.136, Global test loss: 0.940, Global test accuracy: 96.84
Round  35, Train loss: 1.167, Test loss: 0.952, Test accuracy: 95.50
Round  35, Global train loss: 1.167, Global test loss: 0.942, Global test accuracy: 96.48
Round  36, Train loss: 1.184, Test loss: 0.952, Test accuracy: 95.44
Round  36, Global train loss: 1.184, Global test loss: 0.941, Global test accuracy: 96.72
Round  37, Train loss: 1.178, Test loss: 0.952, Test accuracy: 95.52
Round  37, Global train loss: 1.178, Global test loss: 0.944, Global test accuracy: 96.36
Round  38, Train loss: 1.055, Test loss: 0.955, Test accuracy: 95.12
Round  38, Global train loss: 1.055, Global test loss: 0.939, Global test accuracy: 96.96
Round  39, Train loss: 1.116, Test loss: 0.954, Test accuracy: 95.20
Round  39, Global train loss: 1.116, Global test loss: 0.939, Global test accuracy: 97.00
Round  40, Train loss: 1.243, Test loss: 0.955, Test accuracy: 95.14
Round  40, Global train loss: 1.243, Global test loss: 0.946, Global test accuracy: 96.08
Round  41, Train loss: 1.268, Test loss: 0.952, Test accuracy: 95.38
Round  41, Global train loss: 1.268, Global test loss: 0.944, Global test accuracy: 96.30
Round  42, Train loss: 1.065, Test loss: 0.953, Test accuracy: 95.34
Round  42, Global train loss: 1.065, Global test loss: 0.942, Global test accuracy: 96.58
Round  43, Train loss: 1.124, Test loss: 0.952, Test accuracy: 95.44
Round  43, Global train loss: 1.124, Global test loss: 0.943, Global test accuracy: 96.36
Round  44, Train loss: 1.220, Test loss: 0.953, Test accuracy: 95.28
Round  44, Global train loss: 1.220, Global test loss: 0.943, Global test accuracy: 96.38
Round  45, Train loss: 1.167, Test loss: 0.953, Test accuracy: 95.20
Round  45, Global train loss: 1.167, Global test loss: 0.947, Global test accuracy: 95.94
Round  46, Train loss: 1.129, Test loss: 0.956, Test accuracy: 94.90
Round  46, Global train loss: 1.129, Global test loss: 0.940, Global test accuracy: 96.78
Round  47, Train loss: 1.136, Test loss: 0.953, Test accuracy: 95.24
Round  47, Global train loss: 1.136, Global test loss: 0.942, Global test accuracy: 96.52
Round  48, Train loss: 1.227, Test loss: 0.953, Test accuracy: 95.26
Round  48, Global train loss: 1.227, Global test loss: 0.943, Global test accuracy: 96.46
Round  49, Train loss: 1.253, Test loss: 0.953, Test accuracy: 95.38
Round  49, Global train loss: 1.253, Global test loss: 0.949, Global test accuracy: 95.80
Round  50, Train loss: 1.157, Test loss: 0.952, Test accuracy: 95.48
Round  50, Global train loss: 1.157, Global test loss: 0.946, Global test accuracy: 96.00
Round  51, Train loss: 1.222, Test loss: 0.952, Test accuracy: 95.46
Round  51, Global train loss: 1.222, Global test loss: 0.943, Global test accuracy: 96.36
Round  52, Train loss: 1.238, Test loss: 0.960, Test accuracy: 94.74
Round  52, Global train loss: 1.238, Global test loss: 0.950, Global test accuracy: 95.82
Round  53, Train loss: 1.218, Test loss: 0.961, Test accuracy: 94.66
Round  53, Global train loss: 1.218, Global test loss: 0.947, Global test accuracy: 95.94
Round  54, Train loss: 1.121, Test loss: 0.962, Test accuracy: 94.52
Round  54, Global train loss: 1.121, Global test loss: 0.943, Global test accuracy: 96.18
Round  55, Train loss: 1.132, Test loss: 0.963, Test accuracy: 94.44
Round  55, Global train loss: 1.132, Global test loss: 0.942, Global test accuracy: 96.34
Round  56, Train loss: 1.142, Test loss: 0.957, Test accuracy: 94.98
Round  56, Global train loss: 1.142, Global test loss: 0.943, Global test accuracy: 96.24
Round  57, Train loss: 1.245, Test loss: 0.957, Test accuracy: 94.98
Round  57, Global train loss: 1.245, Global test loss: 0.945, Global test accuracy: 96.20
Round  58, Train loss: 1.248, Test loss: 0.960, Test accuracy: 94.62
Round  58, Global train loss: 1.248, Global test loss: 0.948, Global test accuracy: 95.86
Round  59, Train loss: 1.146, Test loss: 0.957, Test accuracy: 94.94
Round  59, Global train loss: 1.146, Global test loss: 0.947, Global test accuracy: 95.98
Round  60, Train loss: 1.242, Test loss: 0.957, Test accuracy: 94.94
Round  60, Global train loss: 1.242, Global test loss: 0.949, Global test accuracy: 95.72
Round  61, Train loss: 1.110, Test loss: 0.958, Test accuracy: 94.90
Round  61, Global train loss: 1.110, Global test loss: 0.942, Global test accuracy: 96.48
Round  62, Train loss: 1.256, Test loss: 0.962, Test accuracy: 94.52
Round  62, Global train loss: 1.256, Global test loss: 0.953, Global test accuracy: 95.50
Round  63, Train loss: 1.235, Test loss: 0.962, Test accuracy: 94.58
Round  63, Global train loss: 1.235, Global test loss: 0.951, Global test accuracy: 95.42
Round  64, Train loss: 1.117, Test loss: 0.962, Test accuracy: 94.50
Round  64, Global train loss: 1.117, Global test loss: 0.943, Global test accuracy: 96.24
Round  65, Train loss: 1.248, Test loss: 0.963, Test accuracy: 94.38
Round  65, Global train loss: 1.248, Global test loss: 0.962, Global test accuracy: 94.50
Round  66, Train loss: 1.160, Test loss: 0.965, Test accuracy: 94.06
Round  66, Global train loss: 1.160, Global test loss: 0.950, Global test accuracy: 95.68
Round  67, Train loss: 1.156, Test loss: 0.967, Test accuracy: 93.84
Round  67, Global train loss: 1.156, Global test loss: 0.955, Global test accuracy: 95.16
Round  68, Train loss: 1.121, Test loss: 0.967, Test accuracy: 93.80
Round  68, Global train loss: 1.121, Global test loss: 0.946, Global test accuracy: 96.16
Round  69, Train loss: 1.232, Test loss: 0.965, Test accuracy: 93.98
Round  69, Global train loss: 1.232, Global test loss: 0.953, Global test accuracy: 95.56
Round  70, Train loss: 1.157, Test loss: 0.962, Test accuracy: 94.28
Round  70, Global train loss: 1.157, Global test loss: 0.950, Global test accuracy: 95.60
Round  71, Train loss: 1.237, Test loss: 0.964, Test accuracy: 94.12
Round  71, Global train loss: 1.237, Global test loss: 0.958, Global test accuracy: 94.76
Round  72, Train loss: 1.240, Test loss: 0.962, Test accuracy: 94.22
Round  72, Global train loss: 1.240, Global test loss: 0.961, Global test accuracy: 94.94
Round  73, Train loss: 1.228, Test loss: 0.964, Test accuracy: 94.04
Round  73, Global train loss: 1.228, Global test loss: 0.960, Global test accuracy: 94.48
Round  74, Train loss: 1.215, Test loss: 0.965, Test accuracy: 93.96
Round  74, Global train loss: 1.215, Global test loss: 0.950, Global test accuracy: 95.66
Round  75, Train loss: 1.119, Test loss: 0.963, Test accuracy: 94.30
Round  75, Global train loss: 1.119, Global test loss: 0.945, Global test accuracy: 96.26
Round  76, Train loss: 1.228, Test loss: 0.958, Test accuracy: 94.80
Round  76, Global train loss: 1.228, Global test loss: 0.949, Global test accuracy: 95.88
Round  77, Train loss: 1.234, Test loss: 0.961, Test accuracy: 94.42
Round  77, Global train loss: 1.234, Global test loss: 0.952, Global test accuracy: 95.46
Round  78, Train loss: 1.115, Test loss: 0.962, Test accuracy: 94.30
Round  78, Global train loss: 1.115, Global test loss: 0.948, Global test accuracy: 95.74
Round  79, Train loss: 1.225, Test loss: 0.960, Test accuracy: 94.64
Round  79, Global train loss: 1.225, Global test loss: 0.955, Global test accuracy: 95.28
Round  80, Train loss: 1.130, Test loss: 0.961, Test accuracy: 94.46
Round  80, Global train loss: 1.130, Global test loss: 0.955, Global test accuracy: 94.96
Round  81, Train loss: 1.104, Test loss: 0.961, Test accuracy: 94.42
Round  81, Global train loss: 1.104, Global test loss: 0.951, Global test accuracy: 95.44
Round  82, Train loss: 1.235, Test loss: 0.960, Test accuracy: 94.72
Round  82, Global train loss: 1.235, Global test loss: 0.948, Global test accuracy: 95.76
Round  83, Train loss: 1.117, Test loss: 0.962, Test accuracy: 94.48
Round  83, Global train loss: 1.117, Global test loss: 0.945, Global test accuracy: 96.36
Round  84, Train loss: 1.247, Test loss: 0.963, Test accuracy: 94.42
Round  84, Global train loss: 1.247, Global test loss: 0.967, Global test accuracy: 93.92
Round  85, Train loss: 1.135, Test loss: 0.963, Test accuracy: 94.36
Round  85, Global train loss: 1.135, Global test loss: 0.950, Global test accuracy: 95.36
Round  86, Train loss: 1.126, Test loss: 0.963, Test accuracy: 94.44
Round  86, Global train loss: 1.126, Global test loss: 0.947, Global test accuracy: 95.90
Round  87, Train loss: 1.160, Test loss: 0.961, Test accuracy: 94.68
Round  87, Global train loss: 1.160, Global test loss: 0.947, Global test accuracy: 95.92
Round  88, Train loss: 1.150, Test loss: 0.961, Test accuracy: 94.56
Round  88, Global train loss: 1.150, Global test loss: 0.949, Global test accuracy: 96.00
Round  89, Train loss: 1.233, Test loss: 0.963, Test accuracy: 94.38
Round  89, Global train loss: 1.233, Global test loss: 0.951, Global test accuracy: 95.68
Round  90, Train loss: 1.212, Test loss: 0.965, Test accuracy: 94.08
Round  90, Global train loss: 1.212, Global test loss: 0.950, Global test accuracy: 95.70
Round  91, Train loss: 1.210, Test loss: 0.965, Test accuracy: 93.98
Round  91, Global train loss: 1.210, Global test loss: 0.952, Global test accuracy: 95.56
Round  92, Train loss: 1.224, Test loss: 0.965, Test accuracy: 94.02
Round  92, Global train loss: 1.224, Global test loss: 0.958, Global test accuracy: 94.98
Round  93, Train loss: 1.236, Test loss: 0.965, Test accuracy: 94.06
Round  93, Global train loss: 1.236, Global test loss: 0.954, Global test accuracy: 95.26/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Train loss: 1.212, Test loss: 0.966, Test accuracy: 94.06
Round  94, Global train loss: 1.212, Global test loss: 0.950, Global test accuracy: 95.84
Round  95, Train loss: 1.133, Test loss: 0.968, Test accuracy: 93.82
Round  95, Global train loss: 1.133, Global test loss: 0.951, Global test accuracy: 95.60
Round  96, Train loss: 1.150, Test loss: 0.964, Test accuracy: 94.40
Round  96, Global train loss: 1.150, Global test loss: 0.949, Global test accuracy: 95.80
Round  97, Train loss: 1.211, Test loss: 0.964, Test accuracy: 94.38
Round  97, Global train loss: 1.211, Global test loss: 0.953, Global test accuracy: 95.62
Round  98, Train loss: 1.130, Test loss: 0.963, Test accuracy: 94.40
Round  98, Global train loss: 1.130, Global test loss: 0.950, Global test accuracy: 95.68
Round  99, Train loss: 1.219, Test loss: 0.963, Test accuracy: 94.40
Round  99, Global train loss: 1.219, Global test loss: 0.952, Global test accuracy: 95.52
Final Round, Train loss: 1.164, Test loss: 0.965, Test accuracy: 94.12
Final Round, Global train loss: 1.164, Global test loss: 0.952, Global test accuracy: 95.52
Average accuracy final 10 rounds: 94.16 

Average global accuracy final 10 rounds: 95.55600000000001 

664.4743597507477
[0.9742555618286133, 1.9485111236572266, 2.782499313354492, 3.616487503051758, 4.442784309387207, 5.269081115722656, 6.084758758544922, 6.9004364013671875, 7.722769260406494, 8.5451021194458, 9.376248359680176, 10.20739459991455, 11.028724670410156, 11.850054740905762, 12.677257776260376, 13.50446081161499, 14.332316875457764, 15.160172939300537, 15.995331764221191, 16.830490589141846, 17.64782404899597, 18.465157508850098, 19.288304090499878, 20.111450672149658, 21.45889663696289, 22.806342601776123, 24.097810983657837, 25.38927936553955, 26.796645879745483, 28.204012393951416, 29.640318155288696, 31.076623916625977, 32.52073264122009, 33.96484136581421, 35.01404333114624, 36.06324529647827, 37.146559953689575, 38.22987461090088, 39.31101894378662, 40.39216327667236, 41.38969707489014, 42.38723087310791, 43.53688859939575, 44.686546325683594, 45.510865449905396, 46.3351845741272, 47.165852546691895, 47.99652051925659, 48.827757596969604, 49.65899467468262, 50.64140486717224, 51.623815059661865, 52.45107626914978, 53.278337478637695, 54.1185564994812, 54.95877552032471, 55.94058036804199, 56.92238521575928, 57.75674104690552, 58.59109687805176, 59.43033742904663, 60.269577980041504, 61.110716819763184, 61.95185565948486, 62.789777755737305, 63.627699851989746, 64.46061301231384, 65.29352617263794, 66.12807774543762, 66.9626293182373, 67.79839754104614, 68.63416576385498, 69.63194179534912, 70.62971782684326, 71.46026492118835, 72.29081201553345, 73.11211085319519, 73.93340969085693, 74.7575798034668, 75.58174991607666, 76.40470838546753, 77.2276668548584, 78.06118249893188, 78.89469814300537, 79.72151851654053, 80.54833889007568, 81.51495027542114, 82.4815616607666, 83.32591915130615, 84.1702766418457, 85.0005693435669, 85.83086204528809, 86.67016220092773, 87.50946235656738, 88.3373031616211, 89.1651439666748, 89.96222114562988, 90.75929832458496, 91.58682489395142, 92.41435146331787, 93.24063229560852, 94.06691312789917, 95.08988237380981, 96.11285161972046, 96.95064759254456, 97.78844356536865, 98.61994051933289, 99.45143747329712, 100.34104418754578, 101.23065090179443, 102.06250929832458, 102.89436769485474, 103.72138810157776, 104.54840850830078, 105.53110980987549, 106.5138111114502, 107.33904457092285, 108.16427803039551, 108.9935793876648, 109.82288074493408, 110.6491322517395, 111.47538375854492, 112.30428791046143, 113.13319206237793, 113.95442295074463, 114.77565383911133, 115.60175275802612, 116.42785167694092, 117.41753482818604, 118.40721797943115, 119.25491547584534, 120.10261297225952, 120.92722916603088, 121.75184535980225, 122.58378314971924, 123.41572093963623, 124.25715517997742, 125.0985894203186, 125.9323742389679, 126.76615905761719, 127.59677934646606, 128.42739963531494, 129.25066018104553, 130.07392072677612, 130.90148639678955, 131.72905206680298, 132.66416192054749, 133.599271774292, 134.49202704429626, 135.38478231430054, 136.2192883491516, 137.05379438400269, 137.88529920578003, 138.71680402755737, 139.67994117736816, 140.64307832717896, 141.48069381713867, 142.3183093070984, 143.15155792236328, 143.98480653762817, 144.82125210762024, 145.6576976776123, 146.5678834915161, 147.47806930541992, 148.32206797599792, 149.16606664657593, 150.00000548362732, 150.8339443206787, 151.66335010528564, 152.49275588989258, 153.46974444389343, 154.4467329978943, 155.27677607536316, 156.10681915283203, 156.94283986091614, 157.77886056900024, 158.6082570552826, 159.43765354156494, 160.26096653938293, 161.08427953720093, 161.91110610961914, 162.73793268203735, 163.57242012023926, 164.40690755844116, 165.2353115081787, 166.06371545791626, 166.89392614364624, 167.72413682937622, 168.54935359954834, 169.37457036972046, 170.4949996471405, 171.61542892456055, 172.69260573387146, 173.76978254318237, 174.91294956207275, 176.05611658096313, 177.10743141174316, 178.1587462425232, 178.97668075561523, 179.79461526870728, 181.71992540359497, 183.64523553848267]
[55.84, 55.84, 69.82, 69.82, 71.96, 71.96, 81.5, 81.5, 85.98, 85.98, 89.06, 89.06, 89.34, 89.34, 89.68, 89.68, 95.62, 95.62, 95.72, 95.72, 95.64, 95.64, 95.72, 95.72, 95.78, 95.78, 95.68, 95.68, 95.66, 95.66, 95.6, 95.6, 95.48, 95.48, 95.66, 95.66, 95.76, 95.76, 95.72, 95.72, 95.64, 95.64, 95.76, 95.76, 95.76, 95.76, 95.72, 95.72, 95.78, 95.78, 95.64, 95.64, 95.8, 95.8, 95.78, 95.78, 95.78, 95.78, 95.76, 95.76, 95.78, 95.78, 95.84, 95.84, 95.86, 95.86, 95.9, 95.9, 95.72, 95.72, 95.5, 95.5, 95.44, 95.44, 95.52, 95.52, 95.12, 95.12, 95.2, 95.2, 95.14, 95.14, 95.38, 95.38, 95.34, 95.34, 95.44, 95.44, 95.28, 95.28, 95.2, 95.2, 94.9, 94.9, 95.24, 95.24, 95.26, 95.26, 95.38, 95.38, 95.48, 95.48, 95.46, 95.46, 94.74, 94.74, 94.66, 94.66, 94.52, 94.52, 94.44, 94.44, 94.98, 94.98, 94.98, 94.98, 94.62, 94.62, 94.94, 94.94, 94.94, 94.94, 94.9, 94.9, 94.52, 94.52, 94.58, 94.58, 94.5, 94.5, 94.38, 94.38, 94.06, 94.06, 93.84, 93.84, 93.8, 93.8, 93.98, 93.98, 94.28, 94.28, 94.12, 94.12, 94.22, 94.22, 94.04, 94.04, 93.96, 93.96, 94.3, 94.3, 94.8, 94.8, 94.42, 94.42, 94.3, 94.3, 94.64, 94.64, 94.46, 94.46, 94.42, 94.42, 94.72, 94.72, 94.48, 94.48, 94.42, 94.42, 94.36, 94.36, 94.44, 94.44, 94.68, 94.68, 94.56, 94.56, 94.38, 94.38, 94.08, 94.08, 93.98, 93.98, 94.02, 94.02, 94.06, 94.06, 94.06, 94.06, 93.82, 93.82, 94.4, 94.4, 94.38, 94.38, 94.4, 94.4, 94.4, 94.4, 94.12, 94.12]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.8 , level_n_lowerb:0.4  

   Client 6, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
prox
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.605, Test loss: 1.596, Test accuracy: 39.80
Round   0, Global train loss: 1.605, Global test loss: 1.596, Global test accuracy: 39.02
Round   1, Train loss: 1.565, Test loss: 1.512, Test accuracy: 62.34
Round   1, Global train loss: 1.565, Global test loss: 1.508, Global test accuracy: 66.54
Round   2, Train loss: 1.484, Test loss: 1.363, Test accuracy: 74.32
Round   2, Global train loss: 1.484, Global test loss: 1.253, Global test accuracy: 87.84
Round   3, Train loss: 1.183, Test loss: 1.209, Test accuracy: 82.48
Round   3, Global train loss: 1.183, Global test loss: 1.024, Global test accuracy: 94.34
Round   4, Train loss: 1.197, Test loss: 1.112, Test accuracy: 87.38
Round   4, Global train loss: 1.197, Global test loss: 0.979, Global test accuracy: 95.78
Round   5, Train loss: 1.164, Test loss: 1.048, Test accuracy: 89.46
Round   5, Global train loss: 1.164, Global test loss: 0.965, Global test accuracy: 96.06
Round   6, Train loss: 1.169, Test loss: 1.033, Test accuracy: 89.74
Round   6, Global train loss: 1.169, Global test loss: 0.959, Global test accuracy: 96.00
Round   7, Train loss: 1.252, Test loss: 1.029, Test accuracy: 89.86
Round   7, Global train loss: 1.252, Global test loss: 0.954, Global test accuracy: 96.06
Round   8, Train loss: 1.171, Test loss: 0.962, Test accuracy: 95.80
Round   8, Global train loss: 1.171, Global test loss: 0.954, Global test accuracy: 96.20
Round   9, Train loss: 1.162, Test loss: 0.960, Test accuracy: 95.92
Round   9, Global train loss: 1.162, Global test loss: 0.950, Global test accuracy: 96.24
Round  10, Train loss: 1.288, Test loss: 0.960, Test accuracy: 95.84
Round  10, Global train loss: 1.288, Global test loss: 0.950, Global test accuracy: 96.44
Round  11, Train loss: 1.149, Test loss: 0.954, Test accuracy: 96.10
Round  11, Global train loss: 1.149, Global test loss: 0.947, Global test accuracy: 96.16
Round  12, Train loss: 1.243, Test loss: 0.952, Test accuracy: 96.12
Round  12, Global train loss: 1.243, Global test loss: 0.945, Global test accuracy: 96.40
Round  13, Train loss: 1.290, Test loss: 0.950, Test accuracy: 96.24
Round  13, Global train loss: 1.290, Global test loss: 0.945, Global test accuracy: 96.52
Round  14, Train loss: 1.173, Test loss: 0.949, Test accuracy: 96.30
Round  14, Global train loss: 1.173, Global test loss: 0.943, Global test accuracy: 96.58
Round  15, Train loss: 1.156, Test loss: 0.948, Test accuracy: 96.38
Round  15, Global train loss: 1.156, Global test loss: 0.945, Global test accuracy: 96.38
Round  16, Train loss: 1.163, Test loss: 0.947, Test accuracy: 96.38
Round  16, Global train loss: 1.163, Global test loss: 0.942, Global test accuracy: 96.46
Round  17, Train loss: 1.138, Test loss: 0.946, Test accuracy: 96.46
Round  17, Global train loss: 1.138, Global test loss: 0.942, Global test accuracy: 96.66
Round  18, Train loss: 1.177, Test loss: 0.945, Test accuracy: 96.56
Round  18, Global train loss: 1.177, Global test loss: 0.943, Global test accuracy: 96.56
Round  19, Train loss: 1.262, Test loss: 0.945, Test accuracy: 96.52
Round  19, Global train loss: 1.262, Global test loss: 0.940, Global test accuracy: 96.60
Round  20, Train loss: 1.243, Test loss: 0.944, Test accuracy: 96.40
Round  20, Global train loss: 1.243, Global test loss: 0.941, Global test accuracy: 96.70
Round  21, Train loss: 1.241, Test loss: 0.944, Test accuracy: 96.46
Round  21, Global train loss: 1.241, Global test loss: 0.942, Global test accuracy: 96.20
Round  22, Train loss: 1.281, Test loss: 0.945, Test accuracy: 96.34
Round  22, Global train loss: 1.281, Global test loss: 0.942, Global test accuracy: 96.62
Round  23, Train loss: 1.142, Test loss: 0.945, Test accuracy: 96.30
Round  23, Global train loss: 1.142, Global test loss: 0.942, Global test accuracy: 96.60
Round  24, Train loss: 1.274, Test loss: 0.945, Test accuracy: 96.42
Round  24, Global train loss: 1.274, Global test loss: 0.942, Global test accuracy: 96.38
Round  25, Train loss: 1.246, Test loss: 0.945, Test accuracy: 96.40
Round  25, Global train loss: 1.246, Global test loss: 0.944, Global test accuracy: 96.50
Round  26, Train loss: 1.142, Test loss: 0.945, Test accuracy: 96.36
Round  26, Global train loss: 1.142, Global test loss: 0.944, Global test accuracy: 96.22
Round  27, Train loss: 1.285, Test loss: 0.945, Test accuracy: 96.24
Round  27, Global train loss: 1.285, Global test loss: 0.941, Global test accuracy: 96.42
Round  28, Train loss: 1.246, Test loss: 0.945, Test accuracy: 96.22
Round  28, Global train loss: 1.246, Global test loss: 0.942, Global test accuracy: 96.24
Round  29, Train loss: 1.257, Test loss: 0.945, Test accuracy: 96.18
Round  29, Global train loss: 1.257, Global test loss: 0.942, Global test accuracy: 96.34
Round  30, Train loss: 1.041, Test loss: 0.945, Test accuracy: 96.12
Round  30, Global train loss: 1.041, Global test loss: 0.943, Global test accuracy: 96.66
Round  31, Train loss: 1.249, Test loss: 0.945, Test accuracy: 96.18
Round  31, Global train loss: 1.249, Global test loss: 0.942, Global test accuracy: 96.54
Round  32, Train loss: 1.176, Test loss: 0.945, Test accuracy: 96.18
Round  32, Global train loss: 1.176, Global test loss: 0.940, Global test accuracy: 96.64
Round  33, Train loss: 1.234, Test loss: 0.945, Test accuracy: 96.16
Round  33, Global train loss: 1.234, Global test loss: 0.942, Global test accuracy: 96.58
Round  34, Train loss: 1.239, Test loss: 0.945, Test accuracy: 96.12
Round  34, Global train loss: 1.239, Global test loss: 0.944, Global test accuracy: 96.10
Round  35, Train loss: 1.168, Test loss: 0.945, Test accuracy: 96.04
Round  35, Global train loss: 1.168, Global test loss: 0.943, Global test accuracy: 96.30
Round  36, Train loss: 1.171, Test loss: 0.945, Test accuracy: 96.00
Round  36, Global train loss: 1.171, Global test loss: 0.941, Global test accuracy: 96.74
Round  37, Train loss: 1.171, Test loss: 0.944, Test accuracy: 96.06
Round  37, Global train loss: 1.171, Global test loss: 0.940, Global test accuracy: 96.82
Round  38, Train loss: 1.152, Test loss: 0.944, Test accuracy: 96.10
Round  38, Global train loss: 1.152, Global test loss: 0.940, Global test accuracy: 96.70
Round  39, Train loss: 1.222, Test loss: 0.944, Test accuracy: 96.16
Round  39, Global train loss: 1.222, Global test loss: 0.943, Global test accuracy: 96.32
Round  40, Train loss: 1.249, Test loss: 0.945, Test accuracy: 96.14
Round  40, Global train loss: 1.249, Global test loss: 0.946, Global test accuracy: 96.20
Round  41, Train loss: 1.261, Test loss: 0.945, Test accuracy: 96.18
Round  41, Global train loss: 1.261, Global test loss: 0.943, Global test accuracy: 96.12
Round  42, Train loss: 1.168, Test loss: 0.945, Test accuracy: 96.16
Round  42, Global train loss: 1.168, Global test loss: 0.941, Global test accuracy: 96.44
Round  43, Train loss: 1.130, Test loss: 0.945, Test accuracy: 96.10
Round  43, Global train loss: 1.130, Global test loss: 0.939, Global test accuracy: 96.72
Round  44, Train loss: 1.121, Test loss: 0.945, Test accuracy: 96.12
Round  44, Global train loss: 1.121, Global test loss: 0.941, Global test accuracy: 96.50
Round  45, Train loss: 1.161, Test loss: 0.945, Test accuracy: 96.00
Round  45, Global train loss: 1.161, Global test loss: 0.944, Global test accuracy: 96.26
Round  46, Train loss: 1.234, Test loss: 0.945, Test accuracy: 96.00
Round  46, Global train loss: 1.234, Global test loss: 0.942, Global test accuracy: 96.26
Round  47, Train loss: 1.238, Test loss: 0.945, Test accuracy: 96.10
Round  47, Global train loss: 1.238, Global test loss: 0.940, Global test accuracy: 96.58
Round  48, Train loss: 1.229, Test loss: 0.944, Test accuracy: 96.12
Round  48, Global train loss: 1.229, Global test loss: 0.945, Global test accuracy: 95.92
Round  49, Train loss: 1.252, Test loss: 0.945, Test accuracy: 96.02
Round  49, Global train loss: 1.252, Global test loss: 0.946, Global test accuracy: 95.92
Round  50, Train loss: 1.150, Test loss: 0.945, Test accuracy: 96.06
Round  50, Global train loss: 1.150, Global test loss: 0.943, Global test accuracy: 96.24
Round  51, Train loss: 1.119, Test loss: 0.945, Test accuracy: 96.10
Round  51, Global train loss: 1.119, Global test loss: 0.943, Global test accuracy: 96.34
Round  52, Train loss: 1.136, Test loss: 0.945, Test accuracy: 96.04
Round  52, Global train loss: 1.136, Global test loss: 0.943, Global test accuracy: 96.30
Round  53, Train loss: 1.221, Test loss: 0.945, Test accuracy: 96.06
Round  53, Global train loss: 1.221, Global test loss: 0.943, Global test accuracy: 96.30
Round  54, Train loss: 1.232, Test loss: 0.946, Test accuracy: 96.00
Round  54, Global train loss: 1.232, Global test loss: 0.942, Global test accuracy: 96.24
Round  55, Train loss: 1.027, Test loss: 0.946, Test accuracy: 96.00
Round  55, Global train loss: 1.027, Global test loss: 0.943, Global test accuracy: 96.36
Round  56, Train loss: 1.249, Test loss: 0.946, Test accuracy: 95.92
Round  56, Global train loss: 1.249, Global test loss: 0.942, Global test accuracy: 96.38
Round  57, Train loss: 1.243, Test loss: 0.946, Test accuracy: 95.80
Round  57, Global train loss: 1.243, Global test loss: 0.943, Global test accuracy: 96.16
Round  58, Train loss: 1.150, Test loss: 0.946, Test accuracy: 95.76
Round  58, Global train loss: 1.150, Global test loss: 0.945, Global test accuracy: 95.96
Round  59, Train loss: 1.142, Test loss: 0.947, Test accuracy: 95.74
Round  59, Global train loss: 1.142, Global test loss: 0.947, Global test accuracy: 95.74
Round  60, Train loss: 1.244, Test loss: 0.947, Test accuracy: 95.80
Round  60, Global train loss: 1.244, Global test loss: 0.944, Global test accuracy: 95.94
Round  61, Train loss: 1.122, Test loss: 0.947, Test accuracy: 95.90
Round  61, Global train loss: 1.122, Global test loss: 0.944, Global test accuracy: 95.98
Round  62, Train loss: 1.256, Test loss: 0.947, Test accuracy: 95.84
Round  62, Global train loss: 1.256, Global test loss: 0.944, Global test accuracy: 96.16
Round  63, Train loss: 1.245, Test loss: 0.947, Test accuracy: 95.82
Round  63, Global train loss: 1.245, Global test loss: 0.949, Global test accuracy: 95.66
Round  64, Train loss: 1.221, Test loss: 0.947, Test accuracy: 95.80
Round  64, Global train loss: 1.221, Global test loss: 0.942, Global test accuracy: 96.46
Round  65, Train loss: 1.249, Test loss: 0.947, Test accuracy: 95.82
Round  65, Global train loss: 1.249, Global test loss: 0.944, Global test accuracy: 96.14
Round  66, Train loss: 1.152, Test loss: 0.947, Test accuracy: 95.76
Round  66, Global train loss: 1.152, Global test loss: 0.944, Global test accuracy: 96.28
Round  67, Train loss: 1.160, Test loss: 0.947, Test accuracy: 95.78
Round  67, Global train loss: 1.160, Global test loss: 0.949, Global test accuracy: 95.62
Round  68, Train loss: 1.227, Test loss: 0.948, Test accuracy: 95.74
Round  68, Global train loss: 1.227, Global test loss: 0.946, Global test accuracy: 95.84
Round  69, Train loss: 1.237, Test loss: 0.948, Test accuracy: 95.72
Round  69, Global train loss: 1.237, Global test loss: 0.946, Global test accuracy: 96.06
Round  70, Train loss: 1.057, Test loss: 0.948, Test accuracy: 95.70
Round  70, Global train loss: 1.057, Global test loss: 0.945, Global test accuracy: 95.98
Round  71, Train loss: 1.249, Test loss: 0.948, Test accuracy: 95.68
Round  71, Global train loss: 1.249, Global test loss: 0.944, Global test accuracy: 96.02
Round  72, Train loss: 1.240, Test loss: 0.948, Test accuracy: 95.70
Round  72, Global train loss: 1.240, Global test loss: 0.945, Global test accuracy: 96.00
Round  73, Train loss: 1.243, Test loss: 0.948, Test accuracy: 95.72
Round  73, Global train loss: 1.243, Global test loss: 0.947, Global test accuracy: 95.62
Round  74, Train loss: 1.218, Test loss: 0.948, Test accuracy: 95.68
Round  74, Global train loss: 1.218, Global test loss: 0.945, Global test accuracy: 96.00
Round  75, Train loss: 1.226, Test loss: 0.948, Test accuracy: 95.66
Round  75, Global train loss: 1.226, Global test loss: 0.945, Global test accuracy: 96.14
Round  76, Train loss: 1.235, Test loss: 0.948, Test accuracy: 95.70
Round  76, Global train loss: 1.235, Global test loss: 0.944, Global test accuracy: 96.16
Round  77, Train loss: 1.241, Test loss: 0.948, Test accuracy: 95.68
Round  77, Global train loss: 1.241, Global test loss: 0.944, Global test accuracy: 96.08
Round  78, Train loss: 1.219, Test loss: 0.948, Test accuracy: 95.68
Round  78, Global train loss: 1.219, Global test loss: 0.942, Global test accuracy: 96.38
Round  79, Train loss: 1.235, Test loss: 0.948, Test accuracy: 95.64
Round  79, Global train loss: 1.235, Global test loss: 0.944, Global test accuracy: 96.24
Round  80, Train loss: 1.245, Test loss: 0.947, Test accuracy: 95.68
Round  80, Global train loss: 1.245, Global test loss: 0.946, Global test accuracy: 95.92
Round  81, Train loss: 1.118, Test loss: 0.948, Test accuracy: 95.64
Round  81, Global train loss: 1.118, Global test loss: 0.947, Global test accuracy: 95.58
Round  82, Train loss: 1.249, Test loss: 0.948, Test accuracy: 95.64
Round  82, Global train loss: 1.249, Global test loss: 0.945, Global test accuracy: 95.98
Round  83, Train loss: 1.225, Test loss: 0.947, Test accuracy: 95.70
Round  83, Global train loss: 1.225, Global test loss: 0.945, Global test accuracy: 95.88
Round  84, Train loss: 1.165, Test loss: 0.948, Test accuracy: 95.74
Round  84, Global train loss: 1.165, Global test loss: 0.946, Global test accuracy: 95.92
Round  85, Train loss: 1.039, Test loss: 0.948, Test accuracy: 95.74
Round  85, Global train loss: 1.039, Global test loss: 0.945, Global test accuracy: 96.08
Round  86, Train loss: 1.033, Test loss: 0.947, Test accuracy: 95.76
Round  86, Global train loss: 1.033, Global test loss: 0.948, Global test accuracy: 95.58
Round  87, Train loss: 1.164, Test loss: 0.947, Test accuracy: 95.76
Round  87, Global train loss: 1.164, Global test loss: 0.946, Global test accuracy: 96.02
Round  88, Train loss: 1.159, Test loss: 0.947, Test accuracy: 95.76
Round  88, Global train loss: 1.159, Global test loss: 0.949, Global test accuracy: 95.52
Round  89, Train loss: 1.248, Test loss: 0.947, Test accuracy: 95.72
Round  89, Global train loss: 1.248, Global test loss: 0.945, Global test accuracy: 96.12
Round  90, Train loss: 1.223, Test loss: 0.947, Test accuracy: 95.72
Round  90, Global train loss: 1.223, Global test loss: 0.948, Global test accuracy: 95.48
Round  91, Train loss: 1.215, Test loss: 0.947, Test accuracy: 95.74
Round  91, Global train loss: 1.215, Global test loss: 0.946, Global test accuracy: 96.02
Round  92, Train loss: 1.235, Test loss: 0.947, Test accuracy: 95.72
Round  92, Global train loss: 1.235, Global test loss: 0.946, Global test accuracy: 95.90
Round  93, Train loss: 1.249, Test loss: 0.948, Test accuracy: 95.74
Round  93, Global train loss: 1.249, Global test loss: 0.947, Global test accuracy: 95.62
Round  94, Train loss: 1.215, Test loss: 0.948, Test accuracy: 95.66
Round  94, Global train loss: 1.215, Global test loss: 0.946, Global test accuracy: 95.94/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  95, Train loss: 1.249, Test loss: 0.948, Test accuracy: 95.60
Round  95, Global train loss: 1.249, Global test loss: 0.944, Global test accuracy: 96.08
Round  96, Train loss: 1.163, Test loss: 0.948, Test accuracy: 95.58
Round  96, Global train loss: 1.163, Global test loss: 0.945, Global test accuracy: 96.16
Round  97, Train loss: 1.215, Test loss: 0.948, Test accuracy: 95.62
Round  97, Global train loss: 1.215, Global test loss: 0.945, Global test accuracy: 96.00
Round  98, Train loss: 1.248, Test loss: 0.948, Test accuracy: 95.72
Round  98, Global train loss: 1.248, Global test loss: 0.944, Global test accuracy: 96.10
Round  99, Train loss: 1.139, Test loss: 0.948, Test accuracy: 95.72
Round  99, Global train loss: 1.139, Global test loss: 0.946, Global test accuracy: 96.16
Final Round, Train loss: 1.178, Test loss: 0.950, Test accuracy: 95.50
Final Round, Global train loss: 1.178, Global test loss: 0.946, Global test accuracy: 96.16
Average accuracy final 10 rounds: 95.682 

Average global accuracy final 10 rounds: 95.946 

664.7200212478638
[1.075517177581787, 2.151034355163574, 3.0899319648742676, 4.028829574584961, 4.976578950881958, 5.924328327178955, 6.845107793807983, 7.765887260437012, 8.695426940917969, 9.624966621398926, 10.553587436676025, 11.482208251953125, 12.41325855255127, 13.344308853149414, 14.271991491317749, 15.199674129486084, 16.19234299659729, 17.185011863708496, 18.121806383132935, 19.058600902557373, 19.99045419692993, 20.92230749130249, 21.860692262649536, 22.799077033996582, 23.83291530609131, 24.866753578186035, 25.814480304718018, 26.76220703125, 27.688236951828003, 28.614266872406006, 29.554863929748535, 30.495460987091064, 31.422619581222534, 32.349778175354004, 33.30054831504822, 34.25131845474243, 35.205913066864014, 36.160507678985596, 37.1630163192749, 38.16552495956421, 39.105799198150635, 40.04607343673706, 40.96449851989746, 41.88292360305786, 42.8091778755188, 43.735432147979736, 44.66473031044006, 45.59402847290039, 46.526042461395264, 47.45805644989014, 48.38887596130371, 49.319695472717285, 50.26012659072876, 51.200557708740234, 52.127214431762695, 53.053871154785156, 53.98741602897644, 54.920960903167725, 55.85888361930847, 56.79680633544922, 57.73760652542114, 58.678406715393066, 59.60117983818054, 60.52395296096802, 61.448187828063965, 62.37242269515991, 63.30967307090759, 64.24692344665527, 65.18987679481506, 66.13283014297485, 67.06878328323364, 68.00473642349243, 68.9360728263855, 69.86740922927856, 70.80438756942749, 71.74136590957642, 72.67704439163208, 73.61272287368774, 74.54339790344238, 75.47407293319702, 76.39518523216248, 77.31629753112793, 78.24266576766968, 79.16903400421143, 80.09369015693665, 81.01834630966187, 81.93656015396118, 82.8547739982605, 83.77581191062927, 84.69684982299805, 85.61301851272583, 86.52918720245361, 87.44979929924011, 88.37041139602661, 89.2825813293457, 90.1947512626648, 91.11469101905823, 92.03463077545166, 92.95342946052551, 93.87222814559937, 94.80517888069153, 95.73812961578369, 96.66454482078552, 97.59096002578735, 98.5180811882019, 99.44520235061646, 100.36978507041931, 101.29436779022217, 102.21292018890381, 103.13147258758545, 104.05531454086304, 104.97915649414062, 105.90921258926392, 106.8392686843872, 107.77604079246521, 108.71281290054321, 109.64231133460999, 110.57180976867676, 111.49690651893616, 112.42200326919556, 113.35250854492188, 114.2830138206482, 115.20636940002441, 116.12972497940063, 117.05361795425415, 117.97751092910767, 118.90683484077454, 119.8361587524414, 120.75692367553711, 121.67768859863281, 122.6197259426117, 123.56176328659058, 124.4912657737732, 125.42076826095581, 126.34604549407959, 127.27132272720337, 128.20549082756042, 129.13965892791748, 130.07037377357483, 131.00108861923218, 131.93006563186646, 132.85904264450073, 133.78492712974548, 134.71081161499023, 135.6528594493866, 136.59490728378296, 137.52279424667358, 138.4506812095642, 139.38630390167236, 140.32192659378052, 141.26703548431396, 142.2121443748474, 143.1530339717865, 144.0939235687256, 145.02844333648682, 145.96296310424805, 146.89641213417053, 147.82986116409302, 148.7610673904419, 149.69227361679077, 150.6303448677063, 151.56841611862183, 152.50271153450012, 153.43700695037842, 154.36735653877258, 155.29770612716675, 156.23144388198853, 157.1651816368103, 158.10077691078186, 159.03637218475342, 160.27224707603455, 161.50812196731567, 162.73813247680664, 163.9681429862976, 165.17319107055664, 166.37823915481567, 167.78096795082092, 169.18369674682617, 170.1152572631836, 171.04681777954102, 171.97542071342468, 172.90402364730835, 173.8302149772644, 174.75640630722046, 175.67391777038574, 176.59142923355103, 177.5205900669098, 178.44975090026855, 179.37795662879944, 180.30616235733032, 181.23015642166138, 182.15415048599243, 183.02174472808838, 183.88933897018433, 184.7565619945526, 185.6237850189209, 186.49199199676514, 187.36019897460938, 188.24682903289795, 189.13345909118652, 191.00079560279846, 192.8681321144104]
[39.8, 39.8, 62.34, 62.34, 74.32, 74.32, 82.48, 82.48, 87.38, 87.38, 89.46, 89.46, 89.74, 89.74, 89.86, 89.86, 95.8, 95.8, 95.92, 95.92, 95.84, 95.84, 96.1, 96.1, 96.12, 96.12, 96.24, 96.24, 96.3, 96.3, 96.38, 96.38, 96.38, 96.38, 96.46, 96.46, 96.56, 96.56, 96.52, 96.52, 96.4, 96.4, 96.46, 96.46, 96.34, 96.34, 96.3, 96.3, 96.42, 96.42, 96.4, 96.4, 96.36, 96.36, 96.24, 96.24, 96.22, 96.22, 96.18, 96.18, 96.12, 96.12, 96.18, 96.18, 96.18, 96.18, 96.16, 96.16, 96.12, 96.12, 96.04, 96.04, 96.0, 96.0, 96.06, 96.06, 96.1, 96.1, 96.16, 96.16, 96.14, 96.14, 96.18, 96.18, 96.16, 96.16, 96.1, 96.1, 96.12, 96.12, 96.0, 96.0, 96.0, 96.0, 96.1, 96.1, 96.12, 96.12, 96.02, 96.02, 96.06, 96.06, 96.1, 96.1, 96.04, 96.04, 96.06, 96.06, 96.0, 96.0, 96.0, 96.0, 95.92, 95.92, 95.8, 95.8, 95.76, 95.76, 95.74, 95.74, 95.8, 95.8, 95.9, 95.9, 95.84, 95.84, 95.82, 95.82, 95.8, 95.8, 95.82, 95.82, 95.76, 95.76, 95.78, 95.78, 95.74, 95.74, 95.72, 95.72, 95.7, 95.7, 95.68, 95.68, 95.7, 95.7, 95.72, 95.72, 95.68, 95.68, 95.66, 95.66, 95.7, 95.7, 95.68, 95.68, 95.68, 95.68, 95.64, 95.64, 95.68, 95.68, 95.64, 95.64, 95.64, 95.64, 95.7, 95.7, 95.74, 95.74, 95.74, 95.74, 95.76, 95.76, 95.76, 95.76, 95.76, 95.76, 95.72, 95.72, 95.72, 95.72, 95.74, 95.74, 95.72, 95.72, 95.74, 95.74, 95.66, 95.66, 95.6, 95.6, 95.58, 95.58, 95.62, 95.62, 95.72, 95.72, 95.72, 95.72, 95.5, 95.5]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.8 , level_n_lowerb:0.4  

   Client 9, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Traceback (most recent call last):
  File "main_fedpac_co_teaching.py", line 250, in <module>
    local.filter_data(net=net_local.to(args.device), net2=net_local2.to(args.device), concept_matrix_local = concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1587, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

   Client 4, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550021 (local), 549696 (global); Percentage 99.94 (549696/550021)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 1.627, Test loss: 1.596, Test accuracy: 51.94
Round   0, Global train loss: 1.627, Global test loss: 1.596, Global test accuracy: 52.10
Round   1, Train loss: 1.588, Test loss: 1.556, Test accuracy: 82.70
Round   1, Global train loss: 1.588, Global test loss: 1.555, Global test accuracy: 83.08
Round   2, Train loss: 1.568, Test loss: 1.478, Test accuracy: 89.00
Round   2, Global train loss: 1.568, Global test loss: 1.472, Global test accuracy: 88.88
Round   3, Train loss: 1.461, Test loss: 1.281, Test accuracy: 90.58
Round   3, Global train loss: 1.461, Global test loss: 1.256, Global test accuracy: 89.88
Round   4, Train loss: 1.320, Test loss: 1.118, Test accuracy: 94.14
Round   4, Global train loss: 1.320, Global test loss: 1.083, Global test accuracy: 93.84
Round   5, Train loss: 1.256, Test loss: 1.061, Test accuracy: 95.24
Round   5, Global train loss: 1.256, Global test loss: 1.044, Global test accuracy: 95.58
Round   6, Train loss: 1.123, Test loss: 1.031, Test accuracy: 95.68
Round   6, Global train loss: 1.123, Global test loss: 1.004, Global test accuracy: 95.82
Round   7, Train loss: 1.202, Test loss: 1.018, Test accuracy: 95.82
Round   7, Global train loss: 1.202, Global test loss: 0.991, Global test accuracy: 96.08
Round   8, Train loss: 1.331, Test loss: 1.014, Test accuracy: 96.06
Round   8, Global train loss: 1.331, Global test loss: 1.019, Global test accuracy: 95.74
Round   9, Train loss: 1.205, Test loss: 1.013, Test accuracy: 96.18
Round   9, Global train loss: 1.205, Global test loss: 0.998, Global test accuracy: 96.04
Round  10, Train loss: 1.229, Test loss: 1.012, Test accuracy: 96.22
Round  10, Global train loss: 1.229, Global test loss: 0.991, Global test accuracy: 96.16
Round  11, Train loss: 1.205, Test loss: 1.001, Test accuracy: 96.40
Round  11, Global train loss: 1.205, Global test loss: 0.993, Global test accuracy: 96.46
Round  12, Train loss: 1.177, Test loss: 0.997, Test accuracy: 96.48
Round  12, Global train loss: 1.177, Global test loss: 0.975, Global test accuracy: 96.46
Round  13, Train loss: 1.333, Test loss: 1.002, Test accuracy: 96.52
Round  13, Global train loss: 1.333, Global test loss: 0.997, Global test accuracy: 96.54
Round  14, Train loss: 1.205, Test loss: 1.001, Test accuracy: 96.52
Round  14, Global train loss: 1.205, Global test loss: 0.980, Global test accuracy: 96.74
Round  15, Train loss: 1.190, Test loss: 0.996, Test accuracy: 96.60
Round  15, Global train loss: 1.190, Global test loss: 0.982, Global test accuracy: 96.68
Round  16, Train loss: 1.210, Test loss: 0.996, Test accuracy: 96.56
Round  16, Global train loss: 1.210, Global test loss: 0.980, Global test accuracy: 96.78
Round  17, Train loss: 1.185, Test loss: 0.991, Test accuracy: 96.68
Round  17, Global train loss: 1.185, Global test loss: 0.977, Global test accuracy: 96.86
Round  18, Train loss: 1.305, Test loss: 0.991, Test accuracy: 96.72
Round  18, Global train loss: 1.305, Global test loss: 0.987, Global test accuracy: 96.84
Round  19, Train loss: 1.183, Test loss: 0.990, Test accuracy: 96.84
Round  19, Global train loss: 1.183, Global test loss: 0.972, Global test accuracy: 96.82
Round  20, Train loss: 1.294, Test loss: 0.989, Test accuracy: 96.84
Round  20, Global train loss: 1.294, Global test loss: 0.982, Global test accuracy: 97.06
Round  21, Train loss: 1.183, Test loss: 0.979, Test accuracy: 96.82
Round  21, Global train loss: 1.183, Global test loss: 0.971, Global test accuracy: 96.78
Round  22, Train loss: 1.312, Test loss: 0.990, Test accuracy: 96.70
Round  22, Global train loss: 1.312, Global test loss: 0.985, Global test accuracy: 96.80
Round  23, Train loss: 1.072, Test loss: 0.989, Test accuracy: 96.48
Round  23, Global train loss: 1.072, Global test loss: 0.966, Global test accuracy: 96.64
Round  24, Train loss: 1.320, Test loss: 0.983, Test accuracy: 96.46
Round  24, Global train loss: 1.320, Global test loss: 0.992, Global test accuracy: 96.50
Round  25, Train loss: 1.299, Test loss: 0.981, Test accuracy: 96.60
Round  25, Global train loss: 1.299, Global test loss: 0.984, Global test accuracy: 97.06
Round  26, Train loss: 1.168, Test loss: 0.976, Test accuracy: 96.94
Round  26, Global train loss: 1.168, Global test loss: 0.966, Global test accuracy: 96.76
Round  27, Train loss: 1.302, Test loss: 0.984, Test accuracy: 96.62
Round  27, Global train loss: 1.302, Global test loss: 0.985, Global test accuracy: 96.50
Round  28, Train loss: 1.177, Test loss: 0.982, Test accuracy: 96.70
Round  28, Global train loss: 1.177, Global test loss: 0.966, Global test accuracy: 96.86
Round  29, Train loss: 1.298, Test loss: 0.984, Test accuracy: 96.54
Round  29, Global train loss: 1.298, Global test loss: 0.984, Global test accuracy: 96.68
Round  30, Train loss: 1.163, Test loss: 0.976, Test accuracy: 96.80
Round  30, Global train loss: 1.163, Global test loss: 0.968, Global test accuracy: 96.80
Round  31, Train loss: 1.280, Test loss: 0.982, Test accuracy: 96.60
Round  31, Global train loss: 1.280, Global test loss: 0.973, Global test accuracy: 96.86
Round  32, Train loss: 1.299, Test loss: 0.985, Test accuracy: 96.60
Round  32, Global train loss: 1.299, Global test loss: 0.982, Global test accuracy: 96.74
Round  33, Train loss: 1.274, Test loss: 0.984, Test accuracy: 96.88
Round  33, Global train loss: 1.274, Global test loss: 0.975, Global test accuracy: 97.20
Round  34, Train loss: 1.272, Test loss: 0.979, Test accuracy: 96.88
Round  34, Global train loss: 1.272, Global test loss: 0.975, Global test accuracy: 97.10
Round  35, Train loss: 1.274, Test loss: 0.983, Test accuracy: 96.58
Round  35, Global train loss: 1.274, Global test loss: 0.978, Global test accuracy: 96.70
Round  36, Train loss: 1.287, Test loss: 0.983, Test accuracy: 96.64
Round  36, Global train loss: 1.287, Global test loss: 0.984, Global test accuracy: 96.58
Round  37, Train loss: 1.285, Test loss: 0.987, Test accuracy: 96.34
Round  37, Global train loss: 1.285, Global test loss: 0.980, Global test accuracy: 96.60
Round  38, Train loss: 1.265, Test loss: 0.982, Test accuracy: 96.44
Round  38, Global train loss: 1.265, Global test loss: 0.977, Global test accuracy: 96.76
Round  39, Train loss: 1.143, Test loss: 0.976, Test accuracy: 96.50
Round  39, Global train loss: 1.143, Global test loss: 0.962, Global test accuracy: 96.70
Round  40, Train loss: 1.261, Test loss: 0.979, Test accuracy: 96.50
Round  40, Global train loss: 1.261, Global test loss: 0.973, Global test accuracy: 96.70
Round  41, Train loss: 1.293, Test loss: 0.985, Test accuracy: 96.00
Round  41, Global train loss: 1.293, Global test loss: 0.981, Global test accuracy: 96.70
Round  42, Train loss: 1.256, Test loss: 0.985, Test accuracy: 96.10
Round  42, Global train loss: 1.256, Global test loss: 0.978, Global test accuracy: 96.90
Round  43, Train loss: 1.156, Test loss: 0.977, Test accuracy: 96.58
Round  43, Global train loss: 1.156, Global test loss: 0.966, Global test accuracy: 97.24
Round  44, Train loss: 1.049, Test loss: 0.968, Test accuracy: 96.76
Round  44, Global train loss: 1.049, Global test loss: 0.954, Global test accuracy: 97.16
Round  45, Train loss: 1.257, Test loss: 0.978, Test accuracy: 96.42
Round  45, Global train loss: 1.257, Global test loss: 0.973, Global test accuracy: 96.32
Round  46, Train loss: 1.256, Test loss: 0.978, Test accuracy: 96.48
Round  46, Global train loss: 1.256, Global test loss: 0.971, Global test accuracy: 97.02
Round  47, Train loss: 1.262, Test loss: 0.984, Test accuracy: 96.14
Round  47, Global train loss: 1.262, Global test loss: 0.974, Global test accuracy: 96.92
Round  48, Train loss: 1.248, Test loss: 0.979, Test accuracy: 96.54
Round  48, Global train loss: 1.248, Global test loss: 0.971, Global test accuracy: 96.80
Round  49, Train loss: 1.251, Test loss: 0.983, Test accuracy: 96.32
Round  49, Global train loss: 1.251, Global test loss: 0.976, Global test accuracy: 96.96
Round  50, Train loss: 1.255, Test loss: 0.985, Test accuracy: 96.12
Round  50, Global train loss: 1.255, Global test loss: 0.977, Global test accuracy: 96.72
Round  51, Train loss: 1.039, Test loss: 0.972, Test accuracy: 96.66
Round  51, Global train loss: 1.039, Global test loss: 0.958, Global test accuracy: 96.90
Round  52, Train loss: 1.044, Test loss: 0.966, Test accuracy: 96.42
Round  52, Global train loss: 1.044, Global test loss: 0.956, Global test accuracy: 96.74
Round  53, Train loss: 1.141, Test loss: 0.970, Test accuracy: 96.64
Round  53, Global train loss: 1.141, Global test loss: 0.958, Global test accuracy: 97.02
Round  54, Train loss: 1.249, Test loss: 0.977, Test accuracy: 96.44
Round  54, Global train loss: 1.249, Global test loss: 0.971, Global test accuracy: 97.00
Round  55, Train loss: 1.027, Test loss: 0.968, Test accuracy: 96.58
Round  55, Global train loss: 1.027, Global test loss: 0.955, Global test accuracy: 96.96
Round  56, Train loss: 1.250, Test loss: 0.976, Test accuracy: 96.22
Round  56, Global train loss: 1.250, Global test loss: 0.969, Global test accuracy: 97.20
Round  57, Train loss: 1.152, Test loss: 0.983, Test accuracy: 95.96
Round  57, Global train loss: 1.152, Global test loss: 0.967, Global test accuracy: 96.66
Round  58, Train loss: 1.143, Test loss: 0.981, Test accuracy: 95.82
Round  58, Global train loss: 1.143, Global test loss: 0.972, Global test accuracy: 96.78
Round  59, Train loss: 1.227, Test loss: 0.986, Test accuracy: 95.80
Round  59, Global train loss: 1.227, Global test loss: 0.979, Global test accuracy: 96.18
Round  60, Train loss: 1.145, Test loss: 0.991, Test accuracy: 95.22
Round  60, Global train loss: 1.145, Global test loss: 0.975, Global test accuracy: 96.44
Round  61, Train loss: 1.130, Test loss: 0.977, Test accuracy: 96.10
Round  61, Global train loss: 1.130, Global test loss: 0.960, Global test accuracy: 97.02
Round  62, Train loss: 1.252, Test loss: 0.996, Test accuracy: 95.08
Round  62, Global train loss: 1.252, Global test loss: 0.986, Global test accuracy: 96.06
Round  63, Train loss: 1.228, Test loss: 0.992, Test accuracy: 95.90
Round  63, Global train loss: 1.228, Global test loss: 0.984, Global test accuracy: 96.48
Round  64, Train loss: 1.131, Test loss: 0.983, Test accuracy: 96.08
Round  64, Global train loss: 1.131, Global test loss: 0.967, Global test accuracy: 96.62
Round  65, Train loss: 1.231, Test loss: 0.996, Test accuracy: 95.18
Round  65, Global train loss: 1.231, Global test loss: 0.992, Global test accuracy: 95.64
Round  66, Train loss: 1.129, Test loss: 0.987, Test accuracy: 95.50
Round  66, Global train loss: 1.129, Global test loss: 0.978, Global test accuracy: 95.74
Round  67, Train loss: 1.212, Test loss: 0.996, Test accuracy: 95.24
Round  67, Global train loss: 1.212, Global test loss: 0.991, Global test accuracy: 95.38
Round  68, Train loss: 1.223, Test loss: 0.994, Test accuracy: 94.98
Round  68, Global train loss: 1.223, Global test loss: 0.982, Global test accuracy: 95.84
Round  69, Train loss: 1.112, Test loss: 0.990, Test accuracy: 95.62
Round  69, Global train loss: 1.112, Global test loss: 0.974, Global test accuracy: 96.12
Round  70, Train loss: 1.123, Test loss: 0.983, Test accuracy: 95.64
Round  70, Global train loss: 1.123, Global test loss: 0.976, Global test accuracy: 95.84
Round  71, Train loss: 1.221, Test loss: 1.004, Test accuracy: 94.78
Round  71, Global train loss: 1.221, Global test loss: 0.990, Global test accuracy: 95.96
Round  72, Train loss: 1.120, Test loss: 1.000, Test accuracy: 94.66
Round  72, Global train loss: 1.120, Global test loss: 0.982, Global test accuracy: 95.28
Round  73, Train loss: 1.208, Test loss: 1.011, Test accuracy: 94.32
Round  73, Global train loss: 1.208, Global test loss: 0.996, Global test accuracy: 95.44
Round  74, Train loss: 1.128, Test loss: 0.992, Test accuracy: 95.40
Round  74, Global train loss: 1.128, Global test loss: 0.974, Global test accuracy: 96.16
Round  75, Train loss: 1.210, Test loss: 0.999, Test accuracy: 94.76
Round  75, Global train loss: 1.210, Global test loss: 0.984, Global test accuracy: 95.96
Round  76, Train loss: 1.111, Test loss: 0.997, Test accuracy: 95.10
Round  76, Global train loss: 1.111, Global test loss: 0.976, Global test accuracy: 95.90
Round  77, Train loss: 1.116, Test loss: 1.002, Test accuracy: 94.52
Round  77, Global train loss: 1.116, Global test loss: 0.980, Global test accuracy: 95.60
Round  78, Train loss: 1.113, Test loss: 0.993, Test accuracy: 95.02
Round  78, Global train loss: 1.113, Global test loss: 0.973, Global test accuracy: 96.10
Round  79, Train loss: 1.099, Test loss: 1.002, Test accuracy: 94.42
Round  79, Global train loss: 1.099, Global test loss: 0.981, Global test accuracy: 95.24
Round  80, Train loss: 1.188, Test loss: 1.021, Test accuracy: 92.64
Round  80, Global train loss: 1.188, Global test loss: 1.011, Global test accuracy: 93.72
Round  81, Train loss: 1.095, Test loss: 0.995, Test accuracy: 94.70
Round  81, Global train loss: 1.095, Global test loss: 0.976, Global test accuracy: 95.56
Round  82, Train loss: 1.205, Test loss: 1.028, Test accuracy: 91.92
Round  82, Global train loss: 1.205, Global test loss: 1.015, Global test accuracy: 93.48
Round  83, Train loss: 1.193, Test loss: 1.016, Test accuracy: 93.36
Round  83, Global train loss: 1.193, Global test loss: 0.994, Global test accuracy: 95.04
Round  84, Train loss: 1.100, Test loss: 1.005, Test accuracy: 93.94
Round  84, Global train loss: 1.100, Global test loss: 1.001, Global test accuracy: 93.54
Round  85, Train loss: 1.107, Test loss: 0.988, Test accuracy: 94.94
Round  85, Global train loss: 1.107, Global test loss: 0.976, Global test accuracy: 95.64
Round  86, Train loss: 1.099, Test loss: 0.986, Test accuracy: 95.18
Round  86, Global train loss: 1.099, Global test loss: 0.974, Global test accuracy: 95.64
Round  87, Train loss: 1.180, Test loss: 1.011, Test accuracy: 93.36
Round  87, Global train loss: 1.180, Global test loss: 1.004, Global test accuracy: 94.04
Round  88, Train loss: 1.166, Test loss: 1.020, Test accuracy: 92.52
Round  88, Global train loss: 1.166, Global test loss: 1.014, Global test accuracy: 93.48
Round  89, Train loss: 1.176, Test loss: 1.034, Test accuracy: 91.60
Round  89, Global train loss: 1.176, Global test loss: 1.020, Global test accuracy: 92.92
Round  90, Train loss: 1.169, Test loss: 1.024, Test accuracy: 92.10
Round  90, Global train loss: 1.169, Global test loss: 1.004, Global test accuracy: 93.78/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  91, Train loss: 1.082, Test loss: 1.003, Test accuracy: 93.56
Round  91, Global train loss: 1.082, Global test loss: 0.981, Global test accuracy: 94.76
Round  92, Train loss: 1.067, Test loss: 1.000, Test accuracy: 93.64
Round  92, Global train loss: 1.067, Global test loss: 0.984, Global test accuracy: 94.54
Round  93, Train loss: 1.154, Test loss: 1.028, Test accuracy: 91.00
Round  93, Global train loss: 1.154, Global test loss: 1.030, Global test accuracy: 91.60
Round  94, Train loss: 1.082, Test loss: 0.999, Test accuracy: 93.84
Round  94, Global train loss: 1.082, Global test loss: 0.976, Global test accuracy: 95.44
Round  95, Train loss: 1.173, Test loss: 1.018, Test accuracy: 92.38
Round  95, Global train loss: 1.173, Global test loss: 1.005, Global test accuracy: 93.84
Round  96, Train loss: 1.153, Test loss: 1.038, Test accuracy: 90.70
Round  96, Global train loss: 1.153, Global test loss: 1.026, Global test accuracy: 91.78
Round  97, Train loss: 1.080, Test loss: 1.004, Test accuracy: 93.08
Round  97, Global train loss: 1.080, Global test loss: 0.977, Global test accuracy: 95.22
Round  98, Train loss: 1.156, Test loss: 1.029, Test accuracy: 90.90
Round  98, Global train loss: 1.156, Global test loss: 1.016, Global test accuracy: 92.44
Round  99, Train loss: 1.073, Test loss: 1.023, Test accuracy: 91.48
Round  99, Global train loss: 1.073, Global test loss: 1.006, Global test accuracy: 92.80
Final Round, Train loss: 1.099, Test loss: 1.014, Test accuracy: 91.98
Final Round, Global train loss: 1.099, Global test loss: 1.006, Global test accuracy: 92.80
Average accuracy final 10 rounds: 92.268
571.5116899013519
[1.1858067512512207, 2.1064929962158203, 3.0324971675872803, 3.9496359825134277, 4.870439767837524, 5.8007543087005615, 6.7262773513793945, 7.653765678405762, 8.566357851028442, 9.491541147232056, 10.417363166809082, 11.352285146713257, 12.28704023361206, 13.222585678100586, 14.146434783935547, 15.051676511764526, 15.982432126998901, 17.633596658706665, 19.306918621063232, 20.94014549255371, 22.578869581222534, 24.092276573181152, 25.769250869750977, 27.004753589630127, 28.46480917930603, 29.80552315711975, 31.120606184005737, 32.068928956985474, 32.97626304626465, 33.88277983665466, 34.80611038208008, 35.698930740356445, 36.647624492645264, 37.5448112487793, 38.45824980735779, 39.38629603385925, 40.30592942237854, 41.23107075691223, 42.162174701690674, 43.07023763656616, 43.974565744400024, 44.915651082992554, 45.840017318725586, 46.75472354888916, 47.67183804512024, 48.661808252334595, 49.57753396034241, 50.47521758079529, 51.37012243270874, 52.2726309299469, 53.191972732543945, 54.11084604263306, 55.04373526573181, 55.97806978225708, 56.906832456588745, 57.82383751869202, 58.73127770423889, 59.637240409851074, 60.538703203201294, 61.46377468109131, 62.41961669921875, 63.35507273674011, 64.27904605865479, 65.19852232933044, 66.14035749435425, 67.06953763961792, 67.98740148544312, 68.91083359718323, 69.83686351776123, 70.77242612838745, 71.7054603099823, 72.62365508079529, 73.52123594284058, 74.42966961860657, 75.3397765159607, 76.24560904502869, 77.16705226898193, 78.08076977729797, 79.23905086517334, 80.14768242835999, 81.45050573348999, 82.79970812797546, 84.23668193817139, 85.66729402542114, 86.57784223556519, 87.69462299346924, 88.61318588256836, 89.53468537330627, 90.46948838233948, 91.39393305778503, 92.46875476837158, 93.40991830825806, 94.32274842262268, 95.22445154190063, 96.14873909950256, 97.07315135002136, 98.22749781608582, 99.13977313041687, 100.06389904022217, 100.96395993232727, 102.65346145629883]
[51.94, 82.7, 89.0, 90.58, 94.14, 95.24, 95.68, 95.82, 96.06, 96.18, 96.22, 96.4, 96.48, 96.52, 96.52, 96.6, 96.56, 96.68, 96.72, 96.84, 96.84, 96.82, 96.7, 96.48, 96.46, 96.6, 96.94, 96.62, 96.7, 96.54, 96.8, 96.6, 96.6, 96.88, 96.88, 96.58, 96.64, 96.34, 96.44, 96.5, 96.5, 96.0, 96.1, 96.58, 96.76, 96.42, 96.48, 96.14, 96.54, 96.32, 96.12, 96.66, 96.42, 96.64, 96.44, 96.58, 96.22, 95.96, 95.82, 95.8, 95.22, 96.1, 95.08, 95.9, 96.08, 95.18, 95.5, 95.24, 94.98, 95.62, 95.64, 94.78, 94.66, 94.32, 95.4, 94.76, 95.1, 94.52, 95.02, 94.42, 92.64, 94.7, 91.92, 93.36, 93.94, 94.94, 95.18, 93.36, 92.52, 91.6, 92.1, 93.56, 93.64, 91.0, 93.84, 92.38, 90.7, 93.08, 90.9, 91.48, 91.98]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fedpac_copsl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist,  filter_alg: loss_psl, level_n_system: 0.8 , level_n_lowerb:0.4  

   Client 2, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550021 (local), 549696 (global); Percentage 99.94 (549696/550021)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 1.626, Test loss: 1.597, Test accuracy: 41.38
Round   0, Global train loss: 1.626, Global test loss: 1.597, Global test accuracy: 40.36
Round   1, Train loss: 1.593, Test loss: 1.566, Test accuracy: 64.52
Round   1, Global train loss: 1.593, Global test loss: 1.566, Global test accuracy: 65.58
Round   2, Train loss: 1.558, Test loss: 1.472, Test accuracy: 64.60
Round   2, Global train loss: 1.558, Global test loss: 1.472, Global test accuracy: 65.44
Round   3, Train loss: 1.468, Test loss: 1.307, Test accuracy: 71.40
Round   3, Global train loss: 1.468, Global test loss: 1.301, Global test accuracy: 72.80
Round   4, Train loss: 1.373, Test loss: 1.162, Test accuracy: 88.42
Round   4, Global train loss: 1.373, Global test loss: 1.151, Global test accuracy: 91.16
Round   5, Train loss: 1.301, Test loss: 1.070, Test accuracy: 93.16
Round   5, Global train loss: 1.301, Global test loss: 1.058, Global test accuracy: 94.50
Round   6, Train loss: 1.270, Test loss: 1.033, Test accuracy: 94.52
Round   6, Global train loss: 1.270, Global test loss: 1.024, Global test accuracy: 95.26
Round   7, Train loss: 1.257, Test loss: 1.016, Test accuracy: 95.08
Round   7, Global train loss: 1.257, Global test loss: 1.008, Global test accuracy: 95.60
Round   8, Train loss: 1.249, Test loss: 1.007, Test accuracy: 95.58
Round   8, Global train loss: 1.249, Global test loss: 0.998, Global test accuracy: 96.28
Round   9, Train loss: 1.244, Test loss: 1.000, Test accuracy: 95.86
Round   9, Global train loss: 1.244, Global test loss: 0.991, Global test accuracy: 96.44
Round  10, Train loss: 1.198, Test loss: 0.997, Test accuracy: 96.24
Round  10, Global train loss: 1.198, Global test loss: 0.983, Global test accuracy: 96.50
Traceback (most recent call last):
  File "main_fedpac_copsl.py", line 280, in <module>
    w_local, loss, indd, class_center_local, class_num, noisy_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys,
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2559, in train
    self.filter_data(net, local_net, iter2-head_eps+1, local_eps-head_eps+1, concept_matrix_local)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2396, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist, level_n_system: 0.8 , level_n_lowerb:0.8  

   Client 3, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.609, Test loss: 1.604, Test accuracy: 41.62
Round   0, Global train loss: 1.609, Global test loss: 1.604, Global test accuracy: 42.96
Round   1, Train loss: 1.572, Test loss: 1.551, Test accuracy: 44.88
Round   1, Global train loss: 1.572, Global test loss: 1.537, Global test accuracy: 46.26
Round   2, Train loss: 1.494, Test loss: 1.498, Test accuracy: 61.36
Round   2, Global train loss: 1.494, Global test loss: 1.494, Global test accuracy: 81.42
Round   3, Train loss: 1.419, Test loss: 1.432, Test accuracy: 60.06
Round   3, Global train loss: 1.419, Global test loss: 1.261, Global test accuracy: 72.72
Round   4, Train loss: 1.595, Test loss: 1.484, Test accuracy: 59.58
Round   4, Global train loss: 1.595, Global test loss: 1.570, Global test accuracy: 60.20
Round   5, Train loss: 1.570, Test loss: 1.448, Test accuracy: 62.50
Round   5, Global train loss: 1.570, Global test loss: 1.465, Global test accuracy: 72.58
Round   6, Train loss: 1.480, Test loss: 1.411, Test accuracy: 63.02
Round   6, Global train loss: 1.480, Global test loss: 1.410, Global test accuracy: 68.76
Round   7, Train loss: 1.277, Test loss: 1.364, Test accuracy: 67.60
Round   7, Global train loss: 1.277, Global test loss: 1.215, Global test accuracy: 87.12
Round   8, Train loss: 1.516, Test loss: 1.370, Test accuracy: 65.62
Round   8, Global train loss: 1.516, Global test loss: 1.289, Global test accuracy: 77.70
Round   9, Train loss: 1.506, Test loss: 1.365, Test accuracy: 63.60
Round   9, Global train loss: 1.506, Global test loss: 1.275, Global test accuracy: 72.66
Round  10, Train loss: 1.253, Test loss: 1.347, Test accuracy: 65.00
Round  10, Global train loss: 1.253, Global test loss: 1.157, Global test accuracy: 82.24
Round  11, Train loss: 1.537, Test loss: 1.348, Test accuracy: 64.74
Round  11, Global train loss: 1.537, Global test loss: 1.321, Global test accuracy: 85.36
Round  12, Train loss: 1.380, Test loss: 1.343, Test accuracy: 64.62
Round  12, Global train loss: 1.380, Global test loss: 1.200, Global test accuracy: 74.96
Round  13, Train loss: 1.393, Test loss: 1.339, Test accuracy: 63.64
Round  13, Global train loss: 1.393, Global test loss: 1.261, Global test accuracy: 71.64
Round  14, Train loss: 1.500, Test loss: 1.336, Test accuracy: 63.74
Round  14, Global train loss: 1.500, Global test loss: 1.331, Global test accuracy: 85.82
Round  15, Train loss: 1.260, Test loss: 1.330, Test accuracy: 65.10
Round  15, Global train loss: 1.260, Global test loss: 1.240, Global test accuracy: 75.82
Round  16, Train loss: 1.322, Test loss: 1.336, Test accuracy: 64.02
Round  16, Global train loss: 1.322, Global test loss: 1.126, Global test accuracy: 80.34
Round  17, Train loss: 1.387, Test loss: 1.334, Test accuracy: 63.86
Round  17, Global train loss: 1.387, Global test loss: 1.271, Global test accuracy: 78.66
Round  18, Train loss: 1.438, Test loss: 1.340, Test accuracy: 62.62
Round  18, Global train loss: 1.438, Global test loss: 1.211, Global test accuracy: 82.44
Round  19, Train loss: 1.399, Test loss: 1.348, Test accuracy: 60.34
Round  19, Global train loss: 1.399, Global test loss: 1.229, Global test accuracy: 75.40
Round  20, Train loss: 1.288, Test loss: 1.349, Test accuracy: 59.76
Round  20, Global train loss: 1.288, Global test loss: 1.161, Global test accuracy: 79.32
Round  21, Train loss: 1.270, Test loss: 1.349, Test accuracy: 60.04
Round  21, Global train loss: 1.270, Global test loss: 1.145, Global test accuracy: 83.14
Round  22, Train loss: 1.374, Test loss: 1.342, Test accuracy: 61.06
Round  22, Global train loss: 1.374, Global test loss: 1.201, Global test accuracy: 80.62
Round  23, Train loss: 1.353, Test loss: 1.333, Test accuracy: 61.74
Round  23, Global train loss: 1.353, Global test loss: 1.189, Global test accuracy: 85.66
Round  24, Train loss: 1.233, Test loss: 1.336, Test accuracy: 61.02
Round  24, Global train loss: 1.233, Global test loss: 1.122, Global test accuracy: 83.50
Round  25, Train loss: 1.260, Test loss: 1.339, Test accuracy: 60.38
Round  25, Global train loss: 1.260, Global test loss: 1.187, Global test accuracy: 79.82
Round  26, Train loss: 1.194, Test loss: 1.346, Test accuracy: 59.54
Round  26, Global train loss: 1.194, Global test loss: 1.143, Global test accuracy: 75.90
Round  27, Train loss: 1.378, Test loss: 1.338, Test accuracy: 59.74
Round  27, Global train loss: 1.378, Global test loss: 1.246, Global test accuracy: 86.82
Round  28, Train loss: 1.172, Test loss: 1.336, Test accuracy: 59.86
Round  28, Global train loss: 1.172, Global test loss: 1.133, Global test accuracy: 77.02
Round  29, Train loss: 1.271, Test loss: 1.330, Test accuracy: 60.46
Round  29, Global train loss: 1.271, Global test loss: 1.178, Global test accuracy: 81.04
Round  30, Train loss: 1.267, Test loss: 1.325, Test accuracy: 60.24
Round  30, Global train loss: 1.267, Global test loss: 1.158, Global test accuracy: 74.42
Round  31, Train loss: 1.292, Test loss: 1.323, Test accuracy: 59.80
Round  31, Global train loss: 1.292, Global test loss: 1.173, Global test accuracy: 74.68
Round  32, Train loss: 1.088, Test loss: 1.330, Test accuracy: 58.88
Round  32, Global train loss: 1.088, Global test loss: 1.054, Global test accuracy: 86.78
Round  33, Train loss: 1.155, Test loss: 1.329, Test accuracy: 59.22
Round  33, Global train loss: 1.155, Global test loss: 1.068, Global test accuracy: 87.84
Round  34, Train loss: 1.294, Test loss: 1.336, Test accuracy: 58.28
Round  34, Global train loss: 1.294, Global test loss: 1.210, Global test accuracy: 73.78
Round  35, Train loss: 1.247, Test loss: 1.339, Test accuracy: 57.14
Round  35, Global train loss: 1.247, Global test loss: 1.140, Global test accuracy: 83.28
Round  36, Train loss: 1.238, Test loss: 1.339, Test accuracy: 56.82
Round  36, Global train loss: 1.238, Global test loss: 1.134, Global test accuracy: 77.62
Round  37, Train loss: 1.201, Test loss: 1.337, Test accuracy: 56.72
Round  37, Global train loss: 1.201, Global test loss: 1.113, Global test accuracy: 83.48
Round  38, Train loss: 1.122, Test loss: 1.341, Test accuracy: 56.48
Round  38, Global train loss: 1.122, Global test loss: 1.086, Global test accuracy: 85.18
Round  39, Train loss: 1.238, Test loss: 1.343, Test accuracy: 56.18
Round  39, Global train loss: 1.238, Global test loss: 1.214, Global test accuracy: 71.88
Round  40, Train loss: 1.167, Test loss: 1.345, Test accuracy: 56.06
Round  40, Global train loss: 1.167, Global test loss: 1.184, Global test accuracy: 74.12
Round  41, Train loss: 1.211, Test loss: 1.344, Test accuracy: 55.94
Round  41, Global train loss: 1.211, Global test loss: 1.172, Global test accuracy: 77.68
Round  42, Train loss: 1.117, Test loss: 1.340, Test accuracy: 56.50
Round  42, Global train loss: 1.117, Global test loss: 1.086, Global test accuracy: 83.64
Round  43, Train loss: 1.119, Test loss: 1.342, Test accuracy: 56.24
Round  43, Global train loss: 1.119, Global test loss: 1.099, Global test accuracy: 81.04
Round  44, Train loss: 1.240, Test loss: 1.351, Test accuracy: 54.84
Round  44, Global train loss: 1.240, Global test loss: 1.207, Global test accuracy: 75.52
Round  45, Train loss: 1.215, Test loss: 1.353, Test accuracy: 54.24
Round  45, Global train loss: 1.215, Global test loss: 1.226, Global test accuracy: 70.00
Round  46, Train loss: 1.215, Test loss: 1.358, Test accuracy: 54.04
Round  46, Global train loss: 1.215, Global test loss: 1.178, Global test accuracy: 76.74
Round  47, Train loss: 1.129, Test loss: 1.357, Test accuracy: 54.18
Round  47, Global train loss: 1.129, Global test loss: 1.179, Global test accuracy: 73.82
Round  48, Train loss: 1.157, Test loss: 1.362, Test accuracy: 53.56
Round  48, Global train loss: 1.157, Global test loss: 1.153, Global test accuracy: 75.16
Round  49, Train loss: 1.127, Test loss: 1.368, Test accuracy: 52.48
Round  49, Global train loss: 1.127, Global test loss: 1.121, Global test accuracy: 77.86
Round  50, Train loss: 1.127, Test loss: 1.370, Test accuracy: 52.14
Round  50, Global train loss: 1.127, Global test loss: 1.150, Global test accuracy: 77.44
Round  51, Train loss: 1.197, Test loss: 1.366, Test accuracy: 52.36
Round  51, Global train loss: 1.197, Global test loss: 1.272, Global test accuracy: 66.94
Round  52, Train loss: 1.124, Test loss: 1.366, Test accuracy: 52.10
Round  52, Global train loss: 1.124, Global test loss: 1.117, Global test accuracy: 83.70
Round  53, Train loss: 1.152, Test loss: 1.368, Test accuracy: 51.96
Round  53, Global train loss: 1.152, Global test loss: 1.181, Global test accuracy: 75.04
Round  54, Train loss: 1.101, Test loss: 1.368, Test accuracy: 52.26
Round  54, Global train loss: 1.101, Global test loss: 1.082, Global test accuracy: 83.84
Round  55, Train loss: 1.109, Test loss: 1.371, Test accuracy: 51.86
Round  55, Global train loss: 1.109, Global test loss: 1.186, Global test accuracy: 73.10
Round  56, Train loss: 1.140, Test loss: 1.371, Test accuracy: 51.62
Round  56, Global train loss: 1.140, Global test loss: 1.170, Global test accuracy: 75.54
Round  57, Train loss: 1.116, Test loss: 1.369, Test accuracy: 51.86
Round  57, Global train loss: 1.116, Global test loss: 1.210, Global test accuracy: 71.04
Round  58, Train loss: 1.146, Test loss: 1.367, Test accuracy: 52.08
Round  58, Global train loss: 1.146, Global test loss: 1.210, Global test accuracy: 72.94
Round  59, Train loss: 1.065, Test loss: 1.372, Test accuracy: 51.68
Round  59, Global train loss: 1.065, Global test loss: 1.128, Global test accuracy: 80.18
Round  60, Train loss: 1.039, Test loss: 1.373, Test accuracy: 51.62
Round  60, Global train loss: 1.039, Global test loss: 1.073, Global test accuracy: 83.82
Round  61, Train loss: 1.056, Test loss: 1.374, Test accuracy: 51.50
Round  61, Global train loss: 1.056, Global test loss: 1.114, Global test accuracy: 80.44
Round  62, Train loss: 1.091, Test loss: 1.374, Test accuracy: 51.68
Round  62, Global train loss: 1.091, Global test loss: 1.049, Global test accuracy: 86.24
Round  63, Train loss: 1.017, Test loss: 1.375, Test accuracy: 51.60
Round  63, Global train loss: 1.017, Global test loss: 1.012, Global test accuracy: 90.66
Round  64, Train loss: 1.089, Test loss: 1.374, Test accuracy: 51.64
Round  64, Global train loss: 1.089, Global test loss: 1.062, Global test accuracy: 85.02
Round  65, Train loss: 1.101, Test loss: 1.380, Test accuracy: 50.96
Round  65, Global train loss: 1.101, Global test loss: 1.185, Global test accuracy: 74.00
Round  66, Train loss: 1.036, Test loss: 1.377, Test accuracy: 51.40
Round  66, Global train loss: 1.036, Global test loss: 1.085, Global test accuracy: 85.10
Round  67, Train loss: 1.059, Test loss: 1.378, Test accuracy: 51.14
Round  67, Global train loss: 1.059, Global test loss: 1.089, Global test accuracy: 82.10
Round  68, Train loss: 1.035, Test loss: 1.378, Test accuracy: 51.04
Round  68, Global train loss: 1.035, Global test loss: 0.996, Global test accuracy: 91.76
Round  69, Train loss: 1.067, Test loss: 1.381, Test accuracy: 50.74
Round  69, Global train loss: 1.067, Global test loss: 1.123, Global test accuracy: 79.56
Round  70, Train loss: 1.075, Test loss: 1.384, Test accuracy: 50.30
Round  70, Global train loss: 1.075, Global test loss: 1.268, Global test accuracy: 62.88
Round  71, Train loss: 1.059, Test loss: 1.384, Test accuracy: 50.22
Round  71, Global train loss: 1.059, Global test loss: 1.122, Global test accuracy: 79.40
Round  72, Train loss: 1.031, Test loss: 1.386, Test accuracy: 50.08
Round  72, Global train loss: 1.031, Global test loss: 1.088, Global test accuracy: 84.08
Round  73, Train loss: 1.077, Test loss: 1.384, Test accuracy: 50.32
Round  73, Global train loss: 1.077, Global test loss: 1.067, Global test accuracy: 84.10
Round  74, Train loss: 1.087, Test loss: 1.383, Test accuracy: 50.60
Round  74, Global train loss: 1.087, Global test loss: 1.164, Global test accuracy: 75.56
Round  75, Train loss: 1.103, Test loss: 1.386, Test accuracy: 50.04
Round  75, Global train loss: 1.103, Global test loss: 1.217, Global test accuracy: 69.34
Round  76, Train loss: 1.081, Test loss: 1.387, Test accuracy: 50.16
Round  76, Global train loss: 1.081, Global test loss: 1.133, Global test accuracy: 78.82
Round  77, Train loss: 0.996, Test loss: 1.386, Test accuracy: 50.22
Round  77, Global train loss: 0.996, Global test loss: 0.997, Global test accuracy: 91.36
Round  78, Train loss: 1.074, Test loss: 1.385, Test accuracy: 50.40
Round  78, Global train loss: 1.074, Global test loss: 1.064, Global test accuracy: 84.78
Round  79, Train loss: 1.020, Test loss: 1.383, Test accuracy: 50.98
Round  79, Global train loss: 1.020, Global test loss: 1.074, Global test accuracy: 83.84
Round  80, Train loss: 1.053, Test loss: 1.383, Test accuracy: 51.04
Round  80, Global train loss: 1.053, Global test loss: 1.080, Global test accuracy: 83.28
Round  81, Train loss: 1.049, Test loss: 1.385, Test accuracy: 50.64
Round  81, Global train loss: 1.049, Global test loss: 1.061, Global test accuracy: 84.96
Round  82, Train loss: 1.069, Test loss: 1.388, Test accuracy: 50.36
Round  82, Global train loss: 1.069, Global test loss: 1.254, Global test accuracy: 64.10
Round  83, Train loss: 1.097, Test loss: 1.388, Test accuracy: 50.42
Round  83, Global train loss: 1.097, Global test loss: 1.168, Global test accuracy: 75.00
Round  84, Train loss: 1.026, Test loss: 1.391, Test accuracy: 49.94
Round  84, Global train loss: 1.026, Global test loss: 1.089, Global test accuracy: 82.06
Round  85, Train loss: 1.097, Test loss: 1.392, Test accuracy: 49.64
Round  85, Global train loss: 1.097, Global test loss: 1.148, Global test accuracy: 77.30
Round  86, Train loss: 1.069, Test loss: 1.390, Test accuracy: 49.80
Round  86, Global train loss: 1.069, Global test loss: 1.052, Global test accuracy: 85.62
Round  87, Train loss: 1.052, Test loss: 1.389, Test accuracy: 49.78
Round  87, Global train loss: 1.052, Global test loss: 1.067, Global test accuracy: 84.88
Round  88, Train loss: 1.046, Test loss: 1.393, Test accuracy: 49.28
Round  88, Global train loss: 1.046, Global test loss: 1.073, Global test accuracy: 85.12
Round  89, Train loss: 1.085, Test loss: 1.396, Test accuracy: 49.20
Round  89, Global train loss: 1.085, Global test loss: 1.178, Global test accuracy: 73.42
Round  90, Train loss: 1.088, Test loss: 1.395, Test accuracy: 49.42
Round  90, Global train loss: 1.088, Global test loss: 1.151, Global test accuracy: 75.72
Round  91, Train loss: 1.085, Test loss: 1.396, Test accuracy: 49.20
Round  91, Global train loss: 1.085, Global test loss: 1.174, Global test accuracy: 73.28
Round  92, Train loss: 1.019, Test loss: 1.392, Test accuracy: 49.56
Round  92, Global train loss: 1.019, Global test loss: 1.079, Global test accuracy: 83.90
Round  93, Train loss: 1.051, Test loss: 1.395, Test accuracy: 49.00
Round  93, Global train loss: 1.051, Global test loss: 1.117, Global test accuracy: 79.32/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Train loss: 1.080, Test loss: 1.400, Test accuracy: 48.34
Round  94, Global train loss: 1.080, Global test loss: 1.225, Global test accuracy: 68.38
Round  95, Train loss: 1.044, Test loss: 1.399, Test accuracy: 48.54
Round  95, Global train loss: 1.044, Global test loss: 1.081, Global test accuracy: 82.54
Round  96, Train loss: 0.999, Test loss: 1.400, Test accuracy: 48.62
Round  96, Global train loss: 0.999, Global test loss: 1.010, Global test accuracy: 89.76
Round  97, Train loss: 1.065, Test loss: 1.399, Test accuracy: 48.74
Round  97, Global train loss: 1.065, Global test loss: 1.158, Global test accuracy: 74.54
Round  98, Train loss: 1.063, Test loss: 1.396, Test accuracy: 49.26
Round  98, Global train loss: 1.063, Global test loss: 1.156, Global test accuracy: 76.20
Round  99, Train loss: 1.005, Test loss: 1.397, Test accuracy: 49.34
Round  99, Global train loss: 1.005, Global test loss: 1.074, Global test accuracy: 83.38
Final Round, Train loss: 1.049, Test loss: 1.396, Test accuracy: 49.40
Final Round, Global train loss: 1.049, Global test loss: 1.074, Global test accuracy: 83.38
Average accuracy final 10 rounds: 49.002 

Average global accuracy final 10 rounds: 78.70199999999998 

599.1556725502014
[0.9165174961090088, 1.8330349922180176, 2.574385166168213, 3.315735340118408, 4.071730375289917, 4.827725410461426, 5.67325496673584, 6.518784523010254, 7.2708539962768555, 8.022923469543457, 8.767535924911499, 9.512148380279541, 10.259230136871338, 11.006311893463135, 11.87218952178955, 12.738067150115967, 13.489335536956787, 14.240603923797607, 14.992548942565918, 15.744493961334229, 16.490004539489746, 17.235515117645264, 17.98036789894104, 18.725220680236816, 19.469950199127197, 20.214679718017578, 20.95172095298767, 21.688762187957764, 22.435291290283203, 23.181820392608643, 23.936476945877075, 24.691133499145508, 25.459129095077515, 26.22712469100952, 26.99345850944519, 27.75979232788086, 28.530139684677124, 29.30048704147339, 30.070581912994385, 30.84067678451538, 31.606645822525024, 32.37261486053467, 33.13968539237976, 33.90675592422485, 34.674320697784424, 35.441885471343994, 36.21485924720764, 36.98783302307129, 37.76051473617554, 38.533196449279785, 39.30360531806946, 40.07401418685913, 40.84902596473694, 41.624037742614746, 42.39576315879822, 43.16748857498169, 43.93587064743042, 44.70425271987915, 45.47926712036133, 46.254281520843506, 47.0308895111084, 47.80749750137329, 48.57358956336975, 49.33968162536621, 50.106508016586304, 50.8733344078064, 51.63067650794983, 52.38801860809326, 53.14737796783447, 53.906737327575684, 54.66136980056763, 55.41600227355957, 56.19336938858032, 56.970736503601074, 57.75252604484558, 58.53431558609009, 59.304150342941284, 60.07398509979248, 60.82666611671448, 61.579347133636475, 62.321420669555664, 63.06349420547485, 63.81112003326416, 64.55874586105347, 65.30929207801819, 66.05983829498291, 66.83516120910645, 67.61048412322998, 68.3630006313324, 69.11551713943481, 69.86540222167969, 70.61528730392456, 71.35312557220459, 72.09096384048462, 72.84048748016357, 73.59001111984253, 74.33239579200745, 75.07478046417236, 75.82518219947815, 76.57558393478394, 77.31769013404846, 78.05979633331299, 78.82989120483398, 79.59998607635498, 80.38290238380432, 81.16581869125366, 81.93350172042847, 82.70118474960327, 83.46496772766113, 84.228750705719, 85.00005102157593, 85.77135133743286, 86.55280232429504, 87.33425331115723, 88.1010103225708, 88.86776733398438, 89.66178846359253, 90.45580959320068, 91.21080899238586, 91.96580839157104, 92.71772766113281, 93.46964693069458, 94.23748421669006, 95.00532150268555, 95.7744140625, 96.54350662231445, 97.31209874153137, 98.08069086074829, 98.85670828819275, 99.6327257156372, 100.40004658699036, 101.1673674583435, 101.93177342414856, 102.69617938995361, 103.46503591537476, 104.2338924407959, 105.00943303108215, 105.78497362136841, 106.55926561355591, 107.33355760574341, 108.09375286102295, 108.85394811630249, 109.62524843215942, 110.39654874801636, 111.17734932899475, 111.95814990997314, 112.73410773277283, 113.51006555557251, 114.25127053260803, 114.99247550964355, 115.7374963760376, 116.48251724243164, 117.22951579093933, 117.97651433944702, 118.74032139778137, 119.50412845611572, 120.2849383354187, 121.06574821472168, 121.83700942993164, 122.6082706451416, 123.40051245689392, 124.19275426864624, 124.96062207221985, 125.72848987579346, 126.49975943565369, 127.27102899551392, 128.0440649986267, 128.8171010017395, 129.58185124397278, 130.34660148620605, 131.10276317596436, 131.85892486572266, 132.63037943840027, 133.40183401107788, 134.15778279304504, 134.9137315750122, 135.67514896392822, 136.43656635284424, 137.20351910591125, 137.97047185897827, 138.73345804214478, 139.49644422531128, 140.27009677886963, 141.04374933242798, 141.80873560905457, 142.57372188568115, 143.3186821937561, 144.06364250183105, 144.80823349952698, 145.5528244972229, 146.31344079971313, 147.07405710220337, 147.83236479759216, 148.59067249298096, 149.37133049964905, 150.15198850631714, 150.92443871498108, 151.69688892364502, 152.47652554512024, 153.25616216659546, 154.79409503936768, 156.3320279121399]
[41.62, 41.62, 44.88, 44.88, 61.36, 61.36, 60.06, 60.06, 59.58, 59.58, 62.5, 62.5, 63.02, 63.02, 67.6, 67.6, 65.62, 65.62, 63.6, 63.6, 65.0, 65.0, 64.74, 64.74, 64.62, 64.62, 63.64, 63.64, 63.74, 63.74, 65.1, 65.1, 64.02, 64.02, 63.86, 63.86, 62.62, 62.62, 60.34, 60.34, 59.76, 59.76, 60.04, 60.04, 61.06, 61.06, 61.74, 61.74, 61.02, 61.02, 60.38, 60.38, 59.54, 59.54, 59.74, 59.74, 59.86, 59.86, 60.46, 60.46, 60.24, 60.24, 59.8, 59.8, 58.88, 58.88, 59.22, 59.22, 58.28, 58.28, 57.14, 57.14, 56.82, 56.82, 56.72, 56.72, 56.48, 56.48, 56.18, 56.18, 56.06, 56.06, 55.94, 55.94, 56.5, 56.5, 56.24, 56.24, 54.84, 54.84, 54.24, 54.24, 54.04, 54.04, 54.18, 54.18, 53.56, 53.56, 52.48, 52.48, 52.14, 52.14, 52.36, 52.36, 52.1, 52.1, 51.96, 51.96, 52.26, 52.26, 51.86, 51.86, 51.62, 51.62, 51.86, 51.86, 52.08, 52.08, 51.68, 51.68, 51.62, 51.62, 51.5, 51.5, 51.68, 51.68, 51.6, 51.6, 51.64, 51.64, 50.96, 50.96, 51.4, 51.4, 51.14, 51.14, 51.04, 51.04, 50.74, 50.74, 50.3, 50.3, 50.22, 50.22, 50.08, 50.08, 50.32, 50.32, 50.6, 50.6, 50.04, 50.04, 50.16, 50.16, 50.22, 50.22, 50.4, 50.4, 50.98, 50.98, 51.04, 51.04, 50.64, 50.64, 50.36, 50.36, 50.42, 50.42, 49.94, 49.94, 49.64, 49.64, 49.8, 49.8, 49.78, 49.78, 49.28, 49.28, 49.2, 49.2, 49.42, 49.42, 49.2, 49.2, 49.56, 49.56, 49.0, 49.0, 48.34, 48.34, 48.54, 48.54, 48.62, 48.62, 48.74, 48.74, 49.26, 49.26, 49.34, 49.34, 49.4, 49.4]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.8 , level_n_lowerb:0.8  

   Client 8, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.608, Test loss: 1.605, Test accuracy: 21.72
Round   0, Global train loss: 1.608, Global test loss: 1.605, Global test accuracy: 20.00
Round   1, Train loss: 1.600, Test loss: 1.591, Test accuracy: 55.24
Round   1, Global train loss: 1.600, Global test loss: 1.587, Global test accuracy: 75.62
Round   2, Train loss: 1.567, Test loss: 1.529, Test accuracy: 63.76
Round   2, Global train loss: 1.567, Global test loss: 1.512, Global test accuracy: 81.76
Round   3, Train loss: 1.472, Test loss: 1.453, Test accuracy: 63.50
Round   3, Global train loss: 1.472, Global test loss: 1.289, Global test accuracy: 90.20
Round   4, Train loss: 1.553, Test loss: 1.330, Test accuracy: 73.84
Round   4, Global train loss: 1.553, Global test loss: 1.205, Global test accuracy: 93.42
Round   5, Train loss: 1.538, Test loss: 1.281, Test accuracy: 73.94
Round   5, Global train loss: 1.538, Global test loss: 1.144, Global test accuracy: 93.42
Round   6, Train loss: 1.565, Test loss: 1.200, Test accuracy: 84.10
Round   6, Global train loss: 1.565, Global test loss: 1.213, Global test accuracy: 84.00
Round   7, Train loss: 1.407, Test loss: 1.162, Test accuracy: 87.62
Round   7, Global train loss: 1.407, Global test loss: 1.104, Global test accuracy: 92.40
Round   8, Train loss: 1.512, Test loss: 1.149, Test accuracy: 87.42
Round   8, Global train loss: 1.512, Global test loss: 1.089, Global test accuracy: 91.92
Round   9, Train loss: 1.521, Test loss: 1.147, Test accuracy: 87.58
Round   9, Global train loss: 1.521, Global test loss: 1.070, Global test accuracy: 93.42
Round  10, Train loss: 1.404, Test loss: 1.142, Test accuracy: 87.02
Round  10, Global train loss: 1.404, Global test loss: 1.049, Global test accuracy: 92.98
Round  11, Train loss: 1.338, Test loss: 1.129, Test accuracy: 86.68
Round  11, Global train loss: 1.338, Global test loss: 1.016, Global test accuracy: 94.08
Round  12, Train loss: 1.183, Test loss: 1.118, Test accuracy: 86.70
Round  12, Global train loss: 1.183, Global test loss: 0.982, Global test accuracy: 95.24
Round  13, Train loss: 1.546, Test loss: 1.116, Test accuracy: 85.04
Round  13, Global train loss: 1.546, Global test loss: 1.103, Global test accuracy: 84.52
Round  14, Train loss: 1.313, Test loss: 1.107, Test accuracy: 84.32
Round  14, Global train loss: 1.313, Global test loss: 1.000, Global test accuracy: 94.04
Round  15, Train loss: 1.385, Test loss: 1.106, Test accuracy: 83.78
Round  15, Global train loss: 1.385, Global test loss: 1.017, Global test accuracy: 92.58
Round  16, Train loss: 1.170, Test loss: 1.103, Test accuracy: 83.74
Round  16, Global train loss: 1.170, Global test loss: 0.972, Global test accuracy: 95.38
Round  17, Train loss: 1.532, Test loss: 1.088, Test accuracy: 84.44
Round  17, Global train loss: 1.532, Global test loss: 1.045, Global test accuracy: 89.34
Round  18, Train loss: 1.318, Test loss: 1.095, Test accuracy: 83.70
Round  18, Global train loss: 1.318, Global test loss: 1.012, Global test accuracy: 92.16
Round  19, Train loss: 1.300, Test loss: 1.093, Test accuracy: 83.66
Round  19, Global train loss: 1.300, Global test loss: 0.999, Global test accuracy: 92.70
Round  20, Train loss: 1.314, Test loss: 1.098, Test accuracy: 83.42
Round  20, Global train loss: 1.314, Global test loss: 1.047, Global test accuracy: 88.60
Round  21, Train loss: 1.490, Test loss: 1.104, Test accuracy: 82.90
Round  21, Global train loss: 1.490, Global test loss: 1.122, Global test accuracy: 81.34
Round  22, Train loss: 1.300, Test loss: 1.111, Test accuracy: 82.10
Round  22, Global train loss: 1.300, Global test loss: 1.011, Global test accuracy: 91.98
Round  23, Train loss: 1.490, Test loss: 1.112, Test accuracy: 81.74
Round  23, Global train loss: 1.490, Global test loss: 1.149, Global test accuracy: 78.78
Round  24, Train loss: 1.451, Test loss: 1.125, Test accuracy: 80.70
Round  24, Global train loss: 1.451, Global test loss: 1.194, Global test accuracy: 74.18
Round  25, Train loss: 1.447, Test loss: 1.148, Test accuracy: 77.28
Round  25, Global train loss: 1.447, Global test loss: 1.219, Global test accuracy: 70.58
Round  26, Train loss: 1.154, Test loss: 1.165, Test accuracy: 75.14
Round  26, Global train loss: 1.154, Global test loss: 0.998, Global test accuracy: 92.22
Round  27, Train loss: 1.474, Test loss: 1.172, Test accuracy: 74.12
Round  27, Global train loss: 1.474, Global test loss: 1.115, Global test accuracy: 82.02
Round  28, Train loss: 1.137, Test loss: 1.168, Test accuracy: 74.64
Round  28, Global train loss: 1.137, Global test loss: 0.997, Global test accuracy: 92.58
Round  29, Train loss: 1.440, Test loss: 1.173, Test accuracy: 74.18
Round  29, Global train loss: 1.440, Global test loss: 1.166, Global test accuracy: 76.36
Round  30, Train loss: 1.300, Test loss: 1.171, Test accuracy: 74.20
Round  30, Global train loss: 1.300, Global test loss: 1.049, Global test accuracy: 87.50
Round  31, Train loss: 1.281, Test loss: 1.179, Test accuracy: 73.38
Round  31, Global train loss: 1.281, Global test loss: 1.062, Global test accuracy: 86.46
Round  32, Train loss: 1.110, Test loss: 1.181, Test accuracy: 73.02
Round  32, Global train loss: 1.110, Global test loss: 1.009, Global test accuracy: 91.44
Round  33, Train loss: 1.282, Test loss: 1.170, Test accuracy: 74.32
Round  33, Global train loss: 1.282, Global test loss: 1.069, Global test accuracy: 85.78
Round  34, Train loss: 1.407, Test loss: 1.173, Test accuracy: 73.94
Round  34, Global train loss: 1.407, Global test loss: 1.159, Global test accuracy: 75.76
Round  35, Train loss: 1.367, Test loss: 1.184, Test accuracy: 72.62
Round  35, Global train loss: 1.367, Global test loss: 1.255, Global test accuracy: 64.84
Round  36, Train loss: 1.291, Test loss: 1.192, Test accuracy: 71.48
Round  36, Global train loss: 1.291, Global test loss: 1.093, Global test accuracy: 82.56
Round  37, Train loss: 1.216, Test loss: 1.184, Test accuracy: 72.48
Round  37, Global train loss: 1.216, Global test loss: 1.043, Global test accuracy: 87.62
Round  38, Train loss: 1.368, Test loss: 1.185, Test accuracy: 72.30
Round  38, Global train loss: 1.368, Global test loss: 1.271, Global test accuracy: 63.04
Round  39, Train loss: 1.365, Test loss: 1.196, Test accuracy: 70.78
Round  39, Global train loss: 1.365, Global test loss: 1.209, Global test accuracy: 70.20
Round  40, Train loss: 1.340, Test loss: 1.205, Test accuracy: 69.84
Round  40, Global train loss: 1.340, Global test loss: 1.250, Global test accuracy: 66.26
Round  41, Train loss: 1.354, Test loss: 1.211, Test accuracy: 68.90
Round  41, Global train loss: 1.354, Global test loss: 1.185, Global test accuracy: 72.06
Round  42, Train loss: 1.305, Test loss: 1.194, Test accuracy: 70.88
Round  42, Global train loss: 1.305, Global test loss: 1.286, Global test accuracy: 62.30
Round  43, Train loss: 1.068, Test loss: 1.200, Test accuracy: 70.12
Round  43, Global train loss: 1.068, Global test loss: 1.021, Global test accuracy: 89.14
Round  44, Train loss: 1.416, Test loss: 1.208, Test accuracy: 69.16
Round  44, Global train loss: 1.416, Global test loss: 1.136, Global test accuracy: 78.22
Round  45, Train loss: 1.327, Test loss: 1.215, Test accuracy: 68.40
Round  45, Global train loss: 1.327, Global test loss: 1.241, Global test accuracy: 66.98
Round  46, Train loss: 1.339, Test loss: 1.230, Test accuracy: 66.70
Round  46, Global train loss: 1.339, Global test loss: 1.226, Global test accuracy: 68.44
Round  47, Train loss: 1.148, Test loss: 1.237, Test accuracy: 65.96
Round  47, Global train loss: 1.148, Global test loss: 1.097, Global test accuracy: 81.42
Round  48, Train loss: 1.194, Test loss: 1.250, Test accuracy: 64.90
Round  48, Global train loss: 1.194, Global test loss: 1.122, Global test accuracy: 79.30
Round  49, Train loss: 1.236, Test loss: 1.261, Test accuracy: 63.66
Round  49, Global train loss: 1.236, Global test loss: 1.099, Global test accuracy: 81.86
Round  50, Train loss: 1.171, Test loss: 1.263, Test accuracy: 63.66
Round  50, Global train loss: 1.171, Global test loss: 1.080, Global test accuracy: 83.24
Round  51, Train loss: 1.342, Test loss: 1.256, Test accuracy: 64.30
Round  51, Global train loss: 1.342, Global test loss: 1.221, Global test accuracy: 68.74
Round  52, Train loss: 1.326, Test loss: 1.275, Test accuracy: 62.24
Round  52, Global train loss: 1.326, Global test loss: 1.285, Global test accuracy: 62.14
Round  53, Train loss: 1.220, Test loss: 1.263, Test accuracy: 63.52
Round  53, Global train loss: 1.220, Global test loss: 1.049, Global test accuracy: 86.72
Round  54, Train loss: 1.176, Test loss: 1.258, Test accuracy: 63.90
Round  54, Global train loss: 1.176, Global test loss: 1.156, Global test accuracy: 75.48
Round  55, Train loss: 1.270, Test loss: 1.251, Test accuracy: 64.64
Round  55, Global train loss: 1.270, Global test loss: 1.234, Global test accuracy: 67.96
Round  56, Train loss: 1.138, Test loss: 1.254, Test accuracy: 64.24
Round  56, Global train loss: 1.138, Global test loss: 1.087, Global test accuracy: 82.36
Round  57, Train loss: 1.287, Test loss: 1.252, Test accuracy: 64.30
Round  57, Global train loss: 1.287, Global test loss: 1.238, Global test accuracy: 66.86
Round  58, Train loss: 1.302, Test loss: 1.266, Test accuracy: 63.08
Round  58, Global train loss: 1.302, Global test loss: 1.254, Global test accuracy: 65.06
Round  59, Train loss: 1.301, Test loss: 1.271, Test accuracy: 62.40
Round  59, Global train loss: 1.301, Global test loss: 1.343, Global test accuracy: 55.48
Round  60, Train loss: 1.154, Test loss: 1.275, Test accuracy: 61.90
Round  60, Global train loss: 1.154, Global test loss: 1.156, Global test accuracy: 75.68
Round  61, Train loss: 1.227, Test loss: 1.274, Test accuracy: 62.20
Round  61, Global train loss: 1.227, Global test loss: 1.383, Global test accuracy: 50.92
Round  62, Train loss: 1.049, Test loss: 1.276, Test accuracy: 62.08
Round  62, Global train loss: 1.049, Global test loss: 1.035, Global test accuracy: 87.36
Round  63, Train loss: 1.155, Test loss: 1.282, Test accuracy: 61.50
Round  63, Global train loss: 1.155, Global test loss: 1.198, Global test accuracy: 70.44
Round  64, Train loss: 1.114, Test loss: 1.282, Test accuracy: 61.48
Round  64, Global train loss: 1.114, Global test loss: 1.184, Global test accuracy: 72.28
Round  65, Train loss: 1.241, Test loss: 1.288, Test accuracy: 60.58
Round  65, Global train loss: 1.241, Global test loss: 1.267, Global test accuracy: 63.14
Round  66, Train loss: 1.232, Test loss: 1.294, Test accuracy: 60.30
Round  66, Global train loss: 1.232, Global test loss: 1.361, Global test accuracy: 53.36
Round  67, Train loss: 1.108, Test loss: 1.300, Test accuracy: 59.74
Round  67, Global train loss: 1.108, Global test loss: 1.204, Global test accuracy: 69.78
Round  68, Train loss: 1.121, Test loss: 1.298, Test accuracy: 59.82
Round  68, Global train loss: 1.121, Global test loss: 1.230, Global test accuracy: 67.96
Round  69, Train loss: 1.299, Test loss: 1.293, Test accuracy: 60.36
Round  69, Global train loss: 1.299, Global test loss: 1.272, Global test accuracy: 62.48
Round  70, Train loss: 1.190, Test loss: 1.292, Test accuracy: 60.18
Round  70, Global train loss: 1.190, Global test loss: 1.362, Global test accuracy: 53.44
Round  71, Train loss: 1.277, Test loss: 1.312, Test accuracy: 58.22
Round  71, Global train loss: 1.277, Global test loss: 1.356, Global test accuracy: 53.44
Round  72, Train loss: 1.202, Test loss: 1.311, Test accuracy: 58.48
Round  72, Global train loss: 1.202, Global test loss: 1.358, Global test accuracy: 53.14
Round  73, Train loss: 1.002, Test loss: 1.318, Test accuracy: 57.72
Round  73, Global train loss: 1.002, Global test loss: 1.058, Global test accuracy: 85.24
Round  74, Train loss: 1.157, Test loss: 1.321, Test accuracy: 57.42
Round  74, Global train loss: 1.157, Global test loss: 1.093, Global test accuracy: 81.30
Round  75, Train loss: 1.202, Test loss: 1.314, Test accuracy: 58.18
Round  75, Global train loss: 1.202, Global test loss: 1.316, Global test accuracy: 57.30
Round  76, Train loss: 1.136, Test loss: 1.317, Test accuracy: 58.02
Round  76, Global train loss: 1.136, Global test loss: 1.105, Global test accuracy: 80.18
Round  77, Train loss: 1.108, Test loss: 1.307, Test accuracy: 59.06
Round  77, Global train loss: 1.108, Global test loss: 1.215, Global test accuracy: 69.00
Round  78, Train loss: 1.142, Test loss: 1.304, Test accuracy: 59.40
Round  78, Global train loss: 1.142, Global test loss: 1.173, Global test accuracy: 73.34
Round  79, Train loss: 1.098, Test loss: 1.309, Test accuracy: 58.62
Round  79, Global train loss: 1.098, Global test loss: 1.191, Global test accuracy: 70.72
Round  80, Train loss: 1.116, Test loss: 1.317, Test accuracy: 57.64
Round  80, Global train loss: 1.116, Global test loss: 1.143, Global test accuracy: 76.62
Round  81, Train loss: 1.013, Test loss: 1.315, Test accuracy: 58.12
Round  81, Global train loss: 1.013, Global test loss: 1.055, Global test accuracy: 85.08
Round  82, Train loss: 1.171, Test loss: 1.300, Test accuracy: 59.34
Round  82, Global train loss: 1.171, Global test loss: 1.328, Global test accuracy: 56.78
Round  83, Train loss: 1.103, Test loss: 1.317, Test accuracy: 57.44
Round  83, Global train loss: 1.103, Global test loss: 1.171, Global test accuracy: 73.34
Round  84, Train loss: 1.083, Test loss: 1.312, Test accuracy: 58.08
Round  84, Global train loss: 1.083, Global test loss: 1.183, Global test accuracy: 72.56
Round  85, Train loss: 1.097, Test loss: 1.326, Test accuracy: 56.56
Round  85, Global train loss: 1.097, Global test loss: 1.145, Global test accuracy: 76.06
Round  86, Train loss: 1.013, Test loss: 1.321, Test accuracy: 57.20
Round  86, Global train loss: 1.013, Global test loss: 1.071, Global test accuracy: 83.42
Round  87, Train loss: 1.190, Test loss: 1.308, Test accuracy: 58.52
Round  87, Global train loss: 1.190, Global test loss: 1.332, Global test accuracy: 56.48
Round  88, Train loss: 1.150, Test loss: 1.325, Test accuracy: 56.62
Round  88, Global train loss: 1.150, Global test loss: 1.406, Global test accuracy: 48.92
Round  89, Train loss: 1.063, Test loss: 1.328, Test accuracy: 56.18
Round  89, Global train loss: 1.063, Global test loss: 1.148, Global test accuracy: 75.54
Round  90, Train loss: 1.125, Test loss: 1.319, Test accuracy: 57.18
Round  90, Global train loss: 1.125, Global test loss: 1.371, Global test accuracy: 52.60
Round  91, Train loss: 1.046, Test loss: 1.320, Test accuracy: 57.22
Round  91, Global train loss: 1.046, Global test loss: 1.148, Global test accuracy: 75.68
Round  92, Train loss: 1.197, Test loss: 1.322, Test accuracy: 57.36
Round  92, Global train loss: 1.197, Global test loss: 1.388, Global test accuracy: 50.54
Round  93, Train loss: 1.144, Test loss: 1.323, Test accuracy: 57.28
Round  93, Global train loss: 1.144, Global test loss: 1.385, Global test accuracy: 50.96/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  94, Train loss: 1.193, Test loss: 1.320, Test accuracy: 57.32
Round  94, Global train loss: 1.193, Global test loss: 1.329, Global test accuracy: 57.04
Round  95, Train loss: 1.114, Test loss: 1.323, Test accuracy: 57.14
Round  95, Global train loss: 1.114, Global test loss: 1.173, Global test accuracy: 72.94
Round  96, Train loss: 1.085, Test loss: 1.320, Test accuracy: 57.50
Round  96, Global train loss: 1.085, Global test loss: 1.232, Global test accuracy: 67.24
Round  97, Train loss: 1.142, Test loss: 1.322, Test accuracy: 57.12
Round  97, Global train loss: 1.142, Global test loss: 1.389, Global test accuracy: 50.26
Round  98, Train loss: 1.148, Test loss: 1.330, Test accuracy: 56.22
Round  98, Global train loss: 1.148, Global test loss: 1.345, Global test accuracy: 55.26
Round  99, Train loss: 1.073, Test loss: 1.330, Test accuracy: 56.34
Round  99, Global train loss: 1.073, Global test loss: 1.229, Global test accuracy: 66.76
Final Round, Train loss: 1.081, Test loss: 1.342, Test accuracy: 55.26
Final Round, Global train loss: 1.081, Global test loss: 1.229, Global test accuracy: 66.76
Average accuracy final 10 rounds: 57.068 

Average global accuracy final 10 rounds: 59.928 

652.4819700717926
[0.9756267070770264, 1.9512534141540527, 2.726104259490967, 3.500955104827881, 4.288849592208862, 5.076744079589844, 5.85804557800293, 6.639347076416016, 7.424410820007324, 8.209474563598633, 8.978721857070923, 9.747969150543213, 10.529545545578003, 11.311121940612793, 12.08238697052002, 12.853652000427246, 13.60256838798523, 14.351484775543213, 15.099121332168579, 15.846757888793945, 16.66373896598816, 17.480720043182373, 18.314490795135498, 19.148261547088623, 19.981428146362305, 20.814594745635986, 21.64823865890503, 22.481882572174072, 23.31499147415161, 24.14810037612915, 24.967268228530884, 25.786436080932617, 26.62752103805542, 27.468605995178223, 28.792605876922607, 30.116605758666992, 31.46178126335144, 32.80695676803589, 34.18564462661743, 35.564332485198975, 36.94594192504883, 38.32755136489868, 39.73069167137146, 41.13383197784424, 42.178765296936035, 43.22369861602783, 44.500253677368164, 45.776808738708496, 46.938982248306274, 48.10115575790405, 49.348172187805176, 50.5951886177063, 51.443767786026, 52.2923469543457, 53.12785482406616, 53.96336269378662, 54.80126976966858, 55.63917684555054, 56.47258400917053, 57.30599117279053, 58.142051696777344, 58.97811222076416, 59.8328070640564, 60.68750190734863, 61.52198386192322, 62.3564658164978, 63.18637943267822, 64.01629304885864, 64.76288986206055, 65.50948667526245, 66.2826280593872, 67.05576944351196, 67.88695311546326, 68.71813678741455, 69.55597734451294, 70.39381790161133, 71.23214340209961, 72.07046890258789, 73.13856601715088, 74.20666313171387, 75.4235155582428, 76.64036798477173, 77.77297115325928, 78.90557432174683, 80.04265069961548, 81.17972707748413, 82.00861716270447, 82.8375072479248, 83.67128086090088, 84.50505447387695, 85.32891249656677, 86.15277051925659, 86.98225855827332, 87.81174659729004, 88.64041423797607, 89.46908187866211, 90.2915689945221, 91.11405611038208, 91.9353699684143, 92.75668382644653, 93.5929753780365, 94.42926692962646, 95.26534724235535, 96.10142755508423, 96.94725728034973, 97.79308700561523, 98.63835859298706, 99.48363018035889, 100.29094314575195, 101.09825611114502, 101.89961838722229, 102.70098066329956, 103.49190497398376, 104.28282928466797, 105.07833766937256, 105.87384605407715, 106.66962766647339, 107.46540927886963, 108.22726202011108, 108.98911476135254, 109.75666093826294, 110.52420711517334, 111.31555676460266, 112.10690641403198, 112.90153503417969, 113.69616365432739, 114.47252082824707, 115.24887800216675, 116.01735758781433, 116.78583717346191, 117.5564136505127, 118.32699012756348, 119.10957551002502, 119.89216089248657, 120.67976975440979, 121.46737861633301, 122.25410652160645, 123.04083442687988, 123.82219576835632, 124.60355710983276, 125.36537718772888, 126.127197265625, 126.89736747741699, 127.66753768920898, 128.43193674087524, 129.1963357925415, 129.98150157928467, 130.76666736602783, 131.55295753479004, 132.33924770355225, 133.12804245948792, 133.91683721542358, 134.69688296318054, 135.4769287109375, 136.2654733657837, 137.05401802062988, 137.84280514717102, 138.63159227371216, 139.42334699630737, 140.2151017189026, 140.97814178466797, 141.74118185043335, 142.5073206424713, 143.27345943450928, 144.04389810562134, 144.8143367767334, 145.61032104492188, 146.40630531311035, 147.18473386764526, 147.96316242218018, 148.75987768173218, 149.55659294128418, 150.3431351184845, 151.12967729568481, 151.8969795703888, 152.66428184509277, 153.44254612922668, 154.2208104133606, 155.02601885795593, 155.83122730255127, 156.63302946090698, 157.4348316192627, 158.22150564193726, 159.00817966461182, 159.80856442451477, 160.60894918441772, 161.40677309036255, 162.20459699630737, 162.9967679977417, 163.78893899917603, 164.57873392105103, 165.36852884292603, 166.16339421272278, 166.95825958251953, 167.7629337310791, 168.56760787963867, 169.36605834960938, 170.16450881958008, 170.9521288871765, 171.73974895477295, 173.3545172214508, 174.96928548812866]
[21.72, 21.72, 55.24, 55.24, 63.76, 63.76, 63.5, 63.5, 73.84, 73.84, 73.94, 73.94, 84.1, 84.1, 87.62, 87.62, 87.42, 87.42, 87.58, 87.58, 87.02, 87.02, 86.68, 86.68, 86.7, 86.7, 85.04, 85.04, 84.32, 84.32, 83.78, 83.78, 83.74, 83.74, 84.44, 84.44, 83.7, 83.7, 83.66, 83.66, 83.42, 83.42, 82.9, 82.9, 82.1, 82.1, 81.74, 81.74, 80.7, 80.7, 77.28, 77.28, 75.14, 75.14, 74.12, 74.12, 74.64, 74.64, 74.18, 74.18, 74.2, 74.2, 73.38, 73.38, 73.02, 73.02, 74.32, 74.32, 73.94, 73.94, 72.62, 72.62, 71.48, 71.48, 72.48, 72.48, 72.3, 72.3, 70.78, 70.78, 69.84, 69.84, 68.9, 68.9, 70.88, 70.88, 70.12, 70.12, 69.16, 69.16, 68.4, 68.4, 66.7, 66.7, 65.96, 65.96, 64.9, 64.9, 63.66, 63.66, 63.66, 63.66, 64.3, 64.3, 62.24, 62.24, 63.52, 63.52, 63.9, 63.9, 64.64, 64.64, 64.24, 64.24, 64.3, 64.3, 63.08, 63.08, 62.4, 62.4, 61.9, 61.9, 62.2, 62.2, 62.08, 62.08, 61.5, 61.5, 61.48, 61.48, 60.58, 60.58, 60.3, 60.3, 59.74, 59.74, 59.82, 59.82, 60.36, 60.36, 60.18, 60.18, 58.22, 58.22, 58.48, 58.48, 57.72, 57.72, 57.42, 57.42, 58.18, 58.18, 58.02, 58.02, 59.06, 59.06, 59.4, 59.4, 58.62, 58.62, 57.64, 57.64, 58.12, 58.12, 59.34, 59.34, 57.44, 57.44, 58.08, 58.08, 56.56, 56.56, 57.2, 57.2, 58.52, 58.52, 56.62, 56.62, 56.18, 56.18, 57.18, 57.18, 57.22, 57.22, 57.36, 57.36, 57.28, 57.28, 57.32, 57.32, 57.14, 57.14, 57.5, 57.5, 57.12, 57.12, 56.22, 56.22, 56.34, 56.34, 55.26, 55.26]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.8 , level_n_lowerb:0.8  

   Client 0, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
prox
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.608, Test loss: 1.605, Test accuracy: 27.60
Round   0, Global train loss: 1.608, Global test loss: 1.605, Global test accuracy: 28.04
Round   1, Train loss: 1.607, Test loss: 1.602, Test accuracy: 34.32
Round   1, Global train loss: 1.607, Global test loss: 1.601, Global test accuracy: 38.66
Round   2, Train loss: 1.605, Test loss: 1.597, Test accuracy: 33.72
Round   2, Global train loss: 1.605, Global test loss: 1.594, Global test accuracy: 39.54
Round   3, Train loss: 1.576, Test loss: 1.559, Test accuracy: 37.64
Round   3, Global train loss: 1.576, Global test loss: 1.538, Global test accuracy: 44.46
Round   4, Train loss: 1.590, Test loss: 1.523, Test accuracy: 56.52
Round   4, Global train loss: 1.590, Global test loss: 1.499, Global test accuracy: 84.80
Round   5, Train loss: 1.444, Test loss: 1.436, Test accuracy: 60.88
Round   5, Global train loss: 1.444, Global test loss: 1.280, Global test accuracy: 93.20
Round   6, Train loss: 1.569, Test loss: 1.342, Test accuracy: 74.80
Round   6, Global train loss: 1.569, Global test loss: 1.257, Global test accuracy: 92.98
Round   7, Train loss: 1.565, Test loss: 1.293, Test accuracy: 83.20
Round   7, Global train loss: 1.565, Global test loss: 1.271, Global test accuracy: 91.08
Round   8, Train loss: 1.374, Test loss: 1.258, Test accuracy: 83.58
Round   8, Global train loss: 1.374, Global test loss: 1.126, Global test accuracy: 93.62
Round   9, Train loss: 1.172, Test loss: 1.226, Test accuracy: 83.94
Round   9, Global train loss: 1.172, Global test loss: 1.017, Global test accuracy: 94.80
Round  10, Train loss: 1.376, Test loss: 1.196, Test accuracy: 83.90
Round  10, Global train loss: 1.376, Global test loss: 1.027, Global test accuracy: 94.10
Round  11, Train loss: 1.336, Test loss: 1.180, Test accuracy: 84.46
Round  11, Global train loss: 1.336, Global test loss: 0.995, Global test accuracy: 95.08
Round  12, Train loss: 1.538, Test loss: 1.141, Test accuracy: 85.08
Round  12, Global train loss: 1.538, Global test loss: 1.010, Global test accuracy: 94.46
Round  13, Train loss: 1.551, Test loss: 1.136, Test accuracy: 84.78
Round  13, Global train loss: 1.551, Global test loss: 1.058, Global test accuracy: 91.24
Round  14, Train loss: 1.343, Test loss: 1.099, Test accuracy: 84.54
Round  14, Global train loss: 1.343, Global test loss: 0.994, Global test accuracy: 95.20
Round  15, Train loss: 1.548, Test loss: 1.101, Test accuracy: 83.54
Round  15, Global train loss: 1.548, Global test loss: 1.046, Global test accuracy: 93.26
Round  16, Train loss: 1.337, Test loss: 1.102, Test accuracy: 83.52
Round  16, Global train loss: 1.337, Global test loss: 1.004, Global test accuracy: 94.52
Round  17, Train loss: 1.354, Test loss: 1.109, Test accuracy: 82.62
Round  17, Global train loss: 1.354, Global test loss: 1.029, Global test accuracy: 92.20
Round  18, Train loss: 1.321, Test loss: 1.110, Test accuracy: 82.36
Round  18, Global train loss: 1.321, Global test loss: 0.995, Global test accuracy: 93.68
Round  19, Train loss: 1.312, Test loss: 1.105, Test accuracy: 82.86
Round  19, Global train loss: 1.312, Global test loss: 0.990, Global test accuracy: 94.00
Round  20, Train loss: 1.515, Test loss: 1.106, Test accuracy: 83.12
Round  20, Global train loss: 1.515, Global test loss: 1.051, Global test accuracy: 89.84
Round  21, Train loss: 1.321, Test loss: 1.107, Test accuracy: 82.98
Round  21, Global train loss: 1.321, Global test loss: 1.017, Global test accuracy: 92.42
Round  22, Train loss: 1.304, Test loss: 1.108, Test accuracy: 82.80
Round  22, Global train loss: 1.304, Global test loss: 0.998, Global test accuracy: 93.30
Round  23, Train loss: 1.516, Test loss: 1.100, Test accuracy: 83.64
Round  23, Global train loss: 1.516, Global test loss: 1.066, Global test accuracy: 87.54
Round  24, Train loss: 1.319, Test loss: 1.111, Test accuracy: 82.72
Round  24, Global train loss: 1.319, Global test loss: 1.058, Global test accuracy: 87.94
Round  25, Train loss: 1.489, Test loss: 1.122, Test accuracy: 80.74
Round  25, Global train loss: 1.489, Global test loss: 1.146, Global test accuracy: 79.52
Round  26, Train loss: 1.319, Test loss: 1.132, Test accuracy: 78.90
Round  26, Global train loss: 1.319, Global test loss: 1.023, Global test accuracy: 91.44
Round  27, Train loss: 1.498, Test loss: 1.137, Test accuracy: 78.18
Round  27, Global train loss: 1.498, Global test loss: 1.085, Global test accuracy: 85.98
Round  28, Train loss: 1.306, Test loss: 1.138, Test accuracy: 78.10
Round  28, Global train loss: 1.306, Global test loss: 1.037, Global test accuracy: 89.60
Round  29, Train loss: 1.484, Test loss: 1.140, Test accuracy: 77.80
Round  29, Global train loss: 1.484, Global test loss: 1.110, Global test accuracy: 82.80
Round  30, Train loss: 1.307, Test loss: 1.149, Test accuracy: 76.86
Round  30, Global train loss: 1.307, Global test loss: 1.039, Global test accuracy: 89.36
Round  31, Train loss: 1.471, Test loss: 1.151, Test accuracy: 76.18
Round  31, Global train loss: 1.471, Global test loss: 1.180, Global test accuracy: 74.84
Round  32, Train loss: 1.458, Test loss: 1.150, Test accuracy: 76.48
Round  32, Global train loss: 1.458, Global test loss: 1.185, Global test accuracy: 74.08
Round  33, Train loss: 1.447, Test loss: 1.154, Test accuracy: 76.22
Round  33, Global train loss: 1.447, Global test loss: 1.216, Global test accuracy: 70.22
Round  34, Train loss: 1.270, Test loss: 1.170, Test accuracy: 74.22
Round  34, Global train loss: 1.270, Global test loss: 1.091, Global test accuracy: 84.52
Round  35, Train loss: 1.435, Test loss: 1.186, Test accuracy: 72.24
Round  35, Global train loss: 1.435, Global test loss: 1.233, Global test accuracy: 69.00
Round  36, Train loss: 1.266, Test loss: 1.189, Test accuracy: 71.90
Round  36, Global train loss: 1.266, Global test loss: 1.062, Global test accuracy: 85.96
Round  37, Train loss: 1.437, Test loss: 1.182, Test accuracy: 72.78
Round  37, Global train loss: 1.437, Global test loss: 1.186, Global test accuracy: 72.58
Round  38, Train loss: 1.246, Test loss: 1.187, Test accuracy: 71.94
Round  38, Global train loss: 1.246, Global test loss: 1.083, Global test accuracy: 84.84
Round  39, Train loss: 1.242, Test loss: 1.183, Test accuracy: 72.68
Round  39, Global train loss: 1.242, Global test loss: 1.084, Global test accuracy: 84.26
Round  40, Train loss: 1.236, Test loss: 1.180, Test accuracy: 72.96
Round  40, Global train loss: 1.236, Global test loss: 1.069, Global test accuracy: 85.30
Round  41, Train loss: 1.249, Test loss: 1.179, Test accuracy: 72.88
Round  41, Global train loss: 1.249, Global test loss: 1.050, Global test accuracy: 87.32
Round  42, Train loss: 1.220, Test loss: 1.180, Test accuracy: 72.90
Round  42, Global train loss: 1.220, Global test loss: 1.093, Global test accuracy: 83.46
Round  43, Train loss: 1.257, Test loss: 1.179, Test accuracy: 73.36
Round  43, Global train loss: 1.257, Global test loss: 1.062, Global test accuracy: 86.58
Round  44, Train loss: 1.250, Test loss: 1.178, Test accuracy: 73.42
Round  44, Global train loss: 1.250, Global test loss: 1.027, Global test accuracy: 89.16
Round  45, Train loss: 1.377, Test loss: 1.173, Test accuracy: 73.94
Round  45, Global train loss: 1.377, Global test loss: 1.108, Global test accuracy: 81.26
Round  46, Train loss: 1.224, Test loss: 1.191, Test accuracy: 71.90
Round  46, Global train loss: 1.224, Global test loss: 1.055, Global test accuracy: 86.44
Round  47, Train loss: 1.363, Test loss: 1.199, Test accuracy: 70.58
Round  47, Global train loss: 1.363, Global test loss: 1.180, Global test accuracy: 73.78
Round  48, Train loss: 1.382, Test loss: 1.200, Test accuracy: 70.32
Round  48, Global train loss: 1.382, Global test loss: 1.240, Global test accuracy: 67.36
Round  49, Train loss: 1.224, Test loss: 1.205, Test accuracy: 69.96
Round  49, Global train loss: 1.224, Global test loss: 1.100, Global test accuracy: 81.82
Round  50, Train loss: 1.226, Test loss: 1.206, Test accuracy: 69.88
Round  50, Global train loss: 1.226, Global test loss: 1.058, Global test accuracy: 85.98
Round  51, Train loss: 1.395, Test loss: 1.193, Test accuracy: 71.22
Round  51, Global train loss: 1.395, Global test loss: 1.144, Global test accuracy: 77.40
Round  52, Train loss: 1.384, Test loss: 1.215, Test accuracy: 68.62
Round  52, Global train loss: 1.384, Global test loss: 1.256, Global test accuracy: 64.66
Round  53, Train loss: 1.236, Test loss: 1.243, Test accuracy: 65.76
Round  53, Global train loss: 1.236, Global test loss: 1.097, Global test accuracy: 82.24
Round  54, Train loss: 1.361, Test loss: 1.246, Test accuracy: 65.30
Round  54, Global train loss: 1.361, Global test loss: 1.211, Global test accuracy: 70.28
Round  55, Train loss: 1.197, Test loss: 1.254, Test accuracy: 64.58
Round  55, Global train loss: 1.197, Global test loss: 1.080, Global test accuracy: 83.26
Round  56, Train loss: 1.348, Test loss: 1.245, Test accuracy: 65.50
Round  56, Global train loss: 1.348, Global test loss: 1.237, Global test accuracy: 66.86
Round  57, Train loss: 1.208, Test loss: 1.245, Test accuracy: 65.50
Round  57, Global train loss: 1.208, Global test loss: 1.106, Global test accuracy: 80.78
Round  58, Train loss: 1.207, Test loss: 1.249, Test accuracy: 64.78
Round  58, Global train loss: 1.207, Global test loss: 1.118, Global test accuracy: 79.44
Round  59, Train loss: 1.356, Test loss: 1.236, Test accuracy: 66.20
Round  59, Global train loss: 1.356, Global test loss: 1.255, Global test accuracy: 65.26
Round  60, Train loss: 1.337, Test loss: 1.241, Test accuracy: 65.56
Round  60, Global train loss: 1.337, Global test loss: 1.253, Global test accuracy: 65.14
Round  61, Train loss: 1.314, Test loss: 1.250, Test accuracy: 64.50
Round  61, Global train loss: 1.314, Global test loss: 1.299, Global test accuracy: 60.88
Round  62, Train loss: 1.204, Test loss: 1.251, Test accuracy: 64.60
Round  62, Global train loss: 1.204, Global test loss: 1.107, Global test accuracy: 80.84
Round  63, Train loss: 1.295, Test loss: 1.264, Test accuracy: 62.96
Round  63, Global train loss: 1.295, Global test loss: 1.298, Global test accuracy: 60.52
Round  64, Train loss: 1.143, Test loss: 1.260, Test accuracy: 63.48
Round  64, Global train loss: 1.143, Global test loss: 1.137, Global test accuracy: 77.86
Round  65, Train loss: 1.185, Test loss: 1.251, Test accuracy: 64.90
Round  65, Global train loss: 1.185, Global test loss: 1.120, Global test accuracy: 79.20
Round  66, Train loss: 1.314, Test loss: 1.260, Test accuracy: 63.72
Round  66, Global train loss: 1.314, Global test loss: 1.315, Global test accuracy: 58.06
Round  67, Train loss: 1.254, Test loss: 1.265, Test accuracy: 63.22
Round  67, Global train loss: 1.254, Global test loss: 1.307, Global test accuracy: 59.46
Round  68, Train loss: 1.137, Test loss: 1.268, Test accuracy: 62.82
Round  68, Global train loss: 1.137, Global test loss: 1.177, Global test accuracy: 73.50
Round  69, Train loss: 1.183, Test loss: 1.282, Test accuracy: 61.56
Round  69, Global train loss: 1.183, Global test loss: 1.169, Global test accuracy: 73.42
Round  70, Train loss: 1.273, Test loss: 1.285, Test accuracy: 60.78
Round  70, Global train loss: 1.273, Global test loss: 1.259, Global test accuracy: 64.44
Round  71, Train loss: 1.158, Test loss: 1.283, Test accuracy: 60.98
Round  71, Global train loss: 1.158, Global test loss: 1.166, Global test accuracy: 73.96
Round  72, Train loss: 1.274, Test loss: 1.268, Test accuracy: 62.74
Round  72, Global train loss: 1.274, Global test loss: 1.314, Global test accuracy: 58.76
Round  73, Train loss: 1.289, Test loss: 1.276, Test accuracy: 61.92
Round  73, Global train loss: 1.289, Global test loss: 1.276, Global test accuracy: 63.48
Round  74, Train loss: 1.184, Test loss: 1.288, Test accuracy: 60.74
Round  74, Global train loss: 1.184, Global test loss: 1.139, Global test accuracy: 76.56
Round  75, Train loss: 1.267, Test loss: 1.291, Test accuracy: 60.46
Round  75, Global train loss: 1.267, Global test loss: 1.321, Global test accuracy: 57.36
Round  76, Train loss: 1.164, Test loss: 1.290, Test accuracy: 60.52
Round  76, Global train loss: 1.164, Global test loss: 1.112, Global test accuracy: 79.66
Round  77, Train loss: 1.256, Test loss: 1.290, Test accuracy: 60.56
Round  77, Global train loss: 1.256, Global test loss: 1.307, Global test accuracy: 59.08
Round  78, Train loss: 1.128, Test loss: 1.294, Test accuracy: 60.06
Round  78, Global train loss: 1.128, Global test loss: 1.179, Global test accuracy: 72.70
Round  79, Train loss: 1.240, Test loss: 1.290, Test accuracy: 60.54
Round  79, Global train loss: 1.240, Global test loss: 1.338, Global test accuracy: 56.04
Round  80, Train loss: 1.157, Test loss: 1.296, Test accuracy: 59.80
Round  80, Global train loss: 1.157, Global test loss: 1.146, Global test accuracy: 76.62
Round  81, Train loss: 1.240, Test loss: 1.292, Test accuracy: 60.38
Round  81, Global train loss: 1.240, Global test loss: 1.307, Global test accuracy: 58.72
Round  82, Train loss: 1.248, Test loss: 1.289, Test accuracy: 60.76
Round  82, Global train loss: 1.248, Global test loss: 1.282, Global test accuracy: 61.96
Round  83, Train loss: 1.142, Test loss: 1.296, Test accuracy: 59.98
Round  83, Global train loss: 1.142, Global test loss: 1.152, Global test accuracy: 74.72
Round  84, Train loss: 1.204, Test loss: 1.298, Test accuracy: 59.80
Round  84, Global train loss: 1.204, Global test loss: 1.296, Global test accuracy: 60.42
Round  85, Train loss: 1.132, Test loss: 1.293, Test accuracy: 60.38
Round  85, Global train loss: 1.132, Global test loss: 1.128, Global test accuracy: 78.20
Round  86, Train loss: 1.106, Test loss: 1.291, Test accuracy: 60.32
Round  86, Global train loss: 1.106, Global test loss: 1.134, Global test accuracy: 77.12
Round  87, Train loss: 1.021, Test loss: 1.281, Test accuracy: 61.54
Round  87, Global train loss: 1.021, Global test loss: 1.031, Global test accuracy: 87.98
Round  88, Train loss: 1.114, Test loss: 1.284, Test accuracy: 61.00
Round  88, Global train loss: 1.114, Global test loss: 1.162, Global test accuracy: 74.18
Round  89, Train loss: 1.116, Test loss: 1.289, Test accuracy: 60.78
Round  89, Global train loss: 1.116, Global test loss: 1.158, Global test accuracy: 75.28
Round  90, Train loss: 1.104, Test loss: 1.281, Test accuracy: 61.40
Round  90, Global train loss: 1.104, Global test loss: 1.152, Global test accuracy: 75.38
Round  91, Train loss: 1.187, Test loss: 1.279, Test accuracy: 61.60
Round  91, Global train loss: 1.187, Global test loss: 1.307, Global test accuracy: 58.94
Round  92, Train loss: 1.132, Test loss: 1.289, Test accuracy: 60.54
Round  92, Global train loss: 1.132, Global test loss: 1.148, Global test accuracy: 76.10
Round  93, Train loss: 1.078, Test loss: 1.288, Test accuracy: 60.68
Round  93, Global train loss: 1.078, Global test loss: 1.151, Global test accuracy: 75.22
Round  94, Train loss: 1.157, Test loss: 1.287, Test accuracy: 60.74
Round  94, Global train loss: 1.157, Global test loss: 1.156, Global test accuracy: 75.22/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  95, Train loss: 1.232, Test loss: 1.295, Test accuracy: 60.18
Round  95, Global train loss: 1.232, Global test loss: 1.343, Global test accuracy: 55.52
Round  96, Train loss: 1.083, Test loss: 1.305, Test accuracy: 59.18
Round  96, Global train loss: 1.083, Global test loss: 1.204, Global test accuracy: 69.56
Round  97, Train loss: 1.178, Test loss: 1.297, Test accuracy: 60.28
Round  97, Global train loss: 1.178, Global test loss: 1.356, Global test accuracy: 54.24
Round  98, Train loss: 1.102, Test loss: 1.302, Test accuracy: 59.70
Round  98, Global train loss: 1.102, Global test loss: 1.164, Global test accuracy: 73.86
Round  99, Train loss: 1.196, Test loss: 1.296, Test accuracy: 60.18
Round  99, Global train loss: 1.196, Global test loss: 1.333, Global test accuracy: 56.52
Final Round, Train loss: 1.118, Test loss: 1.301, Test accuracy: 59.42
Final Round, Global train loss: 1.118, Global test loss: 1.333, Global test accuracy: 56.52
Average accuracy final 10 rounds: 60.44799999999999 

Average global accuracy final 10 rounds: 67.056 

651.1506803035736
[1.0476233959197998, 2.0952467918395996, 3.0076394081115723, 3.920032024383545, 4.8335113525390625, 5.74699068069458, 6.661274194717407, 7.575557708740234, 8.492626905441284, 9.409696102142334, 10.334234952926636, 11.258773803710938, 12.195191860198975, 13.131609916687012, 14.039625644683838, 14.947641372680664, 15.871779918670654, 16.795918464660645, 17.718942642211914, 18.641966819763184, 19.571175813674927, 20.50038480758667, 21.41928505897522, 22.33818531036377, 23.26628851890564, 24.19439172744751, 25.11506199836731, 26.03573226928711, 26.961554765701294, 27.88737726211548, 28.810933113098145, 29.73448896408081, 30.652551889419556, 31.5706148147583, 32.49815511703491, 33.42569541931152, 34.3479323387146, 35.270169258117676, 36.18184185028076, 37.09351444244385, 38.023125648498535, 38.95273685455322, 39.872390270233154, 40.792043685913086, 41.71963286399841, 42.64722204208374, 43.57592248916626, 44.50462293624878, 45.43467998504639, 46.364737033843994, 47.31043481826782, 48.25613260269165, 49.17847394943237, 50.100815296173096, 51.02401614189148, 51.94721698760986, 52.87655854225159, 53.80590009689331, 54.73643708229065, 55.66697406768799, 56.589648723602295, 57.5123233795166, 58.4427649974823, 59.373206615448, 60.299657344818115, 61.22610807418823, 62.14566898345947, 63.06522989273071, 63.98557758331299, 64.90592527389526, 65.83585500717163, 66.765784740448, 67.68751621246338, 68.60924768447876, 69.55042052268982, 70.49159336090088, 71.427561044693, 72.36352872848511, 73.29712724685669, 74.23072576522827, 75.19156622886658, 76.15240669250488, 77.07227921485901, 77.99215173721313, 78.94055461883545, 79.88895750045776, 80.81484317779541, 81.74072885513306, 82.66026210784912, 83.57979536056519, 84.50864934921265, 85.43750333786011, 86.36313033103943, 87.28875732421875, 88.21183848381042, 89.1349196434021, 90.06343674659729, 90.99195384979248, 91.93692827224731, 92.88190269470215, 93.81294655799866, 94.74399042129517, 95.67214012145996, 96.60028982162476, 97.53066062927246, 98.46103143692017, 99.39515519142151, 100.32927894592285, 101.27098488807678, 102.21269083023071, 103.12911772727966, 104.04554462432861, 104.96304154396057, 105.88053846359253, 106.80825853347778, 107.73597860336304, 108.67492628097534, 109.61387395858765, 110.54153275489807, 111.4691915512085, 112.39844369888306, 113.32769584655762, 114.26265954971313, 115.19762325286865, 116.1315450668335, 117.06546688079834, 117.99013662338257, 118.9148063659668, 119.84947228431702, 120.78413820266724, 121.71001124382019, 122.63588428497314, 123.56827664375305, 124.50066900253296, 125.41463994979858, 126.32861089706421, 127.2395555973053, 128.1505002975464, 129.07082629203796, 129.99115228652954, 130.916241645813, 131.84133100509644, 132.75710105895996, 133.6728711128235, 134.58837270736694, 135.5038743019104, 136.4356508255005, 137.36742734909058, 138.30459213256836, 139.24175691604614, 140.17940139770508, 141.117045879364, 142.03797841072083, 142.95891094207764, 143.89942479133606, 144.83993864059448, 145.7610285282135, 146.68211841583252, 147.61259055137634, 148.54306268692017, 149.47233748435974, 150.40161228179932, 151.3472249507904, 152.2928376197815, 153.2245318889618, 154.1562261581421, 155.084942817688, 156.0136594772339, 156.94327116012573, 157.87288284301758, 158.79783654212952, 159.72279024124146, 160.6484706401825, 161.57415103912354, 162.52770066261292, 163.4812502861023, 164.41868257522583, 165.35611486434937, 166.28622674942017, 167.21633863449097, 168.14439749717712, 169.07245635986328, 170.0060212612152, 170.93958616256714, 171.8547558784485, 172.76992559432983, 173.68064260482788, 174.59135961532593, 175.50882124900818, 176.42628288269043, 177.34675574302673, 178.26722860336304, 179.19297909736633, 180.11872959136963, 181.0327377319336, 181.94674587249756, 182.86715364456177, 183.78756141662598, 184.70009803771973, 185.61263465881348, 187.46103143692017, 189.30942821502686]
[27.6, 27.6, 34.32, 34.32, 33.72, 33.72, 37.64, 37.64, 56.52, 56.52, 60.88, 60.88, 74.8, 74.8, 83.2, 83.2, 83.58, 83.58, 83.94, 83.94, 83.9, 83.9, 84.46, 84.46, 85.08, 85.08, 84.78, 84.78, 84.54, 84.54, 83.54, 83.54, 83.52, 83.52, 82.62, 82.62, 82.36, 82.36, 82.86, 82.86, 83.12, 83.12, 82.98, 82.98, 82.8, 82.8, 83.64, 83.64, 82.72, 82.72, 80.74, 80.74, 78.9, 78.9, 78.18, 78.18, 78.1, 78.1, 77.8, 77.8, 76.86, 76.86, 76.18, 76.18, 76.48, 76.48, 76.22, 76.22, 74.22, 74.22, 72.24, 72.24, 71.9, 71.9, 72.78, 72.78, 71.94, 71.94, 72.68, 72.68, 72.96, 72.96, 72.88, 72.88, 72.9, 72.9, 73.36, 73.36, 73.42, 73.42, 73.94, 73.94, 71.9, 71.9, 70.58, 70.58, 70.32, 70.32, 69.96, 69.96, 69.88, 69.88, 71.22, 71.22, 68.62, 68.62, 65.76, 65.76, 65.3, 65.3, 64.58, 64.58, 65.5, 65.5, 65.5, 65.5, 64.78, 64.78, 66.2, 66.2, 65.56, 65.56, 64.5, 64.5, 64.6, 64.6, 62.96, 62.96, 63.48, 63.48, 64.9, 64.9, 63.72, 63.72, 63.22, 63.22, 62.82, 62.82, 61.56, 61.56, 60.78, 60.78, 60.98, 60.98, 62.74, 62.74, 61.92, 61.92, 60.74, 60.74, 60.46, 60.46, 60.52, 60.52, 60.56, 60.56, 60.06, 60.06, 60.54, 60.54, 59.8, 59.8, 60.38, 60.38, 60.76, 60.76, 59.98, 59.98, 59.8, 59.8, 60.38, 60.38, 60.32, 60.32, 61.54, 61.54, 61.0, 61.0, 60.78, 60.78, 61.4, 61.4, 61.6, 61.6, 60.54, 60.54, 60.68, 60.68, 60.74, 60.74, 60.18, 60.18, 59.18, 59.18, 60.28, 60.28, 59.7, 59.7, 60.18, 60.18, 59.42, 59.42]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.8 , level_n_lowerb:0.8  

   Client 9, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Traceback (most recent call last):
  File "main_fedpac_co_teaching.py", line 250, in <module>
    local.filter_data(net=net_local.to(args.device), net2=net_local2.to(args.device), concept_matrix_local = concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1587, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

   Client 8, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550021 (local), 549696 (global); Percentage 99.94 (549696/550021)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 1.625, Test loss: 1.599, Test accuracy: 21.40
Round   0, Global train loss: 1.625, Global test loss: 1.599, Global test accuracy: 21.44
Round   1, Train loss: 1.607, Test loss: 1.594, Test accuracy: 23.76
Round   1, Global train loss: 1.607, Global test loss: 1.594, Global test accuracy: 23.66
Round   2, Train loss: 1.604, Test loss: 1.588, Test accuracy: 22.62
Round   2, Global train loss: 1.604, Global test loss: 1.588, Global test accuracy: 21.20
Round   3, Train loss: 1.604, Test loss: 1.581, Test accuracy: 31.02
Round   3, Global train loss: 1.604, Global test loss: 1.580, Global test accuracy: 32.32
Round   4, Train loss: 1.601, Test loss: 1.573, Test accuracy: 35.34
Round   4, Global train loss: 1.601, Global test loss: 1.573, Global test accuracy: 32.52
Round   5, Train loss: 1.597, Test loss: 1.561, Test accuracy: 40.56
Round   5, Global train loss: 1.597, Global test loss: 1.560, Global test accuracy: 37.10
Round   6, Train loss: 1.566, Test loss: 1.500, Test accuracy: 68.14
Round   6, Global train loss: 1.566, Global test loss: 1.497, Global test accuracy: 69.20
Round   7, Train loss: 1.585, Test loss: 1.483, Test accuracy: 68.24
Round   7, Global train loss: 1.585, Global test loss: 1.481, Global test accuracy: 64.02
Round   8, Train loss: 1.579, Test loss: 1.462, Test accuracy: 69.98
Round   8, Global train loss: 1.579, Global test loss: 1.460, Global test accuracy: 60.54
Round   9, Train loss: 1.576, Test loss: 1.437, Test accuracy: 79.16
Round   9, Global train loss: 1.576, Global test loss: 1.428, Global test accuracy: 74.60
Round  10, Train loss: 1.579, Test loss: 1.422, Test accuracy: 80.60
Round  10, Global train loss: 1.579, Global test loss: 1.415, Global test accuracy: 89.52
Round  11, Train loss: 1.371, Test loss: 1.237, Test accuracy: 87.42
Round  11, Global train loss: 1.371, Global test loss: 1.189, Global test accuracy: 85.44
Round  12, Train loss: 1.399, Test loss: 1.206, Test accuracy: 88.94
Round  12, Global train loss: 1.399, Global test loss: 1.160, Global test accuracy: 94.00
Round  13, Train loss: 1.570, Test loss: 1.250, Test accuracy: 85.60
Round  13, Global train loss: 1.570, Global test loss: 1.266, Global test accuracy: 92.10
Round  14, Train loss: 1.388, Test loss: 1.218, Test accuracy: 87.86
Round  14, Global train loss: 1.388, Global test loss: 1.145, Global test accuracy: 94.22
Round  15, Train loss: 1.430, Test loss: 1.221, Test accuracy: 85.34
Round  15, Global train loss: 1.430, Global test loss: 1.196, Global test accuracy: 92.88
Round  16, Train loss: 1.374, Test loss: 1.209, Test accuracy: 85.28
Round  16, Global train loss: 1.374, Global test loss: 1.129, Global test accuracy: 94.68
Round  17, Train loss: 1.566, Test loss: 1.245, Test accuracy: 83.56
Round  17, Global train loss: 1.566, Global test loss: 1.255, Global test accuracy: 94.14
Round  18, Train loss: 1.366, Test loss: 1.213, Test accuracy: 85.14
Round  18, Global train loss: 1.366, Global test loss: 1.117, Global test accuracy: 94.28
Round  19, Train loss: 1.355, Test loss: 1.197, Test accuracy: 86.52
Round  19, Global train loss: 1.355, Global test loss: 1.092, Global test accuracy: 94.62
Round  20, Train loss: 1.352, Test loss: 1.205, Test accuracy: 85.80
Round  20, Global train loss: 1.352, Global test loss: 1.114, Global test accuracy: 94.32
Round  21, Train loss: 1.546, Test loss: 1.237, Test accuracy: 83.86
Round  21, Global train loss: 1.546, Global test loss: 1.246, Global test accuracy: 91.72
Round  22, Train loss: 1.215, Test loss: 1.176, Test accuracy: 87.18
Round  22, Global train loss: 1.215, Global test loss: 1.057, Global test accuracy: 92.30
Round  23, Train loss: 1.404, Test loss: 1.190, Test accuracy: 85.38
Round  23, Global train loss: 1.404, Global test loss: 1.145, Global test accuracy: 94.58
Round  24, Train loss: 1.548, Test loss: 1.234, Test accuracy: 82.46
Round  24, Global train loss: 1.548, Global test loss: 1.260, Global test accuracy: 90.34
Round  25, Train loss: 1.536, Test loss: 1.258, Test accuracy: 80.82
Round  25, Global train loss: 1.536, Global test loss: 1.303, Global test accuracy: 73.06
Round  26, Train loss: 1.360, Test loss: 1.224, Test accuracy: 83.04
Round  26, Global train loss: 1.360, Global test loss: 1.122, Global test accuracy: 93.58
Round  27, Train loss: 1.396, Test loss: 1.210, Test accuracy: 83.86
Round  27, Global train loss: 1.396, Global test loss: 1.172, Global test accuracy: 92.30
Round  28, Train loss: 1.349, Test loss: 1.207, Test accuracy: 83.66
Round  28, Global train loss: 1.349, Global test loss: 1.101, Global test accuracy: 94.04
Round  29, Train loss: 1.536, Test loss: 1.245, Test accuracy: 80.52
Round  29, Global train loss: 1.536, Global test loss: 1.272, Global test accuracy: 88.34
Round  30, Train loss: 1.546, Test loss: 1.259, Test accuracy: 79.68
Round  30, Global train loss: 1.546, Global test loss: 1.275, Global test accuracy: 88.86
Round  31, Train loss: 1.542, Test loss: 1.272, Test accuracy: 78.40
Round  31, Global train loss: 1.542, Global test loss: 1.319, Global test accuracy: 78.04
Round  32, Train loss: 1.340, Test loss: 1.242, Test accuracy: 80.68
Round  32, Global train loss: 1.340, Global test loss: 1.170, Global test accuracy: 89.04
Round  33, Train loss: 1.523, Test loss: 1.276, Test accuracy: 77.24
Round  33, Global train loss: 1.523, Global test loss: 1.338, Global test accuracy: 66.30
Round  34, Train loss: 1.531, Test loss: 1.269, Test accuracy: 77.14
Round  34, Global train loss: 1.531, Global test loss: 1.287, Global test accuracy: 83.80
Round  35, Train loss: 1.517, Test loss: 1.290, Test accuracy: 74.62
Round  35, Global train loss: 1.517, Global test loss: 1.322, Global test accuracy: 79.26
Round  36, Train loss: 1.384, Test loss: 1.228, Test accuracy: 79.58
Round  36, Global train loss: 1.384, Global test loss: 1.161, Global test accuracy: 89.08
Round  37, Train loss: 1.325, Test loss: 1.225, Test accuracy: 79.76
Round  37, Global train loss: 1.325, Global test loss: 1.143, Global test accuracy: 91.08
Round  38, Train loss: 1.501, Test loss: 1.273, Test accuracy: 74.06
Round  38, Global train loss: 1.501, Global test loss: 1.282, Global test accuracy: 81.62
Round  39, Train loss: 1.510, Test loss: 1.269, Test accuracy: 75.26
Round  39, Global train loss: 1.510, Global test loss: 1.274, Global test accuracy: 83.24
Round  40, Train loss: 1.493, Test loss: 1.289, Test accuracy: 72.62
Round  40, Global train loss: 1.493, Global test loss: 1.263, Global test accuracy: 81.78
Round  41, Train loss: 1.496, Test loss: 1.306, Test accuracy: 68.90
Round  41, Global train loss: 1.496, Global test loss: 1.285, Global test accuracy: 77.38
Round  42, Train loss: 1.468, Test loss: 1.319, Test accuracy: 68.18
Round  42, Global train loss: 1.468, Global test loss: 1.311, Global test accuracy: 75.18
Round  43, Train loss: 1.318, Test loss: 1.240, Test accuracy: 76.54
Round  43, Global train loss: 1.318, Global test loss: 1.145, Global test accuracy: 86.90
Round  44, Train loss: 1.367, Test loss: 1.195, Test accuracy: 79.44
Round  44, Global train loss: 1.367, Global test loss: 1.126, Global test accuracy: 88.88
Round  45, Train loss: 1.319, Test loss: 1.231, Test accuracy: 75.50
Round  45, Global train loss: 1.319, Global test loss: 1.161, Global test accuracy: 84.80
Round  46, Train loss: 1.333, Test loss: 1.221, Test accuracy: 77.32
Round  46, Global train loss: 1.333, Global test loss: 1.157, Global test accuracy: 86.22
Round  47, Train loss: 1.275, Test loss: 1.221, Test accuracy: 76.74
Round  47, Global train loss: 1.275, Global test loss: 1.136, Global test accuracy: 85.24
Round  48, Train loss: 1.477, Test loss: 1.313, Test accuracy: 66.50
Round  48, Global train loss: 1.477, Global test loss: 1.347, Global test accuracy: 64.86
Round  49, Train loss: 1.488, Test loss: 1.315, Test accuracy: 65.68
Round  49, Global train loss: 1.488, Global test loss: 1.336, Global test accuracy: 68.30
Round  50, Train loss: 1.291, Test loss: 1.236, Test accuracy: 74.88
Round  50, Global train loss: 1.291, Global test loss: 1.140, Global test accuracy: 84.56
Round  51, Train loss: 1.309, Test loss: 1.231, Test accuracy: 74.66
Round  51, Global train loss: 1.309, Global test loss: 1.158, Global test accuracy: 86.02
Round  52, Train loss: 1.313, Test loss: 1.242, Test accuracy: 73.50
Round  52, Global train loss: 1.313, Global test loss: 1.196, Global test accuracy: 83.98
Round  53, Train loss: 1.316, Test loss: 1.215, Test accuracy: 77.14
Round  53, Global train loss: 1.316, Global test loss: 1.134, Global test accuracy: 88.90
Round  54, Train loss: 1.293, Test loss: 1.267, Test accuracy: 70.32
Round  54, Global train loss: 1.293, Global test loss: 1.222, Global test accuracy: 76.10
Round  55, Train loss: 1.286, Test loss: 1.252, Test accuracy: 71.58
Round  55, Global train loss: 1.286, Global test loss: 1.178, Global test accuracy: 80.92
Round  56, Train loss: 1.265, Test loss: 1.227, Test accuracy: 74.22
Round  56, Global train loss: 1.265, Global test loss: 1.134, Global test accuracy: 86.06
Round  57, Train loss: 1.285, Test loss: 1.254, Test accuracy: 70.74
Round  57, Global train loss: 1.285, Global test loss: 1.177, Global test accuracy: 80.20
Round  58, Train loss: 1.421, Test loss: 1.326, Test accuracy: 62.08
Round  58, Global train loss: 1.421, Global test loss: 1.345, Global test accuracy: 61.10
Round  59, Train loss: 1.294, Test loss: 1.262, Test accuracy: 70.16
Round  59, Global train loss: 1.294, Global test loss: 1.242, Global test accuracy: 70.34
Round  60, Train loss: 1.273, Test loss: 1.264, Test accuracy: 69.62
Round  60, Global train loss: 1.273, Global test loss: 1.189, Global test accuracy: 78.94
Round  61, Train loss: 1.243, Test loss: 1.282, Test accuracy: 67.24
Round  61, Global train loss: 1.243, Global test loss: 1.203, Global test accuracy: 79.00
Round  62, Train loss: 1.256, Test loss: 1.222, Test accuracy: 74.12
Round  62, Global train loss: 1.256, Global test loss: 1.143, Global test accuracy: 83.88
Round  63, Train loss: 1.372, Test loss: 1.332, Test accuracy: 61.24
Round  63, Global train loss: 1.372, Global test loss: 1.344, Global test accuracy: 62.58
Round  64, Train loss: 1.338, Test loss: 1.357, Test accuracy: 58.00
Round  64, Global train loss: 1.338, Global test loss: 1.332, Global test accuracy: 63.90
Round  65, Train loss: 1.350, Test loss: 1.386, Test accuracy: 54.52
Round  65, Global train loss: 1.350, Global test loss: 1.373, Global test accuracy: 58.10
Round  66, Train loss: 1.256, Test loss: 1.299, Test accuracy: 63.94
Round  66, Global train loss: 1.256, Global test loss: 1.271, Global test accuracy: 68.54
Round  67, Train loss: 1.318, Test loss: 1.359, Test accuracy: 57.08
Round  67, Global train loss: 1.318, Global test loss: 1.345, Global test accuracy: 60.50
Round  68, Train loss: 1.310, Test loss: 1.365, Test accuracy: 56.42
Round  68, Global train loss: 1.310, Global test loss: 1.354, Global test accuracy: 58.38
Round  69, Train loss: 1.411, Test loss: 1.348, Test accuracy: 58.06
Round  69, Global train loss: 1.411, Global test loss: 1.388, Global test accuracy: 52.36
Round  70, Train loss: 1.195, Test loss: 1.281, Test accuracy: 65.92
Round  70, Global train loss: 1.195, Global test loss: 1.220, Global test accuracy: 71.74
Round  71, Train loss: 1.371, Test loss: 1.359, Test accuracy: 56.70
Round  71, Global train loss: 1.371, Global test loss: 1.396, Global test accuracy: 50.24
Round  72, Train loss: 1.219, Test loss: 1.278, Test accuracy: 66.82
Round  72, Global train loss: 1.219, Global test loss: 1.248, Global test accuracy: 69.26
Round  73, Train loss: 1.190, Test loss: 1.245, Test accuracy: 69.60
Round  73, Global train loss: 1.190, Global test loss: 1.184, Global test accuracy: 76.14
Round  74, Train loss: 1.246, Test loss: 1.248, Test accuracy: 68.66
Round  74, Global train loss: 1.246, Global test loss: 1.181, Global test accuracy: 78.00
Round  75, Train loss: 1.306, Test loss: 1.410, Test accuracy: 49.92
Round  75, Global train loss: 1.306, Global test loss: 1.410, Global test accuracy: 50.02
Round  76, Train loss: 1.247, Test loss: 1.245, Test accuracy: 69.42
Round  76, Global train loss: 1.247, Global test loss: 1.172, Global test accuracy: 77.52
Round  77, Train loss: 1.187, Test loss: 1.272, Test accuracy: 66.60
Round  77, Global train loss: 1.187, Global test loss: 1.227, Global test accuracy: 72.12
Round  78, Train loss: 1.308, Test loss: 1.352, Test accuracy: 56.58
Round  78, Global train loss: 1.308, Global test loss: 1.343, Global test accuracy: 59.94
Round  79, Train loss: 1.181, Test loss: 1.307, Test accuracy: 62.20
Round  79, Global train loss: 1.181, Global test loss: 1.264, Global test accuracy: 67.84
Round  80, Train loss: 1.218, Test loss: 1.233, Test accuracy: 71.00
Round  80, Global train loss: 1.218, Global test loss: 1.191, Global test accuracy: 75.50
Round  81, Train loss: 1.159, Test loss: 1.267, Test accuracy: 65.86
Round  81, Global train loss: 1.159, Global test loss: 1.207, Global test accuracy: 74.20
Round  82, Train loss: 1.166, Test loss: 1.298, Test accuracy: 62.60
Round  82, Global train loss: 1.166, Global test loss: 1.235, Global test accuracy: 69.20
Round  83, Train loss: 1.182, Test loss: 1.240, Test accuracy: 69.52
Round  83, Global train loss: 1.182, Global test loss: 1.188, Global test accuracy: 74.94
Round  84, Train loss: 1.228, Test loss: 1.390, Test accuracy: 52.20
Round  84, Global train loss: 1.228, Global test loss: 1.374, Global test accuracy: 55.66
Round  85, Train loss: 1.200, Test loss: 1.256, Test accuracy: 67.60
Round  85, Global train loss: 1.200, Global test loss: 1.195, Global test accuracy: 74.58
Round  86, Train loss: 1.144, Test loss: 1.260, Test accuracy: 67.60
Round  86, Global train loss: 1.144, Global test loss: 1.206, Global test accuracy: 72.94
Round  87, Train loss: 1.268, Test loss: 1.403, Test accuracy: 50.12
Round  87, Global train loss: 1.268, Global test loss: 1.403, Global test accuracy: 49.78
Round  88, Train loss: 1.211, Test loss: 1.414, Test accuracy: 48.56
Round  88, Global train loss: 1.211, Global test loss: 1.413, Global test accuracy: 48.30
Round  89, Train loss: 1.126, Test loss: 1.277, Test accuracy: 65.02
Round  89, Global train loss: 1.126, Global test loss: 1.222, Global test accuracy: 70.96
Round  90, Train loss: 1.164, Test loss: 1.433, Test accuracy: 46.28
Round  90, Global train loss: 1.164, Global test loss: 1.411, Global test accuracy: 49.36/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  91, Train loss: 1.105, Test loss: 1.296, Test accuracy: 62.28
Round  91, Global train loss: 1.105, Global test loss: 1.245, Global test accuracy: 68.26
Round  92, Train loss: 1.192, Test loss: 1.264, Test accuracy: 65.80
Round  92, Global train loss: 1.192, Global test loss: 1.225, Global test accuracy: 71.36
Round  93, Train loss: 1.193, Test loss: 1.416, Test accuracy: 48.42
Round  93, Global train loss: 1.193, Global test loss: 1.404, Global test accuracy: 50.36
Round  94, Train loss: 1.209, Test loss: 1.279, Test accuracy: 64.60
Round  94, Global train loss: 1.209, Global test loss: 1.247, Global test accuracy: 68.26
Round  95, Train loss: 1.267, Test loss: 1.413, Test accuracy: 49.00
Round  95, Global train loss: 1.267, Global test loss: 1.421, Global test accuracy: 48.18
Round  96, Train loss: 1.192, Test loss: 1.460, Test accuracy: 43.28
Round  96, Global train loss: 1.192, Global test loss: 1.449, Global test accuracy: 45.42
Round  97, Train loss: 1.185, Test loss: 1.445, Test accuracy: 45.16
Round  97, Global train loss: 1.185, Global test loss: 1.445, Global test accuracy: 44.26
Round  98, Train loss: 1.173, Test loss: 1.484, Test accuracy: 40.38
Round  98, Global train loss: 1.173, Global test loss: 1.471, Global test accuracy: 41.92
Round  99, Train loss: 1.133, Test loss: 1.310, Test accuracy: 60.38
Round  99, Global train loss: 1.133, Global test loss: 1.287, Global test accuracy: 62.72
Final Round, Train loss: 1.163, Test loss: 1.304, Test accuracy: 60.54
Final Round, Global train loss: 1.163, Global test loss: 1.287, Global test accuracy: 62.72
Average accuracy final 10 rounds: 52.55799999999999
568.6170029640198
[1.1251003742218018, 2.0350520610809326, 2.997581720352173, 3.929415225982666, 4.847381114959717, 5.770576000213623, 6.672315835952759, 7.596133470535278, 8.512922048568726, 9.45072627067566, 10.374170064926147, 11.314903020858765, 12.24411416053772, 13.14829421043396, 14.079094886779785, 15.724202394485474, 17.399681329727173, 19.046593189239502, 20.72103190422058, 22.366657495498657, 24.04763650894165, 25.404274463653564, 26.75781750679016, 28.15614414215088, 29.606712341308594, 30.670238256454468, 31.575903177261353, 32.90947484970093, 34.20354199409485, 35.574509382247925, 36.947283029556274, 38.38944363594055, 39.313812255859375, 40.254883766174316, 41.17952609062195, 42.105592489242554, 43.058249950408936, 43.97305727005005, 44.88194561004639, 45.789074420928955, 46.69282412528992, 47.616137742996216, 48.53830099105835, 49.506882190704346, 50.432546854019165, 51.357964277267456, 52.285321950912476, 53.204169511795044, 54.14665722846985, 55.160340547561646, 56.07926654815674, 57.011091470718384, 57.922443866729736, 58.84145784378052, 59.751065492630005, 60.76928114891052, 61.74486827850342, 62.639647006988525, 63.59926676750183, 64.58145999908447, 65.51273322105408, 66.45202732086182, 67.41206645965576, 68.31678533554077, 69.25860142707825, 70.22749018669128, 71.16014552116394, 72.104238986969, 73.00874519348145, 73.92933511734009, 74.84937024116516, 75.75465106964111, 76.67657423019409, 77.60866165161133, 78.51871156692505, 79.44255423545837, 80.35130834579468, 81.2570972442627, 82.16546750068665, 83.10720658302307, 84.02827906608582, 84.99949073791504, 85.93127775192261, 86.86974048614502, 87.79962420463562, 88.7147741317749, 89.62038397789001, 90.51848554611206, 91.4434642791748, 92.36661553382874, 93.30035948753357, 94.21303462982178, 95.11673879623413, 96.04264426231384, 96.97571134567261, 97.90027117729187, 98.8053503036499, 99.71949481964111, 100.64610981941223, 101.59492468833923, 103.09848093986511]
[21.4, 23.76, 22.62, 31.02, 35.34, 40.56, 68.14, 68.24, 69.98, 79.16, 80.6, 87.42, 88.94, 85.6, 87.86, 85.34, 85.28, 83.56, 85.14, 86.52, 85.8, 83.86, 87.18, 85.38, 82.46, 80.82, 83.04, 83.86, 83.66, 80.52, 79.68, 78.4, 80.68, 77.24, 77.14, 74.62, 79.58, 79.76, 74.06, 75.26, 72.62, 68.9, 68.18, 76.54, 79.44, 75.5, 77.32, 76.74, 66.5, 65.68, 74.88, 74.66, 73.5, 77.14, 70.32, 71.58, 74.22, 70.74, 62.08, 70.16, 69.62, 67.24, 74.12, 61.24, 58.0, 54.52, 63.94, 57.08, 56.42, 58.06, 65.92, 56.7, 66.82, 69.6, 68.66, 49.92, 69.42, 66.6, 56.58, 62.2, 71.0, 65.86, 62.6, 69.52, 52.2, 67.6, 67.6, 50.12, 48.56, 65.02, 46.28, 62.28, 65.8, 48.42, 64.6, 49.0, 43.28, 45.16, 40.38, 60.38, 60.54]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fedpac_copsl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist,  filter_alg: loss_psl, level_n_system: 0.8 , level_n_lowerb:0.8  

   Client 7, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550021 (local), 549696 (global); Percentage 99.94 (549696/550021)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=5, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 1.627, Test loss: 1.605, Test accuracy: 27.72
Round   0, Global train loss: 1.627, Global test loss: 1.605, Global test accuracy: 28.22
Round   1, Train loss: 1.605, Test loss: 1.597, Test accuracy: 49.60
Round   1, Global train loss: 1.605, Global test loss: 1.597, Global test accuracy: 51.62
Round   2, Train loss: 1.601, Test loss: 1.585, Test accuracy: 64.48
Round   2, Global train loss: 1.601, Global test loss: 1.585, Global test accuracy: 73.26
Round   3, Train loss: 1.592, Test loss: 1.565, Test accuracy: 74.34
Round   3, Global train loss: 1.592, Global test loss: 1.565, Global test accuracy: 81.24
Round   4, Train loss: 1.580, Test loss: 1.534, Test accuracy: 76.22
Round   4, Global train loss: 1.580, Global test loss: 1.533, Global test accuracy: 81.92
Round   5, Train loss: 1.563, Test loss: 1.490, Test accuracy: 78.08
Round   5, Global train loss: 1.563, Global test loss: 1.487, Global test accuracy: 82.88
Round   6, Train loss: 1.541, Test loss: 1.432, Test accuracy: 80.44
Round   6, Global train loss: 1.541, Global test loss: 1.424, Global test accuracy: 85.50
Round   7, Train loss: 1.518, Test loss: 1.370, Test accuracy: 84.08
Round   7, Global train loss: 1.518, Global test loss: 1.356, Global test accuracy: 89.46
Round   8, Train loss: 1.498, Test loss: 1.315, Test accuracy: 86.22
Round   8, Global train loss: 1.498, Global test loss: 1.295, Global test accuracy: 91.32
Round   9, Train loss: 1.483, Test loss: 1.273, Test accuracy: 88.12
Round   9, Global train loss: 1.483, Global test loss: 1.246, Global test accuracy: 92.72
Round  10, Train loss: 1.424, Test loss: 1.257, Test accuracy: 88.88
Round  10, Global train loss: 1.424, Global test loss: 1.205, Global test accuracy: 94.62
Traceback (most recent call last):
  File "main_fedpac_copsl.py", line 280, in <module>
    w_local, loss, indd, class_center_local, class_num, noisy_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys,
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2559, in train
    self.filter_data(net, local_net, iter2-head_eps+1, local_eps-head_eps+1, concept_matrix_local)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2396, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
