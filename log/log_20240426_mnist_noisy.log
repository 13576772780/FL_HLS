nohup: ignoring input
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.4  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.292, Test loss: 2.290, Test accuracy: 20.94
Round   0, Global train loss: 2.292, Global test loss: 2.297, Global test accuracy: 17.10
Round   1, Train loss: 2.243, Test loss: 2.235, Test accuracy: 31.16
Round   1, Global train loss: 2.243, Global test loss: 2.274, Global test accuracy: 36.92
Round   2, Train loss: 2.054, Test loss: 2.098, Test accuracy: 42.88
Round   2, Global train loss: 2.054, Global test loss: 2.193, Global test accuracy: 35.32
Round   3, Train loss: 1.823, Test loss: 2.070, Test accuracy: 43.32
Round   3, Global train loss: 1.823, Global test loss: 2.172, Global test accuracy: 27.32
Round   4, Train loss: 1.812, Test loss: 1.969, Test accuracy: 54.92
Round   4, Global train loss: 1.812, Global test loss: 2.109, Global test accuracy: 43.64
Round   5, Train loss: 1.792, Test loss: 1.856, Test accuracy: 66.36
Round   5, Global train loss: 1.792, Global test loss: 2.066, Global test accuracy: 43.64
Round   6, Train loss: 1.742, Test loss: 1.829, Test accuracy: 66.32
Round   6, Global train loss: 1.742, Global test loss: 2.164, Global test accuracy: 27.26
Round   7, Train loss: 1.521, Test loss: 1.804, Test accuracy: 69.24
Round   7, Global train loss: 1.521, Global test loss: 2.113, Global test accuracy: 36.00
Round   8, Train loss: 1.511, Test loss: 1.784, Test accuracy: 71.62
Round   8, Global train loss: 1.511, Global test loss: 1.984, Global test accuracy: 53.02
Round   9, Train loss: 1.584, Test loss: 1.754, Test accuracy: 73.54
Round   9, Global train loss: 1.584, Global test loss: 2.008, Global test accuracy: 46.50
Round  10, Train loss: 1.896, Test loss: 1.704, Test accuracy: 78.00
Round  10, Global train loss: 1.896, Global test loss: 2.094, Global test accuracy: 42.34
Round  11, Train loss: 1.545, Test loss: 1.703, Test accuracy: 78.10
Round  11, Global train loss: 1.545, Global test loss: 1.963, Global test accuracy: 53.94
Round  12, Train loss: 1.578, Test loss: 1.693, Test accuracy: 78.86
Round  12, Global train loss: 1.578, Global test loss: 2.010, Global test accuracy: 46.82
Round  13, Train loss: 1.627, Test loss: 1.649, Test accuracy: 82.84
Round  13, Global train loss: 1.627, Global test loss: 2.037, Global test accuracy: 41.62
Round  14, Train loss: 1.626, Test loss: 1.646, Test accuracy: 83.02
Round  14, Global train loss: 1.626, Global test loss: 2.108, Global test accuracy: 34.88
Round  15, Train loss: 1.561, Test loss: 1.644, Test accuracy: 82.98
Round  15, Global train loss: 1.561, Global test loss: 2.021, Global test accuracy: 47.30
Round  16, Train loss: 1.619, Test loss: 1.641, Test accuracy: 83.18
Round  16, Global train loss: 1.619, Global test loss: 2.052, Global test accuracy: 41.76
Round  17, Train loss: 1.537, Test loss: 1.640, Test accuracy: 83.18
Round  17, Global train loss: 1.537, Global test loss: 2.046, Global test accuracy: 41.20
Round  18, Train loss: 1.472, Test loss: 1.640, Test accuracy: 83.18
Round  18, Global train loss: 1.472, Global test loss: 1.960, Global test accuracy: 53.06
Round  19, Train loss: 1.590, Test loss: 1.624, Test accuracy: 84.80
Round  19, Global train loss: 1.590, Global test loss: 1.976, Global test accuracy: 50.28
Round  20, Train loss: 1.528, Test loss: 1.612, Test accuracy: 86.26
Round  20, Global train loss: 1.528, Global test loss: 2.114, Global test accuracy: 33.72
Round  21, Train loss: 1.538, Test loss: 1.612, Test accuracy: 86.38
Round  21, Global train loss: 1.538, Global test loss: 2.028, Global test accuracy: 44.34
Round  22, Train loss: 1.475, Test loss: 1.611, Test accuracy: 86.52
Round  22, Global train loss: 1.475, Global test loss: 2.107, Global test accuracy: 34.98
Round  23, Train loss: 1.621, Test loss: 1.607, Test accuracy: 86.72
Round  23, Global train loss: 1.621, Global test loss: 1.982, Global test accuracy: 50.32
Round  24, Train loss: 1.541, Test loss: 1.605, Test accuracy: 86.72
Round  24, Global train loss: 1.541, Global test loss: 2.003, Global test accuracy: 47.32
Round  25, Train loss: 1.559, Test loss: 1.602, Test accuracy: 86.88
Round  25, Global train loss: 1.559, Global test loss: 2.045, Global test accuracy: 40.84
Round  26, Train loss: 1.536, Test loss: 1.602, Test accuracy: 86.92
Round  26, Global train loss: 1.536, Global test loss: 2.111, Global test accuracy: 33.28
Round  27, Train loss: 1.598, Test loss: 1.601, Test accuracy: 86.92
Round  27, Global train loss: 1.598, Global test loss: 2.031, Global test accuracy: 43.32
Round  28, Train loss: 1.542, Test loss: 1.600, Test accuracy: 86.94
Round  28, Global train loss: 1.542, Global test loss: 2.009, Global test accuracy: 47.38
Round  29, Train loss: 1.534, Test loss: 1.600, Test accuracy: 86.96
Round  29, Global train loss: 1.534, Global test loss: 2.111, Global test accuracy: 34.92
Round  30, Train loss: 1.473, Test loss: 1.600, Test accuracy: 86.86
Round  30, Global train loss: 1.473, Global test loss: 1.991, Global test accuracy: 47.68
Round  31, Train loss: 1.538, Test loss: 1.599, Test accuracy: 86.90
Round  31, Global train loss: 1.538, Global test loss: 2.156, Global test accuracy: 27.94
Round  32, Train loss: 1.541, Test loss: 1.599, Test accuracy: 86.82
Round  32, Global train loss: 1.541, Global test loss: 2.035, Global test accuracy: 41.64
Round  33, Train loss: 1.469, Test loss: 1.599, Test accuracy: 86.82
Round  33, Global train loss: 1.469, Global test loss: 2.105, Global test accuracy: 35.18
Round  34, Train loss: 1.540, Test loss: 1.598, Test accuracy: 86.86
Round  34, Global train loss: 1.540, Global test loss: 2.121, Global test accuracy: 31.36
Round  35, Train loss: 1.538, Test loss: 1.598, Test accuracy: 86.82
Round  35, Global train loss: 1.538, Global test loss: 2.002, Global test accuracy: 47.72
Round  36, Train loss: 1.540, Test loss: 1.598, Test accuracy: 86.82
Round  36, Global train loss: 1.540, Global test loss: 2.005, Global test accuracy: 45.88
Round  37, Train loss: 1.538, Test loss: 1.598, Test accuracy: 86.84
Round  37, Global train loss: 1.538, Global test loss: 2.126, Global test accuracy: 30.68
Round  38, Train loss: 1.541, Test loss: 1.597, Test accuracy: 86.82
Round  38, Global train loss: 1.541, Global test loss: 2.051, Global test accuracy: 41.50
Round  39, Train loss: 1.534, Test loss: 1.597, Test accuracy: 86.74
Round  39, Global train loss: 1.534, Global test loss: 2.035, Global test accuracy: 40.16
Round  40, Train loss: 1.531, Test loss: 1.597, Test accuracy: 86.78
Round  40, Global train loss: 1.531, Global test loss: 2.016, Global test accuracy: 44.14
Round  41, Train loss: 1.469, Test loss: 1.597, Test accuracy: 86.74
Round  41, Global train loss: 1.469, Global test loss: 2.149, Global test accuracy: 28.76
Round  42, Train loss: 1.535, Test loss: 1.597, Test accuracy: 86.76
Round  42, Global train loss: 1.535, Global test loss: 2.161, Global test accuracy: 27.44
Round  43, Train loss: 1.540, Test loss: 1.597, Test accuracy: 86.82
Round  43, Global train loss: 1.540, Global test loss: 2.115, Global test accuracy: 29.88
Round  44, Train loss: 1.596, Test loss: 1.597, Test accuracy: 86.80
Round  44, Global train loss: 1.596, Global test loss: 1.944, Global test accuracy: 52.38
Round  45, Train loss: 1.534, Test loss: 1.597, Test accuracy: 86.78
Round  45, Global train loss: 1.534, Global test loss: 2.110, Global test accuracy: 33.48
Round  46, Train loss: 1.536, Test loss: 1.596, Test accuracy: 86.86
Round  46, Global train loss: 1.536, Global test loss: 2.050, Global test accuracy: 40.48
Round  47, Train loss: 1.466, Test loss: 1.596, Test accuracy: 86.88
Round  47, Global train loss: 1.466, Global test loss: 2.036, Global test accuracy: 44.96
Round  48, Train loss: 1.531, Test loss: 1.596, Test accuracy: 86.88
Round  48, Global train loss: 1.531, Global test loss: 1.991, Global test accuracy: 47.94
Round  49, Train loss: 1.535, Test loss: 1.596, Test accuracy: 86.88
Round  49, Global train loss: 1.535, Global test loss: 1.953, Global test accuracy: 52.08
Round  50, Train loss: 1.532, Test loss: 1.596, Test accuracy: 86.86
Round  50, Global train loss: 1.532, Global test loss: 2.069, Global test accuracy: 36.30
Round  51, Train loss: 1.468, Test loss: 1.596, Test accuracy: 86.84
Round  51, Global train loss: 1.468, Global test loss: 1.993, Global test accuracy: 48.54
Round  52, Train loss: 1.597, Test loss: 1.596, Test accuracy: 86.80
Round  52, Global train loss: 1.597, Global test loss: 1.996, Global test accuracy: 53.10
Round  53, Train loss: 1.466, Test loss: 1.596, Test accuracy: 86.84
Round  53, Global train loss: 1.466, Global test loss: 2.005, Global test accuracy: 44.96
Round  54, Train loss: 1.531, Test loss: 1.596, Test accuracy: 86.84
Round  54, Global train loss: 1.531, Global test loss: 2.014, Global test accuracy: 44.90
Round  55, Train loss: 1.533, Test loss: 1.595, Test accuracy: 86.92
Round  55, Global train loss: 1.533, Global test loss: 2.096, Global test accuracy: 34.56
Round  56, Train loss: 1.466, Test loss: 1.595, Test accuracy: 86.88
Round  56, Global train loss: 1.466, Global test loss: 2.105, Global test accuracy: 35.16
Round  57, Train loss: 1.471, Test loss: 1.595, Test accuracy: 86.88
Round  57, Global train loss: 1.471, Global test loss: 2.086, Global test accuracy: 38.36
Round  58, Train loss: 1.468, Test loss: 1.595, Test accuracy: 86.86
Round  58, Global train loss: 1.468, Global test loss: 2.091, Global test accuracy: 35.84
Round  59, Train loss: 1.565, Test loss: 1.582, Test accuracy: 88.42
Round  59, Global train loss: 1.565, Global test loss: 1.961, Global test accuracy: 51.08
Round  60, Train loss: 1.532, Test loss: 1.582, Test accuracy: 88.46
Round  60, Global train loss: 1.532, Global test loss: 2.042, Global test accuracy: 41.36
Round  61, Train loss: 1.541, Test loss: 1.581, Test accuracy: 88.46
Round  61, Global train loss: 1.541, Global test loss: 2.121, Global test accuracy: 32.06
Round  62, Train loss: 1.535, Test loss: 1.580, Test accuracy: 88.58
Round  62, Global train loss: 1.535, Global test loss: 1.958, Global test accuracy: 50.92
Round  63, Train loss: 1.469, Test loss: 1.580, Test accuracy: 88.56
Round  63, Global train loss: 1.469, Global test loss: 2.100, Global test accuracy: 36.14
Round  64, Train loss: 1.472, Test loss: 1.580, Test accuracy: 88.60
Round  64, Global train loss: 1.472, Global test loss: 2.099, Global test accuracy: 35.66
Round  65, Train loss: 1.538, Test loss: 1.580, Test accuracy: 88.58
Round  65, Global train loss: 1.538, Global test loss: 2.071, Global test accuracy: 37.86
Round  66, Train loss: 1.598, Test loss: 1.580, Test accuracy: 88.58
Round  66, Global train loss: 1.598, Global test loss: 2.042, Global test accuracy: 40.76
Round  67, Train loss: 1.534, Test loss: 1.579, Test accuracy: 88.58
Round  67, Global train loss: 1.534, Global test loss: 1.875, Global test accuracy: 62.48
Round  68, Train loss: 1.537, Test loss: 1.579, Test accuracy: 88.62
Round  68, Global train loss: 1.537, Global test loss: 1.951, Global test accuracy: 54.18
Round  69, Train loss: 1.466, Test loss: 1.579, Test accuracy: 88.60
Round  69, Global train loss: 1.466, Global test loss: 2.089, Global test accuracy: 35.86
Round  70, Train loss: 1.469, Test loss: 1.579, Test accuracy: 88.58
Round  70, Global train loss: 1.469, Global test loss: 2.100, Global test accuracy: 34.42
Round  71, Train loss: 1.595, Test loss: 1.579, Test accuracy: 88.58
Round  71, Global train loss: 1.595, Global test loss: 2.073, Global test accuracy: 39.26
Round  72, Train loss: 1.533, Test loss: 1.579, Test accuracy: 88.64
Round  72, Global train loss: 1.533, Global test loss: 2.063, Global test accuracy: 40.84
Round  73, Train loss: 1.533, Test loss: 1.579, Test accuracy: 88.60
Round  73, Global train loss: 1.533, Global test loss: 1.949, Global test accuracy: 52.44
Round  74, Train loss: 1.467, Test loss: 1.579, Test accuracy: 88.60
Round  74, Global train loss: 1.467, Global test loss: 2.069, Global test accuracy: 40.22
Round  75, Train loss: 1.467, Test loss: 1.579, Test accuracy: 88.60
Round  75, Global train loss: 1.467, Global test loss: 2.042, Global test accuracy: 43.78
Round  76, Train loss: 1.467, Test loss: 1.579, Test accuracy: 88.62
Round  76, Global train loss: 1.467, Global test loss: 2.063, Global test accuracy: 37.94
Round  77, Train loss: 1.467, Test loss: 1.579, Test accuracy: 88.56
Round  77, Global train loss: 1.467, Global test loss: 1.997, Global test accuracy: 46.44
Round  78, Train loss: 1.532, Test loss: 1.580, Test accuracy: 88.54
Round  78, Global train loss: 1.532, Global test loss: 2.121, Global test accuracy: 31.14
Round  79, Train loss: 1.533, Test loss: 1.580, Test accuracy: 88.48
Round  79, Global train loss: 1.533, Global test loss: 2.129, Global test accuracy: 30.96
Round  80, Train loss: 1.531, Test loss: 1.580, Test accuracy: 88.48
Round  80, Global train loss: 1.531, Global test loss: 1.956, Global test accuracy: 50.84
Round  81, Train loss: 1.469, Test loss: 1.580, Test accuracy: 88.48
Round  81, Global train loss: 1.469, Global test loss: 2.040, Global test accuracy: 41.66
Round  82, Train loss: 1.531, Test loss: 1.579, Test accuracy: 88.52
Round  82, Global train loss: 1.531, Global test loss: 2.019, Global test accuracy: 42.84
Round  83, Train loss: 1.531, Test loss: 1.579, Test accuracy: 88.56
Round  83, Global train loss: 1.531, Global test loss: 2.043, Global test accuracy: 40.50
Round  84, Train loss: 1.470, Test loss: 1.579, Test accuracy: 88.56
Round  84, Global train loss: 1.470, Global test loss: 1.980, Global test accuracy: 48.98
Round  85, Train loss: 1.532, Test loss: 1.579, Test accuracy: 88.54
Round  85, Global train loss: 1.532, Global test loss: 2.096, Global test accuracy: 34.36
Round  86, Train loss: 1.465, Test loss: 1.579, Test accuracy: 88.58
Round  86, Global train loss: 1.465, Global test loss: 2.004, Global test accuracy: 45.00
Round  87, Train loss: 1.466, Test loss: 1.579, Test accuracy: 88.50
Round  87, Global train loss: 1.466, Global test loss: 1.993, Global test accuracy: 47.22
Round  88, Train loss: 1.529, Test loss: 1.579, Test accuracy: 88.50
Round  88, Global train loss: 1.529, Global test loss: 2.008, Global test accuracy: 43.42
Round  89, Train loss: 1.465, Test loss: 1.578, Test accuracy: 88.62
Round  89, Global train loss: 1.465, Global test loss: 2.017, Global test accuracy: 43.14
Round  90, Train loss: 1.509, Test loss: 1.568, Test accuracy: 89.92
Round  90, Global train loss: 1.509, Global test loss: 1.979, Global test accuracy: 50.20
Round  91, Train loss: 1.468, Test loss: 1.568, Test accuracy: 89.94
Round  91, Global train loss: 1.468, Global test loss: 2.018, Global test accuracy: 44.30
Round  92, Train loss: 1.482, Test loss: 1.567, Test accuracy: 89.98
Round  92, Global train loss: 1.482, Global test loss: 1.976, Global test accuracy: 49.74
Round  93, Train loss: 1.470, Test loss: 1.567, Test accuracy: 90.00
Round  93, Global train loss: 1.470, Global test loss: 2.070, Global test accuracy: 37.14
Round  94, Train loss: 1.470, Test loss: 1.567, Test accuracy: 90.00
Round  94, Global train loss: 1.470, Global test loss: 1.983, Global test accuracy: 48.30
Round  95, Train loss: 1.481, Test loss: 1.565, Test accuracy: 90.08
Round  95, Global train loss: 1.481, Global test loss: 1.977, Global test accuracy: 48.38/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 1.467, Test loss: 1.565, Test accuracy: 90.08
Round  96, Global train loss: 1.467, Global test loss: 2.099, Global test accuracy: 34.92
Round  97, Train loss: 1.471, Test loss: 1.565, Test accuracy: 90.08
Round  97, Global train loss: 1.471, Global test loss: 2.016, Global test accuracy: 44.72
Round  98, Train loss: 1.466, Test loss: 1.565, Test accuracy: 90.08
Round  98, Global train loss: 1.466, Global test loss: 2.001, Global test accuracy: 45.64
Round  99, Train loss: 1.473, Test loss: 1.565, Test accuracy: 90.04
Round  99, Global train loss: 1.473, Global test loss: 2.023, Global test accuracy: 42.54
Final Round, Train loss: 1.488, Test loss: 1.565, Test accuracy: 90.06
Final Round, Global train loss: 1.488, Global test loss: 2.023, Global test accuracy: 42.54
Average accuracy final 10 rounds: 90.02 

Average global accuracy final 10 rounds: 44.587999999999994 

540.0053129196167
[0.8436410427093506, 1.6872820854187012, 2.4315903186798096, 3.175898551940918, 3.917444944381714, 4.65899133682251, 5.390124559402466, 6.121257781982422, 6.888945817947388, 7.6566338539123535, 8.42858362197876, 9.200533390045166, 9.972733497619629, 10.744933605194092, 11.514524459838867, 12.284115314483643, 13.057005643844604, 13.829895973205566, 14.598652839660645, 15.367409706115723, 16.133774995803833, 16.900140285491943, 17.67129611968994, 18.44245195388794, 19.209264516830444, 19.97607707977295, 20.74135136604309, 21.506625652313232, 22.27397131919861, 23.041316986083984, 23.811251640319824, 24.581186294555664, 25.350574493408203, 26.119962692260742, 26.887964725494385, 27.655966758728027, 28.425991773605347, 29.196016788482666, 29.965204000473022, 30.73439121246338, 31.50127148628235, 32.26815176010132, 33.03891897201538, 33.80968618392944, 34.5771279335022, 35.34456968307495, 36.11373519897461, 36.88290071487427, 37.652183055877686, 38.4214653968811, 39.195013999938965, 39.968562602996826, 40.739691495895386, 41.510820388793945, 42.27833652496338, 43.04585266113281, 43.81091904640198, 44.57598543167114, 45.34359431266785, 46.11120319366455, 46.88279438018799, 47.654385566711426, 48.42445158958435, 49.194517612457275, 49.9622642993927, 50.730010986328125, 51.5009663105011, 52.27192163467407, 53.04313564300537, 53.81434965133667, 54.58476972579956, 55.35518980026245, 56.12606430053711, 56.89693880081177, 57.66981291770935, 58.442687034606934, 59.21883988380432, 59.99499273300171, 60.77538585662842, 61.55577898025513, 62.32892370223999, 63.10206842422485, 63.87556266784668, 64.6490569114685, 65.42117762565613, 66.19329833984375, 66.97709441184998, 67.7608904838562, 68.54038119316101, 69.31987190246582, 70.09609365463257, 70.87231540679932, 71.64909863471985, 72.42588186264038, 73.19784379005432, 73.96980571746826, 74.7396342754364, 75.50946283340454, 76.29160594940186, 77.07374906539917, 77.8511176109314, 78.62848615646362, 79.39953970909119, 80.17059326171875, 80.94399762153625, 81.71740198135376, 82.48897933959961, 83.26055669784546, 84.03264045715332, 84.80472421646118, 85.58593964576721, 86.36715507507324, 87.14547681808472, 87.92379856109619, 88.69620513916016, 89.46861171722412, 90.23940110206604, 91.01019048690796, 91.78064155578613, 92.5510926246643, 93.3227608203888, 94.09442901611328, 94.86682105064392, 95.63921308517456, 96.41307044029236, 97.18692779541016, 97.95587825775146, 98.72482872009277, 99.49681401252747, 100.26879930496216, 101.05191779136658, 101.835036277771, 102.61763525009155, 103.40023422241211, 104.18046712875366, 104.96070003509521, 105.73118877410889, 106.50167751312256, 107.27143621444702, 108.04119491577148, 108.81611132621765, 109.59102773666382, 110.3634786605835, 111.13592958450317, 111.92131400108337, 112.70669841766357, 113.47859454154968, 114.25049066543579, 115.02295017242432, 115.79540967941284, 116.56897521018982, 117.3425407409668, 118.12270021438599, 118.90285968780518, 119.68811440467834, 120.47336912155151, 121.25736021995544, 122.04135131835938, 122.81798553466797, 123.59461975097656, 124.36886811256409, 125.14311647415161, 125.92745018005371, 126.71178388595581, 127.49637365341187, 128.28096342086792, 129.06470036506653, 129.84843730926514, 130.6298279762268, 131.41121864318848, 132.18429851531982, 132.95737838745117, 133.73107719421387, 134.50477600097656, 135.28515529632568, 136.0655345916748, 136.85009717941284, 137.63465976715088, 138.41649055480957, 139.19832134246826, 139.98059749603271, 140.76287364959717, 141.5383129119873, 142.31375217437744, 143.09214234352112, 143.8705325126648, 144.65742588043213, 145.44431924819946, 146.2311737537384, 147.01802825927734, 147.80011892318726, 148.58220958709717, 149.359436750412, 150.1366639137268, 150.91299486160278, 151.68932580947876, 152.47595477104187, 153.26258373260498, 154.04775428771973, 154.83292484283447, 156.40307760238647, 157.97323036193848]
[20.94, 20.94, 31.16, 31.16, 42.88, 42.88, 43.32, 43.32, 54.92, 54.92, 66.36, 66.36, 66.32, 66.32, 69.24, 69.24, 71.62, 71.62, 73.54, 73.54, 78.0, 78.0, 78.1, 78.1, 78.86, 78.86, 82.84, 82.84, 83.02, 83.02, 82.98, 82.98, 83.18, 83.18, 83.18, 83.18, 83.18, 83.18, 84.8, 84.8, 86.26, 86.26, 86.38, 86.38, 86.52, 86.52, 86.72, 86.72, 86.72, 86.72, 86.88, 86.88, 86.92, 86.92, 86.92, 86.92, 86.94, 86.94, 86.96, 86.96, 86.86, 86.86, 86.9, 86.9, 86.82, 86.82, 86.82, 86.82, 86.86, 86.86, 86.82, 86.82, 86.82, 86.82, 86.84, 86.84, 86.82, 86.82, 86.74, 86.74, 86.78, 86.78, 86.74, 86.74, 86.76, 86.76, 86.82, 86.82, 86.8, 86.8, 86.78, 86.78, 86.86, 86.86, 86.88, 86.88, 86.88, 86.88, 86.88, 86.88, 86.86, 86.86, 86.84, 86.84, 86.8, 86.8, 86.84, 86.84, 86.84, 86.84, 86.92, 86.92, 86.88, 86.88, 86.88, 86.88, 86.86, 86.86, 88.42, 88.42, 88.46, 88.46, 88.46, 88.46, 88.58, 88.58, 88.56, 88.56, 88.6, 88.6, 88.58, 88.58, 88.58, 88.58, 88.58, 88.58, 88.62, 88.62, 88.6, 88.6, 88.58, 88.58, 88.58, 88.58, 88.64, 88.64, 88.6, 88.6, 88.6, 88.6, 88.6, 88.6, 88.62, 88.62, 88.56, 88.56, 88.54, 88.54, 88.48, 88.48, 88.48, 88.48, 88.48, 88.48, 88.52, 88.52, 88.56, 88.56, 88.56, 88.56, 88.54, 88.54, 88.58, 88.58, 88.5, 88.5, 88.5, 88.5, 88.62, 88.62, 89.92, 89.92, 89.94, 89.94, 89.98, 89.98, 90.0, 90.0, 90.0, 90.0, 90.08, 90.08, 90.08, 90.08, 90.08, 90.08, 90.08, 90.08, 90.04, 90.04, 90.06, 90.06]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.4  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.300, Test loss: 2.299, Test accuracy: 15.20
Round   0, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 15.22
Round   1, Train loss: 2.296, Test loss: 2.293, Test accuracy: 30.44
Round   1, Global train loss: 2.296, Global test loss: 2.293, Global test accuracy: 32.18
Round   2, Train loss: 2.285, Test loss: 2.279, Test accuracy: 35.08
Round   2, Global train loss: 2.285, Global test loss: 2.275, Global test accuracy: 35.42
Round   3, Train loss: 2.224, Test loss: 2.182, Test accuracy: 39.60
Round   3, Global train loss: 2.224, Global test loss: 2.138, Global test accuracy: 41.50
Round   4, Train loss: 2.032, Test loss: 2.072, Test accuracy: 45.40
Round   4, Global train loss: 2.032, Global test loss: 1.984, Global test accuracy: 49.70
Round   5, Train loss: 1.935, Test loss: 1.985, Test accuracy: 54.18
Round   5, Global train loss: 1.935, Global test loss: 1.889, Global test accuracy: 62.60
Round   6, Train loss: 1.836, Test loss: 1.948, Test accuracy: 56.58
Round   6, Global train loss: 1.836, Global test loss: 1.836, Global test accuracy: 64.30
Round   7, Train loss: 1.795, Test loss: 1.854, Test accuracy: 62.68
Round   7, Global train loss: 1.795, Global test loss: 1.819, Global test accuracy: 64.96
Round   8, Train loss: 1.782, Test loss: 1.849, Test accuracy: 62.78
Round   8, Global train loss: 1.782, Global test loss: 1.813, Global test accuracy: 65.38
Round   9, Train loss: 1.777, Test loss: 1.828, Test accuracy: 64.66
Round   9, Global train loss: 1.777, Global test loss: 1.809, Global test accuracy: 65.74
Round  10, Train loss: 1.762, Test loss: 1.814, Test accuracy: 65.48
Round  10, Global train loss: 1.762, Global test loss: 1.799, Global test accuracy: 66.50
Round  11, Train loss: 1.740, Test loss: 1.793, Test accuracy: 67.90
Round  11, Global train loss: 1.740, Global test loss: 1.754, Global test accuracy: 71.38
Round  12, Train loss: 1.696, Test loss: 1.768, Test accuracy: 69.88
Round  12, Global train loss: 1.696, Global test loss: 1.736, Global test accuracy: 73.18
Round  13, Train loss: 1.695, Test loss: 1.750, Test accuracy: 71.76
Round  13, Global train loss: 1.695, Global test loss: 1.728, Global test accuracy: 73.66
Round  14, Train loss: 1.687, Test loss: 1.746, Test accuracy: 72.18
Round  14, Global train loss: 1.687, Global test loss: 1.724, Global test accuracy: 74.00
Round  15, Train loss: 1.668, Test loss: 1.735, Test accuracy: 73.58
Round  15, Global train loss: 1.668, Global test loss: 1.688, Global test accuracy: 79.06
Round  16, Train loss: 1.642, Test loss: 1.709, Test accuracy: 76.42
Round  16, Global train loss: 1.642, Global test loss: 1.674, Global test accuracy: 80.00
Round  17, Train loss: 1.616, Test loss: 1.696, Test accuracy: 77.60
Round  17, Global train loss: 1.616, Global test loss: 1.658, Global test accuracy: 81.46
Round  18, Train loss: 1.616, Test loss: 1.688, Test accuracy: 78.28
Round  18, Global train loss: 1.616, Global test loss: 1.654, Global test accuracy: 81.88
Round  19, Train loss: 1.611, Test loss: 1.675, Test accuracy: 79.50
Round  19, Global train loss: 1.611, Global test loss: 1.650, Global test accuracy: 82.44
Round  20, Train loss: 1.592, Test loss: 1.666, Test accuracy: 80.36
Round  20, Global train loss: 1.592, Global test loss: 1.650, Global test accuracy: 82.10
Round  21, Train loss: 1.593, Test loss: 1.667, Test accuracy: 80.30
Round  21, Global train loss: 1.593, Global test loss: 1.645, Global test accuracy: 82.06
Round  22, Train loss: 1.584, Test loss: 1.663, Test accuracy: 80.58
Round  22, Global train loss: 1.584, Global test loss: 1.643, Global test accuracy: 82.06
Round  23, Train loss: 1.592, Test loss: 1.659, Test accuracy: 81.00
Round  23, Global train loss: 1.592, Global test loss: 1.646, Global test accuracy: 81.72
Round  24, Train loss: 1.574, Test loss: 1.657, Test accuracy: 81.12
Round  24, Global train loss: 1.574, Global test loss: 1.642, Global test accuracy: 82.08
Round  25, Train loss: 1.582, Test loss: 1.652, Test accuracy: 81.54
Round  25, Global train loss: 1.582, Global test loss: 1.642, Global test accuracy: 82.10
Round  26, Train loss: 1.584, Test loss: 1.650, Test accuracy: 81.66
Round  26, Global train loss: 1.584, Global test loss: 1.640, Global test accuracy: 82.32
Round  27, Train loss: 1.595, Test loss: 1.648, Test accuracy: 81.66
Round  27, Global train loss: 1.595, Global test loss: 1.640, Global test accuracy: 82.34
Round  28, Train loss: 1.580, Test loss: 1.646, Test accuracy: 81.80
Round  28, Global train loss: 1.580, Global test loss: 1.637, Global test accuracy: 82.62
Round  29, Train loss: 1.574, Test loss: 1.644, Test accuracy: 81.82
Round  29, Global train loss: 1.574, Global test loss: 1.638, Global test accuracy: 82.64
Round  30, Train loss: 1.582, Test loss: 1.645, Test accuracy: 81.80
Round  30, Global train loss: 1.582, Global test loss: 1.638, Global test accuracy: 82.54
Round  31, Train loss: 1.565, Test loss: 1.643, Test accuracy: 81.80
Round  31, Global train loss: 1.565, Global test loss: 1.635, Global test accuracy: 82.84
Round  32, Train loss: 1.586, Test loss: 1.641, Test accuracy: 81.98
Round  32, Global train loss: 1.586, Global test loss: 1.640, Global test accuracy: 82.10
Round  33, Train loss: 1.561, Test loss: 1.641, Test accuracy: 81.98
Round  33, Global train loss: 1.561, Global test loss: 1.634, Global test accuracy: 83.04
Round  34, Train loss: 1.560, Test loss: 1.640, Test accuracy: 82.12
Round  34, Global train loss: 1.560, Global test loss: 1.633, Global test accuracy: 83.16
Round  35, Train loss: 1.574, Test loss: 1.638, Test accuracy: 82.26
Round  35, Global train loss: 1.574, Global test loss: 1.633, Global test accuracy: 82.92
Round  36, Train loss: 1.580, Test loss: 1.637, Test accuracy: 82.52
Round  36, Global train loss: 1.580, Global test loss: 1.637, Global test accuracy: 81.96
Round  37, Train loss: 1.578, Test loss: 1.637, Test accuracy: 82.56
Round  37, Global train loss: 1.578, Global test loss: 1.634, Global test accuracy: 82.84
Round  38, Train loss: 1.580, Test loss: 1.636, Test accuracy: 82.60
Round  38, Global train loss: 1.580, Global test loss: 1.633, Global test accuracy: 82.78
Round  39, Train loss: 1.571, Test loss: 1.636, Test accuracy: 82.60
Round  39, Global train loss: 1.571, Global test loss: 1.633, Global test accuracy: 82.78
Round  40, Train loss: 1.563, Test loss: 1.636, Test accuracy: 82.68
Round  40, Global train loss: 1.563, Global test loss: 1.632, Global test accuracy: 83.00
Round  41, Train loss: 1.583, Test loss: 1.635, Test accuracy: 82.76
Round  41, Global train loss: 1.583, Global test loss: 1.635, Global test accuracy: 82.74
Round  42, Train loss: 1.571, Test loss: 1.635, Test accuracy: 82.74
Round  42, Global train loss: 1.571, Global test loss: 1.633, Global test accuracy: 82.62
Round  43, Train loss: 1.577, Test loss: 1.634, Test accuracy: 82.80
Round  43, Global train loss: 1.577, Global test loss: 1.632, Global test accuracy: 82.98
Round  44, Train loss: 1.569, Test loss: 1.634, Test accuracy: 82.84
Round  44, Global train loss: 1.569, Global test loss: 1.632, Global test accuracy: 83.48
Round  45, Train loss: 1.573, Test loss: 1.634, Test accuracy: 82.82
Round  45, Global train loss: 1.573, Global test loss: 1.633, Global test accuracy: 83.16
Round  46, Train loss: 1.573, Test loss: 1.634, Test accuracy: 82.94
Round  46, Global train loss: 1.573, Global test loss: 1.632, Global test accuracy: 83.10
Round  47, Train loss: 1.580, Test loss: 1.633, Test accuracy: 82.92
Round  47, Global train loss: 1.580, Global test loss: 1.633, Global test accuracy: 83.16
Round  48, Train loss: 1.578, Test loss: 1.633, Test accuracy: 82.94
Round  48, Global train loss: 1.578, Global test loss: 1.632, Global test accuracy: 82.96
Round  49, Train loss: 1.573, Test loss: 1.633, Test accuracy: 82.90
Round  49, Global train loss: 1.573, Global test loss: 1.631, Global test accuracy: 83.18
Round  50, Train loss: 1.564, Test loss: 1.632, Test accuracy: 82.88
Round  50, Global train loss: 1.564, Global test loss: 1.631, Global test accuracy: 83.02
Round  51, Train loss: 1.568, Test loss: 1.633, Test accuracy: 82.88
Round  51, Global train loss: 1.568, Global test loss: 1.631, Global test accuracy: 83.04
Round  52, Train loss: 1.576, Test loss: 1.632, Test accuracy: 82.86
Round  52, Global train loss: 1.576, Global test loss: 1.630, Global test accuracy: 83.50
Round  53, Train loss: 1.577, Test loss: 1.632, Test accuracy: 82.90
Round  53, Global train loss: 1.577, Global test loss: 1.631, Global test accuracy: 83.36
Round  54, Train loss: 1.574, Test loss: 1.632, Test accuracy: 82.90
Round  54, Global train loss: 1.574, Global test loss: 1.630, Global test accuracy: 82.98
Round  55, Train loss: 1.567, Test loss: 1.632, Test accuracy: 82.86
Round  55, Global train loss: 1.567, Global test loss: 1.630, Global test accuracy: 83.06
Round  56, Train loss: 1.576, Test loss: 1.632, Test accuracy: 82.96
Round  56, Global train loss: 1.576, Global test loss: 1.631, Global test accuracy: 82.60
Round  57, Train loss: 1.576, Test loss: 1.632, Test accuracy: 82.98
Round  57, Global train loss: 1.576, Global test loss: 1.631, Global test accuracy: 83.30
Round  58, Train loss: 1.563, Test loss: 1.631, Test accuracy: 82.96
Round  58, Global train loss: 1.563, Global test loss: 1.629, Global test accuracy: 83.54
Round  59, Train loss: 1.559, Test loss: 1.631, Test accuracy: 83.00
Round  59, Global train loss: 1.559, Global test loss: 1.628, Global test accuracy: 83.58
Round  60, Train loss: 1.563, Test loss: 1.631, Test accuracy: 83.00
Round  60, Global train loss: 1.563, Global test loss: 1.629, Global test accuracy: 83.32
Round  61, Train loss: 1.567, Test loss: 1.630, Test accuracy: 83.04
Round  61, Global train loss: 1.567, Global test loss: 1.629, Global test accuracy: 83.40
Round  62, Train loss: 1.576, Test loss: 1.630, Test accuracy: 83.08
Round  62, Global train loss: 1.576, Global test loss: 1.630, Global test accuracy: 83.60
Round  63, Train loss: 1.561, Test loss: 1.630, Test accuracy: 83.10
Round  63, Global train loss: 1.561, Global test loss: 1.628, Global test accuracy: 82.98
Round  64, Train loss: 1.571, Test loss: 1.630, Test accuracy: 83.10
Round  64, Global train loss: 1.571, Global test loss: 1.630, Global test accuracy: 83.36
Round  65, Train loss: 1.570, Test loss: 1.630, Test accuracy: 83.18
Round  65, Global train loss: 1.570, Global test loss: 1.629, Global test accuracy: 83.28
Round  66, Train loss: 1.573, Test loss: 1.630, Test accuracy: 83.14
Round  66, Global train loss: 1.573, Global test loss: 1.628, Global test accuracy: 83.16
Round  67, Train loss: 1.568, Test loss: 1.629, Test accuracy: 83.18
Round  67, Global train loss: 1.568, Global test loss: 1.627, Global test accuracy: 83.56
Round  68, Train loss: 1.576, Test loss: 1.629, Test accuracy: 83.22
Round  68, Global train loss: 1.576, Global test loss: 1.628, Global test accuracy: 83.36
Round  69, Train loss: 1.575, Test loss: 1.629, Test accuracy: 83.20
Round  69, Global train loss: 1.575, Global test loss: 1.628, Global test accuracy: 83.50
Round  70, Train loss: 1.565, Test loss: 1.629, Test accuracy: 83.16
Round  70, Global train loss: 1.565, Global test loss: 1.628, Global test accuracy: 83.52
Round  71, Train loss: 1.558, Test loss: 1.629, Test accuracy: 83.14
Round  71, Global train loss: 1.558, Global test loss: 1.628, Global test accuracy: 83.38
Round  72, Train loss: 1.571, Test loss: 1.629, Test accuracy: 83.14
Round  72, Global train loss: 1.571, Global test loss: 1.629, Global test accuracy: 83.00
Round  73, Train loss: 1.569, Test loss: 1.628, Test accuracy: 83.14
Round  73, Global train loss: 1.569, Global test loss: 1.628, Global test accuracy: 83.26
Round  74, Train loss: 1.570, Test loss: 1.628, Test accuracy: 83.16
Round  74, Global train loss: 1.570, Global test loss: 1.627, Global test accuracy: 83.68
Round  75, Train loss: 1.571, Test loss: 1.628, Test accuracy: 83.20
Round  75, Global train loss: 1.571, Global test loss: 1.628, Global test accuracy: 83.44
Round  76, Train loss: 1.565, Test loss: 1.628, Test accuracy: 83.26
Round  76, Global train loss: 1.565, Global test loss: 1.627, Global test accuracy: 83.52
Round  77, Train loss: 1.569, Test loss: 1.628, Test accuracy: 83.24
Round  77, Global train loss: 1.569, Global test loss: 1.628, Global test accuracy: 83.06
Round  78, Train loss: 1.568, Test loss: 1.628, Test accuracy: 83.26
Round  78, Global train loss: 1.568, Global test loss: 1.627, Global test accuracy: 83.26
Round  79, Train loss: 1.564, Test loss: 1.628, Test accuracy: 83.22
Round  79, Global train loss: 1.564, Global test loss: 1.628, Global test accuracy: 83.24
Round  80, Train loss: 1.559, Test loss: 1.628, Test accuracy: 83.24
Round  80, Global train loss: 1.559, Global test loss: 1.628, Global test accuracy: 83.32
Round  81, Train loss: 1.565, Test loss: 1.628, Test accuracy: 83.16
Round  81, Global train loss: 1.565, Global test loss: 1.629, Global test accuracy: 82.92
Round  82, Train loss: 1.565, Test loss: 1.628, Test accuracy: 83.20
Round  82, Global train loss: 1.565, Global test loss: 1.629, Global test accuracy: 82.88
Round  83, Train loss: 1.564, Test loss: 1.628, Test accuracy: 83.24
Round  83, Global train loss: 1.564, Global test loss: 1.628, Global test accuracy: 83.34
Round  84, Train loss: 1.574, Test loss: 1.628, Test accuracy: 83.22
Round  84, Global train loss: 1.574, Global test loss: 1.626, Global test accuracy: 83.42
Round  85, Train loss: 1.563, Test loss: 1.628, Test accuracy: 83.18
Round  85, Global train loss: 1.563, Global test loss: 1.627, Global test accuracy: 83.50
Round  86, Train loss: 1.559, Test loss: 1.628, Test accuracy: 83.20
Round  86, Global train loss: 1.559, Global test loss: 1.626, Global test accuracy: 83.70
Round  87, Train loss: 1.557, Test loss: 1.628, Test accuracy: 83.18
Round  87, Global train loss: 1.557, Global test loss: 1.627, Global test accuracy: 83.44
Round  88, Train loss: 1.556, Test loss: 1.628, Test accuracy: 83.26
Round  88, Global train loss: 1.556, Global test loss: 1.626, Global test accuracy: 83.76
Round  89, Train loss: 1.568, Test loss: 1.628, Test accuracy: 83.32
Round  89, Global train loss: 1.568, Global test loss: 1.627, Global test accuracy: 83.52
Round  90, Train loss: 1.562, Test loss: 1.628, Test accuracy: 83.40
Round  90, Global train loss: 1.562, Global test loss: 1.626, Global test accuracy: 83.88
Round  91, Train loss: 1.557, Test loss: 1.627, Test accuracy: 83.38
Round  91, Global train loss: 1.557, Global test loss: 1.626, Global test accuracy: 83.74
Round  92, Train loss: 1.562, Test loss: 1.627, Test accuracy: 83.40
Round  92, Global train loss: 1.562, Global test loss: 1.626, Global test accuracy: 83.62
Round  93, Train loss: 1.560, Test loss: 1.627, Test accuracy: 83.40
Round  93, Global train loss: 1.560, Global test loss: 1.626, Global test accuracy: 83.66
Round  94, Train loss: 1.564, Test loss: 1.627, Test accuracy: 83.38
Round  94, Global train loss: 1.564, Global test loss: 1.627, Global test accuracy: 83.66
Round  95, Train loss: 1.569, Test loss: 1.627, Test accuracy: 83.34
Round  95, Global train loss: 1.569, Global test loss: 1.627, Global test accuracy: 83.42/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 1.564, Test loss: 1.627, Test accuracy: 83.28
Round  96, Global train loss: 1.564, Global test loss: 1.626, Global test accuracy: 83.54
Round  97, Train loss: 1.567, Test loss: 1.627, Test accuracy: 83.28
Round  97, Global train loss: 1.567, Global test loss: 1.626, Global test accuracy: 83.58
Round  98, Train loss: 1.565, Test loss: 1.627, Test accuracy: 83.26
Round  98, Global train loss: 1.565, Global test loss: 1.625, Global test accuracy: 83.60
Round  99, Train loss: 1.566, Test loss: 1.627, Test accuracy: 83.32
Round  99, Global train loss: 1.566, Global test loss: 1.625, Global test accuracy: 83.78
Final Round, Train loss: 1.565, Test loss: 1.627, Test accuracy: 83.36
Final Round, Global train loss: 1.565, Global test loss: 1.625, Global test accuracy: 83.78
Average accuracy final 10 rounds: 83.344 

Average global accuracy final 10 rounds: 83.648 

503.7093725204468
[0.8305025100708008, 1.6610050201416016, 2.3927674293518066, 3.1245298385620117, 3.8508715629577637, 4.577213287353516, 5.302500009536743, 6.027786731719971, 6.755294322967529, 7.482801914215088, 8.211493730545044, 8.940185546875, 9.667032241821289, 10.393878936767578, 11.118436574935913, 11.842994213104248, 12.566843509674072, 13.290692806243896, 14.015592575073242, 14.740492343902588, 15.470738649368286, 16.200984954833984, 16.929022073745728, 17.65705919265747, 18.383549451828003, 19.110039710998535, 19.83700466156006, 20.563969612121582, 21.29314684867859, 22.022324085235596, 22.748785972595215, 23.475247859954834, 24.19248104095459, 24.909714221954346, 25.626481533050537, 26.34324884414673, 27.06389355659485, 27.78453826904297, 28.506919384002686, 29.229300498962402, 29.95440125465393, 30.67950201034546, 31.405256986618042, 32.131011962890625, 32.86365795135498, 33.596303939819336, 34.31969904899597, 35.04309415817261, 35.76983189582825, 36.49656963348389, 37.22383785247803, 37.95110607147217, 38.67283296585083, 39.39455986022949, 40.119887590408325, 40.84521532058716, 41.56950783729553, 42.293800354003906, 43.01669096946716, 43.73958158493042, 44.36376619338989, 44.987950801849365, 45.608421087265015, 46.228891372680664, 46.84929323196411, 47.46969509124756, 48.09110403060913, 48.7125129699707, 49.32643151283264, 49.94035005569458, 50.55845236778259, 51.176554679870605, 51.79654359817505, 52.41653251647949, 53.03171515464783, 53.64689779281616, 54.262582778930664, 54.878267765045166, 55.50621938705444, 56.13417100906372, 56.76030874252319, 57.386446475982666, 58.008289098739624, 58.63013172149658, 59.25455713272095, 59.87898254394531, 60.50517988204956, 61.13137722015381, 61.75301909446716, 62.37466096878052, 63.00129532814026, 63.6279296875, 64.25516939163208, 64.88240909576416, 65.5061423778534, 66.12987565994263, 66.74794626235962, 67.36601686477661, 67.99287128448486, 68.61972570419312, 69.23679780960083, 69.85386991500854, 70.46945071220398, 71.08503150939941, 71.70783042907715, 72.33062934875488, 72.95957231521606, 73.58851528167725, 74.2090528011322, 74.82959032058716, 75.45296955108643, 76.0763487815857, 76.70036745071411, 77.32438611984253, 77.94528651237488, 78.56618690490723, 79.18610978126526, 79.80603265762329, 80.43324851989746, 81.06046438217163, 81.67719793319702, 82.29393148422241, 82.90581369400024, 83.51769590377808, 84.13872075080872, 84.75974559783936, 85.37690496444702, 85.99406433105469, 86.60944509506226, 87.22482585906982, 87.84514713287354, 88.46546840667725, 89.0841805934906, 89.70289278030396, 90.31474685668945, 90.92660093307495, 91.54661703109741, 92.16663312911987, 92.78452110290527, 93.40240907669067, 94.01981449127197, 94.63721990585327, 95.25128817558289, 95.8653564453125, 96.4878876209259, 97.1104187965393, 97.72875690460205, 98.3470950126648, 98.96084141731262, 99.57458782196045, 100.19525265693665, 100.81591749191284, 101.4340033531189, 102.05208921432495, 102.66584014892578, 103.27959108352661, 103.90093994140625, 104.52228879928589, 105.14451026916504, 105.76673173904419, 106.3916437625885, 107.01655578613281, 107.6776876449585, 108.33881950378418, 108.96944546699524, 109.6000714302063, 110.2228000164032, 110.8455286026001, 111.46263289451599, 112.07973718643188, 112.7005386352539, 113.32134008407593, 113.94536662101746, 114.56939315795898, 115.18518114089966, 115.80096912384033, 116.42242932319641, 117.04388952255249, 117.66669416427612, 118.28949880599976, 118.91123032569885, 119.53296184539795, 120.15536642074585, 120.77777099609375, 121.40130543708801, 122.02483987808228, 122.64618253707886, 123.26752519607544, 123.88734006881714, 124.50715494155884, 125.13034272193909, 125.75353050231934, 126.376384973526, 126.99923944473267, 127.61830568313599, 128.2373719215393, 128.8563449382782, 129.4753179550171, 130.0944299697876, 130.7135419845581, 131.94591736793518, 133.17829275131226]
[15.2, 15.2, 30.44, 30.44, 35.08, 35.08, 39.6, 39.6, 45.4, 45.4, 54.18, 54.18, 56.58, 56.58, 62.68, 62.68, 62.78, 62.78, 64.66, 64.66, 65.48, 65.48, 67.9, 67.9, 69.88, 69.88, 71.76, 71.76, 72.18, 72.18, 73.58, 73.58, 76.42, 76.42, 77.6, 77.6, 78.28, 78.28, 79.5, 79.5, 80.36, 80.36, 80.3, 80.3, 80.58, 80.58, 81.0, 81.0, 81.12, 81.12, 81.54, 81.54, 81.66, 81.66, 81.66, 81.66, 81.8, 81.8, 81.82, 81.82, 81.8, 81.8, 81.8, 81.8, 81.98, 81.98, 81.98, 81.98, 82.12, 82.12, 82.26, 82.26, 82.52, 82.52, 82.56, 82.56, 82.6, 82.6, 82.6, 82.6, 82.68, 82.68, 82.76, 82.76, 82.74, 82.74, 82.8, 82.8, 82.84, 82.84, 82.82, 82.82, 82.94, 82.94, 82.92, 82.92, 82.94, 82.94, 82.9, 82.9, 82.88, 82.88, 82.88, 82.88, 82.86, 82.86, 82.9, 82.9, 82.9, 82.9, 82.86, 82.86, 82.96, 82.96, 82.98, 82.98, 82.96, 82.96, 83.0, 83.0, 83.0, 83.0, 83.04, 83.04, 83.08, 83.08, 83.1, 83.1, 83.1, 83.1, 83.18, 83.18, 83.14, 83.14, 83.18, 83.18, 83.22, 83.22, 83.2, 83.2, 83.16, 83.16, 83.14, 83.14, 83.14, 83.14, 83.14, 83.14, 83.16, 83.16, 83.2, 83.2, 83.26, 83.26, 83.24, 83.24, 83.26, 83.26, 83.22, 83.22, 83.24, 83.24, 83.16, 83.16, 83.2, 83.2, 83.24, 83.24, 83.22, 83.22, 83.18, 83.18, 83.2, 83.2, 83.18, 83.18, 83.26, 83.26, 83.32, 83.32, 83.4, 83.4, 83.38, 83.38, 83.4, 83.4, 83.4, 83.4, 83.38, 83.38, 83.34, 83.34, 83.28, 83.28, 83.28, 83.28, 83.26, 83.26, 83.32, 83.32, 83.36, 83.36]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.4  

prox
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.301, Test loss: 2.300, Test accuracy: 16.62
Round   0, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 16.52
Round   1, Train loss: 2.299, Test loss: 2.298, Test accuracy: 31.04
Round   1, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 33.08
Round   2, Train loss: 2.295, Test loss: 2.295, Test accuracy: 35.84
Round   2, Global train loss: 2.295, Global test loss: 2.293, Global test accuracy: 41.18
Round   3, Train loss: 2.287, Test loss: 2.288, Test accuracy: 36.74
Round   3, Global train loss: 2.287, Global test loss: 2.283, Global test accuracy: 36.40
Round   4, Train loss: 2.266, Test loss: 2.266, Test accuracy: 32.00
Round   4, Global train loss: 2.266, Global test loss: 2.242, Global test accuracy: 29.10
Round   5, Train loss: 2.166, Test loss: 2.191, Test accuracy: 36.04
Round   5, Global train loss: 2.166, Global test loss: 2.111, Global test accuracy: 39.26
Round   6, Train loss: 2.010, Test loss: 2.081, Test accuracy: 45.14
Round   6, Global train loss: 2.010, Global test loss: 1.960, Global test accuracy: 54.28
Round   7, Train loss: 1.895, Test loss: 1.958, Test accuracy: 57.60
Round   7, Global train loss: 1.895, Global test loss: 1.843, Global test accuracy: 72.56
Round   8, Train loss: 1.767, Test loss: 1.851, Test accuracy: 67.60
Round   8, Global train loss: 1.767, Global test loss: 1.746, Global test accuracy: 77.02
Round   9, Train loss: 1.708, Test loss: 1.802, Test accuracy: 71.20
Round   9, Global train loss: 1.708, Global test loss: 1.708, Global test accuracy: 79.66
Round  10, Train loss: 1.684, Test loss: 1.781, Test accuracy: 72.68
Round  10, Global train loss: 1.684, Global test loss: 1.685, Global test accuracy: 79.80
Round  11, Train loss: 1.654, Test loss: 1.727, Test accuracy: 77.44
Round  11, Global train loss: 1.654, Global test loss: 1.671, Global test accuracy: 80.90
Round  12, Train loss: 1.634, Test loss: 1.717, Test accuracy: 78.14
Round  12, Global train loss: 1.634, Global test loss: 1.661, Global test accuracy: 82.00
Round  13, Train loss: 1.624, Test loss: 1.715, Test accuracy: 78.32
Round  13, Global train loss: 1.624, Global test loss: 1.655, Global test accuracy: 81.88
Round  14, Train loss: 1.630, Test loss: 1.704, Test accuracy: 79.04
Round  14, Global train loss: 1.630, Global test loss: 1.652, Global test accuracy: 82.34
Round  15, Train loss: 1.635, Test loss: 1.664, Test accuracy: 81.28
Round  15, Global train loss: 1.635, Global test loss: 1.645, Global test accuracy: 83.34
Round  16, Train loss: 1.616, Test loss: 1.661, Test accuracy: 81.52
Round  16, Global train loss: 1.616, Global test loss: 1.641, Global test accuracy: 82.84
Round  17, Train loss: 1.607, Test loss: 1.654, Test accuracy: 81.96
Round  17, Global train loss: 1.607, Global test loss: 1.643, Global test accuracy: 83.00
Round  18, Train loss: 1.602, Test loss: 1.649, Test accuracy: 82.22
Round  18, Global train loss: 1.602, Global test loss: 1.638, Global test accuracy: 83.22
Round  19, Train loss: 1.599, Test loss: 1.646, Test accuracy: 82.44
Round  19, Global train loss: 1.599, Global test loss: 1.636, Global test accuracy: 83.26
Round  20, Train loss: 1.611, Test loss: 1.645, Test accuracy: 82.42
Round  20, Global train loss: 1.611, Global test loss: 1.633, Global test accuracy: 83.78
Round  21, Train loss: 1.592, Test loss: 1.643, Test accuracy: 82.56
Round  21, Global train loss: 1.592, Global test loss: 1.634, Global test accuracy: 83.06
Round  22, Train loss: 1.601, Test loss: 1.643, Test accuracy: 82.66
Round  22, Global train loss: 1.601, Global test loss: 1.635, Global test accuracy: 83.02
Round  23, Train loss: 1.588, Test loss: 1.640, Test accuracy: 82.88
Round  23, Global train loss: 1.588, Global test loss: 1.628, Global test accuracy: 84.08
Round  24, Train loss: 1.585, Test loss: 1.639, Test accuracy: 82.90
Round  24, Global train loss: 1.585, Global test loss: 1.629, Global test accuracy: 83.54
Round  25, Train loss: 1.615, Test loss: 1.638, Test accuracy: 83.02
Round  25, Global train loss: 1.615, Global test loss: 1.627, Global test accuracy: 83.96
Round  26, Train loss: 1.606, Test loss: 1.635, Test accuracy: 83.16
Round  26, Global train loss: 1.606, Global test loss: 1.625, Global test accuracy: 84.30
Round  27, Train loss: 1.584, Test loss: 1.634, Test accuracy: 83.14
Round  27, Global train loss: 1.584, Global test loss: 1.626, Global test accuracy: 84.18
Round  28, Train loss: 1.588, Test loss: 1.634, Test accuracy: 83.10
Round  28, Global train loss: 1.588, Global test loss: 1.626, Global test accuracy: 84.16
Round  29, Train loss: 1.598, Test loss: 1.634, Test accuracy: 83.22
Round  29, Global train loss: 1.598, Global test loss: 1.626, Global test accuracy: 83.98
Round  30, Train loss: 1.594, Test loss: 1.631, Test accuracy: 83.52
Round  30, Global train loss: 1.594, Global test loss: 1.627, Global test accuracy: 83.86
Round  31, Train loss: 1.594, Test loss: 1.631, Test accuracy: 83.38
Round  31, Global train loss: 1.594, Global test loss: 1.626, Global test accuracy: 84.10
Round  32, Train loss: 1.590, Test loss: 1.631, Test accuracy: 83.32
Round  32, Global train loss: 1.590, Global test loss: 1.625, Global test accuracy: 83.92
Round  33, Train loss: 1.587, Test loss: 1.631, Test accuracy: 83.46
Round  33, Global train loss: 1.587, Global test loss: 1.624, Global test accuracy: 83.98
Round  34, Train loss: 1.589, Test loss: 1.630, Test accuracy: 83.52
Round  34, Global train loss: 1.589, Global test loss: 1.622, Global test accuracy: 84.38
Round  35, Train loss: 1.589, Test loss: 1.629, Test accuracy: 83.66
Round  35, Global train loss: 1.589, Global test loss: 1.621, Global test accuracy: 84.36
Round  36, Train loss: 1.580, Test loss: 1.628, Test accuracy: 83.82
Round  36, Global train loss: 1.580, Global test loss: 1.622, Global test accuracy: 84.04
Round  37, Train loss: 1.586, Test loss: 1.628, Test accuracy: 83.80
Round  37, Global train loss: 1.586, Global test loss: 1.624, Global test accuracy: 84.08
Round  38, Train loss: 1.580, Test loss: 1.628, Test accuracy: 83.76
Round  38, Global train loss: 1.580, Global test loss: 1.621, Global test accuracy: 84.32
Round  39, Train loss: 1.581, Test loss: 1.628, Test accuracy: 83.84
Round  39, Global train loss: 1.581, Global test loss: 1.622, Global test accuracy: 84.16
Round  40, Train loss: 1.588, Test loss: 1.627, Test accuracy: 83.96
Round  40, Global train loss: 1.588, Global test loss: 1.619, Global test accuracy: 84.60
Round  41, Train loss: 1.588, Test loss: 1.626, Test accuracy: 83.82
Round  41, Global train loss: 1.588, Global test loss: 1.621, Global test accuracy: 84.22
Round  42, Train loss: 1.575, Test loss: 1.625, Test accuracy: 83.94
Round  42, Global train loss: 1.575, Global test loss: 1.620, Global test accuracy: 84.10
Round  43, Train loss: 1.589, Test loss: 1.624, Test accuracy: 83.98
Round  43, Global train loss: 1.589, Global test loss: 1.622, Global test accuracy: 84.08
Round  44, Train loss: 1.579, Test loss: 1.624, Test accuracy: 83.92
Round  44, Global train loss: 1.579, Global test loss: 1.622, Global test accuracy: 84.00
Round  45, Train loss: 1.586, Test loss: 1.624, Test accuracy: 84.02
Round  45, Global train loss: 1.586, Global test loss: 1.619, Global test accuracy: 84.58
Round  46, Train loss: 1.584, Test loss: 1.623, Test accuracy: 84.04
Round  46, Global train loss: 1.584, Global test loss: 1.622, Global test accuracy: 84.00
Round  47, Train loss: 1.576, Test loss: 1.624, Test accuracy: 84.02
Round  47, Global train loss: 1.576, Global test loss: 1.624, Global test accuracy: 84.08
Round  48, Train loss: 1.583, Test loss: 1.623, Test accuracy: 84.10
Round  48, Global train loss: 1.583, Global test loss: 1.618, Global test accuracy: 84.46
Round  49, Train loss: 1.584, Test loss: 1.623, Test accuracy: 84.10
Round  49, Global train loss: 1.584, Global test loss: 1.618, Global test accuracy: 84.40
Round  50, Train loss: 1.573, Test loss: 1.622, Test accuracy: 84.18
Round  50, Global train loss: 1.573, Global test loss: 1.619, Global test accuracy: 84.48
Round  51, Train loss: 1.584, Test loss: 1.622, Test accuracy: 84.20
Round  51, Global train loss: 1.584, Global test loss: 1.622, Global test accuracy: 84.10
Round  52, Train loss: 1.577, Test loss: 1.622, Test accuracy: 84.20
Round  52, Global train loss: 1.577, Global test loss: 1.623, Global test accuracy: 84.26
Round  53, Train loss: 1.581, Test loss: 1.623, Test accuracy: 84.12
Round  53, Global train loss: 1.581, Global test loss: 1.624, Global test accuracy: 84.20
Round  54, Train loss: 1.575, Test loss: 1.622, Test accuracy: 84.14
Round  54, Global train loss: 1.575, Global test loss: 1.623, Global test accuracy: 84.20
Round  55, Train loss: 1.580, Test loss: 1.622, Test accuracy: 84.14
Round  55, Global train loss: 1.580, Global test loss: 1.619, Global test accuracy: 84.02
Round  56, Train loss: 1.567, Test loss: 1.613, Test accuracy: 85.06
Round  56, Global train loss: 1.567, Global test loss: 1.591, Global test accuracy: 87.86
Round  57, Train loss: 1.526, Test loss: 1.606, Test accuracy: 85.84
Round  57, Global train loss: 1.526, Global test loss: 1.580, Global test accuracy: 88.64
Round  58, Train loss: 1.514, Test loss: 1.598, Test accuracy: 86.72
Round  58, Global train loss: 1.514, Global test loss: 1.576, Global test accuracy: 88.90
Round  59, Train loss: 1.505, Test loss: 1.585, Test accuracy: 87.94
Round  59, Global train loss: 1.505, Global test loss: 1.571, Global test accuracy: 89.48
Round  60, Train loss: 1.504, Test loss: 1.583, Test accuracy: 88.12
Round  60, Global train loss: 1.504, Global test loss: 1.567, Global test accuracy: 89.78
Round  61, Train loss: 1.498, Test loss: 1.578, Test accuracy: 88.72
Round  61, Global train loss: 1.498, Global test loss: 1.568, Global test accuracy: 89.80
Round  62, Train loss: 1.493, Test loss: 1.577, Test accuracy: 88.80
Round  62, Global train loss: 1.493, Global test loss: 1.567, Global test accuracy: 89.68
Round  63, Train loss: 1.497, Test loss: 1.575, Test accuracy: 89.16
Round  63, Global train loss: 1.497, Global test loss: 1.567, Global test accuracy: 89.78
Round  64, Train loss: 1.496, Test loss: 1.574, Test accuracy: 89.16
Round  64, Global train loss: 1.496, Global test loss: 1.566, Global test accuracy: 90.02
Round  65, Train loss: 1.502, Test loss: 1.572, Test accuracy: 89.26
Round  65, Global train loss: 1.502, Global test loss: 1.564, Global test accuracy: 89.78
Round  66, Train loss: 1.501, Test loss: 1.571, Test accuracy: 89.42
Round  66, Global train loss: 1.501, Global test loss: 1.560, Global test accuracy: 90.20
Round  67, Train loss: 1.511, Test loss: 1.567, Test accuracy: 89.80
Round  67, Global train loss: 1.511, Global test loss: 1.560, Global test accuracy: 90.36
Round  68, Train loss: 1.503, Test loss: 1.565, Test accuracy: 89.86
Round  68, Global train loss: 1.503, Global test loss: 1.560, Global test accuracy: 90.60
Round  69, Train loss: 1.501, Test loss: 1.566, Test accuracy: 89.72
Round  69, Global train loss: 1.501, Global test loss: 1.560, Global test accuracy: 90.58
Round  70, Train loss: 1.492, Test loss: 1.565, Test accuracy: 89.82
Round  70, Global train loss: 1.492, Global test loss: 1.560, Global test accuracy: 90.52
Round  71, Train loss: 1.490, Test loss: 1.564, Test accuracy: 89.96
Round  71, Global train loss: 1.490, Global test loss: 1.559, Global test accuracy: 90.66
Round  72, Train loss: 1.497, Test loss: 1.564, Test accuracy: 89.96
Round  72, Global train loss: 1.497, Global test loss: 1.559, Global test accuracy: 90.28
Round  73, Train loss: 1.492, Test loss: 1.563, Test accuracy: 90.00
Round  73, Global train loss: 1.492, Global test loss: 1.558, Global test accuracy: 90.80
Round  74, Train loss: 1.500, Test loss: 1.563, Test accuracy: 89.96
Round  74, Global train loss: 1.500, Global test loss: 1.557, Global test accuracy: 90.90
Round  75, Train loss: 1.491, Test loss: 1.563, Test accuracy: 89.96
Round  75, Global train loss: 1.491, Global test loss: 1.558, Global test accuracy: 90.64
Round  76, Train loss: 1.486, Test loss: 1.562, Test accuracy: 90.16
Round  76, Global train loss: 1.486, Global test loss: 1.558, Global test accuracy: 90.84
Round  77, Train loss: 1.502, Test loss: 1.562, Test accuracy: 90.28
Round  77, Global train loss: 1.502, Global test loss: 1.557, Global test accuracy: 91.00
Round  78, Train loss: 1.499, Test loss: 1.561, Test accuracy: 90.26
Round  78, Global train loss: 1.499, Global test loss: 1.558, Global test accuracy: 90.76
Round  79, Train loss: 1.487, Test loss: 1.561, Test accuracy: 90.20
Round  79, Global train loss: 1.487, Global test loss: 1.557, Global test accuracy: 90.70
Round  80, Train loss: 1.486, Test loss: 1.561, Test accuracy: 90.18
Round  80, Global train loss: 1.486, Global test loss: 1.558, Global test accuracy: 90.38
Round  81, Train loss: 1.487, Test loss: 1.560, Test accuracy: 90.26
Round  81, Global train loss: 1.487, Global test loss: 1.559, Global test accuracy: 90.26
Round  82, Train loss: 1.485, Test loss: 1.560, Test accuracy: 90.22
Round  82, Global train loss: 1.485, Global test loss: 1.559, Global test accuracy: 90.40
Round  83, Train loss: 1.486, Test loss: 1.560, Test accuracy: 90.16
Round  83, Global train loss: 1.486, Global test loss: 1.559, Global test accuracy: 90.44
Round  84, Train loss: 1.499, Test loss: 1.560, Test accuracy: 90.18
Round  84, Global train loss: 1.499, Global test loss: 1.559, Global test accuracy: 90.32
Round  85, Train loss: 1.483, Test loss: 1.560, Test accuracy: 90.14
Round  85, Global train loss: 1.483, Global test loss: 1.559, Global test accuracy: 90.50
Round  86, Train loss: 1.483, Test loss: 1.560, Test accuracy: 90.14
Round  86, Global train loss: 1.483, Global test loss: 1.560, Global test accuracy: 90.44
Round  87, Train loss: 1.485, Test loss: 1.560, Test accuracy: 90.14
Round  87, Global train loss: 1.485, Global test loss: 1.560, Global test accuracy: 90.40
Round  88, Train loss: 1.490, Test loss: 1.560, Test accuracy: 90.16
Round  88, Global train loss: 1.490, Global test loss: 1.561, Global test accuracy: 89.94
Round  89, Train loss: 1.497, Test loss: 1.560, Test accuracy: 90.16
Round  89, Global train loss: 1.497, Global test loss: 1.557, Global test accuracy: 90.70
Round  90, Train loss: 1.499, Test loss: 1.560, Test accuracy: 90.16
Round  90, Global train loss: 1.499, Global test loss: 1.558, Global test accuracy: 90.38
Round  91, Train loss: 1.491, Test loss: 1.559, Test accuracy: 90.24
Round  91, Global train loss: 1.491, Global test loss: 1.559, Global test accuracy: 90.24
Round  92, Train loss: 1.486, Test loss: 1.559, Test accuracy: 90.22
Round  92, Global train loss: 1.486, Global test loss: 1.558, Global test accuracy: 90.46
Round  93, Train loss: 1.487, Test loss: 1.559, Test accuracy: 90.24
Round  93, Global train loss: 1.487, Global test loss: 1.556, Global test accuracy: 90.58
Round  94, Train loss: 1.485, Test loss: 1.559, Test accuracy: 90.28
Round  94, Global train loss: 1.485, Global test loss: 1.558, Global test accuracy: 90.78
Round  95, Train loss: 1.487, Test loss: 1.559, Test accuracy: 90.22
Round  95, Global train loss: 1.487, Global test loss: 1.558, Global test accuracy: 90.46/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  96, Train loss: 1.493, Test loss: 1.559, Test accuracy: 90.30
Round  96, Global train loss: 1.493, Global test loss: 1.555, Global test accuracy: 90.70
Round  97, Train loss: 1.486, Test loss: 1.558, Test accuracy: 90.40
Round  97, Global train loss: 1.486, Global test loss: 1.559, Global test accuracy: 90.30
Round  98, Train loss: 1.486, Test loss: 1.558, Test accuracy: 90.44
Round  98, Global train loss: 1.486, Global test loss: 1.556, Global test accuracy: 90.48
Round  99, Train loss: 1.486, Test loss: 1.558, Test accuracy: 90.48
Round  99, Global train loss: 1.486, Global test loss: 1.559, Global test accuracy: 90.38
Final Round, Train loss: 1.488, Test loss: 1.557, Test accuracy: 90.42
Final Round, Global train loss: 1.488, Global test loss: 1.559, Global test accuracy: 90.38
Average accuracy final 10 rounds: 90.298 

Average global accuracy final 10 rounds: 90.476 

532.6713564395905
[0.8475902080535889, 1.6951804161071777, 2.460678815841675, 3.226177215576172, 3.986152410507202, 4.746127605438232, 5.526956081390381, 6.307784557342529, 7.087104320526123, 7.866424083709717, 8.64673900604248, 9.427053928375244, 10.211186647415161, 10.995319366455078, 11.781840801239014, 12.56836223602295, 13.357066869735718, 14.145771503448486, 14.927881717681885, 15.709991931915283, 16.493293046951294, 17.276594161987305, 18.058430194854736, 18.840266227722168, 19.628126859664917, 20.415987491607666, 21.20253849029541, 21.989089488983154, 22.7732253074646, 23.557361125946045, 24.34107232093811, 25.124783515930176, 25.90525770187378, 26.685731887817383, 27.465245008468628, 28.244758129119873, 29.031442165374756, 29.81812620162964, 30.60405969619751, 31.38999319076538, 32.17551565170288, 32.96103811264038, 33.746344566345215, 34.53165102005005, 35.31190586090088, 36.09216070175171, 36.87325859069824, 37.654356479644775, 38.44206738471985, 39.22977828979492, 40.01678919792175, 40.803800106048584, 41.58791756629944, 42.37203502655029, 43.15654635429382, 43.94105768203735, 44.72021532058716, 45.49937295913696, 46.28168964385986, 47.064006328582764, 47.85049247741699, 48.63697862625122, 49.42259192466736, 50.208205223083496, 50.994067668914795, 51.779930114746094, 52.56241250038147, 53.344894886016846, 54.1246874332428, 54.90447998046875, 55.68551254272461, 56.46654510498047, 57.25462889671326, 58.042712688446045, 58.8262984752655, 59.60988426208496, 60.39443111419678, 61.178977966308594, 61.96202564239502, 62.745073318481445, 63.52569842338562, 64.3063235282898, 65.08734202384949, 65.86836051940918, 66.65487313270569, 67.4413857460022, 68.22852802276611, 69.01567029953003, 69.79975318908691, 70.5838360786438, 71.36591124534607, 72.14798641204834, 72.92827701568604, 73.70856761932373, 74.49265456199646, 75.27674150466919, 76.06177806854248, 76.84681463241577, 77.63525557518005, 78.42369651794434, 79.21045899391174, 79.99722146987915, 80.7812430858612, 81.56526470184326, 82.3458297252655, 83.12639474868774, 83.90888118743896, 84.69136762619019, 85.47568368911743, 86.25999975204468, 87.0488133430481, 87.83762693405151, 88.62048006057739, 89.40333318710327, 90.18447232246399, 90.9656114578247, 91.7471911907196, 92.5287709236145, 93.31508469581604, 94.10139846801758, 94.88653945922852, 95.67168045043945, 96.45841336250305, 97.24514627456665, 98.03226017951965, 98.81937408447266, 99.53963875770569, 100.25990343093872, 100.94443798065186, 101.62897253036499, 102.31843686103821, 103.00790119171143, 103.69520378112793, 104.38250637054443, 105.07843065261841, 105.77435493469238, 106.45995712280273, 107.14555931091309, 107.82176637649536, 108.49797344207764, 109.18541431427002, 109.8728551864624, 110.5544981956482, 111.23614120483398, 111.91134643554688, 112.58655166625977, 113.2740912437439, 113.96163082122803, 114.64813876152039, 115.33464670181274, 116.01706624031067, 116.6994857788086, 117.38832712173462, 118.07716846466064, 118.78420996665955, 119.49125146865845, 120.17715334892273, 120.86305522918701, 121.54078364372253, 122.21851205825806, 122.90252876281738, 123.58654546737671, 124.26596140861511, 124.94537734985352, 125.61895680427551, 126.29253625869751, 126.98259973526001, 127.67266321182251, 128.36193871498108, 129.05121421813965, 129.72684574127197, 130.4024772644043, 131.08741855621338, 131.77235984802246, 132.45934176445007, 133.14632368087769, 133.82306480407715, 134.4998059272766, 135.1877715587616, 135.87573719024658, 136.5618281364441, 137.2479190826416, 137.92619633674622, 138.60447359085083, 139.2836856842041, 139.96289777755737, 140.64575624465942, 141.32861471176147, 142.00983357429504, 142.6910524368286, 143.37021565437317, 144.04937887191772, 144.73636722564697, 145.42335557937622, 146.10554671287537, 146.7877378463745, 147.46100664138794, 148.13427543640137, 148.81648993492126, 149.49870443344116, 150.86389780044556, 152.22909116744995]
[16.62, 16.62, 31.04, 31.04, 35.84, 35.84, 36.74, 36.74, 32.0, 32.0, 36.04, 36.04, 45.14, 45.14, 57.6, 57.6, 67.6, 67.6, 71.2, 71.2, 72.68, 72.68, 77.44, 77.44, 78.14, 78.14, 78.32, 78.32, 79.04, 79.04, 81.28, 81.28, 81.52, 81.52, 81.96, 81.96, 82.22, 82.22, 82.44, 82.44, 82.42, 82.42, 82.56, 82.56, 82.66, 82.66, 82.88, 82.88, 82.9, 82.9, 83.02, 83.02, 83.16, 83.16, 83.14, 83.14, 83.1, 83.1, 83.22, 83.22, 83.52, 83.52, 83.38, 83.38, 83.32, 83.32, 83.46, 83.46, 83.52, 83.52, 83.66, 83.66, 83.82, 83.82, 83.8, 83.8, 83.76, 83.76, 83.84, 83.84, 83.96, 83.96, 83.82, 83.82, 83.94, 83.94, 83.98, 83.98, 83.92, 83.92, 84.02, 84.02, 84.04, 84.04, 84.02, 84.02, 84.1, 84.1, 84.1, 84.1, 84.18, 84.18, 84.2, 84.2, 84.2, 84.2, 84.12, 84.12, 84.14, 84.14, 84.14, 84.14, 85.06, 85.06, 85.84, 85.84, 86.72, 86.72, 87.94, 87.94, 88.12, 88.12, 88.72, 88.72, 88.8, 88.8, 89.16, 89.16, 89.16, 89.16, 89.26, 89.26, 89.42, 89.42, 89.8, 89.8, 89.86, 89.86, 89.72, 89.72, 89.82, 89.82, 89.96, 89.96, 89.96, 89.96, 90.0, 90.0, 89.96, 89.96, 89.96, 89.96, 90.16, 90.16, 90.28, 90.28, 90.26, 90.26, 90.2, 90.2, 90.18, 90.18, 90.26, 90.26, 90.22, 90.22, 90.16, 90.16, 90.18, 90.18, 90.14, 90.14, 90.14, 90.14, 90.14, 90.14, 90.16, 90.16, 90.16, 90.16, 90.16, 90.16, 90.24, 90.24, 90.22, 90.22, 90.24, 90.24, 90.28, 90.28, 90.22, 90.22, 90.3, 90.3, 90.4, 90.4, 90.44, 90.44, 90.48, 90.48, 90.42, 90.42]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.0 , level_n_lowerb:0.4  

fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Traceback (most recent call last):
  File "main_fedpac_co_teaching.py", line 250, in <module>
    local.filter_data(net=net_local.to(args.device), net2=net_local2.to(args.device), concept_matrix_local = concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1587, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.320, Test loss: 2.300, Test accuracy: 13.22
Round   0, Global train loss: 2.320, Global test loss: 2.300, Global test accuracy: 13.18
Round   1, Train loss: 2.298, Test loss: 2.296, Test accuracy: 15.94
Round   1, Global train loss: 2.298, Global test loss: 2.296, Global test accuracy: 15.84
Round   2, Train loss: 2.295, Test loss: 2.292, Test accuracy: 27.68
Round   2, Global train loss: 2.295, Global test loss: 2.292, Global test accuracy: 27.52
Round   3, Train loss: 2.289, Test loss: 2.285, Test accuracy: 33.90
Round   3, Global train loss: 2.289, Global test loss: 2.285, Global test accuracy: 33.86
Round   4, Train loss: 2.282, Test loss: 2.272, Test accuracy: 35.26
Round   4, Global train loss: 2.282, Global test loss: 2.271, Global test accuracy: 33.82
Round   5, Train loss: 2.260, Test loss: 2.237, Test accuracy: 36.22
Round   5, Global train loss: 2.260, Global test loss: 2.234, Global test accuracy: 34.82
Round   6, Train loss: 2.207, Test loss: 2.161, Test accuracy: 42.18
Round   6, Global train loss: 2.207, Global test loss: 2.146, Global test accuracy: 39.20
Round   7, Train loss: 2.097, Test loss: 2.080, Test accuracy: 48.58
Round   7, Global train loss: 2.097, Global test loss: 2.049, Global test accuracy: 43.62
Round   8, Train loss: 2.025, Test loss: 2.011, Test accuracy: 54.10
Round   8, Global train loss: 2.025, Global test loss: 1.979, Global test accuracy: 51.66
Round   9, Train loss: 1.941, Test loss: 1.966, Test accuracy: 60.58
Round   9, Global train loss: 1.941, Global test loss: 1.925, Global test accuracy: 61.38
Round  10, Train loss: 1.920, Test loss: 1.919, Test accuracy: 65.86
Round  10, Global train loss: 1.920, Global test loss: 1.884, Global test accuracy: 66.16
Round  11, Train loss: 1.904, Test loss: 1.870, Test accuracy: 68.14
Round  11, Global train loss: 1.904, Global test loss: 1.851, Global test accuracy: 71.04
Round  12, Train loss: 1.836, Test loss: 1.844, Test accuracy: 70.12
Round  12, Global train loss: 1.836, Global test loss: 1.806, Global test accuracy: 72.72
Round  13, Train loss: 1.825, Test loss: 1.814, Test accuracy: 71.78
Round  13, Global train loss: 1.825, Global test loss: 1.793, Global test accuracy: 73.74
Round  14, Train loss: 1.786, Test loss: 1.798, Test accuracy: 72.46
Round  14, Global train loss: 1.786, Global test loss: 1.768, Global test accuracy: 74.34
Round  15, Train loss: 1.767, Test loss: 1.784, Test accuracy: 73.20
Round  15, Global train loss: 1.767, Global test loss: 1.763, Global test accuracy: 74.68
Round  16, Train loss: 1.744, Test loss: 1.775, Test accuracy: 73.74
Round  16, Global train loss: 1.744, Global test loss: 1.747, Global test accuracy: 74.88
Round  17, Train loss: 1.759, Test loss: 1.763, Test accuracy: 74.46
Round  17, Global train loss: 1.759, Global test loss: 1.748, Global test accuracy: 75.22
Round  18, Train loss: 1.744, Test loss: 1.752, Test accuracy: 75.50
Round  18, Global train loss: 1.744, Global test loss: 1.727, Global test accuracy: 77.38
Round  19, Train loss: 1.722, Test loss: 1.727, Test accuracy: 79.02
Round  19, Global train loss: 1.722, Global test loss: 1.698, Global test accuracy: 82.46
Round  20, Train loss: 1.713, Test loss: 1.695, Test accuracy: 81.92
Round  20, Global train loss: 1.713, Global test loss: 1.692, Global test accuracy: 82.94
Round  21, Train loss: 1.676, Test loss: 1.681, Test accuracy: 82.92
Round  21, Global train loss: 1.676, Global test loss: 1.671, Global test accuracy: 83.72
Round  22, Train loss: 1.662, Test loss: 1.672, Test accuracy: 83.30
Round  22, Global train loss: 1.662, Global test loss: 1.665, Global test accuracy: 84.08
Round  23, Train loss: 1.658, Test loss: 1.668, Test accuracy: 83.32
Round  23, Global train loss: 1.658, Global test loss: 1.658, Global test accuracy: 83.70
Round  24, Train loss: 1.658, Test loss: 1.660, Test accuracy: 83.78
Round  24, Global train loss: 1.658, Global test loss: 1.657, Global test accuracy: 84.26
Round  25, Train loss: 1.626, Test loss: 1.649, Test accuracy: 85.36
Round  25, Global train loss: 1.626, Global test loss: 1.623, Global test accuracy: 89.78
Round  26, Train loss: 1.628, Test loss: 1.633, Test accuracy: 87.14
Round  26, Global train loss: 1.628, Global test loss: 1.614, Global test accuracy: 90.66
Round  27, Train loss: 1.599, Test loss: 1.623, Test accuracy: 88.34
Round  27, Global train loss: 1.599, Global test loss: 1.607, Global test accuracy: 90.34
Round  28, Train loss: 1.594, Test loss: 1.617, Test accuracy: 88.68
Round  28, Global train loss: 1.594, Global test loss: 1.597, Global test accuracy: 90.76
Round  29, Train loss: 1.602, Test loss: 1.604, Test accuracy: 89.86
Round  29, Global train loss: 1.602, Global test loss: 1.606, Global test accuracy: 90.78
Round  30, Train loss: 1.566, Test loss: 1.600, Test accuracy: 90.46
Round  30, Global train loss: 1.566, Global test loss: 1.586, Global test accuracy: 91.34
Round  31, Train loss: 1.577, Test loss: 1.594, Test accuracy: 90.66
Round  31, Global train loss: 1.577, Global test loss: 1.595, Global test accuracy: 91.24
Round  32, Train loss: 1.564, Test loss: 1.589, Test accuracy: 91.22
Round  32, Global train loss: 1.564, Global test loss: 1.583, Global test accuracy: 91.48
Round  33, Train loss: 1.569, Test loss: 1.585, Test accuracy: 91.40
Round  33, Global train loss: 1.569, Global test loss: 1.580, Global test accuracy: 91.28
Round  34, Train loss: 1.546, Test loss: 1.586, Test accuracy: 91.40
Round  34, Global train loss: 1.546, Global test loss: 1.581, Global test accuracy: 91.50
Round  35, Train loss: 1.542, Test loss: 1.583, Test accuracy: 91.48
Round  35, Global train loss: 1.542, Global test loss: 1.582, Global test accuracy: 91.48
Round  36, Train loss: 1.548, Test loss: 1.581, Test accuracy: 91.64
Round  36, Global train loss: 1.548, Global test loss: 1.574, Global test accuracy: 91.50
Round  37, Train loss: 1.535, Test loss: 1.579, Test accuracy: 91.70
Round  37, Global train loss: 1.535, Global test loss: 1.575, Global test accuracy: 91.18
Round  38, Train loss: 1.531, Test loss: 1.577, Test accuracy: 91.80
Round  38, Global train loss: 1.531, Global test loss: 1.573, Global test accuracy: 91.96
Round  39, Train loss: 1.547, Test loss: 1.571, Test accuracy: 92.10
Round  39, Global train loss: 1.547, Global test loss: 1.566, Global test accuracy: 92.56
Round  40, Train loss: 1.540, Test loss: 1.570, Test accuracy: 92.04
Round  40, Global train loss: 1.540, Global test loss: 1.564, Global test accuracy: 92.62
Round  41, Train loss: 1.528, Test loss: 1.569, Test accuracy: 92.14
Round  41, Global train loss: 1.528, Global test loss: 1.568, Global test accuracy: 92.20
Round  42, Train loss: 1.541, Test loss: 1.568, Test accuracy: 92.34
Round  42, Global train loss: 1.541, Global test loss: 1.563, Global test accuracy: 92.80
Round  43, Train loss: 1.542, Test loss: 1.566, Test accuracy: 92.08
Round  43, Global train loss: 1.542, Global test loss: 1.561, Global test accuracy: 92.56
Round  44, Train loss: 1.528, Test loss: 1.564, Test accuracy: 92.14
Round  44, Global train loss: 1.528, Global test loss: 1.564, Global test accuracy: 92.20
Round  45, Train loss: 1.516, Test loss: 1.563, Test accuracy: 92.20
Round  45, Global train loss: 1.516, Global test loss: 1.560, Global test accuracy: 92.38
Round  46, Train loss: 1.531, Test loss: 1.561, Test accuracy: 92.40
Round  46, Global train loss: 1.531, Global test loss: 1.558, Global test accuracy: 92.86
Round  47, Train loss: 1.525, Test loss: 1.560, Test accuracy: 92.78
Round  47, Global train loss: 1.525, Global test loss: 1.556, Global test accuracy: 92.96
Round  48, Train loss: 1.516, Test loss: 1.558, Test accuracy: 92.94
Round  48, Global train loss: 1.516, Global test loss: 1.553, Global test accuracy: 92.88
Round  49, Train loss: 1.521, Test loss: 1.557, Test accuracy: 92.98
Round  49, Global train loss: 1.521, Global test loss: 1.553, Global test accuracy: 93.52
Round  50, Train loss: 1.512, Test loss: 1.556, Test accuracy: 93.02
Round  50, Global train loss: 1.512, Global test loss: 1.554, Global test accuracy: 93.24
Round  51, Train loss: 1.512, Test loss: 1.556, Test accuracy: 93.06
Round  51, Global train loss: 1.512, Global test loss: 1.550, Global test accuracy: 93.04
Round  52, Train loss: 1.511, Test loss: 1.555, Test accuracy: 93.18
Round  52, Global train loss: 1.511, Global test loss: 1.551, Global test accuracy: 93.24
Round  53, Train loss: 1.504, Test loss: 1.555, Test accuracy: 93.28
Round  53, Global train loss: 1.504, Global test loss: 1.554, Global test accuracy: 93.16
Round  54, Train loss: 1.516, Test loss: 1.553, Test accuracy: 93.46
Round  54, Global train loss: 1.516, Global test loss: 1.551, Global test accuracy: 93.82
Round  55, Train loss: 1.515, Test loss: 1.551, Test accuracy: 93.58
Round  55, Global train loss: 1.515, Global test loss: 1.550, Global test accuracy: 94.00
Round  56, Train loss: 1.508, Test loss: 1.551, Test accuracy: 93.44
Round  56, Global train loss: 1.508, Global test loss: 1.549, Global test accuracy: 93.82
Round  57, Train loss: 1.513, Test loss: 1.550, Test accuracy: 93.52
Round  57, Global train loss: 1.513, Global test loss: 1.548, Global test accuracy: 93.58
Round  58, Train loss: 1.498, Test loss: 1.549, Test accuracy: 93.62
Round  58, Global train loss: 1.498, Global test loss: 1.548, Global test accuracy: 93.72
Round  59, Train loss: 1.496, Test loss: 1.549, Test accuracy: 93.50
Round  59, Global train loss: 1.496, Global test loss: 1.548, Global test accuracy: 94.12
Round  60, Train loss: 1.505, Test loss: 1.548, Test accuracy: 93.70
Round  60, Global train loss: 1.505, Global test loss: 1.547, Global test accuracy: 93.96
Round  61, Train loss: 1.502, Test loss: 1.548, Test accuracy: 93.84
Round  61, Global train loss: 1.502, Global test loss: 1.545, Global test accuracy: 93.42
Round  62, Train loss: 1.499, Test loss: 1.547, Test accuracy: 93.82
Round  62, Global train loss: 1.499, Global test loss: 1.544, Global test accuracy: 93.62
Round  63, Train loss: 1.504, Test loss: 1.546, Test accuracy: 93.94
Round  63, Global train loss: 1.504, Global test loss: 1.543, Global test accuracy: 94.26
Round  64, Train loss: 1.504, Test loss: 1.546, Test accuracy: 93.98
Round  64, Global train loss: 1.504, Global test loss: 1.545, Global test accuracy: 94.46
Round  65, Train loss: 1.494, Test loss: 1.546, Test accuracy: 94.00
Round  65, Global train loss: 1.494, Global test loss: 1.542, Global test accuracy: 94.24
Round  66, Train loss: 1.495, Test loss: 1.546, Test accuracy: 93.96
Round  66, Global train loss: 1.495, Global test loss: 1.542, Global test accuracy: 93.78
Round  67, Train loss: 1.489, Test loss: 1.546, Test accuracy: 94.00
Round  67, Global train loss: 1.489, Global test loss: 1.544, Global test accuracy: 93.84
Round  68, Train loss: 1.493, Test loss: 1.544, Test accuracy: 94.22
Round  68, Global train loss: 1.493, Global test loss: 1.543, Global test accuracy: 93.94
Round  69, Train loss: 1.492, Test loss: 1.544, Test accuracy: 94.30
Round  69, Global train loss: 1.492, Global test loss: 1.540, Global test accuracy: 94.54
Round  70, Train loss: 1.494, Test loss: 1.543, Test accuracy: 94.16
Round  70, Global train loss: 1.494, Global test loss: 1.540, Global test accuracy: 94.60
Round  71, Train loss: 1.491, Test loss: 1.543, Test accuracy: 94.22
Round  71, Global train loss: 1.491, Global test loss: 1.540, Global test accuracy: 94.52
Round  72, Train loss: 1.485, Test loss: 1.542, Test accuracy: 94.40
Round  72, Global train loss: 1.485, Global test loss: 1.541, Global test accuracy: 94.66
Round  73, Train loss: 1.487, Test loss: 1.541, Test accuracy: 94.46
Round  73, Global train loss: 1.487, Global test loss: 1.540, Global test accuracy: 94.88
Round  74, Train loss: 1.491, Test loss: 1.541, Test accuracy: 94.24
Round  74, Global train loss: 1.491, Global test loss: 1.540, Global test accuracy: 94.52
Round  75, Train loss: 1.483, Test loss: 1.541, Test accuracy: 94.40
Round  75, Global train loss: 1.483, Global test loss: 1.538, Global test accuracy: 94.74
Round  76, Train loss: 1.481, Test loss: 1.542, Test accuracy: 94.42
Round  76, Global train loss: 1.481, Global test loss: 1.538, Global test accuracy: 94.52
Round  77, Train loss: 1.488, Test loss: 1.540, Test accuracy: 94.60
Round  77, Global train loss: 1.488, Global test loss: 1.539, Global test accuracy: 94.76
Round  78, Train loss: 1.488, Test loss: 1.540, Test accuracy: 94.64
Round  78, Global train loss: 1.488, Global test loss: 1.539, Global test accuracy: 94.80
Round  79, Train loss: 1.487, Test loss: 1.539, Test accuracy: 94.60
Round  79, Global train loss: 1.487, Global test loss: 1.538, Global test accuracy: 94.56
Round  80, Train loss: 1.487, Test loss: 1.538, Test accuracy: 94.74
Round  80, Global train loss: 1.487, Global test loss: 1.537, Global test accuracy: 94.58
Round  81, Train loss: 1.491, Test loss: 1.538, Test accuracy: 94.58
Round  81, Global train loss: 1.491, Global test loss: 1.537, Global test accuracy: 94.94
Round  82, Train loss: 1.484, Test loss: 1.539, Test accuracy: 94.62
Round  82, Global train loss: 1.484, Global test loss: 1.536, Global test accuracy: 94.80
Round  83, Train loss: 1.492, Test loss: 1.538, Test accuracy: 94.60
Round  83, Global train loss: 1.492, Global test loss: 1.536, Global test accuracy: 95.16
Round  84, Train loss: 1.487, Test loss: 1.538, Test accuracy: 94.76
Round  84, Global train loss: 1.487, Global test loss: 1.536, Global test accuracy: 94.80
Round  85, Train loss: 1.486, Test loss: 1.538, Test accuracy: 94.62
Round  85, Global train loss: 1.486, Global test loss: 1.536, Global test accuracy: 94.56
Round  86, Train loss: 1.486, Test loss: 1.537, Test accuracy: 94.70
Round  86, Global train loss: 1.486, Global test loss: 1.535, Global test accuracy: 95.02
Round  87, Train loss: 1.487, Test loss: 1.536, Test accuracy: 94.82
Round  87, Global train loss: 1.487, Global test loss: 1.534, Global test accuracy: 95.06
Round  88, Train loss: 1.484, Test loss: 1.536, Test accuracy: 94.84
Round  88, Global train loss: 1.484, Global test loss: 1.534, Global test accuracy: 95.26
Round  89, Train loss: 1.482, Test loss: 1.536, Test accuracy: 94.72
Round  89, Global train loss: 1.482, Global test loss: 1.534, Global test accuracy: 94.86
Round  90, Train loss: 1.478, Test loss: 1.536, Test accuracy: 94.82
Round  90, Global train loss: 1.478, Global test loss: 1.536, Global test accuracy: 95.02
Round  91, Train loss: 1.481, Test loss: 1.536, Test accuracy: 94.56
Round  91, Global train loss: 1.481, Global test loss: 1.535, Global test accuracy: 94.68
Round  92, Train loss: 1.478, Test loss: 1.536, Test accuracy: 94.72
Round  92, Global train loss: 1.478, Global test loss: 1.536, Global test accuracy: 94.54/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  93, Train loss: 1.479, Test loss: 1.536, Test accuracy: 94.72
Round  93, Global train loss: 1.479, Global test loss: 1.534, Global test accuracy: 94.76
Round  94, Train loss: 1.480, Test loss: 1.535, Test accuracy: 94.88
Round  94, Global train loss: 1.480, Global test loss: 1.534, Global test accuracy: 95.08
Round  95, Train loss: 1.480, Test loss: 1.534, Test accuracy: 94.74
Round  95, Global train loss: 1.480, Global test loss: 1.533, Global test accuracy: 94.78
Round  96, Train loss: 1.482, Test loss: 1.534, Test accuracy: 94.68
Round  96, Global train loss: 1.482, Global test loss: 1.534, Global test accuracy: 94.88
Round  97, Train loss: 1.479, Test loss: 1.534, Test accuracy: 94.70
Round  97, Global train loss: 1.479, Global test loss: 1.534, Global test accuracy: 95.08
Round  98, Train loss: 1.478, Test loss: 1.533, Test accuracy: 94.72
Round  98, Global train loss: 1.478, Global test loss: 1.532, Global test accuracy: 94.74
Round  99, Train loss: 1.478, Test loss: 1.534, Test accuracy: 94.88
Round  99, Global train loss: 1.478, Global test loss: 1.532, Global test accuracy: 94.68
Final Round, Train loss: 1.472, Test loss: 1.532, Test accuracy: 94.84
Final Round, Global train loss: 1.472, Global test loss: 1.532, Global test accuracy: 94.68
Average accuracy final 10 rounds: 94.74199999999999
455.28668689727783
[1.0149927139282227, 1.8463373184204102, 2.6848011016845703, 3.524806022644043, 4.363389253616333, 5.200577259063721, 6.039495468139648, 6.875523328781128, 7.713963270187378, 8.550737857818604, 9.386437177658081, 10.220049619674683, 11.0507493019104, 11.876469135284424, 12.70785140991211, 13.542132139205933, 14.367148399353027, 15.20199990272522, 16.038294792175293, 16.866394758224487, 17.703196048736572, 18.54339909553528, 19.369834423065186, 20.205497980117798, 21.040019750595093, 21.86459970474243, 22.70164465904236, 23.536871194839478, 24.36102843284607, 25.20373558998108, 26.03967046737671, 26.86798405647278, 27.707494497299194, 28.539576768875122, 29.366936445236206, 30.203855276107788, 31.03753423690796, 31.862983465194702, 32.70180034637451, 33.53121614456177, 34.35972237586975, 35.19517803192139, 36.029359102249146, 36.85375690460205, 37.69103789329529, 38.52419567108154, 39.34844183921814, 40.18638825416565, 41.01836037635803, 41.844231843948364, 42.68363976478577, 43.514323234558105, 44.34094047546387, 45.176406145095825, 46.009565591812134, 46.83713722229004, 47.673436880111694, 48.50239062309265, 49.33848237991333, 50.176472902297974, 51.00379300117493, 51.84171962738037, 52.680675745010376, 53.51374888420105, 54.35177445411682, 55.18871521949768, 56.011518478393555, 56.84732389450073, 57.6825053691864, 58.50442123413086, 59.33874583244324, 60.17069387435913, 60.993717193603516, 61.83460068702698, 62.670493841171265, 63.49719977378845, 64.33481907844543, 65.1677417755127, 65.99224948883057, 66.83020997047424, 67.66031956672668, 68.4868996143341, 69.32433652877808, 70.1564531326294, 70.98167490959167, 71.8197431564331, 72.648362159729, 73.47511792182922, 74.31603169441223, 75.14711785316467, 75.97041273117065, 76.80491471290588, 77.63369870185852, 78.46222996711731, 79.29857063293457, 80.12783861160278, 80.95719575881958, 81.79416680335999, 82.62216854095459, 83.44936752319336, 84.70425176620483]
[13.22, 15.94, 27.68, 33.9, 35.26, 36.22, 42.18, 48.58, 54.1, 60.58, 65.86, 68.14, 70.12, 71.78, 72.46, 73.2, 73.74, 74.46, 75.5, 79.02, 81.92, 82.92, 83.3, 83.32, 83.78, 85.36, 87.14, 88.34, 88.68, 89.86, 90.46, 90.66, 91.22, 91.4, 91.4, 91.48, 91.64, 91.7, 91.8, 92.1, 92.04, 92.14, 92.34, 92.08, 92.14, 92.2, 92.4, 92.78, 92.94, 92.98, 93.02, 93.06, 93.18, 93.28, 93.46, 93.58, 93.44, 93.52, 93.62, 93.5, 93.7, 93.84, 93.82, 93.94, 93.98, 94.0, 93.96, 94.0, 94.22, 94.3, 94.16, 94.22, 94.4, 94.46, 94.24, 94.4, 94.42, 94.6, 94.64, 94.6, 94.74, 94.58, 94.62, 94.6, 94.76, 94.62, 94.7, 94.82, 94.84, 94.72, 94.82, 94.56, 94.72, 94.72, 94.88, 94.74, 94.68, 94.7, 94.72, 94.88, 94.84]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fedpac_copsl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist,  filter_alg: loss_psl, level_n_system: 0.0 , level_n_lowerb:0.4  

MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.320, Test loss: 2.300, Test accuracy: 9.92
Round   0, Global train loss: 2.320, Global test loss: 2.300, Global test accuracy: 9.92
Round   1, Train loss: 2.299, Test loss: 2.296, Test accuracy: 9.98
Round   1, Global train loss: 2.299, Global test loss: 2.296, Global test accuracy: 9.92
Round   2, Train loss: 2.294, Test loss: 2.291, Test accuracy: 12.54
Round   2, Global train loss: 2.294, Global test loss: 2.291, Global test accuracy: 12.56
Round   3, Train loss: 2.288, Test loss: 2.281, Test accuracy: 22.18
Round   3, Global train loss: 2.288, Global test loss: 2.281, Global test accuracy: 21.02
Round   4, Train loss: 2.272, Test loss: 2.252, Test accuracy: 33.76
Round   4, Global train loss: 2.272, Global test loss: 2.252, Global test accuracy: 34.18
Round   5, Train loss: 2.227, Test loss: 2.178, Test accuracy: 36.62
Round   5, Global train loss: 2.227, Global test loss: 2.177, Global test accuracy: 36.64
Round   6, Train loss: 2.138, Test loss: 2.085, Test accuracy: 41.08
Round   6, Global train loss: 2.138, Global test loss: 2.083, Global test accuracy: 42.40
Round   7, Train loss: 2.054, Test loss: 2.027, Test accuracy: 43.94
Round   7, Global train loss: 2.054, Global test loss: 2.024, Global test accuracy: 45.88
Round   8, Train loss: 1.991, Test loss: 1.966, Test accuracy: 54.68
Round   8, Global train loss: 1.991, Global test loss: 1.962, Global test accuracy: 56.58
Round   9, Train loss: 1.923, Test loss: 1.892, Test accuracy: 62.68
Round   9, Global train loss: 1.923, Global test loss: 1.888, Global test accuracy: 63.38
Round  10, Train loss: 1.841, Test loss: 1.857, Test accuracy: 63.96
Round  10, Global train loss: 1.841, Global test loss: 1.844, Global test accuracy: 64.64
Traceback (most recent call last):
  File "main_fedpac_copsl.py", line 280, in <module>
    w_local, loss, indd, class_center_local, class_num, noisy_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys,
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2559, in train
    self.filter_data(net, local_net, iter2-head_eps+1, local_eps-head_eps+1, concept_matrix_local)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2396, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist, level_n_system: 0.2 , level_n_lowerb:0.4  

   Client 6, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.301, Test loss: 2.300, Test accuracy: 23.58
Round   0, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 24.54
Round   1, Train loss: 2.298, Test loss: 2.297, Test accuracy: 27.86
Round   1, Global train loss: 2.298, Global test loss: 2.296, Global test accuracy: 31.34
Round   2, Train loss: 2.293, Test loss: 2.293, Test accuracy: 29.96
Round   2, Global train loss: 2.293, Global test loss: 2.291, Global test accuracy: 34.20
Round   3, Train loss: 2.287, Test loss: 2.285, Test accuracy: 26.26
Round   3, Global train loss: 2.287, Global test loss: 2.281, Global test accuracy: 24.40
Round   4, Train loss: 2.238, Test loss: 2.258, Test accuracy: 23.78
Round   4, Global train loss: 2.238, Global test loss: 2.221, Global test accuracy: 23.16
Round   5, Train loss: 2.211, Test loss: 2.236, Test accuracy: 27.18
Round   5, Global train loss: 2.211, Global test loss: 2.193, Global test accuracy: 34.60
Round   6, Train loss: 2.203, Test loss: 2.220, Test accuracy: 27.94
Round   6, Global train loss: 2.203, Global test loss: 2.221, Global test accuracy: 42.72
Round   7, Train loss: 2.264, Test loss: 2.208, Test accuracy: 28.50
Round   7, Global train loss: 2.264, Global test loss: 2.244, Global test accuracy: 22.98
Round   8, Train loss: 2.113, Test loss: 2.170, Test accuracy: 31.80
Round   8, Global train loss: 2.113, Global test loss: 2.065, Global test accuracy: 38.46
Round   9, Train loss: 2.074, Test loss: 2.146, Test accuracy: 34.34
Round   9, Global train loss: 2.074, Global test loss: 2.076, Global test accuracy: 45.34
Round  10, Train loss: 2.105, Test loss: 2.120, Test accuracy: 34.96
Round  10, Global train loss: 2.105, Global test loss: 2.116, Global test accuracy: 38.92
Round  11, Train loss: 1.968, Test loss: 2.102, Test accuracy: 37.38
Round  11, Global train loss: 1.968, Global test loss: 2.010, Global test accuracy: 45.82
Round  12, Train loss: 2.055, Test loss: 2.089, Test accuracy: 38.38
Round  12, Global train loss: 2.055, Global test loss: 2.070, Global test accuracy: 44.86
Round  13, Train loss: 2.114, Test loss: 2.067, Test accuracy: 40.14
Round  13, Global train loss: 2.114, Global test loss: 2.092, Global test accuracy: 43.50
Round  14, Train loss: 2.107, Test loss: 2.038, Test accuracy: 43.80
Round  14, Global train loss: 2.107, Global test loss: 2.073, Global test accuracy: 44.30
Round  15, Train loss: 1.898, Test loss: 2.010, Test accuracy: 46.90
Round  15, Global train loss: 1.898, Global test loss: 1.928, Global test accuracy: 53.70
Round  16, Train loss: 1.905, Test loss: 1.992, Test accuracy: 48.50
Round  16, Global train loss: 1.905, Global test loss: 1.950, Global test accuracy: 51.36
Round  17, Train loss: 1.978, Test loss: 1.976, Test accuracy: 49.44
Round  17, Global train loss: 1.978, Global test loss: 2.017, Global test accuracy: 51.34
Round  18, Train loss: 1.751, Test loss: 1.963, Test accuracy: 50.64
Round  18, Global train loss: 1.751, Global test loss: 1.837, Global test accuracy: 61.52
Round  19, Train loss: 1.907, Test loss: 1.948, Test accuracy: 52.74
Round  19, Global train loss: 1.907, Global test loss: 1.952, Global test accuracy: 50.66
Round  20, Train loss: 1.902, Test loss: 1.923, Test accuracy: 55.70
Round  20, Global train loss: 1.902, Global test loss: 1.956, Global test accuracy: 53.68
Round  21, Train loss: 1.773, Test loss: 1.912, Test accuracy: 57.30
Round  21, Global train loss: 1.773, Global test loss: 1.828, Global test accuracy: 65.58
Round  22, Train loss: 1.782, Test loss: 1.891, Test accuracy: 59.76
Round  22, Global train loss: 1.782, Global test loss: 1.854, Global test accuracy: 59.72
Round  23, Train loss: 1.779, Test loss: 1.872, Test accuracy: 61.08
Round  23, Global train loss: 1.779, Global test loss: 1.867, Global test accuracy: 59.80
Round  24, Train loss: 1.898, Test loss: 1.867, Test accuracy: 62.04
Round  24, Global train loss: 1.898, Global test loss: 1.977, Global test accuracy: 48.14
Round  25, Train loss: 1.759, Test loss: 1.857, Test accuracy: 62.52
Round  25, Global train loss: 1.759, Global test loss: 1.876, Global test accuracy: 57.56
Round  26, Train loss: 1.661, Test loss: 1.854, Test accuracy: 62.80
Round  26, Global train loss: 1.661, Global test loss: 1.814, Global test accuracy: 66.16
Round  27, Train loss: 1.743, Test loss: 1.850, Test accuracy: 62.90
Round  27, Global train loss: 1.743, Global test loss: 1.867, Global test accuracy: 60.26
Round  28, Train loss: 1.642, Test loss: 1.845, Test accuracy: 63.48
Round  28, Global train loss: 1.642, Global test loss: 1.771, Global test accuracy: 68.30
Round  29, Train loss: 1.714, Test loss: 1.844, Test accuracy: 63.54
Round  29, Global train loss: 1.714, Global test loss: 1.870, Global test accuracy: 57.86
Round  30, Train loss: 1.675, Test loss: 1.842, Test accuracy: 63.46
Round  30, Global train loss: 1.675, Global test loss: 1.801, Global test accuracy: 70.58
Round  31, Train loss: 1.672, Test loss: 1.841, Test accuracy: 63.48
Round  31, Global train loss: 1.672, Global test loss: 1.828, Global test accuracy: 63.16
Round  32, Train loss: 1.654, Test loss: 1.835, Test accuracy: 64.04
Round  32, Global train loss: 1.654, Global test loss: 1.770, Global test accuracy: 71.94
Round  33, Train loss: 1.661, Test loss: 1.835, Test accuracy: 64.06
Round  33, Global train loss: 1.661, Global test loss: 1.844, Global test accuracy: 61.72
Round  34, Train loss: 1.758, Test loss: 1.835, Test accuracy: 64.04
Round  34, Global train loss: 1.758, Global test loss: 1.890, Global test accuracy: 56.46
Round  35, Train loss: 1.624, Test loss: 1.834, Test accuracy: 64.00
Round  35, Global train loss: 1.624, Global test loss: 1.790, Global test accuracy: 68.04
Round  36, Train loss: 1.867, Test loss: 1.824, Test accuracy: 65.16
Round  36, Global train loss: 1.867, Global test loss: 1.963, Global test accuracy: 49.34
Round  37, Train loss: 1.613, Test loss: 1.823, Test accuracy: 65.16
Round  37, Global train loss: 1.613, Global test loss: 1.781, Global test accuracy: 68.66
Round  38, Train loss: 1.683, Test loss: 1.821, Test accuracy: 65.32
Round  38, Global train loss: 1.683, Global test loss: 1.824, Global test accuracy: 64.60
Round  39, Train loss: 1.846, Test loss: 1.817, Test accuracy: 65.40
Round  39, Global train loss: 1.846, Global test loss: 1.926, Global test accuracy: 52.98
Round  40, Train loss: 1.650, Test loss: 1.815, Test accuracy: 65.74
Round  40, Global train loss: 1.650, Global test loss: 1.815, Global test accuracy: 65.44
Round  41, Train loss: 1.721, Test loss: 1.810, Test accuracy: 66.02
Round  41, Global train loss: 1.721, Global test loss: 1.825, Global test accuracy: 65.94
Round  42, Train loss: 1.908, Test loss: 1.808, Test accuracy: 66.04
Round  42, Global train loss: 1.908, Global test loss: 2.018, Global test accuracy: 42.80
Round  43, Train loss: 1.706, Test loss: 1.808, Test accuracy: 65.98
Round  43, Global train loss: 1.706, Global test loss: 1.890, Global test accuracy: 55.28
Round  44, Train loss: 1.640, Test loss: 1.805, Test accuracy: 66.28
Round  44, Global train loss: 1.640, Global test loss: 1.788, Global test accuracy: 67.26
Round  45, Train loss: 1.745, Test loss: 1.803, Test accuracy: 66.52
Round  45, Global train loss: 1.745, Global test loss: 1.905, Global test accuracy: 55.26
Round  46, Train loss: 1.582, Test loss: 1.802, Test accuracy: 66.58
Round  46, Global train loss: 1.582, Global test loss: 1.763, Global test accuracy: 70.52
Round  47, Train loss: 1.671, Test loss: 1.798, Test accuracy: 67.16
Round  47, Global train loss: 1.671, Global test loss: 1.822, Global test accuracy: 63.84
Round  48, Train loss: 1.697, Test loss: 1.798, Test accuracy: 67.14
Round  48, Global train loss: 1.697, Global test loss: 1.880, Global test accuracy: 58.34
Round  49, Train loss: 1.621, Test loss: 1.793, Test accuracy: 67.68
Round  49, Global train loss: 1.621, Global test loss: 1.757, Global test accuracy: 69.66
Round  50, Train loss: 1.623, Test loss: 1.785, Test accuracy: 68.86
Round  50, Global train loss: 1.623, Global test loss: 1.692, Global test accuracy: 78.46
Round  51, Train loss: 1.728, Test loss: 1.782, Test accuracy: 69.06
Round  51, Global train loss: 1.728, Global test loss: 1.899, Global test accuracy: 56.12
Round  52, Train loss: 1.581, Test loss: 1.782, Test accuracy: 69.24
Round  52, Global train loss: 1.581, Global test loss: 1.756, Global test accuracy: 70.26
Round  53, Train loss: 1.810, Test loss: 1.781, Test accuracy: 69.42
Round  53, Global train loss: 1.810, Global test loss: 1.962, Global test accuracy: 49.72
Round  54, Train loss: 1.771, Test loss: 1.780, Test accuracy: 69.60
Round  54, Global train loss: 1.771, Global test loss: 1.921, Global test accuracy: 53.16
Round  55, Train loss: 1.630, Test loss: 1.774, Test accuracy: 70.00
Round  55, Global train loss: 1.630, Global test loss: 1.775, Global test accuracy: 67.80
Round  56, Train loss: 1.789, Test loss: 1.773, Test accuracy: 70.08
Round  56, Global train loss: 1.789, Global test loss: 1.958, Global test accuracy: 50.58
Round  57, Train loss: 1.711, Test loss: 1.772, Test accuracy: 70.06
Round  57, Global train loss: 1.711, Global test loss: 1.900, Global test accuracy: 56.34
Round  58, Train loss: 1.585, Test loss: 1.771, Test accuracy: 70.10
Round  58, Global train loss: 1.585, Global test loss: 1.677, Global test accuracy: 79.52
Round  59, Train loss: 1.621, Test loss: 1.771, Test accuracy: 70.08
Round  59, Global train loss: 1.621, Global test loss: 1.807, Global test accuracy: 65.58
Round  60, Train loss: 1.653, Test loss: 1.769, Test accuracy: 70.20
Round  60, Global train loss: 1.653, Global test loss: 1.806, Global test accuracy: 65.76
Round  61, Train loss: 1.589, Test loss: 1.765, Test accuracy: 70.72
Round  61, Global train loss: 1.589, Global test loss: 1.770, Global test accuracy: 68.86
Round  62, Train loss: 1.696, Test loss: 1.763, Test accuracy: 70.78
Round  62, Global train loss: 1.696, Global test loss: 1.902, Global test accuracy: 54.04
Round  63, Train loss: 1.768, Test loss: 1.763, Test accuracy: 70.94
Round  63, Global train loss: 1.768, Global test loss: 1.956, Global test accuracy: 49.92
Round  64, Train loss: 1.592, Test loss: 1.760, Test accuracy: 71.36
Round  64, Global train loss: 1.592, Global test loss: 1.712, Global test accuracy: 75.88
Round  65, Train loss: 1.676, Test loss: 1.759, Test accuracy: 71.20
Round  65, Global train loss: 1.676, Global test loss: 1.899, Global test accuracy: 55.60
Round  66, Train loss: 1.686, Test loss: 1.759, Test accuracy: 71.34
Round  66, Global train loss: 1.686, Global test loss: 1.848, Global test accuracy: 62.10
Round  67, Train loss: 1.662, Test loss: 1.759, Test accuracy: 71.28
Round  67, Global train loss: 1.662, Global test loss: 1.855, Global test accuracy: 59.70
Round  68, Train loss: 1.744, Test loss: 1.760, Test accuracy: 71.16
Round  68, Global train loss: 1.744, Global test loss: 1.976, Global test accuracy: 48.50
Round  69, Train loss: 1.713, Test loss: 1.761, Test accuracy: 71.10
Round  69, Global train loss: 1.713, Global test loss: 1.854, Global test accuracy: 61.96
Round  70, Train loss: 1.634, Test loss: 1.760, Test accuracy: 71.02
Round  70, Global train loss: 1.634, Global test loss: 1.832, Global test accuracy: 62.40
Round  71, Train loss: 1.693, Test loss: 1.760, Test accuracy: 71.04
Round  71, Global train loss: 1.693, Global test loss: 1.855, Global test accuracy: 61.20
Round  72, Train loss: 1.605, Test loss: 1.760, Test accuracy: 71.02
Round  72, Global train loss: 1.605, Global test loss: 1.762, Global test accuracy: 70.26
Round  73, Train loss: 1.609, Test loss: 1.760, Test accuracy: 71.04
Round  73, Global train loss: 1.609, Global test loss: 1.788, Global test accuracy: 67.20
Round  74, Train loss: 1.575, Test loss: 1.760, Test accuracy: 71.06
Round  74, Global train loss: 1.575, Global test loss: 1.716, Global test accuracy: 74.84
Round  75, Train loss: 1.678, Test loss: 1.759, Test accuracy: 71.16
Round  75, Global train loss: 1.678, Global test loss: 1.828, Global test accuracy: 64.04
Round  76, Train loss: 1.682, Test loss: 1.754, Test accuracy: 71.70
Round  76, Global train loss: 1.682, Global test loss: 1.846, Global test accuracy: 61.66
Round  77, Train loss: 1.693, Test loss: 1.751, Test accuracy: 72.06
Round  77, Global train loss: 1.693, Global test loss: 1.858, Global test accuracy: 59.76
Round  78, Train loss: 1.676, Test loss: 1.749, Test accuracy: 72.08
Round  78, Global train loss: 1.676, Global test loss: 1.899, Global test accuracy: 55.38
Round  79, Train loss: 1.727, Test loss: 1.748, Test accuracy: 72.28
Round  79, Global train loss: 1.727, Global test loss: 1.958, Global test accuracy: 50.20
Round  80, Train loss: 1.651, Test loss: 1.748, Test accuracy: 72.30
Round  80, Global train loss: 1.651, Global test loss: 1.907, Global test accuracy: 53.60
Round  81, Train loss: 1.642, Test loss: 1.748, Test accuracy: 72.28
Round  81, Global train loss: 1.642, Global test loss: 1.874, Global test accuracy: 56.88
Round  82, Train loss: 1.741, Test loss: 1.750, Test accuracy: 71.90
Round  82, Global train loss: 1.741, Global test loss: 1.935, Global test accuracy: 52.56
Round  83, Train loss: 1.665, Test loss: 1.748, Test accuracy: 72.06
Round  83, Global train loss: 1.665, Global test loss: 1.877, Global test accuracy: 57.12
Round  84, Train loss: 1.732, Test loss: 1.747, Test accuracy: 72.36
Round  84, Global train loss: 1.732, Global test loss: 1.912, Global test accuracy: 54.36
Round  85, Train loss: 1.611, Test loss: 1.744, Test accuracy: 72.76
Round  85, Global train loss: 1.611, Global test loss: 1.789, Global test accuracy: 68.36
Round  86, Train loss: 1.616, Test loss: 1.743, Test accuracy: 72.80
Round  86, Global train loss: 1.616, Global test loss: 1.843, Global test accuracy: 61.02
Round  87, Train loss: 1.712, Test loss: 1.744, Test accuracy: 72.62
Round  87, Global train loss: 1.712, Global test loss: 1.911, Global test accuracy: 55.04
Round  88, Train loss: 1.630, Test loss: 1.744, Test accuracy: 72.60
Round  88, Global train loss: 1.630, Global test loss: 1.831, Global test accuracy: 62.26
Round  89, Train loss: 1.596, Test loss: 1.743, Test accuracy: 72.60
Round  89, Global train loss: 1.596, Global test loss: 1.796, Global test accuracy: 67.70
Round  90, Train loss: 1.565, Test loss: 1.743, Test accuracy: 72.64
Round  90, Global train loss: 1.565, Global test loss: 1.724, Global test accuracy: 73.62
Round  91, Train loss: 1.557, Test loss: 1.743, Test accuracy: 72.52
Round  91, Global train loss: 1.557, Global test loss: 1.681, Global test accuracy: 78.48
Round  92, Train loss: 1.632, Test loss: 1.743, Test accuracy: 72.40
Round  92, Global train loss: 1.632, Global test loss: 1.795, Global test accuracy: 66.66
Round  93, Train loss: 1.554, Test loss: 1.743, Test accuracy: 72.42
Round  93, Global train loss: 1.554, Global test loss: 1.738, Global test accuracy: 71.84
Round  94, Train loss: 1.558, Test loss: 1.743, Test accuracy: 72.46
Round  94, Global train loss: 1.558, Global test loss: 1.750, Global test accuracy: 71.06
Round  95, Train loss: 1.625, Test loss: 1.743, Test accuracy: 72.46
Round  95, Global train loss: 1.625, Global test loss: 1.831, Global test accuracy: 61.86/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 1.711, Test loss: 1.743, Test accuracy: 72.42
Round  96, Global train loss: 1.711, Global test loss: 1.910, Global test accuracy: 54.92
Round  97, Train loss: 1.534, Test loss: 1.742, Test accuracy: 72.54
Round  97, Global train loss: 1.534, Global test loss: 1.740, Global test accuracy: 70.82
Round  98, Train loss: 1.553, Test loss: 1.742, Test accuracy: 72.56
Round  98, Global train loss: 1.553, Global test loss: 1.725, Global test accuracy: 73.20
Round  99, Train loss: 1.547, Test loss: 1.742, Test accuracy: 72.52
Round  99, Global train loss: 1.547, Global test loss: 1.738, Global test accuracy: 71.72
Final Round, Train loss: 1.596, Test loss: 1.742, Test accuracy: 72.58
Final Round, Global train loss: 1.596, Global test loss: 1.738, Global test accuracy: 71.72
Average accuracy final 10 rounds: 72.49399999999999 

Average global accuracy final 10 rounds: 69.418 

521.0478255748749
[0.7664525508880615, 1.532905101776123, 2.232825517654419, 2.932745933532715, 3.608102798461914, 4.283459663391113, 4.974987745285034, 5.666515827178955, 6.353900909423828, 7.041285991668701, 7.731271982192993, 8.421257972717285, 9.107166767120361, 9.793075561523438, 10.488333702087402, 11.183591842651367, 11.867691278457642, 12.551790714263916, 13.215088844299316, 13.878386974334717, 14.568161725997925, 15.257936477661133, 15.922713279724121, 16.58749008178711, 17.275119066238403, 17.962748050689697, 18.626338243484497, 19.289928436279297, 19.978240728378296, 20.666553020477295, 21.337836027145386, 22.009119033813477, 22.696601152420044, 23.38408327102661, 24.066654920578003, 24.749226570129395, 25.433732986450195, 26.118239402770996, 26.79696035385132, 27.47568130493164, 28.16481304168701, 28.853944778442383, 29.566110849380493, 30.278276920318604, 30.98106575012207, 31.683854579925537, 32.4152410030365, 33.14662742614746, 33.852508306503296, 34.55838918685913, 35.28724956512451, 36.01610994338989, 36.73746132850647, 37.45881271362305, 38.17908573150635, 38.89935874938965, 39.628270387649536, 40.357182025909424, 41.08328628540039, 41.80939054489136, 42.53777837753296, 43.26616621017456, 43.974581480026245, 44.68299674987793, 45.404513359069824, 46.12602996826172, 46.83296322822571, 47.5398964881897, 48.273638010025024, 49.00737953186035, 49.72377252578735, 50.440165519714355, 51.163015365600586, 51.885865211486816, 52.61372208595276, 53.3415789604187, 54.063782691955566, 54.78598642349243, 55.50975775718689, 56.23352909088135, 56.93798518180847, 57.642441272735596, 58.36000037193298, 59.07755947113037, 59.781368255615234, 60.4851770401001, 61.21892595291138, 61.952674865722656, 62.660706758499146, 63.368738651275635, 64.09827876091003, 64.82781887054443, 65.55281448364258, 66.27781009674072, 66.99543166160583, 67.71305322647095, 68.44812989234924, 69.18320655822754, 69.88700556755066, 70.59080457687378, 71.30223655700684, 72.01366853713989, 72.71814250946045, 73.422616481781, 74.15085959434509, 74.87910270690918, 75.58052325248718, 76.28194379806519, 77.01027512550354, 77.7386064529419, 78.45440316200256, 79.17019987106323, 79.89378905296326, 80.61737823486328, 81.3532943725586, 82.0892105102539, 82.79749321937561, 83.50577592849731, 84.23356914520264, 84.96136236190796, 85.66952466964722, 86.37768697738647, 87.10117411613464, 87.82466125488281, 88.53119134902954, 89.23772144317627, 89.9703516960144, 90.70298194885254, 91.42199945449829, 92.14101696014404, 92.86577320098877, 93.5905294418335, 94.3239221572876, 95.0573148727417, 95.76762795448303, 96.47794103622437, 97.20561337471008, 97.9332857131958, 98.63782262802124, 99.34235954284668, 100.070072889328, 100.79778623580933, 101.50013828277588, 102.20249032974243, 102.93353652954102, 103.6645827293396, 104.38352465629578, 105.10246658325195, 105.83221745491028, 106.5619683265686, 107.29397249221802, 108.02597665786743, 108.7400872707367, 109.45419788360596, 110.18496918678284, 110.91574048995972, 111.62178421020508, 112.32782793045044, 113.04878902435303, 113.76975011825562, 114.47537779808044, 115.18100547790527, 115.91112184524536, 116.64123821258545, 117.36396837234497, 118.08669853210449, 118.81815099716187, 119.54960346221924, 120.27627539634705, 121.00294733047485, 121.72906756401062, 122.45518779754639, 123.1804187297821, 123.90564966201782, 124.64181232452393, 125.37797498703003, 126.10549736022949, 126.83301973342896, 127.53645038604736, 128.23988103866577, 128.9561104774475, 129.67233991622925, 130.40707206726074, 131.14180421829224, 131.86857891082764, 132.59535360336304, 133.3170838356018, 134.03881406784058, 134.7682659626007, 135.49771785736084, 136.2133662700653, 136.92901468276978, 137.63498616218567, 138.34095764160156, 139.07273626327515, 139.80451488494873, 140.50783705711365, 141.21115922927856, 141.93592309951782, 142.66068696975708, 144.10726189613342, 145.55383682250977]
[23.58, 23.58, 27.86, 27.86, 29.96, 29.96, 26.26, 26.26, 23.78, 23.78, 27.18, 27.18, 27.94, 27.94, 28.5, 28.5, 31.8, 31.8, 34.34, 34.34, 34.96, 34.96, 37.38, 37.38, 38.38, 38.38, 40.14, 40.14, 43.8, 43.8, 46.9, 46.9, 48.5, 48.5, 49.44, 49.44, 50.64, 50.64, 52.74, 52.74, 55.7, 55.7, 57.3, 57.3, 59.76, 59.76, 61.08, 61.08, 62.04, 62.04, 62.52, 62.52, 62.8, 62.8, 62.9, 62.9, 63.48, 63.48, 63.54, 63.54, 63.46, 63.46, 63.48, 63.48, 64.04, 64.04, 64.06, 64.06, 64.04, 64.04, 64.0, 64.0, 65.16, 65.16, 65.16, 65.16, 65.32, 65.32, 65.4, 65.4, 65.74, 65.74, 66.02, 66.02, 66.04, 66.04, 65.98, 65.98, 66.28, 66.28, 66.52, 66.52, 66.58, 66.58, 67.16, 67.16, 67.14, 67.14, 67.68, 67.68, 68.86, 68.86, 69.06, 69.06, 69.24, 69.24, 69.42, 69.42, 69.6, 69.6, 70.0, 70.0, 70.08, 70.08, 70.06, 70.06, 70.1, 70.1, 70.08, 70.08, 70.2, 70.2, 70.72, 70.72, 70.78, 70.78, 70.94, 70.94, 71.36, 71.36, 71.2, 71.2, 71.34, 71.34, 71.28, 71.28, 71.16, 71.16, 71.1, 71.1, 71.02, 71.02, 71.04, 71.04, 71.02, 71.02, 71.04, 71.04, 71.06, 71.06, 71.16, 71.16, 71.7, 71.7, 72.06, 72.06, 72.08, 72.08, 72.28, 72.28, 72.3, 72.3, 72.28, 72.28, 71.9, 71.9, 72.06, 72.06, 72.36, 72.36, 72.76, 72.76, 72.8, 72.8, 72.62, 72.62, 72.6, 72.6, 72.6, 72.6, 72.64, 72.64, 72.52, 72.52, 72.4, 72.4, 72.42, 72.42, 72.46, 72.46, 72.46, 72.46, 72.42, 72.42, 72.54, 72.54, 72.56, 72.56, 72.52, 72.52, 72.58, 72.58]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.2 , level_n_lowerb:0.4  

   Client 4, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.301, Test loss: 2.299, Test accuracy: 27.20
Round   0, Global train loss: 2.301, Global test loss: 2.299, Global test accuracy: 27.76
Round   1, Train loss: 2.296, Test loss: 2.294, Test accuracy: 36.26
Round   1, Global train loss: 2.296, Global test loss: 2.292, Global test accuracy: 44.96
Round   2, Train loss: 2.286, Test loss: 2.281, Test accuracy: 37.64
Round   2, Global train loss: 2.286, Global test loss: 2.275, Global test accuracy: 42.48
Round   3, Train loss: 2.219, Test loss: 2.198, Test accuracy: 33.98
Round   3, Global train loss: 2.219, Global test loss: 2.144, Global test accuracy: 31.12
Round   4, Train loss: 2.081, Test loss: 2.121, Test accuracy: 42.84
Round   4, Global train loss: 2.081, Global test loss: 2.011, Global test accuracy: 51.06
Round   5, Train loss: 2.063, Test loss: 2.062, Test accuracy: 48.08
Round   5, Global train loss: 2.063, Global test loss: 1.908, Global test accuracy: 59.06
Round   6, Train loss: 1.915, Test loss: 1.973, Test accuracy: 54.66
Round   6, Global train loss: 1.915, Global test loss: 1.812, Global test accuracy: 71.34
Round   7, Train loss: 1.795, Test loss: 1.938, Test accuracy: 56.94
Round   7, Global train loss: 1.795, Global test loss: 1.763, Global test accuracy: 72.18
Round   8, Train loss: 1.858, Test loss: 1.890, Test accuracy: 62.02
Round   8, Global train loss: 1.858, Global test loss: 1.750, Global test accuracy: 73.06
Round   9, Train loss: 1.824, Test loss: 1.860, Test accuracy: 64.68
Round   9, Global train loss: 1.824, Global test loss: 1.738, Global test accuracy: 73.74
Round  10, Train loss: 1.736, Test loss: 1.819, Test accuracy: 68.48
Round  10, Global train loss: 1.736, Global test loss: 1.733, Global test accuracy: 73.68
Round  11, Train loss: 1.787, Test loss: 1.810, Test accuracy: 69.18
Round  11, Global train loss: 1.787, Global test loss: 1.729, Global test accuracy: 73.70
Round  12, Train loss: 1.699, Test loss: 1.756, Test accuracy: 71.96
Round  12, Global train loss: 1.699, Global test loss: 1.724, Global test accuracy: 74.46
Round  13, Train loss: 1.826, Test loss: 1.738, Test accuracy: 73.08
Round  13, Global train loss: 1.826, Global test loss: 1.724, Global test accuracy: 73.98
Round  14, Train loss: 1.733, Test loss: 1.735, Test accuracy: 73.16
Round  14, Global train loss: 1.733, Global test loss: 1.723, Global test accuracy: 74.06
Round  15, Train loss: 1.710, Test loss: 1.730, Test accuracy: 73.56
Round  15, Global train loss: 1.710, Global test loss: 1.716, Global test accuracy: 74.90
Round  16, Train loss: 1.708, Test loss: 1.729, Test accuracy: 73.52
Round  16, Global train loss: 1.708, Global test loss: 1.715, Global test accuracy: 74.88
Round  17, Train loss: 1.720, Test loss: 1.728, Test accuracy: 73.64
Round  17, Global train loss: 1.720, Global test loss: 1.716, Global test accuracy: 74.60
Round  18, Train loss: 1.789, Test loss: 1.726, Test accuracy: 73.84
Round  18, Global train loss: 1.789, Global test loss: 1.719, Global test accuracy: 74.16
Round  19, Train loss: 1.815, Test loss: 1.725, Test accuracy: 74.02
Round  19, Global train loss: 1.815, Global test loss: 1.719, Global test accuracy: 74.24
Round  20, Train loss: 1.703, Test loss: 1.724, Test accuracy: 74.04
Round  20, Global train loss: 1.703, Global test loss: 1.715, Global test accuracy: 74.64
Round  21, Train loss: 1.807, Test loss: 1.724, Test accuracy: 73.98
Round  21, Global train loss: 1.807, Global test loss: 1.717, Global test accuracy: 74.22
Round  22, Train loss: 1.799, Test loss: 1.724, Test accuracy: 73.92
Round  22, Global train loss: 1.799, Global test loss: 1.717, Global test accuracy: 74.58
Round  23, Train loss: 1.793, Test loss: 1.722, Test accuracy: 74.22
Round  23, Global train loss: 1.793, Global test loss: 1.716, Global test accuracy: 74.62
Round  24, Train loss: 1.729, Test loss: 1.719, Test accuracy: 74.56
Round  24, Global train loss: 1.729, Global test loss: 1.716, Global test accuracy: 74.32
Round  25, Train loss: 1.782, Test loss: 1.718, Test accuracy: 74.46
Round  25, Global train loss: 1.782, Global test loss: 1.716, Global test accuracy: 74.66
Round  26, Train loss: 1.669, Test loss: 1.718, Test accuracy: 74.48
Round  26, Global train loss: 1.669, Global test loss: 1.712, Global test accuracy: 75.06
Round  27, Train loss: 1.700, Test loss: 1.718, Test accuracy: 74.38
Round  27, Global train loss: 1.700, Global test loss: 1.712, Global test accuracy: 74.90
Round  28, Train loss: 1.775, Test loss: 1.718, Test accuracy: 74.40
Round  28, Global train loss: 1.775, Global test loss: 1.714, Global test accuracy: 74.58
Round  29, Train loss: 1.693, Test loss: 1.717, Test accuracy: 74.50
Round  29, Global train loss: 1.693, Global test loss: 1.711, Global test accuracy: 75.20
Round  30, Train loss: 1.776, Test loss: 1.717, Test accuracy: 74.48
Round  30, Global train loss: 1.776, Global test loss: 1.715, Global test accuracy: 75.02
Round  31, Train loss: 1.792, Test loss: 1.718, Test accuracy: 74.34
Round  31, Global train loss: 1.792, Global test loss: 1.716, Global test accuracy: 74.10
Round  32, Train loss: 1.781, Test loss: 1.718, Test accuracy: 74.24
Round  32, Global train loss: 1.781, Global test loss: 1.716, Global test accuracy: 74.22
Round  33, Train loss: 1.668, Test loss: 1.718, Test accuracy: 74.18
Round  33, Global train loss: 1.668, Global test loss: 1.714, Global test accuracy: 74.56
Round  34, Train loss: 1.716, Test loss: 1.718, Test accuracy: 74.20
Round  34, Global train loss: 1.716, Global test loss: 1.713, Global test accuracy: 74.94
Round  35, Train loss: 1.802, Test loss: 1.718, Test accuracy: 74.16
Round  35, Global train loss: 1.802, Global test loss: 1.714, Global test accuracy: 74.76
Round  36, Train loss: 1.729, Test loss: 1.718, Test accuracy: 74.08
Round  36, Global train loss: 1.729, Global test loss: 1.717, Global test accuracy: 74.58
Round  37, Train loss: 1.798, Test loss: 1.718, Test accuracy: 74.26
Round  37, Global train loss: 1.798, Global test loss: 1.714, Global test accuracy: 74.68
Round  38, Train loss: 1.710, Test loss: 1.718, Test accuracy: 74.30
Round  38, Global train loss: 1.710, Global test loss: 1.713, Global test accuracy: 74.70
Round  39, Train loss: 1.712, Test loss: 1.717, Test accuracy: 74.32
Round  39, Global train loss: 1.712, Global test loss: 1.712, Global test accuracy: 74.86
Round  40, Train loss: 1.691, Test loss: 1.717, Test accuracy: 74.36
Round  40, Global train loss: 1.691, Global test loss: 1.714, Global test accuracy: 74.62
Round  41, Train loss: 1.773, Test loss: 1.716, Test accuracy: 74.46
Round  41, Global train loss: 1.773, Global test loss: 1.714, Global test accuracy: 74.72
Round  42, Train loss: 1.726, Test loss: 1.716, Test accuracy: 74.52
Round  42, Global train loss: 1.726, Global test loss: 1.714, Global test accuracy: 74.62
Round  43, Train loss: 1.797, Test loss: 1.716, Test accuracy: 74.56
Round  43, Global train loss: 1.797, Global test loss: 1.715, Global test accuracy: 74.54
Round  44, Train loss: 1.788, Test loss: 1.715, Test accuracy: 74.58
Round  44, Global train loss: 1.788, Global test loss: 1.713, Global test accuracy: 74.72
Round  45, Train loss: 1.805, Test loss: 1.716, Test accuracy: 74.56
Round  45, Global train loss: 1.805, Global test loss: 1.714, Global test accuracy: 74.88
Round  46, Train loss: 1.747, Test loss: 1.715, Test accuracy: 74.60
Round  46, Global train loss: 1.747, Global test loss: 1.712, Global test accuracy: 74.74
Round  47, Train loss: 1.673, Test loss: 1.715, Test accuracy: 74.68
Round  47, Global train loss: 1.673, Global test loss: 1.709, Global test accuracy: 75.22
Round  48, Train loss: 1.772, Test loss: 1.714, Test accuracy: 74.76
Round  48, Global train loss: 1.772, Global test loss: 1.711, Global test accuracy: 75.26
Round  49, Train loss: 1.688, Test loss: 1.713, Test accuracy: 74.82
Round  49, Global train loss: 1.688, Global test loss: 1.710, Global test accuracy: 74.96
Round  50, Train loss: 1.780, Test loss: 1.713, Test accuracy: 74.88
Round  50, Global train loss: 1.780, Global test loss: 1.712, Global test accuracy: 74.72
Round  51, Train loss: 1.710, Test loss: 1.713, Test accuracy: 74.90
Round  51, Global train loss: 1.710, Global test loss: 1.713, Global test accuracy: 74.94
Round  52, Train loss: 1.769, Test loss: 1.714, Test accuracy: 74.86
Round  52, Global train loss: 1.769, Global test loss: 1.711, Global test accuracy: 75.34
Round  53, Train loss: 1.808, Test loss: 1.714, Test accuracy: 74.84
Round  53, Global train loss: 1.808, Global test loss: 1.716, Global test accuracy: 74.42
Round  54, Train loss: 1.699, Test loss: 1.714, Test accuracy: 74.74
Round  54, Global train loss: 1.699, Global test loss: 1.714, Global test accuracy: 74.78
Round  55, Train loss: 1.691, Test loss: 1.714, Test accuracy: 74.64
Round  55, Global train loss: 1.691, Global test loss: 1.709, Global test accuracy: 75.72
Round  56, Train loss: 1.722, Test loss: 1.714, Test accuracy: 74.72
Round  56, Global train loss: 1.722, Global test loss: 1.711, Global test accuracy: 74.94
Round  57, Train loss: 1.709, Test loss: 1.714, Test accuracy: 74.64
Round  57, Global train loss: 1.709, Global test loss: 1.713, Global test accuracy: 74.64
Round  58, Train loss: 1.797, Test loss: 1.714, Test accuracy: 74.62
Round  58, Global train loss: 1.797, Global test loss: 1.712, Global test accuracy: 75.24
Round  59, Train loss: 1.683, Test loss: 1.714, Test accuracy: 74.68
Round  59, Global train loss: 1.683, Global test loss: 1.710, Global test accuracy: 75.44
Round  60, Train loss: 1.690, Test loss: 1.714, Test accuracy: 74.70
Round  60, Global train loss: 1.690, Global test loss: 1.711, Global test accuracy: 75.12
Round  61, Train loss: 1.685, Test loss: 1.714, Test accuracy: 74.68
Round  61, Global train loss: 1.685, Global test loss: 1.710, Global test accuracy: 75.20
Round  62, Train loss: 1.804, Test loss: 1.713, Test accuracy: 74.80
Round  62, Global train loss: 1.804, Global test loss: 1.713, Global test accuracy: 75.00
Round  63, Train loss: 1.803, Test loss: 1.713, Test accuracy: 74.76
Round  63, Global train loss: 1.803, Global test loss: 1.712, Global test accuracy: 74.92
Round  64, Train loss: 1.770, Test loss: 1.713, Test accuracy: 74.78
Round  64, Global train loss: 1.770, Global test loss: 1.711, Global test accuracy: 75.32
Round  65, Train loss: 1.691, Test loss: 1.713, Test accuracy: 74.86
Round  65, Global train loss: 1.691, Global test loss: 1.709, Global test accuracy: 75.16
Round  66, Train loss: 1.706, Test loss: 1.712, Test accuracy: 74.94
Round  66, Global train loss: 1.706, Global test loss: 1.710, Global test accuracy: 75.12
Round  67, Train loss: 1.779, Test loss: 1.713, Test accuracy: 74.80
Round  67, Global train loss: 1.779, Global test loss: 1.712, Global test accuracy: 74.66
Round  68, Train loss: 1.703, Test loss: 1.713, Test accuracy: 74.86
Round  68, Global train loss: 1.703, Global test loss: 1.710, Global test accuracy: 75.16
Round  69, Train loss: 1.713, Test loss: 1.713, Test accuracy: 74.82
Round  69, Global train loss: 1.713, Global test loss: 1.710, Global test accuracy: 74.88
Round  70, Train loss: 1.772, Test loss: 1.713, Test accuracy: 74.64
Round  70, Global train loss: 1.772, Global test loss: 1.712, Global test accuracy: 75.00
Round  71, Train loss: 1.701, Test loss: 1.713, Test accuracy: 74.66
Round  71, Global train loss: 1.701, Global test loss: 1.711, Global test accuracy: 75.16
Round  72, Train loss: 1.688, Test loss: 1.713, Test accuracy: 74.64
Round  72, Global train loss: 1.688, Global test loss: 1.712, Global test accuracy: 74.82
Round  73, Train loss: 1.787, Test loss: 1.713, Test accuracy: 74.66
Round  73, Global train loss: 1.787, Global test loss: 1.713, Global test accuracy: 74.84
Round  74, Train loss: 1.690, Test loss: 1.713, Test accuracy: 74.64
Round  74, Global train loss: 1.690, Global test loss: 1.709, Global test accuracy: 75.08
Round  75, Train loss: 1.790, Test loss: 1.713, Test accuracy: 74.78
Round  75, Global train loss: 1.790, Global test loss: 1.713, Global test accuracy: 74.98
Round  76, Train loss: 1.701, Test loss: 1.713, Test accuracy: 74.84
Round  76, Global train loss: 1.701, Global test loss: 1.710, Global test accuracy: 75.08
Round  77, Train loss: 1.726, Test loss: 1.713, Test accuracy: 74.78
Round  77, Global train loss: 1.726, Global test loss: 1.710, Global test accuracy: 75.20
Round  78, Train loss: 1.721, Test loss: 1.712, Test accuracy: 74.88
Round  78, Global train loss: 1.721, Global test loss: 1.711, Global test accuracy: 75.02
Round  79, Train loss: 1.698, Test loss: 1.712, Test accuracy: 74.84
Round  79, Global train loss: 1.698, Global test loss: 1.710, Global test accuracy: 75.04
Round  80, Train loss: 1.721, Test loss: 1.713, Test accuracy: 74.84
Round  80, Global train loss: 1.721, Global test loss: 1.710, Global test accuracy: 75.44
Round  81, Train loss: 1.790, Test loss: 1.713, Test accuracy: 74.78
Round  81, Global train loss: 1.790, Global test loss: 1.714, Global test accuracy: 74.78
Round  82, Train loss: 1.726, Test loss: 1.713, Test accuracy: 74.88
Round  82, Global train loss: 1.726, Global test loss: 1.710, Global test accuracy: 75.22
Round  83, Train loss: 1.705, Test loss: 1.713, Test accuracy: 74.86
Round  83, Global train loss: 1.705, Global test loss: 1.711, Global test accuracy: 75.26
Round  84, Train loss: 1.726, Test loss: 1.713, Test accuracy: 74.84
Round  84, Global train loss: 1.726, Global test loss: 1.710, Global test accuracy: 75.12
Round  85, Train loss: 1.686, Test loss: 1.712, Test accuracy: 74.88
Round  85, Global train loss: 1.686, Global test loss: 1.708, Global test accuracy: 75.54
Round  86, Train loss: 1.766, Test loss: 1.712, Test accuracy: 75.04
Round  86, Global train loss: 1.766, Global test loss: 1.711, Global test accuracy: 74.94
Round  87, Train loss: 1.799, Test loss: 1.712, Test accuracy: 74.98
Round  87, Global train loss: 1.799, Global test loss: 1.712, Global test accuracy: 74.82
Round  88, Train loss: 1.790, Test loss: 1.712, Test accuracy: 74.94
Round  88, Global train loss: 1.790, Global test loss: 1.712, Global test accuracy: 74.70
Round  89, Train loss: 1.685, Test loss: 1.712, Test accuracy: 74.94
Round  89, Global train loss: 1.685, Global test loss: 1.708, Global test accuracy: 75.24
Round  90, Train loss: 1.711, Test loss: 1.712, Test accuracy: 74.90
Round  90, Global train loss: 1.711, Global test loss: 1.709, Global test accuracy: 75.28
Round  91, Train loss: 1.788, Test loss: 1.712, Test accuracy: 74.88
Round  91, Global train loss: 1.788, Global test loss: 1.711, Global test accuracy: 74.94
Round  92, Train loss: 1.787, Test loss: 1.712, Test accuracy: 74.86
Round  92, Global train loss: 1.787, Global test loss: 1.712, Global test accuracy: 74.96
Round  93, Train loss: 1.687, Test loss: 1.712, Test accuracy: 74.80
Round  93, Global train loss: 1.687, Global test loss: 1.710, Global test accuracy: 74.94
Round  94, Train loss: 1.783, Test loss: 1.712, Test accuracy: 74.80
Round  94, Global train loss: 1.783, Global test loss: 1.712, Global test accuracy: 74.80
Round  95, Train loss: 1.788, Test loss: 1.712, Test accuracy: 74.64
Round  95, Global train loss: 1.788, Global test loss: 1.713, Global test accuracy: 74.52/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 1.725, Test loss: 1.712, Test accuracy: 74.70
Round  96, Global train loss: 1.725, Global test loss: 1.710, Global test accuracy: 75.12
Round  97, Train loss: 1.765, Test loss: 1.712, Test accuracy: 74.74
Round  97, Global train loss: 1.765, Global test loss: 1.713, Global test accuracy: 74.84
Round  98, Train loss: 1.865, Test loss: 1.712, Test accuracy: 74.76
Round  98, Global train loss: 1.865, Global test loss: 1.717, Global test accuracy: 74.28
Round  99, Train loss: 1.766, Test loss: 1.713, Test accuracy: 74.62
Round  99, Global train loss: 1.766, Global test loss: 1.714, Global test accuracy: 74.52
Final Round, Train loss: 1.745, Test loss: 1.714, Test accuracy: 74.50
Final Round, Global train loss: 1.745, Global test loss: 1.714, Global test accuracy: 74.52
Average accuracy final 10 rounds: 74.77 

Average global accuracy final 10 rounds: 74.82 

522.997789144516
[0.7982409000396729, 1.5964818000793457, 2.3148910999298096, 3.0333003997802734, 3.7778208255767822, 4.522341251373291, 5.245478868484497, 5.968616485595703, 6.707180976867676, 7.445745468139648, 8.181331872940063, 8.916918277740479, 9.663434982299805, 10.40995168685913, 11.15635371208191, 11.902755737304688, 12.632396697998047, 13.362037658691406, 14.100415229797363, 14.83879280090332, 15.556474447250366, 16.274156093597412, 17.018840789794922, 17.76352548599243, 18.474863052368164, 19.186200618743896, 19.924253940582275, 20.662307262420654, 21.397064924240112, 22.13182258605957, 22.863789796829224, 23.595757007598877, 24.34116268157959, 25.086568355560303, 25.79848623275757, 26.510404109954834, 27.23552632331848, 27.96064853668213, 28.66832160949707, 29.37599468231201, 30.105047464370728, 30.834100246429443, 31.540772914886475, 32.247445583343506, 32.98189687728882, 33.71634817123413, 34.44103169441223, 35.16571521759033, 35.89431619644165, 36.62291717529297, 37.36158204078674, 38.10024690628052, 38.81487154960632, 39.52949619293213, 40.259170055389404, 40.98884391784668, 41.69732451438904, 42.4058051109314, 43.12862300872803, 43.85144090652466, 44.557616233825684, 45.26379156112671, 45.994359731674194, 46.72492790222168, 47.45123243331909, 48.177536964416504, 48.90784740447998, 49.63815784454346, 50.37780141830444, 51.11744499206543, 51.82996392250061, 52.54248285293579, 53.26242160797119, 53.98236036300659, 54.68966841697693, 55.396976470947266, 56.128148794174194, 56.85932111740112, 57.57110071182251, 58.2828803062439, 59.01251435279846, 59.74214839935303, 60.47299098968506, 61.20383358001709, 61.926684856414795, 62.6495361328125, 63.38589811325073, 64.12226009368896, 64.83083820343018, 65.53941631317139, 66.27167177200317, 67.00392723083496, 67.71929144859314, 68.43465566635132, 69.17825841903687, 69.92186117172241, 70.63864517211914, 71.35542917251587, 72.10114192962646, 72.84685468673706, 73.58598375320435, 74.32511281967163, 75.06261777877808, 75.80012273788452, 76.53301453590393, 77.26590633392334, 77.97920680046082, 78.69250726699829, 79.43122601509094, 80.1699447631836, 80.88663911819458, 81.60333347320557, 82.34067630767822, 83.07801914215088, 83.81516551971436, 84.55231189727783, 85.28127241134644, 86.01023292541504, 86.74527382850647, 87.4803147315979, 88.22002100944519, 88.95972728729248, 89.69684386253357, 90.43396043777466, 91.15200352668762, 91.87004661560059, 92.60234308242798, 93.33463954925537, 94.05280995368958, 94.77098035812378, 95.50658392906189, 96.2421875, 96.98144745826721, 97.72070741653442, 98.43403029441833, 99.14735317230225, 99.862539768219, 100.57772636413574, 101.31608533859253, 102.05444431304932, 102.7941153049469, 103.53378629684448, 104.24616074562073, 104.95853519439697, 105.67227482795715, 106.38601446151733, 107.05745124816895, 107.72888803482056, 108.43195629119873, 109.1350245475769, 109.8393988609314, 110.54377317428589, 111.24841642379761, 111.95305967330933, 112.65766072273254, 113.36226177215576, 114.07706212997437, 114.79186248779297, 115.5072832107544, 116.22270393371582, 116.93424987792969, 117.64579582214355, 118.3559079170227, 119.06602001190186, 119.77353882789612, 120.48105764389038, 121.19135975837708, 121.90166187286377, 122.61063885688782, 123.31961584091187, 124.03034853935242, 124.74108123779297, 125.43547177314758, 126.1298623085022, 126.82294368743896, 127.51602506637573, 128.21259307861328, 128.90916109085083, 129.60444593429565, 130.29973077774048, 130.99851822853088, 131.6973056793213, 132.40062975883484, 133.1039538383484, 133.80705881118774, 134.5101637840271, 135.21299958229065, 135.9158353805542, 136.61655044555664, 137.31726551055908, 138.01778054237366, 138.71829557418823, 139.42046785354614, 140.12264013290405, 140.8223750591278, 141.52210998535156, 142.22620820999146, 142.93030643463135, 143.63160729408264, 144.33290815353394, 145.73502039909363, 147.13713264465332]
[27.2, 27.2, 36.26, 36.26, 37.64, 37.64, 33.98, 33.98, 42.84, 42.84, 48.08, 48.08, 54.66, 54.66, 56.94, 56.94, 62.02, 62.02, 64.68, 64.68, 68.48, 68.48, 69.18, 69.18, 71.96, 71.96, 73.08, 73.08, 73.16, 73.16, 73.56, 73.56, 73.52, 73.52, 73.64, 73.64, 73.84, 73.84, 74.02, 74.02, 74.04, 74.04, 73.98, 73.98, 73.92, 73.92, 74.22, 74.22, 74.56, 74.56, 74.46, 74.46, 74.48, 74.48, 74.38, 74.38, 74.4, 74.4, 74.5, 74.5, 74.48, 74.48, 74.34, 74.34, 74.24, 74.24, 74.18, 74.18, 74.2, 74.2, 74.16, 74.16, 74.08, 74.08, 74.26, 74.26, 74.3, 74.3, 74.32, 74.32, 74.36, 74.36, 74.46, 74.46, 74.52, 74.52, 74.56, 74.56, 74.58, 74.58, 74.56, 74.56, 74.6, 74.6, 74.68, 74.68, 74.76, 74.76, 74.82, 74.82, 74.88, 74.88, 74.9, 74.9, 74.86, 74.86, 74.84, 74.84, 74.74, 74.74, 74.64, 74.64, 74.72, 74.72, 74.64, 74.64, 74.62, 74.62, 74.68, 74.68, 74.7, 74.7, 74.68, 74.68, 74.8, 74.8, 74.76, 74.76, 74.78, 74.78, 74.86, 74.86, 74.94, 74.94, 74.8, 74.8, 74.86, 74.86, 74.82, 74.82, 74.64, 74.64, 74.66, 74.66, 74.64, 74.64, 74.66, 74.66, 74.64, 74.64, 74.78, 74.78, 74.84, 74.84, 74.78, 74.78, 74.88, 74.88, 74.84, 74.84, 74.84, 74.84, 74.78, 74.78, 74.88, 74.88, 74.86, 74.86, 74.84, 74.84, 74.88, 74.88, 75.04, 75.04, 74.98, 74.98, 74.94, 74.94, 74.94, 74.94, 74.9, 74.9, 74.88, 74.88, 74.86, 74.86, 74.8, 74.8, 74.8, 74.8, 74.64, 74.64, 74.7, 74.7, 74.74, 74.74, 74.76, 74.76, 74.62, 74.62, 74.5, 74.5]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.2 , level_n_lowerb:0.4  

   Client 2, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
prox
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.301, Test loss: 2.301, Test accuracy: 17.22
Round   0, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 17.18
Round   1, Train loss: 2.299, Test loss: 2.299, Test accuracy: 20.66
Round   1, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 22.34
Round   2, Train loss: 2.296, Test loss: 2.296, Test accuracy: 22.72
Round   2, Global train loss: 2.296, Global test loss: 2.295, Global test accuracy: 23.70
Round   3, Train loss: 2.291, Test loss: 2.290, Test accuracy: 23.26
Round   3, Global train loss: 2.291, Global test loss: 2.286, Global test accuracy: 23.18
Round   4, Train loss: 2.271, Test loss: 2.271, Test accuracy: 23.12
Round   4, Global train loss: 2.271, Global test loss: 2.247, Global test accuracy: 23.06
Round   5, Train loss: 2.191, Test loss: 2.236, Test accuracy: 25.00
Round   5, Global train loss: 2.191, Global test loss: 2.149, Global test accuracy: 28.86
Round   6, Train loss: 2.149, Test loss: 2.192, Test accuracy: 28.26
Round   6, Global train loss: 2.149, Global test loss: 2.099, Global test accuracy: 33.14
Round   7, Train loss: 2.096, Test loss: 2.142, Test accuracy: 34.62
Round   7, Global train loss: 2.096, Global test loss: 2.009, Global test accuracy: 52.80
Round   8, Train loss: 1.944, Test loss: 2.072, Test accuracy: 42.42
Round   8, Global train loss: 1.944, Global test loss: 1.901, Global test accuracy: 60.06
Round   9, Train loss: 1.842, Test loss: 2.014, Test accuracy: 48.52
Round   9, Global train loss: 1.842, Global test loss: 1.833, Global test accuracy: 65.06
Round  10, Train loss: 1.816, Test loss: 1.949, Test accuracy: 54.74
Round  10, Global train loss: 1.816, Global test loss: 1.753, Global test accuracy: 75.38
Round  11, Train loss: 1.794, Test loss: 1.894, Test accuracy: 60.76
Round  11, Global train loss: 1.794, Global test loss: 1.714, Global test accuracy: 78.26
Round  12, Train loss: 1.806, Test loss: 1.835, Test accuracy: 65.96
Round  12, Global train loss: 1.806, Global test loss: 1.702, Global test accuracy: 78.58
Round  13, Train loss: 1.792, Test loss: 1.757, Test accuracy: 73.54
Round  13, Global train loss: 1.792, Global test loss: 1.687, Global test accuracy: 78.58
Round  14, Train loss: 1.813, Test loss: 1.730, Test accuracy: 75.58
Round  14, Global train loss: 1.813, Global test loss: 1.682, Global test accuracy: 79.74
Round  15, Train loss: 1.651, Test loss: 1.697, Test accuracy: 78.40
Round  15, Global train loss: 1.651, Global test loss: 1.668, Global test accuracy: 80.72
Round  16, Train loss: 1.722, Test loss: 1.692, Test accuracy: 78.76
Round  16, Global train loss: 1.722, Global test loss: 1.664, Global test accuracy: 81.42
Round  17, Train loss: 1.752, Test loss: 1.689, Test accuracy: 79.10
Round  17, Global train loss: 1.752, Global test loss: 1.662, Global test accuracy: 81.14
Round  18, Train loss: 1.617, Test loss: 1.682, Test accuracy: 79.42
Round  18, Global train loss: 1.617, Global test loss: 1.657, Global test accuracy: 81.30
Round  19, Train loss: 1.716, Test loss: 1.681, Test accuracy: 79.42
Round  19, Global train loss: 1.716, Global test loss: 1.655, Global test accuracy: 81.48
Round  20, Train loss: 1.812, Test loss: 1.679, Test accuracy: 79.58
Round  20, Global train loss: 1.812, Global test loss: 1.655, Global test accuracy: 81.50
Round  21, Train loss: 1.634, Test loss: 1.677, Test accuracy: 79.72
Round  21, Global train loss: 1.634, Global test loss: 1.649, Global test accuracy: 81.90
Round  22, Train loss: 1.639, Test loss: 1.673, Test accuracy: 79.84
Round  22, Global train loss: 1.639, Global test loss: 1.647, Global test accuracy: 82.00
Round  23, Train loss: 1.731, Test loss: 1.668, Test accuracy: 80.24
Round  23, Global train loss: 1.731, Global test loss: 1.649, Global test accuracy: 81.86
Round  24, Train loss: 1.696, Test loss: 1.656, Test accuracy: 81.22
Round  24, Global train loss: 1.696, Global test loss: 1.647, Global test accuracy: 82.22
Round  25, Train loss: 1.653, Test loss: 1.653, Test accuracy: 81.38
Round  25, Global train loss: 1.653, Global test loss: 1.645, Global test accuracy: 81.80
Round  26, Train loss: 1.693, Test loss: 1.652, Test accuracy: 81.58
Round  26, Global train loss: 1.693, Global test loss: 1.644, Global test accuracy: 82.22
Round  27, Train loss: 1.653, Test loss: 1.651, Test accuracy: 81.64
Round  27, Global train loss: 1.653, Global test loss: 1.645, Global test accuracy: 81.78
Round  28, Train loss: 1.682, Test loss: 1.650, Test accuracy: 81.62
Round  28, Global train loss: 1.682, Global test loss: 1.642, Global test accuracy: 82.12
Round  29, Train loss: 1.631, Test loss: 1.650, Test accuracy: 81.68
Round  29, Global train loss: 1.631, Global test loss: 1.644, Global test accuracy: 81.96
Round  30, Train loss: 1.726, Test loss: 1.649, Test accuracy: 81.64
Round  30, Global train loss: 1.726, Global test loss: 1.642, Global test accuracy: 82.22
Round  31, Train loss: 1.618, Test loss: 1.649, Test accuracy: 81.74
Round  31, Global train loss: 1.618, Global test loss: 1.641, Global test accuracy: 82.10
Round  32, Train loss: 1.711, Test loss: 1.648, Test accuracy: 81.88
Round  32, Global train loss: 1.711, Global test loss: 1.641, Global test accuracy: 82.26
Round  33, Train loss: 1.728, Test loss: 1.647, Test accuracy: 81.86
Round  33, Global train loss: 1.728, Global test loss: 1.641, Global test accuracy: 82.20
Round  34, Train loss: 1.654, Test loss: 1.647, Test accuracy: 81.98
Round  34, Global train loss: 1.654, Global test loss: 1.643, Global test accuracy: 81.82
Round  35, Train loss: 1.579, Test loss: 1.646, Test accuracy: 82.02
Round  35, Global train loss: 1.579, Global test loss: 1.637, Global test accuracy: 82.66
Round  36, Train loss: 1.698, Test loss: 1.645, Test accuracy: 82.06
Round  36, Global train loss: 1.698, Global test loss: 1.639, Global test accuracy: 82.68
Round  37, Train loss: 1.573, Test loss: 1.645, Test accuracy: 81.98
Round  37, Global train loss: 1.573, Global test loss: 1.637, Global test accuracy: 82.56
Round  38, Train loss: 1.616, Test loss: 1.644, Test accuracy: 82.04
Round  38, Global train loss: 1.616, Global test loss: 1.639, Global test accuracy: 82.08
Round  39, Train loss: 1.784, Test loss: 1.645, Test accuracy: 81.98
Round  39, Global train loss: 1.784, Global test loss: 1.643, Global test accuracy: 81.94
Round  40, Train loss: 1.716, Test loss: 1.645, Test accuracy: 81.96
Round  40, Global train loss: 1.716, Global test loss: 1.639, Global test accuracy: 82.04
Round  41, Train loss: 1.779, Test loss: 1.643, Test accuracy: 81.98
Round  41, Global train loss: 1.779, Global test loss: 1.643, Global test accuracy: 82.20
Round  42, Train loss: 1.755, Test loss: 1.645, Test accuracy: 81.78
Round  42, Global train loss: 1.755, Global test loss: 1.643, Global test accuracy: 81.76
Round  43, Train loss: 1.680, Test loss: 1.645, Test accuracy: 81.80
Round  43, Global train loss: 1.680, Global test loss: 1.641, Global test accuracy: 82.20
Round  44, Train loss: 1.611, Test loss: 1.645, Test accuracy: 81.78
Round  44, Global train loss: 1.611, Global test loss: 1.638, Global test accuracy: 82.30
Round  45, Train loss: 1.647, Test loss: 1.645, Test accuracy: 81.70
Round  45, Global train loss: 1.647, Global test loss: 1.637, Global test accuracy: 82.42
Round  46, Train loss: 1.685, Test loss: 1.644, Test accuracy: 81.66
Round  46, Global train loss: 1.685, Global test loss: 1.638, Global test accuracy: 82.08
Round  47, Train loss: 1.724, Test loss: 1.642, Test accuracy: 81.86
Round  47, Global train loss: 1.724, Global test loss: 1.639, Global test accuracy: 82.26
Round  48, Train loss: 1.688, Test loss: 1.642, Test accuracy: 81.88
Round  48, Global train loss: 1.688, Global test loss: 1.640, Global test accuracy: 82.00
Round  49, Train loss: 1.700, Test loss: 1.641, Test accuracy: 81.90
Round  49, Global train loss: 1.700, Global test loss: 1.639, Global test accuracy: 82.28
Round  50, Train loss: 1.702, Test loss: 1.641, Test accuracy: 81.98
Round  50, Global train loss: 1.702, Global test loss: 1.638, Global test accuracy: 82.20
Round  51, Train loss: 1.723, Test loss: 1.640, Test accuracy: 82.08
Round  51, Global train loss: 1.723, Global test loss: 1.639, Global test accuracy: 82.10
Round  52, Train loss: 1.576, Test loss: 1.641, Test accuracy: 81.92
Round  52, Global train loss: 1.576, Global test loss: 1.638, Global test accuracy: 82.12
Round  53, Train loss: 1.738, Test loss: 1.640, Test accuracy: 82.06
Round  53, Global train loss: 1.738, Global test loss: 1.642, Global test accuracy: 82.14
Round  54, Train loss: 1.692, Test loss: 1.640, Test accuracy: 82.06
Round  54, Global train loss: 1.692, Global test loss: 1.639, Global test accuracy: 82.30
Round  55, Train loss: 1.620, Test loss: 1.640, Test accuracy: 82.12
Round  55, Global train loss: 1.620, Global test loss: 1.639, Global test accuracy: 82.44
Round  56, Train loss: 1.736, Test loss: 1.640, Test accuracy: 82.16
Round  56, Global train loss: 1.736, Global test loss: 1.642, Global test accuracy: 81.98
Round  57, Train loss: 1.721, Test loss: 1.640, Test accuracy: 82.14
Round  57, Global train loss: 1.721, Global test loss: 1.640, Global test accuracy: 81.96
Round  58, Train loss: 1.601, Test loss: 1.640, Test accuracy: 82.08
Round  58, Global train loss: 1.601, Global test loss: 1.639, Global test accuracy: 82.24
Round  59, Train loss: 1.619, Test loss: 1.640, Test accuracy: 82.02
Round  59, Global train loss: 1.619, Global test loss: 1.638, Global test accuracy: 82.04
Round  60, Train loss: 1.664, Test loss: 1.640, Test accuracy: 82.06
Round  60, Global train loss: 1.664, Global test loss: 1.638, Global test accuracy: 82.40
Round  61, Train loss: 1.585, Test loss: 1.640, Test accuracy: 82.16
Round  61, Global train loss: 1.585, Global test loss: 1.637, Global test accuracy: 82.56
Round  62, Train loss: 1.644, Test loss: 1.639, Test accuracy: 82.12
Round  62, Global train loss: 1.644, Global test loss: 1.636, Global test accuracy: 82.30
Round  63, Train loss: 1.741, Test loss: 1.640, Test accuracy: 82.16
Round  63, Global train loss: 1.741, Global test loss: 1.641, Global test accuracy: 81.86
Round  64, Train loss: 1.624, Test loss: 1.640, Test accuracy: 82.12
Round  64, Global train loss: 1.624, Global test loss: 1.638, Global test accuracy: 82.28
Round  65, Train loss: 1.727, Test loss: 1.640, Test accuracy: 82.12
Round  65, Global train loss: 1.727, Global test loss: 1.643, Global test accuracy: 81.82
Round  66, Train loss: 1.707, Test loss: 1.640, Test accuracy: 82.08
Round  66, Global train loss: 1.707, Global test loss: 1.642, Global test accuracy: 82.04
Round  67, Train loss: 1.649, Test loss: 1.641, Test accuracy: 81.96
Round  67, Global train loss: 1.649, Global test loss: 1.640, Global test accuracy: 82.34
Round  68, Train loss: 1.833, Test loss: 1.640, Test accuracy: 82.08
Round  68, Global train loss: 1.833, Global test loss: 1.643, Global test accuracy: 81.94
Round  69, Train loss: 1.750, Test loss: 1.640, Test accuracy: 82.00
Round  69, Global train loss: 1.750, Global test loss: 1.642, Global test accuracy: 82.18
Round  70, Train loss: 1.761, Test loss: 1.641, Test accuracy: 81.96
Round  70, Global train loss: 1.761, Global test loss: 1.641, Global test accuracy: 81.94
Round  71, Train loss: 1.769, Test loss: 1.640, Test accuracy: 81.96
Round  71, Global train loss: 1.769, Global test loss: 1.639, Global test accuracy: 82.26
Round  72, Train loss: 1.707, Test loss: 1.640, Test accuracy: 81.96
Round  72, Global train loss: 1.707, Global test loss: 1.637, Global test accuracy: 81.96
Round  73, Train loss: 1.613, Test loss: 1.640, Test accuracy: 82.00
Round  73, Global train loss: 1.613, Global test loss: 1.636, Global test accuracy: 82.18
Round  74, Train loss: 1.617, Test loss: 1.639, Test accuracy: 82.10
Round  74, Global train loss: 1.617, Global test loss: 1.638, Global test accuracy: 82.42
Round  75, Train loss: 1.707, Test loss: 1.639, Test accuracy: 82.10
Round  75, Global train loss: 1.707, Global test loss: 1.639, Global test accuracy: 82.24
Round  76, Train loss: 1.767, Test loss: 1.639, Test accuracy: 82.10
Round  76, Global train loss: 1.767, Global test loss: 1.638, Global test accuracy: 82.44
Round  77, Train loss: 1.713, Test loss: 1.639, Test accuracy: 82.08
Round  77, Global train loss: 1.713, Global test loss: 1.639, Global test accuracy: 82.28
Round  78, Train loss: 1.679, Test loss: 1.639, Test accuracy: 82.12
Round  78, Global train loss: 1.679, Global test loss: 1.637, Global test accuracy: 82.18
Round  79, Train loss: 1.751, Test loss: 1.639, Test accuracy: 82.18
Round  79, Global train loss: 1.751, Global test loss: 1.643, Global test accuracy: 81.80
Round  80, Train loss: 1.634, Test loss: 1.639, Test accuracy: 82.18
Round  80, Global train loss: 1.634, Global test loss: 1.640, Global test accuracy: 82.18
Round  81, Train loss: 1.671, Test loss: 1.639, Test accuracy: 82.14
Round  81, Global train loss: 1.671, Global test loss: 1.639, Global test accuracy: 82.16
Round  82, Train loss: 1.775, Test loss: 1.639, Test accuracy: 82.16
Round  82, Global train loss: 1.775, Global test loss: 1.643, Global test accuracy: 81.84
Round  83, Train loss: 1.715, Test loss: 1.639, Test accuracy: 82.20
Round  83, Global train loss: 1.715, Global test loss: 1.640, Global test accuracy: 82.36
Round  84, Train loss: 1.774, Test loss: 1.639, Test accuracy: 82.18
Round  84, Global train loss: 1.774, Global test loss: 1.644, Global test accuracy: 81.94
Round  85, Train loss: 1.758, Test loss: 1.640, Test accuracy: 82.18
Round  85, Global train loss: 1.758, Global test loss: 1.642, Global test accuracy: 81.74
Round  86, Train loss: 1.680, Test loss: 1.640, Test accuracy: 82.14
Round  86, Global train loss: 1.680, Global test loss: 1.641, Global test accuracy: 81.76
Round  87, Train loss: 1.735, Test loss: 1.640, Test accuracy: 82.16
Round  87, Global train loss: 1.735, Global test loss: 1.641, Global test accuracy: 82.28
Round  88, Train loss: 1.708, Test loss: 1.640, Test accuracy: 82.16
Round  88, Global train loss: 1.708, Global test loss: 1.640, Global test accuracy: 82.18
Round  89, Train loss: 1.757, Test loss: 1.640, Test accuracy: 82.18
Round  89, Global train loss: 1.757, Global test loss: 1.641, Global test accuracy: 81.96
Round  90, Train loss: 1.606, Test loss: 1.640, Test accuracy: 82.16
Round  90, Global train loss: 1.606, Global test loss: 1.639, Global test accuracy: 82.16
Round  91, Train loss: 1.601, Test loss: 1.640, Test accuracy: 82.16
Round  91, Global train loss: 1.601, Global test loss: 1.638, Global test accuracy: 82.22
Round  92, Train loss: 1.705, Test loss: 1.640, Test accuracy: 82.16
Round  92, Global train loss: 1.705, Global test loss: 1.640, Global test accuracy: 82.16
Round  93, Train loss: 1.705, Test loss: 1.640, Test accuracy: 82.12
Round  93, Global train loss: 1.705, Global test loss: 1.637, Global test accuracy: 82.32
Round  94, Train loss: 1.567, Test loss: 1.639, Test accuracy: 82.04
Round  94, Global train loss: 1.567, Global test loss: 1.636, Global test accuracy: 82.38
Round  95, Train loss: 1.707, Test loss: 1.639, Test accuracy: 82.08
Round  95, Global train loss: 1.707, Global test loss: 1.639, Global test accuracy: 82.28/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  96, Train loss: 1.774, Test loss: 1.639, Test accuracy: 82.04
Round  96, Global train loss: 1.774, Global test loss: 1.642, Global test accuracy: 81.80
Round  97, Train loss: 1.664, Test loss: 1.640, Test accuracy: 82.04
Round  97, Global train loss: 1.664, Global test loss: 1.637, Global test accuracy: 82.40
Round  98, Train loss: 1.567, Test loss: 1.639, Test accuracy: 82.06
Round  98, Global train loss: 1.567, Global test loss: 1.636, Global test accuracy: 82.10
Round  99, Train loss: 1.582, Test loss: 1.639, Test accuracy: 81.98
Round  99, Global train loss: 1.582, Global test loss: 1.637, Global test accuracy: 81.92
Final Round, Train loss: 1.671, Test loss: 1.639, Test accuracy: 82.16
Final Round, Global train loss: 1.671, Global test loss: 1.637, Global test accuracy: 81.92
Average accuracy final 10 rounds: 82.084 

Average global accuracy final 10 rounds: 82.17399999999998 

529.7923109531403
[0.8625447750091553, 1.7250895500183105, 2.5051541328430176, 3.2852187156677246, 4.064029932022095, 4.842841148376465, 5.624409914016724, 6.405978679656982, 7.183879613876343, 7.961780548095703, 8.741363525390625, 9.520946502685547, 10.301735877990723, 11.082525253295898, 11.863123893737793, 12.643722534179688, 13.426733493804932, 14.209744453430176, 14.993837118148804, 15.777929782867432, 16.558871269226074, 17.339812755584717, 18.123937845230103, 18.90806293487549, 19.686410427093506, 20.464757919311523, 21.245034217834473, 22.025310516357422, 22.800853967666626, 23.57639741897583, 24.356924057006836, 25.137450695037842, 25.921248197555542, 26.705045700073242, 27.48330307006836, 28.261560440063477, 29.043583631515503, 29.82560682296753, 30.60453987121582, 31.38347291946411, 32.16446113586426, 32.945449352264404, 33.72605276107788, 34.50665616989136, 35.28338599205017, 36.060115814208984, 36.842018842697144, 37.6239218711853, 38.4024543762207, 39.1809868812561, 39.957266092300415, 40.73354530334473, 41.51345705986023, 42.29336881637573, 43.07650351524353, 43.85963821411133, 44.63913106918335, 45.41862392425537, 46.19610667228699, 46.9735894203186, 47.755104541778564, 48.536619663238525, 49.315537452697754, 50.09445524215698, 50.873745918273926, 51.65303659439087, 52.4340980052948, 53.21515941619873, 53.99578261375427, 54.776405811309814, 55.55336308479309, 56.33032035827637, 57.11450982093811, 57.89869928359985, 58.676684617996216, 59.45466995239258, 60.234469413757324, 61.01426887512207, 61.796013832092285, 62.5777587890625, 63.361300468444824, 64.14484214782715, 64.92343974113464, 65.70203733444214, 66.4805109500885, 67.25898456573486, 68.03652262687683, 68.8140606880188, 69.58820533752441, 70.36234998703003, 71.1389307975769, 71.91551160812378, 72.69801712036133, 73.48052263259888, 74.25886058807373, 75.03719854354858, 75.81545066833496, 76.59370279312134, 77.37093758583069, 78.14817237854004, 78.92760157585144, 79.70703077316284, 80.488516330719, 81.27000188827515, 82.05032658576965, 82.83065128326416, 83.60745096206665, 84.38425064086914, 85.1586549282074, 85.93305921554565, 86.7077989578247, 87.48253870010376, 88.26020646095276, 89.03787422180176, 89.81951332092285, 90.60115242004395, 91.38145184516907, 92.16175127029419, 92.94200348854065, 93.72225570678711, 94.50116658210754, 95.28007745742798, 96.05912256240845, 96.83816766738892, 97.61457633972168, 98.39098501205444, 99.17016649246216, 99.94934797286987, 100.72986197471619, 101.5103759765625, 102.2897744178772, 103.0691728591919, 103.84784746170044, 104.62652206420898, 105.41056180000305, 106.19460153579712, 106.97698187828064, 107.75936222076416, 108.54250693321228, 109.3256516456604, 110.10485506057739, 110.88405847549438, 111.6644561290741, 112.44485378265381, 113.2222900390625, 113.99972629547119, 114.77663087844849, 115.55353546142578, 116.33382940292358, 117.11412334442139, 117.89249277114868, 118.67086219787598, 119.44688057899475, 120.22289896011353, 121.00798845291138, 121.79307794570923, 122.57448196411133, 123.35588598251343, 124.13747954368591, 124.9190731048584, 125.69858479499817, 126.47809648513794, 127.26064133644104, 128.04318618774414, 128.8205177783966, 129.59784936904907, 130.37319827079773, 131.1485471725464, 131.9275062084198, 132.7064652442932, 133.48534393310547, 134.26422262191772, 135.03833317756653, 135.81244373321533, 136.5845081806183, 137.35657262802124, 138.13308811187744, 138.90960359573364, 139.57215070724487, 140.2346978187561, 140.90987372398376, 141.58504962921143, 142.25712037086487, 142.9291911125183, 143.6020383834839, 144.27488565444946, 144.94785165786743, 145.6208176612854, 146.29570388793945, 146.9705901145935, 147.63849067687988, 148.30639123916626, 148.97972774505615, 149.65306425094604, 150.32709455490112, 151.0011248588562, 151.67301607131958, 152.34490728378296, 153.01933979988098, 153.693772315979, 155.03248524665833, 156.37119817733765]
[17.22, 17.22, 20.66, 20.66, 22.72, 22.72, 23.26, 23.26, 23.12, 23.12, 25.0, 25.0, 28.26, 28.26, 34.62, 34.62, 42.42, 42.42, 48.52, 48.52, 54.74, 54.74, 60.76, 60.76, 65.96, 65.96, 73.54, 73.54, 75.58, 75.58, 78.4, 78.4, 78.76, 78.76, 79.1, 79.1, 79.42, 79.42, 79.42, 79.42, 79.58, 79.58, 79.72, 79.72, 79.84, 79.84, 80.24, 80.24, 81.22, 81.22, 81.38, 81.38, 81.58, 81.58, 81.64, 81.64, 81.62, 81.62, 81.68, 81.68, 81.64, 81.64, 81.74, 81.74, 81.88, 81.88, 81.86, 81.86, 81.98, 81.98, 82.02, 82.02, 82.06, 82.06, 81.98, 81.98, 82.04, 82.04, 81.98, 81.98, 81.96, 81.96, 81.98, 81.98, 81.78, 81.78, 81.8, 81.8, 81.78, 81.78, 81.7, 81.7, 81.66, 81.66, 81.86, 81.86, 81.88, 81.88, 81.9, 81.9, 81.98, 81.98, 82.08, 82.08, 81.92, 81.92, 82.06, 82.06, 82.06, 82.06, 82.12, 82.12, 82.16, 82.16, 82.14, 82.14, 82.08, 82.08, 82.02, 82.02, 82.06, 82.06, 82.16, 82.16, 82.12, 82.12, 82.16, 82.16, 82.12, 82.12, 82.12, 82.12, 82.08, 82.08, 81.96, 81.96, 82.08, 82.08, 82.0, 82.0, 81.96, 81.96, 81.96, 81.96, 81.96, 81.96, 82.0, 82.0, 82.1, 82.1, 82.1, 82.1, 82.1, 82.1, 82.08, 82.08, 82.12, 82.12, 82.18, 82.18, 82.18, 82.18, 82.14, 82.14, 82.16, 82.16, 82.2, 82.2, 82.18, 82.18, 82.18, 82.18, 82.14, 82.14, 82.16, 82.16, 82.16, 82.16, 82.18, 82.18, 82.16, 82.16, 82.16, 82.16, 82.16, 82.16, 82.12, 82.12, 82.04, 82.04, 82.08, 82.08, 82.04, 82.04, 82.04, 82.04, 82.06, 82.06, 81.98, 81.98, 82.16, 82.16]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.2 , level_n_lowerb:0.4  

   Client 8, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Traceback (most recent call last):
  File "main_fedpac_co_teaching.py", line 250, in <module>
    local.filter_data(net=net_local.to(args.device), net2=net_local2.to(args.device), concept_matrix_local = concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1587, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

   Client 4, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.324, Test loss: 2.301, Test accuracy: 13.20
Round   0, Global train loss: 2.324, Global test loss: 2.301, Global test accuracy: 13.20
Round   1, Train loss: 2.300, Test loss: 2.299, Test accuracy: 17.00
Round   1, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 16.84
Round   2, Train loss: 2.298, Test loss: 2.296, Test accuracy: 21.90
Round   2, Global train loss: 2.298, Global test loss: 2.296, Global test accuracy: 21.88
Round   3, Train loss: 2.295, Test loss: 2.292, Test accuracy: 33.62
Round   3, Global train loss: 2.295, Global test loss: 2.292, Global test accuracy: 34.36
Round   4, Train loss: 2.290, Test loss: 2.285, Test accuracy: 44.16
Round   4, Global train loss: 2.290, Global test loss: 2.285, Global test accuracy: 44.22
Round   5, Train loss: 2.290, Test loss: 2.279, Test accuracy: 44.42
Round   5, Global train loss: 2.290, Global test loss: 2.279, Global test accuracy: 43.38
Round   6, Train loss: 2.280, Test loss: 2.266, Test accuracy: 44.40
Round   6, Global train loss: 2.280, Global test loss: 2.264, Global test accuracy: 43.80
Round   7, Train loss: 2.256, Test loss: 2.222, Test accuracy: 44.90
Round   7, Global train loss: 2.256, Global test loss: 2.216, Global test accuracy: 44.28
Round   8, Train loss: 2.202, Test loss: 2.145, Test accuracy: 45.52
Round   8, Global train loss: 2.202, Global test loss: 2.124, Global test accuracy: 42.32
Round   9, Train loss: 2.133, Test loss: 2.075, Test accuracy: 48.80
Round   9, Global train loss: 2.133, Global test loss: 2.049, Global test accuracy: 47.24
Round  10, Train loss: 2.036, Test loss: 2.007, Test accuracy: 53.78
Round  10, Global train loss: 2.036, Global test loss: 1.975, Global test accuracy: 52.62
Round  11, Train loss: 2.005, Test loss: 1.961, Test accuracy: 58.02
Round  11, Global train loss: 2.005, Global test loss: 1.931, Global test accuracy: 58.38
Round  12, Train loss: 1.900, Test loss: 1.910, Test accuracy: 62.26
Round  12, Global train loss: 1.900, Global test loss: 1.873, Global test accuracy: 65.62
Round  13, Train loss: 1.992, Test loss: 1.882, Test accuracy: 64.84
Round  13, Global train loss: 1.992, Global test loss: 1.868, Global test accuracy: 66.78
Round  14, Train loss: 1.869, Test loss: 1.850, Test accuracy: 68.62
Round  14, Global train loss: 1.869, Global test loss: 1.821, Global test accuracy: 71.88
Round  15, Train loss: 1.838, Test loss: 1.821, Test accuracy: 70.94
Round  15, Global train loss: 1.838, Global test loss: 1.797, Global test accuracy: 73.10
Round  16, Train loss: 1.827, Test loss: 1.803, Test accuracy: 72.30
Round  16, Global train loss: 1.827, Global test loss: 1.780, Global test accuracy: 74.18
Round  17, Train loss: 1.807, Test loss: 1.791, Test accuracy: 72.76
Round  17, Global train loss: 1.807, Global test loss: 1.768, Global test accuracy: 74.42
Round  18, Train loss: 1.861, Test loss: 1.785, Test accuracy: 73.54
Round  18, Global train loss: 1.861, Global test loss: 1.764, Global test accuracy: 73.96
Round  19, Train loss: 1.890, Test loss: 1.781, Test accuracy: 73.54
Round  19, Global train loss: 1.890, Global test loss: 1.768, Global test accuracy: 74.24
Round  20, Train loss: 1.775, Test loss: 1.772, Test accuracy: 73.86
Round  20, Global train loss: 1.775, Global test loss: 1.751, Global test accuracy: 74.46
Round  21, Train loss: 1.879, Test loss: 1.770, Test accuracy: 74.26
Round  21, Global train loss: 1.879, Global test loss: 1.755, Global test accuracy: 74.76
Round  22, Train loss: 1.886, Test loss: 1.765, Test accuracy: 75.12
Round  22, Global train loss: 1.886, Global test loss: 1.753, Global test accuracy: 76.22
Round  23, Train loss: 1.854, Test loss: 1.757, Test accuracy: 76.10
Round  23, Global train loss: 1.854, Global test loss: 1.745, Global test accuracy: 76.62
Round  24, Train loss: 1.767, Test loss: 1.737, Test accuracy: 78.38
Round  24, Global train loss: 1.767, Global test loss: 1.719, Global test accuracy: 80.52
Round  25, Train loss: 1.838, Test loss: 1.725, Test accuracy: 80.30
Round  25, Global train loss: 1.838, Global test loss: 1.719, Global test accuracy: 81.26
Round  26, Train loss: 1.676, Test loss: 1.710, Test accuracy: 81.38
Round  26, Global train loss: 1.676, Global test loss: 1.685, Global test accuracy: 82.10
Round  27, Train loss: 1.702, Test loss: 1.695, Test accuracy: 82.36
Round  27, Global train loss: 1.702, Global test loss: 1.678, Global test accuracy: 81.94
Round  28, Train loss: 1.798, Test loss: 1.686, Test accuracy: 84.26
Round  28, Global train loss: 1.798, Global test loss: 1.669, Global test accuracy: 86.76
Round  29, Train loss: 1.649, Test loss: 1.677, Test accuracy: 85.48
Round  29, Global train loss: 1.649, Global test loss: 1.641, Global test accuracy: 87.98
Round  30, Train loss: 1.789, Test loss: 1.664, Test accuracy: 87.02
Round  30, Global train loss: 1.789, Global test loss: 1.646, Global test accuracy: 90.18
Round  31, Train loss: 1.783, Test loss: 1.662, Test accuracy: 87.68
Round  31, Global train loss: 1.783, Global test loss: 1.634, Global test accuracy: 90.36
Round  32, Train loss: 1.748, Test loss: 1.655, Test accuracy: 88.26
Round  32, Global train loss: 1.748, Global test loss: 1.627, Global test accuracy: 90.56
Round  33, Train loss: 1.592, Test loss: 1.641, Test accuracy: 89.22
Round  33, Global train loss: 1.592, Global test loss: 1.603, Global test accuracy: 91.24
Round  34, Train loss: 1.629, Test loss: 1.631, Test accuracy: 89.82
Round  34, Global train loss: 1.629, Global test loss: 1.596, Global test accuracy: 91.40
Round  35, Train loss: 1.775, Test loss: 1.626, Test accuracy: 90.40
Round  35, Global train loss: 1.775, Global test loss: 1.611, Global test accuracy: 91.10
Round  36, Train loss: 1.663, Test loss: 1.614, Test accuracy: 91.08
Round  36, Global train loss: 1.663, Global test loss: 1.607, Global test accuracy: 91.48
Round  37, Train loss: 1.758, Test loss: 1.615, Test accuracy: 91.02
Round  37, Global train loss: 1.758, Global test loss: 1.600, Global test accuracy: 91.54
Round  38, Train loss: 1.622, Test loss: 1.614, Test accuracy: 91.00
Round  38, Global train loss: 1.622, Global test loss: 1.587, Global test accuracy: 91.30
Round  39, Train loss: 1.613, Test loss: 1.600, Test accuracy: 91.26
Round  39, Global train loss: 1.613, Global test loss: 1.588, Global test accuracy: 92.16
Round  40, Train loss: 1.594, Test loss: 1.597, Test accuracy: 91.66
Round  40, Global train loss: 1.594, Global test loss: 1.574, Global test accuracy: 92.18
Round  41, Train loss: 1.713, Test loss: 1.593, Test accuracy: 91.76
Round  41, Global train loss: 1.713, Global test loss: 1.591, Global test accuracy: 92.04
Round  42, Train loss: 1.613, Test loss: 1.588, Test accuracy: 91.86
Round  42, Global train loss: 1.613, Global test loss: 1.586, Global test accuracy: 91.96
Round  43, Train loss: 1.722, Test loss: 1.589, Test accuracy: 91.90
Round  43, Global train loss: 1.722, Global test loss: 1.587, Global test accuracy: 92.20
Round  44, Train loss: 1.728, Test loss: 1.595, Test accuracy: 92.10
Round  44, Global train loss: 1.728, Global test loss: 1.583, Global test accuracy: 92.80
Round  45, Train loss: 1.747, Test loss: 1.593, Test accuracy: 92.06
Round  45, Global train loss: 1.747, Global test loss: 1.594, Global test accuracy: 92.40
Round  46, Train loss: 1.690, Test loss: 1.589, Test accuracy: 92.20
Round  46, Global train loss: 1.690, Global test loss: 1.582, Global test accuracy: 92.78
Round  47, Train loss: 1.558, Test loss: 1.581, Test accuracy: 92.56
Round  47, Global train loss: 1.558, Global test loss: 1.568, Global test accuracy: 93.14
Round  48, Train loss: 1.679, Test loss: 1.578, Test accuracy: 92.42
Round  48, Global train loss: 1.679, Global test loss: 1.579, Global test accuracy: 92.54
Round  49, Train loss: 1.557, Test loss: 1.577, Test accuracy: 92.54
Round  49, Global train loss: 1.557, Global test loss: 1.559, Global test accuracy: 92.92
Round  50, Train loss: 1.688, Test loss: 1.578, Test accuracy: 92.46
Round  50, Global train loss: 1.688, Global test loss: 1.571, Global test accuracy: 93.06
Round  51, Train loss: 1.576, Test loss: 1.576, Test accuracy: 92.68
Round  51, Global train loss: 1.576, Global test loss: 1.565, Global test accuracy: 92.90
Round  52, Train loss: 1.686, Test loss: 1.578, Test accuracy: 92.62
Round  52, Global train loss: 1.686, Global test loss: 1.571, Global test accuracy: 92.74
Round  53, Train loss: 1.687, Test loss: 1.577, Test accuracy: 92.70
Round  53, Global train loss: 1.687, Global test loss: 1.582, Global test accuracy: 92.44
Round  54, Train loss: 1.559, Test loss: 1.572, Test accuracy: 92.98
Round  54, Global train loss: 1.559, Global test loss: 1.565, Global test accuracy: 93.26
Round  55, Train loss: 1.559, Test loss: 1.569, Test accuracy: 93.10
Round  55, Global train loss: 1.559, Global test loss: 1.558, Global test accuracy: 93.10
Round  56, Train loss: 1.552, Test loss: 1.568, Test accuracy: 92.94
Round  56, Global train loss: 1.552, Global test loss: 1.562, Global test accuracy: 92.56
Round  57, Train loss: 1.564, Test loss: 1.565, Test accuracy: 93.22
Round  57, Global train loss: 1.564, Global test loss: 1.556, Global test accuracy: 93.36
Round  58, Train loss: 1.696, Test loss: 1.570, Test accuracy: 92.98
Round  58, Global train loss: 1.696, Global test loss: 1.566, Global test accuracy: 93.04
Round  59, Train loss: 1.546, Test loss: 1.570, Test accuracy: 93.28
Round  59, Global train loss: 1.546, Global test loss: 1.555, Global test accuracy: 93.18
Round  60, Train loss: 1.548, Test loss: 1.567, Test accuracy: 93.12
Round  60, Global train loss: 1.548, Global test loss: 1.556, Global test accuracy: 93.14
Round  61, Train loss: 1.559, Test loss: 1.565, Test accuracy: 93.22
Round  61, Global train loss: 1.559, Global test loss: 1.553, Global test accuracy: 93.22
Round  62, Train loss: 1.722, Test loss: 1.567, Test accuracy: 93.24
Round  62, Global train loss: 1.722, Global test loss: 1.570, Global test accuracy: 93.80
Round  63, Train loss: 1.681, Test loss: 1.570, Test accuracy: 93.32
Round  63, Global train loss: 1.681, Global test loss: 1.574, Global test accuracy: 93.22
Round  64, Train loss: 1.679, Test loss: 1.572, Test accuracy: 92.96
Round  64, Global train loss: 1.679, Global test loss: 1.569, Global test accuracy: 93.16
Round  65, Train loss: 1.526, Test loss: 1.566, Test accuracy: 93.28
Round  65, Global train loss: 1.526, Global test loss: 1.557, Global test accuracy: 93.32
Round  66, Train loss: 1.536, Test loss: 1.564, Test accuracy: 93.22
Round  66, Global train loss: 1.536, Global test loss: 1.552, Global test accuracy: 93.48
Round  67, Train loss: 1.673, Test loss: 1.566, Test accuracy: 93.20
Round  67, Global train loss: 1.673, Global test loss: 1.566, Global test accuracy: 93.48
Round  68, Train loss: 1.520, Test loss: 1.562, Test accuracy: 93.36
Round  68, Global train loss: 1.520, Global test loss: 1.556, Global test accuracy: 93.70
Round  69, Train loss: 1.534, Test loss: 1.562, Test accuracy: 93.24
Round  69, Global train loss: 1.534, Global test loss: 1.553, Global test accuracy: 93.28
Round  70, Train loss: 1.637, Test loss: 1.563, Test accuracy: 93.32
Round  70, Global train loss: 1.637, Global test loss: 1.559, Global test accuracy: 93.76
Round  71, Train loss: 1.532, Test loss: 1.562, Test accuracy: 93.40
Round  71, Global train loss: 1.532, Global test loss: 1.554, Global test accuracy: 93.40
Round  72, Train loss: 1.547, Test loss: 1.561, Test accuracy: 93.34
Round  72, Global train loss: 1.547, Global test loss: 1.550, Global test accuracy: 93.76
Round  73, Train loss: 1.696, Test loss: 1.566, Test accuracy: 93.20
Round  73, Global train loss: 1.696, Global test loss: 1.564, Global test accuracy: 94.00
Round  74, Train loss: 1.541, Test loss: 1.565, Test accuracy: 93.38
Round  74, Global train loss: 1.541, Global test loss: 1.553, Global test accuracy: 93.72
Round  75, Train loss: 1.647, Test loss: 1.566, Test accuracy: 93.20
Round  75, Global train loss: 1.647, Global test loss: 1.561, Global test accuracy: 93.24
Round  76, Train loss: 1.527, Test loss: 1.563, Test accuracy: 93.28
Round  76, Global train loss: 1.527, Global test loss: 1.553, Global test accuracy: 93.60
Round  77, Train loss: 1.546, Test loss: 1.562, Test accuracy: 93.30
Round  77, Global train loss: 1.546, Global test loss: 1.554, Global test accuracy: 93.40
Round  78, Train loss: 1.557, Test loss: 1.561, Test accuracy: 93.54
Round  78, Global train loss: 1.557, Global test loss: 1.553, Global test accuracy: 93.70
Round  79, Train loss: 1.508, Test loss: 1.559, Test accuracy: 93.44
Round  79, Global train loss: 1.508, Global test loss: 1.552, Global test accuracy: 93.40
Round  80, Train loss: 1.560, Test loss: 1.559, Test accuracy: 93.38
Round  80, Global train loss: 1.560, Global test loss: 1.551, Global test accuracy: 93.50
Round  81, Train loss: 1.658, Test loss: 1.563, Test accuracy: 93.42
Round  81, Global train loss: 1.658, Global test loss: 1.560, Global test accuracy: 93.86
Round  82, Train loss: 1.526, Test loss: 1.562, Test accuracy: 93.46
Round  82, Global train loss: 1.526, Global test loss: 1.555, Global test accuracy: 93.78
Round  83, Train loss: 1.533, Test loss: 1.561, Test accuracy: 93.48
Round  83, Global train loss: 1.533, Global test loss: 1.550, Global test accuracy: 93.48
Round  84, Train loss: 1.523, Test loss: 1.560, Test accuracy: 93.44
Round  84, Global train loss: 1.523, Global test loss: 1.552, Global test accuracy: 93.68
Round  85, Train loss: 1.504, Test loss: 1.557, Test accuracy: 93.58
Round  85, Global train loss: 1.504, Global test loss: 1.547, Global test accuracy: 93.68
Round  86, Train loss: 1.625, Test loss: 1.561, Test accuracy: 93.50
Round  86, Global train loss: 1.625, Global test loss: 1.556, Global test accuracy: 93.92
Round  87, Train loss: 1.651, Test loss: 1.566, Test accuracy: 93.30
Round  87, Global train loss: 1.651, Global test loss: 1.564, Global test accuracy: 93.34
Round  88, Train loss: 1.649, Test loss: 1.570, Test accuracy: 93.26
Round  88, Global train loss: 1.649, Global test loss: 1.565, Global test accuracy: 93.40
Round  89, Train loss: 1.505, Test loss: 1.564, Test accuracy: 93.34
Round  89, Global train loss: 1.505, Global test loss: 1.551, Global test accuracy: 93.56
Round  90, Train loss: 1.554, Test loss: 1.563, Test accuracy: 93.46
Round  90, Global train loss: 1.554, Global test loss: 1.553, Global test accuracy: 93.24
Round  91, Train loss: 1.665, Test loss: 1.569, Test accuracy: 92.90
Round  91, Global train loss: 1.665, Global test loss: 1.564, Global test accuracy: 93.32
Round  92, Train loss: 1.631, Test loss: 1.570, Test accuracy: 93.08
Round  92, Global train loss: 1.631, Global test loss: 1.563, Global test accuracy: 93.32/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  93, Train loss: 1.533, Test loss: 1.563, Test accuracy: 93.62
Round  93, Global train loss: 1.533, Global test loss: 1.550, Global test accuracy: 93.86
Round  94, Train loss: 1.671, Test loss: 1.567, Test accuracy: 93.30
Round  94, Global train loss: 1.671, Global test loss: 1.564, Global test accuracy: 92.92
Round  95, Train loss: 1.637, Test loss: 1.571, Test accuracy: 92.96
Round  95, Global train loss: 1.637, Global test loss: 1.566, Global test accuracy: 93.06
Round  96, Train loss: 1.520, Test loss: 1.566, Test accuracy: 93.26
Round  96, Global train loss: 1.520, Global test loss: 1.556, Global test accuracy: 93.54
Round  97, Train loss: 1.649, Test loss: 1.568, Test accuracy: 92.96
Round  97, Global train loss: 1.649, Global test loss: 1.565, Global test accuracy: 93.94
Round  98, Train loss: 1.770, Test loss: 1.584, Test accuracy: 92.06
Round  98, Global train loss: 1.770, Global test loss: 1.603, Global test accuracy: 91.60
Round  99, Train loss: 1.641, Test loss: 1.579, Test accuracy: 92.50
Round  99, Global train loss: 1.641, Global test loss: 1.572, Global test accuracy: 93.00
Final Round, Train loss: 1.579, Test loss: 1.572, Test accuracy: 92.72
Final Round, Global train loss: 1.579, Global test loss: 1.572, Global test accuracy: 93.00
Average accuracy final 10 rounds: 93.01
460.0806293487549
[0.9986097812652588, 1.8272321224212646, 2.6611487865448, 3.490708112716675, 4.3180458545684814, 5.141916990280151, 5.968777656555176, 6.800573110580444, 7.629496335983276, 8.460334777832031, 9.28604006767273, 10.110284566879272, 10.933987379074097, 11.763876676559448, 12.589150428771973, 13.424603939056396, 14.247689723968506, 15.083366632461548, 15.91044306755066, 16.731505632400513, 17.55812668800354, 18.386698961257935, 19.208868503570557, 20.08099389076233, 20.928787231445312, 21.765304565429688, 22.598103523254395, 23.43592119216919, 24.30720043182373, 25.18242335319519, 26.053022623062134, 26.880005836486816, 27.75080895423889, 28.577587842941284, 29.43946862220764, 30.315910816192627, 31.150155782699585, 32.010260820388794, 32.87333679199219, 33.73688101768494, 34.61000108718872, 35.47691583633423, 36.30509805679321, 37.13447880744934, 38.00444221496582, 38.87914204597473, 39.741276264190674, 40.56899118423462, 41.432255268096924, 42.293662548065186, 43.163676500320435, 44.03407692909241, 44.913869857788086, 45.74230694770813, 46.60637664794922, 47.47591686248779, 48.316009521484375, 49.143975257873535, 50.01005458831787, 50.88753032684326, 51.7597930431366, 52.59307551383972, 53.46973633766174, 54.29627847671509, 55.139413833618164, 56.01549768447876, 56.84925603866577, 57.675585985183716, 58.52989149093628, 59.39176893234253, 60.22554659843445, 61.09501576423645, 61.92273139953613, 62.784260749816895, 63.62218260765076, 64.49548435211182, 65.32681941986084, 66.18960452079773, 67.0546646118164, 67.92266845703125, 68.78194403648376, 69.65930891036987, 70.52550506591797, 71.35185885429382, 72.22100234031677, 73.03900647163391, 73.89560270309448, 74.76671290397644, 75.6234622001648, 76.48365664482117, 77.3098349571228, 78.16524887084961, 78.98727655410767, 79.84724235534668, 80.7027485370636, 81.55955672264099, 82.3816728591919, 83.20477676391602, 84.0436601638794, 84.91102981567383, 86.19600081443787]
[13.2, 17.0, 21.9, 33.62, 44.16, 44.42, 44.4, 44.9, 45.52, 48.8, 53.78, 58.02, 62.26, 64.84, 68.62, 70.94, 72.3, 72.76, 73.54, 73.54, 73.86, 74.26, 75.12, 76.1, 78.38, 80.3, 81.38, 82.36, 84.26, 85.48, 87.02, 87.68, 88.26, 89.22, 89.82, 90.4, 91.08, 91.02, 91.0, 91.26, 91.66, 91.76, 91.86, 91.9, 92.1, 92.06, 92.2, 92.56, 92.42, 92.54, 92.46, 92.68, 92.62, 92.7, 92.98, 93.1, 92.94, 93.22, 92.98, 93.28, 93.12, 93.22, 93.24, 93.32, 92.96, 93.28, 93.22, 93.2, 93.36, 93.24, 93.32, 93.4, 93.34, 93.2, 93.38, 93.2, 93.28, 93.3, 93.54, 93.44, 93.38, 93.42, 93.46, 93.48, 93.44, 93.58, 93.5, 93.3, 93.26, 93.34, 93.46, 92.9, 93.08, 93.62, 93.3, 92.96, 93.26, 92.96, 92.06, 92.5, 92.72]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fedpac_copsl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist,  filter_alg: loss_psl, level_n_system: 0.2 , level_n_lowerb:0.4  

   Client 1, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.321, Test loss: 2.300, Test accuracy: 16.16
Round   0, Global train loss: 2.321, Global test loss: 2.300, Global test accuracy: 16.46
Round   1, Train loss: 2.300, Test loss: 2.298, Test accuracy: 27.58
Round   1, Global train loss: 2.300, Global test loss: 2.298, Global test accuracy: 28.62
Round   2, Train loss: 2.298, Test loss: 2.296, Test accuracy: 33.94
Round   2, Global train loss: 2.298, Global test loss: 2.296, Global test accuracy: 35.12
Round   3, Train loss: 2.295, Test loss: 2.292, Test accuracy: 38.76
Round   3, Global train loss: 2.295, Global test loss: 2.292, Global test accuracy: 40.92
Round   4, Train loss: 2.292, Test loss: 2.287, Test accuracy: 41.50
Round   4, Global train loss: 2.292, Global test loss: 2.287, Global test accuracy: 43.74
Round   5, Train loss: 2.286, Test loss: 2.278, Test accuracy: 42.24
Round   5, Global train loss: 2.286, Global test loss: 2.278, Global test accuracy: 43.92
Round   6, Train loss: 2.275, Test loss: 2.257, Test accuracy: 39.62
Round   6, Global train loss: 2.275, Global test loss: 2.257, Global test accuracy: 41.30
Round   7, Train loss: 2.246, Test loss: 2.197, Test accuracy: 34.12
Round   7, Global train loss: 2.246, Global test loss: 2.196, Global test accuracy: 34.82
Round   8, Train loss: 2.190, Test loss: 2.132, Test accuracy: 34.06
Round   8, Global train loss: 2.190, Global test loss: 2.126, Global test accuracy: 36.26
Round   9, Train loss: 2.141, Test loss: 2.075, Test accuracy: 42.84
Round   9, Global train loss: 2.141, Global test loss: 2.069, Global test accuracy: 42.38
Round  10, Train loss: 2.050, Test loss: 2.014, Test accuracy: 52.10
Round  10, Global train loss: 2.050, Global test loss: 1.989, Global test accuracy: 58.14
Traceback (most recent call last):
  File "main_fedpac_copsl.py", line 280, in <module>
    w_local, loss, indd, class_center_local, class_num, noisy_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys,
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2559, in train
    self.filter_data(net, local_net, iter2-head_eps+1, local_eps-head_eps+1, concept_matrix_local)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2396, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist, level_n_system: 0.2 , level_n_lowerb:0.8  

   Client 9, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.301, Test loss: 2.300, Test accuracy: 16.30
Round   0, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 16.30
Round   1, Train loss: 2.299, Test loss: 2.298, Test accuracy: 19.54
Round   1, Global train loss: 2.299, Global test loss: 2.297, Global test accuracy: 20.90
Round   2, Train loss: 2.294, Test loss: 2.296, Test accuracy: 18.32
Round   2, Global train loss: 2.294, Global test loss: 2.293, Global test accuracy: 14.26
Round   3, Train loss: 2.288, Test loss: 2.291, Test accuracy: 19.54
Round   3, Global train loss: 2.288, Global test loss: 2.286, Global test accuracy: 18.36
Round   4, Train loss: 2.285, Test loss: 2.288, Test accuracy: 18.60
Round   4, Global train loss: 2.285, Global test loss: 2.288, Global test accuracy: 9.64
Round   5, Train loss: 2.249, Test loss: 2.276, Test accuracy: 20.88
Round   5, Global train loss: 2.249, Global test loss: 2.265, Global test accuracy: 12.20
Round   6, Train loss: 2.274, Test loss: 2.265, Test accuracy: 26.30
Round   6, Global train loss: 2.274, Global test loss: 2.269, Global test accuracy: 39.28
Round   7, Train loss: 2.236, Test loss: 2.239, Test accuracy: 23.18
Round   7, Global train loss: 2.236, Global test loss: 2.226, Global test accuracy: 21.94
Round   8, Train loss: 2.157, Test loss: 2.200, Test accuracy: 26.76
Round   8, Global train loss: 2.157, Global test loss: 2.182, Global test accuracy: 25.26
Round   9, Train loss: 2.151, Test loss: 2.183, Test accuracy: 29.52
Round   9, Global train loss: 2.151, Global test loss: 2.180, Global test accuracy: 24.68
Round  10, Train loss: 2.177, Test loss: 2.177, Test accuracy: 29.48
Round  10, Global train loss: 2.177, Global test loss: 2.248, Global test accuracy: 16.22
Round  11, Train loss: 2.035, Test loss: 2.127, Test accuracy: 36.60
Round  11, Global train loss: 2.035, Global test loss: 2.084, Global test accuracy: 40.52
Round  12, Train loss: 2.059, Test loss: 2.102, Test accuracy: 39.64
Round  12, Global train loss: 2.059, Global test loss: 2.033, Global test accuracy: 46.02
Round  13, Train loss: 2.092, Test loss: 2.106, Test accuracy: 37.70
Round  13, Global train loss: 2.092, Global test loss: 2.163, Global test accuracy: 30.84
Round  14, Train loss: 1.985, Test loss: 2.082, Test accuracy: 40.42
Round  14, Global train loss: 1.985, Global test loss: 1.948, Global test accuracy: 51.84
Round  15, Train loss: 2.104, Test loss: 2.055, Test accuracy: 42.96
Round  15, Global train loss: 2.104, Global test loss: 2.056, Global test accuracy: 45.30
Round  16, Train loss: 2.077, Test loss: 2.023, Test accuracy: 44.76
Round  16, Global train loss: 2.077, Global test loss: 2.023, Global test accuracy: 45.18
Round  17, Train loss: 1.882, Test loss: 1.999, Test accuracy: 47.22
Round  17, Global train loss: 1.882, Global test loss: 1.890, Global test accuracy: 58.68
Round  18, Train loss: 2.141, Test loss: 1.990, Test accuracy: 48.74
Round  18, Global train loss: 2.141, Global test loss: 2.231, Global test accuracy: 17.56
Round  19, Train loss: 1.868, Test loss: 1.970, Test accuracy: 51.40
Round  19, Global train loss: 1.868, Global test loss: 1.884, Global test accuracy: 58.48
Round  20, Train loss: 1.939, Test loss: 1.957, Test accuracy: 52.86
Round  20, Global train loss: 1.939, Global test loss: 1.959, Global test accuracy: 51.60
Round  21, Train loss: 1.907, Test loss: 1.941, Test accuracy: 54.38
Round  21, Global train loss: 1.907, Global test loss: 1.932, Global test accuracy: 55.16
Round  22, Train loss: 1.757, Test loss: 1.930, Test accuracy: 55.00
Round  22, Global train loss: 1.757, Global test loss: 1.863, Global test accuracy: 59.66
Round  23, Train loss: 1.767, Test loss: 1.923, Test accuracy: 55.50
Round  23, Global train loss: 1.767, Global test loss: 1.890, Global test accuracy: 58.40
Round  24, Train loss: 1.855, Test loss: 1.919, Test accuracy: 55.62
Round  24, Global train loss: 1.855, Global test loss: 2.047, Global test accuracy: 43.32
Round  25, Train loss: 1.725, Test loss: 1.908, Test accuracy: 56.86
Round  25, Global train loss: 1.725, Global test loss: 1.785, Global test accuracy: 69.22
Round  26, Train loss: 1.778, Test loss: 1.895, Test accuracy: 58.90
Round  26, Global train loss: 1.778, Global test loss: 1.835, Global test accuracy: 63.64
Round  27, Train loss: 1.693, Test loss: 1.892, Test accuracy: 58.92
Round  27, Global train loss: 1.693, Global test loss: 1.827, Global test accuracy: 63.44
Round  28, Train loss: 1.748, Test loss: 1.887, Test accuracy: 59.04
Round  28, Global train loss: 1.748, Global test loss: 1.827, Global test accuracy: 63.82
Round  29, Train loss: 1.950, Test loss: 1.881, Test accuracy: 59.68
Round  29, Global train loss: 1.950, Global test loss: 2.136, Global test accuracy: 32.24
Round  30, Train loss: 1.797, Test loss: 1.878, Test accuracy: 59.54
Round  30, Global train loss: 1.797, Global test loss: 1.847, Global test accuracy: 62.78
Round  31, Train loss: 1.658, Test loss: 1.874, Test accuracy: 59.84
Round  31, Global train loss: 1.658, Global test loss: 1.811, Global test accuracy: 65.94
Round  32, Train loss: 1.740, Test loss: 1.869, Test accuracy: 60.34
Round  32, Global train loss: 1.740, Global test loss: 1.846, Global test accuracy: 61.76
Round  33, Train loss: 1.903, Test loss: 1.869, Test accuracy: 60.36
Round  33, Global train loss: 1.903, Global test loss: 2.133, Global test accuracy: 32.70
Round  34, Train loss: 1.882, Test loss: 1.868, Test accuracy: 60.34
Round  34, Global train loss: 1.882, Global test loss: 2.059, Global test accuracy: 41.40
Round  35, Train loss: 1.886, Test loss: 1.867, Test accuracy: 60.42
Round  35, Global train loss: 1.886, Global test loss: 2.069, Global test accuracy: 39.20
Round  36, Train loss: 1.718, Test loss: 1.865, Test accuracy: 60.42
Round  36, Global train loss: 1.718, Global test loss: 1.823, Global test accuracy: 63.52
Round  37, Train loss: 1.771, Test loss: 1.865, Test accuracy: 60.50
Round  37, Global train loss: 1.771, Global test loss: 1.876, Global test accuracy: 58.82
Round  38, Train loss: 1.765, Test loss: 1.864, Test accuracy: 60.58
Round  38, Global train loss: 1.765, Global test loss: 2.003, Global test accuracy: 46.96
Round  39, Train loss: 1.700, Test loss: 1.863, Test accuracy: 60.52
Round  39, Global train loss: 1.700, Global test loss: 1.831, Global test accuracy: 62.46
Round  40, Train loss: 1.684, Test loss: 1.863, Test accuracy: 60.46
Round  40, Global train loss: 1.684, Global test loss: 1.793, Global test accuracy: 66.66
Round  41, Train loss: 1.710, Test loss: 1.863, Test accuracy: 60.40
Round  41, Global train loss: 1.710, Global test loss: 1.856, Global test accuracy: 60.90
Round  42, Train loss: 1.659, Test loss: 1.858, Test accuracy: 61.26
Round  42, Global train loss: 1.659, Global test loss: 1.734, Global test accuracy: 74.00
Round  43, Train loss: 1.732, Test loss: 1.856, Test accuracy: 61.26
Round  43, Global train loss: 1.732, Global test loss: 1.841, Global test accuracy: 62.04
Round  44, Train loss: 1.785, Test loss: 1.852, Test accuracy: 61.72
Round  44, Global train loss: 1.785, Global test loss: 1.913, Global test accuracy: 54.66
Round  45, Train loss: 1.811, Test loss: 1.853, Test accuracy: 61.48
Round  45, Global train loss: 1.811, Global test loss: 2.034, Global test accuracy: 39.98
Round  46, Train loss: 1.679, Test loss: 1.850, Test accuracy: 61.82
Round  46, Global train loss: 1.679, Global test loss: 1.752, Global test accuracy: 70.90
Round  47, Train loss: 1.666, Test loss: 1.849, Test accuracy: 61.82
Round  47, Global train loss: 1.666, Global test loss: 1.894, Global test accuracy: 55.96
Round  48, Train loss: 1.692, Test loss: 1.849, Test accuracy: 61.90
Round  48, Global train loss: 1.692, Global test loss: 1.878, Global test accuracy: 58.36
Round  49, Train loss: 1.664, Test loss: 1.848, Test accuracy: 61.90
Round  49, Global train loss: 1.664, Global test loss: 1.749, Global test accuracy: 72.18
Round  50, Train loss: 1.655, Test loss: 1.848, Test accuracy: 61.80
Round  50, Global train loss: 1.655, Global test loss: 1.745, Global test accuracy: 72.06
Round  51, Train loss: 1.765, Test loss: 1.849, Test accuracy: 61.66
Round  51, Global train loss: 1.765, Global test loss: 1.884, Global test accuracy: 58.74
Round  52, Train loss: 1.628, Test loss: 1.848, Test accuracy: 61.74
Round  52, Global train loss: 1.628, Global test loss: 1.798, Global test accuracy: 66.02
Round  53, Train loss: 1.777, Test loss: 1.847, Test accuracy: 61.74
Round  53, Global train loss: 1.777, Global test loss: 2.073, Global test accuracy: 37.86
Round  54, Train loss: 1.774, Test loss: 1.848, Test accuracy: 61.38
Round  54, Global train loss: 1.774, Global test loss: 1.891, Global test accuracy: 56.60
Round  55, Train loss: 1.827, Test loss: 1.852, Test accuracy: 61.12
Round  55, Global train loss: 1.827, Global test loss: 2.147, Global test accuracy: 30.96
Round  56, Train loss: 1.828, Test loss: 1.851, Test accuracy: 61.20
Round  56, Global train loss: 1.828, Global test loss: 2.178, Global test accuracy: 26.96
Round  57, Train loss: 1.664, Test loss: 1.849, Test accuracy: 61.34
Round  57, Global train loss: 1.664, Global test loss: 1.895, Global test accuracy: 55.88
Round  58, Train loss: 1.596, Test loss: 1.848, Test accuracy: 61.34
Round  58, Global train loss: 1.596, Global test loss: 1.732, Global test accuracy: 73.60
Round  59, Train loss: 1.757, Test loss: 1.848, Test accuracy: 61.32
Round  59, Global train loss: 1.757, Global test loss: 2.089, Global test accuracy: 34.78
Round  60, Train loss: 1.588, Test loss: 1.843, Test accuracy: 61.86
Round  60, Global train loss: 1.588, Global test loss: 1.731, Global test accuracy: 74.02
Round  61, Train loss: 1.740, Test loss: 1.843, Test accuracy: 61.82
Round  61, Global train loss: 1.740, Global test loss: 1.952, Global test accuracy: 50.48
Round  62, Train loss: 1.726, Test loss: 1.843, Test accuracy: 62.08
Round  62, Global train loss: 1.726, Global test loss: 2.014, Global test accuracy: 43.10
Round  63, Train loss: 1.720, Test loss: 1.842, Test accuracy: 62.14
Round  63, Global train loss: 1.720, Global test loss: 1.902, Global test accuracy: 55.86
Round  64, Train loss: 1.618, Test loss: 1.837, Test accuracy: 62.70
Round  64, Global train loss: 1.618, Global test loss: 1.741, Global test accuracy: 72.80
Round  65, Train loss: 1.686, Test loss: 1.837, Test accuracy: 62.68
Round  65, Global train loss: 1.686, Global test loss: 2.031, Global test accuracy: 42.72
Round  66, Train loss: 1.561, Test loss: 1.837, Test accuracy: 62.64
Round  66, Global train loss: 1.561, Global test loss: 1.722, Global test accuracy: 74.40
Round  67, Train loss: 1.706, Test loss: 1.837, Test accuracy: 62.64
Round  67, Global train loss: 1.706, Global test loss: 2.110, Global test accuracy: 33.10
Round  68, Train loss: 1.673, Test loss: 1.834, Test accuracy: 62.84
Round  68, Global train loss: 1.673, Global test loss: 1.775, Global test accuracy: 69.14
Round  69, Train loss: 1.685, Test loss: 1.833, Test accuracy: 62.76
Round  69, Global train loss: 1.685, Global test loss: 1.868, Global test accuracy: 57.72
Round  70, Train loss: 1.720, Test loss: 1.833, Test accuracy: 62.86
Round  70, Global train loss: 1.720, Global test loss: 1.846, Global test accuracy: 61.68
Round  71, Train loss: 1.598, Test loss: 1.833, Test accuracy: 62.80
Round  71, Global train loss: 1.598, Global test loss: 1.750, Global test accuracy: 71.02
Round  72, Train loss: 1.689, Test loss: 1.833, Test accuracy: 62.78
Round  72, Global train loss: 1.689, Global test loss: 1.829, Global test accuracy: 63.74
Round  73, Train loss: 1.637, Test loss: 1.832, Test accuracy: 62.82
Round  73, Global train loss: 1.637, Global test loss: 1.998, Global test accuracy: 44.58
Round  74, Train loss: 1.698, Test loss: 1.832, Test accuracy: 62.86
Round  74, Global train loss: 1.698, Global test loss: 2.094, Global test accuracy: 36.18
Round  75, Train loss: 1.664, Test loss: 1.832, Test accuracy: 62.90
Round  75, Global train loss: 1.664, Global test loss: 1.761, Global test accuracy: 69.82
Round  76, Train loss: 1.635, Test loss: 1.832, Test accuracy: 62.84
Round  76, Global train loss: 1.635, Global test loss: 2.046, Global test accuracy: 39.64
Round  77, Train loss: 1.673, Test loss: 1.832, Test accuracy: 62.86
Round  77, Global train loss: 1.673, Global test loss: 2.034, Global test accuracy: 41.68
Round  78, Train loss: 1.723, Test loss: 1.831, Test accuracy: 62.90
Round  78, Global train loss: 1.723, Global test loss: 1.820, Global test accuracy: 64.08
Round  79, Train loss: 1.594, Test loss: 1.831, Test accuracy: 62.90
Round  79, Global train loss: 1.594, Global test loss: 1.746, Global test accuracy: 71.64
Round  80, Train loss: 1.759, Test loss: 1.828, Test accuracy: 63.28
Round  80, Global train loss: 1.759, Global test loss: 1.944, Global test accuracy: 51.06
Round  81, Train loss: 1.630, Test loss: 1.828, Test accuracy: 63.28
Round  81, Global train loss: 1.630, Global test loss: 1.767, Global test accuracy: 69.12
Round  82, Train loss: 1.740, Test loss: 1.827, Test accuracy: 63.28
Round  82, Global train loss: 1.740, Global test loss: 1.802, Global test accuracy: 66.06
Round  83, Train loss: 1.624, Test loss: 1.827, Test accuracy: 63.30
Round  83, Global train loss: 1.624, Global test loss: 1.783, Global test accuracy: 67.34
Round  84, Train loss: 1.641, Test loss: 1.827, Test accuracy: 63.28
Round  84, Global train loss: 1.641, Global test loss: 1.892, Global test accuracy: 56.72
Round  85, Train loss: 1.745, Test loss: 1.827, Test accuracy: 63.30
Round  85, Global train loss: 1.745, Global test loss: 2.072, Global test accuracy: 38.36
Round  86, Train loss: 1.719, Test loss: 1.827, Test accuracy: 63.28
Round  86, Global train loss: 1.719, Global test loss: 2.117, Global test accuracy: 33.70
Round  87, Train loss: 1.585, Test loss: 1.826, Test accuracy: 63.44
Round  87, Global train loss: 1.585, Global test loss: 1.726, Global test accuracy: 74.02
Round  88, Train loss: 1.557, Test loss: 1.826, Test accuracy: 63.40
Round  88, Global train loss: 1.557, Global test loss: 1.716, Global test accuracy: 74.90
Round  89, Train loss: 1.717, Test loss: 1.826, Test accuracy: 63.42
Round  89, Global train loss: 1.717, Global test loss: 2.119, Global test accuracy: 33.90
Round  90, Train loss: 1.630, Test loss: 1.827, Test accuracy: 63.36
Round  90, Global train loss: 1.630, Global test loss: 1.794, Global test accuracy: 66.96
Round  91, Train loss: 1.628, Test loss: 1.826, Test accuracy: 63.50
Round  91, Global train loss: 1.628, Global test loss: 1.793, Global test accuracy: 67.36
Round  92, Train loss: 1.653, Test loss: 1.826, Test accuracy: 63.46
Round  92, Global train loss: 1.653, Global test loss: 1.800, Global test accuracy: 65.48
Round  93, Train loss: 1.597, Test loss: 1.825, Test accuracy: 63.48
Round  93, Global train loss: 1.597, Global test loss: 2.018, Global test accuracy: 42.40
Round  94, Train loss: 1.752, Test loss: 1.826, Test accuracy: 63.48
Round  94, Global train loss: 1.752, Global test loss: 2.183, Global test accuracy: 27.84
Round  95, Train loss: 1.664, Test loss: 1.827, Test accuracy: 63.36
Round  95, Global train loss: 1.664, Global test loss: 1.788, Global test accuracy: 67.18/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 1.663, Test loss: 1.826, Test accuracy: 63.40
Round  96, Global train loss: 1.663, Global test loss: 1.786, Global test accuracy: 67.30
Round  97, Train loss: 1.560, Test loss: 1.826, Test accuracy: 63.42
Round  97, Global train loss: 1.560, Global test loss: 1.718, Global test accuracy: 74.78
Round  98, Train loss: 1.656, Test loss: 1.826, Test accuracy: 63.50
Round  98, Global train loss: 1.656, Global test loss: 1.803, Global test accuracy: 65.22
Round  99, Train loss: 1.586, Test loss: 1.826, Test accuracy: 63.50
Round  99, Global train loss: 1.586, Global test loss: 1.722, Global test accuracy: 74.34
Final Round, Train loss: 1.654, Test loss: 1.826, Test accuracy: 63.34
Final Round, Global train loss: 1.654, Global test loss: 1.722, Global test accuracy: 74.34
Average accuracy final 10 rounds: 63.446 

Average global accuracy final 10 rounds: 61.885999999999996 

508.65267753601074
[0.8174929618835449, 1.6349859237670898, 2.356593132019043, 3.078200340270996, 3.823059558868408, 4.56791877746582, 5.296849250793457, 6.025779724121094, 6.767212390899658, 7.508645057678223, 8.22087812423706, 8.933111190795898, 9.644091367721558, 10.355071544647217, 11.101289987564087, 11.847508430480957, 12.565479755401611, 13.283451080322266, 14.028105735778809, 14.772760391235352, 15.520402193069458, 16.268043994903564, 16.978922367095947, 17.68980073928833, 18.431884765625, 19.17396879196167, 19.92145824432373, 20.66894769668579, 21.41309690475464, 22.157246112823486, 22.898534059524536, 23.639822006225586, 24.37380862236023, 25.107795238494873, 25.83697271347046, 26.566150188446045, 27.30940580368042, 28.052661418914795, 28.760706663131714, 29.468751907348633, 30.210978984832764, 30.953206062316895, 31.66851568222046, 32.38382530212402, 33.10537385940552, 33.82692241668701, 34.569010972976685, 35.31109952926636, 36.054540395736694, 36.79798126220703, 37.53658318519592, 38.275185108184814, 39.01941227912903, 39.76363945007324, 40.50077939033508, 41.237919330596924, 41.9464430809021, 42.654966831207275, 43.36234426498413, 44.069721698760986, 44.81243133544922, 45.55514097213745, 46.29179525375366, 47.02844953536987, 47.773491621017456, 48.51853370666504, 49.235422134399414, 49.95231056213379, 50.68549919128418, 51.41868782043457, 52.16307473182678, 52.907461643218994, 53.64984345436096, 54.39222526550293, 55.11229348182678, 55.832361698150635, 56.57738399505615, 57.32240629196167, 58.029869079589844, 58.73733186721802, 59.47972059249878, 60.22210931777954, 60.961469888687134, 61.70083045959473, 62.44802379608154, 63.19521713256836, 63.90033960342407, 64.60546207427979, 65.34432744979858, 66.08319282531738, 66.82836723327637, 67.57354164123535, 68.28562879562378, 68.9977159500122, 69.73930549621582, 70.48089504241943, 71.1980812549591, 71.91526746749878, 72.63633251190186, 73.35739755630493, 74.09151101112366, 74.82562446594238, 75.5663673877716, 76.30711030960083, 77.03973698616028, 77.77236366271973, 78.5151720046997, 79.25798034667969, 79.95839166641235, 80.65880298614502, 81.39798736572266, 82.1371717453003, 82.87893414497375, 83.62069654464722, 84.32286047935486, 85.0250244140625, 85.76521944999695, 86.5054144859314, 87.24015140533447, 87.97488832473755, 88.71184706687927, 89.448805809021, 90.18378758430481, 90.91876935958862, 91.54691362380981, 92.175057888031, 92.80652570724487, 93.43799352645874, 94.07523536682129, 94.71247720718384, 95.32078862190247, 95.9291000366211, 96.56277990341187, 97.19645977020264, 97.79559707641602, 98.3947343826294, 99.0242292881012, 99.653724193573, 100.26344919204712, 100.87317419052124, 101.48026394844055, 102.08735370635986, 102.71603345870972, 103.34471321105957, 103.97273397445679, 104.600754737854, 105.22999048233032, 105.85922622680664, 106.48586988449097, 107.1125135421753, 107.7048933506012, 108.2972731590271, 108.93193984031677, 109.56660652160645, 110.17403483390808, 110.78146314620972, 111.39071345329285, 111.99996376037598, 112.6135504245758, 113.22713708877563, 113.83753299713135, 114.44792890548706, 115.04560613632202, 115.64328336715698, 116.25356888771057, 116.86385440826416, 117.48062086105347, 118.09738731384277, 118.6869912147522, 119.27659511566162, 119.88308191299438, 120.48956871032715, 121.09694600105286, 121.70432329177856, 122.31392884254456, 122.92353439331055, 123.5276038646698, 124.13167333602905, 124.72028517723083, 125.30889701843262, 125.9130072593689, 126.51711750030518, 127.1218912601471, 127.72666501998901, 128.33503198623657, 128.94339895248413, 129.55257177352905, 130.16174459457397, 130.75398349761963, 131.34622240066528, 131.95141911506653, 132.55661582946777, 133.164231300354, 133.77184677124023, 134.360759973526, 134.94967317581177, 135.55228352546692, 136.15489387512207, 136.76118421554565, 137.36747455596924, 138.59335446357727, 139.8192343711853]
[16.3, 16.3, 19.54, 19.54, 18.32, 18.32, 19.54, 19.54, 18.6, 18.6, 20.88, 20.88, 26.3, 26.3, 23.18, 23.18, 26.76, 26.76, 29.52, 29.52, 29.48, 29.48, 36.6, 36.6, 39.64, 39.64, 37.7, 37.7, 40.42, 40.42, 42.96, 42.96, 44.76, 44.76, 47.22, 47.22, 48.74, 48.74, 51.4, 51.4, 52.86, 52.86, 54.38, 54.38, 55.0, 55.0, 55.5, 55.5, 55.62, 55.62, 56.86, 56.86, 58.9, 58.9, 58.92, 58.92, 59.04, 59.04, 59.68, 59.68, 59.54, 59.54, 59.84, 59.84, 60.34, 60.34, 60.36, 60.36, 60.34, 60.34, 60.42, 60.42, 60.42, 60.42, 60.5, 60.5, 60.58, 60.58, 60.52, 60.52, 60.46, 60.46, 60.4, 60.4, 61.26, 61.26, 61.26, 61.26, 61.72, 61.72, 61.48, 61.48, 61.82, 61.82, 61.82, 61.82, 61.9, 61.9, 61.9, 61.9, 61.8, 61.8, 61.66, 61.66, 61.74, 61.74, 61.74, 61.74, 61.38, 61.38, 61.12, 61.12, 61.2, 61.2, 61.34, 61.34, 61.34, 61.34, 61.32, 61.32, 61.86, 61.86, 61.82, 61.82, 62.08, 62.08, 62.14, 62.14, 62.7, 62.7, 62.68, 62.68, 62.64, 62.64, 62.64, 62.64, 62.84, 62.84, 62.76, 62.76, 62.86, 62.86, 62.8, 62.8, 62.78, 62.78, 62.82, 62.82, 62.86, 62.86, 62.9, 62.9, 62.84, 62.84, 62.86, 62.86, 62.9, 62.9, 62.9, 62.9, 63.28, 63.28, 63.28, 63.28, 63.28, 63.28, 63.3, 63.3, 63.28, 63.28, 63.3, 63.3, 63.28, 63.28, 63.44, 63.44, 63.4, 63.4, 63.42, 63.42, 63.36, 63.36, 63.5, 63.5, 63.46, 63.46, 63.48, 63.48, 63.48, 63.48, 63.36, 63.36, 63.4, 63.4, 63.42, 63.42, 63.5, 63.5, 63.5, 63.5, 63.34, 63.34]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.2 , level_n_lowerb:0.8  

   Client 7, noise    level: 0.8000 
   Client 3, noise    level: 0.8000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.301, Test loss: 2.300, Test accuracy: 16.66
Round   0, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 16.66
Round   1, Train loss: 2.296, Test loss: 2.297, Test accuracy: 13.94
Round   1, Global train loss: 2.296, Global test loss: 2.295, Global test accuracy: 11.50
Round   2, Train loss: 2.288, Test loss: 2.283, Test accuracy: 12.40
Round   2, Global train loss: 2.288, Global test loss: 2.270, Global test accuracy: 10.12
Round   3, Train loss: 2.244, Test loss: 2.265, Test accuracy: 13.88
Round   3, Global train loss: 2.244, Global test loss: 2.240, Global test accuracy: 11.78
Round   4, Train loss: 2.228, Test loss: 2.240, Test accuracy: 16.46
Round   4, Global train loss: 2.228, Global test loss: 2.211, Global test accuracy: 20.36
Round   5, Train loss: 2.200, Test loss: 2.217, Test accuracy: 20.10
Round   5, Global train loss: 2.200, Global test loss: 2.183, Global test accuracy: 21.76
Round   6, Train loss: 2.210, Test loss: 2.168, Test accuracy: 31.66
Round   6, Global train loss: 2.210, Global test loss: 2.143, Global test accuracy: 39.52
Round   7, Train loss: 2.102, Test loss: 2.075, Test accuracy: 42.62
Round   7, Global train loss: 2.102, Global test loss: 1.959, Global test accuracy: 61.58
Round   8, Train loss: 1.964, Test loss: 1.965, Test accuracy: 54.06
Round   8, Global train loss: 1.964, Global test loss: 1.839, Global test accuracy: 67.30
Round   9, Train loss: 1.796, Test loss: 1.921, Test accuracy: 56.72
Round   9, Global train loss: 1.796, Global test loss: 1.751, Global test accuracy: 75.82
Round  10, Train loss: 1.773, Test loss: 1.815, Test accuracy: 68.20
Round  10, Global train loss: 1.773, Global test loss: 1.710, Global test accuracy: 78.00
Round  11, Train loss: 1.812, Test loss: 1.764, Test accuracy: 71.86
Round  11, Global train loss: 1.812, Global test loss: 1.694, Global test accuracy: 78.90
Round  12, Train loss: 1.676, Test loss: 1.755, Test accuracy: 72.68
Round  12, Global train loss: 1.676, Global test loss: 1.685, Global test accuracy: 79.74
Round  13, Train loss: 1.702, Test loss: 1.743, Test accuracy: 73.44
Round  13, Global train loss: 1.702, Global test loss: 1.677, Global test accuracy: 80.02
Round  14, Train loss: 1.807, Test loss: 1.745, Test accuracy: 73.06
Round  14, Global train loss: 1.807, Global test loss: 1.677, Global test accuracy: 79.28
Round  15, Train loss: 1.681, Test loss: 1.742, Test accuracy: 73.28
Round  15, Global train loss: 1.681, Global test loss: 1.668, Global test accuracy: 81.18
Round  16, Train loss: 1.827, Test loss: 1.698, Test accuracy: 77.90
Round  16, Global train loss: 1.827, Global test loss: 1.678, Global test accuracy: 79.86
Round  17, Train loss: 1.946, Test loss: 1.697, Test accuracy: 77.80
Round  17, Global train loss: 1.946, Global test loss: 1.673, Global test accuracy: 80.04
Round  18, Train loss: 1.702, Test loss: 1.685, Test accuracy: 78.62
Round  18, Global train loss: 1.702, Global test loss: 1.655, Global test accuracy: 81.04
Round  19, Train loss: 1.820, Test loss: 1.681, Test accuracy: 79.10
Round  19, Global train loss: 1.820, Global test loss: 1.665, Global test accuracy: 80.46
Round  20, Train loss: 1.656, Test loss: 1.677, Test accuracy: 79.22
Round  20, Global train loss: 1.656, Global test loss: 1.658, Global test accuracy: 80.86
Round  21, Train loss: 1.697, Test loss: 1.677, Test accuracy: 79.26
Round  21, Global train loss: 1.697, Global test loss: 1.659, Global test accuracy: 80.48
Round  22, Train loss: 1.835, Test loss: 1.674, Test accuracy: 79.38
Round  22, Global train loss: 1.835, Global test loss: 1.665, Global test accuracy: 79.78
Round  23, Train loss: 1.617, Test loss: 1.674, Test accuracy: 79.20
Round  23, Global train loss: 1.617, Global test loss: 1.661, Global test accuracy: 80.26
Round  24, Train loss: 1.851, Test loss: 1.672, Test accuracy: 79.48
Round  24, Global train loss: 1.851, Global test loss: 1.656, Global test accuracy: 81.34
Round  25, Train loss: 1.955, Test loss: 1.677, Test accuracy: 78.66
Round  25, Global train loss: 1.955, Global test loss: 1.673, Global test accuracy: 79.66
Round  26, Train loss: 1.655, Test loss: 1.678, Test accuracy: 78.78
Round  26, Global train loss: 1.655, Global test loss: 1.660, Global test accuracy: 80.74
Round  27, Train loss: 1.785, Test loss: 1.679, Test accuracy: 78.64
Round  27, Global train loss: 1.785, Global test loss: 1.669, Global test accuracy: 79.78
Round  28, Train loss: 1.652, Test loss: 1.678, Test accuracy: 78.54
Round  28, Global train loss: 1.652, Global test loss: 1.661, Global test accuracy: 80.42
Round  29, Train loss: 1.629, Test loss: 1.678, Test accuracy: 78.58
Round  29, Global train loss: 1.629, Global test loss: 1.650, Global test accuracy: 81.46
Round  30, Train loss: 1.770, Test loss: 1.677, Test accuracy: 78.72
Round  30, Global train loss: 1.770, Global test loss: 1.655, Global test accuracy: 81.08
Round  31, Train loss: 1.737, Test loss: 1.673, Test accuracy: 79.14
Round  31, Global train loss: 1.737, Global test loss: 1.660, Global test accuracy: 80.00
Round  32, Train loss: 1.744, Test loss: 1.671, Test accuracy: 79.38
Round  32, Global train loss: 1.744, Global test loss: 1.656, Global test accuracy: 80.60
Round  33, Train loss: 1.625, Test loss: 1.670, Test accuracy: 79.46
Round  33, Global train loss: 1.625, Global test loss: 1.648, Global test accuracy: 81.52
Round  34, Train loss: 1.846, Test loss: 1.670, Test accuracy: 79.40
Round  34, Global train loss: 1.846, Global test loss: 1.656, Global test accuracy: 80.96
Round  35, Train loss: 1.791, Test loss: 1.671, Test accuracy: 79.24
Round  35, Global train loss: 1.791, Global test loss: 1.654, Global test accuracy: 80.68
Round  36, Train loss: 1.795, Test loss: 1.667, Test accuracy: 79.74
Round  36, Global train loss: 1.795, Global test loss: 1.659, Global test accuracy: 80.00
Round  37, Train loss: 1.785, Test loss: 1.667, Test accuracy: 79.68
Round  37, Global train loss: 1.785, Global test loss: 1.661, Global test accuracy: 81.00
Round  38, Train loss: 1.915, Test loss: 1.669, Test accuracy: 79.50
Round  38, Global train loss: 1.915, Global test loss: 1.663, Global test accuracy: 80.20
Round  39, Train loss: 1.735, Test loss: 1.670, Test accuracy: 79.36
Round  39, Global train loss: 1.735, Global test loss: 1.661, Global test accuracy: 80.06
Round  40, Train loss: 1.647, Test loss: 1.670, Test accuracy: 79.52
Round  40, Global train loss: 1.647, Global test loss: 1.659, Global test accuracy: 80.36
Round  41, Train loss: 1.866, Test loss: 1.668, Test accuracy: 79.66
Round  41, Global train loss: 1.866, Global test loss: 1.669, Global test accuracy: 79.36
Round  42, Train loss: 2.045, Test loss: 1.669, Test accuracy: 79.52
Round  42, Global train loss: 2.045, Global test loss: 1.681, Global test accuracy: 78.16
Round  43, Train loss: 1.925, Test loss: 1.668, Test accuracy: 79.66
Round  43, Global train loss: 1.925, Global test loss: 1.665, Global test accuracy: 80.26
Round  44, Train loss: 1.652, Test loss: 1.669, Test accuracy: 79.58
Round  44, Global train loss: 1.652, Global test loss: 1.657, Global test accuracy: 80.44
Round  45, Train loss: 1.695, Test loss: 1.668, Test accuracy: 79.46
Round  45, Global train loss: 1.695, Global test loss: 1.653, Global test accuracy: 81.02
Round  46, Train loss: 1.954, Test loss: 1.668, Test accuracy: 79.50
Round  46, Global train loss: 1.954, Global test loss: 1.669, Global test accuracy: 79.52
Round  47, Train loss: 1.732, Test loss: 1.668, Test accuracy: 79.46
Round  47, Global train loss: 1.732, Global test loss: 1.669, Global test accuracy: 79.52
Round  48, Train loss: 1.767, Test loss: 1.671, Test accuracy: 79.12
Round  48, Global train loss: 1.767, Global test loss: 1.666, Global test accuracy: 79.40
Round  49, Train loss: 1.947, Test loss: 1.669, Test accuracy: 79.28
Round  49, Global train loss: 1.947, Global test loss: 1.669, Global test accuracy: 79.40
Round  50, Train loss: 1.944, Test loss: 1.670, Test accuracy: 79.34
Round  50, Global train loss: 1.944, Global test loss: 1.672, Global test accuracy: 78.84
Round  51, Train loss: 1.649, Test loss: 1.670, Test accuracy: 79.28
Round  51, Global train loss: 1.649, Global test loss: 1.659, Global test accuracy: 80.14
Round  52, Train loss: 1.629, Test loss: 1.669, Test accuracy: 79.34
Round  52, Global train loss: 1.629, Global test loss: 1.662, Global test accuracy: 80.18
Round  53, Train loss: 1.616, Test loss: 1.669, Test accuracy: 79.32
Round  53, Global train loss: 1.616, Global test loss: 1.651, Global test accuracy: 81.14
Round  54, Train loss: 1.799, Test loss: 1.669, Test accuracy: 79.28
Round  54, Global train loss: 1.799, Global test loss: 1.656, Global test accuracy: 80.42
Round  55, Train loss: 1.660, Test loss: 1.669, Test accuracy: 79.28
Round  55, Global train loss: 1.660, Global test loss: 1.650, Global test accuracy: 80.96
Round  56, Train loss: 1.617, Test loss: 1.669, Test accuracy: 79.32
Round  56, Global train loss: 1.617, Global test loss: 1.647, Global test accuracy: 81.32
Round  57, Train loss: 1.599, Test loss: 1.667, Test accuracy: 79.48
Round  57, Global train loss: 1.599, Global test loss: 1.650, Global test accuracy: 81.24
Round  58, Train loss: 1.913, Test loss: 1.665, Test accuracy: 79.82
Round  58, Global train loss: 1.913, Global test loss: 1.662, Global test accuracy: 80.48
Round  59, Train loss: 1.801, Test loss: 1.667, Test accuracy: 79.70
Round  59, Global train loss: 1.801, Global test loss: 1.652, Global test accuracy: 80.94
Round  60, Train loss: 1.881, Test loss: 1.668, Test accuracy: 79.34
Round  60, Global train loss: 1.881, Global test loss: 1.664, Global test accuracy: 80.22
Round  61, Train loss: 1.568, Test loss: 1.668, Test accuracy: 79.24
Round  61, Global train loss: 1.568, Global test loss: 1.652, Global test accuracy: 81.10
Round  62, Train loss: 1.841, Test loss: 1.667, Test accuracy: 79.26
Round  62, Global train loss: 1.841, Global test loss: 1.652, Global test accuracy: 80.72
Round  63, Train loss: 1.772, Test loss: 1.666, Test accuracy: 79.44
Round  63, Global train loss: 1.772, Global test loss: 1.661, Global test accuracy: 80.20
Round  64, Train loss: 1.748, Test loss: 1.667, Test accuracy: 79.46
Round  64, Global train loss: 1.748, Global test loss: 1.661, Global test accuracy: 80.16
Round  65, Train loss: 1.814, Test loss: 1.671, Test accuracy: 78.94
Round  65, Global train loss: 1.814, Global test loss: 1.660, Global test accuracy: 80.60
Round  66, Train loss: 1.751, Test loss: 1.670, Test accuracy: 79.02
Round  66, Global train loss: 1.751, Global test loss: 1.665, Global test accuracy: 79.92
Round  67, Train loss: 1.731, Test loss: 1.670, Test accuracy: 79.06
Round  67, Global train loss: 1.731, Global test loss: 1.653, Global test accuracy: 80.38
Round  68, Train loss: 1.796, Test loss: 1.667, Test accuracy: 79.22
Round  68, Global train loss: 1.796, Global test loss: 1.663, Global test accuracy: 80.60
Round  69, Train loss: 1.597, Test loss: 1.668, Test accuracy: 79.24
Round  69, Global train loss: 1.597, Global test loss: 1.653, Global test accuracy: 80.86
Round  70, Train loss: 1.609, Test loss: 1.667, Test accuracy: 79.32
Round  70, Global train loss: 1.609, Global test loss: 1.651, Global test accuracy: 81.14
Round  71, Train loss: 1.897, Test loss: 1.666, Test accuracy: 79.56
Round  71, Global train loss: 1.897, Global test loss: 1.668, Global test accuracy: 79.20
Round  72, Train loss: 1.784, Test loss: 1.666, Test accuracy: 79.42
Round  72, Global train loss: 1.784, Global test loss: 1.657, Global test accuracy: 80.34
Round  73, Train loss: 1.792, Test loss: 1.666, Test accuracy: 79.46
Round  73, Global train loss: 1.792, Global test loss: 1.655, Global test accuracy: 80.46
Round  74, Train loss: 1.728, Test loss: 1.666, Test accuracy: 79.44
Round  74, Global train loss: 1.728, Global test loss: 1.652, Global test accuracy: 80.66
Round  75, Train loss: 1.905, Test loss: 1.666, Test accuracy: 79.48
Round  75, Global train loss: 1.905, Global test loss: 1.663, Global test accuracy: 79.62
Round  76, Train loss: 1.676, Test loss: 1.666, Test accuracy: 79.46
Round  76, Global train loss: 1.676, Global test loss: 1.652, Global test accuracy: 81.02
Round  77, Train loss: 1.811, Test loss: 1.665, Test accuracy: 79.64
Round  77, Global train loss: 1.811, Global test loss: 1.656, Global test accuracy: 80.96
Round  78, Train loss: 1.765, Test loss: 1.665, Test accuracy: 79.78
Round  78, Global train loss: 1.765, Global test loss: 1.657, Global test accuracy: 80.50
Round  79, Train loss: 1.894, Test loss: 1.664, Test accuracy: 79.90
Round  79, Global train loss: 1.894, Global test loss: 1.667, Global test accuracy: 79.28
Round  80, Train loss: 1.601, Test loss: 1.664, Test accuracy: 79.90
Round  80, Global train loss: 1.601, Global test loss: 1.651, Global test accuracy: 81.08
Round  81, Train loss: 1.876, Test loss: 1.663, Test accuracy: 79.98
Round  81, Global train loss: 1.876, Global test loss: 1.669, Global test accuracy: 79.70
Round  82, Train loss: 1.793, Test loss: 1.663, Test accuracy: 80.02
Round  82, Global train loss: 1.793, Global test loss: 1.653, Global test accuracy: 80.50
Round  83, Train loss: 1.718, Test loss: 1.663, Test accuracy: 80.04
Round  83, Global train loss: 1.718, Global test loss: 1.658, Global test accuracy: 80.16
Round  84, Train loss: 1.676, Test loss: 1.662, Test accuracy: 80.06
Round  84, Global train loss: 1.676, Global test loss: 1.654, Global test accuracy: 80.46
Round  85, Train loss: 1.656, Test loss: 1.662, Test accuracy: 80.08
Round  85, Global train loss: 1.656, Global test loss: 1.648, Global test accuracy: 81.22
Round  86, Train loss: 1.794, Test loss: 1.661, Test accuracy: 80.18
Round  86, Global train loss: 1.794, Global test loss: 1.648, Global test accuracy: 81.16
Round  87, Train loss: 1.705, Test loss: 1.661, Test accuracy: 80.22
Round  87, Global train loss: 1.705, Global test loss: 1.655, Global test accuracy: 80.48
Round  88, Train loss: 1.828, Test loss: 1.662, Test accuracy: 80.06
Round  88, Global train loss: 1.828, Global test loss: 1.667, Global test accuracy: 79.82
Round  89, Train loss: 1.795, Test loss: 1.662, Test accuracy: 80.00
Round  89, Global train loss: 1.795, Global test loss: 1.649, Global test accuracy: 81.30
Round  90, Train loss: 1.597, Test loss: 1.662, Test accuracy: 80.06
Round  90, Global train loss: 1.597, Global test loss: 1.650, Global test accuracy: 80.92
Round  91, Train loss: 1.597, Test loss: 1.662, Test accuracy: 80.02
Round  91, Global train loss: 1.597, Global test loss: 1.649, Global test accuracy: 81.24
Round  92, Train loss: 1.635, Test loss: 1.661, Test accuracy: 80.06
Round  92, Global train loss: 1.635, Global test loss: 1.651, Global test accuracy: 80.86
Round  93, Train loss: 1.761, Test loss: 1.659, Test accuracy: 80.28
Round  93, Global train loss: 1.761, Global test loss: 1.653, Global test accuracy: 80.96
Round  94, Train loss: 1.614, Test loss: 1.658, Test accuracy: 80.36
Round  94, Global train loss: 1.614, Global test loss: 1.645, Global test accuracy: 81.64
Round  95, Train loss: 1.862, Test loss: 1.658, Test accuracy: 80.30
Round  95, Global train loss: 1.862, Global test loss: 1.654, Global test accuracy: 80.48/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  96, Train loss: 1.861, Test loss: 1.658, Test accuracy: 80.30
Round  96, Global train loss: 1.861, Global test loss: 1.655, Global test accuracy: 80.36
Round  97, Train loss: 1.863, Test loss: 1.660, Test accuracy: 80.12
Round  97, Global train loss: 1.863, Global test loss: 1.663, Global test accuracy: 80.20
Round  98, Train loss: 1.671, Test loss: 1.660, Test accuracy: 80.02
Round  98, Global train loss: 1.671, Global test loss: 1.653, Global test accuracy: 80.56
Round  99, Train loss: 1.746, Test loss: 1.661, Test accuracy: 79.94
Round  99, Global train loss: 1.746, Global test loss: 1.659, Global test accuracy: 80.26
Final Round, Train loss: 1.744, Test loss: 1.662, Test accuracy: 79.98
Final Round, Global train loss: 1.744, Global test loss: 1.659, Global test accuracy: 80.26
Average accuracy final 10 rounds: 80.146 

Average global accuracy final 10 rounds: 80.74799999999999 

520.951352596283
[0.816408634185791, 1.632817268371582, 2.246291160583496, 2.85976505279541, 3.564545154571533, 4.269325256347656, 4.966763734817505, 5.6642022132873535, 6.384021759033203, 7.103841304779053, 7.828993558883667, 8.554145812988281, 9.29602599143982, 10.037906169891357, 10.775895833969116, 11.513885498046875, 12.25333857536316, 12.992791652679443, 13.72546124458313, 14.458130836486816, 15.198619842529297, 15.939108848571777, 16.67892551422119, 17.418742179870605, 18.15002179145813, 18.881301403045654, 19.62363290786743, 20.36596441268921, 21.06976294517517, 21.773561477661133, 22.476407766342163, 23.179254055023193, 23.88196063041687, 24.584667205810547, 25.28767991065979, 25.990692615509033, 26.6917986869812, 27.39290475845337, 28.09089159965515, 28.788878440856934, 29.491631269454956, 30.19438409805298, 30.903353691101074, 31.61232328414917, 32.21369481086731, 32.81506633758545, 33.417490005493164, 34.01991367340088, 34.62154769897461, 35.22318172454834, 35.82431721687317, 36.425452709198, 37.008697509765625, 37.59194231033325, 38.19212555885315, 38.79230880737305, 39.38811731338501, 39.98392581939697, 40.57277750968933, 41.16162919998169, 41.768983125686646, 42.3763370513916, 42.978426694869995, 43.58051633834839, 44.17006278038025, 44.75960922241211, 45.350679874420166, 45.94175052642822, 46.54336762428284, 47.14498472213745, 47.74541187286377, 48.34583902359009, 48.93851041793823, 49.53118181228638, 50.13398337364197, 50.73678493499756, 51.33986282348633, 51.9429407119751, 52.54389572143555, 53.144850730895996, 53.736488342285156, 54.328125953674316, 54.9284131526947, 55.52870035171509, 56.13431358337402, 56.73992681503296, 57.33500671386719, 57.930086612701416, 58.521029472351074, 59.11197233200073, 59.71454071998596, 60.31710910797119, 60.92009902000427, 61.52308893203735, 62.1150119304657, 62.70693492889404, 63.306577920913696, 63.90622091293335, 64.5104250907898, 65.11462926864624, 65.716228723526, 66.31782817840576, 66.90968418121338, 67.501540184021, 68.10530090332031, 68.70906162261963, 69.31433510780334, 69.91960859298706, 70.51524353027344, 71.11087846755981, 71.70267462730408, 72.29447078704834, 72.9001030921936, 73.50573539733887, 74.10938477516174, 74.71303415298462, 75.30501079559326, 75.8969874382019, 76.49468636512756, 77.09238529205322, 77.69748377799988, 78.30258226394653, 78.90455889701843, 79.50653553009033, 80.09789657592773, 80.68925762176514, 81.2956109046936, 81.90196418762207, 82.50583863258362, 83.10971307754517, 83.70628070831299, 84.30284833908081, 84.89662146568298, 85.49039459228516, 86.09581708908081, 86.70123958587646, 87.30277466773987, 87.90430974960327, 88.49687218666077, 89.08943462371826, 89.68476414680481, 90.28009366989136, 90.88591241836548, 91.4917311668396, 92.09271931648254, 92.69370746612549, 93.28671264648438, 93.87971782684326, 94.48541641235352, 95.09111499786377, 95.6944305896759, 96.29774618148804, 96.89793539047241, 97.49812459945679, 98.09247398376465, 98.68682336807251, 99.29217219352722, 99.89752101898193, 100.49966788291931, 101.10181474685669, 101.69447708129883, 102.28713941574097, 102.88084197044373, 103.47454452514648, 104.07705688476562, 104.67956924438477, 105.27872586250305, 105.87788248062134, 106.46910977363586, 107.06033706665039, 107.66411995887756, 108.26790285110474, 108.87344789505005, 109.47899293899536, 110.07714009284973, 110.6752872467041, 111.26719331741333, 111.85909938812256, 112.46219992637634, 113.06530046463013, 113.6686589717865, 114.27201747894287, 114.86294364929199, 115.45386981964111, 116.04499340057373, 116.63611698150635, 117.24163341522217, 117.84714984893799, 118.44802141189575, 119.04889297485352, 119.64073896408081, 120.2325849533081, 120.83471918106079, 121.43685340881348, 122.06502437591553, 122.69319534301758, 123.92543387413025, 125.15767240524292, 126.65656518936157, 128.15545797348022, 131.41955423355103, 134.68365049362183]
[16.66, 16.66, 13.94, 13.94, 12.4, 12.4, 13.88, 13.88, 16.46, 16.46, 20.1, 20.1, 31.66, 31.66, 42.62, 42.62, 54.06, 54.06, 56.72, 56.72, 68.2, 68.2, 71.86, 71.86, 72.68, 72.68, 73.44, 73.44, 73.06, 73.06, 73.28, 73.28, 77.9, 77.9, 77.8, 77.8, 78.62, 78.62, 79.1, 79.1, 79.22, 79.22, 79.26, 79.26, 79.38, 79.38, 79.2, 79.2, 79.48, 79.48, 78.66, 78.66, 78.78, 78.78, 78.64, 78.64, 78.54, 78.54, 78.58, 78.58, 78.72, 78.72, 79.14, 79.14, 79.38, 79.38, 79.46, 79.46, 79.4, 79.4, 79.24, 79.24, 79.74, 79.74, 79.68, 79.68, 79.5, 79.5, 79.36, 79.36, 79.52, 79.52, 79.66, 79.66, 79.52, 79.52, 79.66, 79.66, 79.58, 79.58, 79.46, 79.46, 79.5, 79.5, 79.46, 79.46, 79.12, 79.12, 79.28, 79.28, 79.34, 79.34, 79.28, 79.28, 79.34, 79.34, 79.32, 79.32, 79.28, 79.28, 79.28, 79.28, 79.32, 79.32, 79.48, 79.48, 79.82, 79.82, 79.7, 79.7, 79.34, 79.34, 79.24, 79.24, 79.26, 79.26, 79.44, 79.44, 79.46, 79.46, 78.94, 78.94, 79.02, 79.02, 79.06, 79.06, 79.22, 79.22, 79.24, 79.24, 79.32, 79.32, 79.56, 79.56, 79.42, 79.42, 79.46, 79.46, 79.44, 79.44, 79.48, 79.48, 79.46, 79.46, 79.64, 79.64, 79.78, 79.78, 79.9, 79.9, 79.9, 79.9, 79.98, 79.98, 80.02, 80.02, 80.04, 80.04, 80.06, 80.06, 80.08, 80.08, 80.18, 80.18, 80.22, 80.22, 80.06, 80.06, 80.0, 80.0, 80.06, 80.06, 80.02, 80.02, 80.06, 80.06, 80.28, 80.28, 80.36, 80.36, 80.3, 80.3, 80.3, 80.3, 80.12, 80.12, 80.02, 80.02, 79.94, 79.94, 79.98, 79.98]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.2 , level_n_lowerb:0.8  

   Client 8, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
prox
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.300, Test loss: 2.302, Test accuracy: 11.00
Round   0, Global train loss: 2.300, Global test loss: 2.302, Global test accuracy: 10.60
Round   1, Train loss: 2.300, Test loss: 2.300, Test accuracy: 11.26
Round   1, Global train loss: 2.300, Global test loss: 2.300, Global test accuracy: 10.62
Round   2, Train loss: 2.296, Test loss: 2.299, Test accuracy: 11.26
Round   2, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 10.26
Round   3, Train loss: 2.290, Test loss: 2.294, Test accuracy: 12.42
Round   3, Global train loss: 2.290, Global test loss: 2.289, Global test accuracy: 10.18
Round   4, Train loss: 2.268, Test loss: 2.276, Test accuracy: 12.56
Round   4, Global train loss: 2.268, Global test loss: 2.256, Global test accuracy: 17.68
Round   5, Train loss: 2.199, Test loss: 2.231, Test accuracy: 18.52
Round   5, Global train loss: 2.199, Global test loss: 2.179, Global test accuracy: 26.12
Round   6, Train loss: 2.172, Test loss: 2.195, Test accuracy: 23.24
Round   6, Global train loss: 2.172, Global test loss: 2.149, Global test accuracy: 27.48
Round   7, Train loss: 2.179, Test loss: 2.174, Test accuracy: 25.30
Round   7, Global train loss: 2.179, Global test loss: 2.148, Global test accuracy: 26.90
Round   8, Train loss: 2.057, Test loss: 2.101, Test accuracy: 35.14
Round   8, Global train loss: 2.057, Global test loss: 2.010, Global test accuracy: 46.66
Round   9, Train loss: 2.050, Test loss: 2.070, Test accuracy: 39.28
Round   9, Global train loss: 2.050, Global test loss: 1.967, Global test accuracy: 53.28
Round  10, Train loss: 2.041, Test loss: 2.002, Test accuracy: 47.08
Round  10, Global train loss: 2.041, Global test loss: 1.944, Global test accuracy: 54.70
Round  11, Train loss: 1.992, Test loss: 1.970, Test accuracy: 50.34
Round  11, Global train loss: 1.992, Global test loss: 1.918, Global test accuracy: 56.94
Round  12, Train loss: 2.097, Test loss: 1.970, Test accuracy: 50.26
Round  12, Global train loss: 2.097, Global test loss: 1.965, Global test accuracy: 53.08
Round  13, Train loss: 2.023, Test loss: 1.959, Test accuracy: 50.72
Round  13, Global train loss: 2.023, Global test loss: 1.917, Global test accuracy: 56.44
Round  14, Train loss: 2.003, Test loss: 1.953, Test accuracy: 51.34
Round  14, Global train loss: 2.003, Global test loss: 1.905, Global test accuracy: 56.80
Round  15, Train loss: 1.985, Test loss: 1.950, Test accuracy: 51.80
Round  15, Global train loss: 1.985, Global test loss: 1.887, Global test accuracy: 58.48
Round  16, Train loss: 1.866, Test loss: 1.917, Test accuracy: 55.32
Round  16, Global train loss: 1.866, Global test loss: 1.832, Global test accuracy: 64.50
Round  17, Train loss: 1.837, Test loss: 1.906, Test accuracy: 56.16
Round  17, Global train loss: 1.837, Global test loss: 1.820, Global test accuracy: 65.04
Round  18, Train loss: 1.799, Test loss: 1.883, Test accuracy: 58.04
Round  18, Global train loss: 1.799, Global test loss: 1.814, Global test accuracy: 65.18
Round  19, Train loss: 1.967, Test loss: 1.868, Test accuracy: 59.48
Round  19, Global train loss: 1.967, Global test loss: 1.830, Global test accuracy: 64.24
Round  20, Train loss: 1.929, Test loss: 1.864, Test accuracy: 59.76
Round  20, Global train loss: 1.929, Global test loss: 1.834, Global test accuracy: 63.72
Round  21, Train loss: 1.930, Test loss: 1.862, Test accuracy: 60.06
Round  21, Global train loss: 1.930, Global test loss: 1.831, Global test accuracy: 64.02
Round  22, Train loss: 1.914, Test loss: 1.864, Test accuracy: 59.90
Round  22, Global train loss: 1.914, Global test loss: 1.842, Global test accuracy: 62.68
Round  23, Train loss: 1.982, Test loss: 1.862, Test accuracy: 60.10
Round  23, Global train loss: 1.982, Global test loss: 1.901, Global test accuracy: 57.76
Round  24, Train loss: 1.869, Test loss: 1.859, Test accuracy: 60.50
Round  24, Global train loss: 1.869, Global test loss: 1.830, Global test accuracy: 64.24
Round  25, Train loss: 1.910, Test loss: 1.851, Test accuracy: 61.14
Round  25, Global train loss: 1.910, Global test loss: 1.826, Global test accuracy: 64.32
Round  26, Train loss: 1.976, Test loss: 1.855, Test accuracy: 60.76
Round  26, Global train loss: 1.976, Global test loss: 1.901, Global test accuracy: 57.98
Round  27, Train loss: 1.899, Test loss: 1.859, Test accuracy: 60.28
Round  27, Global train loss: 1.899, Global test loss: 1.839, Global test accuracy: 63.04
Round  28, Train loss: 1.956, Test loss: 1.858, Test accuracy: 60.48
Round  28, Global train loss: 1.956, Global test loss: 1.907, Global test accuracy: 57.66
Round  29, Train loss: 1.864, Test loss: 1.863, Test accuracy: 59.58
Round  29, Global train loss: 1.864, Global test loss: 1.830, Global test accuracy: 64.08
Round  30, Train loss: 1.876, Test loss: 1.864, Test accuracy: 59.72
Round  30, Global train loss: 1.876, Global test loss: 1.828, Global test accuracy: 64.02
Round  31, Train loss: 1.934, Test loss: 1.861, Test accuracy: 60.22
Round  31, Global train loss: 1.934, Global test loss: 1.889, Global test accuracy: 58.96
Round  32, Train loss: 1.862, Test loss: 1.863, Test accuracy: 60.00
Round  32, Global train loss: 1.862, Global test loss: 1.837, Global test accuracy: 63.14
Round  33, Train loss: 1.851, Test loss: 1.861, Test accuracy: 60.26
Round  33, Global train loss: 1.851, Global test loss: 1.826, Global test accuracy: 63.72
Round  34, Train loss: 1.771, Test loss: 1.859, Test accuracy: 60.42
Round  34, Global train loss: 1.771, Global test loss: 1.808, Global test accuracy: 65.38
Round  35, Train loss: 1.758, Test loss: 1.858, Test accuracy: 60.50
Round  35, Global train loss: 1.758, Global test loss: 1.804, Global test accuracy: 65.32
Round  36, Train loss: 1.896, Test loss: 1.850, Test accuracy: 61.12
Round  36, Global train loss: 1.896, Global test loss: 1.821, Global test accuracy: 64.16
Round  37, Train loss: 1.792, Test loss: 1.851, Test accuracy: 61.10
Round  37, Global train loss: 1.792, Global test loss: 1.808, Global test accuracy: 65.44
Round  38, Train loss: 1.753, Test loss: 1.850, Test accuracy: 61.20
Round  38, Global train loss: 1.753, Global test loss: 1.803, Global test accuracy: 65.68
Round  39, Train loss: 1.848, Test loss: 1.849, Test accuracy: 61.02
Round  39, Global train loss: 1.848, Global test loss: 1.815, Global test accuracy: 64.08
Round  40, Train loss: 1.927, Test loss: 1.847, Test accuracy: 61.40
Round  40, Global train loss: 1.927, Global test loss: 1.912, Global test accuracy: 55.18
Round  41, Train loss: 1.732, Test loss: 1.839, Test accuracy: 62.46
Round  41, Global train loss: 1.732, Global test loss: 1.768, Global test accuracy: 69.94
Round  42, Train loss: 1.722, Test loss: 1.830, Test accuracy: 63.40
Round  42, Global train loss: 1.722, Global test loss: 1.753, Global test accuracy: 71.32
Round  43, Train loss: 1.710, Test loss: 1.823, Test accuracy: 64.14
Round  43, Global train loss: 1.710, Global test loss: 1.747, Global test accuracy: 71.82
Round  44, Train loss: 1.825, Test loss: 1.817, Test accuracy: 64.64
Round  44, Global train loss: 1.825, Global test loss: 1.777, Global test accuracy: 69.02
Round  45, Train loss: 1.801, Test loss: 1.812, Test accuracy: 65.24
Round  45, Global train loss: 1.801, Global test loss: 1.795, Global test accuracy: 66.88
Round  46, Train loss: 1.747, Test loss: 1.807, Test accuracy: 65.92
Round  46, Global train loss: 1.747, Global test loss: 1.752, Global test accuracy: 71.86
Round  47, Train loss: 1.806, Test loss: 1.808, Test accuracy: 65.80
Round  47, Global train loss: 1.806, Global test loss: 1.772, Global test accuracy: 69.84
Round  48, Train loss: 1.777, Test loss: 1.807, Test accuracy: 65.94
Round  48, Global train loss: 1.777, Global test loss: 1.785, Global test accuracy: 68.46
Round  49, Train loss: 1.736, Test loss: 1.807, Test accuracy: 65.92
Round  49, Global train loss: 1.736, Global test loss: 1.749, Global test accuracy: 72.18
Round  50, Train loss: 1.729, Test loss: 1.806, Test accuracy: 66.04
Round  50, Global train loss: 1.729, Global test loss: 1.746, Global test accuracy: 72.24
Round  51, Train loss: 1.793, Test loss: 1.803, Test accuracy: 66.42
Round  51, Global train loss: 1.793, Global test loss: 1.781, Global test accuracy: 68.34
Round  52, Train loss: 1.915, Test loss: 1.798, Test accuracy: 66.94
Round  52, Global train loss: 1.915, Global test loss: 1.888, Global test accuracy: 57.46
Round  53, Train loss: 1.776, Test loss: 1.800, Test accuracy: 66.64
Round  53, Global train loss: 1.776, Global test loss: 1.785, Global test accuracy: 68.04
Round  54, Train loss: 1.718, Test loss: 1.800, Test accuracy: 66.64
Round  54, Global train loss: 1.718, Global test loss: 1.741, Global test accuracy: 72.88
Round  55, Train loss: 1.687, Test loss: 1.799, Test accuracy: 66.90
Round  55, Global train loss: 1.687, Global test loss: 1.737, Global test accuracy: 73.04
Round  56, Train loss: 1.662, Test loss: 1.798, Test accuracy: 66.92
Round  56, Global train loss: 1.662, Global test loss: 1.733, Global test accuracy: 73.02
Round  57, Train loss: 1.898, Test loss: 1.802, Test accuracy: 66.30
Round  57, Global train loss: 1.898, Global test loss: 1.864, Global test accuracy: 59.72
Round  58, Train loss: 1.806, Test loss: 1.802, Test accuracy: 66.24
Round  58, Global train loss: 1.806, Global test loss: 1.783, Global test accuracy: 68.86
Round  59, Train loss: 1.678, Test loss: 1.802, Test accuracy: 66.24
Round  59, Global train loss: 1.678, Global test loss: 1.739, Global test accuracy: 72.88
Round  60, Train loss: 1.768, Test loss: 1.795, Test accuracy: 67.02
Round  60, Global train loss: 1.768, Global test loss: 1.756, Global test accuracy: 71.02
Round  61, Train loss: 1.776, Test loss: 1.793, Test accuracy: 67.34
Round  61, Global train loss: 1.776, Global test loss: 1.763, Global test accuracy: 70.68
Round  62, Train loss: 1.698, Test loss: 1.791, Test accuracy: 67.38
Round  62, Global train loss: 1.698, Global test loss: 1.739, Global test accuracy: 72.72
Round  63, Train loss: 1.691, Test loss: 1.792, Test accuracy: 67.38
Round  63, Global train loss: 1.691, Global test loss: 1.732, Global test accuracy: 73.44
Round  64, Train loss: 1.793, Test loss: 1.794, Test accuracy: 66.88
Round  64, Global train loss: 1.793, Global test loss: 1.769, Global test accuracy: 70.04
Round  65, Train loss: 1.679, Test loss: 1.794, Test accuracy: 66.88
Round  65, Global train loss: 1.679, Global test loss: 1.738, Global test accuracy: 72.94
Round  66, Train loss: 1.872, Test loss: 1.787, Test accuracy: 67.60
Round  66, Global train loss: 1.872, Global test loss: 1.836, Global test accuracy: 62.20
Round  67, Train loss: 1.651, Test loss: 1.788, Test accuracy: 67.60
Round  67, Global train loss: 1.651, Global test loss: 1.734, Global test accuracy: 72.90
Round  68, Train loss: 1.709, Test loss: 1.788, Test accuracy: 67.70
Round  68, Global train loss: 1.709, Global test loss: 1.742, Global test accuracy: 72.06
Round  69, Train loss: 1.793, Test loss: 1.792, Test accuracy: 67.26
Round  69, Global train loss: 1.793, Global test loss: 1.782, Global test accuracy: 67.68
Round  70, Train loss: 1.779, Test loss: 1.788, Test accuracy: 67.64
Round  70, Global train loss: 1.779, Global test loss: 1.779, Global test accuracy: 68.30
Round  71, Train loss: 1.772, Test loss: 1.790, Test accuracy: 67.48
Round  71, Global train loss: 1.772, Global test loss: 1.768, Global test accuracy: 69.52
Round  72, Train loss: 1.770, Test loss: 1.787, Test accuracy: 67.82
Round  72, Global train loss: 1.770, Global test loss: 1.768, Global test accuracy: 70.10
Round  73, Train loss: 1.781, Test loss: 1.785, Test accuracy: 67.98
Round  73, Global train loss: 1.781, Global test loss: 1.778, Global test accuracy: 68.66
Round  74, Train loss: 1.646, Test loss: 1.786, Test accuracy: 67.90
Round  74, Global train loss: 1.646, Global test loss: 1.734, Global test accuracy: 72.96
Round  75, Train loss: 1.686, Test loss: 1.784, Test accuracy: 68.04
Round  75, Global train loss: 1.686, Global test loss: 1.737, Global test accuracy: 72.68
Round  76, Train loss: 1.773, Test loss: 1.787, Test accuracy: 67.52
Round  76, Global train loss: 1.773, Global test loss: 1.775, Global test accuracy: 69.00
Round  77, Train loss: 1.669, Test loss: 1.788, Test accuracy: 67.32
Round  77, Global train loss: 1.669, Global test loss: 1.738, Global test accuracy: 72.56
Round  78, Train loss: 1.669, Test loss: 1.787, Test accuracy: 67.48
Round  78, Global train loss: 1.669, Global test loss: 1.735, Global test accuracy: 72.48
Round  79, Train loss: 1.763, Test loss: 1.786, Test accuracy: 67.60
Round  79, Global train loss: 1.763, Global test loss: 1.759, Global test accuracy: 70.64
Round  80, Train loss: 1.688, Test loss: 1.790, Test accuracy: 67.14
Round  80, Global train loss: 1.688, Global test loss: 1.738, Global test accuracy: 72.74
Round  81, Train loss: 1.665, Test loss: 1.789, Test accuracy: 67.20
Round  81, Global train loss: 1.665, Global test loss: 1.733, Global test accuracy: 73.22
Round  82, Train loss: 1.682, Test loss: 1.789, Test accuracy: 67.26
Round  82, Global train loss: 1.682, Global test loss: 1.736, Global test accuracy: 72.24
Round  83, Train loss: 1.772, Test loss: 1.784, Test accuracy: 67.88
Round  83, Global train loss: 1.772, Global test loss: 1.761, Global test accuracy: 70.38
Round  84, Train loss: 1.764, Test loss: 1.786, Test accuracy: 67.64
Round  84, Global train loss: 1.764, Global test loss: 1.751, Global test accuracy: 71.58
Round  85, Train loss: 1.659, Test loss: 1.788, Test accuracy: 67.48
Round  85, Global train loss: 1.659, Global test loss: 1.737, Global test accuracy: 72.60
Round  86, Train loss: 1.674, Test loss: 1.789, Test accuracy: 67.22
Round  86, Global train loss: 1.674, Global test loss: 1.732, Global test accuracy: 73.30
Round  87, Train loss: 1.781, Test loss: 1.787, Test accuracy: 67.44
Round  87, Global train loss: 1.781, Global test loss: 1.769, Global test accuracy: 69.82
Round  88, Train loss: 1.758, Test loss: 1.786, Test accuracy: 67.50
Round  88, Global train loss: 1.758, Global test loss: 1.756, Global test accuracy: 70.98
Round  89, Train loss: 1.674, Test loss: 1.786, Test accuracy: 67.42
Round  89, Global train loss: 1.674, Global test loss: 1.733, Global test accuracy: 72.68
Round  90, Train loss: 1.852, Test loss: 1.780, Test accuracy: 68.10
Round  90, Global train loss: 1.852, Global test loss: 1.811, Global test accuracy: 65.44
Round  91, Train loss: 1.845, Test loss: 1.782, Test accuracy: 67.98
Round  91, Global train loss: 1.845, Global test loss: 1.825, Global test accuracy: 63.76
Round  92, Train loss: 1.792, Test loss: 1.784, Test accuracy: 67.84
Round  92, Global train loss: 1.792, Global test loss: 1.793, Global test accuracy: 67.50
Round  93, Train loss: 1.755, Test loss: 1.783, Test accuracy: 67.82
Round  93, Global train loss: 1.755, Global test loss: 1.758, Global test accuracy: 71.12
Round  94, Train loss: 1.652, Test loss: 1.783, Test accuracy: 67.82
Round  94, Global train loss: 1.652, Global test loss: 1.733, Global test accuracy: 73.04
Round  95, Train loss: 1.661, Test loss: 1.782, Test accuracy: 67.96
Round  95, Global train loss: 1.661, Global test loss: 1.731, Global test accuracy: 72.82/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  96, Train loss: 1.660, Test loss: 1.782, Test accuracy: 67.94
Round  96, Global train loss: 1.660, Global test loss: 1.730, Global test accuracy: 72.98
Round  97, Train loss: 1.741, Test loss: 1.780, Test accuracy: 68.30
Round  97, Global train loss: 1.741, Global test loss: 1.749, Global test accuracy: 71.44
Round  98, Train loss: 1.774, Test loss: 1.780, Test accuracy: 68.06
Round  98, Global train loss: 1.774, Global test loss: 1.792, Global test accuracy: 67.10
Round  99, Train loss: 1.781, Test loss: 1.780, Test accuracy: 68.06
Round  99, Global train loss: 1.781, Global test loss: 1.771, Global test accuracy: 69.14
Final Round, Train loss: 1.720, Test loss: 1.781, Test accuracy: 68.08
Final Round, Global train loss: 1.720, Global test loss: 1.771, Global test accuracy: 69.14
Average accuracy final 10 rounds: 67.988 

Average global accuracy final 10 rounds: 69.434 

686.8968405723572
[1.753535270690918, 3.507070541381836, 5.207177400588989, 6.907284259796143, 8.591765403747559, 10.276246547698975, 11.618974924087524, 12.961703300476074, 13.799353837966919, 14.637004375457764, 15.474764585494995, 16.312524795532227, 17.14876389503479, 17.985002994537354, 18.81917452812195, 19.653346061706543, 20.49085569381714, 21.328365325927734, 22.178969144821167, 23.0295729637146, 23.865928411483765, 24.70228385925293, 25.53497862815857, 26.36767339706421, 27.206584453582764, 28.04549551010132, 28.877994060516357, 29.710492610931396, 30.543541193008423, 31.37658977508545, 32.29050040245056, 33.204411029815674, 34.05228090286255, 34.900150775909424, 35.754985094070435, 36.609819412231445, 37.46573543548584, 38.321651458740234, 39.18076753616333, 40.039883613586426, 40.891507148742676, 41.743130683898926, 42.580276012420654, 43.41742134094238, 44.26473951339722, 45.11205768585205, 45.96412897109985, 46.816200256347656, 47.67470645904541, 48.533212661743164, 49.38439226150513, 50.23557186126709, 51.0859956741333, 51.93641948699951, 52.7909095287323, 53.64539957046509, 54.51538395881653, 55.38536834716797, 56.255035638809204, 57.12470293045044, 57.99210214614868, 58.859501361846924, 59.725409746170044, 60.591318130493164, 61.45963001251221, 62.32794189453125, 63.18941903114319, 64.05089616775513, 65.74263048171997, 67.43436479568481, 69.10756206512451, 70.78075933456421, 72.12100410461426, 73.4612488746643, 74.33481454849243, 75.20838022232056, 76.0701174736023, 76.93185472488403, 77.88579654693604, 78.83973836898804, 80.35688209533691, 81.87402582168579, 83.54519581794739, 85.21636581420898, 86.64112281799316, 88.06587982177734, 89.6264500617981, 91.18702030181885, 92.81389379501343, 94.44076728820801, 95.3068675994873, 96.1729679107666, 97.03755497932434, 97.90214204788208, 98.75889706611633, 99.61565208435059, 100.45704007148743, 101.29842805862427, 102.12461638450623, 102.95080471038818, 103.89189410209656, 104.83298349380493, 105.78762936592102, 106.74227523803711, 107.68132710456848, 108.62037897109985, 109.5888295173645, 110.55728006362915, 111.4913957118988, 112.42551136016846, 113.32340216636658, 114.2212929725647, 115.13235640525818, 116.04341983795166, 116.98568892478943, 117.9279580116272, 118.88896250724792, 119.84996700286865, 120.77634787559509, 121.70272874832153, 122.62477135658264, 123.54681396484375, 124.47491574287415, 125.40301752090454, 126.40104627609253, 127.39907503128052, 128.44792580604553, 129.49677658081055, 130.43805146217346, 131.37932634353638, 132.3110272884369, 133.2427282333374, 134.1660451889038, 135.08936214447021, 136.05129671096802, 137.01323127746582, 137.98690128326416, 138.9605712890625, 139.94082975387573, 140.92108821868896, 141.87531924247742, 142.82955026626587, 143.7666153907776, 144.7036805152893, 145.6721646785736, 146.6406488418579, 147.54770612716675, 148.4547634124756, 149.36827278137207, 150.28178215026855, 151.2970073223114, 152.31223249435425, 153.22976350784302, 154.1472945213318, 155.12637782096863, 156.10546112060547, 157.03471612930298, 157.9639711380005, 158.93012046813965, 159.8962697982788, 160.89122366905212, 161.88617753982544, 162.81776189804077, 163.7493462562561, 164.65930485725403, 165.56926345825195, 166.50942277908325, 167.44958209991455, 168.40935635566711, 169.36913061141968, 170.31316137313843, 171.25719213485718, 172.19954442977905, 173.14189672470093, 174.06037282943726, 174.97884893417358, 175.89772820472717, 176.81660747528076, 177.71387887001038, 178.61115026474, 179.5183765888214, 180.42560291290283, 181.33842206001282, 182.2512412071228, 183.13969111442566, 184.02814102172852, 184.91347336769104, 185.79880571365356, 186.75898790359497, 187.71917009353638, 188.63831496238708, 189.5574598312378, 190.48144555091858, 191.40543127059937, 192.28887963294983, 193.1723279953003, 194.06739377975464, 194.96245956420898, 195.8644323348999, 196.76640510559082, 198.63819241523743, 200.50997972488403]
[11.0, 11.0, 11.26, 11.26, 11.26, 11.26, 12.42, 12.42, 12.56, 12.56, 18.52, 18.52, 23.24, 23.24, 25.3, 25.3, 35.14, 35.14, 39.28, 39.28, 47.08, 47.08, 50.34, 50.34, 50.26, 50.26, 50.72, 50.72, 51.34, 51.34, 51.8, 51.8, 55.32, 55.32, 56.16, 56.16, 58.04, 58.04, 59.48, 59.48, 59.76, 59.76, 60.06, 60.06, 59.9, 59.9, 60.1, 60.1, 60.5, 60.5, 61.14, 61.14, 60.76, 60.76, 60.28, 60.28, 60.48, 60.48, 59.58, 59.58, 59.72, 59.72, 60.22, 60.22, 60.0, 60.0, 60.26, 60.26, 60.42, 60.42, 60.5, 60.5, 61.12, 61.12, 61.1, 61.1, 61.2, 61.2, 61.02, 61.02, 61.4, 61.4, 62.46, 62.46, 63.4, 63.4, 64.14, 64.14, 64.64, 64.64, 65.24, 65.24, 65.92, 65.92, 65.8, 65.8, 65.94, 65.94, 65.92, 65.92, 66.04, 66.04, 66.42, 66.42, 66.94, 66.94, 66.64, 66.64, 66.64, 66.64, 66.9, 66.9, 66.92, 66.92, 66.3, 66.3, 66.24, 66.24, 66.24, 66.24, 67.02, 67.02, 67.34, 67.34, 67.38, 67.38, 67.38, 67.38, 66.88, 66.88, 66.88, 66.88, 67.6, 67.6, 67.6, 67.6, 67.7, 67.7, 67.26, 67.26, 67.64, 67.64, 67.48, 67.48, 67.82, 67.82, 67.98, 67.98, 67.9, 67.9, 68.04, 68.04, 67.52, 67.52, 67.32, 67.32, 67.48, 67.48, 67.6, 67.6, 67.14, 67.14, 67.2, 67.2, 67.26, 67.26, 67.88, 67.88, 67.64, 67.64, 67.48, 67.48, 67.22, 67.22, 67.44, 67.44, 67.5, 67.5, 67.42, 67.42, 68.1, 68.1, 67.98, 67.98, 67.84, 67.84, 67.82, 67.82, 67.82, 67.82, 67.96, 67.96, 67.94, 67.94, 68.3, 68.3, 68.06, 68.06, 68.06, 68.06, 68.08, 68.08]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.2 , level_n_lowerb:0.8  

   Client 3, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Traceback (most recent call last):
  File "main_fedpac_co_teaching.py", line 250, in <module>
    local.filter_data(net=net_local.to(args.device), net2=net_local2.to(args.device), concept_matrix_local = concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1587, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

   Client 0, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.320, Test loss: 2.301, Test accuracy: 10.30
Round   0, Global train loss: 2.320, Global test loss: 2.301, Global test accuracy: 10.24
Round   1, Train loss: 2.300, Test loss: 2.299, Test accuracy: 15.18
Round   1, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 15.38
Round   2, Train loss: 2.299, Test loss: 2.298, Test accuracy: 19.72
Round   2, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 20.46
Round   3, Train loss: 2.296, Test loss: 2.296, Test accuracy: 21.14
Round   3, Global train loss: 2.296, Global test loss: 2.296, Global test accuracy: 19.80
Round   4, Train loss: 2.292, Test loss: 2.293, Test accuracy: 17.72
Round   4, Global train loss: 2.292, Global test loss: 2.293, Global test accuracy: 15.44
Round   5, Train loss: 2.287, Test loss: 2.290, Test accuracy: 16.16
Round   5, Global train loss: 2.287, Global test loss: 2.289, Global test accuracy: 14.94
Round   6, Train loss: 2.289, Test loss: 2.285, Test accuracy: 26.84
Round   6, Global train loss: 2.289, Global test loss: 2.284, Global test accuracy: 33.34
Round   7, Train loss: 2.278, Test loss: 2.276, Test accuracy: 30.26
Round   7, Global train loss: 2.278, Global test loss: 2.275, Global test accuracy: 36.20
Round   8, Train loss: 2.262, Test loss: 2.270, Test accuracy: 19.32
Round   8, Global train loss: 2.262, Global test loss: 2.269, Global test accuracy: 19.70
Round   9, Train loss: 2.245, Test loss: 2.251, Test accuracy: 19.64
Round   9, Global train loss: 2.245, Global test loss: 2.248, Global test accuracy: 13.44
Round  10, Train loss: 2.229, Test loss: 2.200, Test accuracy: 38.80
Round  10, Global train loss: 2.229, Global test loss: 2.187, Global test accuracy: 43.80
Round  11, Train loss: 2.196, Test loss: 2.171, Test accuracy: 40.02
Round  11, Global train loss: 2.196, Global test loss: 2.165, Global test accuracy: 43.06
Round  12, Train loss: 2.093, Test loss: 2.080, Test accuracy: 44.08
Round  12, Global train loss: 2.093, Global test loss: 2.026, Global test accuracy: 47.46
Round  13, Train loss: 2.047, Test loss: 2.030, Test accuracy: 46.64
Round  13, Global train loss: 2.047, Global test loss: 1.981, Global test accuracy: 53.12
Round  14, Train loss: 2.026, Test loss: 2.000, Test accuracy: 51.76
Round  14, Global train loss: 2.026, Global test loss: 1.936, Global test accuracy: 60.26
Round  15, Train loss: 1.957, Test loss: 1.962, Test accuracy: 56.00
Round  15, Global train loss: 1.957, Global test loss: 1.895, Global test accuracy: 62.24
Round  16, Train loss: 1.962, Test loss: 1.936, Test accuracy: 57.30
Round  16, Global train loss: 1.962, Global test loss: 1.875, Global test accuracy: 62.90
Round  17, Train loss: 2.034, Test loss: 1.934, Test accuracy: 57.62
Round  17, Global train loss: 2.034, Global test loss: 1.913, Global test accuracy: 63.26
Round  18, Train loss: 2.052, Test loss: 1.927, Test accuracy: 57.66
Round  18, Global train loss: 2.052, Global test loss: 1.951, Global test accuracy: 62.08
Round  19, Train loss: 1.921, Test loss: 1.900, Test accuracy: 60.54
Round  19, Global train loss: 1.921, Global test loss: 1.835, Global test accuracy: 67.90
Round  20, Train loss: 1.855, Test loss: 1.873, Test accuracy: 63.84
Round  20, Global train loss: 1.855, Global test loss: 1.800, Global test accuracy: 72.32
Round  21, Train loss: 1.823, Test loss: 1.843, Test accuracy: 67.74
Round  21, Global train loss: 1.823, Global test loss: 1.762, Global test accuracy: 77.84
Round  22, Train loss: 1.803, Test loss: 1.822, Test accuracy: 70.02
Round  22, Global train loss: 1.803, Global test loss: 1.739, Global test accuracy: 79.72
Round  23, Train loss: 1.874, Test loss: 1.824, Test accuracy: 70.78
Round  23, Global train loss: 1.874, Global test loss: 1.811, Global test accuracy: 74.70
Round  24, Train loss: 1.802, Test loss: 1.797, Test accuracy: 71.88
Round  24, Global train loss: 1.802, Global test loss: 1.724, Global test accuracy: 80.48
Round  25, Train loss: 1.829, Test loss: 1.784, Test accuracy: 73.14
Round  25, Global train loss: 1.829, Global test loss: 1.717, Global test accuracy: 80.94
Round  26, Train loss: 1.709, Test loss: 1.776, Test accuracy: 73.22
Round  26, Global train loss: 1.709, Global test loss: 1.698, Global test accuracy: 80.46
Round  27, Train loss: 1.739, Test loss: 1.767, Test accuracy: 74.06
Round  27, Global train loss: 1.739, Global test loss: 1.687, Global test accuracy: 81.48
Round  28, Train loss: 1.670, Test loss: 1.757, Test accuracy: 74.94
Round  28, Global train loss: 1.670, Global test loss: 1.667, Global test accuracy: 85.54
Round  29, Train loss: 1.735, Test loss: 1.746, Test accuracy: 75.50
Round  29, Global train loss: 1.735, Global test loss: 1.676, Global test accuracy: 81.52
Round  30, Train loss: 1.901, Test loss: 1.760, Test accuracy: 75.34
Round  30, Global train loss: 1.901, Global test loss: 1.746, Global test accuracy: 77.68
Round  31, Train loss: 1.793, Test loss: 1.764, Test accuracy: 75.16
Round  31, Global train loss: 1.793, Global test loss: 1.697, Global test accuracy: 86.46
Round  32, Train loss: 1.843, Test loss: 1.765, Test accuracy: 75.52
Round  32, Global train loss: 1.843, Global test loss: 1.718, Global test accuracy: 83.98
Round  33, Train loss: 1.714, Test loss: 1.748, Test accuracy: 75.72
Round  33, Global train loss: 1.714, Global test loss: 1.660, Global test accuracy: 85.90
Round  34, Train loss: 1.764, Test loss: 1.733, Test accuracy: 77.10
Round  34, Global train loss: 1.764, Global test loss: 1.655, Global test accuracy: 86.74
Round  35, Train loss: 1.892, Test loss: 1.742, Test accuracy: 77.44
Round  35, Global train loss: 1.892, Global test loss: 1.726, Global test accuracy: 83.38
Round  36, Train loss: 1.722, Test loss: 1.726, Test accuracy: 79.32
Round  36, Global train loss: 1.722, Global test loss: 1.631, Global test accuracy: 89.36
Round  37, Train loss: 1.738, Test loss: 1.707, Test accuracy: 80.54
Round  37, Global train loss: 1.738, Global test loss: 1.623, Global test accuracy: 90.36
Round  38, Train loss: 1.895, Test loss: 1.717, Test accuracy: 80.34
Round  38, Global train loss: 1.895, Global test loss: 1.717, Global test accuracy: 84.34
Round  39, Train loss: 1.805, Test loss: 1.725, Test accuracy: 80.36
Round  39, Global train loss: 1.805, Global test loss: 1.681, Global test accuracy: 87.30
Round  40, Train loss: 1.590, Test loss: 1.706, Test accuracy: 80.76
Round  40, Global train loss: 1.590, Global test loss: 1.607, Global test accuracy: 89.70
Round  41, Train loss: 1.884, Test loss: 1.707, Test accuracy: 80.74
Round  41, Global train loss: 1.884, Global test loss: 1.714, Global test accuracy: 84.22
Round  42, Train loss: 1.920, Test loss: 1.715, Test accuracy: 80.66
Round  42, Global train loss: 1.920, Global test loss: 1.747, Global test accuracy: 82.12
Round  43, Train loss: 1.917, Test loss: 1.719, Test accuracy: 80.30
Round  43, Global train loss: 1.917, Global test loss: 1.731, Global test accuracy: 84.86
Round  44, Train loss: 1.648, Test loss: 1.695, Test accuracy: 81.12
Round  44, Global train loss: 1.648, Global test loss: 1.603, Global test accuracy: 90.96
Round  45, Train loss: 1.634, Test loss: 1.685, Test accuracy: 81.52
Round  45, Global train loss: 1.634, Global test loss: 1.595, Global test accuracy: 90.90
Round  46, Train loss: 1.745, Test loss: 1.681, Test accuracy: 81.64
Round  46, Global train loss: 1.745, Global test loss: 1.601, Global test accuracy: 91.00
Round  47, Train loss: 1.631, Test loss: 1.680, Test accuracy: 81.48
Round  47, Global train loss: 1.631, Global test loss: 1.585, Global test accuracy: 91.44
Round  48, Train loss: 1.790, Test loss: 1.693, Test accuracy: 81.14
Round  48, Global train loss: 1.790, Global test loss: 1.665, Global test accuracy: 88.02
Round  49, Train loss: 1.732, Test loss: 1.684, Test accuracy: 81.76
Round  49, Global train loss: 1.732, Global test loss: 1.599, Global test accuracy: 91.32
Round  50, Train loss: 1.720, Test loss: 1.682, Test accuracy: 81.90
Round  50, Global train loss: 1.720, Global test loss: 1.594, Global test accuracy: 91.28
Round  51, Train loss: 1.775, Test loss: 1.691, Test accuracy: 81.56
Round  51, Global train loss: 1.775, Global test loss: 1.680, Global test accuracy: 87.76
Round  52, Train loss: 1.559, Test loss: 1.679, Test accuracy: 81.70
Round  52, Global train loss: 1.559, Global test loss: 1.582, Global test accuracy: 90.94
Round  53, Train loss: 1.782, Test loss: 1.686, Test accuracy: 81.80
Round  53, Global train loss: 1.782, Global test loss: 1.678, Global test accuracy: 86.34
Round  54, Train loss: 1.717, Test loss: 1.675, Test accuracy: 82.28
Round  54, Global train loss: 1.717, Global test loss: 1.591, Global test accuracy: 91.36
Round  55, Train loss: 1.661, Test loss: 1.672, Test accuracy: 82.34
Round  55, Global train loss: 1.661, Global test loss: 1.587, Global test accuracy: 91.14
Round  56, Train loss: 1.815, Test loss: 1.683, Test accuracy: 82.04
Round  56, Global train loss: 1.815, Global test loss: 1.692, Global test accuracy: 84.70
Round  57, Train loss: 1.554, Test loss: 1.673, Test accuracy: 82.20
Round  57, Global train loss: 1.554, Global test loss: 1.578, Global test accuracy: 91.86
Round  58, Train loss: 1.665, Test loss: 1.669, Test accuracy: 82.54
Round  58, Global train loss: 1.665, Global test loss: 1.580, Global test accuracy: 91.68
Round  59, Train loss: 1.864, Test loss: 1.682, Test accuracy: 82.24
Round  59, Global train loss: 1.864, Global test loss: 1.711, Global test accuracy: 84.44
Round  60, Train loss: 1.780, Test loss: 1.684, Test accuracy: 82.58
Round  60, Global train loss: 1.780, Global test loss: 1.674, Global test accuracy: 87.86
Round  61, Train loss: 1.748, Test loss: 1.688, Test accuracy: 81.98
Round  61, Global train loss: 1.748, Global test loss: 1.681, Global test accuracy: 86.00
Round  62, Train loss: 1.700, Test loss: 1.675, Test accuracy: 82.56
Round  62, Global train loss: 1.700, Global test loss: 1.591, Global test accuracy: 92.04
Round  63, Train loss: 1.642, Test loss: 1.670, Test accuracy: 82.62
Round  63, Global train loss: 1.642, Global test loss: 1.579, Global test accuracy: 91.86
Round  64, Train loss: 1.761, Test loss: 1.673, Test accuracy: 82.48
Round  64, Global train loss: 1.761, Global test loss: 1.661, Global test accuracy: 88.72
Round  65, Train loss: 1.646, Test loss: 1.667, Test accuracy: 82.94
Round  65, Global train loss: 1.646, Global test loss: 1.578, Global test accuracy: 92.32
Round  66, Train loss: 1.547, Test loss: 1.665, Test accuracy: 82.74
Round  66, Global train loss: 1.547, Global test loss: 1.573, Global test accuracy: 91.74
Round  67, Train loss: 1.958, Test loss: 1.690, Test accuracy: 82.06
Round  67, Global train loss: 1.958, Global test loss: 1.793, Global test accuracy: 73.84
Round  68, Train loss: 1.638, Test loss: 1.674, Test accuracy: 82.62
Round  68, Global train loss: 1.638, Global test loss: 1.584, Global test accuracy: 92.46
Round  69, Train loss: 1.726, Test loss: 1.679, Test accuracy: 82.44
Round  69, Global train loss: 1.726, Global test loss: 1.670, Global test accuracy: 87.16
Round  70, Train loss: 1.713, Test loss: 1.687, Test accuracy: 82.12
Round  70, Global train loss: 1.713, Global test loss: 1.674, Global test accuracy: 87.18
Round  71, Train loss: 1.804, Test loss: 1.685, Test accuracy: 82.48
Round  71, Global train loss: 1.804, Global test loss: 1.701, Global test accuracy: 86.22
Round  72, Train loss: 1.768, Test loss: 1.692, Test accuracy: 81.66
Round  72, Global train loss: 1.768, Global test loss: 1.706, Global test accuracy: 84.58
Round  73, Train loss: 1.634, Test loss: 1.677, Test accuracy: 82.44
Round  73, Global train loss: 1.634, Global test loss: 1.588, Global test accuracy: 92.02
Round  74, Train loss: 1.914, Test loss: 1.704, Test accuracy: 81.68
Round  74, Global train loss: 1.914, Global test loss: 1.816, Global test accuracy: 71.94
Round  75, Train loss: 1.811, Test loss: 1.710, Test accuracy: 81.18
Round  75, Global train loss: 1.811, Global test loss: 1.740, Global test accuracy: 82.82
Round  76, Train loss: 1.590, Test loss: 1.671, Test accuracy: 82.92
Round  76, Global train loss: 1.590, Global test loss: 1.584, Global test accuracy: 92.14
Round  77, Train loss: 1.625, Test loss: 1.665, Test accuracy: 83.42
Round  77, Global train loss: 1.625, Global test loss: 1.575, Global test accuracy: 92.92
Round  78, Train loss: 1.748, Test loss: 1.682, Test accuracy: 82.50
Round  78, Global train loss: 1.748, Global test loss: 1.684, Global test accuracy: 85.46
Round  79, Train loss: 1.766, Test loss: 1.697, Test accuracy: 81.72
Round  79, Global train loss: 1.766, Global test loss: 1.720, Global test accuracy: 83.98
Round  80, Train loss: 1.748, Test loss: 1.683, Test accuracy: 82.40
Round  80, Global train loss: 1.748, Global test loss: 1.701, Global test accuracy: 85.06
Round  81, Train loss: 1.755, Test loss: 1.693, Test accuracy: 81.82
Round  81, Global train loss: 1.755, Global test loss: 1.706, Global test accuracy: 84.80
Round  82, Train loss: 1.764, Test loss: 1.705, Test accuracy: 80.88
Round  82, Global train loss: 1.764, Global test loss: 1.730, Global test accuracy: 82.74
Round  83, Train loss: 1.694, Test loss: 1.694, Test accuracy: 82.08
Round  83, Global train loss: 1.694, Global test loss: 1.686, Global test accuracy: 86.54
Round  84, Train loss: 1.694, Test loss: 1.688, Test accuracy: 82.20
Round  84, Global train loss: 1.694, Global test loss: 1.682, Global test accuracy: 85.94
Round  85, Train loss: 1.719, Test loss: 1.694, Test accuracy: 81.76
Round  85, Global train loss: 1.719, Global test loss: 1.740, Global test accuracy: 81.72
Round  86, Train loss: 1.649, Test loss: 1.675, Test accuracy: 82.84
Round  86, Global train loss: 1.649, Global test loss: 1.589, Global test accuracy: 91.72
Round  87, Train loss: 1.686, Test loss: 1.683, Test accuracy: 82.68
Round  87, Global train loss: 1.686, Global test loss: 1.685, Global test accuracy: 85.70
Round  88, Train loss: 1.683, Test loss: 1.690, Test accuracy: 82.14
Round  88, Global train loss: 1.683, Global test loss: 1.694, Global test accuracy: 84.96
Round  89, Train loss: 1.640, Test loss: 1.676, Test accuracy: 82.42
Round  89, Global train loss: 1.640, Global test loss: 1.590, Global test accuracy: 92.04
Round  90, Train loss: 1.635, Test loss: 1.677, Test accuracy: 82.56
Round  90, Global train loss: 1.635, Global test loss: 1.677, Global test accuracy: 86.12
Round  91, Train loss: 1.622, Test loss: 1.681, Test accuracy: 82.60
Round  91, Global train loss: 1.622, Global test loss: 1.676, Global test accuracy: 86.54
Round  92, Train loss: 1.553, Test loss: 1.667, Test accuracy: 83.00
Round  92, Global train loss: 1.553, Global test loss: 1.576, Global test accuracy: 92.06/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  93, Train loss: 1.568, Test loss: 1.661, Test accuracy: 83.42
Round  93, Global train loss: 1.568, Global test loss: 1.571, Global test accuracy: 92.56
Round  94, Train loss: 1.692, Test loss: 1.680, Test accuracy: 82.20
Round  94, Global train loss: 1.692, Global test loss: 1.737, Global test accuracy: 80.80
Round  95, Train loss: 1.834, Test loss: 1.741, Test accuracy: 78.62
Round  95, Global train loss: 1.834, Global test loss: 1.870, Global test accuracy: 64.58
Round  96, Train loss: 1.798, Test loss: 1.780, Test accuracy: 75.88
Round  96, Global train loss: 1.798, Global test loss: 1.922, Global test accuracy: 60.10
Round  97, Train loss: 1.668, Test loss: 1.718, Test accuracy: 80.24
Round  97, Global train loss: 1.668, Global test loss: 1.749, Global test accuracy: 79.66
Round  98, Train loss: 1.558, Test loss: 1.675, Test accuracy: 82.34
Round  98, Global train loss: 1.558, Global test loss: 1.588, Global test accuracy: 91.64
Round  99, Train loss: 1.554, Test loss: 1.667, Test accuracy: 82.68
Round  99, Global train loss: 1.554, Global test loss: 1.580, Global test accuracy: 91.58
Final Round, Train loss: 1.617, Test loss: 1.670, Test accuracy: 82.26
Final Round, Global train loss: 1.617, Global test loss: 1.580, Global test accuracy: 91.58
Average accuracy final 10 rounds: 81.354
554.60080742836
[1.307898998260498, 2.288454532623291, 3.2892515659332275, 4.300591230392456, 5.285186767578125, 6.276091575622559, 7.278991937637329, 8.403882503509521, 9.357071161270142, 10.313423871994019, 11.285623788833618, 12.222680568695068, 13.243682622909546, 14.309319257736206, 15.257752180099487, 16.25589919090271, 17.21624493598938, 18.227997541427612, 19.214823722839355, 20.178507804870605, 21.16968059539795, 22.13874101638794, 23.116915464401245, 24.071134090423584, 25.039316415786743, 26.037267208099365, 27.069616556167603, 28.06033945083618, 29.02787470817566, 30.016641855239868, 30.988471269607544, 31.98397135734558, 32.95878005027771, 33.9461772441864, 34.91061615943909, 35.90034866333008, 36.87588119506836, 37.889893770217896, 38.90174126625061, 39.86912679672241, 40.86710786819458, 41.84184455871582, 42.77016615867615, 44.566474199295044, 45.54886436462402, 46.4898247718811, 47.470282316207886, 48.48493957519531, 49.45167255401611, 50.43285942077637, 51.38335824012756, 52.37820315361023, 53.36216974258423, 54.34710907936096, 55.34016752243042, 56.38719606399536, 57.42669868469238, 58.42080545425415, 59.4247522354126, 60.390061378479004, 61.390087366104126, 62.36524844169617, 63.35682797431946, 64.3579330444336, 65.30609273910522, 66.28517866134644, 67.31278681755066, 68.30921030044556, 69.32646632194519, 70.29352879524231, 71.28319549560547, 72.24055528640747, 73.25042486190796, 74.22084951400757, 75.22475695610046, 76.1980984210968, 77.15876364707947, 78.1983425617218, 79.15623617172241, 80.12324452400208, 81.1036217212677, 82.10771203041077, 83.12372374534607, 84.09366917610168, 85.07389497756958, 86.09367346763611, 87.09534406661987, 88.08996367454529, 89.0952935218811, 90.0795259475708, 91.04640507698059, 92.0560154914856, 93.04888987541199, 94.0356514453888, 95.04568839073181, 96.0992841720581, 97.12678384780884, 98.1371922492981, 99.1378448009491, 100.16803812980652, 101.78225684165955]
[10.3, 15.18, 19.72, 21.14, 17.72, 16.16, 26.84, 30.26, 19.32, 19.64, 38.8, 40.02, 44.08, 46.64, 51.76, 56.0, 57.3, 57.62, 57.66, 60.54, 63.84, 67.74, 70.02, 70.78, 71.88, 73.14, 73.22, 74.06, 74.94, 75.5, 75.34, 75.16, 75.52, 75.72, 77.1, 77.44, 79.32, 80.54, 80.34, 80.36, 80.76, 80.74, 80.66, 80.3, 81.12, 81.52, 81.64, 81.48, 81.14, 81.76, 81.9, 81.56, 81.7, 81.8, 82.28, 82.34, 82.04, 82.2, 82.54, 82.24, 82.58, 81.98, 82.56, 82.62, 82.48, 82.94, 82.74, 82.06, 82.62, 82.44, 82.12, 82.48, 81.66, 82.44, 81.68, 81.18, 82.92, 83.42, 82.5, 81.72, 82.4, 81.82, 80.88, 82.08, 82.2, 81.76, 82.84, 82.68, 82.14, 82.42, 82.56, 82.6, 83.0, 83.42, 82.2, 78.62, 75.88, 80.24, 82.34, 82.68, 82.26]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fedpac_copsl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist,  filter_alg: loss_psl, level_n_system: 0.2 , level_n_lowerb:0.8  

   Client 5, noise    level: 0.8000 
   Client 7, noise    level: 0.8000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.321, Test loss: 2.301, Test accuracy: 19.80
Round   0, Global train loss: 2.321, Global test loss: 2.301, Global test accuracy: 20.24
Round   1, Train loss: 2.300, Test loss: 2.299, Test accuracy: 28.64
Round   1, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 30.84
Round   2, Train loss: 2.298, Test loss: 2.297, Test accuracy: 30.80
Round   2, Global train loss: 2.298, Global test loss: 2.297, Global test accuracy: 32.32
Round   3, Train loss: 2.295, Test loss: 2.294, Test accuracy: 28.30
Round   3, Global train loss: 2.295, Global test loss: 2.294, Global test accuracy: 28.88
Round   4, Train loss: 2.291, Test loss: 2.288, Test accuracy: 24.36
Round   4, Global train loss: 2.291, Global test loss: 2.288, Global test accuracy: 23.76
Round   5, Train loss: 2.282, Test loss: 2.275, Test accuracy: 19.06
Round   5, Global train loss: 2.282, Global test loss: 2.274, Global test accuracy: 17.94
Round   6, Train loss: 2.265, Test loss: 2.250, Test accuracy: 18.50
Round   6, Global train loss: 2.265, Global test loss: 2.249, Global test accuracy: 17.38
Round   7, Train loss: 2.245, Test loss: 2.230, Test accuracy: 24.60
Round   7, Global train loss: 2.245, Global test loss: 2.229, Global test accuracy: 25.62
Round   8, Train loss: 2.227, Test loss: 2.207, Test accuracy: 29.62
Round   8, Global train loss: 2.227, Global test loss: 2.206, Global test accuracy: 31.24
Round   9, Train loss: 2.203, Test loss: 2.171, Test accuracy: 33.40
Round   9, Global train loss: 2.203, Global test loss: 2.167, Global test accuracy: 35.36
Round  10, Train loss: 2.156, Test loss: 2.121, Test accuracy: 38.24
Round  10, Global train loss: 2.156, Global test loss: 2.089, Global test accuracy: 38.30
Round  11, Train loss: 2.109, Test loss: 2.085, Test accuracy: 40.24
Round  11, Global train loss: 2.109, Global test loss: 2.058, Global test accuracy: 39.48
Round  12, Train loss: 2.097, Test loss: 2.059, Test accuracy: 43.14
Round  12, Global train loss: 2.097, Global test loss: 2.030, Global test accuracy: 45.20
Traceback (most recent call last):
  File "main_fedpac_copsl.py", line 280, in <module>
    w_local, loss, indd, class_center_local, class_num, noisy_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys,
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2559, in train
    self.filter_data(net, local_net, iter2-head_eps+1, local_eps-head_eps+1, concept_matrix_local)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2396, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist, level_n_system: 0.4 , level_n_lowerb:0.4  

   Client 1, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.301, Test loss: 2.301, Test accuracy: 12.20
Round   0, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.96
Round   1, Train loss: 2.300, Test loss: 2.299, Test accuracy: 14.54
Round   1, Global train loss: 2.300, Global test loss: 2.298, Global test accuracy: 16.12
Round   2, Train loss: 2.297, Test loss: 2.297, Test accuracy: 15.50
Round   2, Global train loss: 2.297, Global test loss: 2.295, Global test accuracy: 14.00
Round   3, Train loss: 2.294, Test loss: 2.294, Test accuracy: 21.56
Round   3, Global train loss: 2.294, Global test loss: 2.291, Global test accuracy: 31.58
Round   4, Train loss: 2.280, Test loss: 2.287, Test accuracy: 22.26
Round   4, Global train loss: 2.280, Global test loss: 2.287, Global test accuracy: 39.10
Round   5, Train loss: 2.239, Test loss: 2.266, Test accuracy: 24.40
Round   5, Global train loss: 2.239, Global test loss: 2.247, Global test accuracy: 42.22
Round   6, Train loss: 2.281, Test loss: 2.267, Test accuracy: 21.02
Round   6, Global train loss: 2.281, Global test loss: 2.281, Global test accuracy: 13.74
Round   7, Train loss: 2.280, Test loss: 2.265, Test accuracy: 19.54
Round   7, Global train loss: 2.280, Global test loss: 2.286, Global test accuracy: 9.92
Round   8, Train loss: 2.186, Test loss: 2.230, Test accuracy: 27.04
Round   8, Global train loss: 2.186, Global test loss: 2.212, Global test accuracy: 31.02
Round   9, Train loss: 2.146, Test loss: 2.213, Test accuracy: 24.64
Round   9, Global train loss: 2.146, Global test loss: 2.190, Global test accuracy: 26.16
Round  10, Train loss: 2.236, Test loss: 2.203, Test accuracy: 25.50
Round  10, Global train loss: 2.236, Global test loss: 2.238, Global test accuracy: 23.62
Round  11, Train loss: 2.087, Test loss: 2.173, Test accuracy: 27.64
Round  11, Global train loss: 2.087, Global test loss: 2.164, Global test accuracy: 25.94
Round  12, Train loss: 2.124, Test loss: 2.130, Test accuracy: 34.26
Round  12, Global train loss: 2.124, Global test loss: 2.123, Global test accuracy: 43.22
Round  13, Train loss: 2.184, Test loss: 2.131, Test accuracy: 33.26
Round  13, Global train loss: 2.184, Global test loss: 2.238, Global test accuracy: 14.00
Round  14, Train loss: 2.028, Test loss: 2.108, Test accuracy: 37.48
Round  14, Global train loss: 2.028, Global test loss: 2.002, Global test accuracy: 54.62
Round  15, Train loss: 2.094, Test loss: 2.096, Test accuracy: 39.24
Round  15, Global train loss: 2.094, Global test loss: 2.176, Global test accuracy: 29.34
Round  16, Train loss: 2.056, Test loss: 2.071, Test accuracy: 41.04
Round  16, Global train loss: 2.056, Global test loss: 2.066, Global test accuracy: 40.78
Round  17, Train loss: 2.102, Test loss: 2.046, Test accuracy: 44.66
Round  17, Global train loss: 2.102, Global test loss: 2.116, Global test accuracy: 31.38
Round  18, Train loss: 2.026, Test loss: 2.021, Test accuracy: 47.28
Round  18, Global train loss: 2.026, Global test loss: 2.033, Global test accuracy: 46.46
Round  19, Train loss: 2.078, Test loss: 2.004, Test accuracy: 48.06
Round  19, Global train loss: 2.078, Global test loss: 2.062, Global test accuracy: 46.36
Round  20, Train loss: 2.012, Test loss: 1.997, Test accuracy: 48.80
Round  20, Global train loss: 2.012, Global test loss: 2.075, Global test accuracy: 42.40
Round  21, Train loss: 2.120, Test loss: 1.988, Test accuracy: 49.56
Round  21, Global train loss: 2.120, Global test loss: 2.214, Global test accuracy: 21.62
Round  22, Train loss: 2.017, Test loss: 1.971, Test accuracy: 51.16
Round  22, Global train loss: 2.017, Global test loss: 2.068, Global test accuracy: 44.28
Round  23, Train loss: 1.933, Test loss: 1.968, Test accuracy: 51.40
Round  23, Global train loss: 1.933, Global test loss: 2.011, Global test accuracy: 44.38
Round  24, Train loss: 1.912, Test loss: 1.944, Test accuracy: 53.84
Round  24, Global train loss: 1.912, Global test loss: 1.970, Global test accuracy: 52.92
Round  25, Train loss: 1.907, Test loss: 1.938, Test accuracy: 53.96
Round  25, Global train loss: 1.907, Global test loss: 1.946, Global test accuracy: 51.50
Round  26, Train loss: 1.997, Test loss: 1.934, Test accuracy: 54.46
Round  26, Global train loss: 1.997, Global test loss: 2.123, Global test accuracy: 28.84
Round  27, Train loss: 1.891, Test loss: 1.929, Test accuracy: 55.08
Round  27, Global train loss: 1.891, Global test loss: 1.957, Global test accuracy: 51.84
Round  28, Train loss: 1.962, Test loss: 1.923, Test accuracy: 56.04
Round  28, Global train loss: 1.962, Global test loss: 2.108, Global test accuracy: 32.74
Round  29, Train loss: 1.794, Test loss: 1.915, Test accuracy: 56.78
Round  29, Global train loss: 1.794, Global test loss: 1.865, Global test accuracy: 58.88
Round  30, Train loss: 1.878, Test loss: 1.914, Test accuracy: 56.66
Round  30, Global train loss: 1.878, Global test loss: 1.887, Global test accuracy: 58.22
Round  31, Train loss: 1.945, Test loss: 1.911, Test accuracy: 56.74
Round  31, Global train loss: 1.945, Global test loss: 2.070, Global test accuracy: 42.28
Round  32, Train loss: 1.965, Test loss: 1.906, Test accuracy: 57.06
Round  32, Global train loss: 1.965, Global test loss: 2.089, Global test accuracy: 35.74
Round  33, Train loss: 1.754, Test loss: 1.903, Test accuracy: 56.92
Round  33, Global train loss: 1.754, Global test loss: 1.848, Global test accuracy: 60.66
Round  34, Train loss: 1.783, Test loss: 1.902, Test accuracy: 56.88
Round  34, Global train loss: 1.783, Global test loss: 1.876, Global test accuracy: 60.82
Round  35, Train loss: 1.865, Test loss: 1.902, Test accuracy: 56.80
Round  35, Global train loss: 1.865, Global test loss: 2.011, Global test accuracy: 45.32
Round  36, Train loss: 1.945, Test loss: 1.899, Test accuracy: 56.94
Round  36, Global train loss: 1.945, Global test loss: 1.973, Global test accuracy: 48.40
Round  37, Train loss: 1.788, Test loss: 1.895, Test accuracy: 57.50
Round  37, Global train loss: 1.788, Global test loss: 1.844, Global test accuracy: 64.12
Round  38, Train loss: 1.758, Test loss: 1.896, Test accuracy: 57.50
Round  38, Global train loss: 1.758, Global test loss: 1.901, Global test accuracy: 57.60
Round  39, Train loss: 1.912, Test loss: 1.896, Test accuracy: 57.42
Round  39, Global train loss: 1.912, Global test loss: 2.089, Global test accuracy: 35.78
Round  40, Train loss: 1.893, Test loss: 1.897, Test accuracy: 57.16
Round  40, Global train loss: 1.893, Global test loss: 2.100, Global test accuracy: 35.56
Round  41, Train loss: 1.762, Test loss: 1.897, Test accuracy: 57.14
Round  41, Global train loss: 1.762, Global test loss: 1.907, Global test accuracy: 55.98
Round  42, Train loss: 1.839, Test loss: 1.893, Test accuracy: 57.96
Round  42, Global train loss: 1.839, Global test loss: 1.954, Global test accuracy: 51.02
Round  43, Train loss: 1.763, Test loss: 1.886, Test accuracy: 58.56
Round  43, Global train loss: 1.763, Global test loss: 1.791, Global test accuracy: 67.10
Round  44, Train loss: 1.831, Test loss: 1.886, Test accuracy: 58.58
Round  44, Global train loss: 1.831, Global test loss: 2.053, Global test accuracy: 40.64
Round  45, Train loss: 1.806, Test loss: 1.886, Test accuracy: 58.56
Round  45, Global train loss: 1.806, Global test loss: 2.056, Global test accuracy: 40.30
Round  46, Train loss: 1.812, Test loss: 1.881, Test accuracy: 59.04
Round  46, Global train loss: 1.812, Global test loss: 1.916, Global test accuracy: 52.84
Round  47, Train loss: 1.733, Test loss: 1.882, Test accuracy: 58.86
Round  47, Global train loss: 1.733, Global test loss: 1.867, Global test accuracy: 58.72
Round  48, Train loss: 1.749, Test loss: 1.880, Test accuracy: 58.94
Round  48, Global train loss: 1.749, Global test loss: 1.917, Global test accuracy: 53.46
Round  49, Train loss: 1.793, Test loss: 1.878, Test accuracy: 58.96
Round  49, Global train loss: 1.793, Global test loss: 1.912, Global test accuracy: 53.14
Round  50, Train loss: 1.781, Test loss: 1.878, Test accuracy: 59.02
Round  50, Global train loss: 1.781, Global test loss: 1.916, Global test accuracy: 52.60
Round  51, Train loss: 1.826, Test loss: 1.878, Test accuracy: 58.98
Round  51, Global train loss: 1.826, Global test loss: 2.044, Global test accuracy: 40.82
Round  52, Train loss: 1.866, Test loss: 1.876, Test accuracy: 59.08
Round  52, Global train loss: 1.866, Global test loss: 2.029, Global test accuracy: 43.30
Round  53, Train loss: 1.714, Test loss: 1.876, Test accuracy: 58.98
Round  53, Global train loss: 1.714, Global test loss: 1.856, Global test accuracy: 59.88
Round  54, Train loss: 1.785, Test loss: 1.876, Test accuracy: 58.76
Round  54, Global train loss: 1.785, Global test loss: 1.920, Global test accuracy: 53.38
Round  55, Train loss: 1.736, Test loss: 1.876, Test accuracy: 58.56
Round  55, Global train loss: 1.736, Global test loss: 1.907, Global test accuracy: 53.44
Round  56, Train loss: 1.654, Test loss: 1.876, Test accuracy: 58.72
Round  56, Global train loss: 1.654, Global test loss: 1.702, Global test accuracy: 77.32
Round  57, Train loss: 1.789, Test loss: 1.874, Test accuracy: 58.90
Round  57, Global train loss: 1.789, Global test loss: 1.907, Global test accuracy: 56.12
Round  58, Train loss: 1.755, Test loss: 1.874, Test accuracy: 58.88
Round  58, Global train loss: 1.755, Global test loss: 1.879, Global test accuracy: 57.50
Round  59, Train loss: 1.676, Test loss: 1.874, Test accuracy: 58.84
Round  59, Global train loss: 1.676, Global test loss: 1.744, Global test accuracy: 71.88
Round  60, Train loss: 1.801, Test loss: 1.873, Test accuracy: 59.08
Round  60, Global train loss: 1.801, Global test loss: 2.007, Global test accuracy: 46.06
Round  61, Train loss: 1.729, Test loss: 1.873, Test accuracy: 59.06
Round  61, Global train loss: 1.729, Global test loss: 1.856, Global test accuracy: 59.42
Round  62, Train loss: 1.757, Test loss: 1.872, Test accuracy: 59.28
Round  62, Global train loss: 1.757, Global test loss: 1.929, Global test accuracy: 51.76
Round  63, Train loss: 1.750, Test loss: 1.873, Test accuracy: 59.18
Round  63, Global train loss: 1.750, Global test loss: 1.859, Global test accuracy: 62.56
Round  64, Train loss: 1.869, Test loss: 1.871, Test accuracy: 59.44
Round  64, Global train loss: 1.869, Global test loss: 2.145, Global test accuracy: 28.90
Round  65, Train loss: 1.727, Test loss: 1.871, Test accuracy: 59.50
Round  65, Global train loss: 1.727, Global test loss: 1.854, Global test accuracy: 62.60
Round  66, Train loss: 1.774, Test loss: 1.874, Test accuracy: 59.04
Round  66, Global train loss: 1.774, Global test loss: 1.949, Global test accuracy: 51.36
Round  67, Train loss: 1.719, Test loss: 1.873, Test accuracy: 58.96
Round  67, Global train loss: 1.719, Global test loss: 1.899, Global test accuracy: 56.16
Round  68, Train loss: 1.818, Test loss: 1.873, Test accuracy: 58.94
Round  68, Global train loss: 1.818, Global test loss: 2.003, Global test accuracy: 44.72
Round  69, Train loss: 1.788, Test loss: 1.869, Test accuracy: 59.52
Round  69, Global train loss: 1.788, Global test loss: 1.958, Global test accuracy: 49.62
Round  70, Train loss: 1.792, Test loss: 1.868, Test accuracy: 59.50
Round  70, Global train loss: 1.792, Global test loss: 1.985, Global test accuracy: 45.64
Round  71, Train loss: 1.812, Test loss: 1.865, Test accuracy: 60.08
Round  71, Global train loss: 1.812, Global test loss: 1.980, Global test accuracy: 49.70
Round  72, Train loss: 1.725, Test loss: 1.864, Test accuracy: 60.30
Round  72, Global train loss: 1.725, Global test loss: 1.884, Global test accuracy: 57.28
Round  73, Train loss: 1.720, Test loss: 1.862, Test accuracy: 60.52
Round  73, Global train loss: 1.720, Global test loss: 1.811, Global test accuracy: 64.56
Round  74, Train loss: 1.701, Test loss: 1.862, Test accuracy: 60.44
Round  74, Global train loss: 1.701, Global test loss: 1.869, Global test accuracy: 59.48
Round  75, Train loss: 1.839, Test loss: 1.860, Test accuracy: 60.86
Round  75, Global train loss: 1.839, Global test loss: 1.971, Global test accuracy: 51.72
Round  76, Train loss: 1.760, Test loss: 1.860, Test accuracy: 60.68
Round  76, Global train loss: 1.760, Global test loss: 1.995, Global test accuracy: 45.98
Round  77, Train loss: 1.722, Test loss: 1.860, Test accuracy: 60.72
Round  77, Global train loss: 1.722, Global test loss: 1.829, Global test accuracy: 64.72
Round  78, Train loss: 1.723, Test loss: 1.858, Test accuracy: 61.12
Round  78, Global train loss: 1.723, Global test loss: 1.846, Global test accuracy: 61.62
Round  79, Train loss: 1.795, Test loss: 1.856, Test accuracy: 61.26
Round  79, Global train loss: 1.795, Global test loss: 1.982, Global test accuracy: 48.58
Round  80, Train loss: 1.721, Test loss: 1.855, Test accuracy: 61.06
Round  80, Global train loss: 1.721, Global test loss: 1.849, Global test accuracy: 61.92
Round  81, Train loss: 1.788, Test loss: 1.855, Test accuracy: 60.92
Round  81, Global train loss: 1.788, Global test loss: 1.942, Global test accuracy: 52.88
Round  82, Train loss: 1.740, Test loss: 1.856, Test accuracy: 60.90
Round  82, Global train loss: 1.740, Global test loss: 1.853, Global test accuracy: 60.96
Round  83, Train loss: 1.822, Test loss: 1.856, Test accuracy: 60.98
Round  83, Global train loss: 1.822, Global test loss: 2.023, Global test accuracy: 42.96
Round  84, Train loss: 1.759, Test loss: 1.856, Test accuracy: 60.90
Round  84, Global train loss: 1.759, Global test loss: 1.874, Global test accuracy: 59.80
Round  85, Train loss: 1.685, Test loss: 1.857, Test accuracy: 60.76
Round  85, Global train loss: 1.685, Global test loss: 1.850, Global test accuracy: 60.60
Round  86, Train loss: 1.672, Test loss: 1.857, Test accuracy: 60.78
Round  86, Global train loss: 1.672, Global test loss: 1.688, Global test accuracy: 77.92
Round  87, Train loss: 1.822, Test loss: 1.857, Test accuracy: 60.84
Round  87, Global train loss: 1.822, Global test loss: 2.059, Global test accuracy: 38.24
Round  88, Train loss: 1.750, Test loss: 1.857, Test accuracy: 60.76
Round  88, Global train loss: 1.750, Global test loss: 1.903, Global test accuracy: 56.42
Round  89, Train loss: 1.668, Test loss: 1.853, Test accuracy: 61.20
Round  89, Global train loss: 1.668, Global test loss: 1.677, Global test accuracy: 78.78
Round  90, Train loss: 1.730, Test loss: 1.852, Test accuracy: 61.22
Round  90, Global train loss: 1.730, Global test loss: 1.895, Global test accuracy: 55.88
Round  91, Train loss: 1.728, Test loss: 1.852, Test accuracy: 61.32
Round  91, Global train loss: 1.728, Global test loss: 1.897, Global test accuracy: 55.72
Round  92, Train loss: 1.828, Test loss: 1.851, Test accuracy: 61.58
Round  92, Global train loss: 1.828, Global test loss: 2.037, Global test accuracy: 41.44
Round  93, Train loss: 1.673, Test loss: 1.850, Test accuracy: 61.76
Round  93, Global train loss: 1.673, Global test loss: 1.797, Global test accuracy: 66.44
Round  94, Train loss: 1.611, Test loss: 1.848, Test accuracy: 61.92
Round  94, Global train loss: 1.611, Global test loss: 1.667, Global test accuracy: 79.82/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  95, Train loss: 1.704, Test loss: 1.848, Test accuracy: 61.84
Round  95, Global train loss: 1.704, Global test loss: 1.876, Global test accuracy: 56.52
Round  96, Train loss: 1.694, Test loss: 1.847, Test accuracy: 62.02
Round  96, Global train loss: 1.694, Global test loss: 1.887, Global test accuracy: 55.40
Round  97, Train loss: 1.749, Test loss: 1.847, Test accuracy: 62.00
Round  97, Global train loss: 1.749, Global test loss: 1.965, Global test accuracy: 50.84
Round  98, Train loss: 1.826, Test loss: 1.848, Test accuracy: 61.78
Round  98, Global train loss: 1.826, Global test loss: 2.064, Global test accuracy: 39.24
Round  99, Train loss: 1.769, Test loss: 1.849, Test accuracy: 61.66
Round  99, Global train loss: 1.769, Global test loss: 1.922, Global test accuracy: 53.86
Final Round, Train loss: 1.715, Test loss: 1.847, Test accuracy: 61.78
Final Round, Global train loss: 1.715, Global test loss: 1.922, Global test accuracy: 53.86
Average accuracy final 10 rounds: 61.709999999999994 

Average global accuracy final 10 rounds: 55.516000000000005 

631.7057611942291
[1.0219051837921143, 2.0438103675842285, 2.8550655841827393, 3.66632080078125, 4.506547212600708, 5.346773624420166, 6.18283224105835, 7.018890857696533, 7.867878437042236, 8.71686601638794, 9.51589560508728, 10.314925193786621, 11.176708698272705, 12.038492202758789, 12.876078367233276, 13.713664531707764, 14.559505224227905, 15.405345916748047, 16.22166109085083, 17.037976264953613, 17.85031294822693, 18.662649631500244, 19.510865449905396, 20.359081268310547, 21.1489577293396, 21.938834190368652, 22.768030405044556, 23.59722661972046, 24.49212074279785, 25.387014865875244, 26.198967695236206, 27.010920524597168, 27.856393814086914, 28.70186710357666, 29.538158416748047, 30.374449729919434, 31.169740200042725, 31.965030670166016, 32.81768035888672, 33.67033004760742, 34.47460317611694, 35.278876304626465, 36.12945199012756, 36.98002767562866, 37.80912137031555, 38.63821506500244, 39.459439754486084, 40.28066444396973, 41.11205220222473, 41.943439960479736, 42.767393827438354, 43.59134769439697, 44.395631313323975, 45.19991493225098, 46.05728459358215, 46.91465425491333, 47.709511041641235, 48.50436782836914, 49.32971477508545, 50.15506172180176, 50.99800515174866, 51.84094858169556, 52.6419894695282, 53.44303035736084, 54.2802197933197, 55.117409229278564, 55.9750702381134, 56.83273124694824, 57.614173889160156, 58.39561653137207, 59.222968101501465, 60.05031967163086, 60.894179344177246, 61.73803901672363, 62.523709774017334, 63.309380531311035, 64.13875484466553, 64.96812915802002, 66.3597583770752, 67.75138759613037, 68.57795524597168, 69.40452289581299, 70.24323844909668, 71.08195400238037, 71.94580507278442, 72.80965614318848, 73.60492014884949, 74.4001841545105, 75.23529148101807, 76.07039880752563, 76.86303186416626, 77.65566492080688, 78.53082180023193, 79.40597867965698, 80.35877013206482, 81.31156158447266, 82.113445520401, 82.91532945632935, 83.7572865486145, 84.59924364089966, 85.41349864006042, 86.22775363922119, 87.06688451766968, 87.90601539611816, 88.77787613868713, 89.6497368812561, 90.4696273803711, 91.28951787948608, 92.0875792503357, 92.8856406211853, 93.66718912124634, 94.44873762130737, 95.25480508804321, 96.06087255477905, 96.86453628540039, 97.66820001602173, 98.5305860042572, 99.39297199249268, 100.21512413024902, 101.03727626800537, 101.86892414093018, 102.70057201385498, 103.61063647270203, 104.52070093154907, 105.40335702896118, 106.28601312637329, 107.08153700828552, 107.87706089019775, 108.72646713256836, 109.57587337493896, 110.37831234931946, 111.18075132369995, 112.05829119682312, 112.93583106994629, 113.75119733810425, 114.5665636062622, 115.40682363510132, 116.24708366394043, 117.11653423309326, 117.9859848022461, 118.81282925605774, 119.63967370986938, 120.4644467830658, 121.2892198562622, 122.10988998413086, 122.93056011199951, 123.73249316215515, 124.53442621231079, 125.34418845176697, 126.15395069122314, 126.98141646385193, 127.80888223648071, 128.64802503585815, 129.4871678352356, 130.25575232505798, 131.02433681488037, 131.81463384628296, 132.60493087768555, 133.44395923614502, 134.2829875946045, 135.07027196884155, 135.8575563430786, 136.72366952896118, 137.58978271484375, 138.49157190322876, 139.39336109161377, 140.18401455879211, 140.97466802597046, 141.75517082214355, 142.53567361831665, 143.4240186214447, 144.31236362457275, 145.13704252243042, 145.9617214202881, 146.77777647972107, 147.59383153915405, 148.4175741672516, 149.24131679534912, 150.11022281646729, 150.97912883758545, 151.76630997657776, 152.55349111557007, 153.349782705307, 154.14607429504395, 154.96690440177917, 155.7877345085144, 156.59034538269043, 157.39295625686646, 158.14474296569824, 158.89652967453003, 159.77768421173096, 160.65883874893188, 161.51960730552673, 162.38037586212158, 163.1730878353119, 163.9657998085022, 164.77196598052979, 165.57813215255737, 166.42978429794312, 167.28143644332886, 168.9305419921875, 170.57964754104614]
[12.2, 12.2, 14.54, 14.54, 15.5, 15.5, 21.56, 21.56, 22.26, 22.26, 24.4, 24.4, 21.02, 21.02, 19.54, 19.54, 27.04, 27.04, 24.64, 24.64, 25.5, 25.5, 27.64, 27.64, 34.26, 34.26, 33.26, 33.26, 37.48, 37.48, 39.24, 39.24, 41.04, 41.04, 44.66, 44.66, 47.28, 47.28, 48.06, 48.06, 48.8, 48.8, 49.56, 49.56, 51.16, 51.16, 51.4, 51.4, 53.84, 53.84, 53.96, 53.96, 54.46, 54.46, 55.08, 55.08, 56.04, 56.04, 56.78, 56.78, 56.66, 56.66, 56.74, 56.74, 57.06, 57.06, 56.92, 56.92, 56.88, 56.88, 56.8, 56.8, 56.94, 56.94, 57.5, 57.5, 57.5, 57.5, 57.42, 57.42, 57.16, 57.16, 57.14, 57.14, 57.96, 57.96, 58.56, 58.56, 58.58, 58.58, 58.56, 58.56, 59.04, 59.04, 58.86, 58.86, 58.94, 58.94, 58.96, 58.96, 59.02, 59.02, 58.98, 58.98, 59.08, 59.08, 58.98, 58.98, 58.76, 58.76, 58.56, 58.56, 58.72, 58.72, 58.9, 58.9, 58.88, 58.88, 58.84, 58.84, 59.08, 59.08, 59.06, 59.06, 59.28, 59.28, 59.18, 59.18, 59.44, 59.44, 59.5, 59.5, 59.04, 59.04, 58.96, 58.96, 58.94, 58.94, 59.52, 59.52, 59.5, 59.5, 60.08, 60.08, 60.3, 60.3, 60.52, 60.52, 60.44, 60.44, 60.86, 60.86, 60.68, 60.68, 60.72, 60.72, 61.12, 61.12, 61.26, 61.26, 61.06, 61.06, 60.92, 60.92, 60.9, 60.9, 60.98, 60.98, 60.9, 60.9, 60.76, 60.76, 60.78, 60.78, 60.84, 60.84, 60.76, 60.76, 61.2, 61.2, 61.22, 61.22, 61.32, 61.32, 61.58, 61.58, 61.76, 61.76, 61.92, 61.92, 61.84, 61.84, 62.02, 62.02, 62.0, 62.0, 61.78, 61.78, 61.66, 61.66, 61.78, 61.78]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.4 , level_n_lowerb:0.4  

   Client 0, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.301, Test loss: 2.300, Test accuracy: 13.58
Round   0, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 13.90
Round   1, Train loss: 2.299, Test loss: 2.299, Test accuracy: 12.56
Round   1, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 12.10
Round   2, Train loss: 2.296, Test loss: 2.296, Test accuracy: 17.72
Round   2, Global train loss: 2.296, Global test loss: 2.293, Global test accuracy: 20.66
Round   3, Train loss: 2.289, Test loss: 2.291, Test accuracy: 21.42
Round   3, Global train loss: 2.289, Global test loss: 2.285, Global test accuracy: 21.92
Round   4, Train loss: 2.277, Test loss: 2.277, Test accuracy: 25.62
Round   4, Global train loss: 2.277, Global test loss: 2.265, Global test accuracy: 25.56
Round   5, Train loss: 2.248, Test loss: 2.235, Test accuracy: 32.58
Round   5, Global train loss: 2.248, Global test loss: 2.192, Global test accuracy: 45.64
Round   6, Train loss: 2.131, Test loss: 2.106, Test accuracy: 42.06
Round   6, Global train loss: 2.131, Global test loss: 1.968, Global test accuracy: 57.72
Round   7, Train loss: 1.945, Test loss: 2.005, Test accuracy: 52.12
Round   7, Global train loss: 1.945, Global test loss: 1.827, Global test accuracy: 68.18
Round   8, Train loss: 1.980, Test loss: 1.899, Test accuracy: 63.52
Round   8, Global train loss: 1.980, Global test loss: 1.770, Global test accuracy: 73.46
Round   9, Train loss: 1.908, Test loss: 1.876, Test accuracy: 65.50
Round   9, Global train loss: 1.908, Global test loss: 1.739, Global test accuracy: 76.06
Round  10, Train loss: 1.754, Test loss: 1.770, Test accuracy: 72.28
Round  10, Global train loss: 1.754, Global test loss: 1.703, Global test accuracy: 77.84
Round  11, Train loss: 1.838, Test loss: 1.744, Test accuracy: 74.08
Round  11, Global train loss: 1.838, Global test loss: 1.691, Global test accuracy: 78.78
Round  12, Train loss: 1.723, Test loss: 1.738, Test accuracy: 74.52
Round  12, Global train loss: 1.723, Global test loss: 1.686, Global test accuracy: 79.16
Round  13, Train loss: 1.768, Test loss: 1.727, Test accuracy: 75.20
Round  13, Global train loss: 1.768, Global test loss: 1.678, Global test accuracy: 79.70
Round  14, Train loss: 1.776, Test loss: 1.727, Test accuracy: 75.20
Round  14, Global train loss: 1.776, Global test loss: 1.670, Global test accuracy: 80.48
Round  15, Train loss: 1.699, Test loss: 1.723, Test accuracy: 75.60
Round  15, Global train loss: 1.699, Global test loss: 1.664, Global test accuracy: 81.12
Round  16, Train loss: 1.762, Test loss: 1.687, Test accuracy: 78.72
Round  16, Global train loss: 1.762, Global test loss: 1.660, Global test accuracy: 80.98
Round  17, Train loss: 1.780, Test loss: 1.685, Test accuracy: 78.82
Round  17, Global train loss: 1.780, Global test loss: 1.659, Global test accuracy: 81.12
Round  18, Train loss: 1.881, Test loss: 1.673, Test accuracy: 79.84
Round  18, Global train loss: 1.881, Global test loss: 1.657, Global test accuracy: 80.60
Round  19, Train loss: 1.734, Test loss: 1.668, Test accuracy: 80.20
Round  19, Global train loss: 1.734, Global test loss: 1.657, Global test accuracy: 81.28
Round  20, Train loss: 1.682, Test loss: 1.665, Test accuracy: 80.48
Round  20, Global train loss: 1.682, Global test loss: 1.652, Global test accuracy: 81.98
Round  21, Train loss: 1.757, Test loss: 1.662, Test accuracy: 80.68
Round  21, Global train loss: 1.757, Global test loss: 1.651, Global test accuracy: 81.62
Round  22, Train loss: 1.738, Test loss: 1.663, Test accuracy: 80.68
Round  22, Global train loss: 1.738, Global test loss: 1.651, Global test accuracy: 82.22
Round  23, Train loss: 1.742, Test loss: 1.662, Test accuracy: 80.56
Round  23, Global train loss: 1.742, Global test loss: 1.651, Global test accuracy: 81.70
Round  24, Train loss: 1.773, Test loss: 1.661, Test accuracy: 80.66
Round  24, Global train loss: 1.773, Global test loss: 1.649, Global test accuracy: 81.74
Round  25, Train loss: 1.802, Test loss: 1.660, Test accuracy: 80.82
Round  25, Global train loss: 1.802, Global test loss: 1.654, Global test accuracy: 80.94
Round  26, Train loss: 1.747, Test loss: 1.660, Test accuracy: 80.76
Round  26, Global train loss: 1.747, Global test loss: 1.651, Global test accuracy: 81.18
Round  27, Train loss: 1.710, Test loss: 1.659, Test accuracy: 80.80
Round  27, Global train loss: 1.710, Global test loss: 1.652, Global test accuracy: 81.24
Round  28, Train loss: 1.743, Test loss: 1.658, Test accuracy: 80.84
Round  28, Global train loss: 1.743, Global test loss: 1.651, Global test accuracy: 81.30
Round  29, Train loss: 1.688, Test loss: 1.657, Test accuracy: 81.02
Round  29, Global train loss: 1.688, Global test loss: 1.647, Global test accuracy: 81.74
Round  30, Train loss: 1.803, Test loss: 1.658, Test accuracy: 80.94
Round  30, Global train loss: 1.803, Global test loss: 1.651, Global test accuracy: 80.92
Round  31, Train loss: 1.691, Test loss: 1.657, Test accuracy: 80.86
Round  31, Global train loss: 1.691, Global test loss: 1.647, Global test accuracy: 81.44
Round  32, Train loss: 1.769, Test loss: 1.657, Test accuracy: 80.86
Round  32, Global train loss: 1.769, Global test loss: 1.647, Global test accuracy: 81.90
Round  33, Train loss: 1.683, Test loss: 1.657, Test accuracy: 80.84
Round  33, Global train loss: 1.683, Global test loss: 1.644, Global test accuracy: 82.02
Round  34, Train loss: 1.840, Test loss: 1.655, Test accuracy: 81.00
Round  34, Global train loss: 1.840, Global test loss: 1.649, Global test accuracy: 81.74
Round  35, Train loss: 1.802, Test loss: 1.656, Test accuracy: 80.78
Round  35, Global train loss: 1.802, Global test loss: 1.648, Global test accuracy: 81.78
Round  36, Train loss: 1.710, Test loss: 1.654, Test accuracy: 80.94
Round  36, Global train loss: 1.710, Global test loss: 1.649, Global test accuracy: 81.70
Round  37, Train loss: 1.732, Test loss: 1.654, Test accuracy: 80.86
Round  37, Global train loss: 1.732, Global test loss: 1.645, Global test accuracy: 81.96
Round  38, Train loss: 1.783, Test loss: 1.653, Test accuracy: 80.96
Round  38, Global train loss: 1.783, Global test loss: 1.647, Global test accuracy: 81.66
Round  39, Train loss: 1.764, Test loss: 1.652, Test accuracy: 81.00
Round  39, Global train loss: 1.764, Global test loss: 1.646, Global test accuracy: 81.72
Round  40, Train loss: 1.737, Test loss: 1.652, Test accuracy: 81.06
Round  40, Global train loss: 1.737, Global test loss: 1.646, Global test accuracy: 82.00
Round  41, Train loss: 1.770, Test loss: 1.652, Test accuracy: 81.06
Round  41, Global train loss: 1.770, Global test loss: 1.647, Global test accuracy: 81.86
Round  42, Train loss: 1.830, Test loss: 1.652, Test accuracy: 80.98
Round  42, Global train loss: 1.830, Global test loss: 1.651, Global test accuracy: 80.88
Round  43, Train loss: 1.874, Test loss: 1.652, Test accuracy: 81.06
Round  43, Global train loss: 1.874, Global test loss: 1.651, Global test accuracy: 80.92
Round  44, Train loss: 1.761, Test loss: 1.652, Test accuracy: 80.98
Round  44, Global train loss: 1.761, Global test loss: 1.646, Global test accuracy: 81.78
Round  45, Train loss: 1.772, Test loss: 1.653, Test accuracy: 80.98
Round  45, Global train loss: 1.772, Global test loss: 1.646, Global test accuracy: 81.52
Round  46, Train loss: 1.787, Test loss: 1.653, Test accuracy: 80.92
Round  46, Global train loss: 1.787, Global test loss: 1.649, Global test accuracy: 81.54
Round  47, Train loss: 1.718, Test loss: 1.652, Test accuracy: 80.98
Round  47, Global train loss: 1.718, Global test loss: 1.646, Global test accuracy: 82.16
Round  48, Train loss: 1.806, Test loss: 1.653, Test accuracy: 80.98
Round  48, Global train loss: 1.806, Global test loss: 1.647, Global test accuracy: 81.78
Round  49, Train loss: 1.784, Test loss: 1.653, Test accuracy: 81.04
Round  49, Global train loss: 1.784, Global test loss: 1.650, Global test accuracy: 81.56
Round  50, Train loss: 1.782, Test loss: 1.655, Test accuracy: 80.78
Round  50, Global train loss: 1.782, Global test loss: 1.653, Global test accuracy: 81.10
Round  51, Train loss: 1.825, Test loss: 1.655, Test accuracy: 80.66
Round  51, Global train loss: 1.825, Global test loss: 1.649, Global test accuracy: 81.54
Round  52, Train loss: 1.639, Test loss: 1.655, Test accuracy: 80.62
Round  52, Global train loss: 1.639, Global test loss: 1.647, Global test accuracy: 81.54
Round  53, Train loss: 1.738, Test loss: 1.655, Test accuracy: 80.70
Round  53, Global train loss: 1.738, Global test loss: 1.648, Global test accuracy: 81.24
Round  54, Train loss: 1.820, Test loss: 1.655, Test accuracy: 80.68
Round  54, Global train loss: 1.820, Global test loss: 1.651, Global test accuracy: 81.34
Round  55, Train loss: 1.768, Test loss: 1.654, Test accuracy: 80.72
Round  55, Global train loss: 1.768, Global test loss: 1.647, Global test accuracy: 81.92
Round  56, Train loss: 1.757, Test loss: 1.656, Test accuracy: 80.60
Round  56, Global train loss: 1.757, Global test loss: 1.647, Global test accuracy: 81.76
Round  57, Train loss: 1.655, Test loss: 1.655, Test accuracy: 80.66
Round  57, Global train loss: 1.655, Global test loss: 1.645, Global test accuracy: 81.74
Round  58, Train loss: 1.778, Test loss: 1.654, Test accuracy: 80.66
Round  58, Global train loss: 1.778, Global test loss: 1.650, Global test accuracy: 81.20
Round  59, Train loss: 1.818, Test loss: 1.655, Test accuracy: 80.64
Round  59, Global train loss: 1.818, Global test loss: 1.655, Global test accuracy: 80.06
Round  60, Train loss: 1.760, Test loss: 1.654, Test accuracy: 80.76
Round  60, Global train loss: 1.760, Global test loss: 1.648, Global test accuracy: 81.78
Round  61, Train loss: 1.722, Test loss: 1.654, Test accuracy: 80.76
Round  61, Global train loss: 1.722, Global test loss: 1.645, Global test accuracy: 81.26
Round  62, Train loss: 1.827, Test loss: 1.653, Test accuracy: 80.92
Round  62, Global train loss: 1.827, Global test loss: 1.654, Global test accuracy: 80.36
Round  63, Train loss: 1.810, Test loss: 1.654, Test accuracy: 80.96
Round  63, Global train loss: 1.810, Global test loss: 1.650, Global test accuracy: 81.10
Round  64, Train loss: 1.683, Test loss: 1.654, Test accuracy: 81.04
Round  64, Global train loss: 1.683, Global test loss: 1.646, Global test accuracy: 81.74
Round  65, Train loss: 1.823, Test loss: 1.654, Test accuracy: 81.06
Round  65, Global train loss: 1.823, Global test loss: 1.652, Global test accuracy: 80.86
Round  66, Train loss: 1.711, Test loss: 1.654, Test accuracy: 81.02
Round  66, Global train loss: 1.711, Global test loss: 1.648, Global test accuracy: 81.54
Round  67, Train loss: 1.777, Test loss: 1.654, Test accuracy: 80.92
Round  67, Global train loss: 1.777, Global test loss: 1.651, Global test accuracy: 80.78
Round  68, Train loss: 1.792, Test loss: 1.653, Test accuracy: 81.00
Round  68, Global train loss: 1.792, Global test loss: 1.648, Global test accuracy: 81.80
Round  69, Train loss: 1.701, Test loss: 1.653, Test accuracy: 81.00
Round  69, Global train loss: 1.701, Global test loss: 1.646, Global test accuracy: 82.20
Round  70, Train loss: 1.794, Test loss: 1.653, Test accuracy: 80.94
Round  70, Global train loss: 1.794, Global test loss: 1.650, Global test accuracy: 81.32
Round  71, Train loss: 1.761, Test loss: 1.652, Test accuracy: 80.98
Round  71, Global train loss: 1.761, Global test loss: 1.649, Global test accuracy: 81.86
Round  72, Train loss: 1.800, Test loss: 1.652, Test accuracy: 81.06
Round  72, Global train loss: 1.800, Global test loss: 1.649, Global test accuracy: 81.38
Round  73, Train loss: 1.727, Test loss: 1.652, Test accuracy: 81.12
Round  73, Global train loss: 1.727, Global test loss: 1.650, Global test accuracy: 81.36
Round  74, Train loss: 1.773, Test loss: 1.652, Test accuracy: 81.04
Round  74, Global train loss: 1.773, Global test loss: 1.650, Global test accuracy: 80.72
Round  75, Train loss: 1.834, Test loss: 1.652, Test accuracy: 81.08
Round  75, Global train loss: 1.834, Global test loss: 1.653, Global test accuracy: 81.32
Round  76, Train loss: 1.670, Test loss: 1.652, Test accuracy: 81.02
Round  76, Global train loss: 1.670, Global test loss: 1.646, Global test accuracy: 81.30
Round  77, Train loss: 1.821, Test loss: 1.653, Test accuracy: 80.96
Round  77, Global train loss: 1.821, Global test loss: 1.651, Global test accuracy: 81.10
Round  78, Train loss: 1.871, Test loss: 1.652, Test accuracy: 80.92
Round  78, Global train loss: 1.871, Global test loss: 1.652, Global test accuracy: 80.76
Round  79, Train loss: 1.756, Test loss: 1.652, Test accuracy: 81.08
Round  79, Global train loss: 1.756, Global test loss: 1.650, Global test accuracy: 81.28
Round  80, Train loss: 1.721, Test loss: 1.652, Test accuracy: 81.08
Round  80, Global train loss: 1.721, Global test loss: 1.643, Global test accuracy: 81.48
Round  81, Train loss: 1.828, Test loss: 1.651, Test accuracy: 81.18
Round  81, Global train loss: 1.828, Global test loss: 1.647, Global test accuracy: 81.86
Round  82, Train loss: 1.874, Test loss: 1.653, Test accuracy: 81.10
Round  82, Global train loss: 1.874, Global test loss: 1.654, Global test accuracy: 80.56
Round  83, Train loss: 1.749, Test loss: 1.653, Test accuracy: 81.08
Round  83, Global train loss: 1.749, Global test loss: 1.649, Global test accuracy: 81.22
Round  84, Train loss: 1.674, Test loss: 1.653, Test accuracy: 81.02
Round  84, Global train loss: 1.674, Global test loss: 1.643, Global test accuracy: 82.14
Round  85, Train loss: 1.826, Test loss: 1.652, Test accuracy: 81.08
Round  85, Global train loss: 1.826, Global test loss: 1.651, Global test accuracy: 80.74
Round  86, Train loss: 1.747, Test loss: 1.652, Test accuracy: 81.02
Round  86, Global train loss: 1.747, Global test loss: 1.648, Global test accuracy: 81.64
Round  87, Train loss: 1.655, Test loss: 1.652, Test accuracy: 81.04
Round  87, Global train loss: 1.655, Global test loss: 1.644, Global test accuracy: 82.40
Round  88, Train loss: 1.729, Test loss: 1.652, Test accuracy: 81.06
Round  88, Global train loss: 1.729, Global test loss: 1.645, Global test accuracy: 81.98
Round  89, Train loss: 1.747, Test loss: 1.652, Test accuracy: 81.06
Round  89, Global train loss: 1.747, Global test loss: 1.649, Global test accuracy: 81.46
Round  90, Train loss: 1.717, Test loss: 1.654, Test accuracy: 80.84
Round  90, Global train loss: 1.717, Global test loss: 1.647, Global test accuracy: 81.54
Round  91, Train loss: 1.715, Test loss: 1.652, Test accuracy: 81.04
Round  91, Global train loss: 1.715, Global test loss: 1.647, Global test accuracy: 81.78
Round  92, Train loss: 1.710, Test loss: 1.651, Test accuracy: 81.08
Round  92, Global train loss: 1.710, Global test loss: 1.644, Global test accuracy: 82.24
Round  93, Train loss: 1.722, Test loss: 1.651, Test accuracy: 81.18
Round  93, Global train loss: 1.722, Global test loss: 1.645, Global test accuracy: 81.96
Round  94, Train loss: 1.749, Test loss: 1.651, Test accuracy: 81.20
Round  94, Global train loss: 1.749, Global test loss: 1.645, Global test accuracy: 81.94/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  95, Train loss: 1.817, Test loss: 1.650, Test accuracy: 81.18
Round  95, Global train loss: 1.817, Global test loss: 1.651, Global test accuracy: 80.60
Round  96, Train loss: 1.816, Test loss: 1.651, Test accuracy: 81.10
Round  96, Global train loss: 1.816, Global test loss: 1.651, Global test accuracy: 81.20
Round  97, Train loss: 1.750, Test loss: 1.651, Test accuracy: 81.04
Round  97, Global train loss: 1.750, Global test loss: 1.645, Global test accuracy: 81.90
Round  98, Train loss: 1.731, Test loss: 1.651, Test accuracy: 80.98
Round  98, Global train loss: 1.731, Global test loss: 1.646, Global test accuracy: 81.74
Round  99, Train loss: 1.690, Test loss: 1.652, Test accuracy: 80.84
Round  99, Global train loss: 1.690, Global test loss: 1.645, Global test accuracy: 81.64
Final Round, Train loss: 1.746, Test loss: 1.652, Test accuracy: 80.98
Final Round, Global train loss: 1.746, Global test loss: 1.645, Global test accuracy: 81.64
Average accuracy final 10 rounds: 81.04800000000002 

Average global accuracy final 10 rounds: 81.65400000000001 

638.4353973865509
[0.8952674865722656, 1.7905349731445312, 2.6049540042877197, 3.419373035430908, 4.246297121047974, 5.073221206665039, 5.8798487186431885, 6.686476230621338, 7.470959663391113, 8.255443096160889, 9.083230018615723, 9.911016941070557, 10.691457509994507, 11.471898078918457, 12.304612159729004, 13.13732624053955, 13.942351579666138, 14.747376918792725, 15.533432722091675, 16.319488525390625, 17.146329164505005, 17.973169803619385, 18.80739164352417, 19.641613483428955, 20.4688241481781, 21.296034812927246, 22.139657974243164, 22.983281135559082, 23.821703672409058, 24.660126209259033, 25.48166251182556, 26.30319881439209, 27.140496969223022, 27.977795124053955, 28.793392658233643, 29.60899019241333, 30.38733148574829, 31.165672779083252, 31.988754987716675, 32.8118371963501, 33.6330509185791, 34.454264640808105, 35.249887466430664, 36.04551029205322, 36.83808159828186, 37.6306529045105, 38.477391481399536, 39.324130058288574, 40.10519528388977, 40.88626050949097, 41.72228455543518, 42.558308601379395, 43.40797996520996, 44.25765132904053, 45.182700872421265, 46.107750415802, 46.92565560340881, 47.743560791015625, 48.63130164146423, 49.51904249191284, 50.324846267700195, 51.13065004348755, 51.97619318962097, 52.821736335754395, 53.609127044677734, 54.396517753601074, 55.25841212272644, 56.12030649185181, 56.92349052429199, 57.72667455673218, 58.58662819862366, 59.44658184051514, 60.3083016872406, 61.170021533966064, 61.98521590232849, 62.80041027069092, 63.62928128242493, 64.45815229415894, 65.28857588768005, 66.11899948120117, 66.93445158004761, 67.74990367889404, 68.59510445594788, 69.44030523300171, 70.2886278629303, 71.13695049285889, 71.97233629226685, 72.8077220916748, 73.66617703437805, 74.5246319770813, 75.33098459243774, 76.13733720779419, 76.9708263874054, 77.8043155670166, 78.6640317440033, 79.52374792098999, 80.3551721572876, 81.1865963935852, 81.99179530143738, 82.79699420928955, 83.68537831306458, 84.5737624168396, 85.39355611801147, 86.21334981918335, 87.07474684715271, 87.93614387512207, 88.8031280040741, 89.67011213302612, 90.49333667755127, 91.31656122207642, 92.1813097000122, 93.046058177948, 93.87313294410706, 94.70020771026611, 95.52713060379028, 96.35405349731445, 97.26113963127136, 98.16822576522827, 98.98275637626648, 99.79728698730469, 100.6549961566925, 101.51270532608032, 102.35000777244568, 103.18731021881104, 104.16234183311462, 105.13737344741821, 105.95257878303528, 106.76778411865234, 107.61436939239502, 108.4609546661377, 109.29736828804016, 110.13378190994263, 110.98044395446777, 111.82710599899292, 112.62805438041687, 113.42900276184082, 114.2688217163086, 115.10864067077637, 115.92872619628906, 116.74881172180176, 117.56259894371033, 118.3763861656189, 119.21096324920654, 120.04554033279419, 120.8979423046112, 121.75034427642822, 122.55319023132324, 123.35603618621826, 124.26325678825378, 125.1704773902893, 125.98690271377563, 126.80332803726196, 127.64278244972229, 128.48223686218262, 129.33303499221802, 130.18383312225342, 130.99881148338318, 131.81378984451294, 132.6422872543335, 133.47078466415405, 134.31600522994995, 135.16122579574585, 135.9389533996582, 136.71668100357056, 137.54223012924194, 138.36777925491333, 139.21070313453674, 140.05362701416016, 140.87472081184387, 141.6958146095276, 142.5246925354004, 143.3535704612732, 144.23434352874756, 145.11511659622192, 145.9175043106079, 146.7198920249939, 147.5837278366089, 148.44756364822388, 149.2638645172119, 150.08016538619995, 150.91158080101013, 151.7429962158203, 152.58904218673706, 153.4350881576538, 154.31407117843628, 155.19305419921875, 156.03144812583923, 156.86984205245972, 157.702294588089, 158.53474712371826, 159.39300990104675, 160.25127267837524, 161.0651924610138, 161.87911224365234, 162.67851519584656, 163.47791814804077, 164.311537027359, 165.14515590667725, 165.95465350151062, 166.764151096344, 168.48617434501648, 170.20819759368896]
[13.58, 13.58, 12.56, 12.56, 17.72, 17.72, 21.42, 21.42, 25.62, 25.62, 32.58, 32.58, 42.06, 42.06, 52.12, 52.12, 63.52, 63.52, 65.5, 65.5, 72.28, 72.28, 74.08, 74.08, 74.52, 74.52, 75.2, 75.2, 75.2, 75.2, 75.6, 75.6, 78.72, 78.72, 78.82, 78.82, 79.84, 79.84, 80.2, 80.2, 80.48, 80.48, 80.68, 80.68, 80.68, 80.68, 80.56, 80.56, 80.66, 80.66, 80.82, 80.82, 80.76, 80.76, 80.8, 80.8, 80.84, 80.84, 81.02, 81.02, 80.94, 80.94, 80.86, 80.86, 80.86, 80.86, 80.84, 80.84, 81.0, 81.0, 80.78, 80.78, 80.94, 80.94, 80.86, 80.86, 80.96, 80.96, 81.0, 81.0, 81.06, 81.06, 81.06, 81.06, 80.98, 80.98, 81.06, 81.06, 80.98, 80.98, 80.98, 80.98, 80.92, 80.92, 80.98, 80.98, 80.98, 80.98, 81.04, 81.04, 80.78, 80.78, 80.66, 80.66, 80.62, 80.62, 80.7, 80.7, 80.68, 80.68, 80.72, 80.72, 80.6, 80.6, 80.66, 80.66, 80.66, 80.66, 80.64, 80.64, 80.76, 80.76, 80.76, 80.76, 80.92, 80.92, 80.96, 80.96, 81.04, 81.04, 81.06, 81.06, 81.02, 81.02, 80.92, 80.92, 81.0, 81.0, 81.0, 81.0, 80.94, 80.94, 80.98, 80.98, 81.06, 81.06, 81.12, 81.12, 81.04, 81.04, 81.08, 81.08, 81.02, 81.02, 80.96, 80.96, 80.92, 80.92, 81.08, 81.08, 81.08, 81.08, 81.18, 81.18, 81.1, 81.1, 81.08, 81.08, 81.02, 81.02, 81.08, 81.08, 81.02, 81.02, 81.04, 81.04, 81.06, 81.06, 81.06, 81.06, 80.84, 80.84, 81.04, 81.04, 81.08, 81.08, 81.18, 81.18, 81.2, 81.2, 81.18, 81.18, 81.1, 81.1, 81.04, 81.04, 80.98, 80.98, 80.84, 80.84, 80.98, 80.98]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.4 , level_n_lowerb:0.4  

   Client 6, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
prox
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.300, Test loss: 2.301, Test accuracy: 15.18
Round   0, Global train loss: 2.300, Global test loss: 2.301, Global test accuracy: 15.04
Round   1, Train loss: 2.299, Test loss: 2.299, Test accuracy: 19.64
Round   1, Global train loss: 2.299, Global test loss: 2.298, Global test accuracy: 20.88
Round   2, Train loss: 2.296, Test loss: 2.296, Test accuracy: 20.18
Round   2, Global train loss: 2.296, Global test loss: 2.293, Global test accuracy: 21.00
Round   3, Train loss: 2.285, Test loss: 2.284, Test accuracy: 18.40
Round   3, Global train loss: 2.285, Global test loss: 2.270, Global test accuracy: 17.02
Round   4, Train loss: 2.261, Test loss: 2.261, Test accuracy: 22.46
Round   4, Global train loss: 2.261, Global test loss: 2.237, Global test accuracy: 26.56
Round   5, Train loss: 2.236, Test loss: 2.238, Test accuracy: 25.32
Round   5, Global train loss: 2.236, Global test loss: 2.207, Global test accuracy: 30.62
Round   6, Train loss: 2.202, Test loss: 2.186, Test accuracy: 29.30
Round   6, Global train loss: 2.202, Global test loss: 2.131, Global test accuracy: 33.18
Round   7, Train loss: 2.158, Test loss: 2.140, Test accuracy: 35.18
Round   7, Global train loss: 2.158, Global test loss: 2.074, Global test accuracy: 42.04
Round   8, Train loss: 2.105, Test loss: 2.080, Test accuracy: 40.78
Round   8, Global train loss: 2.105, Global test loss: 2.005, Global test accuracy: 48.44
Round   9, Train loss: 2.064, Test loss: 2.055, Test accuracy: 42.24
Round   9, Global train loss: 2.064, Global test loss: 1.972, Global test accuracy: 48.74
Round  10, Train loss: 2.009, Test loss: 1.985, Test accuracy: 49.00
Round  10, Global train loss: 2.009, Global test loss: 1.936, Global test accuracy: 54.12
Round  11, Train loss: 2.030, Test loss: 1.941, Test accuracy: 55.20
Round  11, Global train loss: 2.030, Global test loss: 1.893, Global test accuracy: 61.96
Round  12, Train loss: 2.019, Test loss: 1.927, Test accuracy: 56.86
Round  12, Global train loss: 2.019, Global test loss: 1.865, Global test accuracy: 64.42
Round  13, Train loss: 1.928, Test loss: 1.905, Test accuracy: 58.96
Round  13, Global train loss: 1.928, Global test loss: 1.852, Global test accuracy: 63.26
Round  14, Train loss: 1.987, Test loss: 1.898, Test accuracy: 59.70
Round  14, Global train loss: 1.987, Global test loss: 1.828, Global test accuracy: 64.84
Round  15, Train loss: 1.946, Test loss: 1.881, Test accuracy: 61.14
Round  15, Global train loss: 1.946, Global test loss: 1.792, Global test accuracy: 68.82
Round  16, Train loss: 1.866, Test loss: 1.841, Test accuracy: 64.92
Round  16, Global train loss: 1.866, Global test loss: 1.770, Global test accuracy: 71.08
Round  17, Train loss: 1.812, Test loss: 1.826, Test accuracy: 65.84
Round  17, Global train loss: 1.812, Global test loss: 1.754, Global test accuracy: 72.08
Round  18, Train loss: 1.881, Test loss: 1.782, Test accuracy: 69.72
Round  18, Global train loss: 1.881, Global test loss: 1.747, Global test accuracy: 72.70
Round  19, Train loss: 1.869, Test loss: 1.766, Test accuracy: 70.82
Round  19, Global train loss: 1.869, Global test loss: 1.750, Global test accuracy: 71.88
Round  20, Train loss: 1.891, Test loss: 1.757, Test accuracy: 71.56
Round  20, Global train loss: 1.891, Global test loss: 1.755, Global test accuracy: 71.20
Round  21, Train loss: 1.847, Test loss: 1.757, Test accuracy: 71.42
Round  21, Global train loss: 1.847, Global test loss: 1.756, Global test accuracy: 71.32
Round  22, Train loss: 1.806, Test loss: 1.754, Test accuracy: 71.70
Round  22, Global train loss: 1.806, Global test loss: 1.744, Global test accuracy: 72.58
Round  23, Train loss: 1.882, Test loss: 1.752, Test accuracy: 71.86
Round  23, Global train loss: 1.882, Global test loss: 1.746, Global test accuracy: 72.16
Round  24, Train loss: 1.807, Test loss: 1.749, Test accuracy: 71.98
Round  24, Global train loss: 1.807, Global test loss: 1.733, Global test accuracy: 73.40
Round  25, Train loss: 1.817, Test loss: 1.749, Test accuracy: 72.00
Round  25, Global train loss: 1.817, Global test loss: 1.732, Global test accuracy: 72.94
Round  26, Train loss: 1.836, Test loss: 1.745, Test accuracy: 72.32
Round  26, Global train loss: 1.836, Global test loss: 1.735, Global test accuracy: 73.52
Round  27, Train loss: 1.755, Test loss: 1.742, Test accuracy: 72.68
Round  27, Global train loss: 1.755, Global test loss: 1.728, Global test accuracy: 73.52
Round  28, Train loss: 1.829, Test loss: 1.741, Test accuracy: 72.70
Round  28, Global train loss: 1.829, Global test loss: 1.731, Global test accuracy: 73.76
Round  29, Train loss: 1.837, Test loss: 1.739, Test accuracy: 73.02
Round  29, Global train loss: 1.837, Global test loss: 1.730, Global test accuracy: 73.52
Round  30, Train loss: 1.873, Test loss: 1.739, Test accuracy: 72.88
Round  30, Global train loss: 1.873, Global test loss: 1.732, Global test accuracy: 73.18
Round  31, Train loss: 1.823, Test loss: 1.735, Test accuracy: 73.14
Round  31, Global train loss: 1.823, Global test loss: 1.729, Global test accuracy: 73.58
Round  32, Train loss: 1.795, Test loss: 1.735, Test accuracy: 73.22
Round  32, Global train loss: 1.795, Global test loss: 1.720, Global test accuracy: 74.46
Round  33, Train loss: 1.829, Test loss: 1.735, Test accuracy: 73.16
Round  33, Global train loss: 1.829, Global test loss: 1.724, Global test accuracy: 73.84
Round  34, Train loss: 1.759, Test loss: 1.734, Test accuracy: 73.30
Round  34, Global train loss: 1.759, Global test loss: 1.719, Global test accuracy: 74.54
Round  35, Train loss: 1.790, Test loss: 1.733, Test accuracy: 73.30
Round  35, Global train loss: 1.790, Global test loss: 1.715, Global test accuracy: 74.28
Round  36, Train loss: 1.817, Test loss: 1.729, Test accuracy: 73.52
Round  36, Global train loss: 1.817, Global test loss: 1.725, Global test accuracy: 73.72
Round  37, Train loss: 1.791, Test loss: 1.727, Test accuracy: 73.48
Round  37, Global train loss: 1.791, Global test loss: 1.722, Global test accuracy: 74.44
Round  38, Train loss: 1.751, Test loss: 1.727, Test accuracy: 73.58
Round  38, Global train loss: 1.751, Global test loss: 1.715, Global test accuracy: 74.68
Round  39, Train loss: 1.787, Test loss: 1.726, Test accuracy: 73.58
Round  39, Global train loss: 1.787, Global test loss: 1.716, Global test accuracy: 74.92
Round  40, Train loss: 1.814, Test loss: 1.725, Test accuracy: 73.70
Round  40, Global train loss: 1.814, Global test loss: 1.719, Global test accuracy: 74.72
Round  41, Train loss: 1.798, Test loss: 1.724, Test accuracy: 73.80
Round  41, Global train loss: 1.798, Global test loss: 1.718, Global test accuracy: 74.64
Round  42, Train loss: 1.790, Test loss: 1.723, Test accuracy: 73.98
Round  42, Global train loss: 1.790, Global test loss: 1.717, Global test accuracy: 74.46
Round  43, Train loss: 1.826, Test loss: 1.721, Test accuracy: 74.22
Round  43, Global train loss: 1.826, Global test loss: 1.716, Global test accuracy: 74.52
Round  44, Train loss: 1.860, Test loss: 1.721, Test accuracy: 74.30
Round  44, Global train loss: 1.860, Global test loss: 1.720, Global test accuracy: 74.00
Round  45, Train loss: 1.808, Test loss: 1.721, Test accuracy: 74.30
Round  45, Global train loss: 1.808, Global test loss: 1.718, Global test accuracy: 74.38
Round  46, Train loss: 1.774, Test loss: 1.721, Test accuracy: 74.22
Round  46, Global train loss: 1.774, Global test loss: 1.718, Global test accuracy: 74.22
Round  47, Train loss: 1.785, Test loss: 1.721, Test accuracy: 74.24
Round  47, Global train loss: 1.785, Global test loss: 1.719, Global test accuracy: 73.98
Round  48, Train loss: 1.811, Test loss: 1.721, Test accuracy: 74.32
Round  48, Global train loss: 1.811, Global test loss: 1.717, Global test accuracy: 74.40
Round  49, Train loss: 1.771, Test loss: 1.720, Test accuracy: 74.38
Round  49, Global train loss: 1.771, Global test loss: 1.719, Global test accuracy: 74.22
Round  50, Train loss: 1.770, Test loss: 1.721, Test accuracy: 74.32
Round  50, Global train loss: 1.770, Global test loss: 1.720, Global test accuracy: 74.32
Round  51, Train loss: 1.847, Test loss: 1.722, Test accuracy: 74.10
Round  51, Global train loss: 1.847, Global test loss: 1.719, Global test accuracy: 73.98
Round  52, Train loss: 1.791, Test loss: 1.722, Test accuracy: 74.04
Round  52, Global train loss: 1.791, Global test loss: 1.725, Global test accuracy: 73.64
Round  53, Train loss: 1.803, Test loss: 1.722, Test accuracy: 74.08
Round  53, Global train loss: 1.803, Global test loss: 1.720, Global test accuracy: 74.00
Round  54, Train loss: 1.862, Test loss: 1.723, Test accuracy: 73.92
Round  54, Global train loss: 1.862, Global test loss: 1.721, Global test accuracy: 74.06
Round  55, Train loss: 1.814, Test loss: 1.724, Test accuracy: 73.78
Round  55, Global train loss: 1.814, Global test loss: 1.721, Global test accuracy: 73.98
Round  56, Train loss: 1.844, Test loss: 1.723, Test accuracy: 73.86
Round  56, Global train loss: 1.844, Global test loss: 1.721, Global test accuracy: 74.32
Round  57, Train loss: 1.841, Test loss: 1.722, Test accuracy: 74.00
Round  57, Global train loss: 1.841, Global test loss: 1.725, Global test accuracy: 73.04
Round  58, Train loss: 1.777, Test loss: 1.724, Test accuracy: 73.90
Round  58, Global train loss: 1.777, Global test loss: 1.720, Global test accuracy: 74.30
Round  59, Train loss: 1.839, Test loss: 1.723, Test accuracy: 73.98
Round  59, Global train loss: 1.839, Global test loss: 1.718, Global test accuracy: 74.18
Round  60, Train loss: 1.770, Test loss: 1.722, Test accuracy: 74.08
Round  60, Global train loss: 1.770, Global test loss: 1.715, Global test accuracy: 74.16
Round  61, Train loss: 1.843, Test loss: 1.721, Test accuracy: 74.12
Round  61, Global train loss: 1.843, Global test loss: 1.718, Global test accuracy: 74.30
Round  62, Train loss: 1.807, Test loss: 1.720, Test accuracy: 74.10
Round  62, Global train loss: 1.807, Global test loss: 1.715, Global test accuracy: 74.90
Round  63, Train loss: 1.781, Test loss: 1.721, Test accuracy: 74.14
Round  63, Global train loss: 1.781, Global test loss: 1.718, Global test accuracy: 75.08
Round  64, Train loss: 1.789, Test loss: 1.720, Test accuracy: 74.10
Round  64, Global train loss: 1.789, Global test loss: 1.717, Global test accuracy: 74.50
Round  65, Train loss: 1.734, Test loss: 1.721, Test accuracy: 74.16
Round  65, Global train loss: 1.734, Global test loss: 1.714, Global test accuracy: 75.52
Round  66, Train loss: 1.763, Test loss: 1.720, Test accuracy: 74.34
Round  66, Global train loss: 1.763, Global test loss: 1.716, Global test accuracy: 74.78
Round  67, Train loss: 1.798, Test loss: 1.720, Test accuracy: 74.40
Round  67, Global train loss: 1.798, Global test loss: 1.714, Global test accuracy: 75.04
Round  68, Train loss: 1.729, Test loss: 1.720, Test accuracy: 74.42
Round  68, Global train loss: 1.729, Global test loss: 1.715, Global test accuracy: 75.10
Round  69, Train loss: 1.789, Test loss: 1.719, Test accuracy: 74.44
Round  69, Global train loss: 1.789, Global test loss: 1.716, Global test accuracy: 74.42
Round  70, Train loss: 1.802, Test loss: 1.720, Test accuracy: 74.34
Round  70, Global train loss: 1.802, Global test loss: 1.715, Global test accuracy: 74.74
Round  71, Train loss: 1.836, Test loss: 1.720, Test accuracy: 74.36
Round  71, Global train loss: 1.836, Global test loss: 1.716, Global test accuracy: 74.38
Round  72, Train loss: 1.866, Test loss: 1.720, Test accuracy: 74.40
Round  72, Global train loss: 1.866, Global test loss: 1.717, Global test accuracy: 74.54
Round  73, Train loss: 1.797, Test loss: 1.720, Test accuracy: 74.40
Round  73, Global train loss: 1.797, Global test loss: 1.717, Global test accuracy: 74.44
Round  74, Train loss: 1.794, Test loss: 1.720, Test accuracy: 74.26
Round  74, Global train loss: 1.794, Global test loss: 1.714, Global test accuracy: 75.02
Round  75, Train loss: 1.808, Test loss: 1.719, Test accuracy: 74.42
Round  75, Global train loss: 1.808, Global test loss: 1.714, Global test accuracy: 74.92
Round  76, Train loss: 1.779, Test loss: 1.718, Test accuracy: 74.42
Round  76, Global train loss: 1.779, Global test loss: 1.715, Global test accuracy: 74.68
Round  77, Train loss: 1.732, Test loss: 1.719, Test accuracy: 74.36
Round  77, Global train loss: 1.732, Global test loss: 1.712, Global test accuracy: 75.06
Round  78, Train loss: 1.771, Test loss: 1.719, Test accuracy: 74.32
Round  78, Global train loss: 1.771, Global test loss: 1.712, Global test accuracy: 74.90
Round  79, Train loss: 1.832, Test loss: 1.718, Test accuracy: 74.38
Round  79, Global train loss: 1.832, Global test loss: 1.714, Global test accuracy: 74.80
Round  80, Train loss: 1.830, Test loss: 1.716, Test accuracy: 74.60
Round  80, Global train loss: 1.830, Global test loss: 1.715, Global test accuracy: 75.08
Round  81, Train loss: 1.737, Test loss: 1.716, Test accuracy: 74.64
Round  81, Global train loss: 1.737, Global test loss: 1.711, Global test accuracy: 75.26
Round  82, Train loss: 1.839, Test loss: 1.715, Test accuracy: 74.68
Round  82, Global train loss: 1.839, Global test loss: 1.710, Global test accuracy: 75.08
Round  83, Train loss: 1.767, Test loss: 1.715, Test accuracy: 74.76
Round  83, Global train loss: 1.767, Global test loss: 1.712, Global test accuracy: 75.02
Round  84, Train loss: 1.802, Test loss: 1.715, Test accuracy: 74.70
Round  84, Global train loss: 1.802, Global test loss: 1.715, Global test accuracy: 74.96
Round  85, Train loss: 1.796, Test loss: 1.715, Test accuracy: 74.72
Round  85, Global train loss: 1.796, Global test loss: 1.711, Global test accuracy: 75.30
Round  86, Train loss: 1.835, Test loss: 1.716, Test accuracy: 74.64
Round  86, Global train loss: 1.835, Global test loss: 1.713, Global test accuracy: 74.78
Round  87, Train loss: 1.753, Test loss: 1.716, Test accuracy: 74.68
Round  87, Global train loss: 1.753, Global test loss: 1.714, Global test accuracy: 74.90
Round  88, Train loss: 1.731, Test loss: 1.716, Test accuracy: 74.66
Round  88, Global train loss: 1.731, Global test loss: 1.712, Global test accuracy: 75.06
Round  89, Train loss: 1.834, Test loss: 1.715, Test accuracy: 74.82
Round  89, Global train loss: 1.834, Global test loss: 1.714, Global test accuracy: 74.90
Round  90, Train loss: 1.825, Test loss: 1.715, Test accuracy: 74.80
Round  90, Global train loss: 1.825, Global test loss: 1.713, Global test accuracy: 75.02
Round  91, Train loss: 1.824, Test loss: 1.715, Test accuracy: 74.82
Round  91, Global train loss: 1.824, Global test loss: 1.713, Global test accuracy: 74.94
Round  92, Train loss: 1.756, Test loss: 1.715, Test accuracy: 74.74
Round  92, Global train loss: 1.756, Global test loss: 1.715, Global test accuracy: 74.64
Round  93, Train loss: 1.725, Test loss: 1.716, Test accuracy: 74.56
Round  93, Global train loss: 1.725, Global test loss: 1.712, Global test accuracy: 75.16
Round  94, Train loss: 1.827, Test loss: 1.715, Test accuracy: 74.66
Round  94, Global train loss: 1.827, Global test loss: 1.713, Global test accuracy: 74.76/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  95, Train loss: 1.833, Test loss: 1.715, Test accuracy: 74.70
Round  95, Global train loss: 1.833, Global test loss: 1.713, Global test accuracy: 74.98
Round  96, Train loss: 1.832, Test loss: 1.715, Test accuracy: 74.72
Round  96, Global train loss: 1.832, Global test loss: 1.712, Global test accuracy: 75.24
Round  97, Train loss: 1.761, Test loss: 1.715, Test accuracy: 74.80
Round  97, Global train loss: 1.761, Global test loss: 1.712, Global test accuracy: 75.00
Round  98, Train loss: 1.787, Test loss: 1.714, Test accuracy: 74.76
Round  98, Global train loss: 1.787, Global test loss: 1.714, Global test accuracy: 74.70
Round  99, Train loss: 1.721, Test loss: 1.715, Test accuracy: 74.76
Round  99, Global train loss: 1.721, Global test loss: 1.714, Global test accuracy: 74.52
Final Round, Train loss: 1.790, Test loss: 1.715, Test accuracy: 74.56
Final Round, Global train loss: 1.790, Global test loss: 1.714, Global test accuracy: 74.52
Average accuracy final 10 rounds: 74.732 

Average global accuracy final 10 rounds: 74.896 

680.0977163314819
[1.1021928787231445, 2.204385757446289, 3.115753412246704, 4.027121067047119, 4.982229948043823, 5.937338829040527, 6.810779094696045, 7.6842193603515625, 8.645290613174438, 9.606361865997314, 10.554673194885254, 11.502984523773193, 12.407418012619019, 13.311851501464844, 14.275102138519287, 15.23835277557373, 16.188352823257446, 17.138352870941162, 18.139808654785156, 19.14126443862915, 20.107784509658813, 21.074304580688477, 22.072762966156006, 23.071221351623535, 24.050004720687866, 25.028788089752197, 26.06583285331726, 27.102877616882324, 28.111939430236816, 29.12100124359131, 30.14775824546814, 31.17451524734497, 32.208322286605835, 33.2421293258667, 34.246866941452026, 35.25160455703735, 36.27212715148926, 37.29264974594116, 38.28438758850098, 39.27612543106079, 40.212831258773804, 41.149537086486816, 42.12919354438782, 43.10885000228882, 44.11263942718506, 45.1164288520813, 46.10736107826233, 47.09829330444336, 48.12078332901001, 49.14327335357666, 50.058966636657715, 50.97465991973877, 52.002947092056274, 53.03123426437378, 54.00356340408325, 54.975892543792725, 55.922542333602905, 56.869192123413086, 57.876177072525024, 58.88316202163696, 59.90236186981201, 60.92156171798706, 61.89849305152893, 62.8754243850708, 63.87583351135254, 64.87624263763428, 65.88044571876526, 66.88464879989624, 67.91424131393433, 68.94383382797241, 69.96317625045776, 70.98251867294312, 72.02343916893005, 73.06435966491699, 74.05896067619324, 75.05356168746948, 76.02859807014465, 77.00363445281982, 77.95607423782349, 78.90851402282715, 79.88408899307251, 80.85966396331787, 81.84447479248047, 82.82928562164307, 83.85137271881104, 84.873459815979, 85.86319780349731, 86.85293579101562, 87.84793496131897, 88.84293413162231, 89.81876993179321, 90.79460573196411, 91.82602310180664, 92.85744047164917, 93.85188841819763, 94.8463363647461, 95.77000522613525, 96.69367408752441, 97.69075226783752, 98.68783044815063, 99.59281277656555, 100.49779510498047, 101.45278739929199, 102.40777969360352, 103.27187037467957, 104.13596105575562, 105.08196568489075, 106.02797031402588, 106.92430257797241, 107.82063484191895, 108.77549338340759, 109.73035192489624, 110.64073491096497, 111.55111789703369, 112.45368528366089, 113.35625267028809, 114.27710008621216, 115.19794750213623, 116.12576961517334, 117.05359172821045, 117.94918823242188, 118.8447847366333, 120.23958802223206, 121.63439130783081, 122.57272386550903, 123.51105642318726, 124.43615460395813, 125.361252784729, 126.28248143196106, 127.20371007919312, 128.112699508667, 129.02168893814087, 129.96283388137817, 130.90397882461548, 131.8357355594635, 132.76749229431152, 133.73234844207764, 134.69720458984375, 135.60669422149658, 136.5161838531494, 137.45365381240845, 138.39112377166748, 139.30897164344788, 140.22681951522827, 141.12655353546143, 142.02628755569458, 142.9440529346466, 143.86181831359863, 144.82262516021729, 145.78343200683594, 146.71165823936462, 147.6398844718933, 148.57577323913574, 149.51166200637817, 150.42529606819153, 151.33893013000488, 152.30392837524414, 153.2689266204834, 154.21115374565125, 155.1533808708191, 156.104651927948, 157.0559229850769, 157.9813094139099, 158.90669584274292, 159.8046932220459, 160.70269060134888, 161.66169595718384, 162.6207013130188, 163.55786848068237, 164.49503564834595, 165.5124683380127, 166.52990102767944, 167.46527361869812, 168.4006462097168, 169.34493589401245, 170.2892255783081, 171.20954251289368, 172.12985944747925, 173.01815485954285, 173.90645027160645, 174.79823565483093, 175.69002103805542, 176.62347769737244, 177.55693435668945, 178.46199107170105, 179.36704778671265, 180.2728636264801, 181.17867946624756, 182.09251284599304, 183.00634622573853, 183.95172333717346, 184.8971004486084, 185.8610405921936, 186.8249807357788, 187.80026721954346, 188.7755537033081, 189.7737808227539, 190.7720079421997, 191.68368554115295, 192.5953631401062, 194.45886611938477, 196.32236909866333]
[15.18, 15.18, 19.64, 19.64, 20.18, 20.18, 18.4, 18.4, 22.46, 22.46, 25.32, 25.32, 29.3, 29.3, 35.18, 35.18, 40.78, 40.78, 42.24, 42.24, 49.0, 49.0, 55.2, 55.2, 56.86, 56.86, 58.96, 58.96, 59.7, 59.7, 61.14, 61.14, 64.92, 64.92, 65.84, 65.84, 69.72, 69.72, 70.82, 70.82, 71.56, 71.56, 71.42, 71.42, 71.7, 71.7, 71.86, 71.86, 71.98, 71.98, 72.0, 72.0, 72.32, 72.32, 72.68, 72.68, 72.7, 72.7, 73.02, 73.02, 72.88, 72.88, 73.14, 73.14, 73.22, 73.22, 73.16, 73.16, 73.3, 73.3, 73.3, 73.3, 73.52, 73.52, 73.48, 73.48, 73.58, 73.58, 73.58, 73.58, 73.7, 73.7, 73.8, 73.8, 73.98, 73.98, 74.22, 74.22, 74.3, 74.3, 74.3, 74.3, 74.22, 74.22, 74.24, 74.24, 74.32, 74.32, 74.38, 74.38, 74.32, 74.32, 74.1, 74.1, 74.04, 74.04, 74.08, 74.08, 73.92, 73.92, 73.78, 73.78, 73.86, 73.86, 74.0, 74.0, 73.9, 73.9, 73.98, 73.98, 74.08, 74.08, 74.12, 74.12, 74.1, 74.1, 74.14, 74.14, 74.1, 74.1, 74.16, 74.16, 74.34, 74.34, 74.4, 74.4, 74.42, 74.42, 74.44, 74.44, 74.34, 74.34, 74.36, 74.36, 74.4, 74.4, 74.4, 74.4, 74.26, 74.26, 74.42, 74.42, 74.42, 74.42, 74.36, 74.36, 74.32, 74.32, 74.38, 74.38, 74.6, 74.6, 74.64, 74.64, 74.68, 74.68, 74.76, 74.76, 74.7, 74.7, 74.72, 74.72, 74.64, 74.64, 74.68, 74.68, 74.66, 74.66, 74.82, 74.82, 74.8, 74.8, 74.82, 74.82, 74.74, 74.74, 74.56, 74.56, 74.66, 74.66, 74.7, 74.7, 74.72, 74.72, 74.8, 74.8, 74.76, 74.76, 74.76, 74.76, 74.56, 74.56]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.4 , level_n_lowerb:0.4  

   Client 7, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Traceback (most recent call last):
  File "main_fedpac_co_teaching.py", line 250, in <module>
    local.filter_data(net=net_local.to(args.device), net2=net_local2.to(args.device), concept_matrix_local = concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1587, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

   Client 8, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.320, Test loss: 2.302, Test accuracy: 13.62
Round   0, Global train loss: 2.320, Global test loss: 2.302, Global test accuracy: 13.68
Round   1, Train loss: 2.302, Test loss: 2.299, Test accuracy: 17.50
Round   1, Global train loss: 2.302, Global test loss: 2.299, Global test accuracy: 17.28
Round   2, Train loss: 2.298, Test loss: 2.296, Test accuracy: 18.38
Round   2, Global train loss: 2.298, Global test loss: 2.296, Global test accuracy: 18.06
Round   3, Train loss: 2.293, Test loss: 2.290, Test accuracy: 15.34
Round   3, Global train loss: 2.293, Global test loss: 2.290, Global test accuracy: 13.76
Round   4, Train loss: 2.288, Test loss: 2.279, Test accuracy: 14.18
Round   4, Global train loss: 2.288, Global test loss: 2.279, Global test accuracy: 12.98
Round   5, Train loss: 2.263, Test loss: 2.251, Test accuracy: 15.68
Round   5, Global train loss: 2.263, Global test loss: 2.246, Global test accuracy: 13.76
Round   6, Train loss: 2.260, Test loss: 2.236, Test accuracy: 22.08
Round   6, Global train loss: 2.260, Global test loss: 2.233, Global test accuracy: 22.26
Round   7, Train loss: 2.250, Test loss: 2.226, Test accuracy: 23.82
Round   7, Global train loss: 2.250, Global test loss: 2.223, Global test accuracy: 23.54
Round   8, Train loss: 2.226, Test loss: 2.197, Test accuracy: 37.56
Round   8, Global train loss: 2.226, Global test loss: 2.191, Global test accuracy: 38.90
Round   9, Train loss: 2.200, Test loss: 2.162, Test accuracy: 39.78
Round   9, Global train loss: 2.200, Global test loss: 2.155, Global test accuracy: 39.96
Round  10, Train loss: 2.183, Test loss: 2.119, Test accuracy: 41.64
Round  10, Global train loss: 2.183, Global test loss: 2.112, Global test accuracy: 41.88
Round  11, Train loss: 2.115, Test loss: 2.067, Test accuracy: 43.90
Round  11, Global train loss: 2.115, Global test loss: 2.046, Global test accuracy: 44.06
Round  12, Train loss: 2.159, Test loss: 2.056, Test accuracy: 44.94
Round  12, Global train loss: 2.159, Global test loss: 2.047, Global test accuracy: 44.64
Round  13, Train loss: 2.135, Test loss: 2.037, Test accuracy: 45.56
Round  13, Global train loss: 2.135, Global test loss: 2.028, Global test accuracy: 45.04
Round  14, Train loss: 2.098, Test loss: 2.022, Test accuracy: 47.16
Round  14, Global train loss: 2.098, Global test loss: 2.003, Global test accuracy: 48.28
Round  15, Train loss: 2.125, Test loss: 2.018, Test accuracy: 48.28
Round  15, Global train loss: 2.125, Global test loss: 2.004, Global test accuracy: 47.20
Round  16, Train loss: 2.090, Test loss: 1.999, Test accuracy: 50.40
Round  16, Global train loss: 2.090, Global test loss: 1.984, Global test accuracy: 51.98
Round  17, Train loss: 2.035, Test loss: 1.979, Test accuracy: 50.68
Round  17, Global train loss: 2.035, Global test loss: 1.964, Global test accuracy: 50.54
Round  18, Train loss: 1.972, Test loss: 1.947, Test accuracy: 53.20
Round  18, Global train loss: 1.972, Global test loss: 1.928, Global test accuracy: 57.32
Round  19, Train loss: 2.060, Test loss: 1.944, Test accuracy: 54.04
Round  19, Global train loss: 2.060, Global test loss: 1.937, Global test accuracy: 55.00
Round  20, Train loss: 2.086, Test loss: 1.951, Test accuracy: 54.48
Round  20, Global train loss: 2.086, Global test loss: 1.942, Global test accuracy: 55.22
Round  21, Train loss: 2.051, Test loss: 1.950, Test accuracy: 54.82
Round  21, Global train loss: 2.051, Global test loss: 1.941, Global test accuracy: 55.58
Round  22, Train loss: 2.033, Test loss: 1.942, Test accuracy: 55.10
Round  22, Global train loss: 2.033, Global test loss: 1.933, Global test accuracy: 54.94
Round  23, Train loss: 2.023, Test loss: 1.933, Test accuracy: 56.06
Round  23, Global train loss: 2.023, Global test loss: 1.937, Global test accuracy: 54.40
Round  24, Train loss: 1.948, Test loss: 1.908, Test accuracy: 58.46
Round  24, Global train loss: 1.948, Global test loss: 1.893, Global test accuracy: 59.96
Round  25, Train loss: 1.950, Test loss: 1.888, Test accuracy: 61.00
Round  25, Global train loss: 1.950, Global test loss: 1.862, Global test accuracy: 66.20
Round  26, Train loss: 2.014, Test loss: 1.895, Test accuracy: 61.74
Round  26, Global train loss: 2.014, Global test loss: 1.909, Global test accuracy: 56.86
Round  27, Train loss: 1.986, Test loss: 1.888, Test accuracy: 62.26
Round  27, Global train loss: 1.986, Global test loss: 1.870, Global test accuracy: 62.96
Round  28, Train loss: 1.991, Test loss: 1.891, Test accuracy: 62.48
Round  28, Global train loss: 1.991, Global test loss: 1.902, Global test accuracy: 59.52
Round  29, Train loss: 1.957, Test loss: 1.865, Test accuracy: 64.72
Round  29, Global train loss: 1.957, Global test loss: 1.851, Global test accuracy: 66.46
Round  30, Train loss: 1.899, Test loss: 1.847, Test accuracy: 66.32
Round  30, Global train loss: 1.899, Global test loss: 1.829, Global test accuracy: 69.12
Round  31, Train loss: 1.960, Test loss: 1.846, Test accuracy: 67.94
Round  31, Global train loss: 1.960, Global test loss: 1.877, Global test accuracy: 61.32
Round  32, Train loss: 1.890, Test loss: 1.829, Test accuracy: 68.90
Round  32, Global train loss: 1.890, Global test loss: 1.808, Global test accuracy: 69.60
Round  33, Train loss: 1.920, Test loss: 1.823, Test accuracy: 69.84
Round  33, Global train loss: 1.920, Global test loss: 1.814, Global test accuracy: 69.88
Round  34, Train loss: 1.780, Test loss: 1.792, Test accuracy: 72.50
Round  34, Global train loss: 1.780, Global test loss: 1.737, Global test accuracy: 79.76
Round  35, Train loss: 1.745, Test loss: 1.773, Test accuracy: 73.82
Round  35, Global train loss: 1.745, Global test loss: 1.709, Global test accuracy: 83.26
Round  36, Train loss: 1.936, Test loss: 1.780, Test accuracy: 74.74
Round  36, Global train loss: 1.936, Global test loss: 1.788, Global test accuracy: 72.84
Round  37, Train loss: 1.916, Test loss: 1.774, Test accuracy: 76.42
Round  37, Global train loss: 1.916, Global test loss: 1.737, Global test accuracy: 83.06
Round  38, Train loss: 1.700, Test loss: 1.739, Test accuracy: 79.20
Round  38, Global train loss: 1.700, Global test loss: 1.664, Global test accuracy: 87.66
Round  39, Train loss: 1.824, Test loss: 1.735, Test accuracy: 80.34
Round  39, Global train loss: 1.824, Global test loss: 1.704, Global test accuracy: 84.02
Round  40, Train loss: 1.909, Test loss: 1.755, Test accuracy: 80.62
Round  40, Global train loss: 1.909, Global test loss: 1.789, Global test accuracy: 73.76
Round  41, Train loss: 1.788, Test loss: 1.722, Test accuracy: 82.10
Round  41, Global train loss: 1.788, Global test loss: 1.662, Global test accuracy: 88.48
Round  42, Train loss: 1.676, Test loss: 1.700, Test accuracy: 82.72
Round  42, Global train loss: 1.676, Global test loss: 1.632, Global test accuracy: 89.62
Round  43, Train loss: 1.668, Test loss: 1.681, Test accuracy: 83.76
Round  43, Global train loss: 1.668, Global test loss: 1.625, Global test accuracy: 90.28
Round  44, Train loss: 1.889, Test loss: 1.694, Test accuracy: 83.54
Round  44, Global train loss: 1.889, Global test loss: 1.681, Global test accuracy: 86.72
Round  45, Train loss: 1.752, Test loss: 1.697, Test accuracy: 83.36
Round  45, Global train loss: 1.752, Global test loss: 1.666, Global test accuracy: 86.98
Round  46, Train loss: 1.760, Test loss: 1.685, Test accuracy: 84.44
Round  46, Global train loss: 1.760, Global test loss: 1.643, Global test accuracy: 90.14
Round  47, Train loss: 1.844, Test loss: 1.690, Test accuracy: 84.28
Round  47, Global train loss: 1.844, Global test loss: 1.663, Global test accuracy: 87.94
Round  48, Train loss: 1.747, Test loss: 1.684, Test accuracy: 84.56
Round  48, Global train loss: 1.747, Global test loss: 1.653, Global test accuracy: 88.40
Round  49, Train loss: 1.735, Test loss: 1.678, Test accuracy: 84.62
Round  49, Global train loss: 1.735, Global test loss: 1.634, Global test accuracy: 89.76
Round  50, Train loss: 1.719, Test loss: 1.678, Test accuracy: 84.74
Round  50, Global train loss: 1.719, Global test loss: 1.632, Global test accuracy: 89.32
Round  51, Train loss: 1.759, Test loss: 1.675, Test accuracy: 84.88
Round  51, Global train loss: 1.759, Global test loss: 1.655, Global test accuracy: 88.34
Round  52, Train loss: 1.921, Test loss: 1.719, Test accuracy: 82.48
Round  52, Global train loss: 1.921, Global test loss: 1.784, Global test accuracy: 74.62
Round  53, Train loss: 1.714, Test loss: 1.671, Test accuracy: 85.76
Round  53, Global train loss: 1.714, Global test loss: 1.644, Global test accuracy: 88.46
Round  54, Train loss: 1.734, Test loss: 1.662, Test accuracy: 85.98
Round  54, Global train loss: 1.734, Global test loss: 1.628, Global test accuracy: 89.98
Round  55, Train loss: 1.698, Test loss: 1.657, Test accuracy: 86.20
Round  55, Global train loss: 1.698, Global test loss: 1.619, Global test accuracy: 90.76
Round  56, Train loss: 1.671, Test loss: 1.644, Test accuracy: 87.46
Round  56, Global train loss: 1.671, Global test loss: 1.609, Global test accuracy: 90.92
Round  57, Train loss: 1.894, Test loss: 1.680, Test accuracy: 85.42
Round  57, Global train loss: 1.894, Global test loss: 1.717, Global test accuracy: 82.82
Round  58, Train loss: 1.698, Test loss: 1.666, Test accuracy: 86.64
Round  58, Global train loss: 1.698, Global test loss: 1.626, Global test accuracy: 90.66
Round  59, Train loss: 1.577, Test loss: 1.639, Test accuracy: 88.18
Round  59, Global train loss: 1.577, Global test loss: 1.597, Global test accuracy: 91.40
Round  60, Train loss: 1.697, Test loss: 1.644, Test accuracy: 87.70
Round  60, Global train loss: 1.697, Global test loss: 1.621, Global test accuracy: 90.34
Round  61, Train loss: 1.775, Test loss: 1.656, Test accuracy: 86.98
Round  61, Global train loss: 1.775, Global test loss: 1.640, Global test accuracy: 88.90
Round  62, Train loss: 1.585, Test loss: 1.642, Test accuracy: 88.08
Round  62, Global train loss: 1.585, Global test loss: 1.599, Global test accuracy: 91.36
Round  63, Train loss: 1.694, Test loss: 1.645, Test accuracy: 87.56
Round  63, Global train loss: 1.694, Global test loss: 1.608, Global test accuracy: 90.30
Round  64, Train loss: 1.786, Test loss: 1.658, Test accuracy: 86.92
Round  64, Global train loss: 1.786, Global test loss: 1.667, Global test accuracy: 87.78
Round  65, Train loss: 1.577, Test loss: 1.640, Test accuracy: 88.22
Round  65, Global train loss: 1.577, Global test loss: 1.593, Global test accuracy: 90.96
Round  66, Train loss: 1.753, Test loss: 1.661, Test accuracy: 86.82
Round  66, Global train loss: 1.753, Global test loss: 1.664, Global test accuracy: 86.04
Round  67, Train loss: 1.570, Test loss: 1.628, Test accuracy: 88.66
Round  67, Global train loss: 1.570, Global test loss: 1.592, Global test accuracy: 91.40
Round  68, Train loss: 1.689, Test loss: 1.642, Test accuracy: 88.02
Round  68, Global train loss: 1.689, Global test loss: 1.613, Global test accuracy: 89.70
Round  69, Train loss: 1.753, Test loss: 1.653, Test accuracy: 87.72
Round  69, Global train loss: 1.753, Global test loss: 1.650, Global test accuracy: 88.04
Round  70, Train loss: 1.664, Test loss: 1.657, Test accuracy: 87.24
Round  70, Global train loss: 1.664, Global test loss: 1.638, Global test accuracy: 88.54
Round  71, Train loss: 1.657, Test loss: 1.641, Test accuracy: 88.34
Round  71, Global train loss: 1.657, Global test loss: 1.623, Global test accuracy: 90.04
Round  72, Train loss: 1.641, Test loss: 1.641, Test accuracy: 88.06
Round  72, Global train loss: 1.641, Global test loss: 1.621, Global test accuracy: 90.36
Round  73, Train loss: 1.619, Test loss: 1.639, Test accuracy: 88.14
Round  73, Global train loss: 1.619, Global test loss: 1.613, Global test accuracy: 90.16
Round  74, Train loss: 1.547, Test loss: 1.618, Test accuracy: 89.20
Round  74, Global train loss: 1.547, Global test loss: 1.587, Global test accuracy: 91.64
Round  75, Train loss: 1.573, Test loss: 1.620, Test accuracy: 89.28
Round  75, Global train loss: 1.573, Global test loss: 1.590, Global test accuracy: 91.84
Round  76, Train loss: 1.707, Test loss: 1.643, Test accuracy: 88.06
Round  76, Global train loss: 1.707, Global test loss: 1.641, Global test accuracy: 87.90
Round  77, Train loss: 1.552, Test loss: 1.628, Test accuracy: 88.92
Round  77, Global train loss: 1.552, Global test loss: 1.585, Global test accuracy: 91.98
Round  78, Train loss: 1.567, Test loss: 1.626, Test accuracy: 88.88
Round  78, Global train loss: 1.567, Global test loss: 1.589, Global test accuracy: 91.50
Round  79, Train loss: 1.627, Test loss: 1.634, Test accuracy: 88.40
Round  79, Global train loss: 1.627, Global test loss: 1.613, Global test accuracy: 90.40
Round  80, Train loss: 1.744, Test loss: 1.641, Test accuracy: 88.06
Round  80, Global train loss: 1.744, Global test loss: 1.636, Global test accuracy: 89.08
Round  81, Train loss: 1.563, Test loss: 1.630, Test accuracy: 88.96
Round  81, Global train loss: 1.563, Global test loss: 1.592, Global test accuracy: 91.86
Round  82, Train loss: 1.557, Test loss: 1.628, Test accuracy: 88.78
Round  82, Global train loss: 1.557, Global test loss: 1.597, Global test accuracy: 90.88
Round  83, Train loss: 1.631, Test loss: 1.648, Test accuracy: 87.26
Round  83, Global train loss: 1.631, Global test loss: 1.627, Global test accuracy: 89.02
Round  84, Train loss: 1.709, Test loss: 1.650, Test accuracy: 87.52
Round  84, Global train loss: 1.709, Global test loss: 1.636, Global test accuracy: 89.72
Round  85, Train loss: 1.536, Test loss: 1.627, Test accuracy: 88.74
Round  85, Global train loss: 1.536, Global test loss: 1.592, Global test accuracy: 91.12
Round  86, Train loss: 1.615, Test loss: 1.623, Test accuracy: 88.90
Round  86, Global train loss: 1.615, Global test loss: 1.594, Global test accuracy: 91.60
Round  87, Train loss: 1.702, Test loss: 1.650, Test accuracy: 87.46
Round  87, Global train loss: 1.702, Global test loss: 1.645, Global test accuracy: 87.92
Round  88, Train loss: 1.608, Test loss: 1.640, Test accuracy: 88.10
Round  88, Global train loss: 1.608, Global test loss: 1.609, Global test accuracy: 90.64
Round  89, Train loss: 1.614, Test loss: 1.625, Test accuracy: 88.78
Round  89, Global train loss: 1.614, Global test loss: 1.597, Global test accuracy: 91.80
Round  90, Train loss: 1.673, Test loss: 1.657, Test accuracy: 86.86
Round  90, Global train loss: 1.673, Global test loss: 1.664, Global test accuracy: 85.88
Round  91, Train loss: 1.649, Test loss: 1.678, Test accuracy: 84.76
Round  91, Global train loss: 1.649, Global test loss: 1.679, Global test accuracy: 84.84/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  92, Train loss: 1.674, Test loss: 1.680, Test accuracy: 85.04
Round  92, Global train loss: 1.674, Global test loss: 1.679, Global test accuracy: 85.44
Round  93, Train loss: 1.579, Test loss: 1.643, Test accuracy: 87.82
Round  93, Global train loss: 1.579, Global test loss: 1.611, Global test accuracy: 90.36
Round  94, Train loss: 1.605, Test loss: 1.624, Test accuracy: 88.88
Round  94, Global train loss: 1.605, Global test loss: 1.605, Global test accuracy: 90.24
Round  95, Train loss: 1.538, Test loss: 1.614, Test accuracy: 89.58
Round  95, Global train loss: 1.538, Global test loss: 1.588, Global test accuracy: 90.90
Round  96, Train loss: 1.529, Test loss: 1.614, Test accuracy: 89.38
Round  96, Global train loss: 1.529, Global test loss: 1.588, Global test accuracy: 91.22
Round  97, Train loss: 1.594, Test loss: 1.627, Test accuracy: 88.64
Round  97, Global train loss: 1.594, Global test loss: 1.605, Global test accuracy: 90.54
Round  98, Train loss: 1.666, Test loss: 1.658, Test accuracy: 86.22
Round  98, Global train loss: 1.666, Global test loss: 1.672, Global test accuracy: 85.26
Round  99, Train loss: 1.652, Test loss: 1.671, Test accuracy: 85.16
Round  99, Global train loss: 1.652, Global test loss: 1.659, Global test accuracy: 86.76
Final Round, Train loss: 1.592, Test loss: 1.655, Test accuracy: 86.08
Final Round, Global train loss: 1.592, Global test loss: 1.659, Global test accuracy: 86.76
Average accuracy final 10 rounds: 87.23400000000001
562.1042840480804
[1.2529668807983398, 2.350270986557007, 3.4325172901153564, 4.5564398765563965, 5.682840347290039, 6.688522100448608, 7.750666379928589, 8.767408609390259, 9.782353401184082, 10.82554316520691, 11.856491088867188, 12.83457064628601, 13.780858516693115, 14.783729076385498, 15.799543142318726, 16.790369033813477, 17.82550048828125, 18.81553864479065, 19.811271905899048, 20.812912702560425, 21.830544471740723, 22.897666692733765, 23.961365461349487, 24.99311590194702, 26.023508548736572, 27.07207465171814, 28.246342658996582, 29.35552954673767, 30.41777205467224, 31.435093879699707, 32.4694709777832, 33.567413568496704, 34.547775745391846, 35.54742097854614, 36.52603077888489, 37.55318880081177, 38.516456842422485, 39.50616526603699, 40.503050088882446, 41.480287313461304, 42.49277377128601, 43.501649618148804, 44.4933876991272, 45.48644709587097, 46.5343279838562, 47.50105285644531, 48.48509073257446, 49.48699879646301, 50.4822518825531, 51.425987005233765, 52.43890309333801, 53.38803672790527, 54.346096992492676, 55.32738924026489, 56.27756428718567, 57.262861490249634, 58.30052709579468, 59.3015615940094, 60.261927366256714, 61.276803493499756, 62.266655683517456, 63.23738384246826, 64.26567792892456, 65.2928352355957, 66.30284214019775, 67.31217980384827, 68.2988588809967, 69.29343700408936, 70.30982112884521, 71.32446527481079, 72.36809468269348, 73.4168598651886, 74.43728947639465, 75.42146372795105, 76.3941740989685, 77.37629532814026, 78.84623193740845, 79.8556900024414, 80.89207458496094, 81.8764226436615, 82.86503648757935, 83.83900189399719, 84.82877469062805, 85.78877401351929, 86.75743579864502, 87.78546571731567, 88.76306319236755, 89.74726700782776, 90.71639609336853, 91.69475650787354, 92.70421552658081, 93.67565107345581, 94.66927003860474, 95.6337583065033, 96.65700173377991, 97.62654757499695, 98.6268846988678, 99.63426566123962, 100.63478565216064, 101.60878610610962, 103.2030520439148]
[13.62, 17.5, 18.38, 15.34, 14.18, 15.68, 22.08, 23.82, 37.56, 39.78, 41.64, 43.9, 44.94, 45.56, 47.16, 48.28, 50.4, 50.68, 53.2, 54.04, 54.48, 54.82, 55.1, 56.06, 58.46, 61.0, 61.74, 62.26, 62.48, 64.72, 66.32, 67.94, 68.9, 69.84, 72.5, 73.82, 74.74, 76.42, 79.2, 80.34, 80.62, 82.1, 82.72, 83.76, 83.54, 83.36, 84.44, 84.28, 84.56, 84.62, 84.74, 84.88, 82.48, 85.76, 85.98, 86.2, 87.46, 85.42, 86.64, 88.18, 87.7, 86.98, 88.08, 87.56, 86.92, 88.22, 86.82, 88.66, 88.02, 87.72, 87.24, 88.34, 88.06, 88.14, 89.2, 89.28, 88.06, 88.92, 88.88, 88.4, 88.06, 88.96, 88.78, 87.26, 87.52, 88.74, 88.9, 87.46, 88.1, 88.78, 86.86, 84.76, 85.04, 87.82, 88.88, 89.58, 89.38, 88.64, 86.22, 85.16, 86.08]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fedpac_copsl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist,  filter_alg: loss_psl, level_n_system: 0.4 , level_n_lowerb:0.4  

   Client 6, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.322, Test loss: 2.302, Test accuracy: 15.42
Round   0, Global train loss: 2.322, Global test loss: 2.302, Global test accuracy: 14.96
Round   1, Train loss: 2.301, Test loss: 2.300, Test accuracy: 15.30
Round   1, Global train loss: 2.301, Global test loss: 2.300, Global test accuracy: 14.22
Round   2, Train loss: 2.299, Test loss: 2.297, Test accuracy: 14.72
Round   2, Global train loss: 2.299, Global test loss: 2.297, Global test accuracy: 14.26
Round   3, Train loss: 2.296, Test loss: 2.294, Test accuracy: 14.06
Round   3, Global train loss: 2.296, Global test loss: 2.294, Global test accuracy: 13.84
Round   4, Train loss: 2.291, Test loss: 2.287, Test accuracy: 13.02
Round   4, Global train loss: 2.291, Global test loss: 2.287, Global test accuracy: 12.12
Round   5, Train loss: 2.282, Test loss: 2.272, Test accuracy: 11.96
Round   5, Global train loss: 2.282, Global test loss: 2.272, Global test accuracy: 10.94
Round   6, Train loss: 2.265, Test loss: 2.251, Test accuracy: 13.50
Round   6, Global train loss: 2.265, Global test loss: 2.249, Global test accuracy: 12.78
Round   7, Train loss: 2.250, Test loss: 2.234, Test accuracy: 21.20
Round   7, Global train loss: 2.250, Global test loss: 2.233, Global test accuracy: 18.40
Round   8, Train loss: 2.236, Test loss: 2.215, Test accuracy: 28.74
Round   8, Global train loss: 2.236, Global test loss: 2.213, Global test accuracy: 28.38
Round   9, Train loss: 2.217, Test loss: 2.186, Test accuracy: 32.58
Round   9, Global train loss: 2.217, Global test loss: 2.181, Global test accuracy: 38.10
Round  10, Train loss: 2.186, Test loss: 2.152, Test accuracy: 38.28
Round  10, Global train loss: 2.186, Global test loss: 2.145, Global test accuracy: 40.28
Traceback (most recent call last):
  File "main_fedpac_copsl.py", line 280, in <module>
    w_local, loss, indd, class_center_local, class_num, noisy_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys,
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2559, in train
    self.filter_data(net, local_net, iter2-head_eps+1, local_eps-head_eps+1, concept_matrix_local)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2396, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist, level_n_system: 0.4 , level_n_lowerb:0.8  

   Client 2, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.300, Test loss: 2.299, Test accuracy: 29.06
Round   0, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 30.08
Round   1, Train loss: 2.297, Test loss: 2.296, Test accuracy: 30.42
Round   1, Global train loss: 2.297, Global test loss: 2.296, Global test accuracy: 32.18
Round   2, Train loss: 2.292, Test loss: 2.290, Test accuracy: 30.68
Round   2, Global train loss: 2.292, Global test loss: 2.285, Global test accuracy: 35.84
Round   3, Train loss: 2.289, Test loss: 2.289, Test accuracy: 26.10
Round   3, Global train loss: 2.289, Global test loss: 2.288, Global test accuracy: 29.26
Round   4, Train loss: 2.264, Test loss: 2.279, Test accuracy: 21.04
Round   4, Global train loss: 2.264, Global test loss: 2.268, Global test accuracy: 17.54
Round   5, Train loss: 2.265, Test loss: 2.267, Test accuracy: 22.46
Round   5, Global train loss: 2.265, Global test loss: 2.257, Global test accuracy: 28.56
Round   6, Train loss: 2.245, Test loss: 2.251, Test accuracy: 20.74
Round   6, Global train loss: 2.245, Global test loss: 2.248, Global test accuracy: 18.26
Round   7, Train loss: 2.232, Test loss: 2.237, Test accuracy: 22.58
Round   7, Global train loss: 2.232, Global test loss: 2.213, Global test accuracy: 31.64
Round   8, Train loss: 2.217, Test loss: 2.229, Test accuracy: 23.72
Round   8, Global train loss: 2.217, Global test loss: 2.255, Global test accuracy: 33.54
Round   9, Train loss: 2.139, Test loss: 2.194, Test accuracy: 26.86
Round   9, Global train loss: 2.139, Global test loss: 2.140, Global test accuracy: 39.64
Round  10, Train loss: 2.154, Test loss: 2.184, Test accuracy: 29.74
Round  10, Global train loss: 2.154, Global test loss: 2.106, Global test accuracy: 42.86
Round  11, Train loss: 2.179, Test loss: 2.170, Test accuracy: 32.20
Round  11, Global train loss: 2.179, Global test loss: 2.202, Global test accuracy: 28.08
Round  12, Train loss: 2.050, Test loss: 2.144, Test accuracy: 33.34
Round  12, Global train loss: 2.050, Global test loss: 2.075, Global test accuracy: 48.36
Round  13, Train loss: 2.111, Test loss: 2.124, Test accuracy: 35.26
Round  13, Global train loss: 2.111, Global test loss: 2.059, Global test accuracy: 40.50
Round  14, Train loss: 2.103, Test loss: 2.117, Test accuracy: 35.80
Round  14, Global train loss: 2.103, Global test loss: 2.182, Global test accuracy: 27.44
Round  15, Train loss: 2.044, Test loss: 2.105, Test accuracy: 37.24
Round  15, Global train loss: 2.044, Global test loss: 2.083, Global test accuracy: 40.68
Round  16, Train loss: 2.120, Test loss: 2.096, Test accuracy: 38.00
Round  16, Global train loss: 2.120, Global test loss: 2.190, Global test accuracy: 21.94
Round  17, Train loss: 1.996, Test loss: 2.082, Test accuracy: 39.94
Round  17, Global train loss: 1.996, Global test loss: 2.092, Global test accuracy: 35.94
Round  18, Train loss: 1.977, Test loss: 2.073, Test accuracy: 40.44
Round  18, Global train loss: 1.977, Global test loss: 2.028, Global test accuracy: 48.18
Round  19, Train loss: 1.967, Test loss: 2.069, Test accuracy: 40.66
Round  19, Global train loss: 1.967, Global test loss: 2.017, Global test accuracy: 48.48
Round  20, Train loss: 1.845, Test loss: 2.059, Test accuracy: 41.32
Round  20, Global train loss: 1.845, Global test loss: 1.922, Global test accuracy: 52.54
Round  21, Train loss: 2.102, Test loss: 2.055, Test accuracy: 42.04
Round  21, Global train loss: 2.102, Global test loss: 2.151, Global test accuracy: 37.80
Round  22, Train loss: 1.923, Test loss: 2.055, Test accuracy: 41.90
Round  22, Global train loss: 1.923, Global test loss: 1.938, Global test accuracy: 53.60
Round  23, Train loss: 1.990, Test loss: 2.055, Test accuracy: 41.64
Round  23, Global train loss: 1.990, Global test loss: 2.166, Global test accuracy: 25.50
Round  24, Train loss: 1.944, Test loss: 2.045, Test accuracy: 41.76
Round  24, Global train loss: 1.944, Global test loss: 1.959, Global test accuracy: 48.22
Round  25, Train loss: 1.898, Test loss: 2.027, Test accuracy: 43.10
Round  25, Global train loss: 1.898, Global test loss: 1.958, Global test accuracy: 47.48
Round  26, Train loss: 1.919, Test loss: 2.028, Test accuracy: 43.10
Round  26, Global train loss: 1.919, Global test loss: 2.000, Global test accuracy: 51.48
Round  27, Train loss: 2.022, Test loss: 2.025, Test accuracy: 43.68
Round  27, Global train loss: 2.022, Global test loss: 2.138, Global test accuracy: 29.48
Round  28, Train loss: 1.892, Test loss: 2.025, Test accuracy: 43.66
Round  28, Global train loss: 1.892, Global test loss: 1.986, Global test accuracy: 47.72
Round  29, Train loss: 1.894, Test loss: 2.014, Test accuracy: 44.92
Round  29, Global train loss: 1.894, Global test loss: 1.993, Global test accuracy: 46.72
Round  30, Train loss: 2.010, Test loss: 2.010, Test accuracy: 45.52
Round  30, Global train loss: 2.010, Global test loss: 2.179, Global test accuracy: 30.70
Round  31, Train loss: 1.856, Test loss: 2.008, Test accuracy: 45.80
Round  31, Global train loss: 1.856, Global test loss: 1.975, Global test accuracy: 48.90
Round  32, Train loss: 1.947, Test loss: 2.003, Test accuracy: 46.46
Round  32, Global train loss: 1.947, Global test loss: 2.180, Global test accuracy: 24.80
Round  33, Train loss: 1.755, Test loss: 2.000, Test accuracy: 46.66
Round  33, Global train loss: 1.755, Global test loss: 1.839, Global test accuracy: 63.00
Round  34, Train loss: 1.911, Test loss: 1.998, Test accuracy: 46.20
Round  34, Global train loss: 1.911, Global test loss: 2.004, Global test accuracy: 52.08
Round  35, Train loss: 1.894, Test loss: 1.994, Test accuracy: 46.62
Round  35, Global train loss: 1.894, Global test loss: 2.020, Global test accuracy: 49.30
Round  36, Train loss: 1.924, Test loss: 1.993, Test accuracy: 46.58
Round  36, Global train loss: 1.924, Global test loss: 2.183, Global test accuracy: 25.30
Round  37, Train loss: 1.870, Test loss: 1.992, Test accuracy: 46.96
Round  37, Global train loss: 1.870, Global test loss: 2.159, Global test accuracy: 28.44
Round  38, Train loss: 1.940, Test loss: 1.995, Test accuracy: 46.52
Round  38, Global train loss: 1.940, Global test loss: 2.153, Global test accuracy: 39.82
Round  39, Train loss: 1.878, Test loss: 1.995, Test accuracy: 46.36
Round  39, Global train loss: 1.878, Global test loss: 2.040, Global test accuracy: 40.72
Round  40, Train loss: 1.771, Test loss: 1.995, Test accuracy: 46.50
Round  40, Global train loss: 1.771, Global test loss: 1.833, Global test accuracy: 62.92
Round  41, Train loss: 1.780, Test loss: 1.991, Test accuracy: 46.96
Round  41, Global train loss: 1.780, Global test loss: 1.986, Global test accuracy: 46.82
Round  42, Train loss: 1.909, Test loss: 1.989, Test accuracy: 47.14
Round  42, Global train loss: 1.909, Global test loss: 2.186, Global test accuracy: 27.00
Round  43, Train loss: 1.881, Test loss: 1.989, Test accuracy: 47.18
Round  43, Global train loss: 1.881, Global test loss: 2.181, Global test accuracy: 24.02
Round  44, Train loss: 1.794, Test loss: 1.990, Test accuracy: 47.00
Round  44, Global train loss: 1.794, Global test loss: 2.013, Global test accuracy: 46.24
Round  45, Train loss: 1.843, Test loss: 1.993, Test accuracy: 46.68
Round  45, Global train loss: 1.843, Global test loss: 2.140, Global test accuracy: 31.06
Round  46, Train loss: 1.795, Test loss: 1.988, Test accuracy: 46.82
Round  46, Global train loss: 1.795, Global test loss: 1.997, Global test accuracy: 49.98
Round  47, Train loss: 1.739, Test loss: 1.989, Test accuracy: 46.84
Round  47, Global train loss: 1.739, Global test loss: 2.034, Global test accuracy: 41.62
Round  48, Train loss: 1.716, Test loss: 1.987, Test accuracy: 46.98
Round  48, Global train loss: 1.716, Global test loss: 1.834, Global test accuracy: 64.24
Round  49, Train loss: 1.733, Test loss: 1.986, Test accuracy: 47.20
Round  49, Global train loss: 1.733, Global test loss: 1.842, Global test accuracy: 61.74
Round  50, Train loss: 1.697, Test loss: 1.985, Test accuracy: 47.48
Round  50, Global train loss: 1.697, Global test loss: 2.012, Global test accuracy: 46.06
Round  51, Train loss: 1.776, Test loss: 1.987, Test accuracy: 47.20
Round  51, Global train loss: 1.776, Global test loss: 2.003, Global test accuracy: 45.04
Round  52, Train loss: 1.859, Test loss: 1.989, Test accuracy: 47.04
Round  52, Global train loss: 1.859, Global test loss: 2.155, Global test accuracy: 26.64
Round  53, Train loss: 1.727, Test loss: 1.989, Test accuracy: 47.06
Round  53, Global train loss: 1.727, Global test loss: 1.842, Global test accuracy: 63.04
Round  54, Train loss: 1.743, Test loss: 1.986, Test accuracy: 47.28
Round  54, Global train loss: 1.743, Global test loss: 2.033, Global test accuracy: 39.88
Round  55, Train loss: 1.786, Test loss: 1.987, Test accuracy: 47.08
Round  55, Global train loss: 1.786, Global test loss: 2.157, Global test accuracy: 28.68
Round  56, Train loss: 1.832, Test loss: 1.988, Test accuracy: 47.10
Round  56, Global train loss: 1.832, Global test loss: 2.122, Global test accuracy: 32.56
Round  57, Train loss: 1.772, Test loss: 1.986, Test accuracy: 47.22
Round  57, Global train loss: 1.772, Global test loss: 1.961, Global test accuracy: 51.36
Round  58, Train loss: 1.744, Test loss: 1.983, Test accuracy: 47.34
Round  58, Global train loss: 1.744, Global test loss: 1.995, Global test accuracy: 45.26
Round  59, Train loss: 1.695, Test loss: 1.984, Test accuracy: 47.44
Round  59, Global train loss: 1.695, Global test loss: 1.963, Global test accuracy: 55.74
Round  60, Train loss: 1.696, Test loss: 1.980, Test accuracy: 48.04
Round  60, Global train loss: 1.696, Global test loss: 1.789, Global test accuracy: 67.24
Round  61, Train loss: 1.790, Test loss: 1.980, Test accuracy: 47.94
Round  61, Global train loss: 1.790, Global test loss: 2.166, Global test accuracy: 27.48
Round  62, Train loss: 1.719, Test loss: 1.980, Test accuracy: 47.84
Round  62, Global train loss: 1.719, Global test loss: 1.925, Global test accuracy: 53.02
Round  63, Train loss: 1.719, Test loss: 1.978, Test accuracy: 47.94
Round  63, Global train loss: 1.719, Global test loss: 1.808, Global test accuracy: 64.96
Round  64, Train loss: 1.724, Test loss: 1.978, Test accuracy: 48.02
Round  64, Global train loss: 1.724, Global test loss: 2.040, Global test accuracy: 38.66
Round  65, Train loss: 1.775, Test loss: 1.978, Test accuracy: 48.12
Round  65, Global train loss: 1.775, Global test loss: 1.962, Global test accuracy: 49.26
Round  66, Train loss: 1.785, Test loss: 1.978, Test accuracy: 48.00
Round  66, Global train loss: 1.785, Global test loss: 2.085, Global test accuracy: 39.00
Round  67, Train loss: 1.684, Test loss: 1.978, Test accuracy: 48.02
Round  67, Global train loss: 1.684, Global test loss: 2.011, Global test accuracy: 47.26
Round  68, Train loss: 1.725, Test loss: 1.978, Test accuracy: 47.96
Round  68, Global train loss: 1.725, Global test loss: 2.002, Global test accuracy: 47.14
Round  69, Train loss: 1.726, Test loss: 1.977, Test accuracy: 48.10
Round  69, Global train loss: 1.726, Global test loss: 1.840, Global test accuracy: 61.60
Round  70, Train loss: 1.783, Test loss: 1.975, Test accuracy: 48.32
Round  70, Global train loss: 1.783, Global test loss: 2.256, Global test accuracy: 18.78
Round  71, Train loss: 1.724, Test loss: 1.976, Test accuracy: 48.22
Round  71, Global train loss: 1.724, Global test loss: 1.908, Global test accuracy: 55.60
Round  72, Train loss: 1.738, Test loss: 1.976, Test accuracy: 48.18
Round  72, Global train loss: 1.738, Global test loss: 1.926, Global test accuracy: 54.72
Round  73, Train loss: 1.746, Test loss: 1.976, Test accuracy: 48.26
Round  73, Global train loss: 1.746, Global test loss: 1.924, Global test accuracy: 54.34
Round  74, Train loss: 1.685, Test loss: 1.976, Test accuracy: 48.20
Round  74, Global train loss: 1.685, Global test loss: 1.808, Global test accuracy: 65.46
Round  75, Train loss: 1.722, Test loss: 1.976, Test accuracy: 48.26
Round  75, Global train loss: 1.722, Global test loss: 1.998, Global test accuracy: 47.44
Round  76, Train loss: 1.750, Test loss: 1.976, Test accuracy: 48.26
Round  76, Global train loss: 1.750, Global test loss: 1.914, Global test accuracy: 56.64
Round  77, Train loss: 1.698, Test loss: 1.976, Test accuracy: 48.34
Round  77, Global train loss: 1.698, Global test loss: 1.923, Global test accuracy: 54.32
Round  78, Train loss: 1.715, Test loss: 1.976, Test accuracy: 48.26
Round  78, Global train loss: 1.715, Global test loss: 2.035, Global test accuracy: 39.80
Round  79, Train loss: 1.757, Test loss: 1.976, Test accuracy: 48.22
Round  79, Global train loss: 1.757, Global test loss: 1.953, Global test accuracy: 51.18
Round  80, Train loss: 1.737, Test loss: 1.976, Test accuracy: 48.12
Round  80, Global train loss: 1.737, Global test loss: 2.057, Global test accuracy: 36.14
Round  81, Train loss: 1.791, Test loss: 1.976, Test accuracy: 48.06
Round  81, Global train loss: 1.791, Global test loss: 2.178, Global test accuracy: 28.28
Round  82, Train loss: 1.677, Test loss: 1.977, Test accuracy: 48.02
Round  82, Global train loss: 1.677, Global test loss: 1.919, Global test accuracy: 55.04
Round  83, Train loss: 1.714, Test loss: 1.974, Test accuracy: 48.44
Round  83, Global train loss: 1.714, Global test loss: 2.005, Global test accuracy: 47.00
Round  84, Train loss: 1.736, Test loss: 1.974, Test accuracy: 48.40
Round  84, Global train loss: 1.736, Global test loss: 2.102, Global test accuracy: 36.20
Round  85, Train loss: 1.665, Test loss: 1.973, Test accuracy: 48.40
Round  85, Global train loss: 1.665, Global test loss: 2.194, Global test accuracy: 24.08
Round  86, Train loss: 1.694, Test loss: 1.970, Test accuracy: 48.84
Round  86, Global train loss: 1.694, Global test loss: 2.145, Global test accuracy: 28.62
Round  87, Train loss: 1.630, Test loss: 1.970, Test accuracy: 48.96
Round  87, Global train loss: 1.630, Global test loss: 2.013, Global test accuracy: 44.00
Round  88, Train loss: 1.635, Test loss: 1.970, Test accuracy: 48.92
Round  88, Global train loss: 1.635, Global test loss: 1.989, Global test accuracy: 47.94
Round  89, Train loss: 1.654, Test loss: 1.969, Test accuracy: 48.98
Round  89, Global train loss: 1.654, Global test loss: 1.911, Global test accuracy: 55.16
Round  90, Train loss: 1.677, Test loss: 1.968, Test accuracy: 49.08
Round  90, Global train loss: 1.677, Global test loss: 1.813, Global test accuracy: 66.40
Round  91, Train loss: 1.717, Test loss: 1.969, Test accuracy: 49.04
Round  91, Global train loss: 1.717, Global test loss: 1.866, Global test accuracy: 59.90
Round  92, Train loss: 1.719, Test loss: 1.969, Test accuracy: 49.08
Round  92, Global train loss: 1.719, Global test loss: 1.837, Global test accuracy: 61.72
Round  93, Train loss: 1.617, Test loss: 1.969, Test accuracy: 48.94
Round  93, Global train loss: 1.617, Global test loss: 1.732, Global test accuracy: 73.02
Round  94, Train loss: 1.681, Test loss: 1.969, Test accuracy: 48.94
Round  94, Global train loss: 1.681, Global test loss: 1.838, Global test accuracy: 61.92/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  95, Train loss: 1.706, Test loss: 1.968, Test accuracy: 48.94
Round  95, Global train loss: 1.706, Global test loss: 2.142, Global test accuracy: 29.58
Round  96, Train loss: 1.638, Test loss: 1.969, Test accuracy: 48.88
Round  96, Global train loss: 1.638, Global test loss: 2.129, Global test accuracy: 30.70
Round  97, Train loss: 1.681, Test loss: 1.969, Test accuracy: 48.86
Round  97, Global train loss: 1.681, Global test loss: 1.837, Global test accuracy: 62.12
Round  98, Train loss: 1.704, Test loss: 1.969, Test accuracy: 48.90
Round  98, Global train loss: 1.704, Global test loss: 2.140, Global test accuracy: 29.74
Round  99, Train loss: 1.720, Test loss: 1.969, Test accuracy: 48.84
Round  99, Global train loss: 1.720, Global test loss: 2.062, Global test accuracy: 40.60
Final Round, Train loss: 1.688, Test loss: 1.969, Test accuracy: 48.76
Final Round, Global train loss: 1.688, Global test loss: 2.062, Global test accuracy: 40.60
Average accuracy final 10 rounds: 48.949999999999996 

Average global accuracy final 10 rounds: 51.57 

646.7283532619476
[1.0229442119598389, 2.0458884239196777, 2.8918886184692383, 3.737888813018799, 4.569276332855225, 5.40066385269165, 6.261353015899658, 7.122042179107666, 8.019530534744263, 8.91701889038086, 9.765885591506958, 10.614752292633057, 11.442761898040771, 12.270771503448486, 13.196707248687744, 14.122642993927002, 14.978511333465576, 15.83437967300415, 16.748542070388794, 17.662704467773438, 18.572808980941772, 19.482913494110107, 20.42417073249817, 21.36542797088623, 22.195241928100586, 23.02505588531494, 23.839476346969604, 24.653896808624268, 25.53102970123291, 26.408162593841553, 27.239057540893555, 28.069952487945557, 28.894249439239502, 29.718546390533447, 30.55047345161438, 31.382400512695312, 32.1685049533844, 32.954609394073486, 33.7588210105896, 34.56303262710571, 35.42679810523987, 36.29056358337402, 37.08381366729736, 37.8770637512207, 38.68339204788208, 39.48972034454346, 40.28303337097168, 41.0763463973999, 41.91457772254944, 42.752809047698975, 43.54946851730347, 44.34612798690796, 45.147353410720825, 45.94857883453369, 46.75036025047302, 47.55214166641235, 48.435596227645874, 49.319050788879395, 50.12466263771057, 50.93027448654175, 51.76592135429382, 52.6015682220459, 53.40002226829529, 54.19847631454468, 55.03092622756958, 55.86337614059448, 56.71988606452942, 57.576395988464355, 58.426222801208496, 59.27604961395264, 60.11840081214905, 60.96075201034546, 61.80929350852966, 62.65783500671387, 63.484742164611816, 64.31164932250977, 65.18314242362976, 66.05463552474976, 66.87102150917053, 67.68740749359131, 68.59688115119934, 69.50635480880737, 70.32835245132446, 71.15035009384155, 71.97086334228516, 72.79137659072876, 73.62478637695312, 74.45819616317749, 75.27848434448242, 76.09877252578735, 76.91435480117798, 77.7299370765686, 78.57379031181335, 79.4176435470581, 80.2565050125122, 81.09536647796631, 81.92823362350464, 82.76110076904297, 83.60746240615845, 84.45382404327393, 85.35596632957458, 86.25810861587524, 87.10193586349487, 87.9457631111145, 88.84832215309143, 89.75088119506836, 90.5834801197052, 91.41607904434204, 92.23625898361206, 93.05643892288208, 93.8864815235138, 94.71652412414551, 95.57902431488037, 96.44152450561523, 97.35884928703308, 98.27617406845093, 99.2503821849823, 100.22459030151367, 101.09936189651489, 101.97413349151611, 103.23667478561401, 104.49921607971191, 105.29552268981934, 106.09182929992676, 106.94734072685242, 107.80285215377808, 108.67840003967285, 109.55394792556763, 110.36077952384949, 111.16761112213135, 112.00167536735535, 112.83573961257935, 113.64097261428833, 114.44620561599731, 115.276939868927, 116.10767412185669, 116.94050240516663, 117.77333068847656, 118.74538350105286, 119.71743631362915, 120.56100869178772, 121.40458106994629, 122.25158095359802, 123.09858083724976, 123.94701790809631, 124.79545497894287, 125.62155723571777, 126.44765949249268, 127.30367851257324, 128.1596975326538, 129.0154230594635, 129.8711485862732, 130.73611903190613, 131.60108947753906, 132.57553625106812, 133.54998302459717, 134.41934943199158, 135.288715839386, 136.17283749580383, 137.05695915222168, 137.91422486305237, 138.77149057388306, 139.5947232246399, 140.41795587539673, 141.24825191497803, 142.07854795455933, 142.89473462104797, 143.71092128753662, 144.587890625, 145.46485996246338, 146.32170939445496, 147.17855882644653, 148.05204558372498, 148.92553234100342, 149.7906939983368, 150.65585565567017, 151.47009301185608, 152.284330368042, 153.11681294441223, 153.94929552078247, 154.78252387046814, 155.6157522201538, 156.46174955368042, 157.30774688720703, 158.1303493976593, 158.95295190811157, 159.795827627182, 160.63870334625244, 161.48594212532043, 162.33318090438843, 163.13640213012695, 163.93962335586548, 164.82857728004456, 165.71753120422363, 166.60206151008606, 167.4865918159485, 168.35962295532227, 169.23265409469604, 170.08521270751953, 170.93777132034302, 172.68190240859985, 174.4260334968567]
[29.06, 29.06, 30.42, 30.42, 30.68, 30.68, 26.1, 26.1, 21.04, 21.04, 22.46, 22.46, 20.74, 20.74, 22.58, 22.58, 23.72, 23.72, 26.86, 26.86, 29.74, 29.74, 32.2, 32.2, 33.34, 33.34, 35.26, 35.26, 35.8, 35.8, 37.24, 37.24, 38.0, 38.0, 39.94, 39.94, 40.44, 40.44, 40.66, 40.66, 41.32, 41.32, 42.04, 42.04, 41.9, 41.9, 41.64, 41.64, 41.76, 41.76, 43.1, 43.1, 43.1, 43.1, 43.68, 43.68, 43.66, 43.66, 44.92, 44.92, 45.52, 45.52, 45.8, 45.8, 46.46, 46.46, 46.66, 46.66, 46.2, 46.2, 46.62, 46.62, 46.58, 46.58, 46.96, 46.96, 46.52, 46.52, 46.36, 46.36, 46.5, 46.5, 46.96, 46.96, 47.14, 47.14, 47.18, 47.18, 47.0, 47.0, 46.68, 46.68, 46.82, 46.82, 46.84, 46.84, 46.98, 46.98, 47.2, 47.2, 47.48, 47.48, 47.2, 47.2, 47.04, 47.04, 47.06, 47.06, 47.28, 47.28, 47.08, 47.08, 47.1, 47.1, 47.22, 47.22, 47.34, 47.34, 47.44, 47.44, 48.04, 48.04, 47.94, 47.94, 47.84, 47.84, 47.94, 47.94, 48.02, 48.02, 48.12, 48.12, 48.0, 48.0, 48.02, 48.02, 47.96, 47.96, 48.1, 48.1, 48.32, 48.32, 48.22, 48.22, 48.18, 48.18, 48.26, 48.26, 48.2, 48.2, 48.26, 48.26, 48.26, 48.26, 48.34, 48.34, 48.26, 48.26, 48.22, 48.22, 48.12, 48.12, 48.06, 48.06, 48.02, 48.02, 48.44, 48.44, 48.4, 48.4, 48.4, 48.4, 48.84, 48.84, 48.96, 48.96, 48.92, 48.92, 48.98, 48.98, 49.08, 49.08, 49.04, 49.04, 49.08, 49.08, 48.94, 48.94, 48.94, 48.94, 48.94, 48.94, 48.88, 48.88, 48.86, 48.86, 48.9, 48.9, 48.84, 48.84, 48.76, 48.76]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.4 , level_n_lowerb:0.8  

   Client 0, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.303, Test loss: 2.302, Test accuracy: 9.32
Round   0, Global train loss: 2.303, Global test loss: 2.302, Global test accuracy: 8.56
Round   1, Train loss: 2.294, Test loss: 2.300, Test accuracy: 13.72
Round   1, Global train loss: 2.294, Global test loss: 2.299, Global test accuracy: 13.04
Round   2, Train loss: 2.292, Test loss: 2.296, Test accuracy: 15.16
Round   2, Global train loss: 2.292, Global test loss: 2.292, Global test accuracy: 18.22
Round   3, Train loss: 2.267, Test loss: 2.289, Test accuracy: 13.38
Round   3, Global train loss: 2.267, Global test loss: 2.286, Global test accuracy: 11.14
Round   4, Train loss: 2.252, Test loss: 2.285, Test accuracy: 13.42
Round   4, Global train loss: 2.252, Global test loss: 2.285, Global test accuracy: 11.14
Round   5, Train loss: 2.236, Test loss: 2.228, Test accuracy: 22.60
Round   5, Global train loss: 2.236, Global test loss: 2.164, Global test accuracy: 32.58
Round   6, Train loss: 2.201, Test loss: 2.203, Test accuracy: 23.98
Round   6, Global train loss: 2.201, Global test loss: 2.162, Global test accuracy: 29.90
Round   7, Train loss: 2.164, Test loss: 2.180, Test accuracy: 26.80
Round   7, Global train loss: 2.164, Global test loss: 2.095, Global test accuracy: 40.08
Round   8, Train loss: 2.145, Test loss: 2.137, Test accuracy: 31.68
Round   8, Global train loss: 2.145, Global test loss: 2.069, Global test accuracy: 39.94
Round   9, Train loss: 2.125, Test loss: 2.114, Test accuracy: 34.38
Round   9, Global train loss: 2.125, Global test loss: 2.034, Global test accuracy: 42.38
Round  10, Train loss: 2.163, Test loss: 2.096, Test accuracy: 36.46
Round  10, Global train loss: 2.163, Global test loss: 2.033, Global test accuracy: 41.68
Round  11, Train loss: 2.113, Test loss: 2.050, Test accuracy: 41.86
Round  11, Global train loss: 2.113, Global test loss: 2.000, Global test accuracy: 44.44
Round  12, Train loss: 2.065, Test loss: 2.027, Test accuracy: 44.64
Round  12, Global train loss: 2.065, Global test loss: 1.981, Global test accuracy: 47.94
Round  13, Train loss: 2.130, Test loss: 2.017, Test accuracy: 45.56
Round  13, Global train loss: 2.130, Global test loss: 1.988, Global test accuracy: 47.06
Round  14, Train loss: 2.134, Test loss: 2.003, Test accuracy: 46.70
Round  14, Global train loss: 2.134, Global test loss: 1.966, Global test accuracy: 50.04
Round  15, Train loss: 2.105, Test loss: 1.998, Test accuracy: 46.96
Round  15, Global train loss: 2.105, Global test loss: 1.975, Global test accuracy: 49.80
Round  16, Train loss: 2.008, Test loss: 1.991, Test accuracy: 47.72
Round  16, Global train loss: 2.008, Global test loss: 1.912, Global test accuracy: 55.78
Round  17, Train loss: 2.031, Test loss: 1.990, Test accuracy: 47.42
Round  17, Global train loss: 2.031, Global test loss: 1.932, Global test accuracy: 53.66
Round  18, Train loss: 2.069, Test loss: 1.973, Test accuracy: 49.10
Round  18, Global train loss: 2.069, Global test loss: 1.906, Global test accuracy: 56.80
Round  19, Train loss: 2.046, Test loss: 1.967, Test accuracy: 49.60
Round  19, Global train loss: 2.046, Global test loss: 1.933, Global test accuracy: 52.24
Round  20, Train loss: 1.961, Test loss: 1.957, Test accuracy: 50.88
Round  20, Global train loss: 1.961, Global test loss: 1.879, Global test accuracy: 59.88
Round  21, Train loss: 1.949, Test loss: 1.930, Test accuracy: 53.60
Round  21, Global train loss: 1.949, Global test loss: 1.859, Global test accuracy: 61.70
Round  22, Train loss: 1.957, Test loss: 1.919, Test accuracy: 54.78
Round  22, Global train loss: 1.957, Global test loss: 1.841, Global test accuracy: 63.70
Round  23, Train loss: 1.976, Test loss: 1.906, Test accuracy: 56.10
Round  23, Global train loss: 1.976, Global test loss: 1.859, Global test accuracy: 61.20
Round  24, Train loss: 1.927, Test loss: 1.910, Test accuracy: 55.38
Round  24, Global train loss: 1.927, Global test loss: 1.860, Global test accuracy: 61.20
Round  25, Train loss: 1.923, Test loss: 1.903, Test accuracy: 55.94
Round  25, Global train loss: 1.923, Global test loss: 1.846, Global test accuracy: 62.38
Round  26, Train loss: 2.014, Test loss: 1.894, Test accuracy: 57.00
Round  26, Global train loss: 2.014, Global test loss: 1.863, Global test accuracy: 60.44
Round  27, Train loss: 1.939, Test loss: 1.890, Test accuracy: 57.40
Round  27, Global train loss: 1.939, Global test loss: 1.841, Global test accuracy: 63.00
Round  28, Train loss: 2.005, Test loss: 1.893, Test accuracy: 57.04
Round  28, Global train loss: 2.005, Global test loss: 1.939, Global test accuracy: 52.88
Round  29, Train loss: 1.861, Test loss: 1.894, Test accuracy: 56.90
Round  29, Global train loss: 1.861, Global test loss: 1.831, Global test accuracy: 63.40
Round  30, Train loss: 2.019, Test loss: 1.896, Test accuracy: 56.54
Round  30, Global train loss: 2.019, Global test loss: 1.854, Global test accuracy: 61.36
Round  31, Train loss: 1.909, Test loss: 1.901, Test accuracy: 55.98
Round  31, Global train loss: 1.909, Global test loss: 1.879, Global test accuracy: 58.06
Round  32, Train loss: 1.947, Test loss: 1.900, Test accuracy: 56.06
Round  32, Global train loss: 1.947, Global test loss: 1.845, Global test accuracy: 62.14
Round  33, Train loss: 1.883, Test loss: 1.898, Test accuracy: 56.14
Round  33, Global train loss: 1.883, Global test loss: 1.852, Global test accuracy: 61.18
Round  34, Train loss: 1.827, Test loss: 1.900, Test accuracy: 55.92
Round  34, Global train loss: 1.827, Global test loss: 1.821, Global test accuracy: 64.06
Round  35, Train loss: 2.046, Test loss: 1.903, Test accuracy: 55.70
Round  35, Global train loss: 2.046, Global test loss: 1.895, Global test accuracy: 56.82
Round  36, Train loss: 1.925, Test loss: 1.903, Test accuracy: 55.66
Round  36, Global train loss: 1.925, Global test loss: 1.849, Global test accuracy: 62.40
Round  37, Train loss: 1.920, Test loss: 1.900, Test accuracy: 56.12
Round  37, Global train loss: 1.920, Global test loss: 1.847, Global test accuracy: 62.08
Round  38, Train loss: 1.901, Test loss: 1.901, Test accuracy: 56.00
Round  38, Global train loss: 1.901, Global test loss: 1.833, Global test accuracy: 63.48
Round  39, Train loss: 1.884, Test loss: 1.899, Test accuracy: 56.26
Round  39, Global train loss: 1.884, Global test loss: 1.854, Global test accuracy: 60.64
Round  40, Train loss: 1.928, Test loss: 1.899, Test accuracy: 56.38
Round  40, Global train loss: 1.928, Global test loss: 1.902, Global test accuracy: 56.06
Round  41, Train loss: 1.831, Test loss: 1.900, Test accuracy: 56.28
Round  41, Global train loss: 1.831, Global test loss: 1.836, Global test accuracy: 62.96
Round  42, Train loss: 1.950, Test loss: 1.901, Test accuracy: 56.10
Round  42, Global train loss: 1.950, Global test loss: 1.865, Global test accuracy: 59.92
Round  43, Train loss: 1.836, Test loss: 1.901, Test accuracy: 56.14
Round  43, Global train loss: 1.836, Global test loss: 1.826, Global test accuracy: 64.04
Round  44, Train loss: 1.888, Test loss: 1.899, Test accuracy: 56.34
Round  44, Global train loss: 1.888, Global test loss: 1.852, Global test accuracy: 61.48
Round  45, Train loss: 1.906, Test loss: 1.896, Test accuracy: 56.66
Round  45, Global train loss: 1.906, Global test loss: 1.840, Global test accuracy: 62.46
Round  46, Train loss: 1.862, Test loss: 1.897, Test accuracy: 56.52
Round  46, Global train loss: 1.862, Global test loss: 1.839, Global test accuracy: 62.02
Round  47, Train loss: 1.803, Test loss: 1.896, Test accuracy: 56.58
Round  47, Global train loss: 1.803, Global test loss: 1.822, Global test accuracy: 64.28
Round  48, Train loss: 1.853, Test loss: 1.894, Test accuracy: 56.76
Round  48, Global train loss: 1.853, Global test loss: 1.853, Global test accuracy: 60.98
Round  49, Train loss: 1.847, Test loss: 1.895, Test accuracy: 56.70
Round  49, Global train loss: 1.847, Global test loss: 1.857, Global test accuracy: 60.84
Round  50, Train loss: 1.876, Test loss: 1.899, Test accuracy: 56.30
Round  50, Global train loss: 1.876, Global test loss: 1.841, Global test accuracy: 62.36
Round  51, Train loss: 1.870, Test loss: 1.901, Test accuracy: 56.12
Round  51, Global train loss: 1.870, Global test loss: 1.864, Global test accuracy: 60.06
Round  52, Train loss: 1.880, Test loss: 1.901, Test accuracy: 55.92
Round  52, Global train loss: 1.880, Global test loss: 1.873, Global test accuracy: 58.64
Round  53, Train loss: 1.838, Test loss: 1.901, Test accuracy: 55.94
Round  53, Global train loss: 1.838, Global test loss: 1.866, Global test accuracy: 59.82
Round  54, Train loss: 1.845, Test loss: 1.900, Test accuracy: 56.16
Round  54, Global train loss: 1.845, Global test loss: 1.837, Global test accuracy: 62.34
Round  55, Train loss: 1.930, Test loss: 1.897, Test accuracy: 56.50
Round  55, Global train loss: 1.930, Global test loss: 1.861, Global test accuracy: 60.14
Round  56, Train loss: 1.851, Test loss: 1.893, Test accuracy: 56.88
Round  56, Global train loss: 1.851, Global test loss: 1.830, Global test accuracy: 64.52
Round  57, Train loss: 1.823, Test loss: 1.890, Test accuracy: 57.20
Round  57, Global train loss: 1.823, Global test loss: 1.844, Global test accuracy: 62.84
Round  58, Train loss: 1.838, Test loss: 1.889, Test accuracy: 57.44
Round  58, Global train loss: 1.838, Global test loss: 1.833, Global test accuracy: 63.70
Round  59, Train loss: 1.841, Test loss: 1.881, Test accuracy: 58.28
Round  59, Global train loss: 1.841, Global test loss: 1.799, Global test accuracy: 66.68
Round  60, Train loss: 1.844, Test loss: 1.876, Test accuracy: 58.62
Round  60, Global train loss: 1.844, Global test loss: 1.868, Global test accuracy: 60.94
Round  61, Train loss: 1.821, Test loss: 1.872, Test accuracy: 59.08
Round  61, Global train loss: 1.821, Global test loss: 1.801, Global test accuracy: 66.98
Round  62, Train loss: 1.755, Test loss: 1.871, Test accuracy: 59.34
Round  62, Global train loss: 1.755, Global test loss: 1.783, Global test accuracy: 68.32
Round  63, Train loss: 1.837, Test loss: 1.868, Test accuracy: 59.28
Round  63, Global train loss: 1.837, Global test loss: 1.868, Global test accuracy: 60.00
Round  64, Train loss: 1.780, Test loss: 1.871, Test accuracy: 59.14
Round  64, Global train loss: 1.780, Global test loss: 1.809, Global test accuracy: 66.64
Round  65, Train loss: 1.747, Test loss: 1.871, Test accuracy: 59.06
Round  65, Global train loss: 1.747, Global test loss: 1.780, Global test accuracy: 69.42
Round  66, Train loss: 1.885, Test loss: 1.872, Test accuracy: 58.96
Round  66, Global train loss: 1.885, Global test loss: 1.845, Global test accuracy: 62.78
Round  67, Train loss: 1.863, Test loss: 1.884, Test accuracy: 57.64
Round  67, Global train loss: 1.863, Global test loss: 1.867, Global test accuracy: 60.12
Round  68, Train loss: 1.778, Test loss: 1.881, Test accuracy: 58.10
Round  68, Global train loss: 1.778, Global test loss: 1.801, Global test accuracy: 67.02
Round  69, Train loss: 1.790, Test loss: 1.877, Test accuracy: 58.56
Round  69, Global train loss: 1.790, Global test loss: 1.899, Global test accuracy: 56.76
Round  70, Train loss: 1.864, Test loss: 1.874, Test accuracy: 59.04
Round  70, Global train loss: 1.864, Global test loss: 1.811, Global test accuracy: 65.74
Round  71, Train loss: 1.739, Test loss: 1.874, Test accuracy: 58.82
Round  71, Global train loss: 1.739, Global test loss: 1.778, Global test accuracy: 68.96
Round  72, Train loss: 1.763, Test loss: 1.871, Test accuracy: 59.14
Round  72, Global train loss: 1.763, Global test loss: 1.836, Global test accuracy: 63.26
Round  73, Train loss: 1.774, Test loss: 1.872, Test accuracy: 58.96
Round  73, Global train loss: 1.774, Global test loss: 1.828, Global test accuracy: 64.44
Round  74, Train loss: 1.779, Test loss: 1.863, Test accuracy: 60.02
Round  74, Global train loss: 1.779, Global test loss: 1.868, Global test accuracy: 60.38
Round  75, Train loss: 1.763, Test loss: 1.864, Test accuracy: 60.10
Round  75, Global train loss: 1.763, Global test loss: 1.793, Global test accuracy: 67.60
Round  76, Train loss: 1.786, Test loss: 1.868, Test accuracy: 59.50
Round  76, Global train loss: 1.786, Global test loss: 1.907, Global test accuracy: 55.56
Round  77, Train loss: 1.746, Test loss: 1.866, Test accuracy: 59.88
Round  77, Global train loss: 1.746, Global test loss: 1.826, Global test accuracy: 64.10
Round  78, Train loss: 1.739, Test loss: 1.869, Test accuracy: 59.54
Round  78, Global train loss: 1.739, Global test loss: 1.802, Global test accuracy: 66.70
Round  79, Train loss: 1.744, Test loss: 1.866, Test accuracy: 59.74
Round  79, Global train loss: 1.744, Global test loss: 1.834, Global test accuracy: 63.08
Round  80, Train loss: 1.760, Test loss: 1.867, Test accuracy: 59.40
Round  80, Global train loss: 1.760, Global test loss: 1.805, Global test accuracy: 66.88
Round  81, Train loss: 1.744, Test loss: 1.866, Test accuracy: 59.52
Round  81, Global train loss: 1.744, Global test loss: 1.770, Global test accuracy: 69.82
Round  82, Train loss: 1.771, Test loss: 1.868, Test accuracy: 59.44
Round  82, Global train loss: 1.771, Global test loss: 1.815, Global test accuracy: 64.94
Round  83, Train loss: 1.754, Test loss: 1.862, Test accuracy: 59.98
Round  83, Global train loss: 1.754, Global test loss: 1.793, Global test accuracy: 67.50
Round  84, Train loss: 1.781, Test loss: 1.860, Test accuracy: 60.14
Round  84, Global train loss: 1.781, Global test loss: 1.828, Global test accuracy: 64.12
Round  85, Train loss: 1.826, Test loss: 1.862, Test accuracy: 59.94
Round  85, Global train loss: 1.826, Global test loss: 1.793, Global test accuracy: 67.44
Round  86, Train loss: 1.857, Test loss: 1.860, Test accuracy: 60.24
Round  86, Global train loss: 1.857, Global test loss: 1.827, Global test accuracy: 63.94
Round  87, Train loss: 1.823, Test loss: 1.863, Test accuracy: 60.00
Round  87, Global train loss: 1.823, Global test loss: 1.836, Global test accuracy: 63.18
Round  88, Train loss: 1.856, Test loss: 1.861, Test accuracy: 60.06
Round  88, Global train loss: 1.856, Global test loss: 1.889, Global test accuracy: 58.14
Round  89, Train loss: 1.760, Test loss: 1.865, Test accuracy: 59.90
Round  89, Global train loss: 1.760, Global test loss: 1.825, Global test accuracy: 65.16
Round  90, Train loss: 1.741, Test loss: 1.866, Test accuracy: 59.74
Round  90, Global train loss: 1.741, Global test loss: 1.813, Global test accuracy: 66.00
Round  91, Train loss: 1.720, Test loss: 1.866, Test accuracy: 59.58
Round  91, Global train loss: 1.720, Global test loss: 1.830, Global test accuracy: 63.38
Round  92, Train loss: 1.740, Test loss: 1.870, Test accuracy: 59.38
Round  92, Global train loss: 1.740, Global test loss: 1.894, Global test accuracy: 57.50
Round  93, Train loss: 1.751, Test loss: 1.868, Test accuracy: 59.56
Round  93, Global train loss: 1.751, Global test loss: 1.872, Global test accuracy: 59.26
Round  94, Train loss: 1.739, Test loss: 1.867, Test accuracy: 59.86
Round  94, Global train loss: 1.739, Global test loss: 1.892, Global test accuracy: 56.14/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  95, Train loss: 1.696, Test loss: 1.855, Test accuracy: 60.96
Round  95, Global train loss: 1.696, Global test loss: 1.732, Global test accuracy: 74.10
Round  96, Train loss: 1.764, Test loss: 1.861, Test accuracy: 60.50
Round  96, Global train loss: 1.764, Global test loss: 1.791, Global test accuracy: 67.94
Round  97, Train loss: 1.742, Test loss: 1.855, Test accuracy: 61.16
Round  97, Global train loss: 1.742, Global test loss: 1.855, Global test accuracy: 60.58
Round  98, Train loss: 1.659, Test loss: 1.850, Test accuracy: 61.68
Round  98, Global train loss: 1.659, Global test loss: 1.722, Global test accuracy: 74.36
Round  99, Train loss: 1.727, Test loss: 1.841, Test accuracy: 62.68
Round  99, Global train loss: 1.727, Global test loss: 1.769, Global test accuracy: 70.18
Final Round, Train loss: 1.696, Test loss: 1.837, Test accuracy: 62.46
Final Round, Global train loss: 1.696, Global test loss: 1.769, Global test accuracy: 70.18
Average accuracy final 10 rounds: 60.51 

Average global accuracy final 10 rounds: 64.94399999999999 

644.5057697296143
[1.0563628673553467, 2.1127257347106934, 2.985844850540161, 3.858963966369629, 4.736709833145142, 5.614455699920654, 6.411506652832031, 7.208557605743408, 8.108433485031128, 9.008309364318848, 9.826680183410645, 10.645051002502441, 11.449311017990112, 12.253571033477783, 13.113836765289307, 13.97410249710083, 14.799941301345825, 15.62578010559082, 16.461024045944214, 17.296267986297607, 18.14024043083191, 18.98421287536621, 19.812757968902588, 20.641303062438965, 21.47802710533142, 22.314751148223877, 23.117757320404053, 23.92076349258423, 24.77034044265747, 25.619917392730713, 26.4478816986084, 27.275846004486084, 28.088679552078247, 28.90151309967041, 29.715409755706787, 30.529306411743164, 31.354622840881348, 32.17993927001953, 33.03602838516235, 33.892117500305176, 34.72854471206665, 35.564971923828125, 36.367757081985474, 37.17054224014282, 37.98296403884888, 38.79538583755493, 39.59981322288513, 40.40424060821533, 41.25515174865723, 42.10606288909912, 43.002033948898315, 43.89800500869751, 44.776302337646484, 45.65459966659546, 46.660871267318726, 47.66714286804199, 48.46432161331177, 49.26150035858154, 50.2131781578064, 51.16485595703125, 51.98907947540283, 52.813302993774414, 53.63227295875549, 54.45124292373657, 55.2582471370697, 56.06525135040283, 56.89146423339844, 57.71767711639404, 58.56032419204712, 59.402971267700195, 60.22840166091919, 61.053832054138184, 61.86672377586365, 62.67961549758911, 63.458510637283325, 64.23740577697754, 65.04388356208801, 65.85036134719849, 66.71973824501038, 67.58911514282227, 68.46714496612549, 69.34517478942871, 70.22365069389343, 71.10212659835815, 71.94862246513367, 72.79511833190918, 73.65471768379211, 74.51431703567505, 75.36797952651978, 76.2216420173645, 77.07859897613525, 77.935555934906, 78.76847624778748, 79.60139656066895, 80.43407535552979, 81.26675415039062, 82.17175650596619, 83.07675886154175, 83.94315648078918, 84.80955410003662, 85.69915819168091, 86.5887622833252, 87.43616271018982, 88.28356313705444, 89.13246488571167, 89.9813666343689, 90.79705452919006, 91.61274242401123, 92.42300033569336, 93.23325824737549, 94.06442189216614, 94.89558553695679, 95.751131772995, 96.6066780090332, 97.43607902526855, 98.2654800415039, 99.04623603820801, 99.82699203491211, 100.64316439628601, 101.45933675765991, 102.31286120414734, 103.16638565063477, 104.01032853126526, 104.85427141189575, 105.71258163452148, 106.57089185714722, 107.39343333244324, 108.21597480773926, 109.0821213722229, 109.94826793670654, 110.80373787879944, 111.65920782089233, 112.5083999633789, 113.35759210586548, 114.21114873886108, 115.06470537185669, 115.91749024391174, 116.7702751159668, 117.66215324401855, 118.55403137207031, 119.3976194858551, 120.24120759963989, 121.07228827476501, 121.90336894989014, 122.74708890914917, 123.5908088684082, 124.44729471206665, 125.3037805557251, 126.13913536071777, 126.97449016571045, 127.91136050224304, 128.84823083877563, 129.67027139663696, 130.4923119544983, 131.3514175415039, 132.21052312850952, 133.06193232536316, 133.9133415222168, 134.7057662010193, 135.49819087982178, 136.32491970062256, 137.15164852142334, 137.98493552207947, 138.8182225227356, 139.60691595077515, 140.3956093788147, 141.19356274604797, 141.99151611328125, 142.80975651741028, 143.6279969215393, 144.46992588043213, 145.31185483932495, 146.17850160598755, 147.04514837265015, 147.89529418945312, 148.7454400062561, 149.56945776939392, 150.39347553253174, 151.3524148464203, 152.31135416030884, 153.12347102165222, 153.9355878829956, 154.76977157592773, 155.60395526885986, 156.47248554229736, 157.34101581573486, 158.15830659866333, 158.9755973815918, 159.79989910125732, 160.62420082092285, 161.46185731887817, 162.2995138168335, 163.14743971824646, 163.99536561965942, 164.80354261398315, 165.61171960830688, 166.443119764328, 167.27451992034912, 168.10028219223022, 168.92604446411133, 170.74330401420593, 172.56056356430054]
[9.32, 9.32, 13.72, 13.72, 15.16, 15.16, 13.38, 13.38, 13.42, 13.42, 22.6, 22.6, 23.98, 23.98, 26.8, 26.8, 31.68, 31.68, 34.38, 34.38, 36.46, 36.46, 41.86, 41.86, 44.64, 44.64, 45.56, 45.56, 46.7, 46.7, 46.96, 46.96, 47.72, 47.72, 47.42, 47.42, 49.1, 49.1, 49.6, 49.6, 50.88, 50.88, 53.6, 53.6, 54.78, 54.78, 56.1, 56.1, 55.38, 55.38, 55.94, 55.94, 57.0, 57.0, 57.4, 57.4, 57.04, 57.04, 56.9, 56.9, 56.54, 56.54, 55.98, 55.98, 56.06, 56.06, 56.14, 56.14, 55.92, 55.92, 55.7, 55.7, 55.66, 55.66, 56.12, 56.12, 56.0, 56.0, 56.26, 56.26, 56.38, 56.38, 56.28, 56.28, 56.1, 56.1, 56.14, 56.14, 56.34, 56.34, 56.66, 56.66, 56.52, 56.52, 56.58, 56.58, 56.76, 56.76, 56.7, 56.7, 56.3, 56.3, 56.12, 56.12, 55.92, 55.92, 55.94, 55.94, 56.16, 56.16, 56.5, 56.5, 56.88, 56.88, 57.2, 57.2, 57.44, 57.44, 58.28, 58.28, 58.62, 58.62, 59.08, 59.08, 59.34, 59.34, 59.28, 59.28, 59.14, 59.14, 59.06, 59.06, 58.96, 58.96, 57.64, 57.64, 58.1, 58.1, 58.56, 58.56, 59.04, 59.04, 58.82, 58.82, 59.14, 59.14, 58.96, 58.96, 60.02, 60.02, 60.1, 60.1, 59.5, 59.5, 59.88, 59.88, 59.54, 59.54, 59.74, 59.74, 59.4, 59.4, 59.52, 59.52, 59.44, 59.44, 59.98, 59.98, 60.14, 60.14, 59.94, 59.94, 60.24, 60.24, 60.0, 60.0, 60.06, 60.06, 59.9, 59.9, 59.74, 59.74, 59.58, 59.58, 59.38, 59.38, 59.56, 59.56, 59.86, 59.86, 60.96, 60.96, 60.5, 60.5, 61.16, 61.16, 61.68, 61.68, 62.68, 62.68, 62.46, 62.46]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.4 , level_n_lowerb:0.8  

   Client 4, noise    level: 0.8000 
   Client 8, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 6, noise    level: 0.8000 
prox
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.301, Test loss: 2.302, Test accuracy: 10.94
Round   0, Global train loss: 2.301, Global test loss: 2.302, Global test accuracy: 10.72
Round   1, Train loss: 2.298, Test loss: 2.302, Test accuracy: 12.42
Round   1, Global train loss: 2.298, Global test loss: 2.301, Global test accuracy: 12.54
Round   2, Train loss: 2.296, Test loss: 2.301, Test accuracy: 17.04
Round   2, Global train loss: 2.296, Global test loss: 2.299, Global test accuracy: 19.90
Round   3, Train loss: 2.286, Test loss: 2.296, Test accuracy: 14.94
Round   3, Global train loss: 2.286, Global test loss: 2.291, Global test accuracy: 10.12
Round   4, Train loss: 2.254, Test loss: 2.288, Test accuracy: 16.10
Round   4, Global train loss: 2.254, Global test loss: 2.276, Global test accuracy: 10.12
Round   5, Train loss: 2.263, Test loss: 2.269, Test accuracy: 19.40
Round   5, Global train loss: 2.263, Global test loss: 2.249, Global test accuracy: 23.80
Round   6, Train loss: 2.244, Test loss: 2.252, Test accuracy: 22.32
Round   6, Global train loss: 2.244, Global test loss: 2.235, Global test accuracy: 28.82
Round   7, Train loss: 2.228, Test loss: 2.230, Test accuracy: 23.00
Round   7, Global train loss: 2.228, Global test loss: 2.197, Global test accuracy: 30.24
Round   8, Train loss: 2.204, Test loss: 2.196, Test accuracy: 26.88
Round   8, Global train loss: 2.204, Global test loss: 2.140, Global test accuracy: 31.02
Round   9, Train loss: 2.196, Test loss: 2.158, Test accuracy: 32.90
Round   9, Global train loss: 2.196, Global test loss: 2.077, Global test accuracy: 49.88
Round  10, Train loss: 2.163, Test loss: 2.135, Test accuracy: 34.96
Round  10, Global train loss: 2.163, Global test loss: 2.033, Global test accuracy: 49.34
Round  11, Train loss: 2.145, Test loss: 2.083, Test accuracy: 41.48
Round  11, Global train loss: 2.145, Global test loss: 2.022, Global test accuracy: 51.30
Round  12, Train loss: 2.102, Test loss: 2.054, Test accuracy: 43.98
Round  12, Global train loss: 2.102, Global test loss: 1.991, Global test accuracy: 50.68
Round  13, Train loss: 2.113, Test loss: 2.043, Test accuracy: 44.42
Round  13, Global train loss: 2.113, Global test loss: 1.971, Global test accuracy: 52.68
Round  14, Train loss: 2.062, Test loss: 2.022, Test accuracy: 45.66
Round  14, Global train loss: 2.062, Global test loss: 1.940, Global test accuracy: 55.34
Round  15, Train loss: 2.140, Test loss: 2.014, Test accuracy: 46.26
Round  15, Global train loss: 2.140, Global test loss: 1.979, Global test accuracy: 52.72
Round  16, Train loss: 2.061, Test loss: 2.010, Test accuracy: 46.12
Round  16, Global train loss: 2.061, Global test loss: 1.931, Global test accuracy: 55.76
Round  17, Train loss: 2.092, Test loss: 2.004, Test accuracy: 46.94
Round  17, Global train loss: 2.092, Global test loss: 1.956, Global test accuracy: 54.02
Round  18, Train loss: 2.026, Test loss: 1.996, Test accuracy: 47.46
Round  18, Global train loss: 2.026, Global test loss: 1.912, Global test accuracy: 56.52
Round  19, Train loss: 2.033, Test loss: 1.982, Test accuracy: 48.56
Round  19, Global train loss: 2.033, Global test loss: 1.925, Global test accuracy: 54.86
Round  20, Train loss: 2.055, Test loss: 1.987, Test accuracy: 47.78
Round  20, Global train loss: 2.055, Global test loss: 1.925, Global test accuracy: 55.12
Round  21, Train loss: 2.094, Test loss: 1.972, Test accuracy: 49.20
Round  21, Global train loss: 2.094, Global test loss: 1.930, Global test accuracy: 54.68
Round  22, Train loss: 2.036, Test loss: 1.972, Test accuracy: 48.92
Round  22, Global train loss: 2.036, Global test loss: 1.904, Global test accuracy: 56.46
Round  23, Train loss: 2.091, Test loss: 1.968, Test accuracy: 49.44
Round  23, Global train loss: 2.091, Global test loss: 1.933, Global test accuracy: 54.82
Round  24, Train loss: 2.082, Test loss: 1.968, Test accuracy: 49.38
Round  24, Global train loss: 2.082, Global test loss: 1.921, Global test accuracy: 54.94
Round  25, Train loss: 2.093, Test loss: 1.968, Test accuracy: 49.44
Round  25, Global train loss: 2.093, Global test loss: 1.941, Global test accuracy: 53.22
Round  26, Train loss: 2.029, Test loss: 1.973, Test accuracy: 48.46
Round  26, Global train loss: 2.029, Global test loss: 1.921, Global test accuracy: 54.58
Round  27, Train loss: 1.954, Test loss: 1.976, Test accuracy: 48.16
Round  27, Global train loss: 1.954, Global test loss: 1.901, Global test accuracy: 56.00
Round  28, Train loss: 2.047, Test loss: 1.974, Test accuracy: 48.58
Round  28, Global train loss: 2.047, Global test loss: 1.968, Global test accuracy: 51.48
Round  29, Train loss: 2.088, Test loss: 1.971, Test accuracy: 48.78
Round  29, Global train loss: 2.088, Global test loss: 1.932, Global test accuracy: 52.72
Round  30, Train loss: 2.019, Test loss: 1.970, Test accuracy: 49.02
Round  30, Global train loss: 2.019, Global test loss: 1.935, Global test accuracy: 54.34
Round  31, Train loss: 2.008, Test loss: 1.968, Test accuracy: 49.14
Round  31, Global train loss: 2.008, Global test loss: 1.930, Global test accuracy: 53.96
Round  32, Train loss: 1.930, Test loss: 1.970, Test accuracy: 48.88
Round  32, Global train loss: 1.930, Global test loss: 1.907, Global test accuracy: 55.08
Round  33, Train loss: 1.996, Test loss: 1.969, Test accuracy: 49.22
Round  33, Global train loss: 1.996, Global test loss: 1.918, Global test accuracy: 54.88
Round  34, Train loss: 2.035, Test loss: 1.968, Test accuracy: 49.22
Round  34, Global train loss: 2.035, Global test loss: 1.916, Global test accuracy: 54.40
Round  35, Train loss: 1.964, Test loss: 1.967, Test accuracy: 49.26
Round  35, Global train loss: 1.964, Global test loss: 1.921, Global test accuracy: 54.66
Round  36, Train loss: 2.013, Test loss: 1.967, Test accuracy: 49.20
Round  36, Global train loss: 2.013, Global test loss: 1.920, Global test accuracy: 53.86
Round  37, Train loss: 1.917, Test loss: 1.968, Test accuracy: 49.14
Round  37, Global train loss: 1.917, Global test loss: 1.903, Global test accuracy: 55.30
Round  38, Train loss: 1.970, Test loss: 1.965, Test accuracy: 49.42
Round  38, Global train loss: 1.970, Global test loss: 1.907, Global test accuracy: 55.12
Round  39, Train loss: 1.986, Test loss: 1.967, Test accuracy: 49.14
Round  39, Global train loss: 1.986, Global test loss: 1.914, Global test accuracy: 55.10
Round  40, Train loss: 2.001, Test loss: 1.968, Test accuracy: 49.20
Round  40, Global train loss: 2.001, Global test loss: 1.944, Global test accuracy: 52.64
Round  41, Train loss: 2.021, Test loss: 1.961, Test accuracy: 50.00
Round  41, Global train loss: 2.021, Global test loss: 1.911, Global test accuracy: 55.22
Round  42, Train loss: 1.900, Test loss: 1.963, Test accuracy: 49.86
Round  42, Global train loss: 1.900, Global test loss: 1.897, Global test accuracy: 56.32
Round  43, Train loss: 1.955, Test loss: 1.962, Test accuracy: 49.96
Round  43, Global train loss: 1.955, Global test loss: 1.903, Global test accuracy: 55.64
Round  44, Train loss: 2.016, Test loss: 1.958, Test accuracy: 50.34
Round  44, Global train loss: 2.016, Global test loss: 1.920, Global test accuracy: 55.00
Round  45, Train loss: 1.939, Test loss: 1.957, Test accuracy: 50.24
Round  45, Global train loss: 1.939, Global test loss: 1.902, Global test accuracy: 55.96
Round  46, Train loss: 1.992, Test loss: 1.966, Test accuracy: 49.28
Round  46, Global train loss: 1.992, Global test loss: 1.921, Global test accuracy: 54.76
Round  47, Train loss: 1.970, Test loss: 1.962, Test accuracy: 49.66
Round  47, Global train loss: 1.970, Global test loss: 1.911, Global test accuracy: 55.02
Round  48, Train loss: 2.034, Test loss: 1.967, Test accuracy: 49.32
Round  48, Global train loss: 2.034, Global test loss: 1.956, Global test accuracy: 51.32
Round  49, Train loss: 2.038, Test loss: 1.972, Test accuracy: 48.78
Round  49, Global train loss: 2.038, Global test loss: 1.959, Global test accuracy: 50.60
Round  50, Train loss: 1.972, Test loss: 1.974, Test accuracy: 48.54
Round  50, Global train loss: 1.972, Global test loss: 1.927, Global test accuracy: 53.64
Round  51, Train loss: 2.074, Test loss: 1.979, Test accuracy: 47.98
Round  51, Global train loss: 2.074, Global test loss: 1.934, Global test accuracy: 53.56
Round  52, Train loss: 1.982, Test loss: 1.980, Test accuracy: 48.00
Round  52, Global train loss: 1.982, Global test loss: 1.965, Global test accuracy: 51.22
Round  53, Train loss: 1.954, Test loss: 1.979, Test accuracy: 48.14
Round  53, Global train loss: 1.954, Global test loss: 1.947, Global test accuracy: 52.00
Round  54, Train loss: 1.883, Test loss: 1.982, Test accuracy: 47.86
Round  54, Global train loss: 1.883, Global test loss: 1.928, Global test accuracy: 54.38
Round  55, Train loss: 1.947, Test loss: 1.990, Test accuracy: 46.78
Round  55, Global train loss: 1.947, Global test loss: 1.950, Global test accuracy: 52.14
Round  56, Train loss: 1.873, Test loss: 1.988, Test accuracy: 46.92
Round  56, Global train loss: 1.873, Global test loss: 1.928, Global test accuracy: 53.92
Round  57, Train loss: 1.907, Test loss: 1.985, Test accuracy: 47.34
Round  57, Global train loss: 1.907, Global test loss: 1.932, Global test accuracy: 53.52
Round  58, Train loss: 2.038, Test loss: 1.984, Test accuracy: 47.50
Round  58, Global train loss: 2.038, Global test loss: 1.941, Global test accuracy: 52.10
Round  59, Train loss: 1.985, Test loss: 1.981, Test accuracy: 47.78
Round  59, Global train loss: 1.985, Global test loss: 1.937, Global test accuracy: 52.48
Round  60, Train loss: 1.927, Test loss: 1.983, Test accuracy: 47.54
Round  60, Global train loss: 1.927, Global test loss: 1.945, Global test accuracy: 52.34
Round  61, Train loss: 1.896, Test loss: 1.979, Test accuracy: 48.14
Round  61, Global train loss: 1.896, Global test loss: 1.951, Global test accuracy: 51.30
Round  62, Train loss: 1.966, Test loss: 1.979, Test accuracy: 48.06
Round  62, Global train loss: 1.966, Global test loss: 1.937, Global test accuracy: 52.46
Round  63, Train loss: 1.920, Test loss: 1.981, Test accuracy: 47.88
Round  63, Global train loss: 1.920, Global test loss: 1.967, Global test accuracy: 49.64
Round  64, Train loss: 1.880, Test loss: 1.983, Test accuracy: 47.72
Round  64, Global train loss: 1.880, Global test loss: 1.932, Global test accuracy: 53.80
Round  65, Train loss: 1.978, Test loss: 1.983, Test accuracy: 47.66
Round  65, Global train loss: 1.978, Global test loss: 1.959, Global test accuracy: 50.06
Round  66, Train loss: 1.872, Test loss: 1.985, Test accuracy: 47.38
Round  66, Global train loss: 1.872, Global test loss: 1.949, Global test accuracy: 51.60
Round  67, Train loss: 1.907, Test loss: 1.987, Test accuracy: 47.16
Round  67, Global train loss: 1.907, Global test loss: 1.925, Global test accuracy: 54.02
Round  68, Train loss: 1.925, Test loss: 1.979, Test accuracy: 47.94
Round  68, Global train loss: 1.925, Global test loss: 1.937, Global test accuracy: 53.16
Round  69, Train loss: 1.921, Test loss: 1.977, Test accuracy: 48.24
Round  69, Global train loss: 1.921, Global test loss: 1.969, Global test accuracy: 49.20
Round  70, Train loss: 1.899, Test loss: 1.981, Test accuracy: 47.68
Round  70, Global train loss: 1.899, Global test loss: 1.936, Global test accuracy: 52.46
Round  71, Train loss: 1.896, Test loss: 1.979, Test accuracy: 47.88
Round  71, Global train loss: 1.896, Global test loss: 1.924, Global test accuracy: 53.70
Round  72, Train loss: 1.953, Test loss: 1.986, Test accuracy: 46.96
Round  72, Global train loss: 1.953, Global test loss: 1.966, Global test accuracy: 50.08
Round  73, Train loss: 1.868, Test loss: 1.989, Test accuracy: 46.68
Round  73, Global train loss: 1.868, Global test loss: 1.972, Global test accuracy: 49.44
Round  74, Train loss: 1.865, Test loss: 1.990, Test accuracy: 46.56
Round  74, Global train loss: 1.865, Global test loss: 1.991, Global test accuracy: 47.50
Round  75, Train loss: 1.911, Test loss: 1.991, Test accuracy: 46.68
Round  75, Global train loss: 1.911, Global test loss: 1.958, Global test accuracy: 50.92
Round  76, Train loss: 1.840, Test loss: 1.982, Test accuracy: 47.60
Round  76, Global train loss: 1.840, Global test loss: 2.000, Global test accuracy: 46.48
Round  77, Train loss: 1.865, Test loss: 1.988, Test accuracy: 47.08
Round  77, Global train loss: 1.865, Global test loss: 1.954, Global test accuracy: 51.22
Round  78, Train loss: 1.857, Test loss: 1.987, Test accuracy: 47.16
Round  78, Global train loss: 1.857, Global test loss: 1.933, Global test accuracy: 52.62
Round  79, Train loss: 1.874, Test loss: 1.983, Test accuracy: 47.66
Round  79, Global train loss: 1.874, Global test loss: 1.958, Global test accuracy: 51.14
Round  80, Train loss: 1.893, Test loss: 1.985, Test accuracy: 47.44
Round  80, Global train loss: 1.893, Global test loss: 1.927, Global test accuracy: 53.18
Round  81, Train loss: 1.896, Test loss: 1.977, Test accuracy: 48.40
Round  81, Global train loss: 1.896, Global test loss: 1.914, Global test accuracy: 55.10
Round  82, Train loss: 1.817, Test loss: 1.968, Test accuracy: 49.36
Round  82, Global train loss: 1.817, Global test loss: 1.909, Global test accuracy: 56.12
Round  83, Train loss: 1.861, Test loss: 1.972, Test accuracy: 48.84
Round  83, Global train loss: 1.861, Global test loss: 1.917, Global test accuracy: 55.68
Round  84, Train loss: 1.891, Test loss: 1.970, Test accuracy: 48.94
Round  84, Global train loss: 1.891, Global test loss: 1.932, Global test accuracy: 54.08
Round  85, Train loss: 1.846, Test loss: 1.964, Test accuracy: 49.78
Round  85, Global train loss: 1.846, Global test loss: 1.878, Global test accuracy: 59.02
Round  86, Train loss: 1.833, Test loss: 1.961, Test accuracy: 50.28
Round  86, Global train loss: 1.833, Global test loss: 1.925, Global test accuracy: 54.48
Round  87, Train loss: 1.897, Test loss: 1.954, Test accuracy: 51.14
Round  87, Global train loss: 1.897, Global test loss: 1.901, Global test accuracy: 55.62
Round  88, Train loss: 1.806, Test loss: 1.957, Test accuracy: 50.72
Round  88, Global train loss: 1.806, Global test loss: 1.923, Global test accuracy: 54.12
Round  89, Train loss: 1.788, Test loss: 1.952, Test accuracy: 51.26
Round  89, Global train loss: 1.788, Global test loss: 1.897, Global test accuracy: 57.78
Round  90, Train loss: 1.893, Test loss: 1.947, Test accuracy: 51.56
Round  90, Global train loss: 1.893, Global test loss: 1.938, Global test accuracy: 52.54
Round  91, Train loss: 1.904, Test loss: 1.956, Test accuracy: 50.80
Round  91, Global train loss: 1.904, Global test loss: 1.980, Global test accuracy: 48.36
Round  92, Train loss: 1.858, Test loss: 1.957, Test accuracy: 50.56
Round  92, Global train loss: 1.858, Global test loss: 1.945, Global test accuracy: 51.84
Round  93, Train loss: 1.802, Test loss: 1.957, Test accuracy: 50.52
Round  93, Global train loss: 1.802, Global test loss: 1.909, Global test accuracy: 55.18
Round  94, Train loss: 1.857, Test loss: 1.947, Test accuracy: 51.36
Round  94, Global train loss: 1.857, Global test loss: 1.964, Global test accuracy: 50.10/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  95, Train loss: 1.773, Test loss: 1.947, Test accuracy: 51.26
Round  95, Global train loss: 1.773, Global test loss: 1.855, Global test accuracy: 60.88
Round  96, Train loss: 1.773, Test loss: 1.942, Test accuracy: 51.84
Round  96, Global train loss: 1.773, Global test loss: 1.849, Global test accuracy: 61.48
Round  97, Train loss: 1.862, Test loss: 1.941, Test accuracy: 52.10
Round  97, Global train loss: 1.862, Global test loss: 1.950, Global test accuracy: 51.26
Round  98, Train loss: 1.758, Test loss: 1.944, Test accuracy: 51.94
Round  98, Global train loss: 1.758, Global test loss: 1.856, Global test accuracy: 60.84
Round  99, Train loss: 1.821, Test loss: 1.932, Test accuracy: 53.20
Round  99, Global train loss: 1.821, Global test loss: 1.909, Global test accuracy: 55.62
Final Round, Train loss: 1.808, Test loss: 1.947, Test accuracy: 51.76
Final Round, Global train loss: 1.808, Global test loss: 1.909, Global test accuracy: 55.62
Average accuracy final 10 rounds: 51.514 

Average global accuracy final 10 rounds: 54.809999999999995 

740.7102589607239
[1.0843942165374756, 2.168788433074951, 3.1110610961914062, 4.053333759307861, 5.049051761627197, 6.044769763946533, 6.970916748046875, 7.897063732147217, 8.822041511535645, 9.747019290924072, 10.728626012802124, 11.710232734680176, 12.634488344192505, 13.558743953704834, 14.581498861312866, 15.604253768920898, 16.556806802749634, 17.50935983657837, 18.490160703659058, 19.470961570739746, 20.37396216392517, 21.276962757110596, 22.299161434173584, 23.321360111236572, 24.332534790039062, 25.343709468841553, 26.322975873947144, 27.302242279052734, 28.284664392471313, 29.267086505889893, 30.283735513687134, 31.300384521484375, 32.23224186897278, 33.16409921646118, 34.12393522262573, 35.08377122879028, 36.113125801086426, 37.14248037338257, 38.11674880981445, 39.09101724624634, 40.08658814430237, 41.0821590423584, 42.088364601135254, 43.09457015991211, 44.14575242996216, 45.19693470001221, 46.18640065193176, 47.17586660385132, 48.16389799118042, 49.15192937850952, 50.17273664474487, 51.193543910980225, 52.25779628753662, 53.32204866409302, 54.30942153930664, 55.296794414520264, 56.32872939109802, 57.36066436767578, 58.35492825508118, 59.34919214248657, 60.36749267578125, 61.38579320907593, 62.397804737091064, 63.4098162651062, 64.42571139335632, 65.44160652160645, 66.42780232429504, 67.41399812698364, 68.40613055229187, 69.3982629776001, 70.40329217910767, 71.40832138061523, 72.47367215156555, 73.53902292251587, 74.52362418174744, 75.508225440979, 76.60366630554199, 77.69910717010498, 78.70016574859619, 79.7012243270874, 80.75854349136353, 81.81586265563965, 82.82105779647827, 83.8262529373169, 84.78136134147644, 85.73646974563599, 86.75306296348572, 87.76965618133545, 88.76238989830017, 89.75512361526489, 90.77784657478333, 91.80056953430176, 92.7985942363739, 93.79661893844604, 94.78902792930603, 95.78143692016602, 96.78004670143127, 97.77865648269653, 98.78778052330017, 99.79690456390381, 100.86792540550232, 101.93894624710083, 103.01288604736328, 104.08682584762573, 105.10399150848389, 106.12115716934204, 107.18523168563843, 108.24930620193481, 109.26566815376282, 110.28203010559082, 111.29834771156311, 112.3146653175354, 113.29411768913269, 114.27357006072998, 115.28386783599854, 116.29416561126709, 117.28693628311157, 118.27970695495605, 119.29053974151611, 120.30137252807617, 121.289959192276, 122.27854585647583, 123.271071434021, 124.26359701156616, 125.25291514396667, 126.24223327636719, 127.24819898605347, 128.25416469573975, 129.2937092781067, 130.33325386047363, 131.34579753875732, 132.35834121704102, 133.89323377609253, 135.42812633514404, 136.41079473495483, 137.39346313476562, 138.56839990615845, 139.74333667755127, 140.73959946632385, 141.73586225509644, 142.7198510169983, 143.70383977890015, 144.68270611763, 145.66157245635986, 146.69473576545715, 147.72789907455444, 148.69919347763062, 149.6704878807068, 150.64391660690308, 151.61734533309937, 152.63642835617065, 153.65551137924194, 154.64172911643982, 155.6279468536377, 156.6005141735077, 157.57308149337769, 158.5643572807312, 159.55563306808472, 160.60864186286926, 161.6616506576538, 162.67959785461426, 163.6975450515747, 164.6996145248413, 165.7016839981079, 166.71680688858032, 167.73192977905273, 168.71571969985962, 169.6995096206665, 170.6901023387909, 171.68069505691528, 172.68832969665527, 173.69596433639526, 174.71037483215332, 175.72478532791138, 176.74219250679016, 177.75959968566895, 178.8196873664856, 179.87977504730225, 180.8682882785797, 181.85680150985718, 182.83560252189636, 183.81440353393555, 184.85578298568726, 185.89716243743896, 186.9206006526947, 187.94403886795044, 188.9609010219574, 189.97776317596436, 191.00704765319824, 192.03633213043213, 193.04386115074158, 194.05139017105103, 195.0221643447876, 195.99293851852417, 197.01943111419678, 198.04592370986938, 199.0818166732788, 200.11770963668823, 201.15494418144226, 202.1921787261963, 204.21484899520874, 206.2375192642212]
[10.94, 10.94, 12.42, 12.42, 17.04, 17.04, 14.94, 14.94, 16.1, 16.1, 19.4, 19.4, 22.32, 22.32, 23.0, 23.0, 26.88, 26.88, 32.9, 32.9, 34.96, 34.96, 41.48, 41.48, 43.98, 43.98, 44.42, 44.42, 45.66, 45.66, 46.26, 46.26, 46.12, 46.12, 46.94, 46.94, 47.46, 47.46, 48.56, 48.56, 47.78, 47.78, 49.2, 49.2, 48.92, 48.92, 49.44, 49.44, 49.38, 49.38, 49.44, 49.44, 48.46, 48.46, 48.16, 48.16, 48.58, 48.58, 48.78, 48.78, 49.02, 49.02, 49.14, 49.14, 48.88, 48.88, 49.22, 49.22, 49.22, 49.22, 49.26, 49.26, 49.2, 49.2, 49.14, 49.14, 49.42, 49.42, 49.14, 49.14, 49.2, 49.2, 50.0, 50.0, 49.86, 49.86, 49.96, 49.96, 50.34, 50.34, 50.24, 50.24, 49.28, 49.28, 49.66, 49.66, 49.32, 49.32, 48.78, 48.78, 48.54, 48.54, 47.98, 47.98, 48.0, 48.0, 48.14, 48.14, 47.86, 47.86, 46.78, 46.78, 46.92, 46.92, 47.34, 47.34, 47.5, 47.5, 47.78, 47.78, 47.54, 47.54, 48.14, 48.14, 48.06, 48.06, 47.88, 47.88, 47.72, 47.72, 47.66, 47.66, 47.38, 47.38, 47.16, 47.16, 47.94, 47.94, 48.24, 48.24, 47.68, 47.68, 47.88, 47.88, 46.96, 46.96, 46.68, 46.68, 46.56, 46.56, 46.68, 46.68, 47.6, 47.6, 47.08, 47.08, 47.16, 47.16, 47.66, 47.66, 47.44, 47.44, 48.4, 48.4, 49.36, 49.36, 48.84, 48.84, 48.94, 48.94, 49.78, 49.78, 50.28, 50.28, 51.14, 51.14, 50.72, 50.72, 51.26, 51.26, 51.56, 51.56, 50.8, 50.8, 50.56, 50.56, 50.52, 50.52, 51.36, 51.36, 51.26, 51.26, 51.84, 51.84, 52.1, 52.1, 51.94, 51.94, 53.2, 53.2, 51.76, 51.76]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.4 , level_n_lowerb:0.8  

   Client 3, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 4, noise    level: 0.8000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Traceback (most recent call last):
  File "main_fedpac_co_teaching.py", line 250, in <module>
    local.filter_data(net=net_local.to(args.device), net2=net_local2.to(args.device), concept_matrix_local = concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1587, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

   Client 0, noise    level: 0.8000 
   Client 5, noise    level: 0.8000 
   Client 1, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.320, Test loss: 2.301, Test accuracy: 11.14
Round   0, Global train loss: 2.320, Global test loss: 2.301, Global test accuracy: 11.14
Round   1, Train loss: 2.298, Test loss: 2.300, Test accuracy: 11.14
Round   1, Global train loss: 2.298, Global test loss: 2.300, Global test accuracy: 11.14
Round   2, Train loss: 2.300, Test loss: 2.298, Test accuracy: 11.14
Round   2, Global train loss: 2.300, Global test loss: 2.298, Global test accuracy: 11.14
Round   3, Train loss: 2.293, Test loss: 2.297, Test accuracy: 11.14
Round   3, Global train loss: 2.293, Global test loss: 2.296, Global test accuracy: 11.14
Round   4, Train loss: 2.295, Test loss: 2.294, Test accuracy: 11.14
Round   4, Global train loss: 2.295, Global test loss: 2.294, Global test accuracy: 11.14
Round   5, Train loss: 2.295, Test loss: 2.290, Test accuracy: 11.14
Round   5, Global train loss: 2.295, Global test loss: 2.290, Global test accuracy: 11.14
Round   6, Train loss: 2.280, Test loss: 2.286, Test accuracy: 11.14
Round   6, Global train loss: 2.280, Global test loss: 2.285, Global test accuracy: 11.14
Round   7, Train loss: 2.290, Test loss: 2.278, Test accuracy: 11.38
Round   7, Global train loss: 2.290, Global test loss: 2.278, Global test accuracy: 11.14
Round   8, Train loss: 2.279, Test loss: 2.266, Test accuracy: 12.90
Round   8, Global train loss: 2.279, Global test loss: 2.266, Global test accuracy: 11.38
Round   9, Train loss: 2.258, Test loss: 2.248, Test accuracy: 18.92
Round   9, Global train loss: 2.258, Global test loss: 2.243, Global test accuracy: 19.00
Round  10, Train loss: 2.253, Test loss: 2.239, Test accuracy: 23.18
Round  10, Global train loss: 2.253, Global test loss: 2.238, Global test accuracy: 14.62
Round  11, Train loss: 2.241, Test loss: 2.189, Test accuracy: 33.10
Round  11, Global train loss: 2.241, Global test loss: 2.176, Global test accuracy: 34.56
Round  12, Train loss: 2.216, Test loss: 2.164, Test accuracy: 36.48
Round  12, Global train loss: 2.216, Global test loss: 2.153, Global test accuracy: 39.44
Round  13, Train loss: 2.218, Test loss: 2.155, Test accuracy: 36.08
Round  13, Global train loss: 2.218, Global test loss: 2.147, Global test accuracy: 36.04
Round  14, Train loss: 2.233, Test loss: 2.159, Test accuracy: 34.10
Round  14, Global train loss: 2.233, Global test loss: 2.156, Global test accuracy: 37.68
Round  15, Train loss: 2.182, Test loss: 2.130, Test accuracy: 37.10
Round  15, Global train loss: 2.182, Global test loss: 2.100, Global test accuracy: 39.64
Round  16, Train loss: 2.185, Test loss: 2.110, Test accuracy: 37.90
Round  16, Global train loss: 2.185, Global test loss: 2.084, Global test accuracy: 40.98
Round  17, Train loss: 2.128, Test loss: 2.082, Test accuracy: 41.44
Round  17, Global train loss: 2.128, Global test loss: 2.030, Global test accuracy: 43.84
Round  18, Train loss: 2.176, Test loss: 2.092, Test accuracy: 40.38
Round  18, Global train loss: 2.176, Global test loss: 2.080, Global test accuracy: 44.18
Round  19, Train loss: 2.184, Test loss: 2.094, Test accuracy: 41.00
Round  19, Global train loss: 2.184, Global test loss: 2.075, Global test accuracy: 46.28
Round  20, Train loss: 2.069, Test loss: 2.044, Test accuracy: 46.98
Round  20, Global train loss: 2.069, Global test loss: 1.962, Global test accuracy: 56.78
Round  21, Train loss: 2.118, Test loss: 2.023, Test accuracy: 48.00
Round  21, Global train loss: 2.118, Global test loss: 2.004, Global test accuracy: 55.52
Round  22, Train loss: 2.137, Test loss: 2.036, Test accuracy: 45.88
Round  22, Global train loss: 2.137, Global test loss: 2.011, Global test accuracy: 52.48
Round  23, Train loss: 2.126, Test loss: 2.029, Test accuracy: 46.30
Round  23, Global train loss: 2.126, Global test loss: 1.979, Global test accuracy: 55.80
Round  24, Train loss: 2.060, Test loss: 2.010, Test accuracy: 47.26
Round  24, Global train loss: 2.060, Global test loss: 1.960, Global test accuracy: 55.04
Round  25, Train loss: 1.995, Test loss: 1.988, Test accuracy: 48.80
Round  25, Global train loss: 1.995, Global test loss: 1.901, Global test accuracy: 58.58
Round  26, Train loss: 2.079, Test loss: 1.996, Test accuracy: 47.78
Round  26, Global train loss: 2.079, Global test loss: 1.940, Global test accuracy: 57.54
Round  27, Train loss: 2.209, Test loss: 2.029, Test accuracy: 46.06
Round  27, Global train loss: 2.209, Global test loss: 2.097, Global test accuracy: 45.12
Round  28, Train loss: 2.090, Test loss: 2.020, Test accuracy: 46.64
Round  28, Global train loss: 2.090, Global test loss: 1.966, Global test accuracy: 55.90
Round  29, Train loss: 2.041, Test loss: 2.007, Test accuracy: 47.20
Round  29, Global train loss: 2.041, Global test loss: 1.938, Global test accuracy: 57.04
Round  30, Train loss: 2.101, Test loss: 2.007, Test accuracy: 47.02
Round  30, Global train loss: 2.101, Global test loss: 1.953, Global test accuracy: 57.22
Round  31, Train loss: 2.044, Test loss: 2.009, Test accuracy: 46.68
Round  31, Global train loss: 2.044, Global test loss: 1.941, Global test accuracy: 56.68
Round  32, Train loss: 2.124, Test loss: 2.017, Test accuracy: 46.58
Round  32, Global train loss: 2.124, Global test loss: 2.029, Global test accuracy: 52.12
Round  33, Train loss: 1.963, Test loss: 1.996, Test accuracy: 47.24
Round  33, Global train loss: 1.963, Global test loss: 1.887, Global test accuracy: 58.70
Round  34, Train loss: 2.032, Test loss: 1.996, Test accuracy: 47.10
Round  34, Global train loss: 2.032, Global test loss: 1.945, Global test accuracy: 56.54
Round  35, Train loss: 2.125, Test loss: 2.016, Test accuracy: 46.20
Round  35, Global train loss: 2.125, Global test loss: 2.031, Global test accuracy: 49.92
Round  36, Train loss: 2.111, Test loss: 2.020, Test accuracy: 46.14
Round  36, Global train loss: 2.111, Global test loss: 2.035, Global test accuracy: 50.36
Round  37, Train loss: 2.105, Test loss: 2.024, Test accuracy: 45.94
Round  37, Global train loss: 2.105, Global test loss: 2.045, Global test accuracy: 49.30
Round  38, Train loss: 2.118, Test loss: 2.027, Test accuracy: 46.00
Round  38, Global train loss: 2.118, Global test loss: 2.075, Global test accuracy: 42.66
Round  39, Train loss: 2.049, Test loss: 2.009, Test accuracy: 46.64
Round  39, Global train loss: 2.049, Global test loss: 1.971, Global test accuracy: 55.64
Round  40, Train loss: 2.014, Test loss: 2.003, Test accuracy: 46.62
Round  40, Global train loss: 2.014, Global test loss: 1.939, Global test accuracy: 55.74
Round  41, Train loss: 2.003, Test loss: 1.995, Test accuracy: 47.24
Round  41, Global train loss: 2.003, Global test loss: 1.918, Global test accuracy: 58.38
Round  42, Train loss: 2.182, Test loss: 2.028, Test accuracy: 45.68
Round  42, Global train loss: 2.182, Global test loss: 2.107, Global test accuracy: 37.98
Round  43, Train loss: 2.062, Test loss: 2.006, Test accuracy: 46.58
Round  43, Global train loss: 2.062, Global test loss: 1.970, Global test accuracy: 55.92
Round  44, Train loss: 1.979, Test loss: 1.986, Test accuracy: 47.56
Round  44, Global train loss: 1.979, Global test loss: 1.874, Global test accuracy: 60.04
Round  45, Train loss: 2.083, Test loss: 2.000, Test accuracy: 47.46
Round  45, Global train loss: 2.083, Global test loss: 2.020, Global test accuracy: 48.84
Round  46, Train loss: 2.018, Test loss: 1.988, Test accuracy: 48.86
Round  46, Global train loss: 2.018, Global test loss: 1.945, Global test accuracy: 56.10
Round  47, Train loss: 1.981, Test loss: 1.972, Test accuracy: 50.78
Round  47, Global train loss: 1.981, Global test loss: 1.904, Global test accuracy: 63.06
Round  48, Train loss: 1.889, Test loss: 1.951, Test accuracy: 52.60
Round  48, Global train loss: 1.889, Global test loss: 1.830, Global test accuracy: 65.40
Round  49, Train loss: 1.934, Test loss: 1.949, Test accuracy: 53.86
Round  49, Global train loss: 1.934, Global test loss: 1.869, Global test accuracy: 64.90
Round  50, Train loss: 1.951, Test loss: 1.947, Test accuracy: 53.90
Round  50, Global train loss: 1.951, Global test loss: 1.874, Global test accuracy: 66.96
Round  51, Train loss: 1.920, Test loss: 1.927, Test accuracy: 55.82
Round  51, Global train loss: 1.920, Global test loss: 1.796, Global test accuracy: 71.52
Round  52, Train loss: 2.014, Test loss: 1.931, Test accuracy: 56.48
Round  52, Global train loss: 2.014, Global test loss: 1.878, Global test accuracy: 64.84
Round  53, Train loss: 1.843, Test loss: 1.910, Test accuracy: 57.84
Round  53, Global train loss: 1.843, Global test loss: 1.759, Global test accuracy: 75.08
Round  54, Train loss: 1.954, Test loss: 1.915, Test accuracy: 58.54
Round  54, Global train loss: 1.954, Global test loss: 1.851, Global test accuracy: 70.04
Round  55, Train loss: 2.009, Test loss: 1.920, Test accuracy: 58.36
Round  55, Global train loss: 2.009, Global test loss: 1.883, Global test accuracy: 70.82
Round  56, Train loss: 2.048, Test loss: 1.946, Test accuracy: 57.24
Round  56, Global train loss: 2.048, Global test loss: 2.038, Global test accuracy: 43.78
Round  57, Train loss: 1.916, Test loss: 1.923, Test accuracy: 58.98
Round  57, Global train loss: 1.916, Global test loss: 1.843, Global test accuracy: 69.62
Round  58, Train loss: 1.944, Test loss: 1.912, Test accuracy: 59.96
Round  58, Global train loss: 1.944, Global test loss: 1.863, Global test accuracy: 66.24
Round  59, Train loss: 1.908, Test loss: 1.899, Test accuracy: 61.52
Round  59, Global train loss: 1.908, Global test loss: 1.830, Global test accuracy: 74.30
Round  60, Train loss: 1.891, Test loss: 1.897, Test accuracy: 61.86
Round  60, Global train loss: 1.891, Global test loss: 1.841, Global test accuracy: 67.86
Round  61, Train loss: 1.968, Test loss: 1.894, Test accuracy: 62.46
Round  61, Global train loss: 1.968, Global test loss: 1.882, Global test accuracy: 69.58
Round  62, Train loss: 1.851, Test loss: 1.883, Test accuracy: 64.04
Round  62, Global train loss: 1.851, Global test loss: 1.779, Global test accuracy: 77.86
Round  63, Train loss: 1.873, Test loss: 1.884, Test accuracy: 63.86
Round  63, Global train loss: 1.873, Global test loss: 1.828, Global test accuracy: 74.06
Round  64, Train loss: 1.888, Test loss: 1.886, Test accuracy: 63.70
Round  64, Global train loss: 1.888, Global test loss: 1.834, Global test accuracy: 73.74
Round  65, Train loss: 1.838, Test loss: 1.867, Test accuracy: 65.30
Round  65, Global train loss: 1.838, Global test loss: 1.775, Global test accuracy: 78.48
Round  66, Train loss: 2.004, Test loss: 1.912, Test accuracy: 62.70
Round  66, Global train loss: 2.004, Global test loss: 1.987, Global test accuracy: 51.34
Round  67, Train loss: 1.968, Test loss: 1.922, Test accuracy: 61.76
Round  67, Global train loss: 1.968, Global test loss: 1.946, Global test accuracy: 63.36
Round  68, Train loss: 1.878, Test loss: 1.891, Test accuracy: 63.60
Round  68, Global train loss: 1.878, Global test loss: 1.855, Global test accuracy: 73.46
Round  69, Train loss: 1.831, Test loss: 1.883, Test accuracy: 64.38
Round  69, Global train loss: 1.831, Global test loss: 1.809, Global test accuracy: 75.06
Round  70, Train loss: 2.022, Test loss: 1.911, Test accuracy: 62.10
Round  70, Global train loss: 2.022, Global test loss: 2.006, Global test accuracy: 49.00
Round  71, Train loss: 1.796, Test loss: 1.869, Test accuracy: 65.62
Round  71, Global train loss: 1.796, Global test loss: 1.773, Global test accuracy: 79.48
Round  72, Train loss: 1.806, Test loss: 1.866, Test accuracy: 65.74
Round  72, Global train loss: 1.806, Global test loss: 1.785, Global test accuracy: 77.10
Round  73, Train loss: 1.789, Test loss: 1.868, Test accuracy: 65.78
Round  73, Global train loss: 1.789, Global test loss: 1.804, Global test accuracy: 76.22
Round  74, Train loss: 1.719, Test loss: 1.835, Test accuracy: 68.10
Round  74, Global train loss: 1.719, Global test loss: 1.678, Global test accuracy: 86.14
Round  75, Train loss: 1.829, Test loss: 1.848, Test accuracy: 67.36
Round  75, Global train loss: 1.829, Global test loss: 1.798, Global test accuracy: 78.60
Round  76, Train loss: 1.787, Test loss: 1.869, Test accuracy: 65.38
Round  76, Global train loss: 1.787, Global test loss: 1.827, Global test accuracy: 71.12
Round  77, Train loss: 1.757, Test loss: 1.859, Test accuracy: 66.16
Round  77, Global train loss: 1.757, Global test loss: 1.788, Global test accuracy: 77.30
Round  78, Train loss: 1.805, Test loss: 1.867, Test accuracy: 65.74
Round  78, Global train loss: 1.805, Global test loss: 1.797, Global test accuracy: 77.88
Round  79, Train loss: 1.740, Test loss: 1.865, Test accuracy: 65.62
Round  79, Global train loss: 1.740, Global test loss: 1.805, Global test accuracy: 72.72
Round  80, Train loss: 1.897, Test loss: 1.916, Test accuracy: 60.78
Round  80, Global train loss: 1.897, Global test loss: 1.953, Global test accuracy: 60.32
Round  81, Train loss: 1.840, Test loss: 1.870, Test accuracy: 65.38
Round  81, Global train loss: 1.840, Global test loss: 1.854, Global test accuracy: 69.82
Round  82, Train loss: 1.745, Test loss: 1.858, Test accuracy: 66.34
Round  82, Global train loss: 1.745, Global test loss: 1.790, Global test accuracy: 76.58
Round  83, Train loss: 1.779, Test loss: 1.856, Test accuracy: 66.80
Round  83, Global train loss: 1.779, Global test loss: 1.820, Global test accuracy: 74.76
Round  84, Train loss: 1.894, Test loss: 1.898, Test accuracy: 62.02
Round  84, Global train loss: 1.894, Global test loss: 1.953, Global test accuracy: 59.12
Round  85, Train loss: 1.857, Test loss: 1.866, Test accuracy: 65.82
Round  85, Global train loss: 1.857, Global test loss: 1.828, Global test accuracy: 74.66
Round  86, Train loss: 1.841, Test loss: 1.873, Test accuracy: 64.98
Round  86, Global train loss: 1.841, Global test loss: 1.858, Global test accuracy: 71.96
Round  87, Train loss: 1.880, Test loss: 1.894, Test accuracy: 62.68
Round  87, Global train loss: 1.880, Global test loss: 1.930, Global test accuracy: 64.22
Round  88, Train loss: 1.861, Test loss: 1.923, Test accuracy: 59.80
Round  88, Global train loss: 1.861, Global test loss: 1.970, Global test accuracy: 58.16
Round  89, Train loss: 1.723, Test loss: 1.869, Test accuracy: 64.92
Round  89, Global train loss: 1.723, Global test loss: 1.808, Global test accuracy: 74.46
Round  90, Train loss: 1.623, Test loss: 1.821, Test accuracy: 68.46
Round  90, Global train loss: 1.623, Global test loss: 1.667, Global test accuracy: 84.64
Round  91, Train loss: 1.609, Test loss: 1.814, Test accuracy: 69.40
Round  91, Global train loss: 1.609, Global test loss: 1.661, Global test accuracy: 85.40/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  92, Train loss: 1.701, Test loss: 1.850, Test accuracy: 65.96
Round  92, Global train loss: 1.701, Global test loss: 1.797, Global test accuracy: 73.96
Round  93, Train loss: 1.688, Test loss: 1.859, Test accuracy: 65.78
Round  93, Global train loss: 1.688, Global test loss: 1.793, Global test accuracy: 75.30
Round  94, Train loss: 1.603, Test loss: 1.825, Test accuracy: 68.02
Round  94, Global train loss: 1.603, Global test loss: 1.680, Global test accuracy: 84.58
Round  95, Train loss: 1.826, Test loss: 1.901, Test accuracy: 61.56
Round  95, Global train loss: 1.826, Global test loss: 1.997, Global test accuracy: 49.92
Round  96, Train loss: 1.813, Test loss: 1.937, Test accuracy: 57.34
Round  96, Global train loss: 1.813, Global test loss: 2.016, Global test accuracy: 46.28
Round  97, Train loss: 1.616, Test loss: 1.840, Test accuracy: 66.64
Round  97, Global train loss: 1.616, Global test loss: 1.689, Global test accuracy: 83.92
Round  98, Train loss: 1.789, Test loss: 1.921, Test accuracy: 59.04
Round  98, Global train loss: 1.789, Global test loss: 2.003, Global test accuracy: 49.58
Round  99, Train loss: 1.713, Test loss: 1.884, Test accuracy: 63.00
Round  99, Global train loss: 1.713, Global test loss: 1.863, Global test accuracy: 65.78
Final Round, Train loss: 1.716, Test loss: 1.863, Test accuracy: 64.14
Final Round, Global train loss: 1.716, Global test loss: 1.863, Global test accuracy: 65.78
Average accuracy final 10 rounds: 64.52
624.9124262332916
[1.2675602436065674, 2.3378732204437256, 3.3952901363372803, 4.470283269882202, 5.572843313217163, 6.696302175521851, 7.7379631996154785, 8.85901951789856, 9.953896284103394, 11.086674690246582, 12.180999755859375, 13.273589134216309, 14.374631643295288, 15.456034898757935, 16.546897649765015, 17.620295763015747, 18.70653986930847, 19.826025247573853, 20.919062852859497, 22.061513423919678, 23.208507776260376, 24.304832220077515, 25.430968523025513, 26.53224205970764, 27.612008571624756, 28.733494520187378, 29.843913793563843, 30.900320291519165, 31.974982023239136, 33.041313886642456, 34.14763069152832, 35.22146487236023, 36.31025195121765, 37.397544145584106, 38.5176739692688, 39.61899280548096, 40.66099691390991, 41.79286527633667, 42.92004132270813, 43.991939067840576, 45.05041480064392, 46.1736536026001, 47.226231813430786, 48.32863640785217, 49.43958020210266, 50.513840436935425, 51.61400127410889, 52.68976426124573, 53.75899124145508, 54.86086440086365, 56.005597829818726, 57.11469769477844, 58.231916427612305, 59.31716561317444, 60.38612079620361, 61.47594666481018, 62.611433267593384, 63.705073595047, 64.78159666061401, 65.86185336112976, 66.98534774780273, 68.09172248840332, 69.12378001213074, 70.19994497299194, 71.23582983016968, 72.31986165046692, 73.43330931663513, 74.58140635490417, 75.70494437217712, 76.8608660697937, 77.97609806060791, 79.08952569961548, 80.19547510147095, 81.87617206573486, 82.98138761520386, 84.0653829574585, 85.21250653266907, 86.29378461837769, 87.37557721138, 88.51738595962524, 89.60621428489685, 90.71546196937561, 91.79849791526794, 92.87920188903809, 93.97292137145996, 95.04705476760864, 96.11755204200745, 97.18842220306396, 98.35392737388611, 99.49557304382324, 100.62809324264526, 101.68733024597168, 102.78790664672852, 103.89258408546448, 104.96202158927917, 106.08218669891357, 107.20007133483887, 108.37734150886536, 109.47876644134521, 110.57379126548767, 112.3783106803894]
[11.14, 11.14, 11.14, 11.14, 11.14, 11.14, 11.14, 11.38, 12.9, 18.92, 23.18, 33.1, 36.48, 36.08, 34.1, 37.1, 37.9, 41.44, 40.38, 41.0, 46.98, 48.0, 45.88, 46.3, 47.26, 48.8, 47.78, 46.06, 46.64, 47.2, 47.02, 46.68, 46.58, 47.24, 47.1, 46.2, 46.14, 45.94, 46.0, 46.64, 46.62, 47.24, 45.68, 46.58, 47.56, 47.46, 48.86, 50.78, 52.6, 53.86, 53.9, 55.82, 56.48, 57.84, 58.54, 58.36, 57.24, 58.98, 59.96, 61.52, 61.86, 62.46, 64.04, 63.86, 63.7, 65.3, 62.7, 61.76, 63.6, 64.38, 62.1, 65.62, 65.74, 65.78, 68.1, 67.36, 65.38, 66.16, 65.74, 65.62, 60.78, 65.38, 66.34, 66.8, 62.02, 65.82, 64.98, 62.68, 59.8, 64.92, 68.46, 69.4, 65.96, 65.78, 68.02, 61.56, 57.34, 66.64, 59.04, 63.0, 64.14]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fedpac_copsl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist,  filter_alg: loss_psl, level_n_system: 0.4 , level_n_lowerb:0.8  

   Client 5, noise    level: 0.8000 
   Client 2, noise    level: 0.8000 
   Client 0, noise    level: 0.8000 
   Client 9, noise    level: 0.8000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.320, Test loss: 2.301, Test accuracy: 11.02
Round   0, Global train loss: 2.320, Global test loss: 2.301, Global test accuracy: 10.76
Round   1, Train loss: 2.299, Test loss: 2.299, Test accuracy: 12.04
Round   1, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 11.14
Round   2, Train loss: 2.297, Test loss: 2.297, Test accuracy: 14.22
Round   2, Global train loss: 2.297, Global test loss: 2.297, Global test accuracy: 11.88
Round   3, Train loss: 2.294, Test loss: 2.295, Test accuracy: 17.94
Round   3, Global train loss: 2.294, Global test loss: 2.295, Global test accuracy: 14.38
Round   4, Train loss: 2.291, Test loss: 2.291, Test accuracy: 22.18
Round   4, Global train loss: 2.291, Global test loss: 2.291, Global test accuracy: 16.48
Round   5, Train loss: 2.286, Test loss: 2.286, Test accuracy: 25.28
Round   5, Global train loss: 2.286, Global test loss: 2.286, Global test accuracy: 20.92
Round   6, Train loss: 2.278, Test loss: 2.278, Test accuracy: 27.00
Round   6, Global train loss: 2.278, Global test loss: 2.277, Global test accuracy: 26.86
Round   7, Train loss: 2.266, Test loss: 2.261, Test accuracy: 27.62
Round   7, Global train loss: 2.266, Global test loss: 2.260, Global test accuracy: 34.96
Round   8, Train loss: 2.241, Test loss: 2.227, Test accuracy: 27.82
Round   8, Global train loss: 2.241, Global test loss: 2.221, Global test accuracy: 38.82
Round   9, Train loss: 2.206, Test loss: 2.186, Test accuracy: 30.48
Round   9, Global train loss: 2.206, Global test loss: 2.165, Global test accuracy: 39.36
Round  10, Train loss: 2.168, Test loss: 2.154, Test accuracy: 32.44
Round  10, Global train loss: 2.168, Global test loss: 2.125, Global test accuracy: 39.64
Traceback (most recent call last):
  File "main_fedpac_copsl.py", line 280, in <module>
    w_local, loss, indd, class_center_local, class_num, noisy_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys,
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2559, in train
    self.filter_data(net, local_net, iter2-head_eps+1, local_eps-head_eps+1, concept_matrix_local)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2396, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: mnist, level_n_system: 0.6 , level_n_lowerb:0.4  

   Client 5, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.301, Test loss: 2.301, Test accuracy: 12.50
Round   0, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 12.18
Round   1, Train loss: 2.299, Test loss: 2.300, Test accuracy: 15.34
Round   1, Global train loss: 2.299, Global test loss: 2.300, Global test accuracy: 16.32
Round   2, Train loss: 2.296, Test loss: 2.298, Test accuracy: 18.24
Round   2, Global train loss: 2.296, Global test loss: 2.297, Global test accuracy: 22.76
Round   3, Train loss: 2.292, Test loss: 2.293, Test accuracy: 19.36
Round   3, Global train loss: 2.292, Global test loss: 2.292, Global test accuracy: 22.22
Round   4, Train loss: 2.287, Test loss: 2.287, Test accuracy: 19.74
Round   4, Global train loss: 2.287, Global test loss: 2.287, Global test accuracy: 22.24
Round   5, Train loss: 2.276, Test loss: 2.273, Test accuracy: 21.36
Round   5, Global train loss: 2.276, Global test loss: 2.265, Global test accuracy: 25.92
Round   6, Train loss: 2.273, Test loss: 2.265, Test accuracy: 20.24
Round   6, Global train loss: 2.273, Global test loss: 2.271, Global test accuracy: 26.50
Round   7, Train loss: 2.254, Test loss: 2.250, Test accuracy: 20.40
Round   7, Global train loss: 2.254, Global test loss: 2.244, Global test accuracy: 30.00
Round   8, Train loss: 2.233, Test loss: 2.226, Test accuracy: 22.32
Round   8, Global train loss: 2.233, Global test loss: 2.198, Global test accuracy: 24.08
Round   9, Train loss: 2.241, Test loss: 2.222, Test accuracy: 23.42
Round   9, Global train loss: 2.241, Global test loss: 2.250, Global test accuracy: 26.04
Round  10, Train loss: 2.204, Test loss: 2.205, Test accuracy: 24.54
Round  10, Global train loss: 2.204, Global test loss: 2.190, Global test accuracy: 28.62
Round  11, Train loss: 2.246, Test loss: 2.192, Test accuracy: 26.44
Round  11, Global train loss: 2.246, Global test loss: 2.220, Global test accuracy: 30.46
Round  12, Train loss: 2.139, Test loss: 2.178, Test accuracy: 29.46
Round  12, Global train loss: 2.139, Global test loss: 2.123, Global test accuracy: 39.80
Round  13, Train loss: 2.123, Test loss: 2.147, Test accuracy: 32.60
Round  13, Global train loss: 2.123, Global test loss: 2.094, Global test accuracy: 48.18
Round  14, Train loss: 2.123, Test loss: 2.123, Test accuracy: 34.92
Round  14, Global train loss: 2.123, Global test loss: 2.083, Global test accuracy: 43.74
Round  15, Train loss: 2.086, Test loss: 2.109, Test accuracy: 36.38
Round  15, Global train loss: 2.086, Global test loss: 2.073, Global test accuracy: 42.06
Round  16, Train loss: 2.092, Test loss: 2.094, Test accuracy: 38.02
Round  16, Global train loss: 2.092, Global test loss: 2.037, Global test accuracy: 47.58
Round  17, Train loss: 2.066, Test loss: 2.082, Test accuracy: 39.24
Round  17, Global train loss: 2.066, Global test loss: 2.075, Global test accuracy: 43.68
Round  18, Train loss: 2.220, Test loss: 2.067, Test accuracy: 41.86
Round  18, Global train loss: 2.220, Global test loss: 2.195, Global test accuracy: 39.84
Round  19, Train loss: 2.097, Test loss: 2.046, Test accuracy: 44.20
Round  19, Global train loss: 2.097, Global test loss: 2.113, Global test accuracy: 41.80
Round  20, Train loss: 2.021, Test loss: 2.037, Test accuracy: 44.34
Round  20, Global train loss: 2.021, Global test loss: 2.051, Global test accuracy: 39.88
Round  21, Train loss: 1.954, Test loss: 2.023, Test accuracy: 46.08
Round  21, Global train loss: 1.954, Global test loss: 1.938, Global test accuracy: 53.90
Round  22, Train loss: 2.149, Test loss: 2.016, Test accuracy: 46.86
Round  22, Global train loss: 2.149, Global test loss: 2.125, Global test accuracy: 34.02
Round  23, Train loss: 2.018, Test loss: 2.005, Test accuracy: 47.58
Round  23, Global train loss: 2.018, Global test loss: 2.037, Global test accuracy: 42.58
Round  24, Train loss: 1.905, Test loss: 1.997, Test accuracy: 48.32
Round  24, Global train loss: 1.905, Global test loss: 1.957, Global test accuracy: 51.90
Round  25, Train loss: 1.904, Test loss: 1.993, Test accuracy: 48.88
Round  25, Global train loss: 1.904, Global test loss: 1.978, Global test accuracy: 47.82
Round  26, Train loss: 2.096, Test loss: 1.984, Test accuracy: 49.48
Round  26, Global train loss: 2.096, Global test loss: 2.081, Global test accuracy: 38.10
Round  27, Train loss: 2.017, Test loss: 1.979, Test accuracy: 49.70
Round  27, Global train loss: 2.017, Global test loss: 2.051, Global test accuracy: 39.78
Round  28, Train loss: 1.957, Test loss: 1.974, Test accuracy: 49.96
Round  28, Global train loss: 1.957, Global test loss: 1.990, Global test accuracy: 44.92
Round  29, Train loss: 1.977, Test loss: 1.967, Test accuracy: 50.66
Round  29, Global train loss: 1.977, Global test loss: 2.074, Global test accuracy: 37.60
Round  30, Train loss: 1.983, Test loss: 1.965, Test accuracy: 50.72
Round  30, Global train loss: 1.983, Global test loss: 2.029, Global test accuracy: 41.92
Round  31, Train loss: 2.015, Test loss: 1.963, Test accuracy: 51.18
Round  31, Global train loss: 2.015, Global test loss: 2.028, Global test accuracy: 42.02
Round  32, Train loss: 1.803, Test loss: 1.959, Test accuracy: 51.26
Round  32, Global train loss: 1.803, Global test loss: 1.963, Global test accuracy: 47.16
Round  33, Train loss: 1.968, Test loss: 1.954, Test accuracy: 51.38
Round  33, Global train loss: 1.968, Global test loss: 2.077, Global test accuracy: 35.06
Round  34, Train loss: 1.967, Test loss: 1.953, Test accuracy: 51.34
Round  34, Global train loss: 1.967, Global test loss: 2.008, Global test accuracy: 43.54
Round  35, Train loss: 1.855, Test loss: 1.953, Test accuracy: 51.12
Round  35, Global train loss: 1.855, Global test loss: 1.910, Global test accuracy: 56.12
Round  36, Train loss: 1.944, Test loss: 1.951, Test accuracy: 51.36
Round  36, Global train loss: 1.944, Global test loss: 2.068, Global test accuracy: 35.72
Round  37, Train loss: 1.890, Test loss: 1.945, Test accuracy: 52.48
Round  37, Global train loss: 1.890, Global test loss: 1.912, Global test accuracy: 57.18
Round  38, Train loss: 1.871, Test loss: 1.943, Test accuracy: 52.46
Round  38, Global train loss: 1.871, Global test loss: 1.909, Global test accuracy: 56.36
Round  39, Train loss: 1.953, Test loss: 1.942, Test accuracy: 52.44
Round  39, Global train loss: 1.953, Global test loss: 2.023, Global test accuracy: 42.56
Round  40, Train loss: 1.760, Test loss: 1.942, Test accuracy: 52.26
Round  40, Global train loss: 1.760, Global test loss: 1.835, Global test accuracy: 63.28
Round  41, Train loss: 1.791, Test loss: 1.938, Test accuracy: 52.80
Round  41, Global train loss: 1.791, Global test loss: 1.865, Global test accuracy: 60.40
Round  42, Train loss: 1.873, Test loss: 1.936, Test accuracy: 52.94
Round  42, Global train loss: 1.873, Global test loss: 1.971, Global test accuracy: 50.16
Round  43, Train loss: 1.858, Test loss: 1.936, Test accuracy: 52.92
Round  43, Global train loss: 1.858, Global test loss: 1.967, Global test accuracy: 49.98
Round  44, Train loss: 1.854, Test loss: 1.935, Test accuracy: 52.96
Round  44, Global train loss: 1.854, Global test loss: 1.955, Global test accuracy: 49.94
Round  45, Train loss: 1.948, Test loss: 1.932, Test accuracy: 53.50
Round  45, Global train loss: 1.948, Global test loss: 2.032, Global test accuracy: 41.64
Round  46, Train loss: 1.861, Test loss: 1.930, Test accuracy: 53.46
Round  46, Global train loss: 1.861, Global test loss: 1.913, Global test accuracy: 54.18
Round  47, Train loss: 1.845, Test loss: 1.925, Test accuracy: 54.26
Round  47, Global train loss: 1.845, Global test loss: 1.892, Global test accuracy: 56.28
Round  48, Train loss: 1.752, Test loss: 1.926, Test accuracy: 53.96
Round  48, Global train loss: 1.752, Global test loss: 1.893, Global test accuracy: 56.84
Round  49, Train loss: 1.869, Test loss: 1.927, Test accuracy: 53.78
Round  49, Global train loss: 1.869, Global test loss: 1.936, Global test accuracy: 53.36
Round  50, Train loss: 1.928, Test loss: 1.926, Test accuracy: 53.76
Round  50, Global train loss: 1.928, Global test loss: 1.998, Global test accuracy: 45.98
Round  51, Train loss: 1.835, Test loss: 1.928, Test accuracy: 53.62
Round  51, Global train loss: 1.835, Global test loss: 2.015, Global test accuracy: 43.10
Round  52, Train loss: 1.881, Test loss: 1.927, Test accuracy: 53.62
Round  52, Global train loss: 1.881, Global test loss: 2.020, Global test accuracy: 42.26
Round  53, Train loss: 1.841, Test loss: 1.928, Test accuracy: 53.50
Round  53, Global train loss: 1.841, Global test loss: 1.968, Global test accuracy: 49.40
Round  54, Train loss: 1.849, Test loss: 1.927, Test accuracy: 53.54
Round  54, Global train loss: 1.849, Global test loss: 1.983, Global test accuracy: 47.96
Round  55, Train loss: 1.828, Test loss: 1.926, Test accuracy: 53.52
Round  55, Global train loss: 1.828, Global test loss: 1.971, Global test accuracy: 48.72
Round  56, Train loss: 1.773, Test loss: 1.925, Test accuracy: 53.46
Round  56, Global train loss: 1.773, Global test loss: 1.902, Global test accuracy: 55.76
Round  57, Train loss: 1.872, Test loss: 1.927, Test accuracy: 53.12
Round  57, Global train loss: 1.872, Global test loss: 2.017, Global test accuracy: 42.88
Round  58, Train loss: 1.871, Test loss: 1.926, Test accuracy: 53.08
Round  58, Global train loss: 1.871, Global test loss: 1.996, Global test accuracy: 45.22
Round  59, Train loss: 1.802, Test loss: 1.926, Test accuracy: 53.30
Round  59, Global train loss: 1.802, Global test loss: 1.976, Global test accuracy: 47.34
Round  60, Train loss: 1.817, Test loss: 1.925, Test accuracy: 53.28
Round  60, Global train loss: 1.817, Global test loss: 1.952, Global test accuracy: 51.52
Round  61, Train loss: 1.899, Test loss: 1.924, Test accuracy: 53.38
Round  61, Global train loss: 1.899, Global test loss: 2.045, Global test accuracy: 40.58
Round  62, Train loss: 1.852, Test loss: 1.924, Test accuracy: 53.50
Round  62, Global train loss: 1.852, Global test loss: 2.016, Global test accuracy: 42.78
Round  63, Train loss: 1.825, Test loss: 1.925, Test accuracy: 53.42
Round  63, Global train loss: 1.825, Global test loss: 1.976, Global test accuracy: 47.48
Round  64, Train loss: 1.784, Test loss: 1.925, Test accuracy: 53.48
Round  64, Global train loss: 1.784, Global test loss: 1.978, Global test accuracy: 47.36
Round  65, Train loss: 1.861, Test loss: 1.926, Test accuracy: 53.32
Round  65, Global train loss: 1.861, Global test loss: 2.032, Global test accuracy: 41.30
Round  66, Train loss: 1.777, Test loss: 1.925, Test accuracy: 53.46
Round  66, Global train loss: 1.777, Global test loss: 1.966, Global test accuracy: 48.46
Round  67, Train loss: 1.866, Test loss: 1.925, Test accuracy: 53.64
Round  67, Global train loss: 1.866, Global test loss: 2.015, Global test accuracy: 44.16
Round  68, Train loss: 1.829, Test loss: 1.925, Test accuracy: 53.58
Round  68, Global train loss: 1.829, Global test loss: 2.035, Global test accuracy: 41.62
Round  69, Train loss: 1.817, Test loss: 1.925, Test accuracy: 53.54
Round  69, Global train loss: 1.817, Global test loss: 1.975, Global test accuracy: 47.62
Round  70, Train loss: 1.787, Test loss: 1.926, Test accuracy: 53.22
Round  70, Global train loss: 1.787, Global test loss: 1.943, Global test accuracy: 51.20
Round  71, Train loss: 1.763, Test loss: 1.927, Test accuracy: 53.14
Round  71, Global train loss: 1.763, Global test loss: 1.892, Global test accuracy: 57.26
Round  72, Train loss: 1.808, Test loss: 1.929, Test accuracy: 52.84
Round  72, Global train loss: 1.808, Global test loss: 1.973, Global test accuracy: 48.60
Round  73, Train loss: 1.773, Test loss: 1.929, Test accuracy: 53.02
Round  73, Global train loss: 1.773, Global test loss: 1.887, Global test accuracy: 57.36
Round  74, Train loss: 1.860, Test loss: 1.928, Test accuracy: 53.16
Round  74, Global train loss: 1.860, Global test loss: 2.027, Global test accuracy: 42.16
Round  75, Train loss: 1.860, Test loss: 1.930, Test accuracy: 52.98
Round  75, Global train loss: 1.860, Global test loss: 2.019, Global test accuracy: 43.00
Round  76, Train loss: 1.802, Test loss: 1.930, Test accuracy: 53.00
Round  76, Global train loss: 1.802, Global test loss: 1.872, Global test accuracy: 59.10
Round  77, Train loss: 1.803, Test loss: 1.931, Test accuracy: 52.88
Round  77, Global train loss: 1.803, Global test loss: 1.952, Global test accuracy: 50.34
Round  78, Train loss: 1.767, Test loss: 1.931, Test accuracy: 52.82
Round  78, Global train loss: 1.767, Global test loss: 1.968, Global test accuracy: 48.46
Round  79, Train loss: 1.782, Test loss: 1.931, Test accuracy: 52.74
Round  79, Global train loss: 1.782, Global test loss: 2.002, Global test accuracy: 44.50
Round  80, Train loss: 1.837, Test loss: 1.931, Test accuracy: 52.86
Round  80, Global train loss: 1.837, Global test loss: 1.983, Global test accuracy: 47.42
Round  81, Train loss: 1.863, Test loss: 1.929, Test accuracy: 53.00
Round  81, Global train loss: 1.863, Global test loss: 2.034, Global test accuracy: 41.40
Round  82, Train loss: 1.787, Test loss: 1.929, Test accuracy: 52.98
Round  82, Global train loss: 1.787, Global test loss: 1.927, Global test accuracy: 53.22
Round  83, Train loss: 1.853, Test loss: 1.929, Test accuracy: 53.02
Round  83, Global train loss: 1.853, Global test loss: 2.048, Global test accuracy: 40.58
Round  84, Train loss: 1.736, Test loss: 1.929, Test accuracy: 53.06
Round  84, Global train loss: 1.736, Global test loss: 1.950, Global test accuracy: 49.44
Round  85, Train loss: 1.797, Test loss: 1.930, Test accuracy: 52.96
Round  85, Global train loss: 1.797, Global test loss: 1.970, Global test accuracy: 48.70
Round  86, Train loss: 1.782, Test loss: 1.930, Test accuracy: 53.08
Round  86, Global train loss: 1.782, Global test loss: 1.949, Global test accuracy: 50.86
Round  87, Train loss: 1.765, Test loss: 1.930, Test accuracy: 53.04
Round  87, Global train loss: 1.765, Global test loss: 1.930, Global test accuracy: 52.34
Round  88, Train loss: 1.784, Test loss: 1.931, Test accuracy: 52.86
Round  88, Global train loss: 1.784, Global test loss: 1.990, Global test accuracy: 46.10
Round  89, Train loss: 1.734, Test loss: 1.932, Test accuracy: 52.90
Round  89, Global train loss: 1.734, Global test loss: 1.944, Global test accuracy: 49.94
Round  90, Train loss: 1.706, Test loss: 1.931, Test accuracy: 53.02
Round  90, Global train loss: 1.706, Global test loss: 1.815, Global test accuracy: 64.30
Round  91, Train loss: 1.758, Test loss: 1.931, Test accuracy: 52.98
Round  91, Global train loss: 1.758, Global test loss: 1.963, Global test accuracy: 49.16
Round  92, Train loss: 1.838, Test loss: 1.931, Test accuracy: 52.94
Round  92, Global train loss: 1.838, Global test loss: 1.995, Global test accuracy: 46.14
Round  93, Train loss: 1.805, Test loss: 1.931, Test accuracy: 52.78
Round  93, Global train loss: 1.805, Global test loss: 1.984, Global test accuracy: 46.34
Round  94, Train loss: 1.700, Test loss: 1.931, Test accuracy: 52.78
Round  94, Global train loss: 1.700, Global test loss: 1.812, Global test accuracy: 64.48/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  95, Train loss: 1.740, Test loss: 1.928, Test accuracy: 53.14
Round  95, Global train loss: 1.740, Global test loss: 1.809, Global test accuracy: 66.08
Round  96, Train loss: 1.776, Test loss: 1.925, Test accuracy: 53.60
Round  96, Global train loss: 1.776, Global test loss: 1.856, Global test accuracy: 61.06
Round  97, Train loss: 1.781, Test loss: 1.925, Test accuracy: 53.56
Round  97, Global train loss: 1.781, Global test loss: 2.024, Global test accuracy: 42.22
Round  98, Train loss: 1.771, Test loss: 1.926, Test accuracy: 53.62
Round  98, Global train loss: 1.771, Global test loss: 1.976, Global test accuracy: 47.56
Round  99, Train loss: 1.729, Test loss: 1.926, Test accuracy: 53.56
Round  99, Global train loss: 1.729, Global test loss: 1.812, Global test accuracy: 64.40
Final Round, Train loss: 1.776, Test loss: 1.920, Test accuracy: 54.08
Final Round, Global train loss: 1.776, Global test loss: 1.812, Global test accuracy: 64.40
Average accuracy final 10 rounds: 53.19800000000001 

Average global accuracy final 10 rounds: 55.174 

712.5056505203247
[1.0469543933868408, 2.0939087867736816, 3.0259337425231934, 3.957958698272705, 4.9625959396362305, 5.967233180999756, 6.903831720352173, 7.84043025970459, 8.756221055984497, 9.672011852264404, 10.588820457458496, 11.505629062652588, 12.41244387626648, 13.319258689880371, 14.227490186691284, 15.135721683502197, 16.002150535583496, 16.868579387664795, 17.720436573028564, 18.572293758392334, 19.462540864944458, 20.352787971496582, 21.232186555862427, 22.11158514022827, 22.985002279281616, 23.85841941833496, 24.74140763282776, 25.624395847320557, 26.523112058639526, 27.421828269958496, 28.314470291137695, 29.207112312316895, 30.061099767684937, 30.91508722305298, 31.79836654663086, 32.68164587020874, 33.58006405830383, 34.478482246398926, 35.36998796463013, 36.26149368286133, 37.185007095336914, 38.1085205078125, 39.04332995414734, 39.97813940048218, 40.92408323287964, 41.8700270652771, 42.74083137512207, 43.61163568496704, 44.52753400802612, 45.443432331085205, 46.36544871330261, 47.28746509552002, 48.1443305015564, 49.00119590759277, 49.92240357398987, 50.84361124038696, 51.731982946395874, 52.620354652404785, 53.54116201400757, 54.46196937561035, 55.444042444229126, 56.4261155128479, 57.34321308135986, 58.260310649871826, 59.14920997619629, 60.03810930252075, 60.8968071937561, 61.755505084991455, 62.64557075500488, 63.53563642501831, 64.46687364578247, 65.39811086654663, 66.34146976470947, 67.28482866287231, 68.20905232429504, 69.13327598571777, 70.01604652404785, 70.89881706237793, 71.79393911361694, 72.68906116485596, 73.60070061683655, 74.51234006881714, 75.42605233192444, 76.33976459503174, 77.23348617553711, 78.12720775604248, 79.04641151428223, 79.96561527252197, 80.85725235939026, 81.74888944625854, 82.6556122303009, 83.56233501434326, 84.54461288452148, 85.5268907546997, 86.44323801994324, 87.35958528518677, 88.86665964126587, 90.37373399734497, 91.2249870300293, 92.07624006271362, 93.00377345085144, 93.93130683898926, 94.81652736663818, 95.70174789428711, 96.58590984344482, 97.47007179260254, 98.39911651611328, 99.32816123962402, 100.24173927307129, 101.15531730651855, 102.05278515815735, 102.95025300979614, 103.79468131065369, 104.63910961151123, 105.63161635398865, 106.62412309646606, 107.52778148651123, 108.4314398765564, 109.30041980743408, 110.16939973831177, 111.04032945632935, 111.91125917434692, 112.81633448600769, 113.72140979766846, 114.62418055534363, 115.5269513130188, 116.40407085418701, 117.28119039535522, 118.16443276405334, 119.04767513275146, 119.94836115837097, 120.84904718399048, 121.8023476600647, 122.75564813613892, 123.69006299972534, 124.62447786331177, 125.5769293308258, 126.52938079833984, 127.40683102607727, 128.2842812538147, 129.15336155891418, 130.02244186401367, 130.88816905021667, 131.75389623641968, 132.62296605110168, 133.4920358657837, 134.37657475471497, 135.26111364364624, 136.16014099121094, 137.05916833877563, 138.00624704360962, 138.9533257484436, 139.91559743881226, 140.8778691291809, 141.77375674247742, 142.66964435577393, 143.57341599464417, 144.4771876335144, 145.38001799583435, 146.2828483581543, 147.23938488960266, 148.19592142105103, 149.08926391601562, 149.98260641098022, 150.91120600700378, 151.83980560302734, 152.77145099639893, 153.7030963897705, 154.64376521110535, 155.58443403244019, 156.4994559288025, 157.4144778251648, 158.3218252658844, 159.229172706604, 160.11764550209045, 161.0061182975769, 161.86030840873718, 162.71449851989746, 163.61198782920837, 164.5094771385193, 165.42538142204285, 166.3412857055664, 167.26305079460144, 168.18481588363647, 169.08053612709045, 169.97625637054443, 170.8697760105133, 171.76329565048218, 172.6757845878601, 173.58827352523804, 174.4674220085144, 175.34657049179077, 176.25807690620422, 177.16958332061768, 178.05428194999695, 178.93898057937622, 179.85115337371826, 180.7633261680603, 181.6261110305786, 182.48889589309692, 184.2926378250122, 186.0963797569275]
[12.5, 12.5, 15.34, 15.34, 18.24, 18.24, 19.36, 19.36, 19.74, 19.74, 21.36, 21.36, 20.24, 20.24, 20.4, 20.4, 22.32, 22.32, 23.42, 23.42, 24.54, 24.54, 26.44, 26.44, 29.46, 29.46, 32.6, 32.6, 34.92, 34.92, 36.38, 36.38, 38.02, 38.02, 39.24, 39.24, 41.86, 41.86, 44.2, 44.2, 44.34, 44.34, 46.08, 46.08, 46.86, 46.86, 47.58, 47.58, 48.32, 48.32, 48.88, 48.88, 49.48, 49.48, 49.7, 49.7, 49.96, 49.96, 50.66, 50.66, 50.72, 50.72, 51.18, 51.18, 51.26, 51.26, 51.38, 51.38, 51.34, 51.34, 51.12, 51.12, 51.36, 51.36, 52.48, 52.48, 52.46, 52.46, 52.44, 52.44, 52.26, 52.26, 52.8, 52.8, 52.94, 52.94, 52.92, 52.92, 52.96, 52.96, 53.5, 53.5, 53.46, 53.46, 54.26, 54.26, 53.96, 53.96, 53.78, 53.78, 53.76, 53.76, 53.62, 53.62, 53.62, 53.62, 53.5, 53.5, 53.54, 53.54, 53.52, 53.52, 53.46, 53.46, 53.12, 53.12, 53.08, 53.08, 53.3, 53.3, 53.28, 53.28, 53.38, 53.38, 53.5, 53.5, 53.42, 53.42, 53.48, 53.48, 53.32, 53.32, 53.46, 53.46, 53.64, 53.64, 53.58, 53.58, 53.54, 53.54, 53.22, 53.22, 53.14, 53.14, 52.84, 52.84, 53.02, 53.02, 53.16, 53.16, 52.98, 52.98, 53.0, 53.0, 52.88, 52.88, 52.82, 52.82, 52.74, 52.74, 52.86, 52.86, 53.0, 53.0, 52.98, 52.98, 53.02, 53.02, 53.06, 53.06, 52.96, 52.96, 53.08, 53.08, 53.04, 53.04, 52.86, 52.86, 52.9, 52.9, 53.02, 53.02, 52.98, 52.98, 52.94, 52.94, 52.78, 52.78, 52.78, 52.78, 53.14, 53.14, 53.6, 53.6, 53.56, 53.56, 53.62, 53.62, 53.56, 53.56, 54.08, 54.08]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.6 , level_n_lowerb:0.4  

   Client 6, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.302, Test loss: 2.301, Test accuracy: 11.26
Round   0, Global train loss: 2.302, Global test loss: 2.301, Global test accuracy: 11.38
Round   1, Train loss: 2.300, Test loss: 2.299, Test accuracy: 13.68
Round   1, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 14.22
Round   2, Train loss: 2.296, Test loss: 2.296, Test accuracy: 17.98
Round   2, Global train loss: 2.296, Global test loss: 2.294, Global test accuracy: 21.04
Round   3, Train loss: 2.277, Test loss: 2.274, Test accuracy: 11.90
Round   3, Global train loss: 2.277, Global test loss: 2.264, Global test accuracy: 10.12
Round   4, Train loss: 2.266, Test loss: 2.261, Test accuracy: 12.10
Round   4, Global train loss: 2.266, Global test loss: 2.250, Global test accuracy: 10.12
Round   5, Train loss: 2.256, Test loss: 2.243, Test accuracy: 20.48
Round   5, Global train loss: 2.256, Global test loss: 2.223, Global test accuracy: 26.50
Round   6, Train loss: 2.214, Test loss: 2.205, Test accuracy: 25.94
Round   6, Global train loss: 2.214, Global test loss: 2.160, Global test accuracy: 32.04
Round   7, Train loss: 2.191, Test loss: 2.169, Test accuracy: 31.98
Round   7, Global train loss: 2.191, Global test loss: 2.095, Global test accuracy: 46.76
Round   8, Train loss: 2.119, Test loss: 2.103, Test accuracy: 40.30
Round   8, Global train loss: 2.119, Global test loss: 2.009, Global test accuracy: 49.18
Round   9, Train loss: 2.107, Test loss: 2.014, Test accuracy: 49.38
Round   9, Global train loss: 2.107, Global test loss: 1.937, Global test accuracy: 57.24
Round  10, Train loss: 2.001, Test loss: 1.982, Test accuracy: 51.42
Round  10, Global train loss: 2.001, Global test loss: 1.899, Global test accuracy: 58.06
Round  11, Train loss: 2.067, Test loss: 1.941, Test accuracy: 55.08
Round  11, Global train loss: 2.067, Global test loss: 1.893, Global test accuracy: 57.70
Round  12, Train loss: 1.977, Test loss: 1.933, Test accuracy: 55.24
Round  12, Global train loss: 1.977, Global test loss: 1.879, Global test accuracy: 58.40
Round  13, Train loss: 2.047, Test loss: 1.914, Test accuracy: 56.36
Round  13, Global train loss: 2.047, Global test loss: 1.882, Global test accuracy: 58.20
Round  14, Train loss: 1.987, Test loss: 1.897, Test accuracy: 57.72
Round  14, Global train loss: 1.987, Global test loss: 1.863, Global test accuracy: 59.72
Round  15, Train loss: 1.919, Test loss: 1.882, Test accuracy: 59.30
Round  15, Global train loss: 1.919, Global test loss: 1.827, Global test accuracy: 64.80
Round  16, Train loss: 1.946, Test loss: 1.872, Test accuracy: 60.10
Round  16, Global train loss: 1.946, Global test loss: 1.818, Global test accuracy: 65.28
Round  17, Train loss: 1.939, Test loss: 1.865, Test accuracy: 60.92
Round  17, Global train loss: 1.939, Global test loss: 1.800, Global test accuracy: 66.96
Round  18, Train loss: 2.060, Test loss: 1.827, Test accuracy: 64.74
Round  18, Global train loss: 2.060, Global test loss: 1.781, Global test accuracy: 70.12
Round  19, Train loss: 1.971, Test loss: 1.825, Test accuracy: 64.90
Round  19, Global train loss: 1.971, Global test loss: 1.772, Global test accuracy: 70.64
Round  20, Train loss: 2.007, Test loss: 1.806, Test accuracy: 66.86
Round  20, Global train loss: 2.007, Global test loss: 1.763, Global test accuracy: 71.68
Round  21, Train loss: 1.893, Test loss: 1.806, Test accuracy: 66.96
Round  21, Global train loss: 1.893, Global test loss: 1.750, Global test accuracy: 72.06
Round  22, Train loss: 1.961, Test loss: 1.798, Test accuracy: 67.60
Round  22, Global train loss: 1.961, Global test loss: 1.752, Global test accuracy: 71.68
Round  23, Train loss: 1.941, Test loss: 1.784, Test accuracy: 68.98
Round  23, Global train loss: 1.941, Global test loss: 1.743, Global test accuracy: 73.12
Round  24, Train loss: 1.836, Test loss: 1.775, Test accuracy: 69.82
Round  24, Global train loss: 1.836, Global test loss: 1.737, Global test accuracy: 73.24
Round  25, Train loss: 1.779, Test loss: 1.773, Test accuracy: 69.84
Round  25, Global train loss: 1.779, Global test loss: 1.733, Global test accuracy: 73.24
Round  26, Train loss: 2.014, Test loss: 1.768, Test accuracy: 70.22
Round  26, Global train loss: 2.014, Global test loss: 1.738, Global test accuracy: 73.34
Round  27, Train loss: 1.843, Test loss: 1.748, Test accuracy: 72.12
Round  27, Global train loss: 1.843, Global test loss: 1.728, Global test accuracy: 73.86
Round  28, Train loss: 1.841, Test loss: 1.747, Test accuracy: 72.16
Round  28, Global train loss: 1.841, Global test loss: 1.730, Global test accuracy: 73.44
Round  29, Train loss: 1.861, Test loss: 1.747, Test accuracy: 72.26
Round  29, Global train loss: 1.861, Global test loss: 1.733, Global test accuracy: 73.52
Round  30, Train loss: 1.931, Test loss: 1.743, Test accuracy: 72.50
Round  30, Global train loss: 1.931, Global test loss: 1.729, Global test accuracy: 73.96
Round  31, Train loss: 1.956, Test loss: 1.746, Test accuracy: 72.22
Round  31, Global train loss: 1.956, Global test loss: 1.731, Global test accuracy: 73.62
Round  32, Train loss: 1.817, Test loss: 1.744, Test accuracy: 72.32
Round  32, Global train loss: 1.817, Global test loss: 1.732, Global test accuracy: 73.78
Round  33, Train loss: 1.934, Test loss: 1.744, Test accuracy: 72.34
Round  33, Global train loss: 1.934, Global test loss: 1.736, Global test accuracy: 73.00
Round  34, Train loss: 1.926, Test loss: 1.743, Test accuracy: 72.38
Round  34, Global train loss: 1.926, Global test loss: 1.727, Global test accuracy: 73.74
Round  35, Train loss: 1.884, Test loss: 1.741, Test accuracy: 72.60
Round  35, Global train loss: 1.884, Global test loss: 1.727, Global test accuracy: 73.70
Round  36, Train loss: 1.929, Test loss: 1.740, Test accuracy: 72.68
Round  36, Global train loss: 1.929, Global test loss: 1.736, Global test accuracy: 73.16
Round  37, Train loss: 1.920, Test loss: 1.741, Test accuracy: 72.72
Round  37, Global train loss: 1.920, Global test loss: 1.735, Global test accuracy: 73.04
Round  38, Train loss: 1.912, Test loss: 1.741, Test accuracy: 72.66
Round  38, Global train loss: 1.912, Global test loss: 1.737, Global test accuracy: 72.70
Round  39, Train loss: 1.882, Test loss: 1.741, Test accuracy: 72.66
Round  39, Global train loss: 1.882, Global test loss: 1.730, Global test accuracy: 73.76
Round  40, Train loss: 1.864, Test loss: 1.741, Test accuracy: 72.80
Round  40, Global train loss: 1.864, Global test loss: 1.729, Global test accuracy: 73.84
Round  41, Train loss: 1.834, Test loss: 1.740, Test accuracy: 72.84
Round  41, Global train loss: 1.834, Global test loss: 1.727, Global test accuracy: 74.16
Round  42, Train loss: 1.881, Test loss: 1.742, Test accuracy: 72.46
Round  42, Global train loss: 1.881, Global test loss: 1.737, Global test accuracy: 72.74
Round  43, Train loss: 1.872, Test loss: 1.740, Test accuracy: 72.64
Round  43, Global train loss: 1.872, Global test loss: 1.734, Global test accuracy: 72.98
Round  44, Train loss: 1.875, Test loss: 1.739, Test accuracy: 72.76
Round  44, Global train loss: 1.875, Global test loss: 1.731, Global test accuracy: 73.36
Round  45, Train loss: 1.879, Test loss: 1.740, Test accuracy: 72.60
Round  45, Global train loss: 1.879, Global test loss: 1.734, Global test accuracy: 73.14
Round  46, Train loss: 1.840, Test loss: 1.739, Test accuracy: 72.68
Round  46, Global train loss: 1.840, Global test loss: 1.725, Global test accuracy: 73.86
Round  47, Train loss: 1.837, Test loss: 1.738, Test accuracy: 72.70
Round  47, Global train loss: 1.837, Global test loss: 1.724, Global test accuracy: 73.86
Round  48, Train loss: 1.860, Test loss: 1.737, Test accuracy: 72.92
Round  48, Global train loss: 1.860, Global test loss: 1.730, Global test accuracy: 73.18
Round  49, Train loss: 1.832, Test loss: 1.739, Test accuracy: 72.76
Round  49, Global train loss: 1.832, Global test loss: 1.729, Global test accuracy: 73.72
Round  50, Train loss: 1.928, Test loss: 1.738, Test accuracy: 72.72
Round  50, Global train loss: 1.928, Global test loss: 1.729, Global test accuracy: 73.06
Round  51, Train loss: 1.947, Test loss: 1.739, Test accuracy: 72.64
Round  51, Global train loss: 1.947, Global test loss: 1.739, Global test accuracy: 72.70
Round  52, Train loss: 1.869, Test loss: 1.741, Test accuracy: 72.44
Round  52, Global train loss: 1.869, Global test loss: 1.734, Global test accuracy: 72.78
Round  53, Train loss: 1.854, Test loss: 1.740, Test accuracy: 72.36
Round  53, Global train loss: 1.854, Global test loss: 1.728, Global test accuracy: 73.22
Round  54, Train loss: 1.889, Test loss: 1.740, Test accuracy: 72.26
Round  54, Global train loss: 1.889, Global test loss: 1.733, Global test accuracy: 72.64
Round  55, Train loss: 1.801, Test loss: 1.741, Test accuracy: 72.24
Round  55, Global train loss: 1.801, Global test loss: 1.726, Global test accuracy: 73.66
Round  56, Train loss: 1.893, Test loss: 1.741, Test accuracy: 72.22
Round  56, Global train loss: 1.893, Global test loss: 1.736, Global test accuracy: 72.32
Round  57, Train loss: 1.849, Test loss: 1.742, Test accuracy: 72.08
Round  57, Global train loss: 1.849, Global test loss: 1.731, Global test accuracy: 72.88
Round  58, Train loss: 1.881, Test loss: 1.741, Test accuracy: 72.16
Round  58, Global train loss: 1.881, Global test loss: 1.731, Global test accuracy: 73.14
Round  59, Train loss: 1.938, Test loss: 1.741, Test accuracy: 72.16
Round  59, Global train loss: 1.938, Global test loss: 1.739, Global test accuracy: 72.12
Round  60, Train loss: 1.864, Test loss: 1.742, Test accuracy: 72.08
Round  60, Global train loss: 1.864, Global test loss: 1.734, Global test accuracy: 72.88
Round  61, Train loss: 1.879, Test loss: 1.742, Test accuracy: 72.08
Round  61, Global train loss: 1.879, Global test loss: 1.734, Global test accuracy: 72.68
Round  62, Train loss: 1.861, Test loss: 1.742, Test accuracy: 72.14
Round  62, Global train loss: 1.861, Global test loss: 1.734, Global test accuracy: 72.46
Round  63, Train loss: 1.847, Test loss: 1.744, Test accuracy: 71.98
Round  63, Global train loss: 1.847, Global test loss: 1.735, Global test accuracy: 72.56
Round  64, Train loss: 1.933, Test loss: 1.745, Test accuracy: 71.76
Round  64, Global train loss: 1.933, Global test loss: 1.743, Global test accuracy: 71.92
Round  65, Train loss: 1.861, Test loss: 1.744, Test accuracy: 71.70
Round  65, Global train loss: 1.861, Global test loss: 1.738, Global test accuracy: 72.14
Round  66, Train loss: 1.827, Test loss: 1.744, Test accuracy: 71.76
Round  66, Global train loss: 1.827, Global test loss: 1.735, Global test accuracy: 72.42
Round  67, Train loss: 1.877, Test loss: 1.743, Test accuracy: 71.78
Round  67, Global train loss: 1.877, Global test loss: 1.738, Global test accuracy: 72.16
Round  68, Train loss: 1.785, Test loss: 1.743, Test accuracy: 71.86
Round  68, Global train loss: 1.785, Global test loss: 1.733, Global test accuracy: 72.78
Round  69, Train loss: 1.840, Test loss: 1.744, Test accuracy: 71.68
Round  69, Global train loss: 1.840, Global test loss: 1.737, Global test accuracy: 72.12
Round  70, Train loss: 1.830, Test loss: 1.745, Test accuracy: 71.66
Round  70, Global train loss: 1.830, Global test loss: 1.733, Global test accuracy: 72.76
Round  71, Train loss: 1.875, Test loss: 1.744, Test accuracy: 71.70
Round  71, Global train loss: 1.875, Global test loss: 1.736, Global test accuracy: 72.54
Round  72, Train loss: 1.879, Test loss: 1.745, Test accuracy: 71.54
Round  72, Global train loss: 1.879, Global test loss: 1.740, Global test accuracy: 72.02
Round  73, Train loss: 1.903, Test loss: 1.745, Test accuracy: 71.54
Round  73, Global train loss: 1.903, Global test loss: 1.739, Global test accuracy: 72.14
Round  74, Train loss: 1.855, Test loss: 1.744, Test accuracy: 71.72
Round  74, Global train loss: 1.855, Global test loss: 1.737, Global test accuracy: 72.20
Round  75, Train loss: 1.866, Test loss: 1.743, Test accuracy: 71.82
Round  75, Global train loss: 1.866, Global test loss: 1.739, Global test accuracy: 72.04
Round  76, Train loss: 1.800, Test loss: 1.742, Test accuracy: 71.88
Round  76, Global train loss: 1.800, Global test loss: 1.733, Global test accuracy: 72.52
Round  77, Train loss: 1.852, Test loss: 1.742, Test accuracy: 71.94
Round  77, Global train loss: 1.852, Global test loss: 1.736, Global test accuracy: 72.32
Round  78, Train loss: 1.877, Test loss: 1.742, Test accuracy: 72.06
Round  78, Global train loss: 1.877, Global test loss: 1.737, Global test accuracy: 72.08
Round  79, Train loss: 1.818, Test loss: 1.742, Test accuracy: 72.10
Round  79, Global train loss: 1.818, Global test loss: 1.733, Global test accuracy: 72.64
Round  80, Train loss: 1.904, Test loss: 1.742, Test accuracy: 72.06
Round  80, Global train loss: 1.904, Global test loss: 1.744, Global test accuracy: 71.68
Round  81, Train loss: 1.883, Test loss: 1.742, Test accuracy: 72.04
Round  81, Global train loss: 1.883, Global test loss: 1.741, Global test accuracy: 72.04
Round  82, Train loss: 1.841, Test loss: 1.743, Test accuracy: 71.90
Round  82, Global train loss: 1.841, Global test loss: 1.739, Global test accuracy: 72.10
Round  83, Train loss: 1.905, Test loss: 1.743, Test accuracy: 72.00
Round  83, Global train loss: 1.905, Global test loss: 1.743, Global test accuracy: 71.64
Round  84, Train loss: 1.738, Test loss: 1.743, Test accuracy: 71.90
Round  84, Global train loss: 1.738, Global test loss: 1.732, Global test accuracy: 72.86
Round  85, Train loss: 1.873, Test loss: 1.743, Test accuracy: 71.90
Round  85, Global train loss: 1.873, Global test loss: 1.739, Global test accuracy: 71.88
Round  86, Train loss: 1.900, Test loss: 1.744, Test accuracy: 71.74
Round  86, Global train loss: 1.900, Global test loss: 1.743, Global test accuracy: 71.68
Round  87, Train loss: 1.824, Test loss: 1.744, Test accuracy: 71.76
Round  87, Global train loss: 1.824, Global test loss: 1.735, Global test accuracy: 72.60
Round  88, Train loss: 1.799, Test loss: 1.744, Test accuracy: 71.84
Round  88, Global train loss: 1.799, Global test loss: 1.735, Global test accuracy: 72.76
Round  89, Train loss: 1.736, Test loss: 1.744, Test accuracy: 71.80
Round  89, Global train loss: 1.736, Global test loss: 1.732, Global test accuracy: 72.98
Round  90, Train loss: 1.817, Test loss: 1.744, Test accuracy: 71.88
Round  90, Global train loss: 1.817, Global test loss: 1.735, Global test accuracy: 72.46
Round  91, Train loss: 1.920, Test loss: 1.743, Test accuracy: 71.98
Round  91, Global train loss: 1.920, Global test loss: 1.743, Global test accuracy: 72.00
Round  92, Train loss: 1.904, Test loss: 1.743, Test accuracy: 71.98
Round  92, Global train loss: 1.904, Global test loss: 1.742, Global test accuracy: 72.32
Round  93, Train loss: 1.794, Test loss: 1.745, Test accuracy: 71.80
Round  93, Global train loss: 1.794, Global test loss: 1.736, Global test accuracy: 72.28
Round  94, Train loss: 1.786, Test loss: 1.745, Test accuracy: 71.76
Round  94, Global train loss: 1.786, Global test loss: 1.733, Global test accuracy: 72.82/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  95, Train loss: 1.797, Test loss: 1.745, Test accuracy: 71.72
Round  95, Global train loss: 1.797, Global test loss: 1.735, Global test accuracy: 72.90
Round  96, Train loss: 1.831, Test loss: 1.745, Test accuracy: 71.74
Round  96, Global train loss: 1.831, Global test loss: 1.738, Global test accuracy: 72.22
Round  97, Train loss: 1.821, Test loss: 1.745, Test accuracy: 71.78
Round  97, Global train loss: 1.821, Global test loss: 1.737, Global test accuracy: 72.40
Round  98, Train loss: 1.898, Test loss: 1.744, Test accuracy: 71.90
Round  98, Global train loss: 1.898, Global test loss: 1.742, Global test accuracy: 71.98
Round  99, Train loss: 1.810, Test loss: 1.744, Test accuracy: 71.82
Round  99, Global train loss: 1.810, Global test loss: 1.737, Global test accuracy: 72.36
Final Round, Train loss: 1.843, Test loss: 1.745, Test accuracy: 71.56
Final Round, Global train loss: 1.843, Global test loss: 1.737, Global test accuracy: 72.36
Average accuracy final 10 rounds: 71.836 

Average global accuracy final 10 rounds: 72.37400000000001 

716.7347679138184
[1.1008453369140625, 2.201690673828125, 3.082726001739502, 3.963761329650879, 4.82987642288208, 5.695991516113281, 6.626115083694458, 7.556238651275635, 8.446978569030762, 9.337718486785889, 10.263083219528198, 11.188447952270508, 12.079824209213257, 12.971200466156006, 13.821945905685425, 14.672691345214844, 15.591845750808716, 16.511000156402588, 17.41738533973694, 18.32377052307129, 19.224691152572632, 20.125611782073975, 21.01259708404541, 21.899582386016846, 22.834234714508057, 23.768887042999268, 24.66657066345215, 25.56425428390503, 26.468379974365234, 27.37250566482544, 28.307146787643433, 29.241787910461426, 30.097914457321167, 30.954041004180908, 31.83228635787964, 32.71053171157837, 33.611165046691895, 34.51179838180542, 35.363786458969116, 36.21577453613281, 37.067442893981934, 37.919111251831055, 38.83723425865173, 39.75535726547241, 40.70884037017822, 41.66232347488403, 42.62312173843384, 43.58392000198364, 44.50029635429382, 45.416672706604004, 46.35425329208374, 47.29183387756348, 48.179054260253906, 49.066274642944336, 49.90752291679382, 50.74877119064331, 51.71654224395752, 52.68431329727173, 53.58981204032898, 54.49531078338623, 55.32986640930176, 56.164422035217285, 57.118839263916016, 58.073256492614746, 58.97030997276306, 59.86736345291138, 60.729997873306274, 61.59263229370117, 62.49005842208862, 63.387484550476074, 64.27349710464478, 65.15950965881348, 66.07308459281921, 66.98665952682495, 67.88186717033386, 68.77707481384277, 69.62131857872009, 70.46556234359741, 71.32502150535583, 72.18448066711426, 73.12518334388733, 74.0658860206604, 74.9379198551178, 75.8099536895752, 76.68156409263611, 77.55317449569702, 78.39506602287292, 79.23695755004883, 80.1383969783783, 81.03983640670776, 81.94741249084473, 82.85498857498169, 83.75984048843384, 84.66469240188599, 85.56901860237122, 86.47334480285645, 87.38927674293518, 88.30520868301392, 89.1945161819458, 90.08382368087769, 90.99410367012024, 91.9043836593628, 93.24611711502075, 94.58785057067871, 95.55318784713745, 96.51852512359619, 97.47133612632751, 98.42414712905884, 99.30813980102539, 100.19213247299194, 101.10960102081299, 102.02706956863403, 102.92230939865112, 103.81754922866821, 104.73652148246765, 105.65549373626709, 106.57373118400574, 107.49196863174438, 108.41069793701172, 109.32942724227905, 110.22959113121033, 111.1297550201416, 112.0514075756073, 112.973060131073, 113.8615174293518, 114.74997472763062, 115.67560124397278, 116.60122776031494, 117.49492883682251, 118.38862991333008, 119.26299834251404, 120.137366771698, 121.02852630615234, 121.91968584060669, 122.8291563987732, 123.7386269569397, 124.63442993164062, 125.53023290634155, 126.47207832336426, 127.41392374038696, 128.3210906982422, 129.2282576560974, 130.0988256931305, 130.96939373016357, 131.8725242614746, 132.77565479278564, 133.73097348213196, 134.68629217147827, 135.6401023864746, 136.59391260147095, 137.51609778404236, 138.43828296661377, 139.41630482673645, 140.39432668685913, 141.3650164604187, 142.33570623397827, 143.28240752220154, 144.2291088104248, 145.2104287147522, 146.1917486190796, 147.10425901412964, 148.0167694091797, 149.0078902244568, 149.9990110397339, 151.04689979553223, 152.09478855133057, 153.0640811920166, 154.03337383270264, 155.04894137382507, 156.0645089149475, 157.0128059387207, 157.9611029624939, 158.92676663398743, 159.89243030548096, 160.78589010238647, 161.679349899292, 162.68120765686035, 163.6830654144287, 164.62046766281128, 165.55786991119385, 166.45519375801086, 167.35251760482788, 168.3371524810791, 169.32178735733032, 170.32071018218994, 171.31963300704956, 172.27888441085815, 173.23813581466675, 174.1669089794159, 175.09568214416504, 176.06183123588562, 177.0279803276062, 178.05539774894714, 179.0828151702881, 179.9912178516388, 180.8996205329895, 181.83120679855347, 182.76279306411743, 183.7112467288971, 184.65970039367676, 186.61457324028015, 188.56944608688354]
[11.26, 11.26, 13.68, 13.68, 17.98, 17.98, 11.9, 11.9, 12.1, 12.1, 20.48, 20.48, 25.94, 25.94, 31.98, 31.98, 40.3, 40.3, 49.38, 49.38, 51.42, 51.42, 55.08, 55.08, 55.24, 55.24, 56.36, 56.36, 57.72, 57.72, 59.3, 59.3, 60.1, 60.1, 60.92, 60.92, 64.74, 64.74, 64.9, 64.9, 66.86, 66.86, 66.96, 66.96, 67.6, 67.6, 68.98, 68.98, 69.82, 69.82, 69.84, 69.84, 70.22, 70.22, 72.12, 72.12, 72.16, 72.16, 72.26, 72.26, 72.5, 72.5, 72.22, 72.22, 72.32, 72.32, 72.34, 72.34, 72.38, 72.38, 72.6, 72.6, 72.68, 72.68, 72.72, 72.72, 72.66, 72.66, 72.66, 72.66, 72.8, 72.8, 72.84, 72.84, 72.46, 72.46, 72.64, 72.64, 72.76, 72.76, 72.6, 72.6, 72.68, 72.68, 72.7, 72.7, 72.92, 72.92, 72.76, 72.76, 72.72, 72.72, 72.64, 72.64, 72.44, 72.44, 72.36, 72.36, 72.26, 72.26, 72.24, 72.24, 72.22, 72.22, 72.08, 72.08, 72.16, 72.16, 72.16, 72.16, 72.08, 72.08, 72.08, 72.08, 72.14, 72.14, 71.98, 71.98, 71.76, 71.76, 71.7, 71.7, 71.76, 71.76, 71.78, 71.78, 71.86, 71.86, 71.68, 71.68, 71.66, 71.66, 71.7, 71.7, 71.54, 71.54, 71.54, 71.54, 71.72, 71.72, 71.82, 71.82, 71.88, 71.88, 71.94, 71.94, 72.06, 72.06, 72.1, 72.1, 72.06, 72.06, 72.04, 72.04, 71.9, 71.9, 72.0, 72.0, 71.9, 71.9, 71.9, 71.9, 71.74, 71.74, 71.76, 71.76, 71.84, 71.84, 71.8, 71.8, 71.88, 71.88, 71.98, 71.98, 71.98, 71.98, 71.8, 71.8, 71.76, 71.76, 71.72, 71.72, 71.74, 71.74, 71.78, 71.78, 71.9, 71.9, 71.82, 71.82, 71.56, 71.56]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.6 , level_n_lowerb:0.4  

   Client 7, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
prox
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.302, Test loss: 2.300, Test accuracy: 12.30
Round   0, Global train loss: 2.302, Global test loss: 2.300, Global test accuracy: 11.34
Round   1, Train loss: 2.300, Test loss: 2.298, Test accuracy: 16.80
Round   1, Global train loss: 2.300, Global test loss: 2.298, Global test accuracy: 17.36
Round   2, Train loss: 2.297, Test loss: 2.295, Test accuracy: 19.68
Round   2, Global train loss: 2.297, Global test loss: 2.294, Global test accuracy: 20.52
Round   3, Train loss: 2.290, Test loss: 2.288, Test accuracy: 19.98
Round   3, Global train loss: 2.290, Global test loss: 2.285, Global test accuracy: 18.80
Round   4, Train loss: 2.285, Test loss: 2.272, Test accuracy: 15.20
Round   4, Global train loss: 2.285, Global test loss: 2.261, Global test accuracy: 12.28
Round   5, Train loss: 2.264, Test loss: 2.251, Test accuracy: 22.46
Round   5, Global train loss: 2.264, Global test loss: 2.226, Global test accuracy: 27.62
Round   6, Train loss: 2.214, Test loss: 2.209, Test accuracy: 25.86
Round   6, Global train loss: 2.214, Global test loss: 2.162, Global test accuracy: 33.82
Round   7, Train loss: 2.191, Test loss: 2.163, Test accuracy: 31.28
Round   7, Global train loss: 2.191, Global test loss: 2.082, Global test accuracy: 39.58
Round   8, Train loss: 2.113, Test loss: 2.087, Test accuracy: 39.70
Round   8, Global train loss: 2.113, Global test loss: 1.990, Global test accuracy: 49.46
Round   9, Train loss: 2.042, Test loss: 1.992, Test accuracy: 50.26
Round   9, Global train loss: 2.042, Global test loss: 1.915, Global test accuracy: 60.80
Round  10, Train loss: 2.053, Test loss: 1.953, Test accuracy: 53.78
Round  10, Global train loss: 2.053, Global test loss: 1.879, Global test accuracy: 61.00
Round  11, Train loss: 2.069, Test loss: 1.909, Test accuracy: 58.50
Round  11, Global train loss: 2.069, Global test loss: 1.855, Global test accuracy: 64.44
Round  12, Train loss: 2.002, Test loss: 1.886, Test accuracy: 60.40
Round  12, Global train loss: 2.002, Global test loss: 1.809, Global test accuracy: 68.82
Round  13, Train loss: 2.011, Test loss: 1.855, Test accuracy: 63.72
Round  13, Global train loss: 2.011, Global test loss: 1.782, Global test accuracy: 71.54
Round  14, Train loss: 1.945, Test loss: 1.816, Test accuracy: 67.90
Round  14, Global train loss: 1.945, Global test loss: 1.747, Global test accuracy: 74.52
Round  15, Train loss: 1.983, Test loss: 1.788, Test accuracy: 71.16
Round  15, Global train loss: 1.983, Global test loss: 1.721, Global test accuracy: 79.00
Round  16, Train loss: 1.936, Test loss: 1.777, Test accuracy: 71.88
Round  16, Global train loss: 1.936, Global test loss: 1.702, Global test accuracy: 80.12
Round  17, Train loss: 1.849, Test loss: 1.772, Test accuracy: 72.40
Round  17, Global train loss: 1.849, Global test loss: 1.684, Global test accuracy: 80.68
Round  18, Train loss: 1.891, Test loss: 1.732, Test accuracy: 75.84
Round  18, Global train loss: 1.891, Global test loss: 1.676, Global test accuracy: 81.14
Round  19, Train loss: 1.798, Test loss: 1.729, Test accuracy: 75.86
Round  19, Global train loss: 1.798, Global test loss: 1.668, Global test accuracy: 82.04
Round  20, Train loss: 1.884, Test loss: 1.717, Test accuracy: 76.62
Round  20, Global train loss: 1.884, Global test loss: 1.663, Global test accuracy: 81.98
Round  21, Train loss: 1.872, Test loss: 1.716, Test accuracy: 76.82
Round  21, Global train loss: 1.872, Global test loss: 1.667, Global test accuracy: 80.28
Round  22, Train loss: 1.844, Test loss: 1.714, Test accuracy: 76.62
Round  22, Global train loss: 1.844, Global test loss: 1.667, Global test accuracy: 80.74
Round  23, Train loss: 1.919, Test loss: 1.707, Test accuracy: 77.20
Round  23, Global train loss: 1.919, Global test loss: 1.652, Global test accuracy: 82.16
Round  24, Train loss: 1.877, Test loss: 1.693, Test accuracy: 78.30
Round  24, Global train loss: 1.877, Global test loss: 1.634, Global test accuracy: 84.32
Round  25, Train loss: 1.802, Test loss: 1.686, Test accuracy: 78.86
Round  25, Global train loss: 1.802, Global test loss: 1.620, Global test accuracy: 85.48
Round  26, Train loss: 1.819, Test loss: 1.673, Test accuracy: 80.34
Round  26, Global train loss: 1.819, Global test loss: 1.612, Global test accuracy: 85.94
Round  27, Train loss: 1.863, Test loss: 1.632, Test accuracy: 84.56
Round  27, Global train loss: 1.863, Global test loss: 1.607, Global test accuracy: 86.10
Round  28, Train loss: 1.868, Test loss: 1.631, Test accuracy: 84.44
Round  28, Global train loss: 1.868, Global test loss: 1.614, Global test accuracy: 85.80
Round  29, Train loss: 1.701, Test loss: 1.629, Test accuracy: 84.50
Round  29, Global train loss: 1.701, Global test loss: 1.601, Global test accuracy: 87.30
Round  30, Train loss: 1.844, Test loss: 1.621, Test accuracy: 85.10
Round  30, Global train loss: 1.844, Global test loss: 1.601, Global test accuracy: 86.70
Round  31, Train loss: 1.896, Test loss: 1.620, Test accuracy: 85.22
Round  31, Global train loss: 1.896, Global test loss: 1.600, Global test accuracy: 87.02
Round  32, Train loss: 1.743, Test loss: 1.617, Test accuracy: 85.54
Round  32, Global train loss: 1.743, Global test loss: 1.600, Global test accuracy: 87.28
Round  33, Train loss: 1.810, Test loss: 1.615, Test accuracy: 85.64
Round  33, Global train loss: 1.810, Global test loss: 1.595, Global test accuracy: 87.74
Round  34, Train loss: 1.925, Test loss: 1.614, Test accuracy: 85.66
Round  34, Global train loss: 1.925, Global test loss: 1.605, Global test accuracy: 85.82
Round  35, Train loss: 1.903, Test loss: 1.610, Test accuracy: 85.90
Round  35, Global train loss: 1.903, Global test loss: 1.598, Global test accuracy: 86.96
Round  36, Train loss: 1.806, Test loss: 1.610, Test accuracy: 85.94
Round  36, Global train loss: 1.806, Global test loss: 1.591, Global test accuracy: 87.84
Round  37, Train loss: 1.760, Test loss: 1.607, Test accuracy: 86.18
Round  37, Global train loss: 1.760, Global test loss: 1.597, Global test accuracy: 87.44
Round  38, Train loss: 1.750, Test loss: 1.607, Test accuracy: 86.16
Round  38, Global train loss: 1.750, Global test loss: 1.598, Global test accuracy: 87.12
Round  39, Train loss: 1.851, Test loss: 1.605, Test accuracy: 86.28
Round  39, Global train loss: 1.851, Global test loss: 1.602, Global test accuracy: 86.36
Round  40, Train loss: 1.879, Test loss: 1.604, Test accuracy: 86.26
Round  40, Global train loss: 1.879, Global test loss: 1.596, Global test accuracy: 86.80
Round  41, Train loss: 1.781, Test loss: 1.604, Test accuracy: 86.28
Round  41, Global train loss: 1.781, Global test loss: 1.593, Global test accuracy: 86.78
Round  42, Train loss: 1.735, Test loss: 1.603, Test accuracy: 86.22
Round  42, Global train loss: 1.735, Global test loss: 1.590, Global test accuracy: 87.02
Round  43, Train loss: 1.728, Test loss: 1.603, Test accuracy: 86.34
Round  43, Global train loss: 1.728, Global test loss: 1.590, Global test accuracy: 87.30
Round  44, Train loss: 1.853, Test loss: 1.602, Test accuracy: 86.38
Round  44, Global train loss: 1.853, Global test loss: 1.591, Global test accuracy: 86.76
Round  45, Train loss: 1.808, Test loss: 1.600, Test accuracy: 86.46
Round  45, Global train loss: 1.808, Global test loss: 1.599, Global test accuracy: 86.54
Round  46, Train loss: 1.917, Test loss: 1.602, Test accuracy: 86.36
Round  46, Global train loss: 1.917, Global test loss: 1.600, Global test accuracy: 86.36
Round  47, Train loss: 1.911, Test loss: 1.602, Test accuracy: 86.32
Round  47, Global train loss: 1.911, Global test loss: 1.601, Global test accuracy: 86.34
Round  48, Train loss: 1.831, Test loss: 1.601, Test accuracy: 86.52
Round  48, Global train loss: 1.831, Global test loss: 1.593, Global test accuracy: 86.70
Round  49, Train loss: 1.888, Test loss: 1.601, Test accuracy: 86.38
Round  49, Global train loss: 1.888, Global test loss: 1.591, Global test accuracy: 86.76
Round  50, Train loss: 1.829, Test loss: 1.602, Test accuracy: 86.30
Round  50, Global train loss: 1.829, Global test loss: 1.598, Global test accuracy: 86.66
Round  51, Train loss: 1.748, Test loss: 1.604, Test accuracy: 86.12
Round  51, Global train loss: 1.748, Global test loss: 1.594, Global test accuracy: 87.02
Round  52, Train loss: 1.836, Test loss: 1.604, Test accuracy: 86.12
Round  52, Global train loss: 1.836, Global test loss: 1.603, Global test accuracy: 85.90
Round  53, Train loss: 1.878, Test loss: 1.602, Test accuracy: 86.32
Round  53, Global train loss: 1.878, Global test loss: 1.597, Global test accuracy: 86.70
Round  54, Train loss: 1.776, Test loss: 1.603, Test accuracy: 86.14
Round  54, Global train loss: 1.776, Global test loss: 1.592, Global test accuracy: 86.86
Round  55, Train loss: 1.810, Test loss: 1.600, Test accuracy: 86.36
Round  55, Global train loss: 1.810, Global test loss: 1.591, Global test accuracy: 87.48
Round  56, Train loss: 1.737, Test loss: 1.599, Test accuracy: 86.60
Round  56, Global train loss: 1.737, Global test loss: 1.592, Global test accuracy: 86.86
Round  57, Train loss: 1.813, Test loss: 1.598, Test accuracy: 86.84
Round  57, Global train loss: 1.813, Global test loss: 1.585, Global test accuracy: 87.54
Round  58, Train loss: 1.877, Test loss: 1.598, Test accuracy: 86.84
Round  58, Global train loss: 1.877, Global test loss: 1.595, Global test accuracy: 87.44
Round  59, Train loss: 1.779, Test loss: 1.598, Test accuracy: 86.78
Round  59, Global train loss: 1.779, Global test loss: 1.589, Global test accuracy: 87.84
Round  60, Train loss: 1.723, Test loss: 1.599, Test accuracy: 86.58
Round  60, Global train loss: 1.723, Global test loss: 1.590, Global test accuracy: 87.56
Round  61, Train loss: 1.818, Test loss: 1.600, Test accuracy: 86.46
Round  61, Global train loss: 1.818, Global test loss: 1.590, Global test accuracy: 87.64
Round  62, Train loss: 1.826, Test loss: 1.599, Test accuracy: 86.50
Round  62, Global train loss: 1.826, Global test loss: 1.597, Global test accuracy: 86.78
Round  63, Train loss: 1.829, Test loss: 1.600, Test accuracy: 86.32
Round  63, Global train loss: 1.829, Global test loss: 1.591, Global test accuracy: 87.48
Round  64, Train loss: 1.777, Test loss: 1.600, Test accuracy: 86.42
Round  64, Global train loss: 1.777, Global test loss: 1.590, Global test accuracy: 87.30
Round  65, Train loss: 1.785, Test loss: 1.600, Test accuracy: 86.46
Round  65, Global train loss: 1.785, Global test loss: 1.597, Global test accuracy: 86.58
Round  66, Train loss: 1.716, Test loss: 1.599, Test accuracy: 86.58
Round  66, Global train loss: 1.716, Global test loss: 1.590, Global test accuracy: 87.58
Round  67, Train loss: 1.834, Test loss: 1.598, Test accuracy: 86.70
Round  67, Global train loss: 1.834, Global test loss: 1.593, Global test accuracy: 86.80
Round  68, Train loss: 1.813, Test loss: 1.598, Test accuracy: 86.76
Round  68, Global train loss: 1.813, Global test loss: 1.589, Global test accuracy: 88.06
Round  69, Train loss: 1.823, Test loss: 1.598, Test accuracy: 86.76
Round  69, Global train loss: 1.823, Global test loss: 1.590, Global test accuracy: 87.58
Round  70, Train loss: 1.741, Test loss: 1.598, Test accuracy: 86.72
Round  70, Global train loss: 1.741, Global test loss: 1.586, Global test accuracy: 87.92
Round  71, Train loss: 1.860, Test loss: 1.598, Test accuracy: 86.74
Round  71, Global train loss: 1.860, Global test loss: 1.593, Global test accuracy: 87.32
Round  72, Train loss: 1.763, Test loss: 1.598, Test accuracy: 86.68
Round  72, Global train loss: 1.763, Global test loss: 1.589, Global test accuracy: 87.80
Round  73, Train loss: 1.840, Test loss: 1.598, Test accuracy: 86.80
Round  73, Global train loss: 1.840, Global test loss: 1.589, Global test accuracy: 87.60
Round  74, Train loss: 1.761, Test loss: 1.599, Test accuracy: 86.74
Round  74, Global train loss: 1.761, Global test loss: 1.593, Global test accuracy: 86.86
Round  75, Train loss: 1.785, Test loss: 1.599, Test accuracy: 86.74
Round  75, Global train loss: 1.785, Global test loss: 1.592, Global test accuracy: 87.36
Round  76, Train loss: 1.897, Test loss: 1.597, Test accuracy: 87.10
Round  76, Global train loss: 1.897, Global test loss: 1.593, Global test accuracy: 87.34
Round  77, Train loss: 1.826, Test loss: 1.597, Test accuracy: 87.10
Round  77, Global train loss: 1.826, Global test loss: 1.592, Global test accuracy: 87.18
Round  78, Train loss: 1.706, Test loss: 1.597, Test accuracy: 86.98
Round  78, Global train loss: 1.706, Global test loss: 1.588, Global test accuracy: 87.48
Round  79, Train loss: 1.808, Test loss: 1.596, Test accuracy: 86.98
Round  79, Global train loss: 1.808, Global test loss: 1.593, Global test accuracy: 86.78
Round  80, Train loss: 1.743, Test loss: 1.597, Test accuracy: 86.96
Round  80, Global train loss: 1.743, Global test loss: 1.598, Global test accuracy: 86.34
Round  81, Train loss: 1.737, Test loss: 1.596, Test accuracy: 87.06
Round  81, Global train loss: 1.737, Global test loss: 1.588, Global test accuracy: 87.52
Round  82, Train loss: 1.728, Test loss: 1.596, Test accuracy: 87.06
Round  82, Global train loss: 1.728, Global test loss: 1.588, Global test accuracy: 87.60
Round  83, Train loss: 1.687, Test loss: 1.596, Test accuracy: 87.08
Round  83, Global train loss: 1.687, Global test loss: 1.589, Global test accuracy: 87.64
Round  84, Train loss: 1.732, Test loss: 1.595, Test accuracy: 87.08
Round  84, Global train loss: 1.732, Global test loss: 1.588, Global test accuracy: 87.64
Round  85, Train loss: 1.759, Test loss: 1.595, Test accuracy: 87.18
Round  85, Global train loss: 1.759, Global test loss: 1.587, Global test accuracy: 87.64
Round  86, Train loss: 1.780, Test loss: 1.594, Test accuracy: 87.20
Round  86, Global train loss: 1.780, Global test loss: 1.585, Global test accuracy: 87.76
Round  87, Train loss: 1.753, Test loss: 1.594, Test accuracy: 87.06
Round  87, Global train loss: 1.753, Global test loss: 1.589, Global test accuracy: 87.24
Round  88, Train loss: 1.720, Test loss: 1.596, Test accuracy: 86.90
Round  88, Global train loss: 1.720, Global test loss: 1.589, Global test accuracy: 87.56
Round  89, Train loss: 1.731, Test loss: 1.594, Test accuracy: 87.10
Round  89, Global train loss: 1.731, Global test loss: 1.588, Global test accuracy: 87.40
Round  90, Train loss: 1.764, Test loss: 1.594, Test accuracy: 87.14
Round  90, Global train loss: 1.764, Global test loss: 1.587, Global test accuracy: 87.50
Round  91, Train loss: 1.766, Test loss: 1.593, Test accuracy: 87.18
Round  91, Global train loss: 1.766, Global test loss: 1.589, Global test accuracy: 87.16
Round  92, Train loss: 1.766, Test loss: 1.593, Test accuracy: 87.20
Round  92, Global train loss: 1.766, Global test loss: 1.590, Global test accuracy: 87.24
Round  93, Train loss: 1.810, Test loss: 1.593, Test accuracy: 87.40
Round  93, Global train loss: 1.810, Global test loss: 1.590, Global test accuracy: 87.48
Round  94, Train loss: 1.781, Test loss: 1.593, Test accuracy: 87.34
Round  94, Global train loss: 1.781, Global test loss: 1.590, Global test accuracy: 87.04/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  95, Train loss: 1.846, Test loss: 1.593, Test accuracy: 87.30
Round  95, Global train loss: 1.846, Global test loss: 1.589, Global test accuracy: 87.60
Round  96, Train loss: 1.853, Test loss: 1.593, Test accuracy: 87.16
Round  96, Global train loss: 1.853, Global test loss: 1.592, Global test accuracy: 87.24
Round  97, Train loss: 1.653, Test loss: 1.594, Test accuracy: 87.16
Round  97, Global train loss: 1.653, Global test loss: 1.586, Global test accuracy: 87.82
Round  98, Train loss: 1.793, Test loss: 1.594, Test accuracy: 87.14
Round  98, Global train loss: 1.793, Global test loss: 1.589, Global test accuracy: 87.40
Round  99, Train loss: 1.848, Test loss: 1.594, Test accuracy: 87.12
Round  99, Global train loss: 1.848, Global test loss: 1.590, Global test accuracy: 87.52
Final Round, Train loss: 1.779, Test loss: 1.595, Test accuracy: 87.00
Final Round, Global train loss: 1.779, Global test loss: 1.590, Global test accuracy: 87.52
Average accuracy final 10 rounds: 87.21400000000001 

Average global accuracy final 10 rounds: 87.39999999999999 

756.1624653339386
[1.1773648262023926, 2.354729652404785, 3.3305208683013916, 4.306312084197998, 5.288202524185181, 6.270092964172363, 7.3541975021362305, 8.438302040100098, 9.475557565689087, 10.512813091278076, 11.532630443572998, 12.55244779586792, 13.52141785621643, 14.490387916564941, 15.509726524353027, 16.529065132141113, 17.51430368423462, 18.499542236328125, 19.44577932357788, 20.392016410827637, 21.38486671447754, 22.37771701812744, 23.37984848022461, 24.381979942321777, 25.370152235031128, 26.35832452774048, 27.41336727142334, 28.4684100151062, 29.500645875930786, 30.53288173675537, 31.509780406951904, 32.48667907714844, 33.48749923706055, 34.488319396972656, 35.53324747085571, 36.57817554473877, 37.61274838447571, 38.64732122421265, 39.66733407974243, 40.68734693527222, 41.687084913253784, 42.68682289123535, 43.748730421066284, 44.81063795089722, 45.83543658256531, 46.8602352142334, 47.90410137176514, 48.947967529296875, 49.985008001327515, 51.022048473358154, 52.077359199523926, 53.1326699256897, 54.16102623939514, 55.189382553100586, 56.20529651641846, 57.22121047973633, 58.205198526382446, 59.189186573028564, 60.15178418159485, 61.11438179016113, 62.08976984024048, 63.065157890319824, 64.10431957244873, 65.14348125457764, 66.16899108886719, 67.19450092315674, 68.2121205329895, 69.22974014282227, 70.2561936378479, 71.28264713287354, 72.29719853401184, 73.31174993515015, 74.30226945877075, 75.29278898239136, 76.26987051963806, 77.24695205688477, 78.2461268901825, 79.24530172348022, 80.3008725643158, 81.35644340515137, 82.37142133712769, 83.386399269104, 84.3996844291687, 85.4129695892334, 86.39709424972534, 87.38121891021729, 88.40346837043762, 89.42571783065796, 90.42152905464172, 91.41734027862549, 92.39234280586243, 93.36734533309937, 94.3337197303772, 95.30009412765503, 96.32160806655884, 97.34312200546265, 98.33961963653564, 99.33611726760864, 100.34902262687683, 101.36192798614502, 102.33616161346436, 103.31039524078369, 104.29883933067322, 105.28728342056274, 106.39619612693787, 107.50510883331299, 108.52165484428406, 109.53820085525513, 110.53198647499084, 111.52577209472656, 112.53043627738953, 113.53510046005249, 114.55386328697205, 115.5726261138916, 116.65545725822449, 117.73828840255737, 118.82575607299805, 119.91322374343872, 120.96056771278381, 122.0079116821289, 122.98730611801147, 123.96670055389404, 124.98876333236694, 126.01082611083984, 127.03315877914429, 128.05549144744873, 129.05315804481506, 130.0508246421814, 131.04798483848572, 132.04514503479004, 133.0426881313324, 134.04023122787476, 135.0588662624359, 136.07750129699707, 137.10388112068176, 138.13026094436646, 139.15843796730042, 140.18661499023438, 141.17916417121887, 142.17171335220337, 143.16156435012817, 144.15141534805298, 145.15374493598938, 146.15607452392578, 147.21658730506897, 148.27710008621216, 149.302827835083, 150.32855558395386, 151.39688754081726, 152.46521949768066, 153.46983408927917, 154.47444868087769, 155.4352810382843, 156.39611339569092, 157.37654519081116, 158.3569769859314, 159.39720487594604, 160.4374327659607, 161.4385244846344, 162.4396162033081, 163.48193621635437, 164.52425622940063, 165.52433323860168, 166.52441024780273, 167.5211660861969, 168.51792192459106, 169.53968834877014, 170.56145477294922, 171.61666440963745, 172.67187404632568, 173.72682166099548, 174.78176927566528, 175.78625011444092, 176.79073095321655, 177.9069333076477, 179.02313566207886, 180.00546979904175, 180.98780393600464, 181.9861581325531, 182.98451232910156, 183.97989702224731, 184.97528171539307, 185.96382546424866, 186.95236921310425, 187.96142077445984, 188.97047233581543, 189.97592735290527, 190.98138236999512, 192.000412940979, 193.0194435119629, 194.0471785068512, 195.0749135017395, 196.07478785514832, 197.07466220855713, 198.09516716003418, 199.11567211151123, 200.15467810630798, 201.19368410110474, 202.16724157333374, 203.14079904556274, 205.26778531074524, 207.39477157592773]
[12.3, 12.3, 16.8, 16.8, 19.68, 19.68, 19.98, 19.98, 15.2, 15.2, 22.46, 22.46, 25.86, 25.86, 31.28, 31.28, 39.7, 39.7, 50.26, 50.26, 53.78, 53.78, 58.5, 58.5, 60.4, 60.4, 63.72, 63.72, 67.9, 67.9, 71.16, 71.16, 71.88, 71.88, 72.4, 72.4, 75.84, 75.84, 75.86, 75.86, 76.62, 76.62, 76.82, 76.82, 76.62, 76.62, 77.2, 77.2, 78.3, 78.3, 78.86, 78.86, 80.34, 80.34, 84.56, 84.56, 84.44, 84.44, 84.5, 84.5, 85.1, 85.1, 85.22, 85.22, 85.54, 85.54, 85.64, 85.64, 85.66, 85.66, 85.9, 85.9, 85.94, 85.94, 86.18, 86.18, 86.16, 86.16, 86.28, 86.28, 86.26, 86.26, 86.28, 86.28, 86.22, 86.22, 86.34, 86.34, 86.38, 86.38, 86.46, 86.46, 86.36, 86.36, 86.32, 86.32, 86.52, 86.52, 86.38, 86.38, 86.3, 86.3, 86.12, 86.12, 86.12, 86.12, 86.32, 86.32, 86.14, 86.14, 86.36, 86.36, 86.6, 86.6, 86.84, 86.84, 86.84, 86.84, 86.78, 86.78, 86.58, 86.58, 86.46, 86.46, 86.5, 86.5, 86.32, 86.32, 86.42, 86.42, 86.46, 86.46, 86.58, 86.58, 86.7, 86.7, 86.76, 86.76, 86.76, 86.76, 86.72, 86.72, 86.74, 86.74, 86.68, 86.68, 86.8, 86.8, 86.74, 86.74, 86.74, 86.74, 87.1, 87.1, 87.1, 87.1, 86.98, 86.98, 86.98, 86.98, 86.96, 86.96, 87.06, 87.06, 87.06, 87.06, 87.08, 87.08, 87.08, 87.08, 87.18, 87.18, 87.2, 87.2, 87.06, 87.06, 86.9, 86.9, 87.1, 87.1, 87.14, 87.14, 87.18, 87.18, 87.2, 87.2, 87.4, 87.4, 87.34, 87.34, 87.3, 87.3, 87.16, 87.16, 87.16, 87.16, 87.14, 87.14, 87.12, 87.12, 87.0, 87.0]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_co_teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist, level_n_system: 0.6 , level_n_lowerb:0.4  

   Client 1, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 4, noise    level: 0.4000 
   Client 8, noise    level: 0.4000 
   Client 7, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
fedavg
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
[]
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Traceback (most recent call last):
  File "main_fedpac_co_teaching.py", line 250, in <module>
    local.filter_data(net=net_local.to(args.device), net2=net_local2.to(args.device), concept_matrix_local = concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1587, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist  

   Client 5, noise    level: 0.4000 
   Client 9, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 3, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.322, Test loss: 2.303, Test accuracy: 11.44
Round   0, Global train loss: 2.322, Global test loss: 2.303, Global test accuracy: 11.42
Round   1, Train loss: 2.302, Test loss: 2.302, Test accuracy: 11.16
Round   1, Global train loss: 2.302, Global test loss: 2.302, Global test accuracy: 11.14
Round   2, Train loss: 2.301, Test loss: 2.301, Test accuracy: 11.24
Round   2, Global train loss: 2.301, Global test loss: 2.301, Global test accuracy: 11.26
Round   3, Train loss: 2.299, Test loss: 2.299, Test accuracy: 11.50
Round   3, Global train loss: 2.299, Global test loss: 2.299, Global test accuracy: 11.70
Round   4, Train loss: 2.296, Test loss: 2.298, Test accuracy: 13.62
Round   4, Global train loss: 2.296, Global test loss: 2.298, Global test accuracy: 13.38
Round   5, Train loss: 2.295, Test loss: 2.295, Test accuracy: 16.98
Round   5, Global train loss: 2.295, Global test loss: 2.295, Global test accuracy: 17.22
Round   6, Train loss: 2.293, Test loss: 2.292, Test accuracy: 19.18
Round   6, Global train loss: 2.293, Global test loss: 2.292, Global test accuracy: 19.38
Round   7, Train loss: 2.289, Test loss: 2.286, Test accuracy: 20.34
Round   7, Global train loss: 2.289, Global test loss: 2.286, Global test accuracy: 20.32
Round   8, Train loss: 2.280, Test loss: 2.279, Test accuracy: 20.28
Round   8, Global train loss: 2.280, Global test loss: 2.279, Global test accuracy: 20.28
Round   9, Train loss: 2.281, Test loss: 2.272, Test accuracy: 19.88
Round   9, Global train loss: 2.281, Global test loss: 2.271, Global test accuracy: 19.40
Round  10, Train loss: 2.273, Test loss: 2.257, Test accuracy: 21.58
Round  10, Global train loss: 2.273, Global test loss: 2.255, Global test accuracy: 21.66
Round  11, Train loss: 2.250, Test loss: 2.226, Test accuracy: 25.52
Round  11, Global train loss: 2.250, Global test loss: 2.221, Global test accuracy: 25.30
Round  12, Train loss: 2.247, Test loss: 2.196, Test accuracy: 28.60
Round  12, Global train loss: 2.247, Global test loss: 2.186, Global test accuracy: 30.38
Round  13, Train loss: 2.189, Test loss: 2.156, Test accuracy: 31.78
Round  13, Global train loss: 2.189, Global test loss: 2.139, Global test accuracy: 31.10
Round  14, Train loss: 2.208, Test loss: 2.126, Test accuracy: 39.62
Round  14, Global train loss: 2.208, Global test loss: 2.116, Global test accuracy: 44.86
Round  15, Train loss: 2.138, Test loss: 2.077, Test accuracy: 47.00
Round  15, Global train loss: 2.138, Global test loss: 2.036, Global test accuracy: 51.78
Round  16, Train loss: 2.111, Test loss: 2.035, Test accuracy: 49.80
Round  16, Global train loss: 2.111, Global test loss: 1.996, Global test accuracy: 51.62
Round  17, Train loss: 2.147, Test loss: 2.024, Test accuracy: 50.28
Round  17, Global train loss: 2.147, Global test loss: 1.998, Global test accuracy: 52.06
Round  18, Train loss: 2.110, Test loss: 1.993, Test accuracy: 51.58
Round  18, Global train loss: 2.110, Global test loss: 1.981, Global test accuracy: 51.80
Round  19, Train loss: 2.127, Test loss: 1.989, Test accuracy: 51.82
Round  19, Global train loss: 2.127, Global test loss: 1.974, Global test accuracy: 51.98
Round  20, Train loss: 2.116, Test loss: 1.979, Test accuracy: 53.00
Round  20, Global train loss: 2.116, Global test loss: 1.966, Global test accuracy: 53.86
Round  21, Train loss: 2.096, Test loss: 1.964, Test accuracy: 54.88
Round  21, Global train loss: 2.096, Global test loss: 1.942, Global test accuracy: 57.74
Round  22, Train loss: 2.083, Test loss: 1.952, Test accuracy: 57.06
Round  22, Global train loss: 2.083, Global test loss: 1.931, Global test accuracy: 58.40
Round  23, Train loss: 2.077, Test loss: 1.938, Test accuracy: 59.22
Round  23, Global train loss: 2.077, Global test loss: 1.920, Global test accuracy: 58.92
Round  24, Train loss: 2.076, Test loss: 1.928, Test accuracy: 59.94
Round  24, Global train loss: 2.076, Global test loss: 1.912, Global test accuracy: 59.26
Round  25, Train loss: 2.050, Test loss: 1.917, Test accuracy: 61.12
Round  25, Global train loss: 2.050, Global test loss: 1.893, Global test accuracy: 63.86
Round  26, Train loss: 2.032, Test loss: 1.910, Test accuracy: 62.74
Round  26, Global train loss: 2.032, Global test loss: 1.888, Global test accuracy: 61.50
Round  27, Train loss: 2.051, Test loss: 1.890, Test accuracy: 64.32
Round  27, Global train loss: 2.051, Global test loss: 1.886, Global test accuracy: 65.66
Round  28, Train loss: 1.972, Test loss: 1.880, Test accuracy: 64.74
Round  28, Global train loss: 1.972, Global test loss: 1.857, Global test accuracy: 66.14
Round  29, Train loss: 2.092, Test loss: 1.887, Test accuracy: 65.00
Round  29, Global train loss: 2.092, Global test loss: 1.878, Global test accuracy: 65.22
Round  30, Train loss: 2.002, Test loss: 1.876, Test accuracy: 65.34
Round  30, Global train loss: 2.002, Global test loss: 1.860, Global test accuracy: 65.80
Round  31, Train loss: 1.984, Test loss: 1.862, Test accuracy: 65.68
Round  31, Global train loss: 1.984, Global test loss: 1.850, Global test accuracy: 66.28
Round  32, Train loss: 2.101, Test loss: 1.870, Test accuracy: 65.72
Round  32, Global train loss: 2.101, Global test loss: 1.863, Global test accuracy: 65.74
Round  33, Train loss: 2.081, Test loss: 1.865, Test accuracy: 65.82
Round  33, Global train loss: 2.081, Global test loss: 1.866, Global test accuracy: 65.70
Round  34, Train loss: 1.905, Test loss: 1.844, Test accuracy: 66.80
Round  34, Global train loss: 1.905, Global test loss: 1.826, Global test accuracy: 66.52
Round  35, Train loss: 1.864, Test loss: 1.831, Test accuracy: 67.70
Round  35, Global train loss: 1.864, Global test loss: 1.809, Global test accuracy: 68.12
Round  36, Train loss: 2.070, Test loss: 1.836, Test accuracy: 67.96
Round  36, Global train loss: 2.070, Global test loss: 1.837, Global test accuracy: 67.26
Round  37, Train loss: 2.008, Test loss: 1.840, Test accuracy: 67.94
Round  37, Global train loss: 2.008, Global test loss: 1.839, Global test accuracy: 65.62
Round  38, Train loss: 1.997, Test loss: 1.842, Test accuracy: 67.78
Round  38, Global train loss: 1.997, Global test loss: 1.838, Global test accuracy: 65.60
Round  39, Train loss: 1.959, Test loss: 1.838, Test accuracy: 67.76
Round  39, Global train loss: 1.959, Global test loss: 1.832, Global test accuracy: 65.76
Round  40, Train loss: 1.925, Test loss: 1.824, Test accuracy: 68.36
Round  40, Global train loss: 1.925, Global test loss: 1.805, Global test accuracy: 68.10
Round  41, Train loss: 2.060, Test loss: 1.827, Test accuracy: 68.50
Round  41, Global train loss: 2.060, Global test loss: 1.825, Global test accuracy: 66.66
Round  42, Train loss: 1.954, Test loss: 1.820, Test accuracy: 69.46
Round  42, Global train loss: 1.954, Global test loss: 1.803, Global test accuracy: 71.42
Round  43, Train loss: 1.937, Test loss: 1.815, Test accuracy: 69.80
Round  43, Global train loss: 1.937, Global test loss: 1.794, Global test accuracy: 71.38
Round  44, Train loss: 1.851, Test loss: 1.793, Test accuracy: 72.36
Round  44, Global train loss: 1.851, Global test loss: 1.767, Global test accuracy: 74.64
Round  45, Train loss: 1.974, Test loss: 1.791, Test accuracy: 73.64
Round  45, Global train loss: 1.974, Global test loss: 1.798, Global test accuracy: 71.18
Round  46, Train loss: 1.794, Test loss: 1.763, Test accuracy: 75.78
Round  46, Global train loss: 1.794, Global test loss: 1.725, Global test accuracy: 79.22
Round  47, Train loss: 1.766, Test loss: 1.749, Test accuracy: 76.42
Round  47, Global train loss: 1.766, Global test loss: 1.706, Global test accuracy: 79.64
Round  48, Train loss: 1.901, Test loss: 1.749, Test accuracy: 76.86
Round  48, Global train loss: 1.901, Global test loss: 1.724, Global test accuracy: 79.56
Round  49, Train loss: 1.820, Test loss: 1.738, Test accuracy: 78.28
Round  49, Global train loss: 1.820, Global test loss: 1.706, Global test accuracy: 80.70
Round  50, Train loss: 1.856, Test loss: 1.741, Test accuracy: 78.20
Round  50, Global train loss: 1.856, Global test loss: 1.724, Global test accuracy: 79.34
Round  51, Train loss: 1.992, Test loss: 1.756, Test accuracy: 77.64
Round  51, Global train loss: 1.992, Global test loss: 1.764, Global test accuracy: 76.12
Round  52, Train loss: 1.879, Test loss: 1.753, Test accuracy: 78.18
Round  52, Global train loss: 1.879, Global test loss: 1.737, Global test accuracy: 78.54
Round  53, Train loss: 1.933, Test loss: 1.743, Test accuracy: 78.44
Round  53, Global train loss: 1.933, Global test loss: 1.728, Global test accuracy: 80.12
Round  54, Train loss: 1.855, Test loss: 1.743, Test accuracy: 78.34
Round  54, Global train loss: 1.855, Global test loss: 1.732, Global test accuracy: 78.76
Round  55, Train loss: 1.915, Test loss: 1.738, Test accuracy: 78.50
Round  55, Global train loss: 1.915, Global test loss: 1.725, Global test accuracy: 79.88
Round  56, Train loss: 1.906, Test loss: 1.747, Test accuracy: 78.04
Round  56, Global train loss: 1.906, Global test loss: 1.742, Global test accuracy: 77.84
Round  57, Train loss: 1.868, Test loss: 1.736, Test accuracy: 78.78
Round  57, Global train loss: 1.868, Global test loss: 1.721, Global test accuracy: 79.92
Round  58, Train loss: 1.829, Test loss: 1.736, Test accuracy: 78.96
Round  58, Global train loss: 1.829, Global test loss: 1.713, Global test accuracy: 79.94
Round  59, Train loss: 1.910, Test loss: 1.745, Test accuracy: 78.78
Round  59, Global train loss: 1.910, Global test loss: 1.733, Global test accuracy: 79.08
Round  60, Train loss: 1.875, Test loss: 1.739, Test accuracy: 78.88
Round  60, Global train loss: 1.875, Global test loss: 1.729, Global test accuracy: 79.60
Round  61, Train loss: 1.864, Test loss: 1.742, Test accuracy: 78.62
Round  61, Global train loss: 1.864, Global test loss: 1.735, Global test accuracy: 78.32
Round  62, Train loss: 1.834, Test loss: 1.744, Test accuracy: 78.42
Round  62, Global train loss: 1.834, Global test loss: 1.728, Global test accuracy: 78.90
Round  63, Train loss: 1.836, Test loss: 1.730, Test accuracy: 78.96
Round  63, Global train loss: 1.836, Global test loss: 1.714, Global test accuracy: 79.72
Round  64, Train loss: 1.884, Test loss: 1.739, Test accuracy: 78.62
Round  64, Global train loss: 1.884, Global test loss: 1.727, Global test accuracy: 79.50
Round  65, Train loss: 1.858, Test loss: 1.744, Test accuracy: 78.76
Round  65, Global train loss: 1.858, Global test loss: 1.739, Global test accuracy: 78.66
Round  66, Train loss: 1.893, Test loss: 1.744, Test accuracy: 78.60
Round  66, Global train loss: 1.893, Global test loss: 1.742, Global test accuracy: 78.36
Round  67, Train loss: 1.828, Test loss: 1.733, Test accuracy: 78.98
Round  67, Global train loss: 1.828, Global test loss: 1.720, Global test accuracy: 79.26
Round  68, Train loss: 1.841, Test loss: 1.726, Test accuracy: 80.18
Round  68, Global train loss: 1.841, Global test loss: 1.711, Global test accuracy: 79.86
Round  69, Train loss: 1.787, Test loss: 1.715, Test accuracy: 81.24
Round  69, Global train loss: 1.787, Global test loss: 1.693, Global test accuracy: 82.66
Round  70, Train loss: 1.824, Test loss: 1.716, Test accuracy: 81.52
Round  70, Global train loss: 1.824, Global test loss: 1.704, Global test accuracy: 80.32
Round  71, Train loss: 1.775, Test loss: 1.711, Test accuracy: 82.28
Round  71, Global train loss: 1.775, Global test loss: 1.675, Global test accuracy: 86.74
Round  72, Train loss: 1.764, Test loss: 1.712, Test accuracy: 81.98
Round  72, Global train loss: 1.764, Global test loss: 1.695, Global test accuracy: 81.42
Round  73, Train loss: 1.783, Test loss: 1.701, Test accuracy: 83.36
Round  73, Global train loss: 1.783, Global test loss: 1.674, Global test accuracy: 87.26
Round  74, Train loss: 1.805, Test loss: 1.718, Test accuracy: 82.18
Round  74, Global train loss: 1.805, Global test loss: 1.704, Global test accuracy: 83.04
Round  75, Train loss: 1.833, Test loss: 1.722, Test accuracy: 82.30
Round  75, Global train loss: 1.833, Global test loss: 1.711, Global test accuracy: 84.34
Round  76, Train loss: 1.622, Test loss: 1.664, Test accuracy: 86.14
Round  76, Global train loss: 1.622, Global test loss: 1.623, Global test accuracy: 89.76
Round  77, Train loss: 1.668, Test loss: 1.661, Test accuracy: 86.54
Round  77, Global train loss: 1.668, Global test loss: 1.634, Global test accuracy: 89.38
Round  78, Train loss: 1.809, Test loss: 1.685, Test accuracy: 85.40
Round  78, Global train loss: 1.809, Global test loss: 1.685, Global test accuracy: 85.66
Round  79, Train loss: 1.813, Test loss: 1.703, Test accuracy: 83.72
Round  79, Global train loss: 1.813, Global test loss: 1.683, Global test accuracy: 86.04
Round  80, Train loss: 1.774, Test loss: 1.713, Test accuracy: 83.16
Round  80, Global train loss: 1.774, Global test loss: 1.713, Global test accuracy: 83.42
Round  81, Train loss: 1.765, Test loss: 1.713, Test accuracy: 83.08
Round  81, Global train loss: 1.765, Global test loss: 1.706, Global test accuracy: 84.24
Round  82, Train loss: 1.854, Test loss: 1.701, Test accuracy: 83.80
Round  82, Global train loss: 1.854, Global test loss: 1.709, Global test accuracy: 83.20
Round  83, Train loss: 1.793, Test loss: 1.744, Test accuracy: 81.02
Round  83, Global train loss: 1.793, Global test loss: 1.746, Global test accuracy: 80.40
Round  84, Train loss: 1.753, Test loss: 1.699, Test accuracy: 84.52
Round  84, Global train loss: 1.753, Global test loss: 1.680, Global test accuracy: 85.60
Round  85, Train loss: 1.689, Test loss: 1.689, Test accuracy: 85.12
Round  85, Global train loss: 1.689, Global test loss: 1.670, Global test accuracy: 85.54
Round  86, Train loss: 1.758, Test loss: 1.695, Test accuracy: 84.34
Round  86, Global train loss: 1.758, Global test loss: 1.689, Global test accuracy: 85.56
Round  87, Train loss: 1.736, Test loss: 1.687, Test accuracy: 84.74
Round  87, Global train loss: 1.736, Global test loss: 1.679, Global test accuracy: 84.70
Round  88, Train loss: 1.744, Test loss: 1.704, Test accuracy: 83.38
Round  88, Global train loss: 1.744, Global test loss: 1.693, Global test accuracy: 84.68
Round  89, Train loss: 1.707, Test loss: 1.698, Test accuracy: 83.62
Round  89, Global train loss: 1.707, Global test loss: 1.675, Global test accuracy: 85.50
Round  90, Train loss: 1.756, Test loss: 1.698, Test accuracy: 83.00
Round  90, Global train loss: 1.756, Global test loss: 1.687, Global test accuracy: 84.68
Round  91, Train loss: 1.745, Test loss: 1.707, Test accuracy: 82.64
Round  91, Global train loss: 1.745, Global test loss: 1.695, Global test accuracy: 84.32/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()

Round  92, Train loss: 1.677, Test loss: 1.700, Test accuracy: 83.44
Round  92, Global train loss: 1.677, Global test loss: 1.690, Global test accuracy: 83.70
Round  93, Train loss: 1.623, Test loss: 1.673, Test accuracy: 85.10
Round  93, Global train loss: 1.623, Global test loss: 1.644, Global test accuracy: 87.44
Round  94, Train loss: 1.741, Test loss: 1.685, Test accuracy: 83.48
Round  94, Global train loss: 1.741, Global test loss: 1.670, Global test accuracy: 85.06
Round  95, Train loss: 1.727, Test loss: 1.678, Test accuracy: 84.12
Round  95, Global train loss: 1.727, Global test loss: 1.657, Global test accuracy: 86.60
Round  96, Train loss: 1.652, Test loss: 1.662, Test accuracy: 85.96
Round  96, Global train loss: 1.652, Global test loss: 1.635, Global test accuracy: 87.38
Round  97, Train loss: 1.753, Test loss: 1.728, Test accuracy: 80.30
Round  97, Global train loss: 1.753, Global test loss: 1.730, Global test accuracy: 79.80
Round  98, Train loss: 1.697, Test loss: 1.701, Test accuracy: 82.62
Round  98, Global train loss: 1.697, Global test loss: 1.685, Global test accuracy: 84.46
Round  99, Train loss: 1.620, Test loss: 1.674, Test accuracy: 84.72
Round  99, Global train loss: 1.620, Global test loss: 1.644, Global test accuracy: 87.74
Final Round, Train loss: 1.662, Test loss: 1.669, Test accuracy: 84.28
Final Round, Global train loss: 1.662, Global test loss: 1.644, Global test accuracy: 87.74
Average accuracy final 10 rounds: 83.538
645.4676280021667
[1.3696322441101074, 2.6177051067352295, 3.8800957202911377, 5.122488021850586, 6.330073595046997, 7.575063705444336, 8.778869390487671, 9.98297905921936, 11.117103099822998, 12.306901931762695, 13.437497615814209, 14.527911901473999, 15.69122576713562, 16.855547666549683, 18.000349521636963, 19.13801097869873, 20.28823447227478, 21.425660133361816, 22.546741008758545, 23.645108222961426, 24.721474409103394, 25.79755663871765, 26.890623807907104, 27.977187633514404, 29.0623197555542, 30.167470693588257, 31.25758409500122, 32.38206434249878, 33.48316025733948, 34.62641191482544, 35.74576544761658, 36.9155855178833, 38.09866762161255, 39.26010513305664, 40.42281985282898, 41.56996989250183, 42.73812651634216, 43.96843981742859, 45.187692165374756, 46.424551486968994, 47.65449619293213, 48.85910177230835, 50.043548583984375, 51.22669720649719, 52.43330121040344, 53.641693115234375, 54.8726589679718, 56.05141568183899, 57.26514482498169, 58.49191761016846, 59.62858438491821, 60.69772410392761, 61.83255696296692, 62.92369055747986, 64.07078814506531, 65.69982838630676, 66.81637954711914, 67.95605087280273, 69.11523723602295, 70.21947479248047, 71.3400468826294, 72.47835397720337, 73.61062860488892, 74.77967381477356, 75.91042065620422, 77.03526735305786, 78.14505791664124, 79.2496886253357, 80.3784191608429, 81.53052425384521, 82.68397116661072, 83.80815005302429, 84.90549564361572, 86.02742600440979, 87.13712930679321, 88.25718140602112, 89.3573842048645, 90.45584726333618, 91.59971976280212, 92.76813650131226, 93.89569211006165, 95.0509922504425, 96.1912088394165, 97.30396628379822, 98.39176917076111, 99.48853945732117, 100.60218405723572, 101.7075252532959, 102.98988842964172, 104.10657167434692, 105.247487783432, 106.31583619117737, 107.43804740905762, 108.50638175010681, 109.63680863380432, 110.77935028076172, 111.86756730079651, 112.9782133102417, 114.10148620605469, 115.26537489891052, 117.082839012146]
[11.44, 11.16, 11.24, 11.5, 13.62, 16.98, 19.18, 20.34, 20.28, 19.88, 21.58, 25.52, 28.6, 31.78, 39.62, 47.0, 49.8, 50.28, 51.58, 51.82, 53.0, 54.88, 57.06, 59.22, 59.94, 61.12, 62.74, 64.32, 64.74, 65.0, 65.34, 65.68, 65.72, 65.82, 66.8, 67.7, 67.96, 67.94, 67.78, 67.76, 68.36, 68.5, 69.46, 69.8, 72.36, 73.64, 75.78, 76.42, 76.86, 78.28, 78.2, 77.64, 78.18, 78.44, 78.34, 78.5, 78.04, 78.78, 78.96, 78.78, 78.88, 78.62, 78.42, 78.96, 78.62, 78.76, 78.6, 78.98, 80.18, 81.24, 81.52, 82.28, 81.98, 83.36, 82.18, 82.3, 86.14, 86.54, 85.4, 83.72, 83.16, 83.08, 83.8, 81.02, 84.52, 85.12, 84.34, 84.74, 83.38, 83.62, 83.0, 82.64, 83.44, 85.1, 83.48, 84.12, 85.96, 80.3, 82.62, 84.72, 84.28]
/home/ChenSM/code/FL_HLS/utils/sampling.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label = torch.tensor(dataset.targets[i]).item()
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Fedpac_copsl%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 5, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: mnist,  filter_alg: loss_psl, level_n_system: 0.6 , level_n_lowerb:0.4  

   Client 8, noise    level: 0.4000 
   Client 6, noise    level: 0.4000 
   Client 1, noise    level: 0.4000 
   Client 5, noise    level: 0.4000 
   Client 0, noise    level: 0.4000 
   Client 2, noise    level: 0.4000 
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
odict_keys(['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias'])
8
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias']
['layer_input.weight', 'layer_input.bias', 'layer_hidden1.weight', 'layer_hidden1.bias', 'layer_hidden2.weight', 'layer_hidden2.bias', 'layer_out.weight', 'layer_out.bias']
# Params: 550346 (local), 549696 (global); Percentage 99.88 (549696/550346)
learning rate, batch size: 0.01, 10
MLP(
  (layer_input): Linear(in_features=784, out_features=512, bias=True)
  (relu): ReLU()
  (dropout): Dropout(p=0, inplace=False)
  (layer_hidden1): Linear(in_features=512, out_features=256, bias=True)
  (layer_hidden2): Linear(in_features=256, out_features=64, bias=True)
  (layer_out): Linear(in_features=64, out_features=10, bias=True)
  (softmax): Softmax(dim=1)
)
Round   0, Train loss: 2.322, Test loss: 2.301, Test accuracy: 14.64
Round   0, Global train loss: 2.322, Global test loss: 2.301, Global test accuracy: 14.32
Round   1, Train loss: 2.300, Test loss: 2.299, Test accuracy: 18.26
Round   1, Global train loss: 2.300, Global test loss: 2.299, Global test accuracy: 17.96
Round   2, Train loss: 2.298, Test loss: 2.296, Test accuracy: 22.54
Round   2, Global train loss: 2.298, Global test loss: 2.296, Global test accuracy: 22.04
Round   3, Train loss: 2.296, Test loss: 2.293, Test accuracy: 28.58
Round   3, Global train loss: 2.296, Global test loss: 2.293, Global test accuracy: 29.36
Round   4, Train loss: 2.292, Test loss: 2.288, Test accuracy: 34.18
Round   4, Global train loss: 2.292, Global test loss: 2.288, Global test accuracy: 36.52
Round   5, Train loss: 2.287, Test loss: 2.279, Test accuracy: 35.18
Round   5, Global train loss: 2.287, Global test loss: 2.279, Global test accuracy: 35.74
Round   6, Train loss: 2.276, Test loss: 2.257, Test accuracy: 32.66
Round   6, Global train loss: 2.276, Global test loss: 2.257, Global test accuracy: 31.92
Round   7, Train loss: 2.255, Test loss: 2.218, Test accuracy: 31.90
Round   7, Global train loss: 2.255, Global test loss: 2.214, Global test accuracy: 31.50
Round   8, Train loss: 2.229, Test loss: 2.178, Test accuracy: 32.58
Round   8, Global train loss: 2.229, Global test loss: 2.170, Global test accuracy: 32.24
Round   9, Train loss: 2.205, Test loss: 2.143, Test accuracy: 35.24
Round   9, Global train loss: 2.205, Global test loss: 2.135, Global test accuracy: 33.64
Round  10, Train loss: 2.179, Test loss: 2.110, Test accuracy: 40.02
Round  10, Global train loss: 2.179, Global test loss: 2.099, Global test accuracy: 39.70
Traceback (most recent call last):
  File "main_fedpac_copsl.py", line 280, in <module>
    w_local, loss, indd, class_center_local, class_num, noisy_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys,
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2559, in train
    self.filter_data(net, local_net, iter2-head_eps+1, local_eps-head_eps+1, concept_matrix_local)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 2396, in filter_data
    data_tmp = torch.from_numpy(np.array([self.dataset.data[data_idx].reshape(3, 32, 32)])).to(torch.float32)
RuntimeError: shape '[3, 32, 32]' is invalid for input of size 784
