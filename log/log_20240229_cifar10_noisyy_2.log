nohup: ignoring input
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.005, Test loss: 1.745, Test accuracy: 37.78
Round   0, Global train loss: 2.005, Global test loss: 1.735, Global test accuracy: 39.18
Round   1, Train loss: 1.670, Test loss: 1.561, Test accuracy: 43.50
Round   1, Global train loss: 1.670, Global test loss: 1.524, Global test accuracy: 45.53
Round   2, Train loss: 1.551, Test loss: 1.470, Test accuracy: 46.77
Round   2, Global train loss: 1.551, Global test loss: 1.368, Global test accuracy: 51.03
Round   3, Train loss: 1.484, Test loss: 1.450, Test accuracy: 47.86
Round   3, Global train loss: 1.484, Global test loss: 1.321, Global test accuracy: 53.76
Round   4, Train loss: 1.436, Test loss: 1.442, Test accuracy: 47.79
Round   4, Global train loss: 1.436, Global test loss: 1.294, Global test accuracy: 53.91
Round   5, Train loss: 1.468, Test loss: 1.417, Test accuracy: 48.86
Round   5, Global train loss: 1.468, Global test loss: 1.371, Global test accuracy: 52.81
Round   6, Train loss: 1.370, Test loss: 1.397, Test accuracy: 49.58
Round   6, Global train loss: 1.370, Global test loss: 1.324, Global test accuracy: 53.81
Round   7, Train loss: 1.285, Test loss: 1.391, Test accuracy: 50.27
Round   7, Global train loss: 1.285, Global test loss: 1.273, Global test accuracy: 56.87
Round   8, Train loss: 1.243, Test loss: 1.389, Test accuracy: 50.72
Round   8, Global train loss: 1.243, Global test loss: 1.346, Global test accuracy: 54.30
Round   9, Train loss: 1.216, Test loss: 1.376, Test accuracy: 51.30
Round   9, Global train loss: 1.216, Global test loss: 1.174, Global test accuracy: 58.77
Round  10, Train loss: 1.213, Test loss: 1.374, Test accuracy: 51.79
Round  10, Global train loss: 1.213, Global test loss: 1.281, Global test accuracy: 55.54
Round  11, Train loss: 1.126, Test loss: 1.359, Test accuracy: 52.15
Round  11, Global train loss: 1.126, Global test loss: 1.274, Global test accuracy: 56.91
Round  12, Train loss: 1.045, Test loss: 1.375, Test accuracy: 52.20
Round  12, Global train loss: 1.045, Global test loss: 1.168, Global test accuracy: 59.83
Round  13, Train loss: 1.108, Test loss: 1.389, Test accuracy: 52.44
Round  13, Global train loss: 1.108, Global test loss: 1.177, Global test accuracy: 58.62
Round  14, Train loss: 0.989, Test loss: 1.388, Test accuracy: 52.54
Round  14, Global train loss: 0.989, Global test loss: 1.128, Global test accuracy: 60.68
Round  15, Train loss: 1.063, Test loss: 1.391, Test accuracy: 52.85
Round  15, Global train loss: 1.063, Global test loss: 1.258, Global test accuracy: 56.48
Round  16, Train loss: 1.032, Test loss: 1.406, Test accuracy: 52.92
Round  16, Global train loss: 1.032, Global test loss: 1.271, Global test accuracy: 55.57
Round  17, Train loss: 1.037, Test loss: 1.427, Test accuracy: 53.05
Round  17, Global train loss: 1.037, Global test loss: 1.192, Global test accuracy: 58.05
Round  18, Train loss: 0.920, Test loss: 1.409, Test accuracy: 54.08
Round  18, Global train loss: 0.920, Global test loss: 1.289, Global test accuracy: 55.06
Round  19, Train loss: 0.916, Test loss: 1.414, Test accuracy: 54.24
Round  19, Global train loss: 0.916, Global test loss: 1.263, Global test accuracy: 56.95
Round  20, Train loss: 0.927, Test loss: 1.431, Test accuracy: 53.81
Round  20, Global train loss: 0.927, Global test loss: 1.115, Global test accuracy: 61.19
Round  21, Train loss: 0.815, Test loss: 1.442, Test accuracy: 54.03
Round  21, Global train loss: 0.815, Global test loss: 1.221, Global test accuracy: 57.63
Round  22, Train loss: 0.805, Test loss: 1.451, Test accuracy: 54.33
Round  22, Global train loss: 0.805, Global test loss: 1.108, Global test accuracy: 61.07
Round  23, Train loss: 0.757, Test loss: 1.497, Test accuracy: 54.34
Round  23, Global train loss: 0.757, Global test loss: 1.161, Global test accuracy: 59.01
Round  24, Train loss: 0.760, Test loss: 1.506, Test accuracy: 54.42
Round  24, Global train loss: 0.760, Global test loss: 1.183, Global test accuracy: 58.85
Round  25, Train loss: 0.780, Test loss: 1.512, Test accuracy: 54.51
Round  25, Global train loss: 0.780, Global test loss: 1.152, Global test accuracy: 59.96
Round  26, Train loss: 0.763, Test loss: 1.516, Test accuracy: 54.81
Round  26, Global train loss: 0.763, Global test loss: 1.127, Global test accuracy: 60.05
Round  27, Train loss: 0.717, Test loss: 1.537, Test accuracy: 54.77
Round  27, Global train loss: 0.717, Global test loss: 1.140, Global test accuracy: 60.93
Round  28, Train loss: 0.743, Test loss: 1.546, Test accuracy: 54.66
Round  28, Global train loss: 0.743, Global test loss: 1.211, Global test accuracy: 57.66
Round  29, Train loss: 0.726, Test loss: 1.564, Test accuracy: 54.65
Round  29, Global train loss: 0.726, Global test loss: 1.141, Global test accuracy: 60.60
Round  30, Train loss: 0.583, Test loss: 1.583, Test accuracy: 54.83
Round  30, Global train loss: 0.583, Global test loss: 1.095, Global test accuracy: 62.94
Round  31, Train loss: 0.656, Test loss: 1.600, Test accuracy: 54.85
Round  31, Global train loss: 0.656, Global test loss: 1.139, Global test accuracy: 59.22
Round  32, Train loss: 0.714, Test loss: 1.604, Test accuracy: 55.06
Round  32, Global train loss: 0.714, Global test loss: 1.211, Global test accuracy: 57.65
Round  33, Train loss: 0.634, Test loss: 1.624, Test accuracy: 55.16
Round  33, Global train loss: 0.634, Global test loss: 1.148, Global test accuracy: 59.52
Round  34, Train loss: 0.575, Test loss: 1.648, Test accuracy: 55.09
Round  34, Global train loss: 0.575, Global test loss: 1.128, Global test accuracy: 61.74
Round  35, Train loss: 0.569, Test loss: 1.656, Test accuracy: 55.27
Round  35, Global train loss: 0.569, Global test loss: 1.222, Global test accuracy: 57.04
Round  36, Train loss: 0.475, Test loss: 1.690, Test accuracy: 55.33
Round  36, Global train loss: 0.475, Global test loss: 1.166, Global test accuracy: 59.77
Round  37, Train loss: 0.491, Test loss: 1.696, Test accuracy: 55.30
Round  37, Global train loss: 0.491, Global test loss: 1.195, Global test accuracy: 57.96
Round  38, Train loss: 0.670, Test loss: 1.711, Test accuracy: 55.29
Round  38, Global train loss: 0.670, Global test loss: 1.170, Global test accuracy: 58.95
Round  39, Train loss: 0.645, Test loss: 1.727, Test accuracy: 55.26
Round  39, Global train loss: 0.645, Global test loss: 1.225, Global test accuracy: 56.85
Round  40, Train loss: 0.521, Test loss: 1.772, Test accuracy: 55.30
Round  40, Global train loss: 0.521, Global test loss: 1.196, Global test accuracy: 57.66
Round  41, Train loss: 0.498, Test loss: 1.784, Test accuracy: 55.09
Round  41, Global train loss: 0.498, Global test loss: 1.154, Global test accuracy: 59.68
Round  42, Train loss: 0.586, Test loss: 1.783, Test accuracy: 55.41
Round  42, Global train loss: 0.586, Global test loss: 1.165, Global test accuracy: 59.04
Round  43, Train loss: 0.548, Test loss: 1.809, Test accuracy: 55.52
Round  43, Global train loss: 0.548, Global test loss: 1.163, Global test accuracy: 59.71
Round  44, Train loss: 0.507, Test loss: 1.836, Test accuracy: 55.21
Round  44, Global train loss: 0.507, Global test loss: 1.176, Global test accuracy: 58.88
Round  45, Train loss: 0.433, Test loss: 1.836, Test accuracy: 55.55
Round  45, Global train loss: 0.433, Global test loss: 1.205, Global test accuracy: 58.08
Round  46, Train loss: 0.481, Test loss: 1.855, Test accuracy: 55.37
Round  46, Global train loss: 0.481, Global test loss: 1.182, Global test accuracy: 58.63
Round  47, Train loss: 0.576, Test loss: 1.856, Test accuracy: 55.55
Round  47, Global train loss: 0.576, Global test loss: 1.202, Global test accuracy: 57.75
Round  48, Train loss: 0.543, Test loss: 1.871, Test accuracy: 55.63
Round  48, Global train loss: 0.543, Global test loss: 1.160, Global test accuracy: 59.56
Round  49, Train loss: 0.451, Test loss: 1.902, Test accuracy: 55.81
Round  49, Global train loss: 0.451, Global test loss: 1.294, Global test accuracy: 54.14
Round  50, Train loss: 0.451, Test loss: 1.943, Test accuracy: 55.57
Round  50, Global train loss: 0.451, Global test loss: 1.161, Global test accuracy: 60.66
Round  51, Train loss: 0.423, Test loss: 1.952, Test accuracy: 55.40
Round  51, Global train loss: 0.423, Global test loss: 1.186, Global test accuracy: 59.56
Round  52, Train loss: 0.486, Test loss: 1.983, Test accuracy: 55.37
Round  52, Global train loss: 0.486, Global test loss: 1.165, Global test accuracy: 59.56
Round  53, Train loss: 0.450, Test loss: 1.983, Test accuracy: 55.54
Round  53, Global train loss: 0.450, Global test loss: 1.148, Global test accuracy: 60.99
Round  54, Train loss: 0.407, Test loss: 1.956, Test accuracy: 55.82
Round  54, Global train loss: 0.407, Global test loss: 1.196, Global test accuracy: 57.94
Round  55, Train loss: 0.370, Test loss: 1.977, Test accuracy: 55.94
Round  55, Global train loss: 0.370, Global test loss: 1.176, Global test accuracy: 59.53
Round  56, Train loss: 0.360, Test loss: 2.016, Test accuracy: 55.93
Round  56, Global train loss: 0.360, Global test loss: 1.222, Global test accuracy: 57.81
Round  57, Train loss: 0.362, Test loss: 2.045, Test accuracy: 55.81
Round  57, Global train loss: 0.362, Global test loss: 1.206, Global test accuracy: 58.13
Round  58, Train loss: 0.363, Test loss: 2.029, Test accuracy: 56.07
Round  58, Global train loss: 0.363, Global test loss: 1.303, Global test accuracy: 52.70
Round  59, Train loss: 0.387, Test loss: 2.075, Test accuracy: 55.73
Round  59, Global train loss: 0.387, Global test loss: 1.166, Global test accuracy: 60.50
Round  60, Train loss: 0.348, Test loss: 2.069, Test accuracy: 55.95
Round  60, Global train loss: 0.348, Global test loss: 1.208, Global test accuracy: 59.55
Round  61, Train loss: 0.380, Test loss: 2.119, Test accuracy: 55.66
Round  61, Global train loss: 0.380, Global test loss: 1.225, Global test accuracy: 56.65
Round  62, Train loss: 0.346, Test loss: 2.121, Test accuracy: 55.79
Round  62, Global train loss: 0.346, Global test loss: 1.192, Global test accuracy: 60.30
Round  63, Train loss: 0.379, Test loss: 2.150, Test accuracy: 55.61
Round  63, Global train loss: 0.379, Global test loss: 1.181, Global test accuracy: 59.43
Round  64, Train loss: 0.331, Test loss: 2.143, Test accuracy: 55.87
Round  64, Global train loss: 0.331, Global test loss: 1.197, Global test accuracy: 58.91
Round  65, Train loss: 0.370, Test loss: 2.179, Test accuracy: 55.49
Round  65, Global train loss: 0.370, Global test loss: 1.215, Global test accuracy: 58.21
Round  66, Train loss: 0.314, Test loss: 2.185, Test accuracy: 55.53
Round  66, Global train loss: 0.314, Global test loss: 1.188, Global test accuracy: 61.27
Round  67, Train loss: 0.312, Test loss: 2.217, Test accuracy: 55.17
Round  67, Global train loss: 0.312, Global test loss: 1.242, Global test accuracy: 56.93
Round  68, Train loss: 0.309, Test loss: 2.240, Test accuracy: 55.38
Round  68, Global train loss: 0.309, Global test loss: 1.240, Global test accuracy: 61.59
Round  69, Train loss: 0.334, Test loss: 2.253, Test accuracy: 55.85
Round  69, Global train loss: 0.334, Global test loss: 1.226, Global test accuracy: 56.75
Round  70, Train loss: 0.350, Test loss: 2.306, Test accuracy: 55.40
Round  70, Global train loss: 0.350, Global test loss: 1.183, Global test accuracy: 60.87
Round  71, Train loss: 0.280, Test loss: 2.323, Test accuracy: 55.40
Round  71, Global train loss: 0.280, Global test loss: 1.202, Global test accuracy: 60.27
Round  72, Train loss: 0.330, Test loss: 2.352, Test accuracy: 55.21
Round  72, Global train loss: 0.330, Global test loss: 1.256, Global test accuracy: 56.52
Round  73, Train loss: 0.301, Test loss: 2.317, Test accuracy: 55.40
Round  73, Global train loss: 0.301, Global test loss: 1.258, Global test accuracy: 56.64
Round  74, Train loss: 0.311, Test loss: 2.320, Test accuracy: 55.65
Round  74, Global train loss: 0.311, Global test loss: 1.223, Global test accuracy: 56.89
Round  75, Train loss: 0.263, Test loss: 2.324, Test accuracy: 55.67
Round  75, Global train loss: 0.263, Global test loss: 1.243, Global test accuracy: 56.98
Round  76, Train loss: 0.237, Test loss: 2.350, Test accuracy: 55.74
Round  76, Global train loss: 0.237, Global test loss: 1.217, Global test accuracy: 59.94
Round  77, Train loss: 0.291, Test loss: 2.356, Test accuracy: 55.77
Round  77, Global train loss: 0.291, Global test loss: 1.217, Global test accuracy: 60.02
Round  78, Train loss: 0.291, Test loss: 2.363, Test accuracy: 55.81
Round  78, Global train loss: 0.291, Global test loss: 1.228, Global test accuracy: 58.08
Round  79, Train loss: 0.297, Test loss: 2.382, Test accuracy: 55.63
Round  79, Global train loss: 0.297, Global test loss: 1.206, Global test accuracy: 60.09
Round  80, Train loss: 0.274, Test loss: 2.421, Test accuracy: 55.56
Round  80, Global train loss: 0.274, Global test loss: 1.201, Global test accuracy: 60.02
Round  81, Train loss: 0.279, Test loss: 2.442, Test accuracy: 55.52
Round  81, Global train loss: 0.279, Global test loss: 1.223, Global test accuracy: 57.21
Round  82, Train loss: 0.278, Test loss: 2.432, Test accuracy: 55.76
Round  82, Global train loss: 0.278, Global test loss: 1.239, Global test accuracy: 59.63
Round  83, Train loss: 0.254, Test loss: 2.436, Test accuracy: 55.74
Round  83, Global train loss: 0.254, Global test loss: 1.220, Global test accuracy: 60.24
Round  84, Train loss: 0.273, Test loss: 2.413, Test accuracy: 55.95
Round  84, Global train loss: 0.273, Global test loss: 1.223, Global test accuracy: 58.65
Round  85, Train loss: 0.272, Test loss: 2.447, Test accuracy: 55.54
Round  85, Global train loss: 0.272, Global test loss: 1.213, Global test accuracy: 57.87
Round  86, Train loss: 0.264, Test loss: 2.469, Test accuracy: 55.83
Round  86, Global train loss: 0.264, Global test loss: 1.248, Global test accuracy: 57.04
Round  87, Train loss: 0.259, Test loss: 2.469, Test accuracy: 55.80
Round  87, Global train loss: 0.259, Global test loss: 1.229, Global test accuracy: 58.26
Round  88, Train loss: 0.255, Test loss: 2.491, Test accuracy: 55.95
Round  88, Global train loss: 0.255, Global test loss: 1.265, Global test accuracy: 59.47
Round  89, Train loss: 0.247, Test loss: 2.513, Test accuracy: 55.90
Round  89, Global train loss: 0.247, Global test loss: 1.230, Global test accuracy: 58.44
Round  90, Train loss: 0.260, Test loss: 2.511, Test accuracy: 55.81
Round  90, Global train loss: 0.260, Global test loss: 1.257, Global test accuracy: 56.50
Round  91, Train loss: 0.262, Test loss: 2.483, Test accuracy: 56.02
Round  91, Global train loss: 0.262, Global test loss: 1.240, Global test accuracy: 58.27
Round  92, Train loss: 0.258, Test loss: 2.492, Test accuracy: 56.19
Round  92, Global train loss: 0.258, Global test loss: 1.255, Global test accuracy: 56.35
Round  93, Train loss: 0.249, Test loss: 2.526, Test accuracy: 55.93
Round  93, Global train loss: 0.249, Global test loss: 1.211, Global test accuracy: 58.56
Round  94, Train loss: 0.211, Test loss: 2.571, Test accuracy: 55.73
Round  94, Global train loss: 0.211, Global test loss: 1.232, Global test accuracy: 60.40
Round  95, Train loss: 0.227, Test loss: 2.611, Test accuracy: 55.55
Round  95, Global train loss: 0.227, Global test loss: 1.264, Global test accuracy: 57.64
Round  96, Train loss: 0.232, Test loss: 2.602, Test accuracy: 55.65
Round  96, Global train loss: 0.232, Global test loss: 1.252, Global test accuracy: 57.69
Round  97, Train loss: 0.230, Test loss: 2.608, Test accuracy: 55.76
Round  97, Global train loss: 0.230, Global test loss: 1.254, Global test accuracy: 59.16
Round  98, Train loss: 0.201, Test loss: 2.628, Test accuracy: 55.74
Round  98, Global train loss: 0.201, Global test loss: 1.259, Global test accuracy: 62.36
Round  99, Train loss: 0.237, Test loss: 2.641, Test accuracy: 55.70
Round  99, Global train loss: 0.237, Global test loss: 1.271, Global test accuracy: 56.37
Final Round, Train loss: 0.154, Test loss: 2.852, Test accuracy: 55.72
Final Round, Global train loss: 0.154, Global test loss: 1.271, Global test accuracy: 56.37
Average accuracy final 10 rounds: 55.80799999999999 

Average global accuracy final 10 rounds: 58.33025 

5995.677849531174
[4.135285377502441, 8.270570755004883, 12.276660919189453, 16.282751083374023, 20.313108444213867, 24.34346580505371, 28.368748426437378, 32.394031047821045, 36.427151918411255, 40.460272789001465, 44.4388210773468, 48.41736936569214, 52.419365644454956, 56.42136192321777, 60.4030978679657, 64.38483381271362, 68.77464461326599, 73.16445541381836, 77.56839060783386, 81.97232580184937, 86.15474104881287, 90.33715629577637, 94.31922817230225, 98.30130004882812, 102.25429081916809, 106.20728158950806, 110.23771905899048, 114.2681565284729, 118.30596446990967, 122.34377241134644, 126.42707848548889, 130.51038455963135, 134.5273163318634, 138.54424810409546, 142.5687437057495, 146.59323930740356, 150.6631636619568, 154.73308801651, 158.91238117218018, 163.09167432785034, 167.27047395706177, 171.4492735862732, 175.62069392204285, 179.7921142578125, 184.02417922019958, 188.25624418258667, 192.57125234603882, 196.88626050949097, 201.26741337776184, 205.64856624603271, 210.03559064865112, 214.42261505126953, 218.81582903862, 223.20904302597046, 227.7906665802002, 232.37229013442993, 236.88100266456604, 241.38971519470215, 245.84958171844482, 250.3094482421875, 254.79985451698303, 259.29026079177856, 263.7419762611389, 268.19369173049927, 272.69054770469666, 277.18740367889404, 281.67454528808594, 286.16168689727783, 290.6951313018799, 295.22857570648193, 300.1614408493042, 305.09430599212646, 309.59609270095825, 314.09787940979004, 318.6115050315857, 323.12513065338135, 327.4200406074524, 331.71495056152344, 336.13338971138, 340.5518288612366, 344.94268798828125, 349.3335471153259, 353.85546493530273, 358.37738275527954, 362.9135892391205, 367.4497957229614, 371.9734227657318, 376.4970498085022, 381.03928685188293, 385.5815238952637, 390.05784344673157, 394.53416299819946, 399.0955967903137, 403.657030582428, 408.2357544898987, 412.8144783973694, 417.37640857696533, 421.9383387565613, 426.3840847015381, 430.8298306465149, 435.5406029224396, 440.25137519836426, 444.90231347084045, 449.55325174331665, 454.19670057296753, 458.8401494026184, 463.4782717227936, 468.11639404296875, 472.66572403907776, 477.21505403518677, 481.77518796920776, 486.33532190322876, 490.8782548904419, 495.42118787765503, 499.9226920604706, 504.42419624328613, 508.9565110206604, 513.4888257980347, 517.8463356494904, 522.203845500946, 526.6791577339172, 531.1544699668884, 535.625287771225, 540.0961055755615, 544.97234582901, 549.8485860824585, 554.4502604007721, 559.0519347190857, 563.4938580989838, 567.9357814788818, 572.8375067710876, 577.7392320632935, 582.6380155086517, 587.53679895401, 592.2187423706055, 596.9006857872009, 601.7852187156677, 606.6697516441345, 611.679773569107, 616.6897954940796, 621.6574203968048, 626.62504529953, 631.1897375583649, 635.7544298171997, 640.3177056312561, 644.8809814453125, 649.3011581897736, 653.7213349342346, 658.2313706874847, 662.7414064407349, 667.2905843257904, 671.839762210846, 676.2584037780762, 680.6770453453064, 685.3373515605927, 689.9976577758789, 694.5997409820557, 699.2018241882324, 703.704350233078, 708.2068762779236, 712.8357117176056, 717.4645471572876, 722.0233941078186, 726.5822410583496, 731.1801290512085, 735.7780170440674, 740.1946630477905, 744.6113090515137, 749.2479016780853, 753.884494304657, 758.5472798347473, 763.2100653648376, 767.7958681583405, 772.3816709518433, 777.0061900615692, 781.6307091712952, 786.6969819068909, 791.7632546424866, 796.4232354164124, 801.0832161903381, 805.6376085281372, 810.1920008659363, 814.8340301513672, 819.4760594367981, 824.464376449585, 829.4526934623718, 834.1640481948853, 838.8754029273987, 843.4093444347382, 847.9432859420776, 852.4832248687744, 857.0231637954712, 861.4858648777008, 865.9485659599304, 870.8016777038574, 875.6547894477844, 880.6172020435333, 885.5796146392822, 890.1216592788696, 894.663703918457, 896.9337422847748, 899.2037806510925]
[37.7775, 37.7775, 43.4975, 43.4975, 46.765, 46.765, 47.8625, 47.8625, 47.79, 47.79, 48.8625, 48.8625, 49.5775, 49.5775, 50.265, 50.265, 50.72, 50.72, 51.295, 51.295, 51.7875, 51.7875, 52.1475, 52.1475, 52.1975, 52.1975, 52.435, 52.435, 52.5425, 52.5425, 52.8525, 52.8525, 52.925, 52.925, 53.05, 53.05, 54.075, 54.075, 54.2375, 54.2375, 53.815, 53.815, 54.03, 54.03, 54.3325, 54.3325, 54.3375, 54.3375, 54.425, 54.425, 54.5125, 54.5125, 54.8075, 54.8075, 54.7675, 54.7675, 54.6575, 54.6575, 54.6475, 54.6475, 54.83, 54.83, 54.8525, 54.8525, 55.06, 55.06, 55.16, 55.16, 55.09, 55.09, 55.265, 55.265, 55.325, 55.325, 55.2975, 55.2975, 55.2875, 55.2875, 55.26, 55.26, 55.305, 55.305, 55.0875, 55.0875, 55.415, 55.415, 55.525, 55.525, 55.2125, 55.2125, 55.555, 55.555, 55.3725, 55.3725, 55.545, 55.545, 55.6275, 55.6275, 55.81, 55.81, 55.5675, 55.5675, 55.4, 55.4, 55.3725, 55.3725, 55.5425, 55.5425, 55.8175, 55.8175, 55.9375, 55.9375, 55.9275, 55.9275, 55.815, 55.815, 56.0725, 56.0725, 55.7325, 55.7325, 55.9475, 55.9475, 55.6575, 55.6575, 55.7925, 55.7925, 55.6125, 55.6125, 55.8725, 55.8725, 55.4875, 55.4875, 55.53, 55.53, 55.1675, 55.1675, 55.375, 55.375, 55.855, 55.855, 55.4025, 55.4025, 55.4025, 55.4025, 55.2125, 55.2125, 55.395, 55.395, 55.6475, 55.6475, 55.6725, 55.6725, 55.74, 55.74, 55.765, 55.765, 55.8075, 55.8075, 55.63, 55.63, 55.5625, 55.5625, 55.5225, 55.5225, 55.7625, 55.7625, 55.7425, 55.7425, 55.955, 55.955, 55.5375, 55.5375, 55.8325, 55.8325, 55.805, 55.805, 55.95, 55.95, 55.8975, 55.8975, 55.8125, 55.8125, 56.0175, 56.0175, 56.1925, 56.1925, 55.9325, 55.9325, 55.725, 55.725, 55.5475, 55.5475, 55.6475, 55.6475, 55.76, 55.76, 55.745, 55.745, 55.7, 55.7, 55.715, 55.715]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.985, Test loss: 1.720, Test accuracy: 37.37
Round   0, Global train loss: 1.985, Global test loss: 1.710, Global test accuracy: 38.26
Round   1, Train loss: 1.678, Test loss: 1.525, Test accuracy: 44.84
Round   1, Global train loss: 1.678, Global test loss: 1.468, Global test accuracy: 47.49
Round   2, Train loss: 1.534, Test loss: 1.437, Test accuracy: 48.23
Round   2, Global train loss: 1.534, Global test loss: 1.346, Global test accuracy: 51.78
Round   3, Train loss: 1.447, Test loss: 1.389, Test accuracy: 50.03
Round   3, Global train loss: 1.447, Global test loss: 1.254, Global test accuracy: 55.16
Round   4, Train loss: 1.349, Test loss: 1.334, Test accuracy: 52.05
Round   4, Global train loss: 1.349, Global test loss: 1.170, Global test accuracy: 58.69
Round   5, Train loss: 1.264, Test loss: 1.319, Test accuracy: 52.96
Round   5, Global train loss: 1.264, Global test loss: 1.118, Global test accuracy: 60.82
Round   6, Train loss: 1.209, Test loss: 1.305, Test accuracy: 53.75
Round   6, Global train loss: 1.209, Global test loss: 1.055, Global test accuracy: 62.83
Round   7, Train loss: 1.156, Test loss: 1.254, Test accuracy: 55.66
Round   7, Global train loss: 1.156, Global test loss: 1.009, Global test accuracy: 64.66
Round   8, Train loss: 1.115, Test loss: 1.227, Test accuracy: 56.62
Round   8, Global train loss: 1.115, Global test loss: 0.975, Global test accuracy: 65.88
Round   9, Train loss: 1.053, Test loss: 1.210, Test accuracy: 57.45
Round   9, Global train loss: 1.053, Global test loss: 0.945, Global test accuracy: 67.30
Round  10, Train loss: 1.032, Test loss: 1.181, Test accuracy: 58.84
Round  10, Global train loss: 1.032, Global test loss: 0.918, Global test accuracy: 68.39
Round  11, Train loss: 0.978, Test loss: 1.146, Test accuracy: 60.60
Round  11, Global train loss: 0.978, Global test loss: 0.899, Global test accuracy: 69.27
Round  12, Train loss: 0.967, Test loss: 1.118, Test accuracy: 61.83
Round  12, Global train loss: 0.967, Global test loss: 0.876, Global test accuracy: 69.80
Round  13, Train loss: 0.919, Test loss: 1.108, Test accuracy: 62.33
Round  13, Global train loss: 0.919, Global test loss: 0.851, Global test accuracy: 70.43
Round  14, Train loss: 0.894, Test loss: 1.060, Test accuracy: 63.89
Round  14, Global train loss: 0.894, Global test loss: 0.837, Global test accuracy: 70.95
Round  15, Train loss: 0.868, Test loss: 1.041, Test accuracy: 64.66
Round  15, Global train loss: 0.868, Global test loss: 0.820, Global test accuracy: 71.87
Round  16, Train loss: 0.862, Test loss: 1.042, Test accuracy: 64.85
Round  16, Global train loss: 0.862, Global test loss: 0.814, Global test accuracy: 72.01
Round  17, Train loss: 0.823, Test loss: 1.026, Test accuracy: 65.55
Round  17, Global train loss: 0.823, Global test loss: 0.807, Global test accuracy: 72.76
Round  18, Train loss: 0.816, Test loss: 1.018, Test accuracy: 65.92
Round  18, Global train loss: 0.816, Global test loss: 0.799, Global test accuracy: 72.33
Round  19, Train loss: 0.786, Test loss: 1.006, Test accuracy: 66.52
Round  19, Global train loss: 0.786, Global test loss: 0.787, Global test accuracy: 73.36
Round  20, Train loss: 0.766, Test loss: 1.000, Test accuracy: 66.89
Round  20, Global train loss: 0.766, Global test loss: 0.766, Global test accuracy: 73.97
Round  21, Train loss: 0.755, Test loss: 0.985, Test accuracy: 67.35
Round  21, Global train loss: 0.755, Global test loss: 0.762, Global test accuracy: 74.03
Round  22, Train loss: 0.737, Test loss: 0.973, Test accuracy: 67.61
Round  22, Global train loss: 0.737, Global test loss: 0.759, Global test accuracy: 74.54
Round  23, Train loss: 0.734, Test loss: 0.971, Test accuracy: 67.83
Round  23, Global train loss: 0.734, Global test loss: 0.763, Global test accuracy: 74.06
Round  24, Train loss: 0.719, Test loss: 0.959, Test accuracy: 68.36
Round  24, Global train loss: 0.719, Global test loss: 0.752, Global test accuracy: 75.00
Round  25, Train loss: 0.714, Test loss: 0.953, Test accuracy: 68.85
Round  25, Global train loss: 0.714, Global test loss: 0.742, Global test accuracy: 75.01
Round  26, Train loss: 0.703, Test loss: 0.960, Test accuracy: 68.86
Round  26, Global train loss: 0.703, Global test loss: 0.739, Global test accuracy: 75.14
Round  27, Train loss: 0.669, Test loss: 0.962, Test accuracy: 68.81
Round  27, Global train loss: 0.669, Global test loss: 0.737, Global test accuracy: 74.86
Round  28, Train loss: 0.675, Test loss: 0.961, Test accuracy: 69.16
Round  28, Global train loss: 0.675, Global test loss: 0.727, Global test accuracy: 75.50
Round  29, Train loss: 0.655, Test loss: 0.958, Test accuracy: 69.31
Round  29, Global train loss: 0.655, Global test loss: 0.733, Global test accuracy: 75.31
Round  30, Train loss: 0.656, Test loss: 0.956, Test accuracy: 69.25
Round  30, Global train loss: 0.656, Global test loss: 0.722, Global test accuracy: 75.37
Round  31, Train loss: 0.644, Test loss: 0.941, Test accuracy: 69.88
Round  31, Global train loss: 0.644, Global test loss: 0.732, Global test accuracy: 75.57
Round  32, Train loss: 0.624, Test loss: 0.950, Test accuracy: 69.77
Round  32, Global train loss: 0.624, Global test loss: 0.725, Global test accuracy: 75.63
Round  33, Train loss: 0.630, Test loss: 0.952, Test accuracy: 69.90
Round  33, Global train loss: 0.630, Global test loss: 0.721, Global test accuracy: 75.83
Round  34, Train loss: 0.613, Test loss: 0.943, Test accuracy: 70.26
Round  34, Global train loss: 0.613, Global test loss: 0.722, Global test accuracy: 75.81
Round  35, Train loss: 0.599, Test loss: 0.940, Test accuracy: 70.43
Round  35, Global train loss: 0.599, Global test loss: 0.727, Global test accuracy: 75.86
Round  36, Train loss: 0.606, Test loss: 0.942, Test accuracy: 70.56
Round  36, Global train loss: 0.606, Global test loss: 0.715, Global test accuracy: 76.42
Round  37, Train loss: 0.599, Test loss: 0.938, Test accuracy: 70.79
Round  37, Global train loss: 0.599, Global test loss: 0.718, Global test accuracy: 76.23
Round  38, Train loss: 0.600, Test loss: 0.936, Test accuracy: 70.91
Round  38, Global train loss: 0.600, Global test loss: 0.713, Global test accuracy: 76.46
Round  39, Train loss: 0.590, Test loss: 0.945, Test accuracy: 70.86
Round  39, Global train loss: 0.590, Global test loss: 0.724, Global test accuracy: 76.38
Round  40, Train loss: 0.583, Test loss: 0.949, Test accuracy: 70.90
Round  40, Global train loss: 0.583, Global test loss: 0.710, Global test accuracy: 76.85
Round  41, Train loss: 0.561, Test loss: 0.943, Test accuracy: 71.14
Round  41, Global train loss: 0.561, Global test loss: 0.709, Global test accuracy: 77.14
Round  42, Train loss: 0.576, Test loss: 0.939, Test accuracy: 71.23
Round  42, Global train loss: 0.576, Global test loss: 0.702, Global test accuracy: 77.20
Round  43, Train loss: 0.579, Test loss: 0.936, Test accuracy: 71.39
Round  43, Global train loss: 0.579, Global test loss: 0.702, Global test accuracy: 76.91
Round  44, Train loss: 0.541, Test loss: 0.939, Test accuracy: 71.20
Round  44, Global train loss: 0.541, Global test loss: 0.713, Global test accuracy: 76.83
Round  45, Train loss: 0.560, Test loss: 0.926, Test accuracy: 71.52
Round  45, Global train loss: 0.560, Global test loss: 0.708, Global test accuracy: 76.81
Round  46, Train loss: 0.549, Test loss: 0.926, Test accuracy: 71.52
Round  46, Global train loss: 0.549, Global test loss: 0.709, Global test accuracy: 77.05
Round  47, Train loss: 0.548, Test loss: 0.923, Test accuracy: 71.64
Round  47, Global train loss: 0.548, Global test loss: 0.705, Global test accuracy: 77.30
Round  48, Train loss: 0.557, Test loss: 0.922, Test accuracy: 71.73
Round  48, Global train loss: 0.557, Global test loss: 0.702, Global test accuracy: 77.28
Round  49, Train loss: 0.518, Test loss: 0.922, Test accuracy: 71.98
Round  49, Global train loss: 0.518, Global test loss: 0.715, Global test accuracy: 77.05
Round  50, Train loss: 0.550, Test loss: 0.924, Test accuracy: 72.18
Round  50, Global train loss: 0.550, Global test loss: 0.709, Global test accuracy: 77.18
Round  51, Train loss: 0.530, Test loss: 0.931, Test accuracy: 72.12
Round  51, Global train loss: 0.530, Global test loss: 0.711, Global test accuracy: 76.75
Round  52, Train loss: 0.540, Test loss: 0.929, Test accuracy: 72.14
Round  52, Global train loss: 0.540, Global test loss: 0.699, Global test accuracy: 77.09
Round  53, Train loss: 0.511, Test loss: 0.933, Test accuracy: 72.21
Round  53, Global train loss: 0.511, Global test loss: 0.712, Global test accuracy: 76.90
Round  54, Train loss: 0.522, Test loss: 0.934, Test accuracy: 72.31
Round  54, Global train loss: 0.522, Global test loss: 0.706, Global test accuracy: 77.37
Round  55, Train loss: 0.509, Test loss: 0.929, Test accuracy: 72.33
Round  55, Global train loss: 0.509, Global test loss: 0.715, Global test accuracy: 77.41
Round  56, Train loss: 0.518, Test loss: 0.924, Test accuracy: 72.31
Round  56, Global train loss: 0.518, Global test loss: 0.703, Global test accuracy: 77.33
Round  57, Train loss: 0.485, Test loss: 0.922, Test accuracy: 72.37
Round  57, Global train loss: 0.485, Global test loss: 0.714, Global test accuracy: 77.57
Round  58, Train loss: 0.507, Test loss: 0.918, Test accuracy: 72.47
Round  58, Global train loss: 0.507, Global test loss: 0.710, Global test accuracy: 77.35
Round  59, Train loss: 0.484, Test loss: 0.925, Test accuracy: 72.64
Round  59, Global train loss: 0.484, Global test loss: 0.707, Global test accuracy: 77.57
Round  60, Train loss: 0.478, Test loss: 0.928, Test accuracy: 72.84
Round  60, Global train loss: 0.478, Global test loss: 0.714, Global test accuracy: 77.40
Round  61, Train loss: 0.463, Test loss: 0.935, Test accuracy: 72.61
Round  61, Global train loss: 0.463, Global test loss: 0.726, Global test accuracy: 77.27
Round  62, Train loss: 0.473, Test loss: 0.946, Test accuracy: 72.48
Round  62, Global train loss: 0.473, Global test loss: 0.724, Global test accuracy: 77.57
Round  63, Train loss: 0.499, Test loss: 0.936, Test accuracy: 72.59
Round  63, Global train loss: 0.499, Global test loss: 0.712, Global test accuracy: 77.40
Round  64, Train loss: 0.465, Test loss: 0.933, Test accuracy: 72.78
Round  64, Global train loss: 0.465, Global test loss: 0.725, Global test accuracy: 77.19
Round  65, Train loss: 0.451, Test loss: 0.937, Test accuracy: 72.54
Round  65, Global train loss: 0.451, Global test loss: 0.728, Global test accuracy: 77.20
Round  66, Train loss: 0.455, Test loss: 0.939, Test accuracy: 72.64
Round  66, Global train loss: 0.455, Global test loss: 0.733, Global test accuracy: 77.53
Round  67, Train loss: 0.516, Test loss: 0.937, Test accuracy: 72.71
Round  67, Global train loss: 0.516, Global test loss: 0.704, Global test accuracy: 77.77
Round  68, Train loss: 0.452, Test loss: 0.944, Test accuracy: 72.64
Round  68, Global train loss: 0.452, Global test loss: 0.714, Global test accuracy: 77.57
Round  69, Train loss: 0.472, Test loss: 0.947, Test accuracy: 72.67
Round  69, Global train loss: 0.472, Global test loss: 0.713, Global test accuracy: 77.76
Round  70, Train loss: 0.478, Test loss: 0.939, Test accuracy: 72.84
Round  70, Global train loss: 0.478, Global test loss: 0.698, Global test accuracy: 77.75
Round  71, Train loss: 0.462, Test loss: 0.938, Test accuracy: 72.90
Round  71, Global train loss: 0.462, Global test loss: 0.713, Global test accuracy: 77.48
Round  72, Train loss: 0.449, Test loss: 0.933, Test accuracy: 73.14
Round  72, Global train loss: 0.449, Global test loss: 0.736, Global test accuracy: 77.30
Round  73, Train loss: 0.456, Test loss: 0.937, Test accuracy: 73.12
Round  73, Global train loss: 0.456, Global test loss: 0.710, Global test accuracy: 77.55
Round  74, Train loss: 0.437, Test loss: 0.939, Test accuracy: 73.35
Round  74, Global train loss: 0.437, Global test loss: 0.720, Global test accuracy: 77.75
Round  75, Train loss: 0.436, Test loss: 0.930, Test accuracy: 73.38
Round  75, Global train loss: 0.436, Global test loss: 0.723, Global test accuracy: 77.55
Round  76, Train loss: 0.450, Test loss: 0.921, Test accuracy: 73.52
Round  76, Global train loss: 0.450, Global test loss: 0.711, Global test accuracy: 77.64
Round  77, Train loss: 0.437, Test loss: 0.927, Test accuracy: 73.36
Round  77, Global train loss: 0.437, Global test loss: 0.715, Global test accuracy: 77.86
Round  78, Train loss: 0.447, Test loss: 0.930, Test accuracy: 73.30
Round  78, Global train loss: 0.447, Global test loss: 0.711, Global test accuracy: 78.03
Round  79, Train loss: 0.429, Test loss: 0.931, Test accuracy: 73.22
Round  79, Global train loss: 0.429, Global test loss: 0.729, Global test accuracy: 77.32
Round  80, Train loss: 0.434, Test loss: 0.929, Test accuracy: 73.33
Round  80, Global train loss: 0.434, Global test loss: 0.715, Global test accuracy: 77.51
Round  81, Train loss: 0.431, Test loss: 0.934, Test accuracy: 73.33
Round  81, Global train loss: 0.431, Global test loss: 0.707, Global test accuracy: 77.97
Round  82, Train loss: 0.468, Test loss: 0.938, Test accuracy: 73.36
Round  82, Global train loss: 0.468, Global test loss: 0.713, Global test accuracy: 78.14
Round  83, Train loss: 0.434, Test loss: 0.945, Test accuracy: 73.24
Round  83, Global train loss: 0.434, Global test loss: 0.727, Global test accuracy: 77.90
Round  84, Train loss: 0.435, Test loss: 0.941, Test accuracy: 73.36
Round  84, Global train loss: 0.435, Global test loss: 0.717, Global test accuracy: 77.87
Round  85, Train loss: 0.451, Test loss: 0.939, Test accuracy: 73.35
Round  85, Global train loss: 0.451, Global test loss: 0.707, Global test accuracy: 78.36
Round  86, Train loss: 0.424, Test loss: 0.936, Test accuracy: 73.42
Round  86, Global train loss: 0.424, Global test loss: 0.712, Global test accuracy: 78.07
Round  87, Train loss: 0.411, Test loss: 0.933, Test accuracy: 73.56
Round  87, Global train loss: 0.411, Global test loss: 0.711, Global test accuracy: 78.50
Round  88, Train loss: 0.395, Test loss: 0.936, Test accuracy: 73.58
Round  88, Global train loss: 0.395, Global test loss: 0.731, Global test accuracy: 78.09
Round  89, Train loss: 0.383, Test loss: 0.949, Test accuracy: 73.36
Round  89, Global train loss: 0.383, Global test loss: 0.751, Global test accuracy: 77.44
Round  90, Train loss: 0.428, Test loss: 0.953, Test accuracy: 73.31
Round  90, Global train loss: 0.428, Global test loss: 0.722, Global test accuracy: 78.14
Round  91, Train loss: 0.412, Test loss: 0.961, Test accuracy: 73.44
Round  91, Global train loss: 0.412, Global test loss: 0.739, Global test accuracy: 78.29
Round  92, Train loss: 0.415, Test loss: 0.960, Test accuracy: 73.51
Round  92, Global train loss: 0.415, Global test loss: 0.735, Global test accuracy: 78.51
Round  93, Train loss: 0.394, Test loss: 0.953, Test accuracy: 73.63
Round  93, Global train loss: 0.394, Global test loss: 0.736, Global test accuracy: 78.35
Round  94, Train loss: 0.440, Test loss: 0.955, Test accuracy: 73.57
Round  94, Global train loss: 0.440, Global test loss: 0.715, Global test accuracy: 78.31
Round  95, Train loss: 0.416, Test loss: 0.956, Test accuracy: 73.58
Round  95, Global train loss: 0.416, Global test loss: 0.711, Global test accuracy: 78.64
Round  96, Train loss: 0.431, Test loss: 0.950, Test accuracy: 73.75
Round  96, Global train loss: 0.431, Global test loss: 0.717, Global test accuracy: 78.70
Round  97, Train loss: 0.388, Test loss: 0.953, Test accuracy: 73.86
Round  97, Global train loss: 0.388, Global test loss: 0.715, Global test accuracy: 78.81
Round  98, Train loss: 0.399, Test loss: 0.955, Test accuracy: 73.72
Round  98, Global train loss: 0.399, Global test loss: 0.718, Global test accuracy: 78.39
Round  99, Train loss: 0.385, Test loss: 0.959, Test accuracy: 73.82
Round  99, Global train loss: 0.385, Global test loss: 0.722, Global test accuracy: 78.72
Final Round, Train loss: 0.238, Test loss: 1.034, Test accuracy: 74.89
Final Round, Global train loss: 0.238, Global test loss: 0.722, Global test accuracy: 78.72
Average accuracy final 10 rounds: 73.61800000000001 

Average global accuracy final 10 rounds: 78.488 

6841.469348192215
[4.890831708908081, 9.781663417816162, 14.501786708831787, 19.221909999847412, 23.95561194419861, 28.689313888549805, 33.51428818702698, 38.33926248550415, 43.54002046585083, 48.74077844619751, 53.78035831451416, 58.81993818283081, 63.59313201904297, 68.36632585525513, 73.21418190002441, 78.0620379447937, 82.90433979034424, 87.74664163589478, 92.56364870071411, 97.38065576553345, 102.21705341339111, 107.05345106124878, 111.85258054733276, 116.65171003341675, 121.42409944534302, 126.19648885726929, 130.89701652526855, 135.59754419326782, 140.27564430236816, 144.9537444114685, 150.16143822669983, 155.36913204193115, 160.30890083312988, 165.2486696243286, 170.0132613182068, 174.77785301208496, 179.83786582946777, 184.8978786468506, 189.6446533203125, 194.3914279937744, 199.14665627479553, 203.90188455581665, 208.65996479988098, 213.4180450439453, 218.20174288749695, 222.98544073104858, 228.01551342010498, 233.04558610916138, 238.01771712303162, 242.98984813690186, 248.0491669178009, 253.10848569869995, 258.1662893295288, 263.22409296035767, 267.9761583805084, 272.7282238006592, 277.5229105949402, 282.3175973892212, 287.0795021057129, 291.8414068222046, 296.6036398410797, 301.36587285995483, 306.22212767601013, 311.07838249206543, 316.2564465999603, 321.4345107078552, 326.5908131599426, 331.74711561203003, 336.8310890197754, 341.91506242752075, 346.7015414237976, 351.48802042007446, 356.29022312164307, 361.09242582321167, 365.87794852256775, 370.6634712219238, 375.52315044403076, 380.3828296661377, 385.1545729637146, 389.9263162612915, 394.79682302474976, 399.667329788208, 404.5335659980774, 409.3998022079468, 414.2278060913086, 419.0558099746704, 423.8605046272278, 428.66519927978516, 433.4715986251831, 438.27799797058105, 443.0680570602417, 447.85811614990234, 452.67409014701843, 457.4900641441345, 462.3249876499176, 467.1599111557007, 471.9335677623749, 476.7072243690491, 481.419899225235, 486.1325740814209, 490.90953946113586, 495.68650484085083, 500.44477009773254, 505.20303535461426, 509.986941576004, 514.7708477973938, 519.9349489212036, 525.0990500450134, 529.8512101173401, 534.6033701896667, 539.3329975605011, 544.0626249313354, 548.8621847629547, 553.661744594574, 558.4066524505615, 563.1515603065491, 567.988067150116, 572.8245739936829, 577.6581408977509, 582.4917078018188, 587.2282521724701, 591.9647965431213, 596.7943961620331, 601.6239957809448, 606.4913721084595, 611.3587484359741, 616.183678150177, 621.0086078643799, 625.7917563915253, 630.5749049186707, 635.3475675582886, 640.1202301979065, 644.9410102367401, 649.7617902755737, 654.5876324176788, 659.4134745597839, 664.2967050075531, 669.1799354553223, 674.1587941646576, 679.1376528739929, 684.1227254867554, 689.1077980995178, 693.9544208049774, 698.801043510437, 703.5759220123291, 708.3508005142212, 713.0983448028564, 717.8458890914917, 722.9057013988495, 727.9655137062073, 732.8183608055115, 737.6712079048157, 742.7591888904572, 747.8471698760986, 753.0491766929626, 758.2511835098267, 763.2084305286407, 768.1656775474548, 773.1609551906586, 778.1562328338623, 783.3386833667755, 788.5211338996887, 793.6579036712646, 798.7946734428406, 803.6810235977173, 808.567373752594, 813.4438421726227, 818.3203105926514, 823.0990397930145, 827.8777689933777, 832.59983253479, 837.3218960762024, 841.9238684177399, 846.5258407592773, 851.3108956813812, 856.0959506034851, 860.8862860202789, 865.6766214370728, 870.3187494277954, 874.9608774185181, 879.7013087272644, 884.4417400360107, 889.0630829334259, 893.6844258308411, 898.1420121192932, 902.5995984077454, 907.1637170314789, 911.7278356552124, 916.4696514606476, 921.2114672660828, 925.7320642471313, 930.2526612281799, 934.7851331233978, 939.3176050186157, 943.8450846672058, 948.3725643157959, 952.8749213218689, 957.3772783279419, 961.8894550800323, 966.4016318321228, 968.6848068237305, 970.9679818153381]
[37.3725, 37.3725, 44.8425, 44.8425, 48.225, 48.225, 50.03, 50.03, 52.0525, 52.0525, 52.9575, 52.9575, 53.75, 53.75, 55.6625, 55.6625, 56.625, 56.625, 57.455, 57.455, 58.835, 58.835, 60.605, 60.605, 61.83, 61.83, 62.3275, 62.3275, 63.89, 63.89, 64.6625, 64.6625, 64.85, 64.85, 65.545, 65.545, 65.9225, 65.9225, 66.5225, 66.5225, 66.8875, 66.8875, 67.35, 67.35, 67.61, 67.61, 67.835, 67.835, 68.355, 68.355, 68.8525, 68.8525, 68.8575, 68.8575, 68.81, 68.81, 69.1625, 69.1625, 69.3125, 69.3125, 69.2475, 69.2475, 69.875, 69.875, 69.7725, 69.7725, 69.9, 69.9, 70.2575, 70.2575, 70.4325, 70.4325, 70.555, 70.555, 70.79, 70.79, 70.91, 70.91, 70.8625, 70.8625, 70.8975, 70.8975, 71.1375, 71.1375, 71.23, 71.23, 71.395, 71.395, 71.205, 71.205, 71.52, 71.52, 71.5225, 71.5225, 71.635, 71.635, 71.7275, 71.7275, 71.985, 71.985, 72.18, 72.18, 72.12, 72.12, 72.1375, 72.1375, 72.2125, 72.2125, 72.3125, 72.3125, 72.33, 72.33, 72.3075, 72.3075, 72.3725, 72.3725, 72.47, 72.47, 72.645, 72.645, 72.84, 72.84, 72.61, 72.61, 72.4825, 72.4825, 72.59, 72.59, 72.7775, 72.7775, 72.54, 72.54, 72.645, 72.645, 72.7075, 72.7075, 72.6425, 72.6425, 72.6725, 72.6725, 72.8425, 72.8425, 72.9025, 72.9025, 73.14, 73.14, 73.12, 73.12, 73.3475, 73.3475, 73.3775, 73.3775, 73.5175, 73.5175, 73.36, 73.36, 73.295, 73.295, 73.2225, 73.2225, 73.325, 73.325, 73.33, 73.33, 73.355, 73.355, 73.2375, 73.2375, 73.365, 73.365, 73.3475, 73.3475, 73.425, 73.425, 73.56, 73.56, 73.585, 73.585, 73.3625, 73.3625, 73.3075, 73.3075, 73.4375, 73.4375, 73.5125, 73.5125, 73.63, 73.63, 73.57, 73.57, 73.575, 73.575, 73.7475, 73.7475, 73.855, 73.855, 73.725, 73.725, 73.82, 73.82, 74.885, 74.885]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.061, Test loss: 1.851, Test accuracy: 35.29
Round   0, Global train loss: 2.061, Global test loss: 1.847, Global test accuracy: 36.61
Round   1, Train loss: 1.810, Test loss: 1.682, Test accuracy: 38.81
Round   1, Global train loss: 1.810, Global test loss: 1.614, Global test accuracy: 41.23
Round   2, Train loss: 1.685, Test loss: 1.616, Test accuracy: 40.80
Round   2, Global train loss: 1.685, Global test loss: 1.497, Global test accuracy: 45.80
Round   3, Train loss: 1.613, Test loss: 1.562, Test accuracy: 42.89
Round   3, Global train loss: 1.613, Global test loss: 1.439, Global test accuracy: 48.42
Round   4, Train loss: 1.543, Test loss: 1.524, Test accuracy: 44.44
Round   4, Global train loss: 1.543, Global test loss: 1.347, Global test accuracy: 52.67
Round   5, Train loss: 1.487, Test loss: 1.504, Test accuracy: 45.08
Round   5, Global train loss: 1.487, Global test loss: 1.293, Global test accuracy: 53.92
Round   6, Train loss: 1.442, Test loss: 1.474, Test accuracy: 46.09
Round   6, Global train loss: 1.442, Global test loss: 1.241, Global test accuracy: 56.54
Round   7, Train loss: 1.377, Test loss: 1.416, Test accuracy: 48.45
Round   7, Global train loss: 1.377, Global test loss: 1.196, Global test accuracy: 57.87
Round   8, Train loss: 1.335, Test loss: 1.396, Test accuracy: 49.27
Round   8, Global train loss: 1.335, Global test loss: 1.163, Global test accuracy: 58.78
Round   9, Train loss: 1.310, Test loss: 1.377, Test accuracy: 50.05
Round   9, Global train loss: 1.310, Global test loss: 1.133, Global test accuracy: 60.42
Round  10, Train loss: 1.273, Test loss: 1.351, Test accuracy: 51.14
Round  10, Global train loss: 1.273, Global test loss: 1.112, Global test accuracy: 61.12
Round  11, Train loss: 1.250, Test loss: 1.292, Test accuracy: 53.73
Round  11, Global train loss: 1.250, Global test loss: 1.075, Global test accuracy: 62.65
Round  12, Train loss: 1.207, Test loss: 1.244, Test accuracy: 55.63
Round  12, Global train loss: 1.207, Global test loss: 1.056, Global test accuracy: 63.59
Round  13, Train loss: 1.191, Test loss: 1.234, Test accuracy: 56.00
Round  13, Global train loss: 1.191, Global test loss: 1.035, Global test accuracy: 64.27
Round  14, Train loss: 1.143, Test loss: 1.203, Test accuracy: 57.52
Round  14, Global train loss: 1.143, Global test loss: 1.016, Global test accuracy: 64.11
Round  15, Train loss: 1.140, Test loss: 1.177, Test accuracy: 58.31
Round  15, Global train loss: 1.140, Global test loss: 0.995, Global test accuracy: 65.04
Round  16, Train loss: 1.118, Test loss: 1.177, Test accuracy: 58.33
Round  16, Global train loss: 1.118, Global test loss: 0.975, Global test accuracy: 66.21
Round  17, Train loss: 1.085, Test loss: 1.147, Test accuracy: 59.47
Round  17, Global train loss: 1.085, Global test loss: 0.956, Global test accuracy: 67.08
Round  18, Train loss: 1.055, Test loss: 1.141, Test accuracy: 59.67
Round  18, Global train loss: 1.055, Global test loss: 0.937, Global test accuracy: 67.86
Round  19, Train loss: 1.071, Test loss: 1.122, Test accuracy: 60.52
Round  19, Global train loss: 1.071, Global test loss: 0.927, Global test accuracy: 68.17
Round  20, Train loss: 1.028, Test loss: 1.108, Test accuracy: 61.15
Round  20, Global train loss: 1.028, Global test loss: 0.918, Global test accuracy: 68.04
Round  21, Train loss: 1.017, Test loss: 1.104, Test accuracy: 61.44
Round  21, Global train loss: 1.017, Global test loss: 0.905, Global test accuracy: 69.03
Round  22, Train loss: 0.995, Test loss: 1.079, Test accuracy: 62.45
Round  22, Global train loss: 0.995, Global test loss: 0.896, Global test accuracy: 69.57
Round  23, Train loss: 0.981, Test loss: 1.051, Test accuracy: 63.60
Round  23, Global train loss: 0.981, Global test loss: 0.875, Global test accuracy: 70.34
Round  24, Train loss: 0.969, Test loss: 1.041, Test accuracy: 64.06
Round  24, Global train loss: 0.969, Global test loss: 0.873, Global test accuracy: 70.16
Round  25, Train loss: 0.961, Test loss: 1.024, Test accuracy: 64.63
Round  25, Global train loss: 0.961, Global test loss: 0.857, Global test accuracy: 70.69
Round  26, Train loss: 0.948, Test loss: 1.012, Test accuracy: 65.15
Round  26, Global train loss: 0.948, Global test loss: 0.858, Global test accuracy: 70.79
Round  27, Train loss: 0.932, Test loss: 1.004, Test accuracy: 65.41
Round  27, Global train loss: 0.932, Global test loss: 0.846, Global test accuracy: 71.13
Round  28, Train loss: 0.902, Test loss: 1.001, Test accuracy: 65.47
Round  28, Global train loss: 0.902, Global test loss: 0.841, Global test accuracy: 71.23
Round  29, Train loss: 0.891, Test loss: 1.003, Test accuracy: 65.36
Round  29, Global train loss: 0.891, Global test loss: 0.844, Global test accuracy: 71.27
Round  30, Train loss: 0.872, Test loss: 1.005, Test accuracy: 65.30
Round  30, Global train loss: 0.872, Global test loss: 0.837, Global test accuracy: 71.13
Round  31, Train loss: 0.869, Test loss: 1.010, Test accuracy: 65.34
Round  31, Global train loss: 0.869, Global test loss: 0.819, Global test accuracy: 71.86
Round  32, Train loss: 0.895, Test loss: 0.979, Test accuracy: 66.47
Round  32, Global train loss: 0.895, Global test loss: 0.814, Global test accuracy: 72.14
Round  33, Train loss: 0.856, Test loss: 0.973, Test accuracy: 66.71
Round  33, Global train loss: 0.856, Global test loss: 0.805, Global test accuracy: 72.69
Round  34, Train loss: 0.861, Test loss: 0.969, Test accuracy: 67.19
Round  34, Global train loss: 0.861, Global test loss: 0.808, Global test accuracy: 73.01
Round  35, Train loss: 0.846, Test loss: 0.966, Test accuracy: 67.27
Round  35, Global train loss: 0.846, Global test loss: 0.793, Global test accuracy: 73.11
Round  36, Train loss: 0.830, Test loss: 0.955, Test accuracy: 67.56
Round  36, Global train loss: 0.830, Global test loss: 0.784, Global test accuracy: 72.85
Round  37, Train loss: 0.813, Test loss: 0.947, Test accuracy: 67.81
Round  37, Global train loss: 0.813, Global test loss: 0.794, Global test accuracy: 72.90
Round  38, Train loss: 0.814, Test loss: 0.952, Test accuracy: 67.69
Round  38, Global train loss: 0.814, Global test loss: 0.796, Global test accuracy: 72.95
Round  39, Train loss: 0.801, Test loss: 0.936, Test accuracy: 68.25
Round  39, Global train loss: 0.801, Global test loss: 0.780, Global test accuracy: 73.36
Round  40, Train loss: 0.795, Test loss: 0.946, Test accuracy: 67.93
Round  40, Global train loss: 0.795, Global test loss: 0.781, Global test accuracy: 73.42
Round  41, Train loss: 0.791, Test loss: 0.938, Test accuracy: 68.32
Round  41, Global train loss: 0.791, Global test loss: 0.773, Global test accuracy: 73.83
Round  42, Train loss: 0.790, Test loss: 0.929, Test accuracy: 68.54
Round  42, Global train loss: 0.790, Global test loss: 0.773, Global test accuracy: 73.75
Round  43, Train loss: 0.781, Test loss: 0.926, Test accuracy: 68.59
Round  43, Global train loss: 0.781, Global test loss: 0.757, Global test accuracy: 74.09
Round  44, Train loss: 0.776, Test loss: 0.923, Test accuracy: 68.72
Round  44, Global train loss: 0.776, Global test loss: 0.766, Global test accuracy: 73.95
Round  45, Train loss: 0.767, Test loss: 0.925, Test accuracy: 68.54
Round  45, Global train loss: 0.767, Global test loss: 0.758, Global test accuracy: 74.18
Round  46, Train loss: 0.746, Test loss: 0.915, Test accuracy: 68.96
Round  46, Global train loss: 0.746, Global test loss: 0.756, Global test accuracy: 74.62
Round  47, Train loss: 0.739, Test loss: 0.907, Test accuracy: 69.19
Round  47, Global train loss: 0.739, Global test loss: 0.750, Global test accuracy: 74.27
Round  48, Train loss: 0.752, Test loss: 0.910, Test accuracy: 69.42
Round  48, Global train loss: 0.752, Global test loss: 0.761, Global test accuracy: 74.48
Round  49, Train loss: 0.746, Test loss: 0.896, Test accuracy: 69.99
Round  49, Global train loss: 0.746, Global test loss: 0.748, Global test accuracy: 74.69
Round  50, Train loss: 0.740, Test loss: 0.894, Test accuracy: 70.08
Round  50, Global train loss: 0.740, Global test loss: 0.742, Global test accuracy: 74.64
Round  51, Train loss: 0.725, Test loss: 0.898, Test accuracy: 70.12
Round  51, Global train loss: 0.725, Global test loss: 0.750, Global test accuracy: 74.86
Round  52, Train loss: 0.719, Test loss: 0.905, Test accuracy: 69.89
Round  52, Global train loss: 0.719, Global test loss: 0.744, Global test accuracy: 74.84
Round  53, Train loss: 0.709, Test loss: 0.906, Test accuracy: 70.03
Round  53, Global train loss: 0.709, Global test loss: 0.744, Global test accuracy: 74.71
Round  54, Train loss: 0.711, Test loss: 0.903, Test accuracy: 70.03
Round  54, Global train loss: 0.711, Global test loss: 0.736, Global test accuracy: 74.98
Round  55, Train loss: 0.672, Test loss: 0.903, Test accuracy: 70.01
Round  55, Global train loss: 0.672, Global test loss: 0.746, Global test accuracy: 74.26
Round  56, Train loss: 0.681, Test loss: 0.885, Test accuracy: 70.59
Round  56, Global train loss: 0.681, Global test loss: 0.731, Global test accuracy: 75.29
Round  57, Train loss: 0.686, Test loss: 0.894, Test accuracy: 70.46
Round  57, Global train loss: 0.686, Global test loss: 0.734, Global test accuracy: 75.28
Round  58, Train loss: 0.669, Test loss: 0.888, Test accuracy: 70.59
Round  58, Global train loss: 0.669, Global test loss: 0.737, Global test accuracy: 75.11
Round  59, Train loss: 0.661, Test loss: 0.885, Test accuracy: 70.59
Round  59, Global train loss: 0.661, Global test loss: 0.728, Global test accuracy: 75.67
Round  60, Train loss: 0.661, Test loss: 0.889, Test accuracy: 70.67
Round  60, Global train loss: 0.661, Global test loss: 0.729, Global test accuracy: 75.74
Round  61, Train loss: 0.659, Test loss: 0.890, Test accuracy: 70.88
Round  61, Global train loss: 0.659, Global test loss: 0.735, Global test accuracy: 75.46
Round  62, Train loss: 0.654, Test loss: 0.885, Test accuracy: 70.95
Round  62, Global train loss: 0.654, Global test loss: 0.725, Global test accuracy: 75.59
Round  63, Train loss: 0.637, Test loss: 0.886, Test accuracy: 70.87
Round  63, Global train loss: 0.637, Global test loss: 0.730, Global test accuracy: 75.34
Round  64, Train loss: 0.633, Test loss: 0.888, Test accuracy: 70.92
Round  64, Global train loss: 0.633, Global test loss: 0.720, Global test accuracy: 75.97
Round  65, Train loss: 0.633, Test loss: 0.888, Test accuracy: 70.91
Round  65, Global train loss: 0.633, Global test loss: 0.722, Global test accuracy: 75.91
Round  66, Train loss: 0.633, Test loss: 0.896, Test accuracy: 70.83
Round  66, Global train loss: 0.633, Global test loss: 0.739, Global test accuracy: 75.42
Round  67, Train loss: 0.619, Test loss: 0.894, Test accuracy: 71.00
Round  67, Global train loss: 0.619, Global test loss: 0.729, Global test accuracy: 75.88
Round  68, Train loss: 0.629, Test loss: 0.888, Test accuracy: 71.12
Round  68, Global train loss: 0.629, Global test loss: 0.725, Global test accuracy: 75.62
Round  69, Train loss: 0.636, Test loss: 0.887, Test accuracy: 71.20
Round  69, Global train loss: 0.636, Global test loss: 0.725, Global test accuracy: 75.84
Round  70, Train loss: 0.636, Test loss: 0.890, Test accuracy: 71.23
Round  70, Global train loss: 0.636, Global test loss: 0.715, Global test accuracy: 76.13
Round  71, Train loss: 0.591, Test loss: 0.891, Test accuracy: 71.06
Round  71, Global train loss: 0.591, Global test loss: 0.718, Global test accuracy: 76.22
Round  72, Train loss: 0.678, Test loss: 0.882, Test accuracy: 71.43
Round  72, Global train loss: 0.678, Global test loss: 0.704, Global test accuracy: 76.29
Round  73, Train loss: 0.618, Test loss: 0.868, Test accuracy: 71.81
Round  73, Global train loss: 0.618, Global test loss: 0.708, Global test accuracy: 75.92
Round  74, Train loss: 0.604, Test loss: 0.856, Test accuracy: 72.00
Round  74, Global train loss: 0.604, Global test loss: 0.710, Global test accuracy: 76.30
Round  75, Train loss: 0.633, Test loss: 0.860, Test accuracy: 72.09
Round  75, Global train loss: 0.633, Global test loss: 0.728, Global test accuracy: 75.91
Round  76, Train loss: 0.582, Test loss: 0.861, Test accuracy: 72.06
Round  76, Global train loss: 0.582, Global test loss: 0.714, Global test accuracy: 76.85
Round  77, Train loss: 0.606, Test loss: 0.864, Test accuracy: 72.08
Round  77, Global train loss: 0.606, Global test loss: 0.708, Global test accuracy: 76.79
Round  78, Train loss: 0.602, Test loss: 0.864, Test accuracy: 71.93
Round  78, Global train loss: 0.602, Global test loss: 0.704, Global test accuracy: 76.90
Round  79, Train loss: 0.601, Test loss: 0.862, Test accuracy: 72.07
Round  79, Global train loss: 0.601, Global test loss: 0.716, Global test accuracy: 76.22
Round  80, Train loss: 0.605, Test loss: 0.865, Test accuracy: 72.05
Round  80, Global train loss: 0.605, Global test loss: 0.704, Global test accuracy: 76.38
Round  81, Train loss: 0.611, Test loss: 0.863, Test accuracy: 72.33
Round  81, Global train loss: 0.611, Global test loss: 0.693, Global test accuracy: 77.03
Round  82, Train loss: 0.575, Test loss: 0.882, Test accuracy: 71.92
Round  82, Global train loss: 0.575, Global test loss: 0.720, Global test accuracy: 75.84
Round  83, Train loss: 0.612, Test loss: 0.877, Test accuracy: 72.07
Round  83, Global train loss: 0.612, Global test loss: 0.702, Global test accuracy: 76.84
Round  84, Train loss: 0.573, Test loss: 0.860, Test accuracy: 72.43
Round  84, Global train loss: 0.573, Global test loss: 0.698, Global test accuracy: 77.03
Round  85, Train loss: 0.584, Test loss: 0.858, Test accuracy: 72.40
Round  85, Global train loss: 0.584, Global test loss: 0.700, Global test accuracy: 76.86
Round  86, Train loss: 0.554, Test loss: 0.855, Test accuracy: 72.56
Round  86, Global train loss: 0.554, Global test loss: 0.705, Global test accuracy: 76.83
Round  87, Train loss: 0.553, Test loss: 0.863, Test accuracy: 72.53
Round  87, Global train loss: 0.553, Global test loss: 0.712, Global test accuracy: 77.00
Round  88, Train loss: 0.559, Test loss: 0.868, Test accuracy: 72.63
Round  88, Global train loss: 0.559, Global test loss: 0.711, Global test accuracy: 76.73
Round  89, Train loss: 0.552, Test loss: 0.873, Test accuracy: 72.42
Round  89, Global train loss: 0.552, Global test loss: 0.719, Global test accuracy: 76.60
Round  90, Train loss: 0.565, Test loss: 0.877, Test accuracy: 72.25
Round  90, Global train loss: 0.565, Global test loss: 0.716, Global test accuracy: 76.84
Round  91, Train loss: 0.535, Test loss: 0.867, Test accuracy: 72.58
Round  91, Global train loss: 0.535, Global test loss: 0.715, Global test accuracy: 76.99
Round  92, Train loss: 0.537, Test loss: 0.870, Test accuracy: 72.56
Round  92, Global train loss: 0.537, Global test loss: 0.711, Global test accuracy: 76.75
Round  93, Train loss: 0.549, Test loss: 0.869, Test accuracy: 72.64
Round  93, Global train loss: 0.549, Global test loss: 0.713, Global test accuracy: 76.96
Round  94, Train loss: 0.575, Test loss: 0.865, Test accuracy: 72.80
Round  94, Global train loss: 0.575, Global test loss: 0.698, Global test accuracy: 76.97
Round  95, Train loss: 0.577, Test loss: 0.861, Test accuracy: 72.98
Round  95, Global train loss: 0.577, Global test loss: 0.709, Global test accuracy: 77.00/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  96, Train loss: 0.554, Test loss: 0.854, Test accuracy: 73.12
Round  96, Global train loss: 0.554, Global test loss: 0.700, Global test accuracy: 76.95
Round  97, Train loss: 0.552, Test loss: 0.852, Test accuracy: 73.13
Round  97, Global train loss: 0.552, Global test loss: 0.704, Global test accuracy: 76.75
Round  98, Train loss: 0.540, Test loss: 0.857, Test accuracy: 72.96
Round  98, Global train loss: 0.540, Global test loss: 0.702, Global test accuracy: 77.25
Round  99, Train loss: 0.576, Test loss: 0.854, Test accuracy: 73.06
Round  99, Global train loss: 0.576, Global test loss: 0.698, Global test accuracy: 76.96
Final Round, Train loss: 0.354, Test loss: 0.963, Test accuracy: 72.82
Final Round, Global train loss: 0.354, Global test loss: 0.698, Global test accuracy: 76.96
Average accuracy final 10 rounds: 72.80750000000002 

Average global accuracy final 10 rounds: 76.94275 

6798.677043676376
[5.643629550933838, 11.287259101867676, 16.16043782234192, 21.033616542816162, 25.903236627578735, 30.77285671234131, 35.480207204818726, 40.18755769729614, 44.94477963447571, 49.70200157165527, 54.57335901260376, 59.444716453552246, 64.80357551574707, 70.1624345779419, 75.566171169281, 80.96990776062012, 86.36894631385803, 91.76798486709595, 97.05297446250916, 102.33796405792236, 107.64684677124023, 112.9557294845581, 118.05044221878052, 123.14515495300293, 128.14881110191345, 133.15246725082397, 138.23135423660278, 143.3102412223816, 148.1763551235199, 153.0424690246582, 158.03742623329163, 163.03238344192505, 167.9196331501007, 172.80688285827637, 177.74752926826477, 182.68817567825317, 187.76074481010437, 192.83331394195557, 197.7860140800476, 202.73871421813965, 207.74972987174988, 212.7607455253601, 218.32416915893555, 223.887592792511, 229.4723665714264, 235.0571403503418, 240.42834448814392, 245.79954862594604, 251.13626146316528, 256.4729743003845, 261.8091838359833, 267.14539337158203, 272.6058897972107, 278.06638622283936, 283.45457434654236, 288.84276247024536, 294.34749150276184, 299.8522205352783, 305.4067349433899, 310.96124935150146, 316.4649739265442, 321.9686985015869, 327.4788372516632, 332.9889760017395, 338.27703309059143, 343.56509017944336, 348.60925245285034, 353.6534147262573, 358.6977467536926, 363.74207878112793, 368.64088892936707, 373.5396990776062, 378.6158814430237, 383.69206380844116, 388.52351474761963, 393.3549656867981, 398.3350610733032, 403.31515645980835, 408.2115886211395, 413.1080207824707, 418.04825615882874, 422.98849153518677, 428.06760716438293, 433.1467227935791, 438.1423306465149, 443.1379384994507, 448.1195938587189, 453.10124921798706, 458.1067223548889, 463.11219549179077, 468.01478147506714, 472.9173674583435, 477.76790976524353, 482.61845207214355, 487.6445617675781, 492.6706714630127, 497.707394361496, 502.74411725997925, 507.5538020133972, 512.3634867668152, 517.2711427211761, 522.1787986755371, 527.0536987781525, 531.9285988807678, 536.9964163303375, 542.0642337799072, 547.1789157390594, 552.2935976982117, 557.226363658905, 562.1591296195984, 567.0364389419556, 571.9137482643127, 576.9767460823059, 582.0397439002991, 587.1135494709015, 592.1873550415039, 597.0891237258911, 601.9908924102783, 606.965259552002, 611.9396266937256, 616.9748327732086, 622.0100388526917, 627.052277803421, 632.0945167541504, 637.0827081203461, 642.0708994865417, 647.118748664856, 652.1665978431702, 657.270263671875, 662.3739295005798, 667.4843602180481, 672.5947909355164, 677.4666588306427, 682.338526725769, 687.4160087108612, 692.4934906959534, 697.5876779556274, 702.6818652153015, 707.5528695583344, 712.4238739013672, 717.3520314693451, 722.280189037323, 727.3632616996765, 732.44633436203, 737.4992876052856, 742.5522408485413, 747.4214019775391, 752.2905631065369, 757.0849633216858, 761.8793635368347, 766.6677534580231, 771.4561433792114, 776.1921532154083, 780.9281630516052, 785.6486115455627, 790.3690600395203, 795.0668320655823, 799.7646040916443, 804.5233097076416, 809.2820153236389, 814.0045244693756, 818.7270336151123, 823.4543704986572, 828.1817073822021, 832.9015369415283, 837.6213665008545, 842.3063759803772, 846.9913854598999, 851.7361352443695, 856.4808850288391, 861.5086581707001, 866.536431312561, 871.5890729427338, 876.6417145729065, 881.6866602897644, 886.7316060066223, 891.7651886940002, 896.7987713813782, 901.8232569694519, 906.8477425575256, 911.9242744445801, 917.0008063316345, 921.8974339962006, 926.7940616607666, 931.6771042346954, 936.5601468086243, 941.4204714298248, 946.2807960510254, 951.1851761341095, 956.0895562171936, 961.1630177497864, 966.2364792823792, 971.0340571403503, 975.8316349983215, 980.6304721832275, 985.4293093681335, 990.2096920013428, 994.990074634552, 999.8177819252014, 1004.6454892158508, 1007.2315201759338, 1009.8175511360168]
[35.29, 35.29, 38.8075, 38.8075, 40.795, 40.795, 42.89, 42.89, 44.4375, 44.4375, 45.0825, 45.0825, 46.085, 46.085, 48.445, 48.445, 49.27, 49.27, 50.05, 50.05, 51.14, 51.14, 53.725, 53.725, 55.63, 55.63, 56.0025, 56.0025, 57.52, 57.52, 58.3075, 58.3075, 58.33, 58.33, 59.47, 59.47, 59.6725, 59.6725, 60.52, 60.52, 61.15, 61.15, 61.4375, 61.4375, 62.4475, 62.4475, 63.6, 63.6, 64.06, 64.06, 64.6325, 64.6325, 65.1525, 65.1525, 65.4075, 65.4075, 65.465, 65.465, 65.3575, 65.3575, 65.295, 65.295, 65.3375, 65.3375, 66.4725, 66.4725, 66.71, 66.71, 67.1875, 67.1875, 67.27, 67.27, 67.565, 67.565, 67.81, 67.81, 67.69, 67.69, 68.255, 68.255, 67.9325, 67.9325, 68.3175, 68.3175, 68.5425, 68.5425, 68.5875, 68.5875, 68.7175, 68.7175, 68.5375, 68.5375, 68.9575, 68.9575, 69.1925, 69.1925, 69.42, 69.42, 69.9925, 69.9925, 70.085, 70.085, 70.125, 70.125, 69.8925, 69.8925, 70.035, 70.035, 70.03, 70.03, 70.0125, 70.0125, 70.5875, 70.5875, 70.4625, 70.4625, 70.5925, 70.5925, 70.5925, 70.5925, 70.665, 70.665, 70.88, 70.88, 70.955, 70.955, 70.87, 70.87, 70.9175, 70.9175, 70.91, 70.91, 70.8325, 70.8325, 70.9975, 70.9975, 71.1175, 71.1175, 71.1975, 71.1975, 71.23, 71.23, 71.0625, 71.0625, 71.4325, 71.4325, 71.805, 71.805, 72.005, 72.005, 72.095, 72.095, 72.06, 72.06, 72.0825, 72.0825, 71.93, 71.93, 72.0725, 72.0725, 72.05, 72.05, 72.325, 72.325, 71.9225, 71.9225, 72.0675, 72.0675, 72.4275, 72.4275, 72.4, 72.4, 72.565, 72.565, 72.5325, 72.5325, 72.63, 72.63, 72.425, 72.425, 72.245, 72.245, 72.585, 72.585, 72.5575, 72.5575, 72.6375, 72.6375, 72.795, 72.795, 72.9825, 72.9825, 73.1175, 73.1175, 73.13, 73.13, 72.9625, 72.9625, 73.0625, 73.0625, 72.8175, 72.8175]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Co-teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 2.220, Test loss: 1.922, Test accuracy: 33.66
Round   1, Train loss: 1.849, Test loss: 1.627, Test accuracy: 42.81
Round   2, Train loss: 1.680, Test loss: 1.514, Test accuracy: 46.39
Round   3, Train loss: 1.585, Test loss: 1.419, Test accuracy: 50.78
Round   4, Train loss: 1.492, Test loss: 1.352, Test accuracy: 53.44
Round   5, Train loss: 1.427, Test loss: 1.279, Test accuracy: 55.63
Round   6, Train loss: 1.358, Test loss: 1.239, Test accuracy: 56.60
Round   7, Train loss: 1.304, Test loss: 1.197, Test accuracy: 58.77
Round   8, Train loss: 1.262, Test loss: 1.163, Test accuracy: 59.73
Round   9, Train loss: 1.228, Test loss: 1.142, Test accuracy: 60.81
Round  10, Train loss: 1.162, Test loss: 1.140, Test accuracy: 60.52
Round  11, Train loss: 1.138, Test loss: 1.120, Test accuracy: 60.99
Round  12, Train loss: 1.108, Test loss: 1.106, Test accuracy: 61.59
Round  13, Train loss: 1.099, Test loss: 1.074, Test accuracy: 62.60
Round  14, Train loss: 1.056, Test loss: 1.046, Test accuracy: 63.41
Round  15, Train loss: 1.046, Test loss: 1.024, Test accuracy: 64.12
Round  16, Train loss: 1.017, Test loss: 1.000, Test accuracy: 65.25
Round  17, Train loss: 0.995, Test loss: 0.948, Test accuracy: 67.12
Round  18, Train loss: 0.973, Test loss: 0.943, Test accuracy: 67.48
Round  19, Train loss: 0.945, Test loss: 0.928, Test accuracy: 68.40
Round  20, Train loss: 0.913, Test loss: 0.929, Test accuracy: 68.42
Round  21, Train loss: 0.925, Test loss: 0.891, Test accuracy: 69.86
Round  22, Train loss: 0.905, Test loss: 0.883, Test accuracy: 70.07
Round  23, Train loss: 0.899, Test loss: 0.860, Test accuracy: 70.43
Round  24, Train loss: 0.896, Test loss: 0.849, Test accuracy: 70.91
Round  25, Train loss: 0.850, Test loss: 0.851, Test accuracy: 70.97
Round  26, Train loss: 0.857, Test loss: 0.829, Test accuracy: 71.61
Round  27, Train loss: 0.823, Test loss: 0.828, Test accuracy: 71.86
Round  28, Train loss: 0.811, Test loss: 0.833, Test accuracy: 71.66
Round  29, Train loss: 0.844, Test loss: 0.811, Test accuracy: 72.14
Round  30, Train loss: 0.802, Test loss: 0.804, Test accuracy: 72.70
Round  31, Train loss: 0.791, Test loss: 0.809, Test accuracy: 72.50
Round  32, Train loss: 0.796, Test loss: 0.795, Test accuracy: 73.08
Round  33, Train loss: 0.764, Test loss: 0.792, Test accuracy: 72.83
Round  34, Train loss: 0.757, Test loss: 0.796, Test accuracy: 72.99
Round  35, Train loss: 0.760, Test loss: 0.795, Test accuracy: 72.89
Round  36, Train loss: 0.736, Test loss: 0.781, Test accuracy: 73.53
Round  37, Train loss: 0.724, Test loss: 0.789, Test accuracy: 72.98
Round  38, Train loss: 0.717, Test loss: 0.785, Test accuracy: 73.19
Round  39, Train loss: 0.724, Test loss: 0.771, Test accuracy: 73.89
Round  40, Train loss: 0.710, Test loss: 0.763, Test accuracy: 74.17
Round  41, Train loss: 0.704, Test loss: 0.791, Test accuracy: 73.03
Round  42, Train loss: 0.713, Test loss: 0.782, Test accuracy: 73.25
Round  43, Train loss: 0.708, Test loss: 0.786, Test accuracy: 73.38
Round  44, Train loss: 0.677, Test loss: 0.777, Test accuracy: 73.44
Round  45, Train loss: 0.708, Test loss: 0.761, Test accuracy: 74.30
Round  46, Train loss: 0.680, Test loss: 0.754, Test accuracy: 74.33
Round  47, Train loss: 0.658, Test loss: 0.751, Test accuracy: 74.78
Round  48, Train loss: 0.660, Test loss: 0.751, Test accuracy: 74.71
Round  49, Train loss: 0.690, Test loss: 0.740, Test accuracy: 75.25
Round  50, Train loss: 0.630, Test loss: 0.748, Test accuracy: 74.75
Round  51, Train loss: 0.657, Test loss: 0.744, Test accuracy: 75.07
Round  52, Train loss: 0.658, Test loss: 0.747, Test accuracy: 74.98
Round  53, Train loss: 0.649, Test loss: 0.731, Test accuracy: 75.58
Round  54, Train loss: 0.628, Test loss: 0.736, Test accuracy: 75.44
Round  55, Train loss: 0.621, Test loss: 0.732, Test accuracy: 75.21
Round  56, Train loss: 0.609, Test loss: 0.735, Test accuracy: 75.45
Round  57, Train loss: 0.634, Test loss: 0.741, Test accuracy: 75.07
Round  58, Train loss: 0.610, Test loss: 0.727, Test accuracy: 75.51
Round  59, Train loss: 0.622, Test loss: 0.718, Test accuracy: 75.86
Round  60, Train loss: 0.627, Test loss: 0.716, Test accuracy: 76.08
Round  61, Train loss: 0.576, Test loss: 0.724, Test accuracy: 75.95
Round  62, Train loss: 0.574, Test loss: 0.726, Test accuracy: 76.14
Round  63, Train loss: 0.567, Test loss: 0.733, Test accuracy: 75.94
Round  64, Train loss: 0.616, Test loss: 0.728, Test accuracy: 75.93
Round  65, Train loss: 0.590, Test loss: 0.716, Test accuracy: 76.13
Round  66, Train loss: 0.574, Test loss: 0.722, Test accuracy: 75.88
Round  67, Train loss: 0.588, Test loss: 0.723, Test accuracy: 76.06
Round  68, Train loss: 0.593, Test loss: 0.722, Test accuracy: 75.90
Round  69, Train loss: 0.570, Test loss: 0.722, Test accuracy: 76.16
Round  70, Train loss: 0.558, Test loss: 0.717, Test accuracy: 76.31
Round  71, Train loss: 0.579, Test loss: 0.714, Test accuracy: 76.36
Round  72, Train loss: 0.560, Test loss: 0.714, Test accuracy: 76.16
Round  73, Train loss: 0.569, Test loss: 0.710, Test accuracy: 76.71
Round  74, Train loss: 0.563, Test loss: 0.720, Test accuracy: 76.88
Round  75, Train loss: 0.581, Test loss: 0.716, Test accuracy: 76.95
Round  76, Train loss: 0.538, Test loss: 0.719, Test accuracy: 76.69
Round  77, Train loss: 0.556, Test loss: 0.720, Test accuracy: 76.81
Round  78, Train loss: 0.517, Test loss: 0.721, Test accuracy: 76.63
Round  79, Train loss: 0.537, Test loss: 0.711, Test accuracy: 76.98
Round  80, Train loss: 0.535, Test loss: 0.721, Test accuracy: 76.47
Round  81, Train loss: 0.565, Test loss: 0.710, Test accuracy: 77.23
Round  82, Train loss: 0.548, Test loss: 0.711, Test accuracy: 77.05
Round  83, Train loss: 0.530, Test loss: 0.706, Test accuracy: 77.07
Round  84, Train loss: 0.535, Test loss: 0.721, Test accuracy: 76.79
Round  85, Train loss: 0.522, Test loss: 0.712, Test accuracy: 77.23
Round  86, Train loss: 0.536, Test loss: 0.700, Test accuracy: 77.51
Round  87, Train loss: 0.503, Test loss: 0.706, Test accuracy: 77.32
Round  88, Train loss: 0.535, Test loss: 0.702, Test accuracy: 77.52
Round  89, Train loss: 0.513, Test loss: 0.703, Test accuracy: 77.33
Round  90, Train loss: 0.492, Test loss: 0.709, Test accuracy: 76.83
Round  91, Train loss: 0.511, Test loss: 0.710, Test accuracy: 77.14
Round  92, Train loss: 0.527, Test loss: 0.712, Test accuracy: 77.21
Round  93, Train loss: 0.509, Test loss: 0.719, Test accuracy: 77.14
Round  94, Train loss: 0.500, Test loss: 0.712, Test accuracy: 76.97
Round  95, Train loss: 0.479, Test loss: 0.718, Test accuracy: 76.89
Round  96, Train loss: 0.516, Test loss: 0.707, Test accuracy: 77.31
Round  97, Train loss: 0.496, Test loss: 0.707, Test accuracy: 77.24
Round  98, Train loss: 0.468, Test loss: 0.718, Test accuracy: 76.87
Round  99, Train loss: 0.485, Test loss: 0.717, Test accuracy: 76.94
Final Round, Train loss: 0.420, Test loss: 0.711, Test accuracy: 77.20
Average accuracy final 10 rounds: 77.05525
4947.308274030685
[6.615363597869873, 12.385991334915161, 18.06467914581299, 24.178190231323242, 30.161460399627686, 35.89750909805298, 41.58421301841736, 47.32529401779175, 53.07456970214844, 58.75658392906189, 64.41136384010315, 70.18792986869812, 75.89066886901855, 81.54258728027344, 87.346510887146, 93.14971208572388, 98.88195371627808, 104.6326858997345, 110.64097595214844, 116.42844438552856, 122.11241936683655, 127.79569125175476, 133.49538660049438, 139.2940137386322, 144.9423975944519, 150.9434199333191, 157.06816816329956, 162.76126837730408, 168.8756022453308, 175.0513186454773, 181.15453362464905, 187.314551115036, 193.57686972618103, 199.76279759407043, 205.92819166183472, 212.157329082489, 218.46612095832825, 224.75151586532593, 231.0065631866455, 237.32449054718018, 243.4993507862091, 249.81799912452698, 256.1754915714264, 262.4128158092499, 268.64112734794617, 274.83846783638, 281.06912565231323, 287.1669511795044, 293.33694553375244, 299.60031938552856, 305.7376289367676, 312.1295220851898, 318.3980059623718, 324.47770285606384, 330.7080063819885, 336.9072251319885, 343.04175758361816, 349.1220352649689, 355.2574932575226, 361.44613242149353, 367.6947829723358, 373.87224221229553, 379.933358669281, 386.1222002506256, 392.3699538707733, 398.65661883354187, 404.8554196357727, 411.11038732528687, 417.31788778305054, 423.6180911064148, 429.8578221797943, 436.06301045417786, 442.31494975090027, 448.5408136844635, 454.727413892746, 460.9063673019409, 467.10129594802856, 473.31091260910034, 479.4629340171814, 485.7218108177185, 492.0371639728546, 498.2479088306427, 504.4440302848816, 510.6809675693512, 516.94460105896, 523.2113373279572, 529.3185195922852, 535.5877149105072, 541.853976726532, 548.0844357013702, 554.2346386909485, 560.4406492710114, 566.6343061923981, 572.8081340789795, 578.8317556381226, 585.1978740692139, 591.4985535144806, 597.6758418083191, 603.6399049758911, 609.8668196201324, 612.4366610050201]
[33.665, 42.81, 46.3925, 50.7775, 53.435, 55.6275, 56.6025, 58.77, 59.735, 60.81, 60.515, 60.99, 61.595, 62.605, 63.4125, 64.1225, 65.2475, 67.125, 67.48, 68.4, 68.425, 69.86, 70.0675, 70.4275, 70.91, 70.97, 71.6125, 71.865, 71.66, 72.1425, 72.7, 72.5025, 73.075, 72.8275, 72.99, 72.895, 73.5275, 72.9775, 73.1925, 73.89, 74.1675, 73.025, 73.245, 73.3825, 73.44, 74.3, 74.335, 74.78, 74.7075, 75.245, 74.75, 75.0675, 74.9825, 75.575, 75.4375, 75.2125, 75.4475, 75.07, 75.5075, 75.8625, 76.075, 75.9475, 76.1425, 75.9425, 75.93, 76.1325, 75.88, 76.065, 75.8975, 76.16, 76.305, 76.3625, 76.1575, 76.71, 76.8825, 76.9475, 76.695, 76.81, 76.63, 76.9775, 76.465, 77.2325, 77.05, 77.07, 76.79, 77.235, 77.51, 77.3175, 77.5175, 77.3325, 76.8325, 77.145, 77.21, 77.145, 76.9675, 76.8875, 77.31, 77.2425, 76.8725, 76.94, 77.2]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  32.1000
Round 1 global test acc  42.9000
Round 2 global test acc  45.4800
Round 3 global test acc  48.7800
Round 4 global test acc  50.6600
Round 5 global test acc  50.5000
Round 6 global test acc  51.7700
Round 7 global test acc  54.4300
Round 8 global test acc  55.3400
Round 9 global test acc  56.7000
Round 10 global test acc  56.9100
Round 11 global test acc  57.4500
Round 12 global test acc  57.1400
Round 13 global test acc  58.4400
Round 14 global test acc  58.5700
Round 15 global test acc  58.0700
Round 16 global test acc  59.2100
Round 17 global test acc  60.1900
Round 18 global test acc  60.5600
Round 19 global test acc  60.9600
Round 20 global test acc  61.1700
Round 21 global test acc  60.6800
Round 22 global test acc  62.0100
Round 23 global test acc  61.4400
Round 24 global test acc  62.1400
Round 25 global test acc  61.9800
Round 26 global test acc  62.1000
Round 27 global test acc  62.1200
Round 28 global test acc  62.8300
Round 29 global test acc  62.7000
Round 30 global test acc  62.7300
Round 31 global test acc  63.8300
Round 32 global test acc  63.8500
Round 33 global test acc  63.7900
Round 34 global test acc  64.3200
Round 35 global test acc  64.8500
Round 36 global test acc  64.5000
Round 37 global test acc  65.0100
Round 38 global test acc  64.5000
Round 39 global test acc  64.8600
Round 40 global test acc  63.9800
Round 41 global test acc  64.0600
Round 42 global test acc  64.9400
Round 43 global test acc  64.6400
Round 44 global test acc  65.3000
Round 45 global test acc  64.6000
Round 46 global test acc  65.5000
Round 47 global test acc  66.4700
Round 48 global test acc  65.8800
Round 49 global test acc  65.9200
Round 50 global test acc  66.0500
Round 51 global test acc  66.1300
Round 52 global test acc  66.8100
Round 53 global test acc  66.7100
Round 54 global test acc  66.4700
Round 55 global test acc  66.4200
Round 56 global test acc  66.3800
Round 57 global test acc  66.7000
Round 58 global test acc  66.3700
Round 59 global test acc  67.0100
Round 60 global test acc  66.9500
Round 61 global test acc  66.8800
Round 62 global test acc  66.6500
Round 63 global test acc  66.6000
Round 64 global test acc  67.2900
Round 65 global test acc  67.5300
Round 66 global test acc  67.1800
Round 67 global test acc  67.1600
Round 68 global test acc  67.0900
Round 69 global test acc  66.9900
Round 70 global test acc  67.5600
Round 71 global test acc  67.3500
Round 72 global test acc  68.0300
Round 73 global test acc  67.7800
Round 74 global test acc  67.4500
Round 75 global test acc  67.8800
Round 76 global test acc  67.0800
Round 77 global test acc  67.8300
Round 78 global test acc  67.5800
Round 79 global test acc  67.6400
Round 80 global test acc  66.6200
Round 81 global test acc  66.0500
Round 82 global test acc  64.9500
Round 83 global test acc  64.4600
Round 84 global test acc  63.3800
Round 85 global test acc  62.6000
Round 86 global test acc  61.4500
Round 87 global test acc  60.9900
Round 88 global test acc  60.3800
Round 89 global test acc  60.3300
Round 90 global test acc  60.5700
Round 91 global test acc  60.2600
Round 92 global test acc  59.9400
Round 93 global test acc  59.2400
Round 94 global test acc  58.8800
Round 95 global test acc  58.4700
Round 96 global test acc  57.9500
Round 97 global test acc  58.5700
Round 98 global test acc  58.7700
Round 99 global test acc  58.4800
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.514, Test loss: 2.152, Test accuracy: 21.41
Round   1, Train loss: 1.006, Test loss: 1.739, Test accuracy: 37.98
Round   2, Train loss: 0.870, Test loss: 1.478, Test accuracy: 44.79
Round   3, Train loss: 0.810, Test loss: 1.170, Test accuracy: 52.18
Round   4, Train loss: 0.752, Test loss: 1.115, Test accuracy: 55.96
Round   5, Train loss: 0.801, Test loss: 1.014, Test accuracy: 60.95
Round   6, Train loss: 0.699, Test loss: 0.891, Test accuracy: 64.80
Round   7, Train loss: 0.670, Test loss: 0.812, Test accuracy: 68.55
Round   8, Train loss: 0.686, Test loss: 0.836, Test accuracy: 67.40
Round   9, Train loss: 0.659, Test loss: 0.709, Test accuracy: 71.89
Round  10, Train loss: 0.608, Test loss: 0.615, Test accuracy: 75.53
Round  11, Train loss: 0.645, Test loss: 0.599, Test accuracy: 76.03
Round  12, Train loss: 0.607, Test loss: 0.591, Test accuracy: 75.72
Round  13, Train loss: 0.592, Test loss: 0.570, Test accuracy: 76.74
Round  14, Train loss: 0.627, Test loss: 0.562, Test accuracy: 77.84
Round  15, Train loss: 0.552, Test loss: 0.555, Test accuracy: 77.83
Round  16, Train loss: 0.559, Test loss: 0.547, Test accuracy: 78.58
Round  17, Train loss: 0.547, Test loss: 0.538, Test accuracy: 79.27
Round  18, Train loss: 0.513, Test loss: 0.538, Test accuracy: 79.17
Round  19, Train loss: 0.534, Test loss: 0.514, Test accuracy: 79.52
Round  20, Train loss: 0.527, Test loss: 0.500, Test accuracy: 79.93
Round  21, Train loss: 0.522, Test loss: 0.504, Test accuracy: 80.47
Round  22, Train loss: 0.522, Test loss: 0.506, Test accuracy: 80.19
Round  23, Train loss: 0.489, Test loss: 0.486, Test accuracy: 80.24
Round  24, Train loss: 0.478, Test loss: 0.497, Test accuracy: 80.57
Round  25, Train loss: 0.470, Test loss: 0.481, Test accuracy: 81.29
Round  26, Train loss: 0.543, Test loss: 0.461, Test accuracy: 81.79
Round  27, Train loss: 0.443, Test loss: 0.465, Test accuracy: 81.26
Round  28, Train loss: 0.531, Test loss: 0.446, Test accuracy: 82.47
Round  29, Train loss: 0.513, Test loss: 0.450, Test accuracy: 82.02
Round  30, Train loss: 0.462, Test loss: 0.440, Test accuracy: 82.29
Round  31, Train loss: 0.418, Test loss: 0.449, Test accuracy: 82.25
Round  32, Train loss: 0.414, Test loss: 0.443, Test accuracy: 82.42
Round  33, Train loss: 0.448, Test loss: 0.426, Test accuracy: 83.14
Round  34, Train loss: 0.467, Test loss: 0.411, Test accuracy: 83.57
Round  35, Train loss: 0.454, Test loss: 0.419, Test accuracy: 83.36
Round  36, Train loss: 0.444, Test loss: 0.410, Test accuracy: 83.90
Round  37, Train loss: 0.412, Test loss: 0.405, Test accuracy: 84.21
Round  38, Train loss: 0.391, Test loss: 0.401, Test accuracy: 84.40
Round  39, Train loss: 0.430, Test loss: 0.394, Test accuracy: 84.47
Round  40, Train loss: 0.384, Test loss: 0.409, Test accuracy: 83.85
Round  41, Train loss: 0.373, Test loss: 0.400, Test accuracy: 84.48
Round  42, Train loss: 0.369, Test loss: 0.394, Test accuracy: 84.49
Round  43, Train loss: 0.398, Test loss: 0.400, Test accuracy: 84.46
Round  44, Train loss: 0.415, Test loss: 0.388, Test accuracy: 84.84
Round  45, Train loss: 0.403, Test loss: 0.394, Test accuracy: 84.27
Round  46, Train loss: 0.394, Test loss: 0.387, Test accuracy: 84.85
Round  47, Train loss: 0.383, Test loss: 0.384, Test accuracy: 85.12
Round  48, Train loss: 0.397, Test loss: 0.374, Test accuracy: 85.43
Round  49, Train loss: 0.375, Test loss: 0.371, Test accuracy: 85.74
Round  50, Train loss: 0.318, Test loss: 0.370, Test accuracy: 85.64
Round  51, Train loss: 0.386, Test loss: 0.370, Test accuracy: 85.73
Round  52, Train loss: 0.376, Test loss: 0.367, Test accuracy: 85.72
Round  53, Train loss: 0.338, Test loss: 0.366, Test accuracy: 85.67
Round  54, Train loss: 0.346, Test loss: 0.360, Test accuracy: 86.09
Round  55, Train loss: 0.335, Test loss: 0.358, Test accuracy: 85.85
Round  56, Train loss: 0.331, Test loss: 0.361, Test accuracy: 85.93
Round  57, Train loss: 0.315, Test loss: 0.361, Test accuracy: 86.24
Round  58, Train loss: 0.351, Test loss: 0.357, Test accuracy: 86.17
Round  59, Train loss: 0.319, Test loss: 0.351, Test accuracy: 86.38
Round  60, Train loss: 0.294, Test loss: 0.352, Test accuracy: 86.07
Round  61, Train loss: 0.340, Test loss: 0.348, Test accuracy: 86.31
Round  62, Train loss: 0.296, Test loss: 0.352, Test accuracy: 86.12
Round  63, Train loss: 0.320, Test loss: 0.343, Test accuracy: 86.47
Round  64, Train loss: 0.308, Test loss: 0.340, Test accuracy: 86.72
Round  65, Train loss: 0.359, Test loss: 0.351, Test accuracy: 86.32
Round  66, Train loss: 0.285, Test loss: 0.336, Test accuracy: 86.81
Round  67, Train loss: 0.262, Test loss: 0.337, Test accuracy: 86.78
Round  68, Train loss: 0.286, Test loss: 0.338, Test accuracy: 86.73
Round  69, Train loss: 0.310, Test loss: 0.344, Test accuracy: 86.38
Round  70, Train loss: 0.242, Test loss: 0.342, Test accuracy: 86.61
Round  71, Train loss: 0.294, Test loss: 0.335, Test accuracy: 86.76
Round  72, Train loss: 0.296, Test loss: 0.340, Test accuracy: 87.15
Round  73, Train loss: 0.267, Test loss: 0.332, Test accuracy: 87.28
Round  74, Train loss: 0.249, Test loss: 0.341, Test accuracy: 86.92
Round  75, Train loss: 0.280, Test loss: 0.332, Test accuracy: 86.50
Round  76, Train loss: 0.276, Test loss: 0.338, Test accuracy: 86.70
Round  77, Train loss: 0.304, Test loss: 0.333, Test accuracy: 86.72
Round  78, Train loss: 0.268, Test loss: 0.334, Test accuracy: 86.83
Round  79, Train loss: 0.280, Test loss: 0.328, Test accuracy: 87.00
Round  80, Train loss: 0.263, Test loss: 0.330, Test accuracy: 86.96
Round  81, Train loss: 0.255, Test loss: 0.328, Test accuracy: 87.17
Round  82, Train loss: 0.228, Test loss: 0.334, Test accuracy: 86.47
Round  83, Train loss: 0.273, Test loss: 0.336, Test accuracy: 86.83
Round  84, Train loss: 0.248, Test loss: 0.333, Test accuracy: 86.87
Round  85, Train loss: 0.258, Test loss: 0.327, Test accuracy: 87.10
Round  86, Train loss: 0.249, Test loss: 0.336, Test accuracy: 87.26
Round  87, Train loss: 0.231, Test loss: 0.329, Test accuracy: 87.39
Round  88, Train loss: 0.224, Test loss: 0.334, Test accuracy: 87.03
Round  89, Train loss: 0.234, Test loss: 0.323, Test accuracy: 87.59
Round  90, Train loss: 0.232, Test loss: 0.323, Test accuracy: 87.39
Round  91, Train loss: 0.245, Test loss: 0.323, Test accuracy: 87.31
Round  92, Train loss: 0.234, Test loss: 0.321, Test accuracy: 87.55
Round  93, Train loss: 0.208, Test loss: 0.320, Test accuracy: 87.82
Round  94, Train loss: 0.243, Test loss: 0.322, Test accuracy: 87.63
Round  95, Train loss: 0.229, Test loss: 0.324, Test accuracy: 87.31
Round  96, Train loss: 0.219, Test loss: 0.324, Test accuracy: 87.46
Round  97, Train loss: 0.215, Test loss: 0.327, Test accuracy: 87.12
Round  98, Train loss: 0.252, Test loss: 0.328, Test accuracy: 87.28
Round  99, Train loss: 0.234, Test loss: 0.323, Test accuracy: 87.46
Final Round, Train loss: 0.188, Test loss: 0.323, Test accuracy: 87.74
Average accuracy final 10 rounds: 87.43250000000002
1435.2858703136444
[2.1570701599121094, 3.919010639190674, 5.713937282562256, 7.508947372436523, 9.264106273651123, 10.913036346435547, 12.668935775756836, 14.476050615310669, 16.2510244846344, 17.901546001434326, 19.642914056777954, 21.302453756332397, 22.926957845687866, 24.60241460800171, 26.280137538909912, 27.911633491516113, 29.547446250915527, 31.20601487159729, 32.84719109535217, 34.49423122406006, 36.246711015701294, 37.92295598983765, 39.567933797836304, 41.24833703041077, 43.06259608268738, 44.78936266899109, 46.42180132865906, 48.09103775024414, 49.86691331863403, 51.50529861450195, 53.276202917099, 55.0508291721344, 56.909708976745605, 58.785693645477295, 60.71566104888916, 62.52315616607666, 64.33788728713989, 66.14888572692871, 67.97378325462341, 69.87525200843811, 71.79477834701538, 73.65323281288147, 75.53010702133179, 77.42543196678162, 79.35059332847595, 81.25440907478333, 83.08302974700928, 84.90834641456604, 86.75953698158264, 88.63628387451172, 90.52248907089233, 92.38904237747192, 94.25612330436707, 96.06336879730225, 97.96824407577515, 99.88784432411194, 101.70780229568481, 103.43972754478455, 105.13218522071838, 106.82692909240723, 108.53822612762451, 110.29288697242737, 112.02028894424438, 113.71508932113647, 115.49707007408142, 117.28637433052063, 118.94537305831909, 120.71124625205994, 122.3833589553833, 124.05651211738586, 125.71883845329285, 127.38792419433594, 129.01653909683228, 130.69295930862427, 132.40633606910706, 134.15902972221375, 135.8830530643463, 137.63638043403625, 139.37493133544922, 141.16632890701294, 142.82633090019226, 144.5382912158966, 146.26162838935852, 148.04673171043396, 149.69350814819336, 151.33202934265137, 152.9983627796173, 154.67484068870544, 156.3328778743744, 157.98398184776306, 159.6317002773285, 161.3091139793396, 163.01214790344238, 164.6881127357483, 166.3554346561432, 168.016122341156, 169.66925501823425, 171.31469702720642, 173.00199007987976, 174.70024418830872, 176.90631079673767]
[21.408333333333335, 37.983333333333334, 44.791666666666664, 52.18333333333333, 55.958333333333336, 60.95, 64.8, 68.55, 67.4, 71.89166666666667, 75.53333333333333, 76.03333333333333, 75.725, 76.74166666666666, 77.84166666666667, 77.825, 78.575, 79.26666666666667, 79.175, 79.51666666666667, 79.93333333333334, 80.475, 80.19166666666666, 80.24166666666666, 80.56666666666666, 81.29166666666667, 81.79166666666667, 81.25833333333334, 82.475, 82.01666666666667, 82.29166666666667, 82.25, 82.41666666666667, 83.14166666666667, 83.56666666666666, 83.35833333333333, 83.9, 84.20833333333333, 84.4, 84.475, 83.85, 84.48333333333333, 84.49166666666666, 84.45833333333333, 84.84166666666667, 84.26666666666667, 84.85, 85.11666666666666, 85.43333333333334, 85.74166666666666, 85.64166666666667, 85.73333333333333, 85.725, 85.675, 86.09166666666667, 85.85, 85.93333333333334, 86.24166666666666, 86.175, 86.375, 86.06666666666666, 86.30833333333334, 86.125, 86.46666666666667, 86.725, 86.31666666666666, 86.80833333333334, 86.78333333333333, 86.73333333333333, 86.38333333333334, 86.60833333333333, 86.75833333333334, 87.15, 87.275, 86.91666666666667, 86.5, 86.7, 86.725, 86.825, 87.0, 86.95833333333333, 87.175, 86.46666666666667, 86.83333333333333, 86.86666666666666, 87.1, 87.25833333333334, 87.39166666666667, 87.025, 87.59166666666667, 87.39166666666667, 87.30833333333334, 87.55, 87.81666666666666, 87.63333333333334, 87.30833333333334, 87.45833333333333, 87.11666666666666, 87.28333333333333, 87.45833333333333, 87.74166666666666]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.479, Test loss: 2.101, Test accuracy: 28.96
Round   1, Train loss: 0.983, Test loss: 1.780, Test accuracy: 35.51
Round   2, Train loss: 0.883, Test loss: 1.529, Test accuracy: 44.58
Round   3, Train loss: 0.783, Test loss: 1.126, Test accuracy: 53.75
Round   4, Train loss: 0.763, Test loss: 0.903, Test accuracy: 64.52
Round   5, Train loss: 0.693, Test loss: 0.746, Test accuracy: 68.97
Round   6, Train loss: 0.685, Test loss: 0.744, Test accuracy: 70.72
Round   7, Train loss: 0.635, Test loss: 0.711, Test accuracy: 70.25
Round   8, Train loss: 0.621, Test loss: 0.737, Test accuracy: 71.77
Round   9, Train loss: 0.637, Test loss: 0.643, Test accuracy: 74.38
Round  10, Train loss: 0.655, Test loss: 0.647, Test accuracy: 73.86
Round  11, Train loss: 0.610, Test loss: 0.623, Test accuracy: 75.02
Round  12, Train loss: 0.571, Test loss: 0.602, Test accuracy: 75.67
Round  13, Train loss: 0.560, Test loss: 0.571, Test accuracy: 76.88
Round  14, Train loss: 0.570, Test loss: 0.633, Test accuracy: 76.38
Round  15, Train loss: 0.600, Test loss: 0.591, Test accuracy: 77.86
Round  16, Train loss: 0.492, Test loss: 0.608, Test accuracy: 76.37
Round  17, Train loss: 0.507, Test loss: 0.606, Test accuracy: 76.48
Round  18, Train loss: 0.562, Test loss: 0.606, Test accuracy: 76.33
Round  19, Train loss: 0.521, Test loss: 0.575, Test accuracy: 77.67
Round  20, Train loss: 0.527, Test loss: 0.496, Test accuracy: 79.73
Round  21, Train loss: 0.504, Test loss: 0.488, Test accuracy: 80.41
Round  22, Train loss: 0.453, Test loss: 0.480, Test accuracy: 81.23
Round  23, Train loss: 0.460, Test loss: 0.482, Test accuracy: 80.94
Round  24, Train loss: 0.542, Test loss: 0.473, Test accuracy: 80.66
Round  25, Train loss: 0.473, Test loss: 0.466, Test accuracy: 81.36
Round  26, Train loss: 0.455, Test loss: 0.447, Test accuracy: 82.23
Round  27, Train loss: 0.507, Test loss: 0.438, Test accuracy: 82.15
Round  28, Train loss: 0.448, Test loss: 0.446, Test accuracy: 81.76
Round  29, Train loss: 0.419, Test loss: 0.449, Test accuracy: 81.27
Round  30, Train loss: 0.469, Test loss: 0.449, Test accuracy: 81.43
Round  31, Train loss: 0.472, Test loss: 0.436, Test accuracy: 82.01
Round  32, Train loss: 0.418, Test loss: 0.444, Test accuracy: 81.83
Round  33, Train loss: 0.438, Test loss: 0.423, Test accuracy: 82.67
Round  34, Train loss: 0.399, Test loss: 0.411, Test accuracy: 83.53
Round  35, Train loss: 0.434, Test loss: 0.418, Test accuracy: 83.54
Round  36, Train loss: 0.388, Test loss: 0.413, Test accuracy: 83.70
Round  37, Train loss: 0.399, Test loss: 0.410, Test accuracy: 83.65
Round  38, Train loss: 0.417, Test loss: 0.403, Test accuracy: 83.92
Round  39, Train loss: 0.391, Test loss: 0.392, Test accuracy: 84.38
Round  40, Train loss: 0.403, Test loss: 0.393, Test accuracy: 84.15
Round  41, Train loss: 0.388, Test loss: 0.388, Test accuracy: 84.46
Round  42, Train loss: 0.398, Test loss: 0.382, Test accuracy: 84.73
Round  43, Train loss: 0.345, Test loss: 0.384, Test accuracy: 84.97
Round  44, Train loss: 0.358, Test loss: 0.382, Test accuracy: 85.03
Round  45, Train loss: 0.329, Test loss: 0.380, Test accuracy: 84.97
Round  46, Train loss: 0.356, Test loss: 0.377, Test accuracy: 85.34
Round  47, Train loss: 0.409, Test loss: 0.379, Test accuracy: 85.09
Round  48, Train loss: 0.354, Test loss: 0.372, Test accuracy: 85.40
Round  49, Train loss: 0.332, Test loss: 0.375, Test accuracy: 85.12
Round  50, Train loss: 0.343, Test loss: 0.371, Test accuracy: 85.33
Round  51, Train loss: 0.293, Test loss: 0.373, Test accuracy: 85.06
Round  52, Train loss: 0.351, Test loss: 0.364, Test accuracy: 85.59
Round  53, Train loss: 0.353, Test loss: 0.376, Test accuracy: 85.38
Round  54, Train loss: 0.356, Test loss: 0.367, Test accuracy: 85.66
Round  55, Train loss: 0.332, Test loss: 0.371, Test accuracy: 85.20
Round  56, Train loss: 0.320, Test loss: 0.364, Test accuracy: 85.53
Round  57, Train loss: 0.297, Test loss: 0.361, Test accuracy: 85.74
Round  58, Train loss: 0.364, Test loss: 0.363, Test accuracy: 85.74
Round  59, Train loss: 0.301, Test loss: 0.359, Test accuracy: 85.98
Round  60, Train loss: 0.294, Test loss: 0.358, Test accuracy: 86.09
Round  61, Train loss: 0.304, Test loss: 0.350, Test accuracy: 86.33
Round  62, Train loss: 0.344, Test loss: 0.349, Test accuracy: 86.37
Round  63, Train loss: 0.291, Test loss: 0.352, Test accuracy: 86.36
Round  64, Train loss: 0.298, Test loss: 0.356, Test accuracy: 86.17
Round  65, Train loss: 0.328, Test loss: 0.355, Test accuracy: 86.38
Round  66, Train loss: 0.330, Test loss: 0.351, Test accuracy: 86.67
Round  67, Train loss: 0.303, Test loss: 0.348, Test accuracy: 86.42
Round  68, Train loss: 0.260, Test loss: 0.354, Test accuracy: 86.05
Round  69, Train loss: 0.304, Test loss: 0.345, Test accuracy: 86.58
Round  70, Train loss: 0.279, Test loss: 0.343, Test accuracy: 86.81
Round  71, Train loss: 0.295, Test loss: 0.340, Test accuracy: 86.89
Round  72, Train loss: 0.284, Test loss: 0.341, Test accuracy: 86.92
Round  73, Train loss: 0.279, Test loss: 0.343, Test accuracy: 86.55
Round  74, Train loss: 0.286, Test loss: 0.341, Test accuracy: 86.70
Round  75, Train loss: 0.262, Test loss: 0.339, Test accuracy: 86.81
Round  76, Train loss: 0.262, Test loss: 0.334, Test accuracy: 86.96
Round  77, Train loss: 0.248, Test loss: 0.337, Test accuracy: 86.89
Round  78, Train loss: 0.268, Test loss: 0.338, Test accuracy: 86.62
Round  79, Train loss: 0.254, Test loss: 0.339, Test accuracy: 86.77
Round  80, Train loss: 0.250, Test loss: 0.335, Test accuracy: 86.91
Round  81, Train loss: 0.255, Test loss: 0.335, Test accuracy: 87.17
Round  82, Train loss: 0.274, Test loss: 0.333, Test accuracy: 87.13
Round  83, Train loss: 0.227, Test loss: 0.334, Test accuracy: 87.00
Round  84, Train loss: 0.256, Test loss: 0.333, Test accuracy: 87.04
Round  85, Train loss: 0.239, Test loss: 0.335, Test accuracy: 87.06
Round  86, Train loss: 0.227, Test loss: 0.335, Test accuracy: 87.26
Round  87, Train loss: 0.237, Test loss: 0.331, Test accuracy: 86.94
Round  88, Train loss: 0.229, Test loss: 0.332, Test accuracy: 87.22
Round  89, Train loss: 0.220, Test loss: 0.329, Test accuracy: 87.33
Round  90, Train loss: 0.224, Test loss: 0.330, Test accuracy: 87.23
Round  91, Train loss: 0.241, Test loss: 0.328, Test accuracy: 87.28
Round  92, Train loss: 0.226, Test loss: 0.323, Test accuracy: 87.51
Round  93, Train loss: 0.216, Test loss: 0.328, Test accuracy: 87.48
Round  94, Train loss: 0.249, Test loss: 0.329, Test accuracy: 87.35
Round  95, Train loss: 0.210, Test loss: 0.329, Test accuracy: 87.43
Round  96, Train loss: 0.209, Test loss: 0.333, Test accuracy: 87.32
Round  97, Train loss: 0.220, Test loss: 0.337, Test accuracy: 87.29
Round  98, Train loss: 0.222, Test loss: 0.339, Test accuracy: 87.24
Round  99, Train loss: 0.213, Test loss: 0.335, Test accuracy: 87.55
Final Round, Train loss: 0.184, Test loss: 0.328, Test accuracy: 87.78
Average accuracy final 10 rounds: 87.36916666666666
2790.6700880527496
[2.171574115753174, 3.9998133182525635, 5.830634832382202, 7.664311170578003, 9.52626895904541, 11.353412866592407, 13.204258918762207, 15.06955075263977, 16.917062759399414, 18.77087688446045, 20.61693024635315, 22.450246572494507, 24.31036114692688, 26.188276052474976, 28.040665864944458, 29.88012719154358, 31.7743136882782, 33.67209768295288, 35.53902769088745, 37.423821449279785, 39.297375202178955, 44.08621883392334, 48.88604402542114, 53.73215985298157, 58.55145883560181, 63.41665744781494, 68.17081785202026, 73.07012581825256, 77.82239007949829, 82.89407396316528, 87.70443320274353, 92.55894017219543, 97.35395741462708, 102.29382824897766, 107.15031576156616, 112.0359525680542, 116.69343733787537, 121.56930541992188, 126.41329026222229, 131.2305817604065, 136.07354140281677, 140.92627477645874, 145.73811745643616, 150.48580813407898, 155.27822732925415, 159.92765140533447, 164.78576970100403, 169.40413975715637, 174.1096751689911, 178.85339164733887, 183.79761385917664, 188.54114174842834, 193.42914700508118, 198.14421844482422, 202.9210410118103, 207.68637084960938, 212.43878507614136, 216.97887325286865, 221.64016795158386, 226.22382855415344, 230.88425612449646, 235.74813675880432, 240.42083644866943, 244.9594006538391, 249.49430322647095, 254.21888518333435, 258.7828257083893, 263.43955969810486, 267.8525867462158, 272.482125043869, 277.00641679763794, 281.7700870037079, 286.33666610717773, 291.06016969680786, 295.63968205451965, 300.23933696746826, 304.77837920188904, 309.1885795593262, 313.8339829444885, 318.2738320827484, 322.8295364379883, 327.23463797569275, 331.8190519809723, 336.39754366874695, 341.0816078186035, 345.6914281845093, 350.4021439552307, 355.17896580696106, 359.83572697639465, 364.32456851005554, 369.00729966163635, 373.71608233451843, 378.3127474784851, 382.96364736557007, 387.4864227771759, 392.3688702583313, 397.0775339603424, 401.94079399108887, 406.60878896713257, 411.4846477508545, 413.7095136642456]
[28.958333333333332, 35.50833333333333, 44.583333333333336, 53.75, 64.51666666666667, 68.96666666666667, 70.71666666666667, 70.25, 71.76666666666667, 74.38333333333334, 73.85833333333333, 75.01666666666667, 75.66666666666667, 76.88333333333334, 76.38333333333334, 77.85833333333333, 76.36666666666666, 76.48333333333333, 76.325, 77.66666666666667, 79.73333333333333, 80.40833333333333, 81.23333333333333, 80.94166666666666, 80.65833333333333, 81.35833333333333, 82.23333333333333, 82.15, 81.75833333333334, 81.26666666666667, 81.43333333333334, 82.00833333333334, 81.825, 82.675, 83.53333333333333, 83.54166666666667, 83.7, 83.65, 83.925, 84.38333333333334, 84.15, 84.45833333333333, 84.73333333333333, 84.96666666666667, 85.025, 84.96666666666667, 85.34166666666667, 85.09166666666667, 85.4, 85.125, 85.33333333333333, 85.05833333333334, 85.59166666666667, 85.38333333333334, 85.65833333333333, 85.2, 85.53333333333333, 85.74166666666666, 85.74166666666666, 85.98333333333333, 86.09166666666667, 86.325, 86.36666666666666, 86.35833333333333, 86.175, 86.375, 86.675, 86.41666666666667, 86.05, 86.58333333333333, 86.80833333333334, 86.89166666666667, 86.91666666666667, 86.55, 86.7, 86.80833333333334, 86.95833333333333, 86.89166666666667, 86.625, 86.76666666666667, 86.90833333333333, 87.175, 87.13333333333334, 87.0, 87.04166666666667, 87.05833333333334, 87.25833333333334, 86.94166666666666, 87.21666666666667, 87.33333333333333, 87.23333333333333, 87.28333333333333, 87.50833333333334, 87.48333333333333, 87.35, 87.43333333333334, 87.31666666666666, 87.29166666666667, 87.24166666666666, 87.55, 87.775]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9491 (0.8542), real noise ratio: 0.8500
Client 2, noise level: 0.3194 (0.2875), real noise ratio: 0.2815
Client 3, noise level: 0.9178 (0.8260), real noise ratio: 0.8215
Client 4, noise level: 0.0319 (0.0287), real noise ratio: 0.0545
Client 6, noise level: 0.6298 (0.5668), real noise ratio: 0.5725
Client 7, noise level: 0.8738 (0.7864), real noise ratio: 0.7950
Client 8, noise level: 0.0087 (0.0078), real noise ratio: 0.0105
Client 9, noise level: 0.7466 (0.6719), real noise ratio: 0.7545
Client 13, noise level: 0.5093 (0.4583), real noise ratio: 0.5110
Client 15, noise level: 0.9556 (0.8600), real noise ratio: 0.8640
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.117, Test loss: 2.072, Test accuracy: 28.64
Round   0, Global train loss: 2.117, Global test loss: 2.084, Global test accuracy: 29.79
Round   1, Train loss: 2.079, Test loss: 1.998, Test accuracy: 33.37
Round   1, Global train loss: 2.079, Global test loss: 1.987, Global test accuracy: 39.21
Round   2, Train loss: 1.979, Test loss: 1.923, Test accuracy: 34.14
Round   2, Global train loss: 1.979, Global test loss: 1.834, Global test accuracy: 40.55
Round   3, Train loss: 2.033, Test loss: 1.948, Test accuracy: 33.32
Round   3, Global train loss: 2.033, Global test loss: 1.979, Global test accuracy: 38.92
Round   4, Train loss: 1.918, Test loss: 1.914, Test accuracy: 33.84
Round   4, Global train loss: 1.918, Global test loss: 1.856, Global test accuracy: 39.49
Round   5, Train loss: 1.874, Test loss: 1.887, Test accuracy: 35.05
Round   5, Global train loss: 1.874, Global test loss: 1.835, Global test accuracy: 44.62
Round   6, Train loss: 1.967, Test loss: 1.882, Test accuracy: 35.31
Round   6, Global train loss: 1.967, Global test loss: 1.897, Global test accuracy: 41.69
Round   7, Train loss: 1.947, Test loss: 1.876, Test accuracy: 35.48
Round   7, Global train loss: 1.947, Global test loss: 1.975, Global test accuracy: 38.24
Round   8, Train loss: 1.769, Test loss: 1.841, Test accuracy: 36.12
Round   8, Global train loss: 1.769, Global test loss: 1.698, Global test accuracy: 41.99
Round   9, Train loss: 2.022, Test loss: 1.864, Test accuracy: 35.66
Round   9, Global train loss: 2.022, Global test loss: 2.015, Global test accuracy: 36.41
Round  10, Train loss: 1.691, Test loss: 1.829, Test accuracy: 36.85
Round  10, Global train loss: 1.691, Global test loss: 1.688, Global test accuracy: 44.65
Round  11, Train loss: 1.843, Test loss: 1.832, Test accuracy: 36.73
Round  11, Global train loss: 1.843, Global test loss: 1.854, Global test accuracy: 41.88
Round  12, Train loss: 1.923, Test loss: 1.842, Test accuracy: 36.81
Round  12, Global train loss: 1.923, Global test loss: 1.928, Global test accuracy: 40.06
Round  13, Train loss: 1.594, Test loss: 1.847, Test accuracy: 36.80
Round  13, Global train loss: 1.594, Global test loss: 1.694, Global test accuracy: 44.00
Round  14, Train loss: 1.693, Test loss: 1.834, Test accuracy: 36.87
Round  14, Global train loss: 1.693, Global test loss: 1.835, Global test accuracy: 41.76
Round  15, Train loss: 1.511, Test loss: 1.838, Test accuracy: 36.84
Round  15, Global train loss: 1.511, Global test loss: 1.660, Global test accuracy: 46.22
Round  16, Train loss: 1.667, Test loss: 1.845, Test accuracy: 36.70
Round  16, Global train loss: 1.667, Global test loss: 1.818, Global test accuracy: 44.67
Round  17, Train loss: 1.804, Test loss: 1.839, Test accuracy: 37.24
Round  17, Global train loss: 1.804, Global test loss: 1.916, Global test accuracy: 38.52
Round  18, Train loss: 1.557, Test loss: 1.837, Test accuracy: 37.69
Round  18, Global train loss: 1.557, Global test loss: 1.602, Global test accuracy: 46.26
Round  19, Train loss: 1.576, Test loss: 1.838, Test accuracy: 37.55
Round  19, Global train loss: 1.576, Global test loss: 1.689, Global test accuracy: 44.69
Round  20, Train loss: 1.591, Test loss: 1.867, Test accuracy: 37.20
Round  20, Global train loss: 1.591, Global test loss: 1.854, Global test accuracy: 40.88
Round  21, Train loss: 1.686, Test loss: 1.862, Test accuracy: 37.38
Round  21, Global train loss: 1.686, Global test loss: 1.794, Global test accuracy: 40.98
Round  22, Train loss: 1.602, Test loss: 1.885, Test accuracy: 36.94
Round  22, Global train loss: 1.602, Global test loss: 1.947, Global test accuracy: 37.10
Round  23, Train loss: 1.608, Test loss: 1.897, Test accuracy: 37.03
Round  23, Global train loss: 1.608, Global test loss: 1.789, Global test accuracy: 42.38
Round  24, Train loss: 1.457, Test loss: 1.905, Test accuracy: 36.94
Round  24, Global train loss: 1.457, Global test loss: 1.813, Global test accuracy: 41.73
Round  25, Train loss: 1.398, Test loss: 1.932, Test accuracy: 36.68
Round  25, Global train loss: 1.398, Global test loss: 1.690, Global test accuracy: 44.66
Round  26, Train loss: 1.695, Test loss: 1.932, Test accuracy: 36.66
Round  26, Global train loss: 1.695, Global test loss: 1.879, Global test accuracy: 40.97
Round  27, Train loss: 1.294, Test loss: 1.966, Test accuracy: 36.26
Round  27, Global train loss: 1.294, Global test loss: 1.685, Global test accuracy: 43.72
Round  28, Train loss: 1.377, Test loss: 1.995, Test accuracy: 36.29
Round  28, Global train loss: 1.377, Global test loss: 1.747, Global test accuracy: 42.80
Round  29, Train loss: 1.352, Test loss: 2.018, Test accuracy: 35.96
Round  29, Global train loss: 1.352, Global test loss: 1.737, Global test accuracy: 44.59
Round  30, Train loss: 1.316, Test loss: 2.036, Test accuracy: 35.86
Round  30, Global train loss: 1.316, Global test loss: 1.858, Global test accuracy: 38.17
Round  31, Train loss: 1.481, Test loss: 2.039, Test accuracy: 36.37
Round  31, Global train loss: 1.481, Global test loss: 1.787, Global test accuracy: 40.45
Round  32, Train loss: 1.386, Test loss: 2.068, Test accuracy: 36.10
Round  32, Global train loss: 1.386, Global test loss: 1.813, Global test accuracy: 42.33
Round  33, Train loss: 1.286, Test loss: 2.083, Test accuracy: 36.17
Round  33, Global train loss: 1.286, Global test loss: 1.828, Global test accuracy: 40.24
Round  34, Train loss: 1.258, Test loss: 2.111, Test accuracy: 35.90
Round  34, Global train loss: 1.258, Global test loss: 1.925, Global test accuracy: 35.23
Round  35, Train loss: 1.178, Test loss: 2.126, Test accuracy: 35.99
Round  35, Global train loss: 1.178, Global test loss: 1.702, Global test accuracy: 45.38
Round  36, Train loss: 1.203, Test loss: 2.174, Test accuracy: 36.09
Round  36, Global train loss: 1.203, Global test loss: 1.833, Global test accuracy: 38.56
Round  37, Train loss: 1.400, Test loss: 2.217, Test accuracy: 35.96
Round  37, Global train loss: 1.400, Global test loss: 2.003, Global test accuracy: 31.98
Round  38, Train loss: 1.146, Test loss: 2.238, Test accuracy: 35.76
Round  38, Global train loss: 1.146, Global test loss: 1.741, Global test accuracy: 39.48
Round  39, Train loss: 1.386, Test loss: 2.263, Test accuracy: 35.80
Round  39, Global train loss: 1.386, Global test loss: 1.943, Global test accuracy: 34.92
Round  40, Train loss: 0.823, Test loss: 2.265, Test accuracy: 36.06
Round  40, Global train loss: 0.823, Global test loss: 1.529, Global test accuracy: 48.65
Round  41, Train loss: 1.498, Test loss: 2.305, Test accuracy: 35.89
Round  41, Global train loss: 1.498, Global test loss: 2.066, Global test accuracy: 26.64
Round  42, Train loss: 1.199, Test loss: 2.368, Test accuracy: 35.58
Round  42, Global train loss: 1.199, Global test loss: 1.952, Global test accuracy: 35.35
Round  43, Train loss: 1.083, Test loss: 2.404, Test accuracy: 35.53
Round  43, Global train loss: 1.083, Global test loss: 1.787, Global test accuracy: 38.35
Round  44, Train loss: 1.078, Test loss: 2.463, Test accuracy: 35.06
Round  44, Global train loss: 1.078, Global test loss: 1.818, Global test accuracy: 38.09
Round  45, Train loss: 1.196, Test loss: 2.497, Test accuracy: 34.84
Round  45, Global train loss: 1.196, Global test loss: 2.031, Global test accuracy: 30.09
Round  46, Train loss: 1.147, Test loss: 2.533, Test accuracy: 34.69
Round  46, Global train loss: 1.147, Global test loss: 1.855, Global test accuracy: 36.06
Round  47, Train loss: 1.054, Test loss: 2.553, Test accuracy: 35.07
Round  47, Global train loss: 1.054, Global test loss: 1.907, Global test accuracy: 35.38
Round  48, Train loss: 0.881, Test loss: 2.596, Test accuracy: 34.86
Round  48, Global train loss: 0.881, Global test loss: 1.728, Global test accuracy: 39.20
Round  49, Train loss: 0.930, Test loss: 2.621, Test accuracy: 34.99
Round  49, Global train loss: 0.930, Global test loss: 1.747, Global test accuracy: 39.19
Round  50, Train loss: 0.904, Test loss: 2.651, Test accuracy: 34.96
Round  50, Global train loss: 0.904, Global test loss: 1.883, Global test accuracy: 36.84
Round  51, Train loss: 0.907, Test loss: 2.698, Test accuracy: 34.84
Round  51, Global train loss: 0.907, Global test loss: 1.816, Global test accuracy: 37.68
Round  52, Train loss: 0.925, Test loss: 2.745, Test accuracy: 34.62
Round  52, Global train loss: 0.925, Global test loss: 1.657, Global test accuracy: 42.79
Round  53, Train loss: 0.922, Test loss: 2.780, Test accuracy: 34.51
Round  53, Global train loss: 0.922, Global test loss: 1.731, Global test accuracy: 39.77
Round  54, Train loss: 0.931, Test loss: 2.800, Test accuracy: 34.54
Round  54, Global train loss: 0.931, Global test loss: 1.907, Global test accuracy: 34.63
Round  55, Train loss: 0.822, Test loss: 2.843, Test accuracy: 34.26
Round  55, Global train loss: 0.822, Global test loss: 1.894, Global test accuracy: 31.85
Round  56, Train loss: 0.927, Test loss: 2.890, Test accuracy: 34.29
Round  56, Global train loss: 0.927, Global test loss: 1.887, Global test accuracy: 35.23
Round  57, Train loss: 0.750, Test loss: 2.909, Test accuracy: 34.31
Round  57, Global train loss: 0.750, Global test loss: 1.634, Global test accuracy: 45.25
Round  58, Train loss: 0.877, Test loss: 2.895, Test accuracy: 34.38
Round  58, Global train loss: 0.877, Global test loss: 1.982, Global test accuracy: 30.62
Round  59, Train loss: 0.922, Test loss: 2.923, Test accuracy: 34.43
Round  59, Global train loss: 0.922, Global test loss: 1.916, Global test accuracy: 32.23
Round  60, Train loss: 0.858, Test loss: 2.949, Test accuracy: 34.33
Round  60, Global train loss: 0.858, Global test loss: 1.991, Global test accuracy: 28.99
Round  61, Train loss: 0.989, Test loss: 3.032, Test accuracy: 33.91
Round  61, Global train loss: 0.989, Global test loss: 2.015, Global test accuracy: 29.97
Round  62, Train loss: 0.901, Test loss: 3.045, Test accuracy: 34.10
Round  62, Global train loss: 0.901, Global test loss: 1.968, Global test accuracy: 31.98
Round  63, Train loss: 0.582, Test loss: 3.108, Test accuracy: 33.74
Round  63, Global train loss: 0.582, Global test loss: 1.712, Global test accuracy: 40.80
Round  64, Train loss: 0.665, Test loss: 3.166, Test accuracy: 33.92
Round  64, Global train loss: 0.665, Global test loss: 1.642, Global test accuracy: 42.23
Round  65, Train loss: 1.025, Test loss: 3.223, Test accuracy: 34.02
Round  65, Global train loss: 1.025, Global test loss: 2.132, Global test accuracy: 26.77
Round  66, Train loss: 0.606, Test loss: 3.179, Test accuracy: 34.32
Round  66, Global train loss: 0.606, Global test loss: 1.602, Global test accuracy: 45.41
Round  67, Train loss: 0.860, Test loss: 3.238, Test accuracy: 34.42
Round  67, Global train loss: 0.860, Global test loss: 1.992, Global test accuracy: 32.50
Round  68, Train loss: 0.779, Test loss: 3.252, Test accuracy: 34.41
Round  68, Global train loss: 0.779, Global test loss: 1.829, Global test accuracy: 37.98
Round  69, Train loss: 0.604, Test loss: 3.268, Test accuracy: 34.21
Round  69, Global train loss: 0.604, Global test loss: 1.873, Global test accuracy: 32.51
Round  70, Train loss: 0.666, Test loss: 3.281, Test accuracy: 34.32
Round  70, Global train loss: 0.666, Global test loss: 1.868, Global test accuracy: 32.85
Round  71, Train loss: 0.663, Test loss: 3.289, Test accuracy: 34.58
Round  71, Global train loss: 0.663, Global test loss: 1.990, Global test accuracy: 31.81
Round  72, Train loss: 0.781, Test loss: 3.359, Test accuracy: 34.42
Round  72, Global train loss: 0.781, Global test loss: 1.871, Global test accuracy: 36.36
Round  73, Train loss: 0.726, Test loss: 3.414, Test accuracy: 34.33
Round  73, Global train loss: 0.726, Global test loss: 1.865, Global test accuracy: 36.06
Round  74, Train loss: 0.807, Test loss: 3.413, Test accuracy: 34.01
Round  74, Global train loss: 0.807, Global test loss: 1.841, Global test accuracy: 37.69
Round  75, Train loss: 0.560, Test loss: 3.432, Test accuracy: 33.91
Round  75, Global train loss: 0.560, Global test loss: 1.693, Global test accuracy: 40.13
Round  76, Train loss: 0.641, Test loss: 3.492, Test accuracy: 33.94
Round  76, Global train loss: 0.641, Global test loss: 2.006, Global test accuracy: 28.20
Round  77, Train loss: 0.634, Test loss: 3.507, Test accuracy: 33.94
Round  77, Global train loss: 0.634, Global test loss: 1.929, Global test accuracy: 31.22
Round  78, Train loss: 0.604, Test loss: 3.560, Test accuracy: 34.16
Round  78, Global train loss: 0.604, Global test loss: 1.774, Global test accuracy: 37.26
Round  79, Train loss: 0.697, Test loss: 3.579, Test accuracy: 34.24
Round  79, Global train loss: 0.697, Global test loss: 1.871, Global test accuracy: 35.69
Round  80, Train loss: 0.610, Test loss: 3.638, Test accuracy: 34.07
Round  80, Global train loss: 0.610, Global test loss: 1.798, Global test accuracy: 38.26
Round  81, Train loss: 0.499, Test loss: 3.671, Test accuracy: 33.93
Round  81, Global train loss: 0.499, Global test loss: 1.718, Global test accuracy: 39.40
Round  82, Train loss: 0.467, Test loss: 3.731, Test accuracy: 34.19
Round  82, Global train loss: 0.467, Global test loss: 1.705, Global test accuracy: 39.96
Round  83, Train loss: 0.824, Test loss: 3.771, Test accuracy: 33.90
Round  83, Global train loss: 0.824, Global test loss: 2.069, Global test accuracy: 26.20
Round  84, Train loss: 0.559, Test loss: 3.801, Test accuracy: 33.60
Round  84, Global train loss: 0.559, Global test loss: 1.703, Global test accuracy: 41.81
Round  85, Train loss: 0.573, Test loss: 3.826, Test accuracy: 33.84
Round  85, Global train loss: 0.573, Global test loss: 1.724, Global test accuracy: 41.61
Round  86, Train loss: 0.605, Test loss: 3.838, Test accuracy: 33.93
Round  86, Global train loss: 0.605, Global test loss: 1.867, Global test accuracy: 35.28
Round  87, Train loss: 0.545, Test loss: 3.815, Test accuracy: 33.89
Round  87, Global train loss: 0.545, Global test loss: 1.785, Global test accuracy: 36.17
Round  88, Train loss: 0.523, Test loss: 3.804, Test accuracy: 34.12
Round  88, Global train loss: 0.523, Global test loss: 1.713, Global test accuracy: 41.70
Round  89, Train loss: 0.565, Test loss: 3.822, Test accuracy: 33.90
Round  89, Global train loss: 0.565, Global test loss: 1.918, Global test accuracy: 36.22
Round  90, Train loss: 0.504, Test loss: 3.840, Test accuracy: 34.10
Round  90, Global train loss: 0.504, Global test loss: 1.847, Global test accuracy: 34.52
Round  91, Train loss: 0.656, Test loss: 3.853, Test accuracy: 33.97
Round  91, Global train loss: 0.656, Global test loss: 2.010, Global test accuracy: 30.73
Round  92, Train loss: 0.590, Test loss: 3.898, Test accuracy: 34.06
Round  92, Global train loss: 0.590, Global test loss: 2.020, Global test accuracy: 27.01
Round  93, Train loss: 0.520, Test loss: 3.966, Test accuracy: 33.87
Round  93, Global train loss: 0.520, Global test loss: 1.799, Global test accuracy: 37.30
Round  94, Train loss: 0.421, Test loss: 3.983, Test accuracy: 33.91
Round  94, Global train loss: 0.421, Global test loss: 1.751, Global test accuracy: 37.72
Round  95, Train loss: 0.570, Test loss: 3.960, Test accuracy: 34.05
Round  95, Global train loss: 0.570, Global test loss: 1.965, Global test accuracy: 30.70
Round  96, Train loss: 0.621, Test loss: 4.003, Test accuracy: 33.77
Round  96, Global train loss: 0.621, Global test loss: 1.970, Global test accuracy: 30.68
Round  97, Train loss: 0.552, Test loss: 4.030, Test accuracy: 33.80
Round  97, Global train loss: 0.552, Global test loss: 1.956, Global test accuracy: 32.00
Round  98, Train loss: 0.561, Test loss: 3.996, Test accuracy: 33.98
Round  98, Global train loss: 0.561, Global test loss: 2.025, Global test accuracy: 29.02
Round  99, Train loss: 0.515, Test loss: 4.096, Test accuracy: 33.88
Round  99, Global train loss: 0.515, Global test loss: 1.918, Global test accuracy: 30.91
Final Round, Train loss: 0.349, Test loss: 4.689, Test accuracy: 33.55
Final Round, Global train loss: 0.349, Global test loss: 1.918, Global test accuracy: 30.91
Average accuracy final 10 rounds: 33.9395 

Average global accuracy final 10 rounds: 32.0585 

6398.351454496384
[5.306052207946777, 10.612104415893555, 15.542138814926147, 20.47217321395874, 25.547046899795532, 30.621920585632324, 35.81015682220459, 40.998393058776855, 46.10401916503906, 51.20964527130127, 56.30956792831421, 61.40949058532715, 66.52802205085754, 71.64655351638794, 76.78420376777649, 81.92185401916504, 87.11418986320496, 92.30652570724487, 97.48465299606323, 102.66278028488159, 107.8464686870575, 113.0301570892334, 118.25796294212341, 123.48576879501343, 128.71549153327942, 133.9452142715454, 139.0490162372589, 144.1528182029724, 149.26897740364075, 154.38513660430908, 159.49001240730286, 164.59488821029663, 169.15403270721436, 173.71317720413208, 178.24106812477112, 182.76895904541016, 187.30373334884644, 191.83850765228271, 196.3955042362213, 200.9525008201599, 205.49823594093323, 210.04397106170654, 214.43913006782532, 218.8342890739441, 223.20835971832275, 227.58243036270142, 232.013325214386, 236.44422006607056, 240.86639046669006, 245.28856086730957, 249.65099382400513, 254.01342678070068, 258.51280999183655, 263.0121932029724, 267.43368577957153, 271.85517835617065, 276.29803442955017, 280.7408905029297, 285.1730020046234, 289.60511350631714, 294.05750155448914, 298.50988960266113, 302.9219100475311, 307.3339304924011, 311.8191194534302, 316.30430841445923, 320.74903988838196, 325.1937713623047, 329.6462411880493, 334.09871101379395, 338.5265612602234, 342.95441150665283, 347.4506664276123, 351.9469213485718, 356.34737062454224, 360.7478199005127, 365.26671409606934, 369.785608291626, 374.219690322876, 378.653772354126, 383.1062533855438, 387.55873441696167, 391.9570779800415, 396.35542154312134, 400.81869196891785, 405.28196239471436, 409.6876292228699, 414.0932960510254, 418.54792737960815, 423.0025587081909, 427.39900946617126, 431.7954602241516, 436.2049322128296, 440.61440420150757, 445.01675748825073, 449.4191107749939, 453.81929636001587, 458.21948194503784, 462.64273858070374, 467.06599521636963, 471.4713406562805, 475.8766860961914, 480.43134117126465, 484.9859962463379, 489.3517029285431, 493.7174096107483, 498.06803607940674, 502.4186625480652, 506.7631371021271, 511.10761165618896, 515.4736120700836, 519.8396124839783, 524.1942756175995, 528.5489387512207, 533.0124430656433, 537.4759473800659, 541.8638026714325, 546.2516579627991, 550.8660380840302, 555.4804182052612, 559.8736069202423, 564.2667956352234, 568.6337096691132, 573.0006237030029, 577.3669612407684, 581.7332987785339, 586.232234954834, 590.731171131134, 595.1058032512665, 599.4804353713989, 604.0127625465393, 608.5450897216797, 612.8801372051239, 617.2151846885681, 621.5725226402283, 625.9298605918884, 630.2699892520905, 634.6101179122925, 639.1403224468231, 643.6705269813538, 648.0116767883301, 652.3528265953064, 656.8627483844757, 661.372670173645, 665.74010181427, 670.107533454895, 674.464243888855, 678.8209543228149, 683.2395031452179, 687.6580519676208, 692.1618480682373, 696.6656441688538, 701.0242252349854, 705.382806301117, 709.7706441879272, 714.1584820747375, 718.5165193080902, 722.8745565414429, 727.4175138473511, 731.9604711532593, 736.5286407470703, 741.0968103408813, 745.5072176456451, 749.9176249504089, 754.3760716915131, 758.8345184326172, 763.1560008525848, 767.4774832725525, 771.8194372653961, 776.1613912582397, 780.5259430408478, 784.8904948234558, 789.2218470573425, 793.5531992912292, 797.8949744701385, 802.2367496490479, 806.7516860961914, 811.266622543335, 815.8318898677826, 820.3971571922302, 824.8563134670258, 829.3154697418213, 833.8952991962433, 838.4751286506653, 843.005777835846, 847.5364270210266, 852.0015184879303, 856.466609954834, 861.0599522590637, 865.6532945632935, 870.2675862312317, 874.8818778991699, 879.4997580051422, 884.1176381111145, 888.7133536338806, 893.3090691566467, 897.7968633174896, 902.2846574783325, 906.7831282615662, 911.2815990447998, 913.5786459445953, 915.8756928443909]
[28.645, 28.645, 33.365, 33.365, 34.1375, 34.1375, 33.32, 33.32, 33.845, 33.845, 35.0475, 35.0475, 35.3075, 35.3075, 35.4775, 35.4775, 36.12, 36.12, 35.6625, 35.6625, 36.855, 36.855, 36.7325, 36.7325, 36.8075, 36.8075, 36.795, 36.795, 36.8725, 36.8725, 36.835, 36.835, 36.6975, 36.6975, 37.24, 37.24, 37.6925, 37.6925, 37.5525, 37.5525, 37.2025, 37.2025, 37.3775, 37.3775, 36.94, 36.94, 37.0275, 37.0275, 36.935, 36.935, 36.6775, 36.6775, 36.655, 36.655, 36.26, 36.26, 36.2875, 36.2875, 35.9575, 35.9575, 35.8625, 35.8625, 36.37, 36.37, 36.1, 36.1, 36.1675, 36.1675, 35.8975, 35.8975, 35.9875, 35.9875, 36.09, 36.09, 35.96, 35.96, 35.7575, 35.7575, 35.8025, 35.8025, 36.0625, 36.0625, 35.89, 35.89, 35.58, 35.58, 35.535, 35.535, 35.0575, 35.0575, 34.8425, 34.8425, 34.69, 34.69, 35.0675, 35.0675, 34.8625, 34.8625, 34.9875, 34.9875, 34.9625, 34.9625, 34.8425, 34.8425, 34.6225, 34.6225, 34.51, 34.51, 34.5425, 34.5425, 34.2625, 34.2625, 34.2875, 34.2875, 34.315, 34.315, 34.38, 34.38, 34.4275, 34.4275, 34.3275, 34.3275, 33.905, 33.905, 34.1025, 34.1025, 33.74, 33.74, 33.92, 33.92, 34.015, 34.015, 34.3225, 34.3225, 34.4225, 34.4225, 34.405, 34.405, 34.2125, 34.2125, 34.3225, 34.3225, 34.5825, 34.5825, 34.42, 34.42, 34.3275, 34.3275, 34.005, 34.005, 33.915, 33.915, 33.935, 33.935, 33.9375, 33.9375, 34.165, 34.165, 34.2375, 34.2375, 34.0725, 34.0725, 33.93, 33.93, 34.1875, 34.1875, 33.895, 33.895, 33.5975, 33.5975, 33.84, 33.84, 33.93, 33.93, 33.89, 33.89, 34.115, 34.115, 33.9025, 33.9025, 34.1, 34.1, 33.9675, 33.9675, 34.0575, 34.0575, 33.87, 33.87, 33.915, 33.915, 34.055, 34.055, 33.77, 33.77, 33.7975, 33.7975, 33.9825, 33.9825, 33.88, 33.88, 33.5525, 33.5525]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9491 (0.8542), real noise ratio: 0.8550
Client 2, noise level: 0.3194 (0.2875), real noise ratio: 0.2845
Client 3, noise level: 0.9178 (0.8260), real noise ratio: 0.8435
Client 4, noise level: 0.0319 (0.0287), real noise ratio: 0.0305
Client 6, noise level: 0.6298 (0.5668), real noise ratio: 0.5555
Client 7, noise level: 0.8738 (0.7864), real noise ratio: 0.7960
Client 8, noise level: 0.0087 (0.0078), real noise ratio: 0.0345
Client 9, noise level: 0.7466 (0.6719), real noise ratio: 0.6735
Client 13, noise level: 0.5093 (0.4583), real noise ratio: 0.4655
Client 15, noise level: 0.9556 (0.8600), real noise ratio: 0.8800
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.259, Test loss: 1.940, Test accuracy: 29.46
Round   0, Global train loss: 1.259, Global test loss: 2.234, Global test accuracy: 20.14
Round   1, Train loss: 1.479, Test loss: 1.726, Test accuracy: 35.51
Round   1, Global train loss: 1.479, Global test loss: 2.155, Global test accuracy: 22.08
Round   2, Train loss: 1.652, Test loss: 1.480, Test accuracy: 49.15
Round   2, Global train loss: 1.652, Global test loss: 2.049, Global test accuracy: 32.58
Round   3, Train loss: 1.372, Test loss: 1.438, Test accuracy: 48.88
Round   3, Global train loss: 1.372, Global test loss: 1.990, Global test accuracy: 30.64
Round   4, Train loss: 1.393, Test loss: 1.427, Test accuracy: 48.92
Round   4, Global train loss: 1.393, Global test loss: 2.017, Global test accuracy: 29.15
Round   5, Train loss: 0.951, Test loss: 1.331, Test accuracy: 52.90
Round   5, Global train loss: 0.951, Global test loss: 2.000, Global test accuracy: 32.84
Round   6, Train loss: 1.072, Test loss: 1.247, Test accuracy: 57.73
Round   6, Global train loss: 1.072, Global test loss: 1.784, Global test accuracy: 39.62
Round   7, Train loss: 0.885, Test loss: 1.294, Test accuracy: 56.41
Round   7, Global train loss: 0.885, Global test loss: 1.868, Global test accuracy: 35.27
Round   8, Train loss: 0.905, Test loss: 1.164, Test accuracy: 59.76
Round   8, Global train loss: 0.905, Global test loss: 1.858, Global test accuracy: 36.67
Round   9, Train loss: 1.404, Test loss: 1.093, Test accuracy: 63.79
Round   9, Global train loss: 1.404, Global test loss: 1.809, Global test accuracy: 40.00
Round  10, Train loss: 1.221, Test loss: 1.052, Test accuracy: 64.62
Round  10, Global train loss: 1.221, Global test loss: 1.871, Global test accuracy: 29.74
Round  11, Train loss: 1.411, Test loss: 1.066, Test accuracy: 64.41
Round  11, Global train loss: 1.411, Global test loss: 1.837, Global test accuracy: 41.46
Round  12, Train loss: 1.296, Test loss: 1.042, Test accuracy: 65.51
Round  12, Global train loss: 1.296, Global test loss: 1.874, Global test accuracy: 35.84
Round  13, Train loss: 1.059, Test loss: 1.014, Test accuracy: 67.02
Round  13, Global train loss: 1.059, Global test loss: 1.795, Global test accuracy: 40.67
Round  14, Train loss: 0.963, Test loss: 1.003, Test accuracy: 67.64
Round  14, Global train loss: 0.963, Global test loss: 1.679, Global test accuracy: 45.34
Round  15, Train loss: 0.973, Test loss: 0.994, Test accuracy: 67.93
Round  15, Global train loss: 0.973, Global test loss: 1.833, Global test accuracy: 35.25
Round  16, Train loss: 1.120, Test loss: 0.977, Test accuracy: 68.39
Round  16, Global train loss: 1.120, Global test loss: 1.766, Global test accuracy: 40.66
Round  17, Train loss: 1.226, Test loss: 0.981, Test accuracy: 68.78
Round  17, Global train loss: 1.226, Global test loss: 1.741, Global test accuracy: 44.09
Round  18, Train loss: 1.079, Test loss: 0.974, Test accuracy: 69.10
Round  18, Global train loss: 1.079, Global test loss: 1.799, Global test accuracy: 40.32
Round  19, Train loss: 1.532, Test loss: 0.967, Test accuracy: 69.36
Round  19, Global train loss: 1.532, Global test loss: 1.803, Global test accuracy: 39.91
Round  20, Train loss: 0.672, Test loss: 0.968, Test accuracy: 68.96
Round  20, Global train loss: 0.672, Global test loss: 1.572, Global test accuracy: 48.66
Round  21, Train loss: 0.934, Test loss: 0.970, Test accuracy: 68.88
Round  21, Global train loss: 0.934, Global test loss: 1.695, Global test accuracy: 42.58
Round  22, Train loss: 0.954, Test loss: 0.977, Test accuracy: 68.15
Round  22, Global train loss: 0.954, Global test loss: 1.701, Global test accuracy: 41.42
Round  23, Train loss: 1.072, Test loss: 0.994, Test accuracy: 67.84
Round  23, Global train loss: 1.072, Global test loss: 1.623, Global test accuracy: 47.58
Round  24, Train loss: 1.003, Test loss: 0.963, Test accuracy: 68.82
Round  24, Global train loss: 1.003, Global test loss: 1.670, Global test accuracy: 45.76
Round  25, Train loss: 1.233, Test loss: 0.960, Test accuracy: 69.49
Round  25, Global train loss: 1.233, Global test loss: 1.768, Global test accuracy: 41.92
Round  26, Train loss: 0.980, Test loss: 0.955, Test accuracy: 69.96
Round  26, Global train loss: 0.980, Global test loss: 1.727, Global test accuracy: 41.18
Round  27, Train loss: 0.813, Test loss: 0.951, Test accuracy: 69.78
Round  27, Global train loss: 0.813, Global test loss: 1.704, Global test accuracy: 42.24
Round  28, Train loss: 1.468, Test loss: 0.971, Test accuracy: 68.72
Round  28, Global train loss: 1.468, Global test loss: 1.837, Global test accuracy: 38.05
Round  29, Train loss: 1.097, Test loss: 0.974, Test accuracy: 68.88
Round  29, Global train loss: 1.097, Global test loss: 1.752, Global test accuracy: 42.41
Round  30, Train loss: 1.114, Test loss: 0.970, Test accuracy: 69.17
Round  30, Global train loss: 1.114, Global test loss: 1.654, Global test accuracy: 46.72
Round  31, Train loss: 0.928, Test loss: 0.961, Test accuracy: 69.60
Round  31, Global train loss: 0.928, Global test loss: 1.618, Global test accuracy: 47.82
Round  32, Train loss: 0.956, Test loss: 0.959, Test accuracy: 68.99
Round  32, Global train loss: 0.956, Global test loss: 1.585, Global test accuracy: 49.77
Round  33, Train loss: 1.163, Test loss: 0.953, Test accuracy: 68.81
Round  33, Global train loss: 1.163, Global test loss: 1.742, Global test accuracy: 41.39
Round  34, Train loss: 1.124, Test loss: 0.960, Test accuracy: 68.46
Round  34, Global train loss: 1.124, Global test loss: 1.813, Global test accuracy: 39.98
Round  35, Train loss: 0.914, Test loss: 0.970, Test accuracy: 68.17
Round  35, Global train loss: 0.914, Global test loss: 1.633, Global test accuracy: 46.98
Round  36, Train loss: 1.078, Test loss: 0.972, Test accuracy: 67.80
Round  36, Global train loss: 1.078, Global test loss: 1.709, Global test accuracy: 41.92
Round  37, Train loss: 0.970, Test loss: 0.978, Test accuracy: 67.58
Round  37, Global train loss: 0.970, Global test loss: 1.610, Global test accuracy: 45.67
Round  38, Train loss: 0.849, Test loss: 0.992, Test accuracy: 67.22
Round  38, Global train loss: 0.849, Global test loss: 1.743, Global test accuracy: 42.45
Round  39, Train loss: 0.704, Test loss: 0.961, Test accuracy: 68.17
Round  39, Global train loss: 0.704, Global test loss: 1.568, Global test accuracy: 48.77
Round  40, Train loss: 1.000, Test loss: 0.978, Test accuracy: 68.29
Round  40, Global train loss: 1.000, Global test loss: 1.608, Global test accuracy: 45.64
Round  41, Train loss: 1.103, Test loss: 0.985, Test accuracy: 67.46
Round  41, Global train loss: 1.103, Global test loss: 1.757, Global test accuracy: 40.44
Round  42, Train loss: 0.726, Test loss: 0.963, Test accuracy: 68.38
Round  42, Global train loss: 0.726, Global test loss: 1.589, Global test accuracy: 47.25
Round  43, Train loss: 0.775, Test loss: 0.969, Test accuracy: 68.42
Round  43, Global train loss: 0.775, Global test loss: 1.572, Global test accuracy: 48.83
Round  44, Train loss: 0.913, Test loss: 0.972, Test accuracy: 68.60
Round  44, Global train loss: 0.913, Global test loss: 1.647, Global test accuracy: 43.69
Round  45, Train loss: 0.785, Test loss: 0.962, Test accuracy: 68.62
Round  45, Global train loss: 0.785, Global test loss: 1.661, Global test accuracy: 44.45
Round  46, Train loss: 0.985, Test loss: 0.997, Test accuracy: 67.78
Round  46, Global train loss: 0.985, Global test loss: 1.763, Global test accuracy: 40.11
Round  47, Train loss: 0.709, Test loss: 1.003, Test accuracy: 67.62
Round  47, Global train loss: 0.709, Global test loss: 1.621, Global test accuracy: 45.56
Round  48, Train loss: 1.005, Test loss: 0.984, Test accuracy: 67.66
Round  48, Global train loss: 1.005, Global test loss: 1.695, Global test accuracy: 42.57
Round  49, Train loss: 0.745, Test loss: 0.998, Test accuracy: 67.45
Round  49, Global train loss: 0.745, Global test loss: 2.130, Global test accuracy: 43.37
Round  50, Train loss: 0.883, Test loss: 0.987, Test accuracy: 68.18
Round  50, Global train loss: 0.883, Global test loss: 1.859, Global test accuracy: 41.57
Round  51, Train loss: 0.839, Test loss: 1.000, Test accuracy: 67.96
Round  51, Global train loss: 0.839, Global test loss: 1.722, Global test accuracy: 43.36
Round  52, Train loss: 1.050, Test loss: 1.016, Test accuracy: 67.25
Round  52, Global train loss: 1.050, Global test loss: 1.854, Global test accuracy: 37.84
Round  53, Train loss: 0.617, Test loss: 1.017, Test accuracy: 67.34
Round  53, Global train loss: 0.617, Global test loss: 1.571, Global test accuracy: 46.98
Round  54, Train loss: 0.743, Test loss: 1.036, Test accuracy: 66.56
Round  54, Global train loss: 0.743, Global test loss: 1.955, Global test accuracy: 42.19
Round  55, Train loss: 0.778, Test loss: 1.051, Test accuracy: 66.23
Round  55, Global train loss: 0.778, Global test loss: 1.633, Global test accuracy: 46.62
Round  56, Train loss: 0.669, Test loss: 1.072, Test accuracy: 65.67
Round  56, Global train loss: 0.669, Global test loss: 1.767, Global test accuracy: 43.71
Round  57, Train loss: 0.603, Test loss: 1.071, Test accuracy: 66.33
Round  57, Global train loss: 0.603, Global test loss: 1.640, Global test accuracy: 46.58
Round  58, Train loss: 0.661, Test loss: 1.071, Test accuracy: 66.62
Round  58, Global train loss: 0.661, Global test loss: 1.588, Global test accuracy: 49.67
Round  59, Train loss: 0.647, Test loss: 1.107, Test accuracy: 66.06
Round  59, Global train loss: 0.647, Global test loss: 1.647, Global test accuracy: 48.97
Round  60, Train loss: 0.796, Test loss: 1.090, Test accuracy: 66.80
Round  60, Global train loss: 0.796, Global test loss: 1.701, Global test accuracy: 45.88
Round  61, Train loss: 0.820, Test loss: 1.112, Test accuracy: 66.54
Round  61, Global train loss: 0.820, Global test loss: 1.726, Global test accuracy: 46.50
Round  62, Train loss: 0.549, Test loss: 1.074, Test accuracy: 66.91
Round  62, Global train loss: 0.549, Global test loss: 1.685, Global test accuracy: 45.30
Round  63, Train loss: 0.755, Test loss: 1.084, Test accuracy: 66.81
Round  63, Global train loss: 0.755, Global test loss: 2.078, Global test accuracy: 36.93
Round  64, Train loss: 0.667, Test loss: 1.111, Test accuracy: 66.11
Round  64, Global train loss: 0.667, Global test loss: 1.698, Global test accuracy: 48.14
Round  65, Train loss: 0.695, Test loss: 1.104, Test accuracy: 67.09
Round  65, Global train loss: 0.695, Global test loss: 1.880, Global test accuracy: 43.90
Round  66, Train loss: 0.542, Test loss: 1.105, Test accuracy: 66.72
Round  66, Global train loss: 0.542, Global test loss: 1.887, Global test accuracy: 46.45
Round  67, Train loss: 0.546, Test loss: 1.136, Test accuracy: 66.23
Round  67, Global train loss: 0.546, Global test loss: 1.607, Global test accuracy: 49.70
Round  68, Train loss: 0.697, Test loss: 1.130, Test accuracy: 66.73
Round  68, Global train loss: 0.697, Global test loss: 1.626, Global test accuracy: 46.41
Round  69, Train loss: 0.737, Test loss: 1.142, Test accuracy: 66.44
Round  69, Global train loss: 0.737, Global test loss: 1.749, Global test accuracy: 41.94
Round  70, Train loss: 0.529, Test loss: 1.141, Test accuracy: 66.61
Round  70, Global train loss: 0.529, Global test loss: 1.775, Global test accuracy: 47.33
Round  71, Train loss: 0.498, Test loss: 1.153, Test accuracy: 66.55
Round  71, Global train loss: 0.498, Global test loss: 1.868, Global test accuracy: 44.61
Round  72, Train loss: 1.173, Test loss: 1.176, Test accuracy: 66.19
Round  72, Global train loss: 1.173, Global test loss: 1.921, Global test accuracy: 36.84
Round  73, Train loss: 0.628, Test loss: 1.184, Test accuracy: 65.93
Round  73, Global train loss: 0.628, Global test loss: 1.832, Global test accuracy: 45.98
Round  74, Train loss: 0.925, Test loss: 1.182, Test accuracy: 66.60
Round  74, Global train loss: 0.925, Global test loss: 1.757, Global test accuracy: 44.05
Round  75, Train loss: 0.895, Test loss: 1.144, Test accuracy: 66.61
Round  75, Global train loss: 0.895, Global test loss: 2.087, Global test accuracy: 38.03
Round  76, Train loss: 0.792, Test loss: 1.164, Test accuracy: 66.23
Round  76, Global train loss: 0.792, Global test loss: 1.974, Global test accuracy: 38.68
Round  77, Train loss: 0.577, Test loss: 1.164, Test accuracy: 66.72
Round  77, Global train loss: 0.577, Global test loss: 1.712, Global test accuracy: 48.83
Round  78, Train loss: 0.560, Test loss: 1.164, Test accuracy: 66.92
Round  78, Global train loss: 0.560, Global test loss: 1.811, Global test accuracy: 43.90
Round  79, Train loss: 0.690, Test loss: 1.208, Test accuracy: 66.47
Round  79, Global train loss: 0.690, Global test loss: 1.746, Global test accuracy: 46.16
Round  80, Train loss: 0.533, Test loss: 1.229, Test accuracy: 66.47
Round  80, Global train loss: 0.533, Global test loss: 1.656, Global test accuracy: 48.33
Round  81, Train loss: 0.702, Test loss: 1.254, Test accuracy: 66.30
Round  81, Global train loss: 0.702, Global test loss: 1.989, Global test accuracy: 38.62
Round  82, Train loss: 0.828, Test loss: 1.233, Test accuracy: 66.38
Round  82, Global train loss: 0.828, Global test loss: 2.061, Global test accuracy: 36.36
Round  83, Train loss: 0.797, Test loss: 1.206, Test accuracy: 66.45
Round  83, Global train loss: 0.797, Global test loss: 1.880, Global test accuracy: 40.53
Round  84, Train loss: 0.708, Test loss: 1.199, Test accuracy: 66.74
Round  84, Global train loss: 0.708, Global test loss: 1.949, Global test accuracy: 41.98
Round  85, Train loss: 0.610, Test loss: 1.221, Test accuracy: 66.25
Round  85, Global train loss: 0.610, Global test loss: 1.918, Global test accuracy: 43.04
Round  86, Train loss: 0.478, Test loss: 1.210, Test accuracy: 66.72
Round  86, Global train loss: 0.478, Global test loss: 1.886, Global test accuracy: 47.77
Round  87, Train loss: 0.549, Test loss: 1.215, Test accuracy: 66.55
Round  87, Global train loss: 0.549, Global test loss: 1.863, Global test accuracy: 46.12
Round  88, Train loss: 0.676, Test loss: 1.249, Test accuracy: 66.37
Round  88, Global train loss: 0.676, Global test loss: 2.137, Global test accuracy: 43.30
Round  89, Train loss: 0.483, Test loss: 1.263, Test accuracy: 66.35
Round  89, Global train loss: 0.483, Global test loss: 1.791, Global test accuracy: 48.10
Round  90, Train loss: 0.765, Test loss: 1.284, Test accuracy: 65.88
Round  90, Global train loss: 0.765, Global test loss: 2.169, Global test accuracy: 37.26
Round  91, Train loss: 0.594, Test loss: 1.298, Test accuracy: 65.42
Round  91, Global train loss: 0.594, Global test loss: 1.871, Global test accuracy: 44.17
Round  92, Train loss: 0.417, Test loss: 1.299, Test accuracy: 65.34
Round  92, Global train loss: 0.417, Global test loss: 2.231, Global test accuracy: 43.72
Round  93, Train loss: 0.423, Test loss: 1.310, Test accuracy: 65.12
Round  93, Global train loss: 0.423, Global test loss: 2.012, Global test accuracy: 49.08
Round  94, Train loss: 0.401, Test loss: 1.310, Test accuracy: 65.22
Round  94, Global train loss: 0.401, Global test loss: 2.117, Global test accuracy: 50.33
Round  95, Train loss: 0.640, Test loss: 1.284, Test accuracy: 65.52
Round  95, Global train loss: 0.640, Global test loss: 1.757, Global test accuracy: 45.24
Round  96, Train loss: 0.526, Test loss: 1.310, Test accuracy: 65.48
Round  96, Global train loss: 0.526, Global test loss: 1.774, Global test accuracy: 44.83
Round  97, Train loss: 0.582, Test loss: 1.271, Test accuracy: 66.56
Round  97, Global train loss: 0.582, Global test loss: 2.069, Global test accuracy: 42.97
Round  98, Train loss: 0.661, Test loss: 1.265, Test accuracy: 66.97
Round  98, Global train loss: 0.661, Global test loss: 2.088, Global test accuracy: 41.02
Round  99, Train loss: 0.581, Test loss: 1.309, Test accuracy: 66.22
Round  99, Global train loss: 0.581, Global test loss: 1.858, Global test accuracy: 44.92
Final Round, Train loss: 0.454, Test loss: 1.545, Test accuracy: 65.57
Final Round, Global train loss: 0.454, Global test loss: 1.858, Global test accuracy: 44.92
Average accuracy final 10 rounds: 65.77333333333333 

Average global accuracy final 10 rounds: 44.3525 

1953.7020943164825
[1.5888469219207764, 3.1776938438415527, 4.496316909790039, 5.814939975738525, 7.137251615524292, 8.459563255310059, 9.778004884719849, 11.096446514129639, 12.452176809310913, 13.807907104492188, 15.133830308914185, 16.45975351333618, 17.785403966903687, 19.11105442047119, 20.475613832473755, 21.84017324447632, 23.17608666419983, 24.51200008392334, 25.82663083076477, 27.1412615776062, 28.44845676422119, 29.75565195083618, 31.14901041984558, 32.54236888885498, 33.87125325202942, 35.20013761520386, 36.50736355781555, 37.814589500427246, 39.127541065216064, 40.44049263000488, 41.79227638244629, 43.144060134887695, 44.652082204818726, 46.160104274749756, 47.63381481170654, 49.10752534866333, 50.558470249176025, 52.00941514968872, 53.44535493850708, 54.88129472732544, 56.31705355644226, 57.75281238555908, 59.276287317276, 60.79976224899292, 62.243322134017944, 63.68688201904297, 65.18530178070068, 66.6837215423584, 68.15510487556458, 69.62648820877075, 71.12466025352478, 72.62283229827881, 73.9523012638092, 75.2817702293396, 76.58777403831482, 77.89377784729004, 79.21027660369873, 80.52677536010742, 81.84146428108215, 83.15615320205688, 84.48348546028137, 85.81081771850586, 87.12806415557861, 88.44531059265137, 89.78466153144836, 91.12401247024536, 92.5087559223175, 93.89349937438965, 95.25556826591492, 96.61763715744019, 98.00466346740723, 99.39168977737427, 100.78463768959045, 102.17758560180664, 103.52269625663757, 104.8678069114685, 106.19973969459534, 107.53167247772217, 108.86012578010559, 110.18857908248901, 111.50749397277832, 112.82640886306763, 114.15006589889526, 115.4737229347229, 116.80951452255249, 118.14530611038208, 119.48960852622986, 120.83391094207764, 122.21875309944153, 123.60359525680542, 124.93230485916138, 126.26101446151733, 127.61352181434631, 128.9660291671753, 130.4070074558258, 131.84798574447632, 133.2308440208435, 134.6137022972107, 135.98064470291138, 137.34758710861206, 138.7407112121582, 140.13383531570435, 141.4827539920807, 142.83167266845703, 144.25326704978943, 145.67486143112183, 147.0468168258667, 148.41877222061157, 149.8522424697876, 151.28571271896362, 152.6879734992981, 154.09023427963257, 155.51222729682922, 156.93422031402588, 158.38054537773132, 159.82687044143677, 161.21535420417786, 162.60383796691895, 164.03528094291687, 165.4667239189148, 166.88332152366638, 168.29991912841797, 169.65878224372864, 171.0176453590393, 172.3567876815796, 173.69593000411987, 175.06505036354065, 176.43417072296143, 177.8548777103424, 179.2755846977234, 180.69294810295105, 182.1103115081787, 183.47553968429565, 184.8407678604126, 186.24638414382935, 187.6520004272461, 189.02499127388, 190.39798212051392, 191.80362105369568, 193.20925998687744, 194.5614037513733, 195.91354751586914, 197.25237274169922, 198.5911979675293, 199.9214792251587, 201.2517604827881, 202.59052991867065, 203.92929935455322, 205.32496976852417, 206.72064018249512, 208.04980397224426, 209.3789677619934, 210.69925498962402, 212.01954221725464, 213.3440089225769, 214.66847562789917, 216.0040693283081, 217.33966302871704, 218.68081545829773, 220.02196788787842, 221.38473439216614, 222.74750089645386, 224.07505178451538, 225.4026026725769, 226.76081657409668, 228.11903047561646, 229.54422855377197, 230.9694266319275, 232.32445883750916, 233.67949104309082, 235.0468020439148, 236.41411304473877, 237.77838110923767, 239.14264917373657, 240.48395895957947, 241.82526874542236, 243.16659593582153, 244.5079231262207, 245.89089465141296, 247.27386617660522, 248.62190914154053, 249.96995210647583, 251.29397320747375, 252.61799430847168, 253.96966910362244, 255.3213438987732, 256.66379714012146, 258.0062503814697, 259.3422338962555, 260.67821741104126, 262.0213327407837, 263.3644480705261, 264.7120521068573, 266.0596561431885, 267.3924026489258, 268.7251491546631, 270.0662965774536, 271.40744400024414, 272.809330701828, 274.21121740341187, 276.52225613594055, 278.83329486846924]
[29.458333333333332, 29.458333333333332, 35.50833333333333, 35.50833333333333, 49.15, 49.15, 48.88333333333333, 48.88333333333333, 48.916666666666664, 48.916666666666664, 52.9, 52.9, 57.725, 57.725, 56.40833333333333, 56.40833333333333, 59.75833333333333, 59.75833333333333, 63.791666666666664, 63.791666666666664, 64.61666666666666, 64.61666666666666, 64.40833333333333, 64.40833333333333, 65.50833333333334, 65.50833333333334, 67.01666666666667, 67.01666666666667, 67.64166666666667, 67.64166666666667, 67.93333333333334, 67.93333333333334, 68.39166666666667, 68.39166666666667, 68.775, 68.775, 69.1, 69.1, 69.35833333333333, 69.35833333333333, 68.95833333333333, 68.95833333333333, 68.88333333333334, 68.88333333333334, 68.15, 68.15, 67.84166666666667, 67.84166666666667, 68.81666666666666, 68.81666666666666, 69.49166666666666, 69.49166666666666, 69.95833333333333, 69.95833333333333, 69.78333333333333, 69.78333333333333, 68.725, 68.725, 68.88333333333334, 68.88333333333334, 69.175, 69.175, 69.6, 69.6, 68.99166666666666, 68.99166666666666, 68.80833333333334, 68.80833333333334, 68.45833333333333, 68.45833333333333, 68.175, 68.175, 67.8, 67.8, 67.575, 67.575, 67.225, 67.225, 68.175, 68.175, 68.29166666666667, 68.29166666666667, 67.45833333333333, 67.45833333333333, 68.38333333333334, 68.38333333333334, 68.41666666666667, 68.41666666666667, 68.6, 68.6, 68.625, 68.625, 67.775, 67.775, 67.625, 67.625, 67.65833333333333, 67.65833333333333, 67.45, 67.45, 68.18333333333334, 68.18333333333334, 67.95833333333333, 67.95833333333333, 67.25, 67.25, 67.34166666666667, 67.34166666666667, 66.55833333333334, 66.55833333333334, 66.23333333333333, 66.23333333333333, 65.675, 65.675, 66.325, 66.325, 66.61666666666666, 66.61666666666666, 66.05833333333334, 66.05833333333334, 66.8, 66.8, 66.54166666666667, 66.54166666666667, 66.90833333333333, 66.90833333333333, 66.80833333333334, 66.80833333333334, 66.10833333333333, 66.10833333333333, 67.09166666666667, 67.09166666666667, 66.725, 66.725, 66.23333333333333, 66.23333333333333, 66.73333333333333, 66.73333333333333, 66.44166666666666, 66.44166666666666, 66.60833333333333, 66.60833333333333, 66.55, 66.55, 66.19166666666666, 66.19166666666666, 65.93333333333334, 65.93333333333334, 66.6, 66.6, 66.60833333333333, 66.60833333333333, 66.23333333333333, 66.23333333333333, 66.71666666666667, 66.71666666666667, 66.925, 66.925, 66.46666666666667, 66.46666666666667, 66.475, 66.475, 66.3, 66.3, 66.38333333333334, 66.38333333333334, 66.45, 66.45, 66.74166666666666, 66.74166666666666, 66.25, 66.25, 66.725, 66.725, 66.55, 66.55, 66.36666666666666, 66.36666666666666, 66.35, 66.35, 65.875, 65.875, 65.41666666666667, 65.41666666666667, 65.34166666666667, 65.34166666666667, 65.125, 65.125, 65.225, 65.225, 65.51666666666667, 65.51666666666667, 65.48333333333333, 65.48333333333333, 66.55833333333334, 66.55833333333334, 66.96666666666667, 66.96666666666667, 66.225, 66.225, 65.56666666666666, 65.56666666666666]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9491 (0.8542), real noise ratio: 0.8550
Client 2, noise level: 0.3194 (0.2875), real noise ratio: 0.2820
Client 3, noise level: 0.9178 (0.8260), real noise ratio: 0.8200
Client 4, noise level: 0.0319 (0.0287), real noise ratio: 0.1870
Client 6, noise level: 0.6298 (0.5668), real noise ratio: 0.5605
Client 7, noise level: 0.8738 (0.7864), real noise ratio: 0.8340
Client 8, noise level: 0.0087 (0.0078), real noise ratio: 0.1800
Client 9, noise level: 0.7466 (0.6719), real noise ratio: 0.7315
Client 13, noise level: 0.5093 (0.4583), real noise ratio: 0.5310
Client 15, noise level: 0.9556 (0.8600), real noise ratio: 0.8655
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.358, Test loss: 2.028, Test accuracy: 27.52
Round   0, Global train loss: 1.358, Global test loss: 2.280, Global test accuracy: 21.32
Round   1, Train loss: 1.348, Test loss: 1.846, Test accuracy: 34.15
Round   1, Global train loss: 1.348, Global test loss: 2.303, Global test accuracy: 20.42
Round   2, Train loss: 1.202, Test loss: 1.433, Test accuracy: 42.18
Round   2, Global train loss: 1.202, Global test loss: 2.050, Global test accuracy: 21.93
Round   3, Train loss: 1.032, Test loss: 1.418, Test accuracy: 48.79
Round   3, Global train loss: 1.032, Global test loss: 2.218, Global test accuracy: 27.98
Round   4, Train loss: 1.045, Test loss: 1.352, Test accuracy: 48.89
Round   4, Global train loss: 1.045, Global test loss: 2.051, Global test accuracy: 26.41
Round   5, Train loss: 0.731, Test loss: 1.271, Test accuracy: 52.73
Round   5, Global train loss: 0.731, Global test loss: 2.071, Global test accuracy: 31.89
Round   6, Train loss: 0.940, Test loss: 1.207, Test accuracy: 53.62
Round   6, Global train loss: 0.940, Global test loss: 1.841, Global test accuracy: 32.97
Round   7, Train loss: 0.730, Test loss: 1.232, Test accuracy: 55.29
Round   7, Global train loss: 0.730, Global test loss: 1.986, Global test accuracy: 34.39
Round   8, Train loss: 0.970, Test loss: 1.120, Test accuracy: 58.52
Round   8, Global train loss: 0.970, Global test loss: 1.868, Global test accuracy: 33.98
Round   9, Train loss: 1.390, Test loss: 1.064, Test accuracy: 62.70
Round   9, Global train loss: 1.390, Global test loss: 1.800, Global test accuracy: 38.72
Round  10, Train loss: 1.072, Test loss: 1.065, Test accuracy: 62.31
Round  10, Global train loss: 1.072, Global test loss: 1.906, Global test accuracy: 31.69
Round  11, Train loss: 0.833, Test loss: 1.029, Test accuracy: 63.71
Round  11, Global train loss: 0.833, Global test loss: 1.713, Global test accuracy: 38.01
Round  12, Train loss: 1.293, Test loss: 1.053, Test accuracy: 63.00
Round  12, Global train loss: 1.293, Global test loss: 1.807, Global test accuracy: 34.87
Round  13, Train loss: 1.263, Test loss: 1.010, Test accuracy: 64.82
Round  13, Global train loss: 1.263, Global test loss: 1.812, Global test accuracy: 36.85
Round  14, Train loss: 0.863, Test loss: 0.989, Test accuracy: 66.07
Round  14, Global train loss: 0.863, Global test loss: 1.613, Global test accuracy: 44.47
Round  15, Train loss: 1.249, Test loss: 0.979, Test accuracy: 66.28
Round  15, Global train loss: 1.249, Global test loss: 1.830, Global test accuracy: 36.15
Round  16, Train loss: 1.178, Test loss: 0.984, Test accuracy: 65.87
Round  16, Global train loss: 1.178, Global test loss: 1.691, Global test accuracy: 40.37
Round  17, Train loss: 1.201, Test loss: 0.977, Test accuracy: 67.03
Round  17, Global train loss: 1.201, Global test loss: 1.705, Global test accuracy: 45.32
Round  18, Train loss: 0.884, Test loss: 0.964, Test accuracy: 67.00
Round  18, Global train loss: 0.884, Global test loss: 1.916, Global test accuracy: 34.02
Round  19, Train loss: 1.255, Test loss: 0.959, Test accuracy: 67.98
Round  19, Global train loss: 1.255, Global test loss: 1.785, Global test accuracy: 41.01
Round  20, Train loss: 1.087, Test loss: 0.946, Test accuracy: 68.46
Round  20, Global train loss: 1.087, Global test loss: 1.638, Global test accuracy: 47.30
Round  21, Train loss: 0.904, Test loss: 0.960, Test accuracy: 67.62
Round  21, Global train loss: 0.904, Global test loss: 1.590, Global test accuracy: 46.22
Round  22, Train loss: 1.231, Test loss: 0.943, Test accuracy: 68.78
Round  22, Global train loss: 1.231, Global test loss: 1.717, Global test accuracy: 41.52
Round  23, Train loss: 1.282, Test loss: 0.970, Test accuracy: 67.47
Round  23, Global train loss: 1.282, Global test loss: 1.675, Global test accuracy: 48.95
Round  24, Train loss: 1.219, Test loss: 0.969, Test accuracy: 66.88
Round  24, Global train loss: 1.219, Global test loss: 1.694, Global test accuracy: 43.91
Round  25, Train loss: 0.993, Test loss: 0.960, Test accuracy: 67.54
Round  25, Global train loss: 0.993, Global test loss: 1.690, Global test accuracy: 44.52
Round  26, Train loss: 1.254, Test loss: 0.954, Test accuracy: 67.22
Round  26, Global train loss: 1.254, Global test loss: 1.684, Global test accuracy: 44.18
Round  27, Train loss: 1.030, Test loss: 0.941, Test accuracy: 68.30
Round  27, Global train loss: 1.030, Global test loss: 1.635, Global test accuracy: 45.77
Round  28, Train loss: 0.950, Test loss: 0.934, Test accuracy: 68.34
Round  28, Global train loss: 0.950, Global test loss: 1.797, Global test accuracy: 39.67
Round  29, Train loss: 0.987, Test loss: 0.950, Test accuracy: 67.70
Round  29, Global train loss: 0.987, Global test loss: 1.755, Global test accuracy: 40.31
Round  30, Train loss: 1.181, Test loss: 0.960, Test accuracy: 67.08
Round  30, Global train loss: 1.181, Global test loss: 1.674, Global test accuracy: 44.43
Round  31, Train loss: 0.910, Test loss: 0.966, Test accuracy: 67.10
Round  31, Global train loss: 0.910, Global test loss: 1.584, Global test accuracy: 48.23
Round  32, Train loss: 0.947, Test loss: 0.962, Test accuracy: 67.05
Round  32, Global train loss: 0.947, Global test loss: 1.490, Global test accuracy: 51.32
Round  33, Train loss: 1.167, Test loss: 0.961, Test accuracy: 66.97
Round  33, Global train loss: 1.167, Global test loss: 1.643, Global test accuracy: 46.30
Round  34, Train loss: 1.056, Test loss: 0.955, Test accuracy: 67.31
Round  34, Global train loss: 1.056, Global test loss: 1.861, Global test accuracy: 36.72
Round  35, Train loss: 1.195, Test loss: 0.931, Test accuracy: 68.25
Round  35, Global train loss: 1.195, Global test loss: 1.637, Global test accuracy: 48.58
Round  36, Train loss: 1.081, Test loss: 0.953, Test accuracy: 67.67
Round  36, Global train loss: 1.081, Global test loss: 1.693, Global test accuracy: 43.41
Round  37, Train loss: 0.888, Test loss: 0.959, Test accuracy: 67.47
Round  37, Global train loss: 0.888, Global test loss: 1.638, Global test accuracy: 44.69
Round  38, Train loss: 0.694, Test loss: 0.934, Test accuracy: 68.24
Round  38, Global train loss: 0.694, Global test loss: 1.669, Global test accuracy: 44.92
Round  39, Train loss: 1.252, Test loss: 0.929, Test accuracy: 68.12
Round  39, Global train loss: 1.252, Global test loss: 1.642, Global test accuracy: 48.53
Round  40, Train loss: 0.899, Test loss: 0.918, Test accuracy: 68.20
Round  40, Global train loss: 0.899, Global test loss: 1.622, Global test accuracy: 45.41
Round  41, Train loss: 0.569, Test loss: 0.928, Test accuracy: 67.53
Round  41, Global train loss: 0.569, Global test loss: 1.615, Global test accuracy: 45.28
Round  42, Train loss: 0.745, Test loss: 0.926, Test accuracy: 68.03
Round  42, Global train loss: 0.745, Global test loss: 1.527, Global test accuracy: 48.65
Round  43, Train loss: 1.035, Test loss: 0.934, Test accuracy: 67.62
Round  43, Global train loss: 1.035, Global test loss: 1.568, Global test accuracy: 48.14
Round  44, Train loss: 0.888, Test loss: 0.933, Test accuracy: 68.22
Round  44, Global train loss: 0.888, Global test loss: 1.700, Global test accuracy: 42.85
Round  45, Train loss: 1.179, Test loss: 0.914, Test accuracy: 68.97
Round  45, Global train loss: 1.179, Global test loss: 1.722, Global test accuracy: 42.03
Round  46, Train loss: 1.009, Test loss: 0.939, Test accuracy: 67.71
Round  46, Global train loss: 1.009, Global test loss: 1.695, Global test accuracy: 43.00
Round  47, Train loss: 0.937, Test loss: 0.954, Test accuracy: 67.03
Round  47, Global train loss: 0.937, Global test loss: 1.748, Global test accuracy: 41.41
Round  48, Train loss: 0.779, Test loss: 0.933, Test accuracy: 67.85
Round  48, Global train loss: 0.779, Global test loss: 1.774, Global test accuracy: 41.86
Round  49, Train loss: 1.025, Test loss: 0.957, Test accuracy: 67.29
Round  49, Global train loss: 1.025, Global test loss: 1.725, Global test accuracy: 42.03
Round  50, Train loss: 0.701, Test loss: 0.998, Test accuracy: 66.30
Round  50, Global train loss: 0.701, Global test loss: 2.131, Global test accuracy: 39.27
Round  51, Train loss: 1.143, Test loss: 0.996, Test accuracy: 66.32
Round  51, Global train loss: 1.143, Global test loss: 1.741, Global test accuracy: 40.56
Round  52, Train loss: 1.072, Test loss: 0.994, Test accuracy: 66.28
Round  52, Global train loss: 1.072, Global test loss: 1.765, Global test accuracy: 39.98
Round  53, Train loss: 0.683, Test loss: 0.989, Test accuracy: 66.80
Round  53, Global train loss: 0.683, Global test loss: 1.640, Global test accuracy: 44.58
Round  54, Train loss: 0.845, Test loss: 0.998, Test accuracy: 66.48
Round  54, Global train loss: 0.845, Global test loss: 1.703, Global test accuracy: 44.30
Round  55, Train loss: 0.787, Test loss: 0.966, Test accuracy: 67.73
Round  55, Global train loss: 0.787, Global test loss: 1.637, Global test accuracy: 45.26
Round  56, Train loss: 0.838, Test loss: 0.986, Test accuracy: 66.83
Round  56, Global train loss: 0.838, Global test loss: 1.857, Global test accuracy: 38.98
Round  57, Train loss: 0.778, Test loss: 0.993, Test accuracy: 66.95
Round  57, Global train loss: 0.778, Global test loss: 1.563, Global test accuracy: 47.79
Round  58, Train loss: 0.649, Test loss: 0.968, Test accuracy: 67.99
Round  58, Global train loss: 0.649, Global test loss: 1.684, Global test accuracy: 47.04
Round  59, Train loss: 0.871, Test loss: 0.971, Test accuracy: 67.48
Round  59, Global train loss: 0.871, Global test loss: 1.599, Global test accuracy: 47.86
Round  60, Train loss: 0.966, Test loss: 0.974, Test accuracy: 67.74
Round  60, Global train loss: 0.966, Global test loss: 1.699, Global test accuracy: 43.64
Round  61, Train loss: 0.659, Test loss: 0.990, Test accuracy: 66.87
Round  61, Global train loss: 0.659, Global test loss: 1.586, Global test accuracy: 49.92
Round  62, Train loss: 0.655, Test loss: 1.025, Test accuracy: 66.91
Round  62, Global train loss: 0.655, Global test loss: 1.698, Global test accuracy: 44.63
Round  63, Train loss: 0.664, Test loss: 1.002, Test accuracy: 67.11
Round  63, Global train loss: 0.664, Global test loss: 2.315, Global test accuracy: 33.76
Round  64, Train loss: 0.805, Test loss: 1.007, Test accuracy: 67.42
Round  64, Global train loss: 0.805, Global test loss: 1.549, Global test accuracy: 50.41
Round  65, Train loss: 0.696, Test loss: 1.006, Test accuracy: 67.38
Round  65, Global train loss: 0.696, Global test loss: 1.654, Global test accuracy: 50.37
Round  66, Train loss: 0.562, Test loss: 1.026, Test accuracy: 66.76
Round  66, Global train loss: 0.562, Global test loss: 1.848, Global test accuracy: 49.05
Round  67, Train loss: 0.544, Test loss: 1.006, Test accuracy: 67.41
Round  67, Global train loss: 0.544, Global test loss: 1.751, Global test accuracy: 49.17
Round  68, Train loss: 0.623, Test loss: 0.999, Test accuracy: 67.44
Round  68, Global train loss: 0.623, Global test loss: 1.657, Global test accuracy: 46.84
Round  69, Train loss: 0.628, Test loss: 1.022, Test accuracy: 66.96
Round  69, Global train loss: 0.628, Global test loss: 1.869, Global test accuracy: 42.13
Round  70, Train loss: 0.470, Test loss: 1.007, Test accuracy: 67.34
Round  70, Global train loss: 0.470, Global test loss: 1.591, Global test accuracy: 48.67
Round  71, Train loss: 0.660, Test loss: 1.030, Test accuracy: 66.88
Round  71, Global train loss: 0.660, Global test loss: 1.767, Global test accuracy: 44.05
Round  72, Train loss: 1.001, Test loss: 1.000, Test accuracy: 68.08
Round  72, Global train loss: 1.001, Global test loss: 1.701, Global test accuracy: 43.69
Round  73, Train loss: 0.775, Test loss: 1.002, Test accuracy: 68.06
Round  73, Global train loss: 0.775, Global test loss: 1.590, Global test accuracy: 50.09
Round  74, Train loss: 0.619, Test loss: 0.977, Test accuracy: 68.79
Round  74, Global train loss: 0.619, Global test loss: 1.726, Global test accuracy: 47.24
Round  75, Train loss: 0.814, Test loss: 1.018, Test accuracy: 68.28
Round  75, Global train loss: 0.814, Global test loss: 1.916, Global test accuracy: 40.59
Round  76, Train loss: 0.679, Test loss: 1.032, Test accuracy: 67.90
Round  76, Global train loss: 0.679, Global test loss: 1.799, Global test accuracy: 43.12
Round  77, Train loss: 0.913, Test loss: 1.030, Test accuracy: 67.63
Round  77, Global train loss: 0.913, Global test loss: 1.656, Global test accuracy: 46.70
Round  78, Train loss: 0.531, Test loss: 1.032, Test accuracy: 67.77
Round  78, Global train loss: 0.531, Global test loss: 1.695, Global test accuracy: 46.13
Round  79, Train loss: 0.915, Test loss: 1.034, Test accuracy: 67.73
Round  79, Global train loss: 0.915, Global test loss: 1.712, Global test accuracy: 44.99
Round  80, Train loss: 0.529, Test loss: 1.052, Test accuracy: 67.83
Round  80, Global train loss: 0.529, Global test loss: 1.726, Global test accuracy: 45.90
Round  81, Train loss: 0.769, Test loss: 1.070, Test accuracy: 67.58
Round  81, Global train loss: 0.769, Global test loss: 1.834, Global test accuracy: 42.33
Round  82, Train loss: 1.091, Test loss: 1.111, Test accuracy: 66.38
Round  82, Global train loss: 1.091, Global test loss: 2.028, Global test accuracy: 34.80
Round  83, Train loss: 0.830, Test loss: 1.141, Test accuracy: 65.44
Round  83, Global train loss: 0.830, Global test loss: 1.924, Global test accuracy: 39.58
Round  84, Train loss: 0.647, Test loss: 1.144, Test accuracy: 65.46
Round  84, Global train loss: 0.647, Global test loss: 1.747, Global test accuracy: 43.96
Round  85, Train loss: 0.541, Test loss: 1.133, Test accuracy: 65.97
Round  85, Global train loss: 0.541, Global test loss: 1.808, Global test accuracy: 44.66
Round  86, Train loss: 0.588, Test loss: 1.142, Test accuracy: 65.94
Round  86, Global train loss: 0.588, Global test loss: 1.701, Global test accuracy: 50.14
Round  87, Train loss: 0.550, Test loss: 1.166, Test accuracy: 65.76
Round  87, Global train loss: 0.550, Global test loss: 1.743, Global test accuracy: 47.64
Round  88, Train loss: 0.717, Test loss: 1.141, Test accuracy: 66.63
Round  88, Global train loss: 0.717, Global test loss: 1.922, Global test accuracy: 44.80
Round  89, Train loss: 0.639, Test loss: 1.147, Test accuracy: 66.29
Round  89, Global train loss: 0.639, Global test loss: 1.749, Global test accuracy: 46.79
Round  90, Train loss: 0.543, Test loss: 1.144, Test accuracy: 66.30
Round  90, Global train loss: 0.543, Global test loss: 2.080, Global test accuracy: 41.99
Round  91, Train loss: 0.843, Test loss: 1.148, Test accuracy: 66.11
Round  91, Global train loss: 0.843, Global test loss: 1.696, Global test accuracy: 47.77
Round  92, Train loss: 0.509, Test loss: 1.155, Test accuracy: 65.68
Round  92, Global train loss: 0.509, Global test loss: 1.704, Global test accuracy: 46.67
Round  93, Train loss: 0.572, Test loss: 1.124, Test accuracy: 66.38
Round  93, Global train loss: 0.572, Global test loss: 1.831, Global test accuracy: 48.73
Round  94, Train loss: 0.962, Test loss: 1.201, Test accuracy: 64.88
Round  94, Global train loss: 0.962, Global test loss: 1.992, Global test accuracy: 40.40
Round  95, Train loss: 0.487, Test loss: 1.182, Test accuracy: 65.24
Round  95, Global train loss: 0.487, Global test loss: 1.777, Global test accuracy: 49.14
Round  96, Train loss: 0.496, Test loss: 1.169, Test accuracy: 65.67
Round  96, Global train loss: 0.496, Global test loss: 1.685, Global test accuracy: 48.63
Round  97, Train loss: 0.896, Test loss: 1.133, Test accuracy: 66.60
Round  97, Global train loss: 0.896, Global test loss: 1.832, Global test accuracy: 42.71
Round  98, Train loss: 0.788, Test loss: 1.137, Test accuracy: 66.44
Round  98, Global train loss: 0.788, Global test loss: 1.966, Global test accuracy: 41.02
Round  99, Train loss: 0.401, Test loss: 1.159, Test accuracy: 65.92
Round  99, Global train loss: 0.401, Global test loss: 2.143, Global test accuracy: 41.67
Final Round, Train loss: 0.529, Test loss: 1.285, Test accuracy: 65.92
Final Round, Global train loss: 0.529, Global test loss: 2.143, Global test accuracy: 41.67
Average accuracy final 10 rounds: 65.92166666666667 

Average global accuracy final 10 rounds: 44.872499999999995 

2029.0105702877045
[1.822544813156128, 3.645089626312256, 5.394254446029663, 7.14341926574707, 8.856544494628906, 10.569669723510742, 12.207023620605469, 13.844377517700195, 15.454699277877808, 17.06502103805542, 18.49206280708313, 19.91910457611084, 21.339756965637207, 22.760409355163574, 24.19607400894165, 25.631738662719727, 27.03960871696472, 28.447478771209717, 29.86017370223999, 31.272868633270264, 32.6869912147522, 34.10111379623413, 35.49690318107605, 36.89269256591797, 38.30506372451782, 39.717434883117676, 41.23125433921814, 42.7450737953186, 44.23280119895935, 45.7205286026001, 47.22711634635925, 48.73370409011841, 50.17914700508118, 51.624589920043945, 53.073211431503296, 54.52183294296265, 56.01853156089783, 57.51523017883301, 58.99417757987976, 60.473124980926514, 61.99335861206055, 63.51359224319458, 64.97719383239746, 66.44079542160034, 67.86602354049683, 69.29125165939331, 70.73951554298401, 72.1877794265747, 73.59890961647034, 75.01003980636597, 76.46959829330444, 77.92915678024292, 79.3563220500946, 80.78348731994629, 82.20251679420471, 83.62154626846313, 85.1312038898468, 86.64086151123047, 88.07806849479675, 89.51527547836304, 90.94834089279175, 92.38140630722046, 93.89143109321594, 95.40145587921143, 96.81520414352417, 98.22895240783691, 99.64657640457153, 101.06420040130615, 102.48277854919434, 103.90135669708252, 105.3134560585022, 106.72555541992188, 108.1597535610199, 109.59395170211792, 111.01565885543823, 112.43736600875854, 113.86118674278259, 115.28500747680664, 116.71196293830872, 118.13891839981079, 119.55313420295715, 120.96735000610352, 122.3706316947937, 123.77391338348389, 125.1823377609253, 126.5907621383667, 128.01861214637756, 129.44646215438843, 130.86536145210266, 132.2842607498169, 133.69655442237854, 135.10884809494019, 136.5215663909912, 137.93428468704224, 139.35142850875854, 140.76857233047485, 142.18927764892578, 143.6099829673767, 145.06373286247253, 146.51748275756836, 147.9796016216278, 149.44172048568726, 150.8316297531128, 152.22153902053833, 153.64158725738525, 155.06163549423218, 156.44980144500732, 157.83796739578247, 159.31169176101685, 160.78541612625122, 162.200603723526, 163.61579132080078, 165.06812119483948, 166.52045106887817, 167.99265480041504, 169.4648585319519, 170.9419002532959, 172.4189419746399, 173.91594648361206, 175.41295099258423, 176.89268803596497, 178.3724250793457, 179.8668417930603, 181.3612585067749, 182.84266018867493, 184.32406187057495, 185.77271938323975, 187.22137689590454, 188.7133538722992, 190.20533084869385, 191.69365286827087, 193.1819748878479, 194.70533633232117, 196.22869777679443, 197.72006034851074, 199.21142292022705, 200.67225694656372, 202.1330909729004, 203.6467432975769, 205.16039562225342, 206.64599585533142, 208.13159608840942, 209.64201188087463, 211.15242767333984, 212.66170048713684, 214.17097330093384, 215.68192791938782, 217.1928825378418, 218.70968341827393, 220.22648429870605, 221.70815324783325, 223.18982219696045, 224.63104152679443, 226.07226085662842, 227.52547550201416, 228.9786901473999, 230.4781985282898, 231.9777069091797, 233.44774961471558, 234.91779232025146, 236.4322531223297, 237.94671392440796, 239.44297432899475, 240.93923473358154, 242.41315698623657, 243.8870792388916, 245.37658023834229, 246.86608123779297, 248.34701991081238, 249.8279585838318, 251.2974615097046, 252.7669644355774, 254.22029852867126, 255.67363262176514, 257.1770167350769, 258.6804008483887, 260.14582204818726, 261.61124324798584, 263.22663140296936, 264.8420195579529, 266.47598457336426, 268.10994958877563, 269.715283870697, 271.3206181526184, 272.95445680618286, 274.5882954597473, 276.2160942554474, 277.84389305114746, 279.50558161735535, 281.16727018356323, 282.8032705783844, 284.43927097320557, 286.0961127281189, 287.7529544830322, 289.4320819377899, 291.1112093925476, 292.75365591049194, 294.3961024284363, 296.0644624233246, 297.7328224182129, 300.5077805519104, 303.2827386856079]
[27.525, 27.525, 34.15, 34.15, 42.18333333333333, 42.18333333333333, 48.791666666666664, 48.791666666666664, 48.891666666666666, 48.891666666666666, 52.725, 52.725, 53.61666666666667, 53.61666666666667, 55.291666666666664, 55.291666666666664, 58.525, 58.525, 62.7, 62.7, 62.30833333333333, 62.30833333333333, 63.708333333333336, 63.708333333333336, 63.0, 63.0, 64.81666666666666, 64.81666666666666, 66.06666666666666, 66.06666666666666, 66.275, 66.275, 65.86666666666666, 65.86666666666666, 67.03333333333333, 67.03333333333333, 67.0, 67.0, 67.98333333333333, 67.98333333333333, 68.45833333333333, 68.45833333333333, 67.625, 67.625, 68.78333333333333, 68.78333333333333, 67.475, 67.475, 66.875, 66.875, 67.54166666666667, 67.54166666666667, 67.21666666666667, 67.21666666666667, 68.3, 68.3, 68.34166666666667, 68.34166666666667, 67.7, 67.7, 67.075, 67.075, 67.1, 67.1, 67.05, 67.05, 66.975, 66.975, 67.30833333333334, 67.30833333333334, 68.25, 68.25, 67.675, 67.675, 67.475, 67.475, 68.24166666666666, 68.24166666666666, 68.125, 68.125, 68.2, 68.2, 67.53333333333333, 67.53333333333333, 68.03333333333333, 68.03333333333333, 67.61666666666666, 67.61666666666666, 68.21666666666667, 68.21666666666667, 68.96666666666667, 68.96666666666667, 67.70833333333333, 67.70833333333333, 67.03333333333333, 67.03333333333333, 67.85, 67.85, 67.29166666666667, 67.29166666666667, 66.3, 66.3, 66.31666666666666, 66.31666666666666, 66.28333333333333, 66.28333333333333, 66.8, 66.8, 66.48333333333333, 66.48333333333333, 67.73333333333333, 67.73333333333333, 66.825, 66.825, 66.95, 66.95, 67.99166666666666, 67.99166666666666, 67.48333333333333, 67.48333333333333, 67.74166666666666, 67.74166666666666, 66.86666666666666, 66.86666666666666, 66.90833333333333, 66.90833333333333, 67.10833333333333, 67.10833333333333, 67.41666666666667, 67.41666666666667, 67.38333333333334, 67.38333333333334, 66.75833333333334, 66.75833333333334, 67.40833333333333, 67.40833333333333, 67.44166666666666, 67.44166666666666, 66.95833333333333, 66.95833333333333, 67.34166666666667, 67.34166666666667, 66.88333333333334, 66.88333333333334, 68.08333333333333, 68.08333333333333, 68.05833333333334, 68.05833333333334, 68.79166666666667, 68.79166666666667, 68.28333333333333, 68.28333333333333, 67.9, 67.9, 67.63333333333334, 67.63333333333334, 67.76666666666667, 67.76666666666667, 67.73333333333333, 67.73333333333333, 67.825, 67.825, 67.58333333333333, 67.58333333333333, 66.375, 66.375, 65.44166666666666, 65.44166666666666, 65.45833333333333, 65.45833333333333, 65.96666666666667, 65.96666666666667, 65.94166666666666, 65.94166666666666, 65.75833333333334, 65.75833333333334, 66.63333333333334, 66.63333333333334, 66.29166666666667, 66.29166666666667, 66.3, 66.3, 66.10833333333333, 66.10833333333333, 65.68333333333334, 65.68333333333334, 66.38333333333334, 66.38333333333334, 64.875, 64.875, 65.24166666666666, 65.24166666666666, 65.66666666666667, 65.66666666666667, 66.6, 66.6, 66.44166666666666, 66.44166666666666, 65.91666666666667, 65.91666666666667, 65.925, 65.925]/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Co-teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9491 (0.8542), real noise ratio: 0.8570
Client 2, noise level: 0.3194 (0.2875), real noise ratio: 0.2925
Client 3, noise level: 0.9178 (0.8260), real noise ratio: 0.8385
Client 4, noise level: 0.0319 (0.0287), real noise ratio: 0.0275
Client 6, noise level: 0.6298 (0.5668), real noise ratio: 0.5690
Client 7, noise level: 0.8738 (0.7864), real noise ratio: 0.7930
Client 8, noise level: 0.0087 (0.0078), real noise ratio: 0.1510
Client 9, noise level: 0.7466 (0.6719), real noise ratio: 0.7105
Client 13, noise level: 0.5093 (0.4583), real noise ratio: 0.5265
Client 15, noise level: 0.9556 (0.8600), real noise ratio: 0.8705
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.478, Test loss: 2.157, Test accuracy: 18.24
Round   1, Train loss: 1.028, Test loss: 1.879, Test accuracy: 33.42
Round   2, Train loss: 0.943, Test loss: 1.269, Test accuracy: 46.99
Round   3, Train loss: 0.773, Test loss: 1.313, Test accuracy: 54.60
Round   4, Train loss: 0.652, Test loss: 1.224, Test accuracy: 55.13
Round   5, Train loss: 0.600, Test loss: 1.104, Test accuracy: 58.27
Round   6, Train loss: 0.602, Test loss: 0.914, Test accuracy: 61.80
Round   7, Train loss: 0.613, Test loss: 1.064, Test accuracy: 61.38
Round   8, Train loss: 0.621, Test loss: 0.835, Test accuracy: 65.69
Round   9, Train loss: 0.718, Test loss: 0.709, Test accuracy: 70.28
Round  10, Train loss: 0.548, Test loss: 0.737, Test accuracy: 69.65
Round  11, Train loss: 0.629, Test loss: 0.692, Test accuracy: 71.25
Round  12, Train loss: 0.701, Test loss: 0.686, Test accuracy: 71.39
Round  13, Train loss: 0.600, Test loss: 0.596, Test accuracy: 74.44
Round  14, Train loss: 0.570, Test loss: 0.574, Test accuracy: 75.38
Round  15, Train loss: 0.606, Test loss: 0.578, Test accuracy: 75.11
Round  16, Train loss: 0.548, Test loss: 0.562, Test accuracy: 75.93
Round  17, Train loss: 0.533, Test loss: 0.546, Test accuracy: 76.89
Round  18, Train loss: 0.548, Test loss: 0.549, Test accuracy: 77.31
Round  19, Train loss: 0.619, Test loss: 0.539, Test accuracy: 77.45
Round  20, Train loss: 0.454, Test loss: 0.517, Test accuracy: 78.53
Round  21, Train loss: 0.466, Test loss: 0.517, Test accuracy: 78.53
Round  22, Train loss: 0.516, Test loss: 0.506, Test accuracy: 78.79
Round  23, Train loss: 0.489, Test loss: 0.498, Test accuracy: 79.41
Round  24, Train loss: 0.495, Test loss: 0.499, Test accuracy: 79.22
Round  25, Train loss: 0.608, Test loss: 0.502, Test accuracy: 79.22
Round  26, Train loss: 0.435, Test loss: 0.493, Test accuracy: 79.61
Round  27, Train loss: 0.393, Test loss: 0.486, Test accuracy: 79.79
Round  28, Train loss: 0.516, Test loss: 0.489, Test accuracy: 79.60
Round  29, Train loss: 0.390, Test loss: 0.496, Test accuracy: 79.48
Round  30, Train loss: 0.611, Test loss: 0.482, Test accuracy: 79.56
Round  31, Train loss: 0.502, Test loss: 0.468, Test accuracy: 80.30
Round  32, Train loss: 0.355, Test loss: 0.466, Test accuracy: 80.09
Round  33, Train loss: 0.468, Test loss: 0.470, Test accuracy: 80.24
Round  34, Train loss: 0.470, Test loss: 0.466, Test accuracy: 80.72
Round  35, Train loss: 0.470, Test loss: 0.459, Test accuracy: 80.98
Round  36, Train loss: 0.476, Test loss: 0.451, Test accuracy: 81.32
Round  37, Train loss: 0.448, Test loss: 0.451, Test accuracy: 81.38
Round  38, Train loss: 0.392, Test loss: 0.442, Test accuracy: 81.78
Round  39, Train loss: 0.332, Test loss: 0.438, Test accuracy: 81.77
Round  40, Train loss: 0.438, Test loss: 0.436, Test accuracy: 82.14
Round  41, Train loss: 0.418, Test loss: 0.432, Test accuracy: 82.00
Round  42, Train loss: 0.343, Test loss: 0.425, Test accuracy: 82.52
Round  43, Train loss: 0.311, Test loss: 0.425, Test accuracy: 82.70
Round  44, Train loss: 0.479, Test loss: 0.430, Test accuracy: 82.44
Round  45, Train loss: 0.333, Test loss: 0.420, Test accuracy: 82.84
Round  46, Train loss: 0.376, Test loss: 0.423, Test accuracy: 82.67
Round  47, Train loss: 0.362, Test loss: 0.427, Test accuracy: 82.58
Round  48, Train loss: 0.288, Test loss: 0.426, Test accuracy: 82.47
Round  49, Train loss: 0.304, Test loss: 0.413, Test accuracy: 83.28
Round  50, Train loss: 0.383, Test loss: 0.413, Test accuracy: 83.22
Round  51, Train loss: 0.379, Test loss: 0.410, Test accuracy: 83.38
Round  52, Train loss: 0.411, Test loss: 0.415, Test accuracy: 83.00
Round  53, Train loss: 0.301, Test loss: 0.410, Test accuracy: 83.13
Round  54, Train loss: 0.250, Test loss: 0.411, Test accuracy: 83.08
Round  55, Train loss: 0.427, Test loss: 0.408, Test accuracy: 83.04
Round  56, Train loss: 0.274, Test loss: 0.406, Test accuracy: 83.38
Round  57, Train loss: 0.370, Test loss: 0.402, Test accuracy: 83.76
Round  58, Train loss: 0.351, Test loss: 0.396, Test accuracy: 84.12
Round  59, Train loss: 0.245, Test loss: 0.397, Test accuracy: 84.22
Round  60, Train loss: 0.302, Test loss: 0.392, Test accuracy: 84.31
Round  61, Train loss: 0.423, Test loss: 0.393, Test accuracy: 84.19
Round  62, Train loss: 0.289, Test loss: 0.390, Test accuracy: 84.35
Round  63, Train loss: 0.302, Test loss: 0.406, Test accuracy: 83.58
Round  64, Train loss: 0.415, Test loss: 0.393, Test accuracy: 84.17
Round  65, Train loss: 0.322, Test loss: 0.401, Test accuracy: 83.87
Round  66, Train loss: 0.274, Test loss: 0.405, Test accuracy: 83.79
Round  67, Train loss: 0.273, Test loss: 0.402, Test accuracy: 83.83
Round  68, Train loss: 0.320, Test loss: 0.398, Test accuracy: 83.78
Round  69, Train loss: 0.267, Test loss: 0.384, Test accuracy: 84.45
Round  70, Train loss: 0.214, Test loss: 0.388, Test accuracy: 84.49
Round  71, Train loss: 0.212, Test loss: 0.391, Test accuracy: 84.33
Round  72, Train loss: 0.421, Test loss: 0.398, Test accuracy: 83.70
Round  73, Train loss: 0.285, Test loss: 0.392, Test accuracy: 84.32
Round  74, Train loss: 0.354, Test loss: 0.384, Test accuracy: 84.67
Round  75, Train loss: 0.262, Test loss: 0.392, Test accuracy: 84.24
Round  76, Train loss: 0.309, Test loss: 0.385, Test accuracy: 84.32
Round  77, Train loss: 0.255, Test loss: 0.381, Test accuracy: 84.81
Round  78, Train loss: 0.270, Test loss: 0.392, Test accuracy: 84.27
Round  79, Train loss: 0.292, Test loss: 0.388, Test accuracy: 84.66
Round  80, Train loss: 0.179, Test loss: 0.396, Test accuracy: 84.22
Round  81, Train loss: 0.263, Test loss: 0.388, Test accuracy: 84.78
Round  82, Train loss: 0.268, Test loss: 0.386, Test accuracy: 84.77
Round  83, Train loss: 0.318, Test loss: 0.387, Test accuracy: 84.38
Round  84, Train loss: 0.214, Test loss: 0.384, Test accuracy: 84.88
Round  85, Train loss: 0.223, Test loss: 0.382, Test accuracy: 85.04
Round  86, Train loss: 0.215, Test loss: 0.387, Test accuracy: 84.95
Round  87, Train loss: 0.280, Test loss: 0.383, Test accuracy: 84.86
Round  88, Train loss: 0.260, Test loss: 0.391, Test accuracy: 84.65
Round  89, Train loss: 0.308, Test loss: 0.383, Test accuracy: 84.65
Round  90, Train loss: 0.312, Test loss: 0.392, Test accuracy: 84.47
Round  91, Train loss: 0.302, Test loss: 0.381, Test accuracy: 85.12
Round  92, Train loss: 0.183, Test loss: 0.381, Test accuracy: 85.03
Round  93, Train loss: 0.257, Test loss: 0.382, Test accuracy: 85.06
Round  94, Train loss: 0.198, Test loss: 0.393, Test accuracy: 84.57
Round  95, Train loss: 0.306, Test loss: 0.380, Test accuracy: 84.83
Round  96, Train loss: 0.207, Test loss: 0.380, Test accuracy: 85.12
Round  97, Train loss: 0.284, Test loss: 0.386, Test accuracy: 85.12
Round  98, Train loss: 0.190, Test loss: 0.386, Test accuracy: 84.90
Round  99, Train loss: 0.210, Test loss: 0.380, Test accuracy: 85.62
Final Round, Train loss: 0.198, Test loss: 0.380, Test accuracy: 85.73
Average accuracy final 10 rounds: 84.985
1420.3988182544708
[2.1157641410827637, 3.962470054626465, 5.781735181808472, 7.59981632232666, 9.437915802001953, 11.281258821487427, 13.108482360839844, 14.958766222000122, 16.77408790588379, 18.583557605743408, 20.410322904586792, 22.253777265548706, 24.08684515953064, 25.935225248336792, 27.749956369400024, 29.569971084594727, 31.399290561676025, 33.06003499031067, 34.75282692909241, 36.42003130912781, 38.09798812866211, 39.78033638000488, 41.45823097229004, 43.14957022666931, 44.85089111328125, 46.550508975982666, 48.21978950500488, 49.89287304878235, 51.573174715042114, 53.27919411659241, 55.00623369216919, 56.691157817840576, 58.356640100479126, 60.0558979511261, 61.73092031478882, 63.38606524467468, 65.06076788902283, 66.78029823303223, 68.47697496414185, 70.15298509597778, 71.83873677253723, 73.50861287117004, 75.22660493850708, 77.05968689918518, 78.8963634967804, 80.73409652709961, 82.54393196105957, 84.23312163352966, 85.91153693199158, 87.5944173336029, 89.26332712173462, 90.97324180603027, 92.67519640922546, 94.40300846099854, 96.09442234039307, 97.76119303703308, 99.41740322113037, 101.13513326644897, 102.84075546264648, 104.51657462120056, 106.1869900226593, 107.88495993614197, 109.58383250236511, 111.27343082427979, 112.95553994178772, 114.66117572784424, 116.3477897644043, 118.06256461143494, 119.76791048049927, 121.45388674736023, 123.10608625411987, 124.77264285087585, 126.430668592453, 128.10899090766907, 129.78690266609192, 131.4580729007721, 133.10975885391235, 134.7517659664154, 136.42668890953064, 138.10585761070251, 139.77136039733887, 141.47696805000305, 143.13112926483154, 144.8074402809143, 146.48236751556396, 148.18023824691772, 149.83733415603638, 151.49585914611816, 153.15743708610535, 154.82169890403748, 156.46384596824646, 158.12021946907043, 159.813640832901, 161.50099754333496, 163.15623569488525, 164.81938099861145, 166.49535489082336, 168.15619659423828, 169.82504796981812, 171.4865734577179, 173.6648666858673]
[18.241666666666667, 33.416666666666664, 46.99166666666667, 54.6, 55.13333333333333, 58.275, 61.8, 61.38333333333333, 65.69166666666666, 70.28333333333333, 69.65, 71.25, 71.39166666666667, 74.44166666666666, 75.38333333333334, 75.10833333333333, 75.93333333333334, 76.89166666666667, 77.30833333333334, 77.45, 78.53333333333333, 78.525, 78.79166666666667, 79.40833333333333, 79.225, 79.225, 79.60833333333333, 79.79166666666667, 79.6, 79.48333333333333, 79.55833333333334, 80.3, 80.09166666666667, 80.24166666666666, 80.71666666666667, 80.98333333333333, 81.31666666666666, 81.38333333333334, 81.78333333333333, 81.76666666666667, 82.14166666666667, 82.0, 82.51666666666667, 82.7, 82.44166666666666, 82.84166666666667, 82.675, 82.575, 82.475, 83.275, 83.225, 83.375, 83.0, 83.13333333333334, 83.075, 83.04166666666667, 83.375, 83.75833333333334, 84.11666666666666, 84.21666666666667, 84.30833333333334, 84.19166666666666, 84.35, 83.575, 84.175, 83.86666666666666, 83.79166666666667, 83.83333333333333, 83.78333333333333, 84.45, 84.49166666666666, 84.325, 83.7, 84.31666666666666, 84.675, 84.24166666666666, 84.31666666666666, 84.80833333333334, 84.26666666666667, 84.65833333333333, 84.225, 84.775, 84.76666666666667, 84.375, 84.875, 85.04166666666667, 84.95, 84.85833333333333, 84.65, 84.65, 84.475, 85.11666666666666, 85.03333333333333, 85.05833333333334, 84.56666666666666, 84.83333333333333, 85.11666666666666, 85.125, 84.9, 85.625, 85.73333333333333]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9491 (0.8542), real noise ratio: 0.8470
Client 2, noise level: 0.3194 (0.2875), real noise ratio: 0.3430
Client 3, noise level: 0.9178 (0.8260), real noise ratio: 0.8370
Client 4, noise level: 0.0319 (0.0287), real noise ratio: 0.0315
Client 6, noise level: 0.6298 (0.5668), real noise ratio: 0.5615
Client 7, noise level: 0.8738 (0.7864), real noise ratio: 0.7855
Client 8, noise level: 0.0087 (0.0078), real noise ratio: 0.1220
Client 9, noise level: 0.7466 (0.6719), real noise ratio: 0.7100
Client 13, noise level: 0.5093 (0.4583), real noise ratio: 0.4850
Client 15, noise level: 0.9556 (0.8600), real noise ratio: 0.8735
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  20.2300
Traceback (most recent call last):
  File "RFL.py", line 126, in <module>
    w_local, loss_local, f_k = local.train(copy.deepcopy(net_glob).to(args.device), copy.deepcopy(f_G).to(args.device),
  File "/home/ChenSM/code/FL_HLS/util/local_training.py", line 257, in train
    for batch_idx, (images, labels, idxs) in enumerate(self.ldr_train_tmp):
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/code/FL_HLS/util/local_training.py", line 48, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 51009 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9491 (0.8542), real noise ratio: 0.8500
Client 2, noise level: 0.3194 (0.2875), real noise ratio: 0.4030
Client 3, noise level: 0.9178 (0.8260), real noise ratio: 0.8270
Client 4, noise level: 0.0319 (0.0287), real noise ratio: 0.1440
Client 6, noise level: 0.6298 (0.5668), real noise ratio: 0.5965
Client 7, noise level: 0.8738 (0.7864), real noise ratio: 0.7900
Client 8, noise level: 0.0087 (0.0078), real noise ratio: 0.1945
Client 9, noise level: 0.7466 (0.6719), real noise ratio: 0.6915
Client 13, noise level: 0.5093 (0.4583), real noise ratio: 0.5470
Client 15, noise level: 0.9556 (0.8600), real noise ratio: 0.8715
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Traceback (most recent call last):
  File "main_fedpac.py", line 232, in <module>
    w_local, loss, indd, class_center_local, class_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1272, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 51282 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.4 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9491 (0.8542), real noise ratio: 0.8540
Client 2, noise level: 0.3194 (0.2875), real noise ratio: 0.3410
Client 3, noise level: 0.9178 (0.8260), real noise ratio: 0.8270
Client 4, noise level: 0.0319 (0.0287), real noise ratio: 0.1155
Client 6, noise level: 0.6298 (0.5668), real noise ratio: 0.6545
Client 7, noise level: 0.8738 (0.7864), real noise ratio: 0.8040
Client 8, noise level: 0.0087 (0.0078), real noise ratio: 0.0425
Client 9, noise level: 0.7466 (0.6719), real noise ratio: 0.7135
Client 13, noise level: 0.5093 (0.4583), real noise ratio: 0.5195
Client 15, noise level: 0.9556 (0.8600), real noise ratio: 0.8735
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Traceback (most recent call last):
  File "main_fedpac_psl.py", line 235, in <module>
    w_local, loss, indd, class_center_local, class_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx], iter_num_now = iter, train_iter=iter)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1977, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train_local):
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 51683 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9745 (0.8771), real noise ratio: 0.8715
Client 2, noise level: 0.6597 (0.5937), real noise ratio: 0.5855
Client 3, noise level: 0.9589 (0.8630), real noise ratio: 0.8650
Client 4, noise level: 0.5160 (0.4644), real noise ratio: 0.5595
Client 6, noise level: 0.8149 (0.7334), real noise ratio: 0.7720
Client 7, noise level: 0.9369 (0.8432), real noise ratio: 0.8440
Client 8, noise level: 0.5044 (0.4539), real noise ratio: 0.5465
Client 9, noise level: 0.8733 (0.7860), real noise ratio: 0.8015
Client 13, noise level: 0.7546 (0.6792), real noise ratio: 0.7230
Client 15, noise level: 0.9778 (0.8800), real noise ratio: 0.8895
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.146, Test loss: 2.177, Test accuracy: 24.33
Round   0, Global train loss: 2.146, Global test loss: 2.182, Global test accuracy: 24.78
Round   1, Train loss: 2.175, Test loss: 2.138, Test accuracy: 27.06
Round   1, Global train loss: 2.175, Global test loss: 2.148, Global test accuracy: 29.02
Round   2, Train loss: 1.928, Test loss: 1.968, Test accuracy: 31.84
Round   2, Global train loss: 1.928, Global test loss: 1.814, Global test accuracy: 38.92
Round   3, Train loss: 2.059, Test loss: 2.005, Test accuracy: 33.15
Round   3, Global train loss: 2.059, Global test loss: 1.956, Global test accuracy: 44.19
Round   4, Train loss: 1.994, Test loss: 1.977, Test accuracy: 31.82
Round   4, Global train loss: 1.994, Global test loss: 1.954, Global test accuracy: 36.88
Round   5, Train loss: 2.198, Test loss: 2.009, Test accuracy: 31.20
Round   5, Global train loss: 2.198, Global test loss: 2.200, Global test accuracy: 33.35
Round   6, Train loss: 2.010, Test loss: 1.959, Test accuracy: 32.48
Round   6, Global train loss: 2.010, Global test loss: 1.973, Global test accuracy: 42.47
Round   7, Train loss: 1.903, Test loss: 1.952, Test accuracy: 32.83
Round   7, Global train loss: 1.903, Global test loss: 2.014, Global test accuracy: 41.45
Round   8, Train loss: 1.854, Test loss: 1.936, Test accuracy: 32.77
Round   8, Global train loss: 1.854, Global test loss: 1.813, Global test accuracy: 41.60
Round   9, Train loss: 1.820, Test loss: 1.942, Test accuracy: 32.98
Round   9, Global train loss: 1.820, Global test loss: 1.818, Global test accuracy: 42.32
Round  10, Train loss: 1.821, Test loss: 1.944, Test accuracy: 33.28
Round  10, Global train loss: 1.821, Global test loss: 1.954, Global test accuracy: 36.74
Round  11, Train loss: 1.677, Test loss: 1.918, Test accuracy: 33.84
Round  11, Global train loss: 1.677, Global test loss: 1.852, Global test accuracy: 39.80
Round  12, Train loss: 1.734, Test loss: 1.925, Test accuracy: 33.61
Round  12, Global train loss: 1.734, Global test loss: 1.625, Global test accuracy: 48.55
Round  13, Train loss: 1.795, Test loss: 1.922, Test accuracy: 33.92
Round  13, Global train loss: 1.795, Global test loss: 1.866, Global test accuracy: 38.43
Round  14, Train loss: 1.880, Test loss: 1.919, Test accuracy: 33.95
Round  14, Global train loss: 1.880, Global test loss: 1.941, Global test accuracy: 42.63
Round  15, Train loss: 1.721, Test loss: 1.921, Test accuracy: 33.93
Round  15, Global train loss: 1.721, Global test loss: 1.828, Global test accuracy: 40.93
Round  16, Train loss: 1.755, Test loss: 1.924, Test accuracy: 33.74
Round  16, Global train loss: 1.755, Global test loss: 1.929, Global test accuracy: 33.04
Round  17, Train loss: 1.792, Test loss: 1.938, Test accuracy: 33.34
Round  17, Global train loss: 1.792, Global test loss: 2.081, Global test accuracy: 30.77
Round  18, Train loss: 1.760, Test loss: 1.940, Test accuracy: 33.08
Round  18, Global train loss: 1.760, Global test loss: 1.768, Global test accuracy: 49.47
Round  19, Train loss: 1.839, Test loss: 1.957, Test accuracy: 33.07
Round  19, Global train loss: 1.839, Global test loss: 2.087, Global test accuracy: 30.84
Round  20, Train loss: 1.753, Test loss: 1.956, Test accuracy: 33.33
Round  20, Global train loss: 1.753, Global test loss: 2.072, Global test accuracy: 30.45
Round  21, Train loss: 1.738, Test loss: 1.974, Test accuracy: 32.89
Round  21, Global train loss: 1.738, Global test loss: 1.870, Global test accuracy: 43.00
Round  22, Train loss: 1.797, Test loss: 1.982, Test accuracy: 32.88
Round  22, Global train loss: 1.797, Global test loss: 1.964, Global test accuracy: 40.47
Round  23, Train loss: 1.336, Test loss: 2.012, Test accuracy: 32.63
Round  23, Global train loss: 1.336, Global test loss: 1.652, Global test accuracy: 45.16
Round  24, Train loss: 1.738, Test loss: 2.025, Test accuracy: 32.61
Round  24, Global train loss: 1.738, Global test loss: 1.996, Global test accuracy: 37.68
Round  25, Train loss: 1.429, Test loss: 2.066, Test accuracy: 32.40
Round  25, Global train loss: 1.429, Global test loss: 1.878, Global test accuracy: 33.78
Round  26, Train loss: 1.589, Test loss: 2.087, Test accuracy: 32.12
Round  26, Global train loss: 1.589, Global test loss: 1.943, Global test accuracy: 33.78
Round  27, Train loss: 1.433, Test loss: 2.104, Test accuracy: 32.14
Round  27, Global train loss: 1.433, Global test loss: 2.004, Global test accuracy: 32.73
Round  28, Train loss: 1.224, Test loss: 2.124, Test accuracy: 32.09
Round  28, Global train loss: 1.224, Global test loss: 1.656, Global test accuracy: 46.91
Round  29, Train loss: 1.307, Test loss: 2.148, Test accuracy: 32.27
Round  29, Global train loss: 1.307, Global test loss: 1.822, Global test accuracy: 35.70
Round  30, Train loss: 1.664, Test loss: 2.164, Test accuracy: 32.06
Round  30, Global train loss: 1.664, Global test loss: 2.072, Global test accuracy: 30.41
Round  31, Train loss: 1.623, Test loss: 2.184, Test accuracy: 31.77
Round  31, Global train loss: 1.623, Global test loss: 2.063, Global test accuracy: 35.82
Round  32, Train loss: 1.286, Test loss: 2.224, Test accuracy: 31.73
Round  32, Global train loss: 1.286, Global test loss: 1.914, Global test accuracy: 32.27
Round  33, Train loss: 1.200, Test loss: 2.257, Test accuracy: 31.23
Round  33, Global train loss: 1.200, Global test loss: 1.607, Global test accuracy: 47.25
Round  34, Train loss: 1.380, Test loss: 2.258, Test accuracy: 31.45
Round  34, Global train loss: 1.380, Global test loss: 1.847, Global test accuracy: 38.95
Round  35, Train loss: 1.330, Test loss: 2.287, Test accuracy: 31.41
Round  35, Global train loss: 1.330, Global test loss: 1.863, Global test accuracy: 41.05
Round  36, Train loss: 1.124, Test loss: 2.300, Test accuracy: 31.52
Round  36, Global train loss: 1.124, Global test loss: 1.919, Global test accuracy: 33.00
Round  37, Train loss: 1.362, Test loss: 2.320, Test accuracy: 31.19
Round  37, Global train loss: 1.362, Global test loss: 1.859, Global test accuracy: 37.55
Round  38, Train loss: 1.099, Test loss: 2.366, Test accuracy: 31.33
Round  38, Global train loss: 1.099, Global test loss: 1.956, Global test accuracy: 29.00
Round  39, Train loss: 1.291, Test loss: 2.404, Test accuracy: 31.31
Round  39, Global train loss: 1.291, Global test loss: 1.963, Global test accuracy: 30.52
Round  40, Train loss: 1.705, Test loss: 2.443, Test accuracy: 30.94
Round  40, Global train loss: 1.705, Global test loss: 2.098, Global test accuracy: 32.69
Round  41, Train loss: 0.921, Test loss: 2.496, Test accuracy: 30.36
Round  41, Global train loss: 0.921, Global test loss: 1.618, Global test accuracy: 43.94
Round  42, Train loss: 1.184, Test loss: 2.507, Test accuracy: 30.61
Round  42, Global train loss: 1.184, Global test loss: 1.757, Global test accuracy: 38.40
Round  43, Train loss: 1.188, Test loss: 2.536, Test accuracy: 30.35
Round  43, Global train loss: 1.188, Global test loss: 1.913, Global test accuracy: 33.14
Round  44, Train loss: 1.304, Test loss: 2.570, Test accuracy: 30.05
Round  44, Global train loss: 1.304, Global test loss: 1.969, Global test accuracy: 29.23
Round  45, Train loss: 0.898, Test loss: 2.593, Test accuracy: 30.43
Round  45, Global train loss: 0.898, Global test loss: 1.586, Global test accuracy: 47.86
Round  46, Train loss: 1.157, Test loss: 2.630, Test accuracy: 30.55
Round  46, Global train loss: 1.157, Global test loss: 1.986, Global test accuracy: 33.24
Round  47, Train loss: 1.098, Test loss: 2.688, Test accuracy: 30.58
Round  47, Global train loss: 1.098, Global test loss: 1.843, Global test accuracy: 36.16
Round  48, Train loss: 1.207, Test loss: 2.699, Test accuracy: 30.55
Round  48, Global train loss: 1.207, Global test loss: 1.891, Global test accuracy: 38.62
Round  49, Train loss: 1.371, Test loss: 2.765, Test accuracy: 30.19
Round  49, Global train loss: 1.371, Global test loss: 2.083, Global test accuracy: 34.13
Round  50, Train loss: 1.447, Test loss: 2.791, Test accuracy: 30.38
Round  50, Global train loss: 1.447, Global test loss: 2.173, Global test accuracy: 22.45
Round  51, Train loss: 1.030, Test loss: 2.835, Test accuracy: 30.34
Round  51, Global train loss: 1.030, Global test loss: 1.911, Global test accuracy: 32.69
Round  52, Train loss: 1.137, Test loss: 2.906, Test accuracy: 30.03
Round  52, Global train loss: 1.137, Global test loss: 1.936, Global test accuracy: 33.38
Round  53, Train loss: 1.003, Test loss: 2.922, Test accuracy: 29.97
Round  53, Global train loss: 1.003, Global test loss: 1.954, Global test accuracy: 31.48
Round  54, Train loss: 1.122, Test loss: 2.976, Test accuracy: 29.86
Round  54, Global train loss: 1.122, Global test loss: 1.823, Global test accuracy: 40.39
Round  55, Train loss: 1.263, Test loss: 3.024, Test accuracy: 29.80
Round  55, Global train loss: 1.263, Global test loss: 2.062, Global test accuracy: 31.20
Round  56, Train loss: 0.965, Test loss: 3.078, Test accuracy: 29.75
Round  56, Global train loss: 0.965, Global test loss: 2.013, Global test accuracy: 31.24
Round  57, Train loss: 1.040, Test loss: 3.097, Test accuracy: 29.81
Round  57, Global train loss: 1.040, Global test loss: 2.096, Global test accuracy: 22.58
Round  58, Train loss: 0.958, Test loss: 3.103, Test accuracy: 29.70
Round  58, Global train loss: 0.958, Global test loss: 1.988, Global test accuracy: 29.30
Round  59, Train loss: 0.891, Test loss: 3.175, Test accuracy: 29.69
Round  59, Global train loss: 0.891, Global test loss: 1.997, Global test accuracy: 28.18
Round  60, Train loss: 1.069, Test loss: 3.199, Test accuracy: 29.44
Round  60, Global train loss: 1.069, Global test loss: 2.004, Global test accuracy: 32.14
Round  61, Train loss: 0.885, Test loss: 3.219, Test accuracy: 29.44
Round  61, Global train loss: 0.885, Global test loss: 1.831, Global test accuracy: 36.42
Round  62, Train loss: 0.972, Test loss: 3.249, Test accuracy: 29.28
Round  62, Global train loss: 0.972, Global test loss: 1.784, Global test accuracy: 42.70
Round  63, Train loss: 1.083, Test loss: 3.318, Test accuracy: 29.21
Round  63, Global train loss: 1.083, Global test loss: 2.109, Global test accuracy: 26.23
Round  64, Train loss: 0.927, Test loss: 3.297, Test accuracy: 29.49
Round  64, Global train loss: 0.927, Global test loss: 1.907, Global test accuracy: 31.25
Round  65, Train loss: 0.737, Test loss: 3.331, Test accuracy: 29.74
Round  65, Global train loss: 0.737, Global test loss: 1.843, Global test accuracy: 36.20
Round  66, Train loss: 0.763, Test loss: 3.342, Test accuracy: 29.64
Round  66, Global train loss: 0.763, Global test loss: 1.928, Global test accuracy: 32.69
Round  67, Train loss: 0.982, Test loss: 3.363, Test accuracy: 29.58
Round  67, Global train loss: 0.982, Global test loss: 2.079, Global test accuracy: 30.21
Round  68, Train loss: 0.755, Test loss: 3.430, Test accuracy: 29.35
Round  68, Global train loss: 0.755, Global test loss: 1.943, Global test accuracy: 34.99
Round  69, Train loss: 0.750, Test loss: 3.473, Test accuracy: 29.66
Round  69, Global train loss: 0.750, Global test loss: 1.830, Global test accuracy: 38.92
Round  70, Train loss: 0.945, Test loss: 3.529, Test accuracy: 29.57
Round  70, Global train loss: 0.945, Global test loss: 1.978, Global test accuracy: 31.44
Round  71, Train loss: 0.707, Test loss: 3.551, Test accuracy: 29.63
Round  71, Global train loss: 0.707, Global test loss: 2.038, Global test accuracy: 24.12
Round  72, Train loss: 0.862, Test loss: 3.620, Test accuracy: 29.34
Round  72, Global train loss: 0.862, Global test loss: 1.985, Global test accuracy: 30.26
Round  73, Train loss: 0.636, Test loss: 3.608, Test accuracy: 29.94
Round  73, Global train loss: 0.636, Global test loss: 2.099, Global test accuracy: 21.10
Round  74, Train loss: 0.761, Test loss: 3.613, Test accuracy: 29.91
Round  74, Global train loss: 0.761, Global test loss: 1.969, Global test accuracy: 29.49
Round  75, Train loss: 0.953, Test loss: 3.660, Test accuracy: 29.60
Round  75, Global train loss: 0.953, Global test loss: 2.165, Global test accuracy: 21.11
Round  76, Train loss: 0.544, Test loss: 3.685, Test accuracy: 29.34
Round  76, Global train loss: 0.544, Global test loss: 1.604, Global test accuracy: 46.81
Round  77, Train loss: 0.948, Test loss: 3.711, Test accuracy: 29.19
Round  77, Global train loss: 0.948, Global test loss: 2.103, Global test accuracy: 22.41
Round  78, Train loss: 0.847, Test loss: 3.771, Test accuracy: 29.10
Round  78, Global train loss: 0.847, Global test loss: 2.116, Global test accuracy: 21.86
Round  79, Train loss: 0.767, Test loss: 3.792, Test accuracy: 29.21
Round  79, Global train loss: 0.767, Global test loss: 1.996, Global test accuracy: 28.81
Round  80, Train loss: 0.646, Test loss: 3.835, Test accuracy: 29.26
Round  80, Global train loss: 0.646, Global test loss: 1.704, Global test accuracy: 41.33
Round  81, Train loss: 0.463, Test loss: 3.846, Test accuracy: 29.39
Round  81, Global train loss: 0.463, Global test loss: 1.763, Global test accuracy: 38.02
Round  82, Train loss: 0.623, Test loss: 3.888, Test accuracy: 29.57
Round  82, Global train loss: 0.623, Global test loss: 1.993, Global test accuracy: 28.98
Round  83, Train loss: 0.517, Test loss: 3.896, Test accuracy: 29.48
Round  83, Global train loss: 0.517, Global test loss: 1.825, Global test accuracy: 33.42
Round  84, Train loss: 0.872, Test loss: 3.947, Test accuracy: 29.23
Round  84, Global train loss: 0.872, Global test loss: 2.091, Global test accuracy: 26.83
Round  85, Train loss: 0.763, Test loss: 3.986, Test accuracy: 29.21
Round  85, Global train loss: 0.763, Global test loss: 1.983, Global test accuracy: 32.05
Round  86, Train loss: 0.664, Test loss: 4.020, Test accuracy: 29.18
Round  86, Global train loss: 0.664, Global test loss: 2.003, Global test accuracy: 26.77
Round  87, Train loss: 0.745, Test loss: 4.013, Test accuracy: 29.18
Round  87, Global train loss: 0.745, Global test loss: 2.070, Global test accuracy: 28.32
Round  88, Train loss: 0.441, Test loss: 4.066, Test accuracy: 29.28
Round  88, Global train loss: 0.441, Global test loss: 1.685, Global test accuracy: 40.81
Round  89, Train loss: 0.569, Test loss: 4.117, Test accuracy: 29.06
Round  89, Global train loss: 0.569, Global test loss: 1.932, Global test accuracy: 31.13
Round  90, Train loss: 0.720, Test loss: 4.085, Test accuracy: 29.29
Round  90, Global train loss: 0.720, Global test loss: 2.124, Global test accuracy: 23.55
Round  91, Train loss: 0.687, Test loss: 4.112, Test accuracy: 29.01
Round  91, Global train loss: 0.687, Global test loss: 2.071, Global test accuracy: 27.29
Round  92, Train loss: 0.588, Test loss: 4.180, Test accuracy: 28.97
Round  92, Global train loss: 0.588, Global test loss: 1.866, Global test accuracy: 36.87
Round  93, Train loss: 0.592, Test loss: 4.188, Test accuracy: 29.15
Round  93, Global train loss: 0.592, Global test loss: 1.976, Global test accuracy: 30.09
Round  94, Train loss: 0.697, Test loss: 4.260, Test accuracy: 29.08
Round  94, Global train loss: 0.697, Global test loss: 2.211, Global test accuracy: 14.25
Round  95, Train loss: 0.637, Test loss: 4.280, Test accuracy: 29.02
Round  95, Global train loss: 0.637, Global test loss: 1.883, Global test accuracy: 33.91
Round  96, Train loss: 0.614, Test loss: 4.278, Test accuracy: 29.14
Round  96, Global train loss: 0.614, Global test loss: 2.007, Global test accuracy: 30.43
Round  97, Train loss: 0.759, Test loss: 4.287, Test accuracy: 29.13
Round  97, Global train loss: 0.759, Global test loss: 2.135, Global test accuracy: 23.52
Round  98, Train loss: 0.659, Test loss: 4.305, Test accuracy: 29.43
Round  98, Global train loss: 0.659, Global test loss: 2.136, Global test accuracy: 20.97
Round  99, Train loss: 0.603, Test loss: 4.374, Test accuracy: 29.38
Round  99, Global train loss: 0.603, Global test loss: 2.039, Global test accuracy: 29.20
Final Round, Train loss: 0.389, Test loss: 5.230, Test accuracy: 28.97
Final Round, Global train loss: 0.389, Global test loss: 2.039, Global test accuracy: 29.20
Average accuracy final 10 rounds: 29.158749999999998 

Average global accuracy final 10 rounds: 27.0085 

6376.044991016388
[5.182932376861572, 10.365864753723145, 15.515461444854736, 20.665058135986328, 25.729818105697632, 30.794578075408936, 35.84370040893555, 40.89282274246216, 45.956538677215576, 51.020254611968994, 56.09616184234619, 61.17206907272339, 65.63388991355896, 70.09571075439453, 74.57020497322083, 79.04469919204712, 83.52316522598267, 88.00163125991821, 92.42378735542297, 96.84594345092773, 101.26756119728088, 105.68917894363403, 110.52950668334961, 115.36983442306519, 119.79127359390259, 124.21271276473999, 128.70040559768677, 133.18809843063354, 137.63210916519165, 142.07611989974976, 146.45263934135437, 150.82915878295898, 155.28656458854675, 159.74397039413452, 164.20008516311646, 168.6561999320984, 173.04704451560974, 177.4378890991211, 181.83628845214844, 186.23468780517578, 190.66135239601135, 195.08801698684692, 199.46634030342102, 203.84466361999512, 208.26094388961792, 212.67722415924072, 217.1024489402771, 221.52767372131348, 226.20189261436462, 230.87611150741577, 235.24908328056335, 239.62205505371094, 244.01894855499268, 248.4158420562744, 252.81762266159058, 257.21940326690674, 261.61940693855286, 266.019410610199, 270.42542695999146, 274.83144330978394, 279.26247334480286, 283.6935033798218, 288.0371127128601, 292.38072204589844, 297.3879849910736, 302.3952479362488, 307.3841698169708, 312.37309169769287, 317.3696608543396, 322.3662300109863, 327.3808915615082, 332.39555311203003, 337.38769340515137, 342.3798336982727, 347.3729124069214, 352.36599111557007, 357.37363624572754, 362.381281375885, 367.38899421691895, 372.3967070579529, 377.47366309165955, 382.5506191253662, 387.57974457740784, 392.60887002944946, 397.65431690216064, 402.6997637748718, 407.7273952960968, 412.7550268173218, 417.8151617050171, 422.8752965927124, 427.93610095977783, 432.99690532684326, 437.99172711372375, 442.98654890060425, 448.05932807922363, 453.132107257843, 458.11380553245544, 463.09550380706787, 468.1341083049774, 473.17271280288696, 478.2188603878021, 483.2650079727173, 488.3428854942322, 493.42076301574707, 498.418089389801, 503.415415763855, 508.4548544883728, 513.4942932128906, 518.4967958927155, 523.4992985725403, 528.5006453990936, 533.501992225647, 538.4669184684753, 543.4318447113037, 548.4699079990387, 553.5079712867737, 558.4799721240997, 563.4519729614258, 568.4953260421753, 573.5386791229248, 578.5440075397491, 583.5493359565735, 588.5174038410187, 593.4854717254639, 598.495890378952, 603.5063090324402, 607.8509564399719, 612.1956038475037, 616.5105566978455, 620.8255095481873, 625.1638345718384, 629.5021595954895, 633.7974183559418, 638.092677116394, 642.4965946674347, 646.9005122184753, 651.2320852279663, 655.5636582374573, 659.8979053497314, 664.2321524620056, 668.623984336853, 673.0158162117004, 677.3807787895203, 681.7457413673401, 686.1157946586609, 690.4858479499817, 694.8392565250397, 699.1926651000977, 703.5493626594543, 707.906060218811, 712.3109729290009, 716.7158856391907, 721.0301222801208, 725.344358921051, 729.746958732605, 734.1495585441589, 738.5146276950836, 742.8796968460083, 747.1961832046509, 751.5126695632935, 755.8542976379395, 760.1959257125854, 764.4912586212158, 768.7865915298462, 773.0943944454193, 777.4021973609924, 781.7513012886047, 786.100405216217, 790.4044833183289, 794.7085614204407, 799.6912863254547, 804.6740112304688, 809.6950387954712, 814.7160663604736, 819.7146735191345, 824.7132806777954, 829.6984813213348, 834.6836819648743, 839.6815354824066, 844.679388999939, 849.646443605423, 854.613498210907, 859.6212785243988, 864.6290588378906, 869.5993490219116, 874.5696392059326, 878.9075236320496, 883.2454080581665, 887.6129784584045, 891.9805488586426, 896.3424739837646, 900.7043991088867, 905.0554776191711, 909.4065561294556, 913.8308374881744, 918.2551188468933, 922.6332769393921, 927.0114350318909, 931.4331090450287, 935.8547830581665, 938.0354652404785, 940.2161474227905]
[24.3275, 24.3275, 27.06, 27.06, 31.8375, 31.8375, 33.1525, 33.1525, 31.8225, 31.8225, 31.2, 31.2, 32.4825, 32.4825, 32.8275, 32.8275, 32.7675, 32.7675, 32.985, 32.985, 33.285, 33.285, 33.835, 33.835, 33.6075, 33.6075, 33.925, 33.925, 33.9525, 33.9525, 33.9325, 33.9325, 33.74, 33.74, 33.335, 33.335, 33.075, 33.075, 33.0675, 33.0675, 33.3275, 33.3275, 32.8925, 32.8925, 32.875, 32.875, 32.63, 32.63, 32.61, 32.61, 32.4025, 32.4025, 32.1225, 32.1225, 32.14, 32.14, 32.0875, 32.0875, 32.2675, 32.2675, 32.0625, 32.0625, 31.77, 31.77, 31.73, 31.73, 31.2275, 31.2275, 31.445, 31.445, 31.4125, 31.4125, 31.52, 31.52, 31.19, 31.19, 31.33, 31.33, 31.3075, 31.3075, 30.94, 30.94, 30.355, 30.355, 30.615, 30.615, 30.3475, 30.3475, 30.05, 30.05, 30.4275, 30.4275, 30.555, 30.555, 30.5775, 30.5775, 30.545, 30.545, 30.1925, 30.1925, 30.375, 30.375, 30.3375, 30.3375, 30.0325, 30.0325, 29.97, 29.97, 29.8575, 29.8575, 29.795, 29.795, 29.75, 29.75, 29.81, 29.81, 29.6975, 29.6975, 29.69, 29.69, 29.44, 29.44, 29.44, 29.44, 29.2825, 29.2825, 29.2075, 29.2075, 29.49, 29.49, 29.7425, 29.7425, 29.6375, 29.6375, 29.58, 29.58, 29.3525, 29.3525, 29.66, 29.66, 29.5675, 29.5675, 29.6275, 29.6275, 29.335, 29.335, 29.9375, 29.9375, 29.905, 29.905, 29.6025, 29.6025, 29.3375, 29.3375, 29.19, 29.19, 29.1025, 29.1025, 29.2075, 29.2075, 29.26, 29.26, 29.3875, 29.3875, 29.575, 29.575, 29.485, 29.485, 29.225, 29.225, 29.21, 29.21, 29.175, 29.175, 29.175, 29.175, 29.28, 29.28, 29.0625, 29.0625, 29.285, 29.285, 29.0075, 29.0075, 28.9675, 28.9675, 29.15, 29.15, 29.0825, 29.0825, 29.02, 29.02, 29.1425, 29.1425, 29.1275, 29.1275, 29.43, 29.43, 29.375, 29.375, 28.9725, 28.9725]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9745 (0.8771), real noise ratio: 0.8790
Client 2, noise level: 0.6597 (0.5937), real noise ratio: 0.5810
Client 3, noise level: 0.9589 (0.8630), real noise ratio: 0.8660
Client 4, noise level: 0.5160 (0.4644), real noise ratio: 0.4935
Client 6, noise level: 0.8149 (0.7334), real noise ratio: 0.7420
Client 7, noise level: 0.9369 (0.8432), real noise ratio: 0.8535
Client 8, noise level: 0.5044 (0.4539), real noise ratio: 0.5545
Client 9, noise level: 0.8733 (0.7860), real noise ratio: 0.7660
Client 13, noise level: 0.7546 (0.6792), real noise ratio: 0.7290
Client 15, noise level: 0.9778 (0.8800), real noise ratio: 0.8875
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.598, Test loss: 1.909, Test accuracy: 27.08
Round   0, Global train loss: 1.598, Global test loss: 2.244, Global test accuracy: 14.60
Round   1, Train loss: 1.501, Test loss: 1.486, Test accuracy: 47.19
Round   1, Global train loss: 1.501, Global test loss: 2.084, Global test accuracy: 25.02
Round   2, Train loss: 1.393, Test loss: 1.395, Test accuracy: 53.21
Round   2, Global train loss: 1.393, Global test loss: 2.076, Global test accuracy: 28.88
Round   3, Train loss: 1.463, Test loss: 1.193, Test accuracy: 59.42
Round   3, Global train loss: 1.463, Global test loss: 1.956, Global test accuracy: 33.57
Round   4, Train loss: 1.453, Test loss: 1.146, Test accuracy: 62.35
Round   4, Global train loss: 1.453, Global test loss: 1.921, Global test accuracy: 37.69
Round   5, Train loss: 1.403, Test loss: 1.115, Test accuracy: 64.76
Round   5, Global train loss: 1.403, Global test loss: 1.875, Global test accuracy: 35.40
Round   6, Train loss: 1.583, Test loss: 1.090, Test accuracy: 65.69
Round   6, Global train loss: 1.583, Global test loss: 1.873, Global test accuracy: 40.03
Round   7, Train loss: 1.438, Test loss: 1.068, Test accuracy: 67.68
Round   7, Global train loss: 1.438, Global test loss: 1.842, Global test accuracy: 44.55
Round   8, Train loss: 1.270, Test loss: 1.061, Test accuracy: 67.56
Round   8, Global train loss: 1.270, Global test loss: 1.831, Global test accuracy: 42.22
Round   9, Train loss: 1.208, Test loss: 1.084, Test accuracy: 67.23
Round   9, Global train loss: 1.208, Global test loss: 1.910, Global test accuracy: 34.63
Round  10, Train loss: 1.277, Test loss: 1.053, Test accuracy: 67.58
Round  10, Global train loss: 1.277, Global test loss: 1.852, Global test accuracy: 38.56
Round  11, Train loss: 1.338, Test loss: 1.048, Test accuracy: 68.32
Round  11, Global train loss: 1.338, Global test loss: 1.794, Global test accuracy: 45.99
Round  12, Train loss: 1.417, Test loss: 0.998, Test accuracy: 69.81
Round  12, Global train loss: 1.417, Global test loss: 1.776, Global test accuracy: 42.72
Round  13, Train loss: 1.444, Test loss: 1.010, Test accuracy: 69.65
Round  13, Global train loss: 1.444, Global test loss: 1.771, Global test accuracy: 45.04
Round  14, Train loss: 1.238, Test loss: 1.024, Test accuracy: 69.27
Round  14, Global train loss: 1.238, Global test loss: 1.808, Global test accuracy: 38.51
Round  15, Train loss: 1.253, Test loss: 0.927, Test accuracy: 73.43
Round  15, Global train loss: 1.253, Global test loss: 1.714, Global test accuracy: 42.80
Round  16, Train loss: 1.191, Test loss: 0.938, Test accuracy: 72.97
Round  16, Global train loss: 1.191, Global test loss: 1.790, Global test accuracy: 38.73
Round  17, Train loss: 1.219, Test loss: 0.924, Test accuracy: 73.29
Round  17, Global train loss: 1.219, Global test loss: 1.808, Global test accuracy: 38.61
Round  18, Train loss: 1.227, Test loss: 0.905, Test accuracy: 74.83
Round  18, Global train loss: 1.227, Global test loss: 1.700, Global test accuracy: 46.45
Round  19, Train loss: 1.421, Test loss: 0.899, Test accuracy: 75.16
Round  19, Global train loss: 1.421, Global test loss: 1.723, Global test accuracy: 45.36
Round  20, Train loss: 1.278, Test loss: 0.895, Test accuracy: 74.21
Round  20, Global train loss: 1.278, Global test loss: 1.641, Global test accuracy: 47.86
Round  21, Train loss: 1.471, Test loss: 0.870, Test accuracy: 75.47
Round  21, Global train loss: 1.471, Global test loss: 1.709, Global test accuracy: 49.31
Round  22, Train loss: 1.391, Test loss: 0.863, Test accuracy: 75.19
Round  22, Global train loss: 1.391, Global test loss: 1.752, Global test accuracy: 43.38
Round  23, Train loss: 1.302, Test loss: 0.864, Test accuracy: 75.28
Round  23, Global train loss: 1.302, Global test loss: 1.692, Global test accuracy: 43.06
Round  24, Train loss: 1.132, Test loss: 0.854, Test accuracy: 75.33
Round  24, Global train loss: 1.132, Global test loss: 1.664, Global test accuracy: 45.64
Round  25, Train loss: 1.196, Test loss: 0.870, Test accuracy: 75.30
Round  25, Global train loss: 1.196, Global test loss: 1.690, Global test accuracy: 44.68
Round  26, Train loss: 1.287, Test loss: 0.864, Test accuracy: 75.36
Round  26, Global train loss: 1.287, Global test loss: 1.637, Global test accuracy: 47.93
Round  27, Train loss: 1.336, Test loss: 0.854, Test accuracy: 75.56
Round  27, Global train loss: 1.336, Global test loss: 1.687, Global test accuracy: 45.46
Round  28, Train loss: 1.057, Test loss: 0.862, Test accuracy: 75.24
Round  28, Global train loss: 1.057, Global test loss: 1.623, Global test accuracy: 47.33
Round  29, Train loss: 1.347, Test loss: 0.880, Test accuracy: 74.56
Round  29, Global train loss: 1.347, Global test loss: 1.672, Global test accuracy: 46.56
Round  30, Train loss: 1.161, Test loss: 0.878, Test accuracy: 74.87
Round  30, Global train loss: 1.161, Global test loss: 1.575, Global test accuracy: 50.43
Round  31, Train loss: 1.270, Test loss: 0.863, Test accuracy: 75.16
Round  31, Global train loss: 1.270, Global test loss: 1.604, Global test accuracy: 51.09
Round  32, Train loss: 1.113, Test loss: 0.880, Test accuracy: 74.84
Round  32, Global train loss: 1.113, Global test loss: 1.561, Global test accuracy: 49.66
Round  33, Train loss: 1.101, Test loss: 0.879, Test accuracy: 74.87
Round  33, Global train loss: 1.101, Global test loss: 1.598, Global test accuracy: 49.76
Round  34, Train loss: 1.097, Test loss: 0.886, Test accuracy: 74.26
Round  34, Global train loss: 1.097, Global test loss: 1.629, Global test accuracy: 49.54
Round  35, Train loss: 1.146, Test loss: 0.883, Test accuracy: 74.27
Round  35, Global train loss: 1.146, Global test loss: 1.751, Global test accuracy: 44.27
Round  36, Train loss: 0.993, Test loss: 0.866, Test accuracy: 75.07
Round  36, Global train loss: 0.993, Global test loss: 1.652, Global test accuracy: 42.91
Round  37, Train loss: 0.978, Test loss: 0.868, Test accuracy: 74.82
Round  37, Global train loss: 0.978, Global test loss: 1.522, Global test accuracy: 52.33
Round  38, Train loss: 1.265, Test loss: 0.878, Test accuracy: 74.61
Round  38, Global train loss: 1.265, Global test loss: 1.618, Global test accuracy: 49.11
Round  39, Train loss: 1.210, Test loss: 0.899, Test accuracy: 73.57
Round  39, Global train loss: 1.210, Global test loss: 1.680, Global test accuracy: 45.70
Round  40, Train loss: 1.292, Test loss: 0.903, Test accuracy: 73.47
Round  40, Global train loss: 1.292, Global test loss: 1.701, Global test accuracy: 44.48
Round  41, Train loss: 1.155, Test loss: 0.896, Test accuracy: 73.65
Round  41, Global train loss: 1.155, Global test loss: 1.659, Global test accuracy: 48.22
Round  42, Train loss: 1.040, Test loss: 0.912, Test accuracy: 73.42
Round  42, Global train loss: 1.040, Global test loss: 1.751, Global test accuracy: 43.38
Round  43, Train loss: 1.062, Test loss: 0.915, Test accuracy: 73.20
Round  43, Global train loss: 1.062, Global test loss: 1.582, Global test accuracy: 48.54
Round  44, Train loss: 1.106, Test loss: 0.903, Test accuracy: 73.68
Round  44, Global train loss: 1.106, Global test loss: 1.728, Global test accuracy: 43.45
Round  45, Train loss: 1.148, Test loss: 0.883, Test accuracy: 74.10
Round  45, Global train loss: 1.148, Global test loss: 1.616, Global test accuracy: 49.38
Round  46, Train loss: 1.061, Test loss: 0.882, Test accuracy: 73.73
Round  46, Global train loss: 1.061, Global test loss: 1.586, Global test accuracy: 49.57
Round  47, Train loss: 0.887, Test loss: 0.874, Test accuracy: 74.13
Round  47, Global train loss: 0.887, Global test loss: 1.775, Global test accuracy: 42.21
Round  48, Train loss: 1.092, Test loss: 0.891, Test accuracy: 73.76
Round  48, Global train loss: 1.092, Global test loss: 1.740, Global test accuracy: 43.02
Round  49, Train loss: 0.911, Test loss: 0.904, Test accuracy: 73.41
Round  49, Global train loss: 0.911, Global test loss: 1.671, Global test accuracy: 46.76
Round  50, Train loss: 0.863, Test loss: 0.910, Test accuracy: 73.17
Round  50, Global train loss: 0.863, Global test loss: 1.879, Global test accuracy: 40.78
Round  51, Train loss: 0.980, Test loss: 0.906, Test accuracy: 73.03
Round  51, Global train loss: 0.980, Global test loss: 1.911, Global test accuracy: 38.72
Round  52, Train loss: 1.059, Test loss: 0.924, Test accuracy: 72.37
Round  52, Global train loss: 1.059, Global test loss: 1.826, Global test accuracy: 39.77
Round  53, Train loss: 1.110, Test loss: 0.939, Test accuracy: 71.56
Round  53, Global train loss: 1.110, Global test loss: 1.707, Global test accuracy: 42.54
Round  54, Train loss: 0.819, Test loss: 0.931, Test accuracy: 72.01
Round  54, Global train loss: 0.819, Global test loss: 1.913, Global test accuracy: 42.48
Round  55, Train loss: 1.050, Test loss: 0.944, Test accuracy: 71.63
Round  55, Global train loss: 1.050, Global test loss: 1.839, Global test accuracy: 40.47
Round  56, Train loss: 1.085, Test loss: 0.954, Test accuracy: 71.22
Round  56, Global train loss: 1.085, Global test loss: 1.744, Global test accuracy: 43.36
Round  57, Train loss: 0.857, Test loss: 0.958, Test accuracy: 70.86
Round  57, Global train loss: 0.857, Global test loss: 1.830, Global test accuracy: 41.64
Round  58, Train loss: 0.906, Test loss: 0.955, Test accuracy: 71.05
Round  58, Global train loss: 0.906, Global test loss: 1.789, Global test accuracy: 44.46
Round  59, Train loss: 0.909, Test loss: 0.968, Test accuracy: 71.01
Round  59, Global train loss: 0.909, Global test loss: 1.799, Global test accuracy: 41.99
Round  60, Train loss: 0.809, Test loss: 0.963, Test accuracy: 70.80
Round  60, Global train loss: 0.809, Global test loss: 1.725, Global test accuracy: 44.61
Round  61, Train loss: 0.846, Test loss: 0.955, Test accuracy: 71.31
Round  61, Global train loss: 0.846, Global test loss: 1.687, Global test accuracy: 44.41
Round  62, Train loss: 0.890, Test loss: 0.964, Test accuracy: 71.28
Round  62, Global train loss: 0.890, Global test loss: 1.752, Global test accuracy: 43.50
Round  63, Train loss: 1.112, Test loss: 0.953, Test accuracy: 71.52
Round  63, Global train loss: 1.112, Global test loss: 1.682, Global test accuracy: 46.91
Round  64, Train loss: 1.010, Test loss: 0.958, Test accuracy: 70.94
Round  64, Global train loss: 1.010, Global test loss: 1.711, Global test accuracy: 44.95
Round  65, Train loss: 0.981, Test loss: 0.966, Test accuracy: 70.50
Round  65, Global train loss: 0.981, Global test loss: 1.719, Global test accuracy: 45.50
Round  66, Train loss: 0.982, Test loss: 1.011, Test accuracy: 69.85
Round  66, Global train loss: 0.982, Global test loss: 1.851, Global test accuracy: 38.71
Round  67, Train loss: 0.784, Test loss: 0.991, Test accuracy: 70.14
Round  67, Global train loss: 0.784, Global test loss: 1.733, Global test accuracy: 46.04
Round  68, Train loss: 0.969, Test loss: 0.973, Test accuracy: 70.69
Round  68, Global train loss: 0.969, Global test loss: 1.883, Global test accuracy: 39.94
Round  69, Train loss: 0.973, Test loss: 0.959, Test accuracy: 70.77
Round  69, Global train loss: 0.973, Global test loss: 1.786, Global test accuracy: 41.07
Round  70, Train loss: 0.880, Test loss: 0.981, Test accuracy: 70.41
Round  70, Global train loss: 0.880, Global test loss: 1.782, Global test accuracy: 41.76
Round  71, Train loss: 0.946, Test loss: 0.994, Test accuracy: 69.65
Round  71, Global train loss: 0.946, Global test loss: 1.868, Global test accuracy: 39.18
Round  72, Train loss: 1.032, Test loss: 0.998, Test accuracy: 69.49
Round  72, Global train loss: 1.032, Global test loss: 1.754, Global test accuracy: 41.82
Round  73, Train loss: 0.856, Test loss: 0.997, Test accuracy: 69.89
Round  73, Global train loss: 0.856, Global test loss: 1.755, Global test accuracy: 42.34
Round  74, Train loss: 0.949, Test loss: 0.996, Test accuracy: 69.65
Round  74, Global train loss: 0.949, Global test loss: 1.880, Global test accuracy: 41.07
Round  75, Train loss: 0.907, Test loss: 0.997, Test accuracy: 69.68
Round  75, Global train loss: 0.907, Global test loss: 1.744, Global test accuracy: 44.72
Round  76, Train loss: 0.929, Test loss: 1.014, Test accuracy: 69.33
Round  76, Global train loss: 0.929, Global test loss: 1.722, Global test accuracy: 46.18
Round  77, Train loss: 0.997, Test loss: 1.034, Test accuracy: 68.98
Round  77, Global train loss: 0.997, Global test loss: 1.743, Global test accuracy: 44.99
Round  78, Train loss: 0.884, Test loss: 1.024, Test accuracy: 69.16
Round  78, Global train loss: 0.884, Global test loss: 1.761, Global test accuracy: 44.67
Round  79, Train loss: 0.763, Test loss: 1.015, Test accuracy: 69.35
Round  79, Global train loss: 0.763, Global test loss: 1.763, Global test accuracy: 44.13
Round  80, Train loss: 0.788, Test loss: 1.023, Test accuracy: 69.68
Round  80, Global train loss: 0.788, Global test loss: 1.719, Global test accuracy: 45.94
Round  81, Train loss: 0.833, Test loss: 1.046, Test accuracy: 68.98
Round  81, Global train loss: 0.833, Global test loss: 1.867, Global test accuracy: 41.76
Round  82, Train loss: 0.968, Test loss: 1.049, Test accuracy: 68.78
Round  82, Global train loss: 0.968, Global test loss: 1.801, Global test accuracy: 41.80
Round  83, Train loss: 0.953, Test loss: 1.036, Test accuracy: 69.02
Round  83, Global train loss: 0.953, Global test loss: 1.817, Global test accuracy: 42.53
Round  84, Train loss: 0.954, Test loss: 1.041, Test accuracy: 68.88
Round  84, Global train loss: 0.954, Global test loss: 1.687, Global test accuracy: 46.27
Round  85, Train loss: 0.898, Test loss: 1.023, Test accuracy: 69.73
Round  85, Global train loss: 0.898, Global test loss: 1.777, Global test accuracy: 42.98
Round  86, Train loss: 0.711, Test loss: 1.030, Test accuracy: 69.47
Round  86, Global train loss: 0.711, Global test loss: 1.708, Global test accuracy: 47.07
Round  87, Train loss: 0.600, Test loss: 1.060, Test accuracy: 68.83
Round  87, Global train loss: 0.600, Global test loss: 1.984, Global test accuracy: 41.94
Round  88, Train loss: 0.811, Test loss: 1.062, Test accuracy: 68.59
Round  88, Global train loss: 0.811, Global test loss: 1.969, Global test accuracy: 39.54
Round  89, Train loss: 0.759, Test loss: 1.077, Test accuracy: 67.93
Round  89, Global train loss: 0.759, Global test loss: 1.936, Global test accuracy: 41.71
Round  90, Train loss: 0.935, Test loss: 1.078, Test accuracy: 67.67
Round  90, Global train loss: 0.935, Global test loss: 1.893, Global test accuracy: 40.49
Round  91, Train loss: 0.742, Test loss: 1.077, Test accuracy: 67.63
Round  91, Global train loss: 0.742, Global test loss: 1.861, Global test accuracy: 42.35
Round  92, Train loss: 0.746, Test loss: 1.081, Test accuracy: 67.89
Round  92, Global train loss: 0.746, Global test loss: 1.836, Global test accuracy: 44.56
Round  93, Train loss: 0.766, Test loss: 1.113, Test accuracy: 67.56
Round  93, Global train loss: 0.766, Global test loss: 1.870, Global test accuracy: 41.19
Round  94, Train loss: 0.779, Test loss: 1.098, Test accuracy: 68.08
Round  94, Global train loss: 0.779, Global test loss: 1.895, Global test accuracy: 41.18
Round  95, Train loss: 0.714, Test loss: 1.089, Test accuracy: 68.07
Round  95, Global train loss: 0.714, Global test loss: 2.158, Global test accuracy: 38.61
Round  96, Train loss: 0.724, Test loss: 1.095, Test accuracy: 67.78
Round  96, Global train loss: 0.724, Global test loss: 1.866, Global test accuracy: 42.58
Round  97, Train loss: 0.731, Test loss: 1.138, Test accuracy: 66.96
Round  97, Global train loss: 0.731, Global test loss: 1.951, Global test accuracy: 41.84
Round  98, Train loss: 0.711, Test loss: 1.124, Test accuracy: 67.28
Round  98, Global train loss: 0.711, Global test loss: 1.996, Global test accuracy: 40.52
Round  99, Train loss: 0.950, Test loss: 1.130, Test accuracy: 67.49
Round  99, Global train loss: 0.950, Global test loss: 1.855, Global test accuracy: 41.55
Final Round, Train loss: 0.569, Test loss: 1.276, Test accuracy: 66.14
Final Round, Global train loss: 0.569, Global test loss: 1.855, Global test accuracy: 41.55
Average accuracy final 10 rounds: 67.64166666666667 

Average global accuracy final 10 rounds: 41.486666666666665 

2878.283522129059
[2.3911385536193848, 4.7822771072387695, 6.903767347335815, 9.025257587432861, 11.212472677230835, 13.399687767028809, 15.617990970611572, 17.836294174194336, 20.02791976928711, 22.219545364379883, 24.43138599395752, 26.643226623535156, 28.831820964813232, 31.02041530609131, 33.238718032836914, 35.45702075958252, 37.65252685546875, 39.84803295135498, 42.06497859954834, 44.2819242477417, 46.4762544631958, 48.6705846786499, 50.889201402664185, 53.10781812667847, 55.3186309337616, 57.52944374084473, 59.73675775527954, 61.944071769714355, 64.13550806045532, 66.32694435119629, 68.5387876033783, 70.7506308555603, 72.94474363327026, 75.13885641098022, 77.32498860359192, 79.51112079620361, 81.69421076774597, 83.87730073928833, 86.07415390014648, 88.27100706100464, 90.45404386520386, 92.63708066940308, 94.82888126373291, 97.02068185806274, 99.18052053451538, 101.34035921096802, 103.42641139030457, 105.51246356964111, 107.59984397888184, 109.68722438812256, 111.86954736709595, 114.05187034606934, 116.2200095653534, 118.38814878463745, 120.60010480880737, 122.8120608329773, 124.97589159011841, 127.13972234725952, 129.26580667495728, 131.39189100265503, 133.5460889339447, 135.70028686523438, 137.8320655822754, 139.9638442993164, 142.18552899360657, 144.40721368789673, 146.602135181427, 148.79705667495728, 151.01656770706177, 153.23607873916626, 155.43513584136963, 157.634192943573, 159.85429978370667, 162.07440662384033, 164.284574508667, 166.49474239349365, 168.70617485046387, 170.91760730743408, 173.12681531906128, 175.33602333068848, 177.5632300376892, 179.79043674468994, 182.02251291275024, 184.25458908081055, 186.46625113487244, 188.67791318893433, 190.903911113739, 193.1299090385437, 195.35673332214355, 197.5835576057434, 199.81151700019836, 202.03947639465332, 204.2417562007904, 206.4440360069275, 208.65616059303284, 210.86828517913818, 213.1126434803009, 215.35700178146362, 217.58081674575806, 219.8046317100525, 222.04637050628662, 224.28810930252075, 226.5074107646942, 228.72671222686768, 230.9344289302826, 233.1421456336975, 235.3437283039093, 237.5453109741211, 239.75341796875, 241.9615249633789, 244.1905288696289, 246.4195327758789, 248.62540817260742, 250.83128356933594, 252.9352090358734, 255.0391345024109, 257.15254402160645, 259.265953540802, 261.3704192638397, 263.47488498687744, 265.5967319011688, 267.7185788154602, 269.85493421554565, 271.9912896156311, 274.11426424980164, 276.23723888397217, 278.3741731643677, 280.5111074447632, 282.70372343063354, 284.8963394165039, 287.0821182727814, 289.26789712905884, 291.45285177230835, 293.63780641555786, 295.81021308898926, 297.98261976242065, 300.19888639450073, 302.4151530265808, 304.62467527389526, 306.8341975212097, 309.0408592224121, 311.2475209236145, 313.45982813835144, 315.6721353530884, 317.8849461078644, 320.0977568626404, 322.3103702068329, 324.5229835510254, 326.63174986839294, 328.7405161857605, 330.869304895401, 332.9980936050415, 335.10405111312866, 337.2100086212158, 339.393105506897, 341.5762023925781, 343.76729583740234, 345.95838928222656, 348.1734426021576, 350.3884959220886, 352.57254123687744, 354.75658655166626, 356.93313097953796, 359.10967540740967, 361.3159055709839, 363.5221357345581, 365.73259711265564, 367.9430584907532, 370.1636538505554, 372.38424921035767, 374.60979890823364, 376.8353486061096, 378.75625562667847, 380.6771626472473, 382.5761959552765, 384.47522926330566, 386.3807945251465, 388.2863597869873, 390.1936619281769, 392.10096406936646, 394.00798296928406, 395.91500186920166, 397.8684170246124, 399.8218321800232, 401.7561604976654, 403.6904888153076, 405.6339781284332, 407.57746744155884, 409.50632309913635, 411.43517875671387, 413.3655893802643, 415.2960000038147, 417.2381319999695, 419.18026399612427, 421.2087926864624, 423.23732137680054, 425.15590620040894, 427.07449102401733, 428.9755811691284, 430.8766713142395, 433.1431381702423, 435.4096050262451]
[27.083333333333332, 27.083333333333332, 47.18888888888889, 47.18888888888889, 53.205555555555556, 53.205555555555556, 59.416666666666664, 59.416666666666664, 62.35, 62.35, 64.7611111111111, 64.7611111111111, 65.69444444444444, 65.69444444444444, 67.67777777777778, 67.67777777777778, 67.55555555555556, 67.55555555555556, 67.23333333333333, 67.23333333333333, 67.58333333333333, 67.58333333333333, 68.32222222222222, 68.32222222222222, 69.81111111111112, 69.81111111111112, 69.65, 69.65, 69.27222222222223, 69.27222222222223, 73.42777777777778, 73.42777777777778, 72.97222222222223, 72.97222222222223, 73.29444444444445, 73.29444444444445, 74.83333333333333, 74.83333333333333, 75.16111111111111, 75.16111111111111, 74.20555555555555, 74.20555555555555, 75.46666666666667, 75.46666666666667, 75.18888888888888, 75.18888888888888, 75.27777777777777, 75.27777777777777, 75.33333333333333, 75.33333333333333, 75.3, 75.3, 75.36111111111111, 75.36111111111111, 75.55555555555556, 75.55555555555556, 75.2388888888889, 75.2388888888889, 74.56111111111112, 74.56111111111112, 74.86666666666666, 74.86666666666666, 75.15555555555555, 75.15555555555555, 74.83888888888889, 74.83888888888889, 74.87222222222222, 74.87222222222222, 74.2611111111111, 74.2611111111111, 74.27222222222223, 74.27222222222223, 75.07222222222222, 75.07222222222222, 74.82222222222222, 74.82222222222222, 74.61111111111111, 74.61111111111111, 73.56666666666666, 73.56666666666666, 73.47222222222223, 73.47222222222223, 73.65, 73.65, 73.41666666666667, 73.41666666666667, 73.2, 73.2, 73.68333333333334, 73.68333333333334, 74.1, 74.1, 73.73333333333333, 73.73333333333333, 74.13333333333334, 74.13333333333334, 73.7611111111111, 73.7611111111111, 73.40555555555555, 73.40555555555555, 73.16666666666667, 73.16666666666667, 73.03333333333333, 73.03333333333333, 72.37222222222222, 72.37222222222222, 71.55555555555556, 71.55555555555556, 72.0111111111111, 72.0111111111111, 71.62777777777778, 71.62777777777778, 71.22222222222223, 71.22222222222223, 70.86111111111111, 70.86111111111111, 71.05, 71.05, 71.0111111111111, 71.0111111111111, 70.8, 70.8, 71.30555555555556, 71.30555555555556, 71.27777777777777, 71.27777777777777, 71.51666666666667, 71.51666666666667, 70.94444444444444, 70.94444444444444, 70.5, 70.5, 69.85, 69.85, 70.14444444444445, 70.14444444444445, 70.68888888888888, 70.68888888888888, 70.77222222222223, 70.77222222222223, 70.41111111111111, 70.41111111111111, 69.65, 69.65, 69.49444444444444, 69.49444444444444, 69.89444444444445, 69.89444444444445, 69.65, 69.65, 69.68333333333334, 69.68333333333334, 69.32777777777778, 69.32777777777778, 68.98333333333333, 68.98333333333333, 69.15555555555555, 69.15555555555555, 69.35, 69.35, 69.68333333333334, 69.68333333333334, 68.97777777777777, 68.97777777777777, 68.78333333333333, 68.78333333333333, 69.02222222222223, 69.02222222222223, 68.88333333333334, 68.88333333333334, 69.72777777777777, 69.72777777777777, 69.47222222222223, 69.47222222222223, 68.82777777777778, 68.82777777777778, 68.59444444444445, 68.59444444444445, 67.92777777777778, 67.92777777777778, 67.67222222222222, 67.67222222222222, 67.62777777777778, 67.62777777777778, 67.89444444444445, 67.89444444444445, 67.56111111111112, 67.56111111111112, 68.07777777777778, 68.07777777777778, 68.06666666666666, 68.06666666666666, 67.78333333333333, 67.78333333333333, 66.96111111111111, 66.96111111111111, 67.28333333333333, 67.28333333333333, 67.4888888888889, 67.4888888888889, 66.14444444444445, 66.14444444444445]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9745 (0.8771), real noise ratio: 0.8720
Client 2, noise level: 0.6597 (0.5937), real noise ratio: 0.5840
Client 3, noise level: 0.9589 (0.8630), real noise ratio: 0.8605
Client 4, noise level: 0.5160 (0.4644), real noise ratio: 0.5520
Client 6, noise level: 0.8149 (0.7334), real noise ratio: 0.7570
Client 7, noise level: 0.9369 (0.8432), real noise ratio: 0.8530
Client 8, noise level: 0.5044 (0.4539), real noise ratio: 0.5900
Client 9, noise level: 0.8733 (0.7860), real noise ratio: 0.8070
Client 13, noise level: 0.7546 (0.6792), real noise ratio: 0.7075
Client 15, noise level: 0.9778 (0.8800), real noise ratio: 0.8870
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.418, Test loss: 1.949, Test accuracy: 27.96
Round   0, Global train loss: 1.418, Global test loss: 2.222, Global test accuracy: 22.37
Round   1, Train loss: 1.212, Test loss: 1.702, Test accuracy: 41.67
Round   1, Global train loss: 1.212, Global test loss: 2.180, Global test accuracy: 32.29
Round   2, Train loss: 1.252, Test loss: 1.405, Test accuracy: 49.59
Round   2, Global train loss: 1.252, Global test loss: 2.020, Global test accuracy: 33.08
Round   3, Train loss: 1.165, Test loss: 1.225, Test accuracy: 54.34
Round   3, Global train loss: 1.165, Global test loss: 1.919, Global test accuracy: 33.63
Round   4, Train loss: 1.192, Test loss: 1.205, Test accuracy: 56.98
Round   4, Global train loss: 1.192, Global test loss: 1.874, Global test accuracy: 38.52
Round   5, Train loss: 0.891, Test loss: 1.227, Test accuracy: 56.63
Round   5, Global train loss: 0.891, Global test loss: 2.006, Global test accuracy: 32.39
Round   6, Train loss: 0.901, Test loss: 1.174, Test accuracy: 59.02
Round   6, Global train loss: 0.901, Global test loss: 1.954, Global test accuracy: 36.98
Round   7, Train loss: 1.005, Test loss: 1.139, Test accuracy: 58.97
Round   7, Global train loss: 1.005, Global test loss: 1.745, Global test accuracy: 39.79
Round   8, Train loss: 1.158, Test loss: 1.044, Test accuracy: 63.05
Round   8, Global train loss: 1.158, Global test loss: 1.774, Global test accuracy: 39.16
Round   9, Train loss: 1.304, Test loss: 1.022, Test accuracy: 63.49
Round   9, Global train loss: 1.304, Global test loss: 1.736, Global test accuracy: 40.57
Round  10, Train loss: 1.044, Test loss: 1.040, Test accuracy: 62.61
Round  10, Global train loss: 1.044, Global test loss: 1.752, Global test accuracy: 40.52
Round  11, Train loss: 1.083, Test loss: 0.947, Test accuracy: 66.07
Round  11, Global train loss: 1.083, Global test loss: 1.673, Global test accuracy: 44.20
Round  12, Train loss: 0.962, Test loss: 0.941, Test accuracy: 66.80
Round  12, Global train loss: 0.962, Global test loss: 1.781, Global test accuracy: 34.21
Round  13, Train loss: 1.142, Test loss: 0.919, Test accuracy: 67.74
Round  13, Global train loss: 1.142, Global test loss: 1.717, Global test accuracy: 45.54
Round  14, Train loss: 1.178, Test loss: 0.920, Test accuracy: 68.32
Round  14, Global train loss: 1.178, Global test loss: 1.794, Global test accuracy: 38.09
Round  15, Train loss: 1.235, Test loss: 0.913, Test accuracy: 68.44
Round  15, Global train loss: 1.235, Global test loss: 1.866, Global test accuracy: 35.07
Round  16, Train loss: 0.948, Test loss: 0.920, Test accuracy: 67.81
Round  16, Global train loss: 0.948, Global test loss: 1.669, Global test accuracy: 45.68
Round  17, Train loss: 0.981, Test loss: 0.910, Test accuracy: 68.44
Round  17, Global train loss: 0.981, Global test loss: 1.591, Global test accuracy: 47.51
Round  18, Train loss: 1.270, Test loss: 0.899, Test accuracy: 70.01
Round  18, Global train loss: 1.270, Global test loss: 1.657, Global test accuracy: 45.82
Round  19, Train loss: 1.047, Test loss: 0.890, Test accuracy: 69.92
Round  19, Global train loss: 1.047, Global test loss: 1.649, Global test accuracy: 42.39
Round  20, Train loss: 0.842, Test loss: 0.890, Test accuracy: 69.99
Round  20, Global train loss: 0.842, Global test loss: 1.833, Global test accuracy: 37.72
Round  21, Train loss: 0.802, Test loss: 0.885, Test accuracy: 70.20
Round  21, Global train loss: 0.802, Global test loss: 1.838, Global test accuracy: 36.77
Round  22, Train loss: 0.883, Test loss: 0.874, Test accuracy: 70.89
Round  22, Global train loss: 0.883, Global test loss: 1.659, Global test accuracy: 44.11
Round  23, Train loss: 0.849, Test loss: 0.869, Test accuracy: 71.00
Round  23, Global train loss: 0.849, Global test loss: 1.500, Global test accuracy: 48.77
Round  24, Train loss: 0.990, Test loss: 0.877, Test accuracy: 70.74
Round  24, Global train loss: 0.990, Global test loss: 1.629, Global test accuracy: 46.35
Round  25, Train loss: 0.871, Test loss: 0.882, Test accuracy: 70.43
Round  25, Global train loss: 0.871, Global test loss: 1.523, Global test accuracy: 47.98
Round  26, Train loss: 0.895, Test loss: 0.879, Test accuracy: 70.73
Round  26, Global train loss: 0.895, Global test loss: 1.552, Global test accuracy: 48.00
Round  27, Train loss: 1.008, Test loss: 0.859, Test accuracy: 71.02
Round  27, Global train loss: 1.008, Global test loss: 1.518, Global test accuracy: 50.23
Round  28, Train loss: 0.655, Test loss: 0.871, Test accuracy: 70.92
Round  28, Global train loss: 0.655, Global test loss: 1.571, Global test accuracy: 47.35
Round  29, Train loss: 0.908, Test loss: 0.878, Test accuracy: 70.88
Round  29, Global train loss: 0.908, Global test loss: 1.817, Global test accuracy: 43.37
Round  30, Train loss: 0.864, Test loss: 0.880, Test accuracy: 70.92
Round  30, Global train loss: 0.864, Global test loss: 1.554, Global test accuracy: 50.37
Round  31, Train loss: 0.931, Test loss: 0.853, Test accuracy: 71.88
Round  31, Global train loss: 0.931, Global test loss: 1.435, Global test accuracy: 55.13
Round  32, Train loss: 0.859, Test loss: 0.850, Test accuracy: 72.14
Round  32, Global train loss: 0.859, Global test loss: 1.469, Global test accuracy: 50.96
Round  33, Train loss: 0.692, Test loss: 0.839, Test accuracy: 72.14
Round  33, Global train loss: 0.692, Global test loss: 1.537, Global test accuracy: 51.14
Round  34, Train loss: 0.746, Test loss: 0.872, Test accuracy: 70.72
Round  34, Global train loss: 0.746, Global test loss: 1.456, Global test accuracy: 52.55
Round  35, Train loss: 0.807, Test loss: 0.848, Test accuracy: 72.10
Round  35, Global train loss: 0.807, Global test loss: 1.432, Global test accuracy: 53.48
Round  36, Train loss: 0.826, Test loss: 0.833, Test accuracy: 72.86
Round  36, Global train loss: 0.826, Global test loss: 1.455, Global test accuracy: 51.43
Round  37, Train loss: 1.205, Test loss: 0.838, Test accuracy: 72.48
Round  37, Global train loss: 1.205, Global test loss: 1.576, Global test accuracy: 49.88
Round  38, Train loss: 0.793, Test loss: 0.847, Test accuracy: 72.43
Round  38, Global train loss: 0.793, Global test loss: 1.396, Global test accuracy: 55.87
Round  39, Train loss: 0.735, Test loss: 0.832, Test accuracy: 73.06
Round  39, Global train loss: 0.735, Global test loss: 1.472, Global test accuracy: 49.68
Round  40, Train loss: 0.875, Test loss: 0.839, Test accuracy: 72.24
Round  40, Global train loss: 0.875, Global test loss: 1.409, Global test accuracy: 55.02
Round  41, Train loss: 0.656, Test loss: 0.824, Test accuracy: 72.69
Round  41, Global train loss: 0.656, Global test loss: 1.504, Global test accuracy: 50.51
Round  42, Train loss: 0.834, Test loss: 0.835, Test accuracy: 72.72
Round  42, Global train loss: 0.834, Global test loss: 1.411, Global test accuracy: 55.09
Round  43, Train loss: 0.801, Test loss: 0.844, Test accuracy: 71.92
Round  43, Global train loss: 0.801, Global test loss: 1.524, Global test accuracy: 51.66
Round  44, Train loss: 0.703, Test loss: 0.853, Test accuracy: 71.88
Round  44, Global train loss: 0.703, Global test loss: 1.354, Global test accuracy: 56.16
Round  45, Train loss: 0.862, Test loss: 0.873, Test accuracy: 71.01
Round  45, Global train loss: 0.862, Global test loss: 1.378, Global test accuracy: 56.35
Round  46, Train loss: 0.862, Test loss: 0.872, Test accuracy: 71.25
Round  46, Global train loss: 0.862, Global test loss: 1.441, Global test accuracy: 51.79
Round  47, Train loss: 0.699, Test loss: 0.875, Test accuracy: 71.41
Round  47, Global train loss: 0.699, Global test loss: 1.523, Global test accuracy: 48.88
Round  48, Train loss: 0.824, Test loss: 0.865, Test accuracy: 71.88
Round  48, Global train loss: 0.824, Global test loss: 1.462, Global test accuracy: 52.08
Round  49, Train loss: 0.836, Test loss: 0.851, Test accuracy: 72.23
Round  49, Global train loss: 0.836, Global test loss: 1.498, Global test accuracy: 50.98
Round  50, Train loss: 0.834, Test loss: 0.856, Test accuracy: 71.74
Round  50, Global train loss: 0.834, Global test loss: 1.506, Global test accuracy: 50.77
Round  51, Train loss: 0.776, Test loss: 0.855, Test accuracy: 71.97
Round  51, Global train loss: 0.776, Global test loss: 1.472, Global test accuracy: 49.36
Round  52, Train loss: 0.754, Test loss: 0.836, Test accuracy: 72.62
Round  52, Global train loss: 0.754, Global test loss: 1.427, Global test accuracy: 53.02
Round  53, Train loss: 0.657, Test loss: 0.875, Test accuracy: 70.92
Round  53, Global train loss: 0.657, Global test loss: 1.477, Global test accuracy: 52.08
Round  54, Train loss: 0.893, Test loss: 0.854, Test accuracy: 71.78
Round  54, Global train loss: 0.893, Global test loss: 1.495, Global test accuracy: 50.12
Round  55, Train loss: 0.777, Test loss: 0.852, Test accuracy: 71.64
Round  55, Global train loss: 0.777, Global test loss: 1.398, Global test accuracy: 53.54
Round  56, Train loss: 0.809, Test loss: 0.854, Test accuracy: 71.75
Round  56, Global train loss: 0.809, Global test loss: 1.366, Global test accuracy: 53.58
Round  57, Train loss: 0.733, Test loss: 0.854, Test accuracy: 72.05
Round  57, Global train loss: 0.733, Global test loss: 1.474, Global test accuracy: 50.71
Round  58, Train loss: 0.674, Test loss: 0.849, Test accuracy: 72.57
Round  58, Global train loss: 0.674, Global test loss: 1.437, Global test accuracy: 53.04
Round  59, Train loss: 0.715, Test loss: 0.840, Test accuracy: 72.67
Round  59, Global train loss: 0.715, Global test loss: 1.586, Global test accuracy: 48.84
Round  60, Train loss: 0.699, Test loss: 0.845, Test accuracy: 72.86
Round  60, Global train loss: 0.699, Global test loss: 1.461, Global test accuracy: 52.08
Round  61, Train loss: 0.760, Test loss: 0.830, Test accuracy: 73.25
Round  61, Global train loss: 0.760, Global test loss: 1.470, Global test accuracy: 52.79
Round  62, Train loss: 0.678, Test loss: 0.826, Test accuracy: 73.68
Round  62, Global train loss: 0.678, Global test loss: 1.613, Global test accuracy: 46.67
Round  63, Train loss: 0.808, Test loss: 0.864, Test accuracy: 72.29
Round  63, Global train loss: 0.808, Global test loss: 1.504, Global test accuracy: 49.89
Round  64, Train loss: 0.599, Test loss: 0.889, Test accuracy: 71.66
Round  64, Global train loss: 0.599, Global test loss: 1.414, Global test accuracy: 56.16
Round  65, Train loss: 0.618, Test loss: 0.893, Test accuracy: 71.53
Round  65, Global train loss: 0.618, Global test loss: 1.465, Global test accuracy: 53.27
Round  66, Train loss: 0.601, Test loss: 0.889, Test accuracy: 71.97
Round  66, Global train loss: 0.601, Global test loss: 1.463, Global test accuracy: 53.65
Round  67, Train loss: 0.575, Test loss: 0.920, Test accuracy: 71.38
Round  67, Global train loss: 0.575, Global test loss: 1.505, Global test accuracy: 52.69
Round  68, Train loss: 0.586, Test loss: 0.921, Test accuracy: 71.14
Round  68, Global train loss: 0.586, Global test loss: 1.402, Global test accuracy: 54.70
Round  69, Train loss: 0.579, Test loss: 0.906, Test accuracy: 71.49
Round  69, Global train loss: 0.579, Global test loss: 1.451, Global test accuracy: 56.23
Round  70, Train loss: 0.748, Test loss: 0.924, Test accuracy: 70.85
Round  70, Global train loss: 0.748, Global test loss: 1.616, Global test accuracy: 49.44
Round  71, Train loss: 0.886, Test loss: 0.918, Test accuracy: 71.29
Round  71, Global train loss: 0.886, Global test loss: 1.543, Global test accuracy: 48.62
Round  72, Train loss: 0.650, Test loss: 0.923, Test accuracy: 71.55
Round  72, Global train loss: 0.650, Global test loss: 1.385, Global test accuracy: 55.07
Round  73, Train loss: 0.650, Test loss: 0.919, Test accuracy: 71.90
Round  73, Global train loss: 0.650, Global test loss: 1.574, Global test accuracy: 48.92
Round  74, Train loss: 0.563, Test loss: 0.897, Test accuracy: 72.31
Round  74, Global train loss: 0.563, Global test loss: 1.458, Global test accuracy: 56.23
Round  75, Train loss: 0.489, Test loss: 0.902, Test accuracy: 72.45
Round  75, Global train loss: 0.489, Global test loss: 1.455, Global test accuracy: 54.73
Round  76, Train loss: 0.450, Test loss: 0.898, Test accuracy: 72.56
Round  76, Global train loss: 0.450, Global test loss: 1.590, Global test accuracy: 52.85
Round  77, Train loss: 0.905, Test loss: 0.841, Test accuracy: 73.53
Round  77, Global train loss: 0.905, Global test loss: 1.452, Global test accuracy: 54.87
Round  78, Train loss: 0.612, Test loss: 0.893, Test accuracy: 72.29
Round  78, Global train loss: 0.612, Global test loss: 1.556, Global test accuracy: 52.32
Round  79, Train loss: 0.431, Test loss: 0.889, Test accuracy: 72.54
Round  79, Global train loss: 0.431, Global test loss: 1.549, Global test accuracy: 52.91
Round  80, Train loss: 0.727, Test loss: 0.939, Test accuracy: 71.57
Round  80, Global train loss: 0.727, Global test loss: 1.473, Global test accuracy: 54.19
Round  81, Train loss: 0.671, Test loss: 0.944, Test accuracy: 71.31
Round  81, Global train loss: 0.671, Global test loss: 1.540, Global test accuracy: 51.79
Round  82, Train loss: 0.620, Test loss: 0.957, Test accuracy: 71.12
Round  82, Global train loss: 0.620, Global test loss: 1.744, Global test accuracy: 47.78
Round  83, Train loss: 0.560, Test loss: 0.979, Test accuracy: 70.40
Round  83, Global train loss: 0.560, Global test loss: 1.465, Global test accuracy: 53.85
Round  84, Train loss: 0.738, Test loss: 0.993, Test accuracy: 69.59
Round  84, Global train loss: 0.738, Global test loss: 1.520, Global test accuracy: 53.24
Round  85, Train loss: 0.749, Test loss: 0.966, Test accuracy: 70.63
Round  85, Global train loss: 0.749, Global test loss: 1.526, Global test accuracy: 53.52
Round  86, Train loss: 0.511, Test loss: 0.976, Test accuracy: 70.37
Round  86, Global train loss: 0.511, Global test loss: 1.478, Global test accuracy: 55.83
Round  87, Train loss: 0.588, Test loss: 0.958, Test accuracy: 71.11
Round  87, Global train loss: 0.588, Global test loss: 1.506, Global test accuracy: 53.83
Round  88, Train loss: 0.487, Test loss: 0.977, Test accuracy: 71.28
Round  88, Global train loss: 0.487, Global test loss: 1.597, Global test accuracy: 54.55
Round  89, Train loss: 0.404, Test loss: 0.972, Test accuracy: 71.08
Round  89, Global train loss: 0.404, Global test loss: 1.630, Global test accuracy: 52.90
Round  90, Train loss: 0.773, Test loss: 0.978, Test accuracy: 71.02
Round  90, Global train loss: 0.773, Global test loss: 1.611, Global test accuracy: 50.61
Round  91, Train loss: 0.428, Test loss: 0.986, Test accuracy: 71.32
Round  91, Global train loss: 0.428, Global test loss: 1.563, Global test accuracy: 54.25
Round  92, Train loss: 0.538, Test loss: 0.940, Test accuracy: 72.07
Round  92, Global train loss: 0.538, Global test loss: 1.641, Global test accuracy: 51.89
Round  93, Train loss: 0.566, Test loss: 0.958, Test accuracy: 71.49
Round  93, Global train loss: 0.566, Global test loss: 1.473, Global test accuracy: 55.33
Round  94, Train loss: 0.639, Test loss: 0.994, Test accuracy: 70.97
Round  94, Global train loss: 0.639, Global test loss: 1.601, Global test accuracy: 51.27
Round  95, Train loss: 0.644, Test loss: 0.977, Test accuracy: 70.60
Round  95, Global train loss: 0.644, Global test loss: 1.787, Global test accuracy: 49.21
Round  96, Train loss: 0.524, Test loss: 1.005, Test accuracy: 70.02
Round  96, Global train loss: 0.524, Global test loss: 1.500, Global test accuracy: 54.37
Round  97, Train loss: 0.683, Test loss: 1.002, Test accuracy: 70.33
Round  97, Global train loss: 0.683, Global test loss: 1.779, Global test accuracy: 47.75
Round  98, Train loss: 0.631, Test loss: 1.015, Test accuracy: 70.59
Round  98, Global train loss: 0.631, Global test loss: 1.640, Global test accuracy: 49.59
Round  99, Train loss: 0.621, Test loss: 1.036, Test accuracy: 70.47
Round  99, Global train loss: 0.621, Global test loss: 1.655, Global test accuracy: 50.15
Final Round, Train loss: 0.466, Test loss: 1.087, Test accuracy: 70.65
Final Round, Global train loss: 0.466, Global test loss: 1.655, Global test accuracy: 50.15
Average accuracy final 10 rounds: 70.88583333333332 

Average global accuracy final 10 rounds: 51.4425 

2068.2367227077484
[1.934096336364746, 3.868192672729492, 5.54607629776001, 7.223959922790527, 8.92250108718872, 10.621042251586914, 12.303598165512085, 13.986154079437256, 15.69037938117981, 17.394604682922363, 19.019127368927002, 20.64365005493164, 22.27052617073059, 23.89740228652954, 25.53271198272705, 27.16802167892456, 28.808622360229492, 30.449223041534424, 32.113728046417236, 33.77823305130005, 35.53558564186096, 37.292938232421875, 38.992326736450195, 40.691715240478516, 42.3735568523407, 44.05539846420288, 45.74628686904907, 47.437175273895264, 49.129300594329834, 50.821425914764404, 52.57044434547424, 54.31946277618408, 55.9938702583313, 57.668277740478516, 59.352033853530884, 61.03578996658325, 62.72317576408386, 64.41056156158447, 66.08475875854492, 67.75895595550537, 69.42142486572266, 71.08389377593994, 72.75765633583069, 74.43141889572144, 76.11778616905212, 77.80415344238281, 79.46832036972046, 81.1324872970581, 82.80690908432007, 84.48133087158203, 86.17102718353271, 87.8607234954834, 89.54516577720642, 91.22960805892944, 92.9306275844574, 94.63164710998535, 96.30985808372498, 97.9880690574646, 99.72472190856934, 101.46137475967407, 103.09659242630005, 104.73181009292603, 106.36465239524841, 107.9974946975708, 109.62322974205017, 111.24896478652954, 112.87423372268677, 114.499502658844, 116.12619829177856, 117.75289392471313, 119.38907146453857, 121.02524900436401, 122.65343689918518, 124.28162479400635, 125.89968585968018, 127.517746925354, 129.16053533554077, 130.80332374572754, 132.4328773021698, 134.06243085861206, 135.70736861228943, 137.3523063659668, 138.84808111190796, 140.34385585784912, 141.81101989746094, 143.27818393707275, 144.743492603302, 146.20880126953125, 147.69442701339722, 149.18005275726318, 150.67781281471252, 152.17557287216187, 153.64233922958374, 155.10910558700562, 156.57983016967773, 158.05055475234985, 159.5181314945221, 160.98570823669434, 162.45766186714172, 163.9296154975891, 165.38591861724854, 166.84222173690796, 168.32249307632446, 169.80276441574097, 171.28701901435852, 172.77127361297607, 174.26961469650269, 175.7679557800293, 177.24747848510742, 178.72700119018555, 180.22268509864807, 181.7183690071106, 183.20878648757935, 184.6992039680481, 186.17348861694336, 187.64777326583862, 189.1161711215973, 190.58456897735596, 192.06273412704468, 193.5408992767334, 195.02606439590454, 196.51122951507568, 198.01063323020935, 199.51003694534302, 201.0207643508911, 202.5314917564392, 204.01618814468384, 205.50088453292847, 206.97515201568604, 208.4494194984436, 209.93549942970276, 211.4215793609619, 212.89702153205872, 214.37246370315552, 215.86940717697144, 217.36635065078735, 218.86604642868042, 220.3657422065735, 221.83202171325684, 223.29830121994019, 224.78130650520325, 226.2643117904663, 227.75705528259277, 229.24979877471924, 230.73722195625305, 232.22464513778687, 233.72596621513367, 235.22728729248047, 236.71991324424744, 238.2125391960144, 239.71462559700012, 241.21671199798584, 242.7086696624756, 244.20062732696533, 245.69735455513, 247.19408178329468, 248.69064164161682, 250.18720149993896, 251.68303108215332, 253.17886066436768, 254.68437123298645, 256.1898818016052, 257.679221868515, 259.1685619354248, 260.6673741340637, 262.16618633270264, 263.64520502090454, 265.12422370910645, 266.60634779930115, 268.08847188949585, 269.56595158576965, 271.04343128204346, 272.5223286151886, 274.00122594833374, 275.4849851131439, 276.9687442779541, 278.4728693962097, 279.97699451446533, 281.4781289100647, 282.97926330566406, 284.43198227882385, 285.88470125198364, 287.37781524658203, 288.8709292411804, 290.37327551841736, 291.8756217956543, 293.37981820106506, 294.88401460647583, 296.35447096824646, 297.8249273300171, 299.29982590675354, 300.77472448349, 302.23271775245667, 303.69071102142334, 305.15406680107117, 306.617422580719, 308.08622336387634, 309.5550241470337, 311.0265212059021, 312.4980182647705, 314.9850871562958, 317.47215604782104]
[27.958333333333332, 27.958333333333332, 41.666666666666664, 41.666666666666664, 49.59166666666667, 49.59166666666667, 54.34166666666667, 54.34166666666667, 56.975, 56.975, 56.63333333333333, 56.63333333333333, 59.016666666666666, 59.016666666666666, 58.96666666666667, 58.96666666666667, 63.05, 63.05, 63.49166666666667, 63.49166666666667, 62.608333333333334, 62.608333333333334, 66.06666666666666, 66.06666666666666, 66.8, 66.8, 67.74166666666666, 67.74166666666666, 68.31666666666666, 68.31666666666666, 68.44166666666666, 68.44166666666666, 67.80833333333334, 67.80833333333334, 68.44166666666666, 68.44166666666666, 70.00833333333334, 70.00833333333334, 69.91666666666667, 69.91666666666667, 69.99166666666666, 69.99166666666666, 70.2, 70.2, 70.89166666666667, 70.89166666666667, 71.0, 71.0, 70.74166666666666, 70.74166666666666, 70.43333333333334, 70.43333333333334, 70.73333333333333, 70.73333333333333, 71.01666666666667, 71.01666666666667, 70.91666666666667, 70.91666666666667, 70.88333333333334, 70.88333333333334, 70.91666666666667, 70.91666666666667, 71.875, 71.875, 72.14166666666667, 72.14166666666667, 72.14166666666667, 72.14166666666667, 70.725, 70.725, 72.1, 72.1, 72.85833333333333, 72.85833333333333, 72.48333333333333, 72.48333333333333, 72.43333333333334, 72.43333333333334, 73.05833333333334, 73.05833333333334, 72.24166666666666, 72.24166666666666, 72.69166666666666, 72.69166666666666, 72.725, 72.725, 71.925, 71.925, 71.88333333333334, 71.88333333333334, 71.00833333333334, 71.00833333333334, 71.25, 71.25, 71.40833333333333, 71.40833333333333, 71.875, 71.875, 72.23333333333333, 72.23333333333333, 71.74166666666666, 71.74166666666666, 71.96666666666667, 71.96666666666667, 72.61666666666666, 72.61666666666666, 70.925, 70.925, 71.78333333333333, 71.78333333333333, 71.64166666666667, 71.64166666666667, 71.75, 71.75, 72.05, 72.05, 72.56666666666666, 72.56666666666666, 72.66666666666667, 72.66666666666667, 72.85833333333333, 72.85833333333333, 73.25, 73.25, 73.68333333333334, 73.68333333333334, 72.29166666666667, 72.29166666666667, 71.65833333333333, 71.65833333333333, 71.525, 71.525, 71.96666666666667, 71.96666666666667, 71.375, 71.375, 71.14166666666667, 71.14166666666667, 71.49166666666666, 71.49166666666666, 70.85, 70.85, 71.29166666666667, 71.29166666666667, 71.55, 71.55, 71.9, 71.9, 72.30833333333334, 72.30833333333334, 72.45, 72.45, 72.55833333333334, 72.55833333333334, 73.525, 73.525, 72.29166666666667, 72.29166666666667, 72.54166666666667, 72.54166666666667, 71.56666666666666, 71.56666666666666, 71.30833333333334, 71.30833333333334, 71.11666666666666, 71.11666666666666, 70.4, 70.4, 69.59166666666667, 69.59166666666667, 70.63333333333334, 70.63333333333334, 70.36666666666666, 70.36666666666666, 71.10833333333333, 71.10833333333333, 71.275, 71.275, 71.075, 71.075, 71.01666666666667, 71.01666666666667, 71.31666666666666, 71.31666666666666, 72.06666666666666, 72.06666666666666, 71.49166666666666, 71.49166666666666, 70.96666666666667, 70.96666666666667, 70.6, 70.6, 70.01666666666667, 70.01666666666667, 70.325, 70.325, 70.59166666666667, 70.59166666666667, 70.46666666666667, 70.46666666666667, 70.65, 70.65]/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Co-teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9745 (0.8771), real noise ratio: 0.8895
Client 2, noise level: 0.6597 (0.5937), real noise ratio: 0.5865
Client 3, noise level: 0.9589 (0.8630), real noise ratio: 0.8665
Client 4, noise level: 0.5160 (0.4644), real noise ratio: 0.5865
Client 6, noise level: 0.8149 (0.7334), real noise ratio: 0.7550
Client 7, noise level: 0.9369 (0.8432), real noise ratio: 0.8470
Client 8, noise level: 0.5044 (0.4539), real noise ratio: 0.4885
Client 9, noise level: 0.8733 (0.7860), real noise ratio: 0.8170
Client 13, noise level: 0.7546 (0.6792), real noise ratio: 0.7405
Client 15, noise level: 0.9778 (0.8800), real noise ratio: 0.8775
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Traceback (most recent call last):
  File "main_fedpac_co_teaching2.py", line 231, in <module>
    w_local, loss, indd, class_center_local, class_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1272, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 53408 is out of bounds for axis 0 with size 50000
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9745 (0.8771), real noise ratio: 0.8830
Client 2, noise level: 0.6597 (0.5937), real noise ratio: 0.5830
Client 3, noise level: 0.9589 (0.8630), real noise ratio: 0.8605
Client 4, noise level: 0.5160 (0.4644), real noise ratio: 0.4755
Client 6, noise level: 0.8149 (0.7334), real noise ratio: 0.7575
Client 7, noise level: 0.9369 (0.8432), real noise ratio: 0.8440
Client 8, noise level: 0.5044 (0.4539), real noise ratio: 0.5270
Client 9, noise level: 0.8733 (0.7860), real noise ratio: 0.7985
Client 13, noise level: 0.7546 (0.6792), real noise ratio: 0.7380
Client 15, noise level: 0.9778 (0.8800), real noise ratio: 0.8825
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Traceback (most recent call last):
  File "RFL.py", line 126, in <module>
    w_local, loss_local, f_k = local.train(copy.deepcopy(net_glob).to(args.device), copy.deepcopy(f_G).to(args.device),
  File "/home/ChenSM/code/FL_HLS/util/local_training.py", line 257, in train
    for batch_idx, (images, labels, idxs) in enumerate(self.ldr_train_tmp):
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/code/FL_HLS/util/local_training.py", line 48, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 55504 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9745 (0.8771), real noise ratio: 0.8685
Client 2, noise level: 0.6597 (0.5937), real noise ratio: 0.6035
Client 3, noise level: 0.9589 (0.8630), real noise ratio: 0.8665
Client 4, noise level: 0.5160 (0.4644), real noise ratio: 0.5045
Client 6, noise level: 0.8149 (0.7334), real noise ratio: 0.7565
Client 7, noise level: 0.9369 (0.8432), real noise ratio: 0.8495
Client 8, noise level: 0.5044 (0.4539), real noise ratio: 0.6055
Client 9, noise level: 0.8733 (0.7860), real noise ratio: 0.8465
Client 13, noise level: 0.7546 (0.6792), real noise ratio: 0.7230
Client 15, noise level: 0.9778 (0.8800), real noise ratio: 0.8935
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Traceback (most recent call last):
  File "main_fedpac.py", line 232, in <module>
    w_local, loss, indd, class_center_local, class_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1272, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 54880 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.4 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9745 (0.8771), real noise ratio: 0.8775
Client 2, noise level: 0.6597 (0.5937), real noise ratio: 0.5825
Client 3, noise level: 0.9589 (0.8630), real noise ratio: 0.8560
Client 4, noise level: 0.5160 (0.4644), real noise ratio: 0.5085
Client 6, noise level: 0.8149 (0.7334), real noise ratio: 0.7255
Client 7, noise level: 0.9369 (0.8432), real noise ratio: 0.8510
Client 8, noise level: 0.5044 (0.4539), real noise ratio: 0.5515
Client 9, noise level: 0.8733 (0.7860), real noise ratio: 0.7765
Client 13, noise level: 0.7546 (0.6792), real noise ratio: 0.7370
Client 15, noise level: 0.9778 (0.8800), real noise ratio: 0.9055
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Traceback (most recent call last):
  File "main_fedpac_psl.py", line 235, in <module>
    w_local, loss, indd, class_center_local, class_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx], iter_num_now = iter, train_iter=iter)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1977, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train_local):
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 53507 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.6 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
Client 1, noise level: 0.2179 (0.1961), real noise ratio: 0.2035
Client 5, noise level: 0.0651 (0.0586), real noise ratio: 0.0560
Client 10, noise level: 0.8128 (0.7316), real noise ratio: 0.7280
Client 11, noise level: 0.0757 (0.0681), real noise ratio: 0.0620
Client 12, noise level: 0.6565 (0.5908), real noise ratio: 0.6205
Client 14, noise level: 0.4799 (0.4319), real noise ratio: 0.4415
Client 16, noise level: 0.0000 (0.0000), real noise ratio: 0.1305
Client 17, noise level: 0.2470 (0.2223), real noise ratio: 0.2435
Client 18, noise level: 0.7122 (0.6410), real noise ratio: 0.6705
Client 19, noise level: 0.3246 (0.2921), real noise ratio: 0.4115
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.181, Test loss: 2.091, Test accuracy: 29.18
Round   0, Global train loss: 2.181, Global test loss: 2.104, Global test accuracy: 30.39
Round   1, Train loss: 1.936, Test loss: 1.803, Test accuracy: 36.58
Round   1, Global train loss: 1.936, Global test loss: 1.696, Global test accuracy: 41.35
Round   2, Train loss: 1.881, Test loss: 1.816, Test accuracy: 37.99
Round   2, Global train loss: 1.881, Global test loss: 1.755, Global test accuracy: 44.48
Round   3, Train loss: 1.778, Test loss: 1.737, Test accuracy: 39.18
Round   3, Global train loss: 1.778, Global test loss: 1.499, Global test accuracy: 49.74
Round   4, Train loss: 1.759, Test loss: 1.733, Test accuracy: 39.52
Round   4, Global train loss: 1.759, Global test loss: 1.622, Global test accuracy: 51.26
Round   5, Train loss: 1.709, Test loss: 1.712, Test accuracy: 40.37
Round   5, Global train loss: 1.709, Global test loss: 1.513, Global test accuracy: 49.69
Round   6, Train loss: 1.703, Test loss: 1.696, Test accuracy: 41.45
Round   6, Global train loss: 1.703, Global test loss: 1.611, Global test accuracy: 50.92
Round   7, Train loss: 1.725, Test loss: 1.677, Test accuracy: 42.21
Round   7, Global train loss: 1.725, Global test loss: 1.534, Global test accuracy: 50.07
Round   8, Train loss: 1.875, Test loss: 1.666, Test accuracy: 42.41
Round   8, Global train loss: 1.875, Global test loss: 1.714, Global test accuracy: 49.57
Round   9, Train loss: 1.716, Test loss: 1.653, Test accuracy: 43.17
Round   9, Global train loss: 1.716, Global test loss: 1.663, Global test accuracy: 50.40
Round  10, Train loss: 1.835, Test loss: 1.651, Test accuracy: 43.31
Round  10, Global train loss: 1.835, Global test loss: 1.709, Global test accuracy: 50.52
Round  11, Train loss: 1.602, Test loss: 1.654, Test accuracy: 43.05
Round  11, Global train loss: 1.602, Global test loss: 1.457, Global test accuracy: 53.07
Round  12, Train loss: 1.729, Test loss: 1.638, Test accuracy: 44.07
Round  12, Global train loss: 1.729, Global test loss: 1.802, Global test accuracy: 47.34
Round  13, Train loss: 1.612, Test loss: 1.640, Test accuracy: 44.10
Round  13, Global train loss: 1.612, Global test loss: 1.580, Global test accuracy: 54.15
Round  14, Train loss: 1.449, Test loss: 1.640, Test accuracy: 44.12
Round  14, Global train loss: 1.449, Global test loss: 1.405, Global test accuracy: 53.90
Round  15, Train loss: 1.608, Test loss: 1.635, Test accuracy: 44.41
Round  15, Global train loss: 1.608, Global test loss: 1.661, Global test accuracy: 49.30
Round  16, Train loss: 1.355, Test loss: 1.646, Test accuracy: 44.30
Round  16, Global train loss: 1.355, Global test loss: 1.405, Global test accuracy: 53.89
Round  17, Train loss: 1.644, Test loss: 1.644, Test accuracy: 44.61
Round  17, Global train loss: 1.644, Global test loss: 1.749, Global test accuracy: 48.06
Round  18, Train loss: 1.455, Test loss: 1.650, Test accuracy: 44.59
Round  18, Global train loss: 1.455, Global test loss: 1.481, Global test accuracy: 54.22
Round  19, Train loss: 1.452, Test loss: 1.655, Test accuracy: 44.61
Round  19, Global train loss: 1.452, Global test loss: 1.492, Global test accuracy: 55.25
Round  20, Train loss: 1.304, Test loss: 1.654, Test accuracy: 44.57
Round  20, Global train loss: 1.304, Global test loss: 1.361, Global test accuracy: 55.91
Round  21, Train loss: 1.266, Test loss: 1.665, Test accuracy: 44.51
Round  21, Global train loss: 1.266, Global test loss: 1.423, Global test accuracy: 55.01
Round  22, Train loss: 1.067, Test loss: 1.687, Test accuracy: 44.28
Round  22, Global train loss: 1.067, Global test loss: 1.302, Global test accuracy: 56.90
Round  23, Train loss: 1.298, Test loss: 1.699, Test accuracy: 44.43
Round  23, Global train loss: 1.298, Global test loss: 1.554, Global test accuracy: 51.67
Round  24, Train loss: 1.250, Test loss: 1.720, Test accuracy: 44.02
Round  24, Global train loss: 1.250, Global test loss: 1.629, Global test accuracy: 48.50
Round  25, Train loss: 1.111, Test loss: 1.751, Test accuracy: 44.08
Round  25, Global train loss: 1.111, Global test loss: 1.328, Global test accuracy: 56.41
Round  26, Train loss: 1.089, Test loss: 1.772, Test accuracy: 43.95
Round  26, Global train loss: 1.089, Global test loss: 1.344, Global test accuracy: 55.60
Round  27, Train loss: 1.607, Test loss: 1.784, Test accuracy: 43.77
Round  27, Global train loss: 1.607, Global test loss: 1.817, Global test accuracy: 46.78
Round  28, Train loss: 1.234, Test loss: 1.791, Test accuracy: 43.83
Round  28, Global train loss: 1.234, Global test loss: 1.618, Global test accuracy: 48.03
Round  29, Train loss: 1.296, Test loss: 1.809, Test accuracy: 43.63
Round  29, Global train loss: 1.296, Global test loss: 1.676, Global test accuracy: 50.31
Round  30, Train loss: 1.057, Test loss: 1.805, Test accuracy: 43.96
Round  30, Global train loss: 1.057, Global test loss: 1.556, Global test accuracy: 49.56
Round  31, Train loss: 1.240, Test loss: 1.806, Test accuracy: 43.91
Round  31, Global train loss: 1.240, Global test loss: 1.689, Global test accuracy: 47.99
Round  32, Train loss: 1.202, Test loss: 1.835, Test accuracy: 43.78
Round  32, Global train loss: 1.202, Global test loss: 1.525, Global test accuracy: 51.70
Round  33, Train loss: 0.882, Test loss: 1.869, Test accuracy: 43.62
Round  33, Global train loss: 0.882, Global test loss: 1.291, Global test accuracy: 56.88
Round  34, Train loss: 1.011, Test loss: 1.891, Test accuracy: 43.64
Round  34, Global train loss: 1.011, Global test loss: 1.374, Global test accuracy: 54.62
Round  35, Train loss: 1.332, Test loss: 1.915, Test accuracy: 43.38
Round  35, Global train loss: 1.332, Global test loss: 1.784, Global test accuracy: 43.42
Round  36, Train loss: 1.025, Test loss: 1.939, Test accuracy: 43.20
Round  36, Global train loss: 1.025, Global test loss: 1.490, Global test accuracy: 51.92
Round  37, Train loss: 1.044, Test loss: 1.973, Test accuracy: 43.02
Round  37, Global train loss: 1.044, Global test loss: 1.402, Global test accuracy: 53.14
Round  38, Train loss: 0.907, Test loss: 2.021, Test accuracy: 42.67
Round  38, Global train loss: 0.907, Global test loss: 1.393, Global test accuracy: 53.04
Round  39, Train loss: 0.740, Test loss: 2.047, Test accuracy: 42.69
Round  39, Global train loss: 0.740, Global test loss: 1.335, Global test accuracy: 54.19
Round  40, Train loss: 0.904, Test loss: 2.057, Test accuracy: 43.09
Round  40, Global train loss: 0.904, Global test loss: 1.423, Global test accuracy: 52.84
Round  41, Train loss: 0.789, Test loss: 2.065, Test accuracy: 43.22
Round  41, Global train loss: 0.789, Global test loss: 1.356, Global test accuracy: 54.54
Round  42, Train loss: 0.842, Test loss: 2.080, Test accuracy: 43.16
Round  42, Global train loss: 0.842, Global test loss: 1.437, Global test accuracy: 52.31
Round  43, Train loss: 1.011, Test loss: 2.112, Test accuracy: 43.17
Round  43, Global train loss: 1.011, Global test loss: 1.664, Global test accuracy: 45.93
Round  44, Train loss: 0.983, Test loss: 2.185, Test accuracy: 42.42
Round  44, Global train loss: 0.983, Global test loss: 1.625, Global test accuracy: 47.01
Round  45, Train loss: 1.060, Test loss: 2.180, Test accuracy: 42.49
Round  45, Global train loss: 1.060, Global test loss: 1.625, Global test accuracy: 47.84
Round  46, Train loss: 0.632, Test loss: 2.211, Test accuracy: 42.08
Round  46, Global train loss: 0.632, Global test loss: 1.386, Global test accuracy: 53.45
Round  47, Train loss: 0.699, Test loss: 2.213, Test accuracy: 41.99
Round  47, Global train loss: 0.699, Global test loss: 1.472, Global test accuracy: 50.55
Round  48, Train loss: 0.914, Test loss: 2.249, Test accuracy: 42.08
Round  48, Global train loss: 0.914, Global test loss: 1.572, Global test accuracy: 49.36
Round  49, Train loss: 0.651, Test loss: 2.251, Test accuracy: 42.71
Round  49, Global train loss: 0.651, Global test loss: 1.391, Global test accuracy: 53.79
Round  50, Train loss: 0.810, Test loss: 2.248, Test accuracy: 42.55
Round  50, Global train loss: 0.810, Global test loss: 1.467, Global test accuracy: 51.16
Round  51, Train loss: 0.625, Test loss: 2.278, Test accuracy: 42.30
Round  51, Global train loss: 0.625, Global test loss: 1.322, Global test accuracy: 54.95
Round  52, Train loss: 0.868, Test loss: 2.321, Test accuracy: 41.88
Round  52, Global train loss: 0.868, Global test loss: 1.499, Global test accuracy: 50.72
Round  53, Train loss: 0.807, Test loss: 2.358, Test accuracy: 41.73
Round  53, Global train loss: 0.807, Global test loss: 1.397, Global test accuracy: 53.25
Round  54, Train loss: 0.803, Test loss: 2.392, Test accuracy: 42.19
Round  54, Global train loss: 0.803, Global test loss: 1.620, Global test accuracy: 46.25
Round  55, Train loss: 0.932, Test loss: 2.441, Test accuracy: 41.98
Round  55, Global train loss: 0.932, Global test loss: 1.684, Global test accuracy: 46.08
Round  56, Train loss: 0.939, Test loss: 2.477, Test accuracy: 41.74
Round  56, Global train loss: 0.939, Global test loss: 1.585, Global test accuracy: 49.27
Round  57, Train loss: 0.558, Test loss: 2.494, Test accuracy: 41.69
Round  57, Global train loss: 0.558, Global test loss: 1.393, Global test accuracy: 53.62
Round  58, Train loss: 0.613, Test loss: 2.520, Test accuracy: 41.63
Round  58, Global train loss: 0.613, Global test loss: 1.529, Global test accuracy: 48.65
Round  59, Train loss: 0.672, Test loss: 2.510, Test accuracy: 42.40
Round  59, Global train loss: 0.672, Global test loss: 1.501, Global test accuracy: 48.91
Round  60, Train loss: 0.689, Test loss: 2.529, Test accuracy: 42.37
Round  60, Global train loss: 0.689, Global test loss: 1.490, Global test accuracy: 50.78
Round  61, Train loss: 0.761, Test loss: 2.545, Test accuracy: 42.15
Round  61, Global train loss: 0.761, Global test loss: 1.466, Global test accuracy: 51.13
Round  62, Train loss: 0.719, Test loss: 2.563, Test accuracy: 41.83
Round  62, Global train loss: 0.719, Global test loss: 1.541, Global test accuracy: 47.86
Round  63, Train loss: 0.831, Test loss: 2.545, Test accuracy: 41.85
Round  63, Global train loss: 0.831, Global test loss: 1.834, Global test accuracy: 36.10
Round  64, Train loss: 0.767, Test loss: 2.553, Test accuracy: 41.60
Round  64, Global train loss: 0.767, Global test loss: 1.571, Global test accuracy: 47.48
Round  65, Train loss: 0.654, Test loss: 2.616, Test accuracy: 41.49
Round  65, Global train loss: 0.654, Global test loss: 1.493, Global test accuracy: 49.83
Round  66, Train loss: 0.611, Test loss: 2.651, Test accuracy: 41.25
Round  66, Global train loss: 0.611, Global test loss: 1.454, Global test accuracy: 51.23
Round  67, Train loss: 0.546, Test loss: 2.699, Test accuracy: 41.08
Round  67, Global train loss: 0.546, Global test loss: 1.458, Global test accuracy: 51.32
Round  68, Train loss: 0.424, Test loss: 2.738, Test accuracy: 41.10
Round  68, Global train loss: 0.424, Global test loss: 1.412, Global test accuracy: 51.73
Round  69, Train loss: 0.605, Test loss: 2.748, Test accuracy: 41.41
Round  69, Global train loss: 0.605, Global test loss: 1.440, Global test accuracy: 51.71
Round  70, Train loss: 0.677, Test loss: 2.774, Test accuracy: 41.67
Round  70, Global train loss: 0.677, Global test loss: 1.657, Global test accuracy: 44.88
Round  71, Train loss: 0.661, Test loss: 2.809, Test accuracy: 41.44
Round  71, Global train loss: 0.661, Global test loss: 1.473, Global test accuracy: 50.48
Round  72, Train loss: 0.852, Test loss: 2.861, Test accuracy: 41.52
Round  72, Global train loss: 0.852, Global test loss: 1.825, Global test accuracy: 39.73
Round  73, Train loss: 0.691, Test loss: 2.857, Test accuracy: 41.47
Round  73, Global train loss: 0.691, Global test loss: 1.653, Global test accuracy: 44.37
Round  74, Train loss: 0.506, Test loss: 2.838, Test accuracy: 41.85
Round  74, Global train loss: 0.506, Global test loss: 1.482, Global test accuracy: 50.08
Round  75, Train loss: 0.511, Test loss: 2.823, Test accuracy: 41.97
Round  75, Global train loss: 0.511, Global test loss: 1.441, Global test accuracy: 51.87
Round  76, Train loss: 0.439, Test loss: 2.886, Test accuracy: 41.78
Round  76, Global train loss: 0.439, Global test loss: 1.429, Global test accuracy: 52.18
Round  77, Train loss: 0.696, Test loss: 2.917, Test accuracy: 41.78
Round  77, Global train loss: 0.696, Global test loss: 1.737, Global test accuracy: 41.60
Round  78, Train loss: 0.611, Test loss: 2.929, Test accuracy: 41.66
Round  78, Global train loss: 0.611, Global test loss: 1.485, Global test accuracy: 50.38
Round  79, Train loss: 0.691, Test loss: 2.964, Test accuracy: 41.56
Round  79, Global train loss: 0.691, Global test loss: 1.645, Global test accuracy: 44.63
Round  80, Train loss: 0.441, Test loss: 2.994, Test accuracy: 41.48
Round  80, Global train loss: 0.441, Global test loss: 1.445, Global test accuracy: 51.58
Round  81, Train loss: 0.638, Test loss: 3.017, Test accuracy: 41.73
Round  81, Global train loss: 0.638, Global test loss: 1.655, Global test accuracy: 45.87
Round  82, Train loss: 0.395, Test loss: 3.041, Test accuracy: 41.67
Round  82, Global train loss: 0.395, Global test loss: 1.383, Global test accuracy: 52.99
Round  83, Train loss: 0.386, Test loss: 3.070, Test accuracy: 41.38
Round  83, Global train loss: 0.386, Global test loss: 1.470, Global test accuracy: 50.82
Round  84, Train loss: 0.643, Test loss: 3.071, Test accuracy: 41.31
Round  84, Global train loss: 0.643, Global test loss: 1.823, Global test accuracy: 38.53
Round  85, Train loss: 0.729, Test loss: 3.073, Test accuracy: 41.20
Round  85, Global train loss: 0.729, Global test loss: 1.624, Global test accuracy: 46.53
Round  86, Train loss: 0.392, Test loss: 3.104, Test accuracy: 41.24
Round  86, Global train loss: 0.392, Global test loss: 1.380, Global test accuracy: 52.66
Round  87, Train loss: 0.416, Test loss: 3.145, Test accuracy: 41.30
Round  87, Global train loss: 0.416, Global test loss: 1.507, Global test accuracy: 49.14
Round  88, Train loss: 0.485, Test loss: 3.161, Test accuracy: 40.91
Round  88, Global train loss: 0.485, Global test loss: 1.662, Global test accuracy: 42.15
Round  89, Train loss: 0.491, Test loss: 3.149, Test accuracy: 40.94
Round  89, Global train loss: 0.491, Global test loss: 1.576, Global test accuracy: 46.42
Round  90, Train loss: 0.636, Test loss: 3.174, Test accuracy: 41.34
Round  90, Global train loss: 0.636, Global test loss: 1.839, Global test accuracy: 38.30
Round  91, Train loss: 0.765, Test loss: 3.191, Test accuracy: 41.40
Round  91, Global train loss: 0.765, Global test loss: 1.906, Global test accuracy: 37.86
Round  92, Train loss: 0.444, Test loss: 3.257, Test accuracy: 41.28
Round  92, Global train loss: 0.444, Global test loss: 1.598, Global test accuracy: 46.02
Round  93, Train loss: 0.516, Test loss: 3.249, Test accuracy: 41.24
Round  93, Global train loss: 0.516, Global test loss: 1.529, Global test accuracy: 47.51
Round  94, Train loss: 0.430, Test loss: 3.283, Test accuracy: 40.97
Round  94, Global train loss: 0.430, Global test loss: 1.533, Global test accuracy: 48.62
Round  95, Train loss: 0.616, Test loss: 3.280, Test accuracy: 41.16
Round  95, Global train loss: 0.616, Global test loss: 1.861, Global test accuracy: 36.55
Round  96, Train loss: 0.492, Test loss: 3.298, Test accuracy: 41.38
Round  96, Global train loss: 0.492, Global test loss: 1.542, Global test accuracy: 47.59
Round  97, Train loss: 0.561, Test loss: 3.314, Test accuracy: 41.16
Round  97, Global train loss: 0.561, Global test loss: 1.860, Global test accuracy: 36.77
Round  98, Train loss: 0.497, Test loss: 3.332, Test accuracy: 41.02
Round  98, Global train loss: 0.497, Global test loss: 1.613, Global test accuracy: 46.40
Round  99, Train loss: 0.341, Test loss: 3.346, Test accuracy: 40.88
Round  99, Global train loss: 0.341, Global test loss: 1.412, Global test accuracy: 53.55
Final Round, Train loss: 0.321, Test loss: 3.789, Test accuracy: 41.67
Final Round, Global train loss: 0.321, Global test loss: 1.412, Global test accuracy: 53.55
Average accuracy final 10 rounds: 41.184250000000006 

Average global accuracy final 10 rounds: 43.91625 

6107.047271966934
[5.386111497879028, 10.772222995758057, 15.865703821182251, 20.959184646606445, 25.93631076812744, 30.913436889648438, 35.960782051086426, 41.008127212524414, 46.033775091171265, 51.059422969818115, 55.45598840713501, 59.852553844451904, 64.2971670627594, 68.7417802810669, 73.06915068626404, 77.39652109146118, 81.90409708023071, 86.41167306900024, 90.74072289466858, 95.06977272033691, 99.41260409355164, 103.75543546676636, 108.73759078979492, 113.71974611282349, 118.6700394153595, 123.62033271789551, 128.59824442863464, 133.57615613937378, 138.5872299671173, 143.59830379486084, 148.59299063682556, 153.58767747879028, 158.49811840057373, 163.40855932235718, 167.9216685295105, 172.43477773666382, 176.79213762283325, 181.14949750900269, 185.53840613365173, 189.92731475830078, 194.30293607711792, 198.67855739593506, 203.06322073936462, 207.4478840827942, 211.84226274490356, 216.23664140701294, 220.60866260528564, 224.98068380355835, 229.33754062652588, 233.6943974494934, 238.02805376052856, 242.36171007156372, 246.70575761795044, 251.04980516433716, 255.39291262626648, 259.7360200881958, 264.06856989860535, 268.4011197090149, 272.83860993385315, 277.2761001586914, 281.69577264785767, 286.1154451370239, 290.4603934288025, 294.80534172058105, 299.1022982597351, 303.39925479888916, 307.6782913208008, 311.9573278427124, 316.2799780368805, 320.6026282310486, 324.94816970825195, 329.2937111854553, 333.61361360549927, 337.9335160255432, 342.2618741989136, 346.59023237228394, 350.8829824924469, 355.17573261260986, 359.4979968070984, 363.8202610015869, 368.14731645584106, 372.4743719100952, 376.7871789932251, 381.099986076355, 385.41578102111816, 389.73157596588135, 394.0649118423462, 398.39824771881104, 402.8712685108185, 407.3442893028259, 412.299192905426, 417.2540965080261, 422.1623969078064, 427.07069730758667, 431.3887302875519, 435.7067632675171, 440.0091052055359, 444.3114471435547, 448.6398935317993, 452.96833992004395, 457.2560682296753, 461.54379653930664, 465.81560921669006, 470.0874218940735, 474.3822298049927, 478.67703771591187, 483.04063749313354, 487.4042372703552, 491.7375235557556, 496.070809841156, 500.4193227291107, 504.76783561706543, 509.0691695213318, 513.3705034255981, 517.6508684158325, 521.9312334060669, 526.2547137737274, 530.5781941413879, 534.9132115840912, 539.2482290267944, 543.6211919784546, 547.9941549301147, 552.3514020442963, 556.7086491584778, 561.0609896183014, 565.413330078125, 569.7619352340698, 574.1105403900146, 578.4216642379761, 582.7327880859375, 586.99573802948, 591.2586879730225, 595.5727646350861, 599.8868412971497, 604.2237141132355, 608.5605869293213, 612.9557993412018, 617.3510117530823, 621.7525699138641, 626.154128074646, 630.4726960659027, 634.7912640571594, 639.0991640090942, 643.407063961029, 647.8073461055756, 652.2076282501221, 656.6221392154694, 661.0366501808167, 665.3797612190247, 669.7228722572327, 674.072215795517, 678.4215593338013, 682.7672100067139, 687.1128606796265, 691.4228317737579, 695.7328028678894, 700.0860004425049, 704.4391980171204, 708.7384703159332, 713.0377426147461, 717.4266164302826, 721.8154902458191, 726.1985070705414, 730.5815238952637, 735.0100636482239, 739.4386034011841, 743.8863353729248, 748.3340673446655, 752.7391028404236, 757.1441383361816, 761.4538111686707, 765.7634840011597, 770.0893440246582, 774.4152040481567, 778.8535878658295, 783.2919716835022, 787.6988105773926, 792.105649471283, 796.5581889152527, 801.0107283592224, 805.3962295055389, 809.7817306518555, 814.1962659358978, 818.6108012199402, 822.9797923564911, 827.348783493042, 831.7173118591309, 836.0858402252197, 840.449568271637, 844.8132963180542, 849.2543892860413, 853.6954822540283, 858.217903137207, 862.7403240203857, 867.1949291229248, 871.6495342254639, 876.0250723361969, 880.4006104469299, 884.7595226764679, 889.1184349060059, 891.3308551311493, 893.5432753562927]
[29.185, 29.185, 36.575, 36.575, 37.9875, 37.9875, 39.1775, 39.1775, 39.5225, 39.5225, 40.3675, 40.3675, 41.4525, 41.4525, 42.2075, 42.2075, 42.415, 42.415, 43.17, 43.17, 43.31, 43.31, 43.0475, 43.0475, 44.0725, 44.0725, 44.1025, 44.1025, 44.12, 44.12, 44.4075, 44.4075, 44.295, 44.295, 44.6125, 44.6125, 44.585, 44.585, 44.6075, 44.6075, 44.5725, 44.5725, 44.5075, 44.5075, 44.285, 44.285, 44.43, 44.43, 44.0225, 44.0225, 44.08, 44.08, 43.945, 43.945, 43.765, 43.765, 43.8275, 43.8275, 43.6325, 43.6325, 43.9575, 43.9575, 43.9125, 43.9125, 43.7825, 43.7825, 43.62, 43.62, 43.64, 43.64, 43.385, 43.385, 43.205, 43.205, 43.0225, 43.0225, 42.6725, 42.6725, 42.6925, 42.6925, 43.095, 43.095, 43.2175, 43.2175, 43.155, 43.155, 43.175, 43.175, 42.4225, 42.4225, 42.4875, 42.4875, 42.0775, 42.0775, 41.9875, 41.9875, 42.0775, 42.0775, 42.7125, 42.7125, 42.5525, 42.5525, 42.2975, 42.2975, 41.885, 41.885, 41.7325, 41.7325, 42.19, 42.19, 41.9775, 41.9775, 41.745, 41.745, 41.69, 41.69, 41.635, 41.635, 42.395, 42.395, 42.3675, 42.3675, 42.1525, 42.1525, 41.825, 41.825, 41.8475, 41.8475, 41.5975, 41.5975, 41.4875, 41.4875, 41.2525, 41.2525, 41.075, 41.075, 41.105, 41.105, 41.4125, 41.4125, 41.6675, 41.6675, 41.4375, 41.4375, 41.525, 41.525, 41.465, 41.465, 41.8475, 41.8475, 41.9725, 41.9725, 41.785, 41.785, 41.7775, 41.7775, 41.665, 41.665, 41.565, 41.565, 41.485, 41.485, 41.725, 41.725, 41.67, 41.67, 41.38, 41.38, 41.31, 41.31, 41.205, 41.205, 41.2425, 41.2425, 41.305, 41.305, 40.9125, 40.9125, 40.9375, 40.9375, 41.335, 41.335, 41.3975, 41.3975, 41.285, 41.285, 41.2375, 41.2375, 40.9675, 40.9675, 41.165, 41.165, 41.3825, 41.3825, 41.165, 41.165, 41.025, 41.025, 40.8825, 40.8825, 41.675, 41.675]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.6 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
Client 1, noise level: 0.2179 (0.1961), real noise ratio: 0.2110
Client 5, noise level: 0.0651 (0.0586), real noise ratio: 0.0590
Client 10, noise level: 0.8128 (0.7316), real noise ratio: 0.7375
Client 11, noise level: 0.0757 (0.0681), real noise ratio: 0.0945
Client 12, noise level: 0.6565 (0.5908), real noise ratio: 0.5960
Client 14, noise level: 0.4799 (0.4319), real noise ratio: 0.4620
Client 16, noise level: 0.0000 (0.0000), real noise ratio: 0.0000
Client 17, noise level: 0.2470 (0.2223), real noise ratio: 0.2830
Client 18, noise level: 0.7122 (0.6410), real noise ratio: 0.6485
Client 19, noise level: 0.3246 (0.2921), real noise ratio: 0.4320
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.071, Test loss: 1.885, Test accuracy: 33.17
Round   0, Global train loss: 2.071, Global test loss: 1.888, Global test accuracy: 34.17
Round   1, Train loss: 1.843, Test loss: 1.671, Test accuracy: 39.60
Round   1, Global train loss: 1.843, Global test loss: 1.572, Global test accuracy: 44.01
Round   2, Train loss: 1.781, Test loss: 1.650, Test accuracy: 42.11
Round   2, Global train loss: 1.781, Global test loss: 1.540, Global test accuracy: 48.60
Round   3, Train loss: 1.666, Test loss: 1.616, Test accuracy: 42.27
Round   3, Global train loss: 1.666, Global test loss: 1.400, Global test accuracy: 52.32
Round   4, Train loss: 1.572, Test loss: 1.575, Test accuracy: 43.93
Round   4, Global train loss: 1.572, Global test loss: 1.321, Global test accuracy: 55.42
Round   5, Train loss: 1.509, Test loss: 1.533, Test accuracy: 45.94
Round   5, Global train loss: 1.509, Global test loss: 1.238, Global test accuracy: 58.75
Round   6, Train loss: 1.476, Test loss: 1.496, Test accuracy: 47.59
Round   6, Global train loss: 1.476, Global test loss: 1.214, Global test accuracy: 59.87
Round   7, Train loss: 1.470, Test loss: 1.446, Test accuracy: 50.12
Round   7, Global train loss: 1.470, Global test loss: 1.172, Global test accuracy: 62.03
Round   8, Train loss: 1.396, Test loss: 1.391, Test accuracy: 52.22
Round   8, Global train loss: 1.396, Global test loss: 1.116, Global test accuracy: 63.54
Round   9, Train loss: 1.379, Test loss: 1.372, Test accuracy: 52.88
Round   9, Global train loss: 1.379, Global test loss: 1.097, Global test accuracy: 64.70
Round  10, Train loss: 1.315, Test loss: 1.333, Test accuracy: 54.58
Round  10, Global train loss: 1.315, Global test loss: 1.048, Global test accuracy: 65.53
Round  11, Train loss: 1.323, Test loss: 1.323, Test accuracy: 55.02
Round  11, Global train loss: 1.323, Global test loss: 1.055, Global test accuracy: 65.95
Round  12, Train loss: 1.301, Test loss: 1.309, Test accuracy: 55.61
Round  12, Global train loss: 1.301, Global test loss: 1.012, Global test accuracy: 67.31
Round  13, Train loss: 1.200, Test loss: 1.275, Test accuracy: 57.14
Round  13, Global train loss: 1.200, Global test loss: 0.983, Global test accuracy: 66.89
Round  14, Train loss: 1.299, Test loss: 1.239, Test accuracy: 58.37
Round  14, Global train loss: 1.299, Global test loss: 1.031, Global test accuracy: 67.54
Round  15, Train loss: 1.224, Test loss: 1.225, Test accuracy: 59.04
Round  15, Global train loss: 1.224, Global test loss: 0.974, Global test accuracy: 69.02
Round  16, Train loss: 1.204, Test loss: 1.219, Test accuracy: 59.20
Round  16, Global train loss: 1.204, Global test loss: 0.944, Global test accuracy: 69.71
Round  17, Train loss: 1.201, Test loss: 1.220, Test accuracy: 59.34
Round  17, Global train loss: 1.201, Global test loss: 0.947, Global test accuracy: 69.47
Round  18, Train loss: 1.207, Test loss: 1.204, Test accuracy: 60.31
Round  18, Global train loss: 1.207, Global test loss: 0.916, Global test accuracy: 70.53
Round  19, Train loss: 1.094, Test loss: 1.182, Test accuracy: 61.01
Round  19, Global train loss: 1.094, Global test loss: 0.890, Global test accuracy: 70.97
Round  20, Train loss: 1.155, Test loss: 1.177, Test accuracy: 61.34
Round  20, Global train loss: 1.155, Global test loss: 0.922, Global test accuracy: 70.96
Round  21, Train loss: 1.079, Test loss: 1.178, Test accuracy: 61.33
Round  21, Global train loss: 1.079, Global test loss: 0.871, Global test accuracy: 71.45
Round  22, Train loss: 1.087, Test loss: 1.191, Test accuracy: 61.31
Round  22, Global train loss: 1.087, Global test loss: 0.917, Global test accuracy: 70.68
Round  23, Train loss: 1.058, Test loss: 1.185, Test accuracy: 61.59
Round  23, Global train loss: 1.058, Global test loss: 0.869, Global test accuracy: 71.48
Round  24, Train loss: 0.999, Test loss: 1.183, Test accuracy: 61.60
Round  24, Global train loss: 0.999, Global test loss: 0.853, Global test accuracy: 71.42
Round  25, Train loss: 1.025, Test loss: 1.184, Test accuracy: 61.73
Round  25, Global train loss: 1.025, Global test loss: 0.875, Global test accuracy: 71.11
Round  26, Train loss: 1.102, Test loss: 1.154, Test accuracy: 62.42
Round  26, Global train loss: 1.102, Global test loss: 0.889, Global test accuracy: 71.77
Round  27, Train loss: 1.022, Test loss: 1.134, Test accuracy: 63.40
Round  27, Global train loss: 1.022, Global test loss: 0.826, Global test accuracy: 72.92
Round  28, Train loss: 0.995, Test loss: 1.131, Test accuracy: 63.82
Round  28, Global train loss: 0.995, Global test loss: 0.822, Global test accuracy: 73.14
Round  29, Train loss: 1.026, Test loss: 1.142, Test accuracy: 63.59
Round  29, Global train loss: 1.026, Global test loss: 0.842, Global test accuracy: 73.04
Round  30, Train loss: 1.024, Test loss: 1.136, Test accuracy: 63.91
Round  30, Global train loss: 1.024, Global test loss: 0.850, Global test accuracy: 72.29
Round  31, Train loss: 1.000, Test loss: 1.132, Test accuracy: 63.92
Round  31, Global train loss: 1.000, Global test loss: 0.847, Global test accuracy: 72.81
Round  32, Train loss: 0.969, Test loss: 1.123, Test accuracy: 64.32
Round  32, Global train loss: 0.969, Global test loss: 0.820, Global test accuracy: 73.26
Round  33, Train loss: 0.972, Test loss: 1.118, Test accuracy: 64.44
Round  33, Global train loss: 0.972, Global test loss: 0.848, Global test accuracy: 72.25
Round  34, Train loss: 0.959, Test loss: 1.115, Test accuracy: 64.35
Round  34, Global train loss: 0.959, Global test loss: 0.810, Global test accuracy: 73.44
Round  35, Train loss: 0.947, Test loss: 1.116, Test accuracy: 64.70
Round  35, Global train loss: 0.947, Global test loss: 0.836, Global test accuracy: 72.90
Round  36, Train loss: 0.950, Test loss: 1.132, Test accuracy: 64.30
Round  36, Global train loss: 0.950, Global test loss: 0.827, Global test accuracy: 73.14
Round  37, Train loss: 0.959, Test loss: 1.139, Test accuracy: 64.08
Round  37, Global train loss: 0.959, Global test loss: 0.836, Global test accuracy: 72.98
Round  38, Train loss: 0.965, Test loss: 1.119, Test accuracy: 64.75
Round  38, Global train loss: 0.965, Global test loss: 0.814, Global test accuracy: 74.13
Round  39, Train loss: 0.959, Test loss: 1.124, Test accuracy: 64.52
Round  39, Global train loss: 0.959, Global test loss: 0.846, Global test accuracy: 72.88
Round  40, Train loss: 0.916, Test loss: 1.125, Test accuracy: 64.64
Round  40, Global train loss: 0.916, Global test loss: 0.823, Global test accuracy: 73.26
Round  41, Train loss: 0.915, Test loss: 1.131, Test accuracy: 64.41
Round  41, Global train loss: 0.915, Global test loss: 0.818, Global test accuracy: 73.76
Round  42, Train loss: 0.864, Test loss: 1.130, Test accuracy: 64.61
Round  42, Global train loss: 0.864, Global test loss: 0.814, Global test accuracy: 73.62
Round  43, Train loss: 0.842, Test loss: 1.137, Test accuracy: 64.62
Round  43, Global train loss: 0.842, Global test loss: 0.825, Global test accuracy: 73.64
Round  44, Train loss: 0.942, Test loss: 1.129, Test accuracy: 65.06
Round  44, Global train loss: 0.942, Global test loss: 0.833, Global test accuracy: 73.27
Round  45, Train loss: 0.937, Test loss: 1.138, Test accuracy: 64.81
Round  45, Global train loss: 0.937, Global test loss: 0.842, Global test accuracy: 73.25
Round  46, Train loss: 0.868, Test loss: 1.130, Test accuracy: 65.16
Round  46, Global train loss: 0.868, Global test loss: 0.814, Global test accuracy: 73.28
Round  47, Train loss: 0.842, Test loss: 1.116, Test accuracy: 65.33
Round  47, Global train loss: 0.842, Global test loss: 0.803, Global test accuracy: 74.26
Round  48, Train loss: 0.864, Test loss: 1.119, Test accuracy: 65.30
Round  48, Global train loss: 0.864, Global test loss: 0.812, Global test accuracy: 74.06
Round  49, Train loss: 0.871, Test loss: 1.136, Test accuracy: 64.78
Round  49, Global train loss: 0.871, Global test loss: 0.825, Global test accuracy: 73.56
Round  50, Train loss: 0.865, Test loss: 1.141, Test accuracy: 64.82
Round  50, Global train loss: 0.865, Global test loss: 0.827, Global test accuracy: 73.30
Round  51, Train loss: 0.910, Test loss: 1.133, Test accuracy: 64.84
Round  51, Global train loss: 0.910, Global test loss: 0.817, Global test accuracy: 73.95
Round  52, Train loss: 0.902, Test loss: 1.138, Test accuracy: 64.69
Round  52, Global train loss: 0.902, Global test loss: 0.836, Global test accuracy: 73.88
Round  53, Train loss: 0.797, Test loss: 1.130, Test accuracy: 65.11
Round  53, Global train loss: 0.797, Global test loss: 0.793, Global test accuracy: 74.64
Round  54, Train loss: 0.847, Test loss: 1.127, Test accuracy: 65.35
Round  54, Global train loss: 0.847, Global test loss: 0.800, Global test accuracy: 74.44
Round  55, Train loss: 0.830, Test loss: 1.136, Test accuracy: 65.17
Round  55, Global train loss: 0.830, Global test loss: 0.817, Global test accuracy: 73.99
Round  56, Train loss: 0.901, Test loss: 1.139, Test accuracy: 65.39
Round  56, Global train loss: 0.901, Global test loss: 0.855, Global test accuracy: 73.50
Round  57, Train loss: 0.842, Test loss: 1.148, Test accuracy: 65.11
Round  57, Global train loss: 0.842, Global test loss: 0.819, Global test accuracy: 73.68
Round  58, Train loss: 0.801, Test loss: 1.158, Test accuracy: 65.08
Round  58, Global train loss: 0.801, Global test loss: 0.818, Global test accuracy: 73.99
Round  59, Train loss: 0.840, Test loss: 1.145, Test accuracy: 65.49
Round  59, Global train loss: 0.840, Global test loss: 0.832, Global test accuracy: 73.96
Round  60, Train loss: 0.826, Test loss: 1.150, Test accuracy: 65.38
Round  60, Global train loss: 0.826, Global test loss: 0.836, Global test accuracy: 73.78
Round  61, Train loss: 0.835, Test loss: 1.148, Test accuracy: 65.44
Round  61, Global train loss: 0.835, Global test loss: 0.839, Global test accuracy: 73.23
Round  62, Train loss: 0.790, Test loss: 1.167, Test accuracy: 64.71
Round  62, Global train loss: 0.790, Global test loss: 0.831, Global test accuracy: 73.58
Round  63, Train loss: 0.764, Test loss: 1.155, Test accuracy: 65.02
Round  63, Global train loss: 0.764, Global test loss: 0.798, Global test accuracy: 74.65
Round  64, Train loss: 0.810, Test loss: 1.146, Test accuracy: 65.06
Round  64, Global train loss: 0.810, Global test loss: 0.793, Global test accuracy: 74.59
Round  65, Train loss: 0.774, Test loss: 1.159, Test accuracy: 64.92
Round  65, Global train loss: 0.774, Global test loss: 0.816, Global test accuracy: 73.97
Round  66, Train loss: 0.834, Test loss: 1.155, Test accuracy: 65.27
Round  66, Global train loss: 0.834, Global test loss: 0.807, Global test accuracy: 74.47
Round  67, Train loss: 0.807, Test loss: 1.155, Test accuracy: 65.46
Round  67, Global train loss: 0.807, Global test loss: 0.816, Global test accuracy: 74.55
Round  68, Train loss: 0.776, Test loss: 1.148, Test accuracy: 65.82
Round  68, Global train loss: 0.776, Global test loss: 0.823, Global test accuracy: 74.26
Round  69, Train loss: 0.777, Test loss: 1.156, Test accuracy: 65.58
Round  69, Global train loss: 0.777, Global test loss: 0.794, Global test accuracy: 74.85
Round  70, Train loss: 0.808, Test loss: 1.160, Test accuracy: 65.54
Round  70, Global train loss: 0.808, Global test loss: 0.835, Global test accuracy: 73.89
Round  71, Train loss: 0.846, Test loss: 1.153, Test accuracy: 65.35
Round  71, Global train loss: 0.846, Global test loss: 0.852, Global test accuracy: 73.12
Round  72, Train loss: 0.756, Test loss: 1.171, Test accuracy: 65.43
Round  72, Global train loss: 0.756, Global test loss: 0.820, Global test accuracy: 74.44
Round  73, Train loss: 0.767, Test loss: 1.175, Test accuracy: 65.29
Round  73, Global train loss: 0.767, Global test loss: 0.831, Global test accuracy: 73.88
Round  74, Train loss: 0.730, Test loss: 1.175, Test accuracy: 65.59
Round  74, Global train loss: 0.730, Global test loss: 0.808, Global test accuracy: 74.49
Round  75, Train loss: 0.792, Test loss: 1.178, Test accuracy: 65.42
Round  75, Global train loss: 0.792, Global test loss: 0.810, Global test accuracy: 74.59
Round  76, Train loss: 0.747, Test loss: 1.171, Test accuracy: 65.55
Round  76, Global train loss: 0.747, Global test loss: 0.843, Global test accuracy: 73.32
Round  77, Train loss: 0.717, Test loss: 1.171, Test accuracy: 65.30
Round  77, Global train loss: 0.717, Global test loss: 0.848, Global test accuracy: 73.69
Round  78, Train loss: 0.735, Test loss: 1.186, Test accuracy: 65.31
Round  78, Global train loss: 0.735, Global test loss: 0.826, Global test accuracy: 73.98
Round  79, Train loss: 0.727, Test loss: 1.187, Test accuracy: 65.28
Round  79, Global train loss: 0.727, Global test loss: 0.805, Global test accuracy: 74.16
Round  80, Train loss: 0.720, Test loss: 1.185, Test accuracy: 65.44
Round  80, Global train loss: 0.720, Global test loss: 0.816, Global test accuracy: 74.24
Round  81, Train loss: 0.746, Test loss: 1.189, Test accuracy: 65.22
Round  81, Global train loss: 0.746, Global test loss: 0.822, Global test accuracy: 74.31
Round  82, Train loss: 0.764, Test loss: 1.188, Test accuracy: 65.30
Round  82, Global train loss: 0.764, Global test loss: 0.803, Global test accuracy: 74.77
Round  83, Train loss: 0.743, Test loss: 1.185, Test accuracy: 65.44
Round  83, Global train loss: 0.743, Global test loss: 0.813, Global test accuracy: 74.77
Round  84, Train loss: 0.743, Test loss: 1.188, Test accuracy: 65.42
Round  84, Global train loss: 0.743, Global test loss: 0.826, Global test accuracy: 74.37
Round  85, Train loss: 0.773, Test loss: 1.181, Test accuracy: 65.72
Round  85, Global train loss: 0.773, Global test loss: 0.839, Global test accuracy: 73.61
Round  86, Train loss: 0.700, Test loss: 1.183, Test accuracy: 65.58
Round  86, Global train loss: 0.700, Global test loss: 0.802, Global test accuracy: 75.03
Round  87, Train loss: 0.684, Test loss: 1.184, Test accuracy: 65.76
Round  87, Global train loss: 0.684, Global test loss: 0.804, Global test accuracy: 74.99
Round  88, Train loss: 0.713, Test loss: 1.166, Test accuracy: 66.06
Round  88, Global train loss: 0.713, Global test loss: 0.826, Global test accuracy: 74.44
Round  89, Train loss: 0.730, Test loss: 1.162, Test accuracy: 66.48
Round  89, Global train loss: 0.730, Global test loss: 0.808, Global test accuracy: 74.86
Round  90, Train loss: 0.711, Test loss: 1.163, Test accuracy: 66.15
Round  90, Global train loss: 0.711, Global test loss: 0.842, Global test accuracy: 74.16
Round  91, Train loss: 0.784, Test loss: 1.166, Test accuracy: 66.25
Round  91, Global train loss: 0.784, Global test loss: 0.858, Global test accuracy: 74.31
Round  92, Train loss: 0.798, Test loss: 1.171, Test accuracy: 66.32
Round  92, Global train loss: 0.798, Global test loss: 0.892, Global test accuracy: 72.84
Round  93, Train loss: 0.745, Test loss: 1.182, Test accuracy: 66.12
Round  93, Global train loss: 0.745, Global test loss: 0.841, Global test accuracy: 74.09
Round  94, Train loss: 0.726, Test loss: 1.194, Test accuracy: 65.78
Round  94, Global train loss: 0.726, Global test loss: 0.849, Global test accuracy: 74.56
Round  95, Train loss: 0.744, Test loss: 1.193, Test accuracy: 65.78
Round  95, Global train loss: 0.744, Global test loss: 0.821, Global test accuracy: 74.58
Round  96, Train loss: 0.781, Test loss: 1.192, Test accuracy: 65.75
Round  96, Global train loss: 0.781, Global test loss: 0.869, Global test accuracy: 73.07
Round  97, Train loss: 0.705, Test loss: 1.199, Test accuracy: 65.58
Round  97, Global train loss: 0.705, Global test loss: 0.838, Global test accuracy: 74.00
Round  98, Train loss: 0.678, Test loss: 1.189, Test accuracy: 65.93
Round  98, Global train loss: 0.678, Global test loss: 0.839, Global test accuracy: 73.94
Round  99, Train loss: 0.703, Test loss: 1.207, Test accuracy: 65.77
Round  99, Global train loss: 0.703, Global test loss: 0.846, Global test accuracy: 73.64
Final Round, Train loss: 0.464, Test loss: 1.373, Test accuracy: 65.36
Final Round, Global train loss: 0.464, Global test loss: 0.846, Global test accuracy: 73.64
Average accuracy final 10 rounds: 65.9445 

Average global accuracy final 10 rounds: 73.91825 

6064.633849143982
[5.10580039024353, 10.21160078048706, 14.806670427322388, 19.401740074157715, 24.22104001045227, 29.040339946746826, 33.890175104141235, 38.740010261535645, 43.3950629234314, 48.05011558532715, 52.70633363723755, 57.36255168914795, 62.167503356933594, 66.97245502471924, 71.62340688705444, 76.27435874938965, 80.94350552558899, 85.61265230178833, 90.39059090614319, 95.16852951049805, 99.76295280456543, 104.35737609863281, 108.60552310943604, 112.85367012023926, 117.08577060699463, 121.31787109375, 125.53801274299622, 129.75815439224243, 133.9707956314087, 138.18343687057495, 142.46149063110352, 146.73954439163208, 151.0102014541626, 155.28085851669312, 159.56626319885254, 163.85166788101196, 168.11452865600586, 172.37738943099976, 176.63885498046875, 180.90032052993774, 185.10092568397522, 189.3015308380127, 193.6365385055542, 197.9715461730957, 202.23256039619446, 206.4935746192932, 210.725159406662, 214.95674419403076, 219.22946858406067, 223.50219297409058, 227.70559549331665, 231.90899801254272, 236.12360167503357, 240.3382053375244, 244.59818053245544, 248.85815572738647, 253.1557981967926, 257.45344066619873, 261.647057056427, 265.8406734466553, 270.04083585739136, 274.24099826812744, 278.46857380867004, 282.69614934921265, 286.9827997684479, 291.2694501876831, 295.54386615753174, 299.81828212738037, 304.0846815109253, 308.3510808944702, 312.6062035560608, 316.86132621765137, 321.53380966186523, 326.2062931060791, 330.9728021621704, 335.7393112182617, 340.4085581302643, 345.07780504226685, 349.75776529312134, 354.43772554397583, 358.7006266117096, 362.96352767944336, 367.28925251960754, 371.61497735977173, 375.92103004455566, 380.2270827293396, 384.54191184043884, 388.8567409515381, 393.1823716163635, 397.50800228118896, 401.7941212654114, 406.0802402496338, 410.4380238056183, 414.7958073616028, 419.0769131183624, 423.35801887512207, 427.6965057849884, 432.03499269485474, 436.3874523639679, 440.73991203308105, 445.0561797618866, 449.37244749069214, 453.6289870738983, 457.8855266571045, 462.2530059814453, 466.62048530578613, 470.95658588409424, 475.29268646240234, 479.63891649246216, 483.985146522522, 488.3193144798279, 492.6534824371338, 496.95225501060486, 501.2510275840759, 505.49522948265076, 509.7394313812256, 513.9894905090332, 518.2395496368408, 522.6122634410858, 526.9849772453308, 531.26234126091, 535.5397052764893, 539.8553156852722, 544.1709260940552, 548.4784064292908, 552.7858867645264, 557.0828647613525, 561.3798427581787, 565.5871036052704, 569.7943644523621, 574.1347959041595, 578.475227355957, 582.8791432380676, 587.2830591201782, 591.672310590744, 596.0615620613098, 600.4489634037018, 604.8363647460938, 609.2099494934082, 613.5835342407227, 618.0358173847198, 622.488100528717, 626.8314442634583, 631.1747879981995, 635.6267104148865, 640.0786328315735, 644.486927986145, 648.8952231407166, 653.2798149585724, 657.6644067764282, 662.0224223136902, 666.3804378509521, 670.7559607028961, 675.1314835548401, 679.3327307701111, 683.5339779853821, 687.9469568729401, 692.359935760498, 696.6646680831909, 700.9694004058838, 705.6794140338898, 710.3894276618958, 715.2854354381561, 720.1814432144165, 724.871823310852, 729.5622034072876, 733.8563039302826, 738.1504044532776, 742.4444921016693, 746.738579750061, 750.9984962940216, 755.2584128379822, 759.5383675098419, 763.8183221817017, 768.0644505023956, 772.3105788230896, 776.6009030342102, 780.8912272453308, 785.1769952774048, 789.4627633094788, 793.7762727737427, 798.0897822380066, 802.4214344024658, 806.753086566925, 811.0257077217102, 815.2983288764954, 819.606782913208, 823.9152369499207, 828.1997964382172, 832.4843559265137, 836.7057602405548, 840.927164554596, 845.2227349281311, 849.5183053016663, 853.8671724796295, 858.2160396575928, 862.5365514755249, 866.857063293457, 871.1371912956238, 875.4173192977905, 877.5692241191864, 879.7211289405823]
[33.1675, 33.1675, 39.6025, 39.6025, 42.1125, 42.1125, 42.265, 42.265, 43.9325, 43.9325, 45.935, 45.935, 47.585, 47.585, 50.115, 50.115, 52.2175, 52.2175, 52.8775, 52.8775, 54.58, 54.58, 55.0175, 55.0175, 55.61, 55.61, 57.14, 57.14, 58.365, 58.365, 59.0375, 59.0375, 59.2, 59.2, 59.345, 59.345, 60.315, 60.315, 61.005, 61.005, 61.3425, 61.3425, 61.3325, 61.3325, 61.3125, 61.3125, 61.585, 61.585, 61.605, 61.605, 61.73, 61.73, 62.4175, 62.4175, 63.4, 63.4, 63.8175, 63.8175, 63.595, 63.595, 63.9125, 63.9125, 63.925, 63.925, 64.3175, 64.3175, 64.4375, 64.4375, 64.35, 64.35, 64.7, 64.7, 64.2975, 64.2975, 64.08, 64.08, 64.7475, 64.7475, 64.52, 64.52, 64.635, 64.635, 64.41, 64.41, 64.605, 64.605, 64.625, 64.625, 65.055, 65.055, 64.815, 64.815, 65.1575, 65.1575, 65.335, 65.335, 65.2975, 65.2975, 64.7825, 64.7825, 64.8225, 64.8225, 64.84, 64.84, 64.685, 64.685, 65.105, 65.105, 65.35, 65.35, 65.175, 65.175, 65.3925, 65.3925, 65.1075, 65.1075, 65.075, 65.075, 65.49, 65.49, 65.3775, 65.3775, 65.4375, 65.4375, 64.71, 64.71, 65.0225, 65.0225, 65.0625, 65.0625, 64.92, 64.92, 65.2675, 65.2675, 65.4575, 65.4575, 65.82, 65.82, 65.5825, 65.5825, 65.5375, 65.5375, 65.35, 65.35, 65.4275, 65.4275, 65.2925, 65.2925, 65.59, 65.59, 65.42, 65.42, 65.55, 65.55, 65.3025, 65.3025, 65.31, 65.31, 65.275, 65.275, 65.4425, 65.4425, 65.215, 65.215, 65.3, 65.3, 65.435, 65.435, 65.42, 65.42, 65.725, 65.725, 65.58, 65.58, 65.7575, 65.7575, 66.065, 66.065, 66.4775, 66.4775, 66.1525, 66.1525, 66.2475, 66.2475, 66.32, 66.32, 66.1225, 66.1225, 65.7825, 65.7825, 65.7825, 65.7825, 65.75, 65.75, 65.585, 65.585, 65.9325, 65.9325, 65.77, 65.77, 65.355, 65.355]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.6 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
Client 1, noise level: 0.2179 (0.1961), real noise ratio: 0.2030
Client 5, noise level: 0.0651 (0.0586), real noise ratio: 0.0735
Client 10, noise level: 0.8128 (0.7316), real noise ratio: 0.7340
Client 11, noise level: 0.0757 (0.0681), real noise ratio: 0.0695
Client 12, noise level: 0.6565 (0.5908), real noise ratio: 0.6505
Client 14, noise level: 0.4799 (0.4319), real noise ratio: 0.4295
Client 16, noise level: 0.0000 (0.0000), real noise ratio: 0.0695
Client 17, noise level: 0.2470 (0.2223), real noise ratio: 0.2925
Client 18, noise level: 0.7122 (0.6410), real noise ratio: 0.6640
Client 19, noise level: 0.3246 (0.2921), real noise ratio: 0.3145
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.114, Test loss: 1.987, Test accuracy: 30.57
Round   0, Global train loss: 2.114, Global test loss: 1.986, Global test accuracy: 31.86
Round   1, Train loss: 1.934, Test loss: 1.816, Test accuracy: 34.51
Round   1, Global train loss: 1.934, Global test loss: 1.736, Global test accuracy: 38.03
Round   2, Train loss: 1.829, Test loss: 1.760, Test accuracy: 36.11
Round   2, Global train loss: 1.829, Global test loss: 1.629, Global test accuracy: 40.29
Round   3, Train loss: 1.772, Test loss: 1.727, Test accuracy: 37.93
Round   3, Global train loss: 1.772, Global test loss: 1.532, Global test accuracy: 46.28
Round   4, Train loss: 1.722, Test loss: 1.710, Test accuracy: 38.65
Round   4, Global train loss: 1.722, Global test loss: 1.470, Global test accuracy: 49.26
Round   5, Train loss: 1.676, Test loss: 1.659, Test accuracy: 40.34
Round   5, Global train loss: 1.676, Global test loss: 1.454, Global test accuracy: 50.36
Round   6, Train loss: 1.635, Test loss: 1.635, Test accuracy: 41.70
Round   6, Global train loss: 1.635, Global test loss: 1.384, Global test accuracy: 52.73
Round   7, Train loss: 1.600, Test loss: 1.582, Test accuracy: 43.79
Round   7, Global train loss: 1.600, Global test loss: 1.359, Global test accuracy: 54.67
Round   8, Train loss: 1.633, Test loss: 1.540, Test accuracy: 45.55
Round   8, Global train loss: 1.633, Global test loss: 1.354, Global test accuracy: 55.35
Round   9, Train loss: 1.558, Test loss: 1.528, Test accuracy: 45.87
Round   9, Global train loss: 1.558, Global test loss: 1.270, Global test accuracy: 57.10
Round  10, Train loss: 1.561, Test loss: 1.488, Test accuracy: 47.66
Round  10, Global train loss: 1.561, Global test loss: 1.295, Global test accuracy: 57.00
Round  11, Train loss: 1.498, Test loss: 1.463, Test accuracy: 48.51
Round  11, Global train loss: 1.498, Global test loss: 1.210, Global test accuracy: 59.71
Round  12, Train loss: 1.494, Test loss: 1.430, Test accuracy: 49.96
Round  12, Global train loss: 1.494, Global test loss: 1.195, Global test accuracy: 60.50
Round  13, Train loss: 1.453, Test loss: 1.405, Test accuracy: 51.11
Round  13, Global train loss: 1.453, Global test loss: 1.178, Global test accuracy: 60.98
Round  14, Train loss: 1.405, Test loss: 1.369, Test accuracy: 52.74
Round  14, Global train loss: 1.405, Global test loss: 1.178, Global test accuracy: 60.10
Round  15, Train loss: 1.423, Test loss: 1.356, Test accuracy: 53.57
Round  15, Global train loss: 1.423, Global test loss: 1.153, Global test accuracy: 62.56
Round  16, Train loss: 1.393, Test loss: 1.352, Test accuracy: 53.74
Round  16, Global train loss: 1.393, Global test loss: 1.150, Global test accuracy: 61.65
Round  17, Train loss: 1.408, Test loss: 1.331, Test accuracy: 54.45
Round  17, Global train loss: 1.408, Global test loss: 1.125, Global test accuracy: 62.60
Round  18, Train loss: 1.382, Test loss: 1.297, Test accuracy: 55.79
Round  18, Global train loss: 1.382, Global test loss: 1.118, Global test accuracy: 63.38
Round  19, Train loss: 1.349, Test loss: 1.293, Test accuracy: 56.09
Round  19, Global train loss: 1.349, Global test loss: 1.092, Global test accuracy: 64.97
Round  20, Train loss: 1.312, Test loss: 1.290, Test accuracy: 56.47
Round  20, Global train loss: 1.312, Global test loss: 1.074, Global test accuracy: 64.58
Round  21, Train loss: 1.330, Test loss: 1.277, Test accuracy: 57.03
Round  21, Global train loss: 1.330, Global test loss: 1.102, Global test accuracy: 63.84
Round  22, Train loss: 1.319, Test loss: 1.273, Test accuracy: 56.96
Round  22, Global train loss: 1.319, Global test loss: 1.065, Global test accuracy: 64.72
Round  23, Train loss: 1.276, Test loss: 1.265, Test accuracy: 57.34
Round  23, Global train loss: 1.276, Global test loss: 1.065, Global test accuracy: 65.39
Round  24, Train loss: 1.290, Test loss: 1.262, Test accuracy: 57.10
Round  24, Global train loss: 1.290, Global test loss: 1.049, Global test accuracy: 65.68
Round  25, Train loss: 1.260, Test loss: 1.245, Test accuracy: 57.87
Round  25, Global train loss: 1.260, Global test loss: 1.054, Global test accuracy: 65.81
Round  26, Train loss: 1.228, Test loss: 1.236, Test accuracy: 58.25
Round  26, Global train loss: 1.228, Global test loss: 1.012, Global test accuracy: 66.64
Round  27, Train loss: 1.301, Test loss: 1.214, Test accuracy: 59.21
Round  27, Global train loss: 1.301, Global test loss: 1.016, Global test accuracy: 67.64
Round  28, Train loss: 1.199, Test loss: 1.212, Test accuracy: 59.25
Round  28, Global train loss: 1.199, Global test loss: 0.985, Global test accuracy: 67.64
Round  29, Train loss: 1.214, Test loss: 1.192, Test accuracy: 59.93
Round  29, Global train loss: 1.214, Global test loss: 0.960, Global test accuracy: 68.66
Round  30, Train loss: 1.210, Test loss: 1.190, Test accuracy: 59.89
Round  30, Global train loss: 1.210, Global test loss: 0.963, Global test accuracy: 68.44
Round  31, Train loss: 1.185, Test loss: 1.175, Test accuracy: 60.67
Round  31, Global train loss: 1.185, Global test loss: 0.994, Global test accuracy: 67.63
Round  32, Train loss: 1.199, Test loss: 1.164, Test accuracy: 61.23
Round  32, Global train loss: 1.199, Global test loss: 0.971, Global test accuracy: 68.91
Round  33, Train loss: 1.164, Test loss: 1.161, Test accuracy: 61.37
Round  33, Global train loss: 1.164, Global test loss: 0.952, Global test accuracy: 68.80
Round  34, Train loss: 1.170, Test loss: 1.157, Test accuracy: 61.49
Round  34, Global train loss: 1.170, Global test loss: 0.944, Global test accuracy: 69.34
Round  35, Train loss: 1.198, Test loss: 1.148, Test accuracy: 61.92
Round  35, Global train loss: 1.198, Global test loss: 0.938, Global test accuracy: 69.45
Round  36, Train loss: 1.144, Test loss: 1.141, Test accuracy: 62.02
Round  36, Global train loss: 1.144, Global test loss: 0.932, Global test accuracy: 69.71
Round  37, Train loss: 1.196, Test loss: 1.131, Test accuracy: 62.28
Round  37, Global train loss: 1.196, Global test loss: 0.926, Global test accuracy: 69.64
Round  38, Train loss: 1.151, Test loss: 1.129, Test accuracy: 62.42
Round  38, Global train loss: 1.151, Global test loss: 0.928, Global test accuracy: 70.00
Round  39, Train loss: 1.132, Test loss: 1.122, Test accuracy: 62.65
Round  39, Global train loss: 1.132, Global test loss: 0.933, Global test accuracy: 69.52
Round  40, Train loss: 1.085, Test loss: 1.115, Test accuracy: 62.95
Round  40, Global train loss: 1.085, Global test loss: 0.891, Global test accuracy: 70.36
Round  41, Train loss: 1.054, Test loss: 1.121, Test accuracy: 62.73
Round  41, Global train loss: 1.054, Global test loss: 0.894, Global test accuracy: 71.01
Round  42, Train loss: 1.053, Test loss: 1.119, Test accuracy: 63.09
Round  42, Global train loss: 1.053, Global test loss: 0.894, Global test accuracy: 70.69
Round  43, Train loss: 1.070, Test loss: 1.113, Test accuracy: 63.38
Round  43, Global train loss: 1.070, Global test loss: 0.917, Global test accuracy: 70.15
Round  44, Train loss: 1.140, Test loss: 1.115, Test accuracy: 63.21
Round  44, Global train loss: 1.140, Global test loss: 0.944, Global test accuracy: 70.85
Round  45, Train loss: 1.119, Test loss: 1.119, Test accuracy: 62.87
Round  45, Global train loss: 1.119, Global test loss: 0.891, Global test accuracy: 71.60
Round  46, Train loss: 1.057, Test loss: 1.102, Test accuracy: 63.57
Round  46, Global train loss: 1.057, Global test loss: 0.883, Global test accuracy: 71.91
Round  47, Train loss: 1.030, Test loss: 1.092, Test accuracy: 63.95
Round  47, Global train loss: 1.030, Global test loss: 0.858, Global test accuracy: 72.17
Round  48, Train loss: 1.019, Test loss: 1.093, Test accuracy: 63.83
Round  48, Global train loss: 1.019, Global test loss: 0.861, Global test accuracy: 71.90
Round  49, Train loss: 0.986, Test loss: 1.097, Test accuracy: 63.73
Round  49, Global train loss: 0.986, Global test loss: 0.869, Global test accuracy: 71.10
Round  50, Train loss: 1.071, Test loss: 1.090, Test accuracy: 64.14
Round  50, Global train loss: 1.071, Global test loss: 0.867, Global test accuracy: 71.01
Round  51, Train loss: 1.020, Test loss: 1.086, Test accuracy: 64.33
Round  51, Global train loss: 1.020, Global test loss: 0.909, Global test accuracy: 71.30
Round  52, Train loss: 1.049, Test loss: 1.091, Test accuracy: 64.21
Round  52, Global train loss: 1.049, Global test loss: 0.848, Global test accuracy: 72.67
Round  53, Train loss: 1.058, Test loss: 1.098, Test accuracy: 63.92
Round  53, Global train loss: 1.058, Global test loss: 0.866, Global test accuracy: 72.06
Round  54, Train loss: 1.023, Test loss: 1.077, Test accuracy: 64.81
Round  54, Global train loss: 1.023, Global test loss: 0.847, Global test accuracy: 72.20
Round  55, Train loss: 0.974, Test loss: 1.080, Test accuracy: 64.70
Round  55, Global train loss: 0.974, Global test loss: 0.827, Global test accuracy: 72.18
Round  56, Train loss: 1.090, Test loss: 1.080, Test accuracy: 64.71
Round  56, Global train loss: 1.090, Global test loss: 0.876, Global test accuracy: 72.03
Round  57, Train loss: 0.954, Test loss: 1.074, Test accuracy: 64.90
Round  57, Global train loss: 0.954, Global test loss: 0.884, Global test accuracy: 71.22
Round  58, Train loss: 0.909, Test loss: 1.064, Test accuracy: 65.18
Round  58, Global train loss: 0.909, Global test loss: 0.840, Global test accuracy: 72.65
Round  59, Train loss: 0.992, Test loss: 1.075, Test accuracy: 64.86
Round  59, Global train loss: 0.992, Global test loss: 0.871, Global test accuracy: 71.69
Round  60, Train loss: 1.010, Test loss: 1.073, Test accuracy: 64.81
Round  60, Global train loss: 1.010, Global test loss: 0.850, Global test accuracy: 72.84
Round  61, Train loss: 0.991, Test loss: 1.059, Test accuracy: 65.16
Round  61, Global train loss: 0.991, Global test loss: 0.835, Global test accuracy: 72.84
Round  62, Train loss: 0.981, Test loss: 1.068, Test accuracy: 64.96
Round  62, Global train loss: 0.981, Global test loss: 0.851, Global test accuracy: 72.05
Round  63, Train loss: 0.937, Test loss: 1.056, Test accuracy: 65.31
Round  63, Global train loss: 0.937, Global test loss: 0.837, Global test accuracy: 72.07
Round  64, Train loss: 0.952, Test loss: 1.076, Test accuracy: 64.63
Round  64, Global train loss: 0.952, Global test loss: 0.834, Global test accuracy: 72.40
Round  65, Train loss: 0.992, Test loss: 1.076, Test accuracy: 64.74
Round  65, Global train loss: 0.992, Global test loss: 0.880, Global test accuracy: 71.19
Round  66, Train loss: 1.010, Test loss: 1.086, Test accuracy: 64.53
Round  66, Global train loss: 1.010, Global test loss: 0.854, Global test accuracy: 72.28
Round  67, Train loss: 0.942, Test loss: 1.080, Test accuracy: 64.80
Round  67, Global train loss: 0.942, Global test loss: 0.832, Global test accuracy: 73.13
Round  68, Train loss: 0.933, Test loss: 1.085, Test accuracy: 64.67
Round  68, Global train loss: 0.933, Global test loss: 0.840, Global test accuracy: 72.69
Round  69, Train loss: 0.965, Test loss: 1.072, Test accuracy: 65.19
Round  69, Global train loss: 0.965, Global test loss: 0.824, Global test accuracy: 72.82
Round  70, Train loss: 0.973, Test loss: 1.064, Test accuracy: 65.38
Round  70, Global train loss: 0.973, Global test loss: 0.820, Global test accuracy: 73.52
Round  71, Train loss: 0.963, Test loss: 1.048, Test accuracy: 65.93
Round  71, Global train loss: 0.963, Global test loss: 0.843, Global test accuracy: 72.23
Round  72, Train loss: 0.966, Test loss: 1.057, Test accuracy: 65.54
Round  72, Global train loss: 0.966, Global test loss: 0.839, Global test accuracy: 72.59
Round  73, Train loss: 1.012, Test loss: 1.052, Test accuracy: 65.75
Round  73, Global train loss: 1.012, Global test loss: 0.833, Global test accuracy: 72.87
Round  74, Train loss: 0.876, Test loss: 1.054, Test accuracy: 65.91
Round  74, Global train loss: 0.876, Global test loss: 0.814, Global test accuracy: 73.28
Round  75, Train loss: 0.959, Test loss: 1.049, Test accuracy: 66.25
Round  75, Global train loss: 0.959, Global test loss: 0.904, Global test accuracy: 70.65
Round  76, Train loss: 0.863, Test loss: 1.059, Test accuracy: 65.90
Round  76, Global train loss: 0.863, Global test loss: 0.827, Global test accuracy: 73.13
Round  77, Train loss: 0.875, Test loss: 1.061, Test accuracy: 65.74
Round  77, Global train loss: 0.875, Global test loss: 0.826, Global test accuracy: 73.02
Round  78, Train loss: 0.893, Test loss: 1.061, Test accuracy: 65.78
Round  78, Global train loss: 0.893, Global test loss: 0.810, Global test accuracy: 73.16
Round  79, Train loss: 1.010, Test loss: 1.061, Test accuracy: 66.02
Round  79, Global train loss: 1.010, Global test loss: 0.827, Global test accuracy: 73.30
Round  80, Train loss: 0.910, Test loss: 1.074, Test accuracy: 65.88
Round  80, Global train loss: 0.910, Global test loss: 0.858, Global test accuracy: 72.35
Round  81, Train loss: 0.883, Test loss: 1.066, Test accuracy: 65.81
Round  81, Global train loss: 0.883, Global test loss: 0.864, Global test accuracy: 72.60
Round  82, Train loss: 0.944, Test loss: 1.061, Test accuracy: 65.80
Round  82, Global train loss: 0.944, Global test loss: 0.819, Global test accuracy: 73.67
Round  83, Train loss: 0.871, Test loss: 1.070, Test accuracy: 65.66
Round  83, Global train loss: 0.871, Global test loss: 0.810, Global test accuracy: 73.03
Round  84, Train loss: 0.910, Test loss: 1.053, Test accuracy: 66.11
Round  84, Global train loss: 0.910, Global test loss: 0.794, Global test accuracy: 74.02
Round  85, Train loss: 0.987, Test loss: 1.042, Test accuracy: 66.38
Round  85, Global train loss: 0.987, Global test loss: 0.818, Global test accuracy: 73.79
Round  86, Train loss: 0.896, Test loss: 1.037, Test accuracy: 66.60
Round  86, Global train loss: 0.896, Global test loss: 0.808, Global test accuracy: 73.85
Round  87, Train loss: 0.817, Test loss: 1.033, Test accuracy: 66.85
Round  87, Global train loss: 0.817, Global test loss: 0.811, Global test accuracy: 73.78
Round  88, Train loss: 0.853, Test loss: 1.042, Test accuracy: 66.44
Round  88, Global train loss: 0.853, Global test loss: 0.807, Global test accuracy: 73.07
Round  89, Train loss: 0.897, Test loss: 1.048, Test accuracy: 66.62
Round  89, Global train loss: 0.897, Global test loss: 0.803, Global test accuracy: 73.84
Round  90, Train loss: 0.857, Test loss: 1.051, Test accuracy: 66.40
Round  90, Global train loss: 0.857, Global test loss: 0.841, Global test accuracy: 72.58
Round  91, Train loss: 0.950, Test loss: 1.049, Test accuracy: 66.60
Round  91, Global train loss: 0.950, Global test loss: 0.837, Global test accuracy: 73.10/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  92, Train loss: 0.825, Test loss: 1.053, Test accuracy: 66.39
Round  92, Global train loss: 0.825, Global test loss: 0.806, Global test accuracy: 73.98
Round  93, Train loss: 0.905, Test loss: 1.046, Test accuracy: 66.81
Round  93, Global train loss: 0.905, Global test loss: 0.822, Global test accuracy: 73.56
Round  94, Train loss: 0.820, Test loss: 1.065, Test accuracy: 66.23
Round  94, Global train loss: 0.820, Global test loss: 0.828, Global test accuracy: 73.44
Round  95, Train loss: 0.869, Test loss: 1.078, Test accuracy: 66.03
Round  95, Global train loss: 0.869, Global test loss: 0.802, Global test accuracy: 73.50
Round  96, Train loss: 0.812, Test loss: 1.064, Test accuracy: 66.43
Round  96, Global train loss: 0.812, Global test loss: 0.823, Global test accuracy: 73.44
Round  97, Train loss: 0.822, Test loss: 1.079, Test accuracy: 65.99
Round  97, Global train loss: 0.822, Global test loss: 0.837, Global test accuracy: 73.01
Round  98, Train loss: 0.908, Test loss: 1.066, Test accuracy: 66.38
Round  98, Global train loss: 0.908, Global test loss: 0.836, Global test accuracy: 73.24
Round  99, Train loss: 0.857, Test loss: 1.065, Test accuracy: 66.16
Round  99, Global train loss: 0.857, Global test loss: 0.829, Global test accuracy: 72.58
Final Round, Train loss: 0.577, Test loss: 1.192, Test accuracy: 64.91
Final Round, Global train loss: 0.577, Global test loss: 0.829, Global test accuracy: 72.58
Average accuracy final 10 rounds: 66.343 

Average global accuracy final 10 rounds: 73.24324999999999 

6317.9616622924805
[5.308324098587036, 10.616648197174072, 15.664344549179077, 20.712040901184082, 25.461750268936157, 30.211459636688232, 35.13127279281616, 40.05108594894409, 45.044573068618774, 50.03806018829346, 55.0000114440918, 59.96196269989014, 64.91531038284302, 69.8686580657959, 74.78928112983704, 79.70990419387817, 84.67853546142578, 89.64716672897339, 94.72017025947571, 99.79317378997803, 104.9922616481781, 110.19134950637817, 114.8207790851593, 119.45020866394043, 124.35805487632751, 129.2659010887146, 134.08367323875427, 138.90144538879395, 143.97836709022522, 149.0552887916565, 154.0600380897522, 159.0647873878479, 164.17667388916016, 169.2885603904724, 173.88269448280334, 178.47682857513428, 183.1071035861969, 187.73737859725952, 192.74140119552612, 197.74542379379272, 202.8203673362732, 207.89531087875366, 213.0669984817505, 218.23868608474731, 222.87901139259338, 227.51933670043945, 232.1011881828308, 236.68303966522217, 241.2871344089508, 245.89122915267944, 250.46234846115112, 255.0334677696228, 259.64365911483765, 264.2538504600525, 268.8821105957031, 273.51037073135376, 278.103068113327, 282.6957654953003, 287.2604820728302, 291.8251986503601, 296.4331569671631, 301.04111528396606, 305.6680827140808, 310.29505014419556, 314.88168358802795, 319.46831703186035, 324.0613946914673, 328.6544723510742, 333.2144179344177, 337.77436351776123, 342.37606835365295, 346.9777731895447, 351.5769135951996, 356.1760540008545, 360.79489517211914, 365.4137363433838, 370.00053334236145, 374.5873303413391, 379.1810145378113, 383.77469873428345, 388.35467743873596, 392.9346561431885, 397.57714653015137, 402.21963691711426, 406.84471797943115, 411.46979904174805, 416.089430809021, 420.70906257629395, 425.2889132499695, 429.868763923645, 434.4915907382965, 439.114417552948, 443.9076654911041, 448.70091342926025, 453.3345081806183, 457.9681029319763, 462.5524880886078, 467.13687324523926, 472.28330421447754, 477.4297351837158, 482.3646333217621, 487.29953145980835, 491.8363513946533, 496.3731713294983, 501.1767165660858, 505.98026180267334, 511.12909865379333, 516.2779355049133, 521.4903435707092, 526.7027516365051, 531.5387787818909, 536.3748059272766, 541.0834624767303, 545.7921190261841, 550.5306322574615, 555.269145488739, 559.9563317298889, 564.6435179710388, 569.2819573879242, 573.9203968048096, 578.5685095787048, 583.2166223526001, 587.850120306015, 592.4836182594299, 597.295788526535, 602.1079587936401, 606.8663783073425, 611.6247978210449, 616.3076031208038, 620.9904084205627, 625.7355976104736, 630.4807868003845, 635.3687777519226, 640.2567687034607, 645.1154675483704, 649.97416639328, 654.7682280540466, 659.5622897148132, 664.4348442554474, 669.3073987960815, 674.0408005714417, 678.7742023468018, 683.4857711791992, 688.1973400115967, 693.1168482303619, 698.0363564491272, 702.9693133831024, 707.9022703170776, 712.8242461681366, 717.7462220191956, 722.4219682216644, 727.0977144241333, 731.8448429107666, 736.5919713973999, 741.6550912857056, 746.7182111740112, 751.9285349845886, 757.138858795166, 762.1756730079651, 767.2124872207642, 772.3167479038239, 777.4210085868835, 782.6409847736359, 787.8609609603882, 793.0289692878723, 798.1969776153564, 803.6359412670135, 809.0749049186707, 813.9734797477722, 818.8720545768738, 823.7126200199127, 828.5531854629517, 833.3944370746613, 838.2356886863708, 843.1632628440857, 848.0908370018005, 852.761109828949, 857.4313826560974, 862.0963490009308, 866.7613153457642, 871.491369009018, 876.2214226722717, 880.9237382411957, 885.6260538101196, 890.3042604923248, 894.98246717453, 899.6722104549408, 904.3619537353516, 909.0096817016602, 913.6574096679688, 918.3666365146637, 923.0758633613586, 927.6969814300537, 932.3180994987488, 936.972501039505, 941.6269025802612, 946.3529133796692, 951.0789241790771, 955.7998719215393, 960.5208196640015, 962.9032027721405, 965.2855858802795]
[30.5675, 30.5675, 34.51, 34.51, 36.11, 36.11, 37.9325, 37.9325, 38.6525, 38.6525, 40.34, 40.34, 41.6975, 41.6975, 43.7875, 43.7875, 45.55, 45.55, 45.87, 45.87, 47.6625, 47.6625, 48.51, 48.51, 49.9625, 49.9625, 51.11, 51.11, 52.7375, 52.7375, 53.57, 53.57, 53.745, 53.745, 54.4475, 54.4475, 55.79, 55.79, 56.095, 56.095, 56.4675, 56.4675, 57.0275, 57.0275, 56.9625, 56.9625, 57.3425, 57.3425, 57.105, 57.105, 57.865, 57.865, 58.25, 58.25, 59.21, 59.21, 59.25, 59.25, 59.93, 59.93, 59.8875, 59.8875, 60.6725, 60.6725, 61.225, 61.225, 61.3675, 61.3675, 61.4925, 61.4925, 61.9225, 61.9225, 62.025, 62.025, 62.2775, 62.2775, 62.42, 62.42, 62.65, 62.65, 62.945, 62.945, 62.73, 62.73, 63.085, 63.085, 63.3775, 63.3775, 63.2125, 63.2125, 62.87, 62.87, 63.5675, 63.5675, 63.945, 63.945, 63.8325, 63.8325, 63.735, 63.735, 64.135, 64.135, 64.3325, 64.3325, 64.2125, 64.2125, 63.9225, 63.9225, 64.815, 64.815, 64.705, 64.705, 64.7075, 64.7075, 64.8975, 64.8975, 65.18, 65.18, 64.86, 64.86, 64.815, 64.815, 65.1575, 65.1575, 64.9575, 64.9575, 65.315, 65.315, 64.63, 64.63, 64.74, 64.74, 64.5325, 64.5325, 64.795, 64.795, 64.67, 64.67, 65.195, 65.195, 65.3825, 65.3825, 65.9275, 65.9275, 65.5425, 65.5425, 65.745, 65.745, 65.91, 65.91, 66.2475, 66.2475, 65.9, 65.9, 65.7425, 65.7425, 65.775, 65.775, 66.0225, 66.0225, 65.875, 65.875, 65.8075, 65.8075, 65.8, 65.8, 65.6625, 65.6625, 66.115, 66.115, 66.38, 66.38, 66.5975, 66.5975, 66.85, 66.85, 66.4375, 66.4375, 66.6225, 66.6225, 66.3975, 66.3975, 66.6025, 66.6025, 66.3925, 66.3925, 66.81, 66.81, 66.2325, 66.2325, 66.03, 66.03, 66.43, 66.43, 65.9925, 65.9925, 66.38, 66.38, 66.1625, 66.1625, 64.9125, 64.9125]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Co-teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
Client 1, noise level: 0.2179 (0.1961), real noise ratio: 0.2105
Client 5, noise level: 0.0651 (0.0586), real noise ratio: 0.0775
Client 10, noise level: 0.8128 (0.7316), real noise ratio: 0.7420
Client 11, noise level: 0.0757 (0.0681), real noise ratio: 0.0845
Client 12, noise level: 0.6565 (0.5908), real noise ratio: 0.5875
Client 14, noise level: 0.4799 (0.4319), real noise ratio: 0.4590
Client 16, noise level: 0.0000 (0.0000), real noise ratio: 0.0895
Client 17, noise level: 0.2470 (0.2223), real noise ratio: 0.3145
Client 18, noise level: 0.7122 (0.6410), real noise ratio: 0.6905
Client 19, noise level: 0.3246 (0.2921), real noise ratio: 0.3565
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.342, Test loss: 1.904, Test accuracy: 23.38
Round   1, Train loss: 0.827, Test loss: 1.346, Test accuracy: 49.13
Round   2, Train loss: 0.722, Test loss: 1.030, Test accuracy: 61.97
Round   3, Train loss: 0.629, Test loss: 1.085, Test accuracy: 57.04
Round   4, Train loss: 0.683, Test loss: 0.944, Test accuracy: 62.19
Round   5, Train loss: 0.649, Test loss: 0.904, Test accuracy: 67.90
Round   6, Train loss: 0.583, Test loss: 0.741, Test accuracy: 71.01
Round   7, Train loss: 0.603, Test loss: 0.662, Test accuracy: 73.09
Round   8, Train loss: 0.503, Test loss: 0.686, Test accuracy: 73.90
Round   9, Train loss: 0.609, Test loss: 0.592, Test accuracy: 75.69
Round  10, Train loss: 0.538, Test loss: 0.495, Test accuracy: 79.77
Round  11, Train loss: 0.540, Test loss: 0.490, Test accuracy: 80.08
Round  12, Train loss: 0.424, Test loss: 0.479, Test accuracy: 80.49
Round  13, Train loss: 0.390, Test loss: 0.471, Test accuracy: 80.55
Round  14, Train loss: 0.510, Test loss: 0.468, Test accuracy: 80.60
Round  15, Train loss: 0.504, Test loss: 0.449, Test accuracy: 81.81
Round  16, Train loss: 0.419, Test loss: 0.437, Test accuracy: 81.70
Round  17, Train loss: 0.412, Test loss: 0.432, Test accuracy: 82.41
Round  18, Train loss: 0.401, Test loss: 0.421, Test accuracy: 83.26
Round  19, Train loss: 0.372, Test loss: 0.422, Test accuracy: 82.85
Round  20, Train loss: 0.462, Test loss: 0.407, Test accuracy: 83.83
Round  21, Train loss: 0.418, Test loss: 0.389, Test accuracy: 84.59
Round  22, Train loss: 0.350, Test loss: 0.389, Test accuracy: 84.41
Round  23, Train loss: 0.305, Test loss: 0.380, Test accuracy: 84.71
Round  24, Train loss: 0.375, Test loss: 0.375, Test accuracy: 84.93
Round  25, Train loss: 0.353, Test loss: 0.367, Test accuracy: 85.37
Round  26, Train loss: 0.378, Test loss: 0.369, Test accuracy: 85.60
Round  27, Train loss: 0.446, Test loss: 0.369, Test accuracy: 85.76
Round  28, Train loss: 0.377, Test loss: 0.358, Test accuracy: 86.15
Round  29, Train loss: 0.346, Test loss: 0.356, Test accuracy: 86.02
Round  30, Train loss: 0.401, Test loss: 0.359, Test accuracy: 86.04
Round  31, Train loss: 0.363, Test loss: 0.352, Test accuracy: 86.30
Round  32, Train loss: 0.388, Test loss: 0.346, Test accuracy: 86.58
Round  33, Train loss: 0.277, Test loss: 0.341, Test accuracy: 86.68
Round  34, Train loss: 0.279, Test loss: 0.342, Test accuracy: 86.71
Round  35, Train loss: 0.348, Test loss: 0.341, Test accuracy: 86.66
Round  36, Train loss: 0.247, Test loss: 0.339, Test accuracy: 86.46
Round  37, Train loss: 0.261, Test loss: 0.336, Test accuracy: 86.73
Round  38, Train loss: 0.339, Test loss: 0.333, Test accuracy: 86.99
Round  39, Train loss: 0.272, Test loss: 0.326, Test accuracy: 86.97
Round  40, Train loss: 0.379, Test loss: 0.330, Test accuracy: 87.13
Round  41, Train loss: 0.283, Test loss: 0.322, Test accuracy: 87.26
Round  42, Train loss: 0.336, Test loss: 0.324, Test accuracy: 87.38
Round  43, Train loss: 0.311, Test loss: 0.324, Test accuracy: 87.35
Round  44, Train loss: 0.297, Test loss: 0.321, Test accuracy: 87.40
Round  45, Train loss: 0.334, Test loss: 0.312, Test accuracy: 87.73
Round  46, Train loss: 0.372, Test loss: 0.306, Test accuracy: 88.15
Round  47, Train loss: 0.292, Test loss: 0.316, Test accuracy: 87.66
Round  48, Train loss: 0.320, Test loss: 0.313, Test accuracy: 87.88
Round  49, Train loss: 0.284, Test loss: 0.311, Test accuracy: 87.90
Round  50, Train loss: 0.289, Test loss: 0.308, Test accuracy: 88.16
Round  51, Train loss: 0.229, Test loss: 0.304, Test accuracy: 88.06
Round  52, Train loss: 0.306, Test loss: 0.298, Test accuracy: 88.54
Round  53, Train loss: 0.308, Test loss: 0.303, Test accuracy: 88.27
Round  54, Train loss: 0.340, Test loss: 0.300, Test accuracy: 88.48
Round  55, Train loss: 0.301, Test loss: 0.301, Test accuracy: 88.35
Round  56, Train loss: 0.211, Test loss: 0.298, Test accuracy: 88.53
Round  57, Train loss: 0.273, Test loss: 0.300, Test accuracy: 88.34
Round  58, Train loss: 0.300, Test loss: 0.303, Test accuracy: 88.26
Round  59, Train loss: 0.204, Test loss: 0.298, Test accuracy: 88.55
Round  60, Train loss: 0.308, Test loss: 0.298, Test accuracy: 88.58
Round  61, Train loss: 0.189, Test loss: 0.295, Test accuracy: 88.67
Round  62, Train loss: 0.283, Test loss: 0.290, Test accuracy: 88.88
Round  63, Train loss: 0.283, Test loss: 0.295, Test accuracy: 88.62
Round  64, Train loss: 0.176, Test loss: 0.291, Test accuracy: 88.74
Round  65, Train loss: 0.220, Test loss: 0.294, Test accuracy: 88.73
Round  66, Train loss: 0.294, Test loss: 0.287, Test accuracy: 89.14
Round  67, Train loss: 0.269, Test loss: 0.291, Test accuracy: 88.76
Round  68, Train loss: 0.302, Test loss: 0.290, Test accuracy: 88.73
Round  69, Train loss: 0.179, Test loss: 0.290, Test accuracy: 88.78
Round  70, Train loss: 0.258, Test loss: 0.287, Test accuracy: 88.80
Round  71, Train loss: 0.237, Test loss: 0.293, Test accuracy: 88.70
Round  72, Train loss: 0.276, Test loss: 0.286, Test accuracy: 88.95
Round  73, Train loss: 0.298, Test loss: 0.289, Test accuracy: 88.91
Round  74, Train loss: 0.256, Test loss: 0.286, Test accuracy: 88.85
Round  75, Train loss: 0.241, Test loss: 0.289, Test accuracy: 88.78
Round  76, Train loss: 0.211, Test loss: 0.293, Test accuracy: 88.80
Round  77, Train loss: 0.207, Test loss: 0.287, Test accuracy: 89.04
Round  78, Train loss: 0.214, Test loss: 0.288, Test accuracy: 89.05
Round  79, Train loss: 0.206, Test loss: 0.282, Test accuracy: 89.11
Round  80, Train loss: 0.233, Test loss: 0.287, Test accuracy: 89.00
Round  81, Train loss: 0.269, Test loss: 0.291, Test accuracy: 88.68
Round  82, Train loss: 0.234, Test loss: 0.285, Test accuracy: 89.00
Round  83, Train loss: 0.221, Test loss: 0.291, Test accuracy: 88.75
Round  84, Train loss: 0.138, Test loss: 0.292, Test accuracy: 88.62
Round  85, Train loss: 0.196, Test loss: 0.287, Test accuracy: 88.97
Round  86, Train loss: 0.209, Test loss: 0.286, Test accuracy: 89.06
Round  87, Train loss: 0.211, Test loss: 0.293, Test accuracy: 88.86
Round  88, Train loss: 0.257, Test loss: 0.287, Test accuracy: 89.03
Round  89, Train loss: 0.225, Test loss: 0.282, Test accuracy: 89.33
Round  90, Train loss: 0.216, Test loss: 0.285, Test accuracy: 89.03
Round  91, Train loss: 0.179, Test loss: 0.283, Test accuracy: 89.24
Round  92, Train loss: 0.199, Test loss: 0.285, Test accuracy: 88.95
Round  93, Train loss: 0.222, Test loss: 0.285, Test accuracy: 89.02
Round  94, Train loss: 0.205, Test loss: 0.284, Test accuracy: 89.12
Round  95, Train loss: 0.168, Test loss: 0.286, Test accuracy: 89.16
Round  96, Train loss: 0.242, Test loss: 0.286, Test accuracy: 89.02
Round  97, Train loss: 0.240, Test loss: 0.285, Test accuracy: 89.05
Round  98, Train loss: 0.150, Test loss: 0.285, Test accuracy: 89.07
Round  99, Train loss: 0.147, Test loss: 0.283, Test accuracy: 89.25
Final Round, Train loss: 0.159, Test loss: 0.281, Test accuracy: 89.38
Average accuracy final 10 rounds: 89.09041666666667
2764.7450172901154
[3.998199224472046, 7.614601135253906, 11.107386589050293, 14.69271445274353, 18.288320064544678, 21.847367763519287, 25.39867401123047, 28.966527938842773, 32.7238974571228, 36.45057964324951, 39.920069217681885, 43.48620009422302, 47.19474911689758, 50.840555906295776, 54.32443428039551, 57.92775201797485, 61.54970908164978, 65.17802238464355, 68.57025098800659, 72.0541524887085, 75.57273530960083, 79.16420388221741, 82.76605439186096, 86.349050283432, 89.97912955284119, 93.59939074516296, 97.20344495773315, 100.80971503257751, 104.37332773208618, 107.91438674926758, 111.4687340259552, 115.06587219238281, 118.34866094589233, 121.83155083656311, 125.35923552513123, 128.95580673217773, 132.54608035087585, 136.10983729362488, 139.62229681015015, 143.2182605266571, 146.5937259197235, 150.0571208000183, 153.58295154571533, 157.05151176452637, 160.49881148338318, 164.11164021492004, 167.46743893623352, 170.80332589149475, 174.1621551513672, 177.49467206001282, 180.8196563720703, 184.05834341049194, 187.34120678901672, 190.84443593025208, 194.2810468673706, 197.71665501594543, 201.18536019325256, 204.81453728675842, 208.3613784313202, 211.80492115020752, 215.0977749824524, 218.3265163898468, 221.67298579216003, 224.98982405662537, 228.3324429988861, 231.63075995445251, 235.0235321521759, 238.37767672538757, 241.6207001209259, 244.9726104736328, 248.53615307807922, 252.02346634864807, 255.3242015838623, 258.862548828125, 262.33312344551086, 265.8796315193176, 269.3762457370758, 272.7183105945587, 276.0022671222687, 279.3502187728882, 282.8047299385071, 286.0994129180908, 289.37083196640015, 292.9270911216736, 296.2996256351471, 299.6999728679657, 303.05922842025757, 306.4680106639862, 309.8504168987274, 313.26719212532043, 316.6175768375397, 319.8760542869568, 323.1467332839966, 326.54474329948425, 330.0263338088989, 333.5162687301636, 337.129896402359, 340.7268736362457, 344.1416549682617, 347.5808959007263, 349.7146563529968]
[23.375, 49.13333333333333, 61.96666666666667, 57.0375, 62.19166666666667, 67.90416666666667, 71.00833333333334, 73.0875, 73.9, 75.6875, 79.76666666666667, 80.075, 80.49166666666666, 80.54583333333333, 80.59583333333333, 81.8125, 81.7, 82.4125, 83.25833333333334, 82.84583333333333, 83.825, 84.59166666666667, 84.40833333333333, 84.7125, 84.93333333333334, 85.37083333333334, 85.59583333333333, 85.7625, 86.15416666666667, 86.02083333333333, 86.0375, 86.29583333333333, 86.57916666666667, 86.68333333333334, 86.7125, 86.65833333333333, 86.45833333333333, 86.72916666666667, 86.99166666666666, 86.97083333333333, 87.12916666666666, 87.25833333333334, 87.38333333333334, 87.35416666666667, 87.40416666666667, 87.73333333333333, 88.15, 87.6625, 87.88333333333334, 87.89583333333333, 88.1625, 88.05833333333334, 88.5375, 88.26666666666667, 88.47916666666667, 88.34583333333333, 88.53333333333333, 88.34166666666667, 88.2625, 88.55416666666666, 88.58333333333333, 88.675, 88.875, 88.625, 88.74166666666666, 88.72916666666667, 89.14166666666667, 88.7625, 88.73333333333333, 88.78333333333333, 88.79583333333333, 88.69583333333334, 88.94583333333334, 88.9125, 88.84583333333333, 88.78333333333333, 88.8, 89.04166666666667, 89.05416666666666, 89.1125, 89.0, 88.68333333333334, 88.99583333333334, 88.74583333333334, 88.625, 88.97083333333333, 89.0625, 88.85833333333333, 89.025, 89.325, 89.025, 89.2375, 88.95416666666667, 89.02083333333333, 89.125, 89.1625, 89.01666666666667, 89.04583333333333, 89.07083333333334, 89.24583333333334, 89.375]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
Client 1, noise level: 0.2179 (0.1961), real noise ratio: 0.2050
Client 5, noise level: 0.0651 (0.0586), real noise ratio: 0.0975
Client 10, noise level: 0.8128 (0.7316), real noise ratio: 0.7235
Client 11, noise level: 0.0757 (0.0681), real noise ratio: 0.0715
Client 12, noise level: 0.6565 (0.5908), real noise ratio: 0.5865
Client 14, noise level: 0.4799 (0.4319), real noise ratio: 0.4570
Client 16, noise level: 0.0000 (0.0000), real noise ratio: 0.0255
Client 17, noise level: 0.2470 (0.2223), real noise ratio: 0.2795
Client 18, noise level: 0.7122 (0.6410), real noise ratio: 0.6940
Client 19, noise level: 0.3246 (0.2921), real noise ratio: 0.3660
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  11.2100
Round 1 global test acc  21.1500
Round 2 global test acc  17.5600
Round 3 global test acc  28.2700
Round 4 global test acc  19.7200
Round 5 global test acc  34.0800
Round 6 global test acc  22.6400
Round 7 global test acc  30.8900
Round 8 global test acc  29.3700
Round 9 global test acc  28.2000
Round 10 global test acc  29.9800
Round 11 global test acc  22.3600
Round 12 global test acc  26.1800
Round 13 global test acc  28.7900
Round 14 global test acc  29.4500
Round 15 global test acc  25.9700
Round 16 global test acc  29.6200
Round 17 global test acc  28.6900
Round 18 global test acc  37.8000
Round 19 global test acc  31.3500
Round 20 global test acc  31.1100
Round 21 global test acc  38.2400
Round 22 global test acc  32.2100
Round 23 global test acc  22.2900
Round 24 global test acc  23.4000
Round 25 global test acc  30.8700
Round 26 global test acc  36.3200
Round 27 global test acc  31.4300
Round 28 global test acc  32.0700
Round 29 global test acc  28.8200
Round 30 global test acc  38.1700
Round 31 global test acc  28.2200
Round 32 global test acc  34.4100
Round 33 global test acc  34.7600
Round 34 global test acc  20.8300
Round 35 global test acc  35.8800
Round 36 global test acc  31.3700
Round 37 global test acc  26.1800
Round 38 global test acc  33.2900
Round 39 global test acc  36.3400
Round 40 global test acc  29.8800
Round 41 global test acc  28.4000
Round 42 global test acc  25.8700
Round 43 global test acc  32.5900
Round 44 global test acc  32.3400
Round 45 global test acc  38.0800
Round 46 global test acc  31.7300
Round 47 global test acc  41.2500
Round 48 global test acc  29.5600
Round 49 global test acc  25.2900
Round 50 global test acc  28.9500
Round 51 global test acc  39.4000
Round 52 global test acc  33.2900
Round 53 global test acc  27.7100
Round 54 global test acc  27.6000
Round 55 global test acc  34.8700
Round 56 global test acc  42.2700
Round 57 global test acc  25.5800
Round 58 global test acc  30.7600
Round 59 global test acc  35.8600
Round 60 global test acc  32.9100
Round 61 global test acc  28.7300
Round 62 global test acc  38.6700
Round 63 global test acc  31.9100
Round 64 global test acc  39.2200
Round 65 global test acc  36.7000
Round 66 global test acc  28.4900
Round 67 global test acc  34.8300
Round 68 global test acc  29.2400
Round 69 global test acc  33.4400
Round 70 global test acc  30.4100
Round 71 global test acc  25.2900
Round 72 global test acc  30.9000
Round 73 global test acc  40.6000
Round 74 global test acc  31.4200
Round 75 global test acc  36.5200
Round 76 global test acc  36.9400
Round 77 global test acc  34.1800
Round 78 global test acc  29.1300
Round 79 global test acc  33.0200
Round 80 global test acc  32.4700
Round 81 global test acc  33.1700
Round 82 global test acc  30.5400
Round 83 global test acc  29.3900
Round 84 global test acc  28.6500
Round 85 global test acc  29.1600
Round 86 global test acc  31.0100
Round 87 global test acc  29.6800
Round 88 global test acc  29.7400
Round 89 global test acc  30.9100
Round 90 global test acc  32.9800
Round 91 global test acc  32.5500
Round 92 global test acc  30.0000
Round 93 global test acc  29.3700
Round 94 global test acc  31.2300
Round 95 global test acc  31.2200
Round 96 global test acc  30.0500
Round 97 global test acc  30.4400
Round 98 global test acc  29.8300
Round 99 global test acc  28.9600
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
Client 1, noise level: 0.2179 (0.1961), real noise ratio: 0.2055
Client 5, noise level: 0.0651 (0.0586), real noise ratio: 0.0550
Client 10, noise level: 0.8128 (0.7316), real noise ratio: 0.7385
Client 11, noise level: 0.0757 (0.0681), real noise ratio: 0.0650
Client 12, noise level: 0.6565 (0.5908), real noise ratio: 0.5910
Client 14, noise level: 0.4799 (0.4319), real noise ratio: 0.4735
Client 16, noise level: 0.0000 (0.0000), real noise ratio: 0.0265
Client 17, noise level: 0.2470 (0.2223), real noise ratio: 0.3690
Client 18, noise level: 0.7122 (0.6410), real noise ratio: 0.6450
Client 19, noise level: 0.3246 (0.2921), real noise ratio: 0.4310
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.616, Test loss: 2.006, Test accuracy: 26.73
Round   1, Train loss: 1.371, Test loss: 1.557, Test accuracy: 40.70
Round   2, Train loss: 1.096, Test loss: 1.481, Test accuracy: 50.90
Round   3, Train loss: 1.089, Test loss: 1.117, Test accuracy: 61.27
Round   4, Train loss: 1.094, Test loss: 0.914, Test accuracy: 71.30
Round   5, Train loss: 1.088, Test loss: 0.767, Test accuracy: 75.95
Round   6, Train loss: 0.945, Test loss: 0.770, Test accuracy: 76.21
Round   7, Train loss: 1.034, Test loss: 0.709, Test accuracy: 78.31
Round   8, Train loss: 0.954, Test loss: 0.707, Test accuracy: 78.46
Round   9, Train loss: 0.973, Test loss: 0.672, Test accuracy: 80.08
Round  10, Train loss: 0.853, Test loss: 0.665, Test accuracy: 80.37
Round  11, Train loss: 0.823, Test loss: 0.629, Test accuracy: 81.19
Round  12, Train loss: 0.829, Test loss: 0.601, Test accuracy: 81.74
Round  13, Train loss: 0.784, Test loss: 0.596, Test accuracy: 82.15
Round  14, Train loss: 0.998, Test loss: 0.623, Test accuracy: 82.25
Round  15, Train loss: 0.941, Test loss: 0.610, Test accuracy: 82.59
Round  16, Train loss: 0.848, Test loss: 0.572, Test accuracy: 82.70
Round  17, Train loss: 0.914, Test loss: 0.580, Test accuracy: 82.64
Round  18, Train loss: 0.818, Test loss: 0.560, Test accuracy: 83.17
Round  19, Train loss: 0.736, Test loss: 0.540, Test accuracy: 83.89
Round  20, Train loss: 0.706, Test loss: 0.529, Test accuracy: 84.06
Round  21, Train loss: 0.802, Test loss: 0.543, Test accuracy: 84.33
Round  22, Train loss: 0.945, Test loss: 0.539, Test accuracy: 84.42
Round  23, Train loss: 0.708, Test loss: 0.537, Test accuracy: 84.73
Round  24, Train loss: 0.925, Test loss: 0.535, Test accuracy: 84.41
Round  25, Train loss: 0.864, Test loss: 0.516, Test accuracy: 84.84
Round  26, Train loss: 0.665, Test loss: 0.509, Test accuracy: 85.00
Round  27, Train loss: 0.656, Test loss: 0.504, Test accuracy: 85.50
Round  28, Train loss: 0.920, Test loss: 0.498, Test accuracy: 85.50
Round  29, Train loss: 0.849, Test loss: 0.482, Test accuracy: 85.69
Round  30, Train loss: 0.595, Test loss: 0.477, Test accuracy: 85.81
Round  31, Train loss: 0.899, Test loss: 0.489, Test accuracy: 86.05
Round  32, Train loss: 0.763, Test loss: 0.478, Test accuracy: 85.76
Round  33, Train loss: 0.907, Test loss: 0.480, Test accuracy: 85.87
Round  34, Train loss: 0.758, Test loss: 0.466, Test accuracy: 86.37
Round  35, Train loss: 0.683, Test loss: 0.467, Test accuracy: 86.26
Round  36, Train loss: 0.731, Test loss: 0.456, Test accuracy: 86.71
Round  37, Train loss: 0.730, Test loss: 0.451, Test accuracy: 86.70
Round  38, Train loss: 0.828, Test loss: 0.456, Test accuracy: 86.95
Round  39, Train loss: 0.625, Test loss: 0.434, Test accuracy: 87.56
Round  40, Train loss: 0.752, Test loss: 0.450, Test accuracy: 87.17
Round  41, Train loss: 0.785, Test loss: 0.442, Test accuracy: 87.10
Round  42, Train loss: 0.726, Test loss: 0.439, Test accuracy: 87.59
Round  43, Train loss: 0.619, Test loss: 0.432, Test accuracy: 87.67
Round  44, Train loss: 0.803, Test loss: 0.437, Test accuracy: 87.91
Round  45, Train loss: 0.846, Test loss: 0.442, Test accuracy: 87.97
Round  46, Train loss: 0.899, Test loss: 0.446, Test accuracy: 87.47
Round  47, Train loss: 0.588, Test loss: 0.441, Test accuracy: 87.59
Round  48, Train loss: 0.660, Test loss: 0.433, Test accuracy: 87.62
Round  49, Train loss: 0.769, Test loss: 0.427, Test accuracy: 87.51
Round  50, Train loss: 0.836, Test loss: 0.431, Test accuracy: 87.53
Round  51, Train loss: 0.757, Test loss: 0.418, Test accuracy: 87.69
Round  52, Train loss: 0.752, Test loss: 0.423, Test accuracy: 87.92
Round  53, Train loss: 0.481, Test loss: 0.426, Test accuracy: 87.91
Round  54, Train loss: 0.843, Test loss: 0.434, Test accuracy: 87.98
Round  55, Train loss: 0.741, Test loss: 0.431, Test accuracy: 87.68
Round  56, Train loss: 0.759, Test loss: 0.414, Test accuracy: 88.44
Round  57, Train loss: 0.763, Test loss: 0.411, Test accuracy: 88.45
Round  58, Train loss: 0.934, Test loss: 0.409, Test accuracy: 88.52
Round  59, Train loss: 0.664, Test loss: 0.421, Test accuracy: 88.49
Round  60, Train loss: 0.698, Test loss: 0.418, Test accuracy: 88.45
Round  61, Train loss: 0.828, Test loss: 0.427, Test accuracy: 88.42
Round  62, Train loss: 0.517, Test loss: 0.425, Test accuracy: 88.16
Round  63, Train loss: 0.680, Test loss: 0.421, Test accuracy: 88.22
Round  64, Train loss: 0.673, Test loss: 0.412, Test accuracy: 88.42
Round  65, Train loss: 0.661, Test loss: 0.411, Test accuracy: 88.56
Round  66, Train loss: 0.708, Test loss: 0.405, Test accuracy: 88.73
Round  67, Train loss: 0.667, Test loss: 0.419, Test accuracy: 88.53
Round  68, Train loss: 0.597, Test loss: 0.400, Test accuracy: 88.38
Round  69, Train loss: 0.747, Test loss: 0.400, Test accuracy: 88.36
Round  70, Train loss: 0.673, Test loss: 0.401, Test accuracy: 88.26
Round  71, Train loss: 0.666, Test loss: 0.401, Test accuracy: 88.51
Round  72, Train loss: 0.529, Test loss: 0.403, Test accuracy: 88.71
Round  73, Train loss: 0.598, Test loss: 0.406, Test accuracy: 88.86
Round  74, Train loss: 0.623, Test loss: 0.399, Test accuracy: 88.76
Round  75, Train loss: 0.804, Test loss: 0.405, Test accuracy: 88.51
Round  76, Train loss: 0.685, Test loss: 0.397, Test accuracy: 88.78
Round  77, Train loss: 0.549, Test loss: 0.400, Test accuracy: 88.97
Round  78, Train loss: 0.523, Test loss: 0.393, Test accuracy: 88.69
Round  79, Train loss: 0.718, Test loss: 0.394, Test accuracy: 88.99
Round  80, Train loss: 0.668, Test loss: 0.397, Test accuracy: 88.77
Round  81, Train loss: 0.741, Test loss: 0.405, Test accuracy: 88.64
Round  82, Train loss: 0.606, Test loss: 0.398, Test accuracy: 89.14
Round  83, Train loss: 0.639, Test loss: 0.399, Test accuracy: 89.08
Round  84, Train loss: 0.729, Test loss: 0.406, Test accuracy: 88.72
Round  85, Train loss: 0.813, Test loss: 0.401, Test accuracy: 88.69
Round  86, Train loss: 0.582, Test loss: 0.392, Test accuracy: 88.85
Round  87, Train loss: 0.643, Test loss: 0.398, Test accuracy: 88.97
Round  88, Train loss: 0.640, Test loss: 0.409, Test accuracy: 88.61
Round  89, Train loss: 0.552, Test loss: 0.412, Test accuracy: 88.46
Round  90, Train loss: 0.615, Test loss: 0.403, Test accuracy: 88.63
Round  91, Train loss: 0.645, Test loss: 0.394, Test accuracy: 88.93
Round  92, Train loss: 0.612, Test loss: 0.399, Test accuracy: 89.00
Round  93, Train loss: 0.773, Test loss: 0.402, Test accuracy: 88.66
Round  94, Train loss: 0.701, Test loss: 0.401, Test accuracy: 88.80
Round  95, Train loss: 0.764, Test loss: 0.411, Test accuracy: 88.59
Round  96, Train loss: 0.633, Test loss: 0.414, Test accuracy: 88.49
Round  97, Train loss: 0.612, Test loss: 0.407, Test accuracy: 88.75
Round  98, Train loss: 0.764, Test loss: 0.417, Test accuracy: 88.54
Round  99, Train loss: 0.586, Test loss: 0.415, Test accuracy: 88.36
Final Round, Train loss: 0.605, Test loss: 0.413, Test accuracy: 88.50
Average accuracy final 10 rounds: 88.674
3319.4635860919952
[4.7827372550964355, 9.297305583953857, 13.818828105926514, 18.29400062561035, 26.732279062271118, 31.078055143356323, 35.44381284713745, 39.89336109161377, 44.22173810005188, 48.558279275894165, 52.9495689868927, 57.171775579452515, 61.12218999862671, 65.07309770584106, 69.00878691673279, 72.93639540672302, 76.88772940635681, 80.83758592605591, 84.75100135803223, 88.68739724159241, 92.66599106788635, 96.69749808311462, 100.71103048324585, 104.70948815345764, 108.71287870407104, 112.72506427764893, 116.71637487411499, 120.69233679771423, 124.72822308540344, 128.72388100624084, 132.72219491004944, 136.7620599269867, 140.75992465019226, 144.76180481910706, 148.78984379768372, 152.77638983726501, 156.7778766155243, 160.7624535560608, 164.80547785758972, 168.8032956123352, 172.81019377708435, 176.86051535606384, 181.31977534294128, 185.76690983772278, 190.1912055015564, 194.22613835334778, 198.26629829406738, 202.75891256332397, 207.1828863620758, 211.21588397026062, 215.25138020515442, 219.26005387306213, 223.23790788650513, 227.25796341896057, 231.28216743469238, 235.27241802215576, 239.31592082977295, 243.47259950637817, 247.50148725509644, 251.46774053573608, 255.5063452720642, 259.489132642746, 263.6544167995453, 267.6803572177887, 271.7562618255615, 275.92169880867004, 279.9257712364197, 283.94136905670166, 287.9464943408966, 292.1403913497925, 296.1413416862488, 300.1390571594238, 304.13744163513184, 308.15449500083923, 312.20741415023804, 316.20792841911316, 320.31099700927734, 324.32002997398376, 328.3595767021179, 332.3151259422302, 336.3124282360077, 340.2772114276886, 344.42311334609985, 348.4792935848236, 352.4361355304718, 356.4454572200775, 360.49504113197327, 364.48842883110046, 368.5121717453003, 372.52643513679504, 376.5806419849396, 381.6389925479889, 385.7147362232208, 389.7727108001709, 393.8312683105469, 397.82235050201416, 401.87136602401733, 405.9003551006317, 409.93101501464844, 413.90720105171204, 416.0286531448364]
[26.733333333333334, 40.7, 50.903333333333336, 61.27333333333333, 71.30333333333333, 75.95333333333333, 76.20666666666666, 78.31, 78.45666666666666, 80.08333333333333, 80.37333333333333, 81.19333333333333, 81.73666666666666, 82.15, 82.24666666666667, 82.58666666666667, 82.69666666666667, 82.64333333333333, 83.17333333333333, 83.88666666666667, 84.06, 84.32666666666667, 84.42, 84.73, 84.41, 84.84333333333333, 85.00333333333333, 85.49666666666667, 85.49666666666667, 85.69, 85.80666666666667, 86.04666666666667, 85.75666666666666, 85.87333333333333, 86.37, 86.26, 86.71333333333334, 86.7, 86.94666666666667, 87.56333333333333, 87.17333333333333, 87.1, 87.58666666666667, 87.67333333333333, 87.90666666666667, 87.96666666666667, 87.47333333333333, 87.59, 87.62, 87.50666666666666, 87.53333333333333, 87.69333333333333, 87.91666666666667, 87.91, 87.97666666666667, 87.68333333333334, 88.43666666666667, 88.44666666666667, 88.51666666666667, 88.48666666666666, 88.44666666666667, 88.42333333333333, 88.16333333333333, 88.21666666666667, 88.41666666666667, 88.56333333333333, 88.72666666666667, 88.53, 88.37666666666667, 88.35666666666667, 88.25666666666666, 88.50666666666666, 88.71333333333334, 88.86333333333333, 88.76333333333334, 88.50666666666666, 88.78, 88.96666666666667, 88.69, 88.99, 88.77, 88.64, 89.13666666666667, 89.07666666666667, 88.72333333333333, 88.69333333333333, 88.84666666666666, 88.96666666666667, 88.61333333333333, 88.46, 88.62666666666667, 88.93333333333334, 89.0, 88.66333333333333, 88.8, 88.59, 88.48666666666666, 88.74666666666667, 88.53666666666666, 88.35666666666667, 88.49666666666667]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.6 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedpac_psl.py", line 58, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 126, in get_data_v2
    y_train_noisy, gamma_s, real_noise_level = add_noise(args, y_train, dict_users_train, rand_set_all)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 239, in add_noise
    y_train_noisy[rand_sample_idx] = nosiy_sample_labels
IndexError: arrays used as indices must be of integer (or boolean) type
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.6 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 0, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 7, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 11, noise    level: 0.5000 
   Client 13, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
   Client 15, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.181, Test loss: 2.069, Test accuracy: 28.83
Round   0, Global train loss: 2.181, Global test loss: 2.076, Global test accuracy: 30.40
Round   1, Train loss: 2.135, Test loss: 1.952, Test accuracy: 32.97
Round   1, Global train loss: 2.135, Global test loss: 1.914, Global test accuracy: 37.69
Round   2, Train loss: 2.076, Test loss: 1.926, Test accuracy: 33.37
Round   2, Global train loss: 2.076, Global test loss: 1.890, Global test accuracy: 38.89
Round   3, Train loss: 2.116, Test loss: 1.927, Test accuracy: 34.69
Round   3, Global train loss: 2.116, Global test loss: 1.950, Global test accuracy: 41.13
Round   4, Train loss: 2.054, Test loss: 1.891, Test accuracy: 35.12
Round   4, Global train loss: 2.054, Global test loss: 1.838, Global test accuracy: 41.51
Round   5, Train loss: 2.055, Test loss: 1.885, Test accuracy: 35.38
Round   5, Global train loss: 2.055, Global test loss: 1.914, Global test accuracy: 40.69
Round   6, Train loss: 1.938, Test loss: 1.854, Test accuracy: 36.45
Round   6, Global train loss: 1.938, Global test loss: 1.773, Global test accuracy: 43.15
Round   7, Train loss: 2.010, Test loss: 1.854, Test accuracy: 37.08
Round   7, Global train loss: 2.010, Global test loss: 1.859, Global test accuracy: 43.76
Round   8, Train loss: 1.966, Test loss: 1.828, Test accuracy: 37.76
Round   8, Global train loss: 1.966, Global test loss: 1.776, Global test accuracy: 45.05
Round   9, Train loss: 2.013, Test loss: 1.821, Test accuracy: 38.20
Round   9, Global train loss: 2.013, Global test loss: 1.783, Global test accuracy: 46.13
Round  10, Train loss: 1.889, Test loss: 1.812, Test accuracy: 38.31
Round  10, Global train loss: 1.889, Global test loss: 1.803, Global test accuracy: 44.44
Round  11, Train loss: 1.793, Test loss: 1.808, Test accuracy: 38.52
Round  11, Global train loss: 1.793, Global test loss: 1.695, Global test accuracy: 47.68
Round  12, Train loss: 1.935, Test loss: 1.808, Test accuracy: 38.68
Round  12, Global train loss: 1.935, Global test loss: 1.794, Global test accuracy: 47.48
Round  13, Train loss: 1.816, Test loss: 1.812, Test accuracy: 38.61
Round  13, Global train loss: 1.816, Global test loss: 1.743, Global test accuracy: 47.12
Round  14, Train loss: 1.832, Test loss: 1.812, Test accuracy: 38.67
Round  14, Global train loss: 1.832, Global test loss: 1.737, Global test accuracy: 47.90
Round  15, Train loss: 1.734, Test loss: 1.818, Test accuracy: 38.76
Round  15, Global train loss: 1.734, Global test loss: 1.682, Global test accuracy: 47.56
Round  16, Train loss: 1.874, Test loss: 1.830, Test accuracy: 38.33
Round  16, Global train loss: 1.874, Global test loss: 1.870, Global test accuracy: 39.67
Round  17, Train loss: 1.639, Test loss: 1.829, Test accuracy: 38.84
Round  17, Global train loss: 1.639, Global test loss: 1.577, Global test accuracy: 50.81
Round  18, Train loss: 1.736, Test loss: 1.839, Test accuracy: 38.49
Round  18, Global train loss: 1.736, Global test loss: 1.807, Global test accuracy: 44.79
Round  19, Train loss: 1.735, Test loss: 1.840, Test accuracy: 38.69
Round  19, Global train loss: 1.735, Global test loss: 1.905, Global test accuracy: 40.31
Round  20, Train loss: 1.672, Test loss: 1.848, Test accuracy: 38.84
Round  20, Global train loss: 1.672, Global test loss: 1.821, Global test accuracy: 42.92
Round  21, Train loss: 1.750, Test loss: 1.851, Test accuracy: 38.71
Round  21, Global train loss: 1.750, Global test loss: 1.786, Global test accuracy: 46.85
Round  22, Train loss: 1.765, Test loss: 1.860, Test accuracy: 38.12
Round  22, Global train loss: 1.765, Global test loss: 1.862, Global test accuracy: 42.55
Round  23, Train loss: 1.574, Test loss: 1.882, Test accuracy: 37.91
Round  23, Global train loss: 1.574, Global test loss: 1.721, Global test accuracy: 46.85
Round  24, Train loss: 1.579, Test loss: 1.887, Test accuracy: 38.11
Round  24, Global train loss: 1.579, Global test loss: 1.609, Global test accuracy: 51.76
Round  25, Train loss: 1.468, Test loss: 1.912, Test accuracy: 38.10
Round  25, Global train loss: 1.468, Global test loss: 1.761, Global test accuracy: 42.51
Round  26, Train loss: 1.730, Test loss: 1.930, Test accuracy: 37.63
Round  26, Global train loss: 1.730, Global test loss: 1.790, Global test accuracy: 44.84
Round  27, Train loss: 1.605, Test loss: 1.936, Test accuracy: 37.83
Round  27, Global train loss: 1.605, Global test loss: 1.901, Global test accuracy: 36.14
Round  28, Train loss: 1.715, Test loss: 1.943, Test accuracy: 37.85
Round  28, Global train loss: 1.715, Global test loss: 1.825, Global test accuracy: 46.41
Round  29, Train loss: 1.362, Test loss: 1.973, Test accuracy: 37.16
Round  29, Global train loss: 1.362, Global test loss: 1.672, Global test accuracy: 46.91
Round  30, Train loss: 1.423, Test loss: 1.996, Test accuracy: 37.02
Round  30, Global train loss: 1.423, Global test loss: 1.768, Global test accuracy: 41.44
Round  31, Train loss: 1.320, Test loss: 2.022, Test accuracy: 36.92
Round  31, Global train loss: 1.320, Global test loss: 1.766, Global test accuracy: 41.89
Round  32, Train loss: 1.530, Test loss: 2.048, Test accuracy: 36.48
Round  32, Global train loss: 1.530, Global test loss: 1.749, Global test accuracy: 44.69
Round  33, Train loss: 1.240, Test loss: 2.075, Test accuracy: 36.48
Round  33, Global train loss: 1.240, Global test loss: 1.843, Global test accuracy: 35.41
Round  34, Train loss: 1.168, Test loss: 2.086, Test accuracy: 36.35
Round  34, Global train loss: 1.168, Global test loss: 1.632, Global test accuracy: 46.83
Round  35, Train loss: 1.265, Test loss: 2.116, Test accuracy: 35.67
Round  35, Global train loss: 1.265, Global test loss: 1.668, Global test accuracy: 44.55
Round  36, Train loss: 1.084, Test loss: 2.134, Test accuracy: 35.95
Round  36, Global train loss: 1.084, Global test loss: 1.720, Global test accuracy: 41.97
Round  37, Train loss: 1.247, Test loss: 2.170, Test accuracy: 36.06
Round  37, Global train loss: 1.247, Global test loss: 1.893, Global test accuracy: 34.43
Round  38, Train loss: 1.430, Test loss: 2.203, Test accuracy: 35.47
Round  38, Global train loss: 1.430, Global test loss: 1.752, Global test accuracy: 43.31
Round  39, Train loss: 1.581, Test loss: 2.224, Test accuracy: 35.64
Round  39, Global train loss: 1.581, Global test loss: 1.900, Global test accuracy: 38.06
Round  40, Train loss: 1.179, Test loss: 2.282, Test accuracy: 35.07
Round  40, Global train loss: 1.179, Global test loss: 1.862, Global test accuracy: 36.55
Round  41, Train loss: 1.052, Test loss: 2.312, Test accuracy: 34.74
Round  41, Global train loss: 1.052, Global test loss: 1.754, Global test accuracy: 41.15
Round  42, Train loss: 1.028, Test loss: 2.328, Test accuracy: 34.77
Round  42, Global train loss: 1.028, Global test loss: 1.761, Global test accuracy: 39.56
Round  43, Train loss: 1.482, Test loss: 2.353, Test accuracy: 34.50
Round  43, Global train loss: 1.482, Global test loss: 1.833, Global test accuracy: 42.34
Round  44, Train loss: 1.340, Test loss: 2.374, Test accuracy: 34.29
Round  44, Global train loss: 1.340, Global test loss: 1.783, Global test accuracy: 43.13
Round  45, Train loss: 1.068, Test loss: 2.405, Test accuracy: 34.42
Round  45, Global train loss: 1.068, Global test loss: 1.628, Global test accuracy: 47.41
Round  46, Train loss: 1.327, Test loss: 2.444, Test accuracy: 34.15
Round  46, Global train loss: 1.327, Global test loss: 1.987, Global test accuracy: 32.34
Round  47, Train loss: 1.198, Test loss: 2.507, Test accuracy: 33.97
Round  47, Global train loss: 1.198, Global test loss: 1.881, Global test accuracy: 38.03
Round  48, Train loss: 1.058, Test loss: 2.572, Test accuracy: 33.60
Round  48, Global train loss: 1.058, Global test loss: 1.745, Global test accuracy: 41.52
Round  49, Train loss: 0.997, Test loss: 2.576, Test accuracy: 33.70
Round  49, Global train loss: 0.997, Global test loss: 1.746, Global test accuracy: 40.84
Round  50, Train loss: 1.066, Test loss: 2.618, Test accuracy: 33.57
Round  50, Global train loss: 1.066, Global test loss: 1.765, Global test accuracy: 42.59
Round  51, Train loss: 1.013, Test loss: 2.642, Test accuracy: 33.32
Round  51, Global train loss: 1.013, Global test loss: 1.867, Global test accuracy: 36.92
Round  52, Train loss: 0.997, Test loss: 2.649, Test accuracy: 33.24
Round  52, Global train loss: 0.997, Global test loss: 1.888, Global test accuracy: 34.26
Round  53, Train loss: 1.147, Test loss: 2.703, Test accuracy: 33.37
Round  53, Global train loss: 1.147, Global test loss: 1.965, Global test accuracy: 35.30
Round  54, Train loss: 0.850, Test loss: 2.735, Test accuracy: 33.47
Round  54, Global train loss: 0.850, Global test loss: 1.799, Global test accuracy: 38.17
Round  55, Train loss: 0.866, Test loss: 2.750, Test accuracy: 33.37
Round  55, Global train loss: 0.866, Global test loss: 1.571, Global test accuracy: 46.08
Round  56, Train loss: 0.993, Test loss: 2.783, Test accuracy: 32.88
Round  56, Global train loss: 0.993, Global test loss: 1.816, Global test accuracy: 37.02
Round  57, Train loss: 0.879, Test loss: 2.834, Test accuracy: 32.70
Round  57, Global train loss: 0.879, Global test loss: 1.679, Global test accuracy: 42.48
Round  58, Train loss: 0.911, Test loss: 2.867, Test accuracy: 32.45
Round  58, Global train loss: 0.911, Global test loss: 1.867, Global test accuracy: 34.96
Round  59, Train loss: 0.940, Test loss: 2.879, Test accuracy: 32.42
Round  59, Global train loss: 0.940, Global test loss: 1.929, Global test accuracy: 34.21
Round  60, Train loss: 1.007, Test loss: 2.884, Test accuracy: 32.37
Round  60, Global train loss: 1.007, Global test loss: 1.901, Global test accuracy: 35.32
Round  61, Train loss: 0.866, Test loss: 2.937, Test accuracy: 32.21
Round  61, Global train loss: 0.866, Global test loss: 1.731, Global test accuracy: 42.94
Round  62, Train loss: 0.769, Test loss: 2.960, Test accuracy: 32.56
Round  62, Global train loss: 0.769, Global test loss: 1.640, Global test accuracy: 44.59
Round  63, Train loss: 0.925, Test loss: 3.012, Test accuracy: 32.31
Round  63, Global train loss: 0.925, Global test loss: 1.953, Global test accuracy: 32.86
Round  64, Train loss: 0.895, Test loss: 3.047, Test accuracy: 31.93
Round  64, Global train loss: 0.895, Global test loss: 1.887, Global test accuracy: 33.73
Round  65, Train loss: 0.728, Test loss: 3.067, Test accuracy: 32.25
Round  65, Global train loss: 0.728, Global test loss: 1.916, Global test accuracy: 29.78
Round  66, Train loss: 0.809, Test loss: 3.143, Test accuracy: 32.20
Round  66, Global train loss: 0.809, Global test loss: 1.828, Global test accuracy: 36.65
Round  67, Train loss: 0.704, Test loss: 3.181, Test accuracy: 32.48
Round  67, Global train loss: 0.704, Global test loss: 1.772, Global test accuracy: 40.24
Round  68, Train loss: 0.778, Test loss: 3.185, Test accuracy: 32.89
Round  68, Global train loss: 0.778, Global test loss: 1.834, Global test accuracy: 36.54
Round  69, Train loss: 0.780, Test loss: 3.192, Test accuracy: 32.79
Round  69, Global train loss: 0.780, Global test loss: 1.886, Global test accuracy: 35.35
Round  70, Train loss: 0.859, Test loss: 3.251, Test accuracy: 32.75
Round  70, Global train loss: 0.859, Global test loss: 1.905, Global test accuracy: 34.22
Round  71, Train loss: 0.822, Test loss: 3.287, Test accuracy: 32.60
Round  71, Global train loss: 0.822, Global test loss: 1.909, Global test accuracy: 34.17
Round  72, Train loss: 0.700, Test loss: 3.316, Test accuracy: 32.38
Round  72, Global train loss: 0.700, Global test loss: 1.861, Global test accuracy: 37.17
Round  73, Train loss: 0.641, Test loss: 3.352, Test accuracy: 32.66
Round  73, Global train loss: 0.641, Global test loss: 1.851, Global test accuracy: 36.57
Round  74, Train loss: 0.776, Test loss: 3.347, Test accuracy: 32.78
Round  74, Global train loss: 0.776, Global test loss: 1.828, Global test accuracy: 38.36
Round  75, Train loss: 0.800, Test loss: 3.367, Test accuracy: 32.95
Round  75, Global train loss: 0.800, Global test loss: 1.846, Global test accuracy: 35.92
Round  76, Train loss: 0.866, Test loss: 3.370, Test accuracy: 32.72
Round  76, Global train loss: 0.866, Global test loss: 1.919, Global test accuracy: 34.36
Round  77, Train loss: 0.675, Test loss: 3.416, Test accuracy: 32.83
Round  77, Global train loss: 0.675, Global test loss: 1.866, Global test accuracy: 35.32
Round  78, Train loss: 0.658, Test loss: 3.421, Test accuracy: 32.60
Round  78, Global train loss: 0.658, Global test loss: 1.758, Global test accuracy: 40.96
Round  79, Train loss: 0.817, Test loss: 3.514, Test accuracy: 32.38
Round  79, Global train loss: 0.817, Global test loss: 1.795, Global test accuracy: 39.41
Round  80, Train loss: 0.698, Test loss: 3.535, Test accuracy: 32.45
Round  80, Global train loss: 0.698, Global test loss: 1.837, Global test accuracy: 36.41
Round  81, Train loss: 0.608, Test loss: 3.545, Test accuracy: 32.27
Round  81, Global train loss: 0.608, Global test loss: 1.715, Global test accuracy: 42.38
Round  82, Train loss: 0.739, Test loss: 3.578, Test accuracy: 32.05
Round  82, Global train loss: 0.739, Global test loss: 1.808, Global test accuracy: 37.27
Round  83, Train loss: 0.810, Test loss: 3.617, Test accuracy: 31.85
Round  83, Global train loss: 0.810, Global test loss: 1.846, Global test accuracy: 38.12
Round  84, Train loss: 0.721, Test loss: 3.655, Test accuracy: 31.70
Round  84, Global train loss: 0.721, Global test loss: 1.928, Global test accuracy: 32.70
Round  85, Train loss: 0.705, Test loss: 3.663, Test accuracy: 31.69
Round  85, Global train loss: 0.705, Global test loss: 1.883, Global test accuracy: 35.03
Round  86, Train loss: 0.774, Test loss: 3.659, Test accuracy: 32.05
Round  86, Global train loss: 0.774, Global test loss: 1.894, Global test accuracy: 34.56
Round  87, Train loss: 0.645, Test loss: 3.740, Test accuracy: 31.78
Round  87, Global train loss: 0.645, Global test loss: 1.808, Global test accuracy: 38.36
Round  88, Train loss: 0.548, Test loss: 3.743, Test accuracy: 32.08
Round  88, Global train loss: 0.548, Global test loss: 1.740, Global test accuracy: 40.76
Round  89, Train loss: 0.604, Test loss: 3.761, Test accuracy: 31.80
Round  89, Global train loss: 0.604, Global test loss: 1.740, Global test accuracy: 40.02
Round  90, Train loss: 0.652, Test loss: 3.816, Test accuracy: 31.67
Round  90, Global train loss: 0.652, Global test loss: 1.858, Global test accuracy: 35.22
Round  91, Train loss: 0.652, Test loss: 3.839, Test accuracy: 31.54
Round  91, Global train loss: 0.652, Global test loss: 2.031, Global test accuracy: 28.16
Round  92, Train loss: 0.605, Test loss: 3.872, Test accuracy: 31.57
Round  92, Global train loss: 0.605, Global test loss: 1.815, Global test accuracy: 39.02
Round  93, Train loss: 0.637, Test loss: 3.902, Test accuracy: 31.61
Round  93, Global train loss: 0.637, Global test loss: 1.754, Global test accuracy: 39.68
Round  94, Train loss: 0.571, Test loss: 3.849, Test accuracy: 32.02
Round  94, Global train loss: 0.571, Global test loss: 1.796, Global test accuracy: 37.89
Round  95, Train loss: 0.596, Test loss: 3.880, Test accuracy: 31.93
Round  95, Global train loss: 0.596, Global test loss: 1.820, Global test accuracy: 35.95
Round  96, Train loss: 0.579, Test loss: 3.893, Test accuracy: 32.26
Round  96, Global train loss: 0.579, Global test loss: 1.911, Global test accuracy: 31.43
Round  97, Train loss: 0.643, Test loss: 3.880, Test accuracy: 32.35
Round  97, Global train loss: 0.643, Global test loss: 2.005, Global test accuracy: 29.81
Round  98, Train loss: 0.619, Test loss: 3.874, Test accuracy: 32.34
Round  98, Global train loss: 0.619, Global test loss: 1.850, Global test accuracy: 35.09
Round  99, Train loss: 0.588, Test loss: 3.898, Test accuracy: 32.35
Round  99, Global train loss: 0.588, Global test loss: 1.909, Global test accuracy: 33.67
Final Round, Train loss: 0.365, Test loss: 4.586, Test accuracy: 31.99
Final Round, Global train loss: 0.365, Global test loss: 1.909, Global test accuracy: 33.67
Average accuracy final 10 rounds: 31.963749999999997 

Average global accuracy final 10 rounds: 34.59225 

6127.053823709488
[5.136313438415527, 10.272626876831055, 14.613176345825195, 18.953725814819336, 23.313478231430054, 27.67323064804077, 31.974319219589233, 36.275407791137695, 41.00786089897156, 45.74031400680542, 50.439955711364746, 55.13959741592407, 59.97703218460083, 64.81446695327759, 69.53013777732849, 74.2458086013794, 79.05761098861694, 83.86941337585449, 88.62642741203308, 93.38344144821167, 98.1442141532898, 102.90498685836792, 107.55990934371948, 112.21483182907104, 116.89807319641113, 121.58131456375122, 126.01179671287537, 130.4422788619995, 134.74773406982422, 139.05318927764893, 143.34412717819214, 147.63506507873535, 151.92803525924683, 156.2210054397583, 160.54434752464294, 164.8676896095276, 169.15564894676208, 173.44360828399658, 177.73701310157776, 182.03041791915894, 186.33361053466797, 190.636803150177, 194.93124389648438, 199.22568464279175, 203.4984393119812, 207.77119398117065, 212.08980441093445, 216.40841484069824, 221.23087072372437, 226.0533266067505, 230.31656670570374, 234.57980680465698, 238.78663754463196, 242.99346828460693, 247.28468537330627, 251.57590246200562, 256.08625841140747, 260.5966143608093, 265.5199501514435, 270.44328594207764, 275.2879455089569, 280.1326050758362, 284.4929130077362, 288.85322093963623, 293.1949028968811, 297.536584854126, 301.89640951156616, 306.25623416900635, 310.6841297149658, 315.1120252609253, 319.49258518218994, 323.8731451034546, 328.71239256858826, 333.5516400337219, 338.45158553123474, 343.35153102874756, 348.30066871643066, 353.24980640411377, 358.3445920944214, 363.439377784729, 368.48609590530396, 373.5328140258789, 378.46251249313354, 383.3922109603882, 388.3246192932129, 393.2570276260376, 398.1030809879303, 402.949134349823, 407.29135608673096, 411.6335778236389, 415.94434785842896, 420.255117893219, 424.60120606422424, 428.9472942352295, 433.2873525619507, 437.6274108886719, 442.41989374160767, 447.21237659454346, 451.81222009658813, 456.4120635986328, 460.68517875671387, 464.9582939147949, 469.2540588378906, 473.5498237609863, 478.107435464859, 482.6650471687317, 487.3485264778137, 492.03200578689575, 496.3761885166168, 500.7203712463379, 505.1041600704193, 509.48794889450073, 513.8574650287628, 518.2269811630249, 522.61998462677, 527.0129880905151, 531.3198554515839, 535.6267228126526, 539.9531817436218, 544.2796406745911, 548.6575939655304, 553.0355472564697, 557.4105100631714, 561.785472869873, 566.137366771698, 570.489260673523, 574.8210942745209, 579.1529278755188, 583.500655412674, 587.8483829498291, 592.1597666740417, 596.4711503982544, 600.7283325195312, 604.9855146408081, 609.2954595088959, 613.6054043769836, 617.888617515564, 622.1718306541443, 626.4615938663483, 630.7513570785522, 635.0205521583557, 639.2897472381592, 643.5441696643829, 647.7985920906067, 652.0629739761353, 656.3273558616638, 660.5979413986206, 664.8685269355774, 669.1044759750366, 673.3404250144958, 677.6358594894409, 681.931293964386, 686.2771892547607, 690.6230845451355, 695.0256457328796, 699.4282069206238, 703.7828333377838, 708.1374597549438, 712.5674901008606, 716.9975204467773, 721.4765305519104, 725.9555406570435, 730.4196979999542, 734.883855342865, 739.3885371685028, 743.8932189941406, 748.3206875324249, 752.7481560707092, 757.2255885601044, 761.7030210494995, 766.2743391990662, 770.8456573486328, 775.4831466674805, 780.1206359863281, 784.6747601032257, 789.2288842201233, 793.7434623241425, 798.2580404281616, 802.7968201637268, 807.335599899292, 811.8736684322357, 816.4117369651794, 820.965368270874, 825.5189995765686, 830.0403776168823, 834.561755657196, 839.0937869548798, 843.6258182525635, 848.0851962566376, 852.5445742607117, 856.963949918747, 861.3833255767822, 865.7696633338928, 870.1560010910034, 874.6213004589081, 879.0865998268127, 883.4269115924835, 887.7672233581543, 892.1930735111237, 896.618923664093, 898.8435525894165, 901.06818151474]
[28.8325, 28.8325, 32.965, 32.965, 33.3675, 33.3675, 34.685, 34.685, 35.1225, 35.1225, 35.3825, 35.3825, 36.445, 36.445, 37.075, 37.075, 37.76, 37.76, 38.195, 38.195, 38.315, 38.315, 38.5175, 38.5175, 38.6775, 38.6775, 38.61, 38.61, 38.6675, 38.6675, 38.76, 38.76, 38.33, 38.33, 38.835, 38.835, 38.49, 38.49, 38.685, 38.685, 38.8375, 38.8375, 38.7125, 38.7125, 38.1225, 38.1225, 37.91, 37.91, 38.1125, 38.1125, 38.1, 38.1, 37.6275, 37.6275, 37.83, 37.83, 37.8475, 37.8475, 37.155, 37.155, 37.02, 37.02, 36.92, 36.92, 36.4775, 36.4775, 36.48, 36.48, 36.355, 36.355, 35.67, 35.67, 35.945, 35.945, 36.0625, 36.0625, 35.465, 35.465, 35.6375, 35.6375, 35.07, 35.07, 34.745, 34.745, 34.7675, 34.7675, 34.4975, 34.4975, 34.2875, 34.2875, 34.4225, 34.4225, 34.1475, 34.1475, 33.97, 33.97, 33.6, 33.6, 33.6975, 33.6975, 33.5675, 33.5675, 33.3225, 33.3225, 33.245, 33.245, 33.3725, 33.3725, 33.4675, 33.4675, 33.365, 33.365, 32.8825, 32.8825, 32.7, 32.7, 32.4475, 32.4475, 32.4225, 32.4225, 32.3725, 32.3725, 32.2075, 32.2075, 32.565, 32.565, 32.31, 32.31, 31.9325, 31.9325, 32.25, 32.25, 32.2025, 32.2025, 32.485, 32.485, 32.8875, 32.8875, 32.7875, 32.7875, 32.7475, 32.7475, 32.5975, 32.5975, 32.3825, 32.3825, 32.66, 32.66, 32.7825, 32.7825, 32.945, 32.945, 32.72, 32.72, 32.8275, 32.8275, 32.5975, 32.5975, 32.3775, 32.3775, 32.445, 32.445, 32.27, 32.27, 32.045, 32.045, 31.8475, 31.8475, 31.695, 31.695, 31.6875, 31.6875, 32.0525, 32.0525, 31.7825, 31.7825, 32.0825, 32.0825, 31.805, 31.805, 31.6675, 31.6675, 31.54, 31.54, 31.5675, 31.5675, 31.615, 31.615, 32.02, 32.02, 31.935, 31.935, 32.2575, 32.2575, 32.3525, 32.3525, 32.335, 32.335, 32.3475, 32.3475, 31.9925, 31.9925]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.6 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 19, noise    level: 0.5000 
   Client 15, noise    level: 0.5000 
   Client 18, noise    level: 0.5000 
   Client 11, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 12, noise    level: 0.5000 
   Client 7, noise    level: 0.5000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.100, Test loss: 1.962, Test accuracy: 30.02
Round   0, Global train loss: 2.100, Global test loss: 1.987, Global test accuracy: 29.30
Round   1, Train loss: 1.929, Test loss: 1.751, Test accuracy: 37.38
Round   1, Global train loss: 1.929, Global test loss: 1.660, Global test accuracy: 41.41
Round   2, Train loss: 1.823, Test loss: 1.694, Test accuracy: 40.23
Round   2, Global train loss: 1.823, Global test loss: 1.555, Global test accuracy: 47.34
Round   3, Train loss: 1.797, Test loss: 1.641, Test accuracy: 42.29
Round   3, Global train loss: 1.797, Global test loss: 1.481, Global test accuracy: 51.16
Round   4, Train loss: 1.737, Test loss: 1.594, Test accuracy: 44.37
Round   4, Global train loss: 1.737, Global test loss: 1.402, Global test accuracy: 53.23
Round   5, Train loss: 1.686, Test loss: 1.559, Test accuracy: 45.91
Round   5, Global train loss: 1.686, Global test loss: 1.393, Global test accuracy: 53.92
Round   6, Train loss: 1.622, Test loss: 1.536, Test accuracy: 47.18
Round   6, Global train loss: 1.622, Global test loss: 1.324, Global test accuracy: 57.80
Round   7, Train loss: 1.615, Test loss: 1.524, Test accuracy: 47.40
Round   7, Global train loss: 1.615, Global test loss: 1.290, Global test accuracy: 58.60
Round   8, Train loss: 1.573, Test loss: 1.469, Test accuracy: 50.04
Round   8, Global train loss: 1.573, Global test loss: 1.249, Global test accuracy: 59.97
Round   9, Train loss: 1.536, Test loss: 1.450, Test accuracy: 51.20
Round   9, Global train loss: 1.536, Global test loss: 1.213, Global test accuracy: 61.59
Round  10, Train loss: 1.533, Test loss: 1.434, Test accuracy: 51.48
Round  10, Global train loss: 1.533, Global test loss: 1.181, Global test accuracy: 63.07
Round  11, Train loss: 1.501, Test loss: 1.413, Test accuracy: 52.48
Round  11, Global train loss: 1.501, Global test loss: 1.182, Global test accuracy: 64.16
Round  12, Train loss: 1.464, Test loss: 1.394, Test accuracy: 53.30
Round  12, Global train loss: 1.464, Global test loss: 1.182, Global test accuracy: 63.18
Round  13, Train loss: 1.458, Test loss: 1.378, Test accuracy: 53.84
Round  13, Global train loss: 1.458, Global test loss: 1.131, Global test accuracy: 64.53
Round  14, Train loss: 1.392, Test loss: 1.355, Test accuracy: 55.11
Round  14, Global train loss: 1.392, Global test loss: 1.086, Global test accuracy: 66.12
Round  15, Train loss: 1.379, Test loss: 1.339, Test accuracy: 55.76
Round  15, Global train loss: 1.379, Global test loss: 1.060, Global test accuracy: 66.70
Round  16, Train loss: 1.380, Test loss: 1.298, Test accuracy: 57.98
Round  16, Global train loss: 1.380, Global test loss: 1.066, Global test accuracy: 67.25
Round  17, Train loss: 1.285, Test loss: 1.297, Test accuracy: 57.88
Round  17, Global train loss: 1.285, Global test loss: 1.003, Global test accuracy: 67.93
Round  18, Train loss: 1.306, Test loss: 1.301, Test accuracy: 57.71
Round  18, Global train loss: 1.306, Global test loss: 1.040, Global test accuracy: 66.86
Round  19, Train loss: 1.249, Test loss: 1.295, Test accuracy: 57.91
Round  19, Global train loss: 1.249, Global test loss: 1.023, Global test accuracy: 67.56
Round  20, Train loss: 1.249, Test loss: 1.281, Test accuracy: 58.63
Round  20, Global train loss: 1.249, Global test loss: 0.989, Global test accuracy: 68.58
Round  21, Train loss: 1.338, Test loss: 1.276, Test accuracy: 58.83
Round  21, Global train loss: 1.338, Global test loss: 1.045, Global test accuracy: 67.91
Round  22, Train loss: 1.259, Test loss: 1.269, Test accuracy: 59.19
Round  22, Global train loss: 1.259, Global test loss: 0.962, Global test accuracy: 69.46
Round  23, Train loss: 1.241, Test loss: 1.267, Test accuracy: 59.59
Round  23, Global train loss: 1.241, Global test loss: 0.988, Global test accuracy: 69.52
Round  24, Train loss: 1.282, Test loss: 1.260, Test accuracy: 60.02
Round  24, Global train loss: 1.282, Global test loss: 0.968, Global test accuracy: 69.91
Round  25, Train loss: 1.253, Test loss: 1.259, Test accuracy: 60.06
Round  25, Global train loss: 1.253, Global test loss: 0.989, Global test accuracy: 69.88
Round  26, Train loss: 1.308, Test loss: 1.244, Test accuracy: 60.52
Round  26, Global train loss: 1.308, Global test loss: 0.993, Global test accuracy: 70.30
Round  27, Train loss: 1.278, Test loss: 1.242, Test accuracy: 60.52
Round  27, Global train loss: 1.278, Global test loss: 1.016, Global test accuracy: 69.27
Round  28, Train loss: 1.280, Test loss: 1.246, Test accuracy: 60.64
Round  28, Global train loss: 1.280, Global test loss: 0.999, Global test accuracy: 69.95
Round  29, Train loss: 1.149, Test loss: 1.236, Test accuracy: 61.05
Round  29, Global train loss: 1.149, Global test loss: 0.935, Global test accuracy: 70.48
Round  30, Train loss: 1.121, Test loss: 1.245, Test accuracy: 60.81
Round  30, Global train loss: 1.121, Global test loss: 0.906, Global test accuracy: 71.54
Round  31, Train loss: 1.102, Test loss: 1.239, Test accuracy: 60.87
Round  31, Global train loss: 1.102, Global test loss: 0.933, Global test accuracy: 70.06
Round  32, Train loss: 1.185, Test loss: 1.228, Test accuracy: 61.22
Round  32, Global train loss: 1.185, Global test loss: 0.929, Global test accuracy: 71.17
Round  33, Train loss: 1.168, Test loss: 1.227, Test accuracy: 61.21
Round  33, Global train loss: 1.168, Global test loss: 0.958, Global test accuracy: 70.53
Round  34, Train loss: 1.111, Test loss: 1.229, Test accuracy: 61.40
Round  34, Global train loss: 1.111, Global test loss: 0.911, Global test accuracy: 71.13
Round  35, Train loss: 1.175, Test loss: 1.226, Test accuracy: 61.51
Round  35, Global train loss: 1.175, Global test loss: 0.953, Global test accuracy: 70.63
Round  36, Train loss: 1.059, Test loss: 1.232, Test accuracy: 61.41
Round  36, Global train loss: 1.059, Global test loss: 0.916, Global test accuracy: 70.62
Round  37, Train loss: 1.121, Test loss: 1.236, Test accuracy: 61.26
Round  37, Global train loss: 1.121, Global test loss: 0.924, Global test accuracy: 70.72
Round  38, Train loss: 1.146, Test loss: 1.234, Test accuracy: 61.33
Round  38, Global train loss: 1.146, Global test loss: 0.932, Global test accuracy: 71.13
Round  39, Train loss: 1.174, Test loss: 1.242, Test accuracy: 61.05
Round  39, Global train loss: 1.174, Global test loss: 0.956, Global test accuracy: 70.48
Round  40, Train loss: 1.090, Test loss: 1.238, Test accuracy: 61.24
Round  40, Global train loss: 1.090, Global test loss: 0.924, Global test accuracy: 71.13
Round  41, Train loss: 1.095, Test loss: 1.235, Test accuracy: 61.40
Round  41, Global train loss: 1.095, Global test loss: 0.957, Global test accuracy: 70.37
Round  42, Train loss: 1.068, Test loss: 1.246, Test accuracy: 61.48
Round  42, Global train loss: 1.068, Global test loss: 0.962, Global test accuracy: 69.93
Round  43, Train loss: 1.173, Test loss: 1.264, Test accuracy: 61.14
Round  43, Global train loss: 1.173, Global test loss: 0.954, Global test accuracy: 70.59
Round  44, Train loss: 1.044, Test loss: 1.260, Test accuracy: 61.15
Round  44, Global train loss: 1.044, Global test loss: 0.898, Global test accuracy: 71.54
Round  45, Train loss: 0.970, Test loss: 1.268, Test accuracy: 61.07
Round  45, Global train loss: 0.970, Global test loss: 0.917, Global test accuracy: 70.59
Round  46, Train loss: 1.025, Test loss: 1.261, Test accuracy: 61.22
Round  46, Global train loss: 1.025, Global test loss: 0.925, Global test accuracy: 70.89
Round  47, Train loss: 1.092, Test loss: 1.259, Test accuracy: 61.16
Round  47, Global train loss: 1.092, Global test loss: 0.953, Global test accuracy: 70.64
Round  48, Train loss: 1.061, Test loss: 1.263, Test accuracy: 61.26
Round  48, Global train loss: 1.061, Global test loss: 0.980, Global test accuracy: 69.74
Round  49, Train loss: 1.033, Test loss: 1.268, Test accuracy: 61.16
Round  49, Global train loss: 1.033, Global test loss: 0.911, Global test accuracy: 71.73
Round  50, Train loss: 1.053, Test loss: 1.275, Test accuracy: 60.79
Round  50, Global train loss: 1.053, Global test loss: 0.952, Global test accuracy: 70.37
Round  51, Train loss: 1.098, Test loss: 1.267, Test accuracy: 60.80
Round  51, Global train loss: 1.098, Global test loss: 0.969, Global test accuracy: 70.98
Round  52, Train loss: 0.990, Test loss: 1.263, Test accuracy: 61.14
Round  52, Global train loss: 0.990, Global test loss: 0.929, Global test accuracy: 70.82
Round  53, Train loss: 1.043, Test loss: 1.262, Test accuracy: 61.18
Round  53, Global train loss: 1.043, Global test loss: 0.935, Global test accuracy: 70.41
Round  54, Train loss: 0.994, Test loss: 1.268, Test accuracy: 61.01
Round  54, Global train loss: 0.994, Global test loss: 0.942, Global test accuracy: 70.58
Round  55, Train loss: 0.989, Test loss: 1.268, Test accuracy: 61.05
Round  55, Global train loss: 0.989, Global test loss: 0.866, Global test accuracy: 71.69
Round  56, Train loss: 1.040, Test loss: 1.271, Test accuracy: 60.97
Round  56, Global train loss: 1.040, Global test loss: 0.924, Global test accuracy: 70.94
Round  57, Train loss: 1.028, Test loss: 1.262, Test accuracy: 61.28
Round  57, Global train loss: 1.028, Global test loss: 0.930, Global test accuracy: 70.89
Round  58, Train loss: 1.022, Test loss: 1.263, Test accuracy: 61.23
Round  58, Global train loss: 1.022, Global test loss: 0.959, Global test accuracy: 69.70
Round  59, Train loss: 0.981, Test loss: 1.267, Test accuracy: 61.20
Round  59, Global train loss: 0.981, Global test loss: 0.964, Global test accuracy: 69.95
Round  60, Train loss: 1.061, Test loss: 1.272, Test accuracy: 61.35
Round  60, Global train loss: 1.061, Global test loss: 0.972, Global test accuracy: 69.53
Round  61, Train loss: 0.923, Test loss: 1.281, Test accuracy: 61.19
Round  61, Global train loss: 0.923, Global test loss: 0.923, Global test accuracy: 70.86
Round  62, Train loss: 1.030, Test loss: 1.292, Test accuracy: 60.99
Round  62, Global train loss: 1.030, Global test loss: 0.953, Global test accuracy: 70.10
Round  63, Train loss: 1.063, Test loss: 1.290, Test accuracy: 61.22
Round  63, Global train loss: 1.063, Global test loss: 0.954, Global test accuracy: 70.58
Round  64, Train loss: 0.914, Test loss: 1.295, Test accuracy: 61.20
Round  64, Global train loss: 0.914, Global test loss: 0.908, Global test accuracy: 71.36
Round  65, Train loss: 0.926, Test loss: 1.291, Test accuracy: 61.27
Round  65, Global train loss: 0.926, Global test loss: 0.937, Global test accuracy: 70.77
Round  66, Train loss: 0.903, Test loss: 1.286, Test accuracy: 61.27
Round  66, Global train loss: 0.903, Global test loss: 0.910, Global test accuracy: 71.12
Round  67, Train loss: 1.016, Test loss: 1.287, Test accuracy: 61.25
Round  67, Global train loss: 1.016, Global test loss: 1.008, Global test accuracy: 69.50
Round  68, Train loss: 0.928, Test loss: 1.285, Test accuracy: 61.35
Round  68, Global train loss: 0.928, Global test loss: 0.935, Global test accuracy: 70.58
Round  69, Train loss: 0.916, Test loss: 1.292, Test accuracy: 61.10
Round  69, Global train loss: 0.916, Global test loss: 0.967, Global test accuracy: 70.19
Round  70, Train loss: 0.922, Test loss: 1.289, Test accuracy: 61.09
Round  70, Global train loss: 0.922, Global test loss: 0.940, Global test accuracy: 70.48
Round  71, Train loss: 0.902, Test loss: 1.299, Test accuracy: 60.92
Round  71, Global train loss: 0.902, Global test loss: 0.952, Global test accuracy: 70.04
Round  72, Train loss: 0.857, Test loss: 1.322, Test accuracy: 60.76
Round  72, Global train loss: 0.857, Global test loss: 0.953, Global test accuracy: 70.62
Round  73, Train loss: 0.898, Test loss: 1.317, Test accuracy: 61.06
Round  73, Global train loss: 0.898, Global test loss: 0.961, Global test accuracy: 70.04
Round  74, Train loss: 0.918, Test loss: 1.319, Test accuracy: 60.77
Round  74, Global train loss: 0.918, Global test loss: 0.990, Global test accuracy: 68.79
Round  75, Train loss: 1.054, Test loss: 1.315, Test accuracy: 60.80
Round  75, Global train loss: 1.054, Global test loss: 0.984, Global test accuracy: 69.88
Round  76, Train loss: 0.968, Test loss: 1.320, Test accuracy: 60.81
Round  76, Global train loss: 0.968, Global test loss: 0.949, Global test accuracy: 70.07
Round  77, Train loss: 0.844, Test loss: 1.333, Test accuracy: 60.72
Round  77, Global train loss: 0.844, Global test loss: 1.006, Global test accuracy: 69.44
Round  78, Train loss: 0.943, Test loss: 1.329, Test accuracy: 60.72
Round  78, Global train loss: 0.943, Global test loss: 0.957, Global test accuracy: 70.18
Round  79, Train loss: 0.952, Test loss: 1.337, Test accuracy: 60.98
Round  79, Global train loss: 0.952, Global test loss: 0.990, Global test accuracy: 69.12
Round  80, Train loss: 0.939, Test loss: 1.328, Test accuracy: 61.05
Round  80, Global train loss: 0.939, Global test loss: 0.995, Global test accuracy: 69.53
Round  81, Train loss: 0.962, Test loss: 1.333, Test accuracy: 60.98
Round  81, Global train loss: 0.962, Global test loss: 1.005, Global test accuracy: 69.03
Round  82, Train loss: 0.956, Test loss: 1.340, Test accuracy: 60.81
Round  82, Global train loss: 0.956, Global test loss: 0.952, Global test accuracy: 70.13
Round  83, Train loss: 0.923, Test loss: 1.330, Test accuracy: 61.08
Round  83, Global train loss: 0.923, Global test loss: 0.936, Global test accuracy: 70.44
Round  84, Train loss: 0.902, Test loss: 1.338, Test accuracy: 60.79
Round  84, Global train loss: 0.902, Global test loss: 0.971, Global test accuracy: 70.17
Round  85, Train loss: 1.003, Test loss: 1.340, Test accuracy: 60.99
Round  85, Global train loss: 1.003, Global test loss: 0.993, Global test accuracy: 69.25
Round  86, Train loss: 0.950, Test loss: 1.338, Test accuracy: 60.88
Round  86, Global train loss: 0.950, Global test loss: 0.951, Global test accuracy: 70.54
Round  87, Train loss: 0.862, Test loss: 1.335, Test accuracy: 61.16
Round  87, Global train loss: 0.862, Global test loss: 0.953, Global test accuracy: 71.43
Round  88, Train loss: 0.933, Test loss: 1.337, Test accuracy: 61.05
Round  88, Global train loss: 0.933, Global test loss: 0.915, Global test accuracy: 71.26
Round  89, Train loss: 0.852, Test loss: 1.337, Test accuracy: 60.85
Round  89, Global train loss: 0.852, Global test loss: 0.887, Global test accuracy: 71.68
Round  90, Train loss: 0.918, Test loss: 1.334, Test accuracy: 60.99
Round  90, Global train loss: 0.918, Global test loss: 0.958, Global test accuracy: 70.11
Round  91, Train loss: 0.896, Test loss: 1.344, Test accuracy: 60.86
Round  91, Global train loss: 0.896, Global test loss: 0.990, Global test accuracy: 69.64
Round  92, Train loss: 0.921, Test loss: 1.350, Test accuracy: 60.72
Round  92, Global train loss: 0.921, Global test loss: 0.939, Global test accuracy: 70.93
Round  93, Train loss: 0.886, Test loss: 1.354, Test accuracy: 60.67
Round  93, Global train loss: 0.886, Global test loss: 0.946, Global test accuracy: 70.41
Round  94, Train loss: 0.941, Test loss: 1.350, Test accuracy: 60.71
Round  94, Global train loss: 0.941, Global test loss: 1.005, Global test accuracy: 69.13
Round  95, Train loss: 0.883, Test loss: 1.373, Test accuracy: 60.21
Round  95, Global train loss: 0.883, Global test loss: 0.946, Global test accuracy: 70.59
Round  96, Train loss: 0.916, Test loss: 1.359, Test accuracy: 60.63
Round  96, Global train loss: 0.916, Global test loss: 0.930, Global test accuracy: 71.58
Round  97, Train loss: 0.819, Test loss: 1.358, Test accuracy: 60.72
Round  97, Global train loss: 0.819, Global test loss: 0.964, Global test accuracy: 70.98
Round  98, Train loss: 0.836, Test loss: 1.372, Test accuracy: 60.84
Round  98, Global train loss: 0.836, Global test loss: 0.986, Global test accuracy: 70.18
Round  99, Train loss: 0.912, Test loss: 1.355, Test accuracy: 61.17
Round  99, Global train loss: 0.912, Global test loss: 0.989, Global test accuracy: 69.89
Final Round, Train loss: 0.553, Test loss: 1.532, Test accuracy: 61.38
Final Round, Global train loss: 0.553, Global test loss: 0.989, Global test accuracy: 69.89
Average accuracy final 10 rounds: 60.75225 

Average global accuracy final 10 rounds: 70.34450000000001 

6074.194339513779
[4.731787443161011, 9.463574886322021, 14.198622703552246, 18.93367052078247, 23.681042194366455, 28.42841386795044, 33.218562841415405, 38.00871181488037, 42.8112735748291, 47.61383533477783, 52.34756684303284, 57.08129835128784, 61.86050224304199, 66.63970613479614, 71.42792892456055, 76.21615171432495, 81.03146934509277, 85.8467869758606, 90.6441662311554, 95.4415454864502, 100.21769118309021, 104.99383687973022, 109.81956028938293, 114.64528369903564, 119.48966431617737, 124.33404493331909, 129.16085767745972, 133.98767042160034, 138.79789423942566, 143.60811805725098, 148.43564701080322, 153.26317596435547, 157.86390018463135, 162.46462440490723, 167.10401678085327, 171.74340915679932, 176.48107767105103, 181.21874618530273, 185.97546410560608, 190.73218202590942, 195.4675042629242, 200.20282649993896, 204.78682398796082, 209.37082147598267, 213.6723403930664, 217.97385931015015, 222.2660939693451, 226.55832862854004, 231.27658462524414, 235.99484062194824, 240.79001235961914, 245.58518409729004, 250.34985637664795, 255.11452865600586, 259.85003304481506, 264.58553743362427, 269.33819246292114, 274.090847492218, 278.8697328567505, 283.64861822128296, 288.3744442462921, 293.10027027130127, 297.83488965034485, 302.5695090293884, 307.33996057510376, 312.1104121208191, 316.70623683929443, 321.3020615577698, 325.9804496765137, 330.65883779525757, 335.2578282356262, 339.8568186759949, 344.5956792831421, 349.3345398902893, 353.95745301246643, 358.58036613464355, 363.3261296749115, 368.07189321517944, 372.76012206077576, 377.44835090637207, 382.1717028617859, 386.8950548171997, 391.53538632392883, 396.17571783065796, 400.7642903327942, 405.3528628349304, 409.9339790344238, 414.51509523391724, 419.1284828186035, 423.7418704032898, 428.41725420951843, 433.09263801574707, 437.8192002773285, 442.5457625389099, 447.16087579727173, 451.77598905563354, 456.44363474845886, 461.1112804412842, 465.85134744644165, 470.5914144515991, 475.391033411026, 480.1906523704529, 484.83017683029175, 489.4697012901306, 494.11362981796265, 498.7575583457947, 503.3854396343231, 508.01332092285156, 512.6048083305359, 517.1962957382202, 521.4891452789307, 525.7819948196411, 530.0442125797272, 534.3064303398132, 538.5075933933258, 542.7087564468384, 546.8812410831451, 551.0537257194519, 555.2010567188263, 559.3483877182007, 563.5259757041931, 567.7035636901855, 571.8800265789032, 576.0564894676208, 580.2329711914062, 584.4094529151917, 588.5557112693787, 592.7019696235657, 596.875513792038, 601.0490579605103, 605.2208104133606, 609.3925628662109, 613.6172759532928, 617.8419890403748, 622.0271453857422, 626.2123017311096, 630.4188776016235, 634.6254534721375, 638.9001240730286, 643.1747946739197, 647.4672291278839, 651.7596635818481, 656.0242555141449, 660.2888474464417, 664.5158243179321, 668.7428011894226, 672.9907009601593, 677.238600730896, 681.5073227882385, 685.776044845581, 690.035425901413, 694.2948069572449, 698.5752575397491, 702.8557081222534, 707.1286227703094, 711.4015374183655, 715.7005937099457, 719.9996500015259, 724.2509186267853, 728.5021872520447, 732.7260315418243, 736.949875831604, 741.1864356994629, 745.4229955673218, 749.7039337158203, 753.9848718643188, 758.2527844905853, 762.5206971168518, 766.7857773303986, 771.0508575439453, 775.3815248012543, 779.7121920585632, 783.9728436470032, 788.2334952354431, 792.4766871929169, 796.7198791503906, 800.9302000999451, 805.1405210494995, 809.350269317627, 813.5600175857544, 817.8264594078064, 822.0929012298584, 826.2838637828827, 830.474826335907, 834.6700978279114, 838.8653693199158, 843.0438075065613, 847.2222456932068, 851.4139585494995, 855.6056714057922, 859.7909483909607, 863.9762253761292, 868.1400866508484, 872.3039479255676, 876.5018718242645, 880.6997957229614, 884.9112527370453, 889.1227097511292, 893.3951070308685, 897.6675043106079, 899.8195321559906, 901.9715600013733]
[30.0225, 30.0225, 37.385, 37.385, 40.225, 40.225, 42.29, 42.29, 44.3725, 44.3725, 45.915, 45.915, 47.1825, 47.1825, 47.395, 47.395, 50.0425, 50.0425, 51.1975, 51.1975, 51.475, 51.475, 52.475, 52.475, 53.3, 53.3, 53.84, 53.84, 55.1075, 55.1075, 55.7575, 55.7575, 57.9775, 57.9775, 57.8775, 57.8775, 57.71, 57.71, 57.9075, 57.9075, 58.635, 58.635, 58.8325, 58.8325, 59.19, 59.19, 59.5875, 59.5875, 60.02, 60.02, 60.065, 60.065, 60.52, 60.52, 60.525, 60.525, 60.6425, 60.6425, 61.045, 61.045, 60.8075, 60.8075, 60.8675, 60.8675, 61.215, 61.215, 61.21, 61.21, 61.4, 61.4, 61.5075, 61.5075, 61.41, 61.41, 61.2575, 61.2575, 61.3275, 61.3275, 61.0475, 61.0475, 61.2425, 61.2425, 61.4025, 61.4025, 61.485, 61.485, 61.1425, 61.1425, 61.145, 61.145, 61.0725, 61.0725, 61.2225, 61.2225, 61.155, 61.155, 61.255, 61.255, 61.1625, 61.1625, 60.7875, 60.7875, 60.7975, 60.7975, 61.1425, 61.1425, 61.18, 61.18, 61.005, 61.005, 61.045, 61.045, 60.9725, 60.9725, 61.2775, 61.2775, 61.23, 61.23, 61.195, 61.195, 61.3525, 61.3525, 61.1925, 61.1925, 60.99, 60.99, 61.2175, 61.2175, 61.195, 61.195, 61.265, 61.265, 61.27, 61.27, 61.25, 61.25, 61.3525, 61.3525, 61.105, 61.105, 61.09, 61.09, 60.9225, 60.9225, 60.755, 60.755, 61.0625, 61.0625, 60.7675, 60.7675, 60.8, 60.8, 60.81, 60.81, 60.7225, 60.7225, 60.72, 60.72, 60.9825, 60.9825, 61.05, 61.05, 60.98, 60.98, 60.8075, 60.8075, 61.075, 61.075, 60.7925, 60.7925, 60.99, 60.99, 60.885, 60.885, 61.1625, 61.1625, 61.0525, 61.0525, 60.85, 60.85, 60.9875, 60.9875, 60.86, 60.86, 60.72, 60.72, 60.67, 60.67, 60.71, 60.71, 60.2125, 60.2125, 60.6275, 60.6275, 60.7225, 60.7225, 60.8425, 60.8425, 61.17, 61.17, 61.375, 61.375]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.6 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 1, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
   Client 15, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 13, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 0, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 18, noise    level: 0.5000 
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.123, Test loss: 2.012, Test accuracy: 28.68
Round   0, Global train loss: 2.123, Global test loss: 2.010, Global test accuracy: 29.57
Round   1, Train loss: 1.967, Test loss: 1.837, Test accuracy: 33.96
Round   1, Global train loss: 1.967, Global test loss: 1.745, Global test accuracy: 38.55
Round   2, Train loss: 1.872, Test loss: 1.786, Test accuracy: 35.30
Round   2, Global train loss: 1.872, Global test loss: 1.640, Global test accuracy: 41.28
Round   3, Train loss: 1.852, Test loss: 1.727, Test accuracy: 37.88
Round   3, Global train loss: 1.852, Global test loss: 1.574, Global test accuracy: 46.06
Round   4, Train loss: 1.781, Test loss: 1.680, Test accuracy: 39.41
Round   4, Global train loss: 1.781, Global test loss: 1.508, Global test accuracy: 47.66
Round   5, Train loss: 1.785, Test loss: 1.647, Test accuracy: 41.17
Round   5, Global train loss: 1.785, Global test loss: 1.494, Global test accuracy: 49.67
Round   6, Train loss: 1.775, Test loss: 1.631, Test accuracy: 41.98
Round   6, Global train loss: 1.775, Global test loss: 1.457, Global test accuracy: 51.92
Round   7, Train loss: 1.718, Test loss: 1.601, Test accuracy: 43.01
Round   7, Global train loss: 1.718, Global test loss: 1.406, Global test accuracy: 53.26
Round   8, Train loss: 1.666, Test loss: 1.550, Test accuracy: 45.47
Round   8, Global train loss: 1.666, Global test loss: 1.386, Global test accuracy: 55.23
Round   9, Train loss: 1.617, Test loss: 1.538, Test accuracy: 45.75
Round   9, Global train loss: 1.617, Global test loss: 1.313, Global test accuracy: 55.96
Round  10, Train loss: 1.662, Test loss: 1.515, Test accuracy: 46.60
Round  10, Global train loss: 1.662, Global test loss: 1.316, Global test accuracy: 56.42
Round  11, Train loss: 1.630, Test loss: 1.487, Test accuracy: 47.92
Round  11, Global train loss: 1.630, Global test loss: 1.296, Global test accuracy: 58.30
Round  12, Train loss: 1.631, Test loss: 1.472, Test accuracy: 48.77
Round  12, Global train loss: 1.631, Global test loss: 1.303, Global test accuracy: 59.25
Round  13, Train loss: 1.613, Test loss: 1.452, Test accuracy: 49.77
Round  13, Global train loss: 1.613, Global test loss: 1.260, Global test accuracy: 59.87
Round  14, Train loss: 1.517, Test loss: 1.419, Test accuracy: 51.19
Round  14, Global train loss: 1.517, Global test loss: 1.224, Global test accuracy: 59.90
Round  15, Train loss: 1.482, Test loss: 1.400, Test accuracy: 51.78
Round  15, Global train loss: 1.482, Global test loss: 1.187, Global test accuracy: 61.25
Round  16, Train loss: 1.517, Test loss: 1.352, Test accuracy: 54.04
Round  16, Global train loss: 1.517, Global test loss: 1.203, Global test accuracy: 61.66
Round  17, Train loss: 1.571, Test loss: 1.342, Test accuracy: 54.80
Round  17, Global train loss: 1.571, Global test loss: 1.206, Global test accuracy: 63.14
Round  18, Train loss: 1.461, Test loss: 1.342, Test accuracy: 54.81
Round  18, Global train loss: 1.461, Global test loss: 1.141, Global test accuracy: 64.03
Round  19, Train loss: 1.406, Test loss: 1.330, Test accuracy: 55.47
Round  19, Global train loss: 1.406, Global test loss: 1.137, Global test accuracy: 64.50
Round  20, Train loss: 1.402, Test loss: 1.314, Test accuracy: 56.04
Round  20, Global train loss: 1.402, Global test loss: 1.105, Global test accuracy: 64.20
Round  21, Train loss: 1.360, Test loss: 1.319, Test accuracy: 55.75
Round  21, Global train loss: 1.360, Global test loss: 1.091, Global test accuracy: 64.92
Round  22, Train loss: 1.487, Test loss: 1.310, Test accuracy: 56.19
Round  22, Global train loss: 1.487, Global test loss: 1.125, Global test accuracy: 65.50
Round  23, Train loss: 1.339, Test loss: 1.303, Test accuracy: 56.56
Round  23, Global train loss: 1.339, Global test loss: 1.074, Global test accuracy: 65.49
Round  24, Train loss: 1.569, Test loss: 1.301, Test accuracy: 57.00
Round  24, Global train loss: 1.569, Global test loss: 1.164, Global test accuracy: 66.71
Round  25, Train loss: 1.434, Test loss: 1.300, Test accuracy: 56.90
Round  25, Global train loss: 1.434, Global test loss: 1.115, Global test accuracy: 67.06
Round  26, Train loss: 1.448, Test loss: 1.281, Test accuracy: 57.65
Round  26, Global train loss: 1.448, Global test loss: 1.097, Global test accuracy: 66.33
Round  27, Train loss: 1.384, Test loss: 1.279, Test accuracy: 58.23
Round  27, Global train loss: 1.384, Global test loss: 1.080, Global test accuracy: 67.56
Round  28, Train loss: 1.398, Test loss: 1.253, Test accuracy: 59.31
Round  28, Global train loss: 1.398, Global test loss: 1.059, Global test accuracy: 67.92
Round  29, Train loss: 1.305, Test loss: 1.244, Test accuracy: 59.81
Round  29, Global train loss: 1.305, Global test loss: 1.031, Global test accuracy: 67.25
Round  30, Train loss: 1.257, Test loss: 1.244, Test accuracy: 59.92
Round  30, Global train loss: 1.257, Global test loss: 1.009, Global test accuracy: 68.09
Round  31, Train loss: 1.304, Test loss: 1.235, Test accuracy: 60.16
Round  31, Global train loss: 1.304, Global test loss: 1.026, Global test accuracy: 68.03
Round  32, Train loss: 1.305, Test loss: 1.226, Test accuracy: 60.41
Round  32, Global train loss: 1.305, Global test loss: 1.020, Global test accuracy: 68.39
Round  33, Train loss: 1.305, Test loss: 1.218, Test accuracy: 60.61
Round  33, Global train loss: 1.305, Global test loss: 1.004, Global test accuracy: 69.05
Round  34, Train loss: 1.273, Test loss: 1.203, Test accuracy: 61.13
Round  34, Global train loss: 1.273, Global test loss: 0.992, Global test accuracy: 68.84
Round  35, Train loss: 1.334, Test loss: 1.203, Test accuracy: 60.94
Round  35, Global train loss: 1.334, Global test loss: 1.024, Global test accuracy: 68.75
Round  36, Train loss: 1.300, Test loss: 1.197, Test accuracy: 61.42
Round  36, Global train loss: 1.300, Global test loss: 1.006, Global test accuracy: 68.71
Round  37, Train loss: 1.332, Test loss: 1.193, Test accuracy: 61.58
Round  37, Global train loss: 1.332, Global test loss: 1.030, Global test accuracy: 68.84
Round  38, Train loss: 1.369, Test loss: 1.181, Test accuracy: 62.03
Round  38, Global train loss: 1.369, Global test loss: 1.023, Global test accuracy: 69.23
Round  39, Train loss: 1.257, Test loss: 1.188, Test accuracy: 61.51
Round  39, Global train loss: 1.257, Global test loss: 0.979, Global test accuracy: 69.67
Round  40, Train loss: 1.313, Test loss: 1.186, Test accuracy: 61.71
Round  40, Global train loss: 1.313, Global test loss: 1.011, Global test accuracy: 69.34
Round  41, Train loss: 1.287, Test loss: 1.174, Test accuracy: 62.41
Round  41, Global train loss: 1.287, Global test loss: 1.019, Global test accuracy: 69.27
Round  42, Train loss: 1.225, Test loss: 1.176, Test accuracy: 62.17
Round  42, Global train loss: 1.225, Global test loss: 0.973, Global test accuracy: 69.28
Round  43, Train loss: 1.370, Test loss: 1.176, Test accuracy: 62.05
Round  43, Global train loss: 1.370, Global test loss: 0.993, Global test accuracy: 70.19
Round  44, Train loss: 1.211, Test loss: 1.174, Test accuracy: 62.27
Round  44, Global train loss: 1.211, Global test loss: 0.955, Global test accuracy: 70.45
Round  45, Train loss: 1.214, Test loss: 1.176, Test accuracy: 62.18
Round  45, Global train loss: 1.214, Global test loss: 0.951, Global test accuracy: 70.55
Round  46, Train loss: 1.351, Test loss: 1.182, Test accuracy: 61.77
Round  46, Global train loss: 1.351, Global test loss: 1.011, Global test accuracy: 70.37
Round  47, Train loss: 1.135, Test loss: 1.168, Test accuracy: 62.34
Round  47, Global train loss: 1.135, Global test loss: 0.922, Global test accuracy: 70.74
Round  48, Train loss: 1.222, Test loss: 1.163, Test accuracy: 62.53
Round  48, Global train loss: 1.222, Global test loss: 0.953, Global test accuracy: 70.93
Round  49, Train loss: 1.275, Test loss: 1.156, Test accuracy: 62.95
Round  49, Global train loss: 1.275, Global test loss: 1.006, Global test accuracy: 70.36
Round  50, Train loss: 1.278, Test loss: 1.151, Test accuracy: 62.72
Round  50, Global train loss: 1.278, Global test loss: 0.992, Global test accuracy: 69.96
Round  51, Train loss: 1.196, Test loss: 1.149, Test accuracy: 62.70
Round  51, Global train loss: 1.196, Global test loss: 0.944, Global test accuracy: 70.28
Round  52, Train loss: 1.175, Test loss: 1.158, Test accuracy: 62.69
Round  52, Global train loss: 1.175, Global test loss: 0.940, Global test accuracy: 70.25
Round  53, Train loss: 1.115, Test loss: 1.155, Test accuracy: 62.90
Round  53, Global train loss: 1.115, Global test loss: 0.922, Global test accuracy: 70.96
Round  54, Train loss: 1.243, Test loss: 1.159, Test accuracy: 62.82
Round  54, Global train loss: 1.243, Global test loss: 1.027, Global test accuracy: 68.00
Round  55, Train loss: 1.215, Test loss: 1.145, Test accuracy: 63.15
Round  55, Global train loss: 1.215, Global test loss: 0.940, Global test accuracy: 71.17
Round  56, Train loss: 1.191, Test loss: 1.157, Test accuracy: 62.85
Round  56, Global train loss: 1.191, Global test loss: 0.930, Global test accuracy: 71.30
Round  57, Train loss: 1.231, Test loss: 1.149, Test accuracy: 63.09
Round  57, Global train loss: 1.231, Global test loss: 0.966, Global test accuracy: 70.67
Round  58, Train loss: 1.191, Test loss: 1.152, Test accuracy: 62.65
Round  58, Global train loss: 1.191, Global test loss: 0.941, Global test accuracy: 71.08
Round  59, Train loss: 1.077, Test loss: 1.156, Test accuracy: 62.52
Round  59, Global train loss: 1.077, Global test loss: 0.898, Global test accuracy: 71.78
Round  60, Train loss: 1.136, Test loss: 1.152, Test accuracy: 62.69
Round  60, Global train loss: 1.136, Global test loss: 0.904, Global test accuracy: 71.97
Round  61, Train loss: 1.287, Test loss: 1.154, Test accuracy: 62.81
Round  61, Global train loss: 1.287, Global test loss: 0.997, Global test accuracy: 71.07
Round  62, Train loss: 1.227, Test loss: 1.160, Test accuracy: 62.98
Round  62, Global train loss: 1.227, Global test loss: 0.963, Global test accuracy: 71.19
Round  63, Train loss: 1.146, Test loss: 1.154, Test accuracy: 63.28
Round  63, Global train loss: 1.146, Global test loss: 0.904, Global test accuracy: 71.83
Round  64, Train loss: 1.172, Test loss: 1.144, Test accuracy: 63.31
Round  64, Global train loss: 1.172, Global test loss: 0.918, Global test accuracy: 71.56
Round  65, Train loss: 1.110, Test loss: 1.138, Test accuracy: 63.58
Round  65, Global train loss: 1.110, Global test loss: 0.892, Global test accuracy: 72.05
Round  66, Train loss: 1.081, Test loss: 1.149, Test accuracy: 63.22
Round  66, Global train loss: 1.081, Global test loss: 0.921, Global test accuracy: 71.09
Round  67, Train loss: 1.190, Test loss: 1.147, Test accuracy: 63.33
Round  67, Global train loss: 1.190, Global test loss: 0.957, Global test accuracy: 70.73
Round  68, Train loss: 1.039, Test loss: 1.148, Test accuracy: 63.45
Round  68, Global train loss: 1.039, Global test loss: 0.890, Global test accuracy: 71.97
Round  69, Train loss: 1.095, Test loss: 1.151, Test accuracy: 63.44
Round  69, Global train loss: 1.095, Global test loss: 0.918, Global test accuracy: 71.67
Round  70, Train loss: 1.058, Test loss: 1.144, Test accuracy: 63.61
Round  70, Global train loss: 1.058, Global test loss: 0.897, Global test accuracy: 71.68
Round  71, Train loss: 1.055, Test loss: 1.150, Test accuracy: 63.57
Round  71, Global train loss: 1.055, Global test loss: 0.884, Global test accuracy: 72.03
Round  72, Train loss: 1.058, Test loss: 1.141, Test accuracy: 63.73
Round  72, Global train loss: 1.058, Global test loss: 0.892, Global test accuracy: 71.72
Round  73, Train loss: 1.115, Test loss: 1.158, Test accuracy: 63.12
Round  73, Global train loss: 1.115, Global test loss: 0.905, Global test accuracy: 71.61
Round  74, Train loss: 1.144, Test loss: 1.154, Test accuracy: 63.00
Round  74, Global train loss: 1.144, Global test loss: 0.935, Global test accuracy: 71.29
Round  75, Train loss: 1.108, Test loss: 1.152, Test accuracy: 63.12
Round  75, Global train loss: 1.108, Global test loss: 0.926, Global test accuracy: 70.94
Round  76, Train loss: 1.052, Test loss: 1.147, Test accuracy: 63.44
Round  76, Global train loss: 1.052, Global test loss: 0.887, Global test accuracy: 71.68
Round  77, Train loss: 1.031, Test loss: 1.156, Test accuracy: 62.91
Round  77, Global train loss: 1.031, Global test loss: 0.877, Global test accuracy: 71.79
Round  78, Train loss: 1.160, Test loss: 1.167, Test accuracy: 62.55
Round  78, Global train loss: 1.160, Global test loss: 0.921, Global test accuracy: 71.42
Round  79, Train loss: 1.177, Test loss: 1.159, Test accuracy: 62.84
Round  79, Global train loss: 1.177, Global test loss: 0.930, Global test accuracy: 71.88
Round  80, Train loss: 1.090, Test loss: 1.152, Test accuracy: 63.28
Round  80, Global train loss: 1.090, Global test loss: 0.890, Global test accuracy: 72.15
Round  81, Train loss: 1.152, Test loss: 1.152, Test accuracy: 63.48
Round  81, Global train loss: 1.152, Global test loss: 0.934, Global test accuracy: 71.17
Round  82, Train loss: 1.086, Test loss: 1.141, Test accuracy: 63.72
Round  82, Global train loss: 1.086, Global test loss: 0.891, Global test accuracy: 72.14
Round  83, Train loss: 1.041, Test loss: 1.139, Test accuracy: 63.76
Round  83, Global train loss: 1.041, Global test loss: 0.884, Global test accuracy: 71.62
Round  84, Train loss: 1.039, Test loss: 1.129, Test accuracy: 64.14
Round  84, Global train loss: 1.039, Global test loss: 0.886, Global test accuracy: 72.35
Round  85, Train loss: 1.063, Test loss: 1.131, Test accuracy: 64.29
Round  85, Global train loss: 1.063, Global test loss: 0.900, Global test accuracy: 71.94
Round  86, Train loss: 1.114, Test loss: 1.133, Test accuracy: 64.23
Round  86, Global train loss: 1.114, Global test loss: 0.920, Global test accuracy: 71.10
Round  87, Train loss: 1.080, Test loss: 1.141, Test accuracy: 63.88
Round  87, Global train loss: 1.080, Global test loss: 0.941, Global test accuracy: 70.36
Round  88, Train loss: 1.044, Test loss: 1.148, Test accuracy: 63.42
Round  88, Global train loss: 1.044, Global test loss: 0.893, Global test accuracy: 71.12
Round  89, Train loss: 0.977, Test loss: 1.148, Test accuracy: 63.33
Round  89, Global train loss: 0.977, Global test loss: 0.904, Global test accuracy: 71.38
Round  90, Train loss: 1.060, Test loss: 1.139, Test accuracy: 63.80
Round  90, Global train loss: 1.060, Global test loss: 0.925, Global test accuracy: 71.22
Round  91, Train loss: 0.990, Test loss: 1.134, Test accuracy: 64.10
Round  91, Global train loss: 0.990, Global test loss: 0.882, Global test accuracy: 72.26
Round  92, Train loss: 1.026, Test loss: 1.128, Test accuracy: 64.52
Round  92, Global train loss: 1.026, Global test loss: 0.880, Global test accuracy: 72.21/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  93, Train loss: 1.053, Test loss: 1.134, Test accuracy: 64.43
Round  93, Global train loss: 1.053, Global test loss: 0.895, Global test accuracy: 71.61
Round  94, Train loss: 0.935, Test loss: 1.140, Test accuracy: 64.19
Round  94, Global train loss: 0.935, Global test loss: 0.906, Global test accuracy: 71.31
Round  95, Train loss: 0.951, Test loss: 1.151, Test accuracy: 64.11
Round  95, Global train loss: 0.951, Global test loss: 0.873, Global test accuracy: 71.83
Round  96, Train loss: 1.053, Test loss: 1.155, Test accuracy: 63.97
Round  96, Global train loss: 1.053, Global test loss: 0.899, Global test accuracy: 71.70
Round  97, Train loss: 1.054, Test loss: 1.155, Test accuracy: 63.66
Round  97, Global train loss: 1.054, Global test loss: 0.877, Global test accuracy: 72.64
Round  98, Train loss: 1.003, Test loss: 1.149, Test accuracy: 63.83
Round  98, Global train loss: 1.003, Global test loss: 0.894, Global test accuracy: 71.79
Round  99, Train loss: 0.955, Test loss: 1.163, Test accuracy: 63.77
Round  99, Global train loss: 0.955, Global test loss: 0.932, Global test accuracy: 69.97
Final Round, Train loss: 0.711, Test loss: 1.303, Test accuracy: 62.15
Final Round, Global train loss: 0.711, Global test loss: 0.932, Global test accuracy: 69.97
Average accuracy final 10 rounds: 64.038 

Average global accuracy final 10 rounds: 71.655 

6469.3536739349365
[5.479018688201904, 10.958037376403809, 16.16689920425415, 21.375761032104492, 26.61277961730957, 31.84979820251465, 37.111655950546265, 42.37351369857788, 47.60262489318848, 52.83173608779907, 58.036133766174316, 63.24053144454956, 68.43157529830933, 73.62261915206909, 78.83229947090149, 84.04197978973389, 89.27160096168518, 94.50122213363647, 99.71704006195068, 104.93285799026489, 110.11500215530396, 115.29714632034302, 120.48340940475464, 125.66967248916626, 130.86191034317017, 136.05414819717407, 141.25111150741577, 146.44807481765747, 151.34201836585999, 156.2359619140625, 161.03372526168823, 165.83148860931396, 170.55868458747864, 175.2858805656433, 180.6078336238861, 185.9297866821289, 191.3504753112793, 196.7711639404297, 202.21889209747314, 207.6666202545166, 213.12988352775574, 218.59314680099487, 224.05475234985352, 229.51635789871216, 234.96387577056885, 240.41139364242554, 245.872239112854, 251.33308458328247, 256.74264001846313, 262.1521954536438, 267.60104298591614, 273.0498905181885, 278.29330229759216, 283.53671407699585, 288.3106243610382, 293.08453464508057, 297.84012365341187, 302.59571266174316, 307.3783881664276, 312.16106367111206, 316.9682734012604, 321.7754831314087, 326.5931134223938, 331.4107437133789, 336.2284014225006, 341.0460591316223, 345.8034882545471, 350.5609173774719, 355.4590699672699, 360.35722255706787, 365.3068199157715, 370.2564172744751, 375.0297517776489, 379.80308628082275, 384.5833008289337, 389.3635153770447, 394.1063086986542, 398.8491020202637, 403.6013152599335, 408.35352849960327, 413.11738419532776, 417.88123989105225, 422.6121847629547, 427.3431296348572, 432.0827696323395, 436.8224096298218, 441.57998752593994, 446.3375654220581, 451.07482385635376, 455.8120822906494, 460.54156279563904, 465.27104330062866, 469.979266166687, 474.68748903274536, 479.4562916755676, 484.2250943183899, 488.94700264930725, 493.6689109802246, 498.40810108184814, 503.1472911834717, 507.88766503334045, 512.6280388832092, 517.3873949050903, 522.1467509269714, 526.867648601532, 531.5885462760925, 536.316351890564, 541.0441575050354, 545.8060240745544, 550.5678906440735, 555.3275773525238, 560.0872640609741, 564.8322854042053, 569.5773067474365, 574.3446583747864, 579.1120100021362, 583.873304605484, 588.6345992088318, 593.4452991485596, 598.2559990882874, 603.0255391597748, 607.7950792312622, 612.5417091846466, 617.288339138031, 622.0337631702423, 626.7791872024536, 631.5601074695587, 636.3410277366638, 641.0984246730804, 645.8558216094971, 650.5856401920319, 655.3154587745667, 660.064122915268, 664.8127870559692, 669.5586206912994, 674.3044543266296, 679.0542871952057, 683.8041200637817, 688.5050361156464, 693.205952167511, 697.9348211288452, 702.6636900901794, 707.4229593276978, 712.1822285652161, 716.918693780899, 721.655158996582, 726.4115407466888, 731.1679224967957, 735.9054145812988, 740.642906665802, 745.4076170921326, 750.1723275184631, 755.0001332759857, 759.8279390335083, 764.5598113536835, 769.2916836738586, 774.0245108604431, 778.7573380470276, 783.5021650791168, 788.246992111206, 793.020604133606, 797.7942161560059, 802.5706655979156, 807.3471150398254, 812.1168451309204, 816.8865752220154, 821.649386882782, 826.4121985435486, 831.13134765625, 835.8504967689514, 840.5640170574188, 845.2775373458862, 849.9807121753693, 854.6838870048523, 859.4228463172913, 864.1618056297302, 868.89613032341, 873.6304550170898, 878.3331592082977, 883.0358633995056, 887.8251421451569, 892.6144208908081, 897.3756794929504, 902.1369380950928, 906.9004776477814, 911.66401720047, 916.4224045276642, 921.1807918548584, 925.9165482521057, 930.652304649353, 935.4063241481781, 940.1603436470032, 944.9014279842377, 949.6425123214722, 954.355094909668, 959.0676774978638, 963.8099117279053, 968.5521459579468, 973.3345439434052, 978.1169419288635, 980.4814193248749, 982.8458967208862]
[28.68, 28.68, 33.9625, 33.9625, 35.3025, 35.3025, 37.8825, 37.8825, 39.405, 39.405, 41.17, 41.17, 41.9825, 41.9825, 43.005, 43.005, 45.4725, 45.4725, 45.7475, 45.7475, 46.6, 46.6, 47.925, 47.925, 48.77, 48.77, 49.775, 49.775, 51.185, 51.185, 51.78, 51.78, 54.0425, 54.0425, 54.795, 54.795, 54.8125, 54.8125, 55.47, 55.47, 56.04, 56.04, 55.7475, 55.7475, 56.185, 56.185, 56.5625, 56.5625, 57.0, 57.0, 56.9, 56.9, 57.645, 57.645, 58.23, 58.23, 59.315, 59.315, 59.8075, 59.8075, 59.9225, 59.9225, 60.16, 60.16, 60.41, 60.41, 60.6075, 60.6075, 61.13, 61.13, 60.9375, 60.9375, 61.425, 61.425, 61.5775, 61.5775, 62.0275, 62.0275, 61.5125, 61.5125, 61.71, 61.71, 62.405, 62.405, 62.17, 62.17, 62.0525, 62.0525, 62.27, 62.27, 62.18, 62.18, 61.7725, 61.7725, 62.3375, 62.3375, 62.535, 62.535, 62.955, 62.955, 62.7225, 62.7225, 62.7, 62.7, 62.685, 62.685, 62.8975, 62.8975, 62.8175, 62.8175, 63.15, 63.15, 62.8525, 62.8525, 63.09, 63.09, 62.65, 62.65, 62.515, 62.515, 62.69, 62.69, 62.815, 62.815, 62.975, 62.975, 63.2775, 63.2775, 63.315, 63.315, 63.58, 63.58, 63.2225, 63.2225, 63.33, 63.33, 63.4475, 63.4475, 63.4375, 63.4375, 63.6125, 63.6125, 63.5725, 63.5725, 63.73, 63.73, 63.1175, 63.1175, 62.9975, 62.9975, 63.1225, 63.1225, 63.4425, 63.4425, 62.91, 62.91, 62.5525, 62.5525, 62.8375, 62.8375, 63.2825, 63.2825, 63.4775, 63.4775, 63.7225, 63.7225, 63.7575, 63.7575, 64.14, 64.14, 64.2875, 64.2875, 64.235, 64.235, 63.885, 63.885, 63.4175, 63.4175, 63.3325, 63.3325, 63.805, 63.805, 64.1, 64.1, 64.5225, 64.5225, 64.4275, 64.4275, 64.185, 64.185, 64.1125, 64.1125, 63.97, 63.97, 63.6625, 63.6625, 63.825, 63.825, 63.77, 63.77, 62.1525, 62.1525]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Co-teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 10, noise    level: 0.5000 
   Client 11, noise    level: 0.5000 
   Client 0, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
   Client 17, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 14, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 7, noise    level: 0.5000 
   Client 19, noise    level: 0.5000 
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 2.241, Test loss: 1.956, Test accuracy: 32.32
Round   1, Train loss: 1.886, Test loss: 1.632, Test accuracy: 41.33
Round   2, Train loss: 1.671, Test loss: 1.536, Test accuracy: 44.83
Round   3, Train loss: 1.581, Test loss: 1.437, Test accuracy: 48.46
Round   4, Train loss: 1.500, Test loss: 1.349, Test accuracy: 52.04
Round   5, Train loss: 1.433, Test loss: 1.296, Test accuracy: 54.54
Round   6, Train loss: 1.351, Test loss: 1.274, Test accuracy: 55.48
Round   7, Train loss: 1.313, Test loss: 1.228, Test accuracy: 57.68
Round   8, Train loss: 1.281, Test loss: 1.154, Test accuracy: 60.28
Round   9, Train loss: 1.222, Test loss: 1.126, Test accuracy: 61.71
Round  10, Train loss: 1.186, Test loss: 1.107, Test accuracy: 62.26
Round  11, Train loss: 1.137, Test loss: 1.079, Test accuracy: 63.37
Round  12, Train loss: 1.118, Test loss: 1.044, Test accuracy: 64.15
Round  13, Train loss: 1.088, Test loss: 1.040, Test accuracy: 64.34
Round  14, Train loss: 1.061, Test loss: 1.006, Test accuracy: 65.74
Round  15, Train loss: 1.018, Test loss: 1.007, Test accuracy: 65.66
Round  16, Train loss: 1.035, Test loss: 0.969, Test accuracy: 66.34
Round  17, Train loss: 0.993, Test loss: 0.940, Test accuracy: 67.55
Round  18, Train loss: 0.980, Test loss: 0.928, Test accuracy: 68.13
Round  19, Train loss: 0.947, Test loss: 0.910, Test accuracy: 68.64
Round  20, Train loss: 0.933, Test loss: 0.892, Test accuracy: 69.37
Round  21, Train loss: 0.923, Test loss: 0.887, Test accuracy: 69.64
Round  22, Train loss: 0.899, Test loss: 0.868, Test accuracy: 70.12
Round  23, Train loss: 0.896, Test loss: 0.862, Test accuracy: 70.32
Round  24, Train loss: 0.891, Test loss: 0.837, Test accuracy: 71.60
Round  25, Train loss: 0.852, Test loss: 0.835, Test accuracy: 71.41
Round  26, Train loss: 0.837, Test loss: 0.815, Test accuracy: 72.16
Round  27, Train loss: 0.823, Test loss: 0.825, Test accuracy: 71.88
Round  28, Train loss: 0.843, Test loss: 0.791, Test accuracy: 72.88
Round  29, Train loss: 0.797, Test loss: 0.796, Test accuracy: 72.62
Round  30, Train loss: 0.769, Test loss: 0.808, Test accuracy: 72.36
Round  31, Train loss: 0.808, Test loss: 0.792, Test accuracy: 72.79
Round  32, Train loss: 0.777, Test loss: 0.778, Test accuracy: 73.38
Round  33, Train loss: 0.739, Test loss: 0.791, Test accuracy: 72.82
Round  34, Train loss: 0.756, Test loss: 0.774, Test accuracy: 73.31
Round  35, Train loss: 0.759, Test loss: 0.767, Test accuracy: 73.40
Round  36, Train loss: 0.720, Test loss: 0.780, Test accuracy: 72.91
Round  37, Train loss: 0.733, Test loss: 0.766, Test accuracy: 73.73
Round  38, Train loss: 0.739, Test loss: 0.744, Test accuracy: 74.59
Round  39, Train loss: 0.729, Test loss: 0.756, Test accuracy: 74.16
Round  40, Train loss: 0.714, Test loss: 0.758, Test accuracy: 74.11
Round  41, Train loss: 0.695, Test loss: 0.748, Test accuracy: 74.34
Round  42, Train loss: 0.699, Test loss: 0.743, Test accuracy: 74.46
Round  43, Train loss: 0.715, Test loss: 0.733, Test accuracy: 74.75
Round  44, Train loss: 0.695, Test loss: 0.735, Test accuracy: 74.97
Round  45, Train loss: 0.673, Test loss: 0.728, Test accuracy: 75.16
Round  46, Train loss: 0.673, Test loss: 0.724, Test accuracy: 75.34
Round  47, Train loss: 0.678, Test loss: 0.731, Test accuracy: 75.06
Round  48, Train loss: 0.662, Test loss: 0.717, Test accuracy: 75.56
Round  49, Train loss: 0.636, Test loss: 0.723, Test accuracy: 75.28
Round  50, Train loss: 0.653, Test loss: 0.718, Test accuracy: 75.71
Round  51, Train loss: 0.644, Test loss: 0.718, Test accuracy: 75.76
Round  52, Train loss: 0.612, Test loss: 0.717, Test accuracy: 75.42
Round  53, Train loss: 0.638, Test loss: 0.722, Test accuracy: 76.16
Round  54, Train loss: 0.598, Test loss: 0.723, Test accuracy: 75.78
Round  55, Train loss: 0.620, Test loss: 0.718, Test accuracy: 75.88
Round  56, Train loss: 0.622, Test loss: 0.721, Test accuracy: 75.81
Round  57, Train loss: 0.611, Test loss: 0.730, Test accuracy: 75.80
Round  58, Train loss: 0.588, Test loss: 0.737, Test accuracy: 75.52
Round  59, Train loss: 0.594, Test loss: 0.738, Test accuracy: 75.55
Round  60, Train loss: 0.595, Test loss: 0.727, Test accuracy: 75.62
Round  61, Train loss: 0.601, Test loss: 0.722, Test accuracy: 76.19
Round  62, Train loss: 0.606, Test loss: 0.711, Test accuracy: 76.01
Round  63, Train loss: 0.614, Test loss: 0.706, Test accuracy: 76.33
Round  64, Train loss: 0.566, Test loss: 0.705, Test accuracy: 76.46
Round  65, Train loss: 0.587, Test loss: 0.699, Test accuracy: 76.74
Round  66, Train loss: 0.566, Test loss: 0.692, Test accuracy: 76.83
Round  67, Train loss: 0.569, Test loss: 0.700, Test accuracy: 76.64
Round  68, Train loss: 0.577, Test loss: 0.697, Test accuracy: 76.84
Round  69, Train loss: 0.546, Test loss: 0.697, Test accuracy: 76.79
Round  70, Train loss: 0.550, Test loss: 0.694, Test accuracy: 77.25
Round  71, Train loss: 0.562, Test loss: 0.693, Test accuracy: 76.98
Round  72, Train loss: 0.529, Test loss: 0.699, Test accuracy: 76.94
Round  73, Train loss: 0.549, Test loss: 0.701, Test accuracy: 76.92
Round  74, Train loss: 0.562, Test loss: 0.696, Test accuracy: 76.85
Round  75, Train loss: 0.550, Test loss: 0.693, Test accuracy: 77.16
Round  76, Train loss: 0.545, Test loss: 0.699, Test accuracy: 76.94
Round  77, Train loss: 0.543, Test loss: 0.694, Test accuracy: 77.15
Round  78, Train loss: 0.560, Test loss: 0.690, Test accuracy: 76.94
Round  79, Train loss: 0.544, Test loss: 0.695, Test accuracy: 77.16
Round  80, Train loss: 0.537, Test loss: 0.695, Test accuracy: 77.28
Round  81, Train loss: 0.534, Test loss: 0.701, Test accuracy: 76.97
Round  82, Train loss: 0.538, Test loss: 0.702, Test accuracy: 77.27
Round  83, Train loss: 0.541, Test loss: 0.701, Test accuracy: 77.17
Round  84, Train loss: 0.527, Test loss: 0.709, Test accuracy: 76.94
Round  85, Train loss: 0.531, Test loss: 0.698, Test accuracy: 77.15
Round  86, Train loss: 0.523, Test loss: 0.686, Test accuracy: 77.66
Round  87, Train loss: 0.516, Test loss: 0.691, Test accuracy: 77.18
Round  88, Train loss: 0.521, Test loss: 0.699, Test accuracy: 77.31
Round  89, Train loss: 0.502, Test loss: 0.696, Test accuracy: 77.36
Round  90, Train loss: 0.476, Test loss: 0.701, Test accuracy: 77.47
Round  91, Train loss: 0.499, Test loss: 0.701, Test accuracy: 77.35
Round  92, Train loss: 0.506, Test loss: 0.695, Test accuracy: 77.56
Round  93, Train loss: 0.518, Test loss: 0.693, Test accuracy: 77.59
Round  94, Train loss: 0.490, Test loss: 0.688, Test accuracy: 77.71
Round  95, Train loss: 0.460, Test loss: 0.697, Test accuracy: 77.50
Round  96, Train loss: 0.488, Test loss: 0.683, Test accuracy: 77.97
Round  97, Train loss: 0.518, Test loss: 0.686, Test accuracy: 77.98
Round  98, Train loss: 0.472, Test loss: 0.706, Test accuracy: 77.48
Round  99, Train loss: 0.465, Test loss: 0.704, Test accuracy: 77.54
Final Round, Train loss: 0.413, Test loss: 0.698, Test accuracy: 77.75
Average accuracy final 10 rounds: 77.615
4389.463028907776
[5.421220541000366, 10.696580410003662, 15.9910147190094, 21.19920563697815, 26.454987049102783, 31.66093397140503, 36.83157444000244, 42.02321743965149, 47.18920063972473, 52.41470503807068, 57.591272592544556, 62.776376485824585, 67.96311092376709, 73.21118593215942, 78.40524005889893, 83.62464904785156, 88.79748249053955, 93.99785780906677, 99.14510011672974, 104.30472111701965, 109.45113277435303, 114.64063096046448, 119.84523391723633, 125.00166487693787, 130.1659550666809, 135.37154364585876, 140.5633089542389, 145.78748035430908, 151.02374386787415, 156.33537316322327, 161.6259045600891, 166.81441473960876, 172.03341817855835, 177.2992615699768, 182.65071201324463, 187.9138011932373, 193.1904079914093, 198.57472109794617, 203.8473720550537, 209.10400867462158, 214.37011241912842, 219.66008305549622, 225.02796387672424, 230.3662247657776, 235.6712007522583, 240.9566445350647, 246.29133987426758, 251.62433123588562, 256.9743449687958, 262.2159037590027, 267.4965763092041, 272.90314412117004, 278.1870050430298, 283.4896717071533, 288.78319692611694, 294.1033594608307, 299.43485713005066, 304.7780644893646, 310.0307629108429, 315.2596364021301, 320.55866169929504, 325.90980315208435, 331.2829954624176, 336.64895153045654, 342.00326681137085, 347.40394020080566, 352.72598481178284, 358.05971479415894, 363.3974063396454, 368.76649928092957, 374.12222957611084, 379.46781826019287, 384.85044527053833, 390.2284960746765, 395.593807220459, 400.9472191333771, 406.2639446258545, 411.6101179122925, 416.9701659679413, 422.3159034252167, 427.6903672218323, 433.56252360343933, 439.4479293823242, 445.3715867996216, 451.30542373657227, 457.2288739681244, 463.16485810279846, 469.10328245162964, 475.01258301734924, 480.9326205253601, 486.90703225135803, 492.80457639694214, 498.69951844215393, 504.635999917984, 510.5913553237915, 516.47461104393, 522.3787839412689, 528.2727236747742, 534.2022054195404, 540.1886401176453, 542.4152660369873]
[32.3175, 41.3275, 44.8325, 48.4575, 52.04, 54.5375, 55.4825, 57.6825, 60.285, 61.7075, 62.2575, 63.37, 64.15, 64.3375, 65.7425, 65.6625, 66.3375, 67.545, 68.1275, 68.6375, 69.37, 69.6425, 70.1175, 70.3175, 71.6025, 71.4125, 72.155, 71.8825, 72.8825, 72.6225, 72.355, 72.7925, 73.3775, 72.82, 73.315, 73.4, 72.9075, 73.7325, 74.59, 74.1625, 74.11, 74.3425, 74.4625, 74.7475, 74.975, 75.1625, 75.3375, 75.065, 75.5625, 75.275, 75.71, 75.7575, 75.425, 76.1575, 75.7825, 75.8825, 75.815, 75.8025, 75.5225, 75.5525, 75.62, 76.1875, 76.0075, 76.33, 76.4575, 76.7425, 76.835, 76.645, 76.8425, 76.7925, 77.2525, 76.98, 76.9375, 76.9225, 76.85, 77.155, 76.945, 77.15, 76.935, 77.1575, 77.2775, 76.9725, 77.2675, 77.165, 76.945, 77.1525, 77.655, 77.1775, 77.3075, 77.3625, 77.465, 77.3525, 77.5625, 77.5925, 77.7075, 77.505, 77.97, 77.98, 77.4775, 77.5375, 77.755]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 19, noise    level: 0.5000 
   Client 15, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
   Client 10, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
   Client 13, noise    level: 0.5000 
   Client 14, noise    level: 0.5000 
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  29.8400
Round 1 global test acc  34.1300
Round 2 global test acc  39.6700
Round 3 global test acc  44.2200
Round 4 global test acc  46.4500
Round 5 global test acc  47.5000
Round 6 global test acc  50.3200
Round 7 global test acc  49.8800
Round 8 global test acc  51.1400
Round 9 global test acc  52.1000
Round 10 global test acc  52.6300
Round 11 global test acc  54.4000
Round 12 global test acc  54.3800
Round 13 global test acc  53.7200
Round 14 global test acc  55.3400
Round 15 global test acc  55.1800
Round 16 global test acc  57.7700
Round 17 global test acc  58.6300
Round 18 global test acc  56.3100
Round 19 global test acc  57.9400
Round 20 global test acc  57.4700
Round 21 global test acc  59.1200
Round 22 global test acc  58.8400
Round 23 global test acc  60.2600
Round 24 global test acc  58.7500
Round 25 global test acc  58.3700
Round 26 global test acc  59.3100
Round 27 global test acc  59.4900
Round 28 global test acc  59.7100
Round 29 global test acc  59.6700
Round 30 global test acc  61.0700
Round 31 global test acc  61.7500
Round 32 global test acc  60.4600
Round 33 global test acc  60.6600
Round 34 global test acc  61.2000
Round 35 global test acc  60.6100
Round 36 global test acc  59.4300
Round 37 global test acc  59.3100
Round 38 global test acc  61.9900
Round 39 global test acc  62.0500
Round 40 global test acc  61.4100
Round 41 global test acc  61.8400
Round 42 global test acc  62.7800
Round 43 global test acc  62.2300
Round 44 global test acc  63.1600
Round 45 global test acc  63.4100
Round 46 global test acc  64.0400
Round 47 global test acc  64.3700
Round 48 global test acc  63.4400
Round 49 global test acc  64.5000
Round 50 global test acc  62.0300
Round 51 global test acc  64.5000
Round 52 global test acc  64.8500
Round 53 global test acc  63.8000
Round 54 global test acc  63.8700
Round 55 global test acc  62.3800
Round 56 global test acc  64.7200
Round 57 global test acc  64.6700
Round 58 global test acc  65.1300
Round 59 global test acc  62.6100
Round 60 global test acc  63.5300
Round 61 global test acc  61.7500
Round 62 global test acc  65.2200
Round 63 global test acc  63.0500
Round 64 global test acc  65.7100
Round 65 global test acc  62.8100
Round 66 global test acc  65.1100
Round 67 global test acc  64.3700
Round 68 global test acc  63.7600
Round 69 global test acc  64.9000
Round 70 global test acc  64.8900
Round 71 global test acc  65.6900
Round 72 global test acc  65.4900
Round 73 global test acc  65.3000
Round 74 global test acc  65.5900
Round 75 global test acc  64.4400
Round 76 global test acc  66.3400
Round 77 global test acc  65.5800
Round 78 global test acc  62.0800
Round 79 global test acc  65.2300
Round 80 global test acc  63.5600
Round 81 global test acc  62.5000
Round 82 global test acc  62.0000
Round 83 global test acc  61.2200
Round 84 global test acc  60.5500
Round 85 global test acc  60.1900
Round 86 global test acc  59.5600
Round 87 global test acc  59.1100
Round 88 global test acc  58.9000
Round 89 global test acc  59.0600
Round 90 global test acc  58.7900
Round 91 global test acc  58.0400
Round 92 global test acc  57.1000
Round 93 global test acc  56.4200
Round 94 global test acc  56.7900
Round 95 global test acc  57.6500
Round 96 global test acc  58.0500
Round 97 global test acc  57.8300
Round 98 global test acc  57.7300
Round 99 global test acc  57.6100
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 1, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 17, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 13, noise    level: 0.5000 
   Client 19, noise    level: 0.5000 
   Client 15, noise    level: 0.5000 
   Client 0, noise    level: 0.5000 
   Client 11, noise    level: 0.5000 
   Client 7, noise    level: 0.5000 
   Client 12, noise    level: 0.5000 
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 2.230, Test loss: 2.104, Test accuracy: 23.72
Round   1, Train loss: 2.074, Test loss: 1.915, Test accuracy: 33.05
Round   2, Train loss: 1.961, Test loss: 1.813, Test accuracy: 37.39
Round   3, Train loss: 1.939, Test loss: 1.772, Test accuracy: 40.80
Round   4, Train loss: 1.835, Test loss: 1.678, Test accuracy: 43.34
Round   5, Train loss: 1.882, Test loss: 1.653, Test accuracy: 44.43
Round   6, Train loss: 1.815, Test loss: 1.638, Test accuracy: 45.71
Round   7, Train loss: 1.780, Test loss: 1.593, Test accuracy: 47.84
Round   8, Train loss: 1.783, Test loss: 1.527, Test accuracy: 49.53
Round   9, Train loss: 1.747, Test loss: 1.506, Test accuracy: 50.90
Round  10, Train loss: 1.714, Test loss: 1.460, Test accuracy: 52.85
Round  11, Train loss: 1.666, Test loss: 1.440, Test accuracy: 53.99
Round  12, Train loss: 1.723, Test loss: 1.429, Test accuracy: 54.92
Round  13, Train loss: 1.633, Test loss: 1.402, Test accuracy: 55.69
Round  14, Train loss: 1.591, Test loss: 1.372, Test accuracy: 57.18
Round  15, Train loss: 1.607, Test loss: 1.365, Test accuracy: 57.07
Round  16, Train loss: 1.602, Test loss: 1.309, Test accuracy: 59.00
Round  17, Train loss: 1.503, Test loss: 1.297, Test accuracy: 59.35
Round  18, Train loss: 1.559, Test loss: 1.281, Test accuracy: 59.99
Round  19, Train loss: 1.544, Test loss: 1.273, Test accuracy: 60.72
Round  20, Train loss: 1.516, Test loss: 1.268, Test accuracy: 60.96
Round  21, Train loss: 1.485, Test loss: 1.239, Test accuracy: 61.63
Round  22, Train loss: 1.517, Test loss: 1.235, Test accuracy: 62.08
Round  23, Train loss: 1.422, Test loss: 1.225, Test accuracy: 61.94
Round  24, Train loss: 1.433, Test loss: 1.206, Test accuracy: 63.05
Round  25, Train loss: 1.542, Test loss: 1.195, Test accuracy: 63.47
Round  26, Train loss: 1.441, Test loss: 1.176, Test accuracy: 64.00
Round  27, Train loss: 1.424, Test loss: 1.174, Test accuracy: 64.64
Round  28, Train loss: 1.411, Test loss: 1.158, Test accuracy: 64.55
Round  29, Train loss: 1.344, Test loss: 1.146, Test accuracy: 64.78
Round  30, Train loss: 1.343, Test loss: 1.157, Test accuracy: 64.77
Round  31, Train loss: 1.397, Test loss: 1.155, Test accuracy: 64.92
Round  32, Train loss: 1.356, Test loss: 1.148, Test accuracy: 64.85
Round  33, Train loss: 1.383, Test loss: 1.136, Test accuracy: 65.38
Round  34, Train loss: 1.371, Test loss: 1.132, Test accuracy: 65.43
Round  35, Train loss: 1.288, Test loss: 1.117, Test accuracy: 65.79
Round  36, Train loss: 1.301, Test loss: 1.114, Test accuracy: 65.67
Round  37, Train loss: 1.392, Test loss: 1.126, Test accuracy: 65.40
Round  38, Train loss: 1.210, Test loss: 1.110, Test accuracy: 65.80
Round  39, Train loss: 1.278, Test loss: 1.093, Test accuracy: 66.56
Round  40, Train loss: 1.331, Test loss: 1.102, Test accuracy: 66.25
Round  41, Train loss: 1.331, Test loss: 1.107, Test accuracy: 65.78
Round  42, Train loss: 1.249, Test loss: 1.107, Test accuracy: 66.51
Round  43, Train loss: 1.264, Test loss: 1.090, Test accuracy: 67.22
Round  44, Train loss: 1.243, Test loss: 1.084, Test accuracy: 67.24
Round  45, Train loss: 1.270, Test loss: 1.088, Test accuracy: 66.92
Round  46, Train loss: 1.319, Test loss: 1.089, Test accuracy: 67.13
Round  47, Train loss: 1.292, Test loss: 1.084, Test accuracy: 67.41
Round  48, Train loss: 1.231, Test loss: 1.081, Test accuracy: 67.26
Round  49, Train loss: 1.271, Test loss: 1.085, Test accuracy: 67.13
Round  50, Train loss: 1.232, Test loss: 1.071, Test accuracy: 67.41
Round  51, Train loss: 1.262, Test loss: 1.077, Test accuracy: 67.41
Round  52, Train loss: 1.166, Test loss: 1.068, Test accuracy: 67.46
Round  53, Train loss: 1.326, Test loss: 1.079, Test accuracy: 66.77
Round  54, Train loss: 1.210, Test loss: 1.082, Test accuracy: 66.94
Round  55, Train loss: 1.115, Test loss: 1.058, Test accuracy: 67.59
Round  56, Train loss: 1.210, Test loss: 1.059, Test accuracy: 67.58
Round  57, Train loss: 1.179, Test loss: 1.044, Test accuracy: 67.99
Round  58, Train loss: 1.240, Test loss: 1.060, Test accuracy: 67.56
Round  59, Train loss: 1.180, Test loss: 1.062, Test accuracy: 67.36
Round  60, Train loss: 1.273, Test loss: 1.067, Test accuracy: 67.30
Round  61, Train loss: 1.154, Test loss: 1.058, Test accuracy: 67.50
Round  62, Train loss: 1.208, Test loss: 1.043, Test accuracy: 68.14
Round  63, Train loss: 1.280, Test loss: 1.048, Test accuracy: 67.70
Round  64, Train loss: 1.140, Test loss: 1.045, Test accuracy: 68.00
Round  65, Train loss: 1.128, Test loss: 1.042, Test accuracy: 68.02
Round  66, Train loss: 1.097, Test loss: 1.039, Test accuracy: 68.04
Round  67, Train loss: 1.244, Test loss: 1.055, Test accuracy: 67.58
Round  68, Train loss: 1.147, Test loss: 1.044, Test accuracy: 68.03
Round  69, Train loss: 1.114, Test loss: 1.047, Test accuracy: 67.72
Round  70, Train loss: 1.047, Test loss: 1.048, Test accuracy: 67.78
Round  71, Train loss: 1.035, Test loss: 1.053, Test accuracy: 67.52
Round  72, Train loss: 1.067, Test loss: 1.062, Test accuracy: 67.25
Round  73, Train loss: 1.140, Test loss: 1.056, Test accuracy: 67.67
Round  74, Train loss: 1.121, Test loss: 1.054, Test accuracy: 67.81
Round  75, Train loss: 1.173, Test loss: 1.063, Test accuracy: 67.36
Round  76, Train loss: 1.151, Test loss: 1.054, Test accuracy: 67.22
Round  77, Train loss: 1.139, Test loss: 1.054, Test accuracy: 67.91
Round  78, Train loss: 1.221, Test loss: 1.054, Test accuracy: 67.74
Round  79, Train loss: 1.179, Test loss: 1.043, Test accuracy: 68.14
Round  80, Train loss: 1.144, Test loss: 1.058, Test accuracy: 67.49
Round  81, Train loss: 1.119, Test loss: 1.047, Test accuracy: 67.89
Round  82, Train loss: 1.129, Test loss: 1.049, Test accuracy: 67.76
Round  83, Train loss: 1.176, Test loss: 1.057, Test accuracy: 67.82
Round  84, Train loss: 1.072, Test loss: 1.058, Test accuracy: 67.56
Round  85, Train loss: 1.177, Test loss: 1.074, Test accuracy: 66.69
Round  86, Train loss: 1.111, Test loss: 1.066, Test accuracy: 66.82
Round  87, Train loss: 1.052, Test loss: 1.060, Test accuracy: 67.51
Round  88, Train loss: 1.074, Test loss: 1.054, Test accuracy: 67.56
Round  89, Train loss: 1.042, Test loss: 1.064, Test accuracy: 67.50
Round  90, Train loss: 1.002, Test loss: 1.066, Test accuracy: 67.25
Round  91, Train loss: 1.132, Test loss: 1.068, Test accuracy: 67.11
Round  92, Train loss: 1.062, Test loss: 1.058, Test accuracy: 67.53
Round  93, Train loss: 1.072, Test loss: 1.044, Test accuracy: 67.99
Round  94, Train loss: 1.050, Test loss: 1.057, Test accuracy: 67.42
Round  95, Train loss: 1.023, Test loss: 1.077, Test accuracy: 66.67
Round  96, Train loss: 1.111, Test loss: 1.074, Test accuracy: 67.02
Round  97, Train loss: 1.191, Test loss: 1.055, Test accuracy: 67.65
Round  98, Train loss: 1.012, Test loss: 1.065, Test accuracy: 67.23
Round  99, Train loss: 1.104, Test loss: 1.076, Test accuracy: 66.67
Final Round, Train loss: 0.986, Test loss: 1.080, Test accuracy: 66.38
Average accuracy final 10 rounds: 67.25375
4659.599563360214
[6.166364908218384, 11.999277114868164, 17.875886917114258, 23.71654510498047, 29.560415029525757, 35.425392627716064, 41.289302349090576, 47.17335605621338, 53.0354950428009, 58.93354630470276, 64.80170226097107, 70.68845176696777, 76.57761812210083, 82.42731094360352, 88.21318864822388, 93.99030017852783, 99.81058478355408, 105.62798833847046, 111.55550384521484, 117.41804480552673, 123.28684639930725, 129.16345477104187, 135.04770922660828, 140.91015458106995, 146.7666618824005, 152.56849026679993, 158.41364240646362, 164.2933452129364, 170.14129209518433, 176.0421211719513, 181.97040677070618, 187.8966085910797, 193.80437684059143, 199.6890161037445, 205.6306962966919, 211.58670854568481, 217.57916045188904, 223.52773904800415, 229.508540391922, 235.46818089485168, 241.3655869960785, 247.2653021812439, 253.07482051849365, 258.72472167015076, 264.44154834747314, 270.33237981796265, 276.29122829437256, 282.23078322410583, 288.17652130126953, 294.12621688842773, 300.1045217514038, 306.12492871284485, 312.0861461162567, 318.06563782691956, 324.0442199707031, 329.9855704307556, 335.90847420692444, 341.7843976020813, 347.77651476860046, 353.7527632713318, 359.76069259643555, 365.7641463279724, 371.750661611557, 377.75366735458374, 383.70395064353943, 389.6890609264374, 395.5892262458801, 401.57407689094543, 407.56681513786316, 413.5286524295807, 419.48928213119507, 425.43006443977356, 431.3777422904968, 437.30849504470825, 442.98972368240356, 448.65242290496826, 454.3673713207245, 460.2789771556854, 466.23212814331055, 472.1450443267822, 477.98042392730713, 483.7962975502014, 489.6681432723999, 495.5293233394623, 501.5347807407379, 507.5414152145386, 513.5275797843933, 519.4162740707397, 525.3165168762207, 531.2498729228973, 537.1504309177399, 543.0229506492615, 548.9488184452057, 554.807742357254, 560.6831710338593, 566.5320520401001, 571.8216602802277, 577.1660056114197, 582.5115885734558, 587.8129665851593, 589.8889484405518]
[23.7175, 33.0525, 37.39, 40.795, 43.335, 44.43, 45.71, 47.84, 49.5275, 50.8975, 52.8475, 53.9925, 54.9175, 55.69, 57.1775, 57.0675, 59.0025, 59.3525, 59.995, 60.7225, 60.9625, 61.6325, 62.08, 61.94, 63.0525, 63.4725, 63.9975, 64.6425, 64.5525, 64.7825, 64.765, 64.925, 64.85, 65.3825, 65.4275, 65.7875, 65.6725, 65.4025, 65.8, 66.565, 66.25, 65.78, 66.5075, 67.215, 67.2425, 66.925, 67.1275, 67.4125, 67.2625, 67.13, 67.405, 67.405, 67.4625, 66.7725, 66.9425, 67.5925, 67.5775, 67.99, 67.565, 67.355, 67.3025, 67.4975, 68.145, 67.7025, 68.0, 68.015, 68.0375, 67.5825, 68.0325, 67.725, 67.7775, 67.5225, 67.255, 67.6675, 67.805, 67.3575, 67.2225, 67.9125, 67.74, 68.14, 67.4875, 67.89, 67.7625, 67.82, 67.555, 66.695, 66.8225, 67.51, 67.555, 67.505, 67.25, 67.115, 67.5325, 67.99, 67.415, 66.675, 67.02, 67.6475, 67.2275, 66.665, 66.3825]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.6 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 13, noise    level: 0.5000 
   Client 17, noise    level: 0.5000 
   Client 19, noise    level: 0.5000 
   Client 15, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 12, noise    level: 0.5000 
   Client 14, noise    level: 0.5000 
   Client 10, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.237, Test loss: 2.110, Test accuracy: 28.49
Round   1, Train loss: 0.863, Test loss: 1.974, Test accuracy: 38.61
Round   2, Train loss: 0.816, Test loss: 1.303, Test accuracy: 52.67
Round   3, Train loss: 0.757, Test loss: 0.998, Test accuracy: 60.56
Round   4, Train loss: 0.677, Test loss: 0.851, Test accuracy: 67.21
Round   5, Train loss: 0.675, Test loss: 0.680, Test accuracy: 72.60
Round   6, Train loss: 0.585, Test loss: 0.635, Test accuracy: 74.69
Round   7, Train loss: 0.545, Test loss: 0.605, Test accuracy: 75.95
Round   8, Train loss: 0.607, Test loss: 0.601, Test accuracy: 76.06
Round   9, Train loss: 0.524, Test loss: 0.560, Test accuracy: 77.93
Round  10, Train loss: 0.530, Test loss: 0.528, Test accuracy: 79.15
Round  11, Train loss: 0.589, Test loss: 0.512, Test accuracy: 79.74
Round  12, Train loss: 0.452, Test loss: 0.516, Test accuracy: 79.86
Round  13, Train loss: 0.452, Test loss: 0.480, Test accuracy: 80.81
Round  14, Train loss: 0.550, Test loss: 0.472, Test accuracy: 81.34
Round  15, Train loss: 0.438, Test loss: 0.466, Test accuracy: 81.85
Round  16, Train loss: 0.520, Test loss: 0.447, Test accuracy: 82.64
Round  17, Train loss: 0.471, Test loss: 0.444, Test accuracy: 82.67
Round  18, Train loss: 0.515, Test loss: 0.435, Test accuracy: 83.36
Round  19, Train loss: 0.362, Test loss: 0.424, Test accuracy: 83.08
Round  20, Train loss: 0.440, Test loss: 0.419, Test accuracy: 83.43
Round  21, Train loss: 0.421, Test loss: 0.421, Test accuracy: 83.33
Round  22, Train loss: 0.373, Test loss: 0.404, Test accuracy: 84.24
Round  23, Train loss: 0.470, Test loss: 0.402, Test accuracy: 84.41
Round  24, Train loss: 0.438, Test loss: 0.398, Test accuracy: 84.51
Round  25, Train loss: 0.307, Test loss: 0.389, Test accuracy: 84.58
Round  26, Train loss: 0.419, Test loss: 0.379, Test accuracy: 85.07
Round  27, Train loss: 0.317, Test loss: 0.379, Test accuracy: 85.23
Round  28, Train loss: 0.418, Test loss: 0.377, Test accuracy: 85.16
Round  29, Train loss: 0.331, Test loss: 0.370, Test accuracy: 85.54
Round  30, Train loss: 0.408, Test loss: 0.374, Test accuracy: 85.41
Round  31, Train loss: 0.418, Test loss: 0.367, Test accuracy: 85.53
Round  32, Train loss: 0.337, Test loss: 0.363, Test accuracy: 85.41
Round  33, Train loss: 0.301, Test loss: 0.361, Test accuracy: 85.80
Round  34, Train loss: 0.292, Test loss: 0.363, Test accuracy: 85.40
Round  35, Train loss: 0.279, Test loss: 0.358, Test accuracy: 85.57
Round  36, Train loss: 0.296, Test loss: 0.351, Test accuracy: 85.92
Round  37, Train loss: 0.297, Test loss: 0.357, Test accuracy: 85.69
Round  38, Train loss: 0.317, Test loss: 0.350, Test accuracy: 86.02
Round  39, Train loss: 0.354, Test loss: 0.351, Test accuracy: 86.14
Round  40, Train loss: 0.344, Test loss: 0.356, Test accuracy: 85.81
Round  41, Train loss: 0.297, Test loss: 0.350, Test accuracy: 86.12
Round  42, Train loss: 0.326, Test loss: 0.349, Test accuracy: 85.97
Round  43, Train loss: 0.384, Test loss: 0.339, Test accuracy: 86.64
Round  44, Train loss: 0.305, Test loss: 0.333, Test accuracy: 86.92
Round  45, Train loss: 0.324, Test loss: 0.334, Test accuracy: 86.87
Round  46, Train loss: 0.311, Test loss: 0.331, Test accuracy: 87.16
Round  47, Train loss: 0.300, Test loss: 0.331, Test accuracy: 87.16
Round  48, Train loss: 0.333, Test loss: 0.329, Test accuracy: 87.20
Round  49, Train loss: 0.320, Test loss: 0.329, Test accuracy: 87.14
Round  50, Train loss: 0.286, Test loss: 0.337, Test accuracy: 86.60
Round  51, Train loss: 0.267, Test loss: 0.329, Test accuracy: 87.04
Round  52, Train loss: 0.290, Test loss: 0.330, Test accuracy: 87.04
Round  53, Train loss: 0.273, Test loss: 0.330, Test accuracy: 87.19
Round  54, Train loss: 0.302, Test loss: 0.326, Test accuracy: 87.14
Round  55, Train loss: 0.308, Test loss: 0.335, Test accuracy: 86.86
Round  56, Train loss: 0.293, Test loss: 0.324, Test accuracy: 87.23
Round  57, Train loss: 0.317, Test loss: 0.326, Test accuracy: 87.20
Round  58, Train loss: 0.297, Test loss: 0.325, Test accuracy: 87.14
Round  59, Train loss: 0.224, Test loss: 0.320, Test accuracy: 87.41
Round  60, Train loss: 0.300, Test loss: 0.318, Test accuracy: 87.63
Round  61, Train loss: 0.272, Test loss: 0.318, Test accuracy: 87.67
Round  62, Train loss: 0.200, Test loss: 0.322, Test accuracy: 87.52
Round  63, Train loss: 0.249, Test loss: 0.317, Test accuracy: 87.53
Round  64, Train loss: 0.265, Test loss: 0.320, Test accuracy: 87.40
Round  65, Train loss: 0.305, Test loss: 0.323, Test accuracy: 87.45
Round  66, Train loss: 0.309, Test loss: 0.318, Test accuracy: 87.54
Round  67, Train loss: 0.228, Test loss: 0.318, Test accuracy: 87.61
Round  68, Train loss: 0.271, Test loss: 0.315, Test accuracy: 87.67
Round  69, Train loss: 0.273, Test loss: 0.316, Test accuracy: 87.83
Round  70, Train loss: 0.221, Test loss: 0.323, Test accuracy: 87.46
Round  71, Train loss: 0.210, Test loss: 0.319, Test accuracy: 87.63
Round  72, Train loss: 0.276, Test loss: 0.314, Test accuracy: 87.74
Round  73, Train loss: 0.289, Test loss: 0.318, Test accuracy: 87.71
Round  74, Train loss: 0.287, Test loss: 0.312, Test accuracy: 87.91
Round  75, Train loss: 0.181, Test loss: 0.310, Test accuracy: 87.92
Round  76, Train loss: 0.232, Test loss: 0.314, Test accuracy: 87.46
Round  77, Train loss: 0.289, Test loss: 0.314, Test accuracy: 87.75
Round  78, Train loss: 0.196, Test loss: 0.316, Test accuracy: 87.89
Round  79, Train loss: 0.253, Test loss: 0.304, Test accuracy: 88.19
Round  80, Train loss: 0.176, Test loss: 0.311, Test accuracy: 87.93
Round  81, Train loss: 0.206, Test loss: 0.311, Test accuracy: 87.90
Round  82, Train loss: 0.199, Test loss: 0.314, Test accuracy: 88.00
Round  83, Train loss: 0.271, Test loss: 0.311, Test accuracy: 88.13
Round  84, Train loss: 0.224, Test loss: 0.314, Test accuracy: 88.02
Round  85, Train loss: 0.184, Test loss: 0.315, Test accuracy: 87.84
Round  86, Train loss: 0.250, Test loss: 0.313, Test accuracy: 87.97
Round  87, Train loss: 0.206, Test loss: 0.307, Test accuracy: 88.14
Round  88, Train loss: 0.237, Test loss: 0.311, Test accuracy: 88.01
Round  89, Train loss: 0.188, Test loss: 0.310, Test accuracy: 88.11
Round  90, Train loss: 0.167, Test loss: 0.313, Test accuracy: 87.81
Round  91, Train loss: 0.295, Test loss: 0.310, Test accuracy: 88.08
Round  92, Train loss: 0.142, Test loss: 0.312, Test accuracy: 88.02
Round  93, Train loss: 0.259, Test loss: 0.307, Test accuracy: 88.05
Round  94, Train loss: 0.212, Test loss: 0.306, Test accuracy: 88.34
Round  95, Train loss: 0.191, Test loss: 0.308, Test accuracy: 88.31
Round  96, Train loss: 0.240, Test loss: 0.306, Test accuracy: 88.30
Round  97, Train loss: 0.173, Test loss: 0.310, Test accuracy: 88.07
Round  98, Train loss: 0.216, Test loss: 0.310, Test accuracy: 88.18
Round  99, Train loss: 0.165, Test loss: 0.307, Test accuracy: 88.18
Final Round, Train loss: 0.178, Test loss: 0.307, Test accuracy: 88.27
Average accuracy final 10 rounds: 88.13361111111112
6882.139237165451
[5.510446548461914, 10.815886974334717, 16.1255464553833, 21.412188291549683, 26.744142532348633, 32.13536286354065, 37.43178868293762, 42.69614315032959, 48.025020360946655, 53.36275577545166, 58.632420778274536, 63.9016489982605, 69.18038320541382, 74.46481919288635, 79.75956296920776, 85.02017092704773, 90.26474452018738, 95.63668704032898, 100.86458730697632, 106.08033442497253, 111.31833124160767, 123.34639310836792, 135.32573580741882, 147.03040552139282, 158.772225856781, 170.96121621131897, 183.1674427986145, 195.13963532447815, 206.87421107292175, 218.5129849910736, 230.2090358734131, 241.288756608963, 252.50223970413208, 263.88577818870544, 275.29560685157776, 286.53608202934265, 297.6346204280853, 308.96398973464966, 320.44101428985596, 331.8111102581024, 343.0849597454071, 354.23633003234863, 365.7735061645508, 377.30035877227783, 388.709983587265, 400.0966703891754, 412.03314089775085, 423.62365436553955, 435.2954525947571, 447.1210582256317, 458.4496669769287, 469.98309445381165, 481.5711863040924, 493.02983236312866, 504.6546280384064, 516.0846602916718, 527.6615931987762, 539.1111373901367, 550.6431691646576, 561.7409656047821, 572.987434387207, 584.3253781795502, 595.4515159130096, 606.7117671966553, 617.8109087944031, 629.2339570522308, 640.8143601417542, 652.287365436554, 663.861501455307, 675.0993824005127, 686.1635944843292, 697.4421429634094, 708.7979092597961, 720.2361943721771, 731.5928542613983, 742.8198263645172, 753.7826929092407, 764.7192900180817, 776.0634441375732, 787.1080560684204, 798.7829551696777, 810.3676986694336, 821.4743323326111, 832.4723513126373, 843.5063862800598, 854.602897644043, 865.595978975296, 876.7421576976776, 887.6838941574097, 898.7999141216278, 909.9197759628296, 920.9244129657745, 931.8924667835236, 942.8122103214264, 953.9144916534424, 964.696694612503, 975.7879180908203, 986.8057951927185, 997.5451555252075, 1008.4362387657166, 1010.5048620700836]
[28.494444444444444, 38.608333333333334, 52.672222222222224, 60.56111111111111, 67.21111111111111, 72.60277777777777, 74.68888888888888, 75.95277777777778, 76.05555555555556, 77.93333333333334, 79.15, 79.74166666666666, 79.86111111111111, 80.80555555555556, 81.33611111111111, 81.85277777777777, 82.63888888888889, 82.66666666666667, 83.35555555555555, 83.07777777777778, 83.43055555555556, 83.33333333333333, 84.24166666666666, 84.40555555555555, 84.50833333333334, 84.57777777777778, 85.06666666666666, 85.23333333333333, 85.16388888888889, 85.54444444444445, 85.40555555555555, 85.52777777777777, 85.41388888888889, 85.79722222222222, 85.40277777777777, 85.56666666666666, 85.91666666666667, 85.69166666666666, 86.01944444444445, 86.14444444444445, 85.80555555555556, 86.11944444444444, 85.97222222222223, 86.6361111111111, 86.91666666666667, 86.87222222222222, 87.15833333333333, 87.15555555555555, 87.19722222222222, 87.1361111111111, 86.60277777777777, 87.04166666666667, 87.03611111111111, 87.18888888888888, 87.14444444444445, 86.86111111111111, 87.23333333333333, 87.19722222222222, 87.14166666666667, 87.40555555555555, 87.63055555555556, 87.675, 87.51666666666667, 87.52777777777777, 87.4, 87.44722222222222, 87.53888888888889, 87.60555555555555, 87.66666666666667, 87.825, 87.46111111111111, 87.63055555555556, 87.74166666666666, 87.70833333333333, 87.91388888888889, 87.925, 87.46111111111111, 87.74722222222222, 87.89166666666667, 88.18888888888888, 87.93333333333334, 87.89722222222223, 88.0, 88.13055555555556, 88.01666666666667, 87.83611111111111, 87.96666666666667, 88.14444444444445, 88.0111111111111, 88.10555555555555, 87.81388888888888, 88.075, 88.02222222222223, 88.05, 88.33888888888889, 88.30833333333334, 88.30277777777778, 88.06666666666666, 88.18055555555556, 88.17777777777778, 88.26944444444445]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.8 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedrep.py", line 45, in <module>
    dataset_train, dataset_test, dict_users_train, dict_users_test, concept_matrix, rand_set_all = get_data_v3(
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 190, in get_data_v3
    y_train_noisy, gamma_s, real_noise_level = add_noise(args, y_train, dict_users_train, rand_set_all)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 239, in add_noise
    y_train_noisy[rand_sample_idx] = nosiy_sample_labels
IndexError: arrays used as indices must be of integer (or boolean) type
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.8 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedrep.py", line 60, in <module>
    dataset_train, dataset_test, _, _, _,_ = get_data_v3(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 190, in get_data_v3
    y_train_noisy, gamma_s, real_noise_level = add_noise(args, y_train, dict_users_train, rand_set_all)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 239, in add_noise
    y_train_noisy[rand_sample_idx] = nosiy_sample_labels
IndexError: arrays used as indices must be of integer (or boolean) type
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.8 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedrep.py", line 60, in <module>
    dataset_train, dataset_test, _, _, _,_ = get_data_v3(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 190, in get_data_v3
    y_train_noisy, gamma_s, real_noise_level = add_noise(args, y_train, dict_users_train, rand_set_all)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 239, in add_noise
    y_train_noisy[rand_sample_idx] = nosiy_sample_labels
IndexError: arrays used as indices must be of integer (or boolean) type
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Co-teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedpac_co_teaching2.py", line 57, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 126, in get_data_v2
    y_train_noisy, gamma_s, real_noise_level = add_noise(args, y_train, dict_users_train, rand_set_all)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 239, in add_noise
    y_train_noisy[rand_sample_idx] = nosiy_sample_labels
IndexError: arrays used as indices must be of integer (or boolean) type
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "RFL.py", line 50, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 126, in get_data_v2
    y_train_noisy, gamma_s, real_noise_level = add_noise(args, y_train, dict_users_train, rand_set_all)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 239, in add_noise
    y_train_noisy[rand_sample_idx] = nosiy_sample_labels
IndexError: arrays used as indices must be of integer (or boolean) type
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedpac.py", line 58, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 126, in get_data_v2
    y_train_noisy, gamma_s, real_noise_level = add_noise(args, y_train, dict_users_train, rand_set_all)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 239, in add_noise
    y_train_noisy[rand_sample_idx] = nosiy_sample_labels
IndexError: arrays used as indices must be of integer (or boolean) type
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.8 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedpac_psl.py", line 58, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 126, in get_data_v2
    y_train_noisy, gamma_s, real_noise_level = add_noise(args, y_train, dict_users_train, rand_set_all)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 239, in add_noise
    y_train_noisy[rand_sample_idx] = nosiy_sample_labels
IndexError: arrays used as indices must be of integer (or boolean) type
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.8 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 11, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 14, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 10, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
   Client 7, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
   Client 0, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 15, noise    level: 0.5000 
   Client 12, noise    level: 0.5000 
   Client 13, noise    level: 0.5000 
   Client 18, noise    level: 0.5000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.250, Test loss: 2.158, Test accuracy: 24.25
Round   0, Global train loss: 2.250, Global test loss: 2.169, Global test accuracy: 24.98
Round   1, Train loss: 2.194, Test loss: 2.090, Test accuracy: 30.74
Round   1, Global train loss: 2.194, Global test loss: 2.089, Global test accuracy: 34.48
Round   2, Train loss: 2.181, Test loss: 2.033, Test accuracy: 33.34
Round   2, Global train loss: 2.181, Global test loss: 2.035, Global test accuracy: 38.38
Round   3, Train loss: 2.122, Test loss: 1.979, Test accuracy: 32.60
Round   3, Global train loss: 2.122, Global test loss: 1.918, Global test accuracy: 37.67
Round   4, Train loss: 2.008, Test loss: 1.933, Test accuracy: 34.91
Round   4, Global train loss: 2.008, Global test loss: 1.805, Global test accuracy: 43.80
Round   5, Train loss: 2.128, Test loss: 1.976, Test accuracy: 34.35
Round   5, Global train loss: 2.128, Global test loss: 2.016, Global test accuracy: 38.58
Round   6, Train loss: 2.099, Test loss: 1.939, Test accuracy: 35.06
Round   6, Global train loss: 2.099, Global test loss: 1.877, Global test accuracy: 43.41
Round   7, Train loss: 2.071, Test loss: 1.937, Test accuracy: 35.30
Round   7, Global train loss: 2.071, Global test loss: 1.933, Global test accuracy: 44.80
Round   8, Train loss: 2.053, Test loss: 1.932, Test accuracy: 35.35
Round   8, Global train loss: 2.053, Global test loss: 1.941, Global test accuracy: 41.82
Round   9, Train loss: 2.055, Test loss: 1.915, Test accuracy: 35.52
Round   9, Global train loss: 2.055, Global test loss: 1.893, Global test accuracy: 43.07
Round  10, Train loss: 2.069, Test loss: 1.907, Test accuracy: 35.73
Round  10, Global train loss: 2.069, Global test loss: 1.950, Global test accuracy: 40.48
Round  11, Train loss: 2.009, Test loss: 1.904, Test accuracy: 35.58
Round  11, Global train loss: 2.009, Global test loss: 1.817, Global test accuracy: 44.20
Round  12, Train loss: 2.108, Test loss: 1.907, Test accuracy: 35.29
Round  12, Global train loss: 2.108, Global test loss: 1.994, Global test accuracy: 37.66
Round  13, Train loss: 1.958, Test loss: 1.906, Test accuracy: 35.45
Round  13, Global train loss: 1.958, Global test loss: 1.856, Global test accuracy: 43.77
Round  14, Train loss: 2.033, Test loss: 1.894, Test accuracy: 35.72
Round  14, Global train loss: 2.033, Global test loss: 1.962, Global test accuracy: 39.05
Round  15, Train loss: 2.023, Test loss: 1.893, Test accuracy: 35.86
Round  15, Global train loss: 2.023, Global test loss: 1.911, Global test accuracy: 42.49
Round  16, Train loss: 1.987, Test loss: 1.892, Test accuracy: 35.80
Round  16, Global train loss: 1.987, Global test loss: 1.866, Global test accuracy: 41.04
Round  17, Train loss: 1.859, Test loss: 1.895, Test accuracy: 35.95
Round  17, Global train loss: 1.859, Global test loss: 1.827, Global test accuracy: 43.84
Round  18, Train loss: 1.893, Test loss: 1.896, Test accuracy: 36.20
Round  18, Global train loss: 1.893, Global test loss: 1.970, Global test accuracy: 38.36
Round  19, Train loss: 1.987, Test loss: 1.892, Test accuracy: 36.03
Round  19, Global train loss: 1.987, Global test loss: 1.968, Global test accuracy: 35.17
Round  20, Train loss: 1.923, Test loss: 1.905, Test accuracy: 35.76
Round  20, Global train loss: 1.923, Global test loss: 1.902, Global test accuracy: 42.65
Round  21, Train loss: 1.841, Test loss: 1.910, Test accuracy: 35.79
Round  21, Global train loss: 1.841, Global test loss: 1.836, Global test accuracy: 41.96
Round  22, Train loss: 1.734, Test loss: 1.917, Test accuracy: 35.79
Round  22, Global train loss: 1.734, Global test loss: 1.873, Global test accuracy: 40.58
Round  23, Train loss: 1.768, Test loss: 1.937, Test accuracy: 35.27
Round  23, Global train loss: 1.768, Global test loss: 1.867, Global test accuracy: 41.97
Round  24, Train loss: 1.803, Test loss: 1.944, Test accuracy: 35.17
Round  24, Global train loss: 1.803, Global test loss: 1.990, Global test accuracy: 33.91
Round  25, Train loss: 1.769, Test loss: 1.968, Test accuracy: 34.41
Round  25, Global train loss: 1.769, Global test loss: 1.921, Global test accuracy: 39.02
Round  26, Train loss: 1.624, Test loss: 1.973, Test accuracy: 34.63
Round  26, Global train loss: 1.624, Global test loss: 1.803, Global test accuracy: 44.65
Round  27, Train loss: 1.879, Test loss: 1.996, Test accuracy: 33.92
Round  27, Global train loss: 1.879, Global test loss: 1.891, Global test accuracy: 39.94
Round  28, Train loss: 1.714, Test loss: 2.005, Test accuracy: 33.83
Round  28, Global train loss: 1.714, Global test loss: 1.910, Global test accuracy: 40.09
Round  29, Train loss: 1.800, Test loss: 2.018, Test accuracy: 33.55
Round  29, Global train loss: 1.800, Global test loss: 1.956, Global test accuracy: 36.08
Round  30, Train loss: 1.660, Test loss: 2.037, Test accuracy: 33.52
Round  30, Global train loss: 1.660, Global test loss: 1.890, Global test accuracy: 40.38
Round  31, Train loss: 1.500, Test loss: 2.062, Test accuracy: 33.56
Round  31, Global train loss: 1.500, Global test loss: 1.839, Global test accuracy: 39.42
Round  32, Train loss: 1.632, Test loss: 2.081, Test accuracy: 33.38
Round  32, Global train loss: 1.632, Global test loss: 1.852, Global test accuracy: 41.74
Round  33, Train loss: 1.605, Test loss: 2.100, Test accuracy: 33.12
Round  33, Global train loss: 1.605, Global test loss: 1.875, Global test accuracy: 39.95
Round  34, Train loss: 1.487, Test loss: 2.143, Test accuracy: 32.33
Round  34, Global train loss: 1.487, Global test loss: 1.886, Global test accuracy: 38.58
Round  35, Train loss: 1.355, Test loss: 2.178, Test accuracy: 32.21
Round  35, Global train loss: 1.355, Global test loss: 1.776, Global test accuracy: 41.20
Round  36, Train loss: 1.270, Test loss: 2.225, Test accuracy: 31.95
Round  36, Global train loss: 1.270, Global test loss: 1.869, Global test accuracy: 39.93
Round  37, Train loss: 1.453, Test loss: 2.248, Test accuracy: 31.46
Round  37, Global train loss: 1.453, Global test loss: 1.866, Global test accuracy: 37.56
Round  38, Train loss: 1.287, Test loss: 2.283, Test accuracy: 31.15
Round  38, Global train loss: 1.287, Global test loss: 1.816, Global test accuracy: 41.06
Round  39, Train loss: 1.580, Test loss: 2.310, Test accuracy: 30.78
Round  39, Global train loss: 1.580, Global test loss: 1.905, Global test accuracy: 37.05
Round  40, Train loss: 1.535, Test loss: 2.342, Test accuracy: 30.48
Round  40, Global train loss: 1.535, Global test loss: 1.928, Global test accuracy: 35.92
Round  41, Train loss: 1.483, Test loss: 2.369, Test accuracy: 30.28
Round  41, Global train loss: 1.483, Global test loss: 1.841, Global test accuracy: 40.22
Round  42, Train loss: 1.168, Test loss: 2.420, Test accuracy: 30.05
Round  42, Global train loss: 1.168, Global test loss: 1.802, Global test accuracy: 40.44
Round  43, Train loss: 1.498, Test loss: 2.452, Test accuracy: 29.82
Round  43, Global train loss: 1.498, Global test loss: 2.009, Global test accuracy: 30.46
Round  44, Train loss: 1.412, Test loss: 2.456, Test accuracy: 29.64
Round  44, Global train loss: 1.412, Global test loss: 1.968, Global test accuracy: 33.70
Round  45, Train loss: 1.056, Test loss: 2.482, Test accuracy: 29.70
Round  45, Global train loss: 1.056, Global test loss: 1.767, Global test accuracy: 41.02
Round  46, Train loss: 1.248, Test loss: 2.512, Test accuracy: 29.75
Round  46, Global train loss: 1.248, Global test loss: 1.857, Global test accuracy: 37.95
Round  47, Train loss: 1.213, Test loss: 2.570, Test accuracy: 29.21
Round  47, Global train loss: 1.213, Global test loss: 1.934, Global test accuracy: 33.06
Round  48, Train loss: 1.239, Test loss: 2.608, Test accuracy: 28.99
Round  48, Global train loss: 1.239, Global test loss: 1.770, Global test accuracy: 44.77
Round  49, Train loss: 1.180, Test loss: 2.620, Test accuracy: 28.97
Round  49, Global train loss: 1.180, Global test loss: 1.965, Global test accuracy: 33.11
Round  50, Train loss: 0.984, Test loss: 2.656, Test accuracy: 28.89
Round  50, Global train loss: 0.984, Global test loss: 1.835, Global test accuracy: 38.61
Round  51, Train loss: 1.349, Test loss: 2.691, Test accuracy: 28.76
Round  51, Global train loss: 1.349, Global test loss: 1.996, Global test accuracy: 32.02
Round  52, Train loss: 1.217, Test loss: 2.709, Test accuracy: 28.86
Round  52, Global train loss: 1.217, Global test loss: 1.955, Global test accuracy: 33.05
Round  53, Train loss: 1.141, Test loss: 2.792, Test accuracy: 28.38
Round  53, Global train loss: 1.141, Global test loss: 1.974, Global test accuracy: 33.31
Round  54, Train loss: 1.091, Test loss: 2.822, Test accuracy: 28.43
Round  54, Global train loss: 1.091, Global test loss: 1.880, Global test accuracy: 36.87
Round  55, Train loss: 1.282, Test loss: 2.867, Test accuracy: 28.27
Round  55, Global train loss: 1.282, Global test loss: 2.018, Global test accuracy: 28.00
Round  56, Train loss: 1.098, Test loss: 2.891, Test accuracy: 28.41
Round  56, Global train loss: 1.098, Global test loss: 1.960, Global test accuracy: 31.41
Round  57, Train loss: 1.077, Test loss: 2.919, Test accuracy: 28.14
Round  57, Global train loss: 1.077, Global test loss: 1.912, Global test accuracy: 34.81
Round  58, Train loss: 1.140, Test loss: 2.970, Test accuracy: 27.92
Round  58, Global train loss: 1.140, Global test loss: 2.009, Global test accuracy: 32.01
Round  59, Train loss: 1.018, Test loss: 2.965, Test accuracy: 27.97
Round  59, Global train loss: 1.018, Global test loss: 1.936, Global test accuracy: 35.12
Round  60, Train loss: 0.975, Test loss: 3.017, Test accuracy: 27.96
Round  60, Global train loss: 0.975, Global test loss: 1.890, Global test accuracy: 36.82
Round  61, Train loss: 1.034, Test loss: 3.036, Test accuracy: 28.08
Round  61, Global train loss: 1.034, Global test loss: 1.915, Global test accuracy: 36.29
Round  62, Train loss: 0.995, Test loss: 3.057, Test accuracy: 28.30
Round  62, Global train loss: 0.995, Global test loss: 1.933, Global test accuracy: 33.76
Round  63, Train loss: 1.071, Test loss: 3.080, Test accuracy: 28.46
Round  63, Global train loss: 1.071, Global test loss: 1.892, Global test accuracy: 35.95
Round  64, Train loss: 1.036, Test loss: 3.131, Test accuracy: 28.34
Round  64, Global train loss: 1.036, Global test loss: 1.990, Global test accuracy: 29.35
Round  65, Train loss: 0.923, Test loss: 3.109, Test accuracy: 27.93
Round  65, Global train loss: 0.923, Global test loss: 1.922, Global test accuracy: 33.27
Round  66, Train loss: 0.964, Test loss: 3.148, Test accuracy: 27.61
Round  66, Global train loss: 0.964, Global test loss: 1.843, Global test accuracy: 36.72
Round  67, Train loss: 0.893, Test loss: 3.199, Test accuracy: 27.81
Round  67, Global train loss: 0.893, Global test loss: 1.967, Global test accuracy: 30.21
Round  68, Train loss: 0.985, Test loss: 3.237, Test accuracy: 27.66
Round  68, Global train loss: 0.985, Global test loss: 1.885, Global test accuracy: 36.12
Round  69, Train loss: 0.851, Test loss: 3.295, Test accuracy: 27.54
Round  69, Global train loss: 0.851, Global test loss: 1.936, Global test accuracy: 33.18
Round  70, Train loss: 0.844, Test loss: 3.370, Test accuracy: 26.75
Round  70, Global train loss: 0.844, Global test loss: 1.922, Global test accuracy: 32.37
Round  71, Train loss: 0.747, Test loss: 3.402, Test accuracy: 26.58
Round  71, Global train loss: 0.747, Global test loss: 1.797, Global test accuracy: 39.47
Round  72, Train loss: 0.939, Test loss: 3.448, Test accuracy: 26.98
Round  72, Global train loss: 0.939, Global test loss: 1.964, Global test accuracy: 33.87
Round  73, Train loss: 0.963, Test loss: 3.490, Test accuracy: 26.91
Round  73, Global train loss: 0.963, Global test loss: 2.007, Global test accuracy: 29.02
Round  74, Train loss: 0.928, Test loss: 3.500, Test accuracy: 27.14
Round  74, Global train loss: 0.928, Global test loss: 1.985, Global test accuracy: 31.94
Round  75, Train loss: 0.950, Test loss: 3.475, Test accuracy: 27.49
Round  75, Global train loss: 0.950, Global test loss: 1.960, Global test accuracy: 32.95
Round  76, Train loss: 0.816, Test loss: 3.500, Test accuracy: 27.59
Round  76, Global train loss: 0.816, Global test loss: 1.962, Global test accuracy: 30.73
Round  77, Train loss: 0.962, Test loss: 3.518, Test accuracy: 27.49
Round  77, Global train loss: 0.962, Global test loss: 2.099, Global test accuracy: 23.86
Round  78, Train loss: 0.913, Test loss: 3.554, Test accuracy: 27.27
Round  78, Global train loss: 0.913, Global test loss: 1.992, Global test accuracy: 29.38
Round  79, Train loss: 0.918, Test loss: 3.645, Test accuracy: 26.80
Round  79, Global train loss: 0.918, Global test loss: 2.033, Global test accuracy: 28.77
Round  80, Train loss: 0.700, Test loss: 3.658, Test accuracy: 26.85
Round  80, Global train loss: 0.700, Global test loss: 1.987, Global test accuracy: 30.31
Round  81, Train loss: 0.797, Test loss: 3.664, Test accuracy: 26.68
Round  81, Global train loss: 0.797, Global test loss: 2.015, Global test accuracy: 28.30
Round  82, Train loss: 0.841, Test loss: 3.701, Test accuracy: 26.76
Round  82, Global train loss: 0.841, Global test loss: 1.962, Global test accuracy: 32.29
Round  83, Train loss: 0.854, Test loss: 3.746, Test accuracy: 27.11
Round  83, Global train loss: 0.854, Global test loss: 2.083, Global test accuracy: 23.21
Round  84, Train loss: 0.689, Test loss: 3.763, Test accuracy: 27.12
Round  84, Global train loss: 0.689, Global test loss: 1.965, Global test accuracy: 30.37
Round  85, Train loss: 0.797, Test loss: 3.780, Test accuracy: 26.78
Round  85, Global train loss: 0.797, Global test loss: 2.078, Global test accuracy: 22.21
Round  86, Train loss: 0.819, Test loss: 3.797, Test accuracy: 26.85
Round  86, Global train loss: 0.819, Global test loss: 1.946, Global test accuracy: 33.00
Round  87, Train loss: 0.760, Test loss: 3.836, Test accuracy: 27.11
Round  87, Global train loss: 0.760, Global test loss: 1.951, Global test accuracy: 32.31
Round  88, Train loss: 0.735, Test loss: 3.891, Test accuracy: 27.00
Round  88, Global train loss: 0.735, Global test loss: 1.990, Global test accuracy: 28.28
Round  89, Train loss: 0.709, Test loss: 3.920, Test accuracy: 26.69
Round  89, Global train loss: 0.709, Global test loss: 1.908, Global test accuracy: 33.44
Round  90, Train loss: 0.646, Test loss: 3.931, Test accuracy: 26.73
Round  90, Global train loss: 0.646, Global test loss: 1.919, Global test accuracy: 32.26
Round  91, Train loss: 0.703, Test loss: 3.962, Test accuracy: 27.32
Round  91, Global train loss: 0.703, Global test loss: 1.855, Global test accuracy: 36.60
Round  92, Train loss: 0.705, Test loss: 3.989, Test accuracy: 27.08
Round  92, Global train loss: 0.705, Global test loss: 1.990, Global test accuracy: 28.93
Round  93, Train loss: 0.664, Test loss: 3.958, Test accuracy: 27.00
Round  93, Global train loss: 0.664, Global test loss: 1.866, Global test accuracy: 36.88
Round  94, Train loss: 0.704, Test loss: 3.977, Test accuracy: 26.86
Round  94, Global train loss: 0.704, Global test loss: 2.000, Global test accuracy: 25.77
Round  95, Train loss: 0.678, Test loss: 4.025, Test accuracy: 26.73
Round  95, Global train loss: 0.678, Global test loss: 1.992, Global test accuracy: 28.78
Round  96, Train loss: 0.769, Test loss: 4.016, Test accuracy: 26.69
Round  96, Global train loss: 0.769, Global test loss: 2.078, Global test accuracy: 26.86
Round  97, Train loss: 0.673, Test loss: 4.002, Test accuracy: 26.63
Round  97, Global train loss: 0.673, Global test loss: 2.101, Global test accuracy: 22.01
Round  98, Train loss: 0.698, Test loss: 4.046, Test accuracy: 26.86
Round  98, Global train loss: 0.698, Global test loss: 1.967, Global test accuracy: 31.39
Round  99, Train loss: 0.704, Test loss: 4.043, Test accuracy: 26.80
Round  99, Global train loss: 0.704, Global test loss: 2.031, Global test accuracy: 28.55
Final Round, Train loss: 0.419, Test loss: 4.820, Test accuracy: 26.99
Final Round, Global train loss: 0.419, Global test loss: 2.031, Global test accuracy: 28.55
Average accuracy final 10 rounds: 26.869000000000003 

Average global accuracy final 10 rounds: 29.802000000000003 

6045.067495107651
[5.108068466186523, 10.216136932373047, 15.017508745193481, 19.818880558013916, 24.611429929733276, 29.403979301452637, 34.17822194099426, 38.95246458053589, 43.75131344795227, 48.55016231536865, 53.32982158660889, 58.10948085784912, 62.91147494316101, 67.7134690284729, 72.46164202690125, 77.20981502532959, 81.98102974891663, 86.75224447250366, 91.54733991622925, 96.34243535995483, 101.13127946853638, 105.92012357711792, 110.73404908180237, 115.54797458648682, 120.35571146011353, 125.16344833374023, 129.95232582092285, 134.74120330810547, 139.55332922935486, 144.36545515060425, 149.19697618484497, 154.0284972190857, 158.82458519935608, 163.62067317962646, 168.4194312095642, 173.21818923950195, 178.00953674316406, 182.80088424682617, 187.61397671699524, 192.4270691871643, 197.25126123428345, 202.0754532814026, 206.85450839996338, 211.63356351852417, 216.403005361557, 221.17244720458984, 225.96551513671875, 230.75858306884766, 235.58439207077026, 240.41020107269287, 245.2104299068451, 250.01065874099731, 254.8266978263855, 259.6427369117737, 264.44887804985046, 269.25501918792725, 274.09297466278076, 278.9309301376343, 283.747816324234, 288.56470251083374, 293.4123306274414, 298.2599587440491, 303.076340675354, 307.89272260665894, 312.70626068115234, 317.51979875564575, 322.32964539527893, 327.1394920349121, 331.92486095428467, 336.7102298736572, 341.5072412490845, 346.3042526245117, 351.08700227737427, 355.8697519302368, 360.3740701675415, 364.8783884048462, 369.5913016796112, 374.3042149543762, 378.4738872051239, 382.6435594558716, 386.7850065231323, 390.92645359039307, 395.10951590538025, 399.29257822036743, 403.4696066379547, 407.646635055542, 411.84304213523865, 416.0394492149353, 420.23100686073303, 424.42256450653076, 428.6248826980591, 432.8272008895874, 437.0128152370453, 441.1984295845032, 445.3993926048279, 449.6003556251526, 453.81277894973755, 458.0252022743225, 462.2296576499939, 466.4341130256653, 470.63764810562134, 474.8411831855774, 479.0499806404114, 483.25877809524536, 487.4851243495941, 491.71147060394287, 495.8795268535614, 500.04758310317993, 504.246639251709, 508.44569540023804, 512.6454343795776, 516.8451733589172, 521.0598220825195, 525.2744708061218, 529.4884312152863, 533.7023916244507, 537.9123342037201, 542.1222767829895, 546.3232221603394, 550.5241675376892, 554.7249841690063, 558.9258008003235, 563.1379580497742, 567.3501152992249, 571.5488049983978, 575.7474946975708, 579.9585418701172, 584.1695890426636, 588.3842222690582, 592.5988554954529, 596.8088676929474, 601.0188798904419, 605.2355675697327, 609.4522552490234, 613.6712560653687, 617.8902568817139, 622.1152565479279, 626.3402562141418, 630.5888879299164, 634.8375196456909, 639.06214594841, 643.2867722511292, 647.5127193927765, 651.7386665344238, 655.9757254123688, 660.2127842903137, 664.4554584026337, 668.6981325149536, 672.9276587963104, 677.1571850776672, 681.3993277549744, 685.6414704322815, 689.8867688179016, 694.1320672035217, 698.386846780777, 702.6416263580322, 706.8731846809387, 711.1047430038452, 715.3499584197998, 719.5951738357544, 723.812096118927, 728.0290184020996, 732.2521829605103, 736.4753475189209, 740.6865644454956, 744.8977813720703, 749.1163794994354, 753.3349776268005, 757.5431573390961, 761.7513370513916, 765.9732186794281, 770.1951003074646, 774.4451081752777, 778.6951160430908, 782.9317688941956, 787.1684217453003, 791.3985204696655, 795.6286191940308, 799.861261844635, 804.0939044952393, 808.3110902309418, 812.5282759666443, 816.7216925621033, 820.9151091575623, 825.111403465271, 829.3076977729797, 833.4853422641754, 837.6629867553711, 841.8305909633636, 845.9981951713562, 850.2162621021271, 854.434329032898, 858.5801293849945, 862.7259297370911, 866.8921093940735, 871.0582890510559, 875.2185385227203, 879.3787879943848, 883.5832872390747, 887.7877864837646, 889.9018943309784, 892.0160021781921]
[24.25, 24.25, 30.7425, 30.7425, 33.335, 33.335, 32.6, 32.6, 34.91, 34.91, 34.3525, 34.3525, 35.06, 35.06, 35.295, 35.295, 35.3525, 35.3525, 35.5225, 35.5225, 35.725, 35.725, 35.58, 35.58, 35.2875, 35.2875, 35.45, 35.45, 35.715, 35.715, 35.8625, 35.8625, 35.805, 35.805, 35.955, 35.955, 36.2, 36.2, 36.03, 36.03, 35.7575, 35.7575, 35.79, 35.79, 35.7925, 35.7925, 35.275, 35.275, 35.175, 35.175, 34.405, 34.405, 34.6325, 34.6325, 33.9175, 33.9175, 33.83, 33.83, 33.555, 33.555, 33.515, 33.515, 33.5575, 33.5575, 33.38, 33.38, 33.115, 33.115, 32.3275, 32.3275, 32.2125, 32.2125, 31.9525, 31.9525, 31.465, 31.465, 31.1525, 31.1525, 30.7825, 30.7825, 30.4825, 30.4825, 30.2825, 30.2825, 30.0525, 30.0525, 29.8225, 29.8225, 29.6425, 29.6425, 29.6975, 29.6975, 29.7475, 29.7475, 29.21, 29.21, 28.9925, 28.9925, 28.97, 28.97, 28.8875, 28.8875, 28.76, 28.76, 28.865, 28.865, 28.3775, 28.3775, 28.4325, 28.4325, 28.265, 28.265, 28.41, 28.41, 28.135, 28.135, 27.9225, 27.9225, 27.97, 27.97, 27.9575, 27.9575, 28.0825, 28.0825, 28.3, 28.3, 28.4575, 28.4575, 28.3425, 28.3425, 27.93, 27.93, 27.61, 27.61, 27.8125, 27.8125, 27.665, 27.665, 27.535, 27.535, 26.7525, 26.7525, 26.58, 26.58, 26.98, 26.98, 26.915, 26.915, 27.1425, 27.1425, 27.4925, 27.4925, 27.59, 27.59, 27.4875, 27.4875, 27.265, 27.265, 26.8, 26.8, 26.8475, 26.8475, 26.685, 26.685, 26.7625, 26.7625, 27.11, 27.11, 27.1175, 27.1175, 26.7825, 26.7825, 26.85, 26.85, 27.115, 27.115, 27.0025, 27.0025, 26.6875, 26.6875, 26.7325, 26.7325, 27.3225, 27.3225, 27.0775, 27.0775, 26.995, 26.995, 26.855, 26.855, 26.735, 26.735, 26.6875, 26.6875, 26.6325, 26.6325, 26.8575, 26.8575, 26.795, 26.795, 26.9925, 26.9925]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.8 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 17, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
   Client 11, noise    level: 0.5000 
   Client 0, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 7, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 12, noise    level: 0.5000 
   Client 10, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 13, noise    level: 0.5000 
   Client 14, noise    level: 0.5000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.119, Test loss: 2.012, Test accuracy: 29.70
Round   0, Global train loss: 2.119, Global test loss: 2.020, Global test accuracy: 30.45
Round   1, Train loss: 2.001, Test loss: 1.823, Test accuracy: 36.78
Round   1, Global train loss: 2.001, Global test loss: 1.767, Global test accuracy: 40.35
Round   2, Train loss: 1.863, Test loss: 1.712, Test accuracy: 41.18
Round   2, Global train loss: 1.863, Global test loss: 1.621, Global test accuracy: 46.37
Round   3, Train loss: 1.847, Test loss: 1.682, Test accuracy: 42.14
Round   3, Global train loss: 1.847, Global test loss: 1.540, Global test accuracy: 49.34
Round   4, Train loss: 1.748, Test loss: 1.635, Test accuracy: 44.17
Round   4, Global train loss: 1.748, Global test loss: 1.463, Global test accuracy: 52.21
Round   5, Train loss: 1.722, Test loss: 1.573, Test accuracy: 46.26
Round   5, Global train loss: 1.722, Global test loss: 1.397, Global test accuracy: 54.12
Round   6, Train loss: 1.666, Test loss: 1.572, Test accuracy: 45.89
Round   6, Global train loss: 1.666, Global test loss: 1.345, Global test accuracy: 55.63
Round   7, Train loss: 1.660, Test loss: 1.554, Test accuracy: 47.30
Round   7, Global train loss: 1.660, Global test loss: 1.320, Global test accuracy: 59.20
Round   8, Train loss: 1.540, Test loss: 1.526, Test accuracy: 48.35
Round   8, Global train loss: 1.540, Global test loss: 1.226, Global test accuracy: 60.86
Round   9, Train loss: 1.563, Test loss: 1.507, Test accuracy: 49.29
Round   9, Global train loss: 1.563, Global test loss: 1.208, Global test accuracy: 62.07
Round  10, Train loss: 1.541, Test loss: 1.452, Test accuracy: 51.54
Round  10, Global train loss: 1.541, Global test loss: 1.177, Global test accuracy: 63.55
Round  11, Train loss: 1.468, Test loss: 1.442, Test accuracy: 52.08
Round  11, Global train loss: 1.468, Global test loss: 1.124, Global test accuracy: 64.42
Round  12, Train loss: 1.509, Test loss: 1.424, Test accuracy: 53.26
Round  12, Global train loss: 1.509, Global test loss: 1.143, Global test accuracy: 64.93
Round  13, Train loss: 1.578, Test loss: 1.395, Test accuracy: 54.62
Round  13, Global train loss: 1.578, Global test loss: 1.157, Global test accuracy: 65.50
Round  14, Train loss: 1.508, Test loss: 1.379, Test accuracy: 55.19
Round  14, Global train loss: 1.508, Global test loss: 1.141, Global test accuracy: 65.64
Round  15, Train loss: 1.591, Test loss: 1.371, Test accuracy: 55.56
Round  15, Global train loss: 1.591, Global test loss: 1.181, Global test accuracy: 67.09
Round  16, Train loss: 1.465, Test loss: 1.356, Test accuracy: 56.32
Round  16, Global train loss: 1.465, Global test loss: 1.137, Global test accuracy: 67.07
Round  17, Train loss: 1.452, Test loss: 1.351, Test accuracy: 56.47
Round  17, Global train loss: 1.452, Global test loss: 1.112, Global test accuracy: 67.45
Round  18, Train loss: 1.433, Test loss: 1.347, Test accuracy: 56.66
Round  18, Global train loss: 1.433, Global test loss: 1.102, Global test accuracy: 67.32
Round  19, Train loss: 1.464, Test loss: 1.344, Test accuracy: 56.77
Round  19, Global train loss: 1.464, Global test loss: 1.103, Global test accuracy: 67.07
Round  20, Train loss: 1.356, Test loss: 1.337, Test accuracy: 57.33
Round  20, Global train loss: 1.356, Global test loss: 1.027, Global test accuracy: 68.52
Round  21, Train loss: 1.362, Test loss: 1.326, Test accuracy: 57.67
Round  21, Global train loss: 1.362, Global test loss: 1.040, Global test accuracy: 68.30
Round  22, Train loss: 1.393, Test loss: 1.324, Test accuracy: 57.74
Round  22, Global train loss: 1.393, Global test loss: 1.065, Global test accuracy: 68.38
Round  23, Train loss: 1.345, Test loss: 1.322, Test accuracy: 57.80
Round  23, Global train loss: 1.345, Global test loss: 1.035, Global test accuracy: 68.57
Round  24, Train loss: 1.371, Test loss: 1.319, Test accuracy: 57.91
Round  24, Global train loss: 1.371, Global test loss: 1.049, Global test accuracy: 68.95
Round  25, Train loss: 1.385, Test loss: 1.317, Test accuracy: 58.04
Round  25, Global train loss: 1.385, Global test loss: 1.051, Global test accuracy: 69.13
Round  26, Train loss: 1.285, Test loss: 1.309, Test accuracy: 58.41
Round  26, Global train loss: 1.285, Global test loss: 0.969, Global test accuracy: 70.03
Round  27, Train loss: 1.254, Test loss: 1.294, Test accuracy: 59.03
Round  27, Global train loss: 1.254, Global test loss: 0.938, Global test accuracy: 70.11
Round  28, Train loss: 1.185, Test loss: 1.282, Test accuracy: 59.53
Round  28, Global train loss: 1.185, Global test loss: 0.964, Global test accuracy: 70.04
Round  29, Train loss: 1.228, Test loss: 1.291, Test accuracy: 59.24
Round  29, Global train loss: 1.228, Global test loss: 0.974, Global test accuracy: 70.22
Round  30, Train loss: 1.247, Test loss: 1.298, Test accuracy: 59.05
Round  30, Global train loss: 1.247, Global test loss: 0.988, Global test accuracy: 69.86
Round  31, Train loss: 1.259, Test loss: 1.295, Test accuracy: 58.90
Round  31, Global train loss: 1.259, Global test loss: 0.962, Global test accuracy: 70.95
Round  32, Train loss: 1.294, Test loss: 1.289, Test accuracy: 58.92
Round  32, Global train loss: 1.294, Global test loss: 0.962, Global test accuracy: 70.62
Round  33, Train loss: 1.223, Test loss: 1.283, Test accuracy: 59.37
Round  33, Global train loss: 1.223, Global test loss: 0.949, Global test accuracy: 70.73
Round  34, Train loss: 1.205, Test loss: 1.302, Test accuracy: 58.98
Round  34, Global train loss: 1.205, Global test loss: 0.963, Global test accuracy: 70.81
Round  35, Train loss: 1.184, Test loss: 1.306, Test accuracy: 58.84
Round  35, Global train loss: 1.184, Global test loss: 0.929, Global test accuracy: 71.20
Round  36, Train loss: 1.090, Test loss: 1.299, Test accuracy: 58.91
Round  36, Global train loss: 1.090, Global test loss: 0.913, Global test accuracy: 71.33
Round  37, Train loss: 1.324, Test loss: 1.310, Test accuracy: 58.63
Round  37, Global train loss: 1.324, Global test loss: 1.027, Global test accuracy: 69.85
Round  38, Train loss: 1.252, Test loss: 1.304, Test accuracy: 59.13
Round  38, Global train loss: 1.252, Global test loss: 0.985, Global test accuracy: 70.61
Round  39, Train loss: 1.165, Test loss: 1.306, Test accuracy: 59.17
Round  39, Global train loss: 1.165, Global test loss: 0.945, Global test accuracy: 70.68
Round  40, Train loss: 1.104, Test loss: 1.291, Test accuracy: 59.47
Round  40, Global train loss: 1.104, Global test loss: 0.913, Global test accuracy: 71.22
Round  41, Train loss: 1.059, Test loss: 1.308, Test accuracy: 59.00
Round  41, Global train loss: 1.059, Global test loss: 0.931, Global test accuracy: 71.03
Round  42, Train loss: 1.186, Test loss: 1.301, Test accuracy: 59.37
Round  42, Global train loss: 1.186, Global test loss: 0.958, Global test accuracy: 70.30
Round  43, Train loss: 1.222, Test loss: 1.291, Test accuracy: 59.65
Round  43, Global train loss: 1.222, Global test loss: 0.952, Global test accuracy: 71.12
Round  44, Train loss: 1.042, Test loss: 1.293, Test accuracy: 59.47
Round  44, Global train loss: 1.042, Global test loss: 0.892, Global test accuracy: 71.76
Round  45, Train loss: 1.155, Test loss: 1.305, Test accuracy: 59.12
Round  45, Global train loss: 1.155, Global test loss: 0.986, Global test accuracy: 70.22
Round  46, Train loss: 1.129, Test loss: 1.307, Test accuracy: 59.11
Round  46, Global train loss: 1.129, Global test loss: 0.937, Global test accuracy: 70.93
Round  47, Train loss: 1.046, Test loss: 1.301, Test accuracy: 59.11
Round  47, Global train loss: 1.046, Global test loss: 0.898, Global test accuracy: 71.86
Round  48, Train loss: 1.241, Test loss: 1.297, Test accuracy: 59.34
Round  48, Global train loss: 1.241, Global test loss: 0.970, Global test accuracy: 70.84
Round  49, Train loss: 1.154, Test loss: 1.304, Test accuracy: 59.42
Round  49, Global train loss: 1.154, Global test loss: 0.955, Global test accuracy: 70.03
Round  50, Train loss: 1.052, Test loss: 1.298, Test accuracy: 59.67
Round  50, Global train loss: 1.052, Global test loss: 0.932, Global test accuracy: 70.97
Round  51, Train loss: 1.192, Test loss: 1.311, Test accuracy: 59.38
Round  51, Global train loss: 1.192, Global test loss: 0.977, Global test accuracy: 69.94
Round  52, Train loss: 1.215, Test loss: 1.315, Test accuracy: 59.33
Round  52, Global train loss: 1.215, Global test loss: 1.012, Global test accuracy: 69.11
Round  53, Train loss: 1.102, Test loss: 1.315, Test accuracy: 59.33
Round  53, Global train loss: 1.102, Global test loss: 0.974, Global test accuracy: 69.29
Round  54, Train loss: 1.178, Test loss: 1.317, Test accuracy: 59.17
Round  54, Global train loss: 1.178, Global test loss: 0.987, Global test accuracy: 70.13
Round  55, Train loss: 1.086, Test loss: 1.329, Test accuracy: 59.05
Round  55, Global train loss: 1.086, Global test loss: 0.965, Global test accuracy: 70.53
Round  56, Train loss: 1.108, Test loss: 1.330, Test accuracy: 59.16
Round  56, Global train loss: 1.108, Global test loss: 0.947, Global test accuracy: 70.43
Round  57, Train loss: 1.123, Test loss: 1.340, Test accuracy: 58.88
Round  57, Global train loss: 1.123, Global test loss: 0.984, Global test accuracy: 69.86
Round  58, Train loss: 1.169, Test loss: 1.351, Test accuracy: 58.41
Round  58, Global train loss: 1.169, Global test loss: 1.002, Global test accuracy: 69.12
Round  59, Train loss: 1.025, Test loss: 1.342, Test accuracy: 58.77
Round  59, Global train loss: 1.025, Global test loss: 0.955, Global test accuracy: 69.83
Round  60, Train loss: 1.055, Test loss: 1.349, Test accuracy: 58.81
Round  60, Global train loss: 1.055, Global test loss: 0.945, Global test accuracy: 71.11
Round  61, Train loss: 0.932, Test loss: 1.344, Test accuracy: 59.01
Round  61, Global train loss: 0.932, Global test loss: 0.885, Global test accuracy: 71.42
Round  62, Train loss: 1.135, Test loss: 1.329, Test accuracy: 59.45
Round  62, Global train loss: 1.135, Global test loss: 0.952, Global test accuracy: 70.30
Round  63, Train loss: 1.203, Test loss: 1.339, Test accuracy: 59.32
Round  63, Global train loss: 1.203, Global test loss: 0.986, Global test accuracy: 69.52
Round  64, Train loss: 1.002, Test loss: 1.340, Test accuracy: 59.23
Round  64, Global train loss: 1.002, Global test loss: 0.913, Global test accuracy: 70.81
Round  65, Train loss: 0.953, Test loss: 1.335, Test accuracy: 59.37
Round  65, Global train loss: 0.953, Global test loss: 0.912, Global test accuracy: 71.18
Round  66, Train loss: 1.144, Test loss: 1.333, Test accuracy: 59.35
Round  66, Global train loss: 1.144, Global test loss: 0.979, Global test accuracy: 69.87
Round  67, Train loss: 1.055, Test loss: 1.349, Test accuracy: 58.80
Round  67, Global train loss: 1.055, Global test loss: 0.944, Global test accuracy: 70.33
Round  68, Train loss: 1.007, Test loss: 1.351, Test accuracy: 58.90
Round  68, Global train loss: 1.007, Global test loss: 0.921, Global test accuracy: 70.80
Round  69, Train loss: 1.120, Test loss: 1.365, Test accuracy: 58.73
Round  69, Global train loss: 1.120, Global test loss: 0.986, Global test accuracy: 69.76
Round  70, Train loss: 1.000, Test loss: 1.374, Test accuracy: 58.45
Round  70, Global train loss: 1.000, Global test loss: 0.975, Global test accuracy: 69.17
Round  71, Train loss: 1.078, Test loss: 1.363, Test accuracy: 58.95
Round  71, Global train loss: 1.078, Global test loss: 0.981, Global test accuracy: 69.93
Round  72, Train loss: 0.991, Test loss: 1.364, Test accuracy: 58.90
Round  72, Global train loss: 0.991, Global test loss: 0.933, Global test accuracy: 70.60
Round  73, Train loss: 1.019, Test loss: 1.375, Test accuracy: 58.59
Round  73, Global train loss: 1.019, Global test loss: 0.945, Global test accuracy: 70.47
Round  74, Train loss: 1.002, Test loss: 1.348, Test accuracy: 59.22
Round  74, Global train loss: 1.002, Global test loss: 0.951, Global test accuracy: 70.44
Round  75, Train loss: 0.954, Test loss: 1.360, Test accuracy: 59.09
Round  75, Global train loss: 0.954, Global test loss: 0.925, Global test accuracy: 71.20
Round  76, Train loss: 1.168, Test loss: 1.350, Test accuracy: 59.22
Round  76, Global train loss: 1.168, Global test loss: 1.010, Global test accuracy: 69.15
Round  77, Train loss: 1.000, Test loss: 1.357, Test accuracy: 59.17
Round  77, Global train loss: 1.000, Global test loss: 0.984, Global test accuracy: 69.52
Round  78, Train loss: 0.960, Test loss: 1.367, Test accuracy: 58.84
Round  78, Global train loss: 0.960, Global test loss: 0.973, Global test accuracy: 69.36
Round  79, Train loss: 0.953, Test loss: 1.368, Test accuracy: 58.98
Round  79, Global train loss: 0.953, Global test loss: 0.976, Global test accuracy: 69.46
Round  80, Train loss: 1.017, Test loss: 1.387, Test accuracy: 58.51
Round  80, Global train loss: 1.017, Global test loss: 0.984, Global test accuracy: 69.38
Round  81, Train loss: 0.952, Test loss: 1.387, Test accuracy: 58.47
Round  81, Global train loss: 0.952, Global test loss: 0.929, Global test accuracy: 70.72
Round  82, Train loss: 0.992, Test loss: 1.405, Test accuracy: 57.91
Round  82, Global train loss: 0.992, Global test loss: 0.972, Global test accuracy: 70.05
Round  83, Train loss: 1.072, Test loss: 1.395, Test accuracy: 58.37
Round  83, Global train loss: 1.072, Global test loss: 0.982, Global test accuracy: 69.58
Round  84, Train loss: 1.021, Test loss: 1.395, Test accuracy: 58.41
Round  84, Global train loss: 1.021, Global test loss: 1.004, Global test accuracy: 68.52
Round  85, Train loss: 1.050, Test loss: 1.396, Test accuracy: 58.46
Round  85, Global train loss: 1.050, Global test loss: 0.996, Global test accuracy: 68.93
Round  86, Train loss: 1.015, Test loss: 1.394, Test accuracy: 58.37
Round  86, Global train loss: 1.015, Global test loss: 0.954, Global test accuracy: 70.02
Round  87, Train loss: 0.929, Test loss: 1.406, Test accuracy: 58.21
Round  87, Global train loss: 0.929, Global test loss: 0.930, Global test accuracy: 70.67
Round  88, Train loss: 1.020, Test loss: 1.392, Test accuracy: 58.73
Round  88, Global train loss: 1.020, Global test loss: 1.014, Global test accuracy: 68.69
Round  89, Train loss: 1.031, Test loss: 1.380, Test accuracy: 58.98
Round  89, Global train loss: 1.031, Global test loss: 0.960, Global test accuracy: 70.35
Round  90, Train loss: 1.055, Test loss: 1.387, Test accuracy: 58.88
Round  90, Global train loss: 1.055, Global test loss: 1.004, Global test accuracy: 69.12
Round  91, Train loss: 0.935, Test loss: 1.393, Test accuracy: 58.80
Round  91, Global train loss: 0.935, Global test loss: 0.952, Global test accuracy: 69.77
Round  92, Train loss: 1.004, Test loss: 1.397, Test accuracy: 58.66
Round  92, Global train loss: 1.004, Global test loss: 0.999, Global test accuracy: 69.19
Round  93, Train loss: 1.063, Test loss: 1.410, Test accuracy: 58.52
Round  93, Global train loss: 1.063, Global test loss: 1.021, Global test accuracy: 68.29
Round  94, Train loss: 1.109, Test loss: 1.414, Test accuracy: 58.41
Round  94, Global train loss: 1.109, Global test loss: 0.990, Global test accuracy: 69.12
Round  95, Train loss: 0.964, Test loss: 1.417, Test accuracy: 58.37
Round  95, Global train loss: 0.964, Global test loss: 1.041, Global test accuracy: 68.09
Round  96, Train loss: 0.996, Test loss: 1.411, Test accuracy: 58.52
Round  96, Global train loss: 0.996, Global test loss: 0.979, Global test accuracy: 69.72
Round  97, Train loss: 1.001, Test loss: 1.421, Test accuracy: 58.30
Round  97, Global train loss: 1.001, Global test loss: 1.008, Global test accuracy: 69.13
Round  98, Train loss: 0.926, Test loss: 1.434, Test accuracy: 58.06
Round  98, Global train loss: 0.926, Global test loss: 0.951, Global test accuracy: 70.54
Round  99, Train loss: 0.917, Test loss: 1.422, Test accuracy: 58.38
Round  99, Global train loss: 0.917, Global test loss: 0.976, Global test accuracy: 69.50
Final Round, Train loss: 0.638, Test loss: 1.702, Test accuracy: 57.08
Final Round, Global train loss: 0.638, Global test loss: 0.976, Global test accuracy: 69.50
Average accuracy final 10 rounds: 58.487500000000004 

Average global accuracy final 10 rounds: 69.24849999999999 

6447.752269983292
[4.865501403808594, 9.731002807617188, 14.602159023284912, 19.473315238952637, 24.33886170387268, 29.204408168792725, 34.08626127243042, 38.968114376068115, 43.84349012374878, 48.71886587142944, 53.61851692199707, 58.5181679725647, 63.37976145744324, 68.24135494232178, 73.1063768863678, 77.97139883041382, 82.83641910552979, 87.70143938064575, 92.58104109764099, 97.46064281463623, 102.32509207725525, 107.18954133987427, 112.03495168685913, 116.880362033844, 121.72124981880188, 126.56213760375977, 131.3998146057129, 136.23749160766602, 141.1087248325348, 145.97995805740356, 150.85767078399658, 155.7353835105896, 160.59960222244263, 165.46382093429565, 170.33468079566956, 175.20554065704346, 180.0925805568695, 184.97962045669556, 189.83869576454163, 194.6977710723877, 199.5685911178589, 204.43941116333008, 209.31154823303223, 214.18368530273438, 219.04743242263794, 223.9111795425415, 228.78091621398926, 233.650652885437, 238.53953552246094, 243.42841815948486, 247.63907122612, 251.84972429275513, 256.20248794555664, 260.55525159835815, 264.74823665618896, 268.9412217140198, 273.12093210220337, 277.30064249038696, 282.09193229675293, 286.8832221031189, 291.67107582092285, 296.4589295387268, 301.2714443206787, 306.0839591026306, 310.86954617500305, 315.6551332473755, 320.8788697719574, 326.1026062965393, 331.29539465904236, 336.4881830215454, 341.66851806640625, 346.8488531112671, 351.921852350235, 356.9948515892029, 362.2416663169861, 367.4884810447693, 372.7576701641083, 378.02685928344727, 383.28015756607056, 388.53345584869385, 393.80374121665955, 399.07402658462524, 404.31394934654236, 409.5538721084595, 414.78526282310486, 420.01665353775024, 425.2442605495453, 430.47186756134033, 435.68989276885986, 440.9079179763794, 446.4311752319336, 451.9544324874878, 457.14948630332947, 462.34454011917114, 467.60231614112854, 472.86009216308594, 478.10122656822205, 483.34236097335815, 488.64150834083557, 493.940655708313, 499.1422338485718, 504.34381198883057, 509.3500714302063, 514.356330871582, 519.366204738617, 524.3760786056519, 529.3861598968506, 534.3962411880493, 539.0316293239594, 543.6670174598694, 549.3115315437317, 554.956045627594, 559.4375340938568, 563.9190225601196, 568.352064371109, 572.7851061820984, 580.3982241153717, 588.011342048645, 592.4380524158478, 596.8647627830505, 601.2618274688721, 605.6588921546936, 610.1010222434998, 614.5431523323059, 618.9773743152618, 623.4115962982178, 627.9563562870026, 632.5011162757874, 636.9338989257812, 641.3666815757751, 645.8136579990387, 650.2606344223022, 654.6320917606354, 659.0035490989685, 663.9927587509155, 668.9819684028625, 673.9716417789459, 678.9613151550293, 684.7926483154297, 690.6239814758301, 695.6089940071106, 700.5940065383911, 705.5404794216156, 710.4869523048401, 715.4785282611847, 720.4701042175293, 725.5789971351624, 730.6878900527954, 735.8203489780426, 740.9528079032898, 745.9274907112122, 750.9021735191345, 755.8709554672241, 760.8397374153137, 765.8270320892334, 770.8143267631531, 775.8117609024048, 780.8091950416565, 785.8109767436981, 790.8127584457397, 795.7957057952881, 800.7786531448364, 805.7279160022736, 810.6771788597107, 815.6117441654205, 820.5463094711304, 825.7316043376923, 830.9168992042542, 835.9197602272034, 840.9226212501526, 845.9263763427734, 850.9301314353943, 855.9439220428467, 860.9577126502991, 865.9672689437866, 870.9768252372742, 875.9674134254456, 880.958001613617, 885.9187245368958, 890.8794474601746, 895.882081747055, 900.8847160339355, 905.88316655159, 910.8816170692444, 915.8605921268463, 920.8395671844482, 925.7745456695557, 930.7095241546631, 935.6427531242371, 940.575982093811, 945.5647301673889, 950.5534782409668, 955.5462274551392, 960.5389766693115, 965.5165684223175, 970.4941601753235, 975.4833929538727, 980.4726257324219, 985.473726272583, 990.4748268127441, 993.0070698261261, 995.539312839508]
[29.7, 29.7, 36.7825, 36.7825, 41.18, 41.18, 42.1425, 42.1425, 44.1675, 44.1675, 46.2625, 46.2625, 45.8925, 45.8925, 47.295, 47.295, 48.35, 48.35, 49.2925, 49.2925, 51.5425, 51.5425, 52.0825, 52.0825, 53.26, 53.26, 54.6225, 54.6225, 55.19, 55.19, 55.56, 55.56, 56.3225, 56.3225, 56.465, 56.465, 56.6625, 56.6625, 56.77, 56.77, 57.3275, 57.3275, 57.6675, 57.6675, 57.745, 57.745, 57.805, 57.805, 57.915, 57.915, 58.0425, 58.0425, 58.4125, 58.4125, 59.0325, 59.0325, 59.53, 59.53, 59.2425, 59.2425, 59.045, 59.045, 58.8975, 58.8975, 58.9175, 58.9175, 59.365, 59.365, 58.98, 58.98, 58.835, 58.835, 58.91, 58.91, 58.6325, 58.6325, 59.135, 59.135, 59.1725, 59.1725, 59.465, 59.465, 58.9975, 58.9975, 59.365, 59.365, 59.645, 59.645, 59.4725, 59.4725, 59.125, 59.125, 59.1125, 59.1125, 59.1075, 59.1075, 59.345, 59.345, 59.4225, 59.4225, 59.67, 59.67, 59.3825, 59.3825, 59.33, 59.33, 59.3275, 59.3275, 59.175, 59.175, 59.0475, 59.0475, 59.165, 59.165, 58.8825, 58.8825, 58.405, 58.405, 58.7725, 58.7725, 58.8125, 58.8125, 59.005, 59.005, 59.455, 59.455, 59.3175, 59.3175, 59.235, 59.235, 59.3675, 59.3675, 59.355, 59.355, 58.805, 58.805, 58.8975, 58.8975, 58.735, 58.735, 58.4475, 58.4475, 58.955, 58.955, 58.9, 58.9, 58.595, 58.595, 59.2175, 59.2175, 59.09, 59.09, 59.215, 59.215, 59.1725, 59.1725, 58.84, 58.84, 58.985, 58.985, 58.51, 58.51, 58.4675, 58.4675, 57.9125, 57.9125, 58.365, 58.365, 58.41, 58.41, 58.4625, 58.4625, 58.365, 58.365, 58.21, 58.21, 58.73, 58.73, 58.9775, 58.9775, 58.8775, 58.8775, 58.7975, 58.7975, 58.655, 58.655, 58.5175, 58.5175, 58.41, 58.41, 58.365, 58.365, 58.515, 58.515, 58.295, 58.295, 58.0625, 58.0625, 58.38, 58.38, 57.0775, 57.0775]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.8 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 4, noise    level: 0.5000 
   Client 12, noise    level: 0.5000 
   Client 0, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 15, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 18, noise    level: 0.5000 
   Client 7, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 14, noise    level: 0.5000 
   Client 10, noise    level: 0.5000 
   Client 17, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
   Client 19, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.149, Test loss: 2.085, Test accuracy: 28.89
Round   0, Global train loss: 2.149, Global test loss: 2.090, Global test accuracy: 30.47
Round   1, Train loss: 2.031, Test loss: 1.915, Test accuracy: 33.63
Round   1, Global train loss: 2.031, Global test loss: 1.853, Global test accuracy: 37.58
Round   2, Train loss: 1.978, Test loss: 1.832, Test accuracy: 36.03
Round   2, Global train loss: 1.978, Global test loss: 1.756, Global test accuracy: 40.36
Round   3, Train loss: 1.937, Test loss: 1.799, Test accuracy: 36.81
Round   3, Global train loss: 1.937, Global test loss: 1.674, Global test accuracy: 44.22
Round   4, Train loss: 1.883, Test loss: 1.751, Test accuracy: 38.13
Round   4, Global train loss: 1.883, Global test loss: 1.600, Global test accuracy: 45.19
Round   5, Train loss: 1.868, Test loss: 1.741, Test accuracy: 39.55
Round   5, Global train loss: 1.868, Global test loss: 1.628, Global test accuracy: 47.54
Round   6, Train loss: 1.876, Test loss: 1.728, Test accuracy: 39.88
Round   6, Global train loss: 1.876, Global test loss: 1.566, Global test accuracy: 50.16
Round   7, Train loss: 1.800, Test loss: 1.703, Test accuracy: 40.55
Round   7, Global train loss: 1.800, Global test loss: 1.497, Global test accuracy: 50.65
Round   8, Train loss: 1.793, Test loss: 1.681, Test accuracy: 41.86
Round   8, Global train loss: 1.793, Global test loss: 1.505, Global test accuracy: 52.50
Round   9, Train loss: 1.737, Test loss: 1.648, Test accuracy: 42.76
Round   9, Global train loss: 1.737, Global test loss: 1.433, Global test accuracy: 51.66
Round  10, Train loss: 1.777, Test loss: 1.582, Test accuracy: 46.20
Round  10, Global train loss: 1.777, Global test loss: 1.430, Global test accuracy: 55.32
Round  11, Train loss: 1.774, Test loss: 1.574, Test accuracy: 46.77
Round  11, Global train loss: 1.774, Global test loss: 1.405, Global test accuracy: 55.95
Round  12, Train loss: 1.715, Test loss: 1.550, Test accuracy: 47.86
Round  12, Global train loss: 1.715, Global test loss: 1.413, Global test accuracy: 56.00
Round  13, Train loss: 1.716, Test loss: 1.537, Test accuracy: 48.71
Round  13, Global train loss: 1.716, Global test loss: 1.354, Global test accuracy: 58.47
Round  14, Train loss: 1.664, Test loss: 1.535, Test accuracy: 48.85
Round  14, Global train loss: 1.664, Global test loss: 1.326, Global test accuracy: 58.99
Round  15, Train loss: 1.759, Test loss: 1.508, Test accuracy: 50.02
Round  15, Global train loss: 1.759, Global test loss: 1.372, Global test accuracy: 60.30
Round  16, Train loss: 1.654, Test loss: 1.490, Test accuracy: 50.69
Round  16, Global train loss: 1.654, Global test loss: 1.315, Global test accuracy: 60.77
Round  17, Train loss: 1.684, Test loss: 1.478, Test accuracy: 51.23
Round  17, Global train loss: 1.684, Global test loss: 1.326, Global test accuracy: 61.44
Round  18, Train loss: 1.680, Test loss: 1.463, Test accuracy: 51.97
Round  18, Global train loss: 1.680, Global test loss: 1.328, Global test accuracy: 61.45
Round  19, Train loss: 1.618, Test loss: 1.443, Test accuracy: 52.82
Round  19, Global train loss: 1.618, Global test loss: 1.255, Global test accuracy: 62.25
Round  20, Train loss: 1.653, Test loss: 1.444, Test accuracy: 52.61
Round  20, Global train loss: 1.653, Global test loss: 1.285, Global test accuracy: 61.01
Round  21, Train loss: 1.618, Test loss: 1.417, Test accuracy: 53.85
Round  21, Global train loss: 1.618, Global test loss: 1.238, Global test accuracy: 62.19
Round  22, Train loss: 1.583, Test loss: 1.409, Test accuracy: 54.51
Round  22, Global train loss: 1.583, Global test loss: 1.249, Global test accuracy: 62.80
Round  23, Train loss: 1.656, Test loss: 1.379, Test accuracy: 55.77
Round  23, Global train loss: 1.656, Global test loss: 1.238, Global test accuracy: 64.27
Round  24, Train loss: 1.538, Test loss: 1.364, Test accuracy: 56.51
Round  24, Global train loss: 1.538, Global test loss: 1.192, Global test accuracy: 64.31
Round  25, Train loss: 1.625, Test loss: 1.374, Test accuracy: 56.42
Round  25, Global train loss: 1.625, Global test loss: 1.256, Global test accuracy: 63.62
Round  26, Train loss: 1.545, Test loss: 1.366, Test accuracy: 56.49
Round  26, Global train loss: 1.545, Global test loss: 1.199, Global test accuracy: 65.11
Round  27, Train loss: 1.577, Test loss: 1.348, Test accuracy: 56.82
Round  27, Global train loss: 1.577, Global test loss: 1.200, Global test accuracy: 65.31
Round  28, Train loss: 1.495, Test loss: 1.343, Test accuracy: 57.06
Round  28, Global train loss: 1.495, Global test loss: 1.151, Global test accuracy: 65.08
Round  29, Train loss: 1.487, Test loss: 1.340, Test accuracy: 57.30
Round  29, Global train loss: 1.487, Global test loss: 1.151, Global test accuracy: 66.04
Round  30, Train loss: 1.487, Test loss: 1.343, Test accuracy: 57.59
Round  30, Global train loss: 1.487, Global test loss: 1.162, Global test accuracy: 66.24
Round  31, Train loss: 1.489, Test loss: 1.346, Test accuracy: 57.39
Round  31, Global train loss: 1.489, Global test loss: 1.141, Global test accuracy: 65.82
Round  32, Train loss: 1.508, Test loss: 1.344, Test accuracy: 57.15
Round  32, Global train loss: 1.508, Global test loss: 1.163, Global test accuracy: 66.53
Round  33, Train loss: 1.491, Test loss: 1.339, Test accuracy: 57.26
Round  33, Global train loss: 1.491, Global test loss: 1.143, Global test accuracy: 66.76
Round  34, Train loss: 1.470, Test loss: 1.324, Test accuracy: 58.19
Round  34, Global train loss: 1.470, Global test loss: 1.113, Global test accuracy: 67.26
Round  35, Train loss: 1.459, Test loss: 1.320, Test accuracy: 58.62
Round  35, Global train loss: 1.459, Global test loss: 1.141, Global test accuracy: 67.81
Round  36, Train loss: 1.398, Test loss: 1.320, Test accuracy: 58.39
Round  36, Global train loss: 1.398, Global test loss: 1.083, Global test accuracy: 67.94
Round  37, Train loss: 1.560, Test loss: 1.305, Test accuracy: 59.16
Round  37, Global train loss: 1.560, Global test loss: 1.159, Global test accuracy: 68.20
Round  38, Train loss: 1.453, Test loss: 1.304, Test accuracy: 59.45
Round  38, Global train loss: 1.453, Global test loss: 1.152, Global test accuracy: 66.71
Round  39, Train loss: 1.479, Test loss: 1.301, Test accuracy: 59.58
Round  39, Global train loss: 1.479, Global test loss: 1.132, Global test accuracy: 67.21
Round  40, Train loss: 1.445, Test loss: 1.301, Test accuracy: 59.35
Round  40, Global train loss: 1.445, Global test loss: 1.072, Global test accuracy: 68.43
Round  41, Train loss: 1.456, Test loss: 1.297, Test accuracy: 59.38
Round  41, Global train loss: 1.456, Global test loss: 1.098, Global test accuracy: 68.70
Round  42, Train loss: 1.364, Test loss: 1.300, Test accuracy: 59.43
Round  42, Global train loss: 1.364, Global test loss: 1.060, Global test accuracy: 68.81
Round  43, Train loss: 1.473, Test loss: 1.292, Test accuracy: 59.82
Round  43, Global train loss: 1.473, Global test loss: 1.120, Global test accuracy: 68.45
Round  44, Train loss: 1.410, Test loss: 1.289, Test accuracy: 59.91
Round  44, Global train loss: 1.410, Global test loss: 1.069, Global test accuracy: 69.36
Round  45, Train loss: 1.352, Test loss: 1.291, Test accuracy: 59.70
Round  45, Global train loss: 1.352, Global test loss: 1.041, Global test accuracy: 68.64
Round  46, Train loss: 1.462, Test loss: 1.285, Test accuracy: 59.95
Round  46, Global train loss: 1.462, Global test loss: 1.095, Global test accuracy: 69.07
Round  47, Train loss: 1.371, Test loss: 1.281, Test accuracy: 60.38
Round  47, Global train loss: 1.371, Global test loss: 1.077, Global test accuracy: 68.73
Round  48, Train loss: 1.456, Test loss: 1.272, Test accuracy: 60.48
Round  48, Global train loss: 1.456, Global test loss: 1.064, Global test accuracy: 69.70
Round  49, Train loss: 1.359, Test loss: 1.270, Test accuracy: 60.58
Round  49, Global train loss: 1.359, Global test loss: 1.059, Global test accuracy: 69.33
Round  50, Train loss: 1.366, Test loss: 1.258, Test accuracy: 60.60
Round  50, Global train loss: 1.366, Global test loss: 1.043, Global test accuracy: 69.34
Round  51, Train loss: 1.432, Test loss: 1.234, Test accuracy: 61.24
Round  51, Global train loss: 1.432, Global test loss: 1.074, Global test accuracy: 69.06
Round  52, Train loss: 1.419, Test loss: 1.236, Test accuracy: 61.52
Round  52, Global train loss: 1.419, Global test loss: 1.081, Global test accuracy: 69.94
Round  53, Train loss: 1.340, Test loss: 1.228, Test accuracy: 61.67
Round  53, Global train loss: 1.340, Global test loss: 1.054, Global test accuracy: 69.61
Round  54, Train loss: 1.344, Test loss: 1.233, Test accuracy: 61.53
Round  54, Global train loss: 1.344, Global test loss: 1.043, Global test accuracy: 69.66
Round  55, Train loss: 1.384, Test loss: 1.238, Test accuracy: 61.49
Round  55, Global train loss: 1.384, Global test loss: 1.035, Global test accuracy: 69.94
Round  56, Train loss: 1.403, Test loss: 1.244, Test accuracy: 61.10
Round  56, Global train loss: 1.403, Global test loss: 1.051, Global test accuracy: 69.75
Round  57, Train loss: 1.411, Test loss: 1.246, Test accuracy: 61.22
Round  57, Global train loss: 1.411, Global test loss: 1.079, Global test accuracy: 69.69
Round  58, Train loss: 1.395, Test loss: 1.245, Test accuracy: 61.06
Round  58, Global train loss: 1.395, Global test loss: 1.077, Global test accuracy: 69.54
Round  59, Train loss: 1.327, Test loss: 1.256, Test accuracy: 60.72
Round  59, Global train loss: 1.327, Global test loss: 1.062, Global test accuracy: 69.61
Round  60, Train loss: 1.325, Test loss: 1.254, Test accuracy: 60.84
Round  60, Global train loss: 1.325, Global test loss: 1.023, Global test accuracy: 69.27
Round  61, Train loss: 1.292, Test loss: 1.243, Test accuracy: 61.19
Round  61, Global train loss: 1.292, Global test loss: 1.014, Global test accuracy: 70.25
Round  62, Train loss: 1.343, Test loss: 1.241, Test accuracy: 61.41
Round  62, Global train loss: 1.343, Global test loss: 1.017, Global test accuracy: 70.15
Round  63, Train loss: 1.413, Test loss: 1.231, Test accuracy: 61.46
Round  63, Global train loss: 1.413, Global test loss: 1.038, Global test accuracy: 70.78
Round  64, Train loss: 1.303, Test loss: 1.223, Test accuracy: 61.62
Round  64, Global train loss: 1.303, Global test loss: 1.020, Global test accuracy: 69.40
Round  65, Train loss: 1.295, Test loss: 1.225, Test accuracy: 61.86
Round  65, Global train loss: 1.295, Global test loss: 1.018, Global test accuracy: 70.99
Round  66, Train loss: 1.385, Test loss: 1.243, Test accuracy: 61.47
Round  66, Global train loss: 1.385, Global test loss: 1.069, Global test accuracy: 69.24
Round  67, Train loss: 1.302, Test loss: 1.235, Test accuracy: 61.45
Round  67, Global train loss: 1.302, Global test loss: 0.986, Global test accuracy: 70.83
Round  68, Train loss: 1.289, Test loss: 1.237, Test accuracy: 61.31
Round  68, Global train loss: 1.289, Global test loss: 0.994, Global test accuracy: 70.65
Round  69, Train loss: 1.308, Test loss: 1.227, Test accuracy: 61.76
Round  69, Global train loss: 1.308, Global test loss: 1.011, Global test accuracy: 70.66
Round  70, Train loss: 1.275, Test loss: 1.235, Test accuracy: 61.45
Round  70, Global train loss: 1.275, Global test loss: 0.995, Global test accuracy: 71.30
Round  71, Train loss: 1.280, Test loss: 1.235, Test accuracy: 61.45
Round  71, Global train loss: 1.280, Global test loss: 0.982, Global test accuracy: 70.59
Round  72, Train loss: 1.302, Test loss: 1.235, Test accuracy: 61.45
Round  72, Global train loss: 1.302, Global test loss: 0.989, Global test accuracy: 70.92
Round  73, Train loss: 1.306, Test loss: 1.220, Test accuracy: 61.97
Round  73, Global train loss: 1.306, Global test loss: 1.014, Global test accuracy: 70.96
Round  74, Train loss: 1.304, Test loss: 1.236, Test accuracy: 61.35
Round  74, Global train loss: 1.304, Global test loss: 1.019, Global test accuracy: 70.21
Round  75, Train loss: 1.233, Test loss: 1.227, Test accuracy: 61.73
Round  75, Global train loss: 1.233, Global test loss: 0.976, Global test accuracy: 70.37
Round  76, Train loss: 1.370, Test loss: 1.228, Test accuracy: 61.86
Round  76, Global train loss: 1.370, Global test loss: 1.065, Global test accuracy: 70.18
Round  77, Train loss: 1.257, Test loss: 1.217, Test accuracy: 61.93
Round  77, Global train loss: 1.257, Global test loss: 0.978, Global test accuracy: 71.07
Round  78, Train loss: 1.240, Test loss: 1.231, Test accuracy: 61.29
Round  78, Global train loss: 1.240, Global test loss: 0.998, Global test accuracy: 69.74
Round  79, Train loss: 1.317, Test loss: 1.226, Test accuracy: 61.58
Round  79, Global train loss: 1.317, Global test loss: 1.030, Global test accuracy: 70.55
Round  80, Train loss: 1.201, Test loss: 1.232, Test accuracy: 61.45
Round  80, Global train loss: 1.201, Global test loss: 0.986, Global test accuracy: 70.35
Round  81, Train loss: 1.263, Test loss: 1.225, Test accuracy: 61.78
Round  81, Global train loss: 1.263, Global test loss: 0.975, Global test accuracy: 71.01
Round  82, Train loss: 1.272, Test loss: 1.207, Test accuracy: 62.44
Round  82, Global train loss: 1.272, Global test loss: 0.992, Global test accuracy: 70.94
Round  83, Train loss: 1.256, Test loss: 1.211, Test accuracy: 62.28
Round  83, Global train loss: 1.256, Global test loss: 0.982, Global test accuracy: 71.22
Round  84, Train loss: 1.163, Test loss: 1.212, Test accuracy: 62.18
Round  84, Global train loss: 1.163, Global test loss: 0.946, Global test accuracy: 71.41
Round  85, Train loss: 1.228, Test loss: 1.220, Test accuracy: 61.98
Round  85, Global train loss: 1.228, Global test loss: 0.972, Global test accuracy: 70.61
Round  86, Train loss: 1.287, Test loss: 1.201, Test accuracy: 62.73
Round  86, Global train loss: 1.287, Global test loss: 0.999, Global test accuracy: 70.13
Round  87, Train loss: 1.244, Test loss: 1.196, Test accuracy: 62.92
Round  87, Global train loss: 1.244, Global test loss: 0.966, Global test accuracy: 71.14
Round  88, Train loss: 1.261, Test loss: 1.206, Test accuracy: 62.49
Round  88, Global train loss: 1.261, Global test loss: 1.001, Global test accuracy: 71.00
Round  89, Train loss: 1.335, Test loss: 1.210, Test accuracy: 62.24
Round  89, Global train loss: 1.335, Global test loss: 1.009, Global test accuracy: 70.42
Round  90, Train loss: 1.220, Test loss: 1.207, Test accuracy: 62.45
Round  90, Global train loss: 1.220, Global test loss: 0.969, Global test accuracy: 70.96
Round  91, Train loss: 1.229, Test loss: 1.216, Test accuracy: 62.22
Round  91, Global train loss: 1.229, Global test loss: 0.981, Global test accuracy: 71.05/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  92, Train loss: 1.227, Test loss: 1.205, Test accuracy: 62.62
Round  92, Global train loss: 1.227, Global test loss: 0.967, Global test accuracy: 71.01
Round  93, Train loss: 1.264, Test loss: 1.210, Test accuracy: 62.23
Round  93, Global train loss: 1.264, Global test loss: 1.020, Global test accuracy: 69.69
Round  94, Train loss: 1.263, Test loss: 1.220, Test accuracy: 61.74
Round  94, Global train loss: 1.263, Global test loss: 0.984, Global test accuracy: 70.36
Round  95, Train loss: 1.253, Test loss: 1.217, Test accuracy: 61.81
Round  95, Global train loss: 1.253, Global test loss: 0.999, Global test accuracy: 69.60
Round  96, Train loss: 1.254, Test loss: 1.215, Test accuracy: 61.87
Round  96, Global train loss: 1.254, Global test loss: 0.994, Global test accuracy: 70.52
Round  97, Train loss: 1.146, Test loss: 1.212, Test accuracy: 62.11
Round  97, Global train loss: 1.146, Global test loss: 0.964, Global test accuracy: 70.55
Round  98, Train loss: 1.130, Test loss: 1.215, Test accuracy: 62.23
Round  98, Global train loss: 1.130, Global test loss: 0.948, Global test accuracy: 70.80
Round  99, Train loss: 1.161, Test loss: 1.223, Test accuracy: 62.08
Round  99, Global train loss: 1.161, Global test loss: 0.949, Global test accuracy: 70.97
Final Round, Train loss: 0.879, Test loss: 1.357, Test accuracy: 59.20
Final Round, Global train loss: 0.879, Global test loss: 0.949, Global test accuracy: 70.97
Average accuracy final 10 rounds: 62.13625 

Average global accuracy final 10 rounds: 70.54925 

6502.335284233093
[4.87520694732666, 9.75041389465332, 14.953386068344116, 20.156358242034912, 24.805511474609375, 29.454664707183838, 34.156304121017456, 38.857943534851074, 44.115275382995605, 49.37260723114014, 54.6779203414917, 59.98323345184326, 65.27002549171448, 70.5568175315857, 75.87171959877014, 81.18662166595459, 86.50660705566406, 91.82659244537354, 97.11273074150085, 102.39886903762817, 107.68587112426758, 112.97287321090698, 119.01034879684448, 125.04782438278198, 130.33834958076477, 135.62887477874756, 140.91165018081665, 146.19442558288574, 151.68417811393738, 157.173930644989, 162.4483721256256, 167.7228136062622, 173.01596355438232, 178.30911350250244, 183.59212398529053, 188.8751344680786, 194.176611661911, 199.4780888557434, 204.74206733703613, 210.00604581832886, 215.29398941993713, 220.5819330215454, 225.89026999473572, 231.19860696792603, 236.4747805595398, 241.75095415115356, 247.02167296409607, 252.29239177703857, 257.55968284606934, 262.8269739151001, 268.102730512619, 273.37848711013794, 278.6561670303345, 283.933846950531, 289.19602489471436, 294.4582028388977, 299.7351746559143, 305.0121464729309, 310.28128361701965, 315.5504207611084, 320.8155417442322, 326.08066272735596, 331.3530225753784, 336.6253824234009, 341.2942888736725, 345.9631953239441, 350.64380407333374, 355.3244128227234, 360.0063667297363, 364.68832063674927, 369.42942929267883, 374.1705379486084, 378.9047794342041, 383.6390209197998, 388.36213397979736, 393.0852470397949, 397.8214612007141, 402.5576753616333, 407.297648191452, 412.03762102127075, 416.7678105831146, 421.4980001449585, 426.22198128700256, 430.94596242904663, 435.6757547855377, 440.4055471420288, 445.14495944976807, 449.8843717575073, 454.57186794281006, 459.2593641281128, 463.96124958992004, 468.6631350517273, 473.3881185054779, 478.1131019592285, 482.79303312301636, 487.4729642868042, 492.1581416130066, 496.843318939209, 501.52445125579834, 506.2055835723877, 510.90615344047546, 515.6067233085632, 520.3023133277893, 524.9979033470154, 529.6933007240295, 534.3886981010437, 539.0958290100098, 543.8029599189758, 548.5403201580048, 553.2776803970337, 557.98295378685, 562.6882271766663, 567.417323589325, 572.1464200019836, 576.8822159767151, 581.6180119514465, 586.3557007312775, 591.0933895111084, 595.8233706951141, 600.5533518791199, 605.2727143764496, 609.9920768737793, 614.71910405159, 619.4461312294006, 624.2110517024994, 628.9759721755981, 633.6930146217346, 638.4100570678711, 643.127382516861, 647.8447079658508, 652.5562026500702, 657.2676973342896, 661.9648435115814, 666.6619896888733, 671.3515548706055, 676.0411200523376, 680.7245135307312, 685.4079070091248, 690.0467073917389, 694.685507774353, 699.3491041660309, 704.0127005577087, 708.845508813858, 713.6783170700073, 718.3944156169891, 723.110514163971, 727.7798953056335, 732.4492764472961, 737.096922159195, 741.7445678710938, 746.4198997020721, 751.0952315330505, 755.8080289363861, 760.5208263397217, 765.2942111492157, 770.0675959587097, 774.7547104358673, 779.4418249130249, 784.4320292472839, 789.422233581543, 794.1094114780426, 798.7965893745422, 803.4549593925476, 808.113329410553, 812.7614603042603, 817.4095911979675, 822.0923149585724, 826.7750387191772, 831.4556713104248, 836.1363039016724, 840.8238439559937, 845.5113840103149, 850.2073111534119, 854.9032382965088, 859.6257483959198, 864.3482584953308, 869.0550267696381, 873.7617950439453, 878.6266901493073, 883.4915852546692, 888.1764361858368, 892.8612871170044, 897.551563501358, 902.2418398857117, 906.937844991684, 911.6338500976562, 916.5234203338623, 921.4129905700684, 927.3463809490204, 933.2797713279724, 937.959216594696, 942.6386618614197, 947.349503993988, 952.0603461265564, 956.7910711765289, 961.5217962265015, 966.2380747795105, 970.9543533325195, 976.9589350223541, 982.9635167121887, 985.4182856082916, 987.8730545043945]
[28.89, 28.89, 33.63, 33.63, 36.03, 36.03, 36.8075, 36.8075, 38.13, 38.13, 39.545, 39.545, 39.8825, 39.8825, 40.5525, 40.5525, 41.8575, 41.8575, 42.7575, 42.7575, 46.2, 46.2, 46.7725, 46.7725, 47.86, 47.86, 48.7125, 48.7125, 48.855, 48.855, 50.015, 50.015, 50.6925, 50.6925, 51.2325, 51.2325, 51.965, 51.965, 52.8225, 52.8225, 52.61, 52.61, 53.85, 53.85, 54.5075, 54.5075, 55.77, 55.77, 56.505, 56.505, 56.425, 56.425, 56.49, 56.49, 56.82, 56.82, 57.06, 57.06, 57.3, 57.3, 57.5875, 57.5875, 57.3875, 57.3875, 57.1475, 57.1475, 57.2625, 57.2625, 58.19, 58.19, 58.62, 58.62, 58.3875, 58.3875, 59.16, 59.16, 59.455, 59.455, 59.5775, 59.5775, 59.35, 59.35, 59.385, 59.385, 59.4275, 59.4275, 59.8175, 59.8175, 59.9125, 59.9125, 59.6975, 59.6975, 59.955, 59.955, 60.3775, 60.3775, 60.48, 60.48, 60.575, 60.575, 60.5975, 60.5975, 61.2425, 61.2425, 61.5225, 61.5225, 61.675, 61.675, 61.5325, 61.5325, 61.4925, 61.4925, 61.0975, 61.0975, 61.2225, 61.2225, 61.06, 61.06, 60.7175, 60.7175, 60.8425, 60.8425, 61.1875, 61.1875, 61.415, 61.415, 61.46, 61.46, 61.6175, 61.6175, 61.8575, 61.8575, 61.4675, 61.4675, 61.45, 61.45, 61.31, 61.31, 61.7625, 61.7625, 61.4475, 61.4475, 61.45, 61.45, 61.445, 61.445, 61.965, 61.965, 61.35, 61.35, 61.725, 61.725, 61.8625, 61.8625, 61.93, 61.93, 61.2875, 61.2875, 61.5825, 61.5825, 61.455, 61.455, 61.785, 61.785, 62.4425, 62.4425, 62.28, 62.28, 62.18, 62.18, 61.975, 61.975, 62.73, 62.73, 62.925, 62.925, 62.4875, 62.4875, 62.24, 62.24, 62.4525, 62.4525, 62.22, 62.22, 62.62, 62.62, 62.23, 62.23, 61.7425, 61.7425, 61.8125, 61.8125, 61.8725, 61.8725, 62.11, 62.11, 62.2275, 62.2275, 62.075, 62.075, 59.2025, 59.2025]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Co-teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 16, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 17, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
   Client 15, noise    level: 0.5000 
   Client 14, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 18, noise    level: 0.5000 
   Client 11, noise    level: 0.5000 
   Client 10, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
   Client 12, noise    level: 0.5000 
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 2.294, Test loss: 2.203, Test accuracy: 23.90
Round   1, Train loss: 2.240, Test loss: 2.114, Test accuracy: 27.87
Round   2, Train loss: 2.212, Test loss: 2.046, Test accuracy: 33.20
Round   3, Train loss: 2.170, Test loss: 1.994, Test accuracy: 33.70
Round   4, Train loss: 2.103, Test loss: 1.929, Test accuracy: 37.48
Round   5, Train loss: 2.160, Test loss: 1.921, Test accuracy: 39.73
Round   6, Train loss: 2.150, Test loss: 1.941, Test accuracy: 40.25
Round   7, Train loss: 2.139, Test loss: 1.899, Test accuracy: 40.87
Round   8, Train loss: 2.125, Test loss: 1.895, Test accuracy: 41.50
Round   9, Train loss: 2.109, Test loss: 1.851, Test accuracy: 42.61
Round  10, Train loss: 2.119, Test loss: 1.819, Test accuracy: 43.73
Round  11, Train loss: 2.106, Test loss: 1.837, Test accuracy: 44.29
Round  12, Train loss: 2.159, Test loss: 1.819, Test accuracy: 44.96
Round  13, Train loss: 2.050, Test loss: 1.761, Test accuracy: 45.85
Round  14, Train loss: 2.090, Test loss: 1.779, Test accuracy: 46.52
Round  15, Train loss: 2.098, Test loss: 1.793, Test accuracy: 47.29
Round  16, Train loss: 2.097, Test loss: 1.739, Test accuracy: 48.24
Round  17, Train loss: 2.013, Test loss: 1.744, Test accuracy: 49.16
Round  18, Train loss: 2.047, Test loss: 1.728, Test accuracy: 49.79
Round  19, Train loss: 2.085, Test loss: 1.735, Test accuracy: 50.37
Round  20, Train loss: 2.071, Test loss: 1.708, Test accuracy: 50.87
Round  21, Train loss: 2.006, Test loss: 1.690, Test accuracy: 51.48
Round  22, Train loss: 1.979, Test loss: 1.680, Test accuracy: 52.03
Round  23, Train loss: 2.034, Test loss: 1.698, Test accuracy: 52.03
Round  24, Train loss: 2.039, Test loss: 1.688, Test accuracy: 52.61
Round  25, Train loss: 2.024, Test loss: 1.666, Test accuracy: 52.83
Round  26, Train loss: 1.961, Test loss: 1.669, Test accuracy: 53.55
Round  27, Train loss: 2.101, Test loss: 1.645, Test accuracy: 54.16
Round  28, Train loss: 2.032, Test loss: 1.659, Test accuracy: 54.35
Round  29, Train loss: 2.084, Test loss: 1.658, Test accuracy: 54.20
Round  30, Train loss: 2.017, Test loss: 1.636, Test accuracy: 54.62
Round  31, Train loss: 1.886, Test loss: 1.606, Test accuracy: 55.03
Round  32, Train loss: 1.998, Test loss: 1.611, Test accuracy: 55.29
Round  33, Train loss: 1.990, Test loss: 1.612, Test accuracy: 55.60
Round  34, Train loss: 1.938, Test loss: 1.603, Test accuracy: 55.88
Round  35, Train loss: 1.901, Test loss: 1.604, Test accuracy: 55.94
Round  36, Train loss: 1.878, Test loss: 1.597, Test accuracy: 55.63
Round  37, Train loss: 1.888, Test loss: 1.557, Test accuracy: 57.09
Round  38, Train loss: 1.899, Test loss: 1.575, Test accuracy: 56.24
Round  39, Train loss: 1.984, Test loss: 1.588, Test accuracy: 56.27
Round  40, Train loss: 2.035, Test loss: 1.585, Test accuracy: 56.05
Round  41, Train loss: 1.958, Test loss: 1.601, Test accuracy: 55.03
Round  42, Train loss: 1.889, Test loss: 1.587, Test accuracy: 55.88
Round  43, Train loss: 1.946, Test loss: 1.565, Test accuracy: 56.46
Round  44, Train loss: 1.945, Test loss: 1.573, Test accuracy: 56.10
Round  45, Train loss: 1.700, Test loss: 1.537, Test accuracy: 57.23
Round  46, Train loss: 1.944, Test loss: 1.530, Test accuracy: 57.31
Round  47, Train loss: 1.981, Test loss: 1.558, Test accuracy: 56.75
Round  48, Train loss: 1.856, Test loss: 1.525, Test accuracy: 58.12
Round  49, Train loss: 1.907, Test loss: 1.557, Test accuracy: 56.99
Round  50, Train loss: 1.819, Test loss: 1.552, Test accuracy: 57.45
Round  51, Train loss: 2.019, Test loss: 1.542, Test accuracy: 57.10
Round  52, Train loss: 1.979, Test loss: 1.555, Test accuracy: 56.57
Round  53, Train loss: 1.976, Test loss: 1.555, Test accuracy: 56.48
Round  54, Train loss: 1.841, Test loss: 1.537, Test accuracy: 56.88
Round  55, Train loss: 1.975, Test loss: 1.538, Test accuracy: 56.74
Round  56, Train loss: 1.877, Test loss: 1.531, Test accuracy: 57.13
Round  57, Train loss: 1.890, Test loss: 1.541, Test accuracy: 56.33
Round  58, Train loss: 1.957, Test loss: 1.542, Test accuracy: 56.12
Round  59, Train loss: 1.884, Test loss: 1.559, Test accuracy: 55.92
Round  60, Train loss: 1.808, Test loss: 1.518, Test accuracy: 57.20
Round  61, Train loss: 1.882, Test loss: 1.521, Test accuracy: 56.89
Round  62, Train loss: 1.861, Test loss: 1.522, Test accuracy: 56.73
Round  63, Train loss: 1.875, Test loss: 1.509, Test accuracy: 57.47
Round  64, Train loss: 1.870, Test loss: 1.524, Test accuracy: 56.32
Round  65, Train loss: 1.844, Test loss: 1.526, Test accuracy: 56.08
Round  66, Train loss: 1.811, Test loss: 1.488, Test accuracy: 57.85
Round  67, Train loss: 1.833, Test loss: 1.498, Test accuracy: 57.38
Round  68, Train loss: 1.846, Test loss: 1.490, Test accuracy: 57.12
Round  69, Train loss: 1.896, Test loss: 1.527, Test accuracy: 55.69
Round  70, Train loss: 1.739, Test loss: 1.509, Test accuracy: 56.92
Round  71, Train loss: 1.724, Test loss: 1.488, Test accuracy: 57.38
Round  72, Train loss: 1.841, Test loss: 1.509, Test accuracy: 56.55
Round  73, Train loss: 1.852, Test loss: 1.517, Test accuracy: 56.38
Round  74, Train loss: 1.881, Test loss: 1.548, Test accuracy: 54.55
Round  75, Train loss: 1.859, Test loss: 1.520, Test accuracy: 55.52
Round  76, Train loss: 1.816, Test loss: 1.515, Test accuracy: 56.21
Round  77, Train loss: 1.896, Test loss: 1.549, Test accuracy: 54.14
Round  78, Train loss: 1.827, Test loss: 1.535, Test accuracy: 54.88
Round  79, Train loss: 1.878, Test loss: 1.543, Test accuracy: 54.46
Round  80, Train loss: 1.713, Test loss: 1.519, Test accuracy: 55.41
Round  81, Train loss: 1.800, Test loss: 1.505, Test accuracy: 55.64
Round  82, Train loss: 1.802, Test loss: 1.503, Test accuracy: 55.43
Round  83, Train loss: 1.854, Test loss: 1.531, Test accuracy: 54.17
Round  84, Train loss: 1.689, Test loss: 1.514, Test accuracy: 55.40
Round  85, Train loss: 1.764, Test loss: 1.519, Test accuracy: 54.61
Round  86, Train loss: 1.787, Test loss: 1.523, Test accuracy: 54.62
Round  87, Train loss: 1.866, Test loss: 1.529, Test accuracy: 54.27
Round  88, Train loss: 1.762, Test loss: 1.529, Test accuracy: 54.04
Round  89, Train loss: 1.782, Test loss: 1.519, Test accuracy: 55.08
Round  90, Train loss: 1.673, Test loss: 1.520, Test accuracy: 55.02
Round  91, Train loss: 1.681, Test loss: 1.507, Test accuracy: 54.85
Round  92, Train loss: 1.730, Test loss: 1.513, Test accuracy: 54.35
Round  93, Train loss: 1.683, Test loss: 1.492, Test accuracy: 55.25
Round  94, Train loss: 1.756, Test loss: 1.497, Test accuracy: 54.80
Round  95, Train loss: 1.717, Test loss: 1.520, Test accuracy: 53.73
Round  96, Train loss: 1.849, Test loss: 1.545, Test accuracy: 53.08
Round  97, Train loss: 1.712, Test loss: 1.531, Test accuracy: 53.26
Round  98, Train loss: 1.774, Test loss: 1.545, Test accuracy: 52.63
Round  99, Train loss: 1.814, Test loss: 1.550, Test accuracy: 52.60
Final Round, Train loss: 1.673, Test loss: 1.551, Test accuracy: 52.08
Average accuracy final 10 rounds: 53.956999999999994
4399.972618818283
[6.118291616439819, 12.055878639221191, 17.972513914108276, 23.97884249687195, 29.940693855285645, 35.51709771156311, 41.23436665534973, 47.12357544898987, 52.93622159957886, 59.105963468551636, 65.16408848762512, 71.21219873428345, 76.60565829277039, 82.05913138389587, 87.45492625236511, 92.88767147064209, 98.30108952522278, 103.7087013721466, 109.11314558982849, 114.52805829048157, 120.05010199546814, 125.50017476081848, 130.88025164604187, 136.2671663761139, 141.69556403160095, 147.1056683063507, 152.6087577342987, 157.97312450408936, 163.31892228126526, 168.65644431114197, 174.26887321472168, 179.65948939323425, 185.09424686431885, 190.48872923851013, 195.8062105178833, 201.16514611244202, 206.51922297477722, 211.93323302268982, 217.2834165096283, 222.64681720733643, 227.94512486457825, 233.22664785385132, 238.52182126045227, 243.9117465019226, 249.2885811328888, 254.83671259880066, 260.34340143203735, 265.79553174972534, 271.31337547302246, 276.632390499115, 282.005731344223, 287.26791977882385, 292.48011088371277, 297.7338938713074, 303.10585165023804, 308.4282064437866, 313.70570278167725, 319.04134583473206, 324.5310323238373, 329.8338973522186, 335.0809495449066, 340.5065712928772, 345.863650560379, 351.32992482185364, 356.76047372817993, 362.1083345413208, 367.3544166088104, 372.68934655189514, 377.99762511253357, 383.46473574638367, 388.71553587913513, 394.2103633880615, 399.5963444709778, 404.8824291229248, 410.35627341270447, 416.126531124115, 422.08706855773926, 427.8769028186798, 433.66259503364563, 439.60529136657715, 445.5530364513397, 451.3881070613861, 456.6905777454376, 462.12094235420227, 467.5357856750488, 472.8795394897461, 478.104083776474, 483.3630566596985, 488.65114283561707, 493.97143840789795, 499.2932119369507, 504.65997982025146, 509.99561834335327, 515.3691079616547, 520.7506077289581, 526.1398794651031, 531.5058760643005, 536.8269777297974, 542.1461846828461, 547.4894676208496, 549.5751578807831]
[23.9025, 27.8675, 33.2, 33.695, 37.485, 39.73, 40.2475, 40.8725, 41.5025, 42.6075, 43.73, 44.2925, 44.96, 45.8475, 46.5175, 47.29, 48.2375, 49.16, 49.79, 50.365, 50.8675, 51.485, 52.0325, 52.0275, 52.6075, 52.8275, 53.5475, 54.1625, 54.3525, 54.2, 54.6225, 55.0325, 55.2925, 55.6025, 55.88, 55.94, 55.6325, 57.09, 56.245, 56.265, 56.055, 55.035, 55.8775, 56.4625, 56.0975, 57.23, 57.315, 56.7525, 58.12, 56.9925, 57.455, 57.1, 56.5725, 56.475, 56.88, 56.7425, 57.13, 56.3325, 56.12, 55.92, 57.2, 56.89, 56.73, 57.465, 56.32, 56.0775, 57.855, 57.38, 57.125, 55.685, 56.925, 57.3775, 56.5525, 56.3825, 54.5475, 55.5175, 56.2125, 54.1375, 54.875, 54.46, 55.41, 55.6425, 55.4325, 54.1725, 55.3975, 54.61, 54.625, 54.265, 54.0425, 55.0825, 55.02, 54.8525, 54.3525, 55.2525, 54.795, 53.7275, 53.0775, 53.26, 52.6325, 52.6, 52.075]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 10, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 15, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 12, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 11, noise    level: 0.5000 
   Client 0, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 18, noise    level: 0.5000 
   Client 7, noise    level: 0.5000 
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  28.9200
Round 1 global test acc  32.5600
Round 2 global test acc  38.3400
Round 3 global test acc  40.4400
Round 4 global test acc  44.1000
Round 5 global test acc  43.0300
Round 6 global test acc  48.7600
Round 7 global test acc  47.7800
Round 8 global test acc  46.2800
Round 9 global test acc  48.7300
Round 10 global test acc  49.4100
Round 11 global test acc  52.7900
Round 12 global test acc  53.1600
Round 13 global test acc  53.5500
Round 14 global test acc  52.8300
Round 15 global test acc  53.9800
Round 16 global test acc  54.9900
Round 17 global test acc  55.5700
Round 18 global test acc  52.9200
Round 19 global test acc  53.3800
Round 20 global test acc  57.0900
Round 21 global test acc  56.7600
Round 22 global test acc  56.6700
Round 23 global test acc  55.3900
Round 24 global test acc  58.6000
Round 25 global test acc  57.1800
Round 26 global test acc  59.1800
Round 27 global test acc  58.7300
Round 28 global test acc  57.9500
Round 29 global test acc  57.5200
Round 30 global test acc  57.2100
Round 31 global test acc  56.9300
Round 32 global test acc  58.7900
Round 33 global test acc  60.1300
Round 34 global test acc  60.0100
Round 35 global test acc  56.6100
Round 36 global test acc  59.8400
Round 37 global test acc  59.3200
Round 38 global test acc  58.8100
Round 39 global test acc  60.6000
Round 40 global test acc  58.9900
Round 41 global test acc  59.1700
Round 42 global test acc  61.3500
Round 43 global test acc  60.1700
Round 44 global test acc  60.3200
Round 45 global test acc  60.4000
Round 46 global test acc  60.3500
Round 47 global test acc  60.9500
Round 48 global test acc  60.6500
Round 49 global test acc  61.3700
Round 50 global test acc  60.7800
Round 51 global test acc  62.5000
Round 52 global test acc  61.0700
Round 53 global test acc  59.9300
Round 54 global test acc  62.3700
Round 55 global test acc  61.5000
Round 56 global test acc  61.8600
Round 57 global test acc  62.7800
Round 58 global test acc  62.5100
Round 59 global test acc  63.6800
Round 60 global test acc  60.9000
Round 61 global test acc  63.4400
Round 62 global test acc  62.6300
Round 63 global test acc  62.7400
Round 64 global test acc  62.2100
Round 65 global test acc  62.9600
Round 66 global test acc  62.5800
Round 67 global test acc  63.6200
Round 68 global test acc  61.8800
Round 69 global test acc  61.7900
Round 70 global test acc  60.9900
Round 71 global test acc  62.4200
Round 72 global test acc  63.2800
Round 73 global test acc  60.8100
Round 74 global test acc  63.3600
Round 75 global test acc  61.7700
Round 76 global test acc  63.9700
Round 77 global test acc  63.1100
Round 78 global test acc  64.2300
Round 79 global test acc  64.6200
Round 80 global test acc  64.1100
Round 81 global test acc  62.7100
Round 82 global test acc  61.0300
Round 83 global test acc  60.3700
Round 84 global test acc  58.9600
Round 85 global test acc  58.4700
Round 86 global test acc  56.0100
Round 87 global test acc  56.3400
Round 88 global test acc  55.8800
Round 89 global test acc  55.7900
Round 90 global test acc  56.2200
Round 91 global test acc  55.1200
Round 92 global test acc  54.0600
Round 93 global test acc  54.2800
Round 94 global test acc  54.7900
Round 95 global test acc  54.3600
Round 96 global test acc  54.0300
Round 97 global test acc  53.9800
Round 98 global test acc  53.3600
Round 99 global test acc  52.7600
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 10, noise    level: 0.5000 
   Client 0, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 7, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
   Client 15, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
   Client 19, noise    level: 0.5000 
   Client 17, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 18, noise    level: 0.5000 
   Client 14, noise    level: 0.5000 
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 2.228, Test loss: 2.080, Test accuracy: 25.88
Round   1, Train loss: 2.052, Test loss: 1.876, Test accuracy: 34.07
Round   2, Train loss: 1.966, Test loss: 1.761, Test accuracy: 39.33
Round   3, Train loss: 1.956, Test loss: 1.744, Test accuracy: 40.72
Round   4, Train loss: 1.878, Test loss: 1.703, Test accuracy: 42.14
Round   5, Train loss: 1.874, Test loss: 1.629, Test accuracy: 44.13
Round   6, Train loss: 1.821, Test loss: 1.611, Test accuracy: 46.33
Round   7, Train loss: 1.706, Test loss: 1.561, Test accuracy: 48.11
Round   8, Train loss: 1.792, Test loss: 1.558, Test accuracy: 50.17
Round   9, Train loss: 1.744, Test loss: 1.513, Test accuracy: 51.19
Round  10, Train loss: 1.666, Test loss: 1.441, Test accuracy: 52.86
Round  11, Train loss: 1.697, Test loss: 1.472, Test accuracy: 53.71
Round  12, Train loss: 1.685, Test loss: 1.412, Test accuracy: 55.29
Round  13, Train loss: 1.643, Test loss: 1.383, Test accuracy: 55.82
Round  14, Train loss: 1.695, Test loss: 1.385, Test accuracy: 56.81
Round  15, Train loss: 1.727, Test loss: 1.366, Test accuracy: 57.45
Round  16, Train loss: 1.670, Test loss: 1.369, Test accuracy: 57.21
Round  17, Train loss: 1.583, Test loss: 1.347, Test accuracy: 58.54
Round  18, Train loss: 1.521, Test loss: 1.326, Test accuracy: 59.23
Round  19, Train loss: 1.545, Test loss: 1.294, Test accuracy: 60.25
Round  20, Train loss: 1.672, Test loss: 1.302, Test accuracy: 60.75
Round  21, Train loss: 1.591, Test loss: 1.265, Test accuracy: 61.79
Round  22, Train loss: 1.537, Test loss: 1.271, Test accuracy: 62.01
Round  23, Train loss: 1.552, Test loss: 1.260, Test accuracy: 62.52
Round  24, Train loss: 1.396, Test loss: 1.223, Test accuracy: 62.88
Round  25, Train loss: 1.579, Test loss: 1.243, Test accuracy: 61.90
Round  26, Train loss: 1.627, Test loss: 1.239, Test accuracy: 63.19
Round  27, Train loss: 1.517, Test loss: 1.205, Test accuracy: 64.16
Round  28, Train loss: 1.341, Test loss: 1.202, Test accuracy: 64.12
Round  29, Train loss: 1.395, Test loss: 1.194, Test accuracy: 64.52
Round  30, Train loss: 1.424, Test loss: 1.190, Test accuracy: 64.40
Round  31, Train loss: 1.460, Test loss: 1.166, Test accuracy: 65.45
Round  32, Train loss: 1.481, Test loss: 1.169, Test accuracy: 65.57
Round  33, Train loss: 1.530, Test loss: 1.163, Test accuracy: 65.77
Round  34, Train loss: 1.359, Test loss: 1.152, Test accuracy: 66.06
Round  35, Train loss: 1.507, Test loss: 1.168, Test accuracy: 65.84
Round  36, Train loss: 1.428, Test loss: 1.170, Test accuracy: 65.78
Round  37, Train loss: 1.450, Test loss: 1.156, Test accuracy: 66.07
Round  38, Train loss: 1.428, Test loss: 1.155, Test accuracy: 65.76
Round  39, Train loss: 1.486, Test loss: 1.131, Test accuracy: 66.73
Round  40, Train loss: 1.354, Test loss: 1.134, Test accuracy: 66.53
Round  41, Train loss: 1.470, Test loss: 1.147, Test accuracy: 66.25
Round  42, Train loss: 1.325, Test loss: 1.129, Test accuracy: 66.55
Round  43, Train loss: 1.422, Test loss: 1.126, Test accuracy: 66.83
Round  44, Train loss: 1.429, Test loss: 1.132, Test accuracy: 66.67
Round  45, Train loss: 1.438, Test loss: 1.140, Test accuracy: 66.73
Round  46, Train loss: 1.485, Test loss: 1.136, Test accuracy: 66.48
Round  47, Train loss: 1.442, Test loss: 1.137, Test accuracy: 66.44
Round  48, Train loss: 1.402, Test loss: 1.108, Test accuracy: 67.11
Round  49, Train loss: 1.361, Test loss: 1.115, Test accuracy: 66.73
Round  50, Train loss: 1.323, Test loss: 1.115, Test accuracy: 66.80
Round  51, Train loss: 1.243, Test loss: 1.088, Test accuracy: 67.65
Round  52, Train loss: 1.351, Test loss: 1.103, Test accuracy: 67.65
Round  53, Train loss: 1.297, Test loss: 1.104, Test accuracy: 67.28
Round  54, Train loss: 1.228, Test loss: 1.089, Test accuracy: 67.63
Round  55, Train loss: 1.409, Test loss: 1.094, Test accuracy: 67.94
Round  56, Train loss: 1.328, Test loss: 1.097, Test accuracy: 67.78
Round  57, Train loss: 1.462, Test loss: 1.101, Test accuracy: 67.78
Round  58, Train loss: 1.192, Test loss: 1.097, Test accuracy: 67.39
Round  59, Train loss: 1.361, Test loss: 1.099, Test accuracy: 67.50
Round  60, Train loss: 1.257, Test loss: 1.096, Test accuracy: 67.35
Round  61, Train loss: 1.320, Test loss: 1.106, Test accuracy: 66.91
Round  62, Train loss: 1.251, Test loss: 1.090, Test accuracy: 67.54
Round  63, Train loss: 1.271, Test loss: 1.074, Test accuracy: 68.42
Round  64, Train loss: 1.283, Test loss: 1.085, Test accuracy: 68.16
Round  65, Train loss: 1.384, Test loss: 1.088, Test accuracy: 68.01
Round  66, Train loss: 1.183, Test loss: 1.078, Test accuracy: 67.88
Round  67, Train loss: 1.422, Test loss: 1.097, Test accuracy: 67.39
Round  68, Train loss: 1.271, Test loss: 1.096, Test accuracy: 67.25
Round  69, Train loss: 1.260, Test loss: 1.100, Test accuracy: 67.43
Round  70, Train loss: 1.308, Test loss: 1.100, Test accuracy: 67.34
Round  71, Train loss: 1.252, Test loss: 1.109, Test accuracy: 66.46
Round  72, Train loss: 1.382, Test loss: 1.100, Test accuracy: 67.26
Round  73, Train loss: 1.306, Test loss: 1.110, Test accuracy: 67.17
Round  74, Train loss: 1.306, Test loss: 1.094, Test accuracy: 67.62
Round  75, Train loss: 1.066, Test loss: 1.060, Test accuracy: 68.36
Round  76, Train loss: 1.325, Test loss: 1.078, Test accuracy: 68.04
Round  77, Train loss: 1.174, Test loss: 1.071, Test accuracy: 68.14
Round  78, Train loss: 1.138, Test loss: 1.070, Test accuracy: 68.17
Round  79, Train loss: 1.277, Test loss: 1.085, Test accuracy: 67.51
Round  80, Train loss: 1.228, Test loss: 1.097, Test accuracy: 67.19
Round  81, Train loss: 1.195, Test loss: 1.072, Test accuracy: 67.95
Round  82, Train loss: 1.290, Test loss: 1.086, Test accuracy: 67.55
Round  83, Train loss: 1.184, Test loss: 1.075, Test accuracy: 67.96
Round  84, Train loss: 1.143, Test loss: 1.082, Test accuracy: 67.73
Round  85, Train loss: 1.211, Test loss: 1.083, Test accuracy: 67.59
Round  86, Train loss: 1.122, Test loss: 1.081, Test accuracy: 67.84
Round  87, Train loss: 1.269, Test loss: 1.088, Test accuracy: 67.62
Round  88, Train loss: 1.170, Test loss: 1.077, Test accuracy: 67.56
Round  89, Train loss: 1.429, Test loss: 1.091, Test accuracy: 67.48
Round  90, Train loss: 1.164, Test loss: 1.089, Test accuracy: 67.61
Round  91, Train loss: 1.164, Test loss: 1.080, Test accuracy: 67.64
Round  92, Train loss: 1.232, Test loss: 1.085, Test accuracy: 67.55
Round  93, Train loss: 1.246, Test loss: 1.085, Test accuracy: 67.33
Round  94, Train loss: 1.150, Test loss: 1.066, Test accuracy: 67.86
Round  95, Train loss: 1.316, Test loss: 1.086, Test accuracy: 67.36
Round  96, Train loss: 1.066, Test loss: 1.078, Test accuracy: 67.53
Round  97, Train loss: 1.090, Test loss: 1.083, Test accuracy: 67.27
Round  98, Train loss: 1.006, Test loss: 1.065, Test accuracy: 68.11
Round  99, Train loss: 1.115, Test loss: 1.072, Test accuracy: 67.85
Final Round, Train loss: 1.119, Test loss: 1.076, Test accuracy: 67.83
Average accuracy final 10 rounds: 67.61200000000001
4211.725832939148
[5.663690090179443, 10.82147741317749, 15.912182807922363, 21.06631374359131, 26.261422395706177, 31.36001205444336, 36.46666622161865, 41.53192329406738, 46.72918510437012, 51.959970474243164, 57.04900550842285, 62.1958589553833, 67.3546290397644, 72.4826066493988, 77.65553569793701, 82.81863474845886, 87.88098382949829, 93.07643532752991, 98.28991675376892, 103.46303725242615, 108.64685344696045, 113.78147530555725, 118.94890999794006, 124.15691375732422, 129.30642986297607, 134.8374741077423, 140.23466229438782, 145.7640552520752, 151.30220890045166, 156.63904523849487, 162.00174069404602, 167.38206911087036, 172.75344967842102, 178.26476192474365, 183.7928910255432, 189.4401295185089, 194.8113980293274, 200.23526859283447, 205.66263437271118, 211.2065465450287, 216.61899638175964, 222.27391052246094, 227.65095901489258, 233.0861301422119, 238.54240584373474, 243.9753680229187, 249.35986590385437, 254.74582147598267, 260.298371553421, 265.67676305770874, 271.0624930858612, 276.63277530670166, 282.10758900642395, 287.5620517730713, 293.0452287197113, 298.4748682975769, 303.868976354599, 309.47364020347595, 315.0744776725769, 320.71955037117004, 326.3627736568451, 332.003146648407, 337.5973415374756, 343.2128875255585, 348.8115990161896, 353.81831431388855, 358.8451633453369, 363.8821814060211, 368.83386635780334, 373.85881090164185, 378.89686846733093, 383.89416098594666, 388.92082810401917, 393.92829036712646, 398.9557762145996, 403.97625207901, 408.9424569606781, 414.041978597641, 419.1270353794098, 424.1231577396393, 429.171541929245, 434.1725709438324, 439.1698970794678, 444.2013289928436, 449.1736536026001, 454.2341139316559, 459.2725200653076, 464.32003712654114, 469.38815331459045, 474.4868302345276, 479.5148010253906, 484.43804597854614, 489.30104207992554, 494.2319071292877, 499.1386754512787, 504.0821409225464, 508.9974846839905, 513.8891515731812, 518.8045053482056, 524.2790687084198, 526.4115557670593]
[25.8775, 34.0675, 39.3325, 40.7175, 42.14, 44.13, 46.325, 48.1125, 50.17, 51.1925, 52.86, 53.71, 55.29, 55.8175, 56.815, 57.4525, 57.2075, 58.54, 59.235, 60.25, 60.7475, 61.79, 62.0075, 62.525, 62.875, 61.895, 63.1925, 64.1575, 64.1175, 64.52, 64.4025, 65.45, 65.57, 65.765, 66.06, 65.8425, 65.785, 66.0725, 65.7625, 66.73, 66.5275, 66.25, 66.5525, 66.825, 66.665, 66.7275, 66.4825, 66.435, 67.105, 66.7275, 66.8025, 67.6525, 67.65, 67.285, 67.6325, 67.9375, 67.7825, 67.775, 67.385, 67.495, 67.35, 66.905, 67.5425, 68.4225, 68.1625, 68.0125, 67.88, 67.3925, 67.25, 67.4325, 67.3375, 66.4575, 67.2625, 67.165, 67.625, 68.355, 68.0425, 68.135, 68.175, 67.5125, 67.19, 67.955, 67.5525, 67.96, 67.7325, 67.5875, 67.8425, 67.6225, 67.565, 67.48, 67.615, 67.64, 67.5525, 67.33, 67.8625, 67.365, 67.53, 67.265, 68.1125, 67.8475, 67.8275]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.8 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 15, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 7, noise    level: 0.5000 
   Client 17, noise    level: 0.5000 
   Client 12, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
   Client 11, noise    level: 0.5000 
   Client 18, noise    level: 0.5000 
   Client 10, noise    level: 0.5000 
   Client 3, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 19, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 0, noise    level: 0.5000 
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 2.267, Test loss: 2.134, Test accuracy: 26.95
Round   1, Train loss: 2.158, Test loss: 1.953, Test accuracy: 32.98
Round   2, Train loss: 2.079, Test loss: 1.822, Test accuracy: 38.83
Round   3, Train loss: 1.908, Test loss: 1.734, Test accuracy: 41.87
Round   4, Train loss: 1.883, Test loss: 1.666, Test accuracy: 45.14
Round   5, Train loss: 1.926, Test loss: 1.647, Test accuracy: 47.18
Round   6, Train loss: 1.915, Test loss: 1.649, Test accuracy: 47.93
Round   7, Train loss: 1.892, Test loss: 1.623, Test accuracy: 48.82
Round   8, Train loss: 1.867, Test loss: 1.601, Test accuracy: 50.50
Round   9, Train loss: 1.775, Test loss: 1.536, Test accuracy: 52.73
Round  10, Train loss: 1.787, Test loss: 1.469, Test accuracy: 53.99
Round  11, Train loss: 1.700, Test loss: 1.456, Test accuracy: 55.16
Round  12, Train loss: 1.716, Test loss: 1.427, Test accuracy: 56.58
Round  13, Train loss: 1.659, Test loss: 1.415, Test accuracy: 57.09
Round  14, Train loss: 1.872, Test loss: 1.420, Test accuracy: 57.97
Round  15, Train loss: 1.714, Test loss: 1.399, Test accuracy: 58.94
Round  16, Train loss: 1.626, Test loss: 1.377, Test accuracy: 59.15
Round  17, Train loss: 1.537, Test loss: 1.345, Test accuracy: 59.85
Round  18, Train loss: 1.720, Test loss: 1.353, Test accuracy: 60.41
Round  19, Train loss: 1.512, Test loss: 1.303, Test accuracy: 61.12
Round  20, Train loss: 1.801, Test loss: 1.312, Test accuracy: 61.73
Round  21, Train loss: 1.462, Test loss: 1.288, Test accuracy: 62.34
Round  22, Train loss: 1.652, Test loss: 1.293, Test accuracy: 62.97
Round  23, Train loss: 1.569, Test loss: 1.282, Test accuracy: 63.34
Round  24, Train loss: 1.640, Test loss: 1.269, Test accuracy: 63.74
Round  25, Train loss: 1.770, Test loss: 1.274, Test accuracy: 64.25
Round  26, Train loss: 1.634, Test loss: 1.275, Test accuracy: 63.92
Round  27, Train loss: 1.579, Test loss: 1.247, Test accuracy: 64.38
Round  28, Train loss: 1.608, Test loss: 1.238, Test accuracy: 64.48
Round  29, Train loss: 1.511, Test loss: 1.220, Test accuracy: 65.48
Round  30, Train loss: 1.535, Test loss: 1.208, Test accuracy: 65.94
Round  31, Train loss: 1.204, Test loss: 1.159, Test accuracy: 66.59
Round  32, Train loss: 1.586, Test loss: 1.198, Test accuracy: 66.27
Round  33, Train loss: 1.566, Test loss: 1.204, Test accuracy: 65.85
Round  34, Train loss: 1.520, Test loss: 1.190, Test accuracy: 66.29
Round  35, Train loss: 1.305, Test loss: 1.179, Test accuracy: 66.74
Round  36, Train loss: 1.488, Test loss: 1.180, Test accuracy: 66.48
Round  37, Train loss: 1.444, Test loss: 1.171, Test accuracy: 66.81
Round  38, Train loss: 1.439, Test loss: 1.170, Test accuracy: 66.60
Round  39, Train loss: 1.290, Test loss: 1.131, Test accuracy: 67.45
Round  40, Train loss: 1.549, Test loss: 1.147, Test accuracy: 67.35
Round  41, Train loss: 1.475, Test loss: 1.156, Test accuracy: 67.27
Round  42, Train loss: 1.374, Test loss: 1.142, Test accuracy: 67.46
Round  43, Train loss: 1.634, Test loss: 1.133, Test accuracy: 67.77
Round  44, Train loss: 1.511, Test loss: 1.141, Test accuracy: 67.41
Round  45, Train loss: 1.070, Test loss: 1.122, Test accuracy: 67.38
Round  46, Train loss: 1.499, Test loss: 1.128, Test accuracy: 67.91
Round  47, Train loss: 1.361, Test loss: 1.133, Test accuracy: 67.89
Round  48, Train loss: 1.384, Test loss: 1.117, Test accuracy: 68.36
Round  49, Train loss: 1.468, Test loss: 1.128, Test accuracy: 67.91
Round  50, Train loss: 1.320, Test loss: 1.122, Test accuracy: 68.14
Round  51, Train loss: 1.436, Test loss: 1.114, Test accuracy: 68.37
Round  52, Train loss: 1.396, Test loss: 1.118, Test accuracy: 68.09
Round  53, Train loss: 1.455, Test loss: 1.136, Test accuracy: 67.81
Round  54, Train loss: 1.443, Test loss: 1.124, Test accuracy: 67.94
Round  55, Train loss: 1.391, Test loss: 1.114, Test accuracy: 68.29
Round  56, Train loss: 1.073, Test loss: 1.097, Test accuracy: 68.73
Round  57, Train loss: 1.212, Test loss: 1.087, Test accuracy: 68.76
Round  58, Train loss: 1.492, Test loss: 1.101, Test accuracy: 68.61
Round  59, Train loss: 1.565, Test loss: 1.121, Test accuracy: 67.99
Round  60, Train loss: 1.412, Test loss: 1.108, Test accuracy: 68.41
Round  61, Train loss: 1.421, Test loss: 1.099, Test accuracy: 68.36
Round  62, Train loss: 1.443, Test loss: 1.106, Test accuracy: 68.69
Round  63, Train loss: 1.443, Test loss: 1.106, Test accuracy: 68.29
Round  64, Train loss: 1.403, Test loss: 1.097, Test accuracy: 68.63
Round  65, Train loss: 1.298, Test loss: 1.097, Test accuracy: 68.47
Round  66, Train loss: 1.149, Test loss: 1.079, Test accuracy: 68.80
Round  67, Train loss: 1.284, Test loss: 1.072, Test accuracy: 69.10
Round  68, Train loss: 1.263, Test loss: 1.081, Test accuracy: 68.29
Round  69, Train loss: 1.277, Test loss: 1.087, Test accuracy: 68.62
Round  70, Train loss: 1.354, Test loss: 1.082, Test accuracy: 68.89
Round  71, Train loss: 1.058, Test loss: 1.070, Test accuracy: 69.08
Round  72, Train loss: 1.671, Test loss: 1.114, Test accuracy: 67.82
Round  73, Train loss: 1.425, Test loss: 1.092, Test accuracy: 68.28
Round  74, Train loss: 1.541, Test loss: 1.118, Test accuracy: 67.64
Round  75, Train loss: 1.290, Test loss: 1.092, Test accuracy: 68.43
Round  76, Train loss: 1.385, Test loss: 1.087, Test accuracy: 68.55
Round  77, Train loss: 1.315, Test loss: 1.100, Test accuracy: 67.98
Round  78, Train loss: 1.108, Test loss: 1.083, Test accuracy: 68.55
Round  79, Train loss: 1.521, Test loss: 1.106, Test accuracy: 67.58
Round  80, Train loss: 1.094, Test loss: 1.092, Test accuracy: 68.31
Round  81, Train loss: 1.356, Test loss: 1.093, Test accuracy: 68.06
Round  82, Train loss: 1.373, Test loss: 1.092, Test accuracy: 68.16
Round  83, Train loss: 1.269, Test loss: 1.101, Test accuracy: 68.01
Round  84, Train loss: 1.170, Test loss: 1.109, Test accuracy: 67.40
Round  85, Train loss: 1.315, Test loss: 1.103, Test accuracy: 67.70
Round  86, Train loss: 1.361, Test loss: 1.091, Test accuracy: 68.11
Round  87, Train loss: 1.602, Test loss: 1.123, Test accuracy: 66.97
Round  88, Train loss: 1.091, Test loss: 1.092, Test accuracy: 67.78
Round  89, Train loss: 1.360, Test loss: 1.086, Test accuracy: 67.91
Round  90, Train loss: 1.280, Test loss: 1.090, Test accuracy: 67.93
Round  91, Train loss: 1.303, Test loss: 1.098, Test accuracy: 67.54
Round  92, Train loss: 1.184, Test loss: 1.093, Test accuracy: 67.74
Round  93, Train loss: 1.349, Test loss: 1.093, Test accuracy: 67.69
Round  94, Train loss: 1.197, Test loss: 1.074, Test accuracy: 68.43
Round  95, Train loss: 1.179, Test loss: 1.093, Test accuracy: 67.90
Round  96, Train loss: 1.373, Test loss: 1.097, Test accuracy: 67.70
Round  97, Train loss: 1.437, Test loss: 1.108, Test accuracy: 67.23
Round  98, Train loss: 1.181, Test loss: 1.087, Test accuracy: 67.70
Round  99, Train loss: 1.183, Test loss: 1.089, Test accuracy: 67.59
Final Round, Train loss: 1.156, Test loss: 1.095, Test accuracy: 67.22
Average accuracy final 10 rounds: 67.74625
6639.80538725853
[5.753582000732422, 11.282958745956421, 16.822999000549316, 22.36876630783081, 27.953027486801147, 33.51898694038391, 39.05159091949463, 44.60815095901489, 50.17363524436951, 55.69394636154175, 61.18450093269348, 66.6855902671814, 72.14378833770752, 77.61592078208923, 82.88921427726746, 88.15519142150879, 93.40854454040527, 98.66284251213074, 104.14356327056885, 109.46104335784912, 114.79287505149841, 125.74867367744446, 136.60323929786682, 147.61107516288757, 158.6573657989502, 169.55049657821655, 180.49271416664124, 191.47160267829895, 202.28506803512573, 213.07084822654724, 223.8493673801422, 234.7096700668335, 245.6119499206543, 256.5077929496765, 267.4870114326477, 278.4923207759857, 289.2807915210724, 299.96195101737976, 310.767653465271, 321.768892288208, 332.5922315120697, 343.5303671360016, 354.28711104393005, 364.9871335029602, 375.86403822898865, 386.6697690486908, 397.6700451374054, 408.00127506256104, 418.22283577919006, 428.6042320728302, 438.93612813949585, 449.13723850250244, 459.4815151691437, 469.65362429618835, 479.9110972881317, 490.2099280357361, 500.566091299057, 510.95009326934814, 521.2043554782867, 531.530327796936, 541.6718771457672, 551.8625657558441, 562.2053370475769, 572.5235147476196, 582.6349301338196, 592.8020620346069, 602.9542016983032, 613.0342407226562, 623.2529180049896, 633.4131186008453, 643.5071439743042, 653.7131953239441, 663.8913772106171, 674.0129313468933, 684.2480335235596, 694.5455992221832, 704.7440400123596, 714.9327600002289, 724.9930739402771, 735.2762308120728, 745.4747507572174, 755.6192820072174, 765.8206136226654, 775.937730550766, 786.0411324501038, 796.22549700737, 806.2940938472748, 816.6434707641602, 826.8336615562439, 836.9421315193176, 847.4039082527161, 857.9431252479553, 868.348709821701, 878.8895719051361, 889.8421869277954, 901.0413117408752, 912.2614378929138, 923.4537546634674, 934.5705139636993, 945.7572672367096, 947.761093378067]
[26.9525, 32.975, 38.8325, 41.8675, 45.14, 47.18, 47.93, 48.8225, 50.4975, 52.73, 53.9925, 55.1575, 56.58, 57.095, 57.9675, 58.935, 59.1525, 59.855, 60.415, 61.115, 61.73, 62.34, 62.97, 63.3375, 63.7425, 64.245, 63.9175, 64.3825, 64.4775, 65.4825, 65.94, 66.5875, 66.2675, 65.85, 66.2875, 66.7375, 66.48, 66.81, 66.6025, 67.45, 67.35, 67.27, 67.4575, 67.77, 67.4125, 67.3825, 67.91, 67.885, 68.3625, 67.9125, 68.135, 68.3675, 68.095, 67.815, 67.935, 68.2875, 68.73, 68.76, 68.6075, 67.9925, 68.405, 68.355, 68.6875, 68.2875, 68.6325, 68.475, 68.7975, 69.1, 68.2925, 68.625, 68.8925, 69.0775, 67.8225, 68.2825, 67.6375, 68.4325, 68.5525, 67.98, 68.5525, 67.58, 68.305, 68.055, 68.1575, 68.0075, 67.3975, 67.6975, 68.115, 66.9725, 67.775, 67.91, 67.9325, 67.5425, 67.7375, 67.69, 68.4325, 67.9025, 67.7, 67.23, 67.7, 67.595, 67.22]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.085, Test loss: 1.849, Test accuracy: 30.39
Round   0, Global train loss: 1.085, Global test loss: 2.223, Global test accuracy: 19.74
Round   1, Train loss: 0.880, Test loss: 1.746, Test accuracy: 39.60
Round   1, Global train loss: 0.880, Global test loss: 2.392, Global test accuracy: 21.37
Round   2, Train loss: 0.761, Test loss: 1.570, Test accuracy: 46.57
Round   2, Global train loss: 0.761, Global test loss: 2.345, Global test accuracy: 22.60
Round   3, Train loss: 0.798, Test loss: 0.992, Test accuracy: 59.98
Round   3, Global train loss: 0.798, Global test loss: 2.026, Global test accuracy: 30.67
Round   4, Train loss: 0.633, Test loss: 0.824, Test accuracy: 65.89
Round   4, Global train loss: 0.633, Global test loss: 2.109, Global test accuracy: 33.84
Round   5, Train loss: 0.544, Test loss: 0.830, Test accuracy: 66.01
Round   5, Global train loss: 0.544, Global test loss: 1.954, Global test accuracy: 32.92
Round   6, Train loss: 0.625, Test loss: 0.856, Test accuracy: 67.48
Round   6, Global train loss: 0.625, Global test loss: 2.261, Global test accuracy: 27.62
Round   7, Train loss: 0.573, Test loss: 0.730, Test accuracy: 70.17
Round   7, Global train loss: 0.573, Global test loss: 2.074, Global test accuracy: 26.62
Round   8, Train loss: 0.549, Test loss: 0.790, Test accuracy: 69.59
Round   8, Global train loss: 0.549, Global test loss: 2.408, Global test accuracy: 23.58
Round   9, Train loss: 0.599, Test loss: 0.707, Test accuracy: 71.57
Round   9, Global train loss: 0.599, Global test loss: 1.947, Global test accuracy: 35.17
Round  10, Train loss: 0.546, Test loss: 0.712, Test accuracy: 71.11
Round  10, Global train loss: 0.546, Global test loss: 2.060, Global test accuracy: 28.03
Round  11, Train loss: 0.597, Test loss: 0.714, Test accuracy: 72.67
Round  11, Global train loss: 0.597, Global test loss: 2.181, Global test accuracy: 28.20
Round  12, Train loss: 0.505, Test loss: 0.667, Test accuracy: 74.59
Round  12, Global train loss: 0.505, Global test loss: 2.002, Global test accuracy: 31.78
Round  13, Train loss: 0.532, Test loss: 0.692, Test accuracy: 71.46
Round  13, Global train loss: 0.532, Global test loss: 1.955, Global test accuracy: 30.52
Round  14, Train loss: 0.553, Test loss: 0.612, Test accuracy: 75.77
Round  14, Global train loss: 0.553, Global test loss: 2.110, Global test accuracy: 26.26
Round  15, Train loss: 0.402, Test loss: 0.605, Test accuracy: 76.08
Round  15, Global train loss: 0.402, Global test loss: 2.072, Global test accuracy: 26.07
Round  16, Train loss: 0.442, Test loss: 0.604, Test accuracy: 76.34
Round  16, Global train loss: 0.442, Global test loss: 2.023, Global test accuracy: 33.89
Round  17, Train loss: 0.390, Test loss: 0.579, Test accuracy: 77.11
Round  17, Global train loss: 0.390, Global test loss: 2.067, Global test accuracy: 27.31
Round  18, Train loss: 0.464, Test loss: 0.572, Test accuracy: 77.55
Round  18, Global train loss: 0.464, Global test loss: 2.035, Global test accuracy: 29.49
Round  19, Train loss: 0.400, Test loss: 0.569, Test accuracy: 77.76
Round  19, Global train loss: 0.400, Global test loss: 2.236, Global test accuracy: 27.09
Round  20, Train loss: 0.448, Test loss: 0.580, Test accuracy: 77.22
Round  20, Global train loss: 0.448, Global test loss: 1.989, Global test accuracy: 29.63
Round  21, Train loss: 0.319, Test loss: 0.587, Test accuracy: 77.40
Round  21, Global train loss: 0.319, Global test loss: 2.316, Global test accuracy: 24.90
Round  22, Train loss: 0.369, Test loss: 0.589, Test accuracy: 77.53
Round  22, Global train loss: 0.369, Global test loss: 1.915, Global test accuracy: 36.33
Round  23, Train loss: 0.385, Test loss: 0.604, Test accuracy: 77.53
Round  23, Global train loss: 0.385, Global test loss: 2.081, Global test accuracy: 30.20
Round  24, Train loss: 0.440, Test loss: 0.587, Test accuracy: 78.25
Round  24, Global train loss: 0.440, Global test loss: 1.981, Global test accuracy: 35.47
Round  25, Train loss: 0.444, Test loss: 0.594, Test accuracy: 77.97
Round  25, Global train loss: 0.444, Global test loss: 1.960, Global test accuracy: 34.67
Round  26, Train loss: 0.229, Test loss: 0.605, Test accuracy: 77.90
Round  26, Global train loss: 0.229, Global test loss: 2.012, Global test accuracy: 29.52
Round  27, Train loss: 0.514, Test loss: 0.609, Test accuracy: 77.91
Round  27, Global train loss: 0.514, Global test loss: 2.183, Global test accuracy: 18.68
Round  28, Train loss: 0.389, Test loss: 0.616, Test accuracy: 78.12
Round  28, Global train loss: 0.389, Global test loss: 2.140, Global test accuracy: 25.98
Round  29, Train loss: 0.242, Test loss: 0.608, Test accuracy: 78.50
Round  29, Global train loss: 0.242, Global test loss: 2.549, Global test accuracy: 24.48
Round  30, Train loss: 0.314, Test loss: 0.609, Test accuracy: 78.63
Round  30, Global train loss: 0.314, Global test loss: 1.993, Global test accuracy: 34.24
Round  31, Train loss: 0.392, Test loss: 0.603, Test accuracy: 78.92
Round  31, Global train loss: 0.392, Global test loss: 2.081, Global test accuracy: 24.08
Round  32, Train loss: 0.281, Test loss: 0.599, Test accuracy: 79.22
Round  32, Global train loss: 0.281, Global test loss: 2.154, Global test accuracy: 31.59
Round  33, Train loss: 0.316, Test loss: 0.615, Test accuracy: 78.80
Round  33, Global train loss: 0.316, Global test loss: 2.177, Global test accuracy: 29.19
Round  34, Train loss: 0.176, Test loss: 0.636, Test accuracy: 78.43
Round  34, Global train loss: 0.176, Global test loss: 2.173, Global test accuracy: 29.79
Round  35, Train loss: 0.358, Test loss: 0.633, Test accuracy: 79.06
Round  35, Global train loss: 0.358, Global test loss: 2.065, Global test accuracy: 29.74
Round  36, Train loss: 0.377, Test loss: 0.635, Test accuracy: 79.08
Round  36, Global train loss: 0.377, Global test loss: 2.016, Global test accuracy: 35.52
Round  37, Train loss: 0.207, Test loss: 0.644, Test accuracy: 79.13
Round  37, Global train loss: 0.207, Global test loss: 2.069, Global test accuracy: 26.98
Round  38, Train loss: 0.199, Test loss: 0.639, Test accuracy: 79.26
Round  38, Global train loss: 0.199, Global test loss: 2.180, Global test accuracy: 27.98
Round  39, Train loss: 0.238, Test loss: 0.633, Test accuracy: 79.32
Round  39, Global train loss: 0.238, Global test loss: 2.326, Global test accuracy: 28.08
Round  40, Train loss: 0.211, Test loss: 0.662, Test accuracy: 79.31
Round  40, Global train loss: 0.211, Global test loss: 1.891, Global test accuracy: 37.33
Round  41, Train loss: 0.232, Test loss: 0.660, Test accuracy: 79.68
Round  41, Global train loss: 0.232, Global test loss: 2.122, Global test accuracy: 23.72
Round  42, Train loss: 0.227, Test loss: 0.661, Test accuracy: 79.92
Round  42, Global train loss: 0.227, Global test loss: 2.009, Global test accuracy: 35.97
Round  43, Train loss: 0.225, Test loss: 0.655, Test accuracy: 80.40
Round  43, Global train loss: 0.225, Global test loss: 2.014, Global test accuracy: 26.34
Round  44, Train loss: 0.149, Test loss: 0.666, Test accuracy: 79.90
Round  44, Global train loss: 0.149, Global test loss: 1.950, Global test accuracy: 37.02
Round  45, Train loss: 0.171, Test loss: 0.662, Test accuracy: 80.40
Round  45, Global train loss: 0.171, Global test loss: 1.937, Global test accuracy: 36.23
Round  46, Train loss: 0.191, Test loss: 0.669, Test accuracy: 80.27
Round  46, Global train loss: 0.191, Global test loss: 2.210, Global test accuracy: 22.02
Round  47, Train loss: 0.134, Test loss: 0.692, Test accuracy: 80.28
Round  47, Global train loss: 0.134, Global test loss: 2.279, Global test accuracy: 30.07
Round  48, Train loss: 0.109, Test loss: 0.692, Test accuracy: 80.33
Round  48, Global train loss: 0.109, Global test loss: 2.151, Global test accuracy: 32.82
Round  49, Train loss: 0.178, Test loss: 0.683, Test accuracy: 80.14
Round  49, Global train loss: 0.178, Global test loss: 1.888, Global test accuracy: 36.09
Round  50, Train loss: 0.250, Test loss: 0.673, Test accuracy: 80.26
Round  50, Global train loss: 0.250, Global test loss: 2.113, Global test accuracy: 27.93
Round  51, Train loss: 0.120, Test loss: 0.678, Test accuracy: 80.43
Round  51, Global train loss: 0.120, Global test loss: 2.101, Global test accuracy: 30.52
Round  52, Train loss: 0.252, Test loss: 0.685, Test accuracy: 80.62
Round  52, Global train loss: 0.252, Global test loss: 2.107, Global test accuracy: 30.47
Round  53, Train loss: 0.141, Test loss: 0.682, Test accuracy: 80.77
Round  53, Global train loss: 0.141, Global test loss: 2.236, Global test accuracy: 33.05
Round  54, Train loss: 0.138, Test loss: 0.697, Test accuracy: 80.55
Round  54, Global train loss: 0.138, Global test loss: 1.895, Global test accuracy: 32.14
Round  55, Train loss: 0.147, Test loss: 0.718, Test accuracy: 80.47
Round  55, Global train loss: 0.147, Global test loss: 1.860, Global test accuracy: 41.31
Round  56, Train loss: 0.177, Test loss: 0.746, Test accuracy: 80.14
Round  56, Global train loss: 0.177, Global test loss: 2.075, Global test accuracy: 33.98
Round  57, Train loss: 0.214, Test loss: 0.759, Test accuracy: 80.30
Round  57, Global train loss: 0.214, Global test loss: 2.158, Global test accuracy: 29.11
Round  58, Train loss: 0.137, Test loss: 0.775, Test accuracy: 79.98
Round  58, Global train loss: 0.137, Global test loss: 2.015, Global test accuracy: 28.55
Round  59, Train loss: 0.137, Test loss: 0.787, Test accuracy: 80.03
Round  59, Global train loss: 0.137, Global test loss: 2.170, Global test accuracy: 28.93
Round  60, Train loss: 0.156, Test loss: 0.779, Test accuracy: 79.88
Round  60, Global train loss: 0.156, Global test loss: 2.015, Global test accuracy: 28.17
Round  61, Train loss: 0.090, Test loss: 0.776, Test accuracy: 80.42
Round  61, Global train loss: 0.090, Global test loss: 2.025, Global test accuracy: 34.09
Round  62, Train loss: 0.109, Test loss: 0.785, Test accuracy: 80.17
Round  62, Global train loss: 0.109, Global test loss: 2.012, Global test accuracy: 33.71
Round  63, Train loss: 0.211, Test loss: 0.795, Test accuracy: 80.17
Round  63, Global train loss: 0.211, Global test loss: 2.161, Global test accuracy: 23.73
Round  64, Train loss: 0.085, Test loss: 0.822, Test accuracy: 79.47
Round  64, Global train loss: 0.085, Global test loss: 2.144, Global test accuracy: 27.38
Round  65, Train loss: 0.108, Test loss: 0.808, Test accuracy: 79.86
Round  65, Global train loss: 0.108, Global test loss: 1.934, Global test accuracy: 35.17
Round  66, Train loss: 0.108, Test loss: 0.810, Test accuracy: 80.25
Round  66, Global train loss: 0.108, Global test loss: 2.052, Global test accuracy: 29.87
Round  67, Train loss: 0.114, Test loss: 0.817, Test accuracy: 80.17
Round  67, Global train loss: 0.114, Global test loss: 2.100, Global test accuracy: 27.61
Round  68, Train loss: 0.068, Test loss: 0.842, Test accuracy: 79.69
Round  68, Global train loss: 0.068, Global test loss: 2.085, Global test accuracy: 32.80
Round  69, Train loss: 0.088, Test loss: 0.811, Test accuracy: 80.17
Round  69, Global train loss: 0.088, Global test loss: 2.118, Global test accuracy: 29.92
Round  70, Train loss: 0.156, Test loss: 0.796, Test accuracy: 80.55
Round  70, Global train loss: 0.156, Global test loss: 2.178, Global test accuracy: 24.00
Round  71, Train loss: 0.152, Test loss: 0.794, Test accuracy: 80.71
Round  71, Global train loss: 0.152, Global test loss: 2.119, Global test accuracy: 19.61
Round  72, Train loss: 0.198, Test loss: 0.801, Test accuracy: 80.71
Round  72, Global train loss: 0.198, Global test loss: 2.182, Global test accuracy: 20.04
Round  73, Train loss: 0.110, Test loss: 0.804, Test accuracy: 80.69
Round  73, Global train loss: 0.110, Global test loss: 2.035, Global test accuracy: 38.51
Round  74, Train loss: 0.129, Test loss: 0.820, Test accuracy: 80.68
Round  74, Global train loss: 0.129, Global test loss: 2.071, Global test accuracy: 31.96
Round  75, Train loss: 0.088, Test loss: 0.846, Test accuracy: 80.41
Round  75, Global train loss: 0.088, Global test loss: 2.201, Global test accuracy: 21.59
Round  76, Train loss: 0.091, Test loss: 0.863, Test accuracy: 80.47
Round  76, Global train loss: 0.091, Global test loss: 2.148, Global test accuracy: 31.10
Round  77, Train loss: 0.096, Test loss: 0.870, Test accuracy: 80.45
Round  77, Global train loss: 0.096, Global test loss: 2.030, Global test accuracy: 30.48
Round  78, Train loss: 0.080, Test loss: 0.871, Test accuracy: 80.25
Round  78, Global train loss: 0.080, Global test loss: 1.918, Global test accuracy: 36.81
Round  79, Train loss: 0.094, Test loss: 0.886, Test accuracy: 80.08
Round  79, Global train loss: 0.094, Global test loss: 1.991, Global test accuracy: 35.62
Round  80, Train loss: 0.124, Test loss: 0.892, Test accuracy: 80.46
Round  80, Global train loss: 0.124, Global test loss: 2.144, Global test accuracy: 26.53
Round  81, Train loss: 0.072, Test loss: 0.875, Test accuracy: 80.73
Round  81, Global train loss: 0.072, Global test loss: 2.041, Global test accuracy: 28.89
Round  82, Train loss: 0.067, Test loss: 0.856, Test accuracy: 81.02
Round  82, Global train loss: 0.067, Global test loss: 1.997, Global test accuracy: 32.19
Round  83, Train loss: 0.063, Test loss: 0.879, Test accuracy: 81.03
Round  83, Global train loss: 0.063, Global test loss: 2.085, Global test accuracy: 31.07
Round  84, Train loss: 0.080, Test loss: 0.874, Test accuracy: 80.83
Round  84, Global train loss: 0.080, Global test loss: 2.018, Global test accuracy: 32.02
Round  85, Train loss: 0.108, Test loss: 0.895, Test accuracy: 80.56
Round  85, Global train loss: 0.108, Global test loss: 1.989, Global test accuracy: 30.56
Round  86, Train loss: 0.103, Test loss: 0.899, Test accuracy: 80.38
Round  86, Global train loss: 0.103, Global test loss: 2.153, Global test accuracy: 18.18
Round  87, Train loss: 0.127, Test loss: 0.889, Test accuracy: 80.40
Round  87, Global train loss: 0.127, Global test loss: 2.238, Global test accuracy: 17.32
Round  88, Train loss: 0.068, Test loss: 0.907, Test accuracy: 80.46
Round  88, Global train loss: 0.068, Global test loss: 2.199, Global test accuracy: 23.61
Round  89, Train loss: 0.054, Test loss: 0.927, Test accuracy: 80.35
Round  89, Global train loss: 0.054, Global test loss: 1.921, Global test accuracy: 33.62
Round  90, Train loss: 0.101, Test loss: 0.948, Test accuracy: 80.42
Round  90, Global train loss: 0.101, Global test loss: 2.046, Global test accuracy: 31.18
Round  91, Train loss: 0.104, Test loss: 0.965, Test accuracy: 80.35
Round  91, Global train loss: 0.104, Global test loss: 2.159, Global test accuracy: 24.07
Round  92, Train loss: 0.083, Test loss: 0.946, Test accuracy: 80.47
Round  92, Global train loss: 0.083, Global test loss: 2.072, Global test accuracy: 32.51
Round  93, Train loss: 0.070, Test loss: 0.939, Test accuracy: 80.60
Round  93, Global train loss: 0.070, Global test loss: 2.257, Global test accuracy: 23.73
Round  94, Train loss: 0.049, Test loss: 0.940, Test accuracy: 80.62
Round  94, Global train loss: 0.049, Global test loss: 2.003, Global test accuracy: 31.93
Round  95, Train loss: 0.070, Test loss: 0.924, Test accuracy: 80.83
Round  95, Global train loss: 0.070, Global test loss: 1.908, Global test accuracy: 36.08
Round  96, Train loss: 0.094, Test loss: 0.975, Test accuracy: 80.67
Round  96, Global train loss: 0.094, Global test loss: 2.013, Global test accuracy: 30.99
Round  97, Train loss: 0.052, Test loss: 0.943, Test accuracy: 80.96
Round  97, Global train loss: 0.052, Global test loss: 2.021, Global test accuracy: 35.20
Round  98, Train loss: 0.030, Test loss: 0.944, Test accuracy: 81.07
Round  98, Global train loss: 0.030, Global test loss: 2.129, Global test accuracy: 28.93
Round  99, Train loss: 0.061, Test loss: 0.967, Test accuracy: 81.26
Round  99, Global train loss: 0.061, Global test loss: 2.204, Global test accuracy: 20.34
Final Round, Train loss: 0.060, Test loss: 1.002, Test accuracy: 80.88
Final Round, Global train loss: 0.060, Global test loss: 2.204, Global test accuracy: 20.34
Average accuracy final 10 rounds: 80.72416666666666 

Average global accuracy final 10 rounds: 29.495000000000005 

1840.3186011314392
[1.617086410522461, 3.234172821044922, 4.6388421058654785, 6.043511390686035, 7.476093530654907, 8.90867567062378, 10.30707859992981, 11.70548152923584, 13.105751276016235, 14.50602102279663, 15.918430089950562, 17.330839157104492, 18.747563123703003, 20.164287090301514, 21.57788896560669, 22.991490840911865, 24.409245014190674, 25.826999187469482, 27.238309144973755, 28.649619102478027, 30.078924417495728, 31.508229732513428, 32.932947397232056, 34.357665061950684, 35.78959536552429, 37.2215256690979, 38.655264139175415, 40.08900260925293, 41.50973892211914, 42.93047523498535, 44.359978675842285, 45.78948211669922, 47.223328590393066, 48.657175064086914, 50.08154892921448, 51.50592279434204, 52.92937874794006, 54.352834701538086, 55.77230882644653, 57.19178295135498, 58.61592674255371, 60.04007053375244, 61.471203565597534, 62.90233659744263, 64.33748602867126, 65.7726354598999, 67.20290327072144, 68.63317108154297, 70.05303835868835, 71.47290563583374, 72.89682626724243, 74.32074689865112, 75.74822878837585, 77.17571067810059, 78.60452318191528, 80.03333568572998, 81.46691823005676, 82.90050077438354, 84.31995034217834, 85.73939990997314, 87.16552352905273, 88.59164714813232, 90.01482939720154, 91.43801164627075, 92.86573505401611, 94.29345846176147, 95.71616554260254, 97.1388726234436, 98.56199789047241, 99.98512315750122, 101.40758323669434, 102.83004331588745, 104.2623245716095, 105.69460582733154, 107.11486434936523, 108.53512287139893, 109.95595216751099, 111.37678146362305, 112.79493498802185, 114.21308851242065, 115.63575911521912, 117.05842971801758, 118.4851803779602, 119.91193103790283, 121.33200192451477, 122.75207281112671, 124.17732000350952, 125.60256719589233, 127.02165699005127, 128.4407467842102, 129.87094831466675, 131.3011498451233, 132.73297500610352, 134.16480016708374, 135.58949255943298, 137.01418495178223, 138.43910694122314, 139.86402893066406, 141.2811393737793, 142.69824981689453, 144.13067269325256, 145.5630955696106, 146.99096059799194, 148.4188256263733, 149.8440113067627, 151.2691969871521, 152.69303274154663, 154.11686849594116, 155.54310774803162, 156.96934700012207, 158.39442586898804, 159.819504737854, 161.2432804107666, 162.6670560836792, 164.09070682525635, 165.5143575668335, 166.9463496208191, 168.3783416748047, 169.80031538009644, 171.22228908538818, 172.64701867103577, 174.07174825668335, 175.5017547607422, 176.93176126480103, 178.35852432250977, 179.7852873802185, 181.20912742614746, 182.63296747207642, 184.061176776886, 185.48938608169556, 186.91939401626587, 188.34940195083618, 189.77055168151855, 191.19170141220093, 192.61765670776367, 194.04361200332642, 195.46685338020325, 196.89009475708008, 198.31618547439575, 199.74227619171143, 201.1682391166687, 202.59420204162598, 204.0218267440796, 205.4494514465332, 206.8715283870697, 208.2936053276062, 209.72124910354614, 211.14889287948608, 212.57993459701538, 214.01097631454468, 215.4361686706543, 216.86136102676392, 218.28176140785217, 219.70216178894043, 221.12973618507385, 222.55731058120728, 223.99057602882385, 225.42384147644043, 226.84921026229858, 228.27457904815674, 229.7087903022766, 231.14300155639648, 232.56431937217712, 233.98563718795776, 235.4093565940857, 236.83307600021362, 238.25638270378113, 239.67968940734863, 241.1083357334137, 242.53698205947876, 243.96367073059082, 245.39035940170288, 246.81678199768066, 248.24320459365845, 249.6712987422943, 251.09939289093018, 252.51346731185913, 253.9275417327881, 255.35106372833252, 256.77458572387695, 258.20733189582825, 259.64007806777954, 261.0679748058319, 262.4958715438843, 263.9304189682007, 265.3649663925171, 266.7937321662903, 268.2224979400635, 269.64727115631104, 271.0720443725586, 272.49996042251587, 273.92787647247314, 275.3635127544403, 276.79914903640747, 278.2292516231537, 279.6593542098999, 281.0920252799988, 282.52469635009766, 283.95974826812744, 285.3948001861572, 287.79075837135315, 290.1867165565491]
[30.391666666666666, 30.391666666666666, 39.6, 39.6, 46.56666666666667, 46.56666666666667, 59.983333333333334, 59.983333333333334, 65.89166666666667, 65.89166666666667, 66.00833333333334, 66.00833333333334, 67.48333333333333, 67.48333333333333, 70.175, 70.175, 69.59166666666667, 69.59166666666667, 71.56666666666666, 71.56666666666666, 71.10833333333333, 71.10833333333333, 72.675, 72.675, 74.59166666666667, 74.59166666666667, 71.45833333333333, 71.45833333333333, 75.76666666666667, 75.76666666666667, 76.075, 76.075, 76.34166666666667, 76.34166666666667, 77.10833333333333, 77.10833333333333, 77.55, 77.55, 77.75833333333334, 77.75833333333334, 77.225, 77.225, 77.4, 77.4, 77.53333333333333, 77.53333333333333, 77.53333333333333, 77.53333333333333, 78.25, 78.25, 77.975, 77.975, 77.9, 77.9, 77.90833333333333, 77.90833333333333, 78.11666666666666, 78.11666666666666, 78.5, 78.5, 78.63333333333334, 78.63333333333334, 78.91666666666667, 78.91666666666667, 79.225, 79.225, 78.8, 78.8, 78.43333333333334, 78.43333333333334, 79.05833333333334, 79.05833333333334, 79.08333333333333, 79.08333333333333, 79.13333333333334, 79.13333333333334, 79.25833333333334, 79.25833333333334, 79.31666666666666, 79.31666666666666, 79.30833333333334, 79.30833333333334, 79.68333333333334, 79.68333333333334, 79.925, 79.925, 80.4, 80.4, 79.9, 79.9, 80.4, 80.4, 80.26666666666667, 80.26666666666667, 80.28333333333333, 80.28333333333333, 80.325, 80.325, 80.14166666666667, 80.14166666666667, 80.25833333333334, 80.25833333333334, 80.43333333333334, 80.43333333333334, 80.61666666666666, 80.61666666666666, 80.76666666666667, 80.76666666666667, 80.55, 80.55, 80.46666666666667, 80.46666666666667, 80.14166666666667, 80.14166666666667, 80.3, 80.3, 79.98333333333333, 79.98333333333333, 80.025, 80.025, 79.88333333333334, 79.88333333333334, 80.425, 80.425, 80.175, 80.175, 80.16666666666667, 80.16666666666667, 79.475, 79.475, 79.85833333333333, 79.85833333333333, 80.25, 80.25, 80.16666666666667, 80.16666666666667, 79.69166666666666, 79.69166666666666, 80.175, 80.175, 80.55, 80.55, 80.70833333333333, 80.70833333333333, 80.70833333333333, 80.70833333333333, 80.69166666666666, 80.69166666666666, 80.68333333333334, 80.68333333333334, 80.40833333333333, 80.40833333333333, 80.475, 80.475, 80.45, 80.45, 80.25, 80.25, 80.075, 80.075, 80.45833333333333, 80.45833333333333, 80.73333333333333, 80.73333333333333, 81.01666666666667, 81.01666666666667, 81.03333333333333, 81.03333333333333, 80.83333333333333, 80.83333333333333, 80.55833333333334, 80.55833333333334, 80.38333333333334, 80.38333333333334, 80.4, 80.4, 80.45833333333333, 80.45833333333333, 80.35, 80.35, 80.41666666666667, 80.41666666666667, 80.35, 80.35, 80.475, 80.475, 80.6, 80.6, 80.61666666666666, 80.61666666666666, 80.825, 80.825, 80.675, 80.675, 80.95833333333333, 80.95833333333333, 81.06666666666666, 81.06666666666666, 81.25833333333334, 81.25833333333334, 80.875, 80.875]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.101, Test loss: 1.834, Test accuracy: 31.62
Round   0, Global train loss: 1.101, Global test loss: 2.199, Global test accuracy: 21.00
Round   1, Train loss: 0.935, Test loss: 1.551, Test accuracy: 42.32
Round   1, Global train loss: 0.935, Global test loss: 2.083, Global test accuracy: 27.13
Round   2, Train loss: 0.830, Test loss: 1.724, Test accuracy: 42.35
Round   2, Global train loss: 0.830, Global test loss: 2.461, Global test accuracy: 20.89
Round   3, Train loss: 0.795, Test loss: 1.170, Test accuracy: 55.66
Round   3, Global train loss: 0.795, Global test loss: 1.913, Global test accuracy: 33.48
Round   4, Train loss: 0.803, Test loss: 1.145, Test accuracy: 56.13
Round   4, Global train loss: 0.803, Global test loss: 1.960, Global test accuracy: 32.17
Round   5, Train loss: 0.712, Test loss: 1.089, Test accuracy: 59.35
Round   5, Global train loss: 0.712, Global test loss: 1.878, Global test accuracy: 37.38
Round   6, Train loss: 0.824, Test loss: 0.985, Test accuracy: 63.72
Round   6, Global train loss: 0.824, Global test loss: 1.940, Global test accuracy: 35.90
Round   7, Train loss: 0.701, Test loss: 0.866, Test accuracy: 66.75
Round   7, Global train loss: 0.701, Global test loss: 1.683, Global test accuracy: 42.31
Round   8, Train loss: 0.662, Test loss: 0.750, Test accuracy: 71.15
Round   8, Global train loss: 0.662, Global test loss: 1.581, Global test accuracy: 47.20
Round   9, Train loss: 0.618, Test loss: 0.719, Test accuracy: 72.97
Round   9, Global train loss: 0.618, Global test loss: 2.017, Global test accuracy: 38.41
Round  10, Train loss: 0.598, Test loss: 0.645, Test accuracy: 74.08
Round  10, Global train loss: 0.598, Global test loss: 1.592, Global test accuracy: 44.22
Round  11, Train loss: 0.667, Test loss: 0.673, Test accuracy: 74.36
Round  11, Global train loss: 0.667, Global test loss: 1.624, Global test accuracy: 45.72
Round  12, Train loss: 0.528, Test loss: 0.608, Test accuracy: 75.47
Round  12, Global train loss: 0.528, Global test loss: 1.444, Global test accuracy: 50.34
Round  13, Train loss: 0.624, Test loss: 0.640, Test accuracy: 74.78
Round  13, Global train loss: 0.624, Global test loss: 1.684, Global test accuracy: 42.76
Round  14, Train loss: 0.523, Test loss: 0.593, Test accuracy: 76.38
Round  14, Global train loss: 0.523, Global test loss: 1.536, Global test accuracy: 47.29
Round  15, Train loss: 0.507, Test loss: 0.532, Test accuracy: 78.73
Round  15, Global train loss: 0.507, Global test loss: 1.511, Global test accuracy: 48.38
Round  16, Train loss: 0.597, Test loss: 0.528, Test accuracy: 78.97
Round  16, Global train loss: 0.597, Global test loss: 1.508, Global test accuracy: 47.01
Round  17, Train loss: 0.536, Test loss: 0.513, Test accuracy: 79.39
Round  17, Global train loss: 0.536, Global test loss: 1.673, Global test accuracy: 41.92
Round  18, Train loss: 0.495, Test loss: 0.505, Test accuracy: 79.89
Round  18, Global train loss: 0.495, Global test loss: 1.797, Global test accuracy: 41.06
Round  19, Train loss: 0.412, Test loss: 0.496, Test accuracy: 80.45
Round  19, Global train loss: 0.412, Global test loss: 1.606, Global test accuracy: 47.49
Round  20, Train loss: 0.448, Test loss: 0.492, Test accuracy: 80.64
Round  20, Global train loss: 0.448, Global test loss: 1.504, Global test accuracy: 49.19
Round  21, Train loss: 0.492, Test loss: 0.478, Test accuracy: 81.29
Round  21, Global train loss: 0.492, Global test loss: 1.252, Global test accuracy: 55.93
Round  22, Train loss: 0.427, Test loss: 0.482, Test accuracy: 81.03
Round  22, Global train loss: 0.427, Global test loss: 1.303, Global test accuracy: 54.65
Round  23, Train loss: 0.615, Test loss: 0.488, Test accuracy: 80.67
Round  23, Global train loss: 0.615, Global test loss: 1.278, Global test accuracy: 55.21
Round  24, Train loss: 0.468, Test loss: 0.481, Test accuracy: 81.12
Round  24, Global train loss: 0.468, Global test loss: 1.282, Global test accuracy: 55.88
Round  25, Train loss: 0.434, Test loss: 0.498, Test accuracy: 80.70
Round  25, Global train loss: 0.434, Global test loss: 1.462, Global test accuracy: 52.98
Round  26, Train loss: 0.465, Test loss: 0.504, Test accuracy: 80.52
Round  26, Global train loss: 0.465, Global test loss: 1.445, Global test accuracy: 52.58
Round  27, Train loss: 0.427, Test loss: 0.484, Test accuracy: 81.33
Round  27, Global train loss: 0.427, Global test loss: 1.280, Global test accuracy: 57.33
Round  28, Train loss: 0.405, Test loss: 0.481, Test accuracy: 81.43
Round  28, Global train loss: 0.405, Global test loss: 1.412, Global test accuracy: 53.45
Round  29, Train loss: 0.418, Test loss: 0.466, Test accuracy: 81.88
Round  29, Global train loss: 0.418, Global test loss: 1.266, Global test accuracy: 56.06
Round  30, Train loss: 0.477, Test loss: 0.473, Test accuracy: 81.80
Round  30, Global train loss: 0.477, Global test loss: 1.175, Global test accuracy: 60.69
Round  31, Train loss: 0.362, Test loss: 0.468, Test accuracy: 82.00
Round  31, Global train loss: 0.362, Global test loss: 1.418, Global test accuracy: 53.23
Round  32, Train loss: 0.387, Test loss: 0.475, Test accuracy: 81.86
Round  32, Global train loss: 0.387, Global test loss: 1.431, Global test accuracy: 53.01
Round  33, Train loss: 0.406, Test loss: 0.464, Test accuracy: 82.44
Round  33, Global train loss: 0.406, Global test loss: 1.235, Global test accuracy: 56.05
Round  34, Train loss: 0.498, Test loss: 0.458, Test accuracy: 82.66
Round  34, Global train loss: 0.498, Global test loss: 1.154, Global test accuracy: 59.69
Round  35, Train loss: 0.384, Test loss: 0.458, Test accuracy: 82.87
Round  35, Global train loss: 0.384, Global test loss: 1.480, Global test accuracy: 51.62
Round  36, Train loss: 0.350, Test loss: 0.461, Test accuracy: 82.73
Round  36, Global train loss: 0.350, Global test loss: 1.316, Global test accuracy: 55.78
Round  37, Train loss: 0.343, Test loss: 0.465, Test accuracy: 82.50
Round  37, Global train loss: 0.343, Global test loss: 1.381, Global test accuracy: 54.54
Round  38, Train loss: 0.325, Test loss: 0.474, Test accuracy: 82.17
Round  38, Global train loss: 0.325, Global test loss: 1.396, Global test accuracy: 54.50
Round  39, Train loss: 0.367, Test loss: 0.471, Test accuracy: 82.58
Round  39, Global train loss: 0.367, Global test loss: 1.235, Global test accuracy: 58.59
Round  40, Train loss: 0.410, Test loss: 0.488, Test accuracy: 81.88
Round  40, Global train loss: 0.410, Global test loss: 1.307, Global test accuracy: 56.89
Round  41, Train loss: 0.334, Test loss: 0.467, Test accuracy: 82.57
Round  41, Global train loss: 0.334, Global test loss: 1.300, Global test accuracy: 58.51
Round  42, Train loss: 0.330, Test loss: 0.465, Test accuracy: 82.98
Round  42, Global train loss: 0.330, Global test loss: 1.512, Global test accuracy: 53.09
Round  43, Train loss: 0.346, Test loss: 0.460, Test accuracy: 83.28
Round  43, Global train loss: 0.346, Global test loss: 1.313, Global test accuracy: 58.29
Round  44, Train loss: 0.352, Test loss: 0.466, Test accuracy: 83.15
Round  44, Global train loss: 0.352, Global test loss: 1.334, Global test accuracy: 57.58
Round  45, Train loss: 0.292, Test loss: 0.463, Test accuracy: 83.29
Round  45, Global train loss: 0.292, Global test loss: 1.381, Global test accuracy: 56.51
Round  46, Train loss: 0.372, Test loss: 0.457, Test accuracy: 83.58
Round  46, Global train loss: 0.372, Global test loss: 1.482, Global test accuracy: 50.79
Round  47, Train loss: 0.378, Test loss: 0.461, Test accuracy: 83.21
Round  47, Global train loss: 0.378, Global test loss: 1.236, Global test accuracy: 57.83
Round  48, Train loss: 0.408, Test loss: 0.472, Test accuracy: 82.96
Round  48, Global train loss: 0.408, Global test loss: 1.352, Global test accuracy: 56.23
Round  49, Train loss: 0.299, Test loss: 0.473, Test accuracy: 83.49
Round  49, Global train loss: 0.299, Global test loss: 1.235, Global test accuracy: 59.66
Round  50, Train loss: 0.282, Test loss: 0.474, Test accuracy: 83.43
Round  50, Global train loss: 0.282, Global test loss: 1.425, Global test accuracy: 55.99
Round  51, Train loss: 0.300, Test loss: 0.463, Test accuracy: 83.71
Round  51, Global train loss: 0.300, Global test loss: 1.212, Global test accuracy: 59.67
Round  52, Train loss: 0.314, Test loss: 0.476, Test accuracy: 83.31
Round  52, Global train loss: 0.314, Global test loss: 1.281, Global test accuracy: 59.53
Round  53, Train loss: 0.263, Test loss: 0.468, Test accuracy: 83.64
Round  53, Global train loss: 0.263, Global test loss: 1.438, Global test accuracy: 57.73
Round  54, Train loss: 0.289, Test loss: 0.466, Test accuracy: 83.85
Round  54, Global train loss: 0.289, Global test loss: 1.325, Global test accuracy: 57.83
Round  55, Train loss: 0.292, Test loss: 0.458, Test accuracy: 84.03
Round  55, Global train loss: 0.292, Global test loss: 1.500, Global test accuracy: 57.23
Round  56, Train loss: 0.225, Test loss: 0.460, Test accuracy: 84.00
Round  56, Global train loss: 0.225, Global test loss: 1.220, Global test accuracy: 60.40
Round  57, Train loss: 0.300, Test loss: 0.475, Test accuracy: 83.65
Round  57, Global train loss: 0.300, Global test loss: 1.535, Global test accuracy: 56.37
Round  58, Train loss: 0.330, Test loss: 0.469, Test accuracy: 83.85
Round  58, Global train loss: 0.330, Global test loss: 1.311, Global test accuracy: 58.12
Round  59, Train loss: 0.215, Test loss: 0.483, Test accuracy: 83.78
Round  59, Global train loss: 0.215, Global test loss: 1.373, Global test accuracy: 57.94
Round  60, Train loss: 0.221, Test loss: 0.469, Test accuracy: 84.22
Round  60, Global train loss: 0.221, Global test loss: 1.391, Global test accuracy: 57.01
Round  61, Train loss: 0.323, Test loss: 0.450, Test accuracy: 84.62
Round  61, Global train loss: 0.323, Global test loss: 1.180, Global test accuracy: 60.67
Round  62, Train loss: 0.232, Test loss: 0.446, Test accuracy: 84.49
Round  62, Global train loss: 0.232, Global test loss: 1.185, Global test accuracy: 60.23
Round  63, Train loss: 0.261, Test loss: 0.443, Test accuracy: 84.61
Round  63, Global train loss: 0.261, Global test loss: 1.361, Global test accuracy: 58.04
Round  64, Train loss: 0.232, Test loss: 0.443, Test accuracy: 84.49
Round  64, Global train loss: 0.232, Global test loss: 1.334, Global test accuracy: 59.03
Round  65, Train loss: 0.308, Test loss: 0.450, Test accuracy: 84.12
Round  65, Global train loss: 0.308, Global test loss: 1.400, Global test accuracy: 59.17
Round  66, Train loss: 0.254, Test loss: 0.467, Test accuracy: 83.71
Round  66, Global train loss: 0.254, Global test loss: 1.686, Global test accuracy: 51.21
Round  67, Train loss: 0.245, Test loss: 0.487, Test accuracy: 83.60
Round  67, Global train loss: 0.245, Global test loss: 1.515, Global test accuracy: 55.00
Round  68, Train loss: 0.233, Test loss: 0.478, Test accuracy: 83.83
Round  68, Global train loss: 0.233, Global test loss: 1.241, Global test accuracy: 59.70
Round  69, Train loss: 0.264, Test loss: 0.462, Test accuracy: 84.15
Round  69, Global train loss: 0.264, Global test loss: 1.450, Global test accuracy: 56.42
Round  70, Train loss: 0.204, Test loss: 0.465, Test accuracy: 84.09
Round  70, Global train loss: 0.204, Global test loss: 1.517, Global test accuracy: 58.56
Round  71, Train loss: 0.214, Test loss: 0.463, Test accuracy: 84.33
Round  71, Global train loss: 0.214, Global test loss: 1.300, Global test accuracy: 61.01
Round  72, Train loss: 0.219, Test loss: 0.468, Test accuracy: 84.19
Round  72, Global train loss: 0.219, Global test loss: 1.287, Global test accuracy: 60.19
Round  73, Train loss: 0.224, Test loss: 0.465, Test accuracy: 84.23
Round  73, Global train loss: 0.224, Global test loss: 1.453, Global test accuracy: 57.77
Round  74, Train loss: 0.269, Test loss: 0.476, Test accuracy: 84.16
Round  74, Global train loss: 0.269, Global test loss: 1.236, Global test accuracy: 60.79
Round  75, Train loss: 0.234, Test loss: 0.490, Test accuracy: 83.87
Round  75, Global train loss: 0.234, Global test loss: 1.245, Global test accuracy: 60.65
Round  76, Train loss: 0.199, Test loss: 0.472, Test accuracy: 84.52
Round  76, Global train loss: 0.199, Global test loss: 1.843, Global test accuracy: 52.91
Round  77, Train loss: 0.262, Test loss: 0.490, Test accuracy: 84.06
Round  77, Global train loss: 0.262, Global test loss: 1.240, Global test accuracy: 60.46
Round  78, Train loss: 0.189, Test loss: 0.516, Test accuracy: 83.36
Round  78, Global train loss: 0.189, Global test loss: 1.393, Global test accuracy: 58.55
Round  79, Train loss: 0.264, Test loss: 0.501, Test accuracy: 83.60
Round  79, Global train loss: 0.264, Global test loss: 1.187, Global test accuracy: 62.03
Round  80, Train loss: 0.246, Test loss: 0.503, Test accuracy: 83.83
Round  80, Global train loss: 0.246, Global test loss: 1.421, Global test accuracy: 56.81
Round  81, Train loss: 0.181, Test loss: 0.486, Test accuracy: 84.30
Round  81, Global train loss: 0.181, Global test loss: 1.288, Global test accuracy: 59.79
Round  82, Train loss: 0.266, Test loss: 0.479, Test accuracy: 84.49
Round  82, Global train loss: 0.266, Global test loss: 1.194, Global test accuracy: 61.39
Round  83, Train loss: 0.215, Test loss: 0.479, Test accuracy: 84.78
Round  83, Global train loss: 0.215, Global test loss: 1.291, Global test accuracy: 60.96
Round  84, Train loss: 0.199, Test loss: 0.487, Test accuracy: 84.71
Round  84, Global train loss: 0.199, Global test loss: 1.143, Global test accuracy: 63.05
Round  85, Train loss: 0.196, Test loss: 0.477, Test accuracy: 84.79
Round  85, Global train loss: 0.196, Global test loss: 1.358, Global test accuracy: 59.96
Round  86, Train loss: 0.166, Test loss: 0.484, Test accuracy: 84.72
Round  86, Global train loss: 0.166, Global test loss: 1.311, Global test accuracy: 60.91
Round  87, Train loss: 0.214, Test loss: 0.495, Test accuracy: 84.58
Round  87, Global train loss: 0.214, Global test loss: 1.178, Global test accuracy: 63.40
Round  88, Train loss: 0.240, Test loss: 0.503, Test accuracy: 84.14
Round  88, Global train loss: 0.240, Global test loss: 1.272, Global test accuracy: 60.41
Round  89, Train loss: 0.210, Test loss: 0.500, Test accuracy: 84.35
Round  89, Global train loss: 0.210, Global test loss: 1.674, Global test accuracy: 54.65
Round  90, Train loss: 0.187, Test loss: 0.508, Test accuracy: 84.31
Round  90, Global train loss: 0.187, Global test loss: 1.458, Global test accuracy: 59.06
Round  91, Train loss: 0.180, Test loss: 0.531, Test accuracy: 84.21
Round  91, Global train loss: 0.180, Global test loss: 1.259, Global test accuracy: 63.20
Round  92, Train loss: 0.259, Test loss: 0.516, Test accuracy: 84.32
Round  92, Global train loss: 0.259, Global test loss: 1.393, Global test accuracy: 61.88
Round  93, Train loss: 0.259, Test loss: 0.506, Test accuracy: 84.81
Round  93, Global train loss: 0.259, Global test loss: 1.288, Global test accuracy: 61.62
Round  94, Train loss: 0.168, Test loss: 0.499, Test accuracy: 84.80
Round  94, Global train loss: 0.168, Global test loss: 1.378, Global test accuracy: 59.71
Round  95, Train loss: 0.147, Test loss: 0.497, Test accuracy: 84.72
Round  95, Global train loss: 0.147, Global test loss: 1.536, Global test accuracy: 58.27
Round  96, Train loss: 0.194, Test loss: 0.507, Test accuracy: 84.69
Round  96, Global train loss: 0.194, Global test loss: 1.129, Global test accuracy: 64.68
Round  97, Train loss: 0.250, Test loss: 0.509, Test accuracy: 84.78
Round  97, Global train loss: 0.250, Global test loss: 1.327, Global test accuracy: 61.59
Round  98, Train loss: 0.183, Test loss: 0.513, Test accuracy: 84.77
Round  98, Global train loss: 0.183, Global test loss: 1.743, Global test accuracy: 54.87
Round  99, Train loss: 0.197, Test loss: 0.507, Test accuracy: 84.67
Round  99, Global train loss: 0.197, Global test loss: 1.481, Global test accuracy: 59.02
Final Round, Train loss: 0.155, Test loss: 0.545, Test accuracy: 84.90
Final Round, Global train loss: 0.155, Global test loss: 1.481, Global test accuracy: 59.02
Average accuracy final 10 rounds: 84.60750000000002 

Average global accuracy final 10 rounds: 60.39 

1809.1512796878815
[1.6022186279296875, 3.204437255859375, 4.605618000030518, 6.00679874420166, 7.4200849533081055, 8.83337116241455, 10.238096475601196, 11.642821788787842, 13.043796062469482, 14.444770336151123, 15.856549501419067, 17.26832866668701, 18.67849898338318, 20.088669300079346, 21.496041774749756, 22.903414249420166, 24.31163215637207, 25.719850063323975, 27.128911018371582, 28.53797197341919, 29.94866371154785, 31.359355449676514, 32.77284383773804, 34.18633222579956, 35.60487389564514, 37.02341556549072, 38.439602851867676, 39.85579013824463, 41.26579976081848, 42.675809383392334, 44.08507680892944, 45.49434423446655, 46.90918850898743, 48.3240327835083, 49.73394060134888, 51.14384841918945, 52.55289649963379, 53.961944580078125, 55.370566844940186, 56.779189109802246, 58.19125699996948, 59.60332489013672, 61.016247034072876, 62.42916917800903, 63.83711647987366, 65.24506378173828, 66.65178084373474, 68.0584979057312, 69.4700345993042, 70.8815712928772, 72.28959250450134, 73.69761371612549, 75.1100492477417, 76.52248477935791, 77.92671537399292, 79.33094596862793, 80.73895120620728, 82.14695644378662, 83.55226945877075, 84.95758247375488, 86.36607599258423, 87.77456951141357, 89.18456721305847, 90.59456491470337, 92.00215744972229, 93.40974998474121, 94.81696009635925, 96.2241702079773, 97.6268801689148, 99.0295901298523, 100.43601322174072, 101.84243631362915, 103.2544515132904, 104.66646671295166, 106.07526302337646, 107.48405933380127, 108.8908908367157, 110.29772233963013, 111.70363688468933, 113.10955142974854, 114.52592492103577, 115.942298412323, 117.34572720527649, 118.74915599822998, 120.15289187431335, 121.55662775039673, 122.9686541557312, 124.38068056106567, 125.78470230102539, 127.18872404098511, 128.5957989692688, 130.0028738975525, 131.41764545440674, 132.832417011261, 134.23876214027405, 135.6451072692871, 137.0547969341278, 138.4644865989685, 139.86986255645752, 141.27523851394653, 142.68950080871582, 144.1037631034851, 145.51150393486023, 146.91924476623535, 148.33112597465515, 149.74300718307495, 151.1547019481659, 152.56639671325684, 153.97298073768616, 155.37956476211548, 156.7927496433258, 158.20593452453613, 159.61793184280396, 161.02992916107178, 162.4397840499878, 163.8496389389038, 165.26184177398682, 166.67404460906982, 168.08126211166382, 169.4884796142578, 170.9014186859131, 172.31435775756836, 173.72027158737183, 175.1261854171753, 176.53529715538025, 177.9444088935852, 179.3585615158081, 180.772714138031, 182.18120074272156, 183.5896873474121, 184.99823594093323, 186.40678453445435, 187.80874752998352, 189.2107105255127, 190.61771059036255, 192.0247106552124, 193.42853260040283, 194.83235454559326, 196.24123620986938, 197.6501178741455, 199.0559732913971, 200.46182870864868, 201.87145590782166, 203.28108310699463, 204.68931651115417, 206.09754991531372, 207.50323581695557, 208.9089217185974, 210.31733059883118, 211.72573947906494, 213.13771176338196, 214.54968404769897, 215.95766472816467, 217.36564540863037, 218.7741551399231, 220.18266487121582, 221.59413743019104, 223.00560998916626, 224.41292214393616, 225.82023429870605, 227.22383069992065, 228.62742710113525, 230.03915810585022, 231.45088911056519, 232.8615231513977, 234.27215719223022, 235.67482042312622, 237.07748365402222, 238.48653960227966, 239.8955955505371, 241.2742486000061, 242.6529016494751, 244.04709601402283, 245.44129037857056, 246.90191531181335, 248.36254024505615, 249.6272804737091, 250.89202070236206, 252.12468433380127, 253.35734796524048, 254.6010069847107, 255.8446660041809, 257.0598316192627, 258.2749972343445, 259.50456500053406, 260.73413276672363, 261.9554193019867, 263.17670583724976, 264.3856077194214, 265.594509601593, 266.8138654232025, 268.033221244812, 269.2560284137726, 270.47883558273315, 271.75241470336914, 273.0259938240051, 274.25008249282837, 275.4741711616516, 276.68401408195496, 277.8938570022583, 279.9609384536743, 282.02801990509033]
[31.616666666666667, 31.616666666666667, 42.31666666666667, 42.31666666666667, 42.35, 42.35, 55.65833333333333, 55.65833333333333, 56.13333333333333, 56.13333333333333, 59.35, 59.35, 63.71666666666667, 63.71666666666667, 66.75, 66.75, 71.15, 71.15, 72.96666666666667, 72.96666666666667, 74.075, 74.075, 74.35833333333333, 74.35833333333333, 75.46666666666667, 75.46666666666667, 74.775, 74.775, 76.375, 76.375, 78.73333333333333, 78.73333333333333, 78.975, 78.975, 79.39166666666667, 79.39166666666667, 79.89166666666667, 79.89166666666667, 80.45, 80.45, 80.64166666666667, 80.64166666666667, 81.29166666666667, 81.29166666666667, 81.03333333333333, 81.03333333333333, 80.675, 80.675, 81.11666666666666, 81.11666666666666, 80.7, 80.7, 80.51666666666667, 80.51666666666667, 81.325, 81.325, 81.43333333333334, 81.43333333333334, 81.875, 81.875, 81.8, 81.8, 82.0, 82.0, 81.85833333333333, 81.85833333333333, 82.44166666666666, 82.44166666666666, 82.65833333333333, 82.65833333333333, 82.86666666666666, 82.86666666666666, 82.73333333333333, 82.73333333333333, 82.5, 82.5, 82.175, 82.175, 82.58333333333333, 82.58333333333333, 81.875, 81.875, 82.56666666666666, 82.56666666666666, 82.98333333333333, 82.98333333333333, 83.275, 83.275, 83.15, 83.15, 83.29166666666667, 83.29166666666667, 83.58333333333333, 83.58333333333333, 83.20833333333333, 83.20833333333333, 82.95833333333333, 82.95833333333333, 83.49166666666666, 83.49166666666666, 83.43333333333334, 83.43333333333334, 83.70833333333333, 83.70833333333333, 83.30833333333334, 83.30833333333334, 83.64166666666667, 83.64166666666667, 83.85, 83.85, 84.03333333333333, 84.03333333333333, 84.0, 84.0, 83.65, 83.65, 83.85, 83.85, 83.775, 83.775, 84.225, 84.225, 84.625, 84.625, 84.49166666666666, 84.49166666666666, 84.60833333333333, 84.60833333333333, 84.49166666666666, 84.49166666666666, 84.125, 84.125, 83.70833333333333, 83.70833333333333, 83.6, 83.6, 83.825, 83.825, 84.15, 84.15, 84.09166666666667, 84.09166666666667, 84.325, 84.325, 84.19166666666666, 84.19166666666666, 84.23333333333333, 84.23333333333333, 84.15833333333333, 84.15833333333333, 83.86666666666666, 83.86666666666666, 84.51666666666667, 84.51666666666667, 84.05833333333334, 84.05833333333334, 83.35833333333333, 83.35833333333333, 83.6, 83.6, 83.83333333333333, 83.83333333333333, 84.3, 84.3, 84.49166666666666, 84.49166666666666, 84.78333333333333, 84.78333333333333, 84.70833333333333, 84.70833333333333, 84.79166666666667, 84.79166666666667, 84.725, 84.725, 84.575, 84.575, 84.14166666666667, 84.14166666666667, 84.35, 84.35, 84.30833333333334, 84.30833333333334, 84.20833333333333, 84.20833333333333, 84.31666666666666, 84.31666666666666, 84.80833333333334, 84.80833333333334, 84.8, 84.8, 84.725, 84.725, 84.69166666666666, 84.69166666666666, 84.78333333333333, 84.78333333333333, 84.76666666666667, 84.76666666666667, 84.66666666666667, 84.66666666666667, 84.9, 84.9]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.107, Test loss: 1.821, Test accuracy: 34.98
Round   0, Global train loss: 1.107, Global test loss: 2.184, Global test accuracy: 26.14
Round   1, Train loss: 0.926, Test loss: 1.470, Test accuracy: 43.70
Round   1, Global train loss: 0.926, Global test loss: 2.073, Global test accuracy: 26.05
Round   2, Train loss: 0.804, Test loss: 1.548, Test accuracy: 44.86
Round   2, Global train loss: 0.804, Global test loss: 2.300, Global test accuracy: 25.43
Round   3, Train loss: 0.846, Test loss: 1.281, Test accuracy: 52.23
Round   3, Global train loss: 0.846, Global test loss: 2.019, Global test accuracy: 32.25
Round   4, Train loss: 0.753, Test loss: 1.101, Test accuracy: 57.32
Round   4, Global train loss: 0.753, Global test loss: 1.881, Global test accuracy: 34.76
Round   5, Train loss: 0.736, Test loss: 0.840, Test accuracy: 65.18
Round   5, Global train loss: 0.736, Global test loss: 1.831, Global test accuracy: 36.17
Round   6, Train loss: 0.651, Test loss: 0.807, Test accuracy: 66.61
Round   6, Global train loss: 0.651, Global test loss: 1.771, Global test accuracy: 37.48
Round   7, Train loss: 0.696, Test loss: 0.713, Test accuracy: 69.78
Round   7, Global train loss: 0.696, Global test loss: 1.663, Global test accuracy: 39.08
Round   8, Train loss: 0.734, Test loss: 0.715, Test accuracy: 70.50
Round   8, Global train loss: 0.734, Global test loss: 1.786, Global test accuracy: 37.42
Round   9, Train loss: 0.664, Test loss: 0.659, Test accuracy: 72.67
Round   9, Global train loss: 0.664, Global test loss: 2.111, Global test accuracy: 37.63
Round  10, Train loss: 0.732, Test loss: 0.617, Test accuracy: 74.42
Round  10, Global train loss: 0.732, Global test loss: 1.518, Global test accuracy: 46.36
Round  11, Train loss: 0.602, Test loss: 0.600, Test accuracy: 75.38
Round  11, Global train loss: 0.602, Global test loss: 1.495, Global test accuracy: 47.22
Round  12, Train loss: 0.569, Test loss: 0.602, Test accuracy: 75.47
Round  12, Global train loss: 0.569, Global test loss: 1.817, Global test accuracy: 35.78
Round  13, Train loss: 0.736, Test loss: 0.587, Test accuracy: 76.63
Round  13, Global train loss: 0.736, Global test loss: 1.466, Global test accuracy: 46.69
Round  14, Train loss: 0.581, Test loss: 0.584, Test accuracy: 76.67
Round  14, Global train loss: 0.581, Global test loss: 1.743, Global test accuracy: 42.17
Round  15, Train loss: 0.590, Test loss: 0.582, Test accuracy: 76.88
Round  15, Global train loss: 0.590, Global test loss: 1.566, Global test accuracy: 46.61
Round  16, Train loss: 0.615, Test loss: 0.582, Test accuracy: 77.28
Round  16, Global train loss: 0.615, Global test loss: 1.419, Global test accuracy: 50.83
Round  17, Train loss: 0.518, Test loss: 0.540, Test accuracy: 79.01
Round  17, Global train loss: 0.518, Global test loss: 1.411, Global test accuracy: 51.13
Round  18, Train loss: 0.548, Test loss: 0.567, Test accuracy: 77.54
Round  18, Global train loss: 0.548, Global test loss: 1.492, Global test accuracy: 51.37
Round  19, Train loss: 0.590, Test loss: 0.592, Test accuracy: 76.67
Round  19, Global train loss: 0.590, Global test loss: 1.494, Global test accuracy: 48.82
Round  20, Train loss: 0.546, Test loss: 0.557, Test accuracy: 77.78
Round  20, Global train loss: 0.546, Global test loss: 1.636, Global test accuracy: 42.34
Round  21, Train loss: 0.545, Test loss: 0.512, Test accuracy: 80.05
Round  21, Global train loss: 0.545, Global test loss: 1.370, Global test accuracy: 50.92
Round  22, Train loss: 0.569, Test loss: 0.504, Test accuracy: 80.33
Round  22, Global train loss: 0.569, Global test loss: 1.405, Global test accuracy: 51.67
Round  23, Train loss: 0.506, Test loss: 0.497, Test accuracy: 80.81
Round  23, Global train loss: 0.506, Global test loss: 1.458, Global test accuracy: 50.09
Round  24, Train loss: 0.457, Test loss: 0.495, Test accuracy: 80.72
Round  24, Global train loss: 0.457, Global test loss: 1.539, Global test accuracy: 50.91
Round  25, Train loss: 0.439, Test loss: 0.501, Test accuracy: 80.31
Round  25, Global train loss: 0.439, Global test loss: 1.579, Global test accuracy: 51.92
Round  26, Train loss: 0.610, Test loss: 0.493, Test accuracy: 80.63
Round  26, Global train loss: 0.610, Global test loss: 1.232, Global test accuracy: 56.70
Round  27, Train loss: 0.458, Test loss: 0.490, Test accuracy: 80.90
Round  27, Global train loss: 0.458, Global test loss: 1.252, Global test accuracy: 56.67
Round  28, Train loss: 0.530, Test loss: 0.474, Test accuracy: 81.57
Round  28, Global train loss: 0.530, Global test loss: 1.578, Global test accuracy: 46.87
Round  29, Train loss: 0.366, Test loss: 0.475, Test accuracy: 81.83
Round  29, Global train loss: 0.366, Global test loss: 1.557, Global test accuracy: 48.98
Round  30, Train loss: 0.426, Test loss: 0.472, Test accuracy: 81.98
Round  30, Global train loss: 0.426, Global test loss: 1.543, Global test accuracy: 50.59
Round  31, Train loss: 0.501, Test loss: 0.477, Test accuracy: 81.64
Round  31, Global train loss: 0.501, Global test loss: 1.351, Global test accuracy: 54.86
Round  32, Train loss: 0.463, Test loss: 0.468, Test accuracy: 82.03
Round  32, Global train loss: 0.463, Global test loss: 1.180, Global test accuracy: 58.58
Round  33, Train loss: 0.520, Test loss: 0.466, Test accuracy: 82.13
Round  33, Global train loss: 0.520, Global test loss: 1.214, Global test accuracy: 58.02
Round  34, Train loss: 0.423, Test loss: 0.459, Test accuracy: 82.51
Round  34, Global train loss: 0.423, Global test loss: 1.248, Global test accuracy: 57.34
Round  35, Train loss: 0.370, Test loss: 0.458, Test accuracy: 82.51
Round  35, Global train loss: 0.370, Global test loss: 1.244, Global test accuracy: 57.23
Round  36, Train loss: 0.500, Test loss: 0.456, Test accuracy: 82.77
Round  36, Global train loss: 0.500, Global test loss: 1.262, Global test accuracy: 56.25
Round  37, Train loss: 0.408, Test loss: 0.458, Test accuracy: 82.68
Round  37, Global train loss: 0.408, Global test loss: 1.296, Global test accuracy: 56.52
Round  38, Train loss: 0.412, Test loss: 0.450, Test accuracy: 82.96
Round  38, Global train loss: 0.412, Global test loss: 1.337, Global test accuracy: 54.39
Round  39, Train loss: 0.420, Test loss: 0.449, Test accuracy: 82.91
Round  39, Global train loss: 0.420, Global test loss: 1.400, Global test accuracy: 55.23
Round  40, Train loss: 0.448, Test loss: 0.449, Test accuracy: 82.70
Round  40, Global train loss: 0.448, Global test loss: 1.287, Global test accuracy: 55.98
Round  41, Train loss: 0.371, Test loss: 0.458, Test accuracy: 82.70
Round  41, Global train loss: 0.371, Global test loss: 1.238, Global test accuracy: 58.04
Round  42, Train loss: 0.403, Test loss: 0.465, Test accuracy: 82.59
Round  42, Global train loss: 0.403, Global test loss: 1.692, Global test accuracy: 50.17
Round  43, Train loss: 0.367, Test loss: 0.459, Test accuracy: 82.55
Round  43, Global train loss: 0.367, Global test loss: 1.239, Global test accuracy: 57.88
Round  44, Train loss: 0.291, Test loss: 0.460, Test accuracy: 82.67
Round  44, Global train loss: 0.291, Global test loss: 1.222, Global test accuracy: 59.21
Round  45, Train loss: 0.402, Test loss: 0.464, Test accuracy: 82.57
Round  45, Global train loss: 0.402, Global test loss: 1.272, Global test accuracy: 57.37
Round  46, Train loss: 0.454, Test loss: 0.475, Test accuracy: 82.44
Round  46, Global train loss: 0.454, Global test loss: 1.119, Global test accuracy: 61.40
Round  47, Train loss: 0.426, Test loss: 0.471, Test accuracy: 82.72
Round  47, Global train loss: 0.426, Global test loss: 1.389, Global test accuracy: 54.09
Round  48, Train loss: 0.326, Test loss: 0.458, Test accuracy: 83.26
Round  48, Global train loss: 0.326, Global test loss: 1.248, Global test accuracy: 57.79
Round  49, Train loss: 0.392, Test loss: 0.455, Test accuracy: 83.45
Round  49, Global train loss: 0.392, Global test loss: 1.337, Global test accuracy: 55.77
Round  50, Train loss: 0.342, Test loss: 0.454, Test accuracy: 83.42
Round  50, Global train loss: 0.342, Global test loss: 1.252, Global test accuracy: 59.58
Round  51, Train loss: 0.408, Test loss: 0.460, Test accuracy: 83.03
Round  51, Global train loss: 0.408, Global test loss: 1.203, Global test accuracy: 58.70
Round  52, Train loss: 0.302, Test loss: 0.458, Test accuracy: 83.19
Round  52, Global train loss: 0.302, Global test loss: 1.322, Global test accuracy: 57.53
Round  53, Train loss: 0.331, Test loss: 0.476, Test accuracy: 82.81
Round  53, Global train loss: 0.331, Global test loss: 1.206, Global test accuracy: 59.29
Round  54, Train loss: 0.315, Test loss: 0.479, Test accuracy: 82.70
Round  54, Global train loss: 0.315, Global test loss: 1.433, Global test accuracy: 56.29
Round  55, Train loss: 0.454, Test loss: 0.485, Test accuracy: 82.59
Round  55, Global train loss: 0.454, Global test loss: 1.196, Global test accuracy: 59.70
Round  56, Train loss: 0.290, Test loss: 0.499, Test accuracy: 82.17
Round  56, Global train loss: 0.290, Global test loss: 1.165, Global test accuracy: 61.35
Round  57, Train loss: 0.378, Test loss: 0.484, Test accuracy: 82.92
Round  57, Global train loss: 0.378, Global test loss: 1.130, Global test accuracy: 61.95
Round  58, Train loss: 0.325, Test loss: 0.491, Test accuracy: 82.55
Round  58, Global train loss: 0.325, Global test loss: 1.210, Global test accuracy: 60.75
Round  59, Train loss: 0.322, Test loss: 0.470, Test accuracy: 82.96
Round  59, Global train loss: 0.322, Global test loss: 1.357, Global test accuracy: 58.08
Round  60, Train loss: 0.389, Test loss: 0.474, Test accuracy: 83.04
Round  60, Global train loss: 0.389, Global test loss: 1.197, Global test accuracy: 60.79
Round  61, Train loss: 0.320, Test loss: 0.469, Test accuracy: 83.25
Round  61, Global train loss: 0.320, Global test loss: 1.137, Global test accuracy: 62.91
Round  62, Train loss: 0.320, Test loss: 0.476, Test accuracy: 83.22
Round  62, Global train loss: 0.320, Global test loss: 1.138, Global test accuracy: 62.54
Round  63, Train loss: 0.289, Test loss: 0.479, Test accuracy: 83.04
Round  63, Global train loss: 0.289, Global test loss: 1.687, Global test accuracy: 52.98
Round  64, Train loss: 0.338, Test loss: 0.477, Test accuracy: 83.22
Round  64, Global train loss: 0.338, Global test loss: 1.431, Global test accuracy: 54.97
Round  65, Train loss: 0.239, Test loss: 0.477, Test accuracy: 83.33
Round  65, Global train loss: 0.239, Global test loss: 1.397, Global test accuracy: 56.73
Round  66, Train loss: 0.370, Test loss: 0.483, Test accuracy: 83.28
Round  66, Global train loss: 0.370, Global test loss: 1.241, Global test accuracy: 59.56
Round  67, Train loss: 0.319, Test loss: 0.494, Test accuracy: 83.07
Round  67, Global train loss: 0.319, Global test loss: 1.191, Global test accuracy: 59.98
Round  68, Train loss: 0.227, Test loss: 0.474, Test accuracy: 83.56
Round  68, Global train loss: 0.227, Global test loss: 1.109, Global test accuracy: 63.58
Round  69, Train loss: 0.226, Test loss: 0.482, Test accuracy: 83.28
Round  69, Global train loss: 0.226, Global test loss: 1.178, Global test accuracy: 61.58
Round  70, Train loss: 0.232, Test loss: 0.481, Test accuracy: 83.30
Round  70, Global train loss: 0.232, Global test loss: 1.412, Global test accuracy: 59.25
Round  71, Train loss: 0.308, Test loss: 0.472, Test accuracy: 83.41
Round  71, Global train loss: 0.308, Global test loss: 1.605, Global test accuracy: 57.25
Round  72, Train loss: 0.314, Test loss: 0.466, Test accuracy: 83.69
Round  72, Global train loss: 0.314, Global test loss: 1.232, Global test accuracy: 60.71
Round  73, Train loss: 0.273, Test loss: 0.463, Test accuracy: 84.00
Round  73, Global train loss: 0.273, Global test loss: 1.299, Global test accuracy: 59.59
Round  74, Train loss: 0.334, Test loss: 0.465, Test accuracy: 84.20
Round  74, Global train loss: 0.334, Global test loss: 1.343, Global test accuracy: 58.88
Round  75, Train loss: 0.261, Test loss: 0.457, Test accuracy: 84.39
Round  75, Global train loss: 0.261, Global test loss: 1.322, Global test accuracy: 58.52
Round  76, Train loss: 0.316, Test loss: 0.460, Test accuracy: 84.26
Round  76, Global train loss: 0.316, Global test loss: 1.203, Global test accuracy: 61.50
Round  77, Train loss: 0.334, Test loss: 0.466, Test accuracy: 84.29
Round  77, Global train loss: 0.334, Global test loss: 1.124, Global test accuracy: 62.54
Round  78, Train loss: 0.288, Test loss: 0.459, Test accuracy: 84.53
Round  78, Global train loss: 0.288, Global test loss: 1.393, Global test accuracy: 57.45
Round  79, Train loss: 0.327, Test loss: 0.461, Test accuracy: 84.21
Round  79, Global train loss: 0.327, Global test loss: 1.333, Global test accuracy: 58.38
Round  80, Train loss: 0.326, Test loss: 0.460, Test accuracy: 84.35
Round  80, Global train loss: 0.326, Global test loss: 1.175, Global test accuracy: 62.60
Round  81, Train loss: 0.240, Test loss: 0.467, Test accuracy: 84.25
Round  81, Global train loss: 0.240, Global test loss: 1.227, Global test accuracy: 62.19
Round  82, Train loss: 0.249, Test loss: 0.469, Test accuracy: 84.12
Round  82, Global train loss: 0.249, Global test loss: 1.273, Global test accuracy: 61.67
Round  83, Train loss: 0.289, Test loss: 0.481, Test accuracy: 83.63
Round  83, Global train loss: 0.289, Global test loss: 1.373, Global test accuracy: 58.52
Round  84, Train loss: 0.248, Test loss: 0.472, Test accuracy: 83.78
Round  84, Global train loss: 0.248, Global test loss: 1.373, Global test accuracy: 58.59
Round  85, Train loss: 0.296, Test loss: 0.470, Test accuracy: 83.94
Round  85, Global train loss: 0.296, Global test loss: 1.758, Global test accuracy: 52.22
Round  86, Train loss: 0.214, Test loss: 0.475, Test accuracy: 83.72
Round  86, Global train loss: 0.214, Global test loss: 1.303, Global test accuracy: 60.23
Round  87, Train loss: 0.218, Test loss: 0.474, Test accuracy: 84.17
Round  87, Global train loss: 0.218, Global test loss: 1.458, Global test accuracy: 58.46
Round  88, Train loss: 0.238, Test loss: 0.462, Test accuracy: 84.69
Round  88, Global train loss: 0.238, Global test loss: 1.321, Global test accuracy: 60.79
Round  89, Train loss: 0.236, Test loss: 0.481, Test accuracy: 84.27
Round  89, Global train loss: 0.236, Global test loss: 1.199, Global test accuracy: 63.45
Round  90, Train loss: 0.201, Test loss: 0.482, Test accuracy: 84.46
Round  90, Global train loss: 0.201, Global test loss: 1.453, Global test accuracy: 59.50
Round  91, Train loss: 0.336, Test loss: 0.474, Test accuracy: 84.38
Round  91, Global train loss: 0.336, Global test loss: 1.191, Global test accuracy: 61.67
Round  92, Train loss: 0.233, Test loss: 0.488, Test accuracy: 83.85
Round  92, Global train loss: 0.233, Global test loss: 1.217, Global test accuracy: 62.41
Round  93, Train loss: 0.304, Test loss: 0.476, Test accuracy: 84.45
Round  93, Global train loss: 0.304, Global test loss: 1.166, Global test accuracy: 62.12
Round  94, Train loss: 0.302, Test loss: 0.484, Test accuracy: 84.36
Round  94, Global train loss: 0.302, Global test loss: 1.159, Global test accuracy: 62.63
Round  95, Train loss: 0.240, Test loss: 0.498, Test accuracy: 83.81
Round  95, Global train loss: 0.240, Global test loss: 1.105, Global test accuracy: 64.29/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  96, Train loss: 0.258, Test loss: 0.482, Test accuracy: 84.13
Round  96, Global train loss: 0.258, Global test loss: 1.297, Global test accuracy: 61.05
Round  97, Train loss: 0.286, Test loss: 0.494, Test accuracy: 83.79
Round  97, Global train loss: 0.286, Global test loss: 1.728, Global test accuracy: 56.08
Round  98, Train loss: 0.181, Test loss: 0.498, Test accuracy: 83.95
Round  98, Global train loss: 0.181, Global test loss: 1.483, Global test accuracy: 57.79
Round  99, Train loss: 0.247, Test loss: 0.498, Test accuracy: 84.35
Round  99, Global train loss: 0.247, Global test loss: 1.490, Global test accuracy: 58.89
Final Round, Train loss: 0.192, Test loss: 0.501, Test accuracy: 84.96
Final Round, Global train loss: 0.192, Global test loss: 1.490, Global test accuracy: 58.89
Average accuracy final 10 rounds: 84.1525 

Average global accuracy final 10 rounds: 60.645 

1799.2672305107117
[1.5498180389404297, 3.0996360778808594, 4.398452043533325, 5.697268009185791, 6.99584698677063, 8.294425964355469, 9.592692375183105, 10.890958786010742, 12.187934875488281, 13.48491096496582, 14.785368204116821, 16.085825443267822, 17.372660398483276, 18.65949535369873, 19.954230546951294, 21.248965740203857, 22.546966791152954, 23.84496784210205, 25.147175073623657, 26.449382305145264, 27.754021883010864, 29.058661460876465, 30.37058734893799, 31.68251323699951, 32.97367763519287, 34.26484203338623, 35.57076549530029, 36.876688957214355, 38.17714858055115, 39.47760820388794, 40.775437355041504, 42.07326650619507, 43.37085843086243, 44.668450355529785, 45.96680283546448, 47.26515531539917, 48.592767000198364, 49.92037868499756, 51.22108864784241, 52.521798610687256, 53.81766653060913, 55.113534450531006, 56.38952422142029, 57.66551399230957, 58.96770906448364, 60.269904136657715, 61.55811023712158, 62.84631633758545, 64.13218307495117, 65.4180498123169, 66.71190571784973, 68.00576162338257, 69.28634285926819, 70.56692409515381, 72.03015041351318, 73.49337673187256, 74.95238757133484, 76.41139841079712, 77.87794613838196, 79.3444938659668, 80.80411219596863, 82.26373052597046, 83.72073888778687, 85.17774724960327, 86.63778376579285, 88.09782028198242, 89.55709862709045, 91.01637697219849, 92.47276449203491, 93.92915201187134, 95.40625858306885, 96.88336515426636, 98.36184430122375, 99.84032344818115, 101.31733274459839, 102.79434204101562, 104.272207736969, 105.75007343292236, 107.22087383270264, 108.69167423248291, 110.16941785812378, 111.64716148376465, 113.12426161766052, 114.6013617515564, 116.07766103744507, 117.55396032333374, 119.03694176673889, 120.51992321014404, 122.00145030021667, 123.4829773902893, 124.9622449874878, 126.44151258468628, 127.91888332366943, 129.3962540626526, 130.87532925605774, 132.3544044494629, 133.835378408432, 135.31635236740112, 136.79598331451416, 138.2756142616272, 139.75194764137268, 141.22828102111816, 142.70933866500854, 144.19039630889893, 145.66524958610535, 147.14010286331177, 148.6090850830078, 150.07806730270386, 151.54505228996277, 153.01203727722168, 154.47733879089355, 155.94264030456543, 157.41675090789795, 158.89086151123047, 160.25516486167908, 161.61946821212769, 163.01923942565918, 164.41901063919067, 165.81121706962585, 167.20342350006104, 168.672926902771, 170.14243030548096, 171.61746644973755, 173.09250259399414, 174.56853818893433, 176.0445737838745, 177.51804304122925, 178.99151229858398, 180.4689016342163, 181.94629096984863, 183.4165117740631, 184.8867325782776, 186.3595633506775, 187.8323941230774, 189.3067750930786, 190.78115606307983, 192.2474880218506, 193.71381998062134, 195.1876356601715, 196.66145133972168, 198.1323356628418, 199.6032199859619, 201.08667421340942, 202.57012844085693, 204.05655765533447, 205.542986869812, 207.02572798728943, 208.50846910476685, 209.99890160560608, 211.4893341064453, 212.96713733673096, 214.4449405670166, 215.93169474601746, 217.4184489250183, 218.90470027923584, 220.39095163345337, 221.8773787021637, 223.36380577087402, 224.84585046768188, 226.32789516448975, 227.8162612915039, 229.30462741851807, 230.77726411819458, 232.2499008178711, 233.73471593856812, 235.21953105926514, 236.70080852508545, 238.18208599090576, 239.65491199493408, 241.1277379989624, 242.47233247756958, 243.81692695617676, 245.16224360466003, 246.5075602531433, 247.85554790496826, 249.2035355567932, 250.54679417610168, 251.89005279541016, 253.22395491600037, 254.55785703659058, 255.9039969444275, 257.2501368522644, 258.5831458568573, 259.9161548614502, 261.2132737636566, 262.51039266586304, 263.80519914627075, 265.10000562667847, 266.3941423892975, 267.6882791519165, 268.9869694709778, 270.28565979003906, 271.5848755836487, 272.8840913772583, 274.1852300167084, 275.48636865615845, 276.7844171524048, 278.0824656486511, 279.3860387802124, 280.6896119117737, 282.85663890838623, 285.0236659049988]
[34.975, 34.975, 43.7, 43.7, 44.858333333333334, 44.858333333333334, 52.233333333333334, 52.233333333333334, 57.31666666666667, 57.31666666666667, 65.18333333333334, 65.18333333333334, 66.60833333333333, 66.60833333333333, 69.78333333333333, 69.78333333333333, 70.5, 70.5, 72.675, 72.675, 74.41666666666667, 74.41666666666667, 75.375, 75.375, 75.475, 75.475, 76.63333333333334, 76.63333333333334, 76.66666666666667, 76.66666666666667, 76.88333333333334, 76.88333333333334, 77.28333333333333, 77.28333333333333, 79.00833333333334, 79.00833333333334, 77.54166666666667, 77.54166666666667, 76.675, 76.675, 77.78333333333333, 77.78333333333333, 80.05, 80.05, 80.33333333333333, 80.33333333333333, 80.80833333333334, 80.80833333333334, 80.725, 80.725, 80.30833333333334, 80.30833333333334, 80.63333333333334, 80.63333333333334, 80.9, 80.9, 81.56666666666666, 81.56666666666666, 81.825, 81.825, 81.98333333333333, 81.98333333333333, 81.64166666666667, 81.64166666666667, 82.025, 82.025, 82.13333333333334, 82.13333333333334, 82.50833333333334, 82.50833333333334, 82.50833333333334, 82.50833333333334, 82.76666666666667, 82.76666666666667, 82.68333333333334, 82.68333333333334, 82.95833333333333, 82.95833333333333, 82.90833333333333, 82.90833333333333, 82.7, 82.7, 82.7, 82.7, 82.59166666666667, 82.59166666666667, 82.55, 82.55, 82.66666666666667, 82.66666666666667, 82.56666666666666, 82.56666666666666, 82.44166666666666, 82.44166666666666, 82.725, 82.725, 83.25833333333334, 83.25833333333334, 83.45, 83.45, 83.41666666666667, 83.41666666666667, 83.03333333333333, 83.03333333333333, 83.19166666666666, 83.19166666666666, 82.80833333333334, 82.80833333333334, 82.7, 82.7, 82.59166666666667, 82.59166666666667, 82.16666666666667, 82.16666666666667, 82.925, 82.925, 82.55, 82.55, 82.95833333333333, 82.95833333333333, 83.04166666666667, 83.04166666666667, 83.25, 83.25, 83.21666666666667, 83.21666666666667, 83.04166666666667, 83.04166666666667, 83.21666666666667, 83.21666666666667, 83.33333333333333, 83.33333333333333, 83.275, 83.275, 83.06666666666666, 83.06666666666666, 83.55833333333334, 83.55833333333334, 83.275, 83.275, 83.3, 83.3, 83.40833333333333, 83.40833333333333, 83.69166666666666, 83.69166666666666, 84.0, 84.0, 84.2, 84.2, 84.39166666666667, 84.39166666666667, 84.25833333333334, 84.25833333333334, 84.29166666666667, 84.29166666666667, 84.525, 84.525, 84.20833333333333, 84.20833333333333, 84.35, 84.35, 84.25, 84.25, 84.125, 84.125, 83.63333333333334, 83.63333333333334, 83.775, 83.775, 83.94166666666666, 83.94166666666666, 83.725, 83.725, 84.16666666666667, 84.16666666666667, 84.69166666666666, 84.69166666666666, 84.26666666666667, 84.26666666666667, 84.45833333333333, 84.45833333333333, 84.375, 84.375, 83.85, 83.85, 84.45, 84.45, 84.35833333333333, 84.35833333333333, 83.80833333333334, 83.80833333333334, 84.13333333333334, 84.13333333333334, 83.79166666666667, 83.79166666666667, 83.95, 83.95, 84.35, 84.35, 84.95833333333333, 84.95833333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Co-teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.497, Test loss: 2.106, Test accuracy: 29.76
Round   1, Train loss: 1.015, Test loss: 1.817, Test accuracy: 41.06
Round   2, Train loss: 0.837, Test loss: 1.559, Test accuracy: 46.77
Round   3, Train loss: 0.799, Test loss: 1.364, Test accuracy: 50.73
Round   4, Train loss: 0.748, Test loss: 1.072, Test accuracy: 59.48
Round   5, Train loss: 0.663, Test loss: 0.939, Test accuracy: 63.62
Round   6, Train loss: 0.738, Test loss: 0.762, Test accuracy: 68.67
Round   7, Train loss: 0.688, Test loss: 0.642, Test accuracy: 73.61
Round   8, Train loss: 0.645, Test loss: 0.613, Test accuracy: 74.60
Round   9, Train loss: 0.591, Test loss: 0.590, Test accuracy: 76.33
Round  10, Train loss: 0.575, Test loss: 0.597, Test accuracy: 76.46
Round  11, Train loss: 0.648, Test loss: 0.576, Test accuracy: 77.33
Round  12, Train loss: 0.665, Test loss: 0.563, Test accuracy: 78.39
Round  13, Train loss: 0.611, Test loss: 0.547, Test accuracy: 78.96
Round  14, Train loss: 0.604, Test loss: 0.543, Test accuracy: 78.88
Round  15, Train loss: 0.500, Test loss: 0.527, Test accuracy: 79.57
Round  16, Train loss: 0.566, Test loss: 0.519, Test accuracy: 79.72
Round  17, Train loss: 0.511, Test loss: 0.503, Test accuracy: 80.03
Round  18, Train loss: 0.538, Test loss: 0.509, Test accuracy: 79.61
Round  19, Train loss: 0.433, Test loss: 0.483, Test accuracy: 80.68
Round  20, Train loss: 0.439, Test loss: 0.481, Test accuracy: 80.53
Round  21, Train loss: 0.554, Test loss: 0.473, Test accuracy: 81.29
Round  22, Train loss: 0.474, Test loss: 0.468, Test accuracy: 81.20
Round  23, Train loss: 0.413, Test loss: 0.462, Test accuracy: 81.38
Round  24, Train loss: 0.491, Test loss: 0.460, Test accuracy: 81.70
Round  25, Train loss: 0.456, Test loss: 0.450, Test accuracy: 81.78
Round  26, Train loss: 0.507, Test loss: 0.452, Test accuracy: 81.64
Round  27, Train loss: 0.515, Test loss: 0.449, Test accuracy: 81.83
Round  28, Train loss: 0.413, Test loss: 0.442, Test accuracy: 81.96
Round  29, Train loss: 0.509, Test loss: 0.441, Test accuracy: 82.42
Round  30, Train loss: 0.428, Test loss: 0.435, Test accuracy: 82.45
Round  31, Train loss: 0.353, Test loss: 0.444, Test accuracy: 82.11
Round  32, Train loss: 0.359, Test loss: 0.433, Test accuracy: 82.47
Round  33, Train loss: 0.339, Test loss: 0.432, Test accuracy: 82.71
Round  34, Train loss: 0.384, Test loss: 0.430, Test accuracy: 82.78
Round  35, Train loss: 0.489, Test loss: 0.422, Test accuracy: 83.14
Round  36, Train loss: 0.488, Test loss: 0.425, Test accuracy: 83.21
Round  37, Train loss: 0.367, Test loss: 0.413, Test accuracy: 83.69
Round  38, Train loss: 0.441, Test loss: 0.413, Test accuracy: 83.67
Round  39, Train loss: 0.307, Test loss: 0.411, Test accuracy: 83.47
Round  40, Train loss: 0.491, Test loss: 0.413, Test accuracy: 83.58
Round  41, Train loss: 0.389, Test loss: 0.406, Test accuracy: 83.99
Round  42, Train loss: 0.389, Test loss: 0.405, Test accuracy: 84.10
Round  43, Train loss: 0.355, Test loss: 0.399, Test accuracy: 84.15
Round  44, Train loss: 0.367, Test loss: 0.400, Test accuracy: 84.18
Round  45, Train loss: 0.385, Test loss: 0.406, Test accuracy: 83.93
Round  46, Train loss: 0.389, Test loss: 0.401, Test accuracy: 84.22
Round  47, Train loss: 0.413, Test loss: 0.410, Test accuracy: 83.53
Round  48, Train loss: 0.392, Test loss: 0.410, Test accuracy: 83.58
Round  49, Train loss: 0.429, Test loss: 0.404, Test accuracy: 83.97
Round  50, Train loss: 0.279, Test loss: 0.391, Test accuracy: 84.18
Round  51, Train loss: 0.301, Test loss: 0.389, Test accuracy: 84.42
Round  52, Train loss: 0.309, Test loss: 0.387, Test accuracy: 84.48
Round  53, Train loss: 0.420, Test loss: 0.391, Test accuracy: 84.46
Round  54, Train loss: 0.319, Test loss: 0.396, Test accuracy: 84.33
Round  55, Train loss: 0.304, Test loss: 0.398, Test accuracy: 84.23
Round  56, Train loss: 0.331, Test loss: 0.388, Test accuracy: 84.63
Round  57, Train loss: 0.271, Test loss: 0.379, Test accuracy: 85.01
Round  58, Train loss: 0.342, Test loss: 0.380, Test accuracy: 84.92
Round  59, Train loss: 0.323, Test loss: 0.379, Test accuracy: 85.20
Round  60, Train loss: 0.371, Test loss: 0.378, Test accuracy: 85.16
Round  61, Train loss: 0.371, Test loss: 0.381, Test accuracy: 84.96
Round  62, Train loss: 0.331, Test loss: 0.374, Test accuracy: 85.47
Round  63, Train loss: 0.340, Test loss: 0.371, Test accuracy: 85.57
Round  64, Train loss: 0.257, Test loss: 0.371, Test accuracy: 85.49
Round  65, Train loss: 0.321, Test loss: 0.372, Test accuracy: 85.54
Round  66, Train loss: 0.325, Test loss: 0.369, Test accuracy: 85.87
Round  67, Train loss: 0.294, Test loss: 0.372, Test accuracy: 85.83
Round  68, Train loss: 0.338, Test loss: 0.366, Test accuracy: 85.79
Round  69, Train loss: 0.326, Test loss: 0.365, Test accuracy: 86.03
Round  70, Train loss: 0.210, Test loss: 0.364, Test accuracy: 85.68
Round  71, Train loss: 0.246, Test loss: 0.368, Test accuracy: 85.77
Round  72, Train loss: 0.341, Test loss: 0.360, Test accuracy: 85.85
Round  73, Train loss: 0.263, Test loss: 0.372, Test accuracy: 85.55
Round  74, Train loss: 0.245, Test loss: 0.361, Test accuracy: 85.78
Round  75, Train loss: 0.205, Test loss: 0.360, Test accuracy: 86.13
Round  76, Train loss: 0.326, Test loss: 0.366, Test accuracy: 85.87
Round  77, Train loss: 0.273, Test loss: 0.363, Test accuracy: 86.16
Round  78, Train loss: 0.245, Test loss: 0.355, Test accuracy: 86.32
Round  79, Train loss: 0.302, Test loss: 0.361, Test accuracy: 86.22
Round  80, Train loss: 0.205, Test loss: 0.361, Test accuracy: 86.25
Round  81, Train loss: 0.199, Test loss: 0.357, Test accuracy: 86.52
Round  82, Train loss: 0.292, Test loss: 0.356, Test accuracy: 86.41
Round  83, Train loss: 0.265, Test loss: 0.356, Test accuracy: 86.36
Round  84, Train loss: 0.324, Test loss: 0.354, Test accuracy: 86.39
Round  85, Train loss: 0.280, Test loss: 0.352, Test accuracy: 86.47
Round  86, Train loss: 0.224, Test loss: 0.356, Test accuracy: 86.42
Round  87, Train loss: 0.195, Test loss: 0.352, Test accuracy: 86.64
Round  88, Train loss: 0.291, Test loss: 0.354, Test accuracy: 86.53
Round  89, Train loss: 0.239, Test loss: 0.365, Test accuracy: 86.31
Round  90, Train loss: 0.213, Test loss: 0.357, Test accuracy: 86.53
Round  91, Train loss: 0.244, Test loss: 0.358, Test accuracy: 86.44
Round  92, Train loss: 0.336, Test loss: 0.354, Test accuracy: 86.33
Round  93, Train loss: 0.285, Test loss: 0.354, Test accuracy: 86.37
Round  94, Train loss: 0.221, Test loss: 0.357, Test accuracy: 86.55
Round  95, Train loss: 0.248, Test loss: 0.359, Test accuracy: 86.46
Round  96, Train loss: 0.178, Test loss: 0.357, Test accuracy: 86.02
Round  97, Train loss: 0.155, Test loss: 0.358, Test accuracy: 86.30
Round  98, Train loss: 0.213, Test loss: 0.354, Test accuracy: 86.23
Round  99, Train loss: 0.219, Test loss: 0.353, Test accuracy: 86.67
Final Round, Train loss: 0.205, Test loss: 0.353, Test accuracy: 86.64
Average accuracy final 10 rounds: 86.39
1383.8100113868713
[2.0552260875701904, 3.7829718589782715, 5.518919229507446, 7.244230031967163, 9.000406742095947, 10.751331329345703, 12.517362117767334, 14.288933992385864, 16.05643892288208, 17.820733785629272, 19.574292421340942, 21.29603934288025, 23.067800521850586, 24.84226703643799, 26.583253383636475, 28.33037304878235, 30.084522485733032, 31.86208200454712, 33.64117383956909, 35.4085488319397, 37.185187578201294, 38.92026329040527, 40.68670320510864, 42.42634654045105, 44.1598424911499, 45.887099742889404, 47.64207196235657, 49.39111948013306, 51.140913248062134, 52.89176058769226, 54.64974665641785, 56.40514063835144, 58.1614294052124, 59.915393590927124, 61.65317749977112, 63.41222667694092, 65.161123752594, 66.9058449268341, 68.65368747711182, 70.41341090202332, 72.15610766410828, 73.90324759483337, 75.66046214103699, 77.41416645050049, 79.17098617553711, 80.91832375526428, 82.65848135948181, 84.3862795829773, 86.12990880012512, 87.86950039863586, 89.61181116104126, 91.34572172164917, 93.0915458202362, 94.82150554656982, 96.56034350395203, 98.30115127563477, 100.03972005844116, 101.76878380775452, 103.51228833198547, 105.25254988670349, 106.98301649093628, 108.73080348968506, 110.47642493247986, 112.21621584892273, 113.95155000686646, 115.68756747245789, 117.42391538619995, 119.16438603401184, 120.76306700706482, 122.37217307090759, 124.1092541217804, 125.86282849311829, 127.61285781860352, 129.33800840377808, 131.0712320804596, 132.81096935272217, 134.55841183662415, 136.2926459312439, 138.03124237060547, 139.77481293678284, 141.5003206729889, 143.2189486026764, 144.92745280265808, 146.6384153366089, 148.3562388420105, 150.07341861724854, 151.7582437992096, 153.44179010391235, 155.13276171684265, 156.83777976036072, 158.55150151252747, 160.21569871902466, 161.87312388420105, 163.56219244003296, 165.22369050979614, 166.85566067695618, 168.49641180038452, 170.1433823108673, 171.80215573310852, 173.47148489952087, 175.55621361732483]
[29.758333333333333, 41.05833333333333, 46.775, 50.733333333333334, 59.475, 63.625, 68.675, 73.60833333333333, 74.6, 76.33333333333333, 76.45833333333333, 77.33333333333333, 78.39166666666667, 78.95833333333333, 78.875, 79.56666666666666, 79.71666666666667, 80.03333333333333, 79.60833333333333, 80.68333333333334, 80.53333333333333, 81.29166666666667, 81.2, 81.38333333333334, 81.7, 81.78333333333333, 81.64166666666667, 81.825, 81.95833333333333, 82.425, 82.45, 82.10833333333333, 82.475, 82.70833333333333, 82.775, 83.14166666666667, 83.20833333333333, 83.69166666666666, 83.66666666666667, 83.46666666666667, 83.58333333333333, 83.99166666666666, 84.1, 84.15, 84.18333333333334, 83.93333333333334, 84.225, 83.53333333333333, 83.575, 83.96666666666667, 84.18333333333334, 84.425, 84.48333333333333, 84.45833333333333, 84.33333333333333, 84.23333333333333, 84.63333333333334, 85.00833333333334, 84.925, 85.2, 85.15833333333333, 84.95833333333333, 85.475, 85.56666666666666, 85.49166666666666, 85.54166666666667, 85.86666666666666, 85.825, 85.79166666666667, 86.03333333333333, 85.68333333333334, 85.76666666666667, 85.85, 85.55, 85.775, 86.13333333333334, 85.86666666666666, 86.15833333333333, 86.31666666666666, 86.225, 86.25, 86.51666666666667, 86.40833333333333, 86.35833333333333, 86.39166666666667, 86.46666666666667, 86.41666666666667, 86.64166666666667, 86.53333333333333, 86.30833333333334, 86.53333333333333, 86.44166666666666, 86.325, 86.36666666666666, 86.55, 86.45833333333333, 86.01666666666667, 86.3, 86.23333333333333, 86.675, 86.64166666666667]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  22.4000
Round 1 global test acc  23.8200
Round 2 global test acc  14.3900
Round 3 global test acc  28.1700
Round 4 global test acc  20.2100
Round 5 global test acc  18.9100
Round 6 global test acc  25.3300
Round 7 global test acc  21.1400
Round 8 global test acc  21.1300
Round 9 global test acc  28.8100
Round 10 global test acc  24.9200
Round 11 global test acc  25.1300
Round 12 global test acc  26.3300
Round 13 global test acc  19.9400
Round 14 global test acc  28.5000
Round 15 global test acc  28.4300
Round 16 global test acc  31.8900
Round 17 global test acc  25.5700
Round 18 global test acc  19.2000
Round 19 global test acc  18.8900
Round 20 global test acc  26.6400
Round 21 global test acc  25.8900
Round 22 global test acc  25.9400
Round 23 global test acc  26.2900
Round 24 global test acc  29.0000
Round 25 global test acc  23.8300
Round 26 global test acc  28.5500
Round 27 global test acc  34.2900
Round 28 global test acc  24.7500
Round 29 global test acc  26.9200
Round 30 global test acc  22.3700
Round 31 global test acc  27.6400
Round 32 global test acc  22.9100
Round 33 global test acc  37.3100
Round 34 global test acc  28.1800
Round 35 global test acc  35.0500
Round 36 global test acc  38.8600
Round 37 global test acc  36.9600
Round 38 global test acc  26.0300
Round 39 global test acc  27.6900
Round 40 global test acc  29.7400
Round 41 global test acc  25.5600
Round 42 global test acc  37.9000
Round 43 global test acc  38.3800
Round 44 global test acc  26.1600
Round 45 global test acc  36.4400
Round 46 global test acc  32.0200
Round 47 global test acc  38.9200
Round 48 global test acc  32.2400
Round 49 global test acc  31.9700
Round 50 global test acc  33.6300
Round 51 global test acc  32.5000
Round 52 global test acc  32.5700
Round 53 global test acc  32.0800
Round 54 global test acc  41.5700
Round 55 global test acc  38.4000
Round 56 global test acc  29.7600
Round 57 global test acc  32.2600
Round 58 global test acc  32.3600
Round 59 global test acc  38.2900
Round 60 global test acc  33.4900
Round 61 global test acc  26.9100
Round 62 global test acc  32.4800
Round 63 global test acc  33.2900
Round 64 global test acc  28.5800
Round 65 global test acc  39.0700
Round 66 global test acc  33.4100
Round 67 global test acc  28.4300
Round 68 global test acc  28.8700
Round 69 global test acc  40.3300
Round 70 global test acc  34.5300
Round 71 global test acc  41.3200
Round 72 global test acc  35.9800
Round 73 global test acc  25.1600
Round 74 global test acc  23.2300
Round 75 global test acc  33.4200
Round 76 global test acc  33.8900
Round 77 global test acc  42.0200
Round 78 global test acc  43.0400
Round 79 global test acc  42.1700
Round 80 global test acc  37.9300
Round 81 global test acc  39.4400
Round 82 global test acc  38.8400
Round 83 global test acc  33.6600
Round 84 global test acc  32.3100
Round 85 global test acc  31.7600
Round 86 global test acc  28.3800
Round 87 global test acc  25.4400
Round 88 global test acc  24.1900
Round 89 global test acc  24.0600
Round 90 global test acc  22.7800
Round 91 global test acc  21.6600
Round 92 global test acc  21.2600
Round 93 global test acc  20.0600
Round 94 global test acc  19.4900
Round 95 global test acc  19.0700
Round 96 global test acc  18.5600
Round 97 global test acc  18.8300
Round 98 global test acc  18.9500
Round 99 global test acc  18.8700
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.566, Test loss: 2.288, Test accuracy: 14.23
Round   1, Train loss: 0.974, Test loss: 1.628, Test accuracy: 40.23
Round   2, Train loss: 0.844, Test loss: 1.277, Test accuracy: 49.56
Round   3, Train loss: 0.742, Test loss: 1.119, Test accuracy: 53.79
Round   4, Train loss: 0.739, Test loss: 0.803, Test accuracy: 63.93
Round   5, Train loss: 0.714, Test loss: 0.759, Test accuracy: 65.93
Round   6, Train loss: 0.668, Test loss: 0.769, Test accuracy: 68.72
Round   7, Train loss: 0.620, Test loss: 0.799, Test accuracy: 69.89
Round   8, Train loss: 0.571, Test loss: 0.678, Test accuracy: 73.48
Round   9, Train loss: 0.614, Test loss: 0.696, Test accuracy: 72.42
Round  10, Train loss: 0.562, Test loss: 0.605, Test accuracy: 76.09
Round  11, Train loss: 0.547, Test loss: 0.646, Test accuracy: 73.47
Round  12, Train loss: 0.538, Test loss: 0.551, Test accuracy: 77.93
Round  13, Train loss: 0.581, Test loss: 0.523, Test accuracy: 79.07
Round  14, Train loss: 0.459, Test loss: 0.518, Test accuracy: 79.47
Round  15, Train loss: 0.557, Test loss: 0.507, Test accuracy: 80.25
Round  16, Train loss: 0.579, Test loss: 0.494, Test accuracy: 80.70
Round  17, Train loss: 0.493, Test loss: 0.479, Test accuracy: 81.32
Round  18, Train loss: 0.465, Test loss: 0.484, Test accuracy: 80.76
Round  19, Train loss: 0.485, Test loss: 0.481, Test accuracy: 80.72
Round  20, Train loss: 0.489, Test loss: 0.466, Test accuracy: 81.78
Round  21, Train loss: 0.531, Test loss: 0.465, Test accuracy: 81.76
Round  22, Train loss: 0.460, Test loss: 0.452, Test accuracy: 82.17
Round  23, Train loss: 0.522, Test loss: 0.457, Test accuracy: 82.27
Round  24, Train loss: 0.431, Test loss: 0.444, Test accuracy: 82.32
Round  25, Train loss: 0.447, Test loss: 0.437, Test accuracy: 82.88
Round  26, Train loss: 0.478, Test loss: 0.430, Test accuracy: 83.08
Round  27, Train loss: 0.406, Test loss: 0.424, Test accuracy: 83.31
Round  28, Train loss: 0.389, Test loss: 0.421, Test accuracy: 83.64
Round  29, Train loss: 0.410, Test loss: 0.422, Test accuracy: 83.53
Round  30, Train loss: 0.352, Test loss: 0.410, Test accuracy: 83.87
Round  31, Train loss: 0.340, Test loss: 0.410, Test accuracy: 83.66
Round  32, Train loss: 0.407, Test loss: 0.425, Test accuracy: 83.17
Round  33, Train loss: 0.404, Test loss: 0.407, Test accuracy: 84.22
Round  34, Train loss: 0.366, Test loss: 0.406, Test accuracy: 84.35
Round  35, Train loss: 0.444, Test loss: 0.393, Test accuracy: 84.86
Round  36, Train loss: 0.343, Test loss: 0.390, Test accuracy: 84.48
Round  37, Train loss: 0.361, Test loss: 0.385, Test accuracy: 85.12
Round  38, Train loss: 0.397, Test loss: 0.387, Test accuracy: 85.15
Round  39, Train loss: 0.342, Test loss: 0.389, Test accuracy: 85.13
Round  40, Train loss: 0.367, Test loss: 0.379, Test accuracy: 85.14
Round  41, Train loss: 0.418, Test loss: 0.392, Test accuracy: 84.98
Round  42, Train loss: 0.338, Test loss: 0.383, Test accuracy: 85.33
Round  43, Train loss: 0.404, Test loss: 0.370, Test accuracy: 85.87
Round  44, Train loss: 0.285, Test loss: 0.374, Test accuracy: 85.43
Round  45, Train loss: 0.348, Test loss: 0.369, Test accuracy: 85.45
Round  46, Train loss: 0.359, Test loss: 0.366, Test accuracy: 85.60
Round  47, Train loss: 0.308, Test loss: 0.373, Test accuracy: 85.44
Round  48, Train loss: 0.369, Test loss: 0.372, Test accuracy: 85.78
Round  49, Train loss: 0.348, Test loss: 0.363, Test accuracy: 85.97
Round  50, Train loss: 0.323, Test loss: 0.364, Test accuracy: 85.77
Round  51, Train loss: 0.281, Test loss: 0.361, Test accuracy: 86.03
Round  52, Train loss: 0.353, Test loss: 0.355, Test accuracy: 86.36
Round  53, Train loss: 0.310, Test loss: 0.353, Test accuracy: 86.38
Round  54, Train loss: 0.303, Test loss: 0.356, Test accuracy: 86.24
Round  55, Train loss: 0.257, Test loss: 0.362, Test accuracy: 86.32
Round  56, Train loss: 0.341, Test loss: 0.359, Test accuracy: 86.36
Round  57, Train loss: 0.345, Test loss: 0.357, Test accuracy: 86.39
Round  58, Train loss: 0.365, Test loss: 0.354, Test accuracy: 86.53
Round  59, Train loss: 0.267, Test loss: 0.348, Test accuracy: 86.58
Round  60, Train loss: 0.291, Test loss: 0.344, Test accuracy: 86.91
Round  61, Train loss: 0.276, Test loss: 0.345, Test accuracy: 86.49
Round  62, Train loss: 0.276, Test loss: 0.355, Test accuracy: 85.97
Round  63, Train loss: 0.344, Test loss: 0.350, Test accuracy: 86.57
Round  64, Train loss: 0.256, Test loss: 0.347, Test accuracy: 86.42
Round  65, Train loss: 0.252, Test loss: 0.337, Test accuracy: 87.16
Round  66, Train loss: 0.298, Test loss: 0.341, Test accuracy: 87.04
Round  67, Train loss: 0.251, Test loss: 0.338, Test accuracy: 87.00
Round  68, Train loss: 0.252, Test loss: 0.334, Test accuracy: 87.32
Round  69, Train loss: 0.341, Test loss: 0.334, Test accuracy: 87.17
Round  70, Train loss: 0.307, Test loss: 0.338, Test accuracy: 87.06
Round  71, Train loss: 0.255, Test loss: 0.341, Test accuracy: 87.32
Round  72, Train loss: 0.272, Test loss: 0.332, Test accuracy: 87.26
Round  73, Train loss: 0.305, Test loss: 0.336, Test accuracy: 87.15
Round  74, Train loss: 0.281, Test loss: 0.335, Test accuracy: 87.42
Round  75, Train loss: 0.249, Test loss: 0.336, Test accuracy: 87.21
Round  76, Train loss: 0.241, Test loss: 0.331, Test accuracy: 87.39
Round  77, Train loss: 0.218, Test loss: 0.330, Test accuracy: 87.42
Round  78, Train loss: 0.251, Test loss: 0.326, Test accuracy: 87.87
Round  79, Train loss: 0.301, Test loss: 0.328, Test accuracy: 87.63
Round  80, Train loss: 0.220, Test loss: 0.320, Test accuracy: 88.00
Round  81, Train loss: 0.271, Test loss: 0.327, Test accuracy: 87.80
Round  82, Train loss: 0.214, Test loss: 0.337, Test accuracy: 87.42
Round  83, Train loss: 0.198, Test loss: 0.335, Test accuracy: 87.31
Round  84, Train loss: 0.292, Test loss: 0.331, Test accuracy: 87.49
Round  85, Train loss: 0.255, Test loss: 0.338, Test accuracy: 87.17
Round  86, Train loss: 0.205, Test loss: 0.326, Test accuracy: 87.78
Round  87, Train loss: 0.279, Test loss: 0.332, Test accuracy: 87.58
Round  88, Train loss: 0.200, Test loss: 0.328, Test accuracy: 87.61
Round  89, Train loss: 0.229, Test loss: 0.328, Test accuracy: 87.78
Round  90, Train loss: 0.219, Test loss: 0.327, Test accuracy: 87.88
Round  91, Train loss: 0.251, Test loss: 0.327, Test accuracy: 87.85
Round  92, Train loss: 0.190, Test loss: 0.331, Test accuracy: 87.62
Round  93, Train loss: 0.197, Test loss: 0.337, Test accuracy: 87.42
Round  94, Train loss: 0.183, Test loss: 0.327, Test accuracy: 87.76
Round  95, Train loss: 0.264, Test loss: 0.326, Test accuracy: 87.61
Round  96, Train loss: 0.196, Test loss: 0.327, Test accuracy: 87.85
Round  97, Train loss: 0.207, Test loss: 0.335, Test accuracy: 87.33
Round  98, Train loss: 0.186, Test loss: 0.332, Test accuracy: 87.62
Round  99, Train loss: 0.225, Test loss: 0.326, Test accuracy: 87.92
Final Round, Train loss: 0.179, Test loss: 0.323, Test accuracy: 88.31
Average accuracy final 10 rounds: 87.68500000000002
1311.0768632888794
[1.9212470054626465, 3.5503785610198975, 5.209781646728516, 6.842394828796387, 8.45708680152893, 10.089049339294434, 11.761383295059204, 13.416455268859863, 15.05054759979248, 16.671462297439575, 18.322011470794678, 19.957848072052002, 21.584123373031616, 23.2155544757843, 24.848366498947144, 26.496516466140747, 28.14568591117859, 29.77485942840576, 31.39531421661377, 33.02862811088562, 34.661404848098755, 36.287734031677246, 37.91728901863098, 39.53763723373413, 41.18226480484009, 42.816741943359375, 44.4479603767395, 46.07944130897522, 47.7005033493042, 49.3177216053009, 50.919671058654785, 52.51930785179138, 54.1112916469574, 55.71802091598511, 57.33481454849243, 58.931732416152954, 60.54566431045532, 62.171574115753174, 63.79512977600098, 65.4070839881897, 67.01509928703308, 68.62307071685791, 70.2414960861206, 71.86117887496948, 73.48064231872559, 75.09391760826111, 76.71040081977844, 78.32273435592651, 79.92812657356262, 81.53638505935669, 83.16380167007446, 84.79254364967346, 86.41976761817932, 88.0359251499176, 89.66372346878052, 91.28591585159302, 92.89954090118408, 94.51165556907654, 96.12501072883606, 97.74229431152344, 99.37388443946838, 100.99678111076355, 102.61238050460815, 104.22113084793091, 105.84426665306091, 107.45770049095154, 109.07396793365479, 110.6857078075409, 112.31926393508911, 113.9311695098877, 115.54119515419006, 117.15540432929993, 118.78086137771606, 120.40462470054626, 122.01889204978943, 123.6410665512085, 125.25131130218506, 126.86909127235413, 128.48922634124756, 130.10188221931458, 131.709223985672, 133.33859133720398, 134.95936393737793, 136.56860971450806, 138.1767020225525, 139.80324816703796, 141.41754341125488, 143.03176093101501, 144.64238333702087, 146.25678396224976, 147.8686544895172, 149.47742772102356, 151.0956416130066, 152.70881867408752, 154.32535576820374, 155.94158959388733, 157.55165815353394, 159.1579077243805, 160.77544379234314, 162.39963126182556, 164.44374585151672]
[14.233333333333333, 40.233333333333334, 49.55833333333333, 53.791666666666664, 63.93333333333333, 65.93333333333334, 68.71666666666667, 69.89166666666667, 73.48333333333333, 72.425, 76.09166666666667, 73.46666666666667, 77.93333333333334, 79.06666666666666, 79.46666666666667, 80.25, 80.7, 81.31666666666666, 80.75833333333334, 80.71666666666667, 81.78333333333333, 81.75833333333334, 82.175, 82.26666666666667, 82.31666666666666, 82.875, 83.075, 83.30833333333334, 83.64166666666667, 83.525, 83.86666666666666, 83.65833333333333, 83.16666666666667, 84.21666666666667, 84.35, 84.85833333333333, 84.48333333333333, 85.125, 85.15, 85.13333333333334, 85.14166666666667, 84.98333333333333, 85.325, 85.86666666666666, 85.43333333333334, 85.45, 85.6, 85.44166666666666, 85.775, 85.975, 85.76666666666667, 86.03333333333333, 86.35833333333333, 86.38333333333334, 86.24166666666666, 86.31666666666666, 86.35833333333333, 86.39166666666667, 86.525, 86.575, 86.90833333333333, 86.49166666666666, 85.975, 86.56666666666666, 86.41666666666667, 87.15833333333333, 87.04166666666667, 87.0, 87.31666666666666, 87.16666666666667, 87.05833333333334, 87.31666666666666, 87.25833333333334, 87.15, 87.41666666666667, 87.20833333333333, 87.39166666666667, 87.41666666666667, 87.86666666666666, 87.63333333333334, 88.0, 87.8, 87.41666666666667, 87.30833333333334, 87.49166666666666, 87.175, 87.78333333333333, 87.575, 87.60833333333333, 87.775, 87.875, 87.85, 87.61666666666666, 87.41666666666667, 87.75833333333334, 87.60833333333333, 87.85, 87.33333333333333, 87.625, 87.91666666666667, 88.30833333333334]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.581, Test loss: 2.235, Test accuracy: 24.03
Round   1, Train loss: 1.208, Test loss: 1.883, Test accuracy: 35.01
Round   2, Train loss: 1.122, Test loss: 1.809, Test accuracy: 36.47
Round   3, Train loss: 0.965, Test loss: 1.780, Test accuracy: 41.02
Round   4, Train loss: 1.087, Test loss: 1.458, Test accuracy: 43.97
Round   5, Train loss: 1.014, Test loss: 1.453, Test accuracy: 48.21
Round   6, Train loss: 1.095, Test loss: 1.118, Test accuracy: 53.30
Round   7, Train loss: 1.034, Test loss: 1.042, Test accuracy: 56.01
Round   8, Train loss: 1.173, Test loss: 1.021, Test accuracy: 58.62
Round   9, Train loss: 0.991, Test loss: 1.029, Test accuracy: 60.62
Round  10, Train loss: 1.023, Test loss: 0.876, Test accuracy: 67.11
Round  11, Train loss: 1.036, Test loss: 0.879, Test accuracy: 66.88
Round  12, Train loss: 1.110, Test loss: 0.882, Test accuracy: 66.50
Round  13, Train loss: 1.065, Test loss: 0.869, Test accuracy: 67.32
Round  14, Train loss: 1.171, Test loss: 0.884, Test accuracy: 66.83
Round  15, Train loss: 1.052, Test loss: 0.865, Test accuracy: 67.89
Round  16, Train loss: 1.090, Test loss: 0.853, Test accuracy: 69.72
Round  17, Train loss: 1.183, Test loss: 0.854, Test accuracy: 68.33
Round  18, Train loss: 1.011, Test loss: 0.869, Test accuracy: 67.78
Round  19, Train loss: 0.983, Test loss: 0.875, Test accuracy: 67.03
Round  20, Train loss: 0.972, Test loss: 0.829, Test accuracy: 72.07
Round  21, Train loss: 1.106, Test loss: 0.836, Test accuracy: 71.71
Round  22, Train loss: 1.145, Test loss: 0.814, Test accuracy: 73.97
Round  23, Train loss: 0.957, Test loss: 0.809, Test accuracy: 74.05
Round  24, Train loss: 0.943, Test loss: 0.809, Test accuracy: 74.45
Round  25, Train loss: 1.022, Test loss: 0.793, Test accuracy: 74.24
Round  26, Train loss: 1.107, Test loss: 0.804, Test accuracy: 73.58
Round  27, Train loss: 1.001, Test loss: 0.811, Test accuracy: 73.41
Round  28, Train loss: 1.040, Test loss: 0.801, Test accuracy: 74.32
Round  29, Train loss: 1.047, Test loss: 0.798, Test accuracy: 74.85
Round  30, Train loss: 0.995, Test loss: 0.819, Test accuracy: 75.32
Round  31, Train loss: 0.927, Test loss: 0.803, Test accuracy: 75.20
Round  32, Train loss: 1.059, Test loss: 0.790, Test accuracy: 75.19
Round  33, Train loss: 1.031, Test loss: 0.795, Test accuracy: 75.51
Round  34, Train loss: 1.002, Test loss: 0.789, Test accuracy: 75.72
Round  35, Train loss: 0.919, Test loss: 0.788, Test accuracy: 74.96
Round  36, Train loss: 0.978, Test loss: 0.767, Test accuracy: 74.75
Round  37, Train loss: 1.056, Test loss: 0.760, Test accuracy: 76.11
Round  38, Train loss: 0.961, Test loss: 0.754, Test accuracy: 76.22
Round  39, Train loss: 0.914, Test loss: 0.741, Test accuracy: 76.06
Round  40, Train loss: 0.892, Test loss: 0.767, Test accuracy: 76.07
Round  41, Train loss: 0.957, Test loss: 0.754, Test accuracy: 75.82
Round  42, Train loss: 1.060, Test loss: 0.755, Test accuracy: 75.48
Round  43, Train loss: 1.173, Test loss: 0.738, Test accuracy: 75.45
Round  44, Train loss: 1.094, Test loss: 0.762, Test accuracy: 75.72
Round  45, Train loss: 0.889, Test loss: 0.749, Test accuracy: 76.71
Round  46, Train loss: 0.986, Test loss: 0.764, Test accuracy: 76.58
Round  47, Train loss: 0.962, Test loss: 0.761, Test accuracy: 76.59
Round  48, Train loss: 1.093, Test loss: 0.741, Test accuracy: 76.85
Round  49, Train loss: 0.935, Test loss: 0.746, Test accuracy: 77.07
Round  50, Train loss: 0.962, Test loss: 0.753, Test accuracy: 76.88
Round  51, Train loss: 0.910, Test loss: 0.758, Test accuracy: 76.63
Round  52, Train loss: 1.060, Test loss: 0.739, Test accuracy: 76.62
Round  53, Train loss: 0.910, Test loss: 0.726, Test accuracy: 77.50
Round  54, Train loss: 0.992, Test loss: 0.714, Test accuracy: 77.42
Round  55, Train loss: 0.784, Test loss: 0.728, Test accuracy: 77.68
Round  56, Train loss: 1.055, Test loss: 0.733, Test accuracy: 76.28
Round  57, Train loss: 1.016, Test loss: 0.708, Test accuracy: 77.68
Round  58, Train loss: 1.004, Test loss: 0.716, Test accuracy: 77.45
Round  59, Train loss: 0.939, Test loss: 0.736, Test accuracy: 77.16
Round  60, Train loss: 0.879, Test loss: 0.706, Test accuracy: 77.79
Round  61, Train loss: 0.920, Test loss: 0.713, Test accuracy: 77.76
Round  62, Train loss: 0.884, Test loss: 0.717, Test accuracy: 77.37
Round  63, Train loss: 1.049, Test loss: 0.712, Test accuracy: 76.69
Round  64, Train loss: 1.019, Test loss: 0.724, Test accuracy: 76.89
Round  65, Train loss: 1.121, Test loss: 0.733, Test accuracy: 76.86
Round  66, Train loss: 0.872, Test loss: 0.722, Test accuracy: 77.25
Round  67, Train loss: 1.107, Test loss: 0.721, Test accuracy: 76.88
Round  68, Train loss: 0.859, Test loss: 0.725, Test accuracy: 77.28
Round  69, Train loss: 1.108, Test loss: 0.710, Test accuracy: 76.57
Round  70, Train loss: 0.816, Test loss: 0.719, Test accuracy: 76.90
Round  71, Train loss: 0.916, Test loss: 0.705, Test accuracy: 77.19
Round  72, Train loss: 0.925, Test loss: 0.707, Test accuracy: 77.61
Round  73, Train loss: 0.987, Test loss: 0.709, Test accuracy: 76.88
Round  74, Train loss: 1.012, Test loss: 0.713, Test accuracy: 76.78
Round  75, Train loss: 0.837, Test loss: 0.717, Test accuracy: 77.19
Round  76, Train loss: 1.028, Test loss: 0.711, Test accuracy: 77.18
Round  77, Train loss: 0.811, Test loss: 0.723, Test accuracy: 77.08
Round  78, Train loss: 0.964, Test loss: 0.726, Test accuracy: 76.83
Round  79, Train loss: 0.987, Test loss: 0.715, Test accuracy: 77.10
Round  80, Train loss: 1.014, Test loss: 0.720, Test accuracy: 76.71
Round  81, Train loss: 0.814, Test loss: 0.727, Test accuracy: 77.19
Round  82, Train loss: 0.835, Test loss: 0.722, Test accuracy: 76.67
Round  83, Train loss: 0.745, Test loss: 0.704, Test accuracy: 76.93
Round  84, Train loss: 0.971, Test loss: 0.697, Test accuracy: 76.89
Round  85, Train loss: 0.909, Test loss: 0.703, Test accuracy: 76.41
Round  86, Train loss: 0.769, Test loss: 0.703, Test accuracy: 76.62
Round  87, Train loss: 0.840, Test loss: 0.705, Test accuracy: 76.80
Round  88, Train loss: 1.004, Test loss: 0.714, Test accuracy: 76.46
Round  89, Train loss: 0.789, Test loss: 0.711, Test accuracy: 76.69
Round  90, Train loss: 0.896, Test loss: 0.712, Test accuracy: 76.39
Round  91, Train loss: 0.986, Test loss: 0.714, Test accuracy: 75.81
Round  92, Train loss: 0.925, Test loss: 0.700, Test accuracy: 75.95
Round  93, Train loss: 0.849, Test loss: 0.711, Test accuracy: 75.67
Round  94, Train loss: 0.961, Test loss: 0.703, Test accuracy: 75.77
Round  95, Train loss: 0.900, Test loss: 0.711, Test accuracy: 75.52
Round  96, Train loss: 0.819, Test loss: 0.712, Test accuracy: 74.78
Round  97, Train loss: 0.985, Test loss: 0.726, Test accuracy: 74.85
Round  98, Train loss: 0.902, Test loss: 0.729, Test accuracy: 75.11
Round  99, Train loss: 1.007, Test loss: 0.726, Test accuracy: 74.53
Final Round, Train loss: 0.802, Test loss: 0.729, Test accuracy: 73.58
Average accuracy final 10 rounds: 75.4375
1943.4434401988983
[1.9578857421875, 3.581406831741333, 5.218441724777222, 6.86406397819519, 8.497972965240479, 10.144243955612183, 11.694467067718506, 13.309458255767822, 14.935141563415527, 16.554081201553345, 18.183287620544434, 19.80129837989807, 21.440457344055176, 23.070409774780273, 24.703569650650024, 26.338106870651245, 27.978522777557373, 29.630854845046997, 31.25178050994873, 32.89073824882507, 34.53007197380066, 37.722411155700684, 40.91978406906128, 43.98353338241577, 47.032676219940186, 50.05928111076355, 53.06280589103699, 56.078816175460815, 59.02159380912781, 62.008514404296875, 65.06696248054504, 68.01167511940002, 70.99093770980835, 74.0686993598938, 76.96323704719543, 80.0197024345398, 83.06077551841736, 85.9954285621643, 89.07524251937866, 92.15805840492249, 95.04565143585205, 98.04273319244385, 101.06259107589722, 103.99737930297852, 106.95355319976807, 110.0881404876709, 112.98682236671448, 116.08153009414673, 119.21035695075989, 122.11983728408813, 125.21917867660522, 128.40673518180847, 131.2857484817505, 134.47767543792725, 137.61828470230103, 140.50587058067322, 143.6349515914917, 146.81474018096924, 149.64154839515686, 152.77579641342163, 155.86268043518066, 158.7436809539795, 161.91105365753174, 165.02815341949463, 167.9241864681244, 171.0968198776245, 174.17814183235168, 177.14248323440552, 180.3212480545044, 183.42501378059387, 186.42646312713623, 189.63650226593018, 192.6428575515747, 195.5766568183899, 198.71710896492004, 201.71521472930908, 204.7024896144867, 207.84726810455322, 210.79850363731384, 213.7098696231842, 216.75063180923462, 219.72587323188782, 222.76827216148376, 225.94782304763794, 228.90570998191833, 232.05741357803345, 235.19408559799194, 238.0936906337738, 241.1742925643921, 244.2690567970276, 247.14751601219177, 250.29630422592163, 253.37453961372375, 256.2492609024048, 259.29864406585693, 262.4127733707428, 265.27728056907654, 268.40698504447937, 271.4907319545746, 274.41646575927734, 276.37482953071594]
[24.033333333333335, 35.00833333333333, 36.46666666666667, 41.016666666666666, 43.96666666666667, 48.208333333333336, 53.3, 56.00833333333333, 58.625, 60.61666666666667, 67.10833333333333, 66.875, 66.5, 67.31666666666666, 66.83333333333333, 67.89166666666667, 69.725, 68.33333333333333, 67.78333333333333, 67.025, 72.06666666666666, 71.70833333333333, 73.96666666666667, 74.05, 74.45, 74.24166666666666, 73.575, 73.40833333333333, 74.31666666666666, 74.85, 75.31666666666666, 75.2, 75.19166666666666, 75.50833333333334, 75.725, 74.95833333333333, 74.75, 76.10833333333333, 76.21666666666667, 76.05833333333334, 76.06666666666666, 75.81666666666666, 75.48333333333333, 75.45, 75.725, 76.70833333333333, 76.58333333333333, 76.59166666666667, 76.85, 77.06666666666666, 76.88333333333334, 76.63333333333334, 76.61666666666666, 77.5, 77.425, 77.68333333333334, 76.275, 77.68333333333334, 77.45, 77.15833333333333, 77.79166666666667, 77.75833333333334, 77.36666666666666, 76.69166666666666, 76.89166666666667, 76.85833333333333, 77.25, 76.88333333333334, 77.28333333333333, 76.56666666666666, 76.9, 77.19166666666666, 77.60833333333333, 76.88333333333334, 76.78333333333333, 77.19166666666666, 77.18333333333334, 77.08333333333333, 76.825, 77.1, 76.70833333333333, 77.19166666666666, 76.66666666666667, 76.93333333333334, 76.89166666666667, 76.40833333333333, 76.61666666666666, 76.8, 76.45833333333333, 76.69166666666666, 76.39166666666667, 75.80833333333334, 75.95, 75.675, 75.76666666666667, 75.51666666666667, 74.78333333333333, 74.85, 75.10833333333333, 74.525, 73.575]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedrep.py", line 45, in <module>
    dataset_train, dataset_test, dict_users_train, dict_users_test, concept_matrix, rand_set_all = get_data_v3(
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 190, in get_data_v3
    y_train_noisy, gamma_s, real_noise_level = add_noise(args, y_train, dict_users_train, rand_set_all)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 236, in add_noise
    y_train_noisy[rand_sample_idx] = nosiy_sample_labels
IndexError: arrays used as indices must be of integer (or boolean) type
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedrep.py", line 60, in <module>
    dataset_train, dataset_test, _, _, _,_ = get_data_v3(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 190, in get_data_v3
    y_train_noisy, gamma_s, real_noise_level = add_noise(args, y_train, dict_users_train, rand_set_all)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 236, in add_noise
    y_train_noisy[rand_sample_idx] = nosiy_sample_labels
IndexError: arrays used as indices must be of integer (or boolean) type
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedrep.py", line 60, in <module>
    dataset_train, dataset_test, _, _, _,_ = get_data_v3(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 190, in get_data_v3
    y_train_noisy, gamma_s, real_noise_level = add_noise(args, y_train, dict_users_train, rand_set_all)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 236, in add_noise
    y_train_noisy[rand_sample_idx] = nosiy_sample_labels
IndexError: arrays used as indices must be of integer (or boolean) type
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Co-teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedpac_co_teaching2.py", line 57, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 126, in get_data_v2
    y_train_noisy, gamma_s, real_noise_level = add_noise(args, y_train, dict_users_train, rand_set_all)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 236, in add_noise
    y_train_noisy[rand_sample_idx] = nosiy_sample_labels
IndexError: arrays used as indices must be of integer (or boolean) type
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "RFL.py", line 50, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 126, in get_data_v2
    y_train_noisy, gamma_s, real_noise_level = add_noise(args, y_train, dict_users_train, rand_set_all)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 236, in add_noise
    y_train_noisy[rand_sample_idx] = nosiy_sample_labels
IndexError: arrays used as indices must be of integer (or boolean) type
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedpac.py", line 58, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 126, in get_data_v2
    y_train_noisy, gamma_s, real_noise_level = add_noise(args, y_train, dict_users_train, rand_set_all)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 236, in add_noise
    y_train_noisy[rand_sample_idx] = nosiy_sample_labels
IndexError: arrays used as indices must be of integer (or boolean) type
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.4 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
Traceback (most recent call last):
  File "main_fedpac_psl.py", line 58, in <module>
    dataset_train, dataset_test, _, _, _ = get_data_v2(args)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 126, in get_data_v2
    y_train_noisy, gamma_s, real_noise_level = add_noise(args, y_train, dict_users_train, rand_set_all)
  File "/home/ChenSM/code/FL_HLS/utils/train_utils.py", line 236, in add_noise
    y_train_noisy[rand_sample_idx] = nosiy_sample_labels
IndexError: arrays used as indices must be of integer (or boolean) type
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 0, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 19, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 4, noise    level: 0.5000 
   Client 10, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.225, Test loss: 2.009, Test accuracy: 22.43
Round   0, Global train loss: 1.225, Global test loss: 2.350, Global test accuracy: 12.67
Round   1, Train loss: 0.977, Test loss: 1.622, Test accuracy: 34.88
Round   1, Global train loss: 0.977, Global test loss: 2.225, Global test accuracy: 14.60
Round   2, Train loss: 0.891, Test loss: 1.371, Test accuracy: 48.39
Round   2, Global train loss: 0.891, Global test loss: 2.093, Global test accuracy: 25.57
Round   3, Train loss: 1.031, Test loss: 1.078, Test accuracy: 52.95
Round   3, Global train loss: 1.031, Global test loss: 2.041, Global test accuracy: 22.98
Round   4, Train loss: 0.934, Test loss: 1.086, Test accuracy: 58.70
Round   4, Global train loss: 0.934, Global test loss: 2.065, Global test accuracy: 29.50
Round   5, Train loss: 1.075, Test loss: 1.067, Test accuracy: 55.49
Round   5, Global train loss: 1.075, Global test loss: 2.241, Global test accuracy: 12.39
Round   6, Train loss: 0.845, Test loss: 1.014, Test accuracy: 60.02
Round   6, Global train loss: 0.845, Global test loss: 2.085, Global test accuracy: 28.22
Round   7, Train loss: 0.882, Test loss: 0.946, Test accuracy: 61.03
Round   7, Global train loss: 0.882, Global test loss: 2.142, Global test accuracy: 27.45
Round   8, Train loss: 0.930, Test loss: 0.910, Test accuracy: 62.87
Round   8, Global train loss: 0.930, Global test loss: 2.116, Global test accuracy: 28.54
Round   9, Train loss: 0.805, Test loss: 0.851, Test accuracy: 66.14
Round   9, Global train loss: 0.805, Global test loss: 1.986, Global test accuracy: 29.80
Round  10, Train loss: 0.839, Test loss: 0.810, Test accuracy: 67.95
Round  10, Global train loss: 0.839, Global test loss: 2.003, Global test accuracy: 29.59
Round  11, Train loss: 0.847, Test loss: 0.809, Test accuracy: 68.94
Round  11, Global train loss: 0.847, Global test loss: 2.251, Global test accuracy: 23.57
Round  12, Train loss: 0.901, Test loss: 0.814, Test accuracy: 68.19
Round  12, Global train loss: 0.901, Global test loss: 2.127, Global test accuracy: 23.59
Round  13, Train loss: 0.920, Test loss: 0.746, Test accuracy: 70.58
Round  13, Global train loss: 0.920, Global test loss: 2.049, Global test accuracy: 28.42
Round  14, Train loss: 0.834, Test loss: 0.737, Test accuracy: 71.15
Round  14, Global train loss: 0.834, Global test loss: 2.086, Global test accuracy: 28.98
Round  15, Train loss: 0.903, Test loss: 0.735, Test accuracy: 71.17
Round  15, Global train loss: 0.903, Global test loss: 2.161, Global test accuracy: 23.23
Round  16, Train loss: 0.959, Test loss: 0.730, Test accuracy: 71.36
Round  16, Global train loss: 0.959, Global test loss: 2.101, Global test accuracy: 26.56
Round  17, Train loss: 0.803, Test loss: 0.753, Test accuracy: 70.59
Round  17, Global train loss: 0.803, Global test loss: 2.003, Global test accuracy: 32.83
Round  18, Train loss: 0.749, Test loss: 0.748, Test accuracy: 70.73
Round  18, Global train loss: 0.749, Global test loss: 1.970, Global test accuracy: 35.41
Round  19, Train loss: 0.771, Test loss: 0.743, Test accuracy: 70.90
Round  19, Global train loss: 0.771, Global test loss: 1.989, Global test accuracy: 25.56
Round  20, Train loss: 0.720, Test loss: 0.757, Test accuracy: 70.08
Round  20, Global train loss: 0.720, Global test loss: 2.020, Global test accuracy: 32.49
Round  21, Train loss: 0.776, Test loss: 0.749, Test accuracy: 70.47
Round  21, Global train loss: 0.776, Global test loss: 2.150, Global test accuracy: 21.83
Round  22, Train loss: 0.548, Test loss: 0.734, Test accuracy: 71.08
Round  22, Global train loss: 0.548, Global test loss: 1.991, Global test accuracy: 26.18
Round  23, Train loss: 0.741, Test loss: 0.735, Test accuracy: 71.19
Round  23, Global train loss: 0.741, Global test loss: 2.110, Global test accuracy: 22.10
Round  24, Train loss: 0.583, Test loss: 0.743, Test accuracy: 70.90
Round  24, Global train loss: 0.583, Global test loss: 1.924, Global test accuracy: 27.20
Round  25, Train loss: 0.917, Test loss: 0.740, Test accuracy: 70.98
Round  25, Global train loss: 0.917, Global test loss: 2.152, Global test accuracy: 21.30
Round  26, Train loss: 0.790, Test loss: 0.751, Test accuracy: 70.37
Round  26, Global train loss: 0.790, Global test loss: 2.310, Global test accuracy: 19.68
Round  27, Train loss: 0.578, Test loss: 0.741, Test accuracy: 70.42
Round  27, Global train loss: 0.578, Global test loss: 2.127, Global test accuracy: 24.99
Round  28, Train loss: 0.727, Test loss: 0.732, Test accuracy: 70.72
Round  28, Global train loss: 0.727, Global test loss: 2.081, Global test accuracy: 25.02
Round  29, Train loss: 0.617, Test loss: 0.739, Test accuracy: 70.97
Round  29, Global train loss: 0.617, Global test loss: 2.100, Global test accuracy: 23.06
Round  30, Train loss: 0.523, Test loss: 0.744, Test accuracy: 71.09
Round  30, Global train loss: 0.523, Global test loss: 2.085, Global test accuracy: 28.14
Round  31, Train loss: 0.694, Test loss: 0.755, Test accuracy: 70.87
Round  31, Global train loss: 0.694, Global test loss: 1.962, Global test accuracy: 31.41
Round  32, Train loss: 0.475, Test loss: 0.753, Test accuracy: 71.31
Round  32, Global train loss: 0.475, Global test loss: 2.141, Global test accuracy: 27.31
Round  33, Train loss: 0.624, Test loss: 0.770, Test accuracy: 70.50
Round  33, Global train loss: 0.624, Global test loss: 2.013, Global test accuracy: 33.64
Round  34, Train loss: 0.418, Test loss: 0.758, Test accuracy: 70.65
Round  34, Global train loss: 0.418, Global test loss: 1.971, Global test accuracy: 29.57
Round  35, Train loss: 0.499, Test loss: 0.768, Test accuracy: 71.12
Round  35, Global train loss: 0.499, Global test loss: 1.929, Global test accuracy: 39.09
Round  36, Train loss: 0.534, Test loss: 0.774, Test accuracy: 70.79
Round  36, Global train loss: 0.534, Global test loss: 2.082, Global test accuracy: 29.52
Round  37, Train loss: 0.525, Test loss: 0.787, Test accuracy: 70.30
Round  37, Global train loss: 0.525, Global test loss: 2.063, Global test accuracy: 26.06
Round  38, Train loss: 0.497, Test loss: 0.774, Test accuracy: 70.81
Round  38, Global train loss: 0.497, Global test loss: 2.163, Global test accuracy: 26.77
Round  39, Train loss: 0.611, Test loss: 0.793, Test accuracy: 70.04
Round  39, Global train loss: 0.611, Global test loss: 1.958, Global test accuracy: 26.68
Round  40, Train loss: 0.463, Test loss: 0.784, Test accuracy: 71.06
Round  40, Global train loss: 0.463, Global test loss: 2.049, Global test accuracy: 20.24
Round  41, Train loss: 0.721, Test loss: 0.796, Test accuracy: 70.28
Round  41, Global train loss: 0.721, Global test loss: 2.119, Global test accuracy: 22.12
Round  42, Train loss: 0.546, Test loss: 0.821, Test accuracy: 69.55
Round  42, Global train loss: 0.546, Global test loss: 2.039, Global test accuracy: 31.79
Round  43, Train loss: 0.473, Test loss: 0.809, Test accuracy: 70.09
Round  43, Global train loss: 0.473, Global test loss: 1.988, Global test accuracy: 29.45
Round  44, Train loss: 0.447, Test loss: 0.822, Test accuracy: 70.09
Round  44, Global train loss: 0.447, Global test loss: 2.073, Global test accuracy: 25.81
Round  45, Train loss: 0.438, Test loss: 0.823, Test accuracy: 70.37
Round  45, Global train loss: 0.438, Global test loss: 2.101, Global test accuracy: 30.96
Round  46, Train loss: 0.551, Test loss: 0.838, Test accuracy: 69.68
Round  46, Global train loss: 0.551, Global test loss: 2.125, Global test accuracy: 22.54
Round  47, Train loss: 0.403, Test loss: 0.853, Test accuracy: 69.59
Round  47, Global train loss: 0.403, Global test loss: 1.978, Global test accuracy: 25.19
Round  48, Train loss: 0.311, Test loss: 0.864, Test accuracy: 69.24
Round  48, Global train loss: 0.311, Global test loss: 2.005, Global test accuracy: 24.62
Round  49, Train loss: 0.200, Test loss: 0.889, Test accuracy: 68.99
Round  49, Global train loss: 0.200, Global test loss: 2.209, Global test accuracy: 22.47
Round  50, Train loss: 0.496, Test loss: 0.906, Test accuracy: 68.83
Round  50, Global train loss: 0.496, Global test loss: 2.058, Global test accuracy: 25.02
Round  51, Train loss: 0.438, Test loss: 0.908, Test accuracy: 69.38
Round  51, Global train loss: 0.438, Global test loss: 2.175, Global test accuracy: 18.05
Round  52, Train loss: 0.301, Test loss: 0.932, Test accuracy: 68.78
Round  52, Global train loss: 0.301, Global test loss: 2.189, Global test accuracy: 18.98
Round  53, Train loss: 0.581, Test loss: 0.954, Test accuracy: 67.91
Round  53, Global train loss: 0.581, Global test loss: 2.229, Global test accuracy: 13.12
Round  54, Train loss: 0.492, Test loss: 0.927, Test accuracy: 68.88
Round  54, Global train loss: 0.492, Global test loss: 2.072, Global test accuracy: 26.03
Round  55, Train loss: 0.598, Test loss: 0.941, Test accuracy: 69.32
Round  55, Global train loss: 0.598, Global test loss: 2.037, Global test accuracy: 30.09
Round  56, Train loss: 0.347, Test loss: 0.960, Test accuracy: 68.91
Round  56, Global train loss: 0.347, Global test loss: 2.083, Global test accuracy: 29.80
Round  57, Train loss: 0.351, Test loss: 0.964, Test accuracy: 68.97
Round  57, Global train loss: 0.351, Global test loss: 1.959, Global test accuracy: 32.24
Round  58, Train loss: 0.325, Test loss: 0.999, Test accuracy: 68.77
Round  58, Global train loss: 0.325, Global test loss: 2.060, Global test accuracy: 28.28
Round  59, Train loss: 0.362, Test loss: 0.995, Test accuracy: 68.67
Round  59, Global train loss: 0.362, Global test loss: 1.965, Global test accuracy: 31.38
Round  60, Train loss: 0.236, Test loss: 1.040, Test accuracy: 67.66
Round  60, Global train loss: 0.236, Global test loss: 2.056, Global test accuracy: 28.57
Round  61, Train loss: 0.378, Test loss: 1.039, Test accuracy: 67.48
Round  61, Global train loss: 0.378, Global test loss: 2.028, Global test accuracy: 28.03
Round  62, Train loss: 0.282, Test loss: 1.045, Test accuracy: 67.33
Round  62, Global train loss: 0.282, Global test loss: 2.037, Global test accuracy: 27.92
Round  63, Train loss: 0.222, Test loss: 1.078, Test accuracy: 66.83
Round  63, Global train loss: 0.222, Global test loss: 1.964, Global test accuracy: 34.43
Round  64, Train loss: 0.403, Test loss: 1.090, Test accuracy: 66.65
Round  64, Global train loss: 0.403, Global test loss: 2.079, Global test accuracy: 25.37
Round  65, Train loss: 0.215, Test loss: 1.090, Test accuracy: 66.96
Round  65, Global train loss: 0.215, Global test loss: 1.920, Global test accuracy: 35.11
Round  66, Train loss: 0.410, Test loss: 1.141, Test accuracy: 66.71
Round  66, Global train loss: 0.410, Global test loss: 2.188, Global test accuracy: 21.91
Round  67, Train loss: 0.261, Test loss: 1.164, Test accuracy: 66.83
Round  67, Global train loss: 0.261, Global test loss: 1.909, Global test accuracy: 35.67
Round  68, Train loss: 0.191, Test loss: 1.195, Test accuracy: 67.13
Round  68, Global train loss: 0.191, Global test loss: 2.130, Global test accuracy: 24.99
Round  69, Train loss: 0.289, Test loss: 1.222, Test accuracy: 66.82
Round  69, Global train loss: 0.289, Global test loss: 2.093, Global test accuracy: 30.38
Round  70, Train loss: 0.212, Test loss: 1.199, Test accuracy: 67.47
Round  70, Global train loss: 0.212, Global test loss: 2.077, Global test accuracy: 28.32
Round  71, Train loss: 0.201, Test loss: 1.193, Test accuracy: 67.57
Round  71, Global train loss: 0.201, Global test loss: 2.053, Global test accuracy: 18.02
Round  72, Train loss: 0.211, Test loss: 1.204, Test accuracy: 67.60
Round  72, Global train loss: 0.211, Global test loss: 2.078, Global test accuracy: 26.34
Round  73, Train loss: 0.292, Test loss: 1.202, Test accuracy: 67.39
Round  73, Global train loss: 0.292, Global test loss: 2.181, Global test accuracy: 22.71
Round  74, Train loss: 0.394, Test loss: 1.196, Test accuracy: 67.48
Round  74, Global train loss: 0.394, Global test loss: 1.990, Global test accuracy: 30.11
Round  75, Train loss: 0.208, Test loss: 1.201, Test accuracy: 68.03
Round  75, Global train loss: 0.208, Global test loss: 1.969, Global test accuracy: 29.13
Round  76, Train loss: 0.244, Test loss: 1.272, Test accuracy: 67.19
Round  76, Global train loss: 0.244, Global test loss: 2.136, Global test accuracy: 20.31
Round  77, Train loss: 0.133, Test loss: 1.278, Test accuracy: 67.19
Round  77, Global train loss: 0.133, Global test loss: 2.052, Global test accuracy: 23.77
Round  78, Train loss: 0.260, Test loss: 1.265, Test accuracy: 67.57
Round  78, Global train loss: 0.260, Global test loss: 2.209, Global test accuracy: 20.23
Round  79, Train loss: 0.133, Test loss: 1.278, Test accuracy: 67.46
Round  79, Global train loss: 0.133, Global test loss: 1.924, Global test accuracy: 36.12
Round  80, Train loss: 0.278, Test loss: 1.303, Test accuracy: 67.45
Round  80, Global train loss: 0.278, Global test loss: 2.078, Global test accuracy: 28.97
Round  81, Train loss: 0.137, Test loss: 1.312, Test accuracy: 67.38
Round  81, Global train loss: 0.137, Global test loss: 2.165, Global test accuracy: 21.33
Round  82, Train loss: 0.194, Test loss: 1.298, Test accuracy: 67.53
Round  82, Global train loss: 0.194, Global test loss: 2.010, Global test accuracy: 26.16
Round  83, Train loss: 0.181, Test loss: 1.332, Test accuracy: 67.35
Round  83, Global train loss: 0.181, Global test loss: 2.068, Global test accuracy: 29.80
Round  84, Train loss: 0.164, Test loss: 1.369, Test accuracy: 67.51
Round  84, Global train loss: 0.164, Global test loss: 1.996, Global test accuracy: 26.36
Round  85, Train loss: 0.207, Test loss: 1.379, Test accuracy: 67.44
Round  85, Global train loss: 0.207, Global test loss: 2.179, Global test accuracy: 20.52
Round  86, Train loss: 0.191, Test loss: 1.366, Test accuracy: 67.67
Round  86, Global train loss: 0.191, Global test loss: 2.050, Global test accuracy: 30.23
Round  87, Train loss: 0.122, Test loss: 1.388, Test accuracy: 67.48
Round  87, Global train loss: 0.122, Global test loss: 2.067, Global test accuracy: 27.32
Round  88, Train loss: 0.133, Test loss: 1.385, Test accuracy: 67.71
Round  88, Global train loss: 0.133, Global test loss: 2.119, Global test accuracy: 24.46
Round  89, Train loss: 0.164, Test loss: 1.382, Test accuracy: 67.80
Round  89, Global train loss: 0.164, Global test loss: 2.192, Global test accuracy: 15.93
Round  90, Train loss: 0.171, Test loss: 1.384, Test accuracy: 67.94
Round  90, Global train loss: 0.171, Global test loss: 2.041, Global test accuracy: 29.18
Round  91, Train loss: 0.093, Test loss: 1.399, Test accuracy: 67.53
Round  91, Global train loss: 0.093, Global test loss: 2.010, Global test accuracy: 30.28
Round  92, Train loss: 0.205, Test loss: 1.393, Test accuracy: 67.20
Round  92, Global train loss: 0.205, Global test loss: 2.116, Global test accuracy: 29.83
Round  93, Train loss: 0.221, Test loss: 1.392, Test accuracy: 67.29
Round  93, Global train loss: 0.221, Global test loss: 2.114, Global test accuracy: 21.35
Round  94, Train loss: 0.135, Test loss: 1.392, Test accuracy: 67.58
Round  94, Global train loss: 0.135, Global test loss: 2.041, Global test accuracy: 27.38
Round  95, Train loss: 0.173, Test loss: 1.401, Test accuracy: 67.77
Round  95, Global train loss: 0.173, Global test loss: 2.118, Global test accuracy: 23.62
Round  96, Train loss: 0.124, Test loss: 1.425, Test accuracy: 67.56
Round  96, Global train loss: 0.124, Global test loss: 2.104, Global test accuracy: 25.28
Round  97, Train loss: 0.113, Test loss: 1.454, Test accuracy: 67.35
Round  97, Global train loss: 0.113, Global test loss: 1.881, Global test accuracy: 34.52
Round  98, Train loss: 0.094, Test loss: 1.482, Test accuracy: 67.50
Round  98, Global train loss: 0.094, Global test loss: 2.179, Global test accuracy: 23.95
Round  99, Train loss: 0.119, Test loss: 1.479, Test accuracy: 67.90
Round  99, Global train loss: 0.119, Global test loss: 2.113, Global test accuracy: 21.11
Final Round, Train loss: 0.128, Test loss: 1.654, Test accuracy: 66.73
Final Round, Global train loss: 0.128, Global test loss: 2.113, Global test accuracy: 21.11
Average accuracy final 10 rounds: 67.56083333333333 

Average global accuracy final 10 rounds: 26.65 

1719.1596035957336
[1.6661772727966309, 3.3323545455932617, 4.739997386932373, 6.147640228271484, 7.556155443191528, 8.964670658111572, 10.384214639663696, 11.80375862121582, 13.226918458938599, 14.650078296661377, 16.073143005371094, 17.49620771408081, 18.922399759292603, 20.348591804504395, 21.785202980041504, 23.221814155578613, 24.650142431259155, 26.078470706939697, 27.504157066345215, 28.929843425750732, 30.361606121063232, 31.793368816375732, 33.227577924728394, 34.661787033081055, 36.08954334259033, 37.51729965209961, 38.938825845718384, 40.36035203933716, 41.79184126853943, 43.2233304977417, 44.644944190979004, 46.06655788421631, 47.49519062042236, 48.92382335662842, 50.34444618225098, 51.765069007873535, 53.18648314476013, 54.60789728164673, 55.8190975189209, 57.03029775619507, 58.24290180206299, 59.45550584793091, 60.68088102340698, 61.90625619888306, 63.12833619117737, 64.35041618347168, 65.57006883621216, 66.78972148895264, 68.02457880973816, 69.25943613052368, 70.49153923988342, 71.72364234924316, 72.93127179145813, 74.1389012336731, 75.36159944534302, 76.58429765701294, 77.81280732154846, 79.04131698608398, 80.26137256622314, 81.4814281463623, 82.7001543045044, 83.91888046264648, 85.16352915763855, 86.40817785263062, 87.6421627998352, 88.8761477470398, 90.09687042236328, 91.31759309768677, 92.54345273971558, 93.76931238174438, 94.98919081687927, 96.20906925201416, 97.4343900680542, 98.65971088409424, 99.87793302536011, 101.09615516662598, 102.32939910888672, 103.56264305114746, 104.7952184677124, 106.02779388427734, 107.24968266487122, 108.47157144546509, 109.6930582523346, 110.9145450592041, 112.14465856552124, 113.37477207183838, 114.6153974533081, 115.85602283477783, 117.07580518722534, 118.29558753967285, 119.52370953559875, 120.75183153152466, 121.9877769947052, 123.22372245788574, 124.45055079460144, 125.67737913131714, 126.89096784591675, 128.10455656051636, 129.3413610458374, 130.57816553115845, 131.80914974212646, 133.04013395309448, 134.25423192977905, 135.46832990646362, 136.7058584690094, 137.94338703155518, 139.190288066864, 140.43718910217285, 141.67557191848755, 142.91395473480225, 144.14564847946167, 145.3773422241211, 146.61558842658997, 147.85383462905884, 149.07716870307922, 150.3005027770996, 151.52757692337036, 152.7546510696411, 153.98835682868958, 155.22206258773804, 156.46823072433472, 157.7143988609314, 158.94172763824463, 160.16905641555786, 161.39577651023865, 162.62249660491943, 163.85747146606445, 165.09244632720947, 166.32639384269714, 167.56034135818481, 168.7993004322052, 170.0382595062256, 171.27189230918884, 172.5055251121521, 173.7503719329834, 174.9952187538147, 176.23486971855164, 177.47452068328857, 178.7093710899353, 179.94422149658203, 181.16715335845947, 182.3900852203369, 183.62260627746582, 184.85512733459473, 186.0923957824707, 187.32966423034668, 188.56951642036438, 189.80936861038208, 191.03820657730103, 192.26704454421997, 193.49496626853943, 194.7228879928589, 195.94975066184998, 197.17661333084106, 198.4044258594513, 199.63223838806152, 200.85751914978027, 202.08279991149902, 203.29997515678406, 204.5171504020691, 205.74305367469788, 206.96895694732666, 208.19475150108337, 209.4205460548401, 210.65189456939697, 211.88324308395386, 213.10857510566711, 214.33390712738037, 215.56416702270508, 216.79442691802979, 218.01777005195618, 219.24111318588257, 220.47176051139832, 221.70240783691406, 222.93995118141174, 224.17749452590942, 225.39882588386536, 226.6201572418213, 227.84418845176697, 229.06821966171265, 230.29905557632446, 231.52989149093628, 232.75591921806335, 233.98194694519043, 235.19334411621094, 236.40474128723145, 237.62928438186646, 238.85382747650146, 240.08838057518005, 241.32293367385864, 242.54234766960144, 243.76176166534424, 244.98423862457275, 246.20671558380127, 247.44474720954895, 248.68277883529663, 249.91330909729004, 251.14383935928345, 252.3647346496582, 253.58562994003296, 255.65201902389526, 257.71840810775757]
[22.433333333333334, 22.433333333333334, 34.875, 34.875, 48.391666666666666, 48.391666666666666, 52.95, 52.95, 58.7, 58.7, 55.49166666666667, 55.49166666666667, 60.016666666666666, 60.016666666666666, 61.03333333333333, 61.03333333333333, 62.86666666666667, 62.86666666666667, 66.14166666666667, 66.14166666666667, 67.95, 67.95, 68.94166666666666, 68.94166666666666, 68.19166666666666, 68.19166666666666, 70.58333333333333, 70.58333333333333, 71.15, 71.15, 71.175, 71.175, 71.35833333333333, 71.35833333333333, 70.59166666666667, 70.59166666666667, 70.73333333333333, 70.73333333333333, 70.9, 70.9, 70.075, 70.075, 70.46666666666667, 70.46666666666667, 71.08333333333333, 71.08333333333333, 71.19166666666666, 71.19166666666666, 70.9, 70.9, 70.98333333333333, 70.98333333333333, 70.36666666666666, 70.36666666666666, 70.41666666666667, 70.41666666666667, 70.725, 70.725, 70.96666666666667, 70.96666666666667, 71.09166666666667, 71.09166666666667, 70.86666666666666, 70.86666666666666, 71.30833333333334, 71.30833333333334, 70.5, 70.5, 70.65, 70.65, 71.11666666666666, 71.11666666666666, 70.79166666666667, 70.79166666666667, 70.3, 70.3, 70.80833333333334, 70.80833333333334, 70.04166666666667, 70.04166666666667, 71.05833333333334, 71.05833333333334, 70.275, 70.275, 69.55, 69.55, 70.09166666666667, 70.09166666666667, 70.09166666666667, 70.09166666666667, 70.36666666666666, 70.36666666666666, 69.68333333333334, 69.68333333333334, 69.59166666666667, 69.59166666666667, 69.24166666666666, 69.24166666666666, 68.99166666666666, 68.99166666666666, 68.825, 68.825, 69.38333333333334, 69.38333333333334, 68.78333333333333, 68.78333333333333, 67.90833333333333, 67.90833333333333, 68.875, 68.875, 69.31666666666666, 69.31666666666666, 68.90833333333333, 68.90833333333333, 68.96666666666667, 68.96666666666667, 68.76666666666667, 68.76666666666667, 68.66666666666667, 68.66666666666667, 67.65833333333333, 67.65833333333333, 67.48333333333333, 67.48333333333333, 67.325, 67.325, 66.825, 66.825, 66.65, 66.65, 66.95833333333333, 66.95833333333333, 66.70833333333333, 66.70833333333333, 66.83333333333333, 66.83333333333333, 67.13333333333334, 67.13333333333334, 66.81666666666666, 66.81666666666666, 67.475, 67.475, 67.56666666666666, 67.56666666666666, 67.6, 67.6, 67.39166666666667, 67.39166666666667, 67.48333333333333, 67.48333333333333, 68.025, 68.025, 67.19166666666666, 67.19166666666666, 67.19166666666666, 67.19166666666666, 67.56666666666666, 67.56666666666666, 67.45833333333333, 67.45833333333333, 67.45, 67.45, 67.38333333333334, 67.38333333333334, 67.53333333333333, 67.53333333333333, 67.35, 67.35, 67.50833333333334, 67.50833333333334, 67.44166666666666, 67.44166666666666, 67.66666666666667, 67.66666666666667, 67.48333333333333, 67.48333333333333, 67.70833333333333, 67.70833333333333, 67.8, 67.8, 67.94166666666666, 67.94166666666666, 67.525, 67.525, 67.2, 67.2, 67.29166666666667, 67.29166666666667, 67.575, 67.575, 67.76666666666667, 67.76666666666667, 67.55833333333334, 67.55833333333334, 67.35, 67.35, 67.5, 67.5, 67.9, 67.9, 66.73333333333333, 66.73333333333333]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 16, noise    level: 0.5000 
   Client 12, noise    level: 0.5000 
   Client 14, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 19, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 18, noise    level: 0.5000 
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.103, Test loss: 1.974, Test accuracy: 24.70
Round   0, Global train loss: 1.103, Global test loss: 2.358, Global test accuracy: 13.11
Round   1, Train loss: 0.926, Test loss: 1.604, Test accuracy: 37.80
Round   1, Global train loss: 0.926, Global test loss: 2.252, Global test accuracy: 17.32
Round   2, Train loss: 0.760, Test loss: 1.469, Test accuracy: 51.62
Round   2, Global train loss: 0.760, Global test loss: 2.259, Global test accuracy: 30.60
Round   3, Train loss: 0.884, Test loss: 0.963, Test accuracy: 59.16
Round   3, Global train loss: 0.884, Global test loss: 1.868, Global test accuracy: 29.91
Round   4, Train loss: 0.703, Test loss: 0.979, Test accuracy: 63.20
Round   4, Global train loss: 0.703, Global test loss: 1.961, Global test accuracy: 34.83
Round   5, Train loss: 0.750, Test loss: 0.875, Test accuracy: 66.44
Round   5, Global train loss: 0.750, Global test loss: 1.822, Global test accuracy: 37.83
Round   6, Train loss: 0.757, Test loss: 0.848, Test accuracy: 67.58
Round   6, Global train loss: 0.757, Global test loss: 1.833, Global test accuracy: 36.35
Round   7, Train loss: 0.789, Test loss: 0.786, Test accuracy: 69.62
Round   7, Global train loss: 0.789, Global test loss: 1.849, Global test accuracy: 38.75
Round   8, Train loss: 0.702, Test loss: 0.716, Test accuracy: 71.95
Round   8, Global train loss: 0.702, Global test loss: 1.682, Global test accuracy: 39.09
Round   9, Train loss: 0.662, Test loss: 0.682, Test accuracy: 72.72
Round   9, Global train loss: 0.662, Global test loss: 1.633, Global test accuracy: 41.43
Round  10, Train loss: 0.721, Test loss: 0.630, Test accuracy: 74.42
Round  10, Global train loss: 0.721, Global test loss: 1.476, Global test accuracy: 49.90
Round  11, Train loss: 0.715, Test loss: 0.637, Test accuracy: 74.70
Round  11, Global train loss: 0.715, Global test loss: 1.996, Global test accuracy: 36.23
Round  12, Train loss: 0.662, Test loss: 0.619, Test accuracy: 75.32
Round  12, Global train loss: 0.662, Global test loss: 1.509, Global test accuracy: 47.33
Round  13, Train loss: 0.630, Test loss: 0.573, Test accuracy: 77.22
Round  13, Global train loss: 0.630, Global test loss: 1.681, Global test accuracy: 45.50
Round  14, Train loss: 0.498, Test loss: 0.575, Test accuracy: 77.03
Round  14, Global train loss: 0.498, Global test loss: 1.816, Global test accuracy: 42.20
Round  15, Train loss: 0.636, Test loss: 0.582, Test accuracy: 76.77
Round  15, Global train loss: 0.636, Global test loss: 1.660, Global test accuracy: 41.65
Round  16, Train loss: 0.581, Test loss: 0.568, Test accuracy: 77.34
Round  16, Global train loss: 0.581, Global test loss: 1.478, Global test accuracy: 48.73
Round  17, Train loss: 0.559, Test loss: 0.549, Test accuracy: 78.11
Round  17, Global train loss: 0.559, Global test loss: 1.479, Global test accuracy: 52.57
Round  18, Train loss: 0.525, Test loss: 0.554, Test accuracy: 77.81
Round  18, Global train loss: 0.525, Global test loss: 1.448, Global test accuracy: 52.44
Round  19, Train loss: 0.513, Test loss: 0.544, Test accuracy: 78.42
Round  19, Global train loss: 0.513, Global test loss: 1.341, Global test accuracy: 53.61
Round  20, Train loss: 0.466, Test loss: 0.541, Test accuracy: 78.68
Round  20, Global train loss: 0.466, Global test loss: 1.394, Global test accuracy: 52.43
Round  21, Train loss: 0.566, Test loss: 0.538, Test accuracy: 78.78
Round  21, Global train loss: 0.566, Global test loss: 1.461, Global test accuracy: 48.42
Round  22, Train loss: 0.497, Test loss: 0.545, Test accuracy: 78.88
Round  22, Global train loss: 0.497, Global test loss: 1.380, Global test accuracy: 55.37
Round  23, Train loss: 0.594, Test loss: 0.548, Test accuracy: 78.36
Round  23, Global train loss: 0.594, Global test loss: 1.454, Global test accuracy: 52.31
Round  24, Train loss: 0.489, Test loss: 0.532, Test accuracy: 78.99
Round  24, Global train loss: 0.489, Global test loss: 1.315, Global test accuracy: 55.42
Round  25, Train loss: 0.503, Test loss: 0.532, Test accuracy: 79.03
Round  25, Global train loss: 0.503, Global test loss: 1.365, Global test accuracy: 52.98
Round  26, Train loss: 0.366, Test loss: 0.530, Test accuracy: 79.14
Round  26, Global train loss: 0.366, Global test loss: 1.832, Global test accuracy: 44.70
Round  27, Train loss: 0.446, Test loss: 0.528, Test accuracy: 79.29
Round  27, Global train loss: 0.446, Global test loss: 1.250, Global test accuracy: 57.08
Round  28, Train loss: 0.415, Test loss: 0.525, Test accuracy: 79.46
Round  28, Global train loss: 0.415, Global test loss: 1.287, Global test accuracy: 56.42
Round  29, Train loss: 0.484, Test loss: 0.539, Test accuracy: 79.28
Round  29, Global train loss: 0.484, Global test loss: 1.402, Global test accuracy: 54.31
Round  30, Train loss: 0.386, Test loss: 0.518, Test accuracy: 79.94
Round  30, Global train loss: 0.386, Global test loss: 1.308, Global test accuracy: 56.23
Round  31, Train loss: 0.548, Test loss: 0.531, Test accuracy: 79.72
Round  31, Global train loss: 0.548, Global test loss: 1.265, Global test accuracy: 55.71
Round  32, Train loss: 0.468, Test loss: 0.506, Test accuracy: 80.66
Round  32, Global train loss: 0.468, Global test loss: 1.480, Global test accuracy: 48.45
Round  33, Train loss: 0.428, Test loss: 0.515, Test accuracy: 79.78
Round  33, Global train loss: 0.428, Global test loss: 1.222, Global test accuracy: 59.36
Round  34, Train loss: 0.374, Test loss: 0.508, Test accuracy: 80.06
Round  34, Global train loss: 0.374, Global test loss: 1.403, Global test accuracy: 54.49
Round  35, Train loss: 0.380, Test loss: 0.518, Test accuracy: 79.80
Round  35, Global train loss: 0.380, Global test loss: 1.427, Global test accuracy: 55.16
Round  36, Train loss: 0.511, Test loss: 0.496, Test accuracy: 80.80
Round  36, Global train loss: 0.511, Global test loss: 1.387, Global test accuracy: 53.36
Round  37, Train loss: 0.447, Test loss: 0.499, Test accuracy: 80.83
Round  37, Global train loss: 0.447, Global test loss: 1.120, Global test accuracy: 61.97
Round  38, Train loss: 0.444, Test loss: 0.486, Test accuracy: 81.78
Round  38, Global train loss: 0.444, Global test loss: 1.336, Global test accuracy: 57.06
Round  39, Train loss: 0.331, Test loss: 0.484, Test accuracy: 81.88
Round  39, Global train loss: 0.331, Global test loss: 1.267, Global test accuracy: 59.61
Round  40, Train loss: 0.499, Test loss: 0.496, Test accuracy: 81.37
Round  40, Global train loss: 0.499, Global test loss: 1.117, Global test accuracy: 62.12
Round  41, Train loss: 0.558, Test loss: 0.499, Test accuracy: 81.47
Round  41, Global train loss: 0.558, Global test loss: 1.295, Global test accuracy: 55.91
Round  42, Train loss: 0.466, Test loss: 0.504, Test accuracy: 81.15
Round  42, Global train loss: 0.466, Global test loss: 1.234, Global test accuracy: 58.48
Round  43, Train loss: 0.412, Test loss: 0.524, Test accuracy: 80.72
Round  43, Global train loss: 0.412, Global test loss: 1.211, Global test accuracy: 58.54
Round  44, Train loss: 0.323, Test loss: 0.507, Test accuracy: 81.46
Round  44, Global train loss: 0.323, Global test loss: 1.188, Global test accuracy: 59.25
Round  45, Train loss: 0.368, Test loss: 0.494, Test accuracy: 81.87
Round  45, Global train loss: 0.368, Global test loss: 1.223, Global test accuracy: 59.04
Round  46, Train loss: 0.451, Test loss: 0.513, Test accuracy: 81.31
Round  46, Global train loss: 0.451, Global test loss: 1.282, Global test accuracy: 55.32
Round  47, Train loss: 0.368, Test loss: 0.510, Test accuracy: 81.12
Round  47, Global train loss: 0.368, Global test loss: 1.189, Global test accuracy: 59.50
Round  48, Train loss: 0.433, Test loss: 0.495, Test accuracy: 82.07
Round  48, Global train loss: 0.433, Global test loss: 1.190, Global test accuracy: 60.17
Round  49, Train loss: 0.411, Test loss: 0.495, Test accuracy: 82.13
Round  49, Global train loss: 0.411, Global test loss: 1.562, Global test accuracy: 49.87
Round  50, Train loss: 0.327, Test loss: 0.485, Test accuracy: 82.53
Round  50, Global train loss: 0.327, Global test loss: 1.132, Global test accuracy: 63.04
Round  51, Train loss: 0.353, Test loss: 0.504, Test accuracy: 81.92
Round  51, Global train loss: 0.353, Global test loss: 1.196, Global test accuracy: 60.15
Round  52, Train loss: 0.339, Test loss: 0.505, Test accuracy: 81.89
Round  52, Global train loss: 0.339, Global test loss: 1.499, Global test accuracy: 57.25
Round  53, Train loss: 0.430, Test loss: 0.524, Test accuracy: 81.28
Round  53, Global train loss: 0.430, Global test loss: 1.467, Global test accuracy: 50.52
Round  54, Train loss: 0.310, Test loss: 0.520, Test accuracy: 81.33
Round  54, Global train loss: 0.310, Global test loss: 1.272, Global test accuracy: 59.54
Round  55, Train loss: 0.384, Test loss: 0.525, Test accuracy: 81.12
Round  55, Global train loss: 0.384, Global test loss: 1.211, Global test accuracy: 59.45
Round  56, Train loss: 0.373, Test loss: 0.538, Test accuracy: 80.73
Round  56, Global train loss: 0.373, Global test loss: 1.133, Global test accuracy: 62.01
Round  57, Train loss: 0.408, Test loss: 0.522, Test accuracy: 81.42
Round  57, Global train loss: 0.408, Global test loss: 1.180, Global test accuracy: 61.13
Round  58, Train loss: 0.238, Test loss: 0.531, Test accuracy: 81.22
Round  58, Global train loss: 0.238, Global test loss: 1.329, Global test accuracy: 59.99
Round  59, Train loss: 0.364, Test loss: 0.526, Test accuracy: 81.47
Round  59, Global train loss: 0.364, Global test loss: 1.248, Global test accuracy: 59.96
Round  60, Train loss: 0.405, Test loss: 0.530, Test accuracy: 81.16
Round  60, Global train loss: 0.405, Global test loss: 1.216, Global test accuracy: 59.87
Round  61, Train loss: 0.313, Test loss: 0.523, Test accuracy: 81.23
Round  61, Global train loss: 0.313, Global test loss: 1.373, Global test accuracy: 57.08
Round  62, Train loss: 0.259, Test loss: 0.534, Test accuracy: 81.17
Round  62, Global train loss: 0.259, Global test loss: 1.255, Global test accuracy: 60.49
Round  63, Train loss: 0.230, Test loss: 0.512, Test accuracy: 81.54
Round  63, Global train loss: 0.230, Global test loss: 1.252, Global test accuracy: 62.79
Round  64, Train loss: 0.250, Test loss: 0.509, Test accuracy: 81.57
Round  64, Global train loss: 0.250, Global test loss: 1.338, Global test accuracy: 57.88
Round  65, Train loss: 0.243, Test loss: 0.512, Test accuracy: 82.10
Round  65, Global train loss: 0.243, Global test loss: 1.080, Global test accuracy: 63.73
Round  66, Train loss: 0.279, Test loss: 0.499, Test accuracy: 82.22
Round  66, Global train loss: 0.279, Global test loss: 1.124, Global test accuracy: 61.81
Round  67, Train loss: 0.251, Test loss: 0.519, Test accuracy: 82.26
Round  67, Global train loss: 0.251, Global test loss: 1.257, Global test accuracy: 62.01
Round  68, Train loss: 0.348, Test loss: 0.516, Test accuracy: 82.45
Round  68, Global train loss: 0.348, Global test loss: 1.128, Global test accuracy: 62.83
Round  69, Train loss: 0.234, Test loss: 0.515, Test accuracy: 82.62
Round  69, Global train loss: 0.234, Global test loss: 1.356, Global test accuracy: 60.84
Round  70, Train loss: 0.297, Test loss: 0.514, Test accuracy: 82.62
Round  70, Global train loss: 0.297, Global test loss: 1.215, Global test accuracy: 63.15
Round  71, Train loss: 0.312, Test loss: 0.517, Test accuracy: 82.52
Round  71, Global train loss: 0.312, Global test loss: 1.224, Global test accuracy: 60.90
Round  72, Train loss: 0.355, Test loss: 0.543, Test accuracy: 81.47
Round  72, Global train loss: 0.355, Global test loss: 1.134, Global test accuracy: 63.23
Round  73, Train loss: 0.222, Test loss: 0.545, Test accuracy: 81.53
Round  73, Global train loss: 0.222, Global test loss: 1.437, Global test accuracy: 56.27
Round  74, Train loss: 0.333, Test loss: 0.561, Test accuracy: 81.42
Round  74, Global train loss: 0.333, Global test loss: 1.171, Global test accuracy: 61.54
Round  75, Train loss: 0.309, Test loss: 0.578, Test accuracy: 81.05
Round  75, Global train loss: 0.309, Global test loss: 1.187, Global test accuracy: 62.65
Round  76, Train loss: 0.310, Test loss: 0.564, Test accuracy: 81.62
Round  76, Global train loss: 0.310, Global test loss: 1.400, Global test accuracy: 57.43
Round  77, Train loss: 0.353, Test loss: 0.565, Test accuracy: 81.64
Round  77, Global train loss: 0.353, Global test loss: 1.313, Global test accuracy: 59.37
Round  78, Train loss: 0.272, Test loss: 0.544, Test accuracy: 82.24
Round  78, Global train loss: 0.272, Global test loss: 1.605, Global test accuracy: 53.63
Round  79, Train loss: 0.292, Test loss: 0.556, Test accuracy: 81.92
Round  79, Global train loss: 0.292, Global test loss: 1.124, Global test accuracy: 64.87
Round  80, Train loss: 0.240, Test loss: 0.545, Test accuracy: 82.42
Round  80, Global train loss: 0.240, Global test loss: 1.511, Global test accuracy: 57.56
Round  81, Train loss: 0.356, Test loss: 0.555, Test accuracy: 82.38
Round  81, Global train loss: 0.356, Global test loss: 1.203, Global test accuracy: 60.92
Round  82, Train loss: 0.295, Test loss: 0.534, Test accuracy: 82.91
Round  82, Global train loss: 0.295, Global test loss: 1.228, Global test accuracy: 62.73
Round  83, Train loss: 0.268, Test loss: 0.538, Test accuracy: 83.07
Round  83, Global train loss: 0.268, Global test loss: 1.150, Global test accuracy: 64.04
Round  84, Train loss: 0.261, Test loss: 0.548, Test accuracy: 82.67
Round  84, Global train loss: 0.261, Global test loss: 1.131, Global test accuracy: 64.33
Round  85, Train loss: 0.324, Test loss: 0.553, Test accuracy: 82.67
Round  85, Global train loss: 0.324, Global test loss: 1.412, Global test accuracy: 58.08
Round  86, Train loss: 0.323, Test loss: 0.566, Test accuracy: 82.13
Round  86, Global train loss: 0.323, Global test loss: 1.413, Global test accuracy: 57.88
Round  87, Train loss: 0.298, Test loss: 0.574, Test accuracy: 81.83
Round  87, Global train loss: 0.298, Global test loss: 1.132, Global test accuracy: 63.58
Round  88, Train loss: 0.252, Test loss: 0.574, Test accuracy: 81.94
Round  88, Global train loss: 0.252, Global test loss: 1.302, Global test accuracy: 60.96
Round  89, Train loss: 0.318, Test loss: 0.597, Test accuracy: 81.53
Round  89, Global train loss: 0.318, Global test loss: 1.429, Global test accuracy: 55.73
Round  90, Train loss: 0.266, Test loss: 0.610, Test accuracy: 81.19
Round  90, Global train loss: 0.266, Global test loss: 1.316, Global test accuracy: 60.67
Round  91, Train loss: 0.241, Test loss: 0.603, Test accuracy: 81.07
Round  91, Global train loss: 0.241, Global test loss: 1.254, Global test accuracy: 62.45
Round  92, Train loss: 0.277, Test loss: 0.602, Test accuracy: 81.49
Round  92, Global train loss: 0.277, Global test loss: 1.487, Global test accuracy: 57.16
Round  93, Train loss: 0.282, Test loss: 0.578, Test accuracy: 82.12
Round  93, Global train loss: 0.282, Global test loss: 1.572, Global test accuracy: 56.73
Round  94, Train loss: 0.286, Test loss: 0.586, Test accuracy: 81.98
Round  94, Global train loss: 0.286, Global test loss: 1.247, Global test accuracy: 61.83
Round  95, Train loss: 0.240, Test loss: 0.582, Test accuracy: 82.19
Round  95, Global train loss: 0.240, Global test loss: 1.282, Global test accuracy: 61.17
Round  96, Train loss: 0.241, Test loss: 0.565, Test accuracy: 82.68
Round  96, Global train loss: 0.241, Global test loss: 1.198, Global test accuracy: 62.82
Round  97, Train loss: 0.241, Test loss: 0.560, Test accuracy: 82.78
Round  97, Global train loss: 0.241, Global test loss: 1.155, Global test accuracy: 64.91
Round  98, Train loss: 0.277, Test loss: 0.540, Test accuracy: 83.26
Round  98, Global train loss: 0.277, Global test loss: 1.309, Global test accuracy: 61.60
Round  99, Train loss: 0.219, Test loss: 0.533, Test accuracy: 83.06
Round  99, Global train loss: 0.219, Global test loss: 1.201, Global test accuracy: 62.91
Final Round, Train loss: 0.182, Test loss: 0.645, Test accuracy: 82.10
Final Round, Global train loss: 0.182, Global test loss: 1.201, Global test accuracy: 62.91
Average accuracy final 10 rounds: 82.18166666666667 

Average global accuracy final 10 rounds: 61.225 

1825.035370349884
[1.6701643466949463, 3.3403286933898926, 4.76015043258667, 6.179972171783447, 7.59234094619751, 9.004709720611572, 10.421002864837646, 11.83729600906372, 13.266346216201782, 14.695396423339844, 16.12279486656189, 17.550193309783936, 18.88056468963623, 20.210936069488525, 21.641623735427856, 23.072311401367188, 24.429891347885132, 25.787471294403076, 27.153042316436768, 28.51861333847046, 29.919291019439697, 31.319968700408936, 32.73431921005249, 34.148669719696045, 35.5158953666687, 36.88312101364136, 38.24398756027222, 39.604854106903076, 40.96196961402893, 42.319085121154785, 43.73233127593994, 45.1455774307251, 46.5684769153595, 47.9913763999939, 49.42004442214966, 50.84871244430542, 52.278457164764404, 53.70820188522339, 55.14223074913025, 56.57625961303711, 58.0028862953186, 59.4295129776001, 60.86419725418091, 62.29888153076172, 63.73517727851868, 65.17147302627563, 66.59908366203308, 68.02669429779053, 69.46887588500977, 70.911057472229, 72.34488892555237, 73.77872037887573, 75.20538806915283, 76.63205575942993, 78.06196141242981, 79.49186706542969, 80.91965770721436, 82.34744834899902, 83.7776415348053, 85.20783472061157, 86.63108468055725, 88.05433464050293, 89.49218010902405, 90.93002557754517, 92.35851764678955, 93.78700971603394, 95.22694897651672, 96.66688823699951, 98.10115957260132, 99.53543090820312, 100.97060799598694, 102.40578508377075, 103.83216667175293, 105.25854825973511, 106.68832015991211, 108.11809206008911, 109.54879236221313, 110.97949266433716, 112.40901184082031, 113.83853101730347, 115.25783276557922, 116.67713451385498, 118.10774421691895, 119.53835391998291, 120.96450591087341, 122.39065790176392, 123.8218195438385, 125.25298118591309, 126.6840615272522, 128.1151418685913, 129.54471063613892, 130.97427940368652, 132.41113138198853, 133.84798336029053, 135.2758595943451, 136.70373582839966, 138.13156294822693, 139.5593900680542, 140.98378801345825, 142.4081859588623, 143.84206748008728, 145.27594900131226, 146.70964431762695, 148.14333963394165, 149.56991004943848, 150.9964804649353, 152.42667293548584, 153.85686540603638, 155.28679871559143, 156.71673202514648, 158.1427674293518, 159.56880283355713, 160.9960596561432, 162.42331647872925, 163.8619565963745, 165.30059671401978, 166.73222017288208, 168.16384363174438, 169.5881645679474, 171.0124855041504, 172.4478635787964, 173.88324165344238, 175.31095623970032, 176.73867082595825, 178.15895652770996, 179.57924222946167, 181.00696229934692, 182.43468236923218, 183.86049246788025, 185.28630256652832, 186.71736192703247, 188.14842128753662, 189.58453035354614, 191.02063941955566, 192.4440724849701, 193.86750555038452, 195.2946162223816, 196.72172689437866, 198.15261602401733, 199.583505153656, 201.01261353492737, 202.44172191619873, 203.8558692932129, 205.27001667022705, 206.69807314872742, 208.12612962722778, 209.5541443824768, 210.98215913772583, 212.40704870224, 213.83193826675415, 215.24580335617065, 216.65966844558716, 218.0914011001587, 219.52313375473022, 220.94852662086487, 222.3739194869995, 223.80282163619995, 225.2317237854004, 226.65707325935364, 228.08242273330688, 229.50995182991028, 230.93748092651367, 232.36399269104004, 233.7905044555664, 235.2300922870636, 236.6696801185608, 238.08990025520325, 239.5101203918457, 240.93611454963684, 242.36210870742798, 243.7965271472931, 245.2309455871582, 246.6658432483673, 248.10074090957642, 249.52364897727966, 250.9465570449829, 252.3829791545868, 253.81940126419067, 255.24946451187134, 256.679527759552, 258.1024241447449, 259.52532052993774, 260.9358513355255, 262.3463821411133, 263.78243255615234, 265.2184829711914, 266.6520025730133, 268.0855221748352, 269.5132703781128, 270.9410185813904, 272.3626546859741, 273.78429079055786, 275.2096688747406, 276.63504695892334, 277.8618788719177, 279.0887107849121, 280.3268039226532, 281.5648970603943, 282.79470562934875, 284.0245141983032, 286.0877287387848, 288.15094327926636]
[24.7, 24.7, 37.8, 37.8, 51.61666666666667, 51.61666666666667, 59.15833333333333, 59.15833333333333, 63.2, 63.2, 66.44166666666666, 66.44166666666666, 67.575, 67.575, 69.61666666666666, 69.61666666666666, 71.95, 71.95, 72.71666666666667, 72.71666666666667, 74.425, 74.425, 74.7, 74.7, 75.31666666666666, 75.31666666666666, 77.225, 77.225, 77.03333333333333, 77.03333333333333, 76.76666666666667, 76.76666666666667, 77.34166666666667, 77.34166666666667, 78.10833333333333, 78.10833333333333, 77.80833333333334, 77.80833333333334, 78.41666666666667, 78.41666666666667, 78.68333333333334, 78.68333333333334, 78.775, 78.775, 78.875, 78.875, 78.35833333333333, 78.35833333333333, 78.99166666666666, 78.99166666666666, 79.03333333333333, 79.03333333333333, 79.14166666666667, 79.14166666666667, 79.29166666666667, 79.29166666666667, 79.45833333333333, 79.45833333333333, 79.275, 79.275, 79.94166666666666, 79.94166666666666, 79.71666666666667, 79.71666666666667, 80.65833333333333, 80.65833333333333, 79.78333333333333, 79.78333333333333, 80.05833333333334, 80.05833333333334, 79.8, 79.8, 80.8, 80.8, 80.825, 80.825, 81.78333333333333, 81.78333333333333, 81.88333333333334, 81.88333333333334, 81.36666666666666, 81.36666666666666, 81.475, 81.475, 81.15, 81.15, 80.725, 80.725, 81.45833333333333, 81.45833333333333, 81.86666666666666, 81.86666666666666, 81.30833333333334, 81.30833333333334, 81.11666666666666, 81.11666666666666, 82.06666666666666, 82.06666666666666, 82.13333333333334, 82.13333333333334, 82.53333333333333, 82.53333333333333, 81.91666666666667, 81.91666666666667, 81.89166666666667, 81.89166666666667, 81.28333333333333, 81.28333333333333, 81.325, 81.325, 81.11666666666666, 81.11666666666666, 80.73333333333333, 80.73333333333333, 81.41666666666667, 81.41666666666667, 81.225, 81.225, 81.46666666666667, 81.46666666666667, 81.15833333333333, 81.15833333333333, 81.23333333333333, 81.23333333333333, 81.175, 81.175, 81.54166666666667, 81.54166666666667, 81.56666666666666, 81.56666666666666, 82.1, 82.1, 82.21666666666667, 82.21666666666667, 82.25833333333334, 82.25833333333334, 82.45, 82.45, 82.61666666666666, 82.61666666666666, 82.625, 82.625, 82.51666666666667, 82.51666666666667, 81.46666666666667, 81.46666666666667, 81.53333333333333, 81.53333333333333, 81.425, 81.425, 81.05, 81.05, 81.625, 81.625, 81.64166666666667, 81.64166666666667, 82.24166666666666, 82.24166666666666, 81.91666666666667, 81.91666666666667, 82.41666666666667, 82.41666666666667, 82.375, 82.375, 82.90833333333333, 82.90833333333333, 83.06666666666666, 83.06666666666666, 82.66666666666667, 82.66666666666667, 82.675, 82.675, 82.13333333333334, 82.13333333333334, 81.825, 81.825, 81.94166666666666, 81.94166666666666, 81.53333333333333, 81.53333333333333, 81.19166666666666, 81.19166666666666, 81.06666666666666, 81.06666666666666, 81.49166666666666, 81.49166666666666, 82.11666666666666, 82.11666666666666, 81.98333333333333, 81.98333333333333, 82.19166666666666, 82.19166666666666, 82.68333333333334, 82.68333333333334, 82.775, 82.775, 83.25833333333334, 83.25833333333334, 83.05833333333334, 83.05833333333334, 82.1, 82.1]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
   Client 0, noise    level: 0.5000 
   Client 8, noise    level: 0.5000 
   Client 16, noise    level: 0.5000 
   Client 1, noise    level: 0.5000 
   Client 7, noise    level: 0.5000 
   Client 6, noise    level: 0.5000 
   Client 19, noise    level: 0.5000 
   Client 14, noise    level: 0.5000 
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.124, Test loss: 1.929, Test accuracy: 22.05
Round   0, Global train loss: 1.124, Global test loss: 2.304, Global test accuracy: 10.00
Round   1, Train loss: 0.991, Test loss: 1.637, Test accuracy: 36.30
Round   1, Global train loss: 0.991, Global test loss: 2.251, Global test accuracy: 18.70
Round   2, Train loss: 0.866, Test loss: 1.473, Test accuracy: 49.42
Round   2, Global train loss: 0.866, Global test loss: 2.212, Global test accuracy: 29.66
Round   3, Train loss: 0.866, Test loss: 1.006, Test accuracy: 57.12
Round   3, Global train loss: 0.866, Global test loss: 1.953, Global test accuracy: 29.64
Round   4, Train loss: 0.748, Test loss: 0.991, Test accuracy: 60.64
Round   4, Global train loss: 0.748, Global test loss: 1.954, Global test accuracy: 31.59
Round   5, Train loss: 0.818, Test loss: 0.880, Test accuracy: 64.80
Round   5, Global train loss: 0.818, Global test loss: 1.726, Global test accuracy: 38.70
Round   6, Train loss: 0.836, Test loss: 0.904, Test accuracy: 64.15
Round   6, Global train loss: 0.836, Global test loss: 1.881, Global test accuracy: 36.04
Round   7, Train loss: 0.753, Test loss: 0.844, Test accuracy: 65.83
Round   7, Global train loss: 0.753, Global test loss: 1.926, Global test accuracy: 35.32
Round   8, Train loss: 0.715, Test loss: 0.792, Test accuracy: 68.49
Round   8, Global train loss: 0.715, Global test loss: 1.823, Global test accuracy: 36.83
Round   9, Train loss: 0.752, Test loss: 0.725, Test accuracy: 70.31
Round   9, Global train loss: 0.752, Global test loss: 1.682, Global test accuracy: 41.70
Round  10, Train loss: 0.737, Test loss: 0.668, Test accuracy: 72.67
Round  10, Global train loss: 0.737, Global test loss: 1.526, Global test accuracy: 48.38
Round  11, Train loss: 0.844, Test loss: 0.666, Test accuracy: 73.06
Round  11, Global train loss: 0.844, Global test loss: 1.855, Global test accuracy: 36.96
Round  12, Train loss: 0.651, Test loss: 0.658, Test accuracy: 73.34
Round  12, Global train loss: 0.651, Global test loss: 1.539, Global test accuracy: 44.67
Round  13, Train loss: 0.672, Test loss: 0.623, Test accuracy: 74.66
Round  13, Global train loss: 0.672, Global test loss: 1.694, Global test accuracy: 43.59
Round  14, Train loss: 0.606, Test loss: 0.617, Test accuracy: 74.88
Round  14, Global train loss: 0.606, Global test loss: 1.874, Global test accuracy: 39.04
Round  15, Train loss: 0.766, Test loss: 0.612, Test accuracy: 74.97
Round  15, Global train loss: 0.766, Global test loss: 1.676, Global test accuracy: 40.12
Round  16, Train loss: 0.714, Test loss: 0.615, Test accuracy: 75.64
Round  16, Global train loss: 0.714, Global test loss: 1.515, Global test accuracy: 46.73
Round  17, Train loss: 0.734, Test loss: 0.607, Test accuracy: 75.88
Round  17, Global train loss: 0.734, Global test loss: 1.512, Global test accuracy: 50.74
Round  18, Train loss: 0.576, Test loss: 0.592, Test accuracy: 76.71
Round  18, Global train loss: 0.576, Global test loss: 1.512, Global test accuracy: 51.73
Round  19, Train loss: 0.663, Test loss: 0.577, Test accuracy: 77.30
Round  19, Global train loss: 0.663, Global test loss: 1.430, Global test accuracy: 53.62
Round  20, Train loss: 0.550, Test loss: 0.571, Test accuracy: 77.74
Round  20, Global train loss: 0.550, Global test loss: 1.435, Global test accuracy: 51.21
Round  21, Train loss: 0.742, Test loss: 0.563, Test accuracy: 78.01
Round  21, Global train loss: 0.742, Global test loss: 1.445, Global test accuracy: 51.27
Round  22, Train loss: 0.549, Test loss: 0.563, Test accuracy: 78.03
Round  22, Global train loss: 0.549, Global test loss: 1.464, Global test accuracy: 52.49
Round  23, Train loss: 0.554, Test loss: 0.557, Test accuracy: 78.47
Round  23, Global train loss: 0.554, Global test loss: 1.427, Global test accuracy: 52.67
Round  24, Train loss: 0.570, Test loss: 0.551, Test accuracy: 78.67
Round  24, Global train loss: 0.570, Global test loss: 1.324, Global test accuracy: 56.05
Round  25, Train loss: 0.553, Test loss: 0.544, Test accuracy: 78.94
Round  25, Global train loss: 0.553, Global test loss: 1.347, Global test accuracy: 53.09
Round  26, Train loss: 0.507, Test loss: 0.532, Test accuracy: 79.14
Round  26, Global train loss: 0.507, Global test loss: 1.767, Global test accuracy: 42.62
Round  27, Train loss: 0.597, Test loss: 0.549, Test accuracy: 78.38
Round  27, Global train loss: 0.597, Global test loss: 1.299, Global test accuracy: 55.73
Round  28, Train loss: 0.519, Test loss: 0.542, Test accuracy: 78.78
Round  28, Global train loss: 0.519, Global test loss: 1.326, Global test accuracy: 54.26
Round  29, Train loss: 0.486, Test loss: 0.554, Test accuracy: 78.61
Round  29, Global train loss: 0.486, Global test loss: 1.453, Global test accuracy: 52.58
Round  30, Train loss: 0.479, Test loss: 0.541, Test accuracy: 78.98
Round  30, Global train loss: 0.479, Global test loss: 1.315, Global test accuracy: 54.22
Round  31, Train loss: 0.500, Test loss: 0.530, Test accuracy: 79.46
Round  31, Global train loss: 0.500, Global test loss: 1.298, Global test accuracy: 53.83
Round  32, Train loss: 0.514, Test loss: 0.547, Test accuracy: 78.92
Round  32, Global train loss: 0.514, Global test loss: 1.375, Global test accuracy: 49.10
Round  33, Train loss: 0.550, Test loss: 0.554, Test accuracy: 78.83
Round  33, Global train loss: 0.550, Global test loss: 1.261, Global test accuracy: 56.69
Round  34, Train loss: 0.429, Test loss: 0.544, Test accuracy: 79.08
Round  34, Global train loss: 0.429, Global test loss: 1.431, Global test accuracy: 53.27
Round  35, Train loss: 0.481, Test loss: 0.546, Test accuracy: 78.87
Round  35, Global train loss: 0.481, Global test loss: 1.392, Global test accuracy: 54.62
Round  36, Train loss: 0.559, Test loss: 0.542, Test accuracy: 79.16
Round  36, Global train loss: 0.559, Global test loss: 1.414, Global test accuracy: 53.25
Round  37, Train loss: 0.447, Test loss: 0.543, Test accuracy: 78.80
Round  37, Global train loss: 0.447, Global test loss: 1.176, Global test accuracy: 59.46
Round  38, Train loss: 0.481, Test loss: 0.531, Test accuracy: 79.22
Round  38, Global train loss: 0.481, Global test loss: 1.355, Global test accuracy: 55.17
Round  39, Train loss: 0.460, Test loss: 0.517, Test accuracy: 80.36
Round  39, Global train loss: 0.460, Global test loss: 1.309, Global test accuracy: 56.98
Round  40, Train loss: 0.544, Test loss: 0.531, Test accuracy: 79.17
Round  40, Global train loss: 0.544, Global test loss: 1.200, Global test accuracy: 58.17
Round  41, Train loss: 0.561, Test loss: 0.525, Test accuracy: 79.51
Round  41, Global train loss: 0.561, Global test loss: 1.356, Global test accuracy: 53.69
Round  42, Train loss: 0.535, Test loss: 0.520, Test accuracy: 79.76
Round  42, Global train loss: 0.535, Global test loss: 1.224, Global test accuracy: 58.34
Round  43, Train loss: 0.492, Test loss: 0.527, Test accuracy: 79.58
Round  43, Global train loss: 0.492, Global test loss: 1.255, Global test accuracy: 56.83
Round  44, Train loss: 0.455, Test loss: 0.532, Test accuracy: 79.59
Round  44, Global train loss: 0.455, Global test loss: 1.213, Global test accuracy: 58.73
Round  45, Train loss: 0.428, Test loss: 0.529, Test accuracy: 79.79
Round  45, Global train loss: 0.428, Global test loss: 1.281, Global test accuracy: 56.28
Round  46, Train loss: 0.415, Test loss: 0.518, Test accuracy: 80.22
Round  46, Global train loss: 0.415, Global test loss: 1.358, Global test accuracy: 51.44
Round  47, Train loss: 0.469, Test loss: 0.528, Test accuracy: 79.88
Round  47, Global train loss: 0.469, Global test loss: 1.367, Global test accuracy: 54.16
Round  48, Train loss: 0.446, Test loss: 0.532, Test accuracy: 79.88
Round  48, Global train loss: 0.446, Global test loss: 1.221, Global test accuracy: 59.67
Round  49, Train loss: 0.375, Test loss: 0.531, Test accuracy: 80.06
Round  49, Global train loss: 0.375, Global test loss: 1.408, Global test accuracy: 52.23
Round  50, Train loss: 0.451, Test loss: 0.543, Test accuracy: 79.57
Round  50, Global train loss: 0.451, Global test loss: 1.156, Global test accuracy: 61.62
Round  51, Train loss: 0.497, Test loss: 0.545, Test accuracy: 79.83
Round  51, Global train loss: 0.497, Global test loss: 1.174, Global test accuracy: 60.26
Round  52, Train loss: 0.389, Test loss: 0.533, Test accuracy: 80.38
Round  52, Global train loss: 0.389, Global test loss: 1.489, Global test accuracy: 55.57
Round  53, Train loss: 0.564, Test loss: 0.536, Test accuracy: 80.24
Round  53, Global train loss: 0.564, Global test loss: 1.265, Global test accuracy: 56.80
Round  54, Train loss: 0.416, Test loss: 0.524, Test accuracy: 80.47
Round  54, Global train loss: 0.416, Global test loss: 1.297, Global test accuracy: 57.35
Round  55, Train loss: 0.468, Test loss: 0.532, Test accuracy: 80.61
Round  55, Global train loss: 0.468, Global test loss: 1.275, Global test accuracy: 58.08
Round  56, Train loss: 0.382, Test loss: 0.528, Test accuracy: 80.97
Round  56, Global train loss: 0.382, Global test loss: 1.198, Global test accuracy: 60.32
Round  57, Train loss: 0.538, Test loss: 0.534, Test accuracy: 80.55
Round  57, Global train loss: 0.538, Global test loss: 1.275, Global test accuracy: 59.12
Round  58, Train loss: 0.337, Test loss: 0.536, Test accuracy: 80.43
Round  58, Global train loss: 0.337, Global test loss: 1.272, Global test accuracy: 59.99
Round  59, Train loss: 0.464, Test loss: 0.538, Test accuracy: 80.75
Round  59, Global train loss: 0.464, Global test loss: 1.289, Global test accuracy: 58.66
Round  60, Train loss: 0.404, Test loss: 0.547, Test accuracy: 80.52
Round  60, Global train loss: 0.404, Global test loss: 1.268, Global test accuracy: 58.81
Round  61, Train loss: 0.359, Test loss: 0.528, Test accuracy: 81.13
Round  61, Global train loss: 0.359, Global test loss: 1.447, Global test accuracy: 55.21
Round  62, Train loss: 0.338, Test loss: 0.519, Test accuracy: 81.72
Round  62, Global train loss: 0.338, Global test loss: 1.317, Global test accuracy: 58.69
Round  63, Train loss: 0.373, Test loss: 0.520, Test accuracy: 81.63
Round  63, Global train loss: 0.373, Global test loss: 1.244, Global test accuracy: 61.14
Round  64, Train loss: 0.302, Test loss: 0.520, Test accuracy: 81.28
Round  64, Global train loss: 0.302, Global test loss: 1.364, Global test accuracy: 55.80
Round  65, Train loss: 0.290, Test loss: 0.507, Test accuracy: 81.81
Round  65, Global train loss: 0.290, Global test loss: 1.167, Global test accuracy: 61.52
Round  66, Train loss: 0.339, Test loss: 0.525, Test accuracy: 81.17
Round  66, Global train loss: 0.339, Global test loss: 1.156, Global test accuracy: 60.88
Round  67, Train loss: 0.422, Test loss: 0.522, Test accuracy: 81.19
Round  67, Global train loss: 0.422, Global test loss: 1.181, Global test accuracy: 61.39
Round  68, Train loss: 0.411, Test loss: 0.547, Test accuracy: 80.29
Round  68, Global train loss: 0.411, Global test loss: 1.143, Global test accuracy: 61.92
Round  69, Train loss: 0.367, Test loss: 0.547, Test accuracy: 80.38
Round  69, Global train loss: 0.367, Global test loss: 1.302, Global test accuracy: 59.38
Round  70, Train loss: 0.429, Test loss: 0.557, Test accuracy: 80.42
Round  70, Global train loss: 0.429, Global test loss: 1.237, Global test accuracy: 61.85
Round  71, Train loss: 0.401, Test loss: 0.539, Test accuracy: 80.96
Round  71, Global train loss: 0.401, Global test loss: 1.213, Global test accuracy: 60.49
Round  72, Train loss: 0.362, Test loss: 0.515, Test accuracy: 81.44
Round  72, Global train loss: 0.362, Global test loss: 1.126, Global test accuracy: 61.92
Round  73, Train loss: 0.310, Test loss: 0.514, Test accuracy: 81.58
Round  73, Global train loss: 0.310, Global test loss: 1.306, Global test accuracy: 57.48
Round  74, Train loss: 0.319, Test loss: 0.522, Test accuracy: 81.38
Round  74, Global train loss: 0.319, Global test loss: 1.315, Global test accuracy: 57.83
Round  75, Train loss: 0.394, Test loss: 0.525, Test accuracy: 81.24
Round  75, Global train loss: 0.394, Global test loss: 1.269, Global test accuracy: 58.99
Round  76, Train loss: 0.386, Test loss: 0.543, Test accuracy: 81.08
Round  76, Global train loss: 0.386, Global test loss: 1.456, Global test accuracy: 55.27
Round  77, Train loss: 0.396, Test loss: 0.561, Test accuracy: 80.55
Round  77, Global train loss: 0.396, Global test loss: 1.429, Global test accuracy: 55.91
Round  78, Train loss: 0.279, Test loss: 0.554, Test accuracy: 80.88
Round  78, Global train loss: 0.279, Global test loss: 1.671, Global test accuracy: 51.62
Round  79, Train loss: 0.380, Test loss: 0.552, Test accuracy: 81.01
Round  79, Global train loss: 0.380, Global test loss: 1.219, Global test accuracy: 61.60
Round  80, Train loss: 0.373, Test loss: 0.545, Test accuracy: 81.13
Round  80, Global train loss: 0.373, Global test loss: 1.424, Global test accuracy: 57.89
Round  81, Train loss: 0.372, Test loss: 0.546, Test accuracy: 81.12
Round  81, Global train loss: 0.372, Global test loss: 1.174, Global test accuracy: 61.11
Round  82, Train loss: 0.305, Test loss: 0.529, Test accuracy: 81.87
Round  82, Global train loss: 0.305, Global test loss: 1.202, Global test accuracy: 61.33
Round  83, Train loss: 0.351, Test loss: 0.512, Test accuracy: 82.34
Round  83, Global train loss: 0.351, Global test loss: 1.158, Global test accuracy: 62.05
Round  84, Train loss: 0.306, Test loss: 0.516, Test accuracy: 82.07
Round  84, Global train loss: 0.306, Global test loss: 1.165, Global test accuracy: 62.83
Round  85, Train loss: 0.297, Test loss: 0.536, Test accuracy: 81.92
Round  85, Global train loss: 0.297, Global test loss: 1.430, Global test accuracy: 57.60
Round  86, Train loss: 0.335, Test loss: 0.528, Test accuracy: 82.34
Round  86, Global train loss: 0.335, Global test loss: 1.335, Global test accuracy: 58.98
Round  87, Train loss: 0.280, Test loss: 0.521, Test accuracy: 82.53
Round  87, Global train loss: 0.280, Global test loss: 1.128, Global test accuracy: 63.61
Round  88, Train loss: 0.333, Test loss: 0.530, Test accuracy: 82.33
Round  88, Global train loss: 0.333, Global test loss: 1.198, Global test accuracy: 60.92
Round  89, Train loss: 0.284, Test loss: 0.528, Test accuracy: 82.22
Round  89, Global train loss: 0.284, Global test loss: 1.204, Global test accuracy: 60.77
Round  90, Train loss: 0.282, Test loss: 0.536, Test accuracy: 81.78
Round  90, Global train loss: 0.282, Global test loss: 1.230, Global test accuracy: 61.35
Round  91, Train loss: 0.317, Test loss: 0.544, Test accuracy: 81.90
Round  91, Global train loss: 0.317, Global test loss: 1.209, Global test accuracy: 62.87
Round  92, Train loss: 0.255, Test loss: 0.554, Test accuracy: 81.62
Round  92, Global train loss: 0.255, Global test loss: 1.555, Global test accuracy: 55.24
Round  93, Train loss: 0.295, Test loss: 0.559, Test accuracy: 81.57
Round  93, Global train loss: 0.295, Global test loss: 1.391, Global test accuracy: 59.14
Round  94, Train loss: 0.301, Test loss: 0.567, Test accuracy: 81.30
Round  94, Global train loss: 0.301, Global test loss: 1.213, Global test accuracy: 62.44
Round  95, Train loss: 0.302, Test loss: 0.569, Test accuracy: 81.20
Round  95, Global train loss: 0.302, Global test loss: 1.275, Global test accuracy: 59.69
Round  96, Train loss: 0.312, Test loss: 0.554, Test accuracy: 81.47
Round  96, Global train loss: 0.312, Global test loss: 1.225, Global test accuracy: 60.98
Round  97, Train loss: 0.255, Test loss: 0.559, Test accuracy: 81.54
Round  97, Global train loss: 0.255, Global test loss: 1.206, Global test accuracy: 62.58
Round  98, Train loss: 0.303, Test loss: 0.544, Test accuracy: 81.90
Round  98, Global train loss: 0.303, Global test loss: 1.246, Global test accuracy: 62.35
Round  99, Train loss: 0.277, Test loss: 0.552, Test accuracy: 81.50
Round  99, Global train loss: 0.277, Global test loss: 1.155, Global test accuracy: 63.40
Final Round, Train loss: 0.237, Test loss: 0.582, Test accuracy: 81.36
Final Round, Global train loss: 0.237, Global test loss: 1.155, Global test accuracy: 63.40
Average accuracy final 10 rounds: 81.5775 

Average global accuracy final 10 rounds: 61.004999999999995 

1875.188196182251
[1.808746576309204, 3.617493152618408, 5.167686462402344, 6.717879772186279, 8.263253211975098, 9.808626651763916, 11.34738802909851, 12.886149406433105, 14.433554887771606, 15.980960369110107, 17.53721809387207, 19.093475818634033, 20.63145875930786, 22.16944169998169, 23.712656497955322, 25.255871295928955, 26.80775809288025, 28.359644889831543, 29.8992338180542, 31.438822746276855, 32.98517179489136, 34.53152084350586, 36.07999897003174, 37.62847709655762, 39.16905450820923, 40.70963191986084, 42.258986711502075, 43.80834150314331, 45.356770038604736, 46.90519857406616, 48.44220805168152, 49.979217529296875, 51.51978540420532, 53.06035327911377, 54.61227607727051, 56.164198875427246, 57.70070171356201, 59.23720455169678, 60.77364993095398, 62.31009531021118, 63.85540843009949, 65.4007215499878, 66.9494047164917, 68.4980878829956, 70.04059195518494, 71.58309602737427, 73.12615871429443, 74.6692214012146, 76.1698989868164, 77.67057657241821, 79.17708492279053, 80.68359327316284, 82.1351466178894, 83.58669996261597, 85.07047748565674, 86.55425500869751, 87.99737668037415, 89.44049835205078, 90.95686841011047, 92.47323846817017, 93.99441194534302, 95.51558542251587, 97.03364276885986, 98.55170011520386, 100.07137632369995, 101.59105253219604, 103.10702610015869, 104.62299966812134, 106.14087963104248, 107.65875959396362, 109.18144273757935, 110.70412588119507, 112.0785219669342, 113.45291805267334, 114.96591544151306, 116.47891283035278, 117.98774862289429, 119.49658441543579, 121.09200596809387, 122.68742752075195, 124.20323967933655, 125.71905183792114, 127.2327663898468, 128.74648094177246, 130.2681381702423, 131.78979539871216, 133.3005199432373, 134.81124448776245, 136.32133221626282, 137.83141994476318, 139.3448944091797, 140.8583688735962, 142.3690984249115, 143.8798279762268, 145.38817167282104, 146.89651536941528, 148.41345596313477, 149.93039655685425, 151.43573832511902, 152.9410800933838, 154.45513105392456, 155.96918201446533, 157.48989820480347, 159.0106143951416, 160.5268898010254, 162.04316520690918, 163.45124340057373, 164.85932159423828, 166.18595719337463, 167.512592792511, 168.84558415412903, 170.17857551574707, 171.5035743713379, 172.8285732269287, 174.15312957763672, 175.47768592834473, 176.80985403060913, 178.14202213287354, 179.4668779373169, 180.79173374176025, 182.1235852241516, 183.45543670654297, 184.79817247390747, 186.14090824127197, 187.4693956375122, 188.79788303375244, 190.1308455467224, 191.46380805969238, 192.79331707954407, 194.12282609939575, 195.44723773002625, 196.77164936065674, 198.09185338020325, 199.41205739974976, 200.7393069267273, 202.06655645370483, 203.39434957504272, 204.72214269638062, 206.05056834220886, 207.3789939880371, 208.70100450515747, 210.02301502227783, 211.3536913394928, 212.68436765670776, 214.18887162208557, 215.69337558746338, 217.1981325149536, 218.70288944244385, 220.20671701431274, 221.71054458618164, 223.2164146900177, 224.72228479385376, 226.24086952209473, 227.7594542503357, 229.2930612564087, 230.8266682624817, 232.34692358970642, 233.86717891693115, 235.39048266410828, 236.9137864112854, 238.43140816688538, 239.94902992248535, 241.47205805778503, 242.99508619308472, 244.51635909080505, 246.0376319885254, 247.56155562400818, 249.08547925949097, 250.6105306148529, 252.13558197021484, 253.66501379013062, 255.1944456100464, 256.72148180007935, 258.2485179901123, 259.77192783355713, 261.29533767700195, 262.8234624862671, 264.3515872955322, 265.8792428970337, 267.40689849853516, 268.9341630935669, 270.46142768859863, 271.9888687133789, 273.5163097381592, 275.0454316139221, 276.57455348968506, 278.09941053390503, 279.624267578125, 281.15029978752136, 282.6763319969177, 284.1951732635498, 285.7140145301819, 287.24007081985474, 288.7661271095276, 290.2907807826996, 291.8154344558716, 293.33910155296326, 294.86276865005493, 296.37528800964355, 297.8878073692322, 300.53761053085327, 303.18741369247437]
[22.05, 22.05, 36.3, 36.3, 49.416666666666664, 49.416666666666664, 57.11666666666667, 57.11666666666667, 60.641666666666666, 60.641666666666666, 64.8, 64.8, 64.15, 64.15, 65.83333333333333, 65.83333333333333, 68.49166666666666, 68.49166666666666, 70.30833333333334, 70.30833333333334, 72.675, 72.675, 73.05833333333334, 73.05833333333334, 73.34166666666667, 73.34166666666667, 74.65833333333333, 74.65833333333333, 74.875, 74.875, 74.975, 74.975, 75.64166666666667, 75.64166666666667, 75.875, 75.875, 76.70833333333333, 76.70833333333333, 77.3, 77.3, 77.74166666666666, 77.74166666666666, 78.00833333333334, 78.00833333333334, 78.03333333333333, 78.03333333333333, 78.475, 78.475, 78.675, 78.675, 78.94166666666666, 78.94166666666666, 79.14166666666667, 79.14166666666667, 78.38333333333334, 78.38333333333334, 78.78333333333333, 78.78333333333333, 78.60833333333333, 78.60833333333333, 78.98333333333333, 78.98333333333333, 79.45833333333333, 79.45833333333333, 78.925, 78.925, 78.83333333333333, 78.83333333333333, 79.08333333333333, 79.08333333333333, 78.86666666666666, 78.86666666666666, 79.15833333333333, 79.15833333333333, 78.8, 78.8, 79.225, 79.225, 80.35833333333333, 80.35833333333333, 79.175, 79.175, 79.50833333333334, 79.50833333333334, 79.75833333333334, 79.75833333333334, 79.575, 79.575, 79.59166666666667, 79.59166666666667, 79.79166666666667, 79.79166666666667, 80.225, 80.225, 79.88333333333334, 79.88333333333334, 79.88333333333334, 79.88333333333334, 80.05833333333334, 80.05833333333334, 79.56666666666666, 79.56666666666666, 79.83333333333333, 79.83333333333333, 80.38333333333334, 80.38333333333334, 80.24166666666666, 80.24166666666666, 80.46666666666667, 80.46666666666667, 80.60833333333333, 80.60833333333333, 80.975, 80.975, 80.55, 80.55, 80.43333333333334, 80.43333333333334, 80.75, 80.75, 80.51666666666667, 80.51666666666667, 81.13333333333334, 81.13333333333334, 81.71666666666667, 81.71666666666667, 81.63333333333334, 81.63333333333334, 81.275, 81.275, 81.80833333333334, 81.80833333333334, 81.16666666666667, 81.16666666666667, 81.19166666666666, 81.19166666666666, 80.29166666666667, 80.29166666666667, 80.375, 80.375, 80.425, 80.425, 80.95833333333333, 80.95833333333333, 81.44166666666666, 81.44166666666666, 81.575, 81.575, 81.375, 81.375, 81.24166666666666, 81.24166666666666, 81.08333333333333, 81.08333333333333, 80.55, 80.55, 80.875, 80.875, 81.00833333333334, 81.00833333333334, 81.13333333333334, 81.13333333333334, 81.125, 81.125, 81.86666666666666, 81.86666666666666, 82.34166666666667, 82.34166666666667, 82.06666666666666, 82.06666666666666, 81.925, 81.925, 82.34166666666667, 82.34166666666667, 82.53333333333333, 82.53333333333333, 82.33333333333333, 82.33333333333333, 82.225, 82.225, 81.78333333333333, 81.78333333333333, 81.9, 81.9, 81.61666666666666, 81.61666666666666, 81.56666666666666, 81.56666666666666, 81.3, 81.3, 81.2, 81.2, 81.46666666666667, 81.46666666666667, 81.54166666666667, 81.54166666666667, 81.9, 81.9, 81.5, 81.5, 81.35833333333333, 81.35833333333333]/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Co-teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 3, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
   Client 16, noise    level: 0.5000 
   Client 7, noise    level: 0.5000 
   Client 5, noise    level: 0.5000 
   Client 9, noise    level: 0.5000 
   Client 12, noise    level: 0.5000 
   Client 11, noise    level: 0.5000 
   Client 2, noise    level: 0.5000 
   Client 13, noise    level: 0.5000 
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.617, Test loss: 2.190, Test accuracy: 18.38
Round   1, Train loss: 1.116, Test loss: 1.864, Test accuracy: 27.88
Round   2, Train loss: 1.020, Test loss: 1.571, Test accuracy: 44.50
Round   3, Train loss: 1.082, Test loss: 1.173, Test accuracy: 48.49
Round   4, Train loss: 0.988, Test loss: 1.174, Test accuracy: 56.37
Round   5, Train loss: 1.099, Test loss: 1.127, Test accuracy: 52.71
Round   6, Train loss: 0.930, Test loss: 1.105, Test accuracy: 59.22
Round   7, Train loss: 0.940, Test loss: 1.044, Test accuracy: 60.83
Round   8, Train loss: 0.984, Test loss: 0.980, Test accuracy: 65.14
Round   9, Train loss: 0.917, Test loss: 0.893, Test accuracy: 64.90
Round  10, Train loss: 0.905, Test loss: 0.835, Test accuracy: 65.01
Round  11, Train loss: 0.929, Test loss: 0.856, Test accuracy: 67.65
Round  12, Train loss: 0.930, Test loss: 0.840, Test accuracy: 66.12
Round  13, Train loss: 0.997, Test loss: 0.747, Test accuracy: 70.61
Round  14, Train loss: 0.919, Test loss: 0.752, Test accuracy: 70.95
Round  15, Train loss: 1.034, Test loss: 0.760, Test accuracy: 71.96
Round  16, Train loss: 1.061, Test loss: 0.767, Test accuracy: 71.62
Round  17, Train loss: 0.927, Test loss: 0.743, Test accuracy: 72.16
Round  18, Train loss: 0.824, Test loss: 0.731, Test accuracy: 72.04
Round  19, Train loss: 0.892, Test loss: 0.724, Test accuracy: 73.03
Round  20, Train loss: 0.854, Test loss: 0.730, Test accuracy: 72.30
Round  21, Train loss: 0.973, Test loss: 0.730, Test accuracy: 72.64
Round  22, Train loss: 0.687, Test loss: 0.724, Test accuracy: 73.13
Round  23, Train loss: 0.872, Test loss: 0.718, Test accuracy: 74.30
Round  24, Train loss: 0.752, Test loss: 0.704, Test accuracy: 74.15
Round  25, Train loss: 0.990, Test loss: 0.696, Test accuracy: 74.29
Round  26, Train loss: 0.931, Test loss: 0.700, Test accuracy: 74.03
Round  27, Train loss: 0.816, Test loss: 0.698, Test accuracy: 75.45
Round  28, Train loss: 0.916, Test loss: 0.705, Test accuracy: 75.16
Round  29, Train loss: 0.740, Test loss: 0.707, Test accuracy: 75.17
Round  30, Train loss: 0.727, Test loss: 0.705, Test accuracy: 74.28
Round  31, Train loss: 0.831, Test loss: 0.693, Test accuracy: 75.65
Round  32, Train loss: 0.698, Test loss: 0.674, Test accuracy: 76.09
Round  33, Train loss: 0.832, Test loss: 0.671, Test accuracy: 76.47
Round  34, Train loss: 0.602, Test loss: 0.668, Test accuracy: 76.78
Round  35, Train loss: 0.743, Test loss: 0.660, Test accuracy: 77.27
Round  36, Train loss: 0.771, Test loss: 0.655, Test accuracy: 78.01
Round  37, Train loss: 0.724, Test loss: 0.658, Test accuracy: 77.08
Round  38, Train loss: 0.696, Test loss: 0.653, Test accuracy: 76.71
Round  39, Train loss: 0.812, Test loss: 0.643, Test accuracy: 76.40
Round  40, Train loss: 0.724, Test loss: 0.649, Test accuracy: 76.88
Round  41, Train loss: 0.918, Test loss: 0.650, Test accuracy: 76.66
Round  42, Train loss: 0.860, Test loss: 0.633, Test accuracy: 77.42
Round  43, Train loss: 0.795, Test loss: 0.618, Test accuracy: 78.76
Round  44, Train loss: 0.763, Test loss: 0.620, Test accuracy: 78.42
Round  45, Train loss: 0.717, Test loss: 0.627, Test accuracy: 78.35
Round  46, Train loss: 0.840, Test loss: 0.626, Test accuracy: 77.75
Round  47, Train loss: 0.700, Test loss: 0.623, Test accuracy: 78.43
Round  48, Train loss: 0.628, Test loss: 0.614, Test accuracy: 78.94
Round  49, Train loss: 0.445, Test loss: 0.616, Test accuracy: 78.51
Round  50, Train loss: 0.831, Test loss: 0.612, Test accuracy: 79.17
Round  51, Train loss: 0.855, Test loss: 0.630, Test accuracy: 79.16
Round  52, Train loss: 0.627, Test loss: 0.631, Test accuracy: 78.63
Round  53, Train loss: 0.941, Test loss: 0.632, Test accuracy: 78.55
Round  54, Train loss: 0.825, Test loss: 0.640, Test accuracy: 77.58
Round  55, Train loss: 0.971, Test loss: 0.639, Test accuracy: 77.53
Round  56, Train loss: 0.618, Test loss: 0.620, Test accuracy: 78.06
Round  57, Train loss: 0.757, Test loss: 0.605, Test accuracy: 78.94
Round  58, Train loss: 0.703, Test loss: 0.616, Test accuracy: 78.53
Round  59, Train loss: 0.802, Test loss: 0.616, Test accuracy: 78.56
Round  60, Train loss: 0.597, Test loss: 0.614, Test accuracy: 78.77
Round  61, Train loss: 0.756, Test loss: 0.609, Test accuracy: 78.92
Round  62, Train loss: 0.646, Test loss: 0.610, Test accuracy: 79.15
Round  63, Train loss: 0.600, Test loss: 0.597, Test accuracy: 78.82
Round  64, Train loss: 0.822, Test loss: 0.611, Test accuracy: 78.03
Round  65, Train loss: 0.519, Test loss: 0.611, Test accuracy: 78.22
Round  66, Train loss: 0.824, Test loss: 0.628, Test accuracy: 77.34
Round  67, Train loss: 0.750, Test loss: 0.615, Test accuracy: 78.27
Round  68, Train loss: 0.604, Test loss: 0.609, Test accuracy: 78.28
Round  69, Train loss: 0.696, Test loss: 0.610, Test accuracy: 77.78
Round  70, Train loss: 0.720, Test loss: 0.616, Test accuracy: 77.49
Round  71, Train loss: 0.656, Test loss: 0.614, Test accuracy: 77.79
Round  72, Train loss: 0.640, Test loss: 0.608, Test accuracy: 77.98
Round  73, Train loss: 0.677, Test loss: 0.601, Test accuracy: 77.90
Round  74, Train loss: 0.739, Test loss: 0.602, Test accuracy: 78.09
Round  75, Train loss: 0.666, Test loss: 0.600, Test accuracy: 78.22
Round  76, Train loss: 0.794, Test loss: 0.603, Test accuracy: 78.17
Round  77, Train loss: 0.493, Test loss: 0.599, Test accuracy: 78.52
Round  78, Train loss: 0.690, Test loss: 0.608, Test accuracy: 78.06
Round  79, Train loss: 0.511, Test loss: 0.592, Test accuracy: 79.04
Round  80, Train loss: 0.749, Test loss: 0.588, Test accuracy: 78.96
Round  81, Train loss: 0.546, Test loss: 0.587, Test accuracy: 78.80
Round  82, Train loss: 0.655, Test loss: 0.592, Test accuracy: 78.66
Round  83, Train loss: 0.616, Test loss: 0.603, Test accuracy: 77.34
Round  84, Train loss: 0.644, Test loss: 0.592, Test accuracy: 78.49
Round  85, Train loss: 0.546, Test loss: 0.601, Test accuracy: 77.78
Round  86, Train loss: 0.508, Test loss: 0.591, Test accuracy: 78.43
Round  87, Train loss: 0.501, Test loss: 0.604, Test accuracy: 77.86
Round  88, Train loss: 0.606, Test loss: 0.608, Test accuracy: 77.40
Round  89, Train loss: 0.621, Test loss: 0.609, Test accuracy: 77.02
Round  90, Train loss: 0.607, Test loss: 0.597, Test accuracy: 77.72
Round  91, Train loss: 0.461, Test loss: 0.595, Test accuracy: 77.65
Round  92, Train loss: 0.641, Test loss: 0.589, Test accuracy: 78.22
Round  93, Train loss: 0.639, Test loss: 0.603, Test accuracy: 77.14
Round  94, Train loss: 0.492, Test loss: 0.599, Test accuracy: 77.72
Round  95, Train loss: 0.696, Test loss: 0.606, Test accuracy: 76.97
Round  96, Train loss: 0.595, Test loss: 0.615, Test accuracy: 76.11
Round  97, Train loss: 0.537, Test loss: 0.591, Test accuracy: 77.66
Round  98, Train loss: 0.520, Test loss: 0.593, Test accuracy: 77.78
Round  99, Train loss: 0.563, Test loss: 0.588, Test accuracy: 78.03
Final Round, Train loss: 0.550, Test loss: 0.602, Test accuracy: 77.17
Average accuracy final 10 rounds: 77.49833333333332
1327.6360456943512
[1.9909741878509521, 3.6190598011016846, 5.202546834945679, 6.781789302825928, 8.373434782028198, 9.951923608779907, 11.559653520584106, 13.162189483642578, 14.760270357131958, 16.3647677898407, 18.003971099853516, 19.665234565734863, 21.33257293701172, 22.992204189300537, 24.667185068130493, 26.331334829330444, 27.994653463363647, 29.67071795463562, 31.343608140945435, 33.02267551422119, 34.694557189941406, 36.362507343292236, 38.030075788497925, 39.7096951007843, 41.38874554634094, 43.04169273376465, 44.70834708213806, 46.371888160705566, 48.01820635795593, 49.684428215026855, 51.34664797782898, 53.011882066726685, 54.66145157814026, 56.30298447608948, 57.92662286758423, 59.56607007980347, 61.218279123306274, 62.85731053352356, 64.51244044303894, 66.16029715538025, 67.78896594047546, 69.42729806900024, 71.08128595352173, 72.73257255554199, 74.37434506416321, 76.0410041809082, 77.6713707447052, 79.31295704841614, 80.95142269134521, 82.5932388305664, 84.24211382865906, 85.91526246070862, 87.5763008594513, 89.23674845695496, 90.90263175964355, 92.5718936920166, 94.2400598526001, 95.91355586051941, 97.553964138031, 99.19084572792053, 100.82595014572144, 102.46486949920654, 104.10297060012817, 105.83513164520264, 107.43214797973633, 108.95710849761963, 110.47624111175537, 111.96908450126648, 113.49678206443787, 115.02994775772095, 116.67477130889893, 118.32909512519836, 119.9919638633728, 121.64801716804504, 123.3067901134491, 124.9547667503357, 126.59838342666626, 128.26356196403503, 129.91412377357483, 131.55937457084656, 133.1989448070526, 134.84390687942505, 136.51049399375916, 138.15778994560242, 139.79493618011475, 141.44546365737915, 143.09814453125, 144.73967361450195, 146.3701012134552, 148.01920890808105, 149.6791696548462, 151.3418242931366, 152.99244499206543, 154.63756346702576, 156.2806272506714, 157.93366503715515, 159.5898139476776, 161.23525476455688, 162.8909935951233, 164.53980660438538, 166.67803168296814]
[18.383333333333333, 27.883333333333333, 44.5, 48.49166666666667, 56.36666666666667, 52.708333333333336, 59.21666666666667, 60.833333333333336, 65.14166666666667, 64.9, 65.00833333333334, 67.65, 66.125, 70.60833333333333, 70.95, 71.95833333333333, 71.61666666666666, 72.15833333333333, 72.04166666666667, 73.03333333333333, 72.3, 72.64166666666667, 73.13333333333334, 74.3, 74.15, 74.29166666666667, 74.025, 75.45, 75.15833333333333, 75.175, 74.28333333333333, 75.65, 76.09166666666667, 76.46666666666667, 76.78333333333333, 77.26666666666667, 78.00833333333334, 77.08333333333333, 76.70833333333333, 76.4, 76.875, 76.65833333333333, 77.41666666666667, 78.75833333333334, 78.41666666666667, 78.35, 77.75, 78.43333333333334, 78.94166666666666, 78.50833333333334, 79.16666666666667, 79.15833333333333, 78.63333333333334, 78.55, 77.58333333333333, 77.525, 78.05833333333334, 78.94166666666666, 78.525, 78.55833333333334, 78.76666666666667, 78.925, 79.15, 78.81666666666666, 78.03333333333333, 78.225, 77.34166666666667, 78.26666666666667, 78.275, 77.775, 77.49166666666666, 77.79166666666667, 77.98333333333333, 77.9, 78.09166666666667, 78.21666666666667, 78.175, 78.51666666666667, 78.05833333333334, 79.04166666666667, 78.95833333333333, 78.8, 78.65833333333333, 77.34166666666667, 78.49166666666666, 77.775, 78.43333333333334, 77.85833333333333, 77.4, 77.01666666666667, 77.71666666666667, 77.65, 78.21666666666667, 77.14166666666667, 77.71666666666667, 76.96666666666667, 76.10833333333333, 77.65833333333333, 77.775, 78.03333333333333, 77.16666666666667]
