nohup: ignoring input
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.005, Test loss: 1.745, Test accuracy: 37.78
Round   0, Global train loss: 2.005, Global test loss: 1.735, Global test accuracy: 39.18
Round   1, Train loss: 1.670, Test loss: 1.561, Test accuracy: 43.50
Round   1, Global train loss: 1.670, Global test loss: 1.524, Global test accuracy: 45.53
Round   2, Train loss: 1.551, Test loss: 1.470, Test accuracy: 46.77
Round   2, Global train loss: 1.551, Global test loss: 1.368, Global test accuracy: 51.03
Round   3, Train loss: 1.484, Test loss: 1.450, Test accuracy: 47.86
Round   3, Global train loss: 1.484, Global test loss: 1.321, Global test accuracy: 53.76
Round   4, Train loss: 1.436, Test loss: 1.442, Test accuracy: 47.79
Round   4, Global train loss: 1.436, Global test loss: 1.294, Global test accuracy: 53.91
Round   5, Train loss: 1.468, Test loss: 1.417, Test accuracy: 48.86
Round   5, Global train loss: 1.468, Global test loss: 1.371, Global test accuracy: 52.81
Round   6, Train loss: 1.370, Test loss: 1.397, Test accuracy: 49.58
Round   6, Global train loss: 1.370, Global test loss: 1.324, Global test accuracy: 53.81
Round   7, Train loss: 1.285, Test loss: 1.391, Test accuracy: 50.27
Round   7, Global train loss: 1.285, Global test loss: 1.273, Global test accuracy: 56.87
Round   8, Train loss: 1.243, Test loss: 1.389, Test accuracy: 50.72
Round   8, Global train loss: 1.243, Global test loss: 1.346, Global test accuracy: 54.30
Round   9, Train loss: 1.216, Test loss: 1.376, Test accuracy: 51.30
Round   9, Global train loss: 1.216, Global test loss: 1.174, Global test accuracy: 58.77
Round  10, Train loss: 1.213, Test loss: 1.374, Test accuracy: 51.79
Round  10, Global train loss: 1.213, Global test loss: 1.281, Global test accuracy: 55.54
Round  11, Train loss: 1.126, Test loss: 1.359, Test accuracy: 52.15
Round  11, Global train loss: 1.126, Global test loss: 1.274, Global test accuracy: 56.91
Round  12, Train loss: 1.045, Test loss: 1.375, Test accuracy: 52.20
Round  12, Global train loss: 1.045, Global test loss: 1.168, Global test accuracy: 59.83
Round  13, Train loss: 1.108, Test loss: 1.389, Test accuracy: 52.44
Round  13, Global train loss: 1.108, Global test loss: 1.177, Global test accuracy: 58.62
Round  14, Train loss: 0.989, Test loss: 1.388, Test accuracy: 52.54
Round  14, Global train loss: 0.989, Global test loss: 1.128, Global test accuracy: 60.68
Round  15, Train loss: 1.063, Test loss: 1.391, Test accuracy: 52.85
Round  15, Global train loss: 1.063, Global test loss: 1.258, Global test accuracy: 56.48
Round  16, Train loss: 1.032, Test loss: 1.406, Test accuracy: 52.92
Round  16, Global train loss: 1.032, Global test loss: 1.271, Global test accuracy: 55.57
Round  17, Train loss: 1.037, Test loss: 1.427, Test accuracy: 53.05
Round  17, Global train loss: 1.037, Global test loss: 1.192, Global test accuracy: 58.05
Round  18, Train loss: 0.920, Test loss: 1.409, Test accuracy: 54.08
Round  18, Global train loss: 0.920, Global test loss: 1.289, Global test accuracy: 55.06
Round  19, Train loss: 0.916, Test loss: 1.414, Test accuracy: 54.24
Round  19, Global train loss: 0.916, Global test loss: 1.263, Global test accuracy: 56.95
Round  20, Train loss: 0.927, Test loss: 1.431, Test accuracy: 53.81
Round  20, Global train loss: 0.927, Global test loss: 1.115, Global test accuracy: 61.19
Round  21, Train loss: 0.815, Test loss: 1.442, Test accuracy: 54.03
Round  21, Global train loss: 0.815, Global test loss: 1.221, Global test accuracy: 57.63
Round  22, Train loss: 0.805, Test loss: 1.451, Test accuracy: 54.33
Round  22, Global train loss: 0.805, Global test loss: 1.108, Global test accuracy: 61.07
Round  23, Train loss: 0.757, Test loss: 1.497, Test accuracy: 54.34
Round  23, Global train loss: 0.757, Global test loss: 1.161, Global test accuracy: 59.01
Round  24, Train loss: 0.760, Test loss: 1.506, Test accuracy: 54.42
Round  24, Global train loss: 0.760, Global test loss: 1.183, Global test accuracy: 58.85
Round  25, Train loss: 0.780, Test loss: 1.512, Test accuracy: 54.51
Round  25, Global train loss: 0.780, Global test loss: 1.152, Global test accuracy: 59.96
Round  26, Train loss: 0.763, Test loss: 1.516, Test accuracy: 54.81
Round  26, Global train loss: 0.763, Global test loss: 1.127, Global test accuracy: 60.05
Round  27, Train loss: 0.717, Test loss: 1.537, Test accuracy: 54.77
Round  27, Global train loss: 0.717, Global test loss: 1.140, Global test accuracy: 60.93
Round  28, Train loss: 0.743, Test loss: 1.546, Test accuracy: 54.66
Round  28, Global train loss: 0.743, Global test loss: 1.211, Global test accuracy: 57.66
Round  29, Train loss: 0.726, Test loss: 1.564, Test accuracy: 54.65
Round  29, Global train loss: 0.726, Global test loss: 1.141, Global test accuracy: 60.60
Round  30, Train loss: 0.583, Test loss: 1.583, Test accuracy: 54.83
Round  30, Global train loss: 0.583, Global test loss: 1.095, Global test accuracy: 62.94
Round  31, Train loss: 0.656, Test loss: 1.600, Test accuracy: 54.85
Round  31, Global train loss: 0.656, Global test loss: 1.139, Global test accuracy: 59.22
Round  32, Train loss: 0.714, Test loss: 1.604, Test accuracy: 55.06
Round  32, Global train loss: 0.714, Global test loss: 1.211, Global test accuracy: 57.65
Round  33, Train loss: 0.634, Test loss: 1.624, Test accuracy: 55.16
Round  33, Global train loss: 0.634, Global test loss: 1.148, Global test accuracy: 59.52
Round  34, Train loss: 0.575, Test loss: 1.648, Test accuracy: 55.09
Round  34, Global train loss: 0.575, Global test loss: 1.128, Global test accuracy: 61.74
Round  35, Train loss: 0.569, Test loss: 1.656, Test accuracy: 55.27
Round  35, Global train loss: 0.569, Global test loss: 1.222, Global test accuracy: 57.04
Round  36, Train loss: 0.475, Test loss: 1.690, Test accuracy: 55.33
Round  36, Global train loss: 0.475, Global test loss: 1.166, Global test accuracy: 59.77
Round  37, Train loss: 0.491, Test loss: 1.696, Test accuracy: 55.30
Round  37, Global train loss: 0.491, Global test loss: 1.195, Global test accuracy: 57.96
Round  38, Train loss: 0.670, Test loss: 1.711, Test accuracy: 55.29
Round  38, Global train loss: 0.670, Global test loss: 1.170, Global test accuracy: 58.95
Round  39, Train loss: 0.645, Test loss: 1.727, Test accuracy: 55.26
Round  39, Global train loss: 0.645, Global test loss: 1.225, Global test accuracy: 56.85
Round  40, Train loss: 0.521, Test loss: 1.772, Test accuracy: 55.30
Round  40, Global train loss: 0.521, Global test loss: 1.196, Global test accuracy: 57.66
Round  41, Train loss: 0.498, Test loss: 1.784, Test accuracy: 55.09
Round  41, Global train loss: 0.498, Global test loss: 1.154, Global test accuracy: 59.68
Round  42, Train loss: 0.586, Test loss: 1.783, Test accuracy: 55.41
Round  42, Global train loss: 0.586, Global test loss: 1.165, Global test accuracy: 59.04
Round  43, Train loss: 0.548, Test loss: 1.809, Test accuracy: 55.52
Round  43, Global train loss: 0.548, Global test loss: 1.163, Global test accuracy: 59.71
Round  44, Train loss: 0.507, Test loss: 1.836, Test accuracy: 55.21
Round  44, Global train loss: 0.507, Global test loss: 1.176, Global test accuracy: 58.88
Round  45, Train loss: 0.433, Test loss: 1.836, Test accuracy: 55.55
Round  45, Global train loss: 0.433, Global test loss: 1.205, Global test accuracy: 58.08
Round  46, Train loss: 0.481, Test loss: 1.855, Test accuracy: 55.37
Round  46, Global train loss: 0.481, Global test loss: 1.182, Global test accuracy: 58.63
Round  47, Train loss: 0.576, Test loss: 1.856, Test accuracy: 55.55
Round  47, Global train loss: 0.576, Global test loss: 1.202, Global test accuracy: 57.75
Round  48, Train loss: 0.543, Test loss: 1.871, Test accuracy: 55.63
Round  48, Global train loss: 0.543, Global test loss: 1.160, Global test accuracy: 59.56
Round  49, Train loss: 0.451, Test loss: 1.902, Test accuracy: 55.81
Round  49, Global train loss: 0.451, Global test loss: 1.294, Global test accuracy: 54.14
Round  50, Train loss: 0.451, Test loss: 1.943, Test accuracy: 55.57
Round  50, Global train loss: 0.451, Global test loss: 1.161, Global test accuracy: 60.66
Round  51, Train loss: 0.423, Test loss: 1.952, Test accuracy: 55.40
Round  51, Global train loss: 0.423, Global test loss: 1.186, Global test accuracy: 59.56
Round  52, Train loss: 0.486, Test loss: 1.983, Test accuracy: 55.37
Round  52, Global train loss: 0.486, Global test loss: 1.165, Global test accuracy: 59.56
Round  53, Train loss: 0.450, Test loss: 1.983, Test accuracy: 55.54
Round  53, Global train loss: 0.450, Global test loss: 1.148, Global test accuracy: 60.99
Round  54, Train loss: 0.407, Test loss: 1.956, Test accuracy: 55.82
Round  54, Global train loss: 0.407, Global test loss: 1.196, Global test accuracy: 57.94
Round  55, Train loss: 0.370, Test loss: 1.977, Test accuracy: 55.94
Round  55, Global train loss: 0.370, Global test loss: 1.176, Global test accuracy: 59.53
Round  56, Train loss: 0.360, Test loss: 2.016, Test accuracy: 55.93
Round  56, Global train loss: 0.360, Global test loss: 1.222, Global test accuracy: 57.81
Round  57, Train loss: 0.362, Test loss: 2.045, Test accuracy: 55.81
Round  57, Global train loss: 0.362, Global test loss: 1.206, Global test accuracy: 58.13
Round  58, Train loss: 0.363, Test loss: 2.029, Test accuracy: 56.07
Round  58, Global train loss: 0.363, Global test loss: 1.303, Global test accuracy: 52.70
Round  59, Train loss: 0.387, Test loss: 2.075, Test accuracy: 55.73
Round  59, Global train loss: 0.387, Global test loss: 1.166, Global test accuracy: 60.50
Round  60, Train loss: 0.348, Test loss: 2.069, Test accuracy: 55.95
Round  60, Global train loss: 0.348, Global test loss: 1.208, Global test accuracy: 59.55
Round  61, Train loss: 0.380, Test loss: 2.119, Test accuracy: 55.66
Round  61, Global train loss: 0.380, Global test loss: 1.225, Global test accuracy: 56.65
Round  62, Train loss: 0.346, Test loss: 2.121, Test accuracy: 55.79
Round  62, Global train loss: 0.346, Global test loss: 1.192, Global test accuracy: 60.30
Round  63, Train loss: 0.379, Test loss: 2.150, Test accuracy: 55.61
Round  63, Global train loss: 0.379, Global test loss: 1.181, Global test accuracy: 59.43
Round  64, Train loss: 0.331, Test loss: 2.143, Test accuracy: 55.87
Round  64, Global train loss: 0.331, Global test loss: 1.197, Global test accuracy: 58.91
Round  65, Train loss: 0.370, Test loss: 2.179, Test accuracy: 55.49
Round  65, Global train loss: 0.370, Global test loss: 1.215, Global test accuracy: 58.21
Round  66, Train loss: 0.314, Test loss: 2.185, Test accuracy: 55.53
Round  66, Global train loss: 0.314, Global test loss: 1.188, Global test accuracy: 61.27
Round  67, Train loss: 0.312, Test loss: 2.217, Test accuracy: 55.17
Round  67, Global train loss: 0.312, Global test loss: 1.242, Global test accuracy: 56.93
Round  68, Train loss: 0.309, Test loss: 2.240, Test accuracy: 55.38
Round  68, Global train loss: 0.309, Global test loss: 1.240, Global test accuracy: 61.59
Round  69, Train loss: 0.334, Test loss: 2.253, Test accuracy: 55.85
Round  69, Global train loss: 0.334, Global test loss: 1.226, Global test accuracy: 56.75
Round  70, Train loss: 0.350, Test loss: 2.306, Test accuracy: 55.40
Round  70, Global train loss: 0.350, Global test loss: 1.183, Global test accuracy: 60.87
Round  71, Train loss: 0.280, Test loss: 2.323, Test accuracy: 55.40
Round  71, Global train loss: 0.280, Global test loss: 1.202, Global test accuracy: 60.27
Round  72, Train loss: 0.330, Test loss: 2.352, Test accuracy: 55.21
Round  72, Global train loss: 0.330, Global test loss: 1.256, Global test accuracy: 56.52
Round  73, Train loss: 0.301, Test loss: 2.317, Test accuracy: 55.40
Round  73, Global train loss: 0.301, Global test loss: 1.258, Global test accuracy: 56.64
Round  74, Train loss: 0.311, Test loss: 2.320, Test accuracy: 55.65
Round  74, Global train loss: 0.311, Global test loss: 1.223, Global test accuracy: 56.89
Round  75, Train loss: 0.263, Test loss: 2.324, Test accuracy: 55.67
Round  75, Global train loss: 0.263, Global test loss: 1.243, Global test accuracy: 56.98
Round  76, Train loss: 0.237, Test loss: 2.350, Test accuracy: 55.74
Round  76, Global train loss: 0.237, Global test loss: 1.217, Global test accuracy: 59.94
Round  77, Train loss: 0.291, Test loss: 2.356, Test accuracy: 55.77
Round  77, Global train loss: 0.291, Global test loss: 1.217, Global test accuracy: 60.02
Round  78, Train loss: 0.291, Test loss: 2.363, Test accuracy: 55.81
Round  78, Global train loss: 0.291, Global test loss: 1.228, Global test accuracy: 58.08
Round  79, Train loss: 0.297, Test loss: 2.382, Test accuracy: 55.63
Round  79, Global train loss: 0.297, Global test loss: 1.206, Global test accuracy: 60.09
Round  80, Train loss: 0.274, Test loss: 2.421, Test accuracy: 55.56
Round  80, Global train loss: 0.274, Global test loss: 1.201, Global test accuracy: 60.02
Round  81, Train loss: 0.279, Test loss: 2.442, Test accuracy: 55.52
Round  81, Global train loss: 0.279, Global test loss: 1.223, Global test accuracy: 57.21
Round  82, Train loss: 0.278, Test loss: 2.432, Test accuracy: 55.76
Round  82, Global train loss: 0.278, Global test loss: 1.239, Global test accuracy: 59.63
Round  83, Train loss: 0.254, Test loss: 2.436, Test accuracy: 55.74
Round  83, Global train loss: 0.254, Global test loss: 1.220, Global test accuracy: 60.24
Round  84, Train loss: 0.273, Test loss: 2.413, Test accuracy: 55.95
Round  84, Global train loss: 0.273, Global test loss: 1.223, Global test accuracy: 58.65
Round  85, Train loss: 0.272, Test loss: 2.447, Test accuracy: 55.54
Round  85, Global train loss: 0.272, Global test loss: 1.213, Global test accuracy: 57.87
Round  86, Train loss: 0.264, Test loss: 2.469, Test accuracy: 55.83
Round  86, Global train loss: 0.264, Global test loss: 1.248, Global test accuracy: 57.04
Round  87, Train loss: 0.259, Test loss: 2.469, Test accuracy: 55.80
Round  87, Global train loss: 0.259, Global test loss: 1.229, Global test accuracy: 58.26
Round  88, Train loss: 0.255, Test loss: 2.491, Test accuracy: 55.95
Round  88, Global train loss: 0.255, Global test loss: 1.265, Global test accuracy: 59.47
Round  89, Train loss: 0.247, Test loss: 2.513, Test accuracy: 55.90
Round  89, Global train loss: 0.247, Global test loss: 1.230, Global test accuracy: 58.44
Round  90, Train loss: 0.260, Test loss: 2.511, Test accuracy: 55.81
Round  90, Global train loss: 0.260, Global test loss: 1.257, Global test accuracy: 56.50
Round  91, Train loss: 0.262, Test loss: 2.483, Test accuracy: 56.02
Round  91, Global train loss: 0.262, Global test loss: 1.240, Global test accuracy: 58.27
Round  92, Train loss: 0.258, Test loss: 2.492, Test accuracy: 56.19
Round  92, Global train loss: 0.258, Global test loss: 1.255, Global test accuracy: 56.35
Round  93, Train loss: 0.249, Test loss: 2.526, Test accuracy: 55.93
Round  93, Global train loss: 0.249, Global test loss: 1.211, Global test accuracy: 58.56
Round  94, Train loss: 0.211, Test loss: 2.571, Test accuracy: 55.73
Round  94, Global train loss: 0.211, Global test loss: 1.232, Global test accuracy: 60.40
Round  95, Train loss: 0.227, Test loss: 2.611, Test accuracy: 55.55
Round  95, Global train loss: 0.227, Global test loss: 1.264, Global test accuracy: 57.64
Round  96, Train loss: 0.232, Test loss: 2.602, Test accuracy: 55.65
Round  96, Global train loss: 0.232, Global test loss: 1.252, Global test accuracy: 57.69
Round  97, Train loss: 0.230, Test loss: 2.608, Test accuracy: 55.76
Round  97, Global train loss: 0.230, Global test loss: 1.254, Global test accuracy: 59.16
Round  98, Train loss: 0.201, Test loss: 2.628, Test accuracy: 55.74
Round  98, Global train loss: 0.201, Global test loss: 1.259, Global test accuracy: 62.36
Round  99, Train loss: 0.237, Test loss: 2.641, Test accuracy: 55.70
Round  99, Global train loss: 0.237, Global test loss: 1.271, Global test accuracy: 56.37
Final Round, Train loss: 0.154, Test loss: 2.852, Test accuracy: 55.72
Final Round, Global train loss: 0.154, Global test loss: 1.271, Global test accuracy: 56.37
Average accuracy final 10 rounds: 55.80799999999999 

Average global accuracy final 10 rounds: 58.33025 

5995.677849531174
[4.135285377502441, 8.270570755004883, 12.276660919189453, 16.282751083374023, 20.313108444213867, 24.34346580505371, 28.368748426437378, 32.394031047821045, 36.427151918411255, 40.460272789001465, 44.4388210773468, 48.41736936569214, 52.419365644454956, 56.42136192321777, 60.4030978679657, 64.38483381271362, 68.77464461326599, 73.16445541381836, 77.56839060783386, 81.97232580184937, 86.15474104881287, 90.33715629577637, 94.31922817230225, 98.30130004882812, 102.25429081916809, 106.20728158950806, 110.23771905899048, 114.2681565284729, 118.30596446990967, 122.34377241134644, 126.42707848548889, 130.51038455963135, 134.5273163318634, 138.54424810409546, 142.5687437057495, 146.59323930740356, 150.6631636619568, 154.73308801651, 158.91238117218018, 163.09167432785034, 167.27047395706177, 171.4492735862732, 175.62069392204285, 179.7921142578125, 184.02417922019958, 188.25624418258667, 192.57125234603882, 196.88626050949097, 201.26741337776184, 205.64856624603271, 210.03559064865112, 214.42261505126953, 218.81582903862, 223.20904302597046, 227.7906665802002, 232.37229013442993, 236.88100266456604, 241.38971519470215, 245.84958171844482, 250.3094482421875, 254.79985451698303, 259.29026079177856, 263.7419762611389, 268.19369173049927, 272.69054770469666, 277.18740367889404, 281.67454528808594, 286.16168689727783, 290.6951313018799, 295.22857570648193, 300.1614408493042, 305.09430599212646, 309.59609270095825, 314.09787940979004, 318.6115050315857, 323.12513065338135, 327.4200406074524, 331.71495056152344, 336.13338971138, 340.5518288612366, 344.94268798828125, 349.3335471153259, 353.85546493530273, 358.37738275527954, 362.9135892391205, 367.4497957229614, 371.9734227657318, 376.4970498085022, 381.03928685188293, 385.5815238952637, 390.05784344673157, 394.53416299819946, 399.0955967903137, 403.657030582428, 408.2357544898987, 412.8144783973694, 417.37640857696533, 421.9383387565613, 426.3840847015381, 430.8298306465149, 435.5406029224396, 440.25137519836426, 444.90231347084045, 449.55325174331665, 454.19670057296753, 458.8401494026184, 463.4782717227936, 468.11639404296875, 472.66572403907776, 477.21505403518677, 481.77518796920776, 486.33532190322876, 490.8782548904419, 495.42118787765503, 499.9226920604706, 504.42419624328613, 508.9565110206604, 513.4888257980347, 517.8463356494904, 522.203845500946, 526.6791577339172, 531.1544699668884, 535.625287771225, 540.0961055755615, 544.97234582901, 549.8485860824585, 554.4502604007721, 559.0519347190857, 563.4938580989838, 567.9357814788818, 572.8375067710876, 577.7392320632935, 582.6380155086517, 587.53679895401, 592.2187423706055, 596.9006857872009, 601.7852187156677, 606.6697516441345, 611.679773569107, 616.6897954940796, 621.6574203968048, 626.62504529953, 631.1897375583649, 635.7544298171997, 640.3177056312561, 644.8809814453125, 649.3011581897736, 653.7213349342346, 658.2313706874847, 662.7414064407349, 667.2905843257904, 671.839762210846, 676.2584037780762, 680.6770453453064, 685.3373515605927, 689.9976577758789, 694.5997409820557, 699.2018241882324, 703.704350233078, 708.2068762779236, 712.8357117176056, 717.4645471572876, 722.0233941078186, 726.5822410583496, 731.1801290512085, 735.7780170440674, 740.1946630477905, 744.6113090515137, 749.2479016780853, 753.884494304657, 758.5472798347473, 763.2100653648376, 767.7958681583405, 772.3816709518433, 777.0061900615692, 781.6307091712952, 786.6969819068909, 791.7632546424866, 796.4232354164124, 801.0832161903381, 805.6376085281372, 810.1920008659363, 814.8340301513672, 819.4760594367981, 824.464376449585, 829.4526934623718, 834.1640481948853, 838.8754029273987, 843.4093444347382, 847.9432859420776, 852.4832248687744, 857.0231637954712, 861.4858648777008, 865.9485659599304, 870.8016777038574, 875.6547894477844, 880.6172020435333, 885.5796146392822, 890.1216592788696, 894.663703918457, 896.9337422847748, 899.2037806510925]
[37.7775, 37.7775, 43.4975, 43.4975, 46.765, 46.765, 47.8625, 47.8625, 47.79, 47.79, 48.8625, 48.8625, 49.5775, 49.5775, 50.265, 50.265, 50.72, 50.72, 51.295, 51.295, 51.7875, 51.7875, 52.1475, 52.1475, 52.1975, 52.1975, 52.435, 52.435, 52.5425, 52.5425, 52.8525, 52.8525, 52.925, 52.925, 53.05, 53.05, 54.075, 54.075, 54.2375, 54.2375, 53.815, 53.815, 54.03, 54.03, 54.3325, 54.3325, 54.3375, 54.3375, 54.425, 54.425, 54.5125, 54.5125, 54.8075, 54.8075, 54.7675, 54.7675, 54.6575, 54.6575, 54.6475, 54.6475, 54.83, 54.83, 54.8525, 54.8525, 55.06, 55.06, 55.16, 55.16, 55.09, 55.09, 55.265, 55.265, 55.325, 55.325, 55.2975, 55.2975, 55.2875, 55.2875, 55.26, 55.26, 55.305, 55.305, 55.0875, 55.0875, 55.415, 55.415, 55.525, 55.525, 55.2125, 55.2125, 55.555, 55.555, 55.3725, 55.3725, 55.545, 55.545, 55.6275, 55.6275, 55.81, 55.81, 55.5675, 55.5675, 55.4, 55.4, 55.3725, 55.3725, 55.5425, 55.5425, 55.8175, 55.8175, 55.9375, 55.9375, 55.9275, 55.9275, 55.815, 55.815, 56.0725, 56.0725, 55.7325, 55.7325, 55.9475, 55.9475, 55.6575, 55.6575, 55.7925, 55.7925, 55.6125, 55.6125, 55.8725, 55.8725, 55.4875, 55.4875, 55.53, 55.53, 55.1675, 55.1675, 55.375, 55.375, 55.855, 55.855, 55.4025, 55.4025, 55.4025, 55.4025, 55.2125, 55.2125, 55.395, 55.395, 55.6475, 55.6475, 55.6725, 55.6725, 55.74, 55.74, 55.765, 55.765, 55.8075, 55.8075, 55.63, 55.63, 55.5625, 55.5625, 55.5225, 55.5225, 55.7625, 55.7625, 55.7425, 55.7425, 55.955, 55.955, 55.5375, 55.5375, 55.8325, 55.8325, 55.805, 55.805, 55.95, 55.95, 55.8975, 55.8975, 55.8125, 55.8125, 56.0175, 56.0175, 56.1925, 56.1925, 55.9325, 55.9325, 55.725, 55.725, 55.5475, 55.5475, 55.6475, 55.6475, 55.76, 55.76, 55.745, 55.745, 55.7, 55.7, 55.715, 55.715]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.985, Test loss: 1.720, Test accuracy: 37.37
Round   0, Global train loss: 1.985, Global test loss: 1.710, Global test accuracy: 38.26
Round   1, Train loss: 1.678, Test loss: 1.525, Test accuracy: 44.84
Round   1, Global train loss: 1.678, Global test loss: 1.468, Global test accuracy: 47.49
Round   2, Train loss: 1.534, Test loss: 1.437, Test accuracy: 48.23
Round   2, Global train loss: 1.534, Global test loss: 1.346, Global test accuracy: 51.78
Round   3, Train loss: 1.447, Test loss: 1.389, Test accuracy: 50.03
Round   3, Global train loss: 1.447, Global test loss: 1.254, Global test accuracy: 55.16
Round   4, Train loss: 1.349, Test loss: 1.334, Test accuracy: 52.05
Round   4, Global train loss: 1.349, Global test loss: 1.170, Global test accuracy: 58.69
Round   5, Train loss: 1.264, Test loss: 1.319, Test accuracy: 52.96
Round   5, Global train loss: 1.264, Global test loss: 1.118, Global test accuracy: 60.82
Round   6, Train loss: 1.209, Test loss: 1.305, Test accuracy: 53.75
Round   6, Global train loss: 1.209, Global test loss: 1.055, Global test accuracy: 62.83
Round   7, Train loss: 1.156, Test loss: 1.254, Test accuracy: 55.66
Round   7, Global train loss: 1.156, Global test loss: 1.009, Global test accuracy: 64.66
Round   8, Train loss: 1.115, Test loss: 1.227, Test accuracy: 56.62
Round   8, Global train loss: 1.115, Global test loss: 0.975, Global test accuracy: 65.88
Round   9, Train loss: 1.053, Test loss: 1.210, Test accuracy: 57.45
Round   9, Global train loss: 1.053, Global test loss: 0.945, Global test accuracy: 67.30
Round  10, Train loss: 1.032, Test loss: 1.181, Test accuracy: 58.84
Round  10, Global train loss: 1.032, Global test loss: 0.918, Global test accuracy: 68.39
Round  11, Train loss: 0.978, Test loss: 1.146, Test accuracy: 60.60
Round  11, Global train loss: 0.978, Global test loss: 0.899, Global test accuracy: 69.27
Round  12, Train loss: 0.967, Test loss: 1.118, Test accuracy: 61.83
Round  12, Global train loss: 0.967, Global test loss: 0.876, Global test accuracy: 69.80
Round  13, Train loss: 0.919, Test loss: 1.108, Test accuracy: 62.33
Round  13, Global train loss: 0.919, Global test loss: 0.851, Global test accuracy: 70.43
Round  14, Train loss: 0.894, Test loss: 1.060, Test accuracy: 63.89
Round  14, Global train loss: 0.894, Global test loss: 0.837, Global test accuracy: 70.95
Round  15, Train loss: 0.868, Test loss: 1.041, Test accuracy: 64.66
Round  15, Global train loss: 0.868, Global test loss: 0.820, Global test accuracy: 71.87
Round  16, Train loss: 0.862, Test loss: 1.042, Test accuracy: 64.85
Round  16, Global train loss: 0.862, Global test loss: 0.814, Global test accuracy: 72.01
Round  17, Train loss: 0.823, Test loss: 1.026, Test accuracy: 65.55
Round  17, Global train loss: 0.823, Global test loss: 0.807, Global test accuracy: 72.76
Round  18, Train loss: 0.816, Test loss: 1.018, Test accuracy: 65.92
Round  18, Global train loss: 0.816, Global test loss: 0.799, Global test accuracy: 72.33
Round  19, Train loss: 0.786, Test loss: 1.006, Test accuracy: 66.52
Round  19, Global train loss: 0.786, Global test loss: 0.787, Global test accuracy: 73.36
Round  20, Train loss: 0.766, Test loss: 1.000, Test accuracy: 66.89
Round  20, Global train loss: 0.766, Global test loss: 0.766, Global test accuracy: 73.97
Round  21, Train loss: 0.755, Test loss: 0.985, Test accuracy: 67.35
Round  21, Global train loss: 0.755, Global test loss: 0.762, Global test accuracy: 74.03
Round  22, Train loss: 0.737, Test loss: 0.973, Test accuracy: 67.61
Round  22, Global train loss: 0.737, Global test loss: 0.759, Global test accuracy: 74.54
Round  23, Train loss: 0.734, Test loss: 0.971, Test accuracy: 67.83
Round  23, Global train loss: 0.734, Global test loss: 0.763, Global test accuracy: 74.06
Round  24, Train loss: 0.719, Test loss: 0.959, Test accuracy: 68.36
Round  24, Global train loss: 0.719, Global test loss: 0.752, Global test accuracy: 75.00
Round  25, Train loss: 0.714, Test loss: 0.953, Test accuracy: 68.85
Round  25, Global train loss: 0.714, Global test loss: 0.742, Global test accuracy: 75.01
Round  26, Train loss: 0.703, Test loss: 0.960, Test accuracy: 68.86
Round  26, Global train loss: 0.703, Global test loss: 0.739, Global test accuracy: 75.14
Round  27, Train loss: 0.669, Test loss: 0.962, Test accuracy: 68.81
Round  27, Global train loss: 0.669, Global test loss: 0.737, Global test accuracy: 74.86
Round  28, Train loss: 0.675, Test loss: 0.961, Test accuracy: 69.16
Round  28, Global train loss: 0.675, Global test loss: 0.727, Global test accuracy: 75.50
Round  29, Train loss: 0.655, Test loss: 0.958, Test accuracy: 69.31
Round  29, Global train loss: 0.655, Global test loss: 0.733, Global test accuracy: 75.31
Round  30, Train loss: 0.656, Test loss: 0.956, Test accuracy: 69.25
Round  30, Global train loss: 0.656, Global test loss: 0.722, Global test accuracy: 75.37
Round  31, Train loss: 0.644, Test loss: 0.941, Test accuracy: 69.88
Round  31, Global train loss: 0.644, Global test loss: 0.732, Global test accuracy: 75.57
Round  32, Train loss: 0.624, Test loss: 0.950, Test accuracy: 69.77
Round  32, Global train loss: 0.624, Global test loss: 0.725, Global test accuracy: 75.63
Round  33, Train loss: 0.630, Test loss: 0.952, Test accuracy: 69.90
Round  33, Global train loss: 0.630, Global test loss: 0.721, Global test accuracy: 75.83
Round  34, Train loss: 0.613, Test loss: 0.943, Test accuracy: 70.26
Round  34, Global train loss: 0.613, Global test loss: 0.722, Global test accuracy: 75.81
Round  35, Train loss: 0.599, Test loss: 0.940, Test accuracy: 70.43
Round  35, Global train loss: 0.599, Global test loss: 0.727, Global test accuracy: 75.86
Round  36, Train loss: 0.606, Test loss: 0.942, Test accuracy: 70.56
Round  36, Global train loss: 0.606, Global test loss: 0.715, Global test accuracy: 76.42
Round  37, Train loss: 0.599, Test loss: 0.938, Test accuracy: 70.79
Round  37, Global train loss: 0.599, Global test loss: 0.718, Global test accuracy: 76.23
Round  38, Train loss: 0.600, Test loss: 0.936, Test accuracy: 70.91
Round  38, Global train loss: 0.600, Global test loss: 0.713, Global test accuracy: 76.46
Round  39, Train loss: 0.590, Test loss: 0.945, Test accuracy: 70.86
Round  39, Global train loss: 0.590, Global test loss: 0.724, Global test accuracy: 76.38
Round  40, Train loss: 0.583, Test loss: 0.949, Test accuracy: 70.90
Round  40, Global train loss: 0.583, Global test loss: 0.710, Global test accuracy: 76.85
Round  41, Train loss: 0.561, Test loss: 0.943, Test accuracy: 71.14
Round  41, Global train loss: 0.561, Global test loss: 0.709, Global test accuracy: 77.14
Round  42, Train loss: 0.576, Test loss: 0.939, Test accuracy: 71.23
Round  42, Global train loss: 0.576, Global test loss: 0.702, Global test accuracy: 77.20
Round  43, Train loss: 0.579, Test loss: 0.936, Test accuracy: 71.39
Round  43, Global train loss: 0.579, Global test loss: 0.702, Global test accuracy: 76.91
Round  44, Train loss: 0.541, Test loss: 0.939, Test accuracy: 71.20
Round  44, Global train loss: 0.541, Global test loss: 0.713, Global test accuracy: 76.83
Round  45, Train loss: 0.560, Test loss: 0.926, Test accuracy: 71.52
Round  45, Global train loss: 0.560, Global test loss: 0.708, Global test accuracy: 76.81
Round  46, Train loss: 0.549, Test loss: 0.926, Test accuracy: 71.52
Round  46, Global train loss: 0.549, Global test loss: 0.709, Global test accuracy: 77.05
Round  47, Train loss: 0.548, Test loss: 0.923, Test accuracy: 71.64
Round  47, Global train loss: 0.548, Global test loss: 0.705, Global test accuracy: 77.30
Round  48, Train loss: 0.557, Test loss: 0.922, Test accuracy: 71.73
Round  48, Global train loss: 0.557, Global test loss: 0.702, Global test accuracy: 77.28
Round  49, Train loss: 0.518, Test loss: 0.922, Test accuracy: 71.98
Round  49, Global train loss: 0.518, Global test loss: 0.715, Global test accuracy: 77.05
Round  50, Train loss: 0.550, Test loss: 0.924, Test accuracy: 72.18
Round  50, Global train loss: 0.550, Global test loss: 0.709, Global test accuracy: 77.18
Round  51, Train loss: 0.530, Test loss: 0.931, Test accuracy: 72.12
Round  51, Global train loss: 0.530, Global test loss: 0.711, Global test accuracy: 76.75
Round  52, Train loss: 0.540, Test loss: 0.929, Test accuracy: 72.14
Round  52, Global train loss: 0.540, Global test loss: 0.699, Global test accuracy: 77.09
Round  53, Train loss: 0.511, Test loss: 0.933, Test accuracy: 72.21
Round  53, Global train loss: 0.511, Global test loss: 0.712, Global test accuracy: 76.90
Round  54, Train loss: 0.522, Test loss: 0.934, Test accuracy: 72.31
Round  54, Global train loss: 0.522, Global test loss: 0.706, Global test accuracy: 77.37
Round  55, Train loss: 0.509, Test loss: 0.929, Test accuracy: 72.33
Round  55, Global train loss: 0.509, Global test loss: 0.715, Global test accuracy: 77.41
Round  56, Train loss: 0.518, Test loss: 0.924, Test accuracy: 72.31
Round  56, Global train loss: 0.518, Global test loss: 0.703, Global test accuracy: 77.33
Round  57, Train loss: 0.485, Test loss: 0.922, Test accuracy: 72.37
Round  57, Global train loss: 0.485, Global test loss: 0.714, Global test accuracy: 77.57
Round  58, Train loss: 0.507, Test loss: 0.918, Test accuracy: 72.47
Round  58, Global train loss: 0.507, Global test loss: 0.710, Global test accuracy: 77.35
Round  59, Train loss: 0.484, Test loss: 0.925, Test accuracy: 72.64
Round  59, Global train loss: 0.484, Global test loss: 0.707, Global test accuracy: 77.57
Round  60, Train loss: 0.478, Test loss: 0.928, Test accuracy: 72.84
Round  60, Global train loss: 0.478, Global test loss: 0.714, Global test accuracy: 77.40
Round  61, Train loss: 0.463, Test loss: 0.935, Test accuracy: 72.61
Round  61, Global train loss: 0.463, Global test loss: 0.726, Global test accuracy: 77.27
Round  62, Train loss: 0.473, Test loss: 0.946, Test accuracy: 72.48
Round  62, Global train loss: 0.473, Global test loss: 0.724, Global test accuracy: 77.57
Round  63, Train loss: 0.499, Test loss: 0.936, Test accuracy: 72.59
Round  63, Global train loss: 0.499, Global test loss: 0.712, Global test accuracy: 77.40
Round  64, Train loss: 0.465, Test loss: 0.933, Test accuracy: 72.78
Round  64, Global train loss: 0.465, Global test loss: 0.725, Global test accuracy: 77.19
Round  65, Train loss: 0.451, Test loss: 0.937, Test accuracy: 72.54
Round  65, Global train loss: 0.451, Global test loss: 0.728, Global test accuracy: 77.20
Round  66, Train loss: 0.455, Test loss: 0.939, Test accuracy: 72.64
Round  66, Global train loss: 0.455, Global test loss: 0.733, Global test accuracy: 77.53
Round  67, Train loss: 0.516, Test loss: 0.937, Test accuracy: 72.71
Round  67, Global train loss: 0.516, Global test loss: 0.704, Global test accuracy: 77.77
Round  68, Train loss: 0.452, Test loss: 0.944, Test accuracy: 72.64
Round  68, Global train loss: 0.452, Global test loss: 0.714, Global test accuracy: 77.57
Round  69, Train loss: 0.472, Test loss: 0.947, Test accuracy: 72.67
Round  69, Global train loss: 0.472, Global test loss: 0.713, Global test accuracy: 77.76
Round  70, Train loss: 0.478, Test loss: 0.939, Test accuracy: 72.84
Round  70, Global train loss: 0.478, Global test loss: 0.698, Global test accuracy: 77.75
Round  71, Train loss: 0.462, Test loss: 0.938, Test accuracy: 72.90
Round  71, Global train loss: 0.462, Global test loss: 0.713, Global test accuracy: 77.48
Round  72, Train loss: 0.449, Test loss: 0.933, Test accuracy: 73.14
Round  72, Global train loss: 0.449, Global test loss: 0.736, Global test accuracy: 77.30
Round  73, Train loss: 0.456, Test loss: 0.937, Test accuracy: 73.12
Round  73, Global train loss: 0.456, Global test loss: 0.710, Global test accuracy: 77.55
Round  74, Train loss: 0.437, Test loss: 0.939, Test accuracy: 73.35
Round  74, Global train loss: 0.437, Global test loss: 0.720, Global test accuracy: 77.75
Round  75, Train loss: 0.436, Test loss: 0.930, Test accuracy: 73.38
Round  75, Global train loss: 0.436, Global test loss: 0.723, Global test accuracy: 77.55
Round  76, Train loss: 0.450, Test loss: 0.921, Test accuracy: 73.52
Round  76, Global train loss: 0.450, Global test loss: 0.711, Global test accuracy: 77.64
Round  77, Train loss: 0.437, Test loss: 0.927, Test accuracy: 73.36
Round  77, Global train loss: 0.437, Global test loss: 0.715, Global test accuracy: 77.86
Round  78, Train loss: 0.447, Test loss: 0.930, Test accuracy: 73.30
Round  78, Global train loss: 0.447, Global test loss: 0.711, Global test accuracy: 78.03
Round  79, Train loss: 0.429, Test loss: 0.931, Test accuracy: 73.22
Round  79, Global train loss: 0.429, Global test loss: 0.729, Global test accuracy: 77.32
Round  80, Train loss: 0.434, Test loss: 0.929, Test accuracy: 73.33
Round  80, Global train loss: 0.434, Global test loss: 0.715, Global test accuracy: 77.51
Round  81, Train loss: 0.431, Test loss: 0.934, Test accuracy: 73.33
Round  81, Global train loss: 0.431, Global test loss: 0.707, Global test accuracy: 77.97
Round  82, Train loss: 0.468, Test loss: 0.938, Test accuracy: 73.36
Round  82, Global train loss: 0.468, Global test loss: 0.713, Global test accuracy: 78.14
Round  83, Train loss: 0.434, Test loss: 0.945, Test accuracy: 73.24
Round  83, Global train loss: 0.434, Global test loss: 0.727, Global test accuracy: 77.90
Round  84, Train loss: 0.435, Test loss: 0.941, Test accuracy: 73.36
Round  84, Global train loss: 0.435, Global test loss: 0.717, Global test accuracy: 77.87
Round  85, Train loss: 0.451, Test loss: 0.939, Test accuracy: 73.35
Round  85, Global train loss: 0.451, Global test loss: 0.707, Global test accuracy: 78.36
Round  86, Train loss: 0.424, Test loss: 0.936, Test accuracy: 73.42
Round  86, Global train loss: 0.424, Global test loss: 0.712, Global test accuracy: 78.07
Round  87, Train loss: 0.411, Test loss: 0.933, Test accuracy: 73.56
Round  87, Global train loss: 0.411, Global test loss: 0.711, Global test accuracy: 78.50
Round  88, Train loss: 0.395, Test loss: 0.936, Test accuracy: 73.58
Round  88, Global train loss: 0.395, Global test loss: 0.731, Global test accuracy: 78.09
Round  89, Train loss: 0.383, Test loss: 0.949, Test accuracy: 73.36
Round  89, Global train loss: 0.383, Global test loss: 0.751, Global test accuracy: 77.44
Round  90, Train loss: 0.428, Test loss: 0.953, Test accuracy: 73.31
Round  90, Global train loss: 0.428, Global test loss: 0.722, Global test accuracy: 78.14
Round  91, Train loss: 0.412, Test loss: 0.961, Test accuracy: 73.44
Round  91, Global train loss: 0.412, Global test loss: 0.739, Global test accuracy: 78.29
Round  92, Train loss: 0.415, Test loss: 0.960, Test accuracy: 73.51
Round  92, Global train loss: 0.415, Global test loss: 0.735, Global test accuracy: 78.51
Round  93, Train loss: 0.394, Test loss: 0.953, Test accuracy: 73.63
Round  93, Global train loss: 0.394, Global test loss: 0.736, Global test accuracy: 78.35
Round  94, Train loss: 0.440, Test loss: 0.955, Test accuracy: 73.57
Round  94, Global train loss: 0.440, Global test loss: 0.715, Global test accuracy: 78.31
Round  95, Train loss: 0.416, Test loss: 0.956, Test accuracy: 73.58
Round  95, Global train loss: 0.416, Global test loss: 0.711, Global test accuracy: 78.64
Round  96, Train loss: 0.431, Test loss: 0.950, Test accuracy: 73.75
Round  96, Global train loss: 0.431, Global test loss: 0.717, Global test accuracy: 78.70
Round  97, Train loss: 0.388, Test loss: 0.953, Test accuracy: 73.86
Round  97, Global train loss: 0.388, Global test loss: 0.715, Global test accuracy: 78.81
Round  98, Train loss: 0.399, Test loss: 0.955, Test accuracy: 73.72
Round  98, Global train loss: 0.399, Global test loss: 0.718, Global test accuracy: 78.39
Round  99, Train loss: 0.385, Test loss: 0.959, Test accuracy: 73.82
Round  99, Global train loss: 0.385, Global test loss: 0.722, Global test accuracy: 78.72
Final Round, Train loss: 0.238, Test loss: 1.034, Test accuracy: 74.89
Final Round, Global train loss: 0.238, Global test loss: 0.722, Global test accuracy: 78.72
Average accuracy final 10 rounds: 73.61800000000001 

Average global accuracy final 10 rounds: 78.488 

6841.469348192215
[4.890831708908081, 9.781663417816162, 14.501786708831787, 19.221909999847412, 23.95561194419861, 28.689313888549805, 33.51428818702698, 38.33926248550415, 43.54002046585083, 48.74077844619751, 53.78035831451416, 58.81993818283081, 63.59313201904297, 68.36632585525513, 73.21418190002441, 78.0620379447937, 82.90433979034424, 87.74664163589478, 92.56364870071411, 97.38065576553345, 102.21705341339111, 107.05345106124878, 111.85258054733276, 116.65171003341675, 121.42409944534302, 126.19648885726929, 130.89701652526855, 135.59754419326782, 140.27564430236816, 144.9537444114685, 150.16143822669983, 155.36913204193115, 160.30890083312988, 165.2486696243286, 170.0132613182068, 174.77785301208496, 179.83786582946777, 184.8978786468506, 189.6446533203125, 194.3914279937744, 199.14665627479553, 203.90188455581665, 208.65996479988098, 213.4180450439453, 218.20174288749695, 222.98544073104858, 228.01551342010498, 233.04558610916138, 238.01771712303162, 242.98984813690186, 248.0491669178009, 253.10848569869995, 258.1662893295288, 263.22409296035767, 267.9761583805084, 272.7282238006592, 277.5229105949402, 282.3175973892212, 287.0795021057129, 291.8414068222046, 296.6036398410797, 301.36587285995483, 306.22212767601013, 311.07838249206543, 316.2564465999603, 321.4345107078552, 326.5908131599426, 331.74711561203003, 336.8310890197754, 341.91506242752075, 346.7015414237976, 351.48802042007446, 356.29022312164307, 361.09242582321167, 365.87794852256775, 370.6634712219238, 375.52315044403076, 380.3828296661377, 385.1545729637146, 389.9263162612915, 394.79682302474976, 399.667329788208, 404.5335659980774, 409.3998022079468, 414.2278060913086, 419.0558099746704, 423.8605046272278, 428.66519927978516, 433.4715986251831, 438.27799797058105, 443.0680570602417, 447.85811614990234, 452.67409014701843, 457.4900641441345, 462.3249876499176, 467.1599111557007, 471.9335677623749, 476.7072243690491, 481.419899225235, 486.1325740814209, 490.90953946113586, 495.68650484085083, 500.44477009773254, 505.20303535461426, 509.986941576004, 514.7708477973938, 519.9349489212036, 525.0990500450134, 529.8512101173401, 534.6033701896667, 539.3329975605011, 544.0626249313354, 548.8621847629547, 553.661744594574, 558.4066524505615, 563.1515603065491, 567.988067150116, 572.8245739936829, 577.6581408977509, 582.4917078018188, 587.2282521724701, 591.9647965431213, 596.7943961620331, 601.6239957809448, 606.4913721084595, 611.3587484359741, 616.183678150177, 621.0086078643799, 625.7917563915253, 630.5749049186707, 635.3475675582886, 640.1202301979065, 644.9410102367401, 649.7617902755737, 654.5876324176788, 659.4134745597839, 664.2967050075531, 669.1799354553223, 674.1587941646576, 679.1376528739929, 684.1227254867554, 689.1077980995178, 693.9544208049774, 698.801043510437, 703.5759220123291, 708.3508005142212, 713.0983448028564, 717.8458890914917, 722.9057013988495, 727.9655137062073, 732.8183608055115, 737.6712079048157, 742.7591888904572, 747.8471698760986, 753.0491766929626, 758.2511835098267, 763.2084305286407, 768.1656775474548, 773.1609551906586, 778.1562328338623, 783.3386833667755, 788.5211338996887, 793.6579036712646, 798.7946734428406, 803.6810235977173, 808.567373752594, 813.4438421726227, 818.3203105926514, 823.0990397930145, 827.8777689933777, 832.59983253479, 837.3218960762024, 841.9238684177399, 846.5258407592773, 851.3108956813812, 856.0959506034851, 860.8862860202789, 865.6766214370728, 870.3187494277954, 874.9608774185181, 879.7013087272644, 884.4417400360107, 889.0630829334259, 893.6844258308411, 898.1420121192932, 902.5995984077454, 907.1637170314789, 911.7278356552124, 916.4696514606476, 921.2114672660828, 925.7320642471313, 930.2526612281799, 934.7851331233978, 939.3176050186157, 943.8450846672058, 948.3725643157959, 952.8749213218689, 957.3772783279419, 961.8894550800323, 966.4016318321228, 968.6848068237305, 970.9679818153381]
[37.3725, 37.3725, 44.8425, 44.8425, 48.225, 48.225, 50.03, 50.03, 52.0525, 52.0525, 52.9575, 52.9575, 53.75, 53.75, 55.6625, 55.6625, 56.625, 56.625, 57.455, 57.455, 58.835, 58.835, 60.605, 60.605, 61.83, 61.83, 62.3275, 62.3275, 63.89, 63.89, 64.6625, 64.6625, 64.85, 64.85, 65.545, 65.545, 65.9225, 65.9225, 66.5225, 66.5225, 66.8875, 66.8875, 67.35, 67.35, 67.61, 67.61, 67.835, 67.835, 68.355, 68.355, 68.8525, 68.8525, 68.8575, 68.8575, 68.81, 68.81, 69.1625, 69.1625, 69.3125, 69.3125, 69.2475, 69.2475, 69.875, 69.875, 69.7725, 69.7725, 69.9, 69.9, 70.2575, 70.2575, 70.4325, 70.4325, 70.555, 70.555, 70.79, 70.79, 70.91, 70.91, 70.8625, 70.8625, 70.8975, 70.8975, 71.1375, 71.1375, 71.23, 71.23, 71.395, 71.395, 71.205, 71.205, 71.52, 71.52, 71.5225, 71.5225, 71.635, 71.635, 71.7275, 71.7275, 71.985, 71.985, 72.18, 72.18, 72.12, 72.12, 72.1375, 72.1375, 72.2125, 72.2125, 72.3125, 72.3125, 72.33, 72.33, 72.3075, 72.3075, 72.3725, 72.3725, 72.47, 72.47, 72.645, 72.645, 72.84, 72.84, 72.61, 72.61, 72.4825, 72.4825, 72.59, 72.59, 72.7775, 72.7775, 72.54, 72.54, 72.645, 72.645, 72.7075, 72.7075, 72.6425, 72.6425, 72.6725, 72.6725, 72.8425, 72.8425, 72.9025, 72.9025, 73.14, 73.14, 73.12, 73.12, 73.3475, 73.3475, 73.3775, 73.3775, 73.5175, 73.5175, 73.36, 73.36, 73.295, 73.295, 73.2225, 73.2225, 73.325, 73.325, 73.33, 73.33, 73.355, 73.355, 73.2375, 73.2375, 73.365, 73.365, 73.3475, 73.3475, 73.425, 73.425, 73.56, 73.56, 73.585, 73.585, 73.3625, 73.3625, 73.3075, 73.3075, 73.4375, 73.4375, 73.5125, 73.5125, 73.63, 73.63, 73.57, 73.57, 73.575, 73.575, 73.7475, 73.7475, 73.855, 73.855, 73.725, 73.725, 73.82, 73.82, 74.885, 74.885]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.061, Test loss: 1.851, Test accuracy: 35.29
Round   0, Global train loss: 2.061, Global test loss: 1.847, Global test accuracy: 36.61
Round   1, Train loss: 1.810, Test loss: 1.682, Test accuracy: 38.81
Round   1, Global train loss: 1.810, Global test loss: 1.614, Global test accuracy: 41.23
Round   2, Train loss: 1.685, Test loss: 1.616, Test accuracy: 40.80
Round   2, Global train loss: 1.685, Global test loss: 1.497, Global test accuracy: 45.80
Round   3, Train loss: 1.613, Test loss: 1.562, Test accuracy: 42.89
Round   3, Global train loss: 1.613, Global test loss: 1.439, Global test accuracy: 48.42
Round   4, Train loss: 1.543, Test loss: 1.524, Test accuracy: 44.44
Round   4, Global train loss: 1.543, Global test loss: 1.347, Global test accuracy: 52.67
Round   5, Train loss: 1.487, Test loss: 1.504, Test accuracy: 45.08
Round   5, Global train loss: 1.487, Global test loss: 1.293, Global test accuracy: 53.92
Round   6, Train loss: 1.442, Test loss: 1.474, Test accuracy: 46.09
Round   6, Global train loss: 1.442, Global test loss: 1.241, Global test accuracy: 56.54
Round   7, Train loss: 1.377, Test loss: 1.416, Test accuracy: 48.45
Round   7, Global train loss: 1.377, Global test loss: 1.196, Global test accuracy: 57.87
Round   8, Train loss: 1.335, Test loss: 1.396, Test accuracy: 49.27
Round   8, Global train loss: 1.335, Global test loss: 1.163, Global test accuracy: 58.78
Round   9, Train loss: 1.310, Test loss: 1.377, Test accuracy: 50.05
Round   9, Global train loss: 1.310, Global test loss: 1.133, Global test accuracy: 60.42
Round  10, Train loss: 1.273, Test loss: 1.351, Test accuracy: 51.14
Round  10, Global train loss: 1.273, Global test loss: 1.112, Global test accuracy: 61.12
Round  11, Train loss: 1.250, Test loss: 1.292, Test accuracy: 53.73
Round  11, Global train loss: 1.250, Global test loss: 1.075, Global test accuracy: 62.65
Round  12, Train loss: 1.207, Test loss: 1.244, Test accuracy: 55.63
Round  12, Global train loss: 1.207, Global test loss: 1.056, Global test accuracy: 63.59
Round  13, Train loss: 1.191, Test loss: 1.234, Test accuracy: 56.00
Round  13, Global train loss: 1.191, Global test loss: 1.035, Global test accuracy: 64.27
Round  14, Train loss: 1.143, Test loss: 1.203, Test accuracy: 57.52
Round  14, Global train loss: 1.143, Global test loss: 1.016, Global test accuracy: 64.11
Round  15, Train loss: 1.140, Test loss: 1.177, Test accuracy: 58.31
Round  15, Global train loss: 1.140, Global test loss: 0.995, Global test accuracy: 65.04
Round  16, Train loss: 1.118, Test loss: 1.177, Test accuracy: 58.33
Round  16, Global train loss: 1.118, Global test loss: 0.975, Global test accuracy: 66.21
Round  17, Train loss: 1.085, Test loss: 1.147, Test accuracy: 59.47
Round  17, Global train loss: 1.085, Global test loss: 0.956, Global test accuracy: 67.08
Round  18, Train loss: 1.055, Test loss: 1.141, Test accuracy: 59.67
Round  18, Global train loss: 1.055, Global test loss: 0.937, Global test accuracy: 67.86
Round  19, Train loss: 1.071, Test loss: 1.122, Test accuracy: 60.52
Round  19, Global train loss: 1.071, Global test loss: 0.927, Global test accuracy: 68.17
Round  20, Train loss: 1.028, Test loss: 1.108, Test accuracy: 61.15
Round  20, Global train loss: 1.028, Global test loss: 0.918, Global test accuracy: 68.04
Round  21, Train loss: 1.017, Test loss: 1.104, Test accuracy: 61.44
Round  21, Global train loss: 1.017, Global test loss: 0.905, Global test accuracy: 69.03
Round  22, Train loss: 0.995, Test loss: 1.079, Test accuracy: 62.45
Round  22, Global train loss: 0.995, Global test loss: 0.896, Global test accuracy: 69.57
Round  23, Train loss: 0.981, Test loss: 1.051, Test accuracy: 63.60
Round  23, Global train loss: 0.981, Global test loss: 0.875, Global test accuracy: 70.34
Round  24, Train loss: 0.969, Test loss: 1.041, Test accuracy: 64.06
Round  24, Global train loss: 0.969, Global test loss: 0.873, Global test accuracy: 70.16
Round  25, Train loss: 0.961, Test loss: 1.024, Test accuracy: 64.63
Round  25, Global train loss: 0.961, Global test loss: 0.857, Global test accuracy: 70.69
Round  26, Train loss: 0.948, Test loss: 1.012, Test accuracy: 65.15
Round  26, Global train loss: 0.948, Global test loss: 0.858, Global test accuracy: 70.79
Round  27, Train loss: 0.932, Test loss: 1.004, Test accuracy: 65.41
Round  27, Global train loss: 0.932, Global test loss: 0.846, Global test accuracy: 71.13
Round  28, Train loss: 0.902, Test loss: 1.001, Test accuracy: 65.47
Round  28, Global train loss: 0.902, Global test loss: 0.841, Global test accuracy: 71.23
Round  29, Train loss: 0.891, Test loss: 1.003, Test accuracy: 65.36
Round  29, Global train loss: 0.891, Global test loss: 0.844, Global test accuracy: 71.27
Round  30, Train loss: 0.872, Test loss: 1.005, Test accuracy: 65.30
Round  30, Global train loss: 0.872, Global test loss: 0.837, Global test accuracy: 71.13
Round  31, Train loss: 0.869, Test loss: 1.010, Test accuracy: 65.34
Round  31, Global train loss: 0.869, Global test loss: 0.819, Global test accuracy: 71.86
Round  32, Train loss: 0.895, Test loss: 0.979, Test accuracy: 66.47
Round  32, Global train loss: 0.895, Global test loss: 0.814, Global test accuracy: 72.14
Round  33, Train loss: 0.856, Test loss: 0.973, Test accuracy: 66.71
Round  33, Global train loss: 0.856, Global test loss: 0.805, Global test accuracy: 72.69
Round  34, Train loss: 0.861, Test loss: 0.969, Test accuracy: 67.19
Round  34, Global train loss: 0.861, Global test loss: 0.808, Global test accuracy: 73.01
Round  35, Train loss: 0.846, Test loss: 0.966, Test accuracy: 67.27
Round  35, Global train loss: 0.846, Global test loss: 0.793, Global test accuracy: 73.11
Round  36, Train loss: 0.830, Test loss: 0.955, Test accuracy: 67.56
Round  36, Global train loss: 0.830, Global test loss: 0.784, Global test accuracy: 72.85
Round  37, Train loss: 0.813, Test loss: 0.947, Test accuracy: 67.81
Round  37, Global train loss: 0.813, Global test loss: 0.794, Global test accuracy: 72.90
Round  38, Train loss: 0.814, Test loss: 0.952, Test accuracy: 67.69
Round  38, Global train loss: 0.814, Global test loss: 0.796, Global test accuracy: 72.95
Round  39, Train loss: 0.801, Test loss: 0.936, Test accuracy: 68.25
Round  39, Global train loss: 0.801, Global test loss: 0.780, Global test accuracy: 73.36
Round  40, Train loss: 0.795, Test loss: 0.946, Test accuracy: 67.93
Round  40, Global train loss: 0.795, Global test loss: 0.781, Global test accuracy: 73.42
Round  41, Train loss: 0.791, Test loss: 0.938, Test accuracy: 68.32
Round  41, Global train loss: 0.791, Global test loss: 0.773, Global test accuracy: 73.83
Round  42, Train loss: 0.790, Test loss: 0.929, Test accuracy: 68.54
Round  42, Global train loss: 0.790, Global test loss: 0.773, Global test accuracy: 73.75
Round  43, Train loss: 0.781, Test loss: 0.926, Test accuracy: 68.59
Round  43, Global train loss: 0.781, Global test loss: 0.757, Global test accuracy: 74.09
Round  44, Train loss: 0.776, Test loss: 0.923, Test accuracy: 68.72
Round  44, Global train loss: 0.776, Global test loss: 0.766, Global test accuracy: 73.95
Round  45, Train loss: 0.767, Test loss: 0.925, Test accuracy: 68.54
Round  45, Global train loss: 0.767, Global test loss: 0.758, Global test accuracy: 74.18
Round  46, Train loss: 0.746, Test loss: 0.915, Test accuracy: 68.96
Round  46, Global train loss: 0.746, Global test loss: 0.756, Global test accuracy: 74.62
Round  47, Train loss: 0.739, Test loss: 0.907, Test accuracy: 69.19
Round  47, Global train loss: 0.739, Global test loss: 0.750, Global test accuracy: 74.27
Round  48, Train loss: 0.752, Test loss: 0.910, Test accuracy: 69.42
Round  48, Global train loss: 0.752, Global test loss: 0.761, Global test accuracy: 74.48
Round  49, Train loss: 0.746, Test loss: 0.896, Test accuracy: 69.99
Round  49, Global train loss: 0.746, Global test loss: 0.748, Global test accuracy: 74.69
Round  50, Train loss: 0.740, Test loss: 0.894, Test accuracy: 70.08
Round  50, Global train loss: 0.740, Global test loss: 0.742, Global test accuracy: 74.64
Round  51, Train loss: 0.725, Test loss: 0.898, Test accuracy: 70.12
Round  51, Global train loss: 0.725, Global test loss: 0.750, Global test accuracy: 74.86
Round  52, Train loss: 0.719, Test loss: 0.905, Test accuracy: 69.89
Round  52, Global train loss: 0.719, Global test loss: 0.744, Global test accuracy: 74.84
Round  53, Train loss: 0.709, Test loss: 0.906, Test accuracy: 70.03
Round  53, Global train loss: 0.709, Global test loss: 0.744, Global test accuracy: 74.71
Round  54, Train loss: 0.711, Test loss: 0.903, Test accuracy: 70.03
Round  54, Global train loss: 0.711, Global test loss: 0.736, Global test accuracy: 74.98
Round  55, Train loss: 0.672, Test loss: 0.903, Test accuracy: 70.01
Round  55, Global train loss: 0.672, Global test loss: 0.746, Global test accuracy: 74.26
Round  56, Train loss: 0.681, Test loss: 0.885, Test accuracy: 70.59
Round  56, Global train loss: 0.681, Global test loss: 0.731, Global test accuracy: 75.29
Round  57, Train loss: 0.686, Test loss: 0.894, Test accuracy: 70.46
Round  57, Global train loss: 0.686, Global test loss: 0.734, Global test accuracy: 75.28
Round  58, Train loss: 0.669, Test loss: 0.888, Test accuracy: 70.59
Round  58, Global train loss: 0.669, Global test loss: 0.737, Global test accuracy: 75.11
Round  59, Train loss: 0.661, Test loss: 0.885, Test accuracy: 70.59
Round  59, Global train loss: 0.661, Global test loss: 0.728, Global test accuracy: 75.67
Round  60, Train loss: 0.661, Test loss: 0.889, Test accuracy: 70.67
Round  60, Global train loss: 0.661, Global test loss: 0.729, Global test accuracy: 75.74
Round  61, Train loss: 0.659, Test loss: 0.890, Test accuracy: 70.88
Round  61, Global train loss: 0.659, Global test loss: 0.735, Global test accuracy: 75.46
Round  62, Train loss: 0.654, Test loss: 0.885, Test accuracy: 70.95
Round  62, Global train loss: 0.654, Global test loss: 0.725, Global test accuracy: 75.59
Round  63, Train loss: 0.637, Test loss: 0.886, Test accuracy: 70.87
Round  63, Global train loss: 0.637, Global test loss: 0.730, Global test accuracy: 75.34
Round  64, Train loss: 0.633, Test loss: 0.888, Test accuracy: 70.92
Round  64, Global train loss: 0.633, Global test loss: 0.720, Global test accuracy: 75.97
Round  65, Train loss: 0.633, Test loss: 0.888, Test accuracy: 70.91
Round  65, Global train loss: 0.633, Global test loss: 0.722, Global test accuracy: 75.91
Round  66, Train loss: 0.633, Test loss: 0.896, Test accuracy: 70.83
Round  66, Global train loss: 0.633, Global test loss: 0.739, Global test accuracy: 75.42
Round  67, Train loss: 0.619, Test loss: 0.894, Test accuracy: 71.00
Round  67, Global train loss: 0.619, Global test loss: 0.729, Global test accuracy: 75.88
Round  68, Train loss: 0.629, Test loss: 0.888, Test accuracy: 71.12
Round  68, Global train loss: 0.629, Global test loss: 0.725, Global test accuracy: 75.62
Round  69, Train loss: 0.636, Test loss: 0.887, Test accuracy: 71.20
Round  69, Global train loss: 0.636, Global test loss: 0.725, Global test accuracy: 75.84
Round  70, Train loss: 0.636, Test loss: 0.890, Test accuracy: 71.23
Round  70, Global train loss: 0.636, Global test loss: 0.715, Global test accuracy: 76.13
Round  71, Train loss: 0.591, Test loss: 0.891, Test accuracy: 71.06
Round  71, Global train loss: 0.591, Global test loss: 0.718, Global test accuracy: 76.22
Round  72, Train loss: 0.678, Test loss: 0.882, Test accuracy: 71.43
Round  72, Global train loss: 0.678, Global test loss: 0.704, Global test accuracy: 76.29
Round  73, Train loss: 0.618, Test loss: 0.868, Test accuracy: 71.81
Round  73, Global train loss: 0.618, Global test loss: 0.708, Global test accuracy: 75.92
Round  74, Train loss: 0.604, Test loss: 0.856, Test accuracy: 72.00
Round  74, Global train loss: 0.604, Global test loss: 0.710, Global test accuracy: 76.30
Round  75, Train loss: 0.633, Test loss: 0.860, Test accuracy: 72.09
Round  75, Global train loss: 0.633, Global test loss: 0.728, Global test accuracy: 75.91
Round  76, Train loss: 0.582, Test loss: 0.861, Test accuracy: 72.06
Round  76, Global train loss: 0.582, Global test loss: 0.714, Global test accuracy: 76.85
Round  77, Train loss: 0.606, Test loss: 0.864, Test accuracy: 72.08
Round  77, Global train loss: 0.606, Global test loss: 0.708, Global test accuracy: 76.79
Round  78, Train loss: 0.602, Test loss: 0.864, Test accuracy: 71.93
Round  78, Global train loss: 0.602, Global test loss: 0.704, Global test accuracy: 76.90
Round  79, Train loss: 0.601, Test loss: 0.862, Test accuracy: 72.07
Round  79, Global train loss: 0.601, Global test loss: 0.716, Global test accuracy: 76.22
Round  80, Train loss: 0.605, Test loss: 0.865, Test accuracy: 72.05
Round  80, Global train loss: 0.605, Global test loss: 0.704, Global test accuracy: 76.38
Round  81, Train loss: 0.611, Test loss: 0.863, Test accuracy: 72.33
Round  81, Global train loss: 0.611, Global test loss: 0.693, Global test accuracy: 77.03
Round  82, Train loss: 0.575, Test loss: 0.882, Test accuracy: 71.92
Round  82, Global train loss: 0.575, Global test loss: 0.720, Global test accuracy: 75.84
Round  83, Train loss: 0.612, Test loss: 0.877, Test accuracy: 72.07
Round  83, Global train loss: 0.612, Global test loss: 0.702, Global test accuracy: 76.84
Round  84, Train loss: 0.573, Test loss: 0.860, Test accuracy: 72.43
Round  84, Global train loss: 0.573, Global test loss: 0.698, Global test accuracy: 77.03
Round  85, Train loss: 0.584, Test loss: 0.858, Test accuracy: 72.40
Round  85, Global train loss: 0.584, Global test loss: 0.700, Global test accuracy: 76.86
Round  86, Train loss: 0.554, Test loss: 0.855, Test accuracy: 72.56
Round  86, Global train loss: 0.554, Global test loss: 0.705, Global test accuracy: 76.83
Round  87, Train loss: 0.553, Test loss: 0.863, Test accuracy: 72.53
Round  87, Global train loss: 0.553, Global test loss: 0.712, Global test accuracy: 77.00
Round  88, Train loss: 0.559, Test loss: 0.868, Test accuracy: 72.63
Round  88, Global train loss: 0.559, Global test loss: 0.711, Global test accuracy: 76.73
Round  89, Train loss: 0.552, Test loss: 0.873, Test accuracy: 72.42
Round  89, Global train loss: 0.552, Global test loss: 0.719, Global test accuracy: 76.60
Round  90, Train loss: 0.565, Test loss: 0.877, Test accuracy: 72.25
Round  90, Global train loss: 0.565, Global test loss: 0.716, Global test accuracy: 76.84
Round  91, Train loss: 0.535, Test loss: 0.867, Test accuracy: 72.58
Round  91, Global train loss: 0.535, Global test loss: 0.715, Global test accuracy: 76.99
Round  92, Train loss: 0.537, Test loss: 0.870, Test accuracy: 72.56
Round  92, Global train loss: 0.537, Global test loss: 0.711, Global test accuracy: 76.75
Round  93, Train loss: 0.549, Test loss: 0.869, Test accuracy: 72.64
Round  93, Global train loss: 0.549, Global test loss: 0.713, Global test accuracy: 76.96
Round  94, Train loss: 0.575, Test loss: 0.865, Test accuracy: 72.80
Round  94, Global train loss: 0.575, Global test loss: 0.698, Global test accuracy: 76.97
Round  95, Train loss: 0.577, Test loss: 0.861, Test accuracy: 72.98
Round  95, Global train loss: 0.577, Global test loss: 0.709, Global test accuracy: 77.00/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

Round  96, Train loss: 0.554, Test loss: 0.854, Test accuracy: 73.12
Round  96, Global train loss: 0.554, Global test loss: 0.700, Global test accuracy: 76.95
Round  97, Train loss: 0.552, Test loss: 0.852, Test accuracy: 73.13
Round  97, Global train loss: 0.552, Global test loss: 0.704, Global test accuracy: 76.75
Round  98, Train loss: 0.540, Test loss: 0.857, Test accuracy: 72.96
Round  98, Global train loss: 0.540, Global test loss: 0.702, Global test accuracy: 77.25
Round  99, Train loss: 0.576, Test loss: 0.854, Test accuracy: 73.06
Round  99, Global train loss: 0.576, Global test loss: 0.698, Global test accuracy: 76.96
Final Round, Train loss: 0.354, Test loss: 0.963, Test accuracy: 72.82
Final Round, Global train loss: 0.354, Global test loss: 0.698, Global test accuracy: 76.96
Average accuracy final 10 rounds: 72.80750000000002 

Average global accuracy final 10 rounds: 76.94275 

6798.677043676376
[5.643629550933838, 11.287259101867676, 16.16043782234192, 21.033616542816162, 25.903236627578735, 30.77285671234131, 35.480207204818726, 40.18755769729614, 44.94477963447571, 49.70200157165527, 54.57335901260376, 59.444716453552246, 64.80357551574707, 70.1624345779419, 75.566171169281, 80.96990776062012, 86.36894631385803, 91.76798486709595, 97.05297446250916, 102.33796405792236, 107.64684677124023, 112.9557294845581, 118.05044221878052, 123.14515495300293, 128.14881110191345, 133.15246725082397, 138.23135423660278, 143.3102412223816, 148.1763551235199, 153.0424690246582, 158.03742623329163, 163.03238344192505, 167.9196331501007, 172.80688285827637, 177.74752926826477, 182.68817567825317, 187.76074481010437, 192.83331394195557, 197.7860140800476, 202.73871421813965, 207.74972987174988, 212.7607455253601, 218.32416915893555, 223.887592792511, 229.4723665714264, 235.0571403503418, 240.42834448814392, 245.79954862594604, 251.13626146316528, 256.4729743003845, 261.8091838359833, 267.14539337158203, 272.6058897972107, 278.06638622283936, 283.45457434654236, 288.84276247024536, 294.34749150276184, 299.8522205352783, 305.4067349433899, 310.96124935150146, 316.4649739265442, 321.9686985015869, 327.4788372516632, 332.9889760017395, 338.27703309059143, 343.56509017944336, 348.60925245285034, 353.6534147262573, 358.6977467536926, 363.74207878112793, 368.64088892936707, 373.5396990776062, 378.6158814430237, 383.69206380844116, 388.52351474761963, 393.3549656867981, 398.3350610733032, 403.31515645980835, 408.2115886211395, 413.1080207824707, 418.04825615882874, 422.98849153518677, 428.06760716438293, 433.1467227935791, 438.1423306465149, 443.1379384994507, 448.1195938587189, 453.10124921798706, 458.1067223548889, 463.11219549179077, 468.01478147506714, 472.9173674583435, 477.76790976524353, 482.61845207214355, 487.6445617675781, 492.6706714630127, 497.707394361496, 502.74411725997925, 507.5538020133972, 512.3634867668152, 517.2711427211761, 522.1787986755371, 527.0536987781525, 531.9285988807678, 536.9964163303375, 542.0642337799072, 547.1789157390594, 552.2935976982117, 557.226363658905, 562.1591296195984, 567.0364389419556, 571.9137482643127, 576.9767460823059, 582.0397439002991, 587.1135494709015, 592.1873550415039, 597.0891237258911, 601.9908924102783, 606.965259552002, 611.9396266937256, 616.9748327732086, 622.0100388526917, 627.052277803421, 632.0945167541504, 637.0827081203461, 642.0708994865417, 647.118748664856, 652.1665978431702, 657.270263671875, 662.3739295005798, 667.4843602180481, 672.5947909355164, 677.4666588306427, 682.338526725769, 687.4160087108612, 692.4934906959534, 697.5876779556274, 702.6818652153015, 707.5528695583344, 712.4238739013672, 717.3520314693451, 722.280189037323, 727.3632616996765, 732.44633436203, 737.4992876052856, 742.5522408485413, 747.4214019775391, 752.2905631065369, 757.0849633216858, 761.8793635368347, 766.6677534580231, 771.4561433792114, 776.1921532154083, 780.9281630516052, 785.6486115455627, 790.3690600395203, 795.0668320655823, 799.7646040916443, 804.5233097076416, 809.2820153236389, 814.0045244693756, 818.7270336151123, 823.4543704986572, 828.1817073822021, 832.9015369415283, 837.6213665008545, 842.3063759803772, 846.9913854598999, 851.7361352443695, 856.4808850288391, 861.5086581707001, 866.536431312561, 871.5890729427338, 876.6417145729065, 881.6866602897644, 886.7316060066223, 891.7651886940002, 896.7987713813782, 901.8232569694519, 906.8477425575256, 911.9242744445801, 917.0008063316345, 921.8974339962006, 926.7940616607666, 931.6771042346954, 936.5601468086243, 941.4204714298248, 946.2807960510254, 951.1851761341095, 956.0895562171936, 961.1630177497864, 966.2364792823792, 971.0340571403503, 975.8316349983215, 980.6304721832275, 985.4293093681335, 990.2096920013428, 994.990074634552, 999.8177819252014, 1004.6454892158508, 1007.2315201759338, 1009.8175511360168]
[35.29, 35.29, 38.8075, 38.8075, 40.795, 40.795, 42.89, 42.89, 44.4375, 44.4375, 45.0825, 45.0825, 46.085, 46.085, 48.445, 48.445, 49.27, 49.27, 50.05, 50.05, 51.14, 51.14, 53.725, 53.725, 55.63, 55.63, 56.0025, 56.0025, 57.52, 57.52, 58.3075, 58.3075, 58.33, 58.33, 59.47, 59.47, 59.6725, 59.6725, 60.52, 60.52, 61.15, 61.15, 61.4375, 61.4375, 62.4475, 62.4475, 63.6, 63.6, 64.06, 64.06, 64.6325, 64.6325, 65.1525, 65.1525, 65.4075, 65.4075, 65.465, 65.465, 65.3575, 65.3575, 65.295, 65.295, 65.3375, 65.3375, 66.4725, 66.4725, 66.71, 66.71, 67.1875, 67.1875, 67.27, 67.27, 67.565, 67.565, 67.81, 67.81, 67.69, 67.69, 68.255, 68.255, 67.9325, 67.9325, 68.3175, 68.3175, 68.5425, 68.5425, 68.5875, 68.5875, 68.7175, 68.7175, 68.5375, 68.5375, 68.9575, 68.9575, 69.1925, 69.1925, 69.42, 69.42, 69.9925, 69.9925, 70.085, 70.085, 70.125, 70.125, 69.8925, 69.8925, 70.035, 70.035, 70.03, 70.03, 70.0125, 70.0125, 70.5875, 70.5875, 70.4625, 70.4625, 70.5925, 70.5925, 70.5925, 70.5925, 70.665, 70.665, 70.88, 70.88, 70.955, 70.955, 70.87, 70.87, 70.9175, 70.9175, 70.91, 70.91, 70.8325, 70.8325, 70.9975, 70.9975, 71.1175, 71.1175, 71.1975, 71.1975, 71.23, 71.23, 71.0625, 71.0625, 71.4325, 71.4325, 71.805, 71.805, 72.005, 72.005, 72.095, 72.095, 72.06, 72.06, 72.0825, 72.0825, 71.93, 71.93, 72.0725, 72.0725, 72.05, 72.05, 72.325, 72.325, 71.9225, 71.9225, 72.0675, 72.0675, 72.4275, 72.4275, 72.4, 72.4, 72.565, 72.565, 72.5325, 72.5325, 72.63, 72.63, 72.425, 72.425, 72.245, 72.245, 72.585, 72.585, 72.5575, 72.5575, 72.6375, 72.6375, 72.795, 72.795, 72.9825, 72.9825, 73.1175, 73.1175, 73.13, 73.13, 72.9625, 72.9625, 73.0625, 73.0625, 72.8175, 72.8175]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Co-teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 2.220, Test loss: 1.922, Test accuracy: 33.66
Round   1, Train loss: 1.849, Test loss: 1.627, Test accuracy: 42.81
Round   2, Train loss: 1.680, Test loss: 1.514, Test accuracy: 46.39
Round   3, Train loss: 1.585, Test loss: 1.419, Test accuracy: 50.78
Round   4, Train loss: 1.492, Test loss: 1.352, Test accuracy: 53.44
Round   5, Train loss: 1.427, Test loss: 1.279, Test accuracy: 55.63
Round   6, Train loss: 1.358, Test loss: 1.239, Test accuracy: 56.60
Round   7, Train loss: 1.304, Test loss: 1.197, Test accuracy: 58.77
Round   8, Train loss: 1.262, Test loss: 1.163, Test accuracy: 59.73
Round   9, Train loss: 1.228, Test loss: 1.142, Test accuracy: 60.81
Round  10, Train loss: 1.162, Test loss: 1.140, Test accuracy: 60.52
Round  11, Train loss: 1.138, Test loss: 1.120, Test accuracy: 60.99
Round  12, Train loss: 1.108, Test loss: 1.106, Test accuracy: 61.59
Round  13, Train loss: 1.099, Test loss: 1.074, Test accuracy: 62.60
Round  14, Train loss: 1.056, Test loss: 1.046, Test accuracy: 63.41
Round  15, Train loss: 1.046, Test loss: 1.024, Test accuracy: 64.12
Round  16, Train loss: 1.017, Test loss: 1.000, Test accuracy: 65.25
Round  17, Train loss: 0.995, Test loss: 0.948, Test accuracy: 67.12
Round  18, Train loss: 0.973, Test loss: 0.943, Test accuracy: 67.48
Round  19, Train loss: 0.945, Test loss: 0.928, Test accuracy: 68.40
Round  20, Train loss: 0.913, Test loss: 0.929, Test accuracy: 68.42
Round  21, Train loss: 0.925, Test loss: 0.891, Test accuracy: 69.86
Round  22, Train loss: 0.905, Test loss: 0.883, Test accuracy: 70.07
Round  23, Train loss: 0.899, Test loss: 0.860, Test accuracy: 70.43
Round  24, Train loss: 0.896, Test loss: 0.849, Test accuracy: 70.91
Round  25, Train loss: 0.850, Test loss: 0.851, Test accuracy: 70.97
Round  26, Train loss: 0.857, Test loss: 0.829, Test accuracy: 71.61
Round  27, Train loss: 0.823, Test loss: 0.828, Test accuracy: 71.86
Round  28, Train loss: 0.811, Test loss: 0.833, Test accuracy: 71.66
Round  29, Train loss: 0.844, Test loss: 0.811, Test accuracy: 72.14
Round  30, Train loss: 0.802, Test loss: 0.804, Test accuracy: 72.70
Round  31, Train loss: 0.791, Test loss: 0.809, Test accuracy: 72.50
Round  32, Train loss: 0.796, Test loss: 0.795, Test accuracy: 73.08
Round  33, Train loss: 0.764, Test loss: 0.792, Test accuracy: 72.83
Round  34, Train loss: 0.757, Test loss: 0.796, Test accuracy: 72.99
Round  35, Train loss: 0.760, Test loss: 0.795, Test accuracy: 72.89
Round  36, Train loss: 0.736, Test loss: 0.781, Test accuracy: 73.53
Round  37, Train loss: 0.724, Test loss: 0.789, Test accuracy: 72.98
Round  38, Train loss: 0.717, Test loss: 0.785, Test accuracy: 73.19
Round  39, Train loss: 0.724, Test loss: 0.771, Test accuracy: 73.89
Round  40, Train loss: 0.710, Test loss: 0.763, Test accuracy: 74.17
Round  41, Train loss: 0.704, Test loss: 0.791, Test accuracy: 73.03
Round  42, Train loss: 0.713, Test loss: 0.782, Test accuracy: 73.25
Round  43, Train loss: 0.708, Test loss: 0.786, Test accuracy: 73.38
Round  44, Train loss: 0.677, Test loss: 0.777, Test accuracy: 73.44
Round  45, Train loss: 0.708, Test loss: 0.761, Test accuracy: 74.30
Round  46, Train loss: 0.680, Test loss: 0.754, Test accuracy: 74.33
Round  47, Train loss: 0.658, Test loss: 0.751, Test accuracy: 74.78
Round  48, Train loss: 0.660, Test loss: 0.751, Test accuracy: 74.71
Round  49, Train loss: 0.690, Test loss: 0.740, Test accuracy: 75.25
Round  50, Train loss: 0.630, Test loss: 0.748, Test accuracy: 74.75
Round  51, Train loss: 0.657, Test loss: 0.744, Test accuracy: 75.07
Round  52, Train loss: 0.658, Test loss: 0.747, Test accuracy: 74.98
Round  53, Train loss: 0.649, Test loss: 0.731, Test accuracy: 75.58
Round  54, Train loss: 0.628, Test loss: 0.736, Test accuracy: 75.44
Round  55, Train loss: 0.621, Test loss: 0.732, Test accuracy: 75.21
Round  56, Train loss: 0.609, Test loss: 0.735, Test accuracy: 75.45
Round  57, Train loss: 0.634, Test loss: 0.741, Test accuracy: 75.07
Round  58, Train loss: 0.610, Test loss: 0.727, Test accuracy: 75.51
Round  59, Train loss: 0.622, Test loss: 0.718, Test accuracy: 75.86
Round  60, Train loss: 0.627, Test loss: 0.716, Test accuracy: 76.08
Round  61, Train loss: 0.576, Test loss: 0.724, Test accuracy: 75.95
Round  62, Train loss: 0.574, Test loss: 0.726, Test accuracy: 76.14
Round  63, Train loss: 0.567, Test loss: 0.733, Test accuracy: 75.94
Round  64, Train loss: 0.616, Test loss: 0.728, Test accuracy: 75.93
Round  65, Train loss: 0.590, Test loss: 0.716, Test accuracy: 76.13
Round  66, Train loss: 0.574, Test loss: 0.722, Test accuracy: 75.88
Round  67, Train loss: 0.588, Test loss: 0.723, Test accuracy: 76.06
Round  68, Train loss: 0.593, Test loss: 0.722, Test accuracy: 75.90
Round  69, Train loss: 0.570, Test loss: 0.722, Test accuracy: 76.16
Round  70, Train loss: 0.558, Test loss: 0.717, Test accuracy: 76.31
Round  71, Train loss: 0.579, Test loss: 0.714, Test accuracy: 76.36
Round  72, Train loss: 0.560, Test loss: 0.714, Test accuracy: 76.16
Round  73, Train loss: 0.569, Test loss: 0.710, Test accuracy: 76.71
Round  74, Train loss: 0.563, Test loss: 0.720, Test accuracy: 76.88
Round  75, Train loss: 0.581, Test loss: 0.716, Test accuracy: 76.95
Round  76, Train loss: 0.538, Test loss: 0.719, Test accuracy: 76.69
Round  77, Train loss: 0.556, Test loss: 0.720, Test accuracy: 76.81
Round  78, Train loss: 0.517, Test loss: 0.721, Test accuracy: 76.63
Round  79, Train loss: 0.537, Test loss: 0.711, Test accuracy: 76.98
Round  80, Train loss: 0.535, Test loss: 0.721, Test accuracy: 76.47
Round  81, Train loss: 0.565, Test loss: 0.710, Test accuracy: 77.23
Round  82, Train loss: 0.548, Test loss: 0.711, Test accuracy: 77.05
Round  83, Train loss: 0.530, Test loss: 0.706, Test accuracy: 77.07
Round  84, Train loss: 0.535, Test loss: 0.721, Test accuracy: 76.79
Round  85, Train loss: 0.522, Test loss: 0.712, Test accuracy: 77.23
Round  86, Train loss: 0.536, Test loss: 0.700, Test accuracy: 77.51
Round  87, Train loss: 0.503, Test loss: 0.706, Test accuracy: 77.32
Round  88, Train loss: 0.535, Test loss: 0.702, Test accuracy: 77.52
Round  89, Train loss: 0.513, Test loss: 0.703, Test accuracy: 77.33
Round  90, Train loss: 0.492, Test loss: 0.709, Test accuracy: 76.83
Round  91, Train loss: 0.511, Test loss: 0.710, Test accuracy: 77.14
Round  92, Train loss: 0.527, Test loss: 0.712, Test accuracy: 77.21
Round  93, Train loss: 0.509, Test loss: 0.719, Test accuracy: 77.14
Round  94, Train loss: 0.500, Test loss: 0.712, Test accuracy: 76.97
Round  95, Train loss: 0.479, Test loss: 0.718, Test accuracy: 76.89
Round  96, Train loss: 0.516, Test loss: 0.707, Test accuracy: 77.31
Round  97, Train loss: 0.496, Test loss: 0.707, Test accuracy: 77.24
Round  98, Train loss: 0.468, Test loss: 0.718, Test accuracy: 76.87
Round  99, Train loss: 0.485, Test loss: 0.717, Test accuracy: 76.94
Final Round, Train loss: 0.420, Test loss: 0.711, Test accuracy: 77.20
Average accuracy final 10 rounds: 77.05525
4947.308274030685
[6.615363597869873, 12.385991334915161, 18.06467914581299, 24.178190231323242, 30.161460399627686, 35.89750909805298, 41.58421301841736, 47.32529401779175, 53.07456970214844, 58.75658392906189, 64.41136384010315, 70.18792986869812, 75.89066886901855, 81.54258728027344, 87.346510887146, 93.14971208572388, 98.88195371627808, 104.6326858997345, 110.64097595214844, 116.42844438552856, 122.11241936683655, 127.79569125175476, 133.49538660049438, 139.2940137386322, 144.9423975944519, 150.9434199333191, 157.06816816329956, 162.76126837730408, 168.8756022453308, 175.0513186454773, 181.15453362464905, 187.314551115036, 193.57686972618103, 199.76279759407043, 205.92819166183472, 212.157329082489, 218.46612095832825, 224.75151586532593, 231.0065631866455, 237.32449054718018, 243.4993507862091, 249.81799912452698, 256.1754915714264, 262.4128158092499, 268.64112734794617, 274.83846783638, 281.06912565231323, 287.1669511795044, 293.33694553375244, 299.60031938552856, 305.7376289367676, 312.1295220851898, 318.3980059623718, 324.47770285606384, 330.7080063819885, 336.9072251319885, 343.04175758361816, 349.1220352649689, 355.2574932575226, 361.44613242149353, 367.6947829723358, 373.87224221229553, 379.933358669281, 386.1222002506256, 392.3699538707733, 398.65661883354187, 404.8554196357727, 411.11038732528687, 417.31788778305054, 423.6180911064148, 429.8578221797943, 436.06301045417786, 442.31494975090027, 448.5408136844635, 454.727413892746, 460.9063673019409, 467.10129594802856, 473.31091260910034, 479.4629340171814, 485.7218108177185, 492.0371639728546, 498.2479088306427, 504.4440302848816, 510.6809675693512, 516.94460105896, 523.2113373279572, 529.3185195922852, 535.5877149105072, 541.853976726532, 548.0844357013702, 554.2346386909485, 560.4406492710114, 566.6343061923981, 572.8081340789795, 578.8317556381226, 585.1978740692139, 591.4985535144806, 597.6758418083191, 603.6399049758911, 609.8668196201324, 612.4366610050201]
[33.665, 42.81, 46.3925, 50.7775, 53.435, 55.6275, 56.6025, 58.77, 59.735, 60.81, 60.515, 60.99, 61.595, 62.605, 63.4125, 64.1225, 65.2475, 67.125, 67.48, 68.4, 68.425, 69.86, 70.0675, 70.4275, 70.91, 70.97, 71.6125, 71.865, 71.66, 72.1425, 72.7, 72.5025, 73.075, 72.8275, 72.99, 72.895, 73.5275, 72.9775, 73.1925, 73.89, 74.1675, 73.025, 73.245, 73.3825, 73.44, 74.3, 74.335, 74.78, 74.7075, 75.245, 74.75, 75.0675, 74.9825, 75.575, 75.4375, 75.2125, 75.4475, 75.07, 75.5075, 75.8625, 76.075, 75.9475, 76.1425, 75.9425, 75.93, 76.1325, 75.88, 76.065, 75.8975, 76.16, 76.305, 76.3625, 76.1575, 76.71, 76.8825, 76.9475, 76.695, 76.81, 76.63, 76.9775, 76.465, 77.2325, 77.05, 77.07, 76.79, 77.235, 77.51, 77.3175, 77.5175, 77.3325, 76.8325, 77.145, 77.21, 77.145, 76.9675, 76.8875, 77.31, 77.2425, 76.8725, 76.94, 77.2]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  32.1000
Round 1 global test acc  42.9000
Round 2 global test acc  45.4800
Round 3 global test acc  48.7800
Round 4 global test acc  50.6600
Round 5 global test acc  50.5000
Round 6 global test acc  51.7700
Round 7 global test acc  54.4300
Round 8 global test acc  55.3400
Round 9 global test acc  56.7000
Round 10 global test acc  56.9100
Round 11 global test acc  57.4500
Round 12 global test acc  57.1400
Round 13 global test acc  58.4400
Round 14 global test acc  58.5700
Round 15 global test acc  58.0700
Round 16 global test acc  59.2100
Round 17 global test acc  60.1900
Round 18 global test acc  60.5600
Round 19 global test acc  60.9600
Round 20 global test acc  61.1700
Round 21 global test acc  60.6800
Round 22 global test acc  62.0100
Round 23 global test acc  61.4400
Round 24 global test acc  62.1400
Round 25 global test acc  61.9800
Round 26 global test acc  62.1000
Round 27 global test acc  62.1200
Round 28 global test acc  62.8300
Round 29 global test acc  62.7000
Round 30 global test acc  62.7300
Round 31 global test acc  63.8300
Round 32 global test acc  63.8500
Round 33 global test acc  63.7900
Round 34 global test acc  64.3200
Round 35 global test acc  64.8500
Round 36 global test acc  64.5000
Round 37 global test acc  65.0100
Round 38 global test acc  64.5000
Round 39 global test acc  64.8600
Round 40 global test acc  63.9800
Round 41 global test acc  64.0600
Round 42 global test acc  64.9400
Round 43 global test acc  64.6400
Round 44 global test acc  65.3000
Round 45 global test acc  64.6000
Round 46 global test acc  65.5000
Round 47 global test acc  66.4700
Round 48 global test acc  65.8800
Round 49 global test acc  65.9200
Round 50 global test acc  66.0500
Round 51 global test acc  66.1300
Round 52 global test acc  66.8100
Round 53 global test acc  66.7100
Round 54 global test acc  66.4700
Round 55 global test acc  66.4200
Round 56 global test acc  66.3800
Round 57 global test acc  66.7000
Round 58 global test acc  66.3700
Round 59 global test acc  67.0100
Round 60 global test acc  66.9500
Round 61 global test acc  66.8800
Round 62 global test acc  66.6500
Round 63 global test acc  66.6000
Round 64 global test acc  67.2900
Round 65 global test acc  67.5300
Round 66 global test acc  67.1800
Round 67 global test acc  67.1600
Round 68 global test acc  67.0900
Round 69 global test acc  66.9900
Round 70 global test acc  67.5600
Round 71 global test acc  67.3500
Round 72 global test acc  68.0300
Round 73 global test acc  67.7800
Round 74 global test acc  67.4500
Round 75 global test acc  67.8800
Round 76 global test acc  67.0800
Round 77 global test acc  67.8300
Round 78 global test acc  67.5800
Round 79 global test acc  67.6400
Round 80 global test acc  66.6200
Round 81 global test acc  66.0500
Round 82 global test acc  64.9500
Round 83 global test acc  64.4600
Round 84 global test acc  63.3800
Round 85 global test acc  62.6000
Round 86 global test acc  61.4500
Round 87 global test acc  60.9900
Round 88 global test acc  60.3800
Round 89 global test acc  60.3300
Round 90 global test acc  60.5700
Round 91 global test acc  60.2600
Round 92 global test acc  59.9400
Round 93 global test acc  59.2400
Round 94 global test acc  58.8800
Round 95 global test acc  58.4700
Round 96 global test acc  57.9500
Round 97 global test acc  58.5700
Round 98 global test acc  58.7700
Round 99 global test acc  58.4800
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.514, Test loss: 2.152, Test accuracy: 21.41
Round   1, Train loss: 1.006, Test loss: 1.739, Test accuracy: 37.98
Round   2, Train loss: 0.870, Test loss: 1.478, Test accuracy: 44.79
Round   3, Train loss: 0.810, Test loss: 1.170, Test accuracy: 52.18
Round   4, Train loss: 0.752, Test loss: 1.115, Test accuracy: 55.96
Round   5, Train loss: 0.801, Test loss: 1.014, Test accuracy: 60.95
Round   6, Train loss: 0.699, Test loss: 0.891, Test accuracy: 64.80
Round   7, Train loss: 0.670, Test loss: 0.812, Test accuracy: 68.55
Round   8, Train loss: 0.686, Test loss: 0.836, Test accuracy: 67.40
Round   9, Train loss: 0.659, Test loss: 0.709, Test accuracy: 71.89
Round  10, Train loss: 0.608, Test loss: 0.615, Test accuracy: 75.53
Round  11, Train loss: 0.645, Test loss: 0.599, Test accuracy: 76.03
Round  12, Train loss: 0.607, Test loss: 0.591, Test accuracy: 75.72
Round  13, Train loss: 0.592, Test loss: 0.570, Test accuracy: 76.74
Round  14, Train loss: 0.627, Test loss: 0.562, Test accuracy: 77.84
Round  15, Train loss: 0.552, Test loss: 0.555, Test accuracy: 77.83
Round  16, Train loss: 0.559, Test loss: 0.547, Test accuracy: 78.58
Round  17, Train loss: 0.547, Test loss: 0.538, Test accuracy: 79.27
Round  18, Train loss: 0.513, Test loss: 0.538, Test accuracy: 79.17
Round  19, Train loss: 0.534, Test loss: 0.514, Test accuracy: 79.52
Round  20, Train loss: 0.527, Test loss: 0.500, Test accuracy: 79.93
Round  21, Train loss: 0.522, Test loss: 0.504, Test accuracy: 80.47
Round  22, Train loss: 0.522, Test loss: 0.506, Test accuracy: 80.19
Round  23, Train loss: 0.489, Test loss: 0.486, Test accuracy: 80.24
Round  24, Train loss: 0.478, Test loss: 0.497, Test accuracy: 80.57
Round  25, Train loss: 0.470, Test loss: 0.481, Test accuracy: 81.29
Round  26, Train loss: 0.543, Test loss: 0.461, Test accuracy: 81.79
Round  27, Train loss: 0.443, Test loss: 0.465, Test accuracy: 81.26
Round  28, Train loss: 0.531, Test loss: 0.446, Test accuracy: 82.47
Round  29, Train loss: 0.513, Test loss: 0.450, Test accuracy: 82.02
Round  30, Train loss: 0.462, Test loss: 0.440, Test accuracy: 82.29
Round  31, Train loss: 0.418, Test loss: 0.449, Test accuracy: 82.25
Round  32, Train loss: 0.414, Test loss: 0.443, Test accuracy: 82.42
Round  33, Train loss: 0.448, Test loss: 0.426, Test accuracy: 83.14
Round  34, Train loss: 0.467, Test loss: 0.411, Test accuracy: 83.57
Round  35, Train loss: 0.454, Test loss: 0.419, Test accuracy: 83.36
Round  36, Train loss: 0.444, Test loss: 0.410, Test accuracy: 83.90
Round  37, Train loss: 0.412, Test loss: 0.405, Test accuracy: 84.21
Round  38, Train loss: 0.391, Test loss: 0.401, Test accuracy: 84.40
Round  39, Train loss: 0.430, Test loss: 0.394, Test accuracy: 84.47
Round  40, Train loss: 0.384, Test loss: 0.409, Test accuracy: 83.85
Round  41, Train loss: 0.373, Test loss: 0.400, Test accuracy: 84.48
Round  42, Train loss: 0.369, Test loss: 0.394, Test accuracy: 84.49
Round  43, Train loss: 0.398, Test loss: 0.400, Test accuracy: 84.46
Round  44, Train loss: 0.415, Test loss: 0.388, Test accuracy: 84.84
Round  45, Train loss: 0.403, Test loss: 0.394, Test accuracy: 84.27
Round  46, Train loss: 0.394, Test loss: 0.387, Test accuracy: 84.85
Round  47, Train loss: 0.383, Test loss: 0.384, Test accuracy: 85.12
Round  48, Train loss: 0.397, Test loss: 0.374, Test accuracy: 85.43
Round  49, Train loss: 0.375, Test loss: 0.371, Test accuracy: 85.74
Round  50, Train loss: 0.318, Test loss: 0.370, Test accuracy: 85.64
Round  51, Train loss: 0.386, Test loss: 0.370, Test accuracy: 85.73
Round  52, Train loss: 0.376, Test loss: 0.367, Test accuracy: 85.72
Round  53, Train loss: 0.338, Test loss: 0.366, Test accuracy: 85.67
Round  54, Train loss: 0.346, Test loss: 0.360, Test accuracy: 86.09
Round  55, Train loss: 0.335, Test loss: 0.358, Test accuracy: 85.85
Round  56, Train loss: 0.331, Test loss: 0.361, Test accuracy: 85.93
Round  57, Train loss: 0.315, Test loss: 0.361, Test accuracy: 86.24
Round  58, Train loss: 0.351, Test loss: 0.357, Test accuracy: 86.17
Round  59, Train loss: 0.319, Test loss: 0.351, Test accuracy: 86.38
Round  60, Train loss: 0.294, Test loss: 0.352, Test accuracy: 86.07
Round  61, Train loss: 0.340, Test loss: 0.348, Test accuracy: 86.31
Round  62, Train loss: 0.296, Test loss: 0.352, Test accuracy: 86.12
Round  63, Train loss: 0.320, Test loss: 0.343, Test accuracy: 86.47
Round  64, Train loss: 0.308, Test loss: 0.340, Test accuracy: 86.72
Round  65, Train loss: 0.359, Test loss: 0.351, Test accuracy: 86.32
Round  66, Train loss: 0.285, Test loss: 0.336, Test accuracy: 86.81
Round  67, Train loss: 0.262, Test loss: 0.337, Test accuracy: 86.78
Round  68, Train loss: 0.286, Test loss: 0.338, Test accuracy: 86.73
Round  69, Train loss: 0.310, Test loss: 0.344, Test accuracy: 86.38
Round  70, Train loss: 0.242, Test loss: 0.342, Test accuracy: 86.61
Round  71, Train loss: 0.294, Test loss: 0.335, Test accuracy: 86.76
Round  72, Train loss: 0.296, Test loss: 0.340, Test accuracy: 87.15
Round  73, Train loss: 0.267, Test loss: 0.332, Test accuracy: 87.28
Round  74, Train loss: 0.249, Test loss: 0.341, Test accuracy: 86.92
Round  75, Train loss: 0.280, Test loss: 0.332, Test accuracy: 86.50
Round  76, Train loss: 0.276, Test loss: 0.338, Test accuracy: 86.70
Round  77, Train loss: 0.304, Test loss: 0.333, Test accuracy: 86.72
Round  78, Train loss: 0.268, Test loss: 0.334, Test accuracy: 86.83
Round  79, Train loss: 0.280, Test loss: 0.328, Test accuracy: 87.00
Round  80, Train loss: 0.263, Test loss: 0.330, Test accuracy: 86.96
Round  81, Train loss: 0.255, Test loss: 0.328, Test accuracy: 87.17
Round  82, Train loss: 0.228, Test loss: 0.334, Test accuracy: 86.47
Round  83, Train loss: 0.273, Test loss: 0.336, Test accuracy: 86.83
Round  84, Train loss: 0.248, Test loss: 0.333, Test accuracy: 86.87
Round  85, Train loss: 0.258, Test loss: 0.327, Test accuracy: 87.10
Round  86, Train loss: 0.249, Test loss: 0.336, Test accuracy: 87.26
Round  87, Train loss: 0.231, Test loss: 0.329, Test accuracy: 87.39
Round  88, Train loss: 0.224, Test loss: 0.334, Test accuracy: 87.03
Round  89, Train loss: 0.234, Test loss: 0.323, Test accuracy: 87.59
Round  90, Train loss: 0.232, Test loss: 0.323, Test accuracy: 87.39
Round  91, Train loss: 0.245, Test loss: 0.323, Test accuracy: 87.31
Round  92, Train loss: 0.234, Test loss: 0.321, Test accuracy: 87.55
Round  93, Train loss: 0.208, Test loss: 0.320, Test accuracy: 87.82
Round  94, Train loss: 0.243, Test loss: 0.322, Test accuracy: 87.63
Round  95, Train loss: 0.229, Test loss: 0.324, Test accuracy: 87.31
Round  96, Train loss: 0.219, Test loss: 0.324, Test accuracy: 87.46
Round  97, Train loss: 0.215, Test loss: 0.327, Test accuracy: 87.12
Round  98, Train loss: 0.252, Test loss: 0.328, Test accuracy: 87.28
Round  99, Train loss: 0.234, Test loss: 0.323, Test accuracy: 87.46
Final Round, Train loss: 0.188, Test loss: 0.323, Test accuracy: 87.74
Average accuracy final 10 rounds: 87.43250000000002
1435.2858703136444
[2.1570701599121094, 3.919010639190674, 5.713937282562256, 7.508947372436523, 9.264106273651123, 10.913036346435547, 12.668935775756836, 14.476050615310669, 16.2510244846344, 17.901546001434326, 19.642914056777954, 21.302453756332397, 22.926957845687866, 24.60241460800171, 26.280137538909912, 27.911633491516113, 29.547446250915527, 31.20601487159729, 32.84719109535217, 34.49423122406006, 36.246711015701294, 37.92295598983765, 39.567933797836304, 41.24833703041077, 43.06259608268738, 44.78936266899109, 46.42180132865906, 48.09103775024414, 49.86691331863403, 51.50529861450195, 53.276202917099, 55.0508291721344, 56.909708976745605, 58.785693645477295, 60.71566104888916, 62.52315616607666, 64.33788728713989, 66.14888572692871, 67.97378325462341, 69.87525200843811, 71.79477834701538, 73.65323281288147, 75.53010702133179, 77.42543196678162, 79.35059332847595, 81.25440907478333, 83.08302974700928, 84.90834641456604, 86.75953698158264, 88.63628387451172, 90.52248907089233, 92.38904237747192, 94.25612330436707, 96.06336879730225, 97.96824407577515, 99.88784432411194, 101.70780229568481, 103.43972754478455, 105.13218522071838, 106.82692909240723, 108.53822612762451, 110.29288697242737, 112.02028894424438, 113.71508932113647, 115.49707007408142, 117.28637433052063, 118.94537305831909, 120.71124625205994, 122.3833589553833, 124.05651211738586, 125.71883845329285, 127.38792419433594, 129.01653909683228, 130.69295930862427, 132.40633606910706, 134.15902972221375, 135.8830530643463, 137.63638043403625, 139.37493133544922, 141.16632890701294, 142.82633090019226, 144.5382912158966, 146.26162838935852, 148.04673171043396, 149.69350814819336, 151.33202934265137, 152.9983627796173, 154.67484068870544, 156.3328778743744, 157.98398184776306, 159.6317002773285, 161.3091139793396, 163.01214790344238, 164.6881127357483, 166.3554346561432, 168.016122341156, 169.66925501823425, 171.31469702720642, 173.00199007987976, 174.70024418830872, 176.90631079673767]
[21.408333333333335, 37.983333333333334, 44.791666666666664, 52.18333333333333, 55.958333333333336, 60.95, 64.8, 68.55, 67.4, 71.89166666666667, 75.53333333333333, 76.03333333333333, 75.725, 76.74166666666666, 77.84166666666667, 77.825, 78.575, 79.26666666666667, 79.175, 79.51666666666667, 79.93333333333334, 80.475, 80.19166666666666, 80.24166666666666, 80.56666666666666, 81.29166666666667, 81.79166666666667, 81.25833333333334, 82.475, 82.01666666666667, 82.29166666666667, 82.25, 82.41666666666667, 83.14166666666667, 83.56666666666666, 83.35833333333333, 83.9, 84.20833333333333, 84.4, 84.475, 83.85, 84.48333333333333, 84.49166666666666, 84.45833333333333, 84.84166666666667, 84.26666666666667, 84.85, 85.11666666666666, 85.43333333333334, 85.74166666666666, 85.64166666666667, 85.73333333333333, 85.725, 85.675, 86.09166666666667, 85.85, 85.93333333333334, 86.24166666666666, 86.175, 86.375, 86.06666666666666, 86.30833333333334, 86.125, 86.46666666666667, 86.725, 86.31666666666666, 86.80833333333334, 86.78333333333333, 86.73333333333333, 86.38333333333334, 86.60833333333333, 86.75833333333334, 87.15, 87.275, 86.91666666666667, 86.5, 86.7, 86.725, 86.825, 87.0, 86.95833333333333, 87.175, 86.46666666666667, 86.83333333333333, 86.86666666666666, 87.1, 87.25833333333334, 87.39166666666667, 87.025, 87.59166666666667, 87.39166666666667, 87.30833333333334, 87.55, 87.81666666666666, 87.63333333333334, 87.30833333333334, 87.45833333333333, 87.11666666666666, 87.28333333333333, 87.45833333333333, 87.74166666666666]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.0 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.479, Test loss: 2.101, Test accuracy: 28.96
Round   1, Train loss: 0.983, Test loss: 1.780, Test accuracy: 35.51
Round   2, Train loss: 0.883, Test loss: 1.529, Test accuracy: 44.58
Round   3, Train loss: 0.783, Test loss: 1.126, Test accuracy: 53.75
Round   4, Train loss: 0.763, Test loss: 0.903, Test accuracy: 64.52
Round   5, Train loss: 0.693, Test loss: 0.746, Test accuracy: 68.97
Round   6, Train loss: 0.685, Test loss: 0.744, Test accuracy: 70.72
Round   7, Train loss: 0.635, Test loss: 0.711, Test accuracy: 70.25
Round   8, Train loss: 0.621, Test loss: 0.737, Test accuracy: 71.77
Round   9, Train loss: 0.637, Test loss: 0.643, Test accuracy: 74.38
Round  10, Train loss: 0.655, Test loss: 0.647, Test accuracy: 73.86
Round  11, Train loss: 0.610, Test loss: 0.623, Test accuracy: 75.02
Round  12, Train loss: 0.571, Test loss: 0.602, Test accuracy: 75.67
Round  13, Train loss: 0.560, Test loss: 0.571, Test accuracy: 76.88
Round  14, Train loss: 0.570, Test loss: 0.633, Test accuracy: 76.38
Round  15, Train loss: 0.600, Test loss: 0.591, Test accuracy: 77.86
Round  16, Train loss: 0.492, Test loss: 0.608, Test accuracy: 76.37
Round  17, Train loss: 0.507, Test loss: 0.606, Test accuracy: 76.48
Round  18, Train loss: 0.562, Test loss: 0.606, Test accuracy: 76.33
Round  19, Train loss: 0.521, Test loss: 0.575, Test accuracy: 77.67
Round  20, Train loss: 0.527, Test loss: 0.496, Test accuracy: 79.73
Round  21, Train loss: 0.504, Test loss: 0.488, Test accuracy: 80.41
Round  22, Train loss: 0.453, Test loss: 0.480, Test accuracy: 81.23
Round  23, Train loss: 0.460, Test loss: 0.482, Test accuracy: 80.94
Round  24, Train loss: 0.542, Test loss: 0.473, Test accuracy: 80.66
Round  25, Train loss: 0.473, Test loss: 0.466, Test accuracy: 81.36
Round  26, Train loss: 0.455, Test loss: 0.447, Test accuracy: 82.23
Round  27, Train loss: 0.507, Test loss: 0.438, Test accuracy: 82.15
Round  28, Train loss: 0.448, Test loss: 0.446, Test accuracy: 81.76
Round  29, Train loss: 0.419, Test loss: 0.449, Test accuracy: 81.27
Round  30, Train loss: 0.469, Test loss: 0.449, Test accuracy: 81.43
Round  31, Train loss: 0.472, Test loss: 0.436, Test accuracy: 82.01
Round  32, Train loss: 0.418, Test loss: 0.444, Test accuracy: 81.83
Round  33, Train loss: 0.438, Test loss: 0.423, Test accuracy: 82.67
Round  34, Train loss: 0.399, Test loss: 0.411, Test accuracy: 83.53
Round  35, Train loss: 0.434, Test loss: 0.418, Test accuracy: 83.54
Round  36, Train loss: 0.388, Test loss: 0.413, Test accuracy: 83.70
Round  37, Train loss: 0.399, Test loss: 0.410, Test accuracy: 83.65
Round  38, Train loss: 0.417, Test loss: 0.403, Test accuracy: 83.92
Round  39, Train loss: 0.391, Test loss: 0.392, Test accuracy: 84.38
Round  40, Train loss: 0.403, Test loss: 0.393, Test accuracy: 84.15
Round  41, Train loss: 0.388, Test loss: 0.388, Test accuracy: 84.46
Round  42, Train loss: 0.398, Test loss: 0.382, Test accuracy: 84.73
Round  43, Train loss: 0.345, Test loss: 0.384, Test accuracy: 84.97
Round  44, Train loss: 0.358, Test loss: 0.382, Test accuracy: 85.03
Round  45, Train loss: 0.329, Test loss: 0.380, Test accuracy: 84.97
Round  46, Train loss: 0.356, Test loss: 0.377, Test accuracy: 85.34
Round  47, Train loss: 0.409, Test loss: 0.379, Test accuracy: 85.09
Round  48, Train loss: 0.354, Test loss: 0.372, Test accuracy: 85.40
Round  49, Train loss: 0.332, Test loss: 0.375, Test accuracy: 85.12
Round  50, Train loss: 0.343, Test loss: 0.371, Test accuracy: 85.33
Round  51, Train loss: 0.293, Test loss: 0.373, Test accuracy: 85.06
Round  52, Train loss: 0.351, Test loss: 0.364, Test accuracy: 85.59
Round  53, Train loss: 0.353, Test loss: 0.376, Test accuracy: 85.38
Round  54, Train loss: 0.356, Test loss: 0.367, Test accuracy: 85.66
Round  55, Train loss: 0.332, Test loss: 0.371, Test accuracy: 85.20
Round  56, Train loss: 0.320, Test loss: 0.364, Test accuracy: 85.53
Round  57, Train loss: 0.297, Test loss: 0.361, Test accuracy: 85.74
Round  58, Train loss: 0.364, Test loss: 0.363, Test accuracy: 85.74
Round  59, Train loss: 0.301, Test loss: 0.359, Test accuracy: 85.98
Round  60, Train loss: 0.294, Test loss: 0.358, Test accuracy: 86.09
Round  61, Train loss: 0.304, Test loss: 0.350, Test accuracy: 86.33
Round  62, Train loss: 0.344, Test loss: 0.349, Test accuracy: 86.37
Round  63, Train loss: 0.291, Test loss: 0.352, Test accuracy: 86.36
Round  64, Train loss: 0.298, Test loss: 0.356, Test accuracy: 86.17
Round  65, Train loss: 0.328, Test loss: 0.355, Test accuracy: 86.38
Round  66, Train loss: 0.330, Test loss: 0.351, Test accuracy: 86.67
Round  67, Train loss: 0.303, Test loss: 0.348, Test accuracy: 86.42
Round  68, Train loss: 0.260, Test loss: 0.354, Test accuracy: 86.05
Round  69, Train loss: 0.304, Test loss: 0.345, Test accuracy: 86.58
Round  70, Train loss: 0.279, Test loss: 0.343, Test accuracy: 86.81
Round  71, Train loss: 0.295, Test loss: 0.340, Test accuracy: 86.89
Round  72, Train loss: 0.284, Test loss: 0.341, Test accuracy: 86.92
Round  73, Train loss: 0.279, Test loss: 0.343, Test accuracy: 86.55
Round  74, Train loss: 0.286, Test loss: 0.341, Test accuracy: 86.70
Round  75, Train loss: 0.262, Test loss: 0.339, Test accuracy: 86.81
Round  76, Train loss: 0.262, Test loss: 0.334, Test accuracy: 86.96
Round  77, Train loss: 0.248, Test loss: 0.337, Test accuracy: 86.89
Round  78, Train loss: 0.268, Test loss: 0.338, Test accuracy: 86.62
Round  79, Train loss: 0.254, Test loss: 0.339, Test accuracy: 86.77
Round  80, Train loss: 0.250, Test loss: 0.335, Test accuracy: 86.91
Round  81, Train loss: 0.255, Test loss: 0.335, Test accuracy: 87.17
Round  82, Train loss: 0.274, Test loss: 0.333, Test accuracy: 87.13
Round  83, Train loss: 0.227, Test loss: 0.334, Test accuracy: 87.00
Round  84, Train loss: 0.256, Test loss: 0.333, Test accuracy: 87.04
Round  85, Train loss: 0.239, Test loss: 0.335, Test accuracy: 87.06
Round  86, Train loss: 0.227, Test loss: 0.335, Test accuracy: 87.26
Round  87, Train loss: 0.237, Test loss: 0.331, Test accuracy: 86.94
Round  88, Train loss: 0.229, Test loss: 0.332, Test accuracy: 87.22
Round  89, Train loss: 0.220, Test loss: 0.329, Test accuracy: 87.33
Round  90, Train loss: 0.224, Test loss: 0.330, Test accuracy: 87.23
Round  91, Train loss: 0.241, Test loss: 0.328, Test accuracy: 87.28
Round  92, Train loss: 0.226, Test loss: 0.323, Test accuracy: 87.51
Round  93, Train loss: 0.216, Test loss: 0.328, Test accuracy: 87.48
Round  94, Train loss: 0.249, Test loss: 0.329, Test accuracy: 87.35
Round  95, Train loss: 0.210, Test loss: 0.329, Test accuracy: 87.43
Round  96, Train loss: 0.209, Test loss: 0.333, Test accuracy: 87.32
Round  97, Train loss: 0.220, Test loss: 0.337, Test accuracy: 87.29
Round  98, Train loss: 0.222, Test loss: 0.339, Test accuracy: 87.24
Round  99, Train loss: 0.213, Test loss: 0.335, Test accuracy: 87.55
Final Round, Train loss: 0.184, Test loss: 0.328, Test accuracy: 87.78
Average accuracy final 10 rounds: 87.36916666666666
2790.6700880527496
[2.171574115753174, 3.9998133182525635, 5.830634832382202, 7.664311170578003, 9.52626895904541, 11.353412866592407, 13.204258918762207, 15.06955075263977, 16.917062759399414, 18.77087688446045, 20.61693024635315, 22.450246572494507, 24.31036114692688, 26.188276052474976, 28.040665864944458, 29.88012719154358, 31.7743136882782, 33.67209768295288, 35.53902769088745, 37.423821449279785, 39.297375202178955, 44.08621883392334, 48.88604402542114, 53.73215985298157, 58.55145883560181, 63.41665744781494, 68.17081785202026, 73.07012581825256, 77.82239007949829, 82.89407396316528, 87.70443320274353, 92.55894017219543, 97.35395741462708, 102.29382824897766, 107.15031576156616, 112.0359525680542, 116.69343733787537, 121.56930541992188, 126.41329026222229, 131.2305817604065, 136.07354140281677, 140.92627477645874, 145.73811745643616, 150.48580813407898, 155.27822732925415, 159.92765140533447, 164.78576970100403, 169.40413975715637, 174.1096751689911, 178.85339164733887, 183.79761385917664, 188.54114174842834, 193.42914700508118, 198.14421844482422, 202.9210410118103, 207.68637084960938, 212.43878507614136, 216.97887325286865, 221.64016795158386, 226.22382855415344, 230.88425612449646, 235.74813675880432, 240.42083644866943, 244.9594006538391, 249.49430322647095, 254.21888518333435, 258.7828257083893, 263.43955969810486, 267.8525867462158, 272.482125043869, 277.00641679763794, 281.7700870037079, 286.33666610717773, 291.06016969680786, 295.63968205451965, 300.23933696746826, 304.77837920188904, 309.1885795593262, 313.8339829444885, 318.2738320827484, 322.8295364379883, 327.23463797569275, 331.8190519809723, 336.39754366874695, 341.0816078186035, 345.6914281845093, 350.4021439552307, 355.17896580696106, 359.83572697639465, 364.32456851005554, 369.00729966163635, 373.71608233451843, 378.3127474784851, 382.96364736557007, 387.4864227771759, 392.3688702583313, 397.0775339603424, 401.94079399108887, 406.60878896713257, 411.4846477508545, 413.7095136642456]
[28.958333333333332, 35.50833333333333, 44.583333333333336, 53.75, 64.51666666666667, 68.96666666666667, 70.71666666666667, 70.25, 71.76666666666667, 74.38333333333334, 73.85833333333333, 75.01666666666667, 75.66666666666667, 76.88333333333334, 76.38333333333334, 77.85833333333333, 76.36666666666666, 76.48333333333333, 76.325, 77.66666666666667, 79.73333333333333, 80.40833333333333, 81.23333333333333, 80.94166666666666, 80.65833333333333, 81.35833333333333, 82.23333333333333, 82.15, 81.75833333333334, 81.26666666666667, 81.43333333333334, 82.00833333333334, 81.825, 82.675, 83.53333333333333, 83.54166666666667, 83.7, 83.65, 83.925, 84.38333333333334, 84.15, 84.45833333333333, 84.73333333333333, 84.96666666666667, 85.025, 84.96666666666667, 85.34166666666667, 85.09166666666667, 85.4, 85.125, 85.33333333333333, 85.05833333333334, 85.59166666666667, 85.38333333333334, 85.65833333333333, 85.2, 85.53333333333333, 85.74166666666666, 85.74166666666666, 85.98333333333333, 86.09166666666667, 86.325, 86.36666666666666, 86.35833333333333, 86.175, 86.375, 86.675, 86.41666666666667, 86.05, 86.58333333333333, 86.80833333333334, 86.89166666666667, 86.91666666666667, 86.55, 86.7, 86.80833333333334, 86.95833333333333, 86.89166666666667, 86.625, 86.76666666666667, 86.90833333333333, 87.175, 87.13333333333334, 87.0, 87.04166666666667, 87.05833333333334, 87.25833333333334, 86.94166666666666, 87.21666666666667, 87.33333333333333, 87.23333333333333, 87.28333333333333, 87.50833333333334, 87.48333333333333, 87.35, 87.43333333333334, 87.31666666666666, 87.29166666666667, 87.24166666666666, 87.55, 87.775]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9491 (0.8542), real noise ratio: 0.8500
Client 2, noise level: 0.3194 (0.2875), real noise ratio: 0.2815
Client 3, noise level: 0.9178 (0.8260), real noise ratio: 0.8215
Client 4, noise level: 0.0319 (0.0287), real noise ratio: 0.0545
Client 6, noise level: 0.6298 (0.5668), real noise ratio: 0.5725
Client 7, noise level: 0.8738 (0.7864), real noise ratio: 0.7950
Client 8, noise level: 0.0087 (0.0078), real noise ratio: 0.0105
Client 9, noise level: 0.7466 (0.6719), real noise ratio: 0.7545
Client 13, noise level: 0.5093 (0.4583), real noise ratio: 0.5110
Client 15, noise level: 0.9556 (0.8600), real noise ratio: 0.8640
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.117, Test loss: 2.072, Test accuracy: 28.64
Round   0, Global train loss: 2.117, Global test loss: 2.084, Global test accuracy: 29.79
Round   1, Train loss: 2.079, Test loss: 1.998, Test accuracy: 33.37
Round   1, Global train loss: 2.079, Global test loss: 1.987, Global test accuracy: 39.21
Round   2, Train loss: 1.979, Test loss: 1.923, Test accuracy: 34.14
Round   2, Global train loss: 1.979, Global test loss: 1.834, Global test accuracy: 40.55
Round   3, Train loss: 2.033, Test loss: 1.948, Test accuracy: 33.32
Round   3, Global train loss: 2.033, Global test loss: 1.979, Global test accuracy: 38.92
Round   4, Train loss: 1.918, Test loss: 1.914, Test accuracy: 33.84
Round   4, Global train loss: 1.918, Global test loss: 1.856, Global test accuracy: 39.49
Round   5, Train loss: 1.874, Test loss: 1.887, Test accuracy: 35.05
Round   5, Global train loss: 1.874, Global test loss: 1.835, Global test accuracy: 44.62
Round   6, Train loss: 1.967, Test loss: 1.882, Test accuracy: 35.31
Round   6, Global train loss: 1.967, Global test loss: 1.897, Global test accuracy: 41.69
Round   7, Train loss: 1.947, Test loss: 1.876, Test accuracy: 35.48
Round   7, Global train loss: 1.947, Global test loss: 1.975, Global test accuracy: 38.24
Round   8, Train loss: 1.769, Test loss: 1.841, Test accuracy: 36.12
Round   8, Global train loss: 1.769, Global test loss: 1.698, Global test accuracy: 41.99
Round   9, Train loss: 2.022, Test loss: 1.864, Test accuracy: 35.66
Round   9, Global train loss: 2.022, Global test loss: 2.015, Global test accuracy: 36.41
Round  10, Train loss: 1.691, Test loss: 1.829, Test accuracy: 36.85
Round  10, Global train loss: 1.691, Global test loss: 1.688, Global test accuracy: 44.65
Round  11, Train loss: 1.843, Test loss: 1.832, Test accuracy: 36.73
Round  11, Global train loss: 1.843, Global test loss: 1.854, Global test accuracy: 41.88
Round  12, Train loss: 1.923, Test loss: 1.842, Test accuracy: 36.81
Round  12, Global train loss: 1.923, Global test loss: 1.928, Global test accuracy: 40.06
Round  13, Train loss: 1.594, Test loss: 1.847, Test accuracy: 36.80
Round  13, Global train loss: 1.594, Global test loss: 1.694, Global test accuracy: 44.00
Round  14, Train loss: 1.693, Test loss: 1.834, Test accuracy: 36.87
Round  14, Global train loss: 1.693, Global test loss: 1.835, Global test accuracy: 41.76
Round  15, Train loss: 1.511, Test loss: 1.838, Test accuracy: 36.84
Round  15, Global train loss: 1.511, Global test loss: 1.660, Global test accuracy: 46.22
Round  16, Train loss: 1.667, Test loss: 1.845, Test accuracy: 36.70
Round  16, Global train loss: 1.667, Global test loss: 1.818, Global test accuracy: 44.67
Round  17, Train loss: 1.804, Test loss: 1.839, Test accuracy: 37.24
Round  17, Global train loss: 1.804, Global test loss: 1.916, Global test accuracy: 38.52
Round  18, Train loss: 1.557, Test loss: 1.837, Test accuracy: 37.69
Round  18, Global train loss: 1.557, Global test loss: 1.602, Global test accuracy: 46.26
Round  19, Train loss: 1.576, Test loss: 1.838, Test accuracy: 37.55
Round  19, Global train loss: 1.576, Global test loss: 1.689, Global test accuracy: 44.69
Round  20, Train loss: 1.591, Test loss: 1.867, Test accuracy: 37.20
Round  20, Global train loss: 1.591, Global test loss: 1.854, Global test accuracy: 40.88
Round  21, Train loss: 1.686, Test loss: 1.862, Test accuracy: 37.38
Round  21, Global train loss: 1.686, Global test loss: 1.794, Global test accuracy: 40.98
Round  22, Train loss: 1.602, Test loss: 1.885, Test accuracy: 36.94
Round  22, Global train loss: 1.602, Global test loss: 1.947, Global test accuracy: 37.10
Round  23, Train loss: 1.608, Test loss: 1.897, Test accuracy: 37.03
Round  23, Global train loss: 1.608, Global test loss: 1.789, Global test accuracy: 42.38
Round  24, Train loss: 1.457, Test loss: 1.905, Test accuracy: 36.94
Round  24, Global train loss: 1.457, Global test loss: 1.813, Global test accuracy: 41.73
Round  25, Train loss: 1.398, Test loss: 1.932, Test accuracy: 36.68
Round  25, Global train loss: 1.398, Global test loss: 1.690, Global test accuracy: 44.66
Round  26, Train loss: 1.695, Test loss: 1.932, Test accuracy: 36.66
Round  26, Global train loss: 1.695, Global test loss: 1.879, Global test accuracy: 40.97
Round  27, Train loss: 1.294, Test loss: 1.966, Test accuracy: 36.26
Round  27, Global train loss: 1.294, Global test loss: 1.685, Global test accuracy: 43.72
Round  28, Train loss: 1.377, Test loss: 1.995, Test accuracy: 36.29
Round  28, Global train loss: 1.377, Global test loss: 1.747, Global test accuracy: 42.80
Round  29, Train loss: 1.352, Test loss: 2.018, Test accuracy: 35.96
Round  29, Global train loss: 1.352, Global test loss: 1.737, Global test accuracy: 44.59
Round  30, Train loss: 1.316, Test loss: 2.036, Test accuracy: 35.86
Round  30, Global train loss: 1.316, Global test loss: 1.858, Global test accuracy: 38.17
Round  31, Train loss: 1.481, Test loss: 2.039, Test accuracy: 36.37
Round  31, Global train loss: 1.481, Global test loss: 1.787, Global test accuracy: 40.45
Round  32, Train loss: 1.386, Test loss: 2.068, Test accuracy: 36.10
Round  32, Global train loss: 1.386, Global test loss: 1.813, Global test accuracy: 42.33
Round  33, Train loss: 1.286, Test loss: 2.083, Test accuracy: 36.17
Round  33, Global train loss: 1.286, Global test loss: 1.828, Global test accuracy: 40.24
Round  34, Train loss: 1.258, Test loss: 2.111, Test accuracy: 35.90
Round  34, Global train loss: 1.258, Global test loss: 1.925, Global test accuracy: 35.23
Round  35, Train loss: 1.178, Test loss: 2.126, Test accuracy: 35.99
Round  35, Global train loss: 1.178, Global test loss: 1.702, Global test accuracy: 45.38
Round  36, Train loss: 1.203, Test loss: 2.174, Test accuracy: 36.09
Round  36, Global train loss: 1.203, Global test loss: 1.833, Global test accuracy: 38.56
Round  37, Train loss: 1.400, Test loss: 2.217, Test accuracy: 35.96
Round  37, Global train loss: 1.400, Global test loss: 2.003, Global test accuracy: 31.98
Round  38, Train loss: 1.146, Test loss: 2.238, Test accuracy: 35.76
Round  38, Global train loss: 1.146, Global test loss: 1.741, Global test accuracy: 39.48
Round  39, Train loss: 1.386, Test loss: 2.263, Test accuracy: 35.80
Round  39, Global train loss: 1.386, Global test loss: 1.943, Global test accuracy: 34.92
Round  40, Train loss: 0.823, Test loss: 2.265, Test accuracy: 36.06
Round  40, Global train loss: 0.823, Global test loss: 1.529, Global test accuracy: 48.65
Round  41, Train loss: 1.498, Test loss: 2.305, Test accuracy: 35.89
Round  41, Global train loss: 1.498, Global test loss: 2.066, Global test accuracy: 26.64
Round  42, Train loss: 1.199, Test loss: 2.368, Test accuracy: 35.58
Round  42, Global train loss: 1.199, Global test loss: 1.952, Global test accuracy: 35.35
Round  43, Train loss: 1.083, Test loss: 2.404, Test accuracy: 35.53
Round  43, Global train loss: 1.083, Global test loss: 1.787, Global test accuracy: 38.35
Round  44, Train loss: 1.078, Test loss: 2.463, Test accuracy: 35.06
Round  44, Global train loss: 1.078, Global test loss: 1.818, Global test accuracy: 38.09
Round  45, Train loss: 1.196, Test loss: 2.497, Test accuracy: 34.84
Round  45, Global train loss: 1.196, Global test loss: 2.031, Global test accuracy: 30.09
Round  46, Train loss: 1.147, Test loss: 2.533, Test accuracy: 34.69
Round  46, Global train loss: 1.147, Global test loss: 1.855, Global test accuracy: 36.06
Round  47, Train loss: 1.054, Test loss: 2.553, Test accuracy: 35.07
Round  47, Global train loss: 1.054, Global test loss: 1.907, Global test accuracy: 35.38
Round  48, Train loss: 0.881, Test loss: 2.596, Test accuracy: 34.86
Round  48, Global train loss: 0.881, Global test loss: 1.728, Global test accuracy: 39.20
Round  49, Train loss: 0.930, Test loss: 2.621, Test accuracy: 34.99
Round  49, Global train loss: 0.930, Global test loss: 1.747, Global test accuracy: 39.19
Round  50, Train loss: 0.904, Test loss: 2.651, Test accuracy: 34.96
Round  50, Global train loss: 0.904, Global test loss: 1.883, Global test accuracy: 36.84
Round  51, Train loss: 0.907, Test loss: 2.698, Test accuracy: 34.84
Round  51, Global train loss: 0.907, Global test loss: 1.816, Global test accuracy: 37.68
Round  52, Train loss: 0.925, Test loss: 2.745, Test accuracy: 34.62
Round  52, Global train loss: 0.925, Global test loss: 1.657, Global test accuracy: 42.79
Round  53, Train loss: 0.922, Test loss: 2.780, Test accuracy: 34.51
Round  53, Global train loss: 0.922, Global test loss: 1.731, Global test accuracy: 39.77
Round  54, Train loss: 0.931, Test loss: 2.800, Test accuracy: 34.54
Round  54, Global train loss: 0.931, Global test loss: 1.907, Global test accuracy: 34.63
Round  55, Train loss: 0.822, Test loss: 2.843, Test accuracy: 34.26
Round  55, Global train loss: 0.822, Global test loss: 1.894, Global test accuracy: 31.85
Round  56, Train loss: 0.927, Test loss: 2.890, Test accuracy: 34.29
Round  56, Global train loss: 0.927, Global test loss: 1.887, Global test accuracy: 35.23
Round  57, Train loss: 0.750, Test loss: 2.909, Test accuracy: 34.31
Round  57, Global train loss: 0.750, Global test loss: 1.634, Global test accuracy: 45.25
Round  58, Train loss: 0.877, Test loss: 2.895, Test accuracy: 34.38
Round  58, Global train loss: 0.877, Global test loss: 1.982, Global test accuracy: 30.62
Round  59, Train loss: 0.922, Test loss: 2.923, Test accuracy: 34.43
Round  59, Global train loss: 0.922, Global test loss: 1.916, Global test accuracy: 32.23
Round  60, Train loss: 0.858, Test loss: 2.949, Test accuracy: 34.33
Round  60, Global train loss: 0.858, Global test loss: 1.991, Global test accuracy: 28.99
Round  61, Train loss: 0.989, Test loss: 3.032, Test accuracy: 33.91
Round  61, Global train loss: 0.989, Global test loss: 2.015, Global test accuracy: 29.97
Round  62, Train loss: 0.901, Test loss: 3.045, Test accuracy: 34.10
Round  62, Global train loss: 0.901, Global test loss: 1.968, Global test accuracy: 31.98
Round  63, Train loss: 0.582, Test loss: 3.108, Test accuracy: 33.74
Round  63, Global train loss: 0.582, Global test loss: 1.712, Global test accuracy: 40.80
Round  64, Train loss: 0.665, Test loss: 3.166, Test accuracy: 33.92
Round  64, Global train loss: 0.665, Global test loss: 1.642, Global test accuracy: 42.23
Round  65, Train loss: 1.025, Test loss: 3.223, Test accuracy: 34.02
Round  65, Global train loss: 1.025, Global test loss: 2.132, Global test accuracy: 26.77
Round  66, Train loss: 0.606, Test loss: 3.179, Test accuracy: 34.32
Round  66, Global train loss: 0.606, Global test loss: 1.602, Global test accuracy: 45.41
Round  67, Train loss: 0.860, Test loss: 3.238, Test accuracy: 34.42
Round  67, Global train loss: 0.860, Global test loss: 1.992, Global test accuracy: 32.50
Round  68, Train loss: 0.779, Test loss: 3.252, Test accuracy: 34.41
Round  68, Global train loss: 0.779, Global test loss: 1.829, Global test accuracy: 37.98
Round  69, Train loss: 0.604, Test loss: 3.268, Test accuracy: 34.21
Round  69, Global train loss: 0.604, Global test loss: 1.873, Global test accuracy: 32.51
Round  70, Train loss: 0.666, Test loss: 3.281, Test accuracy: 34.32
Round  70, Global train loss: 0.666, Global test loss: 1.868, Global test accuracy: 32.85
Round  71, Train loss: 0.663, Test loss: 3.289, Test accuracy: 34.58
Round  71, Global train loss: 0.663, Global test loss: 1.990, Global test accuracy: 31.81
Round  72, Train loss: 0.781, Test loss: 3.359, Test accuracy: 34.42
Round  72, Global train loss: 0.781, Global test loss: 1.871, Global test accuracy: 36.36
Round  73, Train loss: 0.726, Test loss: 3.414, Test accuracy: 34.33
Round  73, Global train loss: 0.726, Global test loss: 1.865, Global test accuracy: 36.06
Round  74, Train loss: 0.807, Test loss: 3.413, Test accuracy: 34.01
Round  74, Global train loss: 0.807, Global test loss: 1.841, Global test accuracy: 37.69
Round  75, Train loss: 0.560, Test loss: 3.432, Test accuracy: 33.91
Round  75, Global train loss: 0.560, Global test loss: 1.693, Global test accuracy: 40.13
Round  76, Train loss: 0.641, Test loss: 3.492, Test accuracy: 33.94
Round  76, Global train loss: 0.641, Global test loss: 2.006, Global test accuracy: 28.20
Round  77, Train loss: 0.634, Test loss: 3.507, Test accuracy: 33.94
Round  77, Global train loss: 0.634, Global test loss: 1.929, Global test accuracy: 31.22
Round  78, Train loss: 0.604, Test loss: 3.560, Test accuracy: 34.16
Round  78, Global train loss: 0.604, Global test loss: 1.774, Global test accuracy: 37.26
Round  79, Train loss: 0.697, Test loss: 3.579, Test accuracy: 34.24
Round  79, Global train loss: 0.697, Global test loss: 1.871, Global test accuracy: 35.69
Round  80, Train loss: 0.610, Test loss: 3.638, Test accuracy: 34.07
Round  80, Global train loss: 0.610, Global test loss: 1.798, Global test accuracy: 38.26
Round  81, Train loss: 0.499, Test loss: 3.671, Test accuracy: 33.93
Round  81, Global train loss: 0.499, Global test loss: 1.718, Global test accuracy: 39.40
Round  82, Train loss: 0.467, Test loss: 3.731, Test accuracy: 34.19
Round  82, Global train loss: 0.467, Global test loss: 1.705, Global test accuracy: 39.96
Round  83, Train loss: 0.824, Test loss: 3.771, Test accuracy: 33.90
Round  83, Global train loss: 0.824, Global test loss: 2.069, Global test accuracy: 26.20
Round  84, Train loss: 0.559, Test loss: 3.801, Test accuracy: 33.60
Round  84, Global train loss: 0.559, Global test loss: 1.703, Global test accuracy: 41.81
Round  85, Train loss: 0.573, Test loss: 3.826, Test accuracy: 33.84
Round  85, Global train loss: 0.573, Global test loss: 1.724, Global test accuracy: 41.61
Round  86, Train loss: 0.605, Test loss: 3.838, Test accuracy: 33.93
Round  86, Global train loss: 0.605, Global test loss: 1.867, Global test accuracy: 35.28
Round  87, Train loss: 0.545, Test loss: 3.815, Test accuracy: 33.89
Round  87, Global train loss: 0.545, Global test loss: 1.785, Global test accuracy: 36.17
Round  88, Train loss: 0.523, Test loss: 3.804, Test accuracy: 34.12
Round  88, Global train loss: 0.523, Global test loss: 1.713, Global test accuracy: 41.70
Round  89, Train loss: 0.565, Test loss: 3.822, Test accuracy: 33.90
Round  89, Global train loss: 0.565, Global test loss: 1.918, Global test accuracy: 36.22
Round  90, Train loss: 0.504, Test loss: 3.840, Test accuracy: 34.10
Round  90, Global train loss: 0.504, Global test loss: 1.847, Global test accuracy: 34.52
Round  91, Train loss: 0.656, Test loss: 3.853, Test accuracy: 33.97
Round  91, Global train loss: 0.656, Global test loss: 2.010, Global test accuracy: 30.73
Round  92, Train loss: 0.590, Test loss: 3.898, Test accuracy: 34.06
Round  92, Global train loss: 0.590, Global test loss: 2.020, Global test accuracy: 27.01
Round  93, Train loss: 0.520, Test loss: 3.966, Test accuracy: 33.87
Round  93, Global train loss: 0.520, Global test loss: 1.799, Global test accuracy: 37.30
Round  94, Train loss: 0.421, Test loss: 3.983, Test accuracy: 33.91
Round  94, Global train loss: 0.421, Global test loss: 1.751, Global test accuracy: 37.72
Round  95, Train loss: 0.570, Test loss: 3.960, Test accuracy: 34.05
Round  95, Global train loss: 0.570, Global test loss: 1.965, Global test accuracy: 30.70
Round  96, Train loss: 0.621, Test loss: 4.003, Test accuracy: 33.77
Round  96, Global train loss: 0.621, Global test loss: 1.970, Global test accuracy: 30.68
Round  97, Train loss: 0.552, Test loss: 4.030, Test accuracy: 33.80
Round  97, Global train loss: 0.552, Global test loss: 1.956, Global test accuracy: 32.00
Round  98, Train loss: 0.561, Test loss: 3.996, Test accuracy: 33.98
Round  98, Global train loss: 0.561, Global test loss: 2.025, Global test accuracy: 29.02
Round  99, Train loss: 0.515, Test loss: 4.096, Test accuracy: 33.88
Round  99, Global train loss: 0.515, Global test loss: 1.918, Global test accuracy: 30.91
Final Round, Train loss: 0.349, Test loss: 4.689, Test accuracy: 33.55
Final Round, Global train loss: 0.349, Global test loss: 1.918, Global test accuracy: 30.91
Average accuracy final 10 rounds: 33.9395 

Average global accuracy final 10 rounds: 32.0585 

6398.351454496384
[5.306052207946777, 10.612104415893555, 15.542138814926147, 20.47217321395874, 25.547046899795532, 30.621920585632324, 35.81015682220459, 40.998393058776855, 46.10401916503906, 51.20964527130127, 56.30956792831421, 61.40949058532715, 66.52802205085754, 71.64655351638794, 76.78420376777649, 81.92185401916504, 87.11418986320496, 92.30652570724487, 97.48465299606323, 102.66278028488159, 107.8464686870575, 113.0301570892334, 118.25796294212341, 123.48576879501343, 128.71549153327942, 133.9452142715454, 139.0490162372589, 144.1528182029724, 149.26897740364075, 154.38513660430908, 159.49001240730286, 164.59488821029663, 169.15403270721436, 173.71317720413208, 178.24106812477112, 182.76895904541016, 187.30373334884644, 191.83850765228271, 196.3955042362213, 200.9525008201599, 205.49823594093323, 210.04397106170654, 214.43913006782532, 218.8342890739441, 223.20835971832275, 227.58243036270142, 232.013325214386, 236.44422006607056, 240.86639046669006, 245.28856086730957, 249.65099382400513, 254.01342678070068, 258.51280999183655, 263.0121932029724, 267.43368577957153, 271.85517835617065, 276.29803442955017, 280.7408905029297, 285.1730020046234, 289.60511350631714, 294.05750155448914, 298.50988960266113, 302.9219100475311, 307.3339304924011, 311.8191194534302, 316.30430841445923, 320.74903988838196, 325.1937713623047, 329.6462411880493, 334.09871101379395, 338.5265612602234, 342.95441150665283, 347.4506664276123, 351.9469213485718, 356.34737062454224, 360.7478199005127, 365.26671409606934, 369.785608291626, 374.219690322876, 378.653772354126, 383.1062533855438, 387.55873441696167, 391.9570779800415, 396.35542154312134, 400.81869196891785, 405.28196239471436, 409.6876292228699, 414.0932960510254, 418.54792737960815, 423.0025587081909, 427.39900946617126, 431.7954602241516, 436.2049322128296, 440.61440420150757, 445.01675748825073, 449.4191107749939, 453.81929636001587, 458.21948194503784, 462.64273858070374, 467.06599521636963, 471.4713406562805, 475.8766860961914, 480.43134117126465, 484.9859962463379, 489.3517029285431, 493.7174096107483, 498.06803607940674, 502.4186625480652, 506.7631371021271, 511.10761165618896, 515.4736120700836, 519.8396124839783, 524.1942756175995, 528.5489387512207, 533.0124430656433, 537.4759473800659, 541.8638026714325, 546.2516579627991, 550.8660380840302, 555.4804182052612, 559.8736069202423, 564.2667956352234, 568.6337096691132, 573.0006237030029, 577.3669612407684, 581.7332987785339, 586.232234954834, 590.731171131134, 595.1058032512665, 599.4804353713989, 604.0127625465393, 608.5450897216797, 612.8801372051239, 617.2151846885681, 621.5725226402283, 625.9298605918884, 630.2699892520905, 634.6101179122925, 639.1403224468231, 643.6705269813538, 648.0116767883301, 652.3528265953064, 656.8627483844757, 661.372670173645, 665.74010181427, 670.107533454895, 674.464243888855, 678.8209543228149, 683.2395031452179, 687.6580519676208, 692.1618480682373, 696.6656441688538, 701.0242252349854, 705.382806301117, 709.7706441879272, 714.1584820747375, 718.5165193080902, 722.8745565414429, 727.4175138473511, 731.9604711532593, 736.5286407470703, 741.0968103408813, 745.5072176456451, 749.9176249504089, 754.3760716915131, 758.8345184326172, 763.1560008525848, 767.4774832725525, 771.8194372653961, 776.1613912582397, 780.5259430408478, 784.8904948234558, 789.2218470573425, 793.5531992912292, 797.8949744701385, 802.2367496490479, 806.7516860961914, 811.266622543335, 815.8318898677826, 820.3971571922302, 824.8563134670258, 829.3154697418213, 833.8952991962433, 838.4751286506653, 843.005777835846, 847.5364270210266, 852.0015184879303, 856.466609954834, 861.0599522590637, 865.6532945632935, 870.2675862312317, 874.8818778991699, 879.4997580051422, 884.1176381111145, 888.7133536338806, 893.3090691566467, 897.7968633174896, 902.2846574783325, 906.7831282615662, 911.2815990447998, 913.5786459445953, 915.8756928443909]
[28.645, 28.645, 33.365, 33.365, 34.1375, 34.1375, 33.32, 33.32, 33.845, 33.845, 35.0475, 35.0475, 35.3075, 35.3075, 35.4775, 35.4775, 36.12, 36.12, 35.6625, 35.6625, 36.855, 36.855, 36.7325, 36.7325, 36.8075, 36.8075, 36.795, 36.795, 36.8725, 36.8725, 36.835, 36.835, 36.6975, 36.6975, 37.24, 37.24, 37.6925, 37.6925, 37.5525, 37.5525, 37.2025, 37.2025, 37.3775, 37.3775, 36.94, 36.94, 37.0275, 37.0275, 36.935, 36.935, 36.6775, 36.6775, 36.655, 36.655, 36.26, 36.26, 36.2875, 36.2875, 35.9575, 35.9575, 35.8625, 35.8625, 36.37, 36.37, 36.1, 36.1, 36.1675, 36.1675, 35.8975, 35.8975, 35.9875, 35.9875, 36.09, 36.09, 35.96, 35.96, 35.7575, 35.7575, 35.8025, 35.8025, 36.0625, 36.0625, 35.89, 35.89, 35.58, 35.58, 35.535, 35.535, 35.0575, 35.0575, 34.8425, 34.8425, 34.69, 34.69, 35.0675, 35.0675, 34.8625, 34.8625, 34.9875, 34.9875, 34.9625, 34.9625, 34.8425, 34.8425, 34.6225, 34.6225, 34.51, 34.51, 34.5425, 34.5425, 34.2625, 34.2625, 34.2875, 34.2875, 34.315, 34.315, 34.38, 34.38, 34.4275, 34.4275, 34.3275, 34.3275, 33.905, 33.905, 34.1025, 34.1025, 33.74, 33.74, 33.92, 33.92, 34.015, 34.015, 34.3225, 34.3225, 34.4225, 34.4225, 34.405, 34.405, 34.2125, 34.2125, 34.3225, 34.3225, 34.5825, 34.5825, 34.42, 34.42, 34.3275, 34.3275, 34.005, 34.005, 33.915, 33.915, 33.935, 33.935, 33.9375, 33.9375, 34.165, 34.165, 34.2375, 34.2375, 34.0725, 34.0725, 33.93, 33.93, 34.1875, 34.1875, 33.895, 33.895, 33.5975, 33.5975, 33.84, 33.84, 33.93, 33.93, 33.89, 33.89, 34.115, 34.115, 33.9025, 33.9025, 34.1, 34.1, 33.9675, 33.9675, 34.0575, 34.0575, 33.87, 33.87, 33.915, 33.915, 34.055, 34.055, 33.77, 33.77, 33.7975, 33.7975, 33.9825, 33.9825, 33.88, 33.88, 33.5525, 33.5525]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9491 (0.8542), real noise ratio: 0.8550
Client 2, noise level: 0.3194 (0.2875), real noise ratio: 0.2845
Client 3, noise level: 0.9178 (0.8260), real noise ratio: 0.8435
Client 4, noise level: 0.0319 (0.0287), real noise ratio: 0.0305
Client 6, noise level: 0.6298 (0.5668), real noise ratio: 0.5555
Client 7, noise level: 0.8738 (0.7864), real noise ratio: 0.7960
Client 8, noise level: 0.0087 (0.0078), real noise ratio: 0.0345
Client 9, noise level: 0.7466 (0.6719), real noise ratio: 0.6735
Client 13, noise level: 0.5093 (0.4583), real noise ratio: 0.4655
Client 15, noise level: 0.9556 (0.8600), real noise ratio: 0.8800
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.259, Test loss: 1.940, Test accuracy: 29.46
Round   0, Global train loss: 1.259, Global test loss: 2.234, Global test accuracy: 20.14
Round   1, Train loss: 1.479, Test loss: 1.726, Test accuracy: 35.51
Round   1, Global train loss: 1.479, Global test loss: 2.155, Global test accuracy: 22.08
Round   2, Train loss: 1.652, Test loss: 1.480, Test accuracy: 49.15
Round   2, Global train loss: 1.652, Global test loss: 2.049, Global test accuracy: 32.58
Round   3, Train loss: 1.372, Test loss: 1.438, Test accuracy: 48.88
Round   3, Global train loss: 1.372, Global test loss: 1.990, Global test accuracy: 30.64
Round   4, Train loss: 1.393, Test loss: 1.427, Test accuracy: 48.92
Round   4, Global train loss: 1.393, Global test loss: 2.017, Global test accuracy: 29.15
Round   5, Train loss: 0.951, Test loss: 1.331, Test accuracy: 52.90
Round   5, Global train loss: 0.951, Global test loss: 2.000, Global test accuracy: 32.84
Round   6, Train loss: 1.072, Test loss: 1.247, Test accuracy: 57.73
Round   6, Global train loss: 1.072, Global test loss: 1.784, Global test accuracy: 39.62
Round   7, Train loss: 0.885, Test loss: 1.294, Test accuracy: 56.41
Round   7, Global train loss: 0.885, Global test loss: 1.868, Global test accuracy: 35.27
Round   8, Train loss: 0.905, Test loss: 1.164, Test accuracy: 59.76
Round   8, Global train loss: 0.905, Global test loss: 1.858, Global test accuracy: 36.67
Round   9, Train loss: 1.404, Test loss: 1.093, Test accuracy: 63.79
Round   9, Global train loss: 1.404, Global test loss: 1.809, Global test accuracy: 40.00
Round  10, Train loss: 1.221, Test loss: 1.052, Test accuracy: 64.62
Round  10, Global train loss: 1.221, Global test loss: 1.871, Global test accuracy: 29.74
Round  11, Train loss: 1.411, Test loss: 1.066, Test accuracy: 64.41
Round  11, Global train loss: 1.411, Global test loss: 1.837, Global test accuracy: 41.46
Round  12, Train loss: 1.296, Test loss: 1.042, Test accuracy: 65.51
Round  12, Global train loss: 1.296, Global test loss: 1.874, Global test accuracy: 35.84
Round  13, Train loss: 1.059, Test loss: 1.014, Test accuracy: 67.02
Round  13, Global train loss: 1.059, Global test loss: 1.795, Global test accuracy: 40.67
Round  14, Train loss: 0.963, Test loss: 1.003, Test accuracy: 67.64
Round  14, Global train loss: 0.963, Global test loss: 1.679, Global test accuracy: 45.34
Round  15, Train loss: 0.973, Test loss: 0.994, Test accuracy: 67.93
Round  15, Global train loss: 0.973, Global test loss: 1.833, Global test accuracy: 35.25
Round  16, Train loss: 1.120, Test loss: 0.977, Test accuracy: 68.39
Round  16, Global train loss: 1.120, Global test loss: 1.766, Global test accuracy: 40.66
Round  17, Train loss: 1.226, Test loss: 0.981, Test accuracy: 68.78
Round  17, Global train loss: 1.226, Global test loss: 1.741, Global test accuracy: 44.09
Round  18, Train loss: 1.079, Test loss: 0.974, Test accuracy: 69.10
Round  18, Global train loss: 1.079, Global test loss: 1.799, Global test accuracy: 40.32
Round  19, Train loss: 1.532, Test loss: 0.967, Test accuracy: 69.36
Round  19, Global train loss: 1.532, Global test loss: 1.803, Global test accuracy: 39.91
Round  20, Train loss: 0.672, Test loss: 0.968, Test accuracy: 68.96
Round  20, Global train loss: 0.672, Global test loss: 1.572, Global test accuracy: 48.66
Round  21, Train loss: 0.934, Test loss: 0.970, Test accuracy: 68.88
Round  21, Global train loss: 0.934, Global test loss: 1.695, Global test accuracy: 42.58
Round  22, Train loss: 0.954, Test loss: 0.977, Test accuracy: 68.15
Round  22, Global train loss: 0.954, Global test loss: 1.701, Global test accuracy: 41.42
Round  23, Train loss: 1.072, Test loss: 0.994, Test accuracy: 67.84
Round  23, Global train loss: 1.072, Global test loss: 1.623, Global test accuracy: 47.58
Round  24, Train loss: 1.003, Test loss: 0.963, Test accuracy: 68.82
Round  24, Global train loss: 1.003, Global test loss: 1.670, Global test accuracy: 45.76
Round  25, Train loss: 1.233, Test loss: 0.960, Test accuracy: 69.49
Round  25, Global train loss: 1.233, Global test loss: 1.768, Global test accuracy: 41.92
Round  26, Train loss: 0.980, Test loss: 0.955, Test accuracy: 69.96
Round  26, Global train loss: 0.980, Global test loss: 1.727, Global test accuracy: 41.18
Round  27, Train loss: 0.813, Test loss: 0.951, Test accuracy: 69.78
Round  27, Global train loss: 0.813, Global test loss: 1.704, Global test accuracy: 42.24
Round  28, Train loss: 1.468, Test loss: 0.971, Test accuracy: 68.72
Round  28, Global train loss: 1.468, Global test loss: 1.837, Global test accuracy: 38.05
Round  29, Train loss: 1.097, Test loss: 0.974, Test accuracy: 68.88
Round  29, Global train loss: 1.097, Global test loss: 1.752, Global test accuracy: 42.41
Round  30, Train loss: 1.114, Test loss: 0.970, Test accuracy: 69.17
Round  30, Global train loss: 1.114, Global test loss: 1.654, Global test accuracy: 46.72
Round  31, Train loss: 0.928, Test loss: 0.961, Test accuracy: 69.60
Round  31, Global train loss: 0.928, Global test loss: 1.618, Global test accuracy: 47.82
Round  32, Train loss: 0.956, Test loss: 0.959, Test accuracy: 68.99
Round  32, Global train loss: 0.956, Global test loss: 1.585, Global test accuracy: 49.77
Round  33, Train loss: 1.163, Test loss: 0.953, Test accuracy: 68.81
Round  33, Global train loss: 1.163, Global test loss: 1.742, Global test accuracy: 41.39
Round  34, Train loss: 1.124, Test loss: 0.960, Test accuracy: 68.46
Round  34, Global train loss: 1.124, Global test loss: 1.813, Global test accuracy: 39.98
Round  35, Train loss: 0.914, Test loss: 0.970, Test accuracy: 68.17
Round  35, Global train loss: 0.914, Global test loss: 1.633, Global test accuracy: 46.98
Round  36, Train loss: 1.078, Test loss: 0.972, Test accuracy: 67.80
Round  36, Global train loss: 1.078, Global test loss: 1.709, Global test accuracy: 41.92
Round  37, Train loss: 0.970, Test loss: 0.978, Test accuracy: 67.58
Round  37, Global train loss: 0.970, Global test loss: 1.610, Global test accuracy: 45.67
Round  38, Train loss: 0.849, Test loss: 0.992, Test accuracy: 67.22
Round  38, Global train loss: 0.849, Global test loss: 1.743, Global test accuracy: 42.45
Round  39, Train loss: 0.704, Test loss: 0.961, Test accuracy: 68.17
Round  39, Global train loss: 0.704, Global test loss: 1.568, Global test accuracy: 48.77
Round  40, Train loss: 1.000, Test loss: 0.978, Test accuracy: 68.29
Round  40, Global train loss: 1.000, Global test loss: 1.608, Global test accuracy: 45.64
Round  41, Train loss: 1.103, Test loss: 0.985, Test accuracy: 67.46
Round  41, Global train loss: 1.103, Global test loss: 1.757, Global test accuracy: 40.44
Round  42, Train loss: 0.726, Test loss: 0.963, Test accuracy: 68.38
Round  42, Global train loss: 0.726, Global test loss: 1.589, Global test accuracy: 47.25
Round  43, Train loss: 0.775, Test loss: 0.969, Test accuracy: 68.42
Round  43, Global train loss: 0.775, Global test loss: 1.572, Global test accuracy: 48.83
Round  44, Train loss: 0.913, Test loss: 0.972, Test accuracy: 68.60
Round  44, Global train loss: 0.913, Global test loss: 1.647, Global test accuracy: 43.69
Round  45, Train loss: 0.785, Test loss: 0.962, Test accuracy: 68.62
Round  45, Global train loss: 0.785, Global test loss: 1.661, Global test accuracy: 44.45
Round  46, Train loss: 0.985, Test loss: 0.997, Test accuracy: 67.78
Round  46, Global train loss: 0.985, Global test loss: 1.763, Global test accuracy: 40.11
Round  47, Train loss: 0.709, Test loss: 1.003, Test accuracy: 67.62
Round  47, Global train loss: 0.709, Global test loss: 1.621, Global test accuracy: 45.56
Round  48, Train loss: 1.005, Test loss: 0.984, Test accuracy: 67.66
Round  48, Global train loss: 1.005, Global test loss: 1.695, Global test accuracy: 42.57
Round  49, Train loss: 0.745, Test loss: 0.998, Test accuracy: 67.45
Round  49, Global train loss: 0.745, Global test loss: 2.130, Global test accuracy: 43.37
Round  50, Train loss: 0.883, Test loss: 0.987, Test accuracy: 68.18
Round  50, Global train loss: 0.883, Global test loss: 1.859, Global test accuracy: 41.57
Round  51, Train loss: 0.839, Test loss: 1.000, Test accuracy: 67.96
Round  51, Global train loss: 0.839, Global test loss: 1.722, Global test accuracy: 43.36
Round  52, Train loss: 1.050, Test loss: 1.016, Test accuracy: 67.25
Round  52, Global train loss: 1.050, Global test loss: 1.854, Global test accuracy: 37.84
Round  53, Train loss: 0.617, Test loss: 1.017, Test accuracy: 67.34
Round  53, Global train loss: 0.617, Global test loss: 1.571, Global test accuracy: 46.98
Round  54, Train loss: 0.743, Test loss: 1.036, Test accuracy: 66.56
Round  54, Global train loss: 0.743, Global test loss: 1.955, Global test accuracy: 42.19
Round  55, Train loss: 0.778, Test loss: 1.051, Test accuracy: 66.23
Round  55, Global train loss: 0.778, Global test loss: 1.633, Global test accuracy: 46.62
Round  56, Train loss: 0.669, Test loss: 1.072, Test accuracy: 65.67
Round  56, Global train loss: 0.669, Global test loss: 1.767, Global test accuracy: 43.71
Round  57, Train loss: 0.603, Test loss: 1.071, Test accuracy: 66.33
Round  57, Global train loss: 0.603, Global test loss: 1.640, Global test accuracy: 46.58
Round  58, Train loss: 0.661, Test loss: 1.071, Test accuracy: 66.62
Round  58, Global train loss: 0.661, Global test loss: 1.588, Global test accuracy: 49.67
Round  59, Train loss: 0.647, Test loss: 1.107, Test accuracy: 66.06
Round  59, Global train loss: 0.647, Global test loss: 1.647, Global test accuracy: 48.97
Round  60, Train loss: 0.796, Test loss: 1.090, Test accuracy: 66.80
Round  60, Global train loss: 0.796, Global test loss: 1.701, Global test accuracy: 45.88
Round  61, Train loss: 0.820, Test loss: 1.112, Test accuracy: 66.54
Round  61, Global train loss: 0.820, Global test loss: 1.726, Global test accuracy: 46.50
Round  62, Train loss: 0.549, Test loss: 1.074, Test accuracy: 66.91
Round  62, Global train loss: 0.549, Global test loss: 1.685, Global test accuracy: 45.30
Round  63, Train loss: 0.755, Test loss: 1.084, Test accuracy: 66.81
Round  63, Global train loss: 0.755, Global test loss: 2.078, Global test accuracy: 36.93
Round  64, Train loss: 0.667, Test loss: 1.111, Test accuracy: 66.11
Round  64, Global train loss: 0.667, Global test loss: 1.698, Global test accuracy: 48.14
Round  65, Train loss: 0.695, Test loss: 1.104, Test accuracy: 67.09
Round  65, Global train loss: 0.695, Global test loss: 1.880, Global test accuracy: 43.90
Round  66, Train loss: 0.542, Test loss: 1.105, Test accuracy: 66.72
Round  66, Global train loss: 0.542, Global test loss: 1.887, Global test accuracy: 46.45
Round  67, Train loss: 0.546, Test loss: 1.136, Test accuracy: 66.23
Round  67, Global train loss: 0.546, Global test loss: 1.607, Global test accuracy: 49.70
Round  68, Train loss: 0.697, Test loss: 1.130, Test accuracy: 66.73
Round  68, Global train loss: 0.697, Global test loss: 1.626, Global test accuracy: 46.41
Round  69, Train loss: 0.737, Test loss: 1.142, Test accuracy: 66.44
Round  69, Global train loss: 0.737, Global test loss: 1.749, Global test accuracy: 41.94
Round  70, Train loss: 0.529, Test loss: 1.141, Test accuracy: 66.61
Round  70, Global train loss: 0.529, Global test loss: 1.775, Global test accuracy: 47.33
Round  71, Train loss: 0.498, Test loss: 1.153, Test accuracy: 66.55
Round  71, Global train loss: 0.498, Global test loss: 1.868, Global test accuracy: 44.61
Round  72, Train loss: 1.173, Test loss: 1.176, Test accuracy: 66.19
Round  72, Global train loss: 1.173, Global test loss: 1.921, Global test accuracy: 36.84
Round  73, Train loss: 0.628, Test loss: 1.184, Test accuracy: 65.93
Round  73, Global train loss: 0.628, Global test loss: 1.832, Global test accuracy: 45.98
Round  74, Train loss: 0.925, Test loss: 1.182, Test accuracy: 66.60
Round  74, Global train loss: 0.925, Global test loss: 1.757, Global test accuracy: 44.05
Round  75, Train loss: 0.895, Test loss: 1.144, Test accuracy: 66.61
Round  75, Global train loss: 0.895, Global test loss: 2.087, Global test accuracy: 38.03
Round  76, Train loss: 0.792, Test loss: 1.164, Test accuracy: 66.23
Round  76, Global train loss: 0.792, Global test loss: 1.974, Global test accuracy: 38.68
Round  77, Train loss: 0.577, Test loss: 1.164, Test accuracy: 66.72
Round  77, Global train loss: 0.577, Global test loss: 1.712, Global test accuracy: 48.83
Round  78, Train loss: 0.560, Test loss: 1.164, Test accuracy: 66.92
Round  78, Global train loss: 0.560, Global test loss: 1.811, Global test accuracy: 43.90
Round  79, Train loss: 0.690, Test loss: 1.208, Test accuracy: 66.47
Round  79, Global train loss: 0.690, Global test loss: 1.746, Global test accuracy: 46.16
Round  80, Train loss: 0.533, Test loss: 1.229, Test accuracy: 66.47
Round  80, Global train loss: 0.533, Global test loss: 1.656, Global test accuracy: 48.33
Round  81, Train loss: 0.702, Test loss: 1.254, Test accuracy: 66.30
Round  81, Global train loss: 0.702, Global test loss: 1.989, Global test accuracy: 38.62
Round  82, Train loss: 0.828, Test loss: 1.233, Test accuracy: 66.38
Round  82, Global train loss: 0.828, Global test loss: 2.061, Global test accuracy: 36.36
Round  83, Train loss: 0.797, Test loss: 1.206, Test accuracy: 66.45
Round  83, Global train loss: 0.797, Global test loss: 1.880, Global test accuracy: 40.53
Round  84, Train loss: 0.708, Test loss: 1.199, Test accuracy: 66.74
Round  84, Global train loss: 0.708, Global test loss: 1.949, Global test accuracy: 41.98
Round  85, Train loss: 0.610, Test loss: 1.221, Test accuracy: 66.25
Round  85, Global train loss: 0.610, Global test loss: 1.918, Global test accuracy: 43.04
Round  86, Train loss: 0.478, Test loss: 1.210, Test accuracy: 66.72
Round  86, Global train loss: 0.478, Global test loss: 1.886, Global test accuracy: 47.77
Round  87, Train loss: 0.549, Test loss: 1.215, Test accuracy: 66.55
Round  87, Global train loss: 0.549, Global test loss: 1.863, Global test accuracy: 46.12
Round  88, Train loss: 0.676, Test loss: 1.249, Test accuracy: 66.37
Round  88, Global train loss: 0.676, Global test loss: 2.137, Global test accuracy: 43.30
Round  89, Train loss: 0.483, Test loss: 1.263, Test accuracy: 66.35
Round  89, Global train loss: 0.483, Global test loss: 1.791, Global test accuracy: 48.10
Round  90, Train loss: 0.765, Test loss: 1.284, Test accuracy: 65.88
Round  90, Global train loss: 0.765, Global test loss: 2.169, Global test accuracy: 37.26
Round  91, Train loss: 0.594, Test loss: 1.298, Test accuracy: 65.42
Round  91, Global train loss: 0.594, Global test loss: 1.871, Global test accuracy: 44.17
Round  92, Train loss: 0.417, Test loss: 1.299, Test accuracy: 65.34
Round  92, Global train loss: 0.417, Global test loss: 2.231, Global test accuracy: 43.72
Round  93, Train loss: 0.423, Test loss: 1.310, Test accuracy: 65.12
Round  93, Global train loss: 0.423, Global test loss: 2.012, Global test accuracy: 49.08
Round  94, Train loss: 0.401, Test loss: 1.310, Test accuracy: 65.22
Round  94, Global train loss: 0.401, Global test loss: 2.117, Global test accuracy: 50.33
Round  95, Train loss: 0.640, Test loss: 1.284, Test accuracy: 65.52
Round  95, Global train loss: 0.640, Global test loss: 1.757, Global test accuracy: 45.24
Round  96, Train loss: 0.526, Test loss: 1.310, Test accuracy: 65.48
Round  96, Global train loss: 0.526, Global test loss: 1.774, Global test accuracy: 44.83
Round  97, Train loss: 0.582, Test loss: 1.271, Test accuracy: 66.56
Round  97, Global train loss: 0.582, Global test loss: 2.069, Global test accuracy: 42.97
Round  98, Train loss: 0.661, Test loss: 1.265, Test accuracy: 66.97
Round  98, Global train loss: 0.661, Global test loss: 2.088, Global test accuracy: 41.02
Round  99, Train loss: 0.581, Test loss: 1.309, Test accuracy: 66.22
Round  99, Global train loss: 0.581, Global test loss: 1.858, Global test accuracy: 44.92
Final Round, Train loss: 0.454, Test loss: 1.545, Test accuracy: 65.57
Final Round, Global train loss: 0.454, Global test loss: 1.858, Global test accuracy: 44.92
Average accuracy final 10 rounds: 65.77333333333333 

Average global accuracy final 10 rounds: 44.3525 

1953.7020943164825
[1.5888469219207764, 3.1776938438415527, 4.496316909790039, 5.814939975738525, 7.137251615524292, 8.459563255310059, 9.778004884719849, 11.096446514129639, 12.452176809310913, 13.807907104492188, 15.133830308914185, 16.45975351333618, 17.785403966903687, 19.11105442047119, 20.475613832473755, 21.84017324447632, 23.17608666419983, 24.51200008392334, 25.82663083076477, 27.1412615776062, 28.44845676422119, 29.75565195083618, 31.14901041984558, 32.54236888885498, 33.87125325202942, 35.20013761520386, 36.50736355781555, 37.814589500427246, 39.127541065216064, 40.44049263000488, 41.79227638244629, 43.144060134887695, 44.652082204818726, 46.160104274749756, 47.63381481170654, 49.10752534866333, 50.558470249176025, 52.00941514968872, 53.44535493850708, 54.88129472732544, 56.31705355644226, 57.75281238555908, 59.276287317276, 60.79976224899292, 62.243322134017944, 63.68688201904297, 65.18530178070068, 66.6837215423584, 68.15510487556458, 69.62648820877075, 71.12466025352478, 72.62283229827881, 73.9523012638092, 75.2817702293396, 76.58777403831482, 77.89377784729004, 79.21027660369873, 80.52677536010742, 81.84146428108215, 83.15615320205688, 84.48348546028137, 85.81081771850586, 87.12806415557861, 88.44531059265137, 89.78466153144836, 91.12401247024536, 92.5087559223175, 93.89349937438965, 95.25556826591492, 96.61763715744019, 98.00466346740723, 99.39168977737427, 100.78463768959045, 102.17758560180664, 103.52269625663757, 104.8678069114685, 106.19973969459534, 107.53167247772217, 108.86012578010559, 110.18857908248901, 111.50749397277832, 112.82640886306763, 114.15006589889526, 115.4737229347229, 116.80951452255249, 118.14530611038208, 119.48960852622986, 120.83391094207764, 122.21875309944153, 123.60359525680542, 124.93230485916138, 126.26101446151733, 127.61352181434631, 128.9660291671753, 130.4070074558258, 131.84798574447632, 133.2308440208435, 134.6137022972107, 135.98064470291138, 137.34758710861206, 138.7407112121582, 140.13383531570435, 141.4827539920807, 142.83167266845703, 144.25326704978943, 145.67486143112183, 147.0468168258667, 148.41877222061157, 149.8522424697876, 151.28571271896362, 152.6879734992981, 154.09023427963257, 155.51222729682922, 156.93422031402588, 158.38054537773132, 159.82687044143677, 161.21535420417786, 162.60383796691895, 164.03528094291687, 165.4667239189148, 166.88332152366638, 168.29991912841797, 169.65878224372864, 171.0176453590393, 172.3567876815796, 173.69593000411987, 175.06505036354065, 176.43417072296143, 177.8548777103424, 179.2755846977234, 180.69294810295105, 182.1103115081787, 183.47553968429565, 184.8407678604126, 186.24638414382935, 187.6520004272461, 189.02499127388, 190.39798212051392, 191.80362105369568, 193.20925998687744, 194.5614037513733, 195.91354751586914, 197.25237274169922, 198.5911979675293, 199.9214792251587, 201.2517604827881, 202.59052991867065, 203.92929935455322, 205.32496976852417, 206.72064018249512, 208.04980397224426, 209.3789677619934, 210.69925498962402, 212.01954221725464, 213.3440089225769, 214.66847562789917, 216.0040693283081, 217.33966302871704, 218.68081545829773, 220.02196788787842, 221.38473439216614, 222.74750089645386, 224.07505178451538, 225.4026026725769, 226.76081657409668, 228.11903047561646, 229.54422855377197, 230.9694266319275, 232.32445883750916, 233.67949104309082, 235.0468020439148, 236.41411304473877, 237.77838110923767, 239.14264917373657, 240.48395895957947, 241.82526874542236, 243.16659593582153, 244.5079231262207, 245.89089465141296, 247.27386617660522, 248.62190914154053, 249.96995210647583, 251.29397320747375, 252.61799430847168, 253.96966910362244, 255.3213438987732, 256.66379714012146, 258.0062503814697, 259.3422338962555, 260.67821741104126, 262.0213327407837, 263.3644480705261, 264.7120521068573, 266.0596561431885, 267.3924026489258, 268.7251491546631, 270.0662965774536, 271.40744400024414, 272.809330701828, 274.21121740341187, 276.52225613594055, 278.83329486846924]
[29.458333333333332, 29.458333333333332, 35.50833333333333, 35.50833333333333, 49.15, 49.15, 48.88333333333333, 48.88333333333333, 48.916666666666664, 48.916666666666664, 52.9, 52.9, 57.725, 57.725, 56.40833333333333, 56.40833333333333, 59.75833333333333, 59.75833333333333, 63.791666666666664, 63.791666666666664, 64.61666666666666, 64.61666666666666, 64.40833333333333, 64.40833333333333, 65.50833333333334, 65.50833333333334, 67.01666666666667, 67.01666666666667, 67.64166666666667, 67.64166666666667, 67.93333333333334, 67.93333333333334, 68.39166666666667, 68.39166666666667, 68.775, 68.775, 69.1, 69.1, 69.35833333333333, 69.35833333333333, 68.95833333333333, 68.95833333333333, 68.88333333333334, 68.88333333333334, 68.15, 68.15, 67.84166666666667, 67.84166666666667, 68.81666666666666, 68.81666666666666, 69.49166666666666, 69.49166666666666, 69.95833333333333, 69.95833333333333, 69.78333333333333, 69.78333333333333, 68.725, 68.725, 68.88333333333334, 68.88333333333334, 69.175, 69.175, 69.6, 69.6, 68.99166666666666, 68.99166666666666, 68.80833333333334, 68.80833333333334, 68.45833333333333, 68.45833333333333, 68.175, 68.175, 67.8, 67.8, 67.575, 67.575, 67.225, 67.225, 68.175, 68.175, 68.29166666666667, 68.29166666666667, 67.45833333333333, 67.45833333333333, 68.38333333333334, 68.38333333333334, 68.41666666666667, 68.41666666666667, 68.6, 68.6, 68.625, 68.625, 67.775, 67.775, 67.625, 67.625, 67.65833333333333, 67.65833333333333, 67.45, 67.45, 68.18333333333334, 68.18333333333334, 67.95833333333333, 67.95833333333333, 67.25, 67.25, 67.34166666666667, 67.34166666666667, 66.55833333333334, 66.55833333333334, 66.23333333333333, 66.23333333333333, 65.675, 65.675, 66.325, 66.325, 66.61666666666666, 66.61666666666666, 66.05833333333334, 66.05833333333334, 66.8, 66.8, 66.54166666666667, 66.54166666666667, 66.90833333333333, 66.90833333333333, 66.80833333333334, 66.80833333333334, 66.10833333333333, 66.10833333333333, 67.09166666666667, 67.09166666666667, 66.725, 66.725, 66.23333333333333, 66.23333333333333, 66.73333333333333, 66.73333333333333, 66.44166666666666, 66.44166666666666, 66.60833333333333, 66.60833333333333, 66.55, 66.55, 66.19166666666666, 66.19166666666666, 65.93333333333334, 65.93333333333334, 66.6, 66.6, 66.60833333333333, 66.60833333333333, 66.23333333333333, 66.23333333333333, 66.71666666666667, 66.71666666666667, 66.925, 66.925, 66.46666666666667, 66.46666666666667, 66.475, 66.475, 66.3, 66.3, 66.38333333333334, 66.38333333333334, 66.45, 66.45, 66.74166666666666, 66.74166666666666, 66.25, 66.25, 66.725, 66.725, 66.55, 66.55, 66.36666666666666, 66.36666666666666, 66.35, 66.35, 65.875, 65.875, 65.41666666666667, 65.41666666666667, 65.34166666666667, 65.34166666666667, 65.125, 65.125, 65.225, 65.225, 65.51666666666667, 65.51666666666667, 65.48333333333333, 65.48333333333333, 66.55833333333334, 66.55833333333334, 66.96666666666667, 66.96666666666667, 66.225, 66.225, 65.56666666666666, 65.56666666666666]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9491 (0.8542), real noise ratio: 0.8550
Client 2, noise level: 0.3194 (0.2875), real noise ratio: 0.2820
Client 3, noise level: 0.9178 (0.8260), real noise ratio: 0.8200
Client 4, noise level: 0.0319 (0.0287), real noise ratio: 0.1870
Client 6, noise level: 0.6298 (0.5668), real noise ratio: 0.5605
Client 7, noise level: 0.8738 (0.7864), real noise ratio: 0.8340
Client 8, noise level: 0.0087 (0.0078), real noise ratio: 0.1800
Client 9, noise level: 0.7466 (0.6719), real noise ratio: 0.7315
Client 13, noise level: 0.5093 (0.4583), real noise ratio: 0.5310
Client 15, noise level: 0.9556 (0.8600), real noise ratio: 0.8655
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.358, Test loss: 2.028, Test accuracy: 27.52
Round   0, Global train loss: 1.358, Global test loss: 2.280, Global test accuracy: 21.32
Round   1, Train loss: 1.348, Test loss: 1.846, Test accuracy: 34.15
Round   1, Global train loss: 1.348, Global test loss: 2.303, Global test accuracy: 20.42
Round   2, Train loss: 1.202, Test loss: 1.433, Test accuracy: 42.18
Round   2, Global train loss: 1.202, Global test loss: 2.050, Global test accuracy: 21.93
Round   3, Train loss: 1.032, Test loss: 1.418, Test accuracy: 48.79
Round   3, Global train loss: 1.032, Global test loss: 2.218, Global test accuracy: 27.98
Round   4, Train loss: 1.045, Test loss: 1.352, Test accuracy: 48.89
Round   4, Global train loss: 1.045, Global test loss: 2.051, Global test accuracy: 26.41
Round   5, Train loss: 0.731, Test loss: 1.271, Test accuracy: 52.73
Round   5, Global train loss: 0.731, Global test loss: 2.071, Global test accuracy: 31.89
Round   6, Train loss: 0.940, Test loss: 1.207, Test accuracy: 53.62
Round   6, Global train loss: 0.940, Global test loss: 1.841, Global test accuracy: 32.97
Round   7, Train loss: 0.730, Test loss: 1.232, Test accuracy: 55.29
Round   7, Global train loss: 0.730, Global test loss: 1.986, Global test accuracy: 34.39
Round   8, Train loss: 0.970, Test loss: 1.120, Test accuracy: 58.52
Round   8, Global train loss: 0.970, Global test loss: 1.868, Global test accuracy: 33.98
Round   9, Train loss: 1.390, Test loss: 1.064, Test accuracy: 62.70
Round   9, Global train loss: 1.390, Global test loss: 1.800, Global test accuracy: 38.72
Round  10, Train loss: 1.072, Test loss: 1.065, Test accuracy: 62.31
Round  10, Global train loss: 1.072, Global test loss: 1.906, Global test accuracy: 31.69
Round  11, Train loss: 0.833, Test loss: 1.029, Test accuracy: 63.71
Round  11, Global train loss: 0.833, Global test loss: 1.713, Global test accuracy: 38.01
Round  12, Train loss: 1.293, Test loss: 1.053, Test accuracy: 63.00
Round  12, Global train loss: 1.293, Global test loss: 1.807, Global test accuracy: 34.87
Round  13, Train loss: 1.263, Test loss: 1.010, Test accuracy: 64.82
Round  13, Global train loss: 1.263, Global test loss: 1.812, Global test accuracy: 36.85
Round  14, Train loss: 0.863, Test loss: 0.989, Test accuracy: 66.07
Round  14, Global train loss: 0.863, Global test loss: 1.613, Global test accuracy: 44.47
Round  15, Train loss: 1.249, Test loss: 0.979, Test accuracy: 66.28
Round  15, Global train loss: 1.249, Global test loss: 1.830, Global test accuracy: 36.15
Round  16, Train loss: 1.178, Test loss: 0.984, Test accuracy: 65.87
Round  16, Global train loss: 1.178, Global test loss: 1.691, Global test accuracy: 40.37
Round  17, Train loss: 1.201, Test loss: 0.977, Test accuracy: 67.03
Round  17, Global train loss: 1.201, Global test loss: 1.705, Global test accuracy: 45.32
Round  18, Train loss: 0.884, Test loss: 0.964, Test accuracy: 67.00
Round  18, Global train loss: 0.884, Global test loss: 1.916, Global test accuracy: 34.02
Round  19, Train loss: 1.255, Test loss: 0.959, Test accuracy: 67.98
Round  19, Global train loss: 1.255, Global test loss: 1.785, Global test accuracy: 41.01
Round  20, Train loss: 1.087, Test loss: 0.946, Test accuracy: 68.46
Round  20, Global train loss: 1.087, Global test loss: 1.638, Global test accuracy: 47.30
Round  21, Train loss: 0.904, Test loss: 0.960, Test accuracy: 67.62
Round  21, Global train loss: 0.904, Global test loss: 1.590, Global test accuracy: 46.22
Round  22, Train loss: 1.231, Test loss: 0.943, Test accuracy: 68.78
Round  22, Global train loss: 1.231, Global test loss: 1.717, Global test accuracy: 41.52
Round  23, Train loss: 1.282, Test loss: 0.970, Test accuracy: 67.47
Round  23, Global train loss: 1.282, Global test loss: 1.675, Global test accuracy: 48.95
Round  24, Train loss: 1.219, Test loss: 0.969, Test accuracy: 66.88
Round  24, Global train loss: 1.219, Global test loss: 1.694, Global test accuracy: 43.91
Round  25, Train loss: 0.993, Test loss: 0.960, Test accuracy: 67.54
Round  25, Global train loss: 0.993, Global test loss: 1.690, Global test accuracy: 44.52
Round  26, Train loss: 1.254, Test loss: 0.954, Test accuracy: 67.22
Round  26, Global train loss: 1.254, Global test loss: 1.684, Global test accuracy: 44.18
Round  27, Train loss: 1.030, Test loss: 0.941, Test accuracy: 68.30
Round  27, Global train loss: 1.030, Global test loss: 1.635, Global test accuracy: 45.77
Round  28, Train loss: 0.950, Test loss: 0.934, Test accuracy: 68.34
Round  28, Global train loss: 0.950, Global test loss: 1.797, Global test accuracy: 39.67
Round  29, Train loss: 0.987, Test loss: 0.950, Test accuracy: 67.70
Round  29, Global train loss: 0.987, Global test loss: 1.755, Global test accuracy: 40.31
Round  30, Train loss: 1.181, Test loss: 0.960, Test accuracy: 67.08
Round  30, Global train loss: 1.181, Global test loss: 1.674, Global test accuracy: 44.43
Round  31, Train loss: 0.910, Test loss: 0.966, Test accuracy: 67.10
Round  31, Global train loss: 0.910, Global test loss: 1.584, Global test accuracy: 48.23
Round  32, Train loss: 0.947, Test loss: 0.962, Test accuracy: 67.05
Round  32, Global train loss: 0.947, Global test loss: 1.490, Global test accuracy: 51.32
Round  33, Train loss: 1.167, Test loss: 0.961, Test accuracy: 66.97
Round  33, Global train loss: 1.167, Global test loss: 1.643, Global test accuracy: 46.30
Round  34, Train loss: 1.056, Test loss: 0.955, Test accuracy: 67.31
Round  34, Global train loss: 1.056, Global test loss: 1.861, Global test accuracy: 36.72
Round  35, Train loss: 1.195, Test loss: 0.931, Test accuracy: 68.25
Round  35, Global train loss: 1.195, Global test loss: 1.637, Global test accuracy: 48.58
Round  36, Train loss: 1.081, Test loss: 0.953, Test accuracy: 67.67
Round  36, Global train loss: 1.081, Global test loss: 1.693, Global test accuracy: 43.41
Round  37, Train loss: 0.888, Test loss: 0.959, Test accuracy: 67.47
Round  37, Global train loss: 0.888, Global test loss: 1.638, Global test accuracy: 44.69
Round  38, Train loss: 0.694, Test loss: 0.934, Test accuracy: 68.24
Round  38, Global train loss: 0.694, Global test loss: 1.669, Global test accuracy: 44.92
Round  39, Train loss: 1.252, Test loss: 0.929, Test accuracy: 68.12
Round  39, Global train loss: 1.252, Global test loss: 1.642, Global test accuracy: 48.53
Round  40, Train loss: 0.899, Test loss: 0.918, Test accuracy: 68.20
Round  40, Global train loss: 0.899, Global test loss: 1.622, Global test accuracy: 45.41
Round  41, Train loss: 0.569, Test loss: 0.928, Test accuracy: 67.53
Round  41, Global train loss: 0.569, Global test loss: 1.615, Global test accuracy: 45.28
Round  42, Train loss: 0.745, Test loss: 0.926, Test accuracy: 68.03
Round  42, Global train loss: 0.745, Global test loss: 1.527, Global test accuracy: 48.65
Round  43, Train loss: 1.035, Test loss: 0.934, Test accuracy: 67.62
Round  43, Global train loss: 1.035, Global test loss: 1.568, Global test accuracy: 48.14
Round  44, Train loss: 0.888, Test loss: 0.933, Test accuracy: 68.22
Round  44, Global train loss: 0.888, Global test loss: 1.700, Global test accuracy: 42.85
Round  45, Train loss: 1.179, Test loss: 0.914, Test accuracy: 68.97
Round  45, Global train loss: 1.179, Global test loss: 1.722, Global test accuracy: 42.03
Round  46, Train loss: 1.009, Test loss: 0.939, Test accuracy: 67.71
Round  46, Global train loss: 1.009, Global test loss: 1.695, Global test accuracy: 43.00
Round  47, Train loss: 0.937, Test loss: 0.954, Test accuracy: 67.03
Round  47, Global train loss: 0.937, Global test loss: 1.748, Global test accuracy: 41.41
Round  48, Train loss: 0.779, Test loss: 0.933, Test accuracy: 67.85
Round  48, Global train loss: 0.779, Global test loss: 1.774, Global test accuracy: 41.86
Round  49, Train loss: 1.025, Test loss: 0.957, Test accuracy: 67.29
Round  49, Global train loss: 1.025, Global test loss: 1.725, Global test accuracy: 42.03
Round  50, Train loss: 0.701, Test loss: 0.998, Test accuracy: 66.30
Round  50, Global train loss: 0.701, Global test loss: 2.131, Global test accuracy: 39.27
Round  51, Train loss: 1.143, Test loss: 0.996, Test accuracy: 66.32
Round  51, Global train loss: 1.143, Global test loss: 1.741, Global test accuracy: 40.56
Round  52, Train loss: 1.072, Test loss: 0.994, Test accuracy: 66.28
Round  52, Global train loss: 1.072, Global test loss: 1.765, Global test accuracy: 39.98
Round  53, Train loss: 0.683, Test loss: 0.989, Test accuracy: 66.80
Round  53, Global train loss: 0.683, Global test loss: 1.640, Global test accuracy: 44.58
Round  54, Train loss: 0.845, Test loss: 0.998, Test accuracy: 66.48
Round  54, Global train loss: 0.845, Global test loss: 1.703, Global test accuracy: 44.30
Round  55, Train loss: 0.787, Test loss: 0.966, Test accuracy: 67.73
Round  55, Global train loss: 0.787, Global test loss: 1.637, Global test accuracy: 45.26
Round  56, Train loss: 0.838, Test loss: 0.986, Test accuracy: 66.83
Round  56, Global train loss: 0.838, Global test loss: 1.857, Global test accuracy: 38.98
Round  57, Train loss: 0.778, Test loss: 0.993, Test accuracy: 66.95
Round  57, Global train loss: 0.778, Global test loss: 1.563, Global test accuracy: 47.79
Round  58, Train loss: 0.649, Test loss: 0.968, Test accuracy: 67.99
Round  58, Global train loss: 0.649, Global test loss: 1.684, Global test accuracy: 47.04
Round  59, Train loss: 0.871, Test loss: 0.971, Test accuracy: 67.48
Round  59, Global train loss: 0.871, Global test loss: 1.599, Global test accuracy: 47.86
Round  60, Train loss: 0.966, Test loss: 0.974, Test accuracy: 67.74
Round  60, Global train loss: 0.966, Global test loss: 1.699, Global test accuracy: 43.64
Round  61, Train loss: 0.659, Test loss: 0.990, Test accuracy: 66.87
Round  61, Global train loss: 0.659, Global test loss: 1.586, Global test accuracy: 49.92
Round  62, Train loss: 0.655, Test loss: 1.025, Test accuracy: 66.91
Round  62, Global train loss: 0.655, Global test loss: 1.698, Global test accuracy: 44.63
Round  63, Train loss: 0.664, Test loss: 1.002, Test accuracy: 67.11
Round  63, Global train loss: 0.664, Global test loss: 2.315, Global test accuracy: 33.76
Round  64, Train loss: 0.805, Test loss: 1.007, Test accuracy: 67.42
Round  64, Global train loss: 0.805, Global test loss: 1.549, Global test accuracy: 50.41
Round  65, Train loss: 0.696, Test loss: 1.006, Test accuracy: 67.38
Round  65, Global train loss: 0.696, Global test loss: 1.654, Global test accuracy: 50.37
Round  66, Train loss: 0.562, Test loss: 1.026, Test accuracy: 66.76
Round  66, Global train loss: 0.562, Global test loss: 1.848, Global test accuracy: 49.05
Round  67, Train loss: 0.544, Test loss: 1.006, Test accuracy: 67.41
Round  67, Global train loss: 0.544, Global test loss: 1.751, Global test accuracy: 49.17
Round  68, Train loss: 0.623, Test loss: 0.999, Test accuracy: 67.44
Round  68, Global train loss: 0.623, Global test loss: 1.657, Global test accuracy: 46.84
Round  69, Train loss: 0.628, Test loss: 1.022, Test accuracy: 66.96
Round  69, Global train loss: 0.628, Global test loss: 1.869, Global test accuracy: 42.13
Round  70, Train loss: 0.470, Test loss: 1.007, Test accuracy: 67.34
Round  70, Global train loss: 0.470, Global test loss: 1.591, Global test accuracy: 48.67
Round  71, Train loss: 0.660, Test loss: 1.030, Test accuracy: 66.88
Round  71, Global train loss: 0.660, Global test loss: 1.767, Global test accuracy: 44.05
Round  72, Train loss: 1.001, Test loss: 1.000, Test accuracy: 68.08
Round  72, Global train loss: 1.001, Global test loss: 1.701, Global test accuracy: 43.69
Round  73, Train loss: 0.775, Test loss: 1.002, Test accuracy: 68.06
Round  73, Global train loss: 0.775, Global test loss: 1.590, Global test accuracy: 50.09
Round  74, Train loss: 0.619, Test loss: 0.977, Test accuracy: 68.79
Round  74, Global train loss: 0.619, Global test loss: 1.726, Global test accuracy: 47.24
Round  75, Train loss: 0.814, Test loss: 1.018, Test accuracy: 68.28
Round  75, Global train loss: 0.814, Global test loss: 1.916, Global test accuracy: 40.59
Round  76, Train loss: 0.679, Test loss: 1.032, Test accuracy: 67.90
Round  76, Global train loss: 0.679, Global test loss: 1.799, Global test accuracy: 43.12
Round  77, Train loss: 0.913, Test loss: 1.030, Test accuracy: 67.63
Round  77, Global train loss: 0.913, Global test loss: 1.656, Global test accuracy: 46.70
Round  78, Train loss: 0.531, Test loss: 1.032, Test accuracy: 67.77
Round  78, Global train loss: 0.531, Global test loss: 1.695, Global test accuracy: 46.13
Round  79, Train loss: 0.915, Test loss: 1.034, Test accuracy: 67.73
Round  79, Global train loss: 0.915, Global test loss: 1.712, Global test accuracy: 44.99
Round  80, Train loss: 0.529, Test loss: 1.052, Test accuracy: 67.83
Round  80, Global train loss: 0.529, Global test loss: 1.726, Global test accuracy: 45.90
Round  81, Train loss: 0.769, Test loss: 1.070, Test accuracy: 67.58
Round  81, Global train loss: 0.769, Global test loss: 1.834, Global test accuracy: 42.33
Round  82, Train loss: 1.091, Test loss: 1.111, Test accuracy: 66.38
Round  82, Global train loss: 1.091, Global test loss: 2.028, Global test accuracy: 34.80
Round  83, Train loss: 0.830, Test loss: 1.141, Test accuracy: 65.44
Round  83, Global train loss: 0.830, Global test loss: 1.924, Global test accuracy: 39.58
Round  84, Train loss: 0.647, Test loss: 1.144, Test accuracy: 65.46
Round  84, Global train loss: 0.647, Global test loss: 1.747, Global test accuracy: 43.96
Round  85, Train loss: 0.541, Test loss: 1.133, Test accuracy: 65.97
Round  85, Global train loss: 0.541, Global test loss: 1.808, Global test accuracy: 44.66
Round  86, Train loss: 0.588, Test loss: 1.142, Test accuracy: 65.94
Round  86, Global train loss: 0.588, Global test loss: 1.701, Global test accuracy: 50.14
Round  87, Train loss: 0.550, Test loss: 1.166, Test accuracy: 65.76
Round  87, Global train loss: 0.550, Global test loss: 1.743, Global test accuracy: 47.64
Round  88, Train loss: 0.717, Test loss: 1.141, Test accuracy: 66.63
Round  88, Global train loss: 0.717, Global test loss: 1.922, Global test accuracy: 44.80
Round  89, Train loss: 0.639, Test loss: 1.147, Test accuracy: 66.29
Round  89, Global train loss: 0.639, Global test loss: 1.749, Global test accuracy: 46.79
Round  90, Train loss: 0.543, Test loss: 1.144, Test accuracy: 66.30
Round  90, Global train loss: 0.543, Global test loss: 2.080, Global test accuracy: 41.99
Round  91, Train loss: 0.843, Test loss: 1.148, Test accuracy: 66.11
Round  91, Global train loss: 0.843, Global test loss: 1.696, Global test accuracy: 47.77
Round  92, Train loss: 0.509, Test loss: 1.155, Test accuracy: 65.68
Round  92, Global train loss: 0.509, Global test loss: 1.704, Global test accuracy: 46.67
Round  93, Train loss: 0.572, Test loss: 1.124, Test accuracy: 66.38
Round  93, Global train loss: 0.572, Global test loss: 1.831, Global test accuracy: 48.73
Round  94, Train loss: 0.962, Test loss: 1.201, Test accuracy: 64.88
Round  94, Global train loss: 0.962, Global test loss: 1.992, Global test accuracy: 40.40
Round  95, Train loss: 0.487, Test loss: 1.182, Test accuracy: 65.24
Round  95, Global train loss: 0.487, Global test loss: 1.777, Global test accuracy: 49.14
Round  96, Train loss: 0.496, Test loss: 1.169, Test accuracy: 65.67
Round  96, Global train loss: 0.496, Global test loss: 1.685, Global test accuracy: 48.63
Round  97, Train loss: 0.896, Test loss: 1.133, Test accuracy: 66.60
Round  97, Global train loss: 0.896, Global test loss: 1.832, Global test accuracy: 42.71
Round  98, Train loss: 0.788, Test loss: 1.137, Test accuracy: 66.44
Round  98, Global train loss: 0.788, Global test loss: 1.966, Global test accuracy: 41.02
Round  99, Train loss: 0.401, Test loss: 1.159, Test accuracy: 65.92
Round  99, Global train loss: 0.401, Global test loss: 2.143, Global test accuracy: 41.67
Final Round, Train loss: 0.529, Test loss: 1.285, Test accuracy: 65.92
Final Round, Global train loss: 0.529, Global test loss: 2.143, Global test accuracy: 41.67
Average accuracy final 10 rounds: 65.92166666666667 

Average global accuracy final 10 rounds: 44.872499999999995 

2029.0105702877045
[1.822544813156128, 3.645089626312256, 5.394254446029663, 7.14341926574707, 8.856544494628906, 10.569669723510742, 12.207023620605469, 13.844377517700195, 15.454699277877808, 17.06502103805542, 18.49206280708313, 19.91910457611084, 21.339756965637207, 22.760409355163574, 24.19607400894165, 25.631738662719727, 27.03960871696472, 28.447478771209717, 29.86017370223999, 31.272868633270264, 32.6869912147522, 34.10111379623413, 35.49690318107605, 36.89269256591797, 38.30506372451782, 39.717434883117676, 41.23125433921814, 42.7450737953186, 44.23280119895935, 45.7205286026001, 47.22711634635925, 48.73370409011841, 50.17914700508118, 51.624589920043945, 53.073211431503296, 54.52183294296265, 56.01853156089783, 57.51523017883301, 58.99417757987976, 60.473124980926514, 61.99335861206055, 63.51359224319458, 64.97719383239746, 66.44079542160034, 67.86602354049683, 69.29125165939331, 70.73951554298401, 72.1877794265747, 73.59890961647034, 75.01003980636597, 76.46959829330444, 77.92915678024292, 79.3563220500946, 80.78348731994629, 82.20251679420471, 83.62154626846313, 85.1312038898468, 86.64086151123047, 88.07806849479675, 89.51527547836304, 90.94834089279175, 92.38140630722046, 93.89143109321594, 95.40145587921143, 96.81520414352417, 98.22895240783691, 99.64657640457153, 101.06420040130615, 102.48277854919434, 103.90135669708252, 105.3134560585022, 106.72555541992188, 108.1597535610199, 109.59395170211792, 111.01565885543823, 112.43736600875854, 113.86118674278259, 115.28500747680664, 116.71196293830872, 118.13891839981079, 119.55313420295715, 120.96735000610352, 122.3706316947937, 123.77391338348389, 125.1823377609253, 126.5907621383667, 128.01861214637756, 129.44646215438843, 130.86536145210266, 132.2842607498169, 133.69655442237854, 135.10884809494019, 136.5215663909912, 137.93428468704224, 139.35142850875854, 140.76857233047485, 142.18927764892578, 143.6099829673767, 145.06373286247253, 146.51748275756836, 147.9796016216278, 149.44172048568726, 150.8316297531128, 152.22153902053833, 153.64158725738525, 155.06163549423218, 156.44980144500732, 157.83796739578247, 159.31169176101685, 160.78541612625122, 162.200603723526, 163.61579132080078, 165.06812119483948, 166.52045106887817, 167.99265480041504, 169.4648585319519, 170.9419002532959, 172.4189419746399, 173.91594648361206, 175.41295099258423, 176.89268803596497, 178.3724250793457, 179.8668417930603, 181.3612585067749, 182.84266018867493, 184.32406187057495, 185.77271938323975, 187.22137689590454, 188.7133538722992, 190.20533084869385, 191.69365286827087, 193.1819748878479, 194.70533633232117, 196.22869777679443, 197.72006034851074, 199.21142292022705, 200.67225694656372, 202.1330909729004, 203.6467432975769, 205.16039562225342, 206.64599585533142, 208.13159608840942, 209.64201188087463, 211.15242767333984, 212.66170048713684, 214.17097330093384, 215.68192791938782, 217.1928825378418, 218.70968341827393, 220.22648429870605, 221.70815324783325, 223.18982219696045, 224.63104152679443, 226.07226085662842, 227.52547550201416, 228.9786901473999, 230.4781985282898, 231.9777069091797, 233.44774961471558, 234.91779232025146, 236.4322531223297, 237.94671392440796, 239.44297432899475, 240.93923473358154, 242.41315698623657, 243.8870792388916, 245.37658023834229, 246.86608123779297, 248.34701991081238, 249.8279585838318, 251.2974615097046, 252.7669644355774, 254.22029852867126, 255.67363262176514, 257.1770167350769, 258.6804008483887, 260.14582204818726, 261.61124324798584, 263.22663140296936, 264.8420195579529, 266.47598457336426, 268.10994958877563, 269.715283870697, 271.3206181526184, 272.95445680618286, 274.5882954597473, 276.2160942554474, 277.84389305114746, 279.50558161735535, 281.16727018356323, 282.8032705783844, 284.43927097320557, 286.0961127281189, 287.7529544830322, 289.4320819377899, 291.1112093925476, 292.75365591049194, 294.3961024284363, 296.0644624233246, 297.7328224182129, 300.5077805519104, 303.2827386856079]
[27.525, 27.525, 34.15, 34.15, 42.18333333333333, 42.18333333333333, 48.791666666666664, 48.791666666666664, 48.891666666666666, 48.891666666666666, 52.725, 52.725, 53.61666666666667, 53.61666666666667, 55.291666666666664, 55.291666666666664, 58.525, 58.525, 62.7, 62.7, 62.30833333333333, 62.30833333333333, 63.708333333333336, 63.708333333333336, 63.0, 63.0, 64.81666666666666, 64.81666666666666, 66.06666666666666, 66.06666666666666, 66.275, 66.275, 65.86666666666666, 65.86666666666666, 67.03333333333333, 67.03333333333333, 67.0, 67.0, 67.98333333333333, 67.98333333333333, 68.45833333333333, 68.45833333333333, 67.625, 67.625, 68.78333333333333, 68.78333333333333, 67.475, 67.475, 66.875, 66.875, 67.54166666666667, 67.54166666666667, 67.21666666666667, 67.21666666666667, 68.3, 68.3, 68.34166666666667, 68.34166666666667, 67.7, 67.7, 67.075, 67.075, 67.1, 67.1, 67.05, 67.05, 66.975, 66.975, 67.30833333333334, 67.30833333333334, 68.25, 68.25, 67.675, 67.675, 67.475, 67.475, 68.24166666666666, 68.24166666666666, 68.125, 68.125, 68.2, 68.2, 67.53333333333333, 67.53333333333333, 68.03333333333333, 68.03333333333333, 67.61666666666666, 67.61666666666666, 68.21666666666667, 68.21666666666667, 68.96666666666667, 68.96666666666667, 67.70833333333333, 67.70833333333333, 67.03333333333333, 67.03333333333333, 67.85, 67.85, 67.29166666666667, 67.29166666666667, 66.3, 66.3, 66.31666666666666, 66.31666666666666, 66.28333333333333, 66.28333333333333, 66.8, 66.8, 66.48333333333333, 66.48333333333333, 67.73333333333333, 67.73333333333333, 66.825, 66.825, 66.95, 66.95, 67.99166666666666, 67.99166666666666, 67.48333333333333, 67.48333333333333, 67.74166666666666, 67.74166666666666, 66.86666666666666, 66.86666666666666, 66.90833333333333, 66.90833333333333, 67.10833333333333, 67.10833333333333, 67.41666666666667, 67.41666666666667, 67.38333333333334, 67.38333333333334, 66.75833333333334, 66.75833333333334, 67.40833333333333, 67.40833333333333, 67.44166666666666, 67.44166666666666, 66.95833333333333, 66.95833333333333, 67.34166666666667, 67.34166666666667, 66.88333333333334, 66.88333333333334, 68.08333333333333, 68.08333333333333, 68.05833333333334, 68.05833333333334, 68.79166666666667, 68.79166666666667, 68.28333333333333, 68.28333333333333, 67.9, 67.9, 67.63333333333334, 67.63333333333334, 67.76666666666667, 67.76666666666667, 67.73333333333333, 67.73333333333333, 67.825, 67.825, 67.58333333333333, 67.58333333333333, 66.375, 66.375, 65.44166666666666, 65.44166666666666, 65.45833333333333, 65.45833333333333, 65.96666666666667, 65.96666666666667, 65.94166666666666, 65.94166666666666, 65.75833333333334, 65.75833333333334, 66.63333333333334, 66.63333333333334, 66.29166666666667, 66.29166666666667, 66.3, 66.3, 66.10833333333333, 66.10833333333333, 65.68333333333334, 65.68333333333334, 66.38333333333334, 66.38333333333334, 64.875, 64.875, 65.24166666666666, 65.24166666666666, 65.66666666666667, 65.66666666666667, 66.6, 66.6, 66.44166666666666, 66.44166666666666, 65.91666666666667, 65.91666666666667, 65.925, 65.925]/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Co-teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9491 (0.8542), real noise ratio: 0.8570
Client 2, noise level: 0.3194 (0.2875), real noise ratio: 0.2925
Client 3, noise level: 0.9178 (0.8260), real noise ratio: 0.8385
Client 4, noise level: 0.0319 (0.0287), real noise ratio: 0.0275
Client 6, noise level: 0.6298 (0.5668), real noise ratio: 0.5690
Client 7, noise level: 0.8738 (0.7864), real noise ratio: 0.7930
Client 8, noise level: 0.0087 (0.0078), real noise ratio: 0.1510
Client 9, noise level: 0.7466 (0.6719), real noise ratio: 0.7105
Client 13, noise level: 0.5093 (0.4583), real noise ratio: 0.5265
Client 15, noise level: 0.9556 (0.8600), real noise ratio: 0.8705
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Round   0, Train loss: 1.478, Test loss: 2.157, Test accuracy: 18.24
Round   1, Train loss: 1.028, Test loss: 1.879, Test accuracy: 33.42
Round   2, Train loss: 0.943, Test loss: 1.269, Test accuracy: 46.99
Round   3, Train loss: 0.773, Test loss: 1.313, Test accuracy: 54.60
Round   4, Train loss: 0.652, Test loss: 1.224, Test accuracy: 55.13
Round   5, Train loss: 0.600, Test loss: 1.104, Test accuracy: 58.27
Round   6, Train loss: 0.602, Test loss: 0.914, Test accuracy: 61.80
Round   7, Train loss: 0.613, Test loss: 1.064, Test accuracy: 61.38
Round   8, Train loss: 0.621, Test loss: 0.835, Test accuracy: 65.69
Round   9, Train loss: 0.718, Test loss: 0.709, Test accuracy: 70.28
Round  10, Train loss: 0.548, Test loss: 0.737, Test accuracy: 69.65
Round  11, Train loss: 0.629, Test loss: 0.692, Test accuracy: 71.25
Round  12, Train loss: 0.701, Test loss: 0.686, Test accuracy: 71.39
Round  13, Train loss: 0.600, Test loss: 0.596, Test accuracy: 74.44
Round  14, Train loss: 0.570, Test loss: 0.574, Test accuracy: 75.38
Round  15, Train loss: 0.606, Test loss: 0.578, Test accuracy: 75.11
Round  16, Train loss: 0.548, Test loss: 0.562, Test accuracy: 75.93
Round  17, Train loss: 0.533, Test loss: 0.546, Test accuracy: 76.89
Round  18, Train loss: 0.548, Test loss: 0.549, Test accuracy: 77.31
Round  19, Train loss: 0.619, Test loss: 0.539, Test accuracy: 77.45
Round  20, Train loss: 0.454, Test loss: 0.517, Test accuracy: 78.53
Round  21, Train loss: 0.466, Test loss: 0.517, Test accuracy: 78.53
Round  22, Train loss: 0.516, Test loss: 0.506, Test accuracy: 78.79
Round  23, Train loss: 0.489, Test loss: 0.498, Test accuracy: 79.41
Round  24, Train loss: 0.495, Test loss: 0.499, Test accuracy: 79.22
Round  25, Train loss: 0.608, Test loss: 0.502, Test accuracy: 79.22
Round  26, Train loss: 0.435, Test loss: 0.493, Test accuracy: 79.61
Round  27, Train loss: 0.393, Test loss: 0.486, Test accuracy: 79.79
Round  28, Train loss: 0.516, Test loss: 0.489, Test accuracy: 79.60
Round  29, Train loss: 0.390, Test loss: 0.496, Test accuracy: 79.48
Round  30, Train loss: 0.611, Test loss: 0.482, Test accuracy: 79.56
Round  31, Train loss: 0.502, Test loss: 0.468, Test accuracy: 80.30
Round  32, Train loss: 0.355, Test loss: 0.466, Test accuracy: 80.09
Round  33, Train loss: 0.468, Test loss: 0.470, Test accuracy: 80.24
Round  34, Train loss: 0.470, Test loss: 0.466, Test accuracy: 80.72
Round  35, Train loss: 0.470, Test loss: 0.459, Test accuracy: 80.98
Round  36, Train loss: 0.476, Test loss: 0.451, Test accuracy: 81.32
Round  37, Train loss: 0.448, Test loss: 0.451, Test accuracy: 81.38
Round  38, Train loss: 0.392, Test loss: 0.442, Test accuracy: 81.78
Round  39, Train loss: 0.332, Test loss: 0.438, Test accuracy: 81.77
Round  40, Train loss: 0.438, Test loss: 0.436, Test accuracy: 82.14
Round  41, Train loss: 0.418, Test loss: 0.432, Test accuracy: 82.00
Round  42, Train loss: 0.343, Test loss: 0.425, Test accuracy: 82.52
Round  43, Train loss: 0.311, Test loss: 0.425, Test accuracy: 82.70
Round  44, Train loss: 0.479, Test loss: 0.430, Test accuracy: 82.44
Round  45, Train loss: 0.333, Test loss: 0.420, Test accuracy: 82.84
Round  46, Train loss: 0.376, Test loss: 0.423, Test accuracy: 82.67
Round  47, Train loss: 0.362, Test loss: 0.427, Test accuracy: 82.58
Round  48, Train loss: 0.288, Test loss: 0.426, Test accuracy: 82.47
Round  49, Train loss: 0.304, Test loss: 0.413, Test accuracy: 83.28
Round  50, Train loss: 0.383, Test loss: 0.413, Test accuracy: 83.22
Round  51, Train loss: 0.379, Test loss: 0.410, Test accuracy: 83.38
Round  52, Train loss: 0.411, Test loss: 0.415, Test accuracy: 83.00
Round  53, Train loss: 0.301, Test loss: 0.410, Test accuracy: 83.13
Round  54, Train loss: 0.250, Test loss: 0.411, Test accuracy: 83.08
Round  55, Train loss: 0.427, Test loss: 0.408, Test accuracy: 83.04
Round  56, Train loss: 0.274, Test loss: 0.406, Test accuracy: 83.38
Round  57, Train loss: 0.370, Test loss: 0.402, Test accuracy: 83.76
Round  58, Train loss: 0.351, Test loss: 0.396, Test accuracy: 84.12
Round  59, Train loss: 0.245, Test loss: 0.397, Test accuracy: 84.22
Round  60, Train loss: 0.302, Test loss: 0.392, Test accuracy: 84.31
Round  61, Train loss: 0.423, Test loss: 0.393, Test accuracy: 84.19
Round  62, Train loss: 0.289, Test loss: 0.390, Test accuracy: 84.35
Round  63, Train loss: 0.302, Test loss: 0.406, Test accuracy: 83.58
Round  64, Train loss: 0.415, Test loss: 0.393, Test accuracy: 84.17
Round  65, Train loss: 0.322, Test loss: 0.401, Test accuracy: 83.87
Round  66, Train loss: 0.274, Test loss: 0.405, Test accuracy: 83.79
Round  67, Train loss: 0.273, Test loss: 0.402, Test accuracy: 83.83
Round  68, Train loss: 0.320, Test loss: 0.398, Test accuracy: 83.78
Round  69, Train loss: 0.267, Test loss: 0.384, Test accuracy: 84.45
Round  70, Train loss: 0.214, Test loss: 0.388, Test accuracy: 84.49
Round  71, Train loss: 0.212, Test loss: 0.391, Test accuracy: 84.33
Round  72, Train loss: 0.421, Test loss: 0.398, Test accuracy: 83.70
Round  73, Train loss: 0.285, Test loss: 0.392, Test accuracy: 84.32
Round  74, Train loss: 0.354, Test loss: 0.384, Test accuracy: 84.67
Round  75, Train loss: 0.262, Test loss: 0.392, Test accuracy: 84.24
Round  76, Train loss: 0.309, Test loss: 0.385, Test accuracy: 84.32
Round  77, Train loss: 0.255, Test loss: 0.381, Test accuracy: 84.81
Round  78, Train loss: 0.270, Test loss: 0.392, Test accuracy: 84.27
Round  79, Train loss: 0.292, Test loss: 0.388, Test accuracy: 84.66
Round  80, Train loss: 0.179, Test loss: 0.396, Test accuracy: 84.22
Round  81, Train loss: 0.263, Test loss: 0.388, Test accuracy: 84.78
Round  82, Train loss: 0.268, Test loss: 0.386, Test accuracy: 84.77
Round  83, Train loss: 0.318, Test loss: 0.387, Test accuracy: 84.38
Round  84, Train loss: 0.214, Test loss: 0.384, Test accuracy: 84.88
Round  85, Train loss: 0.223, Test loss: 0.382, Test accuracy: 85.04
Round  86, Train loss: 0.215, Test loss: 0.387, Test accuracy: 84.95
Round  87, Train loss: 0.280, Test loss: 0.383, Test accuracy: 84.86
Round  88, Train loss: 0.260, Test loss: 0.391, Test accuracy: 84.65
Round  89, Train loss: 0.308, Test loss: 0.383, Test accuracy: 84.65
Round  90, Train loss: 0.312, Test loss: 0.392, Test accuracy: 84.47
Round  91, Train loss: 0.302, Test loss: 0.381, Test accuracy: 85.12
Round  92, Train loss: 0.183, Test loss: 0.381, Test accuracy: 85.03
Round  93, Train loss: 0.257, Test loss: 0.382, Test accuracy: 85.06
Round  94, Train loss: 0.198, Test loss: 0.393, Test accuracy: 84.57
Round  95, Train loss: 0.306, Test loss: 0.380, Test accuracy: 84.83
Round  96, Train loss: 0.207, Test loss: 0.380, Test accuracy: 85.12
Round  97, Train loss: 0.284, Test loss: 0.386, Test accuracy: 85.12
Round  98, Train loss: 0.190, Test loss: 0.386, Test accuracy: 84.90
Round  99, Train loss: 0.210, Test loss: 0.380, Test accuracy: 85.62
Final Round, Train loss: 0.198, Test loss: 0.380, Test accuracy: 85.73
Average accuracy final 10 rounds: 84.985
1420.3988182544708
[2.1157641410827637, 3.962470054626465, 5.781735181808472, 7.59981632232666, 9.437915802001953, 11.281258821487427, 13.108482360839844, 14.958766222000122, 16.77408790588379, 18.583557605743408, 20.410322904586792, 22.253777265548706, 24.08684515953064, 25.935225248336792, 27.749956369400024, 29.569971084594727, 31.399290561676025, 33.06003499031067, 34.75282692909241, 36.42003130912781, 38.09798812866211, 39.78033638000488, 41.45823097229004, 43.14957022666931, 44.85089111328125, 46.550508975982666, 48.21978950500488, 49.89287304878235, 51.573174715042114, 53.27919411659241, 55.00623369216919, 56.691157817840576, 58.356640100479126, 60.0558979511261, 61.73092031478882, 63.38606524467468, 65.06076788902283, 66.78029823303223, 68.47697496414185, 70.15298509597778, 71.83873677253723, 73.50861287117004, 75.22660493850708, 77.05968689918518, 78.8963634967804, 80.73409652709961, 82.54393196105957, 84.23312163352966, 85.91153693199158, 87.5944173336029, 89.26332712173462, 90.97324180603027, 92.67519640922546, 94.40300846099854, 96.09442234039307, 97.76119303703308, 99.41740322113037, 101.13513326644897, 102.84075546264648, 104.51657462120056, 106.1869900226593, 107.88495993614197, 109.58383250236511, 111.27343082427979, 112.95553994178772, 114.66117572784424, 116.3477897644043, 118.06256461143494, 119.76791048049927, 121.45388674736023, 123.10608625411987, 124.77264285087585, 126.430668592453, 128.10899090766907, 129.78690266609192, 131.4580729007721, 133.10975885391235, 134.7517659664154, 136.42668890953064, 138.10585761070251, 139.77136039733887, 141.47696805000305, 143.13112926483154, 144.8074402809143, 146.48236751556396, 148.18023824691772, 149.83733415603638, 151.49585914611816, 153.15743708610535, 154.82169890403748, 156.46384596824646, 158.12021946907043, 159.813640832901, 161.50099754333496, 163.15623569488525, 164.81938099861145, 166.49535489082336, 168.15619659423828, 169.82504796981812, 171.4865734577179, 173.6648666858673]
[18.241666666666667, 33.416666666666664, 46.99166666666667, 54.6, 55.13333333333333, 58.275, 61.8, 61.38333333333333, 65.69166666666666, 70.28333333333333, 69.65, 71.25, 71.39166666666667, 74.44166666666666, 75.38333333333334, 75.10833333333333, 75.93333333333334, 76.89166666666667, 77.30833333333334, 77.45, 78.53333333333333, 78.525, 78.79166666666667, 79.40833333333333, 79.225, 79.225, 79.60833333333333, 79.79166666666667, 79.6, 79.48333333333333, 79.55833333333334, 80.3, 80.09166666666667, 80.24166666666666, 80.71666666666667, 80.98333333333333, 81.31666666666666, 81.38333333333334, 81.78333333333333, 81.76666666666667, 82.14166666666667, 82.0, 82.51666666666667, 82.7, 82.44166666666666, 82.84166666666667, 82.675, 82.575, 82.475, 83.275, 83.225, 83.375, 83.0, 83.13333333333334, 83.075, 83.04166666666667, 83.375, 83.75833333333334, 84.11666666666666, 84.21666666666667, 84.30833333333334, 84.19166666666666, 84.35, 83.575, 84.175, 83.86666666666666, 83.79166666666667, 83.83333333333333, 83.78333333333333, 84.45, 84.49166666666666, 84.325, 83.7, 84.31666666666666, 84.675, 84.24166666666666, 84.31666666666666, 84.80833333333334, 84.26666666666667, 84.65833333333333, 84.225, 84.775, 84.76666666666667, 84.375, 84.875, 85.04166666666667, 84.95, 84.85833333333333, 84.65, 84.65, 84.475, 85.11666666666666, 85.03333333333333, 85.05833333333334, 84.56666666666666, 84.83333333333333, 85.11666666666666, 85.125, 84.9, 85.625, 85.73333333333333]
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9491 (0.8542), real noise ratio: 0.8470
Client 2, noise level: 0.3194 (0.2875), real noise ratio: 0.3430
Client 3, noise level: 0.9178 (0.8260), real noise ratio: 0.8370
Client 4, noise level: 0.0319 (0.0287), real noise ratio: 0.0315
Client 6, noise level: 0.6298 (0.5668), real noise ratio: 0.5615
Client 7, noise level: 0.8738 (0.7864), real noise ratio: 0.7855
Client 8, noise level: 0.0087 (0.0078), real noise ratio: 0.1220
Client 9, noise level: 0.7466 (0.6719), real noise ratio: 0.7100
Client 13, noise level: 0.5093 (0.4583), real noise ratio: 0.4850
Client 15, noise level: 0.9556 (0.8600), real noise ratio: 0.8735
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Round 0 global test acc  20.2300
Traceback (most recent call last):
  File "RFL.py", line 126, in <module>
    w_local, loss_local, f_k = local.train(copy.deepcopy(net_glob).to(args.device), copy.deepcopy(f_G).to(args.device),
  File "/home/ChenSM/code/FL_HLS/util/local_training.py", line 257, in train
    for batch_idx, (images, labels, idxs) in enumerate(self.ldr_train_tmp):
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/code/FL_HLS/util/local_training.py", line 48, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 51009 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9491 (0.8542), real noise ratio: 0.8500
Client 2, noise level: 0.3194 (0.2875), real noise ratio: 0.4030
Client 3, noise level: 0.9178 (0.8260), real noise ratio: 0.8270
Client 4, noise level: 0.0319 (0.0287), real noise ratio: 0.1440
Client 6, noise level: 0.6298 (0.5668), real noise ratio: 0.5965
Client 7, noise level: 0.8738 (0.7864), real noise ratio: 0.7900
Client 8, noise level: 0.0087 (0.0078), real noise ratio: 0.1945
Client 9, noise level: 0.7466 (0.6719), real noise ratio: 0.6915
Client 13, noise level: 0.5093 (0.4583), real noise ratio: 0.5470
Client 15, noise level: 0.9556 (0.8600), real noise ratio: 0.8715
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Traceback (most recent call last):
  File "main_fedpac.py", line 232, in <module>
    w_local, loss, indd, class_center_local, class_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1272, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 51282 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.4 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9491 (0.8542), real noise ratio: 0.8540
Client 2, noise level: 0.3194 (0.2875), real noise ratio: 0.3410
Client 3, noise level: 0.9178 (0.8260), real noise ratio: 0.8270
Client 4, noise level: 0.0319 (0.0287), real noise ratio: 0.1155
Client 6, noise level: 0.6298 (0.5668), real noise ratio: 0.6545
Client 7, noise level: 0.8738 (0.7864), real noise ratio: 0.8040
Client 8, noise level: 0.0087 (0.0078), real noise ratio: 0.0425
Client 9, noise level: 0.7466 (0.6719), real noise ratio: 0.7135
Client 13, noise level: 0.5093 (0.4583), real noise ratio: 0.5195
Client 15, noise level: 0.9556 (0.8600), real noise ratio: 0.8735
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Traceback (most recent call last):
  File "main_fedpac_psl.py", line 235, in <module>
    w_local, loss, indd, class_center_local, class_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx], iter_num_now = iter, train_iter=iter)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1977, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train_local):
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 51683 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9745 (0.8771), real noise ratio: 0.8715
Client 2, noise level: 0.6597 (0.5937), real noise ratio: 0.5855
Client 3, noise level: 0.9589 (0.8630), real noise ratio: 0.8650
Client 4, noise level: 0.5160 (0.4644), real noise ratio: 0.5595
Client 6, noise level: 0.8149 (0.7334), real noise ratio: 0.7720
Client 7, noise level: 0.9369 (0.8432), real noise ratio: 0.8440
Client 8, noise level: 0.5044 (0.4539), real noise ratio: 0.5465
Client 9, noise level: 0.8733 (0.7860), real noise ratio: 0.8015
Client 13, noise level: 0.7546 (0.6792), real noise ratio: 0.7230
Client 15, noise level: 0.9778 (0.8800), real noise ratio: 0.8895
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.146, Test loss: 2.177, Test accuracy: 24.33
Round   0, Global train loss: 2.146, Global test loss: 2.182, Global test accuracy: 24.78
Round   1, Train loss: 2.175, Test loss: 2.138, Test accuracy: 27.06
Round   1, Global train loss: 2.175, Global test loss: 2.148, Global test accuracy: 29.02
Round   2, Train loss: 1.928, Test loss: 1.968, Test accuracy: 31.84
Round   2, Global train loss: 1.928, Global test loss: 1.814, Global test accuracy: 38.92
Round   3, Train loss: 2.059, Test loss: 2.005, Test accuracy: 33.15
Round   3, Global train loss: 2.059, Global test loss: 1.956, Global test accuracy: 44.19
Round   4, Train loss: 1.994, Test loss: 1.977, Test accuracy: 31.82
Round   4, Global train loss: 1.994, Global test loss: 1.954, Global test accuracy: 36.88
Round   5, Train loss: 2.198, Test loss: 2.009, Test accuracy: 31.20
Round   5, Global train loss: 2.198, Global test loss: 2.200, Global test accuracy: 33.35
Round   6, Train loss: 2.010, Test loss: 1.959, Test accuracy: 32.48
Round   6, Global train loss: 2.010, Global test loss: 1.973, Global test accuracy: 42.47
Round   7, Train loss: 1.903, Test loss: 1.952, Test accuracy: 32.83
Round   7, Global train loss: 1.903, Global test loss: 2.014, Global test accuracy: 41.45
Round   8, Train loss: 1.854, Test loss: 1.936, Test accuracy: 32.77
Round   8, Global train loss: 1.854, Global test loss: 1.813, Global test accuracy: 41.60
Round   9, Train loss: 1.820, Test loss: 1.942, Test accuracy: 32.98
Round   9, Global train loss: 1.820, Global test loss: 1.818, Global test accuracy: 42.32
Round  10, Train loss: 1.821, Test loss: 1.944, Test accuracy: 33.28
Round  10, Global train loss: 1.821, Global test loss: 1.954, Global test accuracy: 36.74
Round  11, Train loss: 1.677, Test loss: 1.918, Test accuracy: 33.84
Round  11, Global train loss: 1.677, Global test loss: 1.852, Global test accuracy: 39.80
Round  12, Train loss: 1.734, Test loss: 1.925, Test accuracy: 33.61
Round  12, Global train loss: 1.734, Global test loss: 1.625, Global test accuracy: 48.55
Round  13, Train loss: 1.795, Test loss: 1.922, Test accuracy: 33.92
Round  13, Global train loss: 1.795, Global test loss: 1.866, Global test accuracy: 38.43
Round  14, Train loss: 1.880, Test loss: 1.919, Test accuracy: 33.95
Round  14, Global train loss: 1.880, Global test loss: 1.941, Global test accuracy: 42.63
Round  15, Train loss: 1.721, Test loss: 1.921, Test accuracy: 33.93
Round  15, Global train loss: 1.721, Global test loss: 1.828, Global test accuracy: 40.93
Round  16, Train loss: 1.755, Test loss: 1.924, Test accuracy: 33.74
Round  16, Global train loss: 1.755, Global test loss: 1.929, Global test accuracy: 33.04
Round  17, Train loss: 1.792, Test loss: 1.938, Test accuracy: 33.34
Round  17, Global train loss: 1.792, Global test loss: 2.081, Global test accuracy: 30.77
Round  18, Train loss: 1.760, Test loss: 1.940, Test accuracy: 33.08
Round  18, Global train loss: 1.760, Global test loss: 1.768, Global test accuracy: 49.47
Round  19, Train loss: 1.839, Test loss: 1.957, Test accuracy: 33.07
Round  19, Global train loss: 1.839, Global test loss: 2.087, Global test accuracy: 30.84
Round  20, Train loss: 1.753, Test loss: 1.956, Test accuracy: 33.33
Round  20, Global train loss: 1.753, Global test loss: 2.072, Global test accuracy: 30.45
Round  21, Train loss: 1.738, Test loss: 1.974, Test accuracy: 32.89
Round  21, Global train loss: 1.738, Global test loss: 1.870, Global test accuracy: 43.00
Round  22, Train loss: 1.797, Test loss: 1.982, Test accuracy: 32.88
Round  22, Global train loss: 1.797, Global test loss: 1.964, Global test accuracy: 40.47
Round  23, Train loss: 1.336, Test loss: 2.012, Test accuracy: 32.63
Round  23, Global train loss: 1.336, Global test loss: 1.652, Global test accuracy: 45.16
Round  24, Train loss: 1.738, Test loss: 2.025, Test accuracy: 32.61
Round  24, Global train loss: 1.738, Global test loss: 1.996, Global test accuracy: 37.68
Round  25, Train loss: 1.429, Test loss: 2.066, Test accuracy: 32.40
Round  25, Global train loss: 1.429, Global test loss: 1.878, Global test accuracy: 33.78
Round  26, Train loss: 1.589, Test loss: 2.087, Test accuracy: 32.12
Round  26, Global train loss: 1.589, Global test loss: 1.943, Global test accuracy: 33.78
Round  27, Train loss: 1.433, Test loss: 2.104, Test accuracy: 32.14
Round  27, Global train loss: 1.433, Global test loss: 2.004, Global test accuracy: 32.73
Round  28, Train loss: 1.224, Test loss: 2.124, Test accuracy: 32.09
Round  28, Global train loss: 1.224, Global test loss: 1.656, Global test accuracy: 46.91
Round  29, Train loss: 1.307, Test loss: 2.148, Test accuracy: 32.27
Round  29, Global train loss: 1.307, Global test loss: 1.822, Global test accuracy: 35.70
Round  30, Train loss: 1.664, Test loss: 2.164, Test accuracy: 32.06
Round  30, Global train loss: 1.664, Global test loss: 2.072, Global test accuracy: 30.41
Round  31, Train loss: 1.623, Test loss: 2.184, Test accuracy: 31.77
Round  31, Global train loss: 1.623, Global test loss: 2.063, Global test accuracy: 35.82
Round  32, Train loss: 1.286, Test loss: 2.224, Test accuracy: 31.73
Round  32, Global train loss: 1.286, Global test loss: 1.914, Global test accuracy: 32.27
Round  33, Train loss: 1.200, Test loss: 2.257, Test accuracy: 31.23
Round  33, Global train loss: 1.200, Global test loss: 1.607, Global test accuracy: 47.25
Round  34, Train loss: 1.380, Test loss: 2.258, Test accuracy: 31.45
Round  34, Global train loss: 1.380, Global test loss: 1.847, Global test accuracy: 38.95
Round  35, Train loss: 1.330, Test loss: 2.287, Test accuracy: 31.41
Round  35, Global train loss: 1.330, Global test loss: 1.863, Global test accuracy: 41.05
Round  36, Train loss: 1.124, Test loss: 2.300, Test accuracy: 31.52
Round  36, Global train loss: 1.124, Global test loss: 1.919, Global test accuracy: 33.00
Round  37, Train loss: 1.362, Test loss: 2.320, Test accuracy: 31.19
Round  37, Global train loss: 1.362, Global test loss: 1.859, Global test accuracy: 37.55
Round  38, Train loss: 1.099, Test loss: 2.366, Test accuracy: 31.33
Round  38, Global train loss: 1.099, Global test loss: 1.956, Global test accuracy: 29.00
Round  39, Train loss: 1.291, Test loss: 2.404, Test accuracy: 31.31
Round  39, Global train loss: 1.291, Global test loss: 1.963, Global test accuracy: 30.52
Round  40, Train loss: 1.705, Test loss: 2.443, Test accuracy: 30.94
Round  40, Global train loss: 1.705, Global test loss: 2.098, Global test accuracy: 32.69
Round  41, Train loss: 0.921, Test loss: 2.496, Test accuracy: 30.36
Round  41, Global train loss: 0.921, Global test loss: 1.618, Global test accuracy: 43.94
Round  42, Train loss: 1.184, Test loss: 2.507, Test accuracy: 30.61
Round  42, Global train loss: 1.184, Global test loss: 1.757, Global test accuracy: 38.40
Round  43, Train loss: 1.188, Test loss: 2.536, Test accuracy: 30.35
Round  43, Global train loss: 1.188, Global test loss: 1.913, Global test accuracy: 33.14
Round  44, Train loss: 1.304, Test loss: 2.570, Test accuracy: 30.05
Round  44, Global train loss: 1.304, Global test loss: 1.969, Global test accuracy: 29.23
Round  45, Train loss: 0.898, Test loss: 2.593, Test accuracy: 30.43
Round  45, Global train loss: 0.898, Global test loss: 1.586, Global test accuracy: 47.86
Round  46, Train loss: 1.157, Test loss: 2.630, Test accuracy: 30.55
Round  46, Global train loss: 1.157, Global test loss: 1.986, Global test accuracy: 33.24
Round  47, Train loss: 1.098, Test loss: 2.688, Test accuracy: 30.58
Round  47, Global train loss: 1.098, Global test loss: 1.843, Global test accuracy: 36.16
Round  48, Train loss: 1.207, Test loss: 2.699, Test accuracy: 30.55
Round  48, Global train loss: 1.207, Global test loss: 1.891, Global test accuracy: 38.62
Round  49, Train loss: 1.371, Test loss: 2.765, Test accuracy: 30.19
Round  49, Global train loss: 1.371, Global test loss: 2.083, Global test accuracy: 34.13
Round  50, Train loss: 1.447, Test loss: 2.791, Test accuracy: 30.38
Round  50, Global train loss: 1.447, Global test loss: 2.173, Global test accuracy: 22.45
Round  51, Train loss: 1.030, Test loss: 2.835, Test accuracy: 30.34
Round  51, Global train loss: 1.030, Global test loss: 1.911, Global test accuracy: 32.69
Round  52, Train loss: 1.137, Test loss: 2.906, Test accuracy: 30.03
Round  52, Global train loss: 1.137, Global test loss: 1.936, Global test accuracy: 33.38
Round  53, Train loss: 1.003, Test loss: 2.922, Test accuracy: 29.97
Round  53, Global train loss: 1.003, Global test loss: 1.954, Global test accuracy: 31.48
Round  54, Train loss: 1.122, Test loss: 2.976, Test accuracy: 29.86
Round  54, Global train loss: 1.122, Global test loss: 1.823, Global test accuracy: 40.39
Round  55, Train loss: 1.263, Test loss: 3.024, Test accuracy: 29.80
Round  55, Global train loss: 1.263, Global test loss: 2.062, Global test accuracy: 31.20
Round  56, Train loss: 0.965, Test loss: 3.078, Test accuracy: 29.75
Round  56, Global train loss: 0.965, Global test loss: 2.013, Global test accuracy: 31.24
Round  57, Train loss: 1.040, Test loss: 3.097, Test accuracy: 29.81
Round  57, Global train loss: 1.040, Global test loss: 2.096, Global test accuracy: 22.58
Round  58, Train loss: 0.958, Test loss: 3.103, Test accuracy: 29.70
Round  58, Global train loss: 0.958, Global test loss: 1.988, Global test accuracy: 29.30
Round  59, Train loss: 0.891, Test loss: 3.175, Test accuracy: 29.69
Round  59, Global train loss: 0.891, Global test loss: 1.997, Global test accuracy: 28.18
Round  60, Train loss: 1.069, Test loss: 3.199, Test accuracy: 29.44
Round  60, Global train loss: 1.069, Global test loss: 2.004, Global test accuracy: 32.14
Round  61, Train loss: 0.885, Test loss: 3.219, Test accuracy: 29.44
Round  61, Global train loss: 0.885, Global test loss: 1.831, Global test accuracy: 36.42
Round  62, Train loss: 0.972, Test loss: 3.249, Test accuracy: 29.28
Round  62, Global train loss: 0.972, Global test loss: 1.784, Global test accuracy: 42.70
Round  63, Train loss: 1.083, Test loss: 3.318, Test accuracy: 29.21
Round  63, Global train loss: 1.083, Global test loss: 2.109, Global test accuracy: 26.23
Round  64, Train loss: 0.927, Test loss: 3.297, Test accuracy: 29.49
Round  64, Global train loss: 0.927, Global test loss: 1.907, Global test accuracy: 31.25
Round  65, Train loss: 0.737, Test loss: 3.331, Test accuracy: 29.74
Round  65, Global train loss: 0.737, Global test loss: 1.843, Global test accuracy: 36.20
Round  66, Train loss: 0.763, Test loss: 3.342, Test accuracy: 29.64
Round  66, Global train loss: 0.763, Global test loss: 1.928, Global test accuracy: 32.69
Round  67, Train loss: 0.982, Test loss: 3.363, Test accuracy: 29.58
Round  67, Global train loss: 0.982, Global test loss: 2.079, Global test accuracy: 30.21
Round  68, Train loss: 0.755, Test loss: 3.430, Test accuracy: 29.35
Round  68, Global train loss: 0.755, Global test loss: 1.943, Global test accuracy: 34.99
Round  69, Train loss: 0.750, Test loss: 3.473, Test accuracy: 29.66
Round  69, Global train loss: 0.750, Global test loss: 1.830, Global test accuracy: 38.92
Round  70, Train loss: 0.945, Test loss: 3.529, Test accuracy: 29.57
Round  70, Global train loss: 0.945, Global test loss: 1.978, Global test accuracy: 31.44
Round  71, Train loss: 0.707, Test loss: 3.551, Test accuracy: 29.63
Round  71, Global train loss: 0.707, Global test loss: 2.038, Global test accuracy: 24.12
Round  72, Train loss: 0.862, Test loss: 3.620, Test accuracy: 29.34
Round  72, Global train loss: 0.862, Global test loss: 1.985, Global test accuracy: 30.26
Round  73, Train loss: 0.636, Test loss: 3.608, Test accuracy: 29.94
Round  73, Global train loss: 0.636, Global test loss: 2.099, Global test accuracy: 21.10
Round  74, Train loss: 0.761, Test loss: 3.613, Test accuracy: 29.91
Round  74, Global train loss: 0.761, Global test loss: 1.969, Global test accuracy: 29.49
Round  75, Train loss: 0.953, Test loss: 3.660, Test accuracy: 29.60
Round  75, Global train loss: 0.953, Global test loss: 2.165, Global test accuracy: 21.11
Round  76, Train loss: 0.544, Test loss: 3.685, Test accuracy: 29.34
Round  76, Global train loss: 0.544, Global test loss: 1.604, Global test accuracy: 46.81
Round  77, Train loss: 0.948, Test loss: 3.711, Test accuracy: 29.19
Round  77, Global train loss: 0.948, Global test loss: 2.103, Global test accuracy: 22.41
Round  78, Train loss: 0.847, Test loss: 3.771, Test accuracy: 29.10
Round  78, Global train loss: 0.847, Global test loss: 2.116, Global test accuracy: 21.86
Round  79, Train loss: 0.767, Test loss: 3.792, Test accuracy: 29.21
Round  79, Global train loss: 0.767, Global test loss: 1.996, Global test accuracy: 28.81
Round  80, Train loss: 0.646, Test loss: 3.835, Test accuracy: 29.26
Round  80, Global train loss: 0.646, Global test loss: 1.704, Global test accuracy: 41.33
Round  81, Train loss: 0.463, Test loss: 3.846, Test accuracy: 29.39
Round  81, Global train loss: 0.463, Global test loss: 1.763, Global test accuracy: 38.02
Round  82, Train loss: 0.623, Test loss: 3.888, Test accuracy: 29.57
Round  82, Global train loss: 0.623, Global test loss: 1.993, Global test accuracy: 28.98
Round  83, Train loss: 0.517, Test loss: 3.896, Test accuracy: 29.48
Round  83, Global train loss: 0.517, Global test loss: 1.825, Global test accuracy: 33.42
Round  84, Train loss: 0.872, Test loss: 3.947, Test accuracy: 29.23
Round  84, Global train loss: 0.872, Global test loss: 2.091, Global test accuracy: 26.83
Round  85, Train loss: 0.763, Test loss: 3.986, Test accuracy: 29.21
Round  85, Global train loss: 0.763, Global test loss: 1.983, Global test accuracy: 32.05
Round  86, Train loss: 0.664, Test loss: 4.020, Test accuracy: 29.18
Round  86, Global train loss: 0.664, Global test loss: 2.003, Global test accuracy: 26.77
Round  87, Train loss: 0.745, Test loss: 4.013, Test accuracy: 29.18
Round  87, Global train loss: 0.745, Global test loss: 2.070, Global test accuracy: 28.32
Round  88, Train loss: 0.441, Test loss: 4.066, Test accuracy: 29.28
Round  88, Global train loss: 0.441, Global test loss: 1.685, Global test accuracy: 40.81
Round  89, Train loss: 0.569, Test loss: 4.117, Test accuracy: 29.06
Round  89, Global train loss: 0.569, Global test loss: 1.932, Global test accuracy: 31.13
Round  90, Train loss: 0.720, Test loss: 4.085, Test accuracy: 29.29
Round  90, Global train loss: 0.720, Global test loss: 2.124, Global test accuracy: 23.55
Round  91, Train loss: 0.687, Test loss: 4.112, Test accuracy: 29.01
Round  91, Global train loss: 0.687, Global test loss: 2.071, Global test accuracy: 27.29
Round  92, Train loss: 0.588, Test loss: 4.180, Test accuracy: 28.97
Round  92, Global train loss: 0.588, Global test loss: 1.866, Global test accuracy: 36.87
Round  93, Train loss: 0.592, Test loss: 4.188, Test accuracy: 29.15
Round  93, Global train loss: 0.592, Global test loss: 1.976, Global test accuracy: 30.09
Round  94, Train loss: 0.697, Test loss: 4.260, Test accuracy: 29.08
Round  94, Global train loss: 0.697, Global test loss: 2.211, Global test accuracy: 14.25
Round  95, Train loss: 0.637, Test loss: 4.280, Test accuracy: 29.02
Round  95, Global train loss: 0.637, Global test loss: 1.883, Global test accuracy: 33.91
Round  96, Train loss: 0.614, Test loss: 4.278, Test accuracy: 29.14
Round  96, Global train loss: 0.614, Global test loss: 2.007, Global test accuracy: 30.43
Round  97, Train loss: 0.759, Test loss: 4.287, Test accuracy: 29.13
Round  97, Global train loss: 0.759, Global test loss: 2.135, Global test accuracy: 23.52
Round  98, Train loss: 0.659, Test loss: 4.305, Test accuracy: 29.43
Round  98, Global train loss: 0.659, Global test loss: 2.136, Global test accuracy: 20.97
Round  99, Train loss: 0.603, Test loss: 4.374, Test accuracy: 29.38
Round  99, Global train loss: 0.603, Global test loss: 2.039, Global test accuracy: 29.20
Final Round, Train loss: 0.389, Test loss: 5.230, Test accuracy: 28.97
Final Round, Global train loss: 0.389, Global test loss: 2.039, Global test accuracy: 29.20
Average accuracy final 10 rounds: 29.158749999999998 

Average global accuracy final 10 rounds: 27.0085 

6376.044991016388
[5.182932376861572, 10.365864753723145, 15.515461444854736, 20.665058135986328, 25.729818105697632, 30.794578075408936, 35.84370040893555, 40.89282274246216, 45.956538677215576, 51.020254611968994, 56.09616184234619, 61.17206907272339, 65.63388991355896, 70.09571075439453, 74.57020497322083, 79.04469919204712, 83.52316522598267, 88.00163125991821, 92.42378735542297, 96.84594345092773, 101.26756119728088, 105.68917894363403, 110.52950668334961, 115.36983442306519, 119.79127359390259, 124.21271276473999, 128.70040559768677, 133.18809843063354, 137.63210916519165, 142.07611989974976, 146.45263934135437, 150.82915878295898, 155.28656458854675, 159.74397039413452, 164.20008516311646, 168.6561999320984, 173.04704451560974, 177.4378890991211, 181.83628845214844, 186.23468780517578, 190.66135239601135, 195.08801698684692, 199.46634030342102, 203.84466361999512, 208.26094388961792, 212.67722415924072, 217.1024489402771, 221.52767372131348, 226.20189261436462, 230.87611150741577, 235.24908328056335, 239.62205505371094, 244.01894855499268, 248.4158420562744, 252.81762266159058, 257.21940326690674, 261.61940693855286, 266.019410610199, 270.42542695999146, 274.83144330978394, 279.26247334480286, 283.6935033798218, 288.0371127128601, 292.38072204589844, 297.3879849910736, 302.3952479362488, 307.3841698169708, 312.37309169769287, 317.3696608543396, 322.3662300109863, 327.3808915615082, 332.39555311203003, 337.38769340515137, 342.3798336982727, 347.3729124069214, 352.36599111557007, 357.37363624572754, 362.381281375885, 367.38899421691895, 372.3967070579529, 377.47366309165955, 382.5506191253662, 387.57974457740784, 392.60887002944946, 397.65431690216064, 402.6997637748718, 407.7273952960968, 412.7550268173218, 417.8151617050171, 422.8752965927124, 427.93610095977783, 432.99690532684326, 437.99172711372375, 442.98654890060425, 448.05932807922363, 453.132107257843, 458.11380553245544, 463.09550380706787, 468.1341083049774, 473.17271280288696, 478.2188603878021, 483.2650079727173, 488.3428854942322, 493.42076301574707, 498.418089389801, 503.415415763855, 508.4548544883728, 513.4942932128906, 518.4967958927155, 523.4992985725403, 528.5006453990936, 533.501992225647, 538.4669184684753, 543.4318447113037, 548.4699079990387, 553.5079712867737, 558.4799721240997, 563.4519729614258, 568.4953260421753, 573.5386791229248, 578.5440075397491, 583.5493359565735, 588.5174038410187, 593.4854717254639, 598.495890378952, 603.5063090324402, 607.8509564399719, 612.1956038475037, 616.5105566978455, 620.8255095481873, 625.1638345718384, 629.5021595954895, 633.7974183559418, 638.092677116394, 642.4965946674347, 646.9005122184753, 651.2320852279663, 655.5636582374573, 659.8979053497314, 664.2321524620056, 668.623984336853, 673.0158162117004, 677.3807787895203, 681.7457413673401, 686.1157946586609, 690.4858479499817, 694.8392565250397, 699.1926651000977, 703.5493626594543, 707.906060218811, 712.3109729290009, 716.7158856391907, 721.0301222801208, 725.344358921051, 729.746958732605, 734.1495585441589, 738.5146276950836, 742.8796968460083, 747.1961832046509, 751.5126695632935, 755.8542976379395, 760.1959257125854, 764.4912586212158, 768.7865915298462, 773.0943944454193, 777.4021973609924, 781.7513012886047, 786.100405216217, 790.4044833183289, 794.7085614204407, 799.6912863254547, 804.6740112304688, 809.6950387954712, 814.7160663604736, 819.7146735191345, 824.7132806777954, 829.6984813213348, 834.6836819648743, 839.6815354824066, 844.679388999939, 849.646443605423, 854.613498210907, 859.6212785243988, 864.6290588378906, 869.5993490219116, 874.5696392059326, 878.9075236320496, 883.2454080581665, 887.6129784584045, 891.9805488586426, 896.3424739837646, 900.7043991088867, 905.0554776191711, 909.4065561294556, 913.8308374881744, 918.2551188468933, 922.6332769393921, 927.0114350318909, 931.4331090450287, 935.8547830581665, 938.0354652404785, 940.2161474227905]
[24.3275, 24.3275, 27.06, 27.06, 31.8375, 31.8375, 33.1525, 33.1525, 31.8225, 31.8225, 31.2, 31.2, 32.4825, 32.4825, 32.8275, 32.8275, 32.7675, 32.7675, 32.985, 32.985, 33.285, 33.285, 33.835, 33.835, 33.6075, 33.6075, 33.925, 33.925, 33.9525, 33.9525, 33.9325, 33.9325, 33.74, 33.74, 33.335, 33.335, 33.075, 33.075, 33.0675, 33.0675, 33.3275, 33.3275, 32.8925, 32.8925, 32.875, 32.875, 32.63, 32.63, 32.61, 32.61, 32.4025, 32.4025, 32.1225, 32.1225, 32.14, 32.14, 32.0875, 32.0875, 32.2675, 32.2675, 32.0625, 32.0625, 31.77, 31.77, 31.73, 31.73, 31.2275, 31.2275, 31.445, 31.445, 31.4125, 31.4125, 31.52, 31.52, 31.19, 31.19, 31.33, 31.33, 31.3075, 31.3075, 30.94, 30.94, 30.355, 30.355, 30.615, 30.615, 30.3475, 30.3475, 30.05, 30.05, 30.4275, 30.4275, 30.555, 30.555, 30.5775, 30.5775, 30.545, 30.545, 30.1925, 30.1925, 30.375, 30.375, 30.3375, 30.3375, 30.0325, 30.0325, 29.97, 29.97, 29.8575, 29.8575, 29.795, 29.795, 29.75, 29.75, 29.81, 29.81, 29.6975, 29.6975, 29.69, 29.69, 29.44, 29.44, 29.44, 29.44, 29.2825, 29.2825, 29.2075, 29.2075, 29.49, 29.49, 29.7425, 29.7425, 29.6375, 29.6375, 29.58, 29.58, 29.3525, 29.3525, 29.66, 29.66, 29.5675, 29.5675, 29.6275, 29.6275, 29.335, 29.335, 29.9375, 29.9375, 29.905, 29.905, 29.6025, 29.6025, 29.3375, 29.3375, 29.19, 29.19, 29.1025, 29.1025, 29.2075, 29.2075, 29.26, 29.26, 29.3875, 29.3875, 29.575, 29.575, 29.485, 29.485, 29.225, 29.225, 29.21, 29.21, 29.175, 29.175, 29.175, 29.175, 29.28, 29.28, 29.0625, 29.0625, 29.285, 29.285, 29.0075, 29.0075, 28.9675, 28.9675, 29.15, 29.15, 29.0825, 29.0825, 29.02, 29.02, 29.1425, 29.1425, 29.1275, 29.1275, 29.43, 29.43, 29.375, 29.375, 28.9725, 28.9725]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9745 (0.8771), real noise ratio: 0.8790
Client 2, noise level: 0.6597 (0.5937), real noise ratio: 0.5810
Client 3, noise level: 0.9589 (0.8630), real noise ratio: 0.8660
Client 4, noise level: 0.5160 (0.4644), real noise ratio: 0.4935
Client 6, noise level: 0.8149 (0.7334), real noise ratio: 0.7420
Client 7, noise level: 0.9369 (0.8432), real noise ratio: 0.8535
Client 8, noise level: 0.5044 (0.4539), real noise ratio: 0.5545
Client 9, noise level: 0.8733 (0.7860), real noise ratio: 0.7660
Client 13, noise level: 0.7546 (0.6792), real noise ratio: 0.7290
Client 15, noise level: 0.9778 (0.8800), real noise ratio: 0.8875
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.598, Test loss: 1.909, Test accuracy: 27.08
Round   0, Global train loss: 1.598, Global test loss: 2.244, Global test accuracy: 14.60
Round   1, Train loss: 1.501, Test loss: 1.486, Test accuracy: 47.19
Round   1, Global train loss: 1.501, Global test loss: 2.084, Global test accuracy: 25.02
Round   2, Train loss: 1.393, Test loss: 1.395, Test accuracy: 53.21
Round   2, Global train loss: 1.393, Global test loss: 2.076, Global test accuracy: 28.88
Round   3, Train loss: 1.463, Test loss: 1.193, Test accuracy: 59.42
Round   3, Global train loss: 1.463, Global test loss: 1.956, Global test accuracy: 33.57
Round   4, Train loss: 1.453, Test loss: 1.146, Test accuracy: 62.35
Round   4, Global train loss: 1.453, Global test loss: 1.921, Global test accuracy: 37.69
Round   5, Train loss: 1.403, Test loss: 1.115, Test accuracy: 64.76
Round   5, Global train loss: 1.403, Global test loss: 1.875, Global test accuracy: 35.40
Round   6, Train loss: 1.583, Test loss: 1.090, Test accuracy: 65.69
Round   6, Global train loss: 1.583, Global test loss: 1.873, Global test accuracy: 40.03
Round   7, Train loss: 1.438, Test loss: 1.068, Test accuracy: 67.68
Round   7, Global train loss: 1.438, Global test loss: 1.842, Global test accuracy: 44.55
Round   8, Train loss: 1.270, Test loss: 1.061, Test accuracy: 67.56
Round   8, Global train loss: 1.270, Global test loss: 1.831, Global test accuracy: 42.22
Round   9, Train loss: 1.208, Test loss: 1.084, Test accuracy: 67.23
Round   9, Global train loss: 1.208, Global test loss: 1.910, Global test accuracy: 34.63
Round  10, Train loss: 1.277, Test loss: 1.053, Test accuracy: 67.58
Round  10, Global train loss: 1.277, Global test loss: 1.852, Global test accuracy: 38.56
Round  11, Train loss: 1.338, Test loss: 1.048, Test accuracy: 68.32
Round  11, Global train loss: 1.338, Global test loss: 1.794, Global test accuracy: 45.99
Round  12, Train loss: 1.417, Test loss: 0.998, Test accuracy: 69.81
Round  12, Global train loss: 1.417, Global test loss: 1.776, Global test accuracy: 42.72
Round  13, Train loss: 1.444, Test loss: 1.010, Test accuracy: 69.65
Round  13, Global train loss: 1.444, Global test loss: 1.771, Global test accuracy: 45.04
Round  14, Train loss: 1.238, Test loss: 1.024, Test accuracy: 69.27
Round  14, Global train loss: 1.238, Global test loss: 1.808, Global test accuracy: 38.51
Round  15, Train loss: 1.253, Test loss: 0.927, Test accuracy: 73.43
Round  15, Global train loss: 1.253, Global test loss: 1.714, Global test accuracy: 42.80
Round  16, Train loss: 1.191, Test loss: 0.938, Test accuracy: 72.97
Round  16, Global train loss: 1.191, Global test loss: 1.790, Global test accuracy: 38.73
Round  17, Train loss: 1.219, Test loss: 0.924, Test accuracy: 73.29
Round  17, Global train loss: 1.219, Global test loss: 1.808, Global test accuracy: 38.61
Round  18, Train loss: 1.227, Test loss: 0.905, Test accuracy: 74.83
Round  18, Global train loss: 1.227, Global test loss: 1.700, Global test accuracy: 46.45
Round  19, Train loss: 1.421, Test loss: 0.899, Test accuracy: 75.16
Round  19, Global train loss: 1.421, Global test loss: 1.723, Global test accuracy: 45.36
Round  20, Train loss: 1.278, Test loss: 0.895, Test accuracy: 74.21
Round  20, Global train loss: 1.278, Global test loss: 1.641, Global test accuracy: 47.86
Round  21, Train loss: 1.471, Test loss: 0.870, Test accuracy: 75.47
Round  21, Global train loss: 1.471, Global test loss: 1.709, Global test accuracy: 49.31
Round  22, Train loss: 1.391, Test loss: 0.863, Test accuracy: 75.19
Round  22, Global train loss: 1.391, Global test loss: 1.752, Global test accuracy: 43.38
Round  23, Train loss: 1.302, Test loss: 0.864, Test accuracy: 75.28
Round  23, Global train loss: 1.302, Global test loss: 1.692, Global test accuracy: 43.06
Round  24, Train loss: 1.132, Test loss: 0.854, Test accuracy: 75.33
Round  24, Global train loss: 1.132, Global test loss: 1.664, Global test accuracy: 45.64
Round  25, Train loss: 1.196, Test loss: 0.870, Test accuracy: 75.30
Round  25, Global train loss: 1.196, Global test loss: 1.690, Global test accuracy: 44.68
Round  26, Train loss: 1.287, Test loss: 0.864, Test accuracy: 75.36
Round  26, Global train loss: 1.287, Global test loss: 1.637, Global test accuracy: 47.93
Round  27, Train loss: 1.336, Test loss: 0.854, Test accuracy: 75.56
Round  27, Global train loss: 1.336, Global test loss: 1.687, Global test accuracy: 45.46
Round  28, Train loss: 1.057, Test loss: 0.862, Test accuracy: 75.24
Round  28, Global train loss: 1.057, Global test loss: 1.623, Global test accuracy: 47.33
Round  29, Train loss: 1.347, Test loss: 0.880, Test accuracy: 74.56
Round  29, Global train loss: 1.347, Global test loss: 1.672, Global test accuracy: 46.56
Round  30, Train loss: 1.161, Test loss: 0.878, Test accuracy: 74.87
Round  30, Global train loss: 1.161, Global test loss: 1.575, Global test accuracy: 50.43
Round  31, Train loss: 1.270, Test loss: 0.863, Test accuracy: 75.16
Round  31, Global train loss: 1.270, Global test loss: 1.604, Global test accuracy: 51.09
Round  32, Train loss: 1.113, Test loss: 0.880, Test accuracy: 74.84
Round  32, Global train loss: 1.113, Global test loss: 1.561, Global test accuracy: 49.66
Round  33, Train loss: 1.101, Test loss: 0.879, Test accuracy: 74.87
Round  33, Global train loss: 1.101, Global test loss: 1.598, Global test accuracy: 49.76
Round  34, Train loss: 1.097, Test loss: 0.886, Test accuracy: 74.26
Round  34, Global train loss: 1.097, Global test loss: 1.629, Global test accuracy: 49.54
Round  35, Train loss: 1.146, Test loss: 0.883, Test accuracy: 74.27
Round  35, Global train loss: 1.146, Global test loss: 1.751, Global test accuracy: 44.27
Round  36, Train loss: 0.993, Test loss: 0.866, Test accuracy: 75.07
Round  36, Global train loss: 0.993, Global test loss: 1.652, Global test accuracy: 42.91
Round  37, Train loss: 0.978, Test loss: 0.868, Test accuracy: 74.82
Round  37, Global train loss: 0.978, Global test loss: 1.522, Global test accuracy: 52.33
Round  38, Train loss: 1.265, Test loss: 0.878, Test accuracy: 74.61
Round  38, Global train loss: 1.265, Global test loss: 1.618, Global test accuracy: 49.11
Round  39, Train loss: 1.210, Test loss: 0.899, Test accuracy: 73.57
Round  39, Global train loss: 1.210, Global test loss: 1.680, Global test accuracy: 45.70
Round  40, Train loss: 1.292, Test loss: 0.903, Test accuracy: 73.47
Round  40, Global train loss: 1.292, Global test loss: 1.701, Global test accuracy: 44.48
Round  41, Train loss: 1.155, Test loss: 0.896, Test accuracy: 73.65
Round  41, Global train loss: 1.155, Global test loss: 1.659, Global test accuracy: 48.22
Round  42, Train loss: 1.040, Test loss: 0.912, Test accuracy: 73.42
Round  42, Global train loss: 1.040, Global test loss: 1.751, Global test accuracy: 43.38
Round  43, Train loss: 1.062, Test loss: 0.915, Test accuracy: 73.20
Round  43, Global train loss: 1.062, Global test loss: 1.582, Global test accuracy: 48.54
Round  44, Train loss: 1.106, Test loss: 0.903, Test accuracy: 73.68
Round  44, Global train loss: 1.106, Global test loss: 1.728, Global test accuracy: 43.45
Round  45, Train loss: 1.148, Test loss: 0.883, Test accuracy: 74.10
Round  45, Global train loss: 1.148, Global test loss: 1.616, Global test accuracy: 49.38
Round  46, Train loss: 1.061, Test loss: 0.882, Test accuracy: 73.73
Round  46, Global train loss: 1.061, Global test loss: 1.586, Global test accuracy: 49.57
Round  47, Train loss: 0.887, Test loss: 0.874, Test accuracy: 74.13
Round  47, Global train loss: 0.887, Global test loss: 1.775, Global test accuracy: 42.21
Round  48, Train loss: 1.092, Test loss: 0.891, Test accuracy: 73.76
Round  48, Global train loss: 1.092, Global test loss: 1.740, Global test accuracy: 43.02
Round  49, Train loss: 0.911, Test loss: 0.904, Test accuracy: 73.41
Round  49, Global train loss: 0.911, Global test loss: 1.671, Global test accuracy: 46.76
Round  50, Train loss: 0.863, Test loss: 0.910, Test accuracy: 73.17
Round  50, Global train loss: 0.863, Global test loss: 1.879, Global test accuracy: 40.78
Round  51, Train loss: 0.980, Test loss: 0.906, Test accuracy: 73.03
Round  51, Global train loss: 0.980, Global test loss: 1.911, Global test accuracy: 38.72
Round  52, Train loss: 1.059, Test loss: 0.924, Test accuracy: 72.37
Round  52, Global train loss: 1.059, Global test loss: 1.826, Global test accuracy: 39.77
Round  53, Train loss: 1.110, Test loss: 0.939, Test accuracy: 71.56
Round  53, Global train loss: 1.110, Global test loss: 1.707, Global test accuracy: 42.54
Round  54, Train loss: 0.819, Test loss: 0.931, Test accuracy: 72.01
Round  54, Global train loss: 0.819, Global test loss: 1.913, Global test accuracy: 42.48
Round  55, Train loss: 1.050, Test loss: 0.944, Test accuracy: 71.63
Round  55, Global train loss: 1.050, Global test loss: 1.839, Global test accuracy: 40.47
Round  56, Train loss: 1.085, Test loss: 0.954, Test accuracy: 71.22
Round  56, Global train loss: 1.085, Global test loss: 1.744, Global test accuracy: 43.36
Round  57, Train loss: 0.857, Test loss: 0.958, Test accuracy: 70.86
Round  57, Global train loss: 0.857, Global test loss: 1.830, Global test accuracy: 41.64
Round  58, Train loss: 0.906, Test loss: 0.955, Test accuracy: 71.05
Round  58, Global train loss: 0.906, Global test loss: 1.789, Global test accuracy: 44.46
Round  59, Train loss: 0.909, Test loss: 0.968, Test accuracy: 71.01
Round  59, Global train loss: 0.909, Global test loss: 1.799, Global test accuracy: 41.99
Round  60, Train loss: 0.809, Test loss: 0.963, Test accuracy: 70.80
Round  60, Global train loss: 0.809, Global test loss: 1.725, Global test accuracy: 44.61
Round  61, Train loss: 0.846, Test loss: 0.955, Test accuracy: 71.31
Round  61, Global train loss: 0.846, Global test loss: 1.687, Global test accuracy: 44.41
Round  62, Train loss: 0.890, Test loss: 0.964, Test accuracy: 71.28
Round  62, Global train loss: 0.890, Global test loss: 1.752, Global test accuracy: 43.50
Round  63, Train loss: 1.112, Test loss: 0.953, Test accuracy: 71.52
Round  63, Global train loss: 1.112, Global test loss: 1.682, Global test accuracy: 46.91
Round  64, Train loss: 1.010, Test loss: 0.958, Test accuracy: 70.94
Round  64, Global train loss: 1.010, Global test loss: 1.711, Global test accuracy: 44.95
Round  65, Train loss: 0.981, Test loss: 0.966, Test accuracy: 70.50
Round  65, Global train loss: 0.981, Global test loss: 1.719, Global test accuracy: 45.50
Round  66, Train loss: 0.982, Test loss: 1.011, Test accuracy: 69.85
Round  66, Global train loss: 0.982, Global test loss: 1.851, Global test accuracy: 38.71
Round  67, Train loss: 0.784, Test loss: 0.991, Test accuracy: 70.14
Round  67, Global train loss: 0.784, Global test loss: 1.733, Global test accuracy: 46.04
Round  68, Train loss: 0.969, Test loss: 0.973, Test accuracy: 70.69
Round  68, Global train loss: 0.969, Global test loss: 1.883, Global test accuracy: 39.94
Round  69, Train loss: 0.973, Test loss: 0.959, Test accuracy: 70.77
Round  69, Global train loss: 0.973, Global test loss: 1.786, Global test accuracy: 41.07
Round  70, Train loss: 0.880, Test loss: 0.981, Test accuracy: 70.41
Round  70, Global train loss: 0.880, Global test loss: 1.782, Global test accuracy: 41.76
Round  71, Train loss: 0.946, Test loss: 0.994, Test accuracy: 69.65
Round  71, Global train loss: 0.946, Global test loss: 1.868, Global test accuracy: 39.18
Round  72, Train loss: 1.032, Test loss: 0.998, Test accuracy: 69.49
Round  72, Global train loss: 1.032, Global test loss: 1.754, Global test accuracy: 41.82
Round  73, Train loss: 0.856, Test loss: 0.997, Test accuracy: 69.89
Round  73, Global train loss: 0.856, Global test loss: 1.755, Global test accuracy: 42.34
Round  74, Train loss: 0.949, Test loss: 0.996, Test accuracy: 69.65
Round  74, Global train loss: 0.949, Global test loss: 1.880, Global test accuracy: 41.07
Round  75, Train loss: 0.907, Test loss: 0.997, Test accuracy: 69.68
Round  75, Global train loss: 0.907, Global test loss: 1.744, Global test accuracy: 44.72
Round  76, Train loss: 0.929, Test loss: 1.014, Test accuracy: 69.33
Round  76, Global train loss: 0.929, Global test loss: 1.722, Global test accuracy: 46.18
Round  77, Train loss: 0.997, Test loss: 1.034, Test accuracy: 68.98
Round  77, Global train loss: 0.997, Global test loss: 1.743, Global test accuracy: 44.99
Round  78, Train loss: 0.884, Test loss: 1.024, Test accuracy: 69.16
Round  78, Global train loss: 0.884, Global test loss: 1.761, Global test accuracy: 44.67
Round  79, Train loss: 0.763, Test loss: 1.015, Test accuracy: 69.35
Round  79, Global train loss: 0.763, Global test loss: 1.763, Global test accuracy: 44.13
Round  80, Train loss: 0.788, Test loss: 1.023, Test accuracy: 69.68
Round  80, Global train loss: 0.788, Global test loss: 1.719, Global test accuracy: 45.94
Round  81, Train loss: 0.833, Test loss: 1.046, Test accuracy: 68.98
Round  81, Global train loss: 0.833, Global test loss: 1.867, Global test accuracy: 41.76
Round  82, Train loss: 0.968, Test loss: 1.049, Test accuracy: 68.78
Round  82, Global train loss: 0.968, Global test loss: 1.801, Global test accuracy: 41.80
Round  83, Train loss: 0.953, Test loss: 1.036, Test accuracy: 69.02
Round  83, Global train loss: 0.953, Global test loss: 1.817, Global test accuracy: 42.53
Round  84, Train loss: 0.954, Test loss: 1.041, Test accuracy: 68.88
Round  84, Global train loss: 0.954, Global test loss: 1.687, Global test accuracy: 46.27
Round  85, Train loss: 0.898, Test loss: 1.023, Test accuracy: 69.73
Round  85, Global train loss: 0.898, Global test loss: 1.777, Global test accuracy: 42.98
Round  86, Train loss: 0.711, Test loss: 1.030, Test accuracy: 69.47
Round  86, Global train loss: 0.711, Global test loss: 1.708, Global test accuracy: 47.07
Round  87, Train loss: 0.600, Test loss: 1.060, Test accuracy: 68.83
Round  87, Global train loss: 0.600, Global test loss: 1.984, Global test accuracy: 41.94
Round  88, Train loss: 0.811, Test loss: 1.062, Test accuracy: 68.59
Round  88, Global train loss: 0.811, Global test loss: 1.969, Global test accuracy: 39.54
Round  89, Train loss: 0.759, Test loss: 1.077, Test accuracy: 67.93
Round  89, Global train loss: 0.759, Global test loss: 1.936, Global test accuracy: 41.71
Round  90, Train loss: 0.935, Test loss: 1.078, Test accuracy: 67.67
Round  90, Global train loss: 0.935, Global test loss: 1.893, Global test accuracy: 40.49
Round  91, Train loss: 0.742, Test loss: 1.077, Test accuracy: 67.63
Round  91, Global train loss: 0.742, Global test loss: 1.861, Global test accuracy: 42.35
Round  92, Train loss: 0.746, Test loss: 1.081, Test accuracy: 67.89
Round  92, Global train loss: 0.746, Global test loss: 1.836, Global test accuracy: 44.56
Round  93, Train loss: 0.766, Test loss: 1.113, Test accuracy: 67.56
Round  93, Global train loss: 0.766, Global test loss: 1.870, Global test accuracy: 41.19
Round  94, Train loss: 0.779, Test loss: 1.098, Test accuracy: 68.08
Round  94, Global train loss: 0.779, Global test loss: 1.895, Global test accuracy: 41.18
Round  95, Train loss: 0.714, Test loss: 1.089, Test accuracy: 68.07
Round  95, Global train loss: 0.714, Global test loss: 2.158, Global test accuracy: 38.61
Round  96, Train loss: 0.724, Test loss: 1.095, Test accuracy: 67.78
Round  96, Global train loss: 0.724, Global test loss: 1.866, Global test accuracy: 42.58
Round  97, Train loss: 0.731, Test loss: 1.138, Test accuracy: 66.96
Round  97, Global train loss: 0.731, Global test loss: 1.951, Global test accuracy: 41.84
Round  98, Train loss: 0.711, Test loss: 1.124, Test accuracy: 67.28
Round  98, Global train loss: 0.711, Global test loss: 1.996, Global test accuracy: 40.52
Round  99, Train loss: 0.950, Test loss: 1.130, Test accuracy: 67.49
Round  99, Global train loss: 0.950, Global test loss: 1.855, Global test accuracy: 41.55
Final Round, Train loss: 0.569, Test loss: 1.276, Test accuracy: 66.14
Final Round, Global train loss: 0.569, Global test loss: 1.855, Global test accuracy: 41.55
Average accuracy final 10 rounds: 67.64166666666667 

Average global accuracy final 10 rounds: 41.486666666666665 

2878.283522129059
[2.3911385536193848, 4.7822771072387695, 6.903767347335815, 9.025257587432861, 11.212472677230835, 13.399687767028809, 15.617990970611572, 17.836294174194336, 20.02791976928711, 22.219545364379883, 24.43138599395752, 26.643226623535156, 28.831820964813232, 31.02041530609131, 33.238718032836914, 35.45702075958252, 37.65252685546875, 39.84803295135498, 42.06497859954834, 44.2819242477417, 46.4762544631958, 48.6705846786499, 50.889201402664185, 53.10781812667847, 55.3186309337616, 57.52944374084473, 59.73675775527954, 61.944071769714355, 64.13550806045532, 66.32694435119629, 68.5387876033783, 70.7506308555603, 72.94474363327026, 75.13885641098022, 77.32498860359192, 79.51112079620361, 81.69421076774597, 83.87730073928833, 86.07415390014648, 88.27100706100464, 90.45404386520386, 92.63708066940308, 94.82888126373291, 97.02068185806274, 99.18052053451538, 101.34035921096802, 103.42641139030457, 105.51246356964111, 107.59984397888184, 109.68722438812256, 111.86954736709595, 114.05187034606934, 116.2200095653534, 118.38814878463745, 120.60010480880737, 122.8120608329773, 124.97589159011841, 127.13972234725952, 129.26580667495728, 131.39189100265503, 133.5460889339447, 135.70028686523438, 137.8320655822754, 139.9638442993164, 142.18552899360657, 144.40721368789673, 146.602135181427, 148.79705667495728, 151.01656770706177, 153.23607873916626, 155.43513584136963, 157.634192943573, 159.85429978370667, 162.07440662384033, 164.284574508667, 166.49474239349365, 168.70617485046387, 170.91760730743408, 173.12681531906128, 175.33602333068848, 177.5632300376892, 179.79043674468994, 182.02251291275024, 184.25458908081055, 186.46625113487244, 188.67791318893433, 190.903911113739, 193.1299090385437, 195.35673332214355, 197.5835576057434, 199.81151700019836, 202.03947639465332, 204.2417562007904, 206.4440360069275, 208.65616059303284, 210.86828517913818, 213.1126434803009, 215.35700178146362, 217.58081674575806, 219.8046317100525, 222.04637050628662, 224.28810930252075, 226.5074107646942, 228.72671222686768, 230.9344289302826, 233.1421456336975, 235.3437283039093, 237.5453109741211, 239.75341796875, 241.9615249633789, 244.1905288696289, 246.4195327758789, 248.62540817260742, 250.83128356933594, 252.9352090358734, 255.0391345024109, 257.15254402160645, 259.265953540802, 261.3704192638397, 263.47488498687744, 265.5967319011688, 267.7185788154602, 269.85493421554565, 271.9912896156311, 274.11426424980164, 276.23723888397217, 278.3741731643677, 280.5111074447632, 282.70372343063354, 284.8963394165039, 287.0821182727814, 289.26789712905884, 291.45285177230835, 293.63780641555786, 295.81021308898926, 297.98261976242065, 300.19888639450073, 302.4151530265808, 304.62467527389526, 306.8341975212097, 309.0408592224121, 311.2475209236145, 313.45982813835144, 315.6721353530884, 317.8849461078644, 320.0977568626404, 322.3103702068329, 324.5229835510254, 326.63174986839294, 328.7405161857605, 330.869304895401, 332.9980936050415, 335.10405111312866, 337.2100086212158, 339.393105506897, 341.5762023925781, 343.76729583740234, 345.95838928222656, 348.1734426021576, 350.3884959220886, 352.57254123687744, 354.75658655166626, 356.93313097953796, 359.10967540740967, 361.3159055709839, 363.5221357345581, 365.73259711265564, 367.9430584907532, 370.1636538505554, 372.38424921035767, 374.60979890823364, 376.8353486061096, 378.75625562667847, 380.6771626472473, 382.5761959552765, 384.47522926330566, 386.3807945251465, 388.2863597869873, 390.1936619281769, 392.10096406936646, 394.00798296928406, 395.91500186920166, 397.8684170246124, 399.8218321800232, 401.7561604976654, 403.6904888153076, 405.6339781284332, 407.57746744155884, 409.50632309913635, 411.43517875671387, 413.3655893802643, 415.2960000038147, 417.2381319999695, 419.18026399612427, 421.2087926864624, 423.23732137680054, 425.15590620040894, 427.07449102401733, 428.9755811691284, 430.8766713142395, 433.1431381702423, 435.4096050262451]
[27.083333333333332, 27.083333333333332, 47.18888888888889, 47.18888888888889, 53.205555555555556, 53.205555555555556, 59.416666666666664, 59.416666666666664, 62.35, 62.35, 64.7611111111111, 64.7611111111111, 65.69444444444444, 65.69444444444444, 67.67777777777778, 67.67777777777778, 67.55555555555556, 67.55555555555556, 67.23333333333333, 67.23333333333333, 67.58333333333333, 67.58333333333333, 68.32222222222222, 68.32222222222222, 69.81111111111112, 69.81111111111112, 69.65, 69.65, 69.27222222222223, 69.27222222222223, 73.42777777777778, 73.42777777777778, 72.97222222222223, 72.97222222222223, 73.29444444444445, 73.29444444444445, 74.83333333333333, 74.83333333333333, 75.16111111111111, 75.16111111111111, 74.20555555555555, 74.20555555555555, 75.46666666666667, 75.46666666666667, 75.18888888888888, 75.18888888888888, 75.27777777777777, 75.27777777777777, 75.33333333333333, 75.33333333333333, 75.3, 75.3, 75.36111111111111, 75.36111111111111, 75.55555555555556, 75.55555555555556, 75.2388888888889, 75.2388888888889, 74.56111111111112, 74.56111111111112, 74.86666666666666, 74.86666666666666, 75.15555555555555, 75.15555555555555, 74.83888888888889, 74.83888888888889, 74.87222222222222, 74.87222222222222, 74.2611111111111, 74.2611111111111, 74.27222222222223, 74.27222222222223, 75.07222222222222, 75.07222222222222, 74.82222222222222, 74.82222222222222, 74.61111111111111, 74.61111111111111, 73.56666666666666, 73.56666666666666, 73.47222222222223, 73.47222222222223, 73.65, 73.65, 73.41666666666667, 73.41666666666667, 73.2, 73.2, 73.68333333333334, 73.68333333333334, 74.1, 74.1, 73.73333333333333, 73.73333333333333, 74.13333333333334, 74.13333333333334, 73.7611111111111, 73.7611111111111, 73.40555555555555, 73.40555555555555, 73.16666666666667, 73.16666666666667, 73.03333333333333, 73.03333333333333, 72.37222222222222, 72.37222222222222, 71.55555555555556, 71.55555555555556, 72.0111111111111, 72.0111111111111, 71.62777777777778, 71.62777777777778, 71.22222222222223, 71.22222222222223, 70.86111111111111, 70.86111111111111, 71.05, 71.05, 71.0111111111111, 71.0111111111111, 70.8, 70.8, 71.30555555555556, 71.30555555555556, 71.27777777777777, 71.27777777777777, 71.51666666666667, 71.51666666666667, 70.94444444444444, 70.94444444444444, 70.5, 70.5, 69.85, 69.85, 70.14444444444445, 70.14444444444445, 70.68888888888888, 70.68888888888888, 70.77222222222223, 70.77222222222223, 70.41111111111111, 70.41111111111111, 69.65, 69.65, 69.49444444444444, 69.49444444444444, 69.89444444444445, 69.89444444444445, 69.65, 69.65, 69.68333333333334, 69.68333333333334, 69.32777777777778, 69.32777777777778, 68.98333333333333, 68.98333333333333, 69.15555555555555, 69.15555555555555, 69.35, 69.35, 69.68333333333334, 69.68333333333334, 68.97777777777777, 68.97777777777777, 68.78333333333333, 68.78333333333333, 69.02222222222223, 69.02222222222223, 68.88333333333334, 68.88333333333334, 69.72777777777777, 69.72777777777777, 69.47222222222223, 69.47222222222223, 68.82777777777778, 68.82777777777778, 68.59444444444445, 68.59444444444445, 67.92777777777778, 67.92777777777778, 67.67222222222222, 67.67222222222222, 67.62777777777778, 67.62777777777778, 67.89444444444445, 67.89444444444445, 67.56111111111112, 67.56111111111112, 68.07777777777778, 68.07777777777778, 68.06666666666666, 68.06666666666666, 67.78333333333333, 67.78333333333333, 66.96111111111111, 66.96111111111111, 67.28333333333333, 67.28333333333333, 67.4888888888889, 67.4888888888889, 66.14444444444445, 66.14444444444445]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  prox  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: prox , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.4 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9745 (0.8771), real noise ratio: 0.8720
Client 2, noise level: 0.6597 (0.5937), real noise ratio: 0.5840
Client 3, noise level: 0.9589 (0.8630), real noise ratio: 0.8605
Client 4, noise level: 0.5160 (0.4644), real noise ratio: 0.5520
Client 6, noise level: 0.8149 (0.7334), real noise ratio: 0.7570
Client 7, noise level: 0.9369 (0.8432), real noise ratio: 0.8530
Client 8, noise level: 0.5044 (0.4539), real noise ratio: 0.5900
Client 9, noise level: 0.8733 (0.7860), real noise ratio: 0.8070
Client 13, noise level: 0.7546 (0.6792), real noise ratio: 0.7075
Client 15, noise level: 0.9778 (0.8800), real noise ratio: 0.8870
prox
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 1.418, Test loss: 1.949, Test accuracy: 27.96
Round   0, Global train loss: 1.418, Global test loss: 2.222, Global test accuracy: 22.37
Round   1, Train loss: 1.212, Test loss: 1.702, Test accuracy: 41.67
Round   1, Global train loss: 1.212, Global test loss: 2.180, Global test accuracy: 32.29
Round   2, Train loss: 1.252, Test loss: 1.405, Test accuracy: 49.59
Round   2, Global train loss: 1.252, Global test loss: 2.020, Global test accuracy: 33.08
Round   3, Train loss: 1.165, Test loss: 1.225, Test accuracy: 54.34
Round   3, Global train loss: 1.165, Global test loss: 1.919, Global test accuracy: 33.63
Round   4, Train loss: 1.192, Test loss: 1.205, Test accuracy: 56.98
Round   4, Global train loss: 1.192, Global test loss: 1.874, Global test accuracy: 38.52
Round   5, Train loss: 0.891, Test loss: 1.227, Test accuracy: 56.63
Round   5, Global train loss: 0.891, Global test loss: 2.006, Global test accuracy: 32.39
Round   6, Train loss: 0.901, Test loss: 1.174, Test accuracy: 59.02
Round   6, Global train loss: 0.901, Global test loss: 1.954, Global test accuracy: 36.98
Round   7, Train loss: 1.005, Test loss: 1.139, Test accuracy: 58.97
Round   7, Global train loss: 1.005, Global test loss: 1.745, Global test accuracy: 39.79
Round   8, Train loss: 1.158, Test loss: 1.044, Test accuracy: 63.05
Round   8, Global train loss: 1.158, Global test loss: 1.774, Global test accuracy: 39.16
Round   9, Train loss: 1.304, Test loss: 1.022, Test accuracy: 63.49
Round   9, Global train loss: 1.304, Global test loss: 1.736, Global test accuracy: 40.57
Round  10, Train loss: 1.044, Test loss: 1.040, Test accuracy: 62.61
Round  10, Global train loss: 1.044, Global test loss: 1.752, Global test accuracy: 40.52
Round  11, Train loss: 1.083, Test loss: 0.947, Test accuracy: 66.07
Round  11, Global train loss: 1.083, Global test loss: 1.673, Global test accuracy: 44.20
Round  12, Train loss: 0.962, Test loss: 0.941, Test accuracy: 66.80
Round  12, Global train loss: 0.962, Global test loss: 1.781, Global test accuracy: 34.21
Round  13, Train loss: 1.142, Test loss: 0.919, Test accuracy: 67.74
Round  13, Global train loss: 1.142, Global test loss: 1.717, Global test accuracy: 45.54
Round  14, Train loss: 1.178, Test loss: 0.920, Test accuracy: 68.32
Round  14, Global train loss: 1.178, Global test loss: 1.794, Global test accuracy: 38.09
Round  15, Train loss: 1.235, Test loss: 0.913, Test accuracy: 68.44
Round  15, Global train loss: 1.235, Global test loss: 1.866, Global test accuracy: 35.07
Round  16, Train loss: 0.948, Test loss: 0.920, Test accuracy: 67.81
Round  16, Global train loss: 0.948, Global test loss: 1.669, Global test accuracy: 45.68
Round  17, Train loss: 0.981, Test loss: 0.910, Test accuracy: 68.44
Round  17, Global train loss: 0.981, Global test loss: 1.591, Global test accuracy: 47.51
Round  18, Train loss: 1.270, Test loss: 0.899, Test accuracy: 70.01
Round  18, Global train loss: 1.270, Global test loss: 1.657, Global test accuracy: 45.82
Round  19, Train loss: 1.047, Test loss: 0.890, Test accuracy: 69.92
Round  19, Global train loss: 1.047, Global test loss: 1.649, Global test accuracy: 42.39
Round  20, Train loss: 0.842, Test loss: 0.890, Test accuracy: 69.99
Round  20, Global train loss: 0.842, Global test loss: 1.833, Global test accuracy: 37.72
Round  21, Train loss: 0.802, Test loss: 0.885, Test accuracy: 70.20
Round  21, Global train loss: 0.802, Global test loss: 1.838, Global test accuracy: 36.77
Round  22, Train loss: 0.883, Test loss: 0.874, Test accuracy: 70.89
Round  22, Global train loss: 0.883, Global test loss: 1.659, Global test accuracy: 44.11
Round  23, Train loss: 0.849, Test loss: 0.869, Test accuracy: 71.00
Round  23, Global train loss: 0.849, Global test loss: 1.500, Global test accuracy: 48.77
Round  24, Train loss: 0.990, Test loss: 0.877, Test accuracy: 70.74
Round  24, Global train loss: 0.990, Global test loss: 1.629, Global test accuracy: 46.35
Round  25, Train loss: 0.871, Test loss: 0.882, Test accuracy: 70.43
Round  25, Global train loss: 0.871, Global test loss: 1.523, Global test accuracy: 47.98
Round  26, Train loss: 0.895, Test loss: 0.879, Test accuracy: 70.73
Round  26, Global train loss: 0.895, Global test loss: 1.552, Global test accuracy: 48.00
Round  27, Train loss: 1.008, Test loss: 0.859, Test accuracy: 71.02
Round  27, Global train loss: 1.008, Global test loss: 1.518, Global test accuracy: 50.23
Round  28, Train loss: 0.655, Test loss: 0.871, Test accuracy: 70.92
Round  28, Global train loss: 0.655, Global test loss: 1.571, Global test accuracy: 47.35
Round  29, Train loss: 0.908, Test loss: 0.878, Test accuracy: 70.88
Round  29, Global train loss: 0.908, Global test loss: 1.817, Global test accuracy: 43.37
Round  30, Train loss: 0.864, Test loss: 0.880, Test accuracy: 70.92
Round  30, Global train loss: 0.864, Global test loss: 1.554, Global test accuracy: 50.37
Round  31, Train loss: 0.931, Test loss: 0.853, Test accuracy: 71.88
Round  31, Global train loss: 0.931, Global test loss: 1.435, Global test accuracy: 55.13
Round  32, Train loss: 0.859, Test loss: 0.850, Test accuracy: 72.14
Round  32, Global train loss: 0.859, Global test loss: 1.469, Global test accuracy: 50.96
Round  33, Train loss: 0.692, Test loss: 0.839, Test accuracy: 72.14
Round  33, Global train loss: 0.692, Global test loss: 1.537, Global test accuracy: 51.14
Round  34, Train loss: 0.746, Test loss: 0.872, Test accuracy: 70.72
Round  34, Global train loss: 0.746, Global test loss: 1.456, Global test accuracy: 52.55
Round  35, Train loss: 0.807, Test loss: 0.848, Test accuracy: 72.10
Round  35, Global train loss: 0.807, Global test loss: 1.432, Global test accuracy: 53.48
Round  36, Train loss: 0.826, Test loss: 0.833, Test accuracy: 72.86
Round  36, Global train loss: 0.826, Global test loss: 1.455, Global test accuracy: 51.43
Round  37, Train loss: 1.205, Test loss: 0.838, Test accuracy: 72.48
Round  37, Global train loss: 1.205, Global test loss: 1.576, Global test accuracy: 49.88
Round  38, Train loss: 0.793, Test loss: 0.847, Test accuracy: 72.43
Round  38, Global train loss: 0.793, Global test loss: 1.396, Global test accuracy: 55.87
Round  39, Train loss: 0.735, Test loss: 0.832, Test accuracy: 73.06
Round  39, Global train loss: 0.735, Global test loss: 1.472, Global test accuracy: 49.68
Round  40, Train loss: 0.875, Test loss: 0.839, Test accuracy: 72.24
Round  40, Global train loss: 0.875, Global test loss: 1.409, Global test accuracy: 55.02
Round  41, Train loss: 0.656, Test loss: 0.824, Test accuracy: 72.69
Round  41, Global train loss: 0.656, Global test loss: 1.504, Global test accuracy: 50.51
Round  42, Train loss: 0.834, Test loss: 0.835, Test accuracy: 72.72
Round  42, Global train loss: 0.834, Global test loss: 1.411, Global test accuracy: 55.09
Round  43, Train loss: 0.801, Test loss: 0.844, Test accuracy: 71.92
Round  43, Global train loss: 0.801, Global test loss: 1.524, Global test accuracy: 51.66
Round  44, Train loss: 0.703, Test loss: 0.853, Test accuracy: 71.88
Round  44, Global train loss: 0.703, Global test loss: 1.354, Global test accuracy: 56.16
Round  45, Train loss: 0.862, Test loss: 0.873, Test accuracy: 71.01
Round  45, Global train loss: 0.862, Global test loss: 1.378, Global test accuracy: 56.35
Round  46, Train loss: 0.862, Test loss: 0.872, Test accuracy: 71.25
Round  46, Global train loss: 0.862, Global test loss: 1.441, Global test accuracy: 51.79
Round  47, Train loss: 0.699, Test loss: 0.875, Test accuracy: 71.41
Round  47, Global train loss: 0.699, Global test loss: 1.523, Global test accuracy: 48.88
Round  48, Train loss: 0.824, Test loss: 0.865, Test accuracy: 71.88
Round  48, Global train loss: 0.824, Global test loss: 1.462, Global test accuracy: 52.08
Round  49, Train loss: 0.836, Test loss: 0.851, Test accuracy: 72.23
Round  49, Global train loss: 0.836, Global test loss: 1.498, Global test accuracy: 50.98
Round  50, Train loss: 0.834, Test loss: 0.856, Test accuracy: 71.74
Round  50, Global train loss: 0.834, Global test loss: 1.506, Global test accuracy: 50.77
Round  51, Train loss: 0.776, Test loss: 0.855, Test accuracy: 71.97
Round  51, Global train loss: 0.776, Global test loss: 1.472, Global test accuracy: 49.36
Round  52, Train loss: 0.754, Test loss: 0.836, Test accuracy: 72.62
Round  52, Global train loss: 0.754, Global test loss: 1.427, Global test accuracy: 53.02
Round  53, Train loss: 0.657, Test loss: 0.875, Test accuracy: 70.92
Round  53, Global train loss: 0.657, Global test loss: 1.477, Global test accuracy: 52.08
Round  54, Train loss: 0.893, Test loss: 0.854, Test accuracy: 71.78
Round  54, Global train loss: 0.893, Global test loss: 1.495, Global test accuracy: 50.12
Round  55, Train loss: 0.777, Test loss: 0.852, Test accuracy: 71.64
Round  55, Global train loss: 0.777, Global test loss: 1.398, Global test accuracy: 53.54
Round  56, Train loss: 0.809, Test loss: 0.854, Test accuracy: 71.75
Round  56, Global train loss: 0.809, Global test loss: 1.366, Global test accuracy: 53.58
Round  57, Train loss: 0.733, Test loss: 0.854, Test accuracy: 72.05
Round  57, Global train loss: 0.733, Global test loss: 1.474, Global test accuracy: 50.71
Round  58, Train loss: 0.674, Test loss: 0.849, Test accuracy: 72.57
Round  58, Global train loss: 0.674, Global test loss: 1.437, Global test accuracy: 53.04
Round  59, Train loss: 0.715, Test loss: 0.840, Test accuracy: 72.67
Round  59, Global train loss: 0.715, Global test loss: 1.586, Global test accuracy: 48.84
Round  60, Train loss: 0.699, Test loss: 0.845, Test accuracy: 72.86
Round  60, Global train loss: 0.699, Global test loss: 1.461, Global test accuracy: 52.08
Round  61, Train loss: 0.760, Test loss: 0.830, Test accuracy: 73.25
Round  61, Global train loss: 0.760, Global test loss: 1.470, Global test accuracy: 52.79
Round  62, Train loss: 0.678, Test loss: 0.826, Test accuracy: 73.68
Round  62, Global train loss: 0.678, Global test loss: 1.613, Global test accuracy: 46.67
Round  63, Train loss: 0.808, Test loss: 0.864, Test accuracy: 72.29
Round  63, Global train loss: 0.808, Global test loss: 1.504, Global test accuracy: 49.89
Round  64, Train loss: 0.599, Test loss: 0.889, Test accuracy: 71.66
Round  64, Global train loss: 0.599, Global test loss: 1.414, Global test accuracy: 56.16
Round  65, Train loss: 0.618, Test loss: 0.893, Test accuracy: 71.53
Round  65, Global train loss: 0.618, Global test loss: 1.465, Global test accuracy: 53.27
Round  66, Train loss: 0.601, Test loss: 0.889, Test accuracy: 71.97
Round  66, Global train loss: 0.601, Global test loss: 1.463, Global test accuracy: 53.65
Round  67, Train loss: 0.575, Test loss: 0.920, Test accuracy: 71.38
Round  67, Global train loss: 0.575, Global test loss: 1.505, Global test accuracy: 52.69
Round  68, Train loss: 0.586, Test loss: 0.921, Test accuracy: 71.14
Round  68, Global train loss: 0.586, Global test loss: 1.402, Global test accuracy: 54.70
Round  69, Train loss: 0.579, Test loss: 0.906, Test accuracy: 71.49
Round  69, Global train loss: 0.579, Global test loss: 1.451, Global test accuracy: 56.23
Round  70, Train loss: 0.748, Test loss: 0.924, Test accuracy: 70.85
Round  70, Global train loss: 0.748, Global test loss: 1.616, Global test accuracy: 49.44
Round  71, Train loss: 0.886, Test loss: 0.918, Test accuracy: 71.29
Round  71, Global train loss: 0.886, Global test loss: 1.543, Global test accuracy: 48.62
Round  72, Train loss: 0.650, Test loss: 0.923, Test accuracy: 71.55
Round  72, Global train loss: 0.650, Global test loss: 1.385, Global test accuracy: 55.07
Round  73, Train loss: 0.650, Test loss: 0.919, Test accuracy: 71.90
Round  73, Global train loss: 0.650, Global test loss: 1.574, Global test accuracy: 48.92
Round  74, Train loss: 0.563, Test loss: 0.897, Test accuracy: 72.31
Round  74, Global train loss: 0.563, Global test loss: 1.458, Global test accuracy: 56.23
Round  75, Train loss: 0.489, Test loss: 0.902, Test accuracy: 72.45
Round  75, Global train loss: 0.489, Global test loss: 1.455, Global test accuracy: 54.73
Round  76, Train loss: 0.450, Test loss: 0.898, Test accuracy: 72.56
Round  76, Global train loss: 0.450, Global test loss: 1.590, Global test accuracy: 52.85
Round  77, Train loss: 0.905, Test loss: 0.841, Test accuracy: 73.53
Round  77, Global train loss: 0.905, Global test loss: 1.452, Global test accuracy: 54.87
Round  78, Train loss: 0.612, Test loss: 0.893, Test accuracy: 72.29
Round  78, Global train loss: 0.612, Global test loss: 1.556, Global test accuracy: 52.32
Round  79, Train loss: 0.431, Test loss: 0.889, Test accuracy: 72.54
Round  79, Global train loss: 0.431, Global test loss: 1.549, Global test accuracy: 52.91
Round  80, Train loss: 0.727, Test loss: 0.939, Test accuracy: 71.57
Round  80, Global train loss: 0.727, Global test loss: 1.473, Global test accuracy: 54.19
Round  81, Train loss: 0.671, Test loss: 0.944, Test accuracy: 71.31
Round  81, Global train loss: 0.671, Global test loss: 1.540, Global test accuracy: 51.79
Round  82, Train loss: 0.620, Test loss: 0.957, Test accuracy: 71.12
Round  82, Global train loss: 0.620, Global test loss: 1.744, Global test accuracy: 47.78
Round  83, Train loss: 0.560, Test loss: 0.979, Test accuracy: 70.40
Round  83, Global train loss: 0.560, Global test loss: 1.465, Global test accuracy: 53.85
Round  84, Train loss: 0.738, Test loss: 0.993, Test accuracy: 69.59
Round  84, Global train loss: 0.738, Global test loss: 1.520, Global test accuracy: 53.24
Round  85, Train loss: 0.749, Test loss: 0.966, Test accuracy: 70.63
Round  85, Global train loss: 0.749, Global test loss: 1.526, Global test accuracy: 53.52
Round  86, Train loss: 0.511, Test loss: 0.976, Test accuracy: 70.37
Round  86, Global train loss: 0.511, Global test loss: 1.478, Global test accuracy: 55.83
Round  87, Train loss: 0.588, Test loss: 0.958, Test accuracy: 71.11
Round  87, Global train loss: 0.588, Global test loss: 1.506, Global test accuracy: 53.83
Round  88, Train loss: 0.487, Test loss: 0.977, Test accuracy: 71.28
Round  88, Global train loss: 0.487, Global test loss: 1.597, Global test accuracy: 54.55
Round  89, Train loss: 0.404, Test loss: 0.972, Test accuracy: 71.08
Round  89, Global train loss: 0.404, Global test loss: 1.630, Global test accuracy: 52.90
Round  90, Train loss: 0.773, Test loss: 0.978, Test accuracy: 71.02
Round  90, Global train loss: 0.773, Global test loss: 1.611, Global test accuracy: 50.61
Round  91, Train loss: 0.428, Test loss: 0.986, Test accuracy: 71.32
Round  91, Global train loss: 0.428, Global test loss: 1.563, Global test accuracy: 54.25
Round  92, Train loss: 0.538, Test loss: 0.940, Test accuracy: 72.07
Round  92, Global train loss: 0.538, Global test loss: 1.641, Global test accuracy: 51.89
Round  93, Train loss: 0.566, Test loss: 0.958, Test accuracy: 71.49
Round  93, Global train loss: 0.566, Global test loss: 1.473, Global test accuracy: 55.33
Round  94, Train loss: 0.639, Test loss: 0.994, Test accuracy: 70.97
Round  94, Global train loss: 0.639, Global test loss: 1.601, Global test accuracy: 51.27
Round  95, Train loss: 0.644, Test loss: 0.977, Test accuracy: 70.60
Round  95, Global train loss: 0.644, Global test loss: 1.787, Global test accuracy: 49.21
Round  96, Train loss: 0.524, Test loss: 1.005, Test accuracy: 70.02
Round  96, Global train loss: 0.524, Global test loss: 1.500, Global test accuracy: 54.37
Round  97, Train loss: 0.683, Test loss: 1.002, Test accuracy: 70.33
Round  97, Global train loss: 0.683, Global test loss: 1.779, Global test accuracy: 47.75
Round  98, Train loss: 0.631, Test loss: 1.015, Test accuracy: 70.59
Round  98, Global train loss: 0.631, Global test loss: 1.640, Global test accuracy: 49.59
Round  99, Train loss: 0.621, Test loss: 1.036, Test accuracy: 70.47
Round  99, Global train loss: 0.621, Global test loss: 1.655, Global test accuracy: 50.15
Final Round, Train loss: 0.466, Test loss: 1.087, Test accuracy: 70.65
Final Round, Global train loss: 0.466, Global test loss: 1.655, Global test accuracy: 50.15
Average accuracy final 10 rounds: 70.88583333333332 

Average global accuracy final 10 rounds: 51.4425 

2068.2367227077484
[1.934096336364746, 3.868192672729492, 5.54607629776001, 7.223959922790527, 8.92250108718872, 10.621042251586914, 12.303598165512085, 13.986154079437256, 15.69037938117981, 17.394604682922363, 19.019127368927002, 20.64365005493164, 22.27052617073059, 23.89740228652954, 25.53271198272705, 27.16802167892456, 28.808622360229492, 30.449223041534424, 32.113728046417236, 33.77823305130005, 35.53558564186096, 37.292938232421875, 38.992326736450195, 40.691715240478516, 42.3735568523407, 44.05539846420288, 45.74628686904907, 47.437175273895264, 49.129300594329834, 50.821425914764404, 52.57044434547424, 54.31946277618408, 55.9938702583313, 57.668277740478516, 59.352033853530884, 61.03578996658325, 62.72317576408386, 64.41056156158447, 66.08475875854492, 67.75895595550537, 69.42142486572266, 71.08389377593994, 72.75765633583069, 74.43141889572144, 76.11778616905212, 77.80415344238281, 79.46832036972046, 81.1324872970581, 82.80690908432007, 84.48133087158203, 86.17102718353271, 87.8607234954834, 89.54516577720642, 91.22960805892944, 92.9306275844574, 94.63164710998535, 96.30985808372498, 97.9880690574646, 99.72472190856934, 101.46137475967407, 103.09659242630005, 104.73181009292603, 106.36465239524841, 107.9974946975708, 109.62322974205017, 111.24896478652954, 112.87423372268677, 114.499502658844, 116.12619829177856, 117.75289392471313, 119.38907146453857, 121.02524900436401, 122.65343689918518, 124.28162479400635, 125.89968585968018, 127.517746925354, 129.16053533554077, 130.80332374572754, 132.4328773021698, 134.06243085861206, 135.70736861228943, 137.3523063659668, 138.84808111190796, 140.34385585784912, 141.81101989746094, 143.27818393707275, 144.743492603302, 146.20880126953125, 147.69442701339722, 149.18005275726318, 150.67781281471252, 152.17557287216187, 153.64233922958374, 155.10910558700562, 156.57983016967773, 158.05055475234985, 159.5181314945221, 160.98570823669434, 162.45766186714172, 163.9296154975891, 165.38591861724854, 166.84222173690796, 168.32249307632446, 169.80276441574097, 171.28701901435852, 172.77127361297607, 174.26961469650269, 175.7679557800293, 177.24747848510742, 178.72700119018555, 180.22268509864807, 181.7183690071106, 183.20878648757935, 184.6992039680481, 186.17348861694336, 187.64777326583862, 189.1161711215973, 190.58456897735596, 192.06273412704468, 193.5408992767334, 195.02606439590454, 196.51122951507568, 198.01063323020935, 199.51003694534302, 201.0207643508911, 202.5314917564392, 204.01618814468384, 205.50088453292847, 206.97515201568604, 208.4494194984436, 209.93549942970276, 211.4215793609619, 212.89702153205872, 214.37246370315552, 215.86940717697144, 217.36635065078735, 218.86604642868042, 220.3657422065735, 221.83202171325684, 223.29830121994019, 224.78130650520325, 226.2643117904663, 227.75705528259277, 229.24979877471924, 230.73722195625305, 232.22464513778687, 233.72596621513367, 235.22728729248047, 236.71991324424744, 238.2125391960144, 239.71462559700012, 241.21671199798584, 242.7086696624756, 244.20062732696533, 245.69735455513, 247.19408178329468, 248.69064164161682, 250.18720149993896, 251.68303108215332, 253.17886066436768, 254.68437123298645, 256.1898818016052, 257.679221868515, 259.1685619354248, 260.6673741340637, 262.16618633270264, 263.64520502090454, 265.12422370910645, 266.60634779930115, 268.08847188949585, 269.56595158576965, 271.04343128204346, 272.5223286151886, 274.00122594833374, 275.4849851131439, 276.9687442779541, 278.4728693962097, 279.97699451446533, 281.4781289100647, 282.97926330566406, 284.43198227882385, 285.88470125198364, 287.37781524658203, 288.8709292411804, 290.37327551841736, 291.8756217956543, 293.37981820106506, 294.88401460647583, 296.35447096824646, 297.8249273300171, 299.29982590675354, 300.77472448349, 302.23271775245667, 303.69071102142334, 305.15406680107117, 306.617422580719, 308.08622336387634, 309.5550241470337, 311.0265212059021, 312.4980182647705, 314.9850871562958, 317.47215604782104]
[27.958333333333332, 27.958333333333332, 41.666666666666664, 41.666666666666664, 49.59166666666667, 49.59166666666667, 54.34166666666667, 54.34166666666667, 56.975, 56.975, 56.63333333333333, 56.63333333333333, 59.016666666666666, 59.016666666666666, 58.96666666666667, 58.96666666666667, 63.05, 63.05, 63.49166666666667, 63.49166666666667, 62.608333333333334, 62.608333333333334, 66.06666666666666, 66.06666666666666, 66.8, 66.8, 67.74166666666666, 67.74166666666666, 68.31666666666666, 68.31666666666666, 68.44166666666666, 68.44166666666666, 67.80833333333334, 67.80833333333334, 68.44166666666666, 68.44166666666666, 70.00833333333334, 70.00833333333334, 69.91666666666667, 69.91666666666667, 69.99166666666666, 69.99166666666666, 70.2, 70.2, 70.89166666666667, 70.89166666666667, 71.0, 71.0, 70.74166666666666, 70.74166666666666, 70.43333333333334, 70.43333333333334, 70.73333333333333, 70.73333333333333, 71.01666666666667, 71.01666666666667, 70.91666666666667, 70.91666666666667, 70.88333333333334, 70.88333333333334, 70.91666666666667, 70.91666666666667, 71.875, 71.875, 72.14166666666667, 72.14166666666667, 72.14166666666667, 72.14166666666667, 70.725, 70.725, 72.1, 72.1, 72.85833333333333, 72.85833333333333, 72.48333333333333, 72.48333333333333, 72.43333333333334, 72.43333333333334, 73.05833333333334, 73.05833333333334, 72.24166666666666, 72.24166666666666, 72.69166666666666, 72.69166666666666, 72.725, 72.725, 71.925, 71.925, 71.88333333333334, 71.88333333333334, 71.00833333333334, 71.00833333333334, 71.25, 71.25, 71.40833333333333, 71.40833333333333, 71.875, 71.875, 72.23333333333333, 72.23333333333333, 71.74166666666666, 71.74166666666666, 71.96666666666667, 71.96666666666667, 72.61666666666666, 72.61666666666666, 70.925, 70.925, 71.78333333333333, 71.78333333333333, 71.64166666666667, 71.64166666666667, 71.75, 71.75, 72.05, 72.05, 72.56666666666666, 72.56666666666666, 72.66666666666667, 72.66666666666667, 72.85833333333333, 72.85833333333333, 73.25, 73.25, 73.68333333333334, 73.68333333333334, 72.29166666666667, 72.29166666666667, 71.65833333333333, 71.65833333333333, 71.525, 71.525, 71.96666666666667, 71.96666666666667, 71.375, 71.375, 71.14166666666667, 71.14166666666667, 71.49166666666666, 71.49166666666666, 70.85, 70.85, 71.29166666666667, 71.29166666666667, 71.55, 71.55, 71.9, 71.9, 72.30833333333334, 72.30833333333334, 72.45, 72.45, 72.55833333333334, 72.55833333333334, 73.525, 73.525, 72.29166666666667, 72.29166666666667, 72.54166666666667, 72.54166666666667, 71.56666666666666, 71.56666666666666, 71.30833333333334, 71.30833333333334, 71.11666666666666, 71.11666666666666, 70.4, 70.4, 69.59166666666667, 69.59166666666667, 70.63333333333334, 70.63333333333334, 70.36666666666666, 70.36666666666666, 71.10833333333333, 71.10833333333333, 71.275, 71.275, 71.075, 71.075, 71.01666666666667, 71.01666666666667, 71.31666666666666, 71.31666666666666, 72.06666666666666, 72.06666666666666, 71.49166666666666, 71.49166666666666, 70.96666666666667, 70.96666666666667, 70.6, 70.6, 70.01666666666667, 70.01666666666667, 70.325, 70.325, 70.59166666666667, 70.59166666666667, 70.46666666666667, 70.46666666666667, 70.65, 70.65]/home/ChenSM/code/FL_HLS/FedProx.py:100: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
  d_p.add_(weight_decay, p.data)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Co-teaching%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9745 (0.8771), real noise ratio: 0.8895
Client 2, noise level: 0.6597 (0.5937), real noise ratio: 0.5865
Client 3, noise level: 0.9589 (0.8630), real noise ratio: 0.8665
Client 4, noise level: 0.5160 (0.4644), real noise ratio: 0.5865
Client 6, noise level: 0.8149 (0.7334), real noise ratio: 0.7550
Client 7, noise level: 0.9369 (0.8432), real noise ratio: 0.8470
Client 8, noise level: 0.5044 (0.4539), real noise ratio: 0.4885
Client 9, noise level: 0.8733 (0.7860), real noise ratio: 0.8170
Client 13, noise level: 0.7546 (0.6792), real noise ratio: 0.7405
Client 15, noise level: 0.9778 (0.8800), real noise ratio: 0.8775
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Traceback (most recent call last):
  File "main_fedpac_co_teaching2.py", line 231, in <module>
    w_local, loss, indd, class_center_local, class_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1272, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 53408 is out of bounds for axis 0 with size 50000
RFL.py:4: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import long
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%RFL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: RFL , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9745 (0.8771), real noise ratio: 0.8830
Client 2, noise level: 0.6597 (0.5937), real noise ratio: 0.5830
Client 3, noise level: 0.9589 (0.8630), real noise ratio: 0.8605
Client 4, noise level: 0.5160 (0.4644), real noise ratio: 0.4755
Client 6, noise level: 0.8149 (0.7334), real noise ratio: 0.7575
Client 7, noise level: 0.9369 (0.8432), real noise ratio: 0.8440
Client 8, noise level: 0.5044 (0.4539), real noise ratio: 0.5270
Client 9, noise level: 0.8733 (0.7860), real noise ratio: 0.7985
Client 13, noise level: 0.7546 (0.6792), real noise ratio: 0.7380
Client 15, noise level: 0.9778 (0.8800), real noise ratio: 0.8825
LeNet(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
Traceback (most recent call last):
  File "RFL.py", line 126, in <module>
    w_local, loss_local, f_k = local.train(copy.deepcopy(net_glob).to(args.device), copy.deepcopy(f_G).to(args.device),
  File "/home/ChenSM/code/FL_HLS/util/local_training.py", line 257, in train
    for batch_idx, (images, labels, idxs) in enumerate(self.ldr_train_tmp):
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/code/FL_HLS/util/local_training.py", line 48, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 55504 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9745 (0.8771), real noise ratio: 0.8685
Client 2, noise level: 0.6597 (0.5937), real noise ratio: 0.6035
Client 3, noise level: 0.9589 (0.8630), real noise ratio: 0.8665
Client 4, noise level: 0.5160 (0.4644), real noise ratio: 0.5045
Client 6, noise level: 0.8149 (0.7334), real noise ratio: 0.7565
Client 7, noise level: 0.9369 (0.8432), real noise ratio: 0.8495
Client 8, noise level: 0.5044 (0.4539), real noise ratio: 0.6055
Client 9, noise level: 0.8733 (0.7860), real noise ratio: 0.8465
Client 13, noise level: 0.7546 (0.6792), real noise ratio: 0.7230
Client 15, noise level: 0.9778 (0.8800), real noise ratio: 0.8935
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Traceback (most recent call last):
  File "main_fedpac.py", line 232, in <module>
    w_local, loss, indd, class_center_local, class_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx])
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1272, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train):
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 54880 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%FedPAC_PSL%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedrep , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10,  filter_alg: loss_psl, level_n_system: 0.4 , level_n_lowerb:0.5  

Files already downloaded and verified
Files already downloaded and verified
Client 0, noise level: 0.9745 (0.8771), real noise ratio: 0.8775
Client 2, noise level: 0.6597 (0.5937), real noise ratio: 0.5825
Client 3, noise level: 0.9589 (0.8630), real noise ratio: 0.8560
Client 4, noise level: 0.5160 (0.4644), real noise ratio: 0.5085
Client 6, noise level: 0.8149 (0.7334), real noise ratio: 0.7255
Client 7, noise level: 0.9369 (0.8432), real noise ratio: 0.8510
Client 8, noise level: 0.5044 (0.4539), real noise ratio: 0.5515
Client 9, noise level: 0.8733 (0.7860), real noise ratio: 0.7765
Client 13, noise level: 0.7546 (0.6792), real noise ratio: 0.7370
Client 15, noise level: 0.9778 (0.8800), real noise ratio: 0.9055
fedrep
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'conv2.weight', 'conv2.bias', 'conv1.weight', 'conv1.bias']
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
# Params: 307842 (local), 307192 (global); Percentage 99.79 (307192/307842)
learning rate, batch size: 0.01, 10
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
Traceback (most recent call last):
  File "main_fedpac_psl.py", line 235, in <module>
    w_local, loss, indd, class_center_local, class_num = local.train(net=net_local.to(args.device), class_center_glob=class_center_glob, idx=idx, w_glob_keys=w_glob_keys, lr=args.lr, last=last, concept_matrix_local=concept_matrix[idx], iter_num_now = iter, train_iter=iter)
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 1977, in train
    for batch_idx, (images, labels) in enumerate(self.ldr_train_local):
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/ChenSM/code/FL_HLS/models/Update.py", line 35, in __getitem__
    image, label = self.dataset[self.idxs[item]]
  File "/home/ChenSM/anaconda3/envs/python38/lib/python3.8/site-packages/torchvision/datasets/cifar.py", line 111, in __getitem__
    img, target = self.data[index], self.targets[index]
IndexError: index 53507 is out of bounds for axis 0 with size 50000
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:1   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 1, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.6 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
Client 1, noise level: 0.2179 (0.1961), real noise ratio: 0.2035
Client 5, noise level: 0.0651 (0.0586), real noise ratio: 0.0560
Client 10, noise level: 0.8128 (0.7316), real noise ratio: 0.7280
Client 11, noise level: 0.0757 (0.0681), real noise ratio: 0.0620
Client 12, noise level: 0.6565 (0.5908), real noise ratio: 0.6205
Client 14, noise level: 0.4799 (0.4319), real noise ratio: 0.4415
Client 16, noise level: 0.0000 (0.0000), real noise ratio: 0.1305
Client 17, noise level: 0.2470 (0.2223), real noise ratio: 0.2435
Client 18, noise level: 0.7122 (0.6410), real noise ratio: 0.6705
Client 19, noise level: 0.3246 (0.2921), real noise ratio: 0.4115
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.181, Test loss: 2.091, Test accuracy: 29.18
Round   0, Global train loss: 2.181, Global test loss: 2.104, Global test accuracy: 30.39
Round   1, Train loss: 1.936, Test loss: 1.803, Test accuracy: 36.58
Round   1, Global train loss: 1.936, Global test loss: 1.696, Global test accuracy: 41.35
Round   2, Train loss: 1.881, Test loss: 1.816, Test accuracy: 37.99
Round   2, Global train loss: 1.881, Global test loss: 1.755, Global test accuracy: 44.48
Round   3, Train loss: 1.778, Test loss: 1.737, Test accuracy: 39.18
Round   3, Global train loss: 1.778, Global test loss: 1.499, Global test accuracy: 49.74
Round   4, Train loss: 1.759, Test loss: 1.733, Test accuracy: 39.52
Round   4, Global train loss: 1.759, Global test loss: 1.622, Global test accuracy: 51.26
Round   5, Train loss: 1.709, Test loss: 1.712, Test accuracy: 40.37
Round   5, Global train loss: 1.709, Global test loss: 1.513, Global test accuracy: 49.69
Round   6, Train loss: 1.703, Test loss: 1.696, Test accuracy: 41.45
Round   6, Global train loss: 1.703, Global test loss: 1.611, Global test accuracy: 50.92
Round   7, Train loss: 1.725, Test loss: 1.677, Test accuracy: 42.21
Round   7, Global train loss: 1.725, Global test loss: 1.534, Global test accuracy: 50.07
Round   8, Train loss: 1.875, Test loss: 1.666, Test accuracy: 42.41
Round   8, Global train loss: 1.875, Global test loss: 1.714, Global test accuracy: 49.57
Round   9, Train loss: 1.716, Test loss: 1.653, Test accuracy: 43.17
Round   9, Global train loss: 1.716, Global test loss: 1.663, Global test accuracy: 50.40
Round  10, Train loss: 1.835, Test loss: 1.651, Test accuracy: 43.31
Round  10, Global train loss: 1.835, Global test loss: 1.709, Global test accuracy: 50.52
Round  11, Train loss: 1.602, Test loss: 1.654, Test accuracy: 43.05
Round  11, Global train loss: 1.602, Global test loss: 1.457, Global test accuracy: 53.07
Round  12, Train loss: 1.729, Test loss: 1.638, Test accuracy: 44.07
Round  12, Global train loss: 1.729, Global test loss: 1.802, Global test accuracy: 47.34
Round  13, Train loss: 1.612, Test loss: 1.640, Test accuracy: 44.10
Round  13, Global train loss: 1.612, Global test loss: 1.580, Global test accuracy: 54.15
Round  14, Train loss: 1.449, Test loss: 1.640, Test accuracy: 44.12
Round  14, Global train loss: 1.449, Global test loss: 1.405, Global test accuracy: 53.90
Round  15, Train loss: 1.608, Test loss: 1.635, Test accuracy: 44.41
Round  15, Global train loss: 1.608, Global test loss: 1.661, Global test accuracy: 49.30
Round  16, Train loss: 1.355, Test loss: 1.646, Test accuracy: 44.30
Round  16, Global train loss: 1.355, Global test loss: 1.405, Global test accuracy: 53.89
Round  17, Train loss: 1.644, Test loss: 1.644, Test accuracy: 44.61
Round  17, Global train loss: 1.644, Global test loss: 1.749, Global test accuracy: 48.06
Round  18, Train loss: 1.455, Test loss: 1.650, Test accuracy: 44.59
Round  18, Global train loss: 1.455, Global test loss: 1.481, Global test accuracy: 54.22
Round  19, Train loss: 1.452, Test loss: 1.655, Test accuracy: 44.61
Round  19, Global train loss: 1.452, Global test loss: 1.492, Global test accuracy: 55.25
Round  20, Train loss: 1.304, Test loss: 1.654, Test accuracy: 44.57
Round  20, Global train loss: 1.304, Global test loss: 1.361, Global test accuracy: 55.91
Round  21, Train loss: 1.266, Test loss: 1.665, Test accuracy: 44.51
Round  21, Global train loss: 1.266, Global test loss: 1.423, Global test accuracy: 55.01
Round  22, Train loss: 1.067, Test loss: 1.687, Test accuracy: 44.28
Round  22, Global train loss: 1.067, Global test loss: 1.302, Global test accuracy: 56.90
Round  23, Train loss: 1.298, Test loss: 1.699, Test accuracy: 44.43
Round  23, Global train loss: 1.298, Global test loss: 1.554, Global test accuracy: 51.67
Round  24, Train loss: 1.250, Test loss: 1.720, Test accuracy: 44.02
Round  24, Global train loss: 1.250, Global test loss: 1.629, Global test accuracy: 48.50
Round  25, Train loss: 1.111, Test loss: 1.751, Test accuracy: 44.08
Round  25, Global train loss: 1.111, Global test loss: 1.328, Global test accuracy: 56.41
Round  26, Train loss: 1.089, Test loss: 1.772, Test accuracy: 43.95
Round  26, Global train loss: 1.089, Global test loss: 1.344, Global test accuracy: 55.60
Round  27, Train loss: 1.607, Test loss: 1.784, Test accuracy: 43.77
Round  27, Global train loss: 1.607, Global test loss: 1.817, Global test accuracy: 46.78
Round  28, Train loss: 1.234, Test loss: 1.791, Test accuracy: 43.83
Round  28, Global train loss: 1.234, Global test loss: 1.618, Global test accuracy: 48.03
Round  29, Train loss: 1.296, Test loss: 1.809, Test accuracy: 43.63
Round  29, Global train loss: 1.296, Global test loss: 1.676, Global test accuracy: 50.31
Round  30, Train loss: 1.057, Test loss: 1.805, Test accuracy: 43.96
Round  30, Global train loss: 1.057, Global test loss: 1.556, Global test accuracy: 49.56
Round  31, Train loss: 1.240, Test loss: 1.806, Test accuracy: 43.91
Round  31, Global train loss: 1.240, Global test loss: 1.689, Global test accuracy: 47.99
Round  32, Train loss: 1.202, Test loss: 1.835, Test accuracy: 43.78
Round  32, Global train loss: 1.202, Global test loss: 1.525, Global test accuracy: 51.70
Round  33, Train loss: 0.882, Test loss: 1.869, Test accuracy: 43.62
Round  33, Global train loss: 0.882, Global test loss: 1.291, Global test accuracy: 56.88
Round  34, Train loss: 1.011, Test loss: 1.891, Test accuracy: 43.64
Round  34, Global train loss: 1.011, Global test loss: 1.374, Global test accuracy: 54.62
Round  35, Train loss: 1.332, Test loss: 1.915, Test accuracy: 43.38
Round  35, Global train loss: 1.332, Global test loss: 1.784, Global test accuracy: 43.42
Round  36, Train loss: 1.025, Test loss: 1.939, Test accuracy: 43.20
Round  36, Global train loss: 1.025, Global test loss: 1.490, Global test accuracy: 51.92
Round  37, Train loss: 1.044, Test loss: 1.973, Test accuracy: 43.02
Round  37, Global train loss: 1.044, Global test loss: 1.402, Global test accuracy: 53.14
Round  38, Train loss: 0.907, Test loss: 2.021, Test accuracy: 42.67
Round  38, Global train loss: 0.907, Global test loss: 1.393, Global test accuracy: 53.04
Round  39, Train loss: 0.740, Test loss: 2.047, Test accuracy: 42.69
Round  39, Global train loss: 0.740, Global test loss: 1.335, Global test accuracy: 54.19
Round  40, Train loss: 0.904, Test loss: 2.057, Test accuracy: 43.09
Round  40, Global train loss: 0.904, Global test loss: 1.423, Global test accuracy: 52.84
Round  41, Train loss: 0.789, Test loss: 2.065, Test accuracy: 43.22
Round  41, Global train loss: 0.789, Global test loss: 1.356, Global test accuracy: 54.54
Round  42, Train loss: 0.842, Test loss: 2.080, Test accuracy: 43.16
Round  42, Global train loss: 0.842, Global test loss: 1.437, Global test accuracy: 52.31
Round  43, Train loss: 1.011, Test loss: 2.112, Test accuracy: 43.17
Round  43, Global train loss: 1.011, Global test loss: 1.664, Global test accuracy: 45.93
Round  44, Train loss: 0.983, Test loss: 2.185, Test accuracy: 42.42
Round  44, Global train loss: 0.983, Global test loss: 1.625, Global test accuracy: 47.01
Round  45, Train loss: 1.060, Test loss: 2.180, Test accuracy: 42.49
Round  45, Global train loss: 1.060, Global test loss: 1.625, Global test accuracy: 47.84
Round  46, Train loss: 0.632, Test loss: 2.211, Test accuracy: 42.08
Round  46, Global train loss: 0.632, Global test loss: 1.386, Global test accuracy: 53.45
Round  47, Train loss: 0.699, Test loss: 2.213, Test accuracy: 41.99
Round  47, Global train loss: 0.699, Global test loss: 1.472, Global test accuracy: 50.55
Round  48, Train loss: 0.914, Test loss: 2.249, Test accuracy: 42.08
Round  48, Global train loss: 0.914, Global test loss: 1.572, Global test accuracy: 49.36
Round  49, Train loss: 0.651, Test loss: 2.251, Test accuracy: 42.71
Round  49, Global train loss: 0.651, Global test loss: 1.391, Global test accuracy: 53.79
Round  50, Train loss: 0.810, Test loss: 2.248, Test accuracy: 42.55
Round  50, Global train loss: 0.810, Global test loss: 1.467, Global test accuracy: 51.16
Round  51, Train loss: 0.625, Test loss: 2.278, Test accuracy: 42.30
Round  51, Global train loss: 0.625, Global test loss: 1.322, Global test accuracy: 54.95
Round  52, Train loss: 0.868, Test loss: 2.321, Test accuracy: 41.88
Round  52, Global train loss: 0.868, Global test loss: 1.499, Global test accuracy: 50.72
Round  53, Train loss: 0.807, Test loss: 2.358, Test accuracy: 41.73
Round  53, Global train loss: 0.807, Global test loss: 1.397, Global test accuracy: 53.25
Round  54, Train loss: 0.803, Test loss: 2.392, Test accuracy: 42.19
Round  54, Global train loss: 0.803, Global test loss: 1.620, Global test accuracy: 46.25
Round  55, Train loss: 0.932, Test loss: 2.441, Test accuracy: 41.98
Round  55, Global train loss: 0.932, Global test loss: 1.684, Global test accuracy: 46.08
Round  56, Train loss: 0.939, Test loss: 2.477, Test accuracy: 41.74
Round  56, Global train loss: 0.939, Global test loss: 1.585, Global test accuracy: 49.27
Round  57, Train loss: 0.558, Test loss: 2.494, Test accuracy: 41.69
Round  57, Global train loss: 0.558, Global test loss: 1.393, Global test accuracy: 53.62
Round  58, Train loss: 0.613, Test loss: 2.520, Test accuracy: 41.63
Round  58, Global train loss: 0.613, Global test loss: 1.529, Global test accuracy: 48.65
Round  59, Train loss: 0.672, Test loss: 2.510, Test accuracy: 42.40
Round  59, Global train loss: 0.672, Global test loss: 1.501, Global test accuracy: 48.91
Round  60, Train loss: 0.689, Test loss: 2.529, Test accuracy: 42.37
Round  60, Global train loss: 0.689, Global test loss: 1.490, Global test accuracy: 50.78
Round  61, Train loss: 0.761, Test loss: 2.545, Test accuracy: 42.15
Round  61, Global train loss: 0.761, Global test loss: 1.466, Global test accuracy: 51.13
Round  62, Train loss: 0.719, Test loss: 2.563, Test accuracy: 41.83
Round  62, Global train loss: 0.719, Global test loss: 1.541, Global test accuracy: 47.86
Round  63, Train loss: 0.831, Test loss: 2.545, Test accuracy: 41.85
Round  63, Global train loss: 0.831, Global test loss: 1.834, Global test accuracy: 36.10
Round  64, Train loss: 0.767, Test loss: 2.553, Test accuracy: 41.60
Round  64, Global train loss: 0.767, Global test loss: 1.571, Global test accuracy: 47.48
Round  65, Train loss: 0.654, Test loss: 2.616, Test accuracy: 41.49
Round  65, Global train loss: 0.654, Global test loss: 1.493, Global test accuracy: 49.83
Round  66, Train loss: 0.611, Test loss: 2.651, Test accuracy: 41.25
Round  66, Global train loss: 0.611, Global test loss: 1.454, Global test accuracy: 51.23
Round  67, Train loss: 0.546, Test loss: 2.699, Test accuracy: 41.08
Round  67, Global train loss: 0.546, Global test loss: 1.458, Global test accuracy: 51.32
Round  68, Train loss: 0.424, Test loss: 2.738, Test accuracy: 41.10
Round  68, Global train loss: 0.424, Global test loss: 1.412, Global test accuracy: 51.73
Round  69, Train loss: 0.605, Test loss: 2.748, Test accuracy: 41.41
Round  69, Global train loss: 0.605, Global test loss: 1.440, Global test accuracy: 51.71
Round  70, Train loss: 0.677, Test loss: 2.774, Test accuracy: 41.67
Round  70, Global train loss: 0.677, Global test loss: 1.657, Global test accuracy: 44.88
Round  71, Train loss: 0.661, Test loss: 2.809, Test accuracy: 41.44
Round  71, Global train loss: 0.661, Global test loss: 1.473, Global test accuracy: 50.48
Round  72, Train loss: 0.852, Test loss: 2.861, Test accuracy: 41.52
Round  72, Global train loss: 0.852, Global test loss: 1.825, Global test accuracy: 39.73
Round  73, Train loss: 0.691, Test loss: 2.857, Test accuracy: 41.47
Round  73, Global train loss: 0.691, Global test loss: 1.653, Global test accuracy: 44.37
Round  74, Train loss: 0.506, Test loss: 2.838, Test accuracy: 41.85
Round  74, Global train loss: 0.506, Global test loss: 1.482, Global test accuracy: 50.08
Round  75, Train loss: 0.511, Test loss: 2.823, Test accuracy: 41.97
Round  75, Global train loss: 0.511, Global test loss: 1.441, Global test accuracy: 51.87
Round  76, Train loss: 0.439, Test loss: 2.886, Test accuracy: 41.78
Round  76, Global train loss: 0.439, Global test loss: 1.429, Global test accuracy: 52.18
Round  77, Train loss: 0.696, Test loss: 2.917, Test accuracy: 41.78
Round  77, Global train loss: 0.696, Global test loss: 1.737, Global test accuracy: 41.60
Round  78, Train loss: 0.611, Test loss: 2.929, Test accuracy: 41.66
Round  78, Global train loss: 0.611, Global test loss: 1.485, Global test accuracy: 50.38
Round  79, Train loss: 0.691, Test loss: 2.964, Test accuracy: 41.56
Round  79, Global train loss: 0.691, Global test loss: 1.645, Global test accuracy: 44.63
Round  80, Train loss: 0.441, Test loss: 2.994, Test accuracy: 41.48
Round  80, Global train loss: 0.441, Global test loss: 1.445, Global test accuracy: 51.58
Round  81, Train loss: 0.638, Test loss: 3.017, Test accuracy: 41.73
Round  81, Global train loss: 0.638, Global test loss: 1.655, Global test accuracy: 45.87
Round  82, Train loss: 0.395, Test loss: 3.041, Test accuracy: 41.67
Round  82, Global train loss: 0.395, Global test loss: 1.383, Global test accuracy: 52.99
Round  83, Train loss: 0.386, Test loss: 3.070, Test accuracy: 41.38
Round  83, Global train loss: 0.386, Global test loss: 1.470, Global test accuracy: 50.82
Round  84, Train loss: 0.643, Test loss: 3.071, Test accuracy: 41.31
Round  84, Global train loss: 0.643, Global test loss: 1.823, Global test accuracy: 38.53
Round  85, Train loss: 0.729, Test loss: 3.073, Test accuracy: 41.20
Round  85, Global train loss: 0.729, Global test loss: 1.624, Global test accuracy: 46.53
Round  86, Train loss: 0.392, Test loss: 3.104, Test accuracy: 41.24
Round  86, Global train loss: 0.392, Global test loss: 1.380, Global test accuracy: 52.66
Round  87, Train loss: 0.416, Test loss: 3.145, Test accuracy: 41.30
Round  87, Global train loss: 0.416, Global test loss: 1.507, Global test accuracy: 49.14
Round  88, Train loss: 0.485, Test loss: 3.161, Test accuracy: 40.91
Round  88, Global train loss: 0.485, Global test loss: 1.662, Global test accuracy: 42.15
Round  89, Train loss: 0.491, Test loss: 3.149, Test accuracy: 40.94
Round  89, Global train loss: 0.491, Global test loss: 1.576, Global test accuracy: 46.42
Round  90, Train loss: 0.636, Test loss: 3.174, Test accuracy: 41.34
Round  90, Global train loss: 0.636, Global test loss: 1.839, Global test accuracy: 38.30
Round  91, Train loss: 0.765, Test loss: 3.191, Test accuracy: 41.40
Round  91, Global train loss: 0.765, Global test loss: 1.906, Global test accuracy: 37.86
Round  92, Train loss: 0.444, Test loss: 3.257, Test accuracy: 41.28
Round  92, Global train loss: 0.444, Global test loss: 1.598, Global test accuracy: 46.02
Round  93, Train loss: 0.516, Test loss: 3.249, Test accuracy: 41.24
Round  93, Global train loss: 0.516, Global test loss: 1.529, Global test accuracy: 47.51
Round  94, Train loss: 0.430, Test loss: 3.283, Test accuracy: 40.97
Round  94, Global train loss: 0.430, Global test loss: 1.533, Global test accuracy: 48.62
Round  95, Train loss: 0.616, Test loss: 3.280, Test accuracy: 41.16
Round  95, Global train loss: 0.616, Global test loss: 1.861, Global test accuracy: 36.55
Round  96, Train loss: 0.492, Test loss: 3.298, Test accuracy: 41.38
Round  96, Global train loss: 0.492, Global test loss: 1.542, Global test accuracy: 47.59
Round  97, Train loss: 0.561, Test loss: 3.314, Test accuracy: 41.16
Round  97, Global train loss: 0.561, Global test loss: 1.860, Global test accuracy: 36.77
Round  98, Train loss: 0.497, Test loss: 3.332, Test accuracy: 41.02
Round  98, Global train loss: 0.497, Global test loss: 1.613, Global test accuracy: 46.40
Round  99, Train loss: 0.341, Test loss: 3.346, Test accuracy: 40.88
Round  99, Global train loss: 0.341, Global test loss: 1.412, Global test accuracy: 53.55
Final Round, Train loss: 0.321, Test loss: 3.789, Test accuracy: 41.67
Final Round, Global train loss: 0.321, Global test loss: 1.412, Global test accuracy: 53.55
Average accuracy final 10 rounds: 41.184250000000006 

Average global accuracy final 10 rounds: 43.91625 

6107.047271966934
[5.386111497879028, 10.772222995758057, 15.865703821182251, 20.959184646606445, 25.93631076812744, 30.913436889648438, 35.960782051086426, 41.008127212524414, 46.033775091171265, 51.059422969818115, 55.45598840713501, 59.852553844451904, 64.2971670627594, 68.7417802810669, 73.06915068626404, 77.39652109146118, 81.90409708023071, 86.41167306900024, 90.74072289466858, 95.06977272033691, 99.41260409355164, 103.75543546676636, 108.73759078979492, 113.71974611282349, 118.6700394153595, 123.62033271789551, 128.59824442863464, 133.57615613937378, 138.5872299671173, 143.59830379486084, 148.59299063682556, 153.58767747879028, 158.49811840057373, 163.40855932235718, 167.9216685295105, 172.43477773666382, 176.79213762283325, 181.14949750900269, 185.53840613365173, 189.92731475830078, 194.30293607711792, 198.67855739593506, 203.06322073936462, 207.4478840827942, 211.84226274490356, 216.23664140701294, 220.60866260528564, 224.98068380355835, 229.33754062652588, 233.6943974494934, 238.02805376052856, 242.36171007156372, 246.70575761795044, 251.04980516433716, 255.39291262626648, 259.7360200881958, 264.06856989860535, 268.4011197090149, 272.83860993385315, 277.2761001586914, 281.69577264785767, 286.1154451370239, 290.4603934288025, 294.80534172058105, 299.1022982597351, 303.39925479888916, 307.6782913208008, 311.9573278427124, 316.2799780368805, 320.6026282310486, 324.94816970825195, 329.2937111854553, 333.61361360549927, 337.9335160255432, 342.2618741989136, 346.59023237228394, 350.8829824924469, 355.17573261260986, 359.4979968070984, 363.8202610015869, 368.14731645584106, 372.4743719100952, 376.7871789932251, 381.099986076355, 385.41578102111816, 389.73157596588135, 394.0649118423462, 398.39824771881104, 402.8712685108185, 407.3442893028259, 412.299192905426, 417.2540965080261, 422.1623969078064, 427.07069730758667, 431.3887302875519, 435.7067632675171, 440.0091052055359, 444.3114471435547, 448.6398935317993, 452.96833992004395, 457.2560682296753, 461.54379653930664, 465.81560921669006, 470.0874218940735, 474.3822298049927, 478.67703771591187, 483.04063749313354, 487.4042372703552, 491.7375235557556, 496.070809841156, 500.4193227291107, 504.76783561706543, 509.0691695213318, 513.3705034255981, 517.6508684158325, 521.9312334060669, 526.2547137737274, 530.5781941413879, 534.9132115840912, 539.2482290267944, 543.6211919784546, 547.9941549301147, 552.3514020442963, 556.7086491584778, 561.0609896183014, 565.413330078125, 569.7619352340698, 574.1105403900146, 578.4216642379761, 582.7327880859375, 586.99573802948, 591.2586879730225, 595.5727646350861, 599.8868412971497, 604.2237141132355, 608.5605869293213, 612.9557993412018, 617.3510117530823, 621.7525699138641, 626.154128074646, 630.4726960659027, 634.7912640571594, 639.0991640090942, 643.407063961029, 647.8073461055756, 652.2076282501221, 656.6221392154694, 661.0366501808167, 665.3797612190247, 669.7228722572327, 674.072215795517, 678.4215593338013, 682.7672100067139, 687.1128606796265, 691.4228317737579, 695.7328028678894, 700.0860004425049, 704.4391980171204, 708.7384703159332, 713.0377426147461, 717.4266164302826, 721.8154902458191, 726.1985070705414, 730.5815238952637, 735.0100636482239, 739.4386034011841, 743.8863353729248, 748.3340673446655, 752.7391028404236, 757.1441383361816, 761.4538111686707, 765.7634840011597, 770.0893440246582, 774.4152040481567, 778.8535878658295, 783.2919716835022, 787.6988105773926, 792.105649471283, 796.5581889152527, 801.0107283592224, 805.3962295055389, 809.7817306518555, 814.1962659358978, 818.6108012199402, 822.9797923564911, 827.348783493042, 831.7173118591309, 836.0858402252197, 840.449568271637, 844.8132963180542, 849.2543892860413, 853.6954822540283, 858.217903137207, 862.7403240203857, 867.1949291229248, 871.6495342254639, 876.0250723361969, 880.4006104469299, 884.7595226764679, 889.1184349060059, 891.3308551311493, 893.5432753562927]
[29.185, 29.185, 36.575, 36.575, 37.9875, 37.9875, 39.1775, 39.1775, 39.5225, 39.5225, 40.3675, 40.3675, 41.4525, 41.4525, 42.2075, 42.2075, 42.415, 42.415, 43.17, 43.17, 43.31, 43.31, 43.0475, 43.0475, 44.0725, 44.0725, 44.1025, 44.1025, 44.12, 44.12, 44.4075, 44.4075, 44.295, 44.295, 44.6125, 44.6125, 44.585, 44.585, 44.6075, 44.6075, 44.5725, 44.5725, 44.5075, 44.5075, 44.285, 44.285, 44.43, 44.43, 44.0225, 44.0225, 44.08, 44.08, 43.945, 43.945, 43.765, 43.765, 43.8275, 43.8275, 43.6325, 43.6325, 43.9575, 43.9575, 43.9125, 43.9125, 43.7825, 43.7825, 43.62, 43.62, 43.64, 43.64, 43.385, 43.385, 43.205, 43.205, 43.0225, 43.0225, 42.6725, 42.6725, 42.6925, 42.6925, 43.095, 43.095, 43.2175, 43.2175, 43.155, 43.155, 43.175, 43.175, 42.4225, 42.4225, 42.4875, 42.4875, 42.0775, 42.0775, 41.9875, 41.9875, 42.0775, 42.0775, 42.7125, 42.7125, 42.5525, 42.5525, 42.2975, 42.2975, 41.885, 41.885, 41.7325, 41.7325, 42.19, 42.19, 41.9775, 41.9775, 41.745, 41.745, 41.69, 41.69, 41.635, 41.635, 42.395, 42.395, 42.3675, 42.3675, 42.1525, 42.1525, 41.825, 41.825, 41.8475, 41.8475, 41.5975, 41.5975, 41.4875, 41.4875, 41.2525, 41.2525, 41.075, 41.075, 41.105, 41.105, 41.4125, 41.4125, 41.6675, 41.6675, 41.4375, 41.4375, 41.525, 41.525, 41.465, 41.465, 41.8475, 41.8475, 41.9725, 41.9725, 41.785, 41.785, 41.7775, 41.7775, 41.665, 41.665, 41.565, 41.565, 41.485, 41.485, 41.725, 41.725, 41.67, 41.67, 41.38, 41.38, 41.31, 41.31, 41.205, 41.205, 41.2425, 41.2425, 41.305, 41.305, 40.9125, 40.9125, 40.9375, 40.9375, 41.335, 41.335, 41.3975, 41.3975, 41.285, 41.285, 41.2375, 41.2375, 40.9675, 40.9675, 41.165, 41.165, 41.3825, 41.3825, 41.165, 41.165, 41.025, 41.025, 40.8825, 40.8825, 41.675, 41.675]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  fedavg  local_only:0   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

# alg: fedavg , epochs: 100, shard_per_user: 10, limit_local_output: 0, local_rep_ep: 3 , local_only: 0, is_concept_shift: 0, dataset: cifar10, level_n_system: 0.6 , level_n_lowerb:0.0  

Files already downloaded and verified
Files already downloaded and verified
Client 1, noise level: 0.2179 (0.1961), real noise ratio: 0.2110
Client 5, noise level: 0.0651 (0.0586), real noise ratio: 0.0590
Client 10, noise level: 0.8128 (0.7316), real noise ratio: 0.7375
Client 11, noise level: 0.0757 (0.0681), real noise ratio: 0.0945
Client 12, noise level: 0.6565 (0.5908), real noise ratio: 0.5960
Client 14, noise level: 0.4799 (0.4319), real noise ratio: 0.4620
Client 16, noise level: 0.0000 (0.0000), real noise ratio: 0.0000
Client 17, noise level: 0.2470 (0.2223), real noise ratio: 0.2830
Client 18, noise level: 0.7122 (0.6410), real noise ratio: 0.6485
Client 19, noise level: 0.3246 (0.2921), real noise ratio: 0.4320
fedavg
CNNCifar(
  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=64, bias=True)
  (fc3): Linear(in_features=64, out_features=10, bias=True)
)
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
10
[]
['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']
learning rate, batch size: 0.01, 10 

Round   0, Train loss: 2.071, Test loss: 1.885, Test accuracy: 33.17
Round   0, Global train loss: 2.071, Global test loss: 1.888, Global test accuracy: 34.17
Round   1, Train loss: 1.843, Test loss: 1.671, Test accuracy: 39.60
Round   1, Global train loss: 1.843, Global test loss: 1.572, Global test accuracy: 44.01
Round   2, Train loss: 1.781, Test loss: 1.650, Test accuracy: 42.11
Round   2, Global train loss: 1.781, Global test loss: 1.540, Global test accuracy: 48.60
Round   3, Train loss: 1.666, Test loss: 1.616, Test accuracy: 42.27
Round   3, Global train loss: 1.666, Global test loss: 1.400, Global test accuracy: 52.32
Round   4, Train loss: 1.572, Test loss: 1.575, Test accuracy: 43.93
Round   4, Global train loss: 1.572, Global test loss: 1.321, Global test accuracy: 55.42
Round   5, Train loss: 1.509, Test loss: 1.533, Test accuracy: 45.94
Round   5, Global train loss: 1.509, Global test loss: 1.238, Global test accuracy: 58.75
Round   6, Train loss: 1.476, Test loss: 1.496, Test accuracy: 47.59
Round   6, Global train loss: 1.476, Global test loss: 1.214, Global test accuracy: 59.87
Round   7, Train loss: 1.470, Test loss: 1.446, Test accuracy: 50.12
Round   7, Global train loss: 1.470, Global test loss: 1.172, Global test accuracy: 62.03
Round   8, Train loss: 1.396, Test loss: 1.391, Test accuracy: 52.22
Round   8, Global train loss: 1.396, Global test loss: 1.116, Global test accuracy: 63.54
Round   9, Train loss: 1.379, Test loss: 1.372, Test accuracy: 52.88
Round   9, Global train loss: 1.379, Global test loss: 1.097, Global test accuracy: 64.70
Round  10, Train loss: 1.315, Test loss: 1.333, Test accuracy: 54.58
Round  10, Global train loss: 1.315, Global test loss: 1.048, Global test accuracy: 65.53
Round  11, Train loss: 1.323, Test loss: 1.323, Test accuracy: 55.02
Round  11, Global train loss: 1.323, Global test loss: 1.055, Global test accuracy: 65.95
Round  12, Train loss: 1.301, Test loss: 1.309, Test accuracy: 55.61
Round  12, Global train loss: 1.301, Global test loss: 1.012, Global test accuracy: 67.31
Round  13, Train loss: 1.200, Test loss: 1.275, Test accuracy: 57.14
Round  13, Global train loss: 1.200, Global test loss: 0.983, Global test accuracy: 66.89
Round  14, Train loss: 1.299, Test loss: 1.239, Test accuracy: 58.37
Round  14, Global train loss: 1.299, Global test loss: 1.031, Global test accuracy: 67.54
Round  15, Train loss: 1.224, Test loss: 1.225, Test accuracy: 59.04
Round  15, Global train loss: 1.224, Global test loss: 0.974, Global test accuracy: 69.02
Round  16, Train loss: 1.204, Test loss: 1.219, Test accuracy: 59.20
Round  16, Global train loss: 1.204, Global test loss: 0.944, Global test accuracy: 69.71
Round  17, Train loss: 1.201, Test loss: 1.220, Test accuracy: 59.34
Round  17, Global train loss: 1.201, Global test loss: 0.947, Global test accuracy: 69.47
Round  18, Train loss: 1.207, Test loss: 1.204, Test accuracy: 60.31
Round  18, Global train loss: 1.207, Global test loss: 0.916, Global test accuracy: 70.53
Round  19, Train loss: 1.094, Test loss: 1.182, Test accuracy: 61.01
Round  19, Global train loss: 1.094, Global test loss: 0.890, Global test accuracy: 70.97
Round  20, Train loss: 1.155, Test loss: 1.177, Test accuracy: 61.34
Round  20, Global train loss: 1.155, Global test loss: 0.922, Global test accuracy: 70.96
Round  21, Train loss: 1.079, Test loss: 1.178, Test accuracy: 61.33
Round  21, Global train loss: 1.079, Global test loss: 0.871, Global test accuracy: 71.45
Round  22, Train loss: 1.087, Test loss: 1.191, Test accuracy: 61.31
Round  22, Global train loss: 1.087, Global test loss: 0.917, Global test accuracy: 70.68
Round  23, Train loss: 1.058, Test loss: 1.185, Test accuracy: 61.59
Round  23, Global train loss: 1.058, Global test loss: 0.869, Global test accuracy: 71.48
Round  24, Train loss: 0.999, Test loss: 1.183, Test accuracy: 61.60
Round  24, Global train loss: 0.999, Global test loss: 0.853, Global test accuracy: 71.42
Round  25, Train loss: 1.025, Test loss: 1.184, Test accuracy: 61.73
Round  25, Global train loss: 1.025, Global test loss: 0.875, Global test accuracy: 71.11
Round  26, Train loss: 1.102, Test loss: 1.154, Test accuracy: 62.42
Round  26, Global train loss: 1.102, Global test loss: 0.889, Global test accuracy: 71.77
Round  27, Train loss: 1.022, Test loss: 1.134, Test accuracy: 63.40
Round  27, Global train loss: 1.022, Global test loss: 0.826, Global test accuracy: 72.92
Round  28, Train loss: 0.995, Test loss: 1.131, Test accuracy: 63.82
Round  28, Global train loss: 0.995, Global test loss: 0.822, Global test accuracy: 73.14
Round  29, Train loss: 1.026, Test loss: 1.142, Test accuracy: 63.59
Round  29, Global train loss: 1.026, Global test loss: 0.842, Global test accuracy: 73.04
Round  30, Train loss: 1.024, Test loss: 1.136, Test accuracy: 63.91
Round  30, Global train loss: 1.024, Global test loss: 0.850, Global test accuracy: 72.29
Round  31, Train loss: 1.000, Test loss: 1.132, Test accuracy: 63.92
Round  31, Global train loss: 1.000, Global test loss: 0.847, Global test accuracy: 72.81
Round  32, Train loss: 0.969, Test loss: 1.123, Test accuracy: 64.32
Round  32, Global train loss: 0.969, Global test loss: 0.820, Global test accuracy: 73.26
Round  33, Train loss: 0.972, Test loss: 1.118, Test accuracy: 64.44
Round  33, Global train loss: 0.972, Global test loss: 0.848, Global test accuracy: 72.25
Round  34, Train loss: 0.959, Test loss: 1.115, Test accuracy: 64.35
Round  34, Global train loss: 0.959, Global test loss: 0.810, Global test accuracy: 73.44
Round  35, Train loss: 0.947, Test loss: 1.116, Test accuracy: 64.70
Round  35, Global train loss: 0.947, Global test loss: 0.836, Global test accuracy: 72.90
Round  36, Train loss: 0.950, Test loss: 1.132, Test accuracy: 64.30
Round  36, Global train loss: 0.950, Global test loss: 0.827, Global test accuracy: 73.14
Round  37, Train loss: 0.959, Test loss: 1.139, Test accuracy: 64.08
Round  37, Global train loss: 0.959, Global test loss: 0.836, Global test accuracy: 72.98
Round  38, Train loss: 0.965, Test loss: 1.119, Test accuracy: 64.75
Round  38, Global train loss: 0.965, Global test loss: 0.814, Global test accuracy: 74.13
Round  39, Train loss: 0.959, Test loss: 1.124, Test accuracy: 64.52
Round  39, Global train loss: 0.959, Global test loss: 0.846, Global test accuracy: 72.88